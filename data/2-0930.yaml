- en: 'From Biological Learning to Artificial Neural Network: What’s Next?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从生物学习到人工神经网络：接下来会是什么？
- en: 原文：[https://towardsdatascience.com/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5](https://towardsdatascience.com/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5](https://towardsdatascience.com/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5)
- en: Can artificial intelligence help us understand how the brain works?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能能否帮助我们理解大脑是如何工作的？
- en: '[](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)[![Stephanie
    Shen](../Images/857cccbe84f0d3a9886c84acfbbac03e.png)](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------)
    [Stephanie Shen](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)[![Stephanie
    Shen](../Images/857cccbe84f0d3a9886c84acfbbac03e.png)](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------)
    [Stephanie Shen](https://jshen9889.medium.com/?source=post_page-----c8cf0d351af5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------)
    ·10 min read·Oct 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----c8cf0d351af5--------------------------------)
    ·10分钟阅读·2023年10月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Back in the beginning of the 21st century, when I studied for MBA at NYU Stern,
    one class I took was called Data Mining, which introduced many algorithms to “mine”
    the data, meaning to automatically find the meaning of the data for forecasts
    and decision making. The neural network was one of them, but it was far from the
    top choices because it was slow, required a lot of data to train, and, hence,
    had minimal use cases. Twenty years later, neural network algorithms have thrived
    as the cornerstones of machine learning and artificial intelligence (AI) due to
    the tremendous computational power that removed the fundamental obstacle and,
    in turn, led to the invention of more advanced algorithms and models.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在21世纪初，当我在NYU Stern学习MBA时，我上过一门叫做数据挖掘的课程，介绍了许多算法用于“挖掘”数据，意思是自动发现数据的意义以进行预测和决策。神经网络就是其中之一，但由于其速度较慢，需要大量数据进行训练，因此其应用案例很少。二十年后，神经网络算法在机器学习和人工智能（AI）的基础中蓬勃发展，这要归功于巨大的计算能力，这种能力去除了根本障碍，从而推动了更先进算法和模型的发明。
- en: With the fast advances in artificial neural networks and deep learning, AI has
    surpassed humans in certain areas. Many intriguing questions have arisen, such
    as how similar AI and the human brain are, what the future objective of AI is,
    and to what degree AI can replace human intelligence. In this article, I will
    start with the neural mechanisms of biological learning and how they have inspired
    AI. A better understanding of the history will help us grasp the fundamental difference
    between artificial neural networks and other machine learning models (e.g., support
    vector machines, decision trees, random forests). It was the learning features
    inspired by the brain that led to the recent breakthroughs of artificial neural
    networks, including convolution neural networks (CNN) for image recognition and
    large language models (LLM) for generative AI. I will then discuss the differences
    between human intelligence and AI and our perspective on the future direction
    of AI. What we expect to see next is that AI will continue to benefit from discoveries
    in the brain, and, equally important, AI can also help us better understand how
    the brain works. The continuous exchange of ideas will propel both neuroscience
    and AI to advance at a healthy, faster pace.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工神经网络和深度学习的快速发展，AI在某些领域已超越了人类。许多引人入胜的问题出现了，比如AI与人脑有多相似、AI的未来目标是什么，以及AI可以在多大程度上取代人类智能。在本文中，我将从生物学习的神经机制和它们如何启发AI开始。对历史的更好理解将帮助我们把握人工神经网络与其他机器学习模型（如支持向量机、决策树、随机森林）之间的根本区别。正是受脑部学习特征的启发，人工神经网络取得了最近的突破，包括用于图像识别的卷积神经网络（CNN）和用于生成AI的大型语言模型（LLM）。然后，我将讨论人类智能与AI的区别以及我们对AI未来方向的看法。我们期望看到的是，AI将继续从脑部发现中受益，同样重要的是，AI也可以帮助我们更好地理解大脑的工作原理。思想的不断交流将推动神经科学和AI以健康、快速的步伐发展。
- en: '**Biological Learning**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**生物学习**'
- en: Learning is an essential feature of animal and human brains. When a baby is
    born, she has to learn almost everything from scratch, including recognizing faces,
    speaking, and walking, followed by many years of school education and training.
    How does learning happen in the brain?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 学习是动物和人类大脑的重要特征。当一个婴儿出生时，她必须从头开始学习几乎所有的东西，包括识别面孔、说话和走路，随后是多年的学校教育和培训。学习在大脑中是如何发生的？
- en: 'Toward the end of the 19th century, Spanish neuroscientist Santiago Ramón y
    Cajal adopted a unique method (Golgi method) to stain neurons and discovered their
    particular shapes and connectivity patterns. Using his excellent artistic talent,
    Cajal made extensive detailed drawings of neural anatomies of major brain regions
    of many species. He identified each neuron has an axon and many dendrites like
    tree branches. Below is one of his drawings of the pigeon cerebellum. It shows
    two types of cells: two large Purkinje neurons on the top and four small granule
    cells at the bottom. Each neuron has the typical axon and dendrites. The axon
    of each granule cell lands on one of the rich dendrite branches of the Purkinje
    neurons. Because the Golgi method does not stain every cell in the brain, the
    eye-catching size of the Purkinje cell’s dendrites suggests that the cell receives
    hundreds or thousands of connections from granule cells in the cerebellum.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在19世纪末，西班牙神经科学家圣地亚哥·拉蒙·卡哈尔采用了一种独特的方法（戈尔基法）来染色神经元，并发现了它们特有的形状和连接模式。凭借出色的艺术天赋，卡哈尔详细描绘了许多物种主要脑区的神经解剖结构。他发现每个神经元都有一个轴突和许多类似树枝的树突。下图是他对鸽子小脑的其中一幅图画，展示了两种类型的细胞：顶部的两个大型普金耶神经元和底部的四个小颗粒细胞。每个神经元都有典型的轴突和树突。每个颗粒细胞的轴突接在普金耶神经元丰富的树突分支之一上。由于戈尔基法并不会染色大脑中的每个细胞，普金耶细胞树突的显著大小表明该细胞从小脑的颗粒细胞处接收了数百或数千个连接。
- en: '![](../Images/e0a823ec8743cb8aad0de40454b7f459.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0a823ec8743cb8aad0de40454b7f459.png)'
- en: Drawing of Purkinje cells (A) and granule cells (B) from the pigeon cerebellum.
    By Santiago Ramón y Cajal. Image source [Wikipedia Commons](https://en.wikipedia.org/wiki/File:PurkinjeCell.jpg).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图为鸽子小脑中的普金耶细胞（A）和颗粒细胞（B）。作者：圣地亚哥·拉蒙·卡哈尔。图片来源 [维基百科公共资源](https://en.wikipedia.org/wiki/File:PurkinjeCell.jpg)。
- en: Cajal confirmed that although those cells connect with each other, their cell
    membranes are not continuous. There is a tiny gap between an axon terminal and
    the connected dendrite, which is called the synapse. He also made some extraordinary
    drawings of complex neuronal connectivity in animal brains. Below is an example
    of the hippocampus, the brain region we know today responsible for short-term
    learning and memory. We can see that the cell bodies line up in layers. An axon
    traverses between the layers while intersecting with multiple dendrites and cell
    bodies. This drawing was among the first accurate portrayals of biological neural
    networks in the brain. His original investigations of the neuronal structure of
    the brain made him the father of modern neuroscience. Cajal and Golgi won the
    Nobel Prize in Physiology and Medicine in 1906.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 卡哈尔确认，尽管这些细胞相互连接，但它们的细胞膜并不连续。轴突末端与连接的树突之间存在一个微小的间隙，称为突触。他还绘制了一些关于动物大脑复杂神经连接的非凡图画。下面是海马体的一个例子，今天我们知道它负责短期学习和记忆的大脑区域。我们可以看到，细胞体排成层状。一个轴突在层之间穿行，同时与多个树突和细胞体交叉。这幅图是对大脑中生物神经网络的最早准确描绘之一。他对大脑神经结构的原始研究使他成为现代神经科学的奠基人。卡哈尔和戈尔基于1906年获得了生理学和医学诺贝尔奖。
- en: '![](../Images/d6b516040858ff3a899d48e207af3667.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6b516040858ff3a899d48e207af3667.png)'
- en: Drawing of the neural circuitry of the rodent hippocampus. By Santiago Ramón
    y Cajal. Image source [Wikipedia Commons](https://commons.wikimedia.org/wiki/File:CajalHippocampus.jpeg)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 哺乳动物海马体神经电路的绘图。作者：圣地亚哥·拉蒙·卡哈尔。图片来源 [维基百科公用资源](https://commons.wikimedia.org/wiki/File:CajalHippocampus.jpeg)
- en: Neural communications require action potentials firing within a cell and neurotransmitters
    released in the synapses. An action potential, also called nerve impulse or spike,
    occurs when the electrical voltage potential of the neuronal cell membrane rapidly
    rises and falls. This depolarization causes adjacent call membrane locations to
    depolarize similarly so that it quickly propagates along an axon in milliseconds.
    When a spike reaches the axon end, the synapses release neural transmitters, the
    small molecules in the brain that act as messengers to communicate across neurons.
    When the post-synaptic neuron receives a sufficient amount of these neurotransmitters
    via its multiple dendrites, it fires its electrical pulses, which then travel
    down its axon toward the next connected cell via synapses in the same fashion.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 神经通信需要细胞内的动作电位发放和突触中释放的神经递质。动作电位，也称为神经冲动或尖峰，发生在神经元细胞膜的电压迅速升高和降低时。这种去极化导致相邻的膜位置也类似去极化，从而在毫秒内沿轴突快速传播。当尖峰到达轴突末端时，突触释放神经递质，这些小分子在大脑中充当信使，跨神经元进行通信。当突触后神经元通过其多个树突接收到足够的神经递质时，它会发放电信号，这些电信号然后通过突触以相同的方式沿其轴突向下一个连接的细胞传递。
- en: '![](../Images/a188137ccd8b174311984d7377398a57.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a188137ccd8b174311984d7377398a57.png)'
- en: 'Image Source: [Wikipedia Commons](https://en.wikipedia.org/wiki/Action_potential)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [维基百科公用资源](https://en.wikipedia.org/wiki/Action_potential)'
- en: 'A single neuron itself is an information processing system. Dendrites play
    a role in accepting and transmitting information from many sources, while the
    cell body integrates the signals and passes them via the axon to the next neuron.
    There are many variables at this level:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 单个神经元本身就是一个信息处理系统。树突在接受和传递来自多个来源的信息中发挥作用，而细胞体则整合信号并通过轴突将其传递给下一个神经元。在这一层面上，有许多变量：
- en: A neuron does not always fire when receiving information from its dendrites
    but only when the incoming signals reach the threshold.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经元在接收到来自树突的信息时并不总是会发放信号，而仅在接收到的信号达到阈值时才会发放。
- en: Axons can transmit information between layers within the same brain area or
    travel to another region over a long distance (e.g., over 1m) in the nervous system.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 轴突可以在同一大脑区域内的层之间传递信息，也可以在神经系统中长距离（例如超过1米）传递到另一个区域。
- en: The higher the frequency of action potentials, the more neurotransmitters an
    axon synapse will release, and the more likely the post-synaptic cell will fire.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 动作电位的频率越高，轴突突触释放的神经递质就越多，突触后细胞发放信号的可能性也就越大。
- en: However, just like any other cell in our body, a neuron is tiny (its cell body’s
    diameter is 4–100 micrometers), and the processing in a single neuron is limited.
    Another essential role of a neuron is to communicate within the network. The amount
    of information in transmission is not only related to a single cell’s firing frequency
    but also the number of cells firing simultaneously in the network.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如我们身体中的其他细胞一样，神经元非常微小（其细胞体直径为4–100微米），单个神经元的处理能力有限。神经元的另一个重要作用是进行网络内的通信。传输的信息量不仅与单个细胞的放电频率有关，还与网络中同时放电的细胞数量有关。
- en: 'In 1949, psychologist Donal O. Hebb gave the famous Hebb rules in his book
    “The Organization of Behavior: A Neuropsychological Theory”:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 1949年，心理学家Donal O. Hebb在他的书《行为的组织：一种神经心理学理论》中提出了著名的赫布规则：
- en: '*When an axon of cell A is near enough to excite cell B and repeatedly or persistently
    takes part in firing it, some growth process or metabolic change takes place in
    one or both cells such that A’s efficiency, as one of the cells firing B, is increased.*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*当细胞A的轴突足够接近以激活细胞B，并且重复或持续参与激发它时，会在一个或两个细胞中发生某种生长过程或代谢变化，使得A作为激发B的细胞之一的效率得以提高。*'
- en: In simplified terms, Hebbian theory predicts that those cells that fire together
    have stronger biological connections, which explains associative learning in the
    brain. In 1966, Norwegian physiologist Terje Lømo discovered the “long-term potentiation,”
    which proved Hebb was right. Lømo stimulated input nerve fibers and recorded action
    potentials from post-synaptic cells in the hippocampus of an anesthetized rabbit.
    After collecting the baseline with single pulse stimuli, he delivered a high-frequency
    train of stimuli and observed the enhanced responses that could last more than
    10 hours. It was the first demonstration that the recent history of neuronal activities
    could modify the strength of connections between brain cells. Since then, neuroscience
    in learning and memory has bloomed. Scientists use various animal models to study
    the long-term potentiation in different brain regions, from behavior to cellular
    and molecular levels. Neuroscientist Eric Kandel developed a simple animal model
    of Aplysia. He and his lab studied thoroughly the electrical, chemical, and molecular
    changes in synapses after various types of long-term potentiation associated with
    Aplysia’s learning behaviors. With his lifelong achievements, Eric Kandel won
    the Nobel Prize in 2000.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 用简化的术语来说，赫布理论预测那些同时激活的细胞具有更强的生物连接，这解释了大脑中的联想学习。1966年，挪威生理学家Terje Lømo发现了“长期增强”现象，证明了赫布的理论是正确的。Lømo刺激了输入神经纤维，并记录了麻醉兔海马体中突触后细胞的动作电位。在通过单脉冲刺激收集基线后，他施加了一组高频刺激，并观察到增强的反应，这些反应可以持续超过10小时。这是首次展示近期神经活动的历史可以改变脑细胞之间连接强度的现象。此后，学习和记忆的神经科学蓬勃发展。科学家们使用各种动物模型研究不同脑区的长期增强现象，从行为到细胞和分子水平。神经科学家Eric
    Kandel开发了一个简单的海虹虫动物模型。他和他的实验室彻底研究了海虹虫学习行为相关的各种长期增强现象后，突触中的电学、化学和分子变化。凭借其终身成就，Eric
    Kandel在2000年获得了诺贝尔奖。
- en: Today’s advances in other Neuroscience disciplines also suggest different types
    of neural plasticity, likely involving cell growth or new cell generation. In
    other words, Hebb’s rule may be one of many mechanisms underlying learning in
    the brain. Neuroscience still has a long way to go to identify and understand
    the other learning mechanisms.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 今天在其他神经科学学科的进展也表明了不同类型的神经可塑性，可能涉及细胞生长或新细胞生成。换句话说，赫布规则可能是大脑学习机制中的众多机制之一。神经科学在识别和理解其他学习机制方面仍有很长的路要走。
- en: '**Artificial Neural Network**'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**人工神经网络**'
- en: In 1943, neurophysiologist Warren McCulloch and logician Alter Pitts collaboratively
    proposed the first mathematical neural network model consisting of artificial
    neurons, each with one or more binary inputs (mimicking dendrites) and one binary
    output (mimicking axon). The network of these interconnected artificial neurons
    could then compute any rules of logic. The model, however, did not have any features
    to learn.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 1943年，神经生理学家Warren McCulloch和逻辑学家Alter Pitts共同提出了第一个数学神经网络模型，该模型由人工神经元组成，每个神经元具有一个或多个二进制输入（模拟树突）和一个二进制输出（模拟轴突）。这些互连的人工神经元网络能够计算任何逻辑规则。然而，该模型没有学习的功能。
- en: 'In 1958, psychologist Frank Rosenblatt invented the first artificial neural
    network (ANN) called Perceptron. It had two layers of artificial neurons: the
    input and the output. Frank remarkably adopted the Hebb rules such that the network
    adjusted the connection weights during training until outcomes were as expected
    in the training data. This feature enabled the neural network to learn anything
    without pre-defined rules, depending only on the example results provided in the
    training data. It was a revolutionary moment in ANN history, as, for the first
    time, a computer could learn as a biological brain does to solve a problem without
    specific rules or instructions.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 1958年，心理学家弗兰克·罗森布拉特发明了第一个人工神经网络（ANN），称为感知器。它有两个层次的人工神经元：输入层和输出层。弗兰克显著地采用了赫布规则，使得网络在训练过程中调整连接权重，直到结果符合训练数据中的预期。这一特性使得神经网络可以在没有预定义规则的情况下学习任何内容，仅依赖于训练数据中提供的示例结果。这是ANN历史上的一个革命性时刻，因为这是计算机首次能够像生物大脑一样在没有特定规则或指令的情况下解决问题。
- en: Two breakthroughs occurred afterward that made ANN genuinely take off. One was
    to add one or more internal hidden layers between input and output layers, allowing
    deep learning algorithms to extract higher-level features from the raw input progressively.
    Second, the weight adjustments were optimized significantly using back-propagation
    techniques. Hidden layers also have biological counterparts. For example, the
    neocortex has six cellular layers. The hippocampus has three layers, as shown
    in the original Cajal drawing. Armed with the powerful computing powers supported
    by the modern infrastructure and big data out of years of capturing and accumulation,
    ANN with deep learning has been significantly scaled up with more hidden layers
    and adjustable connections to solve more complex tasks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 随后发生了两个突破，使得人工神经网络真正腾飞。其一是在输入层和输出层之间添加一个或多个内部隐藏层，使深度学习算法能够逐步从原始输入中提取更高层次的特征。其次，通过使用反向传播技术显著优化了权重调整。隐藏层也有生物学上的对应物。例如，新皮质有六个细胞层。海马体有三个层次，如原始的卡哈尔图所示。凭借现代基础设施和大数据的强大计算能力，人工神经网络与深度学习已经大规模扩展，增加了更多隐藏层和可调连接，以解决更复杂的任务。
- en: '**Biological Neural Network vs. Artificial Neural Network**'
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**生物神经网络与人工神经网络**'
- en: With the fast progress of AI using ANN and deep learning, many questions have
    been raised about AI’s future and its intriguing relationship with humans. Given
    the similarities between the biological and artificial neural networks we have
    discussed above, let’s look into the differences between the two.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能利用人工神经网络和深度学习的快速进展，关于人工智能的未来及其与人类之间的有趣关系提出了许多问题。考虑到我们上面讨论的生物神经网络和人工神经网络之间的相似性，让我们深入探讨两者之间的差异。
- en: '**We still know little about how the brain works**'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**我们仍然对大脑的工作原理知之甚少**'
- en: With the immense strides made in AI in the last decade, we now enter an era
    in which AI may also inspire neuroscientists on the inner workings of the brain.
    Because the brain is the organ for thinking and driving behaviors, studying it
    in awake, behaving animals and humans is exceptionally challenging. Artificial
    neural networks allow scientists to hypothesize, model, and design future experiments
    for their neuroscientific research. In addition, AI researchers and neuroscientists
    could collaborate to simulate the neural network’s emerging behaviors on a computer
    by integrating cellular and even molecular findings from the brain.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 随着过去十年中人工智能取得的巨大进步，我们现在进入了一个人工智能也可能激发神经科学家对大脑内部工作原理的研究时代。由于大脑是思维和驱动行为的器官，在清醒、活动的动物和人类身上研究它是极其困难的。人工神经网络使科学家能够假设、建模并设计未来的实验以进行神经科学研究。此外，人工智能研究人员和神经科学家可以通过整合来自大脑的细胞甚至分子发现，合作模拟神经网络在计算机上的新兴行为。
- en: In other words, not only does AI get inspiration from neural biology, but neuroscientists
    can also get inspiration from progress in AI. For example, back-propagation is
    a mathematical model that has critically enhanced the performance of ANNs to near
    or above the human level. However, there has been no evidence supporting its existence
    in the brain, and both neuroscientists and artificial intelligence researchers
    are actively searching for the biological version.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，人工智能不仅从神经生物学中获取灵感，神经科学家也可以从人工智能的进展中获得灵感。例如，反向传播是一个数学模型，它极大地提升了人工神经网络（ANN）的性能，达到了或超过了人类水平。然而，目前没有证据表明这种模型在大脑中存在，神经科学家和人工智能研究人员都在积极寻找其生物学版本。
- en: '**2\. AI is managed by humans**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 人工智能由人类管理**'
- en: Although AI can learn itself generically without engineer-controlled rules or
    equations, AI models are highly dependent on the quality of input data and especially
    on the training data. Engineers and data scientists must also understand the data
    well to make the training effective and results trustworthy. Given this, the models
    are passive and rely on human-curated training. The AI systems have been designed
    to perform specific tasks more efficiently or accurately than humans, particularly
    in vision, predictive analytics, robotics, natural language processing (NLP),
    and national language understanding (NLU).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管人工智能可以在没有工程师控制的规则或方程式的情况下自我学习，但人工智能模型高度依赖输入数据的质量，特别是训练数据。工程师和数据科学家还必须深入了解数据，以使训练有效且结果可信。鉴于此，这些模型是被动的，依赖于人类策划的训练。人工智能系统被设计为在特定任务上比人类更高效或准确，特别是在视觉、预测分析、机器人技术、自然语言处理（NLP）和国家语言理解（NLU）方面。
- en: In contrast, humans can learn almost anything with much less and worse data.
    They interact with their environments to gain information and are good at leveraging
    context. Furthermore, humans can reason seamlessly in non-defined concept spaces
    and are good at reasoning with uncertainty when gathering enough information during
    a given period is impossible.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，人类可以在数据更少且质量较差的情况下学习几乎任何东西。他们通过与环境互动来获取信息，并善于利用上下文。此外，人类可以在未定义的概念空间中无缝推理，并且在收集足够信息在特定时间内不可能的情况下，善于处理不确定性。
- en: '**3\. Human intelligence and artificial intelligence are fundamentally different**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 人类智能和人工智能在根本上不同**'
- en: Human intelligence relies on biological constructs and is shaped by millions
    of years of evolution and thousands of years of human culture. It is complex and
    multifaceted and encompasses many cognitive and emotional capabilities. The human
    mind appears to be a highly integrated system that can interactively gather information,
    make decisions with feelings, communicate using languages, and take actions at
    the same time. On the other hand, we are all bothered by our seemingly inevitable
    cognitive biases and unreliable memories that seem to be the “bugs” of the superb
    evolutional design.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 人类智能依赖于生物构造，并受到数百万年的进化和数千年的文化的塑造。它复杂且多面，涵盖了许多认知和情感能力。人类大脑似乎是一个高度集成的系统，能够互动地收集信息、带着感情做决策、使用语言进行交流并同时采取行动。另一方面，我们都受到似乎不可避免的认知偏差和不可靠记忆的困扰，这似乎是卓越进化设计中的“缺陷”。
- en: On the contrary, AI is built in software and executed on computer hardware,
    with the ability to perform tasks that would typically require human intelligence,
    such as learning, pattern recognition, problem-solving, and decision-making. Although
    the human brain inspires fundamental principles, engineers and data scientists
    have implemented artificial neural networks using algorithms and mathematical
    models. Given this, AI gives specific, detailed, repeatable, and scalable results
    that are challenging for humans to achieve. These are precisely the features to
    automate and improve the efficiency of human efforts and complement the human
    constraints.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，人工智能是基于软件构建并在计算机硬件上执行的，具备执行通常需要人类智能的任务的能力，如学习、模式识别、问题解决和决策制定。尽管人脑激发了基本原则，但工程师和数据科学家使用算法和数学模型实现了人工神经网络。鉴于此，人工智能提供了具体、详细、可重复和可扩展的结果，这些是人类难以实现的。这些恰恰是自动化和提高人类努力效率的特点，并补充了人类的限制。
- en: '**Conclusions**'
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: As birds inspired us to build airplanes to fly, the artificial neural network
    was successful due to the inspiration from the brain’s neural structure. Because
    the foundational material is fundamentally different, we never expect AI to replicate
    the human brain directly; instead, we expect it to be another type of intelligence
    with its own design and strength that can help humans solve specific problems.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如鸟类启发我们建造飞机飞行一样，人工神经网络因受脑部神经结构的启发而取得成功。由于基础材料本质上不同，我们从不期望人工智能直接复制人脑；相反，我们期待它成为另一种类型的智能，具有自身的设计和优势，能够帮助人类解决特定问题。
- en: In addition, the brain is a highly complex biological system. The experimental
    approaches to studying neural mechanisms underlying human behaviors and cognitions
    are relatively limited. AI can become a powerful tool to offer ideas and support
    evidence for understanding the brain’s inner workings. This mutual inspiration
    from each other to boost both fields to grow should be what we will see in the
    coming decade.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，大脑是一个高度复杂的生物系统。研究人类行为和认知的神经机制的实验方法相对有限。AI 可以成为一个强大的工具，提供想法和支持证据，以理解大脑的内部运作。我们在未来十年中应该会看到这种相互启发，从而推动两个领域的共同发展。
