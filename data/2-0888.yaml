- en: Finding Dark Matter using a Quantum Computer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用量子计算机寻找暗物质
- en: 原文：[https://towardsdatascience.com/finding-dark-matter-using-a-quantum-computer-a99f4bff4685](https://towardsdatascience.com/finding-dark-matter-using-a-quantum-computer-a99f4bff4685)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/finding-dark-matter-using-a-quantum-computer-a99f4bff4685](https://towardsdatascience.com/finding-dark-matter-using-a-quantum-computer-a99f4bff4685)
- en: QML — quantum machine learning in action for a fun use case of high-energy and
    particle Physics
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: QML — 量子机器学习在高能和粒子物理的有趣应用
- en: '[](https://prashantmdgl9.medium.com/?source=post_page-----a99f4bff4685--------------------------------)[![Prashant
    Mudgal](../Images/7aefc3cdbc4985657b26b01c273165bc.png)](https://prashantmdgl9.medium.com/?source=post_page-----a99f4bff4685--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a99f4bff4685--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a99f4bff4685--------------------------------)
    [Prashant Mudgal](https://prashantmdgl9.medium.com/?source=post_page-----a99f4bff4685--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://prashantmdgl9.medium.com/?source=post_page-----a99f4bff4685--------------------------------)[![Prashant
    Mudgal](../Images/7aefc3cdbc4985657b26b01c273165bc.png)](https://prashantmdgl9.medium.com/?source=post_page-----a99f4bff4685--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a99f4bff4685--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a99f4bff4685--------------------------------)
    [Prashant Mudgal](https://prashantmdgl9.medium.com/?source=post_page-----a99f4bff4685--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a99f4bff4685--------------------------------)
    ·9 min read·Nov 3, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a99f4bff4685--------------------------------)
    ·阅读时间 9 分钟·2023年11月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Background
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: This year’s August was dedicated to IBM’s Global Quantum Summer School where
    I not only learned the basics in a compressed timeline and a tight schedule but
    also a few applications of quantum computing. The [badge](https://www.credly.com/go/ZlukKqHe)
    one gets after 4 gruelling weeks is a “*quantum experience”* in itself as you
    think you understand what you are doing but at the same time, you have no idea
    what is going on. The month transitioned from quantum circuit basics to variational
    algorithms at a fast pace which left only a little and limited time to ‘do your
    own research’ and get your hands dirty on the application part.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 今年的八月，致力于 IBM 全球量子暑期学校，在那里我不仅在压缩的时间表和紧凑的日程中学到了基础知识，还学到了一些量子计算的应用。在经过 4 周艰苦的学习后获得的
    [徽章](https://www.credly.com/go/ZlukKqHe) 本身就是一段 "*量子体验*"，因为你以为你了解自己在做什么，但同时你对发生了什么一无所知。这个月的课程从量子电路基础转到变分算法的速度很快，几乎没有时间来“做自己的研究”和亲自参与应用部分。
- en: '![](../Images/5ec7d8ce72d318eaaaf6c7221fe5e741.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ec7d8ce72d318eaaaf6c7221fe5e741.png)'
- en: Photo by [Dynamic Wang](https://unsplash.com/@dynamicwang?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Dynamic Wang](https://unsplash.com/@dynamicwang?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: As far as the applications are concerned, quantum chemistry, quantum simulations,
    and a few really complicated modelling tasks would fit the bill of the problems
    that can be solved with quantum computers. Having said so, there is another branch
    that’s burgeoning and seeking a lot of interest from the users and researchers
    and that’s Quantum Machine Learning — QML in short.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 就应用而言，量子化学、量子模拟和一些非常复杂的建模任务都符合可以用量子计算机解决的问题的标准。话虽如此，还有另一个正在蓬勃发展的领域，受到用户和研究人员的极大关注，那就是量子机器学习——简称
    QML。
- en: I thought QML should be a logical successor to the conventional ML and I set
    out to do the same. Now, I wanted to have a problem that wouldn’t be straightforward
    for ML algorithms to solve because of the sheer size of the data, hard to identify
    the complex patterns, but something that I could code from the comfort of my humble
    machine. I looked no further than our old friend, Physics, which hides a gamut
    of complex but interesting problems in its lap and it sounds intellectually cool
    to work on such problems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为 QML 应该是传统机器学习的合理继承者，于是我开始了这项工作。现在，我希望能找到一个不会因为数据量庞大、复杂模式难以识别而让机器学习算法无法直接解决的问题，但又是我可以在我那台简陋的机器上编程解决的问题。我没有再去寻找其他领域，我们的老朋友物理学正好适合，它在其怀抱中隐藏着一系列复杂但有趣的问题，而且从事这些问题听起来在智力上也很酷。
- en: So it goes.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。
- en: Problem Statement
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题陈述
- en: I decided to deal with the **dark matter classification** problem examined under
    the OPERA experiment (Oscillation Project with Emulsion-tRacking Apparatus) associated
    with the Large Hadron Collider, CERN.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定处理在与大型强子对撞机（CERN）相关的 OPERA 实验（振荡项目与乳胶追踪装置）下研究的**暗物质分类**问题。
- en: Problem Statement
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述
- en: In short, we will train a classifier to differentiate between the signal and
    the noise. The signal is the presence of the dark matter and the noise means an
    absence or something else altogether but not the signal.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们将训练一个分类器来区分信号和噪声。信号是暗物质的存在，而噪声意味着没有信号或完全是其他东西。
- en: Quite simple!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 很简单！
- en: Intuition
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直觉
- en: Let’s elaborate a little on the background of the experiment to develop a little
    intuition.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微详细讲解一下实验的背景，以便形成一些直觉。
- en: So, dark matter is a mysterious and as-yet-undetected form of matter that does
    not interact with electromagnetic radiation, such as light. It’s said that it
    makes up nearly 80% of the total mass of the universe. It is called “dark” because
    it cannot be observed directly with telescopes or other instruments that detect
    electromagnetic radiation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 暗物质是一种神秘且尚未被探测到的物质形式，它不会与电磁辐射（如光）发生相互作用。人们认为它占据了宇宙总质量的近80%。之所以称之为“暗物质”，是因为它无法通过望远镜或其他探测电磁辐射的仪器直接观察到。
- en: Why is it challenging to find dark matter?
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么寻找暗物质是一个挑战？
- en: It’s challenging because we don’t know what we are looking for.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这很具挑战性，因为我们不知道自己在寻找什么。
- en: '**Invisibility**: Dark matter doesn’t interact with light and that’s why we
    don’t really know what we are looking for, there are many theories around it but
    there isn’t any consensus.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**隐形**：暗物质不会与光相互作用，这就是为什么我们真正不知道自己在寻找什么，虽然有许多理论，但仍没有共识。'
- en: '**Background noise**: Experiments designed to detect dark matter must contend
    with various sources of background noise that can mimic the expected signals from
    dark matter. Distinguishing between actual dark matter interactions and these
    background signals is a significant challenge. Dark matter’s interactions with
    regular matter are very weak, making it difficult to detect and distinguish from
    background noise in experiments.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**背景噪声**：设计用于探测暗物质的实验必须应对各种背景噪声，这些噪声可能会模拟暗物质的预期信号。区分实际的暗物质相互作用和这些背景信号是一个重大挑战。暗物质与常规物质的相互作用非常微弱，使得在实验中探测和区分背景噪声变得困难。'
- en: '**Multiple Possibilities**: There are various theoretical candidates for dark
    matter, which require different detection methods. Scientists are exploring these
    possibilities, increasing the complexity of the search.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多种可能性**：暗物质的理论候选者有很多，这需要不同的探测方法。科学家们正在探索这些可能性，这增加了寻找暗物质的复杂性。'
- en: What really happens in the experiment at OPERA?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OPERA 实验中到底发生了什么？
- en: OPERA is located at the Gran Sasso National Laboratory in Italy. It is a neutrino
    physics experiment that primarily focuses on the study of neutrino oscillations.
    It is not specifically designed for finding dark matter.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: OPERA 位于意大利的格兰萨索国家实验室。这是一个中微子物理实验，主要关注中微子振荡的研究。它并不是专门用于寻找暗物质的。
- en: '![](../Images/f1237659642f7c75d0eb7dffc112212a.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1237659642f7c75d0eb7dffc112212a.png)'
- en: Image by author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: When a supposedly dark matter particle (which we are trying to find) collides
    with the lead nuclei, the nucleus emits electrons in the form of a shower that’s
    detected on a screen. This is what we are trying to find. There is a problem though,
    when a neutrino collides with the lead nuclei, it also produces an electron and
    the same way an electromagnetic shower is produced which muddles the signal with
    the noise. We are trying to differentiate between this signal and the noise.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个假定的暗物质粒子（我们正在寻找的）与铅原子核碰撞时，原子核会以电子束的形式发射电子，这些电子束在屏幕上被探测到。这就是我们要寻找的信号。然而，当一个中微子与铅原子核碰撞时，它也会产生电子，并以相同的方式产生电磁冲击，这会将信号与噪声混淆。我们正试图区分这个信号和噪声。
- en: What we’ll do
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的计划
- en: Essentially we have to sift through the data and distinguish between the signal
    and the noise, it can be accomplished using conventional machine learning but
    it’s still a herculean task. In a dataset of 10 million collisions, there would
    be hardly 10 thousand that would correspond to a signal. Such imbalance and sparsity
    in the dataset make it a skewed and difficult problem to solve. And because we
    like challenges, we will add a cherry on top and will use quantum machine learning
    algorithms instead of conventional ones (apologies for starting a sentence with
    a conjunction).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，我们需要筛选数据并区分信号和噪声，这可以通过传统的机器学习方法完成，但仍然是一个艰巨的任务。在一个拥有 1000 万次碰撞的数据集中，只有大约
    1 万次会对应信号。这种数据集中的不平衡和稀疏使问题变得偏斜且困难。因为我们喜欢挑战，我们会加一个小难度，使用量子机器学习算法而非传统算法（对以连词开头的句子表示歉意）。
- en: Data
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据
- en: There are loads and loads of datasets present on the LHC website [here](https://opendata.cern.ch/search?page=1&size=20&type=Dataset)
    at your disposal; the one used in this experiment can be found [here](https://www.kaggle.com/datasets/prashantmudgal/dark-matter-classification-opera-experiement-lhc).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LHC 网站上有大量数据集[在这里](https://opendata.cern.ch/search?page=1&size=20&type=Dataset)可供使用；本实验使用的数据集可以在[这里](https://www.kaggle.com/datasets/prashantmudgal/dark-matter-classification-opera-experiement-lhc)找到。
- en: '**License**: The dataset is released under [**CC0**](https://archive.is/o/ZXMIM/https://creativecommons.org/share-your-work/public-domain/cc0)
    **(CC Zero)** whichis the *Creative Commons Public Domain Dedication License*
    ([https://opendata.cern.ch/record/16541](https://opendata.cern.ch/record/16541))'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**许可证**: 数据集根据[**CC0**](https://archive.is/o/ZXMIM/https://creativecommons.org/share-your-work/public-domain/cc0)
    **(CC Zero)** 发布，这是*创意共享公共领域奉献许可证* ([https://opendata.cern.ch/record/16541](https://opendata.cern.ch/record/16541))'
- en: The code is present on my [GitHub repo](https://github.com/Prashantmdgl9/Miscellaneous_Scripts/tree/main/Dark%20Matter).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 代码可以在我的[GitHub 仓库](https://github.com/Prashantmdgl9/Miscellaneous_Scripts/tree/main/Dark%20Matter)中找到。
- en: The data consists of two h5 files, open30.h5 and test.h5; h5 is hdf i.e. hierarchical
    data format that’s used to store and organise large amounts of data in a compressed
    manner.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 数据包括两个 h5 文件，open30.h5 和 test.h5；h5 是层次数据格式，用于以压缩方式存储和组织大量数据。
- en: 'The data contains the following variables:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据包含以下变量：
- en: X — X coordinate of the base track
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: X — 基础轨道的 X 坐标
- en: Y — Y coordinate of the base track
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Y — 基础轨道的 Y 坐标
- en: Z — Z coordinate of the base track
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Z — 基础轨道的 Z 坐标
- en: TX — Angle from origin projected on X-axis
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TX — 从原点投影到 X 轴的角度
- en: TY — Angle from origin projected on the Y-axis
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TY — 从原点投影到 Y 轴的角度
- en: Signal — A binary variable, 1 indicating signal and 0 indicating noise
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 信号 — 一个二元变量，1 表示信号，0 表示噪声
- en: Library
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 库
- en: IBM’s quantum library — [qiskit 0.44.3](https://github.com/Qiskit/qiskit)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: IBM 的量子库 — [qiskit 0.44.3](https://github.com/Qiskit/qiskit)
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/2808245a4551602b2903b872dccce4c9.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2808245a4551602b2903b872dccce4c9.png)'
- en: Image by author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: A note about the Variational Quantum Algorithms
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于变分量子算法的说明
- en: Quantum algorithms are designed to run on quantum computers but at the moment
    we are in the NISQ — Noisy Intermediate Scale Quantum era of quantum computers
    which makes the reproduction of the results difficult. The current quantum computers
    are very noise-prone, even a trivial change in thermodynamic conditions or other
    circuitry would impact the results a lot. The logic gate that we want to apply
    would turn into something else because of the noise. It’s undesirable.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 量子算法设计用于在量子计算机上运行，但目前我们处于 NISQ — 噪声中等规模量子计算机时代，这使得结果的重现变得困难。当前的量子计算机非常容易受到噪声的影响，甚至微小的热力学条件变化或其他电路问题都会对结果产生很大影响。我们想应用的逻辑门因为噪声会变成其他东西。这是不可取的。
- en: What smart folks working on advanced methods have devised is something called
    variational algorithms, they use both classical and quantum computers for speed
    gain and accuracy.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 聪明的研究人员开发了所谓的变分算法，它们利用经典计算机和量子计算机来提高速度和准确性。
- en: Essentially all the algorithms use some form of optimization and parameter adjustment,
    what variational algorithms do is use the quantum computer to approximate the
    cost function and then calculate the new values of the parameters of the cost
    function on a classical computer and then run with the new values on the quantum
    computer again. Thus, calculations are split between classical and quantum computers,
    speeding up the process.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，所有算法都使用某种形式的优化和参数调整，变分算法所做的是利用量子计算机来近似成本函数，然后在经典计算机上计算成本函数的新参数值，再用新值在量子计算机上运行。这样，计算就分布在经典计算机和量子计算机之间，加速了过程。
- en: 'We will use a variational quantum classifier here as the task is classifying
    signal and noise. For more info on IBM’s VQC: [https://learn.qiskit.org/course/machine-learning/variational-classification](https://learn.qiskit.org/course/machine-learning/variational-classification)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里使用变分量子分类器，因为任务是分类信号和噪声。有关IBM VQC的更多信息，请访问：[https://learn.qiskit.org/course/machine-learning/variational-classification](https://learn.qiskit.org/course/machine-learning/variational-classification)
- en: Modelling
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模
- en: Let’s just take a look at the data and the variables
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们先来看看数据和变量
- en: '![](../Images/6f564ace336bac9aa23bbd2d69977d8e.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f564ace336bac9aa23bbd2d69977d8e.png)'
- en: Image by author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: Let’s look at the pair plot to see if some correlation between the variables.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看配对图，以了解变量之间是否存在相关性。
- en: '![](../Images/29639672d792273d93a82f184e36e9fa.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29639672d792273d93a82f184e36e9fa.png)'
- en: Image by author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: Okay, there is a pattern but quite a complicated one!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，存在一个模式，但相当复杂！
- en: After the usual boiler plater material including sampling, scaling, and train
    test split, we are ready for the quantum model.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成常规的样板工作，包括采样、缩放和训练测试拆分后，我们已经准备好进行量子模型训练。
- en: Before we proceed, let’s run the Support Vector classification algorithm, so
    we have a baseline of the conventional ML.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们运行支持向量分类算法，这样我们就有了传统机器学习的基准。
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/1115cd381771ac8191b85399c4d4623c.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1115cd381771ac8191b85399c4d4623c.png)'
- en: Image by author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: 70% accuracy isn’t that great on the test data, but I haven’t done much feature
    engineering here. It will improve once I do so.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试数据上70%的准确率并不算太好，但我这里没有进行太多的特征工程。一旦我进行特征工程，它会有所改善。
- en: Now, quantum computer’s turn.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，轮到量子计算机了。
- en: The problems are formulated in the form of gates and circuits that are fed qubits
    (quantum bits) in a quantum computer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 问题被以门和电路的形式进行表述，这些门和电路将量子比特（量子位）输入到量子计算机中。
- en: We haven’t dropped any feature — TX, TY, X, Y, Z; let’s use all of them and
    thus the number of qubits used in our circuit will be 5.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有丢弃任何特征——TX、TY、X、Y、Z；我们会使用所有这些特征，因此我们电路中使用的量子比特数量将是5。
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/6e1512dc553c61a910ad7dafa855b841.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e1512dc553c61a910ad7dafa855b841.png)'
- en: Image by author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: That’s what the circuit looks like. It feeds 5 qubits to which Hadamard and
    P gates are applied. Hadamard changes the basis of the qubit from |0> to |+> and
    from |1> to | — > while the P gate causes a single-qubit rotation about the Z
    axis.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 电路的样子就是这样。它输入5个量子比特，应用了Hadamard和P门。Hadamard门将量子比特的基态从|0>变为|+>，从|1>变为| — >，而P门则使得单量子比特绕Z轴旋转。
- en: The next step after we form a circuit is Ansatz, it’s quite a common vernacular
    in the quantum world; it’s German for approach but in physics and mathematics
    it means an educated guess.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 形成电路后的下一步是Ansatz，这是量子世界中相当常见的术语；它在德语中意为“方法”，但在物理学和数学中指的是一种经过教育的猜测。
- en: So, that’s what we have to do, to make educated guesses for the parameters —
    this will create a quantum state and will be executed on a quantum computer. The
    executed value will be compared with the desired value and depending on how far
    off we are, the optimiser will tune the parameters or the ansatz until we reach
    a good enough or a satisfactory value.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们需要做的就是对参数进行经过教育的猜测——这将创建一个量子态，并在量子计算机上执行。执行值将与期望值进行比较，根据偏差程度，优化器将调整参数或ansatz，直到我们达到一个足够好或满意的值。
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/1e586bbbd183d1e1058f370f9eb1b3e5.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e586bbbd183d1e1058f370f9eb1b3e5.png)'
- en: Image by author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: You see there are a lot of R gates applied. Essentially, all the qubits are
    just rotated around their axis to get some arbitrary starting value and that’s
    the ansatz.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到应用了很多R门。本质上，所有量子比特只是绕其轴旋转以获得一些任意的起始值，这就是ansatz。
- en: Now, let’s fit the VQC on the training data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在训练数据上拟合VQC。
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Callback graphs are really cool. It’s like getting the results of your deeds
    in real-time.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 回调图非常酷。就像实时获取你行为的结果一样。
- en: '![](../Images/d123534bf544b702a40bde0248c474fc.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d123534bf544b702a40bde0248c474fc.png)'
- en: Image by author
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Ok, a downward trend is promising which means it is learning but fitting it
    on the test data only would tell whether we are overfitting.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，下行趋势是有希望的，这意味着它正在学习，但只在测试数据上进行拟合才能告诉我们是否存在过拟合。
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/03372b5567e2a4e78afbba776024ebef.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03372b5567e2a4e78afbba776024ebef.png)'
- en: Image by author
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: It is marginally better than the conventional ML. I ran it using a simulator
    on the local machine. Maybe it would perform better if run on real quantum computers
    (nothing stops us, just that one has to queue up and with the server load these
    days, a simple task such as the addition of two numbers takes a few hours, not
    because it is slow but because more and more people line up and use the computation
    time) or spend more time on engineering the features.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于传统的机器学习，略微更好。我在本地机器上使用模拟器运行了它。也许在真实的量子计算机上运行时效果会更好（没有什么阻止我们，只是需要排队，并且由于服务器负载的增加，简单的任务如加法需要几个小时才能完成，这并不是因为计算慢，而是因为越来越多的人排队使用计算时间）或者花更多时间进行特征工程。
- en: Closing Notes
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束语
- en: Having said so, I am quite sure that the conventional ML algorithms will outperform
    quantum algorithms at the moment, especially for the classification tasks, as
    much research and many resources have been spent in making them robust and sophisticated.
    Once QML goes through such an overhaul, it will be a fair competition.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，我很确定目前传统的机器学习算法会优于量子算法，特别是在分类任务中，因为大量研究和资源已经投入到使其稳健和复杂化的工作中。一旦量子机器学习经历这样的升级，它将成为一场公平的竞争。
- en: It doesn't mean that QML will replace ML, this is far from the truth, instead
    quantum computing is for those problems that classical computers can’t really
    solve in polynomial time or can’t even approximate. Machine learning will have
    its place and QML will make its own place in the larger scheme of things.
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这并不意味着量子机器学习会取代机器学习，这远非事实，相反，量子计算是针对那些经典计算机无法在多项式时间内解决或甚至无法近似的问题。机器学习会有它的地位，量子机器学习也会在更大的框架中占有一席之地。
- en: This post isn’t meant to exemplify the power of either ML or QML but only to
    show similarities between the two — how both of them differ in execution but are
    similar in flavour, how both are dependent on feature engineering and choice of
    hyperparameters.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本文并不旨在展示机器学习或量子机器学习的威力，而只是展示两者之间的相似性——它们在执行上有所不同但在本质上类似，两者都依赖于特征工程和超参数的选择。
- en: Before we close, it would be interesting to see if there is a cluster that exists
    in the signals. We have separated the signal from the noise, can we cluster them
    to see if there is they form an electromagnetic shower by a dark matter particle?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束之前，看看信号中是否存在某种聚类将会很有趣。我们已经将信号与噪声分开，我们能否对其进行聚类，看看是否形成了暗物质粒子的电磁喷发？
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/192a2b53a3a0646e1f2f7320f57c1b6d.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/192a2b53a3a0646e1f2f7320f57c1b6d.png)'
- en: Image by author
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Not bad! They aren’t distinctive but they aren’t awful either. One can see some
    patterns. The vertical nature of the clusters is because of the mass and the angle
    of the trajectory after the collision.
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '不错！它们虽然不具备独特性，但也不糟糕。可以看到一些模式。簇的垂直特性是由于质量和碰撞后的轨迹角度。 '
- en: Interesting!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣！
- en: From the noisy data, we have extracted the best possible tracks which could
    be candidates for dark matter particle interactions.
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从嘈杂的数据中，我们提取了可能成为暗物质粒子相互作用候选者的最佳轨迹。
- en: I hope this small post might encourage you to take your quantum leap. Feel free
    to contact me on Twitter or by mail; as usual, I am open to criticism and comments
    that help me grow and learn.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇小文章能鼓励你迈出量子跃迁。欢迎通过 Twitter 或邮件联系我；像往常一样，我愿意接受批评和建议，这些能帮助我成长和学习。
- en: '*PS: Once again, the code is present on my GitHub repo* [*here*](https://github.com/Prashantmdgl9/Miscellaneous_Scripts/tree/main/Dark%20Matter)*.*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*PS：再一次，代码在我的 GitHub 仓库中* [*这里*](https://github.com/Prashantmdgl9/Miscellaneous_Scripts/tree/main/Dark%20Matter)*。*'
