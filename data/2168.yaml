- en: Unleashing the ChatGPT Tokenizer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解放 ChatGPT 令牌器
- en: 原文：[https://towardsdatascience.com/chatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54?source=collection_archive---------3-----------------------#2023-07-06](https://towardsdatascience.com/chatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54?source=collection_archive---------3-----------------------#2023-07-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54?source=collection_archive---------3-----------------------#2023-07-06](https://towardsdatascience.com/chatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54?source=collection_archive---------3-----------------------#2023-07-06)
- en: Hands-On! How ChatGPT Manages Tokens?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实操！ChatGPT 如何管理令牌？
- en: '[](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)[![Andrea
    Valenzuela](../Images/ddfc1534af92413fd91076f826cc49b6.png)](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)[](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)
    [Andrea Valenzuela](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)[![安德烈亚·巴伦苏埃拉](../Images/ddfc1534af92413fd91076f826cc49b6.png)](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)[](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)
    [安德烈亚·巴伦苏埃拉](https://medium.com/@andvalenzuela?source=post_page-----27f78906ea54--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6f3f1654c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=post_page-a6f3f1654c3----27f78906ea54---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)
    ·9 min read·Jul 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27f78906ea54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=-----27f78906ea54---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6f3f1654c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=post_page-a6f3f1654c3----27f78906ea54---------------------post_header-----------)
    发表在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----27f78906ea54--------------------------------)
    · 9 分钟阅读 · 2023年7月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F27f78906ea54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=-----27f78906ea54---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27f78906ea54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&source=-----27f78906ea54---------------------bookmark_footer-----------)![](../Images/d6d00dc92aaafbfe984040c4f28c2509.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F27f78906ea54&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-tokenizer-chatgpt3-chatgpt4-artificial-intelligence-python-ai-27f78906ea54&source=-----27f78906ea54---------------------bookmark_footer-----------)![](../Images/d6d00dc92aaafbfe984040c4f28c2509.png)'
- en: Self-made gif.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自制 gif。
- en: '**Have you ever wondered which are the key components behind ChatGPT?**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**你是否曾经想过 ChatGPT 背后的关键组件是什么？**'
- en: 'We all have been told the same: ChatGPT predicts the next word. But actually,
    there is a bit of a lie in this statement. **It does not predict the next word,
    ChatGPT predicts the next token**.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都被告知同样的事情：ChatGPT 预测下一个词。但实际上，这种说法有点不准确。**它并不预测下一个词，ChatGPT 预测的是下一个令牌**。
- en: '*Token?* Yes, a token is the unit of text for Large Language Models (LLMs).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*令牌？* 是的，令牌是大型语言模型（LLMs）的文本单位。'
- en: Indeed **one of the first steps that ChatGPT does when processing any prompt
    is splitting the user input into tokens**. And that is the job of the so-called
    **tokenizer**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，**ChatGPT 在处理任何提示时的第一步就是将用户输入分割成令牌**。而这正是所谓的 **令牌器** 的工作。
- en: In this article, we will uncover how the ChatGPT tokenizer works with hands-on
    practice with the original library used by OpenAI, the `tiktoken` library.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将揭示ChatGPT分词器如何工作，并通过OpenAI原用的`tiktoken`库进行实践操作。
- en: '*TikTok-en… Funny enough :)*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*TikTok-en… 有趣得很 :)*'
- en: Let’s dive deep and comprehend the actual steps performed by the tokenizer,
    and how its behavior really impacts the quality of the ChatGPT output.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨分词器实际执行的步骤，以及它的行为如何真正影响ChatGPT输出的质量。
- en: How the Tokenizer Works
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分词器如何工作
- en: 'In the article [Mastering ChatGPT: Effective Summarization with LLMs](/chatgpt-summarization-llms-chatgpt3-chatgpt4-artificial-intelligence-16cf0e3625ce)
    we already saw some of the mysteries behind the ChatGPT tokenizer, but let’s start
    from scratch.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在文章[掌握ChatGPT：利用LLM进行有效总结](/chatgpt-summarization-llms-chatgpt3-chatgpt4-artificial-intelligence-16cf0e3625ce)中，我们已经看到了一些ChatGPT分词器的奥秘，但让我们从头开始。
- en: The tokenizer appears at the first step in the process of text generation. **It
    is**…
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器出现在文本生成过程的第一步。**它是**…
