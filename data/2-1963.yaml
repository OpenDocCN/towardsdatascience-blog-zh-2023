- en: Teaching Language Models to use Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教授语言模型使用工具
- en: 原文：[https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b](https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b](https://towardsdatascience.com/teaching-language-models-to-use-tools-7fd58916c66b)
- en: Using tools makes us more capable as humans. Is the same true of LLMs?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用工具让我们作为人类更具能力。LLMs 是否也是如此？
- en: '[](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----7fd58916c66b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    ·17 min read·Aug 27, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7fd58916c66b--------------------------------)
    ·阅读时间 17 分钟·2023年8月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/72793c5d61d43b3d37b876b47eba27a0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72793c5d61d43b3d37b876b47eba27a0.png)'
- en: (Photo by [Barn Images](https://unsplash.com/@barnimages?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/t5YUoHW6zRo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由 [Barn Images](https://unsplash.com/@barnimages?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来自 [Unsplash](https://unsplash.com/photos/t5YUoHW6zRo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: As we learn more about them, large language models (LLMs) become increasingly
    interesting. These models can solve a variety of complex tasks accurately. At
    the same time, however, they struggle with certain functionality that we, as humans,
    consider basic! For example, LLMs commonly make arithmetic mistakes, lack access
    to current information, and even struggle to comprehend the progression of time.
    Given these limitations, we might wonder what can be done to make LLMs more capable.
    *Are LLMs doomed to suffer these limitations forever?*
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们对大语言模型（LLMs）了解的深入，这些模型变得越来越有趣。这些模型能够准确解决各种复杂任务。然而，与此同时，它们在某些我们人类认为基本的功能上却存在困难！例如，LLMs
    常常犯算术错误，缺乏获取当前信息的能力，甚至难以理解时间的进程。鉴于这些局限性，我们可能会想，如何才能使 LLMs 更具能力？*LLMs 注定要永远受到这些局限的困扰吗？*
- en: Many advancements in the human race have been catalyzed by access to new and
    innovative tools (e.g., the [printing press](https://www.history.com/news/printing-press-renaissance)
    or [computer](https://www.youtube.com/watch?v=L40B08nWoMk)). *Might the same finding
    apply to LLMs?* Within this overview, we will study a recent direction of research
    that aims to teach LLMs how to use external tools, which are made available via
    simple, text-to-text APIs. Using these tools, LLMs can delegate tasks like performing
    arithmetic or looking up current information to a specialized tool. Then, information
    returned by this tool can be used as context by the LLM when generating output,
    leading to more accurate and grounded responses.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人类历史上的许多进步都由获得新的创新工具（例如 [印刷机](https://www.history.com/news/printing-press-renaissance)
    或 [计算机](https://www.youtube.com/watch?v=L40B08nWoMk)）所推动。*相同的发现是否适用于 LLMs？* 在这篇概述中，我们将研究一个最新的研究方向，旨在教会
    LLMs 如何使用外部工具，这些工具通过简单的文本到文本的 API 提供。通过使用这些工具，LLMs 可以将执行算术或查找当前信息等任务委派给专门的工具。然后，这些工具返回的信息可以被
    LLM 在生成输出时用作上下文，从而产生更准确和有依据的响应。
- en: '![](../Images/03b7e6324e2b363f22d4c4edd174d543.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03b7e6324e2b363f22d4c4edd174d543.png)'
- en: (from [1] and ChatGPT Plus)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1] 和 ChatGPT Plus）
- en: Making LLMs more Capable
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使 LLMs 更具能力
- en: 'Giving an LLM access to an external tool is a reliable way to solve some of
    the limitations that these models face. However, LLMs will not know how to use
    tools naturally, which raises the question: *How do we teach our model to leverage
    external tools?* In this section, we will explore some of the options we have
    and enumerate various tools that are useful for building LLM applications.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为LLM提供外部工具是一种可靠的方法，可以解决这些模型面临的一些限制。然而，LLM不会自然地知道如何使用工具，这就提出了一个问题：*我们如何教会模型利用外部工具？*
    在本节中，我们将探讨我们拥有的一些选项，并列举对构建LLM应用程序有用的各种工具。
- en: Different Types of Learning
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不同类型的学习
- en: '![](../Images/8a4776a6747b1305ceb19e011495308a.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a4776a6747b1305ceb19e011495308a.png)'
- en: Different forms of learning with LLMs (created by author)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的不同学习形式（作者创建）
- en: Teaching an LLM to leverage tools is no different than learning how to solve
    any other task with an LLM. Since these models learn in a couple of different
    ways, we will go over the main forms of learning with LLMs here. Beyond this post,
    there are also [detailed explanations](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)
    available online.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 教会LLM利用工具与学习如何解决其他任务没有什么不同。由于这些模型以几种不同的方式学习，我们将在这里讨论LLM的主要学习形式。本文之外，网上还有[详细解释](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)。
- en: '**Pre-training.** The first and most basic form of learning for LLMs is pre-training.
    During pre-training, the model is trained over a large corpus of unlabeled textual
    data using a [language modeling objective](https://cameronrwolfe.substack.com/i/85568430/language-modeling).
    The pre-training process begins from a random initialization and is quite computationally
    expensive. Typically, pre-training is performed only once due to its [computational
    expense](https://www.mosaicml.com/blog/gpt-3-quality-for-500k) — we do not want
    to repeat the pre-training process very often! Notably, the computational expense
    of pre-training provides an explanation for the presence of a knowledge cutoff
    in LLMs like ChatGPT. These models learn [all of their knowledge](https://twitter.com/cwolferesearch/status/1660744247123890179?s=20)
    during pre-training, so the knowledge cutoff is just associated with data that
    is present during the most recent pre-training run.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**预训练。** LLM的第一个和最基本的学习形式是预训练。在预训练过程中，模型在大量未标记的文本数据上进行训练，使用[语言建模目标](https://cameronrwolfe.substack.com/i/85568430/language-modeling)。预训练过程从随机初始化开始，计算成本相当高。通常，由于[计算成本](https://www.mosaicml.com/blog/gpt-3-quality-for-500k)，预训练只执行一次——我们不希望频繁重复预训练过程！值得注意的是，预训练的计算成本解释了像ChatGPT这样的LLM中存在知识截止点的原因。这些模型在预训练期间学习[所有知识](https://twitter.com/cwolferesearch/status/1660744247123890179?s=20)，因此知识截止点仅与最近预训练期间存在的数据相关。'
- en: '![](../Images/828a0eac1632401dc5aeea48f70f782f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/828a0eac1632401dc5aeea48f70f782f.png)'
- en: Fine-tuning methods for LLMs (from [11])
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的微调方法（来自[11]）
- en: '**Fine-tuning.** After pre-training, LLMs can accurately perform next-token
    prediction, but this doesn’t always mean that they are actually useful. If we
    play with a demo of [GPT-2](https://cameronrwolfe.substack.com/i/85568430/language-models-are-unsupervised-multitask-learners-gpt)
    for 2 minutes, for example, we immediately see that predicting the next token
    accurately can result in some pretty boring and unhelpful outputs! As such, we
    typically fine-tune LLMs after pre-training, either via supervised fine-tuning
    (SFT) or reinforcement learning from human feedback (RLHF); see the image above
    and [here](https://cameronrwolfe.substack.com/i/93578656/refining-llm-behavior)
    for details. Although the details of these techniques are beyond the scope of
    this post, the basic idea is to:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**微调。** 在预训练之后，LLM可以准确地执行下一个标记预测，但这并不总是意味着它们实际上有用。例如，如果我们玩一下[GPT-2](https://cameronrwolfe.substack.com/i/85568430/language-models-are-unsupervised-multitask-learners-gpt)的演示，只需2分钟，我们立刻会发现准确预测下一个标记可能会导致一些相当无聊和无用的输出！因此，我们通常在预训练之后对LLM进行微调，通常通过监督微调（SFT）或从人类反馈中进行强化学习（RLHF）；详情见上面的图片和[这里](https://cameronrwolfe.substack.com/i/93578656/refining-llm-behavior)。虽然这些技术的细节超出了本文的范围，但基本的思路是：'
- en: Curate more training data (e.g., in-domain data for the task we want to solve,
    examples of correct dialogue, human feedback on the LLM’s output, etc.).
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 筛选更多的训练数据（例如，针对我们要解决的任务的领域数据、正确对话的示例、人类对LLM输出的反馈等）。
- en: Train the model’s parameters over this new data using either [reinforcement
    learning](https://openai.com/research/openai-baselines-ppo) or gradient descent
    with a (self-)supervised objective.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[强化学习](https://openai.com/research/openai-baselines-ppo)或带有（自我）监督目标的梯度下降对模型参数进行训练。
- en: By doing this, we can accomplish quite a bit! For example, [fine-tuning an LLM
    using RLHF](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    [11] has been shown to make LLMs more interesting, factual, and helpful. Going
    further, the recent LIMA publication from Meta showed that performing SFT over
    just 1,000 high-quality dialogue examples can produce a model that rivals the
    quality of GPT-4 [12]. Put simply, fine-tuning takes us from a generic LLM to
    something that is truly special and useful.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我们可以完成很多事情！例如，[使用RLHF对LLM进行微调](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    [11] 已被证明可以使LLM更有趣、更准确、更有帮助。更进一步，Meta最近的LIMA出版物显示，通过仅1,000个高质量对话示例进行SFT，可以生成一个与GPT-4质量相媲美的模型
    [12]。简单来说，微调将我们从一个普通的LLM提升到真正特别且有用的水平。
- en: '![](../Images/69350abf4cdb669e575453984275305a.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69350abf4cdb669e575453984275305a.png)'
- en: (from [7])
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [7]）
- en: '**In-context learning.** The final form of learning that we should be aware
    of is in-context learning; see above. In-context learning is different from pre-training
    and fine-tuning in that it *does not actually modify the underlying model’s parameters*.
    Rather, we teach the LLM to solve a problem more effectively by modifying its
    prompt! In particular, we can rephrase the prompt by using particular prompting
    techniques or even insert data into the prompt to perform [few-shot learning](https://cameronrwolfe.substack.com/i/117151147/few-shot-learning).
    The difference between fine-tuning and in-context learning is shown below.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文学习。** 我们应当了解的最终学习形式是上下文学习；见上文。上下文学习不同于预训练和微调，它*并不会实际修改底层模型的参数*。相反，我们通过修改提示来教LLM更有效地解决问题！特别是，我们可以通过使用特定的提示技术重新表述提示，甚至将数据插入提示中以进行[少样本学习](https://cameronrwolfe.substack.com/i/117151147/few-shot-learning)。微调和上下文学习之间的区别如下所示。'
- en: '![](../Images/5d96239664075744af7bf25bd237feb6.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d96239664075744af7bf25bd237feb6.png)'
- en: (from [7])
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [7]）
- en: 'In-context learning is incredibly powerful as it allows us to solve a variety
    of different tasks using a single model. Instead of fine-tuning the model and
    modifying its underlying parameters, we can insert useful data into the LLM’s
    prompt. The LLM can learn from this data and more accurately solve a task without
    the model itself being modified! Additionally, we can perform in-context learning
    with both pre-trained and fine-tuned models. To learn about prompting techniques
    that can be used with LLMs, check out the overviews below:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文学习是极其强大的，因为它允许我们使用单一模型解决各种不同的任务。我们可以将有用的数据插入到LLM的提示中，而不是微调模型或修改其底层参数。LLM可以从这些数据中学习，更准确地解决任务，而无需修改模型本身！此外，我们可以使用预训练模型和微调模型进行上下文学习。要了解可以与LLM配合使用的提示技术，请查看下面的概述：
- en: Practical Prompting [[link](https://cameronrwolfe.substack.com/p/practical-prompt-engineering-part)]
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实用提示 [[link](https://cameronrwolfe.substack.com/p/practical-prompt-engineering-part)]
- en: Advanced Prompting [[link](https://cameronrwolfe.substack.com/p/advanced-prompt-engineering)]
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级提示 [[link](https://cameronrwolfe.substack.com/p/advanced-prompt-engineering)]
- en: Chain of Thought Prompting [[link](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms)]
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思维链提示 [[link](https://cameronrwolfe.substack.com/p/chain-of-thought-prompting-for-llms)]
- en: Prompt Ensembles [[link](https://cameronrwolfe.substack.com/p/prompt-ensembles-make-llms-more-reliable)]
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示集合 [[link](https://cameronrwolfe.substack.com/p/prompt-ensembles-make-llms-more-reliable)]
- en: What tools are useful for LLMs?
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对LLM有用的工具有哪些？
- en: 'Although the idea of connecting LLMs to external tools seems enticing, we might
    wonder: *what kinds of tools would be the most useful?* To answer this question,
    we should look to common limitations of LLMs, such as:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管将LLM（大语言模型）与外部工具连接的想法很诱人，但我们可能会想：*哪些工具最有用？* 为了回答这个问题，我们应当关注LLM的常见局限性，例如：
- en: Lack of access to up-to-date information [2]
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏访问最新信息 [2]
- en: Tendency to hallucinate (i.e., output incorrect information)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有产生幻觉的倾向（即，输出不正确的信息）
- en: Difficulties with [evaluating mathematical expressions](https://cameronrwolfe.substack.com/i/121554239/program-of-thoughts-pot-prompting)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理[数学表达式](https://cameronrwolfe.substack.com/i/121554239/program-of-thoughts-pot-prompting)的困难
- en: Incomplete understanding of [low-resource languages](https://cameronrwolfe.substack.com/p/many-languages-one-deep-learning)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对[低资源语言](https://cameronrwolfe.substack.com/p/many-languages-one-deep-learning)的理解不完全
- en: Inability to understand the progression of time [8]
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无法理解时间的推移[8]
- en: If we wanted to solve these issues, we have a few options. We could focus on
    fine-tuning and refining the model via [SFT or RLHF](https://cameronrwolfe.substack.com/i/93578656/refining-llm-behavior)
    — just fine-tune the model extensively to avoid the behavior listed above. In
    fact, extensive resources have been invested into refining models like [GPT-4](https://openai.com/research/gpt-4)
    through targeted human feedback, which has produced pretty [impressive results](https://cameronrwolfe.substack.com/i/121554239/background-information).
    Instead of solving these problems within the model itself, however, we could focus
    on fine-tuning the model to take an approach that is indirect, but oftentimes
    more reliable. In particular, we could teach the model how to use external tools
    to help with answering questions!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想解决这些问题，我们有几个选项。我们可以专注于通过[SFT或RLHF](https://cameronrwolfe.substack.com/i/93578656/refining-llm-behavior)对模型进行微调和完善——彻底微调模型以避免上述行为。实际上，大量资源已经投入到通过目标人类反馈来完善像[GPT-4](https://openai.com/research/gpt-4)这样的模型，这也取得了相当[令人印象深刻的结果](https://cameronrwolfe.substack.com/i/121554239/background-information)。然而，我们也可以选择将重点放在让模型采取间接但通常更可靠的方法，而不是在模型内部解决这些问题。特别是，我们可以教会模型如何使用外部工具来帮助回答问题！
- en: '**How do tools help?** When struggling to solve a problem, it is often useful
    for an LLM to query an external tool that can provide more context. Notable examples
    of useful tools include (but are not limited to):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**工具如何提供帮助？** 在解决问题时，LLM通常会通过查询一个可以提供更多上下文的外部工具来获得帮助。值得注意的有用工具包括（但不限于）：'
- en: Calendar apps that can return the current date
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够返回当前日期的日历应用
- en: Calculators that can evaluate mathematical expressions
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够评估数学表达式的计算器
- en: '[Vector databases](https://cameronrwolfe.substack.com/i/118401596/knowledge-augmentation)
    that store (potentially) relevant information that is too large to store directly
    in the prompt'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[向量数据库](https://cameronrwolfe.substack.com/i/118401596/knowledge-augmentation)用于存储（可能）相关但无法直接存储在提示中的大量信息。'
- en: Translation modules for converting data into different languages
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据转换为不同语言的翻译模块
- en: Overall, tools are incredibly useful whenever providing extra information or
    context can help an LLM with solving a problem. Going beyond these simple tools,
    we could even connect LLMs to external code interpreters, giving them the ability
    to write and execute arbitrary programs. When combined with code-enabled LLMs
    (e.g., [Codex](https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica)
    [10]), such an approach can actually be quite powerful! See [here](https://cameronrwolfe.substack.com/p/program-aided-language-models)
    for more info.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，工具在提供额外信息或上下文来帮助LLM解决问题时极为有用。超越这些简单的工具，我们甚至可以将LLM连接到外部代码解释器，使其能够编写和执行任意程序。结合支持代码的LLM（例如，[Codex](https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica)
    [10]），这种方法实际上可以非常强大！更多信息请见[这里](https://cameronrwolfe.substack.com/p/program-aided-language-models)。
- en: Tools are super popular!
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具非常受欢迎！
- en: Although this overview will primarily focus upon recent research that studies
    the integration of tools with LLMs, augmenting models like GPT-4 with external
    tools has been a topic of recent interest. For example, OpenAI recently released
    a plugins extension for their models, allowing these powerful LLMs to leverage
    a massive number of external tools; see below.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本概述将主要关注最近研究的工具与LLM集成，但通过外部工具增强模型（如GPT-4）已成为近期关注的主题。例如，OpenAI最近发布了一个模型插件扩展，使这些强大的LLM能够利用大量外部工具；见下文。
- en: '![](../Images/a8984c0e7ddfc3fca632c989b57fb1b5.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8984c0e7ddfc3fca632c989b57fb1b5.png)'
- en: Popular apps on the ChatGPT Plus plugin store (from ChatGPT Plus)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT Plus插件商店中的热门应用（来自ChatGPT Plus）
- en: As of the time of writing, nearly 130 different plugins are available for GPT-4,
    thus demonstrating the massive amount of interest in integrating various kinds
    of tools with powerful LLMs. Going beyond 3rd party plugins, OpenAI has recently
    released code interpreter and internet search tools for GPT-4\. The internet search
    tools is incredibly useful for mitigating hallucinations within LLMs, as answers
    provided by the model can be contextualized with relevant, up-to-date information
    taken from the internet. Beyond making LLMs more factual and grounded, the code
    interpreter tool is capable of [ingesting massive code and data files](https://news.ycombinator.com/item?id=36047187)
    and performing accurate analysis over this data to yield valuable insights.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 截至撰写时，GPT-4有近130种不同的插件可用，这展示了将各种工具与强大的LLM集成的巨大兴趣。超越第三方插件，OpenAI最近为GPT-4发布了代码解释器和互联网搜索工具。互联网搜索工具对于减轻LLM中的幻觉非常有用，因为模型提供的答案可以通过从互联网获取的相关、最新信息进行情境化。除了使LLM更具事实性和基础性外，代码解释器工具能够[处理大量代码和数据文件](https://news.ycombinator.com/item?id=36047187)并对这些数据进行准确分析，以提供有价值的见解。
- en: '**TL;DR:** The main takeaway here is that tools are becoming a common feature
    for LLMs. Beyond OpenAI’s offerings, we are even seeing models like Bard being
    enhanced with [similar features](https://blog.google/technology/ai/google-bard-updates-io-2023/),
    while open-source libraries like LangChain can be used to easily build a variety
    of tool-like features for available LLMs.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**TL;DR：** 主要结论是，工具正在成为LLM的一个常见特性。除了OpenAI的产品外，我们甚至看到像Bard这样的模型正在增强[类似功能](https://blog.google/technology/ai/google-bard-updates-io-2023/)，而像LangChain这样的开源库可以用来轻松构建多种工具类功能供现有LLM使用。'
- en: Teaching LLMs to Use Tools
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教授LLM使用工具
- en: '![](../Images/86a89f735cbedb5b00de423336bd2630.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86a89f735cbedb5b00de423336bd2630.png)'
- en: (from [1])
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[1]）
- en: In [1], authors explore an approach, called the Toolformer, that *i)* teaches
    an LLM how to leverage external tools and *ii)* maintains the generic nature of
    the LLM in the process. These tools are made available to the LLM via a set of
    simple text-to-text APIs (i.e., meaning that the model provides text as input
    and the API returns textual output). Interestingly, we see in [1] that the LLM
    can learn to leverage these tools in a completely end-to-end manner. The model
    decides what APIs to call, which arguments to pass to these APIs, and how to best
    use the information that is returned without any hard-coded control flows.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在[1]中，作者探讨了一种名为Toolformer的方法，它*i)* 教授LLM如何利用外部工具，并且*ii)* 在过程中保持LLM的通用性质。这些工具通过一组简单的文本到文本的API提供给LLM（即模型提供文本作为输入，API返回文本输出）。有趣的是，我们在[1]中看到LLM可以完全端到端地学习如何利用这些工具。模型决定调用哪些API，向这些API传递哪些参数，并且如何最佳地利用返回的信息，而无需任何硬编码的控制流。
- en: “Language models can learn to control a variety of tools, and to choose for
    themselves which tool to use when and how.” *— from [1]*
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “语言模型可以学习控制各种工具，并自行选择何时、如何使用哪个工具。” *— 来源于[1]*
- en: To do this, we curate a dataset of training data that demonstrates the proper
    use of these tools. In [1], this dataset is created automatically using a self-supervised
    heuristic — meaning that no human intervention is required — that requires only
    a few examples of usage for each tool. Then, we fine-tune the LLM over this data,
    allowing it to learn the correct usage of each tool. The result is a high-performing
    LLM that can delegate simple, but difficult subtasks (e.g., language translation,
    arithmetic, accessing current information, etc.) to specialized, external tools
    that return relevant and accurate data for the LLM to use in generating an output.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们策划了一个训练数据集，展示了这些工具的正确使用。在[1]中，这个数据集是使用自监督启发式方法自动创建的——意味着不需要人工干预——只需为每个工具提供几个使用示例。然后，我们在这些数据上微调LLM，使其学习每个工具的正确使用方法。结果是一个高性能的LLM，它可以将简单但困难的子任务（如语言翻译、算术运算、访问当前信息等）委托给专门的外部工具，这些工具返回相关且准确的数据供LLM生成输出。
- en: '![](../Images/12ec83769c3f4beff4aa138c3d53666d.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12ec83769c3f4beff4aa138c3d53666d.png)'
- en: (from [1])
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[1]）
- en: '**What tools are used?** In [1], the Toolformer uses the following, fixed set
    of tools:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用了哪些工具？** 在[1]中，Toolformer使用了以下固定的一组工具：'
- en: '*Question Answering Tool:* Based on Atlas [13], an LLM that is fine-tuned for
    answering simple, fact-based questions.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*问答工具：* 基于Atlas [13]，一种针对回答简单、基于事实的问题进行微调的LLM。'
- en: '*Calculator:* A basic calculator for numerical operations.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算器：* 用于数值运算的基本计算器。'
- en: '*Wikipedia Search Tool:* A search engine that returns short, textual snippets
    from Wikipedia given a search term.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*维基百科搜索工具:* 一个搜索引擎，给定搜索词返回来自维基百科的简短文本片段。'
- en: '*Translator:* A language translation system that can translate text from any
    language into English (but not the other way around!).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*翻译器:* 一个可以将任何语言的文本翻译成英文的语言翻译系统（但不能反向翻译！）。'
- en: '*Calendar:* A tool that just returns the current date when queried.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*日历:* 一个在查询时只返回当前日期的工具。'
- en: Each of these tools are made available via a simple API with a text-to-text
    structure; see above. To use the tools, the LLM must learn to *i)* identify scenarios
    that require a tool, *ii)* specify which tool to use, *iii)* provide relevant
    textual input to the tool’s API, and *iv)* use text returned from the API to craft
    a response. Notably, the simple text-to-text structure of these APIs allows us
    to easily insert examples of tool usage directly into a textual sequence; see
    below.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具都通过一个简单的文本到文本结构的API提供；见上文。要使用这些工具，LLM必须学习* i)* 识别需要工具的场景，*ii)* 指定使用哪个工具，*iii)*
    向工具的API提供相关的文本输入，以及*iv)* 使用从API返回的文本来制作响应。值得注意的是，这些API简单的文本到文本结构允许我们轻松地将工具使用示例直接插入到文本序列中；见下文。
- en: '![](../Images/d1585e5e2f9cf2ba934e967a87047df2.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1585e5e2f9cf2ba934e967a87047df2.png)'
- en: Calls to external APIs are formatted as text and placed inline with an existing
    textual sequence (from [1])
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对外部API的调用以文本格式呈现，并与现有文本序列内嵌在一起（来自[1]）
- en: '**Improvements over prior work.** Giving LLMs access to external tools is not
    a new idea. As a simple example, many researchers have attempted to make LLMs
    better at arithmetic — especially with large numbers — by giving them access to
    an external calculator (see Appendix B in [4]). However, the main question is:
    *how should we teach the LLM to use such a tool?* Prior approaches were heavily
    dependent upon human annotated datasets. For example, LaMDA [3] uses an external
    search tool to reduce hallucinations; see below.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**相较于以前工作的改进。** 让LLM使用外部工具并不是一个新想法。例如，许多研究者尝试通过让LLM访问外部计算器来提高其在算术——特别是大数计算——方面的能力（见[4]的附录B）。然而，主要问题是：*我们应该如何教LLM使用这样的工具？*
    以前的方法严重依赖于人类标注的数据集。例如，LaMDA[3]使用外部搜索工具来减少幻觉；见下文。'
- en: '![](../Images/aec361d55e49722fd90a5ce72f076a2c.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aec361d55e49722fd90a5ce72f076a2c.png)'
- en: (from [3])
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: (来自[3])
- en: However, we see in [3] that teaching LaMDA to leverage external tools — in this
    case an external [information retrieval system](https://cameronrwolfe.substack.com/i/118401596/knowledge-augmentation)
    — requires a massive amount of human annotated data. More specifically, authors
    in [3] have a large number of crowd workers hand-write dialogues in which they
    leverage the same search tool as the LLM, thus providing examples of how the LLM
    should behave and respond. Related publications tend to rely upon a similar, human-centric
    approach [2]. Creating such a dataset is difficult, expensive, and time consuming,
    which leads authors in [1] to develop a more efficient solution.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们在[3]中看到，教会LaMDA利用外部工具——在这个例子中是外部的[信息检索系统](https://cameronrwolfe.substack.com/i/118401596/knowledge-augmentation)——需要大量的人类标注数据。更具体地说，[3]中的作者让大量的众包工人手动编写对话，利用与LLM相同的搜索工具，从而提供了LLM应如何行为和回应的示例。相关出版物往往依赖于类似的人类中心方法[2]。创建这样的数据集困难、昂贵且耗时，这促使[1]中的作者开发了更高效的解决方案。
- en: '**Learning to use tools automatically.** In [1], we see that a dataset for
    teaching an LLM how to leverage external tools — we will call this a “tool-following
    dataset” for simplicity — can be automatically crafted via a prompting approach
    that leverages existing, pre-trained LLMs. We start with an initial (normal) dataset,
    such as the textual corpus used for pre-training. Then, we prompt a pre-trained
    LLM to augment this data with external API calls. Here, we rely upon the in-context
    learning abilities of generic pre-trained LLMs to curate a set of API calls that
    demonstrate how to correctly use available tools. An example prompt that generates
    requests to a question answering tool’s API is shown below.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**自动学习使用工具。** 在[1]中，我们看到一个用于教LLM如何利用外部工具的数据集——为了简单起见，我们称之为“工具跟随数据集”——可以通过利用现有的、预训练的LLM的提示方法自动创建。我们从一个初始（正常）数据集开始，例如用于预训练的文本语料库。然后，我们提示一个预训练的LLM用外部API调用来增强这些数据。在这里，我们依赖于通用预训练LLM的上下文学习能力，来策划一组API调用，展示如何正确使用可用工具。下面展示了一个生成请求到问答工具API的示例提示。'
- en: '![](../Images/b684b324f800c393642e3a45d02ec489.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b684b324f800c393642e3a45d02ec489.png)'
- en: (from [1])
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: 'After we have augmented our dataset with example usages of each tool, we need
    to perform a filtering step. This step is necessary because we only want to use
    an external tool if it is actually helpful to the LLM! We shouldn’t just always
    rely upon external tools even when they aren’t needed — using a tool usually has
    a latency (or even monetary) cost. To capture this idea, we can just do the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们用每个工具的示例用法扩充了数据集之后，我们需要执行过滤步骤。这一步骤是必要的，因为我们只希望在工具实际上对LLM有帮助时才使用外部工具！我们不应该在不需要时总是依赖外部工具——使用工具通常会有延迟（甚至是经济）成本。为了捕捉这个想法，我们可以这样做：
- en: Measure the LLM’s performance (i.e., [cross entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)
    over tokens that come after the API call) with the tool.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用工具测量LLM的性能（即，[交叉熵损失](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)在API调用之后的标记上）。
- en: Measure the LLM’s performance without the tool.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量LLM在没有工具情况下的性能。
- en: Discard examples where using the tool does not improve the LLM’s performance
    beyond a certain threshold.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 丢弃那些使用工具未能使LLM的性能超越某个阈值的示例。
- en: Here, we are assuming access to a dataset that demonstrates the correct output
    that an LLM should produce. By following this approach, we automatically construct
    a dataset that contains examples of when and how tools can be leveraged to tangibly
    improve the LLM’s output. In practice, the actual procedure is a bit more complex.
    Namely, to measure the LLM’s performance without the tool, we observe performance
    in two separate cases — one without the tool at all, and one that performs an
    API call but provides no response. Such an approach ensures that both the tool
    and its data are useful to the LLM.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们假设可以访问一个演示LLM应产生正确输出的数据集。通过这种方法，我们可以自动构建一个包含示例的数据集，说明何时以及如何利用工具来实际改善LLM的输出。在实践中，实际过程要复杂一些。具体来说，为了在没有工具的情况下测量LLM的性能，我们观察两个独立的情况——一个是完全不使用工具的情况，另一个是执行API调用但不提供响应的情况。这种方法确保了工具及其数据对LLM的有用性。
- en: “An API call is helpful to [the language model] if providing both the input
    and the output of this call makes it easier to predict future tokens” *— from
    [1]*
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “如果提供此调用的输入和输出使得预测未来的标记更容易，则API调用对[语言模型]是有帮助的”*— 来自 [1]*
- en: Additionally, instead of inserting the API call inline with the textual sequence,
    we append it as a prefix, which avoids spikes in the LLM’s loss. Remember, API
    calls like this are not present in the original pre-training corpus for the LLM,
    which means that inserting the API call directly into the textual sequence could
    skew results used for filtering. *The model is not expecting to see an API call
    like this within the data!* Furthermore, when measuring performance, we assign
    a higher weight to tokens that are spatially close to the API call, ensuring that
    the API call is made near where it is needed and not at random times when generating
    output.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们没有将API调用插入到文本序列中，而是将其作为前缀附加，这样可以避免LLM损失的波动。记住，这样的API调用在LLM的原始预训练语料库中不存在，这意味着直接将API调用插入文本序列可能会扭曲用于过滤的结果。*模型并不期望在数据中看到这样的API调用！*
    此外，在测量性能时，我们为API调用空间上接近的标记分配更高的权重，确保API调用发生在所需的地方，而不是在生成输出时的随机时刻。
- en: '![](../Images/3dcd07c52397dd218e5a97edebcea1b7.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dcd07c52397dd218e5a97edebcea1b7.png)'
- en: (from [1])
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: The full process for constructing the tool-following dataset used in [1] is
    shown above. Unlike prior work, this process requires no human labor. Rather,
    we leverage the in-context learning abilities of LLMs and a few clever heuristics
    to construct the dataset automatically. Although this process is not perfect (i.e.,
    some useless API calls may avoid filtering), it works quite well in practice!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]中使用的工具跟随数据集的完整构建过程如上所示。与以前的工作不同，这个过程不需要人工劳动。相反，我们利用LLM的上下文学习能力和一些巧妙的启发式方法来自动构建数据集。尽管这个过程并不完美（即，某些无用的API调用可能会避免过滤），但在实践中效果相当好！'
- en: '**Learning to use tools.** Once we have constructed a dataset, teaching an
    LLM how to leverage external tools is easy — we just fine-tune the model over
    this dataset using a [standard language modeling objective](https://cameronrwolfe.substack.com/i/85568430/language-modeling).
    In [1], the tool-following dataset is derived from a pre-training corpus. As such,
    the fine-tuned LLM is still a general-purpose model, despite having the ability
    to leverage external tools. Moreover, because the filtering process in [1] removes
    API calls that do not benefit performance, the LLM implicitly learns when and
    how each tool should be used to improve its own output. Pretty cool results for
    such a simple approach!'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习使用工具。** 一旦我们构建了数据集，教会LLM如何利用外部工具是很容易的——我们只需使用[标准语言建模目标](https://cameronrwolfe.substack.com/i/85568430/language-modeling)对模型进行微调。在[1]中，工具跟随数据集来源于预训练语料库。因此，尽管微调后的LLM能够利用外部工具，但它仍然是一个通用模型。此外，由于[1]中的筛选过程会去除那些不利于性能的API调用，LLM会在隐含中学习何时以及如何使用每个工具以提升其输出。这种简单的方法取得了相当酷的结果！'
- en: Do tools make a difference?
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具是否有影响？
- en: The model analyzed in [1] is based upon [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6b)
    [5], a 6 billion parameter language model, and [CCNet](https://github.com/facebookresearch/cc_net)
    is adopted as the training dataset. Toolformer is compared to several baselines,
    including a Toolformer model with API calls disabled, the original GPT-J model,
    a version of GPT-J that is fine-tuned on CCNet, as well as a few other LLMs like
    [OPT](https://cameronrwolfe.substack.com/p/understanding-the-open-pre-trained-transformers-opt-library-193a29c14a15)
    [6] and [GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [7]. Unlike prior work that studies few-shot learning, models are evaluated using
    a [zero-shot approach](https://cameronrwolfe.substack.com/i/117151147/zero-shot-learning),
    which simply describes the task to the model without providing any exemplars,
    and a [greedy decoding](https://twitter.com/cwolferesearch/status/1659608476455256078?s=20)
    strategy. With Toolformer, a tool is leveraged whenever `<API>` (i.e., the starting
    token for an API call) appears as one of the model’s `k` most likely tokens.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在[1]中分析的模型基于[GPT-J](https://huggingface.co/EleutherAI/gpt-j-6b) [5]，这是一个拥有60亿参数的语言模型，并且采用了[CCNet](https://github.com/facebookresearch/cc_net)作为训练数据集。Toolformer与多个基准模型进行了比较，包括禁用API调用的Toolformer模型、原始的GPT-J模型、在CCNet上微调的GPT-J版本，以及其他一些LLM，如[OPT](https://cameronrwolfe.substack.com/p/understanding-the-open-pre-trained-transformers-opt-library-193a29c14a15)
    [6]和[GPT-3](https://cameronrwolfe.substack.com/i/88082618/language-models-are-few-shot-learners)
    [7]。与研究少样本学习的先前工作不同，这些模型使用[零样本方法](https://cameronrwolfe.substack.com/i/117151147/zero-shot-learning)进行评估，这种方法只是简单地向模型描述任务而不提供任何示例，并且使用了[贪婪解码](https://twitter.com/cwolferesearch/status/1659608476455256078?s=20)策略。在Toolformer中，只要`<API>`（即API调用的起始标记）出现在模型的`k`个最可能标记之一中，就会利用工具。
- en: Toolformer is evaluated across several different domains. On fact-based datasets,
    we see that the question answering tool is heavily leveraged, leading to a large
    increase in accuracy over baseline models. Similarly, the calculator tool is found
    to be quite useful on mathematical reasoning datasets; see below.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Toolformer在多个不同领域中进行了评估。在基于事实的数据集上，我们发现问答工具被大量利用，相比基准模型的准确率显著提高。同样，在数学推理数据集上，计算器工具也被发现非常有用；见下文。
- en: '![](../Images/8be2f1d1598cecdb922c43c59de1c3a2.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8be2f1d1598cecdb922c43c59de1c3a2.png)'
- en: (from [1])
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[1]）
- en: On (multilingual) question answering benchmarks, the model’s performance is
    not quite as impressive (i.e., Toolformer falls short of GPT-3 or GPT-J performance
    in some cases). However, certain tools, such as the calendar tool, are found to
    be incredibly useful for improving LLM performance on tasks like temporal reasoning.
    Interestingly, the authors also perform some analysis that modifies the probability
    of API calls within the LLM’s decoding strategy. From this analysis, we learn
    that *leveraging external tools more frequently is not always a good thing* —
    performance degrades if tools are used too frequently; see below.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在（多语言）问答基准上，模型的表现并不像预期那样令人印象深刻（即，Toolformer在某些情况下不及GPT-3或GPT-J的表现）。然而，某些工具，如日历工具，被发现对提升LLM在时间推理等任务上的表现非常有用。有趣的是，作者还进行了一些分析，修改了LLM解码策略中API调用的概率。通过这项分析，我们了解到*更频繁地利用外部工具并不总是好事*——如果工具使用过于频繁，性能会下降；见下文。
- en: '![](../Images/10b0a5aa59020cae07b90f4f88e4fbfb.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10b0a5aa59020cae07b90f4f88e4fbfb.png)'
- en: (from [1])
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[1]）
- en: Such a finding highlights the importance of the filtering strategy used in [1].
    Not only does tool usage come with a cost, but it may degrade performance. The
    LLM must learn to understand the scenarios in which calling a tool is most important.
    The approach taken in [1] explicitly biases the LLM towards only leveraging external
    tools when it provides a significant boost in the model’s performance.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的发现突显了[1]中使用的过滤策略的重要性。工具使用不仅有成本，而且可能会降低性能。LLM必须学习在何种场景下调用工具最为重要。[1]中采取的方法明确地使LLM在仅在显著提升模型性能时才利用外部工具。
- en: '![](../Images/2affd3c13e607773c8c7c47da2001e85.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2affd3c13e607773c8c7c47da2001e85.png)'
- en: (from [1])
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自[1]）
- en: '**Remaining generic.** Beyond the downstream evaluations described above, authors
    in [1] evaluate Toolformer on a hold-out portion of the pre-training dataset after
    fine-tuning on the tool-following dataset, finding that the model achieves comparable
    [perplexity](/perplexity-intuition-and-derivation-105dd481c8f3) both before and
    after fine-tuning; see above. In other words, *Toolformer does not lose any of
    its capabilities as a generic language model when it learns to leverage external
    tools*, meaning that — unlike prior work that approaches tool-following in a task-specific
    manner [8] — this model is still a [foundation model](https://crfm.stanford.edu/)
    that can solve a variety of different tasks.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**保持通用。** 除了上述下游评估，[1]中的作者在工具跟随数据集微调后，在预训练数据集的留出部分上评估了Toolformer，发现模型在微调前后都达到可比的[困惑度](/perplexity-intuition-and-derivation-105dd481c8f3)；如上所述。换句话说，*Toolformer在学习如何利用外部工具时不会丧失作为通用语言模型的任何能力*，这意味着—与先前以任务特定方式接近工具跟随的工作不同[8]—该模型仍然是一个[基础模型](https://crfm.stanford.edu/)，能够解决各种不同的任务。'
- en: Using Tools is Getting Easier
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用工具变得越来越简单
- en: Although the approach proposed in [1] is groundbreaking and incredibly informative,
    it still requires an extensive fine-tuning process. Compared to most recent applications
    of LLMs, this is quite a hassle! *Is it possible that we could leverage a prompting-only
    approach to teach an LLM to leverage external tools?* Recent developments surrounding
    GPT-4 suggest that this problem might be solved by improving the [instruction
    following capabilities](https://cameronrwolfe.substack.com/i/117151147/instruction-prompting)
    of LLMs.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管[1]中提出的方法具有突破性并且信息量巨大，但它仍然需要一个广泛的微调过程。与大多数最近应用的LLM相比，这确实是一个麻烦！*我们是否可以利用仅通过提示的方法来教会LLM使用外部工具？*
    最近围绕GPT-4的进展表明，这个问题可能通过提高LLM的[指令跟随能力](https://cameronrwolfe.substack.com/i/117151147/instruction-prompting)来解决。
- en: '![](../Images/92d6a992c44d67f1cfd60f34b559c5d0.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92d6a992c44d67f1cfd60f34b559c5d0.png)'
- en: (created by author)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: （作者创建）
- en: '**GPT-4 plugin workflow.** As an example, GPT-4 has access to a variety of
    different tools via the [plugin store](https://openai.com/blog/chatgpt-plugins).
    However, the model is not explicitly fine-tuned to learn about each plugin within
    the store. Rather, it just uses in-context learning. In particular, OpenAI has
    invested heavily ubto improve GPT-4’s [steerability](https://twitter.com/cwolferesearch/status/1645535868021805056?s=20),
    which has made the model surprisingly capable of following very detailed instructions
    and prompts. As a result, teaching GPT-4 how to use a plugin only requires:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT-4插件工作流程。** 例如，GPT-4可以通过[插件商店](https://openai.com/blog/chatgpt-plugins)访问各种工具。然而，模型并没有明确地针对商店中的每个插件进行微调。相反，它只是使用上下文学习。特别是，OpenAI在提升GPT-4的[可控性](https://twitter.com/cwolferesearch/status/1645535868021805056?s=20)方面投入了大量资金，这使得模型能够非常详细地跟随指令和提示。因此，教会GPT-4如何使用插件只需要：'
- en: A textual description describing the plugin’s purpose
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述插件目的的文本描述
- en: A schema describing the input/output format for the plugin’s API
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述插件API的输入/输出格式的架构
- en: Using this information, the model can determine when to use a plugin on its
    own, make properly-formatted API calls, and integrate the resulting information
    into its dialogue. All of this is done purely via textual descriptions without
    any explicit fine-tuning, *revealing that teaching LLMs to leverage external tools
    is likely to become easier over time*. To understand this process in more detail,
    we can look at [open-source plugin implementations](https://github.com/openai/chatgpt-retrieval-plugin)
    or [developer documentation](https://platform.openai.com/docs/plugins/introduction/plugin-flow)
    for OpenAI plugins.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些信息，模型可以自行决定何时使用插件，进行格式正确的 API 调用，并将结果信息整合到对话中。这一切都是通过文本描述完成的，没有任何明确的微调，*这表明教会
    LLM 利用外部工具可能会随着时间的推移变得更加容易*。要更详细地了解这一过程，我们可以查看 [开源插件实现](https://github.com/openai/chatgpt-retrieval-plugin)
    或 [OpenAI 插件开发文档](https://platform.openai.com/docs/plugins/introduction/plugin-flow)。
- en: Closing Remarks
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结语
- en: Similar to how humans become better with access to tools (e.g., hammers, computers,
    planes, etc.), LLMs become more capable when given access to a set of simple APIs
    that can provide useful information or perform simple tasks for them. *Why would
    we rely 100% on an LLM to solve everything, when we can delegate difficult tasks
    to a more accurate and specialized tool?* We can use such an approach to mitigate
    problems that are constantly encountered with these models, such as incorrect
    information within the output or a lack of temporal reasoning skills. With Toolformer
    [1], we see than LLMs can be taught to leverage external tools via fine-tuning
    over a dataset of tool-following exemplars. But, recent trends suggest that teaching
    LLMs to use external tools might be possible via in-context learning alone. There
    is a lot to be uncovered in this area, and it will be interesting to watch these
    topics and related applications evolve over time!
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于人类在使用工具（例如，锤子、计算机、飞机等）后变得更好，LLMs 在获得一组可以提供有用信息或执行简单任务的简单 API 时也变得更有能力。*为什么我们要完全依赖
    LLM 解决一切问题，而不是将困难的任务委派给更准确、更专业的工具？* 我们可以使用这种方法来缓解这些模型常常遇到的问题，例如输出中的不正确信息或缺乏时间推理能力。通过
    Toolformer [1]，我们看到 LLM 可以通过对工具跟随示例的数据集进行微调来学习利用外部工具。但是，最近的趋势表明，仅通过上下文学习可能就能教会
    LLM 使用外部工具。这个领域还有很多未被揭示的内容，观察这些主题和相关应用随时间的发展将会很有趣！
- en: Connect with me!
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与我联系！
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. If you liked this overview, subscribe
    to my [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/),
    where I help readers understand AI research via overviews of relevant topics from
    the ground up. You can also follow me on [X](https://twitter.com/cwolferesearch)
    and [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/), or
    check out my [other writings](https://medium.com/@wolfecameron) on medium!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢你阅读这篇文章。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/)
    的人工智能总监。我研究深度学习的实证和理论基础。如果你喜欢这个概述，请订阅我的 [Deep (Learning) Focus 新闻通讯](https://cameronrwolfe.substack.com/)，在这里我通过从基础开始概述相关主题，帮助读者理解
    AI 研究。你还可以在 [X](https://twitter.com/cwolferesearch) 和 [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/)
    上关注我，或者查看我在 Medium 上的 [其他文章](https://medium.com/@wolfecameron)！
- en: Bibliography
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Schick, Timo, et al. “Toolformer: Language models can teach themselves
    to use tools.” *arXiv preprint arXiv:2302.04761* (2023).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Schick, Timo 等人. “Toolformer: 语言模型可以自我学习使用工具。” *arXiv 预印本 arXiv:2302.04761*
    (2023)。'
- en: '[2] Komeili, Mojtaba, Kurt Shuster, and Jason Weston. “Internet-augmented dialogue
    generation.” *arXiv preprint arXiv:2107.07566* (2021).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Komeili, Mojtaba, Kurt Shuster 和 Jason Weston. “互联网增强的对话生成。” *arXiv 预印本
    arXiv:2107.07566* (2021)。'
- en: '[3] Thoppilan, Romal, et al. “Lamda: Language models for dialog applications.”
    *arXiv preprint arXiv:2201.08239* (2022).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Thoppilan, Romal 等人. “Lamda: 对话应用的语言模型。” *arXiv 预印本 arXiv:2201.08239* (2022)。'
- en: '[4] Wei, Jason, et al. “Chain of thought prompting elicits reasoning in large
    language models.” *arXiv preprint arXiv:2201.11903* (2022).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Wei, Jason 等人. “思维链提示引发大型语言模型的推理。” *arXiv 预印本 arXiv:2201.11903* (2022)。'
- en: '[5] Wang, Ben, and Aran Komatsuzaki. “GPT-J-6B: A 6 billion parameter autoregressive
    language model.” (2021).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Wang, Ben 和 Aran Komatsuzaki. “GPT-J-6B: 一种 60 亿参数的自回归语言模型。” (2021)。'
- en: '[6] Zhang, Susan, et al. “Opt: Open pre-trained transformer language models.”
    *arXiv preprint arXiv:2205.01068* (2022).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] 张苏珊等，“Opt: 开放预训练变换器语言模型。” *arXiv预印本 arXiv:2205.01068* (2022)。'
- en: '[7] Brown, Tom, et al. “Language models are few-shot learners.” *Advances in
    neural information processing systems* 33 (2020): 1877–1901.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] 布朗·汤姆等，“语言模型是少样本学习者。” *神经信息处理系统进展* 33 (2020): 1877–1901。'
- en: '[8] Parisi, Aaron, Yao Zhao, and Noah Fiedel. “Talm: Tool augmented language
    models.” *arXiv preprint arXiv:2205.12255* (2022).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] 帕里西·亚伦、姚赵和诺亚·费德尔，“Talm: 工具增强语言模型。” *arXiv预印本 arXiv:2205.12255* (2022)。'
- en: '[9] Dhingra, Bhuwan, et al. “Time-aware language models as temporal knowledge
    bases.” *Transactions of the Association for Computational Linguistics* 10 (2022):
    257–273.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] 丁格拉·布万等，“时间感知语言模型作为时间知识库。” *计算语言学学会会刊* 10 (2022): 257–273。'
- en: '[10] Chen, Mark, et al. “Evaluating large language models trained on code.”
    *arXiv preprint arXiv:2107.03374* (2021).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] 陈马克等，“评估基于代码训练的大型语言模型。” *arXiv预印本 arXiv:2107.03374* (2021)。'
- en: '[11] Ouyang, Long, et al. “Training language models to follow instructions
    with human feedback.” *Advances in Neural Information Processing Systems* 35 (2022):
    27730–27744.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] 欧阳龙等，“训练语言模型以遵循人类反馈的指令。” *神经信息处理系统进展* 35 (2022): 27730–27744。'
- en: '[12] Zhou, Chunting, et al. “Lima: Less is more for alignment.” *arXiv preprint
    arXiv:2305.11206* (2023).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] 周春婷等，“Lima: 对齐的少即是多。” *arXiv预印本 arXiv:2305.11206* (2023)。'
- en: '[13] Izacard, Gautier, et al. “Atlas: Few-shot learning with retrieval augmented
    language models.” *arXiv preprint arXiv* 2208 (2022).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] 伊扎卡德·戈蒂埃等，“Atlas: 带检索增强的语言模型的少样本学习。” *arXiv预印本 arXiv* 2208 (2022)。'
