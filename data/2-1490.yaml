- en: 'Mastering Monte Carlo: How to Simulate Your Way to Better Machine Learning
    Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精通蒙特卡洛：如何通过模拟提升机器学习模型
- en: 原文：[https://towardsdatascience.com/mastering-monte-carlo-how-to-simulate-your-way-to-better-machine-learning-models-6b57ec4e5514](https://towardsdatascience.com/mastering-monte-carlo-how-to-simulate-your-way-to-better-machine-learning-models-6b57ec4e5514)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mastering-monte-carlo-how-to-simulate-your-way-to-better-machine-learning-models-6b57ec4e5514](https://towardsdatascience.com/mastering-monte-carlo-how-to-simulate-your-way-to-better-machine-learning-models-6b57ec4e5514)
- en: Application of Probabilistic Approaches by Enhancing Predictive Algorithms through
    Simulation Techniques
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过模拟技术提升预测算法的概率方法应用
- en: '[](https://medium.com/@sydneynye?source=post_page-----6b57ec4e5514--------------------------------)[![Sydney
    Nye](../Images/e85d31078f0844694b857143ded3e912.png)](https://medium.com/@sydneynye?source=post_page-----6b57ec4e5514--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b57ec4e5514--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b57ec4e5514--------------------------------)
    [Sydney Nye](https://medium.com/@sydneynye?source=post_page-----6b57ec4e5514--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@sydneynye?source=post_page-----6b57ec4e5514--------------------------------)[![Sydney
    Nye](../Images/e85d31078f0844694b857143ded3e912.png)](https://medium.com/@sydneynye?source=post_page-----6b57ec4e5514--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b57ec4e5514--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b57ec4e5514--------------------------------)
    [Sydney Nye](https://medium.com/@sydneynye?source=post_page-----6b57ec4e5514--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6b57ec4e5514--------------------------------)
    ·26 min read·Aug 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6b57ec4e5514--------------------------------)
    ·26分钟阅读·2023年8月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/efbc38b2902307f75ef51ff4a36e9eba.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/efbc38b2902307f75ef51ff4a36e9eba.png)'
- en: “At the Roulette Table in Monte Carlo” by Edvard Munch (1892)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “在蒙特卡洛的轮盘赌桌上”由爱德华·蒙克（1892年）
- en: How a Scientist Playing Cards Forever Changed the Game of Statistics
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一位科学家玩扑克牌如何永远改变了统计学游戏
- en: In the tumultuous year of 1945, as the world was gripped by what would be the
    final throes of World War II, a game of solitaire quietly sparked an advancement
    in the realm of computation. This was no ordinary game, mind you, but one that
    would lead to the birth of the Monte Carlo method([1](https://library.lanl.gov/la-pubs/00326866.pdf)).
    The player? None other than scientist Stanislaw Ulam, who was also deeply engrossed
    in the Manhattan Project([2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2924739/)).
    Ulam, while convalescing from an illness, found himself engrossed in solitaire.
    The complex probabilities of the game intrigued him, and he realized that simulating
    the game repeatedly could provide a good approximation of these probabilities([3](https://www.sciencedirect.com/topics/economics-econometrics-and-finance/monte-carlo-simulation)).
    It was a lightbulb moment, akin to Newton’s apple, but with playing cards instead
    of fruit. Ulam then discussed these ideas with his colleague John von Neumann,
    and together they formalized the Monte Carlo method, named after the famed Monte
    Carlo Casino in Monaco, (portrayed in Edvard Munch’s famous painting shown above),
    where the stakes are high and chance rules — much like the method itself.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在1945年的动荡岁月中，当世界正经历第二次世界大战的最后阶段时，一场扑克牌游戏悄然引发了计算领域的一次突破。这不仅仅是普通的游戏，而是导致蒙特卡洛方法诞生的关键。玩家？正是科学家**斯坦尼斯瓦夫·乌拉姆**，他当时还深陷于曼哈顿计划中。乌拉姆在从疾病中恢复的过程中，沉迷于扑克牌游戏。游戏的复杂概率引起了他的兴趣，他意识到反复模拟游戏可以提供这些概率的良好近似。这是一个灵光一现的时刻，类似于牛顿的苹果，但换成了扑克牌。随后，乌拉姆与他的同事**约翰·冯·诺依曼**讨论了这些想法，两人共同形式化了蒙特卡洛方法，命名来源于著名的摩纳哥蒙特卡洛赌场（在上面的爱德华·蒙克的著名画作中描绘），在那里赌注高昂，运气主宰——这正如方法本身。
- en: Fast forward to the present day, and the Monte Carlo method has become an ace
    up the sleeve in the world of machine learning, including applications in reinforcement
    learning, Bayesian filtering, and the optimization of intricate models([4](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_525)).
    Its robustness and versatility have ensured its continued relevance, more than
    seven decades after its inception. From Ulam’s solitaire games to the sophisticated
    AI applications of today, the Monte Carlo method remains a testament to the power
    of simulation and approximation in tackling complex systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 快进到今天，蒙特卡罗方法已成为机器学习领域中的一张王牌，包括在强化学习、贝叶斯滤波和复杂模型优化中的应用([4](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_525))。其稳健性和多功能性确保了其持续的相关性，距其诞生已超过七十年。从乌拉姆的纸牌游戏到今天复杂的AI应用，蒙特卡罗方法依然是应对复杂系统中模拟和逼近力量的见证。
- en: Playing Your Cards Right With Probabilistic Simulations
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用概率模拟来玩转你的牌
- en: In the intricate world of data science and machine learning, Monte Carlo simulations
    are akin to a well-calculated wager. This statistical technique allows us to place
    strategic bets in the face of uncertainty, making probabilistic sense of complex,
    deterministic problems. In this article, we’ll demystify Monte Carlo simulations
    and explore their powerful applications in statistics and machine learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学和机器学习的复杂世界中，蒙特卡罗模拟类似于精心计算的赌注。这种统计技术使我们能够在不确定性面前进行战略性投注，为复杂的确定性问题提供概率性的解决方案。在这篇文章中，我们将揭示蒙特卡罗模拟的神秘面纱，并探讨其在统计学和机器学习中的强大应用。
- en: We’ll start by taking a deep dive into the theory behind Monte Carlo simulations,
    illuminating the principles that make this technique a powerful tool for problem-solving.
    We’ll work through some hands-on applications in Python, demonstrating how Monte
    Carlo simulations can be implemented in practice.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入探讨蒙特卡罗模拟背后的理论，阐明使这一技术成为强大问题解决工具的原理。我们将通过一些Python中的实际应用，演示如何在实践中实现蒙特卡罗模拟。
- en: Next, we’ll explore how Monte Carlo simulations can be used to optimize machine
    learning models. We’ll focus on the often challenging task of hyperparameter tuning,
    providing a practical toolkit for navigating this complex landscape.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何利用蒙特卡罗模拟来优化机器学习模型。我们将专注于通常具有挑战性的超参数调优任务，提供一个实用的工具包，以帮助应对这一复杂的领域。
- en: So, place your bets, and let’s get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，下注吧，开始吧！
- en: Understanding Monte Carlo Simulations
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解蒙特卡罗模拟
- en: Monte Carlo simulations are an invaluable technique for mathematicians and data
    scientists. These simulations provide a methodology for navigating through an
    extensive and complex array of possibilities, formulating educated assumptions,
    and progressively refining choices until the most suitable solution emerges.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特卡罗模拟对于数学家和数据科学家来说是一项宝贵的技术。这些模拟提供了一种在广泛而复杂的可能性中导航的方法，制定有根据的假设，并逐步完善选择，直到出现最合适的解决方案。
- en: 'The way it works is just this: we generate a vast number of random scenarios,
    following a certain predefined process, then scrutinize these scenarios to estimate
    the probability of various outcomes. Here’s an analogy to make this clearer: consider
    each scenario as a turn in the popular Hasbro board game “Clue”. For those unfamiliar,
    “Clue” is a detective-style game where players move around a mansion, gathering
    evidence to deduce the details of a crime — the who, what, and where. Each turn,
    or question asked, eliminates potential answers and brings the players closer
    to revealing the true crime scenario. Similarly, each simulation in a Monte Carlo
    study provides insights that bring us closer to the solution of our complex problem.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 其工作原理如下：我们生成大量随机场景，遵循某个预定义的过程，然后审视这些场景，以估计各种结果的概率。这里有一个类比来帮助理解：将每个场景视为流行的哈斯布罗棋盘游戏“Clue”中的一次回合。对于不熟悉的人来说，“Clue”是一个侦探风格的游戏，玩家在一座豪宅中移动，收集证据以推断犯罪的细节——谁、什么和哪里。每回合或提问都会排除潜在的答案，使玩家更接近揭示真实的犯罪场景。同样，蒙特卡罗研究中的每次模拟提供的见解使我们更接近解决复杂问题的方案。
- en: In the realm of machine learning, these “scenarios” can represent different
    model configurations, varied sets of hyperparameters, alternative ways of splitting
    a dataset into training and test sets, and many other applications. By assessing
    the outcomes of these scenarios, we can glean valuable insights into the behavior
    of our machine learning algorithm, enabling informed decisions about its optimization.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的领域，这些“场景”可以代表不同的模型配置、各种超参数集、将数据集分割为训练集和测试集的不同方式以及其他许多应用。通过评估这些场景的结果，我们可以获得对机器学习算法行为的宝贵洞察，从而做出有关其优化的明智决策。
- en: A Game of Darts
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 飞镖游戏
- en: To understand Monte Carlo simulations, imagine you’re playing a game of darts.
    But instead of aiming for a specific target, you’re blindfolded and throwing darts
    randomly at a large square dartboard. Inside this square, there’s a circular target.
    Your goal is to estimate the value of pi, the ratio of the circle’s circumference
    to its diameter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解蒙特卡洛模拟，想象你在玩飞镖游戏。但不是瞄准特定目标，而是蒙上眼睛随机地将飞镖扔向一个大的正方形飞镖盘。这个正方形里有一个圆形目标。你的目标是估算圆周率π，即圆的周长与直径的比值。
- en: 'Sounds impossible, right? But here’s the trick: the ratio of the area of the
    circle to the area of the square is pi/4\. So, if you throw a large number of
    darts, the ratio of darts landing inside the circle to the total number of darts
    should be approximately pi/4\. Multiply this ratio by 4, and you have an estimate
    of pi!'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来不可能，对吧？但这里有个窍门：圆的面积与正方形的面积之比是π/4。因此，如果你投掷大量的飞镖，落在圆内的飞镖数与总飞镖数的比率应大致为π/4。将这个比率乘以4，你就能估算出π！
- en: Random Guessing vs. Monte Carlo
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机猜测 vs. 蒙特卡洛
- en: 'To illustrate the power of Monte Carlo simulations, let’s compare it with a
    simpler method, perhaps the simplest of all: random guessing.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示蒙特卡洛模拟的威力，让我们将它与一种更简单的方法进行比较，也许是所有方法中最简单的：随机猜测。
- en: 'When you run the code below for both cases (random and Monte Carlo), you’ll
    get a different set of predictions each time. This is to be expected, because
    the darts are thrown randomly. This is a key feature of Monte Carlo simulations:
    they are inherently stochastic, or random. But despite this randomness, they can
    provide very accurate estimates when used properly. Thus, while your figures will
    not look exactly like mine, they’ll tell the same story.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行下面的代码进行随机和蒙特卡洛两种情况时，每次都会得到一组不同的预测。这是意料之中的，因为飞镖是随机投掷的。这是蒙特卡洛模拟的一个关键特征：它们本质上是随机的。然而，尽管有这种随机性，它们在正确使用时可以提供非常准确的估算。因此，虽然你的结果不会完全像我的，但它们会讲述相同的故事。
- en: In the first set of visualizations (**Figure 1a** to **Figure 1f**), we’re making
    a series of random guesses for the value of pi, each time generating a circle
    based on the guessed value. Let’s give this “randomness” a push in the right direction,
    and assume that while we cannot remember the exact value of pi, we know it is
    higher than 2 and lower than 4\. As you can see from the resulting figures, the
    size of the circle varies widely depending on the guess, demonstrating the inaccuracy
    of this approach (which shouldn’t come as a surprise). The green circle in each
    figure represents the unit circle, the “real” circle we’re trying to estimate.
    The blue circle is based on our random guess.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一组可视化图（**图1a** 到 **图1f**）中，我们对π的值进行了一系列随机猜测，每次生成一个基于猜测值的圆。让我们给这个“随机性”一个正确的推动，假设虽然我们不能记住π的确切值，但我们知道它高于2且低于4。从结果图中可以看到，圆的大小根据猜测值变化很大，这显示了这种方法的不准确性（这也不应让人感到惊讶）。每个图中的绿色圆圈代表单位圆，即我们试图估算的“真实”圆。蓝色圆圈则基于我们的随机猜测。
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/c674c42f58e4274d2ff3878161981457.png)![](../Images/4e61d6d90a2f693f42538e5de3c9a8e8.png)![](../Images/726aa1deefec43a789928eb83dc059f3.png)![](../Images/c7298f7008707aeb31dbee4188f529c2.png)![](../Images/667c470d5442820f7de2dc7b42eba11a.png)![](../Images/6ddf15e494f0387330fe91ca4b89421e.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c674c42f58e4274d2ff3878161981457.png)![](../Images/4e61d6d90a2f693f42538e5de3c9a8e8.png)![](../Images/726aa1deefec43a789928eb83dc059f3.png)![](../Images/c7298f7008707aeb31dbee4188f529c2.png)![](../Images/667c470d5442820f7de2dc7b42eba11a.png)![](../Images/6ddf15e494f0387330fe91ca4b89421e.png)'
- en: 'Figures 1a-1f: Random Estimation of Pi'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图1a-1f：π的随机估算
- en: 'You may notice something odd: in the random guessing method, sometimes a guess
    closer to the real value of pi results in a circle farther from the unit circle.
    This apparent contradiction arises because we’re looking at the circles’ circumference,
    not their radius or area. The visual gap between the two circles represents the
    error in estimating the circumference of the circle based on the guess, not the
    circle as a whole.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到一个奇怪的现象：在随机猜测方法中，有时接近真实π值的猜测会导致一个更远离单位圆的圆。这种明显的矛盾产生是因为我们关注的是圆的周长，而不是半径或面积。两个圆之间的视觉差距表示的是基于猜测的圆周长估算误差，而不是整个圆的误差。
- en: In the second set of visualizations (**Figure 2a** to **Figure 2f**), we’re
    using the Monte Carlo method to estimate the value of pi. Instead of making a
    random guess, we’re throwing a large number of darts at a square and counting
    how many fall inside a circle inscribed in the square. The resulting estimate
    of pi is much more accurate, as you can see from the figures where the size of
    the circle is much closer to the actual unit circle. The green dots represent
    darts that landed inside the unit circle, and the red dots represent darts that
    landed outside.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二组可视化（**图2a**至**图2f**）中，我们使用蒙特卡罗方法来估算π值。我们不是进行随机猜测，而是向一个正方形上扔大量的飞镖，并计算落在正方形内切圆内的数量。由此得到的π值估算更为准确，如图中所示，圆的大小更接近实际单位圆。绿色点表示落在单位圆内的飞镖，红色点表示落在单位圆外的飞镖。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/b4abfadbf76394515d476d64869888a0.png)![](../Images/d0483d8b00a390f5ad2f25d9a4f93bb4.png)![](../Images/051502bfd26608a18449573753907325.png)![](../Images/67d5ab3f95e8e9e5541b3b0dee214bcf.png)![](../Images/031d3693a4cb408f2dad132d3a83c9da.png)![](../Images/f95f0f2735c5d151e8b547e58c1953a0.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4abfadbf76394515d476d64869888a0.png)![](../Images/d0483d8b00a390f5ad2f25d9a4f93bb4.png)![](../Images/051502bfd26608a18449573753907325.png)![](../Images/67d5ab3f95e8e9e5541b3b0dee214bcf.png)![](../Images/031d3693a4cb408f2dad132d3a83c9da.png)![](../Images/f95f0f2735c5d151e8b547e58c1953a0.png)'
- en: 'Figures 2a-2f: Monte Carlo Estimation of Pi'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2a-2f：蒙特卡罗估算π值
- en: In the Monte Carlo method, the pi estimate is based on the proportion of “darts”
    that land inside the circle to the total number of darts thrown. The resulting
    estimated pi value is used to generate a circle. If the Monte Carlo estimate is
    inaccurate, the circle will again be the wrong size. The width of the gap between
    this estimated circle and the unit circle gives an indication of the accuracy
    of the Monte Carlo estimate.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在蒙特卡罗方法中，π的估算是基于落在圆内的“飞镖”与总投掷次数的比例。得到的π值估算用于生成一个圆。如果蒙特卡罗估算不准确，生成的圆将再次出现错误。这个估算圆与单位圆之间的差距宽度，提供了蒙特卡罗估算准确性的指示。
- en: However, because the Monte Carlo method generates more accurate estimates as
    the number of “darts” increases, the estimated circle should converge towards
    the unit circle as more “darts” are thrown. Therefore, while both methods show
    a gap when the estimate is inaccurate, this gap should decrease more consistently
    with the Monte Carlo method as the number of “darts” increases.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于蒙特卡罗方法在“飞镖”数量增加时会产生更准确的估算，因此随着更多“飞镖”的投掷，估算的圆应当会趋近于单位圆。因此，虽然两种方法在估算不准确时都显示出差距，但随着“飞镖”数量的增加，这种差距在蒙特卡罗方法中应当会更加一致地减少。
- en: 'Predicting Pi: The Power of Probability'
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测π值：概率的力量
- en: What makes Monte Carlo simulations so powerful is their ability to harness randomness
    to solve deterministic problems. By generating a large number of random scenarios
    and analyzing the results, we can estimate the probability of different outcomes,
    even for complex problems that would be difficult to solve analytically.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特卡罗模拟之所以如此强大，是因为它们能够利用随机性来解决确定性问题。通过生成大量随机场景并分析结果，我们可以估算不同结果的概率，即使对于那些难以通过解析方法解决的复杂问题也是如此。
- en: 'In the case of estimating pi, the Monte Carlo method allows us to make a very
    accurate estimate, even though we’re just throwing darts randomly. As discussed,
    the more darts we throw, the more accurate our estimate becomes. This is a demonstration
    of the law of large numbers, a fundamental concept in probability theory that
    states that the average of the results obtained from a large number of trials
    should be close to the expected value, and will tend to become closer and closer
    as more trials are performed. Let’s see if this tends to be true for our six examples
    shown in **Figures 2a-2f** by plotting the number of darts thrown against the
    difference between Monte Carlo-estimated pi and real pi. In general, our graph
    (**Figure 2g**) should trend negative. Here’s the code to accomplish this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在估计π的情况下，蒙特卡罗方法允许我们即使随机投掷飞镖，也能做出非常准确的估计。如前所述，投掷的飞镖越多，我们的估计就越准确。这展示了大数法则，这是概率论中的一个基本概念，指出从大量试验中获得的结果的平均值应该接近期望值，并且随着试验次数的增加，会趋近于期望值。让我们通过绘制投掷的飞镖数量与蒙特卡罗估计的π与真实π之间的差异的关系图来检验我们的**图2a-2f**中的六个例子是否趋于真实。一般来说，我们的图表（**图2g**）应该呈现负趋势。这里是实现这一点的代码：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/9bc1eaea5faddf7bcbcfdf80c02843ae.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bc1eaea5faddf7bcbcfdf80c02843ae.png)'
- en: 'Note that, even with only 6 examples, the general pattern is as expected: more
    darts thrown (more scenarios), a smaller difference between the estimated and
    real value, and thus a better prediction.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，即使只有6个例子，整体模式也如预期：投掷的飞镖更多（更多的场景），估计值与真实值之间的差异更小，从而预测更准确。
- en: 'Let’s say we throw 1,000,000 total darts, and allow ourselves 500 predictions.
    In other words, we will record the difference between the estimated and actual
    values of pi at 500 evenly spaced intervals throughout the simulation of 1,000,000
    thrown darts. Rather than generate 500 extra figures, let’s just skip to what
    we’re trying to confirm: whether it’s indeed true that as more darts are thrown,
    the difference in our predicted value of pi and real pi gets lower. We’ll use
    a scatter plot (**Figure 2h**):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们投掷1,000,000支飞镖，并进行500次预测。换句话说，我们将记录在1,000,000支飞镖模拟过程中，π的估计值与实际值之间的差异，在500个均匀间隔的位置上。与其生成500个额外的图形，不如直接跳到我们要确认的内容：是否真的如飞镖数量增加那样，π的预测值与真实π之间的差异变小。我们将使用散点图（**图2h**）：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/7b8d1e0d699a105a98436848cde70ada.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b8d1e0d699a105a98436848cde70ada.png)'
- en: 'Monte Carlo Simulations and Hyperparameter Tuning: A Winning Combination'
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 蒙特卡罗模拟与超参数调优：完美组合
- en: 'You might be thinking to yourself at this point, “Monte Carlo is an interesting
    statistical tool, but how does it apply to machine learning?” The short answer
    is: in many ways. One of the many applications of Monte Carlo simulations in machine
    learning is in the realm of hyperparameter tuning.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，“蒙特卡罗是一个有趣的统计工具，但它如何应用于机器学习呢？”简短的回答是：有很多种方式。蒙特卡罗模拟在机器学习中的一个应用就是超参数调优。
- en: Hyperparameters are the knobs and dials that we (the humans) adjust when setting
    up machine learning algorithms. They control aspects of the algorithm’s behavior
    that, crucially, aren’t learned from the data. For example, in a decision tree,
    the maximum depth of the tree is a hyperparameter. In a neural network, the learning
    rate and the number of hidden layers are hyperparameters.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数是我们（人类）在设置机器学习算法时调整的旋钮和拨盘。它们控制算法行为的方面，这些方面关键的是从数据中无法学习到的。例如，在决策树中，树的最大深度是一个超参数。在神经网络中，学习率和隐藏层的数量是超参数。
- en: Choosing the right hyperparameters can make the difference between a model that
    performs poorly and one that performs excellently. But how do we know which hyperparameters
    to choose? This is where Monte Carlo simulations come in.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的超参数可以决定一个模型表现差异与表现优异之间的差别。但是我们如何知道选择哪些超参数呢？这就是蒙特卡罗模拟的作用所在。
- en: Traditionally, machine learning practitioners have used methods like grid search
    or random search to tune hyperparameters. These methods involve specifying a set
    of possible values for each hyperparameter, and then training and evaluating a
    model for every possible combination of hyperparameters. This can be computationally
    expensive and time-consuming, especially when there are many hyperparameters to
    tune or a large range of possible values each can take.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，机器学习从业者使用网格搜索或随机搜索等方法来调整超参数。这些方法涉及为每个超参数指定一组可能的值，然后为每一个可能的超参数组合训练和评估模型。这可能会非常耗费计算资源和时间，尤其是当有许多超参数需要调整或每个超参数可以取的值范围很大时。
- en: Monte Carlo simulations offer a more efficient alternative. Instead of exhaustively
    searching through all possible combinations of hyperparameters, we can randomly
    sample from the space of hyperparameters according to some probability distribution.
    This allows us to explore the hyperparameter space more efficiently and find good
    combinations of hyperparameters faster.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特卡洛模拟提供了一个更高效的替代方案。我们可以根据某种概率分布从超参数空间中随机采样，而不是穷尽所有可能的超参数组合。这使我们能够更有效地探索超参数空间，并更快地找到好的超参数组合。
- en: In the next section, we’ll use a real dataset to demonstrate how to use Monte
    Carlo simulations for hyperparameter tuning in practice. Let’s get started!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将使用一个真实数据集来演示如何在实践中使用蒙特卡洛模拟进行超参数调整。让我们开始吧！
- en: Monte Carlo Simulations for Hyperparameter Tuning
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 蒙特卡洛模拟用于超参数调整
- en: 'The Heartbeat of Our Experiment: The Heart Disease Dataset'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验的核心：心脏病数据集
- en: In the world of machine learning, data is the lifeblood that powers our models.
    For our exploration of Monte Carlo simulations in hyperparameter tuning, let’s
    look at a dataset that’s close to the heart — quite literally. The [Heart Disease
    dataset](https://archive.ics.uci.edu/dataset/45/heart+disease) (CC BY 4.0) from
    the UCI Machine Learning Repository is a collection of medical records from patients,
    some of whom have heart disease.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的世界里，数据是驱动我们模型的命脉。为了探索蒙特卡洛模拟在超参数调整中的应用，让我们来看一个与心脏息息相关的数据集——字面上的意思。[心脏病数据集](https://archive.ics.uci.edu/dataset/45/heart+disease)（CC
    BY 4.0）来自UCI机器学习库，是一些患者的医学记录，其中有些人患有心脏病。
- en: The dataset contains 14 attributes, including age, sex, chest pain type, resting
    blood pressure, cholesterol levels, fasting blood sugar, and others. The target
    variable is the presence of heart disease, making this a binary classification
    task. With a mix of categorical and numerical features, it’s an interesting dataset
    for demonstrating hyperparameter tuning.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含14个属性，包括年龄、性别、胸痛类型、静息血压、胆固醇水平、空腹血糖等。目标变量是心脏病的存在，使这是一个二分类任务。由于包含了分类和数值特征，这是一个有趣的数据集，用于演示超参数调整。
- en: First, let’s take a look at our dataset to get a sense of what we’ll be working
    with — always a good place to start.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们查看一下我们的数据集，以了解我们将要处理的内容——总是一个好的开始。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This shows us the first four values in our dataset across all columns. If you’ve
    loaded the right csv and named your columns as I have, your output will look like
    **Figure 3**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了数据集中所有列的前四个值。如果你加载了正确的csv文件并且像我一样命名了你的列，你的输出将会类似于**图3**。
- en: '![](../Images/825060ccf8474b6394f434b6ad7ad8c1.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/825060ccf8474b6394f434b6ad7ad8c1.png)'
- en: 'Figure 3: First 4 rows of data from our dataset'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：数据集中前4行的数据显示
- en: 'Setting the Pulse: Preprocessing the Data'
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设定脉搏：数据预处理
- en: 'Before we can use the Heart Disease dataset for hyperparameter tuning, we need
    to preprocess the data. This involves several steps:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以使用心脏病数据集进行超参数调整之前，我们需要对数据进行预处理。这涉及几个步骤：
- en: 'Handling missing values: Some records in the dataset have missing values. We’ll
    need to decide how to handle these, whether by deleting the records, filling in
    the missing values, or some other method.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理缺失值：数据集中有些记录缺失了值。我们需要决定如何处理这些缺失值，可以通过删除记录、填补缺失值或其他方法。
- en: 'Encoding categorical variables: Many machine learning algorithms require input
    data to be numerical. We’ll need to convert categorical variables into a numerical
    format.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编码分类变量：许多机器学习算法要求输入数据为数值型。我们需要将分类变量转换为数值格式。
- en: 'Normalizing numerical features: Machine learning algorithms often perform better
    when numerical features are on a similar scale. We’ll apply normalization to adjust
    the scale of these features.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 规范化数值特征：机器学习算法在数值特征处于类似尺度时通常表现更好。我们将应用规范化来调整这些特征的尺度。
- en: Let’s start by handling missing values. In our Heart Disease dataset, we have
    a few missing values in the ‘ca’ and ‘thal’ columns. We’ll fill these missing
    values with the median of the respective column. This is a common strategy for
    dealing with missing data, as it doesn’t drastically affect the distribution of
    the data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先处理缺失值。在我们的心脏病数据集中，‘ca’和‘thal’列中有一些缺失值。我们将用各自列的中位数填补这些缺失值。这是一种处理缺失数据的常见策略，因为它不会严重影响数据的分布。
- en: Next, we’ll encode the categorical variables. In our dataset, the ‘cp’, ‘restecg’,
    ‘slope’, ‘ca’, and ‘thal’ columns are categorical. We’ll use label encoding to
    convert these categorical variables into numerical ones. Label encoding assigns
    each unique category in a column to a different integer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将对分类变量进行编码。在我们的数据集中，‘cp’，‘restecg’，‘slope’，‘ca’和‘thal’列是分类的。我们将使用标签编码将这些分类变量转换为数值型的。标签编码将列中的每个唯一类别分配给不同的整数。
- en: Finally, we’ll normalize the numerical features. Normalization adjusts the scale
    of numerical features so that they all fall within a similar range. This can help
    improve the performance of many machine learning algorithms. We’ll use standard
    scaling for normalization, which transforms the data to have a mean of 0 and a
    standard deviation of 1.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将规范化数值特征。规范化调整数值特征的尺度，使它们都落在类似的范围内。这可以帮助提高许多机器学习算法的性能。我们将使用标准化来进行规范化，将数据转化为均值为0，标准差为1。
- en: 'Here’s the Python code that performs all of these preprocessing steps:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是执行所有这些预处理步骤的Python代码：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The first print statement shows us the number of missing values in each column
    of the original dataset. In our case, the ‘ca’ and ‘thal’ columns had a few missing
    values.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个打印语句显示了原始数据集中每列的缺失值数量。在我们的情况下，‘ca’和‘thal’列中有一些缺失值。
- en: The second print statement shows us the first few rows of the dataset after
    filling in the missing values. As discussed, we used the median of each column
    to fill in the missing values.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个打印语句显示了填补缺失值后的数据集前几行。如前所述，我们使用了每列的中位数来填补缺失值。
- en: The third print statement shows us the first few rows of the dataset after encoding
    the categorical variables. After this step, all the variables in our dataset are
    numerical.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个打印语句显示了对分类变量进行编码后数据集的前几行。经过这一步骤，我们的数据集中的所有变量都是数值型的。
- en: 'The final print statement shows us the first few rows of the dataset after
    normalizing the numerical features, in which the data will have a mean of 0 and
    a standard deviation of 1\. After this step, all the numerical features in our
    dataset are on a similar scale. Check that your output resembles **Figure 4**:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的打印语句显示了在规范化数值特征后数据集的前几行，其中数据的均值为0，标准差为1。经过这一步骤，我们数据集中的所有数值特征都在类似的尺度上。检查您的输出是否类似于**图4**：
- en: '![](../Images/accf0ab79ef4c394e9b4916bee3d6601.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/accf0ab79ef4c394e9b4916bee3d6601.png)'
- en: 'Figure 4: Preprocessing Print Statements Output'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：预处理打印语句输出
- en: After running this code, we have a preprocessed dataset that’s ready for modeling.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码后，我们得到了一个已经过预处理的数据集，准备好进行建模。
- en: Implementing a Basic Machine Learning Model
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现一个基本的机器学习模型
- en: Now that we’ve preprocessed our data, we’re ready to implement a basic machine
    learning model. This will serve as our baseline model, which we’ll later try to
    improve through hyperparameter tuning.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经预处理了数据，准备实施一个基本的机器学习模型。这将作为我们的基准模型，之后我们将尝试通过超参数调优来改进它。
- en: We’ll use a simple logistic regression model for this task. Note that while
    it’s called “regression,” this is actually one of the most popular algorithms
    for binary classification problems, like the one we’re dealing with in the Heart
    Disease dataset. It’s a linear model that predicts the probability of the positive
    class.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个简单的逻辑回归模型来完成这个任务。请注意，尽管它被称为“回归”，但它实际上是处理二分类问题（如我们在心脏病数据集中遇到的）的最受欢迎的算法之一。这是一个线性模型，用于预测正类的概率。
- en: 'After training our model, we’ll evaluate its performance using two common metrics:
    accuracy and ROC-AUC. Accuracy is the proportion of correct predictions out of
    all predictions, while ROC-AUC (Receiver Operating Characteristic — Area Under
    Curve) measures the trade-off between the true positive rate and the false positive
    rate.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练我们的模型后，我们将使用两个常见指标来评估其性能：准确度和ROC-AUC。准确度是所有预测中正确预测的比例，而ROC-AUC（接收者操作特征曲线—曲线下面积）衡量真实正率和假正率之间的权衡。
- en: But what does this have to do with Monte Carlo simulations? Well, machine learning
    models like logistic regression have several hyperparameters that can be tuned
    to improve performance. However, finding the best set of hyperparameters can be
    like searching for a needle in a haystack. This is where Monte Carlo simulations
    come in. By randomly sampling different sets of hyperparameters and evaluating
    their performance, we can estimate the probability distribution of good hyperparameters
    and make an educated guess about the best ones to use, similarly to how we picked
    better values of pi in our dart-throwing exercise.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这与蒙特卡洛模拟有什么关系呢？好吧，像逻辑回归这样的机器学习模型有几个可以调整的超参数，以提高性能。然而，找到最佳的超参数组合就像在大海捞针。这就是蒙特卡洛模拟的用武之地。通过随机采样不同的超参数组合并评估其性能，我们可以估算出良好超参数的概率分布，并对使用哪些最佳参数做出有根据的猜测，类似于我们在掷飞镖练习中挑选更好π值的方式。
- en: 'Here’s the Python code that implements and evaluates a basic logistic regression
    model for our newly pre-processed data:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是实现并评估我们新预处理数据的基本逻辑回归模型的Python代码：
- en: '[PRE6]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/ab7fe1b123a842dc37e015e81ef67a84.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab7fe1b123a842dc37e015e81ef67a84.png)'
- en: With an accuracy of 0.885 and an ROC-AUC score of 0.884, our basic logistic
    regression model has set a solid baseline for us to improve upon. These metrics
    indicate that our model is performing quite well at distinguishing between patients
    with and without heart disease. Let’s see if we can make it better.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的基本逻辑回归模型具有0.885的准确度和0.884的ROC-AUC分数，为我们提供了一个坚实的基准，以便进一步改进。这些指标表明我们的模型在区分有心脏病和无心脏病的患者方面表现相当出色。让我们看看是否能进一步提高。
- en: Hyperparameter Tuning with Grid Search
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用网格搜索进行超参数调整
- en: In machine learning, a model’s performance can often be improved by tuning its
    hyperparameters. Hyperparameters are parameters that are not learned from the
    data, but are set prior to the start of the learning process. For example, in
    logistic regression, the regularization strength ‘C’ and the type of penalty ‘l1’
    or ‘l2’ are hyperparameters.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，模型的性能通常可以通过调整其超参数来提高。超参数是从数据中未学习到的参数，而是在学习过程开始之前设置的。例如，在逻辑回归中，正则化强度‘C’和惩罚类型‘l1’或‘l2’都是超参数。
- en: Let’s perform hyperparameter tuning on our logistic regression model using grid
    search. We’ll tune the ‘C’ and ‘penalty’ hyperparameters, and we’ll use ROC-AUC
    as our scoring metric. Let’s see if we can beat our baseline model’s performance.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用网格搜索对逻辑回归模型进行超参数调整。我们将调整‘C’和‘penalty’超参数，并使用ROC-AUC作为我们的评分指标。让我们看看能否超越基准模型的表现。
- en: Now, let’s start with the Python code for this section.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始这一部分的Python代码。
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/362c2f7a58ab5e1a8870ca80e3d86d16.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/362c2f7a58ab5e1a8870ca80e3d86d16.png)'
- en: 'With the best hyperparameters found to be {‘C’: 0.1, ‘penalty’: ‘l2’}, our
    grid search has an accuracy of 0.852 and an ROC-AUC score of 0.853 for the best
    model. Interestingly, this performance is slightly lower than our baseline model.
    This could be due to the fact that our baseline model’s hyperparameters were already
    well-suited to this particular dataset, or it could be a result of the randomness
    inherent in the train-test split. Regardless, it’s a valuable reminder that more
    complex models and techniques are not always better.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '经过网格搜索发现最佳超参数为{‘C’: 0.1, ‘penalty’: ‘l2’}，我们最佳模型的准确度为0.852，ROC-AUC分数为0.853。有趣的是，这一表现稍低于我们的基准模型。这可能是因为基准模型的超参数已经非常适合这个数据集，或者可能是由于训练-测试划分中的随机性所致。不管怎样，这都提醒我们更复杂的模型和技术并不总是更好。'
- en: However, you might have also noticed that our grid search only explored a relatively
    small number of possible hyperparameter combinations. In practice, the number
    of hyperparameters and their potential values can be much larger, making grid
    search computationally expensive or even infeasible.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，你可能也注意到，我们的网格搜索只探索了相对较少的超参数组合。在实际操作中，超参数及其潜在值的数量可能会大得多，从而使网格搜索计算上昂贵甚至不可行。
- en: 'This is where the Monte Carlo method comes in. Let’s see if this more guided
    approach improves on either the original baseline or grid search-based model’s
    performance:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是蒙特卡罗方法的作用。让我们看看这种更有指导性的方法是否能改善原始基线或基于网格搜索的模型的表现：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/1235ce9445d8466f6cd31a496d0321cf.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1235ce9445d8466f6cd31a496d0321cf.png)'
- en: 'In the Monte Carlo method, we found that the best ROC-AUC score was 0.9014,
    with the best hyperparameters being {‘C’: 0.1, ‘penalty’: ‘l1’}. The accuracy
    of the best model was 0.9016.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '在蒙特卡罗方法中，我们发现最佳ROC-AUC分数为0.9014，最佳超参数为{‘C’: 0.1, ‘penalty’: ‘l1’}。最佳模型的准确率为0.9016。'
- en: '**A Tale of Two Techniques: Grid Search vs. Monte Carlo**'
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**两种技术的故事：网格搜索与蒙特卡罗**'
- en: Grid search selects the “best” hyperparameters by evaluating the performance
    of all possible combinations in the hyperparameter space on the training set,
    and selecting the combination that yields the best average performance according
    to a predefined metric (e.g., accuracy, ROC-AUC, etc.). This involves splitting
    the training data into several subsets (or “folds”, which we’ve set to 5 in our
    code), training the model on some of the folds and evaluating it on the remaining
    fold, and then averaging the performance across all the folds. This is known as
    cross-validation and helps to reduce overfitting by ensuring that the model performs
    well on average across different subsets of the training data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索通过评估超参数空间中所有可能组合在训练集上的性能，并根据预定义的指标（例如，准确率、ROC-AUC等）选择产生最佳平均性能的组合，从而选择“最佳”超参数。这涉及将训练数据分成几个子集（或“折叠”，我们在代码中设置为5），在一些折叠上训练模型，在其余折叠上评估模型，然后在所有折叠中平均性能。这被称为交叉验证，有助于通过确保模型在不同训练数据子集上的平均表现良好来减少过拟合。
- en: In contrast, the Monte Carlo method does not perform any averaging across different
    subsets of the training data. It selects hyperparameters randomly, evaluates the
    model on the entire training set, and then selects the hyperparameters that yield
    the best performance on the test set. This approach does not use any cross-validation
    and hence does not average the performance across different subsets of the training
    data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，蒙特卡罗方法不会对不同训练数据子集进行任何平均。它随机选择超参数，在整个训练集上评估模型，然后选择在测试集上产生最佳性能的超参数。这种方法不使用任何交叉验证，因此不会对不同训练数据子集的性能进行平均。
- en: In the above experiment, even though the grid search method evaluated the combination
    selected by the Monte Carlo method, it did not select it as the “best” hyperparameters
    because it likely did not yield the best average performance across the different
    subsets of the training data during the cross-validation process. However, the
    combination selected by the Monte Carlo method happened to yield better performance
    on the specific test set used in this experiment. This suggests that the selected
    hyperparameters perform well on the specific characteristics of the test set,
    even though they did not perform the best on average across different subsets
    of the training data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述实验中，尽管网格搜索方法评估了蒙特卡罗方法选择的组合，但由于该组合在交叉验证过程中未能在不同训练数据子集上产生最佳平均性能，因此未被选为“最佳”超参数。然而，蒙特卡罗方法选择的组合恰好在本实验中使用的特定测试集上表现更好。这表明所选超参数在特定测试集的特征上表现良好，即使它们在不同训练数据子集上的平均表现不是最好。
- en: This highlights the trade-off between the bias introduced by averaging across
    different subsets of the training data in the grid search method, and the variance
    introduced by evaluating the model on the entire training set and selecting the
    hyperparameters based on a single test set in the Monte Carlo method.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这突显了网格搜索方法中通过对不同训练数据子集进行平均引入的偏差，与蒙特卡罗方法中通过在整个训练集上评估模型并根据单个测试集选择超参数引入的方差之间的权衡。
- en: I encourage you to tinker with the Python code and observe how different factors
    impact the performance. You can also compare the computation time between the
    two methods with different hyperparameter spaces to understand their efficiency.
    This exercise aims to demonstrate the dynamics of these methods, which have their
    merits and limitations, and to highlight that the “best” method may depend on
    your specific scenario, computational resources, and model requirements. So, feel
    free to experiment and happy learning!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你动手尝试 Python 代码，观察不同因素如何影响性能。你还可以比较两种方法在不同超参数空间下的计算时间，以了解它们的效率。这个练习旨在展示这些方法的动态，它们各有优缺点，并突出“最佳”方法可能取决于你的具体场景、计算资源和模型要求。因此，随意实验，祝学习愉快！
- en: Conclusion
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The Monte Carlo method, born from a game of solitaire, has undoubtedly reshaped
    the landscape of computational mathematics and data science. Its power lies in
    its simplicity and versatility, allowing us to tackle complex, high-dimensional
    problems with relative ease. From estimating the value of pi with a game of darts
    to tuning hyperparameters in machine learning models, Monte Carlo simulations
    have proven to be an invaluable tool in our data science arsenal.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 起源于纸牌游戏的蒙特卡罗方法，无疑重新塑造了计算数学和数据科学的格局。它的力量在于其简洁性和多功能性，使我们能够相对轻松地处理复杂的高维问题。从通过掷飞镖估计π的值到在机器学习模型中调整超参数，蒙特卡罗模拟已经证明了其在数据科学武器库中的宝贵价值。
- en: In this article, we’ve journeyed from the origins of the Monte Carlo method,
    through its theoretical underpinnings, and into its practical applications in
    machine learning. We’ve seen how it can be used to optimize machine learning models,
    with a hands-on exploration of hyperparameter tuning using a real-world dataset.
    We’ve also compared it with other methods, demonstrating its efficiency and effectiveness.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们从蒙特卡罗方法的起源出发，了解了它的理论基础，并探讨了其在机器学习中的实际应用。我们看到了它如何用来优化机器学习模型，并通过使用真实数据集进行超参数调整的实践探索。我们还与其他方法进行了比较，展示了它的效率和有效性。
- en: But the story of Monte Carlo is far from over. As we continue to push the boundaries
    of machine learning and data science, the Monte Carlo method will undoubtedly
    continue to play a crucial role. Whether we’re developing sophisticated AI applications,
    making sense of complex data, or simply playing a game of solitaire, the Monte
    Carlo method is a testament to the power of simulation and approximation in solving
    complex problems.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 但蒙特卡罗的故事远未结束。随着我们不断推动机器学习和数据科学的边界，蒙特卡罗方法无疑将继续发挥重要作用。无论我们是在开发复杂的 AI 应用、理解复杂数据，还是只是玩一局纸牌游戏，蒙特卡罗方法都证明了模拟和近似在解决复杂问题中的强大力量。
- en: As we move forward, let’s take a moment to appreciate the beauty of this method
    — a method that has its roots in a simple card game, yet has the power to drive
    some of the most advanced computations in the world. The Monte Carlo method truly
    is a high-stakes game of chance and complexity, and so far, it seems, the house
    always wins. So, keep shuffling the deck, keep playing your cards, and remember
    — in the game of data science, Monte Carlo could just be your ace in the hole.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们向前迈进时，让我们花一点时间欣赏这个方法的美妙——一个起源于简单纸牌游戏的方法，却能够驱动世界上最先进的计算。蒙特卡罗方法确实是一场高风险的机会与复杂性的游戏，到目前为止，它似乎总能获胜。因此，继续洗牌，继续打牌，并记住——在数据科学的游戏中，蒙特卡罗可能就是你手中的王牌。
- en: Parting Thoughts
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 离别感想
- en: Congratulations on making it to the end! We’ve journeyed through the world of
    probabilities, wrestled with complex models, and emerged with a newfound appreciation
    for the power of Monte Carlo simulations. We’ve seen them in action, simplifying
    intricate problems into manageable components, and even optimizing hyperparameters
    for machine learning tasks.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你成功到达终点！我们已经探索了概率的世界，挣扎于复杂的模型，并对蒙特卡罗模拟的强大能力有了新的认识。我们见证了它们如何将复杂的问题简化为可管理的组件，甚至优化了机器学习任务的超参数。
- en: If you enjoy diving into the intricacies of ML problem-solving as much as I
    do, follow me on [Medium](https://medium.com/@sydneynye) and [LinkedIn](http://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=sydney-nye).
    Together, let’s navigate the AI labyrinth, one clever solution at a time.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你像我一样喜欢深入探讨机器学习问题的复杂性，请关注我在 [Medium](https://medium.com/@sydneynye) 和 [LinkedIn](http://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=sydney-nye)
    上。让我们一起在人工智能的迷宫中，一次解决一个巧妙的问题。
- en: Until our next statistical adventure, keep exploring, keep learning, and keep
    simulating! And in your data science and ML journey, may the odds be ever in your
    favor.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 直到我们的下一个统计冒险，继续探索，继续学习，继续模拟！在你数据科学和机器学习的旅程中，愿好运常伴你左右。
- en: '*Note: All images, unless otherwise noted, are by the author.*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：除非另有说明，所有图片均由作者提供。*'
