- en: How Nightshade Works
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nightshade 的工作原理
- en: 原文：[https://towardsdatascience.com/how-nightshade-works-b1ae14ae76c3?source=collection_archive---------1-----------------------#2023-11-03](https://towardsdatascience.com/how-nightshade-works-b1ae14ae76c3?source=collection_archive---------1-----------------------#2023-11-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-nightshade-works-b1ae14ae76c3?source=collection_archive---------1-----------------------#2023-11-03](https://towardsdatascience.com/how-nightshade-works-b1ae14ae76c3?source=collection_archive---------1-----------------------#2023-11-03)
- en: Confusing image-generating AI with poisoned data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将生成图像的人工智能与被污染的数据混淆
- en: '[](https://medium.com/@doriandrost?source=post_page-----b1ae14ae76c3--------------------------------)[![Dorian
    Drost](../Images/1795395ad0586eafd83d3e2f7b975ca8.png)](https://medium.com/@doriandrost?source=post_page-----b1ae14ae76c3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b1ae14ae76c3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b1ae14ae76c3--------------------------------)
    [Dorian Drost](https://medium.com/@doriandrost?source=post_page-----b1ae14ae76c3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@doriandrost?source=post_page-----b1ae14ae76c3--------------------------------)[![Dorian
    Drost](../Images/1795395ad0586eafd83d3e2f7b975ca8.png)](https://medium.com/@doriandrost?source=post_page-----b1ae14ae76c3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b1ae14ae76c3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b1ae14ae76c3--------------------------------)
    [Dorian Drost](https://medium.com/@doriandrost?source=post_page-----b1ae14ae76c3--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d49ea537d1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-nightshade-works-b1ae14ae76c3&user=Dorian+Drost&userId=1d49ea537d1c&source=post_page-1d49ea537d1c----b1ae14ae76c3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b1ae14ae76c3--------------------------------)
    ·10 min read·Nov 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb1ae14ae76c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-nightshade-works-b1ae14ae76c3&user=Dorian+Drost&userId=1d49ea537d1c&source=-----b1ae14ae76c3---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d49ea537d1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-nightshade-works-b1ae14ae76c3&user=Dorian+Drost&userId=1d49ea537d1c&source=post_page-1d49ea537d1c----b1ae14ae76c3---------------------post_header-----------)
    发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b1ae14ae76c3--------------------------------)
    ·10 分钟阅读·2023年11月3日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb1ae14ae76c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-nightshade-works-b1ae14ae76c3&user=Dorian+Drost&userId=1d49ea537d1c&source=-----b1ae14ae76c3---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1ae14ae76c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-nightshade-works-b1ae14ae76c3&source=-----b1ae14ae76c3---------------------bookmark_footer-----------)![](../Images/06b719db201217808f3920a3b86de4c9.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb1ae14ae76c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-nightshade-works-b1ae14ae76c3&source=-----b1ae14ae76c3---------------------bookmark_footer-----------)![](../Images/06b719db201217808f3920a3b86de4c9.png)'
- en: Just like the high walls of a castle, Nightshade can be a way to defend intellectual
    properties against illegitimate use. Photo by [Nabih El Boustani](https://unsplash.com/@nounouis?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 就像城堡的高墙一样，*Nightshade* 可以成为保护知识产权不受非法使用的一种方式。照片由 [Nabih El Boustani](https://unsplash.com/@nounouis?utm_source=medium&utm_medium=referral)
    提供，发布在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The recent emergence of [*Nightshade*](https://arxiv.org/abs/2310.13828), an
    algorithm that allows to create poisoned data for confusing image-generating AI
    models, has given new life to the discussion on adversarial attacks on such models.
    This discussion is also influenced by ethical and social considerations, as such
    attacks may provide a way for artists, content creators, and others to fight back
    if they feel treated unjustly by the fact that AI models use their content without
    permission, but could also be used with bad intentions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最近出现的 [*Nightshade*](https://arxiv.org/abs/2310.13828) 算法能够创建用于混淆图像生成 AI 模型的污染数据，给有关此类模型的对抗攻击讨论注入了新的活力。这一讨论也受到伦理和社会考量的影响，因为这些攻击可能为艺术家、内容创作者和其他人提供了反击的方式，如果他们觉得
    AI 模型未经许可使用了他们的内容，但也可能被用于不良意图。
- en: In this article, I want to explain the core concepts of Nightshade. To this
    end, I will first explain the general idea of data poisoning and highlight its
    shortcomings. Then I will introduce you to Nightshade, an algorithm that overcomes
    some of the disadvantages of the naive approach. In the end, I will briefly discuss
    some ethical considerations that come from its use.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我想解释 Nightshade 的核心概念。为此，我将首先解释数据中毒的一般思路，并突出其不足之处。然后，我将向你介绍 Nightshade，一种克服幼稚方法一些缺点的算法。最后，我将简要讨论一些来自其使用的伦理考虑。
- en: Data poisoning
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据中毒
- en: '![](../Images/af49aea3e5964e2f1d180c6f498af741.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af49aea3e5964e2f1d180c6f498af741.png)'
- en: Poisonous or not? Photo by [Fiona Smallwood](https://unsplash.com/@thepeoplesdigital?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 毒性还是无毒？图片由 [Fiona Smallwood](https://unsplash.com/@thepeoplesdigital?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Let’s start with the idea of data poisoning in general. Say you want to influence
    image-generating AIs in such a way, that they fail to generate certain kinds of
    images, or are unable to understand certain prompts. Why do you want to do this?
    The most likely non-destructive reasons might be, that you are an artist and want
    to avoid that an image-generating model is able to generate images in your style,
    or that you have created a new comic character that should not be reproduced by
    an image-generating model without your permission.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从数据中毒的概念开始说起。假设你想影响图像生成 AI，使其无法生成某些类型的图像，或者无法理解某些提示。你为什么要这样做？最可能的非破坏性原因可能是，你是一个艺术家，想避免图像生成模型能够生成你的风格的图像，或者你创造了一个新的漫画角色，该角色在未经你许可的情况下不应由图像生成模型再现。
- en: So, what do you do? Let us start with understanding a basic concept of how generative
    AI learns. Of course, an image-generating AI depends on its training data. To
    be precise, it relies on the fact that there are images showing a certain concept
    (say a *dog*) and that those images are associated with a text describing their
    content (e.g. an image caption like *a cute dog with glasses*). From that, it
    learns to extract certain visual properties that images share, which also share
    certain keywords in their captions. That is, the model learns *what dogs look
    like* by learning the properties of all those images that mention *dog* in their
    caption.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你该怎么做呢？让我们从了解生成 AI 学习的基本概念开始。显然，图像生成 AI 依赖于其训练数据。具体来说，它依赖于存在展示某个概念（比如 *狗*）的图像，并且这些图像与描述其内容的文本（例如像
    *带眼镜的可爱狗* 这样的图像说明）相关联。基于此，它学习提取图像共享的某些视觉属性，这些图像的说明中也包含某些关键词。也就是说，模型通过学习提到 *狗*
    的所有图像的属性来学习 *狗的样子*。
- en: Now, what would happen if you would introduce images that show dogs, but whose
    captions always mention *cats*? In the end, *dog* and *cat* are just symbols for
    what can be seen in the images. If the images that show dogs are labeled as cats,
    the model will just learn that the symbol *cat* refers to what we would call *dog*.
    Without any prior knowledge of the English language, how would the model know
    that the labels are wrong if they are so consistent? If you don’t speak German,
    and I would show you a hundred images of dogs and tell you their label is *Katze*,
    you would assume that *Katze* is the German word for *dog.* You wouldn’t know
    that the actual German word for *dog* is *Hund,* and *Katze* means *cat* because
    you just learned the correlation between the labels and the images’ properties.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你引入显示狗的图像，但这些图像的说明总是提到 *猫*，会发生什么呢？最终，*狗* 和 *猫* 只是图像中可以看到的东西的符号。如果显示狗的图像被标记为猫，模型将只是学到符号
    *猫* 代表我们称之为 *狗* 的东西。如果模型没有任何英语语言的先验知识，如何知道这些标签是错误的，即使它们是如此一致？如果你不懂德语，我给你展示一百张狗的图像，并告诉你它们的标签是
    *Katze*，你会假设 *Katze* 是德语中的 *狗*。你不会知道实际的德语单词 *狗* 是 *Hund*，而 *Katze* 意思是 *猫*，因为你只是学习了标签与图像属性之间的关联。
- en: The process just described is called *data poisoning,* stemming from the idea
    that you introduce data instances, that have a malicious effect on the model’s
    training (just like a poison has a malicious effect on your health).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 刚才描述的过程被称为 *数据中毒*，源于你引入对模型训练具有恶意影响的数据实例的想法（就像毒药对你的健康有恶意影响一样）。
- en: Naive poisoning attacks
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 幼稚的数据中毒攻击
- en: '![](../Images/8632fa35f988b5aed9475c9f689dd709.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8632fa35f988b5aed9475c9f689dd709.png)'
- en: A cute dog with glasses, thinking about how to attack an image-generating model.
    Photo by [Jamie Street](https://unsplash.com/@jamie452?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一只戴着眼镜的可爱狗狗，想着如何攻击图像生成模型。照片由[Jamie Street](https://unsplash.com/@jamie452?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: As a naive approach, you could take the aforementioned idea and use it to confuse
    machine learning models like Stable Diffusion. Say you want to make Stable Diffusion
    create images of cats when being prompted for dogs. For that, you would need to
    create many images of cats, label them as *dogs,* and upload them to the internet.
    Then you hope that those images are scraped for the next training of a Stable
    Diffusion model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种简单的方法，你可以使用上述想法来混淆像Stable Diffusion这样的机器学习模型。假设你想让Stable Diffusion在被提示为狗时生成猫的图片。为此，你需要创建许多猫的图片，将它们标记为*狗*，并将它们上传到互联网。然后你希望这些图片被抓取用于Stable
    Diffusion模型的下次训练。
- en: 'If many of your images become part of the next training run, that could indeed
    lead to confusion between cats and dogs. However, there are some drawbacks to
    that approach:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你许多图片成为下次训练的一部分，这确实可能导致猫和狗之间的混淆。然而，这种方法也有一些缺点：
- en: You will need many images. Since there are many other images of cats that are
    not poisoned, you need a large number of images to have an impact at all. If you
    provide only 10 poisoned images, and there are 1000 non-poisoned images of cats
    on the other side, you almost have no influence on the training. Typically, you
    can expect to poison 20% or more of all images to have an effect.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要很多图片。由于有许多其他未中毒的猫的图片，你需要大量的图片才能产生影响。如果你只提供10张中毒图片，而另一边有1000张未中毒的猫的图片，你对训练几乎没有影响。通常，你需要对所有图片中20%或更多的图片进行中毒才能产生效果。
- en: Note that you do not know which images exactly will be part of the training.
    Hence, if you want to introduce 500 poisoned images into the training, you may
    have to create 5000 and spread them all over the internet, because only some of
    them may actually be scraped for training.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意，你不知道哪些图片会成为训练的一部分。因此，如果你想将500张中毒图片引入训练中，你可能需要创建5000张并将它们散布在整个互联网，因为只有其中的一些可能会实际被抓取用于训练。
- en: If you upload images of cats, labeled as *dogs*, humans can easily detect that.
    Before using your images for training, they may be filtered out by a quality gate
    (being a human or a specialized AI).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你上传标记为*狗*的猫的图片，人类可以很容易地识别出来。在使用你的图片进行训练之前，它们可能会被质量门槛过滤掉（无论是人类还是专门的AI）。
- en: Nightshade
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Nightshade
- en: '![](../Images/89ec939d3c8c67ec4065cc2af1df3fee.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89ec939d3c8c67ec4065cc2af1df3fee.png)'
- en: The nightshade algorithm has its name from a very poisonous plant. Photo by
    [Georg Eiermann](https://unsplash.com/@georgeiermann?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Nightshade算法的名字源自一种非常毒性的植物。照片由[Georg Eiermann](https://unsplash.com/@georgeiermann?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'Now let’s take a look at *Nightshade*, an algorithm that aims at overcoming
    those disadvantages. For that, Nightshade uses two key concepts: It creates images
    that have the maximum effect on the model (which leads to a need for fewer images
    in total) and that are indistinguishable from non-poisoned images for humans.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看*Nightshade*，这是一种旨在克服这些缺点的算法。为此，Nightshade使用两个关键概念：它创建对模型产生最大影响的图片（这意味着总共需要更少的图片），以及这些图片在人类眼中无法与非中毒图片区分开来。
- en: 'First, how to get the maximum effect out of the images? In theory, you would
    want to use those images, that lead to the biggest change of the gradient during
    the training. However, to find out which images those are, you would have to observe
    the training process, which you can’t do, in general. The authors of Nightshade
    propose a different solution though: You take an image, that has been generated
    by the model you want to poison. That is, if you want to have cat images labeled
    as dogs, you prompt the model with a simple prompt like *an image of a cat*. The
    image it creates will be a very typical representation of what the model understood
    to be a cat. If this image is seen in training, it will have a very high influence
    on the understanding of the concept cat (a much higher than rather untypical images
    of cats have). Hence, if you poison that image, you will get a very large effect
    on the model’s training.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如何从图像中获得最大效果？理论上，你会希望使用那些在训练过程中导致梯度变化最大的图像。然而，要找出这些图像，你需要观察训练过程，这在一般情况下是做不到的。不过，Nightshade
    的作者提出了一种不同的解决方案：你可以使用一个由你想要破坏的模型生成的图像。也就是说，如果你想让猫的图像被标记为狗，你可以用一个简单的提示词来提示模型，比如*一只猫的图像*。模型生成的图像将是它理解为猫的一个非常典型的表现。如果这个图像在训练中出现，它将对猫的概念理解产生很高的影响（比那些不典型的猫图像要高得多）。因此，如果你破坏这个图像，你将对模型的训练产生非常大的影响。
- en: 'Second, we said that Nightshade’s images should be indistinguishable from non-poisoned
    images. To reach this goal, Nightshade takes natural images and applies a perturbation
    (i.e. a small change in the pixel’s values), until the image is perceived differently
    by the model. Continuing with our dog vs. cat example from above, we would take
    an image generated by the model that shows a cat. This image we refer to as the
    *anchor image* or xᵃ in the upcoming formulas. Next, we take a very typical image
    of a dog, which we refer to as xₜ. To this image xₜ, we now add the perturbation
    δ s.t. it optimizes the following objective:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们说过，Nightshade 的图像应该与未被破坏的图像难以区分。为了达到这个目标，Nightshade 采用自然图像并施加扰动（即像素值的小变化），直到图像被模型以不同方式感知。继续使用我们之前的狗与猫的例子，我们会取一个由模型生成的显示猫的图像。这个图像我们称之为*锚图像*或接下来的公式中的
    xᵃ。接下来，我们取一张非常典型的狗图像，我们称之为 xₜ。现在，我们对这张图像 xₜ 添加扰动 δ，使其优化以下目标：
- en: '![](../Images/9a43af97d7fafd49aa3a4825c482c826.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a43af97d7fafd49aa3a4825c482c826.png)'
- en: where *F()* is the image feature extractor used by the model, *Dist* is a distance
    function and *p* is an upper bound for the δ, to avoid the image changing too
    much. That means we want to find δ s.t. the distance between the features of the
    perturbated dog image (F(xₜ + δ)) and the anchor image (showing the cat, F(xᵃ))
    is as small as possible. In other words, we want the two images to look alike
    from the model’s perspective. Be aware, that F(x), the result of the feature extractor,
    is how the model *sees* the image in feature space, which is different from how
    you see the image (in pixel space, if you want).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *F()* 是模型使用的图像特征提取器，*Dist* 是距离函数，*p* 是 δ 的上界，以避免图像变化过大。这意味着我们希望找到 δ，使得扰动后的狗图像（F(xₜ
    + δ)）和锚图像（显示猫的 F(xᵃ)）的特征之间的距离尽可能小。换句话说，我们希望从模型的角度来看，这两个图像是相似的。请注意，F(x) 是特征提取器的结果，它是模型在特征空间中*看见*的图像，这与你在像素空间中看到的图像不同。
- en: In the following images, you won’t be able to spot any difference between the
    original and the poisoned images (at least I can’t). However, in their feature
    space, they differ a lot. The features of the poisoned dog image, for example,
    are very close to the features of a cat image and hence for the model it almost
    looks like a cat.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的图像中，你将无法发现原始图像和被破坏图像之间的任何差异（至少我看不到）。然而，在它们的特征空间中，它们的差异很大。例如，被破坏的狗图像的特征非常接近猫图像的特征，因此对于模型来说，它几乎看起来像一只猫。
- en: '![](../Images/3ab1ef415b193785dc81a66adfde6204.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ab1ef415b193785dc81a66adfde6204.png)'
- en: Two examples of poisoned images. The images in the lower line are perturbated
    versions of the upper ones. Although no difference can be seen by a human, the
    original and poisoned images look very different from a model’s perspective. Image
    taken from the Nightshade paper[1].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 两个被破坏图像的例子。下排的图像是上排图像的扰动版本。尽管人眼无法看出差异，但从模型的角度看，原始图像和被破坏的图像非常不同。图像取自 Nightshade
    论文[1]。
- en: With this technique, we are able to generate images that have a very big effect
    on the model’s training and that can’t be detected as being poisoned. If you would
    upload these images to the internet, no human would be suspicious at all and hence
    it is very unlikely, that they would be filtered out by any quality gate. In addition,
    since they are so powerful, you don’t need to poison 20% of all dog images in
    the training data, as you would with the naive approach. With Nightshade, 50 to
    100 images are typically enough to ruin a model's performance on a particular
    concept.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种技术，我们能够生成对模型训练产生巨大影响且无法被检测为被毒化的图像。如果你将这些图像上传到互联网上，没有人会对其产生怀疑，因此这些图像很不可能被任何质量门槛过滤掉。此外，由于这些图像的威力如此之大，你不需要像采用简单方法时那样毒化20%的狗图像。使用Nightshade，通常50到100张图像就足以破坏模型在特定概念上的表现。
- en: Generalizability
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泛化能力
- en: Beyond the points we just saw, Nightshade has another interesting advantage,
    which is its ability to generalize in multiple ways.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们刚才看到的要点外，Nightshade还有另一个有趣的优势，即其多种方式的概括能力。
- en: First of all, poisoning a certain keyword also influences concepts that are
    related in a linguistic or semantic fashion. E.g. poisoning images of the concept
    *dog* also influences keywords like *puppy* or *husky*, which are related to *dog*.
    In the following examples, the concept *dog* has been poisoned and this also impedes
    the generation of *puppies* and *huskies*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，毒化某个关键词也会影响那些在语言或语义上相关的概念。例如，毒化*狗*的图像也会影响像*小狗*或*哈士奇*这样的关键词，这些概念与*狗*相关。在以下示例中，*狗*概念已被毒化，这也阻碍了*小狗*和*哈士奇*的生成。
- en: '![](../Images/d7ee38ee05cb93705b036d29642c55f7.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7ee38ee05cb93705b036d29642c55f7.png)'
- en: An example of how poisoning a concept (dog) also impedes the generation of related
    concepts (puppy, husky, wolf). Image taken from the Nightshade paper[1].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例，说明了如何通过毒化一个概念（狗）也会阻碍相关概念（小狗、哈士奇、狼）的生成。图像摘自Nightshade论文[1]。
- en: In a likewise fashion, poisoning a concept such as *fantasy* also influences
    concepts that are related semantically, but leaves other concepts unaffected,
    as can be seen in the following example. As you see, a concept like *dragon*,
    which is close to the poisoned *fantasy,* is affected, while a concept like *chair*
    is not.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，毒化一个如*幻想*的概念也会影响语义上相关的概念，但不会影响其他概念，如下例所示。你可以看到，像*龙*这样的概念，它与被毒化的*幻想*相近，受到了影响，而像*椅子*这样的概念则没有。
- en: '![](../Images/cacb3836b0f65edcff5ece31a9a62e37.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cacb3836b0f65edcff5ece31a9a62e37.png)'
- en: An example of how poisoning a concept (fantasy) also impedes related concepts
    (e.g. dragon). Note that non-related concepts (e.g. chair) are not affected. Image
    taken from the Nightshade paper[1].
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例，说明了如何通过毒化一个概念（幻想）也会阻碍相关概念（例如龙）的生成。注意，非相关概念（例如椅子）没有受到影响。图像摘自Nightshade论文[1]。
- en: In addition, when poisoning multiple concepts, the ability to generate images
    may break down in its entirety. In the following example, 100, 250, or 500 concepts
    have been poisoned. With more concepts being poisoned, the generation of other
    concepts, that have not been poisoned at all (like *person* or *painting* in the
    example), is heavily impeded as well.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当毒化多个概念时，生成图像的能力可能会完全崩溃。在以下示例中，100、250或500个概念已被毒化。随着毒化概念的增加，即使是那些完全未被毒化的其他概念（如*人*或*绘画*），其生成也会受到严重阻碍。
- en: '![](../Images/00245ac22b1a1cb87635c2fa244f56b9.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00245ac22b1a1cb87635c2fa244f56b9.png)'
- en: An example is how poisoning many concepts impedes the ability to generate images
    in general. Note that the concepts *person,* painting, *and seashell have not
    been poisoned specifically. Image taken from the Nightshade paper[1].*
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是如何毒化多个概念会阻碍生成图像的能力。注意，*人*、绘画和*海贝*这些概念并没有特别被毒化。图像摘自Nightshade论文[1]。
- en: In addition to that, Nightshade’s effects also generalize over different target
    models. Remember that we used the model we wanted to attack to generate the anchor
    images, that helped us construct our poisoned images. The idea behind that was,
    that those images are very prototypical and hence would have a strong influence
    on the training. We also needed access to the feature extractor to optimize the
    perturbation. Naturally, Nightshade’s influence is strongest if these anchor images
    are generated by the model that is to be attacked and if that model’s feature
    extractor can be used for the optimization. However, even if anchor images and
    feature extractor come from another model, the poisoning works quite well. That
    is, you could generate your poisoned images with the help of, say, Stable Diffusion
    2, even if you want to attack Stable Diffusion XL. This may be of interest if
    you don’t have access to the model you actually want to attack.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Nightshade 的效果也会对不同的目标模型产生普遍影响。请记住，我们使用了我们想攻击的模型来生成锚定图像，这帮助我们构建了被污染的图像。其背后的想法是，这些图像具有很强的原型特征，因此会对训练产生强烈影响。我们还需要访问特征提取器来优化扰动。自然，Nightshade
    的影响在这些锚定图像由被攻击的模型生成，并且该模型的特征提取器可以用于优化时最强。然而，即使锚定图像和特征提取器来自其他模型，中毒效果也相当好。也就是说，你可以使用例如
    Stable Diffusion 2 来生成你的中毒图像，即使你想攻击的是 Stable Diffusion XL。如果你没有访问实际想攻击的模型，这可能会很有趣。
- en: Ethical Concerns
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 伦理问题
- en: So far, I introduced Nightshade as a method that can be used by content creators
    to defend their intellectual properties against illegitimate use. However, as
    there are always two sides to a coin, data poisoning can as well be used in a
    harmful manner, may it be on purpose or not. Needless to say, data poisoning can
    be used to deliberately disturb generative AI models, cause financial damage to
    their creators, and impede scientific research. An AI company destroying the training
    data of their competitors to improve their own model in contrast is only one of
    countless examples of malign usages of data poisoning. However, even if you just
    want to defend your own content, we just saw, that poisoning many concepts impedes
    the AI’s ability to generate images in total. Hence, if many people make use of
    Nightshade, this may destroy image-generating AIs even on those concepts that
    would be legitimate to use. Hence, even with the intention to protect their own
    content, a content creator using Nightshade may cause unwanted damage. Whether
    and to which extent such collateral damage has to be accepted is a question for
    a vivid open debate.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我介绍了 Nightshade 作为一种可以被内容创作者用来防御其知识产权不被非法使用的方法。然而，正如硬币有两面一样，数据中毒也可以被用来有害地，可能是有意的，也可能是无意的。无需多言，数据中毒可以用来故意扰乱生成式
    AI 模型，给其创建者造成财务损失，并妨碍科学研究。一家 AI 公司为了提升自己的模型而摧毁竞争对手的训练数据，只是数据中毒恶意使用的无数例子之一。然而，即使你只是想保护自己的内容，我们刚刚看到，大量的概念中毒会妨碍
    AI 生成图像的能力。因此，如果很多人使用 Nightshade，这可能会摧毁图像生成 AI 对那些本应合法使用的概念的生成能力。因此，即使是为了保护自己的内容，使用
    Nightshade 的内容创作者也可能造成不必要的损害。是否以及在多大程度上接受这种附带损害，是一个值得热烈讨论的问题。
- en: On top of that, as you can imagine, attacking the capabilities of generative
    AI is a battle of constant ups and downs. Whenever new attacks are invented, the
    other side comes up with new defense mechanisms. Although the authors claim that
    Nightshade is quite robust against common defense mechanisms (e.g. detecting images
    as being poisoned by a specialized classifier or other properties), it may only
    be a matter of time until new defenses are discovered that counteract Nightshade.
    From that perspective, Nightshade may allow creators to protect their content
    for the time being but may become outdated sooner or later.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，正如你可以想象的那样，攻击生成式 AI 的能力是一场不断起伏的战斗。每当新的攻击手段被发明出来，另一方便会提出新的防御机制。虽然作者声称 Nightshade
    对常见的防御机制（例如，使用专门分类器检测被污染的图像或其他属性）相当强健，但只不过是时间问题，直到新的防御措施被发现来对抗 Nightshade。从这个角度来看，Nightshade
    可能暂时允许创作者保护他们的内容，但最终可能会变得过时。
- en: Summary
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: As we just saw, Nightshade is an algorithm to create poisoned datasets, that
    goes beyond the naive approach of labeling data with incorrect labels. It creates
    images that are not detectable as being poisoned by humans and that can influence
    an image-generating AI heavily even with a low number of examples. This drastically
    increases the chance of the poisoned images becoming part of the training and
    having an effect there. Even more, it promises to generalize in a number of ways,
    which makes the attacks more powerful and less easy to defend against. With that,
    Nightshade provides a new way of fighting back against the illegitimate use of
    content for model training, for which no permission has been given by its creators,
    but also includes the potential of destructive use and hence calls for a debate
    on its ethical implications. Being used with noble intentions, Nightshade can
    help defend intellectual properties such as an artist’s style or inventions though.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚刚看到的，Nightshade 是一种创建中毒数据集的算法，它超越了用错误标签标记数据的幼稚方法。它创建的图像不会被人类识别为中毒图像，即使示例数量较少，也能严重影响图像生成
    AI。这大大增加了中毒图像成为训练数据的一部分并产生影响的可能性。此外，它承诺在多种方式上进行泛化，这使得攻击更加强大且不易防御。因此，Nightshade
    提供了一种新的方式来反击未经其创作者许可用于模型训练的不正当使用，但也包括了潜在的破坏性使用，因此需要对其伦理影响进行讨论。若出于高尚意图使用，Nightshade
    可以帮助保护知识产权，例如艺术家的风格或发明。
- en: Sources
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 来源
- en: 'That is the original paper introducing Nightshade:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是介绍 Nightshade 的原始论文：
- en: '[1] Shan, S., Ding, W., Passananti, J., Zheng, H., & Zhao, B. Y. (2023). Prompt-Specific
    Poisoning Attacks on Text-to-Image Generative Models. *arXiv preprint arXiv:2310.13828*.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Shan, S., Ding, W., Passananti, J., Zheng, H., & Zhao, B. Y. (2023). Prompt-Specific
    Poisoning Attacks on Text-to-Image Generative Models. *arXiv preprint arXiv:2310.13828*.'
- en: '*Like this article?* [*Follow me*](https://medium.com/@doriandrost) *to be
    notified of my future posts.*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*喜欢这篇文章？* [*关注我*](https://medium.com/@doriandrost) *以便获取我未来的帖子通知。*'
