- en: A Gentle Introduction to Analytical Stream Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对分析流处理的温和介绍
- en: 原文：[https://towardsdatascience.com/a-gentle-introduction-to-stream-processing-f47912a2a2ea?source=collection_archive---------13-----------------------#2023-03-31](https://towardsdatascience.com/a-gentle-introduction-to-stream-processing-f47912a2a2ea?source=collection_archive---------13-----------------------#2023-03-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-gentle-introduction-to-stream-processing-f47912a2a2ea?source=collection_archive---------13-----------------------#2023-03-31](https://towardsdatascience.com/a-gentle-introduction-to-stream-processing-f47912a2a2ea?source=collection_archive---------13-----------------------#2023-03-31)
- en: Building a Mental Model for Engineers and Anyone in Between
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为工程师及其他相关人员构建心理模型
- en: '[](https://newfrontcreative.medium.com/?source=post_page-----f47912a2a2ea--------------------------------)[![Scott
    Haines](../Images/b53c166b64314b4a5fe41abbe1839716.png)](https://newfrontcreative.medium.com/?source=post_page-----f47912a2a2ea--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f47912a2a2ea--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f47912a2a2ea--------------------------------)
    [Scott Haines](https://newfrontcreative.medium.com/?source=post_page-----f47912a2a2ea--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://newfrontcreative.medium.com/?source=post_page-----f47912a2a2ea--------------------------------)[![Scott
    Haines](../Images/b53c166b64314b4a5fe41abbe1839716.png)](https://newfrontcreative.medium.com/?source=post_page-----f47912a2a2ea--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f47912a2a2ea--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f47912a2a2ea--------------------------------)
    [Scott Haines](https://newfrontcreative.medium.com/?source=post_page-----f47912a2a2ea--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3b4cab6af83e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-stream-processing-f47912a2a2ea&user=Scott+Haines&userId=3b4cab6af83e&source=post_page-3b4cab6af83e----f47912a2a2ea---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f47912a2a2ea--------------------------------)
    ·17 min read·Mar 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff47912a2a2ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-stream-processing-f47912a2a2ea&user=Scott+Haines&userId=3b4cab6af83e&source=-----f47912a2a2ea---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3b4cab6af83e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-stream-processing-f47912a2a2ea&user=Scott+Haines&userId=3b4cab6af83e&source=post_page-3b4cab6af83e----f47912a2a2ea---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f47912a2a2ea--------------------------------)
    · 17 分钟阅读 · 2023年3月31日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff47912a2a2ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-stream-processing-f47912a2a2ea&user=Scott+Haines&userId=3b4cab6af83e&source=-----f47912a2a2ea---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff47912a2a2ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-stream-processing-f47912a2a2ea&source=-----f47912a2a2ea---------------------bookmark_footer-----------)![](../Images/fd0a84c03854cae7fa6ec7e862e56b1c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff47912a2a2ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-stream-processing-f47912a2a2ea&source=-----f47912a2a2ea---------------------bookmark_footer-----------)![](../Images/fd0a84c03854cae7fa6ec7e862e56b1c.png)'
- en: 'Stream Processing can be handled gently and with care, or wildly, and almost
    out of control! You be the judge of what future you’d rather embrace. credit:
    [@psalms](https://unsplash.com/@psalms) [original_photo](https://unsplash.com/photos/o3Ggpo3BvqM)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理可以被温柔而细致地处理，也可以被狂野而几乎失控地处理！你可以判断你更愿意拥抱哪种未来。来源：[@psalms](https://unsplash.com/@psalms)
    [原始照片](https://unsplash.com/photos/o3Ggpo3BvqM)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In many cases, processing data in-stream, or as it becomes available, can help
    reduce an enormous data problem (due to the volume and scale of the flow of data)
    into a more manageable one. By processing a smaller set of data, *more often*,
    you effectively divide and conquer a data problem that may otherwise be cost and
    time prohibitive.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，将数据流中或实时可用的数据进行处理，可以将由于数据流量和规模而导致的庞大数据问题，转化为更可管理的问题。通过更频繁地处理较小的数据集，你可以有效地解决那些可能因成本和时间限制而难以处理的数据问题。
- en: How you transition from a batch mindset to a streaming mindset although can
    also be tricky, so let’s start small and build.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从批处理思维转变为流处理思维虽然也可能很棘手，所以让我们从小做起，逐步构建。
- en: From Enormous Data back to Big Data
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从庞大的数据回到大数据
- en: Say you are tasked with building an analytics application that must process
    around *1 billion events* (1,000,000,000) a day. While this might feel far-fetched
    at first, due to the sheer size of the data, it often helps to step back and think
    about the intention of the application (what does it do?) and what you are processing
    (what does the data look like)? Asking yourself if the event data can be broken
    down (divided and partitioned) and processed in parallel as a streaming operation
    (aka in-stream), or must you process things in series, across multiple steps?
    In either case, if you modify the perspective of the application to look at bounded
    windows of time, then you now only need to create an application that can ingest,
    and processing, a mere *11.5 thousand (k) events a second* (or around 695k events
    a minute if the event stream is constant), which is an easier number to rationalize.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你负责构建一个分析应用程序，该应用程序必须处理大约*10亿个事件*（1,000,000,000）每天。虽然这在开始时可能感觉难以实现，但由于数据的巨大规模，通常有助于退后一步，思考应用程序的意图（它做了什么？）和你正在处理的内容（数据是什么样的）？问问自己事件数据是否可以被分解（划分和分区）并作为流处理操作（即流内）并行处理，还是必须通过多个步骤串行处理？无论哪种情况，如果你将应用程序的视角修改为查看有限的时间窗口，那么你现在只需要创建一个可以摄取和处理仅*每秒11,500个事件（k）*（或者如果事件流是恒定的，则每分钟约695k个事件）的应用程序，这是一个更容易理解的数字。
- en: While these numbers may still seem out of reach, this is where distributed stream
    processing can really shine. Essentially, you are reducing the perspective, or
    scope, of the problem, to accomplish a goal over time, across a partitioned data
    set. While not all problems can be handled in-stream, a surprising number of problems
    do lend themselves to this processing pattern.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些数字仍然可能显得难以触及，但这正是分布式流处理真正发挥光芒的地方。从本质上讲，你是在减少问题的视角或范围，以在时间上跨越分区数据集实现目标。虽然并非所有问题都能在流处理中解决，但许多问题确实适合这种处理模式。
- en: '***Note****: This chapter is part of my book* [*“Modern Data Engineering with
    Apache Spark: A Hands-On Guide for Building Mission-Critical Streaming Applications”*](https://www.amazon.com/Modern-Engineering-Apache-Spark-Hands/dp/1484274512)*.
    The book takes you on the journey building from simple scripting, to composing
    applications, and finally deploying and monitoring your mission critical Apache
    Spark applications.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意****：本章是我书中的一部分* [*“现代数据工程与Apache Spark：构建关键流应用程序的实用指南”*](https://www.amazon.com/Modern-Engineering-Apache-Spark-Hands/dp/1484274512)*。本书带你从简单的脚本编写，到应用程序的构建，最后到部署和监控你的关键Apache
    Spark应用程序。*'
- en: What you will learn this Chapter
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本章学习内容
- en: This chapter will act as a gentle introduction to stream processing making room
    for us to jump directly into building our own end to end Structured Streaming
    application in [chapter 10](https://github.com/newfront/spark-moderndataengineering/tree/main/ch-10)
    without the need to backtrack and discuss a lot of the theory behind the decision-making
    process.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将作为流处理的温和介绍，为我们直接进入[第10章](https://github.com/newfront/spark-moderndataengineering/tree/main/ch-10)构建自己的端到端结构化流应用程序做好准备，而无需回顾和讨论许多决策过程背后的理论。
- en: 'By the end of the chapter, you should understand the following (at a high level):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该能高层次地理解以下内容：
- en: How to Reduce Streaming Data Problems in Data Problems *over Time*
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何减少流数据问题中的*时间问题*
- en: The Trouble with Time, Timestamps, and Event Perspective
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 时间、时间戳和事件视角的问题
- en: The Different Processing Modes for Shifting from a Batch to Streaming Mental
    Model
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从批处理到流处理思维模型的不同处理模式
- en: Stream Processing
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流处理
- en: Streaming data is *not stationary*. In fact, you can think of it as being alive
    (if even for a short while). This is because streaming data is data that encapsulates
    the *now, it records events and actions as they occur in flight*. Let’s look at
    a practical, albeit theoretical, example that begins with a simple event stream
    of sensor data. Fix into your mind’s eye the last parking lot (or parking garage)
    you visited.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 流数据是*非静态的*。事实上，你可以将其视为活跃的（即使只是短时间）。这是因为流数据是捕捉*当前时刻的事件和动作的*数据。让我们来看一个实际的，尽管是理论上的例子，它从一个简单的传感器数据流开始。把你最后一次访问的停车场（或停车库）固定在你的脑海中。
- en: 'Use Case: Real-Time Parking Availability'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例：实时停车可用性
- en: '![](../Images/f425e52790bbff4b82e5041a3807a16b.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f425e52790bbff4b82e5041a3807a16b.png)'
- en: 'Parking is a Nightmare: The problem with most parking infrastructure, or a
    common pain point for the customer, is more often than not finding an available
    spot while still being able to get places on time. [Photo via Unspash](https://unsplash.com/photos/k1AFA4N8O0g)
    and [@ryansearle](https://unsplash.com/@ryansearle)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 停车是个噩梦：大多数停车基础设施的问题，或客户的常见痛点，往往是在确保按时到达的情况下找到一个可用的车位。[照片来自 Unspash](https://unsplash.com/photos/k1AFA4N8O0g)
    和 [@ryansearle](https://unsplash.com/@ryansearle)
- en: Imagine you just found a parking spot all thanks to some helpful signs that
    pointed you to an open space. Now let’s say that this was all because of the data
    being emitted from a connected network of local parking sensors. Sensors which
    operate with the sole purpose of *being used to identify the number of available
    parking spaces* available at that precise moment in time.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你刚刚找到一个停车位，感谢一些有用的标志指引你到一个空车位。现在假设这一切都因为来自连接的本地停车传感器网络的数据。传感器的唯一目的是*用于识别此时此刻可用停车位的数量*。
- en: This is a real-time data problem where the real-time accuracy is both measurable,
    as well as physically noticeable, by a user of the parking structure. Enabling
    these capabilities all began with the declaration of the system scenario.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实时数据问题，实时准确性既可以测量，也可以由停车结构的用户实际感受到。这些能力的实现始于系统场景的声明。
- en: '**Product Pitch**: “We’d like to create a system that keeps track of the status
    of all available parking spaces, that identifies when a car parks, how long the
    car remains in a given spot, and lastly this process should be automated as much
    as possible”'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**产品推广**：“我们希望创建一个系统来跟踪所有可用停车位的状态，识别何时有车辆停车、车辆在特定车位停留多久，并且尽可能地自动化这个过程”'
- en: Optimizing a system like this can begin with *a simple sensor* located in each
    parking spot (associated with a sensor.id / spot.id reference). Each sensor would
    be responsible for emitting data in the form of **an event** with a spot identifier,
    timestamp, and simple bit (0 or 1), to denote if a spot is empty or occupied.
    This data can then be encoded into a compact message format, like the example
    from Listing 9–1, and be efficiently sent periodically from each parking spot.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 优化这样的系统可以从*一个简单的传感器*开始，该传感器位于每个停车位（与传感器.id / 车位.id 参考关联）。每个传感器负责以**事件**的形式发出数据，包含车位标识符、时间戳和简单的位（0
    或 1），以表示车位是空的还是被占用。然后，这些数据可以编码为紧凑的消息格式，如示例 9–1，并定期从每个停车位高效地发送。
- en: '**Listing 9–1**. An example sensor event (encapsulated in the [Google Protocol
    Buffer](https://protobuf.dev/) message format) is shown for clarity.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 9–1**. 为了清晰起见，展示了一个示例传感器事件（封装在[Google Protocol Buffer](https://protobuf.dev/)消息格式中）。'
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: During the normal flow of traffic throughout the day, **the state** (availability
    of a parking spot) via the sensors would flip on or off (**binary states**) as
    cars arrive or leave each spot. This behavior is unpredictable due to the dynamic
    schedules of each individual drivers, but patterns always emerge at scale.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在一天的正常交通流中，传感器的**状态**（停车位的可用性）会根据车辆到达或离开每个车位而开或关（**二进制状态**）。由于每个驾驶员的动态日程，这种行为是不可预测的，但随着规模的扩大，模式总是会显现出来。
- en: 'Using the real-time state provided by the collected sensor data , it is easily
    feasible to build real-time, real-life (IRL) “reporting” to update drivers on
    the active state of the parking structure: is the parking infrastructure full,
    or not, and if it isn’t full, that there are *now X total number of available
    spots* in the garage.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 利用收集的传感器数据提供的实时状态，可以轻松构建实时的、现实生活中的（IRL）“报告”，以便更新驾驶员停车结构的活动状态：停车基础设施是否已满，如果未满，则车库中*目前有
    X 个可用车位*。
- en: What the Sensor Data Achieves
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传感器数据的作用
- en: This data can help to automate the *human decision-making process* for drivers
    and could even be made available online, through a simple web service, for real-time
    status tracking, since ultimately drivers just want to park already and not waste
    time! Additionally, this data can also be used to track when each sensor last
    checked in (refreshed) which can be used to diagnosis faulty sensors, and even
    track how often sensors go offline or fail.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据可以帮助自动化*人类决策过程*，甚至可以通过简单的网络服务在线提供，以便实时跟踪状态，因为最终驾驶员只是想尽快停车，而不是浪费时间！此外，这些数据还可以用于跟踪每个传感器上次检查的时间（刷新），这可以用来诊断故障传感器，甚至跟踪传感器离线或故障的频率。
- en: Nowadays, more technologically advanced garages even go so far as to direct
    the driver (via directional signs and cues) to the available spots within the
    structure. This acts to both reduce inter-garage traffic and congestion, which
    in turn raises customer satisfaction, all by simply capturing a live stream of
    sensor data and processing it in near-real-time.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，技术更先进的车库甚至能够通过指示牌和提示引导驾驶员到结构内的空车位。这既减少了车库间的交通和拥堵，又提高了顾客满意度，所有这一切只需捕捉实时的传感器数据流并进行近实时处理。
- en: Surge Pricing and Data Driven Decision Making
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高峰定价和数据驱动决策
- en: Given the temporal (timestamp) information gathered from these streams of sensor
    events, a savvy garage operation could use prior trends to even decrease or increase
    the daily or hourly prices, based on the demand for parking spots, with respect
    to current availability (number of spots left) in real-time. By optimizing the
    pricing (within realistic limits) an operator could find the perfect threshold
    where the price per hour / price per day leads to a full garage more times than
    it doesn’t. In other words, *“at what price will most people park and spots don’t
    go unused?”*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 根据从这些传感器事件流中收集的时间（时间戳）信息，一个精明的车库运营者可以利用先前的趋势来实时减少或增加每日或每小时的价格，这取决于对车位的需求，考虑到当前的可用性（剩余车位数）。通过优化定价（在现实限制范围内），运营者可以找到一个完美的阈值，使得每小时/每日价格能使车库更多时间达到满员。换句话说，*“以什么价格大多数人愿意停车且车位不会空置？”*。
- en: This is an example of an optimization problem that stems from the collection
    of real-time sensor data. It is becoming more common for organizations to look
    at how they reuse data to solve multiple problems at the same time. The *Internet
    of Things* (IOT) use cases are just one of the numerous possible streams of data
    you could be working with when writing streaming applications.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个优化问题的例子，源于实时传感器数据的收集。组织越来越常见地查看如何重用数据来同时解决多个问题。*物联网*（IOT）用例只是你在编写流应用程序时可能处理的众多数据流中的一种。
- en: Earlier in the book we discussed “creating a system that could take information
    about Coffee store occupancy, which would inform folk what shop nearest to them
    has seating for a party of their size” at that point in the story we simply created
    a synthetic table that could be joined to showcase this example, but this is another
    problem that can be solved with sensors, or something as simple as a check-in
    system, that emits relevant event data to be passed reliably downstream via our
    friend the streaming data pipeline.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在书中早些时候，我们讨论了“创建一个系统，可以获取咖啡店的占用信息，以告知人们离他们最近的店铺是否有适合他们人数的座位”。在故事中的那个阶段，我们只是创建了一个合成表来展示这个例子，但这也是一个可以用传感器或简单的签到系统解决的问题，该系统发出相关事件数据，通过我们的流数据管道可靠地传递下游。
- en: Both examples discussed here (parking infrastructure and coffee empire expansion)
    employ basic analytics (statistics) and can benefit from simple machine learning
    to uncovering new patterns of behavior that lead to more optimal operations. Before
    we get too far ahead of ourselves, let’s take a short break to dive deeper into
    the capabilities streaming data networks provide.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里讨论的两个例子（停车基础设施和咖啡帝国扩展）都采用了基本的分析（统计），并可以从简单的机器学习中受益，以发现新的行为模式，从而实现更优的操作。在我们过于深入之前，先休息一下，深入了解流数据网络提供的功能。
- en: Time Series Data and Event Streams
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据和事件流
- en: Moving from a stationary data mindset, about a fixed view or moment in time,
    to one that interprets data as it flows over time, in terms of streams of unbounded
    data across many views and moments in time, is an exercise in perspective but
    also one that can be challenging to adopt at first. Often when you think about
    streaming systems, the notion of streams of continuous events bubble to the surface.
    This is one of the more common use cases and can be used as more of a gentle introduction
    to the concept of *streaming data*. Take for example the abstract time series
    shown in **Figure 9–1**.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个关于固定视图或时间点的静态数据思维方式，转变为一个将数据视为在时间中流动的视角，涉及到对许多视图和时间点中无限数据流的解释，这是一个视角上的练习，但起初可能具有挑战性。通常，当你考虑流式系统时，连续事件流的概念会浮现出来。这是一个更常见的用例，可以作为对*流数据*概念的温和引入。例如，**图
    9–1**中所示的抽象时间序列。
- en: '![](../Images/e4f2326ca1f17b6a665e79c34c4ee4ef.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4f2326ca1f17b6a665e79c34c4ee4ef.png)'
- en: '**Figure 9–1**: Events occur at precise moments of time and can be collected
    and processed individually (t1->t4), or can be aggregated across windows of time
    (w1). Image Credit: Author (Scott Haines)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 9–1**：事件发生在精确的时间点，可以单独收集和处理（t1->t4），也可以在时间窗口（w1）中聚合。图片来源：作者（Scott Haines）'
- en: As you can see, data itself exists across various states depending on the perspective
    or vantage point applied by a given system (or application). Each event (T1->T4)
    individually understand only *what has occurred* within their narrow pane of reference,
    or to put that differently, events capture a limited (relative) perspective of
    *time*. When a series of events are processed together in a bounded collection
    (window), then you have a series of data points (events) that encapsulate either
    *fully realized ideas*, or *partially realized ideas*. When you zoom out and look
    at the entire timeline then you can paint a more accurate story of what happened
    from first event to last.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，数据本身在不同的状态下存在，取决于系统（或应用程序）应用的视角或观点。每个事件（T1->T4）只在其狭窄的参考范围内理解*发生了什么*，或者换句话说，事件捕捉了*时间*的有限（相对）视角。当一系列事件在一个有界集合（窗口）中一起处理时，你会得到一系列数据点（事件），这些数据点要么*完全实现的概念*，要么*部分实现的概念*。当你缩小视角并查看整个时间线时，你可以更准确地描绘从第一个事件到最后一个事件发生的故事。
- en: Let’s take this idea one step further.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步探讨这个想法。
- en: Do Events Stand Alone?
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 事件是否独立存在？
- en: Consider this simple truth. Your event data exists as a complete idea, or as
    partial ideas or thoughts. I have found that thinking of data as a story over
    time helps to give life to these bytes of data. Each data point is therefore responsible
    for helping to compose a complete story, *as a series of interwoven ideas and
    thoughts that assemble or materialize over time*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个简单的事实。你的事件数据存在于完整的概念中，或作为部分概念或思想。我发现将数据视为一个随时间变化的故事有助于赋予这些数据字节以生命。因此，每个数据点负责帮助构建一个完整的故事，*作为一系列随时间展开或呈现的交织思想和观念*。
- en: Data composition is a useful lens through which to look as you work on adopting
    a distributed data view of things. I also find it lends itself well while building
    up and defining new distributed data models, as well as, while working on real
    world data networks (fabrics) at scale. Viewed as a composition, these events
    come together to tell *a specific story*, whose event-based breadcrumbs can inform
    of the order in which something came to be and is greatly enhanced with the timestamp
    of each occurrence. Events without time paint a flat view of how something occurred
    while the addition of time grants you the notion of momentum or speed, or a slowing
    down and stretching of the time between events or for a full series of data points.
    Understanding the behavior of the data flowing through the many pipelines and
    data channels is essential to data operations and requires reliable monitoring
    to keep data flowing at optimal speeds.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 数据组合是一个有用的视角，适用于你在采用分布式数据视图时。我还发现它在构建和定义新的分布式数据模型时很有用，同时在处理大规模的现实世界数据网络（织物）时也很有帮助。作为一种组合来看待，这些事件汇聚在一起讲述了*一个特定的故事*，这些基于事件的痕迹可以揭示事物发生的顺序，并通过每次事件的时间戳得到极大的增强。没有时间的事件描绘了一个平面的发生过程，而时间的加入赋予了你关于动量或速度的概念，或者在事件之间的时间延续和拉伸，或者对于一系列数据点的完整过程。理解数据在许多管道和数据通道中流动的行为对数据操作至关重要，并且需要可靠的监控以保持数据在最佳速度下流动。
- en: Let’s look at a use case where the dimension of time helps paint a better story
    of a real-world scenario.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个用例，其中时间维度帮助讲述一个现实世界场景的更好故事。
- en: 'Use Case: Tracking Customer Satisfaction'
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例：追踪客户满意度
- en: '![](../Images/1dd83636a68554e1777872533261238b.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1dd83636a68554e1777872533261238b.png)'
- en: A quiet coffee shop pouring love with every cup. Photo by [Nafinia Putra](https://unsplash.com/@nputra?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一家安静的咖啡店，每杯咖啡都倾注爱心。照片由 [Nafinia Putra](https://unsplash.com/@nputra?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Put yourself in the shoes of a data engineer working with the data applications
    feature teams in a fake coffee empire named “CoffeeCo”, the conversation is about
    what data paints a good story of customer satisfaction over time (time series
    analysis).
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 设想你是一个数据工程师，与一个名为“CoffeeCo”的虚拟咖啡帝国的数据应用特性团队合作，讨论的是哪些数据能够描述客户满意度随时间变化的故事（时间序列分析）。
- en: What if I told you ***two customers*** came into our coffee shop, ordered drinks
    and left the store with their drinks. You might ask me why I bothered to tell
    you that since that is what happens in coffee shops. What if I told you that the
    two coffee orders were made ***around the same*** and that *the first customer
    in the story was in and out of the coffee shop in under five minutes*. What if
    I told you, it was **a weekday**, and this story took place **during morning rush
    hour**? What if I told you that the second customer, who happened to be next in
    line (or right after the first customer) and was in the coffee shop for thirty
    minutes? You might ask if the customer stayed to read the paper or maybe use the
    facilities. *Both are valid questions*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我告诉你***两位客户***进入我们的咖啡店，点了饮料并带着饮料离开了店里。你可能会问我为什么要告诉你这些，因为这正是咖啡店里发生的事情。如果我告诉你这两个咖啡订单是在***差不多同时***
    下的，并且*故事中的第一位客户在咖啡店待了不到五分钟*。如果我告诉你这是**一个工作日**，且这个故事发生在**早高峰时段**？如果我告诉你第二位客户，恰好排在第一位客户之后，在咖啡店里待了三十分钟？你可能会问这个客户是否在读报纸或者使用设施。*这两个问题都是合理的*。
- en: If I told you that the second customer was waiting around because of an error
    that occurred *between step 3 and 4* of a four-step **coffee pipeline,** then
    we’d have a better understanding of how to streamline the customer experience
    in the future.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我告诉你第二位客户因为在四步**咖啡生产线**的*第3步和第4步之间*发生错误而等待，那么我们将更好地理解如何在未来简化客户体验。
- en: 'The four steps are:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 四个步骤是：
- en: 1\. **Customer Orders:** {customer.order:initialized}
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '1\. **客户订单**: {customer.order:initialized}'
- en: 2\. **Payment Made {**customer.order:payment:processed}
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. **付款完成** {**customer.order:payment:processed}
- en: '3\. **Order Queued**: {customer.order:queued}'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '3\. **订单排队**: {customer.order:queued}'
- en: '4\. **Order Fulfilled**: {customer.order:fulfilled}'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '4\. **订单完成**: {customer.order:fulfilled}'
- en: Whether the error was in the automation, or because of a breakdown in the real-world
    system (printer jam, barista missed an order, or any other reason), the result
    here is that the customer needed to step in (human in the loop) and inform the
    operation (coffee pipeline) that *“it appears that someone forgot to make my drink”*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 无论错误是在自动化过程中，还是由于现实世界系统的故障（如打印机卡纸、咖啡师漏单或其他任何原因），结果是客户需要插手（人工干预），并通知操作系统（咖啡生产线）*“似乎有人忘记制作我的饮料”*。
- en: 'At this point the discussion could turn towards how to handle the customers
    emotional response, which could swing widely across both positive and negative
    reactions: from happy to help (1), to mild frustration (4), all the way to outright
    anger (10) at the delay and breakdown of the coffee pipeline. But by walking through
    a hypothetical use case, we are all now more familiar with how the art of capturing
    good data can be leveraged for all kinds of things.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此时讨论可能会转向如何处理客户的情绪反应，这些反应可能在积极和消极之间大幅波动：从乐于助人（1），到轻微的挫折（4），再到对咖啡生产线的延迟和故障的明显愤怒（10）。但通过分析一个假设的用例，我们现在对如何利用捕捉好数据的艺术有了更深入的了解。
- en: The Event Time, Order of Events Captured, and the Delay Between Events All Tell
    a Story
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件时间、事件捕捉顺序和事件间的延迟都讲述了一个故事
- en: Without the knowledge of *how much time elapsed* from the first event (customer.order:initialized)
    until the terminal event (customer.order:fulfilled), or how long each step typically
    takes to accomplish, we’d have no way to score the experience or really understand
    what happened, essentially creating a blind spot to abnormal delays or faults
    in the system. It pays to know the statistics (average, median, and 99th percentiles)
    of the time a customer typically waits for a variable sized order, as these historic
    data points can be used via automation to step in to fix a problem preemptively
    when, for example, an order is taking longer than expected. It can literally mean
    the difference between an annoyed customer, and a lifetime customer.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不了解从第一个事件（customer.order:initialized）到终端事件（customer.order:fulfilled）之间的*时间经过了多久*，或者每个步骤通常需要多长时间来完成，我们将无法对体验进行评分或真正理解发生了什么，基本上就会在系统中创造出对异常延迟或故障的盲点。了解客户通常等待不同大小订单的时间的统计数据（平均值、中位数和99百分位数）是有益的，因为这些历史数据点可以通过自动化用于预先解决问题，例如当一个订单的处理时间比预期的要长时。这可能意味着客户的不满和终身客户之间的差别。
- en: This is one of the big reasons why companies solicit feedback from their customers
    — be it a thumbs up / thumbs down on an experience, rewarding application-based
    participation (spend your points on free goods and services), and to track real-time
    feedback like in the case of “your order is taking longer than expected, here
    is $2 off your next coffee. Just use the app to redeem”. This data, collected
    and captured through real-world interactions, encoded as events, and processed
    for your benefit, are worth it in the end if it positively affects the operations
    and reputation of the company. Just be sure to follow data privacy rules and regulations
    and ultimately don’t creep out your customers.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是公司请求客户反馈的主要原因之一——无论是对体验的好评/差评，奖励基于应用程序的参与（用你的积分换取免费商品和服务），还是跟踪实时反馈，比如“你的订单比预期的时间长，这里有$2折扣下次咖啡使用。只需使用应用程序兑换”。这些通过现实世界互动收集和捕获的数据，以事件形式编码，并为你的利益处理，最终是值得的，如果它积极影响公司的运营和声誉。只要确保遵循数据隐私规则和法规，最终不要让客户感到不适。
- en: This little thought experiment was intended to shed light on the fact that the
    details captured within your event data (as well as the lineage of the data story
    over time) can be a game changer and furthermore that time is the dimension that
    gives these journeys momentum or speed. There is just one problem with time.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小小的思想实验旨在揭示事件数据中捕获的细节（以及数据故事随时间的演变）可以是一个游戏规则改变者，并进一步说明时间是赋予这些旅程动力或速度的维度。只有一个时间的问题。
- en: The Trouble with Time
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间的麻烦
- en: While events occur at *precise moments in time* the trouble with time is that
    it is also subject to the problems of time and space (location). Einstein used
    his theory of relativity to explain this problem on a cosmic scale, but this is
    also a problem on a more localized scale as well. For example, I have family living
    in different parts of the United States. It can be difficult to *coordinate time*
    where everyone’s *schedule syncs up*. This happens for simple events like catching
    up with everyone over video (remotely) or meeting up in the real-world for reunions
    (locally). Even when everything is all coordinated, people have a habit of just
    *running a little bit late*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然事件发生在*精确的时间点*，但时间的问题在于它也受时间和空间（位置）问题的影响。爱因斯坦利用他的相对论理论在宇宙尺度上解释了这个问题，但在更局部的尺度上这也是一个问题。例如，我有家人住在美国不同的地方。在大家的*时间协调*上可能会有困难，这种情况发生在简单的事件中，比如远程视频聊天或在现实世界中聚会。即使一切都已协调好，人们也习惯于*稍微迟到*。
- en: Zooming out from the perspective of my family, or people in general, with respect
    to central coordination of events, you will start to see that the problem isn’t
    just an issue relating to synchronization across time zones (east / central or
    west coast), but if you look closer you can see that time, relative to our local
    / physical space, is subject to some amount of temporal drift or clock skew.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 从我的家庭或一般人的角度看，关于事件的中心协调问题，你会开始看到这个问题不仅仅是跨时区（东部/中部或西海岸）的同步问题，而是如果你更仔细地看，时间相对于我们的本地/物理空间，会受到一定的时间漂移或时钟偏差的影响。
- en: Take the modern digital clock. It runs as a process on your smart phone, watch
    or any number of many “smart” connected devices. What remains constant is that
    time stays noticeably in sync (even if the drift is on the order of milliseconds).
    Many people still have analog, non-digital, clocks. These devices run the full
    spectrum from incredibly accurate, in the case of high-end watches (“timepieces”)
    to cheap clocks that sometimes need to be reset every few days.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以现代数字时钟为例。它作为一个过程运行在你的智能手机、手表或众多“智能”连接设备中。保持不变的是时间始终明显同步（即使漂移的范围是毫秒级）。许多人仍然使用模拟的非数字时钟。这些设备的准确度从高端手表（“计时器”）的极度准确到需要每几天重新校准的便宜时钟不等。
- en: The bottom line here is that it is rare that two systems agree on the precise
    time in the same way that two or more people share similar trouble coordinating
    within both time and space. Therefore, a central reference (point of view) must
    be used to synchronize the time with respect to systems running across many time
    zones.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点在于，两个系统在精确时间上达成一致的情况很少，就像两个人在时间和空间上协调类似问题一样。因此，必须使用一个中央参考点（视角）来同步跨多个时区运行的系统的时间。
- en: '**Correcting Time**'
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**时间校正**'
- en: Servers running in any modern cloud infrastructures utilize a process called
    [Network Time Protocol](https://en.wikipedia.org/wiki/Network_Time_Protocol) (NTP)
    to correct the problem of time drift. The *ntp* process is charged with synchronizing
    the local server clock using a reliable central time server. This process corrects
    the local time to within a few milliseconds of the Universal Coordinated Time
    (UTC). This is an important concept to keep in mind since an application running
    within a large network, producing event data, will be responsible for creating
    timestamps, and these timestamps need to be precise in order for distributed events
    to line up. There is also the sneaky problem of daylight savings (gain or lose
    an hour ever 6 months) so coordinating data from systems across time zones as
    well as across local datetime semantics (globally) requires time to be viewed
    from this central, synchronized, perspective.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何现代云基础设施中运行的服务器都利用一个称为[网络时间协议](https://en.wikipedia.org/wiki/Network_Time_Protocol)（NTP）的过程来校正时间漂移的问题。*ntp*过程负责使用一个可靠的中央时间服务器同步本地服务器时钟。这个过程将本地时间校正到与协调世界时间（UTC）相差几毫秒。这是一个重要的概念，因为在大型网络中运行的应用程序，产生事件数据，将负责创建时间戳，而这些时间戳需要非常精确，以便分布式事件能够对齐。还有一个狡猾的问题是夏令时（每6个月增加或减少一小时），因此，协调跨时区以及跨本地日期时间语义（全球）的系统数据需要从这个中央、同步的视角来看待时间。
- en: We’ve looked at time as it theoretically relates to event-based data but to
    round out the background we should also look at time as it relates to the *priority*
    in which data needs to be captured and processed within a system (streaming or
    otherwise).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从理论上看过时间如何与事件驱动的数据相关，但为了全面了解背景，我们还应该考虑时间如何与数据在系统（无论是流式还是其他）中需要被捕获和处理的*优先级*相关。
- en: Priority Ordered Event Processing Patterns
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优先级排序事件处理模式
- en: You may be familiar with this quote. Time is of the essence. This is a way of
    saying something is important and a top priority. The speed to resolution matters.
    This sense of priority can be used as an instrument, or defining metric, to make
    the case for *real-time*, *near-real-time*, *batch* or *eventual (on-demand) processing*
    when process critical data. These four processing patterns handles time in a different
    way by creating a narrow, or wide focus on the data problem at hand. The scope
    here is based on the speed in which a process must complete which in turn limits
    the complexity of the job as a factor of time. Think of these styles of processing
    as being deadline driven, there is only a certain amount of time in which to complete
    an action.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能对这句名言很熟悉：“时间就是生命。”这句话的意思是某事很重要，是首要任务。解决问题的速度至关重要。这种优先级感可以作为一个工具或定义指标，用来为*实时*、*接近实时*、*批处理*或*最终处理（按需处理）*的数据处理方式辩护。这四种处理模式以不同的方式处理时间，通过对数据问题施加窄或宽的焦点来应对。这里的范围是基于一个过程必须完成的速度，这反过来限制了工作的复杂性作为时间的一个因素。可以把这些处理风格看作是以截止日期驱动的，完成一个动作的时间是有限的。
- en: Real-Time Processing
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实时处理
- en: The expectations of real-time systems are that end-to-end latency from the time
    an upstream system emits an event, until the time that event is processed and
    available to be used for analytics and insights, occurs in the milliseconds to
    low seconds. These events are emitted (written) directly to an event stream processing
    service, like Apache Kafka, which under normal circumstances enables listeners
    (consumers) to immediately use that event once it is written. There are many typical
    use cases for true real-time systems, including logistics (like the parking space
    example as well as finding a table at a coffee shop), and then processes that
    impact a business on a whole new level like fraud detection, active network intrusion
    detection or other bad actor detection where the longer the mean time to detection
    (average milliseconds / seconds to detection) can lead to devastating consequences
    both in terms of reputation, financially or both.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实时系统的期望是，从上游系统发出事件的时间到该事件被处理并可用于分析和洞察的时间，端到端延迟应在毫秒到低秒级别内。这些事件直接写入事件流处理服务，如 Apache
    Kafka，在正常情况下，允许监听者（消费者）一旦写入事件就能立即使用。真正的实时系统有许多典型用例，包括物流（如停车位示例以及在咖啡馆找到桌子），以及影响整个业务的过程，如欺诈检测、主动网络入侵检测或其他坏演员检测，其中检测的平均时间（毫秒/秒到检测）越长，可能会导致声誉、财务或两者的灾难性后果。
- en: For other systems, it is more than acceptable to run in near real-time. Given
    that answering tough problems requires time, real-time decision making requires
    a performant, pre-computed or low-latency answer to the questions it will ask.
    This really is pure in-memory stream processing.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他系统而言，运行在近实时状态是完全可以接受的。考虑到解决难题需要时间，实时决策需要高效、预计算或低延迟的答案。这确实是纯内存流处理。
- en: Near Real-Time Processing
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 近实时处理
- en: Near real-time is what most people think of when they consider real-time. A
    similar pattern occurs here as you just read about under Real-Time, the only difference
    is that the expectations of end-to-end latency are relaxed to a high number of
    seconds to a handful of minutes. For most systems, there is no real reason to
    react immediately to every event as it arrives, so while time is still of the
    essence, the priority of the SLA for data availability is extended.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 近实时是大多数人在考虑实时时的想法。这里发生的模式类似于你刚刚在实时部分阅读的，唯一的区别是端到端延迟的期望放宽到高秒级别到几分钟。对于大多数系统而言，没有真正的理由对每个到达的事件做出立即反应，因此，虽然时间仍然很重要，但数据可用性的
    SLA 优先级会有所延长。
- en: Operational dashboards and metric systems that are kept up to date (refreshing
    graphs and checking monitors every 30s — 5 minutes) are usually fast enough to
    catch problems and give a close representation of the world. For all other data
    systems, you have the notion of batch or on-demand.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 操作仪表板和度量系统通常更新迅速（每30秒—5分钟刷新图表和检查监控），足够快以捕捉问题，并给出接近现实的表示。对于所有其他数据系统，你会有批处理或按需处理的概念。
- en: Batch Processing
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批处理
- en: We covered batch processing and reoccurring scheduling in the last two chapters
    but for clarity having periodic jobs that push data from a reliable source of
    truth (data lake or database) into other connected systems has been, and continues,
    to be how much of the worlds data is processed.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前两章中涵盖了批处理和周期性调度，但为了明确，将数据从可靠的真实数据源（数据湖或数据库）推送到其他连接系统的周期性作业，一直以来都是世界数据处理的主要方式。
- en: The simple reason for this is cost. Which factors down to both the cost of operations
    and the human cost for maintaining large streaming systems.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这背后的简单原因是成本。这涉及到操作成本和维护大型流媒体系统的人力成本。
- en: Streaming systems demand full time access to a variable number of resources
    from CPUs and GPUs to Network IO and RAM, with an expectation that these resources
    won’t be scarce since delays (blockage) in stream processing can pile up quick.
    Batch on the other hand can be easier to maintain in the long run assuming the
    consumers of the data understand that there will always be a gap from the time
    data is first emitted upstream, until the data becomes available for use downstream.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理系统要求全天候访问从 CPU 和 GPU 到网络 IO 和 RAM 的可变数量资源，期望这些资源不会短缺，因为流处理中的延迟（阻塞）可能会迅速积累。另一方面，批处理在长期维护上可能更容易，只要数据的消费者理解从数据首次发出到下游数据可用之间始终存在间隔。
- en: The last consideration to keep in mind is on-demand processing (or just-in-time
    processing).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后需要考虑的是按需处理（或即时处理）。
- en: On-Demand or Just-In-Time Processing
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按需或即时处理
- en: Let’s face it. Some questions (aka queries) are asked so rarely, or in a way
    that is just not suitable to any predefined pattern.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 说实话，有些问题（即查询）问得非常少，或者以一种不适合任何预定义模式的方式提出。
- en: For example, custom reporting jobs and exploratory data analysis are two styles
    of data access that lend themselves nicely to these paradigms. Most of the time,
    the backing data to answer these queries is loaded directly from the data lake,
    and then processed using shared compute resources, or isolated compute clusters.
    The data that is made available for these queries may be the by-product of other
    real-time or near-real-time systems, that were processed and stored for batch
    or historic analysis.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，自定义报告任务和探索性数据分析是两种适合这些范式的数据访问风格。大多数情况下，回答这些查询的后端数据直接从数据湖中加载，然后使用共享计算资源或隔离计算集群进行处理。为这些查询提供的数据可能是其他实时或接近实时系统的副产品，这些系统被处理和存储用于批处理或历史分析。
- en: Using this pattern data, can be defrosted, and loaded on-demand by importing
    records from slower commodity object storage like Amazon S3 into memory, or across
    fast-access solid state drives (SSDs), or depending on the size, format, and layout
    of the data, can be queried directly from the cloud object store. This pattern
    can be easily delegated to Apache Spark using *SparkSQL*. This enables ad-hoc
    analysis via tools like Apache Zeppelin, or directly in-app through JDBC bindings
    using the [Apache Spark thrift-server](https://spark.apache.org/docs/latest/sql-distributed-sql-engine.html)
    and the Apache Hive Metastore.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种模式，数据可以解冻，并通过将记录从较慢的对象存储（如Amazon S3）导入内存，或通过快速访问的固态硬盘（SSD），或者根据数据的大小、格式和布局，直接从云对象存储中查询。这种模式可以轻松委托给Apache
    Spark，使用*SparkSQL*。这使得通过像Apache Zeppelin这样的工具进行临时分析成为可能，或通过JDBC绑定直接在应用程序中使用[Apache
    Spark thrift-server](https://spark.apache.org/docs/latest/sql-distributed-sql-engine.html)和Apache
    Hive Metastore。
- en: The differentiator between these four flavors of processing is *time*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这四种处理方式之间的区别在于*时间*。
- en: Circling back to the notion of views and perspective, each approach or pattern,
    has its *time and place*. Stream processing deals with events captured at specific
    *moments in time* and as we’ve discussed during the first half of this chapter,
    how we associate time and how we capture and measure a series of events (as data)
    all come together to paint a picture of what is happening now, or what has happened
    in the past. As we move through this gentle introduction to stream processing
    it is important to also talk about the foundations of stream processing. In this
    next section, we’ll walk through some of the common problems and solutions for
    dealing with continuous, unbounded streams of data. It would only make sense to
    therefore discuss data as a central pillar and expand outward from there.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 回到视角和观点的概念，每种方法或模式都有其*时间和地点*。流处理处理的是在特定*时间点*捕获的事件，正如我们在本章前半部分讨论的那样，我们如何关联时间，以及我们如何捕捉和测量一系列事件（作为数据），共同绘制了当前发生的情况或过去发生的情况的画面。在我们对流处理的温和介绍中，重要的是还要讨论流处理的基础。在下一节中，我们将讨论处理连续、无界数据流的一些常见问题和解决方案。因此，讨论数据作为核心支柱并从那里扩展开来是有意义的。
- en: I hope you enjoyed the first half of Chapter 9\. If you’d like to go ahead and
    read part 2\. It is linked below. 👇
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢第9章的前半部分。如果你想继续阅读第2部分，它在下面有链接。👇
- en: '[](/a-modest-introduction-to-analytical-stream-processing-db58b3694263?source=post_page-----f47912a2a2ea--------------------------------)
    [## A Modest Introduction to Analytical Stream Processing'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 谦逊的分析流处理介绍](https://towardsdatascience.com/a-modest-introduction-to-analytical-stream-processing-db58b3694263?source=post_page-----f47912a2a2ea--------------------------------)'
- en: Architectural Foundations for Building Reliable Distributed Systems.
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建可靠分布式系统的架构基础。
- en: towardsdatascience.com](/a-modest-introduction-to-analytical-stream-processing-db58b3694263?source=post_page-----f47912a2a2ea--------------------------------)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[前往数据科学](https://towardsdatascience.com/a-modest-introduction-to-analytical-stream-processing-db58b3694263?source=post_page-----f47912a2a2ea--------------------------------)'
- en: If you want to find out more, please check out my book!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多，请查看我的书！
- en: '[](https://www.amazon.com/Modern-Engineering-Apache-Spark-Hands/dp/1484274512?source=post_page-----f47912a2a2ea--------------------------------)
    [## Modern Data Engineering with Apache Spark: A Hands-On Guide for Building Mission-Critical
    Streaming…'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[现代数据工程与Apache Spark：构建关键任务流处理的实用指南](https://www.amazon.com/Modern-Engineering-Apache-Spark-Hands/dp/1484274512?source=post_page-----f47912a2a2ea--------------------------------)'
- en: 'Amazon.com: Modern Data Engineering with Apache Spark: A Hands-On Guide for
    Building Mission-Critical Streaming…'
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亚马逊网站：现代数据工程与Apache Spark：构建关键任务流处理的实用指南…
- en: www.amazon.com](https://www.amazon.com/Modern-Engineering-Apache-Spark-Hands/dp/1484274512?source=post_page-----f47912a2a2ea--------------------------------)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.amazon.com](https://www.amazon.com/Modern-Engineering-Apache-Spark-Hands/dp/1484274512?source=post_page-----f47912a2a2ea--------------------------------)'
