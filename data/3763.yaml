- en: 'Implementation Details Of Reluplex: An Efficient SMT Solver for Verifying Deep
    Neural Networks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Reluplex 的实现细节：一种高效的 SMT 求解器用于验证深度神经网络
- en: 原文：[https://towardsdatascience.com/implementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a?source=collection_archive---------5-----------------------#2023-12-27](https://towardsdatascience.com/implementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a?source=collection_archive---------5-----------------------#2023-12-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/implementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a?source=collection_archive---------5-----------------------#2023-12-27](https://towardsdatascience.com/implementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a?source=collection_archive---------5-----------------------#2023-12-27)
- en: How to formally verify the bounds of your Neural Network
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何正式验证你的神经网络的边界
- en: '[](https://medium.com/@mattdaw7?source=post_page-----379ea359c41a--------------------------------)[![Matthew
    Daw](../Images/a515428ae9b984c45111d6e868efd55b.png)](https://medium.com/@mattdaw7?source=post_page-----379ea359c41a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----379ea359c41a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----379ea359c41a--------------------------------)
    [Matthew Daw](https://medium.com/@mattdaw7?source=post_page-----379ea359c41a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mattdaw7?source=post_page-----379ea359c41a--------------------------------)[![Matthew
    Daw](../Images/a515428ae9b984c45111d6e868efd55b.png)](https://medium.com/@mattdaw7?source=post_page-----379ea359c41a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----379ea359c41a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----379ea359c41a--------------------------------)
    [Matthew Daw](https://medium.com/@mattdaw7?source=post_page-----379ea359c41a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3a94e02b6ee1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a&user=Matthew+Daw&userId=3a94e02b6ee1&source=post_page-3a94e02b6ee1----379ea359c41a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----379ea359c41a--------------------------------)
    ·17 min read·Dec 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F379ea359c41a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a&user=Matthew+Daw&userId=3a94e02b6ee1&source=-----379ea359c41a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3a94e02b6ee1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a&user=Matthew+Daw&userId=3a94e02b6ee1&source=post_page-3a94e02b6ee1----379ea359c41a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----379ea359c41a--------------------------------)
    ·17分钟阅读·2023年12月27日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F379ea359c41a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a&source=-----379ea359c41a---------------------bookmark_footer-----------)![](../Images/55ccc3b29cd5e6f88d0263addd4b6c1f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F379ea359c41a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplementation-details-of-reluplex-an-efficient-smt-solver-for-verifying-deep-neural-networks-379ea359c41a&source=-----379ea359c41a---------------------bookmark_footer-----------)![](../Images/55ccc3b29cd5e6f88d0263addd4b6c1f.png)'
- en: Photo by [NEOM](https://unsplash.com/@neom?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [NEOM](https://unsplash.com/@neom?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Reluplex is an algorithm submitted to CAV in 2017 by Stanford University [1].
    Reluplex was designed to formally verify if a nerual network is capable of producing
    certain outputs given certain inputs. It accepts as input a neural network and
    a set of constraints on the inputs and outputs of the network. The bounds may
    restrict any arbitrary number of input or output nodes to a single value or a
    range of values. The algorithm then finds an input within the given input bounds
    that can produce an output within the given output bounds. If no example exists,
    it will determine that the problem is infeasible in a reasonable amount of time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Reluplex是斯坦福大学于2017年提交到CAV的一个算法 [1]。Reluplex旨在正式验证神经网络是否能够在给定某些输入的情况下生成特定的输出。它接受一个神经网络及对网络输入和输出的约束作为输入。这些约束可以将任意数量的输入或输出节点限制为一个值或一个值的范围。然后，算法在给定的输入约束范围内找到一个输入，该输入可以产生给定的输出约束范围内的输出。如果不存在这样的例子，它将判断该问题在合理的时间内不可行。
- en: Algorithm Uses
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法用途
- en: The original algorithm was written to help build the “Airborne Collision-Avoidance
    System for drone” system. This system uses 45 deep learning networks to fly a
    series of drones. The researches needed a way to formally guarantee that regardless
    of what other inputs their networks are receiving, if two drones are too close
    to each other they will always fly away from each other and never crash. In the
    most extreme case, the algorithm was able to complete these verifications within
    109.6 hours, which while a long time, is still an order of magnitude faster than
    the previous state of the art algorithm.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 原始算法是为构建“无人机空中碰撞避免系统”而编写的。该系统使用45个深度学习网络来飞行一系列无人机。研究人员需要一种方法来正式保证，无论网络接收到什么其他输入，如果两架无人机太接近，它们将总是远离对方飞行而不会发生碰撞。在最极端的情况下，该算法能够在109.6小时内完成这些验证，虽然时间较长，但仍比之前的最先进算法快一个数量级。
- en: '![](../Images/5829c227dd8ce557078f885d0549a649.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5829c227dd8ce557078f885d0549a649.png)'
- en: Colision course avoidance, image from original paper[1]
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 碰撞航线规避，图像来自原始论文 [1]
- en: In a more recent publication, ReluPlex has been made obsolute by a tool called
    Marabou [4] which does everything ReluPlex does but better. This has been used
    for neural network explainability. The algorithm works by finding an upper bound
    and a lower bound for the for what parts of the input are strictly necessary to
    produce output that a network generates. [6]
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近的出版物中，ReluPlex被一个名为Marabou的工具所取代 [4]，Marabou能够比ReluPlex做得更好。这一工具用于神经网络的可解释性。该算法通过寻找输入的上界和下界来确定生成网络输出所必需的输入部分。[6]
- en: '![](../Images/f21e4bbd4dc66cbd9d57aa8dfa81142f.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f21e4bbd4dc66cbd9d57aa8dfa81142f.png)'
- en: Example of a neural network explanation, from Towards Formal XAI [6]
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络解释的例子，来源于《Towards Formal XAI》 [6]
- en: The algorithm has also been used to set precise bounds on what adversarial perturbations
    are large enough to change the output of a network.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法还被用于设定精确的界限，以确定什么样的对抗性扰动足够大，能够改变网络的输出。
- en: For this paper, we wish to discuss the details for Reluplex as they do form
    an important foundation for being able to understand Maribou.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们希望讨论Reluplex的详细信息，因为它们构成了理解Maribou的重要基础。
- en: '**Basic Neural Network**'
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**基本神经网络**'
- en: 'Before explaining the details of this algorithm, we first need to cover some
    basics of neural networks. Here is a simple diagram of a network:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释该算法的详细信息之前，我们首先需要了解一些神经网络的基础知识。以下是一个简单的网络图：
- en: '![](../Images/b99cd5ef4fde6fc6388ea27048de7578.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b99cd5ef4fde6fc6388ea27048de7578.png)'
- en: Diagram of a basic perceptron Neural Network [8]
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 基本感知机神经网络的图示 [8]
- en: 'In the diagram above, the hidden layer is calculated by multiplying all of
    the nodes in a previous layer by specific values, then adding them together, and
    then adding a bias term that is specific to each node to this sum. The summed
    value then goes through an activation function f before being used in the next
    layer. The activation function we will be using in this article is the ReLU function
    which is defined as f(x) = x if x > 0 else 0:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，隐藏层的计算方式是将前一层的所有节点乘以特定的值，然后将它们相加，再加上一个对每个节点特定的偏置项。然后，求和值通过一个激活函数 f，再用于下一层。我们将在本文中使用的激活函数是ReLU函数，其定义为
    f(x) = x 如果 x > 0 否则为 0：
- en: '![](../Images/52ce28ff62bbab7842fd509e9a7e0af6.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52ce28ff62bbab7842fd509e9a7e0af6.png)'
- en: Example of ReLU function. Image based off Deep Learning using Rectified Linear
    Units [2]
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU函数的例子。图像来源于《Deep Learning using Rectified Linear Units》 [2]
- en: '**High Level View Of Reluplex**'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**Reluplex 的高级视角**'
- en: What reluplex does is it tries to put a neural network into a simplex problem.
    Once constraints are set inside of a simplex problem, it is guaranteed to be able
    to find a solution quickly or determine if there is no valid point given the constraints.
    It is also an algorithm that has proven to be exceptionally efficient at doing
    this, and there are reputable formal proofs that guarantee it will work every
    single time. This is exactly what we want for our reluplex problem. The only problem
    is that reluplex can only work with linear constraints, and the relu funtions
    in our neural network are non-linear and can not be directly put into the simplex
    method. To make it linear we must choose to impose additional constraints that
    either the input to the relu must be non-positive and make the relu inactive,
    or the input of the relu must be constrained to be non-negative making the relu
    function active. By default, most SMT solvers would get around this by manually
    checking every possible combination of constraint. However, in a network with
    300 plus relu functions this can turn into 2³⁰⁰ case splits which is impracticably
    slow to solve. What reluplex does then is it first encodes everything it can about
    a network without the reluconstraints and finds a feasible point. If a feasible
    point exists, it will then fix the parts of a network that violate the relu constraint
    one at a time. If a specific node is updated too many times will split the problem
    into one case where that node is always active and another case where it’s always
    inactive then continue the search. The original authors of the paper are able
    to formally prove that this algorithm is sound and complete and will terminate
    in a finite amount of steps. They also empirically show that it terminates much
    faster than a simple brute force approach of checking every single possible case.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: reluplex 的作用是尝试将神经网络转化为一个简单形问题。一旦在简单形问题中设置了约束，它就能快速找到解决方案或确定在给定约束下是否没有有效解。它还是一个经过证明的非常高效的算法，并且有权威的形式证明保证它每次都能有效。这正是我们对
    reluplex 问题的期望。唯一的问题是 reluplex 只能处理线性约束，而我们神经网络中的 relu 函数是非线性的，不能直接用于简单形方法。为了使其线性化，我们必须选择施加额外的约束，要么使
    relu 的输入必须是非正的，使 relu 失效，或者将 relu 的输入约束为非负的，使 relu 函数有效。默认情况下，大多数 SMT 求解器会通过手动检查每种可能的约束组合来绕过这个问题。然而，在一个包含300多个
    relu 函数的网络中，这可能会转化为 2³⁰⁰ 种情况拆分，这在解决时速度过于缓慢。那么，reluplex 的做法是，首先对一个没有 relu 约束的网络进行编码，并找到一个可行的点。如果存在可行点，它将逐一修复违反
    relu 约束的网络部分。如果一个特定节点更新过多次，会将问题拆分为一个该节点始终有效的情况和一个该节点始终无效的情况，然后继续搜索。原始论文的作者能够形式上证明这个算法是健全且完整的，并且会在有限的步骤内终止。他们还通过实证方法显示它比逐一检查每个可能情况的简单暴力方法终止得更快。
- en: '**Purpose Of This Article**'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**本文的目的**'
- en: The original paper gives a good example of the algorithm actually works. However,
    they assume the reader has a deep understanding of how the simplex method works
    and they skip over some important design choices that have to be made. The purpose
    of this article then is to carefully lay out the exact steps the algorithm uses
    with all the details of how the simplex method works. We also provide a simplified
    and working implementation of the algorithm in python. The original paper provides
    formal proofs to guarantee that as long as the simplex method works, reluplex
    will work. There is also a relatively large body of publications that prove that
    reluplex works. As such, we do not provide any formal justification on why this
    algorithm works. We simply wish to explain the steps needed for the algorithm,
    and give an intuition of why the authors choose those steps. Deeply understanding
    this algorithm may require reading the original reluplex paper or studying the
    simplex method.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 原始论文给出了算法实际工作的一个很好的示例。然而，他们假设读者对简单形方法有深入理解，并跳过了一些必须做出的重要设计选择。因此，本文的目的是详细列出算法使用的确切步骤，以及简单形方法的所有细节。我们还提供了一个简化且有效的
    Python 实现。原始论文提供了形式证明，保证只要简单形方法有效，reluplex 就会有效。同时，还有相对大量的出版物证明了 reluplex 的有效性。因此，我们不提供关于此算法有效性的正式论证。我们只是希望解释算法所需的步骤，并提供作者选择这些步骤的直观理解。深入理解这个算法可能需要阅读原始的
    reluplex 论文或研究简单形方法。
- en: '**The Simplex Method**'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**简单形方法**'
- en: The simplex method is designed to address optimization problems within a defined
    linear space. These problems involve a set of non-negative variables, the introduction
    of constraints on those variables, and the declaration of an objective function.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 单纯形法旨在解决定义线性空间内的优化问题。这些问题涉及一组非负变量，对这些变量施加约束，并声明一个目标函数。
- en: '![](../Images/2323eaadd734fb926fdadcc75d191469.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2323eaadd734fb926fdadcc75d191469.png)'
- en: Image by the author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: After establishing these constraints, the simplex method initially verifies
    the existence of a point that satisfies the specified constraints. Upon identifying
    such a point, the method proceeds to find the point that maximizes the objective
    within the given constraints.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立这些约束条件后，单纯形法最初会验证是否存在满足指定约束条件的点。确定了这样的点后，该方法会继续寻找在给定约束条件下最大化目标的点。
- en: '**A Full Example Of Reluplex**'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**Reluplex 的完整示例**'
- en: The following is a basic neural network we will be using to demonstrate the
    full algorithm.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将用于演示完整算法的基本神经网络。
- en: '![](../Images/16425f50034719c9427e9ed2713622dc.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16425f50034719c9427e9ed2713622dc.png)'
- en: Image by the author
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The first thing we need to do is break the hidden layer nodes, one node will
    be a linear function of the previous nodes, and the other node will a ReLU of
    the output of that linear function.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是分解隐藏层节点，一个节点将是前一节点的线性函数，另一个节点将是该线性函数输出的 ReLU。
- en: '![](../Images/92beee8d84accced9c61a9c0d0b6cdb6.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92beee8d84accced9c61a9c0d0b6cdb6.png)'
- en: Image by the author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Now we declare the following bounds on our function input and output:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们声明对函数输入和输出的以下边界：
- en: '![](../Images/5776c7cf747c44731fcd350ffbd03e02.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5776c7cf747c44731fcd350ffbd03e02.png)'
- en: Image by the author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Given the model setup and declared constraints, our objective is to transform
    this problem into a simplex problem. Since the simplex method is limited to linear
    operations, directly incorporating a ReLU constraint into the setup is not feasible.
    However, we can introduce constraints for all other components of the network.
    If a solution is feasible without the ReLU constraints, we can systematically
    add these constraints one by one until we either discover a feasible solution
    or establish that the ReLU constraints render the problem impossible. Therefore,
    by encoding the applicable constraints, we now have the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型设置和声明的约束，我们的目标是将此问题转化为单纯形问题。由于单纯形法仅限于线性操作，直接将 ReLU 约束纳入设置是不切实际的。然而，我们可以为网络的所有其他组件引入约束。如果在没有
    ReLU 约束的情况下得到的解是可行的，我们可以逐步添加这些约束，直到发现一个可行解或确定 ReLU 约束使问题变得不可解。因此，通过编码适用的约束，我们现在有如下内容：
- en: '![](../Images/6580800c9016fbe1be00c5b57d0a25bd.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6580800c9016fbe1be00c5b57d0a25bd.png)'
- en: Image by the author
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'To incorporate these constraints into the simplex method, we need to convert
    them to standard form. In standard form, all non-constant variables are on the
    left-hand side, and all constants are on the right, with the constants being positive.
    Upon rewriting, we obtain the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这些约束纳入单纯形法，我们需要将它们转换为标准形式。在标准形式中，所有非恒定变量都位于左侧，而所有常量都位于右侧，并且常量为正数。重写后，我们得到如下内容：
- en: '![](../Images/eca382aef9a42d5d55012aca36d98c33.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eca382aef9a42d5d55012aca36d98c33.png)'
- en: Image by the author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Setting Up The Simplex Tableau
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置单纯形表
- en: The subsequent step involves converting all inequalities into equality constraints.
    To achieve this, we will introduce slack variables. These variables are inherently
    non-negative and can assume arbitrarily large values. Additionally, they ensure
    that our new equality constraints are mathematically equivalent to our original
    inequality constraints.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 随后的步骤涉及将所有不等式转换为等式约束。为此，我们将引入松弛变量。这些变量本质上是非负的，并且可以取任意大的值。此外，它们确保我们的新等式约束在数学上等价于原始的不等式约束。
- en: '![](../Images/97efa385f656b40b52b20a2e4db3fe91.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97efa385f656b40b52b20a2e4db3fe91.png)'
- en: Image by the author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'Currently, the simplex method inherently accommodates only non-negative variables.
    However, the nodes in our network might not adhere to this non-negativity constraint.
    To accommodate negative values, we must substitute variables that can be either
    positive or negative with separate positive and negative variables, as illustrated
    below:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，单纯形方法固有地只适用于非负变量。然而，我们网络中的节点可能不符合这个非负性约束。为了适应负值，我们必须用分别表示正值和负值的变量替换可以是正值或负值的变量，如下所示：
- en: '![](../Images/5e863c8f51ba3cf4c7c5b1b417c3292e.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e863c8f51ba3cf4c7c5b1b417c3292e.png)'
- en: Image by the author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: With this substitution, x_{+i} and x_{-i} can always be positive values but
    still combine together to make x_i to be negative. x_4 and x_5 come after a ReLU
    and as such are always non-negative and don’t need this substitution. However,
    all the other neural network node variables do. Doing these substitutions, we
    now have the following set of constraints.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个替换，x_{+i} 和 x_{-i} 可以始终是正值，但仍然组合起来使 x_i 为负值。x_4 和 x_5 出现在 ReLU 之后，因此总是非负的，不需要这个替换。然而，所有其他神经网络节点变量都需要这个替换。进行这些替换后，我们现在有以下约束集。
- en: '![](../Images/c2bc3929cab3e2ea546ec130fbd2044d.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2bc3929cab3e2ea546ec130fbd2044d.png)'
- en: Image by the author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Distributing the negatives and removing the parenthesis we have the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 分配负值并去掉括号后，我们得到如下：
- en: '![](../Images/7259ec8c76733871374652ab46613283.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7259ec8c76733871374652ab46613283.png)'
- en: Image by the author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Now that we have separated variables into positive and negative parts, we need
    to take a small step back and remember that after we solve for this system of
    equations we will be needing to be making adjustments to fix the ReLU violations.
    To help make fixing ReLU violations easier, we are ready to introduce a new linear
    constraint. The constraint constraints we wish to add are setting x_{+2} = x_4
    and x_{+3} = x_5\. This will make it possible for both i in {2,3}, x_{+i} and
    x_{-i} may both me non-negative and when that happens the ReLU constraint will
    not be held. However, fixing the ReLU constraint will become as easy as adding
    a constraint to either make x_{+i} or x_{-i} equal zero. The problem can proceed
    without this constraint and it is not actually needed. In fact, the original paper
    does not actually use, yet, I include in this pose as I did imperially find it
    does make the faster because it limits the search space. This will result in the
    following new set of constraints.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将变量分为正值和负值部分，我们需要稍微退一步并记住，在我们解决这个方程组之后，我们需要进行调整以修正 ReLU 违规。为了帮助修复 ReLU
    违规，我们准备引入一个新的线性约束。我们希望添加的约束是设置 x_{+2} = x_4 和 x_{+3} = x_5。这将使得对所有 i 属于 {2,3}，x_{+i}
    和 x_{-i} 都可以是非负的，但当发生这种情况时，ReLU 约束将不再成立。然而，修正 ReLU 约束将变得像添加一个约束使 x_{+i} 或 x_{-i}
    等于零一样简单。这个问题可以在没有这个约束的情况下继续进行，它实际上并不是必须的。事实上，原始论文实际上并没有使用这个约束，但我包括它是因为我发现它确实使速度更快，因为它限制了搜索空间。这将导致以下新的约束集。
- en: '![](../Images/e40f75d13fdb028c9ba55be202df52ed.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e40f75d13fdb028c9ba55be202df52ed.png)'
- en: Image by the author
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The clutter of having so many different variables around can make it hard to
    tell what’s going on. As such, we’ll rewrite everything into a tableau matrix.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 变量太多可能会导致混乱，使得很难看清楚发生了什么。因此，我们将所有内容重新写入一个表格矩阵中。
- en: '![](../Images/363cc13b4412db78c95731924a45b37a.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/363cc13b4412db78c95731924a45b37a.png)'
- en: Image by the author
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Solving The Primal Problem
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 求解原始问题
- en: Now that we’ve transformed our problem into a tableau matrix, we will use the
    two-phase method to solve this setup. The first phase involves finding a feasible
    point, while the second phase moves the feasible point to maximize a specific
    utility function. However, for our specific use case, we don’t have a utility
    function; our goal is solely to determine the existence of a feasible point. Consequently,
    we will only execute the first phase of the two-phase method.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将问题转换为表格矩阵，我们将使用两阶段法来解决这个设置。第一阶段涉及找到一个可行点，而第二阶段则将可行点移动以最大化特定的效用函数。然而，对于我们的特定用例，我们没有效用函数；我们的目标仅仅是确定是否存在一个可行点。因此，我们只会执行两阶段法的第一阶段。
- en: To identify a feasible point, the simplex method initially checks if setting
    all slack variables to the right-hand side and all other variables to zero is
    feasible. In our case, this approach is not viable due to non-zero equality constraints
    lacking a slack variable. Additionally, on lines 5 and 7, the slack variable is
    multiplied by a negative number, making it impossible for the expression to evaluate
    to positive right-hand sides, as slack variables are always positive. Therefore,
    to obtain an initial feasible point, we will introduce new auxiliary variables
    assigned to be equal to the right-hand side, setting all other variables to zero.
    This won’t be done for constraints with positive signed slack variables, as those
    slack variables may already equal the right-hand side. To enhance clarity, we
    will have the column on the left indicating which variables are assigned a non-zero
    value; these are referred to as our basic variables.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别一个可行点，单纯形法最初检查将所有松弛变量设置为右侧，将所有其他变量设置为零是否可行。在我们的情况下，这种方法不可行，因为没有松弛变量的非零等式约束。此外，在第
    5 行和第 7 行，松弛变量乘以负数，使得表达式不可能评估为正的右侧，因为松弛变量始终为正。因此，为了获得初始可行点，我们将引入新的辅助变量，并将其设置为等于右侧，将所有其他变量设为零。对于具有正符号松弛变量的约束，将不会这样做，因为这些松弛变量可能已经等于右侧。为了提高清晰度，我们将左侧的列标明哪些变量被分配了非零值；这些被称为我们的基本变量。
- en: '![](../Images/e3664bada2597bac1e24c6f4b4a20fde.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3664bada2597bac1e24c6f4b4a20fde.png)'
- en: Image by the author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Our feasible point then is
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的可行点是
- en: '![](../Images/9d5117c9e6bbc52bf04bbd376a93152d.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d5117c9e6bbc52bf04bbd376a93152d.png)'
- en: Image by the author
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Now we have a point that we know is feasible. However, it is important to recognize
    that these auxiliary variables alter the solution, and in order to arrive at our
    desired true solution we need to eliminate them. To eliminate them, we will introduce
    an objective function to set them to zero. Specifically, we aim to minimize the
    function. a1 + a2 + a3 + a4 + a5 + a6 + a7\. If we successfully minimize this
    function to zero, we can conclude that our original set of equations has a feasible
    point. However, if we are unable to achieve this, it indicates that there is no
    feasible point, allowing us to terminate the problem and declair the inputs and
    outputs infeasible.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个已知可行的点。然而，重要的是要认识到这些辅助变量改变了解，为了得到我们想要的真实解，我们需要消除它们。为了消除它们，我们将引入一个目标函数将它们设为零。具体来说，我们的目标是最小化函数
    a1 + a2 + a3 + a4 + a5 + a6 + a7。如果我们成功将这个函数最小化为零，我们可以得出结论，原始方程组有一个可行点。然而，如果我们无法实现这一点，则表明没有可行点，我们可以终止问题并声明输入和输出不可行。
- en: 'With the tableau and objective function declared, we are prepared to execute
    the pivots necessary to optimize our objective. The steps for doing which are
    as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在表格和目标函数声明后，我们准备执行优化目标所需的主元操作。具体步骤如下：
- en: Replace basic variables in objective function with non-basic variables. In this
    case, all the auxiliary variables are basic variables. To replace them, we pivot
    on all of the auxiliary columns and the rows that have a non-zero value entry
    for the basic variable. A pivot is done by adding or subtracting from the pivot
    row to all other rows until the only non-zero entry in the pivot column is the
    entry in the pivot row.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用非基本变量替换目标函数中的基本变量。在这种情况下，所有辅助变量都是基本变量。为了替换它们，我们对所有辅助列和基本变量有非零值条目的行进行主元操作。主元操作是通过从主元行中添加或减去所有其他行，直到主元列中唯一的非零条目是主元行中的条目。
- en: Select a pivot column by finding the column with the first and largest value
    in the objective function.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在目标函数中找到第一个且最大的值的列来选择主元列。
- en: Select a pivot row by using bland’s rule. Bland’s rule identifies all positive
    entries in our column, divide the objective by those entries, and choose the row
    that yields the smallest value.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用布兰德规则选择主元行。布兰德规则识别我们列中的所有正条目，将目标函数除以这些条目，并选择产生最小值的行。
- en: Repeat steps 2 and 3 until all entries in the objective function are non-positive.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤 2 和 3，直到目标函数中的所有条目都为非正值。
- en: Once this done, we will have the following new tableau.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，我们将得到以下新的表格。
- en: '![](../Images/7c00900c9fd660638e5bc2f391f80985.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c00900c9fd660638e5bc2f391f80985.png)'
- en: Image by the author
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: From this, we arrive at the point
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从中，我们得出点
- en: '![](../Images/d083350a5a3acb3ad5c12480121f6885.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d083350a5a3acb3ad5c12480121f6885.png)'
- en: Image by the author
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'We have successfully adjusted all of the auxiliary variables to equal zero.
    We also have pivoted away from them to make them all non-basic. Also, we will
    note that these values do indeed satisfy our initial linear constraints. As such,
    we no longer need the auxiliary variables and may remove them from our set of
    linear equations. If we collapse the positive and negative variables and remove
    the auxiliary variables we have this new point:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功将所有辅助变量调整为零。我们还将它们移到非基本变量中。此外，我们会注意到这些值确实满足了我们最初的线性约束。因此，我们不再需要辅助变量，可以将它们从线性方程组中移除。如果我们合并正负变量并移除辅助变量，我们会得到这个新点：
- en: '![](../Images/ef388334b834f9fed732d30993acab8b.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef388334b834f9fed732d30993acab8b.png)'
- en: Image by the author
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: Relu Fix Search Procedure
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Relu 修复搜索程序
- en: By adding the constraints x_{+2} = x_4 and x_{+3} = x_5 we make it possible
    for both x_{+2} and x_{-2} to both be non-zero (same applies for x_{+3} and x_{-3}
    ). As can be seen above, both x_{+2} and x_{-2} are non-zero and relu(x_2) does
    not equal x_4\. To fix the ReLU, there is no way to directly constrain simplex
    to either have x_{+2} or x_{-2} be zero, we must choose one case and create a
    constraint for that case. Choosing between these two cases is equivalent to deciding
    whether the ReLU will be in an active or inactive state. In the original paper,
    the authors address ReLU violations by assigning one side to equal the value of
    the other side at that specific moment. We believe this approach overly constrains
    the problem. That is because limiting the ReLU to a specific value and necessitating
    potentially an infinite number of configurations to check. Our solution, on the
    other hand, constrains the ReLU to be either active or inactive. Consequently,
    we only need to check these situations to cover the space of all allowable configurations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加约束 x_{+2} = x_4 和 x_{+3} = x_5，我们使得 x_{+2} 和 x_{-2} 都可以是非零的（x_{+3} 和 x_{-3}
    同样适用）。如上所示，x_{+2} 和 x_{-2} 都是非零的，且 relu(x_2) 不等于 x_4。要修复 ReLU，没有办法直接约束单纯形使 x_{+2}
    或 x_{-2} 为零，我们必须选择一种情况并为该情况创建约束。在这两种情况下选择相当于决定 ReLU 是否处于激活状态。原论文中，作者通过在特定时刻将一侧的值赋给另一侧来处理
    ReLU 违规情况。我们认为这种方法对问题的约束过于严苛，因为将 ReLU 限定为一个特定值并需要检查可能无数的配置。我们的解决方案则将 ReLU 限制为激活或不激活。因此，我们只需检查这些情况以涵盖所有允许的配置。
- en: As we need to decide whether the ReLU constraints are active or inactive, and
    with 2 to the n valid constraints to set, manually examining all possible configurations
    in a large network becomes impractical.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们需要决定 ReLU 约束是否处于激活或非激活状态，并且需要设置 2 的 n 次方个有效约束，在大型网络中手动检查所有可能的配置变得不切实际。
- en: 'The authors of Reluplex propose addressing violations by attempting to solve
    them one ReLU fix at a time. They iteratively add one constraint to fix one specific
    violation, update the tableau to accomodate the new constraint, remove the constraint,
    then repeat for all other or new violations. Because only one constraint is ever
    in place it is possible that updating one ReLU fix can break one in another place
    that was already fixed. This can lead to a cycle of repeatedly fixing the same
    ReLU constraints. To get around this, if a ReLU node is updated five times, a
    “ReLU split” is executed. This split divides the problem into two cases: in one,
    they enforce that the negative side of the variable is zero, and in the other,
    the positive side is set to zero. Importantly, the constraint is never removed
    in either case, ensuring that the particular ReLU will never need fixing again.
    This allows the algorithm to only split on particularly “problematic” ReLU nodes,
    and empirical evidence shows that typically only about 10% of ReLUs need to split.
    Consequently, although some fixing operations may be repeated, the overall procedure
    remains faster than a simple brute-force check for every possibility.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Reluplex 的作者建议通过尝试逐一解决每个 ReLU 问题来应对违反情况。他们迭代地添加一个约束以解决一个特定的违规问题，更新表格以适应新约束，移除约束，然后对所有其他或新的违规情况重复这一过程。由于每次只存在一个约束，因此更新一个
    ReLU 修复可能会破坏已经修复的另一个地方的 ReLU。这可能导致重复修复相同的 ReLU 约束的循环。为了绕过这一点，如果一个 ReLU 节点被更新了五次，则会执行“ReLU
    拆分”。该拆分将问题分成两个情况：在一个情况中，他们强制变量的负侧为零，而在另一个情况下，正侧被设置为零。重要的是，无论哪种情况，约束都不会被移除，确保该
    ReLU 不会再需要修复。这允许算法仅在特别“问题” ReLU 节点上进行拆分，实证证据显示，通常只有大约 10% 的 ReLU 需要拆分。因此，尽管某些修复操作可能会重复，但总体过程仍然比简单的暴力检查每一种可能性更快。
- en: Adding Constraint To Fix Relu
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加约束以修复 ReLU
- en: To address the ReLU violation, we need to constrain either x_{+2} or x_{-2}
    to be zero. To maintain a systematic approach, we will consistently attempt to
    set the positive variable to zero first. If that proves infeasible, we will then
    set the negative side to zero.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理 ReLU 违规，我们需要将 x_{+2} 或 x_{-2} 约束为零。为了保持系统化的方法，我们将始终尝试首先将正变量设置为零。如果这证明不可行，我们将把负侧设置为零。
- en: 'Introducing a new constraint involves adding a new auxiliary variable. If we
    add this variable and impose a constraint to set x_{+2}=0, the tableau is transformed
    as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 引入一个新约束涉及添加一个新的辅助变量。如果我们添加这个变量并施加约束使得 x_{+2}=0，表格将被转化如下：
- en: '![](../Images/5d24177e449c1eae83366b2b5c3bfd49.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d24177e449c1eae83366b2b5c3bfd49.png)'
- en: Image by the author
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'x_{+2} functions as a basic variable and appears in two distinct rows. This
    contradicts one of the assumptions necessary for the simplex method to function
    properly. Consequently, a quick pivot on (x_{+2}, x_{+2}) is necessary to rectify
    this issue. Executing this pivot yields the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: x_{+2} 作为基本变量，出现在两个不同的行中。这与单纯形方法正常运行所需的假设之一相矛盾。因此，有必要快速执行 (x_{+2}, x_{+2}) 的枢轴操作以解决此问题。执行此枢轴操作会产生如下结果：
- en: '![](../Images/f413b001620597e321747d60712f7ea9.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f413b001620597e321747d60712f7ea9.png)'
- en: Image by the author
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Solving The Dual Problem
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决对偶问题
- en: In the previous step, we applied the two-phase method to solve the last tableau.
    This method involves introducing artificial variables until a guaranteed trivial
    initial point is established. Subsequently, it pivots from one feasible point
    to another until an optimal solution is attained. However, instead of continuing
    with the two-phase method for this tableau, we will employ the dual simplex method.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一步中，我们应用了两阶段法来解决最后的表格。这种方法涉及引入人工变量，直到建立一个保证的平凡初始点。随后，它从一个可行点枢轴到另一个点，直到获得最优解。然而，我们将采用对偶单纯形法，而不是继续对这个表格使用两阶段法。
- en: 'The dual simplex method initiates by identifying a point that is optimally
    positioned beyond the given constraints, often referred to as a super-optimal
    point. It then progresses from one super-optimal point to another until it reaches
    a feasible point. Once a feasible point is reached, it is ensured to be the global
    optimal point. This method suits our current scenario as it enables us to add
    a constraint to our already solved tableau without the need to solve a primal
    problem. Given that we lack an inherent objective function, we will arbitrarily
    assign an objective function as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 双重单纯形法的起始步骤是识别一个超越给定约束的最优位置点，通常称为超级最优点。然后，它从一个超级最优点移动到另一个，直到达到一个可行点。一旦达到可行点，即可确保它是全局最优点。这种方法适合我们当前的情境，因为它允许我们在已经解决的表格中添加一个约束，而无需解决一个原始问题。鉴于我们缺乏固有的目标函数，我们将任意指定一个目标函数如下：
- en: '![](../Images/df784b9a7d64bd38a91013e9132b1ee0.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df784b9a7d64bd38a91013e9132b1ee0.png)'
- en: Image by the author
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'Solving the Primal Problem typically involves transposing the matrix and replacing
    the objective function values with the right-hand side values. However, in this
    case, we can directly solve it using the tableau we’ve already set up. The process
    is as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 解决原始问题通常涉及转置矩阵并用右侧值替换目标函数值。然而，在这种情况下，我们可以直接使用已经设置好的表格进行解决。过程如下：
- en: '![](../Images/e4f2710dac90af5d65a23c1b77d11d84.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4f2710dac90af5d65a23c1b77d11d84.png)'
- en: Image by the author
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Applying this procedure to the problem we’ve established will reveal its infeasibility.
    This aligns with expectations since setting x_{+3} to zero would necessitate setting
    x_{+1}-x_{-1} or x_1 to 0.4 or lower, falling below the lower bound constraint
    of 0.5 we initially imposed on x_1.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 将此过程应用于我们已建立的问题将揭示其不可行性。这与预期一致，因为将 x_{+3} 设为零将需要将 x_{+1}-x_{-1} 或 x_1 设为 0.4
    或更低，低于我们最初对 x_1 施加的 0.5 的下限约束。
- en: Setting x_{-1}=0
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 x_{-1}=0
- en: 'Since setting x_{+1}=0 failed, we move on to trying to set x_{-1}=0\. This
    actually will succeed and result in the following completed tableau:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于设置 x_{+1}=0 失败，我们继续尝试设置 x_{-1}=0。实际上，这将成功并得到以下完成的表格：
- en: '![](../Images/46e5c92b8f78826bf10272ee56706024.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46e5c92b8f78826bf10272ee56706024.png)'
- en: Image by the author
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'From this, we have the new solution point:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 从中，我们得到新的解点：
- en: '![](../Images/fe903d2bdb884a952f766107230c6d36.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe903d2bdb884a952f766107230c6d36.png)'
- en: Image by the author
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'Which if we collapse becomes:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将其合并，变成：
- en: '![](../Images/4acdfaeb57f40726f3a6d1922d81a045.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4acdfaeb57f40726f3a6d1922d81a045.png)'
- en: Image by the author
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Now that we have successfully made x_4 = relu(x_2) , we must remove the temporary
    constraint before we continuing.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已成功使 x_4 = relu(x_2)，我们必须在继续之前移除临时约束。
- en: Removing The Temporary ReLU Constraint
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移除临时 ReLU 约束
- en: 'To lift the constraint, a pivot operation is required to explicitly state the
    constraint within a single row. This can be achieved by pivoting on our new a_1
    column. Following Bland’s rule for selecting the pivot row, we identify all positive
    entries in our column, divide the objective by those entries, and choose the row
    that yields the smallest value. In this instance, the x_{-2} row emerges as the
    optimal choice since 0/1=0 is smaller than all other candidates. After performing
    the pivot, the resulting tableau is as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高约束，需要一个主元操作来明确在单行中陈述约束。这可以通过以新的 a_1 列作为主元来实现。按照布兰德规则选择主元行，我们识别出我们列中的所有正值，将目标函数值除以这些值，并选择最小值的行。在这种情况下，x_{-2}
    行成为最佳选择，因为 0/1=0 小于所有其他候选值。执行主元操作后的结果表格如下：
- en: '![](../Images/f44c851472476ffa15cf81dba409f949.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f44c851472476ffa15cf81dba409f949.png)'
- en: Image by the author
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'It’s important to observe that none of the variable values have been altered.
    We can now confidently eliminate both the a_1 row and a_1 column from the tableau.
    This action effectively removes the constraint x_{-2}=0, resulting in the following
    updated tableau:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '需要注意的是，没有任何变量值被改变。我们现在可以自信地从表格中删除 a_1 行和 a_1 列。这一操作有效地移除了约束 x_{-2}=0， resulting
    in the following updated tableau:'
- en: '![](../Images/0bea79ee5d711b3538c624ea1f5cde84.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0bea79ee5d711b3538c624ea1f5cde84.png)'
- en: Image by the author
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Continuing to Relu Split
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 继续进行 Relu 分裂
- en: 'As evident, we successfully addressed the ReLU violation, achieving the desired
    outcome of x_4 = ReLU(x_2). However, a new violation arises as x_5 does not equal
    ReLU(x_3). To fix this new violation, we follow the exact same procedure we used
    to fix the x_4 does not equal ReLU(x_2) violation. Once this is done though, we
    find that the tableau reverts to its state before we fixed x_4 = ReLU(x_2). If
    we continue, we will cycle between fixing x_4 = ReLU(x_2) and x_5 = ReLU(x_3)
    until we have updated one of these enough for a ReLU split to be triggered. This
    split creates two tableaus: one where x_{+2}=0 (shown to be infeasible) and another
    where x_{-2}=0, resulting in a tableau we have encountered before.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见，我们成功解决了ReLU违例，实现了x_4 = ReLU(x_2)的预期结果。然而，新的违例出现了，因为x_5不等于ReLU(x_3)。为了解决这个新违例，我们遵循与修复x_4不等于ReLU(x_2)违例时完全相同的程序。不过，一旦完成，我们发现表格恢复到修复x_4
    = ReLU(x_2)之前的状态。如果继续下去，我们将不断循环修复x_4 = ReLU(x_2)和x_5 = ReLU(x_3)，直到其中一个被更新足够以触发ReLU拆分。这个拆分创建了两个表格：一个是x_{+2}=0（已显示为不可行），另一个是x_{-2}=0，结果是我们之前遇到过的表格。
- en: '![](../Images/e6c29f05e05ffc320b78ed3753b36dac.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6c29f05e05ffc320b78ed3753b36dac.png)'
- en: Image by the author
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'This time though, we normally will split the problem into two cases, one where
    x_{-2}=0 and another where x_{+2}=0\. However, we already determined that x_{+2}=0
    is infeasible so we terminate that problem. Nowe just need to determine if x_{-2}=0
    is infeasible then we’ll be done. We proceed now with x_{-2}=0 permanently encoded
    int he tableu. We now try to fix the x_{+3}=0 constraint. Once we go through the
    exact same method, we will be successful and result in the following values:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 不过这次，我们通常会将问题分为两种情况，一种是x_{-2}=0，另一种是x_{+2}=0。然而，我们已经确定x_{+2}=0是不可能的，因此我们终止了那个问题。现在我们只需要确定x_{-2}=0是否不可行，如果是，我们就完成了。我们现在继续处理x_{-2}=0，永久编码到表格中。接下来我们尝试修复x_{+3}=0的约束。一旦我们用完全相同的方法进行处理，我们将成功并得到以下值：
- en: '![](../Images/f0a2a1ee8f74e9513521e49289a92710.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0a2a1ee8f74e9513521e49289a92710.png)'
- en: Image by the author
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'Which when we collapse becomes:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些合并后变成：
- en: '![](../Images/d8eee94e9020f33efa5a2e8ae7227e8c.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8eee94e9020f33efa5a2e8ae7227e8c.png)'
- en: Image by the author
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: This outcome is free of ReLU violations and represents a valid point that the
    neural network can produce within the initially declared bounds. With this, our
    search concludes, and we can officially declare that the neural network can have
    an input in the range of 0.5 and 1 and generate an output between 0.5 and 2 is
    possible.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果没有ReLU违例，并且代表了神经网络在最初声明的范围内可以生成的有效点。至此，我们的搜索结束，我们可以正式声明神经网络在输入范围0.5到1之间生成输出范围0.5到2是可能的。
- en: Possible Optimizations
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可能的优化
- en: The original paper suggests other optimizations such as bound tightening, derived
    bounds, conflict analysis, and floating-point arithmetic. The most promising one,
    bound tightening, is where some simple checks are run to determine if one bound
    necessarily dictacts that another bound has to be within something smaller than
    what the user set. In our example, some simple algebra can quickly show that in
    order for tht output to at least be 0.5 the input would have to at least be 0.9
    and hence we could change that bound before we begin any searching. However, these
    optimizations are not implemented in our solution and as such we leave it to the
    reader to read the original paper to find details on this and other optimizations.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 原始论文建议了其他优化方法，如约束收紧、推导约束、冲突分析和浮点运算。其中最有前景的是约束收紧，其中进行一些简单的检查以确定一个约束是否必然意味着另一个约束必须在用户设置的范围内更小。在我们的例子中，一些简单的代数计算可以迅速表明，为了使输出至少为0.5，输入必须至少为0.9，因此我们可以在开始任何搜索之前改变这个约束。然而，这些优化没有在我们的解决方案中实现，因此我们将其留给读者阅读原始论文以了解这些及其他优化的详细信息。
- en: Code Implementations
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码实现
- en: For the best-performing and production-ready version of the algorithm, we suggest
    exploring the official Marabou GitHub page[5] as that is the current state of
    the art for this problem space. Additionally, you can delve into the official
    Reluplex repository for a more in-depth understanding of the algorithm[2]. I have
    also written a simplified implementation of ReLuPlex in Python[3]. This implementation
    can be valuable for grasping the algorithm and letting a user step through it
    line by line. It can serve as a foundation for developing a customized more advanced
    Python version of the algorithm.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于表现最佳且适用于生产的算法版本，我们建议探索官方的Marabou GitHub页面[5]，因为这是该问题领域的当前最前沿。此外，你可以深入了解官方Reluplex代码库以获得对算法的更深入理解[2]。我还用Python编写了一个简化版的ReLuPlex实现[3]。这个实现对于理解算法并让用户逐行执行它非常有价值。它可以作为开发定制的更高级Python版本算法的基础。
- en: References
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[[1][1702.01135] Reluplex: An Efficient SMT Solver for Verifying Deep Neural
    Networks (arxiv.org)](https://arxiv.org/abs/1702.01135)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1][1702.01135] Reluplex：用于验证深度神经网络的高效SMT求解器 (arxiv.org)](https://arxiv.org/abs/1702.01135)'
- en: '[[2][1803.08375] Deep Learning using Rectified Linear Units (ReLU)](https://arxiv.org/abs/1803.08375)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[[2][1803.08375] 使用修正线性单元（ReLU）的深度学习](https://arxiv.org/abs/1803.08375)'
- en: '[[2] Official Implementation of ReluPlex (github.com)](https://github.com/guykatzz/ReluplexCav2017)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[[2] ReluPlex的官方实现 (github.com)](https://github.com/guykatzz/ReluplexCav2017)'
- en: '[[3] Python Implementation of ReluPlex by author (github.com)](https://github.com/MatthewDaw/reluplex)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[[3] 作者的ReluPlex Python实现 (github.com)](https://github.com/MatthewDaw/reluplex)'
- en: '[[4][1910.14574] An Abstraction-Based Framework for Neural Network Verification
    (arxiv.org)](https://arxiv.org/abs/1910.14574)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[[4][1910.14574] 基于抽象的神经网络验证框架 (arxiv.org)](https://arxiv.org/abs/1910.14574)'
- en: '[[5] Official Implementation Of Marabou (github.com)](https://github.com/NeuralNetworkVerification/Marabou)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[[5] Marabou的官方实现 (github.com)](https://github.com/NeuralNetworkVerification/Marabou)'
- en: '[[6][2210.13915]Towards Formal XAI: Formally Approximate Minimal Explanations
    of Neural Networks](https://arxiv.org/abs/2210.13915)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[[6][2210.13915]迈向正式XAI：神经网络的形式近似最小解释](https://arxiv.org/abs/2210.13915)'
- en: '[[7] Neural Networks By Science Direct](https://www.sciencedirect.com/topics/neuroscience/neural-network)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[[7] Science Direct上的神经网络](https://www.sciencedirect.com/topics/neuroscience/neural-network)'
- en: '[[8]Comprehensive Overview of Backpropagation Algorithm for Digital Image Denoising](https://www.mdpi.com/2079-9292/11/10/1590)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[[8]数字图像去噪的反向传播算法综合概述](https://www.mdpi.com/2079-9292/11/10/1590)'
