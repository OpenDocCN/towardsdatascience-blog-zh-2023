- en: '3D Geospatial Data Integration with Python: The Ultimate Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Python è¿›è¡Œ 3D åœ°ç†ç©ºé—´æ•°æ®é›†æˆï¼šç»ˆææŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/3d-spatial-data-integration-with-python-7ef8ef14589a](https://towardsdatascience.com/3d-spatial-data-integration-with-python-7ef8ef14589a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/3d-spatial-data-integration-with-python-7ef8ef14589a](https://towardsdatascience.com/3d-spatial-data-integration-with-python-7ef8ef14589a)
- en: 3D Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D Python
- en: 'Tutorial to integrate geospatial data with a multi-modal Python workflow: combine
    3D point clouds, CityGML, voxels, vector + raster data'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”¨å¤šæ¨¡å¼ Python å·¥ä½œæµæ•´åˆåœ°ç†ç©ºé—´æ•°æ®çš„æ•™ç¨‹ï¼šç»“åˆ 3D ç‚¹äº‘ã€CityGMLã€ä½“ç´ ã€çŸ¢é‡ + æ …æ ¼æ•°æ®
- en: '[](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----7ef8ef14589a--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)
    Â·39 min readÂ·Nov 7, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ef8ef14589a--------------------------------)
    Â·é˜…è¯»æ—¶é—´ 39 åˆ†é’ŸÂ·2023å¹´11æœˆ7æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The pace of technological progress is just plain crazy nowadays. Even more so
    when looking at how vital 3D data is for geospatial analysis and digital twins.
    Being able to capture and analyze data in three dimensions means we can create
    precise representations of real-world objects and environments.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨çš„ç§‘æŠ€è¿›æ­¥é€Ÿåº¦ç®€ç›´ç–¯ç‹‚ã€‚å°¤å…¶æ˜¯å½“æˆ‘ä»¬çœ‹åˆ°3Dæ•°æ®å¯¹åœ°ç†ç©ºé—´åˆ†æå’Œæ•°å­—åŒèƒèƒçš„é‡è¦æ€§æ—¶æ›´æ˜¯å¦‚æ­¤ã€‚èƒ½å¤Ÿä»¥ä¸‰ç»´æ•æ‰å’Œåˆ†ææ•°æ®æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åˆ›å»ºå¯¹ç°å®ä¸–ç•Œå¯¹è±¡å’Œç¯å¢ƒçš„ç²¾ç¡®è¡¨ç¤ºã€‚
- en: '![](../Images/b80083f9ff4c868cd2c309dbcd41590e.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b80083f9ff4c868cd2c309dbcd41590e.png)'
- en: 3D Spatial Data Integration goes through understanding the scope of 3D Data
    Capture. Â© F. Poux
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ç©ºé—´æ•°æ®é›†æˆé€šè¿‡ç†è§£ 3D æ•°æ®æ•æ‰çš„èŒƒå›´æ¥å®ç°ã€‚Â© F. Poux
- en: 'ğŸ¦„**Mila**: *A picture is worth a thousand words. So what about Digital Twins?*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦„**ç±³æ‹‰**ï¼š*ä¸€å›¾èƒœåƒè¨€ã€‚é‚£ä¹ˆæ•°å­—åŒèƒèƒå‘¢ï¼Ÿ*
- en: This is especially important for fields like urban planning, infrastructure
    management, and disaster response.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¹åŸå¸‚è§„åˆ’ã€åŸºç¡€è®¾æ–½ç®¡ç†å’Œç¾éš¾å“åº”ç­‰é¢†åŸŸå°¤ä¸ºé‡è¦ã€‚
- en: By incorporating 3D data, we can enhance our ability to make informed decisions
    by relying on precise and reliable data representations. Furthermore, the integration
    of this data into digital twins can produce remarkably lifelike replicas of real-world
    assets and systems, thereby increasing the efficiency of simulation and analysis.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ•´åˆ 3D æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¾èµ–äºç²¾ç¡®å’Œå¯é çš„æ•°æ®è¡¨ç¤ºæ¥æé«˜åšå‡ºæ˜æ™ºå†³ç­–çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå°†è¿™äº›æ•°æ®æ•´åˆåˆ°æ•°å­—åŒèƒèƒä¸­å¯ä»¥ç”Ÿæˆéå¸¸é€¼çœŸçš„ç°å®èµ„äº§å’Œç³»ç»Ÿçš„å¤åˆ¶å“ï¼Œä»è€Œæé«˜æ¨¡æ‹Ÿå’Œåˆ†æçš„æ•ˆç‡ã€‚
- en: BUT (there is always a but), effective geospatial analysis and digital twin
    creation rely on efficiently integrating and visualizing different data formats.
    To achieve this, itâ€™s essential to have a comprehensive understanding of the various
    data modalities and how they can be seamlessly integrated and visualized together.
    In data terms, we want to create a unified and comprehensive representation of
    an area with data overlap.How lucky are we, because this is precisely what we
    will unlock today!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼ˆæ€»æ˜¯æœ‰â€œä½†æ˜¯â€ï¼‰ï¼Œæœ‰æ•ˆçš„åœ°ç†ç©ºé—´åˆ†æå’Œæ•°å­—åŒèƒèƒåˆ›å»ºä¾èµ–äºé«˜æ•ˆæ•´åˆå’Œå¯è§†åŒ–ä¸åŒçš„æ•°æ®æ ¼å¼ã€‚ä¸ºå®ç°è¿™ä¸€ç‚¹ï¼Œå¿…é¡»å…¨é¢äº†è§£å„ç§æ•°æ®æ¨¡å¼åŠå…¶å¦‚ä½•æ— ç¼é›†æˆå’Œå¯è§†åŒ–ã€‚åœ¨æ•°æ®æ–¹é¢ï¼Œæˆ‘ä»¬å¸Œæœ›åˆ›å»ºä¸€ä¸ªç»Ÿä¸€ä¸”å…¨é¢çš„åŒºåŸŸè¡¨ç¤ºï¼Œä»¥ä¾¿æ•°æ®èƒ½å¤Ÿé‡å ã€‚æˆ‘ä»¬çœŸæ˜¯å¤ªå¹¸è¿äº†ï¼Œå› ä¸ºè¿™æ­£æ˜¯æˆ‘ä»¬ä»Šå¤©è¦è§£é”çš„å†…å®¹ï¼
- en: '![](../Images/40b5bf0cc5f52b18fbd5938292f0d6fc.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40b5bf0cc5f52b18fbd5938292f0d6fc.png)'
- en: To constitute a Spatial Digital World, we must study 3D Data Integration. Many
    sources of information, such as vector, raster data, 3D point clouds, or 3D city
    models, can be combined to form a unified view of what happens on our planet.
    Â© F. Poux
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ„å»ºä¸€ä¸ªç©ºé—´æ•°å­—ä¸–ç•Œï¼Œæˆ‘ä»¬å¿…é¡»ç ”ç©¶ 3D æ•°æ®é›†æˆã€‚è®¸å¤šä¿¡æ¯æ¥æºï¼Œå¦‚çŸ¢é‡æ•°æ®ã€æ …æ ¼æ•°æ®ã€3D ç‚¹äº‘æˆ– 3D åŸå¸‚æ¨¡å‹ï¼Œå¯ä»¥ç»„åˆå½¢æˆæˆ‘ä»¬æ˜Ÿçƒä¸Šå‘ç”Ÿäº‹ä»¶çš„ç»Ÿä¸€è§†å›¾ã€‚Â©
    F. Poux
- en: In this hands-on guide, I provide a reference system-oriented workflow for 3D
    data integration with Python. So no need for expensive software or a large serialized
    pipeline of bricks without mortar! Just our Python friend and a carefully selected
    tiny range of robust modules and functions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™æœ¬åŠ¨æ‰‹æŒ‡å—ä¸­ï¼Œæˆ‘æä¾›äº†ä¸€ä¸ªé¢å‘ç³»ç»Ÿçš„ 3D æ•°æ®é›†æˆå·¥ä½œæµå‚è€ƒï¼Œä½¿ç”¨ Pythonã€‚å› æ­¤ï¼Œä½ ä¸éœ€è¦æ˜‚è´µçš„è½¯ä»¶æˆ–å¤§è§„æ¨¡çš„ç –å—å¼æµæ°´çº¿ï¼åªéœ€æˆ‘ä»¬çš„ Python
    æœ‹å‹å’Œç²¾å¿ƒæŒ‘é€‰çš„ä¸€å°ç»„å¼ºå¤§æ¨¡å—ä¸å‡½æ•°ã€‚
- en: The ultimate goal of this initiative is that you have a comprehensive guide
    and companion that will follow you along your 3D data journey! The workflow is
    structured in seven distinctive phases, as shown below.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå€¡è®®çš„ç»ˆæç›®æ ‡æ˜¯ï¼Œä½ å°†æ‹¥æœ‰ä¸€ä¸ªå…¨é¢çš„æŒ‡å—å’Œä¼´ä¾£ï¼Œé™ªä¼´ä½ å®Œæˆ 3D æ•°æ®ä¹‹æ—…ï¼å·¥ä½œæµè¢«ç»“æ„åŒ–ä¸ºä¸ƒä¸ªä¸åŒçš„é˜¶æ®µï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/57473a23703dd40f51db1e9702411dd7.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/57473a23703dd40f51db1e9702411dd7.png)'
- en: The 3D Data Integration Workflow with Python. It is a Seven-Step Process to
    produce unified data-centric views. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Python çš„ 3D æ•°æ®é›†æˆå·¥ä½œæµã€‚è¿™æ˜¯ä¸€ä¸ªä¸ƒæ­¥è¿‡ç¨‹ï¼Œç”¨äºç”Ÿæˆç»Ÿä¸€çš„æ•°æ®ä¸­å¿ƒè§†å›¾ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Each phase builds progressively to ensure that you can start from scratch or
    plug into your existing system modularly. Because it is exhaustively constructed,
    a table of contents will make it easier for you to go through!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªé˜¶æ®µé€æ­¥æ„å»ºï¼Œä»¥ç¡®ä¿ä½ å¯ä»¥ä»å¤´å¼€å§‹æˆ–æ¨¡å—åŒ–åœ°æ’å…¥åˆ°ç°æœ‰ç³»ç»Ÿä¸­ã€‚ç”±äºæ„å»ºå¾—éå¸¸å…¨é¢ï¼Œç›®å½•å°†ä½¿ä½ æ›´å®¹æ˜“æµè§ˆï¼
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Whenever you are ready, let us jump together on this marvelous quest to 3D Data
    Integration, with a coffee lying around, but not too close to your computer â˜•
    (speaking from devastating experience)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åªè¦ä½ å‡†å¤‡å¥½äº†ï¼Œå°±è®©æˆ‘ä»¬ä¸€èµ·è·³å…¥è¿™æ¬¡ç²¾å½©çš„ 3D æ•°æ®é›†æˆæ¢é™©å§ï¼Œèº«è¾¹æœ‰æ¯å’–å•¡ï¼Œä½†ä¸è¦ç¦»ç”µè„‘å¤ªè¿‘ â˜•ï¼ˆè¿™æ˜¯æˆ‘äº²èº«ç»å†çš„æƒ¨ç—›æ•™è®­ï¼‰
- en: 'ğŸµ**Note to Readers***: This hands-on guide is part of a* [***UTWENTE***](https://www.itc.nl/)
    *joint work with co-authors* ğŸ¦Š ***F. Poux****, ğŸ¦„* ***M. Koeva*,** *and* ***ğŸ¦ P.
    Nourian****. We acknowledge the financial contribution from the digital twins*
    [*@ITC*](http://twitter.com/ITC) *-project granted by the ITC faculty of the University
    of Twente. All images are Â© F. Poux*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸµ**è¯»è€…æ³¨æ„**ï¼šè¿™æœ¬åŠ¨æ‰‹æŒ‡å—æ˜¯* [***UTWENTE***](https://www.itc.nl/) *ä¸åˆè‘—è€…* ğŸ¦Š ***F. Poux***,
    ğŸ¦„* ***M. Koeva***,* å’Œ* ***ğŸ¦ P. Nourian*** *çš„è”åˆå·¥ä½œçš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬æ„Ÿè°¢æ¥è‡ªæ•°å­—åŒèƒèƒ* [*@ITC*](http://twitter.com/ITC)
    *é¡¹ç›®çš„èµ„åŠ©ï¼Œç”±ç‰¹æ¸©ç‰¹å¤§å­¦ ITC å­¦é™¢æä¾›ã€‚æ‰€æœ‰å›¾ç‰‡å‡ Â© F. Poux*
- en: Step 1\. Implementation Setup for 3D Data
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥ï¼š3D æ•°æ®çš„å®æ–½è®¾ç½®
- en: '![](../Images/225f8a8e13a80a4cb8675b370f93496a.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/225f8a8e13a80a4cb8675b370f93496a.png)'
- en: Step 1\. Implementation Setup for 3D Data. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥ï¼š3D æ•°æ®çš„å®æ–½è®¾ç½®ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: The first mission is quickly setting up a lightweight environment for developing
    our 3D Data Integration workflow. This is a simple phase, but ensuring a proper
    setup is the key to scalability and replication. So let us get on top of things!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯å¿«é€Ÿå»ºç«‹ä¸€ä¸ªè½»é‡çº§ç¯å¢ƒï¼Œä»¥å¼€å‘æˆ‘ä»¬çš„ 3D æ•°æ®é›†æˆå·¥ä½œæµã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„é˜¶æ®µï¼Œä½†ç¡®ä¿è®¾ç½®æ­£ç¡®æ˜¯å¯æ‰©å±•æ€§å’Œå¤åˆ¶çš„å…³é”®ã€‚è®©æˆ‘ä»¬æŠŠäº‹æƒ…åšå¥½å§ï¼
- en: '![](../Images/28627dd762be52c40d8c1adedc8e3c24.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28627dd762be52c40d8c1adedc8e3c24.png)'
- en: The Environment Setup comprises base libraries, 3D Data libraries, Geospatial
    libraries, and an IDE. All of this is on top of virtual environment management
    and Python. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç¯å¢ƒè®¾ç½®åŒ…æ‹¬åŸºç¡€åº“ã€3D æ•°æ®åº“ã€åœ°ç†ç©ºé—´åº“å’Œ IDEã€‚æ‰€æœ‰è¿™äº›éƒ½å»ºç«‹åœ¨è™šæ‹Ÿç¯å¢ƒç®¡ç†å’Œ Python ä¹‹ä¸Šã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: A Lightweight Environment Setup
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è½»é‡çº§ç¯å¢ƒè®¾ç½®
- en: 'Python environment setup using Anaconda, robust libraries, and an Integrated
    Development Environment (IDE) does not have to be painful. Anaconda provides a
    convenient way to manage Python packages and environments, and you can then use
    a powerful IDE such as Jupyter Lab or Spyder to make coding a breeze. For a detailed
    view of the process of setting up a 3D Python development environment, I recommend
    that you check out the following article:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Anaconda è¿›è¡Œ Python ç¯å¢ƒè®¾ç½®ï¼Œå¼ºå¤§çš„åº“å’Œé›†æˆå¼€å‘ç¯å¢ƒï¼ˆIDEï¼‰ä¸å¿…ç—›è‹¦ã€‚Anaconda æä¾›äº†ç®¡ç† Python åŒ…å’Œç¯å¢ƒçš„ä¾¿æ·æ–¹æ³•ï¼Œç„¶åä½ å¯ä»¥ä½¿ç”¨å¼ºå¤§çš„
    IDEï¼Œå¦‚ Jupyter Lab æˆ– Spyderï¼Œè®©ç¼–ç¨‹å˜å¾—è½»æ¾ã€‚å…³äºè®¾ç½® 3D Python å¼€å‘ç¯å¢ƒçš„è¯¦ç»†ä¿¡æ¯ï¼Œæˆ‘å»ºè®®ä½ æŸ¥çœ‹ä»¥ä¸‹æ–‡ç« ï¼š
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## LiDAR åŸå¸‚æ¨¡å‹çš„ 3D Python å·¥ä½œæµï¼šé€æ­¥æŒ‡å—]'
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Pythonâ€¦
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è§£é” 3D åŸå¸‚å»ºæ¨¡åº”ç”¨ç¨‹åºçš„æµç•…å·¥ä½œæµçš„ç»ˆææŒ‡å—ã€‚æ•™ç¨‹æ¶µç›–äº† Pythonâ€¦â€¦
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)'
- en: 'ğŸ¦Š **Florent**: *If you do not want to jump on another session, do not worry,
    I will not leave you high and dry! As part of this ultimate guide, here is a superb
    lightweight setup to get started, under 5 minutes, clocked âŒš.*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent**ï¼š*å¦‚æœä½ ä¸æƒ³å†å‚åŠ å¦ä¸€ä¸ªä¼šè¯ï¼Œä¸ç”¨æ‹…å¿ƒï¼Œæˆ‘ä¸ä¼šæŠ›ä¸‹ä½ ï¼ä½œä¸ºè¿™ä¸ªç»ˆææŒ‡å—çš„ä¸€éƒ¨åˆ†ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªç»ä½³çš„è½»é‡çº§è®¾ç½®ï¼Œå¯åŠ¨æ—¶é—´å°‘äº 5
    åˆ†é’Ÿï¼Œè®¡æ—¶ âŒšã€‚*
- en: To start things off, you can go to the [Anaconda website](https://docs.conda.io/en/latest/miniconda.html)
    and download a Miniconda installer (a free minimal installer for conda) appropriate
    for your operating system (Windows, macOS, or Linux), with a Python 10 version.
    From there, you can follow the installation instructions on the Anaconda website
    to install Miniconda on your machine.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œä½ å¯ä»¥è®¿é—® [Anaconda ç½‘ç«™](https://docs.conda.io/en/latest/miniconda.html) å¹¶ä¸‹è½½é€‚åˆä½ æ“ä½œç³»ç»Ÿï¼ˆWindowsã€macOS
    æˆ– Linuxï¼‰çš„ Miniconda å®‰è£…ç¨‹åºï¼ˆä¸€ä¸ªå…è´¹çš„ conda æœ€å°å®‰è£…ç¨‹åºï¼‰ï¼Œå¹¶é€‰æ‹© Python 10 ç‰ˆæœ¬ã€‚ç„¶åï¼Œä½ å¯ä»¥æŒ‰ç…§ Anaconda
    ç½‘ç«™ä¸Šçš„å®‰è£…è¯´æ˜åœ¨ä½ çš„è®¡ç®—æœºä¸Šå®‰è£… Minicondaã€‚
- en: 'And that is it! You now have secured the most uncomplicated Python installation
    with the lightweight miniconda that will make it super easy to isolate a controlled
    virtual environment. Before moving on to the following steps, we launch miniconda
    with its command line access:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼ä½ ç°åœ¨å·²ç»ç”¨è½»é‡çº§çš„ miniconda å®‰è£…äº†æœ€ç®€å•çš„ Pythonï¼Œè¿™å°†ä½¿ä½ éå¸¸å®¹æ˜“éš”ç¦»ä¸€ä¸ªå—æ§çš„è™šæ‹Ÿç¯å¢ƒã€‚åœ¨ç»§ç»­ä¸‹ä¸€æ­¥ä¹‹å‰ï¼Œæˆ‘ä»¬å¯åŠ¨ miniconda
    å¹¶è®¿é—®å…¶å‘½ä»¤è¡Œï¼š
- en: '![](../Images/df2bb60a544049eca1139b2b848577df.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df2bb60a544049eca1139b2b848577df.png)'
- en: In Windows, just searching â€œminicondaâ€ should yield this
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Windows ä¸­ï¼Œæœç´¢â€œminicondaâ€åº”è¯¥ä¼šå¾—åˆ°è¿™ä¸ªç»“æœã€‚
- en: Once in the Anaconda Prompt, we follow a simple four steps process to be up
    and running, as shown below.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è¿›å…¥ Anaconda Promptï¼Œæˆ‘ä»¬æŒ‰ç…§ä¸‹é¢æ‰€ç¤ºçš„ç®€å•å››æ­¥éª¤è¿‡ç¨‹è¿›è¡Œæ“ä½œã€‚
- en: '![](../Images/1cdedcd8fdd91ee19cf54b3a8cb8ca12.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cdedcd8fdd91ee19cf54b3a8cb8ca12.png)'
- en: Workflow for environment creation. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç¯å¢ƒåˆ›å»ºå·¥ä½œæµç¨‹ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'To create a new environment, we write the line: `conda create -n GEOTUTO python=3.10`'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦åˆ›å»ºä¸€ä¸ªæ–°ç¯å¢ƒï¼Œæˆ‘ä»¬å†™ï¼š`conda create -n GEOTUTO python=3.10`
- en: 'To switch to the newly created environment, we write: `conda activate GEOTUTO`'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦åˆ‡æ¢åˆ°æ–°åˆ›å»ºçš„ç¯å¢ƒï¼Œæˆ‘ä»¬å†™ï¼š`conda activate GEOTUTO`
- en: 'To check the Python version, `python --version`, and the installed packages:
    `conda list`. This should yield Python 3.10 and the list of base libraries respectively'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦æ£€æŸ¥ Python ç‰ˆæœ¬ï¼Œä½¿ç”¨ `python --version`ï¼Œä»¥åŠå·²å®‰è£…çš„åŒ…ï¼š`conda list`ã€‚è¿™åº”è¯¥åˆ†åˆ«æ˜¾ç¤º Python 3.10
    å’ŒåŸºæœ¬åº“çš„åˆ—è¡¨ã€‚
- en: 'To install pip in the new environment, we write: `conda install pip`'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦åœ¨æ–°çš„ç¯å¢ƒä¸­å®‰è£… pipï¼Œæˆ‘ä»¬å†™ï¼š`conda install pip`
- en: 'And that is it! We are now ready to move on installing the necessary libraries
    for 3D Data Integration with the pip manager: `pip install package-name`, where
    you change the package name by each of these (one at a time: `numpy`, `matplotlib`,
    `laspy[lazrs,laszip]`, `open3d`, `rasterio`, `geopandas`.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½ä½¿ç”¨ pip ç®¡ç†å™¨å®‰è£… 3D æ•°æ®é›†æˆæ‰€éœ€çš„åº“ï¼š`pip install package-name`ï¼Œå…¶ä¸­ä½ éœ€è¦é€ä¸€æ›´æ¢åŒ…åï¼ˆä¾‹å¦‚ï¼š`numpy`ã€`matplotlib`ã€`laspy[lazrs,laszip]`ã€`open3d`ã€`rasterio`ã€`geopandas`ï¼‰ã€‚
- en: Python base libraries
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python åŸºç¡€åº“
- en: '![](../Images/7a858df1f83c0e59bb7c37a4f919af96.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a858df1f83c0e59bb7c37a4f919af96.png)'
- en: 'Python Base libraries: Numpy and Matplotlib.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Python åŸºç¡€åº“ï¼šNumpy å’Œ Matplotlibã€‚
- en: 'The first package installation is done via the prompt: `pip install numpy`.No
    need to present **NumPy**, Python''s fundamental numerical and scientific computing
    library. It supports large multi-dimensional matrices and provides a collection
    of mathematical functions to work with ease. NumPy is the foundation of many other
    scientific libraries in Python and is heavily used in data analysis, machine learning,
    and scientific research.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªåŒ…çš„å®‰è£…é€šè¿‡æç¤ºå®Œæˆï¼š`pip install numpy`ã€‚ä¸éœ€è¦ä»‹ç»**NumPy**ï¼Œè¿™æ˜¯ Python çš„åŸºç¡€æ•°å€¼å’Œç§‘å­¦è®¡ç®—åº“ã€‚å®ƒæ”¯æŒå¤§å‹å¤šç»´çŸ©é˜µï¼Œå¹¶æä¾›äº†ä¸€ç³»åˆ—æ•°å­¦å‡½æ•°ï¼Œæ–¹ä¾¿ä½¿ç”¨ã€‚NumPy
    æ˜¯è®¸å¤šå…¶ä»–ç§‘å­¦åº“çš„åŸºç¡€ï¼Œåœ¨æ•°æ®åˆ†æã€æœºå™¨å­¦ä¹ å’Œç§‘å­¦ç ”ç©¶ä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚
- en: 'ğŸ¦ **Nourian**: *NumPy is all about Linear Algebra. If you need to get comfortable
    with re-learning Linear Algebra, you can start from here:* [*Rudiment of Linear
    Algebra for Computer Graphics*](https://www.researchgate.net/publication/335571959_Rudiments_of_Linear_Algebra_Computer_Graphics)
    *(ResearchGate)*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦ **Nourian**ï¼š*NumPy å…¨å…³äºçº¿æ€§ä»£æ•°ã€‚å¦‚æœä½ éœ€è¦é‡æ–°å­¦ä¹ çº¿æ€§ä»£æ•°å¹¶ç†Ÿæ‚‰å®ƒï¼Œä½ å¯ä»¥ä»è¿™é‡Œå¼€å§‹ï¼š* [*è®¡ç®—æœºå›¾å½¢å­¦çš„çº¿æ€§ä»£æ•°åŸºç¡€*](https://www.researchgate.net/publication/335571959_Rudiments_of_Linear_Algebra_Computer_Graphics)
    *(ResearchGate)*
- en: '**Matplotlib** is a popular plotting library for Python that enables 2D plotting
    and basic 3D plotting capabilities. To install it: `pip install matplotlib`. It
    provides a wide range of customizable visualization options, allowing users to
    create various types of plots, such as line plots, scatter plots, bar plots, histograms,
    3D plots, and more. Matplotlib is widely used in scientific research and data
    science workflows.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**Matplotlib** æ˜¯ä¸€ä¸ªæµè¡Œçš„ Python ç»˜å›¾åº“ï¼Œæ”¯æŒ 2D ç»˜å›¾å’ŒåŸºæœ¬çš„ 3D ç»˜å›¾åŠŸèƒ½ã€‚å®‰è£…æ–¹æ³•ä¸ºï¼š`pip install matplotlib`ã€‚å®ƒæä¾›äº†å¹¿æ³›çš„å¯å®šåˆ¶å¯è§†åŒ–é€‰é¡¹ï¼Œå…è®¸ç”¨æˆ·åˆ›å»ºå„ç§ç±»å‹çš„å›¾è¡¨ï¼Œå¦‚æŠ˜çº¿å›¾ã€æ•£ç‚¹å›¾ã€æ¡å½¢å›¾ã€ç›´æ–¹å›¾ã€3D
    å›¾è¡¨ç­‰ã€‚Matplotlib åœ¨ç§‘å­¦ç ”ç©¶å’Œæ•°æ®ç§‘å­¦å·¥ä½œæµä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚'
- en: 3D Python Libraries
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D Python åº“
- en: '![](../Images/c517d8cc0d41fcdeee5abbb2dd1f57f0.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c517d8cc0d41fcdeee5abbb2dd1f57f0.png)'
- en: 'Python 3D Libraries: Open3D and Laspy.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3D åº“ï¼šOpen3D å’Œ Laspyã€‚
- en: '**Open3D** is a modern 3D data processing and visualization library, mainly
    focusing on 3D point clouds and meshes. It provides functionalities to handle
    3D data, such as point cloud registration, geometry processing, mesh creation,
    and visualization. Open3D is particularly useful for tasks related to 3D computer
    vision, robotics, and augmented reality applications. And for installing Open3D:
    `pip install open3d`.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**Open3D** æ˜¯ä¸€ä¸ªç°ä»£çš„ 3D æ•°æ®å¤„ç†å’Œå¯è§†åŒ–åº“ï¼Œä¸»è¦å…³æ³¨ 3D ç‚¹äº‘å’Œç½‘æ ¼ã€‚å®ƒæä¾›äº†å¤„ç† 3D æ•°æ®çš„åŠŸèƒ½ï¼Œå¦‚ç‚¹äº‘é…å‡†ã€å‡ ä½•å¤„ç†ã€ç½‘æ ¼åˆ›å»ºå’Œå¯è§†åŒ–ã€‚Open3D
    ç‰¹åˆ«é€‚ç”¨äºä¸ 3D è®¡ç®—æœºè§†è§‰ã€æœºå™¨äººæŠ€æœ¯å’Œå¢å¼ºç°å®åº”ç”¨ç›¸å…³çš„ä»»åŠ¡ã€‚å®‰è£… Open3D çš„æ–¹æ³•æ˜¯ï¼š`pip install open3d`ã€‚'
- en: Then, we have to install **Laspy**:`pip install laspy[lazrs,laszip]`. This Python
    library is used for reading, writing, and modifying LiDAR data stored in the LAS
    (LiDAR data Exchange Format) and LAZ (compressed LAS) file formats. It provides
    tools to work with point cloud data obtained from LiDAR scanners and is widely
    (small world) used in geospatial applications for terrain modeling, forestry,
    urban planning, and more.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬éœ€è¦å®‰è£… **Laspy**ï¼š`pip install laspy[lazrs,laszip]`ã€‚è¿™ä¸ª Python åº“ç”¨äºè¯»å–ã€å†™å…¥å’Œä¿®æ”¹å­˜å‚¨åœ¨
    LASï¼ˆæ¿€å…‰é›·è¾¾æ•°æ®äº¤æ¢æ ¼å¼ï¼‰å’Œ LAZï¼ˆå‹ç¼© LASï¼‰æ–‡ä»¶æ ¼å¼ä¸­çš„ LiDAR æ•°æ®ã€‚å®ƒæä¾›äº†å¤„ç†æ¥è‡ª LiDAR æ‰«æä»ªçš„ç‚¹äº‘æ•°æ®çš„å·¥å…·ï¼Œå¹¶åœ¨åœ°ç†ç©ºé—´åº”ç”¨ä¸­ï¼ˆå¦‚åœ°å½¢å»ºæ¨¡ã€æ—ä¸šã€åŸå¸‚è§„åˆ’ç­‰ï¼‰è¢«å¹¿æ³›ä½¿ç”¨ã€‚
- en: Geospatial Libraries
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ°ç†ç©ºé—´åº“
- en: '**Geopandas** is a library built on top of pandas and shapely designed to handle
    geospatial data efficiently. To install it: `pip install geopandas`. It extends
    the capabilities of pandas to include geospatial data types and operations, allowing
    users to work with vector data (points, lines, polygons) and efficiently perform
    geospatial analysis. Geopandas is widely used in GIS, cartography, and spatial
    data analysis.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**Geopandas** æ˜¯ä¸€ä¸ªå»ºç«‹åœ¨ pandas å’Œ shapely ä¹‹ä¸Šçš„åº“ï¼Œæ—¨åœ¨é«˜æ•ˆå¤„ç†åœ°ç†ç©ºé—´æ•°æ®ã€‚å®‰è£…æ–¹æ³•ä¸ºï¼š`pip install
    geopandas`ã€‚å®ƒæ‰©å±•äº† pandas çš„åŠŸèƒ½ï¼Œæ”¯æŒåœ°ç†ç©ºé—´æ•°æ®ç±»å‹å’Œæ“ä½œï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿå¤„ç†çŸ¢é‡æ•°æ®ï¼ˆç‚¹ã€çº¿ã€é¢ï¼‰å¹¶é«˜æ•ˆåœ°è¿›è¡Œåœ°ç†ç©ºé—´åˆ†æã€‚Geopandas
    åœ¨ GISã€åˆ¶å›¾å’Œç©ºé—´æ•°æ®åˆ†æä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚'
- en: '**Rasterio** is the last library that we will install with: `pip install rasterio`.
    It is used for reading and writing geospatial raster data. It supports various
    standard raster formats like GeoTIFF or JPEG and provides functionalities for
    geospatial metadata, spatial referencing, and coordinate transformations. rasterio
    is valuable for satellite imagery analysis, remote sensing, and GIS (Geographic
    Information Systems) applications.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**Rasterio** æ˜¯æˆ‘ä»¬å°†è¦å®‰è£…çš„æœ€åä¸€ä¸ªåº“ï¼Œå®‰è£…æ–¹æ³•ä¸ºï¼š`pip install rasterio`ã€‚å®ƒç”¨äºè¯»å–å’Œå†™å…¥åœ°ç†ç©ºé—´æ …æ ¼æ•°æ®ã€‚æ”¯æŒå„ç§æ ‡å‡†çš„æ …æ ¼æ ¼å¼ï¼Œå¦‚
    GeoTIFF æˆ– JPEGï¼Œå¹¶æä¾›åœ°ç†ç©ºé—´å…ƒæ•°æ®ã€ç©ºé—´å‚è€ƒå’Œåæ ‡è½¬æ¢åŠŸèƒ½ã€‚rasterio å¯¹äºå«æ˜Ÿå½±åƒåˆ†æã€é¥æ„Ÿå’Œ GISï¼ˆåœ°ç†ä¿¡æ¯ç³»ç»Ÿï¼‰åº”ç”¨éå¸¸æœ‰ä»·å€¼ã€‚'
- en: Each of these libraries serves a synergic purpose and permits handling a myriad
    of data types in scientific computing, data science, and geospatial applications.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›åº“å„è‡ªå…·æœ‰ååŒä½œç”¨ï¼Œå¯ä»¥å¤„ç†ç§‘å­¦è®¡ç®—ã€æ•°æ®ç§‘å­¦å’Œåœ°ç†ç©ºé—´åº”ç”¨ä¸­çš„å„ç§æ•°æ®ç±»å‹ã€‚
- en: Setting up an IDE
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¾ç½® IDE
- en: 'The last step of our setup is to install an IDE. We are still in the command
    line interface within the environment, and we type: `pip install jupyterlab`,
    which will install jupyterlab on our environment. To use it clearly, we can change
    the directory to the parent directory of our project (let us call it `INTEGRATION`),
    which will hold both a `CODE` folder and a `DATA` Folder: `cd C://COURSES/POUX/INTEGRATION`.
    And then, we will launch jupyterlab from this location by typing in the console:
    `jupyter lab`, which will open a new localhost page in your web browser (Chrome
    would be the preferred choice, but Firefox or Safari work as well).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¾ç½®çš„æœ€åä¸€æ­¥æ˜¯å®‰è£… IDEã€‚æˆ‘ä»¬ä»åœ¨ç¯å¢ƒä¸­çš„å‘½ä»¤è¡Œç•Œé¢ä¸­ï¼Œè¾“å…¥ï¼š`pip install jupyterlab`ï¼Œè¿™å°†ä¼šåœ¨æˆ‘ä»¬çš„ç¯å¢ƒä¸­å®‰è£… jupyterlabã€‚ä¸ºäº†æ¸…æ™°ä½¿ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†ç›®å½•æ›´æ”¹ä¸ºé¡¹ç›®çš„çˆ¶ç›®å½•ï¼ˆæˆ‘ä»¬ç§°ä¹‹ä¸º
    `INTEGRATION`ï¼‰ï¼Œå…¶ä¸­åŒ…å« `CODE` æ–‡ä»¶å¤¹å’Œ `DATA` æ–‡ä»¶å¤¹ï¼š`cd C://COURSES/POUX/INTEGRATION`ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä»è¿™ä¸ªä½ç½®å¯åŠ¨
    jupyterlabï¼Œé€šè¿‡åœ¨æ§åˆ¶å°è¾“å…¥ï¼š`jupyter lab`ï¼Œè¿™å°†ä¼šåœ¨æ‚¨çš„ç½‘é¡µæµè§ˆå™¨ä¸­æ‰“å¼€ä¸€ä¸ªæ–°çš„æœ¬åœ°é¡µé¢ï¼ˆChrome æ˜¯é¦–é€‰ï¼Œä½† Firefox
    æˆ– Safari ä¹Ÿå¯ä»¥ï¼‰ã€‚
- en: 'Well done! Phase one was completed successfully! ğŸ¯We are now ready to attack
    the second phase: finding datasets that we can combine for later use in our NASA-graded
    workflow. ğŸ™ƒ'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åšå¾—å¥½ï¼ç¬¬ä¸€é˜¶æ®µæˆåŠŸå®Œæˆï¼ğŸ¯æˆ‘ä»¬ç°åœ¨å‡†å¤‡è¿›å…¥ç¬¬äºŒé˜¶æ®µï¼šå¯»æ‰¾å¯ä»¥ç»„åˆä»¥ä¾›æœªæ¥ä½¿ç”¨çš„æ•°æ®é›†ï¼Œç”¨äºæˆ‘ä»¬çš„ NASA è¯„åˆ†å·¥ä½œæµç¨‹ã€‚ğŸ™ƒ
- en: Step 2\. Multi-Modal Data Curation
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2. å¤šæ¨¡æ€æ•°æ®ç­–å±•
- en: '![](../Images/4f30096356d29ac7cf24d2996baead60.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f30096356d29ac7cf24d2996baead60.png)'
- en: Step 2\. Multi-Modal Creation. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2. å¤šæ¨¡æ€åˆ›å»ºã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'We want to integrate multi-modal datasets. But what is this swearword: multimodal?
    It refers to data that spans different types and contexts, such as images, point
    clouds, text, and soundâ€¦'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›æ•´åˆå¤šæ¨¡æ€æ•°æ®é›†ã€‚ä½†â€œå¤šæ¨¡æ€â€è¿™ä¸ªè¯æ˜¯ä»€ä¹ˆæ„æ€å‘¢ï¼Ÿå®ƒæŒ‡çš„æ˜¯è·¨ä¸åŒç±»å‹å’ŒèƒŒæ™¯çš„æ•°æ®ï¼Œä¾‹å¦‚å›¾åƒã€ç‚¹äº‘ã€æ–‡æœ¬å’Œå£°éŸ³â€¦â€¦
- en: '![](../Images/7a331b61c40795a96c1600a99bf0cd3c.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a331b61c40795a96c1600a99bf0cd3c.png)'
- en: We use various 2D/2.5D/3D modalities. 3D Point Clouds, 3D Mesh, City Models,
    Voxels, Spatial Rasters, 360Â° Imagery, Tabular Data, Vector Data. Â© F. Poux
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨å„ç§ 2D/2.5D/3D æ¨¡æ€ã€‚3D ç‚¹äº‘ã€3D ç½‘æ ¼ã€åŸå¸‚æ¨¡å‹ã€ä½“ç´ ã€ç©ºé—´æ …æ ¼ã€360Â° å›¾åƒã€è¡¨æ ¼æ•°æ®ã€çŸ¢é‡æ•°æ®ã€‚Â© F. Poux
- en: 'ğŸ¦ **Nourian**: *Additionally, here is a nice hitchhiker''s guide to Web-based
    computing platforms for Urban Planning:* [*Essential Guide*](https://www.researchgate.net/publication/324088589_Essential_Means_for_Urban_Computing_Specification_of_Web-Based_Computing_Platforms_for_Urban_Planning_a_Hitchhiker''s_Guide)
    *(ResearchGate)*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦ **Nourian**ï¼š*æ­¤å¤–ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªå…³äºåŸå¸‚è§„åˆ’çš„åŸºäºç½‘ç»œè®¡ç®—å¹³å°çš„æä½³æŒ‡å—ï¼š* [*å¿…å¤‡æŒ‡å—*](https://www.researchgate.net/publication/324088589_Essential_Means_for_Urban_Computing_Specification_of_Web-Based_Computing_Platforms_for_Urban_Planning_a_Hitchhiker's_Guide)
    *(ResearchGate)*
- en: So, our goal in this phase is to identify a zone of interest and gather as much
    data as possible to help us in our future analysis. The zone of interest selected
    today is a part of Enschede, a city in Eastern Netherlands in the province of
    Overijssel (Twente region), where, it makes sense, the University of Twente shines
    its knowledge beams. ğŸŒ
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬åœ¨æ­¤é˜¶æ®µçš„ç›®æ ‡æ˜¯è¯†åˆ«ä¸€ä¸ªæ„Ÿå…´è¶£çš„åŒºåŸŸï¼Œå¹¶æ”¶é›†å°½å¯èƒ½å¤šçš„æ•°æ®ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬æœªæ¥çš„åˆ†æã€‚ä»Šå¤©é€‰æ‹©çš„æ„Ÿå…´è¶£åŒºåŸŸæ˜¯è·å…°ä¸œéƒ¨Overijsselçœï¼ˆTwenteåœ°åŒºï¼‰Enschedeå¸‚çš„ä¸€éƒ¨åˆ†ï¼Œè¿™é‡Œï¼Œå¤§å­¦çš„çŸ¥è¯†å…‰èŠ’ç…§è€€å››æ–¹ã€‚ğŸŒ
- en: '![](../Images/c06ca6ff77e065d5e3cbb3d23ca0b7b6.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c06ca6ff77e065d5e3cbb3d23ca0b7b6.png)'
- en: Identifying a zone of interest.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šæ„Ÿå…´è¶£çš„åŒºåŸŸã€‚
- en: 'ğŸ¦„ **Mila**: *By unlocking the secrets of our cities through the fusion of 3D
    geospatial and remote sensing data, we give birth to city digital twins that illuminate
    the past, navigate the present, and shape. If you want to dive even more into
    data integration on the web using open-source tools, here is a research paper:*
    *3D Data integration for web-based opensource WebGL interactive visualization*
    *(ISPRS Archives)*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦„ **Mila**ï¼š*é€šè¿‡èåˆ 3D åœ°ç†ç©ºé—´å’Œé¥æ„Ÿæ•°æ®æ¥è§£é”æˆ‘ä»¬åŸå¸‚çš„ç§˜å¯†ï¼Œæˆ‘ä»¬è¯ç”Ÿäº†åŸå¸‚æ•°å­—åŒèƒèƒï¼Œè¿™äº›åŒèƒèƒç…§äº®äº†è¿‡å»ï¼Œå¯¼èˆªå½“å‰ï¼Œå¹¶å¡‘é€ æœªæ¥ã€‚å¦‚æœä½ æƒ³æ›´æ·±å…¥åœ°äº†è§£å¦‚ä½•ä½¿ç”¨å¼€æºå·¥å…·åœ¨ç½‘ç»œä¸Šè¿›è¡Œæ•°æ®æ•´åˆï¼Œè¿™é‡Œæœ‰ä¸€ç¯‡ç ”ç©¶è®ºæ–‡ï¼š*
    *3D æ•°æ®é›†æˆç”¨äºåŸºäº Web çš„å¼€æº WebGL äº’åŠ¨å¯è§†åŒ–* *(ISPRS Archives)*
- en: We are now ready to source different datasets. For clarity concerns, I organized
    this sourcing into four categories by searching for 3D datasets, Spatial Rasters,
    vector datasets, and finally from other sources, as shown below.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å‡†å¤‡è·å–ä¸åŒçš„æ•°æ®é›†ã€‚ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œæˆ‘å°†è¿™äº›æ•°æ®æºåˆ†ä¸ºå››ç±»ï¼š3D æ•°æ®é›†ã€ç©ºé—´æ …æ ¼ã€çŸ¢é‡æ•°æ®é›†ï¼Œä»¥åŠå…¶ä»–æ¥æºï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/4dd3147fbd305984b5b6690111c402cb.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4dd3147fbd305984b5b6690111c402cb.png)'
- en: Multi-modal data curation workflow. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šæ¨¡æ€æ•°æ®ç­–å±•å·¥ä½œæµç¨‹ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 3D Data Sourcing
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D æ•°æ®æº
- en: 'The first step is to source some datasets from some open data repository with
    a data license that allows us to do some experiments. On that front, for the Netherlands,
    there is the possibility of obtaining LiDAR data, elevation data models, and raster
    imagery from one place: [geotiles.nl](https://geotiles.nl/). You can zoom in on
    the original tiles and get access to the various datasets download links, as shown
    below.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥æ˜¯ä»ä¸€äº›å¼€æ”¾æ•°æ®ä»“åº“è·å–æ•°æ®é›†ï¼Œè¿™äº›ä»“åº“çš„æ•°æ®è®¸å¯å…è®¸æˆ‘ä»¬è¿›è¡Œä¸€äº›å®éªŒã€‚åœ¨è¿™æ–¹é¢ï¼Œå¯¹äºè·å…°ï¼Œå¯ä»¥ä»ä¸€ä¸ªåœ°æ–¹è·å– LiDAR æ•°æ®ã€åœ°å½¢æ¨¡å‹å’Œæ …æ ¼å›¾åƒï¼š[geotiles.nl](https://geotiles.nl/)ã€‚ä½ å¯ä»¥æ”¾å¤§åŸå§‹å›¾å—ï¼Œå¹¶è®¿é—®å„ç§æ•°æ®é›†çš„ä¸‹è½½é“¾æ¥ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/7258d565f8e5ba2179bf8e4d51ddf3a8.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7258d565f8e5ba2179bf8e4d51ddf3a8.png)'
- en: Extracting the 34FN2 Tile of the AHN4 Dataset through GeoTiles.nl. Â© Florent
    Poux
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ GeoTiles.nl æå– AHN4 æ•°æ®é›†çš„ 34FN2 å›¾å—ã€‚Â© Florent Poux
- en: 'ğŸ¦Š **Florent**: *To serve you best, all the used data is available in the Drive
    Folder shared at the end of the section. The AHN version is AHN4.*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦Š **Florent**: *ä¸ºäº†æ›´å¥½åœ°æœåŠ¡äºä½ ï¼Œæ‰€æœ‰ä½¿ç”¨çš„æ•°æ®éƒ½å¯ä»¥åœ¨æœ¬èŠ‚æœ«å°¾å…±äº«çš„é©±åŠ¨å™¨æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°ã€‚AHN ç‰ˆæœ¬æ˜¯ AHN4ã€‚*'
- en: 'The second place you can explore to get CityModels is 3D BAG, which stands
    for 3D Register of Buildings and Addresses (BAG), the most detailed, openly available
    data set on buildings and addresses in the Netherlands. It contains 3D models
    at numerous levels of detail, generated by combining two open data sets: the building
    data from the [BAG](https://docs.3dbag.nl/en/overview/sources/#BAG) and the height
    data from the [AHN](https://docs.3dbag.nl/en/overview/sources/#AHN). Using the
    3D Bag Viewer by tile queries, you can explore and access the buildings.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æ¢ç´¢çš„ç¬¬äºŒä¸ªè·å– CityModels çš„åœ°æ–¹æ˜¯ 3D BAGï¼Œå³å»ºç­‘å’Œåœ°å€çš„ 3D æ³¨å†Œï¼ˆBAGï¼‰ï¼Œè¿™æ˜¯è·å…°æœ€è¯¦ç»†ã€å¼€æ”¾å¯ç”¨çš„å»ºç­‘å’Œåœ°å€æ•°æ®é›†ã€‚å®ƒåŒ…å«å¤šä¸ªè¯¦ç»†çº§åˆ«çš„
    3D æ¨¡å‹ï¼Œç”Ÿæˆæ–¹å¼æ˜¯å°†ä¸¤ä¸ªå¼€æ”¾æ•°æ®é›†ç»“åˆèµ·æ¥ï¼šæ¥è‡ª [BAG](https://docs.3dbag.nl/en/overview/sources/#BAG)
    çš„å»ºç­‘æ•°æ®å’Œæ¥è‡ª [AHN](https://docs.3dbag.nl/en/overview/sources/#AHN) çš„é«˜åº¦æ•°æ®ã€‚ä½¿ç”¨ 3D Bag
    Viewer é€šè¿‡å›¾å—æŸ¥è¯¢ï¼Œä½ å¯ä»¥æ¢ç´¢å’Œè®¿é—®å»ºç­‘ç‰©ã€‚
- en: '![](../Images/4c981742889390b5d596eab78a29844c.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c981742889390b5d596eab78a29844c.png)'
- en: The BAG Viewer. The Open Data accessible is licensed under CC BY 4.0, [3DBAG
    by tudelft3d and 3DGI](https://docs.3dbag.nl/en/copyright).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: BAG Viewerã€‚å¼€æ”¾æ•°æ®çš„è®¸å¯ä¸º CC BY 4.0ï¼Œ[3DBAG by tudelft3d å’Œ 3DGI](https://docs.3dbag.nl/en/copyright)ã€‚
- en: The tile extent differs from what we got from the geotiles.nl, making it **interesting**
    when we attack the integration phase. At this stage, we already have exciting
    datasets under our hands. We can now move on to exploring spatial raster datasets.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾å—èŒƒå›´ä¸æˆ‘ä»¬ä» geotiles.nl è·å¾—çš„ä¸åŒï¼Œè¿™åœ¨æˆ‘ä»¬è¿›è¡Œé›†æˆé˜¶æ®µæ—¶æ˜¾å¾—**æœ‰è¶£**ã€‚åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬å·²ç»æ‰‹å¤´æœ‰äº†ä»¤äººå…´å¥‹çš„æ•°æ®é›†ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­æ¢ç´¢ç©ºé—´æ …æ ¼æ•°æ®é›†ã€‚
- en: Spatial Raster Data sources
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç©ºé—´æ …æ ¼æ•°æ®æº
- en: 'For satellite and aerial imagery, the [USGS Earth Explorer](https://earthexplorer.usgs.gov/)
    is one of the largest free data sources. It is worldwide, with a friendly user
    interface that makes accessing remote sensing data simple. It even has a bulk
    download application if you need to download more than one data set. If this is
    the first time for you, you will need to execute one additional step: creating
    an account, but it is free and quick (I did it in under 2 minutes âŒš).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå«æ˜Ÿå’Œèˆªç©ºå›¾åƒï¼Œ[USGS Earth Explorer](https://earthexplorer.usgs.gov/) æ˜¯æœ€å¤§çš„å…è´¹æ•°æ®æºä¹‹ä¸€ã€‚å®ƒæ˜¯å…¨çƒæ€§çš„ï¼Œå…·æœ‰å‹å¥½çš„ç”¨æˆ·ç•Œé¢ï¼Œä½¿è®¿é—®é¥æ„Ÿæ•°æ®å˜å¾—ç®€å•ã€‚å¦‚æœä½ éœ€è¦ä¸‹è½½å¤šä¸ªæ•°æ®é›†ï¼Œå®ƒç”šè‡³æœ‰æ‰¹é‡ä¸‹è½½åº”ç”¨ã€‚å¦‚æœè¿™æ˜¯ä½ ç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼Œä½ éœ€è¦æ‰§è¡Œä¸€ä¸ªé¢å¤–çš„æ­¥éª¤ï¼šåˆ›å»ºä¸€ä¸ªè´¦æˆ·ï¼Œä½†è¿™æ˜¯å…è´¹çš„ä¸”è¿…é€Ÿçš„ï¼ˆæˆ‘ç”¨ä¸åˆ°
    2 åˆ†é’Ÿ âŒšï¼‰ã€‚
- en: '![](../Images/8f2e719409f3981b7a32498cc696f18d.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f2e719409f3981b7a32498cc696f18d.png)'
- en: The USGS Earth Explorer. Open data part of U.S. Public Domain, [Credits USGS](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: USGS Earth Explorerã€‚å¼€æ”¾æ•°æ®å±äºç¾å›½å…¬å…±é¢†åŸŸï¼Œ[Credits USGS](https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits)ã€‚
- en: I drew a polygon from the WebUI and then asked to get the **Landsat > Landsat
    Collection 2 â€” Level 1** group (the most recent Landsat imagery is L8â€“9 OLI/TIRS
    and L7 ETM+). The differences between the collections are based on data quality
    and level of processing. USGS has [classified images into tiers](https://www.usgs.gov/media/videos/landsat-collections-what-are-tiers)
    based on quality and processing level ([Source](https://gisgeography.com/usgs-earth-explorer-download-free-landsat-imagery/)).
    Once in the result section, you can check the footprint before deciding which
    would best fit your needs, as shown below.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä» WebUI ç»˜åˆ¶äº†ä¸€ä¸ªå¤šè¾¹å½¢ï¼Œç„¶åè¯·æ±‚è·å– **Landsat > Landsat Collection 2 â€” Level 1** ç»„ï¼ˆæœ€æ–°çš„
    Landsat å›¾åƒæ˜¯ L8â€“9 OLI/TIRS å’Œ L7 ETM+ï¼‰ã€‚è¿™äº›é›†åˆä¹‹é—´çš„å·®å¼‚åŸºäºæ•°æ®è´¨é‡å’Œå¤„ç†æ°´å¹³ã€‚USGS å·²æ ¹æ®è´¨é‡å’Œå¤„ç†æ°´å¹³ [å°†å›¾åƒåˆ†ç±»ä¸ºä¸åŒçº§åˆ«](https://www.usgs.gov/media/videos/landsat-collections-what-are-tiers)
    ([æ¥æº](https://gisgeography.com/usgs-earth-explorer-download-free-landsat-imagery/))ã€‚ä¸€æ—¦è¿›å…¥ç»“æœéƒ¨åˆ†ï¼Œä½ å¯ä»¥æŸ¥çœ‹è¶³è¿¹ï¼Œç„¶åå†³å®šå“ªä¸ªæœ€é€‚åˆä½ çš„éœ€æ±‚ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/711d76ed2293ecae088248d408fca2c0.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/711d76ed2293ecae088248d408fca2c0.png)'
- en: The polygons to extract LandSAT images. Â© F. Poux
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æå– LandSAT å›¾åƒçš„å¤šè¾¹å½¢ã€‚Â© F. Poux
- en: For Digital Elevation models, I suggest sticking with the [geotiles.nl](https://geotiles.nl/)
    data service as it is already on point with the most up-to-date and precise elevation
    models from the AHN. We are moving at an incredible pace, and the next stage is
    to get some excellent vector datasets!
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ•°å­—é«˜ç¨‹æ¨¡å‹ï¼Œæˆ‘å»ºè®®ä½¿ç”¨ [geotiles.nl](https://geotiles.nl/) æ•°æ®æœåŠ¡ï¼Œå› ä¸ºå®ƒæä¾›äº† AHN çš„æœ€æ–°å’Œæœ€ç²¾ç¡®çš„é«˜ç¨‹æ¨¡å‹ã€‚æˆ‘ä»¬æ­£åœ¨ä»¥ä»¤äººéš¾ä»¥ç½®ä¿¡çš„é€Ÿåº¦å‰è¿›ï¼Œä¸‹ä¸€é˜¶æ®µæ˜¯è·å–ä¸€äº›ä¼˜ç§€çš„çŸ¢é‡æ•°æ®é›†ï¼
- en: Vector data curation
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: çŸ¢é‡æ•°æ®ç­–å±•
- en: If you are in the GIS community, I hope presenting the power of [OpenStreetMap
    (OSM)](https://www.openstreetmap.org/#map=17/52.22687/6.88808&layers=G) will not
    insult your knowledge base.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ åœ¨ GIS ç¤¾åŒºä¸­ï¼Œæˆ‘å¸Œæœ›å±•ç¤º [OpenStreetMap (OSM)](https://www.openstreetmap.org/#map=17/52.22687/6.88808&layers=G)
    çš„åŠ›é‡ä¸ä¼šå†’çŠ¯ä½ çš„çŸ¥è¯†åŸºç¡€ã€‚
- en: '![](../Images/e45243acdfb3b509eee6d1c8c17517c1.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e45243acdfb3b509eee6d1c8c17517c1.png)'
- en: OpenStreetMap Data Curation Portal. The Data is open, under the open database
    license (ODbL), [Credits OpenStreetMap](https://www.openstreetmap.org/copyright).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: OpenStreetMap æ•°æ®ç­–å±•é—¨æˆ·ã€‚æ•°æ®æ˜¯å¼€æ”¾çš„ï¼Œéµå¾ªå¼€æ”¾æ•°æ®åº“è®¸å¯è¯ï¼ˆODbLï¼‰ï¼Œ[OpenStreetMap ç‰ˆæƒ](https://www.openstreetmap.org/copyright)ã€‚
- en: OSM provides different maps and layers with a crowd-sourcing initiative that
    makes it highly exhaustive, with a precision flag nevertheless. Indeed, OSM is
    open to the public and created by a general audience. So this means that accuracy
    can vary based on the creator and its â€œmappingâ€ expertise level. However, OSM
    is a goldmine for openly licensed street-level GIS data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: OSM æä¾›äº†ä¸åŒçš„åœ°å›¾å’Œå›¾å±‚ï¼Œå…·æœ‰ä¼—åŒ…å€¡è®®ï¼Œè¿™ä½¿å¾—å®ƒéå¸¸è¯¦å°½ï¼Œä½†ç²¾ç¡®åº¦ä»ç„¶æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚å®é™…ä¸Šï¼ŒOSM å¯¹å…¬ä¼—å¼€æ”¾ï¼Œç”±æ™®é€šå¤§ä¼—åˆ›å»ºã€‚è¿™æ„å‘³ç€å‡†ç¡®æ€§å¯èƒ½ä¼šæ ¹æ®åˆ›ä½œè€…åŠå…¶â€œåˆ¶å›¾â€æŠ€èƒ½æ°´å¹³è€Œæœ‰æ‰€ä¸åŒã€‚ç„¶è€Œï¼ŒOSM
    æ˜¯ä¸€ä¸ªå¼€æ”¾è®¸å¯è¯è¡—é“çº§ GIS æ•°æ®çš„å®è—ã€‚
- en: 'We have several ways to download OpenStreetMap data to get our hands on some
    of this gold. Conveniently, there is even an [OSM Data Wikipedia page](https://wiki.openstreetmap.org/wiki/Downloading_data)
    with all the available OSM extracts. My recommendation is the use of the tool
    [Geofabrik](http://download.geofabrik.de/). Indeed, you can then leverage a data
    organization by semantic spatial extent (E.g.: country, state, continent â€¦). You
    can quickly choose a geographic location and then download OSM data, as shown
    below.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰å‡ ç§æ–¹æ³•å¯ä»¥ä¸‹è½½ OpenStreetMap æ•°æ®ï¼Œä»¥è·å–ä¸€äº›å®è´µçš„æ•°æ®ã€‚æ–¹ä¾¿çš„æ˜¯ï¼Œç”šè‡³æœ‰ä¸€ä¸ª [OSM æ•°æ®ç»´åŸºé¡µé¢](https://wiki.openstreetmap.org/wiki/Downloading_data)
    åˆ—å‡ºäº†æ‰€æœ‰å¯ç”¨çš„ OSM æå–æ•°æ®ã€‚æˆ‘çš„æ¨èæ˜¯ä½¿ç”¨ [Geofabrik](http://download.geofabrik.de/) å·¥å…·ã€‚å®é™…ä¸Šï¼Œä½ å¯ä»¥åˆ©ç”¨æŒ‰è¯­ä¹‰ç©ºé—´èŒƒå›´ï¼ˆä¾‹å¦‚ï¼šå›½å®¶ã€å·ã€æ´²ç­‰ï¼‰ç»„ç»‡çš„æ•°æ®ã€‚ä½ å¯ä»¥å¿«é€Ÿé€‰æ‹©ä¸€ä¸ªåœ°ç†ä½ç½®ï¼Œç„¶åä¸‹è½½
    OSM æ•°æ®ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/960b1288b62967ac0e4952f6ca76f5af.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/960b1288b62967ac0e4952f6ca76f5af.png)'
- en: GeoFabrik portal to gather vector datasets. Â© F. Poux
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: GeoFabrik é—¨æˆ·ä»¥æ”¶é›†çŸ¢é‡æ•°æ®é›†ã€‚Â© F. Poux
- en: 'ğŸ¦Š **Florent**: *I also prefer downloading OSM data as shapefiles, but more
    on that later ğŸ˜‰.* ***Mila*** *makes me think that a great piece of knowledge is
    distilled in this* [*Geospatial Data with Python*](https://carpentries-incubator.github.io/geospatial-python/)*.*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent**ï¼š*æˆ‘ä¹Ÿå–œæ¬¢å°† OSM æ•°æ®ä¸‹è½½ä¸ºå½¢çŠ¶æ–‡ä»¶ï¼Œä½†ç¨åä¼šè¯¦ç»†è¯´æ˜ ğŸ˜‰ã€‚* ***Mila*** *è®©æˆ‘è§‰å¾—è¿™å…¶ä¸­æµ“ç¼©äº†å¤§é‡çš„çŸ¥è¯†*
    [*Geospatial Data with Python*](https://carpentries-incubator.github.io/geospatial-python/)*ã€‚*
- en: We now have some 3D datasets, some raster datasets, and vector shapefiles. Time
    to dig the world wide web to find other precious stones ğŸ’.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰ä¸€äº› 3D æ•°æ®é›†ã€ä¸€äº›æ …æ ¼æ•°æ®é›†å’ŒçŸ¢é‡å½¢çŠ¶æ–‡ä»¶ã€‚æ˜¯æ—¶å€™åœ¨äº’è”ç½‘ä¸–ç•Œä¸­æŒ–æ˜å…¶ä»–å®è´µçš„èµ„æºäº† ğŸ’ã€‚
- en: Other sources
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…¶ä»–æ¥æº
- en: 'Well, here, the web is your ally. You can find anything you want to tie to
    your analyses, from web pages to news, to sounds to real-time data feeds. I would
    not overstate that sky (or your bandwidth ğŸ˜) is the limit! But, let me be very
    pragmatic again and also guide you toward one platform: [Mappillary](https://www.mapillary.com/).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½å§ï¼Œåœ¨è¿™é‡Œï¼Œç½‘ç»œæ˜¯æ‚¨çš„ç›Ÿå‹ã€‚æ‚¨å¯ä»¥æ‰¾åˆ°ä»»ä½•ä¸åˆ†æç›¸å…³çš„ä¿¡æ¯ï¼Œä»ç½‘é¡µåˆ°æ–°é—»ï¼Œå†åˆ°å£°éŸ³å’Œå®æ—¶æ•°æ®æµã€‚æˆ‘ä¸ä¼šå¤¸å¤§åœ°è¯´å¤©ç©ºï¼ˆæˆ–æ‚¨çš„å¸¦å®½ ğŸ˜ï¼‰æ˜¯æé™ï¼ä¸è¿‡ï¼Œè®©æˆ‘å†å®é™…ä¸€ç‚¹ï¼Œå‘æ‚¨æ¨èä¸€ä¸ªå¹³å°ï¼š[Mappillary](https://www.mapillary.com/)ã€‚
- en: Mappillary is a platform that makes street-level images and map data available
    to scale. You can explore it and download some 360Â° imagery and points of interest
    using the Map Explorer.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Mappillary æ˜¯ä¸€ä¸ªæä¾›è¡—æ™¯å›¾åƒå’Œåœ°å›¾æ•°æ®çš„å¹³å°ã€‚æ‚¨å¯ä»¥ä½¿ç”¨åœ°å›¾æµè§ˆå™¨æ¢ç´¢å¹¶ä¸‹è½½ä¸€äº› 360Â° å›¾åƒå’Œå…´è¶£ç‚¹ã€‚
- en: '![](../Images/c741964aa19871f3fa37c13255b83f5d.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c741964aa19871f3fa37c13255b83f5d.png)'
- en: Mapillary database with the provided portal. If you download images, they are
    licensed under [CC-BY-SA](https://help.mapillary.com/hc/en-us/articles/115001770409-Licenses)
    by Mappillary.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Mapillary æ•°æ®åº“é€šè¿‡æä¾›çš„é—¨æˆ·ã€‚å¦‚æœæ‚¨ä¸‹è½½å›¾åƒï¼Œå®ƒä»¬ç”± Mappillary æŒ‰ [CC-BY-SA](https://help.mapillary.com/hc/en-us/articles/115001770409-Licenses)
    è®¸å¯ã€‚
- en: You also have the ability to filter out elements by their class if you want
    to select only some elements of interest or to cross-validate information with
    OSM data, for example.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æƒ³ä»…é€‰æ‹©ä¸€äº›æ„Ÿå…´è¶£çš„å…ƒç´ æˆ–ä¸ OSM æ•°æ®è¿›è¡Œäº¤å‰éªŒè¯ï¼Œæ‚¨è¿˜å¯ä»¥æŒ‰ç±»åˆ«è¿‡æ»¤å…ƒç´ ã€‚
- en: And now, the good news? To follow along the code lines that are coming, I alleviate
    for you the process of getting all of this data that you can find directly in
    this [Data Drive Repository](https://drive.google.com/drive/folders/1HNvEHftS0SlCXESM19xd6onxSAGHy5wE?usp=sharing).
    Once you have what you need in your DATA folder, we can start a nice exploratory
    data analysis.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¥½æ¶ˆæ¯æ¥äº†ï¼ä¸ºäº†è·Ÿéšå³å°†åˆ°æ¥çš„ä»£ç è¡Œï¼Œæˆ‘ä¸ºæ‚¨ç®€åŒ–äº†è·å–è¿™äº›æ•°æ®çš„è¿‡ç¨‹ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨è¿™ä¸ª [æ•°æ®é©±åŠ¨ä»“åº“](https://drive.google.com/drive/folders/1HNvEHftS0SlCXESM19xd6onxSAGHy5wE?usp=sharing)
    ä¸­æ‰¾åˆ°å®ƒä»¬ã€‚ä¸€æ—¦æ‚¨åœ¨æ‚¨çš„ DATA æ–‡ä»¶å¤¹ä¸­æ‹¥æœ‰æ‰€éœ€çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹ä¸€æ¬¡æ„‰å¿«çš„æ¢ç´¢æ€§æ•°æ®åˆ†æã€‚
- en: Step 3\. Exploratory Data Analysis
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ 3 æ­¥ï¼šæ¢ç´¢æ€§æ•°æ®åˆ†æ
- en: '![](../Images/29b3d09b90bbcecf545e99977709bbf0.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29b3d09b90bbcecf545e99977709bbf0.png)'
- en: Step 3\. Exploratory Data Analysis.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ 3 æ­¥ï¼šæ¢ç´¢æ€§æ•°æ®åˆ†æã€‚
- en: At this stage, we have a Python code setup and a data setup, so we are ready
    to activate a deep focus mode with 15 minutes on clock timer âŒš. Indeed, we will
    now explore the various datasets we gathered with Python.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬å·²ç»è®¾ç½®å¥½äº† Python ä»£ç å’Œæ•°æ®ï¼Œå› æ­¤æˆ‘ä»¬å‡†å¤‡å¥½è¿›å…¥æ·±åº¦é›†ä¸­æ¨¡å¼ï¼Œå®šæ—¶å™¨è®¾ç½®ä¸º 15 åˆ†é’Ÿ âŒšã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Python
    æ¢ç´¢æˆ‘ä»¬æ”¶é›†çš„å„ç§æ•°æ®é›†ã€‚
- en: '![](../Images/870384fec802dd5f4dca991f62660903.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/870384fec802dd5f4dca991f62660903.png)'
- en: Loading and Reading 3D Data. We use Open3D (Point Clouds, Mesh, Voxels), RasterIO,
    and Geopandas. Â© F. Poux
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: åŠ è½½å’Œè¯»å– 3D æ•°æ®ã€‚æˆ‘ä»¬ä½¿ç”¨ Open3Dï¼ˆç‚¹äº‘ã€ç½‘æ ¼ã€ä½“ç´ ï¼‰ã€RasterIO å’Œ Geopandasã€‚Â© F. Poux
- en: This means that, for each modality, we will go through reading, profiling, harmonizing,
    and categorizing its content. Often, that means dealing with library bidirectional
    communication. To stay concise, I took the liberty of regrouping some modalities
    together, as shown below.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€ï¼Œå¯¹äºæ¯ç§æ¨¡å¼ï¼Œæˆ‘ä»¬å°†è¿›è¡Œè¯»å–ã€åˆ†æã€åè°ƒå’Œåˆ†ç±»å…¶å†…å®¹ã€‚é€šå¸¸ï¼Œè¿™æ„å‘³ç€å¤„ç†åº“çš„åŒå‘é€šä¿¡ã€‚ä¸ºäº†ä¿æŒç®€æ´ï¼Œæˆ‘æ“…è‡ªå°†ä¸€äº›æ¨¡å¼å½’ä¸ºä¸€ç»„ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/62cbe01ff61228976f10413fc529ff48.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62cbe01ff61228976f10413fc529ff48.png)'
- en: The multiple modalities covered. Â© F. Poux
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶µç›–çš„å¤šç§æ¨¡å¼ã€‚Â© F. Poux
- en: 'Before loading anything, let us import all the libraries installed by writing
    in your notebook/script the following nine lines:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŠ è½½ä»»ä½•å†…å®¹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬é€šè¿‡åœ¨æ‚¨çš„ç¬”è®°æœ¬/è„šæœ¬ä¸­è¾“å…¥ä»¥ä¸‹ä¹è¡Œæ¥å¯¼å…¥æ‰€æœ‰å·²å®‰è£…çš„åº“ï¼š
- en: '[PRE1]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 3D Point Clouds
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D ç‚¹äº‘
- en: 'Let us start with my protÃ©gÃ©s: 3D point clouds. They are essentially a collection
    of points in 3D space that represent a physical object or environment. These points
    are generated from various sources, including LiDAR, photogrammetry, Artificial
    Intelligence (yes, you read well), scanning devices, etc. The first dataset in
    our hands comes from the Aerial LiDAR AHN campaign in the LAZ file format. It
    spans from the LAS LiDAR data Exchange Format (LAS) as its compressed counterpart,
    widely used for storing LiDAR point cloud data. It supports 2D and 3D point data
    and attributes such as intensity and classification. To read the file with Python,
    we use the `laspy` library with its extensions, as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æˆ‘çš„é—¨ç”Ÿå¼€å§‹ï¼š3Dç‚¹äº‘ã€‚å®ƒä»¬æœ¬è´¨ä¸Šæ˜¯ä¸€ç»„åœ¨3Dç©ºé—´ä¸­è¡¨ç¤ºç‰©ç†å¯¹è±¡æˆ–ç¯å¢ƒçš„ç‚¹ã€‚è¿™äº›ç‚¹æ¥è‡ªå„ç§æ¥æºï¼ŒåŒ…æ‹¬LiDARã€æ‘„å½±æµ‹é‡ã€äººå·¥æ™ºèƒ½ï¼ˆæ˜¯çš„ï¼Œä½ æ²¡çœ‹é”™ï¼‰ã€æ‰«æè®¾å¤‡ç­‰ã€‚æˆ‘ä»¬æ‰‹ä¸­çš„ç¬¬ä¸€ä¸ªæ•°æ®é›†æ¥è‡ªAerial
    LiDAR AHNæ´»åŠ¨ï¼Œæ ¼å¼ä¸ºLAZæ–‡ä»¶ã€‚å®ƒä»LAS LiDARæ•°æ®äº¤æ¢æ ¼å¼ï¼ˆLASï¼‰æ‰©å±•è€Œæ¥ï¼Œæ˜¯å­˜å‚¨LiDARç‚¹äº‘æ•°æ®çš„å‹ç¼©å¯¹ç­‰æ ¼å¼ã€‚å®ƒæ”¯æŒ2Då’Œ3Dç‚¹æ•°æ®åŠå…¶å±æ€§ï¼Œå¦‚å¼ºåº¦å’Œåˆ†ç±»ã€‚ä¸ºäº†ç”¨Pythonè¯»å–è¯¥æ–‡ä»¶ï¼Œæˆ‘ä»¬ä½¿ç”¨`laspy`åº“åŠå…¶æ‰©å±•ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE2]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Great! we now have our file loaded in the `las` variable, which we can explore
    quickly using `laspy` functions to get possible attributes, the `max value` of
    the `red` channel, or the projection information:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªå¥½äº†ï¼æˆ‘ä»¬ç°åœ¨å·²ç»å°†æ–‡ä»¶åŠ è½½åˆ°`las`å˜é‡ä¸­ï¼Œå¯ä»¥ä½¿ç”¨`laspy`å‡½æ•°å¿«é€Ÿæ¢ç´¢ï¼Œè·å–å¯èƒ½çš„å±æ€§ã€`red`é€šé“çš„`max value`æˆ–æŠ•å½±ä¿¡æ¯ï¼š
- en: '[PRE3]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This will yield the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†äº§ç”Ÿä»¥ä¸‹ç»“æœï¼š
- en: '[PRE4]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The third line gives us an interesting profile: the data is expressed in `Amersfoort
    / RD New + NAP height` reference system. We note that down for later.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰è¡Œç»™æˆ‘ä»¬ä¸€ä¸ªæœ‰è¶£çš„æ¦‚å†µï¼šæ•°æ®ä»¥`Amersfoort / RD New + NAP height`å‚è€ƒç³»ç»Ÿè¡¨ç¤ºã€‚æˆ‘ä»¬è®°ä¸‹æ¥ä»¥å¤‡åç”¨ã€‚
- en: 'ğŸ¦Š **Florent***: As you can see, the first line gives us several attributes
    for later use. This is nice that, by default, we can store so much information
    in a semi-structured way. However, we need to sort out the relevancy of this information;
    usually, we default to using* `*X*`*,*`*Y*`*,*`*Z*`*,* `*intensity*`*,* `*red*`*,*
    `*green*`*,* `*blue*`*. I would call the other one''s bonuses* ğŸ˜*.*'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent**ï¼šå¦‚ä½ æ‰€è§ï¼Œç¬¬ä¸€è¡Œç»™äº†æˆ‘ä»¬å‡ ä¸ªåç»­ä½¿ç”¨çš„å±æ€§ã€‚å¾ˆé«˜å…´é»˜è®¤æƒ…å†µä¸‹æˆ‘ä»¬å¯ä»¥ä»¥åŠç»“æ„åŒ–çš„æ–¹å¼å­˜å‚¨è¿™ä¹ˆå¤šä¿¡æ¯ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬éœ€è¦æ•´ç†è¿™äº›ä¿¡æ¯çš„ç›¸å…³æ€§ï¼›é€šå¸¸æˆ‘ä»¬é»˜è®¤ä½¿ç”¨`*X*`ã€`*Y*`ã€`*Z*`ã€`*intensity*`ã€`*red*`ã€`*green*`ã€`*blue*`ã€‚æˆ‘ä¼šæŠŠå…¶ä»–çš„ç§°ä¸ºé¢å¤–çš„å¥–åŠ±ğŸ˜ã€‚
- en: 'At this stage, we have no natural way to visualize if the data is correct;
    we have to transform it into our beloved `numpy` object, which we can after that
    convert to an `open3d` point cloud object to close the loop of switching between
    libraries. First, we convert some `laspy` object attributes to `coords` and `colors`
    numpy objects to hold our point cloud coordinates `X`,`Y`, `Z` and our point cloud
    colors:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬æ²¡æœ‰è‡ªç„¶çš„æ–¹æ³•æ¥å¯è§†åŒ–æ•°æ®æ˜¯å¦æ­£ç¡®ï¼›æˆ‘ä»¬å¿…é¡»å°†å…¶è½¬æ¢ä¸ºæˆ‘ä»¬å–œçˆ±çš„`numpy`å¯¹è±¡ï¼Œç„¶åå†è½¬æ¢ä¸º`open3d`ç‚¹äº‘å¯¹è±¡ï¼Œä»¥å®Œæˆåº“ä¹‹é—´çš„åˆ‡æ¢ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä¸€äº›`laspy`å¯¹è±¡å±æ€§è½¬æ¢ä¸º`coords`å’Œ`colors`
    numpyå¯¹è±¡ï¼Œä»¥ä¿å­˜æˆ‘ä»¬çš„ç‚¹äº‘åæ ‡`X`ã€`Y`ã€`Z`ä»¥åŠç‚¹äº‘é¢œè‰²ï¼š
- en: '[PRE5]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Then we transform our numpy object into an `open3d` object to visualize the
    point cloud. Unfortunately, no direct way from `laspy` exists, yet ğŸ˜.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†numpyå¯¹è±¡è½¬æ¢ä¸º`open3d`å¯¹è±¡ä»¥å¯è§†åŒ–ç‚¹äº‘ã€‚ä¸å¹¸çš„æ˜¯ï¼Œä»`laspy`åˆ°`open3d`æ²¡æœ‰ç›´æ¥çš„æ–¹æ³•ï¼Œå°½ç®¡æœ‰ğŸ˜ã€‚
- en: '[PRE6]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'ğŸ¦Š **Florent***: This is a great exercise to see that switching libraries almost
    always comes down to losing some processing time between conversions and also
    exposes to possible memory errors. Therefore, always using a limited number of
    libraries is my advice when dealing with complex datasets and workflows.*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent**ï¼šè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ç»ƒä¹ ï¼Œå¯ä»¥çœ‹åˆ°åˆ‡æ¢åº“å‡ ä¹æ€»æ˜¯ä¼šå¯¼è‡´åœ¨è½¬æ¢ä¹‹é—´ä¸¢å¤±ä¸€äº›å¤„ç†æ—¶é—´ï¼Œå¹¶ä¸”ä¹Ÿæš´éœ²å‡ºå¯èƒ½çš„å†…å­˜é”™è¯¯ã€‚å› æ­¤ï¼Œå½“å¤„ç†å¤æ‚çš„æ•°æ®é›†å’Œå·¥ä½œæµç¨‹æ—¶ï¼Œæˆ‘å»ºè®®æ€»æ˜¯ä½¿ç”¨æœ‰é™æ•°é‡çš„åº“ã€‚*
- en: '![](../Images/7e22090797ec2e060ff410aafd2c3b76.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e22090797ec2e060ff410aafd2c3b76.png)'
- en: 3D Point Cloud Dataset visualized in Open3D. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Open3Dä¸­å¯è§†åŒ–çš„3Dç‚¹äº‘æ•°æ®é›†ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'You can now visualize the full LiDAR point cloud within Python nicely, on par
    with professional software! Let us now load another point cloud to explore another
    widely used file format: `.ply`. The PLY format is used to store 3D mesh data
    along with attributes like color and normals. It is also suitable for point clouds
    with additional information.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å¯ä»¥åœ¨Pythonä¸­å¾ˆæ¼‚äº®åœ°å¯è§†åŒ–å®Œæ•´çš„LiDARç‚¹äº‘ï¼Œåª²ç¾ä¸“ä¸šè½¯ä»¶ï¼è®©æˆ‘ä»¬åŠ è½½å¦ä¸€ä¸ªç‚¹äº‘ï¼Œä»¥æ¢ç´¢å¦ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„æ–‡ä»¶æ ¼å¼ï¼š`.ply`ã€‚PLYæ ¼å¼ç”¨äºå­˜å‚¨3Dç½‘æ ¼æ•°æ®åŠå…¶å±æ€§ï¼Œå¦‚é¢œè‰²å’Œæ³•çº¿ã€‚å®ƒä¹Ÿé€‚ç”¨äºå¸¦æœ‰é™„åŠ ä¿¡æ¯çš„ç‚¹äº‘ã€‚
- en: 'With `open3d`, this is super simple; you can execute the following code to
    fill the `pcd_itc` variable with the point cloud, and the `o3d.visualization`
    function to draw the point cloud:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`open3d`ï¼Œè¿™éå¸¸ç®€å•ï¼›ä½ å¯ä»¥æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼Œå°†ç‚¹äº‘å¡«å……åˆ°`pcd_itc`å˜é‡ä¸­ï¼Œå¹¶ä½¿ç”¨`o3d.visualization`å‡½æ•°ç»˜åˆ¶ç‚¹äº‘ï¼š
- en: '[PRE7]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/75dd922b578e733201d3335ab0d27f5e.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75dd922b578e733201d3335ab0d27f5e.png)'
- en: 3D Indoor Point Cloud visualized in Open3D. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Open3Dä¸­å¯è§†åŒ–çš„3Då®¤å†…ç‚¹äº‘ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: This point cloud does not show any metadata information, which means that we
    will consider that it is expressed in a local reference system that will need
    to be registered somehow to a reference dataset.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç‚¹äº‘æ²¡æœ‰æ˜¾ç¤ºä»»ä½•å…ƒæ•°æ®ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å°†è®¤ä¸ºå®ƒä»¥æœ¬åœ°å‚è€ƒç³»ç»Ÿè¡¨ç¤ºï¼Œéœ€è¦ä»¥æŸç§æ–¹å¼ä¸å‚è€ƒæ•°æ®é›†è¿›è¡Œé…å‡†ã€‚
- en: 'ğŸ¦Š**Florent**: *Spoiler alert! Point cloud dataset is like a special central
    rock, especially dealing with multiple modalities. Indeed, as I will show later,
    it can act as the canonical reference to then link all the other datasets to it.
    I warned you of the spoiler!*'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦Š**Florent**: *å‰§é€è­¦å‘Šï¼ç‚¹äº‘æ•°æ®é›†å°±åƒä¸€ä¸ªç‰¹æ®Šçš„ä¸­å¿ƒå²©çŸ³ï¼Œå°¤å…¶åœ¨å¤„ç†å¤šæ¨¡æ€æ•°æ®æ—¶ã€‚å®é™…ä¸Šï¼Œæ­£å¦‚æˆ‘ç¨åå°†å±•ç¤ºçš„ï¼Œå®ƒå¯ä»¥ä½œä¸ºæ ‡å‡†å‚è€ƒï¼Œå°†æ‰€æœ‰å…¶ä»–æ•°æ®é›†ä¸ä¹‹å…³è”ã€‚æˆ‘å·²ç»æé†’è¿‡ä½ æœ‰å‰§é€äº†ï¼*'
- en: Time to move on 3D voxels ğŸ§Š
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯æ—¶å€™è½¬å‘3Dä½“ç´ ğŸ§Š
- en: 3D Voxels
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3Dä½“ç´ 
- en: 'Voxels are another type of 3D data format. Voxels are essentially 3D pixels
    that represent a volume of space. They are plain fun, and you can check their
    plain usefulness in the following case studies:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ä½“ç´ æ˜¯å¦ä¸€ç§3Dæ•°æ®æ ¼å¼ã€‚ä½“ç´ æœ¬è´¨ä¸Šæ˜¯è¡¨ç¤ºç©ºé—´ä½“ç§¯çš„3Dåƒç´ ã€‚å®ƒä»¬éå¸¸æœ‰è¶£ï¼Œä½ å¯ä»¥åœ¨ä»¥ä¸‹æ¡ˆä¾‹ç ”ç©¶ä¸­æŸ¥çœ‹å®ƒä»¬çš„å®é™…ç”¨é€”ï¼š
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## 3D Pythonå·¥ä½œæµç”¨äºLiDARåŸå¸‚æ¨¡å‹ï¼šä¸€æ­¥ä¸€æ­¥çš„æŒ‡å—'
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Pythonâ€¦
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è§£é”3DåŸå¸‚å»ºæ¨¡åº”ç”¨çš„æœ€ç»ˆæŒ‡å—ã€‚è¯¥æ•™ç¨‹æ¶µç›–äº†Pythonâ€¦â€¦
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [](/how-to-automate-voxel-modelling-of-3d-point-cloud-with-python-459f4d43a227?source=post_page-----7ef8ef14589a--------------------------------)
    [## How to Automate Voxel Modelling of 3D Point Cloud with Python
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [](/how-to-automate-voxel-modelling-of-3d-point-cloud-with-python-459f4d43a227?source=post_page-----7ef8ef14589a--------------------------------)
    [## å¦‚ä½•ä½¿ç”¨Pythonè‡ªåŠ¨åŒ–3Dç‚¹äº‘çš„ä½“ç´ å»ºæ¨¡
- en: Hands-on tutorial to turn large point clouds into 3D voxels ğŸ§Š with Python and
    open3d. Unlock an automation workflowâ€¦
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å®ç”¨æ•™ç¨‹ï¼Œå°†å¤§å‹ç‚¹äº‘è½¬æ¢ä¸º3Dä½“ç´ ğŸ§Šï¼Œä½¿ç”¨Pythonå’Œopen3dã€‚è§£é”è‡ªåŠ¨åŒ–å·¥ä½œæµâ€¦â€¦
- en: towardsdatascience.com](/how-to-automate-voxel-modelling-of-3d-point-cloud-with-python-459f4d43a227?source=post_page-----7ef8ef14589a--------------------------------)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-automate-voxel-modelling-of-3d-point-cloud-with-python-459f4d43a227?source=post_page-----7ef8ef14589a--------------------------------)
- en: 'ğŸ¦ **Pirouz**: *Voxels are pretty much like LEGO models. Check out this paper
    about voxelization of spatial data and getting serious with digital LEGO:* [*Voxelization
    Algorithms for Geospatial Applications*](https://www.researchgate.net/publication/290507635_Voxelization_Algorithms_for_Geospatial_Applications)
    *(ResearchGate). If you canâ€™t get enough of voxels? Then search Google for â€œvoxel
    artâ€ and check out the library* [*topoGenesis*](https://github.com/shervinazadi/topogenesis/)
    *(GitHub).*'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦ **Pirouz**: *ä½“ç´ éå¸¸åƒä¹é«˜æ¨¡å‹ã€‚æŸ¥çœ‹è¿™ç¯‡å…³äºç©ºé—´æ•°æ®ä½“ç´ åŒ–å¹¶æ·±å…¥ç ”ç©¶æ•°å­—ä¹é«˜çš„è®ºæ–‡ï¼š* [*åœ°ç†ç©ºé—´åº”ç”¨çš„ä½“ç´ åŒ–ç®—æ³•*](https://www.researchgate.net/publication/290507635_Voxelization_Algorithms_for_Geospatial_Applications)
    *(ResearchGate)ã€‚å¦‚æœä½ å¯¹ä½“ç´ æƒ…æœ‰ç‹¬é’Ÿï¼Ÿé‚£ä¹ˆåœ¨Googleä¸Šæœç´¢â€œä½“ç´ è‰ºæœ¯â€ï¼Œå¹¶æŸ¥çœ‹åº“* [*topoGenesis*](https://github.com/shervinazadi/topogenesis/)
    *(GitHub)ã€‚*'
- en: 'Now, we will read and visualize the voxel dataset with the following code lines:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ä»£ç è¡Œè¯»å–å’Œå¯è§†åŒ–ä½“ç´ æ•°æ®é›†ï¼š
- en: '[PRE8]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/6bf16433b5524924f2cd62af7adf0c52.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6bf16433b5524924f2cd62af7adf0c52.png)'
- en: 3D Voxel Dataset visualized in Open3D. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Open3Dä¸­å¯è§†åŒ–çš„3Dä½“ç´ æ•°æ®é›†ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: At this stage, we read, profiled, and made sure that we had a way to deal with
    all this data with a single library for processing (`numpy`) and one for 3D visualization
    (`open3d`).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªé˜¶æ®µï¼Œæˆ‘ä»¬é˜…è¯»ã€åˆ†æï¼Œå¹¶ç¡®ä¿æœ‰ä¸€ä¸ªå•ä¸€çš„åº“æ¥å¤„ç†æ‰€æœ‰è¿™äº›æ•°æ®ï¼ˆ`numpy`ï¼‰å’Œä¸€ä¸ªç”¨äº3Då¯è§†åŒ–çš„åº“ï¼ˆ`open3d`ï¼‰ã€‚
- en: Time to get city models in our Python experiments ğŸ˜
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯æ—¶å€™åœ¨æˆ‘ä»¬çš„Pythonå®éªŒä¸­åŠ å…¥åŸå¸‚æ¨¡å‹äº†ğŸ˜
- en: City Models
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŸå¸‚æ¨¡å‹
- en: 'Models of Cities often follow a standard of expression: CityGML models. CityGML
    is an XML-based data format used to represent the 3D geometry of urban environments.
    CityGML models can include information about buildings, roads, bridges, and other
    infrastructure. City planners, architects, and engineers often use these models
    to simulate and analyze urban environments. An excellent place to get yours, which
    I did not mention on purpose before, is this GitHub repository curated by my colleague
    Olaf (Any Frozen reference forbidden â›„): [CityGML Models](https://github.com/OloOcki/awesome-citygml).'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå¸‚æ¨¡å‹é€šå¸¸éµå¾ªä¸€ç§è¡¨è¾¾æ ‡å‡†ï¼šCityGML æ¨¡å‹ã€‚CityGML æ˜¯ä¸€ç§åŸºäº XML çš„æ•°æ®æ ¼å¼ï¼Œç”¨äºè¡¨ç¤ºåŸå¸‚ç¯å¢ƒçš„ä¸‰ç»´å‡ ä½•ã€‚CityGML æ¨¡å‹å¯ä»¥åŒ…å«æœ‰å…³å»ºç­‘ç‰©ã€é“è·¯ã€æ¡¥æ¢å’Œå…¶ä»–åŸºç¡€è®¾æ–½çš„ä¿¡æ¯ã€‚åŸå¸‚è§„åˆ’å¸ˆã€å»ºç­‘å¸ˆå’Œå·¥ç¨‹å¸ˆå¸¸å¸¸ä½¿ç”¨è¿™äº›æ¨¡å‹æ¥æ¨¡æ‹Ÿå’Œåˆ†æåŸå¸‚ç¯å¢ƒã€‚ä¸€ä¸ªä¼˜ç§€çš„è·å–åœ°ç‚¹ï¼Œæˆ‘ä¹‹å‰æ•…æ„æ²¡æœ‰æåˆ°çš„ï¼Œæ˜¯ç”±æˆ‘çš„åŒäº‹
    Olaf ç²¾å¿ƒç­–åˆ’çš„ GitHub ä»“åº“ï¼ˆä»»ä½•å†°é›ªå¥‡ç¼˜çš„å¼•ç”¨ç¦æ­¢ â›„ï¼‰ï¼š[CityGML Models](https://github.com/OloOcki/awesome-citygml)ã€‚
- en: 'ğŸ¦Š **Florent**: *Basically, in Python, we have to make sure to convert these
    models to 3D meshes while keeping any wanted semantic / topology or other information.
    A friendly Python tool, again by* [*TUM*](https://www.asg.ed.tum.de/en/gis/home/)*,
    is available here:* [*citygml2obj*](https://github.com/tum-gis/CityGML2OBJv2)*.
    But I did the heavy lifting for you if you use the data, thus moving on to the
    next reading modality: 3D meshes.*'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦Š **Florent**: *åŸºæœ¬ä¸Šï¼Œåœ¨ Python ä¸­ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿å°†è¿™äº›æ¨¡å‹è½¬æ¢ä¸ºä¸‰ç»´ç½‘æ ¼ï¼ŒåŒæ—¶ä¿ç•™æ‰€éœ€çš„è¯­ä¹‰/æ‹“æ‰‘æˆ–å…¶ä»–ä¿¡æ¯ã€‚ä¸€ä¸ªå‹å¥½çš„ Python
    å·¥å…·ï¼ŒåŒæ ·ç”±* [*TUM*](https://www.asg.ed.tum.de/en/gis/home/)* æä¾›ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ï¼š* [*citygml2obj*](https://github.com/tum-gis/CityGML2OBJv2)*ã€‚ä½†å¦‚æœä½ ä½¿ç”¨æ•°æ®ï¼Œæˆ‘å·²ç»ä¸ºä½ å®Œæˆäº†ç¹é‡çš„å·¥ä½œï¼Œå› æ­¤ç»§ç»­é˜…è¯»ä¸‹ä¸€ä¸ªé˜…è¯»æ–¹å¼ï¼šä¸‰ç»´ç½‘æ ¼ã€‚*'
- en: 3D Mesh
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D ç½‘æ ¼
- en: Next, letâ€™s talk about meshes. Triangular meshes are constituted of vertices,
    edges that bind vertices, and triangular faces that finish the â€œenvelopeâ€ of objects.
    They allow us to depict the shape of a 3D object. Meshes can be created using
    3D modeling software or generated from point clouds, city models using specialized
    algorithms, or even Artificial Intelligence! The dataset is in an OBJ format commonly
    used to export 3D mesh models representing geometry and texture coordinates.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬è°ˆè°ˆç½‘æ ¼ã€‚ä¸‰è§’ç½‘æ ¼ç”±é¡¶ç‚¹ã€è¿æ¥é¡¶ç‚¹çš„è¾¹ç¼˜å’Œå®Œæˆå¯¹è±¡â€œåŒ…ç»œâ€çš„ä¸‰è§’é¢ç»„æˆã€‚å®ƒä»¬ä½¿æˆ‘ä»¬èƒ½å¤Ÿæç»˜ä¸‰ç»´ç‰©ä½“çš„å½¢çŠ¶ã€‚ç½‘æ ¼å¯ä»¥ä½¿ç”¨ä¸‰ç»´å»ºæ¨¡è½¯ä»¶åˆ›å»ºï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç‚¹äº‘ã€åŸå¸‚æ¨¡å‹å’Œä¸“ç”¨ç®—æ³•ç”Ÿæˆï¼Œç”šè‡³æ˜¯äººå·¥æ™ºèƒ½ï¼æ•°æ®é›†é‡‡ç”¨
    OBJ æ ¼å¼ï¼Œé€šå¸¸ç”¨äºå¯¼å‡ºè¡¨ç¤ºå‡ ä½•ä½“å’Œçº¹ç†åæ ‡çš„ä¸‰ç»´ç½‘æ ¼æ¨¡å‹ã€‚
- en: 'ğŸ¦ **Pirouz**: *If you want to know why these fancy words are used instead of
    points, lines, and polygons, you need to learn a bit more about another fancy
    word:* ***topology****.*'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦ **Pirouz**: *å¦‚æœä½ æƒ³çŸ¥é“ä¸ºä»€ä¹ˆè¿™äº›èŠ±å“¨çš„è¯æ±‡è¢«ç”¨æ¥ä»£æ›¿ç‚¹ã€çº¿å’Œå¤šè¾¹å½¢ï¼Œä½ éœ€è¦å¤šäº†è§£ä¸€ç‚¹å¦ä¸€ä¸ªèŠ±å“¨çš„è¯æ±‡ï¼š***æ‹“æ‰‘****ã€‚*'
- en: 'ğŸ¦Š **Florent**: *You can read a story about topology written by Pirouz which
    may well be one of the easiest story about topology:* [*Rudiments of Geometry
    and Topology*](https://www.researchgate.net/publication/344297280_Rudiments_of_Geometry_and_Topology_for_Computational_Design)
    *(ResearchGate)*'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦Š **Florent**: *ä½ å¯ä»¥é˜…è¯» Pirouz å†™çš„å…³äºæ‹“æ‰‘çš„æ•…äº‹ï¼Œè¿™å¯èƒ½æ˜¯æœ€ç®€å•çš„æ‹“æ‰‘æ•…äº‹ä¹‹ä¸€ï¼š* [*å‡ ä½•å’Œæ‹“æ‰‘åŸºç¡€*](https://www.researchgate.net/publication/344297280_Rudiments_of_Geometry_and_Topology_for_Computational_Design)
    *(ResearchGate)*'
- en: 'To load the mesh and get its extent, we will write the following lines:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åŠ è½½ç½‘æ ¼å¹¶è·å–å…¶èŒƒå›´ï¼Œæˆ‘ä»¬å°†ç¼–å†™ä»¥ä¸‹å‡ è¡Œï¼š
- en: '[PRE9]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: And we see from the output that we have coordinates that span closely to what
    Amersfoort / RD New gives. This is comforting; we now have another dataset in
    this reference system.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¾“å‡ºä¸­æˆ‘ä»¬çœ‹åˆ°åæ ‡æ¥è¿‘äº Amersfoort / RD New æ‰€æä¾›çš„ã€‚è¿™ä»¤äººæ¬£æ…°ï¼›æˆ‘ä»¬ç°åœ¨åœ¨è¿™ä¸ªå‚è€ƒç³»ç»Ÿä¸­æœ‰äº†å¦ä¸€ä¸ªæ•°æ®é›†ã€‚
- en: 'From there, to visualize the mesh, we first compute some vertex normals and
    use the same visualization function from open3d to visualize it:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œå¼€å§‹ï¼Œä¸ºäº†å¯è§†åŒ–ç½‘æ ¼ï¼Œæˆ‘ä»¬é¦–å…ˆè®¡ç®—ä¸€äº›é¡¶ç‚¹æ³•çº¿ï¼Œå¹¶ä½¿ç”¨ open3d çš„ç›¸åŒå¯è§†åŒ–å‡½æ•°æ¥è¿›è¡Œå¯è§†åŒ–ï¼š
- en: '[PRE10]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: On the 3D side, we are good to go! Let us explore our Spatial Rasters with Python
    and rasterio
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‰ç»´æ–¹é¢ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹äº†ï¼è®©æˆ‘ä»¬ç”¨ Python å’Œ rasterio æ¢ç´¢æˆ‘ä»¬çš„ç©ºé—´æ …æ ¼ã€‚
- en: Spatial Imagery
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç©ºé—´å½±åƒ
- en: 'Our imagery is in the GeoTIFF format, an extension of the TIFF format that
    includes geospatial metadata, making it ideal for raster elevation data (DSM/DTM)
    and imagery. To open and profile the spatial imagery that we have, we simply use
    the following lines of code using rasterio:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„å½±åƒé‡‡ç”¨ GeoTIFF æ ¼å¼ï¼Œè¿™æ˜¯ TIFF æ ¼å¼çš„æ‰©å±•ï¼ŒåŒ…å«åœ°ç†ç©ºé—´å…ƒæ•°æ®ï¼Œé€‚ç”¨äºæ …æ ¼é«˜ç¨‹æ•°æ®ï¼ˆDSM/DTMï¼‰å’Œå½±åƒã€‚è¦æ‰“å¼€å’Œåˆ†ææˆ‘ä»¬æ‹¥æœ‰çš„ç©ºé—´å½±åƒï¼Œæˆ‘ä»¬åªéœ€ä½¿ç”¨
    rasterio çš„ä»¥ä¸‹ä»£ç è¡Œï¼š
- en: '[PRE11]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This results in the following output:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š
- en: '[PRE12]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Interestingly, we get a clear detail that it is an image of `20002x25002`, with
    three channels (`R`,`G`, and `B`) expressed in the `CRS 28992`, which corresponds
    to Amersfoort again! This is great!
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°è¿™æ˜¯ä¸€ä¸ª`20002x25002`çš„å›¾åƒï¼Œå…·æœ‰ä¸‰ä¸ªé€šé“ï¼ˆ`R`ã€`G`å’Œ`B`ï¼‰ï¼Œå…¶è¡¨è¾¾åœ¨`CRS 28992`ä¸­ï¼Œè¿™å†æ¬¡å¯¹åº”äºAmersfoortï¼è¿™å¤ªæ£’äº†ï¼
- en: 'Now, to plot with numpy and matplotlib, below is the tiniest possible line
    of code to get an image with numpy, avoiding Memory errors, with a result shown
    afterward:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œä¸ºäº†ä½¿ç”¨numpyå’Œmatplotlibç»˜å›¾ï¼Œä¸‹é¢æ˜¯è·å–å›¾åƒçš„æœ€å°ä»£ç è¡Œï¼Œä»¥é¿å…å†…å­˜é”™è¯¯ï¼Œç»“æœå¦‚å›¾æ‰€ç¤ºï¼š
- en: '[PRE13]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In parallel, rasterio also provides `[show()](https://rasterio.readthedocs.io/en/latest/api/rasterio.plot.html#rasterio.plot.show)`
    function to perform everyday tasks such as displaying multi-band images as RGB
    and labeling the axes with proper geo-referenced extents. This permits to simplify
    the plot, as expressed below:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ­¤åŒæ—¶ï¼Œrasterioè¿˜æä¾›äº†`[show()](https://rasterio.readthedocs.io/en/latest/api/rasterio.plot.html#rasterio.plot.show)`å‡½æ•°ï¼Œä»¥æ‰§è¡Œæ—¥å¸¸ä»»åŠ¡ï¼Œä¾‹å¦‚å°†å¤šæ³¢æ®µå›¾åƒæ˜¾ç¤ºä¸ºRGBï¼Œå¹¶ç”¨é€‚å½“çš„åœ°ç†å‚è€ƒèŒƒå›´æ ‡è®°åæ ‡è½´ã€‚è¿™ä½¿å¾—ç»˜å›¾å˜å¾—æ›´åŠ ç®€å•ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE14]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/55fd9e9d40f9a3756281b73957fbab92.png)![](../Images/989cb39b502ebe4f1a95935a2a64e5ce.png)![](../Images/02e48e5a69ee893ff38c345bd5017826.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55fd9e9d40f9a3756281b73957fbab92.png)![](../Images/989cb39b502ebe4f1a95935a2a64e5ce.png)![](../Images/02e48e5a69ee893ff38c345bd5017826.png)'
- en: Various raster visualized with plot functions from matplotlib and rasterio.
    Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨matplotlibå’Œrasterioçš„ç»˜å›¾å‡½æ•°å¯è§†åŒ–çš„å„ç§å…‰æ …ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: This is superb! We have several 3D datasets (3D point clouds, voxels, 3D meshes)
    and satellite imagery (both infrared and R, G,B) that we could both handle with
    numpy and express for most of them in one common CRS. Let us move to other rasters
    focusing on elevation data (2.5D).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœŸæ˜¯å¤ªæ£’äº†ï¼æˆ‘ä»¬æœ‰å¤šä¸ª3Dæ•°æ®é›†ï¼ˆ3Dç‚¹äº‘ã€ä½“ç´ ã€3Dç½‘æ ¼ï¼‰å’Œå«æ˜Ÿå›¾åƒï¼ˆåŒ…æ‹¬çº¢å¤–å’ŒRã€Gã€Bï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨numpyå¤„ç†è¿™äº›æ•°æ®ï¼Œå¹¶ä¸”å¤§å¤šæ•°å¯ä»¥ç”¨ä¸€ä¸ªé€šç”¨CRSè¡¨ç¤ºã€‚è®©æˆ‘ä»¬è½¬å‘å…¶ä»–å…‰æ …ï¼Œé‡ç‚¹å…³æ³¨é«˜ç¨‹æ•°æ®ï¼ˆ2.5Dï¼‰ã€‚
- en: Elevation Rasters (DSM, DTM)
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é«˜ç¨‹å…‰æ …ï¼ˆDSMï¼ŒDTMï¼‰
- en: 'Elevation models are usually found as raster files, where each pixel has a
    value that can be translated to its elevation. This is why we call that 2.5D data
    as it is a pure top-down or single point of view, also tagged depth image when
    out of any GIS projection system. We can import elevation models with the same
    code line:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: é«˜ç¨‹æ¨¡å‹é€šå¸¸ä»¥å…‰æ …æ–‡ä»¶çš„å½¢å¼å‡ºç°ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ éƒ½æœ‰ä¸€ä¸ªå¯ä»¥è½¬æ¢ä¸ºå…¶é«˜ç¨‹çš„å€¼ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ç§°ä¹‹ä¸º2.5Dæ•°æ®ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªçº¯ç²¹çš„ä¿¯è§†å›¾æˆ–å•ç‚¹è§†è§’ï¼Œå½“å®ƒä¸åœ¨ä»»ä½•GISæŠ•å½±ç³»ç»Ÿä¸­æ—¶ä¹Ÿç§°ä¸ºæ·±åº¦å›¾åƒã€‚æˆ‘ä»¬å¯ä»¥ç”¨ç›¸åŒçš„ä»£ç è¡Œå¯¼å…¥é«˜ç¨‹æ¨¡å‹ï¼š
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now that we have a `dtm` variable that holds the elevation data, we extract
    its metadata on the whole with `dtm.meta`, or more specialized with `dtm.shape`,
    `dtm.crs`, `dtm.bounds`, `dtm.overviews(1)`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªä¿å­˜äº†é«˜ç¨‹æ•°æ®çš„`dtm`å˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡`dtm.meta`æå–å…¶æ•´ä½“å…ƒæ•°æ®ï¼Œæˆ–è€…æ›´ä¸“ä¸šåœ°ä½¿ç”¨`dtm.shape`ã€`dtm.crs`ã€`dtm.bounds`ã€`dtm.overviews(1)`ï¼š
- en: '[PRE16]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This brings us to the following result:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™æˆ‘ä»¬å¸¦æ¥äº†ä»¥ä¸‹ç»“æœï¼š
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: And again, it is interesting to see that we have the same CRS Amersfoort / RD
    New for this dataset.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ä»¤äººæ„Ÿå…´è¶£çš„æ˜¯ï¼Œæˆ‘ä»¬çœ‹åˆ°è¿™ä¸ªæ•°æ®é›†ä½¿ç”¨çš„æ˜¯ç›¸åŒçš„CRS Amersfoort / RD Newã€‚
- en: 'To get a plot and a sense of what we are dealing with, we can transform the
    dataset to a numpy array and use indexing to select part of it in a selection
    variable:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç»˜åˆ¶å›¾å½¢å¹¶äº†è§£æˆ‘ä»¬æ­£åœ¨å¤„ç†çš„å†…å®¹ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®é›†è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œå¹¶ä½¿ç”¨ç´¢å¼•é€‰æ‹©å…¶ä¸­çš„ä¸€éƒ¨åˆ†åˆ°é€‰æ‹©å˜é‡ä¸­ï¼š
- en: '[PRE18]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, we plot using the two ways: `rasterio` and `matplotlib` both the full-scale
    dataset and the zoomed-in selection:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸¤ç§æ–¹å¼ç»˜å›¾ï¼š`rasterio`å’Œ`matplotlib`ï¼Œåˆ†åˆ«ç»˜åˆ¶å…¨å°ºåº¦æ•°æ®é›†å’Œæ”¾å¤§çš„é€‰æ‹©åŒºåŸŸï¼š
- en: '[PRE19]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/f9a8eddbdb97ba300eb28ac36f41db09.png)![](../Images/0891a307d2bcc019a56d4f25e6b0ef3b.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9a8eddbdb97ba300eb28ac36f41db09.png)![](../Images/0891a307d2bcc019a56d4f25e6b0ef3b.png)'
- en: DTM plot with RasterIO and matplotlib. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨RasterIOå’Œmatplotlibç»˜åˆ¶çš„DTMå›¾ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Finally, we cannot discuss raster datasets without diving into vector spatial
    data.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬ä¸èƒ½åœ¨ä¸æ·±å…¥æ¢è®¨çŸ¢é‡ç©ºé—´æ•°æ®çš„æƒ…å†µä¸‹è®¨è®ºå…‰æ …æ•°æ®é›†ã€‚
- en: Spatial Vector Data
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç©ºé—´çŸ¢é‡æ•°æ®
- en: At this stage, it is essential to clarify once and for all that, if you find
    pixels, you are not speaking about vector data. Instead, vector datasets are made
    of vertices and paths, which are available as points (X, Y coordinates), lines
    (they connect these points now tagged vertices), and polygons (connect vertices
    to close a path made of lines).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªé˜¶æ®µï¼Œå¿…é¡»ä¸€æ¬¡æ€§æ˜ç¡®ï¼Œå¦‚æœä½ çœ‹åˆ°çš„æ˜¯åƒç´ ï¼Œé‚£ä¹ˆä½ å¹¶ä¸æ˜¯åœ¨è°ˆè®ºçŸ¢é‡æ•°æ®ã€‚ç›¸åï¼ŒçŸ¢é‡æ•°æ®é›†ç”±é¡¶ç‚¹å’Œè·¯å¾„ç»„æˆï¼Œè¿™äº›é¡¶ç‚¹å’Œè·¯å¾„ä»¥ç‚¹ï¼ˆXï¼ŒYåæ ‡ï¼‰ã€çº¿ï¼ˆè¿æ¥è¿™äº›æ ‡è®°çš„é¡¶ç‚¹ï¼‰å’Œå¤šè¾¹å½¢ï¼ˆè¿æ¥é¡¶ç‚¹ä»¥é—­åˆç”±çº¿ç»„æˆçš„è·¯å¾„ï¼‰çš„å½¢å¼å­˜åœ¨ã€‚
- en: '![](../Images/55bed353a01d2e175b0cb890bd079743.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55bed353a01d2e175b0cb890bd079743.png)'
- en: Vector Data in GIS Systems. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: GISç³»ç»Ÿä¸­çš„çŸ¢é‡æ•°æ®ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'ğŸŒ± **Growing**: *Having that in mind, where does your intuition place 3D point
    clouds? Voxel models? 3D meshes? These are interesting questions with profound
    implications, but nice to situate better how 2D stands with a 3D synergy*.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸŒ± **æˆé•¿**ï¼š*è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œä½ çš„ç›´è§‰æŠŠ 3D ç‚¹äº‘æ”¾åœ¨å“ªé‡Œï¼Ÿä½“ç´ æ¨¡å‹ï¼Ÿ3D ç½‘æ ¼ï¼Ÿè¿™äº›éƒ½æ˜¯æœ‰æ·±è¿œæ„ä¹‰çš„æœ‰è¶£é—®é¢˜ï¼Œä½†æœ‰åŠ©äºæ›´å¥½åœ°å®šä½ 2D ä¸ 3D
    çš„ååŒä½œç”¨*ã€‚
- en: Interestingly, cartographers (but not only) use these as â€œsymbolsâ€ to depict
    real-world components in maps. This means that they constantly have to determine
    a â€œLevel of Detailâ€ (LoD) that the entity represents, and this gives so much symbolic
    power to these entities (a point can be a country, or a town, or a citizen, or
    a specific place, â€¦).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„æ˜¯ï¼Œåˆ¶å›¾å¸ˆï¼ˆä¸ä»…ä»…æ˜¯åˆ¶å›¾å¸ˆï¼‰å°†è¿™äº›ç”¨ä½œâ€œç¬¦å·â€æ¥åœ¨åœ°å›¾ä¸Šæç»˜ç°å®ä¸–ç•Œçš„ç»„ä»¶ã€‚è¿™æ„å‘³ç€ä»–ä»¬å¿…é¡»ä¸æ–­ç¡®å®šå®ä½“æ‰€ä»£è¡¨çš„â€œè¯¦ç»†ç¨‹åº¦â€ (LoD)ï¼Œè¿™èµ‹äºˆè¿™äº›å®ä½“å¦‚æ­¤å¤šçš„ç¬¦å·æ„ä¹‰ï¼ˆä¸€ä¸ªç‚¹å¯ä»¥æ˜¯ä¸€ä¸ªå›½å®¶ã€ä¸€ä¸ªåŸå¸‚ã€ä¸€ä¸ªå…¬æ°‘æˆ–ä¸€ä¸ªç‰¹å®šåœ°ç‚¹ï¼Œâ€¦â€¦ï¼‰ã€‚
- en: 'To handle these vector datasets, we mainly use one open specification, the
    shapefile format. This permits us to spatially describe geometries and attach
    some kind of additional information to them. On our computer, the shapefile file
    format is simply a collection of several files formatted to represent different
    aspects of geodata ([*Reference*](https://wiki.openstreetmap.org/wiki/Shapefiles)):'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¤„ç†è¿™äº›çŸ¢é‡æ•°æ®é›†ï¼Œæˆ‘ä»¬ä¸»è¦ä½¿ç”¨ä¸€ç§å¼€æ”¾è§„èŒƒâ€”â€”shapefile æ ¼å¼ã€‚è¿™å…è®¸æˆ‘ä»¬ç©ºé—´æè¿°å‡ ä½•å½¢çŠ¶å¹¶é™„åŠ ä¸€äº›é¢å¤–çš„ä¿¡æ¯ã€‚åœ¨æˆ‘ä»¬çš„è®¡ç®—æœºä¸Šï¼Œshapefile
    æ–‡ä»¶æ ¼å¼å®é™…ä¸Šæ˜¯å¤šä¸ªæ–‡ä»¶çš„é›†åˆï¼Œç”¨äºè¡¨ç¤ºåœ°ç†æ•°æ®çš„ä¸åŒæ–¹é¢ï¼ˆ[*å‚è€ƒ*](https://wiki.openstreetmap.org/wiki/Shapefiles)ï¼‰ï¼š
- en: '`.shp` â€” The shape file, which contains the feature geometry itself.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.shp` â€” å½¢çŠ¶æ–‡ä»¶ï¼ŒåŒ…å«ç‰¹å¾å‡ ä½•æœ¬èº«ã€‚'
- en: '`.shx` â€”The shape index format, which holds a positional index of the feature
    geometry. This is very useful for large files in order to allow quick search thanks
    to clever â€œindexingâ€.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.shx` â€” å½¢çŠ¶ç´¢å¼•æ ¼å¼ï¼ŒåŒ…å«ç‰¹å¾å‡ ä½•çš„å®šä½ç´¢å¼•ã€‚è¿™å¯¹äºå¤§å‹æ–‡ä»¶éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒåˆ©ç”¨å·§å¦™çš„â€œç´¢å¼•â€å®ç°å¿«é€Ÿæœç´¢ã€‚'
- en: '`.dbf` â€” The attribute format, which holds various attributes for each shape
    in a tabular way (dBase IV format).'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.dbf` â€” å±æ€§æ ¼å¼ï¼Œä»¥è¡¨æ ¼æ–¹å¼ï¼ˆdBase IV æ ¼å¼ï¼‰å­˜å‚¨æ¯ä¸ªå½¢çŠ¶çš„å„ç§å±æ€§ã€‚'
- en: 'On top, we may have optional files that accompany the shapefile format. The
    most noteworthy one is the â€œ`.prj`â€ file. This extra file actually defines the
    coordinate system and any projection information deemed necessary. Thus, having
    all these files allows us to load street data of the region Overijssel using this
    time geopandas:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é¡¶éƒ¨ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæœ‰ä¸ shapefile æ ¼å¼é…å¥—çš„å¯é€‰æ–‡ä»¶ã€‚æœ€å€¼å¾—æ³¨æ„çš„æ˜¯â€œ`.prj`â€æ–‡ä»¶ã€‚è¿™ä¸ªé¢å¤–çš„æ–‡ä»¶å®é™…ä¸Šå®šä¹‰äº†åæ ‡ç³»ç»Ÿå’Œä»»ä½•å¿…è¦çš„æŠ•å½±ä¿¡æ¯ã€‚å› æ­¤ï¼Œæ‹¥æœ‰è¿™äº›æ–‡ä»¶ä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨
    geopandas åŠ è½½ Overijssel åŒºåŸŸçš„è¡—é“æ•°æ®ï¼š
- en: '[PRE20]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/cd2f94aa4d177b76cad9ca52797d37a3.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd2f94aa4d177b76cad9ca52797d37a3.png)'
- en: Vector Data output. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ¢é‡æ•°æ®è¾“å‡ºã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'Let us now explore a bit its projection system by exploring its CRS:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬é€šè¿‡æ¢ç´¢å…¶åæ ‡å‚è€ƒç³»ç»Ÿï¼ˆCRSï¼‰æ¥è¿›ä¸€æ­¥äº†è§£å…¶æŠ•å½±ç³»ç»Ÿï¼š
- en: '[PRE21]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Which results in the following:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´äº†ä»¥ä¸‹ç»“æœï¼š
- en: '[PRE22]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As we can see, this dataset is expressed in the ESPG 4326, which stands for
    WGS84\. So this is different from our other datasets so far.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¯¥æ•°æ®é›†ä»¥ ESPG 4326 è¡¨è¾¾ï¼Œè¿™ä»£è¡¨ WGS84\. å› æ­¤ï¼Œä¸æˆ‘ä»¬ä¹‹å‰çš„æ•°æ®é›†æœ‰æ‰€ä¸åŒã€‚
- en: '**Florent**: *geopandas is a perfect mashup of pandas and shapely. Thus if
    you are familiar with both, geopandas will be a breeze! Some useful commands are*
    `vector_data.columns` *or* `vector_data.describe()` *that can give you an overview
    of its content quickly*.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '**Florent**ï¼š*geopandas æ˜¯ pandas å’Œ shapely çš„å®Œç¾ç»“åˆã€‚å› æ­¤ï¼Œå¦‚æœä½ å¯¹è¿™ä¸¤è€…éƒ½å¾ˆç†Ÿæ‚‰ï¼Œä½¿ç”¨ geopandas
    å°†ä¼šéå¸¸è½»æ¾ï¼ä¸€äº›æœ‰ç”¨çš„å‘½ä»¤æ˜¯* `vector_data.columns` *æˆ–* `vector_data.describe()` *ï¼Œå¯ä»¥è®©ä½ å¿«é€Ÿäº†è§£å…¶å†…å®¹*ã€‚'
- en: 'But let us now explore our dataset visually to see its content:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†ç°åœ¨è®©æˆ‘ä»¬é€šè¿‡å¯è§†åŒ–æˆ‘ä»¬çš„æ•°æ®é›†æ¥æŸ¥çœ‹å…¶å†…å®¹ï¼š
- en: '[PRE23]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Which results in the following plot:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´äº†ä»¥ä¸‹å›¾ç¤ºï¼š
- en: '![](../Images/2fc7bb808b505e587e571a7e671ad9b9.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2fc7bb808b505e587e571a7e671ad9b9.png)'
- en: Vector Data from OpenStreetMap. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª OpenStreetMap çš„çŸ¢é‡æ•°æ®ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: This is very interesting! We can also use Matplotlib to display vector data.
    And the region is densely populated with an extensive road network, which is very
    dense! Let us now extract some points of interest from another source of data.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éå¸¸æœ‰è¶£ï¼æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ Matplotlib æ¥æ˜¾ç¤ºçŸ¢é‡æ•°æ®ã€‚è¯¥åŒºåŸŸäººå£å¯†é›†ï¼Œé“è·¯ç½‘ç»œå¹¿æ³›ä¸”éå¸¸å¯†é›†ï¼ç°åœ¨è®©æˆ‘ä»¬ä»å¦ä¸€ä¸ªæ•°æ®æºä¸­æå–ä¸€äº›å…´è¶£ç‚¹ã€‚
- en: 'Vector: Points of Interest'
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: çŸ¢é‡ï¼šå…´è¶£ç‚¹
- en: 'The dataset pack has a GeoJSON file, a lightweight and popular format for representing
    vector data with geometry and attributes, suitable for web-based applications
    and data exchange. To load the file, we also use geopandas with this code line:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†åŒ…ä¸­åŒ…å«ä¸€ä¸ª GeoJSON æ–‡ä»¶ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§ä¸”æµè¡Œçš„çŸ¢é‡æ•°æ®æ ¼å¼ï¼Œå…·æœ‰å‡ ä½•ä½“å’Œå±æ€§ï¼Œé€‚ç”¨äºåŸºäº Web çš„åº”ç”¨ç¨‹åºå’Œæ•°æ®äº¤æ¢ã€‚è¦åŠ è½½è¯¥æ–‡ä»¶ï¼Œæˆ‘ä»¬ä¹Ÿä½¿ç”¨
    geopandasï¼Œä»£ç å¦‚ä¸‹ï¼š
- en: '[PRE24]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We profile its CRS:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ†æå…¶ CRSï¼š
- en: '[PRE25]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This gives us an answer that this is in the WGS84 CRS again. Finally, we plot
    to check any abnormality firsthand:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™æˆ‘ä»¬çš„ç­”æ¡ˆæ˜¯å®ƒä»ç„¶åœ¨ WGS84 CRS ä¸­ã€‚æœ€åï¼Œæˆ‘ä»¬ç»˜åˆ¶ä»¥æ£€æŸ¥ä»»ä½•å¼‚å¸¸ï¼š
- en: '[PRE26]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/a4b39e1fe098148011685d72801919f3.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4b39e1fe098148011685d72801919f3.png)'
- en: Points of interest. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: å…³æ³¨ç‚¹ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'This may be a bit bland without any more context; thus, layering Raster imagery
    would be a first choice already. But before that, let us explore another dataset
    we could try: 360Â° imagery!'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰æ›´å¤šä¸Šä¸‹æ–‡ï¼Œè¿™å¯èƒ½æœ‰ç‚¹å¹³æ·¡ï¼›å› æ­¤ï¼Œé¦–å…ˆé€‰æ‹©å åŠ æ …æ ¼å½±åƒã€‚ä½†åœ¨æ­¤ä¹‹å‰ï¼Œè®©æˆ‘ä»¬æ¢ç´¢å¦ä¸€ä¸ªå¯ä»¥å°è¯•çš„æ•°æ®é›†ï¼š360Â° å½±åƒï¼
- en: 360Â° Imagery
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 360Â° å½±åƒ
- en: 'From the mappillary platform, we have the ability to extract some 360Â° images
    that come with a specific license to be used. You can still use geopandas to read
    these images :'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ä» mappillary å¹³å°ï¼Œæˆ‘ä»¬å¯ä»¥æå–ä¸€äº›é™„æœ‰ç‰¹å®šè®¸å¯çš„ 360Â° å›¾åƒã€‚ä½ ä»ç„¶å¯ä»¥ä½¿ç”¨ geopandas æ¥è¯»å–è¿™äº›å½±åƒï¼š
- en: '[PRE27]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'That will output:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†è¾“å‡ºï¼š
- en: '[PRE28]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here we can see (of course) that this image has no geotransform data. And this
    is normal: this is not a spatial raster! However, if we wanted, we could add a
    position so that a data point represents the place the picture was taken, a hint
    at layering data modalities through data integration. But before going there,
    let us plot the image:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ˆå½“ç„¶ï¼‰è¿™å¼ å›¾åƒæ²¡æœ‰åœ°ç†å˜æ¢æ•°æ®ã€‚è¿™æ˜¯æ­£å¸¸çš„ï¼šè¿™ä¸æ˜¯ç©ºé—´æ …æ ¼ï¼ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æ„¿æ„ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªä½ç½®ï¼Œä»¥ä¾¿æ•°æ®ç‚¹è¡¨ç¤ºæ‹æ‘„ç…§ç‰‡çš„ä½ç½®ï¼Œè¿™æš—ç¤ºäº†é€šè¿‡æ•°æ®æ•´åˆæ¥å åŠ æ•°æ®æ¨¡æ€ã€‚ä½†åœ¨å»åˆ°é‚£é‡Œä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç»˜åˆ¶å›¾åƒï¼š
- en: '[PRE29]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This results in the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå¦‚ä¸‹ï¼š
- en: '![](../Images/9d16fa976ae1afafa51f2fe9b49cd98d.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d16fa976ae1afafa51f2fe9b49cd98d.png)'
- en: 360Â° imagery from Mapillary. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª Mapillary çš„ 360Â° å½±åƒã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: We have now successfully loaded 3D Point Clouds, 3D City models as 3D Meshes,
    3D Voxel dataset, Spatial rasters (satellite imagery, aerial imagery, and elevation
    rasters), vector datasets (lines and points), as well as 360Â° imagery. The first
    objective is now an evident success! But, we need to check how to bring that all
    together, and the first thing to check is actually if they are expressed in the
    same Coordinate Reference System (CRS). For that, I compiled the results of our
    profiling step in the table below.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å·²ç»æˆåŠŸåŠ è½½äº† 3D ç‚¹äº‘ã€ä½œä¸º 3D ç½‘æ ¼çš„ 3D åŸå¸‚æ¨¡å‹ã€3D ä½“ç´ æ•°æ®é›†ã€ç©ºé—´æ …æ ¼ï¼ˆå«æ˜Ÿå½±åƒã€èˆªæ‹å½±åƒå’Œé«˜ç¨‹æ …æ ¼ï¼‰ã€çŸ¢é‡æ•°æ®é›†ï¼ˆçº¿æ¡å’Œç‚¹ï¼‰ä»¥åŠ
    360Â° å½±åƒã€‚ç¬¬ä¸€ä¸ªç›®æ ‡ç°åœ¨æ˜¾ç„¶å·²ç»æˆåŠŸï¼ä½†æˆ‘ä»¬éœ€è¦æ£€æŸ¥å¦‚ä½•å°†è¿™äº›æ•°æ®æ•´åˆåœ¨ä¸€èµ·ï¼Œé¦–å…ˆéœ€è¦æ£€æŸ¥çš„æ˜¯å®ƒä»¬æ˜¯å¦éƒ½è¡¨ç¤ºåœ¨ç›¸åŒçš„åæ ‡å‚è€ƒç³»ç»Ÿï¼ˆCRSï¼‰ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘å°†æˆ‘ä»¬çš„åˆ†ææ­¥éª¤çš„ç»“æœæ±‡æ€»åœ¨ä¸‹é¢çš„è¡¨æ ¼ä¸­ã€‚
- en: '[PRE30]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We see a mix of EPSG:7415, 28992, 4326 or missing EPSG. The next stage is thus
    to clarify and use a unifying system for all datasets.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°æ··åˆäº† EPSG:7415ã€28992ã€4326 æˆ–ç¼ºå¤± EPSGã€‚ä¸‹ä¸€é˜¶æ®µæ˜¯æ¾„æ¸…å¹¶ä¸ºæ‰€æœ‰æ•°æ®é›†ä½¿ç”¨ç»Ÿä¸€çš„ç³»ç»Ÿã€‚
- en: Data Registration and Reprojection
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æ³¨å†Œå’Œé‡æŠ•å½±
- en: '![](../Images/4d29341fd32f54b9cad5d858722e4e38.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d29341fd32f54b9cad5d858722e4e38.png)'
- en: Step 4\. Registration and Reprojection
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 4ï¼šæ³¨å†Œå’Œé‡æŠ•å½±
- en: Before integration, we have to ensure that all datasets are in a compatible
    format and coordinate reference system (CRS). If this is not the case, we perform
    data reprojection to bring them into a common CRS. This is achieved in four main
    stages by (1) Selecting a reference system, (2) Georeferencing the primary dataset,
    (3) Reprojecting other datasets, and (4) Aligning rigidly local datasets, as shown
    below.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•´åˆä¹‹å‰ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿æ‰€æœ‰æ•°æ®é›†éƒ½å¤„äºå…¼å®¹çš„æ ¼å¼å’Œåæ ‡å‚è€ƒç³»ç»Ÿï¼ˆCRSï¼‰ä¸­ã€‚å¦‚æœä¸æ˜¯è¿™æ ·ï¼Œæˆ‘ä»¬ä¼šæ‰§è¡Œæ•°æ®é‡æŠ•å½±ï¼Œå°†å®ƒä»¬å¸¦å…¥ä¸€ä¸ªå…±åŒçš„ CRSã€‚è¿™é€šè¿‡å››ä¸ªä¸»è¦é˜¶æ®µå®ç°ï¼šï¼ˆ1ï¼‰é€‰æ‹©å‚è€ƒç³»ç»Ÿï¼Œï¼ˆ2ï¼‰åœ°ç†é…å‡†ä¸»è¦æ•°æ®é›†ï¼Œï¼ˆ3ï¼‰é‡æŠ•å½±å…¶ä»–æ•°æ®é›†ï¼Œä»¥åŠï¼ˆ4ï¼‰ä¸¥æ ¼å¯¹é½æœ¬åœ°æ•°æ®é›†ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/6df947aa143ea3754d64afd48adcb515.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6df947aa143ea3754d64afd48adcb515.png)'
- en: 4 Steps Workflow covered. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: å·²è¦†ç›– 4 ä¸ªæ­¥éª¤å·¥ä½œæµã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Let us go through these stages.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€æ­¥äº†è§£è¿™äº›é˜¶æ®µã€‚
- en: Selecting a Reference System
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é€‰æ‹©å‚è€ƒç³»ç»Ÿ
- en: Alright, let us dive into the exciting world of reference systems! Imagine reference
    systems as the GPS coordinates that guide your data through the vast landscape
    of planet Earth. A reference system defines a set of rules and parameters to represent
    the Earthâ€™s surface in a way that makes sense to us mere mortals. Itâ€™s like choosing
    a secret language that your data speaks fluently, allowing it to find its place
    in the world. Now, how do we choose the correct reference system? Letâ€™s be pragmatic
    and attempt to first delineate the scope + region of interest of the project at
    hands.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè®©æˆ‘ä»¬æ·±å…¥æ¢ç´¢å‚è€ƒç³»ç»Ÿçš„æ¿€åŠ¨äººå¿ƒçš„ä¸–ç•Œå§ï¼æƒ³è±¡ä¸€ä¸‹å‚è€ƒç³»ç»Ÿå°±åƒæ˜¯å¼•å¯¼ä½ çš„æ•°æ®ç©¿è¶Šåœ°çƒå¹¿é˜”æ™¯è§‚çš„GPSåæ ‡ã€‚å‚è€ƒç³»ç»Ÿå®šä¹‰äº†ä¸€ç»„è§„åˆ™å’Œå‚æ•°ï¼Œä»¥ä¸€ç§å¯¹æˆ‘ä»¬è¿™äº›å‡¡äººæœ‰æ„ä¹‰çš„æ–¹å¼æ¥è¡¨ç¤ºåœ°çƒè¡¨é¢ã€‚è¿™å°±åƒé€‰æ‹©ä¸€ç§æ•°æ®æµåˆ©ä½¿ç”¨çš„ç§˜å¯†è¯­è¨€ï¼Œè®©å®ƒæ‰¾åˆ°è‡ªå·±åœ¨ä¸–ç•Œä¸Šçš„ä½ç½®ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•é€‰æ‹©æ­£ç¡®çš„å‚è€ƒç³»ç»Ÿå‘¢ï¼Ÿè®©æˆ‘ä»¬åŠ¡å®ä¸€äº›ï¼Œé¦–å…ˆå°è¯•å‹¾ç”»é¡¹ç›®çš„èŒƒå›´å’Œå…³æ³¨åŒºåŸŸã€‚
- en: '![](../Images/5cc44dd0f1cf97049d9ce90cf78a8ea2.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cc44dd0f1cf97049d9ce90cf78a8ea2.png)'
- en: 'Projection classical cases: One standard line, one standard cone and one standard
    point. Â© [F. Poux](https://learngeodata.eu/)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ•å½±ç»å…¸æ¡ˆä¾‹ï¼šä¸€ä¸ªæ ‡å‡†çº¿ï¼Œä¸€ä¸ªæ ‡å‡†åœ†é”¥å’Œä¸€ä¸ªæ ‡å‡†ç‚¹ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Different reference systems work better for different parts of the globe. Something
    like the Amersfoort / RD New can be a fantastic choice for local projects in the
    Netherlands. The trusty WGS84 or Universal Transverse Mercator (UTM) might be
    your best buddy for more global ventures. Therefore, we use the Amersfoort / RD
    New + [NAP height](https://epsg.io/5709) (for the elevation information) as our
    CRS.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŒçš„å‚è€ƒç³»ç»Ÿåœ¨å…¨çƒä¸åŒåŒºåŸŸè¡¨ç°æ›´ä½³ã€‚ä¾‹å¦‚ï¼ŒAmersfoort / RD New å¯¹äºè·å…°çš„æœ¬åœ°é¡¹ç›®å¯èƒ½æ˜¯ä¸€ä¸ªç»ä½³çš„é€‰æ‹©ã€‚å€¼å¾—ä¿¡èµ–çš„WGS84æˆ–å…¨çƒæ¨ªè½´å¢¨å¡æ‰˜ï¼ˆUTMï¼‰å¯èƒ½æ˜¯ä½ å…¨çƒé¡¹ç›®çš„æœ€ä½³ä¼™ä¼´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨Amersfoort
    / RD New + [NAPé«˜ç¨‹](https://epsg.io/5709)ï¼ˆç”¨äºé«˜ç¨‹ä¿¡æ¯ï¼‰ä½œä¸ºæˆ‘ä»¬çš„CRSã€‚
- en: Remember, when choosing a reference system, let the nature of your project and
    the region guide your decision. Pick a system that speaks the language of your
    data and brings harmony to your geospatial endeavors.ğŸ—ºï¸
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½ï¼Œåœ¨é€‰æ‹©å‚è€ƒç³»ç»Ÿæ—¶ï¼Œè®©ä½ çš„é¡¹ç›®æ€§è´¨å’Œåœ°åŒºæ¥æŒ‡å¯¼ä½ çš„å†³ç­–ã€‚é€‰æ‹©ä¸€ä¸ªèƒ½ä¸æ•°æ®è¯­è¨€ç›¸é€šçš„ç³»ç»Ÿï¼Œå¹¶ä¸ºä½ çš„åœ°ç†ç©ºé—´å·¥ä½œå¸¦æ¥å’Œè°ã€‚ğŸ—ºï¸
- en: Data Georeferencing
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®åœ°ç†å‚è€ƒ
- en: 'Okay, we have our CRS defined; this step ensures that the data tagged in EPSG:7415
    for 3D data, and EPSG:28992 for 2D data. When profiling, we could then check that
    these datasets are already coherent:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæˆ‘ä»¬å®šä¹‰äº†CRSï¼›è¿™ä¸€æ­¥ç¡®ä¿æ•°æ®æ ‡è®°ä¸ºEPSG:7415çš„3Dæ•°æ®å’ŒEPSG:28992çš„2Dæ•°æ®ã€‚åœ¨åˆ†ææ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥è¿™äº›æ•°æ®é›†æ˜¯å¦å·²ç»ä¸€è‡´ï¼š
- en: LiDAR 3D Point Cloud
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LiDAR 3D ç‚¹äº‘
- en: Raster Imagery (both Spatial Raster and Elevation Raster)
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ …æ ¼å½±åƒï¼ˆåŒ…æ‹¬ç©ºé—´æ …æ ¼å’Œé«˜ç¨‹æ …æ ¼ï¼‰
- en: 'However, the voxel dataset and the mesh from the city model dataset look like
    they are in the same CRS but have no metadata. Thus, we quickly overlay these
    datasets to check for any possible inconsistencies:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä½“ç´ æ•°æ®é›†å’ŒåŸå¸‚æ¨¡å‹æ•°æ®é›†ä¸­çš„ç½‘æ ¼çœ‹èµ·æ¥ä¼¼ä¹åœ¨ç›¸åŒçš„CRSä¸­ï¼Œä½†æ²¡æœ‰å…ƒæ•°æ®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿…é€Ÿå åŠ è¿™äº›æ•°æ®é›†ä»¥æ£€æŸ¥ä»»ä½•å¯èƒ½çš„ä¸ä¸€è‡´ï¼š
- en: '[PRE31]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Which results in the following:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå¦‚ä¸‹ï¼š
- en: '![](../Images/d9b3ea6b8885875589da756fcc4e517d.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9b3ea6b8885875589da756fcc4e517d.png)'
- en: The point cloud, building, and voxel datasets are combined together and visualized.
    Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹äº‘ã€å»ºç­‘ç‰©å’Œä½“ç´ æ•°æ®é›†è¢«åˆå¹¶åœ¨ä¸€èµ·å¹¶å¯è§†åŒ–ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'ğŸ¦Š**Florent**: *Everything is aligned nicely, as shown in the image. The various
    datasets are cut on purpose to show the overlap between them. You can also see
    that point clouds have a bit more roughness and â€œresolutionâ€ over the 3D models
    that represent the buildings.*'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š**å¼—æ´›æœ—**ï¼š*ä¸€åˆ‡éƒ½å¯¹é½å¾—å¾ˆå¥½ï¼Œå¦‚å›¾æ‰€ç¤ºã€‚å„ç§æ•°æ®é›†è¢«æ•…æ„è£å‰ªä»¥æ˜¾ç¤ºå®ƒä»¬ä¹‹é—´çš„é‡å ã€‚ä½ è¿˜å¯ä»¥çœ‹åˆ°ç‚¹äº‘åœ¨è¡¨ç¤ºå»ºç­‘ç‰©çš„3Dæ¨¡å‹ä¸Šæœ‰äº›è®¸ç²—ç³™å’Œâ€œåˆ†è¾¨ç‡â€å·®å¼‚ã€‚*
- en: 'the remaining datasets to address are the following:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: å‰©ä½™çš„æ•°æ®é›†éœ€è¦å¤„ç†å¦‚ä¸‹ï¼š
- en: Vector datasets (both the OSM and Mappillary one) that are expressed in WGS84
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¡¨ç¤ºä¸ºWGS84çš„çŸ¢é‡æ•°æ®é›†ï¼ˆåŒ…æ‹¬OSMå’ŒMappillaryï¼‰
- en: The ITC Point Cloud dataset is not georeferenced.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ITCç‚¹äº‘æ•°æ®é›†æ²¡æœ‰åœ°ç†å‚è€ƒã€‚
- en: Let us then deal with data projection first.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é¦–å…ˆå¤„ç†æ•°æ®æŠ•å½±ã€‚
- en: Data Reprojection
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®é‡æŠ•å½±
- en: Spatial data reprojection is a fundamental process that involves transforming
    spatial data from one coordinate reference system to another, typically to match
    the projection and coordinate units of a specific spatial analysis. Reprojection
    ensures that different datasets with distinct projections can be accurately overlaid,
    integrated, or analyzed.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ç©ºé—´æ•°æ®é‡æŠ•å½±æ˜¯ä¸€ä¸ªåŸºæœ¬è¿‡ç¨‹ï¼Œæ¶‰åŠå°†ç©ºé—´æ•°æ®ä»ä¸€ä¸ªåæ ‡å‚è€ƒç³»ç»Ÿè½¬æ¢åˆ°å¦ä¸€ä¸ªç³»ç»Ÿï¼Œé€šå¸¸æ˜¯ä¸ºäº†åŒ¹é…ç‰¹å®šç©ºé—´åˆ†æçš„æŠ•å½±å’Œåæ ‡å•ä½ã€‚é‡æŠ•å½±ç¡®ä¿å…·æœ‰ä¸åŒæŠ•å½±çš„æ•°æ®é›†å¯ä»¥å‡†ç¡®åœ°å åŠ ã€é›†æˆæˆ–åˆ†æã€‚
- en: The process involves mathematical calculations that convert geographic coordinates
    (latitude and longitude) from one datum to another, considering parameters like
    scale, rotation, and distortion. Spatial data reprojection is essential for achieving
    data consistency, enabling interoperability between different datasets, and conducting
    accurate geospatial analyses across diverse mapping systems and applications.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è¿‡ç¨‹æ¶‰åŠå°†åœ°ç†åæ ‡ï¼ˆçº¬åº¦å’Œç»åº¦ï¼‰ä»ä¸€ä¸ªåŸºå‡†è½¬æ¢åˆ°å¦ä¸€ä¸ªåŸºå‡†çš„æ•°å­¦è®¡ç®—ï¼Œè€ƒè™‘å‚æ•°å¦‚æ¯”ä¾‹ã€æ—‹è½¬å’Œç•¸å˜ã€‚ç©ºé—´æ•°æ®é‡æ–°æŠ•å½±å¯¹äºå®ç°æ•°æ®ä¸€è‡´æ€§ã€ä¿ƒè¿›ä¸åŒæ•°æ®é›†ä¹‹é—´çš„äº’æ“ä½œæ€§ï¼Œä»¥åŠåœ¨å„ç§åˆ¶å›¾ç³»ç»Ÿå’Œåº”ç”¨ä¸­è¿›è¡Œå‡†ç¡®çš„åœ°ç†ç©ºé—´åˆ†æè‡³å…³é‡è¦ã€‚
- en: 'When reprojecting spatial data between reference systems, several important
    factors must be carefully considered to ensure accurate and meaningful results.
    Here are some of the key considerations:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‚è€ƒç³»ç»Ÿä¹‹é—´é‡æ–°æŠ•å½±ç©ºé—´æ•°æ®æ—¶ï¼Œå¿…é¡»ä»”ç»†è€ƒè™‘å‡ ä¸ªé‡è¦å› ç´ ï¼Œä»¥ç¡®ä¿ç»“æœçš„å‡†ç¡®æ€§å’Œæ„ä¹‰ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å…³é”®è€ƒè™‘å› ç´ ï¼š
- en: 'Coordinate Systems and Projections: Understand the coordinate systems and projections
    of both the source and target reference systems. Make sure they are compatible;
    if not, choose an appropriate transformation method.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åæ ‡ç³»ç»Ÿå’ŒæŠ•å½±ï¼šäº†è§£æºç³»ç»Ÿå’Œç›®æ ‡ç³»ç»Ÿçš„åæ ‡ç³»ç»Ÿå’ŒæŠ•å½±ã€‚ç¡®ä¿å®ƒä»¬å…¼å®¹ï¼›å¦‚æœä¸å…¼å®¹ï¼Œé€‰æ‹©åˆé€‚çš„è½¬æ¢æ–¹æ³•ã€‚
- en: 'Datum and Ellipsoid: Check the datums and ellipsoids used in the source and
    target systems. Differences in datums can lead to significant shifts in coordinates.
    Apply datum transformations if needed to align the data correctly. If you feel
    a bit confused, here is a nice [lecture on datum and ellipsoid](https://www.tamiu.edu/cees/courses/fall2018/geol4460_labs/lecture4.pdf)
    (tamia.edu)'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŸºå‡†å’Œæ¤­çƒä½“ï¼šæ£€æŸ¥æºç³»ç»Ÿå’Œç›®æ ‡ç³»ç»Ÿä¸­ä½¿ç”¨çš„åŸºå‡†å’Œæ¤­çƒä½“ã€‚åŸºå‡†çš„å·®å¼‚å¯èƒ½ä¼šå¯¼è‡´åæ ‡çš„æ˜¾è‘—åç§»ã€‚å¦‚æœ‰éœ€è¦ï¼Œåº”ç”¨åŸºå‡†è½¬æ¢ä»¥æ­£ç¡®å¯¹é½æ•°æ®ã€‚å¦‚æœä½ æ„Ÿåˆ°æœ‰äº›å›°æƒ‘ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªä¸é”™çš„[åŸºå‡†å’Œæ¤­çƒä½“è®²åº§](https://www.tamiu.edu/cees/courses/fall2018/geol4460_labs/lecture4.pdf)
    (tamia.edu)
- en: 'Accuracy / Precision: While these pinpoint two different characteristics (which
    extends the scope of our article), it is important to understand the required
    â€œlevelâ€ for your specific analysis. Reprojection can introduce some errors, especially
    in large-scale transformations. Indeed, any data â€œerrorâ€ has a potential impact
    on the results of our analysis.'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡†ç¡®æ€§/ç²¾åº¦ï¼šè™½ç„¶è¿™äº›æŒ‡å‘ä¸¤ä¸ªä¸åŒçš„ç‰¹å¾ï¼ˆè¿™æ‰©å±•äº†æˆ‘ä»¬æ–‡ç« çš„èŒƒå›´ï¼‰ï¼Œäº†è§£ä½ ç‰¹å®šåˆ†ææ‰€éœ€çš„â€œæ°´å¹³â€å¾ˆé‡è¦ã€‚é‡æ–°æŠ•å½±å¯èƒ½ä¼šå¼•å…¥ä¸€äº›é”™è¯¯ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡è½¬æ¢ä¸­ã€‚ç¡®å®ï¼Œä»»ä½•æ•°æ®â€œé”™è¯¯â€éƒ½æœ‰å¯èƒ½å½±å“æˆ‘ä»¬åˆ†æçš„ç»“æœã€‚
- en: 'Distortions: Different map projections can introduce distortions in shape,
    area, distance, or angles. Be aware of these distortions and their implications
    on your data interpretation.'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç•¸å˜ï¼šä¸åŒçš„åœ°å›¾æŠ•å½±å¯èƒ½ä¼šå¼•å…¥å½¢çŠ¶ã€é¢ç§¯ã€è·ç¦»æˆ–è§’åº¦çš„ç•¸å˜ã€‚æ³¨æ„è¿™äº›ç•¸å˜åŠå…¶å¯¹æ•°æ®è§£é‡Šçš„å½±å“ã€‚
- en: 'Coverage Area: Some projections are suitable for specific regions but may not
    be ideal for global datasets. Choose a projection that preserves the properties
    of your data over the entire coverage area.'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦†ç›–åŒºåŸŸï¼šæŸäº›æŠ•å½±é€‚åˆç‰¹å®šåŒºåŸŸï¼Œä½†å¯èƒ½ä¸é€‚åˆå…¨çƒæ•°æ®é›†ã€‚é€‰æ‹©ä¸€ç§åœ¨æ•´ä¸ªè¦†ç›–åŒºåŸŸå†…ä¿æŒæ•°æ®å±æ€§çš„æŠ•å½±ã€‚
- en: 'Metadata and Documentation: Keep track of the reprojection process and document
    the transformations applied to the data. Properly document the source coordinate
    system and the target projection for future reference.'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å…ƒæ•°æ®å’Œæ–‡æ¡£ï¼šè®°å½•é‡æ–°æŠ•å½±è¿‡ç¨‹ï¼Œå¹¶è®°å½•åº”ç”¨äºæ•°æ®çš„è½¬æ¢ã€‚å¦¥å–„è®°å½•æºåæ ‡ç³»ç»Ÿå’Œç›®æ ‡æŠ•å½±ä»¥å¤‡å°†æ¥å‚è€ƒã€‚
- en: 'By carefully considering these factors, we ensure that reprojection is performed
    accurately and the resulting data is suitable for our intended applications. It
    is essential to be mindful of potential errors and artifacts that can arise during
    the reprojection process and to validate the results to maintain the quality and
    reliability of the data. In our case, we have to reproject both vector datasets.
    To do this, we use the following lines:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»”ç»†è€ƒè™‘è¿™äº›å› ç´ ï¼Œæˆ‘ä»¬ç¡®ä¿é‡æ–°æŠ•å½±å‡†ç¡®æ‰§è¡Œï¼Œå¾—åˆ°çš„æ•°æ®é€‚ç”¨äºæˆ‘ä»¬çš„é¢„æœŸåº”ç”¨ã€‚å¿…é¡»æ³¨æ„åœ¨é‡æ–°æŠ•å½±è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„é”™è¯¯å’Œä¼ªå½±ï¼Œå¹¶éªŒè¯ç»“æœä»¥ä¿æŒæ•°æ®çš„è´¨é‡å’Œå¯é æ€§ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°æŠ•å½±ä¸¤ä¸ªçŸ¢é‡æ•°æ®é›†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹æ­¥éª¤ï¼š
- en: '[PRE32]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Which results in the following:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´äº†ä»¥ä¸‹ç»“æœï¼š
- en: '![](../Images/5be24aaf0ff2a87f7ff146850d80def6.png)![](../Images/7d4741c1990d5ac1e972030c7a079c03.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5be24aaf0ff2a87f7ff146850d80def6.png)![](../Images/7d4741c1990d5ac1e972030c7a079c03.png)'
- en: The resulting plots. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„å›¾è¡¨ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'ğŸ¦Š **Florent**: *3D Reprojection is also possible, but currently extend a bit
    the scope of this guide. Nevertheless, you can browse the library of course tutorials,
    where you will find some nice code and examples for 3D reprojection in the context
    of Segment Anything for Semantic Segmentation.*'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦Š **Florent**: *3Dé‡æŠ•å½±ä¹Ÿæ˜¯å¯èƒ½çš„ï¼Œä½†ç›®å‰è¶…å‡ºäº†æœ¬æŒ‡å—çš„èŒƒå›´ã€‚ç„¶è€Œï¼Œæ‚¨å¯ä»¥æµè§ˆè¯¾ç¨‹åº“ï¼Œå…¶ä¸­ä¼šæ‰¾åˆ°ä¸€äº›å¾ˆå¥½çš„ä»£ç å’Œç¤ºä¾‹ï¼Œç”¨äºåœ¨â€œSegment
    Anythingâ€è¯­å¢ƒä¸‹è¿›è¡Œ3Dé‡æŠ•å½±ã€‚*'
- en: 'Note the change in the coordinates on the axes of our plots! At this stage,
    it looks like we only have one data to register: the 3D Point Cloud of ITC.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æˆ‘ä»¬å›¾è¡¨åæ ‡è½´ä¸Šçš„å˜åŒ–ï¼åœ¨è¿™ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬ä¼¼ä¹åªæœ‰ä¸€ä¸ªæ•°æ®éœ€è¦æ³¨å†Œï¼šITCçš„3Dç‚¹äº‘ã€‚
- en: Data Rigid Registration
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®åˆšæ€§æ³¨å†Œ
- en: '![](../Images/036f65b753a68af1d9b2c43d2faa1a2a.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/036f65b753a68af1d9b2c43d2faa1a2a.png)'
- en: 3D Data Registration classical workflow. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 3Dæ•°æ®æ³¨å†Œç»å…¸å·¥ä½œæµç¨‹ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'In 3D integration, data registration becomes crucial. Point cloud registration
    methods are usually made of two stages: a coarse alignment to position relatively
    closely two point clouds quickly. Then a fine registration like Iterative Closest
    Point (ICP) or feature-based registration to align multiple point clouds with
    a higher degree of precision. To give you a hint concerning global registration,
    we can align the ITC point cloud by picking a list of three pairs of common points
    to get a first estimate, which is later refined with ICP. This permits obtaining
    an overlaid point cloud. These largely extend the scope of the current guide,
    and will be covered in another session.ğŸ˜‰'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨3Dé›†æˆä¸­ï¼Œæ•°æ®æ³¨å†Œå˜å¾—è‡³å…³é‡è¦ã€‚ç‚¹äº‘æ³¨å†Œæ–¹æ³•é€šå¸¸ç”±ä¸¤ä¸ªé˜¶æ®µç»„æˆï¼šç²—ç•¥å¯¹é½ï¼Œå°†ä¸¤ä¸ªç‚¹äº‘ç›¸å¯¹å¿«é€Ÿåœ°å®šä½å¾—è¾ƒè¿‘ã€‚ç„¶åæ˜¯ç²¾ç»†æ³¨å†Œï¼Œå¦‚è¿­ä»£æœ€è¿‘ç‚¹ï¼ˆICPï¼‰æˆ–åŸºäºç‰¹å¾çš„æ³¨å†Œï¼Œä»¥æ›´é«˜çš„ç²¾åº¦å¯¹é½å¤šä¸ªç‚¹äº‘ã€‚ä¸ºäº†ç»™æ‚¨ä¸€ä¸ªå…³äºå…¨å±€æ³¨å†Œçš„æç¤ºï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é€‰æ‹©ä¸‰å¯¹å…¬å…±ç‚¹çš„åˆ—è¡¨æ¥å¯¹é½ITCç‚¹äº‘ï¼Œä»¥è·å¾—åˆæ­¥ä¼°è®¡ï¼Œç„¶åç”¨ICPè¿›è¡Œç²¾ç»†åŒ–ã€‚è¿™å…è®¸æˆ‘ä»¬è·å¾—å åŠ çš„ç‚¹äº‘ã€‚è¿™äº›å†…å®¹å¤§å¤§æ‰©å±•äº†å½“å‰æŒ‡å—çš„èŒƒå›´ï¼Œå°†åœ¨å¦ä¸€ä¸ªä¼šè®®ä¸­è®¨è®ºã€‚ğŸ˜‰
- en: We now possess an aligned dataset expressed in a coherent CRS. The next stage
    is to see if we can refine the â€œdata oilâ€ to get some intelligent analytical workflow
    that can be built from there.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªåœ¨ä¸€è‡´çš„åæ ‡å‚è€ƒç³»ç»Ÿï¼ˆCRSï¼‰ä¸­å¯¹é½çš„æ•°æ®é›†ã€‚ä¸‹ä¸€é˜¶æ®µæ˜¯çœ‹çœ‹æˆ‘ä»¬æ˜¯å¦èƒ½â€œæç‚¼æ•°æ®â€ï¼Œä»¥ä¾¿ä»ä¸­å»ºç«‹ä¸€ä¸ªæ™ºèƒ½çš„åˆ†æå·¥ä½œæµç¨‹ã€‚
- en: Step 5\. Data Processing, Transformations, and Fusion
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬5æ­¥ã€‚æ•°æ®å¤„ç†ã€è½¬æ¢å’Œèåˆ
- en: '![](../Images/b6c0b16e52d182b2c282240b7da919c5.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6c0b16e52d182b2c282240b7da919c5.png)'
- en: Step 5\. Data Pre-Processing
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬5æ­¥ã€‚æ•°æ®é¢„å¤„ç†
- en: This stage can also be done before the registration and reprojection part. Indeed,
    as we predominantly work per dataset, this is a solution and can impact (for better
    or worse) the results of the previous steps.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€é˜¶æ®µä¹Ÿå¯ä»¥åœ¨æ³¨å†Œå’Œé‡æŠ•å½±éƒ¨åˆ†ä¹‹å‰å®Œæˆã€‚å®é™…ä¸Šï¼Œç”±äºæˆ‘ä»¬ä¸»è¦æŒ‰æ•°æ®é›†å·¥ä½œï¼Œè¿™æ˜¯ä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œå¹¶å¯èƒ½å½±å“ï¼ˆæ— è®ºæ˜¯å¥½æ˜¯åï¼‰å‰é¢æ­¥éª¤çš„ç»“æœã€‚
- en: 'Spatial data integration combines different types of spatial data (2D, 3D,
    or 2.5D) to **create a unified and comprehensive representation of an area with
    data overlap**. This process allows us to leverage the strengths of each data
    type and derive more valuable insights from the integrated dataset. Here is a
    quick view of some processing strategies for spatial data integration:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: ç©ºé—´æ•°æ®é›†æˆå°†ä¸åŒç±»å‹çš„ç©ºé—´æ•°æ®ï¼ˆ2Dã€3Dæˆ–2.5Dï¼‰ç»“åˆèµ·æ¥ï¼Œä»¥**åˆ›å»ºä¸€ä¸ªç»Ÿä¸€ä¸”å…¨é¢çš„åŒºåŸŸæ•°æ®é‡å è¡¨ç¤º**ã€‚è¿™ä¸€è¿‡ç¨‹ä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨æ¯ç§æ•°æ®ç±»å‹çš„ä¼˜ç‚¹ï¼Œä»é›†æˆçš„æ•°æ®é›†ä¸­è·å¾—æ›´æœ‰ä»·å€¼çš„è§è§£ã€‚ä»¥ä¸‹æ˜¯ç©ºé—´æ•°æ®é›†æˆçš„ä¸€äº›å¤„ç†ç­–ç•¥çš„å¿«é€Ÿè§†å›¾ï¼š
- en: '![](../Images/5d9d187eb0f750e7e3075ac678eb7b2d.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d9d187eb0f750e7e3075ac678eb7b2d.png)'
- en: '3D Data Pre-Processing major areas: data cleaning, data transformation, data
    reduction, and data enrichment. Â© [F. Poux](https://learngeodata.eu/)'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 3Dæ•°æ®é¢„å¤„ç†çš„ä¸»è¦é¢†åŸŸï¼šæ•°æ®æ¸…ç†ã€æ•°æ®è½¬æ¢ã€æ•°æ®å‡å°‘å’Œæ•°æ®ä¸°å¯Œã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Now, let us explore what these four main stages actually look like, code-wise.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ¢è®¨ä¸€ä¸‹è¿™å››ä¸ªä¸»è¦é˜¶æ®µçš„å®é™…ä»£ç å®ç°ã€‚
- en: Data Cleaning (Raster Dataset)
  id: totrans-310
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®æ¸…ç†ï¼ˆæ …æ ¼æ•°æ®é›†ï¼‰
- en: the first stage is to handle missing or erroneous data points carefully. Data
    cleaning techniques like interpolation or extrapolation may be used to fill in
    gaps or replace erroneous values. In our case, we could fill empty raster values
    from our DTM.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€é˜¶æ®µæ˜¯ä»”ç»†å¤„ç†ç¼ºå¤±æˆ–é”™è¯¯çš„æ•°æ®ç‚¹ã€‚å¯ä»¥ä½¿ç”¨æ’å€¼æˆ–å¤–æ¨ç­‰æ•°æ®æ¸…ç†æŠ€æœ¯æ¥å¡«è¡¥ç©ºç™½æˆ–æ›¿æ¢é”™è¯¯å€¼ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä»æ•°å­—åœ°å½¢æ¨¡å‹ï¼ˆDTMï¼‰ä¸­å¡«è¡¥ç©ºç™½çš„æ …æ ¼å€¼ã€‚
- en: 'I do this by interpolating neighboring pixels for each empty zone to try and
    give a better structure to our dataset with the following code snippet:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘é€šè¿‡å¯¹æ¯ä¸ªç©ºç™½åŒºåŸŸçš„ç›¸é‚»åƒç´ è¿›è¡Œæ’å€¼ï¼Œè¯•å›¾ç”¨ä»¥ä¸‹ä»£ç ç‰‡æ®µä¸ºæˆ‘ä»¬çš„æ•°æ®é›†æä¾›æ›´å¥½çš„ç»“æ„ï¼š
- en: '[PRE33]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'ğŸŒ± **Growing**: *How would you use this to extract contour lines on your zone?*'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸŒ± **Growing**: *ä½ ä¼šå¦‚ä½•ä½¿ç”¨è¿™äº›æ¥æå–ä½ åŒºåŸŸçš„ç­‰é«˜çº¿ï¼Ÿ*'
- en: 'This results in the following:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šå¯¼è‡´ä»¥ä¸‹ç»“æœï¼š
- en: '![](../Images/09eb437fe7b5cabbb33e57de38211fd2.png)![](../Images/17b4a6d800f5b1c48bd591a9065d472e.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/09eb437fe7b5cabbb33e57de38211fd2.png)![](../Images/17b4a6d800f5b1c48bd591a9065d472e.png)'
- en: DTM Visualization results. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: DTM å¯è§†åŒ–ç»“æœã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Data Transformation (3D Point Cloud)
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®è½¬æ¢ï¼ˆ3D ç‚¹äº‘ï¼‰
- en: Aside from conversion between file formats, data transformation refers to the
    various processes to ensure structural and content integrity toward one or more
    processing steps. For example, it is imperative in many feature engineering tasks
    to enhance 3D machine learning model performances.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†æ–‡ä»¶æ ¼å¼ä¹‹é—´çš„è½¬æ¢ï¼Œæ•°æ®è½¬æ¢è¿˜æŒ‡çš„æ˜¯ç¡®ä¿ç»“æ„å’Œå†…å®¹å®Œæ•´æ€§çš„å„ç§è¿‡ç¨‹ï¼Œä»¥ä¾¿äºä¸€ä¸ªæˆ–å¤šä¸ªå¤„ç†æ­¥éª¤ã€‚ä¾‹å¦‚ï¼Œåœ¨è®¸å¤šç‰¹å¾å·¥ç¨‹ä»»åŠ¡ä¸­ï¼Œè¿™å¯¹äºæå‡ 3D æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ã€‚
- en: 'One critical data transformation method is scaling, ensuring that all the values
    in a dataset are within a specific range, such as 0 to 1\. To do this on a point
    cloud, we proceed as follows:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§å…³é”®çš„æ•°æ®è½¬æ¢æ–¹æ³•æ˜¯ç¼©æ”¾ï¼Œç¡®ä¿æ•°æ®é›†ä¸­çš„æ‰€æœ‰å€¼éƒ½åœ¨ç‰¹å®šèŒƒå›´å†…ï¼Œä¾‹å¦‚ 0 åˆ° 1ã€‚è¦å¯¹ç‚¹äº‘æ‰§è¡Œæ­¤æ“ä½œï¼Œæˆ‘ä»¬æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š
- en: '[PRE34]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This transforms our original point cloud with coordinates between 0 and 1 for
    all our points. Therefore, if we were to plot their distribution along the three
    axes, we would use the following:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æˆ‘ä»¬åŸå§‹çš„ç‚¹äº‘è½¬æ¢ä¸ºæ‰€æœ‰ç‚¹çš„åæ ‡åœ¨ 0 å’Œ 1 ä¹‹é—´ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬è¦ç»˜åˆ¶å®ƒä»¬æ²¿ä¸‰ä¸ªè½´çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä»¥ä¸‹å†…å®¹ï¼š
- en: '[PRE35]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'To obtain:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: è·å¾—ï¼š
- en: '![](../Images/59891a96517f44038b65ecdc5efcb218.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59891a96517f44038b65ecdc5efcb218.png)'
- en: 3D Point Cloud Distribution analysis. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ç‚¹äº‘åˆ†å¸ƒåˆ†æã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: As you can see, our point cloud now has X, Y, and Z coordinates that range between
    0 and 1.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬çš„ç‚¹äº‘ç°åœ¨æ‹¥æœ‰ Xã€Y å’Œ Z åæ ‡ï¼Œè¿™äº›åæ ‡çš„èŒƒå›´åœ¨ 0 å’Œ 1 ä¹‹é—´ã€‚
- en: 'ğŸ‡ **Note**: *This is interesting on another flavor. Indeed, we tend to a pattern
    looking at the Z distribution, where a hint toward a Z-driven algorithm makes
    sense, for example, to distinguish roofs from the ground points*.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‡ **æ³¨æ„**ï¼š*è¿™åœ¨å¦ä¸€ç§å£å‘³ä¸Šå¾ˆæœ‰è¶£ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬ä¼šæ ¹æ® Z åˆ†å¸ƒçš„æ¨¡å¼æ¥å¯»æ‰¾çº¿ç´¢ï¼Œè¿™æ ·çš„ Z é©±åŠ¨ç®—æ³•æ˜¯æœ‰æ„ä¹‰çš„ï¼Œä¾‹å¦‚ï¼Œç”¨äºåŒºåˆ†å±‹é¡¶å’Œåœ°é¢ç‚¹*ã€‚
- en: 'Data Reduction: Cropping mask, Point Cloud Sampling'
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®å‡å°‘ï¼šè£å‰ªæ©ç ï¼Œç‚¹äº‘é‡‡æ ·
- en: Data reduction encompasses the various techniques in which data is reduced to
    its simplest possible form to enable optimal analytical tasks.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å‡å°‘åŒ…æ‹¬å„ç§æŠ€æœ¯ï¼Œé€šè¿‡è¿™äº›æŠ€æœ¯æ•°æ®è¢«ç®€åŒ–åˆ°æœ€ç®€å•çš„å½¢å¼ï¼Œä»¥ä¾¿è¿›è¡Œæœ€ä½³çš„åˆ†æä»»åŠ¡ã€‚
- en: 'One of these is data cropping: reducing the spatial extent of our dataset.
    A clear example could be executed on raster datasets to limit the memory footprint
    by loading a huge zone when we want to focus on a tighter area. To do this, with
    rasterio, we have first to create a geopandas bounding box that will act as the
    filtering mask:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¹‹ä¸€æ˜¯æ•°æ®è£å‰ªï¼šå‡å°‘æ•°æ®é›†çš„ç©ºé—´èŒƒå›´ã€‚ä¸€ä¸ªæ˜ç¡®çš„ä¾‹å­æ˜¯åœ¨æ …æ ¼æ•°æ®é›†ä¸Šæ‰§è¡Œï¼Œä»¥é™åˆ¶å†…å­˜å ç”¨ï¼Œå½“æˆ‘ä»¬æƒ³è¦å…³æ³¨æ›´å°çš„åŒºåŸŸæ—¶åŠ è½½ä¸€ä¸ªå·¨å¤§çš„åŒºåŸŸã€‚ä¸ºæ­¤ï¼Œä½¿ç”¨
    rasterioï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ª geopandas è¾¹ç•Œæ¡†ï¼Œä½œä¸ºè¿‡æ»¤æ©ç ï¼š
- en: '[PRE36]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We then get a nice area box that we use as a mask on the original file (or
    any raster of choice) by also making sure we copy the metadata of the original
    file onto the cropped version:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ¼‚äº®çš„åŒºåŸŸæ¡†ï¼Œå°†å…¶ç”¨ä½œåŸå§‹æ–‡ä»¶ï¼ˆæˆ–ä»»ä½•æ …æ ¼æ–‡ä»¶ï¼‰çš„æ©ç ï¼ŒåŒæ—¶ç¡®ä¿å°†åŸå§‹æ–‡ä»¶çš„å…ƒæ•°æ®å¤åˆ¶åˆ°è£å‰ªåçš„ç‰ˆæœ¬ä¸­ï¼š
- en: '[PRE37]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'This results in the following:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šå¯¼è‡´ä»¥ä¸‹ç»“æœï¼š
- en: '![](../Images/e9f27afe0639f0f3410bedfa686989bb.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9f27afe0639f0f3410bedfa686989bb.png)'
- en: Cropping a CIR Image. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: è£å‰ª CIR å›¾åƒã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'Another clear data reduction technique is data sampling. In our case, trying
    to reduce the number of points in our point cloud. This can be done in several
    ways (which, again, extend the scope of this article), with one using the voxel
    data structure a priori: we want to keep one best candidate per voxel:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§æ˜ç¡®çš„æ•°æ®å‡å°‘æŠ€æœ¯æ˜¯æ•°æ®é‡‡æ ·ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå°±æ˜¯è¯•å›¾å‡å°‘ç‚¹äº‘ä¸­çš„ç‚¹æ•°ã€‚è¿™å¯ä»¥é€šè¿‡å‡ ç§æ–¹æ³•æ¥å®ç°ï¼ˆè¿™äº›æ–¹æ³•ä¹Ÿè¶…å‡ºäº†æœ¬æ–‡çš„èŒƒå›´ï¼‰ï¼Œå…¶ä¸­ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨é¢„å®šä¹‰çš„ä½“ç´ æ•°æ®ç»“æ„ï¼šæˆ‘ä»¬å¸Œæœ›æ¯ä¸ªä½“ç´ ä¿ç•™ä¸€ä¸ªæœ€ä½³å€™é€‰ç‚¹ï¼š
- en: '[PRE38]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This results in the following downsampled point cloud:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šå¯¼è‡´ä»¥ä¸‹ä¸‹é‡‡æ ·ç‚¹äº‘ï¼š
- en: '![](../Images/530a14f72994cc61d0aeb547aa8f0e3e.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/530a14f72994cc61d0aeb547aa8f0e3e.png)'
- en: 3D Point Cloud Downsampling results. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ç‚¹äº‘ä¸‹é‡‡æ ·ç»“æœã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Finally, we can enrich our dataset in various ways.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å„ç§æ–¹å¼ä¸°å¯Œæˆ‘ä»¬çš„æ•°æ®é›†ã€‚
- en: 'Data Enrichment: Inject POI proximity to point clouds'
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®ä¸°å¯Œï¼šå°† POI è¿‘ä¼¼å€¼æ³¨å…¥ç‚¹äº‘
- en: Depending on the application, various fusion techniques can be applied to merge
    the datasets. For 2D and 2.5D integration, raster-based methods like weighted
    averaging or majority voting can combine multiple data layers. In 3D integration,
    point cloud fusion techniques, such as merging, averaging, or voxelization, are
    employed to create a single, consolidated 3D point cloud representing the entire
    area.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®åº”ç”¨éœ€æ±‚ï¼Œå¯ä»¥é‡‡ç”¨å„ç§èåˆæŠ€æœ¯æ¥åˆå¹¶æ•°æ®é›†ã€‚å¯¹äº 2D å’Œ 2.5D é›†æˆï¼Œå¯ä»¥ä½¿ç”¨åŸºäºæ …æ ¼çš„æ–¹æ³•ï¼Œå¦‚åŠ æƒå¹³å‡æˆ–å¤šæ•°æŠ•ç¥¨ï¼Œæ¥ç»“åˆå¤šä¸ªæ•°æ®å±‚ã€‚åœ¨ 3D
    é›†æˆä¸­ï¼Œä½¿ç”¨ç‚¹äº‘èåˆæŠ€æœ¯ï¼Œå¦‚åˆå¹¶ã€å¹³å‡æˆ–ä½“ç´ åŒ–ï¼Œæ¥åˆ›å»ºä¸€ä¸ªä»£è¡¨æ•´ä¸ªåŒºåŸŸçš„å•ä¸€åˆæˆ 3D ç‚¹äº‘ã€‚
- en: 'ğŸ¦Š **Florent**: *Using data enrichment (fusion) techniques, we combine information
    from multiple sources (it can be web-based, from a data acquisition mission, or
    any relevant way to gather data). This allows the creation of a more comprehensive
    and accurate representation of the underlying phenomenon. These can touch on raster
    Weighted Averaging (Involves taking a weighted average of pixel values from multiple
    raster layers, where the weights represent the importance or reliability of each
    raster layer), Majority Voting (Combines categorical raster data by assigning
    the majority class to each pixel location, helpful in land cover classification).
    But these are for another time.* ğŸ˜‰'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦Š **Florent**: *ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆèåˆï¼‰æŠ€æœ¯ï¼Œæˆ‘ä»¬å°†æ¥è‡ªå¤šä¸ªæ¥æºçš„ä¿¡æ¯ç»“åˆèµ·æ¥ï¼ˆè¿™äº›æ¥æºå¯ä»¥æ˜¯åŸºäºç½‘ç»œçš„ã€æ¥è‡ªæ•°æ®é‡‡é›†ä»»åŠ¡çš„ï¼Œæˆ–ä»»ä½•ç›¸å…³çš„æ•°æ®æ”¶é›†æ–¹å¼ï¼‰ã€‚è¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿåˆ›å»ºæ›´å…¨é¢ã€æ›´å‡†ç¡®çš„åŸºç¡€ç°è±¡è¡¨ç¤ºã€‚è¿™äº›æŠ€æœ¯åŒ…æ‹¬æ …æ ¼åŠ æƒå¹³å‡ï¼ˆæ¶‰åŠå¯¹æ¥è‡ªå¤šä¸ªæ …æ ¼å±‚çš„åƒç´ å€¼è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œå…¶ä¸­æƒé‡ä»£è¡¨æ¯ä¸ªæ …æ ¼å±‚çš„é‡è¦æ€§æˆ–å¯é æ€§ï¼‰ã€å¤šæ•°æŠ•ç¥¨ï¼ˆé€šè¿‡å°†å¤šæ•°ç±»åˆ«åˆ†é…ç»™æ¯ä¸ªåƒç´ ä½ç½®æ¥ç»“åˆåˆ†ç±»æ …æ ¼æ•°æ®ï¼Œå¯¹åœŸåœ°è¦†ç›–åˆ†ç±»éå¸¸æœ‰å¸®åŠ©ï¼‰ã€‚ä½†è¿™äº›å†…å®¹ç•™åˆ°ä»¥åå†è®²ã€‚*
    ğŸ˜‰'
- en: 'A swift way to extend our dataset is to compute additional features. This is
    done, for example, on the 3D point clouds by extracting normals computed from
    a neighborhood of points that permits extracting the best fitting plane, then
    the normals. We automatically do this with the following piece of code:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰©å±•æ•°æ®é›†çš„å¿«é€Ÿæ–¹æ³•æ˜¯è®¡ç®—é¢å¤–çš„ç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œè¿™å¯ä»¥é€šè¿‡ä»ç‚¹äº‘ä¸­æå–ä»é‚»åŸŸè®¡ç®—å‡ºçš„æ³•çº¿æ¥å®Œæˆï¼Œè¿™æ ·å¯ä»¥æå–æœ€ä½³æ‹Ÿåˆå¹³é¢ï¼Œç„¶åè®¡ç®—æ³•çº¿ã€‚æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç è‡ªåŠ¨å®Œæˆæ­¤æ“ä½œï¼š
- en: '[PRE39]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'And as you can see below, we can visualize our new point cloud without or with
    normals (pressing â€œ`n`â€ in the interactive window viewer):'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸‹æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥åœ¨äº’åŠ¨çª—å£æŸ¥çœ‹å™¨ä¸­æŒ‰ä¸‹â€œ`n`â€é”®æ¥å¯è§†åŒ–æˆ‘ä»¬æ–°çš„ç‚¹äº‘ï¼Œæ— è®ºæ˜¯å¦æ˜¾ç¤ºæ³•çº¿ï¼š
- en: '![](../Images/42d6422b3084e0d01f17e87cc5b58b51.png)![](../Images/b95f5edb82a59699d99586a900bd2284.png)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42d6422b3084e0d01f17e87cc5b58b51.png)![](../Images/b95f5edb82a59699d99586a900bd2284.png)'
- en: Normal computation and visualization from the 3D Point Cloud. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ä» 3D ç‚¹äº‘ä¸­è®¡ç®—å’Œå¯è§†åŒ–æ³•çº¿ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Step 6\. Multi-modal Data Visualization
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 6\. å¤šæ¨¡æ€æ•°æ®å¯è§†åŒ–
- en: '![](../Images/fc0e59685c0dbb2b9508d883a6272491.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc0e59685c0dbb2b9508d883a6272491.png)'
- en: Step 6\. Multi-Modal Data Visualization.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 6\. å¤šæ¨¡æ€æ•°æ®å¯è§†åŒ–ã€‚
- en: Multi-modal data visualization is a powerful approach that seamlessly integrates
    our diverse geospatial data, including vector data, spatial raster imagery, Digital
    Surface Models (DSM), Digital Terrain Models (DTM), point clouds, and city models.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šæ¨¡æ€æ•°æ®å¯è§†åŒ–æ˜¯ä¸€ç§å¼ºå¤§çš„æ–¹æ³•ï¼Œå¯ä»¥æ— ç¼é›†æˆæˆ‘ä»¬å¤šæ ·çš„åœ°ç†ç©ºé—´æ•°æ®ï¼ŒåŒ…æ‹¬çŸ¢é‡æ•°æ®ã€ç©ºé—´æ …æ ¼å½±åƒã€æ•°å­—è¡¨é¢æ¨¡å‹ï¼ˆDSMï¼‰ã€æ•°å­—åœ°å½¢æ¨¡å‹ï¼ˆDTMï¼‰ã€ç‚¹äº‘å’ŒåŸå¸‚æ¨¡å‹ã€‚
- en: '![](../Images/a4b9c501070cac01cda1bdf4410b30eb.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4b9c501070cac01cda1bdf4410b30eb.png)'
- en: 'Libraries used for 3D Data Visualization: Matplotlib, Open3D and RasterIO (2D/2.5D).
    Â© [F. Poux](https://learngeodata.eu/)'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äº 3D æ•°æ®å¯è§†åŒ–çš„åº“ï¼šMatplotlibã€Open3D å’Œ RasterIOï¼ˆ2D/2.5Dï¼‰ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: This comprehensive fusion of data types allows for a more holistic understanding
    of the environment, laying the groundwork for more informed decision-making and
    sophisticated analyses. Now, letâ€™s dive into a Python solution that showcases
    how to achieve this remarkable visualization feat!
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç±»å‹çš„å…¨é¢èåˆä½¿æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç¯å¢ƒæœ‰æ›´å…¨é¢çš„ç†è§£ï¼Œä¸ºæ›´æ˜æ™ºçš„å†³ç­–å’Œå¤æ‚çš„åˆ†æå¥ å®šåŸºç¡€ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ä¸€ä¸ª Python è§£å†³æ–¹æ¡ˆï¼Œå±•ç¤ºå¦‚ä½•å®ç°è¿™ä¸€å“è¶Šçš„å¯è§†åŒ–æ•ˆæœï¼
- en: The trick is to understand the strengths and limits of each of our libraries!
    Indeed, what we will do is actually to stick to Open3D to check for the consistency
    between the data modalities (Meshes, 3D Point Clouds, and Voxels) and use **the
    point cloud dataset as the canonical reference to then link all the other datasets
    to it**.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: è¯€çªåœ¨äºäº†è§£æˆ‘ä»¬æ¯ä¸ªåº“çš„ä¼˜ç‚¹å’Œé™åˆ¶ï¼äº‹å®ä¸Šï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äº Open3Dï¼Œä»¥æ£€æŸ¥æ•°æ®æ¨¡æ€ï¼ˆç½‘æ ¼ã€3D ç‚¹äº‘å’Œä½“ç´ ï¼‰ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œå¹¶ä½¿ç”¨**ç‚¹äº‘æ•°æ®é›†ä½œä¸ºæ ‡å‡†å‚è€ƒï¼Œç„¶åå°†æ‰€æœ‰å…¶ä»–æ•°æ®é›†é“¾æ¥åˆ°å®ƒ**ã€‚
- en: '![](../Images/6f79f90b3eefcc73332f1bad24cd1dec.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f79f90b3eefcc73332f1bad24cd1dec.png)'
- en: Point Cloud as a canonical frame of reference. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹äº‘ä½œä¸ºæ ‡å‡†å‚è€ƒæ¡†æ¶ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'Therefore, the first step is to analyze the 3D modalities:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œç¬¬ä¸€æ­¥æ˜¯åˆ†æ3Dæ¨¡æ€ï¼š
- en: '[PRE40]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![](../Images/d9b3ea6b8885875589da756fcc4e517d.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9b3ea6b8885875589da756fcc4e517d.png)'
- en: Combined 3D Datasets. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: ç»„åˆçš„3Dæ•°æ®é›†ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'ğŸ¦Š **Florent**: *While the image may be confusing, be warned that nothing is
    going wrong when you visualize these three in one image. Indeed, the extent of
    the datasets are different to allow us to delineate the modalities better visually.*'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦Š **Florent**ï¼š*è™½ç„¶å›¾åƒå¯èƒ½ä»¤äººå›°æƒ‘ï¼Œä½†è¯·æ³¨æ„ï¼Œå½“ä½ åœ¨ä¸€å¼ å›¾ä¸­å¯è§†åŒ–è¿™ä¸‰è€…æ—¶ï¼Œä»€ä¹ˆä¹Ÿæ²¡æœ‰å‡ºé”™ã€‚äº‹å®ä¸Šï¼Œæ•°æ®é›†çš„èŒƒå›´ä¸åŒï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´å¥½åœ°åœ¨è§†è§‰ä¸ŠåŒºåˆ†æ¨¡æ€ã€‚*
- en: 'Great! From there, we use the point cloud dataset with Numpy on a top-down
    view to check the X-Y consistency, for example, with vector data:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªå¥½äº†ï¼æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨Numpyå¯¹ç‚¹äº‘æ•°æ®é›†è¿›è¡Œè‡ªä¸Šè€Œä¸‹çš„è§†å›¾ï¼Œä»¥æ£€æŸ¥X-Yä¸€è‡´æ€§ï¼Œä¾‹å¦‚ï¼Œä¸çŸ¢é‡æ•°æ®ä¸€èµ·ï¼š
- en: '[PRE41]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This lays an obvious overlay of the vector dataset onto our point cloud that
    opens up a world of possibility to make these two dataset talk:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜æ˜¾åœ°å°†çŸ¢é‡æ•°æ®é›†å åŠ åˆ°æˆ‘ä»¬çš„ç‚¹äº‘ä¸Šï¼Œä¸ºä½¿è¿™ä¸¤ä¸ªæ•°æ®é›†ç›¸äº’äº¤æµå¼€è¾Ÿäº†å¯èƒ½æ€§ï¼š
- en: '![](../Images/976f9ab5d7824cfb9f9dea1271e5e420.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/976f9ab5d7824cfb9f9dea1271e5e420.png)'
- en: Integrating Vector and Raster datasets. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆçŸ¢é‡å’Œæ …æ ¼æ•°æ®é›†ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'Then, we continue our linkage by linking the vector dataset, reprojected, with
    spatial imagery:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡å°†çŸ¢é‡æ•°æ®é›†ï¼ˆé‡æŠ•å½±ï¼‰ä¸ç©ºé—´å½±åƒè¿æ¥ï¼Œç»§ç»­æˆ‘ä»¬çš„é“¾æ¥ï¼š
- en: '[PRE42]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This results in the visualization, which demands a bit of zoom, as expressed
    in the code, to better situate the fit of both datasets.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´äº†å¯è§†åŒ–ç»“æœï¼Œéœ€è¦ç¨å¾®æ”¾å¤§ï¼Œå¦‚ä»£ç ä¸­æ‰€ç¤ºï¼Œä»¥æ›´å¥½åœ°å®šä½ä¸¤ä¸ªæ•°æ®é›†çš„é€‚é…æƒ…å†µã€‚
- en: '![](../Images/5c29bf16a7b4ec9cdae4a01242c0d4c3.png)![](../Images/82ad186d23513f6900b83de121ce3837.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c29bf16a7b4ec9cdae4a01242c0d4c3.png)![](../Images/82ad186d23513f6900b83de121ce3837.png)'
- en: Results of the integration of raster and vector datasets, with the LiDAR reprojection.
    Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: æ …æ ¼å’ŒçŸ¢é‡æ•°æ®é›†çš„é›†æˆç»“æœï¼Œå¸¦æœ‰LiDARé‡æŠ•å½±ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: The exact process is repeated for the locations from Mappillary, with the code
    below.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹Mappillaryçš„ä½ç½®é‡å¤ç›¸åŒçš„è¿‡ç¨‹ï¼Œä½¿ç”¨å¦‚ä¸‹ä»£ç ã€‚
- en: '[PRE43]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![](../Images/840f727d1ae67895db02d1781f1c2c51.png)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/840f727d1ae67895db02d1781f1c2c51.png)'
- en: View of the points of interest from Mappillary. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: Mappillaryçš„å…´è¶£ç‚¹è§†å›¾ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'And finally, we want to overlay raster, vector, and point cloud modalities
    in one plot with Numpy:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨Numpyå°†æ …æ ¼ã€çŸ¢é‡å’Œç‚¹äº‘æ¨¡æ€å åŠ åœ¨ä¸€ä¸ªå›¾ä¸­ï¼š
- en: '[PRE44]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This little piece of code (careful on the shortcuts and smart tricks employed
    to condense the snippet) permits us to put a final note on the data integration
    of our various modalities.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ®µå°ä»£ç ï¼ˆæ³¨æ„å…¶ä¸­ä½¿ç”¨çš„å¿«æ·æ–¹å¼å’Œèªæ˜çš„æŠ€å·§ä»¥ç¼©çŸ­ä»£ç ï¼‰ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¯¹æˆ‘ä»¬å„ç§æ¨¡æ€çš„æ•°æ®é›†æˆåšå‡ºæœ€ç»ˆçš„è¯´æ˜ã€‚
- en: '![](../Images/c11cb794d94fa4d415fd7bee197ea75e.png)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c11cb794d94fa4d415fd7bee197ea75e.png)'
- en: Shapefile and point cloud visualization with the DTM. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨DTMçš„Shapefileå’Œç‚¹äº‘å¯è§†åŒ–ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: We approach the end of our systematic approach!
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ¥è¿‘æˆ‘ä»¬ç³»ç»Ÿæ–¹æ³•çš„ç»“æŸï¼
- en: 'By carefully applying these processing techniques, spatial data integration
    enables us to create a holistic representation of the environment, facilitating
    better decision-making and insights in a wide range of applications. Still, we
    must consider the last step: sharing the newly processed data.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»”ç»†åº”ç”¨è¿™äº›å¤„ç†æŠ€æœ¯ï¼Œç©ºé—´æ•°æ®é›†æˆä½¿æˆ‘ä»¬èƒ½å¤Ÿåˆ›å»ºç¯å¢ƒçš„æ•´ä½“è¡¨ç¤ºï¼Œä¿ƒè¿›æ›´å¥½çš„å†³ç­–å’Œæ´å¯ŸåŠ›ï¼Œé€‚ç”¨äºå¹¿æ³›çš„åº”ç”¨ã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬è¿˜å¿…é¡»è€ƒè™‘æœ€åä¸€æ­¥ï¼šåˆ†äº«æ–°å¤„ç†çš„æ•°æ®ã€‚
- en: Step 7\. Data Sharing
  id: totrans-388
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬7æ­¥ï¼šæ•°æ®å…±äº«
- en: '![](../Images/7079d325fbed4facb4a5d45a5733ee87.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7079d325fbed4facb4a5d45a5733ee87.png)'
- en: Step 7\. Data Sharing. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬7æ­¥ï¼šæ•°æ®å…±äº«ã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: Spatial data export is vital in the geospatial data workflow, allowing us to
    seamlessly share, visualize, and analyze 2D and 3D data modalities in established
    software. To this end, we can take a higher, almost aerial view to better situate
    the extent of data sharing impacts. I chose to relate to academia and publishing
    proofs of new scientific discoveries. Indeed, this process that I illustrate below
    is the key to an ethical and robust R&D cycle. As you can see, data export in
    standard formats, which we cover here, is the central link to data browsing before
    pushing automated solutions.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: ç©ºé—´æ•°æ®å¯¼å‡ºåœ¨åœ°ç†ç©ºé—´æ•°æ®å·¥ä½œæµä¸­è‡³å…³é‡è¦ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿæ— ç¼åœ°å…±äº«ã€å¯è§†åŒ–å’Œåˆ†æ 2D å’Œ 3D æ•°æ®æ¨¡æ€ã€‚åœ¨è¿™æ–¹é¢ï¼Œæˆ‘ä»¬å¯ä»¥ä»æ›´é«˜çš„è§’åº¦ï¼Œå‡ ä¹æ˜¯ç©ºä¸­è§†è§’ï¼Œä»¥æ›´å¥½åœ°å®šä½æ•°æ®å…±äº«çš„å½±å“èŒƒå›´ã€‚æˆ‘é€‰æ‹©ä¸å­¦æœ¯ç•Œå’Œå‘å¸ƒæ–°ç§‘å­¦å‘ç°çš„è¯æ®ç›¸å…³è”ã€‚ç¡®å®ï¼Œæˆ‘ä¸‹é¢æ‰€ç¤ºçš„è¿™ä¸ªè¿‡ç¨‹æ˜¯ä¸€ä¸ªé“å¾·ä¸”å¼ºå¥çš„ç ”å‘å‘¨æœŸçš„å…³é”®ã€‚æ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œæ ‡å‡†æ ¼å¼çš„æ•°æ®å¯¼å‡ºï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œä»‹ç»ï¼Œæ˜¯åœ¨æ¨åŠ¨è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆä¹‹å‰æ•°æ®æµè§ˆçš„æ ¸å¿ƒç¯èŠ‚ã€‚
- en: '![](../Images/32b96685b5430dddcef3fd798a779b90.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32b96685b5430dddcef3fd798a779b90.png)'
- en: The 3D Data Sharing Workflow. We start with experiments to populate a database.
    This Database is then used to explore or export results to be filtered for publication.
    The results are then used to repopulate and update the 3D Database. Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 3D æ•°æ®å…±äº«å·¥ä½œæµã€‚æˆ‘ä»¬ä»å®éªŒå¼€å§‹ï¼Œä»¥å¡«å……ä¸€ä¸ªæ•°æ®åº“ã€‚ç„¶åä½¿ç”¨è¯¥æ•°æ®åº“æ¥æ¢ç´¢æˆ–å¯¼å‡ºç»“æœï¼Œä»¥è¿›è¡Œç­›é€‰å’Œå‘å¸ƒã€‚ç»“æœéšåç”¨äºé‡æ–°å¡«å……å’Œæ›´æ–° 3D æ•°æ®åº“ã€‚Â©
    [F. Poux](https://learngeodata.eu/)
- en: 'Thus, the export process must create various file formats suitable for applications
    and software environments. Each file format has its specificities, catering to
    different use cases and previously expressed requirements. For in-depth 3D data
    export, I propose to relate to these articles:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¯¼å‡ºè¿‡ç¨‹å¿…é¡»åˆ›å»ºå„ç§é€‚ç”¨äºåº”ç”¨ç¨‹åºå’Œè½¯ä»¶ç¯å¢ƒçš„æ–‡ä»¶æ ¼å¼ã€‚æ¯ç§æ–‡ä»¶æ ¼å¼éƒ½æœ‰å…¶ç‰¹å®šæ€§ï¼Œæ»¡è¶³ä¸åŒçš„ä½¿ç”¨æ¡ˆä¾‹å’Œå…ˆå‰è¡¨è¾¾çš„éœ€æ±‚ã€‚å¯¹äºæ·±å…¥çš„ 3D æ•°æ®å¯¼å‡ºï¼Œæˆ‘å»ºè®®å‚è€ƒä»¥ä¸‹æ–‡ç« ï¼š
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
    [## LiDAR åŸå¸‚æ¨¡å‹çš„ 3D Python å·¥ä½œæµï¼šé€æ­¥æŒ‡å—'
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Pythonâ€¦
  id: totrans-396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è§£é” 3D åŸå¸‚å»ºæ¨¡åº”ç”¨ç¨‹åºçš„ç²¾ç®€å·¥ä½œæµçš„ç»ˆææŒ‡å—ã€‚æ•™ç¨‹æ¶µç›–äº† Pythonâ€¦
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----7ef8ef14589a--------------------------------)
- en: 'Understanding how we can do the same with vector and raster datasets is essential.
    As always, the simpler, the better: let us focus on these last exporting steps.
    To export the raster imagery, you can do the following with rasterio:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: äº†è§£å¦‚ä½•åœ¨çŸ¢é‡å’Œæ …æ ¼æ•°æ®é›†ä¸Šè¿›è¡Œç›¸åŒçš„æ“ä½œæ˜¯è‡³å…³é‡è¦çš„ã€‚åƒå¾€å¸¸ä¸€æ ·ï¼Œè¶Šç®€å•è¶Šå¥½ï¼šè®©æˆ‘ä»¬ä¸“æ³¨äºæœ€åçš„å¯¼å‡ºæ­¥éª¤ã€‚è¦å¯¼å‡ºæ …æ ¼å›¾åƒï¼Œä½ å¯ä»¥ä½¿ç”¨ rasterio
    æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
- en: '[PRE45]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'And concerning vector datasets, geopandas makes it a breeze to export the georeferenced
    and clipped result from our processing stages:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºçŸ¢é‡æ•°æ®é›†ï¼Œgeopandas ä½¿å¾—ä»æˆ‘ä»¬çš„å¤„ç†é˜¶æ®µå¯¼å‡ºåœ°ç†å‚è€ƒå’Œè£å‰ªç»“æœå˜å¾—è½»è€Œæ˜“ä¸¾ï¼š
- en: '[PRE46]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, you can import these in a software such as QGIS or CloudCompare, which
    results in the following:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œä½ å¯ä»¥å°†è¿™äº›æ•°æ®å¯¼å…¥åˆ°åƒ QGIS æˆ– CloudCompare è¿™æ ·çš„è½¯ä»¶ä¸­ï¼Œç»“æœå¦‚ä¸‹ï¼š
- en: '![](../Images/94276d8e4de9c5ae70d26b086db476dd.png)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94276d8e4de9c5ae70d26b086db476dd.png)'
- en: 3D Point Cloud, 3D Voxel, 3D City Model, 3D DTM, Raster and vector dataset overlayed.
    They are integrated with the proposed methodology.Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ç‚¹äº‘ã€3D ä½“ç´ ã€3D åŸå¸‚æ¨¡å‹ã€3D DTMã€æ …æ ¼å’ŒçŸ¢é‡æ•°æ®é›†çš„å åŠ ã€‚å®ƒä»¬ä¸æå‡ºçš„æ–¹æ³•è®ºè¿›è¡Œäº†æ•´åˆã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: This is the perfect layering of 3D, Raster, and Vector datasets!
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ 3Dã€æ …æ ¼å’ŒçŸ¢é‡æ•°æ®é›†çš„å®Œç¾å±‚å ï¼
- en: Conclusion
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: We have embarked on an exciting journey exploring the world of 3D data integration
    with Python. Throughout this comprehensive guide, we have uncovered the immense
    potential of combining various 3D data modalities, such as point clouds, meshes,
    city models, DSM, DTM, and voxels, to create a unified and holistic representation
    of the spatial environment.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼€å§‹äº†ä¸€æ®µæ¿€åŠ¨äººå¿ƒçš„æ—…ç¨‹ï¼Œæ¢ç´¢ä½¿ç”¨ Python è¿›è¡Œ 3D æ•°æ®é›†æˆçš„ä¸–ç•Œã€‚åœ¨è¿™ä»½å…¨é¢çš„æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬æ­ç¤ºäº†å°†å„ç§ 3D æ•°æ®æ¨¡æ€ï¼ˆå¦‚ç‚¹äº‘ã€ç½‘æ ¼ã€åŸå¸‚æ¨¡å‹ã€DSMã€DTM
    å’Œä½“ç´ ï¼‰ç»“åˆèµ·æ¥ï¼Œä»¥åˆ›å»ºç©ºé—´ç¯å¢ƒçš„ç»Ÿä¸€å’Œå…¨é¢è¡¨ç¤ºçš„å·¨å¤§æ½œåŠ›ã€‚
- en: '![](../Images/57473a23703dd40f51db1e9702411dd7.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/57473a23703dd40f51db1e9702411dd7.png)'
- en: The workflow covered in this 3D Data Integration Guide.Â© [F. Poux](https://learngeodata.eu/)
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ 3D æ•°æ®é›†æˆæŒ‡å—ä¸­ä»‹ç»çš„å·¥ä½œæµã€‚Â© [F. Poux](https://learngeodata.eu/)
- en: 'To summarize, I list below the key takeaways related to the seven steps that
    we covered:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“ä¸€ä¸‹ï¼Œæˆ‘åœ¨ä¸‹é¢åˆ—å‡ºäº†æˆ‘ä»¬æ‰€æ¶µç›–çš„ä¸ƒä¸ªæ­¥éª¤çš„å…³é”®è¦ç‚¹ï¼š
- en: Setting up a multi-modal coding environment in Python needs to accommodate a
    minimal number of robust libraries.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨Pythonä¸­è®¾ç½®å¤šæ¨¡æ€ç¼–ç ç¯å¢ƒéœ€è¦é…å¤‡å°½å¯èƒ½å°‘çš„å¼ºå¤§åº“ã€‚
- en: When sourcing datasets, it is best to carefully consider available open datasets
    with clear licensing options through web interfaces that make it easy for you
    to gather relevant samples.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨è·å–æ•°æ®é›†æ—¶ï¼Œæœ€å¥½ä»”ç»†è€ƒè™‘é€šè¿‡ç½‘ç»œæ¥å£æä¾›çš„å…·æœ‰æ˜ç¡®è®¸å¯é€‰é¡¹çš„å¼€æ”¾æ•°æ®é›†ï¼Œè¿™æ ·æ‚¨å¯ä»¥è½»æ¾æ”¶é›†ç›¸å…³æ ·æœ¬ã€‚
- en: It is an excellent practice to independently profile each modality and assess
    its main characteristics (CRS, precision, resolution, â€¦) through quick analysis
    schemes.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‹¬ç«‹åœ°å¯¹æ¯ç§æ¨¡æ€è¿›è¡Œåˆ†æå¹¶è¯„ä¼°å…¶ä¸»è¦ç‰¹æ€§ï¼ˆåæ ‡å‚è€ƒç³»ç»Ÿã€ç²¾åº¦ã€åˆ†è¾¨ç‡ç­‰ï¼‰æ˜¯ä¸€é¡¹ä¼˜ç§€çš„å®è·µï¼Œå»ºè®®é€šè¿‡å¿«é€Ÿåˆ†ææ–¹æ¡ˆæ¥å®ç°ã€‚
- en: Mastering Coordinate Reference Systems and knowing how to go from one another
    and what a specific transformation implies is mandatory for scalable workflows
    with spatial datasets.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŒæ¡åæ ‡å‚è€ƒç³»ç»Ÿï¼Œå¹¶äº†è§£å¦‚ä½•ä»ä¸€ä¸ªç³»ç»Ÿè½¬æ¢åˆ°å¦ä¸€ä¸ªç³»ç»Ÿï¼Œä»¥åŠç‰¹å®šçš„è½¬æ¢æ„å‘³ç€ä»€ä¹ˆï¼Œå¯¹äºå…·æœ‰ç©ºé—´æ•°æ®é›†çš„å¯æ‰©å±•å·¥ä½œæµæ˜¯å¼ºåˆ¶æ€§çš„ã€‚
- en: Pre-processing algorithms and techniques are often the keys between optimized
    and organized data assemblies and data warehouses with chaotic management systems.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„å¤„ç†ç®—æ³•å’ŒæŠ€æœ¯é€šå¸¸æ˜¯ä¼˜åŒ–å’Œç»„ç»‡çš„æ•°æ®é›†ä¸å…·æœ‰æ··ä¹±ç®¡ç†ç³»ç»Ÿçš„æ•°æ®ä»“åº“ä¹‹é—´çš„å…³é”®æ‰€åœ¨ã€‚
- en: nD data visualization is paramount to a successful data integration workflow
    and demands that you carefully consider which dataset/ data modality acts as your
    canonical anchor
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: nD æ•°æ®å¯è§†åŒ–å¯¹æˆåŠŸçš„æ•°æ®é›†æˆå·¥ä½œæµè‡³å…³é‡è¦ï¼Œå¹¶è¦æ±‚æ‚¨ä»”ç»†è€ƒè™‘å“ªä¸ªæ•°æ®é›†/æ•°æ®æ¨¡æ€å……å½“æ‚¨çš„æ ‡å‡†é”šç‚¹ã€‚
- en: Data Sharing as a final stage permits ensuring a system from A to Z that considers
    practical and operational considerations, even in academia or R&D actions where
    production phases can be overlooked.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®å…±äº«ä½œä¸ºæœ€ç»ˆé˜¶æ®µï¼Œå…è®¸ç¡®ä¿ä¸€ä¸ªä»Aåˆ°Zçš„ç³»ç»Ÿï¼Œè€ƒè™‘å®é™…å’Œæ“ä½œæ€§çš„å› ç´ ï¼Œå³ä½¿åœ¨å­¦æœ¯ç•Œæˆ–ç ”å‘æ´»åŠ¨ä¸­ï¼Œç”Ÿäº§é˜¶æ®µä¹Ÿå¯èƒ½è¢«å¿½è§†ã€‚
- en: '![](../Images/9d299f0b910437eb61e9167de8868a19.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d299f0b910437eb61e9167de8868a19.png)'
- en: As I conclude this guide, I cannot help but be thrilled about the future of
    3D data processing. Currently, with Pythonâ€™s versatility and the growing landscape
    of geospatial technologies, we have a large opening for new ways to better understand
    complex spatial phenomena (and act on them).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»“æŸæœ¬æŒ‡å—æ—¶ï¼Œæˆ‘æ— æ³•ä¸å¯¹3Dæ•°æ®å¤„ç†çš„æœªæ¥æ„Ÿåˆ°å…´å¥‹ã€‚ç›®å‰ï¼Œå‡­å€ŸPythonçš„å¤šåŠŸèƒ½æ€§å’Œä¸æ–­å¢é•¿çš„åœ°ç†ç©ºé—´æŠ€æœ¯ï¼Œæˆ‘ä»¬æœ‰äº†æ›´å¤šçš„æœºä¼šæ¥æ›´å¥½åœ°ç†è§£å¤æ‚çš„ç©ºé—´ç°è±¡ï¼ˆå¹¶å¯¹æ­¤é‡‡å–è¡ŒåŠ¨ï¼‰ã€‚
- en: Therefore, you can expect an even deeper guide to efficient algorithms, innovative
    visualization techniques, and seamless integration with cutting-edge technologies.
    By exploring what we can accomplish with integrated 3D data workflows, we pave
    the way for new applications, some of which coming soon to your laps. This makes
    me say that you are on a good track to shape the future of spatial analysis and
    visualization, transforming how we perceive and interact with the world around
    us.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ‚¨å¯ä»¥æœŸå¾…æ›´æ·±å…¥çš„é«˜æ•ˆç®—æ³•ã€åˆ›æ–°å¯è§†åŒ–æŠ€æœ¯å’Œä¸å‰æ²¿æŠ€æœ¯æ— ç¼é›†æˆçš„æŒ‡å—ã€‚é€šè¿‡æ¢ç´¢æˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨é›†æˆçš„3Dæ•°æ®å·¥ä½œæµå®Œæˆçš„ä»»åŠ¡ï¼Œæˆ‘ä»¬ä¸ºæ–°åº”ç”¨é“ºå¹³äº†é“è·¯ï¼Œå…¶ä¸­ä¸€äº›åº”ç”¨å¾ˆå¿«å°±ä¼šåˆ°æ¥ã€‚è¿™ä½¿æˆ‘è¯´ï¼Œæ‚¨æ­£èµ°åœ¨å¡‘é€ ç©ºé—´åˆ†æå’Œå¯è§†åŒ–æœªæ¥çš„æ­£ç¡®è½¨é“ä¸Šï¼Œæ”¹å˜æˆ‘ä»¬æ„ŸçŸ¥å’Œäº’åŠ¨çš„æ–¹å¼ã€‚
- en: References
  id: totrans-421
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: CÃ¡rdenas, Ivan L., Morales, Luis RodrigoandrÃ©s, **Koeva**, Mila, Atun, Funda,
    & Pfeffer, Karin. (2023, August 31). Digital Twins for Physiological Equivalent
    Temperature Calculation Guide. Zenodo. [https://doi.org/10.5281/zenodo.83064562.](https://doi.org/10.5281/zenodo.83064562.)
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CÃ¡rdenas, Ivan L., Morales, Luis RodrigoandrÃ©s, **Koeva**, Mila, Atun, Funda,
    & Pfeffer, Karin. (2023å¹´8æœˆ31æ—¥). ã€Šç”¨äºç”Ÿç†ç­‰æ•ˆæ¸©åº¦è®¡ç®—çš„æ•°å­—åŒèƒèƒæŒ‡å—ã€‹ã€‚Zenodo. [https://doi.org/10.5281/zenodo.83064562.](https://doi.org/10.5281/zenodo.83064562.)
- en: 'Kumalasari, D.; **Koeva**, M.; Vahdatikhaki, F.; Petrova Antonova, D.; Kuffer,
    M. Planning Walkable Cities: Generative Design Approach towards Digital Twin Implementation.
    Remote Sens. 2023, 15, 1088\. [https://doi.org/10.3390/rs150410883.](https://doi.org/10.3390/rs150410883.)'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kumalasari, D.; **Koeva**, M.; Vahdatikhaki, F.; Petrova Antonova, D.; Kuffer,
    M. ã€Šè§„åˆ’å¯æ­¥è¡ŒåŸå¸‚ï¼šé¢å‘æ•°å­—åŒèƒèƒå®æ–½çš„ç”Ÿæˆè®¾è®¡æ–¹æ³•ã€‹ã€‚é¥æ„Ÿ. 2023, 15, 1088\. [https://doi.org/10.3390/rs150410883.](https://doi.org/10.3390/rs150410883.)
- en: Rajan, V.; **Koeva**, M.; Kuffer, M.; Da Silva Mano, A.; Mishra, S. Three-Dimensional
    Modelling of Past and Present Shahjahanabadthrough Multi-Temporal Remotely Sensed
    Data. Remote Sens. 2023, 15, 2924\. [https://doi.org/10.3390/rs151129244.](https://doi.org/10.3390/rs151129244.)
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Rajan, V.; **Koeva**, M.; Kuffer, M.; Da Silva Mano, A.; Mishra, S. ã€Šé€šè¿‡å¤šæ—¶ç›¸é¥æ„Ÿæ•°æ®å¯¹è¿‡å»å’Œç°åœ¨çš„æ²™è´¾æ±‰çº³å·´å¾·è¿›è¡Œä¸‰ç»´å»ºæ¨¡ã€‹ã€‚é¥æ„Ÿ.
    2023, 15, 2924\. [https://doi.org/10.3390/rs151129244.](https://doi.org/10.3390/rs151129244.)
- en: Ying, Y.; **Koeva**, M.; Kuffer, M.; Zevenbergen, J. Toward 3D Property Valuation
    â€” A Review of Urban 3D Modelling Methods for Digital Twin Creation. ISPRS Int.
    J. Geo-Inf. 2023, 12, 2\. [https://doi.org/10.3390/ijgi120100025.](https://doi.org/10.3390/ijgi120100025.)
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ying, Y.; **ç§‘å¨ƒ**ï¼ŒM.; Kuffer, M.; Zevenbergen, J. å…³äºä¸‰ç»´å±æ€§ä¼°å€¼â€”â€”åŸå¸‚ä¸‰ç»´å»ºæ¨¡æ–¹æ³•åœ¨æ•°å­—å­ªç”Ÿåˆ›å»ºä¸­çš„ç»¼è¿°ã€‚ã€Šå›½é™…åœ°ç†ä¿¡æ¯ç§‘å­¦æœŸåˆŠã€‹ï¼Œ2023ï¼Œ12ï¼Œ2\.
    [https://doi.org/10.3390/ijgi120100025.](https://doi.org/10.3390/ijgi120100025.)
- en: 'La Guardia, M.; **Koeva**, M. Towards Digital Twinning on the Web: Heterogeneous
    3D Data Fusion Based on Open-Source Structure.Remote Sens. 2023, 15, 721\. [https://doi.org/10.3390/rs150307216.](https://doi.org/10.3390/rs150307216.)'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: La Guardia, M.; **ç§‘å¨ƒ**ï¼ŒM. æœå‘ç½‘ç»œä¸Šçš„æ•°å­—å­ªç”Ÿï¼šåŸºäºå¼€æºç»“æ„çš„å¼‚æ„ä¸‰ç»´æ•°æ®èåˆã€‚ã€Šé¥æ„Ÿã€‹ï¼Œ2023ï¼Œ15ï¼Œ721\. [https://doi.org/10.3390/rs150307216.](https://doi.org/10.3390/rs150307216.)
- en: 'Khawte, S. S., **Koeva**, M. N., Gevaert, C. M., Oude Elberink, S., and Pedro,
    A. A.: Digital Twin Creation For Slums In Brazil Based OnUAV Data, Int. Arch.
    Photogramm. Remote Sens. Spatial Inf. Sci., XLVIII-4/W4â€“2022, 75â€“81, [https://doi.org/10.5194/isprs-archives-XLVIII-4-W4-2022-75-2022,](https://doi.org/10.5194/isprs-archives-XLVIII-4-W4-2022-75-2022,)
    2022'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Khawte, S. S., **ç§‘å¨ƒ**ï¼ŒM. N., Gevaert, C. M., Oude Elberink, S., å’Œ Pedro, A.
    A.ï¼šåŸºäºæ— äººæœºæ•°æ®çš„å·´è¥¿è´«æ°‘çªŸæ•°å­—å­ªç”Ÿåˆ›å»ºï¼Œã€Šå›½é™…æ‘„å½±æµ‹é‡ä¸é¥æ„Ÿæ¡£æ¡ˆã€‹ï¼ŒXLVIII-4/W4â€“2022ï¼Œ75â€“81ï¼Œ[https://doi.org/10.5194/isprs-archives-XLVIII-4-W4-2022-75-2022,](https://doi.org/10.5194/isprs-archives-XLVIII-4-W4-2022-75-2022,)
    2022
