- en: Feature Encoding Techniques in Machine Learning with Python Implementation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用 Python 实现的机器学习特征编码技术
- en: 原文：[https://towardsdatascience.com/feature-encoding-techniques-in-machine-learning-with-python-implementation-dbf933e64aa](https://towardsdatascience.com/feature-encoding-techniques-in-machine-learning-with-python-implementation-dbf933e64aa)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/feature-encoding-techniques-in-machine-learning-with-python-implementation-dbf933e64aa](https://towardsdatascience.com/feature-encoding-techniques-in-machine-learning-with-python-implementation-dbf933e64aa)
- en: 6 feature encoding techniques to consider for your data science workflows
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学工作流中需要考虑的 6 种特征编码技术
- en: '[](https://kayjanwong.medium.com/?source=post_page-----dbf933e64aa--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page-----dbf933e64aa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dbf933e64aa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dbf933e64aa--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page-----dbf933e64aa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kayjanwong.medium.com/?source=post_page-----dbf933e64aa--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page-----dbf933e64aa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dbf933e64aa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dbf933e64aa--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page-----dbf933e64aa--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dbf933e64aa--------------------------------)
    ·10 min read·Jan 10, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dbf933e64aa--------------------------------)
    ·阅读时间 10 分钟·2023 年 1 月 10 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f0cc329e9db60722e304729377be4544.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0cc329e9db60722e304729377be4544.png)'
- en: Photo by [Susan Holt Simpson](https://unsplash.com/@shs521?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Susan Holt Simpson](https://unsplash.com/@shs521?utm_source=medium&utm_medium=referral)
    提供的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '***Feature Encoding*** converts categorical variables to numerical variables
    as part of the feature engineering step to make the data compatible with Machine
    Learning models. There are various ways to perform feature encoding, depending
    on the type of categorical variable and other considerations.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '***特征编码*** 将分类变量转换为数值变量，作为特征工程的一部分，使数据与机器学习模型兼容。根据分类变量的类型和其他考虑因素，有多种方法可以执行特征编码。'
- en: This article introduces tips to perform feature encoding in general, elaborating
    on 6 feature encoding techniques that you can consider in your Data Science workflows,
    with comments on when to use them, and finally how to implement them in Python.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了执行特征编码的一般技巧，详细阐述了 6 种特征编码技术，您可以在数据科学工作流中考虑这些技术，提供了使用时机的评论，最后介绍了如何在 Python
    中实现这些技术。
- en: '![](../Images/b373a0a726614c75547f877115df740f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b373a0a726614c75547f877115df740f.png)'
- en: 'Fig 1: Summary of Feature Encoding Techniques — Image by author'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：特征编码技术总结 — 作者提供的图像
- en: The cheat sheet summary of the 6 feature encoding techniques is summarized in
    Fig 1; read on for a detailed explanation and implementation of each method.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 6 种特征编码技术的备忘单总结见图 1；请继续阅读以获取每种方法的详细解释和实现。
- en: Table of Contents
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: Label / Ordinal Encoding
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标签 / 有序编码
- en: One-Hot / Dummy Encoding
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: One-Hot / 虚拟编码
- en: Target Encoding
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目标编码
- en: Count / Frequency Encoding
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计数 / 频率编码
- en: Binary / BaseN Encoding
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 二进制 / BaseN 编码
- en: Hash Encoding
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哈希编码
- en: Feature Encoding Tips
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征编码技巧
- en: 'Tip 1: Prevent Data Leakage'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示 1：防止数据泄露
- en: Given that the purpose of feature encoding is to convert categorical variables
    to numerical variables, we can encode categories such as “cat”, “dog”, and “horse”
    to numbers such as 0, 1, 2, etc. However, we must keep in mind the problem of
    **data leakage** which happens when information in test data is leaked into the
    training data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到特征编码的目的是将分类变量转换为数值变量，我们可以将“cat”、“dog”和“horse”等类别编码为 0、1、2 等数字。然而，我们必须记住**数据泄露**的问题，即测试数据中的信息泄露到训练数据中。
- en: The encoder must be fitted on only the training data, such that the encoder
    only learns the categories that exist in the training set, and then be used to
    transform the validation/test data. **Do not fit the encoder on the whole dataset!**
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 编码器必须仅在训练数据上进行拟合，使编码器仅学习训练集中存在的类别，然后用于转换验证/测试数据。 **不要在整个数据集上拟合编码器！**
- en: The question naturally follows “*What if I have missing or new categories in
    the validation/test data?*”, we can handle this in two ways — by removing these
    unseen categories since the model is not trained on these unseen categories anyway.
    Alternatively, we can encode them as `-1` or other arbitrary values to indicate
    that these are unseen categories.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 问题自然接踵而至：“*如果在验证/测试数据中有缺失或新类别怎么办？*”，我们可以通过两种方式来处理——由于模型未在这些未见类别上训练，因此可以删除这些未见类别。或者，我们可以将它们编码为`-1`或其他任意值，以指示这些是未见类别。
- en: 'Tip 2: Save your Encoders'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示 2：保存你的编码器
- en: As mentioned in the previous tip, encoders are fitted on training data (with
    method `.fit`) and used to transform validation/test data (with method `.transform`).
    It is best to save the encoder to transform the validation/test data later on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，编码器在训练数据上进行拟合（使用`.fit`方法），并用于转换验证/测试数据（使用`.transform`方法）。最好保存编码器以便稍后转换验证/测试数据。
- en: Other benefits of saving encoders are the ability to retrieve the categories
    or to transform the encoded values back to their categories (with method `.inverse_transform`)
    if applicable and required.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 保存编码器的其他好处包括能够检索类别或将编码的值转换回其类别（使用`.inverse_transform`方法），如果适用且需要的话。
- en: Now let's dive into the feature encoding techniques!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们深入探讨特征编码技术！
- en: №1\. Label / Ordinal Encoder
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: №1. 标签 / 顺序编码器
- en: Label Encoder and Ordinal Encoder encode categories into numerical values directly
    (refer to Fig 2).
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标签编码器和顺序编码器将类别直接编码为数值（参见图 2）。
- en: Label Encoder is used for ***nominal*** categorical variables (categories without
    order i.e., red, green, blue) while Ordinal Encoder is used for ***ordinal***
    categorical variables (categories with order i.e., small, medium, large).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 标签编码器用于***名义***分类变量（没有顺序的类别，例如红色、绿色、蓝色），而顺序编码器用于***顺序***分类变量（有顺序的类别，例如小、中、大）。
- en: '![](../Images/2e8d46ea0373347ddaf5bfe7bfcef4ab.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e8d46ea0373347ddaf5bfe7bfcef4ab.png)'
- en: 'Fig 2: Example of Label Encoding — Image by author'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：标签编码示例 — 作者提供的图片
- en: Given that the cardinality (number of categories) is `n`, Label and Ordinal
    Encoder encodes the values from `0` to `n-1`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 给定基数（类别数量）为`n`，标签和顺序编码器将值编码从`0`到`n-1`。
- en: When to use Label / Ordinal Encoder
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用标签 / 顺序编码器
- en: '**Nominal/Ordinal Variables**: Label Encoder is used for nominal categorical
    variables, while Ordinal Encoder is used for ordinal categorical variables'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义/顺序变量**：标签编码器用于名义分类变量，而顺序编码器用于顺序分类变量'
- en: '**Supports High Cardinality**: Label and Ordinal Encoder can be used in cases
    where there are many different categories'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持高基数**：标签和顺序编码器可以用于类别非常多的情况'
- en: '**Unseen Variables**: Ordinal Encoder can encode unseen variables in the validation/test
    set with an arbitrary value (refer to the code example below), by default it throws
    a value error'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未见变量**：顺序编码器可以用任意值编码验证/测试集中的未见变量（参见下面的代码示例），默认情况下会抛出值错误'
- en: Cons of Label / Ordinal Encoder
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标签 / 顺序编码器的缺点
- en: '**Unseen Variables**: Label Encoder does not encode unseen variables in the
    validation/test set and will throw a value error, special error handling must
    be done to avoid this error'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未见变量**：标签编码器不对验证/测试集中的未见变量进行编码，并会抛出值错误，必须进行特殊的错误处理以避免此错误'
- en: '**Categories interpreted as numerical values**: Machine Learning models would
    read the encoded columns as numerical variables instead of interpreting them as
    distinct categories'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将类别解释为数值**：机器学习模型会将编码的列读取为数值变量，而不是将其解释为不同的类别'
- en: For Label Encoder, it can only encode one column at a time and multiple label
    encoders must be initialized for each categorical column.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标签编码器，它一次只能编码一列，每个分类列必须初始化多个标签编码器。
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For Ordinal Encoder, it can encode multiple columns at once, and the order of
    the categories can be specified.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于顺序编码器，它可以一次编码多个列，并且可以指定类别的顺序。
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: №2\. One Hot / Dummy Encoding
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: №2. 独热编码 / 虚拟编码
- en: In One-Hot Encoding and Dummy Encoding, the categorical column is split into
    multiple columns consisting of ones and zeros (refer to Fig 3).
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在 One-Hot 编码和虚拟编码中，分类列被拆分为多个包含 1 和 0 的列（参见图 3）。
- en: This addresses the drawback to Label and Ordinal Encoding where columns are
    now read in as categorical columns due to encoded data being represented as multiple
    boolean columns.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这解决了标签编码和序数编码的缺点，即由于编码数据被表示为多个布尔列，列现在被视为分类列。
- en: '![](../Images/0204fe69d55eca38233d97ce66a8d435.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0204fe69d55eca38233d97ce66a8d435.png)'
- en: 'Fig 3: Example of One-Hot Encoding — Image by author'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：One-Hot 编码示例 — 图片由作者提供
- en: Given that the cardinality (number of categories) is `n`, One-Hot Encoder encodes
    the data by creating `n` additional columns. In Dummy Encoding, we can drop the
    last column as it would be a dummy variable, and this will result in `n-1` columns.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 给定基数（类别数）为 `n`，One-Hot 编码器通过创建 `n` 个额外的列来对数据进行编码。在虚拟编码中，我们可以去掉最后一列，因为它是虚拟变量，这将导致
    `n-1` 列。
- en: When to use One-Hot / Dummy Encoder
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用 One-Hot / 虚拟编码器
- en: '**Nominal Variables**: One-Hot Encoder is used for nominal categorical variables'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义变量**：One-Hot 编码器用于名义分类变量。'
- en: '**Low to Medium Cardinality**: As new columns are created for each category,
    it is recommended to use One-Hot encoding where there is a low to a medium number
    of categories such that the resulting data would not be too sparse'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低到中等基数**：由于为每个类别创建了新的列，因此建议在类别数目较少到中等时使用 One-Hot 编码，以免结果数据过于稀疏。'
- en: '**Missing or Unseen Variables**: One-Hot Encoder from the sklearn package can
    handle missing or unseen variables by creating columns for missing variables and
    omitting columns for unseen variables so that the feature columns remain consistent,
    by default it throws a value error'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失或未见变量**：sklearn 包中的 One-Hot 编码器可以通过为缺失的变量创建列、忽略未见的变量列来处理缺失或未见的变量，以保持特征列的一致性，默认情况下会引发值错误。'
- en: Cons of One-Hot / Dummy Encoder
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: One-Hot / 虚拟编码器的缺点
- en: '**Dummy Variable Trap**: It may result in a phenomenon where the features are
    highly correlated since the encoded data is sparse'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**虚拟变量陷阱**：由于编码数据稀疏，可能会导致特征之间高度相关的现象。'
- en: '**Large dataset**: One-hot encoding increases the number of columns in the
    dataset, which may in turn affect the training speed and is not optimal for tree-based
    models'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据集**：One-hot 编码会增加数据集中的列数，这可能会影响训练速度，并且不适用于基于树的模型。'
- en: One-hot encoding can be done with `OneHotEncoder` from the sklearn package or
    using the pandas `get_dummies` method.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: One-hot 编码可以通过 sklearn 包中的 `OneHotEncoder` 或使用 pandas 的 `get_dummies` 方法来完成。
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Using the pandas built-in `get_dummies` method, missing and unseen variables
    in validation/test data must be manually handled.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 pandas 内置的 `get_dummies` 方法时，必须手动处理验证/测试数据中的缺失和未见变量。
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: №3\. Target Encoding
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: №3. 目标编码
- en: Target Encoding uses Bayesian posterior probability to encode categorical variables
    to the mean of the target variable (numerical variable). Smoothing techniques
    are applied to prevent target leakage.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目标编码使用贝叶斯后验概率将分类变量编码为目标变量（数值变量）的均值。应用平滑技术以防止目标泄漏。
- en: Compared to Label and Ordinal Encoding, Target Encoding encodes the data with
    values that explains the target instead of arbitrary numbers 0, 1, 2, etc. Other
    similar encodings can be to encode categorical variables with Information Value
    (IV) or Weight of Evidence (WOE).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与标签编码和序数编码相比，目标编码用解释目标的值对数据进行编码，而不是用任意的数字 0、1、2 等。其他类似的编码方法可以使用信息值（IV）或证据权重（WOE）对分类变量进行编码。
- en: '![](../Images/554464b6423e3f286920f32e04b4ea9a.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/554464b6423e3f286920f32e04b4ea9a.png)'
- en: 'Fig 4: Example of Target Encoding — Image by author'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：目标编码示例 — 图片由作者提供
- en: There are two ways to implement target encoding
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 实现目标编码有两种方法
- en: 'Mean Encoding: The encoded values are the mean of the target values with smoothing
    applied'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均值编码：编码值是目标值的均值，并应用了平滑。
- en: 'Leave-One-Out Encoding: The encoded values are the mean of the target values
    except for the data point that we want to predict'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Leave-One-Out 编码：编码值是目标值的均值，但不包括我们要预测的数据点。
- en: When to use Target Encoder
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用目标编码器
- en: '**Nominal Variables**: Target Encoder is used for nominal categorical variables'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义变量**：目标编码器用于名义分类变量。'
- en: '**Supports High Cardinality**: Target Encoder can be used in cases where there
    are many different categories, and it is better if there are multiple data samples
    for each category'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持高基数**：目标编码器可以用于类别很多的情况，如果每个类别有多个数据样本则更好'
- en: '**Unseen Variables**: Target Encoder can handle unseen variables by encoding
    them with the mean of the target variable'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未见变量**：目标编码器可以通过用目标变量的均值编码未见变量来处理它们'
- en: Cons of Target Encoder
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标编码器的缺点
- en: '**Target Leakage**: Even with smoothing, this may result in target leakage
    and overfitting. Leave-One-Out Encoding and introducing Gaussian noise in the
    target variable can be used to address the overfitting problem'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标泄露**：即使进行平滑处理，这也可能导致目标泄露和过拟合。可以使用留一法编码和在目标变量中引入高斯噪声来解决过拟合问题'
- en: '**Uneven Category Distribution**: The category distribution can differ in train
    and validation/test data and result in categories being encoded with incorrect
    or extreme values'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别分布不均**：类别分布在训练和验证/测试数据中可能不同，从而导致类别被编码为不正确或极端的值'
- en: Target Encoding requires installing the `category_encoders` python package using
    the command `pip install category_encoders`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 目标编码需要使用命令 `pip install category_encoders` 安装 `category_encoders` python 包。
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: №4\. Count / Frequency Encoding
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: №4\. 计数 / 频率编码
- en: Count and Frequency Encoding encodes categorical variables to the count of occurrences
    and frequency (normalized count) of occurrences respectively.
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 计数和频率编码将分类变量分别编码为出现次数和频率（归一化计数）。
- en: '![](../Images/5fac27741fe852ba6bb4d84099316ccf.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5fac27741fe852ba6bb4d84099316ccf.png)'
- en: 'Fig 5: Example of Count and Frequency Encoding — Image by author'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 计数和频率编码示例 — 作者提供的图像'
- en: When to use Count / Frequency Encoder
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用计数 / 频率编码器
- en: '**Nominal Variables**: Frequency and Count Encoder is effective for nominal
    categorical variables'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义变量**：频率和计数编码器对名义分类变量有效'
- en: '**Unseen Variables**: Frequency and Count Encoder can handle unseen variables
    by encoding them with a `0` value'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未见变量**：频率和计数编码器可以通过用 `0` 值编码未见变量来处理它们'
- en: Cons of Count / Frequency Encoder
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计数 / 频率编码器的缺点
- en: '**Similar encodings**: If all categories have similar counts, the encoded values
    will be the same'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相似编码**：如果所有类别的计数相似，则编码后的值将相同。'
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: №5\. Binary / BaseN Encoding
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: №5\. 二进制 / BaseN 编码
- en: Binary Encoding encodes categorical variables into integers, then converts them
    to binary code. The output is similar to One-Hot Encoding, but lesser columns
    are created.
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 二进制编码将分类变量编码为整数，然后转换为二进制代码。输出类似于独热编码，但创建的列更少。
- en: This addresses the drawback to One-Hot Encoding where a cardinality of `n` does
    not result in `n` number of columns, but `log2(n)` columns. BaseN Encoding follows
    the same idea but uses other base values instead of 2, resulting in `logN(n)`
    columns.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这解决了独热编码的缺点，其中 `n` 的基数不会导致 `n` 列，而是 `log2(n)` 列。BaseN 编码遵循相同的理念，但使用其他基数值而不是
    2，从而得到 `logN(n)` 列。
- en: '![](../Images/0e81081ecfdb661632192a68fea03c21.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e81081ecfdb661632192a68fea03c21.png)'
- en: 'Fig 6: Example of Binary Encoding — Image by author'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 二进制编码示例 — 作者提供的图像'
- en: When to use Binary Encoder
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用二进制编码器
- en: '**Nominal Variables**: Binary and BaseN Encoder are used for nominal categorical
    variables'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义变量**：二进制和 BaseN 编码器用于名义分类变量'
- en: '**High Cardinality**: Binary and BaseN encoding works well with a high number
    of categories'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高基数**：二进制和 BaseN 编码在类别数量很高时表现良好'
- en: '**Missing or Unseen Variables**: Binary and BaseN Encoder can handle unseen
    variables by encoding them with `0` values across all columns'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失或未见变量**：二进制和 BaseN 编码器可以通过在所有列中用 `0` 值编码未见变量来处理它们'
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: №6\. Hash Encoding
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: №6\. 哈希编码
- en: Hash Encoding encodes categorical variables into distinct hash values using
    a hash function. The output is similar to One-Hot Encoding, but you can choose
    the number of columns created.
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 哈希编码将分类变量编码为使用哈希函数生成的不同哈希值。输出类似于独热编码，但可以选择创建的列数。
- en: Hash Encoding is similar to Binary Encoding such that they are more space-efficient
    than One-Hot Encoding, but Hash Encoding makes use of a hash function instead
    of binary numbers.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希编码与二进制编码类似，因为它们比独热编码更节省空间，但哈希编码使用哈希函数而不是二进制数。
- en: '![](../Images/465b520aae5b9b37b3af018d62048f45.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/465b520aae5b9b37b3af018d62048f45.png)'
- en: 'Fig 7: Example of Hash Encoding using 2 columns — Image by author'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: 使用 2 列的哈希编码示例 — 作者提供的图像'
- en: Hash encoding can encode high-cardinality data to a fixed-sized array as the
    number of new columns is manually specified. This is also similar to dimensionality
    reduction algorithms such as [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)
    or [Spectral Embedding](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.SpectralEmbedding.html)
    methods which construct fixed-sized arrays from eigenvalues and other distance
    measures.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希编码可以将高基数数据编码为固定大小的数组，因为新列的数量是手动指定的。这也类似于[TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)或[谱嵌入](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.SpectralEmbedding.html)等降维算法，这些算法通过特征值和其他距离度量构建固定大小的数组。
- en: When to use Hash Encoder
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用哈希编码器
- en: '**Nominal Variables**: Hash Encoder is used for nominal categorical variables'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**名义变量**：哈希编码器用于名义分类变量。'
- en: '**High Cardinality**: Hash encoding works well with a high number of categories'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高基数**：哈希编码在类别数量较多时表现良好。'
- en: '**Missing or Unseen Variables**: Hash Encoder can handle unseen variables by
    encoding them with null values across all columns'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失或未见变量**：哈希编码器可以通过在所有列中用空值编码未见变量来处理这些变量。'
- en: Cons of Hash Encoder
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希编码器的缺点
- en: '**Irreversible**: Hashing functions are one-direction such that the original
    input can be hashed into a hash value, but the original input cannot be retrieved
    from the hash value'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不可逆**：哈希函数是单向的，即原始输入可以被哈希为哈希值，但无法从哈希值中恢复原始输入。'
- en: '**Information Loss or Collision**: If too few columns are created, hash encoding
    can lead to loss of information as multiple different inputs may result in the
    same output from the hash function'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息丢失或冲突**：如果创建的列数过少，哈希编码可能会导致信息丢失，因为多个不同的输入可能会导致哈希函数产生相同的输出。'
- en: Hash encoding can be done with `FeatureHasher` from the sklearn package or with
    `HashingEncoder` from the category encoders package.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希编码可以使用来自sklearn包的`FeatureHasher`或来自分类编码器包的`HashingEncoder`来完成。
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Using `category_encoders`,
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`category_encoders`，
- en: '[PRE8]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Hope you have learned more about the different ways to encode your categorical
    data into numerical data. To choose between which feature encoding technique to
    use, it is important to consider the **type of categorical data** (nominal or
    ordinal), the **Machine Learning model used**, and the **pros and cons** of each
    method.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你对将分类数据编码为数值数据的不同方法有更多了解。选择使用哪种特征编码技术时，重要的是考虑**分类数据的类型**（名义或序数）、**使用的机器学习模型**以及每种方法的**优缺点**。
- en: It is also important to consider missing or unseen variables during testing
    due to changing patterns or trends so that the data science workflow does not
    fail in production!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模式或趋势的变化，在测试期间也要考虑缺失或未见的变量，以确保数据科学工作流在生产中不会失败！
- en: Useful Links
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有用的链接
- en: '`sklearn` Documentation: [https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn` 文档：[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)'
- en: '`category_encoders` Documentation: [https://contrib.scikit-learn.org/category_encoders/](https://contrib.scikit-learn.org/category_encoders/)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`category_encoders` 文档：[https://contrib.scikit-learn.org/category_encoders/](https://contrib.scikit-learn.org/category_encoders/)'
