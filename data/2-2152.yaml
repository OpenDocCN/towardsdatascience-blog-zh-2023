- en: Turn GPT-4 into a Poker Coach
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 GPT-4 转变为扑克教练
- en: 原文：[https://towardsdatascience.com/turn-gpt-4-into-a-poker-coach-4a28ba5e9541](https://towardsdatascience.com/turn-gpt-4-into-a-poker-coach-4a28ba5e9541)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/turn-gpt-4-into-a-poker-coach-4a28ba5e9541](https://towardsdatascience.com/turn-gpt-4-into-a-poker-coach-4a28ba5e9541)
- en: Unleashing Creativity Beyond Chatbot Boundaries
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超越聊天机器人界限的创造力释放
- en: '[](https://medium.com/@jacky.kaub?source=post_page-----4a28ba5e9541--------------------------------)[![Jacky
    Kaub](../Images/e66c699ee5a9d5bbd58a1a72d688234a.png)](https://medium.com/@jacky.kaub?source=post_page-----4a28ba5e9541--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4a28ba5e9541--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4a28ba5e9541--------------------------------)
    [Jacky Kaub](https://medium.com/@jacky.kaub?source=post_page-----4a28ba5e9541--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jacky.kaub?source=post_page-----4a28ba5e9541--------------------------------)[![Jacky
    Kaub](../Images/e66c699ee5a9d5bbd58a1a72d688234a.png)](https://medium.com/@jacky.kaub?source=post_page-----4a28ba5e9541--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4a28ba5e9541--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4a28ba5e9541--------------------------------)
    [Jacky Kaub](https://medium.com/@jacky.kaub?source=post_page-----4a28ba5e9541--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4a28ba5e9541--------------------------------)
    ·13 min read·May 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4a28ba5e9541--------------------------------)
    ·阅读时长13分钟·2023年5月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/68f895c49f1100cc14bb864bc37349e8.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68f895c49f1100cc14bb864bc37349e8.png)'
- en: Photo by [Michał Parzuchowski](https://unsplash.com/@mparzuchowski?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Michał Parzuchowski](https://unsplash.com/@mparzuchowski?utm_source=medium&utm_medium=referral)
    提供，刊登在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In this article, we will not talk about how LLM models can pass a law exam or
    replace a developer.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们不会讨论 LLM 模型如何通过法律考试或替代开发人员。
- en: We will not look at hints on optimizing prompts for making GPT do motivation
    letters or marketing content.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会讨论如何优化提示以使 GPT 生成动机信或营销内容。
- en: Like many people, I think that the emergence of the LLM like GPT4 is a little
    revolution from which a lot of new applications will emerge. I also think that
    we should not reduce their use to simple “chatbot assistants” and that with the
    appropriate backend and UX, those models can be leveraged to incredible next-level
    applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 和许多人一样，我认为像 GPT4 这样的 LLM 的出现是一场小小的革命，将会涌现出许多新应用。我还认为我们不应该将其使用仅限于简单的“聊天机器人助手”，而是通过适当的后端和用户体验，这些模型可以被用来实现令人惊叹的下一层应用。
- en: This is why, in this article, we are going to think a bit out of the box and
    create a real application around the GPT API that could not be accessed simply
    via the chatbot interface and how a proper app design could serve a better user
    experience.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在本文中，我们将稍微跳出框框，围绕 GPT API 创建一个真正的应用程序，而这些 API 不能仅通过聊天机器人接口访问，以及如何通过适当的应用程序设计提供更好的用户体验。
- en: Setting up some context
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置一些背景
- en: Leveraging GPT4 in businesses
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在商业中利用 GPT4
- en: I played a lot with GPT4 since its release and I think there is globally two
    main families of use cases for using the model to generate a business.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 自发布以来，我玩了很多 GPT4，我认为使用该模型生成业务的主要用例大致分为两类。
- en: The first way is to use GPT4 to generate static content. Say you want to write
    a cooking book with a particular theme (for example Italian food). You can make
    detailed prompts, generate a few recipes from GPT, try them yourself, and integrate
    the one you like in your book. In that case “prompting” will have a fixed cost
    and once the recipes are generated you don’t need GPT anymore. This type of use
    case can find a lot of variation (Marketing content, website content, or even
    generating some datasets for other uses), but is not as interesting if we want
    to focus on AI-oriented apps.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方式是使用 GPT4 生成静态内容。假设你想写一本关于特定主题（例如意大利食物）的烹饪书。你可以做详细的提示，从 GPT 生成一些食谱，自己试用，然后将你喜欢的食谱整合到你的书中。在这种情况下，“提示”将有一个固定成本，一旦食谱生成后，你就不再需要
    GPT。这种用例可以有很多变体（营销内容、网站内容，甚至生成其他用途的数据集），但如果我们想专注于 AI 导向的应用程序，它就不那么有趣了。
- en: '![](../Images/89df1ab72515de113e4265531f798b4f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89df1ab72515de113e4265531f798b4f.png)'
- en: The logic of generating the content is outside the application, Author Illustration
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 生成内容的逻辑在应用程序之外，作者插图
- en: 'The second use case is live prompting through an interface of your design.
    Going back to the cooking field: we could imagine a well-suited interface in which
    a user can pick up a few ingredients, a specialty, and ask the application to
    generate directly the recipe. Unlike in the first case, the content generated
    can be potentially infinite and suit better the needs of your users.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个用例是通过你设计的界面进行实时提示。回到烹饪领域：我们可以想象一个合适的界面，用户可以选择一些食材、一个特色菜，并要求应用程序直接生成食谱。与第一个案例不同，生成的内容可能是无限的，更好地满足用户的需求。
- en: '![](../Images/7f109dfd3cc45954a6ddfb8e3ba164d3.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f109dfd3cc45954a6ddfb8e3ba164d3.png)'
- en: In this scenario, the user interacts directly with the LLM via a well-designed
    UX which will generate prompts and content, Author Illustration
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，用户通过精心设计的用户体验直接与LLM互动，这将生成提示和内容，作者插图。
- en: The drawback of this is that the number of calls to the LLM will be potentially
    infinite and grow with the number of users, unlike before where the amount of
    calls to the LLM was finite and controlled. This implies that you will have to
    design properly your business model and take a lot of care into including the
    cost of prompts in your business model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 缺点是，LLM的调用次数可能是无限的，并随着用户数量的增加而增长，与之前LLM调用次数有限且可控的情况不同。这意味着你必须妥善设计你的商业模式，并在商业模式中仔细考虑提示费用。
- en: As of when I am writing these lines, GPT4 “prompt” costs 0.03$/1000 tokens (with
    both request and answer tokens counted in the pricing). It does not seem like
    a lot, but could quickly escalate if you don’t pay attention to it. To work around
    this, you could for example propose to your user a subscription depending on the
    amount of prompts or limited the amount of prompts per user (via a login system
    etc…). We will talk a bit more in detail about pricing later in this article.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在我写这些文字时，GPT4的“提示”费用为0.03$/1000 tokens（包括请求和回答的tokens）。这看起来不多，但如果不加注意，费用可能会迅速增加。为了解决这个问题，你可以例如根据提示的数量向用户提供订阅服务，或者限制每个用户的提示数量（通过登录系统等）。我们将在本文后面详细讨论定价问题。
- en: Why a use-case around Poker?
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么围绕扑克构建一个用例？
- en: I thought for some time of the perfect use case to try around LLMs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我考虑了很长时间寻找完美的LLM用例。
- en: First, poker analysis is theoretically a field in which LLM should perform well.
    In fact, every poker hand played can be translated into a standardized simple
    text describing the evolution of the hand. For example, the hand below describes
    a sequence in which “player1” win the pot after making a raise on the bet of “player2”
    after the “flop” action.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，扑克分析理论上是LLM表现良好的领域。实际上，每一手扑克都可以被转换为标准化的简单文本，描述手牌的演变。例如，下面的手牌描述了一个序列，其中“player1”在“flop”动作后对“player2”的下注进行了加注，从而赢得了底池。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This standardization is important because it will make the development more
    simple. We will be able to simulate hands, translate them into this kind of prompt
    message, and “force” the answer of the LLM to continue the sequence.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这种标准化很重要，因为它会使开发变得更加简单。我们将能够模拟手牌，将其转换为这种提示消息，并“强制”LLM的回答继续序列。
- en: A lot of theoretical content is available in books, online, etc… Making it likely
    that GPT has “learned” things around the game and good moves.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 许多理论内容可以在书籍、网上等地方找到……这使得GPT有可能“学习”到有关游戏和良好策略的知识。
- en: Also, a lot of added value will come from the app engine and the UX, and not
    only from the LLM itself (for example we will have to design our own poker engine
    to simulate a game), which will make the application harder to replicate, or to
    simply “reproduce” via GPTChat.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，很多附加价值将来自于应用引擎和用户体验，而不仅仅是LLM本身（例如，我们需要设计自己的扑克引擎来模拟游戏），这将使得应用程序更难以复制，或者仅仅通过GPTChat“再现”。
- en: Finally, the use case might adapt well to the second case scenario described
    above, where the LLM and a good UX can bring a completely new experience to users.
    We could imagine our application playing hands again a real user, analyzing hands
    and also giving rates and areas of improvement. The price per request should not
    be a problem as poker learners are used to paying for this kind of service, so
    a “pay as you use” might be possible in this particular use case (unlike the recipe
    concept app mentioned earlier for example)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，这种用例可能很好地适应上述第二种情况，其中LLM和良好的用户体验可以为用户带来全新的体验。我们可以设想我们的应用程序再次与真实用户进行对战，分析手牌并提供评分和改进领域。每次请求的费用不应该成为问题，因为扑克学习者习惯于为这种服务付费，所以在这个特定用例中，可能会采用“按使用付费”的模式（例如与之前提到的食谱应用程序不同）。
- en: About GPT4 API
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于GPT4 API
- en: 'I decided to build this article around [GPT4 API](https://openai.com/product/gpt-4)
    for its accuracy in comparison to GPT3.5\. OpenAI provides a simple Python wrapper
    that can be used to send your inputs and receive your outputs from the model.
    For example:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定围绕[GPT4 API](https://openai.com/product/gpt-4)来构建这篇文章，因为它与GPT3.5相比更为精准。OpenAI提供了一个简单的Python包装器，可以用来发送输入并从模型中接收输出。例如：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The “pre-prompt” used with the role “system” will help the model to act the
    way you want him to act (you can use it typically to enforce a response format),
    the role “user” is used to add the message from the user. In our case, those messages
    will be pre-designed by our engine, for example, passing a particular poker hand
    to complete.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用“系统”角色的“预提示”将帮助模型按你希望的方式行动（你可以使用它来强制执行响应格式），角色“用户”用于添加用户的消息。在我们的案例中，这些消息将由我们的引擎预先设计，例如，传递特定的扑克手牌以完成。
- en: Note that all the tokens from “system”, “user” and from the answer are counted
    in the price scheme, so it is really important to optimize those queries as much
    as you can.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，“系统”、“用户”和答案中的所有令牌都计入价格方案，因此优化这些查询至关重要。
- en: Initial Exploration
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初步探索
- en: The first thing to assess is the general quality of GPT for the different tasks
    related to poker. I want to evaluate quickly its ability to realize different
    tasks that would be part of the core of the application.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要评估的是GPT在与扑克相关的不同任务中的总体质量。我希望快速评估其完成应用程序核心任务的能力。
- en: Continuing a hand with a realistic move and explanations
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 继续进行手牌并提供现实的行动和解释
- en: One of the core ideas of the application will be to make one or several instances
    of GPT play against a user. We want to assess how well GPT plays. In order to
    do so, I provided the model samples of hands I played for which I wanted an analysis
    regarding the next move and the explanation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的核心理念之一将是让一个或多个GPT实例与用户对战。我们想要评估GPT的表现如何。为此，我提供了我打过的牌局样本，并希望获得关于下一步行动及其解释的分析。
- en: 'An example of a test:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 测试示例：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And the answer:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: I performed several tests like this, validating the fact that the model would
    be able to play decently.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我进行了几次这样的测试，验证了模型能够合理地进行游戏。
- en: Interestingly, by modifying the pre-prompt, I could control the behavior of
    the model making him play more or less aggressively.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，通过修改预提示，我可以控制模型的行为，让它变得更具攻击性或更为保守。
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'would lead, for the same action, to a different move from the AI:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于相同的动作，会导致AI采取不同的行动：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This means we could potentially code different “AI” playing with different styles
    to simulate a real poker field with players with different levels and styles.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以潜在地编写不同风格的“AI”代码，以模拟具有不同水平和风格的玩家的真实扑克场景。
- en: Rating the actions of a player from a full-hand history
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从完整手牌历史记录中对玩家的动作进行评分
- en: A feature we might want to integrate into our application is the possibility
    to rate the user. Grades are always a good indicator of progress or a good way
    to target particular weaknesses when learning something.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能想要集成到应用程序中的一个功能是能够对用户进行评分。评分始终是进步的良好指标，或者在学习某项技能时针对特定弱点的有效方法。
- en: In order to be processed correctly by our application, we would have to “enforce”
    the answer of the bot so that it can be simply parsed and used in the application
    (for example averaging over sessions or over thematics).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们的应用程序正确处理这些信息，我们必须“强制”机器人的回答，以便可以简单地解析并在应用程序中使用（例如对会话或主题进行平均）。
- en: 'For example, the following combination of prompts:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下提示组合：
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Would generate the following output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成以下输出：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is nice for two reasons:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这有两个好处：
- en: We can control the number of tokens displayed by the model
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以控制模型显示的令牌数量
- en: We can easily parse the answer in a dictionary to be used by our app
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以轻松地将答案解析成字典，以便我们的应用程序使用
- en: Transforming the idea into a concrete application
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将想法转化为具体应用
- en: After validating the two points above, it is time to code something bigger to
    demonstrate the whole concept and see how the LLM can be integrated into a larger
    application that diverges from a simple chatbot.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证上述两点后，是时候编写更大的代码来演示整个概念，并查看LLM如何集成到一个更大的应用程序中，这与简单的聊天机器人不同。
- en: In the context of this article, we will go with something fairly simple but
    it should give you a hint about all the capabilities behind LLMs when used out
    of the box.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的背景下，我们将使用相当简单的东西，但它应当能给你一个关于LLMs在开箱即用时所有能力的提示。
- en: The goal of our demonstrator will be to make GPT play a hand against us, and
    then, once the hand has been completely played, ask the model to give us some
    hints on how to improve based on that hand only.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的演示目标是让GPT与我们进行牌局，然后，在牌局完全进行后，要求模型根据这局牌仅给出一些改进的提示。
- en: For this purpose, I quickly coded a simple poker engine that will help simulate
    a hand and play against an AI opponent. I will not go too much into the detail
    of the engine here (which is not the point of the article), but simply give you
    a brief overview of its design.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我快速编写了一个简单的扑克引擎，帮助模拟牌局并与AI对手对战。我不会在这里详细讨论引擎（这不是本文的重点），而是简单介绍其设计概况。
- en: '![](../Images/0cb21081d6bd88ce88d410e40d6ecd06.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cb21081d6bd88ce88d410e40d6ecd06.png)'
- en: Schematic for the Poker Coach proof of concept
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 扑克教练概念验证示意图
- en: The role of the poker engine is to keep track of the game's general metadata
    (number of players, stacks, cards distributed, player turn…). The next action
    (both from a player or an AI) is added to the engine as a standard text message
    such as “call”, “fold”, or “raise 60”, etc… which is parsed and transcribed as
    new input for the engine to run the next step.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 扑克引擎的作用是跟踪游戏的总体元数据（玩家数量、筹码、发牌、玩家回合……）。下一个动作（无论是玩家还是AI）作为标准文本消息如“call”、“fold”或“raise
    60”等添加到引擎中，然后解析并转录为引擎运行下一步的新输入。
- en: The poker engine also transcribes the sequence of action into a text file which
    is used to feed the prompt used by the AI to take a decision on the next move.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 扑克引擎还将动作序列转录为文本文件，这些文件用于供AI使用以决定下一个动作。
- en: 'Two pre-prompts will be used: one for deciding on the next action to take,
    and one, used at the end of the hand, to rate the actions of the human player.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用两个预提示：一个用于决定下一个动作，另一个用于牌局结束时评价人类玩家的动作。
- en: Playing the hand
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进行牌局
- en: 'In order for our application to understand the action from GPT, we need to
    make sure that the message of GPT is standardized. This can be enforced with the
    pre-prompt. In my case I expect GPT to answer me with a maximum of two words “ACTION
    AMOUNT”, and I am enforcing this behavior by providing an example of the model
    to which it would adapt with this simple playing pre-prompt:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们的应用程序理解GPT的动作，我们需要确保GPT的消息是标准化的。这可以通过预提示来实现。在我的情况下，我期望GPT用最多两个词“动作 数量”来回答我，并通过提供一个示例模型来强制这一行为，模型会根据这个简单的玩法预提示进行适应：
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'I will combine this pre-prompt with the actual hand history generated by the
    poker engine:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我将把这个预提示与扑克引擎生成的实际牌局历史结合起来：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This leads to a suitable answer that can be parsed and integrated into the
    poker engine to update the game and continue with the next action:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致一个合适的答案，可以解析并整合到扑克引擎中，以更新游戏并继续下一个动作：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The application in action
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用程序实际运行中
- en: Put in snapshots, it might not look impressive, so I recorded a little video
    about the AI in action in a notebook. In the context of the video, I also asked
    the model to justify its move before taking action. The cards of all the players
    are visible in the widget for debugging purposes, but in real conditions, they
    would be hidden from the player. When the AI takes the action, only its own cards
    are passed to the prompt.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 放在快照中，它可能看起来不那么令人印象深刻，所以我录制了一个关于AI在笔记本中运行的小视频。在视频中，我还要求模型在采取行动前解释其动作。所有玩家的牌在调试用的小工具中可见，但在实际条件下，它们会对玩家隐藏。当AI采取行动时，仅其自己的牌会传递给提示。
- en: My message parser simply takes the action after the “//” separator and I used
    the input() function to register the user input.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我的消息解析器简单地处理“//”分隔符后的操作，我使用了input()函数来记录用户输入。
- en: '![](../Images/647e4c78ec1819bc40ba998dd0149e8e.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/647e4c78ec1819bc40ba998dd0149e8e.png)'
- en: GPT playing a hand of poker against me, Author illustration
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: GPT 与我对战的一手扑克，作者插图
- en: Hand review
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动审核
- en: Once the head is completed, the engine has generated the whole hand that can
    be passed to our “evaluation module” where the LLM will rate the hand.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦头部完成，系统就会生成整个手牌，然后可以传递给我们的“评估模块”，在这里，LLM 将对手牌进行评分。
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Using the prompt designed earlier, this is the kind of answer, easy to parse,
    that we get:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前设计的提示，我们可以得到如下类型的答案，这些答案易于解析：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This output could be easily parsed and data stored in a DB from which we could
    extract all sorts of analysis for the player like identifying weaknesses depending
    on hand, position, configuration, etc… based on average grades provided by the
    model.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这些输出可以轻松解析，并将数据存储在数据库中，从中我们可以提取所有类型的分析，例如根据模型提供的平均评分识别手牌、位置、配置等方面的弱点。
- en: Conclusion
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: At this point, we proved with an example that new concepts centered on LLMs
    could emerge when coupled with well-suited app designs which diverge from the
    simple chatbot assistant.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们通过一个示例证明了以LLM为中心的新概念可以在与合适的应用设计结合时出现，这些设计偏离了简单的聊天机器人助手。
- en: Of course, the example above would be only the first step out of many before
    having a fully ready application, but it should be sufficient to bring food for
    thoughts and creativity.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，上述示例只是众多步骤中的第一步，才能有一个完全准备好的应用程序，但它应该足以引发思考和创造力。
- en: 'Extrapolating a bit about how would look the next steps toward the development
    of a real application for a poker coach, we would have to take several actions:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于开发一个真正的扑克教练应用程序的下一步，我们需要采取几个行动：
- en: 'Prompt token optimization: a large part of the costs of our application would
    come from prompt pricing. Optimizing the prompts in terms of quantity is essential
    to be able to reduce costs and be competitive.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示令牌优化：我们应用程序的大部分成本将来自提示定价。优化提示的数量对于降低成本和保持竞争力至关重要。
- en: 'Prompt content optimization: the quality of the output (rating, next action)
    can vary a lot depending on the context you provide to the model. For example,
    asking the model to first make an analysis before taking an action can improve
    a lot the coherence of the action taken. Many tests and iterations, in partnership
    with real players, should be needed to make sure the quality of the output is
    sufficient for a production-level application.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示内容优化：输出（评分、下一步行动）的质量可能会因你提供给模型的上下文而有所不同。例如，让模型在采取行动之前先进行分析可以显著提高行动的一致性。与真实玩家进行的许多测试和迭代是必需的，以确保输出质量足以满足生产级应用程序的要求。
- en: 'Error handling: even if the outputs provided by the LLM fit your template most
    of the time, it is also important to handle the cases in which the model will
    provide an answer which does not fit your parser. Unlike all your functions, this
    part of the application can stay unpredictable, and it would be important to add
    an extra layer of control to make sure no bugs happen due to bad formats or impossible
    answers.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误处理：即使LLM提供的输出大多数情况下符合你的模板，处理模型提供的不符合你的解析器的答案的情况也很重要。与所有功能不同，这部分应用可能会保持不可预测，因此添加额外的控制层以确保由于格式错误或无法回答的问题不会出现错误是很重要的。
- en: 'User interface: while playing in a notebook with text inputs is enough for
    exploration like in this article, a core element would be a clean UX to sublime
    the user experience and make the interaction with the model and the engine smooth.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户界面：虽然在笔记本中使用文本输入进行探索足以满足本文的需求，但核心元素应该是一个清晰的用户体验，以提升用户体验并使与模型和引擎的交互顺畅。
- en: While prices for this family of applications might be still high, I am sure
    that mass adoption and future improvements will tend to reduce their cost. We
    are only at the beginning of the development of those new technologies and it’s
    up to us to be creative and embrace the potential of LLMs, transforming them into
    powerful tools for innovative and user-centric experiences beyond traditional
    chatbot limitations.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这类应用程序的价格可能仍然很高，但我相信大规模采用和未来的改进将趋向于降低成本。我们只是这些新技术发展的开始，创造性地利用LLMs的潜力，将其转变为超越传统聊天机器人局限性的强大工具，以提供创新和以用户为中心的体验。
