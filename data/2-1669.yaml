- en: Practical Guide for Anomaly Detection in Time Series with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Pythonè¿›è¡Œæ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹çš„å®ç”¨æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/practical-guide-for-anomaly-detection-in-time-series-with-python-d4847d6c099f](https://towardsdatascience.com/practical-guide-for-anomaly-detection-in-time-series-with-python-d4847d6c099f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/practical-guide-for-anomaly-detection-in-time-series-with-python-d4847d6c099f](https://towardsdatascience.com/practical-guide-for-anomaly-detection-in-time-series-with-python-d4847d6c099f)
- en: A hands-on article on detecting outliers in time series data using Python and
    sklearn
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸€ç¯‡å…³äºä½¿ç”¨Pythonå’Œsklearnæ£€æµ‹æ—¶é—´åºåˆ—æ•°æ®å¼‚å¸¸å€¼çš„å®è·µæ–‡ç« 
- en: '[](https://medium.com/@marcopeixeiro?source=post_page-----d4847d6c099f--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----d4847d6c099f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d4847d6c099f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d4847d6c099f--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----d4847d6c099f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcopeixeiro?source=post_page-----d4847d6c099f--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----d4847d6c099f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d4847d6c099f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d4847d6c099f--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----d4847d6c099f--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d4847d6c099f--------------------------------)
    Â·13 min readÂ·Mar 16, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d4847d6c099f--------------------------------)
    Â·é˜…è¯»æ—¶é•¿13åˆ†é’ŸÂ·2023å¹´3æœˆ16æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/4b3f1bd78c54730bd401ce05e9b15b28.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b3f1bd78c54730bd401ce05e9b15b28.png)'
- en: Photo by [Will Myers](https://unsplash.com/@will_myers?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Will Myers](https://unsplash.com/@will_myers?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Anomaly detection is a task in which we want to identify rare events that deviate
    significantly from the majority of the data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¼‚å¸¸æ£€æµ‹æ˜¯ä¸€ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬å¸Œæœ›è¯†åˆ«å‡ºæ˜æ˜¾åç¦»æ•°æ®å¤§å¤šæ•°éƒ¨åˆ†çš„ç¨€æœ‰äº‹ä»¶ã€‚
- en: Anomaly detection in time series has a wide range of real-life applications,
    from manufacturing to healthcare. Anomalies indicate unexpected events, and they
    can be caused by production faults or system defects. For example, if we are monitoring
    the number of visitors on a website, and the number falls to 0, it might mean
    that the server is down.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—ä¸­çš„å¼‚å¸¸æ£€æµ‹æœ‰å¹¿æ³›çš„å®é™…åº”ç”¨ï¼Œä»åˆ¶é€ ä¸šåˆ°åŒ»ç–—ä¿å¥ã€‚å¼‚å¸¸å€¼è¡¨ç¤ºæ„å¤–äº‹ä»¶ï¼Œå®ƒä»¬å¯èƒ½ç”±ç”Ÿäº§æ•…éšœæˆ–ç³»ç»Ÿç¼ºé™·å¼•èµ·ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬ç›‘æ§ä¸€ä¸ªç½‘ç«™çš„è®¿å®¢æ•°é‡ï¼Œæ•°é‡é™åˆ°0ï¼Œå¯èƒ½æ„å‘³ç€æœåŠ¡å™¨å‡ºç°æ•…éšœã€‚
- en: It is also useful to detect anomalies in time series data before modelling for
    forecasting. Many forecasting models are autoregressive, meaning that they take
    into account past values to make predictions. A past outlier will definitely affect
    the model, and it can be a good idea to remove that outlier to get more reasonable
    predictions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡Œé¢„æµ‹å»ºæ¨¡ä¹‹å‰ï¼Œæ£€æµ‹æ—¶é—´åºåˆ—æ•°æ®ä¸­çš„å¼‚å¸¸å€¼ä¹Ÿå¾ˆæœ‰ç”¨ã€‚è®¸å¤šé¢„æµ‹æ¨¡å‹æ˜¯è‡ªå›å½’çš„ï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¼šè€ƒè™‘è¿‡å»çš„å€¼æ¥è¿›è¡Œé¢„æµ‹ã€‚è¿‡å»çš„å¼‚å¸¸å€¼è‚¯å®šä¼šå½±å“æ¨¡å‹ï¼Œå› æ­¤å»é™¤è¿™äº›å¼‚å¸¸å€¼å¯èƒ½æ˜¯ä¸€ä¸ªå¥½çš„ä¸»æ„ï¼Œä»¥è·å¾—æ›´åˆç†çš„é¢„æµ‹ã€‚
- en: In this article, we will take a look a three different anomaly detection techniques,
    and implement them in Python.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸‰ç§ä¸åŒçš„å¼‚å¸¸æ£€æµ‹æŠ€æœ¯ï¼Œå¹¶åœ¨Pythonä¸­å®ç°å®ƒä»¬ã€‚
- en: Mean absolute deviation (MAD)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¹³å‡ç»å¯¹åå·®ï¼ˆMADï¼‰
- en: Isolation forest
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éš”ç¦»æ£®æ—
- en: Local outlier factor (LOF)
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å±€éƒ¨ç¦»ç¾¤å› å­ï¼ˆLOFï¼‰
- en: The first one is a baseline method that can work well if the series satisfies
    certain assumptions. The other two methods are machine learning approaches.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªæ–¹æ³•æ˜¯åŸºçº¿æ–¹æ³•ï¼Œå¦‚æœç³»åˆ—æ»¡è¶³æŸäº›å‡è®¾ï¼Œå®ƒå¯ä»¥å¾ˆå¥½åœ°å·¥ä½œã€‚å…¶ä»–ä¸¤ç§æ–¹æ³•æ˜¯æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚
- en: '***Learn the latest time series analysis techniques with my*** [***free time
    series cheat sheet***](https://www.datasciencewithmarco.com/pl/2147608294) ***in
    Python! Get the implementation of statistical and deep learning techniques, all
    in Python and TensorFlow!***'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***ä½¿ç”¨æˆ‘çš„*** [***å…è´¹æ—¶é—´åºåˆ—å¤‡å¿˜å•***](https://www.datasciencewithmarco.com/pl/2147608294)
    ***å­¦ä¹ æœ€æ–°çš„æ—¶é—´åºåˆ—åˆ†ææŠ€æœ¯ï¼è·å–ç»Ÿè®¡å­¦å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å®ç°ï¼Œå…¨éƒ¨ä½¿ç”¨Pythonå’ŒTensorFlowï¼***'
- en: Letâ€™s get started!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: Types of anomaly detection tasks in time series
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—ä¸­çš„å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ç±»å‹
- en: 'There are two main types of anomaly detection tasks with time series data:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—æ•°æ®ä¸­çš„å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ä¸»è¦æœ‰ä¸¤ç§ç±»å‹ï¼š
- en: Point-wise anomaly detection
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºç‚¹çš„å¼‚å¸¸æ£€æµ‹
- en: Pattern-wise anomaly detection
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åŸºäºæ¨¡å¼çš„å¼‚å¸¸æ£€æµ‹
- en: In the first type, we wish to find single points in time that are considered
    abnormal. For example, a fraudulent transaction is a point-wise anomaly.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€ç§ç±»å‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°è¢«è®¤ä¸ºå¼‚å¸¸çš„å•ä¸ªæ—¶é—´ç‚¹ã€‚ä¾‹å¦‚ï¼Œä¸€æ¬¡æ¬ºè¯ˆäº¤æ˜“å°±æ˜¯ä¸€ä¸ªç‚¹çŠ¶å¼‚å¸¸ã€‚
- en: The second type is interested in finding subsequences that are outliers. An
    example of that could be a stock that is trading at an abnormal level for many
    hours or days.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒç§ç±»å‹å…³æ³¨äºå¯»æ‰¾ä½œä¸ºç¦»ç¾¤ç‚¹çš„å­åºåˆ—ã€‚ä¸€ä¸ªä¾‹å­å¯èƒ½æ˜¯ä¸€ä¸ªè‚¡ç¥¨åœ¨è®¸å¤šå°æ—¶æˆ–å‡ å¤©å†…ä»¥å¼‚å¸¸æ°´å¹³äº¤æ˜“ã€‚
- en: In this article, we will focus only on point-wise anomaly detection, meaning
    that our outliers are isolated points in time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†åªå…³æ³¨åŸºäºç‚¹çš„å¼‚å¸¸æ£€æµ‹ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬çš„ç¦»ç¾¤ç‚¹æ˜¯åœ¨æ—¶é—´ä¸Šçš„å­¤ç«‹ç‚¹ã€‚
- en: 'The scenario: CPU utilization on the AWS cloud'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœºæ™¯ï¼šAWSäº‘ä¸Šçš„CPUåˆ©ç”¨ç‡
- en: We apply the different anomaly detection techniques on a dataset that monitors
    the CPU utilization on an EC2 instance in the AWS cloud. This is real-world data
    that was recorded every 5 minutes, starting on February 14th, 2014 at 14:30\.
    The dataset contains 4032 data points. It was made available through the [Numenta
    Anomaly Benchmark (NAB)](https://github.com/numenta/NAB) under the AGPL-3.0 license.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨ä¸€ä¸ªç›‘æ§AWSäº‘ä¸­EC2å®ä¾‹CPUåˆ©ç”¨ç‡çš„æ•°æ®é›†ä¸Šåº”ç”¨ä¸åŒçš„å¼‚å¸¸æ£€æµ‹æŠ€æœ¯ã€‚è¿™æ˜¯å®é™…æ•°æ®ï¼Œæ¯5åˆ†é’Ÿè®°å½•ä¸€æ¬¡ï¼Œä»2014å¹´2æœˆ14æ—¥14:30å¼€å§‹ã€‚æ•°æ®é›†åŒ…å«4032ä¸ªæ•°æ®ç‚¹ã€‚å®ƒé€šè¿‡[Numenta
    Anomaly Benchmark (NAB)](https://github.com/numenta/NAB)åœ¨AGPL-3.0è®¸å¯è¯ä¸‹æä¾›ã€‚
- en: The particular dataset for this article can be found [here](https://github.com/numenta/NAB/blob/master/data/realAWSCloudwatch/ec2_cpu_utilization_24ae8d.csv),
    and the associated labels are [here](https://github.com/numenta/NAB/blob/master/labels/combined_labels.json).
    Full source code is available on [GitHub](https://github.com/marcopeix/datasciencewithmarco/blob/master/time_series_anomaly_detection.ipynb).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æ‰€ç”¨çš„ç‰¹å®šæ•°æ®é›†å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/numenta/NAB/blob/master/data/realAWSCloudwatch/ec2_cpu_utilization_24ae8d.csv)æ‰¾åˆ°ï¼Œç›¸å…³æ ‡ç­¾åœ¨[è¿™é‡Œ](https://github.com/numenta/NAB/blob/master/labels/combined_labels.json)ã€‚å®Œæ•´æºä»£ç å¯åœ¨[GitHub](https://github.com/marcopeix/datasciencewithmarco/blob/master/time_series_anomaly_detection.ipynb)ä¸Šæ‰¾åˆ°ã€‚
- en: Before we get started, we need to format our data in order to label each value
    as either an outlier or an inlier.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ ¼å¼åŒ–æ•°æ®ï¼Œä»¥ä¾¿å°†æ¯ä¸ªå€¼æ ‡è®°ä¸ºç¦»ç¾¤ç‚¹æˆ–å†…ç‚¹ã€‚
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, an outlier gets a label of -1, and an inlier gets a label of 1\. This matches
    the output of anomaly detection algorithms in scikit-learn.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œç¦»ç¾¤ç‚¹è¢«æ ‡è®°ä¸º-1ï¼Œè€Œå†…ç‚¹è¢«æ ‡è®°ä¸º1ã€‚è¿™ä¸scikit-learnä¸­çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•è¾“å‡ºä¸€è‡´ã€‚
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/48b39a86bf1504a0c73dd2b1e7226575.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48b39a86bf1504a0c73dd2b1e7226575.png)'
- en: Formatted data with the timestamp, the value, and a label to determine if is
    it an outlier (-1) or an inlier (1). Image by the author.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¼å¼åŒ–çš„æ•°æ®åŒ…æ‹¬æ—¶é—´æˆ³ã€å€¼å’Œæ ‡ç­¾ï¼Œä»¥ç¡®å®šå…¶æ˜¯å¦ä¸ºç¦»ç¾¤ç‚¹ï¼ˆ-1ï¼‰æˆ–å†…ç‚¹ï¼ˆ1ï¼‰ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: At this point, we have a dataset with the right timestamp format, the value,
    and a label to indicated whether the value is an outlier (-1) or an inlier (1).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬æ‹¥æœ‰ä¸€ä¸ªæ ¼å¼æ­£ç¡®çš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬æ—¶é—´æˆ³ã€å€¼å’Œæ ‡ç­¾ï¼Œä»¥æŒ‡ç¤ºå€¼æ˜¯å¦ä¸ºç¦»ç¾¤ç‚¹ï¼ˆ-1ï¼‰æˆ–å†…ç‚¹ï¼ˆ1ï¼‰ã€‚
- en: Now, letâ€™s plot the data to visualize the anomalies.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»˜åˆ¶æ•°æ®ä»¥å¯è§†åŒ–å¼‚å¸¸ã€‚
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/8803146e1e998c3319afffb1cf83ca5d.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8803146e1e998c3319afffb1cf83ca5d.png)'
- en: Monitoring CPU usage on an EC2 instance. The two red dots indicated anomalous
    points, while the other blue dots are considered normal. Image by the author.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ç›‘æ§EC2å®ä¾‹ä¸Šçš„CPUä½¿ç”¨æƒ…å†µã€‚ä¸¤ä¸ªçº¢ç‚¹è¡¨ç¤ºå¼‚å¸¸ç‚¹ï¼Œè€Œå…¶ä»–è“ç‚¹è¢«è®¤ä¸ºæ˜¯æ­£å¸¸çš„ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: From the figure above, we can see that our data only contains two outliers,
    as indicated by the red dots.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸Šé¢çš„å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ•°æ®ä»…åŒ…å«ä¸¤ä¸ªç¦»ç¾¤ç‚¹ï¼Œå¦‚çº¢è‰²ç‚¹æ‰€ç¤ºã€‚
- en: This shows how challenging anomaly detection can be! Because they are rare events,
    we have few occasions to learn from them. In this case, only 2 points are outliers,
    which represent 0.05% of the data. It also makes the evaluation of the models
    more challenging. A method basically has two occasions of getting it right, and
    4030 occasions of being wrong.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¾ç¤ºäº†å¼‚å¸¸æ£€æµ‹çš„æŒ‘æˆ˜æ€§ï¼ç”±äºè¿™äº›äº‹ä»¶å¾ˆå°‘ï¼Œæˆ‘ä»¬å¾ˆå°‘æœ‰æœºä¼šä»ä¸­å­¦ä¹ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåªæœ‰2ä¸ªç‚¹æ˜¯ç¦»ç¾¤ç‚¹ï¼Œå æ•°æ®çš„0.05%ã€‚è¿™ä¹Ÿä½¿å¾—æ¨¡å‹è¯„ä¼°æ›´å…·æŒ‘æˆ˜æ€§ã€‚ä¸€ä¸ªæ–¹æ³•åŸºæœ¬ä¸Šåªæœ‰ä¸¤æ¬¡æ­£ç¡®çš„æœºä¼šï¼Œè€Œæœ‰4030æ¬¡é”™è¯¯çš„æœºä¼šã€‚
- en: With all that in mind, letâ€™s apply some techniques for anomaly detection in
    time series, starting with the mean absolute deviation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: é‰´äºä»¥ä¸Šæ‰€æœ‰å†…å®¹ï¼Œè®©æˆ‘ä»¬åº”ç”¨ä¸€äº›æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹æŠ€æœ¯ï¼Œä»å¹³å‡ç»å¯¹åå·®å¼€å§‹ã€‚
- en: Mean absolute deviation (MAD)
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¹³å‡ç»å¯¹åå·®ï¼ˆMADï¼‰
- en: If our data is normally distributed, we can reasonably say that data points
    at each end of the tails can be considered an outlier.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬çš„æ•°æ®æ˜¯æ­£æ€åˆ†å¸ƒçš„ï¼Œæˆ‘ä»¬å¯ä»¥åˆç†åœ°è¯´ï¼Œå°¾éƒ¨çš„æ¯ä¸ªæ•°æ®ç‚¹éƒ½å¯ä»¥è¢«è§†ä¸ºç¦»ç¾¤ç‚¹ã€‚
- en: To identify them, we can use the Z-score, which is a measurement in terms of
    standard deviations from the mean. If the Z-score is 0, the value is equal to
    the mean. Typically, we set a Z-score threshold of 3 or 3.5 to indicate if a value
    is an outlier or not.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¯†åˆ«å®ƒä»¬ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Z åˆ†æ•°ï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥æ ‡å‡†å·®ä¸ºå•ä½çš„å‡å€¼æµ‹é‡ã€‚å¦‚æœ Z åˆ†æ•°ä¸º 0ï¼Œåˆ™å€¼ç­‰äºå‡å€¼ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬è®¾ç½® Z åˆ†æ•°é˜ˆå€¼ä¸º 3 æˆ– 3.5ï¼Œä»¥æŒ‡ç¤ºä¸€ä¸ªå€¼æ˜¯å¦æ˜¯å¼‚å¸¸å€¼ã€‚
- en: Now, recall that the Z-score is calculated as
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå›æƒ³ä¸€ä¸‹ Z åˆ†æ•°çš„è®¡ç®—æ–¹æ³•ã€‚
- en: '![](../Images/87d492189d18a7d3083679f6d2eeeed6.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87d492189d18a7d3083679f6d2eeeed6.png)'
- en: Equation for the Z-score. Image by the author.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Z åˆ†æ•°çš„å…¬å¼ã€‚ä½œè€…æä¾›çš„å›¾åƒã€‚
- en: Where *mu* is the mean of the sample and *sigma* is the standard deviation.
    Basically, if the Z-score is large, it means that the value is far from the mean
    and towards one end of the distributionâ€™s tail, which in turn can mean that it
    is an outlier.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *mu* æ˜¯æ ·æœ¬çš„å‡å€¼ï¼Œ*sigma* æ˜¯æ ‡å‡†å·®ã€‚åŸºæœ¬ä¸Šï¼Œå¦‚æœ Z åˆ†æ•°å¾ˆå¤§ï¼Œæ„å‘³ç€è¯¥å€¼è¿œç¦»å‡å€¼ï¼Œæ¥è¿‘åˆ†å¸ƒå°¾éƒ¨çš„ä¸€ç«¯ï¼Œè¿™ä¹Ÿå¯èƒ½è¡¨ç¤ºå®ƒæ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ã€‚
- en: '![](../Images/de982122e3febefb67266f9215c7f351.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de982122e3febefb67266f9215c7f351.png)'
- en: A normal distribution with the Z-score. We can see that when the Z-score is
    3, we reach the tails of the distribution, and so we can say that beyond that
    threshold, the data are outliers. Image by the author.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦æœ‰ Z åˆ†æ•°çš„æ­£æ€åˆ†å¸ƒã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“ Z åˆ†æ•°ä¸º 3 æ—¶ï¼Œæˆ‘ä»¬è¾¾åˆ°äº†åˆ†å¸ƒçš„å°¾éƒ¨ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥è¯´ï¼Œè¶…è¿‡è¯¥é˜ˆå€¼çš„æ•°æ®æ˜¯å¼‚å¸¸å€¼ã€‚ä½œè€…æä¾›çš„å›¾åƒã€‚
- en: From the figure above, we can visualize the classical Z-score threshold of 3
    to determine if a value is an outlier or not. As shown by the black dashed lines,
    a Z-score of 3 brings us to the ends of the normal distribution. So, any value
    with a Z-score greater than 3 (or less than -3 if we are not working in absolute
    values) can be labelled as an outlier.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸Šå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç›´è§‚åœ°çœ‹åˆ°ç»å…¸çš„ Z åˆ†æ•°é˜ˆå€¼ 3ï¼Œç”¨äºç¡®å®šä¸€ä¸ªå€¼æ˜¯å¦æ˜¯å¼‚å¸¸å€¼ã€‚å¦‚é»‘è‰²è™šçº¿æ‰€ç¤ºï¼ŒZ åˆ†æ•°ä¸º 3 æ—¶ï¼Œæˆ‘ä»¬è¾¾åˆ°äº†æ­£æ€åˆ†å¸ƒçš„å°¾éƒ¨ã€‚å› æ­¤ï¼Œä»»ä½•
    Z åˆ†æ•°å¤§äº 3ï¼ˆæˆ–å°äº -3ï¼Œå¦‚æœæˆ‘ä»¬ä¸å¤„ç†ç»å¯¹å€¼çš„è¯ï¼‰éƒ½å¯ä»¥æ ‡è®°ä¸ºå¼‚å¸¸å€¼ã€‚
- en: Now, this works great under the assumption that we have a perfectly normal distribution,
    but the presence of outliers necessarily affects the mean, which in turns affect
    the Z-score. Therefore, we turn our attention to the median absolute deviation
    or MAD.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè¿™åœ¨æˆ‘ä»¬å‡è®¾æœ‰ä¸€ä¸ªå®Œå…¨æ­£æ€åˆ†å¸ƒçš„æƒ…å†µä¸‹æ•ˆæœå¾ˆå¥½ï¼Œä½†å¼‚å¸¸å€¼çš„å­˜åœ¨å¿…ç„¶ä¼šå½±å“å‡å€¼ï¼Œä»è€Œå½±å“ Z åˆ†æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†æ³¨æ„åŠ›è½¬å‘ä¸­ä½ç»å¯¹åå·®æˆ– MADã€‚
- en: The robust Z-score method
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¼ºå¥ Z åˆ†æ•°æ–¹æ³•
- en: To avoid the influence of outliers on the Z-score, instead use the median, which
    is a more robust metric in the presence of outliers.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†é¿å…å¼‚å¸¸å€¼å¯¹ Z åˆ†æ•°çš„å½±å“ï¼Œæ”¹ç”¨ä¸­ä½æ•°ï¼Œè¿™åœ¨å­˜åœ¨å¼‚å¸¸å€¼æ—¶æ˜¯æ›´å¼ºå¥çš„æŒ‡æ ‡ã€‚
- en: 'The median absolute deviation or MAD is defined as:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸­ä½ç»å¯¹åå·®æˆ– MAD å®šä¹‰ä¸ºï¼š
- en: '![](../Images/7d608cd3d231b2bdc8fe5375a6663d86.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d608cd3d231b2bdc8fe5375a6663d86.png)'
- en: The MAD is the median of the absolute difference between a value and the median
    of the sample. Image by the author.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: MAD æ˜¯å€¼ä¸æ ·æœ¬ä¸­ä½æ•°ä¹‹é—´ç»å¯¹å·®å€¼çš„ä¸­ä½æ•°ã€‚ä½œè€…æä¾›çš„å›¾åƒã€‚
- en: 'Basically, the MAD is the median of the absolute difference between the values
    of a sample and the median of the sample. Then, we can calculate the robust Z-score
    with:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼ŒMAD æ˜¯æ ·æœ¬å€¼ä¸æ ·æœ¬ä¸­ä½æ•°ä¹‹é—´ç»å¯¹å·®å€¼çš„ä¸­ä½æ•°ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—å¼ºå¥ Z åˆ†æ•°ï¼š
- en: '![](../Images/484d48fce120d5619883d7d44cc8958f.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/484d48fce120d5619883d7d44cc8958f.png)'
- en: Robust Z-score formula. Note that 0.6745 is the 75th percentile of the standard
    normal distribution to which the MAD converges to. Image by the author.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ºå¥ Z åˆ†æ•°å…¬å¼ã€‚è¯·æ³¨æ„ï¼Œ0.6745 æ˜¯ MAD æ”¶æ•›çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç¬¬ 75 ä¸ªç™¾åˆ†ä½æ•°ã€‚ä½œè€…æä¾›çš„å›¾åƒã€‚
- en: Here, the robust Z-score takes the difference between a value and the median
    of the sample, multiplies it by 0.6745 and we divide everything by the MAD. Note
    that 0.6745 represents the 75th percentile of a standard normal distribution.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œå¼ºå¥ Z åˆ†æ•°è®¡ç®—æ–¹æ³•æ˜¯ï¼šå–å€¼ä¸æ ·æœ¬ä¸­ä½æ•°ä¹‹é—´çš„å·®å€¼ï¼Œä¹˜ä»¥ 0.6745ï¼Œç„¶åé™¤ä»¥ MADã€‚è¯·æ³¨æ„ï¼Œ0.6745 ä»£è¡¨æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç¬¬ 75 ä¸ªç™¾åˆ†ä½æ•°ã€‚
- en: '**Why 0.6745? (optional read)**'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸ºä»€ä¹ˆæ˜¯ 0.6745ï¼Ÿï¼ˆå¯é€‰é˜…è¯»ï¼‰**'
- en: Unlike the traditional Z-score, the robust Z-score uses the median absolute
    deviation, which is always smaller than the standard deviation. Thus, to obtain
    a value that resembles a Z-score, we must scale it.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ä¼ ç»Ÿçš„ Z åˆ†æ•°ä¸åŒï¼Œå¼ºå¥ Z åˆ†æ•°ä½¿ç”¨ä¸­ä½ç»å¯¹åå·®ï¼Œè¿™é€šå¸¸å°äºæ ‡å‡†å·®ã€‚å› æ­¤ï¼Œä¸ºäº†è·å¾—ç±»ä¼¼ Z åˆ†æ•°çš„å€¼ï¼Œæˆ‘ä»¬å¿…é¡»è¿›è¡Œç¼©æ”¾ã€‚
- en: In a normal distribution with no outliers, the MAD is about 2/3 (0.6745 to be
    precise) as big as the standard deviation. Therefore, because we are dividing
    by the MAD, we multiply by 0.6745 to get back to the scale of the normal Z-score.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ²¡æœ‰å¼‚å¸¸å€¼çš„æ­£æ€åˆ†å¸ƒä¸­ï¼ŒMAD å¤§çº¦æ˜¯æ ‡å‡†å·®çš„ 2/3ï¼ˆç²¾ç¡®æ¥è¯´æ˜¯ 0.6745ï¼‰ã€‚å› æ­¤ï¼Œç”±äºæˆ‘ä»¬æ˜¯é™¤ä»¥ MADï¼Œæˆ‘ä»¬ä¹˜ä»¥ 0.6745 ä»¥å›åˆ°æ­£æ€
    Z åˆ†æ•°çš„å°ºåº¦ã€‚
- en: 'The robust Z-score method will work best under two important assumptions:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨³å¥Zåˆ†æ•°æ–¹æ³•åœ¨ä¸¤ä¸ªé‡è¦å‡è®¾ä¸‹æ•ˆæœæœ€ä½³ï¼š
- en: The data is close to a normal distribution
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•°æ®æ¥è¿‘æ­£æ€åˆ†å¸ƒ
- en: The MAD is not equal to 0 (happens when more than 50% of the data has the same
    value)
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MADä¸ç­‰äº0ï¼ˆå½“è¶…è¿‡50%çš„æ•°æ®å…·æœ‰ç›¸åŒå€¼æ—¶ä¼šå‘ç”Ÿï¼‰
- en: The second point is interesting, because if that is the case, then any value
    that is not equal to the median will be flagged as an outlier, no matter the threshold,
    since the robust Z-score will be incredibly large.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒç‚¹å¾ˆæœ‰è¶£ï¼Œå› ä¸ºå¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œé‚£ä¹ˆä»»ä½•ä¸ç­‰äºä¸­ä½æ•°çš„å€¼éƒ½ä¼šè¢«æ ‡è®°ä¸ºå¼‚å¸¸å€¼ï¼Œæ— è®ºé˜ˆå€¼å¦‚ä½•ï¼Œå› ä¸ºç¨³å¥Zåˆ†æ•°å°†ä¼šéå¸¸å¤§ã€‚
- en: With all that in mind, letâ€™s apply this method to our scenario.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: é‰´äºæ­¤ï¼Œè®©æˆ‘ä»¬å°†æ­¤æ–¹æ³•åº”ç”¨åˆ°æˆ‘ä»¬çš„åœºæ™¯ä¸­ã€‚
- en: Applying the MAD for outlier detection
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åº”ç”¨MADè¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹
- en: First, we need to check the distribution of our data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥æ•°æ®çš„åˆ†å¸ƒæƒ…å†µã€‚
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/e216f583307e317516864b7cb9e47561.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e216f583307e317516864b7cb9e47561.png)'
- en: Distribution of our data. Already, we see that we do not have a normal distribution!
    Even worse, a lot of data points fall right on the median (black dashed line),
    meaning that the MAD is either 0 or very close to 0\. Image by the author.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ•°æ®åˆ†å¸ƒæƒ…å†µã€‚æˆ‘ä»¬å·²ç»çœ‹åˆ°æ•°æ®ä¸ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼æ›´ç³Ÿçš„æ˜¯ï¼Œè®¸å¤šæ•°æ®ç‚¹æ­£å¥½è½åœ¨ä¸­ä½æ•°ï¼ˆé»‘è‰²è™šçº¿ï¼‰ä¸Šï¼Œè¿™æ„å‘³ç€MADè¦ä¹ˆæ˜¯0ï¼Œè¦ä¹ˆéå¸¸æ¥è¿‘0ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: From the figure above, we can already see two problems. First, the data is close
    to a normal distribution. Second, the black dashed line indicates the median of
    the sample, and it fall right on the peak of the distribution. This means that
    a lot of data points are equal to the median, meaning that we are in a situation
    where the MAD is potentially 0 or very close to 0.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸Šå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸¤ä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼Œæ•°æ®æ¥è¿‘æ­£æ€åˆ†å¸ƒã€‚å…¶æ¬¡ï¼Œé»‘è‰²è™šçº¿è¡¨ç¤ºæ ·æœ¬çš„ä¸­ä½æ•°ï¼Œå®ƒæ­£å¥½ä½äºåˆ†å¸ƒçš„å³°å€¼ä¸Šã€‚è¿™æ„å‘³ç€è®¸å¤šæ•°æ®ç‚¹ç­‰äºä¸­ä½æ•°ï¼Œæ„å‘³ç€æˆ‘ä»¬å¤„äºMADå¯èƒ½ä¸º0æˆ–éå¸¸æ¥è¿‘0çš„æƒ…å†µã€‚
- en: Nevertheless, letâ€™s continue applying the method, just so that we understand
    how to work with it.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç»§ç»­åº”ç”¨è¯¥æ–¹æ³•ï¼Œä»¥ä¾¿äº†è§£å¦‚ä½•ä½¿ç”¨å®ƒã€‚
- en: The next step, is to compute the MAD and the median of the sample to calculate
    the robust Z-score. The *scipy* package comes with an implementation of the MAD
    formula.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€æ­¥æ˜¯è®¡ç®—æ ·æœ¬çš„MADå’Œä¸­ä½æ•°ï¼Œä»¥è®¡ç®—ç¨³å¥Zåˆ†æ•°ã€‚*scipy*åŒ…åŒ…å«äº†MADå…¬å¼çš„å®ç°ã€‚
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, we simply write a function to calculate the robust Z-score and create
    a new column to store the score.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ç®€å•åœ°ç¼–å†™ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—ç¨³å¥Zåˆ†æ•°ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ–°åˆ—æ¥å­˜å‚¨åˆ†æ•°ã€‚
- en: '[PRE5]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that we get a MAD of 0.002, which definitely close to 0, meaning that this
    baseline is likely not going to perform very well.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬å¾—åˆ°äº†0.002çš„MADï¼Œè¿™ç¡®å®æ¥è¿‘0ï¼Œæ„å‘³ç€è¿™ä¸ªåŸºå‡†å¯èƒ½è¡¨ç°ä¸ä½³ã€‚
- en: Once this is done, we decide on a threshold to flag outliers. A typical threshold
    is 3 or 3.5\. In this case, any value with a robust Z-score greater than 3.5 (right-hand
    tail) or smaller than -3.5 (left-hand tail) will be flagged as an outlier.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆåï¼Œæˆ‘ä»¬å†³å®šä¸€ä¸ªé˜ˆå€¼æ¥æ ‡è®°å¼‚å¸¸å€¼ã€‚å…¸å‹çš„é˜ˆå€¼æ˜¯3æˆ–3.5ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»»ä½•ç¨³å¥Zåˆ†æ•°å¤§äº3.5ï¼ˆå³å°¾ï¼‰æˆ–å°äº-3.5ï¼ˆå·¦å°¾ï¼‰çš„å€¼å°†è¢«æ ‡è®°ä¸ºå¼‚å¸¸å€¼ã€‚
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Finally, we can plot a confusion matrix to see if our baseline correctly identified
    outliers and inliers.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶æ··æ·†çŸ©é˜µï¼Œçœ‹çœ‹æˆ‘ä»¬çš„åŸºå‡†æ˜¯å¦æ­£ç¡®è¯†åˆ«äº†å¼‚å¸¸å€¼å’Œæ­£å¸¸å€¼ã€‚
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/d6bffc49f5cd8ef27ecc24323f0be5d1.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6bffc49f5cd8ef27ecc24323f0be5d1.png)'
- en: Confusion matrix of the baseline outlier detection method. Clearly, a lot of
    inliers were flagged as anomalies, which is expected since our data did not respect
    the assumptions of the MAD method. Image by the author.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºå‡†å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•çš„æ··æ·†çŸ©é˜µã€‚æ˜¾ç„¶ï¼Œè®¸å¤šæ­£å¸¸å€¼è¢«æ ‡è®°ä¸ºå¼‚å¸¸å€¼ï¼Œè¿™åœ¨é¢„æœŸä¹‹ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ•°æ®æ²¡æœ‰ç¬¦åˆMADæ–¹æ³•çš„å‡è®¾ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: Unsurprisingly, we see that the baseline method performs poorly, since 1066
    inliers were flagged as outliers. Again, this was expected since our data did
    not respect the assumptions of the method, and the MAD was very close to 0\. Still,
    I wanted to cover the implementation of this method in case it serves you in another
    scenario.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯«ä¸æ„å¤–åœ°ï¼Œæˆ‘ä»¬çœ‹åˆ°åŸºå‡†æ–¹æ³•è¡¨ç°ä¸ä½³ï¼Œå› ä¸º1066ä¸ªæ­£å¸¸å€¼è¢«æ ‡è®°ä¸ºå¼‚å¸¸å€¼ã€‚è¿™å†æ¬¡æ˜¯é¢„æœŸä¸­çš„æƒ…å†µï¼Œå› ä¸ºæˆ‘ä»¬çš„æ•°æ®æ²¡æœ‰ç¬¦åˆè¯¥æ–¹æ³•çš„å‡è®¾ï¼Œä¸”MADéå¸¸æ¥è¿‘0ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘è¿˜æ˜¯æƒ³ä»‹ç»è¿™ç§æ–¹æ³•çš„å®ç°ï¼Œä»¥é˜²åœ¨å…¶ä»–åœºæ™¯ä¸­å¯¹ä½ æœ‰ç”¨ã€‚
- en: Although the results are disappointing, this method still holds when the assumptions
    are true for your dataset, and you now know how to apply it when it makes sense.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ç»“æœä»¤äººå¤±æœ›ï¼Œä½†å½“å‡è®¾å¯¹ä½ çš„æ•°æ®é›†æˆç«‹æ—¶ï¼Œè¿™ç§æ–¹æ³•ä»ç„¶æœ‰æ•ˆï¼Œç°åœ¨ä½ çŸ¥é“åœ¨æœ‰æ„ä¹‰çš„æƒ…å†µä¸‹å¦‚ä½•åº”ç”¨å®ƒã€‚
- en: Now, letâ€™s move on to the machine learning approached, starting with isolation
    forest.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬è½¬åˆ°æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œé¦–å…ˆä»éš”ç¦»æ£®æ—å¼€å§‹ã€‚
- en: Isolation Forest
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: éš”ç¦»æ£®æ—
- en: The isolation forest algorithm is a tree-based algorithm that is often used
    for anomaly detection.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å­¤ç«‹æ£®æ—ç®—æ³•æ˜¯ä¸€ç§åŸºäºæ ‘çš„ç®—æ³•ï¼Œé€šå¸¸ç”¨äºå¼‚å¸¸æ£€æµ‹ã€‚
- en: The algorithm starts by randomly selecting an attribute and randomly selecting
    a split value between the maximum and minimum values for that attribute. This
    partitioning is done many times until the algorithm has isolated each point in
    the dataset.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ç®—æ³•é¦–å…ˆéšæœºé€‰æ‹©ä¸€ä¸ªå±æ€§ï¼Œå¹¶åœ¨è¯¥å±æ€§çš„æœ€å¤§å€¼å’Œæœ€å°å€¼ä¹‹é—´éšæœºé€‰æ‹©ä¸€ä¸ªåˆ†è£‚å€¼ã€‚è¿™ä¸ªåˆ†åŒºè¿‡ç¨‹ä¼šé‡å¤å¤šæ¬¡ï¼Œç›´åˆ°ç®—æ³•éš”ç¦»äº†æ•°æ®é›†ä¸­çš„æ¯ä¸ªç‚¹ã€‚
- en: Then, the intuition behind this algorithm is that an outlier will take fewer
    partitions to be isolated than a normal point, as shown in the figures below.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œè¿™ä¸ªç®—æ³•çš„ç›´è§‰æ˜¯ï¼Œç¦»ç¾¤ç‚¹éš”ç¦»æ‰€éœ€çš„åˆ†åŒºä¼šæ¯”æ­£å¸¸ç‚¹å°‘ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
- en: '![](../Images/27a7c0261401deb2477d19830352ec9b.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27a7c0261401deb2477d19830352ec9b.png)'
- en: Isolating an inlier. Notice how the data has to be partitioned many times before
    the point is isolated. Image by Sai Borrelli â€” [Wikipedia](https://commons.wikimedia.org/w/index.php?curid=82709489)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: éš”ç¦»ä¸€ä¸ªå†…ç‚¹ã€‚æ³¨æ„åœ¨ç‚¹è¢«éš”ç¦»ä¹‹å‰ï¼Œæ•°æ®å¿…é¡»ç»è¿‡å¤šæ¬¡åˆ†åŒºã€‚å›¾åƒç”±Sai Borrelliæä¾› â€” [ç»´åŸºç™¾ç§‘](https://commons.wikimedia.org/w/index.php?curid=82709489)
- en: '![](../Images/d456164b1a2801e575d9499036d1997f.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d456164b1a2801e575d9499036d1997f.png)'
- en: Isolating an outlier. Now, we see that less partitions were required to isolate
    it. Therefore, it it likely an anomaly. Image by Sai Borrelli â€” [Wikipedia](https://commons.wikimedia.org/w/index.php?curid=82709491)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: éš”ç¦»ä¸€ä¸ªç¦»ç¾¤ç‚¹ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬çœ‹åˆ°éš”ç¦»å®ƒæ‰€éœ€çš„åˆ†åŒºè¾ƒå°‘ã€‚å› æ­¤ï¼Œå®ƒå¾ˆå¯èƒ½æ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ã€‚å›¾åƒç”±Sai Borrelliæä¾› â€” [ç»´åŸºç™¾ç§‘](https://commons.wikimedia.org/w/index.php?curid=82709491)
- en: In the two figures above, we can see how the number of partitions differ when
    isolating an inlier and an outlier. In the top figure, isolating an inlier required
    many splits. In the bottom figure, fewer splits were necessary to isolate the
    point. Therefore, it is likely to be an anomaly.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„ä¸¤ä¸ªå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨éš”ç¦»å†…ç‚¹å’Œç¦»ç¾¤ç‚¹æ—¶ï¼Œåˆ†åŒºçš„æ•°é‡å¦‚ä½•ä¸åŒã€‚åœ¨é¡¶éƒ¨å›¾ä¸­ï¼Œéš”ç¦»ä¸€ä¸ªå†…ç‚¹éœ€è¦å¾ˆå¤šåˆ†è£‚ã€‚åœ¨åº•éƒ¨å›¾ä¸­ï¼Œéš”ç¦»ç‚¹æ‰€éœ€çš„åˆ†è£‚è¾ƒå°‘ã€‚å› æ­¤ï¼Œå®ƒå¾ˆå¯èƒ½æ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ã€‚
- en: So we see how in an isolation forest, if the path to isolate a data point is
    short, then it is an anomaly!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬çœ‹åˆ°åœ¨å­¤ç«‹æ£®æ—ä¸­ï¼Œå¦‚æœéš”ç¦»æ•°æ®ç‚¹çš„è·¯å¾„å¾ˆçŸ­ï¼Œé‚£ä¹ˆå®ƒå°±æ˜¯ä¸€ä¸ªå¼‚å¸¸å€¼ï¼
- en: Applying the isolation forest
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åº”ç”¨å­¤ç«‹æ£®æ—
- en: First, letâ€™s split our data into a training and a test set. That way, we can
    evaluate if the model is able to flag an anomaly on unseen data. This is sometimes
    called novelty detection, instead of anomaly detection.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬å°†æ•°æ®åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥è¯„ä¼°æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿåœ¨æœªè§æ•°æ®ä¸Šæ ‡è®°å¼‚å¸¸å€¼ã€‚è¿™æœ‰æ—¶è¢«ç§°ä¸ºæ–°é¢–æ€§æ£€æµ‹ï¼Œè€Œä¸æ˜¯å¼‚å¸¸æ£€æµ‹ã€‚
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Then, we can train our isolation forest algorithm. Here, we need to specify
    a level of contamination, which is simply the fraction of outliers in the training
    data. In this case, we only have one outlier in the training set.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒæˆ‘ä»¬çš„å­¤ç«‹æ£®æ—ç®—æ³•ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦æŒ‡å®šä¸€ä¸ªæ±¡æŸ“æ°´å¹³ï¼Œè¿™åªæ˜¯è®­ç»ƒæ•°æ®ä¸­ç¦»ç¾¤ç‚¹çš„æ¯”ä¾‹ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬çš„è®­ç»ƒé›†åªæœ‰ä¸€ä¸ªç¦»ç¾¤ç‚¹ã€‚
- en: '[PRE9]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Once trained, we can then generate predictions.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆé¢„æµ‹ã€‚
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Again, we can plot the confusion matrix to see how the model performs.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶æ··æ·†çŸ©é˜µä»¥æŸ¥çœ‹æ¨¡å‹çš„è¡¨ç°ã€‚
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/b7a0966b20d32421c0fb468077a81ee7.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7a0966b20d32421c0fb468077a81ee7.png)'
- en: Confusion matrix of the isolation forest algorithm. Here, we can see that the
    algorithm did not flag any of the anomalies. It also mislabelled an anomaly as
    a normal point. Image by the author.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å­¤ç«‹æ£®æ—ç®—æ³•çš„æ··æ·†çŸ©é˜µã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç®—æ³•æ²¡æœ‰æ ‡è®°ä»»ä½•å¼‚å¸¸å€¼ã€‚å®ƒè¿˜é”™è¯¯åœ°å°†ä¸€ä¸ªå¼‚å¸¸å€¼æ ‡è®°ä¸ºæ­£å¸¸ç‚¹ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: From the figure above, we notice that the algorithm was not able to flag the
    new anomaly. It also labelled an anomaly as a normal point.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸Šé¢çš„å›¾ä¸­ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°ç®—æ³•æ— æ³•æ ‡è®°æ–°çš„å¼‚å¸¸å€¼ã€‚å®ƒè¿˜å°†ä¸€ä¸ªå¼‚å¸¸å€¼æ ‡è®°ä¸ºæ­£å¸¸ç‚¹ã€‚
- en: Again, this is a disappointing result, but we still have one more method to
    cover, which is the local outlier factor.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼Œè¿™æ˜¯ä¸€é¡¹ä»¤äººå¤±æœ›çš„ç»“æœï¼Œä½†æˆ‘ä»¬è¿˜æœ‰ä¸€ç§æ–¹æ³•éœ€è¦ä»‹ç»ï¼Œå³å±€éƒ¨ç¦»ç¾¤å› å­ã€‚
- en: Local outlier factor
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å±€éƒ¨ç¦»ç¾¤å› å­
- en: Intuitively, the local outlier factor (LOF) works by comparing the local density
    of a point to the local densities of its neighbours. If the densities of the point
    and its neighbours are similar, then the point is an inlier. However, if the density
    of the point is much smaller than the densities of its neighbours, then it must
    be an outlier, because a lower density means that the point is more isolated.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´è§‚ä¸Šï¼Œå±€éƒ¨ç¦»ç¾¤å› å­ï¼ˆLOFï¼‰é€šè¿‡æ¯”è¾ƒç‚¹çš„å±€éƒ¨å¯†åº¦ä¸å…¶é‚»å±…çš„å±€éƒ¨å¯†åº¦æ¥å·¥ä½œã€‚å¦‚æœç‚¹å’Œé‚»å±…çš„å¯†åº¦ç›¸ä¼¼ï¼Œé‚£ä¹ˆè¯¥ç‚¹å°±æ˜¯ä¸€ä¸ªå†…ç‚¹ã€‚ç„¶è€Œï¼Œå¦‚æœç‚¹çš„å¯†åº¦è¿œå°äºé‚»å±…çš„å¯†åº¦ï¼Œé‚£ä¹ˆå®ƒä¸€å®šæ˜¯ä¸€ä¸ªç¦»ç¾¤ç‚¹ï¼Œå› ä¸ºè¾ƒä½çš„å¯†åº¦æ„å‘³ç€è¯¥ç‚¹æ›´å­¤ç«‹ã€‚
- en: Of course, we need to set the number of neighbours to look at, and *scikit-learn*â€™s
    default parameter is 20, which works well in most cases.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®è¦æŸ¥çœ‹çš„é‚»å±…æ•°é‡ï¼Œ*scikit-learn* çš„é»˜è®¤å‚æ•°æ˜¯ 20ï¼Œè¿™åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ•ˆæœå¾ˆå¥½ã€‚
- en: Once the number of neighbours is set, we calculate the *reachability distance.*
    It is a bit tricky to explain this with words and pictures only, but I will do
    my best.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è®¾ç½®äº†é‚»å±…çš„æ•°é‡ï¼Œæˆ‘ä»¬å°±è®¡ç®—*å¯è¾¾è·ç¦»*ã€‚ä»…ç”¨æ–‡å­—å’Œå›¾ç‰‡è§£é‡Šè¿™æœ‰ç‚¹å¤æ‚ï¼Œä½†æˆ‘ä¼šå°½åŠ›è¯´æ˜ã€‚
- en: '![](../Images/44737a3754b4972abba7ac5125c01aa0.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44737a3754b4972abba7ac5125c01aa0.png)'
- en: Visualizing the reachability distance, Image by the author.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–å¯è¾¾è·ç¦»ï¼Œå›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: Suppose that we are studying point A, and that we set the number of neighbours
    to 3 (k=3). Drawing a circle while keeping point A in the middle results in the
    black dotted circle you see in the figure above. Points B, C and D are the three
    closest neighbours to A, and point E is too far in this case, so it is ignored.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æ­£åœ¨ç ”ç©¶ç‚¹ Aï¼Œå¹¶ä¸”æˆ‘ä»¬å°†é‚»å±…æ•°é‡è®¾ç½®ä¸º 3ï¼ˆk=3ï¼‰ã€‚åœ¨ä¿æŒç‚¹ A åœ¨ä¸­é—´çš„æƒ…å†µä¸‹ç”»ä¸€ä¸ªåœ†åœˆï¼Œå°±ä¼šå¾—åˆ°ä½ åœ¨ä¸Šå›¾ä¸­çœ‹åˆ°çš„é»‘è‰²è™šçº¿åœ†åœˆã€‚ç‚¹ Bã€C
    å’Œ D æ˜¯ç¦» A æœ€è¿‘çš„ä¸‰ä¸ªé‚»å±…ï¼Œè€Œç‚¹ E åœ¨è¿™ç§æƒ…å†µä¸‹å¤ªè¿œï¼Œå› æ­¤è¢«å¿½ç•¥ã€‚
- en: 'Now, the reachability distance is defined as:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå¯è¾¾è·ç¦»è¢«å®šä¹‰ä¸ºï¼š
- en: '![](../Images/69369779b5f660ab492552f1d7bba59f.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69369779b5f660ab492552f1d7bba59f.png)'
- en: Reachability equation. Image by the author.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: å¯è¾¾è·ç¦»æ–¹ç¨‹ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: In words, the reachability distance from A to B is the largest value between
    the k-distance of B and the actual distance from A to B.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œä» A åˆ° B çš„å¯è¾¾è·ç¦»æ˜¯ B çš„ k-è·ç¦»å’Œ A åˆ° B çš„å®é™…è·ç¦»ä¹‹é—´çš„è¾ƒå¤§å€¼ã€‚
- en: The k-distance of B is simply the distance from point B to its third nearest
    neighbour. Thatâ€™s why in the figure above, we drew a blue dotted circle with B
    at its center, to realize that the distance from B to C is the k-distance of B.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: B çš„ k-è·ç¦»åªæ˜¯ä»ç‚¹ B åˆ°å…¶ç¬¬ä¸‰ä¸ªæœ€è¿‘é‚»çš„è·ç¦»ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨ä¸Šé¢çš„å›¾ä¸­ï¼Œæˆ‘ä»¬ç”»äº†ä¸€ä¸ªä»¥ B ä¸ºä¸­å¿ƒçš„è“è‰²è™šçº¿åœ†åœˆï¼Œä»¥ä½“ç°ä» B åˆ° C çš„è·ç¦»æ˜¯
    B çš„ k-è·ç¦»ã€‚
- en: Once the reachability distance is calculated for all the k-nearest neighbours
    of A, the local reachability density will be computed. This is simply the inverse
    of the average of the reachability distances.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è®¡ç®—äº† A çš„æ‰€æœ‰ k ä¸ªæœ€è¿‘é‚»çš„å¯è¾¾è·ç¦»ï¼Œå°†è®¡ç®—å±€éƒ¨å¯è¾¾å¯†åº¦ã€‚è¿™ä»…ä»…æ˜¯å¯è¾¾è·ç¦»çš„å¹³å‡å€¼çš„å€’æ•°ã€‚
- en: Intuitively, the reachability density tells us how far we have to travel to
    reach a neighbouring point. If the density is large, then points are close together
    and we donâ€™t have too travel for long.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´è§‚ä¸Šï¼Œå¯è¾¾å¯†åº¦å‘Šè¯‰æˆ‘ä»¬åˆ°è¾¾é‚»è¿‘ç‚¹éœ€è¦èµ°å¤šè¿œã€‚å¦‚æœå¯†åº¦å¤§ï¼Œåˆ™ç‚¹å½¼æ­¤é è¿‘ï¼Œæˆ‘ä»¬ä¸éœ€è¦èµ°å¤ªè¿œã€‚
- en: Finally, the local outlier factor, is simply a ratio of the local reachability
    densities. In the figure above, we set *k* to 3, so we would have three ratios
    that we would average. This allows us to compare the local density of a point
    to its neighbour.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå±€éƒ¨å¼‚å¸¸å› å­ä»…ä»…æ˜¯å±€éƒ¨å¯è¾¾å¯†åº¦çš„æ¯”ç‡ã€‚åœ¨ä¸Šé¢çš„å›¾ä¸­ï¼Œæˆ‘ä»¬å°† *k* è®¾ç½®ä¸º 3ï¼Œå› æ­¤æˆ‘ä»¬ä¼šæœ‰ä¸‰ä¸ªæ¯”ç‡éœ€è¦è¿›è¡Œå¹³å‡ã€‚è¿™å…è®¸æˆ‘ä»¬å°†ç‚¹çš„å±€éƒ¨å¯†åº¦ä¸å…¶é‚»å±…è¿›è¡Œæ¯”è¾ƒã€‚
- en: As mentioned before, if that factor is close to 1 or smaller than 1, then it
    is a normal point. If it is much larger than 1, then it is an outlier.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œå¦‚æœè¯¥å› å­æ¥è¿‘ 1 æˆ–å°äº 1ï¼Œåˆ™ä¸ºæ­£å¸¸ç‚¹ã€‚å¦‚æœå¤§äº 1ï¼Œåˆ™ä¸ºå¼‚å¸¸å€¼ã€‚
- en: Of course, this methods comes with drawbacks, as a value that is larger than
    1 is not a perfect threshold. For example, an LOF of 1.1 could mean an outlier
    for a dataset, and not for another one.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œè¿™ç§æ–¹æ³•ä¹Ÿæœ‰ç¼ºç‚¹ï¼Œå› ä¸ºå¤§äº1çš„å€¼å¹¶ä¸æ˜¯ä¸€ä¸ªå®Œç¾çš„é˜ˆå€¼ã€‚ä¾‹å¦‚ï¼ŒLOF ä¸º 1.1 å¯èƒ½æ„å‘³ç€æŸä¸ªæ•°æ®é›†ä¸­çš„å¼‚å¸¸å€¼ï¼Œä½†å¯¹å¦ä¸€ä¸ªæ•°æ®é›†åˆ™ä¸é€‚ç”¨ã€‚
- en: Applying the local outlier factor method
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åº”ç”¨å±€éƒ¨å¼‚å¸¸å› å­æ–¹æ³•
- en: With the use of *scikit-lean* applying the local outlier factor method is straightforward.
    We use the same train/test split as for the isolation forest to have comparable
    results.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨*scikit-learn*åº”ç”¨å±€éƒ¨å¼‚å¸¸å› å­æ–¹æ³•æ˜¯ç›´æ¥çš„ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸éš”ç¦»æ£®æ—ç›¸åŒçš„è®­ç»ƒ/æµ‹è¯•æ‹†åˆ†ï¼Œä»¥ä¾¿è·å¾—å¯æ¯”è¾ƒçš„ç»“æœã€‚
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Then, we can generate the predictions to flag potential outliers in the test
    set.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆé¢„æµ‹ä»¥æ ‡è®°æµ‹è¯•é›†ä¸­çš„æ½œåœ¨å¼‚å¸¸å€¼ã€‚
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Finally, we plot the confusion matrix to evaluate the performance.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬ç»˜åˆ¶æ··æ·†çŸ©é˜µæ¥è¯„ä¼°æ€§èƒ½ã€‚
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/203bb5e4b53dfff6cab3f7fdd6761e4d.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/203bb5e4b53dfff6cab3f7fdd6761e4d.png)'
- en: Confusion matrix for local outlier factor. We see that the algorithm successfully
    identified the only outlier in the test set. Image by the author.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å±€éƒ¨å¼‚å¸¸å› å­çš„æ··æ·†çŸ©é˜µã€‚æˆ‘ä»¬çœ‹åˆ°è¯¥ç®—æ³•æˆåŠŸè¯†åˆ«äº†æµ‹è¯•é›†ä¸­å”¯ä¸€çš„å¼‚å¸¸å€¼ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: In the figure above we see that the LOF method was able to flag the only outlier
    in the test set, and correctly labelled every other point as a normal point.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° LOF æ–¹æ³•èƒ½å¤Ÿæ ‡è®°æµ‹è¯•é›†ä¸­å”¯ä¸€çš„å¼‚å¸¸å€¼ï¼Œå¹¶ä¸”æ­£ç¡®åœ°å°†å…¶ä»–æ¯ä¸ªç‚¹æ ‡è®°ä¸ºæ­£å¸¸ç‚¹ã€‚
- en: As always, this does not mean that local outlier factor is better method than
    isolation forest. It simply means that it worked better in this particular situation.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œå¾€å¸¸ä¸€æ ·ï¼Œè¿™å¹¶ä¸æ„å‘³ç€å±€éƒ¨å¼‚å¸¸å› å­æ¯”å­¤ç«‹æ£®æ—æ–¹æ³•æ›´å¥½ã€‚è¿™åªæ˜¯è¡¨ç¤ºåœ¨è¿™ä¸ªç‰¹å®šæƒ…å†µä¸‹ï¼Œå±€éƒ¨å¼‚å¸¸å› å­æ•ˆæœæ›´å¥½ã€‚
- en: Conclusion
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this article, we explored three different methods for outlier detection in
    time series data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†ä¸‰ç§ä¸åŒçš„æ—¶é—´åºåˆ—æ•°æ®å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚
- en: First, we explored a robust Z-score that uses the mean absolute deviation (MAD).
    This works well when your data is normally distributed and if your MAD is not
    0.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬æ¢è®¨äº†ä¸€ç§ä½¿ç”¨å¹³å‡ç»å¯¹åå·®ï¼ˆMADï¼‰çš„å¼ºå¥ Z-scoreã€‚è¿™åœ¨æ•°æ®å‘ˆæ­£æ€åˆ†å¸ƒä¸” MAD ä¸ä¸º 0 æ—¶æ•ˆæœè‰¯å¥½ã€‚
- en: Then, we looked at isolation forest, which a machine learning algorithm that
    determines how many times a dataset has to be partitioned in order to isolate
    a single point. If few partitions are necessary, then the point is an outlier.
    If many partitions are required, then the point is likely an inlier.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬çœ‹äº†å­¤ç«‹æ£®æ—æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå®ƒç¡®å®šæ•°æ®é›†éœ€è¦å¤šå°‘æ¬¡åˆ†å‰²æ‰èƒ½å­¤ç«‹ä¸€ä¸ªç‚¹ã€‚å¦‚æœéœ€è¦çš„åˆ†å‰²æ¬¡æ•°å¾ˆå°‘ï¼Œé‚£ä¹ˆè¿™ä¸ªç‚¹å°±æ˜¯ä¸€ä¸ªå¼‚å¸¸ç‚¹ã€‚å¦‚æœéœ€è¦å¾ˆå¤šåˆ†å‰²ï¼Œé‚£ä¹ˆè¿™ä¸ªç‚¹å¾ˆå¯èƒ½æ˜¯å†…ç‚¹ã€‚
- en: Finally, we looked at the local outlier factor (LOF) method, which is an unsupervised
    learning method that compares the local density of a point to that of its neighbours.
    Basically, if the density of a point is small compared to its neighbours, it means
    it is an isolated point, and likely an outlier.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬çœ‹äº†å±€éƒ¨å¼‚å¸¸å› å­ï¼ˆLOFï¼‰æ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œå®ƒå°†ä¸€ä¸ªç‚¹çš„å±€éƒ¨å¯†åº¦ä¸å…¶é‚»å±…çš„å¯†åº¦è¿›è¡Œæ¯”è¾ƒã€‚åŸºæœ¬ä¸Šï¼Œå¦‚æœä¸€ä¸ªç‚¹çš„å¯†åº¦ç›¸å¯¹äºå…¶é‚»å±…è¾ƒå°ï¼Œè¿™æ„å‘³ç€å®ƒæ˜¯ä¸€ä¸ªå­¤ç«‹ç‚¹ï¼Œå¾ˆå¯èƒ½æ˜¯å¼‚å¸¸ç‚¹ã€‚
- en: I hope that you enjoyed this article and learned something new!
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œå¹¶å­¦åˆ°äº†æ–°çŸ¥è¯†ï¼
- en: Interested in mastering time series forecasting? Check out [Applied Time Series
    Forecasting in Python](https://www.datasciencewithmarco.com/offers/zTAs2hi6/checkout?coupon_code=ATSFP10),
    the only course that covers statistical, deep learning, and state-of-the-art models,
    in 100% Python.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è¦æŒæ¡æ—¶é—´åºåˆ—é¢„æµ‹å—ï¼ŸæŸ¥çœ‹[Pythonä¸­çš„åº”ç”¨æ—¶é—´åºåˆ—é¢„æµ‹](https://www.datasciencewithmarco.com/offers/zTAs2hi6/checkout?coupon_code=ATSFP10)ï¼Œè¿™æ˜¯å”¯ä¸€æ¶µç›–ç»Ÿè®¡å­¦ã€æ·±åº¦å­¦ä¹ å’Œæœ€å…ˆè¿›æ¨¡å‹çš„100%
    Pythonè¯¾ç¨‹ã€‚
- en: Cheers ğŸ»
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å¹²æ¯ ğŸ»
- en: Support me
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ”¯æŒæˆ‘
- en: Enjoying my work? Show your support with [Buy me a coffee](http://buymeacoffee.com/dswm),
    a simple way for you to encourage me, and I get to enjoy a cup of coffee! If you
    feel like it, just click the button below ğŸ‘‡
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: äº«å—æˆ‘çš„å·¥ä½œå—ï¼Ÿé€šè¿‡[è¯·æˆ‘å–å’–å•¡](http://buymeacoffee.com/dswm)æ¥æ”¯æŒæˆ‘ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•çš„æ–¹å¼æ¥é¼“åŠ±æˆ‘ï¼Œè€Œæˆ‘ä¹Ÿå¯ä»¥äº«å—ä¸€æ¯å’–å•¡ï¼å¦‚æœä½ æ„¿æ„ï¼Œç‚¹å‡»ä¸‹é¢çš„æŒ‰é’®
    ğŸ‘‡
- en: '[![](../Images/7ad9438bd50b1698fdd722fa6661b16c.png)](http://buymeacoffee.com/dswm)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/7ad9438bd50b1698fdd722fa6661b16c.png)](http://buymeacoffee.com/dswm)'
