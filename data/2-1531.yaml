- en: Modern Data Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç°ä»£æ•°æ®å·¥ç¨‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/modern-data-engineering-e202776fb9a9](https://towardsdatascience.com/modern-data-engineering-e202776fb9a9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/modern-data-engineering-e202776fb9a9](https://towardsdatascience.com/modern-data-engineering-e202776fb9a9)
- en: Platform Specific Tools and Advanced Techniques
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¹³å°ç‰¹å®šå·¥å…·å’Œé«˜çº§æŠ€æœ¯
- en: '[](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    Â·12 min readÂ·Nov 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    Â·é˜…è¯»æ—¶é—´12åˆ†é’ŸÂ·2023å¹´11æœˆ4æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c4dcaf0e3ae7f465c2b949ddc1ac7edf.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4dcaf0e3ae7f465c2b949ddc1ac7edf.png)'
- en: Photo by [Christopher Burns](https://unsplash.com/@christopher__burns?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Christopher Burns](https://unsplash.com/@christopher__burns?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The modern data ecosystem keeps evolving and new data tools emerge now and then.
    In this article, I want to talk about crucial things that affect data engineers.
    We will discuss how to use this knowledge to power advanced analytics pipelines
    and operational excellence.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç°ä»£æ•°æ®ç”Ÿæ€ç³»ç»Ÿä¸æ–­æ¼”å˜ï¼Œæ–°æ•°æ®å·¥å…·æ—¶ä¸æ—¶å‡ºç°ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æƒ³è°ˆè°ˆå½±å“æ•°æ®å·¥ç¨‹å¸ˆçš„å…³é”®å› ç´ ã€‚æˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•åˆ©ç”¨è¿™äº›çŸ¥è¯†æ¥æ¨åŠ¨å…ˆè¿›çš„åˆ†æç®¡é“å’Œå“è¶Šçš„è¿è¥ã€‚
- en: 'Iâ€™d like to discuss some popular Data engineering questions:'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³è®¨è®ºä¸€äº›æµè¡Œçš„æ•°æ®å·¥ç¨‹é—®é¢˜ï¼š
- en: Modern data engineering (DE). What is it?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç°ä»£æ•°æ®å·¥ç¨‹ï¼ˆDEï¼‰ã€‚å®ƒæ˜¯ä»€ä¹ˆï¼Ÿ
- en: Does your DE work well enough to fuel advanced data pipelines and Business intelligence
    (BI)?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ çš„æ•°æ®å·¥ç¨‹ï¼ˆDEï¼‰æ˜¯å¦è¶³å¤Ÿå¥½ï¼Œèƒ½ä¸ºå…ˆè¿›çš„æ•°æ®ç®¡é“å’Œå•†ä¸šæ™ºèƒ½ï¼ˆBIï¼‰æä¾›æ”¯æŒï¼Ÿ
- en: Are your data pipelines efficient?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½ çš„æ•°æ®ç®¡é“æ˜¯å¦é«˜æ•ˆï¼Ÿ
- en: What is required from the technological point of view to enable operational
    excellence?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»æŠ€æœ¯è§’åº¦æ¥çœ‹ï¼Œå®ç°å“è¶Šè¿è¥éœ€è¦ä»€ä¹ˆï¼Ÿ
- en: Back in October, I wrote about the rise of the Data Engineer, the role, its
    challenges, responsibilities, daily routine and how to become successful in this
    field. The data engineering landscape is constantly changing but major trends
    seem to remain the same.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åæœˆä»½ï¼Œæˆ‘å†™äº†å…³äºæ•°æ®å·¥ç¨‹å¸ˆçš„å´›èµ·ã€è§’è‰²ã€æŒ‘æˆ˜ã€èŒè´£ã€æ—¥å¸¸å·¥ä½œä»¥åŠå¦‚ä½•åœ¨è¿™ä¸ªé¢†åŸŸå–å¾—æˆåŠŸã€‚æ•°æ®å·¥ç¨‹é¢†åŸŸåœ¨ä¸æ–­å˜åŒ–ï¼Œä½†ä¸»è¦è¶‹åŠ¿ä¼¼ä¹ä¿æŒä¸å˜ã€‚
- en: '[](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
    [## How to Become a Data Engineer'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
    [## å¦‚ä½•æˆä¸ºæ•°æ®å·¥ç¨‹å¸ˆ'
- en: A shortcut for beginners in 2024
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2024å¹´åˆå­¦è€…çš„æ·å¾„
- en: towardsdatascience.com](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
- en: As a data engineer, I am tasked to design efficient data processes almost every
    day. So here are a few things to consider that can help us answer these questions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€åæ•°æ®å·¥ç¨‹å¸ˆï¼Œæˆ‘å‡ ä¹æ¯å¤©éƒ½éœ€è¦è®¾è®¡é«˜æ•ˆçš„æ•°æ®æµç¨‹ã€‚å› æ­¤ï¼Œè¿™é‡Œæœ‰ä¸€äº›éœ€è¦è€ƒè™‘çš„äº‹é¡¹ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬è§£ç­”è¿™äº›é—®é¢˜ã€‚
- en: Modern data engineering trends
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç°ä»£æ•°æ®å·¥ç¨‹è¶‹åŠ¿
- en: ETL vs ELT
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ETLä¸ELT
- en: Simplified data connectors and API integrations
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç®€åŒ–çš„æ•°æ®è¿æ¥å™¨å’ŒAPIé›†æˆ
- en: ETL frameworks explosion
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ETLæ¡†æ¶çš„çˆ†ç‚¸æ€§å¢é•¿
- en: Data infrastructure as code
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®åŸºç¡€è®¾æ–½å³ä»£ç 
- en: Data Mesh and decentralized data management
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®ç½‘æ ¼ä¸å»ä¸­å¿ƒåŒ–æ•°æ®ç®¡ç†
- en: Democratization of Business intelligence pipelines using AI
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ©ç”¨AIè¿›è¡Œå•†ä¸šæ™ºèƒ½ç®¡é“çš„æ°‘ä¸»åŒ–
- en: Focus on data literacy
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…³æ³¨æ•°æ®ç´ å…»
- en: ELT vs ETL
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ELTä¸ETL
- en: Popular SQL data transformation tools like **Dataform** and **DBT** made a significant
    contribution to the popularisation of the ELT approach [1]. It simply makes sense
    to perform required data transformations, such as cleansing, enrichment and extraction
    in the place where data is being stored. Often it is a data warehouse solution
    (DWH) in the central part of our infrastructure. Cloud platform leaders made DWH
    (Snowflake, BigQuery, Redshift, Firebolt) infrastructure management really simple
    and in many scenarios they will outperform and dedicated in-house infrastructure
    management team in terms of cost-effectiveness and speed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å—æ¬¢è¿çš„ SQL æ•°æ®è½¬æ¢å·¥å…·ï¼Œå¦‚**Dataform**å’Œ**DBT**ï¼Œå¯¹ ELT æ–¹æ³•çš„æ™®åŠåšå‡ºäº†é‡è¦è´¡çŒ®[1]ã€‚åœ¨å­˜å‚¨æ•°æ®çš„åœ°æ–¹æ‰§è¡Œæ‰€éœ€çš„æ•°æ®è½¬æ¢ï¼Œå¦‚æ¸…æ´—ã€ä¸°å¯Œå’Œæå–ï¼Œæ˜¾å¾—éå¸¸åˆç†ã€‚é€šå¸¸ï¼Œè¿™æ˜¯ä¸€ç§ä½äºæˆ‘ä»¬åŸºç¡€è®¾æ–½ä¸­å¿ƒçš„æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆï¼ˆDWHï¼‰ã€‚äº‘å¹³å°é¢†å¯¼è€…ä½¿
    DWHï¼ˆSnowflakeã€BigQueryã€Redshiftã€Fireboltï¼‰çš„åŸºç¡€è®¾æ–½ç®¡ç†å˜å¾—éå¸¸ç®€å•ï¼Œåœ¨è®¸å¤šåœºæ™¯ä¸­ï¼Œå®ƒä»¬åœ¨æˆæœ¬æ•ˆç›Šå’Œé€Ÿåº¦æ–¹é¢å°†ä¼˜äºä¸“é—¨çš„å†…éƒ¨åŸºç¡€è®¾æ–½ç®¡ç†å›¢é˜Ÿã€‚
- en: '![](../Images/d4fbc3d51212c640c74e34cc21f6baff.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4fbc3d51212c640c74e34cc21f6baff.png)'
- en: Data warehouse exmaple. Image by author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ä»“åº“ç¤ºä¾‹ã€‚ä½œè€…æä¾›çš„å›¾ç‰‡
- en: It also might be a datalake in the center and it depends on the type of our
    data platform and tools we use. In this case, SQL stops being an option in many
    cases making it difficult to query the data for those users who are not familiar
    with programming. Tools like Databricks, Tabular and Galaxy try to solve this
    problem and it really feels like the future. Indeed, datalakes can store all types
    of data including unstructured ones and we still need to be able to analyse these
    datasets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¹Ÿå¯èƒ½æ˜¯ä¸­å¿ƒçš„æ•°æ®æ¹–ï¼Œè¿™å–å†³äºæˆ‘ä»¬çš„æ•°æ®å¹³å°ç±»å‹å’Œä½¿ç”¨çš„å·¥å…·ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒSQL åœ¨è®¸å¤šæƒ…å†µä¸‹ä¸å†æ˜¯ä¸€ä¸ªé€‰é¡¹ï¼Œä½¿å¾—é‚£äº›ä¸ç†Ÿæ‚‰ç¼–ç¨‹çš„ç”¨æˆ·éš¾ä»¥æŸ¥è¯¢æ•°æ®ã€‚åƒ
    Databricksã€Tabular å’Œ Galaxy è¿™æ ·çš„å·¥å…·è¯•å›¾è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ„Ÿè§‰å®ƒç¡®å®æ˜¯æœªæ¥çš„å‘å±•æ–¹å‘ã€‚ç¡®å®ï¼Œæ•°æ®æ¹–å¯ä»¥å­˜å‚¨æ‰€æœ‰ç±»å‹çš„æ•°æ®ï¼ŒåŒ…æ‹¬éç»“æ„åŒ–æ•°æ®ï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦èƒ½å¤Ÿåˆ†æè¿™äº›æ•°æ®é›†ã€‚
- en: '![](../Images/121483bb3ae93ecd7fd90f7d796c3cb0.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/121483bb3ae93ecd7fd90f7d796c3cb0.png)'
- en: Datalake example. Image by author.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æ¹–ç¤ºä¾‹ã€‚ä½œè€…æä¾›çš„å›¾ç‰‡ã€‚
- en: Just imagine transactionally consistent datalake tables with point-in-time snapshot
    isolation.
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹å…·æœ‰äº‹åŠ¡ä¸€è‡´æ€§çš„ æ•°æ®æ¹–è¡¨å’Œæ—¶é—´ç‚¹å¿«ç…§éš”ç¦»ã€‚
- en: I previously wrote about it in one of my stories on Apache Iceberg table format
    [2].
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹å‰åœ¨å…³äº Apache Iceberg è¡¨æ ¼å¼çš„æ•…äº‹ä¸­å†™è¿‡è¿™æ–¹é¢çš„å†…å®¹[2]ã€‚
- en: '[](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
    [## Introduction to Apache Iceberg Tables'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
    [## Apache Iceberg è¡¨ä»‹ç»'
- en: A few Compelling Reasons to Choose Apache Iceberg for Data Lakes
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é€‰æ‹© Apache Iceberg ä½œä¸ºæ•°æ®æ¹–çš„å‡ ä¸ªæœ‰åŠ›ç†ç”±
- en: towardsdatascience.com](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
- en: Simplified data integrations
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç®€åŒ–çš„æ•°æ®é›†æˆ
- en: Managed solutions like **Fivetran** and **Stitch** were built to manage third-party
    API integrations with ease. These days many companies choose this approach to
    simplify data interactions with their external data sources. This would be the
    right way to go for data analyst teams that are not familiar with coding.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åƒ**Fivetran**å’Œ**Stitch**è¿™æ ·çš„æ‰˜ç®¡è§£å†³æ–¹æ¡ˆè¢«åˆ›å»ºä»¥è½»æ¾ç®¡ç†ç¬¬ä¸‰æ–¹ API é›†æˆã€‚å¦‚ä»Šï¼Œè®¸å¤šå…¬å¸é€‰æ‹©è¿™ç§æ–¹æ³•æ¥ç®€åŒ–ä¸å¤–éƒ¨æ•°æ®æºçš„äº’åŠ¨ã€‚è¿™å°†æ˜¯æ•°æ®åˆ†æå›¢é˜Ÿä¸­ä¸ç†Ÿæ‚‰ç¼–ç çš„äººå‘˜çš„æ­£ç¡®é€‰æ‹©ã€‚
- en: Indeed, why would we build a data connector from scratch if it already exists
    and is being managed in the cloud?
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¡®å®ï¼Œå¦‚æœæ•°æ®è¿æ¥å™¨å·²ç»å­˜åœ¨å¹¶ä¸”åœ¨äº‘ä¸­ç®¡ç†ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆè¿˜è¦ä»å¤´å¼€å§‹æ„å»ºå‘¢ï¼Ÿ
- en: The downside of this approach is itâ€™s pricing model though.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸è¿‡è¿™ç§æ–¹æ³•çš„ç¼ºç‚¹æ˜¯å…¶å®šä»·æ¨¡å‹ã€‚
- en: Very often it is row-based and might become quite expensive on an enterprise
    level of data ingestion, i.e. big data pipelines. This is where open-source alternatives
    come into play. Frameworks like **Airbyte** and **Meltano** might be an easy and
    quick solution to deploy a data source **integration** microservice.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¤šæ—¶å€™å®ƒæ˜¯åŸºäºè¡Œçš„ï¼Œå¹¶ä¸”åœ¨ä¼ä¸šçº§æ•°æ®æ‘„å–ï¼ˆå³å¤§æ•°æ®ç®¡é“ï¼‰ä¸Šå¯èƒ½å˜å¾—ç›¸å½“æ˜‚è´µã€‚è¿™å°±æ˜¯å¼€æºæ›¿ä»£æ–¹æ¡ˆå‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚åƒ**Airbyte**å’Œ**Meltano**è¿™æ ·çš„æ¡†æ¶å¯èƒ½æ˜¯éƒ¨ç½²æ•°æ®æº**é›†æˆ**å¾®æœåŠ¡çš„ç®€å•å¿«æ·è§£å†³æ–¹æ¡ˆã€‚
- en: 'If you donâ€™t have time to learn a new ETL framework you can create a simple
    data connector yourself. If you know a bit of Python it would be a trivial task.
    In one of my previous articles I wrote how easy it is to create a microservice
    that pulls data from NASA API [3]:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ²¡æœ‰æ—¶é—´å­¦ä¹ æ–°çš„ ETL æ¡†æ¶ï¼Œä½ å¯ä»¥è‡ªå·±åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®è¿æ¥å™¨ã€‚å¦‚æœä½ æ‡‚ä¸€ç‚¹ Pythonï¼Œè¿™å°†æ˜¯ä¸€ä¸ªå¾®ä¸è¶³é“çš„ä»»åŠ¡ã€‚åœ¨æˆ‘ä¹‹å‰çš„ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å†™äº†å¦‚ä½•è½»æ¾åˆ›å»ºä¸€ä¸ªä»
    NASA API æ‹‰å–æ•°æ®çš„å¾®æœåŠ¡[3]ï¼š
- en: '[](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
    [## Python for Data Engineers'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
    [## æ•°æ®å·¥ç¨‹å¸ˆçš„Python'
- en: Advanced ETL techniques for beginners
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åˆå­¦è€…çš„é«˜çº§ETLæŠ€æœ¯
- en: towardsdatascience.com](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
- en: Consider this code snippet for `app.py`
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘`app.py`ä¸­çš„è¿™æ®µä»£ç 
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It can be deployed in any cloud vendor platform and scheduled to run with the
    required frequency. Itâ€™s always a good practice to use something like **Terraform**
    to deploy our data pipeline applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå¯ä»¥éƒ¨ç½²åœ¨ä»»ä½•äº‘æœåŠ¡å•†å¹³å°ä¸Šï¼Œå¹¶æŒ‰æ‰€éœ€é¢‘ç‡è°ƒåº¦è¿è¡Œã€‚ä½¿ç”¨ç±»ä¼¼**Terraform**çš„å·¥å…·æ¥éƒ¨ç½²æˆ‘ä»¬çš„æ•°æ®ç®¡é“åº”ç”¨ç¨‹åºå§‹ç»ˆæ˜¯ä¸€ä¸ªå¥½çš„å®è·µã€‚
- en: ETL frameworks explosion
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ETLæ¡†æ¶çš„çˆ†ç‚¸æ€§å¢é•¿
- en: We can witness a â€œCambrian explosionâ€ of various ETL frameworks for data extraction
    and transformation. Itâ€™s not a surprise that many of them are open-source and
    are Python-based.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è§è¯å„ç§ETLæ¡†æ¶åœ¨æ•°æ®æå–å’Œè½¬æ¢ä¸­çš„â€œå¯’æ­¦çºªå¤§çˆ†å‘â€ã€‚è®¸å¤šæ¡†æ¶éƒ½æ˜¯å¼€æºçš„ï¼Œå¹¶ä¸”åŸºäºPythonï¼Œè¿™å¹¶ä¸ä»¤äººæƒŠè®¶ã€‚
- en: '**Luigi** [8] is one of them and it helps to create ETL pipelines. It was created
    by Spotify to manage massive data processing workloads. It has a command line
    interface and great visualization features. However, even basic ETL pipelines
    would require a certain level of Python programming skills. From my experience,
    I can tell that itâ€™s great for strict and straightforward pipelines. I find it
    particularly difficult to implement complex branching logic using Luigi but it
    works great in many scenarios.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**Luigi** [8]å°±æ˜¯å…¶ä¸­ä¹‹ä¸€ï¼Œå®ƒå¸®åŠ©åˆ›å»ºETLç®¡é“ã€‚å®ƒç”±Spotifyåˆ›å»ºï¼Œç”¨äºç®¡ç†å¤§è§„æ¨¡æ•°æ®å¤„ç†å·¥ä½œè´Ÿè½½ã€‚å®ƒå…·æœ‰å‘½ä»¤è¡Œç•Œé¢å’Œå‡ºè‰²çš„å¯è§†åŒ–åŠŸèƒ½ã€‚ç„¶è€Œï¼Œå³ä½¿æ˜¯åŸºæœ¬çš„ETLç®¡é“ä¹Ÿéœ€è¦ä¸€å®šçš„Pythonç¼–ç¨‹æŠ€èƒ½ã€‚ä»æˆ‘çš„ç»éªŒæ¥çœ‹ï¼Œå®ƒé€‚åˆä¸¥æ ¼ä¸”ç›´æ¥çš„ç®¡é“ã€‚æˆ‘å‘ç°ä½¿ç”¨Luigiå®ç°å¤æ‚çš„åˆ†æ”¯é€»è¾‘ç‰¹åˆ«å›°éš¾ï¼Œä½†å®ƒåœ¨è®¸å¤šåœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ã€‚'
- en: '**Python ETL (PETL) [9]** is one of the most widely used open-source ETL frameworks
    for straightforward data transformations. It is invaluable working with tables,
    extracting data from external data sources and performing basic ETL on data. In
    many ways, it is similar to **Pandas** but the latter has more analytics capabilities
    under the hood. PETL is great for aggregation and row-level ETL.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python ETL (PETL) [9]**æ˜¯æœ€å¹¿æ³›ä½¿ç”¨çš„å¼€æºETLæ¡†æ¶ä¹‹ä¸€ï¼Œç”¨äºç®€å•çš„æ•°æ®è½¬æ¢ã€‚åœ¨å¤„ç†è¡¨æ ¼ã€ä»å¤–éƒ¨æ•°æ®æºæå–æ•°æ®ä»¥åŠå¯¹æ•°æ®æ‰§è¡ŒåŸºæœ¬ETLæ—¶ï¼Œå®ƒéå¸¸å®è´µã€‚åœ¨è®¸å¤šæ–¹é¢ï¼Œå®ƒä¸**Pandas**ç±»ä¼¼ï¼Œä½†åè€…åœ¨åå°å…·æœ‰æ›´å¤šçš„åˆ†æåŠŸèƒ½ã€‚PETLéå¸¸é€‚åˆèšåˆå’Œè¡Œçº§ETLã€‚'
- en: '**Bonobo** [10] is another open-source lightweight data processing tool which
    is great for rapid development, automation and parallel execution of batch-processing
    data pipelines. What I like about it is that it makes it really easy to work with
    various data file formats, i.e. SQL, XML, XLS, CSV and JSON. It will be a great
    tool for those with minimal Python knowledge. Among other benefits, I like that
    it works well with semi-complex data schemas. It is ideal for simple ETL and can
    run in Docker containers (it has a Docker extension).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Bonobo** [10]æ˜¯å¦ä¸€ä¸ªå¼€æºçš„è½»é‡çº§æ•°æ®å¤„ç†å·¥å…·ï¼Œéå¸¸é€‚åˆå¿«é€Ÿå¼€å‘ã€è‡ªåŠ¨åŒ–å’Œæ‰¹å¤„ç†æ•°æ®ç®¡é“çš„å¹¶è¡Œæ‰§è¡Œã€‚æˆ‘å–œæ¬¢å®ƒçš„ä¸€ç‚¹æ˜¯ï¼Œå®ƒè®©å¤„ç†å„ç§æ•°æ®æ–‡ä»¶æ ¼å¼å˜å¾—éå¸¸ç®€å•ï¼Œä¾‹å¦‚SQLã€XMLã€XLSã€CSVå’ŒJSONã€‚å¯¹äºé‚£äº›PythonçŸ¥è¯†æœ‰é™çš„äººæ¥è¯´ï¼Œå®ƒå°†æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å·¥å…·ã€‚åœ¨å…¶ä»–å¥½å¤„ä¸­ï¼Œæˆ‘å–œæ¬¢å®ƒå¯¹åŠå¤æ‚æ•°æ®æ¨¡å¼çš„è‰¯å¥½æ”¯æŒã€‚å®ƒéå¸¸é€‚åˆç®€å•çš„ETLï¼Œå¹¶ä¸”å¯ä»¥åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œï¼ˆå®ƒæœ‰ä¸€ä¸ªDockeræ‰©å±•ï¼‰ã€‚'
- en: '**Pandas** is an absolute beast in the world of data and there is no need to
    cover itâ€™s capabilities in this story. Itâ€™s worth mentioning that its data frame
    transformations have been included in one of the basic methods of data loading
    for many modern data warehouses. Consider this data loading sample into the BigQuery
    data warehouse solution:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pandas**åœ¨æ•°æ®é¢†åŸŸä¸­ç»å¯¹æ˜¯ä¸€ä¸ªå·¨å¤´ï¼Œåœ¨è¿™ä¸ªæ•…äº‹ä¸­æ²¡æœ‰å¿…è¦è¯¦ç»†ä»‹ç»å®ƒçš„èƒ½åŠ›ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œå®ƒçš„æ•°æ®æ¡†æ¶è½¬æ¢å·²è¢«çº³å…¥è®¸å¤šç°ä»£æ•°æ®ä»“åº“çš„åŸºæœ¬æ•°æ®åŠ è½½æ–¹æ³•ä¹‹ä¸€ã€‚è€ƒè™‘å°†æ•°æ®åŠ è½½åˆ°BigQueryæ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆä¸­çš„ç¤ºä¾‹ï¼š'
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Apache Airflow**, for example, is not an ETL tool per se but it helps to
    organize our ETL pipelines into a nice visualization of dependency graphs (DAGs)
    to describe the relationships between tasks. Typical Airflow architecture includes
    a schduler based on metadata, executors, workers and tasks.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œ**Apache Airflow**å¹¶ä¸æ˜¯ä¸€ä¸ªETLå·¥å…·ï¼Œä½†å®ƒæœ‰åŠ©äºå°†æˆ‘ä»¬çš„ETLç®¡é“ç»„ç»‡æˆä¾èµ–å…³ç³»å›¾ï¼ˆDAGsï¼‰çš„å¯è§†åŒ–ï¼Œä»¥æè¿°ä»»åŠ¡ä¹‹é—´çš„å…³ç³»ã€‚å…¸å‹çš„Airflowæ¶æ„åŒ…æ‹¬åŸºäºå…ƒæ•°æ®çš„è°ƒåº¦å™¨ã€æ‰§è¡Œå™¨ã€å·¥ä½œèŠ‚ç‚¹å’Œä»»åŠ¡ã€‚
- en: For example, we can run ml_engine_training_op after we export data into the
    cloud storage (bq_export_op) and make this workflow run daily or weekly.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å°†æ•°æ®å¯¼å‡ºåˆ°äº‘å­˜å‚¨ï¼ˆbq_export_opï¼‰åè¿è¡Œml_engine_training_opï¼Œå¹¶ä½¿æ­¤å·¥ä½œæµæ¯æ—¥æˆ–æ¯å‘¨è¿è¡Œã€‚
- en: '![](../Images/137358971d4273ca60da3554c13fd586.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/137358971d4273ca60da3554c13fd586.png)'
- en: ML model training using Airflow. Image by author.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Airflow è®­ç»ƒ ML æ¨¡å‹ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: Consider this example below.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·è€ƒè™‘ä¸‹é¢çš„è¿™ä¸ªä¾‹å­ã€‚
- en: It creates a simple data pipeline graph to export data into a cloud storage
    bucket and then trains the ML model using MLEngineTrainingOperator.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å®ƒåˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„æ•°æ®ç®¡é“å›¾ï¼Œå°†æ•°æ®å¯¼å‡ºåˆ°äº‘å­˜å‚¨æ¡¶ä¸­ï¼Œç„¶åä½¿ç”¨ MLEngineTrainingOperator è®­ç»ƒ ML æ¨¡å‹ã€‚
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bubbles** [11] is another open-source tool for ETL in the Python world. Itâ€™s
    great for rapid development and I like how it works with metadata to describe
    data pipelines. The creators of Bubbles call it an â€œabstract frameworkâ€ and say
    that it can be used from many other programming languages, not exclusively from
    Python.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**Bubbles** [11] æ˜¯å¦ä¸€ä¸ªç”¨äº Python ä¸–ç•Œä¸­ ETL çš„å¼€æºå·¥å…·ã€‚å®ƒéå¸¸é€‚åˆå¿«é€Ÿå¼€å‘ï¼Œæˆ‘å–œæ¬¢å®ƒå¦‚ä½•ä½¿ç”¨å…ƒæ•°æ®æ¥æè¿°æ•°æ®ç®¡é“ã€‚Bubbles
    çš„åˆ›å»ºè€…ç§°å…¶ä¸ºâ€œæŠ½è±¡æ¡†æ¶â€ï¼Œå¹¶è¡¨ç¤ºå®ƒå¯ä»¥ä»è®¸å¤šå…¶ä»–ç¼–ç¨‹è¯­è¨€ä¸­ä½¿ç”¨ï¼Œè€Œä¸ä»…ä»…æ˜¯ Pythonã€‚'
- en: There are many other tools with more specific applications, i.e. extracting
    data from web pages (PyQuery, BeautifulSoup, etc.) and parallel data processing.
    It can be a topic for another story but I wrote about some of them before, i.e.
    `joblib` library [12]
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰è®¸å¤šå…¶ä»–å·¥å…·å…·æœ‰æ›´å…·ä½“çš„åº”ç”¨ï¼Œä¾‹å¦‚ä»ç½‘é¡µä¸­æå–æ•°æ®ï¼ˆPyQueryã€BeautifulSoup ç­‰ï¼‰å’Œå¹¶è¡Œæ•°æ®å¤„ç†ã€‚è¿™å¯ä»¥æ˜¯å¦ä¸€ä¸ªè¯é¢˜ï¼Œä½†æˆ‘ä¹‹å‰å†™è¿‡ä¸€äº›ç›¸å…³å†…å®¹ï¼Œä¾‹å¦‚
    `joblib` åº“ [12]ã€‚
- en: Data infrastructure as code
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®åŸºç¡€è®¾æ–½å³ä»£ç 
- en: '**Infrastructure as code** (IaC) is a popular and very functional approach
    for **managing data platform resources**. Even for data, it is pretty much a standard
    right now, and it definitely looks great on your CV telling your potential employers
    that you are familiar with DevOps standards. Using tools like Terraform (platform
    agnostic) and CloudFormation we can integrate our development work and deployments
    (operations) with ease.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**åŸºç¡€è®¾æ–½å³ä»£ç **ï¼ˆIaCï¼‰æ˜¯ä¸€ç§æµè¡Œä¸”éå¸¸å®ç”¨çš„æ–¹æ³•ï¼Œç”¨äº**ç®¡ç†æ•°æ®å¹³å°èµ„æº**ã€‚å³ä½¿æ˜¯æ•°æ®æ–¹é¢ï¼Œç›®å‰è¿™å‡ ä¹å·²ç»æˆä¸ºæ ‡å‡†ï¼Œè€Œä¸”åœ¨ç®€å†ä¸Šæåˆ°ä½ ç†Ÿæ‚‰
    DevOps æ ‡å‡†ç»å¯¹ä¼šæ˜¾å¾—å¾ˆæ£’ã€‚ä½¿ç”¨åƒ Terraformï¼ˆå¹³å°æ— å…³ï¼‰å’Œ CloudFormation è¿™æ ·çš„å·¥å…·ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°å°†æˆ‘ä»¬çš„å¼€å‘å·¥ä½œå’Œéƒ¨ç½²ï¼ˆè¿ç»´ï¼‰è¿›è¡Œé›†æˆã€‚'
- en: In general, we would want to have staging and production data environments for
    our data pipelines. It helps to test our pipelines and facilitate collaboration
    between teams.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸ºæ•°æ®ç®¡é“è®¾ç½®æµ‹è¯•ç¯å¢ƒå’Œç”Ÿäº§ç¯å¢ƒã€‚è¿™æœ‰åŠ©äºæµ‹è¯•æˆ‘ä»¬çš„ç®¡é“ï¼Œå¹¶ä¿ƒè¿›å›¢é˜Ÿä¹‹é—´çš„åä½œã€‚
- en: Consider this diagram below. It explains how data environments work.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æŸ¥çœ‹ä¸‹é¢çš„å›¾è¡¨ã€‚å®ƒè§£é‡Šäº†æ•°æ®ç¯å¢ƒçš„å·¥ä½œåŸç†ã€‚
- en: '![](../Images/75b7d0ef1c9e75fbc698ea6d609ab4c1.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75b7d0ef1c9e75fbc698ea6d609ab4c1.png)'
- en: Data environments. Image by author.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç¯å¢ƒã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: Often we might need an extra sandbox for testing purposes or to run data transformation
    unit tests when our ETL services trigger CI/CD workflows.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç»å¸¸éœ€è¦ä¸€ä¸ªé¢å¤–çš„æ²™ç®±æ¥è¿›è¡Œæµ‹è¯•ï¼Œæˆ–åœ¨ ETL æœåŠ¡è§¦å‘ CI/CD å·¥ä½œæµæ—¶è¿è¡Œæ•°æ®è½¬æ¢å•å…ƒæµ‹è¯•ã€‚
- en: 'I previously wrote about it here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹å‰åœ¨è¿™é‡Œå†™è¿‡ç›¸å…³å†…å®¹ï¼š
- en: '[](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
    [## Infrastructure as Code for Beginners'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
    [## åˆå­¦è€…çš„åŸºç¡€è®¾æ–½å³ä»£ç '
- en: Deploy Data Pipelines like a pro with these templates
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åƒä¸“ä¸šäººå£«ä¸€æ ·ä½¿ç”¨è¿™äº›æ¨¡æ¿éƒ¨ç½²æ•°æ®ç®¡é“
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: levelup.gitconnected.com](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
- en: Using AWS CloudFormation template files we can describe required resources and
    their dependencies so we can launch and configure them together as a single stack.
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ AWS CloudFormation æ¨¡æ¿æ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥æè¿°æ‰€éœ€çš„èµ„æºåŠå…¶ä¾èµ–å…³ç³»ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬ä½œä¸ºä¸€ä¸ªæ•´ä½“å †æ ˆä¸€èµ·å¯åŠ¨å’Œé…ç½®ã€‚
- en: If you are a **data professional** this approach will definitely help working
    with different data environments and replicate data platform resources faster
    and more consistently without errors.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ˜¯ä¸€ä½**æ•°æ®ä¸“å®¶**ï¼Œè¿™ç§æ–¹æ³•è‚¯å®šä¼šå¸®åŠ©ä½ æ›´å¥½åœ°å¤„ç†ä¸åŒçš„æ•°æ®ç¯å¢ƒï¼Œå¹¶æ›´å¿«é€Ÿã€æ›´ä¸€è‡´åœ°å¤åˆ¶æ•°æ®å¹³å°èµ„æºè€Œä¸å‡ºé”™ã€‚
- en: The problem is that many data practitioners are not familiar with IaC and it
    creates a lot of errors during the development process.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: é—®é¢˜åœ¨äºè®¸å¤šæ•°æ®ä»ä¸šè€…å¯¹ IaC å¹¶ä¸ç†Ÿæ‚‰ï¼Œè¿™åœ¨å¼€å‘è¿‡ç¨‹ä¸­ä¼šäº§ç”Ÿå¾ˆå¤šé”™è¯¯ã€‚
- en: Data Mesh and decentralized data management
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®ç½‘æ ¼å’Œå»ä¸­å¿ƒåŒ–æ•°æ®ç®¡ç†
- en: Data space has significantly evolved during the last decade and now we have
    lots of data tools and frameworks. **Data Mesh** defines the state when we have
    different data domains (company departments) with their own teams and shared data
    resources. Each team has their own goals, KPIs, data roles and responsibilities.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç©ºé—´åœ¨è¿‡å»åå¹´é‡Œå‘ç”Ÿäº†æ˜¾è‘—å˜åŒ–ï¼Œç°åœ¨æˆ‘ä»¬æœ‰å¾ˆå¤šæ•°æ®å·¥å…·å’Œæ¡†æ¶ã€‚**æ•°æ®ç½‘æ ¼**å®šä¹‰äº†è¿™æ ·ä¸€ç§çŠ¶æ€ï¼šæˆ‘ä»¬æ‹¥æœ‰ä¸åŒçš„æ•°æ®é¢†åŸŸï¼ˆå…¬å¸éƒ¨é—¨ï¼‰ï¼Œæ¯ä¸ªé¢†åŸŸéƒ½æœ‰è‡ªå·±çš„å›¢é˜Ÿå’Œå…±äº«çš„æ•°æ®èµ„æºã€‚æ¯ä¸ªå›¢é˜Ÿéƒ½æœ‰è‡ªå·±çš„ç›®æ ‡ã€å…³é”®ç»©æ•ˆæŒ‡æ ‡ï¼ˆKPIï¼‰ã€æ•°æ®è§’è‰²å’ŒèŒè´£ã€‚
- en: For a long period of time, data bureaucracy has been a real pain for many companies.
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é•¿æœŸä»¥æ¥ï¼Œæ•°æ®å®˜åƒšä¸»ä¹‰ä¸€ç›´æ˜¯è®¸å¤šå…¬å¸çš„çœŸæ­£ç—›ç‚¹ã€‚
- en: This data platform type [4] might seem a bit chaotic but it was meant to become
    a successful and efficient choice for companies where decentralization enables
    different teams to access cross-domain datasets and run analytics or ETL tasks
    on their own.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ•°æ®å¹³å°ç±»å‹[4]å¯èƒ½çœ‹èµ·æ¥æœ‰äº›æ··ä¹±ï¼Œä½†å®ƒæ—¨åœ¨æˆä¸ºä¸€ä¸ªæˆåŠŸä¸”é«˜æ•ˆçš„é€‰æ‹©ï¼Œå°¤å…¶é€‚ç”¨äºå»ä¸­å¿ƒåŒ–çš„å…¬å¸ï¼Œåœ¨è¿™ç§ç»“æ„ä¸‹ï¼Œä¸åŒçš„å›¢é˜Ÿå¯ä»¥è‡ªè¡Œè®¿é—®è·¨é¢†åŸŸçš„æ•°æ®é›†å¹¶æ‰§è¡Œåˆ†ææˆ–ETLä»»åŠ¡ã€‚
- en: Indeed, Snowflake might be your favourite data warehouse solution if you are
    a data analyst and not familiar with Spark. However, often itâ€™s a trivial problem
    when you might want to read datalake data without data engineering help. In this
    scenario, a bunch of metadata records on datasets could be extremely useful and
    thatâ€™s why Data Mesh is so successful.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: çš„ç¡®ï¼Œå¦‚æœä½ æ˜¯æ•°æ®åˆ†æå¸ˆè€Œä¸ç†Ÿæ‚‰Sparkï¼ŒSnowflakeå¯èƒ½æ˜¯ä½ æœ€å–œæ¬¢çš„æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå½“ä½ å¯èƒ½å¸Œæœ›åœ¨æ²¡æœ‰æ•°æ®å·¥ç¨‹å¸®åŠ©çš„æƒ…å†µä¸‹è¯»å–æ•°æ®æ¹–æ•°æ®æ—¶ï¼Œé€šå¸¸è¿™ä¼šæ˜¯ä¸€ä¸ªå¾®ä¸è¶³é“çš„é—®é¢˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¤§é‡çš„æ•°æ®é›†å…ƒæ•°æ®è®°å½•å¯èƒ½éå¸¸æœ‰ç”¨ï¼Œè¿™ä¹Ÿæ˜¯æ•°æ®ç½‘æ ¼å¦‚æ­¤æˆåŠŸçš„åŸå› ã€‚
- en: It enables users with knowledge about data, its origins and how other teams
    can make the best of those datasets they werenâ€™t previously aware of.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—ç”¨æˆ·äº†è§£æ•°æ®åŠå…¶æ¥æºï¼Œå¹¶äº†è§£å…¶ä»–å›¢é˜Ÿå¦‚ä½•å……åˆ†åˆ©ç”¨ä»–ä»¬ä¹‹å‰ä¸çŸ¥é“çš„æ•°æ®é›†ã€‚
- en: Sometimes datasets and data source connections become very intricate and it
    is always a good practice to have a single-source-of-truth data silo or repository
    with metadata and dataset descriptions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶æ•°æ®é›†å’Œæ•°æ®æºè¿æ¥å˜å¾—éå¸¸å¤æ‚ï¼Œå› æ­¤å§‹ç»ˆä¿æŒä¸€ä¸ªåŒ…å«å…ƒæ•°æ®å’Œæ•°æ®é›†æè¿°çš„å•ä¸€çœŸå®æ•°æ®ä»“åº“æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚
- en: In one of my previous stories [5] I wrote about the role of SQL as a unified
    querying language for teams and data. Indeed, it analytical, self-descriptive
    and come be even dynamic which makes it a perfect tool for all data users.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä¹‹å‰çš„ä¸€ç¯‡æ•…äº‹[5]ä¸­ï¼Œæˆ‘å†™åˆ°äº†SQLä½œä¸ºå›¢é˜Ÿå’Œæ•°æ®çš„ç»Ÿä¸€æŸ¥è¯¢è¯­è¨€çš„ä½œç”¨ã€‚ç¡®å®ï¼Œå®ƒå…·æœ‰åˆ†ææ€§ã€è‡ªæè¿°æ€§ï¼Œç”šè‡³å¯ä»¥æ˜¯åŠ¨æ€çš„ï¼Œè¿™ä½¿å¾—å®ƒæˆä¸ºæ‰€æœ‰æ•°æ®ç”¨æˆ·çš„å®Œç¾å·¥å…·ã€‚
- en: '**Often it all turns into a big mes(s/h)**'
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**è¿™å¾€å¾€å˜æˆä¸€å›¢ç³Ÿ**'
- en: This fact makes SQL-based templating engines like DBT, Jinja and Dataform very
    popular. **Just imagine you have an SQL-like platform where all datasets and their
    transformations are described and defined thoroughly [6].**
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€äº‹å®ä½¿å¾—åŸºäºSQLçš„æ¨¡æ¿å¼•æ“å¦‚DBTã€Jinjaå’ŒDataforméå¸¸å—æ¬¢è¿ã€‚**è¯•æƒ³ä¸€ä¸‹ï¼Œä½ æ‹¥æœ‰ä¸€ä¸ªç±»ä¼¼SQLçš„å¹³å°ï¼Œå…¶ä¸­æ‰€æœ‰æ•°æ®é›†åŠå…¶è½¬æ¢éƒ½è¢«å½»åº•æè¿°å’Œå®šä¹‰[6]ã€‚**
- en: '![](../Images/0baeff3ede9d729968e3c27de50bdcaf.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0baeff3ede9d729968e3c27de50bdcaf.png)'
- en: Dataformâ€™s dependency graph and metadata. Image by author.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Dataformçš„ä¾èµ–å›¾å’Œå…ƒæ•°æ®ã€‚å›¾ç‰‡æ¥æºï¼šä½œè€…ã€‚
- en: It might be a big challenge to understand how data teams relate to data sources
    and schemas. Very often it is all tangled in spaghetti of dataset dependencies
    and ETL transformations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£æ•°æ®å›¢é˜Ÿå¦‚ä½•ä¸æ•°æ®æºå’Œæ¨¡å¼å…³è”å¯èƒ½æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æŒ‘æˆ˜ã€‚é€šå¸¸ï¼Œè¿™äº›éƒ½çº ç¼ åœ¨æ•°æ®é›†ä¾èµ–å…³ç³»å’ŒETLè½¬æ¢çš„å¤æ‚ç½‘ç»œä¸­ã€‚
- en: Data engineering plays a critical role in mentoring, improving data literacy
    and empowering the rest of the company with state-of-the-art data processing techniques
    and best practices.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®å·¥ç¨‹åœ¨æŒ‡å¯¼ã€æå‡æ•°æ®ç´ å…»ä»¥åŠé€šè¿‡æœ€å…ˆè¿›çš„æ•°æ®å¤„ç†æŠ€æœ¯å’Œæœ€ä½³å®è·µæ¥èµ‹èƒ½å…¬å¸å…¶ä»–éƒ¨é—¨æ–¹é¢å‘æŒ¥äº†å…³é”®ä½œç”¨ã€‚
- en: Democratization of Business Intelligence pipelines using AI
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨AIè¿›è¡Œå•†ä¸šæ™ºèƒ½ç®¡é“çš„æ°‘ä¸»åŒ–
- en: Improving data accessibility has always been a popular topic in the data space
    but it is interesting to see how the whole data pipeline design process is becoming
    increasingly accessible to teams that werenâ€™t familiar with data before. Now almost
    every department can utilize built-in AI capabilities to create complex BI transformations
    on data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¹å–„æ•°æ®å¯è®¿é—®æ€§ä¸€ç›´æ˜¯æ•°æ®é¢†åŸŸçš„çƒ­é—¨è¯é¢˜ï¼Œä½†æœ‰è¶£çš„æ˜¯ï¼Œæ•´ä¸ªæ•°æ®ç®¡é“è®¾è®¡è¿‡ç¨‹æ­£å˜å¾—è¶Šæ¥è¶Šå®¹æ˜“è¢«é‚£äº›ä¹‹å‰ä¸ç†Ÿæ‚‰æ•°æ®çš„å›¢é˜Ÿæ‰€æ¥è§¦ã€‚ç°åœ¨ï¼Œå‡ ä¹æ¯ä¸ªéƒ¨é—¨éƒ½å¯ä»¥åˆ©ç”¨å†…ç½®çš„AIèƒ½åŠ›ï¼Œåœ¨æ•°æ®ä¸Šåˆ›å»ºå¤æ‚çš„å•†ä¸šæ™ºèƒ½è½¬æ¢ã€‚
- en: All they need is to describe what they want BI-wise in their own words
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä»–ä»¬æ‰€éœ€è¦çš„åªæ˜¯ç”¨è‡ªå·±çš„è¯æè¿°ä»–ä»¬åœ¨å•†ä¸šæ™ºèƒ½æ–¹é¢çš„éœ€æ±‚ã€‚
- en: For example, BI tools like **Thoughspot** use AI with an intuitive â€œGoogle-like
    search interfaceâ€ [7] to gain insights from data stored in any modern DWH solution
    such as Google Big Query, Redshift, Snowflake or Databricks.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåƒ**Thoughspot**è¿™æ ·çš„ BI å·¥å…·ä½¿ç”¨å…·æœ‰ç›´è§‚â€œGoogle é£æ ¼æœç´¢ç•Œé¢â€çš„ AI [7] æ¥ä»å­˜å‚¨åœ¨ä»»ä½•ç°ä»£æ•°æ®ä»“åº“è§£å†³æ–¹æ¡ˆï¼ˆå¦‚
    Google Big Queryã€Redshiftã€Snowflake æˆ– Databricksï¼‰ä¸­çš„æ•°æ®ä¸­è·å¾—æ´å¯Ÿã€‚
- en: Modern Data Stack includes BI tools that help with data modelling and visualization.
    Many of them already have these built-in AI capabilities to gain data insights
    faster based on user behaviour.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ç°ä»£æ•°æ®æ ˆåŒ…æ‹¬å¸®åŠ©æ•°æ®å»ºæ¨¡å’Œå¯è§†åŒ–çš„ BI å·¥å…·ã€‚è®¸å¤šå·¥å…·å·²ç»å…·å¤‡äº†è¿™äº›å†…ç½®çš„ AI åŠŸèƒ½ï¼Œä»¥æ ¹æ®ç”¨æˆ·è¡Œä¸ºæ›´å¿«åœ°è·å¾—æ•°æ®æ´å¯Ÿã€‚
- en: I believe itâ€™s a fairly easy task to integrate GPT and BI. In the next couple
    of years, we will see many new products using this tech.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç›¸ä¿¡å°† GPT ä¸ BI é›†æˆæ˜¯ä¸€é¡¹ç›¸å½“ç®€å•çš„ä»»åŠ¡ã€‚åœ¨æ¥ä¸‹æ¥çš„å‡ å¹´ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°è®¸å¤šæ–°äº§å“ä½¿ç”¨è¿™é¡¹æŠ€æœ¯ã€‚
- en: GPT can pre-process text data to generate a SQL query that understands your
    intent and answers your question.
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT å¯ä»¥é¢„å¤„ç†æ–‡æœ¬æ•°æ®ï¼Œä»¥ç”Ÿæˆç†è§£æ‚¨çš„æ„å›¾å¹¶å›ç­”æ‚¨çš„é—®é¢˜çš„ SQL æŸ¥è¯¢ã€‚
- en: Conclusion
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this article, I tried to give a very high-level overview of major data trends
    that affect data engineering role these days. Data Mesh and templated SQL with
    dependency graphs to facilitate data literacy democratized the whole analytics
    process. Advanced data pipelines with intricate ETL techniques and transformations
    can be transparent for everyone in the organisation now. Data pipelines are becoming
    increasingly accessible for other teams and they donâ€™t need to know programming
    to learn and understand the complexity of ETL. Data Mesh and metadata help to
    solve this problem. From my experience, I can tell that I keep seeing more and
    more people learning SQL to contribute to the transformation layer. Companies
    born during the â€œadvanced data analyticsâ€ age have the luxury of easy access to
    cloud vendor products and their managed services. It definitely helps to acquire
    the required data skills and improve them to gain a competitive advantage.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘è¯•å›¾ç»™å‡ºä¸€ä¸ªå…³äºå½“å‰æ•°æ®å·¥ç¨‹è§’è‰²æ‰€é¢ä¸´çš„ä¸»è¦æ•°æ®è¶‹åŠ¿çš„**é«˜çº§æ¦‚è¿°**ã€‚æ•°æ®ç½‘æ ¼å’Œå¸¦æœ‰ä¾èµ–å…³ç³»å›¾çš„æ¨¡æ¿åŒ– SQL ä½¿æ•°æ®ç´ å…»çš„æ™®åŠæˆä¸ºå¯èƒ½ï¼Œä»è€Œä½¿æ•´ä¸ªåˆ†æè¿‡ç¨‹æ°‘ä¸»åŒ–ã€‚å…ˆè¿›çš„æ•°æ®ç®¡é“ä»¥åŠå¤æ‚çš„
    ETL æŠ€æœ¯å’Œè½¬æ¢ç°åœ¨å¯¹ç»„ç»‡ä¸­çš„æ¯ä¸ªäººéƒ½æ˜¯é€æ˜çš„ã€‚æ•°æ®ç®¡é“æ­£å˜å¾—è¶Šæ¥è¶Šæ˜“äºå…¶ä»–å›¢é˜Ÿè®¿é—®ï¼Œä»–ä»¬ä¸éœ€è¦äº†è§£ç¼–ç¨‹å°±èƒ½å­¦ä¹ å’Œç†è§£ ETL çš„å¤æ‚æ€§ã€‚æ•°æ®ç½‘æ ¼å’Œå…ƒæ•°æ®æœ‰åŠ©äºè§£å†³è¿™ä¸ªé—®é¢˜ã€‚ä»æˆ‘çš„ç»éªŒæ¥çœ‹ï¼Œæˆ‘å‘ç°è¶Šæ¥è¶Šå¤šçš„äººå­¦ä¹ 
    SQL ä»¥å‚ä¸è½¬å‹å±‚ã€‚è¯ç”Ÿäºâ€œé«˜çº§æ•°æ®åˆ†æâ€æ—¶ä»£çš„å…¬å¸äº«æœ‰è½»æ¾è®¿é—®äº‘ä¾›åº”å•†äº§å“åŠå…¶æ‰˜ç®¡æœåŠ¡çš„å¥¢ä¾ˆã€‚å®ƒç¡®å®æœ‰åŠ©äºè·å¾—æ‰€éœ€çš„æ•°æ®æŠ€èƒ½å¹¶åŠ ä»¥æå‡ï¼Œä»¥è·å¾—ç«äº‰ä¼˜åŠ¿ã€‚
- en: Recommended read
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¨èé˜…è¯»
- en: '[1] [https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3](https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3](https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3)'
- en: '[2] [https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009](/introduction-to-apache-iceberg-tables-a791f1758009)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009](/introduction-to-apache-iceberg-tables-a791f1758009)'
- en: '[3] [https://towardsdatascience.com/python-for-data-engineers-f3d5db59b6dd](/python-for-data-engineers-f3d5db59b6dd)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://towardsdatascience.com/python-for-data-engineers-f3d5db59b6dd](/python-for-data-engineers-f3d5db59b6dd)'
- en: '[4] [https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7](https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7](https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7)'
- en: '[5] [https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488](https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488](https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488)'
- en: '[6] [https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365](https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365](https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365)'
- en: '[7] [https://docs.thoughtspot.com/cloud/latest/search-sage](https://docs.thoughtspot.com/cloud/latest/search-sage)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [https://docs.thoughtspot.com/cloud/latest/search-sage](https://docs.thoughtspot.com/cloud/latest/search-sage)'
- en: '[8] [https://github.com/spotify/luigi](https://github.com/spotify/luigi)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [https://github.com/spotify/luigi](https://github.com/spotify/luigi)'
- en: '[9] [https://petl.readthedocs.io/en/stable/](https://petl.readthedocs.io/en/stable/)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] [https://petl.readthedocs.io/en/stable/](https://petl.readthedocs.io/en/stable/)'
- en: '[10] [https://www.bonobo-project.org](https://www.bonobo-project.org)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] [https://www.bonobo-project.org](https://www.bonobo-project.org)'
- en: '[11] [http://bubbles.databrewery.org/](http://bubbles.databrewery.org/)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] [http://bubbles.databrewery.org/](http://bubbles.databrewery.org/)'
- en: '[12] [https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2](https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] [https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2](https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2)'
