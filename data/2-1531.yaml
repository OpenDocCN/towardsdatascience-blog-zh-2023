- en: Modern Data Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代数据工程
- en: 原文：[https://towardsdatascience.com/modern-data-engineering-e202776fb9a9](https://towardsdatascience.com/modern-data-engineering-e202776fb9a9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/modern-data-engineering-e202776fb9a9](https://towardsdatascience.com/modern-data-engineering-e202776fb9a9)
- en: Platform Specific Tools and Advanced Techniques
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平台特定工具和高级技术
- en: '[](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[![💡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    [💡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[![💡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    [💡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----e202776fb9a9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    ·12 min read·Nov 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e202776fb9a9--------------------------------)
    ·阅读时间12分钟·2023年11月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c4dcaf0e3ae7f465c2b949ddc1ac7edf.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4dcaf0e3ae7f465c2b949ddc1ac7edf.png)'
- en: Photo by [Christopher Burns](https://unsplash.com/@christopher__burns?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Christopher Burns](https://unsplash.com/@christopher__burns?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The modern data ecosystem keeps evolving and new data tools emerge now and then.
    In this article, I want to talk about crucial things that affect data engineers.
    We will discuss how to use this knowledge to power advanced analytics pipelines
    and operational excellence.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现代数据生态系统不断演变，新数据工具时不时出现。在这篇文章中，我想谈谈影响数据工程师的关键因素。我们将讨论如何利用这些知识来推动先进的分析管道和卓越的运营。
- en: 'I’d like to discuss some popular Data engineering questions:'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我想讨论一些流行的数据工程问题：
- en: Modern data engineering (DE). What is it?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代数据工程（DE）。它是什么？
- en: Does your DE work well enough to fuel advanced data pipelines and Business intelligence
    (BI)?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的数据工程（DE）是否足够好，能为先进的数据管道和商业智能（BI）提供支持？
- en: Are your data pipelines efficient?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的数据管道是否高效？
- en: What is required from the technological point of view to enable operational
    excellence?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从技术角度来看，实现卓越运营需要什么？
- en: Back in October, I wrote about the rise of the Data Engineer, the role, its
    challenges, responsibilities, daily routine and how to become successful in this
    field. The data engineering landscape is constantly changing but major trends
    seem to remain the same.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在十月份，我写了关于数据工程师的崛起、角色、挑战、职责、日常工作以及如何在这个领域取得成功。数据工程领域在不断变化，但主要趋势似乎保持不变。
- en: '[](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
    [## How to Become a Data Engineer'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
    [## 如何成为数据工程师'
- en: A shortcut for beginners in 2024
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2024年初学者的捷径
- en: towardsdatascience.com](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-become-a-data-engineer-c0319cb226c2?source=post_page-----e202776fb9a9--------------------------------)
- en: As a data engineer, I am tasked to design efficient data processes almost every
    day. So here are a few things to consider that can help us answer these questions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名数据工程师，我几乎每天都需要设计高效的数据流程。因此，这里有一些需要考虑的事项，可以帮助我们解答这些问题。
- en: Modern data engineering trends
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代数据工程趋势
- en: ETL vs ELT
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ETL与ELT
- en: Simplified data connectors and API integrations
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简化的数据连接器和API集成
- en: ETL frameworks explosion
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ETL框架的爆炸性增长
- en: Data infrastructure as code
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据基础设施即代码
- en: Data Mesh and decentralized data management
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据网格与去中心化数据管理
- en: Democratization of Business intelligence pipelines using AI
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用AI进行商业智能管道的民主化
- en: Focus on data literacy
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关注数据素养
- en: ELT vs ETL
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ELT与ETL
- en: Popular SQL data transformation tools like **Dataform** and **DBT** made a significant
    contribution to the popularisation of the ELT approach [1]. It simply makes sense
    to perform required data transformations, such as cleansing, enrichment and extraction
    in the place where data is being stored. Often it is a data warehouse solution
    (DWH) in the central part of our infrastructure. Cloud platform leaders made DWH
    (Snowflake, BigQuery, Redshift, Firebolt) infrastructure management really simple
    and in many scenarios they will outperform and dedicated in-house infrastructure
    management team in terms of cost-effectiveness and speed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 受欢迎的 SQL 数据转换工具，如**Dataform**和**DBT**，对 ELT 方法的普及做出了重要贡献[1]。在存储数据的地方执行所需的数据转换，如清洗、丰富和提取，显得非常合理。通常，这是一种位于我们基础设施中心的数据仓库解决方案（DWH）。云平台领导者使
    DWH（Snowflake、BigQuery、Redshift、Firebolt）的基础设施管理变得非常简单，在许多场景中，它们在成本效益和速度方面将优于专门的内部基础设施管理团队。
- en: '![](../Images/d4fbc3d51212c640c74e34cc21f6baff.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4fbc3d51212c640c74e34cc21f6baff.png)'
- en: Data warehouse exmaple. Image by author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据仓库示例。作者提供的图片
- en: It also might be a datalake in the center and it depends on the type of our
    data platform and tools we use. In this case, SQL stops being an option in many
    cases making it difficult to query the data for those users who are not familiar
    with programming. Tools like Databricks, Tabular and Galaxy try to solve this
    problem and it really feels like the future. Indeed, datalakes can store all types
    of data including unstructured ones and we still need to be able to analyse these
    datasets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可能是中心的数据湖，这取决于我们的数据平台类型和使用的工具。在这种情况下，SQL 在许多情况下不再是一个选项，使得那些不熟悉编程的用户难以查询数据。像
    Databricks、Tabular 和 Galaxy 这样的工具试图解决这个问题，感觉它确实是未来的发展方向。确实，数据湖可以存储所有类型的数据，包括非结构化数据，我们仍然需要能够分析这些数据集。
- en: '![](../Images/121483bb3ae93ecd7fd90f7d796c3cb0.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/121483bb3ae93ecd7fd90f7d796c3cb0.png)'
- en: Datalake example. Image by author.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖示例。作者提供的图片。
- en: Just imagine transactionally consistent datalake tables with point-in-time snapshot
    isolation.
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 想象一下具有事务一致性的 数据湖表和时间点快照隔离。
- en: I previously wrote about it in one of my stories on Apache Iceberg table format
    [2].
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前在关于 Apache Iceberg 表格式的故事中写过这方面的内容[2]。
- en: '[](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
    [## Introduction to Apache Iceberg Tables'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
    [## Apache Iceberg 表介绍'
- en: A few Compelling Reasons to Choose Apache Iceberg for Data Lakes
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择 Apache Iceberg 作为数据湖的几个有力理由
- en: towardsdatascience.com](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/introduction-to-apache-iceberg-tables-a791f1758009?source=post_page-----e202776fb9a9--------------------------------)
- en: Simplified data integrations
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简化的数据集成
- en: Managed solutions like **Fivetran** and **Stitch** were built to manage third-party
    API integrations with ease. These days many companies choose this approach to
    simplify data interactions with their external data sources. This would be the
    right way to go for data analyst teams that are not familiar with coding.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 像**Fivetran**和**Stitch**这样的托管解决方案被创建以轻松管理第三方 API 集成。如今，许多公司选择这种方法来简化与外部数据源的互动。这将是数据分析团队中不熟悉编码的人员的正确选择。
- en: Indeed, why would we build a data connector from scratch if it already exists
    and is being managed in the cloud?
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 确实，如果数据连接器已经存在并且在云中管理，我们为什么还要从头开始构建呢？
- en: The downside of this approach is it’s pricing model though.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不过这种方法的缺点是其定价模型。
- en: Very often it is row-based and might become quite expensive on an enterprise
    level of data ingestion, i.e. big data pipelines. This is where open-source alternatives
    come into play. Frameworks like **Airbyte** and **Meltano** might be an easy and
    quick solution to deploy a data source **integration** microservice.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 很多时候它是基于行的，并且在企业级数据摄取（即大数据管道）上可能变得相当昂贵。这就是开源替代方案发挥作用的地方。像**Airbyte**和**Meltano**这样的框架可能是部署数据源**集成**微服务的简单快捷解决方案。
- en: 'If you don’t have time to learn a new ETL framework you can create a simple
    data connector yourself. If you know a bit of Python it would be a trivial task.
    In one of my previous articles I wrote how easy it is to create a microservice
    that pulls data from NASA API [3]:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有时间学习新的 ETL 框架，你可以自己创建一个简单的数据连接器。如果你懂一点 Python，这将是一个微不足道的任务。在我之前的一篇文章中，我写了如何轻松创建一个从
    NASA API 拉取数据的微服务[3]：
- en: '[](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
    [## Python for Data Engineers'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
    [## 数据工程师的Python'
- en: Advanced ETL techniques for beginners
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初学者的高级ETL技术
- en: towardsdatascience.com](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/python-for-data-engineers-f3d5db59b6dd?source=post_page-----e202776fb9a9--------------------------------)
- en: Consider this code snippet for `app.py`
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑`app.py`中的这段代码
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It can be deployed in any cloud vendor platform and scheduled to run with the
    required frequency. It’s always a good practice to use something like **Terraform**
    to deploy our data pipeline applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以部署在任何云服务商平台上，并按所需频率调度运行。使用类似**Terraform**的工具来部署我们的数据管道应用程序始终是一个好的实践。
- en: ETL frameworks explosion
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ETL框架的爆炸性增长
- en: We can witness a “Cambrian explosion” of various ETL frameworks for data extraction
    and transformation. It’s not a surprise that many of them are open-source and
    are Python-based.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以见证各种ETL框架在数据提取和转换中的“寒武纪大爆发”。许多框架都是开源的，并且基于Python，这并不令人惊讶。
- en: '**Luigi** [8] is one of them and it helps to create ETL pipelines. It was created
    by Spotify to manage massive data processing workloads. It has a command line
    interface and great visualization features. However, even basic ETL pipelines
    would require a certain level of Python programming skills. From my experience,
    I can tell that it’s great for strict and straightforward pipelines. I find it
    particularly difficult to implement complex branching logic using Luigi but it
    works great in many scenarios.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**Luigi** [8]就是其中之一，它帮助创建ETL管道。它由Spotify创建，用于管理大规模数据处理工作负载。它具有命令行界面和出色的可视化功能。然而，即使是基本的ETL管道也需要一定的Python编程技能。从我的经验来看，它适合严格且直接的管道。我发现使用Luigi实现复杂的分支逻辑特别困难，但它在许多场景中表现良好。'
- en: '**Python ETL (PETL) [9]** is one of the most widely used open-source ETL frameworks
    for straightforward data transformations. It is invaluable working with tables,
    extracting data from external data sources and performing basic ETL on data. In
    many ways, it is similar to **Pandas** but the latter has more analytics capabilities
    under the hood. PETL is great for aggregation and row-level ETL.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**Python ETL (PETL) [9]**是最广泛使用的开源ETL框架之一，用于简单的数据转换。在处理表格、从外部数据源提取数据以及对数据执行基本ETL时，它非常宝贵。在许多方面，它与**Pandas**类似，但后者在后台具有更多的分析功能。PETL非常适合聚合和行级ETL。'
- en: '**Bonobo** [10] is another open-source lightweight data processing tool which
    is great for rapid development, automation and parallel execution of batch-processing
    data pipelines. What I like about it is that it makes it really easy to work with
    various data file formats, i.e. SQL, XML, XLS, CSV and JSON. It will be a great
    tool for those with minimal Python knowledge. Among other benefits, I like that
    it works well with semi-complex data schemas. It is ideal for simple ETL and can
    run in Docker containers (it has a Docker extension).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Bonobo** [10]是另一个开源的轻量级数据处理工具，非常适合快速开发、自动化和批处理数据管道的并行执行。我喜欢它的一点是，它让处理各种数据文件格式变得非常简单，例如SQL、XML、XLS、CSV和JSON。对于那些Python知识有限的人来说，它将是一个很好的工具。在其他好处中，我喜欢它对半复杂数据模式的良好支持。它非常适合简单的ETL，并且可以在Docker容器中运行（它有一个Docker扩展）。'
- en: '**Pandas** is an absolute beast in the world of data and there is no need to
    cover it’s capabilities in this story. It’s worth mentioning that its data frame
    transformations have been included in one of the basic methods of data loading
    for many modern data warehouses. Consider this data loading sample into the BigQuery
    data warehouse solution:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pandas**在数据领域中绝对是一个巨头，在这个故事中没有必要详细介绍它的能力。值得一提的是，它的数据框架转换已被纳入许多现代数据仓库的基本数据加载方法之一。考虑将数据加载到BigQuery数据仓库解决方案中的示例：'
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Apache Airflow**, for example, is not an ETL tool per se but it helps to
    organize our ETL pipelines into a nice visualization of dependency graphs (DAGs)
    to describe the relationships between tasks. Typical Airflow architecture includes
    a schduler based on metadata, executors, workers and tasks.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**Apache Airflow**并不是一个ETL工具，但它有助于将我们的ETL管道组织成依赖关系图（DAGs）的可视化，以描述任务之间的关系。典型的Airflow架构包括基于元数据的调度器、执行器、工作节点和任务。
- en: For example, we can run ml_engine_training_op after we export data into the
    cloud storage (bq_export_op) and make this workflow run daily or weekly.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以在将数据导出到云存储（bq_export_op）后运行ml_engine_training_op，并使此工作流每日或每周运行。
- en: '![](../Images/137358971d4273ca60da3554c13fd586.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/137358971d4273ca60da3554c13fd586.png)'
- en: ML model training using Airflow. Image by author.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Airflow 训练 ML 模型。图像由作者提供。
- en: Consider this example below.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑下面的这个例子。
- en: It creates a simple data pipeline graph to export data into a cloud storage
    bucket and then trains the ML model using MLEngineTrainingOperator.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它创建了一个简单的数据管道图，将数据导出到云存储桶中，然后使用 MLEngineTrainingOperator 训练 ML 模型。
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bubbles** [11] is another open-source tool for ETL in the Python world. It’s
    great for rapid development and I like how it works with metadata to describe
    data pipelines. The creators of Bubbles call it an “abstract framework” and say
    that it can be used from many other programming languages, not exclusively from
    Python.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**Bubbles** [11] 是另一个用于 Python 世界中 ETL 的开源工具。它非常适合快速开发，我喜欢它如何使用元数据来描述数据管道。Bubbles
    的创建者称其为“抽象框架”，并表示它可以从许多其他编程语言中使用，而不仅仅是 Python。'
- en: There are many other tools with more specific applications, i.e. extracting
    data from web pages (PyQuery, BeautifulSoup, etc.) and parallel data processing.
    It can be a topic for another story but I wrote about some of them before, i.e.
    `joblib` library [12]
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他工具具有更具体的应用，例如从网页中提取数据（PyQuery、BeautifulSoup 等）和并行数据处理。这可以是另一个话题，但我之前写过一些相关内容，例如
    `joblib` 库 [12]。
- en: Data infrastructure as code
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据基础设施即代码
- en: '**Infrastructure as code** (IaC) is a popular and very functional approach
    for **managing data platform resources**. Even for data, it is pretty much a standard
    right now, and it definitely looks great on your CV telling your potential employers
    that you are familiar with DevOps standards. Using tools like Terraform (platform
    agnostic) and CloudFormation we can integrate our development work and deployments
    (operations) with ease.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**基础设施即代码**（IaC）是一种流行且非常实用的方法，用于**管理数据平台资源**。即使是数据方面，目前这几乎已经成为标准，而且在简历上提到你熟悉
    DevOps 标准绝对会显得很棒。使用像 Terraform（平台无关）和 CloudFormation 这样的工具，我们可以轻松地将我们的开发工作和部署（运维）进行集成。'
- en: In general, we would want to have staging and production data environments for
    our data pipelines. It helps to test our pipelines and facilitate collaboration
    between teams.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们希望为数据管道设置测试环境和生产环境。这有助于测试我们的管道，并促进团队之间的协作。
- en: Consider this diagram below. It explains how data environments work.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看下面的图表。它解释了数据环境的工作原理。
- en: '![](../Images/75b7d0ef1c9e75fbc698ea6d609ab4c1.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75b7d0ef1c9e75fbc698ea6d609ab4c1.png)'
- en: Data environments. Image by author.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 数据环境。图像由作者提供。
- en: Often we might need an extra sandbox for testing purposes or to run data transformation
    unit tests when our ETL services trigger CI/CD workflows.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常需要一个额外的沙箱来进行测试，或在 ETL 服务触发 CI/CD 工作流时运行数据转换单元测试。
- en: 'I previously wrote about it here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前在这里写过相关内容：
- en: '[](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
    [## Infrastructure as Code for Beginners'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
    [## 初学者的基础设施即代码'
- en: Deploy Data Pipelines like a pro with these templates
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 像专业人士一样使用这些模板部署数据管道
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: levelup.gitconnected.com](https://levelup.gitconnected.com/infrastructure-as-code-for-beginners-a4e36c805316?source=post_page-----e202776fb9a9--------------------------------)
- en: Using AWS CloudFormation template files we can describe required resources and
    their dependencies so we can launch and configure them together as a single stack.
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用 AWS CloudFormation 模板文件，我们可以描述所需的资源及其依赖关系，这样我们可以将它们作为一个整体堆栈一起启动和配置。
- en: If you are a **data professional** this approach will definitely help working
    with different data environments and replicate data platform resources faster
    and more consistently without errors.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一位**数据专家**，这种方法肯定会帮助你更好地处理不同的数据环境，并更快速、更一致地复制数据平台资源而不出错。
- en: The problem is that many data practitioners are not familiar with IaC and it
    creates a lot of errors during the development process.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于许多数据从业者对 IaC 并不熟悉，这在开发过程中会产生很多错误。
- en: Data Mesh and decentralized data management
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据网格和去中心化数据管理
- en: Data space has significantly evolved during the last decade and now we have
    lots of data tools and frameworks. **Data Mesh** defines the state when we have
    different data domains (company departments) with their own teams and shared data
    resources. Each team has their own goals, KPIs, data roles and responsibilities.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 数据空间在过去十年里发生了显著变化，现在我们有很多数据工具和框架。**数据网格**定义了这样一种状态：我们拥有不同的数据领域（公司部门），每个领域都有自己的团队和共享的数据资源。每个团队都有自己的目标、关键绩效指标（KPI）、数据角色和职责。
- en: For a long period of time, data bureaucracy has been a real pain for many companies.
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 长期以来，数据官僚主义一直是许多公司的真正痛点。
- en: This data platform type [4] might seem a bit chaotic but it was meant to become
    a successful and efficient choice for companies where decentralization enables
    different teams to access cross-domain datasets and run analytics or ETL tasks
    on their own.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据平台类型[4]可能看起来有些混乱，但它旨在成为一个成功且高效的选择，尤其适用于去中心化的公司，在这种结构下，不同的团队可以自行访问跨领域的数据集并执行分析或ETL任务。
- en: Indeed, Snowflake might be your favourite data warehouse solution if you are
    a data analyst and not familiar with Spark. However, often it’s a trivial problem
    when you might want to read datalake data without data engineering help. In this
    scenario, a bunch of metadata records on datasets could be extremely useful and
    that’s why Data Mesh is so successful.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，如果你是数据分析师而不熟悉Spark，Snowflake可能是你最喜欢的数据仓库解决方案。然而，当你可能希望在没有数据工程帮助的情况下读取数据湖数据时，通常这会是一个微不足道的问题。在这种情况下，大量的数据集元数据记录可能非常有用，这也是数据网格如此成功的原因。
- en: It enables users with knowledge about data, its origins and how other teams
    can make the best of those datasets they weren’t previously aware of.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得用户了解数据及其来源，并了解其他团队如何充分利用他们之前不知道的数据集。
- en: Sometimes datasets and data source connections become very intricate and it
    is always a good practice to have a single-source-of-truth data silo or repository
    with metadata and dataset descriptions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 有时数据集和数据源连接变得非常复杂，因此始终保持一个包含元数据和数据集描述的单一真实数据仓库是一个好习惯。
- en: In one of my previous stories [5] I wrote about the role of SQL as a unified
    querying language for teams and data. Indeed, it analytical, self-descriptive
    and come be even dynamic which makes it a perfect tool for all data users.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前的一篇故事[5]中，我写到了SQL作为团队和数据的统一查询语言的作用。确实，它具有分析性、自描述性，甚至可以是动态的，这使得它成为所有数据用户的完美工具。
- en: '**Often it all turns into a big mes(s/h)**'
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**这往往变成一团糟**'
- en: This fact makes SQL-based templating engines like DBT, Jinja and Dataform very
    popular. **Just imagine you have an SQL-like platform where all datasets and their
    transformations are described and defined thoroughly [6].**
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这一事实使得基于SQL的模板引擎如DBT、Jinja和Dataform非常受欢迎。**试想一下，你拥有一个类似SQL的平台，其中所有数据集及其转换都被彻底描述和定义[6]。**
- en: '![](../Images/0baeff3ede9d729968e3c27de50bdcaf.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0baeff3ede9d729968e3c27de50bdcaf.png)'
- en: Dataform’s dependency graph and metadata. Image by author.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Dataform的依赖图和元数据。图片来源：作者。
- en: It might be a big challenge to understand how data teams relate to data sources
    and schemas. Very often it is all tangled in spaghetti of dataset dependencies
    and ETL transformations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 理解数据团队如何与数据源和模式关联可能是一个很大的挑战。通常，这些都纠缠在数据集依赖关系和ETL转换的复杂网络中。
- en: Data engineering plays a critical role in mentoring, improving data literacy
    and empowering the rest of the company with state-of-the-art data processing techniques
    and best practices.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程在指导、提升数据素养以及通过最先进的数据处理技术和最佳实践来赋能公司其他部门方面发挥了关键作用。
- en: Democratization of Business Intelligence pipelines using AI
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用AI进行商业智能管道的民主化
- en: Improving data accessibility has always been a popular topic in the data space
    but it is interesting to see how the whole data pipeline design process is becoming
    increasingly accessible to teams that weren’t familiar with data before. Now almost
    every department can utilize built-in AI capabilities to create complex BI transformations
    on data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 改善数据可访问性一直是数据领域的热门话题，但有趣的是，整个数据管道设计过程正变得越来越容易被那些之前不熟悉数据的团队所接触。现在，几乎每个部门都可以利用内置的AI能力，在数据上创建复杂的商业智能转换。
- en: All they need is to describe what they want BI-wise in their own words
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他们所需要的只是用自己的话描述他们在商业智能方面的需求。
- en: For example, BI tools like **Thoughspot** use AI with an intuitive “Google-like
    search interface” [7] to gain insights from data stored in any modern DWH solution
    such as Google Big Query, Redshift, Snowflake or Databricks.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，像**Thoughspot**这样的 BI 工具使用具有直观“Google 风格搜索界面”的 AI [7] 来从存储在任何现代数据仓库解决方案（如
    Google Big Query、Redshift、Snowflake 或 Databricks）中的数据中获得洞察。
- en: Modern Data Stack includes BI tools that help with data modelling and visualization.
    Many of them already have these built-in AI capabilities to gain data insights
    faster based on user behaviour.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现代数据栈包括帮助数据建模和可视化的 BI 工具。许多工具已经具备了这些内置的 AI 功能，以根据用户行为更快地获得数据洞察。
- en: I believe it’s a fairly easy task to integrate GPT and BI. In the next couple
    of years, we will see many new products using this tech.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信将 GPT 与 BI 集成是一项相当简单的任务。在接下来的几年中，我们将看到许多新产品使用这项技术。
- en: GPT can pre-process text data to generate a SQL query that understands your
    intent and answers your question.
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT 可以预处理文本数据，以生成理解您的意图并回答您的问题的 SQL 查询。
- en: Conclusion
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, I tried to give a very high-level overview of major data trends
    that affect data engineering role these days. Data Mesh and templated SQL with
    dependency graphs to facilitate data literacy democratized the whole analytics
    process. Advanced data pipelines with intricate ETL techniques and transformations
    can be transparent for everyone in the organisation now. Data pipelines are becoming
    increasingly accessible for other teams and they don’t need to know programming
    to learn and understand the complexity of ETL. Data Mesh and metadata help to
    solve this problem. From my experience, I can tell that I keep seeing more and
    more people learning SQL to contribute to the transformation layer. Companies
    born during the “advanced data analytics” age have the luxury of easy access to
    cloud vendor products and their managed services. It definitely helps to acquire
    the required data skills and improve them to gain a competitive advantage.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我试图给出一个关于当前数据工程角色所面临的主要数据趋势的**高级概述**。数据网格和带有依赖关系图的模板化 SQL 使数据素养的普及成为可能，从而使整个分析过程民主化。先进的数据管道以及复杂的
    ETL 技术和转换现在对组织中的每个人都是透明的。数据管道正变得越来越易于其他团队访问，他们不需要了解编程就能学习和理解 ETL 的复杂性。数据网格和元数据有助于解决这个问题。从我的经验来看，我发现越来越多的人学习
    SQL 以参与转型层。诞生于“高级数据分析”时代的公司享有轻松访问云供应商产品及其托管服务的奢侈。它确实有助于获得所需的数据技能并加以提升，以获得竞争优势。
- en: Recommended read
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐阅读
- en: '[1] [https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3](https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3](https://medium.com/towards-data-science/data-pipeline-design-patterns-100afa4b93e3)'
- en: '[2] [https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009](/introduction-to-apache-iceberg-tables-a791f1758009)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://towardsdatascience.com/introduction-to-apache-iceberg-tables-a791f1758009](/introduction-to-apache-iceberg-tables-a791f1758009)'
- en: '[3] [https://towardsdatascience.com/python-for-data-engineers-f3d5db59b6dd](/python-for-data-engineers-f3d5db59b6dd)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://towardsdatascience.com/python-for-data-engineers-f3d5db59b6dd](/python-for-data-engineers-f3d5db59b6dd)'
- en: '[4] [https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7](https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7](https://medium.com/towards-data-science/data-platform-architecture-types-f255ac6e0b7)'
- en: '[5] [https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488](https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488](https://medium.com/towards-data-science/advanced-sql-techniques-for-beginners-211851a28488)'
- en: '[6] [https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365](https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365](https://medium.com/towards-data-science/easy-way-to-create-live-and-staging-environments-for-your-data-e4f03eb73365)'
- en: '[7] [https://docs.thoughtspot.com/cloud/latest/search-sage](https://docs.thoughtspot.com/cloud/latest/search-sage)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [https://docs.thoughtspot.com/cloud/latest/search-sage](https://docs.thoughtspot.com/cloud/latest/search-sage)'
- en: '[8] [https://github.com/spotify/luigi](https://github.com/spotify/luigi)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [https://github.com/spotify/luigi](https://github.com/spotify/luigi)'
- en: '[9] [https://petl.readthedocs.io/en/stable/](https://petl.readthedocs.io/en/stable/)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] [https://petl.readthedocs.io/en/stable/](https://petl.readthedocs.io/en/stable/)'
- en: '[10] [https://www.bonobo-project.org](https://www.bonobo-project.org)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] [https://www.bonobo-project.org](https://www.bonobo-project.org)'
- en: '[11] [http://bubbles.databrewery.org/](http://bubbles.databrewery.org/)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] [http://bubbles.databrewery.org/](http://bubbles.databrewery.org/)'
- en: '[12] [https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2](https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] [https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2](https://medium.com/towards-data-science/how-to-become-a-data-engineer-c0319cb226c2)'
