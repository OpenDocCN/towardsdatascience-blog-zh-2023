- en: 'Cognitive Biases in Data Science: The Category-Size Bias'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学中的认知偏见：类别规模偏见
- en: 原文：[https://towardsdatascience.com/cognitive-biases-in-data-science-the-category-size-bias-8dbd851608c3](https://towardsdatascience.com/cognitive-biases-in-data-science-the-category-size-bias-8dbd851608c3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cognitive-biases-in-data-science-the-category-size-bias-8dbd851608c3](https://towardsdatascience.com/cognitive-biases-in-data-science-the-category-size-bias-8dbd851608c3)
- en: '[DATA BIAS HACKERS](https://towardsdatascience.com/tagged/data-cognitive-bias)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[数据偏见黑客](https://towardsdatascience.com/tagged/data-cognitive-bias)'
- en: A data scientist’s guide to outsmarting biases
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学家的偏见破解指南
- en: '[](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)[![Maham
    Haroon](../Images/5a9ac82369ecbf7719b765ec160a70ef.png)](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)
    [Maham Haroon](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)[![Maham
    Haroon](../Images/5a9ac82369ecbf7719b765ec160a70ef.png)](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)
    [Maham Haroon](https://medium.com/@MahamsMultiverse?source=post_page-----8dbd851608c3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)
    ·8 min read·Nov 29, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8dbd851608c3--------------------------------)
    ·阅读时间 8 分钟·2023年11月29日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/eee2dc275bfeecb4dd134047e6cab03f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eee2dc275bfeecb4dd134047e6cab03f.png)'
- en: Photo by [Andy Li](https://unsplash.com/@andylid0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/man-in-white-dress-shirt-standing-in-front-of-brown-wooden-shelf-RndRFJ1v1kk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Andy Li](https://unsplash.com/@andylid0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    拍摄的照片，来源于 [Unsplash](https://unsplash.com/photos/man-in-white-dress-shirt-standing-in-front-of-brown-wooden-shelf-RndRFJ1v1kk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)'
- en: Imagine you find yourself in a quaint neighborhood with two bakeries. The first
    is a small, family-owned bakery, warmly nestled on the corner street. The second,
    however, is a grand three-story establishment, with a sign that showcases its
    extensive selection and state-of-the-art ovens.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你发现自己置身于一个风景如画的街区，那里有两家面包店。第一家是一家小型家族经营的面包店，温馨地坐落在街角。第二家则是一座宏伟的三层大楼，招牌上展示了其丰富的选择和先进的烤箱。
- en: As you embark on your quest for the perfect loaf of bread, you are drawn to
    the towering bakery. The sheer size and grandeur of the building make an immediate
    impression, making the assumption that the larger bakery must surely produce the
    finest bread.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始寻找完美的面包时，你被那家高大的面包店所吸引。建筑的巨大和宏伟给人留下了深刻的印象，使你假设较大的面包店一定生产出最好的面包。
- en: Here, in this scenario, you’re unknowingly succumbing to a mental tendency known
    as category size bias. The bias leads you to believe that the larger bakery is
    more likely to offer superior bread.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个情境中，你无意中屈服于一种被称为类别规模偏见的心理倾向。这种偏见让你相信，较大的面包店更可能提供优质的面包。
- en: In reality, the size of the bakery doesn’t necessarily correlate with the quality
    of its bread. The smaller, family-owned bakery may have a closely guarded secret
    recipe, perfected over generations, while the larger bakery might focus on quantity
    over artisanal craftsmanship.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，面包店的规模与其面包的质量并不一定相关。较小的家族经营的面包店可能拥有一份代代相传的秘密配方，而较大的面包店则可能更注重数量而非手工艺。
- en: This bias echoes our inclination to associate larger categories with better
    outcomes, even when the specific characteristics within those categories may not
    align with our assumptions. This phenomenon is called category size bias.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这种偏见反映了我们将更大类别与更好结果联系起来的倾向，即使这些类别中的具体特征可能与我们的假设不符。这种现象被称为类别规模偏见。
- en: Category size bias refers to our inclination to perceive outcomes as more probable
    when they belong to a larger category as opposed to a smaller one, even when the
    likelihood of each outcome is equal.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 类别大小偏差指的是我们倾向于将结果视为更可能发生的情况，当它们属于较大类别时，而不是较小类别，即使每个结果的可能性是相等的。
- en: '[Despite the bias being grounded in experimentally validated studies, there
    is ongoing variability in the interpretation of the evidence.](https://thedecisionlab.com/biases/category-size-bias)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[尽管这种偏差基于经过实验验证的研究，但对证据的解释仍然存在持续的变化。](https://thedecisionlab.com/biases/category-size-bias)'
- en: 'In the realm of Data Science, category size bias may manifest via specific
    assumptions. For instance:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学领域，类别大小偏差可能通过特定假设表现出来。例如：
- en: 'Assumption 1: Larger more complex models always provide better predictions
    compared to smaller models.'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设 1：较大、更复杂的模型总是比较小的模型提供更好的预测。
- en: Within the context of category size bias, the tendency is to believe that the
    performance of a Neural Network or an ML model improves with its size or complexity.
    Consequently, regardless of whether the data or task aligns with the model’s characteristics,
    there’s often a focus on complex models. This inclination is akin to the [bandwagon
    effect](https://thedecisionlab.com/biases/bandwagon-effect), where newer, more
    intricate, and renowned algorithms are presumed to be cutting-edge, even for tasks
    they are not well-suited for. Consider, for instance, using large language models
    (LLMs) for relatively simple tasks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在类别大小偏差的背景下，通常认为神经网络或机器学习模型的性能随着其规模或复杂性而提高。因此，无论数据或任务是否符合模型的特性，人们往往会关注复杂模型。这种倾向类似于[从众效应](https://thedecisionlab.com/biases/bandwagon-effect)，即认为更新、更复杂和更知名的算法是最前沿的，即使它们并不适合某些任务。例如，考虑使用大型语言模型（LLMs）来处理相对简单的任务。
- en: For example, adding extra layers to a Neural Network, even when they don’t really
    make the model much better, as most tasks can be handled well with just two layers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，向神经网络中添加额外的层，即使它们实际上并没有使模型变得更好，因为大多数任务只需两层就能很好地处理。
- en: '![](../Images/714b2e09674794c09c497f79cdd11841.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/714b2e09674794c09c497f79cdd11841.png)'
- en: Image by Author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: '**Caveat:** It’s important to note that the assumption of larger, more complex
    models yielding better predictions holds true in many cases, especially when dealing
    with complex tasks that require a high level of precision or problems involving
    vast and diverse datasets.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告：** 需要注意的是，大型、更复杂的模型往往能够提供更好的预测，这在许多情况下是成立的，特别是在处理需要高度精确度或涉及庞大且多样化数据集的复杂任务时。'
- en: '**Trade-off:** The trade-off in such scenarios encompasses both performance
    and resource consumption. While complex or larger models demand more resources,
    the increased resource consumption doesn’t automatically translate to superior
    model performance. Although this may not always be necessary or impactful, in
    critical problems, making such considerations can indeed make a significant difference.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡：** 在这种情况下的权衡包括性能和资源消耗。尽管复杂或更大的模型需要更多的资源，但增加的资源消耗并不会自动转化为更好的模型性能。尽管这在所有情况下可能不是必要的或有影响的，但在关键问题中，考虑这些因素确实可能会带来显著的差异。'
- en: 'Assumption 2: Overlooking Class Imbalance by Relying Solely on Higher Accuracy'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设 2：仅依赖较高的准确率忽视类别不平衡
- en: This problem is a more widely acknowledged one. When utilizing a metric such
    as accuracy, there is a heightened risk of overlooking an underlying bias. To
    illustrate, consider a dataset with 5 instances of a disease among 1000 patients.
    If a model achieves 99.5% accuracy by consistently classifying almost all instances
    as negative (given the majority of instances are negative), the assumption might
    be that the model performs well. However, in reality, the model would be performing
    inadequately by not classifying any instances as positive.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题是一个被广泛认可的问题。在使用诸如准确率之类的指标时，更容易忽视潜在的偏差。举例来说，考虑一个包含1000名患者的数据库，其中5名患者有某种疾病。如果一个模型通过始终将几乎所有实例都分类为阴性（因为大多数实例是阴性的）来实现99.5%的准确率，那么可能会认为这个模型表现良好。然而，实际上，这个模型的表现是不足的，因为它没有将任何实例分类为阳性。
- en: 'To explain further, let’s look at a basic example. We’ll create 100 random
    numbers between 0 and 1\. If a number is over 0.92, we call it positive; otherwise,
    it’s negative. We’ll use logistic regression as our model. The code snippet below
    demonstrates this scenario:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步说明，我们来看一个基本的例子。我们将生成100个0到1之间的随机数。如果一个数字超过0.92，我们称其为正类；否则为负类。我们将使用逻辑回归作为我们的模型。下面的代码片段演示了这种情况：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Although the model achieves a respectable accuracy of 0.92, an examination of
    other metrics like recall and f1-score reveals a far inferior performance. In
    the plotted chart on the left, it becomes clear that none of the positive instances
    have been correctly classified as positive.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管模型达到令人满意的准确率0.92，但检查其他指标如召回率和f1-score却显示性能远远不如。在左侧绘制的图表中，明显没有任何正实例被正确分类为正类。
- en: '![](../Images/3327d6d5722a6ce1b4638fdb362ea840.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3327d6d5722a6ce1b4638fdb362ea840.png)'
- en: Image by Author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: '**Caveat:** While accuracy is usually a good measure, there are cases where
    prioritizing higher accuracy makes sense. In cases where class imbalances are
    minimal, and the cost of misclassification is relatively low, prioritizing accuracy
    can be a reasonable choice.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告：** 尽管准确性通常是一个很好的衡量标准，但在某些情况下，优先考虑更高的准确性是合理的。在类不平衡最小且误分类成本相对较低的情况下，优先考虑准确性可能是一个合理的选择。'
- en: '**Trade-off:** The trade-off in this scenario revolves around performance itself,
    with considerable stakes. However, in instances of minor imbalances or data previously
    processed, this concern may not be as consequential.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡：** 在这种情况下的权衡集中在性能本身，涉及到相当大的风险。然而，在轻微不平衡或数据已处理的情况下，这种担忧可能不那么重要。'
- en: 'Assumption 3: Equating Larger Datasets with Improved Performance'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设3：将更大的数据集与性能改进等同起来
- en: While it’s often the case that larger datasets bring about more features, additional
    information, and an enhanced likelihood of realistic predictions, this holds true
    only up to a point. The amount of data needed depends on the specific problem.
    For example, in classification tasks, scenarios with a smaller number of classes
    or a many informative features might do well with smaller datasets. Similarly,
    tasks involving lower-order function approximation might be content with a more
    modest dataset.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然较大的数据集通常带来更多特征、附加信息和更高的现实预测概率，但这种情况只在一定程度上成立。所需的数据量取决于具体问题。例如，在分类任务中，类较少或有很多有用特征的情况可能适用于较小的数据集。同样，涉及低阶函数近似的任务可能对较小的数据集感到满意。
- en: Let’s understand this with an example. First, we make fake data with half of
    it being useful, 5 categories, and around 20,000 samples.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来理解这个问题。首先，我们生成虚假的数据，其中一半是有用的，包含5个类别，大约20,000个样本。
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Subsequently, we employ Support Vector Classification (SVC) for class separation
    on a subset of the data, specifically 9,000 instances:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们使用支持向量分类（SVC）对数据子集进行类别分离，特别是9,000个实例：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'When measuring the time taken for this task, we observe 6.9590 seconds with
    an accuracy of 0.8430\. Subsequently, we utilize the entire dataset for training
    the SVC, comprising approximately 16,000 instances for training and 4,000 instances
    for testing:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量该任务所用的时间时，我们观察到6.9590秒，准确率为0.8430。随后，我们利用整个数据集来训练SVC，包括大约16,000个实例用于训练和4,000个实例用于测试：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This time, the algorithm takes 20.4149 seconds, about 3x the previous time,
    yielding an accuracy of 0.8452 — remarkably close despite almost double the data.
    A comparison of ROC curves for both models reveals nearly identical results.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，算法花费了20.4149秒，约为之前时间的3倍，准确率为0.8452——尽管数据量几乎翻倍，但结果非常接近。对两个模型的ROC曲线进行比较，结果几乎相同。
- en: '![](../Images/a3de088294ad99b83d639441dc7a8256.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a3de088294ad99b83d639441dc7a8256.png)'
- en: Image by Author
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: '**Caveat:** Complex tasks often need more data, but there’s a point where more
    data doesn’t necessarily mean better results.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告：** 复杂任务通常需要更多数据，但有一个点是更多的数据不一定意味着更好的结果。'
- en: '**Trade-off:** While additional data rarely harms the model, the trade-off
    lies not in performance but in computational cost. This cost can be substantial
    when irrelevant information is added to the model, emphasizing the importance
    of data pre-processing and cleaning, particularly in complex tasks.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡：** 尽管额外的数据很少会对模型造成伤害，但权衡在于计算成本，而不是性能。当模型中添加无关的信息时，这种成本可能很高，这突显了数据预处理和清理的重要性，特别是在复杂任务中。'
- en: 'Assumption 4: Equating Longer, More Complex Algorithms with Superior Performance'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 假设 4：将较长、更复杂的算法等同于更优性能
- en: While not always true, there exists a notion that longer, complex algorithms
    hold superiority over their shorter, simpler counterparts. Sometimes, a more intricate
    algorithm is favored even when a simpler one perfectly accomplishes the task.
    While this notion is not always unfounded, the issue lies in the underlying rationale
    for such a belief. If complexity and length are genuinely warranted by the algorithm,
    then there’s no harm in their application.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管并非总是如此，但存在一种观点，认为较长、复杂的算法优于较短、简单的算法。有时，即使一个简单的算法可以完美地完成任务，仍会偏向于使用更复杂的算法。尽管这种观点并非总是毫无根据，但问题在于这种信念的根本理由。如果算法确实需要复杂性和长度，那么应用这些特性也无可厚非。
- en: 'To illustrate this assumption, let’s compare two code blocks. The first function
    appears quite straightforward:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一假设，我们比较两个代码块。第一个函数看起来相当简单：
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'On the other hand, the second function seems to involve more work, evident
    in both time and space complexity. However, the ultimate goal of both functions
    is exactly the same:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，第二个函数似乎涉及更多工作，时间和空间复杂度均有所体现。然而，两个函数的*最终目标*是完全相同的：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: I intentionally kept this example simple, but the idea applies to more complicated
    code that might focus too much on a specific problem or do different things.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我故意将这个例子保持简单，但这一理念同样适用于可能过于关注特定问题或做不同事情的更复杂的代码。
- en: '**Caveat:** This doesn’t apply to adding unit tests, comments, or improvements
    that genuinely make the code better. Furthermore, the belief that longer and more
    complex algorithms are superior is not unfounded in certain contexts. For tasks
    that inherently require nuanced decision boundaries or involve complex relationships,
    a more sophisticated algorithm might indeed be necessary.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告：** 这不适用于添加单元测试、注释或真正提升代码质量的改进。此外，较长且复杂的算法在某些情况下并非毫无依据地被认为更优。对于那些本质上需要细致决策边界或涉及复杂关系的任务，更复杂的算法可能确实是必要的。'
- en: '**Trade-off:** The cost of this bias often manifests in terms of computational
    resources. While it might not significantly impact simpler tasks, the expense
    becomes more pronounced for more complex tasks.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**权衡：** 这种偏差的代价通常表现为计算资源的消耗。虽然它可能不会显著影响较简单的任务，但对于更复杂的任务，开销变得更加明显。'
- en: 'Avoiding Category-Size Bias: Strategies for Awareness and Mitigation'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免类别大小偏差：提高意识和缓解策略
- en: While category-size bias may not be the most detrimental bias, it can lead to
    resource drainage.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管类别大小偏差可能不是最具破坏性的偏差，但它可能导致资源消耗。
- en: '***It’s better to break things down to simpler and smaller tasks and start
    there when possible for clearer understanding of the underlying problem.***'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '***将问题分解为更简单、更小的任务，并在可能的情况下从那里开始，以更清晰地理解潜在问题，这是更好的做法。***'
- en: Being aware of our subconscious inclination towards favoring one option over
    another is a key to avoid succumbing to the bias. A valuable approach is to challenge
    assumptions, utilizing the Socratic questioning technique.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 意识到我们潜意识中倾向于偏袒某个选项是避免陷入偏见的关键。一种有价值的方法是挑战假设，利用苏格拉底式提问技术。
- en: '[](https://www.verywellmind.com/socratic-questioning-8350838?source=post_page-----8dbd851608c3--------------------------------)
    [## Understanding Socratic Questioning: A Comprehensive Guide'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[理解苏格拉底式提问：全面指南](https://www.verywellmind.com/socratic-questioning-8350838?source=post_page-----8dbd851608c3--------------------------------)
    [## 理解苏格拉底式提问：全面指南'
- en: Socratic questioning encourages people to think more deeply about an issue,
    stepping outside their own perspective…
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 苏格拉底式提问鼓励人们更深入地思考问题，超越自身的视角……
- en: www.verywellmind.com](https://www.verywellmind.com/socratic-questioning-8350838?source=post_page-----8dbd851608c3--------------------------------)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[理解苏格拉底式提问：全面指南](https://www.verywellmind.com/socratic-questioning-8350838?source=post_page-----8dbd851608c3--------------------------------)'
- en: '***Another approach is attempting to prove the hypothesis opposite to the initially
    favored one.***'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '***另一种方法是尝试证明与最初偏好的假设相反的假设。***'
- en: Taking the time to individually assess data and treat each problem distinctly
    can provide valuable insights.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 花时间逐个评估数据，并将每个问题区别对待，可以提供宝贵的见解。
- en: Wrapping up…
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结：
- en: In conclusion, this post highlighted the influence of category-size bias in
    the realm of data science. The key takeaway is, to stay mindful of the bias and
    consistently take the context of the problem into account.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，本文突出了类别规模偏差在数据科学领域中的影响。关键的结论是，要时刻留意这些偏差，并始终考虑问题的背景。
- en: Coming up on the horizon…
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 即将到来…
- en: Our analyses often don’t rely only on algorithms and models, but are heavily
    influenced by the deeply embedded cognitive biases. This post explored the Category-Size
    Bias and its impact on decision-making in data science. However, this is just
    the start. In upcoming posts of this series, I’d focus on uncovering more cognitive
    biases and their impact on data research and analytics. From assumptions about
    causation to the appeal of anecdotal evidence, from confirmation bias to the bandwagon
    effect, the posts will explore the intersection of human biases and data science.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析不仅仅依赖于算法和模型，还受到深层次的认知偏差的重大影响。本文探讨了类别规模偏差及其对数据科学决策的影响。然而，这只是个开始。在本系列的后续文章中，我将专注于揭示更多认知偏差及其对数据研究和分析的影响。从因果关系的假设到轶事证据的吸引力，从确认偏差到从众效应，这些文章将探索人类偏差与数据科学的交集。
- en: It’s my goal to present more in-depth examination of biases that could affect
    our analytical pursuits, and promote a more nuanced and bias-aware data science
    practice.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我的目标是对可能影响我们分析追求的偏差进行更深入的研究，并促进更细致和偏差意识的数据科学实践。
- en: I add some additional resources or further exploration.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我添加了一些额外的资源或进一步的探索。
- en: Resources
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '[](https://thedecisionlab.com/biases?source=post_page-----8dbd851608c3--------------------------------)
    [## List of Cognitive Biases and Heuristics - The Decision Lab'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://thedecisionlab.com/biases?source=post_page-----8dbd851608c3--------------------------------)
    [## 认知偏差和启发式列表 - 认知决策实验室'
- en: Below is a list of the most important cognitive biases and heuristics in the
    field of behavioural science.
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 以下是行为科学领域中最重要的认知偏差和启发式的列表。
- en: 'thedecisionlab.com](https://thedecisionlab.com/biases?source=post_page-----8dbd851608c3--------------------------------)
    [](https://www.teachthought.com/critical-thinking/cognitive-biases/?source=post_page-----8dbd851608c3--------------------------------)
    [## The Cognitive Biases List: A Visual Of 180+ Heuristics'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[认知偏差列表：180多种启发式的可视化](https://thedecisionlab.com/biases?source=post_page-----8dbd851608c3--------------------------------)
    [](https://www.teachthought.com/critical-thinking/cognitive-biases/?source=post_page-----8dbd851608c3--------------------------------)
    [## 认知偏差列表：180多种启发式的可视化'
- en: Cognitive biases are tendencies to selectively search for or interpret data
    in a way that confirms one's existing…
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 认知偏差是指倾向于选择性地搜索或解释数据，以确认现有的观点…
- en: www.teachthought.com](https://www.teachthought.com/critical-thinking/cognitive-biases/?source=post_page-----8dbd851608c3--------------------------------)
    [](https://www.mindtools.com/aipz4vt/the-ladder-of-inference?source=post_page-----8dbd851608c3--------------------------------)
    [## The Ladder of Inference - How to Avoid Jumping to Conclusions
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.teachthought.com](https://www.teachthought.com/critical-thinking/cognitive-biases/?source=post_page-----8dbd851608c3--------------------------------)
    [](https://www.mindtools.com/aipz4vt/the-ladder-of-inference?source=post_page-----8dbd851608c3--------------------------------)
    [## 推理阶梯 - 如何避免仓促得出结论'
- en: Use the Ladder of Inference to explore the seven steps we take in our thinking
    to get from a fact to a decision or…
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用**推理阶梯**来探索我们在思维中从事实到决策或结论所经过的七个步骤…
- en: www.mindtools.com](https://www.mindtools.com/aipz4vt/the-ladder-of-inference?source=post_page-----8dbd851608c3--------------------------------)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.mindtools.com](https://www.mindtools.com/aipz4vt/the-ladder-of-inference?source=post_page-----8dbd851608c3--------------------------------)'
