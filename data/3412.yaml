- en: The Creative, Occasionally Messy World of Textual Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文字数据的创造性、偶尔混乱的世界
- en: 原文：[https://towardsdatascience.com/the-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a?source=collection_archive---------12-----------------------#2023-11-16](https://towardsdatascience.com/the-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a?source=collection_archive---------12-----------------------#2023-11-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a?source=collection_archive---------12-----------------------#2023-11-16](https://towardsdatascience.com/the-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a?source=collection_archive---------12-----------------------#2023-11-16)
- en: '[](https://towardsdatascience.medium.com/?source=post_page-----9d0ae46fc71a--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page-----9d0ae46fc71a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9d0ae46fc71a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9d0ae46fc71a--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----9d0ae46fc71a--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://towardsdatascience.medium.com/?source=post_page-----9d0ae46fc71a--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page-----9d0ae46fc71a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9d0ae46fc71a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9d0ae46fc71a--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----9d0ae46fc71a--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----9d0ae46fc71a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9d0ae46fc71a--------------------------------)
    ·Sent as a [Newsletter](/newsletter?source=post_page-----9d0ae46fc71a--------------------------------)
    ·3 min read·Nov 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9d0ae46fc71a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a&user=TDS+Editors&userId=7e12c71dfa81&source=-----9d0ae46fc71a---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[跟踪](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----9d0ae46fc71a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9d0ae46fc71a--------------------------------)
    · 作为 [Newsletter](/newsletter?source=post_page-----9d0ae46fc71a--------------------------------)
    · 3 分钟阅读 · 2023 年 11 月 16 日'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d0ae46fc71a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a&source=-----9d0ae46fc71a---------------------bookmark_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9d0ae46fc71a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-creative-occasionally-messy-world-of-textual-data-9d0ae46fc71a&source=-----9d0ae46fc71a---------------------bookmark_footer-----------)'
- en: For several years, the intersection of text and data stayed (more or less) within
    the realm of natural language processing (NLP) — the wide range of machine learning
    tasks that leverage textual data for prediction, classification, and recommendation
    tools.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 几年来，文本与数据的交集（多多少少）仅限于自然语言处理（NLP）领域——利用文本数据进行预测、分类和推荐工具的广泛机器学习任务。
- en: The rise of large language models has introduced a host of exciting new possibilities
    into the field, with novel use cases and innovative workflows popping up at a
    rapid clip. Our highlights this week represent a wide cross-section of concepts
    and approaches that dig deeper into this emerging area. From prompt engineering
    to text-to-image and text-to-speech applications, we’re thrilled to share work
    by authors who explore the creative possibilities of textual data as both inputs
    and outputs of these powerful models. Let’s dive in.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型的崛起为该领域引入了一系列令人兴奋的新可能性，各种新用例和创新工作流程如雨后春笋般涌现。本周的亮点代表了对这一新兴领域深入挖掘的一系列概念和方法。从提示工程到文本转图像和文本转语音应用，我们很高兴分享探索这些强大模型的文本数据作为输入和输出的创造性可能性的作者的工作。让我们深入了解。
- en: '[**Lost in DALL-E 3 Translation**](/lost-in-dall-e-3-translation-b85a3958b9d6)What
    happens when you use text-to-image tools like DALL-E 3 in languages other than
    English? [Yennie Jun](https://medium.com/u/12ca1ab81192?source=post_page-----9d0ae46fc71a--------------------------------)
    continues to explore the discrepancies in model performance for users working
    in under-resourced languages and the ways in which gender and other biases seep
    through into the generated images.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**迷失在DALL-E 3翻译中**](/lost-in-dall-e-3-translation-b85a3958b9d6)当你在非英语语言中使用DALL-E
    3等文本转图像工具时会发生什么？[Yennie Jun](https://medium.com/u/12ca1ab81192?source=post_page-----9d0ae46fc71a--------------------------------)继续探索在使用资源匮乏语言的用户中，模型性能存在的差异以及性别和其他偏见如何渗透到生成的图像中。'
- en: '[**How to Convert Any Text Into a Graph of Concepts**](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a)In
    his latest post, [Rahul Nayak](https://medium.com/u/473e87f4b733?source=post_page-----9d0ae46fc71a--------------------------------)
    dives deep into the world of Knowledge-Graph Augmented Generation, walking us
    through the process of transforming a text corpus into a Graph of Concepts (GC)
    and then visualizing it to detect patterns and draw meaningful insights.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**如何将任何文本转换为概念图**](/how-to-convert-any-text-into-a-graph-of-concepts-110844f22a1a)在他的最新文章中，[Rahul
    Nayak](https://medium.com/u/473e87f4b733?source=post_page-----9d0ae46fc71a--------------------------------)深入探讨了知识图增强生成的世界，引导我们通过将文本语料库转化为概念图（GC），然后可视化来检测模式并得出有意义的洞见。'
- en: '![](../Images/c4621e7999e4e8c487cf1d8e4e375fe5.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4621e7999e4e8c487cf1d8e4e375fe5.png)'
- en: Photo by [Jas Min](https://unsplash.com/@filmbetrachterin?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Jas Min](https://unsplash.com/@filmbetrachterin?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '[**RAG: How to Talk to Your Data**](/rag-how-to-talk-to-your-data-eaf5469b83b0)We’ve
    covered retrieval-augmented generation many times in recent months, but [Mariya
    Mansurova](https://medium.com/u/15a29a4fc6ad?source=post_page-----9d0ae46fc71a--------------------------------)’s
    addition to the conversation is still very much worth your time: it presents a
    compelling, practical workflow for analyzing customer feedback using ChatGPT.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**RAG：如何与您的数据交谈**](/rag-how-to-talk-to-your-data-eaf5469b83b0)在过去几个月中，我们多次涉及检索增强生成技术，但[Mariya
    Mansurova](https://medium.com/u/15a29a4fc6ad?source=post_page-----9d0ae46fc71a--------------------------------)对这一话题的贡献仍然非常值得您花时间阅读：她提出了一个引人入胜的实用工作流程，用于分析使用ChatGPT的客户反馈。'
- en: '[**FastSpeech: Paper Overview & Implementation**](/fastspeech-paper-overview-implementation-e2b3808648f1)Text-to-speech
    tools have made major strides in recent years. To gain a solid understanding of
    how they work and how transformers are employed to improve their performance,
    don’t miss [Essam Wisam](https://medium.com/u/ccb82b9f3b87?source=post_page-----9d0ae46fc71a--------------------------------)’s
    accessible introduction to the FastSpeech paper from 2019, which facilitated much
    of the progress we’ve seen in this domain.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**FastSpeech：论文概述与实现**](/fastspeech-paper-overview-implementation-e2b3808648f1)近年来，文本转语音工具取得了重大进展。要深入了解它们的工作原理以及如何利用变压器来提高它们的性能，请不要错过[Essam
    Wisam](https://medium.com/u/ccb82b9f3b87?source=post_page-----9d0ae46fc71a--------------------------------)对2019年FastSpeech论文的易于理解的介绍，这为我们在该领域看到的许多进展提供了便利。'
- en: '[**Unlocking the Power of Text Data with LLMs**](/unlocking-the-power-of-text-data-with-llms-3ddcd063274a)If
    you’re a beginner who’d like to start experimenting with cutting-edge text-data
    techniques, [Sofia Rosa](https://medium.com/u/a5b24231d702?source=post_page-----9d0ae46fc71a--------------------------------)’s
    step-by-step guide will get you rolling up your sleeves in no time. It walks us
    through an entire workflow, from downloading data to working with GPT-3 and analyzing
    results.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**释放文本数据的力量与LLMs**](/unlocking-the-power-of-text-data-with-llms-3ddcd063274a)如果你是一个初学者，想要开始尝试尖端的文本数据技术，[索非亚·罗莎](https://medium.com/u/a5b24231d702?source=post_page-----9d0ae46fc71a--------------------------------)的分步指南将帮助你迅速入门。它将带领我们完成从下载数据到使用GPT-3和分析结果的整个工作流程。'
- en: '[**A Universal Roadmap for Prompt Engineering: The Contextual Scaffolds Framework
    (CSF)**](/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a)Prompt
    engineering has emerged as a crucial component in the interplay between human
    intuition and large language models’ capabilities. [Giuseppe Scalamogna](https://medium.com/u/e039aa8b7221?source=post_page-----9d0ae46fc71a--------------------------------)
    goes beyond basic prompting tips and tricks to present the contextual scaffolds
    framework (CSF), a “general purpose mental model for effective prompt engineering.”'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**通用提示工程路线图：情境支架框架（CSF）**](/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a)提示工程已成为人类直觉与大型语言模型能力之间互动中的关键组成部分。[朱塞佩·斯卡拉莫尼亚](https://medium.com/u/e039aa8b7221?source=post_page-----9d0ae46fc71a--------------------------------)超越了基本的提示技巧，介绍了情境支架框架（CSF），这是一个“有效提示工程的通用心理模型”。'
- en: 'We hope you have some time to branch out into other topics this week — here
    are some of our recent standouts on data visualization, generated-content detection,
    and more:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望你这周能有时间涉猎其他主题——以下是我们最近在数据可视化、生成内容检测等方面的一些突出成果：
- en: '[Can artificial intelligence help us understand how the brain works](/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5)?
    [Stephanie Shen](https://medium.com/u/574ba7df600a?source=post_page-----9d0ae46fc71a--------------------------------)
    explores this consequential question by mapping out the similarities between biological
    learning and artificial neural networks.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能能否帮助我们理解大脑的工作原理](/from-biological-learning-to-artificial-neural-network-whats-next-c8cf0d351af5)？[斯蒂芬妮·申](https://medium.com/u/574ba7df600a?source=post_page-----9d0ae46fc71a--------------------------------)通过绘制生物学习与人工神经网络之间的相似性来探讨这个重要问题。'
- en: Matplotlib is a ubiquitous and powerful visualization tool, but also comes with
    its share of idiosyncrasies. [Lee Vaughan](https://medium.com/u/5d604015c08b?source=post_page-----9d0ae46fc71a--------------------------------)’s
    beginner-friendly guide will help you [start your learning journey on the right
    foot](/demystifying-matplotlib-3895ab229a63).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib是一个无处不在且强大的可视化工具，但也有其独特的怪癖。[李·沃恩](https://medium.com/u/5d604015c08b?source=post_page-----9d0ae46fc71a--------------------------------)的初学者友好指南将帮助你[踏上学习之旅的正确起点](/demystifying-matplotlib-3895ab229a63)。
- en: 'For all the marketing-focused data scientists out there: don’t miss [Hajime
    Takeda](https://medium.com/u/6d7012b72e49?source=post_page-----9d0ae46fc71a--------------------------------)’s
    clear and [detailed introduction to customer lifetime-value forecasting](/pymc-marketing-the-key-to-advanced-clv-customer-lifetime-value-forecasting-bc0730973c0a).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于所有关注营销的数据科学家：不要错过[竹田一](https://medium.com/u/6d7012b72e49?source=post_page-----9d0ae46fc71a--------------------------------)关于客户生命周期价值预测的清晰且[详细介绍](/pymc-marketing-the-key-to-advanced-clv-customer-lifetime-value-forecasting-bc0730973c0a)。
- en: The ability to [distinguish between human-produced and model-generated content](/detecting-generative-ai-content-286200498f93)
    has never been more crucial—or difficult. [Stephanie Kirmer](https://medium.com/u/a8dc77209ef3?source=post_page-----9d0ae46fc71a--------------------------------)
    unpacks the current stakes and challenges around this conundrum.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分人类生产的内容与模型生成的内容的能力从未如此重要——也从未如此困难。[斯蒂芬妮·基尔默](https://medium.com/u/a8dc77209ef3?source=post_page-----9d0ae46fc71a--------------------------------)解读了当前围绕这一难题的风险和挑战。
- en: Looking to do some hands-on tinkering this week? [Amanda Iglesias Moreno](https://medium.com/u/1bace2932c65?source=post_page-----9d0ae46fc71a--------------------------------)’s
    tutorial will [guide you through the construction of hexagon maps](/constructing-hexagon-maps-with-h3-and-plotly-a-comprehensive-tutorial-8f37a91573bb)
    with H3 and Plotly.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本周想做些实际操作吗？[Amanda Iglesias Moreno](https://medium.com/u/1bace2932c65?source=post_page-----9d0ae46fc71a--------------------------------)的教程将[引导你构建六边形地图](/constructing-hexagon-maps-with-h3-and-plotly-a-comprehensive-tutorial-8f37a91573bb)，使用H3和Plotly。
- en: In his latest deep dive, [Jeffrey Näf](https://medium.com/u/ca780798011a?source=post_page-----9d0ae46fc71a--------------------------------)
    takes a close look at [variable importance in the context of random forests](/variable-importance-in-random-forests-20c6690e44e0),
    covering both traditional methods and newer developments.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在他最新的深度分析中，[Jeffrey Näf](https://medium.com/u/ca780798011a?source=post_page-----9d0ae46fc71a--------------------------------)详细探讨了[随机森林中的变量重要性](/variable-importance-in-random-forests-20c6690e44e0)，涵盖了传统方法和较新的发展。
- en: Thank you for supporting the work of our authors! If you enjoy the articles
    you read on TDS, consider [becoming a Medium member](https://bit.ly/tds-membership)
    — it unlocks our entire archive (and every other post on Medium, too).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你支持我们作者的工作！如果你喜欢你在TDS上阅读的文章，可以考虑[成为Medium会员](https://bit.ly/tds-membership)——这将解锁我们的整个档案（以及Medium上的所有其他帖子）。
- en: Until the next Variable,
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 直到下一个Variable，
- en: TDS Editors
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: TDS编辑团队
