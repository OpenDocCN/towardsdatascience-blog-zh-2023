- en: '3D Deep Learning Python Tutorial: PointNet Data Preparation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D深度学习Python教程：PointNet数据准备
- en: 原文：[https://towardsdatascience.com/3d-deep-learning-python-tutorial-pointnet-data-preparation-90398f880c9f](https://towardsdatascience.com/3d-deep-learning-python-tutorial-pointnet-data-preparation-90398f880c9f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/3d-deep-learning-python-tutorial-pointnet-data-preparation-90398f880c9f](https://towardsdatascience.com/3d-deep-learning-python-tutorial-pointnet-data-preparation-90398f880c9f)
- en: Hands-On Tutorial, Deep Dive, 3D Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实践教程，深度探讨，3D Python
- en: The Ultimate Python Guide to structure large LiDAR point cloud for training
    a 3D Deep Learning Semantic Segmentation Model with the PointNet Architecture.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 《终极Python指南：为PointNet架构训练3D深度学习语义分割模型而构建大型LiDAR点云》
- en: '[](https://medium.com/@florentpoux?source=post_page-----90398f880c9f--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----90398f880c9f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----90398f880c9f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----90398f880c9f--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----90398f880c9f--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@florentpoux?source=post_page-----90398f880c9f--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----90398f880c9f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----90398f880c9f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----90398f880c9f--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----90398f880c9f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----90398f880c9f--------------------------------)
    ·30 min read·May 31, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----90398f880c9f--------------------------------)
    ·30分钟阅读·2023年5月31日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/23e707b7b223e287573f055b8cbb2a60.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23e707b7b223e287573f055b8cbb2a60.png)'
- en: This creative illustration visually highlights how 3D Deep Learning could represent
    a top-down scene in a way it is easy to separate between classes. If you like
    these, contact [Marina Tünsmeyer](http://mimatelier.com/).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这张创意插图直观地突出了3D深度学习如何以易于分类的方式表现自上而下的场景。如果你喜欢这些，联系[Marina Tünsmeyer](http://mimatelier.com/)。
- en: 'The application field of 3D deep learning has snowballed in recent years. We
    have superb applications in various areas, including robotics, autonomous driving
    & mapping, medical imaging, and entertainment. When we look at the results, we
    are often awed (but not all the time 😁), and we may think: “I will use this model
    right now for my application!”. But unfortunately, the nightmare begins: 3D Deep
    Learning implementation. Even if new coding libraries aim at simplifying the process,
    implementing an end-to-end 3D Deep Learning model is a feat, especially if you
    are isolated in a dark corner of some gloomy cave.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，3D深度学习的应用领域迅速扩展。我们在机器人技术、自动驾驶与地图制作、医学成像和娱乐等各个领域都拥有卓越的应用。看到这些结果时，我们常常感到惊叹（但并非总是如此😁），我们可能会想：“我现在就要在我的应用中使用这个模型！”但不幸的是，噩梦开始了：3D深度学习的实现。即使新的编码库旨在简化这一过程，实现一个端到端的3D深度学习模型仍是一项壮举，尤其是当你孤身一人待在某个阴暗的角落时。
- en: '![](../Images/a17e508f9b1bc782eb13b6b65a6cde85.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a17e508f9b1bc782eb13b6b65a6cde85.png)'
- en: This is how it feels to code 3D Deep Learning. © F. Poux
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是编码3D深度学习的感觉。© F. Poux
- en: One of the most overlooked pain points in 3D deep learning frameworks is preparing
    the data to **be usable** by a selected learning architecture. I do not mean a
    nice research dataset but an actual (messy) data silo on which you want to develop
    an application. This is even steeper in the case of large and complex 3D point
    cloud datasets.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在3D深度学习框架中，最被忽视的痛点之一是将数据**准备好**以供选定的学习架构使用。我指的不是一个精美的研究数据集，而是一个实际的（混乱的）数据仓库，你想在其上开发应用程序。在大型且复杂的3D点云数据集的情况下，这个问题尤为严峻。
- en: 'Oh, but do you see where we are going with this article? You dreamed it (Don’t
    hide it, I know 😉), and we will cover it at the proper coding depth. This hands-on
    tutorial explores how to efficiently prepare 3D point clouds from an Aerial LiDAR
    campaign to be used with the most popular 3D deep learning point-based model:
    the PointNet Architecture.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，你是否明白我们要在这篇文章中探讨什么？你梦到了它（不要隐藏，我知道😉），我们将深入到适当的编码深度。这篇实践教程探讨了如何高效地准备从航空LiDAR活动中获得的3D点云，以用于最流行的基于点的3D深度学习模型：PointNet架构。
- en: We cover the entire data preparation pipeline, from 3D data curation to feature
    extraction and normalization. It provides the knowledge and practical Python skills
    to tackle real-world 3D Deep Learning problems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们涵盖了整个数据准备流程，从 3D 数据整理到特征提取和归一化。它提供了知识和实际的 Python 技能，以解决现实世界的 3D 深度学习问题。
- en: '![](../Images/5e3562ca370d6d278c11635d8b34757d.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e3562ca370d6d278c11635d8b34757d.png)'
- en: The PointNet Data Preparation Workflow for 3D Semantic Segmentation. © F. Poux
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: PointNet 数据准备工作流程用于 3D 语义分割。© F. Poux
- en: By following this tutorial, you will be able to apply these techniques to your
    own 3D point cloud datasets and use any of them to train a PointNet Semantic Segmentation
    model. Are you ready?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 通过跟随本教程，你将能够将这些技术应用到你自己的 3D 点云数据集上，并利用它们来训练 PointNet 语义分割模型。你准备好了吗？
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '🎵**Note to Readers***: This hands-on guide is part of a* [***UTWENTE***](https://www.itc.nl/)
    *joint work with my dear colleague* [***Prof. Sander Oude Elberink***](https://people.utwente.nl/s.j.oudeelberink)*.
    We acknowledge the financial contribution from the digital twins* [*@ITC*](http://twitter.com/ITC)
    *-project granted by the ITC faculty of the University of Twente.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 🎵**读者注意**：本实践指南是与我的亲爱的同事* [***UTWENTE***](https://www.itc.nl/) *合作的一部分* [***桑德·奥德·埃尔伯林克教授***](https://people.utwente.nl/s.j.oudeelberink)*。我们感谢来自数字双胞胎*
    [*@ITC*](http://twitter.com/ITC) *项目的财务支持，该项目由特温特大学 ITC 学院资助。*
- en: 3D Deep Learning Essentials
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D 深度学习要点
- en: 3D Semantic Segmentation VS Classification
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D 语义分割 VS 分类
- en: The fundamental difference between 3D semantic segmentation and classification
    for 3D point clouds is that segmentation aims to assign a label to each point
    in the point cloud. In contrast, classification seeks to assign a single label
    to the entire cloud.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 语义分割和 3D 点云分类的根本区别在于，分割旨在为点云中的每个点分配标签。而分类则试图为整个点云分配一个标签。
- en: '![](../Images/1f556b730b7907f9c25b9033d1c0c5b7.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f556b730b7907f9c25b9033d1c0c5b7.png)'
- en: The difference between the classification model and the semantic segmentation
    model. In both cases, we pass a point cloud, but for the classification task,
    the whole point cloud is the entity, whereas, in the Semantic Segmentation case,
    each point is an entity to classify. © F. Poux
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型与语义分割模型之间的区别。在这两种情况下，我们都传递一个点云，但对于分类任务，整个点云是一个实体，而在语义分割的情况下，每个点是一个需要分类的实体。©
    F. Poux
- en: For example, using the PointNet architecture, 3D point cloud classification
    involves passing the entire point cloud through the Network and outputting a single
    label representing the entire cloud. In contrast, the semantic segmentation “header”
    will assign a label to each point in the cloud. The difference in approach is
    because segmentation requires a more detailed understanding of the 3D space represented,
    as it seeks to identify and label individual objects or regions within the point
    cloud. In contrast, classification only requires a high-level understanding of
    the overall shape or composition of the point cloud.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用 PointNet 架构，3D 点云分类涉及将整个点云通过网络，并输出一个代表整个点云的标签。相比之下，语义分割的“头部”将为云中的每个点分配一个标签。方法的不同在于，分割需要对表示的
    3D 空间有更详细的理解，因为它试图识别和标记点云中的个体对象或区域。相比之下，分类仅需要对点云的整体形状或组成有较高层次的理解。
- en: Overall, while 3D semantic segmentation and classification are essential tasks
    for analyzing 3D point cloud data, the main difference is the level of detail
    and granularity required in the labeling process.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，尽管 3D 语义分割和分类是分析 3D 点云数据的关键任务，但主要区别在于标记过程所需的详细程度和粒度。
- en: And as you guessed it, we will attack semantic segmentation because it requires
    a more detailed understanding of the space being analyzed, which is so much fun
    😁.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你猜到的，我们将攻克语义分割，因为它需要对被分析的空间有更详细的理解，这非常有趣 😁。
- en: But before that, let us take a tiny step back to better grasp how PointNet Architecture
    works, shall we?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不过在此之前，让我们稍微回顾一下，以更好地理解 PointNet 架构的工作原理，好吗？
- en: 'PointNet: A Point-based 3D Deep Learning Architecture'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PointNet：一种基于点的 3D 深度学习架构
- en: Turning complex topics into small chunk-wise bits of knowledge is my specialty.
    But I must admit that, when touching upon 3D Deep Learning, the complexity of
    the function learned through the different processes within the neural Network
    and the empirical nature of hyper-parameter determination are important challenges.
    To overcome, hun? 😁
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将复杂的主题拆解成小块知识是我的专长。但是我必须承认，当涉及到 3D 深度学习时，通过神经网络中不同过程学到的函数的复杂性以及超参数确定的经验性特征是重要的挑战。要克服这些挑战，嗯？😁
- en: First, let us recap what PointNet is. PointNet is one of the pioneers in Neural
    Networks for 3D deep learning. If you understand PointNet, you can use all the
    other advanced models. But, of course, understanding is only a part of the equation.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回顾一下 PointNet 是什么。PointNet 是 3D 深度学习中神经网络的开创者之一。如果你理解了 PointNet，你就可以使用所有其他高级模型。但是，当然，理解只是方程的一部分。
- en: '![](../Images/977877dcb2d06fa1636fdd3356d96303.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/977877dcb2d06fa1636fdd3356d96303.png)'
- en: 'The PointNet Architecture has the ability to attack three semantization applications:
    Classification, Part-Segmentation, and Semantic Segmentation. © F. Poux'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: PointNet 架构能够处理三种语义应用：分类、部件分割和语义分割。© F. Poux
- en: The other part is making the scary thing work and extending it to use it with
    your data! And this is a challenging feat! Even for seasoned coders. Therefore,
    we divide into several parts the process. Today, it is about preparing the data
    so that we are sure we have something that works in real conditions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一部分是让这些复杂的东西发挥作用，并将其扩展到你的数据上！这是一项具有挑战性的任务！即使对于经验丰富的编码员也是如此。因此，我们将这个过程分为几个部分。今天，我们讨论的是准备数据，以确保我们在实际条件下有用的东西。
- en: To prepare the data correctly, it is essential to understand the building block
    of the Network. Let me give you the critical aspects of what to consider when
    preparing your data with the Network below.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确准备数据，理解网络的构建块是至关重要的。下面我将介绍在使用网络准备数据时需要考虑的关键方面。
- en: '![](../Images/4f3210ed58bfea5e2afda6856cb79faa.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f3210ed58bfea5e2afda6856cb79faa.png)'
- en: 'The PoinNet Model Architecture as described by the authors of the paper: [ArXiv
    Paper](https://arxiv.org/pdf/1612.00593.pdf).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 论文作者描述的 PointNet 模型架构：[ArXiv 论文](https://arxiv.org/pdf/1612.00593.pdf)。
- en: The architecture of PointNet consists of several layers of neural networks that
    process the point cloud data. The input to PointNet is a simple set of points,
    each represented by its 3D coordinates and additional features such as color or
    intensity. These points are fed into successive shared Multi-Layer Perceptron
    (MLP) network that learns to extract local features from each point.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: PointNet 的架构由几个处理点云数据的神经网络层组成。PointNet 的输入是一个简单的点集，每个点由其 3D 坐标和附加特征（如颜色或强度）表示。这些点被输入到连续的共享多层感知器（MLP）网络中，网络学习从每个点中提取局部特征。
- en: '![](../Images/2dd6409b2608bc0f614285a612ac89ed.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2dd6409b2608bc0f614285a612ac89ed.png)'
- en: 'The MLP in the PointNet Architecture as described by the authors of the paper:
    [ArXiv Paper](https://arxiv.org/pdf/1612.00593.pdf).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 论文作者描述的 PointNet 架构中的 MLP：[ArXiv 论文](https://arxiv.org/pdf/1612.00593.pdf)。
- en: '🦚 **Note**: *An MLP is a neural network of multiple layers of connected nodes
    or neurons. Each neuron in the MLP receives input from the neurons in the previous
    layer, applies a transformation to this input using weights and biases, and then
    passes the result to the neurons in the next layer. The weights and biases in
    the MLP are learned during training using backpropagation, which adjusts them
    to minimize the difference between the Network’s predictions and the true output.*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*MLP 是一个由多个层连接的节点或神经元构成的神经网络。MLP 中的每个神经元从上一层的神经元接收输入，利用权重和偏置对该输入进行变换，然后将结果传递给下一层的神经元。MLP
    中的权重和偏置在训练过程中通过反向传播学习，以最小化网络预测值与真实输出之间的差异。*
- en: These MLPs are fully connected layers, each followed by what we call “a non-linear
    activation function” (such as ReLU). The number of neurons in each layer (E.g.,
    64) and the number of layers themselves (E.g., 2) can be adjusted depending on
    the specific task and the complexity of the input point cloud data. As you can
    guess, the more neurons and layers, the more complex the targeted problem can
    be because of the combinatorial possibilities given by the architecture plasticity.
    If we continue to explore the PointNet architecture, we see that we describe the
    original n input points, with 1024 features that span from the initial ones provided
    (X, Y, and Z). This is where the architecture provides a global description of
    the input point cloud by using a max-pooling operation to the locally learned
    features to get a global feature vector that summarizes the entire point cloud.
    This global feature vector is then fed through several fully connected layers
    to produce the final output of the Classification head, i.e., the score for k
    classes.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 MLP 是全连接层，每一层后面跟着我们称之为“非线性激活函数”（如 ReLU）。每层的神经元数量（例如 64）和层数（例如 2）可以根据具体任务和输入点云数据的复杂性进行调整。正如你所猜测的，神经元和层数越多，目标问题可能越复杂，因为架构的可塑性带来了组合可能性。如果我们继续深入研究
    PointNet 架构，我们会看到我们用 1024 个特征描述原始的 n 个输入点，这些特征从最初提供的（X、Y 和 Z）中延展出来。这是架构通过使用最大池化操作对局部学习特征进行全局描述的地方，从而获得一个总结整个点云的全局特征向量。然后，这个全局特征向量会通过若干全连接层来生成分类头的最终输出，即
    k 类的评分。
- en: '![](../Images/cfccefae9c1356f71ebad1bb415fd7a1.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cfccefae9c1356f71ebad1bb415fd7a1.png)'
- en: 'The MaxPool and MLP of PoinNet Model Architecture as described by the authors
    of the paper: [ArXiv Paper](https://arxiv.org/pdf/1612.00593.pdf).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '由论文作者描述的 PoinNet 模型架构的 MaxPool 和 MLP: [ArXiv Paper](https://arxiv.org/pdf/1612.00593.pdf)。'
- en: If you notice closely, the semantic segmentation head in PointNet is a fully
    connected network that concatenates the global feature vector and the local feature
    vectors to produce a per-point score or label for each point in the input point
    cloud data. The semantic segmentation head consists of several fully connected
    layers with ReLU activation functions and a final softmax layer. The output of
    the final softmax layer represents the per-point probability distribution over
    the different semantic labels or classes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察，PointNet 中的语义分割头是一个全连接网络，它将全局特征向量和局部特征向量串联在一起，为输入点云数据中的每个点生成一个每点评分或标签。语义分割头由若干全连接层、ReLU
    激活函数和一个最终的 softmax 层组成。最终 softmax 层的输出代表不同语义标签或类别的每点概率分布。
- en: '![](../Images/91d55f8e974c16c23c108d75eb491b61.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91d55f8e974c16c23c108d75eb491b61.png)'
- en: 'The Segmentation Head of the PoinNet Model Architecture as described by the
    paper''s authors: [ArXiv Paper](https://arxiv.org/pdf/1612.00593.pdf).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '由论文作者描述的 PoinNet 模型架构的分割头: [ArXiv Paper](https://arxiv.org/pdf/1612.00593.pdf)。'
- en: The PointNet Architecture can capture important geometric and contextual information
    for tasks such as object classification and segmentation in 3D data by learning
    local and global features from each point in the input point cloud. One of the
    critical innovations of PointNet is using a symmetric function in the max-pooling
    operation, which ensures that the output is invariant to the order of the input
    points. This makes PointNet robust to variations in the ordering of the input
    points, which is essential in 3D data analysis.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: PointNet 架构能够捕捉任务如 3D 数据中的对象分类和分割所需的重要几何和上下文信息，通过从输入点云中的每个点学习局部和全局特征。PointNet
    的一个关键创新是在最大池化操作中使用对称函数，这确保了输出对输入点的顺序不变。这使得 PointNet 对输入点顺序的变化具有鲁棒性，这在 3D 数据分析中至关重要。
- en: Now, we are ready to attack heads on preparing the data for PointNet. Which
    point cloud do we mean in the beginning? Do we feed a complete point cloud?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备全力以赴地为 PointNet 准备数据。最开始我们指的是什么点云？我们是否输入一个完整的点云？
- en: 'PointNet: Data preparation key aspects'
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'PointNet: 数据准备的关键方面'
- en: 'On a high-level view, if we study the [original paper published](https://arxiv.org/pdf/1612.00593.pdf),
    we can see that PointNet functions in a very straightforward manner:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，如果我们研究[原始论文](https://arxiv.org/pdf/1612.00593.pdf)，我们可以看到 PointNet 的功能非常直接：
- en: We take a point cloud and normalize the data to a canonical space.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将点云数据规范化到标准空间。
- en: We compute a bunch of features (without ingesting our knowledge but by leveraging
    the network capabilities to create cool ones)
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们计算一系列特征（不依赖于我们已有的知识，而是利用网络的能力来创建有用的特征）
- en: We aggregate these features into a global signature for the considered cloud.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将这些特征汇聚成考虑中的点云的全局特征。
- en: '*Option 1*: we use this global signature to classify the point cloud'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选项 1*：我们使用这个全局特征来对点云进行分类'
- en: '*Option 2*: we combine this global signature with the local signature and build
    even sharper features for Semantic Segmentation.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选项 2*：我们将这个全局特征与局部特征结合，构建更精确的语义分割特征。'
- en: '![](../Images/7b517b55b4f933bf61007f4e08ab20f5.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b517b55b4f933bf61007f4e08ab20f5.png)'
- en: The five steps of PointNet towards either Semantic Segmentation or Classification
    tasks. © F. Poux
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: PointNet 在语义分割或分类任务中的五个步骤。© F. Poux
- en: It is all about features, meaning the chunk we provide the Network should be
    very relevant. E.g., giving the entire point cloud will not work, giving a tiny
    sample will not work, and giving structured samples with a different distribution
    than what will be fed will not work. So how do we do that?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都围绕特征展开，这意味着我们提供给网络的块应该非常相关。例如，给出整个点云是行不通的，给出一个微小的样本也是行不通的，提供具有不同分布的结构化样本也行不通。那么我们怎么做呢？
- en: Let us follow a linear ten-steps process to obtain well-thought 3D point cloud
    training/inference-ready datasets.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们遵循一个线性的十步流程，以获得经过深思熟虑的 3D 点云训练/推理准备数据集。
- en: '![](../Images/5e3562ca370d6d278c11635d8b34757d.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e3562ca370d6d278c11635d8b34757d.png)'
- en: The PointNet Data Preparation Workflow. © F. Poux
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: PointNet 数据准备工作流程。© F. Poux
- en: 'Step 1: Prepare your working environment'
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一步：准备你的工作环境
- en: '![](../Images/e5938db254abaaf0372ea2c43c7c6c0a.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5938db254abaaf0372ea2c43c7c6c0a.png)'
- en: 'In this article, we use two main components: CloudCompare and JupyterLab IDE
    (+ Python). For a detailed view of the best possible setup, I strongly encourage
    you to follow this article which goes into well-needed detail:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们使用两个主要组件：CloudCompare 和 JupyterLab IDE (+ Python)。对于最佳设置的详细视图，我强烈建议你参考这篇文章，它详细介绍了所需内容：
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)
    [## 3D Python 工作流程用于 LiDAR 城市模型：逐步指南'
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Python…
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解锁 3D 城市建模应用程序的终极指南。该教程涵盖了 Python…
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)'
- en: We will have a specific stack of libraries organized into main libraries, plotting
    libraries, and utility libraries.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将有一个特定的库栈，分为主要库、绘图库和实用库。
- en: '🦚 **Note**: *If you work in a local environment, I recommend for this tutorial
    to run pip for your package management* (pip install library_name)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*如果你在本地环境中工作，我建议本教程使用 pip 进行包管理*（pip install library_name）
- en: 'The two main libraries that we will use are NumPy and Pytorch:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的两个主要库是 NumPy 和 Pytorch：
- en: '**Numpy**: NumPy is a Python library for working with numerical data, and it
    provides functions for manipulating arrays and matrices, mathematical operations,
    and linear algebra functions.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Numpy**：NumPy 是一个用于处理数值数据的 Python 库，它提供了操作数组和矩阵、数学运算和线性代数函数的功能。'
- en: '**Pytorch**: Pytorch is a popular deep learning framework in Python. It provides
    tools for building and training neural networks and optimizing and evaluating
    models.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pytorch**：Pytorch 是一个流行的 Python 深度学习框架。它提供了构建和训练神经网络以及优化和评估模型的工具。'
- en: 'Then, we support these with two plotting libraries:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用两个绘图库来支持这些：
- en: '**Matplotlib**: Matplotlib is a Python library for creating visualizations
    such as plots, charts, and graphs.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib**：Matplotlib 是一个用于创建可视化图表、图形和图像的 Python 库。'
- en: '**Plotly**: Plotly is a Python library for creating **interactive** visualizations.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Plotly**：Plotly 是一个用于创建**交互式**可视化的 Python 库。'
- en: 'And finally, we will also use three utility modules:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还将使用三个实用模块：
- en: '**os**: The os module in Python provides a way of using operating system-dependent
    functionality. It provides functions for interacting with the file system, such
    as creating, deleting, and renaming files and directories.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**os**: Python中的os模块提供了一种使用操作系统相关功能的方法。它提供了与文件系统交互的函数，例如创建、删除和重命名文件和目录。'
- en: '**glob**: The glob module in Python provides a way of matching files and directories
    using patterns. For example, it can find all files with a specific extension in
    a directory.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**glob**: Python中的glob模块提供了一种使用模式匹配文件和目录的方法。例如，它可以在目录中找到所有具有特定扩展名的文件。'
- en: '**random** (Optional): The `random` library is a built-in module that provides
    functions for generating random numbers, selecting random items from a list, and
    shuffling sequences.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**random**（可选）：`random`库是一个内置模块，提供生成随机数、从列表中选择随机项和打乱序列的函数。'
- en: 'Once this is done, we are ready to get to the second aspect: Getting our hands
    on new 3D point cloud datasets!'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，我们就可以进入第二个方面：获取新的3D点云数据集！
- en: 'Step 2: 3D Data Curation'
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤2：3D数据整理
- en: '![](../Images/a5e20e985dd57cccb438a4637463b0d9.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a5e20e985dd57cccb438a4637463b0d9.png)'
- en: For this tutorial, we go east of the Netherlands, near Enschede, where the University
    of Twente shines 🌞. Here, we select a part of the AHN4 dataset, which would have
    a good proportion of trees, ground, buildings, and a bit of water as well 🚿. Let
    us say enough in a tile to have sufficient points for each class!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们前往荷兰东部，靠近恩斯赫德，那里有特温特大学的光芒🌞。在这里，我们选择了AHN4数据集的一部分，这部分数据应该有足够的树木、地面、建筑物以及一点水
    🚿。我们可以说每个类别都有足够的点！
- en: '🦚 **Note**: *We will train on imbalanced datasets, with a high predominance
    of ground points compared to the other classes. This is not an ideal scenario,
    where the MLP and semantic segmentation head may be biased towards predicting
    the majority class labels and ignore the minority class labels. This can result
    in inaccurate segmentation and misclassification of minority class points. Still,
    several techniques can be used to mitigate the effects of imbalanced classes,
    such as data augmentation, oversampling or undersampling of the minority class,
    and using weighted loss functions. This is for another time.* 😉'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '🦚 **注意**: *我们将在不平衡的数据集上进行训练，其中地面点的比例远高于其他类别。这不是理想的情况，在这种情况下，MLP和语义分割头可能会偏向于预测多数类别标签，而忽略少数类别标签。这可能导致不准确的分割和少数类别点的错误分类。不过，可以使用几种技术来减轻不平衡类别的影响，如数据增强、少数类别的过采样或欠采样，以及使用加权损失函数。这是另一个话题。*
    😉'
- en: 'To gather the dataset, we access the open data portal [geotiles.nl](https://geotiles.nl/).
    We zoom in onto a part of interest waiting to have the _XX (to have a data size
    coherent), and then, we download the .laz dataset, as illustrated below:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了收集数据集，我们访问开放数据门户 [geotiles.nl](https://geotiles.nl/)。我们缩放到一个感兴趣的区域，等待有_XX（以便数据量一致），然后下载.laz数据集，如下所示：
- en: '![](../Images/b1652f394039a471da8eebb3ae293dd6.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1652f394039a471da8eebb3ae293dd6.png)'
- en: Gathering a Point Cloud Dataset from the AHN4 LiDAR Campaign in the Netherlands.
    © F. Poux
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 从荷兰AHN4 LiDAR活动中收集点云数据集。© F. Poux
- en: Also, we can prepare some compelling use cases where you would like to test
    your model on tile(s) of interest later. This can be, for example, where you live
    if some open data is available there.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以准备一些引人注目的用例，以便你以后可以在感兴趣的切片上测试你的模型。例如，可以在你所在的地方，如果那里有开放数据。
- en: '🦚 **Note**: *If you want to put later on your model to a true challenge, downloading
    a tile in another land is a great generalization test! For example, you could
    download a* [*LiDAR HD*](https://geoservices.ign.fr/lidarhd) *point cloud tile
    to see the differences/improvements if used for training or testing.*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '🦚 **注意**: *如果你想对你的模型进行真正的挑战，下载另一个地区的切片是一个很好的泛化测试！例如，你可以下载一个* [*LiDAR HD*](https://geoservices.ign.fr/lidarhd)
    *点云切片，以查看如果用于训练或测试，是否会有差异/改进。*'
- en: 'Now that you have your point cloud in the .laz file format let us explore the
    characteristics given by the info file that you can also view or download:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有了.laz文件格式的点云，让我们探索info文件提供的特性，你也可以查看或下载：
- en: '![](../Images/8c7883e8cee2dad643b7fdd45639c294.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c7883e8cee2dad643b7fdd45639c294.png)'
- en: A Selected informational document on the selected 3D LiDAR Point Cloud dataset.
    © F. Poux
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一份关于选定3D LiDAR点云数据集的信息文件。© F. Poux
- en: This permits a good grasp of the data content, a crucial first step when building
    qualitative datasets.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于深入理解数据内容，这是构建高质量数据集时至关重要的第一步。
- en: '![](../Images/2cccf5613291347f8208381a21944c7b.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cccf5613291347f8208381a21944c7b.png)'
- en: This shows the content of the additional information on the point cloud. © F.
    Poux
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了点云的附加信息内容。© F. Poux
- en: 'As you scroll through the various information points, several fields are interesting
    to note:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览各种信息点时，有几个字段值得注意：
- en: '[PRE1]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This small file selection hints that we will deal with around 32 million data
    points for our experiments, which have colors, intensity, and a Near Infrared
    Field if we want to steepen our model later on.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小文件选择提示我们将处理大约3200万数据点，这些数据点具有颜色、强度，并且如果我们希望稍后提升模型，还可以具有近红外字段。
- en: Very nice! Now that we have the software stack installed and the 3D point cloud
    downloaded, we can jump onto a 3D Data Analysis to ensure the input fed to our
    model holds its promises.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 非常好！现在我们已经安装了软件堆栈并下载了3D点云，我们可以进行3D数据分析，以确保输入到模型中的数据符合预期。
- en: 'Step 3: 3D Data Analysis (CloudCompare)'
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤3：3D数据分析（CloudCompare）
- en: '![](../Images/ce5da5ed1260e2c915501f876ca57766.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce5da5ed1260e2c915501f876ca57766.png)'
- en: It is time to load the 3D aerial point cloud file into the software [CloudCompare](https://cloudcompare.org/).
    First, open CloudCompare on your computer until an empty GUI appears, which functions
    as shown below.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候将3D航空点云文件加载到软件[CloudCompare](https://cloudcompare.org/)中了。首先，在计算机上打开CloudCompare，直到出现空的GUI，如下所示。
- en: '![](../Images/5835e687656ac5c5a90468fe7fa06d51.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5835e687656ac5c5a90468fe7fa06d51.png)'
- en: 'The GUI of CloudCompare. Source: [learngeodata.eu](http://learngeodata.eu)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: CloudCompare的GUI。来源：[learngeodata.eu](http://learngeodata.eu)
- en: From there, we load the .laz file we downloaded by drag-drop and select some
    attributes from the menu that pops out on import, as illustrated below.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，我们通过拖放的方式加载下载的.laz文件，并在导入时从弹出的菜单中选择一些属性，如下图所示。
- en: '![](../Images/b203996c036f86e53f4b5ac0b5fd6e28.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b203996c036f86e53f4b5ac0b5fd6e28.png)'
- en: Importing a 3D Point Cloud in CloudCompare. We make sure to select relevant
    features to load. © F. Poux
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在CloudCompare中导入3D点云。我们确保选择相关特征进行加载。© F. Poux
- en: '🦚 **Note**: *We unselect all fields to pre-select some features that bring
    uncorrelated or low-correlated information and the labels for each point that
    hint at possible ground truth. We will thus only keep the intensity and classification
    field. Indeed, as we target Aerial point clouds, we want something that can generalize
    quite efficiently. Therefore, we aim at features likely found in unlabelled data
    that we want our model to perform on later. On top, the point cloud has RGB information,
    which is also a sound choice.*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*我们取消选择所有字段以预选一些带来不相关或低相关信息的特征以及每个点的标签，这些标签可能指示真实情况。因此，我们只保留强度和分类字段。确实，由于我们针对的是航空点云，我们希望选择能够高效泛化的特征。因此，我们的目标是选择在未标记的数据中可能找到的特征，以便我们后续的模型能够在这些数据上进行表现。此外，点云还具有RGB信息，这也是一个不错的选择。*
- en: 'At this stage, the **seven** selected features are the following: X, Y, and
    Z (spatial), R, G, B (radiometry), and intensity. On top, we keep the AHN4 labels
    per point from the Classification field of the .laz file. Once your 3D aerial
    point cloud is successfully imported into CloudCompare, we are ready for analysis
    and visualization. We can quickly review the two extra fields (intensity and classification)
    from the “`Object Properties panel` (3)”. If we study the intensity, we notice
    some outlier points that shift our feature vector a bit, as shown below.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一阶段，**七**个选定的特征如下：X、Y和Z（空间），R、G、B（辐射计），以及强度。此外，我们保留来自.laz文件分类字段的AHN4标签。成功将3D航空点云导入CloudCompare后，我们就准备好进行分析和可视化了。我们可以快速查看“`对象属性面板`（3）”中的两个额外字段（强度和分类）。如果我们研究强度，会发现一些离群点稍微偏移了我们的特征向量，如下所示。
- en: '![](../Images/307997f24d50733e36cbacf3eab5ff5e.png)![](../Images/2f693937a99497d559776950f99ad7e3.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/307997f24d50733e36cbacf3eab5ff5e.png)![](../Images/2f693937a99497d559776950f99ad7e3.png)'
- en: The Intensity-colored point cloud and the histogram of the repartition. © F.
    Poux
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 强度着色的点云及其分布直方图。© F. Poux
- en: This is the first observation we must address if we want to use this as an input
    feature for PointNet.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想将其用作PointNet的输入特征，这是我们必须解决的第一个观察点。
- en: Concerning the color values (Red, Green, Blue), they are obtained from another
    sensor, possibly at another time. Therefore, as they are merged from the available
    ortho imagery on the zone, we may have some precision/reprojection issues. But
    as you can imagine, having the ability to separate green elements from red ones
    should give us a clear indication of the probability a point belong to the vegetation
    class😁.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 关于颜色值（红色、绿色、蓝色），它们是从另一个传感器获得的，可能是在另一个时间。因此，由于它们是从该区域的现有正射影像中合成的，我们可能会遇到一些精度/重投影问题。但正如你所想，能够将绿色元素与红色元素分开应该能给我们一个清晰的指示，表明一个点属于植被类别的概率😁。
- en: '![](../Images/cf669bf4b9eaaa56b0230b3b0fae2209.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf669bf4b9eaaa56b0230b3b0fae2209.png)'
- en: The LiDAR dataset is colored with the ortho imagery to get R, G,B features.
    © F. Poux
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: LiDAR 数据集使用正射影像着色以获取 R、G、B 特征。© F. Poux
- en: We have a point cloud, with 32 million points expressed in a cartesian system
    (X, Y, Z), each having an intensity feature and colors (Red, Green, and Blue).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个点云，其中包含3200万个点，以笛卡尔坐标系（X，Y，Z）表示，每个点都有强度特征和颜色（红色、绿色和蓝色）。
- en: '🦚 **Note**: *You can save this stage for later, as you may have a vast choice
    of features such as the one illustrated below, which is the Near InfraRed (NIR)
    Channel available on the dataset. For example, this is a convenient field that
    can highlight healthy (or not) vegetation.* 😉'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*你可以将这个阶段留到后面，因为你可能会有许多选择的特征，例如下面所示的近红外（NIR）通道，它在数据集中是可用的。例如，这是一个方便的字段，可以突出显示健康（或不健康）的植被。*
    😉
- en: '![](../Images/dfe86ac1fc5d20e6293eb31f7c43f894.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfe86ac1fc5d20e6293eb31f7c43f894.png)'
- en: The Near Infrared feature. © F. Poux
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 近红外特征。© F. Poux
- en: We have another last scalar field if you scroll the available ones. The Classification
    field, of course! And this is very handy to help us create a labeled dataset to
    avoid going from scratch (thank you OpenData ! 👌)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你滚动可用的字段，我们还有另一个最后的标量字段。分类字段，当然！这对于帮助我们创建标注数据集非常方便，以避免从零开始（感谢开放数据！👌）
- en: '![](../Images/4c87a229f0f68f78c29dcf7b5429bcfc.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c87a229f0f68f78c29dcf7b5429bcfc.png)'
- en: The provided classification. © F. Poux
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的分类。© F. Poux
- en: '🦚 **Note**: *For the sake of pedagogical training, we will consider the classification
    the ground truth for the rest of the tutorial. However, know that the classification
    was achieved with some uncertainty and that if you want the best-performing model,
    have to be fixed. Indeed, there is a famous saying with 3D Deep Learning: Garbage
    in = Garbage out. Therefore, the quality of your data should be paramount.*'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*出于教学培训的目的，我们将考虑将分类作为教程剩余部分的真实情况。然而，请知道分类是有一定不确定性的，如果你想要最好的模型，必须修正它。确实，有一句著名的3D深度学习格言：垃圾进=垃圾出。因此，数据的质量应该是首要的。*
- en: Let’s focus on refining the labeling phase.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于精炼标注阶段。
- en: Step 4\. 3D Data Labelling (Labels Concatenation)
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4步：3D 数据标注（标签连接）
- en: '![](../Images/b068f5f131c82160cb08b76f3f9f291b.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b068f5f131c82160cb08b76f3f9f291b.png)'
- en: Okay, so before jumping in on this step, I must say something. 3D point cloud
    labeling to train a supervised 3D semantic segmentation learning model is a (painfully)
    manual process. The goal is to assign labels to individual points in a 3D point
    cloud. The main critical objective of this process includes identifying the target
    objects in the point cloud, selecting the appropriate labeling technique, and
    ensuring the accuracy of the labeling process.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，在进入这个步骤之前，我必须说点什么。3D 点云标注用于训练有监督的 3D 语义分割学习模型是一个（痛苦的）手动过程。目标是为 3D 点云中的单个点分配标签。这个过程的主要关键目标包括识别点云中的目标物体、选择合适的标注技术，并确保标注过程的准确性。
- en: '![](../Images/3e191ebfd0b0200319a3fa40a6bd9096.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e191ebfd0b0200319a3fa40a6bd9096.png)'
- en: 'An example of a labeling process: labeling clusters VS labeling individual
    points. © F. Poux'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 标注过程的一个示例：标注簇与标注单个点。© F. Poux
- en: To identify the objects or regions in the point cloud that require labeling,
    we manually inspect the cloud or by using algorithms that automatically detect
    particular objects or regions based on their features, such as size, shape, or
    color.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 要识别点云中需要标注的物体或区域，我们可以手动检查云，或者使用基于特征（如大小、形状或颜色）自动检测特定物体或区域的算法。
- en: '[](https://learngeodata.eu/?source=post_page-----90398f880c9f--------------------------------)
    [## 3D Academy - Point Cloud Online Course'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://learngeodata.eu/?source=post_page-----90398f880c9f--------------------------------)
    [## 3D Academy - 点云在线课程'
- en: The best 3D Online Courses for Teachers, Researchers, Developers, and Engineers.
    Master 3D Point Cloud Processing and…
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为教师、研究人员、开发人员和工程师提供的最佳3D在线课程。掌握3D点云处理及……
- en: learngeodata.eu](https://learngeodata.eu/?source=post_page-----90398f880c9f--------------------------------)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[learngeodata.eu](https://learngeodata.eu/?source=post_page-----90398f880c9f--------------------------------)'
- en: 'In our case, we start with an advantage: the point cloud is already classified.
    The first step is thus to extract each class as an independent point cloud, as
    illustrated below.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们有一个优势：点云已经被分类。因此，第一步是将每个类别提取为独立的点云，如下图所示。
- en: '![](../Images/a96b31c90a448c3ff94dff8288789a7c.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a96b31c90a448c3ff94dff8288789a7c.png)'
- en: First, we select the point cloud and switch the “colors” property from RGB to
    Scalar Field. We then ensure we visualize the Classification Scalar Field. From
    there, we go to EDIT > Scalar Field > Split Cloud by Integer Value, resulting
    in one point cloud per class in the point cloud.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们选择点云并将“颜色”属性从RGB切换到标量场。然后确保我们可视化分类标量场。从那里，我们转到EDIT > Scalar Field > Split
    Cloud by Integer Value，从而在点云中为每个类别生成一个点云。
- en: 'From the various classes that we get as clouds, we see that :'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们得到的各种点云类别中，我们可以看到：
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: From there, we can rework `class 1 = vegetation + clutter`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，我们可以重新处理`class 1 = vegetation + clutter`。
- en: The appropriate labeling technique must be selected based on the specific task
    and the available data. For example, we can use an unsupervised technique for
    more exploratory analysis and iteratively take some color thresholding by selecting
    candidate points in the vegetation, as illustrated below.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 必须根据特定任务和可用数据选择合适的标记技术。例如，我们可以使用无监督技术进行更多的探索性分析，并通过选择植被中的候选点来进行一些颜色阈值处理，如下图所示。
- en: '![](../Images/522101de53d3a12b1147e36185ae82c9.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/522101de53d3a12b1147e36185ae82c9.png)'
- en: Segmenting the point cloud based on color information, in order to create sharper
    labels in a semi-automatic fashion. © F. Poux
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 根据颜色信息对点云进行分割，以半自动化的方式创建更精确的标签。© F. Poux
- en: This will give inaccurate results but may speed up manually selecting any point
    that belongs to the vegetation.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给出不准确的结果，但可能会加快手动选择属于植被的任何点。
- en: Finally, ensuring the accuracy of the labeling process is critical for producing
    reliable results. This can be achieved through manual verification or quality
    control techniques such as cross-validation or inter-annotator agreement.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，确保标签过程的准确性对于产生可靠结果至关重要。这可以通过手动验证或质量控制技术，如交叉验证或标注者一致性，来实现。
- en: '🦚 **Note**: *It is good to grasp the jargon, but do not be scared. These concepts
    can be covered at a later stage. One thing at a time.* 😉'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*了解术语是好的，但不要害怕。这些概念可以在后续阶段覆盖。一件事一次完成。* 😉
- en: 'Ultimately, the labeling process’s accuracy will directly impact subsequent
    tasks’ performance, incl. 3D Semantic Segmentation. In our case, we organize the
    data as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，标签过程的准确性将直接影响后续任务的表现，包括3D语义分割。在我们的案例中，我们将数据组织如下：
- en: '[PRE3]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We execute this within CloudCompare.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在CloudCompare中执行此操作。
- en: '![](../Images/13bdd0ee2f63786bb858e28b0590edd6.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13bdd0ee2f63786bb858e28b0590edd6.png)'
- en: Organization of the various classes within CloudCompare. © F. Poux
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在CloudCompare中组织各种类别。© F. Poux
- en: After renaming for clarity our different clouds (initialization), we will (1)
    fuse the clutter in one single cloud, (2) delete the Classification field for
    all the clouds, (3) recreate a classification field with the new numbering, (4)
    clone all the clouds and (5) merge the cloned clouds, as shown below.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在为清晰度重命名我们的不同点云（初始化）后，我们将（1）将杂乱物体合并为一个单独的点云，（2）删除所有点云的分类字段，（3）用新的编号重新创建分类字段，（4）克隆所有点云，（5）合并克隆点云，如下所示。
- en: '![](../Images/9246ba132e80e03851d3b68b13f5ba5c.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9246ba132e80e03851d3b68b13f5ba5c.png)'
- en: Initial preparation of our labels into the new point cloud. © F. Poux
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 初步准备我们的标签进入新的点云。© F. Poux
- en: '![](../Images/2984926c752b2b5391615bda185f70c3.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2984926c752b2b5391615bda185f70c3.png)'
- en: The Data Preparation Phase is Executed within CloudCompare. © F. Poux
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备阶段在CloudCompare中执行。© F. Poux
- en: Now, we have a labeled dataset with a specific point label repartition.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个带标签的数据集，并具有特定的点标签分布。
- en: '![](../Images/f3252ee1a485053c68189023813c73c5.png)![](../Images/d15e1321ad392c59e82714c17eb58ac8.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f3252ee1a485053c68189023813c73c5.png)![](../Images/d15e1321ad392c59e82714c17eb58ac8.png)'
- en: We notice that out of our 32,080,350 points, 23,131,067 belong to the ground
    (72%), 7,440,825 to the vegetation (23%), 1,146,575 to buildings (4%), 191,039
    to water (less than 1%), and the remaining 170,844 are not labeled (class 0).
    This will be very interesting because we are in this specific imbalance case with
    predominant classes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，在32,080,350个点中，23,131,067个属于地面（72%），7,440,825个属于植被（23%），1,146,575个属于建筑物（4%），191,039个属于水体（不到1%），剩余的170,844个未标记（类别0）。这将非常有趣，因为我们处于这个特定的不平衡情况中，具有主导类别。
- en: Now that we have analyzed what our point cloud contains and refined the labels,
    we can dive into feature selection.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经分析了点云的内容并细化了标签，我们可以*深入*进行特征选择。
- en: Step 5\. 3D Feature Selection
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5步。3D特征选择
- en: '![](../Images/e2b0c2ad5eedfee4eb23e276a88572b8.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2b0c2ad5eedfee4eb23e276a88572b8.png)'
- en: When using the PointNet architecture for 3D point cloud semantic segmentation,
    feature selection is essential in preparing the data for training.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用PointNet架构进行3D点云语义分割时，特征选择对于准备训练数据至关重要。
- en: In traditional machine learning methods, feature engineering is often required
    to select and extract relevant features from the data. However, this step can
    be avoided with deep learning methods like PointNet since the model can learn
    to extract features from the data automatically.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统机器学习方法中，通常需要特征工程来选择和提取数据中的相关特征。然而，使用PointNet等深度学习方法可以避免这一步骤，因为模型可以自动学习从数据中提取特征。
- en: 'However, ensuring that the input data contains the necessary information for
    the model to learn relevant and deducted features is still essential. We use seven
    features: `X`, `Y`, `Z` (spatial attributes), `R`, `G`, `B` (radiometric attributes),
    and the intensity `I` (LiDAR-derived).'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，确保输入数据包含模型学习相关和推导特征所需的信息仍然很重要。我们使用七个特征：`X`、`Y`、`Z`（空间属性）、`R`、`G`、`B`（辐射属性）和强度`I`（激光雷达衍生）。
- en: '[PRE4]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This is our reference. It means that we will build our model with this input,
    and any other dataset we would like to process with the trained PointNet model
    must contain these same features. Before moving within Python, the last step is
    to structure the data according to the Architecture specifications.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的参考。这意味着我们将使用这个输入来构建模型，任何我们希望用训练好的PointNet模型处理的其他数据集必须包含这些相同的特征。在进入Python之前，最后一步是根据架构规范结构化数据。
- en: Step 6\. Data Structuration (Tiling)
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6步。数据结构化（瓦片化）
- en: '![](../Images/42c2dea08aaaf1a4b1414d386c5aa486.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42c2dea08aaaf1a4b1414d386c5aa486.png)'
- en: For several reasons, structuring a 3D point cloud into square tiles is essential
    when processing it with the neural network architecture PointNet.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 由于几个原因，在使用神经网络架构PointNet处理3D点云时，将其结构化为正方形瓦片是必要的。
- en: '![](../Images/201d5711e9e23692b603a0205f583a20.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/201d5711e9e23692b603a0205f583a20.png)'
- en: The tile definition within this workflow is to train PointNet 3D Deep Learning
    Architecture. © F. Poux
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在此工作流中的瓦片定义是训练PointNet 3D深度学习架构。© F. Poux
- en: First, PointNet requires the input data to be of fixed size, meaning that all
    input samples should have the same number of points. By dividing a 3D point cloud
    into square tiles, we can ensure that each tile has a more homogeneous number
    of points, allowing PointNet to process them consistently and effectively without
    the extra overhead or unreversible loss when sampling to the final fixed-point
    number.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，PointNet要求输入数据为固定大小，这意味着所有输入样本应具有相同数量的点。通过将3D点云分割成正方形瓦片，我们可以确保每个瓦片具有更均匀的点数量，使PointNet能够一致有效地处理它们，而不会在采样到最终固定点数时产生额外开销或不可逆损失。
- en: '![](../Images/40b8d89038937bdcdf14757276160636.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40b8d89038937bdcdf14757276160636.png)'
- en: Example of the impact of sampling strategies on the 3D Point Cloud dataset.
    © F. Poux
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 采样策略对3D点云数据集的影响示例。© F. Poux
- en: '🌱 **Growing**: *With PointNet, we need to have the input tile to a fixed number
    of points, recommended at 4096 points by the original paper’s authors. This means
    that a sampling strategy will be needed (****which is not done in CloudCompare****).
    As you can see from the illustration above, sampling the point cloud with different
    strategies will yield different results and object identification capabilities
    (E.,g. the electrical pole on the right). Do you think this impacts the 3D Deep
    Learning architecture performances?*'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 🌱 **增长**：*使用PointNet时，我们需要将输入瓦片固定为推荐的4096个点。这意味着需要一种采样策略（****CloudCompare中未实现****）。如上图所示，使用不同策略对点云进行采样将产生不同的结果和物体识别能力（例如右侧的电线杆）。你认为这会影响3D深度学习架构的性能吗？*
- en: Secondly, PointNet’s architecture involves a shared multi-layer perceptron (MLP)
    applied to each point independently, which means that the Network processes each
    point in isolation from its neighbors. By structuring the point cloud into tiles,
    we can preserve the local context of each point within its tile while still allowing
    the Network to process points independently, enabling it to extract some meaningful
    features from the data.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，PointNet的架构涉及应用于每个点的共享多层感知机（MLP），这意味着网络在处理每个点时是独立的，不考虑其邻居。通过将点云结构化为瓦片，我们可以在保持每个点局部上下文的同时，让网络独立处理点，从而从数据中提取有意义的特征。
- en: '![](../Images/3ecdd116091d1b33e4c152f15903a4f1.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ecdd116091d1b33e4c152f15903a4f1.png)'
- en: The resulting 3D point cloud tile. © F. Poux
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的3D点云瓦片。© F. Poux
- en: Finally, structuring the 3D point cloud into tiles can also improve the computational
    efficiency of the neural Network, as it allows for parallel processing of the
    tiles, reducing the overall processing time required to analyze the entire point
    cloud (on GPU).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将3D点云结构化为瓦片也可以提高神经网络的计算效率，因为它允许对瓦片进行并行处理，从而减少分析整个点云所需的总体处理时间（在GPU上）。
- en: We use the “Cross Section” tool (1) to achieve this feat. We set up the size
    to 100 meters (2), we then shift along X and Y (minus) to get as close as possible
    to the lowest corner of the initial tile (3), we use the multiple slice button
    (4), we repeat along and Y axis (5) and get the resulting square tiles (6), as
    shown below.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用“横截面”工具（1）来实现这一目标。我们将大小设置为100米（2），然后沿X轴和Y轴（负方向）移动，以尽可能接近初始瓦片的最底部角落（3），我们使用多个切片按钮（4），沿X轴和Y轴重复（5），得到最终的方形瓦片（6），如下所示。
- en: '![](../Images/aa7854693120b84501c12c0d7faca466.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa7854693120b84501c12c0d7faca466.png)'
- en: The process to automate the tile creation within CloudCompare. © F. Poux
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化瓦片创建过程在CloudCompare中。© F. Poux
- en: '![](../Images/3b33c2155b7469d98c831fd5aa8d380c.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b33c2155b7469d98c831fd5aa8d380c.png)'
- en: The live process to automate the tile creation within CloudCompare. © F. Poux
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化瓦片创建过程在CloudCompare中。© F. Poux
- en: This allows defining tiles of approximately one hundred meters by one hundred
    meters along X and Y axes. We obtain 143 tiles, from which we discard the last
    13 tiles, as they could be more representative of what we want our input to be
    (i.e., they are not square because they are on the edge). With the remaining 130
    tiles, we choose a good (around 20%) of representative tiles (holding Shift +
    Selection), as shown below.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许定义大约一百米乘一百米的瓦片，沿X轴和Y轴。我们获得了143个瓦片，其中抛弃了最后13个瓦片，因为它们可能更能代表我们希望输入的内容（即，它们不是方形，因为它们位于边缘）。在剩下的130个瓦片中，我们选择了大约20%具有代表性的瓦片（按住Shift
    + 选择），如下所示。
- en: '![](../Images/61b8548c1516f4385b7d17717237774f.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61b8548c1516f4385b7d17717237774f.png)'
- en: Selection and manual split into training and testing set for PointNet. © F.
    Poux
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对PointNet进行的选择和手动分割训练集和测试集。© F. Poux
- en: '🌱 **Growing**: *We split our data between training and testing following an
    80/20 percent scheme. At this stage, what do you think about this approach? What
    would be, in your opinion, a good strategy?*'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 🌱 **增长**：*我们按照80/20的比例将数据分为训练集和测试集。在这个阶段，你怎么看这种方法？你认为什么样的策略比较好？*
- en: At the end of this process, we have around 100 tiles in the train set and 30
    tiles in the test set, each holding the original number of points. We then select
    one folder and export each tile as an ASCII file, as shown below.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，我们在训练集和测试集中分别拥有约100个瓦片和30个瓦片，每个瓦片都保留了原始点数。然后，我们选择一个文件夹，将每个瓦片导出为ASCII文件，如下所示。
- en: '![](../Images/cc137efa069ddc07435b100aa870e872.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc137efa069ddc07435b100aa870e872.png)'
- en: Exporting the point cloud tiles to use with PointNet
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 将点云瓦片导出以供PointNet使用
- en: '🦚 **Note**: *CloudCompare allows to export all the point clouds independently
    within a directory when choosing to export as an ASCII file. He will automatically
    indent after the last character, using a “*`*_*`*” character to ensure consistency.
    This is very handy and can be used/abused.*'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*CloudCompare 允许在选择以 ASCII 文件格式导出时，将所有点云独立导出到一个目录中。它会在最后一个字符之后自动缩进，使用“*`*_*`*”字符以确保一致性。这非常方便，可以使用/滥用。*
- en: Structuring a 3D point cloud into square tiles is an essential preprocessing
    step when using PointNet. It allows for consistent input data size, preserves
    local context, and improves computational efficiency, all of which contribute
    to more accuracy and efficient processing of the data. This is the final step
    before moving on to 3D Python 🎉.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 将 3D 点云结构化为方形瓦片是使用 PointNet 时的一个重要预处理步骤。它允许输入数据大小的一致性，保留局部上下文，并提高计算效率，这些都有助于更准确和高效的数据处理。这是进入
    3D Python 🎉之前的最后一步。
- en: Step 7\. 3D Python Data Loading
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7步。3D Python 数据加载
- en: '![](../Images/e1aae6522def0e1a19d8596c449407f2.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1aae6522def0e1a19d8596c449407f2.png)'
- en: It is time to ingest the point cloud tiles in Python.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候在 Python 中处理点云瓦片了。
- en: 'For this, we import the libraries that we need. If you use the Google Colab
    version accessible here: 💻 Google Colab Code, then it is important to run the
    first line as shown below:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们导入所需的库。如果你使用的是可以在这里访问的 Google Colab 版本：💻 Google Colab Code，那么重要的是要运行下面所示的第一行：
- en: '[PRE5]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For any setup, we have to import the various libraries as illustrated below:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何设置，我们必须导入下述各种库：
- en: '[PRE6]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Great! From there, we split the datafile names in our respective folders in
    `pointcloud_train_files`, and `pointcloud_test_files`
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！从这里开始，我们将数据文件名拆分到各自的文件夹中，`pointcloud_train_files`和`pointcloud_test_files`
- en: '[PRE7]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '🦚 **Note**: *we have two folders in our explorer: the train folder, and the
    test folder, both in the* `AHN4_33EZ2_12` *folder. What we do here is first to
    give the path to the root folder, and then, we will collect with glob all the
    files in train and test with the* `***` *that means “*`select all.”` *A convenient
    way to deal with multiple files!*'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*我们在资源管理器中有两个文件夹：训练文件夹和测试文件夹，均在* `AHN4_33EZ2_12` *文件夹中。我们在这里做的是首先指定根文件夹的路径，然后用
    glob 收集训练和测试中的所有文件，使用* `***` *表示“*`选择所有`”。*一种处理多个文件的便捷方法！*
- en: 'At this step, two variables hold the paths to all the tiles we prepared. To
    ensure that this is correct, we can print one element taken randomly from a 0
    to 20 random distribution:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，两个变量保存了我们准备好的所有瓦片的路径。为了确保这一点，我们可以打印从0到20的随机分布中随机选取的一个元素：
- en: '[PRE8]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Great, so what we can do, is thus to split further our dataset into three variables:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，所以我们可以进一步将数据集拆分成三个变量：
- en: '**valid_list**: This holds the validation data paths. The validation split
    helps to improve the model performance by fine-tuning the model after each epoch.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**valid_list**：这保存了验证数据路径。验证拆分通过在每个训练周期后微调模型来帮助提高模型性能。'
- en: '**train_list**: This holds the training data paths, which is the data set on
    which the training takes place.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**train_list**：这保存了训练数据路径，即用于训练的数据集。'
- en: '**test_list**: This holds the test data paths. The test set informs us about
    the final accuracy of the model after completing the training phase'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**test_list**：这保存了测试数据路径。测试集告知我们模型在完成训练阶段后的最终准确性。'
- en: This is done using the friendly numpy functions that work on the array indexes
    from the list. Indeed, we randomly extract 20% from the `pointcloud_train_files`,
    then split what is retained for validation vs. what is not retained and constitutes
    the `train_list` variable.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过友好的 numpy 函数完成的，这些函数作用于列表中的数组索引。实际上，我们随机提取了`pointcloud_train_files`中的20%，然后将保留的部分与未保留的部分进行分割，后者构成了`train_list`变量。
- en: '[PRE9]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We then randomly study the properties of one data file by looking at the median,
    the standard deviation, and the min-max values with the following snippet:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过查看中位数、标准差和最小-最大值来随机研究一个数据文件的属性，使用以下代码片段：
- en: '[PRE10]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Which gives:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生：
- en: '[PRE11]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As we can notice, there is one central element that we have to address: data
    normalization. Indeed, so to avoid any mismatch, we need to be in this “canonical
    space,” which means we can replicate the same experimental context in the feature
    space. Using a T-Net would be like killing a fly 🪰 with a bazooka. This is fine,
    but if we can avoid and use an actual coherent approach, it would be smarter 😁.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所注意到的，有一个核心问题需要解决：数据归一化。确实，为了避免任何不匹配，我们需要处于这种“规范空间”，这意味着我们可以在特征空间中复制相同的实验环境。使用T-Net就像用火箭筒🪰杀苍蝇。这是可以的，但如果我们可以避免并使用实际一致的方法，那将更聪明😁。
- en: Step 8\. 3D Python Normalization
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 8\. 3D Python 归一化
- en: '![](../Images/5ed3e236dc6c9533e86a3b7760f58254.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ed3e236dc6c9533e86a3b7760f58254.png)'
- en: Normalizing a 3D point cloud tile before feeding it to the PointNet architecture
    is crucial for three main reasons. First, normalization ensures that the input
    data is centered around the origin, which is essential for PointNet’s architecture
    which applies an MLP to each point independently. The MLP is more effective when
    the input data is centered around the origin, which allows for more meaningful
    feature extraction and better overall performance.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在将3D点云瓦片输入到PointNet架构之前进行归一化至关重要，主要有三个原因。首先，归一化确保输入数据围绕原点中心，这对于PointNet的架构至关重要，因为它对每个点独立应用MLP。当输入数据围绕原点中心时，MLP更有效，这使得特征提取更有意义，整体性能更好。
- en: '![](../Images/e7e59d8169a06fc63c88463815748d87.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7e59d8169a06fc63c88463815748d87.png)'
- en: Illustration of the normalization impact on the results of training 3D Deep
    Learning Models. © F. Poux
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化对训练3D深度学习模型结果的影响示意图。© F. Poux
- en: '🌱 **Growing**: *Some sort of intuition is also good before normalizing bluntly.
    For example, we predominantly use gravity-based scenes, meaning that the Z-axis
    is almost always colinear to the Z-axis. Therefore, how would you approach this
    normalization?*'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 🌱 **成长**：*在盲目归一化之前，有些直觉也是有益的。例如，我们主要使用基于重力的场景，这意味着Z轴几乎总是与Z轴共线。因此，你会如何处理这种归一化？*
- en: Secondly, normalization scales the point cloud data to a consistent range, which
    helps prevent saturation of the activation functions within the MLP. This allows
    the Network to learn from the entire range of input values, improving its ability
    to accurately classify or segment the data.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，归一化将点云数据缩放到一致的范围，这有助于防止MLP中的激活函数饱和。这使得网络能够从整个输入值范围中学习，提高了准确分类或分割数据的能力。
- en: '![](../Images/e4f256a4ace3ba7acdfac220fe4cdac1.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4f256a4ace3ba7acdfac220fe4cdac1.png)'
- en: The problem with [0,1] scaling illustrated on the intensity field of 3D point
    clouds. © F. Poux
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在3D点云的强度场上说明[0,1]缩放的问题。© F. Poux
- en: Finally, normalization can help reduce the impact of different scales in the
    point cloud data, which can be caused by differences in sensor resolutions or
    distances from the scanned objects (which is a bit flattened in the case of Aerial
    LiDAR data). This improves the consistency of the data and the Network’s ability
    to extract meaningful features from it.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，归一化有助于减少点云数据中不同尺度的影响，这可能是由于传感器分辨率或扫描物体的距离差异（在航拍LiDAR数据中有所平坦化）。这提高了数据的一致性和网络从中提取有意义特征的能力。
- en: 'Okay, let us get on it. For our experiments, we will first capture the minimum
    value of the features in `min_f`, and the average in `mean_f`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们开始吧。对于我们的实验，我们将首先捕捉特征的最小值`min_f`和平均值`mean_f`：
- en: '[PRE12]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '🦚 **Note**: *We transposed our dataset to handle the data and the indexes much
    more efficiently and conveniently. Therefore, to take the* `X-axis` *elements
    of the point cloud, we can just pass* `cloud_data[0]` *instead of* `cloud_data[:,0]`*,
    which involves a bit of overhead.*'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*我们对数据集进行了转置，以更高效、便捷地处理数据和索引。因此，要获取点云的* `X-axis` *元素，我们可以直接使用* `cloud_data[0]`
    *而不是* `cloud_data[:,0]`*，这样可以减少一些开销。*
- en: 'We will now normalize the different features to use in our PointNet networks.
    First, the spatial coordinates X, Y, and Z. We will center our data on the planimetric
    axis (X and Y) and ensure that we subtract the minimal value of Z to account for
    discrimination between roofs and ground, for example:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将对不同的特征进行归一化，以用于我们的PointNet网络。首先是空间坐标X、Y和Z。我们将把数据中心化到平面坐标轴（X和Y），并确保减去Z的最小值，以区分屋顶和地面，例如：
- en: '[PRE13]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Great, now we can scale our colors by ensuring we are in a [0,1] range. This
    is done by dividing the max value (255) for all our colors:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，现在我们可以通过确保我们在[0,1]范围内来缩放我们的颜色。这是通过将所有颜色的最大值（255）进行除法实现的：
- en: '[PRE14]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, we will attack the normalization of the intensity feature. Here, we
    will work with quantiles to obtain a normalization robust to outliers, as we saw
    when exploring our data. This is done in a three-stage process. First, we compute
    the interquartile difference `IQR`, which is the difference between the 75th and
    25th quantile. Then we subtract the median from all the observations and divide
    by the interquartile difference. Finally, we subtract the minimum value of the
    intensity to have a significant normalization:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将处理强度特征的归一化。在这里，我们将使用分位数来获得对异常值具有鲁棒性的归一化，就像我们在探索数据时看到的那样。这是通过三个阶段的过程完成的。首先，我们计算四分位差`IQR`，即第
    75 个分位数和第 25 个分位数之间的差值。然后我们从所有观测值中减去中位数，并除以四分位差。最后，我们减去强度的最小值，以获得显著的归一化：
- en: '[PRE15]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Wonderful! At this stage, we have a point cloud normalized and ready to be fed
    to a PointNet architecture. But automating this process is the next logical step
    to execute this on all the tiles.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！在这一阶段，我们已经有了一个归一化的点云，准备好输入 PointNet 架构。但是自动化这个过程是执行所有瓦片的下一步逻辑步骤。
- en: Creating a Point Cloud Tile Load and Normalize function
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个点云瓦片加载和归一化函数
- en: 'We create a function `cloud_loader` that takes as input the path to a tile
    `tile_path`, and a string of features used, `features_used`, and outputs a `cloud_data`
    variable, which holds the normalized features, along with its ground-truth variable
    `gt` that holds the labels of each point. The function will act as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个函数`cloud_loader`，它以一个瓦片路径`tile_path`和一个用于的特征字符串`features_used`作为输入，并输出一个`cloud_data`变量，其中包含归一化特征，以及一个真实标签变量`gt`，其中包含每个点的标签。该函数将如下操作：
- en: '![](../Images/8098b012294e7a76b4bb61349c8e7bbd.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8098b012294e7a76b4bb61349c8e7bbd.png)'
- en: The definition of a cloud loading function to process point cloud datasets and
    make them ready for training. © F. Poux
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个云加载函数来处理点云数据集，并使其准备好用于训练。© F. Poux
- en: 'This translates into a simple `cloud_loader` function, as shown below:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这转换为一个简单的`cloud_loader`函数，如下所示：
- en: '[PRE16]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This function is now used to obtain both point cloud features and labels as
    follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数现在用于获取点云特征和标签，如下所示：
- en: '[PRE17]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '🌱 **Growing**: *As you can see, we pass a string for the features. This is
    very convenient for our different ‘*`*if*`*’ tests indeed. However, note that
    we do not return errors if what is fed to the function is not expected. This is
    not a standard code practice, but this extends the scope of this tutorial*. *I
    recommend checking out PEP-8 guidelines if you want to start with beautiful code
    writing.*'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 🌱 **成长**：*如你所见，我们传递了一个特征的字符串。这对于我们不同的‘*`*if*`*’测试非常方便。然而，请注意，如果传递给函数的内容不符合预期，我们不会返回错误。这不是标准的代码实践，但这扩展了本教程的范围*。
    *如果你想开始编写漂亮的代码，我建议查看 PEP-8 指南。*
- en: Step 9\. 3D Python Interactive Visualization
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 9\. 3D Python 交互式可视化
- en: '![](../Images/38078309e7c97475a7442c021a49a0f2.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38078309e7c97475a7442c021a49a0f2.png)'
- en: 'If we want to parallel a previous article, accessible here:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要平行于以前的文章，可以在这里访问：
- en: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)
    [## 3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)
    [## LiDAR 城市模型的 3D Python 工作流：逐步指南'
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Python…
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解锁 3D 城市建模应用的**终极指南**。该教程涵盖 Python…
- en: towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0?source=post_page-----90398f880c9f--------------------------------)'
- en: 'We can visualize our dataset with Open3D. First, we need to install a specific
    version (if working on a Jupyter Notebook environment, such as Google Colab or
    the CRIB platform) and load it in our script:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Open3D 可视化我们的数据集。首先，我们需要安装一个特定版本（如果在 Jupyter Notebook 环境中工作，如 Google
    Colab 或 CRIB 平台），并在我们的脚本中加载它：
- en: '[PRE18]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '🦚 **Note**: T*he “*`!`*” before pip is used when you work on Google Colab to
    say it should use the environment console directly. If you work locally, you should
    delete this character and use* `pip install open3d==0.16` *directly.*'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*在 pip 之前的“*`!`*”是在 Google Colab 上工作时使用的，表示它应该直接使用环境控制台。如果你在本地工作，应删除此字符并直接使用*
    `pip install open3d==0.16` *。*
- en: 'Then we run the following successive steps :'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们执行以下连续步骤：
- en: '![](../Images/f4c17ac7191f63ac5111517f2b34dcc5.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4c17ac7191f63ac5111517f2b34dcc5.png)'
- en: The drawing function to plot interactive 3D scenes directly within Google Colab.
    © F. Poux
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制函数以直接在 Google Colab 中绘制交互式 3D 场景。© F. Poux
- en: 'Which translates into the following code lines:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这转化为以下代码行：
- en: '[PRE19]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '🦚**Note**: *As our pc variable capturing the* `cloud_data` *output of our*
    `cloud_loader` *function is transposed, we must not forget to transpose it back
    when plotting with* `open3d`*.*'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚**注意**：*由于我们的 pc 变量捕获了* `cloud_data` *来自* `cloud_loader` *函数的输出被转置，我们在使用* `open3d`
    *绘图时必须记得将其转置回去。*
- en: 'The previous code snippet will output the following visualization:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码片段将输出以下可视化：
- en: '![](../Images/4bdc90b04fb717cd5e4223afe246cdbd.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4bdc90b04fb717cd5e4223afe246cdbd.png)'
- en: The results of plotting scenes with plotly and R,G,B fields. © F. Poux
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 plotly 绘制场景和 R、G、B 字段的结果。© F. Poux
- en: '🦚 **Note**: *when using the* `draw_plotly` *function, we do not have a direct
    hand in the scaling of the plot, and we can notice that we have non-equal scales
    for* `*X*`*,* `*Y,*` *and* `*Z*`*, which emphasizes the Z largely in that case.*
    😁'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*使用* `draw_plotly` *函数时，我们无法直接控制图表的缩放，并且可以注意到* `*X*`*,* `*Y,*` *和*
    `*Z*`*的比例不等，这在这种情况下强调了 Z。* 😁
- en: 'Due to the limitations that you can notice, we create a custom visualization
    function to visualize a random tile so that running the function: `visualize_input_tile`
    outputs an interactive `plotly` visualization that lets us switch the rendering
    mode.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你可以注意到的限制，我们创建了一个自定义可视化函数来可视化随机切片，以便运行函数：`visualize_input_tile` 输出一个交互式的 `plotly`
    可视化，让我们切换渲染模式。
- en: 'To test the provided function, we first need to define the class names in our
    experiments: `class_names = [‘unclassified’, ‘ground’, ‘vegetation’, ‘buildings’,
    ‘water’]`. Then, we provide the cloud features `cloud_features=’xyzi’`, randomly
    select a point cloud captured in the variable `selection`, and visualize the tile.
    This translates into the following code snippet:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试提供的函数，我们首先需要在实验中定义类名称：`class_names = [‘unclassified’, ‘ground’, ‘vegetation’,
    ‘buildings’, ‘water’]`。然后，我们提供云特征`cloud_features=’xyzi’`，随机选择变量`selection`中捕获的点云，并可视化切片。这转化为以下代码片段：
- en: '[PRE20]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: which outputs the interactive scene below.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出如下交互式场景。
- en: '![](../Images/30e3f33bf92ffaab3aa2cf9ac4ee8593.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30e3f33bf92ffaab3aa2cf9ac4ee8593.png)'
- en: interactive 3D scene within Google Colab. © F. Poux
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Colab 中的交互式 3D 场景。© F. Poux
- en: '🦚 **Note**: *You can use the button to switch rendering modes between the feature
    intensity and the labels from the loaded features of interest.*'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*你可以使用按钮在特征强度和从加载的感兴趣特征的标签之间切换渲染模式。*
- en: We have a working solution for loading, normalizing, and visualizing a single
    tile in Python. The last step is to create what we call a tensor for use with
    the PointNet Architecture.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个工作解决方案用于加载、规范化和可视化 Python 中的单个切片。最后一步是创建我们称之为张量的内容，以用于 PointNet 架构。
- en: Step 10\. Tensor Creation
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 10 步。张量创建
- en: '![](../Images/5a4bea8711a8eb6399d3d4d008598f37.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a4bea8711a8eb6399d3d4d008598f37.png)'
- en: 'I want to show you how we can use PyTorch as an initiation. For clarity concerns,
    let me quickly define the primary Python object type we manipulate with this library:
    a tensor.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我想向你展示如何使用 PyTorch 进行初步操作。为清晰起见，让我快速定义我们使用这个库时操作的主要 Python 对象类型：张量。
- en: 'A PyTorch tensor is a multi-dimensional array used for storing and manipulating
    data in PyTorch. It is similar to a NumPy array but with the added benefit of
    being optimized for use with deep learning models. Tensors can be created using
    the `torch.tensor()` function and initialized with data or created as an empty
    tensor with a specified shape. For example, to create a 3x3 tensor with random
    data:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 张量是一个多维数组，用于在 PyTorch 中存储和操作数据。它类似于 NumPy 数组，但具有针对深度学习模型优化的额外好处。张量可以使用
    `torch.tensor()` 函数创建，并用数据初始化，或者创建一个具有指定形状的空张量。例如，要创建一个 3x3 的张量并填充随机数据：
- en: '[PRE21]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'which will output:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出：
- en: '[PRE22]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Pretty straightforward, hun? Now, to make things easier for us, there is also
    a tiny Pytorch library that we can use to prepare lists of datasets. This library
    is called `TorchNet`. `TorchNet` is designed to simplify the process of building
    and training complex neural network architectures by providing a set of predefined
    modules and helper functions for everyday tasks such as data loading, validation,
    and testing.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 相当简单，对吧？现在，为了简化操作，还有一个小型的 Pytorch 库，我们可以用来准备数据集列表。这个库叫做`TorchNet`。`TorchNet`
    旨在通过提供一组预定义的模块和助手函数来简化构建和训练复杂神经网络架构的过程，这些模块和助手函数适用于数据加载、验证和测试等日常任务。
- en: One of the main advantages of `TorchNet` is its modular design, which allows
    users to easily construct complex neural network architectures by combining a
    series of pre-built modules. This can save significant time and effort compared
    to building neural networks from scratch, especially when new to deep learning.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '`TorchNet` 的主要优势之一是其模块化设计，允许用户通过组合一系列预构建模块来轻松构建复杂的神经网络架构。这可以节省大量时间和精力，相比从头开始构建神经网络，尤其是在刚接触深度学习时。'
- en: '🦚 **Note**: *Besides its modular design, TorchNet provides several helper functions
    for common deep learning tasks, such as data augmentation, early stopping, and
    model checkpointing. This can help users to achieve better results and optimize
    their neural network architectures more efficiently*.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 🦚 **注意**：*除了其模块化设计外，TorchNet 还提供了多个用于常见深度学习任务的助手函数，例如数据增强、早期停止和模型检查点。这可以帮助用户获得更好的结果，并更高效地优化他们的神经网络架构*。
- en: 'To install `torchnet` version `0.0.4` and import it into our script, we can
    do the following:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`torchnet`版本`0.0.4`并将其导入到我们的脚本中，我们可以执行以下操作：
- en: '[PRE23]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We also import another utility module called `functools`. This module is for
    higher-order functions that act on or return other functions. For this, add to
    the import statements `import functools`.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还导入了另一个名为 `functools` 的实用模块。该模块用于处理或返回其他函数的高阶函数。为此，将 `import functools` 添加到导入语句中。
- en: 'In general, any callable object can be treated as a function for the purposes
    of this module. From this additional setup, it is straightforward to generate
    the train, validation, and test sets with the following four lines of code:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，任何可调用的对象都可以被视为此模块的函数。通过这些额外的设置，可以使用以下四行代码轻松生成训练集、验证集和测试集：
- en: '[PRE24]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, if we would like to explore, you can use indexes like a classical numpy
    array to retrieve a tensor on a specific position, such as `train_set[1]`, which
    outputs:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们想要探索，可以使用像经典的 numpy 数组一样的索引来检索特定位置的张量，例如`train_set[1]`，其输出为：
- en: '![](../Images/8de3614b4899010c759ea2104f9c0e0a.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8de3614b4899010c759ea2104f9c0e0a.png)'
- en: 'Finally, we have to save our results to a Python object to use straight out
    of the box for the following steps, such as PointNet training. We are using the
    library pickle, which is handy for saving Python objects. To save an object, just
    run the following:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须将结果保存到 Python 对象中，以便在接下来的步骤中直接使用，例如 PointNet 训练。我们使用的库是 pickle，它非常适合保存
    Python 对象。要保存一个对象，只需运行以下命令：
- en: '[PRE25]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'If you want to test your setup, you can also run the following lines of code
    and ensure that you retrieve back what you intend:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想测试你的设置，还可以运行以下代码行，确保你检索到你想要的内容：
- en: '[PRE26]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '💻 Get Access to the Code here: [Google Colab](https://colab.research.google.com/drive/1pqBqGPV36_gxi4yjPiTUR3fb5IldpdaS?usp=sharing)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 💻 在这里获取代码访问：[Google Colab](https://colab.research.google.com/drive/1pqBqGPV36_gxi4yjPiTUR3fb5IldpdaS?usp=sharing)
- en: '🍇 Get Access to the Data here: [3D Datasets](https://drive.google.com/drive/folders/1RPCX2NCBn24g4lC3qS_xhuS1peR_EnxM?usp=sharing)'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🍇 在这里获取数据访问：[3D 数据集](https://drive.google.com/drive/folders/1RPCX2NCBn24g4lC3qS_xhuS1peR_EnxM?usp=sharing)
- en: '👨‍🏫3D Data Processing and AI Courses: [3D Academy](https://learngeodata.eu/)'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 👨‍🏫3D 数据处理和 AI 课程：[3D 学院](https://learngeodata.eu/)
- en: '📖 Subscribe to get early access to 3D Tutorials: [3D AI Automation](https://medium.com/@florentpoux/subscribe)'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📖 订阅以获得 3D 教程的早期访问：[3D AI 自动化](https://medium.com/@florentpoux/subscribe)
- en: '💁 Support my work with Medium 🤟: [Medium Subscription](https://medium.com/@florentpoux/membership)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 💁 支持我的工作与 Medium 🤟：[Medium 订阅](https://medium.com/@florentpoux/membership)
- en: '![](../Images/9d299f0b910437eb61e9167de8868a19.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d299f0b910437eb61e9167de8868a19.png)'
- en: 🔮 Conclusion
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🔮 结论
- en: Congratulations! In this hands-on tutorial, we explored the critical steps in
    preparing 3D point cloud data from aerial LiDAR scans for use with the PointNet
    architecture.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！在这个实践教程中，我们探讨了准备用于 PointNet 架构的 3D 点云数据的关键步骤。
- en: '![](../Images/5e3562ca370d6d278c11635d8b34757d.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e3562ca370d6d278c11635d8b34757d.png)'
- en: The 3D Deep Learning Data Preparation Workflow for PointNet. © F. Poux
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: PointNet 的 3D 深度学习数据准备工作流程。© F. Poux
- en: By following this step-by-step guide, you have learned how to clean, process
    LiDAR point clouds, extract relevant features, and normalize the data for 3D deep
    learning models. We have also discussed some key considerations in working with
    3D point cloud data, such as tile size, normalization, and data augmentation.
    You can apply these techniques to your 3D point cloud datasets and use them for
    training and testing PointNet models for object classification and segmentation.
    The field of 3D deep learning is rapidly evolving, and this tutorial is a cornerstone
    that provides a solid foundation for you to explore this exciting area further.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这个逐步指南，你已经学会了如何清理、处理 LiDAR 点云，提取相关特征，并为 3D 深度学习模型规范化数据。我们还讨论了一些处理 3D 点云数据的关键注意事项，如瓦片大小、规范化和数据增强。你可以将这些技术应用于你的
    3D 点云数据集，并用它们来训练和测试 PointNet 模型，用于对象分类和分割。3D 深度学习领域正在快速发展，这个教程是一个基石，为你进一步探索这一激动人心的领域提供了坚实的基础。
- en: 🤿 Going Further
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🤿 进一步探索
- en: But the learning journey does not end here. Our lifelong search begins, and
    future steps will dive into deepening 3D Voxel work, Artificial Intelligence for
    3D data, exploring semantics, and digital twinning. On top, we will analyze point
    clouds with deep learning techniques and unlock advanced 3D LiDAR analytical workflows.
    A lot to be excited about!
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 但学习之旅并未止步于此。我们的终身探索才刚刚开始，未来的步骤将深入探讨 3D 体素工作、3D 数据的人工智能、语义分析和数字双胞胎。此外，我们将使用深度学习技术分析点云，解锁高级
    3D LiDAR 分析工作流程。还有很多令人兴奋的内容！
- en: References
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Qi, C. R., Su, H., Mo, K., & Guibas, L. J. (2017). Pointnet: Deep learning
    on point sets for 3d classification and segmentation. In *Proceedings of the IEEE
    conference on computer vision and pattern recognition* (pp. 652–660).'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Qi, C. R., Su, H., Mo, K., & Guibas, L. J. (2017). Pointnet：点集上的深度学习用于 3D 分类和分割。收录于
    *IEEE 计算机视觉与模式识别会议论文集* (第 652–660 页)。
- en: 'Poux, F., & Billen, R. (2019). Voxel-based 3D point cloud semantic segmentation:
    Unsupervised geometric and relationship featuring vs deep learning methods. *ISPRS
    International Journal of Geo-Information*, *8*(5), 213.'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Poux, F., & Billen, R. (2019). 基于体素的 3D 点云语义分割：无监督几何和关系特征与深度学习方法。*ISPRS 国际地理信息学杂志*,
    *8*(5), 213。
- en: Xu, S., Vosselman, G., & Elberink, S. O. (2014). Multiple-entity based classification
    of airborne laser scanning data in urban areas. *ISPRS Journal of photogrammetry
    and remote sensing*, *88*, 1–15.
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Xu, S., Vosselman, G., & Elberink, S. O. (2014). 基于多实体的城市区域航空激光扫描数据分类。*ISPRS
    摄影测量与遥感杂志*, *88*, 1–15。
