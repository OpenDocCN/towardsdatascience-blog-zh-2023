- en: Achieving Greater Self-Consistency in Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现大型语言模型的更大自我一致性
- en: 原文：[https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7?source=collection_archive---------9-----------------------#2023-12-01](https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7?source=collection_archive---------9-----------------------#2023-12-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7?source=collection_archive---------9-----------------------#2023-12-01](https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7?source=collection_archive---------9-----------------------#2023-12-01)
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[![安东尼·阿尔卡拉兹](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [安东尼·阿尔卡拉兹](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----6e6cb5f3c5b7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    ·8 min read·Dec 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e6cb5f3c5b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----6e6cb5f3c5b7---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----6e6cb5f3c5b7---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    ·8分钟阅读·2023年12月1日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e6cb5f3c5b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----6e6cb5f3c5b7---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e6cb5f3c5b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&source=-----6e6cb5f3c5b7---------------------bookmark_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e6cb5f3c5b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&source=-----6e6cb5f3c5b7---------------------bookmark_footer-----------)'
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件被用于提升本文的语法、流畅性和可读性。*'
- en: When LLMs are used to evaluate qualities like the correctness, accuracy, or
    relevance of a piece of text, consistency is paramount. If an LLM exhibits inconsistent
    judgements, then its evaluations become unreliable and untrustworthy.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当大型语言模型用于评估文本的正确性、准确性或相关性等特质时，一致性至关重要。如果LLM表现出不一致的判断，那么它的评估将变得不可靠和不值得信赖。
- en: If an LLM evaluates the reasoning quality of arguments, but contradicts itself
    by rating an invalid argument as more logically sound than a perfectly valid one,
    then it fails as an arbiter of reason. Its evaluations lose credibility due to
    the model’s own lack of logical consistency.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个大型语言模型（LLM）评估论证的推理质量，但通过将无效的论证评为比完全有效的论证更具逻辑性来自我矛盾，那么它作为推理仲裁者就失败了。由于模型自身缺乏逻辑一致性，其评估失去了可信度。
- en: When such inconsistencies appear, there is no stable basis for comparison between
    the LLM’s assessments of different pieces of text. If the model arbitrarily contradicts
    itself, then sentences cannot be reliably ranked against one another based on
    the model’s inconsistent scorings.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当出现这样的不一致时，就没有稳定的基础来比较LLM对不同文本的评估。如果模型随意自相矛盾，那么句子就无法根据模型不一致的评分进行可靠的排序。
- en: In essence, inconsistency destroys the grounds for comparison that evaluations
    aim to provide in the first place. If an LLM cannot demonstrate consistent application
    of assessment criteria, then using it to evaluate text loses all effectiveness
    and utility.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，不一致性破坏了评估最初旨在提供的比较基础。如果一个LLM无法展示评估标准的一致应用，那么用它来评估文本就会失去所有的有效性和实用性。
- en: So, consistency in judgement and evaluation is mandatory for LLMs employed to
    score or judge textual qualities and features. Without a high level of stability
    in its assessments, grounded in a consistent understanding of concepts being evaluated,
    the basis for…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于用于评分或评判文本质量和特征的LLM，一致性的判断和评估是必要的。如果其评估没有高水平的稳定性，且没有基于对所评估概念的一致理解，那么基础就会…
