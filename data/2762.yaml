- en: 'Tidying Up the Framework of Dataset Shifts: The Example'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集转移框架的整理：示例
- en: 原文：[https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5?source=collection_archive---------4-----------------------#2023-09-01](https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5?source=collection_archive---------4-----------------------#2023-09-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5?source=collection_archive---------4-----------------------#2023-09-01](https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5?source=collection_archive---------4-----------------------#2023-09-01)
- en: '*How the conditional probability changes as a function of the three probability
    elements*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*条件概率如何随三个概率元素的函数变化*'
- en: '[](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)[![Valeria
    Fonseca Diaz](../Images/880222be555e8fa7df660f9dd1233818.png)](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)
    [Valeria Fonseca Diaz](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)[![瓦莱里亚·冯塞卡·迪亚兹](../Images/880222be555e8fa7df660f9dd1233818.png)](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)
    [瓦莱里亚·冯塞卡·迪亚兹](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e363caf1c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=post_page-6e363caf1c79----77807ee952f5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)
    ·7 min read·Sep 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F77807ee952f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=-----77807ee952f5---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e363caf1c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=post_page-6e363caf1c79----77807ee952f5---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)
    ·7 min 阅读·2023年9月1日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F77807ee952f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=-----77807ee952f5---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77807ee952f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&source=-----77807ee952f5---------------------bookmark_footer-----------)![](../Images/9e31584718ba2bf5d2608bb69b7ab98e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77807ee952f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&source=-----77807ee952f5---------------------bookmark_footer-----------)![](../Images/9e31584718ba2bf5d2608bb69b7ab98e.png)'
- en: Image by author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: I recently talked about the causes of model performance degradation, meaning
    when their prediction quality drops with respect to the moment we trained and
    deployed our models. [In this other post](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7),
    I proposed a new way of thinking about the causes of model degradation. In that
    framework, the so-called conditional probability comes out as the global cause.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最近我讨论了模型性能下降的原因，即它们在我们训练和部署模型时预测质量下降的情况。[在另一篇文章中](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)，我提出了一种新的思考模型退化原因的方式。在这个框架中，所谓的条件概率成为全局原因。
- en: The conditional probability is, by definition, composed of three probabilities
    which I call the specific causes. The most important learning of this restructure
    of concepts is that *covariate shift* and *conditional shift* are not two separate
    or parallel concepts. *Conditional shift* can happen as a function of *covariate
    shift*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率本质上由三个我称之为具体原因的概率组成。这种概念重构最重要的学习是*协变量偏移*和*条件偏移*不是两个独立或平行的概念。*条件偏移*可以作为*协变量偏移*的一个函数发生。
- en: With this restructuring, I believe it becomes easier to think about the causes
    and it becomes more logical to interpret the shifts that we observe in our applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种重构，我相信我们更容易思考原因，并且解释我们在应用中观察到的变化变得更加合乎逻辑。
- en: 'This is the scheme of causes and model performance for machine learning models:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是机器学习模型的原因与模型性能的框架：
- en: '![](../Images/41a53ba3896a9e14a9b7ada026ce2104.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41a53ba3896a9e14a9b7ada026ce2104.png)'
- en: Image by author. Adapted from [https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7](/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。改编自 [https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7](/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)
- en: In this scheme, we see the clear path that connects the causes to the prediction
    performance of our estimated models. One fundamental assumption we need to make
    in statistical learning is that our models are “good” estimators of the real models
    (real decision boundaries, real regression functions, etc.). “Good” can have different
    meanings, such as unbiased estimators, precise estimators, complete estimators,
    sufficient estimators, etc. But, for the sake of simplicity and the upcoming discussion,
    let’s say that they are good in the sense that they have a small prediction error.
    In other words, we assume that they are representative of the real models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个框架中，我们可以清晰地看到将原因与我们估计模型的预测性能连接起来的路径。我们在统计学习中需要做的一个基本假设是，我们的模型是对真实模型（真实决策边界、真实回归函数等）的“良好”估计。“良好”可以有不同的含义，例如无偏估计、精确估计、完整估计、充分估计等。但为了简化和接下来的讨论，我们可以说它们在预测误差较小的意义上是好的。换句话说，我们假设它们能够代表真实模型。
- en: With this assumption, we are able to look for the causes of model degradation
    of the estimated model in the probabilities ***P(X), P(Y), P(X|Y),*** and consequently***,
    P(Y|X)***.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个假设下，我们可以在概率***P(X)、P(Y)、P(X|Y)***中寻找估计模型退化的原因，并因此***P(Y|X)***。
- en: So, what we will do today is to exemplify and walk through different scenarios
    to see how ***P(Y|X)*** changes as a function of the 3 probabilities ***P(X|Y)***,
    ***P(X)***, and ***P(Y)***. We will do so by using a population of a few points
    in a 2D space and calculating the probabilities from these sample points in the
    way Laplace would do. The purpose is to digest the hierarchy scheme of causes
    of model degradation, keeping ***P(Y|X)*** as the global cause, and the other
    three as the specific causes. In that way, we can understand, for example, how
    a potential covariate shift can be sometimes the argument of the conditional shift
    rather than being a separate shift of its own.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们今天要做的就是举例并演示不同的场景，看看***P(Y|X)***如何作为3个概率***P(X|Y)***、***P(X)***和***P(Y)***的函数变化。我们将使用二维空间中的少量点，并按拉普拉斯的方法计算这些样本点的概率。目的是消化模型退化的原因层次结构，将***P(Y|X)***作为全局原因，而其他三个作为具体原因。通过这种方式，我们可以理解，例如，潜在的协变量偏移有时可能是条件偏移的论据，而不是一个独立的偏移。
- en: The example
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: 'The case we will draw for our lesson today is a very simple one. We have a
    space of two covariates ***X1*** and ***X2*** and the output ***Y*** is a binary
    variable. This is what our model space looks like:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们今天课程中要绘制的案例是一个非常简单的。我们有两个协变量***X1***和***X2***，输出***Y***是一个二元变量。这就是我们的模型空间的样子：
- en: '![](../Images/9dfb0f5e2a871c9c8f7b8fa4e1f989de.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9dfb0f5e2a871c9c8f7b8fa4e1f989de.png)'
- en: Image by author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: You see there that the space is organized in 4 quadrants and the decision boundary
    in this space is the cross. This means that the model classifies samples in class
    1 if they lie in the 1st and 3rd quadrants, and in class 0 otherwise. For the
    sake of this exercise, we will walk through the different cases comparing ***P(Y=1|X1>a)***.
    This will be our conditional probability to showcase. If you are wondering why
    not taking also ***X2***, it’s only for the simplicity of the exercise. It doesn’t
    affect the insight we want to understand.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，空间被划分为4个象限，而这个空间中的决策边界是交叉的。这意味着模型将样本分类为类别1如果它们位于第1象限和第3象限，否则分类为类别0。为了这个练习的目的，我们将通过比较***P(Y=1|X1>a)***来逐步解析不同情况。这将是我们展示的条件概率。如果你在想为什么不考虑***X2***，这是为了简化练习。这不会影响我们想要理解的见解。
- en: If you’re still with a bittersweet feeling, taking **P(Y=1|X1>a)** is equivalent
    to **P(Y=1|X1>a, -inf <X2 < inf)**, so theoretically, we are still taking **X2**
    into account.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你仍然有些复杂的感觉，计算**P(Y=1|X1>a)** 相当于 **P(Y=1|X1>a, -inf <X2 < inf)**，所以理论上，我们仍然考虑了**X2**。
- en: '![](../Images/d82c6e1f04e4f16ef6d95e5fdc45629e.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d82c6e1f04e4f16ef6d95e5fdc45629e.png)'
- en: Image by author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Reference model
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考模型
- en: 'So to start with, we calculate our showcase probability and we obtain ***1/2***.
    Pretty much here our group of samples is quite uniform throughout the space and
    the prior probabilities are also uniform:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，首先，我们计算我们的展示概率，得到的是***1/2***。在这里，我们的样本组在整个空间中相当均匀，先验概率也很均匀：
- en: '![](../Images/88048c01fd014a51c24ce82084572ac3.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/88048c01fd014a51c24ce82084572ac3.png)'
- en: Image by author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Shifts are coming up
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变化正在出现
- en: '*One extra sample appears in the bottom right quadrant. So the first thing
    we ask is: Are we talking about a covariate shift?*'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*一个额外的样本出现在右下角象限。所以我们首先要问的是：我们是否在讨论协变量变化？*'
- en: 'Well, yes, because there is more sampling in ***X1>a*** than there was before.
    So, is this only a *covariate shift* but not a *conditional shift*? Let’s see.
    Here is the calculation of all the same probabilities as before with the updated
    set of points (The probabilities that changed are in orange):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，因为在***X1>a***的区域内的抽样比以前更多。所以，这只是一个*协变量变化*而不是*条件变化*吗？让我们看看。这里是用更新后的点集计算的所有相同概率（变化的概率用橙色标记）：
- en: '![](../Images/3109fa31a6427b9b5f6a068653d9ba86.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3109fa31a6427b9b5f6a068653d9ba86.png)'
- en: Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: What did we see here? In fact, not only did we get a *covariate shift*, but
    overall, all the probabilities changed. The *prior* probability also changed because
    the covariate shift brought a new point of class 1 making the incidence of this
    class bigger than class 2\. Then also, the *inverse probability* ***P(X1>a|Y=1)***
    changed precisely because of the *prior shift*. All of that overall led to a *conditional
    shift* so we now got ***P(Y=1|X1>a)=2/3*** instead of ***1/2***.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里看到了什么？实际上，我们不仅仅获得了*协变量变化*，而且所有的概率都发生了变化。*先验*概率也发生了变化，因为协变量变化带来了一个新的类别1的点，使得这一类别的发生率大于类别2。因此，*逆概率*
    ***P(X1>a|Y=1)*** 正是因为*先验变化*而发生了变化。所有这些最终导致了一个*条件变化*，所以我们现在得到了***P(Y=1|X1>a)=2/3***，而不是***1/2***。
- en: Here’s a thought bubble. A very important one actually.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个思考泡泡。实际上是一个非常重要的思考泡泡。
- en: With this shift in the sampling distribution, we obtained shifts in all the
    probabilities that play a role in the whole scheme of our models. Yet, the decision
    boundary that existed based on the initial sampling remained valid for this shift.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 随着抽样分布的变化，我们获得了所有在我们模型整体方案中起作用的概率的变化。然而，基于初始抽样存在的决策边界对这一变化仍然有效。
- en: What does this mean?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是什么意思？
- en: Even though we obtained a conditional shift, the decision boundary did not necessarily
    degrade. Because the decision boundary comes from the expected value, if we calculate
    this value based on the current shift, the boundary may remain the same but with
    a different conditional probability.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们获得了条件变化，但决策边界并没有必然退化。因为决策边界来自期望值，如果我们基于当前的变化计算这个值，边界可能保持不变，但条件概率不同。
- en: '*2\. Samples at the first quadrant don’t exist anymore.*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*2\. 第一个象限中的样本不再存在。*'
- en: So, for ***X1>a*** things remained unchanged. Let’s see what happens to the
    conditional probability we’re showcasing and its elements.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于***X1>a***，情况保持不变。让我们看看展示的条件概率及其元素发生了什么变化。
- en: '![](../Images/52f461e1e292851cf4fee30558575749.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52f461e1e292851cf4fee30558575749.png)'
- en: Image by author
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Intuitively, because within ***X1>a*** things remain unchanged, the conditional
    probability remained the same. Yet, when we look at ***P(X1>a)*** we obtain ***2/3***
    instead of ***1/2*** compared to the training sampling. So here we have a *covariate
    shift* ***without*** *a conditional shift*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，因为在***X1>a***的情况下，条件概率保持不变。然而，当我们查看***P(X1>a)***时，我们得到***2/3***而不是与训练采样相比的***1/2***。所以在这里我们有一个*协变量漂移*，***没有***
    *条件漂移*。
- en: From a math perspective, how can the covariate probability change without the
    conditional probability changing? This is because ***P(Y=1)*** and ***P(X1>a|Y=1)***
    changed accordingly to the covariate probability. Therefore the compensation makes
    up for an unchanged conditional probability.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度来看，协变量概率如何在条件概率不变的情况下发生变化？这是因为***P(Y=1)***和***P(X1>a|Y=1)***按照协变量概率的变化而变化。因此，补偿使条件概率保持不变。
- en: With these changes, just as before, the decision boundary remained valid.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些变化，就像之前一样，决策边界保持有效。
- en: '*3\. Throwing in some samples in different quadrants while the decision boundary
    remained valid.*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*3\. 在不同象限中投放一些样本，同时决策边界保持有效。*'
- en: We have here 2 extra combinations. In one case, the *prior* remained the same
    while the other two probabilities changed, still not changing the conditional
    probability. In the second case, *only* the *inverse probability* was associated
    with a conditional shift. Check the shifts here below. The latter is a pretty
    important one, so don’t miss it!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个额外的组合。在一种情况下，*先验*保持不变，而其他两个概率发生了变化，但条件概率仍未变化。在第二种情况下，*仅* *逆概率*与条件漂移相关。请查看下面的漂移。后者是一个相当重要的点，所以不要错过！
- en: '![](../Images/77461159b07a374577cd8b77cefaaf64.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77461159b07a374577cd8b77cefaaf64.png)'
- en: Image by author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: With this, we have now a pretty solid perspective on how the conditional probability
    can change as a function of the other three probabilities. But most importantly,
    we also know that not all conditional shifts invalidate the existing decision
    boundary. So what’s the deal with it?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们现在对条件概率如何作为其他三种概率的函数发生变化有了相当扎实的理解。但最重要的是，我们也知道，并非所有的条件漂移都会使现有的决策边界失效。那么问题是什么呢？
- en: Concept drift
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概念漂移
- en: '[In the previous post](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7),
    I also proposed a more specific way of defining *concept drift* (or *concept shift*).
    The proposal is:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[在上一篇文章](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)中，我还提出了一种更具体的定义*概念漂移*（或*概念变化*）的方法。提议是：'
- en: We refer to a change in the **concept** when the decision boundary or regression
    function becomes invalid when the probabilities at play are shifting.
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当决策边界或回归函数在相关概率发生变化时变得无效，我们称之为**概念漂移**。
- en: So, the crucial point about this is that if the decision boundary becomes invalid,
    surely there is a conditional shift. The reverse, as we discussed in [the previous
    post](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)
    and as we saw in the examples above, is not necessarily true.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，关键在于，如果决策边界变得无效，肯定存在条件漂移。相反的情况，如我们在[上一篇文章](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)中讨论过，并且如上述示例所示，并不一定成立。
- en: This might not be so fantastic from a practical perspective because it means
    that to truly know if there’s a concept drift, we might be forced to re-estimate
    the boundary or function. But at least, for our theoretical understanding, this
    is just as fascinating.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度来看，这可能并不是那么令人惊叹，因为这意味着为了真正了解是否存在概念漂移，我们可能被迫重新估计边界或函数。但至少从理论理解的角度来看，这同样引人入胜。
- en: Here’s an example in which we have a *concept drift*, naturally with a *conditional
    shift*, but actually *without a covariate or a prior shift*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例，我们有一个*概念漂移*，自然地伴随着一个*条件漂移*，但实际上*没有协变量或先验漂移*。
- en: '![](../Images/a22fa23667500064f5b8917ba4ab1c63.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a22fa23667500064f5b8917ba4ab1c63.png)'
- en: Image by author
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: How cool is this separation of components? The only element that changed here
    was the *inverse probability*, but, contrary to the previous shift we studied
    above, this change in the inverse probability was linked to the change in the
    decision boundary. Now, a valid decision boundary is only the separation according
    to ***X1>a*** discarding the boundary dictated by ***X2***.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个组件分离有多酷？这里唯一改变的元素是*逆概率*，但与我们上面研究的先前偏移不同，这种逆概率的变化与决策边界的变化相关。现在，合法的决策边界仅仅是根据***X1>a***的分隔，抛弃了由***X2***所决定的边界。
- en: What have we learned?
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们学到了什么？
- en: 'We have walked very slowly through the decomposition of the causes of model
    degradation. We studied different shifts of the probability elements and how they
    relate to the degradation of the prediction performance of our machine learning
    models. The most important insights are:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常缓慢地走过了模型退化原因的分解过程。我们研究了概率元素的不同偏移及其与机器学习模型预测性能退化的关系。最重要的见解是：
- en: A conditional shift is a global cause of prediction degradation in machine learning
    models
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条件偏移是机器学习模型预测退化的全球原因。
- en: The specific causes are covariate shift, prior shift, and inverse probability
    shift
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具体原因包括协变量偏移、先验偏移和逆概率偏移。
- en: We can have many different cases of probability shifts while the decision boundary
    remains valid
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在决策边界保持有效的情况下，我们可能会遇到许多不同的概率偏移情况。
- en: A change in the decision boundary causes a conditional shift, but the reverse
    is not necessarily true!
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策边界的变化会引起条件偏移，但反过来不一定成立！
- en: '*Concept drift* may be more specifically associated with the decision boundary
    rather than with the overall conditional probability distribution'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*概念漂移*可能更具体地与决策边界相关，而不是与整体条件概率分布相关。'
- en: What follows from this? Reorganizing our practical solutions in light of this
    hierarchy of definitions is the biggest invitation I make. We might find so many
    wanted answers to our current questions regarding the way in which we can monitor
    our models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这会带来什么？在这个定义层次结构的指导下重新组织我们的实际解决方案是我提出的最大建议。我们可能会找到许多当前问题的理想答案，关于如何监控我们的模型。
- en: If you are currently working on model performance monitoring using these definitions,
    don’t hesitate to share your thoughts on this framework.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你目前正在使用这些定义进行模型性能监控，不要犹豫，分享你对这个框架的想法。
- en: '*Happy thinking to everyone!*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*祝大家思维愉快！*'
