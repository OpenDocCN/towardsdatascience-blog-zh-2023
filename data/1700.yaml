- en: How To Best Leverage OpenAI’s Evals Framework
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何最佳利用OpenAI的Evals框架
- en: 原文：[https://towardsdatascience.com/how-to-best-leverage-openais-evals-framework-c38bcef0ec47?source=collection_archive---------2-----------------------#2023-05-23](https://towardsdatascience.com/how-to-best-leverage-openais-evals-framework-c38bcef0ec47?source=collection_archive---------2-----------------------#2023-05-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-best-leverage-openais-evals-framework-c38bcef0ec47?source=collection_archive---------2-----------------------#2023-05-23](https://towardsdatascience.com/how-to-best-leverage-openais-evals-framework-c38bcef0ec47?source=collection_archive---------2-----------------------#2023-05-23)
- en: '![](../Images/91f397160d3039365854c9a5bc606c06.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91f397160d3039365854c9a5bc606c06.png)'
- en: Image licensed by author for commercial use
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者授权用于商业用途
- en: Keys for evaluating LLMs using OpenAI Evals
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用OpenAI Evals评估LLM的关键
- en: '[](https://aparnadhinak.medium.com/?source=post_page-----c38bcef0ec47--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page-----c38bcef0ec47--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c38bcef0ec47--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c38bcef0ec47--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page-----c38bcef0ec47--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://aparnadhinak.medium.com/?source=post_page-----c38bcef0ec47--------------------------------)[![Aparna
    Dhinakaran](../Images/e431ee69563ecb27c86f3428ba53574c.png)](https://aparnadhinak.medium.com/?source=post_page-----c38bcef0ec47--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c38bcef0ec47--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c38bcef0ec47--------------------------------)
    [Aparna Dhinakaran](https://aparnadhinak.medium.com/?source=post_page-----c38bcef0ec47--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff32f85889f3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-best-leverage-openais-evals-framework-c38bcef0ec47&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=post_page-f32f85889f3a----c38bcef0ec47---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c38bcef0ec47--------------------------------)
    ·6 min read·May 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc38bcef0ec47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-best-leverage-openais-evals-framework-c38bcef0ec47&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=-----c38bcef0ec47---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff32f85889f3a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-best-leverage-openais-evals-framework-c38bcef0ec47&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=post_page-f32f85889f3a----c38bcef0ec47---------------------post_header-----------)
    发布于 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----c38bcef0ec47--------------------------------)
    ·6 分钟阅读·2023年5月23日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc38bcef0ec47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-best-leverage-openais-evals-framework-c38bcef0ec47&user=Aparna+Dhinakaran&userId=f32f85889f3a&source=-----c38bcef0ec47---------------------clap_footer-----------)'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc38bcef0ec47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-best-leverage-openais-evals-framework-c38bcef0ec47&source=-----c38bcef0ec47---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc38bcef0ec47&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-best-leverage-openais-evals-framework-c38bcef0ec47&source=-----c38bcef0ec47---------------------bookmark_footer-----------)'
- en: '*This blog is co-authored by* [*Trevor LaViale*](https://www.linkedin.com/in/trevor-laviale/)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*本博客由* [*Trevor LaViale*](https://www.linkedin.com/in/trevor-laviale/) *共同撰写*'
- en: According to a recent [survey](https://arize.com/blog/survey-massive-retooling-around-large-language-models-underway/),
    nearly half (43%) of data science and engineering teams are planning production
    deployments of large language models (LLMs) over the next year. The age of LLMs
    is definitely upon us; however, evaluating these models is often challenging,
    and researchers need to develop reliable methods for comparing different models’
    performance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 根据近期的一项[调查](https://arize.com/blog/survey-massive-retooling-around-large-language-models-underway/)，近一半（43%）的数据科学和工程团队计划在未来一年内部署大型语言模型（LLMs）。LLMs的时代确实已经来临；然而，评估这些模型往往具有挑战性，研究人员需要开发可靠的方法来比较不同模型的性能。
- en: A few months ago, OpenAI open-sourced their framework for evaluating LLMs against
    a series of benchmarks. This framework was used internally at OpenAI to ensure
    new versions of their models were performing adequately. OpenAI’s Eval Framework
    is a tool designed to help researchers and practitioners evaluate their LLMs and
    compare them to other state-of-the-art models.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 几个月前，OpenAI 开源了他们的框架，用于根据一系列基准评估 LLM。这一框架在 OpenAI 内部使用，以确保他们的新版本模型表现适当。OpenAI
    的 Eval 框架是一个工具，旨在帮助研究人员和从业者评估他们的 LLM，并将其与其他先进的模型进行比较。
- en: How Does the Eval Framework Work?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Eval 框架是如何工作的？
- en: Now at this point, you may be thinking, “Wow, this seems like a really useful
    tool for evaluating LLMs, but what is an eval and how do I use it?” Let’s dive
    into the specifics!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能会想，“哇，这似乎是一个评估 LLM 的非常有用的工具，但什么是评估，我该如何使用它？”让我们深入了解细节吧！
- en: An “eval” refers to a specific evaluation task that is used to measure the performance
    of a language model in a particular area, such as question answering or sentiment
    analysis. These evals are typically standardized benchmarks that allow for the
    comparison of different language models. The Eval framework provides a standardized
    interface for running these evals and collecting the results.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: “评估”指的是用于衡量语言模型在特定领域（例如问题回答或情感分析）表现的具体任务。这些评估通常是标准化的基准，用于比较不同的语言模型。Eval 框架提供了一个标准化的接口，用于运行这些评估并收集结果。
- en: 'At its core, an eval is a dataset and an eval class that is defined in a YAML
    file. An example of an eval is shown below (this was taken from the [Github repository
    for evals](https://github.com/openai/evals)):'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，评估是一个数据集和一个在 YAML 文件中定义的评估类。下面展示了一个评估示例（该示例取自 [Github 存储库](https://github.com/openai/evals)）：
- en: 'Let’s break down what the above means:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解析一下以上内容的意思：
- en: 'test-match: This is the name of the eval'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'test-match: 这是评估的名称'
- en: 'id: This is the full name of the eval that *test-match* is an alias for'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'id: 这是 *test-match* 的别名的评估全名'
- en: 'description: Description of the eval.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'description: 评估的描述。'
- en: 'metrics: The metrics for the eval.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'metrics: 评估的指标。'
- en: 'class: Specifies the path for the module/class for the eval.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'class: 指定评估的模块/类路径。'
- en: 'args: Anything you want to pass to the class constructor.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'args: 任何你想传递给类构造函数的内容。'
- en: 'samples_jsonl: points to the location of where the samples are, which in this
    case are in test_match/samples.jsonl'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'samples_jsonl: 指向样本所在的位置，在本例中是 test_match/samples.jsonl'
- en: 'To give you an idea of what the samples look like, these are the samples in
    the ***test_match/samples.jsonl*** file:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你了解样本的样子，这些是 ***test_match/samples.jsonl*** 文件中的样本：
- en: Within the JSONL file (just a JSON file with a unique JSON object per line),
    we can see the samples for the eval. Each JSON object represents a task for the
    model to complete, and counts as 1 data point in the eval. For more examples of
    JSONL files, you can go to [registry/data/README.md](https://github.com/openai/evals/blob/main/evals/registry/data/README.md)
    in the Eval Github Repository.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JSONL 文件中（每行一个独特的 JSON 对象的 JSON 文件），我们可以看到评估的样本。每个 JSON 对象代表模型需要完成的任务，并且在评估中计作
    1 个数据点。有关 JSONL 文件的更多示例，可以访问 [registry/data/README.md](https://github.com/openai/evals/blob/main/evals/registry/data/README.md)
    在 Eval Github 存储库中。
- en: In the section below, we’ll go over how to run the test-match eval.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的部分中，我们将介绍如何运行 test-match 评估。
- en: How can I run an eval?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我如何运行评估？
- en: 'We can run the above eval with a simple command:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过一个简单的命令来运行上述评估：
- en: Here we’re using the oaieval CLI to run this eval. We’re specifying the name
    of the completion function (gpt-3.5-turbo) and the name of the eval (test-match).
    It’s as easy as that! *We’ll dive deeper into completion functions and how to
    build your evals in the section below.* After running that command, you’ll see
    the final report of accuracy printed to the console, as well as a file path to
    a temporary file that contains the full report. This just goes to show how easy
    it is to quickly evaluate LLMs using this framework. Next, let’s learn how to
    build our own evals instead of using one already in the registry.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们使用 oaieval CLI 来运行这个评估。我们指定了完成函数的名称（gpt-3.5-turbo）和评估的名称（test-match）。就这么简单！*我们将在下面的部分中更深入地探讨完成函数和如何构建你的评估。*
    运行该命令后，你将看到精度的最终报告打印到控制台，以及一个包含完整报告的临时文件的文件路径。这表明使用这个框架快速评估 LLM 是多么简单。接下来，让我们学习如何构建自己的评估，而不是使用已经在注册表中的评估。
- en: How can I build my own eval?
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我如何构建自己的评估？
- en: In this section, we’ll go over how to build an eval from an existing template,
    as well as explaining completion functions and how to build your own.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍如何从现有模板构建评估，并解释完成函数以及如何构建自己的函数。
- en: Building Evals
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建评估
- en: Building Samples
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建样本
- en: Here we’ll walk through how to build a custom eval using an [existing template](https://github.com/openai/evals/blob/main/docs/eval-templates.md)
    to speed up the work. (If you want to build a completely custom eval, [here is
    a README](https://github.com/openai/evals/blob/main/docs/custom-eval.md) from
    the Eval Github repository.)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将介绍如何使用[现有模板](https://github.com/openai/evals/blob/main/docs/eval-templates.md)来加快工作速度来构建自定义评估。（如果你想构建一个完全自定义的评估，[这里有一个README](https://github.com/openai/evals/blob/main/docs/custom-eval.md)来自Eval
    GitHub存储库。）
- en: 'The first step in building the eval is constructing the samples. The samples
    need to contain certain fields depending on the template that you choose to use.
    Each sample needs to contain an “input” field which represents the prompt, which
    is recommended to be specified in [chat format](https://platform.openai.com/docs/guides/chat/introduction).
    The other fields depend on what template you choose to use for the eval. As an
    example, let’s use the *Match* template. In this case, I’d need to specify the
    field “input” in chat format and “ideal”. This could look like the below:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 构建评估的第一步是构造样本。样本需要根据你选择的模板包含某些字段。每个样本需要包含一个“input”字段，代表提示，建议以[聊天格式](https://platform.openai.com/docs/guides/chat/introduction)指定。其他字段取决于你选择的评估模板。例如，假设我们使用*Match*模板。在这种情况下，我需要在聊天格式中指定“input”字段和“ideal”字段。它可能如下所示：
- en: This is telling the system to complete the phrase as concisely as possible,
    and the phrase we provided is “ABC AI is a company specializing in ML ” with the
    expected answer to be “observability”.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉系统尽可能简洁地完成短语，我们提供的短语是“ABC AI是一家专注于ML的公司”，预期的答案是“可观测性”。
- en: 'If you have the samples in a different file format from JSONL, OpenAI provides
    a CLI to convert those samples to a JSONL file. You can use the code below provided
    by the [Evals repository](https://github.com/openai/evals/blob/main/docs/build-eval.md#formatting-your-data)
    to accomplish that:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的样本在不同于JSONL的文件格式中，OpenAI提供了一个CLI来将这些样本转换为JSONL文件。你可以使用以下代码由[评估存储库](https://github.com/openai/evals/blob/main/docs/build-eval.md#formatting-your-data)提供来完成这个任务：
- en: Great, we have our samples in a JSONL file! The next step is to register our
    eval.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，我们的样本在一个JSONL文件中！下一步是注册我们的评估。
- en: Registering your eval
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注册你的评估
- en: To register the eval, we need to add a file to *evals/registry/evals/<eval_name>.yaml*.
    The format of this file is the same format as the example *test-match* eval above.
    It needs to contain the eval name, id, optional description, metrics, class, and
    args that specify where the sample file is. Once we register the eval, we can
    go ahead and run it just like we ran the test-match eval. That’s all it takes
    to set up your own evals!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 要注册评估，我们需要将一个文件添加到*evals/registry/evals/<eval_name>.yaml*。该文件的格式与上面的示例*test-match*评估格式相同。它需要包含评估名称、ID、可选描述、指标、类别和指定样本文件位置的参数。一旦我们注册了评估，就可以像运行test-match评估一样运行它。这就是设置你自己的评估所需的全部内容！
- en: Building Completion Functions
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建完成函数
- en: What is a completion function?
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是完成函数？
- en: In the *How can I run an eval?* section, we briefly mentioned that you need
    to specify a completion function to run the oaieval command. First, let’s start
    with what a completion is. A completion is a model’s output to a prompt. For example,
    if the prompt we give the model is “Tell me what the capital of California is”,
    we expect the completion to be “Sacramento”. However, some prompts may require
    access to the internet or some other operations that help the model answer the
    question accurately, and this is where completion functions come into play. Completion
    functions allow you to define these operations that the model may need to perform.
    The completion function argument in the **oaieval** command can either be CompletionFn
    URLs, or the name of a model in the OpenAI API or key in the registry. More information
    on completion functions can be found [here](https://github.com/openai/evals/blob/main/docs/completion-fns.md).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *如何运行评估？* 部分，我们简要提到你需要指定一个完成函数来运行 oaieval 命令。首先，让我们了解什么是完成。完成是模型对提示的输出。例如，如果我们给模型的提示是“告诉我加州的首府是什么”，我们期望完成是“萨克拉门托”。然而，有些提示可能需要访问互联网或其他操作来帮助模型准确回答问题，这就是完成函数的作用。完成函数允许你定义模型可能需要执行的这些操作。**oaieval**
    命令中的完成函数参数可以是 CompletionFn URLs，或者是 OpenAI API 中模型的名称或注册表中的键。有关完成函数的更多信息，请参见 [此处](https://github.com/openai/evals/blob/main/docs/completion-fns.md)。
- en: How can I build my own completion function?
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我如何构建自己的完成函数？
- en: In this section, we’ll go over how to build your own completion function. In
    order to make your completion function compatible with all evals, it needs to
    implement a few interfaces. These interfaces essentially just standardize the
    inputs and outputs for the eval. If you’d like to get more information on these
    interfaces, check out the [docs on the Completion Function Protocol here](https://github.com/openai/evals/blob/main/docs/completion-fn-protocol.md).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将讨论如何构建自己的完成函数。为了使你的完成函数与所有评估兼容，它需要实现几个接口。这些接口基本上只是标准化评估的输入和输出。如果你想了解更多有关这些接口的信息，请查看
    [有关完成函数协议的文档](https://github.com/openai/evals/blob/main/docs/completion-fn-protocol.md)。
- en: 'Once your completion functions have been implemented, you need to register
    them similarly to how we registered our eval. Registering the completion function
    allows it to become available to the **oaieval** CLI. An example registration
    taken from the [Evals repository](https://github.com/openai/evals/blob/main/evals/registry/completion_fns/cot.yaml)
    is shown below:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的完成函数实现完毕，你需要像注册我们的评估一样注册它。注册完成函数使其可以在 **oaieval** CLI 中使用。下面是一个来自 [Evals
    仓库](https://github.com/openai/evals/blob/main/evals/registry/completion_fns/cot.yaml)
    的注册示例：
- en: 'Let’s break down the above:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细解析以上内容：
- en: '**cot/gpt-3.5-turbo**: This is the full name of the completion function that
    oaieval will use'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**cot/gpt-3.5-turbo**：这是 oaieval 将使用的完成函数的全名'
- en: '**class**: This is the class path to the implementation of the completion function'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**class**：这是完成函数实现的类路径'
- en: '**args**: Arguments passed to your completion function when initialized'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**args**：初始化时传递给你的完成函数的参数'
- en: '**-> cot_completion_fn**: This is an argument passed to the ChainOfThoughtCompletionFn
    class'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**-> cot_completion_fn**：这是传递给 ChainOfThoughtCompletionFn 类的参数'
- en: Advantages of Using the Eval Framework
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Eval 框架的优势
- en: The Eval Framework provides several benefits to researchers and practitioners.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Eval 框架为研究人员和从业者提供了若干好处。
- en: '**Standardized evaluation metrics and benchmarks**: The Eval Framework provides
    a standardized set of evaluation metrics that researchers can use to compare their
    models’ performance. This allows researchers to compare their models to other
    state-of-the-art models on the same benchmarks.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准化评估指标和基准**：Eval 框架提供了一套标准化的评估指标，研究人员可以用来比较他们模型的性能。这使得研究人员能够将他们的模型与其他最先进的模型在相同的基准上进行比较。'
- en: '**Easy to use**: The Eval Framework is designed to be easy to use. You can
    use existing templates to quickly build your own evals and get up and running
    with only a few lines of code as we’ve shown above.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**易于使用**：Eval 框架旨在易于使用。你可以使用现有的模板快速构建自己的评估，并仅需几行代码即可开始使用，如上所示。'
- en: '**Flexible**: The Eval Framework is flexible and can be used to evaluate models
    on a wide range of tasks and different benchmarks.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**灵活**：Eval 框架具有灵活性，可以用于评估模型在广泛的任务和不同基准上的表现。'
- en: '**Open-source**: The Eval Framework is open-source, which means that researchers/practitioners
    can use and modify it for their specific needs. Additionally, anyone can contribute
    to the [openai/evals Github repository](https://github.com/openai/evals), which
    will help crowdsource even more benchmarks that can be shared across the community.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**开源**：Eval Framework 是开源的，这意味着研究人员/从业者可以根据他们的特定需求使用和修改它。此外，任何人都可以为[openai/evals
    Github 仓库](https://github.com/openai/evals)做贡献，这将有助于众包更多的基准测试，供社区共享。'
- en: Conclusion
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: OpenEvals is a powerful tool for [evaluating LLMs](https://arize.com/blog-course/evals-openai-simplifying-llm-evaluation/),
    providing researchers and practitioners alike a standardized set of evaluation
    metrics and tasks to compare their models to other state-of-the-art models. Given
    its benefits, the framework will likely be a useful tool in the future for evaluating
    and comparing model performance as LLMs continue to improve. Happy evaluating!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: OpenEvals 是一个强大的工具，用于[评估 LLMs](https://arize.com/blog-course/evals-openai-simplifying-llm-evaluation/)，为研究人员和从业者提供了一套标准化的评估指标和任务，以将他们的模型与其他最先进的模型进行比较。考虑到它的好处，这个框架很可能在未来成为评估和比较模型性能的有用工具，因为
    LLMs 将不断改进。祝评估愉快！
