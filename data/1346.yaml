- en: Have Machines Just Made an Evolutionary Leap to Speak in Human Language?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器是否刚刚实现了在人的语言中进行进化性的飞跃？
- en: 原文：[https://towardsdatascience.com/have-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4?source=collection_archive---------15-----------------------#2023-04-17](https://towardsdatascience.com/have-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4?source=collection_archive---------15-----------------------#2023-04-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/have-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4?source=collection_archive---------15-----------------------#2023-04-17](https://towardsdatascience.com/have-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4?source=collection_archive---------15-----------------------#2023-04-17)
- en: '![](../Images/d5cbdf6bebeefae99fe4cb4903ef20f3.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5cbdf6bebeefae99fe4cb4903ef20f3.png)'
- en: 'Image source: Adobe Stock.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Adobe Stock。
- en: '**Assessing where we are on the journey to deep, meaningful communication between
    people and their AI**'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**评估我们在实现人与人工智能之间深层次、有意义的沟通的旅程中的位置**'
- en: '[](https://gadi-singer.medium.com/?source=post_page-----319237593aa4--------------------------------)[![Gadi
    Singer](../Images/293941f11306a6e2100c2375ccb1a85a.png)](https://gadi-singer.medium.com/?source=post_page-----319237593aa4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----319237593aa4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----319237593aa4--------------------------------)
    [Gadi Singer](https://gadi-singer.medium.com/?source=post_page-----319237593aa4--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gadi-singer.medium.com/?source=post_page-----319237593aa4--------------------------------)[![Gadi
    Singer](../Images/293941f11306a6e2100c2375ccb1a85a.png)](https://gadi-singer.medium.com/?source=post_page-----319237593aa4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----319237593aa4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----319237593aa4--------------------------------)
    [Gadi Singer](https://gadi-singer.medium.com/?source=post_page-----319237593aa4--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51de1f48d0b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhave-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4&user=Gadi+Singer&userId=51de1f48d0b&source=post_page-51de1f48d0b----319237593aa4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----319237593aa4--------------------------------)
    ·12 min read·Apr 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F319237593aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhave-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4&user=Gadi+Singer&userId=51de1f48d0b&source=-----319237593aa4---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F51de1f48d0b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhave-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4&user=Gadi+Singer&userId=51de1f48d0b&source=post_page-51de1f48d0b----319237593aa4---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----319237593aa4--------------------------------)
    · 12 min read · 2023年4月17日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F319237593aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhave-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4&user=Gadi+Singer&userId=51de1f48d0b&source=-----319237593aa4---------------------clap_footer-----------)'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F319237593aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhave-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4&source=-----319237593aa4---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F319237593aa4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhave-machines-just-made-an-evolutionary-leap-to-speak-in-human-language-319237593aa4&source=-----319237593aa4---------------------bookmark_footer-----------)'
- en: As people interact with conversational artificial intelligence (AI) systems,
    clear communication is a key factor in getting the intended outcome that will
    best serve and augment our lives. In the broader sense, what language should be
    used for the control system and conversations with machines? In this blog post,
    we evaluate the progression of methods to guide and converse with machines based
    on recent technology innovations, such as OpenAI’s ChatGPT and GPT-4, and explore
    the next needed steps in conversational AIs toward mastering natural conversation
    like a human confidant. Machines have made a categorical leap from prompt engineering
    to “human speak,” however other aspects of intelligence are still awaiting discovery.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 人们与对话型人工智能（AI）系统互动时，清晰的沟通是获得最佳效果的关键因素，这将最有利于提升我们的生活。从更广泛的角度来看，应使用什么语言来控制系统和与机器对话？在这篇博客文章中，我们评估了基于最近技术创新的方法，例如OpenAI的ChatGPT和GPT-4，来引导和对话机器的发展，并探讨对话AI在掌握自然对话方面的下一步所需的步骤。机器已经从提示工程跃升到“人类语言”，但其他智能方面仍在等待发现。
- en: Until recently in 2022, getting an AI to respond properly and utilize its strengths
    required specialized knowledge such as sophisticated prompt engineering. The introduction
    of ChatGPT was a major advancement in the conversational ability of machines,
    making it so that even high school students can chat with high power AI and get
    impressive results. This is a significant milestone. However, we also need to
    assess where we are on the journey of human-machine communication and what is
    still required to achieve meaningful conversations with AI.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 直到2022年之前，让AI做出正确响应并发挥其优势需要专业知识，如复杂的提示工程。ChatGPT的推出是机器对话能力的重大进步，使得即使是高中生也能与高效能AI聊天并获得令人印象深刻的结果。这是一个重要的里程碑。然而，我们也需要评估在人与机器沟通的旅程中，我们处于什么位置，以及还需要什么来实现与AI的有意义对话。
- en: 'The interaction between people and machines has two broad objectives: To instruct
    the machine on needed tasks, and second, to exchange information and guidance
    during the performance of the tasks. The first objective is traditionally done
    by programming, but it is now evolving to where the dialog with the user can define
    a new task, such as asking AI to create a Python script to perform a task. The
    exchange within a task was addressed through natural language processing (NLP)
    or natural language understanding (NLU) coupled with generation of machine response.
    Let us take the assumption that the central characteristics — if not the endpoint
    — of the human-to-machine interaction progression is when people can communicate
    with machines the same as they do with a long-time friend, including all the free-form
    syntactic, semantic, metaphoric, and cultural aspects that are assumed in such
    an interaction. What must be created for AI systems to partake in this natural
    communication fully?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人与机器的互动有两个主要目标：一是指导机器完成所需任务，二是在任务执行过程中交换信息和指导。第一个目标传统上是通过编程来实现，但现在正在演变为用户对话可以定义新任务，例如请求AI创建一个Python脚本来完成任务。在任务执行中的交流是通过自然语言处理（NLP）或自然语言理解（NLU）结合机器响应生成来实现的。我们可以假设，人机互动进展的核心特征——如果不是终点——是当人们可以像与老朋友一样与机器沟通，包括所有的自由形式的语法、语义、隐喻和文化方面的内容。在AI系统要全面参与这种自然交流时，需要创造什么？
- en: Machines have made a categorical leap from prompt engineering to “human speak,”
    however other aspects of intelligence are still awaiting discovery.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 机器已经从提示工程跃升到“人类语言”，但其他智能方面仍在等待发现。
- en: '**Past Conversational AI: Transformer Architecture Redefines NLP Performance**'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**过去的对话AI：变换器架构重新定义了NLP性能**'
- en: '![](../Images/0e2d58942092f9d0995c0cfbc4f7588f.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e2d58942092f9d0995c0cfbc4f7588f.png)'
- en: '*Figure 1\. Evolution of machine programming and instructing. Image source:
    With permission from Intel Labs.*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1\. 机器编程和指令的发展。图片来源：经Intel Labs许可。*'
- en: In the beginning of compute, humans and machines could only communicate through
    machine code, a low-level computer language of binary digits — strings of 0s and
    1s that hold little resemblance to human communication. Over the last century,
    there’s been a gradual journey to make communication with machines closer to human
    language. Today, the fact that we can tell machines to generate a picture of a
    cat playing chess is evidence of great progress. This communication has improved
    gradually with the evolution of programming languages from low to high level code,
    from assembler to C to Python, and the introduction of human speech-like constructs
    such as the if-then statement. Now the final step is to eliminate prompt engineering
    or other sensitivities to tweaks in input phrasing so that machines and humans
    can interact in a natural way. Human-machine dialogue should allow for incremental
    references to continue the conversation from a past “save point.”
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算初期，人类和机器只能通过机器码进行通信，这是一种低级的二进制计算机语言——由0和1组成的字符串，与人类通信几乎没有任何相似之处。过去一个世纪以来，我们逐渐实现了让与机器的交流更接近人类语言的旅程。如今，我们能够让机器生成一张猫在下棋的图片，这是巨大进步的证明。随着编程语言从低级到高级代码的演进，从汇编语言到C语言再到Python，以及引入像if-then语句这样类似人类语言的结构，这种交流逐渐改善。现在的最终步骤是消除输入措辞微调的敏感性，使机器和人类可以以自然的方式互动。人机对话应该允许根据过去的“保存点”进行增量引用以继续对话。
- en: NLP deals with the interactions between computers and human languages to process
    and analyze large amounts of natural language data, while NLU undertakes the difficult
    task of detecting the user’s intention. Virtual assistants such as Alexa and Google
    use NLP, NLU, and machine learning (ML) to acquire new knowledge as they operate.
    By using predictive intelligence and analytics, the AI can personalize conversations
    and responses based on user preferences. While virtual assistants reside in people’s
    homes like a trusted friend, they are currently limited to basic command language
    tautology. People have adapted to this by speaking “keyword-ese” to get the best
    results, but their conversational AI still lags in understanding natural language
    interactions. When there’s a communications breakdown with their virtual assistant,
    people use [repair strategies](https://www.frontiersin.org/articles/10.3389/fcomp.2022.791704/full)
    such as simplification of utterances, variations on the amount of information
    given to the system, semantic and syntactical adjustments to queries, and repetition
    of commands.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）处理计算机与人类语言之间的交互，以处理和分析大量自然语言数据，而自然语言理解（NLU）则承担了检测用户意图的困难任务。像Alexa和Google这样的虚拟助手使用NLP、NLU和机器学习（ML）在运行时获取新知识。通过使用预测性智能和分析，AI可以根据用户偏好个性化对话和响应。虽然虚拟助手像是人们家中的可信朋友，但它们目前仍然受限于基本的命令语言循环。人们已经适应了这一点，通过说出“关键字语言”来获得最佳结果，但他们的对话AI在理解自然语言交互方面仍然存在差距。当与虚拟助手出现沟通中断时，人们会使用[修复策略](https://www.frontiersin.org/articles/10.3389/fcomp.2022.791704/full)，如简化话语、调整信息量的变化、语义和句法上的查询调整以及重复命令。
- en: '![](../Images/688b6b2b167b5169a5dee9f582f9e07b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/688b6b2b167b5169a5dee9f582f9e07b.png)'
- en: '*Figure 2\. Six levels of intent in natural language understanding. Image source:
    With permission from Intel Labs.*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2。自然语言理解中的六个意图层级。图片来源：经由Intel Labs许可使用。*'
- en: This is where NLU is critical in understanding intent. NLU analyzes text and
    speech to determine its meaning (see Figure 2). Using a data model of semantic
    and pragmatic definitions for human speech, NLU focuses on intent and entity recognition.
    The introduction of Transformer neural network architecture in 2018 has led to
    gains in NLP performance in virtual assistants. These types of networks use self-attention
    mechanisms to process input data, allowing them to effectively capture dependencies
    in human language. Introduced by [researchers at Google AI Language](https://arxiv.org/abs/1810.04805),
    BERT addresses 11 of the most common NLP tasks in one model, improving on the
    traditional method of using separate models for each specific task. BERT pre-trains
    language representations by training a general purpose language understanding
    model on a large text corpus such as Wikipedia, and then applying the model to
    downstream NLP tasks such as question answering and language inference.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解意图方面，自然语言理解（NLU）至关重要。NLU 分析文本和语音以确定其含义（见图 2）。使用对人类语言的语义和语用定义的数据模型，NLU 专注于意图和实体识别。2018
    年引入的 Transformer 神经网络架构使虚拟助手的自然语言处理（NLP）性能得到了提升。这些类型的网络利用自注意力机制来处理输入数据，从而有效捕捉人类语言中的依赖关系。由
    [Google AI Language 的研究人员](https://arxiv.org/abs/1810.04805) 提出的 BERT 解决了一个模型中的
    11 个最常见的 NLP 任务，改进了传统的为每个特定任务使用独立模型的方法。BERT 通过在大规模文本语料库（如维基百科）上训练通用语言理解模型，来预训练语言表示，然后将模型应用于下游
    NLP 任务，如问答和语言推理。
- en: Beyond virtual assistants, the advances with ChatGPT are synergistic with Transformer
    models gains in performance for NLP. GPT-3 Transformer technology was introduced
    in 2021, but its major breakthrough in popularity and use was achieved with ChatGPT
    and its innovation in the ability to have a human-like conversational interface,
    which was made possible by utilizing [reinforcement learning from human feedback
    (RLHF)](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback).
    ChatGPT enables LLMs to process and understand natural language inputs and generate
    outputs as human-like as possible.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 除了虚拟助手之外，ChatGPT 的进步与 Transformer 模型在 NLP 性能上的提升是相辅相成的。GPT-3 Transformer 技术于
    2021 年引入，但其在流行度和使用上的重大突破是通过 ChatGPT 实现的，其在人类对话界面的创新得以通过 [来自人类反馈的强化学习（RLHF）](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback)
    的应用实现。ChatGPT 使大型语言模型能够处理和理解自然语言输入，并生成尽可能接近人类的输出。
- en: '**Present: Large Language Models Dominate Conversational AI**'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**当前：大型语言模型主导对话式人工智能**'
- en: Since its release by OpenAI in November 2022, [ChatGPT](https://openai.com/blog/chatgpt)
    has dominated the news with its seemingly well-written language generation for
    essays and tests, and successful passing of medical license and MBA exams. ChatGPT
    passed all three exams for the [U.S. Medical Licensing Examination](https://www.medrxiv.org/content/10.1101/2022.12.19.22283643v2.full)
    (USMLE) without any training or reinforcement. This led to researchers to conclude
    that “large language models may have the potential to assist with medical education,
    and potentially, clinical decision-making.” A [Wharton School professor at the
    University of Pennsylvania](https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/)
    tested ChatGPT on an Operations Management MBA final exam, and it received a B
    to B- grade. ChatGPT performed well on basic operations management and process
    analysis questions based on case studies, providing correct answers and solid
    explanations. When ChatGPT failed to match the problem with the right solution
    method, hints from a human expert helped the model correct its answer. While these
    results are promising, ChatGPT has limitations in reaching conversation at the
    human level (we’ll discuss in the next section).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2022 年 11 月由 OpenAI 发布以来，[ChatGPT](https://openai.com/blog/chatgpt) 以其似乎写得很好的语言生成能力和成功通过医学执照及
    MBA 考试的表现主导了新闻。ChatGPT 在没有任何训练或强化的情况下通过了 [美国医学执照考试](https://www.medrxiv.org/content/10.1101/2022.12.19.22283643v2.full)（USMLE）的所有三个考试。这导致研究人员得出结论：“大型语言模型可能有潜力协助医学教育，并有可能辅助临床决策。”
    一位 [宾夕法尼亚大学沃顿商学院的教授](https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/)
    对 ChatGPT 进行了运营管理 MBA 期末考试测试，其成绩为 B 到 B-。ChatGPT 在基于案例研究的基础运营管理和过程分析问题上表现良好，提供了正确的答案和充分的解释。当
    ChatGPT 未能将问题与正确的解决方法匹配时，人类专家的提示帮助模型纠正了答案。尽管这些结果令人鼓舞，但 ChatGPT 在达到人类水平的对话方面仍有局限性（我们将在下一节讨论）。
- en: As an autoregressive language model with 175 billion parameters, ChatGPT’s large
    model size helps it to perform well on understanding user intent. Based on the
    levels of intent in Figure 2, ChatGPT can process pragmatic requests from users
    that contain an open argument set and flexible structure by analyzing what the
    text prompt is trying to achieve. ChatGPT can write highly detailed responses
    and articulate answers, demonstrating a breadth and depth of knowledge across
    different domains, such as medicine, business operations, computer programming,
    and more. GPT-4 is also showing impressive strengths, such as adding multimodal
    capabilities and improving scores on advanced human tests. GPT-4 is [reported
    to have scored](https://arxiv.org/pdf/2303.08774.pdf) in the 90th percentile of
    the Uniform Bar Exams (versus the 10th percentile for ChatGPT) and in the 99th
    percentile on the USA Biology Olympiad (vs the 31st percentile for ChatGPT).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '-   作为一个自回归语言模型，ChatGPT 拥有 1750 亿个参数，其庞大的模型尺寸帮助其在理解用户意图方面表现出色。基于图 2 中的意图水平，ChatGPT
    可以通过分析文本提示的目标来处理用户包含开放参数集和灵活结构的实用请求。ChatGPT 能够撰写高度详细的回答和清晰的答案，展示出对医学、业务运营、计算机编程等不同领域的广泛和深刻的知识。GPT-4
    也显示出了令人印象深刻的优势，例如添加多模态能力和在高级人类测试中提高得分。据报道，GPT-4 在统一巴尔考试中的得分为 90 分位数（ChatGPT 为
    10 分位数），在美国生物奥林匹克竞赛中的得分为 99 分位数（ChatGPT 为 31 分位数）。'
- en: '[ChatGPT can also do machine programming](https://www.zdnet.com/article/how-to-use-chatgpt-to-write-code/),
    albeit to a degree. It can create programs in multiple languages including [Python,
    JavaScript, C++, Java](https://seo.ai/blog/how-many-languages-does-chatgpt-support),
    and more. It can also [analyze code for bugs and performance issues](https://www.zdnet.com/article/chatgpt-can-write-code-now-researchers-say-its-good-at-fixing-bugs-too/).
    However, so far it seems to be best utilized as part of a joint programmer/AI
    combination.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[ChatGPT 也可以进行机器编程](https://www.zdnet.com/article/how-to-use-chatgpt-to-write-code/)，尽管程度有限。它可以创建多种语言的程序，包括
    [Python, JavaScript, C++, Java](https://seo.ai/blog/how-many-languages-does-chatgpt-support)，等等。它还可以
    [分析代码中的错误和性能问题](https://www.zdnet.com/article/chatgpt-can-write-code-now-researchers-say-its-good-at-fixing-bugs-too/)。然而，目前看来，最好的利用方式似乎是作为程序员和人工智能的联合组合的一部分。'
- en: While OpenAI’s models are attracting much attention, other models are progressing
    in similar direction, such as Google Brain’s open source 1.6 trillion-parameter
    [Switch Transformer](https://arxiv.org/abs/2101.03961) which debuted in 2021,
    and [Google Bard](https://blog.google/technology/ai/bard-google-ai-search-updates/),
    which uses LaMDA (Language Model for Dialogue Applications) technology to search
    the web and provide real-time answers. Bard is currently only available to beta
    testers, so its performance against ChatGPT is unknown.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '-   尽管 OpenAI 的模型吸引了很多关注，其他模型也在类似的方向上取得进展，例如 Google Brain 的开源 1.6 万亿参数的 [Switch
    Transformer](https://arxiv.org/abs/2101.03961)，该模型在 2021 年首次亮相，以及使用 LaMDA（用于对话应用的语言模型）技术的
    [Google Bard](https://blog.google/technology/ai/bard-google-ai-search-updates/)。Bard
    目前仅对测试用户开放，因此其与 ChatGPT 的表现尚不为人知。'
- en: While LLMs have made great strides toward having natural conversations with
    humans, key growth areas need to be addressed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '-   尽管大语言模型在与人类进行自然对话方面取得了巨大进展，但仍需要解决关键增长领域。'
- en: To reach the next level of intelligence and human-level communication, key areas
    need to undergo a leap in capabilities — restructuring of knowledge, integration
    of multiple skills, and providing contextual adaptation.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '-   要达到下一个智能水平和人类级沟通，关键领域需要能力飞跃 —— 知识重组，多技能整合和提供上下文适应。'
- en: '**Future: What is Missing from the Human-Machine Conversation?**'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '-   **未来：人机对话缺少什么？**'
- en: Four key elements are still missing in moving conversational AI to the next
    level in carrying on natural conversations. To reach this level of intimacy and
    shared purpose, the machine needs to understand the meaning of the person’s symbolic
    communication, and answer with trustworthy custom responses that are meaningful
    to the person.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '-   在将会话型人工智能推向下一个水平的过程中，仍然存在四个关键元素的缺失，这些元素包括达成自然对话的亲密性和共享目的。要达到这一水平，机器需要理解个体的象征性沟通的含义，并用有意义的、可信赖的定制回应来回应。'
- en: '**1) Producing trustworthy responses.** AI systems should not hallucinate!
    Epistemological problems affect the way AI builds knowledge and differentiates
    between known and unknown information. The machine can make mistakes, producing
    biased results or even hallucinating when providing answers about things it doesn’t
    know. ChatGPT has difficulty with capturing source attribution and information
    provenance. It can generate plausible sounding, but incorrect or nonsensical answers.
    In addition, it lacks factual correctness and common sense with physical, spatial,
    and temporal questions, and struggles with math reasoning. According to OpenAI,
    it has [difficulty with questions](https://doi.org/10.48550/arxiv.2005.14165)
    such as: “If I put cheese into the fridge, will it melt?” It performs poorly when
    [planning or thinking methodically](https://thenextweb.com/news/large-language-models-cant-plan).
    When tested on the [MBA final exam](https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/),
    it made surprising mistakes in 6th grade level math, which could cause massive
    errors in operations. The research found that “Chat GPT was not capable of handling
    more advanced process analysis questions, even when they are based on standard
    templates. This includes process flows with multiple products and problems with
    stochastic effects such as demand variability.”'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**1) 生成可信的回应。** AI 系统不应该产生幻觉！认识论问题影响了 AI 构建知识的方式，以及区分已知和未知信息的能力。当机器在不了解的事物上提供答案时，可能会出错，产生有偏见的结果，甚至是幻觉。ChatGPT
    在捕捉来源归因和信息出处方面存在困难。它可以生成听起来合理但错误或荒谬的答案。此外，它在处理物理、空间和时间问题以及数学推理方面缺乏事实的正确性和常识。据
    OpenAI 称，它在处理“如果我把奶酪放进冰箱，它会融化吗？”这样的问题时表现不佳。在 [MBA 期末考试](https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/)
    上测试时，它在六年级水平的数学中出现了令人惊讶的错误，可能导致操作上的重大错误。研究发现，“Chat GPT 在处理更复杂的流程分析问题时能力不足，即使这些问题基于标准模板。这包括具有多种产品和需求变异等随机效应的流程流程。”'
- en: '**2) Deep understanding of human symbology and idiosyncrasies.** AI needs to
    work within the full symbolic world of humans, including the ability to do abstraction,
    customize, and understand partial references. The machine must be able to interpret
    people’s speech ambiguities and incomplete sentences in order to have meaningful
    conversations.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**2) 对人类符号和特殊习惯的深刻理解。** AI 需要在人类的完整符号世界内工作，包括能够进行抽象、定制和理解部分引用。机器必须能够解释人们言辞中的模棱两可和不完整的句子，以便进行有意义的对话。'
- en: '![](../Images/fa99e2701e7ffe3b7b6712a01aee2544.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa99e2701e7ffe3b7b6712a01aee2544.png)'
- en: '*Figure 3\. An example from the* [*Switchboard collection*](https://catalog.ldc.upenn.edu/LDC97S62)
    *of two-sided telephone conversations between speakers from all areas of the United
    States. Image source: With permission from Intel Labs.*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3\. 从* [*Switchboard 收集*](https://catalog.ldc.upenn.edu/LDC97S62) *中的一个例子，展示了来自美国各地发言者之间的双向电话对话。图片来源：经过
    Intel Labs 的许可。*'
- en: As shown in Figure 3, human speech patterns are often unintelligible. Should
    AI speak exactly like a human? Realistically, it could be the same as a person
    talking with a friend with loosely structured language, including a reasonable
    amount of “hmms,” “likes,” incomplete or ill formed sentences, ambiguities, semantic
    abstractions, personal references, and common-sense inferences. But these idiosyncrasies
    of human speech should not overpower the communication, rendering it unintelligible.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如图 3 所示，人类的言语模式经常是难以理解的。AI 是否应该像人类一样说话？实际上，它可以与朋友一样使用松散结构的语言进行交流，包括合理数量的“嗯嗯”、“喜欢”、“不完整或不完整的句子”、“模棱两可”、“语义抽象”、“个人引用”
    和常识推断。但这些人类言语的特殊习惯不应该使沟通变得难以理解。
- en: '**3) Providing custom responses.** AI needs the ability to customize and be
    familiar with the world of the user. ChatGPT often guesses the user’s intent instead
    of asking clarifying questions. In addition, as a fully encapsulated information
    model, ChatGPT does not have the ability to browse or search the internet to provide
    custom answers for the user. According to OpenAI, [ChatGPT is limited in its custom
    answers](https://arxiv.org/abs/2005.14165) because “it weights every token equally
    and lacks a notion of what is most important to predict and what is less important.
    With self-supervised objectives, task specification relies on forcing the desired
    task into a prediction problem, whereas ultimately, useful language systems (like
    virtual assistants) might be better thought of as taking goal-directed actions
    rather than just making predictions.” In addition, it would be helpful to have
    a multi-session context of the human-machine conversations as well as a [theory
    of mind model of the user](/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**3) 提供定制化响应。** AI 需要具备定制能力并熟悉用户的世界。ChatGPT 经常猜测用户的意图，而不是提出澄清问题。此外，作为一个完全封装的信息模型，ChatGPT
    不具备浏览或搜索互联网以提供定制答案的能力。根据 OpenAI 的说法，[ChatGPT 的定制答案有限](https://arxiv.org/abs/2005.14165)，因为“它对每个标记的权重相等，缺乏对预测中最重要和较不重要内容的概念。通过自我监督目标，任务规格依赖于将期望任务强制变成预测问题，而最终，像虚拟助手这样的有用语言系统可能更应被视为采取目标导向的行动，而不仅仅是进行预测。”此外，拥有多会话的人工与机器对话的上下文，以及[用户的心理理论模型](/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e)会很有帮助。'
- en: '**4) Becoming purpose-driven.** When people work with a companion, the coordination
    is not just based on a text exchange, but on a shared purpose. AI needs to move
    beyond contextualized answers to become purpose driven. In the evolving human-machine
    relationship, both parties need to become a part of a journey to accomplish a
    goal, avoid or alleviate a problem, or share information. ChatGPT and other LLMs
    have not reached this level of interaction yet. As I explored in a previous blog,
    intelligent machines need to [go beyond input-to-output replies and conversations](https://medium.com/towards-data-science/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e)
    as a chatbot.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**4) 成为目标驱动。** 当人们与伴侣合作时，协调不仅仅基于文本交换，而是基于共同的目标。AI 需要超越上下文答案，变得目标驱动。在不断发展的人工与机器关系中，双方需要成为实现目标、避免或减轻问题，或共享信息的过程的一部分。ChatGPT
    和其他 LLM 尚未达到这种交互水平。正如我在之前的博客中探讨的那样，智能机器需要[超越输入输出回复和对话](https://medium.com/towards-data-science/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e)作为聊天机器人。'
- en: To reach the next level of intelligence and human-level communication, key areas
    need to undergo a leap in capabilities — restructuring of knowledge, integration
    of multiple skills, and providing contextual adaptation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了达到下一水平的智能和人类级别的沟通，关键领域需要在能力上实现飞跃——知识的重组、技能的整合以及提供上下文适应。
- en: '**The Path to the Next Level in Conversational AIs**'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**通往对话 AI 下一水平的道路**'
- en: 'LLMs like ChatGPT still have gaps in the cognitive skills needed to take conversational
    AI to the next level. Missing competencies include logical reasoning, temporal
    reasoning, numeric reasoning, and the overall ability to be goal-driven and define
    subtasks to achieve a larger task. Knowledge-related limitations in ChatGPT and
    other LLMs can be addressed by a [](https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Thrill-K-A-Blueprint-for-The-Next-Generation-of-Machine/post/1397951?wapkw=gadi+singer+thrill-K)
    [Thrill-K approach](/thrill-k-a-blueprint-for-the-next-generation-of-machine-intelligence-7ddacddfa0fe),
    by adding retrieval and continuous learning. Knowledge resides in three places
    for AI:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 像 ChatGPT 这样的 LLM 仍在认知技能上存在差距，这些技能是将对话 AI 提升到下一水平所必需的。缺失的能力包括逻辑推理、时间推理、数值推理以及整体上驱动目标的能力和定义子任务以完成更大任务的能力。ChatGPT
    和其他 LLM 的知识相关限制可以通过[Thrill-K 方法](https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Thrill-K-A-Blueprint-for-The-Next-Generation-of-Machine/post/1397951?wapkw=gadi+singer+thrill-K)来解决，通过增加检索和持续学习。知识对于
    AI 存在于三个地方：
- en: '**1) Instantaneous knowledge.** Knowledge commonly used and continuous functions
    that can be effectively approximated, available in the fastest and most expensive
    layer within the parametric memory for the neural network or other working memory
    for other ML processing. ChatGPT currently uses this end-to-end deep learning
    system, but it needs to expand to include other knowledge sources to be more effective
    as a human companion.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**1) 即时知识.** 常用的知识和连续功能，可以在参数化内存中的最快最昂贵的层或其他ML处理的工作内存中有效近似，ChatGPT目前使用这种端到端的深度学习系统，但需要扩展以包括其他知识来源，以便作为人类伴侣更有效。'
- en: '**2) Standby knowledge.** Knowledge that is valuable to the AI system but not
    as commonly used, available in an adjacent structured knowledge base with as-needed
    extraction. It requires increased representation strength for discrete entities,
    or needs to be kept generalized and flexible for a variety of novel uses. Actions
    or outcomes based on standby knowledge require processing and internal resolution,
    enabling the AI to learn and adapt as a human companion.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**2) 待机知识.** 对AI系统有价值但不常用的知识，通过需要时从相邻的结构化知识库提取。它需要增强对离散实体的表示能力，或者需要保持广泛而灵活，以适应各种新的使用方式。基于待机知识的行动或结果需要处理和内部解决，使得AI能够像人类伴侣一样学习和适应。'
- en: '**3) Retrieved external knowledge.** Information from a vast online repository,
    available outside the AI system for retrieval when needed. This allows the AI
    to customize answers for the human companion with several modalities of information,
    provide reasoned analysis, and explain the sources of information and the path
    to conclusion.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**3) 检索的外部知识.** 来自广阔在线存储库的信息，供AI系统外检索时使用。这使得AI能够根据人类伴侣的需求定制答案，提供理性分析，并解释信息来源和达到结论的路径。'
- en: '**Summary**'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**总结**'
- en: The journey from machine language to human speak has evolved from humans inputting
    simple binary digits into a computer, to bringing virtual assistants into our
    homes to perform simple tasks, to asking and receiving articulate answers from
    LLMs such as ChatGPT. Despite this great progress in recent innovations in LLMs,
    the path to the next level of conversational AI requires knowledge restructuring,
    multiple intelligences, and contextual adaptation to build AI that are true human
    companions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从机器语言到人类语言的旅程已经从人类输入简单的二进制数字到计算机，发展到在家里使用虚拟助手执行简单任务，再到向像ChatGPT这样的LLM询问并接收明确答案。尽管LLM在近期的创新取得了巨大进展，但要达到下一个水平的对话型AI，需要知识重组、多重智能和上下文适应，以构建真正的人类伴侣。
- en: '**References**'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: 'Mavrina, L., Szczuka, J. M., Strathmann, C., Bohnenkamp, L., Krämer, N. C.,
    & Kopp, S. (2022). “Alexa, You’re Really Stupid”: A Longitudinal Field Study on
    Communication Breakdowns Between Family Members and a Voice Assistant. *Frontiers
    in Computer Science*, *4*. [https://doi.org/10.3389/fcomp.2022.791704](https://doi.org/10.3389/fcomp.2022.791704)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Mavrina, L., Szczuka, J. M., Strathmann, C., Bohnenkamp, L., Krämer, N. C.,
    & Kopp, S. (2022). “Alexa, You’re Really Stupid”: A Longitudinal Field Study on
    Communication Breakdowns Between Family Members and a Voice Assistant. *计算机科学前沿*,
    *4*. [https://doi.org/10.3389/fcomp.2022.791704](https://doi.org/10.3389/fcomp.2022.791704)'
- en: 'Devlin, J. (2018, October 11). BERT: Pre-training of Deep Bidirectional Transformers
    for Language Understanding. arXiv.org. [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Devlin, J. (2018年, 10月11日). BERT: 深度双向转换器的预训练用于语言理解. arXiv.org. [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
- en: Wikipedia contributors. (2023). Reinforcement learning from human feedback.
    Wikipedia. [https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback)
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wikipedia贡献者. (2023年). 从人类反馈中的强化学习. 维基百科. [https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback)
- en: Introducing ChatGPT. (n.d.). [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍ChatGPT. (无日期). [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)
- en: 'Kung, T. H., Cheatham, M., Medenilla, A., Sillos, C., De Leon, L., Elepaño,
    C., Madriaga, M., Aggabao, R., Diaz-Candido, G., Maningo, J., & Tseng, V. (2022).
    Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using
    Large Language Models. medRxiv (Cold Spring Harbor Laboratory). [https://doi.org/10.1101/2022.12.19.22283643](https://doi.org/10.1101/2022.12.19.22283643)'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kung, T. H., Cheatham, M., Medenilla, A., Sillos, C., De Leon, L., Elepaño,
    C., Madriaga, M., Aggabao, R., Diaz-Candido, G., Maningo, J., & Tseng, V. (2022)。ChatGPT
    在 USMLE 上的表现：利用大型语言模型进行 AI 辅助医学教育的潜力。medRxiv（冷泉港实验室）。 [https://doi.org/10.1101/2022.12.19.22283643](https://doi.org/10.1101/2022.12.19.22283643)
- en: Needleman, E. (2023). Would Chat GPT Get a Wharton MBA? New White Paper By Christian
    Terwiesch. Mack Institute for Innovation Management. [https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/](https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/)
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Needleman, E. (2023)。Chat GPT 能获得沃顿 MBA 吗？Christian Terwiesch 新白皮书。Mack 创新管理研究所。
    [https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/](https://mackinstitute.wharton.upenn.edu/2023/would-chat-gpt3-get-a-wharton-mba-new-white-paper-by-christian-terwiesch/)
- en: OpenAI. (2023). GPT-4 Technical Report. arXiv (Cornell University). [https://doi.org/10.48550/arxiv.2303.08774](https://doi.org/10.48550/arxiv.2303.08774)
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI. (2023)。GPT-4 技术报告。arXiv（康奈尔大学）。 [https://doi.org/10.48550/arxiv.2303.08774](https://doi.org/10.48550/arxiv.2303.08774)
- en: Gewirtz, D. (2023, April 6). How to use ChatGPT to write code. ZDNET. [https://www.zdnet.com/article/how-to-use-chatgpt-to-write-code/](https://www.zdnet.com/article/how-to-use-chatgpt-to-write-code/)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gewirtz, D. (2023年4月6日)。如何使用 ChatGPT 编写代码。ZDNET。 [https://www.zdnet.com/article/how-to-use-chatgpt-to-write-code/](https://www.zdnet.com/article/how-to-use-chatgpt-to-write-code/)
- en: How Many Languages Does ChatGPT Support? The Complete ChatGPT Language List.
    (n.d.). [https://seo.ai/blog/how-many-languages-does-chatgpt-support](https://seo.ai/blog/how-many-languages-does-chatgpt-support)
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ChatGPT 支持多少种语言？完整的 ChatGPT 语言列表。 (n.d.). [https://seo.ai/blog/how-many-languages-does-chatgpt-support](https://seo.ai/blog/how-many-languages-does-chatgpt-support)
- en: Tung, L. (2023, February 2). ChatGPT can write code. Now researchers say it’s
    good at fixing bugs, too. ZDNET. [https://www.zdnet.com/article/chatgpt-can-write-code-now-researchers-say-its-good-at-fixing-bugs-too/](https://www.zdnet.com/article/chatgpt-can-write-code-now-researchers-say-its-good-at-fixing-bugs-too/)
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Tung, L. (2023年2月2日)。ChatGPT 能编写代码。现在研究人员说它也擅长修复漏洞。ZDNET。 [https://www.zdnet.com/article/chatgpt-can-write-code-now-researchers-say-its-good-at-fixing-bugs-too/](https://www.zdnet.com/article/chatgpt-can-write-code-now-researchers-say-its-good-at-fixing-bugs-too/)
- en: 'Fedus, W., Zoph, B., & Shazeer, N. (2021). Switch Transformers: Scaling to
    Trillion Parameter Models with Simple and Efficient Sparsity. arXiv (Cornell University).
    [https://doi.org/10.48550/arxiv.2101.03961](https://doi.org/10.48550/arxiv.2101.03961)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Fedus, W., Zoph, B., & Shazeer, N. (2021)。Switch Transformers：以简单有效的稀疏性扩展到万亿参数模型。arXiv（康奈尔大学）。
    [https://doi.org/10.48550/arxiv.2101.03961](https://doi.org/10.48550/arxiv.2101.03961)
- en: Pichai, S. (2023, February 6). An important next step on our AI journey. Google.
    [https://blog.google/technology/ai/bard-google-ai-search-updates/](https://blog.google/technology/ai/bard-google-ai-search-updates/)
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pichai, S. (2023年2月6日)。我们 AI 旅程中的一个重要下一步。Google。 [https://blog.google/technology/ai/bard-google-ai-search-updates/](https://blog.google/technology/ai/bard-google-ai-search-updates/)
- en: Dickson, B. (2022, July 31). Large language models can’t plan, even if they
    write fancy essays. TNW | Deep-Tech. [https://thenextweb.com/news/large-language-models-cant-plan](https://thenextweb.com/news/large-language-models-cant-plan)
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dickson, B. (2022年7月31日)。大型语言模型无法计划，即使它们写出花哨的文章。TNW | Deep-Tech。 [https://thenextweb.com/news/large-language-models-cant-plan](https://thenextweb.com/news/large-language-models-cant-plan)
- en: Brown, T., Mann, B. F., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan,
    A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger,
    G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J. C., Winter, C.,
    . . . Amodei, D. (2020). Language Models are Few-Shot Learners. arXiv (Cornell
    University). [https://doi.org/10.48550/arxiv.2005.14165](https://doi.org/10.48550/arxiv.2005.14165)
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Brown, T., Mann, B. F., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan,
    A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger,
    G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J. C., Winter, C.,
    . . . Amodei, D. (2020)。语言模型是少样本学习者。arXiv（康奈尔大学）。 [https://doi.org/10.48550/arxiv.2005.14165](https://doi.org/10.48550/arxiv.2005.14165)
- en: 'Singer, G. (2022, August 17). Beyond Input-Output Reasoning: Four Key Properties
    of Cognitive AI. Medium. [https://towardsdatascience.com/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e](/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e)'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Singer, G. (2022年8月17日). 超越输入输出推理：认知人工智能的四个关键特性。Medium. [https://towardsdatascience.com/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e](/beyond-input-output-reasoning-four-key-properties-of-cognitive-ai-3f82cde8cf1e)
- en: 'Singer, G. (2022, January 6). Thrill-K: A Blueprint for The Next Generation
    of Machine Intelligence. Medium. [https://towardsdatascience.com/thrill-k-a-blueprint-for-the-next-generation-of-machine-intelligence-7ddacddfa0fe](/thrill-k-a-blueprint-for-the-next-generation-of-machine-intelligence-7ddacddfa0fe)'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Singer, G. (2022年1月6日). Thrill-K：下一代机器智能的蓝图。Medium. [https://towardsdatascience.com/thrill-k-a-blueprint-for-the-next-generation-of-machine-intelligence-7ddacddfa0fe](/thrill-k-a-blueprint-for-the-next-generation-of-machine-intelligence-7ddacddfa0fe)
