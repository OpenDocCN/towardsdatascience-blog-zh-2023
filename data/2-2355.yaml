- en: Which Data Format to Use For Your Big Data Project?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 针对你的大数据项目，应该使用哪个数据格式？
- en: 原文：[https://towardsdatascience.com/which-data-format-to-use-for-your-big-data-project-837a48d3661d](https://towardsdatascience.com/which-data-format-to-use-for-your-big-data-project-837a48d3661d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/which-data-format-to-use-for-your-big-data-project-837a48d3661d](https://towardsdatascience.com/which-data-format-to-use-for-your-big-data-project-837a48d3661d)
- en: 'Pickle, Parquet, CSV, Feather, HDF5, ORC, JSON: which one should you be using
    and why?'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pickle、Parquet、CSV、Feather、HDF5、ORC、JSON：你应该使用哪个格式，为什么？
- en: '[](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)[![Armand
    Sauzay](../Images/94b12efc184d75380f293b457c95597f.png)](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)
    [Armand Sauzay](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)[![Armand
    Sauzay](../Images/94b12efc184d75380f293b457c95597f.png)](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)
    [Armand Sauzay](https://armandsauzay.medium.com/?source=post_page-----837a48d3661d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)
    ·6 min read·Oct 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----837a48d3661d--------------------------------)
    ·6分钟阅读·2023年10月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f6052f807142ff0736003534edc8f2dc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6052f807142ff0736003534edc8f2dc.png)'
- en: Image by Maarten van den Heuvel — [Unsplash](https://unsplash.com/photos/assorted-color-book-lot-8EzNkvLQosk)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于Maarten van den Heuvel — [Unsplash](https://unsplash.com/photos/assorted-color-book-lot-8EzNkvLQosk)
- en: Choosing the right data format is crucial in Data Science projects, impacting
    everything from data read/write speeds to memory consumption and interoperability.
    This article explores seven popular serialization/deserialization formats in Python,
    focusing on their speed and memory usage implications.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 选择正确的数据格式在数据科学项目中至关重要，影响从数据读写速度到内存消耗和互操作性等各个方面。本文探讨了Python中七种流行的序列化/反序列化格式，重点关注它们的速度和内存使用影响。
- en: Through the analysis, we’ll also see how we can use profiling in Python (using
    the `cProfile` built-in module) and how we can get statistics on memory usage
    for specific files in your filesystem (using the `os` Python module).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析，我们还将看到如何在Python中使用性能分析（使用`cProfile`内置模块），以及如何获取文件系统中特定文件的内存使用统计（使用`os`
    Python模块）。
- en: Of course, each project has its specificities, beyond just speed and memory
    usage. But we’ll draw some trends, that can hopefully be useful to shed light
    on which format we can choose for a given project.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，每个项目都有其特定性，除了速度和内存使用之外。我们将总结一些趋势，希望能为选择适合的格式提供一些启示。
- en: Understanding Serialization and Deserialization
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解序列化和反序列化
- en: Serialization is the process of saving an object (in Python, a pandas DataFrame
    for example) to a format that can be saved to a file for later retrieval. Deserialization
    is the reverse process.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 序列化是将对象（例如Python中的pandas DataFrame）保存为可以保存到文件中以供后续检索的格式的过程。反序列化是这个过程的逆过程。
- en: A dataframe is a Python object and cannot be persisted as is. It needs to be
    translated to a file to be able to load this object at a later stage.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框是一个Python对象，不能直接持久化。它需要被转换成文件，以便在后续阶段加载该对象。
- en: When you save a dataframe, you “serialize” the data. And when you load it back,
    you “deserialize” or translate it back to a language-readable (here Python-readable)
    format.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当你保存数据框时，你是在“序列化”数据。当你将其加载回时，你是在“反序列化”或将其转换回可读的（此处为Python可读）格式。
- en: Certain formats are widely used because they are human-readable, such as JSON
    or CSV. These two formats are also used because they are language agnostic. Just
    like [protocol buffers](https://protobuf.dev/), which were originally developed
    by Google. JSON and Protocol buffer are also popular for APIs and enable sending
    data between different services written in different languages.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 某些格式因其可读性广泛使用，如JSON或CSV。这两种格式还因其语言无关性而被使用。就像[协议缓冲区](https://protobuf.dev/)，最初由Google开发。JSON和协议缓冲区在API中也很受欢迎，使得不同语言编写的服务之间能够传递数据。
- en: On the other hand, some formats, like Python’s pickle, are language-specific
    and not ideal for transferring data between services in different programming
    languages. For example, for a machine learning use case, if a repository trains
    a model and serializes it in pickle, this file will only be able to be read from
    Python. So if the API that serves that machine learning model is written in Java,
    some transformations will have to be done before it can be used.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，一些格式，如 Python 的 pickle，是特定于语言的，不适合在不同编程语言的服务之间传输数据。例如，对于机器学习用例，如果一个仓库训练了一个模型并用
    pickle 序列化，那么这个文件只能被 Python 读取。因此，如果提供该机器学习模型的 API 是用 Java 编写的，则必须进行一些转换才能使用。
- en: But for storing large data files, formats like CSV, JSON, and Protocol Buffers
    fall short in performance compared to more specialized formats like [HDF5](https://www.hdfgroup.org/solutions/hdf5/),
    [Parquet](https://www.databricks.com/glossary/what-is-parquet), [Feather](https://arrow.apache.org/docs/python/feather.html)
    or [ORC](https://cwiki.apache.org/confluence/display/hive/languagemanual+orc).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但对于存储大型数据文件，CSV、JSON 和 Protocol Buffers 等格式在性能上不如更专业的格式，如 [HDF5](https://www.hdfgroup.org/solutions/hdf5/)、[Parquet](https://www.databricks.com/glossary/what-is-parquet)、[Feather](https://arrow.apache.org/docs/python/feather.html)
    或 [ORC](https://cwiki.apache.org/confluence/display/hive/languagemanual+orc)。
- en: 'When working with data in Python, [pandas](https://pandas.pydata.org/) provide
    a convenient API to extract, transform and load data. Pandas supports a wide array
    of formats (all the supported ones can be found [here](https://pandas.pydata.org/docs/user_guide/io.html)),
    among which we chose the seven most used formats and compared their performance:
    JSON, CSV, Parquet, Pickle, Feather, HDF5, and ORC.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中处理数据时，[pandas](https://pandas.pydata.org/) 提供了一个方便的 API 用于提取、转换和加载数据。Pandas
    支持多种格式（所有支持的格式可以在 [这里](https://pandas.pydata.org/docs/user_guide/io.html) 找到），其中我们选择了使用最广泛的七种格式并比较了它们的性能：JSON、CSV、Parquet、Pickle、Feather、HDF5
    和 ORC。
- en: The code found to reproduce the analysis can be found [here](https://www.kaggle.com/code/armandsauzay/save-load-speed-vs-format-csv-feat-pkl-pqt/edit/run/134172694).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: reproducing 分析的代码可以在 [这里](https://www.kaggle.com/code/armandsauzay/save-load-speed-vs-format-csv-feat-pkl-pqt/edit/run/134172694)
    找到。
- en: Experimental approach
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实验方法
- en: '**Speed** and **memory usage** are two key components to look at when choosing
    the right data format for your project. But these vary based on both the size
    of the data, and which type of data is being used.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**速度** 和 **内存使用** 是选择项目合适数据格式时需要关注的两个关键因素。但这些因素会根据数据的大小和使用的数据类型而有所不同。'
- en: 'To do the analysis, we created 3 datasets that should cover most use cases:
    a number only dataframe, a strings-only dataframe and a dataframe with both numbers
    and strings. Each dataframe is 10,000 rows over 100 columns and are defined by
    the following code:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行分析，我们创建了 3 个数据集，这些数据集应涵盖大多数用例：仅包含数字的数据框、仅包含字符串的数据框和包含数字和字符串的数据框。每个数据框有 10,000
    行和 100 列，代码定义如下：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For the memory usage, we just look at what is the size of the dataset when saved.
    To measure memory usage, we’ll use Python’s `os` module, and specifically `os.stat`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内存使用情况，我们只需查看保存数据集时的大小。为了测量内存使用情况，我们将使用 Python 的 `os` 模块，特别是 `os.stat`。
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For the speed, we use Python’s [cProfile](https://docs.python.org/3/library/profile.html)
    library to profile the time taken by functions to execute. Here, we take a window
    of 10 seconds and look at how many times the function executed. In essence:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于速度，我们使用 Python 的 [cProfile](https://docs.python.org/3/library/profile.html)
    库来分析函数执行所需的时间。在这里，我们选择了 10 秒的时间窗口，并查看函数执行了多少次。实质上：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Assessing speed: how fast are the different formats?'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估速度：不同格式的速度有多快？
- en: Delving straight into the heart of the analysis, let’s look at the graphs created
    for evaluating serialization/deserialization speed. Note that we scale the time
    it took, so you can see on the graph below that csv with numbers only is the slowest
    process while using HDF5 for numbers only is the fastest, taking 1.09% (roughly
    1/100) of the CSV one.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 直接进入分析核心，让我们看看用于评估序列化/反序列化速度的图表。请注意，我们对所花费的时间进行了缩放，因此您可以在下面的图表中看到，仅包含数字的 CSV
    处理过程最慢，而仅包含数字的 HDF5 处理过程最快，占 CSV 处理时间的 1.09%（大约 1/100）。
- en: '![](../Images/ed0e1e8f503ab2d8f7b6f0519129c569.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed0e1e8f503ab2d8f7b6f0519129c569.png)'
- en: 'Image by author: save time by format'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：按格式保存时间
- en: '![](../Images/2b3adaa9a103d3e9b1ef621fd44f7c0c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b3adaa9a103d3e9b1ef621fd44f7c0c.png)'
- en: 'Image by author: load time by format'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：按格式加载时间
- en: 'On the graphs above, we can observe a few interesting take aways in terms of
    speed:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述图表中，我们可以观察到几个有趣的速度要点：
- en: '**Pickle/HDF5** are the fastest to save number-only data'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pickle/HDF5** 是保存纯数字数据的最快格式。'
- en: '**Feather** is the fastest format to load the data.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Feather** 是加载数据的最快格式。'
- en: Human readable formats such as **JSON** or **CSV** are much slower than other
    formats, especially for saving/loading data that only contains numbers (almost
    100x slower than pickle for instance)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类可读格式如 **JSON** 或 **CSV** 比其他格式要慢得多，特别是在保存/加载仅包含数字的数据时（例如，比 pickle 慢近 100 倍）。
- en: '**HDF5** is interestingly very performant for saving data (on par with feather,
    parquet, pickle) but a bit less for loading data.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HDF5** 在保存数据方面表现得非常高效（与 feather、parquet、pickle 持平），但在加载数据时稍逊一些。'
- en: 'Memory usage: which format consumes less space?'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内存使用情况：哪个格式消耗的空间更少？
- en: '![](../Images/b89a6c6f1c4b4c46cdfe2e26b5786987.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b89a6c6f1c4b4c46cdfe2e26b5786987.png)'
- en: 'Image by author: scaled memory usage'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：缩放内存使用情况
- en: 'We can observe that:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到：
- en: once again, human-readable formats such as **CSV or JSON** are the least memory
    efficient formats. And JSON performs even worse than CSV.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再次强调，人类可读格式如 **CSV 或 JSON** 是内存效率最低的格式。而 JSON 的表现甚至比 CSV 更差。
- en: '**parquet** is the most memory efficient format with the given size of the
    data (10,000x100), which makes sense given parquet is a column-oriented data format.
    You can read more about it [here](https://www.databricks.com/glossary/what-is-parquet).'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**parquet** 是在给定数据大小（10,000x100）下内存效率最高的格式，这也符合 parquet 是列式数据格式的特点。你可以在[这里](https://www.databricks.com/glossary/what-is-parquet)了解更多信息。'
- en: once again, when dealing solely with numerical data, **pickle** is the most
    efficient format. [Pickle](https://docs.python.org/3/library/pickle.html) being
    the native Python package for serialization, it is not surprising.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再次强调，当仅处理数值数据时，**pickle** 是最有效的格式。[Pickle](https://docs.python.org/3/library/pickle.html)
    作为 Python 的原生序列化包，这一点并不令人惊讶。
- en: while faster, **feather** data takes a lot more memory compared to parquet.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管速度更快，**feather** 数据相比 parquet 占用的内存要多得多。
- en: 'The findings can be summarized on the following table (with a bit less nuance
    than the analysis above):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以在下表中总结（相较于上面的分析略显简单）：
- en: Gist by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 作者的概要
- en: Conclusions
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: The right format always boils down to your project’s unique demands. But we
    can still draw general conclusions from the above analysis. For example, unless
    interoperability is key and you need to visually see what the raw data looks like,
    you’re better off not using human-readable formats such as **CSV or JSON**.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的格式始终取决于你项目的独特需求。但我们仍然可以从上述分析中得出一些一般性的结论。例如，除非互操作性至关重要，并且你需要直观地查看原始数据的样子，否则你最好不要使用诸如
    **CSV 或 JSON** 的人类可读格式。
- en: Overall, **parquet** seems to be a very solid choice as it is much better on
    the memory usage side of things while still being relatively fast.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，**parquet** 似乎是一个非常可靠的选择，因为它在内存使用方面表现更佳，同时速度仍然相对较快。
- en: It is also pivotal to understand the specificities of each format. For example,
    pickle is Python specific so you won’t be able to read it from other languages.
    But for Python-centric projects, focused solely on numerical data handling, **pickle**
    seems to be the best choice (both in terms of speed and memory).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 了解每种格式的具体特点也是至关重要的。例如，pickle 是 Python 特有的格式，因此你无法从其他语言读取它。但是对于专注于数值数据处理的 Python
    项目来说，**pickle** 似乎是最佳选择（无论是在速度还是内存方面）。
- en: If you’re managing a lot of data and want to minimize the amount of GB you’re
    writing to disk, **parquet** is the way to go. But if speed is your primary focus,
    you might want to give **feather** a try but it will take more memory.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在处理大量数据并希望最小化写入磁盘的 GB 数量，**parquet** 是不错的选择。但如果速度是你的主要关注点，你可能要尝试 **feather**，但它会占用更多内存。
- en: Long story short, only the specific requirements of your project will guide
    you towards the right format. But you can hopefully gain some insights from the
    above to get a grasp on which one is better in your specific case. Happy coding!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 总而言之，只有你的项目具体需求才能指导你选择合适的格式。但你可以从上述内容中获得一些见解，以便了解哪种格式在你的特定情况下更好。祝编程愉快！
