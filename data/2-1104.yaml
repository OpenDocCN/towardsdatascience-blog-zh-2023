- en: How to Auto-Generate a Summary from Long Youtube Videos Using AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用AI自动生成长时间YouTube视频的摘要
- en: 原文：[https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d](https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d](https://towardsdatascience.com/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)
- en: A step-by-step guide to resume a talk by Stephen Wolfram using Whisper and BART
    models on your local PC
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Whisper和BART模型在本地PC上总结斯蒂芬·沃尔夫勒姆的演讲的逐步指南
- en: '[](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    ·7 min read·Apr 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----a2a542b6698d--------------------------------)
    ·7分钟阅读·2023年4月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/73936710bcb5eeef18ac5b7cbe3fa600.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73936710bcb5eeef18ac5b7cbe3fa600.png)'
- en: Image generated by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者生成的图像
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: 'In today’s rapidly changing world, staying informed and inspired can be challenging,
    especially when time is short. Personally, I am a huge fan of YouTube podcasts
    and talks. The podcasts and the talks are goldmines of knowledge, fully packed
    with insights from the brightest minds across various fields. However, due to
    time constraints, it’s not possible for me to watch every interesting video since
    they typically exceed one hour in length. This led me to wonder: what if I could
    create an end-to-end solution to extract automatically the main highlights? As
    a result, I started exploring AI-generative solutions to help me get auto summaries
    of some of the podcasts/talks I missed.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今快速变化的世界中，保持信息更新和获得灵感可能是一项挑战，尤其是当时间紧迫时。就个人而言，我非常喜欢YouTube上的播客和演讲。这些播客和演讲是知识的宝藏，充满了来自各个领域顶尖人才的见解。然而，由于时间限制，我无法观看每一个有趣的视频，因为它们通常超过一小时。这让我开始思考：如果我能创建一个端到端的解决方案来自动提取主要亮点呢？因此，我开始探索AI生成解决方案，帮助我获取一些错过的播客/演讲的自动摘要。
- en: In this article, I discuss the end-to-end solution on a local PC. First, I will
    cover the transcription process of one of [Stephen Wolfram's talks about ChatGPT,
    AI, and AGI](https://www.youtube.com/watch?v=szxiPMyuMGY) available on Youtube*,*
    using the open-source [Whisper Model](https://huggingface.co/openai/whisper-medium)
    available on [HuggingFace Hub](https://huggingface.co/). Then, I will demonstrate
    how to summarize long text using the open-source [BART](https://arxiv.org/abs/1910.13461)
    model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我讨论了在本地PC上进行端到端解决方案。首先，我将介绍如何使用开源的[Whisper模型](https://huggingface.co/openai/whisper-medium)，对[斯蒂芬·沃尔夫勒姆关于ChatGPT、AI和AGI的演讲](https://www.youtube.com/watch?v=szxiPMyuMGY)进行转录，该演讲在YouTube上可用。接着，我将演示如何使用开源的[BART](https://arxiv.org/abs/1910.13461)模型总结长文本。
- en: Let’s see how to achieve this.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何实现这个目标。
- en: Keep in mind, it is crucial to verify that the copyright/licence permits downloading
    the content before you proceed with the download.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请记住，确保在下载内容之前核实版权/许可是否允许下载是至关重要的。
- en: A bit of context
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一点背景
- en: '[**Whisper**](https://cdn.openai.com/papers/whisper.pdf)is an open-source automatic
    speech recognition model, trained on 680,000 hours of multilingual data gathered
    from the internet. It relies on an end-to-end encoder-decoder [Transformer](https://arxiv.org/abs/1706.03762)
    architecture.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**Whisper**](https://cdn.openai.com/papers/whisper.pdf)是一个开源自动语音识别模型，基于从互联网收集的680,000小时多语言数据进行训练。它依赖于端到端的编码器-解码器[Transformer](https://arxiv.org/abs/1706.03762)架构。'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**BART**](https://arxiv.org/abs/1910.13461) is a transformer-based seq2seq
    model that combines a bidirectional (BERT-style) encoder with an autoregressive
    (GPT-style) decoder. It’s pre-trained by randomly adding noise and learning to
    rebuild the original content.It performs well on tacks such as summmarization
    and translation.'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**BART**](https://arxiv.org/abs/1910.13461) 是一个基于 Transformer 的 seq2seq 模型，结合了双向（BERT
    风格）编码器和自回归（GPT 风格）解码器。它通过随机添加噪声并学习重建原始内容进行预训练，在总结和翻译等任务上表现良好。'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**HuggingFace transformers**](https://huggingface.co/docs/transformers/index)
    library provides a user-friendly solution to use and customize models. Additionally,
    it comes with APIs you can use to fine-tune the models to better fit your data.'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**HuggingFace transformers**](https://huggingface.co/docs/transformers/index)
    库提供了一个用户友好的解决方案来使用和自定义模型。此外，它还提供了可以用于微调模型以更好地适应数据的 API。'
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**PyTube**](https://github.com/pytube/pytube) is a depenency-free Python library
    for downloading and streaming YouTube videos.'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**PyTube**](https://github.com/pytube/pytube) 是一个无需依赖的 Python 库，用于下载和流式传输
    YouTube 视频。'
- en: ''
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[**NLTK**](https://www.nltk.org/)is a Natural Language Toolkit standard Python
    library widely used for natural language processing(NLP) tasks.'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**NLTK**](https://www.nltk.org/)是一个标准的自然语言处理（NLP）任务的 Python 库。'
- en: The end-to-end process
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 端到端过程
- en: 'The process contains four main steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 过程包含四个主要步骤：
- en: 1\. Set up the environment
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1\. 设置环境
- en: ''
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '2\. Download the YouTube video : PyTube'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2\. 下载 YouTube 视频：PyTube
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '3\. Transcribe the audio: Whisper'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 3\. 转录音频：Whisper
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '4\. Summarize the generated text: BART'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 4\. 总结生成的文本：BART
- en: '![](../Images/89c729e6ad301d77e5fd22684596eeaa.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89c729e6ad301d77e5fd22684596eeaa.png)'
- en: image by the author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 1\. Set up the environment
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 设置环境
- en: 'My environment setup looks as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我的环境设置如下：
- en: '**Jupyter Notebook** running in a virtual environment with Python 3.10'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jupyter Notebook** 在一个使用 Python 3.10 的虚拟环境中运行'
- en: '**Models***:* [OpenAI Whisper](https://github.com/openai/whisper), [BART](https://huggingface.co/facebook/bart-large-cnn)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**： [OpenAI Whisper](https://github.com/openai/whisper), [BART](https://huggingface.co/facebook/bart-large-cnn)'
- en: '**Libraries**: [pytube](https://pypi.org/project/pytube/), [transformers](https://huggingface.co/docs/transformers/index),
    [unstructured](https://pypi.org/project/unstructured/), ffmpeg-python'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**库**： [pytube](https://pypi.org/project/pytube/), [transformers](https://huggingface.co/docs/transformers/index),
    [unstructured](https://pypi.org/project/unstructured/), ffmpeg-python'
- en: 1.1 Install the libraries
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 安装库
- en: 'Several remarks:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一些备注：
- en: '**👉** ️Please be aware that you need `!` only if you install the libraries
    from a notebook cell.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**👉** 请注意，只有在从笔记本单元格安装库时才需要 `!`。'
- en: '**👉** Install the latest update of the Whisper model directly from GitHub.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**👉** 直接从 GitHub 安装 Whisper 模型的最新更新。'
- en: '**👉 Troubleshoot PyTube.** In case you run into the following error `"pytube:
    AttributeError: ‘NoneType’ object has no attribute ‘span’ cipher.p"` y go to `{home}/.local/lib/{your_pythonversion:
    ex. python3.10}/site-packages/pytube/cipher.py Line 411` and replace the value
    of the`transform_plan_raw` variable as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**👉 解决 PyTube 问题。** 如果遇到以下错误 `"pytube: AttributeError: ‘NoneType’ object has
    no attribute ‘span’ cipher.p"`，请前往 `{home}/.local/lib/{your_pythonversion: ex.
    python3.10}/site-packages/pytube/cipher.py Line 411` 并将 `transform_plan_raw` 变量的值替换如下：'
- en: 1.2 Import the libraries
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 导入库
- en: 1\. Download the YouTube video
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 下载 YouTube 视频
- en: Let’s get the summary of the following talk “[*ChatGPT, AI, and AGI with Stephen
    Wolfram*](https://www.youtube.com/watch?v=szxiPMyuMGY) *(*Founder & CEO of Wolfram
    Research*)*” *available* on YouTube ([Creative Commons Attribution license (reuse
    allowed)](https://www.youtube.com/t/creative_commons)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们获取以下演讲的总结“[*ChatGPT, AI, and AGI with Stephen Wolfram*](https://www.youtube.com/watch?v=szxiPMyuMGY)
    *(Wolfram Research 创始人兼首席执行官)*” *在* YouTube 上可用 ([创作共享许可（允许重用）](https://www.youtube.com/t/creative_commons))。
- en: To download locally the video as an audio file we use the YouTube class of the
    PyTube library. Make sure to provide a valid URL.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要将视频本地下载为音频文件，我们使用 PyTube 库的 YouTube 类。确保提供有效的 URL。
- en: 2\. Transcribe the audio
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 转录音频
- en: Once we have downloaded the audio locally, we should see a file called `demo.mp3`.
    To transcribe the audio, we load the `medium Whisper multilingual model`, which
    has 769 million parameters and is available in either English or a multilingual
    format. You can review the list of [language models available](https://github.com/openai/whisper#available-models-and-languages)
    and choose the more convenient one for your setup. For more accuracy, you can
    use `the large Whisper multilingual model`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将音频下载到本地，我们应该会看到一个名为 `demo.mp3` 的文件。要转录音频，我们加载 `medium Whisper multilingual
    model`，它具有 7.69 亿个参数，并提供英语或多语言格式。您可以查看[可用语言模型列表](https://github.com/openai/whisper#available-models-and-languages)，选择最适合您设置的模型。为了更高的准确性，您可以使用
    `large Whisper multilingual model`。
- en: The resulting concatenated string will be stored in the `result[‘text’]` variable,
    which is saved locally in `demo.txt` file.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 合并后的字符串将存储在 `result[‘text’]` 变量中，并保存在本地的 `demo.txt` 文件中。
- en: ❗️ It’s important to note that the transcription process may take over an hour,
    depending on your PC’s configuration. To test the demo, you may choose a shorter
    video.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ❗️ 需要注意的是，转录过程可能需要超过一个小时，具体取决于您的电脑配置。要测试演示，您可以选择一个较短的视频。
- en: 3\. Summarize the generated text
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 总结生成的文本
- en: Because of the model’s incapacity to handle multiple tokens at once, it’s important
    to split the text into smaller segments, each containing a maximum of 4000 tokens.
    To do this, we can use the `punkt` pre-trained sentence tokenizer model, which
    is part of the Natural Language Toolkit (NLTK) library and is effective in processing
    natural language. Once we’ve divided the text into smaller sentence chunks, we
    can store them in the `text_chunks` variable for further use.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型无法一次处理多个标记，因此重要的是将文本分割成较小的段落，每个段落最多包含 4000 个标记。为此，我们可以使用 `punkt` 预训练句子分割模型，它是自然语言工具包（NLTK）库的一部分，能够有效处理自然语言。一旦我们将文本分割成较小的句子块，就可以将它们存储在
    `text_chunks` 变量中以供进一步使用。
- en: We use sentence tokenization to prevent any loss of information
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用句子分割以防止信息丢失
- en: 3.1 Divide the large text into chunks
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 将大文本分割成块
- en: Here’s the code that can be used to do the work.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是可以用来完成工作的代码。
- en: 'The code consists of two functions: `read_file()` that reads the `demo.txt`
    file and `split_text_into_chunks()` that splits the text into chunks.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 代码包括两个函数：`read_file()` 用于读取 `demo.txt` 文件，`split_text_into_chunks()` 用于将文本分割成块。
- en: 3.2 Text Summarization with BART
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 使用 BART 进行文本摘要
- en: To summarize the text we use the `HuggingFace Transformers`library and the pre-trained
    multilingual BART-large model, `[facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)`
    fine-tuned on the CNN Daily Mail dataset. The Transformers library by Hugging
    Face offers many ready-to-use models for various tasks like text, images, or sounds.
    For instance, it provides an easy-to-use text summarization pipeline for the BART
    model:`pipeline("summarization", model="facebook/bart-large-cnn").` This makes
    it easy and user-friendly.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结文本，我们使用 `HuggingFace Transformers` 库和预训练的多语言 BART-large 模型，`[facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)`，该模型在
    CNN Daily Mail 数据集上进行了微调。Hugging Face 的 Transformers 库提供了许多用于文本、图像或声音等各种任务的现成模型。例如，它提供了一个易于使用的
    BART 模型文本摘要管道：`pipeline("summarization", model="facebook/bart-large-cnn")`。这使得使用起来简单而友好。
- en: The code for performing the summarization is provided below.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是执行摘要生成的代码。
- en: Overall, the code creates an instance of the BART summarizer, generates a summary
    for the given text chunks, and saves it to`summary_demo.txt` file only if the
    summary is successfully generated. If the summary has more than 5000 characters
    we will proceed by applying once gain the Bart summarizer. The output is saved
    in the `short_summary_demo.txt` file.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，代码创建了 BART 摘要生成器的一个实例，为给定的文本块生成摘要，并仅在成功生成摘要时将其保存到 `summary_demo.txt` 文件中。如果摘要超过
    5000 个字符，我们将再次使用 BART 摘要生成器。输出将保存在 `short_summary_demo.txt` 文件中。
- en: '**Here is the summary:**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是总结：**'
- en: The Wolfram language could be the basis for a more systematic exploration of
    the nature and the depths of large language models. It’s a precise computational
    language, but it talks about the real world. There’s not a lot of boilerplate
    in LLM. Chat GPT is showing us, I think, an important piece of science. We’ve
    automated out the boilerplate. My guess is that increasingly as people use it
    for real, they’ll just edit the code. And it will have done a large part of the
    work in making the initial five lines of code. There are more regularities to
    describe meaning. It’s really a question of where the boundaries are between what
    the LLM can produce, what we can catch with our natural language understanding
    system. We’ve had billions of years to evolve, to deal with the way that nature
    is. Microsoft Research published a 154-page analysis of GPT-4 where they conclude,
    and it is in the title of their paper, they are seeing glimpses of AGI. The computational
    universe of possible things you can do is very big. We humans care about only
    a small fraction of that. The question is to connect those things that are out
    in the computational universe with things that we humans are interested in. In
    1900, people would not have been surprised to think that space would be discrete.
    One of the things that I’m sort of hoping for in the not too distant future is
    we’ll actually find a phenomenon that is kind of like the Brownian motion of space
    and where we’ll be able to see, we can tell that it’s discrete.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Wolfram 语言可能成为更系统探索大型语言模型本质和深度的基础。这是一种精确的计算语言，但它谈论的是现实世界。LLM 中没有太多的模板代码。我认为
    Chat GPT 向我们展示了一个重要的科学片段。我们已经自动化了模板代码。我的猜测是，随着人们越来越多地实际使用它，他们只会编辑代码。而它将完成大量的初始五行代码的工作。描述意义的规律性更多了。这实际上是一个问题，即
    LLM 可以生成的内容与我们自然语言理解系统可以捕捉的内容之间的界限在哪里。我们已经有数十亿年的进化时间来处理自然的方式。微软研究院发布了一份关于 GPT-4
    的154页分析报告，在报告中他们得出结论，并且这是他们论文标题中的内容，他们看到了 AGI 的一瞥。你可以做的计算宇宙的可能性是非常大的。我们人类只关心其中的一小部分。问题在于将计算宇宙中的事物与我们人类感兴趣的事物连接起来。在1900年，人们不会感到惊讶地认为空间是离散的。我希望在不久的将来，我们实际上能找到一种类似于空间布朗运动的现象，我们将能够看到，我们可以确定它是离散的。
- en: Key takeaways
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要收获
- en: The tutorial is part of a personal side project focused on exploring generative
    AI tools.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该教程是一个个人副项目的一部分，专注于探索生成性 AI 工具。
- en: To conclude, the Whisper model gave excellent results on all tested videos.
    Although it occasionally misidentified product or person names, I am quite happy
    with the outcome and will definitely keep using it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，Whisper 模型在所有测试的视频中都表现出色。尽管它偶尔会误识别产品或人物名称，但我对结果相当满意，并且会继续使用它。
- en: On the other hand, the BART model offers a trustworthy open-source option for
    summarization. Its summaries are quite effective. I compared it to the [T5 model
    from Google Research](https://huggingface.co/docs/transformers/model_doc/t5) and
    BART’s summaries were superior. Indeed, it may not always capture all the key
    facts, but it delivers good results, so I’ll continue using it for my personal
    summary tasks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，BART 模型提供了一个值得信赖的开源摘要选项。它的摘要效果相当好。我将它与 [谷歌研究的 T5 模型](https://huggingface.co/docs/transformers/model_doc/t5)
    进行了比较，BART 的摘要更优。的确，它可能并不总是捕捉到所有关键事实，但它的结果很好，所以我会继续使用它来处理我的个人总结任务。
- en: Overall AI-generative solutions like Whisper and BART help me efficiently extract
    important insights from long podcasts and talks. This way I can stay informed
    even when I am running out of spare time.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，像 Whisper 和 BART 这样的 AI 生成解决方案帮助我高效提取长时间播客和演讲中的重要见解。这样，即使在我没有剩余时间的时候，我也能保持信息更新。
- en: I hope that you enjoyed the article.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你喜欢这篇文章。
- en: Thank you for reading!
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: Don’t forget to [subscribe](https://medium.com/subscribe/@anna.bildea) if you
    want to get my future stories in your inbox.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想将来在收件箱中收到我的故事，不要忘记 [订阅](https://medium.com/subscribe/@anna.bildea)。
- en: '*If you enjoy reading my story and want to support me as a writer, consider
    signing up to become a Medium member and gain access to thousands of Data Engineering
    and Data Science articles.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢阅读我的故事并希望支持我作为作家，可以考虑注册成为 Medium 会员，访问数千篇数据工程和数据科学文章。*'
- en: '[](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
    [## Join Medium with my referral link — Bildea Ana'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
    [## 使用我的推荐链接加入 Medium — Bildea Ana'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为Medium会员，您会员费的一部分将分配给您阅读的作者，您将获得对每篇故事的完整访问权限…
- en: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----a2a542b6698d--------------------------------)
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/)
    *and* [Twitter](https://twitter.com/AnaBildea)!'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/) *和*
    [Twitter](https://twitter.com/AnaBildea) *上找到我*!'
- en: See my collection of Generative AI, MLOps, and Responsible AI articles
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 查看我关于生成性AI、MLOps和负责任AI的文章合集
- en: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![Ana Bildea博士](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea博士](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: Generative AI
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成性AI
- en: '[View list](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----a2a542b6698d--------------------------------)11
    stories![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----a2a542b6698d--------------------------------)11个故事![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea博士](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea博士](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: Responsible AI
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的AI
- en: '[View list](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----a2a542b6698d--------------------------------)1
    story![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----a2a542b6698d--------------------------------)1个故事![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)![Ana
    Bildea博士](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea博士](https://medium.com/@anna.bildea?source=post_page-----a2a542b6698d--------------------------------)'
- en: MLOps - AI in Production
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps - AI在生产中的应用
- en: '[View list](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----a2a542b6698d--------------------------------)4
    stories![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----a2a542b6698d--------------------------------)4个故事![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)'
