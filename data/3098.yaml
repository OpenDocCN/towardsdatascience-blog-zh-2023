- en: Neural Basis Models for Interpretability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经基础模型的可解释性
- en: 原文：[https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2?source=collection_archive---------8-----------------------#2023-10-11](https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2?source=collection_archive---------8-----------------------#2023-10-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2?source=collection_archive---------8-----------------------#2023-10-11](https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2?source=collection_archive---------8-----------------------#2023-10-11)
- en: Unpacking the new interpretable model proposed by Meta AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解读Meta AI提出的新型可解释模型
- en: '[](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[![Nakul
    Upadhya](../Images/336cb21272e9b1f098177adbde50e92e.png)](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    [Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[![Nakul
    Upadhya](../Images/336cb21272e9b1f098177adbde50e92e.png)](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    [Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d9dddc62a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-basis-models-for-interpretability-fd04ac958ff2&user=Nakul+Upadhya&userId=4d9dddc62a80&source=post_page-4d9dddc62a80----fd04ac958ff2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    ·6 min read·Oct 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffd04ac958ff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-basis-models-for-interpretability-fd04ac958ff2&user=Nakul+Upadhya&userId=4d9dddc62a80&source=-----fd04ac958ff2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d9dddc62a80&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-basis-models-for-interpretability-fd04ac958ff2&user=Nakul+Upadhya&userId=4d9dddc62a80&source=post_page-4d9dddc62a80----fd04ac958ff2---------------------post_header-----------)
    发表在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    · 6 min read · 2023年10月11日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffd04ac958ff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-basis-models-for-interpretability-fd04ac958ff2&user=Nakul+Upadhya&userId=4d9dddc62a80&source=-----fd04ac958ff2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd04ac958ff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-basis-models-for-interpretability-fd04ac958ff2&source=-----fd04ac958ff2---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffd04ac958ff2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-basis-models-for-interpretability-fd04ac958ff2&source=-----fd04ac958ff2---------------------bookmark_footer-----------)'
- en: The widespread application of Machine Learning and Artificial Intelligence across
    various domains brings about heightened challenges regarding risks and ethical
    assessments. As seen in case studies like the [criminal recidivism model reported
    on by ProPublica,](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
    machine learning algorithms can be incredibly biased and, as a result, robust
    explainability mechanisms are needed to ensure trust and safety when these models
    are deployed in high-stakes areas.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和人工智能在各个领域的广泛应用带来了更高的风险和伦理评估挑战。如在[ProPublica报道的犯罪再犯模型](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)案例中所见，机器学习算法可能存在极大的偏见，因此需要强有力的解释机制，以确保在这些模型被应用于高风险领域时的信任和安全。
- en: So, how do we balance interpretability with accuracy and model expressivity?
    Well, Meta AI researchers have proposed a new approach they dubbed [Neural Basis
    Models (NBMs)[1]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/37da88965c016dca016514df0e420c72-Abstract-Conference.html),
    a sub-family of generalized additive models that achieve state-of-the-art (SOTA)
    performance on benchmark datasets while retaining glass-box interpretability.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何在可解释性与准确性和模型表达能力之间取得平衡呢？好吧，Meta AI 研究人员提出了一种新方法，他们称之为[神经基础模型 (NBMs)[1]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/37da88965c016dca016514df0e420c72-Abstract-Conference.html)，这是广义加性模型的一个子系列，在基准数据集上实现了最先进的
    (SOTA) 性能，同时保留了玻璃箱的可解释性。
- en: In this article, I aim to explain the NBM and what makes it a beneficial model.
    As usual, I encourage everyone to read the original paper.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我旨在解释 NBM 及其成为有益模型的原因。像往常一样，我鼓励大家阅读原始论文。
- en: If you’re interested in interpretable machine learning and other aspects of
    ethical AI, consider checking out some of my other articles and following me!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对可解释的机器学习和其他伦理 AI 方面感兴趣，可以查看我的其他文章并关注我！
- en: '![Nakul Upadhya](../Images/e62aa67aa11cd0f9bcd1132257fc3773.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![纳库尔·乌帕德亚](../Images/e62aa67aa11cd0f9bcd1132257fc3773.png)'
- en: '[Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[纳库尔·乌帕德亚](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
- en: Interpretable and Ethical AI
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可解释和伦理 AI
- en: '[View list](https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d?source=post_page-----fd04ac958ff2--------------------------------)5
    stories![](../Images/3718151c0f72303f3d1c71f54229bc98.png)![](../Images/eddb4279ebae7fc1ba79cf6dcc6ebd5a.png)![](../Images/7def8e23dad656929857f2a488b1f547.png)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d?source=post_page-----fd04ac958ff2--------------------------------)5个故事![](../Images/3718151c0f72303f3d1c71f54229bc98.png)![](../Images/eddb4279ebae7fc1ba79cf6dcc6ebd5a.png)![](../Images/7def8e23dad656929857f2a488b1f547.png)'
- en: 'Background: GAMs'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景：GAMs
