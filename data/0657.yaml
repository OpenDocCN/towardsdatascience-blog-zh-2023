- en: 'Step by Step Basics: Text Classifier'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤基础：文本分类器
- en: 原文：[https://towardsdatascience.com/step-by-step-basics-text-classifier-e666c6bac52b?source=collection_archive---------2-----------------------#2023-02-17](https://towardsdatascience.com/step-by-step-basics-text-classifier-e666c6bac52b?source=collection_archive---------2-----------------------#2023-02-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/step-by-step-basics-text-classifier-e666c6bac52b?source=collection_archive---------2-----------------------#2023-02-17](https://towardsdatascience.com/step-by-step-basics-text-classifier-e666c6bac52b?source=collection_archive---------2-----------------------#2023-02-17)
- en: An Instructional Guide and Flow Diagram for Building a Supervised Machine Learning
    Text Classifier in Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个监督学习文本分类器的指导手册和流程图（Python）
- en: '[](https://medium.com/@lucydickinson?source=post_page-----e666c6bac52b--------------------------------)[![Lucy
    Dickinson](../Images/5a075bb38f9133678d55a26b2683729f.png)](https://medium.com/@lucydickinson?source=post_page-----e666c6bac52b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e666c6bac52b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e666c6bac52b--------------------------------)
    [Lucy Dickinson](https://medium.com/@lucydickinson?source=post_page-----e666c6bac52b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@lucydickinson?source=post_page-----e666c6bac52b--------------------------------)[![Lucy
    Dickinson](../Images/5a075bb38f9133678d55a26b2683729f.png)](https://medium.com/@lucydickinson?source=post_page-----e666c6bac52b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e666c6bac52b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e666c6bac52b--------------------------------)
    [Lucy Dickinson](https://medium.com/@lucydickinson?source=post_page-----e666c6bac52b--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243c7ff13cc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-basics-text-classifier-e666c6bac52b&user=Lucy+Dickinson&userId=243c7ff13cc2&source=post_page-243c7ff13cc2----e666c6bac52b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e666c6bac52b--------------------------------)
    ·10 min read·Feb 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe666c6bac52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-basics-text-classifier-e666c6bac52b&user=Lucy+Dickinson&userId=243c7ff13cc2&source=-----e666c6bac52b---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243c7ff13cc2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-basics-text-classifier-e666c6bac52b&user=Lucy+Dickinson&userId=243c7ff13cc2&source=post_page-243c7ff13cc2----e666c6bac52b---------------------post_header-----------)
    发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e666c6bac52b--------------------------------)
    ·10 分钟阅读·2023年2月17日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe666c6bac52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-basics-text-classifier-e666c6bac52b&user=Lucy+Dickinson&userId=243c7ff13cc2&source=-----e666c6bac52b---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe666c6bac52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-basics-text-classifier-e666c6bac52b&source=-----e666c6bac52b---------------------bookmark_footer-----------)![](../Images/7616f5c71c4500433b491ed8fdd0db92.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe666c6bac52b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fstep-by-step-basics-text-classifier-e666c6bac52b&source=-----e666c6bac52b---------------------bookmark_footer-----------)![](../Images/7616f5c71c4500433b491ed8fdd0db92.png)'
- en: Photo by [Patrick Tomasso](https://unsplash.com/@impatrickt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Patrick Tomasso](https://unsplash.com/@impatrickt?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Let’s cut to the chase. There are a lot of steps involved in building a **text
    classifier** and understanding the world of **Natural Language Processing (NLP)**.
    These steps have to be implemented in a specific order. There are even more steps
    required if the target class in the data is imbalanced. Learning this all from
    scratch can be a bit of a minefield. There are plenty of learning resources online,
    yet finding a holistic guide that covers everything in a high level proved tricky.
    So, I am writing this article to hopefully provide some transparency on this process
    with a 10 easy step guide.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 说到重点，构建**文本分类器**和理解**自然语言处理 (NLP)** 的世界涉及很多步骤。这些步骤必须按特定顺序实施。如果数据中的目标类不平衡，还需要更多步骤。从头学习这一切可能有些困难。尽管网上有许多学习资源，但找到一个全面的高水平指南却不易。因此，我写这篇文章，希望能通过一个10步简单指南来提供一些过程透明度。
- en: I’m going to start with providing a flow diagram that I’ve compiled with all
    the necessary steps and key points to understand, all the way from clarifying
    the task to deploying a trained text classifier.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从提供一个我整理的流程图开始，其中包含了从明确任务到部署训练好的文本分类器的所有必要步骤和关键点。
- en: First of all, what is a text classifier?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，什么是文本分类器？
- en: A text classifier is an algorithm that learns the presence or pattern of words
    to predict some kind of target or outcome, usually a category such as whether
    an email is spam or not.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 文本分类器是一种算法，它通过学习单词的出现或模式来预测某种目标或结果，通常是一个类别，比如判断一封邮件是否是垃圾邮件。
- en: It is important to mention here that I will be focussing on building a text
    classifier using Supervised Machine Learning methods. An alternative approach
    is to use Deep Learning methods such as Neural Networks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里需要提到的是，我将专注于使用监督学习方法来构建文本分类器。另一种方法是使用深度学习方法，如神经网络。
- en: Let’s take a peek at that flow diagram.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看那个流程图。
- en: '![](../Images/cf105d0f0e197d6701c455062b55f7d4.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf105d0f0e197d6701c455062b55f7d4.png)'
- en: Diagram by author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图表
- en: There’s a lot to digest there. Let’s break it up into bitesize chunks and walk
    through each section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 信息量很大。让我们将其分解成小块，逐步讲解每个部分。
- en: 1\. Clarify the task
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 明确任务
- en: This is one of the most important steps of any data science project. Ensure
    that you have fully grasped the question that is being asked. Do you have the
    relevant data available to answer the question? Does your methodology align with
    what the stakeholder is expecting? If you need stakeholder buy in, don’t go building
    some super complex model that will be hard to interpret. Start simple, bring everyone
    along on that journey with you.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这是任何数据科学项目中最重要的步骤之一。确保你完全理解所提出的问题。你是否有相关数据来回答这个问题？你的方法是否与利益相关者的期望一致？如果需要利益相关者的认可，不要去构建一个复杂难懂的模型。从简单的开始，让所有人都参与到这个过程中来。
- en: 2\. Data quality checks
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 数据质量检查
- en: Another essential step to any project. Your model will only be as good as the
    data that goes in, so make sure duplicates are removed and missing values are
    dealt with accordingly.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 任何项目中的另一个关键步骤。你的模型的好坏取决于输入的数据，因此确保删除重复数据并妥善处理缺失值。
- en: 3\. Exploratory Data Analysis (EDA)
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 探索性数据分析 (EDA)
- en: Now we can move onto some text data specific analysis. EDA is all about understanding
    the data and getting a feel for what you can derive from it. One of the key points
    for this step is to understand the **target class distribution**. You can use
    either the pandas .value_counts() method or plot a bar chart to visualise the
    distribution of each class within the dataset. You’ll be able to see which are
    the **majority** and **minority classes.**
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进入一些文本数据特定的分析。EDA（探索性数据分析）主要是理解数据，感受从中可以得出的信息。这个步骤的一个关键点是理解**目标类分布**。你可以使用
    pandas 的 .value_counts() 方法或绘制条形图来可视化数据集中每个类的分布。你将能够看到哪些是**主要类**和**次要类**。
- en: '![](../Images/1a7238087383fb8dd9dd6e49f45175eb.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a7238087383fb8dd9dd6e49f45175eb.png)'
- en: Imbalanced class distribution of a binary labelled dataset
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类标记数据集的不平衡类分布
- en: Models do not perform well with imbalanced data. The model will often ignore
    the minority class(es) as there simply is not enough data to train the model to
    detect them. Alas, it’s not the end of the world if you find yourself with an
    imbalanced dataset with a heavy skew towards one of your target classes. That’s
    in fact quite normal. It’s just important to know this ahead of your model building
    process so you can adjust for this later on.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在处理不平衡数据时表现不好。模型往往会忽略少数类别，因为数据量不足以训练模型检测这些类别。不过，如果你发现自己有一个高度倾斜的目标类别的不平衡数据集，这其实并不是世界末日。这在实际上是非常正常的。只要在模型构建过程开始之前知道这一点，以便在后续可以进行调整，就很重要。
- en: The presence of an imbalanced dataset should also get you thinking about which
    metrics you should use to assess model performance. In this instance, ‘accuracy’
    (proportion of correct predictions) really **isn’t** your friend. Let’s say you
    have a dataset with a binary target class where 80% of data is labelled ‘red’
    and 20% is labelled ‘blue’. Your model could simply predict ‘red’ for the entire
    test set and still be 80% accurate. Hence, the accuracy of a model may be misleading,
    given that your model could simply predict the majority class.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不平衡数据集的存在也应该让你思考应使用哪些指标来评估模型性能。在这种情况下，‘准确率’（正确预测的比例）真的**不是**你的朋友。假设你有一个二分类目标类的数据集，其中80%的数据标记为‘红色’，20%的数据标记为‘蓝色’。你的模型可以简单地对整个测试集预测‘红色’，并且仍然保持80%的准确率。因此，模型的准确率可能具有误导性，因为你的模型可能只会预测多数类。
- en: Some better metrics to use are **recall** (proportion of true positives predicted
    correctly), **precision** (proportion of positive predictions predicted correctly),
    or the mean of the two, the **F1 score**. Pay close attention to these scores
    for your minority classes once you’re in the model building stage. It’ll be these
    scores that you’ll want to improve.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一些更好的指标包括**召回率**（正确预测的真正例比例）、**精准率**（正确预测的正例比例）或这两者的平均值，即**F1分数**。在模型构建阶段，要特别关注这些指标，尤其是少数类的指标。你会希望提升这些得分。
- en: 4\. Text pre-processing
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 文本预处理
- en: Now on to some fun stuff! Text data can contain a whole load of stuff that just
    really isn’t useful to any machine learning model (depending on the nature of
    the task). This process is really about removing the ‘noise’ within your dataset,
    homogenising words and stripping it back to the bare bones so that only the useful
    words and ultimately, features, remain.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进入一些有趣的内容！文本数据中可能包含大量对任何机器学习模型都不实用的内容（这取决于任务的性质）。这个过程实际上是为了去除数据集中的“噪声”，使单词同质化，并将其简化到最基本的状态，以便仅保留有用的单词和最终的特征。
- en: 'Generally, you’ll want to remove punctuation, special characters, stop-words
    (words like ‘this’, ‘the’, ‘and’) and reduce each word down to its lemma or stem.
    You can play around with making your own functions to get an idea of what’s in
    your data before cleansing it. Take the function below for example:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你会希望去除标点符号、特殊字符、停用词（如‘this’，‘the’，‘and’），并将每个单词还原到其词根或词干。你可以尝试编写自己的函数，了解数据中的内容，然后进行清洗。例如，考虑下面的函数：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then when you’ve got a better idea of what needs to be removed from your data,
    have a go at writing a function that does it all for you in one go:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当你对需要从数据中去除的内容有了更好的了解后，可以尝试编写一个函数，一次性完成所有操作：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can then run the first function again on the cleansed data to check that
    the everything that you wanted to be removed has indeed been removed.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以在清洗后的数据上再次运行第一个函数，以检查所有你想要去除的内容是否确实被去除了。
- en: For those who noticed the functions above don’t remove any stop-words, well
    spotted. You can remove stop-words during the vectorisation process in a few steps
    time.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些注意到上述函数没有去除任何停用词的人，观察得很好。在向量化过程中的几步操作中，你可以去除停用词。
- en: 5\. Train-test split
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 训练-测试拆分
- en: This is getting its own sub heading because it is so important to do this step
    BEFORE your start fiddling with the features. Split your data using sklearn’s
    train_test_split() function and then **leave the test data alone** so there’s
    no risk of data leakage.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个步骤有自己的子标题，因为在开始调整特征之前执行这个步骤非常重要。使用sklearn的train_test_split()函数拆分数据，然后**保持测试数据不变**，以避免数据泄漏的风险。
- en: If your data are imbalanced, there are a few optional arguments (‘shuffle’ and
    ‘stratify’) that you can specify within the test-train split to ensure an even
    split across your target classes. This ensures that your minority classes don’t
    end up all in your training or test set exclusively.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据不平衡，有一些可选参数（‘shuffle’ 和 ‘stratify’），你可以在测试训练拆分时指定，以确保目标类别之间的均匀分配。这确保了你的少数类别不会全部集中在训练集或测试集中。
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 6\. Text vectorisation
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 文本向量化
- en: Models cannot interpret words. Instead, the words have to be converted into
    numbers using a process known as vectorisation. There are two methods for vectorisation;
    Bag of Words and Word Embeddings. Bag of Words methods look for exact matches
    of words between texts, whereas Word Embedding methods take into account word
    context, and so can look for similar words between texts. An interesting article
    comparing the two methods can be found [here](https://medium.com/swlh/word-embeddings-versus-bag-of-words-the-curious-case-of-recommender-systems-6ac1604d4424).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 模型无法解释词语。相反，词语必须通过一种称为向量化的过程转换为数字。向量化有两种方法：词袋模型和词嵌入。词袋模型寻找文本之间词语的精确匹配，而词嵌入方法考虑词语的上下文，因此可以在文本之间寻找相似的词。比较这两种方法的有趣文章可以在[这里](https://medium.com/swlh/word-embeddings-versus-bag-of-words-the-curious-case-of-recommender-systems-6ac1604d4424)找到。
- en: For the Bag of Words method, sentences are tokenised and then each unique word
    becomes a feature. Each unique word in the dataset will correspond to a feature,
    where each feature will have an integer associated depending on how many times
    that word appears in the text (a Word Count Vector — sklearn’s CountVectorizer())
    or a weighted integer that indicates the importance of the word in the text (a
    TF-IDF Vector — sklearn’s TfidVectorizer()). A useful article explaining TF-IDF
    vectorisation can be found [here](/tf-idf-simplified-aba19d5f5530#:~:text=Term%20frequency%2Dinverse%20document%20frequency,specific%20term%20in%20a%20document.).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于词袋模型，句子会被分词，每个唯一的词成为一个特征。数据集中每个唯一的词将对应一个特征，每个特征会有一个整数值，这个整数值取决于该词在文本中出现的次数（词频向量
    — sklearn 的 CountVectorizer()）或者一个加权整数，表示该词在文本中的重要性（TF-IDF 向量 — sklearn 的 TfidVectorizer()）。有关
    TF-IDF 向量化的有用文章可以在[这里](/tf-idf-simplified-aba19d5f5530#:~:text=Term%20frequency%2Dinverse%20document%20frequency,specific%20term%20in%20a%20document.)找到。
- en: Be sure to train the vectoriser object on the training data and then use this
    to transform the test data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 确保在训练数据上训练向量化对象，然后使用它来转换测试数据。
- en: 7\. Model selection
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 模型选择
- en: It’s a good idea to try out a few classification models to see which performs
    best with your data. You can then use performance metrics to select the most appropriate
    model to optimise. I did this by running a for loop which iterated over each model
    using the cross_validate() function.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试几种分类模型，看看哪一种在你的数据上表现最好。然后，你可以使用性能指标选择最合适的模型进行优化。我通过运行一个 for 循环，使用 cross_validate()
    函数对每个模型进行迭代来完成这个任务。
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 8\. Baseline model
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 基线模型
- en: Before you get carried away with tweaking your chosen model’s hyperparameters
    in a bid to get those performance metrics up, STOP. Make a note of your model’s
    performance before you start optimising it. You’ll only be able to know (and prove)
    that your model improved by comparing it to the baseline scores. It helps you
    with stakeholder buy in and storytelling if you’re in a position where you’ve
    been asked to walk through your methodology.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在你过于热衷于调整所选模型的超参数以提高性能指标之前，停下。记录下你模型的表现，然后再开始优化。只有通过与基线得分进行比较，你才能知道（并证明）你的模型是否有所改进。如果你需要向利益相关者展示你的方法，这也有助于你获得他们的认可和讲述故事。
- en: Create an empty DataFrame, then after each model iteration, append your metric(s)
    of choice along with the number or name of the iteration so you can clearly see
    how your model progressed through your optimisation attempts.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个空的 DataFrame，然后在每次模型迭代后，附加你选择的指标以及迭代的编号或名称，以便你可以清楚地看到模型在优化尝试中的进展。
- en: 9\. Model tuning — rectifying imbalanced data
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9\. 模型调整 — 纠正数据不平衡
- en: Generally, fine tuning your model might involve tweaking its hyperparameters
    and feature engineering with the aim of improving the model’s predictive capability.
    For this section however, I’m going to focus on the techniques that can be used
    to reduce the effect of class imbalance.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，微调你的模型可能涉及调整其超参数和特征工程，以提高模型的预测能力。然而，在这一部分中，我将重点关注用于减少类别不平衡影响的技术。
- en: Short of collecting more data for the minority classes, there are 5 methods
    (that I know of) that you can use to address class imbalance. The majority are
    a form of feature engineering, with the aim of either oversampling the minority
    class(es) or undersampling the majority class(es) to even out the overall class
    distribution.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 除了为少数类收集更多数据外，还有 5 种方法（我所知道的）可以用来解决类别不平衡问题。大多数方法是一种特征工程，目的是通过过采样少数类或欠采样多数类来平衡整体类别分布。
- en: 'Let’s take a quick look at each method:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来快速看一下每种方法：
- en: '**Adding a minority class penalty**'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**添加少数类惩罚**'
- en: Classification algorithms have a parameter, mostly known as ‘class_weight’ that
    you can specify when training the model. This is essentially a penalty function,
    where a higher penalty will be given if a minority class is misclassified in order
    to deter against misclassification. You can either elect for an automated argument,
    or you may be able to manually assign the penalty based on the class. Be sure
    to read the documentation for the algorithm you’re using.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 分类算法有一个参数，通常称为‘class_weight’，你可以在训练模型时指定。这本质上是一个惩罚函数，如果少数类被错误分类，将给予更高的惩罚以防止误分类。你可以选择自动参数，也可以根据类别手动分配惩罚。请务必阅读你正在使用的算法的文档。
- en: '**2.** **Oversample minority class**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.** **过采样少数类**'
- en: Random oversampling involves randomly duplicating examples from the minority
    class(es) and adding them to the training dataset to create a uniform class distribution.
    This method can lead to overfitting as no new data points are being generated,
    so be sure to check for this.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 随机过采样涉及随机复制少数类样本，并将其添加到训练数据集中以创建均匀的类分布。此方法可能导致过拟合，因为没有生成新的数据点，因此请务必检查这一点。
- en: The python library [imblearn](https://imbalanced-learn.org/stable/) contains
    functions for oversampling and undersampling data. It is important to know that
    any oversampling or undersampling techniques are only applied to the training
    data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: python 库 [imblearn](https://imbalanced-learn.org/stable/) 包含用于过采样和欠采样数据的函数。重要的是要知道，任何过采样或欠采样技术仅应用于训练数据。
- en: If you are using a cross-validation method to fit the data to a model, you will
    need to use a pipeline to ensure that only the training folds are being oversampled.
    The Pipeline() function can be imported from the imblearn library.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用交叉验证方法来将数据拟合到模型中，你需要使用管道以确保仅对训练折进行过采样。Pipeline() 函数可以从 imblearn 库中导入。
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**3\. Undersample majority class**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 欠采样多数类**'
- en: An alternative method to the above is to instead undersample the majority class,
    rather than oversample the majority class. Some might argue it’s never worth removing
    data if you have it, but this could be an option worth trying for yourself. Again,
    the imblearn library has oversampling functions to use.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述方法的另一种替代方案是对多数类进行欠采样，而不是对多数类进行过采样。有人可能会认为如果你拥有数据，就不值得删除数据，但这可能是一个值得尝试的选项。同样，imblearn
    库中也有过采样函数可以使用。
- en: '**4\. Synthesise new instances of minority class**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 合成少数类的新实例**'
- en: New instances of the minority classes can be generated using a process called
    SMOTE (Synthetic Minority Oversampling Technique), which again can be implemented
    using the imblearn library. There is a great article [here](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)
    that provides some examples of implementing SMOTE.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 少数类的新实例可以通过称为 SMOTE（合成少数过采样技术）的方法生成，该方法同样可以使用 imblearn 库来实现。这里有一篇很好的文章 [here](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)
    提供了一些实现 SMOTE 的示例。
- en: '**5\. Text augmentation**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 文本增强**'
- en: New data can be generated using synonyms of existing data to increase the number
    of data points of minority classes. Methods involve synonym replacement and back
    translation (translating into one language and back to the original language).
    The [nlpaug library](https://nlpaug.readthedocs.io/en/latest/) is a handy library
    for exploring these options.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用现有数据的同义词生成新数据，以增加少数类的数据点数量。方法包括同义词替换和回译（翻译成一种语言再翻译回原始语言）。[nlpaug library](https://nlpaug.readthedocs.io/en/latest/)
    是一个探索这些选项的方便库。
- en: Running through each of these balancing processing steps iteratively and comparing
    the scores with your baseline score will then allow you to see which method works
    best with your data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 逐步执行这些平衡处理步骤，并将得分与基准得分进行比较，将允许你查看哪种方法最适合你的数据。
- en: 10\. Deploy trained classifier
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10\. 部署训练好的分类器
- en: This is the time to push the trained classifier into a production environment
    and let it work its magic on unseen and unlabelled data, provided it has been
    tested. The method of deployment depends on the platforms that your company uses,
    [here](https://neptune.ai/blog/deploy-nlp-models-in-production) is an article
    that walks through some of the options.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是将经过训练的分类器推向生产环境的时候了，让它在未见过和未标记的数据上发挥魔力，前提是它已经经过测试。部署的方法取决于你的公司使用的平台，[这里](https://neptune.ai/blog/deploy-nlp-models-in-production)有一篇文章详细介绍了一些选项。
- en: 'There we have it! 10 easy steps to building a text classifier in python using
    a supervised machine learning approach. In summary, we learnt:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！10个简单步骤，使用监督式机器学习方法在python中构建文本分类器。总结一下，我们学习了：
- en: The sequence of steps required to build a text classifier
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建文本分类器所需的步骤顺序
- en: The significance of inspecting class distribution and understand how this could
    impact model performance metrics
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查类别分布的重要性，并理解这如何影响模型性能指标
- en: Text pre-processing steps
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本预处理步骤
- en: How to select an appropriate model and record baseline model performance
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何选择合适的模型并记录基准模型的性能
- en: Methods to resolve class imbalance
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决类别不平衡的方法
- en: I hope this has been useful. Please leave any thoughts, comments or suggestions
    :)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这对你有所帮助。请留下任何想法、评论或建议 :)
