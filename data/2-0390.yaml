- en: 'Biases in Recommender Systems: Top Challenges and Recent Breakthroughs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统中的偏差：主要挑战与最新突破
- en: 原文：[https://towardsdatascience.com/biases-in-recommender-systems-top-challenges-and-recent-breakthroughs-edcda59d30bf](https://towardsdatascience.com/biases-in-recommender-systems-top-challenges-and-recent-breakthroughs-edcda59d30bf)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/biases-in-recommender-systems-top-challenges-and-recent-breakthroughs-edcda59d30bf](https://towardsdatascience.com/biases-in-recommender-systems-top-challenges-and-recent-breakthroughs-edcda59d30bf)
- en: Behind the ongoing quest for building unbiased models from biased data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在从偏见数据中构建无偏模型的持续探索背后
- en: '[](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----edcda59d30bf--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------)
    ·7 min read·Feb 23, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----edcda59d30bf--------------------------------)
    ·阅读时间7分钟·2023年2月23日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9efdc9be3f175bee78b1c8774b8b4d96.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9efdc9be3f175bee78b1c8774b8b4d96.png)'
- en: Image generated by the author with Midjourney
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用 Midjourney 生成的图像
- en: '[Recommender systems](/learning-to-rank-a-primer-40d2ff9960af) have become
    ubiquitous in our daily lives, from online shopping to social media to entertainment
    platforms. These systems use complex algorithms to analyze historic user engagement
    data and make recommendations based on their inferred preferences and behaviors.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[推荐系统](/learning-to-rank-a-primer-40d2ff9960af)已经在我们的日常生活中无处不在，从在线购物到社交媒体再到娱乐平台。这些系统使用复杂的算法来分析历史用户互动数据，并根据他们的推断偏好和行为进行推荐。'
- en: 'While these systems can be incredibly useful in helping users discover new
    content or products, they are not without their flaws: recommender systems are
    plagued by various forms of bias that can lead to poor recommendations and therefore
    poor user experience. One of today’s main research threads around recommender
    systems is therefore how to de-bias them.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些系统在帮助用户发现新内容或产品方面极其有用，但它们并非没有缺陷：推荐系统存在各种形式的偏差，这可能导致糟糕的推荐，从而带来糟糕的用户体验。因此，当前关于推荐系统的主要研究方向之一就是如何消除这些偏差。
- en: In this article, we’ll dive into 5 of the most prevalent biases in recommender
    systems, and learn about some of the recent research from Google, YouTube, Netflix,
    Kuaishou, and others.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将深入探讨推荐系统中五种最常见的偏差，并了解来自 Google、YouTube、Netflix、快手等公司的最新研究。
- en: Let’s get started.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 1 — Clickbait bias
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 — 点击诱饵偏差
- en: 'Wherever there’s an entertainment platform, there’s [clickbait](https://medium.com/mind-cafe/im-boycotting-these-forms-of-youtube-clickbait-8148b0d6363b):
    sensational or misleading headlines or video thumbnails designed to grab a user’s
    attention and entice them to click, without providing any real value. *“You won’t
    believe what happened next!”*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '无论何处有娱乐平台，就会有[点击诱饵](https://medium.com/mind-cafe/im-boycotting-these-forms-of-youtube-clickbait-8148b0d6363b):
    引人注目的或误导性的标题或视频缩略图，旨在吸引用户注意并诱使他们点击，而不提供任何实际价值。 *“你绝对不会相信接下来发生了什么！”*'
- en: If we train a ranking model using clicks as positives, naturally that model
    will be biased in favor of clickbait. This is bad, because such a model would
    promote even more clickbait to users, and therefore amplify the damage it does.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用点击作为正面反馈来训练排名模型，那么这个模型自然会偏向点击诱饵。这是不好的，因为这样的模型会进一步向用户推广更多的点击诱饵，从而放大其造成的伤害。
- en: One solution for de-biasing ranking models from clickbait, proposed by [Covington
    et al (2016)](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)
    in the context of YouTube video recommendations, is **weighted logistic regression**,
    where the weights are the watch time for positive training examples (impressions
    with clicks), and unity for the negative training example (impressions without
    clicks).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一种去除点击诱饵排名模型偏差的解决方案，由 [Covington 等人（2016）](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)
    在 YouTube 视频推荐的背景下提出，是**加权逻辑回归**，其中权重是正训练样本（有点击的印象）的观看时间，而负训练样本（没有点击的印象）的权重为 1。
- en: Mathematically, it can be shown that such a weighted logistic regression model
    learns odds that are approximately the expected watch time for a video. At serving
    time, videos are ranked by their predicted odds, resulting in videos with long
    expected watch times to be placed high on top of the recommendations, and clickbait
    (with the lowest expected watch times) at the bottom of it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，可以证明这样的加权逻辑回归模型学习的赔率大致上是视频的预期观看时间。在服务时，视频根据其预测的赔率进行排名，这导致预期观看时间长的视频被排在推荐列表的顶部，而点击诱饵（预期观看时间最低）则被排在底部。
- en: Unfortunately, Covington et al don’t share all of their experimental results,
    but they do say that weighted logistic regression performs “much better” than
    predicting clicks directly.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Covington 等人没有分享他们所有的实验结果，但他们确实表示，加权逻辑回归的表现“好得多”比直接预测点击要好。
- en: 2 — Duration bias
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 — 时长偏差
- en: 'Weighted logistic regression work well for solving the clickbait problem, but
    it introduces a new problem: duration bias. Simply put, longer videos always have
    a tendency to be watched for a longer time, not necessarily because they’re more
    relevant, but simply because they’re longer.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 加权逻辑回归在解决点击诱饵问题上表现良好，但它引入了一个新问题：时长偏差。简单来说，较长的视频总是倾向于被观看更长时间，这不仅仅是因为它们更相关，而是因为它们更长。
- en: 'Think about a video catalog that contains 10-second short-form videos along
    with 2-hour long-form videos. A watch time of 10 seconds means something completely
    different in the two cases: it’s a strong positive signal in the former, and a
    weak positive (perhaps even a negative) signal in the latter. Yet, the Covington
    approach would not be able to distinguish between these two cases, and would bias
    the model in favor of long-form videos (which generate longer watch times simply
    because they’re longer).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个视频目录，包含 10 秒的短视频和 2 小时的长视频。在这两种情况下，10 秒的观看时间意味着完全不同的事情：在前者中是强正信号，而在后者中是弱正信号（甚至可能是负信号）。然而，Covington
    方法无法区分这两种情况，并且会偏向于长视频（因为它们生成更长的观看时间，仅仅是因为它们更长）。
- en: A solution to duration bias, proposed by [Zhan et al (2022)](https://dl.acm.org/doi/abs/10.1145/3534678.3539092)
    from KuaiShou, is **quantile-based watch-time prediction**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决时长偏差的方案，由 [Zhan 等人（2022）](https://dl.acm.org/doi/abs/10.1145/3534678.3539092)
    从快手提出，是**基于分位的观看时间预测**。
- en: 'The key idea is to bucket all videos into duration quantiles, and then bucket
    all watch times within a duration bucket into quantiles as well. For example,
    with 10 quantiles, such an assignment could look like this:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 关键思想是将所有视频分到时长分位中，然后将时长分位中的所有观看时间也分到分位中。例如，使用 10 个分位，这种分配可能看起来像这样：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: By translating all time intervals into quantiles, the model understands that
    10s is “high” in the latter example, but “low” in the former, so the author’s
    hypothesis. At training time, we’re providing the model with the video quantile,
    and task it with predicting the watch quantile. At inference time, we’re simply
    ranking all videos by their predicted watch time, which will now be de-confounded
    from the video duration itself.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将所有时间间隔转化为分位，模型可以理解 10 秒在后一个例子中是“高”的，而在前一个例子中是“低”的，因此作者的假设。在训练时，我们向模型提供视频的分位，并要求其预测观看分位。在推理时，我们仅按预测的观看时间对所有视频进行排序，这样现在将与视频时长本身去偏。
- en: And indeed, this approach appears to work. Using A/B testing, the authors report
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，这种方法似乎有效。通过 A/B 测试，作者报告
- en: 0.5% improvements in total watch time compared weighted logistic regression
    (the idea from Covington et al), and
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与加权逻辑回归（Covington 等人提出的想法）相比，总观看时间提高了 0.5%，以及
- en: 0.75% improvements in total watch time compared to predicting watch time directly.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与直接预测观看时间相比，总观看时间提高了 0.75%。
- en: The results show that removing duration bias can be a powerful approach on platforms
    that serve both long-form and short-form videos. Perhaps counter-intuitively,
    removing bias in favor of long videos in fact improves overall user user watch
    times.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，去除时长偏见在同时提供长视频和短视频的平台上可以是一种有效的方法。也许有点反直觉的是，去除对长视频的偏见实际上改善了整体用户观看时间。
- en: 3 — Position bias
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 — 位置偏见
- en: Position bias means that the highest-ranked items are the ones which create
    the most engagement not because they’re actually the best content for the user,
    but instead simply because they’re ranked highest, and users start to blindly
    trust the ranking they’re being shown. The model predictions become a self-fulfilling
    prophecy, but this is not what we really want. We want to predict what users want,
    and not make them want what we predict.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 位置偏见意味着排名最高的项目之所以获得最多的参与，不是因为它们实际上是最适合用户的内容，而仅仅因为它们排名最高，用户开始盲目相信他们看到的排名。模型预测变成了自我实现的预言，但这并不是我们真正想要的。我们想要预测用户的需求，而不是让他们想要我们预测的内容。
- en: Position bias can be mitigated by techniques such as rank randomization, intervention
    harvesting, or using the ranks themselves as features, which I covered in my other
    post [here](/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 位置偏见可以通过诸如排名随机化、干预采集或使用排名本身作为特征等技术来缓解，我在我的其他帖子中有介绍 [这里](/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9)。
- en: Particularly problematic is that position bias will always make our models look
    better on paper than they actually are. Our models may be slowly degrading in
    quality, but we wouldn’t know what is happening until it’s too late (and users
    have churned away). It is therefore important, when working with recommender systems,
    to monitor multiple quality metrics about the system, including metrics that quantify
    user retention and the diversity of recommendations.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 特别棘手的是，位置偏见总会让我们的模型在纸面上看起来比实际更好。我们的模型可能会慢慢降级，但我们在为时已晚（用户已经流失）之前不会知道发生了什么。因此，在使用推荐系统时，监控系统的多个质量指标，包括量化用户保留和推荐多样性的指标，是非常重要的。
- en: 4 — Popularity bias
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 — 人气偏见
- en: Popularity bias refers to the tendency of the model to give higher rankings
    to items that are more popular overall (due to the fact that they’ve been rated
    by more users), rather than being based on their actual quality or relevance for
    a particular user. This can lead to a distorted ranking, where less popular or
    niche items that could be a better fit for the user’s preferences are not given
    adequate consideration.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 人气偏见是指模型倾向于给那些总体上更受欢迎的项目（因为它们被更多用户评价）更高的排名，而不是基于这些项目的实际质量或对特定用户的相关性。这可能导致排名扭曲，较少受欢迎或小众的项目可能更适合用户的偏好，却未得到充分考虑。
- en: '[Yi et al (2019)](https://research.google/pubs/pub48840/) from Google propose
    a simple but effective algorithmic tweak to de-bias a video recommendation model
    from popularity bias. During model training, they replace the logits in their
    logistic regression layer as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yi et al (2019)](https://research.google/pubs/pub48840/) 来自 Google 提出了一个简单但有效的算法调整，以去除视频推荐模型中的人气偏见。在模型训练过程中，他们将逻辑回归层中的
    logits 替换为：'
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: where
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: logit(u,v) is the logit function (i.e., the log-odds) for user u engaging with
    video v, and
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logit(u,v)` 是用户 u 参与视频 v 的 logit 函数（即 log-odds），并且'
- en: log(P(v)) is the log-frequency of video v.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log(P(v))` 是视频 v 的 log-frequency。'
- en: 'Of course, the right hand side is equivalent to:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，右侧等价于：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In other words, they simply normalize the predicted odds for a user/video pair
    by the video probability. Extremely high odds from popular videos count as much
    as moderately high odds from not-so-popular videos. And that’s the entire magic.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，他们仅仅通过视频概率来归一化用户/视频对的预测赔率。来自热门视频的极高赔率与来自不那么热门视频的中等高赔率一样重要。这就是全部的魔力。
- en: 'And indeed, the magic appears to work: in online A/B tests, the authors find
    a 0.37% improvement in overall user engagements with the de-biased ranking model.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，这种魔力似乎有效：在在线 A/B 测试中，作者发现使用去偏排名模型，整体用户参与度提高了 0.37%。
- en: 5 — Single-interest bias
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 — 单一兴趣偏见
- en: Suppose you watch mostly drama movies, but sometimes you like to watch a comedy,
    and from time to time a documentary. You have multiple interests, yet a ranking
    model trained to maximize your watch time may over-emphasize drama movies because
    that’s what you’re most likely to engage with. This is **single-interest bias**,
    the failure of a model to understand that users inherently have multiple interests
    and preferences.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你主要观看戏剧电影，但有时也喜欢看喜剧，偶尔也会看纪录片。你有多个兴趣，但一个旨在最大化观看时间的排名模型可能会过分强调戏剧电影，因为那是你最可能参与的内容。这就是**单一兴趣偏差**，即模型未能理解用户本身具有多重兴趣和偏好。
- en: In order to remove single-interest bias, a ranking model needs to be calibrated.
    Calibration simply means that, if you watch drama movies 80% of the time, then
    the model’s top 100 recommendations should in fact include around 80 drama movies
    (and not 100).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了消除单一兴趣偏差，需要对排名模型进行校准。校准简单来说，就是如果你80%的时间观看戏剧电影，那么模型的前100个推荐应该实际包含大约80部戏剧电影（而不是100部）。
- en: Netflix’s [Harald Steck](https://dl.acm.org/doi/10.1145/3240323.3240372) (2018)
    demonstrates the benefits of model calibration with a simple post-processing technique
    called Platt scaling. He presents experimental results that demonstrate the effectiveness
    of the method in improving the calibration of Netflix recommendations, which he
    quantifies with KL divergence scores. The resulting movie recommendations are
    more diverse — in fact, as diverse as the actual user preferences — and result
    in improved overall watch times.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Netflix的[Harald Steck](https://dl.acm.org/doi/10.1145/3240323.3240372)（2018年）展示了使用一种名为Platt
    scaling的简单后处理技术对模型进行校准的好处。他呈现了实验结果，展示了该方法在改善Netflix推荐的校准方面的有效性，并通过KL散度分数进行了量化。结果电影推荐更加多样化——实际上，与实际用户偏好一样多样化——并且导致总体观看时间的改善。
- en: Final thoughts
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终思考
- en: 'Recap for memory:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 记忆回顾：
- en: clickbait bias means that the model is biased in favor of clickbait content
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击诱饵偏差意味着模型偏向于点击诱饵内容。
- en: duration bias means that the model is biased in favor of long videos (and against
    short videos)
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 时长偏差意味着模型偏向于长视频（而不是短视频）。
- en: position bias means that the model is biased in favor of its own predictions
    instead of what users really want
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 位置偏差意味着模型偏向于自身的预测，而不是用户真正想要的内容。
- en: popularity bias means that the model is biased in favor of popular content instead
    of the unique interests of a particular user
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流行偏差意味着模型偏向于流行内容，而不是特定用户的独特兴趣。
- en: single-interest bias means that the model fails to learn multiple user interests
    at the same time
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单一兴趣偏差意味着模型无法同时学习多个用户兴趣。
- en: The list of biases is long — we’ve only scratched the surface here — and it
    is also constantly evolving. In some cases, solving for one bias may even introduce
    a new bias, as we’ve seen with clickbait and duration bias.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差的列表很长——我们这里只是触及了表面——并且它也在不断演变。在某些情况下，解决一个偏差甚至可能引入新的偏差，就像我们在点击诱饵和时长偏差中看到的那样。
- en: 'Coming up with innovative ways to quantify and alleviate these biases therefore
    remains one of the most important tasks for today’s ranking engineers. It’s not
    enough to simply assume that ranking models are neutral or objective: they’ll
    always reflect the biases that exist in the data they are trained on.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，提出创新的方法来量化和减轻这些偏差仍然是今天排名工程师最重要的任务之一。仅仅假设排名模型是中立或客观的并不够：它们总是会反映出训练数据中存在的偏差。
- en: '[](https://medium.com/@samuel.flender/subscribe?source=post_page-----edcda59d30bf--------------------------------)
    [## Don''t want to rely on Medium''s algorithms? Sign up.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 不想依赖Medium的算法？注册一下吧。'
- en: Don't want to rely on Medium's algorithms? Sign up. Make sure you won't miss
    my next article by signing up to my Email…
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不想依赖Medium的算法？注册一下吧。通过注册我的电子邮件，确保不会错过我的下一篇文章……
- en: medium.com](https://medium.com/@samuel.flender/subscribe?source=post_page-----edcda59d30bf--------------------------------)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@samuel.flender/subscribe?source=post_page-----edcda59d30bf--------------------------------)'
