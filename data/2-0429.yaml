- en: Build More Capable LLMs with Retrieval Augmented Generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用检索增强生成构建更强大的大型语言模型
- en: 原文：[https://towardsdatascience.com/build-more-capable-llms-with-retrieval-augmented-generation-99d5f86e9779](https://towardsdatascience.com/build-more-capable-llms-with-retrieval-augmented-generation-99d5f86e9779)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/build-more-capable-llms-with-retrieval-augmented-generation-99d5f86e9779](https://towardsdatascience.com/build-more-capable-llms-with-retrieval-augmented-generation-99d5f86e9779)
- en: How Retrieval Augmented Generation Can Enhance Your LLMs by Integrating a Knowledge
    Base
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检索增强生成如何通过整合知识库提升您的大型语言模型
- en: '[](https://johnadeojo.medium.com/?source=post_page-----99d5f86e9779--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----99d5f86e9779--------------------------------)[](https://towardsdatascience.com/?source=post_page-----99d5f86e9779--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----99d5f86e9779--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----99d5f86e9779--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johnadeojo.medium.com/?source=post_page-----99d5f86e9779--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----99d5f86e9779--------------------------------)[](https://towardsdatascience.com/?source=post_page-----99d5f86e9779--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----99d5f86e9779--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----99d5f86e9779--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----99d5f86e9779--------------------------------)
    ·12 min read·Aug 9, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----99d5f86e9779--------------------------------)
    ·阅读时间 12 分钟·2023 年 8 月 9 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/021250c8f523175e7cc88889a35f18bb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/021250c8f523175e7cc88889a35f18bb.png)'
- en: 'Image by author: Generated with Midjourney'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：使用 Midjourney 生成
- en: '**The Limitations of ChatGPT**'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ChatGPT 的局限性**'
- en: 'ChatGPT is limited for many practical business use cases outside of code generation.
    The limitation arises from the training data, and the model’s propensity to hallucinate.
    At the time of writing, if you try to ask the Chat-GPT questions about events
    occurring after September 2021, you will probably receive a response like this:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 在生成代码以外的许多实际业务场景中是有限的。这些局限性源自训练数据以及模型的幻觉倾向。在撰写时，如果你询问 Chat-GPT 关于 2021
    年 9 月之后发生的事件，你很可能会收到如下回应：
- en: '![](../Images/7979343974282a45cf26222befb3887c.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7979343974282a45cf26222befb3887c.png)'
- en: Image by author
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: This isn’t helpful, so how can we go about rectifying it?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这并没有帮助，那么我们如何解决这个问题呢？
- en: '**Option 1 — Train or fine-tune the model on up-to-date data.**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**选项 1 — 对模型进行训练或微调，以使用最新的数据。**'
- en: Fine-tuning or training a model can be impractical and expensive. Putting aside
    the costs, the effort required to prepare the data sets is enough to forgo this
    option.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 微调或训练模型可能不切实际且昂贵。撇开成本不谈，准备数据集所需的工作量也足以使这一选项不被考虑。
- en: '**Option 2 — Use retrieval augmented generation (RAG) methods.**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**选项 2 — 使用检索增强生成（RAG）方法。**'
- en: RAG methods enable us to give the large language model access to an up-to-date
    knowledge base. This is much cheaper than training a model from scratch or fine-tuning,
    and much easier to implement. In this article, I show you how to leverage RAG
    with your OpenAI model. We will put the model to the test by conducting a short
    analysis of its ability to answer questions about the Russia-Ukraine conflict
    of 2022 from a [Wikipedia](https://en.wikipedia.org/wiki/Russian_invasion_of_Ukraine)
    knowledge base.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 方法使我们可以让大型语言模型访问最新的知识库。这比从头训练模型或进行微调便宜得多，而且实现起来也更简单。在这篇文章中，我将展示如何使用 RAG
    来利用你的 OpenAI 模型。我们将通过对模型进行短期测试，以分析其回答有关 2022 年俄罗斯-乌克兰冲突的问题的能力，知识库来源于 [维基百科](https://en.wikipedia.org/wiki/Russian_invasion_of_Ukraine)。
- en: '*Note: This topic, although sensitive, was chosen for the obvious reason that
    the current ChatGPT model has no knowledge of it.*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：尽管这个话题比较敏感，但由于当前 ChatGPT 模型对此没有相关知识，因此被选择作为讨论的内容。*'
- en: '**Libraries & Pre-requisites**'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**库和前置条件**'
- en: You will require an OpenAI API key, you can grab one directly from their website
    or follow this [tutorial](https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/).
    The framework used for RAG is [Haystack](https://haystack.deepset.ai/) by Deepset,
    which is open source. They provide APIs enabling you to build applications on
    top of large language models. We also leverage sentence transformers and the transformers
    library from [Hugging Face](https://huggingface.co/).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个 OpenAI API 密钥，你可以直接从他们的网站获取，或者按照这个 [教程](https://www.howtogeek.com/885918/how-to-get-an-openai-api-key/)。RAG
    使用的框架是 Deepset 的 [Haystack](https://haystack.deepset.ai/)，它是开源的。他们提供了 API，允许你在大型语言模型之上构建应用程序。我们还利用了来自
    [Hugging Face](https://huggingface.co/) 的句子变换器和变换器库。
- en: '**Sentence Embeddings Help Models Interpret Text**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**句子嵌入帮助模型理解文本**'
- en: Before getting into the technical details around building, we should briefly
    cover sentence embedding. Understanding this concept is key to gaining an intuition
    into how RAG methods work.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入技术细节之前，我们应简要介绍句子嵌入。理解这个概念对获得 RAG 方法如何工作的直觉至关重要。
- en: This may be a cliché, especially for those from a data science background, but
    models don’t actually understand text, they only understand numbers. Much of language
    modelling is about formulating ways to effectively encode text into numbers, and
    currently, we do this with sentence embeddings.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是一个陈词滥调，尤其是对于那些有数据科学背景的人，但模型实际上并不理解文本，它们只理解数字。语言建模的大部分内容是关于制定有效地将文本编码为数字的方式，目前我们通过句子嵌入来做到这一点。
- en: Sentence embeddings are a way for us to represent sentences as a dense vector
    while preserving the semantic structure. Embeddings are learnt from a dense layer
    in a deep neural network, the structure of which can vary from network to network.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 句子嵌入是一种将句子表示为密集向量的方式，同时保留其语义结构。嵌入是从深度神经网络中的密集层中学习的，该网络的结构可以因网络而异。
- en: In much simpler terms, sentence embeddings can be thought of as numeric representations
    of our sentences that preserve information about their meaning. We can get our
    sentence embeddings from pre-trained models. Hugging Face provides open-source
    models for this via their sentence transformers library.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 更简单地说，句子嵌入可以被认为是我们句子的数字表示，保留了它们的语义信息。我们可以从预训练模型中获取句子嵌入。Hugging Face 通过他们的句子变换器库提供了开源模型。
- en: '**Pre-processing and Storage**'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**预处理和存储**'
- en: Before we can build our RAG-enabled model, we need to pre-process and store
    our documents. Let’s explore how we do this, but first take note of the architecture
    of this process to help with your understanding.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以构建 RAG 启用的模型之前，我们需要预处理和存储文档。让我们探索一下如何做到这一点，但首先注意这个过程的架构，以帮助你理解。
- en: '*Note: the architectural diagram also applies to the extractive question answer
    pipeline we define in the next section.*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：架构图也适用于我们在下一节中定义的抽取式问答管道。*'
- en: '![](../Images/252d1afb85f050e37dbd6e0dff83e8ba.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/252d1afb85f050e37dbd6e0dff83e8ba.png)'
- en: 'Image by author: High level architecture pre-processing, vectore store, and
    extractive question-answer pipeline'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供：高层次架构预处理、向量存储和抽取式问答管道
- en: Pre-processing our Documents
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理我们的文档
- en: Haystack provides us tools for easily pre-processing most types of text documents
    (.pdf, .txt, .docx included). The preprocessing steps are simple; we read in our
    knowledge base using the [convert_files_to_docs()](https://docs.haystack.deepset.ai/reference/utils-api#convert_files_to_docs:~:text=Module%20preprocessing-,convert_files_to_docs,-Python)
    function, which can automatically detect the file type and convert it to the format
    we need to work with downstream.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Haystack 为我们提供了方便的工具来预处理大多数类型的文本文件（包括 .pdf、.txt、.docx）。预处理步骤很简单；我们使用 [convert_files_to_docs()](https://docs.haystack.deepset.ai/reference/utils-api#convert_files_to_docs:~:text=Module%20preprocessing-,convert_files_to_docs,-Python)
    函数读取知识库，该函数可以自动检测文件类型并将其转换为我们需要的下游格式。
- en: Haystack also provides a [PreProcessor](https://docs.haystack.deepset.ai/reference/preprocessor-api#preprocessor::text=Module%20preprocessor-,PreProcessor,-Python:~:text=Module%20preprocessor-,PreProcessor,-Python)
    class that enables us to apply preprocessing steps to our documents. The steps
    you apply will depend very much on your specific application.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Haystack 还提供了一个 [PreProcessor](https://docs.haystack.deepset.ai/reference/preprocessor-api#preprocessor::text=Module%20preprocessor-,PreProcessor,-Python:~:text=Module%20preprocessor-,PreProcessor,-Python)
    类，使我们能够对文档应用预处理步骤。你应用的步骤将很大程度上取决于你的具体应用。
- en: '*Note: the processor will enable you to split a long document into a list of
    smaller documents, defined as sentences. For question-and-answer applications,
    a common approach is to have some overlap between sentences; I have set this at
    roughly 30%.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：处理器将允许你将长文档拆分为较小的文档列表，定义为句子。对于问答应用，一个常见的方法是句子之间有一些重叠；我将其设置为大约30%。*'
- en: '**Vector Store**'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**向量存储**'
- en: We leverage [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/),
    a library by Meta that enables efficient similarity search over our sentence embeddings.
    The importance of this will become more obvious in the coming sections. The script
    below shows how we can set up our pre-process for our text documents and set up
    the FAISS vector store.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用了[FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)，这是Meta开发的一个库，用于在我们的句子嵌入中进行高效的相似性搜索。这一点在接下来的章节中将变得更加明显。下面的脚本展示了我们如何为文本文档设置预处理，并建立FAISS向量存储。
- en: 'The full pre-processing script is outlined below:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的预处理脚本如下：
- en: 'Script by author: Document Preprocessing and FAISS vector store'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 作者脚本：文档预处理和FAISS向量存储
- en: '**Defining an Extractive Question-Answer Pipeline**'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**定义抽取式问答管道**'
- en: The next step is to construct our extractive question answer pipeline. Our pipeline
    is defined by nodes which are run sequentially as a directed acyclic graph (DAG).
    In this case, the pipeline consists of two nodes, a retriever, and a reader.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是构建我们的抽取式问答管道。我们的管道由按顺序运行的节点组成，形成一个有向无环图（DAG）。在这种情况下，管道由两个节点组成，一个检索器和一个阅读器。
- en: Retriever
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检索器
- en: Retrieval is the method used to find the relevant information from a knowledge
    base based on the user’s query. When defining our retriever node, we specify a
    sentence embedding model from the sentence transformers library, in this case,
    we use [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2),
    which creates 768-dimensional embeddings.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 检索是根据用户的查询从知识库中找到相关信息的方法。在定义我们的检索器节点时，我们从句子变换器库中指定一个句子嵌入模型，这里我们使用[all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)，它生成768维的嵌入。
- en: Once we have fully defined our retrieval node, we can compute and store the
    sentence embeddings in our FAISS vector store. The same sentence embedding model
    is used to generate sentence embeddings for the user’s query.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们完全定义了检索节点，我们可以在FAISS向量存储中计算并存储句子嵌入。相同的句子嵌入模型用于生成用户查询的句子嵌入。
- en: '*Note: when selecting your sentence embedding model, there is a trade-off between
    computational efficiency and information loss. In general, sentence embedding
    models with higher dimensions capture more information but are less computationally
    efficient.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：在选择句子嵌入模型时，计算效率和信息损失之间存在权衡。通常，维度更高的句子嵌入模型能捕捉更多信息，但计算效率较低。*'
- en: Remember, the ultimate purpose of the retriever node is to find the information
    that relates semantically to the query. This is done by performing a similarity
    search between the sentence embeddings from the query and the documents in our
    vector store. The top-k most relevant sentence embeddings are returned as an output
    from this node.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，检索器节点的最终目的是找到与查询在语义上相关的信息。这是通过在查询的句子嵌入和我们向量存储中的文档之间执行相似性搜索来完成的。此节点返回最相关的前k个句子嵌入作为输出。
- en: Reader
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阅读器
- en: The reader node is a large language model that has been fine-tuned on question-answering
    tasks. For our use case, we leverage [Roberta-base-squad2](https://huggingface.co/deepset/roberta-base-squad2)
    as our reader model. The reader operates on the output from the retriever and
    the initial query from the user and returns the relevant span of text to answer
    the query. The reader will do this for each document in the retriever output,
    allocating a confidence score in each case. The answers are ranked by their score,
    and the top-k answers are returned.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读器节点是一个经过微调的大型语言模型，用于问答任务。在我们的用例中，我们利用[Roberta-base-squad2](https://huggingface.co/deepset/roberta-base-squad2)作为我们的阅读器模型。阅读器处理来自检索器的输出和用户的初始查询，并返回相关的文本片段以回答查询。阅读器会对检索器输出中的每个文档进行处理，为每个文档分配一个置信度分数。答案按分数排序，返回前k个答案。
- en: 'The full script for the pipeline is outlined below:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的完整脚本如下：
- en: 'Script by author: Defining our Extractive question-answer pipeline'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 作者脚本：定义我们的抽取式问答管道
- en: '**Leveraging LLM-Powered Agents**'
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**利用LLM驱动的代理**'
- en: Now that we have pre-processed our documents and defined our pipeline, we can
    construct our agent. An agent is powered by a large language model, in our case,
    OpenAI’s gpt-4 (or gpt-3.5-turbo alternatively).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经预处理了文档并定义了我们的管道，我们可以构建我们的代理。一个代理由大型语言模型提供支持，在我们的案例中，是OpenAI的gpt-4（或gpt-3.5-turbo）。
- en: The agent we are using works on the basis of Zero-shot [ReAcT](https://www.promptingguide.ai/techniques/react)
    (Reason + Act) prompting. We prompt the large language model to return verbal
    reasoning traces and actions for a task. The agent can “act” on the verbal reasoning
    traces using a set of tools we provide it access to. The agent can observe and
    reason about the output from using the tools, helping it to inform its next action.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的代理基于Zero-shot [ReAcT](https://www.promptingguide.ai/techniques/react)（Reason
    + Act）提示。我们提示大型语言模型返回任务的口头推理轨迹和行动。代理可以根据我们提供的工具集对口头推理轨迹进行“行动”。代理可以观察并推理使用工具后的输出，帮助它决定下一步行动。
- en: The animation below gives a simplified view of our ReAct agent at work.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的动画展示了我们ReAct代理工作的简化视图。
- en: '![](../Images/0fc3988afd5cd5d727547d73b0400245.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fc3988afd5cd5d727547d73b0400245.png)'
- en: 'Gif by author: Simplified view of a our agent at work'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者GIF：我们代理工作的简化视图
- en: '*Note:* [*Research*](https://arxiv.org/pdf/2210.03629.pdf) *suggests that ReAct
    prompting has been shown to effectively reduce hallucinations by LLMs.*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：* [*研究*](https://arxiv.org/pdf/2210.03629.pdf) *表明ReAct提示已被证明能够有效减少LLM的幻觉。*'
- en: 'The script below shows how we construct our agent:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本展示了我们如何构建我们的代理：
- en: 'Script by author: Defining our zero-shot ReAct agent'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 作者脚本：定义我们的零-shot ReAct代理
- en: In this use case, the tool we have provided the agent is the extractive question-answer
    pipeline we defined earlier. Essentially the agent can interpret our query, use
    our pipeline as a tool to find the relevant responses in our knowledge base, reason
    to see if this answers the query, choose to respond, or perform the action again
    to get a better answer.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，我们为代理提供的工具是我们之前定义的提取式问答管道。本质上，代理可以解释我们的查询，使用我们的管道作为工具在知识库中找到相关回答，推理是否回答了查询，选择响应，或再次执行该操作以获得更好的答案。
- en: A Brief Note on Tools
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具简要说明
- en: It’s important that we define our tools clearly. For our particular use case,
    we only have one tool, but we need to provide a description of that tool so that
    the LLM-powered agent knows how and when to use the tool. This becomes even more
    important when an agent has access to more than just one tool.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 明确地定义我们的工具非常重要。对于我们的特定用例，我们只有一个工具，但我们需要提供该工具的描述，以便LLM驱动的代理知道如何以及何时使用该工具。当一个代理可以访问的不仅仅是一个工具时，这一点变得更加重要。
- en: '**Putting it to the Test**'
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**测试实施**'
- en: So we have defined our RAG-enabled model; let’s put it to the test by asking
    it trivia on the Russia-Ukraine conflict of 2022\. I have chosen two questions,
    each of which can be answered with information from the wikipedia knowledge base.
    As well as the responses I provide the workflow trace for each agent, you should
    inspect this carefully to gain a better insight into how the ReAct prompting works
    with the agent.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了我们的RAG启用模型；让我们通过向它提问关于2022年俄乌冲突的琐事来进行测试。我选择了两个问题，每个问题都可以通过维基百科知识库中的信息来回答。除了提供的回答，我还提供了每个代理的工作流程跟踪，你应该仔细检查这些以更好地了解ReAct提示如何与代理协同工作。
- en: How did the international community respond to Russia’s invasion of Ukraine
    in 2022?
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 国际社会如何回应2022年俄罗斯入侵乌克兰的事件？
- en: 'Response from the RAG enabled model:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: RAG启用模型的回应：
- en: The international community responded to Russia’s invasion of Ukraine in 2022
    with condemnation and the imposition of new sanctions. These sanctions were comprehensive,
    affecting individuals, banks, businesses, and various types of economic activity
    including monetary exchanges, bank transfers, exports, and imports. Some of the
    specific measures included prison sentences of up to 15 years.
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 国际社会对2022年俄罗斯入侵乌克兰的反应是谴责并施加新的制裁。这些制裁是全面的，涉及个人、银行、企业以及包括货币交换、银行转账、出口和进口在内的各种经济活动。具体措施之一包括最高15年的监禁。
- en: '*Note: The prison sentence for up to 15 years appears to be a hallucination.
    The model has mistakenly suggested this as a sanction measure.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：最高15年的监禁似乎是一个幻觉。模型错误地将其建议为制裁措施。*'
- en: '![](../Images/26c5cd8bac5577b38f7edfb479eabe62.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26c5cd8bac5577b38f7edfb479eabe62.png)'
- en: 'Gif by author: Response to the question “How did the international community
    respond to Russia’s invasion of Ukraine in 2022?”'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的Gif：回应“国际社会如何回应俄罗斯在2022年入侵乌克兰？”的问题。
- en: 'Response from Google search:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 来自Google搜索的回应：
- en: '![](../Images/c7fcf3156e0cc6beb2969b48263dccc7.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7fcf3156e0cc6beb2969b48263dccc7.png)'
- en: 'Image by author: Response from Google search for “How did the international
    community respond to Russia’s invasion of Ukraine in 2022?”'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：来自Google搜索的回应：“国际社会如何回应俄罗斯在2022年入侵乌克兰？”
- en: 'Here’s the trace tracking the agent’s workflow:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是追踪代理工作流的记录：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Who led the IAEA team that investigated the plant on 29 August 2022?
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 谁领导了2022年8月29日调查该工厂的IAEA团队？
- en: 'Response from the RAG enabled model:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: RAG支持的模型的回应：
- en: Rafael Grossi led the IAEA team that investigated the plant on 29 August 2022.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**拉斐尔·格罗西**领导了2022年8月29日调查该工厂的国际原子能机构（IAEA）团队。'
- en: '![](../Images/cde1812cfea100b4e511e008fc60fed9.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cde1812cfea100b4e511e008fc60fed9.png)'
- en: 'Gif by author: Response to the question “Who led the IAEA team that investigated
    the plant on 29 August 2022?”'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的Gif：回应“谁领导了2022年8月29日调查该工厂的IAEA团队？”的问题。
- en: 'Response from Google search:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 来自Google搜索的回应：
- en: '![](../Images/32e0d5573db5f2f843d64a8ae2a3875d.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32e0d5573db5f2f843d64a8ae2a3875d.png)'
- en: 'Image by author: Response from Google search for “Who led the IAEA team that
    investigated the plant on 29 August 2022?”'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：来自Google搜索的回应：“谁领导了2022年8月29日调查该工厂的IAEA团队？”
- en: 'Here’s the trace tracking the agent’s workflow:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是追踪代理工作流的记录：
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For your own curiosity, have a look at the [responses](https://chat.openai.com/share/af96d7f7-1408-422a-923f-ced160313828)
    from ChatGPT for the same questions. You can even try to ask the questions yourself
    to confirm the response.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 出于你的好奇，可以查看[ChatGPT的回应](https://chat.openai.com/share/af96d7f7-1408-422a-923f-ced160313828)，你也可以尝试自己提问以确认回应。
- en: '**Conclusion**'
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Retrieval augmented generation (RAG) enables a large language model to connect
    with an existing knowledge base. RAG-enabled language models have access to up-to-date
    information, making them more useful across a variety of use cases.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）使大型语言模型能够连接到现有的知识库。支持RAG的语言模型可以访问最新的信息，使其在各种使用场景中更为实用。
- en: The retriever and reader methods enable the models to query large corpuses of
    text, overcoming the issues faced by the limited context of large language models
    by themselves. Open-source frameworks like Haystack make it easy to build a RAG-enabled
    LLM prototype quickly.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）方法使模型能够查询大量文本，从而克服了大型语言模型自身面临的上下文限制问题。像Haystack这样的开源框架使得快速构建RAG支持的LLM原型变得简单。
- en: Some key points to note here are that the performance of this method is only
    as good as the knowledge base provided. Also, the inference time can be sped up
    dramatically by deploying the model on suitable infrastructure.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一些关键点是，该方法的性能仅与提供的知识库的质量相当。此外，通过在合适的基础设施上部署模型，可以显著加快推理时间。
- en: For more complex queries, agents may get into situations where they can’t respond
    in the alotted amount of steps. It would be interesting to see how the quality
    of responses varies by increasing the amount of steps, or adding a memory component
    to make the pipeline more conversational. Leveraging a more heavy duty sentence
    embedding model could also serve to improve overall performance.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的查询，代理可能会遇到无法在分配的步骤数量内回应的情况。观察增加步骤数量或加入记忆组件以使流程更具对话性会很有趣。利用更高效的句子嵌入模型也可能有助于提高整体性能。
- en: The code base is in the [GitHub](https://github.com/john-adeojo/haystack-lfqa)
    repo (including the front-end) and is available for you to experiment with.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 代码库在[GitHub](https://github.com/john-adeojo/haystack-lfqa)仓库中（包括前端），你可以在这里进行实验。
- en: There is also a [YouTube](https://youtu.be/-3MLqZppSCY) demo of project.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一个项目的[YouTube](https://youtu.be/-3MLqZppSCY)演示。
- en: Thanks for reading.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
- en: If you’re keen to enhance your skills in artificial intelligence, join the waiting
    list for [my course](https://www.data-centric-solutions.com/course), where I will
    guide you through the process of developing large language model powered applications.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望提升人工智能技能，可以加入[我的课程](https://www.data-centric-solutions.com/course)的等待名单，在那里我将引导你开发基于大型语言模型的应用程序。
- en: If you’re seeking AI-transformation for your business, book a discovery call
    today.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望为你的业务实现AI转型，今天就预约一次发现电话。
- en: '[](https://www.brainqub3.com/?source=post_page-----99d5f86e9779--------------------------------)
    [## Brainqub3 | AI software development'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.brainqub3.com/?source=post_page-----99d5f86e9779--------------------------------)
    [## Brainqub3 | 人工智能软件开发'
- en: At Brainqub3 we develop bespoke AI software. We create qub3s, advanced artificial
    brains, using the latest AI to…
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Brainqub3，我们开发定制的人工智能软件。我们使用最新的人工智能技术创建qub3s，即先进的人工智能大脑，以…
- en: www.brainqub3.com](https://www.brainqub3.com/?source=post_page-----99d5f86e9779--------------------------------)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: www.brainqub3.com](https://www.brainqub3.com/?source=post_page-----99d5f86e9779--------------------------------)
- en: For more insights on artificial intelligence, data science, and large language
    models you can subscribe to the [YouTube](https://www.youtube.com/channel/UCkXe-exqi25V4GnZendgEaA)
    channel.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于人工智能、数据科学和大型语言模型的见解，您可以订阅[YouTube](https://www.youtube.com/channel/UCkXe-exqi25V4GnZendgEaA)频道。
