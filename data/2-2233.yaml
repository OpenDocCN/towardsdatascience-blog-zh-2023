- en: 'Unraveling the Design Pattern of Physics-Informed Neural Networks: Part 07'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­ç¤ºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„è®¾è®¡æ¨¡å¼ï¼šç¬¬ 07 éƒ¨åˆ†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)
- en: Active learning for efficiently training parametric PINN
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é«˜æ•ˆè®­ç»ƒå‚æ•°åŒ– PINN çš„ä¸»åŠ¨å­¦ä¹ 
- en: '[](https://shuaiguo.medium.com/?source=post_page-----4ecb543b616a--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----4ecb543b616a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4ecb543b616a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4ecb543b616a--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----4ecb543b616a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----4ecb543b616a--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----4ecb543b616a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4ecb543b616a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4ecb543b616a--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----4ecb543b616a--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4ecb543b616a--------------------------------)
    Â·8 min readÂ·Jul 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4ecb543b616a--------------------------------)
    Â·é˜…è¯»æ—¶é•¿ 8 åˆ†é’ŸÂ·2023 å¹´ 7 æœˆ 25 æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/65bd5d8fceb65306815ee058fe60f42d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65bd5d8fceb65306815ee058fe60f42d.png)'
- en: Photo by [Scott Graham](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº [Scott Graham](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Welcome to the 7th blog post of this series, where we continue our exciting
    journey of exploring ***design patterns*** of physics-informed neural networks
    (PINN)ğŸ™Œ
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ¬¢è¿æ¥åˆ°æœ¬ç³»åˆ—çš„ç¬¬ 7 ç¯‡åšå®¢ï¼Œæˆ‘ä»¬å°†ç»§ç»­æ¿€åŠ¨äººå¿ƒçš„æ¢ç´¢***ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNï¼‰è®¾è®¡æ¨¡å¼***çš„æ—…ç¨‹ğŸ™Œ
- en: 'In this blog, we will take a closer look at a paper that introduces **active
    learning** to PINN. As usual, we will examine the paper through the lens of design
    pattern: we will start with the target problem, followed by introducing the proposed
    method. After that, we will discuss the evaluation procedure and the advantages/disadvantages
    of the proposed method. Finally, we will conclude the blog by exploring future
    opportunities.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†è¯¦ç»†æ¢è®¨ä¸€ç¯‡å°†**ä¸»åŠ¨å­¦ä¹ **å¼•å…¥ PINN çš„è®ºæ–‡ã€‚å’Œä»¥å¾€ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä»è®¾è®¡æ¨¡å¼çš„è§’åº¦åˆ†æè¿™ç¯‡è®ºæ–‡ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬ä¼šä»‹ç»ç›®æ ‡é—®é¢˜ï¼Œç„¶åå¼•å…¥æå‡ºçš„æ–¹æ³•ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è®¨è®ºè¯„ä¼°è¿‡ç¨‹ä»¥åŠè¯¥æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€‚æœ€åï¼Œæˆ‘ä»¬å°†é€šè¿‡æ¢ç´¢æœªæ¥çš„æœºä¼šæ¥æ€»ç»“åšå®¢å†…å®¹ã€‚
- en: 'As this series continues to expand, the collection of PINN design patterns
    grows even richer! Hereâ€™s a sneak peek at what awaits you:'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: éšç€ç³»åˆ—çš„ä¸æ–­æ‰©å±•ï¼ŒPINN è®¾è®¡æ¨¡å¼çš„é›†åˆä¹Ÿå˜å¾—æ›´åŠ ä¸°å¯Œï¼ä»¥ä¸‹æ˜¯ä¸€äº›å³å°†å‘ˆç°çš„å†…å®¹é¢„è§ˆï¼š
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 01: ä¼˜åŒ–æ®‹å·®ç‚¹åˆ†å¸ƒ](/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 02: åŠ¨æ€è§£å†³æ–¹æ¡ˆåŒºé—´æ‰©å±•](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 03: Training PINN with gradient boosting](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 03: ä½¿ç”¨æ¢¯åº¦æå‡è®­ç»ƒ PINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 04: Gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 04: æ¢¯åº¦å¢å¼º PINN å­¦ä¹ ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 05: Automated hyperparameter tuning](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN è®¾è®¡æ¨¡å¼ 05: è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)'
- en: ''
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINNè®¾è®¡æ¨¡å¼06ï¼šå› æœPINNè®­ç»ƒ](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: Letâ€™s dive in!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ·±å…¥äº†è§£å§ï¼
- en: 1\. Paper at a glance ğŸ”
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. è®ºæ–‡æ¦‚è¿° ğŸ”
- en: '**Title**: Active training of physics-informed neural networks to aggregate
    and interpolate parametric solutions to the Navier-Stokes equations'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‡é¢˜**ï¼šä¸»åŠ¨è®­ç»ƒç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œä»¥èšåˆå’Œæ’å€¼Navier-Stokesæ–¹ç¨‹çš„å‚æ•°åŒ–è§£'
- en: '**Authors**: C. A., Arthurs, A. P. King'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½œè€…**ï¼šC. A., Arthurs, A. P. King'
- en: '**Institutes**: Kingâ€™s College London'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æœºæ„**ï¼šä¼¦æ•¦å›½ç‹å­¦é™¢'
- en: '**Link**: [Journal of Computational Physics](https://www.sciencedirect.com/science/article/pii/S002199912100259X)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é“¾æ¥**ï¼š[è®¡ç®—ç‰©ç†å­¦æœŸåˆŠ](https://www.sciencedirect.com/science/article/pii/S002199912100259X)'
- en: 2\. Design pattern ğŸ¨
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. è®¾è®¡æ¨¡å¼ ğŸ¨
- en: 2.1 Problem ğŸ¯
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 é—®é¢˜ ğŸ¯
- en: One of the prime uses of PINNs is to ***surrogate*** high-fidelity, time-consuming
    numerical simulations (e.g., FEM simulations for structural dynamics). Thanks
    to the strong regularizations enforced by the known governing differential equations
    (represented as an extra loss term), PINNsâ€™ training typically only requires minimal
    data gathered from just a handful of simulation runs.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: PINNçš„ä¸»è¦ç”¨é€”ä¹‹ä¸€æ˜¯***æ›¿ä»£***é«˜ä¿çœŸåº¦ã€è€—æ—¶çš„æ•°å€¼æ¨¡æ‹Ÿï¼ˆä¾‹å¦‚ï¼Œç»“æ„åŠ¨åŠ›å­¦çš„FEMæ¨¡æ‹Ÿï¼‰ã€‚å¾—ç›Šäºå·²çŸ¥æ§åˆ¶å¾®åˆ†æ–¹ç¨‹å¼ºæœ‰åŠ›çš„æ­£åˆ™åŒ–ï¼ˆè¡¨ç°ä¸ºé¢å¤–çš„æŸå¤±é¡¹ï¼‰ï¼ŒPINNçš„è®­ç»ƒé€šå¸¸åªéœ€ä»å°‘é‡æ¨¡æ‹Ÿè¿è¡Œä¸­æ”¶é›†çš„æœ€å°‘æ•°æ®ã€‚
- en: However, this ideal scenario is limited to cases where the problem under investigation
    does not involve variable parameters. In practical applications, we frequently
    need to infer solutions for different domain geometries, model parameters (e.g.,
    material properties), and initial and/or boundary conditions. We certainly donâ€™t
    want to retrain a new PINN for each distinct scenario, as that would be highly
    inefficient and computationally costly.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§ç†æƒ³çš„æƒ…å†µä»…é™äºç ”ç©¶çš„é—®é¢˜ä¸æ¶‰åŠå˜é‡å‚æ•°çš„æƒ…å†µã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦æ¨æ–­ä¸åŒé¢†åŸŸå‡ ä½•å½¢çŠ¶ã€æ¨¡å‹å‚æ•°ï¼ˆä¾‹å¦‚ï¼Œææ–™å±æ€§ï¼‰ä»¥åŠåˆå§‹å’Œ/æˆ–è¾¹ç•Œæ¡ä»¶çš„è§£ã€‚æˆ‘ä»¬è‚¯å®šä¸å¸Œæœ›ä¸ºæ¯ç§ä¸åŒçš„æƒ…å†µé‡æ–°è®­ç»ƒä¸€ä¸ªæ–°çš„PINNï¼Œå› ä¸ºè¿™ä¼šéå¸¸ä½æ•ˆä¸”è®¡ç®—æˆæœ¬é«˜ã€‚
- en: 'One strategy to address this challenge is to upgrade the vanilla PINNs to **parametric
    PINNs**: in essence, the variable parameters are treated as additional inputs
    to the PINN, as depicted in the figure below. Once trained, we can use parametric
    PINN to make instant predictions for any given conditions.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³è¿™ä¸ªæŒ‘æˆ˜çš„ä¸€ç§ç­–ç•¥æ˜¯å°†æ™®é€šPINNå‡çº§ä¸º**å‚æ•°åŒ–PINN**ï¼šæœ¬è´¨ä¸Šï¼Œå˜é‡å‚æ•°è¢«è§†ä¸ºPINNçš„é¢å¤–è¾“å…¥ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‚æ•°åŒ–PINNåœ¨ä»»ä½•ç»™å®šæ¡ä»¶ä¸‹è¿›è¡Œå³æ—¶é¢„æµ‹ã€‚
- en: '![](../Images/1049373831d730dae37e7ab666a1755d.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1049373831d730dae37e7ab666a1755d.png)'
- en: Figure 1\. Compared to the vanilla PINN, which only accepts spatial/temporal
    coordinates, parametric PINN also takes the variable parameters as inputs. (Image
    by this blog author)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1\. ä¸ä»…æ¥å—ç©ºé—´/æ—¶é—´åæ ‡çš„æ™®é€šPINNç›¸æ¯”ï¼Œå‚æ•°åŒ–PINNè¿˜å°†å˜é‡å‚æ•°ä½œä¸ºè¾“å…¥ã€‚ï¼ˆå›¾ç‰‡ç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: 'As expected, however, more inputs calls for more training data. Since generating
    new training data implies running time-consuming simulations, a crucial question
    arises: how can we minimize the simulation runs (thus being more data-efficient)
    for PINN training, while reaching the desired prediction accuracy?'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œæ›´å¤šçš„è¾“å…¥è¦æ±‚æ›´å¤šçš„è®­ç»ƒæ•°æ®ã€‚ç”±äºç”Ÿæˆæ–°è®­ç»ƒæ•°æ®æ„å‘³ç€è¿è¡Œè€—æ—¶çš„æ¨¡æ‹Ÿï¼Œå› æ­¤ä¸€ä¸ªå…³é”®é—®é¢˜å‡ºç°äº†ï¼šå¦‚ä½•åœ¨è¾¾åˆ°æœŸæœ›çš„é¢„æµ‹å‡†ç¡®åº¦çš„åŒæ—¶ï¼Œæœ€å°åŒ–æ¨¡æ‹Ÿè¿è¡Œæ¬¡æ•°ï¼ˆä»è€Œæé«˜æ•°æ®æ•ˆç‡ï¼‰ä»¥è¿›è¡ŒPINNè®­ç»ƒï¼Ÿ
- en: 2.2 Solution ğŸ’¡
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 è§£å†³æ–¹æ¡ˆ ğŸ’¡
- en: The key to answering this question lies in the strategic selection of points
    in the parameter space (i.e., **Î¸** space) to run the simulations, and the solution
    brought forth by the paper is **active learning**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å›ç­”è¿™ä¸ªé—®é¢˜çš„å…³é”®åœ¨äºæˆ˜ç•¥æ€§åœ°é€‰æ‹©å‚æ•°ç©ºé—´ï¼ˆå³**Î¸**ç©ºé—´ï¼‰ä¸­çš„ç‚¹æ¥è¿è¡Œæ¨¡æ‹Ÿï¼Œè€Œè®ºæ–‡æå‡ºçš„è§£å†³æ–¹æ¡ˆæ˜¯**ä¸»åŠ¨å­¦ä¹ **ã€‚
- en: '![](../Images/6bcf8135bb99db1d52235180d1849411.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6bcf8135bb99db1d52235180d1849411.png)'
- en: Figure 2\. Active learning workflow. For PINN training, the â€œLabelâ€ step corresponds
    to running the numerical simulation at the selected sample locations in the parameter
    space. (Image by this blog author)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2\. ä¸»åŠ¨å­¦ä¹ å·¥ä½œæµç¨‹ã€‚å¯¹äºPINNè®­ç»ƒï¼Œâ€œæ ‡ç­¾â€æ­¥éª¤å¯¹åº”äºåœ¨å‚æ•°ç©ºé—´ä¸­é€‰æ‹©çš„æ ·æœ¬ä½ç½®è¿è¡Œæ•°å€¼æ¨¡æ‹Ÿã€‚ï¼ˆå›¾ç‰‡ç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: 'Specific to the applications in addressing parametric PDEs, the proposed workflow
    can be illustrated in the figure below:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: é’ˆå¯¹è§£å†³å‚æ•°åŒ–PDEçš„åº”ç”¨ï¼Œæ‰€æå‡ºçš„å·¥ä½œæµç¨‹å¯ä»¥åœ¨ä¸‹å›¾ä¸­è¯´æ˜ï¼š
- en: '![](../Images/3d34a29f4b245d6aef670b5543d36d42.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d34a29f4b245d6aef670b5543d36d42.png)'
- en: Figure 3\. Illustration of the active learning pipeline proposed in the paper.
    Here, *Î¸*â‚ and *Î¸*â‚‚ denote variable parameters (in practice there can be many
    more such variable parameters), and u represents the physical quantity or quantities
    we are trying to simulate (e.g., in a fluid simulation, u can be velocity, pressure,
    etc.) (Image by this blog author)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾3\. è®ºæ–‡ä¸­æå‡ºçš„ä¸»åŠ¨å­¦ä¹ æµç¨‹ç¤ºæ„å›¾ã€‚åœ¨è¿™é‡Œï¼Œ*Î¸*â‚å’Œ*Î¸*â‚‚è¡¨ç¤ºå˜é‡å‚æ•°ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½æœ‰æ›´å¤šè¿™æ ·çš„å˜é‡å‚æ•°ï¼‰ï¼Œè€Œuè¡¨ç¤ºæˆ‘ä»¬å°è¯•æ¨¡æ‹Ÿçš„ç‰©ç†é‡ï¼ˆä¾‹å¦‚ï¼Œåœ¨æµä½“ä»¿çœŸä¸­ï¼Œuå¯ä»¥æ˜¯é€Ÿåº¦ã€å‹åŠ›ç­‰ï¼‰ï¼ˆå›¾ç‰‡ç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: The proposed active learning pipeline starts with randomly sampling the parameter
    space (in the illustration, *Î¸*â‚ and *Î¸*â‚‚ are the variable parameters) and running
    numerical simulations to gather the training data (i.e., *u*, the physical quantity
    being modeled, at various spatial/temporal locations).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æå‡ºçš„ä¸»åŠ¨å­¦ä¹ æµç¨‹ä»éšæœºé‡‡æ ·å‚æ•°ç©ºé—´å¼€å§‹ï¼ˆåœ¨å›¾ç¤ºä¸­ï¼Œ*Î¸*â‚å’Œ*Î¸*â‚‚æ˜¯å˜é‡å‚æ•°ï¼‰ï¼Œå¹¶è¿›è¡Œæ•°å€¼ä»¿çœŸä»¥æ”¶é›†è®­ç»ƒæ•°æ®ï¼ˆå³åœ¨ä¸åŒç©ºé—´/æ—¶é—´ä½ç½®çš„*u*ï¼Œå³æ‰€å»ºæ¨¡çš„ç‰©ç†é‡ï¼‰ã€‚
- en: Then, we proceed with the usual PINN training, where the neural network predictions
    are required to not only match the collected simulation results *u* but also satisfy
    the governing differential equations.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ç»§ç»­è¿›è¡Œå¸¸è§„çš„PINNè®­ç»ƒï¼Œå…¶ä¸­ç¥ç»ç½‘ç»œçš„é¢„æµ‹ä¸ä»…éœ€è¦ä¸æ”¶é›†çš„æ¨¡æ‹Ÿç»“æœ*u*åŒ¹é…ï¼Œè¿˜éœ€è¦æ»¡è¶³ä¸»å¯¼çš„å¾®åˆ†æ–¹ç¨‹ã€‚
- en: Once the training has converged, we would obtain a PINN model that can accurately
    predict *u* within the simulation spatial/temporal domain, for *Î¸*â‚-*Î¸*â‚‚ values
    included in the training dataset. However, up till now, there is no guarantee
    that for unseen *Î¸*â‚-*Î¸*â‚‚ value combinations, the PINN can also deliver accurate
    predictions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è®­ç»ƒæ”¶æ•›ï¼Œæˆ‘ä»¬å°†è·å¾—ä¸€ä¸ªèƒ½å¤Ÿåœ¨ä»¿çœŸç©ºé—´/æ—¶é—´åŸŸå†…å‡†ç¡®é¢„æµ‹*u*çš„PINNæ¨¡å‹ï¼Œå‰ææ˜¯*Î¸*â‚-*Î¸*â‚‚å€¼åŒ…å«åœ¨è®­ç»ƒæ•°æ®é›†ä¸­ã€‚ç„¶è€Œï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œå¯¹äºæœªè§è¿‡çš„*Î¸*â‚-*Î¸*â‚‚å€¼ç»„åˆï¼Œæ²¡æœ‰ä¿è¯PINNä¹Ÿèƒ½æä¾›å‡†ç¡®çš„é¢„æµ‹ã€‚
- en: Thatâ€™s why we kick off the active learning process. Our goal is to select the
    next *Î¸*â‚-*Î¸*â‚‚ sample to run the simulation. **Ideally, we want this new *Î¸*â‚-*Î¸*â‚‚
    sample to be the most informative and once its associated simulation results are
    appended to the training data, it can bring the most improvement in PINNâ€™s accuracy.**
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å¯åŠ¨ä¸»åŠ¨å­¦ä¹ è¿‡ç¨‹çš„åŸå› ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€‰æ‹©ä¸‹ä¸€ä¸ª*Î¸*â‚-*Î¸*â‚‚æ ·æœ¬æ¥è¿›è¡Œä»¿çœŸã€‚**ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›è¿™ä¸ªæ–°çš„*Î¸*â‚-*Î¸*â‚‚æ ·æœ¬èƒ½å¤Ÿæä¾›æœ€å¤šçš„ä¿¡æ¯ï¼Œä¸€æ—¦å°†å…¶ç›¸å…³çš„æ¨¡æ‹Ÿç»“æœé™„åŠ åˆ°è®­ç»ƒæ•°æ®ä¸­ï¼Œå®ƒå¯ä»¥å¸¦æ¥PINNå‡†ç¡®æ€§çš„æœ€å¤§æå‡ã€‚**
- en: 'So how should we select the new *Î¸*â‚-*Î¸*â‚‚ sample? The paper proposed a simple
    criterion: it first uses the currently trained PINN to predict *u* for all candidate
    *Î¸*â‚-*Î¸*â‚‚ samples in the parameter space (those candidate samples can be pre-generated
    in large quantities to evenly fill the space), then it calculates the corresponding
    PDE residuals for different candidate *Î¸*â‚-*Î¸*â‚‚ samples. Finally, **the next *Î¸*â‚-*Î¸*â‚‚
    sample is chosen as the sample with the highest PDE residuals.**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬åº”è¯¥å¦‚ä½•é€‰æ‹©æ–°çš„*Î¸*â‚-*Î¸*â‚‚æ ·æœ¬å‘¢ï¼Ÿè®ºæ–‡æå‡ºäº†ä¸€ä¸ªç®€å•çš„æ ‡å‡†ï¼šé¦–å…ˆï¼Œä½¿ç”¨å½“å‰è®­ç»ƒå¥½çš„PINNé¢„æµ‹å‚æ•°ç©ºé—´ä¸­æ‰€æœ‰å€™é€‰*Î¸*â‚-*Î¸*â‚‚æ ·æœ¬çš„*u*ï¼ˆè¿™äº›å€™é€‰æ ·æœ¬å¯ä»¥é¢„å…ˆå¤§é‡ç”Ÿæˆä»¥å‡åŒ€å¡«å……ç©ºé—´ï¼‰ï¼Œç„¶åè®¡ç®—ä¸åŒå€™é€‰*Î¸*â‚-*Î¸*â‚‚æ ·æœ¬çš„ç›¸åº”PDEæ®‹å·®ã€‚æœ€åï¼Œ**é€‰æ‹©å…·æœ‰æœ€é«˜PDEæ®‹å·®çš„ä¸‹ä¸€ä¸ª*Î¸*â‚-*Î¸*â‚‚æ ·æœ¬ã€‚**
- en: In other words, the paper proposed to use *PDE residuals* as the indicator for
    PINN prediction accuracy. Since the currently trained PINN has the most difficulty
    in accurately predicting *u* (that fulfills the known differential equation)at
    the selected *Î¸*â‚-*Î¸*â‚‚ location, it makes sense to then run the time-consuming
    simulation at the selected *Î¸*â‚-*Î¸*â‚‚ location and append the original training
    data with the simulated results. Once the training data is enriched, we start
    another round of PINN training, thus completing an iteration of active learning.
    The entire process terminates when the calculated maximum PDE residuals drop below
    a pre-defined threshold.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œè®ºæ–‡å»ºè®®ä½¿ç”¨*PDEæ®‹å·®*ä½œä¸ºPINNé¢„æµ‹å‡†ç¡®æ€§çš„æŒ‡æ ‡ã€‚ç”±äºå½“å‰è®­ç»ƒçš„PINNåœ¨é€‰å®šçš„*Î¸*â‚-*Î¸*â‚‚ä½ç½®æœ€éš¾å‡†ç¡®é¢„æµ‹æ»¡è¶³å·²çŸ¥å¾®åˆ†æ–¹ç¨‹çš„*u*ï¼Œå› æ­¤åœ¨é€‰å®šçš„*Î¸*â‚-*Î¸*â‚‚ä½ç½®è¿è¡Œè€—æ—¶çš„ä»¿çœŸï¼Œå¹¶å°†æ¨¡æ‹Ÿç»“æœé™„åŠ åˆ°åŸå§‹è®­ç»ƒæ•°æ®ä¸­æ˜¯æœ‰æ„ä¹‰çš„ã€‚ä¸€æ—¦è®­ç»ƒæ•°æ®å¾—åˆ°ä¸°å¯Œï¼Œæˆ‘ä»¬å°±å¼€å§‹å¦ä¸€è½®PINNè®­ç»ƒï¼Œä»è€Œå®Œæˆä¸€æ¬¡ä¸»åŠ¨å­¦ä¹ çš„è¿­ä»£ã€‚æ•´ä¸ªè¿‡ç¨‹åœ¨è®¡ç®—çš„æœ€å¤§PDEæ®‹å·®é™åˆ°é¢„å®šä¹‰çš„é˜ˆå€¼ä»¥ä¸‹æ—¶ç»ˆæ­¢ã€‚
- en: 2.3 Why the solution might work ğŸ› ï¸
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 ä¸ºä»€ä¹ˆè§£å†³æ–¹æ¡ˆå¯èƒ½æœ‰æ•ˆ ğŸ› ï¸
- en: Active learning is a well-established technique for reducing model training
    costs. It is effective because it identifies the regions in the parameter space
    where the current PINNâ€™s predictions are less satisfactory, and later chooses
    which points to simulate next accordingly such that the model improvement can
    be maximized. This way, active learning can drastically improve data efficiency
    while ensuring the desired prediction accuracy can be reached.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»åŠ¨å­¦ä¹ æ˜¯ä¸€ç§æˆç†Ÿçš„æŠ€æœ¯ï¼Œç”¨äºå‡å°‘æ¨¡å‹è®­ç»ƒæˆæœ¬ã€‚å®ƒä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºå®ƒèƒ½å¤Ÿè¯†åˆ«å½“å‰PINNé¢„æµ‹ä¸å¤Ÿæ»¡æ„çš„å‚æ•°ç©ºé—´åŒºåŸŸï¼Œç„¶åç›¸åº”åœ°é€‰æ‹©ä¸‹ä¸€æ­¥è¦æ¨¡æ‹Ÿçš„ç‚¹ï¼Œä»¥æœ€å¤§åŒ–æ¨¡å‹çš„æ”¹è¿›ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä¸»åŠ¨å­¦ä¹ å¯ä»¥æ˜¾è‘—æé«˜æ•°æ®æ•ˆç‡ï¼ŒåŒæ—¶ç¡®ä¿è¾¾åˆ°æ‰€éœ€çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚
- en: 2.4 Benchmark â±ï¸
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 åŸºå‡†æµ‹è¯• â±ï¸
- en: 'Unlike other PINN papers, the current paper solely focused on solving parametric
    steady, incompressible Navier-Stokes equations in a continuous set of 2D tubular
    domains:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–PINNè®ºæ–‡ä¸åŒï¼Œå½“å‰è®ºæ–‡ä¸“æ³¨äºè§£å†³è¿ç»­2Dç®¡é“åŸŸä¸­çš„å‚æ•°ç¨³æ€ä¸å¯å‹Navier-Stokesæ–¹ç¨‹ï¼š
- en: '![](../Images/12461ce9bd9f065de5590aa598adc368.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12461ce9bd9f065de5590aa598adc368.png)'
- en: Two variable parameters are considered, including a flow boundary condition,
    i.e., the inflow rate, as well as a domain shape parameter.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘äº†ä¸¤ä¸ªå˜é‡å‚æ•°ï¼ŒåŒ…æ‹¬æµåŠ¨è¾¹ç•Œæ¡ä»¶ï¼Œå³æµå…¥é€Ÿç‡ï¼Œä»¥åŠåŸŸå½¢çŠ¶å‚æ•°ã€‚
- en: The paper demonstrated that the PINN trained with the proposed active learning
    strategy can accurately and efficiently predict the flow field for any given values
    of inflow rate and domain shape within their considered variational ranges.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡å±•ç¤ºäº†ï¼Œé€šè¿‡æå‡ºçš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥è®­ç»ƒçš„PINNå¯ä»¥å‡†ç¡®é«˜æ•ˆåœ°é¢„æµ‹ç»™å®šæµå…¥é€Ÿç‡å’ŒåŸŸå½¢çŠ¶å€¼çš„æµåœºï¼Œä¸”è¿™äº›å€¼éƒ½åœ¨è€ƒè™‘çš„å˜åŠ¨èŒƒå›´å†…ã€‚
- en: The paper also demonstrated that using the proposed active learning strategy
    requires much fewer simulation runs compared to random or uniform data selection
    within the considered parameter space, while achieving a far smaller error in
    flow field prediction.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è®ºæ–‡è¿˜å±•ç¤ºäº†ï¼Œä½¿ç”¨æå‡ºçš„ä¸»åŠ¨å­¦ä¹ ç­–ç•¥ç›¸æ¯”äºåœ¨æ‰€è€ƒè™‘çš„å‚æ•°ç©ºé—´å†…è¿›è¡Œéšæœºæˆ–å‡åŒ€æ•°æ®é€‰æ‹©ï¼Œéœ€è¦çš„æ¨¡æ‹Ÿæ¬¡æ•°è¦å°‘å¾—å¤šï¼ŒåŒæ—¶åœ¨æµåœºé¢„æµ‹ä¸­çš„è¯¯å·®ä¹Ÿè¦å°å¾—å¤šã€‚
- en: 'Finally, the paper showcased one practical usage of the trained parametric
    PINN: parameter sweeping. More specifically, the trained PINN can be used to search
    the parameter space and identify the values of the two parameters when the resulting
    flow field satisfies the given conditions.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œè®ºæ–‡å±•ç¤ºäº†è®­ç»ƒåçš„å‚æ•°åŒ–PINNçš„ä¸€ä¸ªå®é™…åº”ç”¨ï¼šå‚æ•°æ‰«æã€‚æ›´å…·ä½“åœ°è¯´ï¼Œè®­ç»ƒåçš„PINNå¯ä»¥ç”¨äºæœç´¢å‚æ•°ç©ºé—´ï¼Œå¹¶è¯†åˆ«å½“æµåœºæ»¡è¶³ç»™å®šæ¡ä»¶æ—¶ä¸¤ä¸ªå‚æ•°çš„å€¼ã€‚
- en: 2.5 Strengths and Weaknesses âš¡
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 ä¼˜åŠ¿ä¸åŠ£åŠ¿ âš¡
- en: '**Strengths** ğŸ’ª'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¼˜ç‚¹** ğŸ’ª'
- en: Dramatically reduce the simulation data needed to train a *parametric* PINN
    model with desired prediction accuracy.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤§å¹…å‡å°‘è®­ç»ƒå…·æœ‰æ‰€éœ€é¢„æµ‹å‡†ç¡®æ€§çš„*å‚æ•°*PINNæ¨¡å‹æ‰€éœ€çš„æ¨¡æ‹Ÿæ•°æ®ã€‚
- en: The trained PINN model can provide extremely fast approximations to PDE solutions
    across a region of parameter space.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒåçš„PINNæ¨¡å‹èƒ½å¤Ÿåœ¨å‚æ•°ç©ºé—´çš„åŒºåŸŸå†…æä¾›æå¿«çš„PDEè§£å†³æ–¹æ¡ˆè¿‘ä¼¼å€¼ã€‚
- en: The trained PINN is highly flexible, as it can be adapted to a different parameter
    space without the need for comprehensive retraining. This is possible because
    active learning allows the model to be easily updated as new rounds of simulations
    are performed in the extended parameter space.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒåçš„PINNå…·æœ‰é«˜åº¦çµæ´»æ€§ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨ä¸éœ€è¦å…¨é¢é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹é€‚åº”ä¸åŒçš„å‚æ•°ç©ºé—´ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºä¸»åŠ¨å­¦ä¹ å…è®¸æ¨¡å‹éšç€æ–°çš„æ¨¡æ‹Ÿå›åˆåœ¨æ‰©å±•å‚æ•°ç©ºé—´ä¸­è¢«è½»æ¾æ›´æ–°ã€‚
- en: No need to store a large number of simulation results, as the trained parametric
    PINN can generate the flow field results on demand. Since a typical neural network
    only consumes a small amount of storage space, the potential data compression
    is significant.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸éœ€è¦å­˜å‚¨å¤§é‡æ¨¡æ‹Ÿç»“æœï¼Œå› ä¸ºè®­ç»ƒåçš„å‚æ•°åŒ–PINNå¯ä»¥æŒ‰éœ€ç”Ÿæˆæµåœºç»“æœã€‚ç”±äºå…¸å‹çš„ç¥ç»ç½‘ç»œåªæ¶ˆè€—å°‘é‡å­˜å‚¨ç©ºé—´ï¼Œå› æ­¤æ½œåœ¨çš„æ•°æ®å‹ç¼©æ˜¯æ˜¾è‘—çš„ã€‚
- en: '**Weaknesses** ğŸ“‰'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**åŠ£åŠ¿** ğŸ“‰'
- en: The effectiveness of the proposed active training pipeline may be dependent
    on the initial data. If the initial data set does not adequately represent the
    underlying behavior of the system, the model may struggle to identify areas of
    potential improvement, thus leading to a suboptimal selection of the following
    simulations.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æå‡ºçš„ä¸»åŠ¨è®­ç»ƒæµç¨‹çš„æœ‰æ•ˆæ€§å¯èƒ½å–å†³äºåˆå§‹æ•°æ®ã€‚å¦‚æœåˆå§‹æ•°æ®é›†ä¸èƒ½å……åˆ†ä»£è¡¨ç³»ç»Ÿçš„åŸºæœ¬è¡Œä¸ºï¼Œæ¨¡å‹å¯èƒ½éš¾ä»¥è¯†åˆ«æ½œåœ¨çš„æ”¹è¿›åŒºåŸŸï¼Œä»è€Œå¯¼è‡´åç»­æ¨¡æ‹Ÿçš„é€‰æ‹©ä¸ç†æƒ³ã€‚
- en: Additionally, the proposed approach uses the PDE residuals as the indication
    for the model prediction accuracy. However, for cases when the model prediction
    accuracy does not correlate well with the PDE residuals, the effectiveness of
    the proposed approach will likely be discounted.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæ‰€æçš„æ–¹æ³•ä½¿ç”¨PDEæ®‹å·®ä½œä¸ºæ¨¡å‹é¢„æµ‹ç²¾åº¦çš„æŒ‡ç¤ºã€‚ç„¶è€Œï¼Œå¯¹äºæ¨¡å‹é¢„æµ‹ç²¾åº¦ä¸PDEæ®‹å·®ä¸ç›¸å…³çš„æƒ…å†µï¼Œæ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§å¯èƒ½ä¼šè¢«æ‰“æŠ˜æ‰£ã€‚
- en: Currently, the paper only considered two variable parameters. However, active
    learning may become computationally expensive as the dimensionality of the problem
    increases. Therefore, the scalability of the proposed approach remains to be investigated.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼Œæœ¬æ–‡ä»…è€ƒè™‘äº†ä¸¤ä¸ªå˜é‡å‚æ•°ã€‚ç„¶è€Œï¼Œéšç€é—®é¢˜ç»´åº¦çš„å¢åŠ ï¼Œä¸»åŠ¨å­¦ä¹ å¯èƒ½å˜å¾—è®¡ç®—æ˜‚è´µã€‚å› æ­¤ï¼Œæ‰€ææ–¹æ³•çš„å¯æ‰©å±•æ€§ä»éœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚
- en: 2.6 Alternatives ğŸ”€
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 æ›¿ä»£æ–¹æ¡ˆ ğŸ”€
- en: Alternative to using an active learning scheme, the samples (which are used
    to run simulations to generate training data) can also be generated by adopting
    quasi-random sampling methods. Popular quasi-random sampling methods include Latin
    hypercube sampling (LHS), Sobol sequences, and Halton sequences. Compared to a
    simple random sampling scheme, the quasi-random sampling approaches have better
    *space-filling* properties, meaning that fewer samples are required to evenly
    cover the investigated parameter space.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æ›¿ä»£ä½¿ç”¨ä¸»åŠ¨å­¦ä¹ æ–¹æ¡ˆï¼Œæ ·æœ¬ï¼ˆç”¨äºè¿è¡Œæ¨¡æ‹Ÿä»¥ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼‰ä¹Ÿå¯ä»¥é€šè¿‡é‡‡ç”¨å‡†éšæœºé‡‡æ ·æ–¹æ³•ç”Ÿæˆã€‚æµè¡Œçš„å‡†éšæœºé‡‡æ ·æ–¹æ³•åŒ…æ‹¬æ‹‰ä¸è¶…ç«‹æ–¹ä½“é‡‡æ ·ï¼ˆLHSï¼‰ã€Sobolåºåˆ—å’ŒHaltonåºåˆ—ã€‚ä¸ç®€å•éšæœºé‡‡æ ·æ–¹æ¡ˆç›¸æ¯”ï¼Œå‡†éšæœºé‡‡æ ·æ–¹æ³•å…·æœ‰æ›´å¥½çš„*ç©ºé—´å¡«å……*ç‰¹æ€§ï¼Œè¿™æ„å‘³ç€éœ€è¦æ›´å°‘çš„æ ·æœ¬æ¥å‡åŒ€è¦†ç›–æ‰€ç ”ç©¶çš„å‚æ•°ç©ºé—´ã€‚
- en: However, compared to the active learning approach proposed in the paper, the
    quasi-random sampling schemes would require the user to specify a sample number
    upfront, therefore they are less flexible in terms of enriching the training dataset
    when new simulation data is available. Nevertheless, active learning would introduce
    extra computational costs due to the necessity of estimating the modelâ€™s performance
    and determining the most informative points for performing the next simulation
    run.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä¸è®ºæ–‡ä¸­æå‡ºçš„ä¸»åŠ¨å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œå‡†éšæœºé‡‡æ ·æ–¹æ¡ˆéœ€è¦ç”¨æˆ·é¢„å…ˆæŒ‡å®šæ ·æœ¬æ•°é‡ï¼Œå› æ­¤åœ¨æ–°æ¨¡æ‹Ÿæ•°æ®å¯ç”¨æ—¶ï¼Œåœ¨ä¸°å¯Œè®­ç»ƒæ•°æ®é›†æ–¹é¢çš„çµæ´»æ€§è¾ƒå·®ã€‚ç„¶è€Œï¼Œä¸»åŠ¨å­¦ä¹ ä¼šå¼•å…¥é¢å¤–çš„è®¡ç®—æˆæœ¬ï¼Œå› ä¸ºéœ€è¦ä¼°è®¡æ¨¡å‹çš„æ€§èƒ½å¹¶ç¡®å®šæœ€å…·ä¿¡æ¯é‡çš„ç‚¹ä»¥è¿›è¡Œä¸‹ä¸€æ¬¡æ¨¡æ‹Ÿè¿è¡Œã€‚
- en: 3 Potential Future Improvements ğŸŒŸ
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3ä¸ªæ½œåœ¨çš„æœªæ¥æ”¹è¿› ğŸŒŸ
- en: 'There are several possibilities to further improve the proposed strategy:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ä¸ªå¯èƒ½çš„æ–¹å‘å¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›æ‰€æçš„ç­–ç•¥ï¼š
- en: Leveraging more sophisticated active learning algorithms to automate the selection
    of training data points. This may further improve the accuracy of the predictions
    and reduce the amount of time needed for training.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ©ç”¨æ›´å¤æ‚çš„ä¸»åŠ¨å­¦ä¹ ç®—æ³•æ¥è‡ªåŠ¨é€‰æ‹©è®­ç»ƒæ•°æ®ç‚¹ã€‚è¿™å¯èƒ½è¿›ä¸€æ­¥æé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶å‡å°‘è®­ç»ƒæ‰€éœ€çš„æ—¶é—´ã€‚
- en: Developing strategies to allow sampling of multiple data points in each active
    learning iteration. As the corresponding simulations can be run in parallel, the
    overall training efficiency can be greatly improved.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¼€å‘ç­–ç•¥ä»¥å…è®¸åœ¨æ¯æ¬¡ä¸»åŠ¨å­¦ä¹ è¿­ä»£ä¸­é‡‡æ ·å¤šä¸ªæ•°æ®ç‚¹ã€‚ç”±äºç›¸åº”çš„æ¨¡æ‹Ÿå¯ä»¥å¹¶è¡Œè¿è¡Œï¼Œå› æ­¤æ•´ä½“è®­ç»ƒæ•ˆç‡å¯ä»¥å¤§å¤§æé«˜ã€‚
- en: Integrating other proven best practices of training PINN (collocation point
    sampling, casual training, ensemble learning, etc.) with the proposed active learning
    scheme to further improve the model performance.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†å…¶ä»–ç»è¿‡éªŒè¯çš„æœ€ä½³å®è·µï¼ˆå¦‚ååŒç‚¹é‡‡æ ·ã€å› æœè®­ç»ƒã€é›†æˆå­¦ä¹ ç­‰ï¼‰ä¸æ‰€æçš„ä¸»åŠ¨å­¦ä¹ æ–¹æ¡ˆæ•´åˆï¼Œä»¥è¿›ä¸€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
- en: 4 Takeaways ğŸ“
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4ä¸ªè¦ç‚¹ ğŸ“
- en: 'In this blog post, we looked at how to perform data-efficient, parametric PINN
    training with active learning. Here are the highlights of the design pattern proposed
    in the paper:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å¦‚ä½•ä½¿ç”¨ä¸»åŠ¨å­¦ä¹ è¿›è¡Œæ•°æ®é«˜æ•ˆçš„å‚æ•°åŒ–PINNè®­ç»ƒã€‚ä»¥ä¸‹æ˜¯è®ºæ–‡ä¸­æå‡ºçš„è®¾è®¡æ¨¡å¼çš„äº®ç‚¹ï¼š
- en: '[Problem]: How to train parametric PINNs with as few data samples as possible.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[é—®é¢˜]ï¼šå¦‚ä½•ç”¨å°½å¯èƒ½å°‘çš„æ•°æ®æ ·æœ¬è®­ç»ƒå‚æ•°åŒ–PINNã€‚'
- en: '[Solution]: **Training PINN with active learning**, where data are collected
    adaptively to maximize the improvement in PINNâ€™s prediction accuracy.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[è§£å†³æ–¹æ¡ˆ]ï¼š**ä½¿ç”¨ä¸»åŠ¨å­¦ä¹ è®­ç»ƒPINN**ï¼Œåœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ•°æ®ä¼šè¢«è‡ªé€‚åº”åœ°æ”¶é›†ï¼Œä»¥æœ€å¤§åŒ–PINNé¢„æµ‹ç²¾åº¦çš„æå‡ã€‚'
- en: '[Potential benefits]: 1\. Significantly reduced the training cost of parametric
    PINNs. 2\. Trained parametric PINN provides fast approximations to PDE solutions
    across a region of parameter space.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ½œåœ¨å¥½å¤„]ï¼š1. æ˜¾è‘—é™ä½äº†å‚æ•°åŒ–PINNçš„è®­ç»ƒæˆæœ¬ã€‚2. è®­ç»ƒåçš„å‚æ•°åŒ–PINNåœ¨å‚æ•°ç©ºé—´çš„åŒºåŸŸå†…æä¾›äº†å¯¹PDEè§£çš„å¿«é€Ÿè¿‘ä¼¼ã€‚'
- en: 'Here is the PINN design card to summarize the takeaways:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æ€»ç»“è¦ç‚¹çš„PINNè®¾è®¡å¡ï¼š
- en: '![](../Images/a8c75b852264307afc8ab527e969f81a.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8c75b852264307afc8ab527e969f81a.png)'
- en: PINN design pattern proposed in the paper. (Image by this blog author)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è®ºæ–‡ä¸­æå‡ºçš„ PINN è®¾è®¡æ¨¡å¼ã€‚ï¼ˆå›¾ç‰‡ç”±æœ¬åšå®¢ä½œè€…æä¾›ï¼‰
- en: Reference ğŸ“‘
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ® ğŸ“‘
- en: '[1] Arthurs et al., Active training of physics-informed neural networks to
    aggregate and interpolate parametric solutions to the Navier-Stokes equations,
    [Journal of Computational Physics](https://www.sciencedirect.com/science/article/pii/S002199912100259X),
    2021.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Arthurs ç­‰äººï¼Œã€Šç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„ä¸»åŠ¨è®­ç»ƒä»¥èšåˆå’Œæ’å€¼ Navier-Stokes æ–¹ç¨‹çš„å‚æ•°è§£ã€‹ï¼Œ[è®¡ç®—ç‰©ç†å­¦æœŸåˆŠ](https://www.sciencedirect.com/science/article/pii/S002199912100259X)ï¼Œ2021å¹´ã€‚'
