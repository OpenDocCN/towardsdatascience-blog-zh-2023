- en: Fine-Tune Your Own Llama 2 Model in a Colab Notebook
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Colab笔记本中微调你自己的Llama 2模型
- en: 原文：[https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32](https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32](https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32)
- en: A practical introduction to LLM fine-tuning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实用的LLM微调介绍
- en: '[](https://medium.com/@mlabonne?source=post_page-----df9823a04a32--------------------------------)[![Maxime
    Labonne](../Images/a7efdd305e3cc77d5509bbb1076d57d8.png)](https://medium.com/@mlabonne?source=post_page-----df9823a04a32--------------------------------)[](https://towardsdatascience.com/?source=post_page-----df9823a04a32--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----df9823a04a32--------------------------------)
    [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----df9823a04a32--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mlabonne?source=post_page-----df9823a04a32--------------------------------)[![Maxime
    Labonne](../Images/a7efdd305e3cc77d5509bbb1076d57d8.png)](https://medium.com/@mlabonne?source=post_page-----df9823a04a32--------------------------------)[](https://towardsdatascience.com/?source=post_page-----df9823a04a32--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----df9823a04a32--------------------------------)
    [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----df9823a04a32--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----df9823a04a32--------------------------------)
    ·12 min read·Jul 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----df9823a04a32--------------------------------)
    ·12分钟阅读·2023年7月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/deab49c0869889d83573906da9f2c40b.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/deab49c0869889d83573906da9f2c40b.png)'
- en: Image by author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'With the release of LLaMA v1, we saw a Cambrian explosion of fine-tuned models,
    including [Alpaca](https://github.com/tatsu-lab/stanford_alpaca), [Vicuna](https://huggingface.co/lmsys/vicuna-13b-v1.3),
    and [WizardLM](https://huggingface.co/WizardLM/WizardLM-13B-V1.1), among others.
    This trend encouraged different businesses to launch their own base models with
    licenses suitable for commercial use, such as [OpenLLaMA](https://github.com/openlm-research/open_llama),
    [Falcon](https://falconllm.tii.ae/), [XGen](https://github.com/salesforce/xgen),
    etc. The release of Llama 2 now combines the best elements from both sides: it
    offers a **highly efficient base model along with a more permissive license**.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLaMA v1的发布，我们见证了微调模型的寒武纪大爆发，包括[Alpaca](https://github.com/tatsu-lab/stanford_alpaca)、[Vicuna](https://huggingface.co/lmsys/vicuna-13b-v1.3)和[WizardLM](https://huggingface.co/WizardLM/WizardLM-13B-V1.1)等。这一趋势促使不同的公司推出了适合商业使用的基础模型许可证，如[OpenLLaMA](https://github.com/openlm-research/open_llama)、[Falcon](https://falconllm.tii.ae/)和[XGen](https://github.com/salesforce/xgen)等。Llama
    2的发布现将两者的最佳元素结合起来：提供了**高效的基础模型和更宽松的许可证**。
- en: 'During the first half of 2023, the software landscape was significantly shaped
    by the **widespread use of APIs** (like OpenAI API) to create infrastructures
    based on Large Language Models (LLMs). Libraries such as [LangChain](https://python.langchain.com/docs/get_started/introduction.html)
    and [LlamaIndex](https://www.llamaindex.ai/) played a critical role in this trend.
    Moving into the latter half of the year, the process of **fine-tuning (or instruction
    tuning) these models is set to become a standard procedure** in the LLMOps workflow.
    This trend is driven by various factors: the potential for cost savings, the ability
    to process confidential data, and even the potential to develop models that exceed
    the performance of prominent models like ChatGPT and GPT-4 in certain specific
    tasks.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在2023年上半年，软件领域受到了**API的广泛使用**（如OpenAI API）的重大影响，利用大型语言模型（LLMs）构建基础设施。[LangChain](https://python.langchain.com/docs/get_started/introduction.html)和[LlamaIndex](https://www.llamaindex.ai/)等库在这一趋势中发挥了关键作用。进入下半年，**微调（或指令调优）这些模型将成为LLMOps工作流中的标准流程**。这一趋势受到多种因素推动：节省成本的潜力、处理机密数据的能力，甚至是开发超越ChatGPT和GPT-4等显著模型在特定任务中的表现的模型的潜力。
- en: In this article, we will see why instruction tuning works and how to implement
    it in a Google Colab notebook to create your own Llama 2 model. As usual, the
    code is available on [Colab](https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing)
    and [GitHub](https://github.com/mlabonne/llm-course).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨为什么指令调优有效，以及如何在Google Colab笔记本中实现它，以创建你自己的Llama 2模型。与往常一样，代码可在[Colab](https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing)和[GitHub](https://github.com/mlabonne/llm-course)上找到。
- en: '**🔧** Background on fine-tuning LLMs'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**🔧** 微调LLMs的背景'
- en: '![](../Images/a0c0ab9d87266afc92a4a41531b2f70f.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0c0ab9d87266afc92a4a41531b2f70f.png)'
- en: Image by author
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: LLMs are pretrained on an extensive corpus of text. In the case of [Llama 2](https://arxiv.org/abs/2307.09288),
    we know very little about the composition of the training set, besides its length
    of 2 trillion tokens. In comparison, [BERT](https://arxiv.org/abs/1810.04805)
    (2018) was “only” trained on the BookCorpus (800M words) and English Wikipedia
    (2,500M words). From experience, this is a **very costly and long process** with
    a lot of hardware issues. If you want to know more about it, I recommend reading
    [Meta’s logbook](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf)
    about the pretraining of the OPT-175B model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs在大量文本语料库上进行预训练。以[Llama 2](https://arxiv.org/abs/2307.09288)为例，我们对训练集的组成知之甚少，除了它有2万亿个标记。相比之下，[BERT](https://arxiv.org/abs/1810.04805)（2018年）“仅”在BookCorpus（8亿词）和英语维基百科（25亿词）上进行过训练。从经验来看，这**是一个非常昂贵且漫长的过程**，并且有很多硬件问题。如果你想了解更多，我推荐阅读[Meta的日志](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf)，了解OPT-175B模型的预训练情况。
- en: 'When the pretraining is complete, auto-regressive models like Llama 2 can **predict
    the next token** in a sequence. However, this does not make them particularly
    useful assistants since they don’t reply to instructions. This is why we employ
    instruction tuning to align their answers with what humans expect. There are two
    main fine-tuning techniques:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当预训练完成后，像Llama 2这样的自回归模型可以**预测序列中的下一个标记**。然而，这并没有使它们成为特别有用的助手，因为它们不会对指令作出回应。这就是我们采用指令调优来使它们的回答与人类期望对齐的原因。主要有两种微调技术：
- en: '**Supervised Fine-Tuning** (SFT): Models are trained on a dataset of instructions
    and responses. It adjusts the weights in the LLM to minimize the difference between
    the generated answers and ground-truth responses, acting as labels.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督微调**（SFT）：模型在一组指令和响应的数据集上进行训练。它调整LLM中的权重，以最小化生成的答案与真实响应之间的差异，作为标签。'
- en: '**Reinforcement Learning from Human Feedback** (RLHF): Models learn by interacting
    with their environment and receiving feedback. They are trained to maximize a
    reward signal (using [PPO](https://arxiv.org/abs/1707.06347)), which is often
    derived from human evaluations of model outputs.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**来自人类反馈的强化学习**（RLHF）：模型通过与环境互动并接收反馈来学习。它们被训练以最大化奖励信号（使用[PPO](https://arxiv.org/abs/1707.06347)），这个信号通常来源于人类对模型输出的评估。'
- en: In general, RLHF is shown to capture **more complex and nuanced** human preferences,
    but is also more challenging to implement effectively. Indeed, it requires careful
    design of the reward system and can be sensitive to the quality and consistency
    of human feedback. A possible alternative in the future is the [Direct Preference
    Optimization](https://arxiv.org/abs/2305.18290) (DPO) algorithm, which directly
    runs preference learning on the SFT model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，RLHF被证明能够捕捉到**更复杂和细致的**人类偏好，但也更难有效实施。确实，它需要精心设计奖励系统，并且对人类反馈的质量和一致性较为敏感。未来的一个可能替代方案是[直接偏好优化](https://arxiv.org/abs/2305.18290)（DPO）算法，它直接在SFT模型上运行偏好学习。
- en: 'In our case, we will perform SFT, but this raises a question: why does fine-tuning
    work in the first place? As highlighted in the [Orca paper](https://mlabonne.github.io/blog/notes/Large%20Language%20Models/orca.html),
    our understanding is that fine-tuning **leverages knowledge learned during the
    pretraining** process. In other words, fine-tuning will be of little help if the
    model has never seen the kind of data you’re interested in. However, if that’s
    the case, SFT can be extremely performant.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们将执行SFT，但这提出了一个问题：为什么微调在第一时间会有效？正如[Orca论文](https://mlabonne.github.io/blog/notes/Large%20Language%20Models/orca.html)中所强调的，我们的理解是微调**利用了在预训练过程中获得的知识**。换句话说，如果模型从未见过你感兴趣的数据类型，微调将无济于事。然而，如果是这种情况，SFT可以表现得极其优秀。
- en: For example, the [LIMA paper](https://mlabonne.github.io/blog/notes/Large%20Language%20Models/lima.html)
    showed how you could outperform GPT-3 (DaVinci003) by fine-tuning a LLaMA (v1)
    model with 65 billion parameters on only 1,000 high-quality samples. The **quality
    of the instruction dataset is essential** to reach this level of performance,
    which is why a lot of work is focused on this issue (like [evol-instruct](https://arxiv.org/abs/2304.12244),
    Orca, or [phi-1](https://mlabonne.github.io/blog/notes/Large%20Language%20Models/phi1.html)).
    Note that the size of the LLM (65b, not 13b or 7b) is also fundamental to leverage
    pre-existing knowledge efficiently.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，[LIMA论文](https://mlabonne.github.io/blog/notes/Large%20Language%20Models/lima.html)展示了如何通过在仅1,000个高质量样本上微调一个具有65亿参数的LLaMA（v1）模型来超越GPT-3（DaVinci003）。**指令数据集的质量至关重要**，以达到这种性能水平，这就是为什么许多工作集中在这个问题上（如[evol-instruct](https://arxiv.org/abs/2304.12244)、Orca或[phi-1](https://mlabonne.github.io/blog/notes/Large%20Language%20Models/phi1.html)）。请注意，LLM的大小（65b，而不是13b或7b）对有效利用已有知识也是至关重要的。
- en: 'Another important point related to the data quality is the **prompt template**.
    Prompts are comprised of similar elements: system prompt (optional) to guide the
    model, user prompt (required) to give the instruction, additional inputs (optional)
    to take into consideration, and the model’s answer (required). In the case of
    Llama 2, the authors used the following template for the **chat models**:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据质量相关的另一个重要点是**提示模板**。提示由类似的元素组成：用于指导模型的系统提示（可选），用于提供指令的用户提示（必需），需要考虑的额外输入（可选），以及模型的回答（必需）。在Llama
    2的情况下，作者使用了以下**聊天模型**的模板：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There are other templates, like the ones from Alpaca and Vicuna, and their impact
    is not very clear. In this example, we will reformat our instruction dataset to
    follow Llama 2’s template. For the purpose of this tutorial, I’ve already done
    it using the excellent `[timdettmers/openassistant-guanaco](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)`
    dataset. You can find it on Hugging Face under the name `[mlabonne/guanaco-llama2-1k](https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k)`.
    Note that you don’t need to follow a specific prompt template if you’re using
    the base Llama 2 model instead of the chat version.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他模板，比如来自Alpaca和Vicuna的模板，它们的影响还不太明确。在这个例子中，我们将重新格式化我们的指令数据集以符合Llama 2的模板。为了本教程的目的，我已经使用了优秀的`[timdettmers/openassistant-guanaco](https://huggingface.co/datasets/timdettmers/openassistant-guanaco)`数据集。你可以在Hugging
    Face上找到它，名称为`[mlabonne/guanaco-llama2-1k](https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k)`。请注意，如果你使用的是基础版Llama
    2模型而不是聊天版本，你不需要遵循特定的提示模板。
- en: 🦙 How to fine-tune Llama 2
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🦙 如何微调Llama 2
- en: 'In this section, we will fine-tune a Llama 2 model with 7 billion parameters
    on a T4 GPU with high RAM using Google Colab (2.21 credits/hour). Note that a
    T4 only has 16 GB of VRAM, which is barely enough to **store Llama 2–7b’s weights**
    (7b × 2 bytes = 14 GB in FP16). In addition, we need to consider the overhead
    due to optimizer states, gradients, and forward activations (see [this excellent
    article](https://huggingface.co/docs/transformers/perf_train_gpu_one#anatomy-of-models-memory)
    for more information). This means that a full fine-tuning is not possible here:
    we need parameter-efficient fine-tuning (PEFT) techniques like [LoRA](https://arxiv.org/abs/2106.09685)
    or [QLoRA](https://arxiv.org/abs/2305.14314).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Google Colab（2.21信用/小时）在配备高RAM的T4 GPU上微调一个具有70亿参数的Llama 2模型。请注意，T4的VRAM仅为16
    GB，这勉强足够**存储Llama 2–7b的权重**（7b × 2字节 = 14 GB的FP16）。此外，我们还需要考虑优化器状态、梯度和前向激活的开销（有关更多信息，请参见[这篇优秀的文章](https://huggingface.co/docs/transformers/perf_train_gpu_one#anatomy-of-models-memory)）。这意味着在这里进行全面微调是不可能的：我们需要像[LoRA](https://arxiv.org/abs/2106.09685)或[QLoRA](https://arxiv.org/abs/2305.14314)这样的参数高效微调（PEFT）技术。
- en: To drastically reduce the VRAM usage, we must **fine-tune the model in 4-bit
    precision**, which is why we’ll use QLoRA here. The good thing is that we can
    leverage the Hugging Face ecosystem with the `transformers`, `accelerate`, `peft`,
    `trl`, and `bitsandbytes` libraries. We'll do this in the following code based
    on Younes Belkada's [GitHub Gist](https://gist.github.com/younesbelkada/9f7f75c94bdc1981c8ca5cc937d4a4da).
    First, we install and load these libraries.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了大幅减少VRAM使用量，我们必须**用4位精度微调模型**，这就是我们在这里使用QLoRA的原因。好消息是我们可以利用Hugging Face生态系统中的`transformers`、`accelerate`、`peft`、`trl`和`bitsandbytes`库。我们将在以下代码中进行操作，基于Younes
    Belkada的[GitHub Gist](https://gist.github.com/younesbelkada/9f7f75c94bdc1981c8ca5cc937d4a4da)。首先，我们安装并加载这些库。
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s talk a bit about the parameters we can tune here. First, we want to load
    a `llama-2-7b-chat-hf` model (**chat** model) and train it on the `mlabonne/guanaco-llama2-1k`
    (1,000 samples), which will produce our fine-tuned model `llama-2-7b-miniguanaco`.
    If you’re interested in how this dataset was created, you can check [this notebook](https://colab.research.google.com/drive/1Ad7a9zMmkxuXTOh1Z7-rNSICA4dybpM2?usp=sharing).
    Feel free to change it: there are many good datasets on the [Hugging Face Hub](https://huggingface.co/datasets),
    like `[databricks/databricks-dolly-15k](https://huggingface.co/datasets/databricks/databricks-dolly-15k)`.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微讨论一下可以在这里调整的参数。首先，我们希望加载一个`llama-2-7b-chat-hf`模型（**chat** 模型），并在`mlabonne/guanaco-llama2-1k`（1,000
    个样本）上训练它，这将生成我们微调后的模型`llama-2-7b-miniguanaco`。如果你对如何创建这个数据集感兴趣，可以查看[这个笔记本](https://colab.research.google.com/drive/1Ad7a9zMmkxuXTOh1Z7-rNSICA4dybpM2?usp=sharing)。可以随意更改：在[Hugging
    Face Hub](https://huggingface.co/datasets)上有很多好的数据集，比如`[databricks/databricks-dolly-15k](https://huggingface.co/datasets/databricks/databricks-dolly-15k)`。
- en: QLoRA will use a rank of 64 with a scaling parameter of 16 (see [this article](https://rentry.org/llm-training#low-rank-adaptation-lora_1)
    for more information about LoRA parameters). We’ll load the Llama 2 model directly
    in 4-bit precision using the NF4 type and train it for one epoch. To get more
    information about the other parameters, check the [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments),
    [PeftModel](https://huggingface.co/docs/peft/package_reference/peft_model), and
    [SFTTrainer](https://huggingface.co/docs/trl/main/en/sft_trainer) documentation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: QLoRA 将使用 64 的秩和 16 的缩放参数（有关 LoRA 参数的更多信息，请参见[这篇文章](https://rentry.org/llm-training#low-rank-adaptation-lora_1)）。我们将使用
    NF4 类型以 4 位精度直接加载 Llama 2 模型，并训练一个周期。有关其他参数的更多信息，请查看[TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)、[PeftModel](https://huggingface.co/docs/peft/package_reference/peft_model)和[SFTTrainer](https://huggingface.co/docs/trl/main/en/sft_trainer)
    文档。
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can now load everything and start the fine-tuning process. We’re relying
    on multiple wrappers, so bear with me.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以加载所有内容并开始微调过程。我们依赖多个包装器，请耐心等待。
- en: First of all, we want to **load the dataset** we defined. Here, our dataset
    is already preprocessed but, usually, this is where you would reformat the prompt,
    filter out bad text, combine multiple datasets, etc.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们要**加载我们定义的数据集**。在这里，我们的数据集已经过预处理，但通常，这时你会重新格式化提示、筛选掉不良文本、合并多个数据集等。
- en: Then, we’re configuring `bitsandbytes` for 4-bit quantization.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们正在配置 `bitsandbytes` 以进行 4 位量化。
- en: Next, we're loading the Llama 2 model in 4-bit precision on a GPU with the corresponding
    tokenizer.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们正在使用相应的分词器将 Llama 2 模型以 4 位精度加载到 GPU 上。
- en: Finally, we're loading configurations for QLoRA, regular training parameters,
    and passing everything to the `SFTTrainer`. The training can finally start!
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们正在加载 QLoRA 配置、常规训练参数，并将所有内容传递给`SFTTrainer`。训练可以最终开始！
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/7a4459b066e68e7cd3002cd3113c8876.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a4459b066e68e7cd3002cd3113c8876.png)'
- en: Image by author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'The training can be very long, depending on the size of your dataset. Here,
    it took less than an hour on a T4 GPU. We can check the plots on tensorboard,
    as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 训练可能会很长时间，这取决于数据集的大小。在这里，T4 GPU 上花了不到一个小时。我们可以在 tensorboard 上检查图表，如下所示：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/0961e701ded34f0fb82b7c66fcdad85f.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0961e701ded34f0fb82b7c66fcdad85f.png)'
- en: Image by author
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Let’s make sure that the model is behaving correctly. It would require a more
    exhaustive evaluation, but we can use the **text generation pipeline** to ask
    questions like “What is a large language model?” Note that I’m formatting the
    input to match Llama 2’s prompt template.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确保模型行为正确。这需要更全面的评估，但我们可以使用**文本生成管道**来提出诸如“什么是大语言模型？”这样的问题。请注意，我正在格式化输入以匹配
    Llama 2 的提示模板。
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The model outputs the following response:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 模型输出了以下响应：
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: From experience, it is **very coherent** for a model with only 7 billion parameters.
    You can play with it and ask harder questions from evaluation datasets like [BigBench-Hard](https://github.com/suzgunmirac/BIG-Bench-Hard).
    Guanaco is an excellent dataset that has produced high-quality models in the past.
    You can train a Llama 2 model on the entire dataset using `[mlabonne/guanaco-llama2](https://huggingface.co/datasets/mlabonne/guanaco-llama2)`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 根据经验，对于只有 70 亿参数的模型来说，它**非常一致**。你可以尝试使用评估数据集中的更难问题，如[BigBench-Hard](https://github.com/suzgunmirac/BIG-Bench-Hard)。Guanaco
    是一个优秀的数据集，以前生产过高质量的模型。你可以使用`[mlabonne/guanaco-llama2](https://huggingface.co/datasets/mlabonne/guanaco-llama2)`在整个数据集上训练
    Llama 2 模型。
- en: 'How can we store our new `llama-2-7b-miniguanaco` model now? We need to merge
    the weights from LoRA with the base model. Unfortunately, as far as I know, there
    is no straightforward way to do it: we need to reload the base model in FP16 precision
    and use the `peft` library to merge everything. Alas, it also creates a problem
    with the VRAM (despite emptying it), so I recommend **restarting the notebook**,
    re-executing the three first cells, and then executing the next one. Please contact
    me if you know a fix!'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们如何存储我们新的 `llama-2-7b-miniguanaco` 模型？我们需要将 LoRA 的权重与基础模型合并。不幸的是，据我所知，没有简单的方法来做到这一点：我们需要以
    FP16 精度重新加载基础模型，并使用 `peft` 库来合并所有内容。可惜的是，这也会引发 VRAM 的问题（尽管已经清空），所以我建议**重启笔记本**，重新执行前三个单元格，然后执行下一个单元格。如果你知道解决办法，请联系我！
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Our weights are merged and we reloaded the tokenizer. We can now push everything
    to the Hugging Face Hub to save our model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的权重已合并并重新加载了分词器。现在我们可以将所有内容推送到 Hugging Face Hub 以保存我们的模型。
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can now use this model for inference by loading it like any other Llama
    2 model from the Hub. It is also possible to reload it for more fine-tuning —
    perhaps with another dataset?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以像加载 Hub 上的其他 Llama 2 模型一样使用这个模型进行推理。也可以重新加载它以进行更多的微调——也许用另一个数据集？
- en: If you’re serious about fine-tuning models, **using a script** instead of a
    notebook is recommended. You can easily rent GPUs on Lambda Labs, Runpod, Vast.ai,
    for less than 0.3$/h. Once you’re connected, you can install libraries, import
    your script, log in to Hugging Face and other tools (like Weights & Biases for
    logging your experiments), and start your fine-tuning.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认真考虑微调模型，建议**使用脚本**而不是笔记本。你可以在 Lambda Labs、Runpod、Vast.ai 上以低于 0.3$/小时的价格轻松租用
    GPU。一旦连接，你可以安装库、导入脚本、登录 Hugging Face 和其他工具（如 Weights & Biases 用于记录实验），然后开始微调。
- en: The `trl` script is currently very limited, so I made my own based on the previous
    notebook. You can [**find it here on GitHub Gist**](https://gist.github.com/mlabonne/8eb9ad60c6340cb48a17385c68e3b1a5).
    If you’re looking for a comprehensive solution, check out [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)
    from the OpenAccess AI Collective, which also natively handles multiple datasets,
    Deepspeed, Flash Attention, etc.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`trl` 脚本目前非常有限，因此我基于之前的笔记本制作了自己的版本。你可以在[**GitHub Gist 上找到它**](https://gist.github.com/mlabonne/8eb9ad60c6340cb48a17385c68e3b1a5)。如果你在寻找全面的解决方案，可以查看来自
    OpenAccess AI Collective 的 [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)，它也原生支持多个数据集、Deepspeed、Flash
    Attention 等。'
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we saw how to fine-tune a Llama 2 7b model using a Colab notebook.
    We introduced some necessary background on LLM training and fine-tuning, as well
    as important considerations related to instruction datasets. In the second section,
    we **successfully fine-tuned the Llama 2 model** with its native prompt template
    and custom parameters.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们展示了如何使用 Colab 笔记本对 Llama 2 7b 模型进行微调。我们介绍了一些 LLM 训练和微调的必要背景，以及与指令数据集相关的重要考虑因素。在第二部分，我们**成功地微调了
    Llama 2 模型**，使用了其原生提示模板和自定义参数。
- en: These fine-tuned models can then be integrated into LangChain and other architectures
    as advantageous alternatives to the OpenAI API. Remember, in this new paradigm,
    instruction datasets are the new gold, and the quality of your model heavily depends
    on the data on which it’s been fine-tuned. So, good luck with building high-quality
    datasets!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些微调后的模型可以集成到 LangChain 和其他架构中，作为 OpenAI API 的有利替代方案。记住，在这个新范式中，指令数据集是新的黄金，你的模型的质量在很大程度上取决于其微调的数据。因此，祝你构建高质量数据集好运！
- en: If you’re interested in more content about LLMs, follow me on Twitter [@maximelabonne](https://twitter.com/maximelabonne).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对更多关于 LLM 的内容感兴趣，可以在 Twitter 上关注我 [@maximelabonne](https://twitter.com/maximelabonne)。
- en: References
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'Hugo Touvron, Thomas Scialom, et al. (2023). [Llama 2: Open Foundation and
    Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hugo Touvron, Thomas Scialom 等人（2023年）。[Llama 2: Open Foundation and Fine-Tuned
    Chat Models](https://arxiv.org/abs/2307.09288)。'
- en: Philipp Schmid, Omar Sanseviero, Pedro Cuenca, & Lewis Tunstall. Llama 2 is
    here — get it on Hugging Face. [https://huggingface.co/blog/llama2](https://huggingface.co/blog/llama2)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Philipp Schmid, Omar Sanseviero, Pedro Cuenca, & Lewis Tunstall. Llama 2 已上线——在
    Hugging Face 上获取它。 [https://huggingface.co/blog/llama2](https://huggingface.co/blog/llama2)
- en: 'Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
    Guestrin, Percy Liang, & Tatsunori B. Hashimoto. (2023). [Stanford Alpaca: An
    Instruction-following LLaMA model](https://crfm.stanford.edu/2023/03/13/alpaca.html).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 罗汉·塔奥里、伊莎恩·古尔拉贾尼、张天艺、扬·杜布瓦、李雪辰、卡洛斯·盖斯特林、珀西·梁及辰野博。 (2023). [斯坦福阿尔帕卡：一种遵循指令的LLaMA模型](https://crfm.stanford.edu/2023/03/13/alpaca.html)。
- en: 'Jacob Devlin, Ming-Wei Chang, Kenton Lee, & Kristina Toutanova. (2019). [BERT:
    Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雅各布·德夫林、明伟·张、肯顿·李及克里斯蒂娜·托特诺娃。 (2019). [BERT：用于语言理解的深度双向变换器的预训练](https://arxiv.org/abs/1810.04805)。
- en: 'Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, & Luke Zettlemoyer. (2023). [QLoRA:
    Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提姆·德特默斯、阿尔蒂多罗·帕尼奥尼、阿里·霍尔茨曼及卢克·泽特尔摩耶。 (2023). [QLoRA：高效微调量化 LLM](https://arxiv.org/abs/2305.14314)。
- en: Related articles
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关文章
- en: '[](/4-bit-quantization-with-gptq-36b0f4f02c34?source=post_page-----df9823a04a32--------------------------------)
    [## 4-bit Quantization with GPTQ'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/4-bit-quantization-with-gptq-36b0f4f02c34?source=post_page-----df9823a04a32--------------------------------)
    [## 使用 GPTQ 进行 4 位量化'
- en: Quantize your own LLMs using AutoGPTQ
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 AutoGPTQ 对自己的 LLM 进行量化
- en: towardsdatascience.com](/4-bit-quantization-with-gptq-36b0f4f02c34?source=post_page-----df9823a04a32--------------------------------)
    [](/decoding-strategies-in-large-language-models-9733a8f70539?source=post_page-----df9823a04a32--------------------------------)
    [## Decoding Strategies in Large Language Models
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/4-bit-quantization-with-gptq-36b0f4f02c34?source=post_page-----df9823a04a32--------------------------------)
    [](/decoding-strategies-in-large-language-models-9733a8f70539?source=post_page-----df9823a04a32--------------------------------)
    [## 大型语言模型中的解码策略
- en: A Guide to Text Generation From Beam Search to Nucleus Sampling
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从束搜索到核采样的文本生成指南
- en: towardsdatascience.com](/decoding-strategies-in-large-language-models-9733a8f70539?source=post_page-----df9823a04a32--------------------------------)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/decoding-strategies-in-large-language-models-9733a8f70539?source=post_page-----df9823a04a32--------------------------------)
- en: '*Learn more about machine learning and support my work with one click — become
    a Medium member here:*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*了解更多机器学习知识，并通过点击支持我的工作——成为 Medium 会员：*'
- en: '[](https://medium.com/@mlabonne/membership?source=post_page-----df9823a04a32--------------------------------)
    [## Join Medium with my referral link - Maxime Labonne'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mlabonne/membership?source=post_page-----df9823a04a32--------------------------------)
    [## 通过我的推荐链接加入 Medium - Maxime Labonne'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为 Medium 会员，你的会员费的一部分会支持你阅读的作者，同时你可以全面访问每一个故事……
- en: medium.com](https://medium.com/@mlabonne/membership?source=post_page-----df9823a04a32--------------------------------)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@mlabonne/membership?source=post_page-----df9823a04a32--------------------------------)
- en: '*If you’re already a member, you can* [*follow me on Medium*](https://medium.com/@mlabonne)*.*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你已经是会员，你可以* [*在 Medium 上关注我*](https://medium.com/@mlabonne)*。*'
