- en: 'Class Imbalance and Resampling: A Formal Introduction'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类别不平衡与重采样：正式介绍
- en: 原文：[https://towardsdatascience.com/class-imbalance-and-oversampling-a-formal-introduction-c77b918e586d?source=collection_archive---------12-----------------------#2023-10-07](https://towardsdatascience.com/class-imbalance-and-oversampling-a-formal-introduction-c77b918e586d?source=collection_archive---------12-----------------------#2023-10-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/class-imbalance-and-oversampling-a-formal-introduction-c77b918e586d?source=collection_archive---------12-----------------------#2023-10-07](https://towardsdatascience.com/class-imbalance-and-oversampling-a-formal-introduction-c77b918e586d?source=collection_archive---------12-----------------------#2023-10-07)
- en: Let’s explore the class imbalance problem and how resampling methods such as
    random oversampling attempt to solve it.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们深入探讨类别不平衡问题，以及诸如随机过采样等重采样方法如何尝试解决这一问题。
- en: '[](https://essamwissam.medium.com/?source=post_page-----c77b918e586d--------------------------------)[![Essam
    Wisam](../Images/6320ce88ba2e5d56d70ce3e0f97ceb1d.png)](https://essamwissam.medium.com/?source=post_page-----c77b918e586d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c77b918e586d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c77b918e586d--------------------------------)
    [Essam Wisam](https://essamwissam.medium.com/?source=post_page-----c77b918e586d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://essamwissam.medium.com/?source=post_page-----c77b918e586d--------------------------------)[![Essam
    Wisam](../Images/6320ce88ba2e5d56d70ce3e0f97ceb1d.png)](https://essamwissam.medium.com/?source=post_page-----c77b918e586d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c77b918e586d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c77b918e586d--------------------------------)
    [Essam Wisam](https://essamwissam.medium.com/?source=post_page-----c77b918e586d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccb82b9f3b87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-and-oversampling-a-formal-introduction-c77b918e586d&user=Essam+Wisam&userId=ccb82b9f3b87&source=post_page-ccb82b9f3b87----c77b918e586d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c77b918e586d--------------------------------)
    ·6 min read·Oct 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc77b918e586d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-and-oversampling-a-formal-introduction-c77b918e586d&user=Essam+Wisam&userId=ccb82b9f3b87&source=-----c77b918e586d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccb82b9f3b87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-and-oversampling-a-formal-introduction-c77b918e586d&user=Essam+Wisam&userId=ccb82b9f3b87&source=post_page-ccb82b9f3b87----c77b918e586d---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c77b918e586d--------------------------------)
    ·6 分钟阅读·2023年10月7日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc77b918e586d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-and-oversampling-a-formal-introduction-c77b918e586d&user=Essam+Wisam&userId=ccb82b9f3b87&source=-----c77b918e586d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc77b918e586d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-and-oversampling-a-formal-introduction-c77b918e586d&source=-----c77b918e586d---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc77b918e586d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fclass-imbalance-and-oversampling-a-formal-introduction-c77b918e586d&source=-----c77b918e586d---------------------bookmark_footer-----------)'
- en: Lately, I have been building a package to address class imbalance in Julia called
    [Imbalance.jl](https://github.com/JuliaAI/Imbalance.jl). It took me a lot of effort
    in terms of reading papers and looking at implementations while building the package
    so I thought it may be helpful to share what I’ve learned about the class imbalance
    problem in general, along with some of the most popular algorithms used to tackle
    it. This includes Naive Random Oversampling, Random Oversampling Examples (ROSE),
    random walk oversampling (RWO), Synthetic Minority Oversampling Technique (SMOTE),
    SMOTE-Nominal, and SMOTE-Nominal Continuous and many undersampling approaches.
    For this story, we will formally define the class imbalance problem and discuss
    how random oversampling is a valid solution. In later articles, we will rationally
    arrive at more solutions for it by considering other techniques.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我在构建一个名为[Imbalance.jl](https://github.com/JuliaAI/Imbalance.jl)的Julia包来解决类别不平衡问题。在构建该包时，我花费了大量的精力阅读论文和查看实现，因此我认为分享我对类别不平衡问题的理解以及一些用于解决该问题的流行算法可能会有所帮助。这些算法包括朴素随机过采样、随机过采样示例（ROSE）、随机游走过采样（RWO）、合成少数类过采样技术（SMOTE）、SMOTE-名义型、SMOTE-名义型连续以及许多欠采样方法。对于这个故事，我们将正式定义类别不平衡问题，并讨论随机过采样作为有效解决方案。在后续文章中，我们将通过考虑其他技术理性地得出更多的解决方案。
- en: Table of Contents
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: ∘ [The Class Imbalance Problem](#c801)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [类别不平衡问题](#c801)
- en: ∘ [Solving the Class Imbalance Problem](#425a)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [解决类别不平衡问题](#425a)
- en: ∘ [Random Oversampling](#bac7)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [随机过采样](#bac7)
- en: ∘ [Why Oversampling?](#fa3c)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [为什么要过采样？](#fa3c)
- en: ∘ [Undersampling](#8ebe)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [欠采样](#8ebe)
- en: '![](../Images/f6e5f9e8d6f67dd7bb40b63d875b143a.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6e5f9e8d6f67dd7bb40b63d875b143a.png)'
- en: Photo by [Artem Kniaz](https://unsplash.com/@artem_kniaz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Artem Kniaz](https://unsplash.com/@artem_kniaz?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供
- en: The Class Imbalance Problem
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类别不平衡问题
- en: 'Most if not all machine learning algorithms can be viewed as a form of empirical
    risk minimization where the objective is to find the parameters θ that for some
    loss function *L* minimize:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数（如果不是全部）机器学习算法可以被视为经验风险最小化的一种形式，其中目标是找到参数θ，使得某些损失函数*L*最小化：
- en: '![](../Images/d0d8a2bc15d20e758f02c4b1d36946b4.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d0d8a2bc15d20e758f02c4b1d36946b4.png)'
- en: For instance, linear regression takes *L* to be squared loss, logistic regression
    takes it to be cross-entropy loss, SVM takes it to be hinge loss, Adaptive boosting
    takes it to be exponential loss.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，线性回归将*L*定义为平方损失，逻辑回归将其定义为交叉熵损失，SVM将其定义为铰链损失，自适应提升将其定义为指数损失。
- en: The underlying assumption is that if the parameters of *f_θ* allow it to minimize
    this empirical risk over the dataset which may be viewed as a random sample from
    the population then it should be close enough to the target function *f* that
    we seek the model which minimizes the same quantity over the dataset and moreover
    the whole population.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 基本假设是，如果*f_θ*的参数允许它在数据集上最小化该经验风险，而数据集可以视为从总体中随机抽取的样本，那么它应该足够接近我们寻求的目标函数*f*，我们寻找的模型是使数据集以及整个总体上的相同量最小化。
- en: In a multi-class setting with K classes, we can write the empirical risk as
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有K个类别的多类别设置中，我们可以将经验风险写作
- en: '![](../Images/3d4322a630bee958b0694cf37dd3e735.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d4322a630bee958b0694cf37dd3e735.png)'
- en: Class imbalance occurs when some classes have much fewer examples than other
    classes. In this case, the terms corresponding to such classes contribute minimally
    to the sum which makes it possible for any learning algorithm to find an approximate
    solution to minimizing the empirical risk that mostly only minimizes it over the
    significant sums. This yields a hypothesis *f_θ* that may be very different from
    the true target *f* with respect to the minority classes which may be the most
    important for the application in question.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当一些类别的样本远少于其他类别时，就会发生类别不平衡问题。在这种情况下，对应于这些类别的术语对总和的贡献最小，这使得任何学习算法都可能找到一个近似解来最小化经验风险，而这个解主要只在显著的和上进行最小化。这会产生一个可能与真实目标*f*相差很大的假设*f_θ*，而这些少数类可能是所讨论应用中最重要的。
- en: 'Conclusively, the following are the conditions where we have a class imbalance
    problem:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，以下是我们有类别不平衡问题的条件：
- en: 1 — The points in the training set are not distributed “fairly” among the classes;
    some classes have far less points belonging to them than others.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 1 — 训练集中点在各个类别之间的分布并不“公平”；某些类别的点远少于其他类别。
- en: 2 — The model does not perform well on points belonging to such minority classes
    after training. That is, the learning algorithm has not minimized the loss appropriately
    for the minority classes as explained above.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 2 — 模型在训练后对这些少数类别的点表现不佳。也就是说，学习算法没有像上面解释的那样适当地最小化少数类别的损失。
- en: The degree to which this problem is adverse depends on how important such minority
    classes are for the application. Most often they are much more important than
    the majority class (e.g., classifying fraudulent transactions or rare diseases).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的严重程度取决于这些少数类别对应用程序的重要性。它们往往比多数类别更重要（例如，分类欺诈交易或稀有疾病）。
- en: Solving the Class Imbalance Problem
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决类别不平衡问题
- en: It becomes obvious from the description of the problem that one remedy is to
    weight the smaller sums (i.e., those belonging to minority classes) so that a
    learning algorithm more easily avoids approximate solutions that exploit their
    insignificance. It’s often easily possible to modify machine learning algorithms
    for that purpose; especially when they are explicitly a form of empirical risk
    minimization and is not just equivalent to it for some loss function.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 从问题的描述中很明显，一个解决办法是给较小的类别（即少数类别）加权，以便学习算法更容易避免利用它们的不重要性来获得近似解。通常可以很容易地为此目的修改机器学习算法；特别是当它们明确是经验风险最小化的一种形式，而不仅仅是对于某些损失函数的等效形式时。
- en: 'Another approach that attempts to solve the problem without requiring any modifications
    to the learning algorithm is resampling the data. In its simplest form it can
    be viewed as equivalent to the cost-sensitive approach of assigning weights. Consider
    the following algorithm:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种试图解决问题而不需要对学习算法进行任何修改的方法是重新采样数据。最简单的形式可以看作是赋权的成本敏感方法。考虑以下算法：
- en: '**Given:** An imbalanced dataset with K classes and an integer for each class'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**给定：** 一个不平衡的数据集，包含K个类别和每个类别的整数'
- en: '**Wanted:** A dataset where data from each class is replicated according to
    the integer'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**需求：** 一个数据集，其中每个类别的数据根据整数进行复制'
- en: '**Operation:** Repeat each point in class k, c times, where c is the associated
    integer with that class'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作：** 将类别k中的每个点重复c次，其中c是与该类别相关的整数'
- en: It should be obvious by plugging to the sum that this is equivalent to the cost-sensitive
    approach; recall that minimizing a function is equivalent to minimizing a scalar
    positive multiple of it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 插入总和时应该很明显，这相当于成本敏感方法；回想一下，最小化一个函数等同于最小化它的标量正倍数。
- en: Random Oversampling
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机过采样
- en: The aforementioned algorithm suffers from a small problem; if class A has 900
    examples and class B has 600 examples then there is no integer multiple that we
    can use to oversample class B to bring the dataset to exact balance. We can extend
    the algorithm to deal with replication ratios that aren’t integers by choosing
    points to replicate randomly. For instance, if we want to oversample 300 examples
    for class B so that the system is brought to balance (equivalent to a ratio of
    1.5) then we can do so by…
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 上述算法存在一个小问题；如果类别A有900个示例，而类别B有600个示例，则没有整数倍数可以用来过采样类别B，使数据集达到完全平衡。我们可以通过随机选择点进行复制，扩展算法以处理非整数的复制比例。例如，如果我们想对类别B进行300个示例的过采样，以使系统达到平衡（相当于比例为1.5），我们可以通过...
- en: 1 — Choosing 300 points randomly from class B
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 1 — 从类别B中随机选择300个点
- en: 2 — Replicating those points
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 2 — 复制这些点
- en: 'This algorithm is called naive random oversampling and what it formally does
    is:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法称为朴素随机过采样，它正式的做法是：
- en: 1 — Compute the necessary number of points to generate for each class (computed
    from some given ratios)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 1 — 计算每个类别所需生成的点数（根据给定的比例计算）
- en: 2 — Suppose for class k that number is *N_k*, then choose *N_k* points randomly
    with replacement from the points belonging to that class then add them to form
    the new dataset
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 2 — 假设对于类别k，这个数字是*N_k*，然后从属于该类别的点中随机选择*N_k*个点，并将它们添加以形成新的数据集
- en: It should be obvious that this is on average equivalent to the aforementioned
    algorithm and hence, also class-weighting. If the ratio for class k is 2.0 then
    on average each point will be picked once by random.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这在平均上等同于前述算法，因此也等同于类别权重。如果类别k的比例为2.0，则每个点平均会被随机选择一次。
- en: Here is a random imbalanced dataset that I have generated for three classes
    (0, 1, 2) which shows a histogram of the classes and a scatter plot of the points
    before and after oversampling.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我为三个类别（0、1、2）生成的随机不平衡数据集，展示了类别的直方图以及过采样前后的点的散点图。
- en: '![](../Images/1e64ac6158a9431b3104391846e8de6d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e64ac6158a9431b3104391846e8de6d.png)'
- en: Figure by the Author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图
- en: Notice that there is no visual difference in the two figures in the bottom because
    all generated points are replicas of existing ones.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，下方的两个图形没有视觉上的差异，因为所有生成的点都是现有点的复制品。
- en: Why Oversampling?
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要过采样？
- en: You may be so far not so convinced that resampling is more prominent than class-weight
    to solve the class imbalance problem; after all, we have shown that naive random
    oversampling can be viewed to be on average equivalent to class-weighting with
    longer training times (due to more data). The only catch in this argument is that
    it’s not generally possible to use class-weighting; especially, if the machine
    learning model does not minimize loss explicitly.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还不太相信重新采样比类别权重在解决类别不平衡问题上更为突出；毕竟，我们已经展示了，朴素的随机过采样可以看作是平均上等同于类别权重的，只是训练时间更长（由于数据量增加）。这个论点唯一的问题是，一般情况下不可能使用类别权重；尤其是，当机器学习模型没有明确最小化损失时。
- en: It makes sense that we would achieve better results than naive random oversampling
    (or class weighting) if we rather naturally added the points for each class by
    collecting more data in our dataset. For instance, suppose that…
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们通过在数据集中自然地添加每个类别的点来收集更多数据，那么我们获得比朴素随机过采样（或类别权重）更好的结果是有道理的。例如，假设……
- en: We want to detect whether a transaction is fraud
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望检测一个交易是否为欺诈交易。
- en: We have collected a dataset of 1K fraud transactions and 999K of valid transactions
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们收集了一个包含1K欺诈交易和999K有效交易的数据集。
- en: It should be obvious that solving the imbalance problem by collecting another
    998K fraud transactions is far more superior than repeating the existing 1K ones
    997K times. In particular, we run a high risk of overfitting to the particular
    data observed in the latter case.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，通过收集另外998K欺诈交易来解决不平衡问题比重复现有的1K交易997K次要好得多。特别是，在后者情况下，我们有很高的过拟合特定数据的风险。
- en: The reality is obviously that it is not generally feasible to collect more data
    for the minority classes; however, it may be possible to simulate the effect of
    doing so. Perhaps, if we synthetically generate data for the minority classes
    that is representative enough of real new examples then ideally, this is much
    better than repeating examples or class weighting. This is the most common form
    of oversampling and its relation to collecting real data may be the most plausible
    justification for why it can outperform random oversampling and class weighting;
    hence, being a worthwhile approach to solve the class imbalance problem.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现实显然是，通常情况下不可能为少数类收集更多数据；然而，可能可以模拟这样做的效果。也许，如果我们合成生成的数据对于少数类足够代表真实的新例子，那么理想情况下，这比重复例子或类别权重要好得多。这是最常见的过采样形式，其与收集真实数据的关系可能是其优于随机过采样和类别权重的最合理理由；因此，成为解决类别不平衡问题的值得方法。
- en: Undersampling
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 欠采样
- en: Lastly note that if instead of randomly choosing examples to replicate in minority
    classes, we randomly chose points to remove in majority classes then then the
    algorithm becomes naive random undersampling. This obviously has the disadvantage
    of losing useful data but sometimes eliminating data from “not so useful” majority
    classes solves the imbalance problem and leads to much better performance towards
    the “much more useful” minority classes. There are also other undersampling approaches
    that more carefully choose which points to exclude such as to preserve the structure
    of the data or to allow for better decision boundaries.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最后请注意，如果我们不是随机选择少数类中的例子来复制，而是随机选择多数类中的点进行删除，那么算法变成了朴素随机欠采样。这显然有丧失有用数据的缺点，但有时从“不是特别有用”的多数类中删除数据可以解决不平衡问题，并导致在“更有用”的少数类上的表现更好。还有其他欠采样方法，可以更仔细地选择排除哪些点，例如为了保持数据结构或允许更好的决策边界。
- en: In [further stories](https://medium.com/towards-data-science/class-imbalance-from-random-oversampling-to-rose-517e06d7a9b)
    we explain all the algorithms initially implemented in [Imbalance.jl](https://github.com/JuliaAI/Imbalance.jl)
    and how they solve the class imbalance problem.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在[进一步的故事](https://medium.com/towards-data-science/class-imbalance-from-random-oversampling-to-rose-517e06d7a9b)中，我们解释了最初在[Imbalance.jl](https://github.com/JuliaAI/Imbalance.jl)中实现的所有算法及其如何解决类别不平衡问题。
