- en: A beginnerâ€™s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»é›¶å¼€å§‹æ„å»ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åº”ç”¨ç¨‹åºçš„åˆå­¦è€…æŒ‡å—
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02](https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02](https://towardsdatascience.com/a-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d?source=collection_archive---------1-----------------------#2023-11-02)
- en: Learn critical knowledge for building AI apps, in plain english
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€å­¦ä¹ æ„å»ºAIåº”ç”¨ç¨‹åºçš„å…³é”®çŸ¥è¯†
- en: '[](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[![Bill
    Chambers](../Images/d04ba934f4cbfdf5fcb42f0b65ac0352.png)](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    [Bill Chambers](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[![Bill
    Chambers](../Images/d04ba934f4cbfdf5fcb42f0b65ac0352.png)](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    [Bill Chambers](https://medium.com/@wachambers?source=post_page-----e52921953a5d--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9627ead2f75f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=post_page-9627ead2f75f----e52921953a5d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    Â·10 min readÂ·Nov 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=-----e52921953a5d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9627ead2f75f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=post_page-9627ead2f75f----e52921953a5d---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e52921953a5d--------------------------------)
    Â·10åˆ†é’Ÿé˜…è¯»Â·2023å¹´11æœˆ2æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&user=Bill+Chambers&userId=9627ead2f75f&source=-----e52921953a5d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&source=-----e52921953a5d---------------------bookmark_footer-----------)![](../Images/937f7d4c1dde1fb4928a29cd60f74320.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe52921953a5d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-a-retrieval-augmented-generation-rag-application-from-scratch-e52921953a5d&source=-----e52921953a5d---------------------bookmark_footer-----------)![](../Images/937f7d4c1dde1fb4928a29cd60f74320.png)'
- en: A beginnerâ€™s guide to building a Retrieval Augmented Generation (RAG) application
    from scratch
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»é›¶å¼€å§‹æ„å»ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åº”ç”¨ç¨‹åºçš„åˆå­¦è€…æŒ‡å—
- en: Retrieval Augmented Generation, or RAG, is all the rage these days because it
    introduces some serious capabilities to large language models like OpenAIâ€™s GPT-4
    â€” and thatâ€™s the ability to use and leverage their own data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç›®å‰éå¸¸æµè¡Œï¼Œå› ä¸ºå®ƒä¸ºåƒOpenAIçš„GPT-4è¿™æ ·çš„è¯­è¨€æ¨¡å‹å¼•å…¥äº†ä¸€äº›å¼ºå¤§çš„åŠŸèƒ½â€”â€”å³åˆ©ç”¨å’Œåˆ©ç”¨è‡ªèº«æ•°æ®çš„èƒ½åŠ›ã€‚
- en: This post will teach you the fundamental intuition behind RAG while providing
    a simple tutorial to help you get started.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡å°†æ•™ä½ RAGçš„åŸºæœ¬ç›´è§‰ï¼Œå¹¶æä¾›ä¸€ä¸ªç®€å•çš„æ•™ç¨‹å¸®åŠ©ä½ å…¥é—¨ã€‚
- en: The problem with learning in a fast moving space
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨å¿«é€Ÿå˜åŒ–çš„é¢†åŸŸä¸­å­¦ä¹ çš„é—®é¢˜
- en: Thereâ€™s so much noise in the AI space and in particular about RAG. Vendors are
    trying to overcomplicate it. Theyâ€™re trying to inject their tools, their ecosystems,
    their vision.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: AIé¢†åŸŸæœ‰å¤ªå¤šå™ªéŸ³ï¼Œç‰¹åˆ«æ˜¯å…³äºRAGçš„å™ªéŸ³ã€‚ä¾›åº”å•†ä»¬è¯•å›¾ä½¿å…¶è¿‡äºå¤æ‚ã€‚ä»–ä»¬è¯•å›¾æ³¨å…¥ä»–ä»¬çš„å·¥å…·ã€ç”Ÿæ€ç³»ç»Ÿå’Œæ„¿æ™¯ã€‚
- en: Itâ€™s making RAG way more complicated than it needs to be. This tutorial is designed
    to help beginners learn how to build RAG applications from scratch. No fluff,
    no (ok, minimal) jargon, no libraries, just a simple step by step RAG application.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—RAGå˜å¾—æ¯”å®é™…éœ€è¦çš„å¤æ‚å¾—å¤šã€‚è¿™ä¸ªæ•™ç¨‹æ—¨åœ¨å¸®åŠ©åˆå­¦è€…ä»é›¶å¼€å§‹å­¦ä¹ å¦‚ä½•æ„å»ºRAGåº”ç”¨ç¨‹åºã€‚ä¸åŒ…å«å†—ä½™å†…å®¹ï¼Œä¸ä½¿ç”¨æœ¯è¯­ï¼ˆå¥½å§ï¼Œå°½é‡å°‘ç”¨ï¼‰ï¼Œä¸ä¾èµ–åº“ï¼Œåªæ˜¯ä¸€ä¸ªç®€å•çš„é€æ­¥RAGåº”ç”¨ç¨‹åºã€‚
- en: '[Jerry from LlamaIndex advocates for building things from scratch to really
    understand the pieces](https://twitter.com/jerryjliu0/status/1716122650836439478).
    Once you do, using a library like LlamaIndex makes more sense.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[LlamaIndexçš„Jerryæå€¡ä»é›¶å¼€å§‹æ„å»ºäº‹ç‰©ä»¥çœŸæ­£ç†è§£å„ä¸ªéƒ¨åˆ†](https://twitter.com/jerryjliu0/status/1716122650836439478)ã€‚ä¸€æ—¦ä½ åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½¿ç”¨åƒLlamaIndexè¿™æ ·çš„åº“å°±æ›´æœ‰æ„ä¹‰äº†ã€‚'
- en: Build from scratch to learn, then build with libraries to scale.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é›¶å¼€å§‹å­¦ä¹ ï¼Œç„¶åç”¨åº“è¿›è¡Œæ‰©å±•ã€‚
- en: Letâ€™s get started!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: 'Introducing our concept: Retrieval Augmented Generation'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»æˆ‘ä»¬çš„æ¦‚å¿µï¼šæ£€ç´¢å¢å¼ºç”Ÿæˆ
- en: You may or may not have heard of Retrieval Augmented Generation or RAG.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½å¬è¯´è¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ï¼Œä¹Ÿå¯èƒ½æ²¡æœ‰ã€‚
- en: 'Hereâ€™s the definition from [the blog post introducing the concept from Facebook](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯[Facebookä»‹ç»è¿™ä¸ªæ¦‚å¿µçš„åšå®¢æ–‡ç« ](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/)ä¸­çš„å®šä¹‰ï¼š
- en: '*Building a model that researches and contextualizes is more challenging, but
    itâ€™s essential for future advancements. We recently made substantial progress
    in this realm with our Retrieval Augmented Generation (RAG) architecture, an end-to-end
    differentiable model that combines an information retrieval component (Facebook
    AIâ€™s dense-passage retrieval system) with a seq2seq generator (our Bidirectional
    and Auto-Regressive Transformers [BART] model). RAG can be fine-tuned on knowledge-intensive
    downstream tasks to achieve state-of-the-art results compared with even the largest
    pretrained seq2seq language models. And unlike these pretrained models, RAGâ€™s
    internal knowledge can be easily altered or even supplemented on the fly, enabling
    researchers and engineers to control what RAG knows and doesnâ€™t know without wasting
    time or compute power retraining the entire model.*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æ„å»ºä¸€ä¸ªèƒ½å¤Ÿç ”ç©¶å’Œä¸Šä¸‹æ–‡åŒ–çš„æ¨¡å‹æ›´å…·æŒ‘æˆ˜æ€§ï¼Œä½†è¿™æ˜¯æœªæ¥å‘å±•çš„å…³é”®ã€‚æˆ‘ä»¬æœ€è¿‘åœ¨è¿™ä¸€é¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ï¼Œæ¨å‡ºäº†æˆ‘ä»¬çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¶æ„ï¼Œè¿™æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„å¯å¾®æ¨¡å‹ï¼Œå°†ä¿¡æ¯æ£€ç´¢ç»„ä»¶ï¼ˆFacebook
    AIçš„å¯†é›†æ®µè½æ£€ç´¢ç³»ç»Ÿï¼‰ä¸seq2seqç”Ÿæˆå™¨ï¼ˆæˆ‘ä»¬çš„åŒå‘è‡ªå›å½’å˜æ¢å™¨[BART]æ¨¡å‹ï¼‰ç›¸ç»“åˆã€‚RAGå¯ä»¥åœ¨çŸ¥è¯†å¯†é›†å‹çš„ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä¸å³ä½¿æ˜¯æœ€å¤§çš„é¢„è®­ç»ƒseq2seqè¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼Œèƒ½å¤Ÿè¾¾åˆ°æœ€å…ˆè¿›çš„ç»“æœã€‚è€Œä¸”ï¼Œä¸è¿™äº›é¢„è®­ç»ƒæ¨¡å‹ä¸åŒï¼ŒRAGçš„å†…éƒ¨çŸ¥è¯†å¯ä»¥éšæ—¶è½»æ¾æ›´æ”¹æˆ–è¡¥å……ï¼Œä½¿ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆèƒ½å¤Ÿæ§åˆ¶RAGçŸ¥é“å’Œä¸çŸ¥é“çš„å†…å®¹ï¼Œè€Œæ— éœ€æµªè´¹æ—¶é—´æˆ–è®¡ç®—èƒ½åŠ›é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚*'
- en: Wow, thatâ€™s a mouthful.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å“‡ï¼ŒçœŸæ˜¯å¤ªå¤æ‚äº†ã€‚
- en: 'In simplifying the technique for beginners, we can state that the essence of
    RAG involves adding your own data (via a retrieval tool) to the prompt that you
    pass into a large language model. As a result, you get an output. That gives you
    several benefits:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€åŒ–æŠ€æœ¯å¯¹åˆå­¦è€…ï¼Œæˆ‘ä»¬å¯ä»¥è¯´RAGçš„æœ¬è´¨æ˜¯å°†ä½ è‡ªå·±çš„æ•°æ®ï¼ˆé€šè¿‡æ£€ç´¢å·¥å…·ï¼‰æ·»åŠ åˆ°ä½ ä¼ é€’ç»™å¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºä¸­ã€‚è¿™æ ·ï¼Œä½ å°†è·å¾—ä¸€ä¸ªè¾“å‡ºã€‚è¿™å¸¦æ¥äº†å‡ ä¸ªå¥½å¤„ï¼š
- en: You can include facts in the prompt to help the LLM avoid hallucinations
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨æç¤ºä¸­åŒ…å«äº‹å®ï¼Œä»¥å¸®åŠ©LLMé¿å…äº§ç”Ÿå¹»è§‰ã€‚
- en: You can (manually) refer to sources of truth when responding to a user query,
    helping to double check any potential issues.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ï¼ˆæ‰‹åŠ¨ï¼‰å‚è€ƒæƒå¨æ¥æºæ¥å›åº”ç”¨æˆ·æŸ¥è¯¢ï¼Œå¸®åŠ©æ£€æŸ¥æ½œåœ¨é—®é¢˜ã€‚
- en: You can leverage data that the LLM might not have been trained on.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åˆ©ç”¨LLMå¯èƒ½æœªæ›¾è®­ç»ƒè¿‡çš„æ•°æ®ã€‚
- en: The High Level Components of our RAG System
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬RAGç³»ç»Ÿçš„é«˜çº§ç»„ä»¶
- en: a collection of documents (formally called a corpus)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸€ç»„æ–‡æ¡£ï¼ˆæ­£å¼ç§°ä¸ºè¯­æ–™åº“ï¼‰
- en: An input from the user
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨æˆ·è¾“å…¥
- en: a similarity measure between the collection of documents and the user input
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ–‡æ¡£é›†åˆä¸ç”¨æˆ·è¾“å…¥ä¹‹é—´çš„ç›¸ä¼¼æ€§æµ‹é‡
- en: Yes, itâ€™s that simple.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯çš„ï¼Œå°±æ˜¯è¿™ä¹ˆç®€å•ã€‚
- en: To start learning and understanding RAG based systems, you donâ€™t need a vector
    store, you donâ€™t even *need* an LLM (at least to learn and understand conceptually).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å¼€å§‹å­¦ä¹ å’Œç†è§£åŸºäºRAGçš„ç³»ç»Ÿï¼Œä½ ä¸éœ€è¦ä¸€ä¸ªå‘é‡å­˜å‚¨ï¼Œç”šè‡³*ä¸éœ€è¦*LLMï¼ˆè‡³å°‘åœ¨æ¦‚å¿µå­¦ä¹ å’Œç†è§£æ–¹é¢ï¼‰ã€‚
- en: While it is often portrayed as complicated, it doesnâ€™t have to be.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶å®ƒç»å¸¸è¢«æç»˜å¾—å¾ˆå¤æ‚ï¼Œä½†å…¶å®ä¸ä¸€å®šå¦‚æ­¤ã€‚
- en: The ordered steps of a querying RAG system
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æŸ¥è¯¢RAGç³»ç»Ÿçš„æœ‰åºæ­¥éª¤
- en: Weâ€™ll perform the following steps in sequence.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚
- en: Receive a user input
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥æ”¶ç”¨æˆ·è¾“å…¥
- en: Perform our similarity measure
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ‰§è¡Œæˆ‘ä»¬çš„ç›¸ä¼¼åº¦åº¦é‡
- en: Post-process the user input and the fetched document(s).
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ç”¨æˆ·è¾“å…¥å’Œè·å–çš„æ–‡æ¡£è¿›è¡Œåå¤„ç†ã€‚
- en: The post-processing is done with an LLM.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åå¤„ç†æ˜¯é€šè¿‡LLMå®Œæˆçš„ã€‚
- en: A note from the paper itself
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®ºæ–‡æœ¬èº«çš„å¤‡æ³¨
- en: '[The actual RAG paper](https://arxiv.org/abs/2005.11401) is obviously *the*
    resource. The problem is that it assumes a LOT of context. Itâ€™s more complicated
    than we need it to be.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[å®é™…çš„RAGè®ºæ–‡](https://arxiv.org/abs/2005.11401)æ˜¾ç„¶æ˜¯*æœ€é‡è¦çš„*èµ„æºã€‚é—®é¢˜åœ¨äºå®ƒå‡è®¾äº†å¤§é‡çš„ä¸Šä¸‹æ–‡ã€‚è¿™æ¯”æˆ‘ä»¬éœ€è¦çš„è¦å¤æ‚å¾—å¤šã€‚'
- en: For instance, hereâ€™s the overview of the RAG system as proposed in the paper.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¸‹é¢æ˜¯è®ºæ–‡ä¸­æå‡ºçš„RAGç³»ç»Ÿæ¦‚è¿°ã€‚
- en: '![](../Images/2d54f5c723763e7d78ae93c9f91bcc2c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d54f5c723763e7d78ae93c9f91bcc2c.png)'
- en: '[An overview of RAG from the RAG paper](https://arxiv.org/abs/2005.11401) by
    Lewis, et al'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ¥è‡ªRAGè®ºæ–‡çš„RAGæ¦‚è¿°](https://arxiv.org/abs/2005.11401) ç”±Lewisç­‰äººæä¾›'
- en: Thatâ€™s dense.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆå¯†é›†ã€‚
- en: Itâ€™s great for researchers but for the rest of us, itâ€™s going to be a lot easier
    to learn step by step by building the system ourselves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºç ”ç©¶äººå‘˜æ¥è¯´ï¼Œè¿™å¾ˆæ£’ï¼Œä½†å¯¹äºæˆ‘ä»¬å…¶ä»–äººæ¥è¯´ï¼Œé€šè¿‡è‡ªå·±æ„å»ºç³»ç»Ÿé€æ­¥å­¦ä¹ å°†ä¼šå®¹æ˜“å¾—å¤šã€‚
- en: Working through an example â€” the simplest RAG system
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€šè¿‡ä¸€ä¸ªç¤ºä¾‹è¿›è¡Œå·¥ä½œâ€”â€”æœ€ç®€å•çš„RAGç³»ç»Ÿ
- en: Letâ€™s get back to building RAG from scratch, step by step. Hereâ€™s the simplified
    steps that weâ€™ll be working through. While this isnâ€™t technically â€œRAGâ€ itâ€™s a
    good simplified model to learn with and allow us to progress to more complicated
    variations.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å›åˆ°ä»å¤´å¼€å§‹æ„å»ºRAGï¼Œé€æ­¥è¿›è¡Œã€‚è¿™é‡Œæ˜¯æˆ‘ä»¬å°†è¦ç»å†çš„ç®€åŒ–æ­¥éª¤ã€‚è™½ç„¶è¿™ä¸ä¸¥æ ¼æ˜¯â€œRAGâ€ï¼Œä½†å®ƒæ˜¯ä¸€ä¸ªå¥½çš„ç®€åŒ–æ¨¡å‹ï¼Œæœ‰åŠ©äºå­¦ä¹ å¹¶ä½¿æˆ‘ä»¬èƒ½å¤Ÿè¿›æ­¥åˆ°æ›´å¤æ‚çš„å˜ä½“ã€‚
- en: '![](../Images/c3aaa700afa3ff0bf86304cef50bac2b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3aaa700afa3ff0bf86304cef50bac2b.png)'
- en: Getting a collection of documents
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è·å–æ–‡æ¡£é›†åˆ
- en: Below you can see that weâ€™ve got a simple corpus of â€˜documentsâ€™ (please be generous
    ğŸ˜‰).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„â€˜æ–‡æ¡£â€™è¯­æ–™åº“ï¼ˆè¯·å®½å®¹ä¸€ç‚¹ğŸ˜‰ï¼‰ã€‚
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Defining and performing the similarity measure
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®šä¹‰å’Œæ‰§è¡Œç›¸ä¼¼åº¦åº¦é‡
- en: Now we need a way of measuring the similarity between the **user input** weâ€™re
    going to receive and the **collection** of documents that we organized. Arguably
    the simplest similarity measure is [jaccard similarity](https://en.wikipedia.org/wiki/Jaccard_index).
    Iâ€™ve written about that in the past (see [this post](https://billchambers.me/posts/tf-idf-explained-in-python)
    but the short answer is that the **jaccard similarity** is the intersection divided
    by the union of the â€œsetsâ€ of words.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•æ¥è¡¡é‡æˆ‘ä»¬å°†è¦æ¥æ”¶çš„**ç”¨æˆ·è¾“å…¥**å’Œæˆ‘ä»¬ç»„ç»‡çš„**æ–‡æ¡£é›†åˆ**ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚å¯ä»¥è¯´ï¼Œæœ€ç®€å•çš„ç›¸ä¼¼åº¦åº¦é‡æ˜¯[æ°å¡å¾·ç›¸ä¼¼åº¦](https://en.wikipedia.org/wiki/Jaccard_index)ã€‚æˆ‘åœ¨è¿‡å»å†™è¿‡è¿™æ–¹é¢çš„å†…å®¹ï¼ˆå‚è§[è¿™ç¯‡æ–‡ç« ](https://billchambers.me/posts/tf-idf-explained-in-python)ï¼‰ï¼Œä½†ç®€çŸ­çš„å›ç­”æ˜¯**æ°å¡å¾·ç›¸ä¼¼åº¦**æ˜¯â€œè¯é›†â€çš„äº¤é›†é™¤ä»¥å¹¶é›†ã€‚
- en: This allows us to compare our user input with the source documents.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†ç”¨æˆ·è¾“å…¥ä¸æºæ–‡æ¡£è¿›è¡Œæ¯”è¾ƒã€‚
- en: 'Side note: preprocessing'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„æ³¨ï¼šé¢„å¤„ç†
- en: A challenge is that if we have a plain string like `"Take a leisurely walk in
    the park and enjoy the fresh air.",`, we're going to have to pre-process that
    into a set, so that we can perform these comparisons. We're going to do this in
    the simplest way possible, lower case and split by `" "`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„å­—ç¬¦ä¸²åƒ`"Take a leisurely walk in the park and enjoy the fresh
    air."`ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶é¢„å¤„ç†ä¸ºä¸€ä¸ªé›†åˆï¼Œä»¥ä¾¿è¿›è¡Œè¿™äº›æ¯”è¾ƒã€‚æˆ‘ä»¬å°†ä»¥æœ€ç®€å•çš„æ–¹å¼è¿›è¡Œå¤„ç†ï¼Œè½¬ä¸ºå°å†™å¹¶æŒ‰`" "`åˆ†å‰²ã€‚
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we need to define a function that takes in the exact query and our corpus
    and selects the â€˜bestâ€™ document to return to the user.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥æ”¶ç²¾ç¡®çš„æŸ¥è¯¢å’Œæˆ‘ä»¬çš„è¯­æ–™åº“ï¼Œå¹¶é€‰æ‹©â€˜æœ€ä½³â€™æ–‡æ¡£è¿”å›ç»™ç”¨æˆ·ã€‚
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we can run it, weâ€™ll start with a simple prompt.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿è¡Œå®ƒäº†ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ªç®€å•çš„æç¤ºå¼€å§‹ã€‚
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: And a simple user inputâ€¦
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€ä¸ªç®€å•çš„ç”¨æˆ·è¾“å…¥â€¦
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now we can return our response.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿”å›å“åº”ã€‚
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Congratulations, youâ€™ve built a basic RAG application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œï¼Œä½ å·²ç»æ„å»ºäº†ä¸€ä¸ªåŸºæœ¬çš„RAGåº”ç”¨ç¨‹åºã€‚
- en: I got 99 problems and bad similarity is one
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆ‘æœ‰99ä¸ªé—®é¢˜ï¼Œç³Ÿç³•çš„ç›¸ä¼¼åº¦æ˜¯å…¶ä¸­ä¹‹ä¸€
- en: Now weâ€™ve opted for a simple similarity measure for learning. But this is going
    to be problematic because itâ€™s so simple. It has no notion of **semantics**. Itâ€™s
    just looks at what words are in both documents. That means that if we provide
    a negative example, weâ€™re going to get the same â€œresultâ€ because thatâ€™s the closest
    document.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªç®€å•çš„ç›¸ä¼¼æ€§åº¦é‡è¿›è¡Œå­¦ä¹ ã€‚ä½†è¿™ä¼šæœ‰é—®é¢˜ï¼Œå› ä¸ºå®ƒè¿‡äºç®€å•ã€‚å®ƒæ²¡æœ‰**è¯­ä¹‰**çš„æ¦‚å¿µã€‚å®ƒåªæ˜¯æŸ¥çœ‹ä¸¤ä¸ªæ–‡æ¡£ä¸­åŒ…å«äº†å“ªäº›è¯ã€‚è¿™æ„å‘³ç€å¦‚æœæˆ‘ä»¬æä¾›ä¸€ä¸ªè´Ÿé¢ä¾‹å­ï¼Œæˆ‘ä»¬å°†å¾—åˆ°ç›¸åŒçš„â€œç»“æœâ€ï¼Œå› ä¸ºè¿™æ˜¯æœ€æ¥è¿‘çš„æ–‡æ¡£ã€‚
- en: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6905b126532fe949de9729a803c563f.png)'
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This is a topic thatâ€™s going to come up a lot with â€œRAGâ€, but for now, rest
    assured that weâ€™ll address this problem later.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªåœ¨â€œRAGâ€ä¸­ç»å¸¸å‡ºç°çš„è¯é¢˜ï¼Œä½†ç›®å‰è¯·æ”¾å¿ƒï¼Œæˆ‘ä»¬ä¼šåœ¨åé¢è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- en: At this point, we have not done any post-processing of the â€œdocumentâ€ to which
    we are responding. So far, weâ€™ve implemented only the â€œretrievalâ€ part of â€œRetrieval-Augmented
    Generationâ€. The next step is to augment generation by incorporating a large language
    model (LLM).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰å¯¹å“åº”çš„â€œæ–‡æ¡£â€è¿›è¡Œä»»ä½•åå¤„ç†ã€‚åˆ°ç°åœ¨ä¸ºæ­¢ï¼Œæˆ‘ä»¬åªå®ç°äº†â€œæ£€ç´¢å¢å¼ºç”Ÿæˆâ€çš„â€œæ£€ç´¢â€éƒ¨åˆ†ã€‚ä¸‹ä¸€æ­¥æ˜¯é€šè¿‡å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å¢å¼ºç”Ÿæˆã€‚
- en: Adding in a LLM
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ·»åŠ LLM
- en: To do this, weâ€™re going to use [ollama](https://ollama.ai/) to get up and running
    with an open source LLM on our local machine. We could just as easily use OpenAIâ€™s
    gpt-4 or Anthropicâ€™s Claude but for now, weâ€™ll start with the open source llama2
    from [Meta AI](https://ai.meta.com/llama/).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[ollama](https://ollama.ai/)æ¥å¯åŠ¨å¹¶è¿è¡Œæœ¬åœ°æœºå™¨ä¸Šçš„å¼€æºLLMã€‚æˆ‘ä»¬åŒæ ·å¯ä»¥ä½¿ç”¨OpenAIçš„gpt-4æˆ–Anthropicçš„Claudeï¼Œä½†ç°åœ¨æˆ‘ä»¬å°†ä»[Meta
    AI](https://ai.meta.com/llama/)çš„å¼€æºllama2å¼€å§‹ã€‚
- en: '[ollama installation instructions are here](https://ollama.ai/)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ollamaå®‰è£…è¯´æ˜åœ¨è¿™é‡Œ](https://ollama.ai/)'
- en: This post is going to assume some basic knowledge of large language models,
    so letâ€™s get right to querying this model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡å‡è®¾ä½ å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æœ‰ä¸€äº›åŸºæœ¬äº†è§£ï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥å¼€å§‹æŸ¥è¯¢è¿™ä¸ªæ¨¡å‹å§ã€‚
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: First weâ€™re going to define the inputs. To work with this model, weâ€™re going
    to take
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®šä¹‰è¾“å…¥ã€‚ä¸ºäº†ä½¿ç”¨è¿™ä¸ªæ¨¡å‹ï¼Œæˆ‘ä»¬å°†é‡‡å–
- en: user input,
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨æˆ·è¾“å…¥ï¼Œ
- en: fetch the most similar document (as measured by our similarity measure),
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è·å–æœ€ç›¸ä¼¼çš„æ–‡æ¡£ï¼ˆæŒ‰æˆ‘ä»¬çš„ç›¸ä¼¼æ€§åº¦é‡æ¥è¡¡é‡ï¼‰ï¼Œ
- en: pass that into a prompt to the language model,
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å…¶ä¼ é€’ç»™è¯­è¨€æ¨¡å‹çš„æç¤ºï¼Œ
- en: '*then* return the result to the user'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç„¶å* å°†ç»“æœè¿”å›ç»™ç”¨æˆ·'
- en: That introduces a new term, the **prompt**. In short, itâ€™s the instructions
    that you provide to the LLM.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¼•å…¥äº†ä¸€ä¸ªæ–°æœ¯è¯­ï¼Œå³**æç¤º**ã€‚ç®€è€Œè¨€ä¹‹ï¼Œå®ƒå°±æ˜¯ä½ ç»™LLMçš„æŒ‡ä»¤ã€‚
- en: When you run this code, youâ€™ll see the streaming result. Streaming is important
    for user experience.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ è¿è¡Œè¿™æ®µä»£ç æ—¶ï¼Œä½ ä¼šçœ‹åˆ°æµå¼ç»“æœã€‚æµå¼å¤„ç†å¯¹ç”¨æˆ·ä½“éªŒå¾ˆé‡è¦ã€‚
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Having defined that, letâ€™s now make the API call to ollama (and llama2). an
    important step is to make sure that ollamaâ€™s running already on your local machine
    by running `ollama serve`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šäº†è¿™ä¸€ç‚¹ä¹‹åï¼Œç°åœ¨è®©æˆ‘ä»¬è°ƒç”¨ollamaï¼ˆå’Œllama2ï¼‰çš„APIã€‚ä¸€ä¸ªé‡è¦çš„æ­¥éª¤æ˜¯ç¡®ä¿ollamaå·²ç»åœ¨ä½ çš„æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œï¼Œé€šè¿‡è¿è¡Œ`ollama
    serve`ã€‚
- en: '*Note: this might be slow on your machine, itâ€™s certainly slow on mine. Be
    patient, young grasshopper.*'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šè¿™åœ¨ä½ çš„æœºå™¨ä¸Šå¯èƒ½å¾ˆæ…¢ï¼Œåœ¨æˆ‘çš„æœºå™¨ä¸Šè‚¯å®šå¾ˆæ…¢ã€‚è¯·è€å¿ƒç‚¹ï¼Œå°è‰hopperã€‚*'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This gives us a complete RAG Application, from scratch, no providers, no services.
    You know all of the components in a Retrieval-Augmented Generation application.
    Visually, hereâ€™s what weâ€™ve built.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ªå®Œæ•´çš„RAGåº”ç”¨ï¼Œä»é›¶å¼€å§‹ï¼Œæ²¡æœ‰æä¾›è€…ï¼Œæ²¡æœ‰æœåŠ¡ã€‚ä½ äº†è§£äº†æ£€ç´¢å¢å¼ºç”Ÿæˆåº”ç”¨ä¸­çš„æ‰€æœ‰ç»„ä»¶ã€‚è§†è§‰ä¸Šï¼Œè¿™æ˜¯æˆ‘ä»¬æ„å»ºçš„å†…å®¹ã€‚
- en: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a2da66e8db36d3cef1c6db81b0b6a9a.png)'
- en: The LLM (if youâ€™re lucky) will handle the user input that goes against the recommended
    document. We can see that below.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¹¸è¿çš„è¯ï¼ŒLLMå°†å¤„ç†ä¸æ¨èæ–‡æ¡£ä¸ç¬¦çš„ç”¨æˆ·è¾“å…¥ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä¸‹é¢çœ‹åˆ°ã€‚
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Areas for improvement
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ”¹è¿›é¢†åŸŸ
- en: If we go back to our diagream of the RAG application and think about what weâ€™ve
    just built, weâ€™ll see various opportunities for improvement. These opportunities
    are where tools like vector stores, embeddings, and prompt â€˜engineeringâ€™ gets
    involved.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å›åˆ°RAGåº”ç”¨çš„å›¾ç¤ºï¼Œè€ƒè™‘ä¸€ä¸‹æˆ‘ä»¬åˆšåˆšæ„å»ºçš„å†…å®¹ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å„ç§æ”¹è¿›çš„æœºä¼šã€‚è¿™äº›æœºä¼šæ˜¯å·¥å…·å¦‚å‘é‡å­˜å‚¨ã€åµŒå…¥å’Œæç¤ºâ€œå·¥ç¨‹â€ä»‹å…¥çš„åœ°æ–¹ã€‚
- en: 'Here are ten potential areas where we could improve the current setup:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰åä¸ªæ½œåœ¨çš„æ”¹è¿›é¢†åŸŸï¼š
- en: '**The number of documents** ğŸ‘‰ more documents might mean more recommendations.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ–‡æ¡£çš„æ•°é‡** ğŸ‘‰ æ›´å¤šæ–‡æ¡£å¯èƒ½æ„å‘³ç€æ›´å¤šçš„æ¨èã€‚'
- en: '**The depth/size of documents** ğŸ‘‰ higher quality content and longer documents
    with more information might be better.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ–‡æ¡£çš„æ·±åº¦/å¤§å°** ğŸ‘‰ æ›´é«˜è´¨é‡çš„å†…å®¹å’Œä¿¡æ¯æ›´å¤šçš„é•¿æ–‡æ¡£å¯èƒ½æ›´å¥½ã€‚'
- en: '**The number of documents we give to the LLM** ğŸ‘‰ Right now, weâ€™re only giving
    the LLM one document. We could feed in several as â€˜contextâ€™ and allow the model
    to provide a more personalized recommendation based on the user input.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬æä¾›ç»™ LLM çš„æ–‡æ¡£æ•°é‡** ğŸ‘‰ ç›®å‰ï¼Œæˆ‘ä»¬åªç»™ LLM ä¸€ä¸ªæ–‡æ¡£ã€‚æˆ‘ä»¬å¯ä»¥å°†å‡ ä¸ªæ–‡æ¡£ä½œä¸ºâ€œä¸Šä¸‹æ–‡â€è¾“å…¥ï¼Œå¹¶å…è®¸æ¨¡å‹æ ¹æ®ç”¨æˆ·è¾“å…¥æä¾›æ›´ä¸ªæ€§åŒ–çš„æ¨èã€‚'
- en: '**The parts of documents that we give to the LLM** ğŸ‘‰ If we have bigger or more
    thorough documents, we might just want to add in parts of those documents, parts
    of various documents, or some variation there of. In the lexicon, this is called
    chunking.'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬æä¾›ç»™ LLM çš„æ–‡æ¡£éƒ¨åˆ†** ğŸ‘‰ å¦‚æœæˆ‘ä»¬æœ‰è¾ƒå¤§æˆ–æ›´å…¨é¢çš„æ–‡æ¡£ï¼Œæˆ‘ä»¬å¯èƒ½åªæƒ³æ·»åŠ è¿™äº›æ–‡æ¡£çš„éƒ¨åˆ†ã€å„ä¸ªæ–‡æ¡£çš„éƒ¨åˆ†ï¼Œæˆ–å…¶æŸç§å˜ä½“ã€‚åœ¨è¯æ±‡ä¸­ï¼Œè¿™è¢«ç§°ä¸ºåˆ†å—ï¼ˆchunkingï¼‰ã€‚'
- en: '**Our document storage tool** ğŸ‘‰ We might store our documents in a different
    way or different database. In particular, if we have a lot of documents, we might
    explore storing them in a data lake or a vector store.'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æˆ‘ä»¬çš„æ–‡æ¡£å­˜å‚¨å·¥å…·** ğŸ‘‰ æˆ‘ä»¬å¯èƒ½ä»¥ä¸åŒçš„æ–¹å¼æˆ–ä¸åŒçš„æ•°æ®åº“å­˜å‚¨æ–‡æ¡£ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬æœ‰å¤§é‡æ–‡æ¡£ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæ¢ç´¢å°†å®ƒä»¬å­˜å‚¨åœ¨æ•°æ®æ¹–æˆ–å‘é‡å­˜å‚¨ä¸­ã€‚'
- en: '**The similarity measure** ğŸ‘‰ How we measure similarity is of consequence, we
    might need to trade off performance and thoroughness (e.g., looking at every individual
    document).'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç›¸ä¼¼åº¦åº¦é‡** ğŸ‘‰ æˆ‘ä»¬å¦‚ä½•åº¦é‡ç›¸ä¼¼åº¦æ˜¯é‡è¦çš„ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦åœ¨æ€§èƒ½å’Œå…¨é¢æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼ˆä¾‹å¦‚ï¼ŒæŸ¥çœ‹æ¯ä¸€ä¸ªå•ç‹¬çš„æ–‡æ¡£ï¼‰ã€‚'
- en: '**The pre-processing of the documents & user input** ğŸ‘‰ We might perform some
    extra preprocessing or augmentation of the user input before we pass it into the
    similarity measure. For instance, we might use an embedding to convert that input
    to a vector.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ–‡æ¡£åŠç”¨æˆ·è¾“å…¥çš„é¢„å¤„ç†** ğŸ‘‰ æˆ‘ä»¬å¯èƒ½åœ¨å°†ç”¨æˆ·è¾“å…¥ä¼ é€’åˆ°ç›¸ä¼¼åº¦åº¦é‡ä¹‹å‰ï¼Œè¿›è¡Œä¸€äº›é¢å¤–çš„é¢„å¤„ç†æˆ–å¢å¼ºã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä½¿ç”¨åµŒå…¥å°†è¾“å…¥è½¬æ¢ä¸ºå‘é‡ã€‚'
- en: '**The similarity measure** ğŸ‘‰ We can change the similarity measure to fetch
    better or more relevant documents.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç›¸ä¼¼åº¦åº¦é‡** ğŸ‘‰ æˆ‘ä»¬å¯ä»¥æ›´æ”¹ç›¸ä¼¼åº¦åº¦é‡ï¼Œä»¥è·å–æ›´å¥½æˆ–æ›´ç›¸å…³çš„æ–‡æ¡£ã€‚'
- en: '**The model** ğŸ‘‰ We can change the final model that we use. Weâ€™re using llama2
    above, but we could just as easily use an Anthropic or Claude Model.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹** ğŸ‘‰ æˆ‘ä»¬å¯ä»¥æ›´æ”¹æˆ‘ä»¬ä½¿ç”¨çš„æœ€ç»ˆæ¨¡å‹ã€‚æˆ‘ä»¬ä¸Šé¢ä½¿ç”¨çš„æ˜¯ llama2ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¯ä»¥è½»æ¾ä½¿ç”¨ Anthropic æˆ– Claude æ¨¡å‹ã€‚'
- en: '**The prompt** ğŸ‘‰ We could use a different prompt into the LLM/Model and tune
    it according to the output we want to get the output we want.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æç¤º** ğŸ‘‰ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸åŒçš„æç¤ºè¾“å…¥ LLM/æ¨¡å‹ï¼Œå¹¶æ ¹æ®æˆ‘ä»¬å¸Œæœ›å¾—åˆ°çš„è¾“å‡ºè¿›è¡Œè°ƒæ•´ã€‚'
- en: '**If youâ€™re worried about harmful or toxic output** ğŸ‘‰ We could implement a
    â€œcircuit breakerâ€ of sorts that runs the user input to see if thereâ€™s toxic, harmful,
    or dangerous discussions. For instance, in a healthcare context you could see
    if the information contained unsafe languages and respond accordingly â€” outside
    of the typical flow.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¦‚æœä½ æ‹…å¿ƒæœ‰å®³æˆ–æœ‰æ¯’çš„è¾“å‡º** ğŸ‘‰ æˆ‘ä»¬å¯ä»¥å®ç°ä¸€ç§â€œæ–­è·¯å™¨â€ï¼Œè¿è¡Œç”¨æˆ·è¾“å…¥ä»¥æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœ‰æ¯’ã€æœ‰å®³æˆ–å±é™©çš„è®¨è®ºã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—ä¿å¥èƒŒæ™¯ä¸­ï¼Œä½ å¯ä»¥æ£€æŸ¥ä¿¡æ¯æ˜¯å¦åŒ…å«ä¸å®‰å…¨çš„è¯­è¨€ï¼Œå¹¶ç›¸åº”åœ°åšå‡ºå›åº”â€”â€”è¶…å‡ºå…¸å‹æµç¨‹ä¹‹å¤–ã€‚'
- en: The scope for improvements isnâ€™t limited to these points; the possibilities
    are vast, and weâ€™ll delve into them in future tutorials. Until then, donâ€™t hesitate
    to [reach out on Twitter](https://twitter.com/bllchmbrs) if you have any questions.
    Happy RAGING :).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¹è¿›çš„èŒƒå›´ä¸ä»…é™äºè¿™äº›ç‚¹ï¼›å¯èƒ½æ€§å¹¿æ³›ï¼Œæˆ‘ä»¬å°†åœ¨æœªæ¥çš„æ•™ç¨‹ä¸­æ·±å…¥æ¢è®¨ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶ [åœ¨ Twitter ä¸Šè”ç³»æˆ‘](https://twitter.com/bllchmbrs)ã€‚ç¥ä½ 
    RAGING æ„‰å¿« :)ã€‚
- en: References
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç”¨äºçŸ¥è¯†å¯†é›†å‹ NLP ä»»åŠ¡](https://arxiv.org/abs/2005.11401)'
- en: '[Jerry Liu on Twitter advocating for users to build RAG from scratch](https://twitter.com/jerryjliu0/status/1716122650836439478)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jerry Liu åœ¨ Twitter ä¸Šå€¡å¯¼ç”¨æˆ·ä»é›¶å¼€å§‹æ„å»º RAG](https://twitter.com/jerryjliu0/status/1716122650836439478)'
- en: '[This post was originally posted on learnbybuilding.ai](https://learnbybuilding.ai/tutorials/rag-from-scratch).
    **Iâ€™m running a course on How to Build Generative AI Products for Product Managers
    in the coming months,** [**sign up here**](https://maven.com/forms/90684f)**.**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¿™ç¯‡æ–‡ç« æœ€åˆå‘å¸ƒåœ¨ learnbybuilding.ai](https://learnbybuilding.ai/tutorials/rag-from-scratch)ã€‚**æˆ‘å°†åœ¨æœªæ¥å‡ ä¸ªæœˆä¸¾åŠä¸€ä¸ªå…³äºå¦‚ä½•ä¸ºäº§å“ç»ç†æ„å»ºç”Ÿæˆå¼
    AI äº§å“çš„è¯¾ç¨‹ï¼Œ** [**ç‚¹å‡»è¿™é‡ŒæŠ¥å**](https://maven.com/forms/90684f)**ã€‚**'
