- en: Effective Data Augmentation for OCR
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„æ•°æ®å¢å¼ºç”¨äºOCR
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06](https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06](https://towardsdatascience.com/effective-data-augmentation-for-ocr-8013080aa9fa?source=collection_archive---------10-----------------------#2023-04-06)
- en: My recipe to reach those last percents of (ac)cu(re)teness
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æˆ‘å®ç°æœ€åå‡ ä¸ªç™¾åˆ†ç‚¹çš„ï¼ˆacï¼‰cu(re)tenessçš„ç§˜è¯€
- en: '[](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[![Toon
    Beerten](../Images/f169eaa8cefa00f17176955596972d57.png)](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    [Toon Beerten](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[![Toon
    Beerten](../Images/f169eaa8cefa00f17176955596972d57.png)](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    [Toon Beerten](https://toon-beerten.medium.com/?source=post_page-----8013080aa9fa--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3aef462e13b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=post_page-3aef462e13b5----8013080aa9fa---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    Â·7 min readÂ·Apr 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=-----8013080aa9fa---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3aef462e13b5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=post_page-3aef462e13b5----8013080aa9fa---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8013080aa9fa--------------------------------)
    Â·7 min readÂ·2023å¹´4æœˆ6æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&user=Toon+Beerten&userId=3aef462e13b5&source=-----8013080aa9fa---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&source=-----8013080aa9fa---------------------bookmark_footer-----------)![](../Images/e6dd122357975bca3efc671c05bae100.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8013080aa9fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-data-augmentation-for-ocr-8013080aa9fa&source=-----8013080aa9fa---------------------bookmark_footer-----------)![](../Images/e6dd122357975bca3efc671c05bae100.png)'
- en: Image by author (generated [with](https://huggingface.co/spaces/albarji/mixture-of-diffusers))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…å›¾ç‰‡ï¼ˆç”Ÿæˆçš„ [with](https://huggingface.co/spaces/albarji/mixture-of-diffusers)ï¼‰
- en: '**Background**'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**èƒŒæ™¯**'
- en: I faced a challenge of handwritten amounts that needed to be recognized as precise
    as possible. The difficulty lies in keeping the false positives below 0.01% .
    The amount of samples in the dataset was fixed, so data augmentation is the logical
    go-to. A quick search revealed no of-the-shelf method for Optical Character Recognition
    (OCR). So I pulled up my sleeves and created a data augmentation routine myself.
    It was used during training and helped my model reach the objective. Read on to
    know how.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘é¢ä¸´äº†ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå³æ‰‹å†™é‡‘é¢éœ€è¦å°½å¯èƒ½ç²¾ç¡®åœ°è¯†åˆ«ã€‚å›°éš¾åœ¨äºå°†è¯¯æŠ¥ç‡ä¿æŒåœ¨0.01%ä»¥ä¸‹ã€‚æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥æ•°æ®å¢å¼ºæ˜¯åˆé€»è¾‘çš„é€‰æ‹©ã€‚å¿«é€Ÿæœç´¢å‘ç°æ²¡æœ‰ç°æˆçš„å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰æ–¹æ³•ã€‚å› æ­¤ï¼Œæˆ‘å·èµ·è¢–å­è‡ªå·±åˆ›å»ºäº†ä¸€ä¸ªæ•°æ®å¢å¼ºç¨‹åºã€‚è¿™ä¸ªç¨‹åºåœ¨è®­ç»ƒæœŸé—´è¢«ä½¿ç”¨ï¼Œå¸®åŠ©æˆ‘çš„æ¨¡å‹è¾¾åˆ°äº†ç›®æ ‡ã€‚ç»§ç»­é˜…è¯»ä»¥äº†è§£è¯¦ç»†æƒ…å†µã€‚
- en: By introducing small changes each time an image is trained, the model is less
    likely to overfit and generalize better. I used it in conjunction with TROCR,
    but any other model should benefit as well.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é€šè¿‡åœ¨æ¯æ¬¡è®­ç»ƒå›¾åƒæ—¶å¼•å…¥å°çš„å˜åŒ–ï¼Œæ¨¡å‹ä¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œä»è€Œæ›´å¥½åœ°è¿›è¡Œæ³›åŒ–ã€‚æˆ‘å°†å…¶ä¸TROCRç»“åˆä½¿ç”¨ï¼Œä½†ä»»ä½•å…¶ä»–æ¨¡å‹ä¹Ÿåº”å—ç›Šã€‚
- en: '**Test setup**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æµ‹è¯•è®¾ç½®**'
- en: Since I canâ€™t share images from my proprietary dataset, I wanted to use samples
    from the [IAM Handwriting Database](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database),
    but I didnâ€™t get a reply to my request for permission to use it in this article.
    So I created some of my own examples for demonstrating.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘ä¸èƒ½åˆ†äº«æˆ‘ä¸“æœ‰æ•°æ®é›†ä¸­çš„å›¾åƒï¼Œæˆ‘æƒ³ä½¿ç”¨[IAMæ‰‹å†™æ•°æ®åº“](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database)ä¸­çš„æ ·æœ¬ï¼Œä½†æˆ‘æ²¡æœ‰æ”¶åˆ°ä½¿ç”¨è¿™äº›å›¾åƒçš„è®¸å¯å›å¤ã€‚å› æ­¤ï¼Œæˆ‘åˆ›å»ºäº†ä¸€äº›è‡ªå·±çš„ç¤ºä¾‹æ¥è¿›è¡Œæ¼”ç¤ºã€‚
- en: 'I will make use of O[penCV](https://opencv.org/) and the [albumentations](https://albumentations.ai/)
    library, for three kinds of alterations: morphological, noise and transformations.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†ä½¿ç”¨O[penCV](https://opencv.org/)å’Œ[albumentations](https://albumentations.ai/)åº“ï¼Œè¿›è¡Œä¸‰ç§ç±»å‹çš„å˜æ¢ï¼šå½¢æ€å­¦ã€å™ªå£°å’Œå˜æ¢ã€‚
- en: OpenCV is a well known computer vision library. Albumentations is a relatively
    new Python library for easy yet powerful image augmentations.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenCVæ˜¯ä¸€ä¸ªçŸ¥åçš„è®¡ç®—æœºè§†è§‰åº“ã€‚Albumentationsæ˜¯ä¸€ä¸ªç›¸å¯¹è¾ƒæ–°çš„Pythonåº“ï¼Œæä¾›äº†ç®€å•è€Œå¼ºå¤§çš„å›¾åƒå¢å¼ºåŠŸèƒ½ã€‚
- en: There is also a nice [demo website](https://demo.albumentations.ai/) where you
    can try what albumentations can do. It is however limited because you canâ€™t use
    your own image to test on. So, I created a Jupyter [notebook](https://github.com/Toon-nooT/notebooks)
    that I used to render all augmented images in this article. Feel free to open
    it in [colab](https://colab.research.google.com/github/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb)
    and experiment.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€ä¸ªå¾ˆæ£’çš„[æ¼”ç¤ºç½‘ç«™](https://demo.albumentations.ai/)ï¼Œä½ å¯ä»¥è¯•è¯•albumentationsèƒ½åšä»€ä¹ˆã€‚ç„¶è€Œå®ƒæœ‰ä¸€å®šçš„é™åˆ¶ï¼Œå› ä¸ºä½ ä¸èƒ½ä½¿ç”¨è‡ªå·±çš„å›¾åƒè¿›è¡Œæµ‹è¯•ã€‚å› æ­¤ï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ªJupyter
    [ç¬”è®°æœ¬](https://github.com/Toon-nooT/notebooks)ï¼Œç”¨äºæ¸²æŸ“æœ¬æ–‡ä¸­çš„æ‰€æœ‰å¢å¼ºå›¾åƒã€‚ä½ å¯ä»¥åœ¨[colab](https://colab.research.google.com/github/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb)ä¸­æ‰“å¼€å¹¶è¿›è¡Œå®éªŒã€‚
- en: I will first show the alterations by itself with some explanation and then i
    will discuss my technique to combine all of them. I will suppose that all images
    are grayscale and will have undergone already contrast enhancement (eg. CLAHE).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†é¦–å…ˆå±•ç¤ºè¿™äº›å˜æ¢åŠå…¶ä¸€äº›è§£é‡Šï¼Œç„¶åè®¨è®ºæˆ‘å°†å®ƒä»¬ç»“åˆåœ¨ä¸€èµ·çš„æŠ€æœ¯ã€‚æˆ‘å‡è®¾æ‰€æœ‰å›¾åƒéƒ½æ˜¯ç°åº¦å›¾åƒï¼Œå¹¶ä¸”å·²ç»è¿›è¡Œäº†å¯¹æ¯”åº¦å¢å¼ºï¼ˆä¾‹å¦‚CLAHEï¼‰ã€‚
- en: '1st augmentation technique: **morphological** alterations'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ç§å¢å¼ºæŠ€æœ¯ï¼š**å½¢æ€å­¦**å˜æ¢
- en: 'These relate to the form of structure. To put it in simpler terms: they can
    be used to make the text lines appear to be written with a finer or thicker pen.
    *Erosion* and *dilation* they are called. Unfortunately these are not (yet?) part
    of the albumentations library, so i have to resort to opencv for this.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ä¸ç»“æ„å½¢å¼æœ‰å…³ã€‚ç®€å•æ¥è¯´ï¼šå®ƒä»¬å¯ä»¥ç”¨æ¥ä½¿æ–‡æœ¬çº¿æ¡çœ‹èµ·æ¥åƒæ˜¯ç”¨æ›´ç»†æˆ–æ›´ç²—çš„ç¬”ä¹¦å†™çš„ã€‚å®ƒä»¬è¢«ç§°ä¸º*è…èš€*å’Œ*è†¨èƒ€*ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™äº›è¿˜ä¸æ˜¯ï¼ˆè¿˜ï¼Ÿï¼‰albumentationsåº“çš„ä¸€éƒ¨åˆ†ï¼Œå› æ­¤æˆ‘å¿…é¡»å€ŸåŠ©opencvæ¥å®ç°ã€‚
- en: 'To create the effect that somebody used a pen with a fatter line width, we
    can **dilate** the original:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åˆ›é€ å‡ºæŸäººä½¿ç”¨äº†æ›´ç²—çº¿å®½çš„ç¬”çš„æ•ˆæœï¼Œæˆ‘ä»¬å¯ä»¥å¯¹åŸå›¾è¿›è¡Œ**è†¨èƒ€**å¤„ç†ï¼š
- en: '![](../Images/4b9a2f4972ba437ab7beb639d560dceb.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b9a2f4972ba437ab7beb639d560dceb.png)'
- en: original vs dilated (*Image by author*)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹å›¾åƒä¸è†¨èƒ€æ•ˆæœ (*å›¾ç‰‡ç”±ä½œè€…æä¾›*)
- en: '**Erosion** on the other hand (pun intended) simulates that the text has been
    written with a finer pen:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œ**è…èš€**ï¼ˆæœ‰æ„çš„åŒå…³ï¼‰æ¨¡æ‹Ÿäº†æ–‡æœ¬æ˜¯ç”¨æ›´ç»†çš„ç¬”ä¹¦å†™çš„æ•ˆæœï¼š
- en: '![](../Images/518656273e4ca8bd9851b3e271c01fec.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/518656273e4ca8bd9851b3e271c01fec.png)'
- en: original vs erosion (*Image by author*)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹å›¾åƒä¸è…èš€æ•ˆæœ (*å›¾ç‰‡ç”±ä½œè€…æä¾›*)
- en: Be careful here that the last parameter â€” which is the number of iterations
    â€” is not set too high (here it was set to 3), otherwise you end up with the handwriting
    completely removed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œè¦å°å¿ƒï¼Œæœ€åä¸€ä¸ªå‚æ•°â€”â€”å³è¿­ä»£æ¬¡æ•°â€”â€”ä¸è¦è®¾ç½®å¾—å¤ªé«˜ï¼ˆè¿™é‡Œè®¾ç½®ä¸º3ï¼‰ï¼Œå¦åˆ™ä½ æœ€ç»ˆä¼šå¾—åˆ°å®Œå…¨å»é™¤çš„æ‰‹å†™å­—ã€‚
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For my dataset I could only set it to 1, so this really depends on your data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘çš„æ•°æ®é›†ï¼Œæˆ‘åªèƒ½è®¾ç½®ä¸º1ï¼Œå› æ­¤è¿™ç¡®å®å–å†³äºä½ çš„æ•°æ®ã€‚
- en: '2nd augmentation technique: **noise introduction**'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬äºŒç§å¢å¼ºæŠ€æœ¯ï¼š**å™ªå£°å¼•å…¥**
- en: 'We can either remove black pixels or add white pixels to the image. there are
    several methods to that. I have experimented with many of them, but here is my
    shortlist:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€‰æ‹©ä»å›¾åƒä¸­å»é™¤é»‘è‰²åƒç´ æˆ–æ·»åŠ ç™½è‰²åƒç´ ã€‚å¯¹æ­¤æœ‰å‡ ç§æ–¹æ³•ã€‚æˆ‘å°è¯•äº†è®¸å¤šæ–¹æ³•ï¼Œä½†è¿™æ˜¯æˆ‘çš„ç®€çŸ­æ¸…å•ï¼š
- en: '**RandomRain** with **black** drop color is very damaging. Even for me itâ€™s
    hard to still read the text. Thatâ€™s why i opt to set the chance of this happening
    very low:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**éšæœºé™é›¨**ä¸**é»‘è‰²**æ»´æ°´é¢œè‰²éå¸¸å…·æœ‰ç ´åæ€§ã€‚å³ä½¿å¯¹æˆ‘æ¥è¯´ä¹Ÿå¾ˆéš¾é˜…è¯»æ–‡æœ¬ã€‚å› æ­¤ï¼Œæˆ‘é€‰æ‹©å°†è¿™ç§æƒ…å†µå‘ç”Ÿçš„æ¦‚ç‡è®¾ç½®å¾—éå¸¸ä½ï¼š'
- en: '![](../Images/0204f3ade1e653b39a087303d12f0e66.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0204f3ade1e653b39a087303d12f0e66.png)'
- en: RandomRain examples (*Image by author*)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: RandomRain ç¤ºä¾‹ï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: '**RandomShadow** will smudge the text with lines of varying intensity:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**RandomShadow** å°†ç”¨ä¸åŒå¼ºåº¦çš„çº¿æ¡æ¶‚æŠ¹æ–‡æœ¬ï¼š'
- en: '![](../Images/e1ac0e10469d87375b5f5e2a4dffb45b.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1ac0e10469d87375b5f5e2a4dffb45b.png)'
- en: RandomShadow (*Image by author*)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: RandomShadowï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: '**PixelDropout** gently turns random pixels into black:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**PixelDropout** è½»è½»å°†éšæœºåƒç´ å˜ä¸ºé»‘è‰²ï¼š'
- en: '![](../Images/be81c47bd860ec1f9fb3693e1dbc18d9.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be81c47bd860ec1f9fb3693e1dbc18d9.png)'
- en: black pixels with PixelDropout (*Image by author*)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ PixelDropout çš„é»‘è‰²åƒç´ ï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: Unlike with black color drops, **RandomRain** with **white** drop color disintegrates
    the writing, which hardens the training. Much like the bad quality you see when
    a photocopy of a xerox of a fax was taken. The probability of this transform happening
    can be set much higher.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸é»‘è‰²æ»´è½ä¸åŒï¼Œ**RandomRain** ä½¿ç”¨ **ç™½è‰²** æ»´è½é¢œè‰²ä¼šä½¿ä¹¦å†™å˜å¾—æ”¯ç¦»ç ´ç¢ï¼Œè¿™ä½¿å¾—è®­ç»ƒå˜å¾—æ›´åŠ å›°éš¾ã€‚å°±åƒä½ åœ¨å¤å°ä¼ çœŸå¤å°ä»¶æ—¶çœ‹åˆ°çš„é‚£ç§åŠ£è´¨æ•ˆæœä¸€æ ·ã€‚è¿™ç§å˜æ¢å‘ç”Ÿçš„æ¦‚ç‡å¯ä»¥è®¾å¾—æ›´é«˜ã€‚
- en: '![](../Images/5755ce839ed7e7fc6508076eef3793cd.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5755ce839ed7e7fc6508076eef3793cd.png)'
- en: RandomRain â€” white version (*Image by author*)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: RandomRain â€” ç™½è‰²ç‰ˆæœ¬ï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: 'In a lesser extent **PixelDropout** to **white** does the same. But it results
    more in a more general faded image:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¾ƒå°ç¨‹åº¦ä¸Šï¼Œ**PixelDropout** å¯¹ **ç™½è‰²** çš„å¤„ç†ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ä½†å®ƒæ›´å¤šåœ°å¯¼è‡´äº†ä¸€ç§æ›´æ™®éçš„è¤ªè‰²å›¾åƒï¼š
- en: '![](../Images/32ba83dfe76e12fea60af4a02368b9a4.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32ba83dfe76e12fea60af4a02368b9a4.png)'
- en: PixelDropout with white pixels (*Image by author*)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ PixelDropout çš„ç™½è‰²åƒç´ ï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: '3rd augmentation technique: transformations'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰ç§å¢å¼ºæŠ€æœ¯ï¼šå˜æ¢
- en: '**ShiftScaleRotate**: be careful here with the parameters. Try to avoid that
    some text is cut off and falls outside the original dimensions. There is both
    a zoom and rotation going on. Be sure to not overdo it with too big parameters.
    Otherwise youâ€™ll have more chance that the 1st sample will happen. You can see
    it actually moves text outside of the image. This can be prevented by choosing
    a larger bounding box â€” so effectively adding more whitespace around the text.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**ShiftScaleRotate**ï¼šåœ¨è¿™é‡Œéœ€è¦æ³¨æ„å‚æ•°ã€‚å°½é‡é¿å…æ–‡æœ¬è¢«åˆ‡å‰²å¹¶è¶…å‡ºåŸå§‹å°ºå¯¸ã€‚è¿™é‡Œæœ‰ç¼©æ”¾å’Œæ—‹è½¬ã€‚è¯·ç¡®ä¿ä¸è¦è¿‡åº¦ä½¿ç”¨è¿‡å¤§çš„å‚æ•°ã€‚å¦åˆ™ï¼Œä½ ä¼šæœ‰æ›´å¤§çš„æœºä¼šè®©ç¬¬ä¸€ä¸ªæ ·æœ¬å‘ç”Ÿã€‚ä½ å¯ä»¥çœ‹åˆ°å®ƒå®é™…ä¸Šå°†æ–‡æœ¬ç§»åŠ¨åˆ°å›¾åƒä¹‹å¤–ã€‚è¿™å¯ä»¥é€šè¿‡é€‰æ‹©æ›´å¤§çš„è¾¹ç•Œæ¡†æ¥é˜²æ­¢â€”â€”ä»è€Œæœ‰æ•ˆåœ°åœ¨æ–‡æœ¬å‘¨å›´æ·»åŠ æ›´å¤šçš„ç©ºç™½ã€‚'
- en: '![](../Images/0363993a0a4467f8609d17c980a84961.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0363993a0a4467f8609d17c980a84961.png)'
- en: zoomed and rotated (*Image by author*)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¾å¤§å’Œæ—‹è½¬ï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: '**Blur**. The old (but gold) reliable. Will be performed in different intensities.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ¨¡ç³Š**ã€‚è¿™ä¸ªæ—§è€Œå¯é çš„æ–¹æ³•ï¼Œå°†ä»¥ä¸åŒçš„å¼ºåº¦æ‰§è¡Œã€‚'
- en: '![](../Images/7775913f3b1f7790b6ebd6e838e0b9cc.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7775913f3b1f7790b6ebd6e838e0b9cc.png)'
- en: blurred handwritten text (*Image by author*)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡ç³Šçš„æ‰‹å†™æ–‡æœ¬ï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: '**The big finale: combining them all together:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**å¤§ç»“å±€ï¼šå°†å®ƒä»¬å…¨éƒ¨ç»“åˆèµ·æ¥ï¼š**'
- en: 'This is where the power lies. We can randomly combine these effects to create
    unique images to include in each training epoch. Careful consideration needs to
    be taken that you donâ€™t do too many methods of the same type. We can do this with
    the function in albumentation *OneOf* . *OneOf* contains a list of possible transformations
    and like the name implies, will only execute one of these with possibility P.
    So it makes sense to group transformations that do more or less the same, to avoid
    overdoing it. Here is the function:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯åŠ›é‡æ‰€åœ¨ã€‚æˆ‘ä»¬å¯ä»¥éšæœºç»„åˆè¿™äº›æ•ˆæœæ¥åˆ›å»ºç‹¬ç‰¹çš„å›¾åƒï¼Œä»¥åŒ…å«åœ¨æ¯ä¸ªè®­ç»ƒå‘¨æœŸä¸­ã€‚éœ€è¦ä»”ç»†è€ƒè™‘çš„æ˜¯ï¼Œé¿å…ä½¿ç”¨å¤ªå¤šç›¸åŒç±»å‹çš„æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ albumentation
    ä¸­çš„ *OneOf* å‡½æ•°æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚*OneOf* åŒ…å«ä¸€ä¸ªå¯èƒ½çš„å˜æ¢åˆ—è¡¨ï¼Œæ­£å¦‚åå­—æ‰€ç¤ºï¼Œå®ƒåªä¼šä»¥æ¦‚ç‡ P æ‰§è¡Œå…¶ä¸­ä¹‹ä¸€ã€‚å› æ­¤ï¼Œå°†åšå¾—æ›´å¤šæˆ–æ›´å°‘ç›¸åŒçš„å˜æ¢ç»„åˆåœ¨ä¸€èµ·æ˜¯æœ‰æ„ä¹‰çš„ï¼Œä»¥é¿å…è¿‡åº¦ä½¿ç”¨ã€‚ä»¥ä¸‹æ˜¯è¯¥å‡½æ•°ï¼š
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: P stands for the chance of something happening. Itâ€™s a value between 0 and 1,
    where 1 means it always happens and 0 never.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: P ä»£è¡¨æŸäº‹å‘ç”Ÿçš„æ¦‚ç‡ã€‚å®ƒæ˜¯ä¸€ä¸ªä»‹äº 0 å’Œ 1 ä¹‹é—´çš„å€¼ï¼Œå…¶ä¸­ 1 è¡¨ç¤ºå®ƒæ€»æ˜¯å‘ç”Ÿï¼Œ0 è¡¨ç¤ºå®ƒä»ä¸å‘ç”Ÿã€‚
- en: 'So, letâ€™s see it in action:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„å®é™…æ•ˆæœï¼š
- en: '![](../Images/e99d22b622bdf6f7bbcae9fbc5a7bb59.png)![](../Images/598a475fa77f1eefe28a95e47e1162d2.png)![](../Images/375968cfdc0a6ec7874d0b48ee5ea3e9.png)![](../Images/d57b638661a531d581e0a8b3fdcd60ea.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e99d22b622bdf6f7bbcae9fbc5a7bb59.png)![](../Images/598a475fa77f1eefe28a95e47e1162d2.png)![](../Images/375968cfdc0a6ec7874d0b48ee5ea3e9.png)![](../Images/d57b638661a531d581e0a8b3fdcd60ea.png)'
- en: augmented text (*Images by author*)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¢å¼ºçš„æ–‡æœ¬ï¼ˆ*å›¾ç‰‡æ¥æºï¼šä½œè€…*ï¼‰
- en: Looks pretty neat, no?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥ç›¸å½“ä¸é”™ï¼Œä¸æ˜¯å—ï¼Ÿ
- en: '**alternative approach:** ğŸŒ®'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¦ä¸€ç§æ–¹æ³•ï¼š** ğŸŒ®'
- en: In the [EASTER 2.0](https://arxiv.org/abs/2205.14879) paper, they came up with
    the [TACo](https://github.com/kartikgill/taco-box) technique. It stand for Tiling
    and Corruption. (ğŸŒ® haha)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ [EASTER 2.0](https://arxiv.org/abs/2205.14879) è®ºæ–‡ä¸­ï¼Œä»–ä»¬æå‡ºäº† [TACo](https://github.com/kartikgill/taco-box)
    æŠ€æœ¯ã€‚å®ƒä»£è¡¨äº† Tiling å’Œ Corruptionã€‚ï¼ˆğŸŒ® å“ˆå“ˆï¼‰
- en: 'It is capable of this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒèƒ½å¤Ÿåšåˆ°è¿™ä¸€ç‚¹ï¼š
- en: '![](../Images/a280195c5c28677c2534bf0d9d10eddd.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a280195c5c28677c2534bf0d9d10eddd.png)'
- en: figure by [Kartik Chaudhary / Raghav Bali](https://github.com/kartikgill/taco-box)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒæ¥æºï¼š[Kartik Chaudhary / Raghav Bali](https://github.com/kartikgill/taco-box)
- en: I have not tried this out because my intuition tells me too much is destroyed
    from the original. In my opinion, if i canâ€™t read it, a computer can neither.
    I might be wrong however, when you consider that as a human, you could guess it
    is â€˜TACOâ€™, if you see â€˜TAâ–ˆOâ€™. We would look at the surrounding letters. and taco
    is a common word. But a computer with a dictionary behind it might make it â€˜TAMOâ€™,
    which happens to be an english word for â€˜japanese ashâ€™*.*
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜æ²¡æœ‰å°è¯•è¿‡ï¼Œå› ä¸ºæˆ‘çš„ç›´è§‰å‘Šè¯‰æˆ‘åŸå§‹æ•°æ®è¢«ç ´åå¾—å¤ªå¤šã€‚ä¾æˆ‘çœ‹ï¼Œå¦‚æœæˆ‘è¯»ä¸å‡ºæ¥ï¼Œè®¡ç®—æœºä¹Ÿè¯»ä¸å‡ºæ¥ã€‚ä¸è¿‡ï¼Œå½“ä½ è€ƒè™‘åˆ°ä½œä¸ºäººç±»ï¼Œä½ å¯ä»¥çŒœæµ‹â€˜TACOâ€™ï¼Œå¦‚æœä½ çœ‹åˆ°â€˜TAâ–ˆOâ€™æ—¶ï¼Œæˆ‘ä»¬ä¼šæŸ¥çœ‹å‘¨å›´çš„å­—æ¯ã€‚è€Œâ€˜tacoâ€™æ˜¯ä¸€ä¸ªå¸¸è§çš„è¯ã€‚ä½†æ˜¯èƒŒåæœ‰å­—å…¸çš„è®¡ç®—æœºå¯èƒ½ä¼šå°†å…¶è¯†åˆ«ä¸ºâ€˜TAMOâ€™ï¼Œè¿™æ°å¥½æ˜¯â€˜japanese
    ashâ€™çš„è‹±æ–‡è¯ã€‚*ã€‚
- en: Conclusion
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Weâ€™ve discussed many image manipulations and how they would be good for the
    task of OCR. I hope this could proof to be useful for you or at least gave you
    some inspiration to try it out yourselves. You can use my recipe as a baseline,
    but youâ€™ll probably need to finetune a few parameters for it to be perfect for
    your dataset. Let me know how much your models have increased in accuracy!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è®¨è®ºäº†è®¸å¤šå›¾åƒå¤„ç†æ–¹æ³•ä»¥åŠå®ƒä»¬å¦‚ä½•å¯¹ OCR ä»»åŠ¡æœ‰ç”¨ã€‚æˆ‘å¸Œæœ›è¿™å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæˆ–è€…è‡³å°‘èƒ½ç»™ä½ ä¸€äº›çµæ„Ÿï¼Œè®©ä½ è‡ªå·±å°è¯•ã€‚ä½ å¯ä»¥ä½¿ç”¨æˆ‘çš„é…æ–¹ä½œä¸ºåŸºç¡€ï¼Œä½†ä½ å¯èƒ½éœ€è¦å¯¹ä¸€äº›å‚æ•°è¿›è¡Œå¾®è°ƒï¼Œä»¥ä½¿å…¶å¯¹ä½ çš„æ•°æ®é›†å®Œç¾ã€‚è®©æˆ‘çŸ¥é“ä½ çš„æ¨¡å‹å‡†ç¡®åº¦æé«˜äº†å¤šå°‘ï¼
- en: I made the technique publicly available in this Jupyter [notebook](https://github.com/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨è¿™ä¸ª Jupyter [notebook](https://github.com/Toon-nooT/notebooks/blob/main/OCR_data_augmentations.ipynb)
    ä¸­å…¬å¼€äº†è¯¥æŠ€æœ¯ã€‚
- en: 'You may also like:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½è¿˜å–œæ¬¢ï¼š
- en: '[](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
    [## Hands-on: document data extraction with ğŸ© transformer'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
    [## å®æ“ï¼šä½¿ç”¨ğŸ© transformer è¿›è¡Œæ–‡æ¡£æ•°æ®æå–'
- en: My experience using donut transformers model to extract invoice indexes.
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨ donut transformers æ¨¡å‹æå–å‘ç¥¨ç´¢å¼•çš„ç»å†ã€‚
- en: toon-beerten.medium.com](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: toon-beerten.medium.com](https://toon-beerten.medium.com/hands-on-document-data-extraction-with-transformer-7130df3b6132?source=post_page-----8013080aa9fa--------------------------------)
- en: 'References:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å‚è€ƒèµ„æ–™ï¼š
- en: '[](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [## Home - OpenCV'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [## ä¸»é¡µ - OpenCV'
- en: OpenCV provides a real-time optimized Computer Vision library, tools, and hardware.
    It also supports model executionâ€¦
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenCV æä¾›äº†ä¸€ä¸ªå®æ—¶ä¼˜åŒ–çš„è®¡ç®—æœºè§†è§‰åº“ã€å·¥å…·å’Œç¡¬ä»¶ã€‚å®ƒè¿˜æ”¯æŒæ¨¡å‹æ‰§è¡Œâ€¦
- en: opencv.org](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [## Albumentations
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: opencv.org](https://opencv.org/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [## Albumentations
- en: Why Albumentations Albumentations is a Python library for fast and flexible
    image augmentations. Albumentationsâ€¦
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆé€‰æ‹© Albumentationsï¼ŸAlbumentations æ˜¯ä¸€ä¸ªç”¨äºå¿«é€Ÿå’Œçµæ´»å›¾åƒå¢å¼ºçš„ Python åº“ã€‚Albumentationsâ€¦
- en: albumentations.ai](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------)
    [## Research Group on Computer Vision and Artificial Intelligence - Computer Vision
    and Artificialâ€¦
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: albumentations.ai](https://albumentations.ai/?source=post_page-----8013080aa9fa--------------------------------)
    [](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------)
    [## è®¡ç®—æœºè§†è§‰ä¸äººå·¥æ™ºèƒ½ç ”ç©¶ç»„ - è®¡ç®—æœºè§†è§‰ä¸äººå·¥æ™ºèƒ½â€¦
- en: The IAM Handwriting Database contains forms of handwritten English text which
    can be used to train and test handwrittenâ€¦
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IAM æ‰‹å†™æ•°æ®åº“åŒ…å«å¯ä»¥ç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ‰‹å†™æ–‡æœ¬çš„è‹±è¯­æ‰‹å†™è¡¨å•â€¦
- en: 'fki.tic.heia-fr.ch](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------)
    [](https://arxiv.org/abs/2205.14879?source=post_page-----8013080aa9fa--------------------------------)
    [## Easter2.0: Improving convolutional models for handwritten text recognition'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[Easter2.0ï¼šæé«˜æ‰‹å†™æ–‡æœ¬è¯†åˆ«çš„å·ç§¯æ¨¡å‹](https://fki.tic.heia-fr.ch/databases/iam-handwriting-database?source=post_page-----8013080aa9fa--------------------------------) '
- en: Convolutional Neural Networks (CNN) have shown promising results for the task
    of Handwritten Text Recognition (HTR) butâ€¦
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åœ¨æ‰‹å†™æ–‡æœ¬è¯†åˆ«ï¼ˆHTRï¼‰ä»»åŠ¡ä¸­å·²æ˜¾ç¤ºå‡ºæœ‰å‰æ™¯çš„ç»“æœï¼Œä½†â€¦
- en: arxiv.org](https://arxiv.org/abs/2205.14879?source=post_page-----8013080aa9fa--------------------------------)
    [](https://github.com/Toon-nooT/notebooks?source=post_page-----8013080aa9fa--------------------------------)
    [## GitHub - Toon-nooT/notebooks
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2205.14879?source=post_page-----8013080aa9fa--------------------------------)'
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab orâ€¦
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½ ç°åœ¨æ— æ³•æ‰§è¡Œè¯¥æ“ä½œã€‚ä½ å·²åœ¨å¦ä¸€ä¸ªæ ‡ç­¾æˆ–çª—å£ä¸­ç™»å½•ã€‚ä½ åœ¨å¦ä¸€ä¸ªæ ‡ç­¾æˆ–çª—å£ä¸­å·²é€€å‡ºâ€¦
- en: github.com](https://github.com/Toon-nooT/notebooks?source=post_page-----8013080aa9fa--------------------------------)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[GitHub - Toon-nooT/notebooks](https://github.com/Toon-nooT/notebooks?source=post_page-----8013080aa9fa--------------------------------)'
