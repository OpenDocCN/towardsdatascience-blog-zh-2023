- en: How to Avoid Being Fooled by Model Accuracy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何避免被模型准确度欺骗
- en: 原文：[https://towardsdatascience.com/how-to-avoid-being-fooled-by-model-accuracy-e26307385fe1](https://towardsdatascience.com/how-to-avoid-being-fooled-by-model-accuracy-e26307385fe1)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-avoid-being-fooled-by-model-accuracy-e26307385fe1](https://towardsdatascience.com/how-to-avoid-being-fooled-by-model-accuracy-e26307385fe1)
- en: A visual guide to binary classification model metrics and their proper usage
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二分类模型指标及其正确使用的视觉指南
- en: '[](https://johnadeojo.medium.com/?source=post_page-----e26307385fe1--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----e26307385fe1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e26307385fe1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e26307385fe1--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----e26307385fe1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johnadeojo.medium.com/?source=post_page-----e26307385fe1--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----e26307385fe1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e26307385fe1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e26307385fe1--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----e26307385fe1--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e26307385fe1--------------------------------)
    ·8 min read·Jul 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e26307385fe1--------------------------------)
    ·阅读时间8分钟·2023年7月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/752a27d99b7d07b9b21cd0e1e97debde.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/752a27d99b7d07b9b21cd0e1e97debde.png)'
- en: 'Image by Author: Generated with Midjourney'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：由 Midjourney 生成
- en: Background — Simple on the Surface
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景 — 表面看起来简单
- en: The metrics used for gauging performance of classification models are fairly
    straightforward, at least from a mathematical standpoint. Nevertheless, I have
    observed that many modellers and data scientists encounter difficulty articulating
    these metrics, and even apply them incorrectly. This is an easy mistake to make,
    as these metrics appear simple on the surface, yet their implications can be profound
    depending on the problem domain.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 用于衡量分类模型性能的指标从数学角度来看相当简单。然而，我发现许多模型构建者和数据科学家在阐述这些指标时遇到困难，甚至应用不当。这个错误很容易出现，因为这些指标在表面上看似简单，但其影响可能在不同问题领域中非常深远。
- en: This article serves as a visual guide to explaining common classification model
    metrics. We will explore definitions and use examples to highlight where metrics
    are used inappropriately.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文作为一个视觉指南，解释了常见分类模型指标。我们将探讨定义，并通过实例突出指标使用不当的情况。
- en: A Brief Note on Visualisation
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于可视化的简要说明
- en: Each visualisation comprises of ninety subjects, representing anything we might
    wish to classify. Blue subjects denote negative samples, whilst red are positive
    samples. The purple box is the model which attempts to predict positive samples.
    Anything inside this box is what the model predicts as positive.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每个可视化包含九十个主题，代表我们可能希望分类的任何事物。蓝色主题表示负样本，而红色表示正样本。紫色框是模型，试图预测正样本。框内的任何内容都是模型预测为正的部分。
- en: With that clarified, let’s delve into the definitions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在澄清这些问题后，让我们深入探讨定义。
- en: Precision & Recall
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精确度与召回率
- en: For many classification tasks there is a trade-off between precision and recall.
    It’s frequently the case that optimising for recall incurs a cost to precision.
    But what do these terms actually mean? Let’s begin with the mathematical definitions,
    and then move onto the visual representations.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多分类任务，精确度和召回率之间存在权衡。优化召回率往往会对精确度产生影响。那么这些术语究竟意味着什么呢？让我们先从数学定义开始，然后转到视觉表示。
- en: Precision = TP/ (TP + FP)
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 精确度 = TP / (TP + FP)
- en: ''
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Recall = TP/(TP + FN)
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 召回率 = TP / (TP + FN)
- en: '*Where TP = Number of true positives, FP = Number of false positives, FN =
    Number of false negatives.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*其中 TP = 真阳性数量，FP = 假阳性数量，FN = 假阴性数量。*'
- en: Let’s focus on the chart directly below in which there are four positive samples.
    Remember, the model’s positive predictions are represented by the box on the chart.
    Observing the chart, we see the model correctly predicts all four positive samples—
    we can see this as all the positive samples sit within the box. We can calculate
    model recall from the chart by counting positive cases within the box (TP = 4)
    divided by the total number of positive cases (TP = 4 + FN = 0).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于下面的图表，其中有四个正样本。记住，模型的正预测由图表上的框表示。观察图表，我们看到模型正确预测了所有四个正样本——我们可以看到所有正样本都位于框内。我们可以通过计算框内的正样本数量（TP
    = 4）除以正样本的总数（TP = 4 + FN = 0）来计算模型召回率。
- en: '*Note FN is 0 because there are no positive cases outside of the box.*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*请注意，FN为0，因为框外没有正样本。*'
- en: '![](../Images/21c5441392a1cafb53f748009e151f5e.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21c5441392a1cafb53f748009e151f5e.png)'
- en: 'Image by Author: Visual Representation of model with 100% recall and 40% precision.
    Model is represented by the purple box.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型的可视化表示，具有100%的召回率和40%的准确率。模型由紫色框表示。
- en: Precision can be explained similarly. It is simply the number of positive cases
    in the box (TP=4) divided by the total number of cases in the box (TP = 4 + FP
    = 6). A straightforward calculation reveals the model’s precision to be just 40%.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率可以类似解释。它只是框内正样本的数量（TP=4）除以框内样本的总数（TP = 4 + FP = 6）。一个简单的计算显示，模型的准确率仅为40%。
- en: You can observe that a model can have a high recall but low precision, and vice
    versa. The chart below shows this, where recall is just 50%, while precision is
    100%. See if you can internalise how to get to these numbers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以观察到，模型可以具有高召回率但低准确率，反之亦然。下面的图表显示了这一点，其中召回率仅为50%，而准确率为100%。看看你是否能理解这些数字的来源。
- en: '*Here is a clue to help you, the number of false negatives is two since there
    are two positive samples outside of the box.*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*这里有个提示帮助你，假阴性数量是2，因为有两个正样本在框外。*'
- en: '![](../Images/73c11298e4cd354608f44fc3e2fc9864.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73c11298e4cd354608f44fc3e2fc9864.png)'
- en: 'Image by Author: Visual Representation of model with 100% Precision and 50%
    Recall. Model is represented as the purple box.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型的可视化表示，具有100%的准确率和50%的召回率。模型以紫色框表示。
- en: False Positive Rates & True Negative Rates
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假阳性率和真负率
- en: 'The false positive rate (FPR) perhaps appears more intuitive, possibly due
    to its name. However, let’s explore the concept in the same way we did for the
    other metrics. Mathematically, we express the FPR as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性率（FPR）也许显得更直观，可能是由于其名称。然而，让我们以与其他指标相同的方式探讨这个概念。从数学上讲，我们将FPR表示如下：
- en: FPR = FP/(FP + TN)
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: FPR = FP/(FP + TN)
- en: '*Here, TN represents the number of true negative subjects.*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*这里，TN表示真正负样本的数量。*'
- en: Examining the first image again, the FPR can be determined by looking at the
    number of negative samples inside the box (FP=6) divided by the total number of
    negative samples (FP=6 + TN=80). For our first image, the false positive rate
    is just 7%, and for the second, it’s 0%. Try figuring out why this is the case.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 再次检查第一个图像，可以通过查看框内负样本的数量（FP=6）除以负样本的总数（FP=6 + TN=80）来确定FPR。在第一个图像中，假阳性率为7%，而在第二个图像中为0%。试着找出为什么会这样。
- en: '*Remember, the subjects inside the box are those that the model* ***predicts***
    *are positive. So by extension, the negative samples outside the box are those
    that the model has identified as negative.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*记住，框内的样本是模型* ***预测*** *为正的样本。所以，框外的负样本就是模型识别为负的样本。*'
- en: 'The true negative rate (TNR) can be computed using the following formula:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 真负率（TNR）可以使用以下公式计算：
- en: TNR = TN/(TN + FP)
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: TNR = TN/(TN + FP)
- en: '*Notice that TNR is always one minus the false positive rate.*'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*请注意，TNR总是等于假阳性率的1减去。*'
- en: Accuracy
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确率
- en: 'Accuracy is a term that is loosely thrown around in the context of model performance,
    but what does it actually mean? Let’s start with the mathematical definition:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是一个在模型性能的上下文中被广泛提及的术语，但它到底是什么意思呢？让我们从数学定义开始：
- en: Accuracy = (TP + TN) / (TP + TN + FP + FN)
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 准确率 = (TP + TN) / (TP + TN + FP + FN)
- en: Using the same logic we previously applied, we can calculate the model’s accuracy
    as 93% for the first image and 97% for the second (see if you can derive this
    for yourself). This might be raising red flags in your mind as to why accuracy
    can be a deceptive metric in some cases. We will explore this in greater detail
    next.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 运用之前的逻辑，我们可以计算出第一个图像的模型准确率为93%，第二个图像的准确率为97%（你可以自己推导出这个结果）。这可能会引发你的疑问：为什么在某些情况下准确率可能是一个具有欺骗性的指标。我们将在接下来的内容中更详细地探讨这个问题。
- en: Using Metrics Correctly
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正确使用指标
- en: Why do we concern ourselves with these metrics? Because they equip us with ways
    to assess the performance of our models. Once we comprehend these metrics, we
    can even determine the commercial value associated with models. This is why it
    is important to have a good intuition around there appropriate (and inappropriate)
    use. To illustrate this, we will briefly investigate the two common scenarios
    in classification tasks, namely balanced and imbalanced datasets.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么要关注这些指标？因为它们为我们提供了评估模型性能的方法。一旦我们理解了这些指标，我们甚至可以确定与模型相关的商业价值。这就是为什么对这些指标的适当（和不适当）使用有良好的直觉是重要的。为了说明这一点，我们将简要探讨分类任务中的两种常见场景，即平衡数据集和不平衡数据集。
- en: Imbalanced Datasets
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不平衡数据集
- en: The diagrams depicted earlier are instances of imbalanced classification tasks.
    Put simply, imbalanced tasks have a low representation of positive subjects compared
    with negative subjects. Many commercial use cases for binary classification fall
    into this category like credit card fraud detection and customer churn prediction,
    spam filtering etc. Selecting the incorrect metrics for imbalanced classification
    can lead you to have over-optimistic beliefs about the performance of your model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 之前描述的图表是**不平衡分类任务**的实例。简单来说，不平衡任务中正样本的表现远低于负样本。许多商业二分类的应用场景，如信用卡欺诈检测、客户流失预测、垃圾邮件过滤等，都属于这一类。选择不适合的不平衡分类指标可能会让你对模型性能有过于乐观的信念。
- en: The primary issue with imbalanced classification is the potential for the number
    of true negative samples to be high, and false negatives to be low. To illustrate,
    let’s consider another model and assess it on our imbalanced data. We can create
    an extreme scenario where the model simply predicts every subject as negative.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 不平衡分类的主要问题在于真正负样本的数量可能很高，而假阴样本的数量很低。为了说明这一点，让我们考虑另一个模型，并在我们的不平衡数据上进行评估。我们可以创建一个极端的场景，其中模型简单地将每个样本都预测为负样本。
- en: '![](../Images/a564ea10aebbec677916263ef6121733.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a564ea10aebbec677916263ef6121733.png)'
- en: 'Image by Author: Visual representation of “non-discriminatory” model predicting
    negative for every subject on an imbalanced dataset'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片：对每个样本在不平衡数据集上预测为负样本的“非区分性”模型的可视化表示
- en: Let’s compute each of the metrics in this scenario.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算这个场景中的每个指标。
- en: '**Accuracy**: *(TP=0 + TN=86)/(TP=0 + TN=86 + FP=0 + FN=4) = 95%*'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确率**: *(TP=0 + TN=86)/(TP=0 + TN=86 + FP=0 + FN=4) = 95%*'
- en: '**Precision**: *(TP=0) /(TP=0 + FP=0) = undefined*'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确率**: *(TP=0) /(TP=0 + FP=0) = 未定义*'
- en: '**Recall**: *(TP=0) / (TP=0 + FN=4) = 0%*'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**: *(TP=0) / (TP=0 + FN=4) = 0%*'
- en: '**FPR**: *(FP=0) / (FP=0 + TN=86) = 0%*'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性率（FPR）**: *(FP=0) / (FP=0 + TN=86) = 0%*'
- en: '**TNR**: *(TN=86) / (TN=86 + FP=0) = 100%*'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正负样本率（TNR）**: *(TN=86) / (TN=86 + FP=0) = 100%*'
- en: The issues with accuracy, FPR and TNR should start to become more apparent.
    When we are working with imbalanced datasets, we can produce a high-accuracy model
    that performs poorly upon deployment. In the previous example, the model has no
    capacity to detect positive subjects but still achieves an accuracy of 95%, A
    0% FPR and a perfect TNR.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率、假阳性率和真正负样本率的问题应当开始变得更加明显。当我们处理不平衡数据集时，可能会产生一个高准确率但在实际应用中表现较差的模型。在之前的例子中，模型没有检测正样本的能力，但仍然获得了95%的准确率、0%的假阳性率和完美的真正负样本率。
- en: Now, imagine deploying such a model to conduct medical diagnostics or detect
    fraud; it would quite evidently be useless and perhaps even dangerous. This extreme
    example illustrates the problem of using metrics such as accuracy, FPR, and TPR
    to assess the performance of models working on imbalanced data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，想象一下将这样的模型用于医学诊断或欺诈检测；显然，它将是无用的，甚至可能是危险的。这个极端的例子说明了使用准确率、假阳性率和真正负样本率等指标来评估在不平衡数据上工作的模型性能的问题。
- en: Balanced Datasets
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平衡数据集
- en: For balanced classification problems, the number of potential true negatives
    is significantly smaller than in the imbalanced case.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平衡分类问题，潜在的真正负样本数量明显少于不平衡情况。
- en: '![](../Images/b0feac1766265cbe79bf05ebb69a82bb.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b0feac1766265cbe79bf05ebb69a82bb.png)'
- en: 'Image by Author: Visual representation of “non-discriminatory” model predicting
    negative for every subject on a balanced dataset'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：在平衡数据集上，“非区分性”模型对每个样本预测负类的可视化表示
- en: 'If we take our “non-discriminatory” model and apply it to the balanced case,
    we obtain the following results:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将“非区分性”模型应用于平衡数据集，我们会得到以下结果：
- en: '**Accuracy**: *(TP=0 + TN=45) / (TP=0 + TN=45 + FP=0 + FN=45) = 50%*'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确率**: *(TP=0 + TN=45) / (TP=0 + TN=45 + FP=0 + FN=45) = 50%*'
- en: '**Precision**: *(TP=0) / (TP=0 + FP=0) = undefined*'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精准度**: *(TP=0) / (TP=0 + FP=0) = 未定义*'
- en: '**Recall**: *(TP=0) / (TP=0 + FN=45) = 0%*'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**: *(TP=0) / (TP=0 + FN=45) = 0%*'
- en: '**FPR**: *(FP=0) / (FP=0 + TN=45) = 0%*'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性率**: *(FP=0) / (FP=0 + TN=45) = 0%*'
- en: '**TNR**: *(TN=45) / (TN=45 + FP=0) = 100%*'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特异度**: *(TN=45) / (TN=45 + FP=0) = 100%*'
- en: While all of the other metrics remain the same, the model’s accuracy has declined
    to 50%, arguably a much more indicative representation of the model’s actual performance.
    Albeit accuracy is still deceptive without precision and recall.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其他所有指标保持不变，但模型的准确率已下降至 50%，这更能反映模型的实际表现。尽管如此，没有精准度和召回率，准确率仍然具有误导性。
- en: ROC Curves vs. Precision-Recall Curves
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ROC 曲线与精准度-召回率曲线
- en: ROC curves are a common approach used to evaluate the performance of binary
    classification models. However, when dealing with imbalanced datasets, they can
    also provide over-optimistic and not entirely meaningful results.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线是评估二分类模型性能的一种常见方法。然而，当处理不平衡数据集时，它们也可能提供过于乐观且不完全有意义的结果。
- en: '***A brief overview of ROC and Precision-Recall curves****: we are essentially
    plotting the classification metrics against each other for different decision
    thresholds. We commonly measure the area under the curve (or AUC), to give us
    an indication of the models performance. Follow the links to learn more about*
    [*ROC*](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc#:~:text=An%20ROC%20curve%20(receiver%20operating,False%20Positive%20Rate)
    *and* [*Precision- Recall Curves*](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)*.*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '***ROC 和精准度-召回率曲线的简要概述***：我们本质上是对不同决策阈值下的分类指标进行对比。我们通常测量曲线下的面积（或 AUC），以给出模型性能的指示。点击链接了解更多关于*
    [*ROC*](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc#:~:text=An%20ROC%20curve%20(receiver%20operating,False%20Positive%20Rate)
    *和* [*精准度-召回率曲线*](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)*的信息。*'
- en: To illustrate how ROC curves can be over optimistic, I have built a classification
    model on a credit card fraud dataset taken from [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).
    The dataset comprises 284,807 transactions, of which 492 are fraudulent.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明 ROC 曲线如何可能过于乐观，我在 [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
    上的信用卡欺诈数据集上构建了一个分类模型。该数据集包含 284,807 笔交易，其中 492 笔为欺诈交易。
- en: '*Note: The data is free to use for commercial and non-commercial purposes without
    permission, as outlined in the* [*Open Data Commons license*](https://opendatacommons.org/licenses/dbcl/1-0/)
    *attributed to the data.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*注：数据可以用于商业和非商业目的，无需许可，详细信息请参见* [*开放数据公共许可证*](https://opendatacommons.org/licenses/dbcl/1-0/)
    *。*'
- en: '![](../Images/714635625769ecff029f475c979d53b3.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/714635625769ecff029f475c979d53b3.png)'
- en: 'Image by Author: ROC Curve on imbalanced dataset'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：不平衡数据集上的 ROC 曲线
- en: Upon examining the ROC curve, we might be led to believe the model performance
    is better than it actually is, since the area under this curve is 0.97\. As we
    have previously seen, the false positive rate can be overly optimistic for imbalanced
    classification problems.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查 ROC 曲线时，我们可能会被误导认为模型的表现优于实际情况，因为这条曲线下的面积为 0.97。正如我们之前看到的，假阳性率对于不平衡的分类问题可能过于乐观。
- en: '![](../Images/0e8c3b3e88b3e3b94211cb37d076a582.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e8c3b3e88b3e3b94211cb37d076a582.png)'
- en: 'Image by Author: Precision-recall curve on imbalanced dataset'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：不平衡数据集上的精准度-召回率曲线
- en: A more robust approach would be to utilise the precision-recall curve. This
    provides a much more robust estimate of our model’s performance. Here we can see
    the area under the precision-recall curve (AUC-PR) is much more conservative at
    0.71.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 更加稳健的方法是使用精准度-召回率曲线。这提供了对模型性能的更稳健的估计。这里我们可以看到，精准度-召回率曲线下的面积（AUC-PR）更加保守，为 0.71。
- en: Taking a balanced version of the dataset where fraudulent and non-fraudulent
    transactions are 50:50, we can see that the AUC and AUC-PR are much closer together.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 采用一个平衡版本的数据集，其中欺诈交易和非欺诈交易的比例为 50:50，我们可以看到 AUC 和 AUC-PR 更加接近。
- en: '![](../Images/8565793fd74edcd5d7ad21e9af3f0bef.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8565793fd74edcd5d7ad21e9af3f0bef.png)'
- en: 'Image by Author: ROC Curve on balanced dataset'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：平衡数据集上的ROC曲线
- en: '![](../Images/751da59649090f65aae00f49d1dc1b37.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/751da59649090f65aae00f49d1dc1b37.png)'
- en: 'Image by Author: Precision-recall curve on balanced dataset'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：平衡数据集上的精确度-召回曲线
- en: The notebook for generating these charts is available in my [GitHub repo](https://github.com/john-adeojo/Precision_Recall_Curves).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成这些图表的笔记本在我的 [GitHub repo](https://github.com/john-adeojo/Precision_Recall_Curves)
    中可以找到。
- en: There are ways to uplift the performance of classification models on imbalanced
    datasets, I explore these in my article on synthetic data.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有方法可以提升分类模型在不平衡数据集上的表现，我在关于合成数据的文章中探讨了这些方法。
- en: '[](/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda?source=post_page-----e26307385fe1--------------------------------)
    [## Can Synthetic Data Boost Machine Learning Performance?'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda?source=post_page-----e26307385fe1--------------------------------)
    [## 合成数据能否提升机器学习性能？'
- en: Investigating the Capability of Synthetic Data to Enhance Model Performance
    on Imbalanced Datasets
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调查合成数据提升模型性能在不平衡数据集上的能力
- en: towardsdatascience.com](/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda?source=post_page-----e26307385fe1--------------------------------)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda?source=post_page-----e26307385fe1--------------------------------)
- en: Conclusion
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Understanding classification model metrics goes beyond the mathematical formulae.
    You should also understand how each metric should be used, and their implications
    for both balanced and imbalanced datasets. As a rule of thumb, metrics that are
    calculated based on true negatives or false negatives may be over optimistic when
    they are applied to imbalanced datasets. I hope this visual tour has given you
    more of an intuition.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 理解分类模型的度量指标超越了数学公式。你还应了解每个指标的使用方式，以及它们在平衡和不平衡数据集上的影响。作为一个经验法则，基于真阴性或假阴性计算的指标在应用于不平衡数据集时可能过于乐观。希望这次视觉之旅能给你更多的直观感受。
- en: I found this visual explanation handy for articulating the approach to my non-technical
    stakeholders. Feel free to share or borrow the approach.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现这种视觉解释对于向我的非技术利益相关者阐述方法非常有用。随意分享或借鉴这种方法。
- en: '*Follow me on* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*关注我在* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/)'
- en: '*Subscribe to medium to get more insights from me:*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*订阅Medium以获取更多我的见解：*'
- en: '[](https://johnadeojo.medium.com/membership?source=post_page-----e26307385fe1--------------------------------)
    [## Join Medium with my referral link — John Adeojo'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johnadeojo.medium.com/membership?source=post_page-----e26307385fe1--------------------------------)
    [## 使用我的推荐链接加入Medium — John Adeojo'
- en: I share data science projects, experiences, and expertise to assist you on your
    journey You can sign up to medium via…
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我分享数据科学项目、经验和专业知识，帮助你在旅途中前进。你可以通过…注册Medium。
- en: johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----e26307385fe1--------------------------------)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----e26307385fe1--------------------------------)
- en: '*Should you be interested in integrating AI or data science into your business
    operations, we invite you to schedule a complimentary initial consultation with
    us:*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你对将AI或数据科学整合到业务运营中感兴趣，我们邀请你安排一次免费的初步咨询：*'
- en: '[](https://www.data-centric-solutions.com/book-online?source=post_page-----e26307385fe1--------------------------------)
    [## Book Online | Data-Centric Solutions'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.data-centric-solutions.com/book-online?source=post_page-----e26307385fe1--------------------------------)
    [## 在线预约 | 数据中心解决方案'
- en: Discover our expertise in helping businesses achieve ambitious goals with a
    free consultation. Our data scientists and…
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过免费的咨询了解我们在帮助企业实现雄心勃勃的目标方面的专业知识。我们的数据科学家和…
- en: www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----e26307385fe1--------------------------------)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----e26307385fe1--------------------------------)
