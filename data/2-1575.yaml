- en: Neural Basis Models for Interpretability
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释性神经基础模型
- en: 原文：[https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2](https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2](https://towardsdatascience.com/neural-basis-models-for-interpretability-fd04ac958ff2)
- en: Unpacking the new interpretable model proposed by Meta AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解读 Meta AI 提出的新解释性模型
- en: '[](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[![Nakul
    Upadhya](../Images/336cb21272e9b1f098177adbde50e92e.png)](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    [Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[![Nakul
    Upadhya](../Images/336cb21272e9b1f098177adbde50e92e.png)](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    [Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    ·6 min read·Oct 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fd04ac958ff2--------------------------------)
    ·6 分钟阅读·2023年10月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The widespread application of Machine Learning and Artificial Intelligence across
    various domains brings about heightened challenges regarding risks and ethical
    assessments. As seen in case studies like the [criminal recidivism model reported
    on by ProPublica,](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
    machine learning algorithms can be incredibly biased and, as a result, robust
    explainability mechanisms are needed to ensure trust and safety when these models
    are deployed in high-stakes areas.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和人工智能在各个领域的广泛应用带来了更高的风险和伦理评估挑战。如在 [ProPublica 报道的刑事再犯模型](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
    中所见，机器学习算法可能存在严重的偏见，因此需要强有力的解释机制，以确保这些模型在高风险领域的信任和安全。
- en: So, how do we balance interpretability with accuracy and model expressivity?
    Well, Meta AI researchers have proposed a new approach they dubbed [Neural Basis
    Models (NBMs)[1]](https://proceedings.neurips.cc/paper_files/paper/2022/hash/37da88965c016dca016514df0e420c72-Abstract-Conference.html),
    a sub-family of generalized additive models that achieve state-of-the-art (SOTA)
    performance on benchmark datasets while retaining glass-box interpretability.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何在解释性、准确性和模型表现力之间取得平衡呢？Meta AI 的研究人员提出了一种新的方法，称为[神经基础模型（NBMs）](https://proceedings.neurips.cc/paper_files/paper/2022/hash/37da88965c016dca016514df0e420c72-Abstract-Conference.html)，这是一种广义加性模型的子家族，在基准数据集上实现了**最先进**的性能，同时保持了**透明的解释性**。
- en: In this article, I aim to explain the NBM and what makes it a beneficial model.
    As usual, I encourage everyone to read the original paper.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我旨在解释 NBM 及其为何是一个有益的模型。像往常一样，我鼓励大家阅读原始论文。
- en: If you’re interested in interpretable machine learning and other aspects of
    ethical AI, consider checking out some of my other articles and following me!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对解释性机器学习和其他伦理 AI 方面感兴趣，考虑查看我的其他文章并关注我！
- en: '![Nakul Upadhya](../Images/e62aa67aa11cd0f9bcd1132257fc3773.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![Nakul Upadhya](../Images/e62aa67aa11cd0f9bcd1132257fc3773.png)'
- en: '[Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----fd04ac958ff2--------------------------------)'
- en: Interpretable and Ethical AI
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解释性与伦理 AI
- en: '[View list](https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d?source=post_page-----fd04ac958ff2--------------------------------)5
    stories![](../Images/3718151c0f72303f3d1c71f54229bc98.png)![](../Images/eddb4279ebae7fc1ba79cf6dcc6ebd5a.png)![](../Images/7def8e23dad656929857f2a488b1f547.png)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d?source=post_page-----fd04ac958ff2--------------------------------)5
    篇故事![](../Images/3718151c0f72303f3d1c71f54229bc98.png)![](../Images/eddb4279ebae7fc1ba79cf6dcc6ebd5a.png)![](../Images/7def8e23dad656929857f2a488b1f547.png)'
- en: 'Background: GAMs'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景：GAMs
- en: NBM is considered a Generalized Additive Model (GAM). GAMs are inherently interpretable
    models that learn a shape function for each feature, and predictions are made
    by “querying” the shape function. Since these shape functions are independent,
    the impact of a feature on the prediction can be understood by visualizing these
    shape functions, making them highly explainable. Interactions between variables
    are modelled by passing multiple variables into the same function and constructing
    the shape function based on that (usually limiting the number of variables to
    2 for interoperability), a configuration that is called a GA2M.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: NBM 被认为是广义加性模型（GAM）。GAM 本质上是可解释的模型，为每个特征学习一个形状函数，预测是通过“查询”形状函数来完成的。由于这些形状函数是独立的，通过可视化这些形状函数可以理解特征对预测的影响，使得模型高度可解释。变量之间的交互通过将多个变量传递到同一函数中并基于此构建形状函数来建模（通常将变量数量限制为
    2 以提高互操作性），这种配置称为 GA2M。
- en: '![](../Images/742a70d6f2f1f6bd50d99c2bca1aab04.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/742a70d6f2f1f6bd50d99c2bca1aab04.png)'
- en: Equations for GAMs and GA2Ms (Figure from Radenovic et al. [1])
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GAMs 和 GA2Ms 的方程（图源自 Radenovic 等人 [1]）
- en: The various GAM and GA2M models use different mechanisms for developing these
    shape functions. The Explainable Boosting Machine (EBM) [2] uses a set of boosted
    trees trained on each feature, Neural Additive Models (NAMs) [3] use a deep neural
    network for each feature, and NODE-GAM [4] uses ensembles of [oblivious neural
    trees](https://medium.com/towards-data-science/node-tabular-focused-neural-trees-ee08c752fcd2)[6].
    I recommend reading the following articles on the [EBM](/the-explainable-boosting-machine-f24152509ebb)
    and [NODE-GAM/NAM](https://medium.com/@chkchang21/interpretable-deep-learning-models-for-tabular-data-neural-gams-500c6ecc0122)
    for a more detailed explanation of these models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 各种 GAM 和 GA2M 模型使用不同的机制来开发这些形状函数。可解释增强机（EBM）[2] 使用一组对每个特征进行训练的提升树，神经加性模型（NAMs）[3]
    对每个特征使用深度神经网络，而 NODE-GAM [4] 使用 [无意识神经树](https://medium.com/towards-data-science/node-tabular-focused-neural-trees-ee08c752fcd2)[6]
    的集合。我推荐阅读以下文章以获得对这些模型的更详细解释：[EBM](/the-explainable-boosting-machine-f24152509ebb)
    和 [NODE-GAM/NAM](https://medium.com/@chkchang21/interpretable-deep-learning-models-for-tabular-data-neural-gams-500c6ecc0122)。
- en: NBM Approach
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NBM 方法
- en: Neural Basis Models (NBM) is a new subfamily of Generalized Additive Models
    (GAMs) that utilizes basis decomposition of shape functions.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 神经基础模型（NBM）是一类新的广义加性模型（GAMs）子家族，利用形状函数的基础分解。
- en: '![](../Images/ca87a05f2e6c1c910d702e09e31938c9.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca87a05f2e6c1c910d702e09e31938c9.png)'
- en: NBM Architecture (Figure from Radenovic et al. [1])
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: NBM 架构（图源自 Radenovic 等人 [1]）
- en: 'Unlike other GAM models (like NAM[3]), which effectively train independent
    models for each feature to construct the shape function, the NBM architecture
    instead relies on a small number of basis functions shared among all features
    and learned jointly for a given task. What are these functions? Well, the Swiss-army
    knife of function approximations: the deep neural network.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他 GAM 模型（如 NAM[3]）不同，后者有效地为每个特征训练独立模型以构建形状函数，而 NBM 架构则依赖于少量的基础函数，这些函数在所有特征中共享，并为特定任务共同学习。这些函数是什么？它们是函数逼近的瑞士军刀：深度神经网络。
- en: Effectively, a common MLP backbone that takes in 1 input and outputs *B* values
    is trained and applied to each input feature. These outputs are then linearly
    combined to form the final prediction for the given feature, and the linear combination
    weights differ for each feature. Another way to think of this architecture is
    through the lens of encoder-decoder networks. All the features share the same
    *encoder* (the common MLP backbone), but each has its own *decoder* (the linear
    transformation of the encoding). The decoded values for each feature are then
    summed together to create the final prediction.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，一个通用的 MLP 主干网络接受 1 个输入并输出 *B* 个值，这些值被训练并应用于每个输入特征。这些输出然后被线性组合以形成给定特征的最终预测，而线性组合的权重对每个特征不同。另一种思考这种架构的方法是通过编码器-解码器网络的视角。所有特征共享相同的
    *编码器*（通用 MLP 主干），但每个特征都有其自己的 *解码器*（编码的线性变换）。每个特征的解码值然后被加总以生成最终预测。
- en: This can easily be extended to include feature interactions as well. If we want
    to model pairwise interactions, we include an MLP that takes two inputs instead
    of one.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以很容易地扩展到包括特征交互。如果我们想要建模配对交互，我们可以包括一个接受两个输入的 MLP，而不是一个。
- en: '![](../Images/223677c0fc646eb67ffc56c432711152.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/223677c0fc646eb67ffc56c432711152.png)'
- en: NBM and NB2M Equations (Figure from Radenovic et al. [1])
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: NBM 和 NB2M 方程（图源自 Radenovic 等人 [1]）
- en: One benefit of using shared MLP backbones instead of different MLPs for each
    feature is the significantly smaller size of the model. This makes the NBM incredibly
    suited to tasks related to extremely high-dimensional data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用共享 MLP 主干而不是为每个特征使用不同的 MLP 的一个好处是模型的显著较小的尺寸。这使得 NBM 非常适合处理极高维度数据的任务。
- en: Performance and Benefits
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能与优势
- en: To test their architecture, Radenovic et al. (2022) compared NBM to various
    other models like Linear Regression, the EBM [2], NAM [3], XGBoost[5], and an
    MLP. Their first evaluation was on a mix of tabular and image datasets.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试他们的架构，Radenovic 等人（2022 年）将 NBM 与各种其他模型进行了比较，如线性回归、EBM [2]、NAM [3]、XGBoost[5]
    和 MLP。他们的首次评估是在混合的表格和图像数据集上进行的。
- en: '![](../Images/6627de5d6dd91ec42eea5363382b0db2.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6627de5d6dd91ec42eea5363382b0db2.png)'
- en: Performance Comparison across Baselines (Figure from Radenovic et al. [1])
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基准性能比较（图来自 Radenovic 等人 [1]）
- en: Overall, the NBM holds its ground, outperforming the other interpretable models
    of the datasets and even outperforming the MLP on some datasets.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，NBM 牢牢站稳脚跟，超越了其他可解释模型，甚至在某些数据集上超过了 MLP。
- en: Radenovic et al. (2022) also did another evaluation on purely tabular datasets,
    focusing on getting a good comparison between SOTA GAM models.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Radenovic 等人（2022 年）还在纯表格数据集上进行了另一项评估，重点是对比 SOTA GAM 模型。
- en: '![](../Images/3d9dbebf2587c6c4e2e6d7d53019b098.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d9dbebf2587c6c4e2e6d7d53019b098.png)'
- en: 'Performance comparison against other GAMS: (Figure from Radenovic et al. [1])'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他 GAMs 的性能比较：（图来自 Radenovic 等人 [1]）
- en: This comparison clearly shows the power of the NBM, beating out the competitors
    in almost every dataset. As mentioned before, the scalability of the NBM is also
    exceptional. As shown below, the number of parameters in an NBM is nearly 70 times
    less than in a NAM for high-dimensional data tasks.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这个比较清楚地展示了 NBM 的强大，几乎在每个数据集上都击败了竞争对手。如前所述，NBM 的可扩展性也非常出色。如下所示，在高维数据任务中，NBM 的参数数量几乎是
    NAM 的 70 分之一。
- en: '![](../Images/4cb1f55b382cb1d68c132d295e0fd895.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cb1f55b382cb1d68c132d295e0fd895.png)'
- en: NAM/NBM Parameter Comparison. X-axis is the dimensionality of the data (Figure
    from Radenovic et al. [1])
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: NAM/NBM 参数比较。X 轴是数据的维度（图来自 Radenovic 等人 [1]）
- en: Conclusion
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Overall, NBMs are incredibly powerful and lightweight models that are inherently
    interpretable due to being a GAM. However, this doesn’t mean it’s a silver-bullet
    solution to high-stakes machine-learning problems. There are still a significant
    number of considerations that need to be taken into account when utilizing these
    models. For one, an inherently interpretable model means almost nothing if the
    [features inputted into the model are not interpretable](https://medium.com/towards-data-science/defining-interpretable-features-ebd7ed94897).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，NBM 是极其强大且轻量级的模型，由于其为 GAM，本质上是可解释的。然而，这并不意味着它是解决高风险机器学习问题的灵丹妙药。在使用这些模型时，仍然需要考虑许多因素。例如，一个本质上可解释的模型几乎没有意义，如果[输入到模型中的特征不可解释](https://medium.com/towards-data-science/defining-interpretable-features-ebd7ed94897)。
- en: Additionally, while the size of NBMs scales well compared to NAMs, the interpretability
    doesn’t. No single human can look at thousands of feature attribution charts,
    especially if those attribution charts also include pairwise interactions. This
    means that pre-processing methods such as feature selection are still needed with
    large parameter spaces, something even the authors acknowledged. However, none
    of this discredits the author, as this is still an incredibly useful model that
    is relatively easy to implement and tune.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，虽然 NBM 的规模相较于 NAM 扩展得很好，但可解释性却没有。没有人能查看数千个特征归因图，特别是当这些归因图还包含成对交互时。这意味着在大参数空间下，仍然需要预处理方法，如特征选择，甚至作者也承认了这一点。然而，这并不贬低作者，因为这是一个仍然非常有用且相对容易实现和调整的模型。
- en: The fact that this model is a GAM is also very nice for machine learning applications
    such as on mobile devices and other non-powerful devices as users can train the
    model and deploy the generated feature attribution functions instead of the full
    model for extremely fast and memory-light inference without any loss in accuracy.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是 GAM 的事实对于机器学习应用（如移动设备和其他性能较低的设备）也非常有利，因为用户可以训练模型并部署生成的特征归因函数，而不是完整模型，从而实现极其快速且内存轻量的推理，而不会损失准确性。
- en: Resources and References
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源与参考文献
- en: 'NBM Code: [https://github.com/facebookresearch/nbm-spam](https://github.com/facebookresearch/nbm-spam)'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NBM代码：[https://github.com/facebookresearch/nbm-spam](https://github.com/facebookresearch/nbm-spam)
- en: 'NBM Open Review: [https://openreview.net/forum?id=fpfDusqKZF](https://openreview.net/forum?id=fpfDusqKZF)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NBM开放评论：[https://openreview.net/forum?id=fpfDusqKZF](https://openreview.net/forum?id=fpfDusqKZF)
- en: 'If you are interested in Interpretable Machine Learning or Time Series Forecasting,
    consider following me: [https://medium.com/@upadhyan](https://medium.com/@upadhyan).'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你对可解释的机器学习或时间序列预测感兴趣，可以考虑关注我：[https://medium.com/@upadhyan](https://medium.com/@upadhyan)。
- en: 'See my other articles on interpretable machine learning: [https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d](https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看我关于可解释机器学习的其他文章：[https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d](https://medium.com/@upadhyan/list/interpretable-and-ethical-ai-f6ee1f0b476d)
- en: '**References**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: '[1] Radenovic, F., Dubey, A., & Mahajan, D. (2022). Neural basis models for
    interpretability. *Advances in Neural Information Processing Systems*, *35*, 8414–8426.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Radenovic, F.、Dubey, A. 和 Mahajan, D.（2022）。用于可解释性的神经基础模型。*神经信息处理系统进展*，*35*，8414–8426。'
- en: '[2] Yin L., Rich C., Johannes G., and Giles H. (2013) Accurate intelligible
    models with pairwise interactions. In *Proceedings of the 19th ACM SIGKDD international
    conference on Knowledge discovery and data mining, 623–631\. 2013*.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Yin L.、Rich C.、Johannes G. 和 Giles H.（2013）准确可理解的模型与配对交互。在*第19届ACM SIGKDD国际会议上的知识发现与数据挖掘论文集，623–631\.
    2013*。'
- en: '[3] Agarwal, R., Melnick, L., Frosst, N., Zhang, X., Lengerich, B., Caruana,
    R., & Hinton, G. E. (2021). Neural additive models: Interpretable machine learning
    with neural nets. *Advances in neural information processing systems*, *34*, 4699–4711.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Agarwal, R.、Melnick, L.、Frosst, N.、Zhang, X.、Lengerich, B.、Caruana, R.
    和 Hinton, G. E.（2021）。神经加性模型：使用神经网络的可解释机器学习。*神经信息处理系统进展*，*34*，4699–4711。'
- en: '[4] Chang, C.H., Caruana, R., & Goldenberg, A. (2022). NODE-GAM: Neural Generalized
    Additive Model for Interpretable Deep Learning. In *International Conference on
    Learning Representations*.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Chang, C.H.、Caruana, R. 和 Goldenberg, A.（2022）。NODE-GAM：用于可解释深度学习的神经广义加性模型。在*国际学习表征会议*。'
- en: '[5] Chen, T., & Guestrin, C. (2016, August). Xgboost: A scalable tree boosting
    system. In *Proceedings of the 22nd ACM SIGKDD international conference on knowledge
    discovery and data mining* (pp. 785–794).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Chen, T. 和 Guestrin, C.（2016年8月）。Xgboost：一个可扩展的树提升系统。在*第22届ACM SIGKDD国际会议上的知识发现与数据挖掘论文集*（第785–794页）。'
- en: '[6] Popov, S., Morozov, S., & Babenko, A. (2019). Neural oblivious decision
    ensembles for deep learning on tabular data. *Eight International Conference on
    Learning Representations.*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Popov, S.、Morozov, S. 和 Babenko, A.（2019）。神经网络忽略决策集成用于表格数据的深度学习。在*第八届国际学习表征会议*。'
