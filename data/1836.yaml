- en: Decoding Strategies in Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è§£ç ç­–ç•¥
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/decoding-strategies-in-large-language-models-9733a8f70539?source=collection_archive---------0-----------------------#2023-06-04](https://towardsdatascience.com/decoding-strategies-in-large-language-models-9733a8f70539?source=collection_archive---------0-----------------------#2023-06-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/decoding-strategies-in-large-language-models-9733a8f70539?source=collection_archive---------0-----------------------#2023-06-04](https://towardsdatascience.com/decoding-strategies-in-large-language-models-9733a8f70539?source=collection_archive---------0-----------------------#2023-06-04)
- en: A Guide to Text Generation From Beam Search to Nucleus Sampling
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»æŸæœç´¢åˆ°æ ¸é‡‡æ ·çš„æ–‡æœ¬ç”ŸæˆæŒ‡å—
- en: '[](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)[![Maxime
    Labonne](../Images/a7efdd305e3cc77d5509bbb1076d57d8.png)](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------)
    [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)[![Maxime
    Labonne](../Images/a7efdd305e3cc77d5509bbb1076d57d8.png)](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------)
    [Maxime Labonne](https://medium.com/@mlabonne?source=post_page-----9733a8f70539--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdc89da634938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&user=Maxime+Labonne&userId=dc89da634938&source=post_page-dc89da634938----9733a8f70539---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------)
    Â·15 min readÂ·Jun 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9733a8f70539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&user=Maxime+Labonne&userId=dc89da634938&source=-----9733a8f70539---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdc89da634938&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&user=Maxime+Labonne&userId=dc89da634938&source=post_page-dc89da634938----9733a8f70539---------------------post_header-----------)
    å‘å¸ƒåœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9733a8f70539--------------------------------)
    Â·15åˆ†é’Ÿé˜…è¯»Â·2023å¹´6æœˆ4æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9733a8f70539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&user=Maxime+Labonne&userId=dc89da634938&source=-----9733a8f70539---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9733a8f70539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&source=-----9733a8f70539---------------------bookmark_footer-----------)![](../Images/8e3084bd4e009d7fb0c6ec5d7aef4aa6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9733a8f70539&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-strategies-in-large-language-models-9733a8f70539&source=-----9733a8f70539---------------------bookmark_footer-----------)![](../Images/8e3084bd4e009d7fb0c6ec5d7aef4aa6.png)'
- en: Image by author.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: In the fascinating world of large language models (LLMs), much attention is
    given to model architectures, data processing, and optimization. However, decoding
    strategies like beam search, which play a crucial role in text generation, are
    often overlooked. In this article, we will explore how LLMs generate text by delving
    into the mechanics of greedy search and beam search, as well as sampling techniques
    with top-k and nucleus sampling.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿·äººçš„ä¸–ç•Œä¸­ï¼Œæ¨¡å‹æ¶æ„ã€æ•°æ®å¤„ç†å’Œä¼˜åŒ–å—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼ŒåƒæŸæœç´¢è¿™æ ·çš„è§£ç ç­–ç•¥åœ¨æ–‡æœ¬ç”Ÿæˆä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œä½†å¸¸è¢«å¿½è§†ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨LLMså¦‚ä½•ç”Ÿæˆæ–‡æœ¬ï¼Œé€šè¿‡å‰–æè´ªå©ªæœç´¢å’ŒæŸæœç´¢çš„æœºåˆ¶ï¼Œä»¥åŠä½¿ç”¨top-kå’Œæ ¸é‡‡æ ·çš„é‡‡æ ·æŠ€æœ¯ã€‚
- en: By the conclusion of this article, youâ€™ll not only understand these decoding
    strategies thoroughly but also be familiar with how to handle important hyperparameters
    like temperature, num_beams, top_k, and top_p.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æœ¬æ–‡ç»“æŸæ—¶ï¼Œä½ å°†ä¸ä»…å½»åº•ç†è§£è¿™äº›è§£ç ç­–ç•¥ï¼Œè¿˜ä¼šç†Ÿæ‚‰å¦‚ä½•å¤„ç†æ¸©åº¦ã€num_beamsã€top_kå’Œtop_pç­‰é‡è¦è¶…å‚æ•°ã€‚
- en: The code for this article can be found on [GitHub](https://github.com/mlabonne/llm-course/blob/main/Decoding_Strategies_in_Large_Language%C2%A0Models.ipynb)
    and [Google Colab](https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing)
    for reference and further exploration.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡çš„ä»£ç å¯ä»¥åœ¨[GitHub](https://github.com/mlabonne/llm-course/blob/main/Decoding_Strategies_in_Large_Language%C2%A0Models.ipynb)å’Œ[Google
    Colab](https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing)ä¸­æ‰¾åˆ°ï¼Œä¾›å‚è€ƒå’Œè¿›ä¸€æ­¥æ¢ç´¢ã€‚
- en: ğŸ“š Background
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ“š èƒŒæ™¯
- en: To kick things off, letâ€™s start with an example. Weâ€™ll feed the text â€œI have
    a dreamâ€ to a GPT-2 model and ask it to generate the next five tokens (words or
    subwords).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¼€å§‹ï¼Œè®©æˆ‘ä»¬ç”¨ä¸€ä¸ªä¾‹å­æ¥è®²è§£ã€‚æˆ‘ä»¬å°†æŠŠæ–‡æœ¬â€œI have a dreamâ€è¾“å…¥åˆ°GPT-2æ¨¡å‹ä¸­ï¼Œå¹¶è¦æ±‚å®ƒç”Ÿæˆæ¥ä¸‹æ¥çš„äº”ä¸ªæ ‡è®°ï¼ˆè¯æˆ–å­è¯ï¼‰ã€‚
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
