- en: Analyze Your Website with NLP and Knowledge Graphs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自然语言处理和知识图谱分析您的网站
- en: 原文：[https://towardsdatascience.com/analyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4?source=collection_archive---------1-----------------------#2023-01-05](https://towardsdatascience.com/analyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4?source=collection_archive---------1-----------------------#2023-01-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/analyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4?source=collection_archive---------1-----------------------#2023-01-05](https://towardsdatascience.com/analyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4?source=collection_archive---------1-----------------------#2023-01-05)
- en: Combine various NLP techniques to construct a knowledge graph representing your
    website
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结合各种自然语言处理技术，构建一个表示您网站的知识图谱
- en: '[](https://bratanic-tomaz.medium.com/?source=post_page-----88e291f6cbf4--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----88e291f6cbf4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----88e291f6cbf4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----88e291f6cbf4--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----88e291f6cbf4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://bratanic-tomaz.medium.com/?source=post_page-----88e291f6cbf4--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----88e291f6cbf4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----88e291f6cbf4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----88e291f6cbf4--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----88e291f6cbf4--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----88e291f6cbf4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----88e291f6cbf4--------------------------------)
    ·14 min read·Jan 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F88e291f6cbf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----88e291f6cbf4---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----88e291f6cbf4---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----88e291f6cbf4--------------------------------)
    · 14分钟阅读 · 2023年1月5日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F88e291f6cbf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----88e291f6cbf4---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F88e291f6cbf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4&source=-----88e291f6cbf4---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F88e291f6cbf4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-your-website-with-nlp-and-knowledge-graphs-88e291f6cbf4&source=-----88e291f6cbf4---------------------bookmark_footer-----------)'
- en: A website is a reflection of the company. For the most part, it is used to inform
    users about various products and services and drive sales. However, the website
    grows and changes over time and many minor and major changes are introduced. As
    a result, it is not uncommon to end up with a disorganized website that fails
    to accomplish its original mission. Therefore, it makes sense to regularly evaluate
    the structure and content of the website to make it as optimized as possible.
    Optimizing websites is a huge business, and consequently, there are multiple commercial
    tools to help you with SEO and other suggestions. However, I will show you how
    you can create a comprehensive and detailed representation of the content on your
    website with a little bit of coding knowledge, which will allow you to analyze
    and improve it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 网站反映了公司。大多数情况下，它用于向用户提供各种产品和服务的信息并推动销售。然而，网站随着时间的推移而增长和变化，许多小的和大的变化被引入。因此，网站最终可能会变得混乱，无法实现其最初的使命。因此，定期评估网站的结构和内容以使其尽可能优化是有意义的。优化网站是一个庞大的业务，因此有多种商业工具可以帮助你进行
    SEO 和其他建议。然而，我将向你展示如何通过一点编码知识创建网站内容的全面而详细的表示，从而允许你分析和改进它。
- en: You can extract the structure of the website using any of the available web
    scrapers. Additionally, it makes sense to not only evaluate the structure but
    also the content of the website by utilizing various natural language processing
    techniques. Since most websites are copyrighted, I have decided to use the Neo4j
    documentation website as an example in this tutorial. The content of the documentation
    website is available under the [CC 4.0 license](https://neo4j.com/docs/license/).
    However, you can apply a similar workflow to any web page you desire.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用任何现有的网络爬虫工具提取网站的结构。此外，利用各种自然语言处理技术评估网站的内容也是有意义的。由于大多数网站是受版权保护的，我决定在本教程中使用
    Neo4j 文档网站作为示例。文档网站的内容在 [CC 4.0 许可证](https://neo4j.com/docs/license/) 下提供。不过，你可以将类似的工作流程应用于任何你希望的网页。
- en: '![](../Images/6ad00f4f0b3e3a40467335675a7bddb2.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ad00f4f0b3e3a40467335675a7bddb2.png)'
- en: Extracting information from documentation to construct a knowledge graph. Image
    by the author.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从文档中提取信息以构建知识图谱。图像由作者提供。
- en: It might seem a bit magical (if you ignore my arrows) how you might construct
    a knowledge graph using information from your website. Throughout this post, I
    aim to bring more clarity to information extraction and provide you with tools
    you can use on your own. I have used similar approaches with [medical documents](/construct-a-biomedical-knowledge-graph-with-nlp-1f25eddc54a0),
    [news](https://medium.com/neo4j/making-sense-of-news-the-knowledge-graph-way-d33810ce5005),
    or even [crypto reports](https://medium.com/neo4j/monitoring-the-cryptocurrency-space-with-nlp-and-knowledge-graphs-92a1cfaebd1a),
    and now we’ll analyze a website with the help of NLP and knowledge graphs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来有点神奇（如果你忽略我的箭头），如何利用你网站上的信息构建知识图谱。在这篇文章中，我旨在为信息提取带来更多的清晰度，并为你提供可以自己使用的工具。我曾经使用类似的方法处理过
    [医疗文档](/construct-a-biomedical-knowledge-graph-with-nlp-1f25eddc54a0)、[新闻](https://medium.com/neo4j/making-sense-of-news-the-knowledge-graph-way-d33810ce5005)
    或甚至 [加密货币报告](https://medium.com/neo4j/monitoring-the-cryptocurrency-space-with-nlp-and-knowledge-graphs-92a1cfaebd1a)，现在我们将利用
    NLP 和知识图谱来分析一个网站。
- en: Data collection and modeling workflow
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据收集和建模工作流程
- en: '![](../Images/8ae215b99d5174684f778dd69e16f5e8.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ae215b99d5174684f778dd69e16f5e8.png)'
- en: Data collection and modeling workflow. Image by the author.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集和建模工作流程。图像由作者提供。
- en: The data collection and preprocessing consist of three parts.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集和预处理分为三个部分。
- en: 'Web scraper: A Python script that walks through the documentation web page
    and collects links and text'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络爬虫：一个 Python 脚本，用于遍历文档网页并收集链接和文本
- en: 'NLP pipeline: Extracts keywords from text and calculate text embeddings to
    detect similar/duplicate content'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NLP 流程：从文本中提取关键词并计算文本嵌入，以检测相似/重复内容
- en: 'Knowledge graph: Store results as a knowledge graph for further analysis'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识图谱：将结果存储为知识图谱以进行进一步分析
- en: The code for the data collection and preprocessing is available [on GitHub as
    a Jupyter notebook](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Preprocessing.ipynb).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集和预处理的代码可在 [GitHub 上的 Jupyter 笔记本](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Preprocessing.ipynb)
    中找到。
- en: '*You don’t have to run the data collection and processing yourself since it
    takes a couple of hours. I have prepared a* [*Neo4j dump*](https://drive.google.com/file/d/1vpQe2gfoPiUVXQpUq-J6Fsjxq5BamyXM/view?usp=sharing)
    *that you can use if you want to follow along with the analysis later in the post.*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*你不需要自己运行数据收集和处理，因为这需要几个小时。我已经准备了一个* [*Neo4j dump*](https://drive.google.com/file/d/1vpQe2gfoPiUVXQpUq-J6Fsjxq5BamyXM/view?usp=sharing)
    *，如果你想跟随文章中的分析，可以使用这个数据。*'
- en: '**Web scraper**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**网页抓取器**'
- en: I usually use [Python Selenium](https://selenium-python.readthedocs.io/) for
    web scraping, but you can use any of other libraries or languages you want to
    extract relevant information from websites. I won’t go into too many details about
    the code, as the goal of this post is not to teach you how to scrape websites.
    However, you can examine the [Jupyter notebook](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Preprocessing.ipynb)
    that handles the web scraping.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我通常使用[Python Selenium](https://selenium-python.readthedocs.io/)进行网页抓取，但你可以使用任何其他库或语言来从网站中提取相关信息。我不会详细介绍代码，因为这篇文章的目标不是教你如何抓取网站。然而，你可以查看处理网页抓取的[Jupyter
    notebook](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Preprocessing.ipynb)。
- en: Specifically for the Neo4j documentation website, I avoided scraping the links
    from the left and top navigation bars as that would introduce much noise in the
    graph since most of the pages have the same navigation bars present.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Neo4j文档网站，我避免抓取左侧和顶部导航栏的链接，因为这会在图中引入大量噪音，因为大多数页面都有相同的导航栏。
- en: '![](../Images/bf41ce13ef482afed63dfc518a87ae2f.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf41ce13ef482afed63dfc518a87ae2f.png)'
- en: Links from navigation bars are ignored during scraping. Image by the author.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在抓取过程中会忽略导航栏中的链接。图片由作者提供。
- en: With the Neo4j documentation website, I wanted to capture how a user could traverse
    the documentation without using the navigation bar. Otherwise, we would introduce
    noise in the knowledge graph as all the pages would be linking to the same pages
    in the navigation bars. Additionally, I have focused on extracting text and links
    from only documentation web pages, so some product or marketing pages were not
    scraped for their content.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Neo4j文档网站中，我希望捕捉到用户如何在不使用导航栏的情况下遍历文档。否则，我们将引入噪音，因为所有页面都会链接到导航栏中的相同页面。此外，我专注于从文档网页中提取文本和链接，因此一些产品或营销页面的内容没有被抓取。
- en: '**Natural language processing**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**自然语言处理**'
- en: The natural language processing step involves extracting keywords and calculating
    text embeddings to detect similar and duplicate content. Before even considering
    training your own NLP model, it is always a good idea to check the [HuggingFace
    model repository](https://huggingface.co/models) and see if any publically available
    models are a good fit for your use case.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理步骤包括提取关键词和计算文本嵌入，以检测相似和重复的内容。在考虑训练自己的NLP模型之前，查看[HuggingFace模型库](https://huggingface.co/models)是否有任何公开可用的模型适合你的用例总是一个好主意。
- en: After a bit of research, I have found a [keyword extraction model](https://huggingface.co/yanekyuk/bert-uncased-keyword-extractor)
    made available by **Yankı Ekin Yüksel** that we will use. I really love how simple
    it is to load and run a model using transformers and HuggingFace.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些研究，我发现了一个由**Yankı Ekin Yüksel**提供的[关键词提取模型](https://huggingface.co/yanekyuk/bert-uncased-keyword-extractor)。我非常喜欢使用transformers和HuggingFace加载和运行模型的简单性。
- en: The following code loads the keyword extraction model and prepares a NLP pipeline.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码加载关键词提取模型并准备一个NLP流水线。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You don’t have to download models or worry about file paths. Instead, you can
    simply define the model name as the argument of the tokenizer and the model, and
    the transformers library does all the work for you.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要下载模型或担心文件路径。相反，你可以简单地将模型名称定义为tokenizer和模型的参数，transformers库会为你完成所有工作。
- en: The pipeline returns tokens, which are not necessarily a word. Therefore, we
    need to construct the words back from tokens after the NLP pipeline finishes.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线返回的令牌不一定是一个单词。因此，我们需要在NLP流水线完成后从令牌构建回单词。
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The example shows that the model extracted **cloud computing**, **vmware**,
    and **broadcom** from the given text. The results seem fitting for our use case
    as we are analyzing the Neo4j documentation, which should contain many technological
    keywords.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例展示了模型从给定文本中提取了**云计算**、**vmware**和**broadcom**。这些结果似乎非常适合我们的用例，因为我们正在分析Neo4j文档，其中应该包含许多技术关键词。
- en: Next, we also need to calculate text embeddings that will help us identify similar
    and duplicate content. Again, I’ve search the HuggingFace model repository a bit
    and came across a [sentence transformers model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
    that can be used to identify similar sentences or paragraphs. Again, the model
    can be loaded and used with as little as three lines of codes.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们还需要计算文本嵌入，以帮助我们识别相似和重复的内容。我在HuggingFace模型库中搜索了一下，发现了一个可以用来识别相似句子或段落的[句子变换模型](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)。此外，该模型只需三行代码即可加载和使用。
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We need to convert the result to a float of lists as Neo4j Driver doesn’t support
    NumPy arrays.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将结果转换为浮点数列表，因为Neo4j Driver不支持NumPy数组。
- en: '**Knowledge graph construction**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**知识图谱构建**'
- en: After the web scraper and natural language processing steps are done, we can
    go ahead and construct a knowledge graph. You might have already guessed that
    we are going to be using Neo4j to store our knowledge graph. You can use a [free
    cloud instance](https://neo4j.com/cloud/platform/aura-graph-database/) or setup
    a [local environment](https://neo4j.com/download/).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成网页抓取和自然语言处理步骤后，我们可以继续构建知识图谱。你可能已经猜到，我们将使用Neo4j来存储我们的知识图谱。你可以使用[免费云实例](https://neo4j.com/cloud/platform/aura-graph-database/)或设置[本地环境](https://neo4j.com/download/)。
- en: The graph schema after the initial import is defined as the following.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 初始导入后的图形模式定义如下。
- en: '![](../Images/65579d768a46deaf64679cbfb3fb339e.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65579d768a46deaf64679cbfb3fb339e.png)'
- en: Initial graph schema. Image by the author.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 初始图形模式。图像由作者提供。
- en: In the center of our graph are web pages. We know their URL address, text embedding
    value, and whether or not the web scraper extracted text from the page. Pages
    can also link or redirect to other pages, which is represented with according
    relationship. As a part of the NLP workflow, we have also detected keywords on
    the site, which we will store as separate nodes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们图表的中心是网页。我们知道它们的URL地址、文本嵌入值，以及网页抓取工具是否提取了页面文本。页面还可以链接或重定向到其他页面，这通过相应的关系表示。作为NLP工作流的一部分，我们还检测了网站上的关键词，并将其作为单独的节点存储。
- en: Check out the [preprocessing notebook](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Preprocessing.ipynb)
    if you are interested in the code implementation of the data import. Otherwise,
    we will jump straight to the network analysis part.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对数据导入的代码实现感兴趣，可以查看[预处理笔记本](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Preprocessing.ipynb)。否则，我们将直接进入网络分析部分。
- en: '**Network Analysis**'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**网络分析**'
- en: '*I have prepared a* [*Neo4j database dump*](https://drive.google.com/file/d/1vpQe2gfoPiUVXQpUq-J6Fsjxq5BamyXM/view?usp=sharing)
    *if you don’t want to scrape the Neo4j documentation but would still like to follow
    the network analysis examples.*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*我准备了一个* [*Neo4j数据库转储*](https://drive.google.com/file/d/1vpQe2gfoPiUVXQpUq-J6Fsjxq5BamyXM/view?usp=sharing)
    *，如果你不想抓取Neo4j文档但仍想跟随网络分析示例，可以使用这个转储。*'
- en: '![](../Images/26d47caa8d619cfe56d2ce2b2c1d69f7.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26d47caa8d619cfe56d2ce2b2c1d69f7.png)'
- en: Sample subgraph of the Neo4j documentation website knowledge graph. Image by
    the author.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j文档网站知识图谱的样本子图。图像由作者提供。
- en: I will walk you through some website network analysis examples that I found
    interesting. We will be using the [Graph Data Science Python](https://neo4j.com/docs/graph-data-science/current/python-client/)
    client, which is ideal tool to perform network analysis with Neo4j from Python.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我将带你了解一些我认为有趣的网站网络分析示例。我们将使用[图数据科学Python](https://neo4j.com/docs/graph-data-science/current/python-client/)客户端，这是一个理想的工具，可以用来从Python进行Neo4j网络分析。
- en: The Jupyter Notebook with all the relevant code for the network analysis is
    [available on GitHub](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Analysis.ipynb).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 包含所有相关网络分析代码的Jupyter Notebook[可在GitHub上获得](https://github.com/tomasonjo/blogs/blob/master/neo4jdocs/Analysis.ipynb)。
- en: '**Overall statistics**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**总体统计数据**'
- en: First of, we will begin by evaluating the size of our dataset by counting the
    number of nodes and relationships with the `apoc.meta.stats` procedure.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将通过使用`apoc.meta.stats`过程来评估数据集的大小，统计节点和关系的数量。
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Our knowledge graph has 15370 pages and 4199 keywords, along with 62365 links
    and 723 redirects. I was not expecting this many pages. However, considering that
    the documentation covers multiple products across multiple versions, it makes
    sense that the number of pages on a website can explode. Additionally, many links
    point to pages outside the Neo4j website.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的知识图谱包含 15370 页和 4199 个关键字，还有 62365 个链接和 723 个重定向。我没有预料到这么多页面。然而，考虑到文档涵盖了多个产品的多个版本，网站上的页面数量激增是有意义的。此外，许多链接指向
    Neo4j 网站外的页面。
- en: Next, we will evaluate from how many pages we successfuly retrieved content
    information.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将评估从多少页面成功检索到内容信息。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have successfully retrieved the content and calculated text embeddings from
    9688 web pages. The web scraper focused on recovering content from the documentation
    website while mostly ignoring the structure and text of the product and similar
    pages. Therefore, there are 2972 on the Neo4j website for which we haven’t retrieved
    content. Finally, the Neo4j website links to 2710 outside its primary domain.
    Pages outside of the Neo4j documentation website were explicitly ignored during
    web scraping.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功检索了 9688 个网页的内容并计算了文本嵌入。网络爬虫专注于从文档网站中恢复内容，同时大多忽略了产品和类似页面的结构和文本。因此，Neo4j
    网站上有 2972 个我们尚未检索到内容的页面。最后，Neo4j 网站链接到其主要域外的 2710 个页面。在网络爬虫过程中，Neo4j 文档网站外的页面被明确忽略。
- en: Out of curiosity, we can list ten random outside web pages that Neo4j links
    to the most.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 出于好奇，我们可以列出 Neo4j 最常链接的十个随机外部网页。
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*Results*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*结果*'
- en: The most linked web page is actually a localhost URL, which is the default address
    of the Neo4j Browser. Following are some links to APOC releases on GitHub. Finally,
    it seems that Neo4j has some products or services that support integrations with
    Microsoft NLP and AWS cloud APIs, as otherwise, they probably wouldn’t link them
    in their documentation.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最常链接的网页实际上是一个本地 URL，即 Neo4j 浏览器的默认地址。以下是一些 GitHub 上 APOC 发布的链接。最后，看起来 Neo4j
    有一些支持与微软 NLP 和 AWS 云 API 集成的产品或服务，否则他们可能不会在文档中链接这些内容。
- en: '**Identify dead links**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**识别死链**'
- en: We will proceed by identifying dead or broken links. A broken link is a link
    that points to a non-existing web page. Like most websites, Neo4j documentation
    has a designated 404 web page. The web scraper assigns a “404” text value to any
    URL that responds with a 404 page.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过识别死链或损坏的链接来进行处理。损坏的链接是指指向不存在网页的链接。与大多数网站一样，Neo4j 文档有一个指定的 404 网页。网络爬虫将“404”文本值分配给任何响应
    404 页面的 URL。
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There are 241 broken links in the dataset. The broken link number sounds small,
    given that there is a total of 62 thousand links in the database. However, if
    you performed this analysis on your website, you could always forward the results
    to the appropriate teams to get the links fixed.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有 241 个损坏的链接。考虑到数据库中总共有 62 千个链接，损坏的链接数量听起来很少。然而，如果你在你的网站上执行了此分析，你可以将结果转发给相关团队以修复这些链接。
- en: '**Finding shortest paths**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**查找最短路径**'
- en: Most websites are designed to gently push the users along the journey to the
    end goal. For example, if you are running an e-commerce website, the goal is probably
    a purchase event. With Neo4j, you can analyze all the paths a user might follow
    to reach the desired destination. Since we are dealing with a documentation website,
    we can’t explore how a user might end up completing a purchase on the website.
    However, we can apply the same techniques and evaluate the shortest paths between
    various parts of the website.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数网站的设计旨在轻轻推动用户沿着路径到达最终目标。例如，如果你经营一个电子商务网站，那么目标可能是购买事件。借助 Neo4j，你可以分析用户可能遵循的所有路径，以到达期望的目的地。由于我们处理的是文档网站，我们无法探讨用户如何最终完成网站上的购买。然而，我们可以应用相同的技术，评估网站各部分之间的最短路径。
- en: The following code finds all the shortest paths between the two given web pages.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码查找两个给定网页之间的所有最短路径。
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The results show that a user must traverse the following web pages in order
    to reach the Aura console page from the documentation home:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，用户必须遍历以下网页才能从文档主页到达 Aura 控制台页面：
- en: '[https://neo4j.com/docs](https://neo4j.com/docs,)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://neo4j.com/docs](https://neo4j.com/docs,)'
- en: '[https://neo4j.com/docs/aura/auradb](https://neo4j.com/docs/aura/auradb,)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://neo4j.com/docs/aura/auradb](https://neo4j.com/docs/aura/auradb,)'
- en: '[https://neo4j.com/docs/aura/auradb/getting-started/create-database](https://neo4j.com/docs/aura/auradb/getting-started/create-database,)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://neo4j.com/docs/aura/auradb/getting-started/create-database](https://neo4j.com/docs/aura/auradb/getting-started/create-database,)'
- en: '[https://console.neo4j.io](https://console.neo4j.io)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://console.neo4j.io](https://console.neo4j.io)'
- en: Representing your website as a knowledge graph can significantly improve the
    understanding of designed flows throughout your web page, which in turn can help
    you optimize them.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将你的网站表示为知识图谱可以显著提高对网页设计流程的理解，从而帮助你优化它们。
- en: '**Link analysis**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**链接分析**'
- en: Next, we will use centrality algorithms to rank the importance of the web pages.
    For example, let’s say we simply define the rank of web pages as the number of
    incoming links. In that case, we can utilize the Degree centrality algorithm to
    rank the importance of the web pages.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用中心性算法对网页的重要性进行排名。例如，假设我们简单地将网页的排名定义为传入链接的数量。在这种情况下，我们可以利用度中心性算法来对网页的重要性进行排名。
- en: To execute any graph algorithms from the [Graph Data Science library](https://neo4j.com/product/graph-data-science/),
    we have first to project an in-memory graph.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行[图数据科学库](https://neo4j.com/product/graph-data-science/)中的任何图算法，我们首先需要在内存中投影一个图。
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: With the Graph Data Science library projection, you have the option to choose
    a specific subgraph of your knowledge graph you want to evaluate with graph algorithms.
    In this example, we selected the **Page** nodes and **LINKS_TO** and **REDIRECTS**
    relationships. For simplicity’s sake, we will treat the links and redirects as
    identical. However, for more in-depth network analysis, we could define some weights
    and perhaps treat redirects as more important than links.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图数据科学库的投影功能，你可以选择要用图算法评估的知识图谱的特定子图。在这个例子中，我们选择了**Page**节点和**LINKS_TO**及**REDIRECTS**关系。为了简便起见，我们将链接和重定向视为相同。然而，进行更深入的网络分析时，我们可以定义一些权重，也许将重定向视为比链接更重要。
- en: The following code will calculate the incoming degree centrality, which is simply
    the number of incoming links or redirects a web page has.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将计算传入度中心性，即网页所拥有的传入链接或重定向的数量。
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'One thing to note here is that we are using the Graph Data Science Python Client
    to interact with the database, so the syntax might be slightly different if you
    are used to Cypher procedure calls. The results are the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，我们使用了图数据科学Python客户端与数据库进行交互，因此如果你习惯于Cypher过程调用，语法可能会略有不同。结果如下：
- en: The developer knowledge base page has 598 incoming links. Many links also point
    to specific tags of the developer blog and graph gists. I would assume that tons
    of documentation sites point to specific examples which can be found in blogs
    of graph gists. If we were to understand the intended flow more, we could drill
    down where the links are coming from and so on.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者知识库页面有598个传入链接。许多链接也指向开发者博客和图形摘要的特定标签。我认为，许多文档网站都指向可以在图形摘要的博客中找到的具体示例。如果我们要更好地理解预期流程，我们可以深入分析这些链接的来源等。
- en: Sometimes the number of incoming links is not a sufficient ranking metric. The
    founders of Google were aware of this issue as they derived the most famous graph
    algorithm, PageRank, which takes into account the number of incoming links and
    where they are coming from. For example, there is a difference if the web page
    has a direct link from the home page or some periphery documentation page that
    only some people visit.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 有时传入链接的数量不足以作为排名指标。Google的创始人意识到这个问题，因此他们提出了最著名的图算法PageRank，它考虑了传入链接的数量及其来源。例如，如果网页直接链接自主页或仅有少数人访问的外围文档页面，则有所不同。
- en: The following code will calculate the PageRank score and merge it with the degree
    dataframe.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码将计算PageRank分数并将其与度数据框合并。
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now we can examine the top five most important web pages judging by the PageRank
    score.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以根据PageRank分数检查前五个最重要的网页。
- en: The score column represent the number of incoming links and redirects, while
    the pagerank columns hold the PageRank score.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 得分列表示传入链接和重定向的数量，而PageRank列则保存PageRank分数。
- en: Interestingly, only the developer knowledge base page retains its position when
    using PageRank instead of Degree centrality. It seems that GraphConnect was vital
    as it is still the second most important web page. As a web UX designer, you might
    take this information and try to change the structure of the website so that perhaps
    the latest GraphConnect would be more important. Remember, we are only scratching
    the surface with this network analysis. However, you could find interesting patterns
    and then drill down to understand the web page flow and optimize it.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，只有开发者知识库页面在使用 PageRank 而不是度中心性时保留了其位置。看来 GraphConnect 非常重要，因为它仍然是第二个最重要的网页。作为一名网页
    UX 设计师，你可以利用这些信息尝试更改网站结构，以便最新的 GraphConnect 可能会更重要。记住，我们只是对这个网络分析进行了初步探索。然而，你可以找到有趣的模式，然后深入了解网页流程并进行优化。
- en: '**Keyword analysis and co-occurrence topic clustering**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键字分析和共现主题聚类**'
- en: In the last part of this analysis, we will take a look at the keyword analysis.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次分析的最后部分，我们将查看关键字分析。
- en: '![](../Images/d05668d1485566abd2d6977f4cc1a65d.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d05668d1485566abd2d6977f4cc1a65d.png)'
- en: Graph representation of web pages and their keywords. Image by the author.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 网页及其关键字的图形表示。图像由作者提供。
- en: Having the right keywords on the right web pages is one of the critical aspects
    of search engine optimization. We can get a high-level overview of the page by
    examining its most frequent keywords.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在正确的网页上拥有合适的关键字是搜索引擎优化的关键方面之一。通过检查页面上最频繁的关键字，我们可以获得页面的高层次概述。
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Results*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*结果*'
- en: The results look exactly what we might expect. The web page talks about nodes,
    neo4j, graphs, and Java. Not sure why the clipboard is there. Perhaps there are
    a lot of “Copy to clipboard” sections throughout the documentation.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 结果看起来正是我们预期的。网页讨论了节点、neo4j、图表和 Java。不确定为什么会有剪贴板。也许文档中有很多“复制到剪贴板”的部分。
- en: We can drill down a bit and look at the most frequent keywords for web pages
    where the “graph-data-science” is present in the URL address. This way, we filter
    primarily for Neo4j Graph Data Science library documentation.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以稍微深入，查看 URL 地址中包含“graph-data-science”的网页上最频繁的关键字。通过这种方式，我们主要筛选出 Neo4j 图数据科学库文档。
- en: '[PRE12]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '*Results*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*结果*'
- en: It looks very similar to the overall keyword presence, except the keyword “algorithm”
    shows up more frequently here. Now, we could go ahead and drill down keywords
    by other sections or by individual pages. A knowledge graph is a fantastic tool
    for either drill-down analysis or to analyze the distribution of keywords and
    content through designated user flows. Additionally, if you used an NLP model
    that is able to detect both short- and long-tail keywords, it would greatly help
    with any SEO analysis and optimization.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来与整体关键字存在情况非常相似，只是“algorithm”这个关键字在这里出现得更频繁。现在，我们可以继续通过其他部分或单独页面深入挖掘关键字。知识图谱是进行深入分析或通过指定的用户流程分析关键字和内容分布的绝佳工具。此外，如果你使用了能够检测短尾和长尾关键字的
    NLP 模型，这将大大有助于 SEO 分析和优化。
- en: Lastly, we can also perform a keyword co-occurrence clustering with only a couple
    of lines of code. A keyword co-occurrence clustering can be understood as a task
    of identifying topics, where the topics consist of multiple keywords that frequently
    co-occur in the text corpus.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还可以只用几行代码执行关键字共现聚类。关键字共现聚类可以理解为识别主题的任务，其中主题由文本语料库中频繁共现的多个关键字组成。
- en: '![](../Images/d729bfd6b956be3df688b531b7b0cae0.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d729bfd6b956be3df688b531b7b0cae0.png)'
- en: Diagram of the co-occurrence topic clustering output. Image by the author.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 关键字共现主题聚类输出的示意图。图像由作者提供。
- en: 'The workflow of the keyword co-occurrence clustering or topic clustering in
    Neo4j is the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j 中关键字共现聚类或主题聚类的工作流程如下：
- en: Project an in-memory graph with relevant information.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 投影一个包含相关信息的内存图。
- en: Create a CO_OCCUR relationship between keyword that commonly appear together
    in text.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 CO_OCCUR 关系，以便在文本中常常一起出现的关键字之间建立联系。
- en: Run a community detection algorithm like the Louvain method to identify communities
    or clusters of keywords.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行像 Louvain 方法这样的社区检测算法来识别关键字的社区或集群。
- en: We will begin by projecting an in-memory graph with all the relevant information.
    We need to project both the Page and the Keyword nodes along with the connecting
    HAS_KEYWORD relationship. We need to reverse the relationship orientation in the
    graph projection as we want to examine clusters of co-occurring keywords and not
    groups of similar web pages.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始通过投影一个包含所有相关信息的内存图。我们需要投影Page和Keyword节点以及连接的HAS_KEYWORD关系。由于我们要检查共同出现的关键词集群，而不是相似网页的组，因此我们需要在图投影中反转关系的方向。
- en: '*P.s. If you leave the natural orientation and follow the examples you will
    identify clusters of similar web pages based on the keywords they mention*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*附注：如果你离开自然方向并按照示例进行操作，你将根据提到的关键词识别出相似网页的集群*'
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Next, we need to create a **CO_OCCUR** relationship between keywords frequently
    appearing together on web pages. To solve this task, we will use the Node Similarity
    algorithm. The Node Similarity uses the [Jaccard similarity coefficient](https://en.wikipedia.org/wiki/Jaccard_index)
    by default to calculate the similarity between two nodes.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要在经常一起出现的关键词之间创建**CO_OCCUR**关系。为了解决这个任务，我们将使用Node Similarity算法。Node Similarity默认使用[Jaccard相似系数](https://en.wikipedia.org/wiki/Jaccard_index)来计算两个节点之间的相似性。
- en: In this example, each keyword has a set of web pages it is mentioned in. If
    the Jaccard coefficient between a pair of keywords based on the web pages they
    appear in is greater than 0.40, then a new **CO_OCCUR** relationship is created
    between them. We use the mutate mode to store the algorithm’s results back to
    the in-memory projected graph.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，每个关键词都有一组包含它的网页。如果基于网页的关键词对之间的Jaccard系数大于0.40，则会在它们之间创建一个新的**CO_OCCUR**关系。我们使用变异模式将算法的结果存储回内存中的投影图。
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Finally, we will use the Louvain method algorithm, a community detection algorithm,
    to identify clusters of keywords. The algorithm outputs each node and its community
    id. Therefore, we need to group the results by their community id to create a
    list of keywords that form a topic or a cluster.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将使用Louvain方法算法，一个社区检测算法，来识别关键词的集群。该算法输出每个节点及其社区ID。因此，我们需要根据社区ID对结果进行分组，以创建形成主题或集群的关键词列表。
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*Results*'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*结果*'
- en: '![](../Images/f7fcca075382867620c5b7a9c8eb250a.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7fcca075382867620c5b7a9c8eb250a.png)'
- en: Since the topic clustering workflow we followed is an unsupervised technique,
    we need to manually assign overall topic names. For example, we can observe that
    the first and largest topic contains keywords like chewbacca, jedi, christmas
    day, independence day, and so on. It is a an interesting mix of holidays and Star
    Wars. We could explore why both holidays and Star Wars are mixed together. Additionally,
    the second largest topic seems to talk about various panama and paradise papers
    along with the companies and people involved.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们遵循的主题聚类工作流程是一种无监督技术，我们需要手动分配总体主题名称。例如，我们可以观察到第一个最大主题包含chewbacca、jedi、christmas
    day、independence day等关键词。这是一个有趣的节日与星球大战的混合。我们可以探索为什么节日和星球大战混合在一起。此外，第二大主题似乎谈论了各种panama和paradise
    papers以及涉及的公司和人物。
- en: Summary
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In my opinion, knowledge graphs and natural language processing techniques are
    a match made in heaven. As mentioned, I have seen similar approaches to analyzing
    [medical documents](/construct-a-biomedical-knowledge-graph-with-nlp-1f25eddc54a0),
    [news](https://medium.com/neo4j/making-sense-of-news-the-knowledge-graph-way-d33810ce5005),
    or even [crypto reports](https://medium.com/neo4j/monitoring-the-cryptocurrency-space-with-nlp-and-knowledge-graphs-92a1cfaebd1a).
    The idea is to use NLP and other tools to extract valuable information from unstructured
    data, which is then used to construct a knowledge graph. A knowledge graph offers
    a friendly and flexible structure of the extracted information that can be used
    to support various analytical workflows.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，知识图谱和自然语言处理技术是天作之合。如前所述，我见过类似的方法来分析[医学文档](/construct-a-biomedical-knowledge-graph-with-nlp-1f25eddc54a0)、[新闻](https://medium.com/neo4j/making-sense-of-news-the-knowledge-graph-way-d33810ce5005)甚至[加密报告](https://medium.com/neo4j/monitoring-the-cryptocurrency-space-with-nlp-and-knowledge-graphs-92a1cfaebd1a)。这个想法是使用NLP和其他工具从非结构化数据中提取有价值的信息，然后用于构建知识图谱。知识图谱提供了一种友好且灵活的提取信息的结构，可用于支持各种分析工作流程。
- en: All the code of this blog post is [available on GitHub](https://github.com/tomasonjo/blogs/tree/master/neo4jdocs).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本博客文章的所有代码都可以在[GitHub](https://github.com/tomasonjo/blogs/tree/master/neo4jdocs)上找到。
