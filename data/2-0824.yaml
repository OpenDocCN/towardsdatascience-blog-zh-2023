- en: Essential Evaluation Metrics for Classification Problems in Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的分类问题关键评估指标
- en: 原文：[https://towardsdatascience.com/essential-evaluation-metrics-for-classification-problems-in-machine-learning-69e90665375b](https://towardsdatascience.com/essential-evaluation-metrics-for-classification-problems-in-machine-learning-69e90665375b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/essential-evaluation-metrics-for-classification-problems-in-machine-learning-69e90665375b](https://towardsdatascience.com/essential-evaluation-metrics-for-classification-problems-in-machine-learning-69e90665375b)
- en: A Comprehensive Guide to Understanding and Evaluating the Performance of Classification
    Models
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解和评估分类模型性能的全面指南
- en: '[](https://aaron-zhu.medium.com/?source=post_page-----69e90665375b--------------------------------)[![Aaron
    Zhu](../Images/42e9690c4b4aad63f396b171a74e29f7.png)](https://aaron-zhu.medium.com/?source=post_page-----69e90665375b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----69e90665375b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----69e90665375b--------------------------------)
    [Aaron Zhu](https://aaron-zhu.medium.com/?source=post_page-----69e90665375b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://aaron-zhu.medium.com/?source=post_page-----69e90665375b--------------------------------)[![Aaron
    Zhu](../Images/42e9690c4b4aad63f396b171a74e29f7.png)](https://aaron-zhu.medium.com/?source=post_page-----69e90665375b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----69e90665375b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----69e90665375b--------------------------------)
    [Aaron Zhu](https://aaron-zhu.medium.com/?source=post_page-----69e90665375b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----69e90665375b--------------------------------)
    ·10 min read·Mar 10, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----69e90665375b--------------------------------)
    ·阅读时长 10 分钟·2023年3月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f1067a61f9cd203144c29c260ca6388d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1067a61f9cd203144c29c260ca6388d.png)'
- en: Photo by [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Markus Winkler](https://unsplash.com/@markuswinkler?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Are you confused about the terms used in evaluating the performance of machine
    learning models? Do you get lost in the sea of confusion when you come across
    the terms confusion matrix, precision, recall, specificity and sensitivity? Well,
    worry no more, because in this blog post we will dive deep into these evaluation
    metrics and help you make sense of these terms.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否对评估机器学习模型性能时使用的术语感到困惑？当遇到混淆矩阵、精确度、召回率、特异性和敏感性等术语时，是否会感到迷茫？别担心，因为在这篇博客文章中，我们将深入探讨这些评估指标，帮助你理解这些术语。
- en: What is a Confusion Matrix?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是混淆矩阵？
- en: 'Let’s start with the confusion matrix. It is a table that is used to evaluate
    the performance of a classification model. It contains four values: true positives
    (**TP**), true negatives (**TN**), false positives (**FP**) and false negatives
    (**FN**). A true positive is when the model correctly predicts the positive class,
    a true negative is when the model correctly predicts the negative class, a false
    positive is when the model predicts the positive class but it is actually negative,
    and a false negative is when the model predicts the negative class but it is actually
    positive.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从混淆矩阵开始。它是用于评估分类模型性能的表格。它包含四个值：真正例 (**TP**)、真负例 (**TN**)、假正例 (**FP**) 和假负例
    (**FN**)。真正例是指模型正确预测正类，真负例是指模型正确预测负类，假正例是指模型预测为正类但实际为负类，假负例是指模型预测为负类但实际为正类。
- en: '![](../Images/e858e19e7cdb87ed020d37c10bf86638.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e858e19e7cdb87ed020d37c10bf86638.png)'
- en: Image by author
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者
- en: What is Accuracy?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是准确率？
- en: '**Accuracy** is a measure of how well a model is performing overall. It is
    the proportion of correct predictions made by the model out of all the predictions
    made. In other words, it is the number of true positives and true negatives divided
    by the total number of predictions.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率** 是衡量模型总体表现的指标。它是模型做出的正确预测占所有预测总数的比例。换句话说，它是正确预测的正例和负例数量除以预测总数。'
- en: Accuracy = (TP+TN)/(TP+TN+FP+FN)
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 准确率 = (TP+TN)/(TP+TN+FP+FN)
- en: What is Precision?
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是精确度？
- en: '**Precision** is a measure of how accurate the positive predictions of a model
    are. It is calculated as the ratio of true positives to the sum of true positives
    and false positives. A high precision indicates that the model correctly predicts
    the positive class most of the time.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**Precision** 是衡量模型正例预测准确度的指标。它的计算方法是将真正例的数量与真正例和假正例的总和之比。高 Precision 表明模型大多数时间正确预测了正类。'
- en: Precision = TP / (TP + FP)
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Precision = TP / (TP + FP)
- en: What is Recall?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 Recall？
- en: '**Recall** is a measure of how well the model is able to identify the positive
    class. It is calculated as the ratio of true positives to the sum of true positives
    and false negatives. A high recall indicates that the model is able to identify
    most of the positive instances.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**Recall** 是衡量模型识别正类能力的指标。它的计算方法是将真正例的数量与真正例和假负例的总和之比。高 Recall 表明模型能够识别大多数正实例。'
- en: Recall = TP / (TP + FN)
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Recall = TP / (TP + FN)
- en: What is Specificity?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 Specificity？
- en: '**Specificity** is a measure of how well the model is able to identify the
    negative class. It is calculated as the ratio of true negatives to the sum of
    true negatives and false positives. A high specificity indicates that the model
    is able to identify most of the negative instances.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**Specificity** 是衡量模型识别负类能力的指标。它的计算方法是将真正例的数量与真正例和假正例的总和之比。高 Specificity 表明模型能够识别大多数负实例。'
- en: Specificity = TN / (TN + FP)
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Specificity = TN / (TN + FP)
- en: You may think of specificity as the recall with a different definition of the
    positive and negative labels, i.e., the positive label is considered negative,
    and the negative label is considered positive.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将 Specificity 视为带有不同正负标签定义的 Recall，即正标签被视为负，负标签被视为正。
- en: What is Sensitivity?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 Sensitivity？
- en: '**Sensitivity** is another term used for recall, especially in medical contexts
    where it refers to the ability of a medical test to detect a disease or condition
    in people who actually have the disease or condition.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sensitivity** 是 Recall 的另一种术语，特别是在医学背景下，它指的是医学测试在实际患病的个体中检测疾病或情况的能力。'
- en: Sensitivity = TP / (TP + FN)
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Sensitivity = TP / (TP + FN)
- en: 'Summary Table:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总结表：
- en: '![](../Images/fa901f75f5c2167956718a5bf5ab86e7.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa901f75f5c2167956718a5bf5ab86e7.png)'
- en: Image by author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: When is Precision-Recall a better measure than Accuracy?
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么时候 Precision-Recall 比准确率更好的指标？
- en: Precision-Recall is used instead of accuracy when the data is **imbalanced**,
    meaning there are significantly more samples of one class than the other.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Precision-Recall 用于数据**不平衡**时，而不是准确率，这意味着一个类别的样本显著多于另一个类别。
- en: In such cases, accuracy can be misleading, as a model can achieve high accuracy
    by simply predicting the majority class. For example, in a binary classification
    problem with 90% of the samples belonging to the negative class, a model that
    always predicts negative will have an accuracy of 90%, even if it is not making
    any correct positive predictions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，准确率可能会产生误导，因为模型可以通过简单地预测多数类来实现高准确率。例如，在一个二分类问题中，如果 90% 的样本属于负类，那么一个总是预测负类的模型将有
    90% 的准确率，即使它没有进行任何正确的正例预测。
- en: When the data is imbalanced, we could have a model with very high accuracy.
    But the model is useless because of low precision-recall values.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当数据不平衡时，我们可能会有一个准确率非常高的模型。但由于 Precision-Recall 值低，模型是无用的。
- en: Precision-Recall is a better measure of a model’s performance in such cases
    because it takes into account the proportion of true positives and true negatives,
    as well as false positives and false negatives, which are more critical in imbalanced
    datasets. Precision measures the proportion of true positive predictions made
    out of all positive predictions made, while recall measures the proportion of
    true positive predictions made out of all actual positive samples.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Precision-Recall 是在这种情况下衡量模型性能的更好指标，因为它考虑了真正例和假正例的比例，以及假负例和真正例，这些在不平衡数据集中更为关键。Precision
    衡量的是所有正例预测中真正例预测的比例，而 Recall 衡量的是所有实际正例样本中真正例预测的比例。
- en: Precision-Recall is more suitable for evaluating the performance of a model
    in imbalanced datasets, while accuracy is more appropriate when the classes are
    balanced.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Precision-Recall 更适合用于评估不平衡数据集中的模型性能，而准确率在类别平衡时更为合适。
- en: What is Precision-Recall Trade-off?
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 Precision-Recall 权衡？
- en: Ideally, we would like to have both high precision and high recall for our model.
    Achieving both simultaneously often is not possible.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望我们的模型具有高精确度和高召回率。通常很难同时实现这两者。
- en: The Precision-Recall trade-off arises because optimizing one metric often comes
    at the expense of the other.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 精确度-召回率权衡的出现是因为优化一个指标通常会以另一个指标为代价。
- en: Here is why
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为什么
- en: If a model is more conservative in its predictions, it may achieve a **higher
    precision** by reducing the number of false positives, but this may also result
    in a lower recall, since it may miss some true positive instances.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个模型在预测中更为保守，它可能通过减少假阳性的数量来实现**更高的精确度**，但这也可能导致召回率降低，因为它可能会遗漏一些真实的正例。
- en: Conversely, suppose a model is more aggressive in its predictions. In that case,
    it may achieve a **higher recall** by capturing more true positive instances,
    but this may also result in a lower precision, since it may make more false positive
    predictions.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相反，假设一个模型在预测中更为激进。在这种情况下，它可能通过捕获更多的真实正例来实现**更高的召回率**，但这也可能导致精确度降低，因为它可能会产生更多的假阳性预测。
- en: Therefore, to determine whether we should prioritize the precision or recall
    value, we need to evaluate the cost of false positives and false negatives.
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 因此，为了确定我们应该优先考虑精确度还是召回率，我们需要评估假阳性和假阴性的成本。
- en: In case 1, a medical test is designed to detect a disease in people.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在情况1中，设计了一种医学检测测试来检测人们是否患有疾病。
- en: The cost of false negative cases might be — patients who are sick don’t receive
    the right treatment, which might cause more people to be infected if the disease
    is contagious.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阴性案例的成本可能是——病人未能接受正确的治疗，如果疾病具有传染性，可能导致更多人感染。
- en: On the other hand, the cost of false positive cases might be — wasting resources
    treating healthy people and unnecessarily quarantining themselves.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，假阳性案例的成本可能是——浪费资源治疗健康人群，并不必要地将其隔离。
- en: Therefore, the cost of false negative cases is much higher than the cost of
    false positive cases. In this case, paying more attention to the recall value
    makes more sense.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，假阴性案例的成本远高于假阳性案例的成本。在这种情况下，更关注召回率更为合理。
- en: '![](../Images/97c0aae8ec053fb3877a5a79f3186269.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97c0aae8ec053fb3877a5a79f3186269.png)'
- en: Image by author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: In case 2, a bank designs an ML model to detect credit card fraud.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在情况2中，一家银行设计了一个机器学习模型来检测信用卡欺诈。
- en: The cost of false negative cases might be — the bank loses money on the fraudulent
    transactions.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阴性案例的成本可能是——银行在欺诈交易中损失金钱。
- en: The cost of false positive cases might be — the false fraud alert hurts the
    customers’ experience, which causes a decrease in customer retention.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性案例的成本可能是——虚假的欺诈警报影响了客户体验，导致客户留存率下降。
- en: Therefore, the cost of false positive cases is much higher than the cost of
    false negative cases. Based on a study about credit card fraud, false-positive
    credit card fraud costs 13 times more in lost income than true fraud. In this
    case, paying more attention to the precision value makes more sense.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，假阳性案例的成本远高于假阴性案例的成本。根据关于信用卡欺诈的研究，假阳性信用卡欺诈的损失收入是实际欺诈的13倍。在这种情况下，更关注精确度更为合理。
- en: '![](../Images/48f9e0833e14b9e5418e7fb251a72254.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48f9e0833e14b9e5418e7fb251a72254.png)'
- en: Image by author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: What is F1-Score?
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是F1-Score？
- en: In the above examples, we try to prioritize either recall or precision at the
    expense of the other measure. But there are also many situations, where both **recall
    and precision are** **equally important**. In such cases, we should use another
    measure, called F1 score.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，我们尝试优先考虑召回率或精确度，但这可能以牺牲另一个指标为代价。然而，也有许多情况，其中**召回率和精确度是** **同等重要的**。在这种情况下，我们应使用另一种度量标准，称为F1分数。
- en: The **F1 score** takes into account both precision and recall, and provides
    a single score that summarizes the model’s overall performance. It ranges from
    0 to 1, with a score of 1 indicating perfect precision and recall.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**F1分数**考虑了精确度和召回率，并提供一个总结模型整体表现的单一分数。其范围从0到1，得分为1表示完美的精确度和召回率。'
- en: 'The formula for calculating the F1 score is:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 计算F1分数的公式是：
- en: '![](../Images/0890623c7974fe4e87d056c37fec34ad.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0890623c7974fe4e87d056c37fec34ad.png)'
- en: 'It can also be calculated as the harmonic mean of precision and recall:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以通过精确度和召回率的调和平均数来计算：
- en: '![](../Images/2b7b4a6d57e8f811b81d6374b0477584.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b7b4a6d57e8f811b81d6374b0477584.png)'
- en: What are Receiver Operating Characteristic Curve (ROC Curve) and **Area Under
    the Curve** (**AUC**)?
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接收者操作特征曲线（ROC曲线）和**曲线下面积**（**AUC**）是什么？
- en: A Receiver Operating Characteristic (ROC) Curve is a graphical representation
    of the performance of a binary classification model that predicts the probability
    of an event occurring. The ROC curve is created by plotting the true positive
    rate (TPR) against the false positive rate (FPR) at **various threshold** settings.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接收者操作特征（ROC）曲线是二分类模型性能的图形表示，它预测事件发生的概率。ROC曲线是通过将真正例率（TPR）与假正例率（FPR）在**不同阈值**设置下绘制出来的。
- en: TPR=TP/(TP+FN)
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: TPR=TP/(TP+FN)
- en: ''
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: FPR=FP/(FP+TN)
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: FPR=FP/(FP+TN)
- en: Let’s consider an example of a binary classification problem where we want to
    predict whether an email is spam or not spam. Let’s say we have a model that predicts
    the **probability** that an email is spam, and we want to use an ROC curve to
    evaluate its performance.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个二分类问题的例子，我们希望预测一封电子邮件是否是垃圾邮件。假设我们有一个模型，它预测电子邮件是垃圾邮件的**概率**，我们希望使用ROC曲线来评估其性能。
- en: To create the ROC curve, we need to set a **threshold** value (i.e., from 0
    to 1) for the predicted probability above which we classify an email as spam,
    and below which we classify it as not spam. The threshold value is a decision
    boundary that determines the trade-off between the true positive rate (TPR) and
    the false positive rate (FPR).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建ROC曲线，我们需要设置一个**阈值**（即从0到1），根据这个阈值我们将电子邮件分类为垃圾邮件，低于这个阈值则分类为非垃圾邮件。阈值是决定真正例率（TPR）和假正例率（FPR）之间权衡的决策边界。
- en: For example, if we set the threshold to 0.5, then any email with a predicted
    probability greater than 0.5 would be classified as spam, and any email with a
    predicted probability less than or equal to 0.5 would be classified as not spam.
    This threshold value would give us a certain TPR and FPR.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们将阈值设置为0.5，则任何预测概率大于0.5的电子邮件将被分类为垃圾邮件，而任何预测概率小于或等于0.5的电子邮件将被分类为非垃圾邮件。这个阈值会给我们一定的TPR和FPR。
- en: In general, as the threshold increases, TPR and FPR decrease. In the most extreme
    case, when the threshold value is 0, all predicted values are positive, therefore,
    TPR=FPR=1\. Conversely, when the threshold value is 1, all predicted values are
    negative, therefore, TPR=FPR=0.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，随着阈值的增加，TPR和FPR都会减少。在最极端的情况下，当阈值为0时，所有预测值都是正的，因此TPR=FPR=1。相反，当阈值为1时，所有预测值都是负的，因此TPR=FPR=0。
- en: 'Suppose that, for a given dataset, we calculate the TPR and FPR for **various
    threshold values**, and we get the following results:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 假设对于给定的数据集，我们计算了**各种阈值**下的TPR和FPR，得到如下结果：
- en: '![](../Images/37721065980b5ead2dbf5a1ac5516358.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37721065980b5ead2dbf5a1ac5516358.png)'
- en: Image by author
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: 'We can plot these values on an ROC curve, with TPR on the y-axis and FPR on
    the x-axis, as shown below:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些值绘制在ROC曲线上，y轴为TPR，x轴为FPR，如下所示：
- en: '![](../Images/a88c859d3bd567bacab8bc6e49c0e459.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a88c859d3bd567bacab8bc6e49c0e459.png)'
- en: Image by author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: As we can see from the plot, the ROC curve is a trade-off between the TPR and
    FPR for different threshold values.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以看出，ROC曲线是不同阈值下TPR和FPR之间的权衡。
- en: The **area under the curve** (**AUC**) measures the overall performance of the
    model, with an AUC of 1 indicating perfect performance, and an AUC of 0.5 indicating
    random guessing (i.e., the diagonal line which represents a classifier making
    random predictions).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**曲线下面积**（**AUC**）衡量模型的整体性能，AUC为1表示完美的性能，AUC为0.5表示随机猜测（即表示随机预测的对角线）。'
- en: 'Key takeaways of ROC:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ROC的主要要点：
- en: ROC works better in evaluating different models when the classes are **balanced**
    and the cost of false positives and false negatives are similar. The higher the
    AUC-ROC is, the better the model.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当类别**平衡**且假正例和假负例的成本相似时，ROC在评估不同模型时效果更好。AUC-ROC值越高，模型越好。
- en: From the ROC, we can pick the **optimal threshold value**, which depends on
    how the classifier is intended to be applied — if the cost of false positives
    and false negatives are similar, the threshold that is close to the upper left
    corner of the ROC is the optimal value. If the cost of false positives and false
    negatives is higher, we can pick a higher threshold value. Conversely, if the
    cost of false negatives and false positives is higher, we can pick a lower threshold
    value.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从ROC曲线中，我们可以选择**最佳阈值**，这取决于分类器的应用目的——如果假阳性和假阴性的成本相似，那么接近ROC曲线左上角的阈值是最佳的。如果假阳性和假阴性的成本较高，我们可以选择较高的阈值。相反，如果假阴性和假阳性的成本较高，我们可以选择较低的阈值。
- en: ROC is **threshold-invariant**. It measures the performance of a model across
    a range of thresholds. It means we don’t need to determine a threshold using ROC
    in advance, unlike precision, recall, accuracy, and F1 score which are based on
    a specific threshold.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROC是**阈值不变的**。它测量了模型在一系列阈值下的表现。这意味着我们不需要提前使用ROC确定阈值，与基于特定阈值的精确度、召回率、准确性和F1分数不同。
- en: What is Precision-Recall Curve (PRC)?
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是精确度-召回曲线（PRC）？
- en: In contrast to the ROC curve that plots TPR and FPR, the Precision-Recall Curve
    (PRC) curve plots precision on the y-axis and recall on the x-axis. The PRC curve
    shows how well the model can identify positive cases while avoiding false positives.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 与绘制TPR和FPR的ROC曲线相比，精确度-召回曲线（PRC）在y轴上绘制精确度，在x轴上绘制召回率。PRC曲线显示了模型在识别正例时如何避免假阳性。
- en: The area under the PRC curve can measure the performance of a model. The higher
    the AUC-PRC, the better the model. A model with an AUC-PRC of 0.5 is no better
    than random guessing, while a model with an AUC-PRC of 1.0 is perfect.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: PRC曲线下面积可以衡量模型的性能。AUC-PRC值越高，模型越好。AUC-PRC为0.5的模型不比随机猜测好，而AUC-PRC为1.0的模型是完美的。
- en: In general, as the threshold increases, the precision would increase and the
    recall would decrease. In the most extreme case, when the threshold value is 0,
    all predicted values are positive, therefore, recall = 1 and precision = 0\. Conversely,
    when the threshold value is 1, all predicted values are negative, therefore, recall
    = 0 and precision = 1.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，随着阈值的增加，精确度会提高，而召回率会降低。在最极端的情况下，当阈值为0时，所有预测值都是正值，因此，召回率=1，精确度=0。相反，当阈值为1时，所有预测值都是负值，因此，召回率=0，精确度=1。
- en: 'Suppose that, for a given dataset, we calculate the precision and recall for
    **various threshold values**, and we get the following results:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 假设对于给定的数据集，我们计算了**各种阈值**下的精确度和召回率，并得到了以下结果：
- en: '![](../Images/e687e008df1fd8694d5fd10614dc1a7a.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e687e008df1fd8694d5fd10614dc1a7a.png)'
- en: Image by author
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '![](../Images/63201c9b57f1ad33a72e5a8d8594152b.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63201c9b57f1ad33a72e5a8d8594152b.png)'
- en: Image by author
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Key takeaways of PRC:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: PRC的关键要点：
- en: The choice between ROC and PRC curves depends on the problem at hand. The ROC
    curve is useful when the classes are balanced and the cost of false positives
    and false negatives are similar. The PRC curve is useful when the classes are
    imbalanced or the cost of false positives and false negatives are different.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在ROC和PRC曲线之间的选择取决于当前的问题。当类别平衡且假阳性和假阴性的成本相似时，ROC曲线是有用的。PRC曲线在类别不平衡或假阳性和假阴性的成本不同的情况下很有用。
- en: By looking at the PRC, you can choose an **optimal threshold** that balances
    precision and recall according to your specific use case.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过查看PRC，你可以选择一个**最佳阈值**，根据你的具体使用案例平衡精确度和召回率。
- en: We’ve covered many evaluation metrics for classification problems. These metrics
    are interrelated, and each has its strengths and weaknesses in measuring the model’s
    accuracy. Overall, understanding these metrics is crucial in developing effective
    machine learning models and making informed decisions based on their predictions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经覆盖了许多分类问题的评估指标。这些指标是相互关联的，每个指标在衡量模型准确性方面都有其优缺点。总体而言，理解这些指标对于开发有效的机器学习模型并根据预测做出明智的决策至关重要。
- en: 'If you would like to explore more posts related to **Statistics**, please check
    out my articles:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多与**统计学**相关的文章，请查看我的文章：
- en: '[**Type I & II Errors and Sample Size Calculation in Hypothesis Testing**](/type-i-ii-errors-and-sample-size-calculation-in-hypothesis-testing-760dae42a065)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**假设检验中的I型和II型错误及样本量计算**](/type-i-ii-errors-and-sample-size-calculation-in-hypothesis-testing-760dae42a065)'
- en: '[**7 Most Asked Questions on Central Limit Theorem**](/7-most-asked-questions-on-central-limit-theorem-82e95eb7d964)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**中心极限定理的7个常见问题**](/7-most-asked-questions-on-central-limit-theorem-82e95eb7d964)'
- en: '[**Standard Deviation vs Standard Error: What’s the Difference?**](/standard-deviation-vs-standard-error-whats-the-difference-ae969f48adef)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**标准差与标准误差：有什么区别？**](/standard-deviation-vs-standard-error-whats-the-difference-ae969f48adef)'
- en: '[**3 Most Common Misinterpretations: Hypothesis Testing, Confidence Interval,
    P-Value**](/the-most-common-misinterpretations-hypothesis-testing-confidence-interval-p-value-4548a10a5b72)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**3种最常见的误解：假设检验、置信区间、P值**](/the-most-common-misinterpretations-hypothesis-testing-confidence-interval-p-value-4548a10a5b72)'
- en: '[**Are the Error Terms Normally Distributed in a Linear Regression Model?**](/are-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**线性回归模型中的误差项是否服从正态分布？**](/are-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4)'
- en: '[**Are the OLS Estimators Normally Distributed in a Linear Regression Model?**](/are-ols-estimators-normally-distributed-in-a-linear-regression-model-89b688fa8dc3)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**线性回归模型中的OLS估计量是否服从正态分布？**](/are-ols-estimators-normally-distributed-in-a-linear-regression-model-89b688fa8dc3)'
- en: '[**What is Regularization: Bias-Variance Tradeoff**](/machine-learning-bias-variance-tradeoff-and-regularization-94846f945131)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**什么是正则化：偏差-方差权衡**](/machine-learning-bias-variance-tradeoff-and-regularization-94846f945131)'
- en: '[**Variance vs Covariance vs Correlation: What is the Difference?**](https://medium.com/geekculture/variance-vs-covariance-vs-correlation-what-is-the-difference-95adff96d542)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**方差与协方差与相关性：有什么区别？**](https://medium.com/geekculture/variance-vs-covariance-vs-correlation-what-is-the-difference-95adff96d542)'
- en: '[**Confidence Interval vs Prediction Interval: What is the Difference?**](/confidence-interval-vs-prediction-interval-what-is-the-difference-64c45146d47d)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**置信区间与预测区间：有什么区别？**](/confidence-interval-vs-prediction-interval-what-is-the-difference-64c45146d47d)'
- en: '[**Which is Worse, Type I or Type II errors?**](https://medium.com/geekculture/which-is-worse-type-i-or-type-ii-errors-f40a0f040fcc)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**哪种错误更糟糕，I型错误还是II型错误？**](https://medium.com/geekculture/which-is-worse-type-i-or-type-ii-errors-f40a0f040fcc)'
- en: Thank you for reading!
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: 'If you enjoy this article, please click the **Clap** icon. If you would like
    to see more articles from me and thousands of other writers on Medium. You can:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，请点击**掌声**图标。如果你想看到我和其他数千位作者在Medium上的更多文章，你可以：
- en: '[**Subscribe**](https://aaron-zhu.medium.com/subscribe) to my newsletter to
    get an email notification whenever I post a new article.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**订阅**](https://aaron-zhu.medium.com/subscribe)我的新闻通讯，以便在我发布新文章时收到邮件通知。'
- en: Sign up for a [**membership**](https://aaron-zhu.medium.com/membership) to unlock
    full access to everything on Medium.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册成为[**会员**](https://aaron-zhu.medium.com/membership)以解锁对Medium上所有内容的完全访问权限。
