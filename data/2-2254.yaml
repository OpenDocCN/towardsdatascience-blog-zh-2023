- en: 'SMOTE and Other Options: A Comprehensive Guide to Handling Imbalanced Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SMOTE 和其他选项：处理不平衡数据的综合指南
- en: 原文：[https://towardsdatascience.com/use-smote-with-caution-3fa015ba3bc5](https://towardsdatascience.com/use-smote-with-caution-3fa015ba3bc5)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/use-smote-with-caution-3fa015ba3bc5](https://towardsdatascience.com/use-smote-with-caution-3fa015ba3bc5)
- en: The guide on when to use and when not to use synthetic data to tackle the class
    imbalance
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于何时使用和何时不使用合成数据来解决类别不平衡问题的指南
- en: '[](https://ransakaravihara.medium.com/?source=post_page-----3fa015ba3bc5--------------------------------)[![Ransaka
    Ravihara](../Images/ac09746938c10ad8f157d46ea0de27ca.png)](https://ransakaravihara.medium.com/?source=post_page-----3fa015ba3bc5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3fa015ba3bc5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3fa015ba3bc5--------------------------------)
    [Ransaka Ravihara](https://ransakaravihara.medium.com/?source=post_page-----3fa015ba3bc5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ransakaravihara.medium.com/?source=post_page-----3fa015ba3bc5--------------------------------)[![Ransaka
    Ravihara](../Images/ac09746938c10ad8f157d46ea0de27ca.png)](https://ransakaravihara.medium.com/?source=post_page-----3fa015ba3bc5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3fa015ba3bc5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3fa015ba3bc5--------------------------------)
    [Ransaka Ravihara](https://ransakaravihara.medium.com/?source=post_page-----3fa015ba3bc5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3fa015ba3bc5--------------------------------)
    ·10 min read·Jan 3, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3fa015ba3bc5--------------------------------)
    ·10分钟阅读·2023年1月3日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7bbfd0409f31269de20f9ae943cb9fd2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7bbfd0409f31269de20f9ae943cb9fd2.png)'
- en: Photo by [은 하](https://unsplash.com/@b0nn13_4nd_clyd3?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [은 하](https://unsplash.com/@b0nn13_4nd_clyd3?utm_source=medium&utm_medium=referral)
    提供，出处 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: If you are a machine learning practitioner, you may face class imbalance problems
    more often. Class imbalance happens when there is a different class distribution
    in the dataset. Let's take an example. Assume we are working on a churn problem.
    In this specific scenario, our minor and majority classes are customer churn,
    and the customer stays with the current service provider. But if you explore this
    problem more, you will notice fewer customers for the churn category because customer
    churn is an infrequent event that is good for business but not for the model.
    As a result, if we feed this dataset into the model, it will learn the majority
    pattern (non-churn scenario) more accurately than the minor scenario. This is
    where our problem begins.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一名机器学习从业者，你可能会更频繁地遇到类别不平衡问题。类别不平衡发生在数据集中类别分布不均的情况。例如，假设我们正在处理流失问题。在这个特定场景下，我们的少数类和多数类分别是客户流失和客户继续留在当前服务提供商。但是，如果你深入探索这个问题，你会发现流失类别的客户较少，因为客户流失是一个对业务有利但对模型不利的不频繁事件。因此，如果我们将这个数据集输入模型，它将比少数类别（流失场景）更准确地学习到多数类别（非流失场景）。这就是我们问题的开始。
- en: How to deal with the class imbalance in machine learning
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何处理机器学习中的类别不平衡
- en: 'The most obvious answer is since model interaction with the minor class during
    training is less, we can improve that by adding more minor classes to the model.
    But how? We have a few methods:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最明显的答案是由于模型在训练过程中与少数类的交互较少，我们可以通过向模型中添加更多少数类数据来改善这一点。但是怎么做呢？我们有几种方法：
- en: Collecting more data for the minor class — This is a theoretically easy and
    practically infeasible solution. Because it's hard to do this while covering the
    business's actual needs, as an example, we may have to change the logic to get
    more customers into the churn category.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集更多的少数类数据——这是一个理论上简单但在实践中不可行的解决方案。因为在满足业务实际需求的同时很难做到这一点，例如，我们可能需要改变逻辑以将更多客户转入流失类别。
- en: Random Oversampling — We can duplicate minor classes till we get a decent class
    distribution. It may result in the model learning inaccurate churn scenarios.
    In simple words, it will over-learn little incident patterns.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机过采样——我们可以复制少数类数据，直到得到合理的类别分布。这可能导致模型学习到不准确的流失场景。简单来说，它会过度学习一些小的事件模式。
- en: Random Undersampling — We can remove the samples from the majority classes to
    balance the dataset. However, it will remove some signals from the dataset. Also,
    if our dataset is highly imbalanced (minor samples are less than 1%), we may have
    to remove significant majority class samples from our dataset to make it more
    balanced.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机欠采样 — 我们可以通过从多数类中删除样本来平衡数据集。然而，这会从数据集中删除一些信号。此外，如果我们的数据集严重不平衡（少数样本少于1%），我们可能需要从数据集中删除大量的多数类样本，以使其更平衡。
- en: We can generate synthetic data — We will focus on this more deeply in this article.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以生成合成数据 — 我们将在本文中更深入地探讨这一点。
- en: Generating synthetic data for rebalancing the dataset
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成合成数据以重新平衡数据集
- en: The basic idea behind this is to generate more minor class samples similar to
    the existing ones in the minority class. But unlike repeating minor class instances
    multiple times, this will generate new minor class instances based on the dataset
    we have. For that SMOTE (Synthetic Minority Oversampling Technique) method is
    commonly used. But there are many alternatives for that, such as…
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 其基本思想是生成与少数类中现有样本类似的更多少数类样本。但与重复少数类实例多次不同，这将基于我们拥有的数据集生成新的少数类实例。为此，通常使用SMOTE（合成少数过采样技术）方法。但也有许多替代方法，如……
- en: ADASYN (Adaptive Synthetic Sampling)
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ADASYN（自适应合成采样）
- en: 'Tomek Links: This technique removes samples from the majority class that are
    very close to examples in the minority class. The idea is to remove easy cases
    from the majority class that will likely be misclassified as the minority class.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Tomek Links：该技术从多数类中移除与少数类样本非常接近的样本。这个想法是移除那些容易被误分类为少数类的多数类简单案例。
- en: 'Near Miss: This technique selects samples from the majority classes closest
    in feature space to examples in the minority class and removes them from the dataset.
    The idea is similar to Tomek Links, but instead of eliminating easy cases from
    the majority class, it removes samples most likely to be misclassified as the
    minority class.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 近邻缺失：该技术从特征空间中选择与少数类样本最接近的多数类样本，并将其从数据集中移除。这个想法类似于Tomek Links，但它移除的是最有可能被误分类为少数类的样本，而不是多数类中的简单案例。
- en: Let's do some experiments around SMOTE.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对SMOTE进行一些实验。
- en: First, import the dataset. Here I am using a *Wine Quality dataset****,*** *and
    you can access the dataset using* [*this*](https://zenodo.org/record/61452#.Y7OfjHZBzrd)
    *link*. Let's load the dataset and plot the class distribution.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入数据集。这里我使用的是*Wine Quality dataset*，*你可以通过* [*这个*](https://zenodo.org/record/61452#.Y7OfjHZBzrd)
    *链接*访问数据集。我们来加载数据集并绘制类别分布。
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/7c416fcda413763c9c500d395d7cbbe6.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c416fcda413763c9c500d395d7cbbe6.png)'
- en: Image by Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Now we can use the imblearn library to perform SMOTE on our dataset. In the
    below code, we will do SMOTE on our dataset and plot both the original and resamples
    versions of the dataset.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用imblearn库对数据集进行SMOTE。在下面的代码中，我们将对数据集进行SMOTE处理，并绘制原始数据集和重采样数据集的图。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/bef012bba3a837560eb9822e2ce2804c.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bef012bba3a837560eb9822e2ce2804c.png)'
- en: Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: As you can see in the plots, we have converted 220 original minor incidents
    into 2152, its ~9x increase. That's where the problem lies. Let's focus on our
    specific churn problem.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，我们将220个原始少数事件转化为2152个，大约增加了9倍。这就是问题所在。让我们关注我们特定的流失问题。
- en: Generating such fake customer data can lead the model to learn patterns that
    do not exist in the real world.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成这种虚假客户数据可能会导致模型学习到在现实世界中不存在的模式。
- en: In most cases, we have quality issues in the dataset. As a result, there is
    a high chance of adding noises into datasets. Generating new data using noisy
    data is a bad idea.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在大多数情况下，我们的数据集存在质量问题。因此，数据集中加入噪声的可能性很高。使用嘈杂数据生成新数据是个坏主意。
- en: With these potential issues, we have the below question in front.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 面对这些潜在的问题，我们有如下问题。
- en: Are we gonna deploy these models into production?
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们要将这些模型部署到生产环境中吗？
- en: If it's a churn or fraud detection problem, I will not deploy it on production
    because these customer data can become noisier after applying SMOTE. But the answer
    to the above question highly depends on the data and business problem we are working
    on. Generally, it's not a good idea to rely on SMOTE when data is noisy and the
    problem is complex.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个流失或欺诈检测问题，我不会将其部署到生产环境中，因为这些客户数据在应用SMOTE后可能变得更加嘈杂。但上述问题的答案很大程度上取决于我们所处理的数据和业务问题。一般来说，当数据嘈杂且问题复杂时，依赖SMOTE并不是一个好主意。
- en: Let's build a classifier using oversampled data and evaluate the model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用过采样数据构建分类器并评估模型。
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/1e27074341ad039e018f6a75f01837be.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e27074341ad039e018f6a75f01837be.png)'
- en: Image by Author
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Now it's time to experiment with other approaches for class imbalance. Below
    I have explained a few methods I have used to tackle imbalance problems.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候尝试其他处理类别不平衡的方法了。下面我将解释一些我用来解决不平衡问题的方法。
- en: Use class weights
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用类别权重
- en: Change evaluation metrics
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改评估指标
- en: Create more features by doing error analysis for the model
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过对模型进行错误分析来创建更多特征
- en: Use an unsupervised algorithm to detect clusters of the dataset.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用无监督算法检测数据集中的聚类。
- en: Let's dive deep into these methods.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们**深入探讨**这些方法。
- en: Use class weights
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用类别权重
- en: When training a model on a dataset with class imbalance, the loss function may
    be dominated by the majority class because it has more instances. It can cause
    the model to pay more attention to the majority class than the minority class.
    The main idea of class weights is assigning weights for each sample based on its
    class. It will give more weight to the minority class during training. Meaning
    the model will pay more attention to the minority class during training in an
    effort to improve its performance in that class.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在对具有类别不平衡的数据集进行模型训练时，损失函数可能会被多数类主导，因为它的实例更多。这可能导致模型更多地关注多数类而不是少数类。类别权重的主要思想是根据每个样本的类别分配权重。在训练过程中，它会对少数类给予更多的权重。这意味着模型在训练过程中会更多关注少数类，以期提高该类别的表现。
- en: In advance, class weights can be used to balance the loss function by assigning
    higher weights to the minority class, so that it has a greater impact on the loss
    function. This can help the model to better learn the characteristics of the minority
    class and improve its performance on it.
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提前使用类别权重可以通过对少数类分配更高的权重来平衡损失函数，使其对损失函数的影响更大。这可以帮助模型更好地学习少数类的特征并提高其表现。
- en: 'Mathematically, class weights are typically incorporated into the loss function
    by multiplying the loss for each example by the weight for its class. For example,
    suppose we have a dataset with two classes (0 and 1) and the following class weights:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，类别权重通常通过将每个样本的损失乘以其类别的权重来融入损失函数。例如，假设我们有一个包含两个类别（0 和 1）的数据集以及以下类别权重：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The loss function for a binary classification model might be defined as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类模型的损失函数可能定义如下：
- en: '![](../Images/ddcc7700b94da37e3ec2cc69f19890e6.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ddcc7700b94da37e3ec2cc69f19890e6.png)'
- en: Image by Author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'To incorporate class weights into this loss function, we can modify it as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要将类别权重融入这个损失函数，我们可以按如下方式修改它：
- en: '![](../Images/1f64aaf6097d779c386cae7f09ff13a1.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f64aaf6097d779c386cae7f09ff13a1.png)'
- en: Image by Author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Now, when the model is trained, the loss for each example will be multiplied
    by the class weight for its class. It will cause the model to pay more attention
    to the minority class since its samples will significantly impact the loss function.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当模型训练完成后，每个样本的损失将乘以其类别的权重。这将使模型更加关注少数类，因为其样本将显著影响损失函数。
- en: Most major machine learning models accept the *sample_weight* parameter. Here
    is an example of how you can do this with the XGBoost library.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数主要机器学习模型接受 *sample_weight* 参数。以下是如何使用 XGBoost 库来做到这一点的示例。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: One thing to notice here is that sample weights can potentially lead to overfitting
    if the weights are too high. It's generally a good idea to try a range of weights
    and see which gives the best performance on the validation set.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，如果权重过高，样本权重可能会导致过拟合。通常，尝试一系列权重并查看哪个在验证集上表现最佳是个好主意。
- en: Alternatively, we can use the [scale_pos_weight](https://xgboost.readthedocs.io/en/stable/parameter.html)
    parameter in XGBoost as well. It will give you similar results.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们也可以使用 [scale_pos_weight](https://xgboost.readthedocs.io/en/stable/parameter.html)
    参数在 XGBoost 中实现。它会给出类似的结果。
- en: Let's quickly plot the above model performance.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速绘制上述模型性能图。
- en: '![](../Images/588387ea39899044b82d87f7db815a88.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/588387ea39899044b82d87f7db815a88.png)'
- en: Image by Author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: If you check the confusion matrix for the above two scenarios. In that case,
    you will notice high false positives in the oversampled scenario. We have fewer
    false positive predictions using class weights. It also reduced our true positives
    as well. So we have to tweak our approaches based on real business needs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你检查上述两种情况的混淆矩阵。你会注意到，在过采样场景中，高假阳性比较多。我们使用类别权重减少了假阳性预测，同时也减少了真正的阳性。因此，我们必须根据实际业务需求调整我们的方法。
- en: Change evaluation metrics
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改评估指标
- en: Most libraries use accuracy as the default evaluation metric for classification
    tasks. It's okay for balanced problems. But imbalanced problems will lead the
    model to guess the majority class without learning any potential signals.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数库将准确率作为分类任务的默认评估指标。对于平衡问题，这没问题。但对于不平衡问题，这将导致模型仅猜测主要类别而不会学习任何潜在的信号。
- en: For example, say we have 97 non-churn customers and three churn customers. Building
    a model and using accuracy as an evaluation metric can achieve 97% accuracy by
    blindly predicting non-churn class for every 100 samples. As an easy fix, we can
    change the evaluation metric into something different. Precision, Recall, F1 Score,
    and Balanced Accuracy are a few best options for the imbalance classification
    task.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有97个非流失客户和三个流失客户。构建一个模型并使用准确率作为评估指标，通过盲目预测每100个样本为非流失类别，可以达到97%的准确率。作为简单的解决方法，我们可以将评估指标更改为其他不同的指标。精确度、召回率、F1分数和**平衡准确率**是处理不平衡分类任务的几个最佳选择。
- en: Create more features by doing error analysis for the model
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过对模型进行错误分析来创建更多特征
- en: When your model performs poorly, we can use error analysis to find different
    data segments with varying performance levels. Let's take the previous churn example;
    we can find the model's error vs. customers' revenue bucket and identify revenue
    segments where the model is good and evil. Likewise, we can create an error analysis
    report with this information. After the error analysis report, we can determine
    possible new features which the model can use to distinguish the churner vs. the
    non-churner scenarios.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的模型表现不佳时，我们可以使用错误分析来寻找不同的数据段，发现不同的性能水平。以之前的流失示例为例，我们可以找到模型的错误与客户收入区间的关系，并识别模型表现好的收入段和表现差的收入段。类似地，我们可以利用这些信息创建错误分析报告。在错误分析报告之后，我们可以确定模型可以用来区分流失者与非流失者的新特征。
- en: For example, if you know low revenue users are churning because of the "XYZ"
    reason, you can add that feature if it's not already in the model. Otherwise,
    you can perform feature engineering methods with that potential feature, such
    as binning the "XYZ" feature.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你知道低收入用户因为“XYZ”原因而流失，你可以添加这个特征（如果模型中还没有的话）。否则，你可以利用这个潜在特征进行特征工程，例如对“XYZ”特征进行分箱处理。
- en: Use an unsupervised algorithm to detect clusters of the dataset
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用无监督算法检测数据集中的聚类
- en: One of the powerful and popular approaches is segmentation. If we know some
    features that can be used for segregating data into different subgroups, we can
    use those features for the clustering model. After clustering, you will note various
    class imbalances in other groups. There are a few possible scenarios. Such as,
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一种强大且流行的方法是分段。如果我们知道一些特征可以用于将数据分隔成不同的子群体，我们可以利用这些特征进行聚类模型。在聚类后，你会注意到不同组之间存在各种类别不平衡的情况。有几种可能的场景，例如，
- en: You may find subgroups only with one class. After verifying this customer behaviour,
    we can further skip modelling for this particular subgroup. It will reduce the
    imbalance of the whole dataset.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可能会发现只有一个类别的子群体。验证了这种客户行为后，我们可以进一步跳过对这个特定子群体的建模。这将减少整个数据集的不平衡。
- en: You may find a somewhat balanced distribution that is easy to model compared
    to the previous dataset.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可能会发现与之前的数据集相比，分布较为平衡且易于建模。
- en: Or, you may find subgroups with a highly imbalanced class distribution. But
    this is not lousy compared to the original distribution. The reason for this is
    this imbalance occurs in similar data points and can be a strong signal even though
    the distribution is imbalanced. For example, if we are working on a disease prediction
    model, it's a good idea to group people into subgroups based on age. If the general
    class imbalance is 2%, grouping on age will produce different class distributions
    for different subgroups. In the higher age group, this will be more balanced.
    In the middle and young age groups, this will be highly imbalanced. Since we are
    modelling each segment separately, the model can generalize to that particular
    segment well.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '或者，你可能会发现具有高度不平衡类别分布的子群体。但这与原始分布相比并不差。这是因为这种不平衡发生在相似的数据点中，并且即使分布不平衡，也可以是一个强烈的信号。例如，如果我们正在处理一个疾病预测模型，将人们根据年龄分组是个好主意。如果整体类别不平衡为2%，则按年龄分组将为不同的子群体产生不同的类别分布。在较高年龄组中，这种分布将更加平衡。在中年和年轻年龄组中，这将高度不平衡。由于我们单独对每个段进行建模，模型可以很好地泛化到该特定段。 '
- en: Conclusion
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This article aims to show alternatives to treat class imbalance other than synthetic
    data generation. It's worth noting that some methods heavily depend on the data,
    problem type, and domain you are working on. It's always a good idea to experiment
    with a few different approaches and pick the best one for your problem.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在展示除了合成数据生成之外的处理类别不平衡的替代方法。值得注意的是，一些方法在很大程度上依赖于数据、问题类型以及你所处理的领域。尝试几种不同的方法，并选择最适合你问题的方法通常是一个好主意。
- en: Please find the citation and license information for the above dataset.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请查找上述数据集的引用和许可证信息。
- en: '1\. Citation: Lemaitre, G., Nogueira, F., Aridas, C. K., & Oliveira, D. V.
    R. (2016). Imbalanced dataset for benchmarking [Data set]. Zenodo. [https://doi.org/10.5281/zenodo.61452](https://doi.org/10.5281/zenodo.61452)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 引用：Lemaître, G., Nogueira, F., Aridas, C. K., & Oliveira, D. V. R. (2016).
    用于基准测试的*不平衡数据集* [Data set]. Zenodo. [https://doi.org/10.5281/zenodo.61452](https://doi.org/10.5281/zenodo.61452)
- en: '2\. Dataset license : [Open Data Commons Open Database License v1.0](https://opendatacommons.org/licenses/odbl/1-0/)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 数据集许可证： [Open Data Commons Open Database License v1.0](https://opendatacommons.org/licenses/odbl/1-0/)
- en: Thanks for reading.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
