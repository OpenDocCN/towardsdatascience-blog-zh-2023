- en: Implement Behaviour Driven Development in data pipelines using Mage
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Mage 在数据管道中实现行为驱动开发
- en: 原文：[https://towardsdatascience.com/implement-behaviour-driven-development-in-data-pipelines-using-mage-19496fea7890](https://towardsdatascience.com/implement-behaviour-driven-development-in-data-pipelines-using-mage-19496fea7890)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/implement-behaviour-driven-development-in-data-pipelines-using-mage-19496fea7890](https://towardsdatascience.com/implement-behaviour-driven-development-in-data-pipelines-using-mage-19496fea7890)
- en: Maximize the quality and productivity of your data pipelines
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最大化数据管道的质量和生产力
- en: '[](https://medium.com/@xiaoxugao?source=post_page-----19496fea7890--------------------------------)[![Xiaoxu
    Gao](../Images/8712a7e5f3bad0d2abd7e04792fad66f.png)](https://medium.com/@xiaoxugao?source=post_page-----19496fea7890--------------------------------)[](https://towardsdatascience.com/?source=post_page-----19496fea7890--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----19496fea7890--------------------------------)
    [Xiaoxu Gao](https://medium.com/@xiaoxugao?source=post_page-----19496fea7890--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@xiaoxugao?source=post_page-----19496fea7890--------------------------------)[![肖旭高](../Images/8712a7e5f3bad0d2abd7e04792fad66f.png)](https://medium.com/@xiaoxugao?source=post_page-----19496fea7890--------------------------------)[](https://towardsdatascience.com/?source=post_page-----19496fea7890--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----19496fea7890--------------------------------)
    [肖旭高](https://medium.com/@xiaoxugao?source=post_page-----19496fea7890--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----19496fea7890--------------------------------)
    ·7 min read·Jul 6, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----19496fea7890--------------------------------)
    ·阅读时间 7 分钟·2023年7月6日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/491eca353ee8a49b28a714e7d2305c7f.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/491eca353ee8a49b28a714e7d2305c7f.png)'
- en: Photo by [Nick Fewings](https://unsplash.com/@jannerboy62) on [Unsplash](https://unsplash.com/)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Nick Fewings](https://unsplash.com/@jannerboy62) 提供，来源于 [Unsplash](https://unsplash.com/)
- en: In my [previous articles](https://medium.com/towards-data-science/how-to-create-valuable-data-tests-850e778718e1),
    I talked a lot about the importance of testing in data pipelines and how to create
    data tests and unit tests respectively. While testing plays an essential role,
    it may not always be the most exciting part of the development cycle. As a result,
    many modern data stacks have introduced frameworks or plugins to expedite the
    implementation of data tests. In addition, unit testing frameworks in Python such
    as Pytest, unittest have been there for a long time, helping engineers efficiently
    create unit tests for data pipelines and any Python applications.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的[之前的文章](https://medium.com/towards-data-science/how-to-create-valuable-data-tests-850e778718e1)中，我详细讲述了数据管道中测试的重要性，以及如何分别创建数据测试和单元测试。虽然测试在开发周期中扮演着至关重要的角色，但它可能不是最令人兴奋的部分。因此，许多现代数据技术栈引入了框架或插件，以加快数据测试的实现。此外，像
    Pytest 和 unittest 这样的 Python 单元测试框架已经存在很长时间，帮助工程师高效地为数据管道和任何 Python 应用程序创建单元测试。
- en: 'In this article, I want to introduce a setup that uses two modern techniques:
    Behaviour Driven Development (BDD) — a business-oriented testing framework, and
    [Mage](https://github.com/mage-ai/mage-ai) — a modern data pipeline tool. By combining
    these two techniques, the objective is to create high-quality unit tests for data
    pipelines while having a seamless developer experience.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我想介绍一个使用两种现代技术的设置：行为驱动开发（BDD）——一个面向业务的测试框架，以及 [Mage](https://github.com/mage-ai/mage-ai)
    ——一个现代数据管道工具。通过将这两种技术结合起来，目标是为数据管道创建高质量的单元测试，同时提供无缝的开发者体验。
- en: What is Behaviour Driven Development (BDD)?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是行为驱动开发（BDD）？
- en: When building data pipelines for business, it’s highly likely that we will encounter
    complicated and tricky business logic. One example is to define customer segmentation
    based on a combination of age, income, and past purchases. The following example
    represents only a fraction of the complexity that business logic can entail. It
    can become progressively complicated as there are more attributes and granularity
    within each attribute. Think about one example in your daily job!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在为业务构建数据管道时，我们很可能会遇到复杂且棘手的业务逻辑。例如，根据年龄、收入和过去的购买记录来定义客户细分。以下示例仅代表业务逻辑可能涉及的一部分复杂性。随着属性和每个属性内的细节增多，它可能变得越来越复杂。想想你在日常工作中的一个例子！
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: So the question is where should the business rules be documented and how to
    ensure the synchronization between the documentation and the code. One common
    approach is to include comments alongside the code or strive to write code that
    is self-explanatory and easily understandable. But there is still a risk of having
    outdated comments or code that stakeholders find challenging to comprehend.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所以问题是商业规则应该如何记录，以及如何确保文档和代码之间的同步。一种常见的方法是在代码旁边包含注释，或者努力编写自解释且易于理解的代码。但仍然存在注释过时或利益相关者难以理解的代码的风险。
- en: Ultimately, what we are looking for is a “documentation-as-code” solution that
    can benefit both engineers and business stakeholders and this is exactly what
    BDD can provide. If you are familiar with the concept of “data contract”, BDD
    can be seen as a form of data contract, but with a focus on the stakeholders rather
    than the data source. **It can be very beneficial, particularly for data pipelines
    with complicated business logic, and it helps prevent debates regarding “feature
    or bug”.**
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们寻求的是一种可以同时惠及工程师和业务利益相关者的“文档即代码”解决方案，这正是 BDD 能提供的。如果你对“数据契约”的概念熟悉，BDD 可以被视为一种数据契约，但重点在于利益相关者而非数据源。**这对于业务逻辑复杂的数据管道特别有利，帮助防止关于“功能或错误”的争论。**
- en: BDD is essentially a software development approach that emphasizes collaboration
    and communication between stakeholders and developers to ensure that software
    meets the desired business outcomes. The behavior is described in scenarios that
    illustrate the expected inputs and outcomes. Each scenario is written in a specific
    format of “Given-When-Then” where each step describes a specific condition or
    action.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: BDD 本质上是一种软件开发方法，强调利益相关者和开发者之间的协作与沟通，以确保软件达到期望的业务结果。行为通过场景进行描述，这些场景说明了预期的输入和结果。每个场景都采用特定的“Given-When-Then”格式，其中每个步骤描述了一个特定的条件或操作。
- en: Let’s see what the scenarios may look like for the customer segmentation example.
    Since the feature file is written in English, it can be well understood by business
    stakeholders and they can even contribute to it. It works like a contract between
    stakeholders and engineers, where engineers are responsible for accurately implementing
    the requirements, and stakeholders are expected to provide all the necessary information.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看客户分段示例中的场景可能是什么样的。由于功能文件是用英语编写的，它可以被业务利益相关者很好地理解，他们甚至可以对其进行贡献。这就像是利益相关者和工程师之间的契约，工程师负责准确实现需求，而利益相关者则需提供所有必要的信息。
- en: Having a clear contract between stakeholders and engineers helps correctly categorize
    the data issue, distinguishing between “software bugs” resulting from implementation
    errors and “feature requests” due to missing requirements.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有利益相关者和工程师之间的明确契约有助于正确分类数据问题，区分由于实施错误导致的“软件缺陷”和由于缺失需求导致的“功能请求”。
- en: Feature file (Created by Author)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 功能文件（作者创建）
- en: The next step is to generate test code from the feature and that’s where the
    connection happens. The Pytest code acts as a bridge between the documentation
    and the implementation code. When there is any misalignment between them, the
    tests will fail, highlighting the need for synchronization between documentation
    and implementation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是从功能文件生成测试代码，这就是连接发生的地方。Pytest 代码充当了文档和实现代码之间的桥梁。当它们之间存在任何不一致时，测试会失败，突显了文档和实现之间需要同步。
- en: '![](../Images/12b13781fde338d849612f472f942bb7.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12b13781fde338d849612f472f942bb7.png)'
- en: Test code acts as a bridge (Created by Author)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 测试代码充当桥梁（作者创建）
- en: Here is what the test code looks like. To keep the example short, I only implement
    the test code for the first scenario. The Given steps set up the initial context
    for the scenario which in this case gets customer age, income, past purchases
    data from the examples. The When step triggers the behavior being tested which
    is `get_user_segment` function. In the Then step, we compare the result from the
    When step with the expected output from the scenario example.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是测试代码的样子。为了简化示例，我只实现了第一个场景的测试代码。Given 步骤设置了场景的初始上下文，在这种情况下，它从示例中获取客户年龄、收入和过去购买数据。When
    步骤触发被测试的行为，即 `get_user_segment` 函数。在 Then 步骤中，我们将 When 步骤的结果与场景示例中的预期输出进行比较。
- en: Test code of the 1st scenario in the feature file(Created by Author)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 功能文件中的第一个场景的测试代码（作者创建）
- en: Imagine a change to the age range specified in the first scenario where an example
    age of 62 is added without updating the code. In such as case, the test would
    immediately fail because the code has conflicting expectations.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果在第一个场景中添加了一个年龄范围62而没有更新代码，那么测试会立即失败，因为代码有冲突的期望。
- en: What is Mage?
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mage是什么？
- en: So far, we’ve seen the potential of BDD and learned how to implement it using
    Python. Now, it’s time to incorporate BDD into our data pipelines. When it comes
    to data orchestration, Airflow as the first Python-based orchestrator with a web
    interface has become the most commonly used tool for executing data pipelines.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到BDD的潜力，并学习了如何使用Python实现它。现在，是时候将BDD融入我们的数据管道中了。在数据编排方面，Airflow作为第一个基于Python的具有Web界面的编排工具，已经成为执行数据管道最常用的工具。
- en: But it certainly is not perfect. For example, testing pipelines outside of the
    production environment, especially when using operators like KubernetesOperator,
    can be challenging. Additionally, a DAG can be cluttered with boilerplate code
    and complicated configurations, making it less straightforward to tell the purpose
    of each task, be it ingestion, transformation, or exportation. Furthermore, Airflow
    is not focused on being a data-driven orchestration tool because it concerns more
    about the successful execution of tasks rather than the quality of the final data
    assets.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但它肯定不是完美的。例如，测试生产环境外的管道，尤其是在使用像KubernetesOperator这样的操作符时，可能会面临挑战。此外，DAG可能会被冗余的代码和复杂的配置搞得一团糟，使得很难明确每个任务的目的，无论是数据摄取、转换还是导出。此外，Airflow并不是专注于数据驱动的编排工具，因为它更关注任务的成功执行，而不是最终数据资产的质量。
- en: As the community of data engineering grows, many Airflow alternatives have come
    out to fill the gap present in Airflow. Mage is one of the growing data pipeline
    tools that is seen as a modern replacement for Airflow. Its four design concepts
    set Mage apart from Airflow and we can sense the difference right from the beginning
    of the development cycle.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据工程社区的成长，许多Airflow的替代品已经出现，以填补Airflow中存在的空白。Mage是一个不断增长的数据管道工具，被视为Airflow的现代替代品。其四大设计概念使Mage区别于Airflow，我们可以从开发周期开始就感受到这种区别。
- en: '![](../Images/677d100b3bcd4920407d71977867ddda.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/677d100b3bcd4920407d71977867ddda.png)'
- en: Design principles of Mage (Created by Author)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Mage的设计原则（由作者创建）
- en: Mage has a very intuitive UI that allows engineers to swiftly edit and test
    the pipeline with ease and efficiency.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Mage具有非常直观的UI，使工程师能够迅速高效地编辑和测试管道。
- en: 'Each pipeline is composed of several types of blocks: @data_loader, @transformer,
    @data_exporter, etc, with a clear purpose. This is one of my favorite features
    because I can immediately understand the objective of each task and focus on the
    business logic rather than getting caught up in boilerplate code.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 每个管道由几种类型的模块组成：@data_loader、@transformer、@data_exporter等，每个模块都有明确的目的。这是我最喜欢的功能之一，因为我可以立即理解每个任务的目标，专注于业务逻辑，而不是被冗余代码困扰。
- en: '![](../Images/e0788c5e73933f45e2367e6acde7d04e.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0788c5e73933f45e2367e6acde7d04e.png)'
- en: Mage UI (Created by Author)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Mage UI（由作者创建）
- en: BDD + Mage
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BDD + Mage
- en: 'A regular data pipeline has three main steps: ingestion, transformation, and
    exportation. Transformation is the place where all the complicated business logic
    is implemented, and it’s not uncommon to have multiple transformation steps incorporated.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个普通的数据管道有三个主要步骤：摄取、转换和导出。转换是实现所有复杂业务逻辑的地方，多个转换步骤被整合在一起并不罕见。
- en: The clear segregation of the ingestion task and transformation task makes it
    incredibly straightforward and intuitive to apply BDD to your transformation logic.
    In fact, it feels just like testing a regular Python function, ignoring the fact
    that it’s part of a data pipeline.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 清晰地将摄取任务和转换任务分开，使得将BDD应用于你的转换逻辑变得非常简单和直观。实际上，这就像是在测试一个普通的Python函数，而忽略它是数据管道的一部分。
- en: Let’s go back to the user segmentation example. The business rules are supposed
    to sit in @transformer block and it is decoupled from the loader and exported.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 回到用户分段的例子。业务规则应该放在@transformer模块中，并且与加载器和导出器解耦。
- en: '![](../Images/aa755e19cd0a23c5f7679bc31c408960.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa755e19cd0a23c5f7679bc31c408960.png)'
- en: '@transformer block in data pipeline (Created by Author)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '@transformer模块在数据管道中（由作者创建）'
- en: The same @transformer block can be plugged into multiple pipelines as long as
    the loader returns a pandas dataframe. To run the test, we just need to run `pytest`
    command in the terminal or in the CI/CD pipeline. The pipeline configuration such
    as the trigger is in a separate file which keeps the main pipeline file as clean
    as possible.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的 @transformer 块可以插入多个管道，只要加载器返回一个 pandas 数据帧。要运行测试，我们只需在终端或 CI/CD 管道中运行`pytest`命令。管道配置（例如触发器）在一个单独的文件中，这使得主管道文件保持尽可能干净。
- en: Let’s imagine what would happen if we implement this in Airflow. As it’s not
    a complicated example, Airflow can certainly handle it well. But there are a few
    details that make me feel “errrr” when I switched from Mage to Airflow.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一下如果在 Airflow 中实现这一点会发生什么。由于这是一个不复杂的示例，Airflow 肯定可以很好地处理。但有一些细节让我在从 Mage
    切换到 Airflow 时感到“额外”的困扰。
- en: DAG file gets cluttered as each DAG has a big code block to define its metadata.
    In Mage, the configuration is moved to a yaml file, so the pipeline file keeps
    concise.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DAG 文件变得混乱，因为每个 DAG 都有一个大的代码块来定义其元数据。在 Mage 中，配置被移动到一个 yaml 文件中，因此管道文件保持简洁。
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 2\. Data-passing is tricky in Airflow. XCOM in Airflow is used for passing data
    between tasks. However, it’s not recommended to pass large datasets such as dataframes
    directly through XCOM. As a workaround, we need to persist the data in temporary
    storage first which seems to be an unnecessary engineering effort. Mage handles
    the data passing naturally for us and we don’t need to worry about the size of
    the dataset.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 数据传递在 Airflow 中比较棘手。Airflow 中的 XCOM 用于在任务之间传递数据。然而，不推荐通过 XCOM 直接传递大数据集，例如数据帧。作为一种解决方法，我们需要先将数据持久化到临时存储中，这似乎是一种不必要的工程努力。Mage
    自然地处理数据传递，我们不需要担心数据集的大小。
- en: 3\. Technically, Airflow supports several versions of Python packages, but with
    a big cost. KubernetesPodOperator and PythonVirtualenvOperator allow you to run
    a task in an isolated environment. But you will lose all the convenience that
    comes out-of-the-box with Airflow such as using another operator. In contrast,
    Mage addresses this challenge by using one centralized `requirements.txt`, ensuring
    that all tasks have access to all the native features of Mage.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 从技术上讲，Airflow 支持多个版本的 Python 包，但代价很高。KubernetesPodOperator 和 PythonVirtualenvOperator
    允许你在隔离的环境中运行任务。但你将失去 Airflow 提供的即开即用的便利，例如使用其他操作符。相比之下，Mage 通过使用一个集中式的`requirements.txt`来解决这个问题，确保所有任务都可以访问
    Mage 的所有原生功能。
- en: Conclusion
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, I brought two technologies together with the goal of improving
    test quality and developer experience. BDD aims to enhance the collaboration between
    stakeholders and engineers by creating a contract in the format of a feature file
    that is directly embedded within the codebase. On the other hand, Mage is a great
    data pipeline tool that keeps developer experience as their top priority and truly
    treats data as a first-class citizen.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我结合了两种技术，目的是提高测试质量和开发者体验。BDD 旨在通过创建直接嵌入代码库中的特性文件格式的合同，来增强利益相关者和工程师之间的协作。另一方面，Mage
    是一个很棒的数据管道工具，将开发者体验作为首要任务，并真正将数据视为一等公民。
- en: I hope you find it inspiring and feel motivated to explore and incorporate at
    least one technology into your daily work. Making the right tooling choice can
    certainly amplify your team’s productivity. I’m curious about what you think.
    Let me know in the comments. Cheers!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你能从中获得启发，并感到有动力在日常工作中探索并融入至少一种技术。选择合适的工具肯定能提升你团队的生产力。我很想知道你的想法。请在评论中告诉我。干杯！
