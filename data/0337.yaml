- en: 'K-means Clustering: An Introductory Guide and Practical Application'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-means 聚类：入门指南及实际应用
- en: 原文：[https://towardsdatascience.com/k-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249?source=collection_archive---------9-----------------------#2023-01-23](https://towardsdatascience.com/k-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249?source=collection_archive---------9-----------------------#2023-01-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/k-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249?source=collection_archive---------9-----------------------#2023-01-23](https://towardsdatascience.com/k-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249?source=collection_archive---------9-----------------------#2023-01-23)
- en: '[](https://medium.com/@kurt.klingensmith?source=post_page-----dce70bfa4249--------------------------------)[![Kurt
    Klingensmith](../Images/2249e99f12d10f81598c754b1aaf76cc.png)](https://medium.com/@kurt.klingensmith?source=post_page-----dce70bfa4249--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dce70bfa4249--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dce70bfa4249--------------------------------)
    [Kurt Klingensmith](https://medium.com/@kurt.klingensmith?source=post_page-----dce70bfa4249--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@kurt.klingensmith?source=post_page-----dce70bfa4249--------------------------------)[![Kurt
    Klingensmith](../Images/2249e99f12d10f81598c754b1aaf76cc.png)](https://medium.com/@kurt.klingensmith?source=post_page-----dce70bfa4249--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dce70bfa4249--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dce70bfa4249--------------------------------)
    [Kurt Klingensmith](https://medium.com/@kurt.klingensmith?source=post_page-----dce70bfa4249--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbaf16815de65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249&user=Kurt+Klingensmith&userId=baf16815de65&source=post_page-baf16815de65----dce70bfa4249---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dce70bfa4249--------------------------------)
    ·10 min read·Jan 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdce70bfa4249&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249&user=Kurt+Klingensmith&userId=baf16815de65&source=-----dce70bfa4249---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbaf16815de65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249&user=Kurt+Klingensmith&userId=baf16815de65&source=post_page-baf16815de65----dce70bfa4249---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dce70bfa4249--------------------------------)
    ·10 分钟阅读·2023 年 1 月 23 日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdce70bfa4249&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249&user=Kurt+Klingensmith&userId=baf16815de65&source=-----dce70bfa4249---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdce70bfa4249&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249&source=-----dce70bfa4249---------------------bookmark_footer-----------)![](../Images/cbfe2141e10479a0bee80aa89d178bef.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdce70bfa4249&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fk-means-clustering-an-introductory-guide-and-practical-application-dce70bfa4249&source=-----dce70bfa4249---------------------bookmark_footer-----------)![](../Images/cbfe2141e10479a0bee80aa89d178bef.png)'
- en: Cars of varying engine types, sizes, and weights. Photograph by author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 不同发动机类型、尺寸和重量的汽车。作者摄影。
- en: Using clustering algorithms such as K-means is one of the most popular starting
    points for machine learning. K-means clustering is an unsupervised machine learning
    technique that sorts similar data into groups, or clusters. Data within a specific
    cluster bears a higher degree of commonality amongst observations within the cluster
    than it does with observations outside of the cluster.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如 K-means 这样的聚类算法是机器学习中最常见的入门点之一。K-means 聚类是一种无监督的机器学习技术，它将相似的数据分组或聚集到一起。特定聚类中的数据在聚类内的观察值之间具有更高的相似度，而与聚类外的观察值相比则相对较低。
- en: The K in K-means represents the user-defined *k*-number of clusters. K-means
    clustering works by attempting to find the best cluster centroid positions within
    the data for *k-*number of clusters, ensuring data within the cluster is closer
    in distance to the given centroid than it is to any other centroid. Ideally, the
    resulting clusters maximize similarity amongst the data within each unique cluster.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: K均值中的K代表用户定义的*k*簇数量。K均值聚类通过尝试在数据中找到最佳的簇中心位置来工作，确保簇内的数据距离给定中心比其他中心更近。理想情况下，生成的簇在每个唯一簇内最大化数据之间的相似性。
- en: 'Note that various methods for clustering exist; this article will focus on
    one of the most popular techniques: K-means.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，存在各种聚类方法；本文将重点介绍最流行的技术之一：K均值。
- en: '**This guide consists of two parts:**'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**本指南包括两个部分：**'
- en: A K-means clustering introduction using generated data.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用生成数据的K均值聚类简介。
- en: An application of K-means clustering to an automotive dataset.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对汽车数据集应用K均值聚类。
- en: 'Code:'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码：
- en: All code is [available at the github page linked here](https://github.com/kurtklingensmith/KMeansClustering)**.**
    Feel free to download the notebook (click CODE and Download Zip) and run it alongside
    this article!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码[可以在这里的github页面上获取](https://github.com/kurtklingensmith/KMeansClustering)**。**
    随时下载笔记本（点击CODE和Download Zip）并与本文一起运行！
- en: 1\. K-means Clustering Introduction
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. K均值聚类简介
- en: 'For this guide, we will use the [scikit-learn](https://scikit-learn.org/stable/)
    libraries [1]:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本指南，我们将使用[scikit-learn](https://scikit-learn.org/stable/)库[1]：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To demonstrate K-means clustering, we first need data. Conveniently, the sklearn
    library includes the ability to [generate data blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)
    [2]. The code is rather simple:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示K均值聚类，我们首先需要数据。方便的是，sklearn库包括了[生成数据块](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)的功能[2]。代码相当简单：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The parameters of the make_blobs() function allow the user to specify the number
    of centers (which could correlate to potential cluster centroids) and how messy
    the “blobs” are (cluster_std, which adjusts the cluster’s standard deviation).
    The above code generates the blobs; the below code gets it into a dataframe and
    a plotly scatter plot:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: make_blobs()函数的参数允许用户指定中心的数量（这可能与潜在的簇中心相关）以及“数据块”的混乱程度（cluster_std，调整簇的标准差）。上述代码生成了数据块；下面的代码将其转换为数据框和plotly散点图：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here’s the output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![](../Images/906ac1b0ddc8eb615f621159644161ae.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/906ac1b0ddc8eb615f621159644161ae.png)'
- en: Screenshot by author.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: Due to picking a low “cluster_std” value in the make_blobs() function, the resulting
    graph has three very clearly defined data blobs that should be easy work for a
    K-means clustering algorithm.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在make_blobs()函数中选择了较低的“cluster_std”值，生成的图形有三个非常明确的数据块，这应该很容易被K均值聚类算法处理。
- en: How Many Clusters?
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多少个簇？
- en: The K in K-means is the number of clusters, a user-defined figure. For a given
    dataset, there is typically an optimal number of clusters. In the generated data
    seen above, it’s probably three.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: K均值中的K是簇的数量，由用户定义。对于给定的数据集，通常存在一个最佳的簇数量。在上面生成的数据中，可能是三个。
- en: To mathematically determine the optimal number of clusters, use the “Elbow Method.”
    This method calculates the within-cluster sum of squares (WCSS) for various values
    of *k*, with lower values generally being better. The WCSS represents the sum
    of the squared distances of each data point from a cluster’s centroid. The Elbow
    Method plots the WCSS as a result of adding additional clusters; eventually, an
    “elbow” appears as WCSS drops diminish with the addition of new clusters. This
    reveals the optimal cluster amount.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要数学地确定最佳的簇数量，可以使用“肘部法则”。该方法计算不同*k*值的簇内平方和（WCSS），一般较低的值更好。WCSS表示每个数据点到簇中心的平方距离之和。肘部法则将WCSS绘制为添加额外簇的结果；最终，随着新簇的增加，WCSS的下降变得缓慢，出现一个“肘部”，这揭示了最佳簇数量。
- en: 'The following code generates an Elbow Chart for the above data:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码为上述数据生成一个肘部图：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When plotted, this yields:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制后，这将产生：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/d7298ba26f86ccc1fb44e0c890840eca.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7298ba26f86ccc1fb44e0c890840eca.png)'
- en: Screenshot by author.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: Note how the plot of WCSS has a sharp “elbow” at 3 clusters. This implies 3
    is the optimal cluster choice, as the WCSS value decreased sharply with the addition
    of clusters up to three. Adding clusters beyond 3 sees only minimal gains in WCSS
    reduction. Thus, the optimal cluster value is *k* = 3.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意WCSS的图形在3个聚类时有一个明显的“肘部”。这意味着3是最佳聚类选择，因为WCSS值在增加到三个聚类时急剧下降。超过3个聚类只会带来WCSS减少的微小增益。因此，最佳的聚类值是*k*
    = 3。
- en: Generating Clusters
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成聚类
- en: 'The next step is to run the K-means clustering algorithm. In the below code,
    the line kmeans = KMeans(3) is where the value for *k* is input:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是运行K均值聚类算法。在下面的代码中，`kmeans = KMeans(3)`是输入*k*值的地方：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result is a labeled dataframe with a “Cluster” column:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个带有“Cluster”列的标记数据框：
- en: '![](../Images/d3ea0a5f10d0373005e1e87b05b5e8a6.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3ea0a5f10d0373005e1e87b05b5e8a6.png)'
- en: Screenshot by author.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: 'Plotting this yields:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制结果如下：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/bf6d46d3c7bc52287ee247dc92bd5372.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf6d46d3c7bc52287ee247dc92bd5372.png)'
- en: Screenshot by author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: The K-means method has successfully clustered the data into three distinct clusters.
    Now let’s see what happens with more realistic data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: K均值方法已成功将数据分成三个不同的聚类。现在让我们看看更现实的数据会发生什么。
- en: 2\. K-means Clustering in Automotive Data
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 汽车数据中的K均值聚类
- en: The Python Library Seaborn provides various datasets, including one on automobile
    fuel efficiency from cars built during the oil crisis era. For the purpose of
    aiding in the learning of clustering, we will filter the dataset for 8 and 4-cylinder-engined
    cars. This represents the largest and smallest engines typically available during
    that time period.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Python库Seaborn提供了各种数据集，包括来自石油危机时代汽车的燃油效率数据集。为了帮助学习聚类，我们将过滤数据集，选择8缸和4缸发动机的汽车。这代表了当时通常可用的最大和最小发动机。
- en: Fortunately, this could be an example of a real world analysis scenario. In
    the 1970’s, rapid increases in fuel prices made 8-cylinder cars less desirable;
    as a result, 4-cylinder cars became increasingly common, but how do 4 and 8-cylinder-engined
    cars truly behave regarding fuel consumption?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这可能是一个真实世界分析场景的示例。在1970年代，燃油价格的快速上涨使得8缸车变得不那么受欢迎；因此，4缸车变得越来越普遍，但4缸和8缸发动机的汽车在燃油消耗方面的实际表现如何呢？
- en: Specifically, we will explore 4 and 8-cylinder cars with regards to their *weight*
    and *fuel efficiency* measured in miles per gallon (MPG).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，我们将探讨4缸和8缸汽车在*重量*和*燃油效率*（以每加仑多少英里（MPG）衡量）方面的表现。
- en: 'Preparing the data is straightfoward:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 准备数据非常简单：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The dataset looks like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集如下所示：
- en: '![](../Images/2997f7cac78fb3d4fe037099ef3bc3eb.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2997f7cac78fb3d4fe037099ef3bc3eb.png)'
- en: Screenshot by author.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: 'Visualizing the weight and MPG of the cars yields the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化汽车的重量和MPG如下：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/8b65254a0c286a353220d23e4eaaaa10.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b65254a0c286a353220d23e4eaaaa10.png)'
- en: Screenshot by author.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: Scaling the Data
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据缩放
- en: Note how the x-axis represents weight, while the y-axis represents MPG. An increase
    of 10 pounds is not as significant as an increase in 10 MPG. This could impact
    the clustering results.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 注意x轴表示重量，而y轴表示MPG。增加10磅的重量不如增加10 MPG重要。这可能会影响聚类结果。
- en: There are various options available to combat this issue; Jeff Hale [has an
    excellent article linked here](/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)
    providing a technical overview of the various methods and use cases for scaling,
    standardizing, and normalizing [1]. For this exercise, we will use Sci-Kit Learn’s
    StandardScaler() function.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种选择来解决这个问题；Jeff Hale [有一篇很好的文章链接在这里](/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)，提供了有关缩放、标准化和归一化的各种方法和使用案例的技术概述[1]。对于这个练习，我们将使用Sci-Kit
    Learn的StandardScaler()函数。
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This returns:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![](../Images/17fd6413a6a9755569920c8ce52f6c9f.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17fd6413a6a9755569920c8ce52f6c9f.png)'
- en: This two-column dataframe is now ready to pass through the Elbow Method.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这个两列数据框现在可以通过肘部法则处理。
- en: How Many Clusters?
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多少个聚类？
- en: 'As in section 1, we follow the Elbow Method with the same code to return the
    following chart:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如第1节所述，我们使用相同的代码遵循肘部法则，以返回以下图表：
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/a230b8f3b371d374be369d31af942c31.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a230b8f3b371d374be369d31af942c31.png)'
- en: Screenshot by author.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: Two clusters appears to be the elbow. However, the jump from 2 to 3 clusters
    isn’t as flat as it was in the data blobs example of section 1.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 两个聚类似乎是肘部。然而，从2到3个聚类的跳跃不像第1节数据块示例中的那样平缓。
- en: '**Note:** The elbow method may not always provide the clearest results, necessitating
    trying a few values for *k* in the region that appears to be the elbow. While
    we are going with 2 clusters, it might be worth trying 3\. For more advanced analysis
    on the topic, Satyam Kumar provides an [alternative to the Elbow Method, referred
    to as the Silhouette Method, in this Towards Data Science article](/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891)
    [4].'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 肘部法则可能不会始终提供最清晰的结果，因此需要尝试肘部区域中几个不同的*k*值。虽然我们选择了2个簇，但尝试3个簇也可能值得。有关该主题的更高级分析，Satyam
    Kumar在这篇[《数据科学中的轮廓法》](https://github.com/kurtklingensmith/KMeansClustering)中提供了一种替代的肘部法则方法。'
- en: Generating Clusters
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成簇
- en: 'The code to generate clusters remains similar to the earlier example:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 生成簇的代码与之前的示例类似：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This gets the dataframe back to where we started, but with one addition — a
    column identifying the Cluster for each observation:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这使数据框回到了我们开始的地方，但新增了一列——标识每个观测值的簇：
- en: '![](../Images/06bbcac8532cf712f93c47d08da6431b.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06bbcac8532cf712f93c47d08da6431b.png)'
- en: Screenshot by author.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: 'Plotting this reveals the clusters:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制这些数据揭示了簇：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/24c319cf86fe9a5cd87dccc76d8d1808.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24c319cf86fe9a5cd87dccc76d8d1808.png)'
- en: Screenshot by author.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: Further Analysis
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步分析
- en: Remember that K-means clustering attempts to group data based on similarities
    within the data, with those similarities determined by distance to a cluster centroid.
    Having the cluster value added to the original dataframe allows additional analysis
    on the original dataset. For example, the above cluster visualization shows a
    split between the clusters around 3000 pounds and about 20 MPG.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，K均值聚类试图根据数据的相似性对数据进行分组，这些相似性由与簇质心的距离决定。将簇值添加到原始数据框中可以对原始数据集进行额外的分析。例如，上述簇可视化显示了大约3000磅和20
    MPG之间的簇分裂。
- en: 'Additional visualizations may yield more insights. Consider the following strip
    plots ([code available at linked Git page](https://github.com/kurtklingensmith/KMeansClustering)):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的可视化可能会提供更多见解。考虑以下条形图（[代码见链接的Git页面](https://github.com/kurtklingensmith/KMeansClustering)）：
- en: '![](../Images/6cb232be802e906e802415e355cda643.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6cb232be802e906e802415e355cda643.png)'
- en: Screenshot by author.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: First, K-means clustering managed to sort vehicles based only on weight and
    MPG into clusters that almost perfectly align with the cylinder counts. One cluster
    is 100% 4-cylinder cars, while the other is almost all 8-cylinder.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，K均值聚类仅根据重量和MPG将车辆分类，结果几乎完美地与气缸数对齐。一个簇是100%4缸车，而另一个几乎全是8缸车。
- en: Second, the mostly 8-cylinder cluster has four cars with 4-cylinder engines.
    Despite having smaller engines, these cars appear to have MPG performance closer
    to larger, 8-cylinder cars. The 4-cylinder cars in cluster zero are all close
    to 3000 pounds in weight while performing at or below 20 MPG.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，主要是8缸的簇中有四辆4缸车。尽管这些车的发动机较小，但它们的MPG表现接近于大型8缸车。簇零中的4缸车都接近3000磅重量，同时MPG表现为20或更低。
- en: 'Finally, there appears to be some 8-cylinder cars that achieve an MPG score
    closer to 4-cylinder cars. An additional chart reveals these examples are considered
    outliers ([code available at Git page](https://github.com/kurtklingensmith/KMeansClustering)):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，似乎有些8缸车的MPG得分接近4缸车。另一张图表显示这些例子被认为是异常值（[代码见Git页面](https://github.com/kurtklingensmith/KMeansClustering)）：
- en: '![](../Images/d92f0ba49a072dec3bfad8c9b7968a7a.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d92f0ba49a072dec3bfad8c9b7968a7a.png)'
- en: Screenshot by author.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 作者截图。
- en: This is an example of how clustering can help understand data while guiding
    follow-on analysis and data exploration. An engineer may find it worth analyzing
    why certain 4-cylinder cars seem to perform poorly for efficiency and get clustered
    with 8-cylinder cars.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这是聚类如何帮助理解数据并指导后续分析和数据探索的一个例子。工程师可能会发现分析为什么某些4缸车在效率上表现较差并与8缸车聚类在一起是有意义的。
- en: '**For additional practice and learning:** [take the full notebook at the linked
    Git page](https://github.com/kurtklingensmith/KMeansClustering), re-load the seaborn
    MPG dataset, but do not filter for 4 and 8-cylinder cars. You will find the Elbow
    Method reveals an ambiguous divide between 2 versus 3 clusters — both may be worth
    trying. Or, attempt the notebook [using one of the other seaborn datasets](/seaborn-essentials-for-data-visualization-in-python-291aa117583b)
    or other features within the MPG dataset [5].'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**欲进行额外练习和学习：** [访问链接中的完整笔记本](https://github.com/kurtklingensmith/KMeansClustering)，重新加载
    seaborn MPG 数据集，但不要过滤 4 和 8 缸的汽车。你会发现肘部法揭示了 2 与 3 聚类之间的模糊分界——这两者都值得尝试。或者，尝试 [使用其他
    seaborn 数据集](/seaborn-essentials-for-data-visualization-in-python-291aa117583b)
    或 MPG 数据集中的其他特征 [5]。'
- en: '**Is K-means clustering the best technique for this data?**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**K-means 聚类是处理这些数据的最佳技术吗？**'
- en: Recall that for the example with blobs, the K-means Elbow Method had a very
    clear optimal point and the resultant clustering analysis easily identified the
    distinct blobs. K-means tends to perform better when the data is more spherical
    in nature, as was the case with the data blobs. Alternative methods may work better
    with complicated data and perhaps even the automotive data used in this example.
    For further reading on some alternative clustering methods, Victor Roman provides
    a great [overview in this Towards Data Science article](/unsupervised-machine-learning-clustering-analysis-d40f2b34ae7e)
    [6].
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，对于有 blobs 的示例，K-means 肘部法有一个非常明确的最佳点，结果聚类分析也很容易识别出不同的 blobs。K-means 通常在数据更加球形的情况下表现更好，就像数据
    blobs 的情况一样。其他方法可能在复杂数据中效果更佳，甚至在本示例中使用的汽车数据中。有关一些替代聚类方法的进一步阅读，Victor Roman 在这篇
    Towards Data Science 文章中提供了很好的 [概述](/unsupervised-machine-learning-clustering-analysis-d40f2b34ae7e)
    [6]。
- en: Conclusion
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: K-means clustering is a powerful machine learning tool that enables identifying
    similarities within data. The technique can provide insights or enhance data understanding
    in a way that guides further analysis questions and improves data visualization.
    This article and code provide a guide on K-means clustering, but there are other
    clustering techniques available, some of which may be more appropriate given the
    type of data being analyzed. But even if K-means is not the most appropriate method
    for the given data, K-means clustering is an excellent method to know and a great
    spot to start getting familiarized with machine learning. Furthermore, K-means
    clustering can serve as a baseline for comparison to other clustering methods,
    meaning it may still prove useful even if it ends up not being the ideal clustering
    algorithm for a given dataset.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 聚类是一个强大的机器学习工具，可以识别数据中的相似性。这种技术可以提供见解或增强对数据的理解，从而指导进一步的分析问题并改善数据可视化。本文及代码提供了
    K-means 聚类的指南，但还有其他聚类技术可用，根据分析的数据类型，有些技术可能更为合适。即使 K-means 不是给定数据的最合适方法，K-means
    聚类仍然是一个值得了解的优秀方法，也是熟悉机器学习的良好起点。此外，K-means 聚类还可以作为其他聚类方法的基准，尽管它可能不是给定数据集的理想聚类算法，但仍可能证明有用。
- en: 'References:'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[1] Scikit learn, [scikit-learn: machine learning in Python](https://scikit-learn.org/stable/)
    (2023).'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Scikit learn, [scikit-learn: machine learning in Python](https://scikit-learn.org/stable/)
    (2023)。'
- en: '[2] Scikit learn, [sklearn.datasets.make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)
    (2023).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Scikit learn, [sklearn.datasets.make_blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)
    (2023)。'
- en: '[3] J. Hale, [Scale, Standardize, or Normalize with Scikit-Learn](/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)
    (2019), Towards Data Science.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] J. Hale, [使用 Scikit-Learn 进行缩放、标准化或归一化](/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)
    (2019), Towards Data Science。'
- en: '[4] S. Kumar, [Silhouette Method — Better than Elbow Method to Find Optimal
    Clusters](/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891)
    (2020), Towards Data Science.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] S. Kumar, [轮廓法——比肘部法更好的寻找最佳聚类方法](/silhouette-method-better-than-elbow-method-to-find-optimal-clusters-378d62ff6891)
    (2020), Towards Data Science。'
- en: '[5] M. Alam, [Seaborn essentials for data visualization in Python](/seaborn-essentials-for-data-visualization-in-python-291aa117583b)
    (2020), Towards Data Science.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] M. Alam, [Python 中的数据可视化必备 Seaborn](/seaborn-essentials-for-data-visualization-in-python-291aa117583b)
    (2020), Towards Data Science。'
- en: '[6] V. Roman, [Machine Learning: Clustering Analysis](/unsupervised-machine-learning-clustering-analysis-d40f2b34ae7e)
    (2019), Towards Data Science.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] V. Roman, [机器学习：聚类分析](/unsupervised-machine-learning-clustering-analysis-d40f2b34ae7e)
    (2019), Towards Data Science。'
