- en: Machine Learning Does Not Only Predict the Future, It Actively Creates It
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习不仅仅预测未来，它还积极地创造未来
- en: 原文：[https://towardsdatascience.com/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9](https://towardsdatascience.com/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9](https://towardsdatascience.com/machine-learning-does-not-only-predict-the-future-it-actively-creates-it-1615895c80a9)
- en: A primer on position bias (and why it matters)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于位置偏差的入门（以及它为何重要）
- en: '[](https://medium.com/@samuel.flender?source=post_page-----1615895c80a9--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----1615895c80a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1615895c80a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1615895c80a9--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----1615895c80a9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samuel.flender?source=post_page-----1615895c80a9--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----1615895c80a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1615895c80a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1615895c80a9--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----1615895c80a9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1615895c80a9--------------------------------)
    ·4 min read·Jan 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----1615895c80a9--------------------------------)
    ·4 min read·2023年1月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d5f8f135bbb8c7670a8290bcd5c6cea9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5f8f135bbb8c7670a8290bcd5c6cea9.png)'
- en: Image generated with Stable Diffusion
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由Stable Diffusion生成
- en: Standard Machine Learning curricula teach that ML models learn from patterns
    that exist in the past in order make predictions about the future.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的机器学习课程教导我们，机器学习模型从过去存在的模式中学习，以预测未来。
- en: 'This is a neat simplification, but things change dramatically once the predictions
    from these models are being used in production, where they create feedback loops:
    now, the model predictions themselves are impacting the world that the model is
    trying to learn from. Our models no longer just predict the future, they actively
    create it.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的简化，但一旦这些模型的预测被用于生产环境中，情况会发生戏剧性的变化，因为它们会产生反馈循环：现在，模型的预测本身正在影响模型试图从中学习的世界。我们的模型不再仅仅是预测未来，它们实际上是在创造未来。
- en: One such feedback loop is **position bias,** a phenomenon that’s been observed
    in [ranking models](/learning-to-rank-a-primer-40d2ff9960af), those that power
    search engines, recommender systems, social media feeds and ads rankers, across
    the industry.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个反馈循环是**位置偏差**，这一现象已经在[排名模型](/learning-to-rank-a-primer-40d2ff9960af)中被观察到，这些模型支持搜索引擎、推荐系统、社交媒体信息流和广告排名器等。
- en: What is position bias?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是位置偏差？
- en: Position bias means that the highest-ranked items (videos on Netflix, pages
    on Google, products on Amazon, posts on Facebook, or Tweets on Twitter) are the
    ones which create the most engagement not because they’re actually the best content
    for the user, but instead simply because they’re ranked highest.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 位置偏差意味着排名最高的项目（Netflix上的视频、Google上的页面、Amazon上的产品、Facebook上的帖子或Twitter上的推文）之所以创造了最多的互动，不是因为它们实际上是用户最需要的内容，而仅仅是因为它们的排名最高。
- en: This bias manifests because the ranking model is so good that users start blindly
    trusting the top-ranked item without even looking any further (“blind trust bias”),
    or because the users didn’t even consider other, potentially better, items because
    they were ranked too low for them to even notice (“presentation bias”).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这种偏差的表现形式是因为排名模型非常好，以至于用户开始盲目相信排名最高的项目，而不再进一步查看（“盲目信任偏差”），或者用户根本没有考虑其他可能更好的项目，因为它们的排名太低，用户甚至没有注意到（“展示偏差”）。
- en: Why is this a problem?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么这是一个问题？
- en: 'Let’s take a step back. The goal of ranking models is to show the most relevant
    content, sorted in order of engagement probability. These models are trained on
    implicit user data: each time a user clicks on an item on the search results page
    or on the engagement interface, we use that click as a positive label in the next
    model training iteration.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到基础。排名模型的目标是展示最相关的内容，按参与概率的顺序排序。这些模型是基于隐式用户数据进行训练的：每次用户点击搜索结果页面上的一个项目或参与界面时，我们将该点击作为下一个模型训练迭代中的正标签。
- en: 'If users start engaging with content just because of its rank and not its relevance,
    our training data is polluted: instead of learning what users really want, the
    model simply learns from its own past predictions. Over time, the predictions
    become static, and will lack diversity. As a result, users may get bored or annoyed,
    and eventually go somewhere else.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户只是因为内容的排名而非其相关性而开始与内容互动，我们的训练数据就会被污染：模型不仅仅是从用户真正想要的东西中学习，而是从自身过去的预测中学习。随着时间的推移，预测会变得静态，缺乏多样性。结果，用户可能会感到厌倦或烦恼，并最终转向其他地方。
- en: Another problem with position bias is that offline tests become unreliable.
    By definition, position-biased user engagement data will always be biased in favor
    of the existing production model, because that’s the model that produced the ranks
    that users saw. A new model that’s actually better may still look worse in offline
    tests, and may be prematurely discarded. Only [online tests](/is-my-model-really-better-560e729f81d2)
    would reveal the truth.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个位置偏差的问题是离线测试变得不可靠。根据定义，位置偏倚的用户参与数据总是会偏向现有的生产模型，因为这是生成用户看到的排名的模型。一个实际上更好的新模型在离线测试中可能看起来更差，可能会被过早地丢弃。只有[在线测试](/is-my-model-really-better-560e729f81d2)才能揭示真相。
- en: How can we mitigate position bias?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何减轻位置偏差？
- en: 'Models learn from data, so in order to de-bias the model, we need to de-bias
    its training data. As shown by [Joachims et al](https://arxiv.org/abs/1608.04468)
    (2016), this can be done by weighing each training sample by the inverse of its
    position bias, creating more weight for samples with low bias, and less weight
    for samples with high bias. Intuitively, this makes sense: a click on the first-ranked
    item (with high position bias) is probably less informative than a click on the
    10th-ranked item (with low position bias).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 模型从数据中学习，因此为了去偏模型，我们需要去偏训练数据。正如[Joachims et al](https://arxiv.org/abs/1608.04468)（2016）所示，这可以通过根据位置偏差的倒数加权每个训练样本来实现，为低偏差的样本赋予更多权重，为高偏差的样本赋予较少的权重。直观地，这很有意义：点击排名第一的项目（具有高位置偏差）可能比点击第十个项目（具有低位置偏差）信息量少。
- en: The problem of mitigating position bias therefore boils down to measuring it.
    How can we do that?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，减轻位置偏差的问题归结为测量它。我们如何做到这一点？
- en: 'One way is **result randomization**: for a small subset of the serving population,
    simply re-rank the top N items randomly, and then measure the change in engagements
    as a function of rank within that population. This works, but it’s costly: random
    search results or recommendations, especially for large N, create poor user experience,
    which can hurt user retention and therefore business revenue.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是**结果随机化**：对于服务人群中的一个小子集，简单地随机重新排序前 N 项，然后测量在该人群中排名变化所引起的参与度变化。这种方法有效，但成本较高：随机搜索结果或推荐，尤其是对于较大的
    N，会导致用户体验较差，从而影响用户留存率和商业收入。
- en: A better alternative may therefore be **intervention harvesting**, proposed
    by [Argawal et al](https://arxiv.org/pdf/1812.05161.pdf) (2018) in the context
    of full-text document search, and in parallel by [Aslanyan et al](https://arxiv.org/pdf/1812.09338.pdf)
    (2019) in the context of e-commerce search. The key idea is that logged user engagement
    data in a matured ranking system already contains the ranks from multiple different
    ranking models, for example from historic A/B tests or simply from different versions
    of the production model that have been rolled out over time. This historic diversity
    creates an inherent randomness in ranks, which we can “harvest” to estimate position
    bias, without any costly interventions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，更好的替代方法可能是**干预采集**，由[Argawal et al](https://arxiv.org/pdf/1812.05161.pdf)（2018）在全文档搜索的背景下提出，同时由[Aslanyan
    et al](https://arxiv.org/pdf/1812.09338.pdf)（2019）在电子商务搜索的背景下提出。关键思想是，成熟排名系统中记录的用户参与数据已经包含了来自多个不同排名模型的排名，例如来自历史
    A/B 测试或仅仅来自时间上推出的不同版本的生产模型。这种历史多样性在排名中创造了固有的随机性，我们可以“采集”这些数据来估计位置偏差，而无需任何昂贵的干预。
- en: Lastly, there’s an even simpler idea, namely Google’s “[Rule 36](https://developers.google.com/machine-learning/guides/rules-of-ml#rule_36_avoid_feedback_loops_with_positional_features)”.
    They suggest to simply add the rank itself as yet another feature when training
    the model, and then set that feature to a default value (such as -1) at inference
    time. The intuition is that, by simply providing all information to the model
    upfront, it will learn both the engagement model and a position bias model implicitly
    under the hood. No extra steps needed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有一个更简单的想法，即谷歌的“[规则 36](https://developers.google.com/machine-learning/guides/rules-of-ml#rule_36_avoid_feedback_loops_with_positional_features)”。他们建议在训练模型时将排名本身作为另一个特征添加，然后在推断时将该特征设置为默认值（例如
    -1）。直觉是，通过提前将所有信息提供给模型，它会在后台隐式地学习参与模型和位置偏见模型。无需额外步骤。
- en: Final thoughts
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终思考
- en: Let’s recap. Position bias is a real thing that’s been observed across the industry.
    It’s a problem because it can limit a ranking model’s diversity in the long run.
    But we can mitigate it by de-biasing the training data with a bias estimate, which
    we can get from either result randomization or intervention harvesting. Another
    mitigation strategy is to use the ranks directly as a model feature, and let the
    model learn the bias implicitly, with no extra steps required.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下。位置偏见是一个在整个行业中都被观察到的真实问题。它之所以成问题，是因为它可能会限制排名模型的多样性。但我们可以通过使用偏见估计对训练数据进行去偏差来减轻它，这些偏见估计可以通过结果随机化或干预采集获得。另一种减轻策略是直接将排名作为模型特征，并让模型隐式地学习偏见，无需额外步骤。
- en: If you think about it more holistically, the existence of position bias is really
    kind of ironic. If we’re making our ranking models better and better over time,
    these improvements may lead to more and more users blindly trusting the top-ranked
    result, thereby enhancing position bias, and ultimately degrading our model. Unless
    we’re taking deliberate steps to monitor and mitigate position bias, any model
    improvements may therefore eventually become self-defeating.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从整体上考虑，位置偏见的存在确实有些讽刺。如果我们不断改进我们的排名模型，这些改进可能会导致越来越多的用户盲目相信排名最高的结果，从而增强位置偏见，并**最终**降低我们的模型效果。除非我们采取有意识的步骤来监测和减轻位置偏见，否则任何模型改进最终可能会变得适得其反。
- en: '[](https://samflender.gumroad.com/l/mlontheground?source=post_page-----1615895c80a9--------------------------------)
    [## Machine Learning on the Ground: Design and Operations of Real-World ML Applications'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://samflender.gumroad.com/l/mlontheground?source=post_page-----1615895c80a9--------------------------------)
    [## 现实中的机器学习：真实世界 ML 应用的设计与操作'
- en: What is this book?One of the most peculiar things about Machine Learning is
    the dichotomy between academic ML research…
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这本书是什么？机器学习最奇特的事情之一是学术 ML 研究的二分法…
- en: samflender.gumroad.com](https://samflender.gumroad.com/l/mlontheground?source=post_page-----1615895c80a9--------------------------------)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: samflender.gumroad.com](https://samflender.gumroad.com/l/mlontheground?source=post_page-----1615895c80a9--------------------------------)
