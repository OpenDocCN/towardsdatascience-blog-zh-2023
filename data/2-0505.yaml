- en: ChatGPT’s Electricity Consumption
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT的电力消耗
- en: 原文：[https://towardsdatascience.com/chatgpts-electricity-consumption-7873483feac4](https://towardsdatascience.com/chatgpts-electricity-consumption-7873483feac4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chatgpts-electricity-consumption-7873483feac4](https://towardsdatascience.com/chatgpts-electricity-consumption-7873483feac4)
- en: Opinion
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 观点
- en: ChatGPT may have consumed as much electricity as 175,000 people in January 2023.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT在2023年1月的电力消耗可能相当于175,000人的用电量。
- en: '[](https://kaspergroesludvigsen.medium.com/?source=post_page-----7873483feac4--------------------------------)[![Kasper
    Groes Albin Ludvigsen](../Images/3c31c9e54fae4fd1c8f1c441379d1f10.png)](https://kaspergroesludvigsen.medium.com/?source=post_page-----7873483feac4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7873483feac4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7873483feac4--------------------------------)
    [Kasper Groes Albin Ludvigsen](https://kaspergroesludvigsen.medium.com/?source=post_page-----7873483feac4--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kaspergroesludvigsen.medium.com/?source=post_page-----7873483feac4--------------------------------)[![Kasper
    Groes Albin Ludvigsen](../Images/3c31c9e54fae4fd1c8f1c441379d1f10.png)](https://kaspergroesludvigsen.medium.com/?source=post_page-----7873483feac4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7873483feac4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7873483feac4--------------------------------)
    [Kasper Groes Albin Ludvigsen](https://kaspergroesludvigsen.medium.com/?source=post_page-----7873483feac4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7873483feac4--------------------------------)
    ·7 min read·Mar 1, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----7873483feac4--------------------------------)
    ·阅读时长7分钟·2023年3月1日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ae36dcab4194bc416080d1f1c5eae69b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae36dcab4194bc416080d1f1c5eae69b.png)'
- en: Photo by [NASA](https://unsplash.com/@nasa?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[NASA](https://unsplash.com/@nasa?utm_source=medium&utm_medium=referral)提供，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: I recently wrote an article in which I guesstimated [ChatGPT’s daily carbon
    footprint to the around 24 kgCO2e](/the-carbon-footprint-of-chatgpt-66932314627d).
    With little information available at the time about ChatGPT’s user base, my estimate
    was based on the assumption that the ChatGPT service was running on 16 A100 GPUs.
    In lieu of recent reports that estimate that ChatGPT had 590 million visits in
    January [1], it’s likely that ChatGPT requires way more GPUs to service its users.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近写了一篇文章，其中我估算了[ChatGPT的每日碳足迹约为24 kgCO2e](/the-carbon-footprint-of-chatgpt-66932314627d)。由于当时关于ChatGPT用户群体的信息很少，我的估算是基于ChatGPT服务运行在16个A100
    GPU上的假设。根据最近的报告估算，ChatGPT在1月份有5.9亿次访问[1]，这很可能意味着ChatGPT需要更多的GPU来服务其用户。
- en: '[](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----7873483feac4--------------------------------)
    [## Join Medium with my referral link - Kasper Groes Albin Ludvigsen'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----7873483feac4--------------------------------)
    [## 使用我的推荐链接加入Medium - Kasper Groes Albin Ludvigsen'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为Medium会员，您的一部分会员费将用于支持您阅读的作者，您可以全面访问每个故事…
- en: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----7873483feac4--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----7873483feac4--------------------------------)'
- en: From this it also follows naturally that ChatGPT is probably deployed in multiple
    geographic locations. This makes it very difficult to estimate ChatGPT’s total
    daily carbon footprint, because we would need to know exactly how many GPUs are
    running in which regions in order to incorporate the carbon intensity of electricity
    in each region into the carbon footprint estimate.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由此也自然推测，ChatGPT可能部署在多个地理位置。这使得估算ChatGPT的总每日碳足迹非常困难，因为我们需要确切知道每个地区运行了多少个GPU，以将每个地区的电力碳强度纳入碳足迹估算中。
- en: Estimating ChatGPT’s electricity consumption, on the other hand, is in principle
    simpler, because we do not need to know in which geographic regions ChatGPT is
    running. Below I explain how one can go about estimating ChatGPT’s energy consumption
    and I specifically produce an estimate of ChatGPT’s electricity use in January
    2023\. The scope is limited to January 2023 because we have some ChatGPT traffic
    estimates for this month.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，估算 ChatGPT 的电力消耗原则上更简单，因为我们无需知道 ChatGPT 运行的地理区域。下面我将解释如何估算 ChatGPT 的能源消耗，并特别给出对
    ChatGPT 在 2023 年 1 月的电力使用的估算。范围限于 2023 年 1 月，因为我们有该月份的 ChatGPT 流量估算。
- en: '[](https://kaspergroesludvigsen.medium.com/chatgpts-electricity-consumption-pt-ii-225e7e43f22b?source=post_page-----7873483feac4--------------------------------)
    [## ChatGPT’s electricity consumption, pt. II'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kaspergroesludvigsen.medium.com/chatgpts-electricity-consumption-pt-ii-225e7e43f22b?source=post_page-----7873483feac4--------------------------------)
    [## ChatGPT 的电力消耗，第二部分'
- en: An estimate of ChatGPT’s costs support estimate that put ChatGPT’s monthly electricity
    consumption at 1.1M to 23M KWh
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ChatGPT 的成本估算表明，ChatGPT 的月电力消耗在 1.1M 到 23M KWh 之间
- en: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/chatgpts-electricity-consumption-pt-ii-225e7e43f22b?source=post_page-----7873483feac4--------------------------------)
    [](/the-carbon-footprint-of-chatgpt-66932314627d?source=post_page-----7873483feac4--------------------------------)
    [## The Carbon Footprint of ChatGPT
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/chatgpts-electricity-consumption-pt-ii-225e7e43f22b?source=post_page-----7873483feac4--------------------------------)
    [](/the-carbon-footprint-of-chatgpt-66932314627d?source=post_page-----7873483feac4--------------------------------)
    [## ChatGPT 的碳足迹
- en: This article attempts to estimate the carbon footprint of the popular OpenAI
    chatbot called ChatGPT
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本文试图估算名为 ChatGPT 的流行 OpenAI 聊天机器人所产生的碳足迹
- en: towardsdatascience.com](/the-carbon-footprint-of-chatgpt-66932314627d?source=post_page-----7873483feac4--------------------------------)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/the-carbon-footprint-of-chatgpt-66932314627d?source=post_page-----7873483feac4--------------------------------)
- en: Estimating ChatGPT’s electricity consumption
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算 ChatGPT 的电力消耗
- en: 'Here’s how ChatGPT’s electricity consumption can be estimated:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何估算 ChatGPT 的电力消耗：
- en: Estimate ChatGPT’s electricity consumption per query
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 估算 ChatGPT 每次查询的电力消耗
- en: Estimate ChatGPT’s total number of queries for a given period in time
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 估算给定时间段内 ChatGPT 的总查询数
- en: Multiply those two
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这两个数值相乘
- en: To calculate a range within which ChatGPT’s electricity consumption may lie,
    I’ll define 3 different values for each of points 1 and 2\. Let’s first take a
    look at point 1.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算 ChatGPT 电力消耗可能的范围，我将为每个第 1 和第 2 点定义 3 个不同的值。让我们首先来看第 1 点。
- en: 'Step 1: ChatGPT’s electricity consumption per query'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：ChatGPT 每次查询的电力消耗
- en: BLOOM is a language model similar in size to ChatGPT’s underlying language model,
    GPT-3.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: BLOOM 是一个与 ChatGPT 基础语言模型 GPT-3 大小相似的语言模型。
- en: BLOOM once consumed 914 KWh of electricity during an 18 day period where it
    was deployed on 16 Nvidia A100 40 GB GPUs and handled an average of 558 requests
    per hour for a total of 230,768 queries. Queries were not batched. The 914 KWh
    account for CPU, RAM and GPU usage [2].
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: BLOOM 曾在 18 天的时间里消耗了 914 KWh 的电力，这期间它在 16 台 Nvidia A100 40 GB GPU 上运行，每小时处理平均
    558 个请求，总共 230,768 个查询。查询未批处理。914 KWh 计算了 CPU、RAM 和 GPU 的使用[2]。
- en: So BLOOM’s electricity consumption in that period was 0,00396 KWh per query.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，BLOOM 在该期间的电力消耗为每次查询 0.00396 KWh。
- en: Let’s consider how good a proxy BLOOM’s electricity usage might be for ChatGPT’s
    electricity usage.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑 BLOOM 的电力使用可能作为 ChatGPT 电力使用的良好代理。
- en: 'First things first: BLOOM has 176b parameters, and GPT-3 (ChatGPT’s underlying
    model) has 175b parameters, so everything else held equal, their energy consumption
    should be quite similar.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，BLOOM 有 176b 个参数，而 GPT-3（ChatGPT 的基础模型）有 175b 个参数，因此在其他条件相同的情况下，它们的能耗应相当相似。
- en: Now, a few things suggest that ChatGPT’s electricity consumption per query could
    be lower than BLOOM’s. For instance, ChatGPT receives way more requests per hour
    than BLOOM did, which could lead to a lower energy consumption per query. Figure
    1 below plots BLOOM’s electricity use against the number of requests and we can
    see that even at 0 requests, BLOOM had an idle consumption of 0.3 KWh, and at
    1,000 requests the electricity consumption was less than 5 times higher than at
    200 requests.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有几个因素表明 ChatGPT 每次查询的电力消耗可能低于 BLOOM。例如，ChatGPT 每小时接收到的请求远多于 BLOOM，这可能导致每次查询的能耗降低。下图（图
    1）绘制了 BLOOM 的电力使用情况与请求数量的关系，我们可以看到，即使在没有请求的情况下，BLOOM 的空闲电力消耗为 0.3 KWh，而在 1000
    个请求时，其电力消耗也只是 200 个请求时的 5 倍不到。
- en: '![](../Images/f09db435a80c6b832d8e23621a535fa3.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f09db435a80c6b832d8e23621a535fa3.png)'
- en: 'Figure 1: “The quantity of energy used by the GCP instance (on the y axis)
    versus the number of requests received by the instance in a 10 minute interval
    (on the x axis). It can be seen that even when zero requests are received by the
    instance in this time span (bottom left of the graph), the energy consumption
    remains at approximately 0.28 kWh.” (Figure and text by [2] p. 6)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: “GCP 实例使用的能源数量（在 y 轴）与实例在 10 分钟间隔内接收到的请求数量（在 x 轴）之间的关系。可以看到，即使在这一时间段内实例接收到零请求（图的左下方），能源消耗仍约为
    0.28 kWh。”（图和文字由 [2] 第 6 页提供）'
- en: Although the authors of the paper that measured BLOOM’s electricity consumption
    state that *“since inference requests are unpredictable, optimization of GPU memory
    using techniques such as batching and padding […] is not possible”* ([2] p. 5),
    we might expect that ChatGPT experiences a constant rate of requests high enough
    to make batching feasible. I would guess that batching of queries would lead to
    a lower energy consumption per query.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管测量 BLOOM 电力消耗的论文作者表示*“由于推理请求是不可预测的，因此使用批处理和填充等技术优化 GPU 内存 […] 是不可能的”*（[2]
    第 5 页），我们可能预期 ChatGPT 会经历一个足够高的请求速率，使得批处理成为可行。我猜测，查询的批处理会导致每次查询的能耗降低。
- en: One thing that could increase ChatGPT’s energy consumption per query is if ChatGPT
    on average generates more words per query, but we don’t have access to any information
    that let’s us approximate this.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可能增加 ChatGPT 每次查询能耗的因素是 ChatGPT 平均生成的词数更多，但我们没有任何信息可以让我们对这一点进行估算。
- en: 'To err on the side of caution, I’ll assume in the following that ChatGPT’s
    electricity consumption is at max the same as BLOOM’s, so I’ll make an estimate
    of ChatGPT’s electricity consumption for each of the following assumptions:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了谨慎起见，我将在以下估算中假设 ChatGPT 的电力消耗最多与 BLOOM 相同，因此我将根据以下假设对 ChatGPT 的电力消耗进行估算：
- en: ChatGPT’s electricity consumption per query is the same as BLOOM’s, i.e. 0.00396
    KWh
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ChatGPT 每次查询的电力消耗与 BLOOM 相同，即 0.00396 KWh
- en: ChatGPT’s electricity consumption per query is 75 % of BLOOM’s, i.e. 0.00297
    KWh
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ChatGPT 每次查询的电力消耗是 BLOOM 的 75%，即 0.00297 KWh
- en: ChatGPT’s electricity consumption per query is 50 % of BLOOM’s, i.e. 0.00198
    KWh
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ChatGPT 每次查询的电力消耗是 BLOOM 的 50%，即 0.00198 KWh
- en: '[](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----7873483feac4--------------------------------)
    [## How to estimate and reduce the carbon footprint of machine learning models'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何估算和减少机器学习模型的碳足迹](https://towardsdatascience.com/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----7873483feac4--------------------------------)'
- en: Two ways to easily estimate the carbon footprint of machine learning models
    and 17 ideas for how you might reduce it
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 有两种简单的方法来估算机器学习模型的碳足迹，以及 17 个减少碳足迹的想法
- en: towardsdatascience.com](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----7873483feac4--------------------------------)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何估算和减少机器学习模型的碳足迹](https://towardsdatascience.com/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----7873483feac4--------------------------------)'
- en: 'Step 2: Number of queries sent to ChatGPT'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 2 步：发送到 ChatGPT 的查询次数
- en: Now that we have some estimates of ChatGPT’s electricity consumption per query,
    we need to estimate how many queries ChatGPT received in January.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一些关于 ChatGPT 每次查询的电力消耗的估算，我们需要估算 ChatGPT 在一月份接收到的查询次数。
- en: It’s been estimated that ChatGPT had 590m visits in January 2023 [1]. How many
    queries did each visit result in? We don’t know, but let’s make some assumptions.
    I would expect that each visit results in at least 1 query, so that’s the minimum
    assumption. Then, I’ll make a scenario with 5 and 10 queries per visit. Annecdotally,
    I’ve heard several people report that they use ChatGPT extensively in their daily
    tasks, so I believe these numbers are not unreasonable.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 估计 ChatGPT 在 2023 年 1 月有 590 万次访问 [1]。每次访问产生了多少查询？我们不知道，但我们可以做一些假设。我预计每次访问至少会产生
    1 个查询，这是最低假设。然后，我将做一个每次访问 5 次和 10 次查询的场景。从一些人的经验来看，他们在日常任务中广泛使用 ChatGPT，所以我认为这些数字是合理的。
- en: Queries per visit = 1, so total number of queries = 590m
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次访问的查询数 = 1，因此总查询数 = 590百万
- en: Queries per visit = 5, so total number of queries = 2.95b
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次访问的查询数 = 5，因此总查询数 = 29.5 亿
- en: Queries per visit = 10, so total number of queries = 5.9b
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次访问的查询数 = 10，因此总查询数 = 59 亿
- en: '3 : Combining electricity consumption estimates with number of queries'
  id: totrans-50
  prefs:
  - PREF_H2
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3：将电力消耗估算与查询次数结合
- en: Above, I outlined three different assumptions regarding ChatGPT’s electricity
    use per query and three different assumptions regarding the total number of queries.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 上述内容概述了有关 ChatGPT 每次查询电力使用的三种不同假设和有关总查询次数的三种不同假设。
- en: This gives us 9 unique set of assumptions that I will refer to as “scenarios”.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了 9 个独特的假设集，我将其称为“场景”。
- en: Table 1 below shows the estimated electricity consumption for each of the scenarios.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了每个场景的估算电力消耗。
- en: The table shows that ChatGPT’s electricity consumption in January 2023 is estimated
    to be between 1,168,200 KWh and 23,364,000 KWh.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表格显示，ChatGPT 在 2023 年 1 月的电力消耗估计在 1,168,200 KWh 和 23,364,000 KWh 之间。
- en: '[Here’s](https://docs.google.com/spreadsheets/d/166ZVGLeQwry7mwtY2aQ0TQhKeRI2e4XNB_edCWi-HPA/edit?usp=sharing)
    an online spreadsheet if you want to check my calculations.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[这是](https://docs.google.com/spreadsheets/d/166ZVGLeQwry7mwtY2aQ0TQhKeRI2e4XNB_edCWi-HPA/edit?usp=sharing)一个在线电子表格，如果你想检查我的计算。'
- en: '![](../Images/21c652434c155f4f92b88c957d40c56e.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21c652434c155f4f92b88c957d40c56e.png)'
- en: 'Table 1: ChatGPT’s estimated electricity consumption in January 2023 in different
    energy efficiency and total queries scenarios. Table by Kasper Groes Albin Ludvigsen,
    based on Luccioni et al, 2022 [2]'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：ChatGPT 在 2023 年 1 月在不同能源效率和总查询场景下的估算电力消耗。表格由 Kasper Groes Albin Ludvigsen
    编制，基于 Luccioni 等人，2022 [2]
- en: ChatGPT may have used more electricity than 175,000 Danes
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 可能使用的电力超过了 175,000 名丹麦人
- en: Let’s put the numbers from Table 1 into perspective.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将表 1 中的数字放在背景中来看。
- en: The annual electricity consumption of the average Dane is 1,600 KWh [3].
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 平均丹麦人的年电力消耗为 1,600 KWh [3]。
- en: If the annual consumption is spread out evenly over the year, the average Dane
    used about 133.33 KWh of electricity in January.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将年度消耗平均分布在全年，那么每位丹麦人在一月份大约使用了 133.33 KWh 的电力。
- en: So when we divide ChatGPT’s estimated electricity consumption by 133.3, we can
    see ChatGPT’s estimated consumption correspond to the monthly electricity consumption
    of between 8,762 and 175,234 Danes.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们将 ChatGPT 估算的电力消耗除以 133.3 时，可以看到 ChatGPT 的估算消耗相当于 8,762 至 175,234 名丹麦人每月的电力消耗。
- en: To put it into another perspective, you can run a standard 7w light bulb for
    around 19,050 years with 1,168,200 KWh of electricity (1,168,200 KWh / (7 / 1000)
    / 24 / 365).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从另一个角度来看，你可以用 1,168,200 KWh 的电力（1,168,200 KWh / (7 / 1000) / 24 / 365）运行一个标准的
    7w 灯泡约 19,050 年。
- en: Training ChatGPT’s underlying language model, GPT-3, consumed an estimated 1,287
    MWh [4].
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 ChatGPT 的基础语言模型 GPT-3 估计消耗了 1,287 MWh [4]。
- en: So at the low end of the estimated range for ChatGPT’s electricity consumption
    in January 2023, training GPT-3 and running ChatGPT for one month took roughly
    the same amount of energy. At the high end of the range, running ChatGPT took
    18 times the energy it took to train.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在 2023 年 1 月 ChatGPT 电力消耗的估算范围的低端，训练 GPT-3 和运行 ChatGPT 一个月所需的能量大致相同。在范围的高端，运行
    ChatGPT 所需的能量是训练所需的 18 倍。
- en: Conclusion
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Although handling a single query requires miniscule resources, the total amount
    of resources (e.g. electricity) add up to noticeable amounts when a product like
    ChatGPT scales. The search engine Bing now has incorporated ChatGPT [5] which
    might significantly increase the number of queries ChatGPT should handle, thereby
    also increasing the electricity consumption. In my opinion, this requires a debate
    about whether the incorporation of large machine learning models into existing
    products elevate the user experience to a level that justifies the large energy
    consumption.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然处理单个查询需要的资源微不足道，但当像ChatGPT这样的产品扩展时，所需的资源（例如电力）会累计成显著的数量。搜索引擎Bing现在已经整合了ChatGPT
    [5]，这可能会显著增加ChatGPT需要处理的查询数量，从而也增加电力消耗。在我看来，这需要讨论是否将大型机器学习模型整合到现有产品中，能够将用户体验提升到一个值得大规模能源消耗的水平。
- en: In addition, unless the estimates put forward here are way too high, this article
    shows that running a machine learning based product in production can easily be
    way more energy consuming than training the model — especially if the product
    has a long life time and/or a large number of users. This should be taken into
    consideration when debating the environmental impact of AI and when thinking of
    how to reduce the life cycle carbon footprint of machine learning models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，除非这里提出的估计值过高，否则本文显示，运行一个基于机器学习的产品在生产中可能比训练模型要消耗更多的能源——特别是当产品有较长的生命周期和/或大量用户时。在讨论人工智能的环境影响以及思考如何减少机器学习模型的生命周期碳足迹时，应考虑到这一点。
- en: It is important for me to emphasize that the estimates put forward in this article
    come with great uncertainties as very little information about how ChatGPT is
    run is publicly available. In the best of all worlds, OpenAI and Microsoft — and
    other tech companies for that matter — would disclose the energy consumption and
    carbon footprint of their products. But while we wait for that to happen, I hope
    my estimates will spur a debate and inspire others to come up with better estimates.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须强调的是，本文提出的估计值存在很大不确定性，因为关于ChatGPT如何运行的信息公开得非常有限。在最理想的情况下，OpenAI 和 Microsoft
    以及其他科技公司会公开其产品的能耗和碳足迹。但在我们等待这一点发生的同时，我希望我的估计能够引发讨论，并激励他人提出更好的估计。
- en: PS. The ChatGPT electricity consumption saga continues [here](https://kaspergroesludvigsen.medium.com/chatgpts-electricity-consumption-pt-ii-225e7e43f22b).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 附注：ChatGPT电力消耗的 saga 继续在 [这里](https://kaspergroesludvigsen.medium.com/chatgpts-electricity-consumption-pt-ii-225e7e43f22b)。
- en: That’s it! I hope you enjoyed this post 🤞
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些！希望你喜欢这篇文章 🤞
- en: 'I’d love to hear from you:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我很想听听你的意见：
- en: 1) what you think about the analysis and
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 你对分析的看法以及
- en: 2) whether you think ChatGPT is worth its electricity consumption.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 你是否认为ChatGPT的电力消耗是值得的。
- en: Follow for more posts related to sustainable data science. I also write about
    time series forecasting like [here](/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e)
    or [here](/multi-step-time-series-forecasting-with-xgboost-65d6820bec39).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 关注以获取更多与可持续数据科学相关的帖子。我还会写关于时间序列预测的内容，例如 [这里](/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e)
    或 [这里](/multi-step-time-series-forecasting-with-xgboost-65d6820bec39)。
- en: Also, make sure to check out the [Danish Data Science Community](https://ddsc.io/)’s
    [Sustainable Data Science](https://github.com/Dansk-Data-Science-Community/sustainable-data-science)
    guide for more resources on sustainable data science and the environmental impact
    of machine learning.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，确保查看 [丹麦数据科学社区](https://ddsc.io/) 的 [可持续数据科学](https://github.com/Dansk-Data-Science-Community/sustainable-data-science)
    指南，以获取更多关于可持续数据科学和机器学习环境影响的资源。
- en: And feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/kaspergroesludvigsen/).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以随时在 [LinkedIn](https://www.linkedin.com/in/kaspergroesludvigsen/) 上与我联系。
- en: References
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app)'
- en: '[2] [https://arxiv.org/pdf/2211.02001.pdf](https://arxiv.org/pdf/2211.02001.pdf)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://arxiv.org/pdf/2211.02001.pdf](https://arxiv.org/pdf/2211.02001.pdf)'
- en: '[3] [https://www.gasel.dk/vaerd-at-vide/bruger-du-mere-el-end-gennemsnittet#:~:text=If%C3%B8lge%20Dansk%20Energi%20er%20et,dog%20v%C3%A6re%20en%20smule%20mindre](https://www.gasel.dk/vaerd-at-vide/bruger-du-mere-el-end-gennemsnittet#:~:text=If%C3%B8lge%20Dansk%20Energi%20er%20et,dog%20v%C3%A6re%20en%20smule%20mindre)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://www.gasel.dk/vaerd-at-vide/bruger-du-mere-el-end-gennemsnittet#:~:text=If%C3%B8lge%20Dansk%20Energi%20er%20et,dog%20v%C3%A6re%20en%20smule%20mindre](https://www.gasel.dk/vaerd-at-vide/bruger-du-mere-el-end-gennemsnittet#:~:text=If%C3%B8lge%20Dansk%20Energi%20er%20et,dog%20v%C3%A6re%20en%20smule%20mindre)'
- en: '[4] [https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf](https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf](https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf)'
- en: '[5] [https://www.digitaltrends.com/computing/how-to-use-microsoft-chatgpt-bing-edge/](https://www.digitaltrends.com/computing/how-to-use-microsoft-chatgpt-bing-edge/)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://www.digitaltrends.com/computing/how-to-use-microsoft-chatgpt-bing-edge/](https://www.digitaltrends.com/computing/how-to-use-microsoft-chatgpt-bing-edge/)'
