- en: Transfer Learning For Beginner
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习入门
- en: 原文：[https://towardsdatascience.com/transfer-learning-for-beginner-9b59490d1b9d](https://towardsdatascience.com/transfer-learning-for-beginner-9b59490d1b9d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/transfer-learning-for-beginner-9b59490d1b9d](https://towardsdatascience.com/transfer-learning-for-beginner-9b59490d1b9d)
- en: A practical guide to transfer learning in image classification
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像分类中的迁移学习实用指南
- en: '[](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----9b59490d1b9d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)
    ·7 min read·Oct 29, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9b59490d1b9d--------------------------------)
    ·阅读时间 7 分钟·2023年10月29日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In this post, we will look at the concept of *transfer learning*, and we will
    see an example of it in *image classification task*.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将探讨*迁移学习*的概念，并将看到一个*图像分类任务*的例子。
- en: What is Transfer Learning?
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是迁移学习？
- en: Transfer learning is a technique in deep learning where pre-trained models trained
    on large-scale datasets are used to solve new tasks with limited labeled data.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 迁移学习是深度学习中的一种技术，其中在大规模数据集上训练的预训练模型被用于解决具有有限标记数据的新任务。
- en: It involves taking a pre-trained model, which has learned rich and generalized
    feature representations from a source task, and fine-tuning it on a target task.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 它涉及到使用一个已经在源任务上学习到丰富且通用特征表示的预训练模型，并在目标任务上进行微调。
- en: For example, ImageNet which is a large dataset (14 million images of 1000 classes)
    are often used to train large convolutional neural networks such as VGGNet or
    ResNet.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，ImageNet 是一个大型数据集（1400万张图像，1000 个类别），通常用于训练大型卷积神经网络，如 VGGNet 或 ResNet。
- en: If we train these networks are ImageNet, these models learn to extract powerful
    and informative features. We call this training *pre-training* and these models
    are *pre-trained on ImageNet*. Note they are trained for image classification
    task on ImageNet. We call it the *source task*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在 ImageNet 上训练这些网络，这些模型会学习提取强大而富有信息的特征。我们称这种训练为*预训练*，这些模型*在 ImageNet 上经过预训练*。注意，它们是在
    ImageNet 上进行图像分类任务的训练。我们称之为*源任务*。
- en: To do transfer learning on a new task which we call *target task*, first of
    all we need to have our labelled dataset which is called *target dataset*. Target
    dataset is often much much smaller than source dataset. Our source dataset here
    was huge (it has 14 million images).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 要在一个新的任务上进行迁移学习，我们称之为*目标任务*，首先我们需要有标记的数据集，即*目标数据集*。目标数据集通常比源数据集要小得多。我们这里的源数据集非常庞大（有1400万张图像）。
- en: Then, we take these pre-trained models and chop off the final classification
    layer, and add a new classifier layer at the end and train them on our own target
    dataset. When we are training, we freeze all layers except the last layer, as
    a result very few parameters are getting trained and therefore training happens
    fast. And Voila! we have done transfer learning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们取这些预训练的模型，去掉最后的分类层，在末尾添加一个新的分类器层，并在我们自己的目标数据集上进行训练。在训练时，我们冻结所有层，除了最后一层，因此只有极少量的参数进行训练，从而训练速度很快。瞧！我们完成了迁移学习。
- en: The second training that model goes through is called *fine-tuning*. As we saw,
    during fine-tuning, most of the pre-trained weights are frozen, and only the final
    layers are adjusted to the new dataset.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 模型经过的第二次训练称为*微调*。正如我们所看到的，在微调期间，大多数预训练的权重被冻结，只有最后几层会根据新数据集进行调整。
- en: '![](../Images/f900286ce6c6dc43ae7eb4b72e4f9a02.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f900286ce6c6dc43ae7eb4b72e4f9a02.png)'
- en: Image by the author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Benefits of Transfer Learning
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习的好处
- en: The key advantages of transfer learning are that it allows you to capitalize
    on the expertise already developed in pre-trained models, hence avoids training
    large models from scratch. It also mitigates the need for large labeled datasets
    which are time-consuming to collect and annotate.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习的关键优势在于，它允许你利用预训练模型中已开发的专业知识，从而避免从头开始训练大型模型。它还减少了需要大量标注数据集的需求，这些数据集收集和注释起来非常耗时。
- en: Fine-tuning a pre-trained model is much faster and computationally cheaper than
    training from scratch. These models often achieve high accuracy by building on
    top of general features learned during pretraining.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 微调预训练模型比从头开始训练要快得多，计算成本也更低。这些模型通过建立在预训练期间学到的一般特征之上，通常能实现高准确率。
- en: Caveats of Transfer Learning
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习的注意事项
- en: Caveats of transfer learning is that the target task and dataset has to be close
    to the source task and dataset. Otherwise the knowledge learned during pre-training
    will be useless for the target task. If that’s the case, we are better off training
    the model from scratch.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习的注意事项是目标任务和数据集必须接近源任务和数据集。否则，预训练过程中学到的知识对目标任务将没有用。如果是这样，我们不如从头开始训练模型。
- en: Practical Example
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实际示例
- en: We will use VGGNet to demonstrate transfer learning. In a [previous post](https://medium.com/towards-data-science/image-classification-for-beginners-8546aa75f331),
    we looked at VGGNet. Take a look if you are unfamiliar.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 VGGNet 来演示迁移学习。在 [上一篇文章](https://medium.com/towards-data-science/image-classification-for-beginners-8546aa75f331)
    中，我们看到了 VGGNet。如果你不熟悉，请查看一下。
- en: '[](/image-classification-for-beginners-8546aa75f331?source=post_page-----9b59490d1b9d--------------------------------)
    [## Image Classification For Beginners'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/image-classification-for-beginners-8546aa75f331?source=post_page-----9b59490d1b9d--------------------------------)
    [## 初学者图像分类'
- en: VGG and ResNet architecture from 2014
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VGG 和 ResNet 架构，2014年
- en: towardsdatascience.com](/image-classification-for-beginners-8546aa75f331?source=post_page-----9b59490d1b9d--------------------------------)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/image-classification-for-beginners-8546aa75f331?source=post_page-----9b59490d1b9d--------------------------------)'
- en: VGG (Visual Geometry Group) is a deep convolutional neural network (CNN) architecture
    developed by the Visual Geometry Group at the University of Oxford. It comes in
    many variants such as VGG16 and VGG19\. All variants have similar architecture
    except the number of layers are different. For example, VGG-16 has 16 layers,
    including 13 convolutional layers and 3 fully connected layers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: VGG（视觉几何组）是由牛津大学视觉几何组开发的深度卷积神经网络（CNN）架构。它有许多变体，如 VGG16 和 VGG19。所有变体的架构类似，除了层数不同。例如，VGG-16
    具有 16 层，包括 13 层卷积层和 3 层全连接层。
- en: '*VGGNet trained on ImageNet* is often used as a pre-trained model for transfer
    learning in image classification.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*在 ImageNet 上训练的 VGGNet* 通常作为图像分类中的预训练模型用于迁移学习。'
- en: For fine-tuning, we will use STL10 datasets which has 5000 small-sized color
    images (96x96 pixels) from 10 different classes. The dataset is split into a training
    set of 5000 images and a test set of 8000 images.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于微调，我们将使用 STL10 数据集，其中包含来自 10 个不同类别的 5000 张小尺寸彩色图像（96x96 像素）。该数据集分为 5000 张图像的训练集和
    8000 张图像的测试集。
- en: The STL10 dataset is our target dataset and the ImageNet is our source dataset
    and they are very similar in nature so it makes sense to use them in transfer
    learning.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: STL10 数据集是我们的目标数据集，ImageNet 是我们的源数据集，它们在本质上非常相似，因此在迁移学习中使用它们是有意义的。
- en: 'Here is a summary of our setup in a table:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们设置的摘要表格：
- en: '![](../Images/d9adc69ae7f73daa4a40e010704fe3bf.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9adc69ae7f73daa4a40e010704fe3bf.png)'
- en: image by author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: Load The Pretrained Model
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载预训练模型
- en: Since the last layer of VGG is 1000 (as it was trained for ImageNet which contains
    1000 classes) we are removing that replacing it with a layer of 10 classes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 VGG 的最后一层是 1000（因为它是为包含 1000 类的 ImageNet 训练的），我们将删除它并用 10 类的层替换它。
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we print VGG architecture, we see the following: the last 3 layers are
    the fully connected layers, of which the last fully connected layer is the classification
    head that classifies an input of 4096 dimension into 1000 classes.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们打印 VGG 架构时，我们看到：最后 3 层是全连接层，其中最后一个全连接层是分类头，它将 4096 维的输入分类为 1000 类。
- en: '![](../Images/7da9fbecfc5047f0493ca31e15b8e5df.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7da9fbecfc5047f0493ca31e15b8e5df.png)'
- en: Image by author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: 'We need to chop off last layer and put a new layer that classifies input into
    10 classes! because STL10 has only 10 classes. So we do:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要剪掉最后一层，并放置一个新的层，将输入分类为 10 类！因为 STL10 只有 10 个类别。所以我们这样做：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Data Preparation
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'We first load and transform our target data. The code is as following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载和转换目标数据。代码如下：
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We explain each section. First,
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解释每一部分。首先，
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '***RandomCrop()*** takes two arguments — output size and padding. For example,
    with output size 32 and padding 4, it first pads the image by 4 pixels on each
    side, then takes a random 32x32 crop from the padded image.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '***RandomCrop()***接受两个参数——输出大小和填充。例如，输出大小为32和填充4时，它首先在每边填充4像素，然后从填充后的图像中随机裁剪一个32x32的区域。'
- en: This allows the crop to include pixels from the edges of the original image,
    hence provides data augmentation by generating diverse crops from the same input.
    Without padding, the crops would always be from the center and not include edge
    regions.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许裁剪包括原始图像的边缘像素，因此通过从相同输入生成不同的裁剪来实现数据增强。如果没有填充，裁剪将总是从中心进行，而不包括边缘区域。
- en: This data augmentation, helps expose the model to different parts of the image,
    and improves generalization.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据增强帮助模型接触图像的不同部分，提高了泛化能力。
- en: Second,
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The ***ToTensor()***converts a PIL image or numpy array to a Tensor that can
    be fed into a neural network. It handles all the transformations required to go
    from image data to PyTorch-compatible tensor such as normalizing the data so that
    they are in (0,1) range, and transposes (H, W, C) array to (C, H, W) for PyTorch
    model input. For example, a RGB image would become a 3xHxW Tensor, and a grayscale
    image becomes a 1xHxW Tensor.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '***ToTensor()***将PIL图像或numpy数组转换为可以输入神经网络的Tensor。它处理从图像数据到PyTorch兼容的张量所需的所有转换，例如将数据标准化到（0,1）范围，并将（H,
    W, C）数组转置为（C, H, W）以供PyTorch模型输入。例如，一个RGB图像将变成一个3xHxW的Tensor，而一个灰度图像变成一个1xHxW的Tensor。'
- en: Lastly,
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: normalizes the data by subtracting mean and dividing by standard deviation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过减去均值并除以标准差来规范化数据。
- en: FinetuneThe Model
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调模型
- en: 'There are two ways to fine-tune the model:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 微调模型有两种方式：
- en: either we freeze the previous layers and let the classification head only be
    trained.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要么我们冻结之前的层，仅训练分类头。
- en: or we train all the layers together.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 或者我们一起训练所有层。
- en: 'While the first method is faster, the second will likely be more accurate.
    Let’s first train the model via option 2\. For that we need the following functions:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然第一种方法更快，但第二种方法可能更准确。我们首先通过选项2训练模型。为此，我们需要以下函数：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'and then putting them together brings us to the full training:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将它们放在一起得到完整的训练：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If we decide to freeze some layers and not train them, we set `requires_grad
    = False` on the weights and biases of a layer to freeze that layer.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们决定冻结某些层并不训练它们，我们需要将某一层的权重和偏置设置为`requires_grad = False`以冻结该层。
- en: This concludes our topic of transfer learning in image classification.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们关于图像分类中迁移学习的话题。
- en: Conclusion
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Transfer learning is a technique where a model trained on one task is reused
    as the starting point for a model on a second related task. It allows you to leverage
    knowledge from a pretrained model instead of training a model from scratch. For
    example, wecan take an ImageNet pretrained model and retrain it on a new dataset
    of similar images. Features learned by the pre-trained model on the first task
    are transferred and reused on the new task.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种技术，其中在一个任务上训练的模型被重新用作第二个相关任务的起点。它允许你利用预训练模型中的知识，而不是从头开始训练模型。例如，我们可以使用一个在ImageNet上预训练的模型，并在一个新的类似图像的数据集上重新训练它。预训练模型在第一个任务中学到的特征被转移并在新任务中重用。
- en: Let me know if you have any comment or questions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何意见或问题，请告诉我。
- en: 'If you have any questions or suggestions, feel free to reach out to me:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题或建议，请随时与我联系：
- en: 'Email: mina.ghashami@gmail.com'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 邮箱：mina.ghashami@gmail.com
- en: 'LinkedIn: [https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 'LinkedIn: [https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)'
