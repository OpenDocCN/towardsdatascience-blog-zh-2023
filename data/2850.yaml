- en: Which Features Are Harmful For Your Classification Model?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哪些特征对你的分类模型有害？
- en: 原文：[https://towardsdatascience.com/which-features-are-harmful-for-your-classification-model-6227859a44a6?source=collection_archive---------2-----------------------#2023-09-12](https://towardsdatascience.com/which-features-are-harmful-for-your-classification-model-6227859a44a6?source=collection_archive---------2-----------------------#2023-09-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/which-features-are-harmful-for-your-classification-model-6227859a44a6?source=collection_archive---------2-----------------------#2023-09-12](https://towardsdatascience.com/which-features-are-harmful-for-your-classification-model-6227859a44a6?source=collection_archive---------2-----------------------#2023-09-12)
- en: How to calculate the Error Contribution of the features of a classifier, with
    the goal of understanding and improving the model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何计算分类器特征的错误贡献，以理解和改进模型
- en: '[](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----6227859a44a6--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe16f3bb86e03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=post_page-e16f3bb86e03----6227859a44a6---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)
    ·14 min read·Sep 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6227859a44a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=-----6227859a44a6---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe16f3bb86e03&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=post_page-e16f3bb86e03----6227859a44a6---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6227859a44a6--------------------------------)
    ·14 min read·Sep 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6227859a44a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&user=Samuele+Mazzanti&userId=e16f3bb86e03&source=-----6227859a44a6---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6227859a44a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&source=-----6227859a44a6---------------------bookmark_footer-----------)![](../Images/76d978549f4c414fe424adb41c37db80.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6227859a44a6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhich-features-are-harmful-for-your-classification-model-6227859a44a6&source=-----6227859a44a6---------------------bookmark_footer-----------)![](../Images/76d978549f4c414fe424adb41c37db80.png)'
- en: '[Image by Author]'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Image by Author]'
- en: Feature importance is the most common tool for explaining a machine learning
    model. It is so popular that many data scientists end up believing that feature
    importance equals feature goodness.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 特征重要性是解释机器学习模型的最常用工具。它如此受欢迎，以至于许多数据科学家最终相信特征重要性等于特征优良性。
- en: It is not so.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 事实并非如此。
- en: '**When a feature is important, it simply means that the model found it useful
    in the training set. However, this doesn’t say anything about the ability of the
    feature to generalize on new data!**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**当一个特征很重要时，这只是意味着模型在训练集上发现了它的用处。然而，这并不说明该特征在新数据上的泛化能力！**'
- en: 'To account for that, we need to make a distinction between two concepts:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了考虑这一点，我们需要区分两个概念：
- en: '**Prediction Contribution**: the weight that a variable has in the predictions
    made by the model. This is determined by the patterns that the model found on
    the training set. This is equivalent to feature importance.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测贡献**：模型在预测中赋予变量的权重。这由模型在训练集上找到的模式决定。这相当于特征重要性。'
- en: '**Error Contribution**: the weight that a variable has in the errors made by
    the model on a holdout dataset. This is a better proxy of the feature performance
    on new data.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误差贡献**：变量在模型在留存数据集上产生误差中的权重。这更好地代表了特征在新数据上的表现。'
- en: In this article, I will explain the logic behind the calculation of these two
    quantities on a classification model. I will also show an example in…
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将解释这两个量在分类模型上计算背后的逻辑。我还将展示一个示例在……
