- en: Leveraging Azure Event Grid to Create a Java Iceberg Table
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 Azure Event Grid 创建 Java Iceberg 表
- en: 原文：[https://towardsdatascience.com/leveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6?source=collection_archive---------29-----------------------#2023-01-10](https://towardsdatascience.com/leveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6?source=collection_archive---------29-----------------------#2023-01-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/leveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6?source=collection_archive---------29-----------------------#2023-01-10](https://towardsdatascience.com/leveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6?source=collection_archive---------29-----------------------#2023-01-10)
- en: We will use Azure Event Grid to implement an event-driven architecture
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们将使用 Azure Event Grid 实现事件驱动架构
- en: '[](https://medium.com/@jean-claude.cote?source=post_page-----d419da06dbc6--------------------------------)[![Jean-Claude
    Cote](../Images/aea2df9c7b95fc85cc336f64d64b0a76.png)](https://medium.com/@jean-claude.cote?source=post_page-----d419da06dbc6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d419da06dbc6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d419da06dbc6--------------------------------)
    [Jean-Claude Cote](https://medium.com/@jean-claude.cote?source=post_page-----d419da06dbc6--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jean-claude.cote?source=post_page-----d419da06dbc6--------------------------------)[![Jean-Claude
    Cote](../Images/aea2df9c7b95fc85cc336f64d64b0a76.png)](https://medium.com/@jean-claude.cote?source=post_page-----d419da06dbc6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d419da06dbc6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d419da06dbc6--------------------------------)
    [Jean-Claude Cote](https://medium.com/@jean-claude.cote?source=post_page-----d419da06dbc6--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F444ed0089012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fleveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6&user=Jean-Claude+Cote&userId=444ed0089012&source=post_page-444ed0089012----d419da06dbc6---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d419da06dbc6--------------------------------)
    ·6 min read·Jan 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd419da06dbc6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fleveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6&user=Jean-Claude+Cote&userId=444ed0089012&source=-----d419da06dbc6---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F444ed0089012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fleveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6&user=Jean-Claude+Cote&userId=444ed0089012&source=post_page-444ed0089012----d419da06dbc6---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d419da06dbc6--------------------------------)
    ·6 min read·2023年1月10日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd419da06dbc6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fleveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6&user=Jean-Claude+Cote&userId=444ed0089012&source=-----d419da06dbc6---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd419da06dbc6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fleveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6&source=-----d419da06dbc6---------------------bookmark_footer-----------)![](../Images/c4e53807053d374896c74f3522697b71.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd419da06dbc6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fleveraging-azure-event-grid-to-create-a-java-iceberg-table-d419da06dbc6&source=-----d419da06dbc6---------------------bookmark_footer-----------)![](../Images/c4e53807053d374896c74f3522697b71.png)'
- en: Photo by Jackson Case on Unsplash
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 Jackson Case 提供于 Unsplash
- en: In [our previous article](https://medium.com/towards-data-science/streaming-iceberg-table-an-alternative-to-kafka-be54a1624917),
    we demonstrated how an Iceberg table can act as a Kafka topic. We showed that
    independent Java Writers can produce parquet files in parallel, while a single
    Bookkeeper attaches these data files to an [Iceberg](https://iceberg.apache.org/)
    table. The Bookkeeper did this by creating an Iceberg commit.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [我们之前的文章](https://medium.com/towards-data-science/streaming-iceberg-table-an-alternative-to-kafka-be54a1624917)
    中，我们展示了 Iceberg 表如何作为 Kafka 主题。我们展示了独立的 Java 写入器如何并行生成 parquet 文件，同时单个 Bookkeeper
    将这些数据文件附加到 [Iceberg](https://iceberg.apache.org/) 表中。Bookkeeper 通过创建 Iceberg 提交来完成这一操作。
- en: The Bookkeeper needs to identify what the newly created data files are. It then
    registers these files with the Iceberg table. In our previous article we kept
    things simple and chose to implement a file-based messaging channel. For every
    data file created, the Writers create a Moniker in a well-known folder. The Bookkeeper
    monitors this well-known folder and periodically reads the Monikers. The Bookkeeper
    uses the information in these Monikers to append the new data files to the Iceberg
    table.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Bookkeeper 需要识别新创建的数据文件是什么。然后，它将这些文件注册到 Iceberg 表中。在我们之前的文章中，我们保持简单，并选择实现基于文件的消息通道。对于每个创建的数据文件，Writers
    会在一个众所周知的文件夹中创建一个 Moniker。Bookkeeper 监视这个众所周知的文件夹，并定期读取这些 Monikers。Bookkeeper
    使用这些 Monikers 中的信息将新数据文件附加到 Iceberg 表中。
- en: The previous solution is entirely file-based. It does not rely on any external
    service. However, the file-based solution requires a lot of additional create/delete
    file operations and necessitates costly data lake list-files operation.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的解决方案完全基于文件。它不依赖于任何外部服务。然而，基于文件的解决方案需要大量额外的创建/删除文件操作，并且需要昂贵的数据湖列出文件操作。
- en: Here’s a high level diagram of our previous file-based solution.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们之前基于文件的解决方案的高层次图示。
- en: '![](../Images/44376c3ecf621c7a345a28dcc851d3cb.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44376c3ecf621c7a345a28dcc851d3cb.png)'
- en: All images unless otherwise noted are by the author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图像均为作者提供
- en: In this article we will attempt to improve on this solution by leveraging the
    [Azure Event Grid](https://learn.microsoft.com/en-us/azure/event-grid/overview)
    service. The Event Grid is an event broker that you can use to implement an event-driven
    architecture. In an event-driven architecture, events are used to transmit state
    changes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将尝试通过利用[Azure Event Grid](https://learn.microsoft.com/en-us/azure/event-grid/overview)服务来改进这个解决方案。Event
    Grid 是一个事件中介，你可以使用它来实现事件驱动架构。在事件驱动架构中，事件用于传输状态变化。
- en: The state changes we are interested in transmitting are the file creation events
    when new files are added to the data lake by the Java Writers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的状态变化是当 Java Writers 向数据湖添加新文件时的文件创建事件。
- en: The consumer of these events is the Bookkeeper, which attaches the new data
    files to an Iceberg table.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这些事件的消费者是 Bookkeeper，它将新数据文件附加到 Iceberg 表中。
- en: Here’s a high level diagram of the queue-based solution.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是基于队列的解决方案的高层次图示。
- en: '![](../Images/65d221b1569b5ca0a31e73b8d4d23938.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65d221b1569b5ca0a31e73b8d4d23938.png)'
- en: All images unless otherwise noted are by the author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图像均为作者提供
- en: The Configuration
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置
- en: 'An Azure storage account consists of four services: Containers, File shares,
    Queues, and Tables. The two data storage services we are interested in are the
    Containers and the [Queues](https://learn.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction).
    Containers are where the blob files are stored. Queues are where we will send
    file creation events.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Azure 存储账户由四项服务组成：容器、文件共享、队列和表。我们感兴趣的两个数据存储服务是容器和[队列](https://learn.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction)。容器是存储
    blob 文件的地方。队列是我们将发送文件创建事件的地方。
- en: '![](../Images/14e2c989baa48ce027ad6483d8a00701.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14e2c989baa48ce027ad6483d8a00701.png)'
- en: Thus, we configure Event Grid to emit events every time a file is created inside
    a particular storage container. We configure Event Grid to publish these file
    creation events to a storage Queue.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们配置 Event Grid 以便每当在特定存储容器内创建文件时发出事件。我们配置 Event Grid 将这些文件创建事件发布到存储队列。
- en: Since we are only interested in file creation events, we configure Event Grid
    to send only the “Blob Created” events.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只对文件创建事件感兴趣，因此我们配置 Event Grid 仅发送“Blob Created”事件。
- en: '![](../Images/ccb4340b6bd1b03ec391ebc9314ed384.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccb4340b6bd1b03ec391ebc9314ed384.png)'
- en: Also, we are only interested in files created under a certain path and with
    a certain file extension.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们只对在特定路径下创建的文件以及具有特定文件扩展名的文件感兴趣。
- en: '![](../Images/567005f9ff1ac2b3ad016e44ebfc0405.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/567005f9ff1ac2b3ad016e44ebfc0405.png)'
- en: Finally, we can further narrow the events we will be processing by specifying
    advanced filters. When a Java Writer is done writing into a file, it invokes the
    REST call `FlushWithClose`. In the advanced filters, we specify `data.api` equals
    `FlushWithClose.`
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以通过指定高级筛选器来进一步缩小我们将处理的事件。当 Java Writer 完成写入文件时，它会调用 REST 接口 `FlushWithClose`。在高级筛选器中，我们指定
    `data.api` 等于 `FlushWithClose`。
- en: We can target a particular Iceberg table or all Iceberg tables by specifying
    a `subject` which contains a substring. In our case we used `/data/` which is
    the data folder used by all Iceberg tables.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过指定包含子字符串的`subject`来定位特定的Iceberg表或所有Iceberg表。在我们的案例中，我们使用了`/data/`，这是所有Iceberg表使用的数据文件夹。
- en: '![](../Images/87d00eac98fee6766dc8ce0f5cc8e1e8.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87d00eac98fee6766dc8ce0f5cc8e1e8.png)'
- en: When Java Writers create parquet files inside the `/data/` folder, events are
    published to the storage Queue. We can use the Azure portal to monitor activity
    in the Event Grid. In particular, we can see that the delivered events are a subset
    of all the published events.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当Java Writers在`/data/`文件夹内创建parquet文件时，事件会发布到存储队列。我们可以使用Azure门户监控Event Grid中的活动。特别是，我们可以看到已交付的事件是所有发布事件的一个子集。
- en: '![](../Images/1f9b567ea15b1fdbb43e5591829fd7f8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f9b567ea15b1fdbb43e5591829fd7f8.png)'
- en: The Writers
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Writers
- en: The implementation of the Writers is essentially the same as in our previous
    file-based solution. In fact, the Writers are even a little simpler since they
    no longer need to publish notifications themselves. The Azure Event Grid takes
    care of publishing notifications. The Writers only write parquet files.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Writers的实现基本上与我们之前的基于文件的解决方案相同。事实上，Writers甚至更简单，因为它们不再需要自己发布通知。Azure Event Grid处理发布通知的任务。Writers只需要写入parquet文件。
- en: The Bookkeeper
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记账员
- en: The bookkeeper is still responsible for registering newly created data files
    to the Iceberg table. However, it now determines which files need to be appended
    by reading a queue of `FlushWithClose` events. We create a Java storage queue
    client like this
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 记账员仍然负责将新创建的数据文件注册到Iceberg表中。然而，它现在通过读取`FlushWithClose`事件的队列来确定需要追加的文件。我们像这样创建一个Java存储队列客户端
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Notice the use of our `DataLakeTokenCredential` class. Since the storage queue
    and the data lake (containers) reside within the same storage account, we leverage
    the same authentication mechanism for both.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意使用我们的`DataLakeTokenCredential`类。由于存储队列和数据湖（容器）都位于同一个存储帐户内，我们利用相同的认证机制。
- en: Retrieving the events is as simple as calling `receiveMessages`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 检索事件就像调用`receiveMessages`一样简单。
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Each of these messages will be a `FlushWithClose`with the file path and file
    size. The messages are JSON that looks like this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 每条消息都是一个带有文件路径和文件大小的`FlushWithClose`。这些消息是JSON，格式如下：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In our previous file-based solution, the Monikers (the messages) were written
    by the Java Writers and contained serialized Iceberg `DataFile` objects. Thus,
    the Bookkeeper could read these objects and directly do the following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的基于文件的解决方案中，Monikers（消息）由Java Writers写入，并包含序列化的Iceberg `DataFile`对象。因此，记账员可以读取这些对象并直接执行以下操作：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that we are using Azure Event Grid, we do not control the content of the
    messages. The Bookkeeper thus needs to create Iceberg `DataFile` objects using
    the file path and file size information provided by Event Grid.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用Azure Event Grid，我们无法控制消息的内容。因此，记账员需要使用Event Grid提供的文件路径和文件大小信息创建Iceberg
    `DataFile`对象。
- en: We are missing the parquet metrics; fortunately, Iceberg has the necessary API
    to retrieve metrics from a parquet file.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们缺少parquet指标；幸运的是，Iceberg提供了从parquet文件中检索指标的必要API。
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Thanks to Samrose Ahmed for showing me this trick. Here’s his blog [Serverless
    asynchronous Iceberg data ingestion](https://www.matano.dev/blog/2022/09/13/ingesting-data-iceberg),
    which uses the AWS SQS (the AWS equivalent to Azure Event Grid).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢Samrose Ahmed向我展示了这个技巧。这里是他的博客[无服务器异步Iceberg数据摄取](https://www.matano.dev/blog/2022/09/13/ingesting-data-iceberg)，使用了AWS
    SQS（AWS等同于Azure Event Grid）。
- en: We now have all the information necessary to create an Iceberg `DataFile` object
    and commit it to an Iceberg table.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有创建Iceberg `DataFile`对象并将其提交到Iceberg表所需的所有信息。
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The Performance
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: When we profile this implementation, we quickly realize that most of the time
    is spent retrieving metrics from parquet files. Retrieving parquet file metrics
    is very efficient and only consists of reading the parquet file footer information.
    However, a REST call per file needs to be executed. The latencies of these REST
    calls can quickly add up. Fortunately, this can easily be remedied by parallelizing
    these requests using a Java executor service.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对这个实现进行性能分析时，我们很快意识到大部分时间花费在从parquet文件中检索指标上。检索parquet文件指标非常高效，仅涉及读取parquet文件的尾部信息。然而，每个文件都需要执行一次REST调用。这些REST调用的延迟会迅速累积。幸运的是，可以通过使用Java执行器服务并行化这些请求来轻松解决这个问题。
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The Results
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: By leveraging an executor service for operations that are latent, we can greatly
    improve performance. Even when appending a large number of data files (hundreds),
    processing messages takes less than a second. Reading parquet metrics takes one
    to three seconds.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用执行器服务处理延迟操作，我们可以大幅提高性能。即使在追加大量数据文件（数百个）时，处理消息也不到一秒钟。读取 parquet 指标需要一到三秒钟。
- en: The only operation that cannot be optimized with an executor service is the
    Iceberg commit operation. Although, this operation is rather quick, taking between
    a second or two. On occasion, this operation can take up to 20 seconds when Iceberg
    reorganizes the manifests.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一不能通过执行器服务优化的操作是 Iceberg 提交操作。尽管该操作相当迅速，通常在一到两秒钟之间，但有时在 Iceberg 重新组织清单时，这一操作可能需要长达20秒。
- en: If we measure the delta between the time a data file is flushed and the time
    a data file is committed to the Iceberg table, we observe overall latencies as
    low as 3 seconds and up to 20 seconds.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们测量数据文件刷新时间与数据文件提交到 Iceberg 表的时间之间的差异，我们观察到总体延迟从3秒到20秒不等。
- en: The Conclusion
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Using Azure Event Grid yields results similar to our previous file-based solution.
    However, the Event Grid solution yields more consistent results. We are not at
    the mercy of the file-listing data lake operation which can sometimes take a long
    time to execute, especially when the data lake is heavily used.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Azure Event Grid 的结果与我们之前的基于文件的解决方案类似。然而，Event Grid 解决方案提供了更一致的结果。我们不再受制于文件列表数据湖操作，这种操作有时可能需要较长时间，尤其是当数据湖使用频繁时。
- en: We also estimate the cost of “messaging” using Event Grid to be about 1/10th
    of “messaging” via a file-based solution. The storage cost of actual data files
    is the same in both solutions.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还估算了使用 Event Grid 的“消息传递”成本约为基于文件的解决方案的1/10。实际数据文件的存储成本在两种解决方案中是相同的。
- en: Leveraging Azure Event Grid is a great way to notify the Bookkeeper of newly
    created data files. However, if your storage appliance does not support a notification
    mechanism, using a file-based solution can also be viable.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 Azure Event Grid 是通知 Bookkeeper 新创建的数据文件的好方法。然而，如果你的存储设备不支持通知机制，使用基于文件的解决方案也可以行得通。
- en: If you are interested in evaluating these experiments for yourself, you can
    find the code used in these articles [here](https://github.com/cccs-jc/java-iceberg-table).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣自己评估这些实验，你可以在[这里](https://github.com/cccs-jc/java-iceberg-table)找到这些文章中使用的代码。
