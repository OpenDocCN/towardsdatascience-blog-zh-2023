- en: 'Extracting Text from PDF Files with Python: A Comprehensive Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 从 PDF 文件中提取文本：全面指南
- en: 原文：[https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517](https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517](https://towardsdatascience.com/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517)
- en: A complete process to extract textual information from tables, images, and plain
    text from a PDF file
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 PDF 文件中提取表格、图像和纯文本的完整过程
- en: '[](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[![George
    Stavrakis](../Images/50a2e9cac1e0af3e9a8402379d6a1f29.png)](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    [George Stavrakis](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[![George
    Stavrakis](../Images/50a2e9cac1e0af3e9a8402379d6a1f29.png)](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    [George Stavrakis](https://medium.com/@george.stavrakis.1996?source=post_page-----9fc4003d517--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    ·17 min read·Sep 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9fc4003d517--------------------------------)
    ·17分钟阅读·2023年9月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b9b1eb9c7f8d41e7811c0bdffa0143f2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9b1eb9c7f8d41e7811c0bdffa0143f2.png)'
- en: Photo by [Giorgio Trovato](https://unsplash.com/@giorgiotrovato?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [Giorgio Trovato](https://unsplash.com/@giorgiotrovato?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the age of Large Language Models (LLMs) and [their wide-ranging applications](https://bit.ly/49i8JoP),
    from simple text summarisation and translation to predicting stock performance
    based on sentiment and financial report topics, the importance of text data has
    never been greater.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型语言模型（LLMs）及其 [广泛应用](https://bit.ly/49i8JoP) 的时代，从简单的文本总结和翻译到基于情感和财务报告主题预测股票表现，文本数据的重要性比以往任何时候都大。
- en: There are many types of documents that share this kind of unstructured information,
    from web articles and blog posts to handwritten letters and poems. However, a
    significant portion of this text data is stored and transferred in PDF format.
    More specifically, it has been found that over 2 billion PDFs are opened in Outlook
    each year, while 73 million new PDF files are saved in Google Drive and email
    daily (2).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 许多类型的文档都包含这种非结构化的信息，从网页文章和博客帖子到手写信件和诗歌。然而，大量的文本数据以 PDF 格式存储和传输。更具体地说，每年在 Outlook
    中打开的 PDF 超过 20 亿个，而每天在 Google Drive 和电子邮件中保存的新 PDF 文件达到 7300 万个 (2)。
- en: Developing, therefore, a more systematic way to process these documents and
    extract information from them would give us the ability to have an automated flow
    and better understand and utilise this vast volume of textual data. And for this
    task, of course, our best friend could be none other than Python.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，开发一种更系统的方法来处理这些文档并从中提取信息将使我们能够实现自动化流程，更好地理解和利用这一大批文本数据。为了完成这一任务，当然，我们最好的朋友无疑就是
    Python。
- en: 'However, before we start our process, we need to specify the different types
    of PDFs that are around these days, and more specifically, the three most frequently
    appearing:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们开始之前，我们需要明确现在存在的不同类型的 PDF，特别是最常见的三种类型：
- en: '**Programmatically generated PDFs**: These PDFs are created on a computer using
    either W3C technologies such as HTML, CSS, and Javascript or another software
    like Adobe Acrobat. This type of file can contain various components, such as
    images, text, and links, which are all searchable and easy to edit.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**程序生成的 PDF**：这些 PDF 是使用 W3C 技术如 HTML、CSS 和 JavaScript 或其他软件如 Adobe Acrobat
    在计算机上创建的。这种类型的文件可以包含各种组件，如图像、文本和链接，这些都可以被搜索和轻松编辑。'
- en: '**Traditional scanned documents**: These PDFs are created from non-electronic
    mediums through a scanner machine or a mobile app. These files are nothing more
    than a collection of images stored together in a PDF file. Saying that, the elements
    appearing in these images, like the text, or links can’t be selected or searched.
    Essentially, the PDF serves as a container for these images.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**传统扫描文档**：这些PDF是通过扫描仪或移动应用程序从非电子介质创建的。这些文件只是存储在PDF文件中的图像集合。也就是说，图像中出现的元素，如文本或链接，无法被选择或搜索。本质上，PDF作为这些图像的容器。'
- en: '**Scanned documents with OCR:** In this case, Optical Character Recognition
    (OCR) software is employed after scanning the document to identify the text within
    each image in the file, converting it into searchable and editable text. Then
    the software adds a layer with the actual text to the image, and that way you
    can select it as a separate component when browsing the file. (3)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**带有OCR的扫描文档**：在这种情况下，在扫描文档后，使用光学字符识别（OCR）软件来识别文件中每个图像中的文本，将其转换为可搜索和可编辑的文本。然后，软件在图像上添加实际文本的层，从而在浏览文件时可以将其作为单独的组件选择。'
- en: Even though nowadays more and more machines have OCR systems installed in them
    that identify the text from scanned documents, there are still documents that
    contain full pages in an image format. You’ve probably seen that when you read
    a great article and try to select a sentence, but instead you select the whole
    page. This can be a result of a limitation in the specific OCR machine or its
    complete absence. That way, in order not to leave this information undetected
    in this article, I tried to create a process that also considers these cases and
    takes the most out of our precious and information-rich PDFs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现在越来越多的机器装有OCR系统来识别扫描文档中的文本，但仍有一些文档包含全页图像格式。你可能已经遇到过这种情况，当你阅读一篇精彩的文章并试图选择一个句子时，却选择了整页。这可能是特定OCR机器的限制或完全缺失的结果。因此，为了不遗漏这篇文章中的信息，我尝试创建一个也考虑这些情况的过程，并充分利用我们宝贵且信息丰富的PDF文件。
- en: The Theoretical Approach
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理论方法
- en: 'With all these different types of PDF files in mind and the various items that
    compose them, it’s important to perform an initial analysis of the layout of the
    PDF to identify the proper tool needed for each component. More specifically,
    based on the findings of this analysis, we will apply the appropriate method for
    extracting text from the PDF, whether it’s text rendered in a corpus block with
    its metadata, text within images, or structured text within tables. In the scanned
    document without OCR, the approach that identifies and extracts text from images
    will perform all the heavy lifting. The output of this process will be a Python
    dictionary containing information extracted for each page of the PDF file. Each
    key in this dictionary will present the page number of the document, and its corresponding
    value will be a list with the following 5 nested lists containing:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这些不同类型的PDF文件及其组成项目，进行PDF布局的初步分析是重要的，以确定每个组件所需的适当工具。更具体地说，根据这项分析的结果，我们将应用适当的方法来提取PDF中的文本，无论是带有元数据的文本块、图像中的文本还是表格中的结构化文本。在没有OCR的扫描文档中，识别和提取图像中文本的方法将承担所有繁重的工作。此过程的输出将是一个Python字典，包含提取的信息，每页PDF文件的信息。此字典中的每个键将表示文档的页码，对应的值将是包含以下5个嵌套列表的列表：
- en: The text extracted per text block of the corpus
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按文本块提取的文本
- en: The format of the text in each text block in terms of font family and size
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个文本块中的字体家族和大小的格式
- en: The text extracted from the images on the page
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从页面上的图像中提取的文本
- en: The text extracted from tables in a structured format
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从表格中以结构化格式提取的文本
- en: The complete text content of the page
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 页面上的完整文本内容
- en: '![](../Images/ca4c55a64e4df3b288a1f84f84c3ff01.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca4c55a64e4df3b288a1f84f84c3ff01.png)'
- en: Image by the author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: That way, we can achieve a more logical separation of the extracted text per
    source component, and it can sometimes help us to more easily retrieve information
    that usually appears in the specific component (e.g., the company name in a logo
    image). In addition, the metadata extracted from the text, like the font family
    and size, can be used to easily identify text headers or highlighted text of greater
    importance that will help us further separate or post-process the text in multiple
    different chunks. Lastly, retaining the structured table information in a way
    that an LLM can understand will enhance significantly the quality of inferences
    made about relationships within the extracted data. Then these results can be
    composed as an output the all the textual information that appeared on each page.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以实现对每个源组件提取文本的更合理分离，有时这可以帮助我们更容易地检索通常出现在特定组件中的信息（例如，徽标图像中的公司名称）。此外，从文本中提取的元数据，如字体系列和大小，可以用于轻松识别文本标题或突出显示的重要文本，这将帮助我们进一步分离或对文本进行多块后处理。最后，以
    LLM 可以理解的方式保留结构化表格信息将显著提升对提取数据中关系的推断质量。然后，这些结果可以作为每页上出现的所有文本信息的输出。
- en: You can see a flowchart of this approach in the images below.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在下图中查看这种方法的流程图。
- en: '![](../Images/d9d68fa706ebff6487d0560e120a2e07.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9d68fa706ebff6487d0560e120a2e07.png)'
- en: Image by the author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Installation of all the necessary libraries
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装所有必要的库
- en: 'Before we start this project, though, we should install the necessary libraries.
    We assume that you have Python 3.10 or above installed on your machine. Otherwise,
    you can install it from [here](https://www.python.org/). Then let’s install the
    following libraries:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，在开始这个项目之前，我们应该安装必要的库。我们假设您的机器上已安装 Python 3.10 或更高版本。否则，您可以从[这里](https://www.python.org/)进行安装。然后让我们安装以下库：
- en: '**PyPDF2**: To read the PDF file from the repository path.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyPDF2**：用于从存储库路径中读取 PDF 文件。'
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Pdfminer**: To perform the layout analysis and extract text and format from
    the PDF. (the .six version of the library is the one that supports Python 3)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pdfminer**：用于执行布局分析并从 PDF 中提取文本和格式。（支持 Python 3 的库版本为 .six）'
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Pdfplumber**: To identify tables in a PDF page and extract the information
    from them.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pdfplumber**：用于识别 PDF 页中的表格并从中提取信息。'
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Pdf2image**: To convert the cropped PDF image to a PNG image.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pdf2image**：用于将裁剪后的 PDF 图像转换为 PNG 图像。'
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**PIL**: To read the PNG image.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**PIL**：用于读取 PNG 图像。'
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Pytesseract**: To extract the text from the images using OCR technology'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pytesseract**：用于使用 OCR 技术从图像中提取文本。'
- en: This is a little trickier to install because first, you need to install [Google
    Tesseract OCR](https://github.com/tesseract-ocr/tesseract), which is an OCR machine
    based on an LSTM model to identify line recognition and character patterns.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 安装这个稍微复杂一些，因为首先，您需要安装[Google Tesseract OCR](https://github.com/tesseract-ocr/tesseract)，这是一个基于
    LSTM 模型的 OCR 机器，用于识别行识别和字符模式。
- en: You can install this on your machine if you are a Mac user through **Brew**
    from your terminal, and you are good to go.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是 Mac 用户，可以通过终端中的 **Brew** 在您的机器上安装这些库，安装后您就可以开始使用了。
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For Windows users, you can follow these steps to install the [link](https://linuxhint.com/install-tesseract-windows/).
    Then, when you download and install the software, you need to add their executable
    paths to Environment Variables on your computer. Alternatively, you can run the
    following commands to directly include their paths in the Python script using
    the following code:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Windows 用户，您可以按照这些步骤安装[链接](https://linuxhint.com/install-tesseract-windows/)。然后，当您下载并安装软件时，您需要将其可执行路径添加到计算机的环境变量中。或者，您可以运行以下命令，通过以下代码直接在
    Python 脚本中包含其路径：
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then you can install the Python library
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然后您可以安装 Python 库
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Lastly, we will import all the libraries at the beginning of our script.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将在脚本开始时导入所有库。
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: So now we are all set. Let’s move to the fun part.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了。让我们进入有趣的部分。
- en: Document’s Layout Analysis with Python
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 进行文档布局分析
- en: '![](../Images/b317b2163ebef139cb95efcbfa2b8ffe.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b317b2163ebef139cb95efcbfa2b8ffe.png)'
- en: Image by the author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'For the preliminary analysis, we used the PDFMiner Python library to separate
    the text from a document object into multiple page objects and then break down
    and examine the layout of each page. PDF files inherently lack structured information,
    such as paragraphs, sentences, or words as seen by the human eye. Instead, they
    understand only the individual characters of the text along with their position
    on the page. That way, the PDFMiner tries to reconstruct the content of the page
    into its individual characters along with their position in the file. Then, by
    comparing the distances of those characters from others it composes the appropriate
    words, sentences, lines, and paragraphs of text. (4) To achieve that, the library:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于初步分析，我们使用了PDFMiner Python库将文档对象中的文本分离为多个页面对象，然后拆解和检查每个页面的布局。PDF文件本质上缺乏结构化信息，例如段落、句子或单词，如人眼所见。相反，它们只理解文本的单个字符及其在页面上的位置。这样，PDFMiner尝试将页面内容重建为其单个字符及其在文件中的位置。然后，通过比较这些字符与其他字符之间的距离，它将组成适当的单词、句子、行和段落文本。（4）为实现这一点，该库：
- en: Separates the individual pages from the PDF file using the high-level function
    extract_pages() and converts them into **LTPage** objects.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用高阶函数extract_pages()将PDF文件中的每个页面分离，并将它们转换为**LTPage**对象。
- en: 'Then for each LTPage object, it iterates from each element from top to bottom
    and tries to identify the appropriate component as either:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于每个LTPage对象，它从顶部到底部迭代每个元素，并尝试将适当的组件识别为：
- en: '**LTFigure** which represents the area of the PDF that can present figures
    or images that have been embedded as another PDF document in the page.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LTFigure**表示PDF中可以呈现嵌入为另一个PDF文档的图形或图像的区域。'
- en: '**LTTextContainer** which represents a group of text lines in a rectangular
    area is then analysed further into a list of **LTTextLine** objects. Each one
    of them represents a list of **LTChar** objects, which store the single characters
    of text along with their metadata. (5)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LTTextContainer**表示一个矩形区域中的文本行组，随后进一步分析为**LTTextLine**对象的列表。每个**LTTextLine**对象表示一系列**LTChar**对象，这些对象存储单个字符及其元数据。（5）'
- en: '**LTRect** represents a 2-dimensional rectangle that can be used to frame images,
    and figures or create tables in an LTPage object.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LTRect**表示一个二维矩形，可用于框定图像、图形或在LTPage对象中创建表格。'
- en: Therefore, based on this reconstruction of the page and the classification of
    its elements either into **LTFigure**, which contains the images or figures of
    the page, **LTTextContainer**, which represents the textual information of the
    page, or **LTRect**, which will be a strong indication of the presence of a table,
    we can apply the appropriate function to better extract the information.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据页面的重建和元素的分类，无论是**LTFigure**（包含页面中的图像或图形）、**LTTextContainer**（表示页面的文本信息）还是**LTRect**（将强烈指示表格的存在），我们可以应用适当的函数以更好地提取信息。
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So now that we understand the analysis part of the process, let’s create the
    functions needed to extract the text from each component.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了过程的分析部分，让我们创建提取每个组件中文本所需的函数。
- en: Define the function to extract text from PDF
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义提取PDF中文本的函数
- en: From here on, extracting text from a text container is really straightforward.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，从文本容器中提取文本非常简单。
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: So to extract text from a text container, we simply use the **get_text**() method
    of the LTTextContainer element. This method retrieves all the characters that
    make up the words within the specific corpus box, storing the output in a list
    of text data. Each element in this list represents the raw textual information
    contained in the container.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要从文本容器中提取文本，我们只需使用**get_text**()方法。该方法检索构成特定语料库框中的单词的所有字符，并将输出存储在文本数据列表中。该列表中的每个元素代表容器中包含的原始文本信息。
- en: 'Now, to identify this text’s format, we iterate through the LTTextContainer
    object to access each text line of this corpus individually. In each iteration,
    a new **LTTextLine** object is created, representing a line of text in this chunk
    of corpus. We then examine whether the nested line element contains text. If it
    does, we access each individual character element as LTChar, which contains all
    the metadata for that character. From this metadata, we extract two types of formats
    and store them in a separate list, positioned correspondingly to the examined
    text:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了识别这些文本的格式，我们遍历LTTextContainer对象，以逐一访问该语料库的每一行文本。在每次迭代中，会创建一个新的**LTTextLine**对象，表示该语料库块中的一行文本。然后我们检查嵌套的行元素是否包含文本。如果包含，我们访问每个单独的字符元素作为LTChar，它包含该字符的所有元数据。从这些元数据中，我们提取两种格式，并将其存储在一个单独的列表中，与被检查的文本相对应。
- en: The font family of the characters, including whether the character is in bold
    or italic format
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符的字体家族，包括字符是否为粗体或斜体格式
- en: The font size for the character
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符的字体大小
- en: Generally, characters within a specific chunk of text tend to have consistent
    formatting unless some are highlighted in bold. To facilitate further analysis,
    we capture the unique values of text formatting for all characters within the
    text and store them in the appropriate list.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，特定文本块中的字符格式趋于一致，除非有些字符以粗体突出显示。为了便于进一步分析，我们捕获文本中所有字符的独特格式值，并将其存储在相应的列表中。
- en: '![](../Images/d29c147610491c54af199c2bcb946554.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d29c147610491c54af199c2bcb946554.png)'
- en: Image by the author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Define the function to extract text from Images
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义提取图像中文本的函数
- en: Here I believe it is a more tricky part.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这是一个更棘手的部分。
- en: '*How to handle text in images found in PDF?*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*如何处理PDF中找到的图像中的文本？*'
- en: Firstly, we need to establish here that image elements stored in PDFs are not
    in a different format from the file, such as JPEG or PNG. That way in order to
    apply OCR software on them we need first to separate them from the file and then
    convert them into an image format.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要在这里确定，存储在PDF中的图像元素与文件的其他格式（如JPEG或PNG）没有不同。因此，为了对它们应用OCR软件，我们需要首先将它们从文件中分离出来，然后将其转换为图像格式。
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To achieve this, we follow the following process:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们遵循以下过程：
- en: We use the metadata from the LTFigure object detected from PDFMiner to crop
    the image box, utilising its coordinates in the page layout. We then save it as
    a new PDF in our directory using the **PyPDF2** library.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用从PDFMiner检测到的LTFigure对象的元数据来裁剪图像框，利用其在页面布局中的坐标。然后我们使用**PyPDF2**库将其保存为我们目录中的新PDF文件。
- en: Then we employ the **convert_from_file**() function from the **pdf2image** library
    to convert all PDF files in the directory into a list of images, saving them in
    PNG format.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用**pdf2image**库的**convert_from_file**()函数将目录中的所有PDF文件转换为图像列表，并将其保存为PNG格式。
- en: Finally, now that we have our image files we read them in our script using the
    **Image** package of the **PIL** module and implement the **image_to_string**()
    function of pytesseract to extract text from the images using the tesseract OCR
    engine.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，现在我们拥有了图像文件，我们使用**PIL**模块的**Image**包在脚本中读取这些图像，并实现pytesseract的**image_to_string**()函数，使用tesseract
    OCR引擎从图像中提取文本。
- en: As a result, this process returns the text from the images, which we then save
    in a third list within the output dictionary. This list contains the textual information
    extracted from the images on the examined page.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个过程从图像中提取文本，然后我们将其保存在输出字典中的第三个列表中。这个列表包含从被检查页面上的图像中提取的文本信息。
- en: Define the function to extract text from Tables
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义提取表格中文本的函数
- en: In this section, we will extract a more logically structured text from tables
    on a PDF page. This is a slightly more complex task than extracting text from
    a corpus because we need to take into account the granularity of the information
    and the relationships formed between data points presented in a table.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将从PDF页面上的表格中提取更具逻辑结构的文本。这比从语料库中提取文本要复杂一些，因为我们需要考虑信息的粒度以及表格中呈现的数据点之间形成的关系。
- en: Although there are several libraries used to extract table data from PDFs, with
    [**Tabula-py**](https://pypi.org/project/tabula-py/) being one of the most well-known,
    we have identified certain limitations in their functionality.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有几个库用于从PDF中提取表格数据，[**Tabula-py**](https://pypi.org/project/tabula-py/)是最著名的之一，但我们发现它们的功能存在一定的局限性。
- en: The most glaring one in our opinion comes from the way that the library identifies
    the different rows of the table using the line-break special character \n in the
    table’s text. This works pretty well in most of the cases but it fails to capture
    correctly when the text in a cell is wrapped into 2 or more rows, leading to the
    addition of unnecessary empty rows and losing the context of the extracted cell.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们看来，最明显的问题来自于库使用换行符\n识别表格的不同行。这在大多数情况下效果很好，但当单元格中的文本被换行成两行或更多行时，它无法正确捕捉，导致添加了不必要的空行并丢失了提取单元格的上下文。
- en: 'You can see the example below when we tried to extract the data from a table
    using tabula-py:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看下面的示例，当我们尝试使用tabula-py提取表格数据时：
- en: '![](../Images/e51d389d867366c2c04485ef945d1519.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e51d389d867366c2c04485ef945d1519.png)'
- en: Image by the author
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Then, the extracted information is outputted in a Pandas DataFrame instead of
    a string. In most cases, this can be a desirable format but in the case of transformers
    that take into account text, these results need to be transformed before feeding
    into a model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将提取的信息输出为Pandas DataFrame，而不是字符串。在大多数情况下，这是一种理想的格式，但对于考虑文本的transformers，这些结果需要在输入模型之前进行转换。
- en: For this reason, to tackle this task we used the **pdfplumber** library for
    various reasons. Firstly, it is built on pdfminer.six which we used for our preliminary
    analysis, meaning that it contains similar objects. In addition, its approach
    to table detection is based on line elements along with their intersections that
    construct the cell that contains the text and then the table itself. That way
    after we identify a cell of a table, we can extract just the content inside the
    cell without carrying how many rows needed to be rendered. Then when we have the
    contents of a table, we will format it in a table-like string and store it in
    the appropriate list.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了处理这个任务，我们使用了**pdfplumber**库。首先，它建立在我们用于初步分析的pdfminer.six之上，这意味着它包含类似的对象。此外，它的表格检测方法基于线条元素及其交点，这些元素构建了包含文本的单元格以及整个表格。这样，在我们识别表格单元格后，可以提取单元格内部的内容，而无需考虑需要渲染多少行。然后，当我们拥有表格内容时，我们会将其格式化为类似表格的字符串并存储在适当的列表中。
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To achieve that, we created two functions, **extract_table()** to extract the
    contents of the table into a list of lists, and **table_converter()** to join
    the contents of those lists in a table-like string.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们创建了两个函数，**extract_table()**用于将表格内容提取为列表的列表，**table_converter()**用于将这些列表的内容连接成类似表格的字符串。
- en: 'In the **extract_table()** function:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在**extract_table()**函数中：
- en: We open the PDF file.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们打开PDF文件。
- en: We navigate to the examined page of the PDF file.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导航到PDF文件的检查页面。
- en: From the list of tables found on the page by pdfplumber, we select the desired
    one.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从pdfplumber找到的页面中的表格列表中，我们选择所需的表格。
- en: We extract the content of the table and output it in a list of nested lists
    representing each row of the table.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们提取了表格的内容，并将其输出为表示每行的嵌套列表。
- en: 'In the **table_converter()** function:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在**table_converter()**函数中：
- en: We iterate in each nested list and clean its context from any unwanted line
    breaks coming from any wrapped text.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们遍历每个嵌套列表，并清除任何来自换行文本的多余换行符。
- en: We join each element of the row by separating them using the | symbol to create
    the structure of a table’s cell.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过使用|符号分隔行中的每个元素，以创建表格单元格的结构。
- en: Finally, we add a line break at the end to move to the next row.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们在末尾添加一个换行符，以移动到下一行。
- en: This will result in a string of text that will present the content of the table
    without losing the granularity of the data presented in it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个文本字符串，展示表格的内容，而不会丢失呈现的数据的细节。
- en: Adding all together
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起
- en: Now that we have all the components of the code ready let’s add them all up
    to a fully functional code. You can copy the code from here or you can find it
    along with the example PDF in my Github repo [here](https://github.com/g-stavrakis/PDF_Text_Extraction).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已准备好所有代码组件，让我们将它们整合成一个完整的代码。你可以从这里复制代码，或者你可以在我的Github仓库[这里](https://github.com/g-stavrakis/PDF_Text_Extraction)找到它及示例PDF。
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The script above will:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的脚本将：
- en: Import the necessary libraries.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 导入必要的库。
- en: Open the PDF file using the **pyPDF2** library.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**pyPDF2**库打开PDF文件。
- en: Extract each page of the PDF and iterate the following steps.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 提取PDF的每一页，并执行以下步骤。
- en: Examine if there are any tables on the page and create a list of them using
    **pdfplumner.**
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 检查页面上是否有表格，并使用**pdfplumner**创建一个表格列表。
- en: Find all the elements nested in the page and sort them as they appeared in its
    layout.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 查找页面中嵌套的所有元素，并按其在布局中出现的顺序对它们进行排序。
- en: 'Then for each element:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然后对每个元素：
- en: Examine if it is a text container, and does not appear in a table element. Then
    use the **text_extraction**() function to extract the text along with its format,
    else pass this text.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 检查是否为文本容器，并且不出现在表格元素中。然后使用**text_extraction**()函数提取文本及其格式，否则忽略此文本。
- en: Examine if it is an image, and use the **crop_image**() function to crop the
    image component from the PDF, convert it into an image file using the **convert_to_images**(),
    and extract text from it using OCR with the **image_to_text**() function.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 检查是否为图像，并使用**crop_image**()函数从PDF中裁剪图像组件，使用**convert_to_images**()将其转换为图像文件，并使用OCR和**image_to_text**()函数提取文本。
- en: 'Examine if it is a rectangular element. In this case, we examine if the first
    rect is part of a page’s table and if yes, we move to the following steps:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 检查是否为矩形元素。在这种情况下，我们检查第一个矩形是否是页面表格的一部分，如果是，则转到以下步骤：
- en: Find the bounding box of the table in order not to extract its text again with
    the text_extraction() function.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查找表格的边界框，以避免使用text_extraction()函数再次提取其文本。
- en: Extract the content of the table and convert it into a string.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取表格内容并将其转换为字符串。
- en: Then add a boolean parameter to clarify that we extract text from Table.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后添加一个布尔参数，以澄清我们是否从表格中提取文本。
- en: This process will finish after the last LTRect that falls into the bounding
    box of the table and the next element in the layout is not a rectangular object.
    (All the other objects that compose the table will be passed)
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个过程将在最后一个LTRect落在表格的边界框内，并且布局中的下一个元素不是矩形对象后结束。（所有组成表格的其他对象将被忽略）
- en: 'The outputs of the process will be stored in 5 lists per iteration, named:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程的输出将每次迭代存储在5个列表中，命名为：
- en: 'page_text: contains the text coming from text containers in the PDF (placeholder
    will be placed when the text was extracted from another element)'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'page_text: 包含来自PDF文本容器的文本（当文本从另一个元素中提取时，将放置占位符）'
- en: 'line_format: contains the formats of the texts extracted above (placeholder
    will be placed when the text was extracted from another element)'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'line_format: 包含上面提取的文本的格式（当文本从另一个元素中提取时，将放置占位符）'
- en: 'text_from_images: contains the texts extracted from images on the page'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'text_from_images: 包含从页面上的图像提取的文本'
- en: 'text_from_tables: contains the table-like string with the contents of tables'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'text_from_tables: 包含表格内容的类似表格的字符串'
- en: 'page_content: contains all the text rendered on the page in a list of elements'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'page_content: 包含以元素列表形式呈现的页面上所有文本'
- en: All the lists will be stored under the key in a dictionary that will represent
    the number of the page examined each time.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 所有列表将存储在一个字典的键下，该字典将表示每次检查的页面编号。
- en: Afterwards, we will close the PDF file.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将关闭PDF文件。
- en: Then we will delete all the additional files created during the process.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将删除在过程中创建的所有额外文件。
- en: Lastly, we can display the content of the page by joining the elements of the
    page_content list.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以通过连接page_content列表的元素来显示页面内容。
- en: Conclusion
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This was one approach that I believe uses the best characteristics of many libraries
    and makes the process resilient to various types of PDFs and elements that we
    can encounter, with PDFMiner however do the most of the heavy lifting. Also, the
    information regarding the format of the text can help us with the identification
    of potential titles that can separate the text into distinct logical sections
    rather than just content per page and can help us to identify the text of greater
    importance.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种方法，我认为它结合了许多库的最佳特性，使过程对各种类型的PDF和我们可能遇到的元素具有弹性，但主要依赖PDFMiner进行繁重的工作。此外，关于文本格式的信息可以帮助我们识别潜在的标题，这些标题可以将文本划分为不同的逻辑部分，而不仅仅是按页面内容，并有助于识别更重要的文本。
- en: However, there will always be more efficient ways to do this task and even though
    I believe that this approach is more inclusive, I am really looking forward to
    discussing with you new and better ways of tackling this problem.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，总会有更高效的方法来完成此任务，尽管我认为这种方法更具包容性，我非常期待与您讨论新的和更好的解决此问题的方法。
- en: '📖 References:'
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 📖 参考文献：
- en: '[https://www.techopedia.com/12-practical-large-language-model-llm-applications](https://www.techopedia.com/12-practical-large-language-model-llm-applications)'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.techopedia.com/12-practical-large-language-model-llm-applications](https://www.techopedia.com/12-practical-large-language-model-llm-applications)'
- en: '[https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf](https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf)'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf](https://www.pdfa.org/wp-content/uploads/2018/06/1330_Johnson.pdf)'
- en: '[https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR](https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR)
    technology reads text from, a searchable and editable PDF.'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR](https://pdfpro.com/blog/guides/pdf-ocr-guide/#:~:text=OCR)
    技术可以读取文本，从而生成可搜索和可编辑的 PDF。'
- en: '[https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1](https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1)'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1](https://pdfminersix.readthedocs.io/en/latest/topic/converting_pdf_to_text.html#id1)'
- en: '[https://github.com/pdfminer/pdfminer.six](https://github.com/pdfminer/pdfminer.six)'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/pdfminer/pdfminer.six](https://github.com/pdfminer/pdfminer.six)'
