- en: Five Things GenAI Can and Can’t Do
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 五件事 GenAI 能做和不能做的事情
- en: 原文：[https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4](https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4](https://towardsdatascience.com/five-things-genai-can-and-cant-do-d8117aad82f4)
- en: An introductory guide for business leaders as to what Generative AI can or cannot
    do
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为商业领袖提供的关于生成型AI能做或不能做的介绍性指南
- en: '[](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[![David
    Hundley](../Images/1779ef96ec3d338f8fe4a9567ba7b194.png)](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    [David Hundley](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[![David
    Hundley](../Images/1779ef96ec3d338f8fe4a9567ba7b194.png)](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)[![数据科学的前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    [David Hundley](https://dkhundley.medium.com/?source=post_page-----d8117aad82f4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    ·11 min read·Oct 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [数据科学的前沿](https://towardsdatascience.com/?source=post_page-----d8117aad82f4--------------------------------)
    ·11分钟阅读·2023年10月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/eb063b6b18c957526b4addb9f73e4feb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb063b6b18c957526b4addb9f73e4feb.png)'
- en: Cover photo created by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 封面照片由作者创作
- en: It’s hard to believe that it’s still not quite been a year since ChatGPT’s launch,
    and we have seen Generative AI (GenAI) take the world by storm. From large language
    models (LLMs) to stable diffusion models for image generation, it is really quite
    remarkable what this new technology can do. A friend described it to me as the
    first time AI has felt tangible to them, as if what we only dreamed about through
    science fiction has now become reality.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 难以置信的是，自ChatGPT发布以来还不到一年，我们已经看到生成型AI（GenAI）席卷了整个世界。从大型语言模型（LLM）到稳定扩散模型用于图像生成，这项新技术所能做的确实令人惊叹。一位朋友告诉我，这是AI第一次让他们感到触手可及，就像我们通过科幻小说梦想到的东西现在已经变成现实。
- en: Naturally, this has given business leaders pause to wonder what GenAI can or
    can’t do to transform their business processes. There are certainly many cool
    things you can do with GenAI, but there are also some misconceptions floating
    around out there that business leaders should be cautious about. The focus of
    this post is to share with you some of the core things that GenAI can do while
    also tempering one’s expectations to caution on what it cannot do.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这让商业领袖们开始思考GenAI能或不能做什么来转变他们的业务流程。确实，你可以用GenAI做很多酷的事情，但也有一些流传的误解，商业领袖们应该小心。本文的重点是与您分享GenAI能够做的一些核心事情，同时也提醒对其不能做的事情保持适当的期望。
- en: 'Can #1: GenAI can summarize a lot of information.'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '能做的 #1：GenAI可以总结大量信息。'
- en: Perhaps one of the most classic use cases I’m hearing across all industries
    is the ability to use large language models (LLM) in particular to condense a
    lot of information into something far more digestible. For example, you can take
    a transcribed dialogue from a meeting and use GenAI to summarize the information
    into a few key bullets. Additionally, you can take a large legal document and
    have an LLM pull out the most relevant bits of information. Of course, you should
    always be cautious to verify that the output of the LLM is correct, but this can
    save a ton of time in many different business contexts. I highly expect this to
    continue to gain traction in more and more industries over time.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 也许我听到的所有行业中最经典的用例之一是，特别是利用大型语言模型（LLM）将大量信息压缩成更易于消化的内容。例如，你可以将会议的转录对话交给GenAI，总结成几个关键要点。此外，你可以将一份大型法律文件交给LLM，让它提取出最相关的信息。当然，你应该始终小心核实LLM的输出是否正确，但这在许多不同的业务环境中可以节省大量时间。我高度预期这将在更多行业中持续获得关注。
- en: 'Can’t #1: GenAI can’t ever be certain about anything.'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '不能做的 #1：GenAI永远无法对任何事情有确切的确定性。'
- en: Perhaps one of the greatest misconceptions about LLMs is that they can think.
    In reality, LLMs are simply word prediction machines, albeit these models are
    so interestingly precise that it almost appears as if they are emulating true
    consciousness. Because LLMs act on probabilities between words, it can never be
    truly certain of its final output. Ironically however, it always will produce
    a very confident output. We refer to these confident but false statements as **hallucinations**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 也许关于 LLM 的最大误解之一是它们能够思考。实际上，LLM 只是预测词汇的机器，尽管这些模型的精确度非常高，以至于看起来它们似乎在模拟真正的意识。由于
    LLM 是基于词汇之间的概率进行操作的，它永远不能真正确定最终输出。然而，具有讽刺意味的是，它总是会产生非常自信的输出。我们将这些自信但错误的陈述称为**虚构**。
- en: 'Consider the following sentence: “I like to drink ______ in the morning.” If
    you were to answer this as a human, you might scratch your head. We can fairly
    ascertain that the blank is a liquid of some sort, but what liquid is it precisely?
    Coffee? Tea? Water? Just like a human, the LLM also can’t be certain of the answer;
    however, unlike the human, the LLM won’t tell you, “I don’t know.” Instead, it
    will confidently give an answer, except you and I know that the LLM can’t possibly
    be certain of the answer. Let’s actually see how ChatGPT attempts to fill in this
    blank.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下句子：“I like to drink ______ in the morning。”如果你作为一个人来回答这个问题，可能会挠头。我们可以相当确定空白处是某种液体，但具体是什么液体呢？咖啡？茶？水？就像人类一样，LLM
    也不能确定答案；然而，不同于人类，LLM 不会告诉你“我不知道”。相反，它会自信地给出一个答案，尽管你和我知道 LLM 不能真正确定答案。让我们实际看看 ChatGPT
    如何尝试填补这个空白。
- en: '![](../Images/b97a5c187eb6db0b62d7b5965afad3f7.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b97a5c187eb6db0b62d7b5965afad3f7.png)'
- en: Screenshot of ChatGPT for iPad captured by the author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者拍摄的 iPad 上 ChatGPT 的截图
- en: As you can see, ChatGPT confidently fills in the blank as “coffee”, yet it gives
    no indication that maybe it filled it in incorrectly. Again, we refer to this
    overly confident “guess” as a hallucination, but we can diminish these hallucinations
    with the next bullet…
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，ChatGPT 自信地将空白填为“coffee”，但它没有表明也许填错了。我们再次将这种过度自信的“猜测”称为虚构，但我们可以通过下一个要点来减少这些虚构……
- en: 'Can #2: GenAI can give more informed answers with an augmented context.'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '#2：GenAI 可以通过增强的上下文提供更有根据的答案。'
- en: 'In the previous point, we noted that an LLM can’t be particularly sure how
    to fill the blank in for the following sentence: “I like to drink ______ in the
    morning.” We can, however, augment the knowledge of the LLM by providing it additional
    context. In the GenAI community, we refer to this as **retrieval augmented generation
    (RAG)**. If we were to ask the LLM to fill in the blank above without any additional
    context, it will definitely give us an answer, but that answer may be hallucinated.
    Now, let’s say we gave the LLM some additional context. Let’s alter what we might
    input to the LLM with the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一点中，我们提到 LLM 对以下句子中的空白填充没有特别确定性：“I like to drink ______ in the morning。”然而，我们可以通过提供额外的上下文来增强
    LLM 的知识。在 GenAI 社区，我们将此称为**检索增强生成（RAG）**。如果我们要求 LLM 在没有任何额外上下文的情况下填充上述空白，它肯定会给出一个答案，但那个答案可能是虚构的。现在，假设我们给
    LLM 一些额外的上下文。让我们修改输入给 LLM 的内容如下：
- en: 'My name is David Hundley. I like to drink a cold brew coffee from Starbucks
    each morning. Using this information, please fill in the blank in the following
    sentence: “I like to drink ______ in the morning.”'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我的名字是 David Hundley。我喜欢每天早晨喝一杯 Starbucks 的冷萃咖啡。使用这些信息，请填补以下句子中的空白：“I like to
    drink ______ in the morning。”
- en: Now that the LLM has been provided some very specific context, it can sufficiently
    fill in the blank. Testing this out in ChatGPT, you’ll see that we receive the
    precisely correct answer.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，LLM 已经获得了一些非常具体的上下文，它可以充分填补空白。在 ChatGPT 中测试时，你会看到我们收到的是精确的正确答案。
- en: '![](../Images/6e1baeab36c1aa690118aea930ee7cf1.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e1baeab36c1aa690118aea930ee7cf1.png)'
- en: Screenshot of ChatGPT for iPad captured by the author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者拍摄的 iPad 上 ChatGPT 的截图
- en: Of course, this still does not make the output of an LLM completely surefire
    in its response. Remember, the LLM is assessing probabilities between words. In
    the RAG process, we are simply augmenting the probability of producing an output
    with a more correct answer. This doesn’t boost the probability of certainty to
    100%, but it definitely can help quite a bit!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这仍然不会使 LLM 的输出完全可靠。请记住，LLM 在评估词汇之间的概率。在 RAG 过程中，我们只是通过更正确的答案增强了输出的概率。这并不会将确定性的概率提升到
    100%，但确实可以提供很大帮助！
- en: 'Can’t #2: GenAI can’t figure out new things on it’s own.'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '无法解决 #2：GenAI 不能自己解决新问题。'
- en: While the RAG process can go a long way to help GenAI provide a more precise
    answer, the RAG process is not one that is automatic. In other words, GenAI technologies
    like LLMs don’t have the ability to go learning things for itself. These GenAI
    models are trained on information provided to it at a snapshot in time, almost
    as if its knowledge is frozen to that fixed date. When we provide additional context
    to the LLM, the context can be helpful to produce a more precise output, but **this
    RAG context is NOT actually altering the underlying model itself**.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 RAG 过程可以在很大程度上帮助 GenAI 提供更精确的回答，但 RAG 过程并不是自动的。换句话说，像 LLMs 这样的 GenAI 技术没有自我学习的能力。这些
    GenAI 模型是在某一时间点提供的信息上进行训练的，几乎就像它们的知识被冻结在那个固定日期。当我们向 LLM 提供额外的上下文时，这些上下文可以帮助生成更精确的输出，但**这个
    RAG 上下文实际上并不会改变基础模型本身**。
- en: The reason I bring this up is while the RAG process can be great, it’s not like
    you can tell GenAI itself to go find that information for itself. Even in the
    cases like Bing Chat where it appears that the LLM is searching the internet,
    it is not actually the model that is crawling the internet. **Rather, the information
    is being brought to the LLM, and the LLM is making sense of what is brought to
    it.** We’ve not yet reached that Skynet-like level of superintelligence where
    these AI models can figure things out for themselves. 🤖
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我提到这一点的原因是，尽管 RAG 过程可能很有用，但你不能让 GenAI 自行去寻找这些信息。即使像 Bing Chat 这样的案例中，LLM 似乎在搜索互联网，但实际上并不是模型在爬取互联网。**而是信息被带到
    LLM，LLM 在理解这些带来的信息。** 我们还没有达到那种像天网一样的超级智能水平，能够让这些 AI 模型自己解决问题。🤖
- en: 'Can #3: GenAI can be a great coding assistant.'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '可以解决 #3：GenAI 可以是一个很棒的编码助手。'
- en: Pay close attention to the phrasing on this particular one. I’m very intentional
    about the word “can” with this point. It’s no secret that people have found ways
    to leverage LLMs for coding purposes, and to be perfectly clear, LLMs can be great
    for helping to write code. Whether it be autofilling common tasks or helping to
    debug errors, GenAI can be a very useful tool when it comes to coding.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请特别注意这一点的措辞。我在这个点上对“能”这个词非常讲究。人们已经发现了利用 LLM 进行编码的方式，这并不是什么秘密。明确来说，LLM 在帮助编写代码方面可以非常出色。无论是自动填充常见任务还是帮助调试错误，GenAI
    在编码时可以是一个非常有用的工具。
- en: The thing is… LLMs aren’t perfect in this task. In addition to being limited
    by being trained on information at a snapshot in time, my personal experience
    is that the LLMs tend to hallucinate quite a bit when asked to write code for
    very nuanced situations. **Remember, LLMs are only as good as the context you
    provide it.** If you have an error that stems from something related to your very
    specific system, the LLM can’t be aware of your system’s details and will thus
    ultimately hallucinate the answer. This isn’t to say that GenAI can’t be helpful
    for writing code, but I would view it more as an assistant than anything.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于…… LLM 在这个任务上并不完美。除了受限于在某一时间点的训练信息外，根据我的个人经验，LLM 在被要求编写非常细致的代码时，往往会出现幻觉现象。**请记住，LLM
    仅能根据你提供的上下文来工作。** 如果你有一个源于你非常特定系统的错误，LLM 无法了解你系统的细节，因此最终会产生幻觉性的答案。这并不是说 GenAI
    无法在编写代码时提供帮助，但我认为它更像是一个助手。
- en: 'Can’t #3: GenAI can’t be certain if another piece of content was created by
    GenAI.'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '无法解决 #3：GenAI 无法确定另一段内容是否由 GenAI 创建。'
- en: This is one of those points where researchers have waffled back and forth. In
    fact, OpenAI at one point released a tool to help teachers determine if a piece
    of homework was created using ChatGPT. Eventually, OpenAI retracted this tool,
    and if you understand the underlying math and architecture of these GenAI solutions,
    I would contest that we’re quickly getting to a point where this will literally
    be impossible.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个研究人员来回摇摆的点。实际上，OpenAI 曾经发布过一个工具，以帮助教师判断作业是否是使用 ChatGPT 创建的。最终，OpenAI 收回了这个工具，如果你了解这些
    GenAI 解决方案的基础数学和架构，我认为我们很快将达到一个这种事情实际上是不可能的阶段。
- en: Consider the most advanced LLMs on the market right now, including OpenAI’s
    GPT-4 and Anthropic’s Claude 2\. These LLMs can produce outputs that appear extremely
    human-like, and this is because the underlying architecture is able to assess
    the probabilities between words with a staggering level of precision. Carefully
    treading the line between actual and artificial consciousness, one can’t help
    but wonder if human speech can also be predicted as probabilities between words.
    At that point, the end results of an LLM and a human are probabilistically indistinguishable,
    so no tool would be able to definitively say, “This was made by GenAI; this was
    made by a human.”
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下当前市场上最先进的 LLM，包括 OpenAI 的 GPT-4 和 Anthropic 的 Claude 2。这些 LLM 可以生成看起来非常人性化的输出，这是因为其基础架构能够以令人震惊的精度评估单词之间的概率。在实际与人工意识之间小心翼翼地踩线时，人们不禁想知道，是否也可以将人类语言预测为单词之间的概率。在那种情况下，LLM
    和人类的最终结果在概率上是无法区分的，因此没有工具能够明确地说，“这是由 GenAI 制作的；这是由人类制作的。”
- en: '**All that to say, don’t fall for a tool that says it can distinguish what
    is generated by AI versus what is not.** Perhaps with more primitive GenAI solutions,
    it can do some level of assessment there, but we have arguably already surpassed
    that point of distinguishability with LLMs like GPT-4.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**总之，不要被那些声称可以区分由 AI 生成的内容和非 AI 生成的内容的工具所迷惑。** 也许在更原始的 GenAI 解决方案中，它可以进行一定程度的评估，但我们可以说，像
    GPT-4 这样的 LLM 已经超越了这种区分的程度。'
- en: 'Can #4: GenAI can be helped along by other software processes.'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '可以 #4：GenAI 可以通过其他软件过程获得帮助。'
- en: While most people are more familiar with interacting with LLMs through a user
    interface like ChatGPT, almost all the major GenAI players offer programmatic
    solutions through things like APIs. This means we can engineer GenAI technology
    into new and existing software processes. In fact, most GenAI startups are doing
    precisely this. Specifically, many GenAI startups are using APIs from providers
    like OpenAI or Anthropic as a backend “engine” to support their GenAI needs. (Which
    is why you should also be careful who your company chooses to do business with,
    as they are probably interacting with a 4th party behind the scenes!)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然大多数人更熟悉通过像 ChatGPT 这样的用户界面与 LLM 互动，但几乎所有主要的 GenAI 参与者都通过 API 等方式提供编程解决方案。这意味着我们可以将
    GenAI 技术嵌入到新的和现有的软件过程中。事实上，大多数 GenAI 初创公司正在做的正是这一点。具体来说，许多 GenAI 初创公司使用像 OpenAI
    或 Anthropic 这样的提供商的 API 作为后端“引擎”来支持他们的 GenAI 需求。（这也是为什么你应该小心你的公司选择与谁合作，因为他们可能在幕后与第四方互动！）
- en: Again, **it can’t be overstated that GenAI should *always* be tempered for hallucinations**.
    While GenAI can produce snippets of code to do things like query specific information
    from a database, I personally would never rely on an LLM for a task like this.
    Because we can’t have 100% certainty that the code would be correct, it would
    be imprudent to rely on GenAI this way. This isn’t to say you should never incorporate
    GenAI into your software systems! There are still great use cases where you can
    leverage GenAI in a programmatic solution in a way that is still beneficial while
    also still being cautious.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，**GenAI 应该*始终*小心幻觉**。虽然 GenAI 可以生成代码片段以执行如从数据库查询特定信息等任务，但我个人绝不会依赖 LLM 来完成这样的任务。因为我们不能百分之百确定代码的正确性，所以依赖
    GenAI 是不明智的。这并不是说你应该完全不将 GenAI 结合到你的软件系统中！仍然有很好的用例，你可以以仍然有益且保持谨慎的方式在编程解决方案中利用
    GenAI。
- en: 'Can’t #4: GenAI can’t properly cite its own source information.'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '不能 #4：GenAI 无法正确引用其自身的信息来源。'
- en: This is a question I’m asked pretty frequently, and if you’ve been paying close
    attention this far, you’ll understand why this isn’t possible. Though LLMs are
    trained on information at a snapshot in time, it’s not as if it is tying all the
    probabilities between words back to specific sources. What the LLM is only storing
    is referred to what is known as **weights and biases**. Without going too deep
    into the underlying architecture of LLMs, LLMs are essentially comprised of tons
    of mathematical operations, and at the time of training, these weights and biases
    are updated to more closely align to the information it is being trained on. (Actually,
    if I were to deeply explain the architecture of an LLM, you’d be astounded that
    the math is rudimentary enough that it almost seems magical that LLMs can do as
    much as they can!)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我经常被问到的问题，如果你到现在为止都在认真听讲，你会明白为什么这是不可能的。尽管LLM是在某一时间点上的信息上进行训练的，但并不是说它将所有词语之间的概率联系到具体的来源。LLM所存储的仅仅是被称为**权重和偏差**的东西。无需深入LLM的底层架构，LLM本质上由大量数学操作组成，在训练时，这些权重和偏差会更新以更贴近它所训练的信息。（实际上，如果我详细解释LLM的架构，你会惊讶于数学的基础到几乎令人感到神奇的程度，LLM能够做得如此之多！）
- en: That’s all there is to an LLM. **There’s no direct tie back to the source information,
    so if you were to ask it to cite its own source, you would receive a hallucination
    at best**. I actually believe specific LLMs like ChatGPT have been fine tuned
    to say that its not possible to reveal its sources, which I would say is a better
    response than a hallucinated one. But it’s not impossible to receive a hallucinated
    response. There’s [the infamous scenario](https://www.pymnts.com/artificial-intelligence-2/2023/attorneys-face-sanctions-after-citing-information-hallucinated-by-chatgpt/)
    where a lawyer used an LLM to cite a source in a legal case, and it was discovered
    that the cited source was hallucinated and ultimately fake. Be careful you don’t
    also fall into this same trap!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是LLM的全部内容。**没有直接联系到源信息，因此如果你要求它引用自己的来源，你最多只能得到虚假的回答**。我实际上相信像ChatGPT这样的特定LLM已经被微调，以表示不可能揭示其来源，我认为这比虚假的回答要好。但是，获得虚假回答并非不可能。有[那个臭名昭著的案例](https://www.pymnts.com/artificial-intelligence-2/2023/attorneys-face-sanctions-after-citing-information-hallucinated-by-chatgpt/)，一名律师使用LLM在法律案件中引用了一个来源，结果发现该来源是虚假的，最终是假的。小心不要陷入同样的陷阱！
- en: 'Can #5: GenAI can be a fantastic way to augment your own knowledge.'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可以#5：GenAI可以极大地增强你的知识。
- en: Similar to the point where GenAI can be a good assistant at writing code, GenAI
    can also simply be a good assistant at any knowledge task. I personally use LLMs
    like ChatGPT as a sort of “search engine” for general knowledge questions. For
    example, it is excellent at providing definitions to words, and it is great to
    receive more elaborative answers as you follow up with additional questions. It’s
    like interacting with a very knowledgeable friend. While internet search engines
    can provide the most up-to-date and relevant information, the back-and-forth of
    a conversation flow is unmatched by a barebones search engine.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与GenAI可以作为编写代码的良好助手的观点类似，GenAI也可以成为任何知识任务的好助手。我个人将LLM（如ChatGPT）用作一种“搜索引擎”来回答一般知识问题。例如，它在提供词汇定义方面表现出色，并且在你继续提出额外问题时，它能给出更详尽的回答。就像和一个非常有知识的朋友互动一样。虽然互联网搜索引擎可以提供最新和最相关的信息，但对话的互动流程是基本搜索引擎无法比拟的。
- en: Of course, I shouldn’t have to remind you by this point to be careful for hallucinations.
    While LLMs might be more helpful about historical events and locations like Ancient
    Rome, you’ll certainly receive a hallucinated answer if you asked it what today’s
    weather is. If it does provide back a correct answer, this would again be because
    the LLM is being augmented in a RAG manner, NOT because the LLM was able to derive
    that information itself. Also, beware of using LLMs for math problems specifically.
    Remember, these LLMs are trained to look for probabilities between words, so there’s
    not any mathematical computation being done when a math problem is given to it.
    In recent months, popular LLMs like ChatGPT have been seemingly augmented to handle
    math problems better, but it is unclear how they are doing this. In any case,
    I would still try to avoid doing complex math problems with an LLM.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我不应该再提醒你注意幻觉。虽然大型语言模型（LLMs）可能在历史事件和地点如古罗马方面更为有用，但如果你问它今天的天气，它肯定会给出一个虚假的答案。如果它提供了正确的答案，那是因为LLM以RAG方式被增强，而不是因为LLM能自行得出这些信息。另外，特别要小心使用LLM解决数学问题。记住，这些LLM是通过寻找单词之间的概率来进行训练的，所以在面对数学问题时，并没有进行实际的数学计算。最近几个月，像ChatGPT这样的流行LLM似乎被增强以更好地处理数学问题，但不清楚它们是如何做到的。在任何情况下，我仍然建议尽量避免用LLM解决复杂的数学问题。
- en: 'Can’t #5: GenAI can’t take your job. (…Yet?)'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '无法做到 #5：GenAI无法取代你的工作。（…还没有？）'
- en: 'Ah yes, the big question on everybody’s mind! Actually, I guess if I’m being
    totally honest, GenAI can be used to reduce a human workforce, but we’re definitely
    not at the point where it’s going to eliminate most people’s jobs. If you paid
    close attention to the sections in this post around information retrieval, you’ll
    recognize GenAI’s biggest “flaw” preventing it from taking everybody’s jobs: **GenAI
    has no way to proactively learn for itself**. GenAI can’t talk to your CEO and
    tease out what’s in their head. GenAI can’t jump in your skull to understand all
    the little nuances of the website you’ve dreamed in your imagination. In this
    way, I consider GenAI to be like a totally naive genius: you can get it to do
    a lot, but you have to be upfront and extremely specific with it to get the most
    ideal results.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，是的，大家最关心的问题！其实，如果我完全诚实的话，GenAI可以用来减少人力，但我们绝对还未达到它会取代大多数人工作的地步。如果你仔细阅读了本帖关于信息检索的部分，你会发现GenAI无法取代所有人的工作的最大“缺陷”：**GenAI无法主动自学**。GenAI无法与您的CEO交谈并了解他们脑中的想法。GenAI无法进入你的脑袋，理解你在想象中构建的网站的所有细微差别。以这种方式，我认为GenAI就像一个完全天真的天才：你可以让它做很多事，但你必须直接而极其具体地与它沟通，以获得最理想的结果。
- en: 'The natural follow up question is: will AI ever get to the point where it can
    do these things? We refer to this next level of superintelligence as **artificial
    general intelligence (AGI)**, and it is why AI safety advocates are raising concern
    with AI progress. The goal is to safely align human interests with AI interests.
    Without dwelling on this topic further, the point is we are not at that point
    today, and it really is unknown at point we will hit the singularity — the point
    at which we do reach AGI. If you understand the history of AI research, you’ll
    quickly learn humanity isn’t very good at predicting this point. 😂'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 自然的后续问题是：AI是否会达到能够完成这些事情的程度？我们将这一超级智能的下一个层次称为**人工通用智能（AGI）**，这也是AI安全倡导者对AI进展表示关注的原因。目标是安全地使人类利益与AI利益对齐。不再深入讨论这一话题，重点是我们今天还未达到这一点，也真的不清楚我们何时会到达奇点——即我们达到AGI的那一点。如果你了解AI研究的历史，你会很快发现人类在预测这一点上并不擅长。
    😂
- en: 'I hope you walk away from this post with a much better idea of what GenAI may
    or may not be good for. It is a truly astounding technology, but it’s not good
    for everything. One final point I should also highlight: **GenAI is not the only
    AI**. GenAI in its current form has been around as early as 2017, but we’ve had
    many other forms of AI that can still suitably get the job done. Just as you wouldn’t
    rent a car to walk ten feet, you should always attempt to rightsize the solution
    to meet the business need. GenAI is just another tool in our toolbox, albeit a
    very cool tool! 😃'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你能从这篇文章中更好地了解GenAI可能的优缺点。这是一项真正令人惊叹的技术，但并不是适用于所有情况。我还要强调的一点是：**GenAI并不是唯一的AI**。GenAI的当前形式最早出现在2017年，但我们还有许多其他形式的AI也能有效完成任务。就像你不会租车走十英尺一样，你应该始终尝试调整解决方案以满足业务需求。GenAI只是我们工具箱中的另一个工具，尽管是一个非常酷的工具！
    😃
