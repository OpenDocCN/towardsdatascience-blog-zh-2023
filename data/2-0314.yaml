- en: Another (Conformal) Way to Predict Probability Distributions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另一种（符合性）预测概率分布的方法
- en: 原文：[https://towardsdatascience.com/another-conformal-way-to-predict-probability-distributions-fcc63e78680d](https://towardsdatascience.com/another-conformal-way-to-predict-probability-distributions-fcc63e78680d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/another-conformal-way-to-predict-probability-distributions-fcc63e78680d](https://towardsdatascience.com/another-conformal-way-to-predict-probability-distributions-fcc63e78680d)
- en: Conformal multi-quantile regression with Catboost
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Catboost 进行符合性多分位回归
- en: '[](https://harrisonfhoffman.medium.com/?source=post_page-----fcc63e78680d--------------------------------)[![Harrison
    Hoffman](../Images/5eaa3e2bd0507297eb6c4a7efcf06324.png)](https://harrisonfhoffman.medium.com/?source=post_page-----fcc63e78680d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fcc63e78680d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fcc63e78680d--------------------------------)
    [Harrison Hoffman](https://harrisonfhoffman.medium.com/?source=post_page-----fcc63e78680d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://harrisonfhoffman.medium.com/?source=post_page-----fcc63e78680d--------------------------------)[![Harrison
    Hoffman](../Images/5eaa3e2bd0507297eb6c4a7efcf06324.png)](https://harrisonfhoffman.medium.com/?source=post_page-----fcc63e78680d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fcc63e78680d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fcc63e78680d--------------------------------)
    [Harrison Hoffman](https://harrisonfhoffman.medium.com/?source=post_page-----fcc63e78680d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fcc63e78680d--------------------------------)
    ·11 min read·Mar 8, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fcc63e78680d--------------------------------)
    ·阅读时间 11 分钟·2023年3月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/01cf92583ef3188b5333a9ebc8b32e34.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01cf92583ef3188b5333a9ebc8b32e34.png)'
- en: Texas. Image by Author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 德克萨斯州。图像来源：作者。
- en: 'In a [previous article](https://medium.com/towards-data-science/a-new-way-to-predict-probability-distributions-e7258349f464),
    we explored the capabilities of Catboost’s multi-quantile loss function, which
    allows for the prediction of multiple quantiles using a single model. This approach
    elegantly overcomes one of the limitations of traditional quantile regression,
    which necessitates the development of a separate model for each quantile, or storing
    the entire training set in the model. However, there is another disadvantage to
    quantile regression, which we will discuss in this article: the potential for
    predicted quantiles to be biased, leaving no guarantees of calibration and coverage.
    This article will demonstrate a way to overcome this with conformal multi-quantile
    regression. I would encourage anyone who hasn’t been following this series to
    refer back to the following articles before reading:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [上一篇文章](https://medium.com/towards-data-science/a-new-way-to-predict-probability-distributions-e7258349f464)
    中，我们探索了 Catboost 的多分位损失函数的能力，该函数允许使用单一模型预测多个分位数。这种方法优雅地克服了传统分位回归的一项限制：后者需要为每个分位数开发一个单独的模型，或将整个训练集存储在模型中。然而，分位回归还有另一个缺点，我们将在本文中讨论：预测的分位数可能存在偏差，无法保证校准和覆盖。本文将演示如何通过符合性多分位回归来克服这一问题。我鼓励尚未跟进本系列的人在阅读之前回顾以下文章：
- en: '[](/a-new-way-to-predict-probability-distributions-e7258349f464?source=post_page-----fcc63e78680d--------------------------------)
    [## A New Way to Predict Probability Distributions'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-new-way-to-predict-probability-distributions-e7258349f464?source=post_page-----fcc63e78680d--------------------------------)
    [## 预测概率分布的新方法'
- en: Exploring multi-quantile regression with Catboost
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 探索 Catboost 的多分位回归
- en: towardsdatascience.com](/a-new-way-to-predict-probability-distributions-e7258349f464?source=post_page-----fcc63e78680d--------------------------------)
    [](/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=post_page-----fcc63e78680d--------------------------------)
    [## Understanding Noisy Data and Uncertainty in Machine Learning
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-new-way-to-predict-probability-distributions-e7258349f464?source=post_page-----fcc63e78680d--------------------------------)
    [](/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=post_page-----fcc63e78680d--------------------------------)
    [## 理解机器学习中的噪声数据和不确定性
- en: The actual reason your machine learning model isn’t working
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实际原因是你的机器学习模型未能正常工作
- en: towardsdatascience.com](/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=post_page-----fcc63e78680d--------------------------------)
    [](/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4?source=post_page-----fcc63e78680d--------------------------------)
    [## How To Predict Risk-Proportional Intervals With “Conformal Quantile Regression”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 如何使用“符合分位数回归”预测风险比例区间](https://towardsdatascience.com/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=post_page-----fcc63e78680d--------------------------------)
    [如何预测风险比例区间与符合分位数回归](https://towardsdatascience.com/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4?source=post_page-----fcc63e78680d--------------------------------)'
- en: This algorithm — published in 2019 by Stanford scholars — combines quantile
    regression with conformal prediction. Here…
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这个算法——由斯坦福学者在2019年发布——将分位数回归与符合预测结合在一起。这里…
- en: towardsdatascience.co](/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4?source=post_page-----fcc63e78680d--------------------------------)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何预测风险比例区间与符合分位数回归](https://towardsdatascience.com/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4?source=post_page-----fcc63e78680d--------------------------------)'
- en: 'Recap: Why Multi-Quantile Regression?'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾：为何选择多分位数回归？
- en: Multi-quantile regression enables us to use a single moded to predict multiple
    target quantiles. Because there is no computational constraint necessitating one
    model per quantile, or the limitation of storing the entire training set in the
    model (e.g. KNN, Quantile Regression Forests), we can efficiently predict more
    quantiles and get a better feel for how the conditional target distribution looks.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 多分位数回归使我们能够使用一个模型预测多个目标分位数。因为没有计算限制要求每个分位数一个模型，也没有像KNN或分位数回归森林那样需要在模型中存储整个训练集的限制，我们可以更有效地预测更多分位数，并更好地了解条件目标分布的样貌。
- en: 'Using traditional quantile regression, generating a 95% prediction interval
    would require one model for the 2.5th quantile, one for the 97.5th quantile, and
    possibly a third for the expected value or the 50th quantile. A single prediction
    from each model would look something like this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统的分位数回归，生成95%的预测区间需要一个用于2.5分位数的模型，一个用于97.5分位数的模型，可能还需要一个用于期望值或50分位数的模型。每个模型的单次预测结果大致如下：
- en: '![](../Images/7be767b1a5b1e2a071524aeb2d961a12.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7be767b1a5b1e2a071524aeb2d961a12.png)'
- en: Predicted [CDF](https://en.wikipedia.org/wiki/Cumulative_distribution_function)
    samples for a single test example (three independent quantile models). Image by
    Author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的 [CDF](https://en.wikipedia.org/wiki/Cumulative_distribution_function) 样本用于单个测试样本（三个独立的分位数模型）。图像由作者提供。
- en: Assuming these quantiles are calibrated, they reveal a few insights. The first
    is the probability that the target is less than or equal to 3.6, *given the features,*
    is around 0.50 or 50%. Similarly, the probability that the target value is between
    3.25 and 4.38, given the features, is roughly 0.95 or 95%.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这些分位数经过校准，它们揭示了一些见解。首先，*给定特征*，目标小于或等于3.6的概率大约是0.50或50%。类似地，给定特征，目标值在3.25和4.38之间的概率大约是0.95或95%。
- en: 'While the models’ output is good and precisely what we required, we may want
    to adjust our risk tolerance dynamically. For instance, what if we need to be
    more conservative and require a 99% prediction interval? Similarly, what if we
    are more risk-seeking and can tolerate a 90% or 80% prediction interval? What
    if we want answers to questions like “given the features, what is the probability
    that the target is greater than y1?”. We might also want to ask questions like
    “given the features, what is the probability that the target is between y1 and
    y2?”. Multi-quantile regression facilities answering these questions by predicting
    as many quantiles as specified:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然模型的输出很好且符合我们的要求，但我们可能希望动态调整风险容忍度。例如，如果我们需要更保守的99%预测区间怎么办？类似地，如果我们更愿意承担风险，接受90%或80%预测区间怎么办？如果我们想知道“给定特征，目标大于y1的概率是多少？”我们可能还想问“给定特征，目标在y1和y2之间的概率是多少？”多分位数回归通过预测尽可能多的分位数来帮助回答这些问题：
- en: '![](../Images/71df22072ad003a551251cd98f8f619c.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71df22072ad003a551251cd98f8f619c.png)'
- en: Predicted [CDF](https://en.wikipedia.org/wiki/Cumulative_distribution_function)
    samples for a single test example (one multi-quantile model). Image by Author.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的 [CDF](https://en.wikipedia.org/wiki/Cumulative_distribution_function) 样本用于单个测试样本（一个多分位数模型）。图像由作者提供。
- en: The more quantiles that can be accurately predicted, the more the risk tolerance
    can be adjusted on the fly, and the more we can answer general probability questions
    about the conditional target distribution.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 能够准确预测的分位数越多，风险容忍度可以随时调整的余地就越大，我们可以更好地回答关于条件目标分布的一般概率问题。
- en: Note that single decision tree models have [been used](https://scikit-garden.github.io/examples/QuantileRegressionForests/)
    to generate multiple quantile predictions. However, this relies on the trees storing
    [all target values in the leaf nodes](https://scikit-garden.github.io/examples/QuantileRegressionForests/#:~:text=also%20all%20the%20target%20values%20in%20the%20leaf%20node.).
    At prediction time, a quantile is specified and computed empirically from the
    data in the leaf node, requiring the model to store the entire training set. This
    also means deep trees could have very few examples to work with in the leaf nodes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，单一决策树模型已被[用于](https://scikit-garden.github.io/examples/QuantileRegressionForests/)生成多个分位数预测。然而，这依赖于树将[所有目标值存储在叶子节点中](https://scikit-garden.github.io/examples/QuantileRegressionForests/#:~:text=also%20all%20the%20target%20values%20in%20the%20leaf%20node.)。在预测时，指定一个分位数，并从叶子节点中的数据中经验性地计算出来，这要求模型存储整个训练集。这也意味着深度树可能在叶子节点中只有很少的样本可供使用。
- en: Catboost is fundamentally different because it only stores the number of specified
    quantiles in the terminal nodes. Moreover, the loss function is optimized to predict
    each specified quantile. We also enjoy the [performance gains](/catboost-vs-lightgbm-vs-xgboost-c80f40662924#:~:text=However%2C%20generally%2C%20from%20the%20literature%2C%20XGBoost%20and%20LightGBM%20yield%20similar%20performance%2C%20with%20CatBoost%20and%20LightGBM%20performing%20much%20faster%20than%20XGBoost%2C%20especially%20for%20larger%20datasets.)
    Catboost offers with its underlying architecture.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Catboost 本质上有所不同，因为它仅在终端节点中存储指定的分位数的数量。此外，损失函数被优化以预测每个指定的分位数。我们还享受了[Catboost
    提供的性能提升](/catboost-vs-lightgbm-vs-xgboost-c80f40662924#:~:text=However%2C%20generally%2C%20from%20the%20literature%2C%20XGBoost%20and%20LightGBM%20yield%20similar%20performance%2C%20with%20CatBoost%20and%20LightGBM%20performing%20much%20faster%20than%20XGBoost%2C%20especially%20for%20larger%20datasets.)，这是其底层架构带来的优势。
- en: The Problem with Quantile Regression
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分位回归的问题
- en: In traditional and multi-quantile regression, [there isn’t always a statistical
    guarantee](https://arxiv.org/pdf/1905.03222.pdf) that quantiles are unbiased.
    This means, for a model trained to predict the 95th quantile of the target distribution,
    there’s no guarantee that 95% of observations will actually be less than or equal
    to the prediction. This is problematic in high-risk applications where accurate
    probability representations are required to make critical decisions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的和多分位回归中，[没有总是有统计保证](https://arxiv.org/pdf/1905.03222.pdf) 分位数是无偏的。这意味着，对于训练来预测目标分布的第95分位数的模型，并不能保证95%的观察值实际上会小于或等于预测值。这在需要准确概率表示来做出关键决策的高风险应用中是一个问题。
- en: Quantile regression can also produce prediction intervals that are [too conservative](https://arxiv.org/pdf/1905.03222.pdf)
    and subsequently uninformative. In general, prediction intervals should be as
    narrow as possible while maintaining the desired coverage level.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 分位回归也可能产生[过于保守](https://arxiv.org/pdf/1905.03222.pdf)的预测区间，进而导致信息不足。一般来说，预测区间应尽可能窄，同时保持所需的覆盖水平。
- en: Conformal Multi-Quantile Regression
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 符合性多分位回归
- en: 'The idea behind conformal quantile regression is to adjust predicted quantiles
    to accurately reflect the desired risk tolerance and interval length. This is
    accomplished through a “calibration” step that computes “conformity scores” to
    correct the predicted quantiles. More details about conformal quantile regression
    can be found in [this paper](https://arxiv.org/pdf/1905.03222.pdf) and [this article](/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4).
    For conformal multi-quantile regression, we will utilize the following theorem:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 符合性分位回归的想法是调整预测的分位数，以准确反映所需的风险容忍度和区间长度。这是通过一个“校准”步骤来完成的，该步骤计算“符合性得分”以纠正预测的分位数。有关符合性分位回归的更多细节可以在[这篇论文](https://arxiv.org/pdf/1905.03222.pdf)和[这篇文章](/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4)中找到。对于符合性多分位回归，我们将利用以下定理：
- en: '![](../Images/b04c51891814e8109f7dd4e1dcc6a51c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b04c51891814e8109f7dd4e1dcc6a51c.png)'
- en: Left and Right Tail Conformal Quantile Regression. [Source](https://arxiv.org/pdf/1905.03222.pdf).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 左尾和右尾符合性分位回归。[来源](https://arxiv.org/pdf/1905.03222.pdf)。
- en: 'Don’t worry if this seems overly abstract, the steps are actually straight
    forward:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这看起来过于抽象，请不要担心，步骤实际上很简单：
- en: Create a training, calibration, and testing set. Fit the multi-quantile model
    on the training set to predict all quantiles of interest.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练集、校准集和测试集。在训练集上拟合多分位模型以预测所有感兴趣的分位数。
- en: Make predictions on the calibration set. For each calibration instance and predicted
    quantile, compute the difference between the predicted quantile and the corresponding
    target value. These are the conformity scores.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在校准集上进行预测。对于每个校准实例和预测的分位数，计算预测分位数与对应目标值之间的差异。这些就是一致性分数。
- en: For each testing example and predicted quantile (say q), subtract the 1-q quantile
    of the conformity scores corresponding to quantile q from the predicted quantile
    of the model. These are the new predicted quantiles.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个测试示例和预测的分位数（假设为 q），从模型预测的分位数中减去对应于分位数 q 的一致性分数的 1-q 分位数。这些就是新的预测分位数。
- en: 'We can implement this logic in a python class:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Python 类中实现这个逻辑：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Example: The Superconductivity Dataset'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：超导性数据集
- en: We’ll implement conformal multi-quantile regression on the [superconductivity
    dataset](https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data) available
    on the UCI Machine Learning Repository. This dataset provides 21,263 instances
    of 81 [superconductor](https://en.wikipedia.org/wiki/Superconductivity) features
    with their [critical temperature](https://link.springer.com/article/10.1007/s42452-020-03266-0#:~:text=The%20critical%20temperature%20is%20the,critical%20temperature%20is%20mostly%20intuitive.)
    (the target). The data is split so that ~64% is allocated for training, ~16% for
    calibration, and 20% for testing.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对 [超导性数据集](https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data)
    上的 **超导体** 数据集进行一致性多分位回归。该数据集提供了 21,263 个包含 81 个 [超导体](https://en.wikipedia.org/wiki/Superconductivity)
    特征及其 [临界温度](https://link.springer.com/article/10.1007/s42452-020-03266-0#:~:text=The%20critical%20temperature%20is%20the,critical%20temperature%20is%20mostly%20intuitive.)
    （目标）。数据被划分为 ~64% 用于训练，~16% 用于校准，20% 用于测试。
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We’ll specify a set of quantiles to predict. To illustrate the power of multi-quantile
    regression, the model will predict 200 quantiles from 0.005 to 0.99 — this is
    probably a bit excessive in practice. Next, we’ll **fit** the conformal multi-quantile
    model, make **uncalibrated predictions**, **calibrate** the model on the **calibration
    set**, and make **calibrated predictions**.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将指定一组要预测的分位数。为了展示多分位回归的强大功能，该模型将预测从 0.005 到 0.99 的 200 个分位数——这在实际中可能有些过度。接下来，我们将
    **拟合** 一致性多分位模型，进行 **未经校准的预测**，在 **校准集** 上 **校准** 模型，并进行 **校准后的预测**。
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The resulting predictions should look something like this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 结果预测应如下所示：
- en: '![](../Images/07a90a10f8b5e439e10c8bf353f4d6ca.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07a90a10f8b5e439e10c8bf353f4d6ca.png)'
- en: First few predicted quantiles for the first 5 observations. Image by Author.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 前五个观察值的前几个预测分位数。图片来源于作者。
- en: 'On the testing set, we can measure how well the uncalibrated and calibrated
    predictions align with the left-tail probability they’re intended to represent.
    For instance, if the quantiles are calibrated, 40% of target values should be
    less than or equal to predicted quantile 0.40, 90% of target values should be
    less than or equal to predicted quantiles 0.90, etc. The code below computes the
    mean absolute error (MAE) between the desired left-tail probability and the actual
    left-tail probability encompassed by the predicted quantiles:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试集上，我们可以测量未经校准和校准的预测如何与它们所表示的左尾概率对齐。例如，如果分位数已校准，则 40% 的目标值应小于或等于预测分位数 0.40，90%
    的目标值应小于或等于预测分位数 0.90 等。下面的代码计算期望左尾概率与实际左尾概率之间的平均绝对误差（MAE）：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The uncalibrated quantiles were off by about 0.026 and the calibrated quantiles
    by 0.008, on average. Hence, the calibrated quantiles were more aligned with the
    desired left-tail probabilities.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 未校准的分位数平均偏差约为 0.026，而校准后的分位数偏差为 0.008。因此，校准后的分位数与期望的左尾概率更加一致。
- en: '![](../Images/b4c9d44ddb0b11485c9d1ce9f9ef6610.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4c9d44ddb0b11485c9d1ce9f9ef6610.png)'
- en: Actual vs Predicted Quantile Left-Tail Probabilities. Image by Author.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实际 vs 预测分位数的左尾概率。图片来源于作者。
- en: 'This may not seem like a dramatic difference in calibration, however, the error
    in the uncalibrated model is made more clear by analyzing actual v.s. desired
    coverage:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来不像校准中有戏剧性的变化，但通过分析实际与期望覆盖率，可以更清楚地看出未经校准模型中的误差：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/b38fa421c4d1f198b0c2d0c9ceac0fde.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b38fa421c4d1f198b0c2d0c9ceac0fde.png)'
- en: Actual vs Desired Coverage. Image by Author.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 实际覆盖率与期望覆盖率。图像来源：作者。
- en: The uncalibrated model tends to be too conservative and covers more examples
    than desired. The calibrated model, on the other hand, exhibits near-perfect alignment
    with each of the desired coverages.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 未校准模型往往过于保守，覆盖了比期望更多的示例。而校准模型则与每个期望的覆盖率几乎完美对齐。
- en: Moreover, the average length of the prediction intervals generated by the calibrated
    model is less than that of the uncalibrated model. Thus, not only is coverage
    better in the calibrated model, the prediction intervals are more informative.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，校准模型生成的预测区间的平均长度少于未校准模型。因此，校准模型的覆盖率更好，预测区间也更具信息性。
- en: '![](../Images/709c27217b03610a8832d2b49467e50f.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/709c27217b03610a8832d2b49467e50f.png)'
- en: Average Prediction Interval Length by Desired Coverage. Image by Author.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 按期望覆盖率的平均预测区间长度。图像来源：作者。
- en: 'One might ask what happens if we allow the uncalibrated model to include the
    calibration set as training data. This makes sense in practice because we wouldn’t
    throw away good training data for no reason. Here are the results:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会有人问，如果我们允许未校准模型将校准集作为训练数据会发生什么。这在实践中是合理的，因为我们不会无缘无故地丢弃好的训练数据。以下是结果：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Even with less training data than the uncalibrated model, the calibrated model
    outputs better quantiles. What’s more, the models perform similarly when we compare
    the expected values of the predicted quantiles to the target values:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在训练数据少于未校准模型的情况下，校准模型输出的分位数也更好。更重要的是，当我们将预测的分位数的期望值与目标值进行比较时，这些模型的表现相似：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Final Thoughts
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: There are no silver bullets in machine learning, and conformal quantile regression
    is no exception. The glue that holds conformal prediction theory together is the
    assumption that the underlying data is [exchangeable](https://en.wikipedia.org/wiki/Exchangeable_random_variables).
    If, for instance, the distribution of the data drifts over time (which is usually
    the case in many real world applications), then conformal prediction can no longer
    make strong probability guarantees. There are [ways around](https://arxiv.org/pdf/2202.13415.pdf)
    this assumption, but these methods ultimately depend on the severity of data drift
    and the nature of the learning problem. It may also be less than ideal to set
    aside valuable training data for calibration.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中没有万无一失的解决方案，符合性分位回归也不例外。支撑符合性预测理论的粘合剂是数据的[可交换性](https://en.wikipedia.org/wiki/Exchangeable_random_variables)假设。例如，如果数据的分布随时间漂移（这在许多实际应用中通常发生），那么符合性预测无法再提供强有力的概率保证。虽然有[绕过](https://arxiv.org/pdf/2202.13415.pdf)这一假设的方法，但这些方法最终取决于数据漂移的严重程度和学习问题的性质。将宝贵的训练数据用于校准也可能不是最佳选择。
- en: As always, the machine learning practitioner is responsible for understanding
    the nature of the data and applying appropriate techniques. Thanks for reading!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，机器学习从业者负责理解数据的性质并应用适当的技术。感谢阅读！
- en: '*Become a Member:* [*https://harrisonfhoffman.medium.com/membership*](https://harrisonfhoffman.medium.com/membership)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*成为会员：* [*https://harrisonfhoffman.medium.com/membership*](https://harrisonfhoffman.medium.com/membership)'
- en: References
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Catboost Loss Functions —* [https://catboost.ai/en/docs/concepts/loss-functions-regression#MultiQuantile](https://catboost.ai/en/docs/concepts/loss-functions-regression#MultiQuantile)'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Catboost 损失函数 —* [https://catboost.ai/en/docs/concepts/loss-functions-regression#MultiQuantile](https://catboost.ai/en/docs/concepts/loss-functions-regression#MultiQuantile)'
- en: '*Conformalized Quantile Regression* — [https://arxiv.org/pdf/1905.03222.pdf](https://arxiv.org/pdf/1905.03222.pdf)'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*符合性分位回归* — [https://arxiv.org/pdf/1905.03222.pdf](https://arxiv.org/pdf/1905.03222.pdf)'
- en: '*Conformal Prediction Beyond Exchangeability* — [https://arxiv.org/pdf/2202.13415.pdf](https://arxiv.org/pdf/2202.13415.pdf)'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*符合性预测超越可交换性* — [https://arxiv.org/pdf/2202.13415.pdf](https://arxiv.org/pdf/2202.13415.pdf)'
- en: '*The Superconductivity Dataset* — [https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data](https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data)'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*超导数据集* — [https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data](https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data)'
- en: '*How to Predict Risk-Proportional Intervals with Conformal Quantile Regression*
    — [https://towardsdatascience.com/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4](/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4)'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*如何使用保形分位回归预测风险比例区间* — [https://towardsdatascience.com/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4](/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4)'
- en: '*How to Predict Full Probability Distributions using Machine Learning Conformal
    Prediction* — [https://valeman.medium.com/how-to-predict-full-probability-distribution-using-machine-learning-conformal-predictive-f8f4d805e420](https://valeman.medium.com/how-to-predict-full-probability-distribution-using-machine-learning-conformal-predictive-f8f4d805e420)'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*如何使用机器学习保形预测预测完整概率分布* — [https://valeman.medium.com/how-to-predict-full-probability-distribution-using-machine-learning-conformal-predictive-f8f4d805e420](https://valeman.medium.com/how-to-predict-full-probability-distribution-using-machine-learning-conformal-predictive-f8f4d805e420)'
