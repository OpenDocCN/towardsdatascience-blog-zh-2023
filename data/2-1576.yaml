- en: Neural Prototype Trees
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经原型树
- en: 原文：[https://towardsdatascience.com/neural-prototype-trees-f7bac36437a9](https://towardsdatascience.com/neural-prototype-trees-f7bac36437a9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/neural-prototype-trees-f7bac36437a9](https://towardsdatascience.com/neural-prototype-trees-f7bac36437a9)
- en: Explainable image classification through mimicking human reasoning.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过模仿人类推理来实现可解释的图像分类。
- en: '[](https://medium.com/@upadhyan?source=post_page-----f7bac36437a9--------------------------------)[![Nakul
    Upadhya](../Images/336cb21272e9b1f098177adbde50e92e.png)](https://medium.com/@upadhyan?source=post_page-----f7bac36437a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f7bac36437a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f7bac36437a9--------------------------------)
    [Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----f7bac36437a9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@upadhyan?source=post_page-----f7bac36437a9--------------------------------)[![Nakul
    Upadhya](../Images/336cb21272e9b1f098177adbde50e92e.png)](https://medium.com/@upadhyan?source=post_page-----f7bac36437a9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f7bac36437a9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f7bac36437a9--------------------------------)
    [Nakul Upadhya](https://medium.com/@upadhyan?source=post_page-----f7bac36437a9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f7bac36437a9--------------------------------)
    ·6 min read·Jun 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f7bac36437a9--------------------------------)
    ·6分钟阅读·2023年6月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Machine Learning and Artificial Intelligence are now being used in a tremendous
    number of fields, but with this increased use comes increased risks and ethical
    tests that models need to pass.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和人工智能现在被应用于大量领域，但随着使用的增加，模型面临着更多的风险和伦理测试。
- en: Let's take a motivating example with the recent news of [a Tesla crashing into
    a tree while in self-driving mode](https://upnorthlive.com/news/local/woman-recovering-after-tesla-crashes-in-self-driving-mode).
    According to authorities, the driver said the vehicle pulled to the right, went
    off the road, and hit a tree once she put it into self-driving mode. Currently,
    these claims are under investigation, but imagine how difficult it would be to
    identify the reasoning behind the car’s sudden erratic decisions. Did it misclassify?
    What did it see that confused it? With traditional black-box models, investigations
    into the model internals are difficult and costly.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过最近的新闻来激发思考，关于[一辆特斯拉在自动驾驶模式下撞上树木的事件](https://upnorthlive.com/news/local/woman-recovering-after-tesla-crashes-in-self-driving-mode)。根据当局的说法，司机表示车辆在她启用自动驾驶模式后向右偏移，驶离了道路，并撞上了一棵树。目前，这些说法正在调查中，但想象一下，识别汽车突然做出怪异决策的原因是多么困难。它是否发生了误分类？它看到了什么让它困惑的东西？对于传统的黑箱模型来说，调查模型内部非常困难且昂贵。
- en: 'So what''s the alternative? Is there an interpretable way to do image classification?
    Yes, through prototype learning [2] and neural prototype trees [1]! With these
    architectures, the model takes a very intuitive approach to prediction: identifying
    pieces that look familiar. Does the bird have a long beak? Does it have a red
    throat? It must be a hummingbird!'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，替代方案是什么？是否有一种可解释的图像分类方法？是的，通过原型学习[2]和神经原型树[1]！借助这些架构，模型采用了一种非常直观的预测方法：识别看起来熟悉的部分。那只鸟有长长的喙吗？它有红色的喉咙吗？那一定是一只蜂鸟！
- en: 'In this article, I aim to provide information on how these models work and
    discuss some of the benefits and downsides of using these models. The two main
    papers I’ll be frequently referencing are below and I highly encourage anyone
    interested to give these a read:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我旨在提供有关这些模型如何工作的资讯，并讨论使用这些模型的一些优缺点。我将频繁引用的两篇主要论文如下，我强烈建议有兴趣的读者阅读这些论文：
- en: '[](https://arxiv.org/abs/1806.10574?source=post_page-----f7bac36437a9--------------------------------)
    [## This Looks Like That: Deep Learning for Interpretable Image Recognition'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arxiv.org/abs/1806.10574?source=post_page-----f7bac36437a9--------------------------------)
    [## 这看起来像那样：用于可解释图像识别的深度学习'
- en: When we are faced with challenging image classification tasks, we often explain
    our reasoning by dissecting the image…
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 当我们面临具有挑战性的图像分类任务时，我们通常通过解构图像来解释我们的推理……
- en: arxiv.org](https://arxiv.org/abs/1806.10574?source=post_page-----f7bac36437a9--------------------------------)
    [](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?ref=https%3A%2F%2Fgithubhelp.com&source=post_page-----f7bac36437a9--------------------------------)
    [## CVPR 2021 Open Access Repository
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/1806.10574?source=post_page-----f7bac36437a9--------------------------------)
    [openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?ref=https%3A%2F%2Fgithubhelp.com&source=post_page-----f7bac36437a9--------------------------------)
    [## CVPR 2021 开放获取库'
- en: Neural Prototype Trees for Interpretable Fine-Grained Image Recognition Meike
    Nauta, Ron van Bree, Christin Seifert …
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 神经原型树用于可解释的细粒度图像识别 Meike Nauta、Ron van Bree、Christin Seifert 等
- en: openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?ref=https%3A%2F%2Fgithubhelp.com&source=post_page-----f7bac36437a9--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[openaccess.thecvf.com](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?ref=https%3A%2F%2Fgithubhelp.com&source=post_page-----f7bac36437a9--------------------------------)'
- en: This is the second article I’ve written about variants of neural decision trees.
    If you haven’t read the first article, I highly encourage you to skim through
    it as many of the concepts outlined here are built off of the standard neural
    tree.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我撰写的关于神经决策树变体的第二篇文章。如果你还没有读过第一篇文章，我强烈建议你浏览一下，因为这里阐述的许多概念都是基于标准神经树构建的。
- en: '[](/neural-networks-as-decision-trees-89cd9fdcdf6a?source=post_page-----f7bac36437a9--------------------------------)
    [## Neural Networks as Decision Trees'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/neural-networks-as-decision-trees-89cd9fdcdf6a?source=post_page-----f7bac36437a9--------------------------------)
    [## 神经网络作为决策树'
- en: Get the power of a Neural Network with the interpretable structure of a Decision
    Tree
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用神经网络的强大能力和决策树的可解释结构
- en: towardsdatascience.com](/neural-networks-as-decision-trees-89cd9fdcdf6a?source=post_page-----f7bac36437a9--------------------------------)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/neural-networks-as-decision-trees-89cd9fdcdf6a?source=post_page-----f7bac36437a9--------------------------------)'
- en: What are Prototypes?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是原型？
- en: 'The idea of prototypes in image recognition was first introduced by Chen &
    Li et. al (2019) in their paper “This Looks Like That: Deep Learning for Interpretable
    Image Recognition” [2] and is a latent representation of some training image patch
    which are associated with a given class. As the name suggests, the model works
    like a human by dissecting the input images and finding prototypical part that
    provide evidence for the image being a certain class. The network simply calculates
    the euclidean distance and inverts it to create a similarity score. These scores
    are then passted through a fully connected layer to create the final class probabilities:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图像识别中的原型思想首次由 Chen & Li 等（2019）在他们的论文“这看起来像那样：用于可解释图像识别的深度学习” [2] 中提出。这是一种潜在表示，表示与给定类别相关的某些训练图像补丁。正如名字所示，该模型通过解剖输入图像并找到提供证据的原型部分来工作，以表明图像属于某一类别。网络简单地计算欧几里得距离，并将其反转以创建相似度分数。这些分数随后通过一个全连接层生成最终的类别概率：
- en: '![](../Images/fe94c79b2ad077b6e29b0a0ecaac7d02.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe94c79b2ad077b6e29b0a0ecaac7d02.png)'
- en: 'Figure 1: ProtoPNet Architecture (Figure from Chen & Li et. al 2019 [2])'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: ProtoPNet 架构（图源自 Chen & Li 等，2019 [2]）'
- en: 'Once the model is trained, users can simply match up the prototypes learned
    with patches from the training set to create a very interpretable explanation
    of any prediction:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，用户可以简单地将学到的原型与训练集中的补丁进行匹配，从而创建对任何预测的非常可解释的解释：
- en: '![](../Images/ec5c309129dd9c0966fb055207056740.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec5c309129dd9c0966fb055207056740.png)'
- en: 'Figure 2: Reasoning process for the prediction of a bird (Figure from Chen
    & Li et. al 2019 [2])'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: 鸟类预测的推理过程（图源自 Chen & Li 等，2019 [2]）'
- en: Neural Prototype Trees
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经原型树
- en: One problem with simply using a bag-of-prototypes model (such as ProtoPNet from
    the original prototype paper [2]) is that the prototype matching is all done at
    the same time, but human image recognition relies on a sequence of steps. If something
    doesn’t have paws or ears but has a tail, it probably isn’t a cat, therefore the
    network shouldn’t be assigning points for it being a cat. This is where the Neural
    Protoype Tree [2] comes in. Instead of a bag-of-prototypes, Nauta et. al [1] opt
    to instead design their model as a neural decision tree. This decision tree provides
    this sequential decision making as well as providing global explainability instead
    of just local interpretability.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原型包模型（例如来自原始原型论文 [2] 的 ProtoPNet）的一个问题是，原型匹配是同时进行的，但人类图像识别依赖于一系列步骤。如果某物没有爪子或耳朵但有尾巴，那它可能不是猫，因此网络不应该给它打上猫的标签。这就是神经原型树
    [2] 发挥作用的地方。与原型包不同，Nauta 等人 [1] 选择将他们的模型设计为神经决策树。这种决策树提供了这种顺序决策，并提供了全局可解释性，而不仅仅是局部可解释性。
- en: Review of Soft Decision Trees
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 软决策树的回顾
- en: The Neural Prototype tree is a soft decision tree, not a hard tree. While hard
    decision trees enforce deterministic branching (you either go left or right),
    soft decision trees instead use probabilistic branching (you have a *p* chance
    of going left and *1-p* probability to go right). Additionally, while a hard decision
    tree outputs a single value, soft decision trees instead output a probability
    distribution for all possible classes where the probability of a class is the
    product of the probabilities that we travel through to reach the leaves and classification
    decisions are just the class with the highest probability.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 神经原型树是软决策树，而不是硬决策树。虽然硬决策树强制执行确定性分支（你要么向左走，要么向右走），但软决策树使用的是概率分支（你有 *p* 的概率向左走和
    *1-p* 的概率向右走）。此外，虽然硬决策树输出一个单一的值，但软决策树输出的是所有可能类别的概率分布，其中类别的概率是到达叶子节点所经过概率的乘积，分类决策则是概率最高的类别。
- en: Decision Making in a Prototype Tree
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原型树中的决策制定
- en: 'Like the standard neural tree, each leaf node contains a probability distribution
    across the classes. The branching decisions are made by calculating the distance
    of the image patches to a given prototype in the node. The score for each image
    is then the minimum distance found between a patch in the image and the prototype
    which is then translated into a probability. Simply put: go right if you find
    a prototype in the image, go left if you can’t find that prototype!'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 像标准神经树一样，每个叶子节点包含一个关于类别的概率分布。分支决策是通过计算图像补丁到节点中给定原型的距离来做出的。每张图像的得分是图像中补丁与原型之间找到的最小距离，然后转换为概率。简单来说：如果在图像中找到原型，就向右走；如果找不到该原型，就向左走！
- en: '![](../Images/56af0995f2165aec9fd71586e3222bfa.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56af0995f2165aec9fd71586e3222bfa.png)'
- en: 'Figure 3: Prediction Mechanisms in the ProtoTree (Figure from Nauta et. al
    2021 [1])'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：ProtoTree 中的预测机制（图源自 Nauta 等人 2021 [1]）
- en: This mechanism obviously allows for incredibly interpretable models that can
    be visualized using the same mechanisms we visualized the normal prototype model.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个机制显然允许我们使用与可视化普通原型模型相同的机制来可视化出极其可解释的模型。
- en: '![](../Images/7f55a06009e874700897d9319d72c417.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f55a06009e874700897d9319d72c417.png)'
- en: 'Figure 4: Global Explanation of the Prototype Tree (Figure from Nauta et. al
    2021 [1])'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：原型树的全局解释（图源自 Nauta 等人 2021 [1]）
- en: Learning Leaf Distributions
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习叶子分布
- en: 'In a normal decision tree, the label of a leaf is learned by looking at the
    samples that end up in that leaf, but in a soft tree, the distributions in the
    leafs are part of the global learning problem. However, the authors noticed that
    clumping together the learning of the leafs with learning the prototypes results
    in inferior classification results. To rectify this, they leveraged a derivative-free
    strategy to get an update scheme for the leaf probabilities:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在普通决策树中，叶子的标签是通过查看最终到达该叶子的样本来学习的，但在软树中，叶子中的分布是全局学习问题的一部分。然而，作者注意到将叶子的学习与原型的学习结合在一起会导致分类结果不佳。为了解决这个问题，他们利用了一种无导数策略来获取叶子概率的更新方案：
- en: '![](../Images/b11b18cfe6c621a6338f729caf3ffc16.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b11b18cfe6c621a6338f729caf3ffc16.png)'
- en: 'Figuree 5: Update Scheme. c_l^t is the leaf probability in leaf l at epoch
    t. y is the truth, yhat is the prediction. pi is path probability to that leaf.
    (Figure from Nauta et. al 2021 [1])'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：更新方案。c_l^t 是第t轮中叶子l的叶子概率。y 是真实值，yhat 是预测值。pi 是到该叶子的路径概率。（图自Nauta等，2021 [1]）
- en: This update scheme was intertwined with mini-batch gradient to learn the prototypes
    and the convolution parameters to create an efficient learning procedure.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该更新方案与小批量梯度相结合，以学习原型和卷积参数，从而创建一个高效的学习过程。
- en: Pruning
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 剪枝
- en: To aid in interpretability, the authors also introduced a pruning mechanism.
    If a leaf node contains an effectively uniform distribution, it doesn’t have much
    discriminating power therefore it is better to prune it since smaller trees are
    easier to read and interpret. Mathematically, the authors define a threshold *t*
    and remove all leaves where the highest class probability is less than *t (*max*(c_l)
    ≤ t*). If all leaves in a subtree are removed, that sub-tree and its associated
    prototypes can be removed, allowing for a more compact tree. Usually, *t = 1/K+
    epsilon* where K is the number of classes and *epsilon* is a very small number
    representing a tolerance.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高可解释性，作者还引入了剪枝机制。如果一个叶节点包含有效的均匀分布，它的区分能力不强，因此最好对其进行剪枝，因为较小的树更易于阅读和解释。从数学上讲，作者定义了一个阈值
    *t* 并移除所有最高类别概率小于 *t*（*max*(c_l) ≤ t*）的叶子。如果一个子树中的所有叶子都被移除，则可以移除该子树及其相关原型，从而使树变得更加紧凑。通常，*t
    = 1/K + epsilon* 其中K是类别数，*epsilon* 是一个非常小的数值，表示容差。
- en: '![](../Images/371d42f0b2fe698980f1fbb4435aad3c.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/371d42f0b2fe698980f1fbb4435aad3c.png)'
- en: 'Figure 5: Pruning Visualization (Figure from Nauta et. al 2021 [1])'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：剪枝可视化（图自Nauta等，2021 [1]）
- en: Performance
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: '![](../Images/8fea1e7c77b79fd2edeab2d7dd74a0c8.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fea1e7c77b79fd2edeab2d7dd74a0c8.png)'
- en: 'Figure 6: Mean accuracy and standard deviations. ProtoTree ens. is an ensemble
    of 3 or 5 prototype trees. (Figure from Nauta et. al 2021 [1])'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：平均准确率和标准差。ProtoTree ens. 是3棵或5棵原型树的集合。 （图自Nauta等，2021 [1]）
- en: The authors benchmarked their methods using the CARS and CUBS dataset against
    other interpretable image-recognition methods (Such as ones with attention-based
    interpretability). They found that they were able to get close to SOTA accuracy
    with a relatively small ensemble of trees with small heights (9 and 11).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用CARS和CUBS数据集对他们的方法进行了基准测试，与其他可解释的图像识别方法（如基于注意力的可解释性方法）进行比较。他们发现，通过使用相对较小的树木集合（9棵和11棵），他们能够接近SOTA准确率。
- en: Conclusion
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Interpretable deep-learning image classifiers offer a number of advantages over
    black-box models. They can help to build trust, improve debugging, and explain
    predictions. Additionally, they can be used to explore the data and learn more
    about the relationships between different features.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释的深度学习图像分类器相对于黑箱模型提供了许多优势。它们可以帮助建立信任，改善调试，并解释预测。此外，它们还可以用于探索数据，了解不同特征之间的关系。
- en: Overall, Neural Prototype Trees are a promising new approach to image recognition
    in a trustworthy manner. A doctor is more likely to trust a cancer-detecting model
    if he can check the characteristics of the image the model is looking at. These
    prototype trees can even be augmented with measures like attention to increase
    the accuracy further!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，神经原型树是一种有前途的新方法，用于以可信赖的方式进行图像识别。如果医生能够检查模型所观察到的图像的特征，他更可能相信癌症检测模型。这些原型树甚至可以通过添加注意力等措施进一步提高准确性！
- en: Resources and References
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源和参考文献
- en: 'Github for the Neural Prototype Tree: [https://github.com/M-Nauta/ProtoTree](https://github.com/M-Nauta/ProtoTree)'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经原型树的Github： [https://github.com/M-Nauta/ProtoTree](https://github.com/M-Nauta/ProtoTree)
- en: 'If you’re interested in Explainable Machine Learning and AI, consider giving
    me a follow: [https://medium.com/@upadhyan](https://medium.com/@upadhyan).'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你对可解释的机器学习和人工智能感兴趣，可以考虑关注我：[https://medium.com/@upadhyan](https://medium.com/@upadhyan)。
- en: References
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] M. Nauta, R.v. Bree, C. Seifert. [Neural Prototype Trees for Interpretable
    Fine-Grained Image Recognition](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?ref=https%3A%2F%2Fgithubhelp.com)
    (2021). IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
    2021'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] M. Nauta, R.v. Bree, C. Seifert. [神经原型树用于可解释的细粒度图像识别](https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html?ref=https%3A%2F%2Fgithubhelp.com)
    (2021). IEEE/CVF计算机视觉与模式识别会议（CVPR），2021'
- en: '[2] C. Chen, O. Li, C. Tao. A.J. Barnett, J. Su, C. Rudin. [This Looks Like
    That: Deep Learning for Interpretable Image Recognition](https://arxiv.org/abs/1806.10574)
    (2019). 33rd Conference on Neural Information Processing Systems.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] C. Chen, O. Li, C. Tao. A.J. Barnett, J. Su, C. Rudin. [这看起来像那样：可解释图像识别的深度学习](https://arxiv.org/abs/1806.10574)
    (2019). 第33届神经信息处理系统会议。'
