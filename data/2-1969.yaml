- en: TensorFlow Model Training Using GradientTape
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GradientTape 进行 TensorFlow 模型训练
- en: 原文：[https://towardsdatascience.com/tensorflow-model-training-using-gradienttape-f2093646ab13](https://towardsdatascience.com/tensorflow-model-training-using-gradienttape-f2093646ab13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tensorflow-model-training-using-gradienttape-f2093646ab13](https://towardsdatascience.com/tensorflow-model-training-using-gradienttape-f2093646ab13)
- en: '![](../Images/fbe16d8537174389bce863e509126468.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbe16d8537174389bce863e509126468.png)'
- en: Photo by [Sivani Bandaru](https://unsplash.com/@agni11?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Sivani Bandaru](https://unsplash.com/@agni11?utm_source=medium&utm_medium=referral)
    提供，发布在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
    上。
- en: Use of GradientTape to Update the Weights
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GradientTape 更新权重
- en: '[](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----f2093646ab13--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)
    ·7 min read·Oct 17, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f2093646ab13--------------------------------)
    ·7 分钟阅读·2023年10月17日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: TensorFlow is arguably the most popular library for deep learning. I wrote so
    many tutorials on TensorFlow before and still continuing. TensorFlow is very well
    organized and easy to use package where you do not need to worry about model development
    and model training too much. Pretty much most of the stuff is taken care of by
    the package itself. That is probably the reason why it has gotten so popular in
    the industry. But at the same time, sometimes it is nice to have control over
    the behind-the-scenes functionalities. It gives you a lot of power to experiment
    with the models. If you are job seeker, some extra knowledge may give you an edge.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 可以说是最受欢迎的深度学习库。我之前写了很多关于 TensorFlow 的教程，并且还在继续。TensorFlow 是一个组织良好且易于使用的包，你不需要过多担心模型开发和训练。大部分工作都由这个包本身处理。这可能就是它在业界如此受欢迎的原因。但与此同时，有时掌控幕后功能也很不错。它为你提供了大量的实验模型的能力。如果你是求职者，一些额外的知识可能会给你带来优势。
- en: Previously, I wrote an article on [how to develop custom activation functions,
    layers, and loss functions](/how-to-define-custom-layer-activation-function-and-loss-function-in-tensorflow-bdd7e78eb67).
    In this article, we will see how you can train the model manually and update the
    weights yourself. But don’t worry. You don’t have to remember the differential
    calculus all over again. We have GradientTape() method available in TensorFlow
    itself to take care of that part.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我写了一篇文章介绍 [如何开发自定义激活函数、层和损失函数](/how-to-define-custom-layer-activation-function-and-loss-function-in-tensorflow-bdd7e78eb67)。在这篇文章中，我们将看到如何手动训练模型并自行更新权重。但不用担心，你不需要重新记住微积分。TensorFlow
    本身提供了 GradientTape() 方法来处理这部分内容。
- en: 'If GradientTape() is totally new to you, please feel free to check this exercises
    on GradientTape() that shows you, how GradientTape() works: [Introduction to GradientTape
    in TensorFlow — Regenerative (regenerativetoday.com)](https://regenerativetoday.com/introduction-to-gradienttape-in-tensorflow/)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 GradientTape() 对你来说完全陌生，请随时查看这个关于 GradientTape() 的练习，了解 GradientTape() 的工作原理：[TensorFlow
    中的 GradientTape 介绍 — Regenerative (regenerativetoday.com)](https://regenerativetoday.com/introduction-to-gradienttape-in-tensorflow/)
- en: Data Preparation
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'In this article we work on a simple classification algorithm in TensorFlow
    using GradientTape(). Please download the dataset from this link:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们使用 GradientTape() 在 TensorFlow 中进行一个简单的分类算法。请从这个链接下载数据集：
- en: '[Heart Failure Prediction Dataset (kaggle.com)](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[心力衰竭预测数据集 (kaggle.com)](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)'
- en: This dataset has an open database license.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集具有开放数据库许可。
- en: 'These are the necessary imports:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是必要的导入：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Creating the DataFrame with the dataset:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据集创建DataFrame：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Output:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](../Images/61a3bb01c99a35bbda05fe057c85d556.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61a3bb01c99a35bbda05fe057c85d556.png)'
- en: 'As shown in the picture above, there are multiple columns with string data
    type. Let’s check the data types of all the columns in the dataset:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，有多个列的数据类型是字符串。让我们检查数据集中所有列的数据类型：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you are here, I can assume that you know the machine learning basics and
    already have learned that the data types need to be numeric for TensorFlow.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你在这里，我可以假设你了解机器学习基础，并且已经学过数据类型需要为数值型才能用于TensorFlow。
- en: This code below loops through the columns and if the data type of a column is
    ‘object’, it changes that to numeric data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码会遍历列，如果列的数据类型是‘object’，则将其转换为数值数据。
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'All the columns have become the numeric type now. Define the training features
    and target variable to move forward with the model:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 所有列现在已变为数值型。定义训练特征和目标变量以继续模型开发：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We should keep a part of the dataset to evaluate the model. So we will use
    the train_test_split method here:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该保留数据集的一部分来评估模型。因此，我们将在这里使用train_test_split方法：
- en: '[PRE6]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Before diving into the model development part, it is also necessary to scale
    the data. I am using standard scaling method here that requires mean and standard
    deviation. Remember, we need the mean and standard deviation of the training data
    only. To scale the test data, the mean and standard deviation of training data
    needs to be used again as we shouldn’t reveal any information about the test data
    to the model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入模型开发之前，还需要对数据进行缩放。我在这里使用的是标准缩放方法，需要均值和标准差。请记住，我们只需要训练数据的均值和标准差。为了缩放测试数据，需要再次使用训练数据的均值和标准差，因为我们不应向模型透露任何关于测试数据的信息。
- en: 'We will use the .describe() method to find out the statistical parameters of
    each column of the training data:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用.describe()方法来查找训练数据每列的统计参数：
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/aaba121317fe5e39bff8a35db170ab88.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aaba121317fe5e39bff8a35db170ab88.png)'
- en: We have the parameters for scaling now.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了缩放的参数。
- en: 'Target variables for training and testing data need to be separated here:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 需要在这里将训练数据和测试数据的目标变量分开：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following function is defined to scale one column of a dataset using the
    standard scaling formula:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了以下函数来使用标准缩放公式对数据集的某一列进行缩放：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Using the function ‘norm’ scaling both training and testing data:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用函数‘norm’对训练数据和测试数据进行缩放：
- en: '[PRE10]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If you check the X_train_norm and X_test_norm, they are actually arrays. Converting
    them to tensors here:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你检查X_train_norm和X_test_norm，它们实际上是数组。这里将它们转换为张量：
- en: '[PRE11]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Shuffling the datasets by each batch where batch_size is set to be 32:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每批数据集通过洗牌处理，其中批次大小（batch_size）设置为32：
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Model Development
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型开发
- en: We will take a simple TensorFlow model for this as the dataset is so simple.
    The model is defined as a function base_model where two fully connected Dense
    layers of 64 neurons and one output layers are added. In the last line, the function
    base_model called and saved in a variable called ’model’.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集非常简单，我们将使用一个简单的TensorFlow模型。模型定义为函数base_model，添加了两个全连接的64神经元Dense层和一个输出层。在最后一行，调用函数base_model并将其保存在名为’model’的变量中。
- en: '[PRE13]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: I chose RMSprop optimizer and BinaryCrossentropy() loss function for this example.
    Please feel free to use any other Optimizer of your choice.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了RMSprop优化器和BinaryCrossentropy()损失函数作为这个例子。请随意使用你选择的其他优化器。
- en: '[PRE14]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Model Training
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: The GradientTape part is going to be useful in the model training part. During
    the model training we need the differentiation to update the weights. The function
    below will use the GradientTape to calculate the gradients. First it calculates
    the outputs using the model which is called the logits. Using the true label and
    predicted label, loss was calculated.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: GradientTape部分将在模型训练过程中发挥作用。在模型训练期间，我们需要微分来更新权重。下面的函数将使用GradientTape来计算梯度。首先，它使用模型计算输出，称为logits。利用真实标签和预测标签，计算损失。
- en: 'Then the gradients were calculated taking the differential of loss with respect
    to the weights and applied the gradients to the optimizers:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，计算梯度，获取损失对权重的偏导数，并将梯度应用于优化器：
- en: '[PRE15]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The next function is to train the network for one epoch. Training one epoch
    includes:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个函数是训练网络一个epoch。训练一个epoch包括：
- en: the process of gradient calculation and applying as in the ‘gradient_calc’ function,
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在‘gradient_calc’函数中的梯度计算和应用过程，
- en: saving the losses and
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 保存损失并
- en: updating the true label to the predicted label by the model after one epoch.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个epoch之后，将真实标签更新为模型的预测标签。
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: One more function is necessary before we start the model training. That is the
    function for the validation loss. This function is pretty self explanatory. It
    calculates the validation loss using the true label and the predicted label, append
    the loss to the list of losses, finally updates the true label for the validation
    data to the new calculated labels.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始模型训练之前，还需要一个函数，那就是用于验证损失的函数。这个函数相当直观。它使用真实标签和预测标签计算验证损失，将损失添加到损失列表中，最后将验证数据的真实标签更新为新计算的标签。
- en: '[PRE17]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For this model I decided to use the accuracy as the evaluation metric. Calling
    the BinaryAccuracy() method for both training and validation:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个模型，我决定使用准确率作为评估指标。对训练和验证调用BinaryAccuracy()方法：
- en: '[PRE18]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: It’s model training time. I am training this model for 60 epochs. We will loop
    through the epochs,
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是模型训练时间。我将训练这个模型60个epoch。我们将循环遍历这些epoch，
- en: we can get the training losses by calling the ‘training_one_epoch’ function
    in each epoch, and validation loss by calling the ‘validation_loss’ function.
    These functions will provide up with a list of losses for each epoch because they
    will calculate the losses for all the data separately. We will take the mean of
    all the losses to get only one loss per epoch for both training and validation.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过在每个epoch中调用‘training_one_epoch’函数来获取训练损失，通过调用‘validation_loss’函数来获取验证损失。这些函数会为每个epoch提供一个损失列表，因为它们会分别计算所有数据的损失。我们将所有损失取平均，以获得每个epoch的训练和验证的单一损失。
- en: '[PRE19]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here is the output for last few epochs:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是最后几个epoch的输出：
- en: '[PRE20]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: After the 60 epochs, we got 93.3% accuracy for training data and 87.5% aacuracy
    for the validation data. Please feel free to train the model for more epochs to
    check if you can improve the accuracy scores. But please be aware of the overfitting
    issue.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在60个epoch之后，我们获得了训练数据93.3%的准确率和验证数据87.5%的准确率。请随意训练更多的epoch以检查是否能提高准确率。但请注意过拟合问题。
- en: Conclusion
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we worked on an example to learn how to manually train the
    model instead of using the model.compile() method. This should give you better
    understanding of the TensorFlow library itself and how exactly model training
    works in TensorFlow.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们通过一个示例学习了如何手动训练模型，而不是使用model.compile()方法。这将帮助你更好地理解TensorFlow库本身以及模型训练在TensorFlow中的具体工作方式。
- en: More Reading
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多阅读
- en: '[How to Define Custom Layer, Activation Function, and Loss Function in TensorFlow
    | by Rashida Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/bdd7e78eb67)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何在TensorFlow中定义自定义层、激活函数和损失函数 | Rashida Nasrin Sucky | 数据科学前沿 (medium.com)](https://medium.com/p/bdd7e78eb67)'
- en: '[Anomaly Detection in TensorFlow and Keras Using the Autoencoder Method | by
    Rashida Nasrin Sucky | Sep, 2023 | Towards Data Science (medium.com)](https://medium.com/p/5600aca29c50)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[在TensorFlow和Keras中使用自编码器方法进行异常检测 | Rashida Nasrin Sucky | 2023年9月 | 数据科学前沿
    (medium.com)](https://medium.com/p/5600aca29c50)'
- en: '[Using a Keras Tuner for Hyperparameter Tuning of a TensorFlow Model | by Rashida
    Nasrin Sucky | Towards AI (medium.com)](https://medium.com/p/41978f53111)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用Keras Tuner进行TensorFlow模型的超参数调整 | Rashida Nasrin Sucky | 人工智能前沿 (medium.com)](https://medium.com/p/41978f53111)'
- en: '[Implementation of a Siamese Network in Keras and TensorFlow | by Rashida Nasrin
    Sucky | Towards Data Science (medium.com)](https://medium.com/p/aa327418e177)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[在Keras和TensorFlow中实现Siamese网络 | Rashida Nasrin Sucky | 数据科学前沿 (medium.com)](https://medium.com/p/aa327418e177)'
- en: '[Complete Implementation of a Mini VGG Network for Image Recognition | by Rashida
    Nasrin Sucky | Towards Data Science (medium.com)](https://medium.com/p/849299480356)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[完整实现一个用于图像识别的迷你VGG网络 | Rashida Nasrin Sucky | 数据科学前沿 (medium.com)](https://medium.com/p/849299480356)'
