- en: Does Your LLM Pipeline Achieve Your Goal?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您的 LLM 流水线达到了您的目标吗？
- en: 原文：[https://towardsdatascience.com/does-your-llm-pipeline-achieve-your-goal-d033c944af8d](https://towardsdatascience.com/does-your-llm-pipeline-achieve-your-goal-d033c944af8d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/does-your-llm-pipeline-achieve-your-goal-d033c944af8d](https://towardsdatascience.com/does-your-llm-pipeline-achieve-your-goal-d033c944af8d)
- en: '*Explore what is most important to evaluate and how to measure it in your LLM
    pipeline.*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*探索评估中最重要的内容及如何在您的 LLM 流水线中进行衡量。*'
- en: '[](https://medium.com/@robertdegraaf78?source=post_page-----d033c944af8d--------------------------------)[![Robert
    de Graaf](../Images/ec3fbe8876fd9110a0455f9d1d6fe548.png)](https://medium.com/@robertdegraaf78?source=post_page-----d033c944af8d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d033c944af8d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d033c944af8d--------------------------------)
    [Robert de Graaf](https://medium.com/@robertdegraaf78?source=post_page-----d033c944af8d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@robertdegraaf78?source=post_page-----d033c944af8d--------------------------------)[![Robert
    de Graaf](../Images/ec3fbe8876fd9110a0455f9d1d6fe548.png)](https://medium.com/@robertdegraaf78?source=post_page-----d033c944af8d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d033c944af8d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d033c944af8d--------------------------------)
    [Robert de Graaf](https://medium.com/@robertdegraaf78?source=post_page-----d033c944af8d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d033c944af8d--------------------------------)
    ·8 min read·Jul 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d033c944af8d--------------------------------)
    ·8 分钟阅读·2023年7月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f033bb7083e947a54ac9c1084bd68a11.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f033bb7083e947a54ac9c1084bd68a11.png)'
- en: AI Photo by [Piret Ilver](https://unsplash.com/es/@saltsup?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/98MbUldcDJY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: AI 照片由 [Piret Ilver](https://unsplash.com/es/@saltsup?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    拍摄，刊登在 [Unsplash](https://unsplash.com/photos/98MbUldcDJY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    上
- en: One of the key ingredients needed to effectively implement an LLM pipeline is
    a way to evaluate the efficacy of your pipeline. That is you need to evaluate
    the final output that is the product of not just the LLM itself or the prompt
    but the interaction between the LLM, the prompt and settings such as temperature
    or minimum and maximum tokens.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 有效实施 LLM 流水线所需的关键成分之一是评估流水线效果的方法。即您需要评估最终输出，这不仅是 LLM 本身或提示的产物，还包括 LLM、提示和设置（如温度或最小最大令牌）之间的交互。
- en: 'Consider the boilerplate code to access the GPT API (autogenerated :'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑访问 GPT API 的样板代码（自动生成：）
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There are seven arguments in the function to create the ‘response’, each of
    which alters the final output. Being able to choose the optimal combination of
    these outputs depends on being able to evaluate and differentiate outputs produced
    by different values of these arguments
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 创建“响应”的函数中有七个参数，每个参数都会改变最终输出。能够选择这些输出的最佳组合取决于能够评估和区分不同参数值产生的输出。
- en: This is a different problem to the LLM evaluations which are most commonly found
    in papers or on LLM makers’ websites . While it may be that you’re using an LLM
    that can pass the bar exam or similar test advertised in these sources, that doesn’t
    mean that your pipeline with the prompt you created and the settings you chose
    will necessarily summarise a collection of legal documents the way you need.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这与最常见于论文或 LLM 制造商网站上的 LLM 评估问题不同。虽然您可能正在使用一个可以通过律师资格考试或这些来源中宣传的类似测试的 LLM，但这并不意味着您创建的提示和所选设置的流水线一定能以您需要的方式总结一系列法律文档。
- en: 'This is especially the case when you are building a pipeline for an external
    user, and therefore can’t adjust the prompt on the fly. For example, suppose you
    want to use an LLM API to embed an LLM solution, and use a basic prompt skeleton
    to generate descriptions of particular items, such as in a catalogue. There are
    two levels to consider for suitablility:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当您为外部用户构建流水线时尤其如此，因此无法即时调整提示。例如，假设您想使用 LLM API 嵌入 LLM 解决方案，并使用基本提示框架生成特定项目的描述，如在目录中。这涉及到两个适用性层级：
- en: Firstly, are the answers you generate fit for purpose?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您生成的答案是否符合目的？
- en: Secondly, can you rely on the answers continuing to be fit for purpose with
    future iterations?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，你能否依赖答案在未来迭代中继续保持适用性？
- en: In a sense the first can be assessed by looking at one or several answers in
    isolation. If you judge them to be suitable, you’re across the line. However,
    to assess the long term reliability of the LLM’s solution, you need to consider
    the variation in multiple answers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，第一个可以通过查看一个或几个独立的答案来评估。如果你判断它们是合适的，那么你就完成了。然而，要评估LLM解决方案的长期可靠性，你需要考虑多个答案的变化。
- en: We will look at this difference in more detail later on, but before we continue,
    we need to consider what fitness for purpose means in the context of an LLM.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后续更详细地讨论这一差异，但在继续之前，我们需要考虑在LLM的背景下适用性是什么意思。
- en: What does fit for purpose even mean?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 适用性究竟是什么意思？
- en: At its most basic level, fitness for purpose means that something achieves the
    the purpose it was designed to achieve. The difficulty in many tech applications
    being knowing what that goal is.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在最基本的层面上，适用性意味着某物实现了它被设计要实现的目的。在许多技术应用中，困难在于知道这个目标是什么。
- en: In relation to LLMs, there are a few common goals users often have, depending
    on how the LLM is being applied. Here are some common use cases people have for
    LLMs-
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与LLM相关，有几个常见的目标用户经常会有，这取决于LLM的应用方式。以下是人们对LLM的一些常见使用场景：
- en: Summarize text
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总结文本
- en: Answer questions
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答问题
- en: Generate text descriptions
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成文本描述
- en: For the use case of summarization, the criteria is how much of the important
    information remains at the end. This is a kind of fidelity or information loss.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于总结的使用场景，标准是最终保留了多少重要信息。这是一种保真度或信息丢失的衡量标准。
- en: In the case of answering questions, accuracy is the likely measure — you can
    score the correct pipeline for how frequently the answer is correct.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在回答问题的情况下，准确性是可能的衡量标准——你可以根据答案的正确频率来评分。
- en: In the case of text descriptions, there is likely to be more than one criteria.
    Similar to summarisation or question answering, accuracy or fidelity is going
    to be important. However, you are likely to also want to grade the model on how
    easily the descriptions are understood or how closely the answers match your style
    requirements.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本描述的情况，可能会有多个标准。类似于总结或回答问题，准确性或保真度将是重要的。然而，你可能还希望根据描述的易懂程度或回答是否符合你的风格要求来评分。
- en: 'In their paper ‘[Large Language Models Encode Clinical Knowledge](https://arxiv.org/abs/2212.13138)’
    , Singhal, Azizi et al propose 10 criteria they use to evaluate LLM implementations
    in the health context. In some cases, such as ‘Extent of possible harm’, the criteria
    are highly specific to the health context. However, in many other cases, the criteria
    are widely applicable. For example, the following criteria suggested by this paper
    can be applied to a wide variety of LLM implementations in a wide variety of contexts:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文‘[大型语言模型编码临床知识](https://arxiv.org/abs/2212.13138)’中，Singhal、Azizi等提出了10个标准，用于评估健康背景下的LLM实现。在一些情况下，如‘可能的伤害程度’，这些标准非常特定于健康背景。然而，在许多其他情况下，这些标准广泛适用。例如，本文建议的以下标准可以适用于各种LLM实现和多种背景：
- en: Does the answer contain any evidence of incorrect reading comprehension?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案中是否有不正确的阅读理解的证据？
- en: Does the answer contain any content it shouldn’t?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案是否包含了不该包含的内容？
- en: Does the answer omit any content it shouldn’t?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案是否省略了不该省略的内容？
- en: The complete list is worth studying, and available via arxiv in the link above.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的列表值得研究，可以通过上述链接在arxiv上获取。
- en: The unfortunate news is that evaluating an implementation against a set of criteria
    like this is a laborious process, likely to involve some degree of manual scoring
    of the criteria, and requiring you to produce model outputs against multiple cases
    to get a full picture of the performance.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，将实现评估与这样一组标准对比是一个繁琐的过程，可能涉及一些手动评分标准，并且需要你在多个案例中生成模型输出，以获得性能的全面图景。
- en: 'To analyse the results of these investigations, you’re going to want to run
    statistics over effectively the whole matrix outputs, putting the task firmly
    into the realm of multivariate statistics. Without going deeply into this area
    to avoid writing an overly long piece, this will mean you need to consider:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要分析这些调查结果，你需要对几乎整个矩阵输出进行统计分析，将任务明确地归入多变量统计领域。为了避免写得过长，不深入探讨这个领域，这意味着你需要考虑：
- en: The overall scores within an answer
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 答案中的总体评分
- en: The overall scores within a category
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别中的总体评分
- en: The variance within each answer e.g. you want criteria scores within each answer
    to be within a tight band, rather than scoring really well on one criterion and
    poorly on another
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个答案的方差，例如，你希望每个答案的评分在一个紧密的范围内，而不是在一个标准上评分很高，而在另一个标准上评分很低。
- en: The variance within a criteria e.g. you want every answer to score within a
    tight band
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准中的方差，例如，你希望每个答案的评分在一个紧密的范围内
- en: Post-Implementation Monitoring
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施后监控
- en: An additional factor to consider is that in addition to be inherently stochastic,
    so that a future answer may not be identical to the current answer, in many cases
    model owners are tweaking the models, which may either improve or degrade the
    output in your specific case.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的因素是，除了固有的随机性，使得未来的答案可能与当前答案不同外，在许多情况下，模型拥有者会调整模型，这可能会改善或降低你特定情况下的输出。
- en: In fact, perceived degradation of ChatGPT and GPT4 in particular has been discussed
    in a variety of places such as the [GPT4 discussion forum](https://community.openai.com/t/experiencing-decreased-performance-with-chatgpt-4/234269).
    Various reasons have been forward for the degradation, but it is worth considering
    that in a tool as complicated and powerful as any LLM, which produces an output
    whose quality can only be measured subjectively, that there is no reason that
    a change that improves the experience for the majority of users won’t result in
    worse performance in any specific case.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，ChatGPT和特别是GPT4的感知退化在各种地方进行了讨论，例如 [GPT4讨论论坛](https://community.openai.com/t/experiencing-decreased-performance-with-chatgpt-4/234269)。退化的各种原因被提出，但值得考虑的是，在像LLM这样复杂且强大的工具中，其输出质量只能主观衡量，任何改善大多数用户体验的变更都可能导致在特定情况下性能下降。
- en: It should also be noted, that some users in these discussions have suggested
    that the perceived degradation was not in fact degradation, but that a user had
    incorrectly decided that a one-off highly suitable answer was representative of
    what would always be achieved into the future when in fact the suitability of
    the answer was in part produced by chance — this highlights the importance of
    testing multiple cases and creating an evaluation that can account for the effect
    of probability.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 还应该注意，在这些讨论中，一些用户提出感知到的退化实际上并不是退化，而是用户错误地认为一个偶然出现的非常合适的答案代表了未来总是会取得的结果，而实际上答案的适用性部分是由偶然因素决定的——这突出了测试多个案例和创建能够考虑概率效应的评估的重要性。
- en: Given that the process of producing and scoring answers is likely to be laborious,
    you may wish to avoid repeating the entire process every single time you look
    at your post-implementation efficacy. Hence, you are likely to want to choose
    a representative subset of the implementation tests that you can perform and then
    analyse on a semi-regular interval.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于生产和评分答案的过程可能会很繁琐，你可能希望避免每次查看实施后的效果时都重复整个过程。因此，你可能会希望选择一个具有代表性的实施测试子集，并在半定期的时间间隔内进行分析。
- en: Example
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: 'As an example of how this might work in a simple case, imagine you are creating
    a pipeline to summarise difficult to read memos. You want to create a pipeline
    that creates a clear, easy to read summary of these memos. You decide that the
    following factors are important:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作为如何在简单情况下工作的一个例子，假设你正在创建一个管道来总结难以阅读的备忘录。你希望创建一个可以清晰、易读地总结这些备忘录的管道。你决定以下因素很重要：
- en: Accurate summary of the original
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原始内容的准确总结
- en: Ease of reading
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阅读的容易程度
- en: No additional material added
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无额外材料添加
- en: Repeatability in the sense of producing similar output each time from the same
    input.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在相同输入下每次产生类似输出的可重复性。
- en: The last of these, repeatability, we don’t measure directly, but we measure
    by repeating the scoring process on several examples for the first three.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个，即可重复性，我们不直接测量，而是通过对前面三个评分过程中的几个示例进行重复测量来评估。
- en: 'As an illustration, imagine summarising a short piece of writing in the public
    domain — a passage from James Joyce’s Ulysses where Joyce describes the protagonist
    (Bloom) taking off his shoes and socks in a comically exaggerated difficult to
    read manner. Here is ChatGPT’s output and the passage to summarise itself:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作为说明，想象一下总结一段公开领域的短文——詹姆斯·乔伊斯《尤利西斯》中的一段，乔伊斯以夸张搞笑的方式描述了主人公（布loom）脱鞋袜的情景。这是ChatGPT的输出以及需要总结的原文：
- en: '![](../Images/2160ca0192064fe47e5c814a943d9905.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2160ca0192064fe47e5c814a943d9905.png)'
- en: Output from ChatGPT when submitted a short passage from James Joyce’s Ulysses,
    where the author describes the main character taking off his shoes after coming
    home
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从《尤利西斯》中提交的短文片段的ChatGPT输出，其中作者描述了主角回家后脱鞋的情景。
- en: Similar outputs can be obtained by using the default settings in the GPT3.5
    API playground. These are the settings found in the code snippet found at the
    beginning of this article.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPT3.5 API playground中的默认设置可以获得类似的输出。这些设置在本文开头的代码片段中可以找到。
- en: 'An example output using this output is:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个输出的示例结果是：
- en: ‘The text describes someone examining and treating their foot. They have a persistent
    ache and notice the marks and pressure points caused by walking. They then remove
    their shoes and socks to address a problem with their toenail, finding satisfaction
    in the familiarity of the scent and the routine of their nightly foot care.’
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: “文本描述了一个人检查和处理他们的脚。他们有持续的疼痛，并注意到由于走路造成的痕迹和压力点。然后，他们脱下鞋子和袜子来解决脚趾甲的问题，发现熟悉的气味和夜间脚部护理的例行程序带来了满足感。”
- en: This is a solid summary, and on a scale of 1 -5 for each of the first three
    criteria I would give the output at least a 4\. These scores are very similar,
    so the variance from criterion to criterion is low. When I repeated the input
    with the same settings, although the output changed, it was at a very similar
    quality, so the variance from output to output was also very low, and therefore
    the repeatability was high.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个全面的总结，在前面三个标准的评分中，我会给这个结果至少打4分。这些评分非常接近，因此标准之间的差异很小。当我用相同的设置重复输入时，尽管结果有所变化，但质量非常相似，因此结果之间的差异也很小，因此重复性很高。
- en: I also tried the experiment after altering one parameter — I increased the temperature
    from 1 to 1.6.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我还在改变一个参数后尝试了这个实验——我将温度从1增加到1.6。
- en: 'The first time I tried this experiement I received the following output:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我第一次尝试这个实验时得到了以下结果：
- en: ‘The text talks about a person examining their foot and treating it. They notice
    the deformations and pressure points from walking before taking off their boots
    and socks. They specifically address a problem with their toenail and gain satisfaction
    from the familiar scents associated with their nighttime foot care routine performed
    daily in prayerful contemplation.’
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: “文本谈到一个人检查他们的脚并进行处理。他们注意到由于走路而形成的变形和压力点，然后脱下靴子和袜子。他们特别解决了脚趾甲的问题，并从与夜间脚部护理程序相关的熟悉气味中获得满足感，这个程序每天都在祈祷般的沉思中进行。”
- en: This output also scored highly across all criteria, and arguably (this is an
    inherently subjective process) captured the sense better when it mentioned ‘prayerful
    contemplation’. I would give this output a 4.5 for fidelity and still 4 for ease
    of reading and a 5 for no additional material.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果在所有标准中得分也很高，可以说（这是一个固有的主观过程）在提到“祈祷般的沉思”时更好地捕捉了意义。我会给这个结果4.5分的忠实度，阅读容易性仍然为4分，没有额外材料为5分。
- en: 'I then submitted the request with precisely the same settings a second time
    and got this output:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我随后用完全相同的设置再次提交了请求，得到了这个结果：
- en: ‘The text describes the protagonist the continued process divesting themselves
    of their footwear and how they take care of their foot. They notice the markings
    left on their foot from walking and then proceed to remove their boots, socks,
    and part of the sock suspender. They recognize the scent of their foot as they
    pick at and discard a piece of their toenail, gaining a sense of satisfaction
    from the routine approach of their beloved evening footcare session. Their steps
    recast shadows as effulgency lies brightly forthcloud although enviti dunterations
    yet continua the fhericy ils prebaurentation yields speceliques ascistsomaticulations…
    read echo halted hollow flames disoluinnlancy rather therminansiology less pertirkeyahken
    inslead vitount the compse fiatic sanctiphall turlegisanitical pruncatheldomatis
    trabenbourineneticulatory formancentials exposedselucinvoundolicariety reconstricted
    devus … finispurninelile’
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: “文本描述了主角继续脱下鞋子的过程，以及他们如何照顾自己的脚。他们注意到脚上走路留下的痕迹，然后继续脱掉靴子、袜子以及部分袜带。他们在挑拣并丢弃脚趾甲的一块时闻到自己脚的气味，从他们心爱的晚间脚部护理活动的例行方法中获得一种满足感。他们的步伐重新投射出阴影，虽然光辉明亮地照耀着，但周围依然有变化，然而火焰的回声中断，留下的是溶解的炭黑，不再具备原有的光辉，整体的结构被重新塑造……”
- en: Even in the first sentence there is a problem with the grammar, and obviously
    by the end of the output it has degraded considerably. This output I would give
    a 3 for fidelity (it does actually capture most of the essence of the original
    similar to the other outputs), 3 for ease of reading (until it adds nonsense words
    is actually easier to read than the original — it could be saved by discarding
    all the words after ‘evening footcare session’) but 1 for not adding additional
    material.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在第一句话中也存在语法问题，显然到输出的末尾已经严重退化。我会给这个输出在忠实度上打3分（它确实捕捉了原文的大部分精髓，与其他输出类似），在易读性上打3分（直到添加了无意义的词汇，实际上比原文更易读——通过丢弃“evening
    footcare session”之后的所有词汇可以挽救），但在未添加额外材料方面打1分。
- en: In this case there is a great deal of difference in the quality of the two outputs,
    which is intuitive given that the temperature setting explicitly increases the
    variance in responses.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，两者输出质量的差异非常大，这一点很直观，因为温度设置明显增加了响应的方差。
- en: Overall, while the difference in outputs is a little exaggerated here, it can
    be seen that scoring outputs on multiple criteria and scoring multiple outputs
    both contribute to understanding how effective the complete package of settings
    is to achieving the target of your LLM implementation.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，虽然这里输出的差异有点夸张，但可以看出，在多个标准上评分输出和评分多个输出都有助于理解完整设置包在实现LLM目标方面的有效性。
- en: Conclusion
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: LLMs are powerful tools, and harnessing that power often requires a developer
    to create a pipeline targeted at a particular use case. As text generating models,
    the quality of the output is an inherently subjective concept in many cases, and
    also frequently requires a multidimensional approach.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 是强大的工具，利用这些工具的力量通常需要开发者创建一个针对特定用例的管道。作为文本生成模型，输出的质量在许多情况下是一个固有的主观概念，并且通常需要多维的方法。
- en: They are also subject to change over time, which could be good or bad. Designing
    a set of test problems that can be run and analysed quickly and easily will help
    your implementation stay performant for a long time to come.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 它们也会随着时间的推移而发生变化，这可能是好事也可能是坏事。设计一组可以快速且轻松运行和分析的测试问题将有助于保持你的实现长期高效。
