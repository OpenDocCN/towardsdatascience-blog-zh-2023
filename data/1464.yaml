- en: 'Similarity Search, Part 1: kNN & Inverted File Index'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相似性搜索，第1部分：kNN与倒排文件索引
- en: 原文：[https://towardsdatascience.com/similarity-search-knn-inverted-file-index-7cab80cc0e79?source=collection_archive---------1-----------------------#2023-04-28](https://towardsdatascience.com/similarity-search-knn-inverted-file-index-7cab80cc0e79?source=collection_archive---------1-----------------------#2023-04-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/similarity-search-knn-inverted-file-index-7cab80cc0e79?source=collection_archive---------1-----------------------#2023-04-28](https://towardsdatascience.com/similarity-search-knn-inverted-file-index-7cab80cc0e79?source=collection_archive---------1-----------------------#2023-04-28)
- en: Introduction to similarity search with kNN and its acceleration with inverted
    file.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍kNN的相似性搜索及其通过倒排文件的加速。
- en: '[](https://medium.com/@slavahead?source=post_page-----7cab80cc0e79--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----7cab80cc0e79--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7cab80cc0e79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7cab80cc0e79--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----7cab80cc0e79--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead?source=post_page-----7cab80cc0e79--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----7cab80cc0e79--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7cab80cc0e79--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7cab80cc0e79--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----7cab80cc0e79--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-knn-inverted-file-index-7cab80cc0e79&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----7cab80cc0e79---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7cab80cc0e79--------------------------------)
    ·9 min read·Apr 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7cab80cc0e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-knn-inverted-file-index-7cab80cc0e79&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----7cab80cc0e79---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-knn-inverted-file-index-7cab80cc0e79&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----7cab80cc0e79---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7cab80cc0e79--------------------------------)
    ·9 分钟阅读·2023年4月28日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7cab80cc0e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-knn-inverted-file-index-7cab80cc0e79&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----7cab80cc0e79---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7cab80cc0e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-knn-inverted-file-index-7cab80cc0e79&source=-----7cab80cc0e79---------------------bookmark_footer-----------)![](../Images/451ba5a7aab8a570f7a67d387bf5fc3d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7cab80cc0e79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-knn-inverted-file-index-7cab80cc0e79&source=-----7cab80cc0e79---------------------bookmark_footer-----------)![](../Images/451ba5a7aab8a570f7a67d387bf5fc3d.png)'
- en: S**imilarity search** is a problem where given a query the goal is to find the
    most similar documents to it among all the database documents.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**相似性搜索**是一个问题，给定一个查询，目标是找到数据库中与之最相似的文档。'
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In data science, similarity search often appears in the NLP domain, search engines
    or recommender systems where the most relevant documents or items need to be retrieved
    for a query. Normally, documents or items are represented in the form of texts
    or images. However, machine learning algorithms cannot directly work with raw
    texts or images, which is why documents and items are usually preprocessed and
    stored as **vectors** of numbers.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，**相似性搜索**常出现在自然语言处理领域、搜索引擎或推荐系统中，需要为查询检索最相关的文档或项目。通常，文档或项目以文本或图像的形式表示。然而，机器学习算法不能直接处理原始文本或图像，这就是为什么文档和项目通常被预处理并存储为**向量**的原因。
- en: Sometimes each component of a vector can store a semantic meaning. In this case,
    these representations are also called **embeddings**. Such embeddings can have
    hundreds of dimensions and their quantity can reach up to millions! Because of
    such huge numbers, any information retrieval system must be capable of rapidly
    detecting relevant documents.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，向量的每个组件可以存储语义信息。在这种情况下，这些表示也称为**嵌入**。这些嵌入可以有数百维，并且其数量可以达到数百万！由于这些巨大的数字，任何信息检索系统必须能够迅速检测到相关文档。
- en: In machine learning, a vector is also referred to as an **object** or **point**.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在机器学习中，向量也被称为**对象**或**点**。
- en: Index
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引
- en: To accelerate the search performance, a special data structure is built on top
    of dataset embeddings. Such a data structure is called **index**. There has been
    a lot of research in this field and many types of indexes have been evolved. Before
    choosing an index to apply for a certain task, it is necessary to understand how
    it operates under the hood since each index serves a different purpose and comes
    with its own pros and cons.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加速搜索性能，数据集嵌入之上建立了一个特殊的数据结构。这种数据结构称为**索引**。在这一领域已有大量研究，并且发展出了许多类型的索引。在选择适用于特定任务的索引之前，有必要了解其内部操作原理，因为每种索引有不同的用途，并且各自有优缺点。
- en: In this article, we will have a look at the most naive approach — **kNN**. Based
    on kNN, we will switch to **inverted file** — an index used for a more scalable
    search that can accelerate the search procedure several times.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将看看最简单的方法——**kNN**。基于kNN，我们将转到**倒排文件**——一种用于更可扩展搜索的索引，可以加速搜索过程数倍。
- en: kNN
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kNN
- en: '**kNN** is the simplest and the most naive algorithm for similarity search.
    Consider a dataset of vectors and a new query vector *Q*. We would like to find
    the top *k* dataset vectors which are the most similar to *Q*. The first aspect
    to think about is how to measure a similarity (distance) between two vectors.
    In fact, there are several similarity metrics to do it. Some of them are illustrated
    in the figure below.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**kNN**是相似性搜索中最简单和最原始的算法。考虑一个向量数据集和一个新的查询向量 *Q*。我们希望找到与 *Q* 最相似的前 *k* 个数据集向量。首先要考虑的是如何测量两个向量之间的相似性（距离）。实际上，有几种相似性度量可以实现这一点。下面的图中展示了其中一些。'
- en: '![](../Images/4205e53775ecd0632f4afe4c159b7868.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4205e53775ecd0632f4afe4c159b7868.png)'
- en: Similarity metrics
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 相似性度量
- en: Training
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: kNN is one of the few algorithms in machine learning that does not require a
    training phase. After choosing an appropriate metric, we can directly make predictions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: kNN是机器学习中为数不多的无需训练阶段的算法之一。选择合适的度量后，我们可以直接进行预测。
- en: Inference
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: For a new object, the algorithm exhaustively calculates distances to all the
    other objects. After that, it finds *k* objects with the smallest distances and
    returns them as a response.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个新的对象，该算法会穷尽地计算与所有其他对象的距离。之后，它会找到距离最小的 *k* 个对象，并将其作为响应返回。
- en: '![](../Images/17b2fd6c8e14a87f9829ebcfaca17bd2.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17b2fd6c8e14a87f9829ebcfaca17bd2.png)'
- en: kNN workflow
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: kNN工作流程
- en: Obviously, by checking distances to all the dataset vectors, kNN guarantees
    100% accurate results. However, such brute force approach is very inefficient
    in terms of time performance. If a dataset consists of *n* vectors with *m* dimensions,
    then for each of *n* vectors *O(m)* time is required to calculate the distance
    to it from a query *Q* which results in *O(mn)* total time complexity. As we will
    see later, there exist more efficient methods.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，通过检查与所有数据集向量的距离，kNN可以保证100%的准确结果。然而，这种蛮力方法在时间性能上非常低效。如果一个数据集由 *n* 个具有 *m*
    维度的向量组成，那么对于每个 *n* 向量，需要 *O(m)* 时间来计算与查询 *Q* 的距离，总时间复杂度为 *O(mn)*。正如我们稍后将看到的，存在更高效的方法。
- en: Moreover, there is no compression mechanism for the original vectors. Imagine
    a dataset with a billions of objects. It would probably be impossible to store
    all of them in RAM!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，原始向量没有压缩机制。想象一下一个包含数十亿个对象的数据集。将所有这些对象存储在RAM中几乎是不可能的！
- en: '![](../Images/29a705c831ea8e2a323f7552749caa1b.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29a705c831ea8e2a323f7552749caa1b.png)'
- en: 'kNN performance. Having 100% accuracy and no training phase results in exhaustive
    search during the inference and no-memory compression of vectors. Note: this type
    of diagram shows relative comparison of different algorithms. Depending on a situation
    and chosen hyperparameters, the performance may vary.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: kNN性能。具有100%的准确率和没有训练阶段会导致在推理过程中进行穷举搜索以及向量的无内存压缩。注意：这种图示显示了不同算法的相对比较。根据情况和选择的超参数，性能可能会有所不同。
- en: Application
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: 'kNN has a limited application scope and should be used only in one of the following
    scenarios:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: kNN的应用范围有限，应该仅在以下情况之一中使用：
- en: The dataset size or embedding dimensionality is relatively small. This aspect
    makes sure that the algorithm still performs fast.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的大小或嵌入维度相对较小。这一方面确保了算法仍然能够快速执行。
- en: The required accuracy of the algorithm must be 100%. In terms of accuracy, there
    is no other nearest neighbours algorithm which can outperform kNN.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的要求准确度必须达到100%。在准确度方面，没有其他最近邻算法能够超越kNN。
- en: Detection of a person based on his or her fingerprints is an example of a problem
    where 100% accuracy is required. If the person has committed a crime and left
    his fingerprints, it is vital to retrieve only the correct results. Otherwise,
    if the system is not 100% reliable, then another person can be found guilty of
    a crime which is a very critical error.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 基于指纹检测一个人的例子是需要100%准确度的问题。如果一个人犯了罪并留下了指纹，检索到的结果必须完全正确。否则，如果系统不是100%可靠，则可能会错误地将另一人定罪，这是一种非常严重的错误。
- en: 'Basically, there are two main ways to improve kNN (which we will discuss later):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，改进kNN有两种主要方法（稍后我们将讨论）：
- en: Reduce the search scope.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩小搜索范围。
- en: Reduce the vectors’ dimensionality.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降低向量的维度。
- en: When using one of these two approaches, we will not be performing an exhaustive
    search again. Such algorithms are called **approximate nearest neighbours (ANN)**
    because they do not guarantee 100% accurate results.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两种方法之一时，我们将不会再次进行穷举搜索。这些算法被称为**近似最近邻（ANN）**，因为它们不保证100%的准确结果。
- en: Inverted File Index
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 倒排文件索引
- en: '**“Inverted index** (also referred to as a **postings list**, **postings file**,
    or **inverted file**) is a database index storing a mapping from content, such
    as words or numbers, to its locations in a table, or in a document or a set of
    documents” — Wikipedia'
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“倒排索引**（也称为**文档列表**、**文档文件**或**倒排文件**）是一个数据库索引，存储内容的映射，例如单词或数字，及其在表格、文档或文档集合中的位置”
    — 维基百科'
- en: When performing a query, the hash function of the query is computed and mapped
    values from the hash table are taken. Each of these mapped values contains its
    own set of potential candidates which then are fully checked on a condition to
    be the nearest neighbour for the query. By doing so, the search scope of all database
    vectors is reduced.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行查询时，计算查询的哈希函数，并从哈希表中获取映射值。这些映射值中的每一个都包含自己的一组潜在候选者，然后在条件下完全检查是否为查询的最近邻。通过这样做，所有数据库向量的搜索范围被缩小。
- en: '![](../Images/51ba64fc16fa1491e565d610b242d177.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51ba64fc16fa1491e565d610b242d177.png)'
- en: Inverted file index workflow
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 倒排文件索引工作流程
- en: There are different implementations of this index depending on how hash functions
    are computed. The implementation we are going to look at is the one that uses
    **Voronoi diagrams** (or **Dirichlet tessellation**).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这种索引有不同的实现方式，具体取决于哈希函数的计算方式。我们将要研究的实现是使用**Voronoi图**（或**Dirichlet镶嵌**）的方法。
- en: Training
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: The idea of the algorithm is to create several non-intersecting regions to which
    each dataset point will belong. Each region has its own centroid which points
    to the center of that region.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法的思想是创建几个不相交的区域，每个数据集点将属于其中一个区域。每个区域都有自己的质心，指向该区域的中心。
- en: Sometimes **Voronoi regions** are referred to as **cells** or **partitions**.
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有时**Voronoi区域**也被称为**单元**或**分区**。
- en: '![](../Images/48380f868bba90119ee7108e5ff65b08.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48380f868bba90119ee7108e5ff65b08.png)'
- en: Example of a Voronoi diagram. White points are centers of respective partitions
    which contain a set of candidates.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Voronoi图示例。白点是各自分区的中心，分区内包含一组候选者。
- en: The main property of Voronoi diagrams is that the distance from a centroid to
    any point of its region is less than the distance from that point to another centroid.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Voronoi图的主要特性是，质心到其区域内任意点的距离小于该点到另一质心的距离。
- en: Inference
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: When given a new object, distances to all the centroids of Voronoi partitions
    are calculated. Then the centroid with the lowest distance is chosen and vectors
    contained in this partition are then taken as candidates.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当给定一个新对象时，计算所有Voronoi分区质心的距离。然后选择距离最小的质心，并将该分区中的向量作为候选项。
- en: '![](../Images/fce8e2a887cf3367fc3eb36fa88ca718.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fce8e2a887cf3367fc3eb36fa88ca718.png)'
- en: By a given query we search for the nearest centroid (located in the green zone)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过给定查询，我们搜索最近的质心（位于绿色区域）
- en: Ultimately, by computing the distances to the candidates and choosing the top
    *k* nearest of them, the final answer is returned.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，通过计算与候选项的距离并选择前*k*个最近的候选项，返回最终答案。
- en: '![](../Images/75d38fc65edd40656193b2f1a8040ec4.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75d38fc65edd40656193b2f1a8040ec4.png)'
- en: Finding the nearest neighbour in the selected region
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在选定区域内查找最近邻居
- en: As you can see, this approach is much faster than the previous one as we do
    not have to look through all the dataset vectors.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这种方法比之前的要快得多，因为我们不需要遍历所有数据集向量。
- en: Edge problem
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边缘问题
- en: 'With the increase in search speed, inverted file comes with a downside: it
    does not guarantee that the found object will always be the nearest.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 随着搜索速度的提高，倒排文件也有一个缺点：它不能保证找到的对象始终是最近的。
- en: 'In the figure below we can see such a scenario: the actual nearest neighbour
    is located in the red region but we are selecting candidates only from the green
    zone. Such a situation is called the **edge problem**.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们可以看到这样的场景：实际的最近邻居位于红色区域，但我们仅从绿色区域选择候选项。这种情况被称为**边缘问题**。
- en: '![](../Images/a1f1b2a0a2066e904df3b7b357469704.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1f1b2a0a2066e904df3b7b357469704.png)'
- en: Edge problem
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘问题
- en: This case typically occurs when the queried object is located near the border
    with another region. To reduce the number of errors in such cases, we can increase
    the search scope and choose several regions to search for candidates based on
    the top *m* closest centroids to the object.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况通常发生在查询对象靠近另一区域边界时。为了减少这种情况下的错误数量，我们可以扩大搜索范围，并基于与对象最接近的前*m*个质心选择多个区域来搜索候选项。
- en: '![](../Images/1a4ccefb2576c2eb6f79749b89d4df8e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a4ccefb2576c2eb6f79749b89d4df8e.png)'
- en: Searching for nearest neighbours within several regions (m = 3)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在几个区域内查找最近邻居（m = 3）
- en: The more regions are explored, the more accurate results are and the more time
    it takes to compute them.
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 探索的区域越多，结果越准确，但计算所需的时间也越长。
- en: Application
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用
- en: Despite the edge problem, inverted file shows decent results in practice. It
    is perfect to utilize in cases where we want to trade-off a little decrease in
    the accuracy for achieving speed growth several times.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在边缘问题，倒排文件在实践中表现出色。它在需要在准确度和速度提升之间进行权衡时非常适合使用。
- en: One of the use-case examples is a content-based recommender system. Imagine
    it recommends a movie to a user based on other movies he watched in the past.
    The database contains a million movies to choose from.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个使用案例示例是基于内容的推荐系统。假设它根据用户过去观看的其他电影向用户推荐一部电影。数据库包含一百万部电影供选择。
- en: By using kNN, the system indeed chooses the most relevant movie for a user and
    recommends it. However, the time required to perform the query is very long.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用kNN时，系统确实会选择对用户最相关的电影并进行推荐。然而，执行查询所需的时间非常长。
- en: Let us assume that with inverted file index, the system recommends the 5-th
    most relevant movie which is probably the case in real life. The search time is
    20 times faster than kNN.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设使用倒排文件索引，系统推荐第5个最相关的电影，这在现实生活中可能是这种情况。搜索时间比kNN快20倍。
- en: 'From the user experience, it will be very hard to distinguish between the quality
    result of these two recommendations: the 1-st and the 5-th most relevant results
    are both good recommendations from a million of possible movies. The user will
    probably be happy with any of these recommendations. From the time perspective,
    inverted file is, obviously, the winner. That is why in this situation it is better
    to use the latter approach.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户体验的角度来看，很难区分这两种推荐结果的质量：第1个和第5个最相关的结果都是来自百万个可能电影中的良好推荐。用户可能对这些推荐中的任何一个都感到满意。从时间的角度来看，倒排文件显然是赢家。这就是为什么在这种情况下，最好使用后者的方法。
- en: '![](../Images/2511a8d8682cf99383f3d628ccc4f4ca.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2511a8d8682cf99383f3d628ccc4f4ca.png)'
- en: Inverted file index performance. Here we slightly reduce the accuracy for achieving
    a higher speed during the inference.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 反向文件索引性能。在这里，我们稍微降低了准确度以在推理过程中获得更高的速度。
- en: Faiss implementation
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Faiss实现
- en: '[**Faiss**](https://github.com/facebookresearch/faiss) (Facebook AI Search
    Similarity) is a Python library written in C++ used for optimised similarity search.
    This library presents different types of indexes which are data structures used
    to efficiently store the data and perform queries.'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**Faiss**](https://github.com/facebookresearch/faiss)（Facebook AI 搜索相似性）是一个用C++编写的Python库，用于优化的相似性搜索。该库展示了不同类型的索引，这些索引是用来高效存储数据和执行查询的数据结构。'
- en: Based on the information from the [Faiss documentation](https://faiss.ai), we
    will see how indexes are created and parametrized.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[Faiss文档](https://faiss.ai)中的信息，我们将了解索引的创建和参数化过程。
- en: kNN
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kNN
- en: 'Indexes implementing the kNN approach are referred to as **flat** in Faiss
    because that they do not compress any information. They are the only indexes that
    guarantee the correct search result. Actually there exist two types of flat indexes
    in Faiss:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 实现kNN方法的索引在Faiss中被称为**flat**，因为它们不压缩任何信息。它们是唯一保证正确搜索结果的索引。实际上，Faiss中存在两种类型的flat索引：
- en: '*IndexFlatL2*. The similarity is calculated as Euclidean distance.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*IndexFlatL2*。相似度计算为欧几里得距离。'
- en: '*IndexFlatIP*. The similarity is calculated as an inner product.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*IndexFlatIP*。相似度计算为内积。'
- en: 'Both of these indexes require a single parameter **d** in their constructors:
    the data dimension. These indexes do not have any tunable parameters.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种索引在构造函数中都需要一个单一的参数**d**：数据维度。这些索引没有任何可调参数。
- en: '![](../Images/a7c95b54cdc224f68c942727d7552b88.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7c95b54cdc224f68c942727d7552b88.png)'
- en: Faiss implementation of IndexFlatL2 and IndexFlatIP
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Faiss对IndexFlatL2和IndexFlatIP的实现
- en: 4 bytes are required to store a single component of a vector. Therefore, to
    store a single vector of dimensionality *d, 4 * d* bytes are required.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 存储一个向量的单一分量需要4字节。因此，存储一个维度为*d*的向量需要*4 * d*字节。
- en: '![](../Images/cf6a38cc71459bd1317b705373914496.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf6a38cc71459bd1317b705373914496.png)'
- en: Inverted file index
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向文件索引
- en: For described inverted file, Faiss implements the class *IndexIVFFlat*. As in
    the case with kNN, the word “*Flat*” indicates that there is no decompression
    of original vectors and they are fully stored.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于描述的反向文件，Faiss实现了*IndexIVFFlat*类。与kNN的情况一样，" *Flat* "一词表示没有对原始向量进行解压，它们被完全存储。
- en: To create this index, we first need to pass a quantizer — an object that will
    determine how database vectors will be stored and compared.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建这个索引，我们首先需要传递一个量化器——一个决定数据库向量如何存储和比较的对象。
- en: '*IndexIVFFlat* has 2 important parameters:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*IndexIVFFlat*有两个重要参数：'
- en: '**nlist**: defines a number of regions (Voronoi cells) to create during training.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nlist**：定义在训练过程中创建的区域（Voronoi单元）的数量。'
- en: '**nprobe**: determines how many regions to take for the search of candidates.
    Changing nprobe parameter does not require retraining.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**nprobe**：决定搜索候选区域的数量。更改nprobe参数不需要重新训练。'
- en: '![](../Images/e689102761b3812784f4ca933ed7c552.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e689102761b3812784f4ca933ed7c552.png)'
- en: Faiss implementation of IndexIVFFlat
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Faiss对IndexIVFFlat的实现
- en: 'As in the previous case, we need *4 * d* bytes to store a single vector. But
    now we also have to store information about Voronoi regions to which dataset vectors
    belong to. In Faiss implementation, this information takes 8 bytes per vector.
    Therefore, the memory required to store a single vector is:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的情况一样，我们需要*4 * d*字节来存储一个向量。但现在我们还需要存储有关Voronoi区域的信息，这些区域是数据集向量所属的。在Faiss实现中，这些信息每个向量占用8字节。因此，存储单个向量所需的内存为：
- en: '![](../Images/e6584546fe377cd8f1a1faef2a7b5cca.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6584546fe377cd8f1a1faef2a7b5cca.png)'
- en: Conclusion
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have gone through two base algorithms in similarity search. Effectively naive
    kNN should almost be never used for machine learning applications because of its
    bad scalability except for specific cases. On the other hand, inverted file provides
    good heuristics for accelerated search whose quality can be improved by tuning
    its hyperparameters. The search performance can still be enhanced from different
    perspectives. In the next part of this article series, we will have a look at
    one of such methods designed to compress dataset vectors.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了相似性搜索中的两种基础算法。实际上，朴素的 kNN 几乎不应该用于机器学习应用，因为它在扩展性方面表现不佳，除非在特定情况下。另一方面，倒排文件提供了加速搜索的良好启发式方法，其质量可以通过调整超参数来提高。从不同的角度仍然可以提升搜索性能。在本系列文章的下一部分，我们将深入探讨一种旨在压缩数据集向量的方法。
- en: '[](/similarity-search-product-quantization-b2a1a6397701?source=post_page-----7cab80cc0e79--------------------------------)
    [## Similarity Search, Part 2: Product Quantization'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/similarity-search-product-quantization-b2a1a6397701?source=post_page-----7cab80cc0e79--------------------------------)
    [## 相似性搜索，第2部分：产品量化'
- en: Learn a powerful technique to effectively compress large data
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习一种有效压缩大数据的强大技术
- en: towardsdatascience.com](/similarity-search-product-quantization-b2a1a6397701?source=post_page-----7cab80cc0e79--------------------------------)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/similarity-search-product-quantization-b2a1a6397701?source=post_page-----7cab80cc0e79--------------------------------)
- en: Resources
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '[Inverted Index | Wikipedia](https://en.wikipedia.org/wiki/Inverted_index)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[倒排索引 | 维基百科](https://en.wikipedia.org/wiki/Inverted_index)'
- en: '[Faiss documentation](https://faiss.ai)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Faiss 文档](https://faiss.ai)'
- en: '[Faiss repository](https://github.com/facebookresearch/faiss)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Faiss 仓库](https://github.com/facebookresearch/faiss)'
- en: '[Summary of Faiss indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Faiss 索引概述](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes)'
- en: '[Guideline for choosing an index](https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[选择索引的指南](https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index)'
- en: '*All images unless otherwise noted are by the author.*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，否则所有图片均由作者提供。*'
