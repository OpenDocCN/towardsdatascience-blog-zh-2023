- en: Comprehensive Guide to Concurrency and Parallelism in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python中的并发与并行综合指南
- en: 原文：[https://towardsdatascience.com/comprehensive-guide-to-concurrency-and-parallelism-in-python-415ee5fbec1a](https://towardsdatascience.com/comprehensive-guide-to-concurrency-and-parallelism-in-python-415ee5fbec1a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/comprehensive-guide-to-concurrency-and-parallelism-in-python-415ee5fbec1a](https://towardsdatascience.com/comprehensive-guide-to-concurrency-and-parallelism-in-python-415ee5fbec1a)
- en: Using multiprocessing, threading and asyncio
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用multiprocessing、threading和asyncio
- en: '[](https://medium.com/@hrmnmichaels?source=post_page-----415ee5fbec1a--------------------------------)[![Oliver
    S](../Images/b5ee0fa2d5fb115f62e2e9dfcb92afdd.png)](https://medium.com/@hrmnmichaels?source=post_page-----415ee5fbec1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----415ee5fbec1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----415ee5fbec1a--------------------------------)
    [Oliver S](https://medium.com/@hrmnmichaels?source=post_page-----415ee5fbec1a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@hrmnmichaels?source=post_page-----415ee5fbec1a--------------------------------)[![Oliver
    S](../Images/b5ee0fa2d5fb115f62e2e9dfcb92afdd.png)](https://medium.com/@hrmnmichaels?source=post_page-----415ee5fbec1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----415ee5fbec1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----415ee5fbec1a--------------------------------)
    [Oliver S](https://medium.com/@hrmnmichaels?source=post_page-----415ee5fbec1a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----415ee5fbec1a--------------------------------)
    ·8 min read·Apr 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----415ee5fbec1a--------------------------------)
    ·8分钟阅读·2023年4月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In this post we’ll give a detailed introduction to concurrency and parallelism
    in Python. We’ll introduce these terms, and then show how they can be applied
    in Python using `multiprocessing`, `threading` and `asyncio`. We’ll learn when
    to use multiple processes and when to use multiple threads, and give practical
    examples for each.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将详细介绍Python中的并发和并行。我们将介绍这些术语，并展示如何使用`multiprocessing`、`threading`和`asyncio`在Python中应用它们。我们将学习何时使用多个进程，何时使用多个线程，并为每种情况提供实际示例。
- en: '![](../Images/d46b0e529b898fbbd9fbb143c1f18a48.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d46b0e529b898fbbd9fbb143c1f18a48.png)'
- en: Photo by [Tomas Sobek](https://unsplash.com/@tomas_nz?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/plwud_FPvwU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于[Tomas Sobek](https://unsplash.com/@tomas_nz?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)的[Unsplash](https://unsplash.com/photos/plwud_FPvwU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Overview
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: 'Let’s first introduce the two terms used in the title from a general computer
    science perspective: concurrency means accessing the same resources, e.g. CPU
    cores or disk, “simultaneously” — while parallelism describes multiple tasks accessing
    separate resources, e.g. different CPU cores.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从计算机科学的一般角度介绍标题中的两个术语：并发是指“同时”访问相同资源，例如CPU核心或磁盘——而并行则描述多个任务访问不同的资源，例如不同的CPU核心。
- en: In the context of Python, parallelism is made available by the `multiprocessing`
    package — which allows the creation of multiple, separate processes. Concurrency
    can be realised using the `threading` package, allowing the creation of different
    threads — or `asyncio`, which follows a slightly different philosophy.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中，通过`multiprocessing`包实现了并行——它允许创建多个独立的进程。并发可以通过`threading`包实现，允许创建不同的线程——或者通过`asyncio`，它遵循稍微不同的哲学。
- en: What are the differences and similarities? A *process* is a separate process
    managed by the underlying operating system. A process can start multiple *threads*
    — a thread can be thought of as a subroutine of a process. By default, processes
    are separate entities and do not share memory or similar. Their creation induces
    overhead, as well as data-sharing and passing is not trivial, and needs to be
    managed e.g via inter-process communication (IPC). In contrast, threads are light-weight,
    and sharing data is easy, as they are part of the same process and same memory
    space.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的异同是什么？一个*进程*是由底层操作系统管理的独立进程。一个进程可以启动多个*线程*——线程可以被视为进程的一个子例程。默认情况下，进程是独立的实体，不共享内存或类似资源。它们的创建会产生开销，同时数据共享和传递也不是简单的，需要通过进程间通信（IPC）来管理。相比之下，线程是轻量级的，数据共享很容易，因为它们属于同一个进程和内存空间。
- en: Python differs from several other languages by the fact it’s using a [Global
    Interpreter Lock (GIL)](https://betterprogramming.pub/pythons-gil-vs-c-with-mutexes-301b244e42),
    to manage concurrent access to the Python interpreter. This lock becomes effective
    for multi-threaded applications, making sure that only one thread at a time is
    allowed to run Python code. Due to this, every multi-threaded Python application
    effectively is single-core!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Python 与其他几种语言的不同之处在于，它使用了一个[全局解释器锁 (GIL)](https://betterprogramming.pub/pythons-gil-vs-c-with-mutexes-301b244e42)来管理对
    Python 解释器的并发访问。这个锁在多线程应用程序中变得有效，确保一次只能有一个线程可以运行 Python 代码。因此，每个多线程 Python 应用程序实际上都是单核的！
- en: 'With this, we can now define use cases and recommendations, when to use multi-processing
    and when to use multi-threading: if your application is CPU-bound, meaning access
    to the CPU is the main bottleneck, use multi-processing. Only with this your application
    will effectively use multiple cores at the same time, and speed-up code which
    can be parallelised over multiple cores. The downside is the increased overhead
    for creating the processes, as well as the added complexity if data is to be shared.
    However, there can be other bottlenecks besides the CPU, e.g. I/O bound applications.
    These are defined by long waiting times of input / output operations, e.g. waiting
    for user input or for a web request to return. If this is the case, multi-threading
    is probably the better alternative, as we can avoid the overhead from multi-processing
    and share data natively.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们现在可以定义使用场景和建议：何时使用多处理，何时使用多线程：如果您的应用程序是 CPU 绑定的，意味着对 CPU 的访问是主要瓶颈，则使用多处理。只有这样，您的应用程序才能有效地同时使用多个核心，并加速可以在多个核心上并行的代码。缺点是创建进程的开销增加，以及如果数据需要共享则增加的复杂性。然而，除了
    CPU 之外，还可能存在其他瓶颈，例如 I/O 绑定的应用程序。这些应用程序的特点是输入/输出操作的长时间等待，例如等待用户输入或等待 web 请求返回。如果是这种情况，多线程可能是更好的选择，因为我们可以避免多处理带来的开销，并原生共享数据。
- en: In the following, we will now introduce these concepts, starting with multi-processing.
    We will then implement the same CPU bound sample application using multiple threads
    and show that it is indeed limited to one core at a time. We then give an example
    using an I/O bound application and implement this using `threading` and `asyncio`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍这些概念，从多处理开始。然后，我们将使用多个线程实现相同的 CPU 绑定示例应用程序，并显示它确实一次只能限制一个核心。接着，我们给出一个使用
    I/O 绑定应用程序的示例，并使用`threading`和`asyncio`来实现。
- en: CPU Bound Applications
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**CPU 绑定应用程序**'
- en: 'For parallelism in Python we use the package `multiprocessing`. Using this,
    we can natively define processes via the `Process` class, and then simply start
    and stop them. The following example starts four processes which all count to
    100000000\. This means, the application is CPU-bound — the faster the CPU(s) can
    increment the counter, the faster they are done:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在 Python 中实现并行，我们使用 `multiprocessing` 包。通过使用这个包，我们可以原生定义进程，通过 `Process` 类，然后简单地启动和停止它们。以下示例启动四个进程，每个进程都计算到
    100000000。这意味着，该应用程序是 CPU 绑定的——CPU（核心）增量计数的速度越快，完成的速度就越快：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: On my laptop, above program takes around 3s to execute.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的笔记本电脑上，上面的程序执行大约需要 3 秒。
- en: Note that the check for `__main__` is important in this context, as new processes
    will be spawned based on the same code. Without the check, we run into an error,
    as otherwise this would trigger an infinite loop.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`__main__` 的检查在这种情况下很重要，因为新进程将基于相同的代码生成。如果没有检查，我们会遇到错误，因为这会触发无限循环。
- en: Multi-threading
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**多线程**'
- en: 'Now let’s have a look how to solve this same problem using multi-threading.
    For this, we see that we can simply exchange `multiprocessing.Process` by `threading.Thread`,
    and otherwise run the code basically analogously:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用多线程来解决相同的问题。为此，我们可以简单地用 `threading.Thread` 替换 `multiprocessing.Process`，其他方面的代码基本上是类似的：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Upon execution, this code takes about 10s to finish — 3x slower than when using
    different processes. We can empirically observe the GIL kicking in, and indeed
    restricting parallel code execution to a single core, as claimed above.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 执行时，这段代码大约需要 10 秒才能完成——比使用不同进程时慢 3 倍。我们可以通过经验观察到 GIL 的作用，确实将并行代码执行限制在一个核心上，正如前面所述。
- en: But for now, let’s dive slightly deeper into multi-processing, and in particular
    using some more high-level abstractions to simplify starting multiple processes.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在，让我们稍微深入了解一下多处理，特别是使用一些更高层次的抽象来简化启动多个进程。
- en: multiprocessing.Pool
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**multiprocessing.Pool**'
- en: 'One such abstraction is `multiprocessing.Pool`. This is a convenience function
    to generate a pool of workers / processes, which automatically split the given
    work amongst each other and execute it:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一种这样的抽象是 `multiprocessing.Pool`。这是一个方便的函数，用于生成一个工人/进程池，它会自动将给定的工作分配给彼此并执行：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As we can see, we instantiate a `Pool` with the number of workers to use. It
    is recommend to set this to the number of CPU cores you have (`os.cpu_count`).
    We then use the `map` function, passing as first argument the function we want
    each worker to run, and as second the input data to be used. In our case, this
    is simply the argument `max_count`. Since we pass an array of length 5, `count`
    will be run 5 times. With the number of pool workers set to 4, this results in
    2 “cycles”: in the first cycle, workers 0–3 process the first 4 arguments / datasets,
    and in the second that worker which finished first processes the last dataset.
    In this example `count` also returns a value to show-case how `map` handles return
    values.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们实例化一个 `Pool`，并设置要使用的工作者数量。建议将此数量设置为您拥有的 CPU 核心数（`os.cpu_count`）。然后我们使用
    `map` 函数，将我们希望每个工作者运行的函数作为第一个参数传递，将输入数据作为第二个参数传递。在我们的案例中，这只是参数 `max_count`。由于我们传递了一个长度为
    5 的数组，`count` 将运行 5 次。将池工作者数量设置为 4，结果是 2 个“周期”：在第一个周期中，工作者 0–3 处理前 4 个参数/数据集，在第二个周期中，完成得最早的工作者处理最后一个数据集。在这个示例中，`count`
    还返回一个值，以展示 `map` 如何处理返回值。
- en: '**Pool.imap**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pool.imap**'
- en: 'To conclude this section, let’s have a look at a very similar function to `map`,
    namely `imap`. The difference between `map` and `imap` is how tasks are processed:
    `map` converts all tasks to a list, and then passes them all at once to the workers,
    breaking them into chunks. `imap` on the other hand passes them one by one. This
    can be more memory efficient, but also slower. Another difference is that `imap`
    returns immediately after each task finished, whereas map blocks until all tasks
    are done. We can use `imap` as such:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束这一部分，让我们看看一个非常类似于 `map` 的函数，即 `imap`。`map` 和 `imap` 之间的区别在于任务处理的方式：`map`
    将所有任务转换为一个列表，然后一次性将它们传递给工作者，将任务分解成块。另一方面，`imap` 逐个传递任务。这可能更节省内存，但也可能较慢。另一个区别是
    `imap` 在每个任务完成后立即返回，而 `map` 会阻塞直到所有任务完成。我们可以这样使用 `imap`：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: I/O Bound Applications
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: I/O 绑定的应用程序
- en: 'This concludes our introduction to parallelism, which is useful and recommended
    for CPU bound applications. Now, let’s talk about applications which are not CPU-bound,
    and in particular are IO-bound. For this, we use concurrency. In particular, we
    will introduce this using an example using multi-threading for which it does not
    make sense to use multi-processing because:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这总结了我们对并行性的介绍，它对于 CPU 绑定的应用程序非常有用并且推荐使用。现在，让我们谈谈那些不是 CPU 绑定的应用程序，特别是 I/O 绑定的应用程序。为此，我们使用并发。特别是，我们将通过一个示例来介绍这个概念，使用多线程，因为对于这种情况，使用多进程没有意义，因为：
- en: The application is not CPU-bound, and thus the extra overhead from multi-processing
    is not worth it.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个应用程序不是 CPU 绑定的，因此多进程带来的额外开销不值得。
- en: The threads communicate between each other, which would induce additional overhead
    and complexity when used with multi-processing.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程之间的通信会引入额外的开销和复杂性，当与多进程一起使用时尤为如此。
- en: 'We chose the following example representing an I/O bound application: there
    is a publisher thread which generates data, in our example coming from the user.
    And there will be N subscriber threads, which wait for a specific condition in
    the data, and when this becomes active start some operation which involves lots
    of idling, i.e. CPU is not the bottle-neck.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了以下示例来表示一个 I/O 绑定的应用程序：有一个发布者线程生成数据，在我们的示例中，这些数据来自用户。然后将有 N 个订阅者线程，它们等待数据中的特定条件，一旦这个条件激活，就开始执行一些涉及大量空闲操作的任务，即
    CPU 不是瓶颈。
- en: 'We can see, that for this case the CPU is not the limit: a lot of time will
    be spent waiting for inputs, and also the subsequent operation is not CPU-heavy.
    Still, we want / need some form of concurrency — we have different threads which
    run independently (producers vs subscribers), and also want to execute the follow-up
    tasks “in parallel”, and not sequentially.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，对于这种情况，CPU 不是限制因素：大量时间将花费在等待输入上，并且随后的操作也不是 CPU 密集型的。然而，我们仍然希望/需要某种形式的并发——我们有不同的线程独立运行（生产者与订阅者），并且还希望执行后续任务时能够“并行”进行，而不是顺序执行。
- en: 'Thus, we employ the package `threading`, with which this example looks as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用 `threading` 包，示例代码如下：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The producer thread continuously queries for user input, and once the user inputs
    “Start” a flag is toggled, signalling the consumers to start. In the consumer,
    we react to this, and upon receiving this signal count to 10 within 10s.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 生产者线程不断查询用户输入，一旦用户输入“开始”，一个标志会被切换，通知消费者开始。在消费者中，我们对此做出反应，并在收到信号后在 10 秒内计数到 10。
- en: asyncio
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: asyncio
- en: 'To conclude this post, we want to quickly introduce `[asyncio](https://medium.com/towards-data-science/introduction-to-asyncio-57a5a1290ce0)`
    and how to use it in this scenario. For a full introduction, I’d like to refer
    to the linked post. Here, let’s just briefly say that `asyncio` can be thought
    of a slightly different paradigm of writing / structuring multi-threaded code
    — which is prefered by many developers in multiple scenarios, mainly due to its
    simplicty. `asyncio` is made for I/O bound applications, and it employs the notion
    of coroutines: while only one is being executed at a time, when it is waiting
    for a certain condition (such as user input, a web request finishing …), it can
    “yield” control and allow another coroutine to run.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结这篇文章，我们想快速介绍一下 `[asyncio](https://medium.com/towards-data-science/introduction-to-asyncio-57a5a1290ce0)`
    以及如何在这种情况下使用它。对于完整的介绍，我建议参考链接中的文章。在这里，我们简单说一下 `asyncio` 可以被视为一种稍微不同的多线程代码编写/结构化范式——许多开发者在多种场景中更喜欢这种方式，主要是因为它的简洁性。`asyncio`
    适用于 I/O 密集型应用，它采用了协程的概念：当一个协程在等待某个条件（如用户输入、网络请求完成等）时，它可以“让出”控制权，让另一个协程运行。
- en: 'Using this principle, the example above can be written as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个原则，上面的示例可以这样编写：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Note that in this case there is no need to use a lock, as we decide when to
    yield execution and switch to a different thread: we only do so (in this simple
    example) in the “wait” periods, where no shared variable is written or accessed.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这种情况下不需要使用锁，因为我们决定何时让出执行并切换到不同的线程：我们仅在“等待”期间进行切换，这时没有共享变量被写入或访问。
- en: Conclusion
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this post we introduced the concepts parallelism and concurrency, and described
    how these translate to multi-processing and multi-threading with Python.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了并行性和并发性概念，并描述了它们如何转换为 Python 中的多进程和多线程。
- en: Due to the GIL, multi-threaded applications in Python essentially are single-core
    — and thus, this paradigm is not suitable for CPU bound applications. For these,
    we showed how to manage multi-processing — and then empirically proved the slow
    down due to the GIL, by re-writing the same example to use multiple threads.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 GIL，Python 中的多线程应用实际上是单核的——因此，这种范式不适用于 CPU 密集型应用。对于这些应用，我们展示了如何管理多进程——然后通过将相同的示例重写为使用多个线程，经验性地证明了由于
    GIL 导致的性能下降。
- en: Still, there are many scenarios where also multi-threading is beneficial and
    desired, in particular for IO-bound applications. For these, we introduced multi-threading
    in Python, and concluded by converting the example to `asyncio`, which is a slightly
    different paradigm of writing multi-threaded applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，仍然有许多场景中多线程也是有益和必要的，特别是对于 I/O 密集型应用。对于这些应用，我们介绍了 Python 中的多线程，并通过将示例转换为
    `asyncio` 这一稍微不同的多线程应用编写范式来结束。
- en: This finishes this tutorial, I hope, it was informative. See you next time!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了本教程，希望对你有所帮助。下次见！
