- en: 'Similarity Search, Part 4: Hierarchical Navigable Small World (HNSW)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相似性搜索，第4部分：分层可导航的小世界（HNSW）
- en: 原文：[https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37?source=collection_archive---------0-----------------------#2023-06-16](https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37?source=collection_archive---------0-----------------------#2023-06-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37?source=collection_archive---------0-----------------------#2023-06-16](https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37?source=collection_archive---------0-----------------------#2023-06-16)
- en: Discover how to construct efficient multi-layered graphs to boost search speed
    in massive volumes of data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现如何构建高效的多层图以提升在海量数据中的搜索速度
- en: '[](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)[![数据科学进展](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----2aad4fe87d37--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----2aad4fe87d37---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)
    ·13 min read·Jun 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2aad4fe87d37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----2aad4fe87d37---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----2aad4fe87d37---------------------post_header-----------)
    发表在 [数据科学进展](https://towardsdatascience.com/?source=post_page-----2aad4fe87d37--------------------------------)
    · 13 分钟阅读 · 2023年6月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2aad4fe87d37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----2aad4fe87d37---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2aad4fe87d37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&source=-----2aad4fe87d37---------------------bookmark_footer-----------)![](../Images/d9c57ffdc93575971084c70c2b6d6e38.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2aad4fe87d37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsimilarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&source=-----2aad4fe87d37---------------------bookmark_footer-----------)![](../Images/d9c57ffdc93575971084c70c2b6d6e38.png)'
- en: S**imilarity search** is a problem where given a query the goal is to find the
    most similar documents to it among all the database documents.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**相似性搜索** 是一个问题，其中给定一个查询，目标是找到与之最相似的文档，这些文档位于所有数据库文档中。'
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In data science, similarity search often appears in the NLP domain, search engines
    or recommender systems where the most relevant documents or items need to be retrieved
    for a query. There exists a large variety of different ways to improve search
    performance in massive volumes of data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，相似性搜索通常出现在自然语言处理领域、搜索引擎或推荐系统中，这些系统需要为查询检索最相关的文档或项目。在海量数据中，有各种不同的方法可以提高搜索性能。
- en: '[**Hierarchical Navigable Small World**](https://arxiv.org/pdf/1603.09320.pdf)
    (HNSW) is a state-of-the-art algorithm used for an approximate search of nearest
    neighbours. Under the hood, HNSW constructs optimized graph structures making
    it very different from other approaches that were discussed in previous parts
    of this article series.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[**分层可导航小世界**](https://arxiv.org/pdf/1603.09320.pdf)（HNSW）是一种用于近似邻居搜索的最先进算法。在背后，HNSW
    构建了优化的图结构，使其与本系列文章前面讨论的其他方法大相径庭。'
- en: The main idea of HNSW is to construct such a graph where a path between any
    pair of vertices could be traversed in a small number of steps.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: HNSW 的主要思想是构建一个图，使得任意一对顶点之间的路径可以在少量步骤内遍历。
- en: 'A well-known analogy on the famous [six handshakes rule](https://en.wikipedia.org/wiki/Six_degrees_of_separation)
    is related to this method:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个著名的类比是著名的 [六度分隔理论](https://en.wikipedia.org/wiki/Six_degrees_of_separation)，与这种方法相关：
- en: All people are six or fewer social connections away from each other.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有人彼此之间的社交联系最多为六层。
- en: Before proceeding to inner workings of HNSW let us first discuss skip lists
    and navigable small words — crucial data structures used inside the HNSW implementation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨 HNSW 的内部工作之前，我们先讨论跳表和可导航小世界——HNSW 实现中使用的关键数据结构。
- en: Skip lists
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跳表
- en: '[Skip list](https://en.wikipedia.org/wiki/Skip_list) is a probabilistic data
    structure that allows inserting and searching elements within a sorted list for
    *O(logn)* on average. A skip list is constructed by several layers of linked lists.
    The lowest layer has the original linked list with all the elements in it. When
    moving to higher levels, the number of skipped elements increases, thus decreasing
    the number of connections.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[跳表](https://en.wikipedia.org/wiki/Skip_list) 是一种概率数据结构，允许在排序列表中以 *O(logn)*
    的平均时间复杂度插入和搜索元素。跳表由多个层次的链表构成。最低层包含所有元素的原始链表。当移动到更高的层级时，被跳过的元素数量增加，从而减少了连接数。'
- en: '![](../Images/2504b3cea528c33a5d4d7ff24c2d8778.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2504b3cea528c33a5d4d7ff24c2d8778.png)'
- en: Finding element 20 in skip list
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在跳表中找到元素 20
- en: The search procedure for a certain value starts from the highest level and compares
    its next element with the value. If the value is less or equal to the element,
    then the algorithm proceeds to its next element. Otherwise, the search procedure
    descends to the lower layer with more connections and repeats the same process.
    At the end, the algorithm descends to the lowest layer and finds the desired node.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某个值的搜索程序从最高层开始，将其下一个元素与该值进行比较。如果值小于或等于该元素，则算法继续到下一个元素。否则，搜索程序降到连接更多的较低层，并重复相同的过程。最后，算法降到最低层并找到所需的节点。
- en: Based on the information from [Wikipedia](https://en.wikipedia.org/wiki/Skip_list),
    a skip list has the main parameter *p* which defines the probability of an element
    appearing in several lists. If an element appears in layer *i*, then the probability
    that it will appear in layer *i + 1* is equal to *p (p* is usually set to 0.5
    or 0.25*)*. On average, each element is presented in *1 / (1 — p)* lists.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 [维基百科](https://en.wikipedia.org/wiki/Skip_list) 的信息，跳表有一个主要参数 *p*，它定义了一个元素出现在多个列表中的概率。如果一个元素出现在层
    *i* 中，则它出现在层 *i + 1* 的概率等于 *p*（*p* 通常设置为 0.5 或 0.25）。平均而言，每个元素会出现在 *1 / (1 — p)*
    个列表中。
- en: As we can see, this process is much faster than the normal linear search in
    the linked list. In fact, HNSW inherits the same idea but instead of linked lists,
    it uses graphs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，这个过程比普通的链表线性搜索要快得多。实际上，HNSW 继承了相同的思想，但它使用的是图而不是链表。
- en: Navigable Small World
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可导航的小世界
- en: '[**Navigable small world**](https://en.wikipedia.org/wiki/Small-world_network)
    is a graph with polylogarithmic *T = O(logᵏn)* search complexity which uses greedy
    routing. **Routing** refers to the process of starting the search process from
    low-degree vertices and ending with high-degree vertices. Since low-degree vertices
    have very few connections, the algorithm can rapidly move between them to efficiently
    navigate to the region where the nearest neighbour is likely to be located. Then
    the algorithm gradually zooms in and switches to high-degree vertices to find
    the nearest neighbour among the vertices in that region.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[**可导航的小世界**](https://en.wikipedia.org/wiki/Small-world_network) 是一个具有多对数 *T
    = O(logᵏn)* 搜索复杂度的图，它使用贪心路由。**路由** 指的是从低度顶点开始搜索过程，并以高维度顶点结束。由于低度顶点的连接非常少，算法可以在它们之间迅速移动，从而高效地导航到可能存在最近邻的区域。然后，算法逐渐放大并切换到高维度顶点，以在该区域的顶点中找到最近邻。'
- en: Vertex is sometimes also referred to as a **node**.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 顶点有时也被称为**节点**。
- en: Search
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索
- en: In the first place, search is proceeded by choosing an entry point. To determine
    the next vertex (or vertices) to which the algorithm makes a move, it calculates
    the distances from the query vector to the current vertex’s neighbours and moves
    to the closest one. At some point, the algorithm terminates the search procedure
    when it cannot find a neighbour node that is closer to the query than the current
    node itself. This node is returned as the response to the query.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过选择一个入口点进行搜索。为了确定算法下一步移动的顶点（或顶点），它计算查询向量到当前顶点邻居的距离，并移动到最近的一个。某些时候，当算法找不到比当前节点更靠近查询的邻居节点时，它会终止搜索过程。这个节点被返回作为查询的响应。
- en: '![](../Images/a4eb5d43f3a843ea5c4d77ac2b3b8846.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4eb5d43f3a843ea5c4d77ac2b3b8846.png)'
- en: Greedy search process in a navigable small world. Node A is used as an entry
    point. It has two neighbours B and D. Node D is closer to the query than B. As
    a result, we move to D. Node D has three neighbours C, E and F. E is the closest
    neighbour to the query, so we move to E. Finally, the search process will lead
    to node L. Since all neighbours of L are located further from the query than L
    itself, we stop the algorithm and return L as the answer to the query.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 可导航的小世界中的贪心搜索过程。节点 A 被用作入口点。它有两个邻居 B 和 D。节点 D 比 B 更接近查询。因此，我们移动到 D。节点 D 有三个邻居
    C、E 和 F。E 是距离查询最近的邻居，所以我们移动到 E。最终，搜索过程将导致节点 L。由于 L 的所有邻居都比 L 本身离查询更远，我们停止算法，并将
    L 作为查询的答案返回。
- en: This greedy strategy does not guarantee that it will find the exact nearest
    neighbour as the method uses only local information at the current step to take
    decisions. **Early stopping** is one of the problems of the algorithm. It occurs
    especially at the beginning of the search procedure when there are no better neighbour
    nodes than the current one. For the most part, this might happen when the starting
    region has too many low-degree vertices.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种贪心策略不能保证找到确切的最近邻，因为该方法仅使用当前步骤的局部信息来做出决策。**早期停止** 是该算法的问题之一。特别是在搜索过程的开始阶段，当没有比当前节点更好的邻居节点时，早期停止现象尤为明显。在大多数情况下，这可能发生在起始区域有太多低度顶点时。
- en: '![](../Images/0f13febee8fe41bde554255204c8a1dc.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f13febee8fe41bde554255204c8a1dc.png)'
- en: Early stopping. Both neighbours of the current node are further away from the
    query. Thus, the algorithm returns the current node as the response, though there
    exist much closer nodes to the query.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 早期停止。当前节点的两个邻居都比查询更远。因此，算法返回当前节点作为响应，尽管存在距离查询更近的节点。
- en: The search accuracy can be improved by using several entry points.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用多个入口点来提高搜索精度。
- en: Construction
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建
- en: The NSW graph is built by shuffling dataset points and inserting them one by
    one in the current graph. When a new node is inserted, it is then linked by edges
    to the *M* nearest vertices to it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: NSW 图是通过打乱数据集点并逐个将它们插入当前图中来构建的。当插入一个新节点时，它会通过边连接到其*M*个最近的顶点。
- en: '![](../Images/1b03640a542eb8fadb8ccfb27ff34f1c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b03640a542eb8fadb8ccfb27ff34f1c.png)'
- en: Sequential insertion of nodes (from left to right) with M = 2\. At each iteration,
    a new vertex is added to the graph and linked to its M = 2 nearest neighbours.
    Blue lines represent the connected edges to a newly inserted node.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 节点的顺序插入（从左到右），M = 2。在每次迭代中，向图中添加一个新顶点，并将其链接到其 M = 2 个最近邻居。蓝线表示连接到新插入节点的边。
- en: In most scenarios, long-range edges will likely be created at the beginning
    phase of the graph construction. They play an important role in graph navigation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，长距离边缘可能会在图构建的初始阶段创建。它们在图导航中扮演着重要角色。
- en: Links to the closest neighbors of the elements inserted in the beginning of
    the construction later become bridges between the network hubs that keep the overall
    graph connectivity and allow the logarithmic scaling of the number of hops during
    greedy routing. — Yu. A. Malkov, D. A. Yashunin
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在构建开始时插入的元素的最近邻链接随后变成了网络中心之间的桥梁，这些桥梁保持了整个图的连通性，并允许在贪婪路由过程中对跳数进行对数缩放。 — Yu. A.
    Malkov, D. A. Yashunin
- en: From the example in the figure above, we can see the importance of the long-range
    edge *AB* that was added in the beginning. Imagine a query requiring the traverse
    of a path from the relatively far-located nodes *A* and I. Having the edge *AB*
    allows doing it rapidly by directly navigating from one side of the graph to the
    opposite one.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从上图中的示例可以看出，在开始时添加的长距离边缘*AB*的重要性。设想一个查询需要遍历从相对远离的节点*A*到*I*的路径。拥有边缘*AB*允许通过直接从图的一侧导航到另一侧来快速完成这个过程。
- en: As the number of vertices in the graph increases, it increases the probability
    that the lengths of newly connected edges to a new node will be smaller.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 随着图中顶点数量的增加，新连接到新节点的边的长度变短的概率也增加。
- en: HNSW
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HNSW
- en: '[**HNSW**](https://arxiv.org/pdf/1603.09320.pdf) is based on the same principles
    as skip list and navigable small world. Its structure represents a multi-layered
    graph with fewer connections on the top layers and more dense regions on the bottom
    layers.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[**HNSW**](https://arxiv.org/pdf/1603.09320.pdf) 基于与跳表和可导航小世界相同的原理。它的结构表现为一个多层次的图，其中顶部层次的连接较少，而底部层次的区域则更为密集。'
- en: Search
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索
- en: The search starts from the highest layer and proceeds to one level below every
    time the local nearest neighbour is greedily found among the layer nodes. Ultimately,
    the found nearest neighbour on the lowest layer is the answer to the query.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索从最高层开始，每次在层节点中贪婪地找到局部最近邻，然后逐层向下。最终，找到的最低层上的最近邻即为查询的答案。
- en: '![](../Images/5a334283e8e94afb5a71acfb241e76ca.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a334283e8e94afb5a71acfb241e76ca.png)'
- en: Search in HNSW
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: HNSW中的搜索
- en: Similarly to NSW, the search quality of HNSW can be improved by using several
    entry points. Instead of finding only one nearest neighbour on each layer, the
    *efSearch* (a hyperparameter)closest nearest neighbours to the query vector are
    found and each of these neighbours is used as the entry point on the next layer.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于NSW，通过使用多个入口点可以提高HNSW的搜索质量。与其在每层上仅找到一个最近邻，不如使用*efSearch*（一个超参数）找到与查询向量最接近的最近邻，并将每个邻居作为下一层的入口点。
- en: Complexity
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复杂度
- en: The authors of the [original paper](https://arxiv.org/pdf/1603.09320.pdf) claim
    that the number of operations required to find the nearest neighbour on any layer
    is bounded by a constant. Taking into consideration that the number of all layers
    in a graph is logarithmic, we get the total search complexity which is *O(logn)*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始论文](https://arxiv.org/pdf/1603.09320.pdf)的作者声称，在任何层上查找最近邻所需的操作数都由一个常数限制。考虑到图中的所有层数是对数级的，我们得到了总的搜索复杂度，即*O(logn)*。'
- en: Construction
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建
- en: Choosing the maximum layer
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择最大层
- en: Nodes in HNSW are inserted sequentially one by one. Every node is randomly assigned
    an integer *l* indicating the maximum layer at which this node can present in
    the graph. For example, if *l = 1*, then the node can only be found on layers
    0 and 1\. The authors select *l* randomly for each node with an *exponentially
    decaying probability distribution* normalized by the non-zero multiplier *mL (mL
    = 0* results in a single layer in HNSW and non-optimized search complexity*)*.
    Normally, the majority of *l* values should be equal to 0, so most of the nodes
    are present only on the lowest level. The larger values of *mL* increase the probability
    of a node appearing on higher layers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 节点在HNSW中是一个接一个地顺序插入的。每个节点会随机分配一个整数*l*，表示该节点可以出现在图中的最大层。例如，如果*l = 1*，则该节点只能在第0层和第1层找到。作者为每个节点随机选择*l*，其*指数衰减概率分布*由非零乘数*mL（mL
    = 0* 结果是HNSW中的单层和非优化的搜索复杂度）*进行归一化*。通常，大多数*l*值应该等于0，因此大多数节点仅存在于最低层。较大的*mL*值增加了节点出现在更高层的概率。
- en: '![](../Images/a1bcb306f30647ddfd33ea0369dab2bd.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1bcb306f30647ddfd33ea0369dab2bd.png)'
- en: The number of layers l for every node is chosen randomly with *exponentially
    decaying probability distribution.*
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点的层数l是根据*指数衰减概率分布*随机选择的。
- en: '![](../Images/80559580b66a286c3abbfeaaf5127e17.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80559580b66a286c3abbfeaaf5127e17.png)'
- en: Distribution of the number of layers based on normalization factor mL. The horizontal
    axis represents values of the uniform(0, 1) distribution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基于标准化因子*mL*的层数分布。横轴表示均匀分布(0, 1)的值。
- en: To achieve the optimum performance advantage of the controllable hierarchy,
    the overlap between neighbors on different layers (i.e. percent of element neighbors
    that are also belong to other layers) has to be small. — Yu. A. Malkov, D. A.
    Yashunin.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了实现可控层次结构的最佳性能优势，不同层之间的邻居重叠（即也属于其他层的元素邻居的百分比）必须很小。 — Yu. A. Malkov, D. A. Yashunin。
- en: One of the ways to decrease the overlap is to decrease *mL*. But it is important
    to keep in mind that reducing *mL* also leads on average to more traversals during
    a greedy search on each layer. That is why it is essential to choose such a value
    of *mL* that will balance both the overlap and the number of traversals.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 减少重叠的一个方法是减小*mL*。但重要的是要记住，减少*mL*通常会导致在每层贪婪搜索过程中需要更多的遍历。因此，选择一个能够平衡重叠和遍历次数的*mL*值至关重要。
- en: The authors of the paper propose choosing the optimal value of *mL* which is
    equal to *1 / ln(M)*. This value corresponds to the parameter *p = 1 / M* of the
    skip list being an average single element overlap between the layers.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的作者建议选择*mL*的最佳值，即*1 / ln(M)*。该值对应于跳表的参数*p = 1 / M*，它是层间的平均单元素重叠。
- en: Insertion
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 插入
- en: 'After a node is assigned the value *l*, there are two phases of its insertion:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 节点被分配*l*值后，有两个插入阶段：
- en: The algorithm starts from the upper layer and greedily finds the nearest node.
    The found node is then used as an entry point to the next layer and the search
    process continues. Once the layer *l* is reached*,* the insertion proceeds to
    the second step.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法从上层开始，贪婪地找到最近的节点。找到的节点随后被用作下一层的入口点，搜索过程继续。一旦达到层*l*，插入过程就进入第二步。
- en: Starting from layer *l* the algorithm inserts the new node at the current layer.
    Then it acts the same as before at step 1 but instead of finding only one nearest
    neighbour, it greedily searches for *efConstruction* (hyperparameter) nearest
    neighbours. Then *M* out of *efConstruction* neighbours are chosen and edges from
    the inserted node to them are built. After that, the algorithm descends to the
    next layer and each of found *efConstruction* nodes acts as an entry point. The
    algorithm terminates after the new node and its edges are inserted on the lowest
    layer 0.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从层*l*开始，算法在当前层插入新节点。然后，它像之前一样执行第1步，但不是仅找到一个最近邻，而是贪婪地搜索*efConstruction*（超参数）个最近邻。然后从*efConstruction*个邻居中选择*M*个，并建立从插入节点到它们的边。之后，算法下降到下一层，每个找到的*efConstruction*节点作为入口点。算法在新节点及其边被插入到最低层0后终止。
- en: '![](../Images/9344c9f75ac1c76b943f2eb9edbe6d69.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9344c9f75ac1c76b943f2eb9edbe6d69.png)'
- en: Insertion of a node (in blue) in HNSW. The maximum layer for a new node was
    randomly chosen as l = 2\. Therefore, the node will be inserted on layers 2, 1
    and 0\. On each of these layers, the node will be connected to its M = 2 nearest
    neighbours.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在HNSW中插入一个节点（蓝色）。新节点的最大层随机选择为l = 2。因此，节点将被插入到层2、1和0。在每一层，节点将连接到其M = 2个最近邻。
- en: Choosing values for construction parameters
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择构造参数的值
- en: 'The original paper provides several useful insights on how to choose hyperparameters:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 原始论文提供了如何选择超参数的几个有用见解：
- en: According to simulations, good values for *M* lie between 5 and 48\. Smaller
    values of *M* tend to be better for lower recalls or low-dimensional data while
    higher values of M are suited better for high recalls or high-dimensional data.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据模拟，*M*的良好值在5到48之间。较小的*M*值适合较低的召回率或低维数据，而较大的M值则更适合较高的召回率或高维数据。
- en: Higher values of *efConstruction* imply a more profound search as more candidates
    are explored. However, it requires more computations. Authors recommend choosing
    such an *efConstruction* value that results at recall being close to *0.95–1*
    during training.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的*efConstruction*值意味着更深层次的搜索，因为会探索更多的候选项。然而，这也需要更多的计算。作者建议选择一个*efConstruction*值，以便在训练过程中回忆接近*0.95–1*。
- en: Additionally, there is another important parameter *Mₘₐₓ* — the maximum number
    of edges a vertex can have. Apart from it, there exists the same parameter *Mₘₐₓ₀*
    but separately for the lowest layer. It is recommended to choose a value for *Mₘₐₓ*
    close to *2 * M*. Values greater than *2 * M* can lead to performance degradation
    and excessive memory usage. At the same time, *Mₘₐₓ = M* results in poor performance
    at high recall.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另外，还有一个重要的参数 *Mₘₐₓ* — 一个顶点可以拥有的最大边数。除此之外，还存在一个相同的参数 *Mₘₐₓ₀*，但仅针对最低层。建议选择一个接近
    *2 * M* 的 *Mₘₐₓ* 值。大于 *2 * M* 的值可能会导致性能下降和过度的内存使用。同时，*Mₘₐₓ = M* 会导致高召回率下性能差。
- en: Candidate selection heuristic
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 候选选择启发式
- en: It was noted above that during node insertion, *M* out of *efConstruction* candidates
    are chosen to build edges to them. Let us discuss possible ways of choosing these
    *M* nodes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上面提到，在节点插入过程中，从 *efConstruction* 候选节点中选择 *M* 个来建立边。让我们讨论选择这些 *M* 个节点的可能方法。
- en: The naïve approach takes *M* closest candidates. Nevertheless, it is not always
    the optimal choice. Below is an example demonstrating it.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 天真的方法选取 *M* 个最近的候选节点。然而，这并不总是最优选择。下面是一个演示这个问题的例子。
- en: Imagine a graph with the structure in the figure below. As you can see, there
    are three regions with two of them not being connected to each other (on the left
    and on the top). As a result, getting, for example, from point *A* to *B* requires
    a long path through another region. It would be logical to somehow connect these
    two regions for better navigation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个如下面图所示的图结构。正如你所见，图中有三个区域，其中两个区域彼此没有连接（在左侧和顶部）。因此，例如，从点 *A* 到 *B* 需要通过另一个区域经过很长的路径。为了更好的导航，将这两个区域以某种方式连接起来是合乎逻辑的。
- en: '![](../Images/5d9fd78eec3c946eaa9179ffc20e6f7b.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d9fd78eec3c946eaa9179ffc20e6f7b.png)'
- en: Node X is inserted into the graph. The objective is to optimally connect it
    to other M = 2 points.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 节点 *X* 被插入到图中。目标是将其最优地连接到其他 *M* = 2 个点。
- en: Then a node *X* is inserted into the graph and needs to be linked to *M* *=
    2* othervertices.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后一个节点 *X* 被插入到图中，并且需要连接到 *M* *= 2* 个其他顶点。
- en: In this case, the naïve approach directly takes the *M = 2* nearest neighbours
    (*B* and *C*) and connects *X* to them. Though *X* is connected to its real nearest
    neighbours, it does not solve the problem. Let us look at the heuristical approach
    invented by the authors.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，天真的方法直接选择 *M = 2* 个最近的邻居（*B* 和 *C*），并将 *X* 连接到它们。尽管 *X* 已经连接到其真实的最近邻居，但这并没有解决问题。让我们来看一下作者们发明的启发式方法。
- en: The heuristic considers not only the closest distances between nodes but also
    the connectivity of different regions on the graph.
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 启发式算法不仅考虑节点之间的最近距离，还考虑图中不同区域的连通性。
- en: The heuristic chooses the first nearest neighbour (*B* in our case) and connects
    the inserted node (*X*) to it. Then the algorithm sequentially takes another most
    closest nearest neighbour in the sorted order (*C*) and builds an edge to it only
    if the distance from this neighbour to the new node (*X*) is smaller than any
    distance from this neighbour to all already connected vertices (*B*) to the new
    node (*X*). After that, the algorithm proceeds to the next closest neighbour until
    *M* edges are built.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 启发式算法选择第一个最近的邻居（在我们的例子中是 *B*）并将插入的节点 (*X*) 连接到它。然后算法按照排序的顺序逐个选择下一个最接近的邻居 (*C*)，并仅当该邻居到新节点
    (*X*) 的距离小于该邻居到所有已经连接的顶点 (*B*) 到新节点 (*X*) 的距离时，才建立一条边。之后，算法继续处理下一个最近的邻居，直到建立 *M*
    条边。
- en: Getting back to the example, the heuristical procedure is illustrated in the
    figure below. The heuristic chooses *B* as the closest nearest neighbour for X
    and builds the edge *BX*. Then the algorithm chooses *C* as the next closest nearest
    neighbour. However, this time *BC < CX*. This indicates that adding the edge *CX*
    to the graph is not optimal because there already exists the edge *BX* and the
    nodes *B* and *C* are very close to each other. The same analogy proceeds with
    the nodes *D* and *E*. After that, the algorithm examines the node *A*. This time,
    it satisfies the condition since *BA* *> AX*. As a result, the new edge *AX* and
    both initial regions become connected to each other.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 回到例子，启发式过程如下面的图所示。启发式算法选择 *B* 作为 *X* 的最近邻居，并建立了边 *BX*。然后算法选择 *C* 作为下一个最近邻居。然而，这次
    *BC < CX*。这表明将边 *CX* 添加到图中并不是最优的，因为已经存在边 *BX*，且节点 *B* 和 *C* 非常接近。相同的类比适用于节点 *D*
    和 *E*。之后，算法检查节点 *A*。这一次，它满足条件，因为 *BA* *> AX*。因此，新边 *AX* 和两个初始区域变得互相连接。
- en: '![](../Images/e6c85eede8fe13f3ede4e8fe2c082bed.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6c85eede8fe13f3ede4e8fe2c082bed.png)'
- en: The example on the left uses the naïve approach. The example on the right uses
    the selection heuristic which results in two initial disjoint regions being connected
    to each other.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的示例使用了简单的方法。右侧的示例使用了选择启发式，使两个初始不相交的区域相互连接。
- en: Complexity
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复杂度
- en: The insertion process works very similarly, compared to the search procedure,
    without any significant differences which could require a non-constant number
    of operations. Thus, the insertion of a single vertex imposes *O(logn)* of time.
    To estimate the total complexity, the number of all inserted nodes *n* in a given
    dataset should be considered. Ultimately, HNSW construction requires *O(n * logn)*
    time.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 插入过程与搜索过程非常相似，没有显著的差异需要非恒定数量的操作。因此，单个顶点的插入需要 *O(logn)* 的时间。要估计总复杂度，应该考虑给定数据集中的所有插入节点
    *n*。最终，HNSW 构建需要 *O(n * logn)* 时间。
- en: Combining HNSW with other methods
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 HNSW 与其他方法结合使用
- en: HNSW can be used together with other similarity search methods to provide better
    performance. One of the most popular ways to do it is to combine it with an inverted
    file index and product quantization (*IndexIVFPQ*) which were described in other
    parts of this article series.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: HNSW 可以与其他相似性搜索方法结合使用，以提供更好的性能。最常见的方法之一是将其与倒排文件索引和产品量化（*IndexIVFPQ*）结合使用，这在本系列文章的其他部分中已有描述。
- en: '[](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
    [## Similarity Search, Part 3: Blending Inverted File Index and Product Quantization'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
    [## 相似性搜索，第 3 部分：融合倒排文件索引和产品量化'
- en: 'In the first two parts of this series we have discussed two fundamental algorithms
    in information retrieval: inverted…'
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在本系列的前两部分中，我们讨论了信息检索中的两个基本算法：倒排……
- en: medium.com](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@slavahead/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa?source=post_page-----2aad4fe87d37--------------------------------)
- en: Within this paradigm, HNSW plays the role of a **coarse quantizer** for *IndexIVFPQ*
    meaning that it will be responsible for finding the nearest Voronoi partition,
    so the search scope can be reduced. To do it, an HNSW index has to be built on
    all Voronoi centroids. When given a query, HNSW is used to find the nearest Voronoi
    centroid (instead of brute-force search as it was previously by comparing distances
    to every centroid). After that, the query vector is quantized within a respective
    Voronoi partition and distances are calculated by using PQ codes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个范式中，HNSW 充当**粗量化器**的角色，负责找到最近的 Voronoi 划分，从而可以缩小搜索范围。为此，必须在所有 Voronoi 质心上构建
    HNSW 索引。给定查询时，使用 HNSW 找到最近的 Voronoi 质心（而不是之前通过比较每个质心的距离进行的暴力搜索）。之后，查询向量在相应的 Voronoi
    划分中被量化，并通过 PQ 代码计算距离。
- en: '![](../Images/e6c54daac1c43ee24feaa3ed5f5c0e5e.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6c54daac1c43ee24feaa3ed5f5c0e5e.png)'
- en: Choosing the nearest Voronoi centroid by finding the nearest neighbour in HNSW
    built on top of Voronoi centroids.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 Voronoi 质心上建立的 HNSW 中找到最近邻，选择最接近的 Voronoi 质心。
- en: When using only an inverted file index, it is better to set the number of Voronoi
    partitions not too large (256 or 1024, for instance) because brute-force search
    is performed to find the nearest centroids. By choosing a small number of Voronoi
    partitions, the number of candidates inside each partition becomes relatively
    large. Therefore, the algorithm rapidly identifies the nearest centroid for a
    query and most of its runtime is concentrated on finding the nearest neighbour
    inside a Voronoi partition.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当仅使用倒排文件索引时，最好将 Voronoi 划分的数量设置得不太大（例如 256 或 1024），因为会执行暴力搜索以找到最近的质心。通过选择较少的
    Voronoi 划分，划分内的候选项数量变得相对较大。因此，算法迅速识别查询的最近质心，并且大部分运行时间集中在 Voronoi 划分内找到最近邻上。
- en: 'However, introducing HNSW into the workflow requires an adjustment. Consider
    running HNSW only on a small number of centroids (256 or 1024): HNSW would not
    bring any significant benefits because, with a small number of vectors, HNSW performs
    relatively the same in terms of execution time as naïve brute-force search. Moreover,
    HNSW would require more memory to store the graph structure.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将HNSW引入工作流需要调整。考虑仅在少量质心（256或1024）上运行HNSW：由于质心数量较少，HNSW在执行时间上与简单的暴力搜索相对相同，因此不会带来显著的好处。此外，HNSW需要更多的内存来存储图结构。
- en: That is why when merging HNSW and inverted file index, it is recommended to
    set the number of Voronoi centroids much bigger than usual. By doing so, the number
    of candidates inside each Voronoi partition becomes much smaller.
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这就是为什么在合并HNSW和倒排文件索引时，建议将Voronoi质心的数量设置得比平时大得多。这样，每个Voronoi分区内的候选者数量会大大减少。
- en: 'This shift in paradigm results in the following settings:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这种范式的转变导致了以下设置：
- en: HNSW rapidly identifies the nearest Voronoi centroids in logarithmic time.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HNSW以对数时间快速识别最近的Voronoi质心。
- en: After that, an exhaustive search inside respective Voronoi partitions is performed.
    It should not be a trouble because the number of potential candidates is small.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 之后，执行各自Voronoi分区内的穷举搜索。因为潜在候选者的数量较少，所以不应成为问题。
- en: Faiss implementation
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Faiss实现
- en: '[**Faiss**](https://github.com/facebookresearch/faiss) (Facebook AI Search
    Similarity) is a Python library written in C++ used for optimised similarity search.
    This library presents different types of indexes which are data structures used
    to efficiently store the data and perform queries.'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[**Faiss**](https://github.com/facebookresearch/faiss)（Facebook AI 搜索相似性）是一个用C++编写的Python库，用于优化相似性搜索。该库提供了不同类型的索引，这些索引是用于高效存储数据和执行查询的数据结构。'
- en: Based on the information from the [Faiss documentation](https://faiss.ai), we
    will see how HNSW can be utilized and merged together with inverted file index
    and product quantization.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[Faiss文档](https://faiss.ai)的信息，我们将探讨如何将HNSW与倒排文件索引和乘积量化结合使用。
- en: IndexHNSWFlat
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IndexHNSWFlat
- en: 'FAISS has a class *IndexHNSWFlat* implementing the HNSW structure. As usual,
    the suffix “*Flat*” indicates that dataset vectors are fully stored in index.
    The constructor accepts 2 parameters:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: FAISS有一个类*IndexHNSWFlat*实现了HNSW结构。通常，“*Flat*”后缀表示数据集向量完全存储在索引中。构造函数接受2个参数：
- en: '**d**: data dimensionality.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**d**：数据维度。'
- en: '**M**: the number of edges that need to be added to every new node during insertion.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**M**：在插入过程中需要添加到每个新节点的边的数量。'
- en: 'Additionally, via thr **hnsw** field, *IndexHNSWFlat* provides several useful
    attributes (which can be modified) and methods:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过**hnsw**字段，*IndexHNSWFlat* 提供了几个有用的属性（可以修改）和方法：
- en: '**hnsw.efConstruction**: number of nearest neighbours to explore during construction.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**hnsw.efConstruction**：构造时要探索的最近邻数量。'
- en: '**hnsw.efSearch**: number of nearest neighbours to explore during search.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**hnsw.efSearch**：搜索时要探索的最近邻数量。'
- en: '**hnsw.max_level**: returns the maximum layer.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**hnsw.max_level**：返回最大层级。'
- en: '**hnsw.entry_point**: returns the entry point.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**hnsw.entry_point**：返回入口点。'
- en: '**faiss.vector_to_array(index.hnsw.levels)**: returns a list of maximum layers
    for each vector'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**faiss.vector_to_array(index.hnsw.levels)**：返回每个向量的最大层级列表。'
- en: '**hnsw.set_default_probas(M: int, level_mult: float)**: allows setting *M*
    and *mL* values respectively. By default, *level_mult* is set to *1 / ln(M)*.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**hnsw.set_default_probas(M: int, level_mult: float)**：允许分别设置*M*和*mL*值。默认情况下，*level_mult*
    设置为 *1 / ln(M)*。'
- en: '![](../Images/d8aa815a66893b9d4185852daa96c27b.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8aa815a66893b9d4185852daa96c27b.png)'
- en: Faiss implementation of IndexHNSWFlat
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Faiss实现的IndexHNSWFlat
- en: '*IndexHNSWFlat* sets values for *Mₘₐₓ = M* and *Mₘₐₓ₀ = 2 * M.*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*IndexHNSWFlat* 为*Mₘₐₓ = M* 和 *Mₘₐₓ₀ = 2 * M* 设置值。'
- en: IndexHNSWFlat + IndexIVFPQ
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IndexHNSWFlat + IndexIVFPQ
- en: '*IndexHNSWFlat* can be combined with other indexes as well. One of the examples
    is *IndexIVFPQ* described in the previous part. Creation of this composite index
    proceeds in two steps:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*IndexHNSWFlat* 也可以与其他索引结合使用。一个例子是前面部分描述的*IndexIVFPQ*。创建这个复合索引分两个步骤进行：'
- en: '*IndexHNSWFlat* is initialized as a coarse quantizer.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*IndexHNSWFlat* 被初始化为粗量化器。'
- en: The quantizer is passed as a parameter to the constructor of *IndexIVFPQ*.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 量化器作为参数传递给*IndexIVFPQ*的构造函数。
- en: Training and adding can be done by using different or the same data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和添加可以使用不同或相同的数据完成。
- en: '![](../Images/a2c65f1fd3db6f3c74764b883b6e46aa.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2c65f1fd3db6f3c74764b883b6e46aa.png)'
- en: FAISS implementation of IndexHNSWFlat + IndexIVFPQ
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: FAISS 实现的 IndexHNSWFlat + IndexIVFPQ
- en: Conclusion
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we have studied a robust algorithm which works especially well
    for large dataset vectors. By using multi-layer graph representations and the
    candidate selection heuristic its search speed scales efficiently while maintaining
    a decent prediction accuracy. It is also worth noting that HNSW can be used in
    combination with other similarity search algorithms making it very flexible.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们研究了一种强大的算法，该算法在处理大型数据集向量时表现尤为出色。通过使用多层图表示和候选选择启发式方法，其搜索速度在保持合理的预测准确性的同时得以高效扩展。值得注意的是，HNSW
    还可以与其他相似性搜索算法结合使用，使其非常灵活。
- en: Resources
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '[Six degrees of separation | Wikipedia](https://en.wikipedia.org/wiki/Six_degrees_of_separation)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[六度分隔理论 | 维基百科](https://en.wikipedia.org/wiki/Six_degrees_of_separation)'
- en: '[Skip List | Wikipedia](https://en.wikipedia.org/wiki/Skip_list)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[跳表 | 维基百科](https://en.wikipedia.org/wiki/Skip_list)'
- en: '[Efficient and robust approximate nearest neighbor search using Hierarchical
    Navigable Small World graphs. Yu. A. Malkov, D. A. Yashunin](https://arxiv.org/pdf/1603.09320.pdf)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用层次导航小世界图进行高效且强大的近似最近邻搜索。Yu. A. Malkov, D. A. Yashunin](https://arxiv.org/pdf/1603.09320.pdf)'
- en: '[Faiss documentation](https://faiss.ai)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Faiss 文档](https://faiss.ai)'
- en: '[Faiss repository](https://github.com/facebookresearch/faiss)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Faiss 仓库](https://github.com/facebookresearch/faiss)'
- en: '[Summary of Faiss indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Faiss 索引总结](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes)'
- en: '*All images unless otherwise noted are by the author.*'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，否则所有图像均由作者提供。*'
