- en: 6 Types of Clustering Methods — An Overview
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 种聚类方法 — 概述
- en: 原文：[https://towardsdatascience.com/6-types-of-clustering-methods-an-overview-7522dba026ca](https://towardsdatascience.com/6-types-of-clustering-methods-an-overview-7522dba026ca)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/6-types-of-clustering-methods-an-overview-7522dba026ca](https://towardsdatascience.com/6-types-of-clustering-methods-an-overview-7522dba026ca)
- en: Types of clustering methods and algorithms and when to use them
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚类方法和算法的类型以及何时使用它们
- en: '[](https://kayjanwong.medium.com/?source=post_page-----7522dba026ca--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page-----7522dba026ca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7522dba026ca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7522dba026ca--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page-----7522dba026ca--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kayjanwong.medium.com/?source=post_page-----7522dba026ca--------------------------------)[![Kay
    Jan Wong](../Images/28e803eca6327d97b6aa97ee4095d7bd.png)](https://kayjanwong.medium.com/?source=post_page-----7522dba026ca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7522dba026ca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7522dba026ca--------------------------------)
    [Kay Jan Wong](https://kayjanwong.medium.com/?source=post_page-----7522dba026ca--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7522dba026ca--------------------------------)
    ·8 min read·Mar 24, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7522dba026ca--------------------------------)
    ·8 分钟阅读·2023年3月24日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/78a95243080c867f084198a587c15efc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/78a95243080c867f084198a587c15efc.png)'
- en: Photo by [Kier in Sight](https://unsplash.com/@kierinsight?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Kier in Sight](https://unsplash.com/@kierinsight?utm_source=medium&utm_medium=referral)
    拍摄的照片，发布于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Clustering is one of the branches of Unsupervised Learning where **unlabelled
    data** is divided into groups with similar data instances assigned to the same
    cluster while dissimilar data instances are assigned to different clusters. Clustering
    has various uses in market segmentation, outlier detection, and network analysis,
    to name a few.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类是无监督学习的一个分支，其中**未标记的数据**被划分为不同的组，相似的数据实例被分配到同一聚类，而不相似的数据实例则被分配到不同的聚类。聚类在市场细分、异常检测和网络分析等领域有广泛的应用。
- en: There are different types of clustering methods, each with its advantages and
    disadvantages. This article introduces the different types of clustering methods
    with algorithm examples, and when to use each algorithm.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的聚类方法各有其优缺点。本文介绍了不同类型的聚类方法及算法示例，以及何时使用每种算法。
- en: Table of Contents
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: Centroid-based / Partitioning (*K-means*)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于质心/划分 (*K-means*)
- en: Connectivity-based (*Hierarchical Clustering*)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于连通性的 (*层次聚类*)
- en: Density-based (*DBSCAN*)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于密度的 (*DBSCAN*)
- en: Graph-based (*Affinity Propagation*)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图基的 (*亲和传播*)
- en: Distribution-based (*Gaussian Mixture Model*)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于分布的 (*高斯混合模型*)
- en: Compression-based (*Spectral Clustering, BIRCH*)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于压缩的 (*谱聚类, BIRCH*)
- en: Centroid-based / Partitioning
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于质心/划分
- en: Centroid-based methods group data points together based on the proximity of
    data points to the centroid (cluster center)
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于质心的方法通过数据点到质心（聚类中心）的接近程度来将数据点分组
- en: '![](../Images/c8c964bd30a5eddbc2e8dd1378b8b3dd.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8c964bd30a5eddbc2e8dd1378b8b3dd.png)'
- en: 'Fig 1: Example of clustering output for centroid-based method (K-means) — Image
    from [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：基于质心的方法（K-means）的聚类输出示例 — 图片来自 [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html)
- en: The proximity between data points to the centroid is measured by
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点到质心的接近程度通过以下方式测量
- en: '**Euclidean distance**: Shortest (straight-line) distance, useful for numerical
    features, this is the default distance measure'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欧几里得距离**：最短（直线）距离，适用于数值特征，这是默认的距离度量'
- en: '**Manhattan distance**: Sum of absolute differences, useful for categorical
    features'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**曼哈顿距离**：绝对差异的总和，适用于分类特征'
- en: '**Hamming distance**: Percentage of bits that differ, useful for binary features'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**汉明距离**：不同位数的百分比，适用于二进制特征'
- en: '**Mahalanobis distance**: Standardised form of Euclidean distance'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**马哈拉诺比斯距离**：欧几里得距离的标准化形式'
- en: '**Minkowski distance**: Generalized form of Euclidean and Manhattan distance'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**闵可夫斯基距离**：欧几里得距离和曼哈顿距离的广义形式'
- en: '**Chebyshev distance**: Maximum absolute difference'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**切比雪夫距离**：最大绝对差异'
- en: Regardless of which distance measure, numerical features should always be standardized
    when performing clustering!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用哪种距离度量，执行聚类时数值特征都应始终标准化！
- en: K-means
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K-means
- en: K-means involves initialization and performing iterative Expectation Maximization
    (EM) steps until convergence or when maximum iteration is reached.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 涉及初始化并执行迭代期望最大化（EM）步骤，直到收敛或达到最大迭代次数。
- en: During initialization, `k` number of centroids are assigned based on the `k-means++`
    optimization algorithm. In the Expectation (E) step, data points are assigned
    to clusters following their closest (by Euclidean distance) centroid. In the Maximization
    (M) step, centroids are updated to minimize the inertia or within-cluster sum-of-squares
    (WCSS). EM steps are repeated until convergence to local minima where the cluster
    assignment and centroids do not change.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化期间，`k` 个质心是根据 `k-means++` 优化算法分配的。在期望（E）步骤中，数据点根据其最近的（欧几里得距离）质心分配到聚类中。在最大化（M）步骤中，质心被更新以最小化惯性或聚类内平方和（WCSS）。EM
    步骤重复进行，直到收敛到局部最小值，聚类分配和质心不再变化。
- en: When to use K-means
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用 K-means
- en: 'You want **interpretability**: K-means is easy to understand and interpret.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你希望**可解释性**：K-means 易于理解和解释。
- en: 'Clusters are **even-sized and globular-shaped**: K-means work well when clusters
    are well-separated globular shapes but do not perform well if clusters are long
    and irregularly shaped.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类是**均匀大小和球形**的：K-means 在聚类是良好分离的球形时表现良好，但如果聚类是长而不规则的形状，它的表现则不佳。
- en: When to NOT use K-means
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时不要使用 K-means
- en: 'You are **unsure about the number of clusters**: K-means require the number
    of clusters to be predefined. Usually, the Elbow method, which plots WCSS against
    the number of clusters, is used to determine the optimal number of clusters.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你**不确定聚类的数量**：K-means 需要预定义聚类的数量。通常使用肘部法，绘制 WCSS 与聚类数量的关系图，以确定最优的聚类数量。
- en: 'You have **outliers in the data**: All data points are assigned to a cluster,
    hence the presence of outliers can skew the results and have to be removed or
    transformed.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的数据中有**离群点**：所有数据点都被分配到一个聚类中，因此离群点的存在可能会扭曲结果，必须去除或转换。
- en: 'You want **computation efficiency**: The computation cost of K-means increases
    with the size of data as it runs in `O(tkn)` time where `t` is the number of iterations,
    `k` is the number of clusters, and `n` is the number of data points. Using dimensionality
    reduction algorithms such as PCA can speed up computation.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你希望**计算效率**：K-means 的计算成本随数据规模增加而增加，因为它的运行时间是 `O(tkn)`，其中 `t` 是迭代次数，`k` 是聚类数量，`n`
    是数据点数量。使用降维算法如 PCA 可以加速计算。
- en: '**Other centroid-based algorithms**: K-Medoids, Mean Shift, Fuzzy Clustering
    (soft K-means; data points can be part of multiple clusters)'
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**其他基于质心的算法**：K-Medoids、均值漂移、模糊聚类（软K-means；数据点可以属于多个聚类）'
- en: ''
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Edit**: There are also Variance-Ratio Criterion (VRC) and Bayesian Information
    Criterion (BIC) as more robust alternatives to the Elbow method (Credits to Victor
    for this information — link to [paper](https://ar5iv.labs.arxiv.org/html/2212.12189)).'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**编辑**：还有方差比准则（VRC）和贝叶斯信息准则（BIC）作为比肘部法更鲁棒的替代方法（感谢 Victor 提供的信息 — 论文链接到 [paper](https://ar5iv.labs.arxiv.org/html/2212.12189)）。'
- en: Connectivity-based
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于连通性
- en: Connectivity-based methods group data points together based on the proximity
    between the clusters
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于连通性的方法根据聚类之间的接近度将数据点分组在一起
- en: '![](../Images/8b314755a33b723683abaf21331467f4.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b314755a33b723683abaf21331467f4.png)'
- en: 'Fig 2: Example of clustering output for connectivity-based method (Hierarchical
    Clustering) — Image from [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基于连通性的方法（层次聚类）的聚类输出示例 — 图片来自 [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html)
- en: The linkage criterion calculates the proximity between clusters,
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 连结标准计算聚类之间的接近度，
- en: '**Single linkage**: Distance between closest points of clusters; minimum distance
    between clusters. Good for detecting arbitrarily shaped clusters but cannot detect
    overlapping clusters. It is efficient to compute but is not robust to noisy data'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单一连结**：聚类间最接近点的距离；聚类间的最小距离。适用于检测任意形状的聚类，但无法检测重叠的聚类。计算效率高，但对噪声数据不够鲁棒。'
- en: '**Complete / Maximum linkage**: Distance between furthest points of clusters;
    maximum distance between clusters. Good for detecting overlapping clusters but
    cannot detect arbitrarily shaped clusters'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全/最大连结**：聚类间最远点之间的距离；聚类间的最大距离。适用于检测重叠聚类，但无法检测任意形状的聚类'
- en: '**Average linkage**: Average of all distances across two clusters'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平均连结**：两个聚类间所有距离的平均值'
- en: '**Centroid linkage**: Distance between centers of two clusters'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**质心连结**：两个聚类中心之间的距离'
- en: '**Ward linkage**: Sum of squared distance from each data point to the centroid
    of the cluster they are assigned to. This results in cluster merging that gives
    the smallest increase in total variance within all clusters. Ward linkage is the
    default linkage criterion'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ward连结**：每个数据点到其分配聚类的质心的平方距离总和。这导致合并聚类时，所有聚类内总方差增加最小。Ward连结是默认的连结标准'
- en: Hierarchical Clustering
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 层次聚类
- en: Agglomerative hierarchical clustering works by doing an iterative **bottom-up
    approach** where each data point is considered as an individual cluster and the
    two closest (by linkage criteria) clusters get iteratively merged until one large
    cluster is left.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 凝聚层次聚类通过进行迭代的**自下而上方法**工作，其中每个数据点被视为一个单独的聚类，并且两个最接近（按连接标准）的聚类被迭代合并，直到只剩下一个大聚类。
- en: Divisive hierarchical clustering does the opposite and performs an iterative
    **top-down approach** where it starts from one large cluster and continuously
    breaks down into two smaller clusters until every data point is an individual
    cluster.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 分裂层次聚类的做法正好相反，执行迭代的**自上而下方法**，从一个大聚类开始，不断分解为两个较小的聚类，直到每个数据点成为一个单独的聚类。
- en: When to use Hierarchical Clustering
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用层次聚类
- en: 'You are **unsure about the number of clusters**: Hierarchical clustering requires
    the number of clusters to be predefined, but the clusters can be viewed on a dendrogram
    and the number of clusters can be tweaked without recomputation.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你对**聚类数量不确定**：层次聚类需要预定义聚类数量，但可以在树状图上查看聚类，并且可以在不重新计算的情况下调整聚类数量。
- en: 'You want **computation efficiency**: Cluster labels at any intermediate stage
    can be recovered, therefore it is not necessary to recompute the proximity matrix
    if the number of clusters changes.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要**计算效率**：在任何中间阶段的聚类标签可以被恢复，因此如果聚类数量改变，则不必重新计算相似度矩阵。
- en: 'You have **high dimensional data**: Output can be visualized using a dendrogram
    which can be used with higher dimensional data.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你有**高维数据**：输出可以通过树状图进行可视化，这可以用于更高维的数据。
- en: Density-based
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于密度
- en: Density-based methods group data points together based on density instead of
    distance
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于密度的方法根据密度而不是距离将数据点分组
- en: '![](../Images/eb1555c77c6d282903a4bb6da175c1fe.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb1555c77c6d282903a4bb6da175c1fe.png)'
- en: 'Fig 3: Example of clustering output for density-based method (DBSCAN) — Image
    from [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：基于密度的方法（DBSCAN）的聚类输出示例 — 图片来自 [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)
- en: Density-Based Spatial Clustering of Applications with Noise (DBSCAN)
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于密度的空间聚类应用于噪声（DBSCAN）
- en: DBSCAN algorithm clusters data points that are in dense regions together, separated
    by areas of low density. Samples in denser areas within `eps` units apart with
    more than `min_samples` number of data points are called **core samples**.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: DBSCAN算法将密集区域中的数据点聚集在一起，用低密度区域分隔开。位于`eps`单位内且有超过`min_samples`数量的数据点的样本称为**核心样本**。
- en: When to use DBSCAN
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用DBSCAN
- en: 'You are **unsure about the number of clusters**: DBSCAN does not require the
    number of clusters to be predefined.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你对**聚类数量不确定**：DBSCAN不需要预定义聚类数量。
- en: 'You want **arbitrarily-shaped clusters**: Clusters are determined by dense
    regions, hence cluster shapes can be odd-shaped or complex.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要**任意形状的聚类**：聚类由密集区域决定，因此聚类形状可以是奇怪或复杂的。
- en: 'You want to **detect outliers**: Data points that are not assigned to any cluster
    as they do not fall in any dense region will be considered outliers.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要**检测离群点**：那些未被分配到任何聚类的数据点，因为它们不落在任何密集区域，将被视为离群点。
- en: When to NOT use DBSCAN
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时不使用DBSCAN
- en: 'When you want **stable performance**: DBSCAN output is highly influenced and
    sensitive to the `eps` parameter, which must be chosen appropriately for the data
    set.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你想要**稳定的性能**：DBSCAN的输出受到`eps`参数的高度影响和敏感，必须为数据集选择适当的`eps`值。
- en: '**Other density-based algorithms**: Ordering Points To Identify the Clustering
    Structure (OPTICS), Hierarchical DBSCAN (HDBSCAN)'
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**其他基于密度的算法**：排序点以识别聚类结构（OPTICS）、层次DBSCAN（HDBSCAN）'
- en: Graph-based
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于图
- en: Graph-based methods group data points together based on graph distance
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于图的方法根据图距离将数据点分组。
- en: '![](../Images/b08720086f04f4f4676ce89fc418e3c2.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b08720086f04f4f4676ce89fc418e3c2.png)'
- en: 'Fig 4: Example of clustering output for graph-based method (Affinity Propagation)
    — Image from [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_affinity_propagation.html)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：基于图的方法（亲和传播）的聚类输出示例 — 图片来自 [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_affinity_propagation.html)
- en: Affinity Propagation
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亲和传播
- en: Affinity propagation works by pair-wise sending of messages between data points
    until convergence. Exemplars, which are points that best represent the surrounding
    data points, are chosen and each point is assigned a cluster of its nearest exemplar.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 亲和传播通过数据点之间的成对消息传递直到收敛。选择代表周围数据点的最佳点作为样本点，并将每个点分配到其最近样本点的簇中。
- en: When to use Affinity Propagation
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用亲和传播
- en: 'You are **unsure about the number of clusters**: Affinity Propagation does
    not require the number of clusters to be predefined.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你**不确定簇的数量**：亲和传播不要求预定义簇的数量。
- en: '**When to NOT use Affinity Propagation**'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**何时不使用亲和传播**'
- en: 'You want **computation efficiency**: Affinity propagation runs in `O(tn²)`
    time complexity where `t` is the number of iterations and `n` is the number of
    data points, as messages are sent pair-wise between every data point.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要**计算效率**：亲和传播的时间复杂度为`O(tn²)`，其中`t`是迭代次数，`n`是数据点数量，因为消息在每个数据点之间成对发送。
- en: 'You want **space efficiency**: If a dense similarity matrix is used, affinity
    propagation takes up `O(n²)` memory as messages sent between every data point
    are considered a ‘vote’ cast to elect the exemplar.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要**空间效率**：如果使用密集相似度矩阵，亲和传播会占用`O(n²)`的内存，因为在每个数据点之间发送的消息被视为‘投票’，以选举样本点。
- en: Distribution-based
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于分布
- en: Distribution-based methods group data points together based on their likelihood
    of belonging to the same probability distribution
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于分布的方法根据数据点属于同一概率分布的可能性将数据点分组。
- en: '![](../Images/f2001805fbeef5503b21d7baae18ca9a.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2001805fbeef5503b21d7baae18ca9a.png)'
- en: 'Fig 5: Example of clustering output for distribution-based method (GMM) — Image
    from [sklearn](https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：基于分布的方法（GMM）的聚类输出示例 — 图片来自 [sklearn](https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html)
- en: Distribution-based methods use statistical inference to cluster data such that
    the closer the data point is to a central point, the higher the probability to
    be assigned to that cluster.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 基于分布的方法使用统计推断来对数据进行聚类，使得数据点距离中心点越近，被分配到该簇的概率越高。
- en: Compared to clustering methods that consider distance measures, distribution-based
    methods are more flexible in determining the shape of clusters, provided that
    the clusters follow a predefined distribution such as with synthetic or simulated
    data. If clusters are noisy, the results will overfit.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 与考虑距离度量的聚类方法相比，基于分布的方法在确定簇的形状方面更具灵活性，前提是簇遵循预定义的分布，如合成数据或模拟数据。如果簇是噪声的，结果会过拟合。
- en: Gaussian Mixture Model (GMM)
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高斯混合模型（GMM）
- en: GMM assumes that every data point is generated from multiple Gaussian distributions
    with unknown parameters and performs iterative Expectation Maximization (EM) steps
    to fit the data points.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: GMM 假设每个数据点都是由多个具有未知参数的高斯分布生成的，并通过迭代的期望最大化（EM）步骤来拟合数据点。
- en: In the Expectation (E) step, data points are assigned to clusters that assume
    randomly selected Gaussian parameters. In the Maximization (M) step, the parameters
    of the Gaussian distribution are updated to best fit the data points in the cluster.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在期望（E）步骤中，数据点被分配到假设随机选择的高斯参数的簇中。在最大化（M）步骤中，高斯分布的参数被更新，以最佳地拟合簇中的数据点。
- en: When to use Gaussian Mixture Model
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用高斯混合模型
- en: 'You want **computation efficiency**: GMM is the fastest distribution-based
    algorithm.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要**计算效率**：GMM 是最快的基于分布的算法。
- en: 'Your clusters follow a **Gaussian distribution**: Distribution can be tweaked
    to fit spherical, diagonal, tied, or full covariance matrices.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的簇遵循**高斯分布**：分布可以调整以适应球形、对角线、绑定或完全协方差矩阵。
- en: When to NOT use Gaussian Mixture Model
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时不使用高斯混合模型
- en: 'You have **insufficient data in each cluster**: It is hard to compute the covariance
    matrices when there are insufficient data points in a Gaussian distribution.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你有**每个簇的数据不足**：当高斯分布中的数据点不足时，计算协方差矩阵会很困难。
- en: Compression-based
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于压缩的
- en: Compression-based methods transform data points to an embedding and subsequently
    perform clustering on the lower-dimension data
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基于压缩的方法将数据点转换为嵌入，然后在低维数据上执行聚类。
- en: Spectral Clustering
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谱聚类
- en: Spectral clustering transforms the affinity matrix between data points to a
    low-dimension embedding before performing clustering (such as K-means).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 谱聚类将数据点之间的亲和矩阵转换为低维嵌入，然后再进行聚类（如K均值）。
- en: When to use Spectral Clustering
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用谱聚类
- en: 'You want **computation efficiency**: Spectral clustering is fast if the affinity
    matrix is sparse and if the `pyamg` solver is used.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你希望**计算效率**：如果亲和矩阵稀疏且使用`pyamg`求解器，谱聚类速度很快。
- en: When to NOT use Spectral Clustering
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时不使用谱聚类
- en: 'You are **unsure about the number of clusters**: Spectral Clustering requires
    the number of clusters to be predefined and the number of clusters should be ideally
    small.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你**不确定簇的数量**：谱聚类需要预定义簇的数量，并且簇的数量应该尽可能小。
- en: BIRCH
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: BIRCH
- en: BIRCH performs lossy compression of data points to a set of Clustering Features
    nodes (CF Nodes) that forms the Clustering Feature Tree (CFT). New data points
    are ‘shuffled’ into the tree until it reaches a leaf and store information regarding
    the subcluster within the node.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: BIRCH对数据点进行有损压缩，生成一组聚类特征节点（CF Nodes），形成聚类特征树（CFT）。新数据点被‘插入’到树中，直到到达叶子节点，并在节点内存储有关子簇的信息。
- en: Information regarding the final cluster centroids is read off the leaf and other
    clustering algorithms (such as hierarchical clustering) can be subsequently performed.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最终簇质心的信息从叶子节点读取，其他聚类算法（如层次聚类）可以随之执行。
- en: When to NOT use BIRCH
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时不使用BIRCH
- en: 'You have **high dimensional data**: BIRCH does not scale well to high dimensional
    data'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你有**高维数据**：BIRCH对高维数据的扩展性较差。
- en: It is interesting how the end goal of obtaining clusters can be obtained with
    vastly different approaches and algorithms. This article does not aim to cover
    all the possible clustering algorithms or go in-depth into the mathematical formulas
    involved in each algorithm, but I hope it does provide some high-level detail
    on the types of clustering methods and when to use different algorithms.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，通过完全不同的方法和算法可以实现获取簇的最终目标。本文并不旨在覆盖所有可能的聚类算法或深入探讨每种算法中的数学公式，但希望能提供一些关于聚类方法类型及其应用场景的高层次细节。
- en: Related Stories
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关故事
- en: Another aspect of clustering is to evaluate the clustering algorithms to determine
    which performs the *best* using statistical measures.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类的另一个方面是评估聚类算法，以确定哪个算法在统计度量上表现*最佳*。
- en: '[](/7-evaluation-metrics-for-clustering-algorithms-bdc537ff54d2?source=post_page-----7522dba026ca--------------------------------)
    [## 7 Evaluation Metrics for Clustering Algorithms'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/7-evaluation-metrics-for-clustering-algorithms-bdc537ff54d2?source=post_page-----7522dba026ca--------------------------------)
    [## 7 聚类算法评估指标'
- en: In-depth explanation with Python examples of unsupervised learning evaluation
    metrics
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Python示例深入解释无监督学习评估指标
- en: towardsdatascience.com](/7-evaluation-metrics-for-clustering-algorithms-bdc537ff54d2?source=post_page-----7522dba026ca--------------------------------)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/7-evaluation-metrics-for-clustering-algorithms-bdc537ff54d2?source=post_page-----7522dba026ca--------------------------------)
- en: Related Links
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关链接
- en: '`sklearn` Clustering Documentation: [https://scikit-learn.org/stable/modules/clustering.html](https://scikit-learn.org/stable/modules/clustering.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sklearn` 聚类文档：[https://scikit-learn.org/stable/modules/clustering.html](https://scikit-learn.org/stable/modules/clustering.html)'
