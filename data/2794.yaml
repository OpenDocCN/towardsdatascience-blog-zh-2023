- en: Effective Load Balancing with Ray on Amazon SageMaker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Ray 在 Amazon SageMaker 上实现有效负载均衡
- en: 原文：[https://towardsdatascience.com/effective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3?source=collection_archive---------8-----------------------#2023-09-04](https://towardsdatascience.com/effective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3?source=collection_archive---------8-----------------------#2023-09-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/effective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3?source=collection_archive---------8-----------------------#2023-09-04](https://towardsdatascience.com/effective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3?source=collection_archive---------8-----------------------#2023-09-04)
- en: A method for increasing DNN training efficiency and reducing training costs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种提高 DNN 训练效率和降低训练成本的方法
- en: '[](https://chaimrand.medium.com/?source=post_page-----d3b9020679d3--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----d3b9020679d3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d3b9020679d3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d3b9020679d3--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----d3b9020679d3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://chaimrand.medium.com/?source=post_page-----d3b9020679d3--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----d3b9020679d3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d3b9020679d3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d3b9020679d3--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----d3b9020679d3--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----d3b9020679d3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d3b9020679d3--------------------------------)
    ·10 min read·Sep 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd3b9020679d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3&user=Chaim+Rand&userId=9440b37e27fe&source=-----d3b9020679d3---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----d3b9020679d3---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d3b9020679d3--------------------------------)
    ·10 分钟阅读·2023年9月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd3b9020679d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3&user=Chaim+Rand&userId=9440b37e27fe&source=-----d3b9020679d3---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd3b9020679d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3&source=-----d3b9020679d3---------------------bookmark_footer-----------)![](../Images/825ef1fcbc6836470358bbe0e79c0b7f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd3b9020679d3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Feffective-load-balancing-with-ray-on-amazon-sagemaker-d3b9020679d3&source=-----d3b9020679d3---------------------bookmark_footer-----------)![](../Images/825ef1fcbc6836470358bbe0e79c0b7f.png)'
- en: Photo by [Fineas Anton](https://unsplash.com/@fineas_anton?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Fineas Anton](https://unsplash.com/@fineas_anton?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供
- en: In previous posts (e.g., [here](/cloud-ml-performance-checklist-caa51e798002))
    we expanded on the importance of profiling and optimizing the performance of your
    DNN training workloads. Training deep learning models — especially large ones
    — can be an expensive undertaking. Your ability to **maximize the utilization
    of your training resources** in a manner that both accelerates your model convergence
    and minimizes training costs, can be a decisive factor in the success of your
    project. **Performance optimization** is an iterative process in which we identify
    and address the **performance bottlenecks** in our application, i.e., the portions
    in our application that are preventing us from increasing resource utilization
    and/or accelerating the run time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的文章中（例如，[这里](/cloud-ml-performance-checklist-caa51e798002)），我们扩展了对DNN训练工作负载性能分析和优化的重要性。训练深度学习模型——尤其是大型模型——可能是一项昂贵的工作。**最大化训练资源的利用率**，以加速模型收敛并最小化训练成本，是决定您项目成功的关键因素。**性能优化**是一个迭代过程，其中我们识别并解决应用程序中的**性能瓶颈**，即阻碍我们提高资源利用率和/或加速运行时间的部分。
- en: This post is the third in a series of posts that focus on one of the more common
    performance bottlenecks that we encounter when training deep learning models,
    the [**data pre-processing bottleneck**](/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851).
    A data pre-processing bottleneck occurs when our GPU (or alternative accelerator)
    — typically the *most expensive* resource in our training setup — finds itself
    idle while it waits for data input from *overly tasked* CPU resources.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文是关于训练深度学习模型时遇到的一个常见性能瓶颈系列文章中的第三篇，涉及到[**数据预处理瓶颈**](/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851)。数据预处理瓶颈发生在我们的GPU（或其他加速器）——通常是我们训练设置中*最昂贵*的资源——在等待来自*过度繁忙*的CPU资源的数据输入时处于闲置状态。
- en: '![](../Images/b1cc394697bc34133fcceda418841e87.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1cc394697bc34133fcceda418841e87.png)'
- en: An image from the [TensorBoard profiler](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras)
    tab demonstrating a typical footprint of a bottleneck on the data input pipeline.
    We can clearly see long periods of GPU idle time on every seventh training step.
    (By Author)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[TensorBoard分析器](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras)标签页的一张图像，展示了数据输入管道中的瓶颈的典型特征。我们可以清楚地看到在每第七个训练步骤中都有长时间的GPU空闲时间。（作者提供）
- en: 'In our [first post](/overcoming-ml-data-preprocessing-bottlenecks-with-grpc-ca30fdc01bee)
    on the topic we discussed and demonstrated different ways of addressing this type
    of bottleneck, including:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们[第一篇文章](/overcoming-ml-data-preprocessing-bottlenecks-with-grpc-ca30fdc01bee)中，我们讨论并演示了应对这种瓶颈的不同方法，包括：
- en: Choosing a training instance with a CPU to GPU compute ratio that is more suited
    to your workload,
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个与您的工作负载更为匹配的CPU与GPU计算比率的训练实例，
- en: Improving the workload balance between the CPU and GPU by moving some of the
    CPU operations to the GPU, and
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将一些CPU操作转移到GPU，改善CPU和GPU之间的工作负载平衡，并且
- en: Offloading some of the CPU computation to auxiliary CPU-worker devices.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一些CPU计算卸载到辅助CPU工作者设备上。
- en: We demonstrated the third option using the [TensorFlow Data Service API](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service),
    a solution specific to TensorFlow, in which a portion of the input data processing
    can be offloaded onto other devices using gRPC as the underlying communication
    protocol.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了[TensorFlow Data Service API](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service)演示了第三种选择，这是一种专门针对TensorFlow的解决方案，其中部分输入数据处理可以通过使用gRPC作为底层通信协议来卸载到其他设备上。
- en: In our [second post](/overcoming-ml-data-preprocessing-bottlenecks-with-grpc-ca30fdc01bee),
    we proposed a more general-purpose gRPC-based solution for using auxiliary CPU
    workers and demonstrated it on a toy PyTorch model. Although it required a bit
    more manual coding and tuning than the [TensorFlow Data Service API](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service),
    the solution provided much greater robustness and allowed for the same optimization
    in training performance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的[第二篇文章](/overcoming-ml-data-preprocessing-bottlenecks-with-grpc-ca30fdc01bee)中，我们提出了一种基于gRPC的更通用的解决方案，用于利用辅助CPU工作者，并在一个玩具PyTorch模型上进行了演示。尽管它需要比[TensorFlow
    Data Service API](https://www.tensorflow.org/api_docs/python/tf/data/experimental/service)更多的手动编码和调整，但该解决方案提供了更大的鲁棒性，并在训练性能上实现了相同的优化。
- en: Load Balancing with Ray
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Ray进行负载均衡
- en: In this post we will demonstrate an additional method for using auxiliary CPU
    workers that aims to combine the robustness of the general-purpose solution with
    the simplicity and ease-of-use of the TensorFlow-specific API. The method we will
    demonstrate will use [**Ray Datasets**](https://docs.ray.io/en/latest/data/dataset.html)
    from the [Ray Data](https://docs.ray.io/en/latest/data/dataset.html) library.
    By leveraging the full power of Ray’s [resource management](https://docs.ray.io/en/latest/ray-core/scheduling/resources.html)
    and [distributed scheduling](https://docs.ray.io/en/latest/ray-core/scheduling/index.html)
    systems, Ray Data is able to run our training data input pipeline in manner that
    is both **scalable** and **distributed**. In particular, we will configure our
    Ray Dataset in such a way that the library will automatically detect and utilize
    all of the available CPU resources for pre-processing the training data. We will
    further wrap our model training loop with a [Ray AIR Trainer](https://docs.ray.io/en/latest/ray-air/trainer.html#air-trainers)
    so as to enable seamless scaling to a multi-GPU setting.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将展示一种额外的方法，利用辅助 CPU 工作线程，这种方法旨在将通用解决方案的鲁棒性与 TensorFlow 特定 API 的简单性和易用性相结合。我们将演示的方法将使用
    [**Ray 数据集**](https://docs.ray.io/en/latest/data/dataset.html) 来自 [Ray 数据](https://docs.ray.io/en/latest/data/dataset.html)
    库。通过利用 Ray 的 [资源管理](https://docs.ray.io/en/latest/ray-core/scheduling/resources.html)
    和 [分布式调度](https://docs.ray.io/en/latest/ray-core/scheduling/index.html) 系统的全部功能，Ray
    数据能够以 **可扩展** 和 **分布式** 的方式运行我们的训练数据输入管道。特别是，我们将配置 Ray 数据集，使得该库能够自动检测和利用所有可用的
    CPU 资源进行训练数据的预处理。我们还将用 [Ray AIR Trainer](https://docs.ray.io/en/latest/ray-air/trainer.html#air-trainers)
    封装我们的模型训练循环，以便能够无缝扩展到多 GPU 设置。
- en: Deploying a Ray Cluster on Amazon SageMaker
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Amazon SageMaker 上部署 Ray 集群
- en: A prerequisite for using the Ray framework and the utilities it offers in a
    multi-node environment is the deployment of a [Ray cluster](https://docs.ray.io/en/latest/cluster/getting-started.html).
    In general, designing, deploying, managing, and maintaining such a compute cluster
    can be a daunting task and often requires a dedicated devops engineer (or team
    of engineers). This can pose an insurmountable obstacle for some development teams.
    In this post we will demonstrate how to overcome this obstacle using AWS’s managed
    training service, Amazon SageMaker. In particular, we will create a [SageMaker
    heterogenous cluster](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html)
    with both GPU instances and CPU instances and use it to deploy a Ray cluster at
    startup. We will then run the Ray AIR training application on this Ray cluster
    while relying on Ray’s backend to perform effective load balancing across all
    of the resources in the cluster. When the training application is completed, the
    Ray cluster will be torn down automatically. Using SageMaker in this manner, enables
    us to deploy and use a Ray cluster without the overhead that is commonly associated
    with cluster management.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在多节点环境中使用 Ray 框架及其提供的工具的前提是部署 [Ray 集群](https://docs.ray.io/en/latest/cluster/getting-started.html)。一般来说，设计、部署、管理和维护这样的计算集群可能是一项艰巨的任务，并且通常需要专门的
    DevOps 工程师（或工程师团队）。这可能对某些开发团队构成无法克服的障碍。在这篇文章中，我们将演示如何使用 AWS 的托管训练服务 Amazon SageMaker
    来克服这一障碍。特别是，我们将创建一个包含 GPU 实例和 CPU 实例的 [SageMaker 异构集群](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html)，并在启动时使用它来部署
    Ray 集群。然后，我们将在此 Ray 集群上运行 Ray AIR 训练应用程序，同时依赖 Ray 的后端在集群中的所有资源之间进行有效的负载均衡。当训练应用程序完成时，Ray
    集群将自动拆除。以这种方式使用 SageMaker，使我们能够在没有与集群管理相关的额外开销的情况下部署和使用 Ray 集群。
- en: Ray is a powerful framework that enables a wide range of machine learning workloads.
    In this post we will demonstrate just a few of its capabilities and APIs using
    Ray version 2.6.1\. This post should not be used as a replacement for the [Ray
    documentation](https://docs.ray.io/en/latest/). Be sure to check out the official
    [documentation](https://docs.ray.io/en/latest/) for the most appropriate and up-to-date
    use of the Ray utilities.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Ray 是一个强大的框架，能够支持广泛的机器学习工作负载。在这篇文章中，我们将演示其一些功能和 API，使用 Ray 版本 2.6.1。本文不应作为 [Ray
    文档](https://docs.ray.io/en/latest/) 的替代品。请务必查阅官方 [文档](https://docs.ray.io/en/latest/)
    以获取有关 Ray 工具的最合适和最新的使用信息。
- en: Before we get started, special thanks to [Boruch Chalk](https://www.linkedin.com/in/boruch-chalk-56b28097/?originalSubdomain=il)
    for introducing me to the Ray Data library and its unique capabilities.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，特别感谢[Boruch Chalk](https://www.linkedin.com/in/boruch-chalk-56b28097/?originalSubdomain=il)引导我了解
    Ray Data 库及其独特的功能。
- en: Toy Example
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 玩具示例
- en: To facilitate our discussion, we will define and train a simple PyTorch (2.0)
    [Vision Transformer](https://en.wikipedia.org/wiki/Vision_transformer)-based classification
    model that we will train on a synthetic dataset comprised of random images and
    labels. The [Ray AIR documentation](https://docs.ray.io/en/latest/ray-air/getting-started.html)
    includes a wide variety of [examples](https://docs.ray.io/en/latest/ray-air/examples/index.html)
    that demonstrate how to build different types of training workloads using Ray
    AIR. The script we create here loosely follows the steps described in the [PyTorch
    image classifier example](https://docs.ray.io/en/latest/ray-air/examples/torch_image_example.html#).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便讨论，我们将定义并训练一个基于 PyTorch (2.0) 的[Vision Transformer](https://en.wikipedia.org/wiki/Vision_transformer)分类模型，该模型将在一个由随机图像和标签组成的合成数据集上进行训练。[Ray
    AIR 文档](https://docs.ray.io/en/latest/ray-air/getting-started.html)包括各种[示例](https://docs.ray.io/en/latest/ray-air/examples/index.html)，演示如何使用
    Ray AIR 构建不同类型的训练工作负载。我们在这里创建的脚本大致遵循了[PyTorch 图像分类器示例](https://docs.ray.io/en/latest/ray-air/examples/torch_image_example.html#)中描述的步骤。
- en: Defining the Ray Dataset and Preprocessor
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义 Ray 数据集和预处理器
- en: 'The [Ray AIR Trainer API](https://docs.ray.io/en/latest/train/api/doc/ray.train.trainer.BaseTrainer.html#ray.train.trainer.BaseTrainer)
    distinguishes between the raw dataset and the preprocessing pipeline that is applied
    to the elements of the dataset before feeding them into the training loop. For
    our raw Ray dataset we create a simple [range of integers](https://docs.ray.io/en/latest/data/api/doc/ray.data.range.html)
    of size *num_records*. Next, we define the [Preprocessor](https://docs.ray.io/en/latest/ray-air/preprocessors.html)
    that we would like to apply to our dataset. Our Ray Preprocesser contains two
    components: The first is a [BatchMapper](https://docs.ray.io/en/latest/ray-air/api/doc/ray.data.preprocessors.BatchMapper.html)
    that maps the raw integers to random image-label pairs. The second is a [TorchVisionPreprocessor](https://docs.ray.io/en/latest/ray-air/api/doc/ray.data.preprocessors.TorchVisionPreprocessor.html)
    that performs a [torchvision transform](https://pytorch.org/vision/0.9/transforms.html)
    on our random batches which converts them to PyTorch tensors and applies a series
    of [GaussianBlur](https://pytorch.org/vision/main/generated/torchvision.transforms.GaussianBlur.html)
    operations. The [GaussianBlur](https://pytorch.org/vision/main/generated/torchvision.transforms.GaussianBlur.html)
    operations are intended to simulate a relatively heavy data pre-processing pipeline.
    The two Preprocessors are combined using a [Chain](https://docs.ray.io/en/latest/ray-air/api/doc/ray.data.preprocessors.Chain.html)
    Preprocessor. The creation of the Ray dataset and Preprocessor is demonstrated
    in the code block below:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ray AIR Trainer API](https://docs.ray.io/en/latest/train/api/doc/ray.train.trainer.BaseTrainer.html#ray.train.trainer.BaseTrainer)
    区分了原始数据集和在将数据集元素送入训练循环之前应用的预处理管道。对于我们的原始 Ray 数据集，我们创建一个大小为*num_records*的简单[整数范围](https://docs.ray.io/en/latest/data/api/doc/ray.data.range.html)。接下来，我们定义我们希望应用于数据集的[预处理器](https://docs.ray.io/en/latest/ray-air/preprocessors.html)。我们的
    Ray 预处理器包含两个组件：第一个是[BatchMapper](https://docs.ray.io/en/latest/ray-air/api/doc/ray.data.preprocessors.BatchMapper.html)，它将原始整数映射到随机的图像-标签对。第二个是[TorchVisionPreprocessor](https://docs.ray.io/en/latest/ray-air/api/doc/ray.data.preprocessors.TorchVisionPreprocessor.html)，它对我们的随机批次执行[torchvision
    transform](https://pytorch.org/vision/0.9/transforms.html)，将其转换为 PyTorch 张量，并应用一系列[GaussianBlur](https://pytorch.org/vision/main/generated/torchvision.transforms.GaussianBlur.html)操作。这些[GaussianBlur](https://pytorch.org/vision/main/generated/torchvision.transforms.GaussianBlur.html)操作旨在模拟相对较重的数据预处理管道。这两个预处理器通过[Chain](https://docs.ray.io/en/latest/ray-air/api/doc/ray.data.preprocessors.Chain.html)
    预处理器进行组合。Ray 数据集和预处理器的创建在下面的代码块中演示：'
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that the Ray data pipeline will automatically use all of the CPUs that
    are available in the Ray cluster. This includes the CPU resources that are on
    the GPU instance as well as the CPU resources of any additional auxiliary instances
    in the cluster.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Ray 数据管道将自动使用 Ray 集群中所有可用的 CPU。这包括 GPU 实例上的 CPU 资源以及集群中任何额外辅助实例的 CPU 资源。
- en: Defining the Training Loop
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义训练循环
- en: 'The next step is to define the training sequence that will run on each of the
    training workers (e.g., GPUs). First we define the model using the popular [timm](https://pypi.org/project/timm/)
    (0.6.13) Python package and wrap it using the [train.torch.prepare_model](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_model.html#ray.train.torch.prepare_model)
    API. Next, we extract the appropriate shard from the dataset and define an iterator
    that yields data batches with the requested batch size and copies them to the
    training device. Then comes the training loop itself which is comprised of standard
    PyTorch code. When we exit the loop, we report back the resultant loss metric.
    The per-worker training sequence is demonstrated in the code block below:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是定义训练序列，该序列将在每个训练节点（例如，GPU）上运行。首先，我们使用流行的 [timm](https://pypi.org/project/timm/)（0.6.13
    版本）Python 包定义模型，并使用 [train.torch.prepare_model](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.prepare_model.html#ray.train.torch.prepare_model)
    API 进行包装。接下来，我们从数据集中提取适当的分片，并定义一个迭代器，该迭代器以请求的批量大小生成数据批次，并将其复制到训练设备。然后是训练循环本身，其中包含标准的
    PyTorch 代码。当我们退出循环时，我们报告结果损失指标。每个训练节点的训练序列在以下代码块中展示：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Defining the Ray Torch Trainer
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义 Ray Torch Trainer
- en: Once we’ve defined our data pipeline and training loop, we can move on to setting
    up the [Ray TorchTrainer](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchTrainer.html).
    We configure the Trainer in a manner that takes into account the available resources
    in the cluster. Specifically, we set the number of training workers according
    to the number of GPUs and we set the batch size according to the memory available
    on our target GPU. We build our dataset with the number of records required to
    train for precisely 1000 steps.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了数据流水线和训练循环，我们可以继续设置 [Ray TorchTrainer](https://docs.ray.io/en/latest/train/api/doc/ray.train.torch.TorchTrainer.html)。我们根据集群中可用的资源配置
    Trainer。具体来说，我们根据 GPU 的数量设置训练节点数，并根据目标 GPU 上可用的内存设置批量大小。我们构建我们的数据集，以确保训练精确进行 1000
    步所需的记录数。
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Deploy a Ray Cluster and Run the Training Sequence
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Ray 集群并运行训练序列
- en: We now define the entry point of our training script. It is here that we setup
    the Ray cluster and initiate the training sequence on the head node. We use the
    [Environment](https://github.com/aws/sagemaker-training-toolkit/blob/master/README.md#get-information-about-the-container-environment)
    class from the [sagemaker-training](https://pypi.org/project/sagemaker-training/)
    library to discover the instances in the heterogenous SageMaker cluster as described
    in [this tutorial](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html#train-heterogeneous-cluster-modify-training-script).
    We define the first node of the GPU instance group as our Ray cluster *head* node
    and run the appropriate command on all of the other nodes to connect them to the
    cluster. (See the [Ray documentation](https://docs.ray.io/en/latest/cluster/getting-started.html)
    for more details on creating clusters.) We program the head node to wait until
    all the nodes have connected and then start the training sequence. This ensures
    that Ray will utilize all of the available resources when defining and distributing
    the underlying Ray tasks.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们定义训练脚本的入口点。在这里，我们设置 Ray 集群并在主节点上启动训练序列。我们使用 [sagemaker-training](https://pypi.org/project/sagemaker-training/)
    库中的 [Environment](https://github.com/aws/sagemaker-training-toolkit/blob/master/README.md#get-information-about-the-container-environment)
    类来发现异构 SageMaker 集群中的实例，如 [此教程](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html#train-heterogeneous-cluster-modify-training-script)
    中所述。我们将 GPU 实例组的第一个节点定义为 Ray 集群的 *head* 节点，并在所有其他节点上运行适当的命令，将它们连接到集群中（有关创建集群的更多详细信息，请参阅
    [Ray 文档](https://docs.ray.io/en/latest/cluster/getting-started.html)）。我们编程主节点等待所有节点连接，然后开始训练序列。这确保了
    Ray 在定义和分发底层任务时利用所有可用资源。
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Training on an Amazon SageMaker Heterogenous Cluster
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Amazon SageMaker 异构集群上进行训练
- en: With our training script complete, we are now tasked with deploying it to an
    Amazon SageMaker Heterogenous Cluster. To do this we follow the steps described
    in [this tutorial](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html).
    We start by creating a *source_dir* directory into which we place the our *train.py*
    script and a *requirements.txt* file containing the two pip packages our script
    depends on, [timm](https://pypi.org/project/timm/) and [ray[air]](https://pypi.org/project/ray/).
    These are automatically installed on each of the nodes in the SageMaker cluster.
    We define two SageMaker [Instance Groups](https://sagemaker.readthedocs.io/en/stable/api/utility/instance_group.html),
    the first with a single [ml.g5.xlarge](https://aws.amazon.com/ec2/instance-types/g5/)
    instance (containing 1 GPU and 4 vCPUs), and the second with a single [ml.c5.4xlarge](https://aws.amazon.com/ec2/instance-types/c5/)
    instance (containing 16 vCPUs). We then use the [SageMaker PyTorch estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html)
    to define and deploy our training job to the cloud.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成我们的训练脚本后，我们现在需要将其部署到 Amazon SageMaker 异构集群。为此，我们遵循 [本教程](https://docs.aws.amazon.com/sagemaker/latest/dg/train-heterogeneous-cluster.html)
    中描述的步骤。我们首先创建一个 *source_dir* 目录，将我们的 *train.py* 脚本和一个包含脚本所依赖的两个 pip 包的 *requirements.txt*
    文件放入其中，分别是 [timm](https://pypi.org/project/timm/) 和 [ray[air]](https://pypi.org/project/ray/)。这些包会自动安装在
    SageMaker 集群的每个节点上。我们定义了两个 SageMaker [实例组](https://sagemaker.readthedocs.io/en/stable/api/utility/instance_group.html)，第一个实例组包含一个
    [ml.g5.xlarge](https://aws.amazon.com/ec2/instance-types/g5/) 实例（包含 1 个 GPU 和
    4 个 vCPUs），第二个实例组包含一个 [ml.c5.4xlarge](https://aws.amazon.com/ec2/instance-types/c5/)
    实例（包含 16 个 vCPUs）。然后我们使用 [SageMaker PyTorch 估算器](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html)
    定义并将训练作业部署到云端。
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Results
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: 'In the table below we compare the runtime results of running our training script
    in two different settings: a single ml.g5.xlarge GPU instance and a heterogenous
    cluster containing an ml.g5.xlarge instance and an ml.c5.4xlarge. We evaluate
    the system resource utilization using [Amazon CloudWatch](https://aws.amazon.com/cloudwatch/)
    and estimate the training cost using the [Amazon SageMaker pricing](https://aws.amazon.com/sagemaker/pricing/?p=pm&c=sm&z=4)
    available as of the time of this writing ($0.816 per hour for the ml.c5.4xlarge
    instance and $1.408 for the ml.g5.xlarge).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，我们比较了在两种不同设置下运行我们的训练脚本的运行时结果：一个单独的 ml.g5.xlarge GPU 实例和一个包含 ml.g5.xlarge
    实例以及 ml.c5.4xlarge 实例的异构集群。我们使用 [Amazon CloudWatch](https://aws.amazon.com/cloudwatch/)
    评估系统资源利用率，并根据编写本文时的 [Amazon SageMaker 定价](https://aws.amazon.com/sagemaker/pricing/?p=pm&c=sm&z=4)
    估算训练成本（ml.c5.4xlarge 实例每小时 $0.816，ml.g5.xlarge 实例每小时 $1.408）。
- en: '![](../Images/3e024e2da81b7e609eb6fcc2d2112427.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e024e2da81b7e609eb6fcc2d2112427.png)'
- en: Comparative Performance Results (By Author)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 性能比较结果（作者提供）
- en: The relatively high CPU utilization combined with the low GPU utilization of
    the single instance experiment indicates a performance bottleneck in the data
    pre-processing pipeline. These are clearly addressed when moving to the heterogenous
    cluster. Not only does the GPU utilization increase, but so does the training
    speed. Overall, the price efficiency of training increases by 23%.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 单个实例实验中相对较高的 CPU 利用率与较低的 GPU 利用率表明数据预处理管道存在性能瓶颈。这些问题在迁移到异构集群时得到了明显解决。GPU 利用率和训练速度都得到了提升。总体而言，训练的价格效率提高了
    23%。
- en: We should emphasize that these toy experiments were created purely for the purpose
    of demonstrating the automated load balancing features enabled by the Ray ecosystem.
    It is possible that tuning of the control parameters may have led to improved
    performance. It is also likely that choosing a different solution for addressing
    the CPU bottleneck (such as choosing an instance from the [EC2 g5](https://aws.amazon.com/ec2/instance-types/g5/)
    family with more CPUs) may have resulted in better cost performance.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要强调的是，这些实验纯粹是为了演示 Ray 生态系统启用的自动负载均衡功能而创建的。调整控制参数可能会导致性能的改善。选择不同的解决方案来解决 CPU
    瓶颈问题（例如选择具有更多 CPU 的 [EC2 g5](https://aws.amazon.com/ec2/instance-types/g5/) 系列实例）也可能会带来更好的成本效益。
- en: Summary
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this post we have demonstrated how Ray datasets can be used to balance the
    load of a heavy data pre-processing pipeline across all of the available CPU workers
    in the cluster. This enables us to easily address CPU bottlenecks by simply adding
    auxiliary CPU instances to the training environment. Amazon SageMaker’s heterogenous
    cluster support is a compelling way to run a Ray training job in the cloud as
    it handles all facets of the cluster management avoiding the need for dedicated
    devops support.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们展示了如何利用 Ray 数据集在集群中所有可用的 CPU 工作节点之间平衡繁重的数据预处理管道的负载。这使我们能够通过简单地向训练环境中添加辅助
    CPU 实例来轻松解决 CPU 瓶颈问题。亚马逊 SageMaker 的异构集群支持是一种在云中运行 Ray 训练任务的有力方式，因为它处理了集群管理的所有方面，避免了对专门
    DevOps 支持的需求。
- en: Keep in mind that the solution presented here is just one of many different
    ways of addressing CPU bottlenecks. The best solution for you will highly depend
    on the details of your project.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这里展示的解决方案只是应对 CPU 瓶颈的众多不同方法之一。最适合您的解决方案将高度依赖于您项目的具体细节。
- en: As usual, please feel free to reach out with comments, corrections, and questions.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，请随时提出意见、纠正和问题。
