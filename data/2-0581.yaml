- en: Cracking Open the Hugging Face Transformers Library
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç ´è§£Hugging Face Transformersåº“
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161](https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161](https://towardsdatascience.com/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
- en: A quick-start guide to using open-source LLMs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å¼€æºLLMsçš„å¿«é€Ÿå…¥é—¨æŒ‡å—
- en: '[](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)[](https://towardsdatascience.com/?source=post_page-----350aa0ef0161--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----350aa0ef0161--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)[](https://towardsdatascience.com/?source=post_page-----350aa0ef0161--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----350aa0ef0161--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----350aa0ef0161--------------------------------)
    Â·10 min readÂ·Aug 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----350aa0ef0161--------------------------------)
    Â·10åˆ†é’Ÿé˜…è¯»Â·2023å¹´8æœˆ5æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: This is the 3rd article in a [series on using large language models (LLMs)](/a-practical-introduction-to-llms-65194dda1148)
    in practice. Here I will give a beginner-friendly guide to the Hugging Face Transformers
    library, which provides an easy and cost-free way to work with a wide variety
    of open-source language models. I will start by reviewing key concepts and then
    dive into example Python code.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå…³äºå®è·µä¸­ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„[ç³»åˆ—æ–‡ç« ä¸­çš„ç¬¬3ç¯‡](/a-practical-introduction-to-llms-65194dda1148)ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å°†ä¸ºHugging
    Face Transformersåº“æä¾›ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„æŒ‡å—ï¼Œè¯¥åº“æä¾›äº†ä¸€ç§ç®€å•ä¸”æ— æˆæœ¬çš„æ–¹å¼æ¥ä½¿ç”¨å„ç§å¼€æºè¯­è¨€æ¨¡å‹ã€‚æˆ‘å°†ä»å›é¡¾å…³é”®æ¦‚å¿µå¼€å§‹ï¼Œç„¶åæ·±å…¥ç¤ºä¾‹Pythonä»£ç ã€‚
- en: '![](../Images/4250c47bc3e0aefc26a5d1c0a7bb88e2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4250c47bc3e0aefc26a5d1c0a7bb88e2.png)'
- en: Photo by [JÃ©an BÃ©ller](https://unsplash.com/@chinatravelchannel?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [JÃ©an BÃ©ller](https://unsplash.com/@chinatravelchannel?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œå‘å¸ƒåœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In the [previous article](/cracking-open-the-openai-python-api-230e4cae7971)
    of this series, we explored the OpenAI Python API and used it to make a custom
    chatbot. One downside of this API, however, is that API calls cost money, which
    may not scale well for some use cases.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç³»åˆ—çš„[ä¸Šä¸€ç¯‡æ–‡ç« ](/cracking-open-the-openai-python-api-230e4cae7971)ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†OpenAI
    Python APIï¼Œå¹¶ç”¨å®ƒåˆ¶ä½œäº†ä¸€ä¸ªå®šåˆ¶çš„èŠå¤©æœºå™¨äººã€‚ç„¶è€Œï¼Œè¯¥APIçš„ä¸€ä¸ªç¼ºç‚¹æ˜¯APIè°ƒç”¨éœ€è¦ä»˜è´¹ï¼Œè¿™å¯èƒ½åœ¨æŸäº›ç”¨ä¾‹ä¸­ä¸å¤ªé€‚ç”¨ã€‚
- en: In these scenarios, it may be advantageous to turn to open-source solutions.
    One popular way to do this is via Hugging Faceâ€™s Transformers library.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œè½¬å‘å¼€æºè§£å†³æ–¹æ¡ˆå¯èƒ½ä¼šå¾ˆæœ‰ä¼˜åŠ¿ã€‚ä¸€ç§æµè¡Œçš„æ–¹æ³•æ˜¯é€šè¿‡**Hugging Face**çš„Transformersåº“æ¥å®ç°ã€‚
- en: '**What is Hugging Face?**'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**Hugging Faceæ˜¯ä»€ä¹ˆï¼Ÿ**'
- en: '**Hugging Face** is an **AI company that has become a major hub for open-source
    machine learning (ML)**. Their platform has 3 major elements which allow users
    to access and share machine learning resources.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**Hugging Face** æ˜¯ä¸€å®¶**å·²ç»æˆä¸ºå¼€æºæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä¸»è¦ä¸­å¿ƒçš„AIå…¬å¸**ã€‚ä»–ä»¬çš„å¹³å°æœ‰3ä¸ªä¸»è¦å…ƒç´ ï¼Œå…è®¸ç”¨æˆ·è®¿é—®å’Œåˆ†äº«æœºå™¨å­¦ä¹ èµ„æºã€‚'
- en: First is their rapidly growing repository of pre-trained open-source ML **models**
    for things such as natural language processing (NLP), computer vision, and more.
    Second is their library of **datasets** for training ML models for almost any
    task. Third, and finally, is **Spaces** which is a collection of open-source ML
    apps hosted by Hugging Face.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆæ˜¯ä»–ä»¬å¿«é€Ÿå¢é•¿çš„é¢„è®­ç»ƒå¼€æºML **æ¨¡å‹**åº“ï¼Œç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ã€è®¡ç®—æœºè§†è§‰ç­‰ã€‚ç¬¬äºŒæ˜¯ä»–ä»¬çš„**æ•°æ®é›†**åº“ï¼Œç”¨äºè®­ç»ƒå‡ ä¹ä»»ä½•ä»»åŠ¡çš„MLæ¨¡å‹ã€‚ç¬¬ä¸‰ï¼Œä¹Ÿæ˜¯æœ€åï¼Œæ˜¯**Spaces**ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±Hugging
    Faceæ‰˜ç®¡çš„å¼€æºMLåº”ç”¨é›†åˆã€‚
- en: The power of these resources is that they are community generated, which leverages
    all the benefits of open-source (i.e. cost-free, wide diversity of tools, high-quality
    resources, and rapid pace of innovation). While these make building powerful ML
    projects more accessible than before, there is another key element of the Hugging
    Face ecosystem â€” the Transformers library.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›èµ„æºçš„åŠ›é‡åœ¨äºå®ƒä»¬æ˜¯ç¤¾åŒºç”Ÿæˆçš„ï¼Œåˆ©ç”¨äº†å¼€æºçš„æ‰€æœ‰ä¼˜åŠ¿ï¼ˆå³å…è´¹ã€å¤§é‡çš„å·¥å…·ã€å¤šæ ·çš„èµ„æºå’Œå¿«é€Ÿçš„åˆ›æ–°æ­¥ä¼ï¼‰ã€‚è™½ç„¶è¿™äº›ä½¿å¾—æ„å»ºå¼ºå¤§çš„ ML é¡¹ç›®æ¯”ä»¥å¾€æ›´å®¹æ˜“ï¼Œä½†
    Hugging Face ç”Ÿæ€ç³»ç»Ÿçš„å¦ä¸€ä¸ªå…³é”®å…ƒç´ æ˜¯â€”â€”Transformers åº“ã€‚
- en: ğŸ¤—**Transformers**
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ¤—**Transformers**
- en: '**Transformers** is a **Python library that makes downloading and training
    state-of-the-art ML models easy**. Although it was initially made for developing
    language models, its functionality has expanded to include models for computer
    vision, audio processing, and beyond.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**Transformers** æ˜¯ä¸€ä¸ª **ä½¿ä¸‹è½½å’Œè®­ç»ƒæœ€å…ˆè¿›çš„ ML æ¨¡å‹å˜å¾—ç®€å•çš„ Python åº“**ã€‚è™½ç„¶å®ƒæœ€åˆæ˜¯ä¸ºå¼€å‘è¯­è¨€æ¨¡å‹è€Œåˆ›å»ºçš„ï¼Œä½†å®ƒçš„åŠŸèƒ½å·²ç»æ‰©å±•åˆ°åŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘å¤„ç†ç­‰æ¨¡å‹ã€‚'
- en: Two big strengths of this library are, **one**, it easily integrates with Hugging
    Faceâ€™s (previously mentioned) Models, Datasets, and Spaces repositories, and **two**,
    the library supports other popular ML frameworks such as PyTorch and TensorFlow.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåº“çš„ä¸¤ä¸ªä¸»è¦ä¼˜ç‚¹æ˜¯ï¼Œ**ä¸€**ï¼Œå®ƒèƒ½å¤Ÿè½»æ¾ä¸ Hugging Faceï¼ˆå‰é¢æåˆ°çš„ï¼‰çš„ Modelsã€Datasets å’Œ Spaces ä»“åº“é›†æˆï¼Œ**äºŒ**ï¼Œè¿™ä¸ªåº“æ”¯æŒå…¶ä»–æµè¡Œçš„
    ML æ¡†æ¶ï¼Œå¦‚ PyTorch å’Œ TensorFlowã€‚
- en: This results in a simple and flexible all-in-one platform for downloading, training,
    and deploying machine learning models and apps.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—ä¸‹è½½ã€è®­ç»ƒå’Œéƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹å’Œåº”ç”¨ç¨‹åºå˜å¾—ç®€å•è€Œçµæ´»ã€‚
- en: '**Pipeline()**'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Pipeline()**'
- en: The easiest way to start using the library is via the *pipeline()* function,
    which abstracts NLP (and other) tasks into 1 line of code. For example, if we
    want to do sentiment analysis, we would need to select a model, tokenize the input
    text, pass it through the model, and decode the numerical output to determine
    the sentiment label (positive or negative).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¿™ä¸ªåº“çš„æœ€ç®€å•æ–¹æ³•æ˜¯é€šè¿‡ *pipeline()* å‡½æ•°ï¼Œå®ƒå°† NLPï¼ˆå’Œå…¶ä»–ï¼‰ä»»åŠ¡æŠ½è±¡æˆ 1 è¡Œä»£ç ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æƒ³åšæƒ…æ„Ÿåˆ†æï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ï¼Œå¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼Œç»è¿‡æ¨¡å‹å¤„ç†ï¼Œç„¶åè§£ç æ•°å€¼è¾“å‡ºä»¥ç¡®å®šæƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯ææˆ–æ¶ˆæï¼‰ã€‚
- en: While this may seem like a lot of steps, we can do all this in 1 line via the
    *pipeline()* function, as shown in the code snippet below.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™çœ‹èµ·æ¥æœ‰å¾ˆå¤šæ­¥éª¤ï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡ *pipeline()* å‡½æ•°åœ¨ 1 è¡Œä»£ç ä¸­å®Œæˆæ‰€æœ‰è¿™äº›æ­¥éª¤ï¼Œå¦‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µæ‰€ç¤ºã€‚
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Of course, sentiment analysis is not the only thing we can do here. Almost any
    NLP task can be done in this way e.g. summarization, translation, question-answering,
    feature extraction (i.e. text embedding), text generation, zero-shot-classification,
    and more â€” *for a full list of the built-in tasks, check out the* [*pipleine()
    documentation*](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.task).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œæƒ…æ„Ÿåˆ†æå¹¶ä¸æ˜¯æˆ‘ä»¬åœ¨è¿™é‡Œå”¯ä¸€èƒ½åšçš„äº‹æƒ…ã€‚å‡ ä¹ä»»ä½• NLP ä»»åŠ¡éƒ½å¯ä»¥ç”¨è¿™ç§æ–¹å¼å®Œæˆï¼Œä¾‹å¦‚æ‘˜è¦ã€ç¿»è¯‘ã€é—®ç­”ã€ç‰¹å¾æå–ï¼ˆå³æ–‡æœ¬åµŒå…¥ï¼‰ã€æ–‡æœ¬ç”Ÿæˆã€é›¶æ ·æœ¬åˆ†ç±»ç­‰
    â€”â€” *æœ‰å…³å†…ç½®ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼Œè¯·æŸ¥çœ‹* [*pipeline() æ–‡æ¡£*](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.task)ã€‚
- en: In the above example code, since we did not specify a model, the default model
    for sentiment analysis was used (i.e. *distilbert-base-uncased-finetuned-sst-2-english*).
    However, if we wanted to be more explicit, we could have used the following line
    of code.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°ç¤ºä¾‹ä»£ç ä¸­ï¼Œç”±äºæˆ‘ä»¬æ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œå› æ­¤ä½¿ç”¨äº†é»˜è®¤çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼ˆå³ *distilbert-base-uncased-finetuned-sst-2-english*ï¼‰ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬æƒ³æ›´æ˜ç¡®ä¸€äº›ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç è¡Œã€‚
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: One of the greatest benefits of the Transformers library is we could have just
    as easily used any of the 28,000+ text classification models on Hugging Faceâ€™s
    [Models repository](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending)
    by simply changing the model name passed into the *pipeline()* function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Transformers åº“çš„æœ€å¤§ä¼˜ç‚¹ä¹‹ä¸€æ˜¯æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åœ°æ›´æ”¹ä¼ é€’ç»™ *pipeline()* å‡½æ•°çš„æ¨¡å‹åç§°ï¼Œè½»æ¾ä½¿ç”¨ Hugging Face
    çš„ [Models repository](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending)
    ä¸Šçš„ä»»ä½• 28,000 å¤šä¸ªæ–‡æœ¬åˆ†ç±»æ¨¡å‹ã€‚
- en: '**Models**'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ¨¡å‹**'
- en: There is a massive repository of pre-trained models available on [Hugging Face](https://huggingface.co/models)
    (277,528 at the time of writing this). Almost all these models can be easily used
    via Transformers, using the same syntax we saw in the above code block.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ [Hugging Face](https://huggingface.co/models) ä¸Šæœ‰å¤§é‡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæˆªè‡³å†™ä½œæ—¶ä¸º 277,528 ä¸ªï¼‰ã€‚å‡ ä¹æ‰€æœ‰è¿™äº›æ¨¡å‹éƒ½å¯ä»¥é€šè¿‡
    Transformers è½»æ¾ä½¿ç”¨ï¼Œä½¿ç”¨ä¸ä¸Šè¿°ä»£ç å—ä¸­ç›¸åŒçš„è¯­æ³•ã€‚
- en: However, the models on Hugging Face **arenâ€™t only for the Transformers library.**
    There are models for other popular machine learning frameworks e.g. PyTorch, Tensorflow,
    Jax. This makes Hugging Faceâ€™s Models repository useful to ML practitioners beyond
    the context of the Transformers library.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼ŒHugging Faceä¸Šçš„æ¨¡å‹**ä¸ä»…ä»…ç”¨äºTransformersåº“ã€‚** è¿˜æœ‰å…¶ä»–æµè¡Œæœºå™¨å­¦ä¹ æ¡†æ¶çš„æ¨¡å‹ï¼Œå¦‚PyTorchã€Tensorflowã€Jaxã€‚è¿™ä½¿å¾—Hugging
    Faceçš„æ¨¡å‹åº“å¯¹è¶…è¶ŠTransformersåº“çš„æœºå™¨å­¦ä¹ ä»ä¸šè€…ä¹Ÿå¾ˆæœ‰ç”¨ã€‚
- en: To see what navigating the repository looks like, letâ€™s consider an example.
    Say we want a model that can do text generation, but we want it to be available
    via the Transformers library so we can use it in one line of code (as we did above).
    We can easily view all models that fit these criteria using the â€œTasksâ€ and â€œLibrariesâ€
    filters.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¦äº†è§£æµè§ˆä»£ç åº“çš„æ ·å­ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘ä¸€ä¸ªä¾‹å­ã€‚å‡è®¾æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¯ä»¥è¿›è¡Œæ–‡æœ¬ç”Ÿæˆçš„æ¨¡å‹ï¼Œä½†æˆ‘ä»¬å¸Œæœ›å®ƒå¯ä»¥é€šè¿‡Transformersåº“ä½¿ç”¨ï¼Œè¿™æ ·æˆ‘ä»¬å°±èƒ½ç”¨ä¸€è¡Œä»£ç æ¥å®ç°ï¼ˆå¦‚ä¸Šæ‰€ç¤ºï¼‰ã€‚æˆ‘ä»¬å¯ä»¥è½»æ¾åœ°ä½¿ç”¨â€œä»»åŠ¡â€å’Œâ€œåº“â€è¿‡æ»¤å™¨æ¥æŸ¥çœ‹ç¬¦åˆè¿™äº›æ¡ä»¶çš„æ‰€æœ‰æ¨¡å‹ã€‚
- en: A model that meets these criteria is the newly released Llama 2\. More specifically,
    *Llama-2â€“7b-chat-hf*, which is a model in the Llama 2 family with about 7 billion
    parameters, optimized for chat, and in the Hugging Face Transformers format. We
    can get more information about this model via its **model card**, which is shown
    in the figure below.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç¬¦åˆè¿™äº›æ ‡å‡†çš„æ¨¡å‹æ˜¯æ–°å‘å¸ƒçš„Llama 2ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œ*Llama-2â€“7b-chat-hf*ï¼Œè¿™æ˜¯Llama 2ç³»åˆ—ä¸­çš„ä¸€ä¸ªæ¨¡å‹ï¼Œå…·æœ‰å¤§çº¦70äº¿ä¸ªå‚æ•°ï¼Œä¼˜åŒ–ç”¨äºèŠå¤©ï¼Œå¹¶ä¸”é‡‡ç”¨Hugging
    Face Transformersæ ¼å¼ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å®ƒçš„**æ¨¡å‹å¡**è·å¾—æ›´å¤šæœ‰å…³è¯¥æ¨¡å‹çš„ä¿¡æ¯ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚
- en: '![](../Images/6f60ee56c40846bbb992c4274c843c92.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f60ee56c40846bbb992c4274c843c92.png)'
- en: Touring the [Llama-2â€“7b-chat-hf model card](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf).
    Image by author.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æµè§ˆ[Llama-2â€“7b-chat-hfæ¨¡å‹å¡](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf)ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: '**Installing** ğŸ¤—**Transformers (with Conda)**'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**å®‰è£…** ğŸ¤—**Transformersï¼ˆä½¿ç”¨Condaï¼‰**'
- en: Now that we have a basic idea of the resources offered by Hugging Face and the
    Transformers library letâ€™s see how we can use them. We start by installing the
    library and other dependencies.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯¹Hugging Faceå’ŒTransformersåº“æä¾›çš„èµ„æºæœ‰äº†åŸºæœ¬äº†è§£ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚æˆ‘ä»¬ä»å®‰è£…åº“å’Œå…¶ä»–ä¾èµ–é¡¹å¼€å§‹ã€‚
- en: Hugging Face provides an [installation guide](https://huggingface.co/docs/transformers/installation)
    on its website. So, I wonâ€™t try to (poorly) duplicate that guide here. However,
    I will provide a quick 2-step guide on **how to set up the conda environment for
    the example code below**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face åœ¨å…¶ç½‘ç«™ä¸Šæä¾›äº†ä¸€ä¸ª[å®‰è£…æŒ‡å—](https://huggingface.co/docs/transformers/installation)ã€‚å› æ­¤ï¼Œæˆ‘ä¸ä¼šåœ¨è¿™é‡Œï¼ˆä¸ç†Ÿç»ƒåœ°ï¼‰é‡å¤é‚£ä¸ªæŒ‡å—ã€‚ä¸è¿‡ï¼Œæˆ‘ä¼šæä¾›ä¸€ä¸ªç®€çŸ­çš„2æ­¥æŒ‡å—ï¼Œè¯´æ˜**å¦‚ä½•ä¸ºä¸‹é¢çš„ç¤ºä¾‹ä»£ç è®¾ç½®condaç¯å¢ƒ**ã€‚
- en: '**Step 1)** The first step is to download the hf-env.yml file available at
    the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/hugging-face).
    You can either download the file directly or clone the whole repo.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤1)** ç¬¬ä¸€æ­¥æ˜¯ä¸‹è½½ä½äº[GitHubä»“åº“](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/hugging-face)çš„hf-env.ymlæ–‡ä»¶ã€‚ä½ å¯ä»¥ç›´æ¥ä¸‹è½½æ–‡ä»¶æˆ–å…‹éš†æ•´ä¸ªä»“åº“ã€‚'
- en: '**Step 2)** Next, in your terminal (or anaconda command prompt), you can create
    a new conda environment based on hf-env.yml using the following commands'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤2)** æ¥ä¸‹æ¥ï¼Œåœ¨ä½ çš„ç»ˆç«¯ï¼ˆæˆ–anacondaå‘½ä»¤æç¤ºç¬¦ï¼‰ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åŸºäºhf-env.ymlåˆ›å»ºä¸€ä¸ªæ–°çš„condaç¯å¢ƒã€‚'
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This may take a couple of minutes to install, but once itâ€™s complete, you should
    be ready to go!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ¥å®‰è£…ï¼Œä½†ä¸€æ—¦å®Œæˆï¼Œä½ åº”è¯¥å°±å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ï¼
- en: '**Example Code: NLP with** ğŸ¤—**Transformers**'
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç¤ºä¾‹ä»£ç ï¼šä½¿ç”¨** ğŸ¤—**Transformersè¿›è¡ŒNLP**'
- en: With the necessary libraries installed, letâ€™s jump into some example code. Here
    we will survey **3 NLP use cases**, namely, **sentiment analysis, summarization,
    and conversational text generation**, using the *pipeline()* function.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®‰è£…äº†å¿…è¦çš„åº“ä¹‹åï¼Œè®©æˆ‘ä»¬è¿›å…¥ä¸€äº›ç¤ºä¾‹ä»£ç ã€‚è¿™é‡Œæˆ‘ä»¬å°†è°ƒæŸ¥**3ä¸ªNLPç”¨ä¾‹**ï¼Œå³**æƒ…æ„Ÿåˆ†æã€æ‘˜è¦å’Œå¯¹è¯æ–‡æœ¬ç”Ÿæˆ**ï¼Œä½¿ç”¨*pipeline()*å‡½æ•°ã€‚
- en: Toward the end, we will use Gradio to quickly generate a User Interface (UI)
    for any of these use cases and deploy it as an app on Hugging Face Spaces. All
    example code is available on the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/hugging-face).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ€åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Gradioå¿«é€Ÿç”Ÿæˆä¸€ä¸ªç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰æ¥å¤„ç†è¿™äº›ç”¨ä¾‹ï¼Œå¹¶å°†å…¶ä½œä¸ºåº”ç”¨éƒ¨ç½²åœ¨Hugging Face Spacesä¸Šã€‚æ‰€æœ‰ç¤ºä¾‹ä»£ç éƒ½å¯ä»¥åœ¨[GitHubä»“åº“](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/hugging-face)ä¸Šæ‰¾åˆ°ã€‚
- en: '**Sentiment Analysis**'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æƒ…æ„Ÿåˆ†æ**'
- en: We start sentiment analysis. Recall from earlier when we used the pipeline function
    to do something like the code block below, where we create a classifier that can
    label the input text as being either positive or negative.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼€å§‹æƒ…æ„Ÿåˆ†æã€‚å›å¿†ä¸€ä¸‹æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨pipelineå‡½æ•°æ¥å®Œæˆç±»ä¼¼ä¸‹é¢çš„ä»£ç å—çš„æ“ä½œï¼Œå…¶ä¸­æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œå¯ä»¥å°†è¾“å…¥æ–‡æœ¬æ ‡è®°ä¸ºæ­£é¢æˆ–è´Ÿé¢ã€‚
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To go one step further, instead of processing text one by one, we can pass a
    list to the classifier to process as a batch.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´è¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ–‡æœ¬åˆ—è¡¨ä¼ é€’ç»™åˆ†ç±»å™¨è¿›è¡Œæ‰¹å¤„ç†ï¼Œè€Œä¸æ˜¯é€ä¸ªå¤„ç†ã€‚
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: However, the text classification models on Hugging Face are not limited to just
    positive-negative sentiment. For example, the â€œ*roberta-base-go_emotions*â€ model
    by SamLowe generates a suite of class labels. We can just as easily apply this
    model to text, as shown in the code snippet below.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼ŒHugging Face ä¸Šçš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹ä¸ä»…é™äºæ­£é¢-è´Ÿé¢æƒ…æ„Ÿã€‚ä¾‹å¦‚ï¼ŒSamLowe çš„â€œ*roberta-base-go_emotions*â€æ¨¡å‹ç”Ÿæˆäº†ä¸€å¥—ç±»åˆ«æ ‡ç­¾ã€‚æˆ‘ä»¬å¯ä»¥åƒä¸‹é¢çš„ä»£ç ç‰‡æ®µæ‰€ç¤ºä¸€æ ·è½»æ¾åœ°å°†æ­¤æ¨¡å‹åº”ç”¨äºæ–‡æœ¬ã€‚
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Summarization**'
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ€»ç»“**'
- en: Another way we can use the *pipeline()* function is for text summarization.
    Although this is an entirely different task than sentiment analysis, the syntax
    is almost identical.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥å°† *pipeline()* å‡½æ•°ç”¨äºæ–‡æœ¬æ€»ç»“ã€‚è™½ç„¶è¿™ä¸æƒ…æ„Ÿåˆ†ææ˜¯å®Œå…¨ä¸åŒçš„ä»»åŠ¡ï¼Œä½†è¯­æ³•å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚
- en: We first load in a summarization model. Then pass in some text along with a
    couple of input parameters.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆåŠ è½½ä¸€ä¸ªæ€»ç»“æ¨¡å‹ã€‚ç„¶åä¼ å…¥ä¸€äº›æ–‡æœ¬ä»¥åŠå‡ ä¸ªè¾“å…¥å‚æ•°ã€‚
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For more sophisticated use cases, it may be necessary to use multiple models
    in succession. For example, we can apply sentiment analysis to the summarized
    text to speed up the runtime.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ›´å¤æ‚çš„ç”¨ä¾‹ï¼Œå¯èƒ½éœ€è¦è¿ç»­ä½¿ç”¨å¤šä¸ªæ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ€»ç»“åçš„æ–‡æœ¬åº”ç”¨æƒ…æ„Ÿåˆ†æä»¥åŠ å¿«è¿è¡Œæ—¶é—´ã€‚
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Conversational**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å¯¹è¯å¼**'
- en: Finally, we can use models developed specifically to generate conversational
    text. Since conversations require past prompts and responses to be passed to subsequent
    model responses, the syntax is a little different here. However, we start by instantiating
    our model using the *pipeline()* function.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸“é—¨å¼€å‘çš„æ¨¡å‹æ¥ç”Ÿæˆå¯¹è¯æ–‡æœ¬ã€‚ç”±äºå¯¹è¯éœ€è¦å°†è¿‡å»çš„æç¤ºå’Œå“åº”ä¼ é€’åˆ°åç»­çš„æ¨¡å‹å“åº”ä¸­ï¼Œå› æ­¤è¯­æ³•åœ¨è¿™é‡Œç•¥æœ‰ä¸åŒã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ *pipeline()*
    å‡½æ•°æ¥å®ä¾‹åŒ–æˆ‘ä»¬çš„æ¨¡å‹ã€‚
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Next, we can use the *Conversation()* class to handle the back-and-forth. We
    initialize it with a user prompt, then pass it into the chatbot model from the
    previous code block.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ *Conversation()* ç±»æ¥å¤„ç†æ¥å›å¯¹è¯ã€‚æˆ‘ä»¬ç”¨ç”¨æˆ·æç¤ºåˆå§‹åŒ–å®ƒï¼Œç„¶åå°†å…¶ä¼ é€’ç»™å‰ä¸€ä¸ªä»£ç å—ä¸­çš„èŠå¤©æœºå™¨äººæ¨¡å‹ã€‚
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To keep the conversation going, we can use the *add_user_input()* method to
    add another prompt to the conversation. We then pass the conversation object back
    into the chatbot.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¿æŒå¯¹è¯è¿›è¡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ *add_user_input()* æ–¹æ³•å‘å¯¹è¯ä¸­æ·»åŠ å¦ä¸€ä¸ªæç¤ºã€‚ç„¶åæˆ‘ä»¬å°†å¯¹è¯å¯¹è±¡ä¼ é€’å›èŠå¤©æœºå™¨äººã€‚
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Chatbot UI with Gradio**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨ Gradio çš„èŠå¤©æœºå™¨äººç•Œé¢**'
- en: While we get the base chatbot functionality with the Transformer library, this
    is an inconvenient way to interact with a chatbot. To make the interaction a bit
    more intuitive, we can use **Gradio** to **spin up a front end in a few lines
    of Python code**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æˆ‘ä»¬é€šè¿‡ Transformer åº“è·å¾—äº†åŸºæœ¬çš„èŠå¤©æœºå™¨äººåŠŸèƒ½ï¼Œä½†è¿™ä¸èŠå¤©æœºå™¨äººäº¤äº’çš„æ–¹å¼å¹¶ä¸æ–¹ä¾¿ã€‚ä¸ºäº†ä½¿äº¤äº’æ›´ç›´è§‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **Gradio**
    æ¥ **ç”¨å‡ è¡Œ Python ä»£ç å¯åŠ¨å‰ç«¯**ã€‚
- en: This is done with the code shown below. At the top, we initialize two lists
    to store user messages and model responses, respectively. Then we define a function
    that will take the user prompt and generate a chatbot output. Next, we create
    the chat UI using the Gradio *ChatInterface()* class. Finally, we launch the app.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥é€šè¿‡ä¸‹é¢çš„ä»£ç å®Œæˆã€‚åœ¨é¡¶éƒ¨ï¼Œæˆ‘ä»¬åˆå§‹åŒ–ä¸¤ä¸ªåˆ—è¡¨ï¼Œåˆ†åˆ«ç”¨äºå­˜å‚¨ç”¨æˆ·æ¶ˆæ¯å’Œæ¨¡å‹å“åº”ã€‚ç„¶åæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°å°†æ¥æ”¶ç”¨æˆ·æç¤ºå¹¶ç”ŸæˆèŠå¤©æœºå™¨äººè¾“å‡ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨
    Gradio çš„*ChatInterface()* ç±»åˆ›å»ºèŠå¤©ç•Œé¢ã€‚æœ€åï¼Œæˆ‘ä»¬å¯åŠ¨åº”ç”¨ç¨‹åºã€‚
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will spin up the UI via a local URL. If the window does not open automatically,
    you can copy and paste the URL directly into your browser.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†é€šè¿‡æœ¬åœ° URL å¯åŠ¨ç”¨æˆ·ç•Œé¢ã€‚å¦‚æœçª—å£æ²¡æœ‰è‡ªåŠ¨æ‰“å¼€ï¼Œæ‚¨å¯ä»¥ç›´æ¥å°† URL å¤åˆ¶å¹¶ç²˜è´´åˆ°æµè§ˆå™¨ä¸­ã€‚
- en: '![](../Images/ec9de13ac0daaafaa94c91ccc160b476.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec9de13ac0daaafaa94c91ccc160b476.png)'
- en: Gradio interface. GIF by author.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Gradio ç•Œé¢ã€‚åŠ¨å›¾ç”±ä½œè€…æä¾›ã€‚
- en: '**Hugging Face Spaces**'
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Hugging Face Spaces**'
- en: To go one step further, we can quickly deploy this UI via **Hugging Face Spaces**.
    These are **Git repositories hosted by Hugging Face and augmented by computational
    resources**. Both free and paid options are available depending on the use case.
    Here we will stick with the free option.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´è¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ **Hugging Face Spaces** å¿«é€Ÿéƒ¨ç½²æ­¤ç”¨æˆ·ç•Œé¢ã€‚è¿™äº›æ˜¯ **ç”± Hugging Face æ‰˜ç®¡å¹¶ç”±è®¡ç®—èµ„æºå¢å¼ºçš„
    Git ä»“åº“**ã€‚æ ¹æ®ä½¿ç”¨æƒ…å†µï¼Œæœ‰å…è´¹å’Œä»˜è´¹é€‰é¡¹å¯ä¾›é€‰æ‹©ã€‚åœ¨è¿™é‡Œæˆ‘ä»¬å°†åšæŒä½¿ç”¨å…è´¹é€‰é¡¹ã€‚
- en: To make a new Space, we first go to the [Spaces page](https://huggingface.co/spaces)
    and click â€œCreate new spaceâ€. Then, configure the Space by giving it the name
    e.g. â€œmy-first-spaceâ€ and selecting Gradio as the SDK. Then hit â€œCreate Spaceâ€.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åˆ›å»ºä¸€ä¸ªæ–°çš„ Spaceï¼Œæˆ‘ä»¬é¦–å…ˆè®¿é—® [Spaces é¡µé¢](https://huggingface.co/spaces) å¹¶ç‚¹å‡»â€œåˆ›å»ºæ–°ç©ºé—´â€ã€‚ç„¶åï¼Œé€šè¿‡ç»™
    Space å‘½åï¼ˆä¾‹å¦‚â€œmy-first-spaceâ€ï¼‰å¹¶é€‰æ‹© Gradio ä½œä¸º SDK æ¥é…ç½® Spaceã€‚ç„¶åç‚¹å‡»â€œåˆ›å»º Spaceâ€ã€‚
- en: '![](../Images/90ba96ca925a2806699593653b3bc14b.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90ba96ca925a2806699593653b3bc14b.png)'
- en: Hugging Face Space configuration. Image by author.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face Space é…ç½®ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: Next, we need to upload app.py and requirements.txt files to the Space. The
    app.py file houses the code we used to generate the Gradio UI, and the requirements.txt
    file specifies the appâ€™s dependencies. The files for this example are available
    at the [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/hugging-face/my-first-space)
    and the [Hugging Face Space](https://huggingface.co/spaces/shawhin/my-first-space/tree/main).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å°† app.py å’Œ requirements.txt æ–‡ä»¶ä¸Šä¼ åˆ° Spaceã€‚app.py æ–‡ä»¶åŒ…å«äº†æˆ‘ä»¬ç”¨äºç”Ÿæˆ Gradio UI
    çš„ä»£ç ï¼Œè€Œ requirements.txt æ–‡ä»¶æŒ‡å®šäº†åº”ç”¨ç¨‹åºçš„ä¾èµ–é¡¹ã€‚è¿™ä¸ªç¤ºä¾‹çš„æ–‡ä»¶å¯ä»¥åœ¨ [GitHub ä»“åº“](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/hugging-face/my-first-space)
    å’Œ [Hugging Face Space](https://huggingface.co/spaces/shawhin/my-first-space/tree/main)
    ä¸­æ‰¾åˆ°ã€‚
- en: Finally, we push the code to the Space just like we would to GitHub. The end
    result is a public application hosted on Hugging Face Spaces.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å°†ä»£ç æ¨é€åˆ° Spaceï¼Œå°±åƒæˆ‘ä»¬æ¨é€åˆ° GitHub ä¸€æ ·ã€‚æœ€ç»ˆç»“æœæ˜¯ä¸€ä¸ªæ‰˜ç®¡åœ¨ Hugging Face Spaces ä¸Šçš„å…¬å¼€åº”ç”¨ç¨‹åºã€‚
- en: '**App link**: [https://huggingface.co/spaces/shawhin/my-first-space](https://huggingface.co/spaces/shawhin/my-first-space)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**åº”ç”¨é“¾æ¥**: [https://huggingface.co/spaces/shawhin/my-first-space](https://huggingface.co/spaces/shawhin/my-first-space)'
- en: '**Conclusion**'
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç»“è®º**'
- en: Hugging Face has become synonymous with open-source language models and machine
    learning. The biggest advantage of their ecosystem is it gives small-time developers,
    researchers, and tinkers access to powerful ML resources.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face å·²æˆä¸ºå¼€æºè¯­è¨€æ¨¡å‹å’Œæœºå™¨å­¦ä¹ çš„ä»£åè¯ã€‚ä»–ä»¬ç”Ÿæ€ç³»ç»Ÿçš„æœ€å¤§ä¼˜åŠ¿åœ¨äºä¸ºå°å‹å¼€å‘è€…ã€ç ”ç©¶äººå‘˜å’Œçˆ±å¥½è€…æä¾›äº†å¼ºå¤§çš„æœºå™¨å­¦ä¹ èµ„æºã€‚
- en: While we covered a lot of material in this post, weâ€™ve only scratched the surface
    of what the Hugging Face ecosystem can do. In future articles of this series,
    we will explore more advanced use cases and cover [how to fine-tune models](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    using ğŸ¤—Transformers.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡æˆ‘ä»¬åœ¨è¿™ç¯‡æ–‡ç« ä¸­è¦†ç›–äº†å¾ˆå¤šå†…å®¹ï¼Œä½†æˆ‘ä»¬ä»…ä»…è§¦åŠäº† Hugging Face ç”Ÿæ€ç³»ç»Ÿæ‰€èƒ½åšçš„çš®æ¯›ã€‚åœ¨æœ¬ç³»åˆ—çš„æœªæ¥æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨æ›´å¤šé«˜çº§ç”¨ä¾‹ï¼Œå¹¶ä»‹ç»
    [å¦‚ä½•å¾®è°ƒæ¨¡å‹](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    ä½¿ç”¨ ğŸ¤—Transformersã€‚
- en: 'ğŸ‘‰ **More on LLMs**: [Introduction](/a-practical-introduction-to-llms-65194dda1148)
    | [OpenAI API](https://medium.com/towards-data-science/cracking-open-the-openai-python-api-230e4cae7971)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    |'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ‘‰ **æ›´å¤šå…³äºLLMs**: [ä»‹ç»](/a-practical-introduction-to-llms-65194dda1148) | [OpenAI
    API](https://medium.com/towards-data-science/cracking-open-the-openai-python-api-230e4cae7971)
    | [æç¤ºå·¥ç¨‹](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    |'
- en: '[Fine-tuning](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [Build an LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [Text Embeddings](/text-embeddings-classification-and-semantic-search-8291746220be)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¾®è°ƒ](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [æ„å»ºLLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [æ–‡æœ¬åµŒå…¥](/text-embeddings-classification-and-semantic-search-8291746220be)'
- en: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
- en: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----350aa0ef0161--------------------------------)'
- en: Large Language Models (LLMs)
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs)
- en: '[View list](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----350aa0ef0161--------------------------------)13
    stories![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----350aa0ef0161--------------------------------)13ä¸ªæ•…äº‹![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
- en: Resources
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: èµ„æº
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**è”ç³»**: [æˆ‘çš„ç½‘ç«™](https://shawhintalebi.com/) | [é¢„çº¦ç”µè¯](https://calendly.com/shawhintalebi)
    | [å‘æˆ‘æé—®](https://shawhintalebi.com/contact/)'
- en: '**Socials**: [YouTube ğŸ¥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç¤¾äº¤åª’ä½“**: [YouTube ğŸ¥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) â˜•ï¸'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ”¯æŒ**: [è¯·æˆ‘å–å’–å•¡](https://www.buymeacoffee.com/shawhint) â˜•ï¸'
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----350aa0ef0161--------------------------------)
    [## Get FREE access to every new story I write'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/subscribe?source=post_page-----350aa0ef0161--------------------------------)
    [## å…è´¹è·å–æˆ‘å†™çš„æ¯ä¸€ä¸ªæ–°æ•…äº‹'
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create aâ€¦
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…è´¹è·å–æˆ‘å†™çš„æ¯ä¸€ä¸ªæ–°æ•…äº‹ é™„è¨€ï¼šæˆ‘ä¸ä¼šä¸ä»»ä½•äººåˆ†äº«ä½ çš„ç”µå­é‚®ä»¶ æ³¨å†Œåï¼Œä½ å°†åˆ›å»ºä¸€ä¸ªâ€¦
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----350aa0ef0161--------------------------------)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----350aa0ef0161--------------------------------)
- en: '[1] Hugging Face â€” [https://huggingface.co/](https://huggingface.co/)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Hugging Face â€” [https://huggingface.co/](https://huggingface.co/)'
- en: '[2] Hugging Face Course â€” [https://huggingface.co/learn/nlp-course/chapter1/1](https://huggingface.co/learn/nlp-course/chapter1/1)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Hugging Face è¯¾ç¨‹ â€” [https://huggingface.co/learn/nlp-course/chapter1/1](https://huggingface.co/learn/nlp-course/chapter1/1)'
