- en: When AutoML Meets Large Language Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当AutoML遇上大型语言模型
- en: 原文：[https://towardsdatascience.com/when-automl-meets-large-language-model-756e6bb9baa7](https://towardsdatascience.com/when-automl-meets-large-language-model-756e6bb9baa7)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/when-automl-meets-large-language-model-756e6bb9baa7](https://towardsdatascience.com/when-automl-meets-large-language-model-756e6bb9baa7)
- en: Leveraging the power of LLMs to guide hyperparameter searches
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用LLMs的力量来指导超参数搜索
- en: '[](https://shuaiguo.medium.com/?source=post_page-----756e6bb9baa7--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----756e6bb9baa7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----756e6bb9baa7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----756e6bb9baa7--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----756e6bb9baa7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----756e6bb9baa7--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----756e6bb9baa7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----756e6bb9baa7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----756e6bb9baa7--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----756e6bb9baa7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----756e6bb9baa7--------------------------------)
    ·23 min read·Oct 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----756e6bb9baa7--------------------------------)
    ·23分钟阅读·2023年10月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/cf26341128d5b5fbb82f432835e76c2d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf26341128d5b5fbb82f432835e76c2d.png)'
- en: Photo by [John Schnobrich](https://unsplash.com/@johnschno?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[约翰·施诺布里奇](https://unsplash.com/@johnschno?utm_source=medium&utm_medium=referral)拍摄于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: '*Automated machine learning*, or AutoML in short, aims to automate various
    steps of a machine learning pipeline. A crucial aspect of it is **hyperparameter
    tuning**. Hyperparameters refer to parameters that govern the structure and behavior
    of an ML algorithm (e.g., the number of layers in a neural network model), and
    the values of those parameters are set beforehand instead of learning from the
    data, unlike other ML parameters (e.g., weights and biases of a neural network
    layer).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*自动化机器学习*，简称AutoML，旨在自动化机器学习流程中的各个步骤。其中一个关键方面是**超参数调优**。超参数是指控制机器学习算法结构和行为的参数（例如，神经网络模型中的层数），这些参数的值在训练之前设定，而不是从数据中学习，这与其他机器学习参数（例如神经网络层的权重和偏置）不同。'
- en: The current practices used in AutoML for hyperparameter tuning rely heavily
    on sophisticated algorithms (such as [Bayesian optimization](https://medium.com/towards-data-science/an-introduction-to-surrogate-optimization-intuition-illustration-case-study-and-the-code-5d9364aed51b))
    to automatically identify the optimal combination of the hyperparameters that
    yields the best model performance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当前在AutoML中用于超参数调优的做法 heavily rely on sophisticated algorithms (such as [贝叶斯优化](https://medium.com/towards-data-science/an-introduction-to-surrogate-optimization-intuition-illustration-case-study-and-the-code-5d9364aed51b))
    to automatically identify the optimal combination of the hyperparameters that
    yields the best model performance.
- en: 'While approaching the hyperparameter tuning problems from a pure algorithmic
    point of view can work, there is another crucial piece of information that could
    complement the algorithmic search strategy: **human expertise**.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从纯算法的角度解决超参数调优问题虽然有效，但还有另一个重要的信息可以补充算法搜索策略：**人类专业知识**。
- en: Senior data scientists, based on their years of experience and deep understanding
    of the ML algorithms, often intuitively know where to initiate the search, which
    regions of the search space might be more promising, or when to narrow down or
    expand the possibilities.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 资深数据科学家凭借多年的经验和对机器学习算法的深刻理解，通常能够直观地知道从哪里开始搜索，哪些搜索空间的区域可能更有前景，或何时缩小或扩大可能性。
- en: 'Therefore, this gives us a very interesting idea: can we design a **scalable
    expertise-guided search strategy** that leverages both the nuanced insights provided
    by the expert and the search efficiency offered by the AutoML algorithms?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这给了我们一个非常有趣的想法：我们能否设计一个**可扩展的专家指导搜索策略**，既利用专家提供的细致见解，又结合AutoML算法提供的搜索效率？
- en: This is where the **large language models** (LLM), such as GPT-4, can play a
    role. Among their vast amount of training data, a certain portion of the corpus
    contains texts that are dedicated to explaining and discussing the best practices
    of machine learning (ML). Thanks to that, the LLMs are able to internalize a substantial
    amount of ML expertise and obtain a significant chunk of the collective ML wisdom.
    This positions LLMs as potential knowledgable ML experts who can interact with
    the existing AutoML tool to collaboratively perform expert-guided hyperparameter
    tuning.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**大语言模型**（LLM），例如 GPT-4，可以发挥作用的地方。在它们的大量训练数据中，有一部分文本专门用于解释和讨论机器学习（ML）的最佳实践。由于这一点，LLM
    能够内化大量的 ML 专业知识，并获得大量的集体 ML 智慧。这使得 LLM 作为潜在的知识渊博的 ML 专家，可以与现有的 AutoML 工具进行互动，共同进行专家指导的超参数调整。
- en: '![](../Images/6ddfb39d0a9b05fc40b3bbe3f19050ec.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ddfb39d0a9b05fc40b3bbe3f19050ec.png)'
- en: An illustration of LLM-guided hyperparameter tuning. (Image by author)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 指导的超参数调整示例。（图像作者提供）
- en: In this blog post, let’s take this idea for a spin and implement an **LLM-guided
    hyperparameter tuning workflow**. Specifically, we will develop a workflow that
    combines LLM guidance with a simple random search, and then compare its tuning
    results against an off-the-shelf, state-of-the-art, algorithmic-based AutoML tool
    called [FLAML](https://microsoft.github.io/FLAML/) (from Microsoft Research).
    The rationale for this comparison is to assess if tapping into ML domain expertise
    can truly bring value, even when paired with a straightforward search algorithm.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，让我们尝试这个想法，并实现一个**由 LLM 指导的超参数调整工作流**。具体来说，我们将开发一个将 LLM 指导与简单随机搜索相结合的工作流，然后将其调整结果与一种名为[FLAML](https://microsoft.github.io/FLAML/)（微软研究院开发的最先进的算法驱动的
    AutoML 工具）的现成工具进行比较。进行这种比较的理由是评估即使与简单的搜索算法配对，借助 ML 领域专业知识是否真的能带来价值。
- en: Does this idea resonate with you? let’s get started!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法与你有共鸣吗？那就开始吧！
- en: '[NOTE]: All the prompts shown in this blog are generated and optimized by ChatGPT
    (GPT-4). This is necessary as it ensures the quality of the prompts and beneficial
    as it saves one from tedious manual prompt engineering.'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[注]: 本博客中展示的所有提示均由 ChatGPT (GPT-4) 生成并优化。这是必要的，因为它确保了提示的质量，并且有助于避免繁琐的手动提示工程。'
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is the 4rd blog on my series of LLM projects. The 1st one is [Building
    an AI-Powered Language Learning App](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd),
    the 2nd one is [Developing an Autonomous Dual-Chatbot System for Research Paper
    Digesting](/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343),
    and the 3rd one is [Training Problem-Solving Skills in Data Science with Real-Life
    Simulations](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c).
    Feel free to check them out!
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是我关于 LLM 项目的系列博客中的第四篇。第一篇是 [构建 AI 驱动的语言学习应用](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)，第二篇是
    [开发用于研究论文摘要的自主双聊天机器人系统](/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343)，第三篇是
    [通过现实生活模拟训练数据科学中的问题解决技能](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c)。欢迎查看！
- en: Table of Content
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: '**·** [**1\. Case Study**](#9ff4)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**1\. 案例研究**](#9ff4)'
- en: ∘ [1.1 Dataset description](#0e69)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [1.1 数据集描述](#0e69)
- en: ∘ [1.2 Model description](#48d1)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [1.2 模型描述](#48d1)
- en: '**·** [**2\. Workflow Design**](#6418) **·** [**3\. Configuring the Chatbot**](#f2d7)
    **·** [**4\. Suggesting Optimization Metric**](#06cb) **·** [**5\. Defining Initial
    Search Space**](#1a84) **·** [**6\. Refining Search Space**](#c4be) **·** [**7\.
    Tuning Log Analysis**](#b34a)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**2\. 工作流设计**](#6418) **·** [**3\. 配置聊天机器人**](#f2d7) **·** [**4\. 建议优化度量**](#06cb)
    **·** [**5\. 定义初始搜索空间**](#1a84) **·** [**6\. 精炼搜索空间**](#c4be) **·** [**7\. 调整日志分析**](#b34a)'
- en: ∘ [7.1 Random search with successive halving](#eaa7)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [7.1 随机搜索与连续减半](#eaa7)
- en: ∘ [7.2 Log analysis](#f702)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [7.2 日志分析](#f702)
- en: '**·** [**8\. Case Study**](#edc2)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**8\. 案例研究**](#edc2)'
- en: ∘ [8.1 Determining metric](#f0ac)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [8.1 确定度量](#f0ac)
- en: ∘ [8.2 1st search iteration](#56af)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [8.2 第一次搜索迭代](#56af)
- en: ∘ [8.3 2nd search iteration](#9055)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [8.3 第二次搜索迭代](#9055)
- en: ∘ [8.4 3rd search iteration](#950f)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [8.4 第三次搜索迭代](#950f)
- en: ∘ [8.5 Testing](#b072)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [8.5 测试](#b072)
- en: '**·** [**9\. Comparison Against Out-of-Box AutoML Tool**](#19b1) **·** [**10\.
    Conclusion**](#2ddd)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**·** [**9\. 与现成 AutoML 工具的比较**](#19b1) **·** [**10\. 结论**](#2ddd)'
- en: 1\. Case Study
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 案例研究
- en: To ground our discussion in a concrete example, let’s start by introducing the
    case study we will investigate.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们的讨论具体化，让我们首先介绍一下我们将要调查的案例研究。
- en: In this blog, we will be looking at a hyperparameter tuning task for a **binary
    classification** problem. More specifically, we will investigate a cybersecurity
    dataset called the [**NSL-KDD**](https://www.unb.ca/cic/datasets/nsl.html) dataset
    and identify the optimal hyperparameters of an [**XGBoost**](https://xgboost.readthedocs.io/en/stable/)model
    such that the trained model can accurately distinguish benign and attack activities.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本博客中，我们将查看一个**二分类**问题的超参数调优任务。更具体地，我们将研究一个名为[**NSL-KDD**](https://www.unb.ca/cic/datasets/nsl.html)的网络安全数据集，并识别[**XGBoost**](https://xgboost.readthedocs.io/en/stable/)模型的最佳超参数，以便训练出的模型可以准确区分良性和攻击活动。
- en: 1.1 Dataset description
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 数据集描述
- en: 'The NSL-KDD dataset is a widely used dataset in the field of network intrusion
    detection. The full dataset contains four attack categories, i.e., dos(Denial
    of Service), r2l(unauthorized Access from a Remote Machine), u2r(privilege escalation
    attempts), as well as probe (brute-force probing attacks). For our current case
    study, we investigate a *binary classification* problem: we only consider data
    samples that are either “benign” or “probe” in nature and train a classifier that
    can distinguish between those two states.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: NSL-KDD数据集是网络入侵检测领域广泛使用的数据集。完整的数据集包含四种攻击类别，即dos（拒绝服务）、r2l（远程机器的未经授权访问）、u2r（权限提升尝试）以及probe（暴力探测攻击）。在我们当前的案例研究中，我们研究一个*二分类*问题：我们只考虑“良性”或“探测”性质的数据样本，并训练一个能够区分这两种状态的分类器。
- en: 'The NSL-KDD dataset consists of 40 features (e.g., connection length, protocol
    type, transmitted data bytes, etc.) that are derived from raw network traffic
    data, and capture various characteristics of individual network connections. The
    dataset has been pre-divided into a train and a test set. The following table
    shows the number of samples in both sets:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: NSL-KDD数据集包含40个特征（例如，连接长度、协议类型、传输数据字节等），这些特征源自原始网络流量数据，捕获了单个网络连接的各种特征。数据集已经预先划分为训练集和测试集。下表显示了两个集合中的样本数量：
- en: '![](../Images/147d68e05fb8230c6c1f69a5970e892d.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/147d68e05fb8230c6c1f69a5970e892d.png)'
- en: Number of samples in train and test set. (Image by author)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集和测试集中样本的数量。（图片作者提供）
- en: Notice that our current dataset is imbalanced. This is typical in cybersecurity
    applications as the available number of attack samples is usually much smaller
    than the number of benign samples.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们当前的数据集是不平衡的。这在网络安全应用中很常见，因为可用的攻击样本数量通常远小于良性样本的数量。
- en: You can find the pre-processed datasets [here](https://github.com/ShuaiGuo16/LLM-guided-AutoML/tree/main/dataset).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://github.com/ShuaiGuo16/LLM-guided-AutoML/tree/main/dataset)找到预处理的数据集。
- en: 1.2 Model description
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 模型描述
- en: Although the full AutoML entails model selection, in the current case study,
    we limit our scope to only optimizing the XGBoost model. XGBoost model is known
    for its versatile performance, under the condition that the right model hyperparameters
    are being used. Unfortunately, given the large number of tunable hyperparameters
    of XGBoost, it is non-trivial to identify the optimal hyperparameter combination
    for a given dataset. This is exactly where AutoML can bring value.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管完整的AutoML包括模型选择，但在当前的案例研究中，我们将范围限制在仅优化XGBoost模型。XGBoost模型以其多才多艺的性能而闻名，但前提是使用了正确的模型超参数。不幸的是，由于XGBoost的超参数数量众多，确定给定数据集的最佳超参数组合并不容易。这正是AutoML可以发挥作用的地方。
- en: 'We consider tuning the following XGBoost hyperparameters:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们考虑调整以下XGBoost超参数：
- en: n_estimators, max_depth, min_child_weight, gamma, scale_pos_weight, learning_rate,
    subsample, colsample_bylevel, colsample_bytree, reg_alpha, and reg_lambda.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: n_estimators, max_depth, min_child_weight, gamma, scale_pos_weight, learning_rate,
    subsample, colsample_bylevel, colsample_bytree, reg_alpha, 和 reg_lambda。
- en: For detailed descriptions of the above-mentioned hyperparameters, please refer
    to the [official documentation](https://xgboost.readthedocs.io/en/stable/).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 关于上述超参数的详细描述，请参阅[官方文档](https://xgboost.readthedocs.io/en/stable/)。
- en: 2\. Workflow Design
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 工作流设计
- en: 'To realize the LLM-guided hyperparameter tuning, there are two questions we
    need to answer: how should we incorporate the LLM’s ML expertise into the tuning
    process? And how should we let LLM interact with the tuning tool?'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现LLM指导的超参数调优，我们需要回答两个问题：我们应该如何将LLM的机器学习专业知识融入调优过程？我们应该如何让LLM与调优工具互动？
- en: 1️⃣ How to incorporate the LLM’s ML expertise into the tuning process?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 1️⃣ 如何将 LLM 的机器学习专业知识融入调整过程中？
- en: 'Well, there are at least three places in the tuning process where LLM’s ML
    expertise can provide guidance:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，在调整过程中至少有三个地方，LLM 的机器学习专业知识可以提供指导：
- en: '**Suggest optimization metric**: Hyperparameter tuning usually requires a metric
    to define what is deemed as “optimal” among various competing hyperparameter combinations.
    This sets the target for the underlying optimization algorithms (e.g., Bayesian
    optimization) in AutoML. LLMs can provide insights into which metrics are more
    suitable for specific types of problems and dataset characteristics and potentially
    offer explanations of the advantages and disadvantages of candidate metrics.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**建议优化指标**：超参数调整通常需要一个指标来定义在各种竞争的超参数组合中什么被认为是“最优”的。这为基础的优化算法（例如，贝叶斯优化）设定了目标。LLMs
    可以提供关于哪些指标更适合特定类型问题和数据集特征的见解，并可能提供对候选指标的优缺点解释。'
- en: '**Suggest initial search space**: As most hyperparameter tuning tasks are conducted
    in an iterative manner, it is usually necessary to configure an initial search
    space to set the stage for the optimization process. LLMs, based on their learned
    ML best practices, can recommend hyperparameter ranges that are meaningful to
    the investigated dataset characteristics and the selected ML model. This can potentially
    reduce the need for unnecessary explorations, thus saving a significant amount
    of computation time.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**建议初始搜索空间**：由于大多数超参数调整任务是以迭代方式进行的，通常需要配置初始搜索空间以为优化过程奠定基础。基于其学习的机器学习最佳实践，LLMs
    可以推荐对研究数据集特征和选定机器学习模型有意义的超参数范围。这可以潜在地减少不必要的探索，从而节省大量计算时间。'
- en: '**Suggest refinement for search space**: As the tuning process progresses,
    it is usually necessary to refine the configured search space. Refinement can
    take two directions, i.e., narrowing down the ranges of certain hyperparameters
    to regions that show promise, or expanding the ranges of certain hyperparameters
    to explore new areas. LLMs, by analyzing the optimization logs from the previous
    rounds, can automatically propose new refinements that drive the tuning process
    to more promising results.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**建议搜索空间的细化**：随着调整过程的推进，通常需要对配置的搜索空间进行细化。细化可以朝两个方向进行，即缩小某些超参数的范围到显示出前景的区域，或扩展某些超参数的范围以探索新的领域。通过分析前几轮的优化日志，大型语言模型（LLMs）可以自动提出新的细化建议，将调整过程引导向更有前景的结果。'
- en: 2️⃣ How to let LLM interact with the tuning tool?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 2️⃣ 如何让 LLM 与调整工具进行互动？
- en: 'Ideally, we could wrap the random search tool as an API and implement an LLM-based
    **agent** that can access this API to perform tuning. However, given the limited
    time, I didn’t manage to configure a working agent that could reliably perform
    the iterative tuning process I outlined above: sometimes the agent couldn’t properly
    use the tool due to the incorrect input schema; other times the agent simply diverged
    from the task.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们可以将随机搜索工具封装为 API，并实现一个基于 LLM 的**代理**，该代理可以访问这个 API 来进行调整。然而，由于时间有限，我未能配置一个能够可靠执行上述迭代调整过程的工作代理：有时代理由于输入模式不正确而无法正确使用工具；其他时候代理则完全偏离了任务。
- en: 'Alternatively, I implemented a simple chatbot-based workflow, which consists
    of the following two components:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 作为替代，我实现了一个简单的基于聊天机器人的工作流，其中包含以下两个组件：
- en: A chatbot with memory. Here, memory is important because the chatbot needs to
    recall the previously suggested search space.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有记忆的聊天机器人。在这里，记忆很重要，因为聊天机器人需要回忆之前建议的搜索空间。
- en: Three prompts correspond to suggesting optimization metric, suggesting initial
    search space, and suggesting search space refinement, respectively.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个提示分别对应建议优化指标、建议初始搜索空间和建议搜索空间的细化。
- en: To kick-start the workflow, the chatbot is first prompted to suggest a suitable
    optimization metric based on the problem context and the dataset characteristics.
    The chatbot’s response will then be parsed and the name of the metric will be
    extracted and stored as a variable. As a second step, the chatbot is prompted
    to suggest an initial search space. Same as in the first step, the response will
    be parsed and the search space will be extracted and stored as a variable. With
    both pieces of information available, the random search tool will be invoked with
    the chatbot-suggested metric and search space. Overall, this constitutes the first
    round of iterations.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启动工作流，首先提示聊天机器人根据问题背景和数据集特征建议一个合适的优化指标。然后解析聊天机器人的响应，提取并存储指标名称作为变量。第二步，提示聊天机器人建议一个初始搜索空间。与第一步一样，解析响应并提取搜索空间，存储为变量。获得这两个信息后，将调用随机搜索工具，使用聊天机器人建议的指标和搜索空间。总体而言，这构成了第一轮迭代。
- en: Once the random search tool completes the search, the chatbot will be prompted
    to recommend refinement of the search space based on the results obtained from
    the last run. After a new search space is successfully parsed from the chatbot’s
    response, another round of random search will proceed. This process iterates until
    either the computational budget is exhausted, or the convergence is obtained,
    e.g., no more improvement over the previous run.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦随机搜索工具完成搜索，将提示聊天机器人根据上一次运行的结果推荐搜索空间的细化。在成功解析聊天机器人的响应中的新搜索空间后，将进行另一轮随机搜索。这个过程会迭代，直到计算预算耗尽或达到收敛，例如，较上次运行没有更多改进。
- en: '![](../Images/0c217e54637dd58fd79a95279472c13d.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c217e54637dd58fd79a95279472c13d.png)'
- en: An illustration of a chatbot-based solution for achieving LLM-guided hyperparameter
    tuning. (Image by author)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 基于聊天机器人的解决方案，用于实现 LLM 引导的超参数调优。（图像由作者提供）
- en: 'Although not as elegant as the agent-based approach, this chatbot-based workflow
    bears a couple of benefits:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不如基于代理的方法优雅，这种基于聊天机器人的工作流具有几个好处：
- en: '**Easy to implement and realize quality control**. The integration of a chatbot
    with the tuning tool is simplified to designing three prompts and a couple of
    helper functions to extract target information from the chatbot’s response. This
    is much simpler compared to a fully integrated agent-based approach. Also, quality
    control becomes more manageable as the hyperparameter tuning task is divided into
    explicit steps, where each step can be monitored and adjusted, ensuring that the
    search process remains on track.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于实现和实现质量控制**。将聊天机器人与调优工具集成简化为设计三个提示和几个辅助函数，以从聊天机器人的响应中提取目标信息。这比完全集成的基于代理的方法要简单得多。此外，由于超参数调优任务被分解为明确的步骤，每一步都可以被监控和调整，从而使质量控制变得更可控，确保搜索过程保持在轨道上。'
- en: '**Fully transparent decision-making**. As the chatbot will clearly articulate
    each decision or recommendation it has made, the hyperparameter tuning process
    is no longer a black-box process for the user. This is crucial for achieving *interpretable*
    and *trustworthy* AutoML.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完全透明的决策过程**。由于聊天机器人会清晰地说明其做出的每个决策或建议，超参数调优过程不再是对用户的黑箱过程。这对于实现*可解释的*和*值得信赖的*
    AutoML 至关重要。'
- en: '**Allow incorporation of human intuition**. Although the current workflow is
    designed to be autonomous, it can be trivially extended to allow the human expert
    to either choose to accept the advice or make necessary adjustments based on their
    own expertise, before each search iteration. This flexibility opens the door for
    *human-in-the-loop tuning* and potentially leads to better optimization results.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**允许结合人类直觉**。尽管当前的工作流设计为自动化，但可以轻松扩展，以允许人类专家在每次搜索迭代之前选择接受建议或根据自己的专业知识进行必要的调整。这种灵活性为*人类参与的调优*打开了大门，可能会导致更好的优化结果。'
- en: In the next sections, we will go through the details of configuring the chatbot,
    as well as the prompts for suggesting the metric, initial search space, and search
    space refinement, individually.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将逐一详细介绍配置聊天机器人以及建议指标、初始搜索空间和搜索空间细化的提示。
- en: 3\. Configuring the Chatbot
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 配置聊天机器人
- en: 'We can easily set up a chatbot with memory using LangChain. We start by importing
    the necessary libraries:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 LangChain 轻松设置一个具有记忆的聊天机器人。我们首先导入必要的库：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In LangChain, a chatbot can be configured by an`ConversationChain` object,
    which requires a backbone LLM, a memory object to hold conversation history, as
    well as a prompt template to specify the chatbot’s behavior:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LangChain 中，聊天机器人可以通过`ConversationChain`对象进行配置，这需要一个主干 LLM、一个用于保存对话历史的内存对象以及一个用于指定聊天机器人行为的提示模板：
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the code snippet above, the variable `system_message` sets the context for
    the chatbot, which is shown below:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码片段中，变量`system_message`设置了聊天机器人的上下文，如下所示：
- en: '[PRE2]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that we have specified the role, the purpose, and the expected behavior
    of the chatbot in the system message. Later, we can make inferences with the configured
    chatbot using:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在系统消息中指定了聊天机器人的角色、目的和预期行为。稍后，我们可以使用配置好的聊天机器人进行推理：
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: where the `prompt`is the specific instructions we have for the chatbot, i.e.,
    suggesting optimization metric, suggesting initial search space, or suggesting
    refining search space. We will cover those prompts in the next couple of sections.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 `prompt` 是我们对聊天机器人的具体指令，即建议优化度量标准、建议初始搜索空间或建议优化搜索空间。我们将在接下来的几节中介绍这些提示。
- en: 4\. Suggesting Optimization Metric
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 建议优化度量标准
- en: As the first step of LLM-guided hyperparameter tuning, we would like the chatbot
    to propose a suitable metric for the tuning tool to optimize. This decision should
    be based on several factors, including the nature of the problem (i.e., regression
    or classification), the characteristics of the given dataset, and any other specific
    requirements from business or real-world implications.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 LLM 引导的超参数调整的第一步，我们希望聊天机器人提出一个合适的度量标准，以便调整工具进行优化。这个决定应基于几个因素，包括问题的性质（即回归还是分类）、给定数据集的特征，以及来自业务或实际应用的其他具体要求。
- en: 'The following snippet defines the prompt to achieve our goal:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下片段定义了实现我们目标的提示：
- en: '[PRE4]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the prompt shown above, we have informed the chatbot of the context of the
    problem, the dataset characteristics (encapsulated in the variable `report`, which
    we will discuss later), the objective (recommending a suitable hyperparameter
    optimization metric for training an XGBoost model), the specific requirements
    (high detection rate and low false alarm rate), and the candidate metrics (they
    are all supported in sci-kit learn). Note that we explicitly asked the chatbot
    to output the metric name inside a [BEGIN]-[END] block, which eases the automatic
    extraction of the information.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的提示中，我们已经向聊天机器人说明了问题的背景、数据集特征（封装在变量`report`中，我们稍后将讨论），目标（推荐一个适合的超参数优化度量标准用于训练
    XGBoost 模型）、具体要求（高检测率和低误报率）以及候选度量标准（它们都在 sci-kit learn 中受支持）。注意，我们明确要求聊天机器人将度量标准名称输出在[BEGIN]-[END]块内，这样可以方便地自动提取信息。
- en: 'To generate the data report, we can define the following function:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成数据报告，我们可以定义以下函数：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, we specifically calculated if the given dataset is imbalanced, as this
    information could impact the selection of the optimization metric.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们特别计算了给定的数据集是否存在不平衡，因为这一信息可能会影响优化度量标准的选择。
- en: Now we have completed the first prompt for instructing the chatbot to suggest
    a suitable metric for evaluating the performance of various hyperparameter configurations.
    Next, let’s look at constructing the prompt for defining the initial search space.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了第一个提示，指示聊天机器人建议一个适合的度量标准来评估各种超参数配置的性能。接下来，让我们看看如何构建定义初始搜索空间的提示。
- en: '**5\. Defining Initial Search Space**'
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**5\. 定义初始搜索空间**'
- en: 'Besides the optimization metric, we still need an initial search space of the
    hyperparameters to start the tuning round. The following snippet shows the prompt
    for achieving that goal:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了优化度量标准，我们还需要一个超参数的初始搜索空间来开始调整过程。以下片段展示了实现这一目标的提示：
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The prompt above contains quite a lot of information, so let’s break it down:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的提示包含了大量信息，所以我们来逐步拆解：
- en: We started by informing the chatbot about our objective.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们首先向聊天机器人说明了我们的目标。
- en: We provided a list of tunable hyperparameters and their meanings. Additionally,
    we also indicate the expected data type of each hyperparameter. This piece of
    information is important for the LLM to decide the sampling distribution.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们提供了一个可调超参数及其含义的列表。此外，我们还指出了每个超参数的预期数据类型。这些信息对 LLM 决定采样分布至关重要。
- en: We defined the expected output format for the search space for effective parsing.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了搜索空间的预期输出格式，以便进行有效解析。
- en: We indicated available sampling distributions the LLM can suggest.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们指明了LLM可以建议的可用采样分布。
- en: Note that we explicitly asked the chatbot to briefly explain the rationale behind
    the suggested search space. This is crucial for achieving transparency and interpretability.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们明确要求聊天机器人简要说明建议的搜索空间的理由。这对于实现透明度和可解释性至关重要。
- en: That’s it for recommending the initial search space. Next, we look at refining
    the search space.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是推荐初始搜索空间的内容。接下来，我们来看看如何优化搜索空间。
- en: 6\. Refining Search Space
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 优化搜索空间
- en: After obtaining the optimization metric and initial search space from the chatbot,
    we can kick-start a tuning round. Afterward, we can feed the generated AutoML
    logs into the chatbot and prompt it to suggest refinements to the search space.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在从聊天机器人获取优化指标和初始搜索空间后，我们可以启动一次调优轮次。随后，我们可以将生成的AutoML日志输入到聊天机器人中，并提示它建议对搜索空间进行优化。
- en: 'The following snippet shows the prompt to achieve the goal:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了实现目标的提示：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'There are a couple of things worth explaining:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个值得解释的地方：
- en: We supply the chatbot with the top-5 best-performing configurations as well
    as their associated test scores from the last tuning round. This could serve as
    the base for the chatbot to determine the next round of refinement.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们向聊天机器人提供了上一次调优轮次中表现最好的前5个配置及其相关测试分数。这可以作为聊天机器人确定下一轮优化的基础。
- en: By including the best test scores of the last run and all previous runs, the
    chatbot could know if the suggested search space from the previous run is effective
    or not.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过包括上一次运行的最佳测试分数和所有之前的运行，聊天机器人可以判断上次运行中建议的搜索空间是否有效。
- en: We explicitly ask the chatbot to consider further exploring the search space.
    Generally, the best practice in optimization is to **balance exploration and exploitation**.
    Since our employed random search algorithm (which will be discussed in the results
    section) already entailed the *exploitation*, it makes sense that we instruct
    the LLM to focus more on *exploration*.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们明确要求聊天机器人考虑进一步探索搜索空间。一般而言，优化的最佳实践是**平衡探索与利用**。由于我们使用的随机搜索算法（将在结果部分讨论）已经涵盖了*利用*，因此让LLM更多地关注*探索*是合理的。
- en: As with the other prompts, we asked the LLM to reason about its suggestions
    for transparency and interpretability.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他提示类似，我们要求LLM对其建议进行推理，以确保透明度和可解释性。
- en: In the next section, let’s take a look at the log analysis logic that produces
    the `top_n` variable.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，让我们看看生成`top_n`变量的日志分析逻辑。
- en: 7\. Tuning Log Analysis
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. 调优日志分析
- en: As an iterative approach, we would like the chatbot to propose a new search
    space once the previous search run has been completed, and the basis for that
    decision-making process should be the log produced during the last search run.
    In this section, we first introduced the search algorithm employed in the current
    case study. Then, we discuss the log structure and the code to extract useful
    insights.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种迭代方法，我们希望聊天机器人在上一轮搜索完成后提出新的搜索空间，而决策过程的基础应该是上一轮搜索中生成的日志。在本节中，我们首先介绍了当前案例研究中使用的搜索算法。然后，我们讨论了日志结构和提取有用见解的代码。
- en: 7.1 Random search with successive halving
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 逐步折半的随机搜索
- en: As mentioned at the beginning of this post, we would like to couple a simple
    hyperparameter search algorithm with the LLM to examine if domain expertise can
    bring value.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本文开头所提到的，我们希望将一种简单的超参数搜索算法与LLM结合，以检验领域专业知识是否能带来价值。
- en: 'One of the simplest tuning approaches is **random search**: for a defined search
    space (which is specified by attaching sampling distributions to the hyperparameters),
    a given number of instances of hyperparameter combinations are sampled and their
    associated model performances are evaluated. The sampled hyperparameter configuration
    which produced the best performance is deemed as the best.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的调优方法之一是**随机搜索**：对于一个定义好的搜索空间（通过将采样分布附加到超参数上来指定），对给定数量的超参数组合实例进行采样，并评估其相关的模型性能。产生最佳性能的采样超参数配置被认为是最佳的。
- en: Despite its simplicity, the naive version of the random search may lead to inefficient
    use of computational resources, as it does not discriminate between hyperparameter
    configurations and poor hyperparameter choices are trained anyway.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其简单性，随机搜索的朴素版本可能导致计算资源的低效使用，因为它不区分超参数配置，而不良的超参数选择仍然会被训练。
- en: To address this issue, the **successive halving** technique is proposed to enhance
    the basic random search strategy. Essentially, a successive halving strategy first
    evaluates many configurations for a small number of resources, and then gradually
    allocates more resources to only the promising ones. As a result, poor configurations
    can be effectively discarded early on, therefore enhancing the search efficiency.
    Sci-kit Learn provides the`[HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html)`
    estimator that exactly implements this strategy, which we will adopt in our current
    case study.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为解决这个问题，提出了**连续折半**技术，以增强基本的随机搜索策略。基本上，连续折半策略首先使用少量资源评估许多配置，然后逐渐将更多资源分配给有前景的配置。因此，劣质配置可以在早期有效地被淘汰，从而提高搜索效率。Sci-kit
    Learn提供了精确实现这一策略的`[HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html)`估算器，我们将在当前案例研究中采用。
- en: 7.2 Log analysis
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 日志分析
- en: 'When running the `[HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html)`
    search, the search logs are stored in the attribute `cv_results_`. The raw logs
    are in a dictionary format, which can be converted to a Pandas Dataframe for better
    insights extraction:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行`[HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html)`搜索时，搜索日志存储在属性`cv_results_`中。原始日志以字典格式存储，可以转换为Pandas数据框以便于提取见解：
- en: '![](../Images/d792bd9f77cdd9399c163cc7a0f550f6.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d792bd9f77cdd9399c163cc7a0f550f6.png)'
- en: Logs produced by the search algorithm. (Examples taken from the [official user
    guide](https://scikit-learn.org/stable/modules/grid_search.html#successive-halving-cv-results).)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索算法生成的日志。（示例取自[官方用户指南](https://scikit-learn.org/stable/modules/grid_search.html#successive-halving-cv-results)。）
- en: 'For our current purposes, we would like to extract the top-N (default 5) best-performing
    configurations as well as their associated test scores. The following function
    shows how we can achieve that:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们当前的目的，我们希望提取表现最好的前N个（默认5个）配置及其相关的测试分数。以下函数展示了我们如何实现这一目标：
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 8\. Case Study
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8\. 案例研究
- en: Now we have all the pieces, it’s time to apply the LLM-guided workflow to our
    case study.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了所有的要素，是时候将LLM指导的工作流程应用于我们的案例研究了。
- en: 8.1 Determining metric
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 确定度量标准
- en: 'To begin with, we prompt the LLM to suggest a suitable optimization metric:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们提示LLM建议一个合适的优化度量标准：
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following is the response produced by the LLM:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是LLM生成的响应：
- en: '![](../Images/4de8c745b8dcf8e34ba6db0c3e505e68.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4de8c745b8dcf8e34ba6db0c3e505e68.png)'
- en: LLM suggested a suitable metric and provided the reasoning. (Image by author)
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: LLM建议了一个合适的度量标准，并提供了理由。（图片作者提供）
- en: We can see that the LLM recommended the “F1” score as the metric based on the
    problem context and dataset characteristics, which aligns with our expectations.
    In addition, the metric name is correctly enclosed between our specified markers
    for postprocessing.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，LLM根据问题背景和数据集特征推荐了“F1”分数作为度量标准，这与我们的期望一致。此外，度量标准名称被正确地封装在我们指定的后处理标记之间。
- en: 8.2 1st search iteration
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 第一次搜索迭代
- en: 'Next, we prompt the LLM to suggest an initial search space:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们提示LLM建议一个初步的搜索空间：
- en: '[PRE10]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output of LLM is shown below:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的输出如下所示：
- en: '![](../Images/600300d6a76769e45671c9ec4a119283.png)![](../Images/4f43e2b130e9c79be142e94115b2f1ce.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/600300d6a76769e45671c9ec4a119283.png)![](../Images/4f43e2b130e9c79be142e94115b2f1ce.png)'
- en: LLM suggested an initial search space and provided the reasoning. (Image by
    author)
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: LLM建议了一个初步的搜索空间，并提供了理由。（图片作者提供）
- en: We can see that the LLM has faithfully followed our instructions and provided
    detailed explanations regarding setting the variational range for each of the
    tunable hyperparameters. This is crucial for ensuring the transparency of the
    hyperparameter tuning process. Also, note that the LLM has managed to output a
    search space with the correct format. This shows the importance of giving specific
    examples in the prompt design.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，LLM忠实地遵循了我们的指示，并提供了有关设置每个可调超参数的变异范围的详细说明。这对确保超参数调优过程的透明性至关重要。此外，请注意LLM成功输出了正确格式的搜索空间。这显示了在提示设计中提供具体示例的重要性。
- en: 'Then, we invoke the random search with successive halving and run for the first
    iteration:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们调用随机搜索与连续折半，并运行第一次迭代：
- en: '[PRE11]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note that the `HalvingRandomSearchCV` estimator is still experimental. Therefore,
    it is necessary to first explicitly import `enable_halving_search_cv` before using
    the estimator.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`HalvingRandomSearchCV` 估计器仍处于实验阶段。因此，在使用估计器之前，必须首先显式导入 `enable_halving_search_cv`。
- en: 'Using the `HalvingRandomSearchCV` estimator requires setting up a couple of
    parameters. In addition to specifying the estimator (clf), the parameter distribution
    (search space), and the optimization metric (f1), we also need to specify the
    parameters that govern the time budget. For our current case, we set `n_candidates`
    to 500, which means that we will sample 500 candidate configurations (each configuration
    has a different hyperparameter combination) at the first iteration. Also, the
    `factor` is set to 3, meaning that only one-third of the candidates are selected
    for each subsequent iteration. Meanwhile, those selected one-third of the candidates
    will use 3 times more resources (i.e., the number of training samples) in the
    subsequent iteration. Finally, we set `min_resource` to ‘exhaust’, meaning that
    at the last iteration, the remaining candidates will use all the available training
    samples. For a detailed description of setting up the `HalvingRandomSearchCV`
    estimator, please refer to this post: [11 Times Faster Hyperparameter Tuning with
    HalvingGridSearch](/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232ed0160155).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `HalvingRandomSearchCV` 估计器需要设置几个参数。除了指定估计器（clf）、参数分布（搜索空间）和优化指标（f1）外，我们还需要指定控制时间预算的参数。在我们的案例中，我们将
    `n_candidates` 设置为500，这意味着我们将在第一次迭代中抽取500个候选配置（每个配置有不同的超参数组合）。此外，`factor` 设置为3，这意味着每次后续迭代中仅选择三分之一的候选者。同时，这些选中的三分之一的候选者将在后续迭代中使用三倍的资源（即训练样本数）。最后，我们将
    `min_resource` 设置为“exhaust”，这意味着在最后一次迭代中，剩余的候选者将使用所有可用的训练样本。有关设置 `HalvingRandomSearchCV`
    估计器的详细说明，请参阅此帖子：[使用 HalvingGridSearch 速度提升11倍的超参数调优](/11-times-faster-hyperparameter-tuning-with-halvinggridsearch-232ed0160155)。
- en: A snapshot of the logs produced by running the `HalvingRandomSearchCV` estimator
    is shown below. The wall time for running the search is around 20 minutes on my
    PC.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 下面显示了运行 `HalvingRandomSearchCV` 估计器生成的日志快照。在我的电脑上运行搜索的实际时间约为20分钟。
- en: '![](../Images/4b3d4f7ac96bd8387075ff4b8535ca6d.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b3d4f7ac96bd8387075ff4b8535ca6d.png)'
- en: Snapshot of the logs produced by the successive halving random search algorithm.
    (Image by author)
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 连续缩小随机搜索算法生成的日志快照。（图片来源：作者）
- en: 8.3 2nd search iteration
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 第二次搜索迭代
- en: 'Once the search is completed, we can retrieve the search history stored in
    `search.cv_results`and send it to the previously-defined `log_analysis()` function
    to extract tuning insights. Afterward, we call `suggest_refine_search_space()`
    function to prompt the LLM to recommend a new search space based on the previous
    search results:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦搜索完成，我们可以从 `search.cv_results` 中检索搜索历史记录，并将其发送到之前定义的 `log_analysis()` 函数以提取调优见解。之后，我们调用
    `suggest_refine_search_space()` 函数来提示LLM根据之前的搜索结果推荐新的搜索空间：
- en: '[PRE12]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The response of the LLM is shown below:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的响应如下所示：
- en: '![](../Images/99bf92d70ab4368587e5e9b67f529dff.png)![](../Images/9d33863c6bfdb562d5621ae313802eea.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99bf92d70ab4368587e5e9b67f529dff.png)![](../Images/9d33863c6bfdb562d5621ae313802eea.png)'
- en: LLM suggested a refinement of search space and provided the reasoning. (Image
    by author)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: LLM建议了搜索空间的优化并提供了理由。（图片来源：作者）
- en: Here, we can see that the LLM has suggested narrowed space for some hyperparameters
    and expanded space for other hyperparameters. The rationale for those suggestions
    is also clearly articulated, which promotes interpretability and transparency.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到LLM建议对一些超参数进行缩小空间，对其他超参数进行扩展空间。这些建议的理由也被清晰地阐述，从而提高了可解释性和透明度。
- en: 'Given the refined search space, we can run the `HalvingRandomSearchCV` estimator
    for the second time:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 基于优化后的搜索空间，我们可以第二次运行 `HalvingRandomSearchCV` 估计器：
- en: '[PRE13]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The wall time for running the search is around 29 minutes on my PC.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的电脑上运行搜索的实际时间约为29分钟。
- en: 8.4 3rd search iteration
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 第三次搜索迭代
- en: 'Let’s run one more iteration with the LLM-guided search. Same as before, we
    first extract useful insights from the previous search logs and then prompt the
    LLM to suggest further refinement for the search space. The response produced
    by the LLM is shown below:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再运行一次LLM引导的搜索。与之前一样，我们首先从之前的搜索日志中提取有用的见解，然后提示LLM进一步优化搜索空间。LLM生成的响应如下所示：
- en: '![](../Images/540632b029e66cbdc8a8e703cf94cb62.png)![](../Images/fa9ed4b32ca9bd7882a8a1d4f81d0240.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/540632b029e66cbdc8a8e703cf94cb62.png)![](../Images/fa9ed4b32ca9bd7882a8a1d4f81d0240.png)'
- en: LLM suggested a refinement of search space and provided the reasoning. (Image
    by author)
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 建议了搜索空间的优化并提供了理由。（图像由作者提供）
- en: 'Given the newly defined search space, we run the `HalvingRandomSearchCV` estimator
    for the third time:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在新定义的搜索空间下，我们第三次运行了 `HalvingRandomSearchCV` 估计器：
- en: '[PRE14]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The wall time for running the search is around 11 minutes on my PC.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的 PC 上运行搜索的时间大约为 11 分钟。
- en: 8.5 Testing
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 测试
- en: 'Now we have gone through three rounds of random search, let’s test the performance
    of the obtained XGBoost model. For that, we can define a helper function to calculate
    various performance indices:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 经过三轮随机搜索后，让我们测试获得的 XGBoost 模型的性能。为此，我们可以定义一个辅助函数来计算各种性能指标：
- en: '[PRE15]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In the code snippet above, we applied the trained XGBoost model to the testing
    dataset and assessed its performance. The obtained confusion matrix is shown below:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，我们将训练好的 XGBoost 模型应用于测试数据集，并评估其性能。获得的混淆矩阵如下所示：
- en: '![](../Images/120b41a0c443fd2cf2227f2d8da24863.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/120b41a0c443fd2cf2227f2d8da24863.png)'
- en: The confusion matrix of applying the trained XGBoost model to the testing dataset.
    (Image by author)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后的 XGBoost 模型在测试数据集上的混淆矩阵。（图像由作者提供）
- en: 'Based on the confusion matrix, we can calculate various performance metrics:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 根据混淆矩阵，我们可以计算各种性能指标：
- en: 'Accuracy: 94.22%'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率：94.22%
- en: 'Precision: 89.5%'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确度：89.5%
- en: 'Detection rate (recall): 80.52%'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测率（召回率）：80.52%
- en: 'False alarm rate (1-Specificity): 2.35%'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚警率（1-特异性）：2.35%
- en: 'ROC-AUC score: 0.983'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ROC-AUC 分数：0.983
- en: 'F1 score: 0.848'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F1 分数：0.848
- en: 'Matthews correlation coefficient: 0.81'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马修斯相关系数：0.81
- en: 9\. Comparison Against Out-of-Box AutoML Tool
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9. 与开箱即用 AutoML 工具的比较
- en: As we have mentioned in the beginning, we would like to compare the tuning results
    of the developed LLM-guided search against an off-the-shelf, algorithmic-based
    AutoML tool to assess if tapping into ML domain expertise can truly bring value.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在开头提到的，我们希望将开发的 LLM 引导搜索的调优结果与现成的、基于算法的 AutoML 工具进行比较，以评估是否借助 ML 领域专业知识确实能带来价值。
- en: The AutoML tool we will be employing is called [FLAML](https://microsoft.github.io/FLAML/),
    which is developed by Microsoft Research and stands for *A Fast Library for Automated
    Machine Learning & Tuning*. This tool is state-of-the-art and supports fast and
    economical automatic tuning, capable of handling large search space with heterogeneous
    evaluation costs and complex constraints/guidance/early stopping. For installing
    the library, please refer to the [official page](https://microsoft.github.io/FLAML/docs/Installation).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的 AutoML 工具叫做 [FLAML](https://microsoft.github.io/FLAML/)，由微软研究院开发，代表 *一种用于自动机器学习和调整的快速库*。此工具是最先进的，支持快速且经济的自动调优，能够处理具有异质评估成本和复杂约束/指导/提前停止的大型搜索空间。有关安装库的详细信息，请参阅
    [官方页面](https://microsoft.github.io/FLAML/docs/Installation)。
- en: 'Using this tool is extremely simple: in the code snippet below, we first instantiate
    an `AutoML` object and then call its `fit()` method to kick off the hyperparameter
    tuning process. We limit the tuning to the XGBoost model only (FLAML also supports
    other model types) and set a time budget of 3600s, which is roughly the same as
    the total time we spent on 3-rounds of LLM-guided search (Random search time+
    LLM response time).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此工具极其简单：在下面的代码片段中，我们首先实例化一个`AutoML`对象，然后调用其`fit()`方法启动超参数调整过程。我们将调整限制在 XGBoost
    模型上（FLAML 也支持其他模型类型），并设置 3600 秒的时间预算，这大致等于我们在 3 轮 LLM 引导搜索中花费的总时间（随机搜索时间+ LLM
    响应时间）。
- en: '[PRE16]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The results comparison between the LLM-guided search and out-of-box FLAML is
    shown in the following:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 LLM 引导搜索与开箱即用的 FLAML 结果的比较：
- en: '![](../Images/3201aa335fbd481e84542172ca070b9c.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3201aa335fbd481e84542172ca070b9c.png)'
- en: Results comparison between two tuning approaches. (Image by author)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 两种调优方法的结果比较。（图像由作者提供）
- en: We can see that the LLM-guided search has yielded better results than the out-of-box
    FLAML for all of the considered metrics. Since we are looking at a cybersecurity
    application, the two most important metrics are the **detection rate** and the
    **false alarm rate**. Here, we can see that the LLM-guided search has managed
    to significantly improve the detection rate while slightly lowering the false
    alarm rate. As a result, the XGBoost model trained via the LLM-guided search would
    be a superior anomaly detector compared to the FLAML-searched one.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，LLM-guided 搜索在所有考虑的指标上都比开箱即用的FLAML表现更好。由于我们关注的是网络安全应用，两个最重要的指标是**检测率**和**误报率**。在这里，我们可以看到LLM-guided
    搜索成功显著提高了检测率，同时略微降低了误报率。因此，通过LLM-guided 搜索训练的XGBoost模型将是一个优于FLAML搜索模型的异常检测器。
- en: Overall, we can conclude that for our current case study, leveraging the ML
    domain expertise embedded in the LLM can indeed bring value in hyperparameter
    tuning, even when paired with a straightforward search algorithm.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们可以得出结论，对于我们当前的案例研究，利用嵌入在LLM中的机器学习领域专业知识确实可以在超参数调优中带来价值，即使它与简单的搜索算法配对。
- en: 10\. Conclusion
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10\. 结论
- en: 'In this blog, we investigated a new paradigm of AutoML: LLM-guided hyperparameter
    tuning. Here, the key idea is to treat the large language model as an ML expert
    and leverage its ML domain knowledge to propose a suitable optimization metric,
    suggest initial search space, as well as recommend refinement for the search space.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在本博客中，我们探讨了一种新的AutoML范式：LLM-guided超参数调优。这里的关键思想是将大型语言模型视为机器学习专家，并利用其机器学习领域知识来提出合适的优化指标、建议初始搜索空间以及推荐搜索空间的细化。
- en: Later, we applied this approach to identify the optimal XGBoost model for a
    cybersecurity dataset, and our results indicated that the informed hyperparameter
    search (i.e., the LLM-guided search) yielded a better anomaly detection model
    than the pure algorithmic-based AutoML tool FLAML, achieving a higher detection
    rate and a lower false alarm rate.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们将这种方法应用于识别网络安全数据集的最佳XGBoost模型，我们的结果表明，信息驱动的超参数搜索（即LLM-guided 搜索）比纯算法驱动的AutoML工具FLAML产生了更好的异常检测模型，达到了更高的检测率和更低的误报率。
- en: 'If you find my content useful, you could buy me a coffee [here](https://www.buymeacoffee.com/Shuaiguo09f)
    🤗As always, you can find the companion notebook with full code [here](https://github.com/ShuaiGuo16/LLM-guided-AutoML/tree/main)💻If
    you would like to look deeper, feel free to check out the following two recent
    research papers that investigated the same topic:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得我的内容有用，你可以在[这里](https://www.buymeacoffee.com/Shuaiguo09f)请我喝杯咖啡 🤗和往常一样，你可以在[这里](https://github.com/ShuaiGuo16/LLM-guided-AutoML/tree/main)找到包含完整代码的伴随笔记本💻如果你想深入了解，可以查看以下两篇最近的研究论文，它们研究了相同的主题：
- en: '[AutoML-GPT: Automatic Machine Learning with GPT](https://arxiv.org/pdf/2305.02499.pdf)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AutoML-GPT：与GPT的自动机器学习](https://arxiv.org/pdf/2305.02499.pdf)'
- en: '[AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities
    and Risks](https://arxiv.org/pdf/2306.08107.pdf)'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大型语言模型时代的AutoML：当前挑战、未来机会与风险](https://arxiv.org/pdf/2306.08107.pdf)'
- en: 'Also, if you are interested in other interesting applications of large language
    models, take a look at my previous blogs:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你对大型语言模型的其他有趣应用感兴趣，可以看看我之前的博客：
- en: '[Building an AI-Powered Language Learning App](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建一个AI驱动的语言学习应用](/building-an-ai-powered-language-learning-app-learning-from-two-ai-chatting-6db7f9b0d7cd)'
- en: '[Developing an Autonomous Dual-Chatbot System for Research Paper Digesting](/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开发自主双聊天机器人系统以消化研究论文](/developing-an-autonomous-dual-chatbot-system-for-research-paper-digesting-ea46943e9343)'
- en: '[Training Problem-Solving Skills in Data Science with Real-Life Simulations](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c).'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过现实生活模拟训练数据科学中的问题解决技能](/training-soft-skills-in-data-science-with-real-life-simulations-a-role-playing-dual-chatbot-c80dec3dd08c)。'
- en: Looking forward to sharing with you more exciting LLM projects. Stay tuned!
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 期待与你分享更多令人兴奋的LLM项目。敬请关注！
