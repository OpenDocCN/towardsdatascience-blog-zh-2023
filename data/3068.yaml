- en: Mastering data integration from SAP Systems with prompt engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握来自SAP系统的数据集成与快速工程
- en: 原文：[https://towardsdatascience.com/mastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a?source=collection_archive---------13-----------------------#2023-10-07](https://towardsdatascience.com/mastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a?source=collection_archive---------13-----------------------#2023-10-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a?source=collection_archive---------13-----------------------#2023-10-07](https://towardsdatascience.com/mastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a?source=collection_archive---------13-----------------------#2023-10-07)
- en: '[](https://medium.com/@markus.stadi?source=post_page-----4cb03a57463a--------------------------------)[![Markus
    Stadi](../Images/c3b1c3b040370d4e24e406b172a830d5.png)](https://medium.com/@markus.stadi?source=post_page-----4cb03a57463a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4cb03a57463a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4cb03a57463a--------------------------------)
    [Markus Stadi](https://medium.com/@markus.stadi?source=post_page-----4cb03a57463a--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@markus.stadi?source=post_page-----4cb03a57463a--------------------------------)[![Markus
    Stadi](../Images/c3b1c3b040370d4e24e406b172a830d5.png)](https://medium.com/@markus.stadi?source=post_page-----4cb03a57463a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4cb03a57463a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4cb03a57463a--------------------------------)
    [Markus Stadi](https://medium.com/@markus.stadi?source=post_page-----4cb03a57463a--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F88759409b50c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a&user=Markus+Stadi&userId=88759409b50c&source=post_page-88759409b50c----4cb03a57463a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4cb03a57463a--------------------------------)
    ·8 min read·Oct 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4cb03a57463a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a&user=Markus+Stadi&userId=88759409b50c&source=-----4cb03a57463a---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[跟进](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F88759409b50c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a&user=Markus+Stadi&userId=88759409b50c&source=post_page-88759409b50c----4cb03a57463a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4cb03a57463a--------------------------------)
    ·8 分钟阅读·2023年10月7日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4cb03a57463a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a&user=Markus+Stadi&userId=88759409b50c&source=-----4cb03a57463a---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4cb03a57463a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a&source=-----4cb03a57463a---------------------bookmark_footer-----------)![](../Images/21e67a7c882aeffe929ead60333342e1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4cb03a57463a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-sap-data-integration-tasks-with-prompt-engineering-4cb03a57463a&source=-----4cb03a57463a---------------------bookmark_footer-----------)![](../Images/21e67a7c882aeffe929ead60333342e1.png)'
- en: Construction engineer investigating his work — Stable diffusion
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 建筑工程师调查他的工作 — 稳定扩散
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: 'In our previous publication, [From Data Engineering to Prompt Engineering](https://medium.com/towards-data-science/from-data-engineering-to-prompt-engineering-5debd1c636e0),
    we demonstrated how to utilize ChatGPT to solve data preparation tasks. Apart
    from the good feedback we have received, one critical point has been raised: Prompt
    engineering may help with simple tasks, but is it really useful in a more challenging
    environment? This is a fair point. In recent decades, data architectures have
    grown increasingly diverse and complex. As a result of this complexity, data engineers
    more and more have to integrate a variety of data sources they are not necessarily
    familiar with. Can prompt engineering help in this context?'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的出版物中，[从数据工程到提示工程](https://medium.com/towards-data-science/from-data-engineering-to-prompt-engineering-5debd1c636e0)，我们展示了如何利用
    ChatGPT 解决数据准备任务。除了我们收到的良好反馈外，还有一个关键问题被提出：提示工程可能对简单任务有所帮助，但在更具挑战性的环境中是否真的有用？这是一个合理的观点。在最近几十年，数据架构变得越来越多样化和复杂。因此，数据工程师越来越多地需要整合他们不一定熟悉的各种数据源。提示工程在这种情况下能否提供帮助？
- en: This article examines the question based on a real use case from human resources
    management. We apply few shot learning to introduce an SAP HCM data model to ChatGPT
    and analyze the collected information with Apache Spark. This way, we illustrate
    how prompt engineering can deliver value even in advanced data engineering settings.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文基于来自人力资源管理的实际用例来探讨这个问题。我们应用少量示例学习将 SAP HCM 数据模型引入 ChatGPT，并使用 Apache Spark
    分析收集到的信息。通过这种方式，我们展示了提示工程在先进的数据工程环境中如何提供价值。
- en: About the business case
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于业务案例
- en: A common task every medium to large company has to accomplish, is to determine
    the number of its employees and their organizational assignment for any given
    point in time. The associated data in our scenario is stored in a SAP HCM system
    which is one of the leading applications for human resource management in enterprise
    environments.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 每个中型到大型公司都需要完成的一项常见任务是确定其员工数量及其组织分配。我们场景中的相关数据存储在 SAP HCM 系统中，这是一款领先的企业人力资源管理应用程序。
- en: To solve this kind of objective, every data engineer needs to build up a lot
    of business related knowledge which is strongly interdependent to the underlying
    data model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这种目标，每个数据工程师需要建立大量与业务相关的知识，这些知识与基础数据模型密切相关。
- en: This article will provide a step by step guide to solve the described business
    problem by creating PySpark code that can be used to build the data model and
    consequently the basis for any reporting solution.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将提供一个逐步指南，通过创建 PySpark 代码来解决描述的业务问题，这些代码可用于构建数据模型，并因此作为任何报告解决方案的基础。
- en: '![](../Images/e474925308bd9e8f426d6c767fef7069.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e474925308bd9e8f426d6c767fef7069.png)'
- en: PowerBi Example report showing personnel headcount
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: PowerBi 示例报告显示了人员数量
- en: 'Step 1: Determine which information is needed'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一步：确定需要哪些信息
- en: 'One of the main challenges in data science is to select the necessary information
    according to the business use case and to determine its origin in the source systems.
    To solve this we have to bring in some business knowledge to chatgpt. For this
    purpose we teach chatgpt some information on SAP HCM basic tables which can be
    found in SAP reference manual: [Human Resources | SAP Help Portal](https://help.sap.com/docs/HR_RENEWAL/4946a4f5c2d7427c96d89242e1ff2d9a/48d5d5537c004308e10000000a174cb4.html?locale=en-US)
    combining it with a csv-Sample record for each table.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的主要挑战之一是根据业务用例选择必要的信息，并确定其在源系统中的来源。为了解决这个问题，我们需要向 ChatGPT 传递一些业务知识。为此，我们向
    ChatGPT 介绍了 SAP HCM 基本表的一些信息，这些信息可以在 SAP 参考手册中找到：[人力资源 | SAP 帮助门户](https://help.sap.com/docs/HR_RENEWAL/4946a4f5c2d7427c96d89242e1ff2d9a/48d5d5537c004308e10000000a174cb4.html?locale=en-US)，并结合每个表的
    CSV 示例记录。
- en: In this first scenario, our intention is to report all active Employees at a
    specific point in time. The result should also include the employees personal
    number, name, status and organizational assignment.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个初步场景中，我们的目的是报告某一特定时间点的所有在职员工。结果还应包括员工的个人编号、姓名、状态和组织分配。
- en: To gather all the necessary information we need to infere a Database Schema
    to ChatGPT including example datasets and field descriptions by using few-shot
    prompting. We will start out propagating the Database Schema and some example
    data to ChatGPT.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了收集所有必要的信息，我们需要向 ChatGPT 推断一个数据库模式，包括示例数据集和字段描述，使用少量示例提示。我们将从向 ChatGPT 传播数据库模式和一些示例数据开始。
- en: Everyone who knows SAP HCMs Data Model should be familiar with the concept of
    infotypes and transparent tables. The infotype contains all the transactional
    information whereas the transparent tables contain the business information (masterdata)
    of each entity.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每个了解 SAP HCM 数据模型的人都应该对 infotypes 和透明表的概念非常熟悉。infotype 包含所有事务信息，而透明表包含每个实体的业务信息（主数据）。
- en: For the following scenario we will be using *OpenAIs GPT-4* to create the code
    we need. Lets start by providing the basic table information to ChatGPT.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下场景，我们将使用*OpenAIs GPT-4*来创建所需的代码。让我们首先向 ChatGPT 提供基本的表格信息。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Step 2:Join the necessary base tables and filter active employees only
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 2 步：连接必要的基本表并仅筛选活跃员工
- en: 'Now lets create the code to join the base tables:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建连接基本表的代码：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will produce pretty decent and well formatted PySpark code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成相当不错且格式良好的 PySpark 代码：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Notice GPT-4 recognized the join criteria for both tables which is based on
    Column STAT2 of Table PA0000 and column STATV of table T529U which is the corresponding
    transparent table. Over that the created code contains the business descriptions
    as column aliases to improve its readability.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 GPT-4 识别了两个表的连接条件，基于表 PA0000 的列 STAT2 和表 T529U 的列 STATV，后者是对应的透明表。此外，创建的代码包含业务描述作为列别名，以提高其可读性。
- en: 'Step 3: Build a Timeline to reflect the companies employees history'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 步：构建一个时间轴以反映公司的员工历史
- en: Now we will create a DataFrame that contains date values for the period starting
    from 2020–01–01 until 2024–01–01 and join all valid employees according to their
    entry date (BEGDA) and possible exit date (ENDDA) we need to create an artificial
    timeline to join the employees to.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建一个包含从 2020–01–01 到 2024–01–01 期间的日期值的 DataFrame，并根据员工的入职日期（BEGDA）和可能的离职日期（ENDDA）连接所有有效员工，我们需要创建一个人工时间轴以将员工关联起来。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Step 4: Dissolving a parent-child relationship table by determining the highest
    level organizational object'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 4 步：通过确定最高级别的组织对象来拆解父子关系表
- en: In this last step we want to build a DataFrame that represents the organizational
    structure of the company and determine each objects organizational assignment.
    Specifically we want to determine which highest level organizational unit (e.g.
    area or division) each child object is assigned to.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步，我们希望构建一个表示公司组织结构的 DataFrame，并确定每个对象的组织分配。具体来说，我们要确定每个子对象分配到哪个最高级别的组织单元（例如区域或部门）。
- en: 'The organizational structure can be used to join the employees timeline and
    get detailed information on each employees organizational assignment at a later
    step. We need to utilize SAPs HRP1001 table to achieve this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 组织结构可以用于将员工时间轴连接起来，并在后续步骤中获取每个员工组织分配的详细信息。我们需要利用 SAP 的 HRP1001 表来实现这一点：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The Language model produces a recursive function that is searching for the
    highest level organizational unit (‘O’) for each object:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型生成一个递归函数，搜索每个对象的最高级别组织单元（‘O’）：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Even when the created code is not very well optimized it contains a recursive
    function to dissolve the hierarchy. Users that prefer common table expressions
    (CTEs) should give the hint (using a common table expression) in the input prompt
    to create a more readable and understandable PySpark statement.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 即使生成的代码没有很好地优化，它也包含一个递归函数来拆解层级。那些偏好使用公共表表达式（CTE）的用户应在输入提示中给出提示（使用公共表表达式），以创建更具可读性和可理解性的
    PySpark 语句。
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Both code versions will create the dataframe for the flattened hierarchical
    organization structure which can be used for further data integration steps by
    simply joining it to the previously generated DataFrame.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 两个代码版本将创建一个用于扁平化层级组织结构的 DataFrame，该 DataFrame 可以通过简单地将其连接到之前生成的 DataFrame 来用于进一步的数据集成步骤。
- en: '![](../Images/0325bb79846b04476b5c5a967469cd3b.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0325bb79846b04476b5c5a967469cd3b.png)'
- en: Dataset containing hierarchical information
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 包含层级信息的数据集
- en: Conclusion
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'We have shown how to tackle more advanced data engineering tasks in a practical
    use case by extracting and integrating data from SAP Systems using ChatGPT to
    generate PySpark code. Large Language models might not yet be perfect but everyone
    can perhaps already imagine how powerful these techniques can become for data
    engineers. There are several key takeaways:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了如何通过提取和集成来自 SAP 系统的数据来解决更高级的数据工程任务，使用 ChatGPT 生成 PySpark 代码。虽然大型语言模型可能尚不完美，但每个人或许已经可以想象这些技术对数据工程师的强大潜力。这里有几个关键要点：
- en: ChatGPT is capable of understanding the fundamental principles of data models.
    You can refine its understanding utilizing prompting techniques to supply more
    in depth knowledge.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatGPT 能够理解数据模型的基本原理。你可以通过利用提示技术来精细化它的理解，从而提供更深入的知识。
- en: Even if the approach won´t produce perfect code at the first try, we can easily
    adjust the created code to fit our individual scenarios.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使这种方法第一次尝试时不会产生完美的代码，我们仍然可以轻松调整生成的代码以适应我们个人的场景。
- en: Due to the wide availability of open reference documents and SAP knowledge bases,
    the approach can be expanded to an Retrieval-Augmented Generation (RAG) solution.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于开放参考文档和 SAP 知识库的广泛可用性，该方法可以扩展为一种检索增强生成（RAG）解决方案。
- en: When it comes to prompt engineering best practices, try to be as precise as
    possible and provide errorcodes returned by your Spark environment to leverage
    the LLMs capabilities to refactor the generated code. Multiple tries might be
    necessary to refine the code, nevertheless adding keywords like “precise” to your
    prompt might help ChatGPT to produce better results. Ask for detailed explanation
    for the solution approach as this will force ChatGPTs transformer model to dig
    deeper.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示工程最佳实践方面，尽量做到尽可能精确，并提供 Spark 环境返回的错误代码，以利用 LLM 的能力来重构生成的代码。可能需要多次尝试来完善代码，不过在提示中添加像“精确”这样的关键词可能会帮助
    ChatGPT 产生更好的结果。要求对解决方案方法进行详细解释，这将迫使 ChatGPT 的 Transformer 模型深入挖掘。
- en: 'Note: The prompts containing the csv example datasets had to be cut off due
    to length constraints of this article.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：由于本文长度限制，包含 csv 示例数据集的提示不得不被截断。
- en: About the authors
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于作者
- en: '*Markus Stadi* is a Senior Cloud Data Engineer at Dehn SE working in the field
    of Data Engineering, Data Science and Data Analytics for many years.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*马克斯·斯塔迪* 是 Dehn SE 的高级云数据工程师，多年来从事数据工程、数据科学和数据分析领域的工作。'
- en: '*Christian Koch* is an Enterprise Architect at BWI GmbH and Lecturer at the
    Nuremberg Institute of Technology Georg Simon Ohm.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*克里斯蒂安·科赫* 是 BWI GmbH 的企业架构师，同时也是纽伦堡工业大学乔治·西蒙·欧姆的讲师。'
