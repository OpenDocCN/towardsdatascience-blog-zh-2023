- en: Turn Linear Regression into Logistic Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将线性回归转变为逻辑回归
- en: 原文：[https://towardsdatascience.com/turn-linear-regression-into-logistic-regression-e088e2408ec9](https://towardsdatascience.com/turn-linear-regression-into-logistic-regression-e088e2408ec9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/turn-linear-regression-into-logistic-regression-e088e2408ec9](https://towardsdatascience.com/turn-linear-regression-into-logistic-regression-e088e2408ec9)
- en: A Comprehensive Guideline on How to Implement Logistic Regression from Scratch
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于如何从头实现逻辑回归的全面指南
- en: '[](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)[![Md.
    Zubair](../Images/1b983a23226ce7561796fa5b28c00d65.png)](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)
    [Md. Zubair](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)[![Md.
    Zubair](../Images/1b983a23226ce7561796fa5b28c00d65.png)](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)
    [Md. Zubair](https://zubairhossain.medium.com/?source=post_page-----e088e2408ec9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)
    ·10 min read·Mar 27, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e088e2408ec9--------------------------------)
    ·阅读时间10分钟·2023年3月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/764eaf14aa790304658c9ca236dfedb0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/764eaf14aa790304658c9ca236dfedb0.png)'
- en: Photo by [Rutger Leistra](https://unsplash.com/ko/@rutgerleistra?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Rutger Leistra](https://unsplash.com/ko/@rutgerleistra?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动机
- en: If you read my previous articles on [*simple linear regression*](https://medium.com/towards-data-science/deep-understanding-of-simple-linear-regression-3776afe34473)
    and [*multiple linear regression*](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236),
    you will get to know that linear regression predicts continuous value. But not
    all of our real-life prediction problems are associated with continuous values.
    Sometimes we need to classify an object or data based on its features. Linear
    regression algorithms can’t solve these problems. In this scenario, logistic regression’s
    necessity comes in. The title of the algorithm, ‘**Logistic Regression’** holds
    the word **‘Regression’.** It is the modified version of linear regression so
    that it can predict the discrete class value rather than continuous values.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读了我之前关于[*简单线性回归*](https://medium.com/towards-data-science/deep-understanding-of-simple-linear-regression-3776afe34473)和[*多重线性回归*](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236)的文章，你会了解到线性回归预测的是连续值。但是并非所有现实中的预测问题都与连续值相关。有时我们需要根据特征对对象或数据进行分类。线性回归算法无法解决这些问题。在这种情况下，逻辑回归的必要性就体现出来了。算法的名称‘**逻辑回归**’中包含了**‘回归’**一词。它是线性回归的改进版本，以便可以预测离散类别值而不是连续值。
- en: '`So, this article will explain how logistic regression generates the prediction
    value of a class derived from linear regression.`'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '`因此，本文将解释逻辑回归如何生成从线性回归派生的类别预测值。`'
- en: Table of Contents
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: '`[**What does Make Linear Regression a Logistic Regression?**](#b874)`'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**是什么让线性回归变成逻辑回归？**](#b874)`'
- en: '`[**Which Function Plays a Key Role?**](#a923)`'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**哪个函数起关键作用？**](#a923)`'
- en: '`[**How Does Linear Regression Fall into Logistic Regression?**](#8b86)`'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**线性回归如何转变为逻辑回归？**](#8b86)`'
- en: '`[**Generate a Loss Function**](#7623)`'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**生成损失函数**](#7623)`'
- en: '`[**Why can’t We use MSE as a cost function?**](#7222)`'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**为什么不能使用均方误差作为成本函数？**](#7222)`'
- en: '`[**Gradient Descent for Parameter Optimization**](#daa3)`'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**用于参数优化的梯度下降**](#daa3)`'
- en: '`[**Putting All the Concept Together for Python Implementation from Scratch**](#1a72)`'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`[**将所有概念结合起来进行Python从头实现**](#1a72)`'
- en: What Does Make Linear Regression a Logistic Regression?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么让线性回归变成逻辑回归？
- en: I will bring two equations mentioned in my previous articles on [*simple*](https://medium.com/towards-data-science/deep-understanding-of-simple-linear-regression-3776afe34473)
    and [*multiple linear regression*](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我会带来我之前文章中提到的两个方程，[*简单线性回归*](https://medium.com/towards-data-science/deep-understanding-of-simple-linear-regression-3776afe34473)
    和 [*多重线性回归*](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236)。
- en: The first one is the equation for simple linear regression.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是简单线性回归的方程。
- en: '![](../Images/920f82c0f7922826fbf6113a6fcd5063.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/920f82c0f7922826fbf6113a6fcd5063.png)'
- en: We will get the predicted regression value `(y)` only by plugging the value
    of the independent variable `(x)`. But we need to fit the value of the coefficients
    slope`(m)` and the y-intercept value `c`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过插入自变量 `(x)` 的值来获得预测的回归值 `(y)`。但我们需要拟合系数斜率`(m)` 和 y 截距值 `c`。
- en: The second equation is similar to the first one, but there is more than one
    independent variable `*(x1……..xn)*`*, coefficients m* `*(m1…….m0)*`, and y-intercept
    `m0`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个方程式类似于第一个方程，但存在多个自变量 `*(x1……..xn)*`*，系数 m* `*(m1…….m0)*`，以及 y 轴截距 `m0`。
- en: '![](../Images/282ecd71530478bad24425e4ceefaa2e.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/282ecd71530478bad24425e4ceefaa2e.png)'
- en: Both for the ***1st and 2nd*** equations, if we have the best-fit values of
    the coefficients, we can easily get the regression value like 34, 687.93 etc.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于***第1个和第2个***方程，如果我们有系数的最佳拟合值，我们可以轻松得到回归值，例如 34，687.93 等等。
- en: But it doesn’t give us any sense of transforming the continuous value into a
    distinct classification value. So, we need a function or way by which we can convert
    all the regression values into a range of values between `**[0,1]**`. In logistic
    regression, we exactly do the same. I am going to discuss the function in the
    next section.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不能给我们将连续值转化为离散分类值的直观感受。因此，我们需要一个函数或方法，通过它可以将所有回归值转换为 `**[0,1]**` 之间的值。在逻辑回归中，我们正是这样做的。我将在下一节中讨论这个函数。
- en: Which Function Plays a Key Role?
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哪个函数起着关键作用？
- en: Instead of directly mentioning the function, I will explain it gradually. *Let’s
    try to have some visual impacts of linear regression and logistic regression.*
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会直接提到函数，而是会逐步解释。 *让我们尝试直观了解线性回归和逻辑回归的效果。*
- en: '![](../Images/83a42f810ece4934a0e2ed0b27530a3d.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83a42f810ece4934a0e2ed0b27530a3d.png)'
- en: Regression Model Graph (Image By Author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型图（图片由作者提供）
- en: Look at the above regression model graph. The diagonal blue line is the regression
    line. We can predict any value of `***y***`only by plugging the`***x***`value.
    Try to formulate a logistic regression problem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下上述回归模型图。对角线上的蓝色线是回归线。我们可以通过插入 `***x***` 值来预测任何 `***y***` 值。尝试制定一个逻辑回归问题。
- en: '![](../Images/8828848f104c2f56fe8d8a28eb85890c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8828848f104c2f56fe8d8a28eb85890c.png)'
- en: Image By Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The above dataset has one feature, **‘Age’,** based on the feature the target
    class is defined. The value **1** indicates the person is a student, and **0**
    represents the person is not a student. And it is impossible to predict such categorical
    values with linear regression. ***How does it look like if we plot it? Let’s see.***
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上述数据集有一个特征，**‘年龄’，** 基于该特征定义目标类别。值 **1** 表示该人是学生，**0** 表示该人不是学生。用线性回归预测这样的分类值是不可能的。
    ***如果我们绘制它，会是什么样子呢？让我们看看。***
- en: '![](../Images/f2f120d89c87e3d29036fb8d601003d0.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2f120d89c87e3d29036fb8d601003d0.png)'
- en: Image By Author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The stars represent the level of the class (Student or not). Simply, a regression
    line won’t be an appropriate way to predict the classification values.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 星星表示类别的水平（学生与否）。简单地说，回归线并不是预测分类值的合适方法。
- en: Here, the **‘S-shaped** function named ‘‘**sigmoid** ’’ comes to play the role.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，**‘S形’** 函数，名为 ‘‘**sigmoid**’’ 发挥了作用。
- en: '![](../Images/b777a2e970131850f52585d18304177b.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b777a2e970131850f52585d18304177b.png)'
- en: This function can convert any number between `*[0,1]*`. I will show you a coding
    example of the sigmoid function.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数可以将任何数字转换到 `*[0,1]*` 之间。我将给你展示一个 sigmoid 函数的编码示例。
- en: '***Creating a function for sigmoid function***'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '***创建一个 sigmoid 函数***'
- en: '***Plotting the sigmoid graph***'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '***绘制 sigmoid 图***'
- en: This **S-shaped** sigmoid graph would be the best fit for the classification
    problem rather than a straight line. With the increasing value of **x,** the **y**
    value goes from ***0 to 1*** and for ***x=0, y=0.5***. It’s a good function to
    be used. We can easily set a threshold value like 0.5\. All values greater than
    the threshold (0.5) will be 1; otherwise, 0.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 **S形** 的 sigmoid 图形比直线更适合分类问题。随着 **x** 的增加，**y** 值从 ***0 到 1*** 变化，当 ***x=0，y=0.5***。这是一个很好的函数，我们可以轻松设置一个阈值，例如
    0.5。所有大于阈值（0.5）的值将为 1，否则为 0。
- en: '*Yes! finally, we have found the appropriate function.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*是的！终于，我们找到了合适的函数。*'
- en: How Does Linear Regression Fall into Logistic Regression?
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归如何转变为逻辑回归？
- en: Now, we have all the staff to translate a linear regression into a logistic
    regression. Let’s put it all together.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们具备了将线性回归转换为逻辑回归的所有条件。让我们把它们放在一起。
- en: In the [**first section**](#b874), I have shown the linear regression equations
    for simple and multiple linear regression. The value of the linear regression
    is continuous. It can be any continuous numerical value.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [**第一部分**](#b874)，我展示了简单线性回归和多重线性回归的方程。线性回归的值是连续的，可以是任何连续的数值。
- en: But the sigmoid function helps us produce a categorical value like ***0* and
    *1***, as shown in the [**last section**](#a923).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但 sigmoid 函数帮助我们产生诸如 ***0* 和 *1*** 的分类值，如 [**最后一部分**](#a923) 所示。
- en: So, the equation for the logistics regression will be as follows.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，逻辑回归的方程将如下所示。
- en: '![](../Images/5df00f2eb8c759ad124fac20919765cc.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5df00f2eb8c759ad124fac20919765cc.png)'
- en: The symbol **σ** represents the sigmoid function. If we pass the output of the
    equation into the sigmoid function, we will get results ranging from ***0 to 1.***
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 符号 **σ** 代表 sigmoid 函数。如果我们将方程的输出传入 sigmoid 函数，我们将得到从 ***0 到 1*** 的结果。
- en: Now, we can calculate the linear equation’s value by manually multiplying and
    adding the values.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过手动相乘和相加来计算线性方程的值。
- en: '![](../Images/3b0152745c586c8f2e5aef39d2285af9.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b0152745c586c8f2e5aef39d2285af9.png)'
- en: But the manual process is time-consuming. Vectorized implementation is much
    faster and easy. Let’s formulate the linear equation to make it compatible with
    vectorized implementation.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 但手动过程很耗时。向量化实现要快得多且容易。让我们制定线性方程，使其与向量化实现兼容。
- en: '![](../Images/98a2acce6d48d63851f8a1cc4ae2041e.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98a2acce6d48d63851f8a1cc4ae2041e.png)'
- en: We have added an extra constant variable `***xi0=1***`***.***
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们添加了一个额外的常数变量 `***xi0=1***`***。***
- en: '![](../Images/3ef0d02a2078307aedd85548cff7852a.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ef0d02a2078307aedd85548cff7852a.png)'
- en: Matrix Implementation for Calculating the Linear Equation (Image By Author)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵实现线性方程计算（图片来自作者）
- en: The **X** holds all the values of the independent variables, and the transpose
    of **M** represents the transpose matrix of all the coefficients.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**X** 包含所有自变量的值，**M** 的转置代表所有系数的转置矩阵。'
- en: '**Vectorized Logistic Regression Equation**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**向量化逻辑回归方程**'
- en: Vectorized implementation of the logistic regression will be something like
    this.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化的逻辑回归实现将是这样的。
- en: '![](../Images/98867d6ce9809b40eebe991c7324044f.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98867d6ce9809b40eebe991c7324044f.png)'
- en: It will transform the linear equation values between 0 to 1\. A function with
    python is given below.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它会将线性方程的值转换到 0 到 1 之间。下面是一个 Python 函数。
- en: Testing the function with a demo value.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 用演示值测试函数。
- en: Yeah! We have successfully created the function.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 是的！我们已经成功创建了这个函数。
- en: Generate a Loss Function
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成一个损失函数
- en: If we look back to our previous [**multiple linear regression**](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236)
    article, we will find the **Mean Square Error (MSE)** as a cost function.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾之前的 [**多重线性回归**](https://medium.com/towards-data-science/multiple-linear-regression-a-deep-dive-f104c8ede236)
    文章，我们会发现 **均方误差 (MSE)** 作为代价函数。
- en: '![](../Images/ac1432e6410acf46306052db39d43187.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac1432e6410acf46306052db39d43187.png)'
- en: But we know logistics regression is not a regression algorithm. Rather, it is
    a binary classification (two classes) algorithm. In logistic regression, there
    are two classes, **1** and **0**. So, **MSE** is not an appropriate cost function
    to be used in case of logistic regression. `*(But why? I will explain the exact
    reason a bit later)*`
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们知道逻辑回归不是回归算法。相反，它是一个二分类（两个类别）算法。在逻辑回归中，有两个类别，**1** 和 **0**。因此，**MSE** 不是用于逻辑回归的合适代价函数。`*(但为什么？我稍后会解释具体原因)*`
- en: Now, I will introduce a new cost function for this classification algorithm.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我将介绍一个新的成本函数用于这个分类算法。
- en: '![](../Images/88464bbf8811c6148e81e80b913ba542.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/88464bbf8811c6148e81e80b913ba542.png)'
- en: The above cost function is suitable for logistic regression.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上述成本函数适用于逻辑回归。
- en: Let’s try to have some intuition about the cost function. For `**yi = 1**`,
    the cost function is —
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试对成本函数有一些直观的了解。对于`**yi = 1**`，成本函数为——
- en: '![](../Images/eb64152ec90b186342590592b4c2a425.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb64152ec90b186342590592b4c2a425.png)'
- en: How does the function look like? Let’s plot the function.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数看起来如何？让我们绘制这个函数。
- en: The above plot is the graphical representation of the loss function when `yi=1`.
    The graph says the more the prediction value closer to **1**, the less the error.
    And when the prediction value is 0.0, the error is infinity.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图是`yi=1`时损失函数的图形表示。图表显示，预测值越接近**1**，误差越小。当预测值为0.0时，误差是无限的。
- en: '*Let’s plot the cost function for* `***y0=1***`*.*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*让我们绘制* `***y0=1***`*的成本函数。*'
- en: For `yi=0`, when the prediction value is close to `**1**`**,** the error is
    infinity and reduces the errors by decreasing the value. Now, we will plot the
    two graphs combined.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`yi=0`，当预测值接近`**1**`时，误差是无限的，通过减小值来减少误差。现在，我们将绘制两个图形的结合。
- en: Now, the graphical representation is more intuitive. If we combine the loss
    functions for `**yi=0 and yi=1**`, we will get an appropriate function to apply
    gradient descent which has global minima.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，图形表示更加直观。如果我们将`**yi=0 和 yi=1**`的损失函数结合起来，我们将得到一个适合应用梯度下降的函数，它具有全局最小值。
- en: '![](../Images/4b9bf8f7e5cb2ebf8fec25254e1f469b.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b9bf8f7e5cb2ebf8fec25254e1f469b.png)'
- en: If we plugin the target value`***yi=1*** *or* ***yi=0***`in the above equation,
    one part will be cancelled and turn out to be the same equation I mentioned. This
    is what we need.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将目标值`***yi=1*** *或* ***yi=0***`代入上述方程，其中一部分将被取消，结果将是我提到的相同方程。这就是我们需要的。
- en: '***Convert the cost function into code.***'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '***将成本函数转换为代码。***'
- en: '**Why can’t We Use MSE as a cost function?**'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**为什么不能使用均方误差（MSE）作为成本函数？**'
- en: In logistic regression, the target or output value is discrete or categorical.
    It is not a continuous value like regression problems. If we plug in the value
    in the **MSE** cost function *(the cost function which we have used for linear
    and multiple linear regression),* we will get the following graph rather than
    a convex curve.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑回归中，目标或输出值是离散的或分类的。它不像回归问题中的连续值。如果我们将值代入**均方误差（MSE）**成本函数（*我们用于线性回归和多重线性回归的成本函数*），我们将得到如下图形，而不是一个凸曲线。
- en: '![](../Images/1b0d02be4a76ad791e5986ce4fd52591.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b0d02be4a76ad791e5986ce4fd52591.png)'
- en: Cost Function with Many Local Minima (Image by Author)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 多局部最小值的成本函数（图片由作者提供）
- en: As this type of curve contains many local minima, we will be in trouble to apply
    gradient descent in the cost function. That’s why we won’t use MSE as a cost function
    in logistic regression.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种类型的曲线包含多个局部最小值，我们在成本函数中应用梯度下降时会遇到麻烦。这就是为什么我们在逻辑回归中不会使用均方误差（MSE）作为成本函数的原因。
- en: Gradient Descent for Parameter Optimization
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数优化的梯度下降
- en: Gradient descent is a way of minimizing the loss/cost function by optimizing
    the coefficients of a machine learning algorithm how the cost function looks like.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种通过优化机器学习算法的系数来最小化损失/成本函数的方法，这取决于成本函数的形状。
- en: '![](../Images/28ca4da8d625104cf9c1ab593f94ec5e.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28ca4da8d625104cf9c1ab593f94ec5e.png)'
- en: Gradient Descent (Image By Author)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降（图片由作者提供）
- en: The cost function is a **convex** curve, as shown in the **Loss Function** section.
    Now, we have to calculate the derivative of the cost function. Derivative indicates
    how the cost is changed in which direction.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 成本函数是一个**凸**曲线，如**损失函数**部分所示。现在，我们需要计算成本函数的导数。导数表示成本在什么方向上发生变化。
- en: Firstly, we will randomly initialize the weights of the coefficients and update
    the weights gradually. The main target is finding the minimum cost shown in the
    above image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将随机初始化系数的权重并逐步更新权重。主要目标是找到如上图所示的最小成本。
- en: '![](../Images/4b9bf8f7e5cb2ebf8fec25254e1f469b.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b9bf8f7e5cb2ebf8fec25254e1f469b.png)'
- en: '*The derivative of the cost function will be —*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*成本函数的导数为——*'
- en: '![](../Images/34e0a5589e0fbd3ae80df4f2517a1ee0.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34e0a5589e0fbd3ae80df4f2517a1ee0.png)'
- en: '*[N.B. If I show the details calculation of the derivative, the article will
    be unnecessarily long. Read out the* [***article***](https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d)
    *for a details explanation.]*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*[注：如果展示导数的详细计算，文章会变得不必要地长。请阅读* [***文章***](https://medium.com/analytics-vidhya/derivative-of-log-loss-function-for-logistic-regression-9b832f025c2d)
    *以获得详细解释。]*'
- en: '*Vectorized implementation will be as follows.*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*矢量化实现如下。*'
- en: '![](../Images/9aef7d6eaa9ef8b78d26ff839b06d03a.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9aef7d6eaa9ef8b78d26ff839b06d03a.png)'
- en: '`***X***` is the matrix form of all the features value, `**M**` represents
    the vectorized form of the coefficients, and `**Y**` stands for the vectorized
    representation of the target value.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`***X***`是所有特征值的矩阵形式，`**M**`代表系数的矢量化形式，`**Y**`表示目标值的矢量化表示。'
- en: '*Code for vectorized gradient descent implementation.*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*矢量化梯度下降实现的代码。*'
- en: '*We are one step ahead of our final implementation. We have all the functions
    ready to implement the logistic regression. In the next step, we will combine
    all tools and implement the complete algorithms.*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们已经迈出了实现最终模型的一步。所有功能都已准备好进行逻辑回归。在下一步中，我们将结合所有工具，实施完整的算法。*'
- en: Putting All the Concepts Together for Python Implementation from Scratch
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将所有概念结合起来进行Python从零实现
- en: Let’s load the dataset of titanic (first thing first). The [**dataset is publicly**
    **available**](https://www.kaggle.com/datasets/brendan45774/test-file) and licenced
    under the public domain.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 首先加载泰坦尼克号数据集。 [**数据集是公开的** **可用的**](https://www.kaggle.com/datasets/brendan45774/test-file)
    并且在公共领域许可下。
- en: '**Importing the necessary libraries**'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**导入必要的库**'
- en: '`*[Our main target is to show the basic mechanism of the algorithm. So, we
    have kept the pre-processing simple and easy. Rather than concentrate on the data
    analysis, we will keep our eyes on the core implementation.]*`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`*[我们的主要目标是展示算法的基本机制。因此，我们保持了简单易懂的预处理。我们将重点放在核心实现上，而不是数据分析。]*`'
- en: '*For our convenience, we have selected some features —*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*为了方便，我们选择了一些特征——*'
- en: '**Let’s have some insights into the selected features.**'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**让我们对选择的特征进行一些深入了解。**'
- en: The features ‘`Age’` and `‘Fare’` have some missing values. We will fill the
    values with the average value. And map the `‘Sex’` **male** with **1** *and* **female**
    with **0**.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 特征`‘Age’`和`‘Fare’`有一些缺失值。我们将用平均值填补这些缺失值，并将`‘Sex’`中的**男性**映射为**1**，*女性*映射为**0**。
- en: Now, all the features are numerical, and no missing value exists.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，所有特征都是数值型的，没有缺失值。
- en: '**Let’s extract the independent variables (x) and dependent variable (y)**'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提取自变量（x）和因变量（y）**'
- en: '**Normalizing the data so that it will increase the performance of gradient
    descent**'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规范化数据，以提高梯度下降的性能**'
- en: '**Splitting the train and test set**'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拆分训练集和测试集**'
- en: Kept 25% data for testing and rest of the data for training. Now, we will feed
    the data to our scratch model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 保留了25%的数据用于测试，其余数据用于训练。现在，我们将数据输入到我们的初步模型中。
- en: '**Putting all the functions together for performing logistic regression**'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将所有功能结合在一起进行逻辑回归**'
- en: '**Fit the model with training data**'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用训练数据拟合模型**'
- en: '**See how the coefficients of the model are optimized**'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查看模型系数如何优化**'
- en: '**Create a prediction function**'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建预测函数**'
- en: Here, I have used a threshold value of *0.5* to classify the data. All the results
    below *0.5* are considered as class *0*, and above or equal to *0.5* is *1*.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我使用了*0.5*的阈值来分类数据。所有低于*0.5*的结果被视为类*0*，等于或高于*0.5*的结果被视为类*1*。
- en: '**Let’s compare our model with the benchmark scikit-learn library**'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**让我们将模型与基准scikit-learn库进行比较**'
- en: '*Creating a logistic regression model with scikit-learn*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用scikit-learn创建逻辑回归模型*'
- en: '*Prediction on the test data*'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*在测试数据上的预测*'
- en: '**Results of scikit-learn model vs our scratch model**'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**scikit-learn模型与我们初步模型的结果对比**'
- en: '**👉Result of our scratch model**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**👉我们初步模型的结果**'
- en: '*Confusion matrix*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*混淆矩阵*'
- en: '*Precision, recall and f1-score*'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确度、召回率和f1-score*'
- en: '**👉 Result of scikit-learn model**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**👉scikit-learn模型的结果**'
- en: '*Confusion matrix*'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*混淆矩阵*'
- en: '*Precision, recall and f1-score*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*精确度、召回率和f1-score*'
- en: It turns out that both our scratch model and scikit-learn model possess the
    same results. So, we claim that our scratch model is identical to the scikit-learn
    model.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，我们的初步模型和scikit-learn模型具有相同的结果。因此，我们声称我们的初步模型与scikit-learn模型相同。
- en: Conclusion
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Nowadays, machine learning models are very easy to implement for some built-in
    libraries. So, learning the core mechanisms may be unnecessary for you. As a researcher
    and academician, I always consider it from a different point of view. If you know
    the core concepts of the algorithms, it will be very helpful for you to work at
    the core level, like research, development and optimization of the algorithm,
    etc. You can implement the concept in those programming languages where machine
    learning libraries don’t exist.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一些内置库使得机器学习模型的实现变得非常简单。因此，学习核心机制可能对你来说并不必要。作为研究人员和学者，我总是从不同的角度考虑这个问题。如果你了解算法的核心概念，这将对你在核心层面的工作，如算法的研究、开发和优化等非常有帮助。你可以在那些没有机器学习库的编程语言中实现这些概念。
- en: '`[***Full Notebook and dataset is available in the repository***](https://github.com/Zubair063/ML_articles/tree/main/Logistic%20Regression%20from%20Scratch)***.***`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`[***完整的笔记本和数据集可在仓库中获取***](https://github.com/Zubair063/ML_articles/tree/main/Logistic%20Regression%20from%20Scratch)***.***`'
- en: References
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Logistic Regression from scratch — Philipp Muens](https://philippmuens.com/logistic-regression-from-scratch)'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[从头开始的逻辑回归 — Philipp Muens](https://philippmuens.com/logistic-regression-from-scratch)'
- en: Machine Learning Course By Andrew Ng
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Andrew Ng 的机器学习课程
- en: '`My previous **Algorithm from Scratch** series articles.`'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`我之前的**从头开始的算法**系列文章。`'
- en: '[](/multiple-linear-regression-a-deep-dive-f104c8ede236?source=post_page-----e088e2408ec9--------------------------------)
    [## Multiple Linear Regression: A Deep Dive'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 多重线性回归：深入探讨](https://towardsdatascience.com/multiple-linear-regression-a-deep-dive-f104c8ede236?source=post_page-----e088e2408ec9--------------------------------)'
- en: 'Multiple Linear Regression from Scratch: Deep Understanding'
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从零开始的多重线性回归：深入理解
- en: towardsdatascience.com](/multiple-linear-regression-a-deep-dive-f104c8ede236?source=post_page-----e088e2408ec9--------------------------------)
    [](/deep-understanding-of-simple-linear-regression-3776afe34473?source=post_page-----e088e2408ec9--------------------------------)
    [## Deep Understanding of Simple Linear Regression
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 简单线性回归的深入理解](https://towardsdatascience.com/deep-understanding-of-simple-linear-regression-3776afe34473?source=post_page-----e088e2408ec9--------------------------------)'
- en: 'Linear Regression from Scratch: Detailed Explanation'
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从零开始的线性回归：详细解释
- en: towardsdatascience.com](/deep-understanding-of-simple-linear-regression-3776afe34473?source=post_page-----e088e2408ec9--------------------------------)
    [](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----e088e2408ec9--------------------------------)
    [## KNN Algorithm from Scratch
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[KNN 算法从零开始](https://towardsdatascience.com/deep-understanding-of-simple-linear-regression-3776afe34473?source=post_page-----e088e2408ec9--------------------------------)
    [## KNN 算法从零开始'
- en: Implementation and Details Explanation of the KNN Algorithm
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: KNN 算法的实现和详细解释
- en: towardsdatascience.com](/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----e088e2408ec9--------------------------------)
    [](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----e088e2408ec9--------------------------------)
    [## K-means Clustering from Scratch
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[K-means 从零开始](https://towardsdatascience.com/knn-algorithm-from-scratch-37febe0c15b3?source=post_page-----e088e2408ec9--------------------------------)
    [## K-means 从零开始'
- en: 'K-means: The Best ML Algorithm to Cluster Data'
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: K-means：聚类数据的最佳 ML 算法
- en: towardsdatascience.com](/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----e088e2408ec9--------------------------------)
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 无监督学习和 K-means 聚类从零开始](https://towardsdatascience.com/unsupervised-learning-and-k-means-clustering-from-scratch-f4e5e9947c39?source=post_page-----e088e2408ec9--------------------------------)'
- en: '`**Statistics and data visualization** for data science series.`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`**统计和数据可视化** 数据科学系列。`'
- en: '[](/ultimate-guide-to-statistics-for-data-science-a3d8f1fd69a7?source=post_page-----e088e2408ec9--------------------------------)
    [## Ultimate Guide to Statistics for Data Science'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[**数据科学的终极统计指南**](https://towardsdatascience.com/ultimate-guide-to-statistics-for-data-science-a3d8f1fd69a7?source=post_page-----e088e2408ec9--------------------------------)
    [## 数据科学的终极统计指南'
- en: 'Statistics at a glance for data science: standard guidelines'
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据科学的一瞥：标准指南
- en: towardsdatascience.com](/ultimate-guide-to-statistics-for-data-science-a3d8f1fd69a7?source=post_page-----e088e2408ec9--------------------------------)
    [](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)
    [## Ultimate Guide to Data Visualization for Data Science
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据科学终极统计指南](https://towardsdatascience.com/ultimate-guide-to-statistics-for-data-science-a3d8f1fd69a7?source=post_page-----e088e2408ec9--------------------------------)
    [](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)
    [## 数据科学数据可视化终极指南'
- en: 'Data Visualization at a glance for data science: standard guidelines'
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据科学中的数据可视化概述：标准指南
- en: medium.datadriveninvestor.com](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据驱动投资者](https://medium.datadriveninvestor.com/ultimate-guide-to-data-visualization-for-data-science-90b0b13e72ab?source=post_page-----e088e2408ec9--------------------------------)'
