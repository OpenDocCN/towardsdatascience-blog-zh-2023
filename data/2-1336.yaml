- en: Introducing KeyLLM â€” Keyword Extraction with LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»KeyLLM â€” ä½¿ç”¨LLMè¿›è¡Œå…³é”®è¯æå–
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/introducing-keyllm-keyword-extraction-with-llms-39924b504813](https://towardsdatascience.com/introducing-keyllm-keyword-extraction-with-llms-39924b504813)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/introducing-keyllm-keyword-extraction-with-llms-39924b504813](https://towardsdatascience.com/introducing-keyllm-keyword-extraction-with-llms-39924b504813)
- en: Use KeyLLM, KeyBERT, and Mistral 7B to extract keywords
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨KeyLLMã€KeyBERTå’ŒMistral 7Bæ¥æå–å…³é”®è¯
- en: '[](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)[![Maarten
    Grootendorst](../Images/58e24b9cf7e10ff1cd5ffd75a32d1a26.png)](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)[](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------)
    [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)[![Maarten
    Grootendorst](../Images/58e24b9cf7e10ff1cd5ffd75a32d1a26.png)](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)[](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------)
    [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----39924b504813--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------)
    Â·9 min readÂ·Oct 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----39924b504813--------------------------------)
    Â·é˜…è¯»æ—¶é—´9åˆ†é’ŸÂ·2023å¹´10æœˆ5æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/47514c37ae551ce79a535285a4d4488a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47514c37ae551ce79a535285a4d4488a.png)'
- en: Large Language Models (LLMs) are becoming smaller, faster, and more efficient.
    Up to the point where I started to consider them for iterative tasks, like keyword
    extraction.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å˜å¾—è¶Šæ¥è¶Šå°ã€å¿«é€Ÿä¸”é«˜æ•ˆã€‚ç›´åˆ°æˆ‘å¼€å§‹è€ƒè™‘å®ƒä»¬ç”¨äºè¿­ä»£ä»»åŠ¡ï¼Œå¦‚å…³é”®è¯æå–ã€‚
- en: Having created [KeyBERT](https://github.com/MaartenGr/KeyBERT), I felt that
    it was time to extend the package to also include LLMs. They are quite powerful
    and I wanted to prepare the package for when these models can be run on smaller
    GPUs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åˆ›å»ºäº†[KeyBERT](https://github.com/MaartenGr/KeyBERT)ä¹‹åï¼Œæˆ‘è§‰å¾—æ˜¯æ—¶å€™æ‰©å±•è¯¥åŒ…ä»¥åŒ…æ‹¬LLMsäº†ã€‚å®ƒä»¬éå¸¸å¼ºå¤§ï¼Œæˆ‘å¸Œæœ›ä¸ºå°†æ¥è¿™äº›æ¨¡å‹å¯ä»¥åœ¨æ›´å°çš„GPUä¸Šè¿è¡Œåšå¥½å‡†å¤‡ã€‚
- en: As such, introducing `[KeyLLM](https://maartengr.github.io/KeyBERT/guides/keyllm.html)`,
    an extension to KeyBERT that allows you to use any LLM to extract, create, or
    even fine-tune the keywords!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä»‹ç»`[KeyLLM](https://maartengr.github.io/KeyBERT/guides/keyllm.html)`ï¼Œè¿™æ˜¯KeyBERTçš„ä¸€ä¸ªæ‰©å±•ï¼Œå…è®¸ä½ ä½¿ç”¨ä»»ä½•LLMæ¥æå–ã€åˆ›å»ºç”šè‡³å¾®è°ƒå…³é”®è¯ï¼
- en: In this tutorial, we will go through keyword extraction with `[KeyLLM](https://maartengr.github.io/KeyBERT/guides/keyllm.html)`
    using the recently released Mistral 7B model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä½¿ç”¨æœ€è¿‘å‘å¸ƒçš„Mistral 7Bæ¨¡å‹çš„`[KeyLLM](https://maartengr.github.io/KeyBERT/guides/keyllm.html)`è¿›è¡Œå…³é”®è¯æå–ã€‚
- en: 'We will start by installing a number of packages that we are going to use throughout
    this example:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»å®‰è£…ä¸€ç³»åˆ—åœ¨æœ¬ç¤ºä¾‹ä¸­å°†è¦ä½¿ç”¨çš„åŒ…å¼€å§‹ï¼š
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We are installing `sentence-transformers` from its main branch since it has
    a fix for community detection which we will use in the last few use cases. We
    do the same for `transformers` since it does not yet support the Mistral architecture.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ­£åœ¨ä»ä¸»åˆ†æ”¯å®‰è£…`sentence-transformers`ï¼Œå› ä¸ºå®ƒä¿®å¤äº†ç¤¾åŒºæ£€æµ‹çš„åŠŸèƒ½ï¼Œæˆ‘ä»¬å°†åœ¨æœ€åå‡ ä¸ªç”¨ä¾‹ä¸­ä½¿ç”¨ã€‚æˆ‘ä»¬å¯¹`transformers`ä¹Ÿåšäº†åŒæ ·çš„å¤„ç†ï¼Œå› ä¸ºå®ƒå°šä¸æ”¯æŒMistralæ¶æ„ã€‚
- en: You can also follow along with the [**Google Colab Notebook**](https://colab.research.google.com/drive/1A1lbPnBhtxL9jR7vFcm7Z0F0aJdEl-zj?usp=sharing)
    to make sure everything works as intended.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥è·Ÿéš[**Google Colab Notebook**](https://colab.research.google.com/drive/1A1lbPnBhtxL9jR7vFcm7Z0F0aJdEl-zj?usp=sharing)ä»¥ç¡®ä¿ä¸€åˆ‡æŒ‰é¢„æœŸå·¥ä½œã€‚
- en: ğŸ¤– Loading the Model
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ¤– åŠ è½½æ¨¡å‹
- en: In previous tutorials, we demonstrated how we could quantize the original modelâ€™s
    weight to make it run without running into memory problems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¹‹å‰çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å¯¹åŸå§‹æ¨¡å‹çš„æƒé‡è¿›è¡Œé‡åŒ–ï¼Œä»¥ä¾¿åœ¨ä¸é‡åˆ°å†…å­˜é—®é¢˜çš„æƒ…å†µä¸‹è¿è¡Œã€‚
- en: Over the course of the last few months, [TheBloke](https://huggingface.co/TheBloke)
    has been working hard on doing the quantization for hundreds of models for us.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿‡å»å‡ ä¸ªæœˆé‡Œï¼Œ[TheBloke](https://huggingface.co/TheBloke)ä¸ºæˆ‘ä»¬è¾›å‹¤å·¥ä½œï¼Œå¯¹æ•°ç™¾ä¸ªæ¨¡å‹è¿›è¡Œäº†é‡åŒ–ã€‚
- en: This way, we can download the model directly which will speed things up quite
    a bit.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä¸‹è½½æ¨¡å‹ï¼Œè¿™å°†å¤§å¤§åŠ å¿«é€Ÿåº¦ã€‚
- en: Weâ€™ll start with loading the model itself. We will offload 50 layers to the
    GPU. This will reduce RAM usage and use VRAM instead. If you are running into
    memory errors, reducing this parameter (`gpu_layers`) might help!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»åŠ è½½æ¨¡å‹æœ¬èº«å¼€å§‹ã€‚æˆ‘ä»¬å°†æŠŠ50å±‚å¸è½½åˆ°GPUä¸Šã€‚è¿™å°†å‡å°‘RAMä½¿ç”¨é‡ï¼Œè€Œä½¿ç”¨VRAMã€‚å¦‚æœä½ é‡åˆ°å†…å­˜é”™è¯¯ï¼Œå‡å°‘è¿™ä¸ªå‚æ•°ï¼ˆ`gpu_layers`ï¼‰å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ï¼
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After having loaded the model itself, we want to create a ğŸ¤— Transformers pipeline.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŠ è½½äº†æ¨¡å‹æœ¬èº«åï¼Œæˆ‘ä»¬æƒ³åˆ›å»ºä¸€ä¸ªğŸ¤— Transformersç®¡é“ã€‚
- en: The main benefit of doing so is that these pipelines are found in many tutorials
    and are often used in packages as a backend. Thus far, `ctransformers` is not
    yet natively supported as much as `transformers`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·åšçš„ä¸»è¦å¥½å¤„æ˜¯ï¼Œè¿™äº›ç®¡é“åœ¨è®¸å¤šæ•™ç¨‹ä¸­éƒ½æœ‰å‡ºç°ï¼Œé€šå¸¸ä½œä¸ºåå°åœ¨è½¯ä»¶åŒ…ä¸­ä½¿ç”¨ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œ`ctransformers`çš„åŸç”Ÿæ”¯æŒç¨‹åº¦è¿˜æ²¡æœ‰`transformers`é‚£ä¹ˆé«˜ã€‚
- en: Loading the Mistral tokenizer with `ctransformers` is not yet possible as the
    model is quite new. Instead, we use the tokenizer from the original repository
    instead.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºMistralçš„åˆ†è¯å™¨ç›¸å¯¹è¾ƒæ–°ï¼Œå°šæ— æ³•ä½¿ç”¨`ctransformers`åŠ è½½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸå§‹ä»“åº“ä¸­çš„åˆ†è¯å™¨ã€‚
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ğŸ“„ Prompt Engineering
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ“„ æç¤ºå·¥ç¨‹
- en: 'Letâ€™s see if this works with a very basic example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç”¨ä¸€ä¸ªéå¸¸åŸºç¡€çš„ç¤ºä¾‹æ¥çœ‹çœ‹è¿™æ˜¯å¦æœ‰æ•ˆï¼š
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Perfect! It can handle a very basic question. For the purpose of keyword extraction,
    letâ€™s explore whether it can handle a bit more complexity.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œç¾ï¼å®ƒå¯ä»¥å¤„ç†ä¸€ä¸ªéå¸¸åŸºæœ¬çš„é—®é¢˜ã€‚ä¸ºäº†å…³é”®è¯æå–çš„ç›®çš„ï¼Œè®©æˆ‘ä»¬æ¢ç´¢ä¸€ä¸‹å®ƒæ˜¯å¦èƒ½å¤„ç†æ›´å¤šçš„å¤æ‚æ€§ã€‚
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We get the following output:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It does great! However, if we want the structure of the output to stay consistent
    regardless of the input text we will have to give the LLM an example.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒè¡¨ç°å¾—éå¸¸å¥½ï¼ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›è¾“å‡ºçš„ç»“æ„åœ¨è¾“å…¥æ–‡æœ¬ä¸åŒçš„æƒ…å†µä¸‹ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬éœ€è¦ç»™LLMä¸€ä¸ªç¤ºä¾‹ã€‚
- en: This is where more advanced prompt engineering comes in. As with most Large
    Language Models, Mistral 7B expects a certain prompt format. This is tremendously
    helpful when we want to show what a â€œcorrectâ€ interaction looks like.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æ›´é«˜çº§æç¤ºå·¥ç¨‹çš„ç”¨æ­¦ä¹‹åœ°ã€‚ä¸å¤§å¤šæ•°å¤§å‹è¯­è¨€æ¨¡å‹ä¸€æ ·ï¼ŒMistral 7BæœŸæœ›ç‰¹å®šçš„æç¤ºæ ¼å¼ã€‚å½“æˆ‘ä»¬æƒ³å±•ç¤ºâ€œæ­£ç¡®â€äº¤äº’çš„æ ·å­æ—¶ï¼Œè¿™éå¸¸æœ‰å¸®åŠ©ã€‚
- en: 'The prompt template is as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºæ¨¡æ¿å¦‚ä¸‹ï¼š
- en: '![](../Images/ed736ed8bd3f7f90ec3b71a5fe87d324.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed736ed8bd3f7f90ec3b71a5fe87d324.png)'
- en: Based on that template, letâ€™s create a template for keyword extraction.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºäºè¯¥æ¨¡æ¿ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå…³é”®è¯æå–çš„æ¨¡æ¿ã€‚
- en: 'It needs to have two components:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒéœ€è¦æœ‰ä¸¤ä¸ªç»„ä»¶ï¼š
- en: '`Example prompt` - This will be used to show the LLM what a â€œgoodâ€ output looks
    like'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Example prompt` - è¿™å°†ç”¨äºå‘LLMå±•ç¤ºâ€œè‰¯å¥½â€è¾“å‡ºçš„æ ·å­'
- en: '`Keyword prompt` - This will be used to ask the LLM to extract the keywords'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Keyword prompt` - è¿™å°†ç”¨äºè¯·æ±‚LLMæå–å…³é”®è¯'
- en: The first component, the `example_prompt`, will simply be an example of correctly
    extracting the keywords in the format that we are interested in.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªç»„ä»¶ï¼Œ`example_prompt`ï¼Œå°†ä»…ä»…æ˜¯ä¸€ä¸ªæ­£ç¡®æå–å…³é”®è¯çš„ç¤ºä¾‹ï¼Œç¬¦åˆæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ ¼å¼ã€‚
- en: 'The **format** is a key component since it will make sure that the LLM will
    always output keywords the way we want:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ ¼å¼**æ˜¯ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œå› ä¸ºå®ƒç¡®ä¿LLMå§‹ç»ˆä»¥æˆ‘ä»¬å¸Œæœ›çš„æ–¹å¼è¾“å‡ºå…³é”®è¯ï¼š'
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The second component, the `keyword_prompt`, will essentially be a repeat of
    the `example_prompt` but with two changes:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒä¸ªç»„ä»¶ï¼Œ`keyword_prompt`ï¼Œå®é™…ä¸Šæ˜¯`example_prompt`çš„é‡å¤ï¼Œåªä¸è¿‡æœ‰ä¸¤ä¸ªå˜åŒ–ï¼š
- en: It will not have an output yet. That will be generated by the LLM.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒè¿˜ä¸ä¼šæœ‰è¾“å‡ºã€‚é‚£å°†ç”±LLMç”Ÿæˆã€‚
- en: We make use of `KeyBERT`â€™s **[DOCUMENT]** tag for indicating where the input
    document will go.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`KeyBERT`çš„**[DOCUMENT]**æ ‡ç­¾æ¥æŒ‡ç¤ºè¾“å…¥æ–‡æ¡£çš„ä½ç½®ã€‚
- en: We can use the **[DOCUMENT]** to insert a document at a location of your choice.
    Having this option helps us to change the structure of the prompt if needed without
    being set on having the prompt at a specific location.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨**[DOCUMENT]**å°†æ–‡æ¡£æ’å…¥åˆ°æ‚¨é€‰æ‹©çš„ä½ç½®ã€‚è¿™ä¸ªé€‰é¡¹æœ‰åŠ©äºæˆ‘ä»¬åœ¨éœ€è¦æ—¶æ›´æ”¹æç¤ºçš„ç»“æ„ï¼Œè€Œä¸å¿…å°†æç¤ºè®¾ç½®åœ¨ç‰¹å®šä½ç½®ã€‚
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Lastly, we combine the two prompts to create our final template:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å°†ä¸¤ä¸ªæç¤ºåˆå¹¶ä»¥åˆ›å»ºæˆ‘ä»¬çš„æœ€ç»ˆæ¨¡æ¿ï¼š
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now that we have our final prompt template, we can start exploring a couple
    of interesting new features in `KeyBERT` with `KeyLLM`. We will start by exploring
    `KeyLLM` only using Mistralâ€™s 7B model
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†æœ€ç»ˆçš„æç¤ºæ¨¡æ¿ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ¢ç´¢`KeyBERT`ä¸`KeyLLM`çš„ä¸€äº›æœ‰è¶£çš„æ–°åŠŸèƒ½ã€‚æˆ‘ä»¬å°†é¦–å…ˆæ¢ç´¢ä»…ä½¿ç”¨Mistralçš„7Bæ¨¡å‹çš„`KeyLLM`
- en: ğŸ—ï¸ Keyword Extraction with `KeyLLM`
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ—ï¸ ä½¿ç”¨`KeyLLM`è¿›è¡Œå…³é”®è¯æå–
- en: Keyword extraction with vanilla `KeyLLM` couldnâ€™t be more straightforward; we
    simply ask it to extract keywords from a document.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åŸç”Ÿ`KeyLLM`è¿›è¡Œå…³é”®è¯æå–æ˜¯æå…¶ç®€å•çš„ï¼›æˆ‘ä»¬åªéœ€è®©å®ƒä»æ–‡æ¡£ä¸­æå–å…³é”®è¯å³å¯ã€‚
- en: '![](../Images/80116740c612fd002adc807f474e5863.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80116740c612fd002adc807f474e5863.png)'
- en: This idea of extracting keywords from documents through an LLM is straightforward
    and allows for easily testing your LLM and its capabilities.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ LLM ä»æ–‡æ¡£ä¸­æå–å…³é”®è¯çš„æƒ³æ³•å¾ˆç®€å•ï¼Œå¯ä»¥è½»æ¾æµ‹è¯•ä½ çš„ LLM åŠå…¶åŠŸèƒ½ã€‚
- en: Using `KeyLLM` is straightforward, we start by loading our LLM through `keybert.llm.TextGeneration`
    and give it the prompt template that we created before.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`KeyLLM`å¾ˆç®€å•ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡`keybert.llm.TextGeneration`åŠ è½½æˆ‘ä»¬çš„ LLMï¼Œå¹¶ç»™å®ƒä¹‹å‰åˆ›å»ºçš„æç¤ºæ¨¡æ¿ã€‚
- en: 'ğŸ”¥ **Tip** ğŸ”¥: If you want to use a different LLM, like ChatGPT, you can find
    a full overview of implemented algorithms [here:](https://maartengr.github.io/KeyBERT/guides/llms.html)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”¥ **æç¤º** ğŸ”¥ï¼šå¦‚æœä½ æƒ³ä½¿ç”¨ä¸åŒçš„ LLMï¼Œå¦‚ ChatGPTï¼Œä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://maartengr.github.io/KeyBERT/guides/llms.html)æŸ¥çœ‹å·²å®ç°ç®—æ³•çš„å®Œæ•´æ¦‚è¿°ã€‚
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After preparing our `KeyLLM` instance, it is as simple as running `.extract_keywords`
    over your documents:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‡†å¤‡å¥½æˆ‘ä»¬çš„`KeyLLM`å®ä¾‹åï¼Œåªéœ€å¯¹ä½ çš„æ–‡æ¡£è¿è¡Œ`.extract_keywords`å³å¯ï¼š
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We get the following keywords:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å…³é”®è¯ï¼š
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: These seem like a great set of keywords!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å…³é”®è¯çœ‹èµ·æ¥å¾ˆæ£’ï¼
- en: You can play around with the prompt to specify the kind of keywords you want
    extracted, how long they can be, and even in which language they should be returned
    if your LLM is multi-lingual.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥è°ƒæ•´æç¤ºä»¥æŒ‡å®šä½ æƒ³æå–çš„å…³é”®è¯ç±»å‹ï¼Œå®ƒä»¬å¯ä»¥æœ‰å¤šé•¿ï¼Œç”šè‡³åœ¨ LLM æ˜¯å¤šè¯­è¨€çš„æƒ…å†µä¸‹è¿”å›å“ªç§è¯­è¨€ã€‚
- en: ğŸš€ Efficient Keyword Extraction with `KeyLLM`
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸš€ ä½¿ç”¨`KeyLLM`è¿›è¡Œé«˜æ•ˆå…³é”®è¯æå–
- en: Iterating your LLM over thousands of documents is not the most efficient approach!
    Instead, we can leverage embedding models to make the keyword extraction a bit
    more efficient.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æˆåƒä¸Šä¸‡çš„æ–‡æ¡£è¿›è¡Œ LLM è¿­ä»£å¹¶ä¸æ˜¯æœ€æœ‰æ•ˆçš„æ–¹æ³•ï¼ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨åµŒå…¥æ¨¡å‹ä½¿å…³é”®è¯æå–æ›´é«˜æ•ˆã€‚
- en: This works as follows. First, we embed all of our documents and convert them
    to numerical representations. Second, we find out which documents are most similar
    to one another. We assume that documents that are highly similar will have the
    same keywords, so there would be no need to extract keywords for all documents.
    Third, we only extract keywords from 1 document in each cluster and assign the
    keywords to all documents in the same cluster.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¿‡ç¨‹å¦‚ä¸‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ‰€æœ‰æ–‡æ¡£åµŒå…¥å¹¶è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æ‰¾å‡ºå“ªäº›æ–‡æ¡£å½¼æ­¤æœ€ç›¸ä¼¼ã€‚æˆ‘ä»¬å‡è®¾é«˜åº¦ç›¸ä¼¼çš„æ–‡æ¡£å°†å…·æœ‰ç›¸åŒçš„å…³é”®è¯ï¼Œå› æ­¤ä¸éœ€è¦ä¸ºæ‰€æœ‰æ–‡æ¡£æå–å…³é”®è¯ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬åªä»æ¯ä¸ªç°‡ä¸­çš„ä¸€ä¸ªæ–‡æ¡£ä¸­æå–å…³é”®è¯ï¼Œå¹¶å°†è¿™äº›å…³é”®è¯åˆ†é…ç»™åŒä¸€ç°‡ä¸­çš„æ‰€æœ‰æ–‡æ¡£ã€‚
- en: This is much more efficient and also quite flexible. The clusters are generated
    purely based on the similarity between documents, without taking cluster structures
    into account. In other words, it is essentially finding near-duplicate documents
    that we expect to have the same set of keywords.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ›´é«˜æ•ˆï¼Œè€Œä¸”ç›¸å½“çµæ´»ã€‚ç°‡æ˜¯çº¯ç²¹åŸºäºæ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼æ€§ç”Ÿæˆçš„ï¼Œè€Œä¸è€ƒè™‘ç°‡ç»“æ„ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒæœ¬è´¨ä¸Šæ˜¯åœ¨å¯»æ‰¾æˆ‘ä»¬é¢„æœŸå…·æœ‰ç›¸åŒå…³é”®è¯é›†åˆçš„è¿‘é‡å¤æ–‡æ¡£ã€‚
- en: '![](../Images/eaa53dc36d4b4e0a0d725a0870665841.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eaa53dc36d4b4e0a0d725a0870665841.png)'
- en: To do this with `KeyLLM`, we embed our documents beforehand and pass them to
    `.extract_keywords`. The threshold indicates how similar documents will minimally
    need to be in order to be assigned to the same cluster.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨`KeyLLM`å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æå‰åµŒå…¥æ–‡æ¡£å¹¶å°†å®ƒä»¬ä¼ é€’ç»™`.extract_keywords`ã€‚é˜ˆå€¼æŒ‡ç¤ºæ–‡æ¡£éœ€è¦å¤šç›¸ä¼¼æ‰èƒ½åˆ†é…åˆ°åŒä¸€ä¸ªç°‡ã€‚
- en: Increasing this value to something like .95 will identify near-identical documents
    whereas setting it to something like .5 will identify documents about the same
    topic.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ­¤å€¼å¢åŠ åˆ°åƒ.95è¿™æ ·çš„æ•°å­—å°†è¯†åˆ«è¿‘ä¹ç›¸åŒçš„æ–‡æ¡£ï¼Œè€Œå°†å…¶è®¾ç½®ä¸ºåƒ.5è¿™æ ·çš„å€¼å°†è¯†åˆ«å…³äºç›¸åŒä¸»é¢˜çš„æ–‡æ¡£ã€‚
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We get the following keywords:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å…³é”®è¯ï¼š
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this example, we can see that the first two documents were clustered together
    and received the same keywords. Instead of passing all three documents to the
    LLM, we only pass two documents. This can speed things up significantly if you
    have thousands of documents.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å‰ä¸¤ä¸ªæ–‡æ¡£è¢«èšç±»åœ¨ä¸€èµ·å¹¶è·å¾—äº†ç›¸åŒçš„å…³é”®è¯ã€‚æˆ‘ä»¬åªä¼ é€’ä¸¤ä¸ªæ–‡æ¡£ï¼Œè€Œä¸æ˜¯ä¼ é€’æ‰€æœ‰ä¸‰ä¸ªæ–‡æ¡£ã€‚å¦‚æœä½ æœ‰æˆåƒä¸Šä¸‡çš„æ–‡æ¡£ï¼Œè¿™å¯ä»¥æ˜¾è‘—åŠ å¿«é€Ÿåº¦ã€‚
- en: ğŸ† Efficient Keyword Extraction with `KeyBERT` & `KeyLLM`
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ† ä½¿ç”¨`KeyBERT`å’Œ`KeyLLM`è¿›è¡Œé«˜æ•ˆå…³é”®è¯æå–
- en: Before, we manually passed the embeddings to `KeyLLM` to essentially do a zero-shot
    extraction of keywords. We can further extend this example by leveraging `KeyBERT`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹å‰ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å°†åµŒå…¥ä¼ é€’ç»™`KeyLLM`ä»¥è¿›è¡Œé›¶-shot å…³é”®è¯æå–ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ©ç”¨`KeyBERT`è¿›ä¸€æ­¥æ‰©å±•è¿™ä¸ªä¾‹å­ã€‚
- en: Since `KeyBERT` generates keywords and embeds the documents, we can leverage
    that to not only simplify the pipeline but suggest a number of keywords to the
    LLM.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº`KeyBERT`ç”Ÿæˆå…³é”®è¯å¹¶åµŒå…¥æ–‡æ¡£ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ä¸€ç‚¹ä¸ä»…ç®€åŒ–æµç¨‹ï¼Œè¿˜å¯ä»¥å‘ LLM å»ºè®®ä¸€äº›å…³é”®è¯ã€‚
- en: These suggested keywords can help the LLM decide on the keywords to use. Moreover,
    it allows for everything within `KeyBERT` to be used with `KeyLLM`!
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å»ºè®®çš„å…³é”®å­—å¯ä»¥å¸®åŠ©LLMå†³å®šä½¿ç”¨å“ªäº›å…³é”®å­—ã€‚æ­¤å¤–ï¼Œè¿™å…è®¸`KeyBERT`ä¸­çš„æ‰€æœ‰å†…å®¹ä¸`KeyLLM`ä¸€èµ·ä½¿ç”¨ï¼
- en: '![](../Images/fbe7f8a1b581d44e8cc90b0aed10af87.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbe7f8a1b581d44e8cc90b0aed10af87.png)'
- en: 'This efficient keyword extraction with both `KeyBERT` and `KeyLLM` only requires
    three lines of code! We create a KeyBERT model and assign it the LLM with the
    embedding model we previously created:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§é«˜æ•ˆçš„å…³é”®å­—æå–æ–¹æ³•ï¼Œä½¿ç”¨`KeyBERT`å’Œ`KeyLLM`åªéœ€è¦ä¸‰è¡Œä»£ç ï¼æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªKeyBERTæ¨¡å‹ï¼Œå¹¶å°†ä¹‹å‰åˆ›å»ºçš„åµŒå…¥æ¨¡å‹åˆ†é…ç»™LLMï¼š
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We get the following keywords:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å…³é”®å­—ï¼š
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: And that is it! With `KeyLLM` you are able to use Large Language Models to help
    create better keywords. We can choose to extract keywords from the text itself
    or ask the LLM to come up with keywords.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼ä½¿ç”¨`KeyLLM`ï¼Œä½ å¯ä»¥åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ¥å¸®åŠ©åˆ›å»ºæ›´å¥½çš„å…³é”®å­—ã€‚æˆ‘ä»¬å¯ä»¥é€‰æ‹©ä»æ–‡æœ¬æœ¬èº«æå–å…³é”®å­—ï¼Œæˆ–è€…è®©LLMæå‡ºå…³é”®å­—ã€‚
- en: By combining `KeyLLM` with `KeyBERT`, we increase its potential by doing some
    computation and suggestions beforehand.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†`KeyLLM`ä¸`KeyBERT`ç»“åˆä½¿ç”¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›è®¡ç®—å’Œå»ºè®®æ¥å¢åŠ å…¶æ½œåŠ›ã€‚
- en: '**Update**: I uploaded a video version to YouTube that goes more in-depth into
    how to use KeyLLM:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ›´æ–°**ï¼šæˆ‘åœ¨YouTubeä¸Šä¸Šä¼ äº†ä¸€ä¸ªè§†é¢‘ç‰ˆæœ¬ï¼Œæ›´æ·±å…¥åœ°è®²è§£äº†å¦‚ä½•ä½¿ç”¨KeyLLMï¼š'
- en: Thank you for reading!
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼
- en: If you are, like me, passionate about AI and/or Psychology, please feel free
    to add me on [**LinkedIn**](https://www.linkedin.com/in/mgrootendorst/), follow
    me on [**Twitter**](https://twitter.com/MaartenGr), or subscribe to my [**Newsletter**](http://maartengrootendorst.substack.com/).
    You can also find some of my content on my [**Personal Website**](https://maartengrootendorst.com/).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å’Œæˆ‘ä¸€æ ·ï¼Œå¯¹AIå’Œ/æˆ–å¿ƒç†å­¦å……æ»¡çƒ­æƒ…ï¼Œè¯·éšæ—¶åœ¨[**LinkedIn**](https://www.linkedin.com/in/mgrootendorst/)ä¸Šæ·»åŠ æˆ‘ï¼Œåœ¨[**Twitter**](https://twitter.com/MaartenGr)ä¸Šå…³æ³¨æˆ‘ï¼Œæˆ–è€…è®¢é˜…æˆ‘çš„[**Newsletter**](http://maartengrootendorst.substack.com/)ã€‚ä½ è¿˜å¯ä»¥åœ¨æˆ‘çš„[**ä¸ªäººç½‘ç«™**](https://maartengrootendorst.com/)ä¸Šæ‰¾åˆ°ä¸€äº›æˆ‘çš„å†…å®¹ã€‚
- en: '*All images without a source credit were created by the author â€” Which means
    all of them, I like creating my own images ;)*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ‰€æœ‰æ²¡æœ‰æ¥æºä¿¡ç”¨çš„å›¾åƒéƒ½æ˜¯ä½œè€…åˆ›å»ºçš„â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æœ‰å›¾åƒéƒ½æ˜¯æˆ‘è‡ªå·±åˆ¶ä½œçš„ ;)*'
