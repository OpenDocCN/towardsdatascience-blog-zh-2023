- en: Temporal Graph Learning in 2023
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2023年的时间图学习
- en: 原文：[https://towardsdatascience.com/temporal-graph-learning-in-2023-d28d1640dbf2?source=collection_archive---------1-----------------------#2023-01-16](https://towardsdatascience.com/temporal-graph-learning-in-2023-d28d1640dbf2?source=collection_archive---------1-----------------------#2023-01-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/temporal-graph-learning-in-2023-d28d1640dbf2?source=collection_archive---------1-----------------------#2023-01-16](https://towardsdatascience.com/temporal-graph-learning-in-2023-d28d1640dbf2?source=collection_archive---------1-----------------------#2023-01-16)
- en: The story so far
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目前为止的故事
- en: '[](https://medium.com/@shenyanghuang1996?source=post_page-----d28d1640dbf2--------------------------------)[![Shenyang(Andy)
    Huang](../Images/ab63c37868db97b19480d536388930c5.png)](https://medium.com/@shenyanghuang1996?source=post_page-----d28d1640dbf2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d28d1640dbf2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d28d1640dbf2--------------------------------)
    [Shenyang(Andy) Huang](https://medium.com/@shenyanghuang1996?source=post_page-----d28d1640dbf2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@shenyanghuang1996?source=post_page-----d28d1640dbf2--------------------------------)[![Shenyang(Andy)
    Huang](../Images/ab63c37868db97b19480d536388930c5.png)](https://medium.com/@shenyanghuang1996?source=post_page-----d28d1640dbf2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d28d1640dbf2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d28d1640dbf2--------------------------------)
    [Shenyang(Andy) Huang](https://medium.com/@shenyanghuang1996?source=post_page-----d28d1640dbf2--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8aa224c5cedd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-learning-in-2023-d28d1640dbf2&user=Shenyang%28Andy%29+Huang&userId=8aa224c5cedd&source=post_page-8aa224c5cedd----d28d1640dbf2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d28d1640dbf2--------------------------------)
    ·15 min read·Jan 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd28d1640dbf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-learning-in-2023-d28d1640dbf2&user=Shenyang%28Andy%29+Huang&userId=8aa224c5cedd&source=-----d28d1640dbf2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8aa224c5cedd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-learning-in-2023-d28d1640dbf2&user=Shenyang%28Andy%29+Huang&userId=8aa224c5cedd&source=post_page-8aa224c5cedd----d28d1640dbf2---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d28d1640dbf2--------------------------------)
    ·15分钟阅读·2023年1月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd28d1640dbf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-learning-in-2023-d28d1640dbf2&user=Shenyang%28Andy%29+Huang&userId=8aa224c5cedd&source=-----d28d1640dbf2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd28d1640dbf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-learning-in-2023-d28d1640dbf2&source=-----d28d1640dbf2---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd28d1640dbf2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftemporal-graph-learning-in-2023-d28d1640dbf2&source=-----d28d1640dbf2---------------------bookmark_footer-----------)'
- en: Real world networks such as social, traffic and citation networks often evolve
    over time and the field of Temporal Graph Learning (TGL) aims to extract, learn
    and predict from these evolving networks. Recently, TGL has gained increasing
    attention from the ML community, with a surge in the number of papers and the
    [first workshop](https://sites.google.com/view/tglworkshop2022/home) in this area
    held last year at NeurIPS 2022!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的网络，如社交网络、交通网络和引用网络，往往会随着时间演变，而**时间图学习（TGL）**领域旨在从这些不断演变的网络中提取、学习和预测。最近，TGL在机器学习社区中受到越来越多的关注，相关论文数量激增，去年在NeurIPS
    2022上举办了该领域的[首个研讨会](https://sites.google.com/view/tglworkshop2022/home)！
- en: '![](../Images/8318f9cf45be7274d6407d27d3808232.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8318f9cf45be7274d6407d27d3808232.png)'
- en: Evolutions in a temporal graph. Image by authors.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 时间图中的演变。图片由作者提供。
- en: '*This post was co-authored with* [*Emanuele Rossi*](https://www.emanuelerossi.co.uk/),
    [*Michael Galkin*](https://migalkin.github.io/) *and* [*Kellin Pelrine*](https://scholar.google.com/citations?user=_s2HT_0AAAAJ&hl=en).
    *Thanks to* [*Farimah Poursafaei*](https://scholar.google.ca/citations?user=gZ7HEsMAAAAJ&hl=en)
    *for the helpful feedback.*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章由* [*Emanuele Rossi*](https://www.emanuelerossi.co.uk/), [*Michael Galkin*](https://migalkin.github.io/)
    *和* [*Kellin Pelrine*](https://scholar.google.com/citations?user=_s2HT_0AAAAJ&hl=en)
    *共同撰写。* *感谢* [*Farimah Poursafaei*](https://scholar.google.ca/citations?user=gZ7HEsMAAAAJ&hl=en)
    *提供的有益反馈。*'
- en: In this blog post, we present major progress in TGL until 2022 and discuss promising
    future directions. Note that we use the term “dynamic graph” and “temporal graph”
    interchangeably. If you want to learn or start a project in TGL, this article
    would be a good reference and starting point.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们展示了 TGL 在 2022 年之前的主要进展，并讨论了有前景的未来方向。请注意，我们将“动态图”和“时序图”交替使用。如果你想学习或开始一个
    TGL 项目，这篇文章将是一个很好的参考和起点。
- en: Please share with us in the comment section any other advances you are excited
    about.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 请在评论区与我们分享您感兴趣的其他进展。
- en: '**Table of Contents:**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**目录：**'
- en: '[Introduction to Temporal Graph Learning](#a31b)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[时序图学习简介](#a31b)'
- en: '[Expressiveness of Temporal Graph Networks](#ba74)'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[时序图网络的表达能力](#ba74)'
- en: '[Rethinking Evaluation in Temporal Graphs](#1305)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[重新思考时序图中的评估](#1305)'
- en: '[Temporal Knowledge Graphs](#8b9a)'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[时序知识图谱](#8b9a)'
- en: '[Libraries and Datasets](#e4ec)'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[库和数据集](#e4ec)'
- en: '[Disease Modeling with Temporal Graphs](#f7ab)'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[利用时序图进行疾病建模](#f7ab)'
- en: '[Anomaly Detection in Temporal Graphs](#c801)'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[时序图中的异常检测](#c801)'
- en: '[Detecting Misinformation on Temporal Graphs](#6386)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[检测时序图中的虚假信息](#6386)'
- en: '[Joining Temporal Graph Learning Community](#5628)'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[加入时序图学习社区](#5628)'
- en: Introduction to Temporal Graph Learning
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时序图学习简介
- en: 'In this section, we provide a brief overview of some well-known TGL methods
    in the literature. There exist two main broad classes of methods for learning
    on Continuous-Time Dynamic Graphs (CTDGs): Temporal Graph Networks and Walk Aggregating
    methods. For more details on the formulation of CTDGs, see this survey by [Kazemi
    et al.](https://arxiv.org/pdf/1905.11485.pdf)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们简要介绍了文献中一些著名的 TGL 方法。学习连续时间动态图（CTDGs）的方法主要分为两类：时序图网络和游走聚合方法。有关 CTDGs
    的详细信息，请参阅 [Kazemi 等](https://arxiv.org/pdf/1905.11485.pdf) 的这篇综述。
- en: Temporal Graph Networks ([TGNs](https://arxiv.org/abs/2006.10637)) generalize
    Message Passing Neural Networks ([MPNNs](https://dl.acm.org/doi/10.5555/3305381.3305512))
    to temporal graphs. They do so by introducing a node memory which represents the
    state of the node at a given time, acting as a compressed representation of the
    node’s past interactions. Every time two nodes are involved in an interaction,
    they send messages to each other which are then used to update their memories.
    When computing the embedding of a node, an additional graph aggregation is performed
    over the temporal neighbors of the node, using both the original node features
    and memory at that point in time. Below we show a diagram of the computation of
    TGN.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 时序图网络 ([TGNs](https://arxiv.org/abs/2006.10637)) 将信息传递神经网络 ([MPNNs](https://dl.acm.org/doi/10.5555/3305381.3305512))
    推广到时序图。它们通过引入一个节点记忆来实现，该记忆表示节点在给定时间的状态，作为节点过去交互的压缩表示。每当两个节点参与交互时，它们会相互发送消息，这些消息然后用于更新它们的记忆。在计算节点嵌入时，会对节点的时序邻居进行额外的图聚合，使用该时刻的原始节点特征和记忆。以下是
    TGN 计算的示意图。
- en: '![](../Images/c18e9bd0bc197d1d47dc82e3e91f864d.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c18e9bd0bc197d1d47dc82e3e91f864d.png)'
- en: Computations of TGN on a batch of training edges.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对一批训练边缘的 TGN 计算。
- en: 'Image source: [Rossi et al.](https://arxiv.org/abs/2006.10637)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Rossi 等](https://arxiv.org/abs/2006.10637)
- en: TGNs are a general framework that generalizes previous models such as Joint
    Dynamic User-Item Embeddings ([JODIE](https://snap.stanford.edu/jodie/)) and Temporal
    Graph Attention ([TGAT](https://openreview.net/forum?id=rJeW1yHYwH)) as specific
    cases. A more comprehensive introduction to TGNs can be found in the below blog
    post by one of the authors.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: TGN 是一个通用框架，它将以前的模型，如联合动态用户-项目嵌入 ([JODIE](https://snap.stanford.edu/jodie/))
    和时序图注意力 ([TGAT](https://openreview.net/forum?id=rJeW1yHYwH))，作为特例进行推广。有关 TGN 的更全面介绍，请参阅下面其中一位作者的博客文章。
- en: '[](/temporal-graph-networks-ab8f327f2efe?source=post_page-----d28d1640dbf2--------------------------------)
    [## Temporal Graph Networks'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/temporal-graph-networks-ab8f327f2efe?source=post_page-----d28d1640dbf2--------------------------------)
    [## 时序图网络'
- en: A new neural network architecture for dynamic graphs
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一种用于动态图的新型神经网络架构。
- en: towardsdatascience.com](/temporal-graph-networks-ab8f327f2efe?source=post_page-----d28d1640dbf2--------------------------------)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/temporal-graph-networks-ab8f327f2efe?source=post_page-----d28d1640dbf2--------------------------------)'
- en: Walk Aggregating methods such as Causal Anonymous Walks ([CAW](http://snap.stanford.edu/caw/))
    instead rely on (temporal) random walks. In particular, to predict the existence
    of a link *(u, v)* at time *t*, CAW first extracts multiple random walks starting
    from *u* and *v* such that the timestamps of edges in a walk can only be monotonically
    decreasing. The walks are first anonymized by replacing each node identifier with
    a count vector of how many times that node appears at each of the possible positions
    in the walks. Each walk is then encoded using an RNN, and the encodings are then
    aggregated by using self-attention or taking a simple average.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如 Causal Anonymous Walks ([CAW](http://snap.stanford.edu/caw/)) 这样的 Walk 聚合方法则依赖于（时间）随机游走。特别是，为了预测时间
    *t* 上的一个链接 *(u, v)* 的存在，CAW 首先提取多个从 *u* 和 *v* 开始的随机游走，使得游走中的边的时间戳只能单调递减。这些游走首先通过用节点在游走中每个可能位置出现的次数向量替换每个节点标识符来进行匿名化。然后，使用
    RNN 对每个游走进行编码，并通过自注意力或简单平均来聚合编码。
- en: Expressiveness of Temporal Graph Networks
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间图网络的表达力。
- en: There is a large body of work studying the expressive power of GNNs operating
    on static graphs. [Xu et al. 2019](https://openreview.net/pdf?id=ryGs6iA5Km) first
    characterized the discriminative power of Graph Neural Networks (GNNs) by connecting
    them to the Weisfeiler-Lehman (WL) graph isomorphism test and showing that many
    GNNs are no more powerful than the 1-WL test. Subsequent more expressive models
    such as [subgraph GNNs](/using-subgraphs-for-more-expressive-gnns-8d06418d5ab),
    [graph transformers](https://openreview.net/pdf?id=lMMaNf6oxKM%5C) and [higher
    order GNNs](https://arxiv.org/pdf/1810.02244.pdf) are designed to be more expressive
    than 1-WL test (below is link to [Michael Bronstein](https://michael-bronstein.medium.com/)’s
    excellent blog post on how to go beyond WL test).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在静态图上运行的图神经网络（GNNs）表达能力的研究已有大量工作。[Xu et al. 2019](https://openreview.net/pdf?id=ryGs6iA5Km)
    首次通过将图神经网络（GNNs）与 Weisfeiler-Lehman (WL) 图同构测试关联起来，并展示了许多 GNNs 的能力不超过 1-WL 测试，从而描述了其区分能力。随后，出现了更具表达能力的模型，如
    [子图 GNNs](/using-subgraphs-for-more-expressive-gnns-8d06418d5ab)，[图变换器](https://openreview.net/pdf?id=lMMaNf6oxKM%5C)
    和 [高阶 GNNs](https://arxiv.org/pdf/1810.02244.pdf)，这些模型被设计得比 1-WL 测试更具表达力（下面是 [Michael
    Bronstein](https://michael-bronstein.medium.com/) 关于如何超越 WL 测试的精彩博客文章的链接）。
- en: '[](/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a?source=post_page-----d28d1640dbf2--------------------------------)
    [## Graph Neural Networks beyond Weisfeiler-Lehman and vanilla Message Passing'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Graph Neural Networks beyond Weisfeiler-Lehman and vanilla Message Passing](/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a?source=post_page-----d28d1640dbf2--------------------------------)'
- en: Physics-inspired continuous learning models on graphs allow to overcome the
    limitations of traditional GNNs
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 受物理启发的图上连续学习模型可以克服传统 GNNs 的局限性。
- en: towardsdatascience.com](/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a?source=post_page-----d28d1640dbf2--------------------------------)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a?source=post_page-----d28d1640dbf2--------------------------------)'
- en: Until this year, there has been little work on understanding the expressive
    power of TGL methods. The first effort to bridge this gap was by [Ribeiro et al.](https://proceedings.mlr.press/v162/gao22e.html)
    where the key idea is to categorize existing TGL methods into *time-and-graph*
    and *time-then-graph* frameworks.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 直到今年，关于 TGL 方法的表达力的研究仍然很少。第一个弥合这一差距的努力是由 [Ribeiro et al.](https://proceedings.mlr.press/v162/gao22e.html)
    提出的，其关键思想是将现有的 TGL 方法分为 *时间-和-图* 和 *时间-然后-图* 框架。
- en: '![](../Images/1adc4f01c0bb270cb1e3a66645cc95ae.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1adc4f01c0bb270cb1e3a66645cc95ae.png)'
- en: Converting a TG into time-then-graph representation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将 TG 转换为时间-然后-图表示。
- en: 'image source: [Ribeiro et al.](https://arxiv.org/abs/2103.07016)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [Ribeiro et al.](https://arxiv.org/abs/2103.07016)'
- en: 1️). In *time-and-graph*, GNNs are used to generate node embeddings on the snapshot
    graph at each time thus forming a sequence of node embeddings.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 1️）。在 *时间-和-图* 中，GNNs 用于在每个时间快照图上生成节点嵌入，从而形成节点嵌入的序列。
- en: 2️). In *time-then-graph*, each edge in the TG is converted to a time series
    which indicates at which time the edge exists, therefore collapsing the temporal
    edges into edge features in a static graph.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 2️）。在 *时间-然后-图* 中，TG 中的每条边被转换为一个时间序列，该序列指示边存在的时间，从而将时间边折叠为静态图中的边特征。
- en: It was shown that a *time-then-graph* representation can be constructed from
    any given *time-and-graph* representation thus proving *time-then-graph* is at
    least as expressive as *time-and-graph.* With the static representation in *time-then-graph*,
    we can directly use the WL-test expressiveness framework from the static graph
    for TGL methods. In this way, *time-then-graph* is more expressive than *time-and-graph*
    as long as a 1-WL GNN is used as the backbone model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 已证明 *时间-然后-图* 表示可以从任何给定的 *时间-和-图* 表示中构建，从而证明 *时间-然后-图* 至少与 *时间-和-图* 一样具备表达力。通过在
    *时间-然后-图* 中的静态表示，我们可以直接将静态图的 WL 测试表达框架应用于 TGL 方法。这样，只要使用 1-WL GNN 作为主干模型，*时间-然后-图*
    就比 *时间-和-图* 更具表达力。
- en: '[Souza et al.](https://openreview.net/pdf?id=MwSXgQSxL5s) also aims to establish
    the 1-WL expressiveness framework for TGL methods. Notably, they view a CTDG as
    a sequence of time-stamped multi-graphs where the multi-graph *G(t)* at a given
    time *t* is obtained by sequentially applying all events prior to *t.* A multi-graph
    here means there can be multiple edges between two nodes in the graph and the
    edge attribute is the timestamp information.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[Souza et al.](https://openreview.net/pdf?id=MwSXgQSxL5s) 也旨在为 TGL 方法建立 1-WL
    表达框架。值得注意的是，他们将 CTDG 视为一系列时间戳多图，其中在给定时间 *t* 的多图 *G(t)* 是通过顺序应用所有早于 *t* 的事件来获得的。这里的多图意味着两个节点之间可以有多条边，而边的属性是时间戳信息。'
- en: Now, the Temporal WL test can be defined by applying the WL test on the multigraphs
    constructed from CTDGs. Therefore, more expressive TGN methods must be injective
    on its temporal neighborhood (i.e. hashing two different multi-set nodes into
    different colors), called injective MP-TGNs. [Souza et al.](https://openreview.net/pdf?id=MwSXgQSxL5s)
    also analyzed walk based TGNs such as [CAW](http://snap.stanford.edu/caw/) and
    show that MP-TGNs and CAW are not more expressive than each other (as seen above).
    Their proposed PINT method combines benefits from both categories of methods thus
    being the most expressive. The example below shows two temporal graphs that MP-TGNs
    are unable to distinguish. The colors are node labels and the edge has timestamps
    starting from *t₁*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，时间 WL 测试可以通过对从 CTDG 构建的多图应用 WL 测试来定义。因此，更具表达力的 TGN 方法必须在其时间邻域上是单射的（即将两个不同的多集节点哈希为不同的颜色），称为单射
    MP-TGNs。[Souza et al.](https://openreview.net/pdf?id=MwSXgQSxL5s) 还分析了基于游走的 TGNs，如
    [CAW](http://snap.stanford.edu/caw/)，并显示 MP-TGNs 和 CAW 之间并没有比彼此更具表达力（如上所示）。他们提出的
    PINT 方法结合了这两类方法的优点，因此是最具表达力的。下面的示例显示了 MP-TGNs 无法区分的两个时间图。颜色表示节点标签，边的时间戳从 *t₁*
    开始。
- en: '![](../Images/fa101bc3babee6d1c6350da5ff64f895.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa101bc3babee6d1c6350da5ff64f895.png)'
- en: Examples of temporal graphs for which MP-TGNs are unable to distinguish graph
    structures such as diameter, girth, and number of cycles.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: MP-TGNs 无法区分的时间图示例，例如直径、环长和循环数量。
- en: 'Image source: [Souza et al.](https://arxiv.org/abs/2209.15059)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Souza et al.](https://arxiv.org/abs/2209.15059)
- en: Rethinking Evaluation in Temporal Graphs
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重新思考时间图中的评估
- en: 'To a large extent, the evaluation procedure in TGL is relatively under-explored
    and heavily influenced by static graph learning. For example, evaluation on the
    link prediction task on dynamic graphs (or dynamic link prediction) often involves:
    1). *fixed train, test split*, 2). *random negative edge sampling* and 3). *small
    datasets from similar domains*. Such evaluation protocols often lead to result
    tables where reported metrics are already around 95+% and it’s really hard to
    distinguish whether new models bring any benefit or just rehash existing methods
    again.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在很大程度上，TGL 中的评估程序相对未被充分探索，并且受到静态图学习的重大影响。例如，对动态图上的链路预测任务（或动态链路预测）的评估通常涉及：1）。*固定的训练、测试拆分*，2）。*随机负边采样*
    和 3）。*来自类似领域的小数据集*。这样的评估协议往往导致结果表中报告的指标已经达到 95% 以上，很难区分新模型是否带来了实际的好处，还是只是重新使用现有方法。
- en: '![](../Images/8fd48489b3f4fb80c50944eaa712ab7a.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fd48489b3f4fb80c50944eaa712ab7a.png)'
- en: A typical temporal link prediction result table reporting Average Precision
    (AP). Are we really making any progress when even baselines yield 98%?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的时间链路预测结果表，报告了平均精度（AP）。即使基线模型也能达到98%，我们真的在取得进展吗？
- en: 'Image source: [Souza et al.](https://arxiv.org/abs/2209.15059)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [Souza 等](https://arxiv.org/abs/2209.15059)'
- en: '[You et al.](https://arxiv.org/abs/2208.07239) discussed the limitations of
    current TGL methods in model design, evaluation settings and training strategies
    for Discrete Time Dynamic Graphs (DTDGs). They argue that the evolving nature
    of data and models are not accounted for. In standard evaluation, all time points
    are split chronologically into a training set, an evaluation set and then a test
    set. The split is fixed for a given dataset.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[You 等](https://arxiv.org/abs/2208.07239) 讨论了当前 TGL 方法在离散时间动态图（DTDGs）中的模型设计、评估设置和训练策略的局限性。他们认为数据和模型的演变特性没有被考虑。在标准评估中，所有时间点按时间顺序划分为训练集、评估集和测试集。对于给定的数据集，这种划分是固定的。'
- en: They pointed out that such a fixed split means only edges from the chosen test
    period would be evaluated thus long term behavior potentially spanning training,
    validation and test period would not be correctly evaluated. In addition, many
    TGL methods are stale at test time, meaning that the model representation is not
    updated with information during evaluation. Consider an example transaction graph,
    if information on the prior day is available, the user would likely want to update
    the model with such information to achieve the best possible performance. Therefore,
    a live-update evaluation is proposed where models are finetuned with newly observed
    data, utilizing historical information and predicting future links.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 他们指出，这种固定的划分意味着只有来自所选测试期的边会被评估，因此可能跨越训练、验证和测试期的长期行为将无法正确评估。此外，许多 TGL 方法在测试时是过时的，意味着模型表示在评估过程中没有得到更新。考虑一个示例交易图，如果前一天的信息可用，用户很可能希望利用这些信息来更新模型，以实现最佳性能。因此，提出了一种实时更新评估的方法，其中模型根据新观察到的数据进行微调，利用历史信息并预测未来的连接。
- en: '![](../Images/3177c3500825244ea4dc8109926d7259.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3177c3500825244ea4dc8109926d7259.png)'
- en: Grey / red bars indicate the amount of recurring / novel edges respectively
    in the Wikipedia / MOOC dataset. Many edges recur over time in temporal graphs.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 灰色/红色条分别表示 Wikipedia / MOOC 数据集中的重复/新颖边。时间图中的许多边随时间重复出现。
- en: 'Image source: [*Poursafaei et al.*](https://arxiv.org/abs/2207.10128)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [*Poursafaei 等*](https://arxiv.org/abs/2207.10128)'
- en: '[Recent work](https://openreview.net/forum?id=1GVpwr2Tfdg) by two of the authors
    examines which negative edges to sample for evaluation of CTDG methods and introduces
    more datasets from diverse domains. When evaluating dynamic link prediction, negative
    edges are often randomly sampled from any node pair. However, many edges in a
    temporal graph recur over time (as seen in the figure above). Considering the
    sparsity of real world graphs, the majority of node pairs are unlikely to form
    an edge. Therefore, *random* negative edges can be seen as *easy* negative edges.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[近期工作](https://openreview.net/forum?id=1GVpwr2Tfdg)由两位作者研究了如何选择负边进行 CTDG 方法的评估，并引入了来自不同领域的更多数据集。在动态链接预测中，负边通常是从任意节点对中随机抽取的。然而，时间图中的许多边会随着时间的推移而重复（如上图所示）。考虑到现实世界图的稀疏性，大多数节点对不太可能形成边。因此，*随机*
    负边可以被视为*容易*的负边。'
- en: '![](../Images/c1a1e4a8ab7287729ba5feeb337d1efa.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1a1e4a8ab7287729ba5feeb337d1efa.png)'
- en: Avg. Performance of TGL methods. Using more difficult negative edges significantly
    impacts model performance. The simple baseline EdgeBank also works surprisingly
    well.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: TGL 方法的平均性能。使用更困难的负边显著影响模型性能。简单的基线 EdgeBank 的表现也出奇地好。
- en: 'Image source: [*Poursafaei et al.*](https://arxiv.org/abs/2207.10128)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [*Poursafaei 等*](https://arxiv.org/abs/2207.10128)'
- en: Now, what can be considered as *hard* negative edges? First, we introduce the
    *historical* negative edges which are edges that appeared in the training set
    but are absent in the current test step. We also define *inductive* negative edges
    as test edges which occurred previously in the test set but are not present at
    the current step. Lastly, we propose a baseline EdgeBank relying solely on memorizing
    past edges (essentially a hashtable of seen edges). In the plot above, we see
    that by changing the negative edges for evaluation, the average performance of
    existing TGL methods reduces significantly in the *historical* and *inductive*
    setting when compared to the *standard* setting. EdgeBank is also a surprisingly
    strong baseline for the *standard* setting. For details, see the blog below from
    one of the authors.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，什么可以被视为*困难*的负边？首先，我们介绍*历史*负边，即在训练集中出现但在当前测试步骤中缺失的边。我们还将*归纳*负边定义为在测试集中之前出现但在当前步骤中不存在的测试边。最后，我们提出了一个基线EdgeBank，仅依靠记住过去的边（本质上是已见边的哈希表）。在上面的图中，我们看到，通过改变负边进行评估时，现有TGL方法在*历史*和*归纳*设置下的平均性能显著降低，与*标准*设置相比。EdgeBank
    在*标准*设置下也是一个出乎意料的强大基线。有关详细信息，请参见下方作者之一的博客。
- en: '[](https://medium.com/@shenyanghuang1996/towards-better-link-prediction-in-dynamic-graphs-cdb8bb1e24e9?source=post_page-----d28d1640dbf2--------------------------------)
    [## Towards Better Link Prediction in Dynamic Graphs'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@shenyanghuang1996/towards-better-link-prediction-in-dynamic-graphs-cdb8bb1e24e9?source=post_page-----d28d1640dbf2--------------------------------)
    [## 迈向更好的动态图链接预测'
- en: companion blog post for Towards Better Evaluation for Dynamic Link Prediction,
    to appear in NeurIPS 2022 Dataset and…
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 伴随博客文章，介绍了《迈向更好的动态链接预测》的评估，将在 NeurIPS 2022 数据集和…
- en: medium.com](https://medium.com/@shenyanghuang1996/towards-better-link-prediction-in-dynamic-graphs-cdb8bb1e24e9?source=post_page-----d28d1640dbf2--------------------------------)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@shenyanghuang1996/towards-better-link-prediction-in-dynamic-graphs-cdb8bb1e24e9?source=post_page-----d28d1640dbf2--------------------------------)
- en: Temporal Knowledge Graphs
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间知识图谱
- en: In the realm of Knowledge Graphs (KGs), temporal setup is slightly different
    from the homogeneous world, i.e., timestamped graph snapshots are not that common.
    Instead, some (or all) triples have an accompanying (start time, end time) pair
    of attributes denoting the time frame when a given fact was true. Triples thus
    become *quintuples,* or, in Wikidata, time attributes become [*qualifiers*](https://www.wikidata.org/wiki/Help:Qualifiers)
    of a more general [*statement*](https://www.wikidata.org/wiki/Help:Statements)(main
    triple + multiple key-value qualifiers), and statements form so-called [hyper-relational
    KGs](/representation-learning-on-rdf-and-lpg-knowledge-graphs-6a92f2660241)*.*
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在知识图谱（KG）的领域中，时间设置与同质世界略有不同，即时间戳图快照并不常见。相反，一些（或所有）三元组具有一个（开始时间，结束时间）对属性，表示某个事实为真的时间范围。因此，三元组变成了*五元组*，或者在
    Wikidata 中，时间属性成为 [*限定词*](https://www.wikidata.org/wiki/Help:Qualifiers) 的一部分，更一般的
    [*声明*](https://www.wikidata.org/wiki/Help:Statements)（主三元组 + 多个键值限定词），声明形成所谓的
    [超关系KGs](/representation-learning-on-rdf-and-lpg-knowledge-graphs-6a92f2660241)*.*
- en: For example, `(President of the French republic, office holder, Nicolas Sarkozy,
    2007, 2012)` is a quintuple describing the time period where Nicolas Sarkozy was
    the President of the French republic. Alternatively, there can be only one timestamp
    per triple (forming quadruples). The most common prediction task is scoring head/tail
    prediction given the time attributes, e.g. , `(President of the French Republic,
    office holder, **???**, 2007, 2012)` — this can be considered as a particular
    case of the hyper-relational link prediction where qualifiers are only dateTime
    literals. A classic example of temporal KG completion model is [**TNTComplex**](https://arxiv.org/pdf/2004.04926.pdf)
    (ICLR 2020).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`(法国总统，职务持有者，尼古拉·萨科齐，2007，2012)` 是一个五元组，描述了尼古拉·萨科齐担任法国总统的时间段。或者，每个三元组也可以只有一个时间戳（形成四元组）。最常见的预测任务是给定时间属性评分头/尾预测，例如，`(法国总统，职务持有者，**???**，2007，2012)`
    —— 这可以被视为超关系链接预测的特例，其中限定词仅为日期时间文字。一个经典的时间KG补全模型是 [**TNTComplex**](https://arxiv.org/pdf/2004.04926.pdf)（ICLR
    2020）。
- en: '[Krause et al.](https://arxiv.org/pdf/2207.09964.pdf) has taken the first effort
    towards bridging the gap between temporal KGs and homogeneous graphs. In this
    work, the authors propose a framework to formalize various temporal aspects in
    KGs. Namely, they define **temporal** KGs as local extensions, i.e., graphs that
    have timestamps on the edges, and **dynamic** KGs as global extensions, i.e.,
    graphs that change topology over time by adding or removing nodes and edges. Even
    more, there can exits combinations of those basic types, e.g., a temporal and
    dynamic KG would be called **incremental**. We hope this work would bring a bit
    more order and clarity to the hectic literature on temporal KGs and the community
    would stick to the nice taxonomy. Next step: finalize a proper evaluation protocol
    for those graph types.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[Krause et al.](https://arxiv.org/pdf/2207.09964.pdf) 已经迈出了弥合时间知识图谱与同质图之间差距的第一步。在这项工作中，作者提出了一个框架，以形式化知识图谱中的各种时间方面。即，他们将
    **时间** 知识图谱定义为局部扩展，即边上具有时间戳的图，而 **动态** 知识图谱定义为全局扩展，即随着时间的推移通过添加或删除节点和边而改变拓扑的图。更进一步，这些基本类型的组合是存在的，例如，时间和动态知识图谱的组合被称为
    **增量**。我们希望这项工作能为时间知识图谱的繁杂文献带来更多秩序和清晰度，社区也能遵循这个良好的分类法。下一步：为这些图类型最终确定一个适当的评估协议。'
- en: '![](../Images/b33b6420eb72ee2d292b5b038008968f.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b33b6420eb72ee2d292b5b038008968f.png)'
- en: Temporal and Dynamic KGs (and their combinations).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 时间和动态知识图谱（及其组合）。
- en: 'Image source: [Krause et al.](https://arxiv.org/abs/2207.09964)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Krause et al.](https://arxiv.org/abs/2207.09964)
- en: '[Wang et al.](https://openreview.net/pdf?id=1LmgISIDZJ) addressed the task
    of few-shot link prediction over temporal + dynamic graphs where the edges have
    timestamps **and** new nodes might appear at later timesteps (*Incremental* *graphs*
    as to the above classification by Krause et al.). The few-shot scenario makes
    the task even more challenging — we only have access to a limited number of training
    and inference points (usually, <5) to reason about the queries link. Here, the
    authors propose **MetaTKGR**, a meta-learning based approach that builds representations
    of new nodes by aggregating features of existing nodes within a certain *delta
    t* temporal neighborhood. The scalar difference between timestamps is vectorized
    via the Fourier transform.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[Wang et al.](https://openreview.net/pdf?id=1LmgISIDZJ) 解决了在时间 + 动态图上进行少样本链接预测的任务，其中边具有时间戳**并且**新节点可能在后续时间步出现（*增量*
    *图*，如 Krause et al. 上述分类）。少样本场景使得任务更加具有挑战性——我们只能访问有限数量的训练和推理点（通常小于 5）来推理查询链接。在这里，作者提出了
    **MetaTKGR**，这是一种基于元学习的方法，通过聚合一定 *delta t* 时间邻域内现有节点的特征来构建新节点的表示。时间戳之间的标量差异通过傅里叶变换进行向量化。'
- en: '![](../Images/9800b8a8cd1f35415b12f3ca6d500cb5.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9800b8a8cd1f35415b12f3ca6d500cb5.png)'
- en: Components of MetaTKGR.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: MetaTKGR 的组件。
- en: 'Image source: [Wang et al.](https://arxiv.org/abs/2210.08654)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Wang et al.](https://arxiv.org/abs/2210.08654)
- en: Libraries and Datasets
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 库和数据集
- en: The lack of large datasets and challenging tasks has been holding back research
    on Temporal Graph Learning in the past few years. Luckily, new datasets from diverse
    domains are emerging. For example, [Poursafaei et al.](https://openreview.net/forum?id=1GVpwr2Tfdg)
    introduced six new publicly available TG datasets from the transportation, politics,
    economics and proximity domains. However, the field is still lacking a consistent
    effort to standardize benchmarks and evaluation to a high quality, what [OGB](https://ogb.stanford.edu/)
    did for static graphs. We hope that in 2023, we can see more standardized TG benchmarks
    with a focus on real applications.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年中，缺乏大规模数据集和具有挑战性的任务一直阻碍着时间图学习领域的研究。幸运的是，来自不同领域的新数据集正在涌现。例如，[Poursafaei et
    al.](https://openreview.net/forum?id=1GVpwr2Tfdg) 引入了六个新的公开可用的 TG 数据集，涵盖了交通、政治、经济和接近领域。然而，该领域仍然缺乏一致的努力来将基准和评估标准化到高质量，就像
    [OGB](https://ogb.stanford.edu/) 对静态图所做的那样。我们希望在 2023 年，我们能看到更多关注实际应用的标准化 TG 基准。
- en: Regarding libraries, a well-known one is [Pytorch Geometric Temporal](https://pytorch-geometric-temporal.readthedocs.io/en/latest/),
    an extension of [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/)
    for temporal graphs. However, Pytorch-Geometric Temporal seems to only feature
    discrete-time methods and datasets. A library which also includes continuous-time
    methods would be a great added value for the community. Recently, [Zhou et al.](https://www.vldb.org/pvldb/vol15/p1572-zhou.pdf)
    introduced TGL, a unified framework for large-scale offline Temporal Graph Neural
    Network training. In particular, on a 4-GPU machine, TGL can train one epoch of
    more than one billion temporal edges within 1–10 hours.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 关于库，著名的一个是 [Pytorch Geometric Temporal](https://pytorch-geometric-temporal.readthedocs.io/en/latest/)，这是
    [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) 的时间图扩展。然而，Pytorch-Geometric
    Temporal 似乎只包含离散时间方法和数据集。一个包含连续时间方法的库将为社区带来很大价值。最近，[Zhou et al.](https://www.vldb.org/pvldb/vol15/p1572-zhou.pdf)
    提出了 TGL，这是一个用于大规模离线时间图神经网络训练的统一框架。特别是在一台 4-GPU 机器上，TGL 可以在 1–10 小时内训练超过十亿条时间边的一轮。
- en: We list links to various TGL libraries and datasets below.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们列出了各种 TGL 库和数据集的链接如下。
- en: 13 processed TG datasets accessible via “[pip install dgb](https://complexdata.ml/docs/proj-tg/dgb/start)”
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 “[pip install dgb](https://complexdata.ml/docs/proj-tg/dgb/start)” 访问的 13
    个处理过的 TG 数据集
- en: '[Pytorch Geometric Temporal](https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/installation.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pytorch Geometric Temporal](https://pytorch-geometric-temporal.readthedocs.io/en/latest/notes/installation.html)'
- en: '[TGL library](https://github.com/amazon-science/tgl)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TGL library](https://github.com/amazon-science/tgl)'
- en: '[Chartalist Dynamic Blockchain Transaction Network](https://github.com/cakcora/chartalist)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Chartalist Dynamic Blockchain Transaction Network](https://github.com/cakcora/chartalist)'
- en: '[Temporal knowledge graph forecasting benchmark](https://github.com/nec-research/TKG-Forecasting-Evaluation)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Temporal knowledge graph forecasting benchmark](https://github.com/nec-research/TKG-Forecasting-Evaluation)'
- en: Disease Modeling with Temporal Graphs
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用时间图进行疾病建模
- en: In the recent COVID-19 pandemic, epidemic modeling is instrumental for understanding
    the spread of the disease as well as designing corresponding intervention strategies.
    Human contact networks are in fact temporal graphs. By combining contact graphs
    with classical compartment based models such as [SEIR](https://www.canada.ca/en/public-health/services/reports-publications/canada-communicable-disease-report-ccdr/monthly-issue/2020-46/issue-6-june-4-2020/predictive-modelling-covid-19-canada.html)
    and [SIR](http://networksciencebook.com/chapter/10#epidemic), we can more accurately
    forecast COVID-19 infection curve and go beyond the homogenous mixing assumption
    (all individuals are equally likely to be in contact with each other).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在近期的 COVID-19 大流行中，流行病建模对理解疾病传播以及设计相应的干预策略至关重要。人际接触网络实际上是时间图。通过将接触图与经典的基于隔离的模型如
    [SEIR](https://www.canada.ca/en/public-health/services/reports-publications/canada-communicable-disease-report-ccdr/monthly-issue/2020-46/issue-6-june-4-2020/predictive-modelling-covid-19-canada.html)
    和 [SIR](http://networksciencebook.com/chapter/10#epidemic) 相结合，我们可以更准确地预测 COVID-19
    感染曲线，并超越同质混合假设（所有个体之间的接触概率相等）。
- en: '[Chang et al.](https://www.nature.com/articles/s41586-020-2923-3) derived a
    temporal mobility network from cell phone data and mapped the hourly movement
    of 98 million people from census block groups (CBGs) to specific points of interest
    (POIs) in the US. By combining the hourly contact network with SEIR models on
    the CBG level, they are able to accurately fit real infection trajectory. In particular,
    the model shows that some ‘superspreader’ POIs such as restaurants and fitness
    centers account for a large majority of the infections. Also, differences in mobility
    between racial and socioeconomic groups lead to different infection rates among
    these groups. This work showcased the real world potential of utilizing large
    scale temporal graphs for disease forecasting and informing policies on intervention
    strategies.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[Chang et al.](https://www.nature.com/articles/s41586-020-2923-3) 从手机数据中推导出了时间移动网络，并将
    9800 万人的小时移动从人口普查区块组（CBGs）映射到美国的特定兴趣点（POIs）。通过将小时接触网络与 CBG 层面的 SEIR 模型结合，他们能够准确拟合实际感染轨迹。特别是，模型显示一些‘超级传播者’POIs
    如餐馆和健身中心占据了大多数感染。此外，不同种族和社会经济群体之间的流动差异导致这些群体之间的感染率不同。这项工作展示了利用大规模时间图进行疾病预测和制定干预策略的现实潜力。'
- en: Besides human contact networks, dynamic transportation networks also play an
    important role in the spread of COVID-19\. In [recent work](https://appliednetsci.springeropen.com/articles/10.1007/s41109-021-00378-3)
    by one of the authors, we incorporated daily flight networks into the SEIR model
    to estimate imported COVID-19 cases. By incorporating flight networks, it is possible
    for early detection of outbreaks and forecast the impact of travel restrictions.
    See the [blog post](https://mila.quebec/en/article/flight-seir-incorporating-flight-data-to-improve-epidemiological-modelling-and-disease-outbreak-prevention/)
    by one of the authors for more details.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 除了人际接触网络，动态交通网络在COVID-19的传播中也扮演着重要角色。在[一项研究](https://appliednetsci.springeropen.com/articles/10.1007/s41109-021-00378-3)中，我们将每日航班网络纳入SEIR模型，以估计输入的COVID-19病例。通过纳入航班网络，可以实现对疫情爆发的早期检测并预测旅行限制的影响。更多细节请见作者的[博客文章](https://mila.quebec/en/article/flight-seir-incorporating-flight-data-to-improve-epidemiological-modelling-and-disease-outbreak-prevention/)。
- en: Despite the empirical success of temporal-graph-based disease models, it is
    also important to answer questions such as “*how does the contact network structure
    impact the spread of disease?*” and “*what is the best way to modify the contact
    pattern such that the spread of COVID-19 can be slowed or prevented?*” [Holme
    et al.](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.94.022305) compared
    the difference in outbreak characteristics between using temporal, static and
    fully-connected networks on eight network datasets and examined various network
    structures affecting the spread of the disease. They showed that converting temporal
    networks into static ones can lead to severe under- or over-estimation of both
    the outbreak size and extinction time of the disease.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于时间图的疾病模型在实践中取得了成功，但回答诸如“*接触网络结构如何影响疾病传播？*”和“*如何修改接触模式以减缓或阻止COVID-19的传播？*”等问题也很重要。[Holme
    等](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.94.022305)比较了在八个网络数据集中使用时间、静态和完全连接网络的爆发特征差异，并研究了不同网络结构对疾病传播的影响。他们展示了将时间网络转换为静态网络可能导致对疾病爆发规模和消失时间的严重低估或高估。
- en: What are the next steps for TGL on epidemic modeling?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: TGL在流行病建模方面的下一步是什么？
- en: 1️). First, forecasting the entire contact or mobility network snapshot for
    the immediate future is a crucial challenge. With the predicted structure, we
    can apply network based SEIR models to estimate the infection curve.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，预测整个接触或流动网络的快照以应对短期挑战是一个关键问题。通过预测的结构，我们可以应用基于网络的SEIR模型来估计感染曲线。
- en: 2️). Second, defining and understanding the impact of interaction patterns on
    the contact network is crucial for policy making and interpretability. Analyzing
    the interplay between graph structures and the infection curve can help us identify
    the most effective intervention strategies.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，定义和理解互动模式对接触网络的影响对于政策制定和可解释性至关重要。分析图结构与感染曲线之间的相互作用可以帮助我们确定最有效的干预策略。
- en: Anomaly Detection in Temporal Graphs
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间图中的异常检测
- en: Anomaly detection is a fundamental task in analyzing temporal graphs which identifies
    entities that deviate significantly from the rest. For example, fraud detection
    can be modeled as detecting abnormal edges in a transaction network and traffic
    accident identification can be seen as detecting anomalous events in a traffic
    network.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测是分析时间图中的一个基本任务，它识别出与其他实体显著偏离的实体。例如，欺诈检测可以被建模为在交易网络中检测异常边缘，而交通事故识别可以被视为在交通网络中检测异常事件。
- en: There is growing interest in utilizing the representation power of temporal
    graph networks for anomaly detection. [Cai et al.](https://arxiv.org/abs/2005.07427)
    designed an end-to-end structural temporal Graph Neural Network model for detecting
    anomalous edges, called **StrGNN**. An enclosing subgraph, a k-hop subgraph centered
    around an edge, is first extracted based on the edge of interest to reduce computational
    complexity. A Graph Convolutional Neural Network ([GCN](https://openreview.net/forum?id=SJU4ayYgl))
    is then used to generate structural embedding from the subgraph. Gated Recurrent
    Units ([GRUs](https://aclanthology.org/D14-1179/)) are then used to capture temporal
    information. One of the challenges of anomaly detection is the lack of labeled
    examples. Therefore, [Cai et al.](https://arxiv.org/abs/2005.07427) proposed to
    generate “context-dependent” negative edges by replacing one of the nodes in a
    normal edge and training the model with these negative edges.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于利用时间图网络的表示能力进行异常检测的兴趣日益增长。[蔡等人](https://arxiv.org/abs/2005.07427)设计了一个端到端结构化时间图神经网络模型，用于检测异常边，称为**StrGNN**。首先基于感兴趣的边提取一个包围子图，一个以该边为中心的k-hop子图，以减少计算复杂性。然后使用图卷积神经网络([GCN](https://openreview.net/forum?id=SJU4ayYgl))从子图中生成结构嵌入。接着使用门控递归单元([GRUs](https://aclanthology.org/D14-1179/))来捕捉时间信息。异常检测的挑战之一是缺乏标记样本。因此，[蔡等人](https://arxiv.org/abs/2005.07427)提出通过替换正常边中的一个节点来生成“上下文相关”的负边，并用这些负边来训练模型。
- en: When comparing with unsupervised, non-GNN based anomaly detection methods such
    as [**SEDANSPOT**](https://dhivyaeswaran.github.io/papers/icdm18-sedanspot.pdf)
    and [**AnomRank**](https://www.cs.cmu.edu/~christos/PUBLICATIONS/kdd20-ANRank.pdf),
    GNN based methods can easily incorporate any given attribute and has the potential
    to achieve stronger performance. However, there are two significant challenges
    for GNN based approaches.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 与无监督的、非GNN基础的异常检测方法，如[**SEDANSPOT**](https://dhivyaeswaran.github.io/papers/icdm18-sedanspot.pdf)和[**AnomRank**](https://www.cs.cmu.edu/~christos/PUBLICATIONS/kdd20-ANRank.pdf)相比，GNN基础的方法可以轻松地结合任何给定的属性，并具有实现更强性能的潜力。然而，GNN基础的方法面临两个重大挑战。
- en: 1). First, how to scale to dynamic graphs with millions of edges and nodes?
    This is an open question for both the GNN module in extracting the graph features
    but also the temporal module such as GRUs and transformers in processing long
    term information.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 1). 首先，如何扩展到具有数百万条边和节点的动态图？这是一个开放性问题，既涉及到GNN模块在提取图特征时的挑战，也涉及到处理长期信息的时间模块，如GRUs和transformers。
- en: 2️). Second, how to produce accurate explanations for the detected anomalies?
    In real applications, detected anomalies are often verified and then potentially
    resulting in punitive measures for those detected entities. GNN explainability
    on dynamic graphs remains an open challenge.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 2️). 其次，如何为检测到的异常提供准确的解释？在实际应用中，检测到的异常通常会被验证，然后可能对这些检测到的实体采取惩罚措施。GNN在动态图上的可解释性仍然是一个未解决的挑战。
- en: '![](../Images/2f03649d8d6032495851a120e3981981.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f03649d8d6032495851a120e3981981.png)'
- en: LAD detects 2013 as a change point in the Canadian MP voting network due to
    abnormal amounts of edges between political parties.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: LAD检测到2013年是加拿大MP投票网络中的一个变化点，原因是政治党派之间的边的数量异常。
- en: 'Image source: [Huang et al.](https://arxiv.org/abs/2007.01229)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[黄等人](https://arxiv.org/abs/2007.01229)
- en: The task of *change point detection* aims to detect time points in a dynamic
    graph where the graph structure or distribution deviates significantly from what
    was observed before. This change can be attributed to external events (such as
    traffic disruption and COVID-19 related flight restrictions) or simply natural
    evolution of the dynamic graph. [Recent work](https://arxiv.org/abs/2007.01229)
    by one of the authors utilized the eigenvalues of the Laplacian matrix of each
    graph snapshot to embed the graph structure while applying sliding windows to
    compare the changes in graph structure in the long and short term. In the above,
    the proposed Laplacian Anomaly Detection (**LAD**) method detects a change in
    the Canadian Member of Parliament (MP) voting network due to increased edges between
    political parties. This coincides with Justin Trudeau being selected as the Liberal
    party leader in 2013.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*变化点检测*任务旨在检测动态图中时间点的变化，其中图结构或分布显著偏离之前观察到的状态。这种变化可能归因于外部事件（如交通中断和 COVID-19
    相关的航班限制），或仅仅是动态图的自然演变。作者之一的[近期工作](https://arxiv.org/abs/2007.01229)利用了每个图快照的拉普拉斯矩阵的特征值来嵌入图结构，同时应用滑动窗口来比较图结构在长短期内的变化。在上述内容中，提出的拉普拉斯异常检测
    (**LAD**) 方法检测到了由于政治党派之间边缘增加而导致的加拿大国会议员（MP）投票网络中的变化。这与贾斯廷·特鲁多在2013年被选为自由党领导人的事件相吻合。'
- en: Detecting Misinformation on Temporal Graphs
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在时间图上检测虚假信息
- en: '**Misinformation** spreads in different patterns and rates when compared to
    true information ([Vosoughi et al.](https://www.science.org/doi/10.1126/science.aap9559)).
    There has been considerable research studying these network patterns in a static
    graph while dynamic graph based methods are underexplored ([Song et al.](https://www.sciencedirect.com/science/article/abs/pii/S0306457321001965)).
    However, in the past year an increased amount of TGL methods were employed for
    misinformation detection and understanding. For instance, [Zhang et al.](https://link.springer.com/chapter/10.1007/978-3-030-72240-1_48)
    developed a method based on Temporal Point Processes while Dynamic GCN ([**DynGCN**](https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0256039))
    and [**DGNF**](https://www.sciencedirect.com/science/article/pii/S0925231222009158)
    are dynamic GNN based methods.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**虚假信息**的传播模式和速度与真实信息不同 ([Vosoughi 等](https://www.science.org/doi/10.1126/science.aap9559))。已有大量研究在静态图中研究这些网络模式，而动态图方法尚未得到充分探索
    ([Song 等](https://www.sciencedirect.com/science/article/abs/pii/S0306457321001965))。然而，在过去的一年里，使用
    TGL 方法进行虚假信息检测和理解的数量有所增加。例如，[Zhang 等](https://link.springer.com/chapter/10.1007/978-3-030-72240-1_48)
    开发了一种基于时间点过程的方法，而动态 GCN ([**DynGCN**](https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0256039))
    和 [**DGNF**](https://www.sciencedirect.com/science/article/pii/S0925231222009158)
    是基于动态 GNN 的方法。'
- en: The illustration below shows the architecture of DynGCN. They construct graph
    snapshots with even spacing in time, feed each through GCN layers, and then combine
    the representations and learn the snapshots’ evolution patterns using attention.
    This is a relatively simpler approach to leverage temporal information compared
    to some methods discussed above like [TGN](https://arxiv.org/abs/2006.10637) or
    [CAW](http://snap.stanford.edu/caw/), but nonetheless gives better performance
    than previous state-of-the-art for misinformation detection on the datasets that
    the authors examined.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 DynGCN 的架构。他们以均匀时间间隔构建图快照，通过 GCN 层处理每个快照，然后结合这些表示并使用注意力机制学习快照的演变模式。这是一种相对简单的方法，比起上述一些方法如
    [TGN](https://arxiv.org/abs/2006.10637) 或 [CAW](http://snap.stanford.edu/caw/)，它利用时间信息的方式更为简单，但在作者检查的数据集上，比之前的最先进技术在虚假信息检测方面表现更好。
- en: '![](../Images/a9486bf6050dd1d05cadf94488b24b72.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9486bf6050dd1d05cadf94488b24b72.png)'
- en: DynGCN processes individual graph snapshots using GCN layers with shared weights,
    then combines the representations over time with an attention mechanism.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: DynGCN 使用具有共享权重的 GCN 层处理单个图快照，然后通过注意力机制结合这些表示以获取时间上的演变。
- en: 'Image source: [Choi et al.](https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0256039)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '图片来源: [Choi 等](https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0256039)'
- en: Dynamic interaction patterns are shown to be quite informative for misinformation
    detection ([Plepi et al.](https://aclanthology.org/2022.textgraphs-1.10/)). With
    significant recent advances in TGL methods, we can expect novel state-of-the-art
    misinformation detection methods that incorporate dynamic graphs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 动态交互模式在虚假信息检测中被证明非常有用（[Plepi等](https://aclanthology.org/2022.textgraphs-1.10/)）。随着TGL方法的显著进展，我们可以期待结合动态图的新型最先进的虚假信息检测方法。
- en: Joining Temporal Graph Learning Community
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入时间图学习社区
- en: 2022 has seen increased attention in TGL from the ML community. The first ever
    [TGL workshop](https://sites.google.com/view/tglworkshop2022/home) was held at
    NeurIPS 2022\. The recordings of the talks and panel will be available soon on
    the [NeurIPS virtual site](https://neurips.cc/virtual/2022/workshop/49999). The
    accepted papers are available on the [workshop website](https://sites.google.com/view/tglworkshop2022/home).
    Keep an eye out for announcements of new iterations of the TGL workshop there
    and join the workshop slack (up-to-date link in the website) to engage with the
    community. This year, we are also planning a TGL reading group, if you would like
    to share your work or be involved in co-organizing the reading group, please email
    [shenyang.huang@mail.mcgill.ca](mailto:shenyang.huang@mail.mcgill.ca)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年，机器学习社区对时间图学习（TGL）的关注有所增加。首届[TGL研讨会](https://sites.google.com/view/tglworkshop2022/home)于NeurIPS
    2022上举办。会议的演讲和讨论会录像将很快在[NeurIPS虚拟网站](https://neurips.cc/virtual/2022/workshop/49999)上提供。接受的论文可以在[研讨会网站](https://sites.google.com/view/tglworkshop2022/home)上找到。请关注TGL研讨会的新版本公告，并加入研讨会Slack（网站上有最新链接）以便与社区互动。今年，我们还计划组织一个TGL阅读小组，如果你希望分享你的工作或参与组织阅读小组，请发送邮件至[shenyang.huang@mail.mcgill.ca](mailto:shenyang.huang@mail.mcgill.ca)。
- en: '![](../Images/16687a5a16fb0ec79714aab91d36d2a0.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16687a5a16fb0ec79714aab91d36d2a0.png)'
- en: 'Image Source: Logo of the [NeurIPS 2022 Temporal Graph Learning Workshop](https://sites.google.com/view/tglworkshop2022/home).
    Image by authors.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[NeurIPS 2022时间图学习研讨会](https://sites.google.com/view/tglworkshop2022/home)的logo。图片由作者提供。
