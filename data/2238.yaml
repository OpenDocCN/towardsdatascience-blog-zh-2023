- en: Probabilistic View of Principal Component Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主成分分析的概率视角
- en: 原文：[https://towardsdatascience.com/probabilistic-view-of-principal-component-analysis-9c1bbb3f167?source=collection_archive---------8-----------------------#2023-07-12](https://towardsdatascience.com/probabilistic-view-of-principal-component-analysis-9c1bbb3f167?source=collection_archive---------8-----------------------#2023-07-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/probabilistic-view-of-principal-component-analysis-9c1bbb3f167?source=collection_archive---------8-----------------------#2023-07-12](https://towardsdatascience.com/probabilistic-view-of-principal-component-analysis-9c1bbb3f167?source=collection_archive---------8-----------------------#2023-07-12)
- en: Latent Variables, Expectation-Maximization & Variational Inference
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 潜在变量、期望最大化与变分推断
- en: '[](https://saptashwa.medium.com/?source=post_page-----9c1bbb3f167--------------------------------)[![Saptashwa
    Bhattacharyya](../Images/b01238113a1f6b91cb6fb0fbfa50303a.png)](https://saptashwa.medium.com/?source=post_page-----9c1bbb3f167--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c1bbb3f167--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c1bbb3f167--------------------------------)
    [Saptashwa Bhattacharyya](https://saptashwa.medium.com/?source=post_page-----9c1bbb3f167--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://saptashwa.medium.com/?source=post_page-----9c1bbb3f167--------------------------------)[![Saptashwa
    Bhattacharyya](../Images/b01238113a1f6b91cb6fb0fbfa50303a.png)](https://saptashwa.medium.com/?source=post_page-----9c1bbb3f167--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c1bbb3f167--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c1bbb3f167--------------------------------)
    [Saptashwa Bhattacharyya](https://saptashwa.medium.com/?source=post_page-----9c1bbb3f167--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9a3c3c477239&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-view-of-principal-component-analysis-9c1bbb3f167&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=post_page-9a3c3c477239----9c1bbb3f167---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c1bbb3f167--------------------------------)
    ·9 min read·Jul 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c1bbb3f167&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-view-of-principal-component-analysis-9c1bbb3f167&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=-----9c1bbb3f167---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9a3c3c477239&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-view-of-principal-component-analysis-9c1bbb3f167&user=Saptashwa+Bhattacharyya&userId=9a3c3c477239&source=post_page-9a3c3c477239----9c1bbb3f167---------------------post_header-----------)
    发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c1bbb3f167--------------------------------)
    ·9分钟阅读·2023年7月12日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c1bbb3f167&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-view-of-principal-component-analysis-9c1bbb3f167&source=-----9c1bbb3f167---------------------bookmark_footer-----------)![](../Images/ea43c4d373d4f057fb224899a1bae3d3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c1bbb3f167&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprobabilistic-view-of-principal-component-analysis-9c1bbb3f167&source=-----9c1bbb3f167---------------------bookmark_footer-----------)![](../Images/ea43c4d373d4f057fb224899a1bae3d3.png)'
- en: 'Looking for Hidden Variables (Pic Credit: [Author](https://flickr.com/photos/suvob/52911155451/))'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找隐藏变量（图片来源：[作者](https://flickr.com/photos/suvob/52911155451/))
- en: One of the primarily used dimension reduction techniques in data science and
    machine learning is Principal Component Analysis (PCA). Previously, We have already
    discussed a few examples of applying PCA in a [pipeline](/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976)
    with [Support Vector Machine](/visualizing-support-vector-machine-decision-boundary-69e7591dacea)
    and here we will see a probabilistic perspective of PCA to provide a more robust
    and comprehensive understanding of the underlying data structure. *One of the
    biggest advantages of Probabilistic PCA (PPCA) is that it can handle missing values
    in a dataset, which is not possible with classical PCA.* Since we will discuss
    Latent Variable Model and Expectation-Maximization algorithm, you can also check
    [this detailed post](/latent-variables-expectation-maximization-algorithm-fb15c4e0f32c).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学和机器学习中，主要使用的降维技术之一是主成分分析（PCA）。之前，我们已经讨论了在一个[管道](/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976)中应用PCA的几个例子，其中包括[支持向量机](/visualizing-support-vector-machine-decision-boundary-69e7591dacea)，在这里我们将从概率视角来看待PCA，以提供对数据结构的更稳健和全面的理解。*概率PCA（PPCA）的最大优势之一是它可以处理数据集中的缺失值，而传统PCA则无法做到这一点。*
    由于我们将讨论潜在变量模型和期望最大化算法，你还可以查看[这篇详细文章](/latent-variables-expectation-maximization-algorithm-fb15c4e0f32c)。
- en: What you can expect to learn from this post?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从这篇文章中学到什么？
- en: Short Intro to PCA.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）简短介绍。
- en: Mathematical building blocks for PPCA.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PPCA的数学构建块。
- en: Expectation Maximization (EM) algorithm or Variational Inference? What to use
    for parameter estimation?
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 期望最大化（EM）算法还是变分推断？用于参数估计时该选择哪个？
- en: Implementing PPCA with TensorFlow Probability for a toy dataset.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用TensorFlow Probability实现PPCA以处理一个玩具数据集。
- en: Let’s dive into this!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解吧！
- en: '1\. Singular Value Decomposition (SVD) and PCA:'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 奇异值分解（SVD）和主成分分析（PCA）：
