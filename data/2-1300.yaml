- en: Illuminating the Black Box of Textual GenAI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 揭开文本生成 AI 的黑箱
- en: 原文：[https://towardsdatascience.com/illuminating-the-black-box-of-ai-ddea07e65c35](https://towardsdatascience.com/illuminating-the-black-box-of-ai-ddea07e65c35)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/illuminating-the-black-box-of-ai-ddea07e65c35](https://towardsdatascience.com/illuminating-the-black-box-of-ai-ddea07e65c35)
- en: The need for insights
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需求洞察
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----ddea07e65c35--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----ddea07e65c35--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ddea07e65c35--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ddea07e65c35--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----ddea07e65c35--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----ddea07e65c35--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----ddea07e65c35--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ddea07e65c35--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ddea07e65c35--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----ddea07e65c35--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ddea07e65c35--------------------------------)
    ·8 min read·Dec 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ddea07e65c35--------------------------------)
    ·8 分钟阅读·2023年12月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能软件用于提升本文的语法、流畅性和可读性。*'
- en: LLMs like ChatGPT, Claude 3, Gemini, and Mistral captivate the world with their
    articulateness and erudition. Yet these large language models remain black boxes,
    concealing the intricate machinery powering their responses. Their prowess at
    generating human-quality text outstrips our prowess at understanding how their
    machine minds function.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 像 ChatGPT、Claude 3、Gemini 和 Mistral 这样的语言模型以其表达能力和博学引人注目。然而，这些大型语言模型仍然是黑箱，掩盖了驱动其响应的复杂机制。它们生成类似人类的文本的能力超越了我们理解其机器思维如何运作的能力。
- en: But as artificial intelligence is set loose upon scenarios where trust and transparency
    are paramount, like hiring and risk assessment, explicability now moves to the
    fore. Explainability is no longer an optional bell or whistle on complex systems,
    it is an essential prerequisite to safely progressing AI in high-impact domains.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 但随着人工智能在信任和透明度至关重要的场景中发挥作用，如招聘和风险评估，可解释性现在成为了重点。可解释性不再是复杂系统的可选配件，而是安全推动高影响领域
    AI 的必要前提。
- en: To unpack these black box models, the vibrant field of explainable NLP offers
    a growing toolkit — from attention visualizations revealing patterns in focus,
    to probing random parts of input to quantify influence. Some approaches like LIME
    create simplified models that mimic key decisions locally. Other methods like
    SHAP adapt concepts from cooperative game theory to distribute “credits” and “blame”
    across different parts of a model’s input based on its final output.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了揭开这些黑箱模型的面纱，生动的可解释 NLP 领域提供了越来越多的工具——从揭示关注模式的注意力可视化，到探查输入的随机部分以量化影响。像 LIME
    这样的某些方法创建了模拟关键决策的简化模型。其他方法，如 SHAP，则借鉴了合作博弈论的概念，将“信贷”和“责任”分配到模型输入的不同部分，基于其最终输出。
- en: 'Regardless of technique, all pursue the same crucial end: elucidating how language
    models utilize the abundance of text we feed them to compose coherent passages
    or carry out consequential assessments.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 无论技术如何，所有方法都追求相同的关键目标：阐明语言模型如何利用我们提供的大量文本来编写连贯的段落或进行重要评估。
- en: AI already makes decisions affecting human lives — selectively judging applicants,
    moderating hateful content, diagnosing illness.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能已经在影响人类生活的决策中发挥作用——选择性地评估申请者、审查仇恨内容、诊断疾病。
- en: Explanations aren’t mere accessories — they will prove instrumental in overseeing
    these powerful models as they proliferate through society.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 解释不仅仅是附加功能——它们将对监督这些强大的模型在社会中的普及起到关键作用。
- en: As large language models continue to advance, their inner workings remain veiled
    in obscurity. Yet trustworthy AI necessitates transparency into their reasoning
    on impactful decisions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型的不断进步，它们的内部工作机制仍然笼罩在神秘之中。然而，可信的人工智能需要对其在重大决策中的推理过程保持透明。
- en: 'The vibrant field of explainable NLP offers two major approaches to elucidate
    model logic:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 解释性 NLP 的充满活力的领域提供了两种主要方法来阐明模型逻辑：
- en: '**Perturbation-based Methods**: Techniques like LIME and SHAP systematically
    probe models by masking input components and quantify importance based on output
    changes. These external perspectives treat models as black boxes.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**基于扰动的方法**：如 LIME 和 SHAP 的技术通过遮蔽输入组件系统地探测模型，并根据输出变化量化重要性。这些外部视角将模型视为黑箱。'
- en: '**Self-Explanations**: An alternative paradigm enables models to explain their
    own reasoning via generated texts. For instance, highlighting pivotal input features
    that informed a prediction. This relies on introspective model awareness rather
    than imposing interpretations.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自我解释**：一种替代范式使模型能够通过生成文本解释自己的推理。例如，突出影响预测的关键输入特征。这依赖于内省的模型意识，而不是强加的解释。'
- en: Early analysis finds promise in both approaches — LIME and SHAP excel at faithfully
    capturing model behaviors while self-explanations align better with human rationales.
    Yet current practices also struggle to adequately assess either, suggesting the
    need for rethinking evaluation strategies.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 早期分析发现这两种方法都很有前景——LIME 和 SHAP 擅长忠实捕捉模型行为，而自我解释则更符合人类的理性。然而，当前的实践也难以充分评估这两者，建议重新考虑评估策略。
- en: Ideally, synergies between both camps could unite to propel progress. For instance,
    self-declared important factors could be verified against perturbation experiments.
    And attribution scores could add validation signals anchoring free-form explanations.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，两者之间的协同作用可以结合起来推动进展。例如，自我声明的重要因素可以与扰动实验进行验证。并且归因分数可以增加验证信号，为自由形式的解释提供支撑。
- en: As models continue ingesting more world knowledge, elucidating their multifaceted
    reasoning grows increasingly crucial. A diversity of emerging ideas may prove
    essential to meet this challenge.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型不断吸收更多的世界知识，阐明它们多方面的推理变得越来越重要。多样化的新兴想法可能对应对这一挑战至关重要。
- en: The Balancing Act of Explaining AI
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释 AI 的平衡艺术
- en: Constructing explanations inevitably requires simplification. But oversimplifying
    breeds distortion. Take common attention-based explanations — they highlight parts
    of input that models supposedly focus on. However, attention scores often misalign
    with an AI system’s actual reasoning process.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 构建解释不可避免地需要简化。但过度简化会导致扭曲。以常见的基于注意力的解释为例——它们突出模型 supposedly 关注的输入部分。然而，注意力分数往往与
    AI 系统的实际推理过程不一致。
- en: More rigorous techniques like **SHAP** avoid this by systematically masking
    different input components and directly measuring the impact on output. By comparing
    predictions with and without each feature present, SHAP assigns each an “importance
    score” representing its influence. This perturbation-based approach better reflects
    models’ logic.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 更严格的技术如 **SHAP** 通过系统地遮蔽不同的输入组件并直接测量对输出的影响来避免这一点。通过比较有无每个特征的预测，SHAP 为每个特征分配一个“重要性分数”以表示其影响。这种基于扰动的方法更好地反映了模型的逻辑。
- en: 'However, faithfulness comes at the cost of intelligibility. Removing combinations
    of words and clauses quickly becomes cognitively taxing for humans to parse explanations.
    Thus the research community emphasizes balancing two key criteria:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，忠实性往往以可理解性为代价。移除单词和子句的组合很快变得认知负担过重。因此，研究社区强调平衡两个关键标准：
- en: '**Faithfulness**: How accurately does the explanation capture the model’s actual
    decision making process? Masking-based perturbation methods excel here.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**忠实性**：解释多准确地捕捉了模型的实际决策过程？基于遮蔽的扰动方法在这里表现出色。'
- en: '**Understandability**: How intuitive and digestible is the explanation for
    the intended audience? Simplified linear models facilitate comprehension but can
    distort.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**可理解性**：解释对目标受众的直观性和易消化程度如何？简化的线性模型有助于理解，但可能会扭曲。'
- en: Ideally, an explanation exhibits both traits. But even SHAP, which lands high
    on faithfulness, struggles when models process extensive texts and unrestricted
    generation — exponentially blowing up the output combinations to account for.
    Running computations over all possible masked permutations of a 10,000 word essay
    is infeasible!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，解释应同时展现两者特征。但即便是忠实性高的 SHAP，在模型处理大量文本和不受限制的生成时，也会遇到困难——需要处理的输出组合呈指数级增长。对
    10,000 字文章的所有可能遮蔽排列进行计算是不可行的！
- en: This impedes progress on critical applications like explaining essay scoring
    models or question answering systems that handle documents. Creating simplified
    models that mimic predictions, a la LIME, also grows intractable for complex textual
    reasoning. More tailored solutions are needed to extend explainability to large
    language models.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这阻碍了对关键应用的进展，如解释作文评分模型或处理文档的问答系统。创建模仿预测的简化模型（如LIME）在复杂文本推理中也变得不可行。需要更具针对性的解决方案来扩展大型语言模型的可解释性。
- en: The key challenges are highlighted — specifically the exponential complexity
    introduced by long inputs and open-ended outputs. Please let me know if any parts
    need more clarification!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 突出了关键挑战 —— 特别是由长输入和开放输出引入的指数复杂性。如果有任何部分需要更多解释，请告诉我！
- en: 'TextGenSHAP: Optimizing Explanations for Language Tasks'
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TextGenSHAP：优化语言任务的解释
- en: '[](https://arxiv.org/abs/2312.01279?source=post_page-----ddea07e65c35--------------------------------)
    [## TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arxiv.org/abs/2312.01279?source=post_page-----ddea07e65c35--------------------------------)
    [## TextGenSHAP：在长文档中生成的可扩展事后解释'
- en: Large language models (LLMs) have attracted huge interest in practical applications
    given their increasingly accurate…
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）由于其日益准确的性能而引起了对实际应用的极大关注…
- en: arxiv.org](https://arxiv.org/abs/2312.01279?source=post_page-----ddea07e65c35--------------------------------)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2312.01279?source=post_page-----ddea07e65c35--------------------------------)'
- en: To surmount the obstacles of explainability for complex language models, researchers
    develop **TextGenSHAP** — extending SHAP by baking in optimizations for both efficiency
    and accounting for linguistic structure.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服复杂语言模型的可解释性障碍，研究人员开发了**TextGenSHAP** —— 在SHAP的基础上，融入了对效率的优化，并考虑了语言结构。
- en: Several innovations address the exponential computational complexity. **Speculative
    decoding** predicts likely text outputs first, avoiding wasted decoding attempts.
    **Flash attention** simplifies memory-intensive attention calculations. **In-place
    resampling** precomputes input encodings once for efficiency.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 若干创新技术应对了指数级的计算复杂性。**预测解码**首先预测可能的文本输出，避免了浪费的解码尝试。**闪电注意力**简化了内存密集型的注意力计算。**原地重采样**为提高效率预计算了输入编码。
- en: Together these accelerator techniques reduce runtimes from hours to minutes,
    enabling practical turnaround. The authors verify orders-of-magnitude speedups
    across model types and dataset complexity.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些加速技术使运行时间从几小时减少到几分钟，实现了实用的周转。作者验证了在不同模型类型和数据集复杂性下的数量级加速。
- en: 'But raw efficiency alone is not enough — the intricacies of language itself
    must be represented. TextGenSHAP tackles explanatory challenges unique to NLP:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 但仅仅是原始效率是不够的 —— 语言本身的复杂性必须得到体现。TextGenSHAP解决了自然语言处理独有的解释挑战：
- en: '**Hierarchical structure** — Beyond individual words, language models learn
    conceptual connections across sentences, paragraphs, even documents. TextGenSHAP’s
    hierarchical attribution allows importance scores to be assigned at both coarse-grained
    and fine-grained levels.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**层次结构** —— 除了单个词语外，语言模型还学习句子、段落甚至文档之间的概念联系。TextGenSHAP的层次化归因允许在粗粒度和细粒度层面上分配重要性评分。'
- en: '**Exponential output space** — Open-ended text generation produces a colossal
    set of possible outputs, unlike confined classification tasks. Via reformulations
    like the Shapley-Shubik index, TextGenSHAP bypasses exhaustive enumeration to
    estimate feature importance.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**指数输出空间** —— 开放式文本生成产生了巨大的可能输出集，不同于受限的分类任务。通过如Shapley-Shubik指数等重新表述，TextGenSHAP绕过了详尽的枚举来估计特征重要性。'
- en: '**Autoregressive dependence** — Generated tokens probabilistically depend on
    those preceding them. TextGenSHAP’s adapted decoding algorithms such as speculative
    decoding explicitly respect these inter-token dependencies during attribution.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**自回归依赖** —— 生成的标记概率上依赖于前面的标记。TextGenSHAP的适应性解码算法，如预测解码，明确地尊重这些标记间的依赖关系。'
- en: Together, the architectural and linguistic advances pave the pathway for TextGenSHAP
    to handle complexity at the scale of modern NLP. The door now opens to tackling
    explainability in long-standing challenges like question answering over documents.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些架构和语言上的进展为TextGenSHAP应对现代自然语言处理的复杂性铺平了道路。现在可以着手解决长期挑战中的可解释性问题，例如文档上的问答。
- en: '![](../Images/4082cbd9d8fadca02166150efb0ff90f.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4082cbd9d8fadca02166150efb0ff90f.png)'
- en: Image by the author generated by Dall-E-3.0
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 作者生成的图像，来源于Dall-E-3.0
- en: 'Applications: Explaining Question-Answering Over Documents'
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用：解释文档中的问答
- en: Question answering over documents represents a coveted milestone for AI — synthesizing
    information scattered across passages to address nuanced queries. TextGenSHAP
    now makes explaining these complex text reasoning workflows possible.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 文档中的问答代表了AI的一个宝贵里程碑——综合散布在段落中的信息以解决复杂的查询。TextGenSHAP现在使解释这些复杂的文本推理工作流程成为可能。
- en: The authors evaluate TextGenSHAP on challenging datasets requiring deducing
    answers from contexts spanning 10,000+ words. Impressively, it accurately identifies
    the pivotal sentences and phrases dispersed throughout extended texts that most
    informed each answer.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作者在需要从超过10,000个单词的上下文中推导答案的挑战性数据集上评估了TextGenSHAP。令人印象深刻的是，它准确地识别出分布在扩展文本中的关键句子和短语，这些句子和短语对每个答案的形成最有帮助。
- en: 'By properly crediting different parts of lengthy documents, TextGenSHAP enables
    powerful applications:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过适当地归因于冗长文档的不同部分，TextGenSHAP使强大的应用成为可能：
- en: '**Improving document retrieval** — Ranking and filtering contexts by influence
    scores extracted more relevant passages. Just by re-ordering based on TextGenSHAP,
    the authors demonstrate substantial gains in retrieval recall — from 84% to almost
    89%. This helps better supply information to downstream reasoning steps.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**改进文档检索**——通过影响评分对上下文进行排名和筛选，提取了更相关的段落。仅通过根据TextGenSHAP重新排序，作者展示了检索召回率的显著提升——从84%提高到近89%。这有助于更好地为下游推理步骤提供信息。'
- en: '**Distilling evidence** — Using importance scores to cull the most integral
    supporting passages for answering each question, accuracy improves from 50% to
    70% on datasets with diverse evidence. Ensuring models focus on concise explanatory
    extracts counters overfitting to spurious patterns in large corpora.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**提炼证据**——使用重要性评分来挑选每个问题回答的最核心支持段落，在具有多样证据的数据集上准确率从50%提高到70%。确保模型关注简明的解释提取物，以对抗在大型语料库中对虚假模式的过拟合。'
- en: '**Human oversight** — By surfacing the most influential text snippets, TextGenSHAP
    allows auditors to rapidly validate if models utilized appropriate supportive
    content instead of latching onto unintended cues. Monitoring complex reasoning
    is otherwise intractable.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工监督**——通过揭示最有影响力的文本片段，TextGenSHAP使审计员能够快速验证模型是否使用了适当的支持内容，而不是依赖于非预期的提示。否则，监控复杂的推理过程是不可行的。'
- en: The success on reasoning-intensive question answering suggests wider applicability
    explaining AI capabilities with societal impacts — like scoring essay content
    and prose or interpreting medical diagnoses. By exposing the crucial connections
    within language, TextGenSHAP moves us towards accountable and trustworthy NLP
    systems.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推理密集型问题回答的成功表明，解释AI能力的社会影响有更广泛的适用性——如评分论文内容和散文或解释医疗诊断。通过揭示语言中的关键联系，TextGenSHAP使我们朝着负责任和可信赖的NLP系统迈进。
- en: '[https://anon832098265.github.io/](https://anon832098265.github.io/)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://anon832098265.github.io/](https://anon832098265.github.io/)'
- en: Investigating Self-Explanations
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调查自我解释
- en: '[](https://arxiv.org/abs/2310.11207?source=post_page-----ddea07e65c35--------------------------------)
    [## Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/2310.11207?source=post_page-----ddea07e65c35--------------------------------](https://arxiv.org/abs/2310.11207?source=post_page-----ddea07e65c35--------------------------------)
    [## 大型语言模型能否自我解释？LLM生成自我解释的研究'
- en: Large language models (LLMs) such as ChatGPT have demonstrated superior performance
    on a variety of natural language…
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）如ChatGPT在各种自然语言任务中展示了卓越的性能…
- en: arxiv.org](https://arxiv.org/abs/2310.11207?source=post_page-----ddea07e65c35--------------------------------)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2310.11207?source=post_page-----ddea07e65c35--------------------------------)'
- en: We’ve discussed traditional post-hoc methods that treat models as black boxes.
    An intriguing alternative is enabling systems to explain their own reasoning —
    **self-explanations**.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了将模型视为黑箱的传统事后方法。一个有趣的替代方案是使系统能够解释自身的推理——**自我解释**。
- en: Recent research analyzed these for sentiment analysis using ChatGPT. The model
    highlighted input words informing its predictions. Unlike external techniques
    directly perturbing inputs, self-explanations rely on introspective model awareness
    to declare important factors.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究分析了这些用于情感分析，使用ChatGPT。模型突出了输入词汇对其预测的影响。与直接扰动输入的外部技术不同，自我解释依赖于内省模型意识来声明重要因素。
- en: The paper systematically compared formats, finding that both predicting then
    explaining or vice versa worked reasonably well. The models readily produced feature
    attribution scores for all words or just top highlights. But interestingly, importance
    scores frequently clustered into “well-rounded” levels (e.g. 0.0, 0.5, 0.75) resembling
    human judgment more than discrete machine precision.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 论文系统地比较了不同格式，发现预测然后解释或反之都工作得相当好。模型容易生成所有单词的特征归因分数或仅仅是最重要的高亮部分。但有趣的是，重要性分数通常聚集在“全面的”水平（例如
    0.0、0.5、0.75），这更类似于人类判断，而不是离散的机器精度。
- en: While self-explanations aligned fairly with human rationales, widely used evaluation
    practices struggled to differentiate quality. Metrics easily fooled on classifiers
    depended on fine-grained model prediction changes often insensitive for ChatGPT.
    The researchers concluded that the classic interpretability pipeline needs rethinking
    for large language models.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管自我解释与人类的推理相对一致，但广泛使用的评估实践难以区分质量。依赖于细粒度模型预测变化的指标容易受到欺骗，而这些变化对于 ChatGPT 常常不敏感。研究人员得出结论认为，经典的可解释性流程需要重新考虑以适应大型语言模型。
- en: Fully realizing self-explanation potential requires new assessment frameworks
    attuned to their blended human-machine nature. Anchoring them to directly observable
    signals like attention weights could enhance faithfulness. Architecting modular
    reasoning/explaining components might also enable purer introspective elucidation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 要充分实现自我解释的潜力，需要新的评估框架，以适应其混合的人机特性。将它们与直接可观察的信号如注意力权重相结合，可能会增强其真实性。构建模块化的推理/解释组件也可能使得自我解释更加纯粹。
- en: With careful co-design accommodating their emergent characteristics, self-explanations
    could unlock unprecedented model transparency — converting black boxes into “glass
    boxes” with systems not just displaying but also discussing their inner workings.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过精心协同设计，以适应其新兴特性，自我解释有可能开启前所未有的模型透明度——将黑箱转换为“玻璃箱”，使系统不仅展示其内部工作原理，还讨论其内在机制。
- en: The TextGenSHAP method focuses on enabling efficient Shapley value attribution
    for text generation models. It makes progress on quantifying feature importance
    for tasks like long-document question answering.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: TextGenSHAP 方法专注于为文本生成模型提供高效的 Shapley 值归因。它在量化特征重要性方面取得了进展，适用于长文档问答任务。
- en: However, TextGenSHAP still relies on an external perspective, perturbing inputs
    and observing output changes rather than asking models to introspect on their
    own reasoning. This leaves room for integration with self-explanation methods.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，TextGenSHAP 仍然依赖外部视角，扰动输入并观察输出变化，而不是让模型自我反思其推理。这为与自我解释方法的整合留下了空间。
- en: Self-explanations could provide a more qualitative, intuitive understanding
    to complement the quantitative attribution scores from TextGenSHAP. For example,
    TextGenSHAP may identify a pivotal paragraph in a document and highlight certain
    sentences as most influential in answering a question. Self-explanations could
    then enrich this by discussing the logic for focusing on those areas.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 自我解释可以提供更为定性、直观的理解，以补充来自 TextGenSHAP 的定量归因分数。例如，TextGenSHAP 可能会识别文档中的关键段落，并将某些句子突出为回答问题时最具影响力的部分。自我解释可以通过讨论聚焦于这些领域的逻辑来丰富这些信息。
- en: Conversely, self-explanations today often take the form of free generation without
    any grounding. Combining with attribution scores that synthesize model reasoning
    into token importance rankings could help validate and enhance the meaningfulness
    of self-explanations.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，目前的自我解释通常以自由生成的形式出现，缺乏基础。与将模型推理综合为标记重要性排名的归因分数结合起来，可能有助于验证和增强自我解释的意义。
- en: Architecturally, TextGenSHAP modules could first digest documents and questions,
    produce attention distributions and passagens rankings. Then self-explanation
    modules could consume these quantitative signals to generate free-form rationales
    discussing the assessment, with the attribution scores steering the interpretation.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在架构上，TextGenSHAP 模块可以首先处理文档和问题，生成注意力分布和段落排名。然后，自我解释模块可以利用这些定量信号生成自由形式的推理，讨论评估内容，并通过归因分数引导解释。
- en: Joint evaluation could also assess whether self-declared explanatory factors
    align with input components that perturbation-based scoring designates as influential.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 联合评估还可以评估自我声明的解释因素是否与扰动基础评分指定为有影响的输入组件一致。
- en: In essence, self-explanations provide the “what” of model understanding while
    attribution scores offer the “why”. Their symbiosis could enable rich explainability
    blending quantitative and qualitative insights into system reasoning.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，自我解释提供了模型理解的“是什么”，而归因分数则提供了“为什么”。它们的共生关系可能使丰富的解释性融合定量和定性见解成为可能。
- en: 'The Path Ahead: Towards Trust through Transparency'
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前进的道路：通过透明度实现信任
- en: TextGenSHAP furnishes a pivotal advancement — the means to peer inside the intricate
    workings of large language models as they ingest volumes of text. By creating
    efficient and accurate explanations, it circumvents existing barriers that constrained
    explainability methods to tiny snippets of language.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: TextGenSHAP提供了一个关键的进展——窥视大型语言模型在处理大量文本时的复杂工作。通过创建高效准确的解释，它绕过了现有解释方法仅限于少量语言片段的障碍。
- en: Yet, rich fluency alone does not guarantee trustworthy AI. Mastery of language
    — the hallmark of progress powering ChatGPT’s eloquence — must couple with mastery
    of elucidation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，单纯的语言流畅性并不能保证可信赖的人工智能。语言的掌握——推动ChatGPT口才进步的标志——必须与阐明的掌握相结合。
- en: Elucidation entails more than spitting out a few keywords in attention rolls
    — it requires replicating the complex chains of inferential reasoning that yield
    final assessments. Advances like TextGenSHAP bring this requisite transparency
    closer to reality.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 阐明不仅仅是抛出几个关键词那么简单——它需要复制复杂的推理链条，从而得出最终评估。像TextGenSHAP这样的进展将这一必要的透明度更接近现实。
- en: As models continue absorbing more world knowledge, their inner representational
    tapestries grow vastly multifaceted. Attempting oversight via reductionist attention
    scores or small perturbation samples will only muddle, not illuminate. More holistic
    methodologies in the spirit of TextGenSHAP that respect dependencies in structure
    and logic will prove critical.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型不断吸收更多世界知识，其内部表征的复杂性也大大增加。通过简化的注意力分数或小扰动样本尝试监督只会混淆视听，而非阐明。尊重结构和逻辑依赖的更全面的方法，如TextGenSHAP，将证明至关重要。
- en: Learning without transparency risks power devoid of responsibility. Observation
    without illumination risks rubber stamps lacking in rigor. Part and parcel with
    the remarkable renaissance of neural networks must come techniques that expose
    their intricacies.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 学习缺乏透明度将导致权力没有责任。观察缺乏阐明将导致缺乏严谨的橡皮图章。神经网络的显著复兴必须伴随揭示其复杂性的技术。
- en: Progress on this frontier remains nascent — but vital seeds are taking root.
    By striving to perfect hybrids of understandability and faithfulness, whether
    via efficient approximations or innately interpretable architectures, perhaps
    future systems can masterfully explain their mastery to lift the veil of black
    box mysticism once and for all.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一领域的进展仍处于初期阶段——但重要的种子已经扎根。通过努力完善理解性与忠实性的混合，无论是通过高效的近似方法还是天生可解释的架构，也许未来的系统可以巧妙地解释其掌握，从而彻底揭开黑箱神秘的面纱。
