- en: Unsupervised Learning Method Series — Exploring K-Means Clustering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习方法系列 — 探索 K-均值聚类
- en: 原文：[https://towardsdatascience.com/unsupervised-learning-method-series-exploring-k-means-clustering-d129fff3ab6a](https://towardsdatascience.com/unsupervised-learning-method-series-exploring-k-means-clustering-d129fff3ab6a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unsupervised-learning-method-series-exploring-k-means-clustering-d129fff3ab6a](https://towardsdatascience.com/unsupervised-learning-method-series-exploring-k-means-clustering-d129fff3ab6a)
- en: Let’s explore one of the most famous unsupervised learning methods and how it
    uses distances to map similar instances together
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们探索一种最著名的无监督学习方法之一，看看它如何利用距离将相似的实例映射在一起
- en: '[](https://ivopbernardo.medium.com/?source=post_page-----d129fff3ab6a--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page-----d129fff3ab6a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d129fff3ab6a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d129fff3ab6a--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page-----d129fff3ab6a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ivopbernardo.medium.com/?source=post_page-----d129fff3ab6a--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page-----d129fff3ab6a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d129fff3ab6a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d129fff3ab6a--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page-----d129fff3ab6a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d129fff3ab6a--------------------------------)
    ·13 min read·Apr 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d129fff3ab6a--------------------------------)
    ·阅读时间 13 分钟·2023年4月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d3f57dc819639ea669371626800d21bd.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d3f57dc819639ea669371626800d21bd.png)'
- en: Photo by [alexlanting](https://unsplash.com/pt-br/@alexlanting) @Unsplash.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [alexlanting](https://unsplash.com/pt-br/@alexlanting) @Unsplash.com 提供
- en: Unsupervised learning is a misterious, yet fun, art. While there is no ground
    truth label to predict and it may be harder to evaluate the solution we come up
    with, unsupervised learning methods are extremely interesting techniques to understand
    our data’s structure and reduce it’s complexity.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是一门神秘而有趣的艺术。虽然没有明确的标签可以预测，评估我们得到的解决方案可能会更困难，但无监督学习方法是理解数据结构和降低数据复杂性的极其有趣的技术。
- en: Along with visualization and dimensionality reduction techniques, clustering
    is an important group of unsupervised machine learning methods that help us collapse
    single instances into fewer examples by losing some of the original signal from
    our data. In this unsupervised learning series, we’ll first approach `k-means`
    clustering, a very interesting and famous distance-based clustering method.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与可视化和降维技术一起，聚类是无监督机器学习方法的重要组，它帮助我们将单个实例合并为更少的示例，同时丧失一些原始数据的信号。在这个无监督学习系列中，我们将首先介绍
    `k-均值` 聚类，这是一种非常有趣和著名的基于距离的聚类方法。
- en: K-means Algorithm
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-均值算法
- en: The K-means algorithm works by mapping every observation to a fixed number (*k*)
    of clusters in a dataset based on distances.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: K-均值算法通过将每个观察映射到数据集中固定数量（*k*）的簇来工作。
- en: 'Let’s start by visualizing an example where we have customers mapped on a 2
    dimensional plot by `Age`and `Annual Income`:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个示例开始，在这个示例中，我们将客户映射到一个 2 维图中，按 `年龄` 和 `年收入`：
- en: '![](../Images/2744cfd3c10f245ffe2621a550600507.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2744cfd3c10f245ffe2621a550600507.png)'
- en: Age vs. Annual Income Example — Image by Author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 年龄与年收入示例 — 作者提供的图片
- en: If we needed to group the customers of our fictional shop (each customer is
    a dot), how many distinct groups should we choose, **given that there is no definitive
    labeling system for these groups?**
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要对虚构商店的客户（每个客户是一个点）进行分组，在**没有确定的标签系统来区分这些组的情况下，我们应该选择多少个不同的组？**
- en: To answer these questions, we will first conduct some experiments. **Our initial
    assumption is that there are 2 distinct groups, and we need to allocate our customers
    to them.**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题，我们将首先进行一些实验。**我们最初的假设是有 2 个不同的群体，我们需要将客户分配到这些群体中。**
- en: 'To begin with, we will randomly select two points on the plot, which will serve
    as *cluster centroids* (representing the center of our groups). These points are
    highlighted in orange for ease of identification:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将随机选择图上的两个点，这些点将作为 *聚类中心点*（代表我们组的中心）。这些点为方便识别而被标记为橙色：
- en: '![](../Images/415a38e8d9a9351d574587c93a5f6f80.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/415a38e8d9a9351d574587c93a5f6f80.png)'
- en: Cluster Centroids Example— Image by Author
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类中心示例 — 作者图像
- en: The number of orange points are considered the *k* of k-means. Our solution
    is awful. Why? **Because the orange points fail to represent the underlying data.**
    We have a centroid (bottom left corner) that is just too far away from the data.
    How can we improve this?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 橙点的数量被认为是 k-means 的 *k*。我们的解决方案很糟糕。为什么？**因为橙点未能代表潜在的数据。** 我们有一个中心点（左下角），离数据太远了。我们怎么改进？
- en: The first step of *k-means* consists of allocating every data point to the nearest
    *centroid.* In our case, every customer will be considered part of one of the
    orange dots we see in the picture.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*k-means* 的第一步是将每个数据点分配给最近的 *中心点*。在我们的案例中，每个客户将被认为是我们在图中看到的橙点的一部分。'
- en: To make this even easier to understand, let’s start by naming one of our points
    — customer *Steve*!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易理解，让我们从给其中一个点命名开始——客户 *Steve*！
- en: '![](../Images/ac098e17ea7d6051ae722528db68b5d6.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac098e17ea7d6051ae722528db68b5d6.png)'
- en: Steve vs. Centroids — Image by Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Steve 与中心点 — 作者图像
- en: '*Steve* is a bit confused — he doesn’t know which group he should join. **Should
    he join the group on the bottom right corner** (represented by the orange dot)
    **or the one on the top left corner** (represented by the other orange dot)?'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*Steve* 有点困惑——他不知道应该加入哪个小组。**他应该加入右下角的小组**（由橙点表示）**还是左上角的小组**（由另一个橙点表示）？'
- en: 'Let’s give a helping hand to Steve, by drawing the distance between itself
    and each group:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过绘制 Steve 与每个小组之间的距离来帮助 Steve：
- en: '![](../Images/2e234e62b6822aa53e8a46f3b8a1d8c1.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e234e62b6822aa53e8a46f3b8a1d8c1.png)'
- en: Distance from Steve to First Group — Image by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Steve 到第一组的距离 — 作者图像
- en: 'One easy way to represent this distance is by calculating the *euclidean distance*
    between Steve and the group, something that is represented by the following formula:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 表示这一距离的一个简单方法是计算*欧几里得距离*，即 Steve 与该组之间的距离，表示为下列公式：
- en: '![](../Images/ce5ea57a06d30834de0c3b271fec57f0.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce5ea57a06d30834de0c3b271fec57f0.png)'
- en: 'If we substitute *P1* and *P2* by *Steve* and the cluster centroid, we have
    the following calculation:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将 *P1* 和 *P2* 替换为 *Steve* 和聚类中心点，我们得到以下计算：
- en: '![](../Images/8d25cdc0b220f2d75d5c474bc49d198b.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d25cdc0b220f2d75d5c474bc49d198b.png)'
- en: The distance of Steve to Centroid 1 is **22.36**. What about the distance from
    Steve to Centroid 2?
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Steve 到中心点 1 的距离是 **22.36**。那 Steve 到中心点 2 的距离呢？
- en: '![](../Images/da0facb2f05dab85c208983573f9496f.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da0facb2f05dab85c208983573f9496f.png)'
- en: Distance from Steve to Second Group — Image by Author
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Steve 到第二组的距离 — 作者图像
- en: 'In this case, the distance is:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，距离是：
- en: '![](../Images/77dc81d4b4c995a8d8524c52f03ab44d.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77dc81d4b4c995a8d8524c52f03ab44d.png)'
- en: '**Steve is clearly nearer Group 1** (or Centroid 1)according to the euclidean
    distance, so he’ll get assigned to that group — let’s do that by painting the
    dot representing *Steve* with a red column:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**根据欧几里得距离，Steve 显然离第 1 组**（或中心点 1）更近，因此他将被分配到该组——我们通过将代表 *Steve* 的点涂成红色来实现这一点：'
- en: '![](../Images/cf4eb7c92d48670590aefa9e98ea3477.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf4eb7c92d48670590aefa9e98ea3477.png)'
- en: Assigning Steve to the First Group — Image by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Steve 分配到第一组 — 作者图像
- en: 'If we repeat the same process for all other customers the result will be the
    following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对所有其他客户重复相同的过程，结果将是：
- en: '![](../Images/2be5e462c2f3d30ef88052b87dd8508f.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2be5e462c2f3d30ef88052b87dd8508f.png)'
- en: In the figure above, we mark customers that are near Centroid 1 as red (just
    like *Steve*) and the ones that are near Centroid 2 as green.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，我们将靠近中心点 1 的客户标记为红色（就像 *Steve* 一样），将靠近中心点 2 的客户标记为绿色。
- en: Is our clustering solution done? Nope!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的聚类解决方案完成了吗？不！
- en: The next phase of *k-means* is to recalculate the centroids (orange dots). How
    can we do that? We just compute the average of the points assigned to each cluster!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*k-means* 的下一阶段是重新计算中心点（橙点）。我们怎么做呢？我们只需计算分配给每个簇的点的平均值！'
- en: 'In this case:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下：
- en: Average of all `Ages` assigned to Centroid 1 is 46.9\. Average of all `Annual
    Income` for this group is 39.9.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配给中心点 1 的所有 `Ages` 的平均值是 46.9。该组的所有 `Annual Income` 的平均值是 39.9。
- en: Average of all `Ages` for Centroid 2 is 37\. Average of all `Annual Income`
    for this group is 91.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质心 2 的所有 `年龄` 的平均值为 37。这个组的所有 `年收入` 的平均值为 91。
- en: 'The coordinates *(46.9, 39.9)* and *(37, 91)* will be our new centroids! Let’s
    move them in our 2-D plot:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 坐标 *(46.9, 39.9)* 和 *(37, 91)* 将成为我们新的质心！让我们在 2-D 图中移动它们：
- en: '![](../Images/aa69d317eed10b28581d5a5f9a5ce937.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa69d317eed10b28581d5a5f9a5ce937.png)'
- en: Moving our Centroids — Image by Author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 移动我们的质心 — 作者提供的图片
- en: With the new centroids on our plot, we reset the attribution of customers to
    clusters. *Steve* and friends will have to be allocated again!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在图上显示新质心后，我们重新分配客户到聚类。*Steve* 和他的朋友们将需要重新分配！
- en: '![](../Images/86557f68118d32a5efd70d6a848b5ca3.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86557f68118d32a5efd70d6a848b5ca3.png)'
- en: Re-setting cluster attribution — Image by Author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 重新设置聚类分配 — 作者提供的图片
- en: 'We calculate the *euclidean distance* between each data point and centroids
    again — after doing that, we’ll have new groups:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次计算每个数据点和质心之间的 *欧几里得距离*——完成后，我们将得到新的组别：
- en: '![](../Images/4267631b095efef537e1f97604299135.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4267631b095efef537e1f97604299135.png)'
- en: Re-setting cluster attribution — Image by Author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 重新设置聚类分配 — 作者提供的图片
- en: Notice that something changed between our first and second iteration! Let’s
    visualize our iterations again next to each other.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到我们第一次和第二次迭代之间发生了变化！让我们再次将迭代结果并排可视化。
- en: 'Iteration 1:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代 1：
- en: '![](../Images/2be5e462c2f3d30ef88052b87dd8508f.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2be5e462c2f3d30ef88052b87dd8508f.png)'
- en: 1st Iteration of K-means — Image by Author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 的第一次迭代 — 作者提供的图片
- en: 'Iteration 2:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代 2：
- en: '![](../Images/5931d08f715a20996c851eff4d323e51.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5931d08f715a20996c851eff4d323e51.png)'
- en: 2nd Iteration of K-means — Image by Author
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 的第二次迭代 — 作者提供的图片
- en: 'Some customers moved from Group 1 to Group 2 between iterations — namely the
    purple points highlighted below:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一些客户在迭代之间从组 1 移动到组 2——即下面突出显示的紫色点：
- en: '![](../Images/c91aeff17d8f7e5511f3dd96c925ffc4.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c91aeff17d8f7e5511f3dd96c925ffc4.png)'
- en: Moving Customers — Image by Author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 移动客户 — 作者提供的图片
- en: This is a central theme in *k-means* clustering as the process will stop when
    **no points change cluster from iteration to iteration.**
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 *k-means* 聚类的核心主题，因为当**没有点在迭代中更改聚类**时，过程将停止。
- en: In our case, two iterations are enough as no customer will change it’s group
    in the next iteration — *k-means* complete!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，两次迭代就足够了，因为没有客户会在下一次迭代中改变其组别——*k-means* 完成！
- en: After performing a clustering grouping, we will treat our data as two single
    data points , **represented by the centroids!**
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行聚类分组后，我们将把数据视为两个单独的数据点，**由质心表示！**
- en: '![](../Images/1359171cc04507f98ba93b3f03e1c1fd.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1359171cc04507f98ba93b3f03e1c1fd.png)'
- en: K-means Centroids — Image by Author
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 质心 — 作者提供的图片
- en: This is a very important step — **we are making the active choice of reducing
    our data points to only 2.** This is a significant loss of variance of the data
    and one of the core ideas behind of clustering.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常重要的步骤——**我们主动选择将数据点减少到仅 2 个。** 这是数据方差的显著损失，也是聚类的核心思想之一。
- en: '**How can we evaluate this solution?** One idea is to compute the *within clusters
    sum of squares,* a metric that calculates the distance between each data point
    and it’s corresponding cluster — visually:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们如何评估这个解决方案？** 一个想法是计算 *簇内平方和*，这是一个衡量每个数据点与其对应聚类之间距离的指标——从视觉上来看：'
- en: '![](../Images/30014a329a95733566548ab1efbf5cf9.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30014a329a95733566548ab1efbf5cf9.png)'
- en: Visualizing WCSS — Image by Author
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化 WCSS — 作者提供的图片
- en: If we compute all the euclidean distances between our points and their respective
    centroid, we will get a value of around 8850 — this value gives us translates
    into the information we are losing by considering our customers as two clusters.
    Additionally, we can also check the *Between Cluster Sum of Squares(bcss)* that
    measures the average squared distance between all centroids.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们计算所有点与其相应质心之间的欧几里得距离，我们将得到一个大约 8850 的值——这个值表示了我们通过将客户视为两个聚类而丧失的信息。此外，我们还可以检查
    *簇间平方和 (bcss)*，它衡量所有质心之间的平均平方距离。
- en: '**Naturally, when we add a new centroid, the *WCSS* will be lower, as points
    will have to travel less to their centroid:**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**自然地，当我们添加一个新的质心时，*WCSS* 将会更低，因为点到其质心的距离减少：**'
- en: '![](../Images/5ceeb61c03e02a4f04a40c9eccbf2e83.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ceeb61c03e02a4f04a40c9eccbf2e83.png)'
- en: Visualizing WCSS with 3 clusters — Image by Author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 用 3 个聚类可视化 WCSS — 作者提供的图片
- en: With the *k-means* intuition in our pocket, we can check the *sklearn* implementation
    in Python. Additionally, we still don’t know how to evaluate an appropriate number
    of clusters (*k*) — something we will see next!
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有*k-means*直觉后，我们可以检查Python中*sklearn*的实现。此外，我们仍然不知道如何评估适当的簇数（*k*）——这是我们接下来会看到的内容！
- en: Sklearn Implementation
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sklearn 实现
- en: In this part we’ll use the [The Airlines Customer Satisfaction](https://www.kaggle.com/datasets/sjleshrac/airlines-customer-satisfaction)
    dataset, that contains information about customer satisfaction for an airline
    company. Each observation represents a customer, and the variables include things
    like the customer’s demographic information, the travel type (business, etc.),
    and their satisfaction ratings for various aspects of the flight.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将使用[航空公司客户满意度](https://www.kaggle.com/datasets/sjleshrac/airlines-customer-satisfaction)数据集，该数据集包含有关航空公司客户满意度的信息。每个观察值代表一个客户，变量包括客户的
    demographic 信息、旅行类型（商务等）以及他们对航班各个方面的满意度评分。
- en: 'Here’s a look at the first 5 rows and 13 columns of the data:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据前5行和13列的展示：
- en: '[PRE0]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/d17754ed06e12f2be0b1b5511338074a.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d17754ed06e12f2be0b1b5511338074a.png)'
- en: Airline Data Preview — Image by Author
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 航空公司数据预览——图像由作者提供
- en: 'Starting our pipeline with preprocessing let’s remove some columns that we
    don’t want to influence our clusters — for that purpose, I’ll remove all categorical
    columns from a possible solution:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的管道中进行预处理时，让我们移除一些不希望影响我们簇的列——为此，我将从可能的解决方案中移除所有分类列：
- en: Satisfaction;
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 满意度；
- en: Gender;
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别；
- en: Customer Type;
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户类型；
- en: Class;
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别；
- en: Type of Travel;
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旅行类型；
- en: 'Naturally, this is a choice that I’m doing in the data pipeline, for two reasons:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 自然，这是一种我在数据管道中做出的选择，原因有两个：
- en: I want to keep the focus of this blog post on explaining k-means, and avoid
    building a more complex data pipeline that takes away our attention from that
    purpose.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我希望这篇博客文章的重点是解释k-means，并避免构建一个更复杂的数据管道，这会使我们的注意力从这个目标上转移开。
- en: When it comes to categorical variables, we don’t want to have too many dummy
    variables influencing our clusters.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于分类变量，我们不希望有太多虚拟变量影响我们的簇。
- en: As we add more and more binary (also called *dummy*) variables into the k-means
    solution, these variables start to weight a lot in the final clustering distances,
    even after standardization, so it’s very important to be cautious when adding
    this types of data to any *k-means* solution.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们在k-means解决方案中添加越来越多的二元（也称为*虚拟*）变量，这些变量在最终的簇距离中开始占据很大权重，即使在标准化之后，所以在向任何*k-means*解决方案中添加这类数据时要非常小心。
- en: '[PRE1]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: I also noticed that there are 393 rows with *Arrival Delay in Minutes* as NA
    — *k-means* implementation will not deal very well with this, so we need to do
    some *data imputation*.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我还注意到有393行的*Arrival Delay in Minutes*为NA——*k-means*实现对此处理不是很好，所以我们需要做一些*数据插补*。
- en: 'If we zoom-in on these rows, no pattern emerges:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们放大这些行，没有模式出现：
- en: '[PRE2]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/c4f93736e875754c381a639d0f4e8888.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4f93736e875754c381a639d0f4e8888.png)'
- en: Rows with Arrival Delay in Minutes as Null — Image by Author
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 到达延误以分钟为单位为空的行——图像由作者提供
- en: 'For these rows, I’ll just assume that the plane arrived with the same delay
    as it departed — applying that rule using `np.where`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些行，我将假设飞机到达的延误与起飞时的延误相同——使用`np.where`应用这个规则：
- en: '[PRE3]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The rule is quite simple and we are leaning on `np.where` to do this:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 规则很简单，我们依赖`np.where`来完成这个操作：
- en: When `Arrival Delay in Minutes` is `na` , we say that this column should be
    equal to the `Departure Delay in Minutes` , otherwise we use the original value.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当`Arrival Delay in Minutes`为`na`时，我们会将这一列设置为`Departure Delay in Minutes`，否则我们使用原始值。
- en: Next step in the preprocessing pipeline is to standardize all our variables
    into a common scale. Particularly in *k-means,* where distances are a crucial
    part of the algorithm, this step may be extremely important to find meaningful
    customers (although testing without standardization may also give you good results,
    depending on how the underlying variable distribution behaves and how large the
    difference in numeric scales).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理管道中的下一步是将所有变量标准化到一个共同的尺度。特别是在*k-means*中，距离是算法的关键部分，这一步骤可能对找到有意义的客户极其重要（尽管根据底层变量分布的行为和数字尺度的差异，未经标准化的测试也可能给出良好的结果）。
- en: 'I’m going to apply a *StandardScaler* from `sklearn` :'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我将应用`sklearn`中的*StandardScaler*：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Preprocessing done** — we’re ready to fit our *k-means* solution!'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**预处理完成**——我们准备好拟合我们的*k-means*解决方案了！'
- en: But..
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 但是..
- en: How many centroids do we choose?
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择多少个质心？
- en: 'Normally, in a *k-means* solution, we would run the algorithm for different
    *k’s* and evaluate each solution *WCSS —* that’s what we will do below, using
    *KMeans* from *sklearn,* and obtaining the `wcss` for each one of them (stored
    in the `inertia_` attribute):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在*k-means*解决方案中，我们会对不同的*k*值运行算法并评估每个解决方案的*WCSS*——这就是我们将要做的，使用来自*sklearn*的*KMeans*，并获取每个解决方案的`wcss`（存储在`inertia_`属性中）：
- en: '[PRE5]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can now visualize the evolution of `WCSS` per each solution. There are [several
    methods](https://www.analyticsvidhya.com/blog/2021/05/k-mean-getting-the-optimal-number-of-clusters/)
    to choose the number of appropriate clusters — in this post, we’ll use the `elbow
    method` that chooses the # of clusters where adding the curve below becomes starts
    to become less steep as this represents the solution where adding a new cluster
    won’t lower `WCSS` so much:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以可视化每个解决方案中`WCSS`的演变。有[几种方法](https://www.analyticsvidhya.com/blog/2021/05/k-mean-getting-the-optimal-number-of-clusters/)来选择合适的簇数——在这篇文章中，我们将使用`肘部法则`，它选择了使曲线下方变得不那么陡峭的簇数，因为这表示增加新簇不会显著降低`WCSS`：
- en: '![](../Images/8d968a090ee7195422e3f89c865ff33b.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d968a090ee7195422e3f89c865ff33b.png)'
- en: WCSS Plot— Image by Author
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: WCSS图 — 作者提供的图像
- en: 'We are going to choose 5 as our ideal number of clusters (keep in mind that
    choosing a point in the elbow plot is not scientific and it’s actually a good
    idea to test different solution near the “elbow”):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将选择5作为理想的簇数（请记住，选择肘部图中的点并不科学，实际上测试“肘部”附近的不同解决方案是个好主意）：
- en: '![](../Images/ba186201c26a78cb9c4c17064853a2c7.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba186201c26a78cb9c4c17064853a2c7.png)'
- en: WCSS Plot — Image by Author
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: WCSS图 — 作者提供的图像
- en: 'To fit the solution with 5 clusters, we can pass that value to the parameter
    in the `Kmeans` implementation:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了适配5个簇的解决方案，我们可以将该值传递给`Kmeans`实现中的参数：
- en: '[PRE6]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we’ll predict the cluster based on this solution for each customer on
    our filtered data frame — although we should `predict` on the scaled_data (as
    it contains the same scale where the solution was fitted), it’s actually a good
    idea to add the predictions to the original dataframe so that we are able to interpret
    the means of the clusters with scales that make sense:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将根据此解决方案对过滤后的数据框中的每个客户进行簇预测——尽管我们应该在scaled_data上`预测`（因为它包含了解决方案拟合的相同尺度），实际上将预测结果添加到原始数据框中是个好主意，以便我们能够用有意义的尺度解释簇的均值：
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'How do we analyze the clusters? One cool idea is to compare the means of the
    features across clusters:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何分析这些簇？一个很好的想法是比较各簇中特征的均值：
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To interpret the `cluster_kmeans` , we just compute the averages accross all
    variables for each cluster:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要解释`cluster_kmeans`，我们只需计算每个簇中所有变量的平均值：
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/1531fa48172aaff6a653dd268a1173e1.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1531fa48172aaff6a653dd268a1173e1.png)'
- en: Cluster Means — Image by Author
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 簇均值 — 作者提供的图像
- en: For example, cluster index 1 seem very annoyed with their `Seat Comfort` as
    , on average, customers that belong to this group only gave `1.83` points to this
    variable on the survey. Although we can keep doing these comparisons for all variables,
    we still have a lot of dimensions (features) on our clustering solution, making
    it harder to analyze the differences between them.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，簇索引1似乎对他们的`座位舒适度`感到非常不满，因为平均而言，这组客户在调查中仅给了这个变量`1.83`分。虽然我们可以继续对所有变量进行这些比较，但在我们的聚类方案中仍然有很多维度（特征），这使得分析它们之间的差异变得更加困难。
- en: 'To remove some features from the clustering solutions, some ideas we can apply
    are:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从聚类方案中去除一些特征，我们可以应用的一些想法有：
- en: Remove or combine highly correlated variables.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去除或合并高度相关的变量。
- en: Fit a Principal Component Analysis or other dimensionality reduction techniques.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行主成分分析或其他降维技术。
- en: 'To keep this post light, let’s analyze the correlation matrix between our numeric
    features:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持文章简洁，我们来分析数值特征之间的相关矩阵：
- en: '![](../Images/46b91ad255123fd8cbf08239e8669b80.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46b91ad255123fd8cbf08239e8669b80.png)'
- en: Correlation Matrix of Numeric Features — Image by Author
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 数值特征的相关矩阵 — 作者提供的图像
- en: 'From the correlation matrix above, we can identify that “Online Boarding”,
    “Inflight Wifi Service”, “Online Support” and “Ease of Online Booking” seem to
    be correlated together. I’m going to average these 4 variables into a single one
    called `Online and Wi-Fi Satisfaction` :'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的相关矩阵中，我们可以识别出“在线登机”、“机上Wi-Fi服务”、“在线支持”和“在线预订的便捷性”似乎相关联。我将把这4个变量的平均值合并为一个称为`在线和Wi-Fi满意度`的变量：
- en: '[PRE10]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Seat Comfort and Food and Drink can also be combined into a “Comfort & Food”
    variable:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 座椅舒适度和食品饮料也可以合并成一个“舒适与食品”变量：
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, I’m going to drop `Arrival Delay in Minutes` as it has a very high
    correlation with `Departure Delay in Minutes` :'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我将删除`Arrival Delay in Minutes`，因为它与`Departure Delay in Minutes`的相关性非常高：
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Also, we’ve already fitted a clustering solution to this dataset, so let me
    remove that variable as well:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们已经为这个数据集拟合了聚类解决方案，所以让我也删除这个变量：
- en: '[PRE13]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We’re only left with 13 features! *K-means* solutions may also suffer from the
    curse of dimensionality (particularly when we try to interpret our clusters) and
    trying to reduce the dataset features may be a good idea to interpret our clustering
    solution in a more easy manner.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只剩下13个特征了！*K-means* 解决方案可能也会受到维度灾难的影响（特别是在我们尝试解释聚类时），尝试减少数据集特征可能是以更简单的方式解释我们的聚类解决方案的好主意。
- en: 'Let’s see the elbow curve based on the new dataset that contains less features:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看基于包含较少特征的新数据集的肘部曲线：
- en: '![](../Images/bd445aee010af3be18436363b2b7c1d8.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd445aee010af3be18436363b2b7c1d8.png)'
- en: WCSS Plot for KMeans with Less Features— Image by Author
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 特征较少的KMeans的WCSS图 — 作者提供的图像
- en: 'In this case, I’,m going to choose 6 clusters as a solution. Predicting them
    and adding the new `cluster` to the `airline_data_filter` dataset again:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我将选择6个聚类作为解决方案。预测这些聚类，并将新的`cluster`再次添加到`airline_data_filter`数据集中：
- en: '[PRE14]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/68186a60718757f343623f1a7f5878b4.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68186a60718757f343623f1a7f5878b4.png)'
- en: Cluster Profile — First Columns of the Dataset— Image by Author
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类概况 — 数据集的前几列 — 作者提供的图像
- en: '![](../Images/61fa9062d24c34d13d04edf709651381.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61fa9062d24c34d13d04edf709651381.png)'
- en: Cluster Profile — Other Columns of the Dataset — Image by Author
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类概况 — 数据集的其他列 — 作者提供的图像
- en: 'To do a profiling of our customers, it’s relevant to know the average of our
    features, as well:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在对我们的客户进行分析时，了解我们特征的平均值也是很重要的：
- en: '![](../Images/21dc44f527c7d80f3794f743c27c2a44.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21dc44f527c7d80f3794f743c27c2a44.png)'
- en: Global average of features — Image by Author
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 特征的全球平均值 — 作者提供的图像
- en: 'Based on the comparison between the average of each variable, we can now do
    some profilling of our clusters! For example:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 基于每个变量的平均值比较，我们现在可以对我们的聚类进行一些分析！例如：
- en: Cluster index 0 consists of a group of customers that is on the average of most
    variables. They do seem a bit unhappy about some parts of the flying experience
    such as `On-board and Leg room Service` , `Baggage Handling` , `Checkin service`
    and `Cleanliness` . How do we know that? Because they gave, on average 2.8 points
    to these variables in the survey, 0.5 p.p below the overall average.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类索引0由一组在大多数变量上接近平均水平的客户组成。他们对飞行体验中的一些方面，如`机上和腿部空间服务`、`行李处理`、`值机服务`和`清洁度`，似乎有些不满意。我们怎么知道的？因为他们在调查中对这些变量的平均评分为2.8分，比整体平均水平低0.5个百分点。
- en: Cluster index 1 is made of very happy customers. These customers rated the airline
    services with above than average points (most variables have an average of above
    4 stars for this group of customers).
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类索引1由非常满意的客户组成。这些客户给航空公司服务打分高于平均水平（对于这个客户群体，大多数变量的平均分数都在4星以上）。
- en: On the other hand, cluster with index 2 seems very unhappy. These customers
    rated the airline services with a below than average rating.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，索引为2的聚类似乎非常不满意。这些客户给航空公司服务的评分低于平均水平。
- en: Cluster with index 3 consists of customers with longer trips and that rate the
    airline services a bit below the average. These customers also seem to have been
    impacted more often by a delay on their flight.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引为3的聚类包含长途旅行的客户，他们对航空公司服务的评分稍低于平均水平。这些客户似乎也更频繁地受到航班延误的影响。
- en: 'Cluster with index 4 has customers that are generally happy except for three
    variables: `Departure/Arrival Time Convenience` , `Gate Location` and `Comfort
    & Food` . Probably, there’s some extra variable that may justify these ratings,
    such as these customers travelling low-cost.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引为4的聚类的客户一般都很满意，除了三个变量：`Departure/Arrival Time Convenience`、`Gate Location`和`Comfort
    & Food`。可能有一些额外的变量可以解释这些评分，例如这些客户可能是低成本旅行。
- en: Cluster with index 5 contains the younger customers. It’s very interesting to
    check that they rated most of the variables with average points, except for `Inflight
    Entertainment` , `Online & Wi-Fi Satisfaction` and `Comfort and Food` . Possibly,
    as these customers are younger, they had different expectations regarding online
    services and entertainment that were not met by the airline, something that may
    impact the airline’s ability to captivate younger customers.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引为 5 的集群包含年轻客户。非常有趣的是，他们对大多数变量的评分都为平均分，只有`Inflight Entertainment`、`Online &
    Wi-Fi Satisfaction` 和 `Comfort and Food` 除外。可能由于这些客户较年轻，他们对在线服务和娱乐的期望与航空公司未能满足的期望不同，这可能影响航空公司吸引年轻客户的能力。
- en: 'As you can see, it’s very easy to set up a clustering solution in Python. Here
    are some suggestions of next steps that you can do:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在 Python 中设置聚类解决方案非常简单。以下是你可以采取的一些下一步建议：
- en: Visualize the distribution of the categorical variables inside the clusters.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化集群内分类变量的分布。
- en: Check how these clusters relate to customer satisfaction.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查这些集群如何与客户满意度相关。
- en: Build targeted campaigns to improve customer satisfaction. For example, it seemed
    that the last cluster was disappointed about the entertainment and online services
    — why not build a personalized campaign for younger customers offering a better
    experience on these services?
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建有针对性的营销活动以提高客户满意度。例如，最后一个集群似乎对娱乐和在线服务感到失望——为什么不为年轻客户建立一个个性化的营销活动，以便在这些服务上提供更好的体验呢？
- en: Conclusion
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: That’s it! Thank you for taking the time to read this blog post.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了！感谢你花时间阅读这篇博客文章。
- en: 'Some things we didn’t discuss were limitations of this algorithm. Let’s use
    this conclusion for that:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有讨论的一些内容是该算法的局限性。让我们用这个结论来讨论：
- en: One important thing to keep in mind when using *k-means* is that the algorithm
    is sensitive to the initial placement of the centroids. This is because the algorithm
    may converge to a local minimum, rather than the global minimum, if the initial
    centroids are poorly chosen. **Therefore, it is often a good idea to run the algorithm
    multiple times with different initial centroids and choose the solution that gives
    the lowest overall sum of squared distances.**
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*k-means* 时需要记住的一点是算法对质心的初始位置非常敏感。这是因为如果初始质心选择不佳，算法可能会收敛到局部最小值而不是全局最小值。**因此，通常建议多次运行算法，使用不同的初始质心，并选择提供最低总平方距离的解决方案。**
- en: Another limitation of k-means is that it assumes that the clusters are roughly
    spherical and equally sized. This means that it may not work well on datasets
    where the clusters are irregularly shaped or have vastly different sizes. In such
    cases, other clustering algorithms may be more appropriate, such as **hierarchical
    clustering or density-based clustering.**
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-means 的另一个局限性是它假设集群大致是球形的且大小相等。这意味着它可能在集群形状不规则或大小差异很大的数据集上效果不佳。在这种情况下，其他聚类算法可能更为合适，例如**层次聚类或基于密度的聚类**。
- en: Despite its limitations, k-means is a popular and effective clustering algorithm
    that has been widely used in many different applications. It is relatively easy
    to implement, explainable and can handle large datasets efficiently. With its
    simple and intuitive approach, it is a good starting point for exploring the structure
    of your data and identifying patterns that may not be immediately obvious.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有其局限性，k-means 仍然是一种流行且有效的聚类算法，已广泛应用于许多不同的场景。它相对容易实现，易于解释，并且能够高效处理大数据集。凭借其简单直观的方法，它是探索数据结构和识别可能不立即显现的模式的良好起点。
- en: '*If you would like to drop by my Python courses, feel free to join* ***my free
    course*** *here (*[*Python For Busy People — Python Introduction in 2 Hours*](https://www.udemy.com/course/python-for-busy-people-python-introduction-2-hours/?referralCode=1588B6BF72D40253CDD4)*)*
    ***or a longer 16 hour version*** *(*[*The Complete Python Bootcamp for Beginners*](https://www.udemy.com/course/the-python-for-absolute-beginners-bootcamp/?referralCode=8D25992A055C19079B8A)*).
    My Python courses are suitable for beginners/mid-level developers and I would
    love to have you on my class!*'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你想参加我的 Python 课程，欢迎随时加入* ***我的免费课程*** *（*[*Python For Busy People — Python
    Introduction in 2 Hours*](https://www.udemy.com/course/python-for-busy-people-python-introduction-2-hours/?referralCode=1588B6BF72D40253CDD4)*)*
    ***或更长的 16 小时版本*** *（*[*The Complete Python Bootcamp for Beginners*](https://www.udemy.com/course/the-python-for-absolute-beginners-bootcamp/?referralCode=8D25992A055C19079B8A)*）。我的
    Python 课程适合初学者和中级开发人员，欢迎来参加我的课程！*'
- en: '![](../Images/10080764725e472e5b103d3cf5518065.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10080764725e472e5b103d3cf5518065.png)'
- en: Python for Absolute Beginners Course — Image by Author
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Python 初学者课程 — 作者提供的图像
- en: '*The dataset used on this blog post is under the* [*CC0: Public Domain*](https://creativecommons.org/publicdomain/zero/1.0/)
    *license.*'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文博客使用的数据集遵循* [*CC0: 公共领域*](https://creativecommons.org/publicdomain/zero/1.0/)
    *许可协议。*'
