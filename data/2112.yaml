- en: How I Coded My Own Private French Tutor Out of ChatGPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘å¦‚ä½•ç”¨ ChatGPT ç¼–å†™äº†è‡ªå·±çš„ç§äººæ³•è¯­ tutor
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/how-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb?source=collection_archive---------1-----------------------#2023-06-30](https://towardsdatascience.com/how-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb?source=collection_archive---------1-----------------------#2023-06-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/how-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb?source=collection_archive---------1-----------------------#2023-06-30](https://towardsdatascience.com/how-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb?source=collection_archive---------1-----------------------#2023-06-30)
- en: Step-by-step guide to how I used the latest AI services to teach me a new language,
    from architecture to prompt engineering
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é€æ­¥æŒ‡å—ï¼Œè®²è¿°äº†æˆ‘å¦‚ä½•åˆ©ç”¨æœ€æ–°çš„äººå·¥æ™ºèƒ½æœåŠ¡æ¥å­¦ä¹ ä¸€é—¨æ–°è¯­è¨€ï¼Œä»æ¶æ„åˆ°æç¤ºå·¥ç¨‹
- en: '[](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)[![Shaked
    Zychlinski ğŸ—ï¸](../Images/4d050b916bccab64df3c02236b3129eb.png)](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)
    [Shaked Zychlinski ğŸ—ï¸](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)[![Shaked
    Zychlinski ğŸ—ï¸](../Images/4d050b916bccab64df3c02236b3129eb.png)](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)
    [Shaked Zychlinski ğŸ—ï¸](https://shakedzy.medium.com/?source=post_page-----16b3e15007bb--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F43218078e688&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&user=Shaked+Zychlinski+%F0%9F%8E%97%EF%B8%8F&userId=43218078e688&source=post_page-43218078e688----16b3e15007bb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)
    Â·10 min readÂ·Jun 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16b3e15007bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&user=Shaked+Zychlinski+%F0%9F%8E%97%EF%B8%8F&userId=43218078e688&source=-----16b3e15007bb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F43218078e688&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&user=Shaked+Zychlinski+%F0%9F%8E%97%EF%B8%8F&userId=43218078e688&source=post_page-43218078e688----16b3e15007bb---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16b3e15007bb--------------------------------)
    Â· 10åˆ†é’Ÿé˜…è¯» Â· 2023å¹´6æœˆ30æ—¥'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b3e15007bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&source=-----16b3e15007bb---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16b3e15007bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb&source=-----16b3e15007bb---------------------bookmark_footer-----------)'
- en: '*Code of the discussed foreign-language tutor can be found in the* `[companion](https://github.com/shakedzy/companion)`
    [*repo on my GitHub page*](https://github.com/shakedzy/companion)*, and you can
    use it freely for any non-commercial use.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*è®¨è®ºä¸­æåˆ°çš„å¤–è¯­ tutor çš„ä»£ç å¯ä»¥åœ¨* `[companion](https://github.com/shakedzy/companion)`
    [*æˆ‘çš„ GitHub é¡µé¢ä¸Šçš„ repo*](https://github.com/shakedzy/companion)*ä¸­æ‰¾åˆ°ï¼Œæ‚¨å¯ä»¥åœ¨ä»»ä½•éå•†ä¸šç”¨é€”ä¸‹è‡ªç”±ä½¿ç”¨ã€‚*'
- en: '![](../Images/77c41f40c1d0441c96b20495c9f79836.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77c41f40c1d0441c96b20495c9f79836.png)'
- en: Made with Dall-E
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Dall-E åˆ¶ä½œ
- en: So after postponing it for quite some time, I made a choice to resume my French
    studies. As I signed up for the class, this thought struck me â€” *what if I could
    program ChatGPT to be my personal French tutor? What if I could* ***speak*** *to
    it, and it would speak back to me?* Being a Data Scientist working with LLMs,
    this seemed like something worth building. I mean, yes, I can just speak to my
    wife, whoâ€™s French, but thatâ€™s not as cool as designing my own personal tutor
    out of ChatGPT. Love you, honey â¤ï¸.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥åœ¨æ¨è¿Ÿäº†ä¸€æ®µæ—¶é—´ä¹‹åï¼Œæˆ‘å†³å®šé‡æ–°å¼€å§‹æˆ‘çš„æ³•è¯­å­¦ä¹ ã€‚å½“æˆ‘æŠ¥åå‚åŠ è¯¾ç¨‹æ—¶ï¼Œè¿™ä¸ªæƒ³æ³•çªç„¶å‡ºç°â€”â€”*å¦‚æœæˆ‘èƒ½ç¼–ç¨‹è®©ChatGPTæˆä¸ºæˆ‘çš„ä¸ªäººæ³•è¯­å¯¼å¸ˆä¼šæ€ä¹ˆæ ·ï¼Ÿå¦‚æœæˆ‘èƒ½*
    ***ä¸å®ƒå¯¹è¯*** *ï¼Œè€Œå®ƒä¼šå›åº”æˆ‘å‘¢ï¼Ÿ* ä½œä¸ºä¸€åä¸LLMsåˆä½œçš„æ•°æ®ç§‘å­¦å®¶ï¼Œè¿™ä¼¼ä¹æ˜¯å€¼å¾—æ„å»ºçš„ä¸œè¥¿ã€‚æˆ‘æ˜¯è¯´ï¼Œæ˜¯çš„ï¼Œæˆ‘å¯ä»¥ç›´æ¥å’Œæˆ‘çš„æ³•è¯­å¦»å­å¯¹è¯ï¼Œä½†è¿™ä¸å¦‚è®¾è®¡ä¸€ä¸ªç”±ChatGPTæ„å»ºçš„ä¸ªäººå¯¼å¸ˆæ¥å¾—é…·ã€‚çˆ±ä½ ï¼Œäº²çˆ±çš„â¤ï¸ã€‚
- en: 'But seriously now, this project is a little more than just â€œanother cool code-toyâ€.
    Generative AI is headed to every field in our lives, and Large Language Models
    (LLMs) seem to take the lead here. The possibilities of what a single person can
    do these days with access to these models is jaw-dropping, and I decided this
    project is worth my time â€” and yours, too, I believe â€” for two main reason:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¯´çœŸçš„ï¼Œè¿™ä¸ªé¡¹ç›®ä¸ä»…ä»…æ˜¯â€œå¦ä¸€ä¸ªé…·ç‚«çš„ä»£ç ç©å…·â€ã€‚ç”Ÿæˆæ€§AIæ­£å‘æˆ‘ä»¬ç”Ÿæ´»çš„æ¯ä¸€ä¸ªé¢†åŸŸè¿›å†›ï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¼¼ä¹åœ¨è¿™é‡Œå æ®ä¸»å¯¼åœ°ä½ã€‚å¦‚ä»Šï¼Œä¸€ä¸ªäººé€šè¿‡è®¿é—®è¿™äº›æ¨¡å‹æ‰€èƒ½åšçš„äº‹æƒ…ä»¤äººç ç›®ç»“èˆŒï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªé¡¹ç›®å€¼å¾—æˆ‘æŠ•å…¥æ—¶é—´â€”â€”æˆ‘ç›¸ä¿¡ä¹Ÿå€¼å¾—ä½ çš„æ—¶é—´â€”â€”ä¸»è¦æœ‰ä¸¤ä¸ªåŸå› ï¼š
- en: Using ChatGPT as the well-known online tool is powerful, but integrating an
    LLM into your code is a whole different thing. LLMs are still somewhat unpredictable,
    and when your product relies on an LLM â€” or any other GenAI model â€” for the core
    product, you need to learn how to really control GenAI. And itâ€™s not as easy as
    it sounds.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ChatGPTä½œä¸ºçŸ¥åçš„åœ¨çº¿å·¥å…·æ˜¯å¾ˆå¼ºå¤§çš„ï¼Œä½†å°†LLMé›†æˆåˆ°ä½ çš„ä»£ç ä¸­æ˜¯å®Œå…¨ä¸åŒçš„äº‹æƒ…ã€‚LLMsä»ç„¶æœ‰äº›ä¸å¯é¢„æµ‹ï¼Œå½“ä½ çš„äº§å“ä¾èµ–äºLLMâ€”â€”æˆ–ä»»ä½•å…¶ä»–ç”ŸæˆAIæ¨¡å‹â€”â€”ä½œä¸ºæ ¸å¿ƒäº§å“æ—¶ï¼Œä½ éœ€è¦å­¦ä¼šçœŸæ­£æ§åˆ¶ç”ŸæˆAIã€‚è¿™å¹¶ä¸åƒå¬èµ·æ¥é‚£ä¹ˆç®€å•ã€‚
- en: Getting a first working version took only a few workdays. Before GenAI and LLMs,
    this would take months, and would probably require more than a single person.
    The power of using these tools to create powerful applications fast is something
    you really have to try yourself â€” thatâ€™s the future, as far as I see it. Weâ€™re
    not going back.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è·å–ç¬¬ä¸€ä¸ªå·¥ä½œç‰ˆæœ¬åªç”¨äº†å‡ å¤©å·¥ä½œæ—¶é—´ã€‚åœ¨ç”ŸæˆAIå’ŒLLMså‡ºç°ä¹‹å‰ï¼Œè¿™éœ€è¦å‡ ä¸ªæœˆï¼Œå¹¶ä¸”å¯èƒ½éœ€è¦ä¸æ­¢ä¸€ä¸ªäººã€‚åˆ©ç”¨è¿™äº›å·¥å…·å¿«é€Ÿåˆ›å»ºå¼ºå¤§åº”ç”¨çš„åŠ›é‡æ˜¯ä½ çœŸæ­£éœ€è¦è‡ªå·±å°è¯•çš„â€”â€”è¿™æ˜¯æœªæ¥ï¼Œè‡³å°‘åœ¨æˆ‘çœ‹æ¥ï¼Œæˆ‘ä»¬ä¸ä¼šå›å¤´ã€‚
- en: Plus, this project can actually do good. My mom really wants someone she can
    practice her English with. Now she can, and it costs less than $3 a month. My
    wifeâ€™s mom wants to kick off Korean studying. Same thing, same cost. And of course
    I use it too! This project really helps people, and it costs less than a small
    cup of coffee. Thatâ€™s the real GenAI revolution, if you ask me.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä¸”ï¼Œè¿™ä¸ªé¡¹ç›®å®é™…ä¸Šå¯ä»¥åšä¸€äº›å¥½äº‹ã€‚æˆ‘å¦ˆå¦ˆçœŸçš„å¸Œæœ›æ‰¾ä¸€ä¸ªå¯ä»¥ç»ƒä¹ è‹±è¯­çš„å¯¹è±¡ã€‚ç°åœ¨å¥¹å¯ä»¥åšåˆ°ï¼Œè€Œä¸”è´¹ç”¨ä¸åˆ°æ¯æœˆ3ç¾å…ƒã€‚æˆ‘çš„å¦»å­çš„å¦ˆå¦ˆæƒ³å¼€å§‹å­¦ä¹ éŸ©è¯­ã€‚æƒ…å†µç›¸åŒï¼Œè´¹ç”¨ç›¸åŒã€‚å½“ç„¶ï¼Œæˆ‘è‡ªå·±ä¹Ÿåœ¨ä½¿ç”¨ï¼è¿™ä¸ªé¡¹ç›®çœŸçš„å¸®åŠ©äº†äººä»¬ï¼Œè´¹ç”¨æ¯”ä¸€æ¯å°å’–å•¡è¿˜å°‘ã€‚å¦‚æœä½ é—®æˆ‘ï¼Œè¿™æ‰æ˜¯çœŸæ­£çš„ç”ŸæˆAIé©å‘½ã€‚
- en: Starting from Scratch
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»é›¶å¼€å§‹
- en: 'Looking at this project from a high-level perspective, what I needed were 4
    elements:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼Œæˆ‘éœ€è¦çš„æœ‰4ä¸ªè¦ç´ ï¼š
- en: '**Speech-to-text**, to transcribe my own voice to words'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¯­éŸ³è½¬æ–‡æœ¬**ï¼Œå°†æˆ‘çš„å£°éŸ³è½¬å½•ä¸ºæ–‡å­—'
- en: '**Large-Language Model**, preferably a Chat-LLM, which I can ask questions
    and get responses from'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤§å‹è¯­è¨€æ¨¡å‹**ï¼Œæœ€å¥½æ˜¯ä¸€ä¸ªèŠå¤©å‹LLMï¼Œæˆ‘å¯ä»¥å‘å®ƒæé—®å¹¶è·å¾—å›ç­”'
- en: '**Text-to-speech**, to turn the LLMâ€™s answers to voice'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–‡æœ¬è½¬è¯­éŸ³**ï¼Œå°†LLMçš„å›ç­”è½¬æ¢ä¸ºå£°éŸ³'
- en: '**Translation**, to convert any French text I do not fully understand to English
    (or Hebrew, my native language)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¿»è¯‘**ï¼Œå°†æˆ‘ä¸å®Œå…¨ç†è§£çš„æ³•è¯­æ–‡æœ¬è½¬æ¢ä¸ºè‹±è¯­ï¼ˆæˆ–å¸Œä¼¯æ¥è¯­ï¼Œæˆ‘çš„æ¯è¯­ï¼‰'
- en: Luckily, itâ€™s 2023, and all of the above are very *very* accessible. Iâ€™ve also
    chosen to use managed services and APIs rather than running any of these locally,
    as inference will be much faster this way. Also, the low prices of these APIs
    for personal use made this decision a no-brainer.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œç°åœ¨æ˜¯2023å¹´ï¼Œä»¥ä¸Šæåˆ°çš„ä¸€åˆ‡éƒ½å˜å¾—éå¸¸*éå¸¸*å®¹æ˜“è·å¾—ã€‚æˆ‘è¿˜é€‰æ‹©ä½¿ç”¨æ‰˜ç®¡æœåŠ¡å’ŒAPIï¼Œè€Œä¸æ˜¯åœ¨æœ¬åœ°è¿è¡Œè¿™äº›æœåŠ¡ï¼Œå› ä¸ºè¿™æ ·æ¨ç†é€Ÿåº¦ä¼šæ›´å¿«ã€‚æ­¤å¤–ï¼Œè¿™äº›APIçš„ä¸ªäººä½¿ç”¨ä»·æ ¼éå¸¸ä½ï¼Œä½¿å¾—è¿™ä¸ªå†³å®šæ¯«æ— ç–‘é—®ã€‚
- en: After playing around with several alternatives, Iâ€™ve chosen OpenAIâ€™s Whisper
    and ChatGPT as my Speech-to-text and LLM, and Googleâ€™s Text-to-speech and Translate
    as the remaining modules. Creating API keys and setting these services up was
    super-simple, and I was able to communicate with all of them through their native
    Python libraries in a matter of minutes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ç»è¿‡å°è¯•å‡ ç§æ›¿ä»£æ–¹æ¡ˆåï¼Œæˆ‘é€‰æ‹©äº† OpenAI çš„ Whisper å’Œ ChatGPT ä½œä¸ºæˆ‘çš„è¯­éŸ³è½¬æ–‡æœ¬å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒGoogle çš„æ–‡æœ¬è½¬è¯­éŸ³å’Œç¿»è¯‘ä½œä¸ºå‰©ä½™æ¨¡å—ã€‚åˆ›å»º
    API å¯†é’¥å¹¶è®¾ç½®è¿™äº›æœåŠ¡éå¸¸ç®€å•ï¼Œæˆ‘èƒ½å¤Ÿé€šè¿‡å®ƒä»¬åŸç”Ÿçš„ Python åº“åœ¨å‡ åˆ†é’Ÿå†…ä¸æ‰€æœ‰æœåŠ¡è¿›è¡Œé€šä¿¡ã€‚
- en: What really struck me after testing all these services, is that the tutor Iâ€™m
    constructing is not a just an English-to-French teacher; as Whisper, ChatGPT,
    and Google Translate & TTS support dozens of languages, this can be used to learn
    pretty much *any language* while speaking *any other language*. Thatâ€™s insane!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç»è¿‡æµ‹è¯•è¿™äº›æœåŠ¡åï¼Œæˆ‘çœŸæ­£éœ‡æƒŠçš„æ˜¯æˆ‘æ­£åœ¨æ„å»ºçš„å¯¼å¸ˆä¸ä»…ä»…æ˜¯ä¸€ä¸ªè‹±æ³•ç¿»è¯‘è€å¸ˆï¼›ç”±äº Whisperã€ChatGPT å’Œ Google Translate
    & TTS æ”¯æŒå‡ åç§è¯­è¨€ï¼Œè¿™å¯ä»¥ç”¨æ¥å­¦ä¹ å‡ ä¹*ä»»ä½•è¯­è¨€*ï¼ŒåŒæ—¶ä½¿ç”¨*ä»»ä½•å…¶ä»–è¯­è¨€*è¿›è¡Œäº¤æµã€‚è¿™çœŸæ˜¯ç–¯ç‹‚ï¼
- en: '![](../Images/8bbea41fc4b9ccef5a4b39f60266e911.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8bbea41fc4b9ccef5a4b39f60266e911.png)'
- en: Made with Dall-E
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç”± Dall-E åˆ¶ä½œ
- en: Architecture and Threading
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¶æ„å’Œçº¿ç¨‹å¤„ç†
- en: 'Letâ€™s first make sure the overall flow is well understood: **(1)** We begin
    by recording the userâ€™s voice, which is **(2)** sent to Whisper API, and returns
    as text. **(3)** The text is added to the chat history and sent to ChatGPT, which
    **(4)** returns a written response. Its response is **(5)** sent to Google Text-to-speech,
    which returns a sound file that will be **(6)** played as audio.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®©æˆ‘ä»¬ç¡®ä¿æ•´ä½“æµç¨‹å¾—åˆ°å……åˆ†ç†è§£ï¼š**(1)** æˆ‘ä»¬ä»å½•åˆ¶ç”¨æˆ·çš„å£°éŸ³å¼€å§‹ï¼Œ**(2)** è¯¥å£°éŸ³å‘é€åˆ° Whisper APIï¼Œå¹¶è¿”å›æ–‡æœ¬ã€‚**(3)**
    æ–‡æœ¬è¢«æ·»åŠ åˆ°èŠå¤©è®°å½•ä¸­ï¼Œå¹¶å‘é€åˆ° ChatGPTï¼Œ**(4)** ChatGPT è¿”å›ä¹¦é¢å›å¤ã€‚å…¶å›å¤è¢«**(5)** å‘é€åˆ° Google Text-to-speechï¼ŒGoogle
    è¿”å›çš„éŸ³é¢‘æ–‡ä»¶å°†**(6)** è¢«æ’­æ”¾ã€‚
- en: '![](../Images/d796016494a36f4692161e52032412a3.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d796016494a36f4692161e52032412a3.png)'
- en: High-level architecture
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é«˜çº§æ¶æ„
- en: My first practical step was to break this down to components and design the
    overall architecture. I knew Iâ€™ll need a UI, preferably a Web UI as itâ€™s just
    easier to launch apps through the browser these days then having a standalone
    executable. Iâ€™ll also need a â€œbackendâ€, which will be the actual Python code,
    communicating with all the different services. But in order to provide a real-time
    flowing experience, I realized Iâ€™ll need to break it to different threads.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç¬¬ä¸€ä¸ªå®é™…æ­¥éª¤æ˜¯å°†å…¶æ‹†è§£ä¸ºç»„ä»¶å¹¶è®¾è®¡æ•´ä½“æ¶æ„ã€‚æˆ‘çŸ¥é“æˆ‘éœ€è¦ä¸€ä¸ª UIï¼Œæœ€å¥½æ˜¯ Web UIï¼Œå› ä¸ºç°åœ¨é€šè¿‡æµè§ˆå™¨å¯åŠ¨åº”ç”¨ç¨‹åºæ¯”ä½¿ç”¨ç‹¬ç«‹çš„å¯æ‰§è¡Œæ–‡ä»¶æ›´ç®€å•ã€‚æˆ‘è¿˜éœ€è¦ä¸€ä¸ªâ€œåç«¯â€ï¼Œå³å®é™…çš„
    Python ä»£ç ï¼Œä¸æ‰€æœ‰ä¸åŒçš„æœåŠ¡è¿›è¡Œé€šä¿¡ã€‚ä½†ä¸ºäº†æä¾›å®æ—¶çš„æµç•…ä½“éªŒï¼Œæˆ‘æ„è¯†åˆ°æˆ‘éœ€è¦å°†å…¶æ‹†åˆ†ä¸ºä¸åŒçš„çº¿ç¨‹ã€‚
- en: 'The main thread will run the majority of the code: itâ€™ll transcribe my recording
    to text (via Whisper), display this text on the screen as part of the chat, and
    then display the tutorâ€™s written response on the chat screen as well (as received
    by ChatGPT). But Iâ€™ll have to move the tutorâ€™s text-to-speech to a separate thread
    â€” otherwise, what weâ€™ll have is:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»çº¿ç¨‹å°†è¿è¡Œå¤§éƒ¨åˆ†ä»£ç ï¼šå®ƒå°†æŠŠæˆ‘çš„å½•éŸ³è½¬å½•ä¸ºæ–‡æœ¬ï¼ˆé€šè¿‡ Whisperï¼‰ï¼Œå°†æ­¤æ–‡æœ¬æ˜¾ç¤ºåœ¨èŠå¤©ç•Œé¢ä¸Šï¼Œç„¶åå°†å¯¼å¸ˆçš„ä¹¦é¢å›å¤ï¼ˆç”± ChatGPT æ¥æ”¶ï¼‰ä¹Ÿæ˜¾ç¤ºåœ¨èŠå¤©å±å¹•ä¸Šã€‚ä½†æˆ‘å¿…é¡»å°†å¯¼å¸ˆçš„æ–‡æœ¬è½¬è¯­éŸ³ç§»åˆ°ä¸€ä¸ªå•ç‹¬çš„çº¿ç¨‹â€”â€”å¦åˆ™æˆ‘ä»¬å°†å¾—åˆ°ï¼š
- en: the tutorâ€™s voice will only be heard once the entire message will be received
    from ChatGPT, and its response might be long
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¼å¸ˆçš„å£°éŸ³åªèƒ½åœ¨ä» ChatGPT æ¥æ”¶åˆ°æ•´ä¸ªæ¶ˆæ¯åæ‰ä¼šè¢«å¬åˆ°ï¼Œè€Œä¸”å…¶å›å¤å¯èƒ½ä¼šå¾ˆé•¿
- en: itâ€™ll block the user from responding while the tutor speaks
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒå°†é˜»æ­¢ç”¨æˆ·åœ¨å¯¼å¸ˆè®²è¯æ—¶è¿›è¡Œå›åº”
- en: thatâ€™s not the â€œflowingâ€ behavior Iâ€™d like to have; Iâ€™d like the tutor to begin
    speaking as its message is being written on the screen, and to certainly not block
    the user and prevent it from responding just because audio is still playing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸æ˜¯æˆ‘æƒ³è¦çš„â€œæµåŠ¨â€è¡Œä¸ºï¼›æˆ‘å¸Œæœ›å¯¼å¸ˆåœ¨æ¶ˆæ¯æ˜¾ç¤ºåœ¨å±å¹•ä¸Šæ—¶å°±å¼€å§‹è®²è¯ï¼Œå¹¶ä¸”ç»å¯¹ä¸è¦å› ä¸ºéŸ³é¢‘ä»åœ¨æ’­æ”¾è€Œé˜»æ­¢ç”¨æˆ·å¹¶é˜»æ­¢å…¶å›åº”ã€‚
- en: To do that, the text-to-speech part of the project was split to *two* additional
    threads. As the tutorâ€™s response was being received from ChatGPT token-by-token,
    every full sentence created was passed to another thread, from which it was sent
    to the text-to-speech service, converting it to sound files. Iâ€™d like to emphasize
    the word *files* here â€” as Iâ€™m sending text to the TTS service sentence-by-sentence,
    I also have multiple audio files, one per each sentence, which need to be played
    in the correct order. These sound files are then played from another thread, making
    sure audio playback does not block the rest of the program from running.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œé¡¹ç›®çš„æ–‡æœ¬è½¬è¯­éŸ³éƒ¨åˆ†è¢«æ‹†åˆ†ä¸º *ä¸¤ä¸ª* é¢å¤–çš„çº¿ç¨‹ã€‚å½“ä» ChatGPT æ”¶åˆ°å¯¼å¸ˆçš„å“åº”æ—¶ï¼Œæ¯ä¸ªå®Œæ•´çš„å¥å­è¢«ä¼ é€’åˆ°å¦ä¸€ä¸ªçº¿ç¨‹ï¼Œå†ä»é‚£é‡Œå‘é€åˆ°æ–‡æœ¬è½¬è¯­éŸ³æœåŠ¡ï¼Œè½¬æ¢ä¸ºå£°éŸ³æ–‡ä»¶ã€‚æˆ‘æƒ³åœ¨è¿™é‡Œå¼ºè°ƒä¸€ä¸‹
    *æ–‡ä»¶* è¿™ä¸ªè¯â€”â€”ç”±äºæˆ‘å°†æ–‡æœ¬é€å¥å‘é€åˆ° TTS æœåŠ¡ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿæœ‰å¤šä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œæ¯ä¸ªå¥å­ä¸€ä¸ªï¼Œéœ€è¦æŒ‰æ­£ç¡®çš„é¡ºåºæ’­æ”¾ã€‚è¿™äº›å£°éŸ³æ–‡ä»¶ç„¶åä»å¦ä¸€ä¸ªçº¿ç¨‹æ’­æ”¾ï¼Œç¡®ä¿éŸ³é¢‘æ’­æ”¾ä¸ä¼šé˜»å¡ç¨‹åºçš„å…¶ä½™éƒ¨åˆ†è¿è¡Œã€‚
- en: Making all this work, along with several other issues originating from UI-server
    interactions, were *the* complicated part of this project. Surprising, huh â€” software
    engineering is where things get hard.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿æ‰€æœ‰è¿™äº›å·¥ä½œï¼Œä»¥åŠæºäº UI-æœåŠ¡å™¨äº¤äº’çš„å…¶ä»–å‡ ä¸ªé—®é¢˜ï¼Œæ˜¯ *è¿™ä¸ª* é¡¹ç›®ä¸­å¤æ‚çš„éƒ¨åˆ†ã€‚ä»¤äººæƒŠè®¶ï¼Œå¯¹å§â€”â€”è½¯ä»¶å·¥ç¨‹æ‰æ˜¯æœ€éš¾çš„ã€‚
- en: Designing the UI
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®¾è®¡ç”¨æˆ·ç•Œé¢
- en: '![](../Images/f6755d93b567e854ae6f1373a6eec390.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6755d93b567e854ae6f1373a6eec390.png)'
- en: Projectâ€™s UI
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: é¡¹ç›®çš„ç”¨æˆ·ç•Œé¢
- en: 'Well, a UI was something I knew Iâ€™ll need, and I also knew pretty much how
    Iâ€™d like it to look â€” but coding a UI is beyond my knowledge. So I decided to
    try a novel approach: I asked ChatGPT to write my UI for me.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å—¯ï¼Œæˆ‘çŸ¥é“æˆ‘éœ€è¦ä¸€ä¸ªç”¨æˆ·ç•Œé¢ï¼Œæˆ‘ä¹Ÿå¤§è‡´çŸ¥é“æˆ‘å¸Œæœ›å®ƒçœ‹èµ·æ¥æ˜¯ä»€ä¹ˆæ ·çš„â€”â€”ä½†ç¼–å†™ç”¨æˆ·ç•Œé¢è¶…å‡ºäº†æˆ‘çš„çŸ¥è¯†èŒƒå›´ã€‚æ‰€ä»¥æˆ‘å†³å®šå°è¯•ä¸€ç§æ–°æ–¹æ³•ï¼šæˆ‘è®© ChatGPT
    ä¸ºæˆ‘ç¼–å†™ç”¨æˆ·ç•Œé¢ã€‚
- en: 'For this I used the actual ChatGPT service (not the API), and used GPT-4 (yes,
    Iâ€™m a proud paying customer!). Surprisingly, my initial prompt:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä½¿ç”¨äº†å®é™…çš„ ChatGPT æœåŠ¡ï¼ˆè€Œé APIï¼‰ï¼Œå¹¶ä½¿ç”¨äº† GPT-4ï¼ˆæ˜¯çš„ï¼Œæˆ‘æ˜¯ä¸€ä¸ªè‡ªè±ªçš„ä»˜è´¹ç”¨æˆ·ï¼ï¼‰ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘çš„åˆå§‹æç¤ºï¼š
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: delivered an amazing first result, ending up with a Python-Flask backend, jQuery
    code, HTML and matching CSS. But that was only about 80% of all the functionality
    I was hoping to get, so I spent roughly 10 hours going back-and-forth with GPT-4,
    optimizing and upgrading my UI, one request at a time.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: äº¤ä»˜äº†ä¸€ä¸ªæƒŠäººçš„åˆæ­¥ç»“æœï¼Œæœ€ç»ˆå¾—åˆ°äº†ä¸€ä¸ª Python-Flask åç«¯ã€jQuery ä»£ç ã€HTML å’ŒåŒ¹é…çš„ CSSã€‚ä½†è¿™åªæ˜¯æˆ‘å¸Œæœ›è·å¾—çš„æ‰€æœ‰åŠŸèƒ½çš„çº¦
    80%ï¼Œæ‰€ä»¥æˆ‘èŠ±äº†å¤§çº¦ 10 ä¸ªå°æ—¶ä¸ GPT-4 æ¥å›æ²Ÿé€šï¼Œä¸€æ¬¡ä¸€ä¸ªè¯·æ±‚ï¼Œä¼˜åŒ–å’Œå‡çº§æˆ‘çš„ç”¨æˆ·ç•Œé¢ã€‚
- en: 'If I made it look simple,I wonâ€™t to clearly say that it wasnâ€™t. The more requests
    I added, the more GPT-4 got confused and delivered malfunctioning code, which
    at some point was easier to correct manually than asking it to fix it. And I had
    a lot of requests:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘è®©å®ƒçœ‹èµ·æ¥å¾ˆç®€å•ï¼Œæˆ‘æƒ³æ˜ç¡®è¯´æ˜å…¶å®å¹¶éå¦‚æ­¤ã€‚æˆ‘æ·»åŠ çš„è¯·æ±‚è¶Šå¤šï¼ŒGPT-4 å°±è¶Šå›°æƒ‘ï¼Œå¹¶ä¸”äº¤ä»˜çš„ä»£ç å‡ºç°æ•…éšœï¼Œè¿™åœ¨æŸäº›æ—¶å€™æ¯”è®©å®ƒä¿®å¤è¦æ‰‹åŠ¨çº æ­£æ›´å®¹æ˜“ã€‚æˆ‘æœ‰å¾ˆå¤šè¯·æ±‚ï¼š
- en: Add a profile picture next to each message
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æ¯æ¡æ¶ˆæ¯æ—è¾¹æ·»åŠ ä¸€ä¸ªä¸ªäººèµ„æ–™å›¾ç‰‡
- en: Add a button for every message re-playing the its audio
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºæ¯æ¡æ¶ˆæ¯æ·»åŠ ä¸€ä¸ªæŒ‰é’®ï¼Œç”¨äºé‡æ–°æ’­æ”¾å…¶éŸ³é¢‘
- en: Add a button to every French message that will add its translation below the
    original text
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºæ¯æ¡æ³•è¯­æ¶ˆæ¯æ·»åŠ ä¸€ä¸ªæŒ‰é’®ï¼Œå°†å…¶ç¿»è¯‘æ·»åŠ åˆ°åŸå§‹æ–‡æœ¬ä¸‹æ–¹
- en: Add a save-session and a load-session buttons
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ ä¸€ä¸ªä¿å­˜ä¼šè¯å’ŒåŠ è½½ä¼šè¯çš„æŒ‰é’®
- en: Add a dark-mode option, make it choose the right mode automatically
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ ä¸€ä¸ªæš—æ¨¡å¼é€‰é¡¹ï¼Œä½¿å…¶è‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„æ¨¡å¼
- en: Add a â€œworkingâ€ icon whenever a respond from a service is waited for
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ·»åŠ ä¸€ä¸ªâ€œå·¥ä½œä¸­â€å›¾æ ‡ï¼Œä»¥ä¾¿åœ¨ç­‰å¾…æœåŠ¡å“åº”æ—¶æ˜¾ç¤º
- en: And many many moreâ€¦
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿˜æœ‰æ›´å¤šâ€¦â€¦
- en: Still, even though usually GPTâ€™s code never worked out of the box, considering
    the fact I have very little knowledge in the fields of front-end, the results
    are amazing â€” and far beyond anything I could have done myself just by Googling
    and StackOverflowing. Iâ€™ve also made a lot of progress in learning how to craft
    better prompts. Thinking about it, perhaps I should write another blogpost just
    on the lessons-learned from literally building a product from the ground up alongside
    an LLMâ€¦ (*well,* [*I did*](https://shakedzy.medium.com/7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡é€šå¸¸æƒ…å†µä¸‹ GPT çš„ä»£ç æ— æ³•ç›´æ¥è¿è¡Œï¼Œä½†è€ƒè™‘åˆ°æˆ‘åœ¨å‰ç«¯é¢†åŸŸçŸ¥è¯†æœ‰é™ï¼Œç»“æœä»ç„¶ä»¤äººæƒŠå¹â€”â€”è¿œè¿œè¶…å‡ºäº†æˆ‘ä»…å‡­è°·æ­Œæœç´¢å’Œ StackOverflow èƒ½åšåˆ°çš„ä»»ä½•äº‹æƒ…ã€‚æˆ‘åœ¨å­¦ä¹ å¦‚ä½•åˆ¶ä½œæ›´å¥½çš„æç¤ºæ–¹é¢ä¹Ÿå–å¾—äº†å¾ˆå¤§è¿›å±•ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œä¹Ÿè®¸æˆ‘åº”è¯¥å†å†™ä¸€ç¯‡åšå®¢ï¼Œä¸“é—¨è®²è¿°ä»é›¶å¼€å§‹ä¸
    LLM ä¸€èµ·æ„å»ºäº§å“çš„ç»éªŒæ•™è®­â€¦â€¦ï¼ˆ*å—¯ï¼Œ* [*æˆ‘ç¡®å®åšè¿‡*](https://shakedzy.medium.com/7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85)ï¼‰ã€‚
- en: Prompt Engineering
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æç¤ºå·¥ç¨‹
- en: '*For this part of the post, I will assume you have some basic knowledge of
    how communication with a Chat LLM (like ChatGPT) works via API. If you donâ€™t,
    you might get a little lost.*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¯¹äºè¿™éƒ¨åˆ†å†…å®¹ï¼Œæˆ‘å°†å‡è®¾ä½ å¯¹å¦‚ä½•é€šè¿‡ API ä¸èŠå¤© LLMï¼ˆå¦‚ ChatGPTï¼‰è¿›è¡Œé€šä¿¡æœ‰ä¸€äº›åŸºæœ¬äº†è§£ã€‚å¦‚æœæ²¡æœ‰ï¼Œä½ å¯èƒ½ä¼šæœ‰äº›è¿·å¤±ã€‚*'
- en: '![](../Images/c540817f73169cb754ea28c5f3936d12.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c540817f73169cb754ea28c5f3936d12.png)'
- en: Made with Dall-E
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç”± Dall-E åˆ¶ä½œ
- en: Last but most-certainly not least â€” I had to make GPT take the role of a private
    tutor.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä½†ç»å¯¹ä¸æ˜¯æœ€ä¸é‡è¦çš„ â€” æˆ‘è®© GPT æ‰®æ¼”ä¸€ä¸ªç§äººå¯¼å¸ˆçš„è§’è‰²ã€‚
- en: 'As a starting point, I added a *System Prompt* to the beginning of the chat.
    As the chat with an LLM is basically a list of messages sent by the user and the
    bot to each other, a System Prompt is usually the first message of the chat, which
    describes to the bot how it should behave and what is expected of it. Mine looked
    something like this (parameters encapsulated by curly-braces are replaced by run-time
    values):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºèµ·ç‚¹ï¼Œæˆ‘åœ¨èŠå¤©å¼€å§‹æ—¶æ·»åŠ äº†ä¸€ä¸ª *ç³»ç»Ÿæç¤º*ã€‚ç”±äºä¸ LLM çš„èŠå¤©åŸºæœ¬ä¸Šæ˜¯ç”¨æˆ·å’Œæœºå™¨äººç›¸äº’å‘é€çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œç³»ç»Ÿæç¤ºé€šå¸¸æ˜¯èŠå¤©çš„ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œç”¨äºå‘æœºå™¨äººæè¿°å®ƒåº”è¯¥å¦‚ä½•è¡¨ç°ä»¥åŠæœŸæœ›å®ƒåšä»€ä¹ˆã€‚æˆ‘çš„ç³»ç»Ÿæç¤ºçœ‹èµ·æ¥åƒè¿™æ ·ï¼ˆç”±èŠ±æ‹¬å·åŒ…å›´çš„å‚æ•°ä¼šè¢«è¿è¡Œæ—¶å€¼æ›¿ä»£ï¼‰ï¼š
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This was actually yielding pretty good results, but it seemed like the effectiveness
    of the behavioral instructions I gave the bot (â€œcorrect me when Iâ€™m wrongâ€, â€œalways
    respond in Frenchâ€), decayed as the chat went on.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®é™…ä¸Šäº§ç”Ÿäº†ç›¸å½“ä¸é”™çš„ç»“æœï¼Œä½†ä¼¼ä¹éšç€èŠå¤©çš„è¿›è¡Œï¼Œæˆ‘ç»™æœºå™¨äººçš„è¡Œä¸ºæŒ‡ä»¤ï¼ˆâ€œå½“æˆ‘é”™äº†æ—¶çº æ­£æˆ‘â€ï¼Œâ€œå§‹ç»ˆç”¨æ³•è¯­å›åº”â€ï¼‰çš„æœ‰æ•ˆæ€§é€æ¸å‡å¼±ã€‚
- en: 'Trying to fight this vanishing behavior, I came up with an interesting solution;
    I manipulated the user messages before sending them over to GPT. Whatever the
    userâ€™s message was, I added additional text to it:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åº”å¯¹è¿™ç§é€æ¸æ¶ˆå¤±çš„è¡Œä¸ºï¼Œæˆ‘æƒ³å‡ºäº†ä¸€ä¸ªæœ‰è¶£çš„è§£å†³æ–¹æ¡ˆï¼›æˆ‘åœ¨å°†ç”¨æˆ·æ¶ˆæ¯å‘é€ç»™ GPT ä¹‹å‰å¯¹å…¶è¿›è¡Œäº†å¤„ç†ã€‚ä¸è®ºç”¨æˆ·çš„æ¶ˆæ¯æ˜¯ä»€ä¹ˆï¼Œæˆ‘éƒ½ä¼šåœ¨å…¶ä¸­æ·»åŠ é¢å¤–çš„æ–‡æœ¬ï¼š
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Adding these at the end of every userâ€™s message made sure the LLM responds exactly
    the way I wanted it to. It is worth mentioning that the long suffix I added is
    written in English, while the userâ€™s message might not. This is why I added an
    explicit separator between the original message and my addition (the `---`), ending
    the context of the original message and starting a new context. Also note that
    as this suffix is added to the userâ€™s message, it is written in first-person (â€œIâ€,
    â€œmeâ€, etc..). This little trick improved results and behavior dramatically. While
    it might goes without saying, it might be worth emphasizing that this suffix is
    not displayed in the chat UI and the user has no idea it is added to their messages.
    It is inserted behind the scenes, right before being sent with the rest of the
    chat history to ChatGPT.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¯ä¸ªç”¨æˆ·æ¶ˆæ¯çš„æœ«å°¾æ·»åŠ è¿™äº›å†…å®¹ç¡®ä¿äº† LLM æŒ‰ç…§æˆ‘å¸Œæœ›çš„æ–¹å¼å›åº”ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæˆ‘æ·»åŠ çš„é•¿åç¼€æ˜¯ç”¨è‹±è¯­ä¹¦å†™çš„ï¼Œè€Œç”¨æˆ·çš„æ¶ˆæ¯å¯èƒ½ä¸æ˜¯ã€‚å› æ­¤ï¼Œæˆ‘åœ¨åŸå§‹æ¶ˆæ¯å’Œæˆ‘çš„é™„åŠ å†…å®¹ä¹‹é—´æ·»åŠ äº†ä¸€ä¸ªæ˜ç¡®çš„åˆ†éš”ç¬¦ï¼ˆ`---`ï¼‰ï¼Œä»¥ç»“æŸåŸå§‹æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡å¹¶å¼€å§‹æ–°çš„ä¸Šä¸‹æ–‡ã€‚è¿˜è¯·æ³¨æ„ï¼Œç”±äºè¿™ä¸ªåç¼€æ˜¯æ·»åŠ åˆ°ç”¨æˆ·çš„æ¶ˆæ¯ä¸­ï¼Œå› æ­¤æ˜¯ç”¨ç¬¬ä¸€äººç§°ï¼ˆâ€œæˆ‘â€ï¼Œâ€œæˆ‘è‡ªå·±â€ç­‰ï¼‰ä¹¦å†™çš„ã€‚è¿™ä¸ªå°æŠ€å·§æ˜¾è‘—æ”¹å–„äº†ç»“æœå’Œè¡Œä¸ºã€‚è™½ç„¶è¿™å¯èƒ½æ˜¯æ˜¾è€Œæ˜“è§çš„ï¼Œä½†å€¼å¾—å¼ºè°ƒçš„æ˜¯ï¼Œè¿™ä¸ªåç¼€ä¸ä¼šæ˜¾ç¤ºåœ¨èŠå¤©ç•Œé¢ä¸­ï¼Œç”¨æˆ·ä¸çŸ¥é“å®ƒè¢«æ·»åŠ åˆ°ä»–ä»¬çš„æ¶ˆæ¯ä¸­ã€‚å®ƒåœ¨å¹•åæ’å…¥ï¼Œåœ¨ä¸èŠå¤©å†å²è®°å½•ä¸€èµ·å‘é€ç»™
    ChatGPT ä¹‹å‰ã€‚
- en: One more behavior I wanted to have was making the tutor speak first, meaning
    ChatGPT will send the first message as the session begins, without waiting for
    the user to initiate the session. That is, apparently, not something ChatGPT was
    designed to do.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³è¦çš„å¦ä¸€ç§è¡Œä¸ºæ˜¯è®©å¯¼å¸ˆå…ˆå‘è¨€ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼ŒChatGPT å°†åœ¨ä¼šè¯å¼€å§‹æ—¶å‘é€ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œè€Œä¸ç­‰å¾…ç”¨æˆ·å¯åŠ¨ä¼šè¯ã€‚æ˜¾ç„¶ï¼Œè¿™ä¸æ˜¯ ChatGPT è®¾è®¡æ—¶çš„åŠŸèƒ½ã€‚
- en: What I found out when attempting to make ChatGPT reply on a messages-history
    that contained only the System Prompt, is that ChatGPT â€œlost itâ€, and began creating
    a chat with itself, playing both the user and the bot. No matter what I tried,
    I wasnâ€™t able to make it properly initiate the session without the user saying
    something first.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘å°è¯•è®© ChatGPT åœ¨ä»…åŒ…å«ç³»ç»Ÿæç¤ºçš„æ¶ˆæ¯å†å²è®°å½•ä¸­å›å¤æ—¶ï¼Œæˆ‘å‘ç° ChatGPT â€œä¸¢å¤±äº†â€ï¼Œå¼€å§‹ä¸è‡ªå·±è¿›è¡ŒèŠå¤©ï¼Œæ‰®æ¼”ç”¨æˆ·å’Œæœºå™¨äººã€‚ä¸ç®¡æˆ‘å°è¯•ä»€ä¹ˆï¼Œæˆ‘éƒ½æ— æ³•è®©å®ƒåœ¨ç”¨æˆ·å…ˆè¯´è¯ä¹‹å‰æ­£ç¡®å¯åŠ¨ä¼šè¯ã€‚
- en: 'And then I had an idea. When the session initialized, I send ChatGPT the following
    message on behalf of the user:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘æœ‰äº†ä¸€ä¸ªæƒ³æ³•ã€‚å½“ä¼šè¯åˆå§‹åŒ–æ—¶ï¼Œæˆ‘ä»£è¡¨ç”¨æˆ·å‘ ChatGPT å‘é€ä»¥ä¸‹æ¶ˆæ¯ï¼š
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This request was designed to make GPTâ€™s response look exactly how I thought
    a proper initialization of the session by the bot should be like. I then removed
    my message from the chat, and made it seem as if the bot kicked off the session
    by itself.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªè¯·æ±‚æ—¨åœ¨ä½¿ GPT çš„å“åº”çœ‹èµ·æ¥æ­£å¦‚æˆ‘æ‰€è®¤ä¸ºçš„é‚£æ ·ï¼Œåº”è¯¥æ˜¯æœºå™¨äººçš„é€‚å½“ä¼šè¯åˆå§‹åŒ–æ–¹å¼ã€‚ç„¶åæˆ‘ä»èŠå¤©ä¸­åˆ é™¤äº†æˆ‘çš„æ¶ˆæ¯ï¼Œè®©å®ƒçœ‹èµ·æ¥å¥½åƒæ˜¯æœºå™¨äººè‡ªè¡Œå¯åŠ¨äº†ä¼šè¯ã€‚
- en: Summary
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¦‚è¿°
- en: '![](../Images/bccd020fb50ed849a1d0f71945c66286.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bccd020fb50ed849a1d0f71945c66286.png)'
- en: Made with Dall-E, edited
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Dall-E åˆ¶ä½œï¼Œå·²ç¼–è¾‘
- en: What kicked-off as a funny little whim became reality in literally no-time,
    done completely during spare-time of only one quite-busy man. The fact that tasks
    such as these are now so simple to create does not cease to amaze me. Just one
    year ago, having something as ChatGPT available was sci-fi, and now I can shape
    it from my own personal laptop.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸€ä¸ªæœ‰è¶£çš„å°å¿µå¤´å¼€å§‹ï¼Œå‡ ä¹åœ¨ç¬é—´å˜ä¸ºç°å®ï¼Œè¿™å®Œå…¨æ˜¯åœ¨ä¸€ä¸ªéå¸¸å¿™ç¢Œçš„äººç©ºé—²æ—¶é—´ä¸­å®Œæˆçš„ã€‚ä»»åŠ¡å˜å¾—å¦‚æ­¤ç®€å•ï¼Œæˆ‘æ„Ÿåˆ°éå¸¸æƒŠè®¶ã€‚ä»…ä»…ä¸€å¹´å‰ï¼Œåƒ ChatGPT
    è¿™æ ·çš„å·¥å…·è¿˜æ˜¯ç§‘å¹»å°è¯´ä¸­çš„å†…å®¹ï¼Œè€Œç°åœ¨æˆ‘å¯ä»¥åœ¨è‡ªå·±ä¸ªäººçš„ç¬”è®°æœ¬ç”µè„‘ä¸Šè¿›è¡Œå¡‘é€ ã€‚
- en: This is the beginning of the future, and whatever is to come â€” at least I know
    Iâ€™ll be ready for it with one more foreign language. *Au revoir!*
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æœªæ¥çš„å¼€å§‹ï¼Œæ— è®ºæœªæ¥ä¼šå‘ç”Ÿä»€ä¹ˆâ€”â€”è‡³å°‘æˆ‘çŸ¥é“ï¼Œæˆ‘ä¼šç”¨ä¸€ç§æ–°çš„å¤–è¯­åšå¥½å‡†å¤‡ã€‚*å†è§ï¼*
