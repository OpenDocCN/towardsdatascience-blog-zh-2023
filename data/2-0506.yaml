- en: ChatGPT’s energy use per query
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 每次查询的能耗
- en: 原文：[https://towardsdatascience.com/chatgpts-energy-use-per-query-9383b8654487](https://towardsdatascience.com/chatgpts-energy-use-per-query-9383b8654487)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chatgpts-energy-use-per-query-9383b8654487](https://towardsdatascience.com/chatgpts-energy-use-per-query-9383b8654487)
- en: How much electricity does ChatGPT use to answer one question?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT 回答一个问题需要多少电力？
- en: '[](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)[![Kasper
    Groes Albin Ludvigsen](../Images/3c31c9e54fae4fd1c8f1c441379d1f10.png)](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)
    [Kasper Groes Albin Ludvigsen](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)[![Kasper
    Groes Albin Ludvigsen](../Images/3c31c9e54fae4fd1c8f1c441379d1f10.png)](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)
    [Kasper Groes Albin Ludvigsen](https://kaspergroesludvigsen.medium.com/?source=post_page-----9383b8654487--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)
    ·8 min read·Aug 6, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9383b8654487--------------------------------)
    ·阅读时间 8 分钟·2023年8月6日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/de264b7d68d991177b6bf38b6e6e98b0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de264b7d68d991177b6bf38b6e6e98b0.png)'
- en: Photo by Andrey Metelev on Unsplash
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影：Andrey Metelev，来自 Unsplash
- en: This article presents a range within which the electricity consumption per query
    of ChatGPT may fall and compares it to the measured energy consumption of two
    other large language models (LLMs).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示了 ChatGPT 每次查询的电力消耗可能的范围，并与另外两个大型语言模型（LLMs）的测量能耗进行了比较。
- en: 'This is an interesting undertaking for two reasons:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有趣的课题，原因有二：
- en: First of all, if organizations know how much electricity ChatGPT requires to
    answer one question, they can approximate the carbon footprint associated with
    their use of ChatGPT or similar services such as OpenAI’s LLM APIs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果组织知道 ChatGPT 回答一个问题需要多少电力，他们可以估算使用 ChatGPT 或类似服务（如 OpenAI 的 LLM API）的碳足迹。
- en: For more than 50,000 European businesses, this may soon become highly relevant,
    as the coming Corporate Social Responsibility Directive (CSRD) will likely force
    them to disclose scope 3 emissions in their management reports [1]. I expect usage
    of services like ChatGPT to fall under scope 3 because cloud compute is considered
    to be scope 3 [2]. I hope this article can provide inspiration for how to estimate
    your organization’s scope 3 emissions from ChatGPT and similar services.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于超过 50,000 家欧洲企业来说，这可能很快变得非常相关，因为即将出台的《公司社会责任指令》（CSRD）可能迫使它们在管理报告中披露第 3 类排放
    [1]。我预计像 ChatGPT 这样的服务的使用将被归入第 3 类，因为云计算被视为第 3 类 [2]。我希望这篇文章能为如何估算您组织的 ChatGPT
    和类似服务的第 3 类排放提供一些启示。
- en: Another reason why it’s interesting to look into ChatGPT’s energy use per query
    is that it’ll enable individuals to come up with their own estimates of ChatGPT’s
    total electricity consumption or carbon footprint. As such, I hope this blog post
    will inspire others to publish similar work.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个原因是，了解 ChatGPT 每次查询的能耗很有趣，因为这将使个人能够自行估算 ChatGPT 的总电力消耗或碳足迹。因此，我希望这篇博客文章能激励其他人发表类似的研究。
- en: In the remainder of this article, the terms “query” and “request” will be used
    interchangeably.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的其余部分，“查询”和“请求”这两个术语将被交替使用。
- en: '[](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9383b8654487--------------------------------)
    [## Join Medium with my referral link - Kasper Groes Albin Ludvigsen'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9383b8654487--------------------------------)
    [## 通过我的推荐链接加入 Medium - Kasper Groes Albin Ludvigsen'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为 Medium 会员，您的一部分会费将用于支持您阅读的作者，同时您将获得对所有故事的完全访问权限……
- en: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9383b8654487--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: kaspergroesludvigsen.medium.com](https://kaspergroesludvigsen.medium.com/membership?source=post_page-----9383b8654487--------------------------------)
- en: Methodology for estimating ChatGPT’s electricity consumption per query
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 估算ChatGPT每次查询的电力消耗的方法
- en: 'In this section, I’ll present the methodology used to produce estimates of
    ChatGPT’s electricity consumption per query. The estimates rely on two different
    methods:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我将介绍用于估算ChatGPT每次查询电力消耗的方法。估算依赖于两种不同的方法：
- en: One in which we estimate the total energy consumption of the hardware ChatGPT
    presumably is running on and divide by the assumed number of daily queries
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种是估算ChatGPT运行所需的硬件总能耗，并除以假定的每日查询量
- en: One in which we use the reported floating point operations (FLOPS) required
    by GPT-4 to make one forward pass to calculate the energy consumption
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一种方法是使用GPT-4进行一次前向传递所需的浮点运算（FLOPS）来计算能耗
- en: 'Estimating ChatGPT’s electricity consumption per request with method # 1'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用方法#1估算ChatGPT每次请求的电力消耗
- en: 'Below is the formula used to produce estimates of ChatGPT’s electricity consumption
    via method 1\. This formula is a standard way of producing estimates of machine
    learning model energy consumption (see e.g. [3] [4]):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过方法1估算ChatGPT电力消耗的公式。这一公式是机器学习模型能耗估算的标准方法（参见例如 [3] [4]）：
- en: '`Energy consumption per query (KWh) = (Amount of hardware * average hardware
    power draw * TDP * 24 * PUE) / total daily queries`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`每次查询的能耗 (KWh) = (硬件总量 * 平均硬件功耗 * TDP * 24 * PUE) / 每日总查询量`'
- en: 'For method 1, I’ll assume the following values:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于方法1，我将假设以下值：
- en: '*Amount of hardware:* 3,617 Nvidia HGX servers containing a total of 28,936
    Nvidia A100 GPUs as per SemiAnalysis’s estimates of how much compute it took to
    serve ChatGPT’s users when the service was based on the GPT-3.5 LLM [5].'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*硬件总量：* 根据SemiAnalysis对服务ChatGPT用户所需计算量的估算，ChatGPT使用了3,617台Nvidia HGX服务器，包含总共28,936个Nvidia
    A100 GPU，这些估算基于GPT-3.5 LLM时的服务情况 [5]。'
- en: '*Average hardware power draw:* 50 % to 75 %.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*平均硬件功耗：* 50%至75%。'
- en: '*TDP (Thermal Design Power)*: TDP is the maximum theoretical power draw of
    a piece of hardware, but is often used as a proxy for actual maximum hardware
    power draw. I’ll assume a TDP of 6.5 kW as that’s the TDP of the Nvidia DGX A100
    server which is reasonably similar to the Nvidia HGX A100 server.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*TDP（热设计功耗）*：TDP是硬件的最大理论功耗，但通常用作实际最大硬件功耗的替代值。我将假设TDP为6.5 kW，因为Nvidia DGX A100服务器的TDP与Nvidia
    HGX A100服务器相似。'
- en: '*Power usage effectiveness (PUE):* I’ll assume that ChatGPT is deployed to
    Microsoft data centers. Microsoft’s average PUE is 1.18 [6].'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*功耗效率（PUE）：* 我将假设ChatGPT部署在微软的数据中心。微软的平均PUE为1.18 [6]。'
- en: '*Total daily queries:* The estimate of the amount of hardware assumes 13 million
    daily active users, 15 daily queries each, i.e. 195 million daily queries [5].
    It seems like a reasonable estimate and I expect it to increase linearly with
    the amount of users such that if the number of daily queries doubles, so will
    the amount of hardware. Under these assumptions, for the purpose of calculating
    ChatGPT’s energy use per query, it doesn’t matter if ChatGPT currently has fewer
    or more daily queries, as long as it’s reasonably accurate that 195,000,000 daily
    queries require 3,617 Nvidia HGX A100 servers.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*每日查询量：* 硬件总量的估算假设13百万活跃用户，每人每天15次查询，即每日195百万查询 [5]。这似乎是一个合理的估算，我预计它会随着用户数量的增加而线性增长，因此如果每日查询量翻倍，硬件数量也会翻倍。在这些假设下，为了计算ChatGPT每次查询的能耗，ChatGPT当前是否有更多或更少的每日查询并不重要，只要195,000,000次每日查询需要3,617台Nvidia
    HGX A100服务器的估算是合理的。'
- en: 'So the calculation becomes:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所以计算公式变成了：
- en: '`Energy consumption per query (KWh) = (3617 * 6.5 * average hardware power
    draw * 24 * 1.18) / 195,000,000`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`每次查询的能耗 (KWh) = (3617 * 6.5 * 平均硬件功耗 * 24 * 1.18) / 195,000,000`'
- en: where average hardware power draw is 0.5 or 0.75.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，平均硬件功耗为0.5或0.75。
- en: '[](/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800?source=post_page-----9383b8654487--------------------------------)
    [## Environmental Impact of Ubiquitous Generative AI'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800?source=post_page-----9383b8654487--------------------------------)
    [## 普遍生成式人工智能的环境影响'
- en: What could happen to our environment if billions of people began to use generative
    AI technology on a daily basis?
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如果数十亿人开始每天使用生成式人工智能技术，我们的环境会发生什么？
- en: towardsdatascience.com](/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800?source=post_page-----9383b8654487--------------------------------)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/environmental-impact-of-ubiquitous-generative-ai-9e061bac6800?source=post_page-----9383b8654487--------------------------------)'
- en: Estimating ChatGPT’s electricity consumption per request with method 2
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用方法 2 估算 ChatGPT 每次请求的电力消耗
- en: 'Method 2 uses this formula (adapted from Mike Ellis’s approach [7]):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 方法 2 使用以下公式（改编自 Mike Ellis 的方法 [7]）：
- en: '`Energy consumption per query (KWh) = (FLOPS per query * joules per FLOP *
    PUE) / 3600000`'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`每次查询的能量消耗 (KWh) = (每次查询的 FLOPS * 每 FLOP 的焦耳数 * PUE) / 3600000`'
- en: I divide by 3,600,000 to convert from joules to KWh.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我除以 3,600,000 来将焦耳转换为 KWh。
- en: 'For method 2, I’ll assume the following values:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于方法 2，我将假设以下值：
- en: '*FLOPS per query*: 560,000,000,000,000 (560 Teraflops)[8].'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*每次查询的 FLOPS*: 560,000,000,000,000 (560 Teraflops) [8]。'
- en: '*Joules per FLOP*: 0.00000000001 [7].'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*每 FLOP 的焦耳数*: 0.00000000001 [7]。'
- en: '*PUE*: 1.18 (same as for method 1).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*PUE*: 1.18（与方法 1 相同）。'
- en: 'So, the calculation becomes:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，计算公式变为：
- en: '`Energy consumption per query (KWh) = (560000000000000 * 0.00000000001 * 1.18)
    / 3600000`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`每次查询的能量消耗 (KWh) = (560000000000000 * 0.00000000001 * 1.18) / 3600000`'
- en: Now, let’s apply these methods to produce estimates of ChatGPT’s energy use
    per query.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们应用这些方法来估算 ChatGPT 每次查询的能量使用。
- en: '[](/the-carbon-footprint-of-gpt-4-d6c676eb21ae?source=post_page-----9383b8654487--------------------------------)
    [## The carbon footprint of GPT-4'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/the-carbon-footprint-of-gpt-4-d6c676eb21ae?source=post_page-----9383b8654487--------------------------------)
    [## GPT-4 的碳足迹'
- en: Recently leaked data allows us for the first time to estimate the carbon emissions
    from training OpenAI’s GPT-4.
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最近泄露的数据首次允许我们估算训练 OpenAI 的 GPT-4 所产生的碳排放。
- en: towardsdatascience.com](/the-carbon-footprint-of-gpt-4-d6c676eb21ae?source=post_page-----9383b8654487--------------------------------)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/the-carbon-footprint-of-gpt-4-d6c676eb21ae?source=post_page-----9383b8654487--------------------------------)'
- en: Estimates of ChatGPT’s electricity consumption per request
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 每次请求的电力消耗估算
- en: In this section, I’ll present the estimates of how much energy ChatGPT needs
    to answer one request, along with the measured energy consumption per query of
    two other large language models, BLOOM and GPT-J, as reported elsewhere [9][10].
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我将展示 ChatGPT 处理一次请求所需的能量估算值，以及另外两种大型语言模型 BLOOM 和 GPT-J 的每次查询的实际能量消耗，如其他地方所报道
    [9][10]。
- en: In Table 1 below, we can see that method 1 and 2 yield similar estimates of
    ChatGPT’s energy consumption per query. Using method 1, ChatGPT’s estimated energy
    consumption per query is 0.0017 KWh at the lower range (average power draw is
    50 % of TDP) and 0.0026 at the higher range (average power draw is 75 % of TDP).
    Using method 2, ChatGPT’s estimated energy use per request is 0.0018 KWh.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表 1 中，我们可以看到方法 1 和方法 2 对 ChatGPT 每次查询的能量消耗估算值相似。使用方法 1，ChatGPT 每次查询的估算能量消耗为
    0.0017 KWh（低估值范围，平均功耗为 TDP 的 50%）和 0.0026 KWh（高估值范围，平均功耗为 TDP 的 75%）。使用方法 2，ChatGPT
    每次请求的估算能量使用为 0.0018 KWh。
- en: '![](../Images/457c95f9578d6c16bd932f32c9f95a3d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/457c95f9578d6c16bd932f32c9f95a3d.png)'
- en: 'Table 1: ChatGPT’s estimated energy use per query'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: ChatGPT 每次查询的估算能量使用'
- en: Let’s see how the estimates of ChatGPT’s electricty use per query compare to
    the electricty use per query observed for other LLMs. Table 2 below shows the
    energy consumption per query for GPT-J and BLOOM. GPT-J has been measured to consume
    0.196 KWh per query, while BLOOM has been measured to consume 0.0039 KWh per query.
    Notice that BLOOM’s electricity consumption per query is not much larger than
    the estimated electricity consumption per query for ChatGPT, while GPT-J’s energy
    use is noticeably larger.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 ChatGPT 每次查询的电力消耗估算值与其他大型语言模型的电力消耗比较。下表 2 显示了 GPT-J 和 BLOOM 每次查询的能量消耗。GPT-J
    的每次查询电力消耗为 0.196 KWh，而 BLOOM 的每次查询电力消耗为 0.0039 KWh。请注意，BLOOM 每次查询的电力消耗与 ChatGPT
    的估算电力消耗差别不大，而 GPT-J 的能量使用明显更高。
- en: '![](../Images/fdd010187100c940091ef301382584c7.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdd010187100c940091ef301382584c7.png)'
- en: 'Table 2: Comparing the estimated electricity consumption per query for ChatGPT
    to the measured electricity consumption per query for BLOOM and GPT-J reported
    in [9][10]'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 将 ChatGPT 每次查询的估算电力消耗与 BLOOM 和 GPT-J 的每次查询实际电力消耗进行比较，如 [9][10] 中所述'
- en: '[](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9383b8654487--------------------------------)
    [## How to estimate and reduce the carbon footprint of machine learning models'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9383b8654487--------------------------------)
    [## 如何估算和减少机器学习模型的碳足迹'
- en: Two ways to easily estimate the carbon footprint of machine learning models
    and 17 ideas for how you might reduce it
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 两种方法轻松估算机器学习模型的碳足迹，并提供了17个减少碳足迹的想法
- en: towardsdatascience.com](/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9383b8654487--------------------------------)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何估算和减少机器学习模型的碳足迹](https://towardsdatascience.com/how-to-estimate-and-reduce-the-carbon-footprint-of-machine-learning-models-49f24510880?source=post_page-----9383b8654487--------------------------------)'
- en: Discussion
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: Above, we saw that ChatGPT’s electricity consumption per query may be between
    0.0017 and 0.0026 KWh depending on the assumptions we use. We can see that the
    estimated energy use is similar for both method 1 and 2 which to me suggests that
    the estimates are in the right ballpark. The reason method 2 yields an estimate
    that is a bit lower than the upper range of method 1’s estimate could be because
    method 2 only accounts for the energy consumption of the GPUs. However, other
    hardware (CPU, RAM, networking equipment) also consumes energy.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 上述内容中，我们看到ChatGPT每次查询的电力消耗可能在0.0017到0.0026 KWh之间，具体取决于我们使用的假设。我们可以看到，两种方法估算的能量使用量相似，这对我来说表明估算是合理的。方法2的估算稍低于方法1的上限范围，可能是因为方法2仅考虑了GPU的能量消耗。然而，其他硬件（CPU、RAM、网络设备）也消耗能量。
- en: If we believe the estimates by SemiAnalysis [5] to be in the right ballpark,
    then — from my perspective — the main source of uncertainty in the ChatGPT electricity
    consumption estimates are how much electricity each piece of hardware is using.
    In this article I have assumed that each piece of hardware uses 50–75% of its
    maximum power draw, which I personally believe to be reasonable, but please challenge
    this.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们相信SemiAnalysis [5] 的估算是正确的，那么——从我的角度来看——ChatGPT电力消耗估算中的主要不确定来源是每个硬件的电力使用量。在这篇文章中，我假设每个硬件使用其最大功耗的50–75%，我个人认为这是合理的，但请质疑这一点。
- en: Also note that the estimated quantity is the *average* electricity consumption
    of a ChatGPT query because we use Microsoft’s *average* PUE. However, the PUE
    can vary from data center to data cetner. If you’d like to estimate *your* electricity
    consumption from using ChatGPT or similar services, you should use the PUE of
    the data center you expect handles your requests. The MLCO2 Impact calculator
    can show you a list of Microsoft Azure regions [11].
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 还需注意，估算的数量是ChatGPT查询的*平均*电力消耗，因为我们使用了微软的*平均* PUE。然而，PUE在不同的数据中心可能有所不同。如果你想估算使用ChatGPT或类似服务的*你的*电力消耗，应该使用你预期处理请求的数据中心的PUE。MLCO2
    Impact计算器可以向你展示微软Azure地区的列表[11]。
- en: This blog post estimates that ChatGPT’s energy use per request is smaller than
    the measured energy consumption of the LLM called BLOOM. BLOOM is similar in size
    to GPT-3 – the LLM on which ChatGPT was initially based. It would make sense that
    ChatGPT is more energy efficient than BLOOM, because the authors of the BLOOM
    paper did not take any measures to improve the energy efficiency of request processing.
    In addition, it would be reasonable to expect that OpenAI have made such efforts
    since it could reduce their costs.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇博客文章估计了ChatGPT每次请求的能量使用量小于名为BLOOM的LLM的测量能量消耗。BLOOM与GPT-3类似——ChatGPT最初基于的LLM。ChatGPT比BLOOM更节能是有道理的，因为BLOOM论文的作者没有采取任何措施来提高请求处理的能效。此外，考虑到这可能减少他们的成本，合理预期OpenAI会进行这种努力。
- en: The results also show that GPT-J was measured to consume much more electricity
    per query than the other models although at 6 billion parameters, GPT-J is significantly
    smaller than BLOOM (176 billion), GPT-3 (175 billion), and GPT-4 (rumored 1.8
    trillion). A likely explanation for this is that in the reported experiment, GPT-J
    was running on an Nvidia RTX3090 GPU that’s probably less energy efficient than
    the Nvidia A100 on which ChatGPT is likely running. In addition, no measures were
    taken to improve the energy efficiency of GPT-J in the experiment.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 结果还显示，GPT-J每次查询的电力消耗远高于其他模型，尽管GPT-J有60亿个参数，远小于BLOOM（1760亿）、GPT-3（1750亿）和GPT-4（传闻1800亿）。这可能的解释是，在报告的实验中，GPT-J运行在可能不如ChatGPT运行的Nvidia
    A100能效高的Nvidia RTX3090 GPU上。此外，实验中没有采取任何措施来提高GPT-J的能效。
- en: On AI stack exchange [7], Mike Ellis has calculated ChatGPT’s energy consumption
    using method 2 and arrived at 0.000083 KWh per query. In his calculations, he
    uses 30 teraflops, where I in this article use 560 teraflops. Mike Ellis uses
    30 teraflops because ChatGPT itself said that it uses 30 teraflops. But as Mike
    Ellis himself also points out, we should be vary of trusting ChatGPT’s answer
    because it known to hallucinate and provide false information [12]. Using 560
    teraflops as I do here, yields an energy consumption that is closer to the measured
    energy consumption of BLOOM. Combined with the fact that the 560 teraflops figure
    stems from SemiAnalysis, I therefore believe 560 teraflops per query to be more
    realistic.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI堆栈交换[7]中，Mike Ellis使用方法2计算了ChatGPT的能耗，得出每次查询0.000083 KWh。他在计算中使用了30 teraflops，而我在本文中使用了560
    teraflops。Mike Ellis使用30 teraflops是因为ChatGPT自己说它使用30 teraflops。但正如Mike Ellis自己也指出的那样，我们应该对ChatGPT的回答持谨慎态度，因为它被认为会产生幻觉并提供虚假信息[12]。使用560
    teraflops，如我在这里所做的，得出的能耗更接近BLOOM的测量能耗。再加上560 teraflops的数据来自SemiAnalysis，因此我认为每查询560
    teraflops更为现实。
- en: 'Finally, to put ChatGPT’s estimated energy consumption per request into perspective:
    if you turn on a standard 40W light bulb for 1 hour, it will have consumed the
    same amount of energy as 15 to 24 ChatGPT queries as per my estimates.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了将ChatGPT每次请求的估计能耗放入一个大的背景中：如果你打开一个标准的40W灯泡1小时，它将消耗的能量与15到24次ChatGPT查询的能量相当，这也是我的估算。
- en: Conclusion
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This article estimates that ChatGPT may use between 0.0017 and 0.0026 KWh of
    electricity to answer one query. These numbers can be used by organizations to
    approximate their carbon footprint from using ChatGPT and similar services. Two
    different methods were used to obtain these results and both methods yielded estimates
    that are in the same ballpark. These estimates are lower than the measured energy
    consumption of the LLMs BLOOM and GPT-J, which have previously been measured to
    consume 0.0039 and 0.196 KWh per query respectively. According to these estimates
    of ChatGPT’s energy consumption per query, if you turn on a standard 40W light
    bulb for 1 hour, it will have consumed the same amount of energy as 15 to 24 ChatGPT
    queries.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章估算了ChatGPT回答一个查询可能使用0.0017到0.0026 KWh的电量。这些数据可以帮助组织估算使用ChatGPT及类似服务的碳足迹。两种不同的方法得出了相近的结果。这些估算值低于LLMs
    BLOOM和GPT-J的测量能耗，前者为0.0039，后者为0.196 KWh每个查询。根据这些ChatGPT每查询的能耗估算值，如果你打开一个标准的40W灯泡1小时，它将消耗的能量相当于15到24次ChatGPT查询的能量。
- en: That’s it! I hope you enjoyed the story. Let me know what you think!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了！希望你喜欢这个故事。告诉我你的想法吧！
- en: Get the benefits of Medium and support my writing by signing up for a Medium
    membership [HERE](https://kaspergroesludvigsen.medium.com/membership).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过注册Medium会员[HERE](https://kaspergroesludvigsen.medium.com/membership)，你可以享受Medium的福利并支持我的写作。
- en: Follow me for more on AI and sustainability and [subscribe](https://kaspergroesludvigsen.medium.com/subscribe)
    to get my stories via email when I publish.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 关注我，获取更多关于AI和可持续性的内容，并且[订阅](https://kaspergroesludvigsen.medium.com/subscribe)，当我发布新故事时通过电子邮件接收我的更新。
- en: I also sometimes write about [time series forecasting](/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我有时也会写关于[时间序列预测](/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e)的内容。
- en: And feel free to connect on [LinkedIn](https://www.linkedin.com/in/kaspergroesludvigsen).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以在[LinkedIn](https://www.linkedin.com/in/kaspergroesludvigsen)上与我联系。
- en: References
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [https://normative.io/insight/csrd-explained](https://normative.io/insight/csrd-explained/)/'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://normative.io/insight/csrd-explained](https://normative.io/insight/csrd-explained/)/'
- en: '[2] [https://www.bloomberg.com/news/articles/2022-11-17/hidden-emissions-from-cloud-computing-pose-net-zero-threat](https://www.bloomberg.com/news/articles/2022-11-17/hidden-emissions-from-cloud-computing-pose-net-zero-threat)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://www.bloomberg.com/news/articles/2022-11-17/hidden-emissions-from-cloud-computing-pose-net-zero-threat](https://www.bloomberg.com/news/articles/2022-11-17/hidden-emissions-from-cloud-computing-pose-net-zero-threat)'
- en: '[3] [https://arxiv.org/pdf/2307.09288.pdf](https://arxiv.org/pdf/2307.09288.pdf)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://arxiv.org/pdf/2307.09288.pdf](https://arxiv.org/pdf/2307.09288.pdf)'
- en: '[4] [https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf](https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf](https://arxiv.org/ftp/arxiv/papers/2204/2204.05149.pdf)'
- en: '[5] [https://www.semianalysis.com/p/the-inference-cost-of-search-disruption](https://www.semianalysis.com/p/the-inference-cost-of-search-disruption)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [https://www.semianalysis.com/p/the-inference-cost-of-search-disruption](https://www.semianalysis.com/p/the-inference-cost-of-search-disruption)'
- en: '[6] [https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/](https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/](https://azure.microsoft.com/en-us/blog/how-microsoft-measures-datacenter-water-and-energy-use-to-improve-azure-cloud-sustainability/)'
- en: '[7] [https://ai.stackexchange.com/questions/38970/how-much-energy-consumption-is-involved-in-chat-gpt-responses-being-generated/39418?noredirect=1#comment58882_39418](https://ai.stackexchange.com/questions/38970/how-much-energy-consumption-is-involved-in-chat-gpt-responses-being-generated/39418?noredirect=1#comment58882_39418)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [https://ai.stackexchange.com/questions/38970/how-much-energy-consumption-is-involved-in-chat-gpt-responses-being-generated/39418?noredirect=1#comment58882_39418](https://ai.stackexchange.com/questions/38970/how-much-energy-consumption-is-involved-in-chat-gpt-responses-being-generated/39418?noredirect=1#comment58882_39418)'
- en: '[8] [https://archive.md/2RQ8X](https://archive.md/2RQ8X)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [https://archive.md/2RQ8X](https://archive.md/2RQ8X)'
- en: '[9] [https://arxiv.org/abs/2211.02001](https://arxiv.org/abs/2211.02001)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] [https://arxiv.org/abs/2211.02001](https://arxiv.org/abs/2211.02001)'
- en: '[10] [https://borsen.dk/nyheder/baeredygtig/de-har-regnet-paa-chat-gpts-klimaaftryk-nu-raader-de-folk-til-at-taenke-sig-rigtig-godt-om?b_source=topchef-i-sydbank-krigen-i-ukraine-minder-om-finanskrisen&b_medium=row_8&b_campaign=news_2](https://borsen.dk/nyheder/baeredygtig/de-har-regnet-paa-chat-gpts-klimaaftryk-nu-raader-de-folk-til-at-taenke-sig-rigtig-godt-om?b_source=topchef-i-sydbank-krigen-i-ukraine-minder-om-finanskrisen&b_medium=row_8&b_campaign=news_2)
    and BLOOM [https://arxiv.org/abs/2211.02001](https://arxiv.org/abs/2211.0200)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] [https://borsen.dk/nyheder/baeredygtig/de-har-regnet-paa-chat-gpts-klimaaftryk-nu-raader-de-folk-til-at-taenke-sig-rigtig-godt-om?b_source=topchef-i-sydbank-krigen-i-ukraine-minder-om-finanskrisen&b_medium=row_8&b_campaign=news_2](https://borsen.dk/nyheder/baeredygtig/de-har-regnet-paa-chat-gpts-klimaaftryk-nu-raader-de-folk-til-at-taenke-sig-rigtig-godt-om?b_source=topchef-i-sydbank-krigen-i-ukraine-minder-om-finanskrisen&b_medium=row_8&b_campaign=news_2)
    和 BLOOM [https://arxiv.org/abs/2211.02001](https://arxiv.org/abs/2211.02001)'
- en: '[11] [https://mlco2.github.io/impact/](https://mlco2.github.io/impact/)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] [https://mlco2.github.io/impact/](https://mlco2.github.io/impact/)'
- en: '[12] [https://fortune.com/2023/08/01/can-ai-chatgpt-hallucinations-be-fixed-experts-doubt-altman-openai/](https://fortune.com/2023/08/01/can-ai-chatgpt-hallucinations-be-fixed-experts-doubt-altman-openai/)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] [https://fortune.com/2023/08/01/can-ai-chatgpt-hallucinations-be-fixed-experts-doubt-altman-openai/](https://fortune.com/2023/08/01/can-ai-chatgpt-hallucinations-be-fixed-experts-doubt-altman-openai/)'
