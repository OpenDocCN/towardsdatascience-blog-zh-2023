- en: Hands on Otsu Thresholding Algorithm for Image Background Segmentation, using
    Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äº²è‡ªåŠ¨æ‰‹å®ç° Otsu é˜ˆå€¼åˆ†å‰²ç®—æ³•ï¼Œç”¨äºå›¾åƒèƒŒæ™¯åˆ†å‰²ï¼Œä½¿ç”¨ Python
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/hands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2?source=collection_archive---------7-----------------------#2023-03-20](https://towardsdatascience.com/hands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2?source=collection_archive---------7-----------------------#2023-03-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/hands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2?source=collection_archive---------7-----------------------#2023-03-20](https://towardsdatascience.com/hands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2?source=collection_archive---------7-----------------------#2023-03-20)
- en: From theory to practice with the Otsu thresholding algorithm
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»ç†è®ºåˆ°å®è·µï¼Œä½¿ç”¨ Otsu é˜ˆå€¼åˆ†å‰²ç®—æ³•
- en: '[](https://piero-paialunga.medium.com/?source=post_page-----9fa0575ac3d2--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----9fa0575ac3d2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9fa0575ac3d2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9fa0575ac3d2--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----9fa0575ac3d2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://piero-paialunga.medium.com/?source=post_page-----9fa0575ac3d2--------------------------------)[![Piero
    Paialunga](../Images/de2185596a49484698733e85114dd1ff.png)](https://piero-paialunga.medium.com/?source=post_page-----9fa0575ac3d2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9fa0575ac3d2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9fa0575ac3d2--------------------------------)
    [Piero Paialunga](https://piero-paialunga.medium.com/?source=post_page-----9fa0575ac3d2--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F254e653181d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2&user=Piero+Paialunga&userId=254e653181d2&source=post_page-254e653181d2----9fa0575ac3d2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9fa0575ac3d2--------------------------------)
    Â·8 min readÂ·Mar 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9fa0575ac3d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2&user=Piero+Paialunga&userId=254e653181d2&source=-----9fa0575ac3d2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F254e653181d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2&user=Piero+Paialunga&userId=254e653181d2&source=post_page-254e653181d2----9fa0575ac3d2---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9fa0575ac3d2--------------------------------)
    Â·8åˆ†é’Ÿé˜…è¯»Â·2023å¹´3æœˆ20æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9fa0575ac3d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2&user=Piero+Paialunga&userId=254e653181d2&source=-----9fa0575ac3d2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fa0575ac3d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2&source=-----9fa0575ac3d2---------------------bookmark_footer-----------)![](../Images/ec82b49b11dfd1d2e3831de232497bc8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fa0575ac3d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-otsu-thresholding-algorithm-for-image-background-segmentation-using-python-9fa0575ac3d2&source=-----9fa0575ac3d2---------------------bookmark_footer-----------)![](../Images/ec82b49b11dfd1d2e3831de232497bc8.png)'
- en: Photo by [Luke Porter](https://unsplash.com/@lukeporter?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/SZOfKAaQYLI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Luke Porter](https://unsplash.com/@lukeporter?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/photos/SZOfKAaQYLI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: 'Let me start with a very technical concept:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»ä¸€ä¸ªéå¸¸æŠ€æœ¯æ€§çš„æ¦‚å¿µå¼€å§‹ï¼š
- en: An Image will be viewed, treated, analyzed, and processed as a 2D signal.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å›¾åƒå°†è¢«è§†ä½œã€å¤„ç†ã€åˆ†æå’Œå¤„ç†ä¸ºäºŒç»´ä¿¡å·ã€‚
- en: 'And some proper definitions:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥åŠä¸€äº›æ°å½“çš„å®šä¹‰ï¼š
- en: A **signal** is a quantity that changes over space or time and can be used to
    transmit a form of information.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¿¡å·**æ˜¯ä¸€ä¸ªåœ¨ç©ºé—´æˆ–æ—¶é—´ä¸Šå˜åŒ–çš„é‡ï¼Œå¯ç”¨äºä¼ é€’æŸç§ä¿¡æ¯ã€‚'
- en: An **image** is nothing but a quantity of light that hits an optical system,
    that is the camera or the canvas where you are painting it.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å›¾åƒ**æ— éæ˜¯å…‰çº¿ç…§å°„åˆ°å…‰å­¦ç³»ç»Ÿä¸Šï¼Œå³ç›¸æœºæˆ–ä½ æ­£åœ¨ç»˜ç”»çš„ç”»å¸ƒã€‚'
- en: In this sense, an image is nothing but a 2D signal, an electromagnetic signal
    that carries some information that is retrieved by a physical system.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™ä¸ªæ„ä¹‰ä¸Šè¯´ï¼Œå›¾åƒä¸è¿‡æ˜¯ä¸€ä¸ª2Dä¿¡å·ï¼Œä¸€ä¸ªæºå¸¦æŸäº›ä¿¡æ¯çš„ç”µç£ä¿¡å·ï¼Œè¿™äº›ä¿¡æ¯ç”±ç‰©ç†ç³»ç»Ÿè·å–ã€‚
- en: So as we have established that an image is indeed a signal, we can think of
    applying a **signal processing** technique to an **image processing** task. We
    can thus stop discussing **philosophy** and start with the **nerd** part.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ—¢ç„¶æˆ‘ä»¬å·²ç»ç¡®å®šå›¾åƒç¡®å®æ˜¯ä¸€ä¸ªä¿¡å·ï¼Œæˆ‘ä»¬å¯ä»¥è€ƒè™‘å°†**ä¿¡å·å¤„ç†**æŠ€æœ¯åº”ç”¨äº**å›¾åƒå¤„ç†**ä»»åŠ¡ã€‚è¿™æ ·æˆ‘ä»¬å¯ä»¥åœæ­¢è®¨è®º**å“²å­¦**ï¼Œå¼€å§‹è¿›å…¥**æŠ€æœ¯**éƒ¨åˆ†ã€‚
- en: 'Speaking of philosophy. Letâ€™s take this **image**:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¯´åˆ°å“²å­¦ã€‚æˆ‘ä»¬æ¥çœ‹è¿™å¼ **å›¾åƒ**ï¼š
- en: '![](../Images/882ffc2b413c45538c86ed4defa87a06.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/882ffc2b413c45538c86ed4defa87a06.png)'
- en: Photo by [Tingey Injury Law Firm](https://unsplash.com/it/@tingeyinjurylawfirm?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/9SKhDFnw4c4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [Tingey Injury Law Firm](https://unsplash.com/it/@tingeyinjurylawfirm?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    åœ¨ [Unsplash](https://unsplash.com/photos/9SKhDFnw4c4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    æä¾›
- en: 'There is the philosopher in the image doing his job: thinking. And then there
    is this very white background, that we really donâ€™t care about. **Can we get rid
    of it?** Can we get something like that?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ä¸­æœ‰ä½å“²å­¦å®¶åœ¨æ€è€ƒä»–çš„å·¥ä½œã€‚ç„¶åæ˜¯è¿™ä¸ªéå¸¸ç™½çš„èƒŒæ™¯ï¼Œæˆ‘ä»¬å…¶å®å¹¶ä¸åœ¨ä¹ã€‚**æˆ‘ä»¬èƒ½å»æ‰å®ƒå—ï¼Ÿ** æˆ‘ä»¬èƒ½å¾—åˆ°è¿™æ ·çš„ä¸œè¥¿å—ï¼Ÿ
- en: '![](../Images/1d7edaaeca7c602dea43e254b947997a.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d7edaaeca7c602dea43e254b947997a.png)'
- en: Image by author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: If Iâ€™m asking you, it means that we can. ğŸ˜…
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘é—®ä½ ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ã€‚ ğŸ˜…
- en: Every person who knows a little bit of ***photoshop*** can do that, but how
    can you do that automatically and with Python? Again, yes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªäººåªè¦æ‡‚ä¸€ç‚¹***Photoshop***å°±å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†å¦‚ä½•ç”¨Pythonè‡ªåŠ¨å®Œæˆå‘¢ï¼Ÿå†è¯´ä¸€éï¼Œæ˜¯çš„ã€‚
- en: Let me show you how ğŸš€
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ç»™ä½ å±•ç¤ºä¸€ä¸‹ ğŸš€
- en: 0\. The Idea
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 0\. æƒ³æ³•
- en: So letâ€™s take a straightforward case.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬æ‹¿ä¸€ä¸ªç®€å•çš„ä¾‹å­ã€‚
- en: Yep. A small square inside a bigger square. This is an extremely simple case.
    What we want to do is to set all the values in the smaller square to 1 and everything
    that is outside to 0.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡é”™ã€‚ä¸€ä¸ªå°æ–¹å—åœ¨ä¸€ä¸ªå¤§æ–¹å—é‡Œé¢ã€‚è¿™æ˜¯ä¸€ä¸ªæå…¶ç®€å•çš„æƒ…å†µã€‚æˆ‘ä»¬æƒ³åšçš„æ˜¯å°†å°æ–¹å—ä¸­çš„æ‰€æœ‰å€¼è®¾ç½®ä¸º1ï¼Œè€Œå¤–é¢çš„æ‰€æœ‰å€¼è®¾ç½®ä¸º0ã€‚
- en: 'We can extract the two values with this code:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç æå–ä¸¤ä¸ªå€¼ï¼š
- en: 'And then do something like:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååšä¸€äº›ç±»ä¼¼äºï¼š
- en: This converts the image from two values to 1 and 0.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†å›¾åƒä»ä¸¤ä¸ªå€¼è½¬æ¢ä¸º1å’Œ0ã€‚
- en: This is extremely simple, right? Letâ€™s make it a little bit harder.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™éå¸¸ç®€å•ï¼Œå¯¹å§ï¼Ÿè®©æˆ‘ä»¬æŠŠå®ƒå˜å¾—æœ‰äº›å¤æ‚ã€‚
- en: Now we will do the little square inside the bigger square **but both the squares
    have some noise.**
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å°†åšçš„æ˜¯åœ¨å¤§æ–¹å—å†…çš„å°æ–¹å—**ä½†ä¸¤ä¸ªæ–¹å—éƒ½æœ‰ä¸€äº›å™ªå£°ã€‚**
- en: What I mean is that we donâ€™t have only 2 values but we can theoretically have
    **all the values between 0 and 255** which is the whole range of values in the
    encoding.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çš„æ„æ€æ˜¯ï¼Œæˆ‘ä»¬ä¸ä»…ä»…æœ‰2ä¸ªå€¼ï¼Œè€Œæ˜¯ç†è®ºä¸Šå¯ä»¥æœ‰**ä»0åˆ°255ä¹‹é—´çš„æ‰€æœ‰å€¼**ï¼Œè¿™å°±æ˜¯ç¼–ç ä¸­çš„æ•´ä¸ªå€¼èŒƒå›´ã€‚
- en: How do we deal with this?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Ÿ
- en: Well, the first thing we want to do is to **flatten** the image (2D signal)
    and change it into a 1D one.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæˆ‘ä»¬é¦–å…ˆè¦åšçš„æ˜¯**æ‰å¹³åŒ–**å›¾åƒï¼ˆ2Dä¿¡å·ï¼‰ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º1Då›¾åƒã€‚
- en: '![](../Images/132122519b5885a6e93186b7916ec191.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/132122519b5885a6e93186b7916ec191.png)'
- en: Image by author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: The image was a 50x50 image and we have a â€œraveledâ€ 50x50=2500 long 1D signal.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒæ˜¯50x50çš„ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªâ€œå±•å¼€â€çš„50x50=2500é•¿åº¦çš„1Dä¿¡å·ã€‚
- en: 'Now if we study the distribution of our 1D Signal we got something like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å¦‚æœæˆ‘ä»¬ç ”ç©¶1Dä¿¡å·çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¾—åˆ°è¿™æ ·çš„ä¸œè¥¿ï¼š
- en: '![](../Images/5cc87aec378dd846951541988b138150.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cc87aec378dd846951541988b138150.png)'
- en: As we can see, we have **two normal distributions**. This is **exactly** where
    the Otsu algorithm performs best. The underlying idea is that the **background**
    and the **subject** of the image have two different natures and two different
    **domains**. For example, in this case, the first gaussian bell is the one related
    to the background (letâ€™s say from 0 to 50), while the second Gaussian bell is
    the one of the smaller square (from 150 to 250).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæˆ‘ä»¬æœ‰ **ä¸¤ä¸ªæ­£æ€åˆ†å¸ƒ**ã€‚è¿™æ­£æ˜¯ Otsu ç®—æ³•è¡¨ç°æœ€ä½³çš„åœ°æ–¹ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯ **èƒŒæ™¯** å’Œ **å›¾åƒä¸­çš„ä¸»ä½“** å…·æœ‰ä¸¤ç§ä¸åŒçš„æ€§è´¨å’Œä¸¤ä¸ªä¸åŒçš„
    **é¢†åŸŸ**ã€‚ä¾‹å¦‚ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç¬¬ä¸€ä¸ªé«˜æ–¯é’Ÿå½¢æ›²çº¿ä¸èƒŒæ™¯ç›¸å…³ï¼ˆä» 0 åˆ° 50ï¼‰ï¼Œè€Œç¬¬äºŒä¸ªé«˜æ–¯é’Ÿå½¢æ›²çº¿åˆ™ä¸è¾ƒå°çš„æ–¹å—ç›¸å…³ï¼ˆä» 150 åˆ° 250ï¼‰ã€‚
- en: 'So letâ€™s say that we decide that we set everything that is larger than 100
    as 1 and everything that is smaller as 0:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬å†³å®šå°†æ‰€æœ‰å¤§äº 100 çš„å€¼è®¾ä¸º 1ï¼Œå°†æ‰€æœ‰å°äº 100 çš„å€¼è®¾ä¸º 0ï¼š
- en: And the result is the following mask between the **background** and the **subject:**
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœæ˜¯ä»¥ä¸‹ **èƒŒæ™¯** å’Œ **ä¸»ä½“** ä¹‹é—´çš„æ©ç ï¼š
- en: 'This is it. This is the whole idea of the Otsu algorithm:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å°±æ˜¯è¿™æ ·ã€‚è¿™å°±æ˜¯ Otsu ç®—æ³•çš„æ•´ä¸ªæ€è·¯ï¼š
- en: '**Import/Read** the image as a 2D signal'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¯¼å…¥/è¯»å–**å›¾åƒä½œä¸º 2D ä¿¡å·'
- en: '**Flatten** the image into a 1D vector'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å°†**å›¾åƒå±•å¹³ä¸º 1D å‘é‡'
- en: Choose a **threshold**
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä¸€ä¸ª **é˜ˆå€¼**
- en: '**Set** everything that is below that threshold as 0 and everything that is
    above as 1'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å°†**ä½äºè¯¥é˜ˆå€¼çš„æ‰€æœ‰å†…å®¹è®¾ä¸º 0ï¼Œå°†é«˜äºè¯¥é˜ˆå€¼çš„æ‰€æœ‰å†…å®¹è®¾ä¸º 1'
- en: Very easy right?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆç®€å•ï¼Œå¯¹å§ï¼Ÿ
- en: But how do we choose the proper threshold? What is the best one? Letâ€™s talk
    about **math**.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•é€‰æ‹©åˆé€‚çš„é˜ˆå€¼å‘¢ï¼Ÿæœ€ä½³é˜ˆå€¼æ˜¯ä»€ä¹ˆï¼Ÿè®©æˆ‘ä»¬è°ˆè°ˆ **æ•°å­¦**ã€‚
- en: 1\. Theoretical Introduction
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. ç†è®ºä»‹ç»
- en: Letâ€™s formalize this concept a little bit.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç¨å¾®å½¢å¼åŒ–ä¸€ä¸‹è¿™ä¸ªæ¦‚å¿µã€‚
- en: We have a **domain** of pixels in an image. The full domain goes from 0 to 255
    (white to black) but it doesnâ€™t have to be that wide (it can be from 20 to 200
    for example).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰ä¸€ä¸ªå›¾åƒçš„ **é¢†åŸŸ**ã€‚æ•´ä¸ªé¢†åŸŸä» 0 åˆ° 255ï¼ˆç™½åˆ°é»‘ï¼‰ï¼Œä½†å®ƒä¸å¿…é‚£ä¹ˆå®½ï¼ˆä¾‹å¦‚å¯ä»¥æ˜¯ 20 åˆ° 200ï¼‰ã€‚
- en: Now, multiple points can have the same pixel intensity of course (we can have
    two black pixels in the same image). Letâ€™s say that we have 3 pixels with an intensity
    of 255 in an image that has 100 pixels. Now the probability of having intensity
    255 in that image is 3/100.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œå¤šä¸ªç‚¹å¯ä»¥å…·æœ‰ç›¸åŒçš„åƒç´ å¼ºåº¦ï¼ˆæˆ‘ä»¬å¯ä»¥åœ¨åŒä¸€å›¾åƒä¸­æœ‰ä¸¤ä¸ªé»‘è‰²åƒç´ ï¼‰ã€‚å‡è®¾æˆ‘ä»¬æœ‰ 3 ä¸ªå¼ºåº¦ä¸º 255 çš„åƒç´ ï¼Œåœ¨ä¸€ä¸ªæœ‰ 100 ä¸ªåƒç´ çš„å›¾åƒä¸­ã€‚é‚£ä¹ˆåœ¨è¯¥å›¾åƒä¸­å¼ºåº¦ä¸º
    255 çš„æ¦‚ç‡æ˜¯ 3/100ã€‚
- en: 'In general, we can say that the probability of having pixel i in an image is:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è¯´å›¾åƒä¸­åƒç´  i çš„æ¦‚ç‡æ˜¯ï¼š
- en: '![](../Images/b879d59f443db2c1db2239ab874f99c1.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b879d59f443db2c1db2239ab874f99c1.png)'
- en: Image by author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Now letâ€™s say that the pixel on which we are doing the split is pixel k (in
    our previous example k was 100). This **classifies** the data points. All the
    points **before k belong to class 0** and all the points **after k belong to class
    1.**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å‡è®¾æˆ‘ä»¬è¿›è¡Œåˆ†å‰²çš„åƒç´ æ˜¯åƒç´  kï¼ˆåœ¨æˆ‘ä»¬ä¹‹å‰çš„ç¤ºä¾‹ä¸­ï¼Œk æ˜¯ 100ï¼‰ã€‚è¿™ **åˆ†ç±»** äº†æ•°æ®ç‚¹ã€‚æ‰€æœ‰ **k ä¹‹å‰çš„ç‚¹å±äºç±»åˆ« 0**ï¼Œæ‰€æœ‰ **k
    ä¹‹åçš„ç‚¹å±äºç±»åˆ« 1**ã€‚
- en: 'This means that the probability of picking a point from class 0 is the following:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€ä»ç±»åˆ« 0 ä¸­é€‰æ‹©ä¸€ä¸ªç‚¹çš„æ¦‚ç‡å¦‚ä¸‹ï¼š
- en: '![](../Images/269e994475d0e500da0c16f16cfdf65c.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/269e994475d0e500da0c16f16cfdf65c.png)'
- en: Image by author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'While the probability of picking a point from class 1 is the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è€Œä»ç±»åˆ« 1 ä¸­é€‰æ‹©ä¸€ä¸ªç‚¹çš„æ¦‚ç‡å¦‚ä¸‹ï¼š
- en: '![](../Images/baee39159ae78f3af2735c3fac1c14e7.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/baee39159ae78f3af2735c3fac1c14e7.png)'
- en: Image by author
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: As we can see, both probabilities are obviously dependent on k.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¿™ä¸¤ä¸ªæ¦‚ç‡æ˜¾ç„¶ä¾èµ–äº kã€‚
- en: Now, another thing that we can compute is the **variance for each class:**
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ **æ–¹å·®ï¼š**
- en: '![](../Images/51c36a80173951098f5a0dd8a5fc42cb.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51c36a80173951098f5a0dd8a5fc42cb.png)'
- en: Image by author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: '![](../Images/e1009db6a01810f246e1c6387e0956da.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1009db6a01810f246e1c6387e0956da.png)'
- en: Image by author
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'Where:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼š
- en: '![](../Images/72e0b9a5bc808a383db17f593aaba2ec.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72e0b9a5bc808a383db17f593aaba2ec.png)'
- en: Image by author
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: And
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œ
- en: '![](../Images/6383eb59617b9e87ddd063a1f0ebd8dd.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6383eb59617b9e87ddd063a1f0ebd8dd.png)'
- en: Image by author
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: The sigma value is the **variance** of each class aka how much the class is
    **spread** around the mean values that are mu_0 and mu_1.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: sigma å€¼æ˜¯æ¯ä¸ªç±»åˆ«çš„ **æ–¹å·®**ï¼Œå³è¯¥ç±»åˆ«åœ¨å‡å€¼ mu_0 å’Œ mu_1 å‘¨å›´çš„ **æ‰©æ•£** ç¨‹åº¦ã€‚
- en: 'Now theoretically the idea is to find the value that creates that little **valley**
    that we saw in this picture earlier:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç†è®ºä¸Šè®²ï¼Œç›®çš„æ˜¯æ‰¾åˆ°ä¸€ä¸ªå€¼ï¼Œè¿™ä¸ªå€¼å½¢æˆäº†æˆ‘ä»¬ä¹‹å‰åœ¨å›¾ç‰‡ä¸­çœ‹åˆ°çš„å° **å‡¹è°·**ï¼š
- en: '![](../Images/5cc87aec378dd846951541988b138150.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cc87aec378dd846951541988b138150.png)'
- en: But the approach that we use is slightly different and more rigorous. By using
    the same idea of the [Linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis#Fisher's_linear_discriminant)
    (LDA). In the (Fisher) LDA we want to find a hyperplane that splits the two distributions
    in a way that the variance **between** classes is as big as possible (so that
    the two means are the furthest away from each other) and the variance **within**
    the classes is as small as possible (so that we donâ€™t have too much overlap between
    the two classes data points).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æˆ‘ä»¬ä½¿ç”¨çš„æ–¹æ³•ç¨æœ‰ä¸åŒä¸”æ›´ä¸ºä¸¥æ ¼ã€‚é€šè¿‡ä½¿ç”¨[çº¿æ€§åˆ¤åˆ«åˆ†æ](https://en.wikipedia.org/wiki/Linear_discriminant_analysis#Fisher's_linear_discriminant)ï¼ˆLDAï¼‰çš„ç›¸åŒæ€è·¯ã€‚åœ¨ï¼ˆFisherï¼‰LDAä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä¸€ä¸ªè¶…å¹³é¢ï¼Œå°†ä¸¤ä¸ªåˆ†å¸ƒåˆ†å¼€ï¼Œä½¿å¾—ç±»åˆ«**ä¹‹é—´**çš„æ–¹å·®å°½å¯èƒ½å¤§ï¼ˆè¿™æ ·ä¸¤ä¸ªå‡å€¼ä¹‹é—´çš„è·ç¦»å°½å¯èƒ½è¿œï¼‰ï¼Œè€Œç±»åˆ«**å†…éƒ¨**çš„æ–¹å·®å°½å¯èƒ½å°ï¼ˆè¿™æ ·ä¸¤ä¸ªç±»åˆ«æ•°æ®ç‚¹ä¹‹é—´çš„é‡å æœ€å°‘ï¼‰ã€‚
- en: In this case, we donâ€™t have any hyperplane and the threshold that we set (our
    k) is not even a line, but it is more of a probability value that we use to discriminate
    data points and classify them.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ²¡æœ‰ä»»ä½•è¶…å¹³é¢ï¼Œæˆ‘ä»¬è®¾ç½®çš„é˜ˆå€¼ï¼ˆæˆ‘ä»¬çš„kï¼‰ç”šè‡³ä¸æ˜¯ä¸€æ¡çº¿ï¼Œè€Œæ›´åƒæ˜¯ä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œç”¨äºåŒºåˆ†æ•°æ®ç‚¹å¹¶å¯¹å…¶è¿›è¡Œåˆ†ç±»ã€‚
- en: 'It can be proven (full proof here in the original [paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4310076))
    that the **best split** between the **background** and **subject** (is given the
    assumption that the domain of the background is different from the domain of the
    subject) is obtained by minimizing this quantity:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥è¯æ˜ï¼ˆå®Œæ•´è¯æ˜è§åŸå§‹[è®ºæ–‡](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4310076)ï¼‰ï¼Œ**æœ€ä½³åˆ†å‰²**åœ¨**èƒŒæ™¯**å’Œ**ä¸»ä½“**ä¹‹é—´ï¼ˆå‡è®¾èƒŒæ™¯çš„åŸŸä¸ä¸»ä½“çš„åŸŸä¸åŒï¼‰æ˜¯é€šè¿‡æœ€å°åŒ–è¯¥æ•°é‡æ¥è·å¾—çš„ï¼š
- en: '![](../Images/201fa4937a409c6adc3af5410dcfd0db.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/201fa4937a409c6adc3af5410dcfd0db.png)'
- en: Image by author
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: This means that we can try all different ks and just pick the one with the lowest
    k.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å°è¯•æ‰€æœ‰ä¸åŒçš„kï¼Œå¹¶é€‰æ‹©å…¶ä¸­æœ€å°çš„kã€‚
- en: 2\. Hands On implementation
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. å®è·µæ“ä½œ
- en: 'The theory might look complex and difficult to understand, but the implementation
    is extremely easy and it is made of three blocks:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è®ºå¯èƒ½çœ‹èµ·æ¥å¤æ‚ä¸”éš¾ä»¥ç†è§£ï¼Œä½†å®ç°èµ·æ¥éå¸¸ç®€å•ï¼Œç”±ä¸‰ä¸ªå—ç»„æˆï¼š
- en: 2.1 Importing the libraries
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 å¯¼å…¥åº“
- en: The first thing that we want to do is to import 4 basic libraries that we will
    need.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆéœ€è¦å¯¼å…¥4ä¸ªåŸºæœ¬åº“ã€‚
- en: 2.2 The threshold function
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 é˜ˆå€¼å‡½æ•°
- en: 'Once you find the perfect threshold, this is how to apply it to your image:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‰¾åˆ°å®Œç¾çš„é˜ˆå€¼ï¼Œè¿™å°±æ˜¯å¦‚ä½•å°†å…¶åº”ç”¨åˆ°æ‚¨çš„å›¾åƒä¸­ï¼š
- en: 2.3 The Otsu criterion
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 Otsuå‡†åˆ™
- en: 'The function that will compute this quantity:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è®¡ç®—è¯¥æ•°é‡çš„å‡½æ•°ï¼š
- en: '![](../Images/201fa4937a409c6adc3af5410dcfd0db.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/201fa4937a409c6adc3af5410dcfd0db.png)'
- en: Image by author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç‰‡
- en: 'Is the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯ä»¥ä¸‹å†…å®¹ï¼š
- en: 2.4 Best threshold computation
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 æœ€ä½³é˜ˆå€¼è®¡ç®—
- en: 'This other function just runs all over the possible ks and finds the best one
    according to the criterion above:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªå‡½æ•°ä¼šéå†æ‰€æœ‰å¯èƒ½çš„kï¼Œå¹¶æ ¹æ®ä¸Šè¿°å‡†åˆ™æ‰¾åˆ°æœ€ä½³å€¼ã€‚
- en: 2.5 The whole process
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 æ•´ä¸ªè¿‡ç¨‹
- en: 'So the image we are using is the following one:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨çš„å›¾åƒæ˜¯ä»¥ä¸‹è¿™ä¸ªï¼š
- en: '![](../Images/bb682b7a3df65e2c7a6a3ed1ad6619aa.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb682b7a3df65e2c7a6a3ed1ad6619aa.png)'
- en: Photo by [Ben Dumond](https://unsplash.com/@bendumond?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/VedK8_UlmkY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±[Ben Dumond](https://unsplash.com/@bendumond?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æ‹æ‘„çš„ç…§ç‰‡ï¼Œæ¥æºäº[Unsplash](https://unsplash.com/photos/VedK8_UlmkY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: 'If we save that image in a path and we apply the Otsu algorithm we get:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å°†è¯¥å›¾åƒä¿å­˜åœ¨è·¯å¾„ä¸­å¹¶åº”ç”¨Otsuç®—æ³•ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
- en: 'And if we compare im (the original image) and im_otsu (the one after the algorithm)
    we get:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æ¯”è¾ƒimï¼ˆåŸå§‹å›¾åƒï¼‰å’Œim_otsuï¼ˆç®—æ³•å¤„ç†åçš„å›¾åƒï¼‰ï¼Œæˆ‘ä»¬å¾—åˆ°ï¼š
- en: As we can see, the black part of the right upper part of the picture is misinterpreted
    as the subject because it has the same tone as some of the subjects. People are
    not perfect and neither are the algorithms ğŸ™ƒ
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œå›¾åƒå³ä¸Šéƒ¨åˆ†çš„é»‘è‰²åŒºåŸŸè¢«è¯¯è§£ä¸ºä¸»ä½“ï¼Œå› ä¸ºå®ƒä¸ä¸€äº›ä¸»ä½“æœ‰ç›¸åŒçš„è‰²è°ƒã€‚äººä»¬ä¸å®Œç¾ï¼Œç®—æ³•ä¹Ÿä¸€æ ·ğŸ™ƒ
- en: 3\. Wrapping it up
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. æ€»ç»“
- en: Thank you for being here with me throughout the whole path of this Otsu algorithm
    tutorial.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢æ‚¨åœ¨æ•´ä¸ªOtsuç®—æ³•æ•™ç¨‹ä¸­ä¸æˆ‘åŒè¡Œã€‚
- en: 'In this brief article, we saw:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡ç®€çŸ­çš„æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°ï¼š
- en: That an **Image** can be treated as a **2D signal** and can then be analyzed
    using Signal Processing technique
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å›¾åƒ**å¯ä»¥è¢«è§†ä¸º**äºŒç»´ä¿¡å·**ï¼Œç„¶åå¯ä»¥ä½¿ç”¨ä¿¡å·å¤„ç†æŠ€æœ¯è¿›è¡Œåˆ†æ'
- en: The assumption of the **Otsu algorithm,** that is the **background** and the
    **subject** of an image have two, continuous, non-overlapping, distinguished domains
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Otsuç®—æ³•**çš„å‡è®¾æ˜¯å›¾åƒçš„**èƒŒæ™¯**å’Œ**ä¸»ä½“**å…·æœ‰ä¸¤ä¸ªè¿ç»­çš„ã€äº’ä¸é‡å çš„ã€æ˜ç¡®åŒºåˆ†çš„é¢†åŸŸã€‚'
- en: How to find the **best** discrimination between the background and subject of
    an image given the Otsu algorithm. How we can interpret the Otsu algorithm as
    a Fisher Linear Discriminant.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•åœ¨ç»™å®šOtsuç®—æ³•çš„æƒ…å†µä¸‹æ‰¾åˆ°å›¾åƒçš„**æœ€ä½³**èƒŒæ™¯å’Œä¸»ä½“çš„åŒºåˆ†ã€‚æˆ‘ä»¬å¦‚ä½•å°†Otsuç®—æ³•è§£é‡Šä¸ºFisherçº¿æ€§åˆ¤åˆ«ã€‚
- en: How to implement the Otsu algorithm using **Python**
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ç”¨**Python**å®ç°Otsuç®—æ³•ã€‚
- en: How to **apply** this algorithm in a real **image**
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•åœ¨å®é™…**å›¾åƒ**ä¸­**åº”ç”¨**æ­¤ç®—æ³•ã€‚
- en: 4\. Conclusions
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. ç»“è®º
- en: 'If you liked the article and you want to know more about machine learning,
    or you just want to ask me something, you can:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œæƒ³äº†è§£æ›´å¤šå…³äºæœºå™¨å­¦ä¹ çš„å†…å®¹ï¼Œæˆ–åªæ˜¯æƒ³é—®æˆ‘ä¸€äº›é—®é¢˜ï¼Œä½ å¯ä»¥ï¼š
- en: A. Follow me on [**Linkedin**](https://www.linkedin.com/in/pieropaialunga/),
    where I publish all my stories
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: A. åœ¨[**Linkedin**](https://www.linkedin.com/in/pieropaialunga/)ä¸Šå…³æ³¨æˆ‘ï¼Œæˆ‘ä¼šåœ¨ä¸Šé¢å‘å¸ƒæˆ‘çš„æ‰€æœ‰æ•…äº‹ã€‚
- en: B. Subscribe to my [**newsletter**](https://piero-paialunga.medium.com/subscribe).
    It will keep you updated about new stories and give you the chance to text me
    to receive all the corrections or doubts you may have.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: B. è®¢é˜…æˆ‘çš„[**æ–°é—»é€šè®¯**](https://piero-paialunga.medium.com/subscribe)ã€‚å®ƒå°†è®©ä½ äº†è§£æœ€æ–°æ•…äº‹ï¼Œå¹¶ç»™ä½ æœºä¼šé€šè¿‡çŸ­ä¿¡ä¸æˆ‘è”ç³»ï¼Œè·å–æ‰€æœ‰çš„æ›´æ­£æˆ–è§£ç­”ä½ å¯èƒ½æœ‰çš„ç–‘é—®ã€‚
- en: C. Become a [**referred member**](https://piero-paialunga.medium.com/membership),
    so you wonâ€™t have any â€œmaximum number of stories for the monthâ€ and you can read
    whatever I (and thousands of other Machine Learning and Data Science top writers)
    write about the newest technology available.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: C. æˆä¸º[**ä¼šå‘˜**](https://piero-paialunga.medium.com/membership)ï¼Œè¿™æ ·ä½ å°±ä¸ä¼šæœ‰â€œæ¯æœˆæ•…äº‹æ•°é‡ä¸Šé™â€çš„é™åˆ¶ï¼Œå¯ä»¥é˜…è¯»æˆ‘ï¼ˆä»¥åŠæˆåƒä¸Šä¸‡çš„å…¶ä»–æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦é¡¶çº§ä½œå®¶ï¼‰å…³äºæœ€æ–°æŠ€æœ¯çš„æ–‡ç« ã€‚
