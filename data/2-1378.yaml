- en: Java and Data Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Java和数据工程
- en: 原文：[https://towardsdatascience.com/java-and-data-engineering-f0e0a145cb52](https://towardsdatascience.com/java-and-data-engineering-f0e0a145cb52)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/java-and-data-engineering-f0e0a145cb52](https://towardsdatascience.com/java-and-data-engineering-f0e0a145cb52)
- en: DATA ENGINEERING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据工程
- en: 'Java Juggernaut: The key to data engineering mastery'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Java Juggernaut: 数据工程掌握的关键'
- en: '[](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)[![Naser
    Tamimi](../Images/8d43c66ea3c0ef9b49c7d33dbc008c28.png)](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)
    [Naser Tamimi](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)[![Naser
    Tamimi](../Images/8d43c66ea3c0ef9b49c7d33dbc008c28.png)](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)
    [Naser Tamimi](https://tamimi-naser.medium.com/?source=post_page-----f0e0a145cb52--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)
    ·4 min read·Nov 11, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0e0a145cb52--------------------------------)
    ·阅读时间4分钟·2023年11月11日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/beb492e0841f67c958a6cbd9ba1cd4b5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/beb492e0841f67c958a6cbd9ba1cd4b5.png)'
- en: Photo by [Zhen H](https://unsplash.com/@zhenh2424?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Zhen H](https://unsplash.com/@zhenh2424?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Data Engineering and Programming Skills
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据工程和编程技能
- en: When we think about data engineering, the first programming skills that usually
    come to mind are SQL and maybe Python. SQL is this well-known language for querying
    data, deeply ingrained in the world of data and pipelines. Python, on the other
    hand, has become quite powerful in data science and is now making its mark in
    the evolving field of data engineering. But, is this common belief accurate? Are
    SQL and Python really the most important programming skills for Data Engineers?
    In this article, I’ll share my experiences on this topic, aiming to help young
    professionals figure out the best skills to make the most of their time and energy.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想到数据工程时，首先想到的编程技能通常是SQL和Python。SQL是一种用于查询数据的著名语言，深深根植于数据和管道的世界。另一方面，Python在数据科学中变得相当强大，并且现在在不断发展的数据工程领域中也开始展现其影响力。但是，这种普遍的看法是否准确？SQL和Python真的就是数据工程师最重要的编程技能吗？在本文中，我将分享我在这一领域的经验，旨在帮助年轻专业人士找出最佳技能，以充分利用他们的时间和精力。
- en: Why Java and Scala?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择Java和Scala？
- en: In today’s data engineering, we handle a massive amount of data. The main job
    is figuring out how to gather, change, and store this huge load of data every
    day, hour, or even in real-time. What makes it trickier is making sure different
    data services can smoothly run on various systems without worrying about what’s
    happening underneath.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的数据工程中，我们处理大量的数据。主要的工作是搞清楚如何每天、每小时甚至实时地收集、改变和存储这些海量数据。更棘手的是，要确保不同的数据服务能够在各种系统上顺利运行，而不用担心底层发生了什么。
- en: In the last 15 years, smart folks have come up with distributed computing frameworks
    to deal with this data overload. Hadoop and Spark are two big names in this game.
    Because both these frameworks are mainly built using JVM (Java Virtual Machine)
    languages (Hadoop uses Java, and Spark uses Scala), many data and software experts
    believe that Java and Scala are the way forward in data engineering.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的15年里，聪明的人们提出了分布式计算框架来应对数据过载问题。Hadoop和Spark是这个领域的两个大名鼎鼎的名字。由于这两个框架主要使用JVM（Java虚拟机）语言构建（Hadoop使用Java，而Spark使用Scala），许多数据和软件专家认为Java和Scala是数据工程的未来方向。
- en: Moreover, the ability of JVM applications to be portable makes them an excellent
    choice for data applications operating across diverse systems and environments.
    You can develop data pipelines that seamlessly run on various cloud and local
    setups, allowing you to scale your systems up or down without concerns about the
    underlying infrastructure.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，JVM应用程序的可移植性使它们成为跨各种系统和环境操作的数据应用的优秀选择。你可以开发无缝运行于各种云端和本地环境的数据管道，从而可以在不担心底层基础设施的情况下，按需扩展系统。
- en: How does a data pipeline look like in a JVM-based applications?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在基于JVM的应用程序中，数据管道是什么样的？
- en: 'Now that we’ve explored the benefits of Java and Scala, or more broadly, JVM-based
    data applications, in handling big data, the next logical question is: what do
    these applications, or simply data pipelines, look like? This section aims to
    provide an overview of the architecture of such applications.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了Java和Scala，或者更广泛地说，基于JVM的数据应用在处理大数据方面的好处，接下来的逻辑问题是：这些应用程序，或者简单的数据管道，看起来是什么样的？本节旨在概述这些应用程序的架构。
- en: To begin, it’s essential to develop a data pipeline in Java or Scala. Typically,
    multiple related data pipelines can coexist within the same Java or Scala project.
    For effective project management, tools like Apache Maven can be employed. Maven
    simplifies the creation, management, and building of Java applications, making
    the process more efficient and reliable.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，必须在Java或Scala中开发一个数据管道。通常，多个相关的数据管道可以共存于同一个Java或Scala项目中。为了有效的项目管理，可以使用像**Apache
    Maven**这样的工具。Maven简化了Java应用程序的创建、管理和构建过程，使这一过程更加高效和可靠。
- en: In these projects, a data pipeline often comprises one or more Java or Scala
    classes. Spark is commonly integrated into these classes for tasks such as reading
    (or extracting), transforming, and writing (or loading) data. While data can be
    read from and written to various sources, Hive tables are often the natural choices.
    Standard transformations are encapsulated in common classes, making them reusable
    across different pipelines.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些项目中，数据管道通常包括一个或多个Java或Scala类。Spark通常集成到这些类中，用于读取（或提取）、转换和写入（或加载）数据。尽管数据可以从各种来源读取和写入，但Hive表通常是自然选择。标准转换被封装在常用类中，使其可以在不同管道之间重用。
- en: This code shows a basic data pipeline in Spark Scala.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码展示了一个基本的Spark Scala数据管道。
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Ultimately, the goal is to build a Java application typically in the form of
    a jar file. This jar file, along with appropriate arguments, can be invoked using
    job and workflow management systems like Apache Airflow. This enables the execution
    of specific data pipelines at scheduled intervals, contributing to an organized
    and automated data processing workflow.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*最终*，目标是构建一个通常以jar文件形式存在的Java应用程序。这个jar文件以及适当的参数，可以通过像**Apache Airflow**这样的作业和工作流管理系统进行调用。这使得在计划的时间间隔执行特定的数据管道成为可能，从而促进有序和自动化的数据处理工作流。'
- en: Here’s a simple example demonstrating how to execute a data pipeline, represented
    as a class, from the command line.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的示例，展示如何从命令行执行一个作为类表示的数据管道。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: More advanced practices
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更高级的实践
- en: As previously mentioned, data pipelines, now encapsulated in jar files, typically
    require scheduled execution, especially for batch processing, or activation based
    on triggered events, commonly for real-time processing. Apache Airflow serves
    as a robust solution for orchestrating these jar files and task classes, facilitating
    the execution of jobs on a regular schedule. Alternatively, jar files can be triggered
    using tools like AWS Lambda for irregular schedules and real-time processing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，数据管道现在被封装在jar文件中，通常需要定时执行，特别是用于批处理，或者基于触发事件激活，通常用于实时处理。**Apache Airflow**
    作为一个强大的解决方案，用于编排这些jar文件和任务类，促进定期执行作业。或者，可以使用像 AWS Lambda 这样的工具触发jar文件，以应对不规则的时间表和实时处理。
- en: This is an example of an Apache Airflow DAG designed to execute a Java class
    daily.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个Apache Airflow DAG的示例，旨在每天执行一个Java类。
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Moreover, Continuous Integration/Continuous Deployment (CI/CD) tools, including
    Jenkins, GitHub Actions, Spinnaker, among others, offer a seamless way to develop
    and deploy pipelines across various environments from development to testing and
    production environments. This ensures a smooth and automated transition of pipelines
    throughout the development lifecycle.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，持续集成/持续部署（CI/CD）工具，包括Jenkins、GitHub Actions、Spinnaker等，提供了一种无缝的方式来开发和部署跨各种环境的数据管道，从开发到测试和生产环境。这确保了管道在整个开发生命周期中的平滑和自动化过渡。
- en: At the end …
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在最后...
- en: We explored the evolving landscape of data engineering and the essential programming
    skills required in this field. While SQL and Python have traditionally been associated
    with data engineering, the focus is shifting towards Java and Scala, particularly
    in the context of handling massive amounts of data through distributed computing
    frameworks like Hadoop and Spark.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了数据工程不断变化的格局以及该领域所需的基本编程技能。虽然SQL和Python传统上与数据工程相关，但重点正转向Java和Scala，特别是在通过像Hadoop和Spark这样的分布式计算框架处理大量数据的背景下。
- en: Again, we emphasized the importance of JVM (Java Virtual Machine) languages
    due to their portability, making them suitable for developing data applications
    that seamlessly run across diverse systems and environments. It delves into the
    architecture of JVM-based data applications, illustrating the development of data
    pipelines using Java or Scala, with Apache Maven aiding project management.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次强调了JVM（Java虚拟机）语言的重要性，因为它们的可移植性使其适合开发可以在各种系统和环境中无缝运行的数据应用程序。它深入探讨了基于JVM的数据应用程序的架构，展示了如何使用Java或Scala开发数据管道，同时Apache
    Maven帮助项目管理。
