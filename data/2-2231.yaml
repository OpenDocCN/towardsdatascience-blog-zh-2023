- en: 'Unraveling the Design Pattern of Physics-Informed Neural Networks: Part 05'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '揭示物理信息神经网络的设计模式: 第05部分'
- en: 原文：[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23](https://towardsdatascience.com/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-05-67a35a984b23)
- en: Harnessing automated hyperparameter optimization for effective PINN
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用自动化超参数优化提升PINN效果
- en: '[](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----67a35a984b23--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    ·9 min read·Jun 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----67a35a984b23--------------------------------)
    ·阅读时间9分钟·2023年6月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/33b724900a8fa118517e377c2e46f3fb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33b724900a8fa118517e377c2e46f3fb.png)'
- en: Photo by [Drew Patrick Miller](https://unsplash.com/@drewpatrickmiller?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Drew Patrick Miller](https://unsplash.com/@drewpatrickmiller?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Welcome to the 5th blog of this series, where we continue our exciting journey
    of exploring ***design patterns*** of physics-informed neural networks (PINN)🙌
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到本系列的第5篇博客，我们继续探索物理信息神经网络（PINN）的***设计模式***之旅🙌
- en: Have you ever wondered if the best architecture for physics-informed neural
    networks can be automatically searched? It turns out there is a way to do that,
    as indicated by the paper we will be talking about today.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经想过，物理信息神经网络的最佳架构是否可以自动搜索？事实证明，有一种方法可以做到这一点，如我们今天要讨论的论文所示。
- en: Same as usual, let’s start with a discussion of the issues at hand, followed
    by the solutions brought forward, the benchmarking process, as well as the strengths
    and weaknesses of the proposed technique. We will end the blog with some potential
    future opportunities.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们将从讨论当前问题开始，然后介绍提出的解决方案、基准测试过程以及所提技术的优缺点。博客最后将探讨一些潜在的未来机会。
- en: 'In case you are also interested in other PINN design patterns covered in this
    series, feel free to catch up here:'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你对本系列中涵盖的其他PINN设计模式感兴趣，可以在这里跟进：
- en: ''
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 01: 优化残差点分布](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 02: 动态解区间扩展](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: ''
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 03: training PINN with gradient boosting](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 03: 用梯度提升训练PINN](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 04: 梯度增强PINN学习](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: ''
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 06：因果 PINN 训练](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 07：使用 PINN 进行主动学习](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Let’s dive in!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨！
- en: 1\. Paper at a glance 🔍
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 论文概览 🔍
- en: '**Title**: Auto-PINN: Understanding and Optimizing Physics-Informed Neural
    Architecture'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标题**：Auto-PINN：理解和优化物理信息神经网络架构'
- en: '**Authors**: Y. C. Wang, X. T. Han, C. Y. Chang, D. C. Zha, U. Braga-Neto,
    X. Hu'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作者**：Y. C. Wang, X. T. Han, C. Y. Chang, D. C. Zha, U. Braga-Neto, X. Hu'
- en: '**Institutes**: Texas A&M University, Rice University'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机构**：德克萨斯农工大学，莱斯大学'
- en: 'Link: [arXiv](https://arxiv.org/abs/2205.13748)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 链接：[arXiv](https://arxiv.org/abs/2205.13748)
- en: 2\. Design pattern 🎨
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 设计模式 🎨
- en: 2.1 Problem 🎯
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 问题 🎯
- en: In the application of Physics-Informed Neural Networks (PINNs), it comes as
    no surprise that the neural network hyperparameters, such as network depth, width,
    the choice of activation function, etc, all have significant impacts on the PINNs’
    efficiency and accuracy.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在物理信息神经网络（PINNs）的应用中，神经网络超参数，如网络深度、宽度、激活函数的选择等，都会对 PINN 的效率和准确性产生显著影响，这并不令人意外。
- en: 'Naturally, people would resort to **AutoML** (more specifically, neural architecture
    search) to automatically identify the optimal network hyperparameters. But before
    we can do that, there are two questions that need to be addressed:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 自然，人们会求助于**AutoML**（更具体地说，神经架构搜索）来自动识别最佳网络超参数。但在此之前，有两个问题需要解决：
- en: How to effectively navigate the vast search space?
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何有效地在广阔的搜索空间中导航？
- en: How to define a proper search objective?
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何定义合适的搜索目标？
- en: 'This latter point is due to the fact that PINN is usually seen as an “unsupervised”
    problem: no labeled data is needed since the training is guided by minimizing
    the ODE/PDE residuals.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 后者的原因在于 PINN 通常被视为一个“无监督”问题：由于训练是通过最小化 ODE/PDE 残差来指导的，因此不需要标记数据。
- en: '![](../Images/b054003291a6248de678f76d6c53354e.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b054003291a6248de678f76d6c53354e.png)'
- en: PINN workflow. PINNs’ performance is highly sensitive to the network structure.
    One promising way to address this issue is by leveraging AutoML for automatic
    hyperparameter tuning. (Image by this blog author)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: PINN 工作流。PINN 的性能对网络结构非常敏感。解决这一问题的一个有前途的方法是利用 AutoML 进行自动超参数调优。（图片由本博客作者提供）
- en: To better understand those two issues, the authors have conducted extensive
    experiments to investigate the PINN performance’s sensitivity with respect to
    the network structure. Let’s now take a look at what they have found.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这两个问题，作者进行了大量实验，以调查 PINN 性能对网络结构的敏感性。现在，让我们看看他们发现了什么。
- en: 2.2 Solution 💡
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 解决方案 💡
- en: The first idea proposed in the paper is that **the training loss can be used
    as the surrogate for the search objective**, as it highly correlates with the
    final prediction accuracy of the PINN. This addresses the issue of defining a
    proper optimization target for hyperparameter search.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 论文提出的第一个观点是**训练损失可以作为搜索目标的替代指标**，因为它与 PINN 的最终预测准确性高度相关。这解决了为超参数搜索定义合适优化目标的问题。
- en: The second idea is that **there is no need to optimize all network hyperparameters
    simultaneously**. Instead, we can adopt a **step-by-step decoupling strategy**
    to, for example, first search for the optimal activation function, then fix the
    choice of the activation function and find the optimal network width, then fix
    the previous decisions and optimize network depth, and so on. In their experiments,
    the authors demonstrated that this strategy is very effective.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个观点是**无需同时优化所有网络超参数**。相反，我们可以采用**逐步解耦策略**，例如，首先搜索最佳激活函数，然后固定激活函数的选择，寻找最佳网络宽度，再固定之前的决定并优化网络深度，依此类推。在他们的实验中，作者证明了这一策略非常有效。
- en: With those two ideas in mind, let’s see how we can execute the search in detail.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这两个观点，我们来详细看看如何执行搜索。
- en: 'First of all, which network hyperparameters are considered? In the paper, the
    recommended search space is:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，考虑哪些网络超参数？在论文中，推荐的搜索空间是：
- en: '**Width**: number of neurons in each hidden layer. The considered range is
    [8, 512] with a step of 4 or 8.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**宽度**：每个隐藏层中的神经元数量。考虑的范围是[8, 512]，步长为4或8。'
- en: '**Depth**: number of hidden layers. The considered range is [3, 10] with a
    step of 1.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度**：隐藏层的数量。考虑的范围是[3, 10]，步长为1。'
- en: '**Activation function**: Tanh, Sigmoid, ReLU, and [Swish](https://paperswithcode.com/method/swish).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激活函数**：Tanh、Sigmoid、ReLU，以及[Swish](https://paperswithcode.com/method/swish)。'
- en: '**Changing point**: the portion of the epochs using Adam to the total training
    epochs. The considered values are [0.1, 0.2, 0.3, 0.4, 0.5]. In PINN, it’s a common
    practice to first use Adam to train for certain epochs and then switch to L-BFGS
    to keep training for some epochs. This changing point hyperparameter determines
    the timing of the change.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变化点**：使用Adam的周期占总训练周期的比例。考虑的值为[0.1, 0.2, 0.3, 0.4, 0.5]。在PINN中，通常的做法是首先使用Adam训练若干周期，然后切换到L-BFGS继续训练若干周期。此变化点超参数决定了切换的时机。'
- en: '**Learning rate**: a fixed value of 1e-5, as it has a small effect on the final
    architecture search results.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习率**：固定值为1e-5，因为它对最终的架构搜索结果影响较小。'
- en: '**Training epochs**: a fixed value of 10000, as it has a small effect on the
    final architecture search results.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练周期**：固定值为10000，因为它对最终的架构搜索结果影响较小。'
- en: 'Secondly, let’s examine the proposed procedure in detail:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，让我们详细审查提出的过程：
- en: The first search target is the *activation function*. To achieve that, we sample
    the width and depth parameter space and calculate the losses for all width-depth
    samples under different activation functions. These results can give us ideas
    of which activation function is the dominant one. Once decided, we fix the activation
    function for the following steps.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个搜索目标是*激活函数*。为此，我们采样宽度和深度参数空间，并计算不同激活函数下所有宽度-深度样本的损失。这些结果可以为我们提供哪个激活函数是主导的线索。一旦决定，我们将在后续步骤中固定激活函数。
- en: '![](../Images/e70feda925ce7e4e1ad55422943f9095.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e70feda925ce7e4e1ad55422943f9095.png)'
- en: The first step is to identify the dominant activation function. (Image by this
    blog author)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是识别主导的激活函数。（图片由博客作者提供）
- en: The second search target is the *width*. More specifically, we are looking for
    a couple of width intervals where PINN performs well.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个搜索目标是*宽度*。更具体地说，我们寻找几个PINN表现良好的宽度区间。
- en: '![](../Images/2417264fc5c89ffe09c62dba799b2279.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2417264fc5c89ffe09c62dba799b2279.png)'
- en: The second step is to identify the promising intervals for the network width.
    (Image by this blog author)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是识别网络宽度的有前景区间。（图片由博客作者提供）
- en: The third search target is the *depth*. Here, we only consider width varying
    within the best-performing intervals determined from the last step, and we would
    like to find the best K width-depth combinations where PINN performs well.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个搜索目标是*深度*。在这里，我们只考虑在上一步确定的最佳表现区间内变化的宽度，并希望找到PINN表现良好的最佳K个宽度-深度组合。
- en: '![](../Images/f37b81dfa8baf9b6797c43c68b6e824d.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f37b81dfa8baf9b6797c43c68b6e824d.png)'
- en: The third step is to identify the top-K best-performing width-depth combinations.
    (Image by this blog author)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 第三步是识别表现最好的宽度-深度组合的前K名。（图片由博客作者提供）
- en: The final search target is the *changing point*. We simply search for the best
    changing point for each of the top-K configurations identified from the last step.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终搜索目标是*变化点*。我们仅需为上一步识别的前K个配置中的每一个寻找最佳变化点。
- en: '![](../Images/b2c971e519b77efebc33fc216a95519c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2c971e519b77efebc33fc216a95519c.png)'
- en: The final step is to identify the best changing point. (Image by this blog author)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是识别最佳变化点。（图片由博客作者提供）
- en: The outcome of this search procedure is **K different PINN structures**. We
    can either select the best-performing one out of those K candidates or simply
    use all of them to form a K-ensemble PINN model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这一搜索过程的结果是**K种不同的PINN结构**。我们可以从这些K个候选中选择表现最好的一个，或简单地使用所有这些模型形成一个K-ensemble PINN模型。
- en: Notice that several tuning parameters need to be specified in the above-presented
    procedure (e.g., number of width intervals, number of K, etc.), which would depend
    on the available tuning budget.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，上述过程需要指定若干调优参数（如宽度区间的数量、K的数量等），这将取决于可用的调优预算。
- en: As for the specific optimization algorithms used in individual steps, off-the-shelf
    AutoML libraries can be employed to complete the task. For example, the authors
    in the paper used [Tune package](https://docs.ray.io/en/latest/tune/index.html)
    for executing the hyperparameter tuning.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 至于具体优化算法的使用，可以利用现成的AutoML库来完成任务。例如，论文中的作者使用了[Tune package](https://docs.ray.io/en/latest/tune/index.html)来执行超参数调优。
- en: 2.3 Why the solution might work 🛠️
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 为什么解决方案可能有效 🛠️
- en: By decoupling the search of different hyperparameters, the scale of the search
    space can be greatly decreased. This not only substantially decreases the search
    complexity, but also significantly increases the chance of locating a (near) optimal
    network architecture for the physical problems under investigation.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解耦不同超参数的搜索，搜索空间的规模可以大大缩小。这不仅大大降低了搜索复杂性，还显著提高了为研究中的物理问题找到（近）最优网络架构的可能性。
- en: Also, using the training loss as the search objective is both simple to implement
    and desirable. As the training loss (mainly constituted by PDE residual loss)
    highly correlates with the PINN accuracy during inference (according to the experiments
    conducted in the paper), identifying an architecture that delivers minimum training
    loss will also likely lead to a model with high prediction accuracy.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，使用训练损失作为搜索目标既简单易行又令人期望。由于训练损失（主要由PDE残差损失构成）与推理过程中的PINN准确性高度相关（根据论文中进行的实验），识别出能提供最小训练损失的架构也可能会导致一个高预测准确度的模型。
- en: 2.4 Benchmark ⏱️
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 基准测试 ⏱️
- en: The paper considered a total of 7 different benchmark problems. All problems
    are forward problems where PINN is used to solve the PDEs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 论文考虑了总共7个不同的基准问题。所有问题都是正向问题，PINN用于求解PDE。
- en: Heat equation with Dirichlet boundary condition. This type of equation describes
    the heat or temperature distribution in a given domain over
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有Dirichlet边界条件的热方程。这类方程描述了给定区域内的热量或温度分布。
- en: time.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 时间。
- en: '![](../Images/4baa6f65157c0e3740d7b95632c2b11a.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4baa6f65157c0e3740d7b95632c2b11a.png)'
- en: Heat equation with Neumann boundary conditions.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有Neumann边界条件的热方程。
- en: '![](../Images/7ceb8b43195cdc1210a823a443906a72.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ceb8b43195cdc1210a823a443906a72.png)'
- en: Wave equation, which describes the propagation of oscillations in a space, such
    as mechanical and electromagnetic waves. Both Dirichlet and Neumann conditions
    are considered here.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 波动方程，描述了空间中振动的传播，如机械波和电磁波。这里考虑了Dirichlet和Neumann条件。
- en: '![](../Images/863da3e4ee07cc436fd1d948a0c6f4e4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/863da3e4ee07cc436fd1d948a0c6f4e4.png)'
- en: Burgers equation, which has been leveraged to model shock flows, wave propagation
    in combustion chambers, vehicular traffic movement, and more.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Burgers方程，已被用来模拟冲击流、燃烧室中的波动传播、交通流动等。
- en: '![](../Images/ccb5818acb93b826e62f1637680b1f1b.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccb5818acb93b826e62f1637680b1f1b.png)'
- en: Advection equation, which describes the motion of a scalar field as it is advected
    by a known velocity vector field.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对流方程，描述了标量场在已知速度矢量场的作用下的运动。
- en: '![](../Images/af451ca8c4d7d29e6ce8c86244de3eaa.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af451ca8c4d7d29e6ce8c86244de3eaa.png)'
- en: Advection equation, with different boundary conditions.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对流方程，具有不同的边界条件。
- en: '![](../Images/966c71e45e89ed8449727b345a07ba24.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/966c71e45e89ed8449727b345a07ba24.png)'
- en: Reaction equation, which describes chemical reactions.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反应方程，描述化学反应。
- en: '![](../Images/97b592caefa99d168ae75a97f3ebe41d.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97b592caefa99d168ae75a97f3ebe41d.png)'
- en: 'The benchmark studies yielded that:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 基准研究结果显示：
- en: The proposed Auto-PINN shows stable performance for various PDEs.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出的Auto-PINN在各种PDE问题中表现稳定。
- en: For most cases, Auto-PINN is able to identify the neural network architecture
    with the smallest error values.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大多数情况下，Auto-PINN能够识别出具有最小误差值的神经网络架构。
- en: The search trials are fewer with the Auto-PINN approach.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Auto-PINN方法的搜索尝试次数较少。
- en: 2.5 Strengths and Weaknesses ⚡
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 优势和劣势 ⚡
- en: '**Strengths** 💪'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**优势** 💪'
- en: Significantly reduced computational cost for performing neural architecture
    search for PINN applications.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显著降低了进行PINN应用的神经架构搜索的计算成本。
- en: Improved likelihood of identifying a (near) optimal neural network architecture
    for different PDE problems.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高了识别适用于不同PDE问题的（近）最优神经网络架构的可能性。
- en: '**Weaknesses** 📉'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**劣势** 📉'
- en: The effectiveness of using the training loss value as the search objective might
    depend on the specific characteristics of the PDE problem at hand, as the benchmarks
    are performed only for a specific set of PDEs.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练损失值作为搜索目标的有效性可能依赖于特定的PDE问题特征，因为基准测试仅针对特定的一组PDE进行。
- en: Data sampling strategy influences Auto-PINN performance. While the paper discusses
    the impact of different data sampling strategies, it does not provide a clear
    guideline on how to choose the best strategy for a given PDE problem. This could
    potentially add another layer of complexity to the use of Auto-PINN.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据采样策略影响 Auto-PINN 的性能。尽管论文讨论了不同数据采样策略的影响，但并未提供如何选择适合特定 PDE 问题的最佳策略的明确指南。这可能为使用
    Auto-PINN 增添了另一层复杂性。
- en: 2.6 Alternatives 🔀
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 替代方案 🔀
- en: The conventional out-of-box AutoML algorithms can also be employed to tackle
    the problem of hyperparameter optimization in Physics-Informed Neural Networks
    (PINNs). Those algorithms include *Random Search*, *Genetic Algorithms*, *Bayesian
    optimization*, etc.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的现成 AutoML 算法也可以用于解决物理信息神经网络（PINNs）的超参数优化问题。这些算法包括 *随机搜索*、*遗传算法*、*贝叶斯优化* 等。
- en: Compared to those alternative algorithms, the newly proposed Auto-PINN is specifically
    designed for PINN. This makes it a unique and effective solution for optimizing
    PINN hyperparameters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与那些替代算法相比，新提出的 Auto-PINN 专门为 PINN 设计。这使得它成为优化 PINN 超参数的独特且有效的解决方案。
- en: 3 Potential Future Improvements 🌟
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 个潜在的未来改进 🌟
- en: 'There are several possibilities to further improve the proposed strategy:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 还有几个可能的方式来进一步改进所提议的策略：
- en: Incorporating more sophisticated data sampling strategies, such as adaptive-
    and residual-based sampling methods, to improve the search accuracy and the model
    performance.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合更复杂的数据采样策略，例如自适应和基于残差的采样方法，以提高搜索精度和模型性能。
- en: To learn more about how to optimize the residual points distribution, check
    out [this blog](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)
    in the PINN design pattern series.
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要了解更多关于如何优化残差点分布的信息，请查看 [这篇博客](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)
    这是 PINN 设计模式系列中的一篇文章。
- en: More benchmarking on the search objective, to assess if training loss value
    is indeed a good surrogate for various types of PDEs.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对搜索目标进行更多的基准测试，以评估训练损失值是否确实是各种类型 PDE 的良好代理。
- en: Incorporating other types of neural networks. The current version of Auto-PINN
    is designed for multilayer perceptron (MLP) architectures only. Future work could
    explore convolutional neural networks (CNNs) or recurrent neural networks (RNNs),
    which could potentially enhance the capability of PINNs in solving more complex
    PDE problems.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纳入其他类型的神经网络。目前版本的 Auto-PINN 仅为多层感知机（MLP）架构设计。未来的工作可以探索卷积神经网络（CNNs）或递归神经网络（RNNs），这些可能增强
    PINNs 解决更复杂 PDE 问题的能力。
- en: Transfer learning in Auto-PINN. For instance, architectures that perform well
    on certain types of PDE problems could be used as starting points for the search
    process on similar types of PDE problems. This could potentially speed up the
    search process and improve the performance of the model.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Auto-PINN 中的迁移学习。例如，在某些类型的 PDE 问题上表现良好的架构可以作为类似类型 PDE 问题搜索过程的起点。这可能加快搜索过程并提高模型的性能。
- en: 4 Takeaways 📝
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 个收获 📝
- en: 'In this blog, we looked at how to efficiently tune PINN model hyperparameters
    with the Auto-PINN approach. Here are the highlights of the design pattern proposed
    in the paper:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们讨论了如何使用 Auto-PINN 方法有效调优 PINN 模型超参数。以下是论文中提出的设计模式的亮点：
- en: '[Problem]: How to automatically tune PINNs’ model hyperparameters?'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[问题]: 如何自动调优 PINNs 的模型超参数？'
- en: '[Solution]: **Customized Neural Architecture Search**, where the training loss
    is used as the search objective and a step-by-step decoupling strategy is employed
    to effectively narrow the search space.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解决方案]: **定制化神经架构搜索**，在该方法中，训练损失被用作搜索目标，并采用逐步解耦策略来有效缩小搜索空间。'
- en: '[Potential benefits]: 1\. More efficient search with significantly reduced
    computational cost. 2\. Improved likelihood to identify the (near) optimal neural
    network hyperparameters for different types of PDE problems.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[潜在好处]: 1\. 更高效的搜索，显著降低计算成本。2\. 提高识别不同类型 PDE 问题的（近似）最优神经网络超参数的可能性。'
- en: 'As usual, I have prepared a PINN design card to summarize the takeaways:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我准备了一张 PINN 设计卡来总结收获：
- en: '![](../Images/50de7543bac39e0495455ac5c882c868.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50de7543bac39e0495455ac5c882c868.png)'
- en: PINN design pattern proposed in the paper. (Image by this blog author)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中提出的 PINN 设计模式。（图像由该博客作者提供）
- en: 'I hope you found this blog useful! To learn more about PINN design patterns,
    feel free to check out other posts in this series:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您觉得这篇博客对您有用！要了解更多关于 PINN 设计模式的内容，请随时查看本系列的其他文章：
- en: '[PINN design pattern 01: Optimizing the residual point distribution](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 01：优化残差点分布](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
- en: '[PINN design pattern 02: Dynamic solution interval expansion](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 02：动态解空间区间扩展](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-02-2156516f2791)'
- en: '[PINN design pattern 03: PINN training with gradient boost](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 03：使用梯度提升的 PINN 训练](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-03-fe365ef480d9)'
- en: '[PINN design pattern 04: gradient-enhanced PINN learning](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 04：梯度增强的 PINN 学习](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-04-c778f4829dde)'
- en: '[PINN design pattern 06: Causal PINN training](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 06：因果 PINN 训练](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-06-bcb3557199e2)'
- en: '[PINN design pattern 07: Active learning with PINN](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PINN 设计模式 07：使用 PINN 的主动学习](/unraveling-the-design-pattern-of-physics-informed-neural-networks-part-07-4ecb543b616a)'
- en: Looking forward to sharing more insights with you in the upcoming blogs!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 期待在即将发布的博客中与您分享更多见解！
- en: Reference 📑
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考 📑
- en: '[1] Wang et al., Auto-PINN: Understanding and Optimizing Physics-Informed Neural
    Architecture, [arXiv](https://arxiv.org/abs/2205.13748), 2022.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Wang et al., Auto-PINN: 理解和优化物理信息神经网络架构, [arXiv](https://arxiv.org/abs/2205.13748),
    2022.'
