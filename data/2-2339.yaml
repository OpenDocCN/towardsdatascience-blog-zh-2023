- en: What Is the Environmental Impact of AI?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 的环境影响是什么？
- en: 原文：[https://towardsdatascience.com/what-is-the-environmental-impact-of-ai-b8af55ec169e](https://towardsdatascience.com/what-is-the-environmental-impact-of-ai-b8af55ec169e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-is-the-environmental-impact-of-ai-b8af55ec169e](https://towardsdatascience.com/what-is-the-environmental-impact-of-ai-b8af55ec169e)
- en: The new AI Index report points out the vast amount of energy that AI like ChatGPT
    require — though there is a positive side, too
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新的 AI Index 报告指出了像 ChatGPT 这样的 AI 所需的巨大能量 — 尽管也有积极的一面。
- en: '[](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)[![Alan
    Jones](../Images/359379fab1d6685ff08080b98173e67c.png)](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)
    [Alan Jones](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)[![Alan
    Jones](../Images/359379fab1d6685ff08080b98173e67c.png)](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)
    [Alan Jones](https://medium.com/@alan-jones?source=post_page-----b8af55ec169e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)
    ·6 min read·Apr 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b8af55ec169e--------------------------------)
    ·阅读时长 6 分钟·2023年4月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3fd74ad59f0fbf43893e40662d549918.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fd74ad59f0fbf43893e40662d549918.png)'
- en: Photo by [Jason Blackeye](https://unsplash.com/@jeisblack?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Jason Blackeye](https://unsplash.com/@jeisblack?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: A small but important part of the *AI Index Report* for 2023¹ points to the
    growing concern about the energy consumption required for AI training.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2023¹ 年的*AI Index Report*中的一个小但重要的部分指出了对 AI 训练所需能耗的日益关注。
- en: 'Spoiler alert: it’s quite a lot.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 剧透警告：这确实是非常多。
- en: There’s no standard benchmark for tracking the carbon intensity of AI systems,
    so the report focuses on research from a recent paper by Luccioni et al., 2022²
    which records the energy requirements of a number of large language models (LLMs)
    including ChatGPT.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 目前没有用于追踪 AI 系统碳强度的标准基准，因此报告侧重于 Luccioni 等人，2022² 的一篇近期论文中的研究，该论文记录了包括 ChatGPT
    在内的大型语言模型（LLMs）的能源需求。
- en: The following table shows the energy requirements for training four different
    AI models and the CO2 emissions associated with it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了训练四种不同 AI 模型的能源需求以及相关的 CO2 排放。
- en: '![](../Images/8694704f08c5994ddc13dae2bd9f812e.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8694704f08c5994ddc13dae2bd9f812e.png)'
- en: 'Image by author, data source: Luccioni, et al., 2022²'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者，数据来源：Luccioni 等人，2022²
- en: The data contains a number of measurements but the bottom line is represented
    by the power consumption and CO2 emissions which I have summarised in the charts
    below.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据包含了若干测量值，但关键点在于我在下方的图表中总结的电力消耗和 CO2 排放。
- en: '![](../Images/462033742b2de182498726e0415e1615.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/462033742b2de182498726e0415e1615.png)'
- en: 'Power Consumption of four AI models — Image by author, data source: Luccioni,
    et al., 2022²'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 四种 AI 模型的电力消耗 — 图片来源：作者，数据来源：Luccioni 等人，2022²
- en: There is quite a difference between the various models and, as you can see,
    OpenAI’s GPT-3 comes top with a consumption of over 1200 Megawatt-hours. That’s
    about as much electricity as 120 US homes would consume in a year according to
    consumption figures by the U.S. Energy Information Administration³. That certainly
    seems like a lot of energy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 各种模型之间存在相当大的差异，正如你所见，OpenAI 的 GPT-3 排名第一，消耗超过 1200 兆瓦时。根据美国能源信息署的数据，这大约是 120
    个美国家庭一年所消耗的电量³。这确实看起来是非常大量的能源。
- en: The chart below illustrates the CO2 emissions which follow a similar pattern.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 CO2 排放情况，其模式相似。
- en: '![](../Images/3f877739a29b5ad3ce3c83282fe18e38.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f877739a29b5ad3ce3c83282fe18e38.png)'
- en: 'CO2 emissions of four AI models — Image by author, data source: Luccioni, et
    al., 2022²'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 四种 AI 模型的 CO2 排放 — 图片来源：作者，数据来源：Luccioni 等人，2022²
- en: Luccioni, the paper’s principal author, is a researcher at Hugging Face Inc.
    and the work is mostly concerned with BLOOM, her company’s alternative to ChatGPT.
    The figures for other models are approximate and based on what public information
    is available ([Bloomberg](https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure)
    reports Lucciana saying that nothing is really known about ChatGPT and that it
    could just be “…three raccoons in a trench coat.” — does that mean GPT-4 will
    be four raccoons?).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的主要作者Luccioni是Hugging Face Inc.的研究员，该工作的主要关注点是她公司开发的替代ChatGPT的模型BLOOM。其他模型的数据是近似的，基于公开信息（[Bloomberg](https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure)报道Lucciana说没有关于ChatGPT的确切数据，可能只是“…三只穿着大衣的浣熊。”——这是否意味着GPT-4将会是四只浣熊？）。
- en: CO2 emissions for training ChatGPT are equivalent to around 500 flights from
    New York to San Francisco
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 训练ChatGPT的CO2排放量相当于约500次从纽约到旧金山的航班
- en: The AI Index Report makes some comparisons with other energy-intensive activities
    and their CO2 emissions (see chart, below). It finds for example, that the CO2
    emissions generated in training ChatGPT are equivalent to one passenger taking
    a flight from New York to San Francisco around 500 times! Or the total energy
    consumption of a single American over 28 years!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能指数报告对其他能源密集型活动及其CO2排放进行了比较（见下图）。例如，它发现训练ChatGPT产生的CO2排放量相当于一名乘客从纽约飞往旧金山约500次！或者相当于一个美国人28年的总能源消耗！
- en: '![](../Images/82e15c6e88f807258e92e6723ae160f3.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82e15c6e88f807258e92e6723ae160f3.png)'
- en: 'Energy consumption comparisons: AI models and real-life examples. Image by
    author, data source AI Index Report¹'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 能源消耗比较：人工智能模型和现实生活中的例子。作者提供的图片，数据来源于人工智能指数报告¹
- en: 'Unsurprisingly, the single air passenger does not produce zero emissions as
    it may appear from the chart above (the figure is nearly 1 tonne). You can see
    the actual numbers more clearly in this table:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 不足为奇的是，单个航空乘客并未如上图所示产生零排放（实际排放量接近1吨）。你可以在下表中更清楚地看到实际数字：
- en: '![](../Images/e8fa9dc44568b79f98ca3d4b8b424199.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8fa9dc44568b79f98ca3d4b8b424199.png)'
- en: 'Energy consumption comparisons: AI models and real-life examples. Image by
    author, data source AI Index Report¹'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 能源消耗比较：人工智能模型和现实生活中的例子。作者提供的图片，数据来源于人工智能指数报告¹
- en: But it’s not all bad news.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但这并不是全然坏消息。
- en: AI can also reduce energy consumption
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能也可以减少能源消耗
- en: According to [Bloomberg](https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure),
    while AI models are getting larger (and presumably more energy intensive), the
    companies creating them are working on improving efficiency. Microsoft, Google
    and Amazon — the cloud companies that host much of the work — all are aiming for
    carbon-negative or carbon-neutral operations. This is, of course, highly desirable.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[Bloomberg](https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure)的报道，虽然人工智能模型变得越来越大（并且可能更具能源密集性），但创建这些模型的公司正在致力于提高效率。微软、谷歌和亚马逊——这些托管大部分工作的云公司——都在致力于实现碳负或碳中和运营。这当然是非常可取的。
- en: Also, while training AI systems is energy-intensive, recent research shows that
    AI systems can also be used to optimize energy consumption. A paper from DeepMind⁴
    released in 2022 details the results of a 2021 experiment in which it trained
    an AI called BCOOLER to optimize cooling in Google’s data centres.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管训练人工智能系统是能源密集型的，但最近的研究表明，人工智能系统也可以用于优化能源消耗。2022年DeepMind发布的一篇论文⁴详细介绍了2021年的一个实验，该实验训练了一个名为BCOOLER的人工智能，以优化Google数据中心的冷却。
- en: '![](../Images/2de2a1c96e21552eeef79cddf568820e.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2de2a1c96e21552eeef79cddf568820e.png)'
- en: Energy saving by BCOOLER. Image by author, data source AI Index¹
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: BCOOLER的节能。作者提供的图片，数据来源于人工智能指数报告¹
- en: The graph above shows the energy-saving results from one BCOOLER experiment.
    After three months, a, roughly, 12.7% energy saving was achieved.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了BCOOLER实验的节能结果。经过三个月，大约节省了12.7%的能源。
- en: Even if carbon neutrality is achieved, the use of AI to increase the efficiency
    of these centres will also make them cheaper to run. Maybe we should be thinking
    about applying AI to other energy-intensive industries, too.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 即使实现了碳中和，利用人工智能提高这些中心的效率也会使其运行成本降低。也许我们应该考虑将人工智能应用于其他能源密集型行业。
- en: I doubt that we are currently in a position to know exactly what the eventual
    toll on the environment will be. LLMs like ChatGPT are not going away and so the
    energy that needs to be spent in training them is definitely going to be spent.
    On the other hand, it’s not the case that people are going to stop flying NY to
    SF, heating their homes or using their cars.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我怀疑我们目前是否能确切了解最终对环境的影响。像ChatGPT这样的LLM不会消失，因此训练它们所需的能源肯定会被消耗。另一方面，人们也不会停止从纽约飞往旧金山、给家里供暖或使用汽车。
- en: But we should try and put some of this somewhat shocking data into perspective.
    While a ChatGPT training session might use as much energy as one American does
    in 28 years (which sounds an awful lot), it is also true that 330 million Americans,
    the population of the USA, emit around **10 million times more CO2** than a single
    ChatGPT session⁵.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们应该尝试将这些令人震惊的数据放在相对的视角中。虽然一次ChatGPT训练会消耗相当于一个美国人28年的能源（这听起来很多），但330万美国人——即美国人口——产生的CO2是单次ChatGPT会话的**1000万倍**⁵。
- en: And there appear to be around 20 flights a day from New York to San Francisco,
    and say that each flight serves 150 passengers; that works out to be over 1 million
    tonnes of CO2 emissions per year — **more than 2000 ChatGPTs⁵**.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从纽约到旧金山的航班每天大约有20班，假设每班服务150名乘客，这样每年产生超过100万吨的CO2排放——**超过2000个ChatGPT⁵**。
- en: For single entities, ChatGPT, and its like, clearly use a lot of energy (and
    thus — at the moment, at least — produce a lot of CO2 emissions) but compared
    to energy consumption and CO2 emissions from other human activity, are they really
    very significant (there are, after all, a lot more humans than LLMs)?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单一实体，像ChatGPT这样的系统显然使用了大量能源（因此——至少目前——也产生了大量的CO2排放），但与其他人类活动的能源消耗和CO2排放相比，它们真的很重要吗（毕竟，人类的数量远远多于LLM）？
- en: Also, it’s got to be good news that the large cloud hosting companies are aiming
    to achieve carbon neutrality which, if achieved, will reduce CO2 emissions to
    zero. So while energy use might remain high, the aim is to make its environmental
    impact neutral.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，大型云托管公司旨在实现碳中和，这将减少CO2排放至零。因此，虽然能源使用可能仍然很高，但目标是使其环境影响达到中性。
- en: Additionally, AI can be used to mitigate some of the energy use in data centres.
    Maybe similar technology could be used in airlines and other energy-intensive
    industries.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AI可以用于减少数据中心的能源使用。也许类似的技术可以应用于航空公司和其他能源密集型行业。
- en: The bottom line, however, is that we are all producing more CO2 than we should,
    so any additional energy use, that is not produced from renewables, is moving
    in the wrong direction.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关键点是我们所有人都在产生比应有更多的CO2，因此任何额外的能源使用（如果不是来自可再生能源）都是朝着错误的方向发展。
- en: Thanks for reading, I hope you found this useful. If you would like to see more
    of my work, please visit my [website](http://alanjones2.github.io).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，希望你觉得这有用。如果你想查看我的更多作品，请访问我的[网站](http://alanjones2.github.io)。
- en: You can also get updates by subscribing to my occasional, free, [newsletter
    on Substack](https://technofile.substack.com).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过订阅我偶尔发布的免费[Substack通讯](https://technofile.substack.com)来获取更新。
- en: If you are not a Medium member you can sign up using my [referral link](https://medium.com/@alan-jones/membership)
    and get to read any Medium content for only $5 per month.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不是Medium会员，你可以使用我的[推荐链接](https://medium.com/@alan-jones/membership)注册，每月仅需$5即可阅读任何Medium内容。
- en: References
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: The AI Index 2023 Annual Report
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AI Index 2023 Annual Report
- en: Nestor Maslej, Loredana Fattorini, Erik Brynjolfsson, John Etchemendy, Katrina
    Ligett, Terah Lyons, James Manyika, Helen Ngo, Juan Carlos Niebles, Vanessa Parli,
    Yoav Shoham, Russell Wald, Jack Clark, and Raymond Perrault, “*The AI Index 2023
    Annual Report,*” AI Index Steering Committee, Institute for Human-Centered AI,
    Stanford University, Stanford, CA, April 2023.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Nestor Maslej, Loredana Fattorini, Erik Brynjolfsson, John Etchemendy, Katrina
    Ligett, Terah Lyons, James Manyika, Helen Ngo, Juan Carlos Niebles, Vanessa Parli,
    Yoav Shoham, Russell Wald, Jack Clark, 和Raymond Perrault，“*AI Index 2023 Annual
    Report*”，AI Index Steering Committee, Institute for Human-Centered AI, Stanford
    University, Stanford, CA, 2023年4月。
- en: The *AI Index 2023 Annual Report* by Stanford University is licensed under [Attribution-NoDerivatives
    4.0 International](https://creativecommons.org/licenses/by-nd/4.0/?ref=chooser-v1).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 斯坦福大学的*AI Index 2023 Annual Report*在[署名-禁止演绎 4.0 国际](https://creativecommons.org/licenses/by-nd/4.0/?ref=chooser-v1)许可下发布。
- en: You can find the complete report on the [AI Index](https://aiindex.stanford.edu/)
    page at Stanford University.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在斯坦福大学的[AI Index](https://aiindex.stanford.edu/)页面找到完整报告。
- en: 2\. [*Estimating the carbon footprint of BLOOM, a 176B parameter language model*](https://arxiv.org/pdf/2211.02001.pdf),
    Luccioni et al., 2022.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. [*估算BLOOM的碳足迹，一个176B参数的语言模型*](https://arxiv.org/pdf/2211.02001.pdf)，Luccioni等人，2022。
- en: 3\. The [U.S. Energy Information Administration](https://www.eia.gov/tools/faqs/faq.php?id=97&t=3#:~:text=In%202021,%20the%20average%20annual,about%20886%20kWh%20per%20month.)
    estimates that in 2021, the average annual electricity consumption of a U.S. residential
    utility customer was 10,632 kilowatt hours (kWh).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. [美国能源信息管理局](https://www.eia.gov/tools/faqs/faq.php?id=97&t=3#:~:text=In%202021,%20the%20average%20annual,about%20886%20kWh%20per%20month.)
    估计2021年，美国住宅电力用户的年平均电力消耗为10,632千瓦时（kWh）。
- en: 4\. [Controlling Commercial Cooling Systems Using Reinforcement Learning](https://www.deepmind.com/publications/controlling-commercial-cooling-systems-using-reinforcement-learning),
    DeepMind, 2022
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. [使用强化学习控制商业冷却系统](https://www.deepmind.com/publications/controlling-commercial-cooling-systems-using-reinforcement-learning)，DeepMind，2022
- en: '5\. CO2 emissions from other sources (these are rough calculations):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 来自其他来源的CO2排放（这些是粗略计算）：
- en: 330 million Americans emit 18 tonnes of CO2 each year, that’s 330m x 18, 5900m
    tonnes of CO2–10 million ChatGPTs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 3.3亿美国人每年排放18吨CO2，即3.3亿 x 18，5900万吨CO2——1000万个ChatGPT。
- en: Approx. 20 flights (each day), NY to SF, with around 150 passengers on board
    produce 20 x 150, or 3000 tonnes of CO2\. That’s 3000 x 365, about 1 million tonnes
    of CO2 per year — 2000 ChatGPTs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 约20个航班（每天），从纽约到旧金山，每个航班大约有150名乘客，产生20 x 150，即3000吨的CO2。这相当于3000 x 365，大约每年1百万吨的CO2——2000个ChatGPT。
