- en: Overfitting, Underfitting, and Regularization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合、欠拟合与正则化
- en: 原文：[https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62?source=collection_archive---------9-----------------------#2023-02-15](https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62?source=collection_archive---------9-----------------------#2023-02-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62?source=collection_archive---------9-----------------------#2023-02-15](https://towardsdatascience.com/overfitting-underfitting-and-regularization-7f83dd998a62?source=collection_archive---------9-----------------------#2023-02-15)
- en: Making Friends with AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与人工智能交朋友
- en: The bias-variance tradeoff, part 2 of 3
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差-方差权衡，第三部分中的第二部分
- en: '[](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[![Cassie
    Kozyrkov](../Images/ad18dd12979a4a3ec130bdf8b889af23.png)](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    [Cassie Kozyrkov](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[![Cassie
    Kozyrkov](../Images/ad18dd12979a4a3ec130bdf8b889af23.png)](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    [Cassie Kozyrkov](https://kozyrkov.medium.com/?source=post_page-----7f83dd998a62--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2fccb851bb5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foverfitting-underfitting-and-regularization-7f83dd998a62&user=Cassie+Kozyrkov&userId=2fccb851bb5e&source=post_page-2fccb851bb5e----7f83dd998a62---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    ·4 min read·Feb 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7f83dd998a62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foverfitting-underfitting-and-regularization-7f83dd998a62&user=Cassie+Kozyrkov&userId=2fccb851bb5e&source=-----7f83dd998a62---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2fccb851bb5e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foverfitting-underfitting-and-regularization-7f83dd998a62&user=Cassie+Kozyrkov&userId=2fccb851bb5e&source=post_page-2fccb851bb5e----7f83dd998a62---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f83dd998a62--------------------------------)
    ·4分钟阅读·2023年2月15日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7f83dd998a62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foverfitting-underfitting-and-regularization-7f83dd998a62&user=Cassie+Kozyrkov&userId=2fccb851bb5e&source=-----7f83dd998a62---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7f83dd998a62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foverfitting-underfitting-and-regularization-7f83dd998a62&source=-----7f83dd998a62---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7f83dd998a62&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foverfitting-underfitting-and-regularization-7f83dd998a62&source=-----7f83dd998a62---------------------bookmark_footer-----------)'
- en: 'In [Part 1](http://bit.ly/quaesita_bivar1), we covered much of the basic terminology
    as well as a few key insights about the bias-variance formula (**MSE = Bias² +
    Variance**), including this paraphrase from [Anna Karenina](https://www.goodreads.com/work/quotes/2507928):'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一部分](http://bit.ly/quaesita_bivar1)中，我们介绍了许多基本术语以及有关偏差-方差公式（**MSE = Bias²
    + Variance**）的一些关键见解，包括来自[安娜·卡列尼娜](https://www.goodreads.com/work/quotes/2507928)的这段话：
- en: All perfect models are alike, but each unhappy model can be unhappy in its own
    way.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所有完美的模型都是相似的，但每个不完美的模型都有其独特的不幸。
- en: To make the most of *this* article, I suggest taking a look at [Part 1](http://bit.ly/quaesita_bivar1)
    to make sure you’re well-situated to absorb this one.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大化*这篇*文章的价值，我建议先阅读[第一部分](http://bit.ly/quaesita_bivar1)，以确保你能更好地理解本文。
- en: '![](../Images/6073e1755019bc63fad47ad5d1bed129.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6073e1755019bc63fad47ad5d1bed129.png)'
- en: Under vs over… fitting. Image by the author.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合与过拟合…… 图片由作者提供。
- en: What does overfitting/underfitting have to do with it?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合/欠拟合与此有何关系？
- en: Let’s say you have a [model](http://bit.ly/quaesita_emperorm) that is as good
    as you’re going to get for the information you have.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个和你所拥有的信息最匹配的[模型](http://bit.ly/quaesita_emperorm)。
- en: To have an even better model, you need better [data](http://bit.ly/quaesita_hist).
    In other words, more data (quantity) or *more relevant* data (quality).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要拥有一个更好的模型，你需要更好的[数据](http://bit.ly/quaesita_hist)。换句话说，更多的数据（数量）或*更相关*的数据（质量）。
- en: When I say as *good* as you’re going to get, I mean in “good” terms of [MSE](http://bit.ly/quaesita_msefav)
    performance on data your model hasn’t seen before. (It’s supposed to [*pre*dict](http://bit.ly/quaesita_parrot),
    not *post*dict.) You’ve done a perfect job of getting what you can from the information
    you have — the rest is error you can’t do anything about with your information.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说“尽可能好”时，我指的是在数据上，你的模型之前没有见过的情况下的[均方误差](http://bit.ly/quaesita_msefav)表现。（它应该是[*预测*](http://bit.ly/quaesita_parrot)，而不是*后验推断*。）你已经在从你所拥有的信息中尽可能地获取了所需的东西——剩下的误差是你无法用你现有的信息解决的。
