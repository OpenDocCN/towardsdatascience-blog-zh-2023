- en: A Beginner’s Guide to Building High-Quality Datasets for Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建高质量机器学习数据集的初学者指南
- en: 原文：[https://towardsdatascience.com/a-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565?source=collection_archive---------1-----------------------#2023-11-11](https://towardsdatascience.com/a-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565?source=collection_archive---------1-----------------------#2023-11-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565?source=collection_archive---------1-----------------------#2023-11-11](https://towardsdatascience.com/a-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565?source=collection_archive---------1-----------------------#2023-11-11)
- en: Tools and techniques for data cleaning, visualization, augmentation, and synthetic
    data generation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清洗、可视化、增强和合成数据生成的工具和技术
- en: '[](https://medium.com/@miriam.santos?source=post_page-----586a2ce7a565--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----586a2ce7a565--------------------------------)[](https://towardsdatascience.com/?source=post_page-----586a2ce7a565--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----586a2ce7a565--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----586a2ce7a565--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@miriam.santos?source=post_page-----586a2ce7a565--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----586a2ce7a565--------------------------------)[](https://towardsdatascience.com/?source=post_page-----586a2ce7a565--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----586a2ce7a565--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----586a2ce7a565--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----586a2ce7a565---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----586a2ce7a565--------------------------------)
    ·9 min read·Nov 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F586a2ce7a565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565&user=Miriam+Santos&userId=243289394aaa&source=-----586a2ce7a565---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----586a2ce7a565---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----586a2ce7a565--------------------------------)
    ·9分钟阅读·2023年11月11日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F586a2ce7a565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565&user=Miriam+Santos&userId=243289394aaa&source=-----586a2ce7a565---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F586a2ce7a565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565&source=-----586a2ce7a565---------------------bookmark_footer-----------)![](../Images/37b184efcb3a5a08d4483fdffd2ea4f8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F586a2ce7a565&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-beginners-guide-to-building-high-quality-datasets-for-machine-learning-586a2ce7a565&source=-----586a2ce7a565---------------------bookmark_footer-----------)![](../Images/37b184efcb3a5a08d4483fdffd2ea4f8.png)'
- en: Finding the real source of complexity on data can look a lot like playing “data
    detective” until you find the “golden key” that unlocks the really useful insights.
    Photo by [Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 找到数据复杂性的真实来源可能就像在扮演“数据侦探”，直到你找到解锁真正有用洞察的“黄金钥匙”。照片由[Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)提供，刊登在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Smart Data over Big Data. That’s the postulate of the “Data-Centric AI” paradigm.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 智能数据胜过大数据。这是“数据中心人工智能”范式的基本假设。
- en: '**More than just “simply preprocessing” data, data scientists should a build
    a continuous and systematic practice of understanding and improving their datasets.**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据科学家不仅仅是“简单地预处理”数据，还应该建立一种持续且系统的理解和改进数据集的实践。**'
- en: This will ultimately drive our focus from blindly pursuing higher classification
    results by throwing ever more complex algorithms to the problem to a **deep understanding
    of why the classification results are what they are, what is indeed the source
    of complexity of the problem, and how we can adjust the data so that classifiers
    can learn the problem better,** thus increasing their performance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这将**最终将我们的重点从盲目追求通过使用越来越复杂的算法来提升分类结果，转向对分类结果本身的深刻理解，问题的复杂性源自何处，以及如何调整数据以便分类器能够更好地学习问题**，从而提高其性能。
- en: 'If you’re new to machine learning, this might seem a little bit daunting: *“What
    are the best practices of building high-quality datasets and how to put them in
    place?”*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是机器学习新手，这可能会让你感到有些畏惧：*“构建高质量数据集的最佳实践是什么，如何实施？”*
- en: In this tutorial, we’ll go through a simple case of leveraging the Data-Centric
    AI paradigm to achieve high-quality data and improve our machine learning classification
    results.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将通过一个简单的案例来运用数据中心人工智能范式，以实现高质量数据并改善我们的机器学习分类结果。
- en: Following the mantra of Data-Centric AI — *it’s all about the data—*at no point
    will we delve into the model itself (honestly, it will be a simple decision tree).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据中心人工智能的原则——*一切都围绕数据*——我们不会深入到模型本身（说实话，它会是一个简单的决策树）。
- en: 'We’ll use the [Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)
    , freely available on Kaggle (License: [CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/)).
    You’ll can also find all the code and additional materials at the [Data-Centric
    AI Community GitHub](https://github.com/Data-Centric-AI-Community/awesome-python-for-data-science).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将使用[皮马印第安人糖尿病数据集](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)，该数据集在
    Kaggle 上免费提供（许可证：[CC0: 公开领域](https://creativecommons.org/publicdomain/zero/1.0/)）。你还可以在[数据中心人工智能社区
    GitHub](https://github.com/Data-Centric-AI-Community/awesome-python-for-data-science)找到所有代码和额外的材料。'
- en: '*Shall we get started?*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们开始吧？*'
- en: 'Step 1: Performing Data Profiling for Data Understanding'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 1：进行数据概况分析以理解数据
- en: Before we start curating our dataset, we need to **understand the problem**
    we’re trying to solve and the peculiarities of the data we’re working with. Thoroughly
    understanding our data characteristics, problem complexity, and use case domain
    is one of the first principles of Data-Centric AI.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始整理我们的数据集之前，我们需要**理解我们要解决的问题**以及我们处理的数据的特殊性。彻底理解数据特征、问题复杂性和使用案例领域是数据中心人工智能的基本原则之一。
- en: '**This will help us determine the next steps to move along your machine learning
    pipeline.**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**这将帮助我们确定下一步行动，以推进你的机器学习流程。**'
- en: 'When it comes to data profiling, there are several interesting open-source
    tools that you can explore: [I’ve made a review of a few myself](/awesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779),
    including `[ydata-profiling](https://github.com/ydataai/ydata-profiling)`, `[dataprep](https://github.com/sfu-db/dataprep)`,
    `[sweetviz](https://github.com/fbdesignpro/sweetviz)`, `[autoviz](https://github.com/AutoViML/AutoViz)`,
    and `[lux](https://github.com/lux-org/lux)`.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据概况分析，有几个有趣的开源工具可以探索：[我自己做了一些评测](/awesome-data-science-tools-to-master-in-2023-data-profiling-edition-29d29310f779)，包括`[ydata-profiling](https://github.com/ydataai/ydata-profiling)`、`[dataprep](https://github.com/sfu-db/dataprep)`、`[sweetviz](https://github.com/fbdesignpro/sweetviz)`、`[autoviz](https://github.com/AutoViML/AutoViz)`和`[lux](https://github.com/lux-org/lux)`。
- en: 'I currently use mostly [ydata-profiling](https://github.com/ydataai/ydata-profiling):
    I find it to be a top-notch tool for data practitioners that, rather than making
    us jump through pandas hoops to get the most of our data’s characteristics and
    visualizations, lets us do it all in a few lines of code.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我目前主要使用[ydata-profiling](https://github.com/ydataai/ydata-profiling)：我发现它是一个顶尖的工具，可以让数据从业者在几行代码中完成对数据特征和可视化的全面分析，而无需费劲地使用
    pandas。
- en: 'First, you’ll need to install ydata-profiling (better use a virtual environment
    for this — if you don’t know how, you can [check this 2-min video](https://www.youtube.com/watch?v=fvXZcpTwbtA),
    or this [full tutorial](https://www.youtube.com/watch?v=jj9X1_cKRwI) if you’ve
    never worked in conda environments before):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要安装ydata-profiling（最好使用虚拟环境——如果你不知道怎么做，你可以 [查看这个2分钟的视频](https://www.youtube.com/watch?v=fvXZcpTwbtA)，或者如果你从未在conda环境中工作过，可以查看这个
    [完整教程](https://www.youtube.com/watch?v=jj9X1_cKRwI)）：
- en: 'Then, we can get a complete overview of the data by saving a `.html` report
    of all the characteristics and visualizations we need to get started:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过保存一个`.html`报告来获得数据的完整概述，其中包含所有必要的特征和可视化：
- en: 'The data report let’s us know immediately the overall characteristics of our
    data and highlights some warnings that we might need to take into account:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 数据报告立即让我们了解数据的整体特征，并突出一些我们可能需要考虑的警告：
- en: '![](../Images/d33cfdfc97325f58a47c17349f181605.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d33cfdfc97325f58a47c17349f181605.png)'
- en: 'YData Profiling Report: Finding the dataset’s basis statistics, visualizations,
    and quality warnings.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: YData Profiling报告：查找数据集的基本统计信息、可视化和质量警告。
- en: The datasets contains 768 observations and 9 variables/features. While 8 are
    numeric, 1 is identified as categorical (`Outcome` seems to be our target). There
    are no duplicate rows and ***apparently*** there are no missing values. Finally,
    some `High Correlation` warning sare found among the the features. Moreover, several
    features have a large number of `Zeros`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含768个观察值和9个变量/特征。虽然8个是数值型的，1个被识别为分类变量（`Outcome`似乎是我们的目标）。没有重复的行，并且***显然***没有缺失值。最后，特征中发现了一些`高相关性`警告。此外，几个特征有大量的`零值`。
- en: Now it’s time to play data detective. `High Correlations` are rather expected
    in biological features, but how about these `Zero` values?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候充当数据侦探了。`高相关性`在生物特征中是比较常见的，但这些`零`值怎么样呢？
- en: 'Looking at some of the features highlighted (e.g., `BMI`), we can see that
    these values are quite far off from the overall distribution. And resorting to
    domain knowledge, these “0” values are actually nonsensical: a 0 value is OK for
    `Pregnancies` but for BMI, Glucose, Insulin, Blood Pressure, or Skin Thickness
    is invalid.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 查看一些突出的特征（例如`BMI`），我们可以看到这些值与整体分布相差甚远。根据领域知识，这些“0”值实际上是没有意义的：`怀孕次数`的0值是可以接受的，但BMI、葡萄糖、胰岛素、血压或皮肤厚度的0值则是无效的。
- en: '![](../Images/6592ca40c0a8d3d714a7124930b80a97.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6592ca40c0a8d3d714a7124930b80a97.png)'
- en: 'YData Profiling Report: BMI feature, indicating that zero values are rather
    “off” from the distribution.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: YData Profiling报告：BMI特征，表明零值与分布有很大差距。
- en: 'We quickly realize what these zeros are encoding: **missing data**.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快意识到这些零值编码了什么：**缺失数据**。
- en: For now we’ll get on fixing this issue, but a thorough process of EDA can comprehend
    a lot more. Check this [Essential Guide to Exploratory Data Analysis](https://medium.com/towards-data-science/a-data-scientists-essential-guide-to-exploratory-data-analysis-25637eee0cf6)
    to see what else you could uncover from your data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将解决这个问题，但一个彻底的EDA过程可以涵盖更多内容。查看这个 [探索性数据分析的基本指南](https://medium.com/towards-data-science/a-data-scientists-essential-guide-to-exploratory-data-analysis-25637eee0cf6)
    以了解你可以从数据中发现什么其他信息。
- en: 'Step 2: Investigating Data Quality Issues'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2步：调查数据质量问题
- en: Now that we found that some columns have invalid zero values, we can start by
    handling the missing data issue on our dataset.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们发现某些列有无效的零值，我们可以开始处理数据集中的缺失数据问题。
- en: '**Many machine learning models and scikit-learn estimators do not natively
    support missing values**, so we need to handle these NaNs somehow before feeding
    our dataset to the estimator.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**许多机器学习模型和scikit-learn估算器本身不支持缺失值**，因此在将数据集提供给估算器之前，我们需要以某种方式处理这些NaNs。'
- en: 'First, lets mark these 0 values as NaN values:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将这些0值标记为NaN值：
- en: '**Now, we can use data imputation to replace the NaN observations with plausible
    replacement values.**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**现在，我们可以使用数据填充来用合理的替代值替换NaN观察值。**'
- en: 'The “no free lunch” theorem tells us that there is no best solution for every
    situation — we should investigate how different solutions affect the complexity
    of our training data and determine what boosts our machine learning model the
    best. That’s actually another principle of Data-Centric AI: *constant iteration
    and improvement*.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: “没有免费午餐”定理告诉我们，没有一种最佳的解决方案适用于所有情况——我们应该调查不同解决方案对训练数据复杂性的影响，并确定什么能最好地提升我们的机器学习模型。这实际上是数据中心AI的另一个原则：*不断迭代和改进*。
- en: 'For now will use a very simple method — `SimpleImputer` — to replace the zero
    values with the mean value of each feature. This is a very naive approach that
    is likely to create some undesired “spikes” in our distributions, but the goal
    is simply to showcase how to highlight and impute missing data, we can try better
    approaches later on:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们将使用一个非常简单的方法——`SimpleImputer`——将零值替换为每个特征的均值。这是一个非常初级的方法，可能会在我们的分布中产生一些不希望有的“尖峰”，但目标只是展示如何突出和填补缺失数据，我们可以稍后尝试更好的方法：
- en: 'Now, we can then try out a very simple decision tree classifier and see what
    would be the baseline of our classification results. As a side note, decision
    trees can be extended to support missing values naturally, via surrogate splits
    or other methods. Indeed, in [scikit-learn’s documentation](https://scikit-learn.org/stable/modules/tree.html#missing-values-support)
    seems like decision trees do have built-in support for missing values in some
    conditions in the current version ( `1.3.2`). However, as I was using version
    `1.2.2` , I stumbled upon this error:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以尝试一个非常简单的决策树分类器，看看我们的分类结果的基线是什么。作为旁注，决策树可以扩展以自然支持缺失值，通过替代拆分或其他方法。确实，在
    [scikit-learn的文档](https://scikit-learn.org/stable/modules/tree.html#missing-values-support)
    中似乎决策树在当前版本 (`1.3.2`) 中确实支持缺失值。然而，当我使用版本 `1.2.2` 时，我遇到了这个错误：
- en: '![](../Images/3d5570a443c728f87f81aa6fe8bd82df.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d5570a443c728f87f81aa6fe8bd82df.png)'
- en: Still, even if the NaN values are dealt with internally, **training your models
    with missing data is not a good practice**, as it will jeopardize the concepts
    that the model learns from messy and limited information.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 即使NaN值在内部处理了，**用缺失数据训练你的模型也不是一个好习惯**，因为这会危及模型从混乱和有限的信息中学习到的概念。
- en: '![](../Images/5b0297f4de098b794bcbdcb1e364000f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b0297f4de098b794bcbdcb1e364000f.png)'
- en: 'Here’s the confusion matrix:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是混淆矩阵：
- en: The classification results are not great. Keep in mind that we’re using a simple
    decision tree, but still… there is a significant different between the prediction
    for our target categories. **Why is the classifier performing better for class
    “0” than class “1”?**
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 分类结果不是很好。请记住，我们使用的是简单决策树，但仍然……我们目标类别的预测存在显著差异。**为什么分类器在类别“0”上的表现优于类别“1”？**
- en: 'Step 3: Augmenting Underrepresented Classes'
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3步：增强不足代表的类别
- en: 'If we were paying attention in Step 1 (*maybe you’ve discovered it already*),
    our target class, `Outcome`, is imbalanced. Maybe not at the point to trigger
    a warning in the default settings (the [default threshold](https://docs.profiling.ydata.ai/4.5/advanced_settings/available_settings/#variable-summary-settings)
    is `0.5`), but enough to still bias the classifier towards the majority class,
    neglecting the minority one. This is clear from the data visualization presented
    in the Profiling Report:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在第1步中有留意到（*也许你已经发现了*），我们的目标类别`Outcome`是不平衡的。虽然可能不足以在默认设置中触发警告（[默认阈值](https://docs.profiling.ydata.ai/4.5/advanced_settings/available_settings/#variable-summary-settings)是`0.5`），但足以使分类器对多数类别产生偏向，忽视少数类别。从Profiling
    Report中提供的数据可视化中可以清楚地看出这一点：
- en: '![](../Images/8cb5549bd2baeac466ac5c50f245051e.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cb5549bd2baeac466ac5c50f245051e.png)'
- en: 'YData Profiling Report: Outcome classes “0” and “1” are not equally represented.
    Classifiers will naturally be more biased towards the well-represented class,
    “0”, neglecting class “1”.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 'YData Profiling Report: 结果类别“0”和“1”并不均等地代表。分类器自然会对代表性较强的类别“0”更有偏向，忽视类别“1”。'
- en: 'Note that while missing data can be caused by several errors during data collection,
    transmission or storage, **the class imbalance may reflect a natural characteristic
    of the domain**: e.g., there are simply less patients diagnosed with diabetes
    in this medical center.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然缺失数据可能是由于数据收集、传输或存储过程中出现的多个错误造成的，**类不平衡可能反映了领域的自然特征**：例如，这个医疗中心诊断出的糖尿病患者较少。
- en: '**Nevertheless, it is still important to act over the training data to guarantee
    that the model does not overlook the minority cases: in fact, that’s what we’re
    trying to predict more accurately.**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**然而，对训练数据进行处理仍然很重要，以确保模型不会忽视少数类别：事实上，这就是我们试图更准确预测的内容。**'
- en: '**A false positive is bad since it will give the wrong information to a healthy
    patient the she has diabetes.** But when additional tests are made, this will
    be just a “scare”.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**假阳性是糟糕的，因为它会给健康患者错误的信息，告诉她她有糖尿病。** 但当进行额外的测试时，这将只是一个“惊吓”。'
- en: '**However, in this case, a false negative is worse.** We’d be telling a patient
    with diabetes that everything is OK, she passes undiagnosed, and the disease progresses.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**然而，在这种情况下，假阴性更糟。** 我们将告诉一位患有糖尿病的患者一切正常，她未被诊断出来，疾病继续发展。'
- en: '**One way to increase these numbers is by using data oversampling techniques.**
    Data Oversampling is a popular technique among data practitioners to adjust the
    distributions of a dataset — i.e., the ratio between the existing classes or categories
    in data — thus mitigating the imbalanced data problem.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**增加这些数字的一种方法是使用数据过采样技术。** 数据过采样是数据从业者中流行的一种技术，用于调整数据集中现有类别或分类之间的比例，从而缓解数据不平衡问题。'
- en: '**And is just one of many interesting and useful applications of Synthetic
    Data.**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**这只是合成数据的许多有趣和有用应用之一。**'
- en: While [synthetic data can have several interpretations](https://ydata.ai/resources/10-most-frequently-asked-questions-about-synthetic-data)
    — e.g., “fake data”, “dummy data”, “simulated data” — here we’re referring to
    “data-driven” synthetic data generation.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然[合成数据可能有多种解释](https://ydata.ai/resources/10-most-frequently-asked-questions-about-synthetic-data)
    — 例如，“假数据”，“虚拟数据”，“模拟数据” — 但在这里我们指的是“数据驱动的”合成数据生成。
- en: '**In that sense, synthetic data is artificially generated that that preserves
    the characteristics of real data — its structure, statistical properties, dependencies,
    and correlations.**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**从这个意义上说，合成数据是人工生成的，保留了真实数据的特征 — 结构、统计属性、依赖关系和相关性。**'
- en: There are a plethora of methods and open-source tools to generate synthetic
    data — `[ydata-synthetic](https://github.com/ydataai/ydata-synthetic)`, `[sdv](https://github.com/sdv-dev/SDV)`,
    `[gretel-synthetics](https://github.com/gretelai/gretel-synthetics)`, `[nbsynthetic](https://github.com/NextBrain-ai/nbsynthetic)`,
    and `[synthcity](https://github.com/vanderschaarlab/synthcity)` are just some
    that I’ve experimented with in the past.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有大量的方法和开源工具可用于生成合成数据 — `[ydata-synthetic](https://github.com/ydataai/ydata-synthetic)`,
    `[sdv](https://github.com/sdv-dev/SDV)`, `[gretel-synthetics](https://github.com/gretelai/gretel-synthetics)`,
    `[nbsynthetic](https://github.com/NextBrain-ai/nbsynthetic)`, 和 `[synthcity](https://github.com/vanderschaarlab/synthcity)`
    只是我过去尝试过的一些。
- en: 'And again… there are “no free lunches”: choosing the most appropriate method
    will invariably depend on the objective for which the synthetic data is needed.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地…… 这里没有“免费午餐”：选择最合适的方法将始终取决于需要合成数据的目标。
- en: To have a quick grasp of how synthetic data can be used for augmentation, we’ll
    leverage the `[ydata-synthetic](https://github.com/ydataai/ydata-synthetic)` package,
    and experiment with their [Gaussian Mixture Models](https://ydata.ai/resources/synthetic-data-generation-with-gaussian-mixture-models).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速掌握合成数据如何用于增强，我们将利用`[ydata-synthetic](https://github.com/ydataai/ydata-synthetic)`包，并尝试他们的[高斯混合模型](https://ydata.ai/resources/synthetic-data-generation-with-gaussian-mixture-models)。
- en: 'First, we’ll need to install the package:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要安装该包：
- en: 'And once that’s done, creating synthetic data is super straightforward:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成这些步骤，创建合成数据就非常简单了：
- en: 'After we have our synthetic data, we can simply take out a subset of the newly
    generated minority class samples generated by sampling from the synthetic data,
    and add it to the training data to create a balanced (i.e., 50%-50%) distribution:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 获得我们的合成数据之后，我们可以简单地从合成数据中抽取新生成的少数类样本的子集，并将其添加到训练数据中，以创建一个平衡（即50%-50%）的分布：
- en: 'Let’s see how that impacts the learning of our decision tree and its subsequent
    results:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 看看这如何影响我们决策树的学习及其随后的结果：
- en: '![](../Images/5188a10a712e1e78cfab9912fd45de6b.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5188a10a712e1e78cfab9912fd45de6b.png)'
- en: 'And the confusion matrix:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以及混淆矩阵：
- en: Note how such a simple modification of our training set resulted in a performance
    boost of our F-score in 10% and a significant improvement of the minority class
    sensitivity results (from 53% to 73%).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到我们对训练集进行如此简单的修改，导致我们的F-score提升了10%，少数类敏感性结果显著改善（从53%提高到73%）。
- en: '**Here lies the beauty of the Data-Centric AI paradigm: without ever touching
    our model parametrization, we’ve significantly improved the quality of our training
    set with very simple heuristics and standard techniques** — imagine what we could
    do with more advanced strategies and specialized data preparation pipelines!'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**这就是数据中心化AI范式的美妙之处：在不触及模型参数化的情况下，我们用非常简单的启发式方法和标准技术显著改善了我们的训练集的质量** — 想象一下如果我们采用更先进的策略和专门的数据准备流水线能做些什么！'
- en: 'Sure, class 0''s recall suffered a bit, but ultimately, we need **this model
    to be more sensitive than specific** (i.e., detect better the positive class than
    the negative class) due to the particular constraints that we’re dealing with:
    disease diagnosis — again, **another principle of Data-Centric AI: methods and
    results need to be evaluated based on the domain’s needs and constraints.**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，类别0的召回率有些下降，但最终，我们需要**这个模型比特异性更敏感**（即更好地检测正类而非负类），这是由于我们所面临的特定约束：疾病诊断——再一次，**数据中心人工智能的另一个原则：方法和结果需要根据领域的需求和约束进行评估。**
- en: Final Thoughts and Further Directions
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考和进一步方向
- en: Throughout this article, we’ve experimented with the Data-Centric AI paradigm
    with a very hands-on, practical use case.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们用一个非常实际的案例实验了数据中心人工智能范式。
- en: We started, as always, by understanding our data. We discovered, investigated,
    and solved particular data quality issues such as **missing data**, **and improving
    our training data with synthetic data to overcome the imbalanced nature of the
    domain.** Of course, for such a quick and simple case study, we focused on simple
    heuristics to get the job done, but the work of a data scientist never stop theres.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们总是从理解数据开始。我们发现、调查并解决了特定的数据质量问题，如**缺失数据**，**以及通过合成数据来改善我们的训练数据，以克服领域的不平衡性。**当然，对于这样一个快速而简单的案例研究，我们专注于简单的启发式方法来完成工作，但数据科学家的工作从未止步于此。
- en: '*How would the results change if we considered a different imputation method?
    How could we have achieved a better fit in our synthetic data generation? Should
    we have balanced both classes equally or perhaps increase the representation of
    the minority class even higher? Could some feature transformation or dimensionality
    reduction helped the classification result? Should we have removed some cofounding
    features?*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果我们考虑不同的插补方法，结果会如何变化？我们如何在合成数据生成中获得更好的拟合？我们是否应该平衡两个类别，还是提高少数类别的表示？某些特征转换或降维是否有助于分类结果？我们是否应该去除一些混淆特征？*'
- en: All of these questions seem unknowable at the start of any machine learning
    project. **But as we start to measure and uncover the source of complexity in
    each dataset, we get better insights on what methods could improve classification
    results (a sort of “meta-learning” approach).** And sure enough, the data needs
    to be manipulated and improved according to both the data characteristics and
    the ultimate goal of the project.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些问题在任何机器学习项目开始时似乎都是不可知的。**但是随着我们开始测量和揭示每个数据集中的复杂源，我们可以获得更好的见解，了解哪些方法可以改进分类结果（一种“元学习”方法）。**当然，数据需要根据数据特征和项目的最终目标进行处理和改进。
- en: Producing a pre-defined pipeline and treating data preparation like a one-fits-all
    solution is similar to flying blind. **Instead, a skilled data scientist continuously
    plays data detective and tries to find the best techniques based on the clues
    that the data leaves out for us to catch.** And it usually does. We just need
    to keep our eyes sharp!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 生产一个预定义的流程并将数据准备视为一刀切的解决方案，就像是盲目飞行一样。**相反，一个熟练的数据科学家会不断扮演数据侦探的角色，并尝试根据数据留给我们的线索找到最佳的技术。**通常这确实有效。我们只需要保持警觉！
- en: I hope you’ve enjoyed the tutorial, and as always, feedback, questions, and
    suggestions are much appreciated. Let me know what other topics you would like
    me to write about in the comments!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你喜欢这个教程，像往常一样，反馈、问题和建议非常受欢迎。请在评论中告诉我你希望我写关于哪些其他主题！
- en: About me
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: Ph.D., Machine Learning Researcher, Educator, Data Advocate, and overall “jack-of-all-trades”.
    Here on Medium, I write about **Data-Centric AI and Data Quality**, educating
    the Data Science & Machine Learning communities on how to move from imperfect
    to intelligent data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 博士，机器学习研究员，教育者，数据倡导者，以及全能型人才。在Medium上，我撰写关于**数据中心人工智能和数据质量**的文章，教育数据科学和机器学习社区如何将不完美的数据转变为智能数据。
- en: '[Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据中心人工智能社区](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
