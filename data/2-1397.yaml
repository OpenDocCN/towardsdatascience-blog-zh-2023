- en: 'Large Models Meet Big Data: Spark and LLMs in Harmony'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型模型遇见大数据：Spark 和 LLMs 的和谐
- en: 原文：[https://towardsdatascience.com/large-models-meet-big-data-spark-and-llms-in-harmony-5e2976b69b62](https://towardsdatascience.com/large-models-meet-big-data-spark-and-llms-in-harmony-5e2976b69b62)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/large-models-meet-big-data-spark-and-llms-in-harmony-5e2976b69b62](https://towardsdatascience.com/large-models-meet-big-data-spark-and-llms-in-harmony-5e2976b69b62)
- en: DATA ENGINEERING & GENERATIVE AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据工程与生成式 AI
- en: '*A step-by-step guide to use Apache Spark and large language models*'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*使用 Apache Spark 和大型语言模型的逐步指南*'
- en: '[](https://tamimi-naser.medium.com/?source=post_page-----5e2976b69b62--------------------------------)[![Naser
    Tamimi](../Images/8d43c66ea3c0ef9b49c7d33dbc008c28.png)](https://tamimi-naser.medium.com/?source=post_page-----5e2976b69b62--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5e2976b69b62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5e2976b69b62--------------------------------)
    [Naser Tamimi](https://tamimi-naser.medium.com/?source=post_page-----5e2976b69b62--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://tamimi-naser.medium.com/?source=post_page-----5e2976b69b62--------------------------------)[![Naser
    Tamimi](../Images/8d43c66ea3c0ef9b49c7d33dbc008c28.png)](https://tamimi-naser.medium.com/?source=post_page-----5e2976b69b62--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5e2976b69b62--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5e2976b69b62--------------------------------)
    [Naser Tamimi](https://tamimi-naser.medium.com/?source=post_page-----5e2976b69b62--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5e2976b69b62--------------------------------)
    ·6 min read·Dec 5, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5e2976b69b62--------------------------------)
    ·6分钟阅读·2023年12月5日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/4b2f8379a79a83aae121976d9e91f2c7.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b2f8379a79a83aae121976d9e91f2c7.png)'
- en: The image is generated by Midjourney.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 该图像由 Midjourney 生成。
- en: Generative AI, including Large Language Models (LLMs), is revolutionizing different
    aspects of human life. Over the past five years, Generative AI has evolved from
    a research project into a real-life application for many people. As a data engineer
    interested in Generative AI, I have always asked myself, what does this technology
    bring to my work and Data Engineering applications? There are some common applications
    of Gen AI and LLMs for engineers such as pilot coding, assisting in documentation,
    and so on. But, here, I am evaluating some of the more specialized uses of Gen
    AI and LLMs for data engineering. If you are interested in this topic, please
    read this article and follow me on [Medium](https://tamimi-naser.medium.com/)
    and [Linkedin](https://www.linkedin.com/in/nasertamimi/) to get more articles
    about other use cases.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI，包括大型语言模型（LLMs），正在革新人类生活的各个方面。在过去五年里，生成式 AI 从一个研究项目发展成为许多人日常生活中的实际应用。作为一名对生成式
    AI 感兴趣的数据工程师，我一直在问自己，这项技术为我的工作和数据工程应用带来了什么？对于工程师来说，生成式 AI 和 LLMs 的一些常见应用包括自动编码、协助文档编写等等。但是，在这里，我正在评估生成式
    AI 和 LLMs 在数据工程中的一些更专业的使用。如果你对这个话题感兴趣，请阅读这篇文章，并关注我在 [Medium](https://tamimi-naser.medium.com/)
    和 [Linkedin](https://www.linkedin.com/in/nasertamimi/) 上的其他文章，以获取更多关于其他用例的内容。
- en: 'LLMs: Powerful Tools for Transformations'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs：强大的变革工具
- en: It is not new that data engineers love structured and abstracted data. But,
    the world is full of unstructured and disorganized data that requires the attention
    of data engineers. Transformations on unstructured data are always complicated
    and sometimes impossible with traditional tools. Historically, one of these challenging
    unstructured data was text (e.g. comments, reviews, conversation). Simple transformations
    on texts were not a big deal, but complicated transformations can extract more
    information from texts and we can make more rich data sets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师喜欢结构化和抽象化数据，这已经不是什么新鲜事了。但是，世界上充满了需要数据工程师关注的非结构化和杂乱的数据。对非结构化数据的转换总是很复杂，有时用传统工具是无法完成的。历史上，其中一种具有挑战性的非结构化数据是文本（例如评论、评价、对话）。对文本的简单转换并不难，但复杂的转换可以从文本中提取更多信息，我们可以生成更丰富的数据集。
- en: Examples of complicated text transformations could be extracting names and objects
    from a text, sentiment analysis on a review or a comment, masking important information
    (e.g. private data, user data) in the stored texts, translating from one language
    to a standard language, text summarization, and so on. The good news is nowadays
    LLMs can do all sorts of these transformations. Therefore, I believe one of hundreds
    LLMs applications in data engineering, is to act as transform functions for complicated
    data such as texts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂文本转换的例子可能包括从文本中提取姓名和对象、对评论或意见进行情感分析、在存储的文本中掩盖重要信息（例如私人数据、用户数据）、从一种语言翻译到标准语言、文本摘要等。好消息是现在的
    LLM 可以完成所有这些转换。因此，我相信在数据工程中，LLM 的应用之一就是作为复杂数据（如文本）的转换函数。
- en: In this article, I will show this ability of LLMs via Apache Spark, a powerful
    distributed data processing system. More specifically, I am going to use, a small
    LLM (t5-small) from Hugging Face as an Apache Spark UDF function and apply a specific
    transformation (sentiment analysis) to a sample data set.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将通过 Apache Spark 展示 LLM 的这一能力，Apache Spark 是一个强大的分布式数据处理系统。更具体地说，我将使用
    Hugging Face 的一个小型 LLM（t5-small）作为 Apache Spark UDF 函数，并对一个示例数据集应用特定的转换（情感分析）。
- en: Set up the project
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置项目
- en: First, we need a system with Apache Spark. You can either install Apache Spark
    on your local system or use services such as AWS EMR. I used AWS EMR and set up
    a small cluster for testing. There are many articles on how to install Apache
    Spark on your local machine or use AWS EMR which you can use them. Here, I am
    assuming you already have Apache Spark on your system.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个 Apache Spark 系统。你可以在本地系统上安装 Apache Spark，也可以使用 AWS EMR 等服务。我使用了 AWS
    EMR 并设置了一个小型集群进行测试。有很多关于如何在本地机器上安装 Apache Spark 或使用 AWS EMR 的文章，你可以参考它们。在这里，我假设你已经在系统上安装了
    Apache Spark。
- en: I also chose Python 3.8 for this project. We are going to use Hugging Face libraries
    and they are well aligned with Python. If you are using AWS EMR, you should already
    have it on your system. Otherwise, you need to install Python 3.8.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我还为这个项目选择了 Python 3.8。我们将使用 Hugging Face 库，它们与 Python 的兼容性很好。如果你使用 AWS EMR，你的系统上应该已经有
    Python 3.8。否则，你需要安装 Python 3.8。
- en: Now, that you have both Apache Spark and Python 3 on your system, it is time
    to install the necessary libraries for testing this project. Run the following
    pip commands to install libraries. Here we are installing PySpark to run Spark
    jobs, and the Transformers library from Hugging Face (which enables us to use
    hundreds of models including LLMs).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经在系统上安装了 Apache Spark 和 Python 3，接下来是安装测试此项目所需的库。运行以下 pip 命令来安装库。我们在这里安装
    PySpark 以运行 Spark 任务，以及来自 Hugging Face 的 Transformers 库（这使我们能够使用包括 LLM 在内的数百种模型）。
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Coding Time
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编码时间
- en: Start with creating a new Python file. I named it spark_llm_test.py. First,
    we need to import libraries as well as create a new spark session.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先创建一个新的 Python 文件。我将其命名为 spark_llm_test.py。首先，我们需要导入库并创建一个新的 Spark 会话。
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For this test, I created a dummy table with only two columns. The first column
    is an index and the second column is a random sentence. My goal for this project
    is to do sentiment analysis on the second column. Obviously, in a real-life use
    case, you probably read your Spark dataframe from a table (e.g. Hive Table) with
    much more complex data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个测试，我创建了一个仅有两列的虚拟表。第一列是索引，第二列是随机句子。我为这个项目设定的目标是对第二列进行情感分析。显然，在实际使用情况下，你可能会从一个包含更复杂数据的表（例如
    Hive 表）中读取 Spark 数据帧。
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For this purpose, I use the “Flan T5” model which is fine-tuned for various
    tasks, including sentiment analysis. As you see here, the model and tokenizer
    setup is very easy using the Hugging Face Transformers library.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我使用了“Flan T5”模型，该模型经过针对各种任务的微调，包括情感分析。如你所见，使用 Hugging Face Transformers 库，模型和分词器的设置非常简单。
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now it is time to define our Spark UDF function. Spark will call this function
    on every row of our data to transform the data as we specify in this function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是定义我们的 Spark UDF 函数的时候了。Spark 将在每一行数据上调用这个函数，以按照我们在函数中指定的方式转换数据。
- en: One important point regarding this UDF function. As you see, we did not instantiate
    the model and tokenizer inside the UDF function. The reason is that defining the
    model and tokenizer (even such a small LLM model) takes a large overhead for our
    processing. It means for every row that we call this UDF function, the model and
    tokenizer should loaded on the worker nodes and the transformation (which is an
    inference here) should happen after that. It definitely slows down our process
    significantly. To avoid it, we loaded the model and tokenizer outside of the UDF
    function.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个 UDF 函数，有一点很重要。正如你所见，我们没有在 UDF 函数内部实例化模型和分词器。原因是定义模型和分词器（即使是这样一个小的 LLM 模型）需要较大的处理开销。这意味着每次调用这个
    UDF 函数时，模型和分词器都需要在工作节点上加载，然后进行转换（这里是推断）。这无疑会显著减慢我们的处理速度。为避免这种情况，我们在 UDF 函数外部加载了模型和分词器。
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Finally, we need to register the UDF function and create a new column to save
    the sentiment analysis results.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要注册 UDF 函数并创建一个新列以保存情感分析结果。
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Below, you can find the entire code.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，你可以找到完整的代码。
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you run the code using the spark-submit command, you will get the following
    results. As you see Flan T5 model did a good job on recognizing the positive sentences
    from negative ones.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 spark-submit 命令运行代码，你将得到以下结果。正如你所见，Flan T5 模型在识别正面句子与负面句子方面表现良好。
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Future of Spark and LLMs
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spark 和 LLMs 的未来
- en: Congratulations! You have successfully executed Flan T5 as a Spark job. To simplify,
    we omitted several details, including how master and worker nodes transfer model
    weights to conduct inferences. This topic could be extensive for future discussions
    on whether Spark can be efficiently employed for inferences using LLMs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已成功将 Flan T5 作为 Spark 作业执行。为了简化，我们省略了一些细节，包括主节点和工作节点如何传输模型权重以进行推断。这个话题可能会在未来的讨论中涉及，即
    Spark 是否可以高效地用于使用 LLMs 进行推断。
- en: In addition, here we used Spark for data transformation (an application). But
    if Spark can be used efficiently in the model development process, that’s another
    big win for Apache Spark.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们在这里使用了 Spark 进行数据转换（一个应用）。但如果 Spark 可以在模型开发过程中高效使用，那将是 Apache Spark 的另一个重大胜利。
- en: And finally, it was just a simple example of batch processing. Another application
    of Spark and LLMs could be stream processing and providing real-time analysis
    on those kinds of data streams. Definitely, it was a good start to using Spark
    and LLMs, but the applications and collaborations between these two tools are
    endless.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这只是一个简单的批处理示例。Spark 和 LLMs 的另一个应用可能是流处理，并对这些数据流提供实时分析。毫无疑问，这是使用 Spark 和 LLMs
    的良好开端，但这两个工具之间的应用和协作是无穷无尽的。
