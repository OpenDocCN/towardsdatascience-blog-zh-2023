- en: 5 Ways to Get Interesting Datasets for Your Next Data Project (Not Kaggle)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取你下一个数据项目的有趣数据集的5种方法（非Kaggle）
- en: 原文：[https://towardsdatascience.com/5-ways-to-get-interesting-datasets-for-your-next-data-project-not-kaggle-71cf76eef64b](https://towardsdatascience.com/5-ways-to-get-interesting-datasets-for-your-next-data-project-not-kaggle-71cf76eef64b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/5-ways-to-get-interesting-datasets-for-your-next-data-project-not-kaggle-71cf76eef64b](https://towardsdatascience.com/5-ways-to-get-interesting-datasets-for-your-next-data-project-not-kaggle-71cf76eef64b)
- en: Bored of Kaggle and FiveThirtyEight? Here are the alternative strategies I use
    for getting high-quality and unique datasets
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对Kaggle和FiveThirtyEight感到厌倦了吗？这里是我用来获取高质量和独特数据集的替代策略。
- en: '[](https://medium.com/@mattchapmanmsc?source=post_page-----71cf76eef64b--------------------------------)[![Matt
    Chapman](../Images/7511deb8d9ed408ece21031f6614c532.png)](https://medium.com/@mattchapmanmsc?source=post_page-----71cf76eef64b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----71cf76eef64b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----71cf76eef64b--------------------------------)
    [Matt Chapman](https://medium.com/@mattchapmanmsc?source=post_page-----71cf76eef64b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mattchapmanmsc?source=post_page-----71cf76eef64b--------------------------------)[![Matt
    Chapman](../Images/7511deb8d9ed408ece21031f6614c532.png)](https://medium.com/@mattchapmanmsc?source=post_page-----71cf76eef64b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----71cf76eef64b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----71cf76eef64b--------------------------------)
    [Matt Chapman](https://medium.com/@mattchapmanmsc?source=post_page-----71cf76eef64b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----71cf76eef64b--------------------------------)
    ·7 min read·Jun 24, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----71cf76eef64b--------------------------------)
    ·7分钟阅读·2023年6月24日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e876fa791ac0f463d9091464b6651ba9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e876fa791ac0f463d9091464b6651ba9.png)'
- en: Image by [Efe Kurnaz](https://unsplash.com/@efekurnaz) on [Unsplash](https://unsplash.com/photos/RnCPiXixooY)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源 [Efe Kurnaz](https://unsplash.com/@efekurnaz) 在 [Unsplash](https://unsplash.com/photos/RnCPiXixooY)
- en: The key to a great data science project is a great dataset, but finding great
    data is much easier said than done.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一个伟大的数据科学项目的关键是一个优秀的数据集，但找到优质数据远比说起来容易。
- en: I remember back when I was studying for my master’s in Data Science, a little
    over a year ago. Throughout the course, I found that coming up with project ideas
    was the easy part — it was *finding good datasets* that I struggled with the most.
    I would spend hours scouring the internet, pulling my hair out trying to find
    juicy data sources and getting nowhere.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我记得在我读数据科学硕士学位时，一年多前。整个课程中，我发现想出项目想法很简单——真正让我困扰的是*找到好的数据集*。我会花几个小时在互联网上搜索，拼命想找到有用的数据源，但始终无功而返。
- en: Since then, I’ve come a long way in my approach, and in this article I want
    to share with you the 5 strategies that I use to find datasets. If you’re bored
    of standard sources like Kaggle and FiveThirtyEight, these strategies will enable
    you to get data that are unique and much more tailored to the specific use cases
    you have in mind.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从那时起，我在方法上取得了很大进展，在这篇文章中，我想与您分享我用来寻找数据集的5种策略。如果你对Kaggle和FiveThirtyEight这样的标准来源感到厌倦，这些策略将使你能够获得独特且更加贴合你特定用例的数据。
- en: 1\. Make your own data
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 制作自己的数据
- en: Yep, believe it or not, this is actually a legit strategy. It’s even got a fancy
    technical name (“synthetic data generation”).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 没错，无论你信不信，这确实是一个合法的策略。它甚至有一个花哨的技术名称（“合成数据生成”）。
- en: If you’re trying out a new idea or have very specific data requirements, making
    synthetic data is a fantastic way to get original and tailored datasets.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在尝试一个新想法或有非常具体的数据需求，制作合成数据是获取原创且量身定制的数据集的绝佳方式。
- en: 'For example, let’s say that you’re trying to build a churn prediction model
    — a model that can predict how likely a customer is to leave a company. Churn
    is a pretty common “operational problem” faced by many companies, and tackling
    a problem like this is a great way to show recruiters that you can use ML to solve
    commercially-relevant problems, as I’ve argued previously:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，假设你正在尝试建立一个客户流失预测模型——一个可以预测客户离开公司的可能性模型。流失是许多公司面临的一个相当常见的“运营问题”，解决这样的问题是展示你可以利用机器学习解决商业相关问题的绝佳方式，就像我之前所说的：
- en: '[](/how-to-find-unique-data-science-project-ideas-that-make-your-portfolio-stand-out-1c2ddfdbefa6?source=post_page-----71cf76eef64b--------------------------------)
    [## How to Find Unique Data Science Project Ideas That Make Your Portfolio Stand
    Out'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-find-unique-data-science-project-ideas-that-make-your-portfolio-stand-out-1c2ddfdbefa6?source=post_page-----71cf76eef64b--------------------------------)
    [## 如何找到独特的数据科学项目创意，使你的作品集脱颖而出'
- en: 'Forget Titanic and MNIST: Pick a unique project that builds your skills and
    helps you stand out from the crowd'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 忘掉 Titanic 和 MNIST：选择一个独特的项目来提升你的技能，帮助你在众人中脱颖而出
- en: towardsdatascience.com](/how-to-find-unique-data-science-project-ideas-that-make-your-portfolio-stand-out-1c2ddfdbefa6?source=post_page-----71cf76eef64b--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-find-unique-data-science-project-ideas-that-make-your-portfolio-stand-out-1c2ddfdbefa6?source=post_page-----71cf76eef64b--------------------------------)
- en: 'However, if you search online for “churn datasets,” you’ll find that there
    are (at the time of writing) only two main datasets obviously available to the
    public: the [Bank Customer Churn Dataset](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset),
    and the [Telecom Churn Dataset](https://www.kaggle.com/mnassrib/telecom-churn-datasets).
    These datasets are a fantastic place to start, but might not reflect the kind
    of data required for modelling churn in other industries.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你在网上搜索“客户流失数据集”，你会发现（截至写作时）公开可用的主要数据集只有两个： [银行客户流失数据集](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset)
    和 [电信流失数据集](https://www.kaggle.com/mnassrib/telecom-churn-datasets)。这些数据集是一个很好的起点，但可能无法反映其他行业所需的数据类型。
- en: Instead, you could try creating synthetic data that’s more tailored to your
    requirements.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，你可以尝试创建更符合你要求的合成数据。
- en: 'If this sounds too good to be true, here’s an example dataset which I created
    with just a short prompt to that old chestnut, ChatGPT:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来太美好而不真实，这里有一个我用一个简短提示创建的示例数据集，这个提示是发给 ChatGPT 的老方法：
- en: '![](../Images/38fca05145d88471423f4ed5fb19d78b.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38fca05145d88471423f4ed5fb19d78b.png)'
- en: Image by author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Of course, ChatGPT is limited in the speed and size of the datasets it can create,
    so if you want to upscale this technique I’d recommend using either the Python
    library `faker` or scikit-learn’s `sklearn.datasets.make_classification` and `sklearn.datasets.make_regression`
    functions. These tools are a fantastic way to programmatically generate huge datasets
    in the blink of an eye, and perfect for building proof-of-concept models without
    having to spend ages searching for the perfect dataset.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，ChatGPT 在创建数据集的速度和规模上有一定的限制，所以如果你想扩展这项技术，我建议使用 Python 库 `faker` 或 scikit-learn
    的 `sklearn.datasets.make_classification` 和 `sklearn.datasets.make_regression`
    函数。这些工具是以编程方式快速生成巨大数据集的绝佳方法，非常适合构建概念验证模型，而不必花费大量时间寻找完美的数据集。
- en: In practice, I have rarely needed to use synthetic data creation techniques
    to generate *entire* datasets (and, as I will explain later, you’d be wise to
    exercise caution if you intend to do this). Instead, I find this is a really neat
    technique for generating adversarial examples or adding noise to your datasets,
    enabling me to test my models’ weaknesses and build more robust versions. But,
    regardless of how you use this technique, it’s an incredibly useful tool to have
    at your disposal.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我很少需要使用合成数据创建技术来生成*完整*数据集（而且，正如我稍后将解释的那样，如果你打算这样做，你应该谨慎）。相反，我发现这是生成对抗性示例或向数据集中添加噪声的一个非常好的技术，使我能够测试模型的弱点并构建更强健的版本。但是，无论你如何使用这项技术，它都是一个非常有用的工具。
- en: Ask a company for their data (nicely)
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向公司请求他们的数据（礼貌地）
- en: Creating synthetic data is a nice workaround for situations when you can’t find
    the type of data you’re looking for, but the obvious problem is that you’ve got
    no guarantee that the data are good representations of real-life populations.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 创建合成数据是当你找不到所需数据类型时的一个不错的解决办法，但明显的问题是，你无法保证这些数据能很好地代表真实生活中的人群。
- en: If you want to guarantee that your data are realistic, the best way to do that
    is, surprise surprise…
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想确保你的数据是现实的，最好的方法是，出乎意料的是……
- en: … to actually go and find some *real* data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: … 实际上去寻找一些*真实*数据。
- en: One way of doing this is to reach out to companies that might hold such data
    and ask if they’d be interested in sharing some with you. At risk of stating the
    obvious, no company is going to give you data that are highly sensitive or if
    you are planning to use them for commercial or unethical purposes. That would
    just be plain stupid.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是联系可能持有这些数据的公司，询问他们是否有兴趣与您分享一些数据。风险提示，没有公司会给你高度敏感的数据，尤其是如果你计划将其用于商业或不道德的目的。这会显得非常愚蠢。
- en: However, if you intend to use the data for research (e.g., for a university
    project), you might well find that companies are open to providing data if it’s
    in the context of a *quid pro quo* joint research agreement.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你打算将数据用于研究（例如，用于大学项目），你可能会发现公司愿意提供数据，只要这是在*互惠互利*的联合研究协议的背景下。
- en: 'What do I mean by this? It’s actually pretty simple: I mean an arrangement
    whereby they provide you with some (anonymised/de-sensitised) data and you use
    the data to conduct research which is of some benefit to them. For example, if
    you’re interested in studying churn modelling, you could put together a proposal
    for comparing different churn prediction techniques. Then, share the proposal
    with some companies and ask whether there’s potential to work together. If you’re
    persistent and cast a wide net, you will likely find a company that is willing
    to provide data for your project *as long as you share your findings with them*
    so that they can get a benefit out of the research.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我所说的是什么意思？实际上很简单：我指的是一种安排，即他们向你提供一些（匿名/去敏感化的）数据，而你利用这些数据进行对他们有一定益处的研究。例如，如果你有兴趣研究客户流失建模，你可以提出一个比较不同流失预测技术的提案。然后，将提案与一些公司分享，并询问是否有可能合作。如果你足够坚持并广泛接触，你可能会找到愿意提供数据的公司*只要你与他们分享你的发现*，这样他们就可以从研究中获得益处。
- en: If that sounds too good to be true, you might be surprised to hear that [this
    is exactly what I did during my master’s degree](https://medium.com/towards-data-science/4-ways-to-get-the-most-out-of-your-data-science-degree-40815f6a311d).
    I reached out to a couple of companies with a proposal for how I could use their
    data for research that would benefit them, signed some paperwork to confirm that
    I wouldn’t use the data for any other purpose, and conducted a really fun project
    using some real-world data. It really can be done.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来太好了以至于难以置信，你可能会惊讶地发现[这正是我在硕士学位期间所做的](https://medium.com/towards-data-science/4-ways-to-get-the-most-out-of-your-data-science-degree-40815f6a311d)。我联系了几家公司，提出了一个如何利用他们的数据进行对他们有益的研究的提案，签署了一些文件以确认我不会将数据用于其他目的，并使用一些真实世界的数据进行了一个非常有趣的项目。确实可以做到这一点。
- en: The other thing I particularly like about this strategy is that it provides
    a way to exercise and develop quite a broad set of skills which are important
    in Data Science. You have to communicate well, show commercial awareness, and
    become a pro at managing stakeholder expectations — all of which are essential
    skills in the day-to-day life of a Data Scientist.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我特别喜欢这种策略的另一点是，它提供了一种锻炼和发展一套广泛技能的方式，这些技能在数据科学中非常重要。你必须善于沟通，展示商业意识，并成为管理利益相关者期望的高手——这些都是数据科学家日常生活中必不可少的技能。
- en: '![](../Images/2f5396a4ba057dbee6ac686705a4b161.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f5396a4ba057dbee6ac686705a4b161.png)'
- en: Pleeeeeease let me have your data. I’ll be a good boy, I promise! Image by [Nayeli
    Rosales](https://unsplash.com/@nrosales) on [Unsplash](https://unsplash.com/photos/BbGxyxb2O3U)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请让我获取你的数据。我会表现良好的，我保证！图片由[Nayeli Rosales](https://unsplash.com/@nrosales)提供，来源于[Unsplash](https://unsplash.com/photos/BbGxyxb2O3U)
- en: Look in the repositories where academics store code for their journal articles
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查阅学术界存储其期刊文章代码的代码库
- en: Lots of datasets used in academic studies aren’t published on platforms like
    Kaggle, but are still publicly available for use by other researchers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 很多用于学术研究的数据集并没有发布在像 Kaggle 这样的平台上，但仍然对其他研究人员公开可用。
- en: One of the best ways to find datasets like these is by looking in the repositories
    associated with academic journal articles. Why? Because lots of journals require
    their contributors to make the underlying data publicly available. For example,
    two of the data sources I used during my master’s degree (the [Fragile Families](https://www.fragilefamilieschallenge.org/)
    dataset and the [Hate Speech Data](https://github.com/leondz/hatespeechdata) website)
    weren’t available on Kaggle; I found them through academic papers and their associated
    code repositories.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找类似数据集的最佳方法之一是查看与学术期刊文章相关的资料库。为什么？因为很多期刊要求其投稿者公开基础数据。例如，我在攻读硕士学位期间使用的两个数据源（[Fragile
    Families](https://www.fragilefamilieschallenge.org/) 数据集和 [Hate Speech Data](https://github.com/leondz/hatespeechdata)
    网站）在 Kaggle 上没有提供；我通过学术论文及其相关代码库找到了这些数据源。
- en: How can you find these repositories? It’s actually surprisingly simple — I start
    by opening up [paperswithcode.com](https://paperswithcode.com/), search for papers
    in the area I’m interested in, and look at the available datasets until I find
    something that looks interesting. In my experience, this is a really neat way
    to find datasets which haven’t been done-to-death by the masses on Kaggle.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如何找到这些资料库？实际上非常简单——我从打开 [paperswithcode.com](https://paperswithcode.com/) 开始，搜索我感兴趣领域的论文，并查看可用的数据集，直到找到看起来有趣的内容。根据我的经验，这是一种非常巧妙的方式来找到那些没有被
    Kaggle 群众反复使用的数据集。
- en: BigQuery Public Datasets
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BigQuery 公共数据集
- en: Honestly, I’ve no idea why more people don’t make use of BigQuery Public Datasets.
    There are literally *hundreds* of datasets covering everything from Google Search
    Trends to London Bicycle Hires to Genomic Sequencing of Cannabis.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 老实说，我不知道为什么更多人不利用 BigQuery 公共数据集。这里真的有*数百*个数据集，涵盖从 Google 搜索趋势到伦敦自行车租赁，再到大麻基因组测序的所有内容。
- en: One of the things I especially like about this source is that lots of these
    datasets are incredibly commercially relevant. You can kiss goodbye to niche academic
    topics like flower classification and digit prediction; in BigQuery, there are
    datasets on real-world business issues like ad performance, website visits and
    economic forecasts.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我特别喜欢这个来源的一个原因是，这些数据集在商业上非常相关。你可以告别像花卉分类和数字预测这样的小众学术话题；在 BigQuery 中，有关于广告效果、网站访问和经济预测等现实世界商业问题的数据集。
- en: Lots of people shy away from these datasets because they require SQL skills
    to load them. But, even if you don’t know SQL and only know a language like Python
    or R, I’d still encourage you to take an hour or two to learn some basic SQL and
    then start querying these datasets. It doesn’t take long to get up and running,
    and this truly is a treasure trove of high-value data assets.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 很多人避开这些数据集，因为它们需要 SQL 技能来加载。但即使你不知道 SQL，只会 Python 或 R 等语言，我仍然建议你花一两个小时学习一些基本的
    SQL，然后开始查询这些数据集。上手并不需要很长时间，这确实是一个高价值数据资产的宝库。
- en: To use the datasets in BigQuery Public Datasets, you can sign up for a completely
    free account and create a sandbox project by following the instructions [here](https://cloud.google.com/bigquery/docs/sandbox).
    You don’t need to enter your credit card details or anything like that — just
    your name, your email, a bit of info about the project, and you’re good to go.
    If you need more computing power at a later date, you can upgrade the project
    to a paid one and access GCP’s compute resources and advanced BigQuery features,
    but I’ve personally never needed to do this and have found the sandbox to be more
    than adequate.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 BigQuery 公共数据集中的数据集，你可以按照 [这里](https://cloud.google.com/bigquery/docs/sandbox)
    的说明注册一个完全免费的账户并创建一个沙箱项目。你无需输入信用卡信息或类似的东西——只需提供你的名字、电子邮件、项目的基本信息即可。如果以后需要更多计算能力，你可以将项目升级为付费项目，访问
    GCP 的计算资源和高级 BigQuery 功能，但我个人从未需要这样做，发现沙箱环境已经足够了。
- en: Try a dataset search engine
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 尝试使用数据集搜索引擎
- en: 'My final tip is to try using a dataset search engine. These are incredibly
    tools that have only emerged in the last few years, and they make it very easy
    to quickly see what’s out there. Three of my favourites are:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我的最后一个建议是尝试使用数据集搜索引擎。这些工具在过去几年才刚刚出现，它们使得快速查看现有数据变得非常容易。我最喜欢的三个是：
- en: '[Harvard Dataverse](https://dataverse.harvard.edu/)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[哈佛数据集](https://dataverse.harvard.edu/)'
- en: '[Google Dataset Search](https://datasetsearch.research.google.com/)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Google 数据集搜索](https://datasetsearch.research.google.com/)'
- en: '[Papers with Code](https://paperswithcode.com/datasets)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Papers with Code](https://paperswithcode.com/datasets)'
- en: In my experience, searching with these tools can be a much more effective strategy
    than using generic search engines as you’re often provided with metadata about
    the datasets and you have the ability to rank them by how often they’ve been used
    and the publication date. Quite a nifty approach, if you ask me.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，使用这些工具进行搜索往往比使用通用搜索引擎更有效，因为你通常可以获得有关数据集的元数据，并且可以根据使用频率和发布日期对其进行排名。如果你问我，这是一种相当巧妙的方法。
- en: Thanks for reading! I hope you find these 5 strategies helpful, and please feel
    free to reach out if you have any feedback or questions :-)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！希望你觉得这 5 种策略有帮助，如果你有任何反馈或问题，请随时联系我 :-)
- en: One more thing — could you be in my 1%?
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有一件事——你能成为我那 1% 的一员吗？
- en: Less than 1% of my readers on Medium click my ‘Follow’ button, so it really
    means a lot when you do, whether here on Medium, [Twitter](https://twitter.com/matt_chapma)
    or [LinkedIn](https://www.linkedin.com/in/matt-chapman-ba8488118/).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Medium 上不到 1% 的读者点击我的“关注”按钮，因此无论是在 Medium、[Twitter](https://twitter.com/matt_chapma)
    还是 [LinkedIn](https://www.linkedin.com/in/matt-chapman-ba8488118/)，你做出这样的举动对我而言意义重大。
- en: If you’d like to get unlimited access to all of my stories (and the rest of
    Medium.com), you can sign up via my [referral link](https://medium.com/@mattchapmanmsc/membership)
    for $5 per month. It adds no extra cost to you vs. signing up via the general
    signup page, and helps to support my writing as I get a small commission.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望获得对我所有故事（以及 Medium.com 上其他内容）的无限访问权限，你可以通过我的 [推荐链接](https://medium.com/@mattchapmanmsc/membership)
    以每月 $5 注册。相比于通过普通注册页面注册，这不会额外增加你的费用，并且有助于支持我的写作，因为我会获得一小部分佣金。
