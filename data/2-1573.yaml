- en: 'Need for Speed: Comparing Pandas 2.0 with Four Python Speed-Up Libs (with Code)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 需要速度：将 Pandas 2.0 与四个 Python 加速库进行比较（附代码）
- en: 原文：[https://towardsdatascience.com/need-for-speed-comparing-pandas-2-0-with-four-python-speed-up-libs-with-code-b287e0d9b836](https://towardsdatascience.com/need-for-speed-comparing-pandas-2-0-with-four-python-speed-up-libs-with-code-b287e0d9b836)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/need-for-speed-comparing-pandas-2-0-with-four-python-speed-up-libs-with-code-b287e0d9b836](https://towardsdatascience.com/need-for-speed-comparing-pandas-2-0-with-four-python-speed-up-libs-with-code-b287e0d9b836)
- en: '*Polars*, *Dask,* *RAPIDS.ai cuDF*, and *Numba* are compared against *Pandas
    2.0* with *pyarrow* in the backend, vectorization, and *itertuples()*, *apply()*
    methods.'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*Polars*、*Dask*、*RAPIDS.ai cuDF* 和 *Numba* 与使用 *pyarrow* 的 *Pandas 2.0* 在后台处理、向量化以及
    *itertuples()*、*apply()* 方法上进行了比较。'
- en: '[](https://theomitsa.medium.com/?source=post_page-----b287e0d9b836--------------------------------)[![Dr.
    Theophano Mitsa](../Images/a39dfae5f4409120b840cd9182b148c6.png)](https://theomitsa.medium.com/?source=post_page-----b287e0d9b836--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b287e0d9b836--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b287e0d9b836--------------------------------)
    [Dr. Theophano Mitsa](https://theomitsa.medium.com/?source=post_page-----b287e0d9b836--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://theomitsa.medium.com/?source=post_page-----b287e0d9b836--------------------------------)[![Theophano
    Mitsa博士](../Images/a39dfae5f4409120b840cd9182b148c6.png)](https://theomitsa.medium.com/?source=post_page-----b287e0d9b836--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b287e0d9b836--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b287e0d9b836--------------------------------)
    [Theophano Mitsa博士](https://theomitsa.medium.com/?source=post_page-----b287e0d9b836--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b287e0d9b836--------------------------------)
    ·9 min read·May 19, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b287e0d9b836--------------------------------)
    ·阅读时间 9 分钟·2023年5月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3e9e1405f4a9150be078fd1dfff4beda.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e9e1405f4a9150be078fd1dfff4beda.png)'
- en: Image by alan9187 from Pixabay
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 alan9187 提供，来源于 Pixabay
- en: 2023, so far, has been a year that brought phenomenal progress to the field
    of machine learning, with the development and worldwide distribution of advanced
    *Large Language Models* *(LLMs*). However, machine learning proficiency is not
    restricted to fine-tuning *LLLMs* and prompt engineering. A machine learning expert
    knows what happens under the hood, is able to explain/optimize various system
    behaviors, and ultimately is responsible for the overall quality, business-need-fit,
    and performance of the machine learning solution.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到2023年为止，这一年给机器学习领域带来了显著的进展，先进的*大语言模型*（*LLMs*）得到了开发和全球分布。然而，机器学习的专业能力不仅限于对*LLLMs*的微调和提示工程。一位机器学习专家了解系统内部的运作，能够解释/优化各种系统行为，并最终负责机器学习解决方案的整体质量、业务需求适配性和性能。
- en: Besides performance comparison, the article aims to educate the reader on how
    to implement various Python speed-up operations by offering code examples that
    illustrate the key points.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除了性能比较，文章还旨在通过提供代码示例来教育读者如何实现各种 Python 加速操作，突出关键点。
- en: 'Speaking of knowing what happens under the hood and performance, this article
    will compare the performance of the newly released *Pandas 2.0* against four other
    speed-up Python libraries and operations: *Polars, RAPIDS.ai cuDF, Dask,* and
    *Numba*. The code was executed on an *ASUS Rig Strix Scar* (2022) gaming laptop
    with *NVIDIA GeForce RTX 3080 Ti Laptop GPU* and *Intel Core i9 12900Hz* processor.
    Besides performance comparison, the article aims to educate the reader on how
    to implement various Python speed-up operations by offering code examples that
    illustrate the key points.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 说到了解系统内部运作和性能，本文将对比新发布的 *Pandas 2.0* 与四个其他加速 Python 库和操作：*Polars*、*RAPIDS.ai
    cuDF*、*Dask* 和 *Numba*。代码在 *ASUS Rig Strix Scar*（2022款）游戏笔记本电脑上执行，配置为 *NVIDIA
    GeForce RTX 3080 Ti Laptop GPU* 和 *Intel Core i9 12900Hz* 处理器。除了性能比较，文章还旨在通过提供代码示例来教育读者如何实现各种
    Python 加速操作，突出关键点。
- en: In our code examples, we will work with a synthetic *.csv* file that contains
    500K rows that simulate a superstore’s merchandise prices that has two locations.
    The file has three columns; column 1, called *Store1,* contains the inventory
    prices of the first superstore location, and column 2, called *Store2,* contains
    the inventory prices of the second superstore location. The prices of *Store2*
    are slightly higher (up to 20% higher). Finally, column 3, called *Discountability*,
    contains only 0s and 1s and tells us whether an item can be discounted. Zero means
    the item can not be discounted, and one means it can be discounted. The code for
    the creation of the *Pandas 2.0 DataFrame* and synthetic *.csv* file is shown
    below.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码示例中，我们将使用一个合成的*.csv*文件，该文件包含500K行，模拟一个超级商店的两地商品价格。文件有三列；第一列，称为*Store1*，包含第一个超级商店位置的库存价格，第二列，称为*Store2*，包含第二个超级商店位置的库存价格。*Store2*的价格略高（最高可高20%）。最后，第三列，称为*Discountability*，仅包含0和1，指示一个项目是否可以打折。0表示该项目不能打折，1表示可以打折。创建*Pandas
    2.0 DataFrame*和合成*.csv*文件的代码如下。
- en: '***Key point***: Note that *col2* (prices of *Store2*) is created from the
    *numpy* arrays *col1* and *var* using a vectorized operation without having to
    use loops. We can do that because N*umPy* supports vectorized operations.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '***关键点***：注意到*col2*（*Store2*的价格）是通过使用矢量化操作从*numpy*数组*col1*和*var*创建的，而无需使用循环。我们之所以能这样做，是因为N*umPy*支持矢量化操作。'
- en: A. Dataframe Creation Performance Comparison
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: A. Dataframe创建性能比较
- en: The first operation for which we will compare the performance of different approaches
    is that of a *DataFrame* creation. Specifically, we will compare the performance
    of *Pandas 2.0*, *Dask*, and *Polars*. In the following two sections, we will
    discuss the code implementations, and then in section A.3, we will compare the
    performance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将比较不同方法性能的第一个操作是*DataFrame*的创建。具体来说，我们将比较*Pandas 2.0*、*Dask*和*Polars*的性能。在接下来的两个部分中，我们将讨论代码实现，然后在A.3节中，我们将比较性能。
- en: '**A.1\. With Pandas 2.0**'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**A.1\. 使用Pandas 2.0**'
- en: One of the essential new features in *Pandas 2.0* is the addition of A*pache
    Arrow (pyarrow)* backing memory format. The main advantage of *Apache Arrow* is
    that it can perform faster and more memory-efficient operations. In the code below,
    we show the construction of a *Pandas Dataframe* with and without the use of *pyarrow*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*Pandas 2.0*中的一个重要新特性是添加了A*pache Arrow (pyarrow)*支持的内存格式。*Apache Arrow*的主要优点是它可以执行更快、更节省内存的操作。下面的代码展示了使用和不使用*pyarrow*构建*Pandas
    DataFrame*的方式。'
- en: '***Keypoint:*** Note that once we specify the backend type (*dtype_backend)*
    to be *pyarrow*, we need to specify the *engine* as *pyarrow* as well.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '***关键点：*** 注意，一旦我们将后端类型(*dtype_backend*)指定为*pyarrow*，我们还需要将*engine*指定为*pyarrow*。'
- en: A.2 With Polars and Dask
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.2 使用Polars和Dask
- en: '*Polars* is a turbocharged Python *DataFrame* library that implements the *Apache
    Arrow* memory model and is written in *Rust*. Similarly to *Apache Arrow*, it
    is both fast and memory-efficient, which makes it particularly suitable for data-intensive
    computing. In order to create the *Polars* *DataFrame*, all we need to do is to
    import the *Polars* library and invoke its *read_csv()* method.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*Polars*是一个加速的Python *DataFrame*库，实施了*Apache Arrow*内存模型，并用*Rust*编写。与*Apache
    Arrow*类似，它既快速又内存高效，特别适合数据密集型计算。为了创建*Polars* *DataFrame*，我们只需导入*Polars*库并调用其*read_csv()*方法。'
- en: '*Dask* is an open-source framework that enables parallel and distributed computing
    in Python, and therefore, it is particularly suited for data-intensive applications.
    In order to create a *Dask* *DataFrame*, we must first import the *dask.dataframe*
    library and then call its *read_csv()* method.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*Dask*是一个开源框架，支持Python中的并行和分布式计算，因此特别适合数据密集型应用程序。为了创建一个*Dask* *DataFrame*，我们必须首先导入*dask.dataframe*库，然后调用其*read_csv()*方法。'
- en: '**Key point.** Be careful when installing the *Dask* library because *Pandas*
    is one of its dependencies, and it will install it. At the time of this writing,
    *Dask* install will not install *Pandas 2.0* but an older version. So, if you
    want to work with *Dask* and not overwrite your *Pandas 2.0* installation, create
    a virtual environment and install *Dask* in it.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键点。** 安装*Dask*库时要小心，因为*Pandas*是其依赖项之一，它会安装它。在撰写本文时，*Dask*的安装不会安装*Pandas
    2.0*，而是一个较旧的版本。因此，如果你想使用*Dask*而不覆盖你的*Pandas 2.0*安装，请创建一个虚拟环境并在其中安装*Dask*。'
- en: A.3 Dataframe Creation Execution Time Comparison
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: A.3 Dataframe创建执行时间比较
- en: Timing of operations is implemented using the *timeit* library, as shown below.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 操作时间使用*timeit*库进行实现，如下所示。
- en: Below are shown the execution times for *DataFrame* creation from fastest to
    slowest. The fastest are *Polars* and *Dask*, followed closely by *Pandas 2.0,*
    with a *pyarrow* backend*.* As for the traditional *Pandas DataFrame* creation,
    it is 4.37 times slower than the former. So, even from the first step of creating
    our *Pandas DataFrame,* *pyarrow* makes a difference.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 下方展示了从最快到最慢的*DataFrame*创建执行时间。最快的是*Polars*和*Dask*，紧随其后的是具有*pyarrow*后端的*Pandas
    2.0*。至于传统的*Pandas DataFrame*创建，它比前者慢4.37倍。因此，即使从创建*Pandas DataFrame*的第一步开始，*pyarrow*也能发挥作用。
- en: 'With *Dask*: 0.020656200009398162'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*Dask*：0.020656200009398162
- en: 'With *Polars*: 0.027874399966094643'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*Polars*：0.027874399966094643
- en: 'With *pyarrow*-enabled *Pandas* 2.0: 0.04491699999198317'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*pyarrow*支持的*Pandas* 2.0：0.04491699999198317
- en: 'With *Pandas* 2.0 (without *pyarrow*): 0.196299700008239'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*Pandas* 2.0（不使用*pyarrow*）：0.196299700008239
- en: In addition to measuring the execution time, I also performed some estimations
    of memory usage. The *cuDF D*ata*Frame* has the smallest memory footprint (0.12MB),
    while the *Polars DataFrame* has one of about 7.63MB, and the *Pandas DataFrame*
    has a memory footprint of about 11.44MB. Note that the time for creating the *cuDF
    DataFrame* is not provided because the *.csv* file is stored in the CPU, so we
    can not harness the GPU capabilities of *cuDF* for this operation. We will do
    so later in the article.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 除了测量执行时间，我还进行了一些内存使用的估算。*cuDF DataFrame*的内存占用最小（0.12MB），而*Polars DataFrame*的内存占用约为7.63MB，*Pandas
    DataFrame*的内存占用约为11.44MB。注意，*cuDF DataFrame*的创建时间未提供，因为*.csv*文件存储在CPU中，因此我们无法利用*cuDF*的GPU能力进行此操作。我们将在文章后面讨论这一点。
- en: B. Performance Comparison of DataFrame Operations
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: B. *DataFrame*操作的性能比较
- en: 'In order to compare the performance of the aforementioned libraries when they
    are tasked with *DataFrame* operations, let us assume the following: All eligible
    merchandise of *Store1* will be discounted by 20%, all eligible merchandise of
    *Store2* will be discounted by 30%, and the discounted prices will be saved in
    a new dataframe. We use the word “eligible” because, as discussed above, items
    that have a *Discountability* of 0 can not be discounted. So, we will perform
    an execution time comparison on applying a function to the rows of a *DataFrame*,
    which is a prevalent task.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较上述库在执行*DataFrame*操作时的性能，假设如下情况：所有*Store1*的合格商品将折扣20%，所有*Store2*的合格商品将折扣30%，折扣后的价格将保存在一个新的数据框中。我们使用“合格”这个词，因为如上所述，*Discountability*为0的项目不能享受折扣。因此，我们将对应用函数到*DataFrame*的行上进行执行时间比较，这是一个常见任务。
- en: Code implementations are shown in sections B.1-B.8, and the performance comparison
    is shown in section B.9.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 代码实现展示在B.1-B.8节，性能比较展示在B.9节。
- en: B.1 Pandas with pyarrow
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.1 使用pyarrow的Pandas
- en: In our first experiment for *DataFrame* operations, we will harness the capabilities
    of *Apache Arrow*, given its recent interoperability with *Pandas 2.0*. As shown
    in the first line of the code below, we convert a *Pandas DataFrame* to a *pyarrow
    Table*, which is an efficient way to represent columnar data in memory. Each column
    is stored separately, which allows for efficient compression and data queries.
    Then, the *Store1*, *Store2*, and *Discountability* columns are passed to the
    function *scale_columns()*, which scales the columns by the appropriate discount
    (0.2 or 0.3) and the mask value (0 or 1) of the *Discountability* column. The
    scaled columns are returned by the function as a tuple. Finally, the Table *result_table*
    is converted to a *Pandas DataFrame*.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对*DataFrame*操作的第一次实验中，我们将利用*Apache Arrow*的能力，鉴于它最近与*Pandas 2.0*的互操作性。如下面代码的第一行所示，我们将一个*Pandas
    DataFrame*转换为*pyarrow Table*，这是一种在内存中高效表示列数据的方式。每一列单独存储，这允许高效的压缩和数据查询。然后，将*Store1*、*Store2*和*Discountability*列传递给*scale_columns()*函数，该函数通过适当的折扣（0.2或0.3）和*Discountability*列的掩码值（0或1）来缩放这些列。缩放后的列作为元组由函数返回。最后，将表*result_table*转换为*Pandas
    DataFrame*。
- en: '***Key point*:** Multiplications inside the function *scale_columns()* are
    implemented using the *pyarrow.compute* function *multiply()*. Note that *EVERY*
    multiplication has to be implemented using *multiply()*. For example, if above,
    we replaced *pc.multiply(0.2,mask_col)* with *pc.multiply(0.2*mask_col),* we would
    get an error. Finally, we use the *subtract() f*unction of *pyarrow.compute* for
    subtraction.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '***关键点：** 在函数*scale_columns()*中，乘法操作是通过*pyarrow.compute* 函数*multiply()* 实现的。注意*每一个*乘法操作都必须使用*multiply()*
    实现。例如，如果我们将上面的*pc.multiply(0.2,mask_col)* 替换为*pc.multiply(0.2*mask_col)*，我们将会遇到错误。最后，我们使用*pyarrow.compute*
    的*subtract()*函数进行减法。'
- en: '**B2\. With the Pandas method apply()**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**B2. 使用 Pandas 方法 apply()**'
- en: Our second experiment will use the *Pandas DataFrame* *apply()* method that
    performs row-wise operations. The function *scale_columns()* performs the scaling
    in the code below. Note that the actual scaling is done inside the nested function
    *discount_store()*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个实验将使用*Pandas DataFrame*的*apply()*方法来执行逐行操作。函数*scale_columns()*在下面的代码中执行缩放。请注意，实际的缩放是在嵌套函数*discount_store()*中完成的。
- en: '**Key point:** The nested function returns a *Pandas Series* that contains
    a dictionary where the *key* is the column, and the *value* is the scaled store
    price. You may wonder why we are returning this type of object. The reason is
    that the *Pandas apply()* method returns a *Series* where the index is the column
    name. Thus sending to *apply()* an object that has a similar structure to what
    it has to return facilitates computations. For education purposes, in the *github*
    directory of my code (link at the end of article), I provide two implementations
    using *apply()*. The one shown here, and one more, where the nested function returns
    the scaled values as a tuple. This implementation is more computationally intensive
    because the returned type is a different structure from what *apply()* has to
    return.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键点：** 嵌套函数返回一个包含字典的*Pandas Series*，其中*key*是列名，*value*是缩放后的商店价格。你可能会好奇为什么我们要返回这种类型的对象。原因是，*Pandas
    apply()* 方法返回一个*Series*，其索引是列名。因此，将结构类似于其返回值的对象传递给*apply()*有助于计算。为了教育目的，在我的代码的*github*目录中（文章末尾有链接），我提供了两个使用*apply()*的实现。这里展示的是其中一个，还有一个实现，其中嵌套函数将缩放值作为元组返回。这个实现计算上更为密集，因为返回的类型与*apply()*需要返回的结构不同。'
- en: B.3\. With Pandas itertuples()
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.3. 使用 Pandas itertuples()
- en: '*itertuples()* is a fast *Pandas* row *iterator* that produces *namedtuples*
    (column-name, value-of-corresponding-row). The code that implements the scaling
    of the store prices and computes the discounted prices using *itertuples()* is
    shown below.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*itertuples()* 是一个快速的*Pandas* 行*迭代器*，生成*namedtuples*（列名，相应行的值）。实现商店价格缩放并使用*itertuples()*
    计算折扣价格的代码如下所示。'
- en: '**Key point:** The Pandas *itertuples()* method is often faster than Pandas
    *apply(),* particularly for larger datasets, as in our code example. The reason
    is that *apply()* calls a function for every row, while *itertuples()* does not
    and can take advantage of vectorized operations while returning a lightweight
    iterator that does not create new objects and is memory-efficient.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键点：** *Pandas itertuples()* 方法通常比 *Pandas apply()* 更快，特别是对于较大的数据集，就像我们的代码示例一样。原因是*apply()*为每一行调用一个函数，而*itertuples()*则不会，并且可以利用向量化操作，同时返回一个轻量级迭代器，这不会创建新对象，且内存效率高。'
- en: '**B.4 Pandas Vectorized Operations**'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**B.4 Pandas 向量化操作**'
- en: 'And now, we have come to the most elegant and fastest way to compute discounted
    store prices: Vectorization! This is a way that allows the application of the
    desired operations to entire arrays at once instead of iterating using loops.
    The implementation is shown below.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经到了计算折扣商店价格的最优雅和最快的方法：向量化！这是一种允许对整个数组一次性应用所需操作的方法，而不是使用循环进行迭代。实现如下所示。
- en: '**B.5 With Numba**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.5 使用 Numba**'
- en: '*Numba* is a just-in-time (*JIT*) compiler for Python that, **at runtime**,
    translates Python code into optimized machine code. It is instrumental in optimizing
    operations involving loops and *NumPy* arrays.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*Numba* 是一个即时（*JIT*）编译器，用于将 Python 代码在**运行时**翻译成优化的机器代码。它在优化涉及循环和*NumPy* 数组的操作中非常有用。'
- en: The *@numba.njit* symbol shown below is a *decorator* that tells *Numba* that
    the function that follows is to be compiled into machine code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*@numba.njit* 符号是一个*装饰器*，它告诉*Numba* 随后的函数要编译成机器代码。'
- en: B.6 With Dask
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.6 使用 Dask
- en: Similar to *NumPy*, *Dask* offers vectorized operations, with the additional
    advantage that these operations can be applied in a parallel and distributed manner.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于*NumPy*，*Dask*提供了向量化操作，额外的优势是这些操作可以以并行和分布的方式应用。
- en: 'Additional advantages of *Dask* include: (a) Lazy evaluation, i.e., *Dask*
    arrays and operations are built on a task graph and executed only when the result
    is requested, by calling *compute()*, for example. (b) Out of core processing,
    i.e., it can process datasets that do not fit into memory. ( c ) Integration with
    *Pandas.*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*Dask*的额外优势包括：(a) 懒惰计算，即*Dask*数组和操作建立在任务图上，仅在请求结果时执行，例如调用*compute()*。(b) 超出内存处理，即可以处理不适合内存的数据集。(c)
    与*Pandas*的集成。'
- en: B.7 With Polars
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.7 使用Polars
- en: '*Polars* offers vectorized operations that leverage the speed and memory efficiency
    of the *Rust* language. Similar to *Dask*, it offers lazy evaluation, out-of-core
    processing, and integration with *Pandas*. Implementation is shown below.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*Polars*提供了利用*Rust*语言的速度和内存效率的向量化操作。类似于*Dask*，它提供了懒惰计算、超出内存处理和与*Pandas*的集成。实现如下所示。'
- en: B.8 With RAPIDS.ai cuDF
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.8 使用RAPIDS.ai cuDF
- en: Finally, we use *cuDF* to implement the price discounting function via vectorized
    operations. The *cuDF* library is built on top of *CUDA*, and so its vectorized
    operations leverage the computational strength of GPUs for faster processing.
    One handy feature of *cudF* is the offering of *CUDA* *kernels*. These are optimized
    functions that harness the parallel nature of GPUs. The *cuDF* implementation
    is shown below.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用*cuDF*通过向量化操作实现了价格折扣功能。*cuDF*库建立在*CUDA*之上，因此其向量化操作利用了GPU的计算能力以加快处理速度。*cuDF*的一个方便功能是提供*CUDA*
    *kernels*。这些是优化的函数，利用了GPU的并行特性。*cuDF*的实现如下所示。
- en: B.9 Execution Time Comparison of Function Application
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.9 函数应用的执行时间比较
- en: Similar to the timing of *DataFrame* creation, *timeit* was used to measure
    the execution time of the price discounting function and its saving in a new *DataFrame*.
    Below are the execution times, ranked from fastest to slowest.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于*DataFrame*的创建时间，*timeit*被用来测量价格折扣功能的执行时间及其在新*DataFrame*中的节省。下面是执行时间，按从最快到最慢排序。
- en: With *RAPIDS.ai, cuDF:* 0.008894977000011295
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*RAPIDS.ai, cuDF:* 0.008894977000011295
- en: With *Polars:* 0.009557300014421344
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*Polars:* 0.009557300014421344
- en: 'With *pyarrow Table*: 0.028865800006315112'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用*pyarrow Table*: 0.028865800006315112'
- en: 'With *Pandas 2.0* vectorized operations: 0.0536642000079155'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用*Pandas 2.0*向量化操作: 0.0536642000079155'
- en: With *Dask:* 0.6413181999814697
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*Dask:* 0.6413181999814697
- en: With *Numba:* 0.9497981000000095
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*Numba:* 0.9497981000000095
- en: 'With *Pandas 2.0 itertuples()*: 1.0882243000087328'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用*Pandas 2.0 itertuples()*: 1.0882243000087328'
- en: 'With *Pandas 2.0 apply()*: 197.63155489997007'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用*Pandas 2.0 apply()*: 197.63155489997007'
- en: Not surprisingly, the GPU-enabled *Rapids.ai cuDF* achieves the fastest time,
    followed very closely by the lightning-fast *Polars* library. The execution times
    of *pyarrow Table* and *Pandas 2.0* vectorized operations follow closely, too;
    *cuDF’s* execution time is only about 4.64 times faster on average than the latter
    two. *Dask*, *Numba*, and the *Panda*s method i*tertuples()* have an inferior
    but reasonable performance (approximately 72, 107, and 122 times slower than Polars,
    respectively). Finally, the *Pandas* *apply()* has an outstandingly *inferior*
    performance to all other methods, which is also not surprising given that this
    method works in a row-wise, relatively slow manner for large datasets.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，支持GPU的*Rapids.ai cuDF*取得了最快的时间，其次是闪电般快速的*Polars*库。*pyarrow Table*和*Pandas
    2.0*的向量化操作的执行时间也紧随其后；*cuDF*的执行时间平均比后两者快约4.64倍。*Dask*、*Numba*和*Pandas*的*itertuples()*方法的表现较差但仍合理（分别比*Polars*慢约72、107和122倍）。最后，*Pandas*的*apply()*相对于所有其他方法表现极其*差*，这也不令人惊讶，因为此方法在处理大型数据集时以逐行方式操作，速度相对较慢。
- en: '**Key points**: (a) Generally speaking, *apply()* is an excellent way to implement
    functions on *Pandas DataFrames* for small to medium-sized datasets*.* But, when
    dealing with large datasets, as in our case, it is best to look at other ways
    to implement the functions. (b) If you decide to use *apply()* in *Pandas 2.0*,
    ensure that this is done on a *DataFrame* created the standard way and not with
    *pyarrow* in the back end. The reason is that a very significant datatype conversion
    overhead will slow your computations considerably.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**关键点**：（a）一般来说，*apply()*是对小到中型数据集上的*Pandas DataFrames*应用函数的优秀方法。但是，当处理大型数据集时，如我们所例，最好考虑其他实现函数的方法。（b）如果你决定在*Pandas
    2.0*中使用*apply()*，请确保这在标准创建的*DataFrame*上进行，而不是在后台使用*pyarrow*的。原因是，显著的数据类型转换开销会大大减慢你的计算速度。'
- en: '**C. Conclusion**'
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**C. 结论**'
- en: 'In this article, I described several ways to speed up Python code applied to
    a large dataset, with a particular focus on the newly released *Pandas 2.0*, with
    a *pyarrow* back-end. The different speed-up techniques were compared performance-wise
    for two tasks: (a) *DataFrame* creation and (b) Application of a function on the
    rows of the *DataFrame*. **The news is indeed excellent for *Pandas 2.0* users;**
    *Pandas DataFrame* vectorized operations and *pyarrow Table* (extracted from a
    *Pandas DataFrame*) achieved **comparable performance** to *Rapids.ai cuDF* and
    *Polars* library.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我描述了几种加速应用于大型数据集的Python代码的方法，特别关注新发布的*Pandas 2.0*和*pyarrow*后端。不同的加速技术在两个任务中进行了性能比较：（a）*DataFrame*创建和（b）对*DataFrame*行应用函数。**对于*Pandas
    2.0*用户来说，确实是好消息；** *Pandas DataFrame*的向量化操作和*pyarrow Table*（从*Pandas DataFrame*中提取）实现了**与*Rapids.ai
    cuDF*和*Polars*库相当的性能**。
- en: 'The entire code is in the *github* directory: [link](https://github.com/theomitsa/Pandas2.0-Performance-comparison)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 整个代码在*github*目录下：[link](https://github.com/theomitsa/Pandas2.0-Performance-comparison)
- en: Thank you for reading!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！
