- en: How to Generate Real-World Synthetic Data with CTGAN
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用CTGAN生成真实世界的合成数据
- en: 原文：[https://towardsdatascience.com/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde?source=collection_archive---------2-----------------------#2023-04-13](https://towardsdatascience.com/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde?source=collection_archive---------2-----------------------#2023-04-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde?source=collection_archive---------2-----------------------#2023-04-13](https://towardsdatascience.com/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde?source=collection_archive---------2-----------------------#2023-04-13)
- en: Synthetic Data Generation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合成数据生成
- en: Exploring the Streamlit App introduced in ydata-synthetic
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索ydata-synthetic中介绍的Streamlit应用
- en: '[](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)[![Miriam
    Santos](../Images/decbc6528a641e7b02934a03e136284a.png)](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)
    [Miriam Santos](https://medium.com/@miriam.santos?source=post_page-----af41b4d60fde--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----af41b4d60fde---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)
    ·10 min read·Apr 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf41b4d60fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&user=Miriam+Santos&userId=243289394aaa&source=-----af41b4d60fde---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F243289394aaa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&user=Miriam+Santos&userId=243289394aaa&source=post_page-243289394aaa----af41b4d60fde---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af41b4d60fde--------------------------------)
    ·10分钟阅读·2023年4月13日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf41b4d60fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&user=Miriam+Santos&userId=243289394aaa&source=-----af41b4d60fde---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf41b4d60fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&source=-----af41b4d60fde---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf41b4d60fde&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde&source=-----af41b4d60fde---------------------bookmark_footer-----------)'
- en: G*enerating synthetic data is increasingly becoming a fundamental task to master
    as we move towards a Data-Centric paradigm of AI development.*
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: G*生成合成数据正日益成为掌握的基本任务，因为我们正朝着数据中心的AI开发范式迈进。*
- en: '[Synthetic Data](https://medium.com/ydata-ai/synthetic-data-1cd0ba907609) truly
    has a tremendous potential, but it also comes with its own challenges, especially
    in what concerns fully capturing the complexity and intricacies of real-world
    domains, namely their heterogeneity.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[合成数据](https://medium.com/ydata-ai/synthetic-data-1cd0ba907609)确实具有巨大的潜力，但它也带来了自身的挑战，特别是完全捕捉真实世界领域的复杂性和微妙之处，尤其是其异质性。'
- en: '![](../Images/a596a47e4d2bddb9612433846d953718.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a596a47e4d2bddb9612433846d953718.png)'
- en: Data heterogeneity is tough to handle in synthetic data generation models, especially
    for real-world domains, comprising additional (complex!) data characteristics
    and difficulty factors. Photo by [Tolga Ulkan](https://unsplash.com/@tolga__?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据异质性在合成数据生成模型中处理起来非常困难，特别是对于包含额外（复杂！）数据特征和难度因素的现实世界领域。照片由[Tolga Ulkan](https://unsplash.com/@tolga__?utm_source=medium&utm_medium=referral)在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)提供。
- en: Real-world domains are associated to [numerous aspects of complexity](/data-quality-issues-that-kill-your-machine-learning-models-961591340b40)
    (e.g., missing data, imbalanced data, noisy data), yet **one of the most common
    is encompassing heterogeneous (or “mixed”) data**, i.e., data that comprises both
    numeric and categorical features.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的领域与[众多复杂性方面](/data-quality-issues-that-kill-your-machine-learning-models-961591340b40)相关（例如，缺失数据、不平衡数据、噪声数据），然而**最常见的情况之一是涵盖异质（或“混合”）数据，**
    即包含数值型和类别型特征的数据。
- en: As each feature type may come with its own intrinsic characteristics, **heterogeneous
    data raises additional challenges** to the process of synthetic data generation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每种特征类型可能具有其固有的特征，**异质数据给合成数据生成过程带来了额外的挑战**。
- en: '[CTGAN](https://arxiv.org/abs/1907.00503) (Conditional Tabular Generative Adversarial
    Network) was conceptualized to partially “capture” this heterogeneity of real-world
    data and compared to other architectures such as [WGAN and WGAN-GP](https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-1-866705a77302),
    has proven to be more robust and generalizable for a variety of datasets.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[CTGAN](https://arxiv.org/abs/1907.00503)（条件表格生成对抗网络）旨在部分“捕捉”这种现实世界数据的异质性，与[WGAN
    和 WGAN-GP](https://medium.com/ydata-ai/generating-synthetic-tabular-data-with-gans-part-1-866705a77302)等其他架构相比，已证明在各种数据集上更为稳健和通用。'
- en: '*Throughout this article, we’ll dissect the properties of this architecture
    that make it so different and performant for tabular data, and why and when you
    should leverage it.*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*在本文中，我们将剖析使该架构在表格数据中如此不同和高效的特性，并说明何时以及为什么应该利用它。*'
- en: Real-World Tabular Heterogeneous Data
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现实世界的表格异质数据
- en: '**Real-world domains are often described by what we call “tabular data”,**
    i.e., data that can be structured and organized in a table-like format.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**现实世界的领域通常由我们所称的“表格数据”来描述，** 即可以结构化和组织成类似表格格式的数据。'
- en: As a standard, features (sometimes called “variables” or “attributes”) are represented
    in *columns*, whereas observations (or “records”) correspond to the *rows*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种标准，特征（有时称为“变量”或“属性”）在*列*中表示，而观察值（或“记录”）对应于*行*。
- en: '**Additionally, real-world data usually comprises both numeric and categorical
    features.**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**此外，现实世界的数据通常包含数值型和类别型特征。**'
- en: '**Numeric** features (also called “continuous”) are those that encode quantitative
    values, whereas **categorical** (also called “discrete”) represent qualitative
    measurements.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**数值型**特征（也称为“连续型”）是编码定量值的特征，而**类别型**（也称为“离散型”）表示定性测量。'
- en: 'Here’s an example of the [Adult Census Income](https://www.kaggle.com/datasets/uciml/adult-census-income?resource=download)
    dataset (available in [Kaggle](https://www.kaggle.com) under the [CC0: Public
    Domain](https://creativecommons.org/publicdomain/zero/1.0/) license) that we’ll
    be exploring later on: `age` and `fnlwgt` are **numeric** features, while the
    remaining are **categorical**.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '这是一个[成人收入普查](https://www.kaggle.com/datasets/uciml/adult-census-income?resource=download)数据集的示例（在[Kaggle](https://www.kaggle.com)上以[CC0:
    公开领域](https://creativecommons.org/publicdomain/zero/1.0/)许可证提供），我们将在后续中探讨：`age`
    和 `fnlwgt` 是**数值型**特征，而其余的都是**类别型**特征。'
- en: '![](../Images/d47e13ee9a35e8eda7a821bd7492bce4.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d47e13ee9a35e8eda7a821bd7492bce4.png)'
- en: A simple example of a tabular heterogenous dataset, containing numeric and categorical
    features. Image by Author.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的表格异质数据集示例，包含数值型和类别型特征。图片由作者提供。
- en: '**Due to the nature of each feature type, handling heterogeneous data is not
    straightforward when developing our machine learning models.**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**由于每种特征类型的性质，处理异质数据在开发机器学习模型时并不简单。**'
- en: Depending on the internal workings of the algorithm we need to train, the input
    data needs to be represented or preprocessed in different ways, so that their
    characteristics are properly learned by the model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们需要训练的算法的内部工作原理，输入数据需要以不同方式表示或预处理，以便模型能够正确学习它们的特征。
- en: '**When it comes to generating synthetic data, this assumes an even greater
    importance.** We’re not just worried about preprocessing the data so that it can
    be consumed efficiently by the model, **we’re concerned about whether the model
    can efficiently learn the characteristics of the real data**, so that it is able
    to output synthetic data that preserves its properties.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**在生成合成数据时，这点显得尤为重要。** 我们不仅关心数据的预处理，以便模型可以高效地使用数据，**我们还关心模型是否能高效地学习真实数据的特征**，以便能够输出保留这些特性的合成数据。'
- en: Why CTGAN for Heterogeneous Tabular Data?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择 CTGAN 处理异构表格数据？
- en: Since the original [GAN](https://arxiv.org/abs/1406.2661) formulation, research
    has been proposing modifications to the original architecture, new loss functions,
    or optimization strategies to address specific GAN limitations.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 自原始 [GAN](https://arxiv.org/abs/1406.2661) 公式化以来，研究者们提出了对原始架构的修改、新的损失函数或优化策略，以解决特定的
    GAN 限制。
- en: For instance, certain architectures such as [WGAN](https://arxiv.org/abs/1701.07875)
    and [WGAN-GP](https://arxiv.org/abs/1704.00028) introduced significant improvements
    to GAN in what concerns training stability and convergence time. [PacGAN](https://arxiv.org/abs/1712.04086),
    on the other hand, was designed to alleviate mode collapse, another common shortcoming
    of traditional GAN architectures.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，某些架构如 [WGAN](https://arxiv.org/abs/1701.07875) 和 [WGAN-GP](https://arxiv.org/abs/1704.00028)
    在训练稳定性和收敛时间方面对 GAN 做出了显著改进。而 [PacGAN](https://arxiv.org/abs/1712.04086) 则旨在缓解模式崩溃，这是传统
    GAN 架构的另一个常见缺陷。
- en: '**Yet, in what concerns data heterogeneity (i.e., handling both numeric and
    categorical features and their intrinsic characteristics) these architectures
    still seemed to fall short.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**然而，在数据异质性（即处理数值特征和类别特征及其内在特性）方面，这些架构仍然显得不足。**'
- en: Although they have shown to be great for numeric features, they struggled to
    capture the distributions of categorical features, whose presence is a reality
    for great the majority of real-world datasets.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们在数值特征上表现良好，但在捕捉类别特征的分布时遇到了困难，而类别特征在大多数现实世界数据集中是普遍存在的。
- en: Indeed, none of these architectures was conceptualized to address heterogeneous
    data comprising mixed feature types — both numeric *and* categorical.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，这些架构没有被概念化为处理包含混合特征类型的数据——既有数值型 *也有* 类别型。
- en: '**On the contrary, CTGAN was specifically designed to deal with the challenges
    posed by tabular datasets, handling mixed data.**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**相反，CTGAN 是专门设计来应对表格数据挑战的，处理混合数据。**'
- en: Building on top of the success attained by other architectures, such as WGAN-GP
    and PacGAN, **CTGAN goes one step further by considering synthetic data generation
    as a complete flow — from data preparation to the GAN architecture itself.** In
    other words, CTGAN attends to the specific characteristics of both numeric and
    categorical features and incorporates those characteristics into the generator
    model. *How?*
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基于其他架构（如 WGAN-GP 和 PacGAN）取得的成功，**CTGAN 进一步考虑了将合成数据生成作为一个完整的流程——从数据准备到 GAN 架构本身。**
    换句话说，CTGAN 关注数值特征和类别特征的具体特征，并将这些特征融入生成模型中。*如何做到的？*
- en: 'Numeric features: Non-Gaussian and Multimodal Distributions'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数值特征：非高斯和多模态分布
- en: '**CTGAN introduces Mode-Specific Normalization**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**CTGAN 引入了模式特定归一化**'
- en: Contrary to image data, where pixel values normally follow a Gaussian-like distribution,
    **continuous features in tabular data are often non-Gaussian.**
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与图像数据中像素值通常遵循高斯分布不同，**表格数据中的连续特征往往是非高斯的。**
- en: 'Moreover, they **tend to follow multimodal distributions**, where probability
    distributions have more than one mode, i.e., they present distinct local maxima
    (or “peaks”):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它们**往往遵循多模态分布**，即概率分布具有多个模式，即它们呈现出不同的局部极大值（或“峰值”）：
- en: '![](../Images/c3fa694d297e1a4fb73e11d468362f5f.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3fa694d297e1a4fb73e11d468362f5f.png)'
- en: Example of a Guassian-like versus a Skewed data distributon (Figs. a and b).
    Example of a multimodal distribution decomposed into distributions with distinct
    modes (c and d). Image by Author.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯型与偏斜数据分布的例子（图 a 和 b）。多模态分布分解为具有不同模式的分布的例子（图 c 和 d）。图片由作者提供。
- en: 'To capture these behaviors, CTGAN uses **mode-specific normalization**. Using
    a VGM (Variational Gaussian Mixture) model, each value in a continuous feature
    is represented by a one-hot vector indicating its sampled mode and a scalar that
    represents the value normalized according to that mode:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉这些行为，CTGAN 使用 **模式特定归一化**。通过使用 VGM（变分高斯混合）模型，连续特征中的每个值由一个表示其采样模式的独热向量和一个表示根据该模式归一化的值的标量组成：
- en: '![](../Images/b83ba6bee60f36edfd5e8f095c0345e4.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b83ba6bee60f36edfd5e8f095c0345e4.png)'
- en: An example of mode-specific normalization. ci,j represents a value i in a feature
    j (e.g., j = “Age”), for which p3 was picked. ci,j is therefore represented by
    a vector [ai,j, 0, 0, 1]. n3 and p3 represent the mode and standard deviation
    of p3\. Image from [1].
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 模式特定归一化的示例。ci,j 表示特征 j（例如，j = “年龄”）中的一个值 i，p3 被选择。因此，ci,j 由一个向量 [ai,j, 0, 0,
    1] 表示。n3 和 p3 分别代表 p3 的模式和标准差。图片来自 [1]。
- en: 'Categorical features: Sparse One-Hot-Encoded Vector and High Category Imbalance'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类特征：稀疏的独热编码向量和高类别失衡
- en: '**CTGAN introduces the Conditional Generator**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**CTGAN 引入了条件生成器**'
- en: 'CTGAN aims to address essentially two main challenges introduced by categorical
    features:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: CTGAN 旨在解决由分类特征引入的主要两个挑战：
- en: '**One is the the sparsity of one-hot-encoded vectors in real-world data.**
    While the generator outputs the probability distributions over all possible categorical
    values, the original “real” categorical values are directly encoded in a one-hot-vector.
    These are easily distinguishable by the discriminator by comparing the distribution
    sparseness between real and synthetic data.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一个是现实数据中独热编码向量的稀疏性。** 虽然生成器输出所有可能分类值的概率分布，但原始的“真实”分类值直接编码在独热向量中。通过比较真实和合成数据之间的分布稀疏性，鉴别器可以很容易区分这些数据。'
- en: '**The other is the imbalance associated to some categorical features.** If
    some categories of a feature are underrepresented, they cannot be learned adequately
    by the generator. If we were concerned with predictive modeling or classification
    tasks, data oversampling could be a solution to alleviate this issue. However,
    since the goal of synthetic data generation is to mimic the properties of the
    original data, this is not an option.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**另一个问题是某些分类特征的失衡。** 如果某些类别的特征被低估，生成器无法充分学习这些特征。如果我们关心的是预测建模或分类任务，数据过采样可能是缓解这个问题的解决方案。然而，由于合成数据生成的目标是模拟原始数据的属性，这不是一个选项。'
- en: '**CTGAN introduces a Conditional Generator** to deal with the challenges imposed
    by imbalanced categories which usually lead to GAN’s infamous mode collapse. Nevertheless,
    there are no free lunches with conditional architectures: **the input needs to
    be prepared** so that the generator can interpret the conditions, **and the generated
    rows need to preserve an input condition**.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**CTGAN 引入了条件生成器** 以应对由失衡类别带来的挑战，这通常会导致 GAN 臭名昭著的模式崩溃。然而，条件架构没有免费的午餐：**输入需要被准备好**
    以便生成器可以解释这些条件，**生成的行需要保留输入条件**。'
- en: 'To this end, CTGAN considers a **conditional vector** which, when used in a
    sample-by-sample training, makes a lot of difference in what concerns the use
    of CTGAN:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，CTGAN 考虑了一个 **条件向量**，在逐样本训练中使用时，CTGAN 的使用会有很大不同：
- en: '![](../Images/731878c5e5a23c8bf49f5553f37bed42.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/731878c5e5a23c8bf49f5553f37bed42.png)'
- en: Overview of the CTGAN model. With training-by-sampling, examples are conditioned
    on the possible values of categorical features, sampled according to their log-frequency.
    Image from [1].
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: CTGAN 模型概述。通过采样训练，示例根据分类特征的可能值进行条件化，并根据其对数频率进行采样。图片来自 [1]。
- en: Generating Synthetic Tabular Data with CTGAN
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 CTGAN 生成合成表格数据
- en: '**One of the easiest ways to get started with synthetic data is to explore
    the models available as open source software scattered through GitHub.** There
    are plenty of tools that you can experiment with: *take a look into the* [*awesome-data-centric-ai*](https://github.com/Data-Centric-AI-Community/awesome-data-centric-ai#-synthetic-data)
    *repository for a curated list of open-source tools!*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**获取合成数据的最简单方法之一是探索作为开源软件散布在 GitHub 上的模型。** 你可以尝试的工具很多：*查看* [*awesome-data-centric-ai*](https://github.com/Data-Centric-AI-Community/awesome-data-centric-ai#-synthetic-data)
    *库，获取开源工具的精选列表！*'
- en: '**When it comes to learning and experimenting with new libraries, I’m all for
    an easy and intuitive experience: if there’s a UI, even better.**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**在学习和尝试新库时，我倾向于选择简单直观的体验：如果有UI，那就更好。**'
- en: For synthetic data generation, `ydata-synthetic` has recently introduced a Streamlit
    app that lets us conduct a complete flow from data reading to profiling the newly
    generated synthetic data. *Perfect!*
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于合成数据生成，`ydata-synthetic`最近推出了一个Streamlit应用程序，让我们能够从数据读取到分析新生成的合成数据进行完整的流程。*太完美了！*
- en: '![](../Images/eaee4d32a4fb7f4a3136faa9606300d6.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eaee4d32a4fb7f4a3136faa9606300d6.png)'
- en: 'ydata-synthetic Streamlit app: Welcome Screen. Image by Author.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ydata-synthetic Streamlit应用程序：欢迎屏幕。作者提供的图像。
- en: 'The first step to get the UI running is installing `ydata-synthetic`. Don’t
    forget to add the “streamlit” extra:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让UI运行的第一步是安装`ydata-synthetic`。不要忘记添加“streamlit”额外组件：
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you can open up a Python file and run:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以打开一个Python文件并运行：
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After running the above command, the console will output the URL from which
    you can access the app!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述命令后，控制台将输出一个URL，您可以通过该URL访问应用程序！
- en: Train a Synthesizer Model
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练合成器模型
- en: 'Training a synthesizer is straightforward: you can access the “**Train a Synthesizer**”
    tab and upload a file (again, I’m using the Adult Census Income dataset):'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 训练合成器很简单：您可以访问“**训练合成器**”标签并上传一个文件（再次说明，我使用的是成人普查收入数据集）：
- en: '![](../Images/9390e1b69b3494f4bcd8c71103e81b52.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9390e1b69b3494f4bcd8c71103e81b52.png)'
- en: 'ydata-synthetic Streamlit app: Upload file. Screencast by Author.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ydata-synthetic Streamlit应用程序：上传文件。作者的录屏。
- en: 'Once the file loads, we need to specify which features are `numeric` and `categorical`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 文件加载后，我们需要指定哪些特征是`numeric`和`categorical`：
- en: '![](../Images/01f558ca1c18e02b21013ca25bb61b07.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01f558ca1c18e02b21013ca25bb61b07.png)'
- en: 'ydata-synthetic Streamlit app: Specify numeric and categorical features. Screencast
    by Author.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ydata-synthetic Streamlit应用程序：指定数值和分类特征。作者的录屏。
- en: Then, we can select our synthesizer parameters, namely the `model` we intend
    to use and its parameters, such as `batch size`, `learning rate`, and additional
    settings (e.g. `noise dimension`, `layer dimension`, and the regularization constants
    `beta`).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以选择我们的合成器参数，即我们打算使用的`model`及其参数，如`batch size`、`learning rate`和其他设置（例如`noise
    dimension`、`layer dimension`以及正则化常数`beta`）。
- en: 'Finally, we select the training parameters, namely the training `epochs`, and
    the training starts with a click of a button:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们选择训练参数，即训练`epochs`，然后点击一个按钮开始训练：
- en: '![](../Images/1a7ab9fae777680654ca7b33c7513446.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a7ab9fae777680654ca7b33c7513446.png)'
- en: 'ydata-synthetic Streamlit app: Define synthesizer and traning parameters. Screencast
    by Author.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ydata-synthetic Streamlit应用程序：定义合成器和训练参数。作者的录屏。
- en: Note that I’m naturally using CTGAN in the example, but other models are currently
    supported such as GAN, WGAN, WGANGP, CRAMER, and DRAGAN.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我在示例中自然使用了CTGAN，但目前也支持其他模型，如GAN、WGAN、WGANGP、CRAMER和DRAGAN。
- en: Generate and Profile Synthetic Data Samples
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成和分析合成数据样本
- en: To generate new synthetic samples, we can access the “**Generate synthetic data**”
    tab, choose the number of samples to generate and specify the filename where they’ll
    be saved.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成新的合成样本，我们可以访问“**生成合成数据**”标签，选择要生成的样本数量，并指定保存文件的文件名。
- en: Our model is saved and loaded by default as `trained_synth.pkl` but we can load
    a previously trained model by providing its path.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型默认保存并加载为`trained_synth.pkl`，但我们可以通过提供其路径来加载之前训练的模型。
- en: '![](../Images/a54f9970c135707eefb498543aae0cae.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a54f9970c135707eefb498543aae0cae.png)'
- en: 'ydata-synthetic Streamlit app: Generate new synthetic samples. Screencast by
    Author.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ydata-synthetic Streamlit应用程序：生成新的合成样本。作者的录屏。
- en: 'Additionally, I decided to generate a data profiling report to check the overall
    characteristics of the synthetic data, so I checked the “**Generate synthetic
    data profiling**” and the synthesization process starts by clicking “**Generate
    Samples**”:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我决定生成数据分析报告，以检查合成数据的整体特征，因此我勾选了“**生成合成数据分析**”，然后通过点击“**生成样本**”开始合成过程：
- en: '![](../Images/44256306c01ea416694065cb71be96b4.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/44256306c01ea416694065cb71be96b4.png)'
- en: 'ydata-synthetic Streamlit app: New synthetic samples and data profiling. Screencast
    by Author.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ydata-synthetic Streamlit应用程序：新的合成样本和数据分析。作者的录屏。
- en: The report is generated using the familiar `[ydata-profiling](https://github.com/ydataai/ydata-profiling)`
    package and the synthetic samples are now saved in a `synthetic_adult.csv` file.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 报告是使用熟悉的`[ydata-profiling](https://github.com/ydataai/ydata-profiling)`包生成的，合成样本现在保存在`synthetic_adult.csv`文件中。
- en: 'By exploring the profile report of our newly generated samples, we can easily
    determine that **CTGAN has sucessfully learned the characteristics of the original
    data**, even in a complex heterogeneous scenario such as the Adult Dataset:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过探索我们新生成样本的概况报告，我们可以轻松确定**CTGAN成功地学习了原始数据的特征**，即使在像成人数据集这样复杂的异构场景中也是如此：
- en: Basic feature **statistics remain consistent** for both numeric and categorical
    features (e.g., mean/standard deviation, number of categories/mode);
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本特征**统计数据保持一致**，适用于数值和分类特征（例如，均值/标准差、类别数量/众数）；
- en: The **representation of categorical features is mimicked**, i.e., the frequency
    of original categories is maintained on the synthetic data;
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别特征的表示被模仿**，即原始类别的频率在合成数据中得到保持。'
- en: The **underlying relationships** — correlation and interaction — between features
    **are also kept**, including the original data quality alerts (i.e., the synthetic
    data shows the same quality alerts as those presented for the original data).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征之间的**潜在关系**——相关性和交互——**也得到了保留**，包括原始数据质量警报（即，合成数据显示了与原始数据相同的质量警报）。
- en: Naturally, depending on the specific parameters given to the model, we can improve
    our synthetic data generation results so that the new data is as close as possible
    to the original data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，根据模型所给的具体参数，我们可以改进合成数据生成结果，使新数据尽可能接近原始数据。
- en: '*And that’s a wrap! Painless and hassle-free generation in just a few steps!*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*就这样！几步完成，轻松无忧！*'
- en: Limitations and Open Challenges
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制与开放挑战
- en: 'Although CTGAN has proven to be a powerful architecture for tabular data, it
    still has some limitations and drawbacks (some common to all deep learning models,
    as expected):'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管CTGAN已被证明是一个强大的表格数据架构，但它仍然存在一些限制和缺点（有些是所有深度学习模型共有的，正如预期的那样）：
- en: '**Optimizing hyperparameters** for datasets with different characteristics
    is challenging and it may require a significant amount of trial and error;'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于具有不同特征的数据集，**优化超参数**是具有挑战性的，可能需要大量的反复试验；
- en: '**Handling high-cardinality** features remains problematic since it becomes
    difficult for the model to learn and generate such a large number of unique categories;'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理高基数**特征仍然是个问题，因为模型学习和生成如此大量唯一类别变得困难；'
- en: '**Handling skewed distributions** or distributions with a large amount of **constant
    values** (e.g., a large amount of 0’s) are also hard to capture by this architecture;'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理**偏斜分布**或包含大量**常量值**（例如，大量0）的分布也是该架构难以捕捉的；
- en: Synthesization might be less accurate for **small datasets**, since CTGAN, as
    any other deep learning model, is data savvy;
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于**小数据集**，合成的准确性可能较低，因为CTGAN与其他深度学习模型一样，对数据的要求较高；
- en: Training and convergence may require significant **computational resources and
    time**, especially for very large datasets;
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和收敛可能需要大量的**计算资源和时间**，尤其是对于非常大的数据集；
- en: Overall, CTGAN can be most effective for generating synthetic data for **structured,
    tabular datasets with heterogeneous features and an adequate training size**,
    but may require a sharp eye to spot specific data characteristics and assess whether
    the model is in the best possible conditions to generate synthetic data that accurately
    incorporates the properties of the original data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，CTGAN在为**结构化、具有异构特征且训练规模适中的表格数据集生成合成数据**方面最为有效，但可能需要细致的观察，以发现特定的数据特征并评估模型是否在最佳条件下生成准确反映原始数据特性的合成数据。
- en: Final Thoughts
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: Throughout this article, we discussed the working principles of CTGAN, focusing
    on how the architecture captures certain complex characteristics, extensively
    found in real-world domains. Additionally, we explored the `ydata-synthetic` Streamlit
    app, that allows us to get started with synthetic data and learn more about CTGAN
    and other generation models in a no-code, friendly environment. *Pretty cool,
    han?*
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们讨论了CTGAN的工作原理，重点关注了该架构如何捕捉在现实世界领域广泛存在的某些复杂特征。此外，我们还探讨了`ydata-synthetic`
    Streamlit应用程序，这使我们可以开始使用合成数据，并在无代码、友好的环境中更多地了解CTGAN和其他生成模型。*很酷，对吧？*
- en: To be added to the UI soon is the support for time-series models, namely [TimeGAN](/synthetic-time-series-data-a-gan-approach-869a984f2239),
    more advanced settings for CTGAN, and [side-by-side comparison reports](https://pub.towardsai.net/how-to-compare-2-dataset-with-pandas-profiling-2ae3a9d7695e)
    using `ydata-profiling`. *Something to look for in future articles!*
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 即将加入 UI 的功能包括对时间序列模型的支持，即 [TimeGAN](/synthetic-time-series-data-a-gan-approach-869a984f2239)、CTGAN
    的更高级设置，以及使用 `ydata-profiling` 的 [并排比较报告](https://pub.towardsai.net/how-to-compare-2-dataset-with-pandas-profiling-2ae3a9d7695e)。*期待未来的文章！*
- en: 'As always, feedback, questions, and suggestions are always appreciated: you
    can leave me a comment, star or contribute to the repo, and even find me at the
    [Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) to discuss other
    data-related topics. *See you there?*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，反馈、问题和建议总是受到欢迎：您可以留下评论、给仓库加星或贡献，甚至在 [数据中心 AI 社区](https://tiny.ydata.ai/dcai-medium)
    讨论其他数据相关话题。*到时候见？*
- en: About me
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: Ph.D., Machine Learning Researcher, Educator, Data Advocate, and overall “jack-of-all-trades”.
    Here on Medium, I write about **Data-Centric AI and Data Quality**, educating
    the Data Science & Machine Learning communities on how to move from imperfect
    to intelligent data.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 博士，机器学习研究员，教育者，数据倡导者，以及全面的“万事通”。在 Medium 上，我撰写关于 **数据中心 AI 和数据质量** 的文章，教育数据科学与机器学习社区如何将不完美的数据转变为智能数据。
- en: '[Data-Centric AI Community](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据中心 AI 社区](https://tiny.ydata.ai/dcai-medium) | [GitHub](https://github.com/Data-Centric-AI-Community)
    | [Google Scholar](https://scholar.google.com/citations?user=isaI6u8AAAAJ&hl=en)
    | [LinkedIn](https://www.linkedin.com/in/miriamseoanesantos/)'
- en: References
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Xu, L., Skoularidou, M., Cuesta-Infante, A., & Veeramachaneni, K. [Modeling
    Tabular Data Using Conditional GAN](https://arxiv.org/abs/1907.00503) (2019).
    *Advances in Neural Information Processing Systems, 32.*
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Xu, L., Skoularidou, M., Cuesta-Infante, A., & Veeramachaneni, K. [使用条件 GAN
    建模表格数据](https://arxiv.org/abs/1907.00503)（2019年）。*神经信息处理系统进展，32*。
- en: Arjovsky, M., Chintala, S., & Bottou, L. [Wasserstein Generative Adversarial
    Networks](https://arxiv.org/abs/1701.07875) (2017). In *International conference
    on machine learning* (pp. 214–223).
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Arjovsky, M., Chintala, S., & Bottou, L. [Wasserstein 生成对抗网络](https://arxiv.org/abs/1701.07875)（2017年）。在
    *国际机器学习大会*（第214–223页）。
- en: Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., & Courville, A. C. [Improved
    Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028) (2017). *Advances
    in neural information processing systems*, *30*.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., & Courville, A. C. [改进的
    Wasserstein GAN 训练](https://arxiv.org/abs/1704.00028)（2017年）。*神经信息处理系统进展*，*30*。
- en: 'Lin, Z., Khetan, A., Fanti, G., & Oh, S. PacGAN: [The power of two samples
    in generative adversarial networks](https://arxiv.org/abs/1712.04086) (2018).
    *Advances in neural information processing systems*, *31*.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Lin, Z., Khetan, A., Fanti, G., & Oh, S. PacGAN: [生成对抗网络中两个样本的力量](https://arxiv.org/abs/1712.04086)（2018年）。*神经信息处理系统进展*，*31*。'
- en: Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., Courville, A. & Bengio, Y. (2014). [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661).
    In *Advances in neural information processing systems* (pp. 2672–2680).
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
    S., Courville, A. & Bengio, Y. (2014). [生成对抗网络](https://arxiv.org/abs/1406.2661)。在
    *神经信息处理系统进展*（第2672–2680页）。
- en: '[Adult Census Income](https://www.kaggle.com/datasets/uciml/adult-census-income)
    Dataset (obtained from [Kaggle](https://www.kaggle.com) under the [CC0: Public
    Domain](https://creativecommons.org/publicdomain/zero/1.0/) license). Kohavi R.,
    [Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid](http://robotics.stanford.edu/~ronnyk/nbtree.pdf)
    (1996), *Proceedings of the Second International Conference on Knowledge Discovery
    and Data Mining.*'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[成人普查收入](https://www.kaggle.com/datasets/uciml/adult-census-income) 数据集（获取自
    [Kaggle](https://www.kaggle.com)，根据 [CC0: 公共领域](https://creativecommons.org/publicdomain/zero/1.0/)
    许可证）。Kohavi R.，[提高朴素贝叶斯分类器准确性的规模化：决策树混合方法](http://robotics.stanford.edu/~ronnyk/nbtree.pdf)（1996年），*第二届国际知识发现与数据挖掘大会论文集*。'
