- en: 'Unsupervised Learning Series: Exploring Hierarchical Clustering'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习系列：探索层次聚类
- en: 原文：[https://towardsdatascience.com/unsupervised-learning-series-exploring-hierarchical-clustering-15d992467aa8](https://towardsdatascience.com/unsupervised-learning-series-exploring-hierarchical-clustering-15d992467aa8)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unsupervised-learning-series-exploring-hierarchical-clustering-15d992467aa8](https://towardsdatascience.com/unsupervised-learning-series-exploring-hierarchical-clustering-15d992467aa8)
- en: Let’s explore how hierarchical clustering works and how it builds clusters based
    on pairwise distances.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们探讨层次聚类是如何工作的，以及它如何基于成对距离构建簇。
- en: '[](https://ivopbernardo.medium.com/?source=post_page-----15d992467aa8--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page-----15d992467aa8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----15d992467aa8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----15d992467aa8--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page-----15d992467aa8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ivopbernardo.medium.com/?source=post_page-----15d992467aa8--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page-----15d992467aa8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----15d992467aa8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----15d992467aa8--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page-----15d992467aa8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----15d992467aa8--------------------------------)
    ·11 min read·Jun 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----15d992467aa8--------------------------------)
    ·阅读时间 11 分钟·2023年6月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1ad73696743c551e19d34fe0ff09b9b0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ad73696743c551e19d34fe0ff09b9b0.png)'
- en: Photo by Nathan Anderson @unsplash.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Nathan Anderson @unsplash.com
- en: In my last post of the Unsupervised Learning Series, we explored one of the
    most famous clustering methods, the [K-means Clustering](https://medium.com/towards-data-science/unsupervised-learning-method-series-exploring-k-means-clustering-d129fff3ab6a).
    In this post, we are going to discuss the methods behind another important clustering
    technique — **hierarchical clustering**!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我上一篇无监督学习系列的文章中，我们探讨了最著名的聚类方法之一，[K-means 聚类](https://medium.com/towards-data-science/unsupervised-learning-method-series-exploring-k-means-clustering-d129fff3ab6a)。在这篇文章中，我们将讨论另一种重要聚类技术背后的方法——**层次聚类**！
- en: This method is also based on distances (euclidean, manhattan, etc.) and uses
    an hierarchical representation of data to combine data points. Contrary to *k-means,*
    it does not contain any hyperparameter regarding the number of centroids (such
    as *k*) that data scientists can configure.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法也基于距离（欧氏距离、曼哈顿距离等），并使用数据的层次表示来组合数据点。与*k-means* 相反，它不包含任何关于质心数量的超参数（如*k*），这些是数据科学家可以配置的。
- en: 'Mostly, hierarchical clustering can be divided into two groups: agglomerative
    clustering and divisive clustering. In the first, data points are considered single
    units and are aggregated to nearby data points based on distances. In the latter,
    we consider all data points as a single cluster and start to divide them based
    on certain criteria. As the agglomerative version is the most famous and widely
    used ([sklearn’s built-in implementation follows this protocol](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html´)),
    that is the hierarchical type we are going to explore in this post.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，层次聚类可以分为两类：凝聚型聚类和分裂型聚类。在前者中，数据点被视为单一单位，并根据距离聚合到附近的数据点。在后者中，我们将所有数据点视为一个整体簇，并根据某些标准开始将其划分。由于凝聚型版本是最著名和广泛使用的（[sklearn
    的内置实现遵循这种协议](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)），这是我们将在这篇文章中探讨的层次类型。
- en: 'In this blog post we’ll approach Agglomerative Hierarchical Clustering in two
    steps:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将分两步探讨凝聚型层次聚类：
- en: First, we’ll do a play-by-play analysis of how hierarchies are built, using
    agglomerative clustering with the *average* method (one of the methods we can
    use to build the hierarchy of data points).
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们将逐步分析如何构建层次结构，使用凝聚型聚类中的*平均*方法（这是我们用来构建数据点层次结构的方法之一）。
- en: Then, we’ll see some examples of how to fit a hierarchical clustering on a real
    dataset using *sklearn’s* implementation. This is also where we’ll detail other
    methods we can use to build our hierarchies (*ward, minimum, etc.*)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们将看到如何使用 *sklearn* 的实现对实际数据集进行层次聚类的一些示例。这也是我们详细说明构建层次结构的其他方法（*ward, minimum,
    等*）的地方。
- en: Let’s start!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Agglomerative Clustering Example — Step by Step
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 聚类示例 — 步骤详解
- en: 'In our step-by-step example, we are going to use a fictional dataset with 5
    customers:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的逐步示例中，我们将使用一个包含5个客户的虚拟数据集：
- en: '![](../Images/3d0f507a52c1a87959d8c20acbd598fe.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d0f507a52c1a87959d8c20acbd598fe.png)'
- en: Hierarchical Clustering Example — Image by Author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类示例 — 作者图片
- en: 'Let’s imagine that we run a shop with 5 customers and we wanted to group these
    customers based on their similarities. We have two variables that we want to consider:
    the *customer’s age* and their *annual income*.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 设想一下我们经营一个有5个客户的商店，并希望根据他们的相似性对这些客户进行分组。我们有两个变量需要考虑：*客户年龄*和*年收入*。
- en: '**The first step of our agglomerative clustering consists of creating pairwise
    distances between all our data points.** Let’s do just that by representing each
    data point by their coordinate in a [x, y] format:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们聚类的第一步是计算所有数据点之间的成对距离。** 我们通过将每个数据点表示为[x, y]格式来实现：'
- en: 'Distance between [60, 30] and [60, 55]: **25.0**'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 30]和[60, 55]之间的距离：**25.0**'
- en: 'Distance between [60, 30] and [30, 75]: **54.08**'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 30]和[30, 75]之间的距离：**54.08**'
- en: 'Distance between [60, 30] and [41, 100]: **72.53**'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 30]和[41, 100]之间的距离：**72.53**'
- en: 'Distance between [60, 30] and [38, 55]: **33.30**'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 30]和[38, 55]之间的距离：**33.30**'
- en: 'Distance between [60, 55] and [30, 75]: **36.06**'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 55]和[30, 75]之间的距离：**36.06**'
- en: 'Distance between [60, 55] and [41, 100]: **48.85**'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 55]和[41, 100]之间的距离：**48.85**'
- en: 'Distance between [60, 55] and [38, 55]: **22.0**'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 55]和[38, 55]之间的距离：**22.0**'
- en: 'Distance between [30, 75] and [41, 100]: **27.31**'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30, 75]和[41, 100]之间的距离：**27.31**'
- en: 'Distance between [30, 75] and [38, 55]: **21.54**'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30, 75]和[38, 55]之间的距离：**21.54**'
- en: 'Distance between [41, 100] and [38, 55]: **45.10**'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41, 100]和[38, 55]之间的距离：**45.10**'
- en: Although we can use any type of distance metric we want, we’ll use [euclidean](https://en.wikipedia.org/wiki/Euclidean_distance)
    due to its simplicity. From the pairwise distances we’ve calculated above, which
    distance is the smallest one?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可以使用任何类型的距离度量，但由于其简单性，我们将使用[欧几里得距离](https://en.wikipedia.org/wiki/Euclidean_distance)。从我们之前计算的成对距离中，哪一个是最小的呢？
- en: '**The distance between middle aged customers that make less than 90k dollars
    a year — customers on coordinates [30, 75] and [38, 55]!**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**中年客户之间的距离，这些客户年收入不到90k美元 — 坐标为[30, 75]和[38, 55]！**'
- en: 'Reviewing the formula for euclidean distance between two arbitrary points *p1*
    and *p2*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下两个任意点 *p1* 和 *p2* 之间的欧几里得距离公式：
- en: '![](../Images/7ce3ab7b2ae103b307ef2f97f38e805b.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ce3ab7b2ae103b307ef2f97f38e805b.png)'
- en: Euclidean Distance Formula — image by author
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离公式 — 作者图片
- en: 'Let’s visualize our smallest distance on the 2-D plot by connecting the two
    customers that are nearer:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过连接更近的两个客户，在二维图上可视化我们最小的距离：
- en: '![](../Images/4db474d8ffd6e89e314f7d5b4499c89c.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4db474d8ffd6e89e314f7d5b4499c89c.png)'
- en: Connecting the two closest customers — Image by Author
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 连接两个最近的客户 — 作者图片
- en: '**The next step of hierarchical clustering is to consider these two customers
    as our first cluster!**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**层次聚类的下一步是将这两个客户视为我们的第一个簇！**'
- en: '![](../Images/795dc268cf3e64281ad7e78bc5610762.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/795dc268cf3e64281ad7e78bc5610762.png)'
- en: Considering closest customers as one cluster — Image by Author
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将最近的客户视为一个簇 — 作者图片
- en: 'Next, we are going to calculate the distances between the data points, again.
    **But this time, the two customers that we’ve grouped into a single cluster will
    be treated as a single data point**. For instance, consider the red point below
    that positions itself in the middle of the two data points:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将再次计算数据点之间的距离。**但这一次，我们将把我们分为一个簇的两个客户视为一个数据点**。例如，考虑下面的红点，它位于两个数据点的中间：
- en: '![](../Images/89f31736bf227760d31178f8cd98b8e8.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89f31736bf227760d31178f8cd98b8e8.png)'
- en: Considering closest customers as one cluster — Image by Author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将最近的客户视为一个簇 — 作者图片
- en: In summary, for the next iterations of our hierarchical solution, we won’t consider
    the coordinates of the original data points (*emojis*) but the red point (the
    *average* between those data points). This is the standard way to calculate distances
    on the ***average linkage method.***
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，对于我们层次解决方案的下一次迭代，我们不会考虑原始数据点的坐标（*表情符号*），而是红点（这些数据点之间的*平均值*）。这就是计算***平均连结方法***距离的标准方式。
- en: 'Other methods we can use to calculate distances based on aggregated data points
    are:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用来计算基于聚合数据点的距离的其他方法有：
- en: 'Maximum (or *complete* linkage): considers the farthest data point in the cluster
    related to the point we are trying to aggregate.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大（或*完全*连结）：考虑与我们尝试聚合的点相关的集群中最远的数据点。
- en: 'Minimum (or *single* linkage): considers the closest data point in the cluster
    related to the point we are trying to aggregate.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小（或*单一*连结）：考虑与我们尝试聚合的点相关的集群中最近的数据点。
- en: 'Ward (or *ward* linkage): minimizes the variance in the clusters with the next
    aggregation.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ward（或*Ward*连结）：在下一次聚合中最小化集群中的方差。
- en: 'Let me do a small break on the step-by-step explanation to delve a bit deeper
    into the linkage methods as they are crucial in this type of clustering. Here’s
    a visual example of the different *linkage* methods available in hierarchical
    clustering, for a fictional example of 3 clusters to merge:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我在逐步解释中稍作停顿，*深入探讨*一下连结方法，因为这些方法在这种类型的聚类中至关重要。这里是一个关于层次聚类中不同*连结*方法的视觉示例，展示了合并的3个虚拟集群：
- en: '![](../Images/b4704ccc475adb3c5e542c173e373ab0.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4704ccc475adb3c5e542c173e373ab0.png)'
- en: Linkage Methods Visualization
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 连结方法可视化
- en: In the *sklearn* implementation**,** we’ll be able to experiment with some of
    these linkage methods and see a significant difference in the clustering results.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在*sklearn*实现中，我们将能够尝试一些这些连结方法，并在聚类结果中看到显著差异。
- en: 'Returning to our example, let’s now generate the distances between all our
    new data points — remember that there are two clusters that are being treated
    as a single one from now on:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 返回我们的示例，现在生成所有新数据点之间的距离 — 记住，从现在开始有两个集群被视为一个：
- en: '![](../Images/89f31736bf227760d31178f8cd98b8e8.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89f31736bf227760d31178f8cd98b8e8.png)'
- en: Considering closest customers as one cluster — Image by Author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将最接近的客户视为一个集群 — 作者提供的图像
- en: 'Distance between [60, 30] and [60, 55]: 25.0'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 30]与[60, 55]之间的距离：25.0'
- en: 'Distance between [60, 30] and [34, 65]: 43.60'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 30]与[34, 65]之间的距离：43.60'
- en: 'Distance between [60, 30] and [41, 100]: 72.53'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 30]与[41, 100]之间的距离：72.53'
- en: 'Distance between [60, 55] and [34, 65]: 27.85'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 55]与[34, 65]之间的距离：27.85'
- en: 'Distance between [60, 55] and [41, 100]: 48.85'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 55]与[41, 100]之间的距离：48.85'
- en: 'Distance between [34, 65] and [41, 100]: 35.69'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34, 65]与[41, 100]之间的距离：35.69'
- en: Which distance has the shortest path? **It’s the path between data points on
    coordinates [60, 30] and [60, 55]:**
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个距离最短？ **是坐标[60, 30]和[60, 55]之间的路径：**
- en: '![](../Images/27cce7426459cc20c344792be41e560b.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27cce7426459cc20c344792be41e560b.png)'
- en: Considering next closest customers as one cluster — Image by Author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 将下一个最接近的客户视为一个集群 — 作者提供的图像
- en: 'The next step is, naturally, to join these two customers into a single cluster:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步自然是将这两个客户合并为一个集群：
- en: '![](../Images/c8a9fe6c5b117aed167c88b1bb013b1d.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8a9fe6c5b117aed167c88b1bb013b1d.png)'
- en: Creating next cluster — Image by Author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 创建下一个集群 — 作者提供的图像
- en: With this new landscape of clusters, we calculate pairwise distances again!
    **Remember that we are always considering the average between data points (due
    to the linkage method we chose) in each cluster as reference point for the distance
    calculation:**
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新的集群布局中，我们再次计算成对的距离！ **请记住，我们总是将每个集群中数据点之间的平均值（根据我们选择的连结方法）作为距离计算的参考点：**
- en: 'Distance between [60, 42.5] and [34, 65]: 34.38'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 42.5]与[34, 65]之间的距离：34.38'
- en: 'Distance between [60, 42.5] and [41, 100]: 60.56'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60, 42.5]与[41, 100]之间的距离：60.56'
- en: 'Distance between [34, 65] and [41, 100]: 35.69'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34, 65]与[41, 100]之间的距离：35.69'
- en: '**Interestingly, the next data points to aggregate are the two clusters** as
    they lie on coordinates [60, 42.5] and [34, 65]:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**有趣的是，下一个需要聚合的数据点是两个集群**，它们位于坐标[60, 42.5]和[34, 65]：'
- en: '![](../Images/4e28889a138d4bbe81ed62b0f596ecf3.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e28889a138d4bbe81ed62b0f596ecf3.png)'
- en: Merging the next clusters — Image by Author
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 合并下一个集群 — 作者提供的图像
- en: 'Finally, we finish the algorithm by aggregating all data points in a single
    big cluster:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们通过将所有数据点聚合成一个大集群来完成算法：
- en: '![](../Images/91c6107ce3b6a50cd6b9ce8e16f037ed.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91c6107ce3b6a50cd6b9ce8e16f037ed.png)'
- en: Merging the final data point into our cluster — Image by Author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 将最终数据点合并到我们的簇中 — 作者提供的图片
- en: With this in mind, where do we exactly stop? It’s probably not a great idea
    to have a single big cluster with all data points, right?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，我们到底在哪里停止呢？拥有一个包含所有数据点的大簇可能不是一个好主意，对吧？
- en: To know where we stop, there’s some heuristic rules we can use. But first, we
    need to get familiar with another way of visualizing the process we’ve just done
    — the ***dendrogram****:*
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要知道我们在哪里停止，我们可以使用一些启发式规则。但首先，我们需要熟悉另一种可视化我们刚刚完成的过程的方式 —— ***树状图***：
- en: '![](../Images/cce2f025357fa3de06747671f842dcf9.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cce2f025357fa3de06747671f842dcf9.png)'
- en: Dendrogram of Our Hierarchical Clustering Solution — Image by Author
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的层次聚类解决方案的树状图 — 作者提供的图片
- en: On the *y-axis,* we have the distances that we’ve just calculated. On the *x-axis,*
    we have each data point. Climbing from each data point, we reach an horizontal
    line — the y-axis value of this line states the total distance that will connect
    the data points on the edges.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在*y轴*上，我们有刚刚计算的距离。在*x轴*上，我们有每个数据点。从每个数据点爬升，我们到达一条水平线 —— 这条线的 y 轴值表示将连接边缘数据点的总距离。
- en: 'Remember the first customers we’ve connected in a single cluster? What we’ve
    seen in the 2D plot matches the dendrogram as those are exactly the first customers
    connected using an horizontal line (climbing the dendrogram from below):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们最初将客户连接成一个簇吗？我们在 2D 图中的观察结果与树状图相符，因为这些正是使用水平线连接的第一个客户（从树状图底部爬升）：
- en: '![](../Images/30aa14b1b9d6fa8c84dda27ecaf1fa79.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30aa14b1b9d6fa8c84dda27ecaf1fa79.png)'
- en: First Horizontal Line in Dendrogram — Image by Author
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 树状图中的第一条水平线 — 作者提供的图片
- en: The horizontal lines represent the merging process we’ve just done! **Naturally,
    the dendrogram ends in a big horizontal line that connects all data points.**
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 水平线代表我们刚刚完成的合并过程！**自然地，树状图的末尾是一条连接所有数据点的大水平线。**
- en: As we just got familiar with the *Dendrogram*, we’re now ready to check the
    *sklearn* implementation and use a real dataset to understand how we can select
    the appropriate number of clusters based on this cool clustering method!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经熟悉了*树状图*，我们现在准备检查*sklearn*实现，并使用真实数据集来理解如何根据这种酷炫的聚类方法选择适当的簇数量！
- en: Sklearn Implementation
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sklearn 实现
- en: For the sklearn implementation, I’m going to use the Wine Quality dataset available
    [here.](https://archive.ics.uci.edu/dataset/186/wine+quality)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 sklearn 实现，我将使用[这里](https://archive.ics.uci.edu/dataset/186/wine+quality)提供的葡萄酒质量数据集。
- en: '[PRE0]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/dbc1f9f527fa660bccf69d2e8a76a9bd.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbc1f9f527fa660bccf69d2e8a76a9bd.png)'
- en: Wine Quality Data Set Preview — Image by Author
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 葡萄酒质量数据集预览 — 作者提供的图片
- en: This dataset contains information about wines (particularly red wines) with
    different characteristics such as citric acid, chlorides or density. The last
    column of the dataset gives respect to the quality of the wine, a classification
    done by a jury panel.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含了关于葡萄酒（特别是红葡萄酒）的信息，如柠檬酸、氯化物或密度等特征。数据集的最后一列表示葡萄酒的质量，这是由一个评审小组进行的分类。
- en: '**As hierarchical clustering deals with distances and we’re going to use the
    euclidean distance, we need to standardize our data.** We’ll start by using a
    `StandardScaler`on top of our data:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**由于层次聚类处理的是距离，而我们将使用欧几里得距离，我们需要对数据进行标准化。** 我们将从对数据应用 `StandardScaler` 开始：'
- en: '[PRE1]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With our scaled dataset, we can fit our first hierarchical clustering solution!
    We can access hierarchical clustering by creating an `AgglomerativeClustering`
    object:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们标准化的数据集，我们可以拟合我们的第一个层次聚类解决方案！我们可以通过创建一个 `AgglomerativeClustering` 对象来访问层次聚类：
- en: '[PRE2]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let me detail the arguments we are using inside the *AgglomerativeClustering*:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我详细说明我们在*AgglomerativeClustering*中使用的参数：
- en: '`n_clusters=None` is used as a way to have the full solution of the clusters
    (and where we can produce the full dendrogram).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_clusters=None` 用作获取所有簇的完整解决方案的方式（并且在这里我们可以生成完整的树状图）。'
- en: '`distance_threshold = 0` must be set in the `sklearn` implementation for the
    full dendrogram to be produced.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`distance_threshold = 0` 必须在 `sklearn` 实现中设置，以生成完整的树状图。'
- en: '`linkage = ‘average’` is a very important hyperparameter. Remember that, in
    the theoretical implementation, we’ve described one method to consider the distances
    between newly formed clusters. `average` is the method that considers the average
    point between every new formed cluster in the calculation of new distances. In
    the `sklearn` implementation, we have three other methods that we also described:
    `single` , `complete` and `ward` .'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`linkage = ‘average’`是一个非常重要的超参数。记住，在理论实现中，我们描述了一种考虑新形成簇之间距离的方法。`average`是计算新距离时考虑每个新形成簇之间的平均点的方法。在`sklearn`实现中，我们还有三种其他方法，也就是我们所描述的：`single`，`complete`和`ward`。'
- en: 'After fitting the model, it’s time to plot our dendrogram. For this, I’m going
    to use the helper function provided in the `sklearn` [documentation](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合模型后，接下来是绘制树状图。为此，我将使用`sklearn` [文档](https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html)中提供的辅助函数：
- en: '[PRE3]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If we plot our hierarchical clustering solution:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制我们的层次聚类解决方案：
- en: '[PRE4]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/3320257042cb9f8d72717bda19149824.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3320257042cb9f8d72717bda19149824.png)'
- en: Dendrogram of Average Method — Image by Author
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 平均方法的树状图 — 作者提供的图像
- en: 'The dendrogram is not great as our observations seem to get a bit jammed. Sometimes,
    the `average` , `single` and `complete` linkage may result in strange dendrograms,
    particularly when there are strong outliers in the data. The `ward` method may
    be appropriate for this type of data so let’s test that method:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个树状图不是很好，因为我们的观察似乎有点拥挤。有时，`average`，`single`和`complete`链接可能会导致奇怪的树状图，尤其是当数据中有强烈的离群值时。`ward`方法可能适合这种类型的数据，因此我们来测试一下这个方法：
- en: '[PRE5]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/6d4f1dd94235fae92b91c7f484cd1b3b.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d4f1dd94235fae92b91c7f484cd1b3b.png)'
- en: Dendrogram of Ward Method — Image by Author
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Ward 方法的树状图 — 作者提供的图像
- en: Much better! Notice that the clusters seem to be better defined according to
    the dendrogram. The ward method attempts to divide clusters by minimizing the
    intra-variance between newly formed clusters ([https://online.stat.psu.edu/stat505/lesson/14/14.7](https://online.stat.psu.edu/stat505/lesson/14/14.7))
    as we’ve described on the first part of the post. The objective is that for every
    iteration the clusters to be aggregated minimize the variance (distance between
    data points and new cluster to be formed).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 更好了！注意到这些簇似乎根据树状图得到了更好的定义。正如我们在帖子第一部分中描述的，ward方法试图通过最小化新形成簇之间的内部方差来划分簇（[https://online.stat.psu.edu/stat505/lesson/14/14.7](https://online.stat.psu.edu/stat505/lesson/14/14.7)）。目标是使得每次迭代中要聚合的簇最小化方差（数据点与新簇之间的距离）。
- en: Again, changing methods can be achieved by changing the `linkage` parameter
    in the `AgglomerativeClustering` function!
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，通过更改`linkage`参数可以在`AgglomerativeClustering`函数中实现更换方法！
- en: 'As we’re happy with the look of the `ward` method dendrogram, we’ll use that
    solution for our cluster profilling:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们对`ward`方法的树状图效果满意，我们将使用该解决方案进行簇分析：
- en: '![](../Images/6d4f1dd94235fae92b91c7f484cd1b3b.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d4f1dd94235fae92b91c7f484cd1b3b.png)'
- en: Dendrogram of Ward Method — Image by Author
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Ward 方法的树状图 — 作者提供的图像
- en: Can you guess how many clusters we should choose?
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 你能猜到我们应该选择多少个簇吗？
- en: 'According to the distances, a good candidate is cutting the dendrogram on this
    point, where every cluster seems to be relatively far from each other:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 根据距离，一个好的选择是将树状图在这个点切割，在这里每个簇似乎相对彼此远离：
- en: '![](../Images/b7039304ec84b89b551748b390d42724.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7039304ec84b89b551748b390d42724.png)'
- en: Dendrogram of Ward Method with Cutoff at 30 — Image by Author
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Ward 方法的树状图，截止点在 30 — 作者提供的图像
- en: The number of vertical lines that our line crosses are the number of final clusters
    of our solution. Choosing the number of clusters is not very “scientific” and
    different number of clustering solutions may be achieved, depending on business
    interpretation. For example, in our case, cutting off our dendrogram a bit above
    and reducing the number of clusters of the final solution may also be an hypothesis.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的线穿过的垂直线数即为最终解的簇数。选择簇的数量并不是很“科学”，不同的簇数可能会得到不同的聚类解，这取决于业务解释。例如，在我们的案例中，稍微在树状图上方切割并减少最终解的簇数也可能是一种假设。
- en: 'We’ll stick with the 7 cluster solution, so let’s fit our `ward` method with
    those `n_clusters` in mind:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将坚持使用 7 个簇的解决方案，因此让我们将`ward`方法与这些`n_clusters`进行拟合：
- en: '[PRE6]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**As we want to interpret our clusters based on the original variables, we’ll
    use the predict method on the scaled data (the distances are based on the scaled
    dataset) but add the cluster to the original dataset.**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**由于我们希望基于原始变量解释我们的集群，我们将对标准化数据使用预测方法（距离基于标准化数据集）但将集群添加到原始数据集中。**'
- en: 'Let’s compare our clusters using the means of each variable conditioned on
    the `cluster` variable:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用每个变量的均值来比较我们的集群，条件是 `集群` 变量：
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/e91997b6c3ee6c462c3ac67985e918ea.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e91997b6c3ee6c462c3ac67985e918ea.png)'
- en: Cluster Profilling — Image by Author
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 集群特征分析——作者图像
- en: 'Interestingly, we can start to have some insights about the data — for example:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们可以开始对数据进行一些见解——例如：
- en: 'Low quality wines seem to have a large value of `total sulfur dioxide` — notice
    the difference between the highest average quality cluster and the lower quality
    cluster:'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低质量的葡萄酒似乎有较高的 `总二氧化硫` 含量——请注意最高平均质量集群和较低质量集群之间的差异：
- en: '![](../Images/f6a9841ea9045e02b2aa01cab9c4877e.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6a9841ea9045e02b2aa01cab9c4877e.png)'
- en: Sulfur Dioxide between Cluster 6 and 2 — Image by Author
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 集群 6 和 2 之间的二氧化硫——作者图像
- en: 'And if we compare the `quality` of the wines in these clusters:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们比较这些集群中葡萄酒的 `质量`：
- en: '![](../Images/fab1b35968b601570de7f43b8f2e895d.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fab1b35968b601570de7f43b8f2e895d.png)'
- en: Quality Density Plot between Cluster 6 and 2 — Image by Author
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 集群 6 和 2 之间的质量密度图——作者图像
- en: Clearly, on average, Cluster 2 contains higher quality wines.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，平均而言，集群 2 包含更高质量的葡萄酒。
- en: 'Another cool analysis we can do is performing a correlation matrix between
    clustered data means:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的分析是对聚类数据均值进行相关矩阵分析：
- en: '![](../Images/9f56e000fddc1b9bb185a0703855ef6c.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f56e000fddc1b9bb185a0703855ef6c.png)'
- en: Correlation Matrix of Cluster Means— Image by Author
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 集群均值的相关矩阵——作者图像
- en: This gives us some good hints of potential things we can explore (even for supervised
    learning). For example, on a multidimensional level, wines with higher `sulphates`
    and `chlorides` may get bundled together. Another conclusion is that wines with
    higher alcohol proof tend to be associated with higher quality wines.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一些可以探索的潜在线索（即使是对监督学习）。例如，在多维层面上，含有较高 `硫酸盐` 和 `氯化物` 的葡萄酒可能会被聚集在一起。另一个结论是，含有更高酒精度的葡萄酒往往与更高质量的葡萄酒相关。
- en: Conclusion
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: That’s it! Thank you for taking the time to read this blog post about unsupervised
    learning. I’ll keep adding more unsupervised learning algorithms to this series
    to showcase different types of methods we can use to get to know the structure
    of our data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！感谢您花时间阅读这篇关于无监督学习的博客文章。我会继续在这个系列中添加更多无监督学习算法，以展示我们可以使用的不同类型的方法来了解数据的结构。
- en: 'Naturally, Hierarchical Clustering has some pros and cons that we can discuss:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，层次聚类有一些优缺点，我们可以讨论：
- en: A big con of the algorithm is that it may require too much heuristics to reach
    a final solution. A combination of dendrogram analysis, distance based analysis,
    or silhouette coefficient methods may be applied to reach a number of clusters
    that make sense. Also, one must not discard crossing these technical approaches
    with some business knowledge about the data to avoid falling in some type of clustering
    trap.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的一个大缺点是它可能需要过多的启发式方法来达到最终解决方案。可能需要结合树状图分析、基于距离的分析或轮廓系数方法来确定合理的集群数量。此外，必须避免将这些技术方法与一些业务知识结合，以避免陷入某种聚类陷阱。
- en: On the positive side, the hierarchical clustering approach is very explainable,
    helping uncover hidden structures in the data.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从积极的一面来看，层次聚类方法非常可解释，有助于揭示数据中的隐藏结构。
- en: Additionally, hierarchical clustering does not suffer from the centroid initialization
    problem — something that may be an advantage for some datasets.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另外，层次聚类不受中心点初始化问题的影响——这可能对某些数据集来说是一个优势。
- en: 'Hierarchical clustering is a very famous clustering method that has been applied
    for multiple applications as diverse as:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 层次聚类是一种非常著名的聚类方法，已应用于多种不同的应用场景：
- en: Customer segmentation;
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户细分；
- en: Outlier analysis;
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常值分析；
- en: Analyzing multi-dimensional gene expression data;
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析多维基因表达数据；
- en: Document clustering;
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档聚类；
- en: It’s a very cool method that data scientists should have on their tool belt.
    Feel free to try it on your next project and stay tuned for more posts on this
    **Unsupervised Learning Series!**
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种非常酷的方法，数据科学家应该在他们的工具箱中拥有它。可以在下一个项目中尝试，并关注更多关于这个**无监督学习系列**的帖子！
- en: '*If you would like to drop by my Python courses, feel free to join* ***my free
    course*** *here (*[*Python For Busy People — Python Introduction in 2 Hours*](https://www.udemy.com/course/python-for-busy-people-python-introduction-2-hours/?referralCode=1588B6BF72D40253CDD4)*)*
    ***or a longer 16 hour version*** *(*[*The Complete Python Bootcamp for Beginners*](https://www.udemy.com/course/the-python-for-absolute-beginners-bootcamp/?referralCode=8D25992A055C19079B8A)*).
    My Python courses are suitable for beginners/mid-level developers and I would
    love to have you on my class!*'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你有兴趣参加我的Python课程，请随时加入* ***我的免费课程*** *（*[*Python For Busy People — Python
    Introduction in 2 Hours*](https://www.udemy.com/course/python-for-busy-people-python-introduction-2-hours/?referralCode=1588B6BF72D40253CDD4)*)*
    ***或一个更长的16小时版本*** *（*[*The Complete Python Bootcamp for Beginners*](https://www.udemy.com/course/the-python-for-absolute-beginners-bootcamp/?referralCode=8D25992A055C19079B8A)*）。我的Python课程适合初学者/中级开发人员，我非常希望你能来上我的课！*'
- en: '*The dataset used on this post is licensed under a* [*Creative Commons Attribution
    4.0 International*](https://creativecommons.org/licenses/by/4.0/legalcode) *(CC
    BY 4.0) license as shown in the following link:* [https://archive.ics.uci.edu/dataset/186/wine+quality](https://archive.ics.uci.edu/dataset/186/wine+quality)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文使用的数据集遵循* [*创意共享署名 4.0 国际*](https://creativecommons.org/licenses/by/4.0/legalcode)
    *(CC BY 4.0) 许可协议，相关链接如下：* [https://archive.ics.uci.edu/dataset/186/wine+quality](https://archive.ics.uci.edu/dataset/186/wine+quality)'
