- en: 'Unlocking the Power of Big Data: The Fascinating World of Graph Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解锁大数据的力量：图学习的迷人世界
- en: 原文：[https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09](https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09](https://towardsdatascience.com/unlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c?source=collection_archive---------8-----------------------#2023-11-09)
- en: Harnessing Deep Learning to Transform Untapped Data into a Strategic Asset for
    Long-Term Competitiveness.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用深度学习将未开发的数据转变为长期竞争力的战略资产。
- en: '[](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[![Mathieu
    Laversin](../Images/9ca7f2528f9fe655e2aa18e382e560f9.png)](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    [Mathieu Laversin](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Mathieu Laversin](../Images/9ca7f2528f9fe655e2aa18e382e560f9.png)](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    [Mathieu Laversin](https://medium.com/@mathieulaversin3?source=post_page-----c0a2ddf4043c--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6ebca0f38b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=post_page-d6ebca0f38b4----c0a2ddf4043c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    ·12 min read·Nov 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc0a2ddf4043c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=-----c0a2ddf4043c---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6ebca0f38b4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&user=Mathieu+Laversin&userId=d6ebca0f38b4&source=post_page-d6ebca0f38b4----c0a2ddf4043c---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c0a2ddf4043c--------------------------------)
    ·12分钟阅读·2023年11月9日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc0a2ddf4043c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-big-data-the-fascinating-world-of-graph-learning-c0a2ddf4043c&source=-----c0a2ddf4043c---------------------bookmark_footer-----------)![](../Images/a392b226af14c62e715a11a498e32b34.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/a392b226af14c62e715a11a498e32b34.png)'
- en: Photo by [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，[Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    上的照片
- en: Large companies generate and collect vast amounts of data, as an example and
    90% of this data has been created in recent years. Yet, **73% of these data remain
    unused [1]**. However, as you may know, data is a goldmine for companies working
    with Big Data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大公司生成和收集大量数据，以一个例子来说，90% 的数据是在最近几年创建的。然而，**73% 的这些数据仍然未被使用 [1]**。然而，正如你可能知道的那样，数据是从事大数据工作的公司的金矿。
- en: Deep learning is constantly evolving, and today, the challenge is to adapt these
    new solutions to specific goals to stand out and enhance long-term competitiveness.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习不断发展，今天的挑战是将这些新解决方案调整到特定目标，以突出表现并增强长期竞争力。
- en: My previous manager had a good intuition that these two events could come together,
    and together facilitate access, requests, and above all stop wasting time and
    money.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我以前的经理很有直觉，认为这两个事件可以结合在一起，共同促进访问、请求，最重要的是避免浪费时间和金钱。
- en: '**Why is this data left unused?**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么这些数据被闲置？**'
- en: Accessing it takes too long, rights verification, and especially content checks
    are necessary before granting access to users.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 访问这些数据需要很长时间，权利验证，特别是内容检查在授予用户访问权限之前是必需的。
- en: '![](../Images/90c71b29e47c2a19feb1d4229fd0a774.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90c71b29e47c2a19feb1d4229fd0a774.png)'
- en: Visualize reasons for data being unused. (generated by Bing Image Creator)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化数据未被使用的原因。（由 Bing Image Creator 生成）
- en: '**Is there a solution to automatically document new data?**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**有没有自动记录新数据的解决方案？**'
- en: If you’re not familiar with large enterprises, no problem — I wasn’t either.
    An interesting concept in such environments is the use of Big Data, particularly
    **HDFS** (Hadoop Distributed File System), which is a cluster designed to consolidate
    all of the company’s data. Within this vast pool of data, you can find structured
    data, and within that structured data, Hive columns are referenced. Some of these
    columns are used to create additional tables and likely serve as sources for various
    datasets. Companies keep the informations between some table by the lineage.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对大型企业不太熟悉，也没关系——我也是。这样环境中的一个有趣概念是使用大数据，特别是**HDFS**（Hadoop 分布式文件系统），它是一个旨在整合公司所有数据的集群。在这庞大的数据池中，你可以找到结构化数据，而在这些结构化数据中，Hive
    列被引用。这些列中的一些用于创建附加表，并可能作为各种数据集的来源。公司通过数据血缘保持表与表之间的信息。
- en: These columns also have various characteristics (domain, type, name, date, owner…).
    The goal of the project was to document the data known as physical data with business
    data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些列还具有各种特征（领域、类型、名称、日期、所有者等）。项目的目标是用业务数据来记录被称为物理数据的数据。
- en: '**Distinguishing between physical and business data:**'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**区分物理数据和业务数据：**'
- en: To put it simply, physical data is a column name in a table, and business data
    is the usage of that column.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，物理数据是表格中的列名，而业务数据则是该列的使用方式。
- en: 'For exemple: Table named Friends contains columns (character, salary, address).
    Our **physical data** are character, salary, and address. **Our business data**
    are for example,'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：名为 Friends 的表格包含列（角色、薪资、地址）。我们的**物理数据**是角色、薪资和地址。**我们的业务数据**例如，
- en: For “Character” -> Name of the Character
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“Character” -> 角色的名称
- en: For “Salary” -> Amount of the salary
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“Salary” -> 薪资金额
- en: For “Address” -> Location of the person
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“Address” -> 人的地址
- en: Those business data would help in accessing data because you would directly
    have the information you needed. You would know that this is the dataset you want
    for your project, the **information** you’re looking for **is in this table**.
    So you’d just have to ask and find your happiness, go early without losing your
    time and money.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些业务数据将帮助访问数据，因为你可以直接获得所需的信息。你会知道这是你项目所需的数据集，**你寻找的信息** **在这个表格中**。所以你只需请求并找到你的幸福，提前去而不浪费时间和金钱。
- en: '*“During my final internship, I, along with my team of* ***interns****, implemented
    a Big Data / Graph Learning solution to document these data.*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*“在我的最后一次实习中，我和我的团队* ***实习生****，实现了一个大数据/图学习解决方案来记录这些数据。*'
- en: '*The idea was to create a graph to structure our data and at the end predict
    business data based on features. In other word from data stored on the company’s
    environnement, document each dataset to associate an use and in the future reduce
    the search cost and be more data-driven.*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*这个想法是创建一个图来结构化我们的数据，并最终根据特征预测业务数据。换句话说，从存储在公司环境中的数据中，记录每个数据集以关联用途，将来减少搜索成本，并更具数据驱动。*'
- en: '*We had 830 labels to classify and not so many rows. Hopefully the power of
    graph learning come into play. I’m letting you read… “*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们有830个标签需要分类，但行数不多。希望图学习的力量能发挥作用。我让你阅读...“*'
- en: '**Article Objectives:** This article aims to provide an understanding of Big
    Data concepts, Graph Learning, the algorithm used, and the results. It also covers
    deployment considerations and how to successfully develop a model.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**文章目标：** 本文旨在提供对大数据概念、图学习、使用的算法及结果的理解。它还涉及部署考虑事项以及如何成功开发模型。'
- en: 'To help you understand my journey, the outline of this article contain :'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助你理解我的过程，本文的提纲包括：
- en: '**Data Acquisition: Sourcing the Essential Data for Graph Creation**'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据采集：为图创建获取必要数据**'
- en: '**Graph-based Modeling with GSage**'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于图的建模与GSage**'
- en: '**Effective Deployment Strategies**'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效的部署策略**'
- en: Data Acquisition
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据采集
- en: As I mentioned earlier, data is often stored in Hive columns. If you didn’t
    already know, these data are stored in large containers. We extract, transform,
    and load this data through techniques known as ETL.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，数据通常存储在Hive列中。如果你还不知道，这些数据存储在大型容器中。我们通过称为ETL的技术提取、转换和加载这些数据。
- en: What type of data did I need?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要什么类型的数据？
- en: '**Physical data** and their **characteristics** (domain, name, data type).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**物理数据**及其**特征**（领域、名称、数据类型）。'
- en: '**Lineage** (the relationships between physical data, if they have undergone
    common transformations).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谱系**（物理数据之间的关系，如果它们经历了共同的转换）。'
- en: A **mapping** of ‘some physical data related to business data’ to then “let”
    the algorithm perform on its own.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将“某些与业务数据相关的物理数据”进行**映射**，然后“让”算法自行执行。
- en: '**1\. Characteristics/ Features** are obtained directly when we store the data;
    they are mandatory as soon as we store data. For example (depends on your case)
    :'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.** **特征/特性**在我们存储数据时直接获得；它们在我们存储数据时是必需的。例如（取决于你的情况）：'
- en: '![](../Images/0c8c2d149fa04420ea7b0029121e641c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c8c2d149fa04420ea7b0029121e641c.png)'
- en: '**Exemple of main feature**s, (made by the author)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**主要特征**的示例，（由作者提供）'
- en: For the features, based on empirical experience, we decided to use a feature
    hasher on three columns.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特征，基于经验，我们决定对三列使用特征哈希器。
- en: '**Feature Hasher:** technique used in machine learning to convert high-dimensional
    categorical data, such as text or categorical variables, into a lower-dimensional
    numerical representation to reduce memory and computational requirements while
    preserving meaningful information.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征哈希器：** 机器学习中用于将高维度的分类数据（如文本或分类变量）转换为低维度数值表示的技术，以减少内存和计算需求，同时保留有意义的信息。'
- en: You could have the choice with **One Hot Encoding** technique if you have similar
    patterns. *If you want to deliver your model, my advice would be to use Feature
    Hasher.*
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有类似的模式，可以选择**独热编码**技术。*如果你想交付你的模型，我建议使用特征哈希器。*
- en: '**2.** **Lineage** is a bit more complex but not impossible to understand.
    Lineage is like a **history of physical data,** where we have a rough idea of
    what transformations have been applied and where the data is stored elsewhere.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.** **谱系**稍微复杂一些，但并非不可理解。谱系就像**物理数据的历史**，我们大致了解已应用的转换以及数据存储在其他地方的位置。'
- en: Imagine big data in your mind and all these data. In some projects, we use data
    from a table and apply a transformation through a job (Spark).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你脑海中的大数据以及所有这些数据。在一些项目中，我们使用表格中的数据，并通过一个任务（Spark）进行转换。
- en: '![](../Images/8f2312f07cc5597c8426f1474c11ff3b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f2312f07cc5597c8426f1474c11ff3b.png)'
- en: Atlas Lineage visualized, from Atlas Website, [LINK](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从Atlas网站可视化的Atlas谱系，[LINK](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
- en: We gather the informations of all physical data we have to create connections
    in our graph, or at least one of the connections.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了所有物理数据的信息，以便在我们的图中创建连接，或者至少创建其中一个连接。
- en: '**3\. The mapping** is the foundation that adds value to our project. It’s
    where we associate our business data with our physical data. This provides the
    algorithm with verified information so that it can classify the new incoming data
    in the end. This mapping had to be done by someone who understands the process
    of the company, and has the skills to recognize difficult patterns without asking.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.** **映射**是为我们的项目增值的基础。在这里，我们将业务数据与物理数据关联起来。这为算法提供了经过验证的信息，使其能够最终对新进来的数据进行分类。这个映射必须由了解公司流程的人完成，并且具备识别复杂模式的技能，而无需询问。'
- en: 'ML advice, from my own experience :'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ML建议，基于我自己的经验：
- en: '*Quoting Mr. Andrew NG, in classical machine learning, there’s something called
    the algorithm lifecycle. We often think about the algorithm, making it complicated,
    and not just using a good old Linear Regression (I’ve tried; it doesn’t work).
    In this lifecycle, there are all the stages of preprocessing, modeling and monitoring…
    but most importantly, there is data focusing.*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*引用Andrew NG先生的话，在经典机器学习中，有一种叫做算法生命周期的东西。我们常常考虑算法，使其复杂，而不只是使用一个老式的线性回归（我尝试过；它不起作用）。在这个生命周期中，包括所有的预处理、建模和监控阶段……但最重要的是，数据聚焦。*'
- en: '**This is a mistake we often make;** we take it for granted and start doing
    data analysis. We draw conclusions from the dataset without sometimes **questioning
    its relevance**. **Don’t forget data focusing, my friends; it can boost your performance
    or even lead to a change of project :)**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是我们经常犯的错误；** 我们理所当然地开始进行数据分析。我们从数据集中得出结论，而有时却**没有质疑其相关性**。**不要忘记数据聚焦，我的朋友们；它可以提升你的表现，甚至导致项目的改变
    :)**'
- en: Returning to our article, after obtaining the data, we can finally **create
    our graph**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的文章，获取数据后，我们最终可以**创建我们的图**。
- en: '![](../Images/0618769c8a8310b5805d1aaf12701ac6.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0618769c8a8310b5805d1aaf12701ac6.png)'
- en: Plot ([networkx](https://networkx.org/)) of **the distribution of our dataset,
    in a graph**. (made by the author)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们数据集的分布图**的绘图（使用[networkx](https://networkx.org/)制作）。(由作者制作)'
- en: This plot considers a batch of 2000 rows, so 2000 columns in datasets and tables.
    You can find in the center the business data and off-centered the physical data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该图考虑了一批2000行的数据，因此在数据集和表格中有2000列。你可以在中心找到业务数据，而偏离中心的是物理数据。
- en: In mathematics, we denote a graph as G, **G(N, V, f)**. N represents the nodes,
    V stands for vertices (edges), and f represents the features. Let’s assume all
    three are non-empty sets.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，我们将图表示为G，**G(N, V, f)**。N代表节点，V代表顶点（边），f代表特征。假设这三者都是非空集合。
- en: For the nodes (we have the business data IDs in the mapping table) and also
    the physical data to trace them with lineage.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于节点（我们在映射表中有业务数据ID）以及物理数据，以便通过谱系追踪它们。
- en: '**Speaking of lineage**, it partly serves as edges with the links we already
    have through the mapping and the IDs. We had to extract it through an ETL process
    using the **Apache Atlas APIs.**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**谈到谱系**，它部分作为边，通过映射和ID链接我们已有的链接。我们必须通过使用**Apache Atlas API**的ETL过程来提取它。'
- en: You can see how a big data problem, after laying the foundations, can become
    easy to understand but more challenging to implement, especially for a young intern…
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，在奠定基础之后，大数据问题可以变得容易理解，但实施起来却更具挑战性，尤其对于一名年轻的实习生来说……
- en: '![](../Images/fdd4ca2d0fd9ef6663ce673842638bd9.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdd4ca2d0fd9ef6663ce673842638bd9.png)'
- en: “Ninja cartoon on a computer” (generated by Dall.E 3)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: “计算机上的忍者卡通”（由Dall.E 3生成）
- en: '**Graph-based Modeling with GSage**'
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**基于图的建模与GSage**'
- en: Basics of Graph Learning
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图学习基础
- en: This section will be dedicated to explaining GSage and why it was chosen both
    mathematically and empirically.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将致力于解释GSage以及为何在数学和经验上都选择了它。
- en: Before this internship, I was not accustomed to working with graphs. That’s
    why I purchased the book **[2]**, which I’ve included in the description, as it
    greatly assisted me in understanding the principles.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次实习之前，我不习惯使用图形。这就是为什么我购买了书籍**[2]**，我在描述中包含了它，因为它大大帮助我理解了原理。
- en: '[](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
    [## Graph Machine Learning: Take graph data to the next level by applying machine
    learning techniques…'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
    [## 图机器学习：通过应用机器学习技术将图数据提升到一个新的水平……'
- en: 'Noté /5\. Retrouvez Graph Machine Learning: Take graph data to the next level
    by applying machine learning techniques…'
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意 /5。请查阅《图机器学习：通过应用机器学习技术将图数据提升到一个新的水平》……
- en: www.amazon.fr](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.amazon.fr](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=13866138887051738726&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c&source=post_page-----c0a2ddf4043c--------------------------------)'
- en: 'The principle is simple: when we talk about graph learning, we will inevitably
    discuss embedding. **In this context, nodes and their proximity are mathematically
    translated into coefficients that reduce the dimensionality of the original dataset**,
    making it more efficient for calculations. During the reduction, one of the key
    principles of the decoder **is to preserve the proximities between nodes that
    were initially close**.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 原理很简单：当我们谈论图学习时，我们必然会讨论嵌入。**在这个背景下，节点及其邻近关系在数学上被转换为减少原始数据集维度的系数**，使计算更加高效。在降维过程中，解码器的一个关键原则**是保持初始接近的节点之间的邻近关系**。
- en: Another source of inspiration was [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page-----c0a2ddf4043c--------------------------------)
    **[3]** for his explanations of GraphSages and Graph Convolutional Networks. He
    demonstrated great pedagogy and provided clear and comprehensible examples, making
    these concepts accessible to those who wish to go into them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个灵感来源是 [Maxime Labonne](https://medium.com/u/dc89da634938?source=post_page-----c0a2ddf4043c--------------------------------)
    **[3]**，他对 GraphSages 和图卷积网络的解释展示了极佳的教学法，提供了清晰易懂的例子，使这些概念对希望深入了解的人变得更加易于理解。
- en: '***GraphSage’s model***'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '***GraphSage 的模型***'
- en: If this term doesn’t ring a bell, rest assured, just a few months ago, I was
    in your shoes. Architectures like Attention networks and Graph Convolutional Networks
    gave me quite a few nightmares and, more importantly, *kept me awake at night*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个术语对你来说不熟悉，请放心，几个月前我也在你的位置。像注意力网络和图卷积网络这样的架构曾让我经历了不少噩梦，更重要的是，它们*让我夜不能寐*。
- en: But to save you from taking up your entire day and, especially, your commute
    time, I’m going to simplify the algorithm for you.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了节省你整天的时间，尤其是你的通勤时间，我将为你简化算法。
- en: Once you have the embeddings in place, that’s when the magic can happen. But
    how does it all work, you ask?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了嵌入，这时候魔法才会发生。但你问一切是如何运作的？
- en: '![](../Images/c31b2b4e40887261f7f86918c039e19d.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c31b2b4e40887261f7f86918c039e19d.png)'
- en: Schema based on the Scooby-Doo Universe to explain GSage (made by the author).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 基于《史酷比宇宙》的图解来解释 GSage（由作者制作）。
- en: “**You are known by the company you keep**” is the sentence, you must remember.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: “**你以交友闻名**”这句话，你必须记住。
- en: Because one of the fundamental assumptions underlying GraphSAGE is that nodes
    residing in the **same neighborhood should exhibit similar embeddings**. To achieve
    this, GraphSAGE employs **aggregation functions** that take a neighborhood as
    input and combine each neighbor’s embedding with specific weights. That’s why
    the mystery company embeddings would be in scooby’s neighborhood.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 GraphSAGE 的一个基本假设是**同一邻域中的节点应该表现出类似的嵌入**。为实现这一点，GraphSAGE 使用**聚合函数**，将邻域作为输入，并结合每个邻居的嵌入及特定权重。这就是为什么神秘公司嵌入会出现在
    Scooby 的邻域中的原因。
- en: In essence, it gathers information from the neighborhood, with the weights being
    either learned or fixed depending on the loss function.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，它从邻域收集信息，权重可以是学习得出的，也可以是固定的，具体取决于损失函数。
- en: The true strength of GraphSAGE becomes evident when the aggregator weights are
    learned. At this point, the architecture can generate embeddings for unseen nodes
    using their features and neighborhood, making it a powerful tool for various applications
    in graph-based machine learning.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当聚合器权重被学习时，GraphSAGE 的真正实力便会显现。此时，该架构可以利用节点的特征和邻域为未见节点生成嵌入，使其成为图基机器学习中各种应用的强大工具。
- en: '![](../Images/3999bbbf4baf9b568d5cd3679b6efe4a.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3999bbbf4baf9b568d5cd3679b6efe4a.png)'
- en: Difference in training time between architecture, Maxime Labonne’s Article,
    [Link](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 架构训练时间的差异，Maxime Labonne 的文章，[链接](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
- en: As you saw on this graph, training time decrease when we’re taking the same
    dataset on GraphSage architecture. GAT (Graph Attention Network) and GCN (Graph
    Convolutional Network) are also really interesting graphs architectures. I really
    encourage you to look forward !
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在此图中所见，当我们在GraphSage架构上使用相同的数据集时，训练时间会减少。GAT（图注意网络）和GCN（图卷积网络）也是非常有趣的图架构。我真的鼓励你关注！
- en: '*At the first compute, I was shocked, shocked to see 25 seconds to train 1000
    batches on thousands of rows.*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*第一次计算时，我感到震惊，震惊于看到训练1000批次在数千行数据上仅需25秒。*'
- en: I know at this point you’re interested in Graph Learning and you want to learn
    more, my advice would be to read this guy. Great examples, great advice).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道你现在对图学习感兴趣，并想了解更多，我的建议是阅读这位作者的内容。提供了很好的示例和建议。
- en: '[](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------)
    [## GraphSAGE: Scaling up Graph Neural Networks'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------)
    [## GraphSAGE: 扩展图神经网络'
- en: Introduction to GraphSAGE with PyTorch Geometric
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用PyTorch Geometric的GraphSAGE简介
- en: towardsdatascience.com](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/introduction-to-graphsage-in-python-a9e7f9ecf9d7?source=post_page-----c0a2ddf4043c--------------------------------) '
- en: As I’m a reader of Medium, I’m curious to read code when I’m looking at a new
    article, and for you, we can implement a GraphSAGE architecture in PyTorch Geometric
    with the `SAGEConv` layer.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Medium的读者，当我查看一篇新文章时，我会好奇阅读代码，对于你来说，我们可以在PyTorch Geometric中实现GraphSAGE架构，使用`SAGEConv`层。
- en: 'Let’s create a network with two `SAGEConv` layers:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个包含两个`SAGEConv`层的网络：
- en: The first one uses *ReLU* as the activation function and a **dropout layer**;
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个使用了*ReLU*作为激活函数和一个**dropout层**；
- en: The second one directly outputs the **node embeddings**.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个直接输出**节点嵌入**。
- en: In our multi-class classification task, we’ve chosen to employ the cross-entropy
    loss as our primary loss function. This choice is driven by its suitability for
    classification problems with multiple classes. Additionally, we’ve incorporated
    L2 regularization with a strength of 0.0005.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的多类分类任务中，我们选择使用交叉熵损失作为主要损失函数。这一选择是由于其适用于具有多个类别的分类问题。此外，我们还采用了强度为0.0005的L2正则化。
- en: '**This regularization technique helps prevent overfitting** and promotes model
    generalization by penalizing large parameter values. It’s a well-rounded approach
    to ensure model stability and predictive accuracy.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**这种正则化技术有助于防止过拟合**，通过对大参数值进行惩罚来促进模型的泛化。这是一种确保模型稳定性和预测准确性的全面方法。'
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Deployment of the model :'
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型的部署：
- en: 'In the development and deployment of our project, we harnessed the power of
    three key technologies, each serving a distinct and integral purpose:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们项目的开发和部署过程中，我们利用了三种关键技术，每种技术都有其独特而重要的作用：
- en: '![](../Images/7a4dae7fadcc90f34fa31346cfeea253.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a4dae7fadcc90f34fa31346cfeea253.png)'
- en: Three logos from [Google](https://www.google.com/)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 来自[Google](https://www.google.com/)的三个标志
- en: '**Airflow :** To efficiently manage and schedule our project’s complex data
    workflows, we utilized the Airflow Orchestrator. Airflow is a **widely adopted
    tool for orchestrating tasks**, automating processes, and ensuring that our data
    pipelines ran smoothly and on schedule.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**Airflow：** 为了高效管理和调度我们项目复杂的数据工作流，我们使用了Airflow Orchestrator。Airflow是一个**广泛采用的任务调度工具**，可以自动化流程，并确保我们的数据管道平稳且按时运行。'
- en: '**Mirantis:** Our project’s infrastructure was built and hosted on the Mirantis
    cloud platform. Mirantis is renowned for providing **robust, scalable, and reliable
    cloud solutions**, offering a solid foundation for our **deployment**.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mirantis：** 我们项目的基础设施是在Mirantis云平台上构建和托管的。Mirantis以提供**强大、可扩展和可靠的云解决方案**而闻名，为我们的**部署**提供了坚实的基础。'
- en: '**Jenkins:** To streamline our development and deployment processes, we relied
    on Jenkins, a trusted name in the world of continuous integration and **continuous
    delivery (CI/CD)**. Jenkins automated the **building, testing, and deployment
    of our project**, ensuring **efficiency** and **reliability** throughout our development
    cycle.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jenkins：** 为了简化我们的开发和部署流程，我们依赖Jenkins，一个在持续集成和**持续交付（CI/CD）**领域中值得信赖的名字。Jenkins自动化了**项目的构建、测试和部署**，确保了我们开发周期中的**效率**和**可靠性**。'
- en: Additionally, we stored our machine learning code in the company’s Artifactory.
    **But what exactly is an Artifactory?**
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将我们的机器学习代码存储在公司的 Artifactory 中。 **但什么是 Artifactory？**
- en: '**Artifactory:** An Artifactory is a centralized repository manager for storing,
    managing, and distributing various artifacts, such as code, libraries, and dependencies.
    It serves as a **secure** and organized storage space, ensuring that all team
    members have easy access to the necessary assets. This enables seamless **collaboration
    and simplifies the deployment of applications and projects**, making it a valuable
    asset for efficient development and deployment workflows.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**Artifactory:** Artifactory 是一个集中式仓库管理器，用于存储、管理和分发各种工件，如代码、库和依赖项。它作为一个 **安全**
    和有组织的存储空间，确保所有团队成员都可以轻松访问所需的资产。这使得 **协作无缝并简化了应用程序和项目的部署**，使其成为高效开发和部署工作流程的宝贵资产。'
- en: By housing our machine learning code in the Artifactory, we ensured that our
    models and data were **readily available to support our deployment via Jenkins.**
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将我们的机器学习代码存储在 Artifactory 中，我们确保了我们的模型和数据 **可以轻松支持通过 Jenkins 部署**。
- en: ET VOILA ! The solution was deployed.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ET VOILA ! 解决方案已部署。
- en: I talked a lot about the infrastrucute but not so much about the Machine Learning
    and the results we had.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我谈了很多关于基础设施的内容，但对机器学习和我们取得的结果讲得不多。
- en: 'Results :'
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '结果 :'
- en: 'The trust of the predictions :'
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '预测的可信度 :'
- en: For each physical data, we’re taking in consideration 2 predictions, because
    of the model performances.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个物理数据，我们考虑了 2 个预测，因为模型性能的原因。
- en: How’s that possible?
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这怎么可能？
- en: '[PRE1]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: First I used a softmax to make the outputs comparable, and after I used a function
    named [torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html).
    It returns the `k` largest elements of the given `input` tensor along a given
    dimension.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我使用了一个 softmax 函数来使输出可比，然后使用了一个名为 [torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html)
    的函数。它返回给定 `input` 张量在指定维度上的 `k` 个最大元素。
- en: So, back to the first prediction, here was our distribution after training.
    Let me tell you boys and girls, that’s great!
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，回到第一次预测，这里是我们训练后的分布。告诉你们，真棒！
- en: '![](../Images/fa18b82584a0d1ee6f8deab16a1d02ef.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa18b82584a0d1ee6f8deab16a1d02ef.png)'
- en: Plot (from matplotlib) of the **probabilities of the model outputs**, First
    prediction (made by the author)
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型输出的概率**的绘图（来自 matplotlib），第一次预测（由作者制作）'
- en: Accuracies, Losses on Train / Test / Validation.
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练/测试/验证中的准确率和损失。
- en: I won’t teached you what’s accuracies and losses in ML, I presumed you are all
    pros… (ask to chatgpt if you’re not sure, no shame). On the training, by different
    scale, you can see convergences on the curves, which is great and show a stable
    learning.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会教你什么是机器学习中的准确率和损失，我假设你们都是专家……（如果不确定，可以询问 ChatGPT，没有羞耻感）。在训练中，通过不同的尺度，你可以看到曲线上的收敛，这很好，说明学习稳定。
- en: '![](../Images/38e9591e0e39237f97c80f277014c1d7.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38e9591e0e39237f97c80f277014c1d7.png)'
- en: Plot (matplotlib) of **accuracies and losses.** (made by the author)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**准确率和损失**的绘图（matplotlib）（由作者制作）'
- en: 't-SNE :'
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 't-SNE :'
- en: t-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction
    technique used for visualizing and exploring high-dimensional data by preserving
    the pairwise similarities between data points in a lower-dimensional space.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE（t-分布随机邻域嵌入）是一种降维技术，用于通过在较低维空间中保留数据点之间的成对相似性来可视化和探索高维数据。
- en: 'In other words, imagine a random distribution before training :'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '换句话说，想象一下训练前的随机分布 :'
- en: '![](../Images/17dff6aca2e38a337b1ab1a1ed626493.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17dff6aca2e38a337b1ab1a1ed626493.png)'
- en: Data Distribution **before training,** (made by the author)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分布 **训练前，**（由作者制作）
- en: Remember we are doing multi-classification, so here’s the distribution after
    the training. The aggregations of features seem to have done a satisfactory work.
    Clusters are formed and physical data seem to have joined groups, demonstrating
    that the training went well.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 记住我们正在做多分类，因此这是训练后的分布。特征的聚合似乎做得很满意。聚类形成，物理数据似乎已加入组，表明训练进行了良好。
- en: '![](../Images/70933a0ca1c2018e23c7f3afb006d35f.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70933a0ca1c2018e23c7f3afb006d35f.png)'
- en: Data distribution **after training,** (made by the author)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分布 **训练后，**（由作者制作）
- en: 'Conclusion :'
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '结论 :'
- en: Our goal was to predict business data based on physical data (and we did it).
    I am pleased to inform you that the algorithm is now in production and is onboarding
    new users for the future.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是基于物理数据预测业务数据（而且我们做到了）。我很高兴地通知你，该算法现在已投入生产，并正在为未来的用户进行接入。
- en: While I cannot provide the entire solution due to proprietary reasons, I believe
    you have all the necessary details or are well-equipped to implement it on your
    own.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然由于专有原因我不能提供完整的解决方案，但我相信你已经掌握了所有必要的细节，或者你完全有能力自行实施。
- en: My last piece of advice, I swear, have a great team, not only people who work
    well but people who make you laugh each day.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我最后的一条建议，我发誓，拥有一个出色的团队，不仅是那些工作出色的人，还有那些每天让你开心的人。
- en: If you have any questions, please don’t hesitate to reach out to me. *Feel free
    to connect with me, and we can have a detailed discussion about it.*
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题，请随时联系我。*随时与我联系，我们可以详细讨论。*
- en: '**In case I don’t see ya, good afternoon, good evening and goodnight !**'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果我没见到你，下午好，晚上好，晚安！**'
- en: Have you grasped everything ?
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你掌握了吗？
- en: 'As **Chandler Bing** would have said :'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 正如**钱德勒·宾**可能会说：
- en: '**“It’s always better to lie, than to have the complicated discussion”**'
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“说谎总比进行复杂的讨论要好”**'
- en: Don’t forget to like and share!
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 别忘了点赞和分享！
- en: References and Resources
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料和资源
- en: '**[1]** [Inc](https://www.inc.com/jeff-barrett/misusing-data-could-be-costing-your-business-heres-how.html)
    (2018), Web Article from Inc'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**[1]** [Inc](https://www.inc.com/jeff-barrett/misusing-data-could-be-costing-your-business-heres-how.html)（2018），来自Inc的网络文章'
- en: '**[2]** [Graph Machine Learning: Take graph data to the next level by applying
    machine learning techniques and algorithms](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=7038120787362687179&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c)
    (2021), Claudio Stamile'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**[2]** [图机器学习：通过应用机器学习技术和算法将图数据提升到一个新水平](https://www.amazon.fr/Graph-Machine-Learning-techniques-algorithms/dp/1800204493/ref=asc_df_1800204493/?tag=googshopfr-21&linkCode=df0&hvadid=506880135571&hvpos=&hvnetw=g&hvrand=7038120787362687179&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9055317&hvtargid=pla-1503184391952&psc=1&mcid=ad38156d270633babacde02db431d62c)（2021），Claudio
    Stamile'
- en: '**[3]** [GSage, Scaling up the Graph Neural Network](/introduction-to-graphsage-in-python-a9e7f9ecf9d7),
    (2021), Maxime Labonne'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**[3]** [GraphSAGE，扩展图神经网络](/introduction-to-graphsage-in-python-a9e7f9ecf9d7)，（2021），Maxime
    Labonne'
- en: Image Credits
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图片来源
- en: Photo by [Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Nathan Anderson](https://unsplash.com/@nathananderson?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)的照片，来源于[Unsplash](https://unsplash.com/s/photos/night-sky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)'
- en: GSage difference of time,from Maxime Labonne’s article, [link](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GraphSAGE时间差，来自Maxime Labonne的文章，[链接](https://mlabonne.github.io/blog/posts/2022-04-06-GraphSAGE.html)
- en: Atlas Lineage visualized, from Atlas Website, [LINK](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Atlas Lineage可视化，来自Atlas网站，[链接](https://atlas.apache.org/1.2.0/ClassificationPropagation.html)
- en: Three logos taken [Google](https://www.google.com/)
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个标志来自[Google](https://www.google.com/)
