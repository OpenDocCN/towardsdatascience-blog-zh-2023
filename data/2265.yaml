- en: Deploying Large Language Models With HuggingFace TGI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 HuggingFace TGI 部署大型语言模型
- en: 原文：[https://towardsdatascience.com/deploying-large-language-models-with-huggingface-tgi-981747c669e3?source=collection_archive---------3-----------------------#2023-07-14](https://towardsdatascience.com/deploying-large-language-models-with-huggingface-tgi-981747c669e3?source=collection_archive---------3-----------------------#2023-07-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deploying-large-language-models-with-huggingface-tgi-981747c669e3?source=collection_archive---------3-----------------------#2023-07-14](https://towardsdatascience.com/deploying-large-language-models-with-huggingface-tgi-981747c669e3?source=collection_archive---------3-----------------------#2023-07-14)
- en: Another way to efficiently host and scale your LLMs with Amazon SageMaker
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker 高效托管和扩展您的 LLMs
- en: '[](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----981747c669e3--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b----981747c669e3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)
    ·5 min read·Jul 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F981747c669e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----981747c669e3---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b----981747c669e3---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----981747c669e3--------------------------------)
    · 5分钟阅读 · 2023年7月14日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F981747c669e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----981747c669e3---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F981747c669e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&source=-----981747c669e3---------------------bookmark_footer-----------)![](../Images/87080a29c8a17cddf9ed8b4ece860f12.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F981747c669e3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-large-language-models-with-huggingface-tgi-981747c669e3&source=-----981747c669e3---------------------bookmark_footer-----------)![](../Images/87080a29c8a17cddf9ed8b4ece860f12.png)'
- en: Image from [Unsplash](https://unsplash.com/photos/4NYtYSiZVlA)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Unsplash](https://unsplash.com/photos/4NYtYSiZVlA)
- en: Large Language Models (LLMs) continue to soar in popularity as a new one is
    released nearly every week. With the number of these models increasing, so are
    the options for how we can host them. In my previous article we explored how we
    could utilize [DJL Serving](https://github.com/deepjavalibrary/djl-serving) within
    Amazon SageMaker to efficiently host LLMs. In this article we explore another
    optimized model server and solution in [HuggingFace Text Generation Inference
    (TGI)](https://github.com/huggingface/text-generation-inference).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着几乎每周都有新的大型语言模型（LLMs）发布，这些模型的受欢迎程度持续上升。随着这些模型数量的增加，我们托管它们的选项也在增多。在我上一篇文章中，我们探讨了如何利用
    [DJL Serving](https://github.com/deepjavalibrary/djl-serving) 在 Amazon SageMaker
    中高效托管 LLMs。本文我们将深入探讨另一个优化的模型服务器和解决方案，即 [HuggingFace 文本生成推理（TGI）](https://github.com/huggingface/text-generation-inference)。
- en: '**NOTE**: For those of you new to AWS, make sure you make an account at the
    following [link](https://aws.amazon.com/console/) if you want to follow along.
    The article also assumes an intermediate understanding of SageMaker Deployment,
    I would suggest following this [article](https://aws.amazon.com/blogs/machine-learning/part-2-model-hosting-patterns-in-amazon-sagemaker-getting-started-with-deploying-real-time-models-on-sagemaker/)
    for understanding Deployment/Inference more in depth.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**: 对于那些刚接触 AWS 的人，如果你想跟进，请务必在以下[链接](https://aws.amazon.com/console/)注册一个账户。本文还假设你对
    SageMaker 部署有中级的理解，我建议阅读这篇[文章](https://aws.amazon.com/blogs/machine-learning/part-2-model-hosting-patterns-in-amazon-sagemaker-getting-started-with-deploying-real-time-models-on-sagemaker/)更深入地了解部署/推理。'
- en: '**DISCLAIMER**: I am a Machine Learning Architect at AWS and my opinions are
    my own.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**免责声明**: 我是 AWS 的机器学习架构师，本文中的观点仅代表个人观点。'
- en: Why HuggingFace Text Generation Inference? How Does It Work With Amazon SageMaker?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择 HuggingFace 文本生成推理？它如何与 Amazon SageMaker 协同工作？
- en: TGI is a Rust, Python, gRPC model server created by HuggingFace that can be
    used to host specific large language models. HuggingFace has long been the central
    hub for NLP and it contains a large set of…
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: TGI 是由 HuggingFace 创建的 Rust、Python、gRPC 模型服务器，可用于托管特定的大型语言模型。HuggingFace 长期以来一直是
    NLP 领域的中心枢纽，拥有大量的...
