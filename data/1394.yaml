- en: New Frontiers in Audio Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 音频机器学习的新领域
- en: 原文：[https://towardsdatascience.com/new-frontiers-in-audio-machine-learning-6474ffaa5cb9?source=collection_archive---------9-----------------------#2023-04-20](https://towardsdatascience.com/new-frontiers-in-audio-machine-learning-6474ffaa5cb9?source=collection_archive---------9-----------------------#2023-04-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/new-frontiers-in-audio-machine-learning-6474ffaa5cb9?source=collection_archive---------9-----------------------#2023-04-20](https://towardsdatascience.com/new-frontiers-in-audio-machine-learning-6474ffaa5cb9?source=collection_archive---------9-----------------------#2023-04-20)
- en: '[](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----6474ffaa5cb9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)
    ·Sent as a [Newsletter](/newsletter?source=post_page-----6474ffaa5cb9--------------------------------)
    ·3 min read·Apr 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6474ffaa5cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&user=TDS+Editors&userId=7e12c71dfa81&source=-----6474ffaa5cb9---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----6474ffaa5cb9---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)
    · 发送 [新闻简报](/newsletter?source=post_page-----6474ffaa5cb9--------------------------------)
    · 阅读时间 3 分钟 · Apr 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6474ffaa5cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&user=TDS+Editors&userId=7e12c71dfa81&source=-----6474ffaa5cb9---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6474ffaa5cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&source=-----6474ffaa5cb9---------------------bookmark_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6474ffaa5cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&source=-----6474ffaa5cb9---------------------bookmark_footer-----------)'
- en: Not that long ago, any workflow that involved processing audio files—even a
    fairly simple task like transcribing a podcast episode—came with a set of tough
    choices. You could go manual (and waste hours, if not days, in the process), rely
    on a few clunky and ultimately underwhelming apps, or patch together a Frankenstein’s
    monster-equivalent of tools and code.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 不久以前，任何涉及处理音频文件的工作流程——甚至是像转录播客剧集这样相对简单的任务——都伴随着一系列艰难的选择。你可以选择手动操作（在过程中浪费数小时甚至数天的时间），依赖于几款笨拙且最终令人失望的应用程序，或者拼凑出类似于弗兰肯斯坦怪物的工具和代码组合。
- en: Those days are behind us. The rise of powerful models and accessible AI interfaces
    has made working with audio and music exponentially more streamlined, and new
    horizons continue to open up every day. To help you catch up with some of the
    recent advances in audio-focused machine learning, we’ve collected a few standout
    articles from the past few weeks, covering a wide range of approaches and use
    cases. Tune out the noise and dive in!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那些日子已经过去。强大的模型和易于访问的AI界面的兴起使得处理音频和音乐变得更加高效，新的视野每天都在不断开启。为了帮助您跟上音频聚焦机器学习的最新进展，我们从过去几周收集了一些突出的文章，涵盖了各种方法和用例。过滤掉噪音，深入了解吧！
- en: '[**A look inside the black box of music tagging**](/making-music-tagging-ai-explainable-through-source-separation-2d9493547a7e).
    With thousands of songs added to platforms like Spotify and Apple Music every
    day, have you ever wondered how these services know which musical genre to assign
    to each one? [Max Hilsdorf](https://medium.com/u/d0c085a74ae8?source=post_page-----6474ffaa5cb9--------------------------------)’s
    fascinating project leverages Shapley values to determine how the presence of
    specific instruments shapes the way AI systems tag new tracks.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**揭示音乐标签AI的黑箱**](/making-music-tagging-ai-explainable-through-source-separation-2d9493547a7e)。随着每天在Spotify和Apple
    Music等平台上添加数千首歌曲，您是否曾想过这些服务如何知道为每首歌分配哪种音乐流派？[Max Hilsdorf](https://medium.com/u/d0c085a74ae8?source=post_page-----6474ffaa5cb9--------------------------------)的项目利用Shapley值确定特定乐器的存在如何影响AI系统标记新曲目的方式。'
- en: '[**Explore a deep learning approach to identifying bird calls**](/audio-classification-with-deep-learning-in-python-cf752b22ba07).
    [Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----6474ffaa5cb9--------------------------------)’s
    recent contribution covers last year’s BirdCLEF2022 Kaggle competition, where
    participants were tasked with creating a classifier for bird-song recordings.
    Leonie walks us through a neat approach that converts audio waveforms into mel
    spectrograms so a deep learning model can approach them the same way it does images.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**探索基于深度学习的鸟鸣识别方法**](/audio-classification-with-deep-learning-in-python-cf752b22ba07)。[Leonie
    Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----6474ffaa5cb9--------------------------------)最近的贡献涵盖了去年的BirdCLEF2022
    Kaggle竞赛，参赛者需创建鸟鸣录音的分类器。Leonie向我们展示了一种巧妙的方法，将音频波形转换为梅尔频谱图，使深度学习模型可以像处理图像一样处理它们。'
- en: '![](../Images/bd4b9d5ac6e5d107fb089b0520914472.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd4b9d5ac6e5d107fb089b0520914472.png)'
- en: Photo by [Oskars Sylwan](https://unsplash.com/@oskarssylwan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Oskars Sylwan](https://unsplash.com/@oskarssylwan?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '[**Get the gist of recorded conversations, lectures, and interviews**](/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d).
    If you’re a consummate optimizer, you’ll appreciate [Bildea Ana](https://medium.com/u/c57d3db39a47?source=post_page-----6474ffaa5cb9--------------------------------)’s
    streamlined process for transcribing audio with OpenAI’s Whisper model on Hugging
    Face, and then summarizing it using the open-source BART encoder. You could apply
    this method to your own recordings and voice memos, or to any other audio file
    (as long as its owners allow it, of course—*always* double-check the copyright
    and license status of any data you’d like to use).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**从长YouTube视频中自动生成摘要**](/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d)。如果您是一个完美主义者，您会欣赏[Bildea
    Ana](https://medium.com/u/c57d3db39a47?source=post_page-----6474ffaa5cb9--------------------------------)使用OpenAI的Whisper模型和Hugging
    Face进行音频转录的简化流程，然后使用开源的BART编码器进行总结。您可以将此方法应用于自己的录音和语音备忘录，或者任何其他音频文件（前提是其所有者允许，当然——*始终*仔细检查您希望使用的数据的版权和许可状态）。'
- en: '[**Taking transcription to the next level**](/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281).
    [Luís Roque](https://medium.com/u/2195f049db86?source=post_page-----6474ffaa5cb9--------------------------------)’s
    latest project follows a parallel path to Ana’s, up to a point. It also relies
    on Whisper to transcribe audio files, but then explores a different direction
    altogether by deploying PyAnnotate for speaker diarization, “the process of identifying
    and segmenting speech by different speakers.”'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**将转录提升到一个新水平**](/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281)。[Luís
    Roque](https://medium.com/u/2195f049db86?source=post_page-----6474ffaa5cb9--------------------------------)的最新项目与Ana的项目有相似之处，但有所不同。它也依赖于Whisper来转录音频文件，但随后通过部署PyAnnotate进行说话者分离，“即识别和区分不同说话者的语音的过程”。'
- en: Please don’t stop the music, you say? We’re happy to oblige — here are some
    of our favorite recent articles on non-audio-related topics. Enjoy!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你说“请不要停止音乐”？我们很乐意满足——这里是我们最近一些最喜欢的关于非音频相关主题的文章。请享用！
- en: '*“*Learning neural networks should not be an exercise in decoding misleading
    diagrams,*”* say [Aaron Master](https://medium.com/u/31905cfe67ce?source=post_page-----6474ffaa5cb9--------------------------------)
    and Doron Bergman, who [propose a constructive, novel approach](/please-stop-drawing-neural-networks-wrong-ffd02b67ad77)
    to creating better and more accurate ones.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*“*学习神经网络不应该是解读误导性图示的练习，*”* [Aaron Master](https://medium.com/u/31905cfe67ce?source=post_page-----6474ffaa5cb9--------------------------------)和Doron
    Bergman 表示，他们[提出了一种建设性的新方法](/please-stop-drawing-neural-networks-wrong-ffd02b67ad77)来创建更好、更准确的神经网络。'
- en: 'From promotion design to inventory analysis, [Idil Ismiguzel](https://medium.com/u/6d965c736f2?source=post_page-----6474ffaa5cb9--------------------------------)
    demonstrates [the power of association rule mining](/a-guide-to-association-rule-mining-96c42968ba6):
    a technique that empowers data professionals to find frequent patterns in a dataset.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从推广设计到库存分析，[Idil Ismiguzel](https://medium.com/u/6d965c736f2?source=post_page-----6474ffaa5cb9--------------------------------)
    展示了[关联规则挖掘的力量](/a-guide-to-association-rule-mining-96c42968ba6)：一种赋能数据专业人士发现数据集中的频繁模式的技术。
- en: For a [hands-on approach to unsupervised learning and K-means clustering](/unsupervised-learning-with-k-means-clustering-generate-color-palettes-from-images-94bb8e6a1416),
    don’t miss [Nabanita Roy](https://medium.com/u/d36a8b28c928?source=post_page-----6474ffaa5cb9--------------------------------)’s
    new tutorial, which focuses on the use case of grouping image pixels by color.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于[无监督学习和K-means聚类的动手实践](/unsupervised-learning-with-k-means-clustering-generate-color-palettes-from-images-94bb8e6a1416)，不要错过[Nabanita
    Roy](https://medium.com/u/d36a8b28c928?source=post_page-----6474ffaa5cb9--------------------------------)的最新教程，该教程专注于按颜色分组图像像素的使用案例。
- en: If you find [the intersection of AI, government regulations, and the intricacies
    of Canadian bureaucracy](/how-we-won-our-first-government-ai-project-8c67e58c22f0)
    fascinating (who wouldn’t?), [Mathieu Lemay](https://medium.com/u/f84a70d8f74?source=post_page-----6474ffaa5cb9--------------------------------)’s
    deep dive is the one article you absolutely shouldn’t miss this week.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你发现[人工智能、政府监管和加拿大官僚主义的交集](/how-we-won-our-first-government-ai-project-8c67e58c22f0)很吸引人（谁会不感兴趣呢？），[Mathieu
    Lemay](https://medium.com/u/f84a70d8f74?source=post_page-----6474ffaa5cb9--------------------------------)的深度剖析是你本周绝对不容错过的一篇文章。
- en: As the role of synthetic data continues to evolve (and grow) in numerous sectors,
    [Miriam Santos](https://medium.com/u/243289394aaa?source=post_page-----6474ffaa5cb9--------------------------------)’
    practical [guide to generating it with CTGAN](/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde)
    is as timely and useful as ever.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着合成数据在多个领域的作用不断发展（和增长），[Miriam Santos](https://medium.com/u/243289394aaa?source=post_page-----6474ffaa5cb9--------------------------------)的实用[CTGAN生成合成数据指南](/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde)依然时效性和实用性十足。
- en: We couldn’t possibly go an entire week without a GPT-themed pick; if you haven’t
    read it already, we highly recommend [Henry Lai](https://medium.com/u/d5548707b59?source=post_page-----6474ffaa5cb9--------------------------------)’s
    overview of [the data-centric AI concepts behind these ever-popular models](/what-are-the-data-centric-ai-concepts-behind-gpt-models-a590071bb727).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们绝对不能在一整周内没有一个以GPT为主题的推荐；如果你还没读过，我们强烈推荐[Henry Lai](https://medium.com/u/d5548707b59?source=post_page-----6474ffaa5cb9--------------------------------)对[这些备受欢迎的模型背后的数据驱动AI概念的概述](/what-are-the-data-centric-ai-concepts-behind-gpt-models-a590071bb727)。
- en: Thank you for tuning in to the Variable this week! If you enjoy the articles
    you read on TDS, consider [becoming a Medium member](https://bit.ly/tds-membership)—and
    if you’re a student in an eligible country, don’t miss a chance to [enjoy a substantial
    discount on a membership](https://blog.medium.com/new-student-discounts-cc10e964495b).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您本周收听《Variable》！如果您喜欢在TDS上阅读的文章，请考虑[成为Medium会员](https://bit.ly/tds-membership)——如果您是符合条件国家的学生，不要错过[享受会员大幅折扣](https://blog.medium.com/new-student-discounts-cc10e964495b)的机会。
- en: Until the next Variable,
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 下期《Variable》见，
- en: TDS Editors
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: TDS编辑团队
