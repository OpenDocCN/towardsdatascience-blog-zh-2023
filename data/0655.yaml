- en: Generative Q&A With GPT 3.5 and Long-Term Memory
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式问答与GPT 3.5及长期记忆
- en: 原文：[https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144?source=collection_archive---------0-----------------------#2023-02-17](https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144?source=collection_archive---------0-----------------------#2023-02-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144?source=collection_archive---------0-----------------------#2023-02-17](https://towardsdatascience.com/generative-question-answering-with-long-term-memory-c280e237b144?source=collection_archive---------0-----------------------#2023-02-17)
- en: Exploring the new world of retrieval-augmented ML
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索检索增强机器学习的新世界
- en: '[](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[![James
    Briggs](../Images/cb34b7011748e4d8607b7ff4a8510a93.png)](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    [James Briggs](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[![詹姆斯·布里格斯](../Images/cb34b7011748e4d8607b7ff4a8510a93.png)](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    [詹姆斯·布里格斯](https://jamescalam.medium.com/?source=post_page-----c280e237b144--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb9d77a4ca1d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-question-answering-with-long-term-memory-c280e237b144&user=James+Briggs&userId=b9d77a4ca1d1&source=post_page-b9d77a4ca1d1----c280e237b144---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    ·6 min read·Feb 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc280e237b144&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-question-answering-with-long-term-memory-c280e237b144&user=James+Briggs&userId=b9d77a4ca1d1&source=-----c280e237b144---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb9d77a4ca1d1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-question-answering-with-long-term-memory-c280e237b144&user=James+Briggs&userId=b9d77a4ca1d1&source=post_page-b9d77a4ca1d1----c280e237b144---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c280e237b144--------------------------------)
    ·6分钟阅读·2023年2月17日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc280e237b144&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-question-answering-with-long-term-memory-c280e237b144&source=-----c280e237b144---------------------bookmark_footer-----------)![](../Images/c5e51b39e15d83cb4ab0c9ed3580abef.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc280e237b144&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgenerative-question-answering-with-long-term-memory-c280e237b144&source=-----c280e237b144---------------------bookmark_footer-----------)![](../Images/c5e51b39e15d83cb4ab0c9ed3580abef.png)'
- en: Photo by [Bret Kavanaugh](https://unsplash.com/@bretkavanaugh?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral). *Originally
    published at* [*pinecone.io*](https://www.pinecone.io/learn/openai-gen-qa/), where
    the author is employed*.*
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [布雷特·卡瓦诺](https://unsplash.com/@bretkavanaugh?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)。
    *最初发表于* [*pinecone.io*](https://www.pinecone.io/learn/openai-gen-qa/)，*作者在该网站工作*。*
- en: Generative AI sparked several *“wow”* moments in 2022\. From generative art
    tools like OpenAI’s DALL-E 2, Midjourney, and Stable Diffusion, to the next generation
    of **L**arge **L**anguage **M**odels like OpenAI’s GPT-3.5 generation models,
    BLOOM, and chatbots like LaMDA and ChatGPT.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI在2022年引发了几个*“哇”*的时刻。从生成艺术工具如OpenAI的DALL-E 2、Midjourney和Stable Diffusion，到下一代**大**型**语**言**模**型，如OpenAI的GPT-3.5系列模型、BLOOM，以及像LaMDA和ChatGPT这样的聊天机器人。
- en: 'It’s hardly surprising that Generative AI is experiencing a boom in interest
    and innovation [1]. Yet, this marks *just* the first year of widespread adoption
    of generative AI: The early days of a new field poised to disrupt how we interact
    with machines.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 正经历着兴趣和创新的繁荣，这一点并不令人惊讶[1]。然而，这只是生成式 AI 广泛应用的**第一年**：这是一个新兴领域的早期阶段，预计将颠覆我们与机器的互动方式。
- en: One of the most thought-provoking use cases belongs to **G**enerative **Q**uestion-
    **A**nswering (GQA). Using GQA, we can sculpt human-like interaction with machines
    for information retrieval (IR).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最引人深思的应用之一属于**生成式问题回答（GQA）**。通过使用 GQA，我们可以打造类似人类的机器信息检索（IR）交互。
- en: We all use IR systems every day. Google search indexes the web and retrieves
    relevant information to your search terms. Netflix uses your behavior and history
    on the platform to recommend new TV shows and movies, and Amazon does the same
    with products [2].
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每天都在使用 IR 系统。Google 搜索索引了网络并检索与搜索词相关的信息。Netflix 利用你在平台上的行为和历史来推荐新的电视剧和电影，Amazon
    也用类似的方法推荐产品[2]。
- en: These applications of IR are world-changing. Yet, they may be little more than
    a faint echo of what we will see in the coming months and years with the combination
    of IR and GQA.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 IR 应用正在改变世界。然而，它们可能只是未来几个月和几年 IR 与 GQA 结合后的微弱回声。
