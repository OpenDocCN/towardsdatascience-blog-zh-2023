- en: Mixed Effects Machine Learning for Longitudinal & Panel Data with GPBoost (Part
    III)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GPBoost 进行纵向数据和面板数据的混合效应机器学习（第三部分）
- en: 原文：[https://towardsdatascience.com/mixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc?source=collection_archive---------3-----------------------#2023-07-17](https://towardsdatascience.com/mixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc?source=collection_archive---------3-----------------------#2023-07-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc?source=collection_archive---------3-----------------------#2023-07-17](https://towardsdatascience.com/mixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc?source=collection_archive---------3-----------------------#2023-07-17)
- en: A demo of GPBoost in Python & R using real-world data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用真实世界数据的 Python 和 R 中 GPBoost 的演示
- en: '[](https://medium.com/@fabsig?source=post_page-----523bb38effc--------------------------------)[![Fabio
    Sigrist](../Images/f7bc2adc17255ae1efd0886a19ec202c.png)](https://medium.com/@fabsig?source=post_page-----523bb38effc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----523bb38effc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----523bb38effc--------------------------------)
    [Fabio Sigrist](https://medium.com/@fabsig?source=post_page-----523bb38effc--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@fabsig?source=post_page-----523bb38effc--------------------------------)[![Fabio
    Sigrist](../Images/f7bc2adc17255ae1efd0886a19ec202c.png)](https://medium.com/@fabsig?source=post_page-----523bb38effc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----523bb38effc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----523bb38effc--------------------------------)
    [Fabio Sigrist](https://medium.com/@fabsig?source=post_page-----523bb38effc--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5b503a0c329&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc&user=Fabio+Sigrist&userId=b5b503a0c329&source=post_page-b5b503a0c329----523bb38effc---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----523bb38effc--------------------------------)
    ·11 min read·Jul 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F523bb38effc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc&user=Fabio+Sigrist&userId=b5b503a0c329&source=-----523bb38effc---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb5b503a0c329&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc&user=Fabio+Sigrist&userId=b5b503a0c329&source=post_page-b5b503a0c329----523bb38effc---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----523bb38effc--------------------------------)
    ·11 分钟阅读·2023年7月17日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F523bb38effc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc&user=Fabio+Sigrist&userId=b5b503a0c329&source=-----523bb38effc---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F523bb38effc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc&source=-----523bb38effc---------------------bookmark_footer-----------)![](../Images/afd55898ea6f1eb8180a279480fcead9.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F523bb38effc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmixed-effects-machine-learning-for-longitudinal-panel-data-with-gpboost-part-iii-523bb38effc&source=-----523bb38effc---------------------bookmark_footer-----------)![](../Images/afd55898ea6f1eb8180a279480fcead9.png)'
- en: '**Illustration of longitudinal data**: time series plots for different subjects
    (idcode) — Image by author'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**纵向数据的示例**：不同对象（idcode）的时间序列图 — 图片由作者提供'
- en: In [Part I](/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-i-an-empirical-df0a43dce059)
    and [Part II](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)
    of this series, we showed how random effects can be used for modeling high-cardinality
    categorical in machine learning models, and we gave an introduction to the `[GPBoost](https://github.com/fabsig/GPBoost)`
    [library](https://github.com/fabsig/GPBoost) which implements the [GPBoost algorithm](https://www.jmlr.org/papers/v23/20-322.html)
    combining tree-boosting with random effects. In this article, we demonstrate how
    the Python and R packages of the `GPBoost` library can be used for longitudinal
    data (aka repeated measures or panel data). You might want to first read [Part
    II](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)
    of this series as it gives a first introduction to the `GPBoost` library. `GPBoost`
    version 1.2.1 is used in this demo.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 I 部分](/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-i-an-empirical-df0a43dce059)
    和 [第 II 部分](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)
    的系列文章中，我们展示了如何使用随机效应对机器学习模型中的高基数类别变量进行建模，并介绍了实现 [GPBoost 算法](https://www.jmlr.org/papers/v23/20-322.html)
    的 `[GPBoost](https://github.com/fabsig/GPBoost)` [库](https://github.com/fabsig/GPBoost)，该算法将树提升与随机效应结合。在本文中，我们演示了如何使用
    `GPBoost` 库的 Python 和 R 包进行纵向数据（也称为重复测量或面板数据）分析。你可能需要先阅读 [第 II 部分](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)，因为它对
    `GPBoost` 库进行了初步介绍。此演示中使用的是 `GPBoost` 版本 1.2.1。
- en: Table of contents
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: '∘ [1 Data: description, loading, and sample split](#2605)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [1 数据：描述、加载和样本分割](#2605)
- en: ∘ [2 Modeling options for longitudinal data in GPBoost](#3fc9)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [2 GPBoost 中的纵向数据建模选项](#3fc9)
- en: · · [2.1 Subject grouped random effects](#fd01)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: · · [2.1 主题分组随机效应](#fd01)
- en: · · [2.2 Fixed effects only](#f29f)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: · · [2.2 仅固定效应](#f29f)
- en: · · [2.3 Subject and time grouped random effects](#a34f)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: · · [2.3 主题和时间分组的随机效应](#a34f)
- en: · · [2.4 Subject random effects with temporal random slopes](#d0bc)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: · · [2.4 带时间随机斜率的主题随机效应](#d0bc)
- en: · · [2.5 Subject-specific AR(1) / Gaussian process models](#b7a6)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: · · [2.5 主题特定的 AR(1) / 高斯过程模型](#b7a6)
- en: · · [2.6 Subject grouped random effects and a joint AR(1) model](#447d)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: · · [2.6 主题分组随机效应和联合 AR(1) 模型](#447d)
- en: ∘ [3 Training a GPBoost model](#cf4d)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [3 训练 GPBoost 模型](#cf4d)
- en: ∘ [4 Choosing tuning parameters](#8791)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [4 选择调优参数](#8791)
- en: ∘ [5 Prediction](#171b)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [5 预测](#171b)
- en: ∘ [6 Conclusion and references](#b4d0)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [6 结论和参考文献](#b4d0)
- en: '1 Data: description, loading, and sample split'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 数据：描述、加载和样本分割
- en: The data used in this demo is the wages data which was already used in [Part
    II](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492).
    It can be downloaded from [here](https://raw.githubusercontent.com/fabsig/Compare_ML_HighCardinality_Categorical_Variables/master/data/wages.csv.gz).
    The data set contains a total of 28’013 samples for 4’711 persons for which data
    was measured over several years. Such data is called longitudinal data, or panel
    data, since for every subject (person ID =`idcode`), data was collected repeatedly
    over time (years = `t`). In other words, the samples for every level of the categorical
    variable `idcode` are repeated measurements over time. The response variable is
    the logarithmic real wage (`ln_wage`), and the data includes several predictor
    variables such as age, total work experience, job tenure in years, date, and others.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此演示中使用的数据是已在 [第 II 部分](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)
    使用过的工资数据。数据可以从 [这里](https://raw.githubusercontent.com/fabsig/Compare_ML_HighCardinality_Categorical_Variables/master/data/wages.csv.gz)
    下载。数据集包含 28,013 个样本，涉及 4,711 个人，这些数据在几年内被测量。此类数据称为纵向数据或面板数据，因为对于每个主题（个人 ID = `idcode`），数据在时间上（年份
    = `t`）被重复收集。换句话说，每个类别变量 `idcode` 的级别的样本都是随时间重复测量的。响应变量是对数实际工资 (`ln_wage`)，数据还包括年龄、总工作经验、工作年限、日期等多个预测变量。
- en: In the code below, we load the data and randomly partition the data into 80%
    training data and 20% test data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们加载数据并将其随机分成 80% 的训练数据和 20% 的测试数据。
- en: '***Python***'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '***R***'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 2 Modeling options for longitudinal data in GPBoost
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 GPBoost 中的纵向数据建模选项
- en: Various combinations of fixed and random effects models for longitudinal data
    can be handled with the `GPBoost` library. In the following, we demonstrate several
    ones. This list is not exhaustive and other models are possible. After defining
    a random effects model (`gp_model`) and a `Dataset` (`data_bst`), training can
    be done with the `gpb.train` function. This latter training step is identical
    for all models presented in the following. For this reason, we do not include
    it here, but first show only how to define the corresponding models. See the subsequent
    Section 3 for how training is done.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`GPBoost`库可以处理纵向数据的各种固定和随机效应模型组合。下面，我们演示了几种模型。这个列表并不详尽，还有其他模型可能。定义了随机效应模型（`gp_model`）和`Dataset`（`data_bst`）之后，可以使用`gpb.train`函数进行训练。后续的训练步骤对所有模型都是相同的，因此在这里我们不包括训练步骤，而是首先仅展示如何定义相应的模型。关于如何进行训练，请参见后续的第3节。
- en: 2.1 Subject grouped random effects
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 受试者分组的随机效应
- en: 'A first option is to use grouped random effects for the categorical subject
    variable (`idcode`) and fixed effects for the time variable. This corresponds
    to the following model:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种选择是对分类受试者变量（`idcode`）使用分组随机效应，对时间变量使用固定效应。这对应于以下模型：
- en: '![](../Images/e61757b9a3cce538403dfbc6fddce6b3.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e61757b9a3cce538403dfbc6fddce6b3.png)'
- en: where i is the person index (=`idcode`), j is the temporal index, and we assume
    that xij contains the time variable (or a “dummified” / one-hot encoding version
    of it) and other predictor variables. The `idcode` random effect for person number
    i is bi and F(xij) is the tree-ensemble fixed effects function. Such a model can
    be specified in `GPBoost` as shown below. Subject-specific random effects are
    defined by passing the `idcode` categorical variable to the `group_data` argument
    of the `GPModel()` constructor. Note that the time variable `t` is of very low
    cardinality, and we can thus use one-hot encoding or dummy variables. This is
    what we do below as `pred_vars`, which defines the fixed effects predictor variables,
    already contains year dummy variables.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中i是人员索引（=`idcode`），j是时间索引，并且我们假设xij包含时间变量（或其“虚拟化”/独热编码版本）和其他预测变量。人员编号i的`idcode`随机效应是bi，F(xij)是树集成固定效应函数。这样的模型可以在`GPBoost`中指定，如下所示。受试者特定的随机效应通过将`idcode`分类变量传递给`GPModel()`构造函数的`group_data`参数来定义。注意时间变量`t`的基数非常低，因此我们可以使用独热编码或虚拟变量。我们在下面所做的即为此，`pred_vars`定义的固定效应预测变量已经包含了年份虚拟变量。
- en: '***Python***'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '***R***'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 2.2 Fixed effects only
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 仅固定效应
- en: 'Another option is to use a fixed effects-only model in which both subjects
    (`idcode`) and time are modeled using fixed effects, and there are no random effects.
    This corresponds to the following model:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用仅固定效应模型，其中受试者（`idcode`）和时间都使用固定效应进行建模，没有随机效应。这对应于以下模型：
- en: '![](../Images/1302953138704753c9828513d538b462.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1302953138704753c9828513d538b462.png)'
- en: again, for notational simplicity, assuming that xij contains the time variable.
    Such a model can be specified in `GPBoost` by simply including the subject (`idcode`)
    and time variables in the tree-boosting predictor variables and having no random
    effects model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，为了简化符号，假设xij包含时间变量。这样的模型可以通过在`GPBoost`中简单地将受试者（`idcode`）和时间变量包含在树提升预测变量中并且没有随机效应模型来指定。
- en: '***Python***'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '***R***'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 2.3 Subject and time grouped random effects
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 受试者和时间分组的随机效应
- en: 'One can also use random effects for both subjects (`idcode`) and time (`t`).
    This corresponds to the following model:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以对受试者（`idcode`）和时间（`t`）使用随机效应。这对应于以下模型：
- en: '![](../Images/faf9ee83a76b0a5c1b5206c9f70df28c.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/faf9ee83a76b0a5c1b5206c9f70df28c.png)'
- en: where bi and bj are the `idcode` and `t` random effects. Such a model can be
    specified in `GPBoost` as follows. In contrast to the above single-level random
    effects model in Section 2.1, we now pass two variables (`idcode` and `t)` to
    the `group_data` argument of the `GPModel()` constructor.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中bi和bj是`idcode`和`t`随机效应。这样的模型可以在`GPBoost`中如下指定。与上述第2.1节中的单级随机效应模型相比，我们现在将两个变量（`idcode`和`t`）传递给`GPModel()`构造函数的`group_data`参数。
- en: '***Python***'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '***R***'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 2.4 Subject random effects with temporal random slopes
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 受试者随机效应与时间随机斜率
- en: In the random effects models introduced so far (e.g., in Section 2.1), every
    subject (`idcode`) has a different intercept (=mean). However, besides this “shift”,
    the temporal evolution over time is the same for all persons. This restriction
    can be relaxed by including polynomial random coefficients (= random slopes).
    For instance, a model with random slopes for `t` and `t^2` is given by
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在迄今为止介绍的随机效应模型中（例如，在第 2.1 节中），每个个体（`idcode`）都有不同的截距（=均值）。然而，除了这种“偏移”之外，时间上的演变对所有个体是相同的。通过包括多项式随机系数（=
    随机斜率），可以放宽这一限制。例如，一个对`t`和`t^2`具有随机斜率的模型为
- en: '![](../Images/cd89f3740c0715815bf5a81984dd1e6c.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd89f3740c0715815bf5a81984dd1e6c.png)'
- en: where b(0,i) are the intercept random effects, b(1,i) and b(2,i) are the random
    slopes, and tij denotes the time `t` for the sample ij. Due to the temporal random
    slopes, every person has a different evolution over time `t` in this model. Such
    a model can be specified in `GPBoost` as shown in the code below. The `group_rand_coef_data`
    variable contains the random coefficient covariate data `t` and `t^2`. Further,
    the indices in `ind_effect_group_rand_coef` indicate for which categorical variable
    in `group_data` this covariate data should be used to obtain random coefficients.
    Here, there is only one categorical variable (`idcode`), and thus `ind_effect_group_rand_coef`
    is simply (1,1) (i.e., both `t` and `t^2` belong to `idcode`).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 b(0,i) 是截距随机效应，b(1,i) 和 b(2,i) 是随机斜率，tij 表示样本 ij 的时间`t`。由于时间上的随机斜率，在此模型中每个人在时间`t`上的演变是不同的。这种模型可以在`GPBoost`中进行指定，如下代码所示。`group_rand_coef_data`
    变量包含随机系数协变量数据`t` 和 `t^2`。此外，`ind_effect_group_rand_coef`中的索引指示应该使用哪些`group_data`中的分类变量来获取随机系数。在这里，只有一个分类变量（`idcode`），因此
    `ind_effect_group_rand_coef` 只是 (1,1)（即，`t` 和 `t^2` 都属于 `idcode`）。
- en: '***Python***'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '***R***'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 2.5 Subject-specific AR(1) / Gaussian process models
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 个体特定的 AR(1) / 高斯过程模型
- en: 'A further extension of the above random slopes model is to use time series
    models, or Gaussian processes, instead of polynomial random slopes. This allows
    for separately modeling the temporal evolution of every subject in a more flexible
    way. For instance, one can use subject-specific AR(1) models:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对上述随机斜率模型的进一步扩展是使用时间序列模型或高斯过程，而不是多项式随机斜率。这允许以更灵活的方式分别建模每个个体的时间演变。例如，可以使用个体特定的
    AR(1) 模型：
- en: '![](../Images/55d67efe369fecf9328b9271cdd93ba8.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55d67efe369fecf9328b9271cdd93ba8.png)'
- en: In this model, every person i has separate random effects bij which evolve over
    time according to an AR(1) model (= discretized Gaussian process with an exponential
    covariance function). Such a model can be specified in `GPBoost` as shown in the
    following code. A temporal Gaussian process is defined by passing the time variable
    `t` to the `gp_coords` argument. We use a Gaussian process with an exponential
    covariance function which is equivalent to an AR(1) model. Further, the `cluster_ids`
    variable indicates that every person (`idcode`) has a separate (= a priori independent)
    Gaussian process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在此模型中，每个个体 i 都有独立的随机效应 bij，这些效应随时间按照 AR(1) 模型演变（= 离散化的高斯过程，具有指数协方差函数）。这种模型可以在`GPBoost`中进行指定，如下代码所示。时间高斯过程通过将时间变量`t`传递给`gp_coords`参数来定义。我们使用具有指数协方差函数的高斯过程，这相当于
    AR(1) 模型。此外，`cluster_ids` 变量指示每个人（`idcode`）都有一个独立的（= 先验独立）高斯过程。
- en: '***Python***'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '***R***'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: After training, the AR(1) model parameters can be obtained from the Gaussian
    process covariance parameters as follows.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后，AR(1) 模型参数可以从高斯过程协方差参数中获得，如下所示。
- en: '***Python***'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '***R***'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE13]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 2.6 Subject grouped random effects and a joint AR(1) model
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 主题分组随机效应和联合 AR(1) 模型
- en: 'Another alternative is to use one single temporal AR(1) model which is shared
    across subjects but include separate temporally constant subject (`idcode`) random
    effects. This corresponds to the following model:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用一个在所有个体中共享的单一时间 AR(1) 模型，但包括单独的时间常数个体（`idcode`）随机效应。这对应于以下模型：
- en: '![](../Images/a931905ccac70d85093438b147020273.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a931905ccac70d85093438b147020273.png)'
- en: Such a model can be specified in `GPBoost` as follows.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型可以在`GPBoost`中进行如下指定。
- en: '***Python***'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '***R***'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE15]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 3 Training a GPBoost model
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 训练 GPBoost 模型
- en: The following code shows how to train a GPBoost model. We first define a random
    effects model (`gp_model`), a `Dataset` (`data_bst`), tuning parameters (`params`
    and `nrounds` = number of trees / boosting iteration), and then run the GPBoost
    algorithm by calling the `gpb.train` function. We use a subject (`idcode`) random
    effects model with temporal random slopes (see Section 2.4) as such a model often
    provides a good compromise between flexibility/accuracy and runtime. Note that
    we use tuning parameters that have been selected beforehand (see below).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何训练一个GPBoost模型。我们首先定义了一个随机效应模型（`gp_model`）、一个`Dataset`（`data_bst`）、调整参数（`params`和`nrounds`
    = 树的数量/提升迭代次数），然后通过调用`gpb.train`函数运行GPBoost算法。我们使用一个带有时间随机斜率的受试者（`idcode`）随机效应模型（见第2.4节），因为这样的模型通常在灵活性/准确性和运行时间之间提供了很好的折衷。请注意，我们使用的是提前选择好的调整参数（见下文）。
- en: '***Python***'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '***R***'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: When having multiple random effects (as is the case here), it can be faster
    to use `nelder_mead` instead of `gradient_descent`(=default) as optimizer*.* This
    can be set as follows before calling `gpb.train`. For this data set, it does not
    matter, though.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当存在多个随机效应（如这里的情况）时，使用`nelder_mead`作为优化器通常比`gradient_descent`（默认为优化器）更快*。* 这可以在调用`gpb.train`之前设置。然而，对于这个数据集来说，这并不重要。
- en: '***Python***'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '***R***'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE20]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 4 Choosing tuning parameters
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 选择调整参数
- en: 'It is important that tuning parameters are appropriately chosen for boosting.
    There are no universal default values and every data set will likely need different
    tuning parameters. Below, we show how tuning parameters can be chosen using the
    `gpb.grid.search.tune.parameters` function. We use a deterministic grid search
    with the parameter combinations shown below in the code. Note that we tune the
    `max_depth` parameter and thus set the `num_leaves` to a large value. We randomly
    split the training data into 80% inner training data 20% validation data and use
    the mean squared error (`mse`) as a prediction accuracy measure on the validation
    data. Alternatively, one can also use, e.g., the test negative log-likelihood
    (`metric = "test_neg_log_likelihood"` = default) which also takes prediction uncertainty
    into account. *Note: depending on the data set and the grid size, this can take
    some time (approx. half an hour on my laptop for this data set). Instead of a
    deterministic grid search as below, one can also do a random grid search (see*
    `*num_try_random*`*) or another approach such as Bayesian optimization to speed
    things up.*'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 调整参数在提升模型中选择得当是非常重要的。没有通用的默认值，每个数据集可能需要不同的调整参数。下面，我们展示了如何使用`gpb.grid.search.tune.parameters`函数来选择调整参数。我们使用带有下述参数组合的确定性网格搜索。请注意，我们调整了`max_depth`参数，并将`num_leaves`设置为较大的值。我们将训练数据随机拆分为80%的内部训练数据和20%的验证数据，并使用均方误差（`mse`）作为验证数据上的预测准确度测量。或者，也可以使用例如测试负对数似然（`metric
    = "test_neg_log_likelihood"` = 默认），它也会考虑预测的不确定性。*注意：根据数据集和网格大小，这可能需要一些时间（在我的笔记本电脑上大约半小时）。除了下面的确定性网格搜索外，还可以进行随机网格搜索（见`*num_try_random*`）或其他方法，如贝叶斯优化，以加快速度。*
- en: '***Python***'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '***R***'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 5 Prediction
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 预测
- en: Predictions can be obtained via the `predict` function. We need to provide both
    test predictor variables (`data`) for the tree ensemble as well as test subject
    variables and random slopes data (`group_data_pred` and `group_rand_coef_data_pred`)
    for the random effects model. Below, we make predictions on the left-out test
    data and calculate the test mean squared error (MSE). As the results below show,
    the prediction accuracy of this random slopes model is higher compared to a simpler
    subject random effects model without random slopes introduced in Section 2.1 (see
    [Part II](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)
    for results of the latter model).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过`predict`函数获得预测结果。我们需要提供树集成的测试预测变量（`data`）以及随机效应模型的测试受试者变量和随机斜率数据（`group_data_pred`和`group_rand_coef_data_pred`）。下面，我们对遗漏的测试数据进行预测，并计算测试均方误差（MSE）。正如下面的结果所示，与第2.1节中介绍的没有引入随机斜率的简单受试者随机效应模型相比，这个随机斜率模型的预测准确度更高（有关后者模型的结果，请参见[第二部分](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)）。
- en: '***Python***'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '***Python***'
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '***R***'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '***R***'
- en: '[PRE25]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 6 Conclusion and references
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 结论和参考文献
- en: We have demonstrated how to use the `GPBoost` library for modeling longitudinal
    data. There are several more features of the `GPBoost` library that we did not
    show here. For instance, in [Part II](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)
    of this series, we show to understand the fixed effects function using machine
    learning interpretability techniques, and we also demonstrate how the `GPBoost`
    library can handle (generalized) linear mixed effects models (GLMMs → F() is linear
    instead of tree ensemble). You may also want to have a look at the [Python examples](https://github.com/fabsig/GPBoost/tree/master/examples/python-guide)
    and [R examples](https://github.com/fabsig/GPBoost/tree/master/R-package/demo).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了如何使用`GPBoost`库来建模纵向数据。`GPBoost`库还有更多我们未展示的功能。例如，在[第二部分](https://medium.com/towards-data-science/mixed-effects-machine-learning-for-high-cardinality-categorical-variables-part-ii-gpboost-3bdd9ef74492)中，我们展示了如何利用机器学习可解释性技术理解固定效应函数，同时也演示了`GPBoost`库如何处理（广义）线性混合效应模型（GLMMs
    → F() 是线性的而不是树集合）。你还可以查看[Python 示例](https://github.com/fabsig/GPBoost/tree/master/examples/python-guide)和[R
    示例](https://github.com/fabsig/GPBoost/tree/master/R-package/demo)。
- en: F. Sigrist. Gaussian Process Boosting. The Journal of Machine Learning Research,
    23(1):10565–10610, 2022.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F. Sigrist. 高斯过程提升. 机器学习研究杂志, 23(1):10565–10610, 2022。
- en: F. Sigrist. Latent Gaussian Model Boosting. IEEE Transactions on Pattern Analysis
    and Machine Intelligence, 45(2):1894–1905, 2023.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F. Sigrist. 潜在高斯模型提升. IEEE模式分析与机器智能学报, 45(2):1894–1905, 2023。
- en: '[https://github.com/fabsig/GPBoost](https://github.com/fabsig/GPBoost)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/fabsig/GPBoost](https://github.com/fabsig/GPBoost)'
