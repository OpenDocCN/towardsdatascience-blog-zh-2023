- en: '3D Python Workflows for LiDAR City Models: A Step-by-Step Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ã€ŠLiDAR åŸå¸‚æ¨¡å‹çš„ 3D Python å·¥ä½œæµç¨‹ï¼šä¸€æ­¥æ­¥æŒ‡å—ã€‹
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0](https://towardsdatascience.com/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0](https://towardsdatascience.com/3d-python-workflows-for-lidar-point-clouds-100ff40e4ff0)
- en: 3D Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3D Python
- en: '[](https://medium.com/@florentpoux?source=post_page-----100ff40e4ff0--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----100ff40e4ff0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----100ff40e4ff0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----100ff40e4ff0--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----100ff40e4ff0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@florentpoux?source=post_page-----100ff40e4ff0--------------------------------)[![Florent
    Poux, Ph.D.](../Images/74df1e559b2edefba71ffd0d1294a251.png)](https://medium.com/@florentpoux?source=post_page-----100ff40e4ff0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----100ff40e4ff0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----100ff40e4ff0--------------------------------)
    [Florent Poux, Ph.D.](https://medium.com/@florentpoux?source=post_page-----100ff40e4ff0--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----100ff40e4ff0--------------------------------)
    Â·38 min readÂ·Apr 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----100ff40e4ff0--------------------------------)
    Â·38 åˆ†é’Ÿé˜…è¯»Â·2023å¹´4æœˆ4æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling
    Applications. The tutorial covers Python Automation combining 3D Point Clouds,
    Meshes, and Voxels for advanced analysis.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è§£é” 3D åŸå¸‚å»ºæ¨¡åº”ç”¨çš„ç²¾ç®€å·¥ä½œæµç¨‹çš„ç»ˆææŒ‡å—ã€‚æ•™ç¨‹æ¶µç›–äº†ç»“åˆ 3D ç‚¹äº‘ã€ç½‘æ ¼å’Œä½“ç´ çš„ Python è‡ªåŠ¨åŒ–ï¼Œä»¥è¿›è¡Œé«˜çº§åˆ†æã€‚
- en: '![](../Images/97c090b15454c5c08f7efcab12fb9808.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97c090b15454c5c08f7efcab12fb9808.png)'
- en: '3D Python Workflows for LiDAR City Models: A Step-by-Step Guide. This cover
    is from my other half [Marina](https://www.instagram.com/mimatelier_/), and highlights
    the art process of 3D City Modelling. Â© [Mimatelier](https://mimatelier.com/).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ã€ŠLiDAR åŸå¸‚æ¨¡å‹çš„ 3D Python å·¥ä½œæµç¨‹ï¼šä¸€æ­¥æ­¥æŒ‡å—ã€‹ã€‚å°é¢æ¥è‡ªæˆ‘çš„å¦ä¸€åŠ[Marina](https://www.instagram.com/mimatelier_/)ï¼Œå±•ç¤ºäº†
    3D åŸå¸‚å»ºæ¨¡çš„è‰ºæœ¯è¿‡ç¨‹ã€‚Â© [Mimatelier](https://mimatelier.com/)ã€‚
- en: 'Did you stumble upon the term Smart City before? or Smart Something? Well,
    we touch on the subject! Think of a Smart City as a baker on steroids ğŸ¥: it knows
    what you need before you even ask for it and will provide you with the most straightforward
    advice to make a delicious choice. No, this Smart City Metaphor is not all I have
    for you today. Indeed, to get to this level of â€œSmartâ€, we first have to get to
    the base layer: 3D City Models.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹‹å‰é‡åˆ°è¿‡â€œæ™ºèƒ½åŸå¸‚â€è¿™ä¸ªè¯å—ï¼Ÿæˆ–è€…â€œæ™ºèƒ½æŸç‰©â€ï¼Ÿå¥½å§ï¼Œæˆ‘ä»¬ä¼šæ¶‰åŠè¿™ä¸ªè¯é¢˜ï¼å°†æ™ºèƒ½åŸå¸‚æƒ³è±¡æˆä¸€ä¸ªè¶…èƒ½çš„é¢åŒ…å¸ˆ ğŸ¥ï¼šå®ƒçŸ¥é“ä½ éœ€è¦ä»€ä¹ˆï¼Œç”šè‡³åœ¨ä½ æå‡ºä¹‹å‰å°±ä¼šæä¾›æœ€ç›´æ¥çš„å»ºè®®ï¼Œå¸®åŠ©ä½ åšå‡ºç¾å‘³çš„é€‰æ‹©ã€‚ä¸ï¼Œè¿™ä¸ªæ™ºèƒ½åŸå¸‚çš„æ¯”å–»å¹¶ä¸æ˜¯æˆ‘ä»Šå¤©å”¯ä¸€è¦åˆ†äº«çš„å†…å®¹ã€‚ç¡®å®ï¼Œè¦è¾¾åˆ°è¿™ç§â€œæ™ºèƒ½â€çš„æ°´å¹³ï¼Œæˆ‘ä»¬é¦–å…ˆå¾—ä»åŸºç¡€å±‚é¢å…¥æ‰‹ï¼š3D
    åŸå¸‚æ¨¡å‹ã€‚
- en: If you ever wanted to create stunning 3D City Models but found the workflow
    daunting and complex, this is where I come in! This article explores how Python
    and open-source software can define a powerful 3D workflow to kickstart your 3D
    City Modelling journey. Say (almost) goodbye to tedious manual processes and hello
    to efficient, dynamic, and eye-catching creations!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ›¾ç»æƒ³è¦åˆ›å»ºä»¤äººæƒŠå¹çš„ 3D åŸå¸‚æ¨¡å‹ï¼Œä½†å‘ç°å·¥ä½œæµç¨‹ä»¤äººç”Ÿç•ä¸”å¤æ‚ï¼Œé‚£ä¹ˆæˆ‘å¯ä»¥å¸®å¿™ï¼æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨ Python å’Œå¼€æºè½¯ä»¶å®šä¹‰ä¸€ä¸ªå¼ºå¤§çš„
    3D å·¥ä½œæµç¨‹ï¼Œä»¥å¯åŠ¨ä½ çš„ 3D åŸå¸‚å»ºæ¨¡ä¹‹æ—…ã€‚å‘ç¹ççš„æ‰‹åŠ¨æµç¨‹è¯´ï¼ˆå‡ ä¹ï¼‰å†è§ï¼Œè¿æ¥é«˜æ•ˆã€åŠ¨æ€ä¸”å¼•äººæ³¨ç›®çš„åˆ›ä½œå§ï¼
- en: We dive into a four-step strategy that describes Environment setup, 3D Data
    Curation & Preparation, and 3D Geometry Processing to extract critical insights
    such as the built coverage of your neighborhood using point cloud data, meshes,
    voxels, and some grey matter ğŸ§ .
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ·±å…¥æ¢è®¨äº†ä¸€ä¸ªå››æ­¥ç­–ç•¥ï¼Œæè¿°äº†ç¯å¢ƒè®¾ç½®ã€3D æ•°æ®ç­–åˆ’ä¸å‡†å¤‡ä»¥åŠ 3D å‡ ä½•å¤„ç†ï¼Œä»¥æå–å…³é”®æ´å¯Ÿï¼Œä¾‹å¦‚ä½¿ç”¨ç‚¹äº‘æ•°æ®ã€ç½‘æ ¼ã€ä½“ç´ ä»¥åŠä¸€äº›ç°è´¨ ğŸ§ ï¼Œäº†è§£ä½ æ‰€åœ¨ç¤¾åŒºçš„å»ºç­‘è¦†ç›–æƒ…å†µã€‚
- en: '![](../Images/dd6cd4c7638e5fd0967612930ab5e1a1.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd6cd4c7638e5fd0967612930ab5e1a1.png)'
- en: '3D Python Workflows for LiDAR City Models: A Step-by-Step Guide. Â© Author'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ã€ŠLiDAR åŸå¸‚æ¨¡å‹çš„ 3D Python å·¥ä½œæµç¨‹ï¼šä¸€æ­¥æ­¥æŒ‡å—ã€‹ã€‚Â© ä½œè€…
- en: If you are ready and pumped, it is time to get 3D Coding!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å·²ç»å‡†å¤‡å¥½å¹¶å……æ»¡çƒ­æƒ…ï¼Œç°åœ¨æ˜¯æ—¶å€™å¼€å§‹ 3D ç¼–ç¨‹äº†ï¼
- en: 'ğŸµ**Note to Readers***: This hands-on guide is part of a* [***UTWENTE***](https://www.itc.nl/)
    *joint work with my dear colleagues* [***Dr. Sander Oude Elberink***](https://people.utwente.nl/s.j.oudeelberink)*,*
    [***Dr. Mila Koeva***](https://people.utwente.nl/m.n.koeva)*,* [***Dr. Ville Lehtola***](https://people.utwente.nl/v.v.lehtola)*,*
    [***Dr. Pirouz Nourian***](https://people.utwente.nl/p.nourian)*,* [***Dr. Paulo
    Raposo***](https://people.utwente.nl/p.raposo)*. and* [***Prof G. Vosselman***](https://research.utwente.nl/en/persons/george-vosselman)*.
    We acknowledge the financial contribution from the digital twins* [*@ITC*](http://twitter.com/ITC)
    *-project granted by the ITC faculty of the University of Twente.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸµ**è‡´è¯»è€…çš„è¯´æ˜**ï¼šè¿™æœ¬å®è·µæŒ‡å—æ˜¯* [***UTWENTE***](https://www.itc.nl/) *ä¸æˆ‘äº²çˆ±çš„åŒäº‹ä»¬* [***Dr.
    Sander Oude Elberink***](https://people.utwente.nl/s.j.oudeelberink)*,* [***Dr.
    Mila Koeva***](https://people.utwente.nl/m.n.koeva)*,* [***Dr. Ville Lehtola***](https://people.utwente.nl/v.v.lehtola)*,*
    [***Dr. Pirouz Nourian***](https://people.utwente.nl/p.nourian)*,* [***Dr. Paulo
    Raposo***](https://people.utwente.nl/p.raposo)*. å’Œ* [***Prof G. Vosselman***](https://research.utwente.nl/en/persons/george-vosselman)*
    çš„å…±åŒå·¥ä½œä¹‹ä¸€ã€‚æˆ‘ä»¬æ„Ÿè°¢æ¥è‡ªæ•°å­—åŒèƒèƒ* [*@ITC*](http://twitter.com/ITC) *é¡¹ç›®çš„èµ„é‡‘æ”¯æŒï¼Œè¯¥é¡¹ç›®ç”±ç‰¹æ¸©ç‰¹å¤§å­¦ITCå­¦é™¢æˆäºˆã€‚*
- en: '![](../Images/a969888432c000fbe6ebde8acd430ae3.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a969888432c000fbe6ebde8acd430ae3.png)'
- en: An extract of the 3D Python dataset we will handle in this guide. Â© Author
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æœ¬æŒ‡å—ä¸­å¤„ç†çš„3D Pythonæ•°æ®é›†çš„æ‘˜å½•ã€‚Â© ä½œè€…
- en: Introduction
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¼•è¨€
- en: 'Before rushing onto the fun bits, let me tell you a small story to give a bit
    of depth to what we will achieve. This starts with a fundamental question: What
    is 3D City Modeling, and why is it helpful?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›å…¥æœ‰è¶£çš„éƒ¨åˆ†ä¹‹å‰ï¼Œè®©æˆ‘è®²ä¸€ä¸ªå°æ•…äº‹ï¼Œä¸ºæˆ‘ä»¬å°†è¦å®ç°çš„ç›®æ ‡æä¾›ä¸€äº›èƒŒæ™¯ã€‚è¿™å§‹äºä¸€ä¸ªåŸºæœ¬çš„é—®é¢˜ï¼šä»€ä¹ˆæ˜¯3DåŸå¸‚å»ºæ¨¡ï¼Œå®ƒä¸ºä½•æœ‰ç”¨ï¼Ÿ
- en: 'In an urbanized world, 3D city modeling is essential for efficiently managing
    our daily lives. By accurately representing our cities in three dimensions, we
    can analyze and visualize complex urban environments, understand the impact of
    proposed changes, and make informed decisions to improve the quality of life for
    residents. This is a fundamental notion that is well captured by the beautifully
    phrased sentence: Cities shape lifeÂ¹.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ä¸ªåŸå¸‚åŒ–çš„ä¸–ç•Œé‡Œï¼Œ3DåŸå¸‚å»ºæ¨¡å¯¹äºé«˜æ•ˆç®¡ç†æˆ‘ä»¬çš„æ—¥å¸¸ç”Ÿæ´»è‡³å…³é‡è¦ã€‚é€šè¿‡å‡†ç¡®åœ°ä»¥ä¸‰ç»´æ–¹å¼å‘ˆç°æˆ‘ä»¬çš„åŸå¸‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ†æå’Œå¯è§†åŒ–å¤æ‚çš„åŸå¸‚ç¯å¢ƒï¼Œç†è§£æè®®æ›´æ”¹çš„å½±å“ï¼Œå¹¶åšå‡ºæ˜æ™ºçš„å†³ç­–ï¼Œä»¥æ”¹å–„å±…æ°‘çš„ç”Ÿæ´»è´¨é‡ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºæœ¬çš„æ¦‚å¿µï¼Œç”±é‚£å¥ä¼˜ç¾çš„è¯å¾ˆå¥½åœ°è¡¨è¾¾ï¼šåŸå¸‚å¡‘é€ ç”Ÿæ´»Â¹ã€‚
- en: '![](../Images/8cfddea6a8bbd75cb37a16e5edb3493c.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cfddea6a8bbd75cb37a16e5edb3493c.png)'
- en: Toward Smart Cities to improve our lives. Â© Author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æœå‘æ™ºèƒ½åŸå¸‚ä»¥æ”¹å–„æˆ‘ä»¬çš„ç”Ÿæ´»ã€‚Â© ä½œè€…
- en: Indeed, Cities are places where people live, form communities, and establish
    their own identities. They are spaces, such as the inner city and the suburb,
    that offer a way to configure and shape the material world and natural environment.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: çš„ç¡®ï¼ŒåŸå¸‚æ˜¯äººä»¬ç”Ÿæ´»ã€å½¢æˆç¤¾åŒºå¹¶å»ºç«‹è‡ªå·±èº«ä»½çš„åœ°æ–¹ã€‚å®ƒä»¬æ˜¯å¦‚å¸‚ä¸­å¿ƒå’ŒéƒŠåŒºè¿™æ ·çš„ç©ºé—´ï¼Œæä¾›äº†ä¸€ç§é…ç½®å’Œå¡‘é€ ç‰©è´¨ä¸–ç•Œå’Œè‡ªç„¶ç¯å¢ƒçš„æ–¹å¼ã€‚
- en: Imagine if you had a superpowered ability to model transportation networks in
    your city, predict traffic patterns and identify areas of congestion. How would
    it change the way you live your city? And that is a super tiny example taken as
    a city â€œuserâ€. But at the root, 3D city modeling provides valuable insights for
    urban planners, architects, and policymakers to optimize city infrastructure,
    reduce traffic, and enhance public safety.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ æœ‰ä¸€ç§è¶…çº§èƒ½åŠ›ï¼Œå¯ä»¥å¯¹ä½ çš„åŸå¸‚äº¤é€šç½‘ç»œè¿›è¡Œå»ºæ¨¡ï¼Œé¢„æµ‹äº¤é€šæ¨¡å¼å¹¶è¯†åˆ«æ‹¥å µåŒºåŸŸã€‚è¿™å°†å¦‚ä½•æ”¹å˜ä½ åœ¨åŸå¸‚ä¸­çš„ç”Ÿæ´»æ–¹å¼ï¼Ÿè¿™åªæ˜¯ä½œä¸ºåŸå¸‚â€œç”¨æˆ·â€çš„ä¸€ä¸ªå¾®å°ä¾‹å­ã€‚ä½†ä»æ ¹æœ¬ä¸Šè®²ï¼Œ3DåŸå¸‚å»ºæ¨¡ä¸ºåŸå¸‚è§„åˆ’å¸ˆã€å»ºç­‘å¸ˆå’Œæ”¿ç­–åˆ¶å®šè€…æä¾›äº†å®è´µçš„è§è§£ï¼Œä»¥ä¼˜åŒ–åŸå¸‚åŸºç¡€è®¾æ–½ã€å‡å°‘äº¤é€šæ‹¥å µå¹¶æé«˜å…¬å…±å®‰å…¨ã€‚
- en: By creating a digital replica of our cities, we can thus better plan for the
    future and create sustainable, livable communities for generations to come.Â²â»Â³
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åˆ›å»ºæˆ‘ä»¬åŸå¸‚çš„æ•°å­—åŒ–å¤åˆ¶å“ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°è§„åˆ’æœªæ¥ï¼Œä¸ºå­å­™åä»£åˆ›é€ å¯æŒç»­ã€å®œå±…çš„ç¤¾åŒºã€‚Â²â»Â³
- en: 'Â¹ Chen, X., Orum, A. M., & Paulsen, K. E. (2018). *Introduction to Cities:
    How place and space shape human experience*. John Wiley & Sons.'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Â¹ Chen, X., Orum, A. M., & Paulsen, K. E. (2018). *ã€ŠåŸå¸‚å¯¼è®ºï¼šåœ°æ–¹å’Œç©ºé—´å¦‚ä½•å¡‘é€ äººç±»ä½“éªŒã€‹*ã€‚çº¦ç¿°Â·å¨åˆ©çˆ¶å­å…¬å¸ã€‚
- en: ''
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Â² Lehtola, V. V., Koeva, M., Elberink, S. O., Raposo, P., Virtanen, J. P.,
    Vahdatikhaki, F., & Borsci, S. (2022). *Digital twin of a city: Review of technology
    serving city needs.* International Journal of Applied Earth Observation and Geoinformation,
    102915.'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Â² Lehtola, V. V., Koeva, M., Elberink, S. O., Raposo, P., Virtanen, J. P., Vahdatikhaki,
    F., & Borsci, S. (2022). *ã€ŠåŸå¸‚æ•°å­—åŒèƒèƒï¼šæœåŠ¡åŸå¸‚éœ€æ±‚çš„æŠ€æœ¯ç»¼è¿°ã€‹*ã€‚ã€Šå›½é™…åº”ç”¨åœ°çƒè§‚å¯Ÿä¸åœ°ç†ä¿¡æ¯æ‚å¿—ã€‹ï¼Œ102915ã€‚
- en: ''
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Â³ Nourian, P., Ohori, K. A., & Martinez-Ortiz, C. (2018). Essential means for
    urban computing: Specification of web-based computing platforms for urban planning,
    a Hitchhikerâ€™s guide. Urban Planning, 3(1), 47â€“57'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Â³ Nourian, P., Ohori, K. A., & Martinez-Ortiz, C. (2018). åŸå¸‚è®¡ç®—çš„åŸºæœ¬æ‰‹æ®µï¼šåŸºäºç½‘ç»œçš„åŸå¸‚è§„åˆ’è®¡ç®—å¹³å°çš„è§„èŒƒï¼Œæ—…è¡Œè€…æŒ‡å—ã€‚åŸå¸‚è§„åˆ’ï¼Œ3(1)ï¼Œ47â€“57
- en: '3D City Modelling: The Workflow'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3DåŸå¸‚å»ºæ¨¡ï¼šå·¥ä½œæµç¨‹
- en: Time to get half-serious and define a coherent 3D Workflow that we could use
    as an inspiration for different 3D City Modeling Operations. We aim at something
    that is (1) Easy to set up and run, (2) Provides great flexibility to various
    scenarios, and (3) powerful enough to encompass the complexity of multi-modal
    applications.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¯æ—¶å€™è®¤çœŸèµ·æ¥ï¼Œå®šä¹‰ä¸€ä¸ªä¸€è‡´çš„3Då·¥ä½œæµç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶ä½œä¸ºä¸åŒ3DåŸå¸‚å»ºæ¨¡æ“ä½œçš„çµæ„Ÿã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼ˆ1ï¼‰æ˜“äºè®¾ç½®å’Œè¿è¡Œï¼Œï¼ˆ2ï¼‰ä¸ºå„ç§åœºæ™¯æä¾›æå¤§çš„çµæ´»æ€§ï¼Œä»¥åŠï¼ˆ3ï¼‰è¶³å¤Ÿå¼ºå¤§ä»¥æ¶µç›–å¤šæ¨¡æ€åº”ç”¨çš„å¤æ‚æ€§ã€‚
- en: 'ğŸ¦š **Note**: *No, multi-modal is not a swearword: it just touches on the point
    that when dealing with 3D City Models, we encounter various geospatial data modalities
    to be considered. In this tutorial, we will focus on a beautiful niche: 3D Geospatial
    Data in the form of* ***Point Clouds****,* ***Voxels****, and* ***3D Meshes****.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*ä¸ï¼Œå¤šæ¨¡æ€ä¸æ˜¯è„è¯ï¼šå®ƒåªæ˜¯è§¦åŠåˆ°å½“å¤„ç†3DåŸå¸‚æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é‡åˆ°å„ç§éœ€è¦è€ƒè™‘çš„åœ°ç†ç©ºé—´æ•°æ®æ¨¡æ€ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äºä¸€ä¸ªç¾ä¸½çš„ç»†åˆ†é¢†åŸŸï¼š*
    ***ç‚¹äº‘****ï¼Œ* ***ä½“ç´ ****ï¼Œä»¥åŠ* ***3Dç½‘æ ¼****ã€‚
- en: If we decompose the workflow definition on a high-level view, we follow four
    main steps, as shown below.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ä»é«˜å±‚æ¬¡å®šä¹‰å·¥ä½œæµç¨‹ï¼Œæˆ‘ä»¬ä¼šéµå¾ªå››ä¸ªä¸»è¦æ­¥éª¤ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/35a2f7dccc19d471620463aa5284aeb7.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35a2f7dccc19d471620463aa5284aeb7.png)'
- en: The 3D Python LiDAR Workflow in the context of City Models. We start with the
    Environment Set up (Step 1) and 3D Data Preparation (Step 2). Once this is done,
    we move on to Python Automation (Step 3), with a specific part dealing with 3D
    Python Challenges (Step 4), such as Parcel Surface or Point Of Interest Queries.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŸå¸‚æ¨¡å‹èƒŒæ™¯ä¸‹çš„3D Python LiDARå·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬ä»ç¯å¢ƒè®¾ç½®ï¼ˆæ­¥éª¤1ï¼‰å’Œ3Dæ•°æ®å‡†å¤‡ï¼ˆæ­¥éª¤2ï¼‰å¼€å§‹ã€‚ä¸€æ—¦å®Œæˆè¿™äº›æ­¥éª¤ï¼Œæˆ‘ä»¬è¿›å…¥Pythonè‡ªåŠ¨åŒ–ï¼ˆæ­¥éª¤3ï¼‰ï¼Œå…¶ä¸­ä¸€ä¸ªç‰¹å®šéƒ¨åˆ†å¤„ç†3D
    PythonæŒ‘æˆ˜ï¼ˆæ­¥éª¤4ï¼‰ï¼Œä¾‹å¦‚åœ°å—è¡¨é¢æˆ–å…´è¶£ç‚¹æŸ¥è¯¢ã€‚
- en: Excited? Looking closely at the pipeline, you can see that we start from scratch.
    This permits the adaptation of the proposed structure to various scenarios, which
    would necessitate various environments, datasets, or automation bits.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æ¿€åŠ¨äº†å—ï¼Ÿä»”ç»†æŸ¥çœ‹æµç¨‹ï¼Œä½ ä¼šå‘ç°æˆ‘ä»¬ä»é›¶å¼€å§‹ã€‚è¿™å…è®¸å°†æå‡ºçš„ç»“æ„é€‚åº”å„ç§åœºæ™¯ï¼Œè¿™äº›åœºæ™¯éœ€è¦ä¸åŒçš„ç¯å¢ƒã€æ•°æ®é›†æˆ–è‡ªåŠ¨åŒ–å·¥å…·ã€‚
- en: 'Let us now go a bit deeper. Let us imagine we own a house in the Netherlands
    (It can be close to the University of Twente), and we would like to understand
    the surrounding area better. That is our starting point. Now, to better grasp
    the relationship of our house to the surrounding, some questions arise: how dense
    is the built area of the neighborhood? Can the house be subject to flooding? Am
    I respecting the built ratio for the parcel I own?'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬æ›´æ·±å…¥ä¸€ç‚¹ã€‚å‡è®¾æˆ‘ä»¬åœ¨è·å…°æ‹¥æœ‰ä¸€æ‰€æˆ¿å­ï¼ˆå¯ä»¥é è¿‘ç‰¹æ–‡ç‰¹å¤§å­¦ï¼‰ï¼Œæˆ‘ä»¬æƒ³æ›´å¥½åœ°äº†è§£å‘¨å›´çš„åŒºåŸŸã€‚è¿™æ˜¯æˆ‘ä»¬çš„èµ·ç‚¹ã€‚ç°åœ¨ï¼Œä¸ºäº†æ›´å¥½åœ°ç†è§£æˆ‘ä»¬æˆ¿å­ä¸å‘¨å›´ç¯å¢ƒçš„å…³ç³»ï¼Œå‡ºç°äº†ä¸€äº›é—®é¢˜ï¼šé‚»é‡Œå»ºç­‘åŒºçš„å¯†åº¦æœ‰å¤šé«˜ï¼Ÿæˆ¿å­æ˜¯å¦å¯èƒ½é¢ä¸´æ´ªæ°´ï¼Ÿæˆ‘æ˜¯å¦éµå®ˆäº†æˆ‘æ‰€æ‹¥æœ‰åœ°å—çš„å»ºç­‘æ¯”ä¾‹ï¼Ÿ
- en: How should we go around and answer these questions? Should we look on the internet?
    Should we open a map? Should we call the cadastral services? Let's work around
    that together and simultaneously unlock a new robust set of skills in this context.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åº”è¯¥å¦‚ä½•è§£å†³è¿™äº›é—®é¢˜ï¼Ÿæˆ‘ä»¬æ˜¯å¦åº”è¯¥ä¸Šç½‘æŸ¥æ‰¾ï¼Ÿæ˜¯å¦åº”è¯¥æ‰“å¼€åœ°å›¾ï¼Ÿæ˜¯å¦åº”è¯¥è”ç³»æµ‹ç»˜æœåŠ¡ï¼Ÿè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢è¿™ä¸ªè¿‡ç¨‹ï¼ŒåŒæ—¶åœ¨è¿™ä¸ªèƒŒæ™¯ä¸‹è§£é”ä¸€å¥—æ–°çš„å¼ºå¤§æŠ€èƒ½ã€‚
- en: 'In the following, we detail the four steps that allow answering these questions:
    the first step covers the ideal environment setup. Secondly, we get our hands
    on 3D point clouds and city models as meshes of an area of interest. Then, we
    create a 3D Python notebook with a high focus on automation. Finally, we create
    a set of Python functions to answer the challenging scenarios. Okay, let us arm
    ourselves with coffee or tea ğŸµ and dive into finding answers to these interrogations!'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„å†…å®¹ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†å›ç­”è¿™äº›é—®é¢˜çš„å››ä¸ªæ­¥éª¤ï¼šç¬¬ä¸€æ­¥æ˜¯ç†æƒ³çš„ç¯å¢ƒè®¾ç½®ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬è·å–3Dç‚¹äº‘å’Œä½œä¸ºæ„Ÿå…´è¶£åŒºåŸŸç½‘æ ¼çš„åŸå¸‚æ¨¡å‹ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªé«˜åº¦å…³æ³¨è‡ªåŠ¨åŒ–çš„3D
    Pythonç¬”è®°æœ¬ã€‚æœ€åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€å¥—Pythonå‡½æ•°ä»¥åº”å¯¹å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚å¥½äº†ï¼Œè®©æˆ‘ä»¬æ‹¿èµ·å’–å•¡æˆ–èŒ¶ğŸµï¼Œæ·±å…¥å¯»æ‰¾è¿™äº›é—®é¢˜çš„ç­”æ¡ˆå§ï¼
- en: 'ğŸ¦š **Note**: *I designed the next series of actions to be easy to follow linearly
    without needing coding skills or available data. Nevertheless, if you are an experienced
    coder, I provided helpful optimization tricks on crucial tasks to ensure code
    performance is at its peak!*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*æˆ‘è®¾è®¡äº†ä¸‹ä¸€ç³»åˆ—æ“ä½œï¼Œä½¿å…¶æ˜“äºçº¿æ€§è·Ÿéšï¼Œæ— éœ€ç¼–ç æŠ€èƒ½æˆ–å¯ç”¨æ•°æ®ã€‚ç„¶è€Œï¼Œå¦‚æœä½ æ˜¯ç»éªŒä¸°å¯Œçš„ç¼–ç äººå‘˜ï¼Œæˆ‘æä¾›äº†æœ‰ç”¨çš„ä¼˜åŒ–æŠ€å·§ï¼Œä»¥ç¡®ä¿ä»£ç æ€§èƒ½è¾¾åˆ°å·…å³°ï¼*
- en: 'Step 1: 3D Environment Set-up'
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥ï¼š3D ç¯å¢ƒè®¾ç½®
- en: Before making our hands dirty with code and 3D thoughts, a good practice is
    to ensure we work in a proper environment. We do not cook on a dirty countertop
    with dull knives and outdated food (or at least we avoid ğŸ˜)! Let us follow the
    three sub-steps as illustrated below.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹åŠ¨æ‰‹ç¼–å†™ä»£ç å’Œè¿›è¡Œ 3D æ€è€ƒä¹‹å‰ï¼Œä¸€ä¸ªå¥½çš„åšæ³•æ˜¯ç¡®ä¿æˆ‘ä»¬åœ¨é€‚å½“çš„ç¯å¢ƒä¸­å·¥ä½œã€‚æˆ‘ä»¬ä¸ä¼šåœ¨è‚®è„çš„å°é¢ä¸Šç”¨é’åˆ€å’Œè¿‡æœŸçš„é£Ÿæåšé¥­ï¼ˆæˆ–è€…è‡³å°‘æˆ‘ä»¬ä¼šé¿å… ğŸ˜ï¼‰ï¼è®©æˆ‘ä»¬éµå¾ªä¸‹é¢æ‰€ç¤ºçš„ä¸‰ä¸ªå­æ­¥éª¤ã€‚
- en: '![](../Images/d2e39d1775e3819afe4a4b05635da305.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2e39d1775e3819afe4a4b05635da305.png)'
- en: 'Step 1: 3D Environment Set-up.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥ï¼š3D ç¯å¢ƒè®¾ç½®ã€‚
- en: 1\. 1\. The software stack
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 1\. è½¯ä»¶å †æ ˆ
- en: 'To get things going, let us first install a 3D point cloud and mesh processing
    software: CloudCompare. It is a marvelous tool that permits to efficiently handle
    the scientific analysis of point cloud data (but not only). It is an essential
    cog in any iterative experiment where you want to quickly get a data-driven idea
    about the feasibility of a theory, for example.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¼€å§‹ï¼Œè®©æˆ‘ä»¬é¦–å…ˆå®‰è£…ä¸€ä¸ª 3D ç‚¹äº‘å’Œç½‘æ ¼å¤„ç†è½¯ä»¶ï¼šCloudCompareã€‚å®ƒæ˜¯ä¸€ä¸ªå‡ºè‰²çš„å·¥å…·ï¼Œå…è®¸æœ‰æ•ˆåœ°å¤„ç†ç‚¹äº‘æ•°æ®çš„ç§‘å­¦åˆ†æï¼ˆä½†ä¸é™äºæ­¤ï¼‰ã€‚å®ƒæ˜¯ä»»ä½•è¿­ä»£å®éªŒä¸­çš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†ï¼Œä¾‹å¦‚ï¼Œå½“ä½ æƒ³å¿«é€Ÿè·å¾—å…³äºç†è®ºå¯è¡Œæ€§çš„æ•°æ®é©±åŠ¨æƒ³æ³•æ—¶ã€‚
- en: To get the CloudCompare software, you can go to the download section of [CloudCompare.org](https://cloudcompare.org/)
    and get the latest stable release for your OS, as illustrated below.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è·å– CloudCompare è½¯ä»¶ï¼Œä½ å¯ä»¥å‰å¾€ [CloudCompare.org](https://cloudcompare.org/) çš„ä¸‹è½½éƒ¨åˆ†ï¼Œè·å–é€‚åˆä½ æ“ä½œç³»ç»Ÿçš„æœ€æ–°ç¨³å®šç‰ˆï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/22b4cf7d7ef80b3b341e8aaeebaee4aa.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22b4cf7d7ef80b3b341e8aaeebaee4aa.png)'
- en: Downloading CloudCompare from [https://cloudcompare.org/](https://cloudcompare.org/)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä» [https://cloudcompare.org/](https://cloudcompare.org/) ä¸‹è½½ CloudCompare
- en: 'After downloading the software, follow the linear installation steps to get
    to a working software that you can open, which should look similar to the following
    GUI upon launch:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½è½¯ä»¶åï¼ŒæŒ‰ç…§çº¿æ€§å®‰è£…æ­¥éª¤æ“ä½œï¼Œç›´åˆ°è·å¾—å¯ä»¥æ‰“å¼€çš„å·¥ä½œè½¯ä»¶ï¼Œå¯åŠ¨æ—¶ç•Œé¢åº”ç±»ä¼¼äºä»¥ä¸‹ GUIï¼š
- en: '![](../Images/78d2d6aca43e0ca4a55ee2ca7be1797e.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/78d2d6aca43e0ca4a55ee2ca7be1797e.png)'
- en: CloudCompare GUI.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: CloudCompare GUIã€‚
- en: Then, we want to get a Python Distribution that allows us to focus on the actual
    code. It is called Anaconda, and it is available on various platforms from [Anaconda.com](https://www.anaconda.com/).
    Once you download the software that matches your OS, you can install it. A GUI
    is provided (Anaconda Navigator) that you can launch to get up and running quickly,
    as shown below..
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¸Œæœ›è·å¾—ä¸€ä¸ªå…è®¸æˆ‘ä»¬ä¸“æ³¨äºå®é™…ä»£ç çš„ Python å‘è¡Œç‰ˆã€‚å®ƒè¢«ç§°ä¸º Anacondaï¼Œå¯ä»¥åœ¨å„ç§å¹³å°ä¸Šä» [Anaconda.com](https://www.anaconda.com/)
    è·å¾—ã€‚ä¸‹è½½ä¸æ‚¨çš„æ“ä½œç³»ç»ŸåŒ¹é…çš„è½¯ä»¶åï¼Œæ‚¨å¯ä»¥è¿›è¡Œå®‰è£…ã€‚æä¾›äº†ä¸€ä¸ª GUIï¼ˆAnaconda Navigatorï¼‰ï¼Œæ‚¨å¯ä»¥å¯åŠ¨å®ƒä»¥å¿«é€Ÿå¼€å§‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/0de35f78f0fcbacebf630f4eb0510aea.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0de35f78f0fcbacebf630f4eb0510aea.png)'
- en: This is the Anaconda Navigator GUI that allows you to manage independent Python
    Environments for your future experiments.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ Anaconda Navigator GUIï¼Œå…è®¸ä½ ç®¡ç†æœªæ¥å®éªŒçš„ç‹¬ç«‹ Python ç¯å¢ƒã€‚
- en: Using the GUI Anaconda Navigator, go to the â€œ`Environments`â€ Tab on the left.
    We then create a brand new isolated Python environment by clicking on â€œ`Create`â€
    as shown below.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GUI Anaconda Navigatorï¼Œè½¬åˆ°å·¦ä¾§çš„â€œ`ç¯å¢ƒ`â€æ ‡ç­¾ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ç‚¹å‡»â€œ`åˆ›å»º`â€æ¥åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„éš”ç¦» Python ç¯å¢ƒï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/af87f918dfe6a994ed3653fc37485d0d.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af87f918dfe6a994ed3653fc37485d0d.png)'
- en: In Anaconda Navigator, you have four tabs on the left side. In the Home Tab,
    you will find the IDE at your disposal in a specific environment; in the â€œEnvironmentsâ€
    tab, you can create, manage, and select any environment.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Anaconda Navigator ä¸­ï¼Œä½ çš„å·¦ä¾§æœ‰å››ä¸ªæ ‡ç­¾ã€‚åœ¨â€œé¦–é¡µâ€æ ‡ç­¾ä¸­ï¼Œä½ ä¼šå‘ç° IDE å¤„äºç‰¹å®šç¯å¢ƒä¸­ï¼›åœ¨â€œç¯å¢ƒâ€æ ‡ç­¾ä¸­ï¼Œä½ å¯ä»¥åˆ›å»ºã€ç®¡ç†å’Œé€‰æ‹©ä»»ä½•ç¯å¢ƒã€‚
- en: This will allow us to manage better some Python â€œlibrariesâ€ we want to install
    (Step 1.3) while avoiding version conflicts.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´å¥½åœ°ç®¡ç†ä¸€äº›æˆ‘ä»¬æƒ³è¦å®‰è£…çš„ Python â€œåº“â€ï¼ˆç¬¬ 1.3 æ­¥ï¼‰ï¼ŒåŒæ—¶é¿å…ç‰ˆæœ¬å†²çªã€‚
- en: 'ğŸ¦š **Note**: *For this tutorial, we chose a Python version of 3.9.16, as shown
    above. Once you created an environment and after clicking on it, you can see a
    â€œplayâ€ icon next to its name. This opens the possibility of launching an* ***Anaconda
    Terminal*** *directly acting in the selected environment.* ***This is the go-to
    way to install libraries or IDEs in this environment****.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*å¯¹äºæœ¬æ•™ç¨‹ï¼Œæˆ‘ä»¬é€‰æ‹©äº† Python ç‰ˆæœ¬ 3.9.16ï¼Œå¦‚ä¸Šæ‰€ç¤ºã€‚åˆ›å»ºç¯å¢ƒåï¼Œç‚¹å‡»å®ƒï¼Œä½ ä¼šçœ‹åˆ°å…¶åç§°æ—è¾¹æœ‰ä¸€ä¸ªâ€œæ’­æ”¾â€å›¾æ ‡ã€‚è¿™å°†å¼€å¯ç›´æ¥åœ¨æ‰€é€‰ç¯å¢ƒä¸­å¯åŠ¨*
    ***Anaconda Terminal*** *çš„å¯èƒ½æ€§ã€‚***è¿™æ˜¯åœ¨æ­¤ç¯å¢ƒä¸­å®‰è£…åº“æˆ– IDE çš„é¦–é€‰æ–¹å¼****ã€‚*
- en: If you have a working Anaconda Navigator and a new environment created, we are
    ready to choose a way to code, intending to be more efficient than a text editor.
    ğŸ˜
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å·²ç»æœ‰ä¸€ä¸ªå·¥ä½œä¸­çš„ Anaconda Navigator å’Œä¸€ä¸ªæ–°åˆ›å»ºçš„ç¯å¢ƒï¼Œæˆ‘ä»¬å°±å¯ä»¥é€‰æ‹©ä¸€ç§ç¼–ç æ–¹å¼ï¼Œæ—¨åœ¨æ¯”æ–‡æœ¬ç¼–è¾‘å™¨æ›´é«˜æ•ˆã€‚ğŸ˜
- en: 1.2\. The Python IDE
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2\. Python IDE
- en: A Python IDE (Integrated Development Environment) is a software application
    that provides a comprehensive set of tools for developing, testing, and debugging
    Python code. They offer an all-in-one environment where we can write, edit, and
    execute code, manage project files, track changes, and collaborate with other
    developers. Some popular Desktop Python IDEs include PyCharm, Visual Studio Code,
    and Spyder, each offering unique features and capabilities to suit different programming
    needs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Python IDEï¼ˆé›†æˆå¼€å‘ç¯å¢ƒï¼‰æ˜¯ä¸€ç§è½¯ä»¶åº”ç”¨ç¨‹åºï¼Œæä¾›äº†ä¸€æ•´å¥—ç”¨äºå¼€å‘ã€æµ‹è¯•å’Œè°ƒè¯• Python ä»£ç çš„å·¥å…·ã€‚å®ƒä»¬æä¾›äº†ä¸€ä¸ªä¸€ä½“åŒ–çš„ç¯å¢ƒï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å…¶ä¸­ç¼–å†™ã€ç¼–è¾‘å’Œæ‰§è¡Œä»£ç ï¼Œç®¡ç†é¡¹ç›®æ–‡ä»¶ï¼Œè·Ÿè¸ªæ›´æ”¹ï¼Œå¹¶ä¸å…¶ä»–å¼€å‘äººå‘˜åä½œã€‚ä¸€äº›æµè¡Œçš„æ¡Œé¢
    Python IDE åŒ…æ‹¬ PyCharmã€Visual Studio Code å’Œ Spyderï¼Œæ¯ä¸ª IDE éƒ½æä¾›äº†é€‚åº”ä¸åŒç¼–ç¨‹éœ€æ±‚çš„ç‹¬ç‰¹åŠŸèƒ½å’Œèƒ½åŠ›ã€‚
- en: 'Today, I want to highlight a great â€œweb-basedâ€ IDE: JupyterLab. One of the
    main benefits of JupyterLab is its notebook interface, which provides a visual,
    interactive environment for working with code. It makes it easy to create, edit,
    and run code cells in real time without switching between different windows or
    applications. Additionally, JupyterLab supports a wide range of data visualization
    tools, making it an excellent choice for working with any geodata science or 3D
    machine learning project.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä»Šå¤©ï¼Œæˆ‘æƒ³é‡ç‚¹ä»‹ç»ä¸€ä¸ªå‡ºè‰²çš„â€œåŸºäºç½‘ç»œâ€çš„ IDEï¼šJupyterLabã€‚JupyterLab çš„ä¸»è¦ä¼˜ç‚¹ä¹‹ä¸€æ˜¯å…¶ç¬”è®°æœ¬ç•Œé¢ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªå¯è§†åŒ–çš„ã€äº’åŠ¨çš„ç¼–ç¨‹ç¯å¢ƒã€‚å®ƒä½¿å¾—å®æ—¶åˆ›å»ºã€ç¼–è¾‘å’Œè¿è¡Œä»£ç å•å…ƒå˜å¾—ç®€å•ï¼Œè€Œæ— éœ€åœ¨ä¸åŒçª—å£æˆ–åº”ç”¨ç¨‹åºä¹‹é—´åˆ‡æ¢ã€‚æ­¤å¤–ï¼ŒJupyterLab
    æ”¯æŒå¹¿æ³›çš„æ•°æ®å¯è§†åŒ–å·¥å…·ï¼Œæ˜¯å¤„ç†ä»»ä½•åœ°ç†æ•°æ®ç§‘å­¦æˆ– 3D æœºå™¨å­¦ä¹ é¡¹ç›®çš„ç»ä½³é€‰æ‹©ã€‚
- en: '![](../Images/11bbac3dd2b3dbf60e7b3f3a15fd2f2f.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11bbac3dd2b3dbf60e7b3f3a15fd2f2f.png)'
- en: JupyterLab IDE for 3D Python.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: JupyterLab IDE ç”¨äº 3D Pythonã€‚
- en: JupyterLabâ€™s intuitive interface, robust feature set, and support for multiple
    programming languages make it a popular choice for Python developers of all skill
    levels.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: JupyterLab ç›´è§‚çš„ç•Œé¢ã€å¼ºå¤§çš„åŠŸèƒ½é›†ä»¥åŠå¯¹å¤šç§ç¼–ç¨‹è¯­è¨€çš„æ”¯æŒï¼Œä½¿å…¶æˆä¸ºå„ä¸ªæŠ€èƒ½æ°´å¹³çš„ Python å¼€å‘äººå‘˜çš„çƒ­é—¨é€‰æ‹©ã€‚
- en: 'ğŸ¦š **Note**: *JupyterLab IDE also offers support for multiple programming languages,
    including Python, R, and Julia, allowing one to work with various tools and libraries
    within a single environment. And this is massively cool, as R and Julia are lovely
    languages.*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*JupyterLab IDE è¿˜æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€ï¼ŒåŒ…æ‹¬ Pythonã€R å’Œ Juliaï¼Œå…è®¸åœ¨ä¸€ä¸ªç¯å¢ƒä¸­ä½¿ç”¨å„ç§å·¥å…·å’Œåº“ã€‚è¿™éå¸¸é…·ï¼Œå› ä¸º
    R å’Œ Julia æ˜¯å¾ˆæ£’çš„è¯­è¨€ã€‚*
- en: Before being able to use JupyterLab, we need to install it in our current Anaconda
    Environment. As mentioned before, we have to open the Anaconda Terminal in the
    environment of choice (ITC in our case). To achieve this with Anaconda Navigator,
    from your selected environment, (1) click on the green arrow, (2) select *â€œ*`Open
    Terminal`*â€* as shown below*.*
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨èƒ½å¤Ÿä½¿ç”¨ JupyterLab ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å½“å‰ Anaconda ç¯å¢ƒä¸­å®‰è£…å®ƒã€‚å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨æ‰€é€‰ç¯å¢ƒä¸­æ‰“å¼€ Anaconda Terminalï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯
    ITCï¼‰ã€‚è¦é€šè¿‡ Anaconda Navigator å®ç°è¿™ä¸€ç‚¹ï¼Œä»ä½ é€‰æ‹©çš„ç¯å¢ƒä¸­ï¼Œï¼ˆ1ï¼‰ç‚¹å‡»ç»¿è‰²ç®­å¤´ï¼Œï¼ˆ2ï¼‰é€‰æ‹© *â€œ*`Open Terminal`*â€*ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚*
- en: '![](../Images/3ab8549967e0a486f8d32c8a1b6afef4.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3ab8549967e0a486f8d32c8a1b6afef4.png)'
- en: How to install dependencies on the current environment.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•åœ¨å½“å‰ç¯å¢ƒä¸­å®‰è£…ä¾èµ–ã€‚
- en: 'In the console (Anaconda Terminal) that opens, write the following line: `conda
    install -c conda-forge jupyterlab`, and press â€œ`Enter`â€. This will install JupyterLab
    directly.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰“å¼€çš„æ§åˆ¶å°ï¼ˆAnaconda Terminalï¼‰ä¸­ï¼Œè¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼š`conda install -c conda-forge jupyterlab`ï¼Œç„¶åæŒ‰â€œ`Enter`â€ã€‚è¿™å°†ç›´æ¥å®‰è£…
    JupyterLabã€‚
- en: '![](../Images/302aec290a29f80cbf63ec1609280c43.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/302aec290a29f80cbf63ec1609280c43.png)'
- en: The command line is executed in the Anaconda Terminal (we see that we are in
    the (ITC) environment).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å‘½ä»¤è¡Œåœ¨ Anaconda Terminal ä¸­æ‰§è¡Œï¼ˆæˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬åœ¨ï¼ˆITCï¼‰ç¯å¢ƒä¸­ï¼‰ã€‚
- en: Note that it may ask for your approval to install some needed library, which
    you need to accept by typing `y` followed by pressing the key â€œ`Enter`â€.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå®ƒå¯èƒ½ä¼šè¦æ±‚ä½ ç¡®è®¤å®‰è£…ä¸€äº›éœ€è¦çš„åº“ï¼Œä½ éœ€è¦é€šè¿‡è¾“å…¥`y`å¹¶æŒ‰ä¸‹â€œ`Enter`â€é”®æ¥æ¥å—ã€‚
- en: '![](../Images/aecfb0e6f732cc0b0b1d8d0c1c85d1b9.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aecfb0e6f732cc0b0b1d8d0c1c85d1b9.png)'
- en: After 30+ seconds, the installation needs our approval. type â€˜`y`â€™ and press
    `Enter`. This will download, extract and install the libraries mentioned above.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç»è¿‡30å¤šç§’åï¼Œå®‰è£…éœ€è¦æˆ‘ä»¬çš„ç¡®è®¤ã€‚è¾“å…¥â€˜`y`â€™å¹¶æŒ‰`Enter`é”®ã€‚è¿™å°†ä¸‹è½½ã€è§£å‹å¹¶å®‰è£…ä¸Šè¿°æåˆ°çš„åº“ã€‚
- en: Once the process is done, you have a JupyterLab IDE installed in your ITC Conda
    environment. Do not close the console; from there, we will test that everything
    works smoothly in four simple steps.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è¿‡ç¨‹å®Œæˆï¼Œä½ å°±æœ‰ä¸€ä¸ªå®‰è£…åœ¨ITC Condaç¯å¢ƒä¸­çš„JupyterLab IDEã€‚ä¸è¦å…³é—­æ§åˆ¶å°ï¼›ä»é‚£é‡Œï¼Œæˆ‘ä»¬å°†é€šè¿‡å››ä¸ªç®€å•çš„æ­¥éª¤æµ‹è¯•ä¸€åˆ‡æ˜¯å¦é¡ºåˆ©ã€‚
- en: '**Launch JupyterLab**: From the same console, you can launch JupyterLab by
    writing the command: â€œ`jupyter lab`â€. This will automatically open the JupyterLab
    interface in your default web browser.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å¯åŠ¨JupyterLab**ï¼šåœ¨ç›¸åŒçš„æ§åˆ¶å°ä¸­ï¼Œä½ å¯ä»¥é€šè¿‡è¾“å…¥å‘½ä»¤ï¼šâ€œ`jupyter lab`â€æ¥å¯åŠ¨JupyterLabã€‚è¿™å°†è‡ªåŠ¨åœ¨é»˜è®¤ç½‘é¡µæµè§ˆå™¨ä¸­æ‰“å¼€JupyterLabç•Œé¢ã€‚'
- en: '**Create a new notebook**: To create a new notebook (where we want to write
    code), click on the â€œ`File`â€ menu in the top-left corner of the JupyterLab interface
    and select â€œ`New Notebook`.â€ This will open a new notebook in a new tab.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åˆ›å»ºä¸€ä¸ªæ–°çš„ç¬”è®°æœ¬**ï¼šè¦åˆ›å»ºä¸€ä¸ªæ–°çš„ç¬”è®°æœ¬ï¼ˆæˆ‘ä»¬åœ¨å…¶ä¸­ç¼–å†™ä»£ç ï¼‰ï¼Œè¯·ç‚¹å‡»JupyterLabç•Œé¢å·¦ä¸Šè§’çš„â€œ`æ–‡ä»¶`â€èœå•ï¼Œå¹¶é€‰æ‹©â€œ`æ–°å»ºç¬”è®°æœ¬`â€ã€‚è¿™å°†ä¼šåœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€ä¸€ä¸ªæ–°çš„ç¬”è®°æœ¬ã€‚'
- en: '**Write code**: You can now start writing code in the notebook. To create a
    new code cell, click the â€œ`+`â€ button in the toolbar or press â€œ`Ctrl + Shift +
    Enter`.â€ You can then write your Python code (E.g. : `â€˜This is workingâ€™` in the
    cell and run it by pressing â€œ`Shift + Enter`.â€'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ç¼–å†™ä»£ç **ï¼šç°åœ¨ä½ å¯ä»¥åœ¨ç¬”è®°æœ¬ä¸­å¼€å§‹ç¼–å†™ä»£ç ã€‚è¦åˆ›å»ºä¸€ä¸ªæ–°çš„ä»£ç å•å…ƒæ ¼ï¼Œè¯·ç‚¹å‡»å·¥å…·æ ä¸­çš„â€œ`+`â€æŒ‰é’®æˆ–æŒ‰â€œ`Ctrl + Shift + Enter`â€ã€‚ç„¶åä½ å¯ä»¥åœ¨å•å…ƒæ ¼ä¸­ç¼–å†™Pythonä»£ç ï¼ˆä¾‹å¦‚ï¼š`â€˜This
    is workingâ€™`ï¼‰ï¼Œå¹¶é€šè¿‡æŒ‰â€œ`Shift + Enter`â€è¿è¡Œå®ƒã€‚'
- en: '**Save your work**: Remember to save your work regularly by clicking the â€œ`Save`â€
    button in the toolbar or using the â€œ`Ctrl + S`â€ keyboard shortcut.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¿å­˜ä½ çš„å·¥ä½œ**ï¼šè®°å¾—å®šæœŸä¿å­˜ä½ çš„å·¥ä½œï¼Œé€šè¿‡ç‚¹å‡»å·¥å…·æ ä¸­çš„â€œ`ä¿å­˜`â€æŒ‰é’®æˆ–ä½¿ç”¨â€œ`Ctrl + S`â€é”®ç›˜å¿«æ·é”®æ¥ä¿å­˜ã€‚'
- en: These are the basic steps to get started with JupyterLab. As you become more
    familiar with the interface, you can explore more advanced features, such as adding
    markdown text, importing and exporting data, and working with JupyterLab extensions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯å¼€å§‹ä½¿ç”¨JupyterLabçš„åŸºæœ¬æ­¥éª¤ã€‚éšç€ä½ å¯¹ç•Œé¢çš„ç†Ÿæ‚‰ï¼Œä½ å¯ä»¥æ¢ç´¢æ›´å¤šé«˜çº§åŠŸèƒ½ï¼Œå¦‚æ·»åŠ Markdownæ–‡æœ¬ã€å¯¼å…¥å’Œå¯¼å‡ºæ•°æ®ä»¥åŠä½¿ç”¨JupyterLabæ‰©å±•ã€‚
- en: 'ğŸ¦š **Note**: *For students at ITC â€” University of Twente, we have the luck to
    have the* [***CRIB: A Geospatial Computing Platform***](https://crib.utwente.nl/)
    *using Jupyter Lab. I highly recommend using this cloud computing service if your
    computer shows some processing limitations while following this course.*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦š **æ³¨æ„**ï¼š*å¯¹äºITCâ€”ç‰¹æ¸©ç‰¹å¤§å­¦çš„å­¦ç”Ÿï¼Œæˆ‘ä»¬å¾ˆå¹¸è¿èƒ½ä½¿ç”¨* [***CRIB: A Geospatial Computing Platform***](https://crib.utwente.nl/)
    *è¿›è¡ŒJupyter Labã€‚ å¦‚æœä½ çš„è®¡ç®—æœºåœ¨è·Ÿéšæœ¬è¯¾ç¨‹æ—¶æ˜¾ç¤ºå‡ºæŸäº›å¤„ç†é™åˆ¶ï¼Œæˆ‘å¼ºçƒˆæ¨èä½¿ç”¨è¿™ä¸ªäº‘è®¡ç®—æœåŠ¡ã€‚*'
- en: 1.3\. 3D Python Libraries
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3\. 3D Pythonåº“
- en: For this tutorial, I will introduce five libraries that are key to 3D Geospatial
    Analysis. These are `NumPy`, `Pandas`, `Open3D`, `Matplotlib,` and `Shapely`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘å°†ä»‹ç»äº”ä¸ªå¯¹3Dåœ°ç†ç©ºé—´åˆ†æè‡³å…³é‡è¦çš„åº“ã€‚è¿™äº›åº“æ˜¯`NumPy`ã€`Pandas`ã€`Open3D`ã€`Matplotlib`å’Œ`Shapely`ã€‚
- en: 'ğŸ¦š **Note**: i*f you want to use the mentioned libraries, we must ensure they
    are installed and available in your environment. Therefore, in the same environment
    terminal, we use the formula* â€œ`pip install package-name==version`â€ *(the* `==version`
    *is optional to fix certain versions) as follows:*'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*å¦‚æœä½ æƒ³ä½¿ç”¨ä¸Šè¿°åº“ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿å®ƒä»¬åœ¨ä½ çš„ç¯å¢ƒä¸­å·²å®‰è£…å¹¶å¯ç”¨ã€‚å› æ­¤ï¼Œåœ¨ç›¸åŒçš„ç¯å¢ƒç»ˆç«¯ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¬å¼* â€œ`pip install
    package-name==version`â€ *(å…¶ä¸­`==version`æ˜¯å¯é€‰çš„ï¼Œç”¨äºå›ºå®šæŸäº›ç‰ˆæœ¬)ï¼Œå¦‚ä¸‹é¢æ‰€ç¤ºï¼š*
- en: '![](../Images/9265d7a29ec28a42dda3e94ef33194e0.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9265d7a29ec28a42dda3e94ef33194e0.png)'
- en: '[PRE0]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**NumPy**: This library is used for working with arrays and matrices. It provides
    fast and efficient operations on large, multi-dimensional arrays, making it a
    powerful tool for scientific computing and data analysis. One hands-on example
    of how to use `NumPy` is to create a point cloud as a set of data points in the
    3D euclidean space. To do this, you can create a NumPy array with three columns,
    where each row represents a single point in the point cloud:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**NumPy**ï¼šè¿™ä¸ªåº“ç”¨äºå¤„ç†æ•°ç»„å’ŒçŸ©é˜µã€‚å®ƒæä¾›äº†å¯¹å¤§å‹å¤šç»´æ•°ç»„çš„å¿«é€Ÿé«˜æ•ˆæ“ä½œï¼Œä½¿å…¶æˆä¸ºç§‘å­¦è®¡ç®—å’Œæ•°æ®åˆ†æçš„å¼ºå¤§å·¥å…·ã€‚ä¸€ä¸ªä½¿ç”¨`NumPy`çš„å®é™…ç¤ºä¾‹æ˜¯åˆ›å»ºä¸€ä¸ªç‚¹äº‘ï¼Œå°†å…¶ä½œä¸º3Dæ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­çš„æ•°æ®ç‚¹é›†åˆã€‚ä¸ºæ­¤ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ä¸ªå…·æœ‰ä¸‰åˆ—çš„NumPyæ•°ç»„ï¼Œæ¯ä¸€è¡Œè¡¨ç¤ºç‚¹äº‘ä¸­çš„ä¸€ä¸ªç‚¹ï¼š'
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this example, the point cloud has three points with coordinates `(1, 2, 3),
    (4, 5, 6)`, and `(7, 8, 9)`, respectively. Easy, Peasy, you said? ğŸ˜
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œç‚¹äº‘åŒ…å«ä¸‰ä¸ªåæ ‡ä¸º`(1, 2, 3)`ã€`(4, 5, 6)`å’Œ`(7, 8, 9)`çš„ç‚¹ã€‚ç®€å•å§ï¼Œä½ è¯´ï¼ŸğŸ˜
- en: '**Pandas**: This library is more geared towards data manipulation and analysis.
    It provides robust data structures and tools for working with structured data,
    such as CSV files, spreadsheets, and databases. While itâ€™s not specifically designed
    for 3D data processing, it can still be used to write and access point clouds
    in a tabular format. To do this, you can create a DataFrame object with columns
    representing the X, Y, and Z coordinates of each point:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pandas**ï¼šè¿™ä¸ªåº“æ›´ä¾§é‡äºæ•°æ®æ“ä½œå’Œåˆ†æã€‚å®ƒæä¾›äº†å¼ºå¤§çš„æ•°æ®ç»“æ„å’Œå·¥å…·ï¼Œç”¨äºå¤„ç†ç»“æ„åŒ–æ•°æ®ï¼Œä¾‹å¦‚ CSV æ–‡ä»¶ã€ç”µå­è¡¨æ ¼å’Œæ•°æ®åº“ã€‚è™½ç„¶å®ƒå¹¶ä¸æ˜¯ä¸“é—¨ä¸º
    3D æ•°æ®å¤„ç†è®¾è®¡çš„ï¼Œä½†ä»å¯ä»¥ç”¨æ¥ä»¥è¡¨æ ¼æ ¼å¼è¯»å†™ç‚¹äº‘ã€‚ä¸ºæ­¤ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ä¸ª DataFrame å¯¹è±¡ï¼Œå…¶ä¸­åˆ—è¡¨ç¤ºæ¯ä¸ªç‚¹çš„ Xã€Y å’Œ Z åæ ‡ï¼š'
- en: '[PRE2]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, the point cloud has three points with coordinates `(1, 2, 3)`,
    `(4, 5, 6)`, and `(7, 8, 9)`, as obtained with NumPy. The DataFrame is then saved
    to a CSV file using the `to_csv` function.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œç‚¹äº‘åŒ…å«ä¸‰ä¸ªåæ ‡ä¸º`(1, 2, 3)`ã€`(4, 5, 6)`å’Œ`(7, 8, 9)`çš„ç‚¹ï¼Œå¦‚ä½¿ç”¨ NumPy è·å¾—çš„ã€‚ç„¶åï¼ŒDataFrame
    ä½¿ç”¨ `to_csv` å‡½æ•°ä¿å­˜åˆ° CSV æ–‡ä»¶ä¸­ã€‚
- en: 'ğŸ¦š **Note**: *Pandas can be extended with another Python module:* [***Geopandas***](https://geopandas.org/)*.
    This library makes it possible to directly work with spatial data stored e.g.
    in Shapefiles or PostGIS database. This extends the scope of the current tutorial,
    but it is good to know because we will surely use it in other cases.* ğŸ˜‰'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*Pandas å¯ä»¥é€šè¿‡å¦ä¸€ä¸ª Python æ¨¡å—è¿›è¡Œæ‰©å±•ï¼š* [***Geopandas***](https://geopandas.org/)*ã€‚è¿™ä¸ªåº“ä½¿å¾—å¯ä»¥ç›´æ¥å¤„ç†å­˜å‚¨åœ¨ä¾‹å¦‚
    Shapefiles æˆ– PostGIS æ•°æ®åº“ä¸­çš„ç©ºé—´æ•°æ®ã€‚è¿™æ‰©å±•äº†å½“å‰æ•™ç¨‹çš„èŒƒå›´ï¼Œä½†äº†è§£è¿™äº›å†…å®¹æ˜¯æœ‰ç›Šçš„ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨å…¶ä»–æƒ…å†µä¸‹è‚¯å®šä¼šç”¨åˆ°å®ƒã€‚* ğŸ˜‰
- en: '**Open3D**: This library is geared toward 3D data processing and visualization.
    It provides various tools and functions for working with point clouds, meshes,
    and other 3D data formats, such as voxels.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**Open3D**ï¼šè¿™ä¸ªåº“ä¸“æ³¨äº 3D æ•°æ®å¤„ç†å’Œå¯è§†åŒ–ã€‚å®ƒæä¾›äº†å„ç§å·¥å…·å’Œå‡½æ•°ï¼Œç”¨äºå¤„ç†ç‚¹äº‘ã€ç½‘æ ¼å’Œå…¶ä»– 3D æ•°æ®æ ¼å¼ï¼Œå¦‚ä½“ç´ ã€‚'
- en: 'ğŸ¦š **Note**: *A quick way to install the library is to run the Anaconda Environment
    Terminal the same way as before and type the following command:* `pip install
    open3d==0.16.0`, *which will install the version 0.16.0 of* [*Open3D*](http://www.open3d.org/)*,
    as used in this tutorial.*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*å¿«é€Ÿå®‰è£…è¯¥åº“çš„æ–¹æ³•æ˜¯è¿è¡Œ Anaconda ç¯å¢ƒç»ˆç«¯å¹¶è¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼š* `pip install open3d==0.16.0` *ï¼Œè¿™å°†å®‰è£…ç‰ˆæœ¬
    0.16.0 çš„* [*Open3D*](http://www.open3d.org/)*ï¼Œå¦‚æœ¬æ•™ç¨‹ä¸­ä½¿ç”¨çš„ç‰ˆæœ¬ã€‚*
- en: 'Now, back in the Jupyter Lab IDE, let us create a point cloud using built-in
    Open3D functions:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œåœ¨ Jupyter Lab IDE ä¸­ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨å†…ç½®çš„ Open3D å‡½æ•°åˆ›å»ºä¸€ä¸ªç‚¹äº‘ï¼š
- en: '[PRE3]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this example, the point cloud has the same three points with coordinates
    `(1, 2, 3)`, `(4, 5, 6)`, and `(7, 8, 9)`, respectively.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œç‚¹äº‘åŒ…å«ä¸‰ä¸ªå…·æœ‰åæ ‡`(1, 2, 3)`ã€`(4, 5, 6)`å’Œ`(7, 8, 9)`çš„ç‚¹ã€‚
- en: 'ğŸ¦š **Note**: *In the code block above, we created an Open3D PointCloud object
    and then* passed *the points list to the points attribute through the* `o3d.utility.Vector3dVector`
    *function that converts the list of points into a format that can be added to
    the point cloud object.*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*åœ¨ä¸Šé¢çš„ä»£ç å—ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª Open3D PointCloud å¯¹è±¡ï¼Œç„¶åé€šè¿‡* `o3d.utility.Vector3dVector`
    *å‡½æ•°å°†ç‚¹åˆ—è¡¨ä¼ é€’ç»™ points å±æ€§ï¼Œè¯¥å‡½æ•°å°†ç‚¹åˆ—è¡¨è½¬æ¢ä¸ºå¯ä»¥æ·»åŠ åˆ°ç‚¹äº‘å¯¹è±¡ä¸­çš„æ ¼å¼ã€‚*
- en: '**Matplotlib**: This library is used for data visualization. It provides many
    tools for creating high-quality charts, graphs, and other visualizations. While
    itâ€™s not specifically designed for 3D data visualization, it can still create
    3D scatter plots of point clouds. To do this, you can use the Axes3D class to
    create a 3D plot and the scatter function to plot the points:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**Matplotlib**ï¼šè¿™ä¸ªåº“ç”¨äºæ•°æ®å¯è§†åŒ–ã€‚å®ƒæä¾›äº†è®¸å¤šå·¥å…·ï¼Œç”¨äºåˆ›å»ºé«˜è´¨é‡çš„å›¾è¡¨ã€å›¾å½¢å’Œå…¶ä»–å¯è§†åŒ–å†…å®¹ã€‚è™½ç„¶å®ƒå¹¶ä¸æ˜¯ä¸“é—¨ä¸º 3D æ•°æ®å¯è§†åŒ–è®¾è®¡çš„ï¼Œä½†å®ƒä»ç„¶å¯ä»¥åˆ›å»ºç‚¹äº‘çš„
    3D æ•£ç‚¹å›¾ã€‚ä¸ºæ­¤ï¼Œä½ å¯ä»¥ä½¿ç”¨ Axes3D ç±»åˆ›å»º 3D å›¾ï¼Œå¹¶ä½¿ç”¨ scatter å‡½æ•°ç»˜åˆ¶ç‚¹ï¼š'
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this example, a point cloud with 1000 random points is generated using NumPy.
    The points are then plotted as a scatter plot in a 3D plot using the `scatter`
    function. Finally, the plot is displayed using the `show` function.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œä½¿ç”¨ NumPy ç”Ÿæˆäº†ä¸€ä¸ªåŒ…å« 1000 ä¸ªéšæœºç‚¹çš„ç‚¹äº‘ã€‚ç„¶åï¼Œä½¿ç”¨ `scatter` å‡½æ•°åœ¨ 3D å›¾ä¸­ç»˜åˆ¶è¿™äº›ç‚¹ã€‚æœ€åï¼Œä½¿ç”¨ `show`
    å‡½æ•°æ˜¾ç¤ºå›¾å½¢ã€‚
- en: '**Shapely**: This library is used mainly for 2D geometric operations to create,
    manipulate, and analyze geometric objects. It provides a wide range of tools for
    working with points, lines, polygons, and other geometric shapes. One common use
    case for `Shapely` is creating a polygon and checking if a point is within the
    polygon. To do this, you can create a Polygon object using a list of coordinates
    that define the polygon and then use the `contains` function to check if a point
    is within the polygon:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**Shapely**ï¼šè¿™ä¸ªåº“ä¸»è¦ç”¨äº2Då‡ ä½•æ“ä½œï¼Œç”¨äºåˆ›å»ºã€æ“ä½œå’Œåˆ†æå‡ ä½•å¯¹è±¡ã€‚å®ƒæä¾›äº†å¹¿æ³›çš„å·¥å…·æ¥å¤„ç†ç‚¹ã€çº¿ã€å¤šè¾¹å½¢å’Œå…¶ä»–å‡ ä½•å½¢çŠ¶ã€‚`Shapely`çš„ä¸€ä¸ªå¸¸è§ç”¨ä¾‹æ˜¯åˆ›å»ºä¸€ä¸ªå¤šè¾¹å½¢ï¼Œå¹¶æ£€æŸ¥ä¸€ä¸ªç‚¹æ˜¯å¦åœ¨å¤šè¾¹å½¢å†…ã€‚ä¸ºæ­¤ï¼Œä½ å¯ä»¥ä½¿ç”¨å®šä¹‰å¤šè¾¹å½¢çš„åæ ‡åˆ—è¡¨åˆ›å»ºä¸€ä¸ªPolygonå¯¹è±¡ï¼Œç„¶åä½¿ç”¨`contains`å‡½æ•°æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨å¤šè¾¹å½¢å†…ï¼š'
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This is just a simple example, but Shapely provides many other functions for
    working with geometric objects that can be useful for more complex applications.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œä½†Shapelyæä¾›äº†è®¸å¤šå…¶ä»–ç”¨äºå¤„ç†å‡ ä½•å¯¹è±¡çš„å‡½æ•°ï¼Œè¿™äº›å‡½æ•°å¯¹äºæ›´å¤æ‚çš„åº”ç”¨å¯èƒ½ä¼šå¾ˆæœ‰ç”¨ã€‚
- en: 'ğŸ¦š **Note**: *In this example, a polygon with four vertices is created using
    a list of coordinates. A point is then created using the* `Point` *function. Finally,
    the* `contains` *function is used to check if the point is within the polygon,
    and a message is printed to the console depending on the result of the check.*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä½¿ç”¨ä¸€ä¸ªåæ ‡åˆ—è¡¨åˆ›å»ºäº†ä¸€ä¸ªå…·æœ‰å››ä¸ªé¡¶ç‚¹çš„å¤šè¾¹å½¢ã€‚ç„¶åï¼Œä½¿ç”¨* `Point` *å‡½æ•°åˆ›å»ºä¸€ä¸ªç‚¹ã€‚æœ€åï¼Œä½¿ç”¨* `contains`
    *å‡½æ•°æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨å¤šè¾¹å½¢å†…ï¼Œå¹¶æ ¹æ®æ£€æŸ¥ç»“æœå°†æ¶ˆæ¯æ‰“å°åˆ°æ§åˆ¶å°ã€‚*
- en: Our first step in this 3D Workflow for 3D City Modeling is a clever combination
    of simple yet effective and proven tools and libraries, visually summarized below.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ª3DåŸå¸‚å»ºæ¨¡çš„å·¥ä½œæµç¨‹ä¸­ï¼Œæˆ‘ä»¬çš„ç¬¬ä¸€æ­¥æ˜¯å·§å¦™åœ°ç»“åˆç®€å•è€Œæœ‰æ•ˆä¸”ç»è¿‡éªŒè¯çš„å·¥å…·å’Œåº“ï¼Œä¸‹é¢åšäº†è§†è§‰æ€»ç»“ã€‚
- en: '![](../Images/36edff1699f49afb2c4cc4a1515dcaeb.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36edff1699f49afb2c4cc4a1515dcaeb.png)'
- en: The summary of the environment set-up. Â© Author
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ç¯å¢ƒè®¾ç½®çš„æ€»ç»“ã€‚Â© ä½œè€…
- en: Now that we have an explicit software stack, a functional python IDE and a basic
    understanding of python libraries, we can start preparing our data.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†æ˜ç¡®çš„è½¯ä»¶æ ˆã€åŠŸèƒ½é½å…¨çš„Python IDEå’Œå¯¹Pythonåº“çš„åŸºæœ¬ç†è§£ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹å‡†å¤‡æ•°æ®ã€‚
- en: Step 2\. 3D Data Preparation
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬2æ­¥ï¼š3Dæ•°æ®å‡†å¤‡
- en: 'We now move on to the second step: 3D Data Preparation.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨è¿›å…¥ç¬¬äºŒæ­¥ï¼š3Dæ•°æ®å‡†å¤‡ã€‚
- en: '![](../Images/eef72b8db48508cfa76b3ed2f1ecd575.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eef72b8db48508cfa76b3ed2f1ecd575.png)'
- en: 3D Data Preparation. We will download 3D dataset, then develop some easy 3D
    visualization to work by subsampling and exporting the data in a ready-to-use
    Python-friendly format.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 3Dæ•°æ®å‡†å¤‡ã€‚æˆ‘ä»¬å°†ä¸‹è½½3Dæ•°æ®é›†ï¼Œç„¶åå¼€å‘ä¸€äº›ç®€å•çš„3Då¯è§†åŒ–ï¼Œé€šè¿‡ä¸‹é‡‡æ ·å’Œå¯¼å‡ºæ•°æ®ä¸ºé€‚åˆPythonä½¿ç”¨çš„æ ¼å¼æ¥è¿›è¡Œå¤„ç†ã€‚
- en: Our goal is to gather and prepare the datasets to be usable for our analysis
    with Python in mind. Therefore, this step also acts as a â€œ3D Data Visualizationâ€
    phase, where we will qualitatively assess what we are dealing with. If you are
    ready, let us get started.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ”¶é›†å’Œå‡†å¤‡æ•°æ®é›†ï¼Œä»¥ä¾¿æˆ‘ä»¬ç”¨Pythonè¿›è¡Œåˆ†æã€‚å› æ­¤ï¼Œè¿™ä¸€æ­¥ä¹Ÿå……å½“äº†â€œ3Dæ•°æ®å¯è§†åŒ–â€é˜¶æ®µï¼Œæˆ‘ä»¬å°†å®šæ€§è¯„ä¼°æˆ‘ä»¬æ‰€å¤„ç†çš„æ•°æ®ã€‚å¦‚æœä½ å‡†å¤‡å¥½äº†ï¼Œå°±å¼€å§‹å§ã€‚
- en: 2.1\. Downloading 3D Datasets
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1. ä¸‹è½½3Dæ•°æ®é›†
- en: For 3D City Model Analysis, we gather some excellent datasets from OpenData
    Sources. I illustrate a specific tile of interest in the Netherlands, but I encourage
    you to study on your house or any point of interest for you (if you live in the
    Netherlands, of course, ğŸ˜‰).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº3DåŸå¸‚æ¨¡å‹åˆ†æï¼Œæˆ‘ä»¬ä»å¼€æ”¾æ•°æ®æºä¸­æ”¶é›†äº†ä¸€äº›ä¼˜ç§€çš„æ•°æ®é›†ã€‚æˆ‘å±•ç¤ºäº†è·å…°ä¸€ä¸ªç‰¹å®šçš„å…´è¶£åŒºåŸŸï¼Œä½†æˆ‘é¼“åŠ±ä½ ç ”ç©¶ä½ è‡ªå·±çš„æˆ¿å­æˆ–ä»»ä½•å¯¹ä½ æ„Ÿå…´è¶£çš„åœ°ç‚¹ï¼ˆå¦‚æœä½ ä½åœ¨è·å…°çš„è¯ï¼Œå½“ç„¶ï¼ŒğŸ˜‰ï¼‰ã€‚
- en: '**The Point Cloud Dataset.** First, we gather a point cloud dataset using the
    [geotiles.nl](https://geotiles.nl/) portal, which provides some nice datasets
    under the CC-BY 4.0 license. For this, you can head over to the website, zoom
    in on the tile of interest, and get the latest version of the AHN LiDAR point
    cloud (in our case, AHN4), as illustrated below. The file will then be downloaded
    as a .laz (LasZip) file.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç‚¹äº‘æ•°æ®é›†**ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨[geotiles.nl](https://geotiles.nl/)é—¨æˆ·ç½‘ç«™æ”¶é›†ç‚¹äº‘æ•°æ®é›†ï¼Œè¯¥ç½‘ç«™æä¾›äº†ä¸€äº›åœ¨CC-BY
    4.0è®¸å¯ä¸‹çš„è‰¯å¥½æ•°æ®é›†ã€‚ä¸ºæ­¤ï¼Œä½ å¯ä»¥è®¿é—®è¯¥ç½‘ç«™ï¼Œç¼©æ”¾åˆ°æ„Ÿå…´è¶£çš„ç“¦ç‰‡ï¼Œå¹¶è·å–æœ€æ–°ç‰ˆæœ¬çš„AHN LiDARç‚¹äº‘ï¼ˆåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­æ˜¯AHN4ï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚æ–‡ä»¶å°†è¢«ä¸‹è½½ä¸º.lazï¼ˆLasZipï¼‰æ–‡ä»¶ã€‚'
- en: '![](../Images/f230047cf879386afe3e52e933855c1c.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f230047cf879386afe3e52e933855c1c.png)'
- en: Downloading a 3D LiDAR dataset from the AHN-X campaing, through the portal geotiles.nl.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ä»AHN-Xé¡¹ç›®ä¸‹è½½3D LiDARæ•°æ®é›†ï¼Œé€šè¿‡é—¨æˆ·ç½‘ç«™geotiles.nlã€‚
- en: 'ğŸ¦š **Note**: *The AHN (Actueel Hoogtebestand Nederland) stems from an Aerial
    LiDAR coverage that provides a digital elevation map for all of the Netherlands.
    It contains detailed and precise height data with an average of eight measurements
    per square meter. Organizations such as the water boards, the provinces, and the
    Department of Public Works use the AHN for water and dam management. Based on
    the height and elevation of the ground level, it is determined whether the water
    can flow sufficiently from the land, how high the water level in the ditches can
    be, whether the water in rivers, flood plains, and ditches can be drained sufficiently
    and whether the dikes are still high and strong enough. The AHN is also used for
    many other types of management, such as daily management and maintenance of dikes,
    preparing specifications for significant maintenance, 3D mapping, permitting,
    and enforcement. Municipalities, businesses, and researchers also use detailed
    elevation data.*'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*AHNï¼ˆActueel Hoogtebestand Nederlandï¼‰æºè‡ªèˆªæ‹LiDARè¦†ç›–ï¼Œä¸ºè·å…°æ‰€æœ‰åœ°åŒºæä¾›æ•°å­—é«˜ç¨‹åœ°å›¾ã€‚å®ƒåŒ…å«è¯¦ç»†ä¸”ç²¾ç¡®çš„é«˜åº¦æ•°æ®ï¼Œæ¯å¹³æ–¹ç±³å¹³å‡æœ‰å…«æ¬¡æµ‹é‡ã€‚æ°´åŠ¡å±€ã€çœä»½å’Œå…¬å…±å·¥ç¨‹éƒ¨é—¨ç­‰ç»„ç»‡ä½¿ç”¨AHNè¿›è¡Œæ°´åŠ¡å’Œå ¤åç®¡ç†ã€‚æ ¹æ®åœ°é¢é«˜åº¦å’Œé«˜ç¨‹ï¼Œå†³å®šæ°´æ˜¯å¦èƒ½ä»åœŸåœ°ä¸Šé¡ºåˆ©æ’å‡ºï¼Œæ²Ÿæ¸ ä¸­çš„æ°´ä½å¯ä»¥å¤šé«˜ï¼Œæ²³æµã€æ´ªæ°´å¹³åŸå’Œæ²Ÿæ¸ ä¸­çš„æ°´æ˜¯å¦èƒ½å¾—åˆ°å……åˆ†æ’æ”¾ï¼Œä»¥åŠå ¤åæ˜¯å¦ä»ç„¶è¶³å¤Ÿé«˜ä¸”å¼ºå¤§ã€‚AHNè¿˜ç”¨äºè®¸å¤šå…¶ä»–ç±»å‹çš„ç®¡ç†ï¼Œå¦‚æ—¥å¸¸ç®¡ç†å’Œå ¤åç»´æŠ¤ã€é‡å¤§ç»´æŠ¤çš„è§„æ ¼å‡†å¤‡ã€3Dç»˜å›¾ã€è®¸å¯å’Œæ‰§æ³•ã€‚å¸‚æ”¿åºœã€ä¼ä¸šå’Œç ”ç©¶äººå‘˜ä¹Ÿä½¿ç”¨è¯¦ç»†çš„é«˜ç¨‹æ•°æ®ã€‚*
- en: 'If you like figures, I have a quick overview of AHN LiDAR data for you:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢å›¾å½¢ï¼Œæˆ‘ä¸ºä½ å‡†å¤‡äº†AHN LiDARæ•°æ®çš„å¿«é€Ÿæ¦‚è¿°ï¼š
- en: 'AHN1: 1997â€“2004, 1 pt/16 m2 to 1 pt/m2'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AHN1: 1997â€“2004, 1 pt/16 m2è‡³1 pt/m2'
- en: 'AHN2: 2007â€“2012, 8 pts/m2'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AHN2: 2007â€“2012, 8 pts/m2'
- en: 'AHN3: 2014â€“2019, 8 pts/m2'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AHN3: 2014â€“2019, 8 pts/m2'
- en: 'AHN4: 2020â€“2022, 10â€“15 pts/m2,'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AHN4: 2020â€“2022, 10â€“15 pts/m2ï¼Œ'
- en: 'AHN5: 2023â€“2025, 10â€“15 pts/m2'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AHN5: 2023â€“2025, 10â€“15 pts/m2'
- en: '**The Mesh Dataset.**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç½‘æ ¼æ•°æ®é›†**ã€‚'
- en: For this part, we want to find a 3D Mesh in the same spot as the LiDAR area
    we downloaded. We thus use the platform [3DBAG](http://3dbag.nl) created by TUDelft
    that allows us to retrieve 10M buildings in the Netherlands in LoD1.2, LoD1.3,
    and LoD2.2 from the [CityGML Specification](https://www.ogc.org/standard/citygml/).
    At this step, we are mainly interested in the geometry. Still, we know that the
    semantics and topology are crucial aspects of the CityGML / City JSON Data Models
    and will be explored in further articles. ğŸ˜‰
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬æƒ³åœ¨ä¸æˆ‘ä»¬ä¸‹è½½çš„LiDARåŒºåŸŸç›¸åŒçš„ä½ç½®æ‰¾åˆ°ä¸€ä¸ª3Dç½‘æ ¼ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ç”±TUDelftåˆ›å»ºçš„å¹³å° [3DBAG](http://3dbag.nl)ï¼Œå®ƒå…è®¸æˆ‘ä»¬ä»
    [CityGML Specification](https://www.ogc.org/standard/citygml/) ä¸­æ£€ç´¢è·å…°çš„10Må»ºç­‘ç‰©ï¼Œå…·æœ‰LoD1.2ã€LoD1.3å’ŒLoD2.2ã€‚åœ¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨å‡ ä½•å½¢çŠ¶ã€‚è™½ç„¶æˆ‘ä»¬çŸ¥é“è¯­ä¹‰å’Œæ‹“æ‰‘æ˜¯CityGML
    / City JSONæ•°æ®æ¨¡å‹çš„é‡è¦æ–¹é¢ï¼Œä½†å°†åœ¨åç»­æ–‡ç« ä¸­æ¢è®¨ã€‚ğŸ˜‰
- en: '![](../Images/50f588623ef6881757261e292df79872.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50f588623ef6881757261e292df79872.png)'
- en: Downloading a dataset from the portal 3Dbag.nl.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é—¨æˆ·ç½‘ç«™3Dbag.nlä¸‹è½½æ•°æ®é›†ã€‚
- en: 'ğŸ¦š **Note**: *3DBAG contains 3D models at multiple levels of detail, which are
    generated by combining two available data sets: the building data from the* [*BAG*](https://docs.3dbag.nl/en/overview/sources/#BAG)
    *and the height data from the* [*AHN*](https://docs.3dbag.nl/en/overview/sources/#AHN)*.
    The 3D BAG is updated regularly, keeping it up-to-date with the latest openly
    available building stock and elevation information*.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*3DBAGåŒ…å«å¤šä¸ªç»†èŠ‚å±‚çº§çš„3Dæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹æ˜¯é€šè¿‡ç»“åˆä¸¤ä¸ªå¯ç”¨æ•°æ®é›†ç”Ÿæˆçš„ï¼šæ¥è‡ª* [*BAG*](https://docs.3dbag.nl/en/overview/sources/#BAG)
    *çš„å»ºç­‘æ•°æ®å’Œæ¥è‡ª* [*AHN*](https://docs.3dbag.nl/en/overview/sources/#AHN)*çš„é«˜åº¦æ•°æ®ã€‚3D BAGä¼šå®šæœŸæ›´æ–°ï¼Œä¿æŒæœ€æ–°çš„å¼€æ”¾å»ºç­‘åº“å­˜å’Œé«˜ç¨‹ä¿¡æ¯*ã€‚
- en: After downloading the datasets, you should have one point cloud in the .laz
    file format and one or more .obj datasets (with their accompanying .mtl files)
    that describe approximately the same extent with different Levels of Detail (in
    our case LoD 1.2, 1.3, and 2.2), as illustrated below.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½æ•°æ®é›†åï¼Œä½ åº”è¯¥ä¼šæœ‰ä¸€ä¸ª.lazæ–‡ä»¶æ ¼å¼çš„ç‚¹äº‘å’Œä¸€ä¸ªæˆ–å¤šä¸ª.objæ•°æ®é›†ï¼ˆä»¥åŠå…¶é™„å¸¦çš„.mtlæ–‡ä»¶ï¼‰ï¼Œè¿™äº›æ•°æ®é›†å¤§è‡´æè¿°äº†ç›¸åŒçš„èŒƒå›´ï¼Œä½†å…·æœ‰ä¸åŒçš„ç»†èŠ‚å±‚çº§ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯LoD
    1.2ã€1.3å’Œ2.2ï¼‰ï¼Œå¦‚ä¸‹é¢æ‰€ç¤ºã€‚
- en: '![](../Images/50511df16a6b00c5995b8594721a4391.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50511df16a6b00c5995b8594721a4391.png)'
- en: 'ğŸ§™â€â™‚ï¸ **Wizard**: [OPTIONAL] *If you want to deepen your expertise on 3D data
    file format, especially meshes from point clouds, I encourage you to follow the
    tutorial below that will show you in-depth how to mesh point clouds and how they
    are structured.*'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ§™â€â™‚ï¸ **å‘å¯¼**ï¼š [å¯é€‰] *å¦‚æœä½ æƒ³æ·±å…¥äº†è§£3Dæ•°æ®æ–‡ä»¶æ ¼å¼ï¼Œå°¤å…¶æ˜¯ç‚¹äº‘ç½‘æ ¼çš„éƒ¨åˆ†ï¼Œæˆ‘å»ºè®®ä½ è·Ÿéšä¸‹é¢çš„æ•™ç¨‹ï¼Œè¯¦ç»†äº†è§£å¦‚ä½•å°†ç‚¹äº‘ç½‘æ ¼åŒ–åŠå…¶ç»“æ„ã€‚*
- en: '[](/5-step-guide-to-generate-3d-meshes-from-point-clouds-with-python-36bad397d8ba?source=post_page-----100ff40e4ff0--------------------------------)
    [## 5-Step Guide to generate 3D meshes from point clouds with Python'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/5-step-guide-to-generate-3d-meshes-from-point-clouds-with-python-36bad397d8ba?source=post_page-----100ff40e4ff0--------------------------------)
    [## 5æ­¥æŒ‡å—ï¼šä½¿ç”¨Pythonä»ç‚¹äº‘ç”Ÿæˆ3Dç½‘æ ¼'
- en: Tutorial to generate 3D meshes (.obj, .ply, .stl, .gltf) automatically from
    3D point clouds using python. (Bonus)â€¦
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•™ç¨‹ï¼šä½¿ç”¨pythonè‡ªåŠ¨ä»3Dç‚¹äº‘ç”Ÿæˆ3Dç½‘æ ¼ï¼ˆ.obj, .ply, .stl, .gltfï¼‰ã€‚(é™„èµ )â€¦
- en: towardsdatascience.com](/5-step-guide-to-generate-3d-meshes-from-point-clouds-with-python-36bad397d8ba?source=post_page-----100ff40e4ff0--------------------------------)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/5-step-guide-to-generate-3d-meshes-from-point-clouds-with-python-36bad397d8ba?source=post_page-----100ff40e4ff0--------------------------------)
- en: For the sake of convenience, you can directly download the selection from this
    [**Drive Folder**](https://drive.google.com/drive/folders/1CFX42bIcl3Y4NBa6qhrtmYZ-IX3o7q4r?usp=sharing).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œä½ å¯ä»¥ç›´æ¥ä»è¿™ä¸ª [**Driveæ–‡ä»¶å¤¹**](https://drive.google.com/drive/folders/1CFX42bIcl3Y4NBa6qhrtmYZ-IX3o7q4r?usp=sharing)
    ä¸‹è½½é€‰æ‹©é¡¹ã€‚
- en: 2.2\. 3D Data Visualization
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2\. 3Dæ•°æ®å¯è§†åŒ–
- en: We will now jump into `CloudCompare` to ensure that the data downloaded for
    the analysis hold no distinctive surprise. ğŸ˜ After launching `CloudCompare`, you
    can load the `.laz` point cloud from your local folder. When the import window
    displays, ensure to import only the `â€œClassificationâ€` Extra field for this application
    and accept the global shift as shown below.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å°†è¿›å…¥`CloudCompare`ä»¥ç¡®ä¿ä¸‹è½½çš„æ•°æ®åˆ†ææ²¡æœ‰ç‰¹æ®Šçš„æƒŠå–œã€‚ğŸ˜ å¯åŠ¨`CloudCompare`åï¼Œä½ å¯ä»¥ä»æœ¬åœ°æ–‡ä»¶å¤¹åŠ è½½`.laz`ç‚¹äº‘ã€‚å½“å¯¼å…¥çª—å£æ˜¾ç¤ºæ—¶ï¼Œç¡®ä¿ä»…å¯¼å…¥æ­¤åº”ç”¨ç¨‹åºçš„`â€œClassificationâ€`é¢å¤–å­—æ®µï¼Œå¹¶æ¥å—å¦‚ä¸‹é¢æ‰€ç¤ºçš„å…¨å±€åç§»ã€‚
- en: '![](../Images/135545f5da43ce67aede78208a48476c.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/135545f5da43ce67aede78208a48476c.png)'
- en: 3D Data Visualization within CloudCompare.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨CloudCompareä¸­è¿›è¡Œ3Dæ•°æ®å¯è§†åŒ–ã€‚
- en: 'ğŸ¦š **Note**: *The Global Shift is a temporary shift to permit* `*CloudCompare*`
    *to work with georeferenced data that cross the bounds of the number of numbers
    it can handle for visualization purposes. Thus, it is a transparent step* and
    will be applied to the data upon saving*.*'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*å…¨å±€åç§»æ˜¯ä¸€ä¸ªä¸´æ—¶çš„åç§»ï¼Œä»¥å…è®¸`*CloudCompare*`å¤„ç†åœ°ç†å‚è€ƒæ•°æ®ï¼Œè¯¥æ•°æ®è¶…å‡ºäº†å®ƒå¯ä»¥å¤„ç†çš„å¯è§†åŒ–èŒƒå›´ã€‚å› æ­¤ï¼Œè¿™ä¸€æ­¥æ˜¯é€æ˜çš„*ï¼Œå¹¶å°†åœ¨ä¿å­˜æ•°æ®æ—¶åº”ç”¨*ã€‚*
- en: We can now move on to importing the mesh data as well. For this, we execute
    the same import action and accept the proposed translation shift while ensuring
    it is the same as the one applied to the point cloud.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç»§ç»­å¯¼å…¥ç½‘æ ¼æ•°æ®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ‰§è¡Œç›¸åŒçš„å¯¼å…¥æ“ä½œï¼Œå¹¶æ¥å—å»ºè®®çš„å¹³ç§»åç§»ï¼ŒåŒæ—¶ç¡®ä¿å®ƒä¸åº”ç”¨äºç‚¹äº‘çš„åç§»ç›¸åŒã€‚
- en: '![](../Images/1f493402266cfe74dbbebb61afaf2d50.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f493402266cfe74dbbebb61afaf2d50.png)'
- en: Loading 3D meshes from the downloaded assets.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸‹è½½çš„èµ„äº§ä¸­åŠ è½½3Dç½‘æ ¼ã€‚
- en: You can now see from the Database Tree the different objects imported in your
    current project (You can check the image below if you cannot find the DBTree).
    The `DBTree` behaves a bit like your OS Explorer, where you have a folder that
    holds different point clouds or meshes. Each object (e.g., a point cloud or a
    3D Mesh) can be activated â˜‘ï¸ (or deactivated) visually like a layer and selected
    to identify object properties.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å¯ä»¥ä»æ•°æ®åº“æ ‘ä¸­çœ‹åˆ°å½“å‰é¡¹ç›®ä¸­å¯¼å…¥çš„ä¸åŒå¯¹è±¡ï¼ˆå¦‚æœæ‰¾ä¸åˆ°DBTreeï¼Œå¯ä»¥æŸ¥çœ‹ä¸‹å›¾ï¼‰ã€‚`DBTree`çš„åŠŸèƒ½æœ‰ç‚¹ç±»ä¼¼äºä½ çš„æ“ä½œç³»ç»Ÿèµ„æºç®¡ç†å™¨ï¼Œå…¶ä¸­åŒ…å«ä¸åŒçš„ç‚¹äº‘æˆ–ç½‘æ ¼ã€‚æ¯ä¸ªå¯¹è±¡ï¼ˆä¾‹å¦‚ç‚¹äº‘æˆ–3Dç½‘æ ¼ï¼‰å¯ä»¥åƒå›¾å±‚ä¸€æ ·å¯è§†åŒ–åœ°æ¿€æ´»
    â˜‘ï¸ï¼ˆæˆ–åœç”¨ï¼‰å¹¶é€‰æ‹©ä»¥è¯†åˆ«å¯¹è±¡å±æ€§ã€‚
- en: '![](../Images/5835e687656ac5c5a90468fe7fa06d51.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5835e687656ac5c5a90468fe7fa06d51.png)'
- en: CloudCompare Interface for 3D data processing and analysis. Â© Author
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: CloudCompare 3Dæ•°æ®å¤„ç†å’Œåˆ†æç•Œé¢ã€‚Â© ä½œè€…
- en: 'ğŸ¦š **Note**: *CloudCompare does not save by default. To bypass any crash, if
    you are worried, you can always put all your data and analysis in one folder from
    the DBTree (Right-Click > Create New Empty Group) and save this folder as a .bin
    CloudCompare project.*'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*CloudCompareé»˜è®¤ä¸ä¿å­˜ã€‚ä¸ºäº†é¿å…å´©æºƒï¼Œå¦‚æœä½ æ‹…å¿ƒï¼Œå¯ä»¥å°†æ‰€æœ‰æ•°æ®å’Œåˆ†ææ”¾åœ¨DBTreeä¸­çš„ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ï¼ˆå³é”®ç‚¹å‡» > åˆ›å»ºæ–°çš„ç©ºç»„ï¼‰ï¼Œå¹¶å°†æ­¤æ–‡ä»¶å¤¹ä¿å­˜ä¸º.bin
    CloudCompareé¡¹ç›®ã€‚*
- en: 2.3\. 3D Data Subsampling
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3\. 3Dæ•°æ®å­é‡‡æ ·
- en: It is now time to dive into 3D data filtering. First, we select the point cloud
    from the `DBTree` and apply a spatial subsampling function to keep one point every
    50 cm, allowing us to retain sufficient information while not comprising the computational
    speed after that. For this, we use the `subsample` function as illustrated below.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯æ·±å…¥3Dæ•°æ®è¿‡æ»¤çš„æ—¶å€™äº†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä»`DBTree`ä¸­é€‰æ‹©ç‚¹äº‘ï¼Œå¹¶åº”ç”¨ç©ºé—´å­é‡‡æ ·å‡½æ•°ä»¥æ¯50å˜ç±³ä¿ç•™ä¸€ä¸ªç‚¹ï¼Œè¿™æ ·å¯ä»¥ä¿ç•™è¶³å¤Ÿçš„ä¿¡æ¯ï¼ŒåŒæ—¶ä¸ä¼šå½±å“è®¡ç®—é€Ÿåº¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸‹é¢æ‰€ç¤ºçš„`subsample`å‡½æ•°ã€‚
- en: '![](../Images/75c60243e4fdfd456fd59b6de354358d.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75c60243e4fdfd456fd59b6de354358d.png)'
- en: 3D Point Cloud Sub-sampling
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ç‚¹äº‘å­é‡‡æ ·
- en: 'ğŸ§™â€â™‚ï¸ **Wizard**: *[OPTIONAL] In our case, we used a spatial subsampling function
    to retain one point every 50 cm on average. If you want to explore and deepen
    the 3D point cloud sampling strategies, I recommend diving into the following
    article.*'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ§™â€â™‚ï¸ **å‘å¯¼**: *[å¯é€‰] åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ç©ºé—´å­é‡‡æ ·å‡½æ•°ï¼Œæ¯éš” 50 cm å¹³å‡ä¿ç•™ä¸€ä¸ªç‚¹ã€‚å¦‚æœä½ æƒ³æ¢ç´¢å’Œæ·±å…¥ 3D ç‚¹äº‘é‡‡æ ·ç­–ç•¥ï¼Œæˆ‘æ¨èæ·±å…¥é˜…è¯»ä»¥ä¸‹æ–‡ç« ã€‚*'
- en: '[](/how-to-automate-lidar-point-cloud-processing-with-python-a027454a536c?source=post_page-----100ff40e4ff0--------------------------------)
    [## How to automate LiDAR point cloud processing with Python'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-automate-lidar-point-cloud-processing-with-python-a027454a536c?source=post_page-----100ff40e4ff0--------------------------------)
    [## å¦‚ä½•ä½¿ç”¨ Python è‡ªåŠ¨åŒ– LiDAR ç‚¹äº‘å¤„ç†'
- en: The ultimate guide on point cloud sub-sampling from scratch, with Python. It
    covers LiDAR I/O, 3D voxel grid processingâ€¦
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…³äºç‚¹äº‘å­é‡‡æ ·çš„ç»ˆææŒ‡å—ï¼Œä»é›¶å¼€å§‹ï¼Œç”¨ Python ç¼–å†™ã€‚æ¶µç›– LiDAR I/Oã€3D ä½“ç´ ç½‘æ ¼å¤„ç†ç­‰â€¦â€¦
- en: towardsdatascience.com](/how-to-automate-lidar-point-cloud-processing-with-python-a027454a536c?source=post_page-----100ff40e4ff0--------------------------------)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/how-to-automate-lidar-point-cloud-processing-with-python-a027454a536c?source=post_page-----100ff40e4ff0--------------------------------)
- en: Once the subsampling step is done, we get a resulting subsampled point cloud
    in the `DBTree`, that we can use for downstream processes.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦å®Œæˆå­é‡‡æ ·æ­¥éª¤ï¼Œæˆ‘ä»¬å°†åœ¨ `DBTree` ä¸­å¾—åˆ°ä¸€ä¸ªç»“æœå­é‡‡æ ·ç‚¹äº‘ï¼Œå¯ä»¥ç”¨äºåç»­å¤„ç†ã€‚
- en: On the Mesh side, upon import, we see that we can open each mesh object from
    the DBTree by clicking on the little arrow icon next to it, which shows many different
    sub-mesh elements. This is because, in the original `.obj` file, we have an â€œobjectâ€
    refinement that permits us to retain some â€œsemanticâ€ decomposition linked to geometries.
    Each sub-mesh is a building entity decomposition.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Mesh æ–¹é¢ï¼Œå¯¼å…¥åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç‚¹å‡»æ¯ä¸ªç½‘æ ¼å¯¹è±¡æ—è¾¹çš„å°ç®­å¤´å›¾æ ‡ä» DBTree ä¸­æ‰“å¼€å®ƒï¼Œè¿™ä¼šæ˜¾ç¤ºè®¸å¤šä¸åŒçš„å­ç½‘æ ¼å…ƒç´ ã€‚è¿™æ˜¯å› ä¸ºåœ¨åŸå§‹çš„ `.obj`
    æ–‡ä»¶ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªâ€œå¯¹è±¡â€ç»†åŒ–ï¼Œè¿™å…è®¸æˆ‘ä»¬ä¿ç•™ä¸€äº›ä¸å‡ ä½•ä½“ç›¸å…³çš„â€œè¯­ä¹‰â€åˆ†è§£ã€‚æ¯ä¸ªå­ç½‘æ ¼æ˜¯ä¸€ä¸ªæ„å»ºå®ä½“çš„åˆ†è§£ã€‚
- en: If you want to see these elements, you can open the mesh, select all the sub-element
    by holding `Ctrl+Shift` on the second mouse click, and `right-click > toggle`
    to display them. You can also uncheck the `Visible` property of the parent mesh
    element to ensure what you view is only the sub-elements, as shown below.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³æŸ¥çœ‹è¿™äº›å…ƒç´ ï¼Œå¯ä»¥æ‰“å¼€ç½‘æ ¼ï¼Œé€šè¿‡æŒ‰ä½ `Ctrl+Shift` å¹¶åœ¨ç¬¬äºŒæ¬¡é¼ æ ‡ç‚¹å‡»æ—¶é€‰æ‹©æ‰€æœ‰å­å…ƒç´ ï¼Œç„¶å `å³é”®ç‚¹å‡» > åˆ‡æ¢` ä»¥æ˜¾ç¤ºå®ƒä»¬ã€‚ä½ è¿˜å¯ä»¥å–æ¶ˆé€‰ä¸­çˆ¶ç½‘æ ¼å…ƒç´ çš„
    `å¯è§` å±æ€§ï¼Œä»¥ç¡®ä¿ä½ çœ‹åˆ°çš„ä»…æ˜¯å­å…ƒç´ ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/694d934e30ea666f3dfb863b4b8a4544.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/694d934e30ea666f3dfb863b4b8a4544.png)'
- en: 3D Data Preparation within CloudCompare.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: CloudCompare ä¸­çš„ 3D æ•°æ®å‡†å¤‡ã€‚
- en: 'ğŸ¦š **Note**: *We cannot use the sub-mesh selection as they also encompass all
    the vertices from the mesh parent, which means that, if we were to use it, we
    would have to segment the mesh to only the vertices of the sub-mesh selected.*'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦š **æ³¨æ„**: *æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨å­ç½‘æ ¼é€‰æ‹©ï¼Œå› ä¸ºå®ƒä»¬ä¹ŸåŒ…å«ç½‘æ ¼çˆ¶é¡¹çš„æ‰€æœ‰é¡¶ç‚¹ï¼Œè¿™æ„å‘³ç€ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨å®ƒï¼Œæˆ‘ä»¬å°†ä¸å¾—ä¸å°†ç½‘æ ¼åˆ†å‰²ä¸ºä»…é€‰ä¸­çš„å­ç½‘æ ¼çš„é¡¶ç‚¹ã€‚*'
- en: Excellent, well done! From there, you can uncheck all elements except the mesh
    you want to consider (in our case, the LoD 1.2) and use, E.g., the â€œCross Sectionâ€
    function, to select the house you are interested in, as shown below.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆæ£’ï¼Œå¹²å¾—å¥½ï¼ä»é‚£é‡Œï¼Œä½ å¯ä»¥å–æ¶ˆé€‰æ‹©æ‰€æœ‰å…ƒç´ ï¼Œåªä¿ç•™ä½ æƒ³è¦è€ƒè™‘çš„ç½‘æ ¼ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ LoD 1.2ï¼‰ï¼Œå¹¶ä½¿ç”¨ä¾‹å¦‚â€œæ¨ªæˆªé¢â€åŠŸèƒ½ï¼Œé€‰æ‹©ä½ æ„Ÿå…´è¶£çš„æˆ¿å±‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/f552098ff1c35a90d330c244b378b1d8.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f552098ff1c35a90d330c244b378b1d8.png)'
- en: 3D Data Selection within CloudCompare
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: CloudCompare ä¸­çš„ 3D æ•°æ®é€‰æ‹©
- en: Once this is done, we are ready to export our selected study site for both 3D
    modalities.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦å®Œæˆï¼Œæˆ‘ä»¬å°±å‡†å¤‡å¥½å¯¼å‡ºæˆ‘ä»¬é€‰æ‹©çš„ç ”ç©¶ç«™ç‚¹çš„ä¸¤ç§ 3D æ¨¡æ€ã€‚
- en: 2.4\. 3D Data Export
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4\. 3D æ•°æ®å¯¼å‡º
- en: Concerning the point cloud data, we can export it in various file formats. Because
    we want to retain the classification field for some Python analysis (E.g., to
    know if a point belongs to the ground or a building), we export the 3D point cloud
    as an ASCII file for easy manipulation in Python, as shown below.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºç‚¹äº‘æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥å„ç§æ–‡ä»¶æ ¼å¼å¯¼å‡ºå®ƒã€‚ç”±äºæˆ‘ä»¬å¸Œæœ›ä¿ç•™åˆ†ç±»å­—æ®µä»¥è¿›è¡Œä¸€äº› Python åˆ†æï¼ˆä¾‹å¦‚ï¼Œäº†è§£ä¸€ä¸ªç‚¹æ˜¯å¦å±äºåœ°é¢æˆ–å»ºç­‘ç‰©ï¼‰ï¼Œæˆ‘ä»¬å°† 3D
    ç‚¹äº‘å¯¼å‡ºä¸º ASCII æ–‡ä»¶ï¼Œä»¥ä¾¿åœ¨ Python ä¸­è½»æ¾å¤„ç†ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/e375bc8da30926779b138a3c60a9416c.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e375bc8da30926779b138a3c60a9416c.png)'
- en: 3D Point Cloud Data Export within CloudCompare.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: CloudCompare ä¸­çš„ 3D ç‚¹äº‘æ•°æ®å¯¼å‡ºã€‚
- en: 'ğŸ¦š **Note**: *When saving the file, we can optionally modify the file extension
    to* `*.xyz*` *and check the â€œkeep the column namesâ€ option when the export dialog
    opens. This will allow having the columnâ€™s name written in your file. However,
    if you open your file with a text editor, make sure to delete the two backslashes
    that are not really useful, as shown above.*'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*åœ¨ä¿å­˜æ–‡ä»¶æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¿®æ”¹æ–‡ä»¶æ‰©å±•åä¸º* `*.xyz*` *ï¼Œå¹¶åœ¨å¯¼å‡ºå¯¹è¯æ¡†æ‰“å¼€æ—¶å‹¾é€‰â€œä¿ç•™åˆ—åâ€é€‰é¡¹ã€‚è¿™å°†å…è®¸åœ¨æ–‡ä»¶ä¸­å†™å…¥åˆ—åã€‚ç„¶è€Œï¼Œå¦‚æœä½ ç”¨æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€æ–‡ä»¶ï¼Œç¡®ä¿åˆ é™¤ä¸¤ä¸ªä¸å¿…è¦çš„åæ–œæ ï¼Œå¦‚ä¸Šæ‰€ç¤ºã€‚*
- en: Our first 3D dataset is prepared and ready to be used as a `.xyz` file for Python.
    Now, let us move on to the 3D Mesh.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç¬¬ä¸€ä¸ª3Dæ•°æ®é›†å·²ç»å‡†å¤‡å¥½ï¼Œå¯ä»¥ä½œä¸º`.xyz`æ–‡ä»¶ç”¨äºPythonã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬ç»§ç»­è¿›è¡Œ3Dç½‘æ ¼å¤„ç†ã€‚
- en: After selecting your house/building block of interest, I encourage you to get
    the associated sub-mesh element name and use this as the name for your exported
    file. Concerning the export dialog options, you can choose the .obj file extension,
    which is a safe bet ğŸ˜‰.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: é€‰æ‹©ä½ æ„Ÿå…´è¶£çš„æˆ¿å±‹/å»ºç­‘å—åï¼Œæˆ‘å»ºè®®ä½ è·å–ç›¸å…³çš„å­ç½‘æ ¼å…ƒç´ åç§°ï¼Œå¹¶å°†å…¶ç”¨ä½œå¯¼å‡ºæ–‡ä»¶çš„åç§°ã€‚å…³äºå¯¼å‡ºå¯¹è¯æ¡†çš„é€‰é¡¹ï¼Œä½ å¯ä»¥é€‰æ‹©`.obj`æ–‡ä»¶æ‰©å±•åï¼Œè¿™æ˜¯ä¸€ä¸ªå®‰å…¨çš„é€‰æ‹©ğŸ˜‰ã€‚
- en: '![](../Images/ac17be9b0af97e470aaa69ecb8fa42ff.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac17be9b0af97e470aaa69ecb8fa42ff.png)'
- en: 3D Mesh Export within CloudCompare.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: CloudCompareä¸­çš„3Dç½‘æ ¼å¯¼å‡ºã€‚
- en: The 3D Mesh is now ready and accompanied by a material `.mtl` file (not helpful
    in our case).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 3Dç½‘æ ¼ç°åœ¨å·²ç»å‡†å¤‡å¥½ï¼Œå¹¶é™„å¸¦ä¸€ä¸ªææ–™`.mtl`æ–‡ä»¶ï¼ˆåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ä¸å¤ªæœ‰ç”¨ï¼‰ã€‚
- en: Step 2 is Complete! Well done. We first gathered a 3D Point Cloud and a 3D Mesh
    of a zone of the Netherlands. We then visualized them to check if they were corresponding
    to our intent. Then we filtered the point cloud to retain around 1 point every
    50 cm, the 3D Mesh to keep only one object representing a building house, and
    we exported both modalities respectively as a `.xyz`, and a `.obj` + `.mtl` file.Â¹
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤2å·²å®Œæˆï¼å¹²å¾—å¥½ã€‚æˆ‘ä»¬é¦–å…ˆæ”¶é›†äº†è·å…°ä¸€ä¸ªåŒºåŸŸçš„3Dç‚¹äº‘å’Œ3Dç½‘æ ¼ã€‚ç„¶åæˆ‘ä»¬è¿›è¡Œäº†å¯è§†åŒ–ï¼Œä»¥æ£€æŸ¥å®ƒä»¬æ˜¯å¦ç¬¦åˆæˆ‘ä»¬çš„æ„å›¾ã€‚æ¥ç€æˆ‘ä»¬è¿‡æ»¤äº†ç‚¹äº‘ï¼Œä¿ç•™æ¯50å˜ç±³å·¦å³ä¸€ä¸ªç‚¹ï¼Œ3Dç½‘æ ¼åªä¿ç•™ä¸€ä¸ªä»£è¡¨å»ºç­‘æˆ¿å±‹çš„å¯¹è±¡ï¼Œå¹¶å°†ä¸¤ç§æ•°æ®åˆ†åˆ«å¯¼å‡ºä¸º`.xyz`å’Œ`.obj`
    + `.mtl`æ–‡ä»¶ã€‚Â¹
- en: '![](../Images/4595e2ca0af6a47c7bf76134ee9cf658.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4595e2ca0af6a47c7bf76134ee9cf658.png)'
- en: 'A visual summary of Step 2: 3D Data Preparation. Â© F. Poux'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤2çš„å¯è§†åŒ–æ€»ç»“ï¼š3Dæ•°æ®å‡†å¤‡ã€‚Â© F. Poux
- en: Let us now put these bad boys into a great Python setup to maximize automation
    and 3D analysis!
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬å°†è¿™äº›æ•°æ®é›†æ”¾å…¥ä¸€ä¸ªå‡ºè‰²çš„Pythonè®¾ç½®ä¸­ï¼Œä»¥æœ€å¤§åŒ–è‡ªåŠ¨åŒ–å’Œ3Dåˆ†æï¼
- en: Â¹For convenience, you can find these datasets in this [**Drive Folder**](https://drive.google.com/drive/folders/1ANqPB5t_pw_n26QkZggbt5JMI0cZ-cO_?usp=sharing).
  id: totrans-188
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Â¹ä¸ºäº†æ–¹ä¾¿ï¼Œä½ å¯ä»¥åœ¨è¿™ä¸ª[**Driveæ–‡ä»¶å¤¹**](https://drive.google.com/drive/folders/1ANqPB5t_pw_n26QkZggbt5JMI0cZ-cO_?usp=sharing)ä¸­æ‰¾åˆ°è¿™äº›æ•°æ®é›†ã€‚
- en: Step 3\. Python Automation
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬3æ­¥\. Pythonè‡ªåŠ¨åŒ–
- en: Now the real fun begins, time for coding with Python! ğŸ¤“
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨çœŸæ­£æœ‰è¶£çš„éƒ¨åˆ†å¼€å§‹äº†ï¼Œæ˜¯æ—¶å€™ç”¨Pythonç¼–ç¨‹äº†ï¼ğŸ¤“
- en: '![](../Images/a314de57983d17100cf5259317f63320.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a314de57983d17100cf5259317f63320.png)'
- en: 3D Python Automation.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 3D Pythonè‡ªåŠ¨åŒ–ã€‚
- en: As shown above, we will follow a five-stage approach by importing libraries,
    loading datasets, setting up our 3D Python Visualiser, Defining solutions to 3D
    Challenges, and then exporting our results to be used outside Python. Let us first
    build the bulk of our automated pipeline in Python before moving to the different
    challenges
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šæ‰€ç¤ºï¼Œæˆ‘ä»¬å°†éµå¾ªäº”ä¸ªé˜¶æ®µçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å¯¼å…¥åº“ã€åŠ è½½æ•°æ®é›†ã€è®¾ç½®æˆ‘ä»¬çš„3D Pythonå¯è§†åŒ–å·¥å…·ã€å®šä¹‰3DæŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆï¼Œç„¶åå°†ç»“æœå¯¼å‡ºä»¥ä¾›Pythonä¹‹å¤–ä½¿ç”¨ã€‚è®©æˆ‘ä»¬å…ˆåœ¨Pythonä¸­å»ºç«‹æˆ‘ä»¬è‡ªåŠ¨åŒ–ç®¡é“çš„ä¸»ä½“ï¼Œç„¶åå†å¤„ç†ä¸åŒçš„æŒ‘æˆ˜ã€‚
- en: 3.1\. Importing libraries
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1\. å¯¼å…¥åº“
- en: As defined in Step 1., we will stick to a minimal amount of libraries to deepen
    our expertise in their usage. These are `NumPy`, `Pandas`, `Open3D`, `Matplotlib,`
    and `Shapely`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æ­¥éª¤1ä¸­å®šä¹‰çš„ï¼Œæˆ‘ä»¬å°†åšæŒä½¿ç”¨æœ€å°‘çš„åº“ï¼Œä»¥åŠ æ·±æˆ‘ä»¬å¯¹å…¶ä½¿ç”¨çš„äº†è§£ã€‚è¿™äº›åº“åŒ…æ‹¬`NumPy`ã€`Pandas`ã€`Open3D`ã€`Matplotlib`å’Œ`Shapely`ã€‚
- en: We will write the lines of code that follow in a Python notebook (`.ipynb`)
    from our IDE.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»æˆ‘ä»¬çš„IDEä¸­åœ¨Pythonç¬”è®°æœ¬ï¼ˆ`.ipynb`ï¼‰ä¸­ç¼–å†™ä»¥ä¸‹ä»£ç è¡Œã€‚
- en: '![](../Images/b8a497ba7aed223b175d69426e78d072.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8a497ba7aed223b175d69426e78d072.png)'
- en: The IDE view to write our script.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºç¼–å†™æˆ‘ä»¬è„šæœ¬çš„IDEè§†å›¾ã€‚
- en: 'We import the libraries mentioned above with the following code block:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç”¨ä»¥ä¸‹ä»£ç å—å¯¼å…¥ä¸Šè¿°æåˆ°çš„åº“ï¼š
- en: '[PRE6]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will return the current Open 3D Version as a string: `Open 3D Version:
    0.16.0`. We are set up, and we can move on to loading the datasets.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 'è¿™å°†è¿”å›å½“å‰çš„Open 3Dç‰ˆæœ¬ä½œä¸ºå­—ç¬¦ä¸²ï¼š`Open 3D Version: 0.16.0`ã€‚æˆ‘ä»¬å·²ç»è®¾ç½®å¥½äº†ï¼Œå¯ä»¥ç»§ç»­åŠ è½½æ•°æ®é›†ã€‚'
- en: 3.2\. Loading datasets
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2\. åŠ è½½æ•°æ®é›†
- en: Now we will define the specific paths where our datasets are stored. I like
    to make it clear and relative to my code file. This way, everything is expressed
    relatively (the `../` means go to the parent folder) in my current notebook, making
    navigating the folder easy if I need to code on different machines.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å°†å®šä¹‰å­˜å‚¨æ•°æ®é›†çš„å…·ä½“è·¯å¾„ã€‚æˆ‘å–œæ¬¢å°†å…¶æ˜ç¡®ä¸”ç›¸å¯¹äºæˆ‘çš„ä»£ç æ–‡ä»¶ã€‚è¿™æ ·ï¼Œä¸€åˆ‡éƒ½ç›¸å¯¹è¡¨è¾¾ï¼ˆ`../` è¡¨ç¤ºè½¬åˆ°çˆ¶æ–‡ä»¶å¤¹ï¼‰ï¼Œä½¿å¾—åœ¨ä¸åŒæœºå™¨ä¸Šç¼–ç æ—¶ï¼Œæµè§ˆæ–‡ä»¶å¤¹å˜å¾—å®¹æ˜“ã€‚
- en: '[PRE7]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Point Cloud Dataset.**'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç‚¹äº‘æ•°æ®é›†**ã€‚'
- en: 'We can prepare the point cloud by first creating a Pandas `DataFrame` object
    called `pcd_df`, which will host the point cloud data:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡é¦–å…ˆåˆ›å»ºä¸€ä¸ªåä¸º `pcd_df` çš„ Pandas `DataFrame` å¯¹è±¡æ¥å‡†å¤‡ç‚¹äº‘ï¼Œè¯¥å¯¹è±¡å°†åŒ…å«ç‚¹äº‘æ•°æ®ï¼š
- en: '[PRE8]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will return the name of the columns in this pcd_df DataFrame, which are:
    `[â€˜Xâ€™, â€˜Yâ€™, â€˜Zâ€™, â€˜Râ€™, â€˜Gâ€™, â€˜Bâ€™, â€˜Classificationâ€™]`. This is handy for selecting
    only the explicit â€œcolumnsâ€ without blurry indexes ğŸ˜. And this is precisely what
    we will do: select only the `[â€˜Xâ€™, â€˜Yâ€™, â€˜Zâ€™]` coordinates to create an Open3D
    `PointCloud` object. This is an excellent way to understand that when we use a
    different library, we must cope with different mechanisms to transform the dataset
    in different Python Objects. Here, we go from a Pandas DataFrame to an Open3D
    PointCloud, which is necessary to use the Open3D functions implemented in the
    Open3D library. Let us proceed in four steps, as illustrated below:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†è¿”å› pcd_df æ•°æ®æ¡†ä¸­çš„åˆ—åï¼Œå®ƒä»¬æ˜¯ï¼š`[â€˜Xâ€™, â€˜Yâ€™, â€˜Zâ€™, â€˜Râ€™, â€˜Gâ€™, â€˜Bâ€™, â€˜Classificationâ€™]`ã€‚è¿™å¯¹äºä»…é€‰æ‹©æ˜ç¡®çš„â€œåˆ—â€è€Œä¸æ˜¯æ¨¡ç³Šçš„ç´¢å¼•éå¸¸æœ‰ç”¨
    ğŸ˜ã€‚è¿™æ­£æ˜¯æˆ‘ä»¬è¦åšçš„ï¼šä»…é€‰æ‹© `[â€˜Xâ€™, â€˜Yâ€™, â€˜Zâ€™]` åæ ‡ä»¥åˆ›å»º Open3D `PointCloud` å¯¹è±¡ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ–¹æ³•æ¥ç†è§£å½“æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„åº“æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»é€‚åº”ä¸åŒçš„æœºåˆ¶ä»¥å°†æ•°æ®é›†è½¬æ¢ä¸ºä¸åŒçš„
    Python å¯¹è±¡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä» Pandas DataFrame è½¬åˆ° Open3D PointCloudï¼Œè¿™æ˜¯ä½¿ç”¨ Open3D åº“ä¸­å®ç°çš„ Open3D
    å‡½æ•°æ‰€å¿…éœ€çš„ã€‚è®©æˆ‘ä»¬æŒ‰ä»¥ä¸‹å››ä¸ªæ­¥éª¤è¿›è¡Œï¼š
- en: '![](../Images/7e414dcc4e8af9947fabce7223ab2bb6.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e414dcc4e8af9947fabce7223ab2bb6.png)'
- en: The concept workflow for open3D point cloud creation. Â© Author
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Open3D ç‚¹äº‘åˆ›å»ºçš„æ¦‚å¿µå·¥ä½œæµç¨‹ã€‚Â© ä½œè€…ã€‚
- en: 'This decomposed mechanism translates into the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåˆ†è§£æœºåˆ¶è½¬åŒ–ä¸ºä»¥ä¸‹å†…å®¹ï¼š
- en: '![](../Images/8c0ddc98b107fe8264d4b46bc61da2e7.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c0ddc98b107fe8264d4b46bc61da2e7.png)'
- en: The code workflow for open3D point cloud creation. Â© Author.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»º Open3D ç‚¹äº‘çš„ä»£ç å·¥ä½œæµç¨‹ã€‚Â© ä½œè€…ã€‚
- en: 'But hey, if we want to be a bit more condensed, this transformation can then
    be done with a single code line, this one:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦æ›´ç®€æ´ä¸€ç‚¹ï¼Œè¿™ä¸ªè½¬æ¢å¯ä»¥é€šè¿‡ä¸€è¡Œä»£ç å®Œæˆï¼Œå³ï¼š
- en: '[PRE9]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We now have two important variables: `pcd_o3d` and `pcd_df`. We can also give
    some colors to the Open3D `PointCloud` object:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨æœ‰ä¸¤ä¸ªé‡è¦çš„å˜é‡ï¼š`pcd_o3d` å’Œ `pcd_df`ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä¸º Open3D `PointCloud` å¯¹è±¡æ·»åŠ ä¸€äº›é¢œè‰²ï¼š
- en: '[PRE10]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We have to be mindful to transform the `R,G,B` values to float values between
    `[0,1]`, and make sure that we pass a `Vector3dVector` object to the `colors`
    attribute.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»æ³¨æ„å°† `R,G,B` å€¼è½¬æ¢ä¸º `[0,1]` èŒƒå›´å†…çš„æµ®ç‚¹å€¼ï¼Œå¹¶ç¡®ä¿å°† `Vector3dVector` å¯¹è±¡ä¼ é€’ç»™ `colors` å±æ€§ã€‚
- en: '**Mesh Dataset.**'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç½‘æ ¼æ•°æ®é›†**ã€‚'
- en: 'Now, we can load the 3D Mesh in a `mesh` variable using the `read_triangle_mesh()`
    method from `open3d`. We can also paint the mesh with the `paint_uniform_color()`
    method:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `open3d` çš„ `read_triangle_mesh()` æ–¹æ³•å°† 3D ç½‘æ ¼åŠ è½½åˆ° `mesh` å˜é‡ä¸­ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨
    `paint_uniform_color()` æ–¹æ³•ä¸ºç½‘æ ¼ä¸Šè‰²ï¼š
- en: '[PRE11]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We now have two Open3D objects: APointCloud with 7 103 848 points and a Triangle
    Mesh with 674 points and 488 triangles. Let us see what that means, shall we?'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨æœ‰ä¸¤ä¸ª Open3D å¯¹è±¡ï¼šä¸€ä¸ªåŒ…å« 7 103 848 ä¸ªç‚¹çš„ APointCloud å’Œä¸€ä¸ªåŒ…å« 674 ä¸ªç‚¹å’Œ 488 ä¸ªä¸‰è§’å½¢çš„ä¸‰è§’ç½‘æ ¼ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ„å‘³ç€ä»€ä¹ˆï¼Œå¥½å—ï¼Ÿ
- en: 3.3\. Python 3D Visualization
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3\. Python 3D å¯è§†åŒ–
- en: 'To visualize in Open3D different 3D objects, we have to pass a **python list**
    of holding these Open3D objects. Our list is thus composed of one Open3D `PointCloud`,
    and one Open3D `TriangleMesh`, which gives `[pcd_o3d,mesh]`. Let us visualize
    this combination in a standalone window with the following:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨ Open3D ä¸­å¯è§†åŒ–ä¸åŒçš„ 3D å¯¹è±¡ï¼Œæˆ‘ä»¬å¿…é¡»ä¼ é€’ä¸€ä¸ªåŒ…å«è¿™äº› Open3D å¯¹è±¡çš„ **python åˆ—è¡¨**ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„åˆ—è¡¨ç”±ä¸€ä¸ª Open3D
    `PointCloud` å’Œä¸€ä¸ª Open3D `TriangleMesh` ç»„æˆï¼Œå³ `[pcd_o3d, mesh]`ã€‚è®©æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹ä»£ç åœ¨ç‹¬ç«‹çª—å£ä¸­å¯è§†åŒ–è¿™ä¸ªç»„åˆï¼š
- en: '[PRE12]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'ğŸ¦š **Note**: *The line above will create an interactive Open3D window that combines
    the 3D point cloud and the 3D mesh.*'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*ä¸Šé¢çš„ä»£ç è¡Œå°†åˆ›å»ºä¸€ä¸ªäº¤äº’å¼çš„ Open3D çª—å£ï¼Œç»“åˆäº† 3D ç‚¹äº‘å’Œ 3D ç½‘æ ¼ã€‚*
- en: 'To play with the colors to display, there is one handy trick: using a color
    variable that we will pass to the colors attribute of the PointCloud Open3D object.
    This variable should hold R, G, B float values ranging from `O` to `1`.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è°ƒæ•´æ˜¾ç¤ºçš„é¢œè‰²ï¼Œæœ‰ä¸€ä¸ªå®ç”¨çš„æŠ€å·§ï¼šä½¿ç”¨ä¸€ä¸ªé¢œè‰²å˜é‡ï¼Œè¯¥å˜é‡å°†ä¼ é€’ç»™ PointCloud Open3D å¯¹è±¡çš„é¢œè‰²å±æ€§ã€‚æ­¤å˜é‡åº”åŒ…å«ä» `0` åˆ° `1`
    çš„ Rã€Gã€B æµ®ç‚¹å€¼ã€‚
- en: '![](../Images/18551016caa1227467965bcf70bb8738.png)![](../Images/3cff291b433da91c893721c7d6b934e7.png)![](../Images/e5a4d747c0c69f956eeb40c7e9454e05.png)![](../Images/e12a344c10402c875344a31f1a3f84a7.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/18551016caa1227467965bcf70bb8738.png)![](../Images/3cff291b433da91c893721c7d6b934e7.png)![](../Images/e5a4d747c0c69f956eeb40c7e9454e05.png)![](../Images/e12a344c10402c875344a31f1a3f84a7.png)'
- en: 'ğŸ¦š **Note**: *Do you see the slight difference between both screenshots? On
    the right side, we can better delineate the borders, and we have a bit more of
    a depth impression (this is more noticeable interactively). This is because, in
    the second case, we also use normals for visualization. To do that, you can run
    the line* `pcd_o3d.estimate_normals()` *and* `mesh.compute_vertex_normals()` *before
    running the visualization part. Enjoy* ğŸ˜‰'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*ä½ æ˜¯å¦æ³¨æ„åˆ°ä¸¤ä¸ªæˆªå›¾ä¹‹é—´çš„ç»†å¾®å·®åˆ«ï¼Ÿå³ä¾§æˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°å‹¾å‹’å‡ºè¾¹ç•Œï¼Œå¹¶ä¸”æœ‰æ›´å¼ºçš„æ·±åº¦æ„Ÿï¼ˆè¿™åœ¨äº¤äº’å¼æ“ä½œä¸­æ›´ä¸ºæ˜æ˜¾ï¼‰ã€‚è¿™æ˜¯å› ä¸ºåœ¨ç¬¬äºŒç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨äº†æ³•çº¿è¿›è¡Œå¯è§†åŒ–ã€‚è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½ å¯ä»¥åœ¨è¿è¡Œå¯è§†åŒ–éƒ¨åˆ†ä¹‹å‰è¿è¡Œ*
    `pcd_o3d.estimate_normals()` *å’Œ* `mesh.compute_vertex_normals()` *ã€‚äº«å—å§* ğŸ˜‰
- en: 'Let us say that we want to visualize the point cloud colored based on the classification
    attribute. What we thus need to do is to follow this four-stage process:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æƒ³è¦æ ¹æ®åˆ†ç±»å±æ€§å¯è§†åŒ–ç‚¹äº‘ã€‚æˆ‘ä»¬éœ€è¦éµå¾ªä»¥ä¸‹å››é˜¶æ®µè¿‡ç¨‹ï¼š
- en: '![](../Images/3f448bdbc8c3545587c308f4e2c961e2.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f448bdbc8c3545587c308f4e2c961e2.png)'
- en: The concept workflow to use classification as a color for Open3D.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åˆ†ç±»ä½œä¸ºOpen3Dé¢œè‰²çš„æ¦‚å¿µå·¥ä½œæµç¨‹ã€‚
- en: 'If you carefully notice, this then translates into code such as:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä»”ç»†è§‚å¯Ÿï¼Œè¿™å°†è½¬æ¢ä¸ºå¦‚ä¸‹ä»£ç ï¼š
- en: '![](../Images/3fa8055f2ac49a7fb61ac506f2745632.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fa8055f2ac49a7fb61ac506f2745632.png)'
- en: The code workflow to use classification as a color for Open3D.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åˆ†ç±»ä½œä¸ºOpen3Dé¢œè‰²çš„ä»£ç å·¥ä½œæµç¨‹ã€‚
- en: '[PRE13]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'ğŸ¦š **Note**: *Because we want to have a hand on the color of each class, we
    can adapt the code above to the number of unique classes. Then, the correspondence
    is done based on the* [*LAS (1.4) Specifications*](https://www.asprs.org/wp-content/uploads/2010/12/LAS_Specification.pdf)*.*'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*å› ä¸ºæˆ‘ä»¬å¸Œæœ›å¯¹æ¯ä¸ªç±»åˆ«çš„é¢œè‰²è¿›è¡Œæ§åˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®å”¯ä¸€ç±»åˆ«çš„æ•°é‡è°ƒæ•´ä¸Šè¿°ä»£ç ã€‚ç„¶åï¼Œæ˜ å°„æ˜¯åŸºäº* [*LAS (1.4) è§„èŒƒ*](https://www.asprs.org/wp-content/uploads/2010/12/LAS_Specification.pdf)*è¿›è¡Œçš„ã€‚*
- en: '![](../Images/4cb0fbe0068e65ff012e850ddb032d3d.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cb0fbe0068e65ff012e850ddb032d3d.png)'
- en: ASPRS Standard Point Classes of the LAS LiDAR data specifications file format.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: LAS LiDARæ•°æ®è§„æ ¼æ–‡ä»¶æ ¼å¼çš„ASPRSæ ‡å‡†ç‚¹ç±»åˆ«ã€‚
- en: 'We could visualize the results that would give something like this (with different
    colors depending on the `R,G,B` values inputted):'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å¯è§†åŒ–ç»“æœï¼Œç±»ä¼¼äºè¿™æ ·ï¼ˆæ ¹æ®è¾“å…¥çš„`R,G,B`å€¼æ˜¾ç¤ºä¸åŒçš„é¢œè‰²ï¼‰ï¼š
- en: '![](../Images/445de1239d521084b27fe5e0e32d8e8d.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/445de1239d521084b27fe5e0e32d8e8d.png)'
- en: Open3D interactive multi-modal data visualization. Â© Author.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Open3Däº¤äº’å¼å¤šæ¨¡å¼æ•°æ®å¯è§†åŒ–ã€‚Â© ä½œè€…ã€‚
- en: We have variables loaded, we can see both the point cloud and the 3D Mesh, and
    everything looks like it is working smoothly! Time to define the various 3D City
    Analytical tasks we want to do!
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»åŠ è½½äº†å˜é‡ï¼Œå¯ä»¥çœ‹åˆ°ç‚¹äº‘å’Œ3Dç½‘æ ¼ï¼Œä¸€åˆ‡çœ‹èµ·æ¥è¿è¡Œé¡ºç•…ï¼ç°åœ¨æ˜¯å®šä¹‰æˆ‘ä»¬æƒ³è¦è¿›è¡Œçš„å„ç§3DåŸå¸‚åˆ†æä»»åŠ¡çš„æ—¶åˆ»ï¼
- en: 3.4\. 3D City Analysis
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4. 3DåŸå¸‚åˆ†æ
- en: '3D city analysis refers to the process of using three-dimensional (3D) models
    of urban environments to analyze and understand various aspects of the built environment,
    such as building energy performance, urban morphology, and pedestrian movement.
    This analysis typically involves using specialized paradigms and conducting analyses
    to gain insights into urban planning and design. 3D city analysis can be used
    by urban planners, architects, and engineers to inform decisions about the placement
    of infrastructure, the design of public spaces, and the mitigation of various
    environmental impacts. In this tutorial, we will touch on three main aspects of
    3D City Analysis:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 3DåŸå¸‚åˆ†ææŒ‡çš„æ˜¯ä½¿ç”¨åŸå¸‚ç¯å¢ƒçš„ä¸‰ç»´ï¼ˆ3Dï¼‰æ¨¡å‹æ¥åˆ†æå’Œç†è§£å»ºç­‘ç¯å¢ƒçš„å„ç§æ–¹é¢ï¼Œå¦‚å»ºç­‘èƒ½æºæ€§èƒ½ã€åŸå¸‚å½¢æ€å’Œè¡ŒäººæµåŠ¨ã€‚è¿™ç§åˆ†æé€šå¸¸æ¶‰åŠä½¿ç”¨ä¸“ä¸šèŒƒå¼å’Œè¿›è¡Œåˆ†æï¼Œä»¥è·å¾—æœ‰å…³åŸå¸‚è§„åˆ’å’Œè®¾è®¡çš„è§è§£ã€‚3DåŸå¸‚åˆ†æå¯ä¾›åŸå¸‚è§„åˆ’å¸ˆã€å»ºç­‘å¸ˆå’Œå·¥ç¨‹å¸ˆä½¿ç”¨ï¼Œä»¥æä¾›æœ‰å…³åŸºç¡€è®¾æ–½å¸ƒç½®ã€å…¬å…±ç©ºé—´è®¾è®¡å’Œå„ç§ç¯å¢ƒå½±å“ç¼“è§£çš„å†³ç­–ä¿¡æ¯ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ¶‰åŠ3DåŸå¸‚åˆ†æçš„ä¸‰ä¸ªä¸»è¦æ–¹é¢ï¼š
- en: '1\. Urban Morphology analysis: We can use Python to analyze the shape and form
    of buildings in 3D city dataset, which can help inform decisions about urban design
    and planning.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 1. åŸå¸‚å½¢æ€åˆ†æï¼šæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Pythonåˆ†æ3DåŸå¸‚æ•°æ®é›†ä¸­å»ºç­‘ç‰©çš„å½¢çŠ¶å’Œå½¢å¼ï¼Œè¿™å¯ä»¥å¸®åŠ©æä¾›æœ‰å…³åŸå¸‚è®¾è®¡å’Œè§„åˆ’çš„å†³ç­–ã€‚
- en: '2\. Geospatial Znalysis: We can perform geospatial analysis on the city model,
    such as identifying the optimal location for new infrastructure projects based
    on factors such as accessibility and environmental impact.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. åœ°ç†ç©ºé—´åˆ†æï¼šæˆ‘ä»¬å¯ä»¥å¯¹åŸå¸‚æ¨¡å‹è¿›è¡Œåœ°ç†ç©ºé—´åˆ†æï¼Œä¾‹å¦‚æ ¹æ®å¯è¾¾æ€§å’Œç¯å¢ƒå½±å“ç­‰å› ç´ ç¡®å®šæ–°åŸºç¡€è®¾æ–½é¡¹ç›®çš„æœ€ä½³ä½ç½®ã€‚
- en: '3\. 3D Visualization: We can create interactive 3D visualizations, which can
    help stakeholders better understand and engage with urban planning and design
    projects.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 3D å¯è§†åŒ–ï¼šæˆ‘ä»¬å¯ä»¥åˆ›å»ºäº¤äº’å¼ 3D å¯è§†åŒ–ï¼Œè¿™å¯ä»¥å¸®åŠ©åˆ©ç›Šç›¸å…³è€…æ›´å¥½åœ°ç†è§£å’Œå‚ä¸åŸå¸‚è§„åˆ’å’Œè®¾è®¡é¡¹ç›®ã€‚
- en: Therefore, this step is specialized to one application, where we do most of
    the analysis. We illustrate on 3D City Analysis, which we extend in section 4,
    through the various Python Challenges, as illustrated below.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè¿™ä¸€æ­¥ä¸“é—¨ç”¨äºä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè¿›è¡Œå¤§éƒ¨åˆ†åˆ†æã€‚æˆ‘ä»¬åœ¨ 3D åŸå¸‚åˆ†æä¸­è¿›è¡Œæ¼”ç¤ºï¼Œå¹¶åœ¨ç¬¬4èŠ‚é€šè¿‡å„ç§ Python æŒ‘æˆ˜è¿›è¡Œæ‰©å±•ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/bed78e8f4aea28f4d8fcfef513f4121b.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bed78e8f4aea28f4d8fcfef513f4121b.png)'
- en: '3D Analysis in the context of cities, and its decomposition in Step 4: 3D Python
    Challenges (Section 4).'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå¸‚èƒŒæ™¯ä¸‹çš„ 3D åˆ†æåŠå…¶åœ¨ç¬¬4æ­¥ä¸­çš„åˆ†è§£ï¼š3D Python æŒ‘æˆ˜ï¼ˆç¬¬4èŠ‚ï¼‰ã€‚
- en: However, we can follow a common workflow, adapted to each application, which
    is usually composed of an input, a processing pipeline, and an output for each
    specific analytical part.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œæˆ‘ä»¬å¯ä»¥éµå¾ªä¸€ä¸ªé€šç”¨çš„å·¥ä½œæµç¨‹ï¼Œé€‚åº”äºæ¯ä¸ªåº”ç”¨ç¨‹åºï¼Œé€šå¸¸ç”±è¾“å…¥ã€å¤„ç†ç®¡é“å’Œæ¯ä¸ªç‰¹å®šåˆ†æéƒ¨åˆ†çš„è¾“å‡ºç»„æˆã€‚
- en: '![](../Images/1e05945cdf9c74f35899860f253e8508.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e05945cdf9c74f35899860f253e8508.png)'
- en: The conceptual workflow from input to output in the context of point cloud data.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ¦‚å¿µæ€§å·¥ä½œæµç¨‹ï¼Œé€‚ç”¨äºç‚¹äº‘æ•°æ®ã€‚
- en: The input can vary, but in most cases, it is a NumPy array that holds the spatial
    information. The output can be an integer, a list, another NumPy array, â€¦ Anything
    you need in return. ğŸ˜
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å…¥å¯ä»¥æœ‰æ‰€ä¸åŒï¼Œä½†åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŒ…å«ç©ºé—´ä¿¡æ¯çš„ NumPy æ•°ç»„ã€‚è¾“å‡ºå¯ä»¥æ˜¯ä¸€ä¸ªæ•´æ•°ã€ä¸€ä¸ªåˆ—è¡¨ã€å¦ä¸€ä¸ª NumPy æ•°ç»„â€¦â€¦ä½ éœ€è¦çš„ä»»ä½•ä¸œè¥¿ã€‚ğŸ˜
- en: 'ğŸ¦š **Note**: *This specific stage is dense, and we will leave some space in
    our notebook for the different analyses linked to the challenges we will see in
    Step 4\. For now, let us move to define some way to export our data.*'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*è¿™ä¸ªç‰¹å®šé˜¶æ®µæ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬å°†åœ¨ç¬”è®°æœ¬ä¸­ç•™å‡ºä¸€äº›ç©ºé—´ï¼Œç”¨äºè®°å½•ä¸ç¬¬4æ­¥æŒ‘æˆ˜ç›¸å…³çš„ä¸åŒåˆ†æã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€äº›æ–¹æ³•æ¥å¯¼å‡ºæˆ‘ä»¬çš„æ•°æ®ã€‚*
- en: 3.5\. 3D Multi-Modal Export
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.5\. 3D å¤šæ¨¡æ€å¯¼å‡º
- en: After our 3D pipeline is fully functional, we can save the results to one or
    more files to work them outside Python. For this, we will use two valuable possibilities.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ 3D ç®¡é“å®Œå…¨åŠŸèƒ½åï¼Œæˆ‘ä»¬å¯ä»¥å°†ç»“æœä¿å­˜åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶ä¸­ï¼Œä»¥ä¾¿åœ¨ Python ä¹‹å¤–å¤„ç†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸¤ç§æœ‰ä»·å€¼çš„å¯èƒ½æ€§ã€‚
- en: '**Numpy (Recommended for complex outputs):** We can export with Numpy with
    the following line of code: `np.savetxt(result_folder+pc_dataset.split(â€œ.â€)[0]+â€_selection.xyzâ€,
    np.asarray(o3d_parcel_corners),delimiter=â€™;â€™, fmt=â€™%1.9fâ€™)`'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Numpyï¼ˆæ¨èç”¨äºå¤æ‚è¾“å‡ºï¼‰ï¼š** æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç è¡Œé€šè¿‡ Numpy å¯¼å‡ºï¼š`np.savetxt(result_folder+pc_dataset.split(â€œ.â€)[0]+â€_selection.xyzâ€,
    np.asarray(o3d_parcel_corners),delimiter=â€™;â€™, fmt=â€™%1.9fâ€™)`'
- en: '**Open3D (Recommended when needing only spatial attributes):** We can Export
    with Open3D with the following line of code: `o3d.io.write_point_cloud(result_folder+pc_dataset.split(â€œ.â€)[0]+â€_result_filtered_o3d.plyâ€,
    pcd_selection, write_ascii=False, compressed=False, print_progress=False)`'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Open3Dï¼ˆæ¨èä»…éœ€ç©ºé—´å±æ€§æ—¶ä½¿ç”¨ï¼‰ï¼š** æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç è¡Œé€šè¿‡ Open3D å¯¼å‡ºï¼š`o3d.io.write_point_cloud(result_folder+pc_dataset.split(â€œ.â€)[0]+â€_result_filtered_o3d.plyâ€,
    pcd_selection, write_ascii=False, compressed=False, print_progress=False)`'
- en: '*ğŸ¦š* **Note***: the* `.split(â€œ.â€)`*allows to split the* `pc_dataset` *string
    object into a list of two strings, before and after the* `.`*, an then we keep
    only the first element with* `[0]`*. The NumPy exports a variable* `o3d_parcel_corners`
    *stage wit a delimiter ; in a* `.xyz` *ASCII file. The Open3D will write a* `.ply`
    *file from the open3d object* `pcd_selection` *.*'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '*ğŸ¦š* **æ³¨æ„**ï¼š*`.split(â€œ.â€)`*å…è®¸å°†*`pc_dataset`*å­—ç¬¦ä¸²å¯¹è±¡æ‹†åˆ†ä¸ºä¸¤ä¸ªå­—ç¬¦ä¸²çš„åˆ—è¡¨ï¼Œåˆ†åˆ«åœ¨*`.`*ä¹‹å‰å’Œä¹‹åï¼Œç„¶åæˆ‘ä»¬ä»…ä¿ç•™ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œä½¿ç”¨*`[0]`*ã€‚NumPy
    å°†ä¸€ä¸ªå˜é‡*`o3d_parcel_corners`*çš„é˜¶æ®µä»¥åˆ†éš”ç¬¦ ; å¯¼å‡ºåˆ°ä¸€ä¸ª*.xyz* ASCII æ–‡ä»¶ä¸­ã€‚Open3D å°†ä» open3d å¯¹è±¡*`pcd_selection`*ä¸­å†™å…¥ä¸€ä¸ª*.ply*
    æ–‡ä»¶ã€‚*'
- en: 'Wow, well done! The Python Automation bulk structure is up and running! Congratulation!
    We have the libraries imported, the datasets are stored in different explicit
    variables, and we ensure we can deal with various visualization without leaving
    the comfort of Python. The Export step is set up; all that is left is to target
    the initial question we had in Step 4:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: å“‡ï¼Œå¹²å¾—å¥½ï¼Python è‡ªåŠ¨åŒ–çš„æ‰¹é‡ç»“æ„å·²ç»è¿è¡Œèµ·æ¥äº†ï¼æ­å–œï¼æˆ‘ä»¬å·²ç»å¯¼å…¥äº†åº“ï¼Œæ•°æ®é›†è¢«å­˜å‚¨åœ¨ä¸åŒçš„æ˜¾å¼å˜é‡ä¸­ï¼Œæˆ‘ä»¬ç¡®ä¿å¯ä»¥å¤„ç†å„ç§å¯è§†åŒ–è€Œæ— éœ€ç¦»å¼€
    Python çš„èˆ’é€‚ç¯å¢ƒã€‚å¯¼å‡ºæ­¥éª¤å·²è®¾ç½®å®Œæˆï¼›å‰©ä¸‹çš„å°±æ˜¯è§£å†³æˆ‘ä»¬åœ¨ç¬¬4æ­¥ä¸­æå‡ºçš„åˆå§‹é—®é¢˜ï¼š
- en: How dense is the built area of the neighborhood around our house? Can the house
    be subject to flooding? Am I respecting the built ratio for the parcel I own?
  id: totrans-263
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æˆ¿å­å‘¨å›´çš„å»ºç­‘åŒºåŸŸæœ‰å¤šå¯†é›†ï¼Ÿæˆ¿å­æ˜¯å¦å¯èƒ½ä¼šå—åˆ°æ´ªæ°´å½±å“ï¼Ÿæˆ‘æ˜¯å¦éµå®ˆäº†æˆ‘æ‹¥æœ‰åœ°å—çš„å»ºç­‘æ¯”ä¾‹ï¼Ÿ
- en: Step 4\. 3D Python Challenges
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 4. 3D Python æŒ‘æˆ˜
- en: To answer the questions above, we will find a solution to four challenges and
    voxelization steps, as illustrated below.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å›ç­”ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬å°†æ‰¾åˆ°è§£å†³å››ä¸ªæŒ‘æˆ˜å’Œä½“ç´ åŒ–æ­¥éª¤çš„æ–¹æ¡ˆï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: '![](../Images/4b3d247558729a28d903f154c58610c7.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b3d247558729a28d903f154c58610c7.png)'
- en: 'Step 4: 3D Python Challenges. We investigate Point of Interest queries, Manual
    Boundary selection, High point extraction, voxelization and built coverage extraction.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 4ï¼š3D Python æŒ‘æˆ˜ã€‚æˆ‘ä»¬ç ”ç©¶å…´è¶£ç‚¹æŸ¥è¯¢ã€æ‰‹åŠ¨è¾¹ç•Œé€‰æ‹©ã€é«˜ç‚¹æå–ã€ä½“ç´ åŒ–å’Œå»ºç­‘è¦†ç›–æå–ã€‚
- en: Challenge 1 will permit cropping out the study zone to the desired neighborhood.
    Challenge 2 will permit to extract a built ratio for the owned parcel. Challenge
    3 guides the flooding analysis. And Challenge 4, with a voxelization beforehand,
    will allow getting the built coverage of the area of interest. Let us get started.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‘æˆ˜ 1 å°†å…è®¸è£å‰ªå‡ºæ‰€éœ€çš„ç ”ç©¶åŒºåŸŸã€‚æŒ‘æˆ˜ 2 å°†å…è®¸æå–æ‰€æ‹¥æœ‰åœ°å—çš„å»ºç­‘æ¯”ä¾‹ã€‚æŒ‘æˆ˜ 3 æŒ‡å¯¼æ´ªæ°´åˆ†æã€‚è€ŒæŒ‘æˆ˜ 4ï¼Œç»è¿‡ä½“ç´ åŒ–å¤„ç†åï¼Œå°†å…è®¸è·å–æ„Ÿå…´è¶£åŒºåŸŸçš„å»ºç­‘è¦†ç›–æƒ…å†µã€‚è®©æˆ‘ä»¬å¼€å§‹å§ã€‚
- en: 4.1\. Point of Interest Query
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1. å…´è¶£ç‚¹æŸ¥è¯¢
- en: 'For this challenge, we start with an input that comprises a 3D `PointCloud`
    Open3D Object and a `TriangleMesh` Open3D Object, as illustrated below:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªæŒ‘æˆ˜ï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªåŒ…å« 3D `PointCloud` Open3D å¯¹è±¡å’Œ `TriangleMesh` Open3D å¯¹è±¡çš„è¾“å…¥å¼€å§‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/76e8121f7bd21325fbe30c9778a0856b.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76e8121f7bd21325fbe30c9778a0856b.png)'
- en: A 3D Point Cloud with a 3D mesh object. Â© F. Poux
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¸¦æœ‰ 3D ç½‘æ ¼å¯¹è±¡çš„ 3D ç‚¹äº‘ã€‚Â© F. Poux
- en: 'The objective of this challenge is to keep only the data points that fall within
    a certain distance from your point of interest, the building house. Our inputs
    are the point cloud and the mesh, and our output is the filtered point cloud which
    answers the distance to the POI criterion as shown below:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæŒ‘æˆ˜çš„ç›®æ ‡æ˜¯åªä¿ç•™è½åœ¨å…´è¶£ç‚¹ï¼ˆå»ºç­‘æˆ¿å±‹ï¼‰ä¸€å®šè·ç¦»å†…çš„æ•°æ®ç‚¹ã€‚æˆ‘ä»¬çš„è¾“å…¥æ˜¯ç‚¹äº‘å’Œç½‘æ ¼ï¼Œè¾“å‡ºæ˜¯ç»è¿‡è¿‡æ»¤çš„ç‚¹äº‘ï¼Œç¬¦åˆåˆ° POI è·ç¦»çš„æ ‡å‡†ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/6a9063effb3862f75a508f44428c39cc.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a9063effb3862f75a508f44428c39cc.png)'
- en: 'To get there, I set up a six-stage process as illustrated below:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘è®¾ç½®äº†ä¸€ä¸ªå…­é˜¶æ®µçš„è¿‡ç¨‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/6453feea2a7852e03490303e8fd1d213.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6453feea2a7852e03490303e8fd1d213.png)'
- en: The Conceptual Workflow for a radius search in a 3D Point Cloud. Â© Author.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ç‚¹äº‘åŠå¾„æœç´¢çš„æ¦‚å¿µå·¥ä½œæµã€‚Â© ä½œè€…ã€‚
- en: 'ğŸ“ **Learning Note**: *The goal is to try to sort things out on your own and
    check back if you have troubles. Whenever you are ready, you can read the solution
    below.* ğŸ‘‡'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“ **å­¦ä¹ ç¬”è®°**ï¼š*ç›®æ ‡æ˜¯å°½é‡è‡ªå·±è§£å†³é—®é¢˜ï¼Œå¦‚æœé‡åˆ°å›°éš¾å¯ä»¥æŸ¥çœ‹ä¸‹é¢çš„è§£å†³æ–¹æ¡ˆã€‚å‡†å¤‡å¥½åï¼Œå¯ä»¥é˜…è¯»ä¸‹é¢çš„è§£å†³æ–¹æ¡ˆã€‚* ğŸ‘‡
- en: '(1) To set the distance threshold, we pass the radius value we want to use
    as a threshold (E.g., `50`) to a new variable `dist_POI`. (2) Then, we get the
    POI from the BAG dataset `mesh` using the `get_center()` Open3D method of the
    Mesh object. This permits getting the center of the mesh as a POI: `POI=mesh.get_center()`.
    We can, after that, create a KD-tree (3), a data structure used to organize points
    in space. KD trees are helpful for point cloud processing because they allow for
    fast nearest-neighbor searches and range queries. These are good news then because
    this is what we are doing ğŸ˜. Indeed, using a KD-tree makes it possible to find
    the points closest to a given point quickly, or all the points within a certain
    distance (our POI), without having to search through all the points in the point
    cloud.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: (1) è®¾ç½®è·ç¦»é˜ˆå€¼æ—¶ï¼Œæˆ‘ä»¬å°†æ‰€éœ€çš„åŠå¾„å€¼ï¼ˆä¾‹å¦‚ `50`ï¼‰ä¼ é€’ç»™æ–°å˜é‡ `dist_POI`ã€‚ (2) ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ Mesh å¯¹è±¡çš„ `get_center()`
    Open3D æ–¹æ³•ä» BAG æ•°æ®é›†ä¸­è·å– POIã€‚è¿™å…è®¸è·å–ç½‘æ ¼çš„ä¸­å¿ƒä½œä¸º POIï¼š`POI=mesh.get_center()`ã€‚ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»º KD
    æ ‘ (3)ï¼Œä¸€ç§ç”¨äºç»„ç»‡ç©ºé—´ä¸­ç‚¹çš„æ•°æ®ç»“æ„ã€‚KD æ ‘å¯¹ç‚¹äº‘å¤„ç†éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒä»¬å…è®¸å¿«é€Ÿè¿›è¡Œæœ€è¿‘é‚»æœç´¢å’ŒèŒƒå›´æŸ¥è¯¢ã€‚è¿™æ˜¯å¥½æ¶ˆæ¯ï¼Œå› ä¸ºè¿™æ­£æ˜¯æˆ‘ä»¬è¦åšçš„ ğŸ˜ã€‚å®é™…ä¸Šï¼Œä½¿ç”¨
    KD æ ‘å¯ä»¥å¿«é€Ÿæ‰¾åˆ°ç¦»ç»™å®šç‚¹æœ€è¿‘çš„ç‚¹ï¼Œæˆ–è€…æ‰€æœ‰åœ¨ä¸€å®šè·ç¦»å†…çš„ç‚¹ï¼ˆæˆ‘ä»¬çš„ POIï¼‰ï¼Œè€Œæ— éœ€éå†ç‚¹äº‘ä¸­çš„æ‰€æœ‰ç‚¹ã€‚
- en: '[PRE14]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'ğŸ¦š **Note**: *The KD-Tree works by recursively partitioning the space into smaller
    regions, dividing it along the median of one of the dimensions at each level (*`X`
    *is a dimension,* `Y` *another,* `Z` *another* ğŸ˜‰*). This results in a â€œtreeâ€ structure
    where each node represents a space partition, and each leaf node represents a
    single point.*'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*KD-Tree é€šè¿‡é€’å½’åœ°å°†ç©ºé—´åˆ’åˆ†ä¸ºè¾ƒå°çš„åŒºåŸŸï¼Œæ¯ä¸ªçº§åˆ«æ²¿ä¸€ä¸ªç»´åº¦çš„ä¸­ä½æ•°è¿›è¡Œåˆ’åˆ†ï¼ˆ*`X` *æ˜¯ä¸€ä¸ªç»´åº¦ï¼Œ* `Y` *æ˜¯å¦ä¸€ä¸ªï¼Œ*
    `Z` *æ˜¯å¦ä¸€ä¸ª* ğŸ˜‰*ï¼‰ã€‚è¿™ä¼šç”Ÿæˆä¸€ä¸ªâ€œæ ‘â€ç»“æ„ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªç©ºé—´åˆ†åŒºï¼Œæ¯ä¸ªå¶å­èŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªå•ç‹¬çš„ç‚¹ã€‚*
- en: 'From there, we can then use the `search_radius_vector_3d()` method of Open3D
    and select the points from the output index: to finally visualize our result (`4`+`5`+`6`):'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ Open3D çš„ `search_radius_vector_3d()` æ–¹æ³•ï¼Œå¹¶ä»è¾“å‡ºç´¢å¼•ä¸­é€‰æ‹©ç‚¹ï¼šæœ€åå¯è§†åŒ–æˆ‘ä»¬çš„ç»“æœï¼ˆ`4`+`5`+`6`ï¼‰ï¼š
- en: '[PRE15]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can finally visualize our results (6):'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ€ç»ˆå¯ä»¥å¯è§†åŒ–æˆ‘ä»¬çš„ç»“æœï¼ˆ6ï¼‰ï¼š
- en: '[PRE16]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/01cce6fda16a7553c4811b3f1eccd17f.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01cce6fda16a7553c4811b3f1eccd17f.png)'
- en: The 3D Point Cloud and Mesh underlay of the radius search.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: åŠå¾„æœç´¢ä¸‹çš„ 3D ç‚¹äº‘å’Œç½‘æ ¼å åŠ ã€‚
- en: 'Which amount, all in all, to the following code pipeline:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»å…±æ¶‰åŠä»¥ä¸‹ä»£ç ç®¡é“ï¼š
- en: '![](../Images/ca75475c8f727b0c5dd5067e69a82134.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca75475c8f727b0c5dd5067e69a82134.png)'
- en: The Code workflow of the radius search.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: åŠå¾„æœç´¢çš„ä»£ç å·¥ä½œæµã€‚
- en: Very good! Now that you have a working solution let us extract the parcel area
    from that selection.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: éå¸¸å¥½ï¼ç°åœ¨ä½ æœ‰äº†ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œè®©æˆ‘ä»¬ä»é‚£ä¸ªé€‰æ‹©ä¸­æå–åœ°å—é¢ç§¯ã€‚
- en: 4.2\. Manual Boundaries Selection
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2\. æ‰‹åŠ¨è¾¹ç•Œé€‰æ‹©
- en: To extract the unofficial boundaries, we have to move onto some semi-automated
    and interactive approach. The good news is that we can do that directly within
    Python with Open3D.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æå–éå®˜æ–¹è¾¹ç•Œï¼Œæˆ‘ä»¬éœ€è¦é‡‡ç”¨ä¸€äº›åŠè‡ªåŠ¨å’Œäº’åŠ¨çš„æ–¹æ³•ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åœ¨ Python ä¸­ä½¿ç”¨ Open3D æ¥å®Œæˆè¿™é¡¹å·¥ä½œã€‚
- en: 'The first thing to do is to create an interactive Open3D window with the following
    `draw_geometries_with_vertex_selection()` method:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆéœ€è¦åˆ›å»ºä¸€ä¸ªå¸¦æœ‰ä»¥ä¸‹ `draw_geometries_with_vertex_selection()` æ–¹æ³•çš„äº’åŠ¨ Open3D çª—å£ï¼š
- en: '[PRE17]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You can then follow the animated part below, which allows selecting the points
    that define the corners of your parcel.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå¯ä»¥è·Ÿéšä¸‹é¢çš„åŠ¨ç”»éƒ¨åˆ†ï¼Œè¿™å…è®¸é€‰æ‹©å®šä¹‰åœ°å—è§’è½çš„ç‚¹ã€‚
- en: '![](../Images/2ec4c396a33dc3162d115db29197734f.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ec4c396a33dc3162d115db29197734f.png)'
- en: The Manual Boundary selection Interactive Process, using Open3D GUI and holding
    the MAJ+Mouse to select points of interest.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰‹åŠ¨è¾¹ç•Œé€‰æ‹©çš„äº’åŠ¨è¿‡ç¨‹ï¼Œä½¿ç”¨ Open3D GUI å¹¶æŒ‰ä½ MAJ+é¼ æ ‡é€‰æ‹©æ„Ÿå…´è¶£çš„ç‚¹ã€‚
- en: The results will then appear in the results under your cell in your notebook
    (or your REPL) upon closing the window.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå°†å‡ºç°åœ¨ä½ çš„ç¬”è®°æœ¬ï¼ˆæˆ– REPLï¼‰ä¸­çš„å•å…ƒæ ¼ä¸‹æ–¹ï¼Œå…³é—­çª—å£åå³å¯æŸ¥çœ‹ã€‚
- en: 'ğŸ¦š **Note**: *It may be easier at this step to use the* `R`*,* `G`*,* `B` *coloring.
    You would thus have to move back to change this before the selection if you want
    to work with the correct indexes.* ğŸ˜‰ *If you want to extract the cadastral boundary*,
    *this is feasible, by importing the official 2D vector shape and cutting based
    on this data constraint.*'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œä½¿ç”¨* `R`*ã€* `G`*ã€* `B` *ç€è‰²å¯èƒ½æ›´å®¹æ˜“ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨æƒ³ä½¿ç”¨æ­£ç¡®çš„ç´¢å¼•ï¼Œéœ€è¦åœ¨é€‰æ‹©å‰è¿”å›è¿›è¡Œæ›´æ”¹ã€‚*
    ğŸ˜‰ *å¦‚æœæ‚¨æƒ³æå–åœ°ç±è¾¹ç•Œ*ï¼Œ*å¯ä»¥é€šè¿‡å¯¼å…¥å®˜æ–¹çš„ 2D çŸ¢é‡å›¾å½¢å¹¶æ ¹æ®æ­¤æ•°æ®çº¦æŸè¿›è¡Œè£å‰ªæ¥å®ç°ã€‚*
- en: 'From your REPL, you can copy and paste the different indexes (E.g., `34335`,`979`
    ,`21544`,`19666`,`5924`,`21816`,`38008`) of the selected points into the `select_by_index()`
    selection method to define a `o3d_parcel_corners` variable:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä½ çš„ REPL ä¸­ï¼Œä½ å¯ä»¥å°†é€‰å®šç‚¹çš„ä¸åŒç´¢å¼•ï¼ˆä¾‹å¦‚ `34335`ã€`979`ã€`21544`ã€`19666`ã€`5924`ã€`21816`ã€`38008`ï¼‰å¤åˆ¶å¹¶ç²˜è´´åˆ°
    `select_by_index()` é€‰æ‹©æ–¹æ³•ä¸­ï¼Œä»¥å®šä¹‰ `o3d_parcel_corners` å˜é‡ï¼š
- en: '[PRE18]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We still have to prepare the corners further because we want to avoid considering
    the `Z` value. Therefore, we will filter out the coordinates to drop the Z value,
    but beware: doing this means that we consider that we are in a flat area (which
    is the case in the Netherlands ğŸ˜‰).'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»ç„¶éœ€è¦è¿›ä¸€æ­¥å‡†å¤‡è§’è½ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³é¿å…è€ƒè™‘ `Z` å€¼ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†è¿‡æ»¤åæ ‡ä»¥å»æ‰ Z å€¼ï¼Œä½†è¦æ³¨æ„ï¼šè¿™æ ·åšæ„å‘³ç€æˆ‘ä»¬è®¤ä¸ºæˆ‘ä»¬åœ¨ä¸€ä¸ªå¹³å¦åŒºåŸŸï¼ˆè¿™åœ¨è·å…°æ˜¯äº‹å®
    ğŸ˜‰ï¼‰ã€‚
- en: '[PRE19]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'From there, it is time to compute the area of the parcel with the `Shapely`
    library! For this, we can directly use `Polygon` function first to create a polygon
    out of the set of provided corners:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œï¼Œæ¥ä¸‹æ¥ä½¿ç”¨ `Shapely` åº“è®¡ç®—åœ°å—çš„é¢ç§¯ï¼ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ `Polygon` å‡½æ•°é¦–å…ˆä»æä¾›çš„è§’è½é›†åˆä¸­åˆ›å»ºä¸€ä¸ªå¤šè¾¹å½¢ï¼š
- en: '[PRE20]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Which outputs the following:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå¦‚ä¸‹ï¼š
- en: '![](../Images/ea3f386608dbe0efefe779723d4ad548.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea3f386608dbe0efefe779723d4ad548.png)'
- en: wrong geometry
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: é”™è¯¯çš„å‡ ä½•å½¢çŠ¶
- en: 'This looks somewhat wrong, doesnâ€™t it? If you do not believe me, we can compute
    the area to check:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœ‹èµ·æ¥æœ‰ç‚¹ä¸å¯¹ï¼Œæ˜¯å§ï¼Ÿå¦‚æœä½ ä¸ç›¸ä¿¡æˆ‘ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—é¢ç§¯æ¥æ£€æŸ¥ï¼š
- en: '[PRE21]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Which outputs `43.583 mÂ²`. That sounds weird for a big building, doesnâ€™t it?
    Ha, a simple problem becomes a bit more complicated! Indeed, the problem here
    is that computing the area needs a polygon that is constituted in a way we obtain
    a closed shape. This is not always the case because the order corners have been
    added to the data structure. Thus, the problem becomes sorting out the coordinates
    to avoid any edges intersection.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šè¾“å‡º`43.583 mÂ²`ã€‚å¯¹äºä¸€ä¸ªå¤§å»ºç­‘æ¥è¯´ï¼Œè¿™å¬èµ·æ¥å¾ˆå¥‡æ€ªï¼Œä¸æ˜¯å—ï¼Ÿå“ˆå“ˆï¼Œä¸€ä¸ªç®€å•çš„é—®é¢˜å˜å¾—æœ‰ç‚¹å¤æ‚äº†ï¼å®é™…ä¸Šï¼Œè¿™é‡Œçš„é—®é¢˜åœ¨äºè®¡ç®—é¢ç§¯éœ€è¦ä¸€ä¸ªç”±å¤šè¾¹å½¢ç»„æˆçš„é—­åˆå½¢çŠ¶ã€‚è¿™å¹¶ä¸æ€»æ˜¯èƒ½å®ç°ï¼Œå› ä¸ºæ·»åŠ è§’ç‚¹çš„é¡ºåºå¯èƒ½ä¼šå½±å“æ•°æ®ç»“æ„ã€‚å› æ­¤ï¼Œé—®é¢˜å˜æˆäº†æ’åºåæ ‡ä»¥é¿å…è¾¹ç¼˜äº¤å‰ã€‚
- en: 'One way of dealing with the problem is to perceive all coordinates from the
    perspective of the center point. We can then compute the angle between each corner
    in the list and our center point. We do this to have an idea of how wide the individual
    angles are and therefore provide us with the means tosort out the coordinates
    based on their values. Translating this into code allows defining a sorting function
    as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯ä»ä¸­å¿ƒç‚¹çš„è§’åº¦æ¥çœ‹æ‰€æœ‰åæ ‡ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—åˆ—è¡¨ä¸­æ¯ä¸ªè§’ç‚¹ä¸ä¸­å¿ƒç‚¹ä¹‹é—´çš„è§’åº¦ã€‚æˆ‘ä»¬è¿™æ ·åšæ˜¯ä¸ºäº†äº†è§£æ¯ä¸ªè§’åº¦çš„å®½åº¦ï¼Œä»è€Œæä¾›æ’åºåæ ‡çš„æ‰‹æ®µã€‚å°†å…¶ç¿»è¯‘æˆä»£ç å…è®¸å®šä¹‰ä¸€ä¸ªæ’åºå‡½æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE22]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'ğŸ¦š **Note**: *I use the NumPy* `arctan2()` *method to perform angle estimation
    for every coordinate. This will return the array of angles in radians. All thatâ€™s
    left is to sort out the angles in ascending order to receive a list of indices
    in the correct order. The list can then fix the original list indices with the*
    `argsort()` *method. At this step, it will not work with U-shape buildings.*'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*æˆ‘ä½¿ç”¨ NumPy* `arctan2()` *æ–¹æ³•å¯¹æ¯ä¸ªåæ ‡è¿›è¡Œè§’åº¦ä¼°ç®—ã€‚è¿™å°†è¿”å›ä»¥å¼§åº¦è¡¨ç¤ºçš„è§’åº¦æ•°ç»„ã€‚å‰©ä¸‹çš„å·¥ä½œæ˜¯å°†è§’åº¦æŒ‰å‡åºæ’åºï¼Œä»¥è·å–æ­£ç¡®é¡ºåºçš„ç´¢å¼•åˆ—è¡¨ã€‚ç„¶åï¼Œåˆ—è¡¨å¯ä»¥ä½¿ç”¨*
    `argsort()` *æ–¹æ³•ä¿®æ­£åŸå§‹åˆ—è¡¨çš„ç´¢å¼•ã€‚åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œå®ƒä¸é€‚ç”¨äº U å½¢å»ºç­‘ã€‚*
- en: 'From there, we can apply our sorting function to the corners, create a new
    sorted variable, compute the polygon and the associated area:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: ä»é‚£é‡Œï¼Œæˆ‘ä»¬å¯ä»¥å°†æ’åºå‡½æ•°åº”ç”¨äºè§’ç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ’åºå˜é‡ï¼Œè®¡ç®—å¤šè¾¹å½¢åŠå…¶ç›¸å…³é¢ç§¯ï¼š
- en: '[PRE23]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This returns the following polygon with an area of `2 247.14 mÂ²`, which is much
    more plausible. ğŸ˜‰
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¿”å›äº†ä¸€ä¸ªé¢ç§¯ä¸º`2 247.14 mÂ²`çš„å¤šè¾¹å½¢ï¼Œè¿™æ›´ä¸ºå¯ä¿¡ã€‚ğŸ˜‰
- en: '![](../Images/5d875c3360117687f6b52f9bace96f7e.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d875c3360117687f6b52f9bace96f7e.png)'
- en: right geometry
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£ç¡®çš„å‡ ä½•å½¢çŠ¶
- en: Well done again. We now have a good idea of the area of our parcel. Now, let
    us find the high and low points in the zone
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡åšå¾—å¾ˆå¥½ã€‚æˆ‘ä»¬ç°åœ¨å¯¹æˆ‘ä»¬åœ°å—çš„é¢ç§¯æœ‰äº†ä¸€ä¸ªä¸é”™çš„äº†è§£ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨åŒºåŸŸå†…æ‰¾åˆ°é«˜ç‚¹å’Œä½ç‚¹ã€‚
- en: 4.3\. Find high and low points
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3\. æŸ¥æ‰¾é«˜ç‚¹å’Œä½ç‚¹
- en: 'To get the low and high points of the area, one specific way would be to use
    the `get_max_bound()` and `get_min_bound()` methods of Open3D:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è·å–åŒºåŸŸçš„ä½ç‚¹å’Œé«˜ç‚¹ï¼Œä¸€ç§ç‰¹å®šçš„æ–¹æ³•æ˜¯ä½¿ç”¨ Open3D çš„`get_max_bound()`å’Œ`get_min_bound()`æ–¹æ³•ï¼š
- en: '[PRE24]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'However, doing this will not hint which point is the highest and which is the
    lowest. What we need are the point indexes to retrieve the coordinates after that.
    For this, I propose that we code it this way:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œè¿™æ ·åšä¸ä¼šæç¤ºå“ªä¸ªç‚¹æ˜¯æœ€é«˜çš„ï¼Œå“ªä¸ªç‚¹æ˜¯æœ€ä½çš„ã€‚æˆ‘ä»¬éœ€è¦çš„æ˜¯ç‚¹çš„ç´¢å¼•ï¼Œä»¥ä¾¿åœ¨ä¹‹åæ£€ç´¢åæ ‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘å»ºè®®æˆ‘ä»¬è¿™æ ·ç¼–ç ï¼š
- en: We create a NumPy array object, `np_pcd_selection`, from the Open3D PointCloud
    object that holds only the `X`,`Y` and `Z` coordinates.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä» Open3D PointCloud å¯¹è±¡ä¸­åˆ›å»ºä¸€ä¸ª NumPy æ•°ç»„å¯¹è±¡`np_pcd_selection`ï¼Œè¯¥å¯¹è±¡ä»…åŒ…å«`X`ã€`Y`å’Œ`Z`åæ ‡ã€‚
- en: We gather the indexes of the min and max values over the `Z` dimension with
    the `argmax()` method and store the results in the variables `lowest_point_index`
    and `highest_point_index`.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`argmax()`æ–¹æ³•æ”¶é›†`Z`ç»´åº¦ä¸Šçš„æœ€å°å€¼å’Œæœ€å¤§å€¼çš„ç´¢å¼•ï¼Œå¹¶å°†ç»“æœå­˜å‚¨åœ¨å˜é‡`lowest_point_index`å’Œ`highest_point_index`ä¸­ã€‚
- en: '[PRE25]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let us check the results by selecting using the indexes, creating `TriangleMesh`
    Spheres, translating them to the position of the points, and then visualizing
    with Open3D:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡é€‰æ‹©ç´¢å¼•ï¼Œåˆ›å»º`TriangleMesh`çƒä½“ï¼Œå°†å®ƒä»¬è½¬æ¢åˆ°ç‚¹çš„ä½ç½®ï¼Œç„¶åä½¿ç”¨ Open3D è¿›è¡Œå¯è§†åŒ–æ¥æ£€æŸ¥ç»“æœï¼š
- en: '[PRE26]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As shown below, we now have our 3D scene with the high and low points.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸‹æ‰€ç¤ºï¼Œæˆ‘ä»¬ç°åœ¨æœ‰äº†åŒ…å«é«˜ç‚¹å’Œä½ç‚¹çš„ 3D åœºæ™¯ã€‚
- en: '![](../Images/3184931216ccb57af6023a5964685cfa.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3184931216ccb57af6023a5964685cfa.png)'
- en: Let us study the building coverage in an extended vicinity of 350 meters. For
    this, we will re-execute the code for some parts, as explained below.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åœ¨ 350 ç±³çš„æ‰©å±•åŒºåŸŸå†…ç ”ç©¶å»ºç­‘è¦†ç›–æƒ…å†µã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†é‡æ–°æ‰§è¡Œä»£ç ä¸­çš„æŸäº›éƒ¨åˆ†ï¼Œå¦‚ä¸‹æ‰€è¿°ã€‚
- en: 4.4\. Point Cloud Voxelization
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4\. ç‚¹äº‘ä½“ç´ åŒ–
- en: 'We want to extract the built coverage. For this, we will take an intuitive
    approach by first transforming the point cloud modality to a filled analog of
    the 2D pixels: 3D voxels. This will allow us to pursue the following methodology:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æƒ³è¦æå–å·²å»ºç«‹çš„è¦†ç›–èŒƒå›´ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†é‡‡å–ä¸€ç§ç›´è§‚çš„æ–¹æ³•ï¼Œé¦–å…ˆå°†ç‚¹äº‘çš„æ¨¡å¼è½¬æ¢ä¸º2Dåƒç´ çš„å¡«å……æ¨¡æ‹Ÿï¼š3Dä½“ç´ ã€‚è¿™å°†å…è®¸æˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š
- en: '![](../Images/b6ed77cf8ddc61af78175af10bfa9c2f.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6ed77cf8ddc61af78175af10bfa9c2f.png)'
- en: Extracting high points by constructing a 3D voxel data structure. We first voxelize
    the point cloud, then we color each voxel from a binary perspective, and then
    we filter by top-down indexes. Â© F. Poux
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ„å»º3Dä½“ç´ æ•°æ®ç»“æ„æ¥æå–é«˜ç‚¹ã€‚æˆ‘ä»¬é¦–å…ˆå¯¹ç‚¹äº‘è¿›è¡Œä½“ç´ åŒ–ï¼Œç„¶åä»äºŒè¿›åˆ¶è§’åº¦å¯¹æ¯ä¸ªä½“ç´ ä¸Šè‰²ï¼Œæœ€åæŒ‰è‡ªä¸Šè€Œä¸‹çš„ç´¢å¼•è¿›è¡Œç­›é€‰ã€‚Â© F. Poux
- en: Basically, we will (1) generate voxels where points exist, then (2) we will
    color the voxels based on the classification of the points they hold, and finally,
    we will filter the voxels to keep and count only the highest voxel per X,Y coordinate.
    This way, we can avoid counting elements that would bias the built coverage.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬ä¸Šï¼Œæˆ‘ä»¬å°†ï¼ˆ1ï¼‰ç”Ÿæˆå­˜åœ¨ç‚¹çš„ä½“ç´ ï¼Œç„¶åï¼ˆ2ï¼‰æ ¹æ®ä½“ç´ æ‰€æŒæœ‰çš„ç‚¹çš„åˆ†ç±»å¯¹ä½“ç´ ä¸Šè‰²ï¼Œæœ€åï¼Œæˆ‘ä»¬å°†ç­›é€‰ä½“ç´ ï¼Œåªä¿ç•™å’Œè®¡æ•°æ¯ä¸ªX,Yåæ ‡çš„æœ€é«˜ä½“ç´ ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é¿å…è®¡æ•°é‚£äº›ä¼šåå‘å·²å»ºç«‹è¦†ç›–èŒƒå›´çš„å…ƒç´ ã€‚
- en: 'The first step is to create a voxel grid. This is where Open3D shines: with
    these simple lines of code, we can fit a voxel grid to the point cloud, where
    each voxel is a cube of 20 cm, then visualize the results:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€æ­¥æ˜¯åˆ›å»ºä¸€ä¸ªä½“ç´ ç½‘æ ¼ã€‚è¿™æ˜¯Open3Dçš„å¼ºé¡¹ï¼šé€šè¿‡è¿™äº›ç®€å•çš„ä»£ç è¡Œï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸€ä¸ªä½“ç´ ç½‘æ ¼é€‚é…åˆ°ç‚¹äº‘ä¸­ï¼Œæ¯ä¸ªä½“ç´ æ˜¯ä¸€ä¸ª20 cmçš„ç«‹æ–¹ä½“ï¼Œç„¶åå¯è§†åŒ–ç»“æœï¼š
- en: '[PRE27]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](../Images/fd12edaca914ab554fbe335093ad0e41.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd12edaca914ab554fbe335093ad0e41.png)'
- en: A View of the 3D voxel data structure. Â© F. Poux
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 3D ä½“ç´ æ•°æ®ç»“æ„çš„è§†å›¾ã€‚Â© F. Poux
- en: 'ğŸ¦š **Note**: *The result you see has been through a change in the coloring of
    the voxels beforehand. This change means, with Open3D, that we have to change
    the color of the voxelâ€™s points. Then, the VoxelGrid method will average the colors
    and retain the result as a color for the voxel.*'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¦š **æ³¨æ„**ï¼š*æ‚¨çœ‹åˆ°çš„ç»“æœå·²ç»ç»è¿‡ä½“ç´ ä¸Šè‰²çš„å˜åŒ–ã€‚è¿™ä¸ªå˜åŒ–æ„å‘³ç€ï¼Œä½¿ç”¨Open3Dæ—¶ï¼Œæˆ‘ä»¬å¿…é¡»æ›´æ”¹ä½“ç´ ç‚¹çš„é¢œè‰²ã€‚ç„¶åï¼ŒVoxelGridæ–¹æ³•å°†å¹³å‡è¿™äº›é¢œè‰²ï¼Œå¹¶å°†ç»“æœä¿ç•™ä¸ºä½“ç´ çš„é¢œè‰²ã€‚*
- en: 'Now that we know how to generate 3D voxels from point clouds let us play on
    their color scheme to bypass the coloring averaging problem. For this, a simple
    way would be to handle the color in a binary way. Either it is black ([0,0,0])
    or not (all the rest). This means that we can initialize the colors variable to
    0, and then select all the points which are classified as a building, and give
    them another color, E.g., Red ([1,0,0]):'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çŸ¥é“å¦‚ä½•ä»ç‚¹äº‘ç”Ÿæˆ3Dä½“ç´ ï¼Œè®©æˆ‘ä»¬é€šè¿‡æ”¹å˜å®ƒä»¬çš„é¢œè‰²æ–¹æ¡ˆæ¥ç»•è¿‡é¢œè‰²å¹³å‡çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä¸€ä¸ªç®€å•çš„æ–¹æ³•æ˜¯ä»¥äºŒè¿›åˆ¶æ–¹å¼å¤„ç†é¢œè‰²ã€‚å³é»‘è‰²ï¼ˆ[0,0,0]ï¼‰æˆ–å…¶ä»–é¢œè‰²ï¼ˆæ‰€æœ‰å…¶ä»–é¢œè‰²ï¼‰ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å°†é¢œè‰²å˜é‡åˆå§‹åŒ–ä¸º0ï¼Œç„¶åé€‰æ‹©æ‰€æœ‰è¢«åˆ†ç±»ä¸ºå»ºç­‘çš„ç‚¹ï¼Œå¹¶èµ‹äºˆå®ƒä»¬å¦ä¸€ç§é¢œè‰²ï¼Œä¾‹å¦‚çº¢è‰²ï¼ˆ[1,0,0]ï¼‰ï¼š
- en: '[PRE28]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Very nice! Now, because we played with the original point cloud, we will need
    to redefine the POI and the selection to our choosing. For the sake of efficiency,
    you will find the code block that you can run to update your voxel rendering to
    the new color scheme:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: éå¸¸å¥½ï¼ç°åœ¨ï¼Œç”±äºæˆ‘ä»¬å¯¹åŸå§‹ç‚¹äº‘è¿›è¡Œäº†æ“ä½œï¼Œæˆ‘ä»¬éœ€è¦æ ¹æ®è‡ªå·±çš„é€‰æ‹©é‡æ–°å®šä¹‰POIå’Œé€‰æ‹©ã€‚ä¸ºäº†æé«˜æ•ˆç‡ï¼Œæ‚¨ä¼šæ‰¾åˆ°å¯ä»¥è¿è¡Œçš„ä»£ç å—ï¼Œä»¥æ›´æ–°ä½“ç´ æ¸²æŸ“åˆ°æ–°çš„é¢œè‰²æ–¹æ¡ˆï¼š
- en: '[PRE29]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](../Images/8fe6067757404ffe3a2d928221c50c0a.png)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8fe6067757404ffe3a2d928221c50c0a.png)'
- en: The binary coloured point cloud. Â© F. Poux
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: äºŒè¿›åˆ¶ç€è‰²çš„ç‚¹äº‘ã€‚Â© F. Poux
- en: 'Awesome! now, we need to actually get the discrete integer indexes of each
    voxel in a list, as well as the colors and the bounds. This will permit us to
    loop over each voxel and its color later to check if a voxel is the highest in
    a â€œvoxel column.â€ To do this, an efficient way is to do a list comprehension to
    vectorize our computation and avoid unnecessary loops:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ï¼ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦å®é™…è·å–æ¯ä¸ªä½“ç´ çš„ç¦»æ•£æ•´æ•°ç´¢å¼•ï¼Œå¹¶å°†å®ƒä»¬åˆ—å‡ºï¼Œè¿˜æœ‰ä½“ç´ çš„é¢œè‰²å’Œè¾¹ç•Œã€‚è¿™å°†å…è®¸æˆ‘ä»¬ä¹‹åéå†æ¯ä¸ªä½“ç´ åŠå…¶é¢œè‰²ï¼Œæ£€æŸ¥ä¸€ä¸ªä½“ç´ æ˜¯å¦åœ¨â€œä½“ç´ åˆ—â€ä¸­æ˜¯æœ€é«˜çš„ã€‚ä¸ºæ­¤ï¼Œä¸€ä¸ªæœ‰æ•ˆçš„æ–¹æ³•æ˜¯ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æ¥å‘é‡åŒ–æˆ‘ä»¬çš„è®¡ç®—ï¼Œé¿å…ä¸å¿…è¦çš„å¾ªç¯ï¼š
- en: '[PRE30]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This is awesome! On a selection of 50 meters, we have a grid of 49 x 49x 16
    voxels, which amounts to 38 416 filled voxels. Time to extract the built coverage!
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªæ£’äº†ï¼åœ¨50ç±³çš„é€‰æ‹©åŒºåŸŸä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ª49 x 49 x 16çš„ä½“ç´ ç½‘æ ¼ï¼Œæ€»å…±æœ‰38,416ä¸ªå¡«å……çš„ä½“ç´ ã€‚ç°åœ¨æ˜¯æå–å·²å»ºç«‹çš„è¦†ç›–èŒƒå›´çš„æ—¶å€™äº†ï¼
- en: 4.5\. Extract the Built Coverage
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5\. æå–å·²å»ºç«‹çš„è¦†ç›–èŒƒå›´
- en: 'Now that we have a voxelized point cloud with binary colors, we focus on the
    third stage of the illustration below:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå…·æœ‰äºŒè¿›åˆ¶é¢œè‰²çš„ä½“ç´ åŒ–ç‚¹äº‘ï¼Œæˆ‘ä»¬ä¸“æ³¨äºä¸‹å›¾çš„ç¬¬ä¸‰é˜¶æ®µï¼š
- en: '![](../Images/f9bc143b7fc885997f06c2ae9dffff23.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9bc143b7fc885997f06c2ae9dffff23.png)'
- en: As we see, selecting only the top voxels is a bit more complex than it seems!
    ğŸ˜ But lucky you, I designed a simple yet robust pipeline that will do just that,
    below.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œé€‰æ‹©ä»…é¡¶å±‚ä½“ç´ æ¯”çœ‹èµ·æ¥å¤æ‚ä¸€äº›ï¼ğŸ˜ ä½†å¹¸è¿çš„æ˜¯ï¼Œæˆ‘è®¾è®¡äº†ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„ç®¡é“ï¼Œå¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œè§ä¸‹æ–‡ã€‚
- en: '![](../Images/f0032781dab39f48d3a5d500f98e2246.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0032781dab39f48d3a5d500f98e2246.png)'
- en: The Voxel Selection Workflow to extract the built coverage in seven sub-step.
    Â© F. Poux.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: ä½“ç´ é€‰æ‹©å·¥ä½œæµä»¥ä¸ƒä¸ªå­æ­¥éª¤æå–å·²å»ºæˆçš„è¦†ç›–èŒƒå›´ã€‚Â© F. Pouxã€‚
- en: Let us go through it step by step.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ¥ã€‚
- en: '(1) First, we initialize two dictionaries that hold the max indices:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: (1) é¦–å…ˆï¼Œæˆ‘ä»¬åˆå§‹åŒ–ä¸¤ä¸ªå­—å…¸æ¥ä¿å­˜æœ€å¤§ç´¢å¼•ï¼š
- en: '[PRE31]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '(2 to 5) We loop over all filled voxels to check if they are the highest in
    a voxel column or to be dropped, which gives the following for loop :'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: (2åˆ°5) æˆ‘ä»¬éå†æ‰€æœ‰å¡«å……çš„ä½“ç´ ï¼Œä»¥æ£€æŸ¥å®ƒä»¬æ˜¯å¦åœ¨ä½“ç´ åˆ—ä¸­æœ€é«˜æˆ–åº”è¢«ä¸¢å¼ƒï¼Œè¿™ç»™å‡ºäº†ä»¥ä¸‹forå¾ªç¯ï¼š
- en: '[PRE32]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'ğŸ¦š **Note**: *The first thing to notice is the* `enumerate()` *method in the
    loop definition. This permits looping over each value of the variable* `idx_voxels`
    *while keeping track of the index of the list. Handy! The second thing is that
    we are using the â€œtuplesâ€ data type as* `(X, Y)` *, which gives the integer position
    of our voxel. This permits us to ensure that we are continuously checking on the
    identical* `X`*,*`Y` *grid position. Finally, the â€œ*`if`*â€ statement permits testing
    the expressed condition and will execute if the condition returns* `True`*. If
    it does not, it will execute the* `else` *statement (in the case there is one)
    or pass and exit the condition check.*'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦š **æ³¨æ„**: *é¦–å…ˆè¦æ³¨æ„çš„æ˜¯å¾ªç¯å®šä¹‰ä¸­çš„* `enumerate()` *æ–¹æ³•ã€‚è¿™å…è®¸åœ¨å¾ªç¯* `idx_voxels` *å˜é‡çš„æ¯ä¸ªå€¼æ—¶è·Ÿè¸ªåˆ—è¡¨çš„ç´¢å¼•ã€‚å¾ˆæ–¹ä¾¿ï¼ç¬¬äºŒç‚¹æ˜¯æˆ‘ä»¬ä½¿ç”¨â€œå…ƒç»„â€æ•°æ®ç±»å‹ï¼Œå¦‚*
    `(X, Y)`*ï¼Œè¿™ç»™å‡ºäº†ä½“ç´ çš„æ•´æ•°ä½ç½®ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿç¡®ä¿æˆ‘ä»¬æŒç»­æ£€æŸ¥ç›¸åŒçš„* `X`*ã€* `Y` *ç½‘æ ¼ä½ç½®ã€‚æœ€åï¼Œâ€œ*`if`*â€è¯­å¥å…è®¸æµ‹è¯•è¡¨è¾¾çš„æ¡ä»¶ï¼Œå¹¶åœ¨æ¡ä»¶è¿”å›*
    `True`*æ—¶æ‰§è¡Œã€‚å¦‚æœæ¡ä»¶ä¸ä¸º* `True`*ï¼Œåˆ™æ‰§è¡Œ* `else` *è¯­å¥ï¼ˆå¦‚æœå­˜åœ¨ï¼‰æˆ–è·³è¿‡å¹¶é€€å‡ºæ¡ä»¶æ£€æŸ¥ã€‚*'
- en: '(6) We initialize the counts of voxels tagged as built or non-built, and we
    check if the color of the top voxel retained is black or not, in which case we
    update the voxel count of the respective category:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: (6) æˆ‘ä»¬åˆå§‹åŒ–æ ‡è®°ä¸ºå·²å»ºæˆæˆ–æœªå»ºæˆçš„ä½“ç´ çš„è®¡æ•°ï¼Œå¹¶æ£€æŸ¥ä¿ç•™çš„é¡¶éƒ¨ä½“ç´ çš„é¢œè‰²æ˜¯å¦ä¸ºé»‘è‰²ï¼Œå¦‚æœæ˜¯ï¼Œæˆ‘ä»¬æ›´æ–°ç›¸åº”ç±»åˆ«çš„ä½“ç´ è®¡æ•°ï¼š
- en: '[PRE33]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'ğŸ¦š **Note**: `np.all()` *is also a boolean check and will return* `True` *only
    if all values within are* `True`*. In our case, the black color is* `[0,0,0]`*,
    which will thus return* `True` *because all* `R`*,* `G`*, and* `B` *are set to*
    `0` *in this case. If one of them is not zero, that means that not all are* `0`
    *and the* `np.all()` *will return* `False`*, which will trigger the* `else` *statement.
    Easy?* ğŸ˜‰'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ¦š **æ³¨æ„**: `np.all()` *ä¹Ÿæ˜¯ä¸€ä¸ªå¸ƒå°”æ£€æŸ¥ï¼Œåªä¼šåœ¨æ‰€æœ‰å€¼éƒ½æ˜¯* `True` *æ—¶è¿”å›* `True`ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œé»‘è‰²æ˜¯* `[0,0,0]`*ï¼Œå› æ­¤è¿”å›*
    `True` *ï¼Œå› ä¸ºæ‰€æœ‰* `R`*ã€* `G`* å’Œ* `B` *éƒ½è®¾ç½®ä¸º* `0`ã€‚å¦‚æœå…¶ä¸­ä¸€ä¸ªä¸æ˜¯é›¶ï¼Œåˆ™æ„å‘³ç€å¹¶éæ‰€æœ‰å€¼éƒ½æ˜¯* `0`*ï¼Œ`np.all()`
    *å°†è¿”å›* `False`*ï¼Œè¿™ä¼šè§¦å‘* `else` *è¯­å¥ã€‚ç®€å•å§ï¼Ÿ* ğŸ˜‰'
- en: '(7) We can extract the area covered for each type (built and non-built) without
    forgetting to multiply the count variable by the actual 2D voxel area (4 mÂ² in
    our case) and get the ratio:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: (7) æˆ‘ä»¬å¯ä»¥æå–æ¯ç§ç±»å‹ï¼ˆå·²å»ºæˆå’Œæœªå»ºæˆï¼‰çš„è¦†ç›–åŒºåŸŸï¼Œè®°å¾—å°†è®¡æ•°å˜é‡ä¹˜ä»¥å®é™…çš„2Dä½“ç´ é¢ç§¯ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ä¸º4å¹³æ–¹ç±³ï¼‰ï¼Œå¹¶è®¡ç®—æ¯”ç‡ï¼š
- en: '[PRE34]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This gives us, for 50 meters, a coverage of 17.3%, which amount to 1352 mÂ² of
    built area and 6456 mÂ² belonging to the rest. (19.2%, 73416 mÂ² and 308280 mÂ² for
    the 350 meters query).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·ï¼Œå¯¹äº50ç±³çš„èŒƒå›´ï¼Œæˆ‘ä»¬çš„è¦†ç›–ç‡ä¸º17.3%ï¼Œç›¸å½“äº1352å¹³æ–¹ç±³çš„å·²å»ºæˆåŒºåŸŸå’Œ6456å¹³æ–¹ç±³çš„å…¶ä½™åŒºåŸŸã€‚ï¼ˆ350ç±³æŸ¥è¯¢çš„è¦†ç›–ç‡ä¸º19.2%ï¼Œ73416å¹³æ–¹ç±³å’Œ308280å¹³æ–¹ç±³ï¼‰ã€‚
- en: So, we have a nice balance of building occupation on the selected point of interest
    compared to the rest!
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¸å…¶ä½™éƒ¨åˆ†ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨é€‰å®šçš„å…´è¶£ç‚¹ä¸Šæœ‰ä¸€ä¸ªå¾ˆå¥½çš„å»ºç­‘å ç”¨å¹³è¡¡ï¼
- en: Hopefully, putting our 3D Python Workflow to the test was not too nerve-wracking!
    Feel free to return regularly to the code and workflow snippets to master the
    hidden code tricks that permit (1) to answer with brio the challenges and (2)
    optimize the efficiency of our implementation.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›æµ‹è¯•æˆ‘ä»¬çš„3D Pythonå·¥ä½œæµå¹¶æ²¡æœ‰è®©ä½ æ„Ÿåˆ°å¤ªç´§å¼ ï¼éšæ—¶è¿”å›æŸ¥çœ‹ä»£ç å’Œå·¥ä½œæµç‰‡æ®µï¼ŒæŒæ¡éšè—çš„ä»£ç æŠ€å·§ï¼Œä»¥ä¾¿ï¼ˆ1ï¼‰å‡ºè‰²åœ°åº”å¯¹æŒ‘æˆ˜å’Œï¼ˆ2ï¼‰ä¼˜åŒ–æˆ‘ä»¬å®ç°çš„æ•ˆç‡ã€‚
- en: '![](../Images/7c041bc073b2d234e2497baf19ce1a09.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c041bc073b2d234e2497baf19ce1a09.png)'
- en: Yet, some room remains left for tweaking, such as using the classification information
    combined with the high-low POI to isolate the ground point for water flows or
    using the parcel surface selection as a filtering technique for built coverage
    extraction.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œä»ç„¶æœ‰ä¸€äº›è°ƒæ•´ç©ºé—´ï¼Œä¾‹å¦‚ä½¿ç”¨åˆ†ç±»ä¿¡æ¯ç»“åˆé«˜ä½POIæ¥éš”ç¦»æ°´æµçš„åœ°é¢ç‚¹ï¼Œæˆ–ä½¿ç”¨åœ°å—è¡¨é¢é€‰æ‹©ä½œä¸ºè¿‡æ»¤æŠ€æœ¯æ¥æå–å·²å»ºæˆçš„è¦†ç›–èŒƒå›´ã€‚
- en: 'ğŸ’» Direct access to the hands-on code: [Google Colab](https://colab.research.google.com/drive/1vvPOYZtUMx2zUxDczakv6XDUq0Ram21y)'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ’» ç›´æ¥è®¿é—®å®æ“ä»£ç ï¼š[Google Colab](https://colab.research.google.com/drive/1vvPOYZtUMx2zUxDczakv6XDUq0Ram21y)
- en: 'ğŸª„ Direct access to Point Cloud Processing: [Github](https://github.com/florentPoux/point-cloud-processing)'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸª„ ç›´æ¥è®¿é—®ç‚¹äº‘å¤„ç†ï¼š[Github](https://github.com/florentPoux/point-cloud-processing)
- en: 'ğŸ§™â€â™‚ï¸ Direct access to Point Cloud Courses: [3D Academy](https://learngeodata.eu)'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ§™â€â™‚ï¸ ç›´æ¥è®¿é—®ç‚¹äº‘è¯¾ç¨‹ï¼š[3D Academy](https://learngeodata.eu)
- en: ğŸ”® Conclusion
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ”® ç»“è®º
- en: Congratulations! This was an actual giant first leap in the world of 3D Python
    Workflows using LiDAR for City Modelling! The pipeline that we constructed below
    is very generic and can be considered a point of reference for your future analytical
    work, which likely follows a similar pattern.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: æ­å–œï¼è¿™åœ¨ä½¿ç”¨ LiDAR è¿›è¡ŒåŸå¸‚å»ºæ¨¡çš„ 3D Python å·¥ä½œæµç¨‹é¢†åŸŸæ˜¯ä¸€ä¸ªçœŸæ­£çš„å·¨å¤§ç¬¬ä¸€æ­¥ï¼æˆ‘ä»¬ä¸‹é¢æ„å»ºçš„æµç¨‹éå¸¸é€šç”¨ï¼Œå¯ä»¥ä½œä¸ºä½ æœªæ¥åˆ†æå·¥ä½œçš„å‚è€ƒç‚¹ï¼Œè¿™äº›å·¥ä½œå¯èƒ½ä¼šéµå¾ªç±»ä¼¼çš„æ¨¡å¼ã€‚
- en: '![](../Images/35a2f7dccc19d471620463aa5284aeb7.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35a2f7dccc19d471620463aa5284aeb7.png)'
- en: The 3D Python Workflow in the context of LiDAR City Models. We start with the
    Environment Set up (Step 1) and 3D Data Preparation (Step 2). Once this is done,
    we move on to Python Automation (Step 3), with a specific part dealing with 3D
    Python Challenges (Step 4), such as Parcel Surface or Point Of Interest Queries.
    Â© Author
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ LiDAR åŸå¸‚æ¨¡å‹èƒŒæ™¯ä¸‹çš„ 3D Python å·¥ä½œæµç¨‹ã€‚æˆ‘ä»¬ä»ç¯å¢ƒè®¾ç½®ï¼ˆæ­¥éª¤ 1ï¼‰å’Œ 3D æ•°æ®å‡†å¤‡ï¼ˆæ­¥éª¤ 2ï¼‰å¼€å§‹ã€‚ä¸€æ—¦å®Œæˆè¿™äº›æ­¥éª¤ï¼Œæˆ‘ä»¬å°†è¿›å…¥
    Python è‡ªåŠ¨åŒ–ï¼ˆæ­¥éª¤ 3ï¼‰ï¼Œå…¶ä¸­ä¸€ä¸ªç‰¹å®šéƒ¨åˆ†æ¶‰åŠ 3D Python æŒ‘æˆ˜ï¼ˆæ­¥éª¤ 4ï¼‰ï¼Œå¦‚åœ°å—è¡¨é¢æˆ–å…´è¶£ç‚¹æŸ¥è¯¢ã€‚Â© ä½œè€…
- en: 'To summarize the new skills you unlocked, you can now efficiently address the
    following challenges:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“ä¸€ä¸‹ä½ è§£é”çš„æ–°æŠ€èƒ½ï¼Œä½ ç°åœ¨å¯ä»¥é«˜æ•ˆåœ°åº”å¯¹ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- en: Combining Open-Source Software with Python in a coherent workflow;
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å¼€æºè½¯ä»¶ä¸ Python ç»“åˆæˆä¸€ä¸ªè¿è´¯çš„å·¥ä½œæµç¨‹ï¼›
- en: Gathering Open datasets and preparing them before processing;
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ”¶é›†å¼€æ”¾æ•°æ®é›†å¹¶åœ¨å¤„ç†ä¹‹å‰å‡†å¤‡å¥½å®ƒä»¬ï¼›
- en: Processing 3D Data Modalities, especially 3D Point Clouds, 3D Meshes and 3D
    Voxels with 3D Python;
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ 3D Python å¤„ç† 3D æ•°æ®æ¨¡å¼ï¼Œç‰¹åˆ«æ˜¯ 3D ç‚¹äº‘ã€3D ç½‘æ ¼å’Œ 3D ä½“ç´ ï¼›
- en: Using critical aspects of each 3D Modality for Advanced Geospatial Analysis
    while optimizing the code;
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¯ç§ 3D æ¨¡å¼çš„å…³é”®æ–¹é¢è¿›è¡Œé«˜çº§åœ°ç†ç©ºé—´åˆ†æï¼ŒåŒæ—¶ä¼˜åŒ–ä»£ç ï¼›
- en: Extracting Key insights as a City Planner to better understand a local area
    based on the classified point cloud.
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½œä¸ºåŸå¸‚è§„åˆ’å¸ˆä»åˆ†ç±»ç‚¹äº‘ä¸­æå–å…³é”®æ´å¯Ÿï¼Œä»¥æ›´å¥½åœ°ç†è§£æœ¬åœ°åŒºåŸŸã€‚
- en: If you feel in control and able to address these different aspects, then you
    are on the path to becoming a great 3D Geospatial Professional! The only thing
    to do is to keep up the effort and push existing boundaries.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ„Ÿåˆ°è‡ªå·±èƒ½å¤ŸæŒæ¡å¹¶å¤„ç†è¿™äº›ä¸åŒçš„æ–¹é¢ï¼Œé‚£ä¹ˆä½ æ­£èµ°åœ¨æˆä¸ºä¼Ÿå¤§çš„ 3D åœ°ç†ç©ºé—´ä¸“ä¸šäººå£«çš„é“è·¯ä¸Šï¼å”¯ä¸€éœ€è¦åšçš„å°±æ˜¯ä¿æŒåŠªåŠ›ï¼Œæ¨åŠ¨ç°æœ‰çš„è¾¹ç•Œã€‚
- en: ğŸ¤¿ Going Further
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ¤¿ æ›´è¿›ä¸€æ­¥
- en: But the learning journey does not end here. Our lifelong search begins, and
    future steps will dive into deepening 3D Voxel work, exploring semantics, CityGML,
    CityJSON, and especially how to get from Clever to Smart Cities. On top, we will
    analyze point clouds with deep learning techniques and unlock advanced 3D LiDAR
    analytical workflows. A lot to be excited about!
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å­¦ä¹ æ—…ç¨‹å¹¶æœªå°±æ­¤ç»“æŸã€‚æˆ‘ä»¬çš„ç»ˆèº«æ¢ç´¢æ‰åˆšåˆšå¼€å§‹ï¼Œæœªæ¥çš„æ­¥éª¤å°†æ·±å…¥ç ”ç©¶ 3D ä½“ç´ å·¥ä½œï¼Œæ¢ç´¢è¯­ä¹‰ã€CityGMLã€CityJSONï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•ä»èªæ˜çš„åŸå¸‚èµ°å‘æ™ºæ…§åŸå¸‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯åˆ†æç‚¹äº‘ï¼Œå¹¶è§£é”é«˜çº§
    3D LiDAR åˆ†æå·¥ä½œæµç¨‹ã€‚æœ‰å¾ˆå¤šä»¤äººå…´å¥‹çš„å†…å®¹ï¼
