- en: Processing Data At Scale With MapReduce
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MapReduce 进行大规模数据处理
- en: 原文：[https://towardsdatascience.com/mapreduce-f0d8776d0fcf](https://towardsdatascience.com/mapreduce-f0d8776d0fcf)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mapreduce-f0d8776d0fcf](https://towardsdatascience.com/mapreduce-f0d8776d0fcf)
- en: A deep dive into MapReduce and parallelization
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨 MapReduce 和并行化
- en: '[](https://gmyrianthous.medium.com/?source=post_page-----f0d8776d0fcf--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----f0d8776d0fcf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0d8776d0fcf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0d8776d0fcf--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----f0d8776d0fcf--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gmyrianthous.medium.com/?source=post_page-----f0d8776d0fcf--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----f0d8776d0fcf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0d8776d0fcf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0d8776d0fcf--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----f0d8776d0fcf--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0d8776d0fcf--------------------------------)
    ·4 min read·Jul 19, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0d8776d0fcf--------------------------------)
    ·4分钟阅读·2023年7月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/485ac39f931bd934b5c4a820f518771a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/485ac39f931bd934b5c4a820f518771a.png)'
- en: Photo by [Luca Nicoletti](https://unsplash.com/@luca_nicoletti?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/fkA-hGDs-Y8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Luca Nicoletti](https://unsplash.com/@luca_nicoletti?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，发布在 [Unsplash](https://unsplash.com/photos/fkA-hGDs-Y8?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: In the current market landscape, organizations must engage in data-driven decision-making
    to maintain competitiveness and foster innovation. As a result, an immense amount
    of data is collected on a daily basis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的市场环境中，组织必须进行数据驱动的决策，以保持竞争力并促进创新。因此，每天都会收集大量数据。
- en: Although the challenge of data persistence has largely been resolved, thanks
    to the widespread availability and affordability of cloud storage, modern organizations
    continue to grapple with the efficient and effective processing of massive amounts
    of data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据持久性问题在很大程度上已得到解决，这要归功于云存储的广泛可用性和价格实惠，现代组织仍然面临着高效有效处理大量数据的挑战。
- en: Over the past few decades, numerous programming models have emerged to address
    the challenge of processing big data at scale. Undoubtedly, MapReduce stands out
    as one of the most popular and effective approaches.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年中，出现了许多编程模型来解决大规模处理大数据的挑战。毫无疑问，MapReduce 是最受欢迎和有效的方法之一。
- en: What is MapReduce
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 MapReduce
- en: MapReduce is a distributed programming framework originally developed at Google
    by [Jeffrey Dean and Sanjay Ghemawat, back in 2004](https://research.google/pubs/pub62/)
    and was inspired by fundamental concepts of functional programming. Their proposal
    invloved a parallel data processing model consisting of two steps; *map* and *reduce*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 是一个分布式编程框架，最初由 [Jeffrey Dean 和 Sanjay Ghemawat 于 2004 年在 Google 开发](https://research.google/pubs/pub62/)，并受到函数式编程基本概念的启发。他们的提案涉及一个包含两个步骤的并行数据处理模型；*map*
    和 *reduce*。
- en: In simple terms, *map* step invovles the division of the original data into
    small chunks such that transformation logic can be applied to individual data
    blocks. Data processing can therefore be applied in parallel across the created
    chunks and finally, the *reduce* step will then aggregate/consolidate the processed
    blocks and return the end result back to the caller.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，*map* 步骤涉及将原始数据分割成小块，以便对每个数据块应用转换逻辑。因此，可以在创建的块上并行处理数据，最后，*reduce* 步骤将汇总/整合处理过的块，并将最终结果返回给调用者。
- en: How does MapReduce algorithm work
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MapReduce 算法如何工作
- en: Even though MapReduce algorithm has been widely known as a two-step process,
    it actually invovles three distinct stages.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 MapReduce 算法通常被认为是一个两步过程，但它实际上包含三个不同的阶段。
- en: '**1\. Map:** In this very first step, the data is split into smaller chunks
    and distributed across multiple nodes that are usually part of a cluster of processing
    units. Each chunk created is then assigned to a *mapper.* The input to the mapper
    is a set of `<key, value>` pair. Once the processing is executed on the data (which
    is once again in the form of `<key, value>`) the mapper will then write the resulting
    output to a temporary storage.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. Map：** 在这个第一步骤中，数据被拆分成更小的块，并分布到通常属于处理单元集群的多个节点上。每个创建的块被分配给一个 *mapper*。Mapper
    的输入是一组 `<key, value>` 对。数据处理执行后（依然是 `<key, value>` 形式），Mapper 会将生成的输出写入临时存储。'
- en: As an example, let’s consider the following example where the input text is
    first split across three mappers and the input is provided in the form of key-value
    pairs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以考虑以下例子，其中输入文本首先被拆分到三个 Mapper 上，输入以键值对的形式提供。
- en: '![](../Images/6751c679a3ac5e5d9ed7f88fa047acd0.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6751c679a3ac5e5d9ed7f88fa047acd0.png)'
- en: 'Mapping step of MapReduce algorithm — Source: Author'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 算法的映射步骤 — 来源：作者
- en: '**2\. Shuffling:** Now in this step, the algorithm will shuffle the data such
    that reocrds with the same key are allocated to the same worker node. This is
    usually the most expensive operation that is performed throughout the lifecycle
    of a MapReduce process.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. Shuffling：** 在这个步骤中，算法将数据洗牌，以便具有相同键的记录被分配到相同的工作节点。这通常是整个 MapReduce 过程生命周期中最昂贵的操作。'
- en: '![](../Images/f210f55e219ce84830516a60db5e0940.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f210f55e219ce84830516a60db5e0940.png)'
- en: 'Shuffling step in MapReduce — Source: Author'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 中的洗牌步骤 — 来源：作者
- en: '**3\. Reduce:** In this final step, each reducer will accept as an input the
    output of the corresponding mapper, which is in the form of a `<key, value>` pair.
    All mapper outputs with the same key will be assigned to the same reducer, which
    in turn will aggregate the values and return the consolidated result in as a `<key,
    value>` pair.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. Reduce：** 在这最后一步中，每个 Reducer 将接受对应 Mapper 输出的 `<key, value>` 对作为输入。所有具有相同键的
    Mapper 输出将分配给相同的 Reducer，Reducer 将汇总这些值，并将汇总结果以 `<key, value>` 对的形式返回。'
- en: '![](../Images/2dc8e8b0fdd2194182f04ba6fe65f17f.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2dc8e8b0fdd2194182f04ba6fe65f17f.png)'
- en: 'Reduce step in MapReduce — Source: Author'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Reduce 步骤中的 MapReduce — 来源：作者
- en: MapReduce and Hadoop
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MapReduce 和 Hadoop
- en: 'MapReduce is part of the Apache Hadoop framework that is used to access data
    stored in Hadoop Distributed File System (HDFS). Hadoop consists of four basic
    modules:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 是 Apache Hadoop 框架的一部分，用于访问存储在 Hadoop 分布式文件系统（HDFS）中的数据。Hadoop 由四个基本模块组成：
- en: '*Hadoop Distributed File System (HDFS)*: This ia a distributed file system
    that can store large datasets in a fault-tolerant fashion'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Hadoop Distributed File System (HDFS)*：这是一个分布式文件系统，可以以容错的方式存储大型数据集'
- en: '*Yet Another Resource Negotiation (YARN)*: This is the node manager that monitors
    cluster and resources. It also acts as the scheduler of jobs'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Yet Another Resource Negotiation (YARN)*：这是一个节点管理器，监控集群和资源，同时也作为作业调度器。'
- en: '*MapReduce*'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MapReduce*'
- en: '*Hadoop Common*: This is a module that provides commonly used Java libraries'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Hadoop Common*：这是一个提供常用 Java 库的模块'
- en: Previously, we mentioned how mappers and reducers run on individual nodes within
    a cluster of computers. In fact, these worker nodes are part of the Hadoop framework
    that decides the amount of mappers required to be used in each case, depending
    on the volume of the input size.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们提到过，Mapper 和 Reducer 在计算机集群的独立节点上运行。实际上，这些工作节点是 Hadoop 框架的一部分，该框架决定了每种情况下所需的
    Mapper 数量，这取决于输入大小的体积。
- en: Be design, Hadoop offers fault-tolerance. In the event of a node failure, Hadoop
    will rerun the task on another mapper node and generate the output required.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 设计时提供了容错功能。在节点发生故障时，Hadoop 会在另一个映射节点上重新运行任务并生成所需的输出。
- en: Final Thoughts
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后的思考
- en: MapReduce has been a groundbreaking concept in distributed computing, empowering
    numerous organizations to process vast volumes of data and extract valuable insights.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: MapReduce 在分布式计算中是一个突破性的概念，使许多组织能够处理大量数据并提取有价值的洞察。
- en: Familiarizing oneself with this concept is crucial, particularly when utilizing
    technologies like Spark that leverage the MapReduce framework.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉这个概念至关重要，特别是在利用如 Spark 等依赖于 MapReduce 框架的技术时。
- en: 👉 [**Become a member**](https://gmyrianthous.medium.com/membership) **and read
    every story on Medium. Your membership fee directly supports me and other writers
    you read. You’ll also get full access to every story on Medium.**
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 👉 [**成为会员**](https://gmyrianthous.medium.com/membership) **，在 Medium 上阅读所有故事。您的会员费直接支持我和您阅读的其他作者。您还将获得对
    Medium 上每个故事的全面访问权限。**
- en: '[](https://gmyrianthous.medium.com/membership?source=post_page-----f0d8776d0fcf--------------------------------)
    [## Join Medium with my referral link — Giorgos Myrianthous'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gmyrianthous.medium.com/membership?source=post_page-----f0d8776d0fcf--------------------------------)
    [## 通过我的推荐链接加入 Medium — Giorgos Myrianthous'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 成为 Medium 会员后，您的会员费的一部分将分配给您阅读的作者，并且您可以全面访问每个故事…
- en: gmyrianthous.medium.com](https://gmyrianthous.medium.com/membership?source=post_page-----f0d8776d0fcf--------------------------------)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: gmyrianthous.medium.com](https://gmyrianthous.medium.com/membership?source=post_page-----f0d8776d0fcf--------------------------------)
