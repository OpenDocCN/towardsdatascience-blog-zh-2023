- en: Poems, Flowers, and Dragons at EMNLP 2022
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2022年EMNLP上的诗歌、花卉和龙
- en: 原文：[https://towardsdatascience.com/poems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db?source=collection_archive---------13-----------------------#2023-01-02](https://towardsdatascience.com/poems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db?source=collection_archive---------13-----------------------#2023-01-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/poems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db?source=collection_archive---------13-----------------------#2023-01-02](https://towardsdatascience.com/poems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db?source=collection_archive---------13-----------------------#2023-01-02)
- en: '[](https://medium.com/@phoenixilya?source=post_page-----e83dbb0e91db--------------------------------)[![Ilya
    Gusev](../Images/f6b6cee7d3bd208c0731b784ea4fc0c6.png)](https://medium.com/@phoenixilya?source=post_page-----e83dbb0e91db--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e83dbb0e91db--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e83dbb0e91db--------------------------------)
    [Ilya Gusev](https://medium.com/@phoenixilya?source=post_page-----e83dbb0e91db--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@phoenixilya?source=post_page-----e83dbb0e91db--------------------------------)[![Ilya
    Gusev](../Images/f6b6cee7d3bd208c0731b784ea4fc0c6.png)](https://medium.com/@phoenixilya?source=post_page-----e83dbb0e91db--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e83dbb0e91db--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e83dbb0e91db--------------------------------)
    [Ilya Gusev](https://medium.com/@phoenixilya?source=post_page-----e83dbb0e91db--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F99b43d56e4b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpoems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db&user=Ilya+Gusev&userId=99b43d56e4b6&source=post_page-99b43d56e4b6----e83dbb0e91db---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e83dbb0e91db--------------------------------)
    ·8 min read·Jan 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe83dbb0e91db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpoems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db&user=Ilya+Gusev&userId=99b43d56e4b6&source=-----e83dbb0e91db---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F99b43d56e4b6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpoems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db&user=Ilya+Gusev&userId=99b43d56e4b6&source=post_page-99b43d56e4b6----e83dbb0e91db---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e83dbb0e91db--------------------------------)
    ·8 min 阅读·2023年1月2日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe83dbb0e91db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpoems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db&user=Ilya+Gusev&userId=99b43d56e4b6&source=-----e83dbb0e91db---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe83dbb0e91db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpoems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db&source=-----e83dbb0e91db---------------------bookmark_footer-----------)![](../Images/bfd6c85917e82ed35248b178b1138ab4.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe83dbb0e91db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpoems-flowers-and-dragons-at-emnlp-2022-e83dbb0e91db&source=-----e83dbb0e91db---------------------bookmark_footer-----------)![](../Images/bfd6c85917e82ed35248b178b1138ab4.png)'
- en: “poems, flowers, dungeons and dragons united, digital art — ar 3:2 — v 4”, Midjourney
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “诗歌、花卉、地牢与龙的结合，数字艺术 — ar 3:2 — v 4”，Midjourney
- en: The EMNLP conference is a highly regarded event in the field of natural language
    processing, where researchers come together to share and discuss the latest findings
    in the field. This year’s conference took place from December 7th to December
    11th in Abu Dhabi. Of the many papers presented at the conference, I wanted to
    highlight three that stood out to me. These papers may not necessarily be the
    most practical or well-known, but I believe they are worth mentioning. Two papers
    were presented as posters, while the third was a full talk. My favorite of the
    three is PoeLM.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: EMNLP 会议是自然语言处理领域一个备受推崇的活动，研究人员汇聚一堂，分享和讨论该领域的最新发现。今年的会议于12月7日至12月11日在阿布扎比举行。在会议上展示的众多论文中，我想特别提到三篇给我留下深刻印象的论文。这些论文可能不是最实用或最知名的，但我认为它们值得一提。两篇论文以海报的形式展示，第三篇是完整的演讲。我最喜欢的三篇论文中的一篇是
    PoeLM。
- en: 'PoeLM: A Meter- and Rhyme-Controllable Language Model for Unsupervised Poetry
    Generation'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'PoeLM: 一种用于无监督诗歌生成的节奏和韵律可控语言模型'
- en: '**Paper**: [Ormazabal et al., 2022](https://arxiv.org/abs/2205.12206)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**论文**: [Ormazabal et al., 2022](https://arxiv.org/abs/2205.12206)'
- en: '**Organizations**: University of the Basque Country, Meta AI, University of
    Copenhagen'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组织**: 巴斯克大学、Meta AI、哥本哈根大学'
- en: '**Code**: [https://github.com/aitorormazabal/poetry_generation](https://github.com/aitorormazabal/poetry_generation),
    though there is only dataset creation.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码**: [https://github.com/aitorormazabal/poetry_generation](https://github.com/aitorormazabal/poetry_generation)，不过这里只有数据集创建。'
- en: '**Main idea**: Generating Spanish and Basque formal verse poems through control
    codes with a language model trained on non-poetic texts.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要思想**: 通过控制代码生成西班牙语和巴斯克语正式诗歌，使用在非诗歌文本上训练的语言模型。'
- en: '**Motivation**'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**动机**'
- en: Can modern language models write poems? Of course, they can. You can quickly
    test it with [ChatGPT](https://chat.openai.com/chat). The challenges arise when
    trying to impose specific constraints, such as a fixed number of syllables or
    a specific rhyme or rhythm scheme.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现代语言模型能写诗吗？当然能。你可以快速用[ChatGPT](https://chat.openai.com/chat)测试一下。挑战在于强加特定的约束，比如固定的音节数或特定的韵律或节奏方案。
- en: How can we force language models to generate formal verse poems? One way is
    to modify the decoding algorithm, which is complicated with modern language models
    as they operate with sub-words, which are neither words nor syllables. This paper
    describes another way to do it. For this to work, you will need a regular text
    corpus and a system capable of analyzing syllables and rhymes.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何强迫语言模型生成正式的诗歌？一种方法是修改解码算法，这在现代语言模型中很复杂，因为它们处理的是子词，既不是词也不是音节。本文描述了另一种方法。要使其有效，你需要一个常规的文本语料库和一个能够分析音节和韵律的系统。
- en: Training a language model
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练语言模型
- en: '![](../Images/2b9e1894de81d349cd9dfe3d2174d3d8.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b9e1894de81d349cd9dfe3d2174d3d8.png)'
- en: Figure from the paper, a proposed method.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 来自论文的图，提出的方法。
- en: 'Here is what you need to do:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做的步骤是：
- en: Get a regular, non-poetic corpus, and split it into phrases.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取一个常规的非诗歌语料库，并将其拆分成短语。
- en: Group the text in blocks of N phrases, where N is randomly sampled.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本分成N个短语块，其中N是随机采样的。
- en: Augment groups with structure descriptors (=prefixes) to include the number
    of syllables and rhyme endings for each phrase.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用结构描述符（=前缀）增强组，以包含每个短语的音节数和韵尾。
- en: Train a classic transformer language model with structure descriptors treated
    as ordinary tokens.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用将结构描述符视为普通标记的经典变换器语言模型进行训练。
- en: '![](../Images/4706bb3972c9984ed6593fe904d5aa7a.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4706bb3972c9984ed6593fe904d5aa7a.png)'
- en: Figure from the paper. A formal verse poem and its associated structure descriptor.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 来自论文的图。正式诗歌及其相关的结构描述符。
- en: A structure descriptor from the figure above is
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 上图中的结构描述符是
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This descriptor means four lines; each has 11 syllables; the first and last
    lines end with “echo”, and lines 2 and 3 end with “ura”. The model will learn
    how to use these codes, as generating texts using such hints is easier than without
    them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这个描述符意味着四行；每行有11个音节；首尾两行以“echo”结尾，第2和第3行以“ura”结尾。模型将学习如何使用这些代码，因为使用这些提示生成文本比没有提示要容易。
- en: Generation
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成
- en: Choose a rhyming scheme and number of syllables.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择韵律方案和音节数。
- en: Generate a structure descriptor. Authors do it from the given scheme by sampling
    each rhyming sound independently from the training corpus’s five most common rhyme
    sounds.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一个结构描述符。作者通过从训练语料库中五种最常见的韵律声音中独立采样每种韵律声音来完成这个任务。
- en: Provide the first line of a poem (optionally)
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供诗歌的第一行（可选）
- en: Generate a lot of poem candidates using the trained language model.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练过的语言模型生成大量诗歌候选。
- en: Filter all candidates that do not fit the rhyming scheme or contain an incorrect
    number of syllables.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤掉所有不符合韵律方案或包含错误音节数的候选。
- en: Re-rank remaining candidates by general fluency using the trained language model
    without a structure descriptor and output the one with the highest score.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练过的语言模型（没有结构描述符）按一般流畅度重新排序剩余的候选，并输出得分最高的那个。
- en: How well does it work?
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它的效果如何？
- en: '![](../Images/86ed9e5dfa2c81e1ca4e2e1f0a143066.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86ed9e5dfa2c81e1ca4e2e1f0a143066.png)'
- en: Table from the paper. Percentage of times that system S1 is ranked ahead of
    S2 in the human evaluation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 来自论文的表格。系统S1在人工评估中排名高于S2的次数百分比。
- en: The filtering rate from step 5 is 30.9% for Spanish poems and 23.4% for Basque
    poems. 37.3% of humans prefer automatic poems over those written by renowned poets
    comparing poems with the same first line.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第5步的过滤率对于西班牙语诗歌为30.9%，对于巴斯克语诗歌为23.4%。37.3%的人更喜欢自动生成的诗歌而非知名诗人的诗歌，比较的是第一行相同的诗歌。
- en: Can you do the same in your language?
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你能在你的语言中做到这一点吗？
- en: A reliable syllabication and rhyme detection process are necessary to use the
    described algorithm. While such programs may already exist for some languages,
    other languages may have more complex features, such as rhythm, that need to be
    considered. The structure descriptors can be modified in these cases to include
    additional components.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用描述的算法需要可靠的音节划分和押韵检测过程。虽然某些语言可能已有这样的程序，但其他语言可能具有更复杂的特征，如节奏，需要考虑。在这些情况下，可以修改结构描述符以包括额外的组件。
- en: Why is it important to me?
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么这对我很重要？
- en: 'Six years ago, Daniil Anastasyev and I developed a system for the Russian poem
    generation, [rupo](https://github.com/IlyaGusev/rupo). It was an LSTM-based language
    model with some unique features: it predicted texts from right to left, separately
    using normal forms of words and their grammatical features, and it was based on
    finite-state acceptors. Since then, natural language processing technologies have
    advanced significantly, making it likely easier to create a similar system today.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 六年前，丹尼尔·阿纳斯捷耶夫和我开发了一个俄罗斯诗歌生成系统，[rupo](https://github.com/IlyaGusev/rupo)。这是一个基于LSTM的语言模型，具有一些独特的特征：它从右到左预测文本，分别使用单词的标准形式及其语法特征，并且基于有限状态接受器。自那时以来，自然语言处理技术取得了显著进展，使得今天创建类似系统可能更加容易。
- en: 'Draw Me a Flower: Processing and Grounding Abstraction in Natural Language'
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 画一朵花：自然语言中的处理和基础抽象
- en: '**Paper**: [Lachmy et al., 2022](https://arxiv.org/abs/2106.14321)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**论文**: [Lachmy 等人, 2022](https://arxiv.org/abs/2106.14321)'
- en: '**Organizations**: Bar-Ilan University, AI2'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机构**: 巴伊兰大学, AI2'
- en: '**Code**: [https://github.com/OnlpLab/Hexagons](https://github.com/OnlpLab/Hexagons),
    but there are no baselines yet, only the dataset itself.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码**: [https://github.com/OnlpLab/Hexagons](https://github.com/OnlpLab/Hexagons)，但目前还没有基准，只有数据集本身。'
- en: '**Main idea**: Creating a benchmark for grounded abstractions in natural language
    with instruction-based pattern drawing on a hexagonal grid.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要思想**: 创建一个基于六边形网格的指令式模式绘制的自然语言基础抽象基准。'
- en: '![](../Images/caa75894bd38530ef82f6b8da0b6c514.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/caa75894bd38530ef82f6b8da0b6c514.png)'
- en: Figure from the paper, levels of abstraction in natural language
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的图，展示自然语言中的抽象层次
- en: '**Motivation**'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**动机**'
- en: We know large language models [can’t count correctly](https://arxiv.org/pdf/2210.17517.pdf)
    or perform [back-of-the-envelope calculations](https://aclanthology.org/2021.emnlp-main.582.pdf).
    Even [a simple spatial reasoning](https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/navigate)
    task is a problem ([chain-of-thought](https://arxiv.org/pdf/2210.09261.pdf) helps,
    though). But what about abstraction? When you command your hypothetical AI assistant,
    “order three pizzas, one BBQ, one Pepperoni, and one Margherita, first two large,
    the last medium, at 5 pm”, it should be able to understand you. It’s not only
    about ellipsis but also conditions, iterations, functional decomposition, recursion,
    and other mechanisms.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道大型语言模型[无法正确计算](https://arxiv.org/pdf/2210.17517.pdf)或执行[简便的估算](https://aclanthology.org/2021.emnlp-main.582.pdf)。即使是[简单的空间推理](https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/navigate)任务也是个问题（不过[思维链](https://arxiv.org/pdf/2210.09261.pdf)有所帮助）。但是抽象呢？当你命令你假设的AI助手，“订三个披萨，一个BBQ，一个意大利辣香肠，一个玛格丽塔，前两个大，最后一个中，下午5点”，它应该能够理解你。这不仅仅涉及省略号，还有条件、迭代、功能分解、递归和其他机制。
- en: To measure the extent to which a model can grasp abstract concepts, we can ground
    it in [various](https://en.wikipedia.org/wiki/SHRDLU) [virtual](https://aclanthology.org/2020.acl-main.232/)
    [worlds](https://arxiv.org/abs/2106.00188). In this case, the authors used a hexagonal
    board with 10x18 tiles and eight colors as the basis for grounding abstractions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了衡量模型 grasp 抽象概念的程度，我们可以将其 grounding 在[各种](https://en.wikipedia.org/wiki/SHRDLU)
    [虚拟](https://aclanthology.org/2020.acl-main.232/) [世界](https://arxiv.org/abs/2106.00188)中。在这种情况下，作者使用了一个10x18瓷砖和八种颜色的六边形棋盘作为
    grounding 抽象的基础。
- en: '**Dataset**'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**数据集**'
- en: 'The dataset for this study was gathered through crowd-sourcing efforts. While
    the authors provided the starting images, crowd workers also contributed by drawing
    additional patterns. The annotation process was divided into two phases: in the
    first phase, a group of annotators wrote instructions based on the images, and
    in the second phase, another group attempted to recreate the images based on the
    instructions. Any discrepancies or disagreements were resolved through manual
    inspection. The resulting dataset has 175 unique images, 620 instruction sets,
    and 4177 instruction steps.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的数据集是通过众包方式收集的。虽然作者提供了起始图像，但众包工作者也通过绘制额外的模式进行了贡献。注释过程分为两个阶段：第一阶段，一组注释人员根据图像编写说明；第二阶段，另一组人员根据说明尝试重建图像。任何不一致或分歧都通过人工检查解决。最终数据集包含175张独特的图像、620组说明和4177个说明步骤。
- en: '![](../Images/c01560bdcb5e62f69aea21d43adf3bd4.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c01560bdcb5e62f69aea21d43adf3bd4.png)'
- en: Figure from the paper, a gallery sample.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的图，画廊样本。
- en: '**Experiments**'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**实验**'
- en: 'Two types of models were tested: classification and generation-based. DeBERTa
    was used for the classification to predict every tile’s state. For the generation,
    T5 was used to generate a set of actions. The models were tested under various
    settings that varied in terms of the amount of history and current board information
    available to them: no history, one previous step, full history, predicted board,
    and oracle board. The results indicate that the models performed significantly
    worse than humans and could only handle the most basic abstractions, even with
    access to an oracle board and full history.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 测试了两种模型：分类模型和生成模型。分类模型使用了DeBERTa来预测每个瓦片的状态。生成模型则使用了T5来生成一系列动作。模型在各种设置下进行了测试，这些设置在历史记录和当前棋盘信息的量上有所不同：无历史记录、一个前一步、完整历史记录、预测棋盘和神谕棋盘。结果表明，这些模型的表现明显低于人类，甚至在拥有神谕棋盘和完整历史记录的情况下，也只能处理最基本的抽象。
- en: '![](../Images/1ed33a694e851e0b5e806278d9e5196c.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ed33a694e851e0b5e806278d9e5196c.png)'
- en: Table from the paper. Results for both types of models on the test set, actions-based
    metrics.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的表格。两种模型在测试集上的结果，基于动作的指标。
- en: '![](../Images/e62af6758b619f747658f1966e1f66d4.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e62af6758b619f747658f1966e1f66d4.png)'
- en: Table from the paper. Dataset evaluation, human performance.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的表格。数据集评估，人类表现。
- en: '**Why is it important?**'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**为什么这很重要？**'
- en: It is a great visual representation of how challenging this problem is for natural
    language models. This benchmark makes it possible to identify which abstraction
    mechanisms are lacking in these models quickly. I suspect code-based models [would](https://arxiv.org/pdf/2210.09261.pdf)
    perform better in this task and am interested in testing this hypothesis.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对自然语言模型面临的挑战的一个很好的视觉展示。这个基准使得可以迅速识别这些模型中缺乏哪些抽象机制。我怀疑基于代码的模型[会](https://arxiv.org/pdf/2210.09261.pdf)在这个任务中表现更好，并且我对测试这一假设很感兴趣。
- en: Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 龙与地下城作为人工智能对话挑战
- en: '**Paper**: [Callison-Burch et al., 2022](https://arxiv.org/pdf/2210.07109.pdf)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**论文**：[Callison-Burch et al., 2022](https://arxiv.org/pdf/2210.07109.pdf)'
- en: '**Organizations**: University of Pennsylvania, Google Research'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机构**：宾夕法尼亚大学，谷歌研究'
- en: '**Code**: not yet released, should be [here](https://www.cis.upenn.edu/~ccb/dnd-data.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码**：尚未发布，应该在[这里](https://www.cis.upenn.edu/~ccb/dnd-data.html)'
- en: '**Main idea**: Creating a challenge for dialogue systems based on D&D conversations,
    where the tasks are to generate the next conversational turn in the game and predict
    the state of the game, given the dialogue history.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要思想**：基于D&D对话创建一个对话系统挑战，任务是在游戏中生成下一个对话回合，并预测游戏的状态，给定对话历史。'
- en: '![](../Images/252309de0d7d010f49ed25dc0dcd03f6.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/252309de0d7d010f49ed25dc0dcd03f6.png)'
- en: “robots playing D&D, digital art, futuristic — ar 3:2 — v 4”, Midjourney
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: “robots playing D&D, digital art, futuristic — ar 3:2 — v 4”，Midjourney
- en: '**Motivation**'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**动机**'
- en: '*Dungeons & Dragons is a fantasy tabletop role-playing game. Characters embark
    upon adventures within a fantasy setting. A Dungeon Master serves as the game’s
    referee and storyteller while maintaining the setting in which the adventures
    occur, and playing the role of the game world’s inhabitants, also referred to
    as non-player characters (NPCs). The characters form a party and interact with
    the setting’s inhabitants and each other. Together they solve dilemmas, engage
    in battles, explore, and gather treasure and knowledge. In the process, the characters
    earn experience points to rise in levels and become increasingly powerful over
    a series of separate gaming sessions. —* [*Wikipedia*](https://en.wikipedia.org/wiki/Dungeons_%26_Dragons)'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*龙与地下城（Dungeons & Dragons）是一款奇幻桌面角色扮演游戏。角色们在奇幻的环境中展开冒险。地下城主作为游戏的裁判和讲述者，同时维护冒险发生的环境，并扮演游戏世界的居民，也称为非玩家角色（NPCs）。角色们组成一个小队，与环境中的居民和彼此互动。他们一起解决难题，参与战斗，探索并收集宝藏和知识。在这个过程中，角色们获得经验值，逐渐升级并变得越来越强大，经过一系列的游戏会话。—*
    [*维基百科*](https://en.wikipedia.org/wiki/Dungeons_%26_Dragons)'
- en: Many natural language processing datasets are highly specialized, focusing on
    a specific task. Dungeons and Dragons (D&D) is a human activity that requires
    a high level of language comprehension from all participants. It involves a range
    of skills such as text generation, knowledge base lookup, multi-party dialogue,
    goal setting, common sense reasoning, intent detection, state tracking, and question
    answering, making it an ideal testbed for evaluating the capabilities of NLP models.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 许多自然语言处理数据集都高度专业化，专注于特定任务。龙与地下城（D&D）是一项需要所有参与者高度语言理解的人类活动。它涉及一系列技能，如文本生成、知识库查找、多方对话、目标设定、常识推理、意图检测、状态跟踪和问题回答，使其成为评估
    NLP 模型能力的理想测试平台。
- en: Other applications of AI for D&D include [character photo creation](https://www.reddit.com/r/StableDiffusion/comments/yskhce/my_new_dd_model_trained_for_30000_steps_on_2500/)
    and, of course, the famous [AI Dungeon](https://play.aidungeon.io/main/home).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: AI 在 D&D 中的其他应用包括 [角色照片生成](https://www.reddit.com/r/StableDiffusion/comments/yskhce/my_new_dd_model_trained_for_30000_steps_on_2500/)
    和当然还有著名的 [AI Dungeon](https://play.aidungeon.io/main/home)。
- en: '**Dataset**'
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**数据集**'
- en: '![](../Images/dfa1d9b3291c840b852879194e0115af.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dfa1d9b3291c840b852879194e0115af.png)'
- en: Figure from the paper. Example of 3 turns in the D&D Beyond play-by-post forum.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的图示。D&D Beyond 论坛中 3 回合的示例。
- en: Authors scraped Play-By-Post data from the D&D Beyond web forum, where people
    play by taking turns posting on the forum to describe their moves. It isn’t the
    only possible source for D&D sessions. For instance, [the CRD3 dataset](https://aclanthology.org/2020.acl-main.459.pdf)
    used transcripts from the Critical Role show.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作者从 D&D Beyond 论坛上抓取了 Play-By-Post 数据，在这个论坛上，人们通过轮流在论坛上发帖来描述他们的行动。这不是 D&D 会话的唯一可能来源。例如，[CRD3
    数据集](https://aclanthology.org/2020.acl-main.459.pdf)使用了 Critical Role 节目的转录稿。
- en: '![](../Images/cce369b1c375586b380c1aafc21f022b.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cce369b1c375586b380c1aafc21f022b.png)'
- en: Table from the paper, dataset statistics.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的表格，数据集统计信息。
- en: Rule-based heuristics were used to extract game state information from texts
    using regular expressions and NER. In addition, a CNN classifier for texts was
    used in cases where heuristics failed to extract anything. The dataset includes
    not only in-character texts but also out-of-character posts.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于规则的启发式方法通过正则表达式和命名实体识别（NER）从文本中提取游戏状态信息。此外，在启发式方法无法提取信息的情况下，还使用了用于文本的 CNN
    分类器。数据集不仅包括角色内文本，还包括角色外帖子。
- en: '**Experiments**'
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**实验**'
- en: 'LaMDA, Google’s large language model similar to GPT-3, was used to tackle two
    tasks: game state tracking and response generation. The authors experimented with
    various fine-tuning variations of the model, including using states from the current
    or previous turns as control features. To evaluate the model’s performance, six
    professional raters interested in the fantasy genre and prior experience with
    D&D, including three who had served as Dungeon Masters, were recruited for a manual
    assessment.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: LaMDA，谷歌类似于 GPT-3 的大型语言模型，用于处理两个任务：游戏状态跟踪和回应生成。作者尝试了模型的各种微调变体，包括使用当前或前几个回合的状态作为控制特征。为了评估模型的表现，招募了六名对幻想题材感兴趣并具有
    D&D 经验的专业评估员，其中包括三名曾担任地下城主的人员，进行手动评估。
- en: '![](../Images/d5bc8d152a0a423b146e26757acfe3aa.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5bc8d152a0a423b146e26757acfe3aa.png)'
- en: Table from the paper. Average human evaluators’ scores for systems and human-written
    gold responses.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的表格。系统和人工编写的金牌回应的平均人类评估者评分。
- en: The evaluation results show that domain adaptation is beneficial, but the impact
    of control features could be clearer. However, these features enable the model
    to take on specific roles within the game, which could make it a valuable substitute
    for a Dungeon Master or a player in actual D&D games.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 评估结果显示领域适应是有益的，但控制特征的影响可能更清晰。然而，这些特征使得模型能够在游戏中担任特定角色，这可能使其成为实际D&D游戏中地下城主或玩家的有价值替代品。
- en: '![](../Images/1ef0592e0de0d6e335543d4953d69d5e.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ef0592e0de0d6e335543d4953d69d5e.png)'
- en: Table from the paper. Average accuracy for GST compared to a majority class
    baseline.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的表格。GST的平均准确率与多数类基线相比。
- en: The results for the game state tracking task could have been better. The model
    was fed all previous dialog turns and their corresponding state variables, as
    well as the text of the current turn, and was expected to output the correct state
    variables for the current turn. The joint accuracy for the model was 58%. These
    results suggest that the use of a large language model alone is not sufficient
    for this task and that further modifications may be necessary to improve performance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏状态跟踪任务的结果本可以更好。模型接收了所有以前对话回合及其对应的状态变量，以及当前回合的文本，并期望输出当前回合的正确状态变量。模型的联合准确率为58%。这些结果表明，仅使用大型语言模型不足以完成此任务，可能需要进一步修改以提高性能。
- en: Conclusion
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In conclusion, the research and findings discussed above highlight the ongoing
    challenges and areas for improvement. It is essential to consider the value of
    non-mainstream papers, as they may offer unique insights and approaches that could
    be overlooked in a rush to keep up with more widely recognized works.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 总结上述研究和发现突出了持续存在的挑战和改进领域。必须考虑非主流论文的价值，因为它们可能提供独特的见解和方法，这些可能在急于跟上更广为人知的作品时被忽视。
