- en: Data-Driven Dispatch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据驱动的调度
- en: 原文：[https://towardsdatascience.com/data-driven-dispatch-76b7e998a7a7?source=collection_archive---------4-----------------------#2023-08-04](https://towardsdatascience.com/data-driven-dispatch-76b7e998a7a7?source=collection_archive---------4-----------------------#2023-08-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/data-driven-dispatch-76b7e998a7a7?source=collection_archive---------4-----------------------#2023-08-04](https://towardsdatascience.com/data-driven-dispatch-76b7e998a7a7?source=collection_archive---------4-----------------------#2023-08-04)
- en: Using supervised learning to predict service callouts to Chicago car collisions
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用监督学习预测芝加哥车辆碰撞的服务呼叫
- en: '[](https://medium.com/@john_lenehan?source=post_page-----76b7e998a7a7--------------------------------)[![John
    Lenehan](../Images/addeeb0bacca7ddec928aa12c2a4fc53.png)](https://medium.com/@john_lenehan?source=post_page-----76b7e998a7a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----76b7e998a7a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----76b7e998a7a7--------------------------------)
    [John Lenehan](https://medium.com/@john_lenehan?source=post_page-----76b7e998a7a7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@john_lenehan?source=post_page-----76b7e998a7a7--------------------------------)[![John
    Lenehan](../Images/addeeb0bacca7ddec928aa12c2a4fc53.png)](https://medium.com/@john_lenehan?source=post_page-----76b7e998a7a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----76b7e998a7a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----76b7e998a7a7--------------------------------)
    [John Lenehan](https://medium.com/@john_lenehan?source=post_page-----76b7e998a7a7--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2eb00da71bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-driven-dispatch-76b7e998a7a7&user=John+Lenehan&userId=2eb00da71bb6&source=post_page-2eb00da71bb6----76b7e998a7a7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----76b7e998a7a7--------------------------------)
    ·13 min read·Aug 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F76b7e998a7a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-driven-dispatch-76b7e998a7a7&user=John+Lenehan&userId=2eb00da71bb6&source=-----76b7e998a7a7---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2eb00da71bb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-driven-dispatch-76b7e998a7a7&user=John+Lenehan&userId=2eb00da71bb6&source=post_page-2eb00da71bb6----76b7e998a7a7---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----76b7e998a7a7--------------------------------)
    · 13分钟阅读 · 2023年8月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F76b7e998a7a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-driven-dispatch-76b7e998a7a7&user=John+Lenehan&userId=2eb00da71bb6&source=-----76b7e998a7a7---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F76b7e998a7a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-driven-dispatch-76b7e998a7a7&source=-----76b7e998a7a7---------------------bookmark_footer-----------)![](../Images/c2c5a6ca3ae97936c5c408411e705545.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F76b7e998a7a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-driven-dispatch-76b7e998a7a7&source=-----76b7e998a7a7---------------------bookmark_footer-----------)![](../Images/c2c5a6ca3ae97936c5c408411e705545.png)'
- en: Photo by [Sawyer Bengtson](https://unsplash.com/@sawyerbengtson?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sawyer Bengtson](https://unsplash.com/@sawyerbengtson?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 的照片'
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In today’s fast-paced world, the need for data-driven decisions in dispatch
    response systems is becoming essential. Dispatchers will perform a kind of triage
    when listening to calls, prioritising cases based on severity and time sensitivity
    among other factors. There is potential in optimising this process by leveraging
    the power of supervised learning models, to make more accurate predictions of
    case severity in tandem with a human dispatcher’s assessment.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今快节奏的世界中，数据驱动的调度响应系统变得越来越重要。调度员在接听电话时会进行一种分诊，基于严重性和时间敏感性等因素来优先处理案件。通过利用监督学习模型的力量，优化这一过程有很大的潜力，可以在与人工调度员的评估相结合的情况下，更准确地预测案件的严重性。
- en: In this post, I’m going to run through one solution I developed to improve predictions
    of casualties and/or serious vehicular damage from car collisions in Chicago.
    Factors such as crash location, road conditions, speed limit, and time of occurrence
    were taken into account to answer a simple yes or no question — *will this car
    crash require an ambulance or tow truck?*
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将介绍我开发的一个解决方案，以改善对芝加哥汽车碰撞中伤亡和/或严重车辆损坏的预测。考虑了碰撞地点、道路条件、限速和发生时间等因素，以回答一个简单的是或否的问题——*这次车祸是否需要救护车或拖车？*
- en: '![](../Images/1a30aa5c17291cf500139dfce5f2094d.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a30aa5c17291cf500139dfce5f2094d.png)'
- en: Photo by [Chris Dickens](https://unsplash.com/@chrisdickens?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[Chris Dickens](https://unsplash.com/@chrisdickens?utm_source=medium&utm_medium=referral)提供的照片，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: In a nutshell, this machine learning tool’s primary objective is to classify
    collisions that will most likely require a callout (medical, tow, or both) based
    on other known factors. By leveraging this tool, responders would be able to efficiently
    allocate their resources across different parts of the city, based on various
    conditions such as weather and time of day.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这个机器学习工具的主要目标是基于其他已知因素，分类最可能需要呼叫（医疗、拖车或两者）的碰撞。通过利用这个工具，响应人员可以根据天气和时间等各种条件高效分配资源到城市的不同区域。
- en: For such a tool to be accurate and effective, a large data source would be needed
    to make predictions from the historical data — thankfully the city of Chicago
    already has such a resource (the [**Chicago Data Portal**](https://data.cityofchicago.org/)**),**
    so this data will be used as the test case.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个工具准确有效，需要一个大型数据源来从历史数据中进行预测——幸运的是，芝加哥市已经有这样的资源（[**芝加哥数据门户**](https://data.cityofchicago.org/)**），**因此将使用这些数据作为测试案例。
- en: Implementing these kinds of predictive models would certainly improve preparedness
    and response time efficiency when dealing with collisions on city streets. By
    gaining insights into the underlying patterns and trends within the collision
    data, we can work towards fostering safer road environments and optimising emergency
    services.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 实施这些预测模型无疑将提高处理城市街道碰撞时的准备性和响应时间效率。通过深入了解碰撞数据中的潜在模式和趋势，我们可以致力于创造更安全的道路环境，并优化应急服务。
- en: I go into the details of data cleaning, model building, fine tuning and evaluation
    below, before analysing the model’s results and drawing conclusions. A link to
    the github folder for this project, which includes a jupyter notebook and a more
    comprehensive report on the project, can be found [**here**](https://github.com/jlenehan/Chicago_Dispatch_Classification).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在下面详细讨论数据清理、模型构建、微调和评估，然后分析模型的结果并得出结论。该项目的github文件夹链接，包括一个jupyter notebook和一个更全面的项目报告，可以在[**这里**](https://github.com/jlenehan/Chicago_Dispatch_Classification)找到。
- en: Data Collection and Preparation
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据收集与准备
- en: Initial Setup
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始设置
- en: 'I’ve listed the basic data analysis libraries used in the project below; standard
    libraries such as pandas and numpy were used throughout the project, along with
    matplotlib’s pyplot and seaborn for visualisation. Additionally, I used the missingno
    library to identify gaps in the data — I find this library incredibly useful for
    visualising missing data in a dataset, and would recommend it for any data science
    project involving dataframes:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我列出了项目中使用的基本数据分析库；标准库如pandas和numpy在整个项目中都有使用，以及用于可视化的matplotlib的pyplot和seaborn。此外，我还使用了missingno库来识别数据中的缺失情况——我发现这个库在可视化数据集中缺失数据方面非常有用，并推荐在涉及数据框的数据科学项目中使用：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Functions from the machine learning module SciKit learn (sklearn) were imported
    to build the machine learning engine. these functions are shown here — I will
    describe the purpose of each of these functions in the Classification Model section
    later:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从机器学习模块SciKit learn (sklearn)中导入了函数来构建机器学习引擎。这些函数在此处展示——我将在分类模型部分详细描述这些函数的用途：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The data for this project were all imported from the Chicago Data Portal, from
    two sources:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目的数据全部从芝加哥数据门户中导入，来源于两个渠道：
- en: '[**Traffic Crashes**](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if)**:**
    Live dataset of vehicle collisions in the Chicago area. The features of this dataset
    are conditions recorded at the time of the collision, such as weather conditions,
    road alignment, latitude and longitude data, among other details.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[**交通事故**](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if)**:**
    芝加哥地区车辆碰撞的实时数据集。该数据集的特征是碰撞发生时记录的条件，如天气条件、道路对齐、纬度和经度数据等细节。'
- en: '[**Police Beats Boundaries**](https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74)**:**
    A static dataset indicating the boundaries of CPD beats; this dataset is used
    to supplement district information to the traffic crashes dataset. This can be
    joined to the original dataset to run analysis on districts with the most frequent
    collisions.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[**警察巡逻区边界**](https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74)**:**
    一个静态数据集，指示 CPD 巡逻区的边界；该数据集用于补充交通事故数据集的区信息。可以将其与原始数据集连接，以对事故最频繁的地区进行分析。'
- en: Data Cleaning
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据清理
- en: 'With both datasets imported, they can now be merged to add district data to
    the final analysis. This is done using the .merge() function in pandas — I used
    an inner join on both dataframes to capture all information in both, using the
    beat data in both as the join key (listed as beat_of_occurrence in the traffic
    crashes dataset, and BEAT_NUM in the police beats dataset):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 导入两个数据集后，现在可以合并它们以将区数据添加到最终分析中。这是通过 pandas 中的 .merge() 函数完成的——我在两个数据框上使用了内连接，以捕捉两个数据框中的所有信息，使用两个数据框中的
    beat 数据作为连接键（在交通事故数据集中列为 beat_of_occurrence，在警察巡逻区数据集中为 BEAT_NUM）：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'A quick look at the information provided from the .info() function shows a
    number of columns with sparse data. This can be visualized using the missingno
    matrix function:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 从 .info() 函数提供的信息快速查看显示了几个数据稀疏的列。这可以通过 missingno 矩阵函数可视化：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This displays a matrix of missing data in all columns, as can be seen here:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了所有列中的缺失数据矩阵，如下图所示：
- en: '![](../Images/8ddefcffff4587b8760e38a75063522a.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ddefcffff4587b8760e38a75063522a.png)'
- en: Unrefined dataset, with multiple columns containing a large number of null values
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 未经精炼的数据集，多个列包含大量的空值
- en: 'By dropping columns with sparse data, a much cleaner dataset can be extracted;
    the columns to drop are defined in a list and then removed from the dataset using
    the .drop() function:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过删除包含稀疏数据的列，可以提取一个更干净的数据集；要删除的列在列表中定义，然后使用 .drop() 函数从数据集中移除：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This leads to a much cleaner msno matrix:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了一个更干净的 msno 矩阵：
- en: '![](../Images/86afb14e5fbe44f518d42995e2a3cafe.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86afb14e5fbe44f518d42995e2a3cafe.png)'
- en: msno matrix of the pruned dataset
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 修剪后的数据集的 msno 矩阵
- en: 'Looking at the data for latitude and longitude, a small handful of rows had
    null values, and others mistakenly had zero values (most likely a reporting error):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 查看纬度和经度的数据，少量行有空值，而其他行错误地有零值（很可能是报告错误）：
- en: '![](../Images/9560f62ade6057976786637b088d1019.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9560f62ade6057976786637b088d1019.png)'
- en: Both the latitude and longitude columns contain zero values (see min and max
    of each)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 纬度和经度列都包含零值（查看每列的最小值和最大值）
- en: 'These would cause errors in training the model, so I removed them:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些会导致训练模型时出错，所以我将它们移除了：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With the data adequately cleaned, I was able to progress with developing the
    classification model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据充分清理后，我能够继续开发分类模型。
- en: Classification Model
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类模型
- en: Exploratory Data Analysis
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: 'Before proceeding with the machine learning model some exploratory data analysis
    (EDA) needs to be performed — each of the columns of the data frame are plotted
    on a histogram, with bins of 50 to show the distribution of the data. Histograms
    are useful in the EDA step for a number of reasons, namely that they give an overview
    of the data distribution, help to identify outliers, and ultimately assist in
    making decisions on feature engineering:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行机器学习模型之前，需要进行一些探索性数据分析（EDA）——数据框的每一列都绘制在直方图上，使用 50 个箱子来显示数据的分布。直方图在 EDA 步骤中很有用，主要是因为它们提供了数据分布的概述，有助于识别异常值，并最终帮助做出特征工程的决策：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/dabb1f342e2339419ce97928a009e5c9.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dabb1f342e2339419ce97928a009e5c9.png)'
- en: Histograms of columns in the final dataset
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最终数据集中列的直方图
- en: A cursory look at the column histograms indicates that the latitude data is
    bimodal, while the longitude data is rightly skewed. This will need to be standardized
    so that it can be better applied for machine learning purposes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 粗略查看列的直方图显示，纬度数据是双峰的，而经度数据则是偏斜的。这需要标准化，以便更好地应用于机器学习目的。
- en: '![](../Images/58122511ccb77af36d3f28cdc50dfa73.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58122511ccb77af36d3f28cdc50dfa73.png)'
- en: Latitude-longitude data without scaling
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 未缩放的纬度-经度数据
- en: Additionally, it appears the crash hour column is cyclic in nature — this can
    be transformed using a trigonometric function (for example sine).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，崩溃小时列似乎具有周期性特征——这可以通过三角函数（例如正弦）进行变换。
- en: '![](../Images/bca2dc70a0a58594ad142e00fc5d70c1.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bca2dc70a0a58594ad142e00fc5d70c1.png)'
- en: Unscaled crash hour data
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 未缩放的崩溃小时数据
- en: Scaling and Transformation
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩放与变换
- en: Scaling is a technique used in data preprocessing to standardise features so
    they have similar magnitudes. This is particularly important for machine learning
    models, since models are generally sensitive to the scale of input features. I’ve
    defined the StandardScaler() function to act as the scaler in this model — this
    scaling function transforms the data so that it has a mean of 0 and standard deviation
    of 1.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放是一种在数据预处理中用于标准化特征的技术，使其具有相似的大小。这对于机器学习模型尤为重要，因为模型通常对输入特征的尺度很敏感。我定义了 StandardScaler()
    函数作为此模型中的缩放器——这个缩放函数将数据转换为均值为 0 和标准差为 1 的形式。
- en: For data with a skewed or bimodal distribution, scaling can be done using logarithmic
    functions. Log functions make skewed data more symmetrical and reduce the tail
    on the data — this is useful when dealing with outlier values. I scaled the latitude
    and longitude data in this way; as the longitude data is all negative, the negative
    log was calculated and then scaled.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有偏斜或双峰分布的数据，可以使用对数函数进行缩放。对数函数使偏斜的数据更为对称，并减少数据中的尾部——这在处理异常值时非常有用。我以这种方式缩放了纬度和经度数据；由于经度数据都是负值，因此计算了负对数，然后进行了缩放。
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This produces the desired effect, as can be seen below:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了期望的效果，如下所示：
- en: '![](../Images/d40c2792cadb8aa7ed521ec34a48a922.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d40c2792cadb8aa7ed521ec34a48a922.png)'
- en: Scaled latitude-longitude data
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放后的纬度-经度数据
- en: 'In comparison, cyclic data is usually scaled using trigonometric functions
    such as sine and cos. The crash hour data looks roughly cyclic based on earlier
    observations, so I applied a sine function to the data as below — since numpy’s
    sin() function is in radians, I first converted the input to radians before calculating
    the sine of the input:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，周期性数据通常使用三角函数（如正弦和余弦）进行缩放。根据早期观察，崩溃小时数据看起来大致是周期性的，所以我对数据应用了正弦函数——由于 numpy
    的 sin() 函数以弧度为单位，我在计算输入的正弦值之前，首先将输入转换为弧度：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'A histogram of the transformed data can be seen below:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 变换后的数据的直方图如下所示：
- en: '![](../Images/430743b8c2856810abdecffc1247a433.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/430743b8c2856810abdecffc1247a433.png)'
- en: Scaled crash hour data
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放后的崩溃小时数据
- en: 'Finally I removed the unscaled data from the model to avoid this interfering
    with model predictions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我从模型中移除了未缩放的数据，以避免干扰模型预测：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Data Encoding
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据编码
- en: 'Another important step in data preprocessing is data encoding — this is where
    non-numerical data (for example categories) are represented in numerical format,
    to make it compatible with machine learning algorithms. For categorical data in
    this model, I used a method called label encoding — each category in a column
    is given a numerical value before it’s inputted to the model. A diagram of this
    process is shown below:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理的另一个重要步骤是数据编码——这是将非数值数据（例如类别）表示为数值格式的过程，以使其与机器学习算法兼容。在这个模型中，对于类别数据，我使用了一种叫做标签编码的方法——在将每个类别输入到模型之前，为列中的每个类别分配一个数值。此过程的示意图如下：
- en: '![](../Images/99c8167d785b05fe41467a25090b78d1.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/99c8167d785b05fe41467a25090b78d1.png)'
- en: An example of label encoding (credits to Zach M—[source](https://www.statology.org/label-encoding-in-python/))
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 标签编码的一个示例（感谢 Zach M—[来源](https://www.statology.org/label-encoding-in-python/)）
- en: 'I encoded the columns in the dataset, first segmenting out the columns I wanted
    to keep from the original dataset and making a copy of the dataframe (collisions_ml).
    I then defined the categorical columns in a list, and used the LabelEncoder()
    function from sklearn to fit and transform the categorical columns:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我对数据集中的列进行了编码，首先将要保留的列从原始数据集中分离出来，并制作了数据框（collisions_ml）的副本。然后，我在列表中定义了类别列，并使用
    sklearn 的 LabelEncoder() 函数来拟合和变换这些类别列：
- en: '[PRE10]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With the data now sufficiently preprocessed, the data can now be split into
    train and test data, and a classification model can be fitted to the data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据已经足够预处理，现在可以将数据拆分为训练数据和测试数据，并对数据进行分类模型拟合。
- en: Splitting the Train & Test Data
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆分训练和测试数据
- en: It’s important to separate data into a training and test sets when building
    a machine learning model; the training set is a fraction of the initial data which
    is used to train the model on the right responses, whereas the test set is used
    to evaluate model performance. Keeping these separate is necessary to reduce the
    risk of overfitting and model bias.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建机器学习模型时，将数据分为训练集和测试集非常重要；训练集是初始数据的一部分，用于对模型进行正确响应的训练，而测试集用于评估模型性能。保持这两者分开是减少过拟合和模型偏差风险的必要措施。
- en: I separated out the crash_type column using the drop() function (the remaining
    features will be used as the variables to predict crash_type), and defined crash_type
    as the y result to be predicted using the model. The train_test_split function
    from sklearn was used to take 20% of the initial dataset as training data, with
    the rest to be used for model testing.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用 drop() 函数分离出 crash_type 列（其余特征将用作预测 crash_type 的变量），并将 crash_type 定义为使用模型进行预测的
    y 结果。使用 sklearn 的 train_test_split 函数将初始数据集的 20% 作为训练数据，其余部分用于模型测试。
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: K-Nearest Neighbors Classification
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K-近邻分类
- en: For this project, a K-Nearest Neighbors (KNN) classification model is used to
    predict results from the features. KNN models work by checking the value of the
    K nearest known values around an unknown data point, then classifying the data
    point based on the values of those “neighbor” points. It’s a non-parametric classifier,
    meaning it doesn’t make any assumptions about the underlying data distribution;
    however it is computationally expensive, and can be sensitive to outliers in the
    data.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，使用 K-近邻（KNN）分类模型根据特征预测结果。KNN 模型通过检查未知数据点周围 K 个最近已知值的值来工作，然后根据这些“邻居”点的值对数据点进行分类。它是一种非参数分类器，这意味着它对底层数据分布没有任何假设；然而，它计算开销大，并且对数据中的异常值可能敏感。
- en: 'I instantiated the KNN classifier with an initial n_neighbors equal to 3, using
    Euclidean metrics, before fitting the model to the training data:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我初始化了 KNN 分类器，初始 n_neighbors 设置为 3，使用欧几里得度量，然后将模型拟合到训练数据上：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once the model was fitted to the training data, I made predictions on the test
    data as below:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型拟合到训练数据上，我对测试数据进行了如下预测：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Evaluation
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估
- en: 'Evaluation of a machine learning model is typically done using four metrics;
    accuracy, precision, recall, and F1 score. The differences between these metrics
    are very subtle, but in plain English these terms can be defined as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的评估通常使用四个指标：准确率、精确率、召回率和 F1 分数。这些指标之间的差异非常细微，但用通俗的语言可以定义如下：
- en: '***Accuracy:***the percentage of true positive predictions out of all model
    predictions. Typically the accuracy of both the train and test data should be
    measured to evaluate model fit.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***准确率:*** 真正例预测占所有模型预测的百分比。通常，应测量训练数据和测试数据的准确率以评估模型拟合情况。'
- en: '***Precision:***the percentage of true positive predictions out of all *positive*
    model predictions.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***精确率:*** 真正例预测占所有*正*模型预测的百分比。'
- en: '***Recall:***the percentage of true positive predictions out of all *positive
    cases in the dataset*.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***召回率:*** 真正例预测占所有*数据集中正例的百分比*。'
- en: '***F1 Score:***An overall metric of the model’s ability to identify positive
    instances in the data, combining the precision and recall scores.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***F1 分数:*** 模型识别数据中正例能力的总体指标，结合了精确率和召回率分数。'
- en: 'I computed the metrics of the KNN model using the below code snippet — I also
    calculated the difference between the model’s accuracy on the train and test set,
    to assess fit:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用以下代码片段计算了 KNN 模型的指标——我还计算了模型在训练集和测试集上的准确性差异，以评估拟合情况：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The initial metrics of the KNN model are given below:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 模型的初始指标如下：
- en: '![](../Images/17700f1bc58bfc9e8bd2aea18151e5d6.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17700f1bc58bfc9e8bd2aea18151e5d6.png)'
- en: Metrics of the KNN model on the 1st iteration
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: KNN 模型在第一次迭代中的指标
- en: The model scored well on test accuracy (79.6%), precision (82.1%), recall (91.1%),
    and F1 score (86.3%) — however the test accuracy was much higher than the train
    accuracy at 93.1%, a 13.5% difference. This indicates the model is overfitting
    the data, which means it would struggle to accurately make predictions on unseen
    data. Therefore the model needs to be adjusted for a better fit — this can be
    done using a process called hyperparameter tuning.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在测试准确率（79.6%）、精确度（82.1%）、召回率（91.1%）和F1分数（86.3%）上表现良好——然而，测试准确率远高于训练准确率，达到了93.1%，差异为13.5%。这表明模型存在过拟合现象，这意味着它在对未见数据进行准确预测时会遇到困难。因此，需要调整模型以获得更好的拟合——这可以通过一种称为超参数调整的过程来完成。
- en: Hyperparameter Tuning
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数调整
- en: Hyperparameter tuning is the process of selecting the best set of hyperparameters
    for a machine learning model. I fine-tuned the model using *k-fold cross-validation*
    — this is a resampling technique where the data is split into *k* subsets (or
    *folds*), then each fold in turn is used as the validation set while the remaining
    data is used as the training set. This method is effective at reducing the risk
    of bias being introduced to the model by a particular choice of training/test
    set.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调整是选择机器学习模型最佳超参数集的过程。我使用了*k折交叉验证*对模型进行了微调——这是一种重采样技术，将数据拆分为*k*个子集（或*折*），然后每个折轮流用作验证集，而其余数据用作训练集。这种方法有效地降低了由于特定训练/测试集选择引入模型偏差的风险。
- en: 'The hyperparameters for the KNN model are number of neighbors (*n_neighbors*)
    and the distance metric. There are a number of different ways to measure distance
    in a KNN classifier, but here I focused on two options:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: KNN模型的超参数包括邻居数量（*n_neighbors*）和距离度量。有多种方法可以在KNN分类器中测量距离，但在这里我专注于两个选项：
- en: '***Euclidean:*** This can be thought of as the straight-line distance between
    two points — it’s the most commonly used distance metric.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***欧几里得：*** 这可以被认为是两点之间的直线距离——它是最常用的距离度量。'
- en: '***Manhattan:*** Also called “city block” distance, this is the sum of absolute
    differences between the coordinates of 2 points. If you imagine standing at the
    corner of a city building and trying to get to the opposite corner — you wouldn’t
    cross through the building to get to the other side, but instead go up one block,
    then across one block.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***曼哈顿：*** 也称为“城市街区”距离，这是两个点之间坐标绝对差异的总和。如果你想象站在城市建筑的一个角落并试图到达对角线的另一角——你不会穿过建筑物，而是先上一个街区，然后横穿一个街区。'
- en: Note that I could have also fine-tuned the weight parameter (which determines
    whether all neighbors vote equally or if the closer neighbors are given more importance),
    but I decided to keep the voting weight uniform.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我也可以对权重参数进行微调（该参数决定了所有邻居是否平等投票，或者较近的邻居是否被赋予更高的重要性），但我决定保持投票权重均匀。
- en: 'I defined a parameter grid with n_neighbors of 3, 7, and 10, as well as metrics
    of Euclidean or Manhattan. I then instantiated a *RandomizedSearchCV* algorithm,
    passing in the KNN classifier as the estimator, along with the parameter grid.
    I set the algorithm to split the data into 5 folds by setting the *cv* parameter
    to 5; this was then fit to the training set. A snippet of the code for this can
    be seen below:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我定义了一个参数网格，包含`n_neighbors`值为3、7和10，以及欧几里得或曼哈顿度量。我然后实例化了一个*RandomizedSearchCV*算法，将KNN分类器作为估计器，并传入参数网格。我将算法设置为将数据拆分为5折，通过将*cv*参数设置为5；然后将其拟合到训练集上。以下是相关代码片段：
- en: '[PRE15]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The best accuracy and classifier were retrieved from the algorithm, indicating
    the classifier performs best with n_neighbors set to 10 while using the Manhattan
    distance metric, and that this would lead to an accuracy score of 74.0%:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从算法中检索到最佳准确率和分类器，表明分类器在使用曼哈顿距离度量时，`n_neighbors`设置为10的效果最佳，这将导致准确率为74.0%：
- en: '![](../Images/9963e8e45180eccf9d1164261b6bec92.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9963e8e45180eccf9d1164261b6bec92.png)'
- en: Results of cross-validation — the random search classifier recommends n_neighbors=10
    using the manhattan distance metric
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的结果——随机搜索分类器推荐使用`n_neighbors=10`，采用曼哈顿距离度量
- en: 'as such these parameters were inputted to the classifier, and the model was
    retrained:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这些参数被输入到分类器中，模型被重新训练：
- en: '[PRE16]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Performance metrics were again extracted from the classifier, in the same manner
    as before — a screengrab of the metrics for this iteration can be seen below:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 性能指标再次从分类器中提取，方式与之前相同——以下是此迭代的指标截屏：
- en: '![](../Images/74133d0794d4f83f0e6c7c3c131f0ad6.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74133d0794d4f83f0e6c7c3c131f0ad6.png)'
- en: Metrics of the tuned KNN model
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的KNN模型指标
- en: Cross-validation led to slightly poorer results for all metrics; test accuracy
    dropped by 2.6%, precision by 1.5%, recall by 0.5%, and F1 score by 1%. however
    the training-test accuracy difference dropped to 3.8%, where it was initially
    13.5%. This indicates the model is no longer overfitting the data, and is therefore
    more suitable for predicting unseen data.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证导致所有指标的结果略有下降；测试准确率下降了2.6%，精确度下降了1.5%，召回率下降了0.5%，F1分数下降了1%。然而，训练与测试准确率的差异降至3.8%，而最初为13.5%。这表明模型不再过拟合数据，因此更适合预测未见过的数据。
- en: Conclusion
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In summary, the KNN classifier performed well in predicting whether a collision
    would require a tow or ambulance. Initial metrics from the model’s first iteration
    were impressive, however the disparity between test and training accuracy indicated
    overfitting. Hyperparameter tuning allowed for the model to be optimised, which
    significantly reduced the gap in accuracies between the two datasets. While performance
    metrics did take a small hit during this process, the benefit of a model with
    better fit outweighs these concerns.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，KNN分类器在预测碰撞是否需要拖车或救护车方面表现良好。模型首次迭代的初步指标令人印象深刻，但测试和训练准确率之间的差距表明存在过拟合。超参数调整使得模型得以优化，从而显著减少了两个数据集之间的准确率差距。虽然在此过程中性能指标有所下降，但模型更好的拟合度的好处超越了这些问题。
- en: References
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Levy, J. (n.d.). Traffic Crashes — Crashes [Dataset]. Retrieved from Chicago
    Data Portal. Available at: [https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if)
    (Accessed: 14th May 2023).'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Levy, J. (无日期)。交通事故——事故[数据集]。取自芝加哥数据门户网站。网址：[https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if](https://data.cityofchicago.org/Transportation/Traffic-Crashes-Crashes/85ca-t3if)（访问日期：2023年5月14日）。
- en: 'Chicago Police Department. (n.d.). Boundaries — Police Beats (current) [Data
    set]. Retrieved from Chicago Data Portal. Available at: [https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74](https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74)
    (Accessed: 14th May 2023).'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 芝加哥警察局（无日期）。边界——警察巡逻区（当前）[数据集]。取自芝加哥数据门户网站。网址：[https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74](https://data.cityofchicago.org/Public-Safety/Boundaries-Police-Beats-current-/aerh-rz74)（访问日期：2023年5月14日）。
- en: 'Zach M. (2022). “How to Perform Label Encoding in Python (With Example).” [Online].
    Available at: [https://www.statology.org/label-encoding-in-python/](https://www.statology.org/label-encoding-in-python/)
    (Accessed: July 19th, 2023).'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zach M. (2022)。“如何在Python中进行标签编码（附示例）。”[在线]。网址：[https://www.statology.org/label-encoding-in-python/](https://www.statology.org/label-encoding-in-python/)（访问日期：2023年7月19日）。
