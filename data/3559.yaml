- en: 'dbt Core, Snowflake, and GitHub Actions: pet project for Data Engineers'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt Core、Snowflake 和 GitHub Actions：数据工程师的个人项目
- en: 原文：[https://towardsdatascience.com/dbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44?source=collection_archive---------7-----------------------#2023-12-01](https://towardsdatascience.com/dbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44?source=collection_archive---------7-----------------------#2023-12-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/dbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44?source=collection_archive---------7-----------------------#2023-12-01](https://towardsdatascience.com/dbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44?source=collection_archive---------7-----------------------#2023-12-01)
- en: 'Pet Project for Data/Analytics Engineers: Explore Modern Data Stack Tools —
    dbt Core, Snowflake, Fivetran, GitHub Actions.'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据/分析工程师的个人项目：探索现代数据堆栈工具——dbt Core、Snowflake、Fivetran 和 GitHub Actions。
- en: '[](https://medium.com/@kategera6?source=post_page-----815991a48b44--------------------------------)[![Kateryna
    Herashchenko](../Images/dd6018e0f3ffb6d4fecd8cb72100282c.png)](https://medium.com/@kategera6?source=post_page-----815991a48b44--------------------------------)[](https://towardsdatascience.com/?source=post_page-----815991a48b44--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----815991a48b44--------------------------------)
    [Kateryna Herashchenko](https://medium.com/@kategera6?source=post_page-----815991a48b44--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@kategera6?source=post_page-----815991a48b44--------------------------------)[![Kateryna
    Herashchenko](../Images/dd6018e0f3ffb6d4fecd8cb72100282c.png)](https://medium.com/@kategera6?source=post_page-----815991a48b44--------------------------------)[](https://towardsdatascience.com/?source=post_page-----815991a48b44--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----815991a48b44--------------------------------)
    [Kateryna Herashchenko](https://medium.com/@kategera6?source=post_page-----815991a48b44--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4fc94e2ed685&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44&user=Kateryna+Herashchenko&userId=4fc94e2ed685&source=post_page-4fc94e2ed685----815991a48b44---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----815991a48b44--------------------------------)
    ·6 min read·Dec 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F815991a48b44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44&user=Kateryna+Herashchenko&userId=4fc94e2ed685&source=-----815991a48b44---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4fc94e2ed685&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44&user=Kateryna+Herashchenko&userId=4fc94e2ed685&source=post_page-4fc94e2ed685----815991a48b44---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----815991a48b44--------------------------------)
    ·6 分钟阅读·2023年12月1日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F815991a48b44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44&user=Kateryna+Herashchenko&userId=4fc94e2ed685&source=-----815991a48b44---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F815991a48b44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44&source=-----815991a48b44---------------------bookmark_footer-----------)![](../Images/c550e2d6ed787a2bf6243b3e727599ff.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F815991a48b44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdbt-core-snowflake-and-github-actions-pet-project-for-data-engineers-815991a48b44&source=-----815991a48b44---------------------bookmark_footer-----------)![](../Images/c550e2d6ed787a2bf6243b3e727599ff.png)'
- en: Photo by [Gaining Visuals](https://unsplash.com/@gainingvisuals?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Gaining Visuals](https://unsplash.com/@gainingvisuals?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Here is a simple and fast pet project for Data/Analytics Engineers, who want
    to kick the tires on Modern Data Stack tools including dbt Core, Snowflake, Fivetran,
    and GitHub Actions. This hands-on experience will allow you to develop an end-to-end
    data lifecycle, from extracting data from your Google Calendar to presenting it
    in a Snowflake analytics dashboard. In this article, I’ll walk you through the
    project, sharing insights and tips along the way. [*See Github repo.*](https://github.com/KHerashchenko/SurfalyticsWorkshop/tree/master)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单且快速的宠物项目，适合希望尝试现代数据栈工具的 Data/Analytics 工程师，包括 dbt Core、Snowflake、Fivetran
    和 GitHub Actions。通过这个实践经验，你可以开发一个端到端的数据生命周期，从从你的 Google Calendar 提取数据到在 Snowflake
    分析仪表板中展示数据。在本文中，我将带你了解这个项目，并分享一些见解和技巧。[*查看 GitHub 仓库*](https://github.com/KHerashchenko/SurfalyticsWorkshop/tree/master)
- en: Technical Overview
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术概述
- en: 'The project architecture is depicted as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 项目架构如下所示：
- en: '**Google Calendar** -> **Fivetran** -> **Snowflake** -> **dbt** -> **Snowflake
    Dashboard**, with **GitHub Actions** orchestrating the deployment.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**Google Calendar** -> **Fivetran** -> **Snowflake** -> **dbt** -> **Snowflake
    Dashboard**，由**GitHub Actions**协调部署。'
- en: '![](../Images/8ff05646a8b0204831aa105f5ef64cda.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ff05646a8b0204831aa105f5ef64cda.png)'
- en: Architecture
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 架构
- en: 'Referencing Joe Reis’s “Fundamentals of Data Engineering,” let’s review our
    project in alignment with the defined stages of the data lifecycle:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 参考 Joe Reis 的《数据工程基础》，让我们根据数据生命周期的定义阶段来审视我们的项目：
- en: '![](../Images/f1733e478c42fe23b00c1fa9d7338888.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1733e478c42fe23b00c1fa9d7338888.png)'
- en: Data Engineering Lifecycle [1]
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程生命周期 [1]
- en: '**Data Generation — *Google Calendar, Fivetran*** If you’re a Google Calendar
    user, chances are you’ve accumulated a wealth of data there. Now you can easily
    retrieve it from your account by leveraging “data movement platforms” like Fivetran.
    This tool automates ELT (Extract, Load, Transform) process, integrating your data
    from the source system of Google Calendar to our Snowflake data warehouse.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据生成 — *Google Calendar, Fivetran*** 如果你是 Google Calendar 用户，你可能已经积累了大量的数据。现在，你可以通过利用
    Fivetran 这样的“数据移动平台”轻松从你的账户中检索这些数据。该工具自动化了 ELT（提取、加载、转换）过程，将数据从 Google Calendar
    源系统集成到我们的 Snowflake 数据仓库中。'
- en: As of now, Fivetran offers 14-day free trial — [link](https://fivetran.com/docs/getting-started/free-trials/account-trial).
    Registration is very straightforward.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目前，Fivetran 提供 14 天的免费试用 — [链接](https://fivetran.com/docs/getting-started/free-trials/account-trial)。注册非常简单。
- en: '**Storage — *Snowflake*** Snowflake, a cloud-based data warehouse tailored
    for analytical needs, will serve as our data storage solution. The data volume
    we will deal with is small, so we will not try to overkill with data partitioning,
    time travel, Snowpark, and other Snowflake advanced capabilities. However, we
    will pay particular attention to Access Control (this will be used for dbt access).
    You need to [set up a trial account](https://signup.snowflake.com/) which provides
    you with 30 days of free usage and 400$ limit for the Enterprise edition.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储 — *Snowflake*** Snowflake 是一个针对分析需求的云数据仓库，将作为我们的数据存储解决方案。我们处理的数据量较小，因此不会过度使用数据分区、时间旅行、Snowpark
    和其他 Snowflake 高级功能。然而，我们会特别关注访问控制（这将用于 dbt 访问）。你需要 [设置试用账户](https://signup.snowflake.com/)，这将为你提供
    30 天的免费使用和 400$ 的企业版额度。'
- en: '**Ingestion — *Fivetran*** Data ingestion can be configured from both Fivetran
    and Snowflake using the Partner Connect feature. Choose your preferred method
    and set up the Google Calendar connector. After the initial sync, you can access
    your data from the Snowflake UI. You can visit the connector webpage to see the
    schema diagram [here](https://www.fivetran.com/connectors/google-calendar).'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取 — *Fivetran*** 数据摄取可以通过 Fivetran 和 Snowflake 的 Partner Connect 功能进行配置。选择你喜欢的方法并设置
    Google Calendar 连接器。初始同步后，你可以通过 Snowflake UI 访问你的数据。你可以访问连接器网页查看模式图 [这里](https://www.fivetran.com/connectors/google-calendar)。'
- en: A new database will be created specifically for Fivetran sync, and the corresponding
    warehouse to run SQL workloads. As you should know, Snowflake is built with decoupled
    Storage and Compute, hence the costs are separated as well. As a best practice,
    you should use different warehouses for different workloads (ad-hoc, sync, BI
    analytics) or different environments (dev, prod).
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将专门为 Fivetran 同步创建一个新数据库，以及相应的仓库以运行 SQL 工作负载。你应该知道，Snowflake 采用了解耦的存储和计算，因此费用也是分开的。作为最佳实践，你应该为不同的工作负载（如临时、同步、BI
    分析）或不同的环境（如开发、生产）使用不同的仓库。
- en: '![](../Images/f431365d1580340e358dcf4cd9e149a9.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f431365d1580340e358dcf4cd9e149a9.png)'
- en: Go to Partner Connect to connect Fivetran
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 转到 Partner Connect 以连接 Fivetran。
- en: '![](../Images/7a112d493f9447f09ce99c6536c95c72.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7a112d493f9447f09ce99c6536c95c72.png)'
- en: Set up Google Calendar connector in Fivetran
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Fivetran 中设置 Google Calendar 连接器。
- en: '![](../Images/38a2542d3dac0d8066fd9bdccd10fae0.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38a2542d3dac0d8066fd9bdccd10fae0.png)'
- en: Synced data appears in Snowflake
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 同步的数据会出现在 Snowflake 中。
- en: '**Transformation — *dbt Core*** With the data residing in Snowflake (and automatically
    syncing every 6 hours by default), we move to the Transformation stage using dbt
    Core. dbt (data build tool) facilitates modularization of SQL queries, enabling
    the reuse and version control of SQL workflows, just like software code is typically
    managed. There are two ways to access dbt: dbt Cloud and dbt Core. dbt Cloud is
    a paid cloud-based version of the service and dbt Core is a python package providing
    all functionality you can use for free.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformation — *dbt Core*** 数据存储在 Snowflake 中（默认每 6 小时自动同步），我们使用 dbt Core
    进入变换阶段。dbt（数据构建工具）有助于 SQL 查询的模块化，使 SQL 工作流能够重用和版本控制，就像软件代码通常被管理一样。有两种方式可以访问 dbt：dbt
    Cloud 和 dbt Core。dbt Cloud 是一个付费的云版本服务，而 dbt Core 是一个提供所有功能的 Python 包，你可以免费使用。'
- en: Install dbt Core on your machine, initialize the project using **“dbt init”**
    command in CLI, and set up the Snowflake connection. See the example of my [profiles.yml
    file](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/dbt_hol/profiles.yml).
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在你的机器上安装 dbt Core，通过 CLI 使用**“dbt init”**命令初始化项目，并设置 Snowflake 连接。请查看我的 [profiles.yml
    文件](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/dbt_hol/profiles.yml)。
- en: To be able to connect to Snowflake, we will also need to run a bunch of DCL
    (Data Control Language) SQL commands, find them [here](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/snowflake_setup.sql).
    Following the least privilege principle, we will create a separate user for dbt
    and give it access only to the source database (where Fivetran syncs data) and
    development, and production databases (where we will sink transformed data).
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了能够连接到 Snowflake，我们还需要运行一系列 DCL（数据控制语言）SQL 命令，详细信息请见 [这里](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/snowflake_setup.sql)。遵循最小权限原则，我们将为
    dbt 创建一个单独的用户，并仅授予其对源数据库（Fivetran 同步数据的位置）、开发数据库和生产数据库的访问权限（我们将在这些数据库中接收转换后的数据）。
- en: Following the [best practice structuring approach](https://docs.getdbt.com/best-practices/how-we-structure/1-guide-overview),
    you need to create three folders representing the *staging, intermediate, and
    marts layers* of your data transformations. Here you can experiment with your
    models, but also you can copy my [examples](https://github.com/KHerashchenko/SurfalyticsWorkshop/tree/master/dbt_hol/models)
    for Google Calendar data.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按照 [最佳实践结构化方法](https://docs.getdbt.com/best-practices/how-we-structure/1-guide-overview)，你需要创建三个文件夹，代表数据转换的
    *staging、intermediate 和 marts 层*。在这里你可以试验你的模型，也可以复制我的 [示例](https://github.com/KHerashchenko/SurfalyticsWorkshop/tree/master/dbt_hol/models)
    来处理 Google Calendar 数据。
- en: In the repo, you will find the “sources.yml” file listing all tables in the
    Google Calendar schema. There are 3 staging models created (event.sql,
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在仓库中，你会找到列出 Google Calendar 架构中所有表的 “sources.yml” 文件。创建了 3 个 staging 模型（event.sql，
- en: attendee.sql, recurrence.sql), 1 transform model (utc_event.sql), and 1 mart
    model (event_attendee_summary.sql).
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包括 1 个变换模型（utc_event.sql）和 1 个数据集市模型（event_attendee_summary.sql）在内的 attendee.sql
    和 recurrence.sql。
- en: The important features of dbt are [Jinja and macros](https://courses.getdbt.com/courses/jinja-macros-packages)
    that you can weave into SQL, enhancing its impact and reusability.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: dbt 的重要功能是 [Jinja 和宏](https://courses.getdbt.com/courses/jinja-macros-packages)，你可以将其编织到
    SQL 中，从而增强其影响力和可重用性。
- en: '![](../Images/875c9de7d5e6d260a7ea70df5ce0a13c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/875c9de7d5e6d260a7ea70df5ce0a13c.png)'
- en: Choose different types of model materializations
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 选择不同类型的模型物化。
- en: Set data expectations using generic or singular tests in dbt to ensure data
    quality. Some data quality rules are placed in the “source.yml” file,
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 dbt 中的通用或单一测试设置数据期望，以确保数据质量。一些数据质量规则位于 “source.yml” 文件中，
- en: as well as in the “/tests” folder. During the **“dbt build”** command these
    data quality checks will be run along with models build to prevent data corruption.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以及 “/tests” 文件夹中。在**“dbt build”**命令期间，这些数据质量检查将与模型构建一起运行，以防止数据损坏。
- en: '![](../Images/4c204eaf6b005f942f81ca4c07541544.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c204eaf6b005f942f81ca4c07541544.png)'
- en: You can run tests using “dbt test”
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 “dbt test” 运行测试。
- en: Explore dbt’s Snapshot feature for change data capture and type-2 Slowly Changing
    Dimensions. In our [example](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/dbt_hol/snapshots/recurrence_snapshot.sql),
    we capture changes in the “recurrence” table.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索dbt的快照功能，用于变更数据捕获和类型2缓慢变化维度。在我们的[示例](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/dbt_hol/snapshots/recurrence_snapshot.sql)中，我们捕获了“recurrence”表中的变化。
- en: '![](../Images/e0da53b1e6955a9e2b81b1e635462f0f.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0da53b1e6955a9e2b81b1e635462f0f.png)'
- en: Store snapshots in a separate schema
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将快照存储在单独的模式中
- en: Take a while to generate dbt documentation using the **“dbt docs generate”**
    command. You will see the data lineage graph and metadata which is automatically
    created from your project. You can further enhance it by adding descriptions to
    data entities in your .yml files.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**“dbt docs generate”**命令生成dbt文档可能需要一些时间。你将看到从项目中自动创建的数据血缘图和元数据。你可以通过在你的 .yml
    文件中添加对数据实体的描述来进一步增强它。
- en: Good documentation provides better data discoverability and governance.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 良好的文档提供了更好的数据发现性和治理。
- en: '![](../Images/4f4e168ba3ead8b7e73fb3217d083382.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f4e168ba3ead8b7e73fb3217d083382.png)'
- en: run “dbt docs serve” to open it in browser
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `dbt docs serve` 以在浏览器中打开它。
- en: '**Serving — *Snowflake Dashboard*** Finally, visualize your transformed data
    using Snowflake Dashboards. Create a dashboard in the Snowflake UI and experiment
    with tiles (plots) based on your SQL queries.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务 — *Snowflake仪表板*** 最后，使用Snowflake仪表板可视化你的转换数据。在Snowflake UI中创建一个仪表板，并根据你的SQL查询尝试使用图块（绘图）。'
- en: '![](../Images/266ccc344bbcbe911847257bee354a3a.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/266ccc344bbcbe911847257bee354a3a.png)'
- en: Example of the dashboard
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板示例
- en: '**Deploying — *GitHub Actions*** While dbt Cloud offers an easy deployment
    option, we’ll use GitHub Actions workflows for our dbt Core project. You need
    to create a [workflow .yml file](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/.github/workflows/dbt_prod.yaml)
    which will be triggered whenever changes are pushed to the GitHub dbt repo, running
    specified actions. In my example workflow, you can see a two-step deployment process:
    **dbt build** for the development environment and in case of success, also **dbt'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署 — *GitHub Actions*** 虽然dbt Cloud提供了一个简单的部署选项，但我们将使用GitHub Actions工作流来进行我们的dbt
    Core项目。你需要创建一个[workflow .yml 文件](https://github.com/KHerashchenko/SurfalyticsWorkshop/blob/master/.github/workflows/dbt_prod.yaml)，该文件将在对GitHub
    dbt repo进行更改时触发，运行指定的操作。在我的示例工作流中，你可以看到一个两步的部署过程：**dbt build**用于开发环境，成功后还会执行**dbt'
- en: build** for the production environment.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**用于生产环境的build**。'
- en: 'Note: replace secrets like Snowflake account and password with GitHub secrets.
    For that, on your repo webpage, go to Settings -> Secrets and Variables -> Actions.'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：将Snowflake账户和密码等机密替换为GitHub机密。为此，请在你的repo网页上，转到Settings -> Secrets and Variables
    -> Actions。
- en: 'Every time “master” branch gets updated, you can see the workflow started in
    your Actions tab on the repo:'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每次“master”分支更新时，你可以在repo的Actions标签中看到工作流的启动情况：
- en: '![](../Images/129492b139aaeea10506b6b16fd85bf2.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/129492b139aaeea10506b6b16fd85bf2.png)'
- en: See Actions results
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Actions结果
- en: In this project, we’ve just scratched the surface of various technologies in
    the modern data engineering stack. It’s not only a practical accomplishment but
    also an excellent starting point for deeper exploration. Thank you for reading,
    and happy coding!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们仅仅触及了现代数据工程栈中各种技术的表面。这不仅是一个实际的成就，也是深入探索的绝佳起点。感谢阅读，祝编程愉快！
- en: '**If you reached the end of the article, maybe you found it valuable and may
    want to connect with me on** [**LinkedIn**](https://www.linkedin.com/in/kategera6/)**.
    *I am open to opportunities!***'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你读到了文章的末尾，也许你觉得它很有价值，并且可能想通过** [**LinkedIn**](https://www.linkedin.com/in/kategera6/)**与我联系。*我对机会持开放态度！***'
- en: '*Unless otherwise noted, all images are by the author.*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，否则所有图片均为作者提供。*'
- en: 'References:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[1] Reis, J. (2022). Fundamentals of Data Engineering: Plan and Build Robust
    Data Systems. O’Reilly Media.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Reis, J. (2022). 《数据工程基础：计划和构建强大的数据系统》。O''Reilly Media。'
