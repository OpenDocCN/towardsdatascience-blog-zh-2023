- en: How to Implement Learning to Rank Model using Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用Python实现学习排序模型
- en: 原文：[https://towardsdatascience.com/how-to-implement-learning-to-rank-model-using-python-569cd9c49b08](https://towardsdatascience.com/how-to-implement-learning-to-rank-model-using-python-569cd9c49b08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-implement-learning-to-rank-model-using-python-569cd9c49b08](https://towardsdatascience.com/how-to-implement-learning-to-rank-model-using-python-569cd9c49b08)
- en: The step-by-step guide on how to implement the lambdarank algorithm using Python
    and LightGBM
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Python和LightGBM实现lambdarank算法的逐步指南
- en: '[](https://ransakaravihara.medium.com/?source=post_page-----569cd9c49b08--------------------------------)[![Ransaka
    Ravihara](../Images/ac09746938c10ad8f157d46ea0de27ca.png)](https://ransakaravihara.medium.com/?source=post_page-----569cd9c49b08--------------------------------)[](https://towardsdatascience.com/?source=post_page-----569cd9c49b08--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----569cd9c49b08--------------------------------)
    [Ransaka Ravihara](https://ransakaravihara.medium.com/?source=post_page-----569cd9c49b08--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[![Ransaka Ravihara](../Images/ac09746938c10ad8f157d46ea0de27ca.png)](https://ransakaravihara.medium.com/?source=post_page-----569cd9c49b08--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----569cd9c49b08--------------------------------)
    [Ransaka Ravihara](https://ransakaravihara.medium.com/?source=post_page-----569cd9c49b08--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----569cd9c49b08--------------------------------)
    ·9 min read·Jan 18, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[数据科学前沿](https://towardsdatascience.com/?source=post_page-----569cd9c49b08--------------------------------)
    ·阅读时间9分钟·2023年1月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a1226b3e93be13fec3c422a5220459bf.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a1226b3e93be13fec3c422a5220459bf.png)'
- en: Photo by [Andrik Langfield](https://unsplash.com/@andriklangfield?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[安德里克·兰菲尔德](https://unsplash.com/@andriklangfield?utm_source=medium&utm_medium=referral)
    在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In my previous two articles, I discussed the basic concepts of Learning to Rank
    models and widely used evaluation metrics for evaluating LTR models. You can access
    those using the links listed below.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前的两篇文章中，我讨论了学习排序模型的基本概念以及评估LTR模型的广泛使用的评估指标。你可以通过下面列出的链接访问这些文章。
- en: '[](/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c?source=post_page-----569cd9c49b08--------------------------------)
    [## What Is Learning to Rank: A Beginner''s Guide to Learning to Rank Methods'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 什么是学习排序：学习排序方法的初学者指南](/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c?source=post_page-----569cd9c49b08--------------------------------) '
- en: A guide on how to approach LTR problems in Machine Learning
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于如何处理机器学习中的LTR问题的指南
- en: towardsdatascience.com](/what-is-learning-to-rank-a-beginners-guide-to-learning-to-rank-methods-23bbb99ef38c?source=post_page-----569cd9c49b08--------------------------------)
    [](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----569cd9c49b08--------------------------------)
    [## How to evaluate Learning to Rank Models
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 如何评估学习排序模型](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----569cd9c49b08--------------------------------)'
- en: A practical guide on how to evaluate LTR models in Machine Learning
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于如何在机器学习中评估LTR模型的实用指南
- en: towardsdatascience.com](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----569cd9c49b08--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[如何评估学习排序模型](/how-to-evaluate-learning-to-rank-models-d12cadb99d47?source=post_page-----569cd9c49b08--------------------------------)'
- en: In this article, we will build a lambdarank algorithm for anime recommendations.
    A research group first introduced LambdaRank at Microsoft, and now it's available
    on Microsoft's LightGBM library with an easy-to-use sklearn wrapper. Let's start.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将构建一个用于动漫推荐的lambdarank算法。LambdaRank最初由一个研究小组在微软介绍，现在它已经在微软的LightGBM库中提供，并配有易于使用的sklearn包装器。让我们开始吧。
- en: From Search Engines to Product Recommendations
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从搜索引擎到产品推荐
- en: As mentioned above, ranking is widely used in search engines. But it's not limited
    to search engines; we can adopt the concept and build a solution whenever applicable.
    Assuming that we want to develop a ranking model for a search engine, we should
    start with a dataset with queries, its associated documents(URLs), and the relevance
    score for each query document pair, as shown below.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，排名在搜索引擎中被广泛使用。但它不仅限于搜索引擎；我们可以采用这一概念，并在适用时构建解决方案。假设我们想为搜索引擎开发一个排名模型，我们应该从一个包含查询、其相关文档（URLs）以及每个查询文档对的相关性评分的数据集开始，如下所示。
- en: '![](../Images/0daaef87cb000cb9dc59e195a4456018.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0daaef87cb000cb9dc59e195a4456018.png)'
- en: Image by Author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Finally, we can derive features based on each query and document pair.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以基于每个查询和文档对推导特征。
- en: '![](../Images/548d9e099ae03770a1bddafffabac0da.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/548d9e099ae03770a1bddafffabac0da.png)'
- en: Image by Author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: This is the dataset format for well-known Learning to Rank research papers and
    datasets. Well, that's about search engines. Let's discuss how we can adapt these
    concepts for traditional product recommendation tasks. There are various ways
    to recommend products to users. You can show recommendations when the user purchases
    an item, or while a user is browsing the page, etc. But for simplicity, let's
    narrow it down to a specific scenario.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是著名的学习排名研究论文和数据集的数据集格式。好吧，这些是关于搜索引擎的内容。让我们讨论一下如何将这些概念适用于传统的产品推荐任务。有多种方法可以向用户推荐产品。你可以在用户购买物品时展示推荐，或在用户浏览页面时展示推荐等。但为了简单起见，我们将其缩小到一个具体场景。
- en: This article will build an anime recommendation model for users' homepage customization.
    When the user logs into the account, we need to show animes based on the relevance
    scores predicted by the ranker model. Here I will use Anime Recommendation LTR
    Dataset, which is available under a public license. You can access it via [this
    kaggle link](https://www.kaggle.com/datasets/ransakaravihara/anime-recommendation-ltr-dataset).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将建立一个用于用户主页定制的动漫推荐模型。当用户登录账户时，我们需要根据排名模型预测的相关性评分来展示动漫。这里我将使用Anime Recommendation
    LTR Dataset，它在公共许可下提供。你可以通过[这个kaggle链接](https://www.kaggle.com/datasets/ransakaravihara/anime-recommendation-ltr-dataset)访问它。
- en: Let's read the dataset and quickly check its columns.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们读取数据集并快速检查其列。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Alright, let me explain the methodology I am going to use here. Unlike search
    engine data, we don't have query and document pairs in this use case. So we will
    treat users as queries and the animes they are interested in as documents. One
    search query can be associated with multiple documents; users can interact with
    many animes. You got the idea, right :)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我解释一下我将在这里使用的方法。与搜索引擎数据不同，在这个用例中我们没有查询和文档对。因此，我们将用户视为查询，将他们感兴趣的动漫视为文档。一个搜索查询可以与多个文档关联；用户可以与许多动漫互动。你明白了，对吧
    :)
- en: The target label we predict here is *relevance_score,* stored in the *relevance_scores*
    dataset. When we build a raking model, it will learn a function to rank those
    anime into an optimum order where the highest relevant anime comes first for each
    user.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里预测的目标标签是*relevance_score*，存储在*relevance_scores*数据集中。当我们建立排名模型时，它将学习一个函数，将这些动漫按最优顺序排序，使每个用户的相关性最高的动漫排在最前面。
- en: Next, we need to create a dataset by joining the above three datasets. I will
    also create new features based on anime and user features. Let's create a dataset.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要通过合并上述三个数据集来创建一个新数据集。我还会基于动漫和用户特征创建新的特征。让我们开始创建数据集。
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let's quickly check a few statistics of our dataset. In total, there are 4.8Mn
    user-anime interactions, 15K users, and 16K animes in the dataset.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速查看一下数据集的一些统计信息。数据集中总共有4.8百万条用户-动漫互动记录，15K用户，和16K动漫。
- en: Here is the user and anime interaction distribution.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用户和动漫互动分布情况。
- en: '![](../Images/c5e62050e6c3c69368136027a119b174.png)![](../Images/dba0f5f2e2da5ddd60c7271f41ce87ac.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5e62050e6c3c69368136027a119b174.png)![](../Images/dba0f5f2e2da5ddd60c7271f41ce87ac.png)'
- en: Image by Author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: The below chart shows how the relevance score is distributed.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了相关性评分的分布情况。
- en: '![](../Images/4076e507b91eed9f8d5c55c6d4681c51.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4076e507b91eed9f8d5c55c6d4681c51.png)'
- en: Image by Author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Now we have created the dataset for model training. But one of the main confusing
    points of the Learning to Rank model is the *group* parameter. Because the *group*
    is a strange parameter for us since it is not commonly used in other machine-learning
    algorithms. The idea of a *group* parameter is partitioning the dataset for each
    query and document pair. It enables the model to learn the relative importance
    of different features within each group, which can improve the model's overall
    performance. Having ten user-anime pairs means we have ten groups in our LTR model.
    Each group can be different in size. But the sum of groups should be the number
    of samples we have. In simple words, we have to provide group boundaries using
    *group* parameters. Then the model can identify each user-anime instance separately.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了用于模型训练的数据集。但学习排名模型的一个主要困惑点是*group*参数。因为*group*对我们来说是一个陌生的参数，因为它在其他机器学习算法中并不常见。*group*参数的思想是对每个查询和文档对的
    数据集进行分区。它使模型能够学习每个组内不同特征的相对重要性，从而提高模型的整体性能。拥有十对用户-动漫意味着我们在 LTR 模型中有十个组。每个组的大小可以不同。但组的总和应该是我们拥有的样本数量。简单来说，我们必须使用*group*参数提供组边界。然后模型可以单独识别每个用户-动漫实例。
- en: For example, if you have a 6-anime dataset with `group = [3, 2, 1]`, which means
    that you have three groups, where the first three records are in the first group,
    records 4–5 are in the second group, and record 6 is in the third group.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有一个包含 6 部动漫的数据集，`group = [3, 2, 1]`，这意味着你有三个组，其中前三条记录在第一个组中，记录 4–5 在第二个组中，记录
    6 在第三个组中。
- en: '![](../Images/fbb8930d2c949a0b90e38c37ed935f9f.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbb8930d2c949a0b90e38c37ed935f9f.png)'
- en: Image by Author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**So it''s vital to sort the dataset by *user_id(query_id)* before creating
    the group parameter.**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**因此，在创建组参数之前，按 *user_id(query_id)* 排序数据集是至关重要的。**'
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the above code snippet, I have done the following steps,
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码片段中，我执行了以下步骤，
- en: Dropped all the columns which have more than 50% null values.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 丢弃了所有空值超过 50% 的列。
- en: Sorted dataset based on *user_id.* Otherwise, a *group* parameter will have
    inconsistent groups everywhere.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据 *user_id* 排序的数据集。否则，*group* 参数将在各处产生不一致的组。
- en: After sorting the dataset, I declared the last 100,000 rows as validation data
    and the rest as training data.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 排序数据集后，我将最后 100,000 行声明为验证数据，其余的作为训练数据。
- en: Since the LightGBM model expects integers as target values, I have scaled the
    target between 1–10 and converted it to an integer. ( If you want, try converting
    it to 0 or 1 based on the threshold).
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于 LightGBM 模型期望目标值为整数，我已将目标值缩放到 1–10 之间并转换为整数。 （如果你愿意，可以根据阈值尝试将其转换为 0 或 1。）
- en: Let's define the group parameters and quickly fit the model as follows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义组参数，并迅速拟合模型，如下所示。
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Alright, now we finished the training. It's time to make some predictions about
    specific customers.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，我们完成了训练。现在是对特定客户进行预测的时候了。
- en: There is one more critical point to notice here. That is, how the model predictions
    are calculated. I was confused because when calling the `.predict` method, it
    does not expect additional parameters such as *group.* So I found below information
    from GitHub issues. According to the creator of LightGBM mentioned in [this issue](https://github.com/microsoft/LightGBM/issues/3326),
    LightGBM's lambdarank uses a pointwise approach to generate predictions. Meaning
    we do not want to provide additional parameters such as *group.* We can call the
    `.predict()` method with the correct feature vector.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一个关键点需要注意。即模型预测是如何计算的。我感到困惑，因为调用 `.predict` 方法时，它不需要额外的参数，例如*group*。所以我从
    GitHub 问题中找到了以下信息。根据 LightGBM 的创建者在 [这个问题](https://github.com/microsoft/LightGBM/issues/3326)中提到的，LightGBM
    的 lambdarank 使用逐点方法生成预测。这意味着我们不需要提供额外的参数，如*group*。我们可以使用正确的特征向量调用 `.predict()`
    方法。
- en: However, since we are developing the LTR model, it's essential to have some
    candidate products and rank those according to the predicted relevance score.
    To generate candidate animes, I will use a straightforward method here. That is,
    select the animes that are not exposed to a given user. Select an N random subset
    from unexposed animes. Generate features based on user and selected N anime subset.
    Finally, use generated feature vector to get the relevance score and sort animes
    based on the relevance score. But in real-world use cases, we should use some
    meaningful methodologies. As an example, you can generate candidates as follows,
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于我们正在开发LTR模型，必须有一些候选产品，并根据预测的相关性评分对其进行排序。为了生成候选动漫，我将在这里使用一种简单的方法。即，选择未向给定用户展示的动漫。从未展示的动漫中选择一个N的随机子集。基于用户和选择的N部动漫子集生成特征。最后，使用生成的特征向量获取相关性评分，并根据相关性评分对动漫进行排序。但在实际应用中，我们应该使用一些有意义的方法。例如，你可以如下生成候选项，
- en: Select the user's favorite *N* number of genres.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择用户最喜欢的*N*个类别。
- en: For each genre in the above-selected genres, pick the highest-rated *m* animes.
    Now you have *M* N* animes to rank for that user. Just create the user base and
    anime-based features. And finally, call the `.predict()` method with the created
    feature vector.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于上面选择的每个类别，选择评分最高的*m*部动漫。现在你有*M* N*部动漫需要为该用户排序。只需创建用户基础和动漫基础特征。最后，使用创建的特征向量调用`.predict()`方法。
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/b98b6a5dfbfdd5cb97d730eea3e21d37.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b98b6a5dfbfdd5cb97d730eea3e21d37.png)'
- en: Additionally, we can use shap to explain the model's predictions.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以使用shap来解释模型的预测结果。
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/7bea7248bb0c60a3a4f301c298a0e1bb.png)![](../Images/fa10cc03b1fce53c20773110d75a055d.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7bea7248bb0c60a3a4f301c298a0e1bb.png)![](../Images/fa10cc03b1fce53c20773110d75a055d.png)'
- en: Image by Author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Conclusion
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: This article aims to give a good starting point to address readers' specific
    use cases. Because when I started building an LTR model for my project, there
    wasn't a good guide for beginners. However, training the LTR model may not be
    necessary for some use cases. You can use straightforward methods like regression,
    multiclass/ label classification, or clustering. So don't over-engineer your solutions;
    pick the tool wisely ; )
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在为读者的特定用例提供一个良好的起点。因为当我开始为我的项目构建LTR模型时，没有好的初学者指南。然而，对于某些用例，训练LTR模型可能不是必要的。你可以使用简单的方法，如回归、多分类/标签分类或聚类。所以不要过度设计你的解决方案；明智地选择工具吧
    ; )
- en: Thank you for reading! The notebook for this article is available in my [GitHub
    repo](https://github.com/Ransaka/LTR-with-LIghtGBM).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！本文的笔记本可以在我的[GitHub repo](https://github.com/Ransaka/LTR-with-LIghtGBM)中找到。
- en: 'References :'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[LightGBM documentation](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html#lightgbm.LGBMRanker)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LightGBM文档](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRanker.html#lightgbm.LGBMRanker)'
- en: '[Microsoft Learning to Rank Datasets](https://www.microsoft.com/en-us/research/project/mslr/)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[微软学习排序数据集](https://www.microsoft.com/en-us/research/project/mslr/)'
