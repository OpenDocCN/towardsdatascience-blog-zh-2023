- en: 'Retro-Engineering a Database Schema: GPT vs. Bard vs. LLama2 (Episode 2)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®åº“æ¨¡å¼çš„é€†å‘å·¥ç¨‹ï¼šGPT ä¸ Bard ä¸ Llama2ï¼ˆç¬¬2é›†ï¼‰
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/retro-engineering-a-database-schema-gpt-vs-bard-vs-llama2-episode-2-e7f144a6753b](https://towardsdatascience.com/retro-engineering-a-database-schema-gpt-vs-bard-vs-llama2-episode-2-e7f144a6753b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/retro-engineering-a-database-schema-gpt-vs-bard-vs-llama2-episode-2-e7f144a6753b](https://towardsdatascience.com/retro-engineering-a-database-schema-gpt-vs-bard-vs-llama2-episode-2-e7f144a6753b)
- en: In my previous article, I benchmarked GPT-4 model against Bard. Now Llama-2
    enters the arena and itâ€™s high time we see how it performs against its competitors!
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä¹‹å‰çš„æ–‡ç« ä¸­ï¼Œæˆ‘å¯¹æ¯”äº† GPT-4 æ¨¡å‹å’Œ Bardã€‚ç°åœ¨ Llama-2 è¿›å…¥äº†ç«æŠ€åœºï¼Œæ˜¯æ—¶å€™çœ‹çœ‹å®ƒä¸ç«äº‰å¯¹æ‰‹çš„è¡¨ç°äº†ï¼
- en: '[](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)[![Pierre-Louis
    Bescond](../Images/bb236055962b420fb3ab22088ab28f11.png)](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)
    [Pierre-Louis Bescond](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)[![çš®åŸƒå°”-è·¯æ˜“æ–¯Â·è´æ–¯å­”](../Images/bb236055962b420fb3ab22088ab28f11.png)](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)
    [çš®åŸƒå°”-è·¯æ˜“æ–¯Â·è´æ–¯å­”](https://pl-bescond.medium.com/?source=post_page-----e7f144a6753b--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)
    Â·6 min readÂ·Oct 6, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e7f144a6753b--------------------------------)
    Â·6 åˆ†é’Ÿé˜…è¯»Â·2023 å¹´ 10 æœˆ 6 æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2941f397ecb8ea1cf96ab9c325122f57.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2941f397ecb8ea1cf96ab9c325122f57.png)'
- en: Photo by [Dustin Humes](https://unsplash.com/@dustinhumes_photography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [è¾¾æ–¯æ±€Â·ä¼‘å§†æ–¯](https://unsplash.com/@dustinhumes_photography?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The Initial (and Final) Dataset
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆå§‹ï¼ˆå’Œæœ€ç»ˆï¼‰æ•°æ®é›†
- en: As explained [in this first article](https://medium.com/p/2e2776e8af86), weâ€™ll
    start with a fake AI-generated dataset containing employeesâ€™ information.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ [è¿™ç¯‡æ–‡ç« ](https://medium.com/p/2e2776e8af86) ä¸­æ‰€è¿°ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ªåŒ…å«å‘˜å·¥ä¿¡æ¯çš„å‡ AI ç”Ÿæˆæ•°æ®é›†å¼€å§‹ã€‚
- en: '[](/retro-engineering-a-database-schema-and-quality-checks-gpt-vs-bard-2e2776e8af86?source=post_page-----e7f144a6753b--------------------------------)
    [## Retro-engineering a database schema and quality checks: GPT vs. Bard'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[é“¾æ¥](https://retro-engineering-a-database-schema-and-quality-checks-gpt-vs-bard-2e2776e8af86?source=post_page-----e7f144a6753b--------------------------------)
    [## æ•°æ®åº“æ¨¡å¼åŠè´¨é‡æ£€æŸ¥çš„é€†å‘å·¥ç¨‹ï¼šGPT ä¸ Bard'
- en: Can LLMs retro-engineer a consolidated dataset to design the original database
    and suggest the corresponding dataâ€¦
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLM æ˜¯å¦å¯ä»¥é€†å‘å·¥ç¨‹ä¸€ä¸ªåˆå¹¶çš„æ•°æ®é›†æ¥è®¾è®¡åŸå§‹æ•°æ®åº“ï¼Œå¹¶æå‡ºç›¸åº”çš„æ•°æ®â€¦â€¦
- en: towardsdatascience.com](/retro-engineering-a-database-schema-and-quality-checks-gpt-vs-bard-2e2776e8af86?source=post_page-----e7f144a6753b--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[é“¾æ¥](https://towardsdatascience.com/retro-engineering-a-database-schema-and-quality-checks-gpt-vs-bard-2e2776e8af86?source=post_page-----e7f144a6753b--------------------------------)'
- en: The original table has 11 columns x 7688 rows but weâ€™ll limit the extract to
    a sample of 50 rows to accommodate current LLMs token limitations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹è¡¨æ ¼æœ‰ 11 åˆ— x 7688 è¡Œï¼Œä½†æˆ‘ä»¬å°†æå– 50 è¡Œæ ·æœ¬ï¼Œä»¥é€‚åº”å½“å‰ LLM çš„ä»¤ç‰Œé™åˆ¶ã€‚
- en: '![](../Images/0c36c37aab2a4cf97caf94e274d64dcd.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c36c37aab2a4cf97caf94e274d64dcd.png)'
- en: Sample of the source data (Image by Author)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥æºæ•°æ®æ ·æœ¬ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: '*(Note: the notebook and data source are available at the end of the article)*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*(æ³¨æ„ï¼šç¬”è®°æœ¬å’Œæ•°æ®æºåœ¨æ–‡ç« æœ«å°¾æä¾›)*'
- en: Retro-Engineering the Data Model
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æ¨¡å‹çš„é€†å‘å·¥ç¨‹
- en: The idea here is to ask each LLM to analyze this sample data and provide some
    insight into what the initial data scheme might look like.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„æƒ³æ³•æ˜¯è®©æ¯ä¸ª LLM åˆ†æè¿™ä¸ªæ ·æœ¬æ•°æ®ï¼Œå¹¶æä¾›æœ‰å…³åˆå§‹æ•°æ®æ–¹æ¡ˆå¯èƒ½æ˜¯ä»€ä¹ˆæ ·çš„è§è§£ã€‚
- en: 'Weâ€™ll keep the same prompt as the one we used for GPT-4 and Bard:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä¿æŒä¸ GPT-4 å’Œ Bard ä½¿ç”¨çš„ç›¸åŒæç¤ºï¼š
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Ok great! â€¦ But now the question is â€œWhere can I test Llama-2?â€
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼â€¦â€¦ä½†ç°åœ¨çš„é—®é¢˜æ˜¯â€œæˆ‘åœ¨å“ªé‡Œå¯ä»¥æµ‹è¯• Llama-2ï¼Ÿâ€
- en: 'There are several options available:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ç§å¯ç”¨çš„é€‰é¡¹ï¼š
- en: The most obvious one (but also more complex and expensive ğŸ’¸) is to host the
    model on a dedicated server in your cloud architecture. This is usually a good
    option if you intend to serve heavy-duty applications.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ€æ˜æ˜¾çš„ä¸€ä¸ªï¼ˆä½†ä¹Ÿæ›´å¤æ‚å’Œæ˜‚è´µ ğŸ’¸ï¼‰æ˜¯å°†æ¨¡å‹æ‰˜ç®¡åœ¨ä½ äº‘æ¶æ„ä¸­çš„ä¸“ç”¨æœåŠ¡å™¨ä¸Šã€‚å¦‚æœä½ æ‰“ç®—æœåŠ¡äºé‡å‹åº”ç”¨ç¨‹åºï¼Œè¿™é€šå¸¸æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚
- en: Keep in mind that the virtual machines required to run an LLM can go from 2â€“3$/hour
    for a small modelâ€¦ up to 18$/hour if you want to host LLama2â€“70b properly, according
    to Azure ğŸ˜¨
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: è¯·è®°ä½ï¼Œè¿è¡Œ LLM æ‰€éœ€çš„è™šæ‹Ÿæœºä»å°æ¨¡å‹çš„ 2â€“3$/å°æ—¶... åˆ°è¦å¦¥å–„æ‰˜ç®¡ LLama2â€“70b çš„ 18$/å°æ—¶ä¸ç­‰ï¼Œæ ¹æ® Azure çš„ä¿¡æ¯
    ğŸ˜¨
- en: An intermediary solution â€” recommended [by Yann Lecun himself](https://www.linkedin.com/feed/update/urn:li:activity:7109561666324885504?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7109561666324885504%2C7111453478513733632%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287111453478513733632%2Curn%3Ali%3Aactivity%3A7109561666324885504%29)
    â€” is to use platforms like [Anyscale](https://www.anyscale.com/) which, for example,
    offers $1 for 1M token on Llama-2â€“70b-chat (when Azure pricing is between $30
    and $60 for GPT-4)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªä¸­é—´è§£å†³æ–¹æ¡ˆâ€”â€”ç”± [Yann Lecun æœ¬äºº](https://www.linkedin.com/feed/update/urn:li:activity:7109561666324885504?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7109561666324885504%2C7111453478513733632%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287111453478513733632%2Curn%3Ali%3Aactivity%3A7109561666324885504%29)
    æ¨èâ€”â€”æ˜¯ä½¿ç”¨åƒ [Anyscale](https://www.anyscale.com/) è¿™æ ·çš„å¹³å°ï¼Œä¾‹å¦‚ï¼Œå®ƒåœ¨ Llama-2â€“70b-chat ä¸Šæä¾›
    1M æ ‡è®° $1ï¼ˆè€Œ Azure å¯¹ GPT-4 çš„å®šä»·åœ¨ $30 å’Œ $60 ä¹‹é—´ï¼‰
- en: The awesome Hugging Face platform also offers us a testbed. A good way, for
    example, to keep our finances straight!
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¤äººæƒŠå¹çš„ Hugging Face å¹³å°è¿˜ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªæµ‹è¯•å¹³å°ã€‚ä¾‹å¦‚ï¼Œè¿™æ˜¯ä¸€ä¸ªä¿æŒè´¢åŠ¡æ¸…æ™°çš„å¥½æ–¹æ³•ï¼
- en: '[](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat?source=post_page-----e7f144a6753b--------------------------------)
    [## Llama 2 7B Chat - a Hugging Face Space by huggingface-projects'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat?source=post_page-----e7f144a6753b--------------------------------)
    [## Llama 2 7B Chat - ç”± huggingface-projects æä¾›çš„ Hugging Face ç©ºé—´'
- en: Discover amazing ML apps made by the community
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å‘ç°ç¤¾åŒºåˆ¶ä½œçš„ä»¤äººæƒŠå¹çš„ ML åº”ç”¨
- en: huggingface.co](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat?source=post_page-----e7f144a6753b--------------------------------)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: huggingface.co](https://huggingface.co/spaces/huggingface-projects/llama-2-7b-chat?source=post_page-----e7f144a6753b--------------------------------)
- en: While writing this second episode, I also discovered [https://chat.lmsys.org/](https://chat.lmsys.org/)
    that allows you to execute one single prompt with two models in parallel. Perfect
    to benchmark their performance. This is the tool Iâ€™ll use for this article.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å†™è¿™ç¬¬äºŒé›†æ—¶ï¼Œæˆ‘è¿˜å‘ç°äº† [https://chat.lmsys.org/](https://chat.lmsys.org/)ï¼Œå®ƒå…è®¸ä½ ç”¨ä¸¤ä¸ªæ¨¡å‹å¹¶è¡Œæ‰§è¡Œä¸€ä¸ªå•ä¸€çš„æç¤ºã€‚éå¸¸é€‚åˆåŸºå‡†æµ‹è¯•å®ƒä»¬çš„æ€§èƒ½ã€‚è¿™æ˜¯æˆ‘å°†åœ¨æœ¬æ–‡ä¸­ä½¿ç”¨çš„å·¥å…·ã€‚
- en: '![](../Images/d98758be443f6eec0e3aabe30a2c800d.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d98758be443f6eec0e3aabe30a2c800d.png)'
- en: Photo by [Paz Arando](https://unsplash.com/@pazarando?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[Paz Arando](https://unsplash.com/@pazarando?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Analyzing results (LLama-2)
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ†æç»“æœï¼ˆLLama-2ï¼‰
- en: 'When running the benchmark on ChatGPT, we chose the most advanced and generally
    available version: 4.0.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ChatGPTä¸Šè¿è¡ŒåŸºå‡†æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬é€‰æ‹©äº†æœ€å…ˆè¿›ä¸”æ™®éå¯ç”¨çš„ç‰ˆæœ¬ï¼š4.0ã€‚
- en: In the same spirit, weâ€™ll run our query on the â€œ[LLama-2â€“70b-chat](https://ai.meta.com/llama/)â€
    version which, as its name suggests, has a size of 70 billion parameters and a
    context window of 4096 tokens.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ºäºç›¸åŒçš„ç²¾ç¥ï¼Œæˆ‘ä»¬å°†åœ¨â€œ[LLama-2â€“70b-chat](https://ai.meta.com/llama/)â€ç‰ˆæœ¬ä¸Šè¿è¡Œæˆ‘ä»¬çš„æŸ¥è¯¢ï¼Œè¯¥ç‰ˆæœ¬å¦‚å…¶åç§°æ‰€ç¤ºï¼Œå…·æœ‰70äº¿ä¸ªå‚æ•°å’Œ4096ä¸ªæ ‡è®°çš„ä¸Šä¸‹æ–‡çª—å£ã€‚
- en: Identifying Categorical and Confidential Data
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯†åˆ«åˆ†ç±»å’Œæœºå¯†æ•°æ®
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Even if one could challenge the fact that â€œEmployee_IDâ€ actually belongs to
    confidential data (but the more I think about it, the more it makes sense), LLama-2
    managed to find all categorical and confidential columns, by order of appearance
    âœ…
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æœ‰äººå¯èƒ½ä¼šè´¨ç–‘â€œEmployee_IDâ€æ˜¯å¦ç¡®å®å±äºæœºå¯†æ•°æ®ï¼ˆä½†æˆ‘è¶Šæƒ³è¶Šè§‰å¾—æœ‰é“ç†ï¼‰ï¼ŒLLama-2 è¿˜æ˜¯æˆåŠŸæ‰¾å‡ºäº†æ‰€æœ‰åˆ†ç±»å’Œæœºå¯†åˆ—ï¼ŒæŒ‰å‡ºç°é¡ºåº âœ…
- en: Suggesting a database model
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æè®®ä¸€ä¸ªæ•°æ®åº“æ¨¡å‹
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Again, Llama-2 does pretty well by properly converting categorical columns into
    sub-tables with key/label pairs. âœ…
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡ï¼ŒLlama-2 åšå¾—å¾ˆå¥½ï¼Œå°†åˆ†ç±»åˆ—æ­£ç¡®è½¬æ¢ä¸ºåŒ…å«é”®/æ ‡ç­¾å¯¹çš„å­è¡¨ã€‚ âœ…
- en: Separating the confidential data into another table like ChatGPT did would have
    been a plus but thatâ€™s already a near result! ğŸ”¶
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æœºå¯†æ•°æ®åˆ†ç¦»åˆ°å¦ä¸€ä¸ªè¡¨ä¸­ï¼Œå°±åƒ ChatGPT æ‰€åšçš„é‚£æ ·ï¼Œä¼šæ˜¯ä¸€ä¸ªåŠ åˆ†é¡¹ï¼Œä½†è¿™å·²ç»æ˜¯ä¸€ä¸ªæ¥è¿‘çš„ç»“æœï¼ ğŸ”¶
- en: Finally, the â€œageâ€ column has disappeared from the suggested schema. âŒ
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œâ€œå¹´é¾„â€åˆ—å·²ä»å»ºè®®çš„æ¨¡å¼ä¸­æ¶ˆå¤±ã€‚ âŒ
- en: SQL Scripts to create tables
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ›å»ºè¡¨çš„ SQL è„šæœ¬
- en: 'Iâ€™ll continue here with the â€œacid testâ€ ğŸ§ª of simply running these queries in
    Snowflake and checking what the result looks like:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†åœ¨è¿™é‡Œç»§ç»­è¿›è¡Œâ€œé…¸æ€§æµ‹è¯•â€ğŸ§ªï¼Œå³ç®€å•åœ°åœ¨ Snowflake ä¸­è¿è¡Œè¿™äº›æŸ¥è¯¢å¹¶æ£€æŸ¥ç»“æœæ˜¯ä»€ä¹ˆæ ·çš„ï¼š
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Besides the fact that â€œageâ€ still missing, everything runs like a charm and
    all tables are created seamlessly in Snowflake! âœ…
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†â€œå¹´é¾„â€ä»ç„¶ç¼ºå¤±ä¹‹å¤–ï¼Œä¸€åˆ‡è¿è¡Œå¾—éå¸¸é¡ºåˆ©ï¼Œæ‰€æœ‰è¡¨æ ¼åœ¨ Snowflake ä¸­æ— ç¼åˆ›å»ºï¼ âœ…
- en: Data Quality Checks
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®è´¨é‡æ£€æŸ¥
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here, Llama-2 suggests some common wisdom:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼ŒLlama-2 æå‡ºäº†äº›å¸¸è§çš„è§è§£ï¼š
- en: Check for duplicates âœ…
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥é‡å¤ âœ…
- en: Check invalid characters âœ…
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€æŸ¥æ— æ•ˆå­—ç¬¦ âœ…
- en: 'â€¦ and also tries to adapt to the nature of some fields:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: â€¦ è¿˜å°è¯•é€‚åº”æŸäº›å­—æ®µçš„æ€§è´¨ï¼š
- en: A valid email address format âœ…
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœ‰æ•ˆçš„ç”µå­é‚®ä»¶åœ°å€æ ¼å¼ âœ…
- en: Negative or non-numeric values for â€œsalaryâ€ & â€œannual_evaluationâ€ âœ…
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€œè–ªèµ„â€ä¸â€œå¹´åº¦è¯„ä¼°â€çš„è´Ÿå€¼æˆ–éæ•°å­—å€¼ âœ…
- en: 'â€¦ but also produces some mistakes:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: â€¦ ä½†ä¹Ÿä¼šäº§ç”Ÿä¸€äº›é”™è¯¯ï¼š
- en: For example, it wonâ€™t be unusual to find identical first (or even last) names
    in the table so duplicates should be accepted âŒ
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œåœ¨è¡¨ä¸­æ‰¾åˆ°ç›¸åŒçš„åå­—ï¼ˆç”šè‡³æ˜¯å§“æ°ï¼‰å¹¶ä¸ç½•è§ï¼Œå› æ­¤åº”æ¥å—é‡å¤ âŒ
- en: Looking back at what ChatGPT did, identifying ranges for columns like salary,
    age or even defining the acceptable values for the annual evaluation, Llama-2
    provides an â€œaverageâ€ answer.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å›é¡¾ ChatGPT çš„è¡¨ç°ï¼Œè¯†åˆ«è¯¸å¦‚è–ªèµ„ã€å¹´é¾„ç­‰åˆ—çš„èŒƒå›´ï¼Œç”šè‡³å®šä¹‰å¹´åº¦è¯„ä¼°çš„å¯æ¥å—å€¼ï¼ŒLlama-2 æä¾›äº†ä¸€ä¸ªâ€œå¹³å‡â€çš„ç­”æ¡ˆã€‚
- en: 'Conclusion for Llama-2â€“70b:'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Llama-2â€“70b çš„ç»“è®ºï¼š
- en: Identifying Categorical and Confidential Data âœ…
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¯†åˆ«åˆ†ç±»æ•°æ®å’Œæœºå¯†æ•°æ® âœ…
- en: Suggesting a database model âœ…
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å»ºè®®ä¸€ä¸ªæ•°æ®åº“æ¨¡å‹ âœ…
- en: SQL Scripts to create tables âœ…
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºè¡¨çš„ SQL è„šæœ¬ âœ…
- en: Data Quality Checks ğŸ”¶
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®è´¨é‡æ£€æŸ¥ ğŸ”¶
- en: Conclusion (Updated with Llama-2)
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®ºï¼ˆæ›´æ–°äº† Llama-2ï¼‰
- en: GPT-4k clearly outperforms Bard and Llama-2 when it comes to understanding a
    dataset, designing a proper data model (here under the 3rd Normal Form (3NF)),
    writing the corresponding SQL queries, and suggesting data quality checks.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4k åœ¨ç†è§£æ•°æ®é›†ã€è®¾è®¡åˆé€‚çš„æ•°æ®æ¨¡å‹ï¼ˆæ­¤å¤„ä¸ºç¬¬ä¸‰èŒƒå¼ (3NF)ï¼‰ã€ç¼–å†™ç›¸åº”çš„ SQL æŸ¥è¯¢ä»¥åŠå»ºè®®æ•°æ®è´¨é‡æ£€æŸ¥æ–¹é¢æ˜æ˜¾ä¼˜äº Bard å’Œ Llama-2ã€‚
- en: For this specific task (database retro-engineering), Llama-2 achieves a higher
    performance than Bard.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªç‰¹å®šçš„ä»»åŠ¡ï¼ˆæ•°æ®åº“é€†å‘å·¥ç¨‹ï¼‰ï¼ŒLlama-2 çš„è¡¨ç°ä¼˜äº Bardã€‚
- en: Looking at the answers above, I believe that the insights provided by Llama-2
    are much more valuable than those provided by Bard.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹çœ‹ä¸Šé¢çš„ç­”æ¡ˆï¼Œæˆ‘è®¤ä¸º Llama-2 æä¾›çš„è§è§£æ¯” Bard æä¾›çš„è¦æœ‰ä»·å€¼å¾—å¤šã€‚
- en: '![](../Images/d6dbaa44d89f44de9848183352e5cb06.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d6dbaa44d89f44de9848183352e5cb06.png)'
- en: 'Notes:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¤‡æ³¨ï¼š
- en: In late August, Meta released a â€œCode Llamaâ€ model that we could also benchmark,
    perhaps in a future article.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å…«æœˆåº•ï¼ŒMeta å‘å¸ƒäº†ä¸€ä¸ªâ€œCode Llamaâ€æ¨¡å‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å¯¹å…¶è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œä¹Ÿè®¸åœ¨æœªæ¥çš„æ–‡ç« ä¸­ã€‚
- en: I used the predefined temperature of 0.7 for the inference, meaning that executing
    the same queries with the same model could produce different results. I decided
    to simply keep the first result provided by the model, not to bias the analysis.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨äº†é¢„å®šä¹‰çš„æ¸©åº¦ 0.7 è¿›è¡Œæ¨ç†ï¼Œè¿™æ„å‘³ç€æ‰§è¡Œç›¸åŒçš„æŸ¥è¯¢å¯èƒ½ä¼šå¾—åˆ°ä¸åŒçš„ç»“æœã€‚æˆ‘å†³å®šä»…ä¿ç•™æ¨¡å‹æä¾›çš„ç¬¬ä¸€ä¸ªç»“æœï¼Œä»¥é¿å…åå€šåˆ†æã€‚
- en: â© Links to the corresponding [Jupyter Notebook](https://github.com/pierrelouisbescond/medium_articles/blob/main/medium_llm_db_retro_eng_load_and_format_data.ipynb)
    and [CSV Data Source](https://github.com/pierrelouisbescond/medium_articles/blob/main/Employees_Base.csv).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: â© ç›¸å…³çš„ [Jupyter Notebook](https://github.com/pierrelouisbescond/medium_articles/blob/main/medium_llm_db_retro_eng_load_and_format_data.ipynb)
    å’Œ [CSV æ•°æ®æº](https://github.com/pierrelouisbescond/medium_articles/blob/main/Employees_Base.csv)
    é“¾æ¥ã€‚
- en: As usual, I have tried to identify all the necessary steps if youâ€™d like to
    reproduce the analysis, but do not hesitate to contact me if there are any missing
    instructions in this tutorial!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œå¾€å¸¸ä¸€æ ·ï¼Œæˆ‘å·²ç»å°½åŠ›è¯†åˆ«å‡ºæ‰€æœ‰å¿…è¦çš„æ­¥éª¤ï¼Œå¦‚æœä½ æƒ³é‡å¤åˆ†æï¼Œä½†å¦‚æœæ•™ç¨‹ä¸­æœ‰ä»»ä½•ç¼ºå¤±çš„è¯´æ˜ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ï¼
- en: 'And feel free to check out my other posts on Medium:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥æŸ¥çœ‹æˆ‘åœ¨ Medium ä¸Šçš„å…¶ä»–æ–‡ç« ï¼š
- en: '[](https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad?source=post_page-----e7f144a6753b--------------------------------)
    [## Pierre-Louis Bescondâ€™s articles on Medium'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad?source=post_page-----e7f144a6753b--------------------------------)
    [## Pierre-Louis Bescond çš„ Medium æ–‡ç« '
- en: Data Science, Machine Learning and Innovation
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ ä¸åˆ›æ–°
- en: pl-bescond.medium.com](https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad?source=post_page-----e7f144a6753b--------------------------------)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: pl-bescond.medium.com](https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad?source=post_page-----e7f144a6753b--------------------------------)
