- en: Graph Machine Learning @ ICML 2023
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图形机器学习 @ ICML 2023
- en: 原文：[https://towardsdatascience.com/graph-machine-learning-icml-2023-9b5e4306a1cc?source=collection_archive---------0-----------------------#2023-08-06](https://towardsdatascience.com/graph-machine-learning-icml-2023-9b5e4306a1cc?source=collection_archive---------0-----------------------#2023-08-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/graph-machine-learning-icml-2023-9b5e4306a1cc?source=collection_archive---------0-----------------------#2023-08-06](https://towardsdatascience.com/graph-machine-learning-icml-2023-9b5e4306a1cc?source=collection_archive---------0-----------------------#2023-08-06)
- en: What’s new in Graph ML?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图形机器学习的新动态？
- en: Recent advancements and hot trends, August 2023 edition
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最近的进展和热门趋势，2023年8月版
- en: '[](https://mgalkin.medium.com/?source=post_page-----9b5e4306a1cc--------------------------------)[![Michael
    Galkin](../Images/c5eb13334712ca0462d8a5df4a268ad0.png)](https://mgalkin.medium.com/?source=post_page-----9b5e4306a1cc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9b5e4306a1cc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9b5e4306a1cc--------------------------------)
    [Michael Galkin](https://mgalkin.medium.com/?source=post_page-----9b5e4306a1cc--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mgalkin.medium.com/?source=post_page-----9b5e4306a1cc--------------------------------)[![Michael
    Galkin](../Images/c5eb13334712ca0462d8a5df4a268ad0.png)](https://mgalkin.medium.com/?source=post_page-----9b5e4306a1cc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9b5e4306a1cc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9b5e4306a1cc--------------------------------)
    [Michael Galkin](https://mgalkin.medium.com/?source=post_page-----9b5e4306a1cc--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d4f8ddd1e68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-machine-learning-icml-2023-9b5e4306a1cc&user=Michael+Galkin&userId=4d4f8ddd1e68&source=post_page-4d4f8ddd1e68----9b5e4306a1cc---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9b5e4306a1cc--------------------------------)
    ·16 min read·Aug 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9b5e4306a1cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-machine-learning-icml-2023-9b5e4306a1cc&user=Michael+Galkin&userId=4d4f8ddd1e68&source=-----9b5e4306a1cc---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d4f8ddd1e68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-machine-learning-icml-2023-9b5e4306a1cc&user=Michael+Galkin&userId=4d4f8ddd1e68&source=post_page-4d4f8ddd1e68----9b5e4306a1cc---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9b5e4306a1cc--------------------------------)
    ·16分钟阅读·2023年8月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9b5e4306a1cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-machine-learning-icml-2023-9b5e4306a1cc&user=Michael+Galkin&userId=4d4f8ddd1e68&source=-----9b5e4306a1cc---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9b5e4306a1cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-machine-learning-icml-2023-9b5e4306a1cc&source=-----9b5e4306a1cc---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9b5e4306a1cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fgraph-machine-learning-icml-2023-9b5e4306a1cc&source=-----9b5e4306a1cc---------------------bookmark_footer-----------)'
- en: Magnificent beaches and tropical Hawaiian landscapes 🌴did not turn brave scientists
    away from attending the [International Conference on Machine Learning](https://icml.cc/Conferences/2023)
    in Honolulu and presenting their recent work! Let’s see what’s new in our favorite
    Graph Machine Learning area.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 壮丽的海滩和热带夏威夷风光🌴并没有阻止勇敢的科学家们参加在檀香山举办的[国际机器学习大会](https://icml.cc/Conferences/2023)并展示他们的最新研究成果！让我们一起看看我们最喜欢的图形机器学习领域的新动态。
- en: '![](../Images/c984ed95b5365a9c6b59956d31ab3dac.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c984ed95b5365a9c6b59956d31ab3dac.png)'
- en: Image By Author.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者。
- en: '*Thanks Santiago Miret for proofreading the post.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢Santiago Miret校对本文。*'
- en: To make the post less boring about papers, I took some photos around Honolulu
    📷
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让帖子不那么枯燥，我在檀香山拍了一些照片📷
- en: 'Table of contents (clickable):'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录（可点击）：
- en: '[Graph Transformers: Sparser, Faster, and Directed](#8d41)'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[图形变换器：更稀疏、更快且有方向](#8d41)'
- en: '[Theory: VC dimension of GNNs, deep dive in over-squashing](#0d40)'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[理论：GNN的VC维，深入探讨过度挤压](#0d40)'
- en: '[New GNN architectures: delays and half-hops](#c5be)'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[新的GNN架构：延迟和半跳](#c5be)'
- en: '[Generative Models — Stable Diffusion for Molecules, Discrete diffusion](#7e7c)'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[生成模型 — 分子稳定扩散，离散扩散](#7e7c)'
- en: '[Geometric Learning: Geometric WL, Clifford Algebras](#b0d0)'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[几何学习：几何 WL，克利福德代数](#b0d0)'
- en: '[Molecules: 2D-3D pretraining, Uncertainty Estimation in MD](#32a5)'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[分子：2D-3D 预训练，MD 中的不确定性估计](#32a5)'
- en: '[Materials & Proteins: CLIP for proteins, Ewald Message Passing, Equivariant
    Augmentations](#1ff6)'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[材料与蛋白质：用于蛋白质的 CLIP，Ewald 消息传递，对称增强](#1ff6)'
- en: '[Cool Applications: Algorithmic reasoning, Inductive KG completion, GNNs for
    mass spectra](#1891)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[酷应用：算法推理、归纳 KG 完成、用于质谱的 GNN](#1891)'
- en: '[The Concluding Meme Part](#5eb2)'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[总结的 Meme 部分](#5eb2)'
- en: '**Graph Transformers: Sparser, Faster, and Directed**'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**图转换器：更稀疏、更快、且有方向**'
- en: We [presented](/graphgps-navigating-graph-transformers-c2cc223a051c) **GraphGPS**
    about a year ago and it is pleasing to see many ICML papers building upon our
    framework and expanding GT capabilities even further.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们[大约一年前](/graphgps-navigating-graph-transformers-c2cc223a051c) 提出了 **GraphGPS**，很高兴看到许多
    ICML 论文基于我们的框架并进一步扩展 GT 能力。
- en: '**➡️ Exphormer** by [Shirzad, Velingker, Venkatachalam et al](https://openreview.net/forum?id=3Ge74dgjjU)
    adds a missing piece of graph-motivated sparse attention to GTs: instead of BigBird
    or Performer (originally designed for sequences), Exphormer’s attention builds
    upon 1-hop edges, virtual nodes (connected to all nodes in a graph), and a neat
    idea of [expander edges](https://en.wikipedia.org/wiki/Expander_graph). Expander
    graphs have a constant degree and are shown to approximate fully-connected graphs.
    All components combined, attention costs *O(V+E)* instead of *O(V²)*. This allows
    Exphormer to outperform GraphGPS almost everywhere and scale to really large graphs
    of up to 160k nodes. Amazing work and all chances to make Exphormer the standard
    sparse attention mechanism in GTs 👏.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️ Exphormer** 由 [Shirzad, Velingker, Venkatachalam 等人](https://openreview.net/forum?id=3Ge74dgjjU)
    添加了图动机的稀疏注意力的缺失部分：与 BigBird 或 Performer（最初为序列设计）不同，Exphormer 的注意力基于 1-hop 边、虚拟节点（与图中的所有节点相连）以及一个精巧的
    [扩展边](https://en.wikipedia.org/wiki/Expander_graph) 想法。扩展图具有固定度，并被证明可以近似完全连接的图。所有组件结合起来，注意力成本为
    *O(V+E)* 而不是 *O(V²)*。这使得 Exphormer 能够在几乎所有地方超越 GraphGPS，并扩展到最多 16 万个节点的非常大图。令人惊叹的工作，Exphormer
    有很大机会成为 GT 中标准的稀疏注意力机制 👏。'
- en: '**➡️** Concurrently with graph transformers, expander graphs can already be
    used to enhance the performance of any MPNN architecture as shown in [Expander
    Graph Propagation](https://arxiv.org/abs/2210.02997) by *Deac, Lackenby, and Veličković*.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 与图转换器并行，扩展图已经可以用来增强任何 MPNN 架构的性能，如 *Deac, Lackenby, 和 Veličković* 在
    [Expander Graph Propagation](https://arxiv.org/abs/2210.02997) 中所示。'
- en: In a similar vein, [Cai et al](https://openreview.net/forum?id=1EuHYKFPgA) show
    that MPNNs with virtual nodes can approximate linear Performer-like attention
    such that even classic GCN and GatedGCN imbued with virtual nodes show pretty
    much a SOTA performance in long-range graph tasks (we [released](/lrgb-long-range-graph-benchmark-909a6818f02c)
    the [LGRB benchmark](https://github.com/vijaydwivedi75/lrgb) last year exactly
    for measuring long-range capabilities of GNNs and GTs).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，[Cai 等人](https://openreview.net/forum?id=1EuHYKFPgA) 证明了具有虚拟节点的 MPNN 可以近似线性
    Performer-like 注意力，因此即使是经典的 GCN 和 GatedGCN 只要加入虚拟节点，也能在长范围图任务中表现出相当的 SOTA 性能（我们[发布了](/lrgb-long-range-graph-benchmark-909a6818f02c)
    [LGRB 基准测试](https://github.com/vijaydwivedi75/lrgb)来测量 GNN 和 GT 的长范围能力）。
- en: '![](../Images/70f4870bdd013ec69ff15c45339cc653.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70f4870bdd013ec69ff15c45339cc653.png)'
- en: 'Source: [Shirzad, Velingker, Venkatachalam et al](https://openreview.net/forum?id=3Ge74dgjjU)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Shirzad, Velingker, Venkatachalam 等人](https://openreview.net/forum?id=3Ge74dgjjU)
- en: '**➡️** A few **patch-based** subsampling approaches for GTs inspired by vision
    models: [**“A Generalization of ViT/MLP-Mixer to Graphs”**](https://openreview.net/forum?id=l7yTbEWuOQ)
    by *He et al* split the input into several patches, encode each patch with a GNN
    into a token, and run a transformer over those tokens.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 一些受视觉模型启发的 GT 的 **基于补丁** 的子采样方法：*He 等人* 的 [**“ViT/MLP-Mixer 在图上的推广”**](https://openreview.net/forum?id=l7yTbEWuOQ)
    将输入分成多个补丁，使用 GNN 将每个补丁编码为一个令牌，并对这些令牌运行变换器。'
- en: '![](../Images/e3818ed7d6eef99eb892d922370b497d.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3818ed7d6eef99eb892d922370b497d.png)'
- en: 'Source: [“A Generalization of ViT/MLP-Mixer to Graphs”](https://openreview.net/forum?id=l7yTbEWuOQ)
    by He et al'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[“ViT/MLP-Mixer 在图上的推广”](https://openreview.net/forum?id=l7yTbEWuOQ) 由 He
    等人
- en: In **GOAT** by [Kong et al](https://openreview.net/forum?id=Le2dVIoQun), node
    features are projected into a codebook of K clusters with K-Means, and a sampled
    3-hop neighborhood of each node attends to the codebook. GOAT is a 1-layer model
    and scales to graphs of millions of nodes.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **GOAT** 中，由 [Kong 等人](https://openreview.net/forum?id=Le2dVIoQun) 提出，节点特征被投影到
    K-Means 的 K 个簇的代码本中，并且每个节点的采样的三跳邻域都关注这个代码本。GOAT 是一个单层模型，并且可以扩展到数百万节点的图中。
- en: '**➡️ Directed graphs** got some transformer love as well 💗. [**“Transformers
    Meet Directed Graphs”**](https://openreview.net/forum?id=a7PVyayyfp) by *Geisler
    et al* introduces Magnetic Laplacian — a generalization of a Laplacian for directed
    graphs with a non-symmetric adjacency matrix. Eigenvectors of the Magnetic Laplacian
    paired with directed random walks are strong input features for the transformer
    that enable setting a new SOTA on the [OGB Code2](https://ogb.stanford.edu/docs/leader_graphprop/#ogbg-code2)
    graph property prediction dataset by a good margin!'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️ 有向图** 也受到了一些 Transformer 的喜爱 💗。[“Transformers Meet Directed Graphs”](https://openreview.net/forum?id=a7PVyayyfp)
    由 *Geisler 等人* 引入了磁拉普拉斯 —— 非对称邻接矩阵的拉普拉斯的泛化。磁拉普拉斯的特征向量与有向随机游走结合，成为 Transformer
    的强大输入特征，在 [OGB Code2](https://ogb.stanford.edu/docs/leader_graphprop/#ogbg-code2)
    图属性预测数据集上设置了新的 SOTA，超过了现有方法很多！'
- en: 🏅 Last but not least, we have a new SOTA GT on the community standard ZINC dataset
    — **GRIT** by [Ma, Lin, et al](https://openreview.net/forum?id=HjMdlNgybR) incorporates
    the full *d*-dimensional random walk matrix, coined as relative random walk probabilities
    (RRWP), as edge features to the attention computation (for comparison, popular
    [RWSE](https://openreview.net/forum?id=wTTjnvGphYj) features are just the diagonal
    elements of this matrix). RRWP are provably more powerful than shortest path distance
    features and set a record-low 0.059 MAE on ZINC (down from 0.070 by GraphGPS).
    GRIT often outperforms GPS in other benchmarks as well 👏. In a similar vein, [Eliasof
    et al](https://openreview.net/forum?id=1Nx2n1lk5T) propose a neat idea to combine
    random and spectral features as positional encodings that outperform RWSE but
    were not tried with GTs.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 🏅 最后但并非最不重要的是，我们在社区标准 ZINC 数据集上有了一个新的 SOTA GT — **GRIT**，由 [Ma, Lin, 等人](https://openreview.net/forum?id=HjMdlNgybR)
    提出，其全 *d*-维随机游走矩阵被称为相对随机游走概率（RRWP），作为边特征用于注意力计算（相比之下，流行的 [RWSE](https://openreview.net/forum?id=wTTjnvGphYj)
    特征只是这个矩阵的对角元素）。RRWP 明显比最短路径距离特征更强大，在 ZINC 上取得了创纪录的低 0.059 MAE（比 GraphGPS 的 0.070
    低）。GRIT 在其他基准测试中通常也优于 GPS 👏。同样地，[Eliasof 等人](https://openreview.net/forum?id=1Nx2n1lk5T)
    提出了一个巧妙的思路，将随机和谱特征结合为位置编码，在超越 RWSE 的同时并未尝试过与 GTs 结合。
- en: '![](../Images/5dbb993c02b7139828ad024f7a1d9328.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5dbb993c02b7139828ad024f7a1d9328.png)'
- en: Image by Author.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '**Theory: VC dimension of GNNs, deep dive into over-squashing**'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**理论：GNNs 的 VC 维，深入探讨过度压缩**'
- en: '**➡️** [VC dimension](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension)
    measures model capacity and expressiveness. It is studied well for classical ML
    algorithms but, surprisingly, has never been applied to study GNNs. In[**“WL meet
    VC”**](https://openreview.net/forum?id=rZN3mc5m3C) by *Morris et al*, the connection
    between the WL test and VC dimension is finally uncovered — turns out it the VC
    dimension can be bounded by the bitlength of GNN weights, i.e., float32 weights
    would imply the VC dimension of 32\. Furthermore, the VC dimension depends logarithmically
    on the number of unique WL colors in the given task and polynomially on the depth
    and number of layers. This is a great theoretical result and I’d encourage you
    to have a look!'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** [VC 维](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension)
    衡量了模型的容量和表达能力。它已经广泛应用于经典机器学习算法的研究中，但令人惊讶的是，从未应用于研究 GNNs。在 [“WL meet VC”](https://openreview.net/forum?id=rZN3mc5m3C)
    中，*Morris 等人* 最终揭示了 WL 测试和 VC 维之间的联系 — 原来 VC 维可以由 GNN 权重的比特长度界定，即 float32 权重意味着
    VC 维为 32。此外，VC 维对给定任务中唯一 WL 颜色的数量以对数方式依赖，对深度和层数则多项式依赖。这是一个重要的理论结果，我鼓励你深入了解！'
- en: '![](../Images/3e0e2bb4b10259d188b9ce9b748796f3.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e0e2bb4b10259d188b9ce9b748796f3.png)'
- en: 'Source: [“WL meet VC”](https://openreview.net/forum?id=rZN3mc5m3C) by *Morris
    et al*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[“WL meet VC”](https://openreview.net/forum?id=rZN3mc5m3C) by *Morris 等人*
- en: 🍊🖐️ The over-squashing effect — information loss when you try to stuff messages
    from too many neighboring nodes — is another common problem of MPNNs, and we don’t
    fully understand how to properly deal with it. This year, there were 3 papers
    dedicated to this topic. Perhaps the most foundational is the work by [**Di Giovanni
    et al**](https://openreview.net/forum?id=t2tTfWwAEl) that explains how MPNNs width,
    depth, and graph topology affect over-squashing.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 🍊🖐️ 过度压缩效应——尝试将来自过多邻居节点的信息塞入会导致信息丢失——是MPNN的另一个常见问题，我们尚未完全理解如何妥善处理。今年，有3篇论文专门讨论了这个话题。也许最基础的是[**Di
    Giovanni 等**](https://openreview.net/forum?id=t2tTfWwAEl)的工作，解释了MPNN的宽度、深度和图拓扑如何影响过度压缩。
- en: '![](../Images/9b93ed516702c4448b7a0a9772541cdd.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b93ed516702c4448b7a0a9772541cdd.png)'
- en: 'Source: [**Di Giovanni et al**](https://openreview.net/forum?id=t2tTfWwAEl)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[**Di Giovanni 等**](https://openreview.net/forum?id=t2tTfWwAEl)
- en: Turns out that **width** might help (but with generalization issues), **depth**
    does **not** really help, and **graph topology** (characterized by the commute
    time between nodes) plays the most important role. We can reduce the commute time
    by various *graph rewiring* strategies (adding and removing edges based on spatial
    or spectral properties), and there are many of them (you might have heard about
    the [Ricci flow-based rewiring](https://openreview.net/forum?id=7UmjRGzp-A) that
    took home the Outstanding Paper award at ICLR 2022). In fact, there is a [follow-up
    work](https://arxiv.org/abs/2306.03589) to this study that goes even deeper and
    derives some impossibility statements wrt over-squashing and some MPNN properties
    — I’d highly encourage to read it as well!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，**宽度**可能有帮助（但存在泛化问题），**深度**实际上**没有**什么帮助，而**图拓扑**（由节点间的通勤时间表征）起着最重要的作用。我们可以通过各种*图重连*策略（基于空间或谱特性添加和移除边）来减少通勤时间，这些策略有很多（你可能听说过[基于Ricci流的重连](https://openreview.net/forum?id=7UmjRGzp-A)，该研究在ICLR
    2022上获得了杰出论文奖）。事实上，还有一项[后续研究](https://arxiv.org/abs/2306.03589)对此进行了更深入的探讨，推导了一些关于过度压缩和MPNN属性的不可能性声明——我强烈推荐阅读！
- en: '**➡️** Effective resistance is one example of spatial rewiring strategies,
    and [**Black et al**](https://openreview.net/forum?id=50SO1LwcYU)study it in great
    detail. The Ricci flow-based rewiring works with graph curvature and is studied
    further in the work by [Nguyen et al](https://openreview.net/forum?id=eWAvwKajx2).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 有效电阻是空间重连策略的一个例子，[**Black 等**](https://openreview.net/forum?id=50SO1LwcYU)对此进行了详细研究。基于Ricci流的重连方法与图的曲率相关，进一步研究见于[Nguyen
    等](https://openreview.net/forum?id=eWAvwKajx2)的工作中。'
- en: '**➡️** Subgraph GNNs continue to be in the spotlight: two works ([**Zhang,
    Feng, Du, et al**](https://openreview.net/forum?id=2Hp7U3k5Ph) and [**Zhou, Wang,
    Zhang**](https://openreview.net/forum?id=K07XAlzh5i)) concurrently derive expressiveness
    hierarchies of the recently proposed subgraph GNNs and their relationship to the
    1- and higher-order WL tests.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 子图GNN继续受到关注：两项工作（[**Zhang, Feng, Du 等**](https://openreview.net/forum?id=2Hp7U3k5Ph)
    和 [**Zhou, Wang, Zhang**](https://openreview.net/forum?id=K07XAlzh5i)）同时推导了最近提出的子图GNN的表现力等级及其与1阶及更高阶WL测试的关系。'
- en: '![](../Images/ba83d721dae2076255c799aaeeb07f6b.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba83d721dae2076255c799aaeeb07f6b.png)'
- en: Image By Author.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图像作者提供。
- en: '**New GNN architectures: Delays and Half-hops**'
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**新型GNN架构：延迟和半跳**'
- en: 'If you are tired of yet another variation of GCN or GAT, here are some fresh
    ideas that can work with any GNN of your choice:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你厌倦了GCN或GAT的各种变体，这里有一些新鲜的想法，可以与任何你选择的GNN搭配使用：
- en: '⏳ As we know from the **Theory** section, rewiring helps combat over-squashing.
    [**Gutteridge et al**](https://openreview.net/forum?id=WEgjbJ6IDN) introduce *“DRew:
    Dynamically Rewired Message Passing with Delay”* which gradually densifies the
    graph in later GNN layers such that long-distance nodes see the original states
    of previous nodes (the original DRew) or those skip-connections are added based
    on the *delay* — depending on a distance between two nodes (the vDRew version).
    For example ( 🖼️👇), in vDRew delayed message passing, a starting node from layer
    0 will show its state to 2-hop neighbors on layer 1, and will show its state to
    a 3-hop neighbor on layer 2\. **DRew** significantly improves the ability of vanilla
    GNNs to perform long-range tasks — in fact, a DRew-enabled GCN is the current
    [SOTA](https://github.com/vijaydwivedi75/lrgb) on the Peptides-func dataset from
    the [Long Range Graph Benchmark](https://github.com/vijaydwivedi75/lrgb) 👀'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '⏳ 正如我们在**理论**部分所知，重新连接有助于对抗过度挤压。[**Gutteridge 等人**](https://openreview.net/forum?id=WEgjbJ6IDN)
    介绍了*“DRew: 动态重连的延迟消息传递”*，它在后期 GNN 层中逐渐稠密化图，使得长距离节点能够看到先前节点的原始状态（原始 DRew），或者这些跳跃连接是基于*延迟*来添加的——取决于两个节点之间的距离（vDRew
    版本）。例如（ 🖼️👇），在 vDRew 延迟消息传递中，来自层 0 的起始节点将在层 1 上向 2-hop 邻居展示其状态，并将在层 2 上向 3-hop
    邻居展示其状态。**DRew** 显著提高了普通 GNN 处理长距离任务的能力——实际上，启用 DRew 的 GCN 是来自 [长距离图基准](https://github.com/vijaydwivedi75/lrgb)
    的 Peptides-func 数据集上的当前 [SOTA](https://github.com/vijaydwivedi75/lrgb) 👀'
- en: '![](../Images/8089fde4f860732baf4f33dc17a967be.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8089fde4f860732baf4f33dc17a967be.png)'
- en: 'Source: [**Gutteridge et al**](https://openreview.net/forum?id=WEgjbJ6IDN)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [**Gutteridge 等人**](https://openreview.net/forum?id=WEgjbJ6IDN)'
- en: 🦘 Another neat idea by [**Azabou et al**](https://openreview.net/forum?id=lXczFIwQkv)
    is to slow down message passing by inserting new, *slow nodes* at each edge with
    a special connectivity pattern — only an incoming connection from the starting
    node and a symmetric edge with the destination node. Slow nodes improve the performance
    of vanilla GNNs on heterophilic benchmarks by a large margin, and it is also possible
    to use slow nodes for self-supervised learning by creating views with different
    locations of slow nodes for the same original graph. **HalfHop** is a no-brainer-to-include
    SSL component that boosts performance and should be in a standard suite of many
    GNN libraries 👍.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 🦘 另一个有趣的想法来自[**Azabou 等人**](https://openreview.net/forum?id=lXczFIwQkv)，即通过在每条边上插入具有特殊连接模式的新*慢节点*来减慢消息传递——仅从起始节点来的一个输入连接和与目标节点的对称边。慢节点在异质性基准测试中大幅提升了普通
    GNN 的性能，也可以通过创建具有不同慢节点位置的视图来实现自监督学习，针对相同的原始图。**HalfHop** 是一个无需深思熟虑的自监督学习组件，它提升了性能，并且应该成为许多
    GNN 库的标准套件 👍。
- en: '![](../Images/05240ff796d9ab8c9f9984a30a0e5dda.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05240ff796d9ab8c9f9984a30a0e5dda.png)'
- en: 'Source: [**Azabou et al**](https://openreview.net/forum?id=lXczFIwQkv)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [**Azabou 等人**](https://openreview.net/forum?id=lXczFIwQkv)'
- en: '![](../Images/d16ae29ccd4c9d38a6e3081cc4edf72c.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d16ae29ccd4c9d38a6e3081cc4edf72c.png)'
- en: Image By Author.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '**Generative Models — Stable Diffusion for Molecules, Discrete Diffusion**'
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**生成模型 — 分子稳定扩散，离散扩散**'
- en: '**➡️** Diffusion models might work in the **feature** space (e.g., pixel space
    in image generation like the original DDPM) or in the **latent** space (like Stable
    Diffusion). In the feature space, you have to design the noising process to respect
    symmetries and equivariances of your feature space. In the latent space, you can
    just add Gaussian noise to the features produced by (pre-trained) encoder. Most
    3D molecule generation models work in the feature space (like a pioneering [EDM](https://arxiv.org/abs/2203.17003)),
    and the new **GeoLDM** model by [Xu et al](https://openreview.net/forum?id=sLfHWWrfe2)
    (authors of the prominent [GeoDiff](https://arxiv.org/abs/2203.02923)) is the
    first to define **latent** diffusion for 3D molecule generation. That is, after
    training an EGNN autoencoder, GeoLDM is trained on the denoising objective where
    noise is sampled from a standard Gaussian. GeoLDM brings significant improvements
    over EDM and other non-latent diffusion approaches 👏.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 扩散模型可以在**特征**空间（例如，图像生成中的像素空间，如原始DDPM）或**潜在**空间（如稳定扩散）中工作。在特征空间中，必须设计噪声过程以尊重特征空间的对称性和等变性。在潜在空间中，可以简单地向（预训练的）编码器生成的特征添加高斯噪声。大多数3D分子生成模型在特征空间中工作（如开创性的[EDM](https://arxiv.org/abs/2203.17003)），而由[Xu等人](https://openreview.net/forum?id=sLfHWWrfe2)（著名的[GeoDiff](https://arxiv.org/abs/2203.02923)的作者）提出的新**GeoLDM**模型是首个为3D分子生成定义**潜在**扩散的模型。也就是说，在训练EGNN自编码器之后，GeoLDM在去噪目标上进行训练，其中噪声从标准高斯分布中采样。GeoLDM相比于EDM和其他非潜在扩散方法带来了显著的改进👏。'
- en: '![](../Images/0ff52f569c070f1ff4ed28af64260f86.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ff52f569c070f1ff4ed28af64260f86.png)'
- en: 'GeoLDM. Source: [Xu et al](https://openreview.net/forum?id=sLfHWWrfe2)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: GeoLDM。来源：[Xu等人](https://openreview.net/forum?id=sLfHWWrfe2)
- en: '**➡️** In the realm of non-geometric graphs (just with an adjacency and perhaps
    categorical node features), discrete graph diffusion pioneered by [DiGress](https://openreview.net/forum?id=UaAD-Nu86WX)
    (ICLR’23) seems the most applicable option. [Chen et al](https://openreview.net/forum?id=vn9O1N5ZOw)
    propose **EDGE,** a discrete diffusion model guided by the node degree distribution.
    In contrast to DiGress, the final target graph in EDGE is a disconnected graph
    without edges, a forward noising model removes edges through a Bernoulli distribution,
    and a reverse process adds edges to the most recent *active* nodes (active are
    the nodes whose degrees changed in the previous step). Thanks to the sparsity
    introduced by the degree guidance, EDGE can generate pretty large graphs up to
    4k nodes and 40k edges!'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 在非几何图的领域（仅具有邻接关系和可能的类别节点特征）中，由[DiGress](https://openreview.net/forum?id=UaAD-Nu86WX)（ICLR’23）开创的离散图扩散似乎是最适用的选项。[Chen等人](https://openreview.net/forum?id=vn9O1N5ZOw)提出了**EDGE**，这是一种由节点度分布引导的离散扩散模型。与DiGress不同，EDGE中的最终目标图是没有边的断开图，前向噪声模型通过伯努利分布移除边，反向过程将边添加到最近的*活跃*节点（活跃节点是指在前一步中度数发生变化的节点）。由于度引导引入的稀疏性，EDGE可以生成高达4k节点和40k边的大型图！'
- en: '![](../Images/80698f82635bb17812b19baa5e974b13.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80698f82635bb17812b19baa5e974b13.png)'
- en: Graph Generation with EDGE. Source:[Chen et al](https://openreview.net/forum?id=vn9O1N5ZOw)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图生成与EDGE。来源：[Chen等人](https://openreview.net/forum?id=vn9O1N5ZOw)
- en: '**➡️** Finally, [**“Graphically Structured Diffusion Models”**](https://openreview.net/forum?id=24wzmwrldX)
    by *Weilbach et al* bridges the gap between continuous generative models and probabilistic
    graphical models that induce a certain structure in the problem of interest —
    often such problems have a combinatorial nature. The central idea is to encode
    the problem’s structure as an attention mask that respects permutation invariances
    and use this mask in the attention computation in the Transformer encoder (which
    by definition is equivariant to input token permutation unless you use positional
    embeddings). **GSDM** can tackle binary continuous matrix factorization, boolean
    circuits, can generate sudokus, and perform sorting. Particularly enjoyable is
    a pinch of irony the paper is written with 🙃.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 最后，[**“图形结构扩散模型”**](https://openreview.net/forum?id=24wzmwrldX)由*Weilbach等人*提出，弥合了连续生成模型与在感兴趣问题中引入特定结构的概率图模型之间的差距——通常此类问题具有组合性质。核心思想是将问题的结构编码为尊重排列不变性的注意力掩码，并在Transformer编码器的注意力计算中使用该掩码（根据定义，除非使用位置嵌入，否则对输入标记排列是等变的）。**GSDM**可以处理二进制连续矩阵分解、布尔电路，生成数独，并执行排序。特别有趣的是论文中蕴含的一丝讽刺🙃。'
- en: '![](../Images/e620b5450f6622c4e491e7a640999da5.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e620b5450f6622c4e491e7a640999da5.png)'
- en: 'GSDM task-to-attention-bias. Source: [**“Graphically Structured Diffusion Models”**](https://openreview.net/forum?id=24wzmwrldX)
    by *Weilbach et al*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: GSDM 任务到注意力偏差。来源：[**“图形结构扩散模型”**](https://openreview.net/forum?id=24wzmwrldX)
    由 *Weilbach 等*
- en: '![](../Images/7385dbac39148c3f404eed5abcd3b871.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7385dbac39148c3f404eed5abcd3b871.png)'
- en: Image By Author
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**Geometric Learning: Geometric WL, Clifford Algebras**'
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**几何学习：几何 WL，Clifford 代数**'
- en: Geometric Deep Learning thrives! There were so many interesting papers presented
    that would take pretty much the whole post, so I’d highlight only a few.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 几何深度学习蓬勃发展！有很多有趣的论文展示，这将占据整个帖子，因此我只会重点介绍几个。
- en: '**➡️ Geometric WL** has finally arrived in the work by [Joshi, Bodnar, et al](https://openreview.net/forum?id=6Ed3gchl9L).
    Geometric WL extends the notion of the WL test with geometric features (e.g.,
    coordinates or velocity) and derives the expressiveness hierarchy up to k-order
    GWL. Key takeaways: 1️⃣ **equivariant** models are more expressive than **invariant**
    (with a note that in fully connected graphs the difference disappears), 2️⃣ **tensor
    order** of features improves expressiveness, 3️⃣ **body order** of features improves
    expressiveness (see the image 👇). That is, *spherical > cartesian > scalars*,
    and *many-body interactions > just distances*. The paper also features the amazing
    learning source [Geometric GNN Dojo](https://github.com/chaitjo/geometric-gnn-dojo)
    where you can derive and implement most SOTA models from the first principles!'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️ 几何 WL** 终于在 [Joshi, Bodnar 等](https://openreview.net/forum?id=6Ed3gchl9L)
    的工作中出现。几何 WL 扩展了 WL 测试的概念，加入了几何特征（例如坐标或速度），并推导出表达力层级，直到 k-order GWL。关键点：1️⃣ **等变**
    模型比 **不变** 模型更具表现力（注意在完全连接的图中差异消失），2️⃣ **张量阶** 的特征提升了表现力，3️⃣ **体序** 的特征提升了表现力（见下图
    👇）。也就是说，*球面 > 笛卡尔坐标 > 标量*，以及 *多体交互 > 仅距离*。论文还展示了一个令人惊叹的学习资源 [Geometric GNN Dojo](https://github.com/chaitjo/geometric-gnn-dojo)，你可以从基本原理推导并实现大多数
    SOTA 模型！'
- en: '![](../Images/1a31d31c426441c200f0f409dda8d99b.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a31d31c426441c200f0f409dda8d99b.png)'
- en: 'Source: [Joshi, Bodnar, et al](https://openreview.net/forum?id=6Ed3gchl9L)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Joshi, Bodnar 等](https://openreview.net/forum?id=6Ed3gchl9L)
- en: '**➡️** Going beyond vectors to Clifford algebras, [Ruhe et al](https://openreview.net/forum?id=DNAJdkHPQ5)
    derive **Geometric Clifford Algebra Networks** (GCANs). Clifford algebras naturally
    support higher-order interactions by means of bivectors, trivectors, and (in general)
    multivectors. The key idea is the [Cartan-Dieudonné theorem](https://en.wikipedia.org/wiki/Cartan%E2%80%93Dieudonn%C3%A9_theorem)
    that every orthogonal transformation can be decomposed into *reflections* in hyperplanes,
    and geometric algebras represent data as the elements of the *Pin(p,q,r)* group.
    GCANs introduce a notion of linear layers, normalizations, non-linearities, and
    how they can be parameterized with neural networks. Experiments include modeling
    fluid dynamics and Navier-Stokes equations.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 超越向量到 Clifford 代数，[Ruhe 等](https://openreview.net/forum?id=DNAJdkHPQ5)
    推导了 **几何 Clifford 代数网络**（GCANs）。Clifford 代数通过双向量、三向量和（一般）多向量自然支持高阶交互。关键思想是 [Cartan-Dieudonné
    定理](https://en.wikipedia.org/wiki/Cartan%E2%80%93Dieudonn%C3%A9_theorem)，即每个正交变换都可以分解为在超平面上的
    *反射*，而几何代数将数据表示为 *Pin(p,q,r)* 群的元素。GCANs 引入了线性层、归一化、非线性等概念，以及它们如何用神经网络进行参数化。实验包括流体动力学建模和
    Navier-Stokes 方程。'
- en: '![](../Images/27b33c8d8cda800ff13af41870110670.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27b33c8d8cda800ff13af41870110670.png)'
- en: 'Source: [Ruhe et al](https://openreview.net/forum?id=DNAJdkHPQ5)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Ruhe 等](https://openreview.net/forum?id=DNAJdkHPQ5)
- en: In fact, there is already a [follow-up work](https://arxiv.org/abs/2305.11141)
    introducing equivariant Clifford NNs — you can learn more about Clifford algebras
    foundations and the most recent papers on [CliffordLayers](https://microsoft.github.io/cliffordlayers/)
    supported by Microsoft Research.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，已经有一篇[后续工作](https://arxiv.org/abs/2305.11141)介绍了等变 Clifford 神经网络——你可以了解更多关于
    Clifford 代数基础以及微软研究院支持的最新论文 [CliffordLayers](https://microsoft.github.io/cliffordlayers/)。
- en: 💊 [Equivariant GNN](http://proceedings.mlr.press/v139/satorras21a/satorras21a.pdf)
    (EGNN) is the Aspirin of Geometric DL that gets applied to almost every task and
    has seen quite a number of improvements. [**Eijkelboom et al**](https://openreview.net/forum?id=hF65aKF8Bf)
    marry EGNN with [Simplicial networks](https://arxiv.org/abs/2103.03212) that operate
    on higher-order structures (namely, simplicial complexes) into **EMPSN**. This
    is one of the first examples that combines geometric and topological features
    and has great improvement potential! Finally, [**Passaro and Zitnick**](https://openreview.net/forum?id=QIejMwU0r9)
    derive a neat trick to reduce SO(3) convolutions to SO(2) bringing the complexity
    down from O(L⁶) to O(L³) but with mathematical equivalence guarantees 👀. This
    finding allows to scale up geometric models on larger datasets like OpenCatalyst
    and already made it to [Equiformer V2](https://arxiv.org/abs/2306.12059) — soon
    in many other libraries for geometric models 😉
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 💊 [等变 GNN](http://proceedings.mlr.press/v139/satorras21a/satorras21a.pdf)（EGNN）是几何深度学习中的阿司匹林，几乎适用于所有任务，并且已经看到相当多的改进。[**Eijkelboom
    等**](https://openreview.net/forum?id=hF65aKF8Bf) 将 EGNN 与 [单纯形网络](https://arxiv.org/abs/2103.03212)
    结合，这些网络在高阶结构（即单纯形复合体）上操作，形成 **EMPSN**。这是第一个结合几何和拓扑特征的例子之一，具有很大的改进潜力！最后，[**Passaro
    和 Zitnick**](https://openreview.net/forum?id=QIejMwU0r9) 推导出一种巧妙的技巧，将 SO(3) 卷积简化为
    SO(2)，将复杂度从 O(L⁶) 降到 O(L³)，同时提供了数学等价性保证 👀。这一发现使得几何模型在像 OpenCatalyst 这样的大型数据集上得以扩展，并已被应用于
    [Equiformer V2](https://arxiv.org/abs/2306.12059) —— 很快将在许多其他几何模型库中出现 😉
- en: '![](../Images/211f7d576a50de6991e79cca291a5ac4.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/211f7d576a50de6991e79cca291a5ac4.png)'
- en: Image By Author.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者。
- en: '**Molecules: 2D-3D pretraining, Uncertainty Estimation in MD**'
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**分子：2D-3D 预训练，MD 中的不确定性估计**'
- en: '**➡️** [Liu, Du, et al](https://openreview.net/forum?id=mPEVwu50th) propose
    **MoleculeSDE**, a new framework for joint 2D-3D pretraining on molecular data.
    In addition to standard contrastive loss, the authors add two **generative** components:
    reconstructing 2D -> 3D and 3D -> 2D inputs through the score-based diffusion
    generation. Using standard GIN and SchNet as 2D and 3D models, MoleculeSDE is
    pre-trained on PCQM4M v2 and performs well on downstream fine-tuning tasks.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** [Liu, Du 等](https://openreview.net/forum?id=mPEVwu50th) 提出了 **MoleculeSDE**，这是一个新的框架，用于在分子数据上进行
    2D-3D 联合预训练。除了标准的对比损失外，作者还添加了两个 **生成** 组件：通过基于分数的扩散生成重建 2D -> 3D 和 3D -> 2D 输入。使用标准的
    GIN 和 SchNet 作为 2D 和 3D 模型，MoleculeSDE 在 PCQM4M v2 上进行了预训练，并在下游微调任务中表现良好。'
- en: '![](../Images/36ea80c8fb548a5e0c318b4447aa0425.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36ea80c8fb548a5e0c318b4447aa0425.png)'
- en: 'Source: [MoleculeSDE Github repo](https://github.com/chao1224/MoleculeSDE)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[MoleculeSDE Github 仓库](https://github.com/chao1224/MoleculeSDE)
- en: '**➡️** [Wollschläger et al](https://openreview.net/forum?id=DjwMRloMCO) perform
    a comprehensive study of Uncertainty Estimation in GNNs for molecular dynamics
    and force fields. Identifying key physics-informed and application-focused principles,
    the authors propose a **Localized Neural Kernel**, a Gaussian Process-based extension
    to any geometric GNN that works on invariant and equivariant quantities (tried
    on SchNet, DimeNet, and NequIP). In many cases, LNK’s estimations from one model
    are on par with or better than costly ensembling where you’d need to train several
    models.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** [Wollschläger 等](https://openreview.net/forum?id=DjwMRloMCO) 对 GNN 中的不确定性估计进行了一项全面研究，重点关注分子动力学和力场。识别关键的物理信息和应用导向原则，作者提出了一种
    **局部神经核**，这是一种基于高斯过程的扩展，适用于任何几何 GNN，处理不变和等变量（已在 SchNet、DimeNet 和 NequIP 上进行尝试）。在许多情况下，LNK
    从一个模型的估计与需要训练多个模型的昂贵集成效果相当或更好。'
- en: '![](../Images/c44e143e7fcd2be4bb3a3c5e1a0b13c8.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c44e143e7fcd2be4bb3a3c5e1a0b13c8.png)'
- en: 'Source: [Wollschläger et al](https://openreview.net/forum?id=DjwMRloMCO)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[Wollschläger 等](https://openreview.net/forum?id=DjwMRloMCO)
- en: '![](../Images/72f1a4c6b25d78630777885379b512c2.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72f1a4c6b25d78630777885379b512c2.png)'
- en: Image By Author.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者。
- en: '**Materials & Proteins: CLIP for proteins, Ewald Message Passing, Equivariant
    Augmentations**'
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**材料与蛋白质：CLIP 用于蛋白质，Ewald 消息传递，等变增强**'
- en: CLIP and its descendants have become a standard staple in text-to-image models.
    Can we do the same but for text-to-protein? Yes!
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: CLIP 及其后代已经成为文本到图像模型中的标准工具。我们能否对文本到蛋白质做同样的事情？可以！
- en: '**➡️** [Xu, Yuan, et al](https://openreview.net/forum?id=ZOOwHgxfR4) present
    **ProtST**, a framework for learning joint representations of text protein descriptions
    (via PubMedBERT) and protein sequences (via ESM). In addition to a contrastive
    loss, ProtST has a multimodal mask prediction objective, e.g., masking 15% of
    tokens in text and protein sequence, and predicting those jointly based on latent
    representations, and mask prediction losses based on sequences or language alone.
    Additionally, the authors design a novel **ProtDescribe** dataset with 550K aligned
    protein sequence-description pairs. **ProtST** excels across many protein modeling
    tasks in the [**PEER**](https://github.com/DeepGraphLearning/PEER_Benchmark) benchmark,
    including protein function annotation and localization, but also allows for zero-shot
    protein retrieval right from the textual description (see an example below). Looks
    like **ProtST** has a bright future of being a backbone behind many protein generative
    models 😉'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** [Xu, Yuan 等](https://openreview.net/forum?id=ZOOwHgxfR4) 提出了 **ProtST**，一个用于学习文本蛋白质描述（通过
    PubMedBERT）和蛋白质序列（通过 ESM）联合表示的框架。除了对比损失外，ProtST 还有一个多模态掩码预测目标，例如，掩盖文本和蛋白质序列中的
    15% 令牌，并基于潜在表示联合预测这些令牌，以及基于序列或语言单独的掩码预测损失。此外，作者设计了一个新的 **ProtDescribe** 数据集，包含
    550K 对齐的蛋白质序列-描述对。 **ProtST** 在 [**PEER**](https://github.com/DeepGraphLearning/PEER_Benchmark)
    基准测试中在许多蛋白质建模任务上表现出色，包括蛋白质功能注释和定位，同时还允许从文本描述中进行零样本蛋白质检索（见下例）。看起来 **ProtST** 具有成为许多蛋白质生成模型背后核心的光明前景
    😉'
- en: '![](../Images/724581ab255403ddca3fe2aebda87a1d.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/724581ab255403ddca3fe2aebda87a1d.png)'
- en: 'Source: [Xu, Yuan, et al](https://openreview.net/forum?id=ZOOwHgxfR4)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Xu, Yuan 等](https://openreview.net/forum?id=ZOOwHgxfR4)'
- en: Actually, ICML features several protein generation works like **GENIE** by [Lin
    and AlQuraishi](https://openreview.net/forum?id=4Kw5hKY8u8) and **FrameDiff**
    by [Yim, Trippe, De Bortoli, Mathieu, et al](https://openreview.net/forum?id=m8OUBymxwv)
    — those are not yet conditioned on textual descriptions, so incorporating ProtST
    there looks like a no-brainer performance boost 📈.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，ICML 展示了几项蛋白质生成工作，如 [Lin 和 AlQuraishi](https://openreview.net/forum?id=4Kw5hKY8u8)
    的 **GENIE** 和 [Yim, Trippe, De Bortoli, Mathieu 等](https://openreview.net/forum?id=m8OUBymxwv)
    的 **FrameDiff** — 这些工作尚未依赖文本描述，因此将 ProtST 融入其中似乎是提升性能的明智选择 📈
- en: '![](../Images/acfc681ee5d4ad4efc9a0d11266aae01.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/acfc681ee5d4ad4efc9a0d11266aae01.png)'
- en: 'Gif Source: [SE(3) Diffusion Github](https://github.com/jasonkyuyim/se3_diffusion)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 'Gif 来源: [SE(3) Diffusion Github](https://github.com/jasonkyuyim/se3_diffusion)'
- en: ⚛️ MPNNs on molecules have a strict locality bias that inhibits modeling long-range
    interactions. [Kosmala et al](https://openreview.net/forum?id=vd5JYAml0A) derive
    **Ewald Message Passing** and apply the idea of [Ewald summation](https://en.wikipedia.org/wiki/Ewald_summation)
    that breaks down the interaction potential into short-range and long-range terms.
    Short-range interaction is modeled by any GNN while long-range interaction is
    new and is modeled with a **3D Fourier transform** and message passing over Fourier
    frequencies. Turns out this long-range term is pretty flexible and can be applied
    to any network modeling periodic and aperiodic systems (like crystals or molecules)
    like SchNet, DimeNet, or GemNet. The model was evaluated on OC20 and OE62 datasets.
    If you are interested in more details, check out the [1-hour talk by Arthur Kosmala](https://www.youtube.com/watch?v=Ip8EGde5SUQ)
    at the LOG2 Reading Group!
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ⚛️ 分子上的 MPNNs 具有严格的局部性偏差，这会抑制对长程交互的建模。 [Kosmala 等](https://openreview.net/forum?id=vd5JYAml0A)
    推导出了 **Ewald 消息传递**，并应用了 [Ewald 求和](https://en.wikipedia.org/wiki/Ewald_summation)
    的思想，该思想将相互作用势能分解为短程和长程项。短程交互由任何 GNN 建模，而长程交互则是新的，通过 **3D 傅里叶变换** 和傅里叶频率上的消息传递来建模。结果表明，这一长程项相当灵活，可以应用于任何建模周期性和非周期性系统（如晶体或分子）的网络，如
    SchNet、DimeNet 或 GemNet。该模型在 OC20 和 OE62 数据集上进行了评估。如果你对更多细节感兴趣，可以查看 [Arthur Kosmala
    的 1 小时讲座](https://www.youtube.com/watch?v=Ip8EGde5SUQ)！
- en: '![](../Images/5d9f656fc6565a98a0b8db30a1aca1ba.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d9f656fc6565a98a0b8db30a1aca1ba.png)'
- en: 'Source: [Kosmala et al](https://openreview.net/forum?id=vd5JYAml0A)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [Kosmala 等](https://openreview.net/forum?id=vd5JYAml0A)'
- en: A similar idea of using Ewald summation for 3D crystals is used in **PotNet**
    by [Lin et al](https://openreview.net/forum?id=jxI4CulNr1) where the long-range
    connection is modeled with incomplete Bessel functions. PotNet was evaluated on
    the Materials Project dataset and JARVIS — so reading those two papers you can
    have a good understanding of the benefits brought by Ewald summation for many
    crystal-related tasks 😉
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在**PotNet**中，[林等人](https://openreview.net/forum?id=jxI4CulNr1)使用了与Ewald求和类似的思想来处理3D晶体，其中长程连接使用不完全贝塞尔函数建模。PotNet在Materials
    Project数据集和JARVIS上进行了评估，因此阅读这两篇论文可以很好地理解Ewald求和为许多与晶体相关的任务带来的好处 😉
- en: '![](../Images/2c37a782852ab0a7c1e90efe7aea17d7.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c37a782852ab0a7c1e90efe7aea17d7.png)'
- en: 'Source: [Lin et al](https://openreview.net/forum?id=jxI4CulNr1)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[林等人](https://openreview.net/forum?id=jxI4CulNr1)
- en: '**➡️** Another look at imbuing *any* GNNs with equivariance for crystals and
    molecules is given by [Duval, Schmidt, et al](https://openreview.net/forum?id=HRDRZNxQXc)
    in **FAENet**. A standard way is to bake certain symmetries and equivariances
    right into GNN architectures (like in EGNN, GemNet, and Ewald Message Passing)
    — this is a safe but computationally expensive way (especially when it comes to
    spherical harmonics and tensor products). Another option often used in vision
    — show many augmentations of the same input and the model should eventually learn
    the same invariances in the augmentations. The authors go for the 2nd path and
    design a rigorous way to sample 2D / 3D data invariant or equivariant augmentations
    (e.g., for energy or forces, respectively) all with fancy proofs ✍️. For that,
    the data augmentation pipeline includes projecting 2D / 3D inputs to a canonical
    representation (based on PCA of the covariance matrix of distances) from which
    we can uniformly sample rotations.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** 另一种方法是通过[杜瓦尔、施密特等人](https://openreview.net/forum?id=HRDRZNxQXc)在**FAENet**中赋予*任何*
    GNNs晶体和分子等效性的看法。一种标准的方法是将某些对称性和等效性直接嵌入GNN架构中（例如在EGNN、GemNet和Ewald Message Passing中）—
    这是一种安全但计算昂贵的方式（特别是涉及球谐函数和张量积时）。另一种选项通常用于视觉 — 展示相同输入的许多增强，模型最终应该学习到增强中的相同不变性。作者选择第二条路径，并设计了一种严格的方法来采样2D
    / 3D数据的不变或等变增强（例如用于能量或力的增强），所有这些增强都有花哨的证明 ✍️。为此，数据增强管道包括将2D / 3D输入投影到基于距离协方差矩阵的PCA的规范表示中，从中我们可以均匀采样旋转。'
- en: The proposed FAENet is a simple model that uses only distances but shows very
    good performance with the stochastic frame averaging data augmentation while being
    6–20 times faster. Works for crystal structures as well!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的FAENet是一个简单的模型，只使用距离，但在使用随机帧平均数据增强时表现非常好，同时速度快6到20倍。同样适用于晶体结构！
- en: '![](../Images/893a76e8a13595d1073078d444759d13.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/893a76e8a13595d1073078d444759d13.png)'
- en: 'Augmentations and Stochastic Frame Averaging. Source: [Duval, Schmidt, et al](https://openreview.net/forum?id=HRDRZNxQXc)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 增强和随机帧平均。来源：[杜瓦尔、施密特等](https://openreview.net/forum?id=HRDRZNxQXc)
- en: '![](../Images/45f447e910299d52cd636e7cb49cf723.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45f447e910299d52cd636e7cb49cf723.png)'
- en: Image By Author.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '**Cool Applications: Algorithmic Reasoning, Inductive KG Completion, GNNs for
    Mass Spectra**'
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**酷炫应用：算法推理，归纳KG完成，质谱GNN**'
- en: A few papers in this section did not belong to any of the above but are still
    worthy of your attention.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的几篇论文不属于上述任何一篇，但仍值得关注。
- en: '**➡️** [**”Neural Algorithmic Reasoning with Causal Regularisation”**](https://openreview.net/forum?id=kP2p67F4G7)
    by *Bevilacqua et al* tackles a common issue in graph learning — OOD generalization
    to larger inputs at test time. Studying OOD generalization in algorithmic reasoning
    problems, the authors observe that there exist many different inputs that make
    identical computations at a certain step. At the same time, it means that some
    subset of inputs does not (should not) affect the prediction result. This assumption
    allows to design a self-supervised objective (termed **Hint-ReLIC**) that prefers
    a “meaningful” step to a bunch of steps that do not affect the prediction result.
    The new objective significantly bumps the performance on many CLRS-30 tasks to
    90+% micro-F1\. It is an interesting question whether we could leverage the same
    principle in general message passing and improve OOD transfer in other graph learning
    tasks 🤔'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** [**“神经算法推理与因果正则化”**](https://openreview.net/forum?id=kP2p67F4G7) *Bevilacqua
    等人* 解决了图学习中的一个常见问题——在测试时对更大输入的OOD泛化。研究算法推理问题中的OOD泛化时，作者观察到在某一步骤中存在许多不同的输入产生相同的计算。与此同时，这也意味着某些输入子集不会（或不应该）影响预测结果。这个假设使得可以设计一个自监督目标（称为**Hint-ReLIC**），该目标更倾向于一个“有意义”的步骤而不是一堆不影响预测结果的步骤。这个新目标显著提高了许多CLRS-30任务的表现，达到90%以上的micro-F1。是否可以在一般消息传递中利用相同的原则来改进其他图学习任务中的OOD转移是一个有趣的问题
    🤔'
- en: '![](../Images/41ff0b6d703cdfba98fb986c679f46b4.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41ff0b6d703cdfba98fb986c679f46b4.png)'
- en: 'Source: [**”Neural Algorithmic Reasoning with Causal Regularisation”**](https://openreview.net/forum?id=kP2p67F4G7)
    by *Bevilacqua et al*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[**“神经算法推理与因果正则化”**](https://openreview.net/forum?id=kP2p67F4G7) *Bevilacqua
    等人*。
- en: If you are further interested in neural algorithmic reasoning, check out the
    proceedings of the [Knowledge and Logical Reasoning workshop](https://klr-icml2023.github.io/papers.html)
    which has even more works on that topic.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对神经算法推理更感兴趣，可以查看[知识与逻辑推理研讨会](https://klr-icml2023.github.io/papers.html)的会议记录，其中包含更多相关工作。
- en: '**➡️** [**“InGram: Inductive Knowledge Graph Embedding via Relation Graphs”**](https://openreview.net/forum?id=OoOpO0u4Xd)
    by *Lee et al* seems to be one of the very few knowledge graph papers at ICML’23
    (to the best of my search). **InGram** is one of the first approaches that can
    inductively generalize to both unseen entities and **unseen relations** at test
    time. Previously, inductive KG models needed to learn at least relation embeddings
    in some form to generalize to new nodes, and in this paradigm, new unseen relations
    are non-trivial to model. InGram builds a relation graph on top of the original
    multi-relational graph, that is, a graph of relation types, and learns representations
    of relations based on this graph by running a GAT. Entity representations are
    obtained from the random initialization and a GNN encoder. Having both entity
    and relation representations, a DistMult decoder is applied as a scoring function.
    There are good chances that InGram for unseen relations might be as influential
    as [GraIL (ICML 2020)](http://proceedings.mlr.press/v119/teru20a/teru20a.pdf)
    for unseen entities 😉.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**➡️** [**“InGram: 通过关系图的归纳知识图嵌入”**](https://openreview.net/forum?id=OoOpO0u4Xd)
    *Lee 等人* 似乎是ICML’23上为数不多的知识图谱论文之一（根据我的搜索）。**InGram** 是首批能够在测试时对未见实体和**未见关系**进行归纳泛化的方法之一。之前的归纳KG模型需要以某种形式学习关系嵌入以对新节点进行泛化，而在这种范式下，新的未见关系很难建模。InGram在原始的多关系图上构建了一个关系图，即关系类型的图，并通过运行GAT基于这个图学习关系的表示。实体表示是从随机初始化和GNN编码器中获得的。拥有实体和关系表示后，应用DistMult解码器作为评分函数。InGram在未见关系方面有很大机会与[GraIL
    (ICML 2020)](http://proceedings.mlr.press/v119/teru20a/teru20a.pdf)对未见实体的影响相当
    😉。'
- en: '![](../Images/6d1039c15f9e6f9a04a02604d808dda2.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d1039c15f9e6f9a04a02604d808dda2.png)'
- en: 'Source: [**“InGram: Inductive Knowledge Graph Embedding via Relation Graphs”**](https://openreview.net/forum?id=OoOpO0u4Xd)
    by *Lee et al*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '来源：[**“InGram: 通过关系图的归纳知识图嵌入”**](https://openreview.net/forum?id=OoOpO0u4Xd)
    *Lee 等人*。'
- en: 🌈 [**”Efficiently predicting high resolution mass spectra with graph neural
    networks”**](https://openreview.net/forum?id=81RIPI742h) by *Murphy et al* is
    a cool application of GNNs to a real physics problem of predicting mass spectra.
    The main finding is that most of the signal in mass spectra is explained by a
    small number of components (product ion and neutral loss *formulas*). And it is
    possible to mine a vocabulary of those *formulas* from training data. The problem
    can thus be framed as graph classification (or graph property prediction) when,
    given a molecular graph, we predict tokens from a vocabulary that correspond to
    certain mass spectra values. The approach, **GRAFF-MS**, builds molecular graph
    representation through GIN with edge features, with Laplacian features (via SignNet),
    and pooled with covariate features. Compared to the baseline CFM-ID, GRAFF-MS
    performs inference in ~19 minutes compared to 126 hours reaching much higher performance
    👀.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 🌈 [**“利用图神经网络高效预测高分辨率质谱”**](https://openreview.net/forum?id=81RIPI742h)由*Murphy等人*提出，是一个将GNNs应用于预测质谱这一实际物理问题的酷应用。主要发现是，大部分质谱信号可以通过少数几个成分（产物离子和中性丧失*公式*）来解释。并且有可能从训练数据中挖掘出这些*公式*的词汇。因此，这个问题可以被框架为图分类（或图属性预测），在给定分子图的情况下，我们预测与某些质谱值对应的词汇项。这种方法，**GRAFF-MS**，通过GIN构建带有边特征的分子图表示，通过SignNet获得拉普拉斯特征，并与协变量特征进行汇总。与基线CFM-ID相比，GRAFF-MS的推断时间为约19分钟，而CFM-ID则为126小时，性能显著提升👀。
- en: '![](../Images/594717432f130e81320f52d0aae3cda5.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/594717432f130e81320f52d0aae3cda5.png)'
- en: 'Source: [**”Efficiently predicting high resolution mass spectra with graph
    neural networks”**](https://openreview.net/forum?id=81RIPI742h) by *Murphy et
    al*'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [**“利用图神经网络高效预测高分辨率质谱”**](https://openreview.net/forum?id=81RIPI742h)由*Murphy等人*提出'
- en: The Concluding Meme Part
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论性表情包部分
- en: '![](../Images/ea3760ec5d97e92fb80054a68be94867.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea3760ec5d97e92fb80054a68be94867.png)'
- en: Four Michaels (+ epsilon in the background) on the same photo!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 同一张照片上的四位Michaels（背景中还有一个ε）！
- en: The meme of 2022 has finally converged to [Michael Bronstein](https://michael-bronstein.medium.com/)!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年的表情包终于汇聚到了[Michael Bronstein](https://michael-bronstein.medium.com/)！
