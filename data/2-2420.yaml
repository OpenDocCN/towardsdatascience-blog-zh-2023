- en: Your Own Personal LLaMa
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您的个人 LLaMa
- en: 原文：[https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb](https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb](https://towardsdatascience.com/your-own-personal-llama-8cf24a9237cb)
- en: How you can find, retrieve, and feed your custom data into LLaMa 2 to improve
    responses
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何找到、检索并将您的自定义数据输入 LLaMa 2 以改善响应
- en: '[](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Robert
    A. Gonsalves](../Images/96b4da0f602a1cd9d1e1d2917868cbee.png)](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    [Robert A. Gonsalves](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Robert
    A. Gonsalves](../Images/96b4da0f602a1cd9d1e1d2917868cbee.png)](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    [Robert A. Gonsalves](https://robgon.medium.com/?source=post_page-----8cf24a9237cb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    ·12 min read·Oct 9, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8cf24a9237cb--------------------------------)
    ·12 分钟阅读·2023年10月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1b4813b49c3698de27945718255e006d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b4813b49c3698de27945718255e006d.png)'
- en: '**“a minimalist painting of a cute llama standing in an art class,”** I*mage
    created using an AI image creation program,* Midjourney, and edited by the author'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**“一幅极简主义风格的可爱草泥马站在艺术课堂上的画作，”** 我*使用 AI 图像生成程序* Midjourney 创建，并由作者编辑'
- en: In my [last article](https://medium.com/p/cb0512091e3f), I showed how I could
    fine-tune OpenAI’s ChatGPT to improve the results of performing tasks like formatting
    text documents. Although fine-tuning helped the Large Language Model (LLM) better
    perform the formatting task, the model didn’t seem to absorb much of the knowledge
    in the training data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的 [上一篇文章](https://medium.com/p/cb0512091e3f) 中，我展示了如何微调 OpenAI 的 ChatGPT 以改善执行诸如格式化文本文档等任务的结果。尽管微调帮助大型语言模型（LLM）更好地执行格式化任务，但该模型似乎没有吸收训练数据中的很多知识。
- en: For this article, I explored using an open-source LLM, Meta’s LLaMa 2 [1], and
    a technique called Retrieval Augmented Generation (RAG) [2] to automatically find
    relevant reference text that helped the model answer questions. I used the text
    from 36 of my articles on Medium as reference material to see if I could create
    a private, custom chatbot that could answer questions about my writings.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我探索了使用开源 LLM，Meta 的 LLaMa 2 [1]，以及一种称为检索增强生成（RAG）[2] 的技术，自动找到相关参考文本，以帮助模型回答问题。我使用了我在
    Medium 上发表的 36 篇文章中的文本作为参考材料，看看是否可以创建一个私人定制的聊天机器人，能够回答关于我写作的相关问题。
- en: For example, without providing any reference text, here’s how LLaMa 2 responded
    to a question about [one of my articles](/muybridge-derby-bringing-animal-locomotion-photographs-to-life-with-ai-b1918e6622ec).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在没有提供任何参考文本的情况下，以下是 LLaMa 2 如何回应关于 [我的一篇文章](/muybridge-derby-bringing-animal-locomotion-photographs-to-life-with-ai-b1918e6622ec)
    的问题。
- en: '***RobG:*** *What is Muybridge Derby?*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***RobG:*** *什么是 Muybridge Derby？*'
- en: ''
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**LLaMa 2:** Thank you for asking! I’m here to help you with your question.
    However, I must inform you that “Muybridge Derby” is not a real or recognized
    term in any context. It’s possible that it may be a misspelling or a made-up'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**LLaMa 2：** 感谢您的提问！我在这里帮助您解答问题。然而，我必须告知您，“Muybridge Derby”不是任何上下文中真实或认可的术语。这可能是一个拼写错误或虚构的'
- en: term, and I cannot provide information on something that does not exist.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 术语，我无法提供关于不存在的事物的信息。
- en: If you could provide more context or clarify the term you are referring to,
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果您能提供更多上下文或澄清您所指的术语，
- en: I would be happy to try and assist you further. Please let me know if
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我很乐意进一步尝试协助您。请让我知道是否
- en: there’s anything else I can help with!
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果还有其他我可以帮助的地方，请告诉我！
- en: That was a very polite way to say it had never heard of the project. And it
    didn’t “hallucinate” and make up something false.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 那是一种非常礼貌的方式来表示它从未听说过这个项目。而且它没有“幻觉”并编造虚假的信息。
- en: Here’s the question again with a follow-up request for more info, but the system
    had access to some reference text this time.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这是再次提问并请求更多信息的情况，不过这次系统有一些参考文本可用。
- en: '***RobG:*** *What is Muybridge Derby?*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***RobG:*** *什么是穆伊布里奇德比？*'
- en: ''
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**LLaMa 2:** Muybridge Derby is a project by Robert A. Gonsalves where he used
    Midjourney and RunwayML to transform Eadweard Muybridge’s photo sequences into
    high-resolution videos.'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**LLaMa 2：** 穆伊布里奇德比是Robert A. Gonsalves的一个项目，他使用了Midjourney和RunwayML将Eadweard
    Muybridge的照片序列转换为高分辨率视频。'
- en: ''
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***RobG:*** *Tell me more about the AI systems.*'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***RobG:*** *告诉我更多关于人工智能系统的事。*'
- en: ''
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**LLaMa 2:** In the Muybridge Derby project, Robert A. Gonsalves used two AI
    systems to transform Eadweard Muybridge’s photo sequences into high-resolution
    videos: 1\. Midjourney: a tool for creating interactive visual stories using AI-generated
    images and text. 2\. RunwayML: a platform for creating, training, and deploying
    machine learning models. These systems allowed Gonsalves to transform Muybridge’s
    static photographs into dynamic videos that bring the animal locomotion to life.'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**LLaMa 2：** 在穆伊布里奇德比项目中，Robert A. Gonsalves使用了两个人工智能系统，将Eadweard Muybridge的照片序列转换为高分辨率视频：1.
    Midjourney：一个使用人工智能生成图像和文本创建互动视觉故事的工具。2. RunwayML：一个用于创建、训练和部署机器学习模型的平台。这些系统使Gonsalves能够将Muybridge的静态照片转换为动态视频，展现动物的运动。'
- en: Much better! The system answered the first question briefly and accurately.
    The response to the follow-up request was a bit wordy in that it repeated some
    of the info in the first answer, but overall, the results were good.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 好多了！系统对第一个问题的回答简洁而准确。对后续请求的回应略显冗长，因为重复了一些第一个回答中的信息，但总体结果还是不错的。
- en: Overview
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: This section provides an overview of the project and the components I used.
    I’ll discuss each component and process in more detail further below.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了项目和我使用的组件的概述。我将在下面进一步详细讨论每个组件和过程。
- en: '![](../Images/90ef413a7e5d766317b90abe3ffc9443.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90ef413a7e5d766317b90abe3ffc9443.png)'
- en: '**Components of the Personal LLaMa Project**, Diagram by Author'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人LLaMa项目的组件**，作者图示'
- en: I started with the text from 36 of my articles on Medium and converted them
    from HTML to Markdown language for ease of retrieval. I used an open-source framework
    for text generation called [LlamaIndex](https://github.com/run-llama/llama_index)
    to index, search, and provide sections of my articles as reference text to the
    LLMs.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我从我在Medium上的36篇文章中提取了文本，并将其从HTML格式转换为Markdown语言，以便于检索。我使用了一个名为[LlamaIndex](https://github.com/run-llama/llama_index)的开源文本生成框架，用于索引、搜索和提供文章部分作为参考文本给LLMs。
- en: 'To test the system’s accuracy, I used GPT-4 [3] to generate a set of 100 questions
    and answers about my articles. I tested three LLMs to see how well they worked:
    two variants of LLaMa with 7 and 13 billion parameters and ChatGPT [4], which
    has a whopping 175B parameters.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试系统的准确性，我使用GPT-4 [3]生成了一组关于我的文章的100个问题和答案。我测试了三种LLM，看看它们的效果如何：两种参数分别为7亿和13亿的LLaMa变体，以及具有1750亿参数的ChatGPT
    [4]。
- en: I assessed the results using a semantic text embedding model, MPNet [5], which
    a team at Hugging Face further trained as a model called [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2).
    I compared the embeddings of the answers from the three models to the embedding
    of the expected response from GPT-4 using cosine similarity to get accuracy scores,
    which are reported in the Results section below.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了一个语义文本嵌入模型MPNet [5]来评估结果，该模型由Hugging Face团队进一步训练成一个名为[all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)的模型。我通过余弦相似度比较了三种模型的回答嵌入与GPT-4预期响应的嵌入，以获得准确性得分，这些得分在下文的结果部分报告。
- en: Components and Processes
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组件和过程
- en: Here are the details of the components and processes I used in this project.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我在这个项目中使用的组件和过程的详细信息。
- en: Converting HTML to Markdown
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将HTML转换为Markdown
- en: Markdown is a lightweight markup language with plain-text-formatting syntax.
    John Gruber and Aaron Swartz created Markdown in 2004 as a markup language intended
    to be easy to read and easy to write [6]. Because of the simplified syntax, documents
    in Markdown format are easier to parse and break into cohesive text segments than
    HTML. I used the [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)
    Python library to help convert my articles from HTML to Markdown.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Markdown 是一种轻量级标记语言，具有纯文本格式化语法。John Gruber 和 Aaron Swartz 于 2004 年创建了 Markdown，旨在成为一种易读易写的标记语言
    [6]。由于简化的语法，Markdown 格式的文档比 HTML 更容易解析和分解为连贯的文本段落。我使用了 [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)
    Python 库来帮助将我的文章从 HTML 转换为 Markdown。
- en: For example, here is an excerpt from my Muybridge Derby article in HTML and
    Markdown formats.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里是我在 HTML 和 Markdown 格式中的 Muybridge Derby 文章摘录。
- en: '![](../Images/f4c61b0d18122feb1d13156a79882fdb.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4c61b0d18122feb1d13156a79882fdb.png)'
- en: '**Comparison of HTML Format** (left) and **Markdown Format** (right), Image
    by Author'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**HTML 格式**（左）与**Markdown 格式**（右）的比较，图片由作者提供'
- en: You can see how the HTML format on the left has a lot more metadata and punctuation
    characters than the same document in Markdown format on the right. Having the
    documents in Markdown format makes the downstream processes easier. You can see
    my conversion code in this [Google Colab](https://colab.research.google.com/github/robgon-art/Finetune-ChatGPT/blob/main/1_Get_Article_Text.ipynb).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到左侧的 HTML 格式比右侧的 Markdown 格式包含更多的元数据和标点符号。将文档转为 Markdown 格式可以使下游过程更为简单。你可以在这个
    [Google Colab](https://colab.research.google.com/github/robgon-art/Finetune-ChatGPT/blob/main/1_Get_Article_Text.ipynb)
    中查看我的转换代码。
- en: LlamaIndex
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LlamaIndex
- en: LlamaIndex is an open-source project that connects LLMs to various data sources,
    enabling structured data interaction and application enhancement through natural
    language interfaces and knowledge-augmented responses. It facilitates data ingestion,
    indexing, and utilization across diverse formats and supports the development
    of interactive, data-informed applications [7].
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex 是一个开源项目，它将 LLMs 连接到各种数据源，通过自然语言接口和知识增强的响应来实现结构化数据的交互和应用提升。它支持数据摄取、索引和利用，适用于多种格式，并支持开发交互式、数据驱动的应用程序
    [7]。
- en: It’s straightforward to use the LlamaIndex framework in Python. Here’s a simple
    example that shows the system’s API. It uses ChatGPT by default, but other LLMs,
    like LLaMa 2, can easily be used.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中使用 LlamaIndex 框架非常简单。这里有一个简单的示例展示了系统的 API。默认使用 ChatGPT，但也可以轻松使用其他
    LLM，如 LLaMa 2。
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I stored the Markdown files for my 36 articles in the robgon_articles_md folder.
    The SimpleDirectoryReader object reads them in and breaks them into multiple segments,
    using the formatting as hints to isolate cohesive blocks of text. It averaged
    about 18 blocks per article for a total of 632\. The VectorStoreIndex object creates
    semantic embeddings for the segments to find references for the queries. A query
    engine is created from the index, which facilitates answering questions related
    to the documents.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我将 36 篇文章的 Markdown 文件存储在 robgon_articles_md 文件夹中。SimpleDirectoryReader 对象读取这些文件，并将其分成多个段落，利用格式作为提示来隔离连贯的文本块。每篇文章平均约
    18 个块，总共 632 个。VectorStoreIndex 对象为这些段落创建语义嵌入，以寻找查询的参考。查询引擎由索引创建，便于回答与文档相关的问题。
- en: Here is the response to a question about [another one of my projects](/deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对 [我另一个项目]( /deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701)
    的问题的回应。
- en: 'RobG: What is DeepHaiku? Be brief.'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: RobG：什么是 DeepHaiku？请简要说明。
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'ChatGPT: Deep Haiku is a model that generates Haikus using a fine-tuned GPT-J
    6B model. It starts with a prompt and creates 20 candidate Haikus, filtering for
    adherence to the [5, 7, 5] meter and optionally removing explicit language. The
    top candidates are displayed along with their scores.'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ChatGPT：Deep Haiku 是一个使用微调的 GPT-J 6B 模型生成 Haikus 的模型。它从一个提示开始，生成 20 个候选 Haikus，筛选出符合
    [5, 7, 5] 韵律的，并可选择性地去除显式语言。最终候选者及其得分会被展示出来。
- en: This is an excellent summary of my DeepHaiku article. We’ll see in a moment
    how well LLaMa 2 7B and 13B perform answering questions like this.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我 DeepHaiku 文章的一个很好的总结。我们很快将看到 LLaMa 2 7B 和 13B 在回答类似问题时的表现如何。
- en: Language Models
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言模型
- en: The following sections describe the three LLMs I used in this project, listed
    chronologically by release date.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分描述了我在这个项目中使用的三个 LLM，按发布日期的时间顺序列出。
- en: '**ChatGPT**'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ChatGPT**'
- en: ChatGPT is a language generation model developed by OpenAI based on the GPT
    (Generative Pretrained Transformer) architecture released in November 2022\. Like
    the original GPT, the newer ChatGPT model has 175 billion machine-learning parameters.
    It’s capable of understanding and generating human-like text based on the input
    it receives, and it’s used for various natural language processing tasks, such
    as text completion, summarization, and conversational agents [4]. A version of
    ChatGPT called GPT-3.5 Turbo was released in March 2023\. It was trained using
    supervised learning with a massive corpus of text data and fine-tuned through
    reinforcement learning from human feedback. This allows it to create coherent
    and contextually relevant text based on the input it receives [8].
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 是一个由OpenAI开发的语言生成模型，基于2022年11月发布的GPT（生成预训练变换器）架构。与原始GPT一样，新版ChatGPT模型具有1750亿个机器学习参数。它能够根据接收到的输入理解和生成类似人类的文本，并用于各种自然语言处理任务，如文本完成、总结和对话代理
    [4]。一个名为GPT-3.5 Turbo 的ChatGPT版本于2023年3月发布。它通过监督学习，使用大量的文本数据进行训练，并通过人类反馈的强化学习进行微调。这使得它能够基于接收到的输入生成连贯且具有上下文相关性的文本
    [8]。
- en: '**GPT-4**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**GPT-4**'
- en: GPT-4 is a large-scale, multimodal model developed to accept image and text
    inputs and produce text outputs. It was also released in March 2023 by OpenAI.
    Although a version of the model supports image inputs, it’s not currently available
    to the public. GPT-4 demonstrated human-level performance on various benchmarks,
    including passing a simulated bar exam with high scores. The model underwent a
    post-training alignment process to enhance its factuality and adherence to desired
    behavior. Most of its development involved creating infrastructure and optimization
    methods that behave predictably across various scales [3].
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 是一个大规模的多模态模型，旨在接受图像和文本输入并生成文本输出。它于2023年3月由OpenAI发布。虽然该模型的一个版本支持图像输入，但目前尚未向公众开放。GPT-4
    在各种基准测试中表现出人类水平的性能，包括以高分通过了模拟的律师资格考试。该模型经历了后训练对齐过程，以提高其事实性和对期望行为的遵循。其大部分开发工作涉及创建基础设施和优化方法，这些方法在各种规模下表现一致
    [3]。
- en: '**LLaMa 2**'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**LLaMa 2**'
- en: Meta’s LLaMa 2 is a collection of pretrained and fine-tuned LLMs with a scale
    ranging from 7 billion to 70 billion parameters, released in July 2023\. The collection
    includes a variant named LLaMa 2-Chat for interactive text generation. Meta showed
    how their models have demonstrated superior performance as compared to open-source
    chat models across numerous benchmarks and have shown promising results in human
    evaluations for helpfulness and safety. The developers explain their fine-tuning
    and safety enhancement approaches for LLaMa 2-Chat, aiming to facilitate further
    community involvement and responsible LLM development [1].
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Meta的LLaMa 2是一系列经过预训练和微调的LLM，规模从70亿到700亿参数不等，于2023年7月发布。该系列包括一个名为LLaMa 2-Chat的变体，用于交互式文本生成。Meta展示了他们的模型在许多基准测试中相比开源聊天模型表现优越，并在有用性和安全性方面在人类评估中显示出良好的结果。开发者解释了他们对LLaMa
    2-Chat的微调和安全增强方法，旨在促进更多社区参与和负责任的LLM开发 [1]。
- en: The authors described their safety considerations for the LLaMa 2 model. They
    explained their safety alignment process, which involved collecting safety-related
    annotations supported by experimental results. They also engaged “red teams” that
    tested and enhanced model safety. They presented an examination and mitigation
    of potential risks associated with the model’s deployment and concluded their
    paper with the following warning.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 作者描述了他们对LLaMa 2模型的安全考虑。他们解释了他们的安全对齐过程，该过程包括收集安全相关的注释，这些注释得到了实验结果的支持。他们还聘用了“红队”，这些团队测试并增强了模型的安全性。他们对与模型部署相关的潜在风险进行了检查和缓解，并以以下警告结束了他们的论文。
- en: Llama 2 is a new technology that carries risks with use. Testing conducted to
    date has been in English, and has not covered, nor could it cover all scenarios.
    For these reasons, as with all LLMs, Llama 2’s potential outputs cannot be predicted
    in advance, and the model may in some instances produce inaccurate or objectionable
    responses to user prompts. Therefore, before deploying any applications of Llama
    2, developers should perform safety testing and tuning tailored to their specific
    applications of the model. - Hugo Touvron, et al. [1]
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Llama 2 是一种新技术，使用中存在风险。迄今为止进行的测试仅限于英语，并且没有涵盖所有场景，也无法涵盖所有场景。因此，与所有 LLM 一样，Llama
    2 的潜在输出无法提前预测，模型在某些情况下可能会对用户提示产生不准确或令人反感的回应。因此，在部署 Llama 2 的任何应用程序之前，开发人员应针对模型的具体应用进行安全测试和调整。
    - Hugo Touvron 等 [1]
- en: I’m happy to read that the researchers at Meta are taking model safety seriously.
    Fortunately, my use of the LLaMa 2 models didn’t stress the system to try and
    produce objectionable responses, but it’s good to know that mitigations are in
    place.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我很高兴看到 Meta 的研究人员认真对待模型安全性。幸运的是，我对 LLaMa 2 模型的使用并没有对系统造成压力以产生令人反感的回应，但知道已有缓解措施是好的。
- en: '**LLaMa 2 License**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**LLaMa 2 许可证**'
- en: Although Meta released the source code and trained weights for LLaMa 2 as free
    and open-source, [their license](https://ai.meta.com/llama/license/) has a couple
    of unique twists. It stipulates that entities with over 700 million monthly active
    users must request and be granted a specific license from Meta to use the model.
    It explicitly prohibits anyone from using LLaMa 2 to enhance other LLMs. I’m not
    a lawyer, so please seek legal advice to fully understand the terms and conditions
    before using LLaMa 2.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Meta 发布了 LLaMa 2 的源代码和训练权重作为免费和开源，但[他们的许可证](https://ai.meta.com/llama/license/)有几个独特的细节。它规定，每月活跃用户超过
    7 亿的实体必须请求并获得 Meta 授予的特定许可证才能使用该模型。它明确禁止任何人使用 LLaMa 2 来增强其他 LLM。我不是律师，所以在使用 LLaMa
    2 之前，请寻求法律建议以全面理解条款和条件。
- en: Generating Test Questions and Answers
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成测试问题和答案
- en: To judge the correctness of answers from the LLaMa 2 chat models, I used GPT-4
    to generate 100 questions and answers about my articles on Medium. I started with
    100 segments of text collected by LlamaIndex and fed the reference text into GPT-4
    with the following prompt.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了判断 LLaMa 2 聊天模型回答的正确性，我使用 GPT-4 生成了 100 个关于我在 Medium 上文章的问题和答案。我从 LlamaIndex
    收集了 100 段文本，并将参考文本输入到 GPT-4 中，使用了以下提示。
- en: '*Ask one question about the reference material and answer it.'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提出一个关于参考材料的问题并回答。'
- en: Don’t use the phrase ‘reference material.’ Instead, use the article's title
    or the project's nickname.
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不要使用“参考材料”这个词。请改用文章标题或项目的昵称。
- en: In the question don’t use the phrase ‘the author’. Use ‘Robert’ or ‘Robert A.
    Gonsalves’ instead.
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在问题中不要使用“作者”这个词。请改用“Robert”或“Robert A. Gonsalves”。
- en: In the answer, refer to the author as ‘he/him/his’ if his name was used in the
    question.
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在答案中，如果问题中提到了他的名字，请用‘他’或‘他的’来指代作者。
- en: 'Use the format:'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用格式：
- en: 'q: <question>'
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'q: <question>'
- en: 'a: <answer>*'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'a: <answer>*'
- en: Here are some example questions and answers generated by GPT-4.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是 GPT-4 生成的一些示例问题和答案。
- en: 'q: How did Robert use CLIP to filter the images for the MAGnet project?'
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'q: Robert 如何使用 CLIP 筛选 MAGnet 项目的图像？'
- en: 'a: Robert used CLIP to filter the images by comparing the embedding from the
    phrase “modern painting” to the embeddings from the paintings. This allowed him
    to find the top 10,000 images that best matched the phrase “modern painting”.
    This was done to ensure that the images used for training were good examples of
    modern painting.'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'a: Robert 使用 CLIP 通过将“现代绘画”这个短语的嵌入与绘画的嵌入进行比较来筛选图像。这使他能够找到最符合“现代绘画”这个短语的前 10,000
    张图像。这是为了确保用于训练的图像是现代绘画的良好示例。'
- en: ''
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'q: What is the main objective of Robert A. Gonsalves’ project ‘GPT-4 Chords’?'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'q: Robert A. Gonsalves 的项目“GPT-4 和弦”的主要目标是什么？'
- en: 'a: The main objective of his project ‘GPT-4 Chords’ is to demonstrate how to
    use the latest large language model from OpenAI, GPT-4, to help compose chords
    for original songs.'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'a: 他项目“GPT-4 和弦”的主要目标是展示如何使用 OpenAI 最新的大型语言模型 GPT-4 来帮助创作原创歌曲的和弦。'
- en: ''
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'q: How did Robert A. Gonsalves modify the images created by DALL-E for the
    Mark Madness comic?'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'q: Robert A. Gonsalves 如何修改 DALL-E 为 Mark Madness 漫画创建的图像？'
- en: 'a: Robert cleaned up the images in Photoshop, added the title, and replaced
    the gibberish text in the word balloons with dialog generated by GPT-3\. He also
    used a trick in Photoshop to replicate the eyes of the characters Mark and Enrique,
    and used the Comic Sans font for the dialog.'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'a: 罗伯特在 Photoshop 中清理了图像，添加了标题，并用 GPT-3 生成的对话替换了文字气泡中的胡言乱语文本。他还在 Photoshop
    中使用了一个技巧来复制角色 Mark 和 Enrique 的眼睛，并为对话使用了 Comic Sans 字体。'
- en: These all look pretty good. The questions ask about things readers might be
    interested in, and the answers seem accurate, well-written, and brief.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这些看起来都很好。问题涉及读者可能感兴趣的内容，答案似乎准确、写得好且简洁。
- en: Generating the Answers
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成答案
- en: For each of the three LLMs I tested, LLaMa 2 7B, LLaMa 2 13B, and ChatGPT, I
    fed in the corresponding reference material and the question with an additional
    prompt, “Be brief.” The systems generated answers for all 100 questions. Here
    is a table that shows the answers to three of the questions.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我测试的三种 LLM，LLaMa 2 7B、LLaMa 2 13B 和 ChatGPT，我输入了相应的参考材料和问题，并附加了提示“简洁”。系统生成了所有
    100 个问题的答案。以下是显示三个问题答案的表格。
- en: '![](../Images/a2dcc1ba8ee7e063fd92a4fa9a039e93.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2dcc1ba8ee7e063fd92a4fa9a039e93.png)'
- en: '**Questions with Answers from the Large Language Models**, Table by Author'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**来自大型语言模型的问答**，由作者编制的表格'
- en: All of the answers seem good. They all state the main facts clearly and succinctly.
    The only notable differences can be seen in the responses from LLaMa 2 13B. All
    three of its answers start with a general clause like “Sure! Here is the answer
    to your question …” and “Based on the information provided …” These phrases don’t
    add much value to the responses.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的回答似乎都不错。它们都清晰而简洁地陈述了主要事实。唯一显著的区别可以在 LLaMa 2 13B 的回答中看到。它的所有三个回答都以类似于“当然！这是你问题的答案……”和“基于提供的信息……”的通用条款开始。这些短语对回答的价值不大。
- en: Comparing Text for Semantic Similarity
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较文本的语义相似性
- en: To assess the three models quantitatively, I used a semantic text encoding model
    called [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)
    developed by the researchers at Hugging Face. The encoding model takes in text
    strings and produces a corresponding array of embeddings, lists of 768 floating-point
    numbers, that represent the meaning of the text. Here’s some Python code to show
    how it works.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定量评估这三种模型，我使用了一个名为 [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)
    的语义文本编码模型，该模型由 Hugging Face 的研究人员开发。该编码模型接收文本字符串并生成对应的嵌入数组，这些数组包含 768 个浮点数，表示文本的含义。以下是一些
    Python 代码，展示了其工作原理。
- en: '[PRE1]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: I sent two text strings into the model to create embeddings and compared them
    using the cosine similarity metric. The resulting similarity ranges from 0.0 to
    1.0, depending on how close the two text strings are in meaning. In this example,
    the strings were 90.2% the same. I used this metric to assess the results of the
    LMMs.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我将两个文本字符串输入模型以创建嵌入，并使用余弦相似度度量进行比较。结果的相似度范围从 0.0 到 1.0，具体取决于两个文本字符串的语义接近程度。在这个例子中，字符串的相似度为
    90.2%。我使用这个度量来评估 LMM 的结果。
- en: Results
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: I used the semantic embedding model to compare all 100 answers from the three
    LLMs to the baseline answers from GPT-4 and compiled the following graph that
    shows the results.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用语义嵌入模型将三种 LLM 的所有 100 个答案与 GPT-4 的基准答案进行比较，并编制了以下图表以显示结果。
- en: '![](../Images/176bc12b220cb59c338921d9e0e60be6.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/176bc12b220cb59c338921d9e0e60be6.png)'
- en: '**LMM Results Comparison**, Chart by Author'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**LMM 结果比较**，由作者编制的图表'
- en: This Box and Whisker graph shows a visualization of the test results. The central
    boxes represent the middle 50% of the data, with lines indicating the median.
    Whiskers extend to the smallest and largest values, while dots indicate statistical
    outliers. The X’s represent the mean values of the scores. In general, you can
    see that the results from LLaMa 2 7B and ChatGPT are very close, although the
    LLaMa 2 does have some of the lowest scores. It’s curious to see that the results
    from LLaMa 2 13B are slightly worse than the other two models. This may be due
    to the extra wordiness of the answers.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个箱线图展示了测试结果的可视化。中央的箱子代表数据的中间 50%，箱子的线条表示中位数。胡须延伸到最小值和最大值，而点表示统计异常值。X 代表分数的平均值。通常，可以看到
    LLaMa 2 7B 和 ChatGPT 的结果非常接近，尽管 LLaMa 2 的分数有一些最低的值。令人好奇的是，LLaMa 2 13B 的结果略逊于其他两个模型。这可能是由于答案的冗长。
- en: Conclusion
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: My exploration of using Meta’s LLaMa 2 for enhancing the quality and accuracy
    of responses in a custom chatbot, built upon a knowledge base of my 36 articles
    on Medium, has provided insights into LLMs’ practical application and limitations.
    The experiment demonstrated that while providing LLaMa 2 with relevant reference
    text significantly improved response accuracy, the relationship between model
    size and response quality was not linear, as evidenced by the varied performance
    between LLaMa 2 7B and 13B. Furthermore, using semantic similarity as a metric
    for evaluating responses highlighted the nuanced differences and variability in
    the answers provided by different models.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我对使用 Meta 的 LLaMa 2 来提高基于我在 Medium 上发布的 36 篇文章知识库的自定义聊天机器人回应的质量和准确性的探索，提供了对
    LLM 实际应用和局限性的见解。实验表明，尽管为 LLaMa 2 提供相关参考文本显著提高了回应准确性，但模型大小与回应质量之间的关系并非线性，这从 LLaMa
    2 7B 和 13B 之间的性能差异中得到了体现。此外，使用语义相似性作为评估回应的指标突显了不同模型提供的答案之间的细微差异和变异性。
- en: This investigation not only underscores the potential of using LLaMa 2 for specific,
    customized applications but also brings to light the critical importance of ethical
    considerations and thorough testing in deploying such technologies. The guidelines
    and warnings provided by Meta are a pertinent reminder of the responsibilities
    of developers and researchers in ensuring the safe and ethical use of LLMs, especially
    as they become more integrated into various digital platforms and applications.
    The balance between technological advancement and ethical deployment will continue
    to be a pivotal focus in developing and applying LLMs in diverse environments.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这项调查不仅强调了使用 LLaMa 2 进行特定、定制化应用的潜力，还揭示了在部署这些技术时伦理考量和彻底测试的重要性。Meta 提供的指南和警示恰恰提醒了开发者和研究人员在确保
    LLM 的安全和伦理使用方面的责任，特别是在这些技术逐渐融入各种数字平台和应用程序时。技术进步与伦理部署之间的平衡将继续是开发和应用 LLM 在不同环境中的关键焦点。
- en: Next Steps
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步
- en: Further exploration into the retrieval accuracy of LlamaIndex could involve
    a structured evaluation to understand the model’s effectiveness in identifying
    and providing relevant reference material. Additionally, investigating text comparison
    metrics beyond semantic similarity might offer insights into model responses’
    linguistic and contextual nuances. This dual-faceted approach aims to provide
    a more comprehensive understanding of model performance and guide future developments
    in enhancing the accuracy and linguistic quality of LLM responses.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步探索 LlamaIndex 的检索准确性可以通过结构化评估来理解模型在识别和提供相关参考材料方面的有效性。此外，调查语义相似性之外的文本比较指标可能会提供有关模型回应语言和上下文细微差异的见解。这种双重方法旨在提供对模型性能的更全面理解，并指导未来在提高
    LLM 回应准确性和语言质量方面的发展。
- en: Source Code
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源代码
- en: I am releasing the [source code](https://github.com/robgon-art/personal-llama)
    for this project on GitHub under the Creative Commons Attribution Sharealike license.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在 GitHub 上发布[源代码](https://github.com/robgon-art/personal-llama)，使用创意共享署名-相同方式共享许可证。
- en: '![](../Images/9a80f99277d71fcafa90f620b3c68396.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a80f99277d71fcafa90f620b3c68396.png)'
- en: '**Creative Commons Attribution Sharealike**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**创意共享署名-相同方式共享**'
- en: Acknowledgments
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: I want to thank Jennifer Lim for reviewing the article and providing feedback.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢 Jennifer Lim 对本文的审阅和反馈。
- en: References
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] H. Touvron et al., [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288),
    (2023)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] H. Touvron 等，[Llama 2: 开放基础与微调聊天模型](https://arxiv.org/abs/2307.09288)，（2023）'
- en: '[2] P. Lewis et al., [Retrieval-Augmented Generation for Knowledge-Intensive
    NLP Tasks](https://arxiv.org/abs/2005.11401), (2020), Advances in Neural Information
    Processing Systems'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] P. Lewis 等，[增强检索生成用于知识密集型 NLP 任务](https://arxiv.org/abs/2005.11401)，（2020），《神经信息处理系统进展》'
- en: '[3] OpenAI, [GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf),
    (2023)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] OpenAI，[GPT-4 技术报告](https://cdn.openai.com/papers/gpt-4.pdf)，（2023）'
- en: '[4] T. Brown et al. [Language models are few-shot learners](https://arxiv.org/abs/2005.14165),
    Advances in Neural Information Processing Systems, (2020)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] T. Brown 等，[语言模型是少样本学习者](https://arxiv.org/abs/2005.14165)，《神经信息处理系统进展》，（2020）'
- en: '[5] S. Kaitao, et al. [Mpnet: Masked and permuted pre-training for language
    understanding](https://proceedings.neurips.cc/paper/2020/hash/c3a690be93aa602ee2dc0ccab5b7b67e-Abstract.html),
    Advances in Neural Information Processing Systems, (2020)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] S. Kaitao 等，[Mpnet: Masked and permuted pre-training for language understanding](https://proceedings.neurips.cc/paper/2020/hash/c3a690be93aa602ee2dc0ccab5b7b67e-Abstract.html)，《神经信息处理系统进展》，（2020）'
- en: '[6] A. Swartz, [Markdown](http://www.aaronsw.com/weblog/001189)*,* (2017)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] A. Swartz，[Markdown](http://www.aaronsw.com/weblog/001189)*,*（2017）'
- en: '[7] J. Liu, [LlamaIndex](https://github.com/run-llama/llama_index), (2022)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] J. Liu, [LlamaIndex](https://github.com/run-llama/llama_index)，（2022）'
- en: '[8] OpenAI, [Introducing ChatGPT](https://openai.com/blog/chatgpt), (2022)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] OpenAI，[Introducing ChatGPT](https://openai.com/blog/chatgpt)，（2022）'
