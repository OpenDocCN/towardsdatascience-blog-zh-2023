- en: Deploy a Custom ML Model as a SageMaker Endpoint
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将自定义 ML 模型部署为 SageMaker 端点
- en: 原文：[https://towardsdatascience.com/deploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428?source=collection_archive---------0-----------------------#2023-12-08](https://towardsdatascience.com/deploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428?source=collection_archive---------0-----------------------#2023-12-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428?source=collection_archive---------0-----------------------#2023-12-08](https://towardsdatascience.com/deploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428?source=collection_archive---------0-----------------------#2023-12-08)
- en: '![](../Images/4c0d654b542867fe832bc898ebb49a1d.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c0d654b542867fe832bc898ebb49a1d.png)'
- en: Photo by [Ricardo Gomez Angel](https://unsplash.com/@rgaleriacom?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Ricardo Gomez Angel](https://unsplash.com/@rgaleriacom?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: SageMaker Endpoint Deployment
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker 端点部署
- en: A quick and easy guide for creating an AWS SageMaker endpoint for your model
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速简便的 AWS SageMaker 端点创建指南
- en: '[](https://hai-rozen.medium.com/?source=post_page-----6d2540226428--------------------------------)[![Hai
    Rozencwajg](../Images/8812d8935fe505ef26b58a8ec739a06f.png)](https://hai-rozen.medium.com/?source=post_page-----6d2540226428--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6d2540226428--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6d2540226428--------------------------------)
    [Hai Rozencwajg](https://hai-rozen.medium.com/?source=post_page-----6d2540226428--------------------------------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://hai-rozen.medium.com/?source=post_page-----6d2540226428--------------------------------)[![Hai
    Rozencwajg](../Images/8812d8935fe505ef26b58a8ec739a06f.png)](https://hai-rozen.medium.com/?source=post_page-----6d2540226428--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6d2540226428--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6d2540226428--------------------------------)
    [Hai Rozencwajg](https://hai-rozen.medium.com/?source=post_page-----6d2540226428--------------------------------)'
- en: ·
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5921283ee0f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428&user=Hai+Rozencwajg&userId=5921283ee0f1&source=post_page-5921283ee0f1----6d2540226428---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6d2540226428--------------------------------)
    ·10 min read·Dec 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6d2540226428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428&user=Hai+Rozencwajg&userId=5921283ee0f1&source=-----6d2540226428---------------------clap_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5921283ee0f1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428&user=Hai+Rozencwajg&userId=5921283ee0f1&source=post_page-5921283ee0f1----6d2540226428---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6d2540226428--------------------------------)
    · 10 分钟阅读 · 2023年12月8日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6d2540226428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428&user=Hai+Rozencwajg&userId=5921283ee0f1&source=-----6d2540226428---------------------clap_footer-----------)'
- en: --
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d2540226428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428&source=-----6d2540226428---------------------bookmark_footer-----------)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d2540226428&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploy-a-custom-ml-model-as-a-sagemaker-endpoint-6d2540226428&source=-----6d2540226428---------------------bookmark_footer-----------)'
- en: Developing a machine learning (ML) model involves key steps, from data collection
    to model deployment. After refining algorithms and ensuring performance through
    testing, the final crucial step is deployment. This phase transforms innovation
    into utility, allowing others to benefit from the model’s predictive capabilities.
    The deployed ML model bridges the gap between development and real-world impact,
    providing tangible benefits to users and stakeholders.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 开发机器学习（ML）模型涉及关键步骤，从数据收集到模型部署。在通过测试优化算法并确保性能后，最终的关键步骤是部署。这个阶段将创新转化为实用性，使他人能够从模型的预测能力中受益。部署的
    ML 模型弥合了开发和现实世界影响之间的差距，为用户和利益相关者提供了切实的好处。
- en: This guide covers the basic steps required to develop a custom ML as a SageMaker
    endpoint. At this point, I assume that you already have a working model and wish
    to expose it to the rest of the world via an endpoint. The guide will work you
    through deploying a PyTorch-based model that aims to predict anomalies in video
    clips. The model, aka **AI VAD**, is based on the paper [“Attribute-based Representations
    for Accurate and Interpretable Video Anomaly Detection”](https://arxiv.org/pdf/2212.00789.pdf),
    and its implementation of it can be found in the [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    GitHub repository by [OpenVINO](https://docs.openvino.ai/). To read more about
    this interesting approach, please scroll down to the end of this blog to the Appendix
    section.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本指南涵盖了将自定义 ML 作为 SageMaker 端点开发所需的基本步骤。在这一点上，我假设你已经有一个工作模型，并希望通过端点将其公开给其他人。该指南将引导你部署一个基于
    PyTorch 的模型，旨在预测视频片段中的异常。该模型，也称为**AI VAD**，基于论文[《基于属性的准确且可解释的视频异常检测表示》](https://arxiv.org/pdf/2212.00789.pdf)，其实现可以在
    [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    GitHub 仓库中找到，仓库由 [OpenVINO](https://docs.openvino.ai/) 提供。要了解更多有关这种有趣方法的信息，请滚动到本博客的末尾，查看附录部分。
- en: At this point, I want to emphasize that in this case, we can’t use the [PyTorchModel](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html#pytorch-model)
    abstraction specifically built for deploying PyTorch models for two reasons. The
    first reason is that we have the [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    package as an additional dependency that is not included in the pre-built PyTorch
    Sagemaker image. The second reason is that the model requires additional information
    that was learned during the training step which is not part of the PyTorch model’s
    weights.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我想强调的是，在这种情况下，我们不能使用专门为部署 PyTorch 模型构建的 [PyTorchModel](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html#pytorch-model)
    抽象，原因有两个。第一个原因是我们有 [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    包作为额外的依赖项，而该依赖项不包含在预构建的 PyTorch SageMaker 镜像中。第二个原因是模型需要在训练步骤中学到的额外信息，而这些信息不是
    PyTorch 模型权重的一部分。
- en: 'Below are the steps to achieve this goal:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一目标的步骤如下：
- en: Write the Sagemaker model serving script
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写 SageMaker 模型服务脚本
- en: Upload the Model to S3
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型上传到 S3
- en: Upload a custom Docker image to AWS ECR
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将自定义 Docker 镜像上传到 AWS ECR
- en: Create a Model in SageMaker
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 SageMaker 中创建模型
- en: Create an Endpoint Configuration
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建端点配置
- en: Create an Endpoint
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建端点
- en: Invoke the Endpoint
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用端点
- en: Write the Sagemaker model serving script
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写 SageMaker 模型服务脚本
- en: The Sagemaker model serving script (`inference.py`) is an important component
    when creating a Sagemaker model. It bridges between machine learning models and
    real-world data. Essentially, it processes incoming requests, runs the model predictions,
    and returns the results. Thus, influencing an application’s decision-making process.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 模型服务脚本（`inference.py`）是创建 SageMaker 模型的重要组成部分。它在机器学习模型和现实数据之间架起桥梁。本质上，它处理传入请求，运行模型预测，并返回结果，从而影响应用程序的决策过程。
- en: The `inference.py` script is composed of several key methods, each serving a
    unique purpose, collectively facilitating the model serving process. Below I listed
    the four main ones.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`inference.py` 脚本由几个关键方法组成，每个方法都具有独特的功能，共同促进模型服务过程。下面列出了四个主要方法。'
- en: The `model_fn` method is tasked with loading the trained model. It reads the
    model artifacts that have been saved and returns a model object that can be used
    for predictions. This method is called only once when the SageMaker model server
    is started.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`model_fn` 方法负责加载训练好的模型。它读取已保存的模型工件，并返回一个可以用于预测的模型对象。此方法仅在启动 SageMaker 模型服务器时调用一次。'
- en: The `input_fn` method method takes request data and formats it into a form suitable
    for making predictions. For example, in the code below this function formats the
    data differently based on the source of the data (image bytes or list of S3 URIs)
    and whether the list of frames should be considered as one video clip.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`input_fn` 方法将请求数据格式化为适合进行预测的形式。例如，在下面的代码中，这个函数根据数据来源（图像字节或 S3 URI 列表）以及帧列表是否应视为一个视频片段来格式化数据。'
- en: The `predict_fn` method takes the formatted request data and performs inference
    against the loaded model.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`predict_fn` 方法接受格式化的请求数据并对加载的模型进行推断。'
- en: Finally, the `output_fn` method is used. It takes the prediction result and
    formats it into a response message. For example, pack it as a JSON object.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用 `output_fn` 方法。它将预测结果格式化为响应消息。例如，将其打包为 JSON 对象。
- en: The code for the Sagemaker model serving script can be found below.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Sagemaker 模型服务脚本的代码可以在下面找到。
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: P.S. It is strongly recommended to test the model serving script before moving
    forward to the next step. This can be done easily by simulating the invocation
    pipeline as shown in the code below.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: P.S. 强烈建议在进入下一步之前测试模型服务脚本。这可以通过模拟调用管道轻松完成，如下面的代码所示。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Upload the Model to S3
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将模型上传到 S3
- en: 'To create a SageMaker endpoint that loads the AI VAD PyTorch model in the exact
    same state, we need the following files:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个 SageMaker 端点，使其加载 AI VAD PyTorch 模型到完全相同的状态，我们需要以下文件：
- en: AI VAD PyTorch model’s weights (aka state_dict)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI VAD PyTorch 模型的权重（即 state_dict）
- en: Density estimator memory banks (which are not part of the model’s weights)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密度估计器内存库（不属于模型的权重）
- en: A config file with the hyperparameters of the PyTorch model
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含 PyTorch 模型超参数的配置文件
- en: A Sagemaker model serving script (`inference.py`)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sagemaker 模型服务脚本 (`inference.py`)
- en: The code below demonstrates how to organize all the required files in one directory.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了如何将所有所需的文件组织在一个目录中。
- en: P.S., I overrode the built-in PyTorch ModelCheckpoint callback to ensure those
    memory banks are being saved as part of the checkpoint saving (implementation
    can be found [here](https://github.com/hairozen/anomalib/blob/ai-vad-inference-improvements/src/anomalib/utils/callbacks/ai_vad/ai_vad_model_checkpoint.py)).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: P.S. 我重写了内置的 PyTorch ModelCheckpoint 回调，以确保这些内存库作为检查点保存的一部分（实现可以在 [这里](https://github.com/hairozen/anomalib/blob/ai-vad-inference-improvements/src/anomalib/utils/callbacks/ai_vad/ai_vad_model_checkpoint.py)
    找到）。
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then, the four files were zipped together to create the `tar.gz` using the command
    below.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用下面的命令将这四个文件压缩在一起，生成 `tar.gz` 文件。
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Lastly, the file was uploaded to S3 using boto3.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用 boto3 将文件上传到 S3。
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Upload a custom Docker image to AWS ECR
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将自定义 Docker 镜像上传到 AWS ECR
- en: As mentioned above, since we have an additional dependency that is not included
    in the pre-built PyTorch Sagemaker image (i.e., [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    package), we created a new Docker image for that purpose. Before building the
    custom Docker image, authentication to the Amazon ECR repository is required.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，由于我们有一个不包含在预构建 PyTorch Sagemaker 镜像中的额外依赖项（即 [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    包），我们为此目的创建了一个新的 Docker 镜像。在构建自定义 Docker 镜像之前，需要进行 Amazon ECR 存储库认证。
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The Dockerfile can be found below and the different Docker registry paths can
    be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg-ecr-paths/sagemaker-algo-docker-registry-paths.html).
    Make sure to select the right registry path based on the model’s needs (CPU/GPU,
    Python version, etc.) and your AWS region. For example, if the region is `us-east-1`
    the full Docker registry path should look similar to this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile 可以在下面找到，不同的 Docker 注册表路径可以在 [这里](https://docs.aws.amazon.com/sagemaker/latest/dg-ecr-paths/sagemaker-algo-docker-registry-paths.html)
    找到。确保根据模型的需求（CPU/GPU，Python 版本等）和您的 AWS 区域选择正确的注册表路径。例如，如果区域是 `us-east-1`，则完整的
    Docker 注册表路径应类似于：
- en: '`763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:2.0.0-gpu-py310`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:2.0.0-gpu-py310`'
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, we can run the classic Docker build command to build this custom image.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行经典的 Docker 构建命令来构建这个自定义镜像。
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The next step is to create the AWS ECR repository for the new image we built,
    tag it, and push the image to the AWS ECR repository.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是为我们构建的新镜像创建 AWS ECR 存储库，对其进行标记，然后将镜像推送到 AWS ECR 存储库。
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Create a Model in SageMaker
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 SageMaker 中创建一个模型
- en: This step is pretty straightforward. Code below.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步非常简单。代码如下。
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Create an Endpoint Configuration
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建端点配置
- en: The next step is to create an endpoint configuration. Below you can find a basic
    one.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个端点配置。下面是一个基本的示例。
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Create an Endpoint
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个端点
- en: Now we are ready to create the endpoint itself.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好创建端点本身了。
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Please note that it might take a few minutes till the status of the endpoint
    changes from “Creating” to “InService”. The current status can be checked as shown
    below.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，端点状态可能需要几分钟才能从“创建中”变为“服务中”。可以通过下面所示的方式检查当前状态。
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Invoke the Endpoint
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调用端点
- en: The money time has come. Now it’s time to invoke the endpoint to test everything
    works as expected.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 关键时刻到了。现在是调用端点测试一切是否按预期工作的时候。
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'So, this is a nice check but you should take into account that the `predictor.predict`
    function does not run the full invocation pipeline from the SageMaker serving
    script that includes:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这是一项很好的检查，但请注意，`predictor.predict` 函数并不会运行完整的调用管道，这个管道来自 SageMaker 服务脚本，其中包括：
- en: '`output_fn(predict_fn(input_fn(input_data, model_fn(model_dir)),accept)`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`output_fn(predict_fn(input_fn(input_data, model_fn(model_dir)),accept)`'
- en: To test it as well, let’s invoke the model using an API call.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试它，我们可以通过 API 调用来调用模型。
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Using the great visualization [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    provides, we can draw the boxes and their labels for a given frame from the UCSDped2
    dataset.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    提供的出色可视化，我们可以绘制给定 UCSDped2 数据集中某帧的框和标签。
- en: '![](../Images/d149445b2ddcf4c8112e7bede44c60a7.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d149445b2ddcf4c8112e7bede44c60a7.png)'
- en: Image by the author. The image was generated using the [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    package based on the [UCSD Anomaly Detection Dataset](http://www.svcl.ucsd.edu/projects/anomaly/dataset.htm).The
    green boxes indicate there is no anomaly with how those pedestrians walk whereas
    the red box, for the biker, indicates an anomaly probably due to the velocity
    and pose features of the AI VAD model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。该图像是使用 [anomalib](https://github.com/openvinotoolkit/anomalib/tree/main/src/anomalib/models/ai_vad)
    包生成的，基于 [UCSD 异常检测数据集](http://www.svcl.ucsd.edu/projects/anomaly/dataset.htm)。绿色框表示那些行人的步态没有异常，而红色框表示的骑车者则可能由于
    AI VAD 模型的速度和姿态特征而存在异常。
- en: Conclusion
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: OK, let’s quickly wrap up what we covered here. Deploying a SageMaker model
    for serving requires a series of steps.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，让我们快速回顾一下我们在这里讨论的内容。部署 SageMaker 模型以进行服务需要一系列步骤。
- en: First, the Sagemaker model serving script must be written to define the functionality
    and behavior of the model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，必须编写 SageMaker 模型服务脚本，以定义模型的功能和行为。
- en: The model is then uploaded to Amazon S3 for storage and retrieval.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将模型上传到 Amazon S3 进行存储和检索。
- en: Additionally, a custom Docker image is uploaded to the AWS Elastic Container
    Registry (ECR) to containerize the model and its dependencies.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，定制的 Docker 镜像被上传到 AWS Elastic Container Registry (ECR)，以容器化模型及其依赖项。
- en: The next step involves creating a model in SageMaker, which associates the model
    artifacts stored in S3 with the Docker image stored in ECR.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个 SageMaker 模型，该模型将存储在 S3 中的模型工件与存储在 ECR 中的 Docker 镜像关联起来。
- en: An endpoint configuration is then created, defining the number and type of instances
    to use for hosting the model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然后创建一个端点配置，定义用于托管模型的实例数量和类型。
- en: Finally, an endpoint is created to establish a live connection between the deployed
    model and client applications, allowing them to invoke the endpoint and make real-time
    predictions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建一个端点以在部署的模型和客户端应用程序之间建立实时连接，允许它们调用端点并进行实时预测。
- en: Through these steps, deploying a SageMaker model becomes a streamlined process
    that ensures efficient and reliable model serving.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤，部署 SageMaker 模型成为了一个简化的过程，确保了高效和可靠的模型服务。
- en: Appendix
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: The [Attribute-based Representations for Accurate and Interpretable Video Anomaly
    Detection](https://arxiv.org/pdf/2212.00789.pdf) paper published in 2023 by Reiss
    et al. that proposes a simple but highly effective method for video anomaly detection
    (VAD) using attribute-based representations.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 2023 年由 Reiss 等人发布的论文 [基于属性的准确且可解释的视频异常检测](https://arxiv.org/pdf/2212.00789.pdf)，提出了一种使用基于属性的表示进行视频异常检测
    (VAD) 的简单但极其有效的方法。
- en: The paper argues that traditional VAD methods, which often rely on deep learning,
    are often difficult to interpret, making it difficult for users to understand
    why the system is flagging certain frames or objects as anomalous.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 论文认为，传统的 VAD 方法通常依赖深度学习，这些方法往往难以解释，使得用户难以理解系统为何将某些帧或对象标记为异常。
- en: To address this issue, the authors propose a method that represents each object
    in a video by its velocity, pose, and depth. These attributes are easy to understand
    and interpret, and they can be used to compute anomaly scores using a density-based
    approach.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，作者提出了一种方法，通过速度、姿态和深度来表示视频中的每个对象。这些属性易于理解和解释，并且可以使用基于密度的方法来计算异常分数。
- en: The paper shows that this simple representation is sufficient to achieve state-of-the-art
    performance on several challenging VAD datasets, including ShanghaiTech, the largest
    and most complex VAD dataset.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 论文表明，这种简单的表示方法足以在多个具有挑战性的 VAD 数据集上实现最先进的性能，包括上海科技大学的数据集，这是最大的和最复杂的 VAD 数据集。
- en: In addition to being accurate, the authors also show that their method is interpretable.
    For example, they can provide users with a list of the objects in a video that
    are contributing most to its anomaly score, along with their velocity, pose, and
    deep information. This can help users to understand why the system is flagging
    the video as anomalous.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 除了准确之外，作者还展示了他们的方法具有可解释性。例如，他们可以向用户提供视频中对异常评分贡献最大的对象的列表，以及这些对象的速度、姿态和深度信息。这可以帮助用户理解系统为何将视频标记为异常。
- en: Overall, this paper is a significant contribution to the field of VAD. It proposes
    a simple, accurate, and interpretable method for VAD that can be used in a variety
    of applications.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这篇论文是 VAD 领域的重要贡献。它提出了一种简单、准确且可解释的 VAD 方法，可以用于各种应用。
