- en: Prompt Engineering Could Be the Hottest Programming Language of 2024 — Here’s
    Why
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程可能是2024年最热门的编程语言——原因如下
- en: 原文：[https://towardsdatascience.com/prompt-engineering-could-be-the-hottest-programming-language-of-2024-heres-why-a9ccf4ba8d49](https://towardsdatascience.com/prompt-engineering-could-be-the-hottest-programming-language-of-2024-heres-why-a9ccf4ba8d49)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/prompt-engineering-could-be-the-hottest-programming-language-of-2024-heres-why-a9ccf4ba8d49](https://towardsdatascience.com/prompt-engineering-could-be-the-hottest-programming-language-of-2024-heres-why-a9ccf4ba8d49)
- en: Large Language Models are the next generation of Operating Systems
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型是下一代操作系统
- en: '[](https://nabil-alouani.medium.com/?source=post_page-----a9ccf4ba8d49--------------------------------)[![Nabil
    Alouani](../Images/8ceea018e9b15413d318bfb710bb0011.png)](https://nabil-alouani.medium.com/?source=post_page-----a9ccf4ba8d49--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a9ccf4ba8d49--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a9ccf4ba8d49--------------------------------)
    [Nabil Alouani](https://nabil-alouani.medium.com/?source=post_page-----a9ccf4ba8d49--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://nabil-alouani.medium.com/?source=post_page-----a9ccf4ba8d49--------------------------------)[![Nabil
    Alouani](../Images/8ceea018e9b15413d318bfb710bb0011.png)](https://nabil-alouani.medium.com/?source=post_page-----a9ccf4ba8d49--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a9ccf4ba8d49--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a9ccf4ba8d49--------------------------------)
    [Nabil Alouani](https://nabil-alouani.medium.com/?source=post_page-----a9ccf4ba8d49--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a9ccf4ba8d49--------------------------------)
    ·16 min read·Dec 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a9ccf4ba8d49--------------------------------)
    ·阅读时间 16 分钟·2023年12月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8914fb851cbf6bd3ef466345eacf0eb1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8914fb851cbf6bd3ef466345eacf0eb1.png)'
- en: Unless indicated otherwise, all the images are generated by the author using
    Midjourney, DALL-E, and Canva.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者使用 Midjourney、DALL-E 和 Canva 生成。
- en: “I don’t think it’s accurate to think of Large Language Models as chatbots or
    some kind of word generators,” [Andrej Karpathy](https://karpathy.ai/), one of
    OpenAI’s founding members, said. “It’s a lot more correct to think about [them]
    as **the kernel process of an emerging Operating System**.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “我不认为把大型语言模型看作聊天机器人或某种文字生成器是准确的，” OpenAI 创始成员之一的[Andrej Karpathy](https://karpathy.ai/)说。“更正确的想法是把它们看作**新兴操作系统的内核进程**。”
- en: Wait, but what the heck does that mean?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 等等，但那到底是什么意思？
- en: Large Language Models (LLMs) will gradually become the interface between you
    and computer systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）将逐渐成为你与计算机系统之间的界面。
- en: Right now, you’re holding a device that has some computing power inside it,
    but you can’t directly access that power. Your interaction is mediated by an Operating
    System (such as Windows, Mac OS, and Android,), which transforms a collection
    of chips and circuits into a user-friendly interface.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你手上拿着一个拥有一些计算能力的设备，但你不能直接访问这些能力。你的交互由操作系统（如 Windows、Mac OS 和 Android）介导，它将一组芯片和电路转换成一个用户友好的界面。
- en: Your Operating System (OS) allows you to perform a wide range of activities
    (like reading some bald dude’s article) through a variety of apps running on top
    of it. Each app has its own User Interface (UI) and its own set of tasks it can
    accomplish. You jump from one app to another, one UI to another, depending on
    what you need to do.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你的操作系统（OS）允许你通过一系列运行在其上的应用程序执行各种活动（如阅读某个秃头家的文章）。每个应用程序都有自己的用户界面（UI）和可以完成的任务。你根据需要在不同应用程序和用户界面之间跳转。
- en: '![](../Images/702445b34dcdd1c17bfd8c0e23d264c3.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/702445b34dcdd1c17bfd8c0e23d264c3.png)'
- en: Tomorrow, you’ll have a single UI to do everything from writing an annual business
    report to building a new app from scratch. The said UI will be a chatbox or a
    “context window” inside which you can submit instructions in natural language
    — and that’s where Prompt Engineering comes into play.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 明天，你将拥有一个单一的用户界面来完成从编写年度业务报告到从头构建新应用的所有任务。这个用户界面将是一个聊天框或一个“上下文窗口”，你可以在其中用自然语言提交指令——这就是提示工程发挥作用的地方。
- en: Prompt Engineering is a fancy way to say “Write better and better instructions
    for your AI model until it does exactly what you want.” Except, it’s not merely
    wordplay; it’s the blueprint for the future of programming.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt Engineering 是一种花哨的说法，用来表示“为你的 AI 模型编写越来越好的指令，直到它完全按照你的要求执行。”不过，这不仅仅是文字游戏；它是未来编程的蓝图。
- en: Programming as a (cheap) commodity
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程作为（便宜的）商品
- en: “Programming refers to a technological process for telling a computer which
    tasks to perform in order to solve problems,” Coursera [wrote on their website](https://www.coursera.org/articles/what-is-programming).
    “You can think of programming as a collaboration between humans and computers,
    in which humans create instructions for a computer to follow (code) in a language
    computers can understand.”
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: “编程指的是一种技术过程，用于告诉计算机执行哪些任务以解决问题，”Coursera [在他们的网站上写道](https://www.coursera.org/articles/what-is-programming)。“你可以将编程看作是人类与计算机之间的协作，其中人类创建计算机可以理解的指令（代码）供计算机遵循。”
- en: 'In other words, programming turns computing power into a commodity: a resource
    you can use to accomplish your goals. Prompt Engineering is a tool that turns
    programming itself into a commodity. You submit an instruction to an LLM and it
    writes the code for you.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，编程将计算能力转变为一种商品：你可以用来实现目标的资源。Prompt Engineering 是一种将编程本身转变为商品的工具。你提交一个指令给
    LLM，它会为你编写代码。
- en: Say you want to analyze a tiny data set for a work project. Normally, you’d
    start by gathering hundreds of CSV files scattered across your company’s cloud.
    You then double-click on Jupyter Notebook and type in a few lines of Python to
    compile your inputs into a single data frame.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，你想为一个工作项目分析一个小数据集。通常，你会先从公司云端收集数百个 CSV 文件。然后，你双击 Jupyter Notebook，输入几行 Python
    代码，将输入数据编译成一个数据框。
- en: 'From there, you sprinkle some Data Science magic, run a dozen iterations, and
    congratulations: you got yourself a collection of elegant tables, fancy graphs,
    and data-driven predictions. Your last step is to compress your six weeks of work
    into 42 beautiful slides displayed on yet another app called Microsoft PowerPoint.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，你施加一些数据科学的魔法，运行几轮迭代，恭喜你：你获得了一系列优雅的表格、花哨的图表和数据驱动的预测。你最后一步是将六周的工作压缩成 42
    张漂亮的幻灯片，展示在另一个叫做 Microsoft PowerPoint 的应用程序上。
- en: '![](../Images/234a6b82ed7ee30a81061e3d3691a201.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/234a6b82ed7ee30a81061e3d3691a201.png)'
- en: Your typical Data Scientist on a random Tuesday.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你典型的数据科学家在一个随意的星期二。
- en: You just combined off-the-shelf apps with code you wrote yourself to build a
    program that runs a specific data analysis. But what if instead, all you had to
    do was to write a few instructions in plain English?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚将现成的应用程序与自己编写的代码结合起来，构建了一个运行特定数据分析的程序。但如果你只需用简单的英语写几条指令呢？
- en: “Hey AI buddy,” you’d say. “Here’s a messy dataset about the deliveries our
    company made across Paris in the last five years. Please clean up the mess and
    run a clustering algorithm. Display a heat map and zoom on high-density spots.
    Throw in a two-year projection and use the results to optimize the daily itinerary
    of our delivery fleet. When you’re done with math, generate a report with clear
    graphs and succinct comments. And take your time! I’ll be gone for at least six
    hours.”
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: “嘿，AI 伙伴，”你会说，“这是一个关于我们公司在过去五年中在巴黎进行的交付的混乱数据集。请清理这些数据，运行一个聚类算法。展示热力图，并放大高密度区域。加上两年的预测，并利用这些结果优化我们配送车队的每日行程。当你完成数学部分时，生成一个包含清晰图表和简洁评论的报告。慢慢来！我会离开至少六小时。”
- en: Every time you write such a prompt, you’re effectively programming an app that
    solves a specific problem.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 每次你编写这样的提示时，你实际上是在编程一个解决特定问题的应用程序。
- en: It’s almost as Coursera described it — you collaborate with a computer to achieve
    a goal. The only difference is instead of code, you’ll use plain English. Okay,
    the prompt may be a few yards shy of the finish line, but in principle, that’s
    what your interactions with future LLMs will look like.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎就像 Coursera 描述的那样——你与计算机协作以实现目标。唯一的区别是，你将使用简单的英语，而不是代码。好吧，提示可能离终点线还有几步之遥，但原则上，这就是你与未来
    LLM 互动的方式。
- en: For a more concrete illustration, consider the famous demo below, where GPT-4
    turned a hand-drawn sketch into functional HTML code.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以更具体的例子来看，考虑下面的著名演示，其中 GPT-4 将手绘草图转换为功能性 HTML 代码。
- en: Prompts are all you need
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示就是你所需要的一切
- en: It’ll be a while before we can replace data scientists, web developers, and
    software engineers with a bunch of clever prompts. In the meantime, we’ll augment
    them with AI assistants that make their work more efficient — and each one of
    these AI assistants will be programmed in plain English.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够用一堆聪明的提示替代数据科学家、网页开发者和软件工程师之前，还需要一段时间。在此期间，我们将通过AI助手来增强他们的工作效率——这些AI助手将用普通英语编程。
- en: 'Instead of using a bundle of complementary apps like Google Workspace, Jupyter
    Notebook, and Microsoft PowerPoint, you’ll put together an assistant called “StatSniffer:
    your personal Data Science expert.”'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '你将不再使用如 Google Workspace、Jupyter Notebook 和 Microsoft PowerPoint 等一系列互补应用，而是创建一个名为“StatSniffer:
    你的个人数据科学专家”的助手。'
- en: '![](../Images/34aa9d60a397b4baeaa48b9d8c8ab62e.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34aa9d60a397b4baeaa48b9d8c8ab62e.png)'
- en: Much like the current ChatGPT PLUS, your personalized StatSniffer will be an
    LLM hooked to a series of tools that give it extra capabilities like browsing
    files, running code, and generating graphs. You can also infuse StatSniffer with
    top-performing methodologies by giving it access to research papers, case studies,
    and academic textbooks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于当前的 ChatGPT PLUS，你的个性化 StatSniffer 将是一个连接到一系列工具的LLM，这些工具赋予它额外的能力，比如浏览文件、运行代码和生成图表。你还可以通过让它访问研究论文、案例研究和学术教科书来注入顶级的方法论。
- en: OpenAI is already experimenting with personalized AI assistants through the
    GPT store where you can build assistants called GPTs. The current GPTs are clunky,
    however. For instance, they’re vulnerable to simple jailbreaks that make them
    reveal their “core instructions.” GPTs also tend to revert to their default mode
    (GPT-4) after a few exchanges with the users.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 已经通过 GPT 商店实验个性化AI助手，你可以构建名为 GPT 的助手。然而，目前的 GPTs 确实显得笨拙。例如，它们容易受到简单的破解，使其暴露“核心指令”。GPTs
    也往往在与用户交流几次后恢复到默认模式（GPT-4）。
- en: This is not a surprise because the tech is still in its infancy. As AI research
    advances, and open-source models get better, the ecosystem of AI assistants will
    evolve to cover more capabilities with increased reliability. Speaking of which,
    there’s a long way to go.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不令人惊讶，因为技术仍处于初期阶段。随着AI研究的进展和开源模型的改善，AI助手的生态系统将演变为覆盖更多功能，并提高可靠性。说到这，还有很长的路要走。
- en: Problems like planning and multi-step reasoning remain unsolved in part because
    [LLMs are still lagging behind humans](https://nabilalouani.substack.com/p/chatgpt-hype-is-proof-nobody-really)
    (and even cats) when it comes to understanding physical reality.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 像规划和多步骤推理等问题仍未解决，部分原因是 [LLMs在理解物理现实方面仍落后于人类](https://nabilalouani.substack.com/p/chatgpt-hype-is-proof-nobody-really)（甚至是猫）。
- en: This doesn’t mean people will hold their breath for fully autonomous assistants
    versed in Quantum Gravity to leverage existing AI models. Even the so-called ‘dumb’
    LLMs can crank up your efficiency by a factor of two. Here’s an excerpt from a
    [McKinsey study on](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai#/)
    how developers are using LLMs to accelerate their work.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着人们会期待完全自主的助手掌握量子引力来利用现有的AI模型。即便是所谓的‘愚蠢’ LLMs，也能将你的效率提高一倍。以下是 [麦肯锡关于](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai#/)
    开发人员如何使用LLMs加速工作的研究摘录。
- en: “Our latest empirical research finds generative AI–based tools delivering impressive
    **speed gains** for many common developer tasks. **Documenting code** functionality
    for maintainability (which considers how easily code can be improved) can be **completed
    in** **half the time**, **writing new code in nearly half the time**, and **optimizing
    existing code** (called code refactoring) in **nearly two-thirds the time**.”
    [Emphasis by the author].
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: “我们最新的实证研究发现，基于生成AI的工具在许多常见开发任务中提供了令人印象深刻的**速度提升**。**记录代码**功能以便于维护（考虑到代码如何容易改进）可以在**一半的时间**内**完成**，**编写新代码几乎在一半的时间**内完成，**优化现有代码**（称为代码重构）则**在近三分之二的时间**内完成。”
    [作者强调]。
- en: “For developers to effectively use the technology to augment their daily work,
    they will likely need a combination of training and coaching,” the McKinsey research
    team explained. “Initial training should include best practices and hands-on exercises
    for inputting natural-language prompts into the tools, often called prompt engineering.”
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: “为了让开发人员有效地利用这些技术来增强日常工作，他们可能需要培训和指导的结合，”麦肯锡研究团队解释说。“初始培训应包括最佳实践和将自然语言提示输入工具的动手练习，通常称为提示工程。”
- en: And this is not only true for software-related tasks. The same pattern extends
    to a wider range of corporate activities as well. For instance, researchers at
    [Harvard Business School](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700)
    (HBS) conducted a [study](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700)
    to assess the impact of equipping employees from Boston Consulting Group (BCG)
    with Generative AI tools.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅对软件相关任务是正确的。这种模式也扩展到更广泛的公司活动中。例如，[哈佛商学院](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700)的研究人员进行了一项[研究](https://www.hbs.edu/faculty/Pages/item.aspx?num=64700)，评估了为波士顿咨询集团（BCG）的员工配备生成AI工具的影响。
- en: “For each one of a set of 18 realistic consulting tasks within the frontier
    of AI capabilities, consultants using AI were significantly more productive (they
    completed 12.2% more tasks on average, and completed tasks 25.1% more quickly),
    and produced significantly higher quality results (more than 40% higher quality
    compared to a control group),” HBS researchers wrote.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: “在AI能力前沿的一组18个现实咨询任务中，使用AI的顾问生产力显著提高（他们平均完成的任务多出12.2%，任务完成速度提高了25.1%），并且产生了显著更高质量的结果（与对照组相比质量高出40%以上），”HBS研究人员写道。
- en: This is a 2-minute summary of the study by [Rajiv Shah](https://www.linkedin.com/in/rajistics/overlay/about-this-profile/),
    a Machine Learning Engineer and YouTuber.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[Rajiv Shah](https://www.linkedin.com/in/rajistics/overlay/about-this-profile/)的研究总结，Rajiv
    Shah是一位机器学习工程师和YouTuber。
- en: 'These studies feed into the new cliché of “AI won’t replace you, but someone
    who uses AI will.” Perhaps a fancier formulation could be: “AI won’t replace you,
    but a Prompt Engineer will.”'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些研究为新的陈词滥调提供了支持：“AI不会取代你，但使用AI的人会。”也许更花哨的表述是：“AI不会取代你，但提示工程师会。”
- en: The bigger the “frontier of AI” gets (meaning tasks that AI models can perform
    with high accuracy), the more problems we’ll be able to solve using prompts. This
    brings us to a widespread fallacy that suggests more capable AI models require
    less Prompt Engineering skills.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: “‘AI前沿’越大（意味着AI模型可以高准确度执行的任务越多），我们通过提示可以解决的问题就越多。”这带我们到一个普遍的谬论，认为更强大的AI模型需要更少的提示工程技能。
- en: “Is Prompt Engineering dead?” No, it’s State of the Art
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: “提示工程死了吗？”不，它是最前沿的技术。
- en: One way to see the relationship between a Large Language Model and Prompt Engineering
    is to picture the former as a multiverse and the latter as a pointer — yes, like
    a laser pointer.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 看到大型语言模型和提示工程之间的关系的一种方式是把前者想象成一个多元宇宙，后者则像一个指示器——没错，就像一个激光指示器。
- en: When you ask an LLM a question, it considers a multiverse of relevant documents.
    Inside each document, there’s a cluster of possible answers, and each possible
    answer is a chain of probabilities.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当你向LLM提问时，它会考虑一个相关文档的多元宇宙。在每个文档内，有一组可能的答案，每个可能的答案都是一系列概率。
- en: Your prompt points toward the universe that’s most likely to contain the desired
    answer — and from there, your model tries to navigate its way to that desired
    answer, one word at a time.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你的提示指向最有可能包含所需答案的宇宙——然后，你的模型尝试一步步地导航到那个所需的答案。
- en: Each time the model predicts a token, it eliminates hundreds of alternative
    paths and continues to narrow down its options until all that’s left is a series
    of words that constitute “the destination.”
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 每当模型预测一个标记时，它会排除数百条替代路径，并继续缩小选项，直到剩下的只有一系列构成“目的地”的词。
- en: '![](../Images/262ca56dd5ecd01082e543569bd55375.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/262ca56dd5ecd01082e543569bd55375.png)'
- en: Your LLM navigating multiverses of possible answers (more like “navigating mushy
    planets” here, but you get the idea).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你的LLM在多元宇宙中导航可能的答案（这里更像是“在模糊的星球上导航”，但你明白我的意思）。
- en: This destination is never the same, however. Even if you use the exact same
    prompt, you almost never reach the exact same address. Instead, you’ll land somewhere
    in the “neighborhood” of the most relevant answers.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个目的地从未相同。即使你使用完全相同的提示，你几乎不会达到完全相同的地址。相反，你会在“邻域”中找到最相关的答案。
- en: 'Here’s a [more technical description](https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering)
    by François Chollet, a software engineer and AI researcher who currently works
    at Google:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一篇[更技术性的描述](https://fchollet.substack.com/p/how-i-think-about-llm-prompt-engineering)，作者是**弗朗索瓦·肖利**，他是一位软件工程师和AI研究员，目前在谷歌工作：
- en: If a LLM is like a database of millions of vector programs, then a prompt is
    like a search query in that database […] this “program database” is continuous
    and interpolative — it’s not a discrete set of programs.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果一个LLM就像是一个包含数百万个向量程序的数据库，那么提示就像是在那个数据库中的搜索查询[...] 这个“程序数据库”是连续的和插值的——它不是一个离散的程序集合。
- en: ''
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This means that a slightly different prompt, like “Lyrically rephrase this text
    in the style of x” would still have pointed to a very similar location in program
    space, resulting in a program that would behave pretty closely but not quite identically.
    […]
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这意味着，像“以x风格重新措辞此文本”这样略有不同的提示仍然会指向程序空间中非常相似的位置，导致生成的程序行为非常接近但不完全相同。[...]
- en: ''
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Prompt engineering is the process of searching through program space to find
    the program that empirically seems to perform best on your target task.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提示工程是搜索程序空间以找到在你的目标任务上表现最佳的程序的过程。
- en: As Chollet pointed out, your prompt’s goal is to call the right program for
    the task you want to accomplish. The reasoning trap many people fall for is to
    believe future LLMs should be able to predict which program we want them to run,
    even when we give them vague assignments.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如**肖利**指出的，你的提示目标是调用适合你要完成的任务的正确程序。许多人陷入的推理陷阱是相信未来的LLMs应该能够预测我们希望它们运行哪个程序，即使我们给出的是模糊的任务。
- en: Except, as with humans, even if you hire the most technically capable engineer,
    she won’t be able to read your mind. You have to explain exactly what you want,
    otherwise, you’re wasting time and energy.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除非，就像人类一样，即使你雇佣了技术能力最强的工程师，她也无法读懂你的心思。你必须准确说明你想要的，否则你是在浪费时间和精力。
- en: Let’s say you instructed your formidable engineer to build a product, but you
    didn’t like the result. You can either change the engineer or change your instructions.
    Since you know your engineer is highly skilled, common sense suggests you opt
    for the second option.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你指示你那位杰出的工程师去开发一个产品，但你不满意结果。你可以选择更换工程师或更改你的指示。既然你知道你的工程师非常熟练，常识告诉你选择第二种选项。
- en: Similarly, if your highly capable Language Model doesn’t produce the answer
    you want, you don’t throw it away. You don’t sit around hoping the next model
    will be able to read your mind. The most reasonable and cost-effective approach
    is to improve your prompt.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，如果你高度能力的语言模型没有产生你想要的答案，你不会把它扔掉。你也不会坐等下一个模型能读懂你的心思。最合理且具成本效益的方法是改进你的提示。
- en: That’s what a research team at Microsoft did with GPT-4\. Instead of fine-tuning
    the model for a specific use case, [they used prompt engineering techniques to
    improve its performance](https://arxiv.org/abs/2311.16452).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是微软研究团队在GPT-4上所做的。与其为特定用例微调模型，[他们使用了提示工程技术来提高其性能](https://arxiv.org/abs/2311.16452)。
- en: GPT-4’s score improved by up to 9% across nine different medical benchmarks.
    As a result, the model’s accuracy surpassed 90%, outperforming models that were
    specifically fine-tuned for medical applications.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4在九个不同的医学基准测试中的分数提高了多达9%。因此，该模型的准确性超过了90%，优于专门为医学应用微调的模型。
- en: Riley Goodside is arguably the first Prompt Engineer.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**赖利·古德赛德**可以说是首位提示工程师。'
- en: Note that fine-tuning requires extra resources like hiring experts to produce
    high-quality training data and some computing resources to retrain the model.
    Sure, fine-tuning requires a fraction of computing power compared to pre-training,
    but it’s still an extra cost.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，微调需要额外的资源，比如雇佣专家来制作高质量的训练数据以及一些计算资源来重新训练模型。虽然微调所需的计算能力比预训练少，但这仍然是额外的成本。
- en: 'Plus, you need to invest the same resources every time you want to fine-tune
    your model for a new domain of expertise. In contrast, Microsoft produced a prompting
    technique that improves performance across different fields: electrical engineering,
    machine learning, philosophy, accounting, law, nursing, and clinical psychology.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每次你想为新的专业领域微调模型时，都需要投入相同的资源。相比之下，微软开发了一种提高不同领域（如电气工程、机器学习、哲学、会计、法律、护理和临床心理学）表现的提示技术。
- en: Another [example that highlights the power of prompt engineering comes from
    Anthropic](https://www.anthropic.com/index/claude-2-1-prompting). Their team enhanced
    the performance of their Claude 2.1 model by 98% in an information-retrieval evaluation,
    a feat they achieved by adding one sentence to their prompt. Just one sentence.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个[突显提示工程强大之处的例子来自Anthropic](https://www.anthropic.com/index/claude-2-1-prompting)。他们的团队通过在提示中添加一句话，将Claude
    2.1模型在信息检索评估中的表现提高了98%。仅仅一句话。
- en: Manipulating LLMs is like playing with an alien tool. The only way to figure
    out what it can do is to press its buttons in different ways. When a new version
    of this alien tool comes out, you’d expect it to have more capabilities, but also
    more buttons.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 操控LLM就像玩一个外星工具。弄清楚它能做什么的唯一办法是以不同的方式按它的按钮。当这个外星工具的新版本出来时，你会期望它有更多的功能，但也有更多的按钮。
- en: The naive approach is to think “more capable models require less prompting.”
    In reality, the more capable your model, the more features you can unlock using
    the right prompts.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 天真的方法是认为“更强大的模型需要更少的提示”。实际上，你的模型越强大，你可以通过正确的提示解锁的功能就越多。
- en: Time to shine, human agent!
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 展现风采的时候到了，人类代理！
- en: In the long term, we’ll use LLMs as Operating Systems to wield computing power
    and solve all kinds of problems. In the midterm, we’ll program AI agents to perform
    tasks we used to write code for. In both stages, we’ll use English as the main
    programming language.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，我们将使用LLM作为操作系统来运用计算能力并解决各种问题。在中期，我们将编程AI代理以执行以前需要编写代码的任务。在这两个阶段中，我们都将使用英语作为主要编程语言。
- en: Okay, but what happens now?
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，但现在发生了什么？
- en: Until AI agents catch up, it’s your time to shine. Think of yourself as a tech
    artisan who combines AI models, code, and traditional apps to tackle complex challenges.
    You’ll play Lego so to speak, and thanks to the open-source community in particular,
    you’ll have an endless supply of pieces you can combine to create innovative projects.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI代理赶上之前，正是你大展身手的时候。把自己想象成一个技术工匠，将AI模型、代码和传统应用结合起来，以应对复杂的挑战。可以说，你将玩乐高，而且特别感谢开源社区，你将拥有无尽的积木，可以组合起来创造创新项目。
- en: LLMs are special pieces of this hypothetical Lego because you’ll often end up
    with one at the center of your creations. This brings us to the two complementary
    flavors of Prompt Engineering.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LLM是这个假设的乐高积木中的特殊部分，因为你常常会发现它们在你的创作中心。这将我们引向Prompt Engineering的两个互补风格。
- en: 'See, [Prompt Engineering has two meanings](https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/):
    (1) Write high-quality natural language instructions for LLMs and (2) Write code
    on top of LLMs to improve their output using conditional prompting and other techniques.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 见，[Prompt Engineering 有两个含义](https://simonwillison.net/2023/Feb/21/in-defense-of-prompt-engineering/)：(1)
    为大型语言模型（LLM）编写高质量的自然语言指令，以及 (2) 在LLM之上编写代码，通过条件提示和其他技术来改善其输出。
- en: The second definition includes the first because, even if you wrap code around
    an LLM, you still use English to interact with it. Here’s how both of these definitions
    intertwine with LLM usage.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个定义包含了第一个，因为即使你在LLM周围包裹了代码，你仍然使用英语与其互动。这两种定义如何与LLM的使用交织在一起。
- en: '**LLMs as stand-alone programs:** Hereyou write high-quality prompts in natural
    language to unlock the best possible outputs. Examples involve idea generation,
    document summary, and writing code.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM作为独立程序：** 在这里，你编写高质量的自然语言提示以解锁最佳输出。示例包括创意生成、文档总结和编写代码。'
- en: '**LLMs as part of a program you design:** Here you write software (in Python,
    Java, C++, or other programming languages) wrapped around LLMs to achieve specific
    tasks. Examples involve sentiment analysis of social media comments, specialized
    chatbots, and autonomous agents.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM作为你设计的程序的一部分：** 在这里，你编写软件（用Python、Java、C++或其他编程语言）来包裹LLM以完成特定任务。示例包括社交媒体评论的情感分析、专用聊天机器人和自主代理。'
- en: Now let’s explore what Prompt Engineering looks like for each use-case.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们深入探讨一下Prompt Engineering在每种用例中的表现。
- en: 1️⃣ Prompt Engineering for “LLMs as stand-alone programs”
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1️⃣ “LLM作为独立程序”的Prompt Engineering
- en: The most common use case for LLMs is to interact with them through web interfaces
    like ChatGPT’s, and Bard’s.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LLM最常见的用例是通过像ChatGPT和Bard这样的网页界面与它们互动。
- en: Based on your specific needs, you can build a personal library of prompts. You
    want your prompts to be templated and easy to update. This way you don’t have
    to rewrite your prompts from scratch or search for them in the chat history every
    time you want to run one of them.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的具体需求，你可以建立个人提示库。你希望你的提示是模板化且易于更新的。这样，你就不必每次运行提示时从头编写或在聊天记录中搜索它们。
- en: 'Below are three varied examples of flexible prompts that may inspire you:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是三种不同的灵活提示示例，可能会激发你的灵感：
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 2️⃣ **Prompt Engineering for “LLMs as part of a program you design”**
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2️⃣ **“将LLMs作为你设计的程序的一部分的提示工程”**
- en: In this case, you’ll use your LLMs as functions you can call to process, analyze,
    and generate natural language.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你将使用你的LLMs作为可以调用的函数来处理、分析和生成自然语言。
- en: For example, your code can call an LLM to analyze sentiment in a series of comments
    related to a given product. After processing these comments, you can use another
    LLM-reliant function to generate a response based on the previous results.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你的代码可以调用LLM来分析一系列与某个产品相关的评论的情感。在处理这些评论后，你可以使用另一个依赖LLM的函数来生成基于先前结果的回应。
- en: 'Now, let’s look at how you can embed LLMs in your code. There are three primary
    ways:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何在代码中嵌入LLM。有三种主要方式：
- en: Connect through an API provided by another company;
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过另一个公司提供的API进行连接；
- en: Use a local server within your company’s network;
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用公司网络中的本地服务器；
- en: Install an open-source LLM directly on your computer.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接在你的计算机上安装开源LLM。
- en: 'Here’s a basic example of how you can use an LLM inside a program:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个如何在程序中使用LLM的基本示例：
- en: '[PRE3]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How to improve your Prompt Engineering skills
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何提高你的提示工程技能
- en: The short answer is an elegant quote I stole from Stephen King. “You must do
    two things above all others,” [he said](https://www.goodreads.com/quotes/312517-if-you-want-to-be-a-writer-you-must-do).
    “Read a lot, and write a lot.”
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 简短的回答是我从Stephen King那里偷来的优雅名言。“你必须做两件事，” [他说](https://www.goodreads.com/quotes/312517-if-you-want-to-be-a-writer-you-must-do)。“多读书，多写作。”
- en: Much like writing, Prompt Engineering appears easy until you sit down and hit
    the keyboard. Since we use natural language to write prompts, we approach it with
    a false sense of simplicity.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 就像写作一样，提示工程看似简单，直到你坐下来动手键盘。由于我们使用自然语言编写提示，我们对它有一种虚假的简单感。
- en: Pardon the repetition here, but AI models can’t read your mind (yet).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 请原谅这里的重复，但AI模型还无法读懂你的思维（尚未）。
- en: If you want high-quality responses, you have to learn to express your intentions
    as clearly as possible. Keep up with the literature to learn new techniques and
    put in as many reps as you can to integrate them.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要高质量的回应，你必须学会尽可能清晰地表达你的意图。跟进文献，学习新技术，并尽可能多地练习将它们融入。
- en: You may get bored of typing random instructions into a flickering context window.
    The antidote is to find difficult problems to solve. How can you randomize parts
    of your output? How to dynamically change your prompt’s content? Can you program
    an assistant that resists jailbreaking attempts?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会厌倦在闪烁的上下文窗口中输入随机指令。解药是找到困难的问题来解决。你如何使输出的某些部分随机化？如何动态改变提示的内容？你能编程一个抵抗越狱尝试的助手吗？
- en: Find problems hard to solve and Prompt Engineering will go from “a skill you
    have to learn” to a daily dose of “blissful (but sometimes frustrating) intellectual
    stimulation.”
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 找到难以解决的问题，提示工程将从“你必须学习的技能”转变为每日的“愉快（但有时令人沮丧）的智力刺激”。
- en: 'Further, there are two other topics that deserve your attention: Machine Learning
    in general and Deep Learning in particular. You want to explore both their strengths
    and shortcomings, because once you understand how the tech behind generative AI
    works, you’ll develop intuitions on why your model behaves in certain ways.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有两个其他话题值得你关注：机器学习总体以及深度学习特别。你需要探讨它们的优缺点，因为一旦你理解了生成式AI背后的技术，你将对你的模型为何以特定方式表现出直觉。
- en: 'Here are a few resources that can help you get started:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些可以帮助你入门的资源：
- en: '[**Making Friends of Machine Learning**](https://www.youtube.com/watch?v=lKXv19eRLZg&list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG&ab_channel=CassieKozyrkov)by
    Cassie Kozyrkov. (Series of YouTube videos)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**机器学习的朋友**](https://www.youtube.com/watch?v=lKXv19eRLZg&list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG&ab_channel=CassieKozyrkov)由Cassie
    Kozyrkov制作。（YouTube视频系列）'
- en: '[**Intro to Large Language Models**](https://www.youtube.com/watch?v=zjkBMFhNj_g&ab_channel=AndrejKarpathy)
    by Andrej Karpathy. (YouTube video)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**大语言模型简介**](https://www.youtube.com/watch?v=zjkBMFhNj_g&ab_channel=AndrejKarpathy)由Andrej
    Karpathy提供。（YouTube视频）'
- en: '[**Prompt Engineering for Developers**](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    by Isa Fulford and Andrew Ng (Free online course)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**开发者的提示工程**](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)由Isa
    Fulford和Andrew Ng提供（免费在线课程）'
- en: '[**How to Write Expert Prompts for LLMs**](/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550?sk=49c4528973c462c1c6d3d28cc29855fe)
    by this bald dude (Full 16,000-word guide that includes 25+ prompting techniques,
    examples, and commentary).'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**如何为LLMs编写专家级提示**](/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550?sk=49c4528973c462c1c6d3d28cc29855fe)由这位秃顶兄弟提供（完整的16,000字指南，包括25+种提示技术、示例和评论）。'
- en: '[](/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550?source=post_page-----a9ccf4ba8d49--------------------------------)
    [## How to Write Expert Prompts for ChatGPT (GPT-4) and Other Language Models'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550?source=post_page-----a9ccf4ba8d49--------------------------------)
    [## 如何为ChatGPT（GPT-4）及其他语言模型编写专家级提示'
- en: A beginner-friendly guide to prompt engineering with LLMs
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 适合初学者的LLM提示工程指南
- en: towardsdatascience.com](/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550?source=post_page-----a9ccf4ba8d49--------------------------------)
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/how-to-write-expert-prompts-for-chatgpt-gpt-4-and-other-language-models-23133dc85550?source=post_page-----a9ccf4ba8d49--------------------------------)'
- en: The TL;DR version
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TL;DR版
- en: LLMs are progressively becoming our interface with computing power. Prompt Engineering
    is the art of writing instructions that bring the best possible results from your
    LLMs (and other AI models).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs正逐渐成为我们与计算能力的接口。提示工程是编写指令的艺术，以从你的LLMs（及其他AI模型）中获得最佳结果。
- en: We’ll use natural language to interact with future Operating Systems.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用自然语言与未来的操作系统互动。
- en: Before that, we’ll use natural language to program AI assistants.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在那之前，我们将使用自然语言编程AI助手。
- en: Prompt Engineering is mostly done in natural language but it doesn’t mean AI
    models can read your mind. You still have to express your instructions clearly.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程大多用自然语言进行，但这并不意味着AI模型能读懂你的心思。你仍需清晰地表达指令。
- en: If you can write high-quality prompts, you can write code.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你能编写高质量的提示，你也能编写代码。
- en: Those who write better instructions will build better programs and get better
    results.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那些能编写更好指令的人将构建更好的程序并获得更好的结果。
- en: Prompt Engineering is a key to unlocking the latent capabilities of Language
    Models (and AI models in general).
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程是解锁语言模型（以及AI模型整体）潜在能力的关键。
- en: Prompt Engineering is an empirical science. You can learn from other people’s
    experiences, but you learn the most from your own.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程是一门经验科学。你可以从他人的经验中学习，但从自己的经验中学到的最多。
- en: Keep in touch?
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保持联系？
- en: You can [**subscribe to get email notifications**](https://nabil-alouani.medium.com/subscribe)when
    I publish new posts.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以[**订阅以获取电子邮件通知**](https://nabil-alouani.medium.com/subscribe)当我发布新文章时。
- en: I’m also active on [**Linkedin**](https://www.linkedin.com/in/nabil-alouani/)
    and[**X**](https://twitter.com/Nabil_Alouani_)and reply to every single message.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我也活跃于[**Linkedin**](https://www.linkedin.com/in/nabil-alouani/)和[**X**](https://twitter.com/Nabil_Alouani_)，并回复每一条消息。
- en: 'For Prompt Engineering inquiries, write me at: **nabil@nabilalouani.com.**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如需咨询提示工程，请联系我：**nabil@nabilalouani.com**。
- en: 'And in case you’re wondering: this article is 100% human-generated.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在想：这篇文章是100%人工生成的。
