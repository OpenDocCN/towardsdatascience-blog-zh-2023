- en: Improving Diffusers Package for High-Quality Image Generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ”¹è¿› Diffusers åŒ…ä»¥ç”Ÿæˆé«˜è´¨é‡å›¾åƒ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4](https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4](https://towardsdatascience.com/improving-diffusers-package-for-high-quality-image-generation-a50fff04bdd4)
- en: Overcoming token size limitations, custom model loading, LoRa support, textual
    inversion support, and more
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å…‹æœ token å¤§å°é™åˆ¶ã€è‡ªå®šä¹‰æ¨¡å‹åŠ è½½ã€LoRa æ”¯æŒã€æ–‡æœ¬åè½¬æ”¯æŒç­‰
- en: '[](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Andrew
    Zhu (Shudong Zhu)](../Images/46f07a875a42bcc4e0c262aea5e2a504.png)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    [Andrew Zhu (Shudong Zhu)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Andrew
    Zhu (Shudong Zhu)](../Images/46f07a875a42bcc4e0c262aea5e2a504.png)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    [Andrew Zhu (Shudong Zhu)](https://xhinker.medium.com/?source=post_page-----a50fff04bdd4--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    Â·15 min readÂ·Apr 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒåœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a50fff04bdd4--------------------------------)
    Â·15 åˆ†é’Ÿé˜…è¯»Â·2023å¹´4æœˆ5æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ec28506deb9273669dd315b83ff91aec.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec28506deb9273669dd315b83ff91aec.png)'
- en: Goodbye Babel, generated by Andrew Zhu using Diffusers in pure Python
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å†è§ Babelï¼Œç”± Andrew Zhu ä½¿ç”¨çº¯ Python ä¸­çš„ Diffusers ç”Ÿæˆ
- en: '[Stable Diffusion WebUI from AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
    has proven to be a powerful tool for generating high-quality images using the
    Diffusion model. However, while the WebUI is easy to use, data scientists, machine
    learning engineers, and researchers often require more control over the image
    generation process. This is where the [diffusers](https://github.com/huggingface/diffusers)
    package from huggingface comes in, providing a way to run the Diffusion model
    in Python and allowing users to customize their models and prompts to generate
    images to their specific needs.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[AUTOMATIC1111 çš„ Stable Diffusion WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
    å·²è¢«è¯æ˜æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œå¯ä»¥ä½¿ç”¨ Diffusion æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚ç„¶è€Œï¼Œå°½ç®¡ WebUI ä½¿ç”¨ç®€å•ï¼Œæ•°æ®ç§‘å­¦å®¶ã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œç ”ç©¶äººå‘˜é€šå¸¸éœ€è¦å¯¹å›¾åƒç”Ÿæˆè¿‡ç¨‹æœ‰æ›´å¤šæ§åˆ¶ã€‚è¿™æ—¶ï¼Œæ¥è‡ª
    huggingface çš„ [diffusers](https://github.com/huggingface/diffusers) åŒ…å°±æ´¾ä¸Šäº†ç”¨åœºï¼Œå®ƒæä¾›äº†ä¸€ç§åœ¨
    Python ä¸­è¿è¡Œ Diffusion æ¨¡å‹çš„æ–¹æ³•ï¼Œå¹¶å…è®¸ç”¨æˆ·è‡ªå®šä¹‰æ¨¡å‹å’Œæç¤ºï¼Œä»¥ç”Ÿæˆç¬¦åˆä»–ä»¬å…·ä½“éœ€æ±‚çš„å›¾åƒã€‚'
- en: 'Despite its potential, the Diffusers package has several limitations that prevent
    it from generating images as good as those produced by the Stable Diffusion WebUI.
    The most significant of these limitations include:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å…·æœ‰æ½œåŠ›ï¼ŒDiffusers åŒ…ä»æœ‰å‡ ä¸ªé™åˆ¶ï¼Œé˜»ç¢äº†å®ƒç”Ÿæˆä¸ Stable Diffusion WebUI ç›¸åª²ç¾çš„å›¾åƒã€‚è¿™äº›é™åˆ¶ä¸­æœ€æ˜¾è‘—çš„åŒ…æ‹¬ï¼š
- en: The inability to use custom models in the `.safetensor` file format;
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ— æ³•ä½¿ç”¨ `.safetensor` æ–‡ä»¶æ ¼å¼ä¸­çš„è‡ªå®šä¹‰æ¨¡å‹ï¼›
- en: The 77 prompt token limitation;
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 77 ä¸ªæç¤º token çš„é™åˆ¶ï¼›
- en: A lack of LoRA support;
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼ºä¹ LoRA æ”¯æŒï¼›
- en: And the absence of image scale-up functionality (also known as HighRes in Stable
    Diffusion WebUI);
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥åŠç¼ºå°‘å›¾åƒæ”¾å¤§åŠŸèƒ½ï¼ˆåœ¨ Stable Diffusion WebUI ä¸­ä¹Ÿç§°ä¸º HighResï¼‰ï¼›
- en: Low performance and high VRAM usage by default.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é»˜è®¤æƒ…å†µä¸‹æ€§èƒ½ä½ä¸” VRAM ä½¿ç”¨é«˜ã€‚
- en: This article aims to address these limitations and enable the Diffusers package
    to generate high-quality images comparable to those produced by the Stable Diffusion
    WebUI. With the enhancement solutions provided, data scientists, machine learning
    engineers, and researchers can enjoy greater control and flexibility in their
    image generation processes while also achieving exceptional results. In the following
    sections, we will explore the various strategies and techniques that can be used
    to overcome these limitations and unlock the full potential of the Diffusers package.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æ—¨åœ¨è§£å†³è¿™äº›é™åˆ¶ï¼Œå¹¶ä½¿DiffusersåŒ…èƒ½å¤Ÿç”Ÿæˆä¸Stable Diffusion WebUIäº§ç”Ÿçš„å›¾åƒç›¸åª²ç¾çš„é«˜è´¨é‡å›¾åƒã€‚é€šè¿‡æä¾›çš„å¢å¼ºè§£å†³æ–¹æ¡ˆï¼Œæ•°æ®ç§‘å­¦å®¶ã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œç ”ç©¶äººå‘˜å¯ä»¥åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­äº«æœ‰æ›´å¤§çš„æ§åˆ¶å’Œçµæ´»æ€§ï¼ŒåŒæ—¶å®ç°å“è¶Šçš„ç»“æœã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å„ç§ç­–ç•¥å’ŒæŠ€æœ¯ï¼Œè¿™äº›ç­–ç•¥å’ŒæŠ€æœ¯å¯ä»¥ç”¨æ¥å…‹æœè¿™äº›é™åˆ¶ï¼Œå¹¶é‡Šæ”¾DiffusersåŒ…çš„å…¨éƒ¨æ½œåŠ›ã€‚
- en: Note that please follow this link to install all required CUDA and Python packages
    if it is your first time running Stable Diffusion.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå¦‚æœè¿™æ˜¯ä½ ç¬¬ä¸€æ¬¡è¿è¡ŒStable Diffusionï¼Œè¯·æŒ‰ç…§æ­¤[é“¾æ¥](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)å®‰è£…æ‰€æœ‰æ‰€éœ€çš„CUDAå’ŒPythonåŒ…ã€‚
- en: '[](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)
    [## Installation'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[## å®‰è£…](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)'
- en: Install ğŸ¤— Diffusers for whichever deep learning library you're working with.
    ğŸ¤— Diffusers is tested on Python 3.7+â€¦
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸ºä½ æ­£åœ¨ä½¿ç”¨çš„æ·±åº¦å­¦ä¹ åº“å®‰è£…ğŸ¤— Diffusersã€‚ğŸ¤— Diffuserså·²åœ¨Python 3.7+ä¸Šæµ‹è¯•è¿‡â€¦
- en: huggingface.co](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[huggingface.co](https://huggingface.co/docs/diffusers/installation?source=post_page-----a50fff04bdd4--------------------------------)'
- en: 1\. Load Up Local Model files in .safetensor Format
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. åŠ è½½æœ¬åœ°çš„.safetensoræ ¼å¼æ¨¡å‹æ–‡ä»¶
- en: 'Users can easily spin up diffusers to generate an image like this:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·å¯ä»¥è½»æ¾å¯åŠ¨diffusersæ¥ç”Ÿæˆè¿™æ ·çš„å›¾åƒï¼š
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You may not satisfy with either the output image or the performance. Letâ€™s
    deal with the problems one by one. First, letâ€™s load up a custom model in `.safetensor`
    format located anywhere on your machine. you **canâ€™t** just load the model file
    like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½å¯¹è¾“å‡ºçš„å›¾åƒæˆ–æ€§èƒ½ä¸æ»¡æ„ã€‚è®©æˆ‘ä»¬é€ä¸ªè§£å†³è¿™äº›é—®é¢˜ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ª`.safetensor`æ ¼å¼çš„è‡ªå®šä¹‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½äºä½ è®¡ç®—æœºä¸Šçš„ä»»ä½•ä½ç½®ã€‚ä½ **ä¸èƒ½**åƒè¿™æ ·ç›´æ¥åŠ è½½æ¨¡å‹æ–‡ä»¶ï¼š
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here are the detailed steps to covert `.safetensor` file to diffusers format:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å°†`.safetensor`æ–‡ä»¶è½¬æ¢ä¸ºdiffusersæ ¼å¼çš„è¯¦ç»†æ­¥éª¤ï¼š
- en: '**Step 1**. Pull all diffusers code from GitHub'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤1**ã€‚ä»GitHubæ‹‰å–æ‰€æœ‰diffusersä»£ç '
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Step 2**. Under the `scripts` folder locate the [file](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py):
    `convert_original_stable_diffusion_to_diffusers.py`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤2**ã€‚åœ¨`script`æ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ°[æ–‡ä»¶](https://github.com/huggingface/diffusers/blob/main/scripts/convert_original_stable_diffusion_to_diffusers.py)ï¼š`convert_original_stable_diffusion_to_diffusers.py`'
- en: In your terminal, run this command to convert `.safetensor` file to Diffusers
    format. Remember to change the `â€” checkpoint_path` value to represent your case.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»ˆç«¯ä¸­è¿è¡Œæ­¤å‘½ä»¤å°†`.safetensor`æ–‡ä»¶è½¬æ¢ä¸ºDiffusersæ ¼å¼ã€‚è®°å¾—å°†`â€” checkpoint_path`å€¼æ›´æ”¹ä¸ºä½ çš„æƒ…å†µã€‚
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Step 3**. Now you can load up the pipeline using the newly converted model
    file, here is the complete code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤3**ã€‚ç°åœ¨ä½ å¯ä»¥ä½¿ç”¨æ–°è½¬æ¢çš„æ¨¡å‹æ–‡ä»¶åŠ è½½ç®¡é“ï¼Œä¸‹é¢æ˜¯å®Œæ•´ä»£ç ï¼š'
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You should be able to convert and use any models you download from huggingface
    or civitai.com.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åº”è¯¥èƒ½å¤Ÿè½¬æ¢å¹¶ä½¿ç”¨ä½ ä»huggingfaceæˆ–civitai.comä¸‹è½½çš„ä»»ä½•æ¨¡å‹ã€‚
- en: '![](../Images/a205baa885ec1cb4bb289043bcc75c7d.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a205baa885ec1cb4bb289043bcc75c7d.png)'
- en: Cat playing piano generated by the above code
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±ä¸Šè¿°ä»£ç ç”Ÿæˆçš„å¼¹é’¢ç´çš„çŒ«
- en: 2\. Boost the Performance of Diffusers
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. æå‡Diffusersçš„æ€§èƒ½
- en: Generating high-quality images can be a time-consuming process even for the
    latest 3xxx and 4xxx Nvidia RTX GPUs. By default, Diffuers package comes with
    non-optimized settings. Two solutions can be applied to greatly boost performance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆé«˜è´¨é‡å›¾åƒå¯èƒ½æ˜¯ä¸€ä¸ªè€—æ—¶çš„è¿‡ç¨‹ï¼Œå³ä½¿å¯¹äºæœ€æ–°çš„3xxxå’Œ4xxx Nvidia RTX GPUä¹Ÿæ˜¯å¦‚æ­¤ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒDiffuersåŒ…çš„è®¾ç½®æ˜¯æœªä¼˜åŒ–çš„ã€‚å¯ä»¥åº”ç”¨ä¸¤ç§è§£å†³æ–¹æ¡ˆæ¥å¤§å¹…æå‡æ€§èƒ½ã€‚
- en: Here is the interaction speed before applying the following solution, only about
    2.x iterations per second in RTX 3070 TI 8G RAM to generate a 512x512 image
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åº”ç”¨ä»¥ä¸‹è§£å†³æ–¹æ¡ˆä¹‹å‰çš„äº¤äº’é€Ÿåº¦å¦‚ä¸‹ï¼šåœ¨RTX 3070 TI 8G RAMä¸­ç”Ÿæˆä¸€ä¸ª512x512å›¾åƒçš„é€Ÿåº¦å¤§çº¦ä¸ºæ¯ç§’2.xæ¬¡è¿­ä»£ã€‚
- en: '![](../Images/523fd850a9008a5879b938236e13116f.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/523fd850a9008a5879b938236e13116f.png)'
- en: '**Use Half Precision Weights**'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨åŠç²¾åº¦æƒé‡**'
- en: The first solution is to use half precision weights. Half precision weights
    use 16-bit floating-point numbers instead of the traditional 32-bit numbers. This
    reduces the memory required for storing weights and speeds up computation, which
    can significantly improve the performance of the Diffusers package.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯ä½¿ç”¨åŠç²¾åº¦æƒé‡ã€‚åŠç²¾åº¦æƒé‡ä½¿ç”¨16ä½æµ®ç‚¹æ•°ä»£æ›¿ä¼ ç»Ÿçš„32ä½æµ®ç‚¹æ•°ã€‚è¿™å‡å°‘äº†å­˜å‚¨æƒé‡æ‰€éœ€çš„å†…å­˜ï¼Œå¹¶åŠ å¿«äº†è®¡ç®—é€Ÿåº¦ï¼Œè¿™å¯ä»¥æ˜¾è‘—æé«˜DiffusersåŒ…çš„æ€§èƒ½ã€‚
- en: According to this [video](https://www.youtube.com/watch?v=9tpLJpqxdE8&ab_channel=NVIDIADeveloper),
    reducing float precision from FP32 to FP16 will also enable the Tensor Cores.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®è¿™ä¸ª[è§†é¢‘](https://www.youtube.com/watch?v=9tpLJpqxdE8&ab_channel=NVIDIADeveloper)ï¼Œå°†æµ®ç‚¹ç²¾åº¦ä»FP32å‡å°‘åˆ°FP16ä¹Ÿä¼šå¯ç”¨Tensor
    Coresã€‚
- en: I had another article to test out how fast GPU Tensor cores can boost the computation
    speed.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è¿˜æœ‰å¦ä¸€ç¯‡æ–‡ç« æ¥æµ‹è¯•GPU Tensor Coresèƒ½å¤šå¿«æå‡è®¡ç®—é€Ÿåº¦ã€‚
- en: '[](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
    [## How Fast GPU Computation Can Be'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
    [## GPUè®¡ç®—èƒ½æœ‰å¤šå¿«'
- en: A comparison of matrix arithmetic calculation in CPU and GPU with Python and
    PyTorch
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CPUå’ŒGPUåœ¨Pythonå’ŒPyTorchä¸­è¿›è¡ŒçŸ©é˜µè¿ç®—æ¯”è¾ƒ
- en: towardsdatascience.com](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/how-fast-gpu-computation-can-be-41e8cff75974?source=post_page-----a50fff04bdd4--------------------------------)'
- en: Here is how to enable FP16 in diffusers, Just adding two lines of code will
    boost the performance by 500%, with almost no image quality impacts.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å¦‚ä½•åœ¨diffusersä¸­å¯ç”¨FP16ï¼Œåªéœ€æ·»åŠ ä¸¤è¡Œä»£ç å³å¯å°†æ€§èƒ½æå‡500%ï¼Œå‡ ä¹æ²¡æœ‰å›¾åƒè´¨é‡å½±å“ã€‚
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now the iteration speed boosts to 10.x iteration per second. A **5x times faster**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿­ä»£é€Ÿåº¦æå‡è‡³æ¯ç§’10.xæ¬¡ï¼Œ**å¿«äº†5å€**ã€‚
- en: '![](../Images/e365ff233687b79a64d433c7508b776d.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e365ff233687b79a64d433c7508b776d.png)'
- en: '**Use Xformers**'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨Xformers**'
- en: '[Xformers](https://github.com/facebookresearch/xformers) is an open-source
    library that provides a set of high-performance transformers for various natural
    language processing (NLP) tasks. It is built on top of PyTorch and aims to provide
    efficient and scalable transformer models that can be easily integrated into existing
    NLP pipelines. (Nowadays, are there any models that donâ€™t use Transformer? :P)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[Xformers](https://github.com/facebookresearch/xformers)æ˜¯ä¸€ä¸ªå¼€æºåº“ï¼Œæä¾›äº†ä¸€ç»„é«˜æ€§èƒ½çš„å˜æ¢å™¨ï¼Œé€‚ç”¨äºå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ã€‚å®ƒåŸºäºPyTorchæ„å»ºï¼Œæ—¨åœ¨æä¾›é«˜æ•ˆä¸”å¯æ‰©å±•çš„å˜æ¢å™¨æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„NLPæµç¨‹ä¸­ã€‚ï¼ˆå¦‚ä»Šï¼Œè¿˜æœ‰å“ªäº›æ¨¡å‹ä¸ä½¿ç”¨Transformerï¼Ÿ:Pï¼‰'
- en: Install Xformers by `pip install xformers` , then we can easily switch diffusers
    to use xformers by one line code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨`pip install xformers`å®‰è£…Xformersï¼Œç„¶åæˆ‘ä»¬åªéœ€ä¸€è¡Œä»£ç å³å¯è½»æ¾åˆ‡æ¢diffusersä½¿ç”¨xformersã€‚
- en: '[PRE6]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This one-line code boosts performance by another 20%.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€è¡Œä»£ç æ€§èƒ½æå‡äº†å¦å¤–20%ã€‚
- en: '![](../Images/d31f5865af53b4ed32364192c78b7d52.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d31f5865af53b4ed32364192c78b7d52.png)'
- en: 3\. Remove the 77 prompt tokens limitation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. ç§»é™¤77ä¸ªæç¤ºç¬¦çš„é™åˆ¶
- en: In the current version of Diffusers, there is a limitation of 77 prompt tokens
    that can be used in the generation of images.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å½“å‰ç‰ˆæœ¬çš„Diffusersä¸­ï¼Œç”Ÿæˆå›¾åƒæ—¶æœ‰77ä¸ªæç¤ºç¬¦çš„é™åˆ¶ã€‚
- en: Fortunately, there is a solution to this problem. By using the â€œ`lpw_stable_diffusion`â€
    pipeline provided by the community, you can unlock the 77 prompt token limitation
    and generate high-quality images with longer prompts.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œé’ˆå¯¹è¿™ä¸ªé—®é¢˜æœ‰ä¸€ä¸ªè§£å†³æ–¹æ¡ˆã€‚é€šè¿‡ä½¿ç”¨ç¤¾åŒºæä¾›çš„â€œ`lpw_stable_diffusion`â€ç®¡é“ï¼Œä½ å¯ä»¥è§£é”77ä¸ªæç¤ºç¬¦çš„é™åˆ¶ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„é•¿æç¤ºå›¾åƒã€‚
- en: 'To use the â€œ`lpw_stable_diffusion`â€ pipeline, you can use the following code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨â€œ`lpw_stable_diffusion`â€ç®¡é“ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this code, we are initializing a new DiffusionPipeline object using the â€œ`from_pretrained`â€
    method. We are specifying the path to the pre-trained model and setting the â€œ`custom_pipeline`â€
    argument to â€œ`lpw_stable_diffusion`â€. This tells Diffusers to use the â€œ`lpw_stable_diffusion`â€
    pipeline, which unlocks the 77 prompt token limitation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨â€œ`from_pretrained`â€æ–¹æ³•åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„DiffusionPipelineå¯¹è±¡ã€‚æˆ‘ä»¬æŒ‡å®šäº†é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„ï¼Œå¹¶å°†â€œ`custom_pipeline`â€å‚æ•°è®¾ç½®ä¸ºâ€œ`lpw_stable_diffusion`â€ã€‚è¿™å‘Šè¯‰Diffusersä½¿ç”¨â€œ`lpw_stable_diffusion`â€ç®¡é“ï¼Œä»è€Œè§£é”77ä¸ªæç¤ºç¬¦çš„é™åˆ¶ã€‚
- en: 'Now, letâ€™s use a long prompt string to test it out. Here is the complete code:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé•¿æç¤ºå­—ç¬¦ä¸²æ¥æµ‹è¯•ä¸€ä¸‹ã€‚ä»¥ä¸‹æ˜¯å®Œæ•´çš„ä»£ç ï¼š
- en: '[PRE8]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And you will get an image like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†è·å¾—å¦‚ä¸‹å›¾åƒï¼š
- en: '![](../Images/7b1e72d61d933d3acdae9a6b8ceb0da2.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b1e72d61d933d3acdae9a6b8ceb0da2.png)'
- en: Goodby Babel, generated by Andrew Zhu using diffusers
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Goodby Babelï¼Œç”±Andrew Zhuä½¿ç”¨diffusersç”Ÿæˆ
- en: 'If you still see a warning message like: `Token indices sequence length is
    longer than the specified maximum sequence length for this model ( *** > 77 )
    . Running this sequence through the model will result in indexing errors.` It
    is normal, you can just ignore it.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä»ç„¶çœ‹åˆ°ç±»ä¼¼çš„è­¦å‘Šä¿¡æ¯ï¼š`Token indices sequence length is longer than the specified maximum
    sequence length for this model ( *** > 77 ) . Running this sequence through the
    model will result in indexing errors.` è¿™å¾ˆæ­£å¸¸ï¼Œä½ å¯ä»¥å¿½ç•¥å®ƒã€‚
- en: 4\. Use Custom LoRA with Diffusers
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. ä½¿ç”¨è‡ªå®šä¹‰ LoRA ä¸æ‰©æ•£å™¨
- en: Despite the claims of [LoRA support](https://huggingface.co/docs/diffusers/training/lora)
    in Diffusers, users still face limitations when it comes to loading local LoRA
    files in the `.safetensor` file format. This can be a significant obstacle for
    users to use the LoRA from the community.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ [LoRA æ”¯æŒ](https://huggingface.co/docs/diffusers/training/lora) åœ¨ Diffusers
    ä¸­æœ‰æ‰€å£°ç§°ï¼Œä½†ç”¨æˆ·åœ¨åŠ è½½æœ¬åœ° `.safetensor` æ–‡ä»¶æ ¼å¼çš„ LoRA æ–‡ä»¶æ—¶ä»é¢ä¸´é™åˆ¶ã€‚è¿™å¯¹ç”¨æˆ·ä½¿ç”¨ç¤¾åŒº LoRA å¯èƒ½æ˜¯ä¸€ä¸ªé‡å¤§éšœç¢ã€‚
- en: To overcome this limitation, I have created a function that allows users to
    load LoRA files with weighted numbers in real time. This function can be used
    to load LoRA files and their corresponding weights to a Diffusers model, enabling
    the generation of high-quality images with LoRA data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å…‹æœè¿™ä¸€é™åˆ¶ï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ªå…è®¸ç”¨æˆ·å®æ—¶åŠ è½½å¸¦æœ‰æƒé‡çš„ LoRA æ–‡ä»¶çš„å‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°å¯ä»¥ç”¨æ¥å°† LoRA æ–‡ä»¶åŠå…¶å¯¹åº”çš„æƒé‡åŠ è½½åˆ° Diffusers
    æ¨¡å‹ä¸­ï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡çš„ LoRA æ•°æ®å›¾åƒã€‚
- en: 'Here is the function body:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å‡½æ•°ä¸»ä½“ï¼š
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The logic is extracted from the [convert_lora_safetensor_to_diffusers.py](https://github.com/huggingface/diffusers/blob/main/scripts/convert_lora_safetensor_to_diffusers.py)
    of the diffusers git repo.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: é€»è¾‘æå–è‡ª diffusers git ä»“åº“çš„ [convert_lora_safetensor_to_diffusers.py](https://github.com/huggingface/diffusers/blob/main/scripts/convert_lora_safetensor_to_diffusers.py)ã€‚
- en: 'Take one of the famous [LoRA:MoXin](https://civitai.com/models/12597/moxin)
    for example. you can use the `__load_lora` function like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥è‘—åçš„ [LoRA:MoXin](https://civitai.com/models/12597/moxin) ä¸ºä¾‹ã€‚ä½ å¯ä»¥åƒè¿™æ ·ä½¿ç”¨ `__load_lora`
    å‡½æ•°ï¼š
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The prompt will generate an image like this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºå°†ç”Ÿæˆç±»ä¼¼è¿™æ ·çš„å›¾åƒï¼š
- en: '![](../Images/0c2db814c9d57b74bd9cdcf193ee1ce4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c2db814c9d57b74bd9cdcf193ee1ce4.png)'
- en: a branch of flower, generated by Andrew Zhu using diffusers
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æèŠ±ï¼Œç”± Andrew Zhu ä½¿ç”¨æ‰©æ•£å™¨ç”Ÿæˆ
- en: You can call multiple times of `__load_lora()` to load several LoRAs for one
    generation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥å¤šæ¬¡è°ƒç”¨`__load_lora()`æ¥ä¸ºä¸€æ¬¡ç”ŸæˆåŠ è½½å¤šä¸ª LoRAã€‚
- en: With this function, you can now load LoRA files with weighted numbers in real
    time and use them to generate high-quality images with Diffusers. The LoRA loading
    is pretty fast, usually taking only 1â€“2 seconds, way better than converting and
    using(which will generate another model file in GB size).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œä½ ç°åœ¨å¯ä»¥å®æ—¶åŠ è½½å¸¦æœ‰æƒé‡çš„ LoRA æ–‡ä»¶ï¼Œå¹¶ç”¨å®ƒä»¬ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚LoRA åŠ è½½é€Ÿåº¦éå¸¸å¿«ï¼Œé€šå¸¸åªéœ€ 1-2 ç§’ï¼Œæ¯”è½¬æ¢å’Œä½¿ç”¨ï¼ˆè¿™ä¼šç”Ÿæˆä¸€ä¸ª
    GB å¤§å°çš„æ¨¡å‹æ–‡ä»¶ï¼‰è¦å¥½å¾—å¤šã€‚
- en: 5\. Use Custom Textural Inversions with Diffusers
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. ä½¿ç”¨è‡ªå®šä¹‰çº¹ç†åæ¼”ä¸æ‰©æ•£å™¨
- en: Using custom Texture Inversions with Diffusers package can be a powerful way
    to generate high-quality images. However, the [official documentation of Diffusers](https://huggingface.co/docs/diffusers/training/text_inversion)
    suggests that users need to train their own Textual Inversions which can take
    up to an hour on a V100 GPU. This may not be practical for many users who want
    to generate images quickly.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Diffusers åŒ…ä¸­çš„è‡ªå®šä¹‰çº¹ç†åæ¼”æ˜¯ä¸€ç§ç”Ÿæˆé«˜è´¨é‡å›¾åƒçš„å¼ºå¤§æ–¹æ³•ã€‚ç„¶è€Œï¼Œ[Diffusers çš„å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/diffusers/training/text_inversion)
    æåˆ°ï¼Œç”¨æˆ·éœ€è¦è®­ç»ƒè‡ªå·±çš„æ–‡æœ¬åæ¼”ï¼Œè¿™å¯èƒ½éœ€è¦åœ¨ V100 GPU ä¸ŠèŠ±è´¹ä¸€ä¸ªå°æ—¶ã€‚è¿™å¯¹äºè®¸å¤šå¸Œæœ›å¿«é€Ÿç”Ÿæˆå›¾åƒçš„ç”¨æˆ·æ¥è¯´å¯èƒ½ä¸åˆ‡å®é™…ã€‚
- en: So I investigated it and found a solution that can enable diffusers to use a
    textual inversion just like in Stable Diffusion WebUI. Below is the function I
    created to load a custom Textual Inversion.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘è¿›è¡Œäº†è°ƒæŸ¥å¹¶æ‰¾åˆ°äº†ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼Œä½¿æ‰©æ•£å™¨èƒ½å¤Ÿåƒåœ¨ Stable Diffusion WebUI ä¸­ä¸€æ ·ä½¿ç”¨æ–‡æœ¬åæ¼”ã€‚ä»¥ä¸‹æ˜¯æˆ‘åˆ›å»ºçš„ç”¨äºåŠ è½½è‡ªå®šä¹‰æ–‡æœ¬åæ¼”çš„å‡½æ•°ã€‚
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the `load_textual_inversion()` function, you need to provide the following
    arguments:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ `load_textual_inversion()` å‡½æ•°ä¸­ï¼Œä½ éœ€è¦æä¾›ä»¥ä¸‹å‚æ•°ï¼š
- en: '`learned_embeds_path`: Path to the pre-trained textual inversion model file
    in .pt or .bin format.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learned_embeds_path`ï¼šé¢„è®­ç»ƒæ–‡æœ¬åæ¼”æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ï¼Œæ ¼å¼ä¸º .pt æˆ– .binã€‚'
- en: '`text_encoder`: Text encoder object obtained from the Diffusion Pipeline.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_encoder`ï¼šä»æ‰©æ•£ç®¡é“è·å¾—çš„æ–‡æœ¬ç¼–ç å™¨å¯¹è±¡ã€‚'
- en: '`tokenizer`: Tokenizer object obtained from the Diffusion Pipeline.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`ï¼šä»æ‰©æ•£ç®¡é“è·å¾—çš„åˆ†è¯å™¨å¯¹è±¡ã€‚'
- en: '`token`: Optional argument specifying the prompt token. By default, it is set
    to None. it is the keyword that will trigger the textual inversion in your prompt'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`token`ï¼šå¯é€‰å‚æ•°ï¼ŒæŒ‡å®šæç¤ºè¯ä»¤ç‰Œã€‚é»˜è®¤è®¾ç½®ä¸º Noneã€‚å®ƒæ˜¯ä¼šåœ¨æç¤ºä¸­è§¦å‘æ–‡æœ¬åæ¼”çš„å…³é”®è¯ã€‚'
- en: '`weight`: Optional argument specifying the weight of the textual inversion.
    By default, I set it to 0.5\. you can change to other value as needed.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight`: å¯é€‰å‚æ•°ï¼ŒæŒ‡å®šæ–‡æœ¬åæ¼”çš„æƒé‡ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘å°†å…¶è®¾ç½®ä¸º0.5ï¼Œä½ å¯ä»¥æ ¹æ®éœ€è¦æ›´æ”¹ä¸ºå…¶ä»–å€¼ã€‚'
- en: 'You can now use the function with a diffusers pipeline like this:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ç°åœ¨å¯ä»¥ä½¿ç”¨ç±»ä¼¼è¿™æ ·çš„diffusersç®¡é“åŠŸèƒ½ï¼š
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here is the result of applying an [Empire Style](https://civitai.com/models/2032/empire-style)
    Textual Inversion.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯åº”ç”¨[å¸å›½é£æ ¼](https://civitai.com/models/2032/empire-style)æ–‡æœ¬åæ¼”çš„ç»“æœã€‚
- en: '![](../Images/f2f7296d2aa833114ac96d08f3556338.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2f7296d2aa833114ac96d08f3556338.png)'
- en: The leftâ€™s modern street turns to an old London style.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å·¦è¾¹çš„ç°ä»£è¡—é“å˜æˆäº†æ—§ä¼¦æ•¦é£æ ¼ã€‚
- en: 6\. Upscale Images
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. æ”¾å¤§å›¾åƒ
- en: Diffusers package is great for generating high-quality images, but image upscaling
    is not its primary function. However, the Stable-Diffusion-WebUI offers a feature
    called HighRes, which allows users to upscale their generated images to 2x or
    4x. It would be great if Diffusers users could enjoy the same feature. After some
    research and testing, I found that the SwinRI model is an excellent option for
    image upscaling, and it can easily upscale images to 2x or 4x after they are generated.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: DiffusersåŒ…éå¸¸é€‚åˆç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œä½†å›¾åƒæ”¾å¤§ä¸æ˜¯å…¶ä¸»è¦åŠŸèƒ½ã€‚ç„¶è€Œï¼ŒStable-Diffusion-WebUIæä¾›äº†ä¸€ä¸ªåä¸ºHighResçš„åŠŸèƒ½ï¼Œå…è®¸ç”¨æˆ·å°†ç”Ÿæˆçš„å›¾åƒæ”¾å¤§åˆ°2å€æˆ–4å€ã€‚å¦‚æœDiffusersç”¨æˆ·ä¹Ÿèƒ½äº«å—ç›¸åŒçš„åŠŸèƒ½ï¼Œé‚£å°±å¤ªå¥½äº†ã€‚ç»è¿‡ä¸€äº›ç ”ç©¶å’Œæµ‹è¯•ï¼Œæˆ‘å‘ç°SwinRIæ¨¡å‹æ˜¯å›¾åƒæ”¾å¤§çš„ä¼˜ç§€é€‰æ‹©ï¼Œå¯ä»¥è½»æ¾å°†å›¾åƒæ”¾å¤§åˆ°2å€æˆ–4å€ã€‚
- en: To use the SwinRI model for image upscaling, we can use the code from the GitHub
    repository of [JingyunLiang/SwinIR](https://github.com/JingyunLiang/SwinIR). If
    you just want codes, downloading `models/network_swinir.py`, `utils/util_calculate_psnr_ssim.py`
    and `main_test_swinir.py` is enough. Following the readme guideline, you can upscale
    images like magic.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨SwinRIæ¨¡å‹è¿›è¡Œå›¾åƒæ”¾å¤§ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨[JingyunLiang/SwinIR](https://github.com/JingyunLiang/SwinIR)çš„GitHubå­˜å‚¨åº“ä¸­çš„ä»£ç ã€‚å¦‚æœä½ åªéœ€è¦ä»£ç ï¼Œä¸‹è½½`models/network_swinir.py`ï¼Œ`utils/util_calculate_psnr_ssim.py`å’Œ`main_test_swinir.py`å³å¯ã€‚æŒ‰ç…§readmeæŒ‡å—ï¼Œä½ å¯ä»¥åƒé­”æ³•ä¸€æ ·æ”¾å¤§å›¾åƒã€‚
- en: Here is a sample of how well SwinRI can scale up an image.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯SwinRIå¦‚ä½•å‡ºè‰²æ”¾å¤§å›¾åƒçš„ä¸€ä¸ªç¤ºä¾‹ã€‚
- en: '![](../Images/b977daec46ca853876ed6c25563a0159.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b977daec46ca853876ed6c25563a0159.png)'
- en: 'Left: original image, Right: 4x SwinRI upscaled image'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å·¦ä¾§ï¼šåŸå§‹å›¾åƒï¼Œå³ä¾§ï¼š4å€SwinRIæ”¾å¤§å›¾åƒ
- en: Many other open-source solutions can be used to improve image quality. Here
    list three other models that I tried that return wonderful results.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šå…¶ä»–å¼€æºè§£å†³æ–¹æ¡ˆå¯ä»¥ç”¨æ¥æ”¹å–„å›¾åƒè´¨é‡ã€‚è¿™é‡Œåˆ—å‡ºäº†æˆ‘å°è¯•è¿‡çš„å¦å¤–ä¸‰ç§è¿”å›ä¼˜ç§€ç»“æœçš„æ¨¡å‹ã€‚
- en: '**RealSR**: [https://github.com/jixiaozhong/RealSR](https://github.com/jixiaozhong/RealSR)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RealSR**: [https://github.com/jixiaozhong/RealSR](https://github.com/jixiaozhong/RealSR)'
- en: RealSR can scale up an image 4 times almost as good as SwinRI, and its execution
    performance is the fastest, instead of invoking PyTorch and CUDA. The author compiles
    the code and CUDA usage to binary directly. My observations reveal that the RealSR
    can upscale a mage in about just 2â€“4 seconds.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: RealSRå¯ä»¥å°†å›¾åƒæ”¾å¤§4å€ï¼Œå‡ ä¹ä¸SwinRIä¸€æ ·å¥½ï¼Œå¹¶ä¸”æ‰§è¡Œæ€§èƒ½æœ€å¿«ï¼Œä¸éœ€è¦è°ƒç”¨PyTorchå’ŒCUDAã€‚ä½œè€…å°†ä»£ç å’ŒCUDAä½¿ç”¨ç›´æ¥ç¼–è¯‘ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶ã€‚æˆ‘çš„è§‚å¯Ÿå‘ç°ï¼ŒRealSRå¯ä»¥åœ¨å¤§çº¦2â€“4ç§’å†…æ”¾å¤§å›¾åƒã€‚
- en: '**CodeFormer**: [https://github.com/sczhou/CodeFormer](https://github.com/sczhou/CodeFormer)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CodeFormer**: [https://github.com/sczhou/CodeFormer](https://github.com/sczhou/CodeFormer)'
- en: CodeFormer is good at restoring blurred or broken faces, it can also remove
    noise and enhance background details. This solution and algorithm is widely used
    in other applications, including Stable-Diffusion-WebUI
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: CodeFormeræ“…é•¿ä¿®å¤æ¨¡ç³Šæˆ–ç ´æŸçš„é¢å­”ï¼Œå®ƒè¿˜å¯ä»¥å»é™¤å™ªå£°å’Œå¢å¼ºèƒŒæ™¯ç»†èŠ‚ã€‚è¿™ç§è§£å†³æ–¹æ¡ˆå’Œç®—æ³•åœ¨å…¶ä»–åº”ç”¨ä¸­ä¹Ÿå¾—åˆ°äº†å¹¿æ³›ä½¿ç”¨ï¼ŒåŒ…æ‹¬Stable-Diffusion-WebUIã€‚
- en: '**GFPGAN:** [https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GFPGAN:** [https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)'
- en: Another powerful open-source solution that archives amazing results of face
    restoration, and it is fast too. GFPGAN is also integrated into Stable-Diffusion-WebUI.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªå¼ºå¤§çš„å¼€æºè§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿå®ç°æƒŠäººçš„é¢éƒ¨ä¿®å¤æ•ˆæœï¼Œè€Œä¸”é€Ÿåº¦ä¹Ÿå¾ˆå¿«ã€‚GFPGANè¿˜é›†æˆåˆ°äº†Stable-Diffusion-WebUIä¸­ã€‚
- en: '[Updated by April 19, 2023]'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ›´æ–°äº2023å¹´4æœˆ19æ—¥]'
- en: Found that the SD 1.5 and all extended models canâ€™t handle well with generating
    a high-resolution image by simply using the text2img pipeline. In practice, I
    found that the Diffusers text2img pipeline will easily generate twisted and broken
    images even at 1920x1080, the same settings and prompt can generate good images
    at 800x600.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å‘ç°SD 1.5åŠæ‰€æœ‰æ‰©å±•æ¨¡å‹åœ¨ä»…ä½¿ç”¨text2imgç®¡é“ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒæ—¶æ•ˆæœä¸å¥½ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘å‘ç°Diffusers text2imgç®¡é“å³ä½¿åœ¨1920x1080ä¸‹ä¹Ÿä¼šå®¹æ˜“ç”Ÿæˆæ‰­æ›²å’Œç ´æŸçš„å›¾åƒï¼Œç›¸åŒçš„è®¾ç½®å’Œæç¤ºå¯ä»¥åœ¨800x600ä¸‹ç”Ÿæˆè‰¯å¥½çš„å›¾åƒã€‚
- en: 'I found Diffusersâ€™ img2img pipeline can function as a great image high-resolution
    fix solution. here are the overall steps to implement img2img pipeline as an image
    high-resolution fix solution:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å‘ç° Diffusers çš„ img2img æµç¨‹å¯ä»¥ä½œä¸ºä¸€ä¸ªå¾ˆå¥½çš„å›¾åƒé«˜åˆ†è¾¨ç‡ä¿®å¤è§£å†³æ–¹æ¡ˆã€‚ä»¥ä¸‹æ˜¯å°† img2img æµç¨‹ä½œä¸ºå›¾åƒé«˜åˆ†è¾¨ç‡ä¿®å¤è§£å†³æ–¹æ¡ˆçš„æ€»ä½“æ­¥éª¤ï¼š
- en: Generate a low-resolution image using the text2img pipeline
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ text2img æµç¨‹ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ
- en: Upsize the image to whatever resolution you want (max size depends on your VRAM
    size). `img = img.resize((width,height))` . The test shows that my 8G VRAM RTX
    3070 Ti can handle upscaling a 800x600 3 times to 2400x1800\. Note that at this
    step, no image upscaling or fixing happening, just upsize the image to the size
    you want.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†å›¾åƒæ”¾å¤§åˆ°ä½ æƒ³è¦çš„åˆ†è¾¨ç‡ï¼ˆæœ€å¤§å°ºå¯¸å–å†³äºä½ çš„ VRAM å¤§å°ï¼‰ã€‚`img = img.resize((width,height))` ã€‚æµ‹è¯•æ˜¾ç¤ºæˆ‘çš„
    8G VRAM RTX 3070 Ti èƒ½å¤„ç†å°† 800x600 æ”¾å¤§ 3 å€åˆ° 2400x1800ã€‚åœ¨è¿™ä¸€æ­¥éª¤ä¸­ï¼Œè¯·æ³¨æ„æ²¡æœ‰å›¾åƒæ”¾å¤§æˆ–ä¿®å¤ï¼Œåªæ˜¯å°†å›¾åƒæ”¾å¤§åˆ°ä½ æƒ³è¦çš„å°ºå¯¸ã€‚
- en: 'Then feed the new manually upsized `img` to the img2img pipeline with the same
    prompt, negative prompt, and additional setting: `strength` into the call, you
    will see the input get upscaled like magic.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åå°†æ–°çš„æ‰‹åŠ¨æ”¾å¤§ `img` ä»¥ç›¸åŒçš„æç¤ºã€è´Ÿé¢æç¤ºå’Œé¢å¤–è®¾ç½® `strength` ä¼ é€’åˆ° img2img æµç¨‹ä¸­ï¼Œä½ ä¼šçœ‹åˆ°è¾“å…¥åƒé­”æ³•ä¸€æ ·è¢«æ”¾å¤§ã€‚
- en: The img2img will slightly change the image content, take a face as an example,
    it will not only upscale the image and somewhat change the face a little bit.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: img2img ä¼šç¨å¾®æ”¹å˜å›¾åƒå†…å®¹ï¼Œä»¥é¢éƒ¨ä¸ºä¾‹ï¼Œå®ƒä¸ä»…ä¼šæ”¾å¤§å›¾åƒï¼Œè¿˜ä¼šç¨å¾®æ”¹å˜é¢éƒ¨ã€‚
- en: '![](../Images/7527d699ce47ca6f85c6b30f975efb7e.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7527d699ce47ca6f85c6b30f975efb7e.png)'
- en: Face HighRes upscale using Diffuses img2img pipeline, image generated by the
    author
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Diffuses img2img æµç¨‹è¿›è¡Œé¢éƒ¨é«˜åˆ†è¾¨ç‡æ”¾å¤§ï¼Œå›¾åƒç”±ä½œè€…ç”Ÿæˆ
- en: 7\. Optimize Diffusers CUDA Memory Usage
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. ä¼˜åŒ– Diffusers CUDA å†…å­˜ä½¿ç”¨
- en: 'When using Diffusers to generate images, itâ€™s important to consider the CUDA
    memory usage, especially when you want to load other models to further process
    the generated images. If you try to load another model like SwinIR to upscale
    images, you might encounter a `RuntimeError: CUDA out of memory` due to the Diffuser
    model still occupying the CUDA memory.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä½¿ç”¨ Diffusers ç”Ÿæˆå›¾åƒæ—¶ï¼Œé‡è¦çš„æ˜¯è¦è€ƒè™‘ CUDA å†…å­˜ä½¿ç”¨ï¼Œç‰¹åˆ«æ˜¯å½“ä½ æƒ³åŠ è½½å…¶ä»–æ¨¡å‹æ¥è¿›ä¸€æ­¥å¤„ç†ç”Ÿæˆçš„å›¾åƒæ—¶ã€‚å¦‚æœä½ å°è¯•åŠ è½½å¦ä¸€ä¸ªæ¨¡å‹å¦‚
    SwinIR ä»¥æ”¾å¤§å›¾åƒï¼Œä½ å¯èƒ½ä¼šé‡åˆ° `RuntimeError: CUDA out of memory`ï¼Œå› ä¸º Diffuser æ¨¡å‹ä»ç„¶å ç”¨ CUDA
    å†…å­˜ã€‚'
- en: 'To mitigate this issue, there are several solutions to optimize CUDA memory
    usage. The following two solutions I found work the best:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæœ‰å‡ ç§è§£å†³æ–¹æ¡ˆå¯ä»¥ä¼˜åŒ– CUDA å†…å­˜ä½¿ç”¨ã€‚æˆ‘å‘ç°ä»¥ä¸‹ä¸¤ç§è§£å†³æ–¹æ¡ˆæ•ˆæœæœ€å¥½ï¼š
- en: Sliced Attention for Additional Memory Savings
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ‡ç‰‡æ³¨æ„åŠ›ç”¨äºé¢å¤–çš„å†…å­˜èŠ‚çœ
- en: Sliced attention is a technique that reduces the memory usage of self-attention
    mechanisms in transformers. By partitioning the attention matrix into smaller
    blocks, the memory requirements are reduced. This technique can be used with the
    Diffusers package to reduce the memory footprint of the Diffuser model.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ‡ç‰‡æ³¨æ„åŠ›æ˜¯ä¸€ç§å‡å°‘å˜æ¢å™¨ä¸­è‡ªæ³¨æ„åŠ›æœºåˆ¶å†…å­˜ä½¿ç”¨çš„æŠ€æœ¯ã€‚é€šè¿‡å°†æ³¨æ„åŠ›çŸ©é˜µåˆ†å‰²æˆè¾ƒå°çš„å—ï¼Œå‡å°‘äº†å†…å­˜éœ€æ±‚ã€‚è¿™ç§æŠ€æœ¯å¯ä»¥ä¸ Diffusers åŒ…ä¸€èµ·ä½¿ç”¨ï¼Œä»¥å‡å°‘
    Diffuser æ¨¡å‹çš„å†…å­˜å ç”¨ã€‚
- en: 'To use it in Diffusers, simply one line code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Diffusers ä¸­ä½¿ç”¨å®ƒï¼Œåªéœ€ä¸€è¡Œä»£ç ï¼š
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Model offloading to CPU
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹è½¬ç§»åˆ° CPU
- en: Usually, you wonâ€™t have two models running at the same time, the idea is to
    offload the model data to the CPU memory temporarily and free up CUA memory space
    for other models, and only load up to VRAM when you start using the model.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œä½ ä¸ä¼šåŒæ—¶è¿è¡Œä¸¤ä¸ªæ¨¡å‹ï¼Œç›®çš„æ˜¯å°†æ¨¡å‹æ•°æ®æš‚æ—¶è½¬ç§»åˆ° CPU å†…å­˜ä¸­ï¼Œé‡Šæ”¾ CUDA å†…å­˜ç©ºé—´ç»™å…¶ä»–æ¨¡å‹ï¼Œåªæœ‰åœ¨å¼€å§‹ä½¿ç”¨æ¨¡å‹æ—¶æ‰åŠ è½½åˆ° VRAM ä¸­ã€‚
- en: 'To use dynamically offload data to CPU memory in Diffusers, use this line code:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Diffusers ä¸­åŠ¨æ€å°†æ•°æ®è½¬ç§»åˆ° CPU å†…å­˜ä¸­ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š
- en: '[PRE14]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: After applying this, whenever Diffusers finish the image generation task, the
    model data will be offloaded to CPU memory automatically until the next time calling.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨æ­¤æ–¹æ³•åï¼Œæ¯å½“ Diffusers å®Œæˆå›¾åƒç”Ÿæˆä»»åŠ¡æ—¶ï¼Œæ¨¡å‹æ•°æ®å°†è‡ªåŠ¨è½¬ç§»åˆ° CPU å†…å­˜ä¸­ï¼Œç›´åˆ°ä¸‹ä¸€æ¬¡è°ƒç”¨ã€‚
- en: For more performance and VRAM optimization for Diffusers with PyTorch 2.0, please
    check out this article I wrote up as a supplement to this article.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è·å–æ›´å¤šå…³äº PyTorch 2.0 çš„ Diffusers æ€§èƒ½å’Œ VRAM ä¼˜åŒ–çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹æˆ‘å†™çš„è¿™ç¯‡æ–‡ç« ï¼Œä½œä¸ºå¯¹æœ¬æ–‡çš„è¡¥å……ã€‚
- en: '[](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
    [## Performance Testing Note of Diffusers With PyTorch 2.0'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
    [## ä½¿ç”¨ PyTorch 2.0 è¿›è¡Œæ‰©æ•£æ¨¡å‹æ€§èƒ½æµ‹è¯•ç¬”è®°'
- en: Test various methods to boost Stable Diffusion package Diffusers' performance
    and lower VRAM usage
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æµ‹è¯•å„ç§æ–¹æ³•ä»¥æå‡ Stable Diffusion åŒ… Diffusers çš„æ€§èƒ½å¹¶é™ä½ VRAM ä½¿ç”¨
- en: betterprogramming.pub](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[betterprogramming.pub](https://betterprogramming.pub/performance-testing-note-of-diffusers-with-pytorch-2-0-fbe96054258c?source=post_page-----a50fff04bdd4--------------------------------)'
- en: Summary
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: The article discusses how to improve the performance and capabilities of the
    Diffusers package, The article covers several solutions to common issues faced
    by Diffusers users, including loading local `.safetensor` models, boosting performance,
    removing the 77 prompt tokens limitation, using custom LoRA and Textual Inversion,
    upscaling images, and optimizing CUDA memory usage.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡ç« è®¨è®ºäº†å¦‚ä½•æå‡DiffusersåŒ…çš„æ€§èƒ½å’ŒåŠŸèƒ½ï¼Œæ¶µç›–äº†Diffusersç”¨æˆ·é¢ä¸´çš„å‡ ä¸ªå¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬åŠ è½½æœ¬åœ°`.safetensor`æ¨¡å‹ã€æå‡æ€§èƒ½ã€ç§»é™¤77ä¸ªæç¤ºä»¤ç‰Œé™åˆ¶ã€ä½¿ç”¨è‡ªå®šä¹‰LoRAå’ŒTextual
    Inversionã€å›¾åƒæ”¾å¤§å’Œä¼˜åŒ–CUDAå†…å­˜ä½¿ç”¨ã€‚
- en: By applying these solutions, Diffusers users can generate high-quality images
    with better performance and more control over the process. The article also includes
    code snippets and detailed explanations for each solution.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åº”ç”¨è¿™äº›è§£å†³æ–¹æ¡ˆï¼ŒDiffusersç”¨æˆ·å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œå…·æœ‰æ›´å¥½çš„æ€§èƒ½å’Œæ›´å¤šçš„è¿‡ç¨‹æ§åˆ¶ã€‚æ–‡ç« è¿˜åŒ…æ‹¬æ¯ä¸ªè§£å†³æ–¹æ¡ˆçš„ä»£ç ç‰‡æ®µå’Œè¯¦ç»†è§£é‡Šã€‚
- en: If you can successfully apply these solutions and code in your case, there could
    be an additional benefit, which I benefit a lot, is that you may implement your
    own solutions by reading the Diffusers source code and understand better how Stable
    Diffusion works. To me, learning, finding, and implementing these solutions is
    a fun journey. Hope these solutions can also help you and wish you enjoy with
    Stable Diffusion and diffusers package.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ èƒ½æˆåŠŸåº”ç”¨è¿™äº›è§£å†³æ–¹æ¡ˆå’Œä»£ç ï¼Œå¯èƒ½ä¼šæœ‰é¢å¤–çš„å¥½å¤„ï¼Œæˆ‘å—ç›ŠåŒªæµ…ï¼Œä½ å¯ä»¥é€šè¿‡é˜…è¯»Diffusersæºä»£ç å®ç°ä½ è‡ªå·±çš„è§£å†³æ–¹æ¡ˆï¼Œæ›´å¥½åœ°ç†è§£Stable
    Diffusionçš„å·¥ä½œåŸç†ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œå­¦ä¹ ã€å‘ç°å’Œå®æ–½è¿™äº›è§£å†³æ–¹æ¡ˆæ˜¯ä¸€æ®µæœ‰è¶£çš„æ—…ç¨‹ã€‚å¸Œæœ›è¿™äº›è§£å†³æ–¹æ¡ˆä¹Ÿèƒ½å¸®åŠ©ä½ ï¼Œå¹¶å¸Œæœ›ä½ åœ¨ä½¿ç”¨Stable Diffusionå’ŒdiffusersåŒ…æ—¶æ„Ÿåˆ°æ„‰å¿«ã€‚
- en: 'Here provide the prompt that generates the heading image:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæä¾›ç”Ÿæˆæ ‡é¢˜å›¾åƒçš„æç¤ºï¼š
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Size: **600 * 800**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: å°ºå¯¸ï¼š**600 * 800**
- en: 'Seed: **3977059881**'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ç§å­ï¼š**3977059881**
- en: 'Scheduler (or Sampling method): **DPMSolverMultistepScheduler**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒåº¦å™¨ï¼ˆæˆ–é‡‡æ ·æ–¹æ³•ï¼‰ï¼š**DPMSolverMultistepScheduler**
- en: 'Sampling steps: **25**'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: é‡‡æ ·æ­¥éª¤ï¼š**25**
- en: 'CFG Scale (or Guidance Scale): **7.5** SwinRI model: **003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: CFGè§„æ¨¡ï¼ˆæˆ–æŒ‡å¯¼å°ºåº¦ï¼‰ï¼š**7.5** SwinRIæ¨¡å‹ï¼š**003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x4_GAN.pth**
- en: License and Code Reuse
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¸å¯è¯å’Œä»£ç é‡ç”¨
- en: The solutions provided in this article were achieved through extensive source
    reading, later night testing, and logical design. It is important to note that
    at the time of writing (April 2023), loading LoRA and Textual Inversion solutions
    and code included in this article are the only working versions across the internet.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡ç« ä¸­æä¾›çš„è§£å†³æ–¹æ¡ˆæ˜¯é€šè¿‡å¹¿æ³›çš„æºä»£ç é˜…è¯»ã€æ·±å¤œæµ‹è¯•å’Œé€»è¾‘è®¾è®¡å®ç°çš„ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼ˆ2023å¹´4æœˆï¼‰ï¼ŒåŠ è½½LoRAå’ŒTextual Inversionè§£å†³æ–¹æ¡ˆå’Œä»£ç æ˜¯äº’è”ç½‘ä¸Šå”¯ä¸€æœ‰æ•ˆçš„ç‰ˆæœ¬ã€‚
- en: If you find the code presented in this article useful and want to reuse it in
    your project, paper, or article, please reference back to this Medium article.
    The code presented here is licensed under the MIT license, which permits you to
    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
    of the software, subject to the conditions of the license.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å‘ç°æœ¬æ–‡ä¸­å±•ç¤ºçš„ä»£ç æœ‰ç”¨ï¼Œå¹¶å¸Œæœ›åœ¨ä½ çš„é¡¹ç›®ã€è®ºæ–‡æˆ–æ–‡ç« ä¸­é‡ç”¨ï¼Œè¯·å‚è€ƒè¿™ç¯‡Mediumæ–‡ç« ã€‚è¿™é‡Œå±•ç¤ºçš„ä»£ç éµå¾ªMITè®¸å¯è¯ï¼Œè¿™å…è®¸ä½ åœ¨éµå®ˆè®¸å¯è¯æ¡æ¬¾çš„æ¡ä»¶ä¸‹ï¼Œä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å†è®¸å¯å’Œ/æˆ–å‡ºå”®è½¯ä»¶çš„å‰¯æœ¬ã€‚
- en: Please note that the solutions presented in this article may not be the optimal
    or most efficient way to achieve the desired results, and are subject to change
    as new developments and improvements are made. It is always recommended to thoroughly
    test and validate any code before implementing it in a production environment.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæœ¬æ–‡ä¸­æå‡ºçš„è§£å†³æ–¹æ¡ˆå¯èƒ½ä¸æ˜¯å®ç°æœŸæœ›ç»“æœçš„æœ€ä½³æˆ–æœ€æœ‰æ•ˆçš„æ–¹æ³•ï¼Œéšç€æ–°å‘å±•å’Œæ”¹è¿›ï¼Œå¯èƒ½ä¼šæœ‰æ‰€å˜åŒ–ã€‚å§‹ç»ˆå»ºè®®åœ¨å°†ä»»ä½•ä»£ç åº”ç”¨äºç”Ÿäº§ç¯å¢ƒä¹‹å‰ï¼Œå½»åº•æµ‹è¯•å’ŒéªŒè¯ä»£ç ã€‚
- en: 'Book: Using Stable Diffusion with Python'
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¹¦ç±ï¼šä½¿ç”¨Pythonçš„Stable Diffusion
- en: The article provided a glimpse into the potential of Stable Diffusion controlling
    using Python. Delving deeper into this interdisciplinary field requires a comprehensive
    guide that not only explains the theory but also demonstrates practical applications
    through Python programming.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: æ–‡ç« æä¾›äº†å¯¹ä½¿ç”¨Pythonæ§åˆ¶Stable Diffusionæ½œåŠ›çš„åˆæ­¥äº†è§£ã€‚æ·±å…¥æ¢è®¨è¿™ä¸ªè·¨å­¦ç§‘é¢†åŸŸéœ€è¦ä¸€ä¸ªå…¨é¢çš„æŒ‡å—ï¼Œä¸ä»…è§£é‡Šç†è®ºï¼Œè¿˜é€šè¿‡Pythonç¼–ç¨‹å±•ç¤ºå®é™…åº”ç”¨ã€‚
- en: Thus, I am thrilled to announce the release of my book, â€œ[Using Stable Diffusion
    with Python](https://www.amazon.com/Using-Stable-Diffusion-Python-Generation/dp/1835086373).â€
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘å¾ˆé«˜å…´åœ°å®£å¸ƒæˆ‘çš„ä¹¦ç±â€œ[ç”¨ Python ä½¿ç”¨ç¨³å®šæ‰©æ•£](https://www.amazon.com/Using-Stable-Diffusion-Python-Generation/dp/1835086373)â€çš„å‘å¸ƒã€‚
- en: '![](../Images/d86f8ba31c642e1d9042ef8d70ed379f.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d86f8ba31c642e1d9042ef8d70ed379f.png)'
- en: Using Stable Diffusion with Python
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨ Python ä½¿ç”¨ç¨³å®šæ‰©æ•£
- en: This book is a culmination of the latest research, experimentation, and dedication
    to making complex AI concepts accessible to everyone (using Python). Whether you
    are a beginner programmer intrigued by the power of Python, a seasoned engineer
    looking to expand your toolkit, or a scientist eager to delve into mathematical
    modeling, this book is designed to cater to your needs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦æ˜¯æœ€æ–°ç ”ç©¶ã€å®éªŒå’Œè‡´åŠ›äºä½¿å¤æ‚çš„ AI æ¦‚å¿µå¯¹æ‰€æœ‰äººï¼ˆä½¿ç”¨ Pythonï¼‰å¯åŠçš„ç»ˆææˆæœã€‚ä¸è®ºä½ æ˜¯å¯¹ Python å¼ºå¤§åŠŸèƒ½æ„Ÿå…´è¶£çš„åˆå­¦è€…ç¨‹åºå‘˜ã€å¯»æ±‚æ‰©å±•å·¥å…·åŒ…çš„ç»éªŒå·¥ç¨‹å¸ˆï¼Œè¿˜æ˜¯æ¸´æœ›æ·±å…¥æ•°å­¦å»ºæ¨¡çš„ç§‘å­¦å®¶ï¼Œæœ¬ä¹¦éƒ½æ—¨åœ¨æ»¡è¶³ä½ çš„éœ€æ±‚ã€‚
- en: Within its pages, you will find detailed explanations of the mathematical foundations
    of Stable Diffusion, coupled with clear, step-by-step tutorials on how to use
    these models withPython. From setting up your Python environment to running the
    Diffusion models, visualizing results, every aspect is covered with meticulous
    attention to detail.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¹¦ä¸­ï¼Œä½ å°†æ‰¾åˆ°ç¨³å®šæ‰©æ•£çš„æ•°å­¦åŸºç¡€çš„è¯¦ç»†è§£é‡Šï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨è¿™äº›æ¨¡å‹ä¸ Python çš„æ¸…æ™°é€æ­¥æ•™ç¨‹ã€‚ä»è®¾ç½® Python ç¯å¢ƒåˆ°è¿è¡Œæ‰©æ•£æ¨¡å‹ã€å¯è§†åŒ–ç»“æœï¼Œæ¯ä¸€ä¸ªæ–¹é¢éƒ½ä»¥ç»†è‡´çš„æ³¨æ„åŠ›è¿›è¡Œè¦†ç›–ã€‚
- en: I hope you like it.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢å®ƒã€‚
- en: References
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒèµ„æ–™
- en: '[diffusers github repository](https://github.com/huggingface/diffusers)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[diffusers github ä»“åº“](https://github.com/huggingface/diffusers)'
- en: '[Issue: Overcoming the 77 token limit in diffusers](https://github.com/huggingface/diffusers/issues/2136)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[é—®é¢˜ï¼šå…‹æœ diffusers ä¸­çš„ 77 ä¸ª token é™åˆ¶](https://github.com/huggingface/diffusers/issues/2136)'
- en: '[Diffusers memory and speed](https://huggingface.co/docs/diffusers/optimization/fp16)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Diffusers å†…å­˜å’Œé€Ÿåº¦](https://huggingface.co/docs/diffusers/optimization/fp16)'
- en: '[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://huggingface.co/docs/diffusers/training/text_inversion](https://huggingface.co/docs/diffusers/training/text_inversion)'
- en: '[Deliberate model download](https://civitai.com/models/4823/deliberate)'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[åˆ»æ„æ¨¡å‹ä¸‹è½½](https://civitai.com/models/4823/deliberate)'
