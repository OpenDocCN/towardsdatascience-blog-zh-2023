- en: '🦜🔗 LangChain: Question Answering Agent over Docs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🦜🔗 LangChain：文档上的问答代理
- en: 原文：[https://towardsdatascience.com/langchain-question-answering-agent-over-docs-18e5585bdbd3](https://towardsdatascience.com/langchain-question-answering-agent-over-docs-18e5585bdbd3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/langchain-question-answering-agent-over-docs-18e5585bdbd3](https://towardsdatascience.com/langchain-question-answering-agent-over-docs-18e5585bdbd3)
- en: '![](../Images/1c8d2ceae9a87852899c61a5f3be5e5c.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c8d2ceae9a87852899c61a5f3be5e5c.png)'
- en: Photo by [Mike Alonzo](https://unsplash.com/@mikezo?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Mike Alonzo](https://unsplash.com/@mikezo?utm_source=medium&utm_medium=referral)
    提供的照片，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Learn about embeddings and agents to build a QA application
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解嵌入和代理以构建问答应用
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----18e5585bdbd3--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----18e5585bdbd3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----18e5585bdbd3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----18e5585bdbd3--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----18e5585bdbd3--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcellopoliti?source=post_page-----18e5585bdbd3--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----18e5585bdbd3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----18e5585bdbd3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----18e5585bdbd3--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----18e5585bdbd3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----18e5585bdbd3--------------------------------)
    ·6 min read·Jun 4, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----18e5585bdbd3--------------------------------)
    ·6 分钟阅读·2023年6月4日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: One of the most common use cases in the NLP field is **question-answering related
    to documents**. For example, imagine feeding a pdf or perhaps multiple pdf files
    to the machine and then asking questions related to those files. This can be useful,
    for example, if you have to prepare for a university exam and want to ask the
    machine about things you didn’t understand. Actually, a more advanced use case
    would be to ask the machine to ask you questions to perform a sort of mock interrogation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理领域，最常见的用例之一是**与文档相关的问答**。例如，想象一下将一个或多个 PDF 文件输入到机器中，然后询问与这些文件相关的问题。这可能很有用，比如当你需要为大学考试做准备时，并且想要向机器询问你不理解的内容。实际上，一个更高级的用例是让机器向你提问，进行一种模拟审问。
- en: A lot of research has been done to solve this task and many tools have been
    developed, but today we can use the power of Large Language Models (LLMs) such
    as ag example GPT-3 from OpenAI and beyond.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个任务，已经做了大量研究并开发了许多工具，但今天我们可以利用大型语言模型（LLMs）的力量，例如 OpenAI 的 GPT-3 及更高版本。
- en: LangChain is a very recent library that allows us to manage and create applications
    based on LLMs. In fact, the **LLM is just one part of a much more complex AI architecture**.
    When we create a system like this we do not only have to make queries to the OpenAI
    models and get a response, but for example save this response, structure the prompt
    properly etc.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个非常新的库，它允许我们管理和创建基于 LLM 的应用程序。实际上，**LLM 只是一个更复杂的 AI 架构中的一部分**。当我们创建这样一个系统时，我们不仅需要向
    OpenAI 模型提出查询并获得响应，还需要例如保存这个响应、正确结构化提示等。
- en: In this article, we see how to build a simple Question Answering over Docs application
    using LangChain and OpenAI.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将看到如何使用 LangChain 和 OpenAI 构建一个简单的文档问答应用。
- en: Embeddings
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入
- en: 'In this application, we will make use of a library called ChromaDB. This is
    an open-source library that allows us to save embeddings. Here a question might
    arise: **But what are embeddings?**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个应用中，我们将使用一个叫做 ChromaDB 的库。这是一个开源库，允许我们保存嵌入。这里可能会出现一个问题：**那么什么是嵌入？**
- en: '**An embedding is nothing more than a projection in a vector space of a word**
    (or text).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**嵌入不过是词（或文本）在向量空间中的投影**。'
- en: 'I try to explain myself in a simpler way. Suppose we have the following words
    available: “king,” “queen,” “man,” and “woman.”'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我尝试用更简单的方式来解释自己。假设我们有以下几个词可用：“king”，“queen”，“man”和“woman”。
- en: We people from our experience intuitively understand distances between these
    words. For example, man is closer to king conceptually than queen. But machines
    are not intuitive they need data and metrics to work. So what we do is turn these
    words into data on a Cartesian space so that this intuitive concept of distance
    is represented accurately.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据经验直观地理解这些词之间的距离。例如，“man”在概念上比“queen”更接近“king”。但机器不具备直观能力，它们需要数据和指标来工作。所以我们做的是将这些词转化为笛卡尔空间中的数据，以便准确表示这种直观的距离概念。
- en: '![](../Images/bf99a853a4b7a26870f0caba5f8a1656.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf99a853a4b7a26870f0caba5f8a1656.png)'
- en: Embedding Example (Image By Author)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入示例（图片由作者提供）
- en: In the image above we have an example (dummy) of embeddings. We see that Man
    is much closer to King than to the other words, and the same is true for woman
    and queen.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图像中，我们有一个嵌入（虚拟）的示例。我们看到“Man”比其他单词更接近“King”，同样“woman”和“queen”也是如此。
- en: Another interesting thing is that **the distance between man and king is the
    same as that between woman and queen**. So somehow it seems that this embedding
    has really captured the essence of these words.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的事情是**“man”和“king”之间的距离与“woman”和“queen”之间的距离是相同的**。所以某种程度上，这个嵌入确实捕捉到了这些词的本质。
- en: Another thing to specify though is that of the metric, i.e. how the **distance**
    is measured. In most cases, this is measured using **cosin similarity** i.e. using
    the cosine of the angle between two embeddings.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要说明的事情是度量标准，即如何测量**距离**。在大多数情况下，这是使用**余弦相似度**来测量的，即使用两个嵌入之间角度的余弦值。
- en: '![](../Images/80e63e7fcd76cf55f4640b7248e5b062.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80e63e7fcd76cf55f4640b7248e5b062.png)'
- en: Cosin Similarity (Image By Author)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度（图片由作者提供）
- en: The embedding in my example has only two dimensions, two axes. But the embeddings
    that are created by modern algorithms like BERT have **hundreds or thousands of
    axes**, so it’s hard to understand why the algorithm put text at a particular
    point in space.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我在示例中的嵌入只有两个维度，两条轴。但现代算法如BERT创建的嵌入有**数百或数千条轴**，所以很难理解算法为什么将文本放置在空间中的特定位置。
- en: In this [demo](https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/), you can navigate
    a real embedding space in 3 dimensions and see how the words are near or far from
    each other.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个[演示](https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/)中，你可以在3维空间中导航真实的嵌入，并查看单词彼此之间的距离。
- en: Let’s code!
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们开始编程吧！
- en: First of all, we need to install some libraries. Surely we will need Langchain
    and OpenAI to instantiate and manage LLMs.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要安装一些库。我们肯定需要Langchain和OpenAI来实例化和管理LLM。
- en: After that we will go to install ChromaDB and TikToken (the latter is required
    to successfully install ChromaDB)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将安装ChromaDB和TikToken（后者是成功安装ChromaDB所必需的）
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now we need a text file that we are going to work on. In fact, our purpose is
    to ask questions to the LLM about this file. Downloading a file with Python is
    very simple, it can be done with the following commands.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要一个我们要处理的文本文件。事实上，我们的目的是向LLM提问有关这个文件的内容。用Python下载文件非常简单，可以使用以下命令完成。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we import all the classes we will need.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们导入所有需要的类。
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Obviously to use the OpenAI templates, and to do this you have to enter your
    personal API KEY. If you don’t know how to do this you can see [my previous article
    about Langchain](https://medium.com/towards-data-science/develop-applications-powered-by-language-models-with-langchain-d2f7a1d1ad1a).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，要使用OpenAI的模板，你必须输入你的个人API KEY。如果你不知道怎么做，可以查看[我关于Langchain的上一篇文章](https://medium.com/towards-data-science/develop-applications-powered-by-language-models-with-langchain-d2f7a1d1ad1a)。
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In a real application, you will probably have many text files, and you want
    the LLM to figure out in which of these texts is the answer to your question.
    Instead, in this simple example **we break the single text file into multiple
    parts (chunks) and treat each part as a different document**. The model will have
    to figure out which part contains the answer to our question. We break this text
    into multiple parts by assigning each part a maximum length using the commands
    below.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，你可能会有很多文本文件，你希望LLM找出这些文本中哪个包含你问题的答案。在这个简单的例子中，**我们将单个文本文件分成多个部分（块），并将每个部分视为不同的文档**。模型需要找出哪个部分包含我们问题的答案。我们通过使用下面的命令将文本分成多个部分，每部分分配一个最大长度。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We see that 64 parts have been created from the original text.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到从原始文本创建了64个部分。
- en: We can print the different parts individually since they are contained in a
    list.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以逐个打印不同的部分，因为它们被包含在一个列表中。
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now we create an object that we need to save the embeddings of the various parts
    of the created text.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们创建一个对象，用于保存创建的文本各个部分的嵌入。
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: But we want to **save the embeddings in a DB that is persistent** because recreating
    them every time we open the application would be a resource waste. This is where
    ChromaDB helps us. We can create and save the embeddings using text parts, and
    add metadata for each part. In this, the metadata will be strings that name each
    text part.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们希望**将嵌入保存到一个持久化的数据库中**，因为每次打开应用程序时重新创建它们会浪费资源。这就是 ChromaDB 帮助我们的地方。我们可以使用文本片段创建和保存嵌入，并为每个片段添加元数据。在这里，元数据将是命名每个文本片段的字符串。
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now we want to turn docsearch into a retrieval because that will be its purpose.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们希望将 docsearch 转变为检索，因为这将是它的目的。
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We can also see the retriever what distance metric it is using, in this case,
    the default one is similarity as explained in the part on embeddings.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看检索器使用的距离度量，在这种情况下，默认的度量是相似度，如嵌入部分所解释的。
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Finally, we can ask the retriever to take the document that most answers one
    of our queries. The retriever could also take more than one document if necessary.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以要求检索器选择最能回答我们查询的文档。如果有必要，检索器也可以选择多于一份文档。
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Let’s see now how many documents he took and what they contain.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下他提取了多少文档以及这些文档的内容。
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now what we can do is to create an agent. **An agent is able to perform a series
    of steps to solve the user’s task on its own**. Our agent will have to go and
    look through the documents available to it where the answer to the question asked
    is and return that document.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建一个代理。 **代理能够执行一系列步骤来独立完成用户的任务**。我们的代理需要去查看可用的文档，找出回答问题的文档，并返回该文档。
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If we want, we can also create a function to post-process the agent’s output
    so that it is more readable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们还可以创建一个函数来后处理代理的输出，以使其更易读。
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now everything is finally ready, we can use our agent and go and answer our
    queries!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一切终于准备好了，我们可以使用我们的代理来回答我们的查询！
- en: '[PRE17]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Final Thoughts
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束语
- en: In this article, we introduced LangChain, ChromaDB and some explanation about
    embeddings. We saw with a simple example how to save embeddings of several documents,
    or parts of a document, into a persistent database and do retrieval of the desired
    part to answer a user query.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了 LangChain、ChromaDB 以及一些关于嵌入的解释。我们通过一个简单的例子展示了如何将多个文档或文档的部分的嵌入保存到持久化数据库中，并检索所需的部分来回答用户查询。
- en: If you found this article useful follow me here on Medium! [😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得这篇文章有用，可以在 Medium 上关注我！ [😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
- en: The End
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束
- en: '*Marcello Politi*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*马切洛·波利提*'
- en: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [Website](https://marcello-politi.super.site/)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[Linkedin](https://www.linkedin.com/in/marcello-politi/)、[Twitter](https://twitter.com/_March08_)、[Website](https://marcello-politi.super.site/)'
