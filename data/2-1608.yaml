- en: 'Orca: Properly Imitating Proprietary LLMs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Orca: 正确模仿专有LLMs'
- en: 原文：[https://towardsdatascience.com/orca-properly-imitating-proprietary-llms-44ffa0293adb](https://towardsdatascience.com/orca-properly-imitating-proprietary-llms-44ffa0293adb)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/orca-properly-imitating-proprietary-llms-44ffa0293adb](https://towardsdatascience.com/orca-properly-imitating-proprietary-llms-44ffa0293adb)
- en: Leveraging imitation to create high-quality, open-source LLMs…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用模仿来创建高质量的开源LLM…
- en: '[](https://wolfecameron.medium.com/?source=post_page-----44ffa0293adb--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----44ffa0293adb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----44ffa0293adb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----44ffa0293adb--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----44ffa0293adb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----44ffa0293adb--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----44ffa0293adb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----44ffa0293adb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----44ffa0293adb--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----44ffa0293adb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----44ffa0293adb--------------------------------)
    ·16 min read·Sep 30, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----44ffa0293adb--------------------------------)
    ·阅读时长16分钟·2023年9月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/aa2e365a5a760e33e8968360e016c5b1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa2e365a5a760e33e8968360e016c5b1.png)'
- en: (Photo by [Thomas Lipke](https://unsplash.com/@t_lipke?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/p5nDU-d3Y0s?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由 [Thomas Lipke](https://unsplash.com/@t_lipke?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    拍摄，来自 [Unsplash](https://unsplash.com/photos/p5nDU-d3Y0s?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: As research progresses on large language models (LLMs), one key question that
    remains unanswered is whether an existing, high-quality LLM can be used to effectively
    train another LLM. Currently, there is a lot of debate and contention around this
    topic. The recent explosion of open-source imitation models initially indicated
    that proprietary LLMs like ChatGPT could be easily replicated at a low cost. However,
    subsequent research concluded that the evaluation of such models was incomplete
    and misleading, finding that these models actually have large gaps in their comprehension.
    In this overview, we will study work [1] that aims to solve the limitations of
    open-source replicas of proprietary LLMs via a more robust approach. In particular,
    we will see that imitation learning can be made more effective by curating a larger
    dataset with more detailed information.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对大型语言模型（LLMs）研究的深入，一个关键问题尚未得到回答，那就是现有的高质量LLM是否可以有效地用来训练另一个LLM。目前，围绕这一主题存在大量的辩论和争议。最近，开源模仿模型的爆炸性增长最初表明，像ChatGPT这样的专有LLM可以以低成本轻松复制。然而，随后的研究得出结论，这些模型的评估是不完整且具有误导性的，发现这些模型实际上在理解方面存在很大差距。在这次概述中，我们将研究工作[1]，旨在通过更稳健的方法解决专有LLM的开源复制品的局限性。特别是，我们将看到，通过策划一个更大、更详细的数据集，模仿学习可以变得更加有效。
- en: '“As these models continue to evolve and become more powerful, an intriguing
    question arises: Can we use the model itself to supervise its own behavior or
    that of other AI models?” *— from [1]*'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “随着这些模型的不断发展并变得更强大，一个有趣的问题出现了：我们能否利用模型本身来监督其自身行为或其他AI模型的行为？” *— 来源于 [1]*
- en: '![](../Images/b5d588e2b370b7b8a9b08e1c73db02e5.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5d588e2b370b7b8a9b08e1c73db02e5.png)'
- en: (from [1])
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于 [1]）
- en: Background Information
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景信息
- en: Before diving into the overview, we will cover a few ideas related to both LLMs
    and deep learning in general. These concepts might not be explicitly described
    in papers that we read. Rather, they are oftentimes referenced via a citation
    or assumed to be common knowledge. So, getting a basic grasp of these concepts
    will make this overview, and the papers it considers, easier to understand.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入概述之前，我们将介绍一些与LLM和深度学习相关的概念。这些概念可能在我们阅读的论文中没有明确描述，而是通过引用或被假定为常识。因此，了解这些基本概念将使这次概述及其涉及的论文更容易理解。
- en: Instruction Tuning
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指令调整
- en: '![](../Images/c8d38ae3d4bd9110c4cff154b7fbaf7f.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8d38ae3d4bd9110c4cff154b7fbaf7f.png)'
- en: (from [12])
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [12]）
- en: Instruction tuning was originally proposed by [FLAN](https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html)
    [12] and aimed to provide a form of training that teaches LLMs to solve language-based
    tasks in general, rather than a specific task. In particular, this is done by
    fine-tuning an LLM over sets of “instructions”, or input prompts — including a
    description of the task being solved — combined with the desired model output;
    see above. Recent LLMs mostly use a specific variant of instruction tuning that
    fine-tunes the LLM over examples of dialogue sessions, either from humans or another
    LLM. Usually, instruction tuning is a fine-tuning step that occurs after pre-training;
    see below.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 指令调整最初由[FLAN](https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html)
    [12] 提出，旨在提供一种训练形式，教会大语言模型（LLM）解决语言基础任务，而不是特定任务。具体而言，这通过对一组“指令”或输入提示进行微调来完成——包括解决的任务描述——以及期望的模型输出；见上文。最近的大语言模型主要使用一种特定的指令调整变体，该变体通过人类或其他LLM的对话示例对LLM进行微调。通常，指令调整是在预训练之后进行的微调步骤；见下文。
- en: '![](../Images/bc50710db511a3bada2f4cb0daad823a.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc50710db511a3bada2f4cb0daad823a.png)'
- en: Instruction tuning versus other common training paradigms (from [12])
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 指令调整与其他常见训练范式（来自 [12]）
- en: '**Synthetic instruction tuning.** Although humans can manually create data
    for instruction tuning, we can also synthetically generate this data using an
    LLM. There are two basic approaches for this:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**合成指令调整。** 尽管人类可以手动创建用于指令调整的数据，我们也可以使用LLM合成生成这些数据。有两种基本方法：'
- en: Obtain example dialogue sessions from another model (e.g., from [ShareGPT](https://sharegpt.com/)).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从另一个模型获取示例对话会话（例如，从[ShareGPT](https://sharegpt.com/)）。
- en: Use a prompting framework (e.g., self-instruct [9]) to generate and refine high-quality
    dialogue examples with an LLM.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用提示框架（例如，自我指令 [9]）来生成和完善高质量的对话示例。
- en: Both of these approaches are valid, but they have their limitations. For example,
    public examples of LLM dialogues tend to be biased towards certain tasks, such
    as creative content generation or information-seeking dialogue. Additionally,
    dialogues that are generated via self-instruct [9] tend to lack complexity, though
    this issue was mitigated by the Evol-Instruct [2] strategy that explicitly instructs
    and guides the LLM towards more complex generations; see below.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法都是有效的，但它们各有局限。例如，公共LLM对话示例往往偏向于某些任务，例如创意内容生成或信息获取对话。此外，通过自我指令 [9] 生成的对话往往缺乏复杂性，尽管这个问题通过
    Evol-Instruct [2] 策略得到了缓解，该策略明确指示和引导LLM生成更复杂的内容；见下文。
- en: '![](../Images/49975962b82c40126f3428356f0a679b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49975962b82c40126f3428356f0a679b.png)'
- en: (from [2])
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [2]）
- en: The System Message
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统消息
- en: '![](../Images/84ce6262f12aabed338df5010f0520f5.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/84ce6262f12aabed338df5010f0520f5.png)'
- en: (from OpenAI API documentation)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 OpenAI API 文档）
- en: Most chat-based LLMs that we interact with allow us to provide a system message;
    see above. This message is basically an instruction to the model that describes
    how it is expected to behave or respond to the user. In the [chat markup language](https://github.com/openai/openai-python/blob/main/chatml.md)
    used by ChatGPT and GPT-4 APIs, this system message is given the “system” role
    — as opposed to “user” or “assistant” — within a chat history. Generally, the
    system message is where we should place any instructions that should be followed
    by the LLM throughout the dialogue session with a user.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们互动的大多数基于聊天的LLM允许我们提供系统消息；见上文。该消息基本上是对模型的指令，描述了期望其如何对用户做出反应。在ChatGPT和GPT-4
    API使用的[聊天标记语言](https://github.com/openai/openai-python/blob/main/chatml.md)中，该系统消息被赋予“系统”角色——与“用户”或“助手”相对——在聊天记录中。通常，系统消息是我们应该放置在与用户对话过程中LLM应遵循的任何指令的地方。
- en: '**Modern LLMs are steerable.** Although prior LLMs (e.g., early versions of
    GPT-3.5-turbo) did not pay much attention to the system message, current models
    (e.g., GPT-4) are much more steerable. This means that we can provide detailed
    instructions in the system message for the LLM to follow. In practice, this property
    of modern LLMs can be leveraged to tweak their style or format (via the system
    message) to exactly match the application or task we are solving.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**现代大型语言模型是可引导的。** 尽管以前的大型语言模型（例如早期版本的 GPT-3.5-turbo）对系统消息关注不多，但当前的模型（例如 GPT-4）则更具引导性。这意味着我们可以在系统消息中提供详细的指示，以供大型语言模型遵循。在实践中，现代大型语言模型的这一特性可以用来调整它们的风格或格式（通过系统消息），以精确匹配我们正在解决的应用或任务。'
- en: Other Useful Ideas
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他有用的想法
- en: '*Knowledge distillation and model imitation*: we have explained this idea extensively
    in prior overviews, but it is incredibly relevant to the analysis presented within
    this overview. [[link](/knowledge-distillation-simplified-dd4973dbc764)]'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*知识蒸馏和模型模仿*：我们在之前的综述中已经详细解释了这个概念，但它与本综述中提出的分析非常相关。[[link](/knowledge-distillation-simplified-dd4973dbc764)]'
- en: '*Packing technique*: This is a trick used in [1] that simply concatenates multiple
    text sequences into a single example during training to avoid excessive padding
    after each sequence and improve efficiency. [[link]](https://arxiv.org/abs/2107.02027)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*打包技术*：这是在[1]中使用的一个技巧，简单地将多个文本序列连接成一个单一示例进行训练，以避免在每个序列后面过多的填充，并提高效率。[[link]](https://arxiv.org/abs/2107.02027)'
- en: '*Chain of Thought Prompting [13]*: We have seen that encouraging an LLM to
    produce a problem-solving rationale along with its answer to a problem improves
    reasoning capabilities. Explanation tuning (more details to come) in [1] has a
    lot of fundamental similarities to this technique. [[link](/chain-of-thought-prompting-for-llms-33c963eead38)]'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*思维链提示[13]*：我们已经看到，鼓励大型语言模型在回答问题时给出问题解决的理由，可以提高推理能力。在[1]中的解释调优（更多细节稍后提供）与这种技术有很多基本的相似之处。[[link](/chain-of-thought-prompting-for-llms-33c963eead38)]'
- en: '*Curriculum or progressive learning*: Instead of just training a model over
    all of the data that we have, we could form a particular strategy or curriculum
    for exposing this data to our model. In the case of [1], this curriculum involves
    first training the model over dialogue examples from ChatGPT, then performing
    further training over GPT-4 dialogue. This term is quite generic, as many different
    types of curriculums may exist. [[link](https://ronan.collobert.com/pub/2009_curriculum_icml.pdf)]'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*课程或渐进学习*：我们可以制定一个特定的策略或课程来展示这些数据给模型，而不仅仅是训练一个模型处理我们所有的数据。在[1]的案例中，这个课程包括首先用
    ChatGPT 的对话示例训练模型，然后在 GPT-4 对话上进一步训练。这个术语相当通用，因为可能存在许多不同类型的课程。[[link](https://ronan.collobert.com/pub/2009_curriculum_icml.pdf)]'
- en: The Explosion of Open-Source LLMs
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源大型语言模型的爆炸性增长
- en: '![](../Images/43f9217027b2c0d3710dfd5b0939ad45.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43f9217027b2c0d3710dfd5b0939ad45.png)'
- en: The future for open-source LLMs is *almost* as bright as this photo (from DreamStudio)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 开源大型语言模型的未来*几乎*和这张照片一样光明（来自 DreamStudio）
- en: As LLMs began to increase in popularity, the most impactful models (e.g., GPT-3
    and ChatGPT) were initially available only via paid, proprietary APIs. As we have
    learned in recent overviews, however, there is a burgeoning movement in the LLM
    community to create powerful open-source models! Many open-source models have
    been proposed, but this movement was especially catalyzed by the recent proposal
    of [LLaMA](/llama-llms-for-everyone-724e737835be) [4], a suite of high-performing
    base models of various sizes that are trained solely on publicly-available data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型的受欢迎程度不断上升，最具影响力的模型（例如 GPT-3 和 ChatGPT）最初仅通过付费的专有 API 提供。然而，正如我们在最近的综述中了解到的那样，LLM
    社区正在蓬勃发展，致力于创建强大的开源模型！虽然已经提出了许多开源模型，但这一运动特别受到最近提出的[LLaMA](/llama-llms-for-everyone-724e737835be)
    [4]的推动，这是一套高性能的基础模型，具有不同的规模，仅在公开数据上进行训练。
- en: LLaMA and Imitation Models
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLaMA 和模仿模型
- en: '![](../Images/2f27039e169556225fa10f83af270cb3.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f27039e169556225fa10f83af270cb3.png)'
- en: Derivative models created from LLaMA (from [5, 6, 7, 8])
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从 LLaMA 创建的衍生模型（来自[5, 6, 7, 8]）
- en: The weights of LLMs within the LLaMA suite were openly released (for research
    purposes) and then subsequently leaked online for anyone to access. Following
    this leak, LLaMA quickly gained in popularity and was used to create a variety
    of open-source derivative models, which we have explored in prior overviews.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA 套件中的 LLM 权重已公开发布（用于研究目的），随后在线泄露，任何人都可以访问。此泄露事件后，LLaMA 快速获得了人气，并被用于创建各种开源衍生模型，我们在之前的概述中已进行了探讨。
- en: 'Beyond LLaMA: The Power of Open LLMs [[link](/beyond-llama-the-power-of-open-llms-cef807a54a4f)]'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超越 LLaMA：开源 LLM 的力量 [[link](/beyond-llama-the-power-of-open-llms-cef807a54a4f)]
- en: Imitation Models and the Open-Source LLM Revolution [[link](/imitation-models-and-the-open-source-llm-revolution-431ce48d4bae)]
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模仿模型与开源 LLM 革命 [[link](/imitation-models-and-the-open-source-llm-revolution-431ce48d4bae)]
- en: Such LLaMA derivatives were primarily created using an imitation approach that
    instruction tunes LLaMA over dialogue examples from a more powerful model (e.g.,
    ChatGPT). These imitation models were proposed in quick succession and seemed
    to perform really well — *even on par with powerful models like ChatGPT in certain
    cases* [6]. This led the LLM community to believe that proprietary LLMs could
    be easily replicated, but there’s a bit more to the story than that.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 LLaMA 衍生模型主要是通过模仿方法创建的，该方法在来自更强大模型（例如 ChatGPT）的对话示例上调整 LLaMA。这些模仿模型接连被提出，似乎表现非常好——*在某些情况下甚至与像
    ChatGPT 这样的强大模型相媲美* [6]。这使得 LLM 社区相信专有 LLM 可以很容易地被复制，但事情比这要复杂一些。
- en: '![](../Images/5c40c5f2dfe0e9330bd6c06ffcacd555.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c40c5f2dfe0e9330bd6c06ffcacd555.png)'
- en: (from [3])
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [3]）
- en: '**Imitation or limitation?** Although imitation models seem to perform well,
    we see in prior work [3] that this is only the case on the small subset of tasks
    that are observed during fine-tuning. Namely, most imitation models capture the
    style of proprietary LLMs like ChatGPT, but they fail to capture the knowledge,
    reasoning capabilities, and comprehension of these models. Such limitations can
    easily be missed within human evaluations of a model, as verifying whether a model’s
    information is factually correct requires a significant time investment.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**模仿还是限制？** 尽管模仿模型似乎表现良好，但我们在之前的工作 [3] 中看到，这仅在微调过程中观察到的小部分任务中适用。即，大多数模仿模型捕捉了像
    ChatGPT 这样的专有 LLM 的风格，但它们未能捕捉这些模型的知识、推理能力和理解能力。这种限制在人类对模型的评估中很容易被忽视，因为验证模型的信息是否事实正确需要大量时间投入。'
- en: '![](../Images/ef6657ad497e0465de0db523849f8a6f.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef6657ad497e0465de0db523849f8a6f.png)'
- en: (from [1])
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: Because modern LLMs are so good at generating coherent text, the differences
    between them can be difficult to measure, especially when the models being compared
    have a similar style and fluency. When imitation models are more rigorously evaluated
    using a broad set of quantitative benchmarks, we begin to clearly see their shortcomings.
    For example, the performance of Vicuna [6] — one of the higher-performing imitation
    models created with LLaMA — is seen to fall far short of ChatGPT on more difficult
    and complex benchmarks; see above.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于现代 LLM 在生成连贯文本方面非常出色，它们之间的差异可能难以测量，尤其是当被比较的模型具有相似的风格和流畅度时。当模仿模型通过广泛的定量基准进行更严格的评估时，我们开始清楚地看到它们的不足之处。例如，Vicuna
    [6] 的表现——这是用 LLaMA 创建的较高性能的模仿模型之一——在更困难和复杂的基准测试中远远落后于 ChatGPT；见上文。
- en: Why is imitation not working?
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么模仿没有效果？
- en: 'When we study existing attempts at creating open-source replicas of proprietary
    LLMs via an imitation approach, most issues that we see are caused by the same
    problem: *we don’t have enough high-quality data for instruction tuning*. There
    are three basic ways in which we can generate this data:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们研究通过模仿方法创建开源专有 LLM 的现有尝试时，我们看到的大多数问题都由相同的问题造成：*我们没有足够的高质量数据用于指令调整*。我们可以生成这些数据的三种基本方法是：
- en: Ask humans to generate the data
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让人类生成数据
- en: Use a prompting framework (e.g., self-instruct [9]) to generate synthetic data
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用提示框架（例如，自我指导 [9]）生成合成数据
- en: Directly train on the outputs of existing LLMs
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接在现有 LLM 的输出上进行训练
- en: Popular LLMs like GPT-4 are trained over extensive amounts of human feedback,
    but generating data from humans is expensive and time consuming. To automate the
    collection of data, recent imitation models rely upon some variant of self-instruct
    [9] to generate a synthetic — *meaning the data is generated by an LLM rather
    than a human* — fine-tuning dataset. Unfortunately, datasets generated in this
    manner tend to lack in diversity and complexity. Plus, we run into similar problems
    when directly fine-tuning on LLM dialogues obtained from public APIs or ShareGPT.
    These datasets tend to be small-scale and homogenous, which is insufficient for
    creating a powerful imitation model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 像GPT-4这样的流行LLMs在大量人类反馈上进行训练，但生成数据是昂贵且耗时的。为了自动化数据收集，近期的模仿模型依赖于某种变体的自我指导[9]来生成合成——*即数据是由LLM生成而非人类*——微调数据集。不幸的是，这种方式生成的数据集往往缺乏多样性和复杂性。而且，当直接在从公共API或ShareGPT获取的LLM对话上进行微调时，我们也会遇到类似的问题。这些数据集往往规模小且同质化，这对于创建强大的模仿模型是不足够的。
- en: “We conclude that broadly matching ChatGPT using purely imitation would require
    a concerted effort to collect enormous imitation datasets and far more diverse
    and higher quality imitation data than is currently available.” *— from [3]*
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们得出结论，纯粹通过模仿广泛匹配ChatGPT需要全力收集巨大的模仿数据集，并且需要比目前可用的数据更为多样化和高质量的模仿数据。” *— 来自[3]*
- en: '**The path forward.** Although existing attempts at using imitation have fallen
    short, there are a few different ways we can move forward. As proposed in [3],
    we could begin by creating more powerful, open-source base LLMs that could serve
    as a better “starting point” for instruction tuning. Prior work shows that using
    a better underlying base LLM drastically improves the performance of resulting
    imitation models. This area is already being extensively explored, as we see with
    the proposal of awesome, open-source foundation models like [Falcon](https://falconllm.tii.ae/)
    or [MPT](https://www.mosaicml.com/blog/mpt-7b).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**前进的道路。** 尽管现有的模仿尝试未能达到预期，但我们可以有几种不同的前进方式。如[3]中所提，我们可以从创建更强大的开源基础LLMs开始，这些基础LLMs可以作为更好的“起点”进行指令调优。之前的工作表明，使用更好的基础LLM可以显著提高结果模仿模型的性能。我们看到，像[Falcon](https://falconllm.tii.ae/)或[MPT](https://www.mosaicml.com/blog/mpt-7b)这样令人惊叹的开源基础模型的提案已经在广泛探索这个领域。'
- en: '![](../Images/0f2aea22ef791196f73a0bcc7c430404.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f2aea22ef791196f73a0bcc7c430404.png)'
- en: (from [1])
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: (来自[1])
- en: 'Alternatively, we could consider ways to improve or expand existing datasets
    used for imitation learning. Current work relies solely upon prompt and response
    pairs generated from an LLM; see above. Within this overview, we will refer to
    such dialogues as “shallow” imitation examples, as they only contain information
    about the proprietary LLM’s response to a prompt. Going beyond shallow imitation,
    this overview will explore the idea of augmenting synthetic instruction tuning
    datasets with more detailed outputs from the proprietary LLM, such as:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们可以考虑改进或扩展现有的用于模仿学习的数据集。目前的工作仅依赖于LLM生成的提示和响应对；见上文。在这个概述中，我们将把这些对话称为“浅层”模仿示例，因为它们仅包含关于专有LLM对提示的响应的信息。超越浅层模仿，本概述将探讨通过专有LLM提供的更详细输出来增强合成指令调优数据集的想法，例如：
- en: Explanation traces
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释跟踪
- en: Step-by-step thought processes
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步思考过程
- en: Complex instructions
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂指令
- en: The imitation model can learn from extra information produced by a proprietary
    model during fine-tuning. We want imitation datasets that are large and diverse.
    In this overview, however, *we will see that the type and granularity of data
    used can make a huge difference too*. Such extra information can allow smaller,
    open-source LLMs to learn the reasoning process followed by a more powerful model.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 模仿模型可以从专有模型在微调过程中生成的额外信息中学习。我们希望模仿数据集大而多样。然而，在这个概述中，*我们将看到使用的数据类型和粒度也可以产生巨大的差异*。这些额外信息可以让较小的开源LLMs学习到更强大模型所遵循的推理过程。
- en: Properly Learning to Imitate
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正确学习模仿
- en: '![](../Images/e03790ccb1f21e9b300fe606752c30b0.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e03790ccb1f21e9b300fe606752c30b0.png)'
- en: (from [1])
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: (来自[1])
- en: 'Aiming to mitigate issues with existing imitation models, authors in [1] propose
    a 13 billion parameter imitation LLM, referred to as Orca. Like prior imitation
    models, Orca is based upon the LLaMA suite of LLMs, but it is fine-tuned using
    more than just a small set of “shallow” imitation examples. More specifically,
    Orca differentiates itself from prior work in two main ways:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解现有模仿模型的问题，文献 [1] 中的作者提出了一个 130 亿参数的模仿 LLM，称为 Orca。与先前的模仿模型类似，Orca 基于 LLaMA
    系列的 LLMs，但它使用的不仅仅是一小部分“浅层”模仿示例进行微调。更具体地说，Orca 在两个主要方面与先前的工作有所不同：
- en: A much larger and more comprehensive imitation dataset
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个更大、更全面的模仿数据集
- en: Injecting detailed explanation traces into each instruction tuning example
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个指令调优示例中注入详细的解释痕迹
- en: The resulting model performs quite well across a variety of benchmarks, allowing
    the gap between imitation models and proprietary LLMs (e.g., ChatGPT or GPT-4)
    to be narrowed; see below. As we will see, however, GPT-4 is still much better.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 结果模型在各种基准测试中表现相当出色，从而缩小了模仿模型与专有 LLMs（例如，ChatGPT 或 GPT-4）之间的差距；见下文。然而，正如我们将看到的，GPT-4
    仍然要好得多。
- en: '![](../Images/ac3c1df91a5f7cd798c77e2983632919.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac3c1df91a5f7cd798c77e2983632919.png)'
- en: (from [1])
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: '**Bigger and better data.** Orca selectively samples tasks from the [FLAN collection](https://ai.googleblog.com/2023/02/the-flan-collection-advancing-open.html)
    [10] — a massive data source for instruction tuning — and acquires millions of
    responses from both ChatGPT and GPT-4 over complex prompts from each of these
    tasks. Using the system message, authors encourage these models to explain their
    response with added details, thus providing an “explanation trace” for each output
    generated by an LLM. Such an approach has a massive impact on model quality, as
    it provides a richer source of information from which the imitation model can
    learn. We will refer to this approach as “explanation tuning” — it’s just instruction
    tuning over data that contains explanation traces!'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**更大更好的数据。** Orca 从 [FLAN collection](https://ai.googleblog.com/2023/02/the-flan-collection-advancing-open.html)
    [10] —— 一个用于指令调优的大型数据源 —— 中有选择地抽取任务，并从这些任务中的复杂提示中获取了来自 ChatGPT 和 GPT-4 的数百万个回应。通过系统消息，作者鼓励这些模型用更多细节解释其回应，从而为每个由
    LLM 生成的输出提供“解释痕迹”。这种方法对模型质量有着巨大影响，因为它提供了一个更丰富的信息来源，从中模仿模型可以学习。我们将这种方法称为“解释调优”——它只是对包含解释痕迹的数据进行的指令调优！'
- en: “Our research indicates that learning from step-by-step explanations, whether
    these are generated by humans or more advanced AI models, is a promising direction
    to improve model capabilities and skills.” *— from [1]*
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们的研究表明，无论这些逐步解释是由人类还是更先进的 AI 模型生成的，逐步解释的学习都是提升模型能力和技能的一个有前途的方向。” *— 来自 [1]*
- en: '**Relation to prior work.** In a prior overview, we saw that LLaMA-based imitation
    models fall far short of imitating proprietary LLMs. To close the capability gap
    between imitation models and proprietary LLMs, we would need an imitation dataset
    that is significantly larger and more diverse. Prior work in [3] claims that obtaining
    such a dataset is too difficult, indicating that imitation models are a dead end.
    However, authors in [1] do exactly this (i.e., generate a massive and complex
    imitation dataset) to achieve a breakthrough in imitation model quality.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**与先前工作的关系。** 在先前的概述中，我们看到基于 LLaMA 的模仿模型远远不能模仿专有 LLMs。为了缩小模仿模型与专有 LLMs 之间的能力差距，我们需要一个显著更大和更多样化的模仿数据集。文献
    [3] 中的先前工作声称获取这样的数据集太困难，表明模仿模型是一条死胡同。然而，文献 [1] 中的作者正是这样做的（即，生成一个大规模且复杂的模仿数据集），以实现模仿模型质量的突破。'
- en: A better approach for imitation learning…
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更好的模仿学习方法…
- en: '![](../Images/7b9072ba778737ec19d4a1d445e050f9.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b9072ba778737ec19d4a1d445e050f9.png)'
- en: (from [1])
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: Orca’s breakthrough in imitation model quality can be attributed to its much
    larger, more detailed, and more complex imitation dataset; see above. Let’s explore
    the details of this dataset, focusing upon how proprietary models can be prompted
    to output step-by-step problem solving explanations that are a much more powerful
    learning signal for open-source imitation models.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Orca 在模仿模型质量上的突破可以归因于其更大、更详细和更复杂的模仿数据集；见上文。让我们探索这个数据集的细节，重点关注专有模型如何被提示以输出逐步问题解决解释，这对于开源模仿模型是一个更强大的学习信号。
- en: '**Explanation tuning.** Prior imitation models are trained over pairs of prompts
    and associated responses generated from an LLM. Although this approach can teach
    the imitation model to replicate or memorize the teacher model’s output, there
    is not much else that can be learned from the model’s response alone — *this information
    is shallow and lacks information regarding how or why a response was produced*.
    In [1], authors explore an alternative approach that trains an imitation model
    how to replicate the reasoning process of the teacher model.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**解释调优。** 之前的模仿模型是在由LLM生成的提示和相关回应对上进行训练的。虽然这种方法可以教会模仿模型复制或记忆教师模型的输出，但仅从模型的回应中学到的东西不多——*这些信息浅显且缺乏有关回应是如何产生的或为何产生的详细信息*。在[1]中，作者探索了一种替代方法，该方法训练模仿模型如何复制教师模型的推理过程。'
- en: '![](../Images/4fad24ff73bd29073af67758d1c019e9.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fad24ff73bd29073af67758d1c019e9.png)'
- en: (from [1])
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于[1])
- en: To do this, we just need to prompt the teacher model to output a detailed explanation
    along with its normal response. Drawing upon ideas like zero-shot CoT prompting
    [11], we can encourage the model to produce detailed explanations with each of
    its responses by just tweaking the system message; see above. Then, we can fine-tune
    the imitation model using both the response and the explanation as a training
    signal. As we have seen in prior work [11], teaching an LLM to output such detailed
    explanation traces with each of its answers can lead to large improvements on
    reasoning tasks and complex instruction following.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们只需要提示教师模型输出详细解释以及其正常回应。借鉴零样本CoT提示的思想[11]，我们可以通过调整系统消息来鼓励模型在每次回应时提供详细解释；见上文。然后，我们可以利用回应和解释作为训练信号来微调模仿模型。正如我们在先前的工作中所见[11]，教会一个LLM在每次回答时输出如此详细的解释痕迹，可以显著改善推理任务和复杂指令的跟随。
- en: '**Creating the dataset.** To fine-tune Orca, a massive imitation dataset is
    created by sampling from the millions of instructions contained in the [FLAN collection](https://ai.googleblog.com/2023/02/the-flan-collection-advancing-open.html)
    as shown in the table below. The resulting set of instructions is called FLAN-5M.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建数据集。** 为了微调Orca，通过从[FLAN collection](https://ai.googleblog.com/2023/02/the-flan-collection-advancing-open.html)中包含的数百万条指令中采样来创建一个大规模的模仿数据集，如下表所示。结果数据集称为FLAN-5M。'
- en: '![](../Images/27576e84516dfa4980a245c06adea32a.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27576e84516dfa4980a245c06adea32a.png)'
- en: (from [1])
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于[1])
- en: The FLAN-5M instruction set is augmented with responses and explanations from
    ChatGPT obtained with the OpenAI API. Similarly, using a smaller set of sampled
    instructions called FLAN-1M (i.e., we basically just sub-sample the original set
    of 5M instructions), a similar procedure is performed using GPT-4, producing a
    dataset of 6 million total instruction examples paired with a response and explanation
    from a proprietary teacher model. Interestingly, authors in [1] note that collecting
    data from each of these models takes several weeks — even using the [Azure OpenAI
    service](https://azure.microsoft.com/en-us/products/cognitive-services/openai-service)
    — due to rate limits; see below.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: FLAN-5M指令集通过使用OpenAI API从ChatGPT获得的回应和解释进行增强。同样，使用一组称为FLAN-1M的较小采样指令集（即，我们基本上只是从原始的5M指令集中进行子采样），使用GPT-4执行类似程序，生成一个总计600万条指令示例的数据集，每条指令配有来自专有教师模型的回应和解释。有趣的是，[1]中的作者指出，从每个模型收集数据需要几周时间——即使使用[Azure
    OpenAI service](https://azure.microsoft.com/en-us/products/cognitive-services/openai-service)——由于速率限制；见下文。
- en: '![](../Images/1ef12119d4941653f4cad25f0542c231.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ef12119d4941653f4cad25f0542c231.png)'
- en: (from [1])
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于[1])
- en: '**Progressive learning.** Instead of training on all of this data together,
    we can achieve improved performance by fine-tuning Orca over ChatGPT-based explanations
    first, then fine-tuning on explanations from GPT-4 afterwards. Given that Orca
    is based upon a smaller LLaMA model that is significantly less powerful than proprietary
    LLMs, this progressive learning approach allows the imitation model to first learn
    from “easier” examples, prior to learning from the more detailed explanations
    of a powerful model like GPT-4\. The positive impact of this approach is likely
    due to the fact that GPT-4 tends to produce longer and more intricate explanations
    that are harder to learn from; see below.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**渐进学习。** 我们可以通过首先在 ChatGPT 基础上的解释中微调 Orca，然后再在 GPT-4 的解释中微调，从而在所有数据上训练时实现性能的提升。鉴于
    Orca 基于一个较小的 LLaMA 模型，这个模型的能力明显低于专有 LLM，这种渐进学习方法使得模仿模型能够先从“较简单”的例子中学习，然后再从像 GPT-4
    这样强大的模型的更详细解释中学习。这种方法的积极影响可能源于 GPT-4 往往生成较长且复杂的解释，这些解释更难以学习；见下文。'
- en: '![](../Images/716fc54e5415f1258cd7bd4a5e509a10.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/716fc54e5415f1258cd7bd4a5e509a10.png)'
- en: (from [1])
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [1])
- en: Explanation-based imitation learning is effective!
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于解释的模仿学习是有效的！
- en: Orca is compared to a variety of different baselines, including Vicuna [6],
    text-davinci-003 (i.e., GPT-3.5), ChatGPT, and GPT-4\. Authors in [1] consider
    a suite of different benchmarks that include writing, comprehension, and reasoning
    tasks; see below. Orca’s evaluation strategy is made quite comprehensive as to
    avoid the issues with misleading or incomplete evaluation results that plagued
    prior imitation models. Notably, we see in [1] that benchmarks composed of standardized
    tests offer a surprisingly robust evaluation framework.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Orca 与多种不同的基准进行比较，包括 Vicuna [6]、text-davinci-003（即 GPT-3.5）、ChatGPT 和 GPT-4。文献
    [1] 中的作者考虑了一系列不同的基准，包括写作、理解和推理任务；见下文。Orca 的评估策略被做得非常全面，以避免先前模仿模型所遇到的误导或不完整的评估结果问题。值得注意的是，我们在
    [1] 中看到，由标准化测试组成的基准提供了一个令人惊讶的强大评估框架。
- en: '![](../Images/81bd7c8cc3bd62dd067638ff6628b4b3.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81bd7c8cc3bd62dd067638ff6628b4b3.png)'
- en: (from [1])
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [1])
- en: '**Open-ended generation.** When evaluated on open-ended generation tasks, Orca
    outperforms Vicuna by a large margin in all experimental settings; see below.
    Here, performance is measured by considering a reference model (e.g., ChatGPT
    or GPT-4) and prompting GPT-4 to determine whether the output produced by the
    candidate model is better than the reference model’s output.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**开放式生成。** 在开放式生成任务的评估中，Orca 在所有实验设置中都大幅超越了 Vicuna；见下文。在这里，性能通过考虑参考模型（例如，ChatGPT
    或 GPT-4）并提示 GPT-4 来确定候选模型生成的输出是否优于参考模型的输出来衡量。'
- en: '![](../Images/a83e827fa427cf783a7c775e25f02c2c.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a83e827fa427cf783a7c775e25f02c2c.png)'
- en: (from [1])
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [1])
- en: We see in these experiments that Orca maintains 95% of ChatGPT quality and 85%
    of GPT-4 quality across datasets. Although these metrics indicate a significant
    improvement in performance compared to prior imitation models, we should keep
    in mind that [LLM-based evaluations are imperfect](https://ehudreiter.com/2023/05/22/future-of-nlg-evaluation/)
    and still being explored. As such, these results, although positive, could be
    misleading.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这些实验中看到，Orca 在数据集上保持了 ChatGPT 质量的 95% 和 GPT-4 质量的 85%。虽然这些指标表明与先前的模仿模型相比性能有显著改善，但我们应记住
    [LLM 基于评估不完美](https://ehudreiter.com/2023/05/22/future-of-nlg-evaluation/) 且仍在探索中。因此，这些结果虽然积极，但可能会误导。
- en: '**Reasoning.** Orca continues to perform similarly to ChatGPT across reasoning
    benchmarks. For example, across (nearly) all topics on the [AGIEval](https://github.com/microsoft/AGIEval)
    and [BigBench-Hard](https://github.com/suzgunmirac/BIG-Bench-Hard) datasets, Orca
    comes near or exceeds the performance of ChatGPT!'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**推理。** Orca 在推理基准测试中继续表现出与 ChatGPT 相似的性能。例如，在 [AGIEval](https://github.com/microsoft/AGIEval)
    和 [BigBench-Hard](https://github.com/suzgunmirac/BIG-Bench-Hard) 数据集的（几乎）所有主题中，Orca
    的表现接近或超过了 ChatGPT！'
- en: '![](../Images/9edf1f363abb32ca253cc336297ab908.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9edf1f363abb32ca253cc336297ab908.png)'
- en: (from [1])
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [1])
- en: Although Orca’s performance on standardized exams still falls below that of
    ChatGPT in certain cases, we see that work in [1] makes significant progress towards
    bridging the gap with proprietary LLMs compared to prior imitation models; see
    below. Although it might not come as a surprise, GPT-4 is still a clear frontrunner
    in performance across nearly all tasks that are considered.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Orca在标准化考试中的表现仍然低于ChatGPT的某些情况，但我们看到[1]中的工作在弥合专有LLMs与之前模仿模型之间的差距方面取得了显著进展；见下文。尽管这可能并不令人惊讶，但GPT-4在几乎所有被考虑的任务中仍然是明显的领先者。
- en: '![](../Images/2a6edf0269e22616e2e9b5cae27c17bd.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a6edf0269e22616e2e9b5cae27c17bd.png)'
- en: (from [1])
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: （来源于 [1]）
- en: '**Other findings.** Beyond the main empirical results presented in [1], we
    see that the proposed curriculum (or progressive) learning approach — where the
    model is first fine-tuned over 5M ChatGPT dialogue examples then 1M examples from
    GPT-4 — has a large and positive impact on Orca’s performance. Additionally, Orca
    consistently underperforms ChatGPT in modeling long sequences.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**其他发现。** 除了[1]中提出的主要实证结果之外，我们发现建议的课程（或渐进式）学习方法——即模型首先在5M个ChatGPT对话示例上进行微调，然后在1M个GPT-4示例上进行微调——对Orca的性能产生了很大且积极的影响。此外，Orca在建模长序列时始终表现不如ChatGPT。'
- en: Closing Remarks
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结语
- en: “Our findings indicate that Orca significantly outperforms other open-source
    smaller models. Moreover, in some settings, it can match or even surpass the quality
    of ChatGPT, although a substantial gap with GPT-4 still remains.” *— from [1]*
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们的发现表明，Orca在性能上显著优于其他开源较小模型。此外，在一些设置中，它可以匹配甚至超越ChatGPT的质量，但与GPT-4之间仍然存在较大的差距。”
    *— 来源于 [1]*
- en: Research on open-source LLMs is constantly evolving. One week, we think that
    proprietary LLMs have [completely lost their moat](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither),
    and the next week we find out that open-source (imitation) models are far worse
    than originally claimed. Although it seemed like imitation models were a dead
    end only a few weeks ago, we see in this overview that imitation is a valid approach!
    All we need is a bigger and better dataset. The major takeaways from this work
    are outlined below.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对开源LLMs的研究不断发展。一个星期，我们认为专有LLMs已经[完全失去了优势](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)，而下一个星期我们发现开源（模仿）模型远比最初声称的要差。尽管几周前模仿模型似乎是死路一条，但我们在本概述中看到模仿是一种有效的方法！我们所需要的只是更大更好的数据集。这项工作的主要结论如下。
- en: '**Learning from step-by-step instructions.** Prior work on imitation models
    relied upon simple prompt-response pairs for training. We see here that augmenting
    such data with detailed explanation traces allows the resulting model to learn
    from a much richer source of information. Rather than memorizing a model’s response
    for a small set of examples, we can allow the proprietary LLM’s problem-solving
    process to be replicated. As a result, the approach in [1] enables imitation model
    performance to generalize beyond data seen during fine-tuning.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**从逐步说明中学习。** 之前的模仿模型研究依赖于简单的提示-回应对进行训练。我们在这里看到，通过详细的解释轨迹来增强这些数据，使得结果模型能够从更丰富的信息源中学习。我们可以让专有的LLM的解决问题过程被复制，而不是仅仅记住模型在一小部分示例上的回应。因此，文献[1]中的方法使得模仿模型的性能能够超越在微调期间看到的数据。'
- en: “We emphasize the crucial role of data size and coverage when it comes to aligning
    smaller models to their more powerful counterparts, like GPT-4.” *— from [1]*
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们强调了数据规模和覆盖范围在将较小模型对齐到更强大的模型（如GPT-4）时的重要作用。” *— 来源于 [1]*
- en: '**Lots of imitation data.** One of the main problems with prior imitation models
    is that they only performed well on tasks that were similar to data seen in their
    fine-tuning datasets. Given this particular limitation, we clearly need larger
    imitation datasets with more coverage. Although prior work indicated that producing
    such a dataset would be too difficult, we see in [1] that it is possible. Given
    a much larger and more comprehensive dataset (i.e., millions of examples), we
    can make imitation models perform much better than before.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**大量的模仿数据。** 之前模仿模型的一个主要问题是它们仅在与其微调数据集中的数据相似的任务上表现良好。鉴于这一特定限制，我们显然需要更大、覆盖范围更广的模仿数据集。尽管之前的工作表明，生成这样一个数据集会太困难，但我们在[1]中看到这是可能的。鉴于更大且更全面的数据集（即数百万个示例），我们可以使模仿模型比以前表现得更好。'
- en: '**Remaining work.** Orca’s performance, although impressive, still falls short
    of the best proprietary LLMs — *more work has to be done to make open-source LLMs
    truly competitive*. Closing this gap will mostly likely be a product of multiple
    ongoing initiatives, such as imitation learning, creating better foundation models,
    and curating better publicly-available datasets for instruction tuning and LLM
    refinement. However, open-source offerings should not be underestimated, as they
    will continue to improve alongside their proprietary counterparts.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**剩余工作。** 尽管 Orca 的表现令人印象深刻，但仍然不及最佳的专有语言模型——*需要更多工作才能使开源语言模型真正具有竞争力*。弥合这一差距很可能是多项正在进行的倡议的结果，例如模仿学习、创建更好的基础模型以及策划更好的公开数据集用于指令调整和语言模型改进。然而，开源产品不应被低估，因为它们将继续与专有产品一同改进。'
- en: Connect with me!
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与我联系！
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. If you liked this overview, subscribe
    to my [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/),
    where I help readers understand AI research via overviews of relevant topics from
    the ground up. You can also follow me on [X](https://twitter.com/cwolferesearch)
    and [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/), or
    check out my [other writings](https://medium.com/@wolfecameron) on medium!
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢阅读本文。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/)
    的 AI 总监。我研究深度学习的实证和理论基础。如果你喜欢这个概述，订阅我的 [Deep (Learning) Focus 新闻通讯](https://cameronrwolfe.substack.com/)，我将通过从头到尾的相关话题概述帮助读者理解
    AI 研究。你也可以在 [X](https://twitter.com/cwolferesearch) 和 [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/)
    上关注我，或查看我在 medium 上的 [其他著作](https://medium.com/@wolfecameron)！
- en: Bibliography
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Mukherjee, Subhabrata, et al. “Orca: Progressive Learning from Complex
    Explanation Traces of GPT-4.” *arXiv preprint arXiv:2306.02707* (2023).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Mukherjee, Subhabrata 等。“Orca: 从 GPT-4 的复杂解释痕迹中逐步学习。” *arXiv 预印本 arXiv:2306.02707*（2023）。'
- en: '[2] Xu, Can, et al. “Wizardlm: Empowering large language models to follow complex
    instructions.” *arXiv preprint arXiv:2304.12244* (2023).'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Xu, Can 等。“Wizardlm: 赋能大型语言模型以遵循复杂指令。” *arXiv 预印本 arXiv:2304.12244*（2023）。'
- en: '[3] Gudibande, Arnav, et al. “The false promise of imitating proprietary llms.”
    *arXiv preprint arXiv:2305.15717* (2023).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Gudibande, Arnav 等。“模仿专有语言模型的虚假承诺。” *arXiv 预印本 arXiv:2305.15717*（2023）。'
- en: '[4] Touvron, Hugo, et al. “Llama: Open and efficient foundation language models.”
    *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Touvron, Hugo 等。“Llama: 开放且高效的基础语言模型。” *arXiv 预印本 arXiv:2302.13971*（2023）。'
- en: '[5] Taori, Rohan et al. “Stanford Alpaca: An Instruction-following LLaMA model.”
    (2023).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Taori, Rohan 等。“斯坦福 Alpaca: 一款遵循指令的 LLaMA 模型。”（2023）。'
- en: '[6] Chiang, Wei-Lin et al. “Vicuna: An Open-Source Chatbot Impressing GPT-4
    with 90%* ChatGPT Quality.” (2023).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Chiang, Wei-Lin 等。“Vicuna: 一款开源聊天机器人，令人印象深刻的 GPT-4 质量达到 90%*。”（2023）。'
- en: '[7] Geng, Xinyang et al. “Koala: A Dialogue Model for Academic Research.” (2023).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Geng, Xinyang 等。“Koala: 一款用于学术研究的对话模型。”（2023）。'
- en: '[8] Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt, and
    Andriy Mulyar. GPT4All: Training an assistant-style chatbot with large scale data
    distillation from GPT-3.5-Turbo, 2023.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt 和 Andriy
    Mulyar。“GPT4All: 使用从 GPT-3.5-Turbo 提取的大规模数据蒸馏训练助手风格的聊天机器人。”（2023）。'
- en: '[9] Wang, Yizhong, et al. “Self-Instruct: Aligning Language Model with Self
    Generated Instructions.” *arXiv preprint arXiv:2212.10560* (2022).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Wang, Yizhong 等。“Self-Instruct: 将语言模型与自生成指令对齐。” *arXiv 预印本 arXiv:2212.10560*（2022）。'
- en: '[10] Longpre, Shayne, et al. “The flan collection: Designing data and methods
    for effective instruction tuning.” *arXiv preprint arXiv:2301.13688* (2023).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Longpre, Shayne 等。“flan 集合：为有效指令调整设计的数据和方法。” *arXiv 预印本 arXiv:2301.13688*（2023）。'
- en: '[11] Kojima, Takeshi, et al. “Large language models are zero-shot reasoners.”
    *arXiv preprint arXiv:2205.11916* (2022).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] Kojima, Takeshi 等。“大型语言模型是零样本推理器。” *arXiv 预印本 arXiv:2205.11916*（2022）。'
- en: '[12] Wei, Jason, et al. “Finetuned language models are zero-shot learners.”
    *arXiv preprint arXiv:2109.01652* (2021).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] Wei, Jason 等。“微调语言模型是零样本学习者。” *arXiv 预印本 arXiv:2109.01652*（2021）。'
- en: '[13] Wei, Jason, et al. “Chain of thought prompting elicits reasoning in large
    language models.” *arXiv preprint arXiv:2201.11903* (2022).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] Wei, Jason 等。“思维链提示引发大型语言模型中的推理。” *arXiv 预印本 arXiv:2201.11903*（2022）。'
