- en: 'Private GPT: Fine-Tune LLM on Enterprise Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 私有GPT：在企业数据上微调大语言模型
- en: 原文：[https://towardsdatascience.com/private-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a?source=collection_archive---------0-----------------------#2023-07-05](https://towardsdatascience.com/private-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a?source=collection_archive---------0-----------------------#2023-07-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/private-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a?source=collection_archive---------0-----------------------#2023-07-05](https://towardsdatascience.com/private-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a?source=collection_archive---------0-----------------------#2023-07-05)
- en: Doing cool things with data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用数据做一些酷炫的事情
- en: '[](https://priya-dwivedi.medium.com/?source=post_page-----7e663d808e6a--------------------------------)[![Priya
    Dwivedi](../Images/73087cb699750466312cc4752e2044d4.png)](https://priya-dwivedi.medium.com/?source=post_page-----7e663d808e6a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7e663d808e6a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7e663d808e6a--------------------------------)
    [Priya Dwivedi](https://priya-dwivedi.medium.com/?source=post_page-----7e663d808e6a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://priya-dwivedi.medium.com/?source=post_page-----7e663d808e6a--------------------------------)[![Priya
    Dwivedi](../Images/73087cb699750466312cc4752e2044d4.png)](https://priya-dwivedi.medium.com/?source=post_page-----7e663d808e6a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7e663d808e6a--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7e663d808e6a--------------------------------)
    [Priya Dwivedi](https://priya-dwivedi.medium.com/?source=post_page-----7e663d808e6a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb040ce924438&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprivate-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a&user=Priya+Dwivedi&userId=b040ce924438&source=post_page-b040ce924438----7e663d808e6a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7e663d808e6a--------------------------------)
    ·9 min read·Jul 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e663d808e6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprivate-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a&user=Priya+Dwivedi&userId=b040ce924438&source=-----7e663d808e6a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb040ce924438&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprivate-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a&user=Priya+Dwivedi&userId=b040ce924438&source=post_page-b040ce924438----7e663d808e6a---------------------post_header-----------)
    发表在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----7e663d808e6a--------------------------------)
    · 9 分钟阅读 · 2023年7月5日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e663d808e6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprivate-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a&user=Priya+Dwivedi&userId=b040ce924438&source=-----7e663d808e6a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e663d808e6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprivate-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a&source=-----7e663d808e6a---------------------bookmark_footer-----------)![](../Images/b1c22ad1ee60a9ba1c68c1dc31d44dc6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e663d808e6a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprivate-gpt-fine-tune-llm-on-enterprise-data-7e663d808e6a&source=-----7e663d808e6a---------------------bookmark_footer-----------)![](../Images/b1c22ad1ee60a9ba1c68c1dc31d44dc6.png)'
- en: Photo by [Robynne Hu](https://unsplash.com/@robynnexy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/technology?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [Robynne Hu](https://unsplash.com/@robynnexy?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    由 [Unsplash](https://unsplash.com/s/photos/technology?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供
- en: '**Introduction**'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**简介**'
- en: In the era of big data and advanced artificial intelligence, language models
    have emerged as formidable tools capable of processing and generating human-like
    text. Large Language Models like ChatGPT are general-purpose bots capable of having
    conversations on many topics. However, LLMs can also be fine-tuned on domain-specific
    data making them more accurate and on-point on domain-specific enterprise questions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在大数据和先进人工智能的时代，语言模型作为处理和生成类人文本的强大工具已然崭露头角。像 ChatGPT 这样的**大语言模型**是通用的聊天机器人，能够就许多话题进行对话。然而，大语言模型也可以在特定领域的数据上进行微调，从而在特定领域的企业问题上变得更为准确和切题。
- en: 'Many industries and applications will require a fine-tuned LLMs. Reasons include:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 许多行业和应用将需要微调的 LLMs。原因包括：
- en: Better performance from a chatbot trained on specific data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特定数据上训练的聊天机器人能提供更好的性能。
- en: OpenAI models like chatgpt are a black box and companies may be hesitant to
    share their confidential data over an API
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI 模型，如 chatgpt，是一个黑箱，企业可能会对通过 API 共享其机密数据感到犹豫。
- en: ChatGPT API costs may be prohibitive for large applications
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatGPT API 成本对于大型应用可能是难以承受的。
- en: The challenge with fine-tuning an LLM is that the process is unknown and the
    computational resources required to train a billion-parameter model without optimizations
    can be prohibitive.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 微调 LLM 的挑战在于该过程不明确，训练一个没有优化的十亿参数模型所需的计算资源可能是巨大的。
- en: Fortunately, a lot of research has been done on training techniques that allow
    us now to fine-tune LLMs on smaller GPUs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，许多关于训练技术的研究已经完成，这使得我们现在可以在较小的 GPU 上微调 LLMs。
