- en: Neural Graph Databases
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾æ•°æ®åº“
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/neural-graph-databases-cc35c9e1d04f?source=collection_archive---------0-----------------------#2023-03-28](https://towardsdatascience.com/neural-graph-databases-cc35c9e1d04f?source=collection_archive---------0-----------------------#2023-03-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/neural-graph-databases-cc35c9e1d04f?source=collection_archive---------0-----------------------#2023-03-28](https://towardsdatascience.com/neural-graph-databases-cc35c9e1d04f?source=collection_archive---------0-----------------------#2023-03-28)
- en: Whatâ€™s New in Graph ML?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›¾ç¥ç»ç½‘ç»œæ•°æ®åº“çš„æœ€æ–°è¿›å±•
- en: A new milestone in graph data management
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›¾æ•°æ®ç®¡ç†çš„æ–°é‡Œç¨‹ç¢‘
- en: '[](https://mgalkin.medium.com/?source=post_page-----cc35c9e1d04f--------------------------------)[![Michael
    Galkin](../Images/c5eb13334712ca0462d8a5df4a268ad0.png)](https://mgalkin.medium.com/?source=post_page-----cc35c9e1d04f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cc35c9e1d04f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cc35c9e1d04f--------------------------------)
    [Michael Galkin](https://mgalkin.medium.com/?source=post_page-----cc35c9e1d04f--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mgalkin.medium.com/?source=post_page-----cc35c9e1d04f--------------------------------)[![Michael
    Galkin](../Images/c5eb13334712ca0462d8a5df4a268ad0.png)](https://mgalkin.medium.com/?source=post_page-----cc35c9e1d04f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cc35c9e1d04f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cc35c9e1d04f--------------------------------)
    [Michael Galkin](https://mgalkin.medium.com/?source=post_page-----cc35c9e1d04f--------------------------------)'
- en: Â·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d4f8ddd1e68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-graph-databases-cc35c9e1d04f&user=Michael+Galkin&userId=4d4f8ddd1e68&source=post_page-4d4f8ddd1e68----cc35c9e1d04f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cc35c9e1d04f--------------------------------)
    Â·14 min readÂ·Mar 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcc35c9e1d04f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-graph-databases-cc35c9e1d04f&user=Michael+Galkin&userId=4d4f8ddd1e68&source=-----cc35c9e1d04f---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4d4f8ddd1e68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-graph-databases-cc35c9e1d04f&user=Michael+Galkin&userId=4d4f8ddd1e68&source=post_page-4d4f8ddd1e68----cc35c9e1d04f---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cc35c9e1d04f--------------------------------)
    Â·14 åˆ†é’Ÿé˜…è¯»Â·2023å¹´3æœˆ28æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcc35c9e1d04f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-graph-databases-cc35c9e1d04f&user=Michael+Galkin&userId=4d4f8ddd1e68&source=-----cc35c9e1d04f---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc35c9e1d04f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-graph-databases-cc35c9e1d04f&source=-----cc35c9e1d04f---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcc35c9e1d04f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-graph-databases-cc35c9e1d04f&source=-----cc35c9e1d04f---------------------bookmark_footer-----------)'
- en: We introduce the concept of Neural Graph Databases as the next step in the evolution
    of graph databases. Tailored for large incomplete graphs and on-the-fly inference
    of missing edges using graph representation learning, neural reasoning maintains
    high expressiveness and supports complex logical queries similar to standard graph
    query languages.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¼•å…¥äº†ç¥ç»å›¾æ•°æ®åº“çš„æ¦‚å¿µï¼Œä½œä¸ºå›¾æ•°æ®åº“å‘å±•çš„ä¸‹ä¸€æ­¥ã€‚ç¥ç»å›¾æ•°æ®åº“ä¸“ä¸ºå¤§è§„æ¨¡ä¸å®Œæ•´å›¾è®¾è®¡ï¼Œå¹¶åˆ©ç”¨å›¾è¡¨ç¤ºå­¦ä¹ è¿›è¡Œç¼ºå¤±è¾¹çš„å³æ—¶æ¨ç†ã€‚ç¥ç»æ¨ç†ä¿æŒäº†è¾ƒé«˜çš„è¡¨è¾¾èƒ½åŠ›ï¼Œæ”¯æŒç±»ä¼¼äºæ ‡å‡†å›¾æŸ¥è¯¢è¯­è¨€çš„å¤æ‚é€»è¾‘æŸ¥è¯¢ã€‚
- en: '![](../Images/52796205e90c035d95249244ab623490.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52796205e90c035d95249244ab623490.png)'
- en: Image by Authors, assisted by Stable Diffusion.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›ï¼Œè¾…åŠ©å·¥å…·ä¸º Stable Diffusionã€‚
- en: '*This post was written together with* [*Hongyu Ren*](http://hyren.me/)*,* [*Michael
    Cochez*](https://www.cochez.nl/)*, and* [*Zhaocheng Zhu*](https://kiddozhu.github.io/)
    *based on our newest paper* [*Neural Graph Reasoning: Complex Logical Query Answering
    Meets Graph Databases*](https://arxiv.org/abs/2303.14617)*. You can also follow*
    [*me*](https://twitter.com/michael_galkin)*,* [*Hongyu*](https://twitter.com/ren_hongyu)*,*
    [*Michael*](https://twitter.com/michaelcochez)*, and* [*Zhaocheng*](https://twitter.com/zhu_zhaocheng)
    *on Twitter. Check our* [*project website*](https://www.ngdb.org/) *for more materials.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ¬æ–‡ç”±* [*Hongyu Ren*](http://hyren.me/)*,* [*Michael Cochez*](https://www.cochez.nl/)*
    å’Œ* [*Zhaocheng Zhu*](https://kiddozhu.github.io/) *å…±åŒæ’°å†™ï¼ŒåŸºäºæˆ‘ä»¬æœ€æ–°çš„è®ºæ–‡* [*Neural Graph
    Reasoning: Complex Logical Query Answering Meets Graph Databases*](https://arxiv.org/abs/2303.14617)*ã€‚ä½ ä¹Ÿå¯ä»¥å…³æ³¨*
    [*æˆ‘*](https://twitter.com/michael_galkin)*,* [*Hongyu*](https://twitter.com/ren_hongyu)*,*
    [*Michael*](https://twitter.com/michaelcochez)* å’Œ* [*Zhaocheng*](https://twitter.com/zhu_zhaocheng)
    *åœ¨Twitterä¸Šçš„åŠ¨æ€ã€‚æŸ¥çœ‹æˆ‘ä»¬çš„* [*é¡¹ç›®ç½‘ç«™*](https://www.ngdb.org/) *è·å–æ›´å¤šèµ„æ–™ã€‚*'
- en: '**Outline**:'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**æ¦‚è¿°**ï¼š'
- en: 'Neural Graph Databases: What and Why?'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾æ•°æ®åº“ï¼šä»€ä¹ˆå’Œä¸ºä»€ä¹ˆï¼Ÿ
- en: The blueprint of NGDBs
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NGDBsçš„è“å›¾
- en: Neural Graph Storage
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾å­˜å‚¨
- en: Neural Query Engine
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¥ç»æŸ¥è¯¢å¼•æ“
- en: Neural Graph Reasoning for Query Engines
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŸ¥è¯¢å¼•æ“çš„ç¥ç»å›¾æ¨ç†
- en: Open Challenges for NGDBs
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NGDBsçš„å¼€æ”¾æŒ‘æˆ˜
- en: Learn More
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº†è§£æ›´å¤š
- en: 'Neural Graph Databases: What and Why?'
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾æ•°æ®åº“ï¼šä»€ä¹ˆå’Œä¸ºä»€ä¹ˆï¼Ÿ
- en: 'ğŸ¨Vanilla graph databases are pretty much everywhere thanks to the ever-growing
    graphs in production, flexible graph data models, and expressive query languages.
    Classical, symbolic graph DBs are fast and cool under one important assumption:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ¨é¦™è‰å›¾æ•°æ®åº“å‡ ä¹éšå¤„å¯è§ï¼Œè¿™è¦å½’åŠŸäºä¸æ–­å¢é•¿çš„ç”Ÿäº§å›¾ã€çµæ´»çš„å›¾æ•°æ®æ¨¡å‹å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„æŸ¥è¯¢è¯­è¨€ã€‚ç»å…¸çš„ç¬¦å·å›¾æ•°æ®åº“åœ¨ä¸€ä¸ªé‡è¦å‡è®¾ä¸‹è¿è¡Œå¾—åˆå¿«åˆé…·ï¼š
- en: Completeness. Query engines assume that graphs in classical graph DBs are complete.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å®Œæ•´æ€§ã€‚æŸ¥è¯¢å¼•æ“å‡è®¾ç»å…¸å›¾æ•°æ®åº“ä¸­çš„å›¾æ˜¯å®Œæ•´çš„ã€‚
- en: Under the completeness assumption, we can build indexes, store the graphs in
    a variety of read/write-optimized formats and expect the DB would return **what
    is there**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®Œæ•´æ€§å‡è®¾ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºç´¢å¼•ï¼Œä»¥å¤šç§è¯»å†™ä¼˜åŒ–æ ¼å¼å­˜å‚¨å›¾ï¼Œå¹¶æœŸæœ›æ•°æ®åº“è¿”å›**æœ‰ä»€ä¹ˆ**ã€‚
- en: 'But this assumption does not often hold in practice (weâ€™d say, doesnâ€™t hold
    way too often). If we look at some prominent knowledge graphs (KGs): in Freebase,
    93.8% of people have no place of birth and [78.5% have no nationality](https://aclanthology.org/P09-1113.pdf),
    about 68% of people [do not have any profession](https://dl.acm.org/doi/abs/10.1145/2566486.2568032),
    while in Wikidata, about [50% of artists have no date of birth](https://arxiv.org/abs/2207.00143),
    and only [0.4% of known buildings have information about height](https://dl.acm.org/doi/abs/10.1145/3485447.3511932).
    And thatâ€™s for the largest KG openly curated by hundreds of enthusiasts. Surely,
    100M nodes and 1B statements are not the largest ever graph in the industry, so
    you can imagine the degree of incompleteness there.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†è¿™ä¸€å‡è®¾åœ¨å®é™…ä¸­å¾€å¾€ä¸æˆç«‹ï¼ˆæˆ‘ä»¬ä¼šè¯´ï¼Œå‡ ä¹æ€»æ˜¯ä¸æˆç«‹ï¼‰ã€‚ä¾‹å¦‚åœ¨ä¸€äº›çªå‡ºçš„çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä¸­ï¼šåœ¨Freebaseä¸­ï¼Œ93.8%çš„äººæ²¡æœ‰å‡ºç”Ÿåœ°ï¼Œ[78.5%æ²¡æœ‰å›½ç±](https://aclanthology.org/P09-1113.pdf)ï¼Œçº¦68%çš„äºº[æ²¡æœ‰ä»»ä½•èŒä¸š](https://dl.acm.org/doi/abs/10.1145/2566486.2568032)ï¼Œè€Œåœ¨Wikidataä¸­ï¼Œ[çº¦50%çš„è‰ºæœ¯å®¶æ²¡æœ‰å‡ºç”Ÿæ—¥æœŸ](https://arxiv.org/abs/2207.00143)ï¼Œåªæœ‰[0.4%çš„å·²çŸ¥å»ºç­‘æœ‰é«˜åº¦ä¿¡æ¯](https://dl.acm.org/doi/abs/10.1145/3485447.3511932)ã€‚è¿™ä»…ä»…æ˜¯ç”±æ•°ç™¾åçˆ±å¥½è€…å…¬å¼€ç¼–è¾‘çš„æœ€å¤§KGï¼Œ100MèŠ‚ç‚¹å’Œ1Bè¯­å¥å¹¶ä¸æ˜¯è¡Œä¸šä¸­æœ€å¤§çš„å›¾ï¼Œæ‰€ä»¥ä½ å¯ä»¥æƒ³è±¡å…¶ä¸å®Œæ•´æ€§çš„ç¨‹åº¦ã€‚
- en: 'Clearly, to account for incompleteness, in addition to **â€œwhat is there?â€**
    we have to also ask **â€œwhat is missing?â€** (or â€œwhat can be there?â€). Letâ€™s look
    at the example:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç„¶ï¼Œä¸ºäº†è€ƒè™‘ä¸å®Œæ•´æ€§ï¼Œé™¤äº†**â€œæœ‰ä»€ä¹ˆï¼Ÿâ€**æˆ‘ä»¬è¿˜å¿…é¡»é—®**â€œç¼ºå°‘ä»€ä¹ˆï¼Ÿâ€**ï¼ˆæˆ–â€œå¯ä»¥æœ‰ä»€ä¹ˆï¼Ÿâ€ï¼‰ã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªä¾‹å­ï¼š
- en: '![](../Images/f323dce3ed36b383b14b5194429efd45.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f323dce3ed36b383b14b5194429efd45.png)'
- en: (a) - input query; (b) â€” incomplete graph with predicted edges (dashed lines);
    (c) â€” a SPARQL query returning one answer (UofT) via graph traversal; (d) â€” neural
    execution that recovers missing edges and returns two new answers (UdeM, NYU).
    Image by Authors.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: (a) - è¾“å…¥æŸ¥è¯¢ï¼›(b) â€” å¸¦æœ‰é¢„æµ‹è¾¹ï¼ˆè™šçº¿ï¼‰çš„ä¸å®Œæ•´å›¾ï¼›(c) â€” é€šè¿‡å›¾éå†è¿”å›ä¸€ä¸ªç­”æ¡ˆï¼ˆUofTï¼‰çš„SPARQLæŸ¥è¯¢ï¼›(d) â€” ç¥ç»æ‰§è¡Œæ¢å¤ç¼ºå¤±çš„è¾¹ï¼Œå¹¶è¿”å›ä¸¤ä¸ªæ–°ç­”æ¡ˆï¼ˆUdeM,
    NYUï¼‰ã€‚å›¾ç‰‡æ¥æºï¼šä½œè€…ã€‚
- en: Here, given an incomplete graph (edges `(Turing Award, win, Bengio)` and `(Deep
    Learning, field, LeCun)` are missing) and a query *â€œAt what universities do the
    Turing Award winners in the field of Deep Learning work?â€* (expressed in a logical
    form or in some language like SPARQL), a symbolic graph DB would return only one
    answer **UofT** reachable by graph traversal. We refer to such answers as *easy*
    answers, or existing answers. Accounting for missing edges, we would recover two
    more answers **UdeM** and **NYU** (*hard* answers, or inferred answers).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œç»™å®šä¸€ä¸ªä¸å®Œæ•´çš„å›¾ï¼ˆç¼ºå¤±è¾¹ `(Turing Award, win, Bengio)` å’Œ `(Deep Learning, field, LeCun)`ï¼‰ä»¥åŠä¸€ä¸ªæŸ¥è¯¢
    *â€œåœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸçš„å›¾çµå¥–å¾—ä¸»åœ¨å“ªäº›å¤§å­¦å·¥ä½œï¼Ÿâ€*ï¼ˆä»¥é€»è¾‘å½¢å¼æˆ–ç±»ä¼¼ SPARQL çš„è¯­è¨€è¡¨è¾¾ï¼‰ï¼Œç¬¦å·å›¾æ•°æ®åº“åªä¼šè¿”å›ä¸€ä¸ªé€šè¿‡å›¾éå†å¾—åˆ°çš„ç­”æ¡ˆ **UofT**ã€‚æˆ‘ä»¬å°†è¿™ç§ç­”æ¡ˆç§°ä¸º
    *ç®€å•* ç­”æ¡ˆï¼Œæˆ–ç°æœ‰ç­”æ¡ˆã€‚è€ƒè™‘åˆ°ç¼ºå¤±çš„è¾¹ï¼Œæˆ‘ä»¬å¯ä»¥æ¢å¤ä¸¤ä¸ªæ›´å¤šçš„ç­”æ¡ˆ **UdeM** å’Œ **NYU**ï¼ˆ*å›°éš¾* ç­”æ¡ˆï¼Œæˆ–æ¨æ–­ç­”æ¡ˆï¼‰ã€‚
- en: How to infer missing edges?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½•æ¨æ–­ç¼ºå¤±çš„è¾¹ï¼Ÿ
- en: In classical DBs, we donâ€™t have much choice. RDF-based databases have some formal
    semantics and can be backed by hefty OWL ontologies but, depending on graph size
    and complexity of inference, it might take an infinite amount of time to complete
    the inference in [SPARQL entailment regimes](https://www.w3.org/TR/sparql11-entailment/).
    Labeled Property Graph (LPG) graph databases do not have built-in means for inferring
    missing edges at all.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ç»å…¸æ•°æ®åº“ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©ä¸å¤šã€‚åŸºäº RDF çš„æ•°æ®åº“å…·æœ‰ä¸€äº›å½¢å¼è¯­ä¹‰ï¼Œå¯ä»¥ç”±åºå¤§çš„ OWL æœ¬ä½“æ”¯æŒï¼Œä½†æ ¹æ®å›¾çš„å¤§å°å’Œæ¨ç†çš„å¤æ‚æ€§ï¼Œåœ¨ [SPARQL
    æ¨ç†è§„åˆ™](https://www.w3.org/TR/sparql11-entailment/) ä¸­å®Œæˆæ¨ç†å¯èƒ½éœ€è¦æ— é™çš„æ—¶é—´ã€‚æ ‡è®°å±æ€§å›¾ï¼ˆLPGï¼‰æ•°æ®åº“å®Œå…¨æ²¡æœ‰å†…ç½®çš„æ¨æ–­ç¼ºå¤±è¾¹çš„æ‰‹æ®µã€‚
- en: Thanks to the advances in Graph Machine Learning, we can often perform link
    prediction in a latent (embedding) space in linear time! We can then extend this
    mechanism to executing complex, database-like queries right in the embedding space.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¾—ç›Šäºå›¾æœºå™¨å­¦ä¹ çš„è¿›å±•ï¼Œæˆ‘ä»¬é€šå¸¸å¯ä»¥åœ¨æ½œåœ¨ï¼ˆåµŒå…¥ï¼‰ç©ºé—´ä¸­ä»¥çº¿æ€§æ—¶é—´æ‰§è¡Œé“¾æ¥é¢„æµ‹ï¼ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ç§æœºåˆ¶æ‰©å±•åˆ°åœ¨åµŒå…¥ç©ºé—´ä¸­æ‰§è¡Œå¤æ‚çš„ã€ç±»ä¼¼æ•°æ®åº“çš„æŸ¥è¯¢ã€‚
- en: Neural Graph Databases combine the advantages of traditional graph DBs with
    modern graph machine learning.
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾æ•°æ®åº“ç»“åˆäº†ä¼ ç»Ÿå›¾æ•°æ®åº“å’Œç°ä»£å›¾æœºå™¨å­¦ä¹ çš„ä¼˜åŠ¿ã€‚
- en: That is, DB principles like (1) graphs as a first-class citizen, (2) efficient
    storage, and (3) uniform querying interface are now backed by Graph ML techniques
    such as (1) geometric representations, (2) robustness to noisy inputs, (3) large-scale
    pretraining and fine-tuning in order to bridge the incompleteness gap and enable
    neural graph reasoning and inference.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å³ï¼Œæ•°æ®åº“åŸåˆ™å¦‚ï¼ˆ1ï¼‰å›¾ä½œä¸ºä¸€ç­‰å…¬æ°‘ï¼Œï¼ˆ2ï¼‰é«˜æ•ˆå­˜å‚¨ï¼Œä»¥åŠï¼ˆ3ï¼‰ç»Ÿä¸€æŸ¥è¯¢æ¥å£ï¼Œç°åœ¨ç”±å›¾ ML æŠ€æœ¯æ”¯æŒï¼Œå¦‚ï¼ˆ1ï¼‰å‡ ä½•è¡¨ç¤ºï¼Œï¼ˆ2ï¼‰å¯¹å™ªå£°è¾“å…¥çš„é²æ£’æ€§ï¼Œï¼ˆ3ï¼‰å¤§è§„æ¨¡é¢„è®­ç»ƒå’Œå¾®è°ƒï¼Œä»¥å¼¥åˆä¸å®Œæ•´æ€§å·®è·å¹¶å®ç°ç¥ç»å›¾æ¨ç†å’Œæ¨æ–­ã€‚
- en: 'In general, the design principles for NGDBs are:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€èˆ¬æ¥è¯´ï¼ŒNGDB çš„è®¾è®¡åŸåˆ™åŒ…æ‹¬ï¼š
- en: The **data incompleteness assumption** â€” the underlying data might have missing
    information on node-, link-, and graph-levels which we would like to infer and
    leverage in query answering;
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ•°æ®ä¸å®Œæ•´æ€§å‡è®¾** â€” æ½œåœ¨æ•°æ®å¯èƒ½åœ¨èŠ‚ç‚¹ã€é“¾æ¥å’Œå›¾çº§åˆ«ä¸Šç¼ºå°‘ä¿¡æ¯ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨æ–­å¹¶åœ¨æŸ¥è¯¢å›ç­”ä¸­åŠ ä»¥åˆ©ç”¨ï¼›'
- en: '**Inductiveness and updatability** â€” similar to traditional databases that
    allow updates and instant querying, representation learning algorithms for building
    graph latents have to be inductive and generalize to unseen data (new entities
    and relation at inference time) in the zero-shot (or few-shot) manner to prevent
    costly re-training (for instance, of shallow node embeddings);'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å½’çº³æ€§å’Œå¯æ›´æ–°æ€§** â€” ç±»ä¼¼äºä¼ ç»Ÿæ•°æ®åº“ï¼Œå…è®¸æ›´æ–°å’Œå³æ—¶æŸ¥è¯¢ï¼Œæ„å»ºå›¾æ½œå˜é‡çš„è¡¨ç¤ºå­¦ä¹ ç®—æ³•å¿…é¡»å…·æœ‰å½’çº³æ€§ï¼Œå¹¶ä»¥é›¶æ ·æœ¬ï¼ˆæˆ–å°‘æ ·æœ¬ï¼‰æ–¹å¼å¯¹æœªè§æ•°æ®ï¼ˆæ–°å®ä½“å’Œå…³ç³»ï¼‰è¿›è¡Œæ³›åŒ–ï¼Œä»¥é˜²æ­¢æ˜‚è´µçš„å†è®­ç»ƒï¼ˆä¾‹å¦‚ï¼Œæµ…å±‚èŠ‚ç‚¹åµŒå…¥ï¼‰ï¼›'
- en: '**Expressiveness** â€” the ability of latent representations to encode logical
    and semantic relations in the data akin to FOL (or its fragments) and leverage
    them in query answering. Practically, the set of supported logical operators for
    neural reasoning should be close to or equivalent to standard graph database languages
    like SPARQL or Cypher;'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¡¨è¾¾èƒ½åŠ›** â€” æ½œåœ¨è¡¨ç¤ºåœ¨æ•°æ®ä¸­ç¼–ç é€»è¾‘å’Œè¯­ä¹‰å…³ç³»çš„èƒ½åŠ›ï¼Œç±»ä¼¼äº FOLï¼ˆæˆ–å…¶ç‰‡æ®µï¼‰ï¼Œå¹¶åœ¨æŸ¥è¯¢å›ç­”ä¸­åŠ ä»¥åˆ©ç”¨ã€‚å®é™…ä¸Šï¼Œç¥ç»æ¨ç†æ”¯æŒçš„é€»è¾‘æ“ä½œç¬¦é›†åº”æ¥è¿‘æˆ–ç­‰åŒäºæ ‡å‡†å›¾æ•°æ®åº“è¯­è¨€ï¼Œå¦‚
    SPARQL æˆ– Cypherï¼›'
- en: '**Multimodality** beyond knowledge graphs â€” any graph-structured data that
    can be stored as a node or record in classical databases (consisting, for example,
    of images, texts, molecular graphs, or timestamped sequences) and can be imbued
    with a vector representation is a valid source for the Neural Graph Storage and
    Neural Query Engine.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¶…è¶ŠçŸ¥è¯†å›¾è°±çš„å¤šæ¨¡æ€æ€§**â€”â€”ä»»ä½•å¯ä»¥ä½œä¸ºèŠ‚ç‚¹æˆ–è®°å½•å­˜å‚¨åœ¨ç»å…¸æ•°æ®åº“ä¸­çš„å›¾ç»“æ„æ•°æ®ï¼ˆä¾‹å¦‚å›¾åƒã€æ–‡æœ¬ã€åˆ†å­å›¾æˆ–å¸¦æ—¶é—´æˆ³çš„åºåˆ—ï¼‰ï¼Œå¹¶ä¸”å¯ä»¥èµ‹äºˆå‘é‡è¡¨ç¤ºçš„ï¼Œéƒ½æ˜¯ç¥ç»å›¾å­˜å‚¨å’Œç¥ç»æŸ¥è¯¢å¼•æ“çš„æœ‰æ•ˆæ¥æºã€‚'
- en: 'The key methods to address the NGDB principles are:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è§£å†³NGDBåŸåˆ™çš„å…³é”®æ–¹æ³•æ˜¯ï¼š
- en: '**Vector representation as the atomic element** â€” while traditional graph DBs
    hash the adjacency matrix (or edge list) in many indexes, the incompleteness assumption
    implies that both given edges **and** graph latents (vector representations) become
    the *sources of truth* in the *Neural Graph Storage*;'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‘é‡è¡¨ç¤ºä½œä¸ºåŸå­å…ƒç´ **â€”â€”è™½ç„¶ä¼ ç»Ÿçš„å›¾æ•°æ®åº“åœ¨è®¸å¤šç´¢å¼•ä¸­å¯¹é‚»æ¥çŸ©é˜µï¼ˆæˆ–è¾¹åˆ—è¡¨ï¼‰è¿›è¡Œå“ˆå¸Œå¤„ç†ï¼Œä½†ä¸å®Œå…¨æ€§å‡è®¾æ„å‘³ç€ç»™å®šçš„è¾¹**å’Œ**å›¾æ½œåœ¨ï¼ˆå‘é‡è¡¨ç¤ºï¼‰éƒ½æˆä¸º*çœŸç†çš„æ¥æº*ï¼Œåœ¨*ç¥ç»å›¾å­˜å‚¨*ä¸­ã€‚'
- en: '**Neural query execution in the latent space** â€“, basic operations such as
    edge traversal cannot be performed solely symbolically due to the incompleteness
    assumption. Instead, the *Neural Query Engine* operates on both adjacency and
    graph latents to incorporate possibly missing data into query answering;'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åœ¨æ½œåœ¨ç©ºé—´ä¸­çš„ç¥ç»æŸ¥è¯¢æ‰§è¡Œ**â€”â€”ç”±äºä¸å®Œå…¨æ€§å‡è®¾ï¼ŒåŸºæœ¬æ“ä½œå¦‚è¾¹éå†ä¸èƒ½ä»…é€šè¿‡ç¬¦å·æ“ä½œæ¥æ‰§è¡Œã€‚ç›¸åï¼Œ*ç¥ç»æŸ¥è¯¢å¼•æ“*åœ¨é‚»æ¥å’Œå›¾æ½œåœ¨ç©ºé—´ä¸Šæ“ä½œï¼Œä»¥å°†å¯èƒ½ç¼ºå¤±çš„æ•°æ®çº³å…¥æŸ¥è¯¢å›ç­”ä¸­ï¼›'
- en: In fact, by answering queries in the latent space (and not sacrificing traversal
    performance) we can ditch symbolic database indexes altogether.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­å›ç­”æŸ¥è¯¢ï¼ˆä¸”ä¸ç‰ºç‰²éå†æ€§èƒ½ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å®Œå…¨æŠ›å¼ƒç¬¦å·æ•°æ®åº“ç´¢å¼•ã€‚
- en: '![](../Images/9e2a728bb9c7fb27b599ef19bf69ac7f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e2a728bb9c7fb27b599ef19bf69ac7f.png)'
- en: 'The main difference between symbolic graph DBs and neural graph DBs: traditional
    DBs answer the question â€œWhat is there?â€ by edge traversal while neural graph
    DBs also answer â€œWhat is missing?â€. Image by Authors.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¦å·å›¾æ•°æ®åº“å’Œç¥ç»å›¾æ•°æ®åº“ä¹‹é—´çš„ä¸»è¦åŒºåˆ«ï¼šä¼ ç»Ÿçš„æ•°æ®åº“é€šè¿‡è¾¹éå†å›ç­”â€œæœ‰ä»€ä¹ˆï¼Ÿâ€çš„é—®é¢˜ï¼Œè€Œç¥ç»å›¾æ•°æ®åº“è¿˜ä¼šå›ç­”â€œç¼ºå°‘ä»€ä¹ˆï¼Ÿâ€çš„é—®é¢˜ã€‚å›¾åƒæ¥æºï¼šä½œè€…ã€‚
- en: The Blueprint of NGDBs
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NGDBsçš„è“å›¾
- en: Before diving into NGDBs, letâ€™s take a look at **neural databases** in general
    â€” turns out they have been around for a while and you might have noticed that.
    Many machine learning systems already operate in this paradigm when data is encoded
    into model parameters and querying is equivalent to a forward pass that can output
    a new representation or prediction for a downstream task.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ·±å…¥äº†è§£NGDBsä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹**ç¥ç»æ•°æ®åº“**çš„ä¸€èˆ¬æƒ…å†µâ€”â€”äº‹å®è¯æ˜å®ƒä»¬å·²ç»å­˜åœ¨äº†ä¸€æ®µæ—¶é—´ï¼Œä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°äº†ã€‚è®¸å¤šæœºå™¨å­¦ä¹ ç³»ç»Ÿåœ¨æ•°æ®è¢«ç¼–ç ä¸ºæ¨¡å‹å‚æ•°æ—¶ï¼Œå·²ç»åœ¨è¿™ä¸€èŒƒå¼ä¸‹è¿è¡Œï¼Œè€ŒæŸ¥è¯¢ç›¸å½“äºå‰å‘ä¼ æ’­ï¼Œå¯ä»¥ä¸ºä¸‹æ¸¸ä»»åŠ¡è¾“å‡ºæ–°çš„è¡¨ç¤ºæˆ–é¢„æµ‹ã€‚
- en: '**Neural Databases: Overview**'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¥ç»æ•°æ®åº“æ¦‚è¿°**'
- en: What is the current state of neural databases? What are the differences between
    its kinds and whatâ€™s special about NGDBs?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»æ•°æ®åº“çš„ç°çŠ¶å¦‚ä½•ï¼Ÿå®ƒçš„ä¸åŒç§ç±»ä¹‹é—´æœ‰ä»€ä¹ˆåŒºåˆ«ï¼ŒNGDBsï¼ˆç¥ç»å›¾æ•°æ®åº“ï¼‰æœ‰ä»€ä¹ˆç‰¹åˆ«ä¹‹å¤„ï¼Ÿ
- en: '![](../Images/a2a55a65281df449a1cecf755ec66364.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2a55a65281df449a1cecf755ec66364.png)'
- en: Differences between Vector DBs, natural language DBs, and neural graph DBs.
    Image by Authors
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡æ•°æ®åº“ã€è‡ªç„¶è¯­è¨€æ•°æ®åº“å’Œç¥ç»å›¾æ•°æ®åº“ä¹‹é—´çš„åŒºåˆ«ã€‚å›¾åƒæ¥æºï¼šä½œè€…
- en: '**Vector databases** belong to the family of storage-oriented systems commonly
    built around approximate nearest neighbor libraries (ANN) like [Faiss](https://github.com/facebookresearch/faiss)
    or [ScaNN](https://github.com/google-research/google-research/tree/master/scann)
    (or custom solutions) to answer distance-based queries using Maximum Inner-Product
    Search (MIPS), L1, L2, or other distances. Being encoder-independent (that is,
    any encoder yielding vector representations can be a source like a ResNet or BERT),
    vector databases are fast but lack complex query answering capabilities.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å‘é‡æ•°æ®åº“**å±äºå­˜å‚¨å¯¼å‘çš„ç³»ç»Ÿï¼Œè¿™äº›ç³»ç»Ÿé€šå¸¸åŸºäºè¿‘ä¼¼æœ€è¿‘é‚»åº“ï¼ˆANNï¼‰ï¼Œå¦‚[Faiss](https://github.com/facebookresearch/faiss)æˆ–[ScaNN](https://github.com/google-research/google-research/tree/master/scann)ï¼ˆæˆ–å®šåˆ¶è§£å†³æ–¹æ¡ˆï¼‰æ¥å›ç­”åŸºäºè·ç¦»çš„æŸ¥è¯¢ï¼Œä½¿ç”¨æœ€å¤§å†…ç§¯æœç´¢ï¼ˆMIPSï¼‰ã€L1ã€L2æˆ–å…¶ä»–è·ç¦»ã€‚ç”±äºå‘é‡æ•°æ®åº“ä¸ç¼–ç å™¨æ— å…³ï¼ˆå³ï¼Œä»»ä½•ç”Ÿæˆå‘é‡è¡¨ç¤ºçš„ç¼–ç å™¨ï¼Œå¦‚ResNetæˆ–BERTï¼Œéƒ½å¯ä»¥ä½œä¸ºæ¥æºï¼‰ï¼Œå®ƒä»¬é€Ÿåº¦å¾ˆå¿«ï¼Œä½†ç¼ºä¹å¤æ‚çš„æŸ¥è¯¢å›ç­”èƒ½åŠ›ã€‚'
- en: With the recent rise of large-scale pretrained models â€” or, [foundation models](https://en.wikipedia.org/wiki/Foundation_models)
    â€” we have witnessed their huge success in natural language processing and computer
    vision tasks. We argue that such foundation models are also a prominent example
    of neural databases. There, the *storage module* might be presented directly with
    model parameters or outsourced to an external index often used in [retrieval-augmented
    models](https://arxiv.org/abs/2002.08909) since encoding all world knowledge even
    into billions of model parameters is hard. The *query module* performs in-context
    learning either via filling in the blanks in encoder models (BERT or T5 style)
    or via prompts in decoder-only models (GPT-style) that can span multiple modalities,
    eg, [learnable tokens for vision applications](https://arxiv.org/abs/2205.10337)
    or even [calling external tools](https://arxiv.org/abs/2302.07842).
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€è¿‘ï¼Œéšç€å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å´›èµ·â€”â€”æˆ–ç§°ä¸º[åŸºç¡€æ¨¡å‹](https://en.wikipedia.org/wiki/Foundation_models)â€”â€”æˆ‘ä»¬è§è¯äº†å®ƒä»¬åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­çš„å·¨å¤§æˆåŠŸã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œè¿™äº›åŸºç¡€æ¨¡å‹ä¹Ÿæ˜¯ç¥ç»æ•°æ®åº“çš„ä¸€ä¸ªé‡è¦ä¾‹å­ã€‚åœ¨è¿™äº›æ¨¡å‹ä¸­ï¼Œ*å­˜å‚¨æ¨¡å—*å¯èƒ½ç›´æ¥ä»¥æ¨¡å‹å‚æ•°çš„å½¢å¼å‘ˆç°ï¼Œæˆ–è€…å¤–åŒ…ç»™ä¸€ä¸ªå¤–éƒ¨ç´¢å¼•ï¼Œè¿™åœ¨[æ£€ç´¢å¢å¼ºæ¨¡å‹](https://arxiv.org/abs/2002.08909)ä¸­å¸¸å¸¸ä½¿ç”¨ï¼Œå› ä¸ºå°†æ‰€æœ‰ä¸–ç•ŒçŸ¥è¯†ç¼–ç åˆ°å³ä¾¿æ˜¯æ•°åäº¿ä¸ªæ¨¡å‹å‚æ•°ä¸­ä¹Ÿæ˜¯å›°éš¾çš„ã€‚*æŸ¥è¯¢æ¨¡å—*é€šè¿‡å¡«å……ç¼–ç å™¨æ¨¡å‹ï¼ˆBERTæˆ–T5é£æ ¼ï¼‰ä¸­çš„ç©ºç™½æˆ–é€šè¿‡è§£ç å™¨æ¨¡å‹ï¼ˆGPTé£æ ¼ï¼‰ä¸­çš„æç¤ºï¼Œè¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œè¿™äº›æç¤ºå¯ä»¥è·¨è¶Šå¤šç§æ¨¡å¼ï¼Œä¾‹å¦‚[è§†è§‰åº”ç”¨çš„å¯å­¦ä¹ æ ‡è®°](https://arxiv.org/abs/2205.10337)æˆ–ç”šè‡³[è°ƒç”¨å¤–éƒ¨å·¥å…·](https://arxiv.org/abs/2302.07842)ã€‚
- en: '**Natural Language Databases (NLDB)** introduced by [Thorne et al](https://arxiv.org/abs/2106.01074)
    model atomic elements as textual facts encoded to a vector via a pre-trained language
    model (LM). Queries to NLDB are sent as natural language utterances that get encoded
    to vectors and query processing employs the *retriever-reader* approach.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Thorne et al](https://arxiv.org/abs/2106.01074)ä»‹ç»çš„**è‡ªç„¶è¯­è¨€æ•°æ®åº“ (NLDB)**å°†åŸå­å…ƒç´ å»ºæ¨¡ä¸ºé€šè¿‡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰ç¼–ç ä¸ºå‘é‡çš„æ–‡æœ¬äº‹å®ã€‚å¯¹NLDBçš„æŸ¥è¯¢ä»¥è‡ªç„¶è¯­è¨€è¡¨è¾¾çš„å½¢å¼å‘é€ï¼Œè¿™äº›æŸ¥è¯¢è¢«ç¼–ç ä¸ºå‘é‡ï¼ŒæŸ¥è¯¢å¤„ç†é‡‡ç”¨*æ£€ç´¢å™¨-é˜…è¯»å™¨*æ–¹æ³•ã€‚'
- en: Neural Graph Databases is not a novel term â€” many graph ML approaches tried
    to combine graph embeddings with database indexes, perhaps [RDF2Vec](http://rdf2vec.org/)
    and [LPG2Vec](https://openreview.net/forum?id=p0sMj8oH2O) are some of the most
    prominent examples how embeddings can be plugged into **existing** graph DBs and
    run on top of symbolic indexes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾æ•°æ®åº“å¹¶ä¸æ˜¯ä¸€ä¸ªæ–°åè¯â€”â€”è®¸å¤šå›¾æœºå™¨å­¦ä¹ æ–¹æ³•å°è¯•å°†å›¾åµŒå…¥ä¸æ•°æ®åº“ç´¢å¼•ç»“åˆèµ·æ¥ï¼Œæˆ–è®¸[RDF2Vec](http://rdf2vec.org/)å’Œ[LPG2Vec](https://openreview.net/forum?id=p0sMj8oH2O)æ˜¯ä¸€äº›æœ€æ˜¾è‘—çš„ä¾‹å­ï¼Œå±•ç¤ºäº†å¦‚ä½•å°†åµŒå…¥æ’ä»¶åˆ°**ç°æœ‰**å›¾æ•°æ®åº“ä¸­ï¼Œå¹¶åœ¨ç¬¦å·ç´¢å¼•ä¹‹ä¸Šè¿è¡Œã€‚
- en: In contrast, we posit that NGDBs can **work without symbolic indexes** right
    in the latent space. As we show below, there exist ML algorithms that can simulate
    exact edge traversal-like behavior in embedding space to retrieve â€œ**what is there**â€
    as well as perform neural reasoning to answer â€œ**what is missing**â€.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸æ¯”ä¹‹ä¸‹ï¼Œæˆ‘ä»¬è®¤ä¸ºNGDBå¯ä»¥åœ¨æ½œåœ¨ç©ºé—´ä¸­**æ— éœ€ç¬¦å·ç´¢å¼•**ç›´æ¥å·¥ä½œã€‚å¦‚ä¸‹é¢æ‰€ç¤ºï¼Œå­˜åœ¨èƒ½å¤Ÿæ¨¡æ‹ŸåµŒå…¥ç©ºé—´ä¸­ç²¾ç¡®è¾¹éå†è¡Œä¸ºçš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œä»¥æ£€ç´¢â€œ**é‚£é‡Œæœ‰ä»€ä¹ˆ**â€ï¼Œå¹¶è¿›è¡Œç¥ç»æ¨ç†ä»¥å›ç­”â€œ**ç¼ºå°‘ä»€ä¹ˆ**â€ã€‚
- en: '**Neural Graph Databases: Architecture**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ç¥ç»å›¾æ•°æ®åº“ï¼šæ¶æ„**'
- en: '![](../Images/223c920f6d8c52a35526536fdd7523b5.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/223c920f6d8c52a35526536fdd7523b5.png)'
- en: A conceptual scheme of Neural Graph Databases. An input query is processed by
    the Neural Query Engine where the Planner derives a computation graph of the query
    and the Executor executes the query in the latent space. The Neural Graph Storage
    employs Graph Store and Feature Store to obtain latent representations in the
    Embedding Store. The Executor communicates with the embedding store to retrieve
    and return results. Image by Authors
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾æ•°æ®åº“çš„æ¦‚å¿µå›¾ã€‚è¾“å…¥æŸ¥è¯¢ç”±ç¥ç»æŸ¥è¯¢å¼•æ“å¤„ç†ï¼Œå…¶ä¸­è§„åˆ’å™¨å¯¼å‡ºæŸ¥è¯¢çš„è®¡ç®—å›¾ï¼Œæ‰§è¡Œå™¨åœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡ŒæŸ¥è¯¢ã€‚ç¥ç»å›¾å­˜å‚¨ä½¿ç”¨å›¾å­˜å‚¨å’Œç‰¹å¾å­˜å‚¨åœ¨åµŒå…¥å­˜å‚¨ä¸­è·å–æ½œåœ¨è¡¨ç¤ºã€‚æ‰§è¡Œå™¨ä¸åµŒå…¥å­˜å‚¨é€šä¿¡ï¼Œä»¥æ£€ç´¢å’Œè¿”å›ç»“æœã€‚å›¾åƒæ¥æºäºä½œè€…
- en: On a higher level, NGDB contains two main components, **Neural Graph Storage**
    and **Neural Query Engine**. The query answering pipeline starts with the query
    sent by some application or downstream task already in a structured format (obtained,
    for example, via [semantic parsing](https://arxiv.org/abs/2209.15003) if an initial
    query is in natural language to transform it into a structured format).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ›´é«˜å±‚æ¬¡ä¸Šï¼ŒNGDBåŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š**ç¥ç»å›¾å­˜å‚¨**å’Œ**ç¥ç»æŸ¥è¯¢å¼•æ“**ã€‚æŸ¥è¯¢å›ç­”æµç¨‹ä»æŸäº›åº”ç”¨ç¨‹åºæˆ–ä¸‹æ¸¸ä»»åŠ¡å‘é€çš„å·²ç»“æ„åŒ–æ ¼å¼çš„æŸ¥è¯¢å¼€å§‹ï¼ˆä¾‹å¦‚ï¼Œé€šè¿‡[è¯­ä¹‰è§£æ](https://arxiv.org/abs/2209.15003)å°†åˆå§‹è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºç»“æ„åŒ–æ ¼å¼ï¼‰ã€‚
- en: The query first arrives to the Neural Query Engine, and, in particular, to the
    *Query Planner* module. The task of the Query Planner is to derive an efficient
    computation graph of atomic operations (projections and logical operations) with
    respect to the query complexity, prediction tasks, and underlying data storage
    such as possible graph partitioning.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥è¯¢é¦–å…ˆåˆ°è¾¾ç¥ç»æŸ¥è¯¢å¼•æ“ï¼Œç‰¹åˆ«æ˜¯åˆ°*æŸ¥è¯¢è§„åˆ’å™¨*æ¨¡å—ã€‚æŸ¥è¯¢è§„åˆ’å™¨çš„ä»»åŠ¡æ˜¯æ ¹æ®æŸ¥è¯¢å¤æ‚æ€§ã€é¢„æµ‹ä»»åŠ¡å’Œåº•å±‚æ•°æ®å­˜å‚¨ï¼ˆå¦‚å¯èƒ½çš„å›¾åˆ’åˆ†ï¼‰ç”Ÿæˆä¸€ä¸ªé«˜æ•ˆçš„åŸå­æ“ä½œè®¡ç®—å›¾ã€‚
- en: The derived plan is then sent to the *Query Executor* that encodes the query
    in a latent space, executes the atomic operations over the underlying graph and
    its latent representations, and aggregates the results of atomic operations into
    a final answer set. The execution is done via the *Retrieval* module that communicates
    with the *Neural Graph Storage*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„è®¡åˆ’éšåè¢«é€å¾€*æŸ¥è¯¢æ‰§è¡Œå™¨*ï¼Œè¯¥æ‰§è¡Œå™¨å°†æŸ¥è¯¢ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œæ‰§è¡Œå¯¹åº•å±‚å›¾åŠå…¶æ½œåœ¨è¡¨ç¤ºçš„åŸå­æ“ä½œï¼Œå¹¶å°†åŸå­æ“ä½œçš„ç»“æœèšåˆæˆæœ€ç»ˆç­”æ¡ˆé›†ã€‚æ‰§è¡Œæ˜¯é€šè¿‡ä¸*ç¥ç»å›¾å­˜å‚¨*é€šä¿¡çš„*æ£€ç´¢*æ¨¡å—å®Œæˆçš„ã€‚
- en: The storage layer consists of
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å­˜å‚¨å±‚åŒ…æ‹¬
- en: 1ï¸âƒ£ *Graph Store* for keeping the multi-relational adjacency matrix in space-
    and time-efficient manner (eg, in various sparse formats like COO and CSR);
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ *å›¾å­˜å‚¨* ç”¨äºä»¥ç©ºé—´å’Œæ—¶é—´é«˜æ•ˆçš„æ–¹å¼ä¿å­˜å¤šå…³ç³»é‚»æ¥çŸ©é˜µï¼ˆä¾‹å¦‚ï¼Œä»¥å„ç§ç¨€ç–æ ¼å¼å¦‚COOå’ŒCSRï¼‰ã€‚
- en: 2ï¸âƒ£ *Feature Store* for keeping node- and edge-level multimodal features associated
    with the underlying graph.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ *ç‰¹å¾å­˜å‚¨* ç”¨äºä¿å­˜ä¸åº•å±‚å›¾ç›¸å…³çš„èŠ‚ç‚¹å’Œè¾¹çº§å¤šæ¨¡æ€ç‰¹å¾ã€‚
- en: 3ï¸âƒ£ *Embedding Store* that leverages an Encoder module to produce graph representations
    in a latent space based on the underlying adjacency and associated features.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£ *åµŒå…¥å­˜å‚¨* åˆ©ç”¨ç¼–ç å™¨æ¨¡å—ç”ŸæˆåŸºäºåº•å±‚é‚»æ¥å’Œç›¸å…³ç‰¹å¾çš„æ½œåœ¨ç©ºé—´ä¸­çš„å›¾è¡¨ç¤ºã€‚
- en: The Retrieval module queries the encoded graph representations to build a distribution
    of potential answers to atomic operations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€ç´¢æ¨¡å—æŸ¥è¯¢ç¼–ç åçš„å›¾è¡¨ç¤ºï¼Œä»¥æ„å»ºæ½œåœ¨ç­”æ¡ˆçš„åˆ†å¸ƒã€‚
- en: '**Neural Graph Storage**'
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç¥ç»å›¾å­˜å‚¨**'
- en: '![](../Images/59c2e89f7e466bbfb47e484f362dd3ab.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59c2e89f7e466bbfb47e484f362dd3ab.png)'
- en: In traditional graph DBs (right), queries are optimized into a plan (often,
    a tree of join operators) and executed against the storage of DB indexes. In Neural
    Graph DBs (left), we encode the query (or its steps) in a latent space and execute
    against the latent space of the underlying graph. Image by Authors.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¼ ç»Ÿçš„å›¾æ•°æ®åº“ï¼ˆå³ä¾§ï¼‰ï¼ŒæŸ¥è¯¢è¢«ä¼˜åŒ–ä¸ºä¸€ä¸ªè®¡åˆ’ï¼ˆé€šå¸¸æ˜¯ä¸€ä¸ªè¿æ¥æ“ä½œç¬¦çš„æ ‘ï¼‰ï¼Œå¹¶æ‰§è¡Œäºæ•°æ®åº“ç´¢å¼•çš„å­˜å‚¨ä¸­ã€‚åœ¨ç¥ç»å›¾æ•°æ®åº“ï¼ˆå·¦ä¾§ï¼‰ä¸­ï¼Œæˆ‘ä»¬å°†æŸ¥è¯¢ï¼ˆæˆ–å…¶æ­¥éª¤ï¼‰ç¼–ç åˆ°ä¸€ä¸ªæ½œåœ¨ç©ºé—´ä¸­ï¼Œå¹¶åœ¨åº•å±‚å›¾çš„æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: In traditional graph DBs, storage design often depends on the graph modeling
    paradigm.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¼ ç»Ÿçš„å›¾æ•°æ®åº“ä¸­ï¼Œå­˜å‚¨è®¾è®¡é€šå¸¸å–å†³äºå›¾å»ºæ¨¡èŒƒå¼ã€‚
- en: The two most popular paradigms are Resource Description Framework (RDF) graphs
    and Labeled Property Graphs (LPG). We posit, however, that the new [RDF-star](https://w3c.github.io/rdf-star/cg-spec/editors_draft.html)
    (and accompanying SPARQL-star) is going to unify those two merging logical expressiveness
    of RDF graphs with attributed nature of LPG. Many existing KGs already follow
    the RDF-star (-like) paradigm like [hyper-relational KGs](/representation-learning-on-rdf-and-lpg-knowledge-graphs-6a92f2660241)
    and [Wikidata Statement Model](https://www.wikidata.org/wiki/Help:Statements).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤ç§æœ€æµè¡Œçš„èŒƒå¼æ˜¯èµ„æºæè¿°æ¡†æ¶ï¼ˆRDFï¼‰å›¾å’Œæ ‡è®°å±æ€§å›¾ï¼ˆLPGï¼‰ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è®¤ä¸ºæ–°çš„ [RDF-star](https://w3c.github.io/rdf-star/cg-spec/editors_draft.html)ï¼ˆåŠå…¶ä¼´éšçš„SPARQL-starï¼‰å°†ç»Ÿä¸€è¿™ä¸¤ç§èŒƒå¼ï¼Œå°†RDFå›¾çš„é€»è¾‘è¡¨è¾¾æ€§ä¸LPGçš„å±æ€§ç‰¹æ€§èåˆèµ·æ¥ã€‚è®¸å¤šç°æœ‰çš„çŸ¥è¯†å›¾è°±å·²ç»éµå¾ªäº†ç±»ä¼¼RDF-starçš„èŒƒå¼ï¼Œå¦‚
    [è¶…å…³ç³»çŸ¥è¯†å›¾è°±](/representation-learning-on-rdf-and-lpg-knowledge-graphs-6a92f2660241)
    å’Œ [Wikidata Statement Model](https://www.wikidata.org/wiki/Help:Statements)ã€‚
- en: If we are to envision the backbone graph modeling paradigm in the next years,
    weâ€™d go for RDF-star.
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å±•æœ›æœªæ¥å‡ å¹´çš„éª¨å¹²å›¾å»ºæ¨¡èŒƒå¼ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©RDF-starã€‚
- en: 'In the Neural Graph Storage, both the input graph and its vector representations
    are sources of truth. For answering queries in the latent space, we need:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¥ç»å›¾å­˜å‚¨ä¸­ï¼Œè¾“å…¥å›¾åŠå…¶å‘é‡è¡¨ç¤ºéƒ½æ˜¯äº‹å®æ¥æºã€‚ä¸ºäº†åœ¨æ½œåœ¨ç©ºé—´ä¸­å›ç­”æŸ¥è¯¢ï¼Œæˆ‘ä»¬éœ€è¦ï¼š
- en: Query Encoder
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æŸ¥è¯¢ç¼–ç å™¨
- en: Graph Encoder
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å›¾ç¼–ç å™¨
- en: Retrieval mechanism to match query representation against the graph representation
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ£€ç´¢æœºåˆ¶ç”¨äºå°†æŸ¥è¯¢è¡¨ç¤ºä¸å›¾è¡¨ç¤ºè¿›è¡ŒåŒ¹é…
- en: The graph encoding (embedding) process can be viewed as a compression step but
    the semantic and structure similarity of entities/relations is kept. The distance
    between entities/relations in the embedding space should be positively correlated
    with the semantic/structure similarity. There are many options for the architecture
    of the encoder â€” and we recommend sticking to **inductive** ones to adhere to
    the NGDB design principles. In our recent [NeurIPS 2022 work](https://arxiv.org/abs/2210.08008),
    we presented two such inductive models.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç¼–ç ï¼ˆåµŒå…¥ï¼‰è¿‡ç¨‹å¯ä»¥è§†ä¸ºä¸€ä¸ªå‹ç¼©æ­¥éª¤ï¼Œä½†ä¿ç•™äº†å®ä½“/å…³ç³»çš„è¯­ä¹‰å’Œç»“æ„ç›¸ä¼¼æ€§ã€‚åµŒå…¥ç©ºé—´ä¸­å®ä½“/å…³ç³»ä¹‹é—´çš„è·ç¦»åº”è¯¥ä¸è¯­ä¹‰/ç»“æ„ç›¸ä¼¼æ€§æ­£ç›¸å…³ã€‚ç¼–ç å™¨çš„æ¶æ„æœ‰å¾ˆå¤šé€‰æ‹©â€”â€”æˆ‘ä»¬å»ºè®®åšæŒä½¿ç”¨**å½’çº³**å‹çš„ï¼Œä»¥éµå¾ªNGDBè®¾è®¡åŸåˆ™ã€‚åœ¨æˆ‘ä»¬æœ€è¿‘çš„[NeurIPS
    2022å·¥ä½œ](https://arxiv.org/abs/2210.08008)ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸¤ä¸ªè¿™æ ·çš„å½’çº³æ¨¡å‹ã€‚
- en: Query encoding is usually matched with the nature graph encoding such that both
    of them will be in the same space. Once we have latent representations, the Retrieval
    module kicks in to extract relevant answers.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥è¯¢ç¼–ç é€šå¸¸ä¸è‡ªç„¶å›¾ç¼–ç ç›¸åŒ¹é…ï¼Œä½¿å¾—å®ƒä»¬å¤„äºåŒä¸€ç©ºé—´ã€‚ä¸€æ—¦æˆ‘ä»¬æœ‰äº†æ½œåœ¨è¡¨ç¤ºï¼Œæ£€ç´¢æ¨¡å—å°±ä¼šå¯åŠ¨ä»¥æå–ç›¸å…³ç­”æ¡ˆã€‚
- en: 'The retrieval process can be seen as a nearest neighbor search of the input
    vector in the embedding space and has 3 direct benefits:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€ç´¢è¿‡ç¨‹å¯ä»¥è¢«è§†ä¸ºåœ¨åµŒå…¥ç©ºé—´ä¸­å¯¹è¾“å…¥å‘é‡çš„æœ€è¿‘é‚»æœç´¢ï¼Œå¹¶ä¸”å…·æœ‰3ä¸ªç›´æ¥å¥½å¤„ï¼š
- en: Confidence scores for each retrieved item â€” thanks to a predefined distance
    function in the embedding space
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ£€ç´¢é¡¹çš„ç½®ä¿¡åº¦è¯„åˆ†â€”â€”å¤šäºäº†åµŒå…¥ç©ºé—´ä¸­é¢„å®šä¹‰çš„è·ç¦»å‡½æ•°ã€‚
- en: Different definitions of the latent space and the distance function â€” catering
    for different graphs, eg, tree-like graphs are easier to work in hyperbolic spaces
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ½œåœ¨ç©ºé—´å’Œè·ç¦»å‡½æ•°çš„ä¸åŒå®šä¹‰â€”â€”é’ˆå¯¹ä¸åŒçš„å›¾ï¼Œä¾‹å¦‚ï¼Œæ ‘çŠ¶å›¾åœ¨åŒæ›²ç©ºé—´ä¸­æ›´æ˜“äºå¤„ç†ã€‚
- en: Efficiency and scalability â€” retrieval scales to extremely large graphs with
    billions of nodes and edges
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ•ˆç‡å’Œå¯æ‰©å±•æ€§â€”â€”æ£€ç´¢å¯ä»¥æ‰©å±•åˆ°åŒ…å«æ•°åäº¿èŠ‚ç‚¹å’Œè¾¹çš„æå¤§å›¾ã€‚
- en: '**Neural Query Engine**'
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**ç¥ç»æŸ¥è¯¢å¼•æ“**'
- en: '![](../Images/d34c8122344f986bba31e4b69db9153e.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d34c8122344f986bba31e4b69db9153e.png)'
- en: Query planning in NGDBs (left) and traditional graph DBs (right). The NGDB planning
    (assuming incomplete graphs) can be performed autoregressively step-by-step (1)
    or generated entirely in one step (2). The traditional DB planning is cost-based
    and resorts to metadata (assuming complete graphs and extracted from them) such
    as the number of intermediate answers to build a tree of join operators. Image
    by Authors
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: NGDBsï¼ˆå·¦ï¼‰å’Œä¼ ç»Ÿå›¾æ•°æ®åº“ï¼ˆå³ï¼‰çš„æŸ¥è¯¢è§„åˆ’ã€‚NGDBè§„åˆ’ï¼ˆå‡è®¾å›¾ä¸å®Œæ•´ï¼‰å¯ä»¥é€æ­¥è‡ªå›å½’æ‰§è¡Œï¼ˆ1ï¼‰æˆ–å®Œå…¨ç”Ÿæˆä¸€ä¸ªæ­¥éª¤ï¼ˆ2ï¼‰ã€‚ä¼ ç»Ÿæ•°æ®åº“è§„åˆ’æ˜¯åŸºäºæˆæœ¬çš„ï¼Œå¹¶ä¸”ä¾èµ–äºå…ƒæ•°æ®ï¼ˆå‡è®¾å›¾å®Œæ•´å¹¶ä»ä¸­æå–ï¼‰ï¼Œä¾‹å¦‚ä¸­é—´ç­”æ¡ˆçš„æ•°é‡æ¥æ„å»ºè¿æ¥æ“ä½œç¬¦çš„æ ‘ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: In traditional DBs, a typical query engine performs three major operations.
    (1) **Query parsing** to verify syntax correctness (often enriched with a deeper
    semantic analysis of query terms); (2) **Query planning** and optimization to
    derive an efficient query plan (usually, a tree of relational operators) that
    minimizes computational costs; (3) **Query execution** that scans the storage
    and processes intermediate results according to the query plan.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¼ ç»Ÿæ•°æ®åº“ä¸­ï¼Œå…¸å‹çš„æŸ¥è¯¢å¼•æ“æ‰§è¡Œä¸‰ä¸ªä¸»è¦æ“ä½œã€‚(1) **æŸ¥è¯¢è§£æ**ä»¥éªŒè¯è¯­æ³•æ­£ç¡®æ€§ï¼ˆé€šå¸¸ä¼šè¿›è¡Œæ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰åˆ†æï¼‰ï¼›(2) **æŸ¥è¯¢è§„åˆ’**å’Œä¼˜åŒ–ä»¥å¾—å‡ºä¸€ä¸ªæœ‰æ•ˆçš„æŸ¥è¯¢è®¡åˆ’ï¼ˆé€šå¸¸æ˜¯å…³ç³»æ“ä½œç¬¦çš„æ ‘ï¼‰ï¼Œä»¥æœ€å°åŒ–è®¡ç®—æˆæœ¬ï¼›(3)
    **æŸ¥è¯¢æ‰§è¡Œ**æ ¹æ®æŸ¥è¯¢è®¡åˆ’æ‰«æå­˜å‚¨å¹¶å¤„ç†ä¸­é—´ç»“æœã€‚
- en: It is rather straightforward to extend those operations to NGDBs.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¿™äº›æ“ä½œæ‰©å±•åˆ°NGDBsæ˜¯ç›¸å½“ç®€å•çš„ã€‚
- en: 1ï¸âƒ£ Query Parsing can be achieved via semantic parsing to a structured query
    format. We intentionally leave the discussion on a query language for NGDBs for
    future works and heated public discussions ğŸ˜‰
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ æŸ¥è¯¢è§£æå¯ä»¥é€šè¿‡è¯­ä¹‰è§£æè½¬åŒ–ä¸ºç»“æ„åŒ–æŸ¥è¯¢æ ¼å¼ã€‚æˆ‘ä»¬æ•…æ„å°†NGDBsçš„æŸ¥è¯¢è¯­è¨€è®¨è®ºç•™å¾…æœªæ¥çš„å·¥ä½œå’Œçƒ­çƒˆçš„å…¬ä¼—è®¨è®ºğŸ˜‰
- en: 2ï¸âƒ£ Query Planner derives an efficient query plan of atomic operations (projections
    and logical operators) maximizing completeness (all answers over existing edges
    must be returned) and inference (of missing edges predicted on the fly) taking
    into account query complexity and underlying graph.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ æŸ¥è¯¢è§„åˆ’å™¨å¾—å‡ºåŸå­æ“ä½œï¼ˆæŠ•å½±å’Œé€»è¾‘æ“ä½œç¬¦ï¼‰çš„æœ‰æ•ˆæŸ¥è¯¢è®¡åˆ’ï¼Œæœ€å¤§åŒ–å®Œæ•´æ€§ï¼ˆå¿…é¡»è¿”å›æ‰€æœ‰ç°æœ‰è¾¹ä¸Šçš„ç­”æ¡ˆï¼‰å’Œæ¨æ–­ï¼ˆå³æ—¶é¢„æµ‹ç¼ºå¤±è¾¹ï¼‰åŒæ—¶è€ƒè™‘æŸ¥è¯¢å¤æ‚æ€§å’Œåº•å±‚å›¾ã€‚
- en: '3ï¸âƒ£ Once the query plan is finalized, the Query Executor encodes the query
    (or its parts) into a latent space, communicates with the Graph Storage and its
    Retrieval module, and aggregates intermediate results into the final answer set.
    There exist two common mechanisms for query execution:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£ ä¸€æ—¦æŸ¥è¯¢è®¡åˆ’å®Œæˆï¼ŒæŸ¥è¯¢æ‰§è¡Œå™¨å°†æŸ¥è¯¢ï¼ˆæˆ–å…¶éƒ¨åˆ†ï¼‰ç¼–ç åˆ°æ½œåœ¨ç©ºé—´ï¼Œä¸å›¾å­˜å‚¨åŠå…¶æ£€ç´¢æ¨¡å—è¿›è¡Œé€šä¿¡ï¼Œå¹¶å°†ä¸­é—´ç»“æœèšåˆåˆ°æœ€ç»ˆç­”æ¡ˆé›†ä¸­ã€‚æŸ¥è¯¢æ‰§è¡Œå­˜åœ¨ä¸¤ç§å¸¸è§æœºåˆ¶ï¼š
- en: '*Atomic*, resembling traditional DBs, when a query plan is executed sequentially
    by encoding atomic patterns, retrieving their answers, and executing logical operators
    as intermediate steps;'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*åŸå­*ï¼Œç±»ä¼¼äºä¼ ç»Ÿæ•°æ®åº“ï¼Œå½“æŸ¥è¯¢è®¡åˆ’æŒ‰é¡ºåºæ‰§è¡Œï¼Œé€šè¿‡ç¼–ç åŸå­æ¨¡å¼ã€æ£€ç´¢å…¶ç­”æ¡ˆå’Œæ‰§è¡Œé€»è¾‘æ“ä½œä½œä¸ºä¸­é—´æ­¥éª¤ï¼›'
- en: '*Global*, when the entire query graph is encoded and executed in a latent space
    in one step.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*å…¨å±€*ï¼Œå½“æ•´ä¸ªæŸ¥è¯¢å›¾åœ¨ä¸€ä¸ªæ­¥éª¤ä¸­è¢«ç¼–ç å¹¶åœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œã€‚'
- en: The main challenge for neural query execution is matching query expressiveness
    to that of symbolic languages like SPARQL or Cypher â€” so far, neural methods can
    execute queries close to First-Order Logic expressiveness, but we are somewhat
    halfway there to symbolic languages.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»æŸ¥è¯¢æ‰§è¡Œçš„ä¸»è¦æŒ‘æˆ˜æ˜¯å°†æŸ¥è¯¢è¡¨è¾¾èƒ½åŠ›ä¸ SPARQL æˆ– Cypher ç­‰ç¬¦å·è¯­è¨€åŒ¹é…â€”â€”è¿„ä»Šä¸ºæ­¢ï¼Œç¥ç»æ–¹æ³•å¯ä»¥æ‰§è¡Œæ¥è¿‘ä¸€é˜¶é€»è¾‘è¡¨è¾¾èƒ½åŠ›çš„æŸ¥è¯¢ï¼Œä½†åœ¨ç¬¦å·è¯­è¨€æ–¹é¢è¿˜å·®ä¸€åŠã€‚
- en: A Taxonomy of Neural Graph Reasoning for Query Engines
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¥ç»å›¾æ¨ç†çš„åˆ†ç±»å­¦ç”¨äºæŸ¥è¯¢å¼•æ“
- en: The literature on neural methods for complex logical query answering (aka, *query
    embedding*) has been growing since 2018 and the seminal NeurIPS work of [Hamilton
    et al](https://proceedings.neurips.cc/paper/7473-embedding-logical-queries-on-knowledge-graphs)
    on **Graph Query Embedding** (GQE). GQE was able to answer conjunctive queries
    with intersections and predict missing links on the fly.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ª 2018 å¹´ä»¥æ¥ï¼Œå…³äºå¤æ‚é€»è¾‘æŸ¥è¯¢å›ç­”çš„ç¥ç»æ–¹æ³•ï¼ˆå³*æŸ¥è¯¢åµŒå…¥*ï¼‰çš„æ–‡çŒ®ä¸æ–­å¢åŠ ï¼Œç‰¹åˆ«æ˜¯ [Hamilton ç­‰äºº](https://proceedings.neurips.cc/paper/7473-embedding-logical-queries-on-knowledge-graphs)
    åœ¨**å›¾æŸ¥è¯¢åµŒå…¥**ï¼ˆGQEï¼‰æ–¹é¢çš„å¼€åˆ›æ€§ NeurIPS å·¥ä½œã€‚GQE èƒ½å¤Ÿå›ç­”å¸¦æœ‰äº¤é›†çš„è”æ¥æŸ¥è¯¢ï¼Œå¹¶å®æ—¶é¢„æµ‹ç¼ºå¤±çš„é“¾æ¥ã€‚
- en: GQE can be considered as the first take on Neural Query Engines for NGDBs.
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GQE å¯ä»¥è¢«è§†ä¸ºå¯¹ NGDBs çš„ç¥ç»æŸ¥è¯¢å¼•æ“çš„ç¬¬ä¸€æ¬¡å°è¯•ã€‚
- en: 'GQE started the whole subfield of Graph Machine Learning followed by some prominent
    examples like [Query2Box (ICLR 2020)](https://openreview.net/forum?id=BJgr4kSFDS)
    and [Continuous Query Decomposition (ICLR 2021)](https://openreview.net/forum?id=Mos9F9kDwkz).
    We undertook a major effort categorizing all those (about 50) works along 3 main
    directions:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: GQE å¼€åˆ›äº†å›¾æœºå™¨å­¦ä¹ çš„æ•´ä¸ªå­é¢†åŸŸï¼Œéšåå‡ºç°äº†ä¸€äº›è‘—åçš„ä¾‹å­ï¼Œå¦‚ [Query2Box (ICLR 2020)](https://openreview.net/forum?id=BJgr4kSFDS)
    å’Œ [Continuous Query Decomposition (ICLR 2021)](https://openreview.net/forum?id=Mos9F9kDwkz)ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹é‡å¤§å·¥ä½œï¼Œå°†æ‰€æœ‰è¿™äº›ï¼ˆçº¦
    50 é¡¹ï¼‰å·¥ä½œæŒ‰ 3 ä¸ªä¸»è¦æ–¹å‘è¿›è¡Œäº†åˆ†ç±»ï¼š
- en: âš›ï¸ **Graphs** â€” what is the underlying structure against which we answer queries;
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: âš›ï¸ **å›¾**â€”â€”æˆ‘ä»¬å›ç­”æŸ¥è¯¢çš„åŸºç¡€ç»“æ„æ˜¯ä»€ä¹ˆï¼›
- en: ğŸ› ï¸ **Modeling** â€” how we answer queries and which inductive biases are employed;
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ› ï¸ **å»ºæ¨¡**â€”â€”æˆ‘ä»¬å¦‚ä½•å›ç­”æŸ¥è¯¢ä»¥åŠé‡‡ç”¨äº†å“ªäº›å½’çº³åå·®ï¼›
- en: ğŸ—£ï¸ **Queries** â€” what we answer, what are the query structures and what are
    the expected answers.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ—£ï¸ **æŸ¥è¯¢**â€”â€”æˆ‘ä»¬å›ç­”ä»€ä¹ˆï¼ŒæŸ¥è¯¢ç»“æ„æ˜¯ä»€ä¹ˆï¼Œä»¥åŠé¢„æœŸçš„ç­”æ¡ˆæ˜¯ä»€ä¹ˆã€‚
- en: '![](../Images/96529703229bccd94ad6c37088dd2a2b.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96529703229bccd94ad6c37088dd2a2b.png)'
- en: The taxonomy of neural approaches for complex logical query answering. See the
    <paper> for more details. Image by Authors
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å¤æ‚é€»è¾‘æŸ¥è¯¢å›ç­”çš„ç¥ç»æ–¹æ³•åˆ†ç±»ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§<paper>ã€‚å›¾åƒç”±ä½œè€…æä¾›
- en: âš›ï¸ Talking about **Graphs**, we further break them down into **Modality** (classic
    triple-only graphs, hyper-relational graphs, hypergraphs, and more), **Reasoning
    Domain** (discrete entities or including continuous outputs), and **Semantics**
    (how neural encoders capture higher-order relationships like OWL ontologies).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: âš›ï¸ è¯´åˆ°**å›¾**ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å°†å…¶ç»†åˆ†ä¸º**æ¨¡æ€**ï¼ˆç»å…¸çš„ä¸‰å…ƒç»„å›¾ã€è¶…å…³ç³»å›¾ã€è¶…å›¾ç­‰ï¼‰ã€**æ¨ç†é¢†åŸŸ**ï¼ˆç¦»æ•£å®ä½“æˆ–åŒ…æ‹¬è¿ç»­è¾“å‡ºï¼‰å’Œ**è¯­ä¹‰**ï¼ˆç¥ç»ç¼–ç å™¨å¦‚ä½•æ•æ‰æ›´é«˜é˜¶å…³ç³»ï¼Œå¦‚
    OWL æœ¬ä½“ï¼‰ã€‚
- en: ğŸ› ï¸ In **Modeling**, we follow the Encoder-Processor-Decoder paradigm classifying
    inductive biases of existing models, eg, transductive or inductive encoders with
    neural or neuro-symbolic processors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ› ï¸ åœ¨**å»ºæ¨¡**ä¸­ï¼Œæˆ‘ä»¬éµå¾ªç¼–ç å™¨-å¤„ç†å™¨-è§£ç å™¨èŒƒå¼ï¼Œå¯¹ç°æœ‰æ¨¡å‹çš„å½’çº³åå·®è¿›è¡Œåˆ†ç±»ï¼Œä¾‹å¦‚ï¼Œå…·æœ‰ç¥ç»æˆ–ç¥ç»ç¬¦å·å¤„ç†å™¨çš„ä¼ é€’æ€§æˆ–å½’çº³ç¼–ç å™¨ã€‚
- en: ğŸ—£ï¸ In **Queries**, we aim at mapping the set of queries answerable by neural
    methods with that of symbolic graph query languages. We talk about **Query Operators**
    (going beyond standard And/Or/Not), **Query Patterns** (from chain-like queries
    to DAGs and cyclic patterns), and **Projected Variables** (your favorite relational
    algebra ).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ—£ï¸ åœ¨ **æŸ¥è¯¢** ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†ç¥ç»æ–¹æ³•èƒ½å¤Ÿå›ç­”çš„æŸ¥è¯¢é›†ä¸ç¬¦å·å›¾æŸ¥è¯¢è¯­è¨€çš„æŸ¥è¯¢é›†è¿›è¡Œæ˜ å°„ã€‚æˆ‘ä»¬è®¨è®º**æŸ¥è¯¢æ“ä½œç¬¦**ï¼ˆè¶…è¶Šæ ‡å‡†çš„ä¸/æˆ–/éï¼‰ï¼Œ**æŸ¥è¯¢æ¨¡å¼**ï¼ˆä»é“¾çŠ¶æŸ¥è¯¢åˆ°DAGå’Œå¾ªç¯æ¨¡å¼ï¼‰ï¼Œä»¥åŠ**æŠ•å½±å˜é‡**ï¼ˆä½ å–œæ¬¢çš„å…³ç³»ä»£æ•°ï¼‰ã€‚
- en: Open Challenges for NGDBs
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NGDBçš„å¼€æ”¾æŒ‘æˆ˜
- en: Analyzing the taxonomy we find that there is no silver bullet at the moment,
    eg, most processors can only work in discrete mode with tree-based queries. But
    it also means there is a lot of room for future work â€” possibly your contribution!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†æåˆ†ç±»æ³•æ—¶ï¼Œæˆ‘ä»¬å‘ç°ç›®å‰æ²¡æœ‰é“¶å¼¹ï¼Œä¾‹å¦‚ï¼Œå¤§å¤šæ•°å¤„ç†å™¨åªèƒ½åœ¨ç¦»æ•£æ¨¡å¼ä¸‹å¤„ç†åŸºäºæ ‘çš„æŸ¥è¯¢ã€‚ä½†è¿™ä¹Ÿæ„å‘³ç€æœªæ¥æœ‰å¾ˆå¤§çš„å·¥ä½œç©ºé—´â€”â€”å¯èƒ½åŒ…æ‹¬ä½ çš„è´¡çŒ®ï¼
- en: To be more precise, here are the main NGDB challenges for the following years.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å…·ä½“åœ°è¯´ï¼Œä»¥ä¸‹æ˜¯æœªæ¥å‡ å¹´NGDBçš„ä¸»è¦æŒ‘æˆ˜ã€‚
- en: 'Along the **Graph** branch:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¿ç€ **å›¾** åˆ†æ”¯ï¼š
- en: '**Modality**: Supporting more graph modalities: from classic triple-only graphs
    to hyper-relational graphs, hypergraphs, and multimodal sources combining graphs,
    texts, images, and more.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡æ€**ï¼šæ”¯æŒæ›´å¤šå›¾çš„æ¨¡æ€ï¼šä»ç»å…¸çš„ä»…ä¸‰å…ƒç»„å›¾åˆ°è¶…å…³ç³»å›¾ã€è¶…å›¾ä»¥åŠç»“åˆå›¾ã€æ–‡æœ¬ã€å›¾åƒç­‰çš„å¤šæ¨¡æ€æºã€‚'
- en: '**Reasoning Domain**: Supporting logical reasoning and neural query answering
    over temporal and continuous (textual and numerical) data â€” literals constitute
    a major portion of graphs as well as relevant queries over literals.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨ç†é¢†åŸŸ**ï¼šæ”¯æŒå¯¹æ—¶é—´å’Œè¿ç»­ï¼ˆæ–‡æœ¬å’Œæ•°å€¼ï¼‰æ•°æ®è¿›è¡Œé€»è¾‘æ¨ç†å’Œç¥ç»æŸ¥è¯¢å›ç­”â€”â€”å­—é¢é‡æ„æˆäº†å›¾çš„å¤§éƒ¨åˆ†ä»¥åŠå¯¹å­—é¢é‡çš„ç›¸å…³æŸ¥è¯¢ã€‚'
- en: '**Background Semantics**: Supporting complex axioms and formal semantics that
    encode higher-order relationships between (latent) classes of entities and their
    hierarchies, \eg, enabling neural reasoning over description logics and OWL fragments.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**èƒŒæ™¯è¯­ä¹‰**ï¼šæ”¯æŒå¤æ‚å…¬ç†å’Œå½¢å¼è¯­ä¹‰ï¼Œè¿™äº›è¯­ä¹‰ç¼–ç äº†ï¼ˆæ½œåœ¨çš„ï¼‰å®ä½“ç±»åŠå…¶å±‚æ¬¡ç»“æ„ä¹‹é—´çš„é«˜é˜¶å…³ç³»ï¼Œä¾‹å¦‚ï¼Œæ”¯æŒå¯¹æè¿°é€»è¾‘å’ŒOWLç‰‡æ®µè¿›è¡Œç¥ç»æ¨ç†ã€‚'
- en: 'In the **Modeling** branch:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ **å»ºæ¨¡** åˆ†æ”¯ï¼š
- en: '**Encoder**: Inductive encoders supporting unseen relation at inference time
    â€” this a key for (1) *updatability* of neural databases without the need of retraining;
    (2) enabling the *pretrain-finetune* strategy generalizing query answering to
    custom graphs with custom relational schema.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¼–ç å™¨**ï¼šæ”¯æŒåœ¨æ¨ç†æ—¶å¤„ç†æœªè§è¿‡çš„å…³ç³»â€”â€”è¿™æ˜¯ï¼ˆ1ï¼‰*å¯æ›´æ–°æ€§*çš„å…³é”®ï¼Œæ— éœ€é‡æ–°è®­ç»ƒå³å¯æ›´æ–°ç¥ç»æ•°æ®åº“ï¼›ï¼ˆ2ï¼‰å¯ç”¨*é¢„è®­ç»ƒ-å¾®è°ƒ*ç­–ç•¥ï¼Œå°†æŸ¥è¯¢å›ç­”æ¨å¹¿åˆ°å…·æœ‰è‡ªå®šä¹‰å…³ç³»æ¨¡å¼çš„è‡ªå®šä¹‰å›¾ã€‚'
- en: '**Processor**: Expressive processor networks able to effectively and efficiently
    execute complex query operators akin to SPARQL and Cypher operators. Improving
    sample efficiency of neural processors is crucial for the *training time vs quality*
    tradeoff â€” reducing training time while maintaining high predictive qualities.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤„ç†å™¨**ï¼šè¡¨è¾¾æ€§å¤„ç†å™¨ç½‘ç»œèƒ½å¤Ÿæœ‰æ•ˆä¸”é«˜æ•ˆåœ°æ‰§è¡Œç±»ä¼¼äºSPARQLå’ŒCypheræ“ä½œç¬¦çš„å¤æ‚æŸ¥è¯¢æ“ä½œç¬¦ã€‚æé«˜ç¥ç»å¤„ç†å™¨çš„æ ·æœ¬æ•ˆç‡å¯¹äº*è®­ç»ƒæ—¶é—´ä¸è´¨é‡*æƒè¡¡è‡³å…³é‡è¦â€”â€”åœ¨ä¿æŒé«˜é¢„æµ‹è´¨é‡çš„åŒæ—¶å‡å°‘è®­ç»ƒæ—¶é—´ã€‚'
- en: '**Decoder**: So far, all neural query answering decoders operate exclusively
    on discrete nodes. Extending the range of answers to continuous outputs is crucial
    for answering real-world queries.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è§£ç å™¨**ï¼šè¿„ä»Šä¸ºæ­¢ï¼Œæ‰€æœ‰ç¥ç»æŸ¥è¯¢å›ç­”è§£ç å™¨ä»…åœ¨ç¦»æ•£èŠ‚ç‚¹ä¸Šæ“ä½œã€‚æ‰©å±•ç­”æ¡ˆèŒƒå›´åˆ°è¿ç»­è¾“å‡ºå¯¹äºå›ç­”ç°å®ä¸–ç•Œçš„æŸ¥è¯¢è‡³å…³é‡è¦ã€‚'
- en: '**Complexity**: As the main computational bottleneck of processor networks
    is the dimensionality of embedding space (for purely neural models) and/or the
    number of nodes (for neuro-symbolic), new efficient algorithms for neural logical
    operators and retrieval methods are the key to scaling NGDBs to billions of nodes
    and trillions of edges.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤æ‚æ€§**ï¼šç”±äºå¤„ç†å™¨ç½‘ç»œçš„ä¸»è¦è®¡ç®—ç“¶é¢ˆæ˜¯åµŒå…¥ç©ºé—´çš„ç»´åº¦ï¼ˆå¯¹äºçº¯ç¥ç»æ¨¡å‹ï¼‰å’Œ/æˆ–èŠ‚ç‚¹æ•°ï¼ˆå¯¹äºç¥ç»-ç¬¦å·æ¨¡å‹ï¼‰ï¼Œæ–°å‹é«˜æ•ˆçš„ç¥ç»é€»è¾‘æ“ä½œç¬¦å’Œæ£€ç´¢æ–¹æ³•æ˜¯å°†NGDBæ‰©å±•åˆ°æ•°åäº¿èŠ‚ç‚¹å’Œä¸‡äº¿è¾¹çš„å…³é”®ã€‚'
- en: 'In **Queries**:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ **æŸ¥è¯¢** ä¸­ï¼š
- en: '**Operators**: Neuralizing more complex query operators matching the expressiveness
    of declarative graph query languages, e.g., supporting Kleene plus and star, property
    paths, filters.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ“ä½œç¬¦**ï¼šä½¿æ›´å¤æ‚çš„æŸ¥è¯¢æ“ä½œç¬¦å…·å¤‡ä¸å£°æ˜å¼å›¾æŸ¥è¯¢è¯­è¨€ç›¸åŒ¹é…çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä¾‹å¦‚ï¼Œæ”¯æŒå…‹æ—æ˜Ÿå·å’ŒåŠ å·ã€å±æ€§è·¯å¾„ã€è¿‡æ»¤å™¨ã€‚'
- en: '**Patterns**: Answering more complex patterns beyond tree-like queries. This
    includes DAGs and cyclic graphs.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¨¡å¼**ï¼šå›ç­”æ¯”æ ‘çŠ¶æŸ¥è¯¢æ›´å¤æ‚çš„æ¨¡å¼ï¼ŒåŒ…æ‹¬DAGå’Œå¾ªç¯å›¾ã€‚'
- en: '**Projected Variables**: Allowing projecting more than a final leaf node entity,
    that is, allowing returning intermediate variables, relations, and multiple variables
    organized in tuples (bindings).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æŠ•å½±å˜é‡**ï¼šå…è®¸æŠ•å½±è¶…å‡ºæœ€ç»ˆå¶èŠ‚ç‚¹å®ä½“ï¼Œå³å…è®¸è¿”å›ä¸­é—´å˜é‡ã€å…³ç³»ä»¥åŠç»„ç»‡åœ¨å…ƒç»„ï¼ˆç»‘å®šï¼‰ä¸­çš„å¤šä¸ªå˜é‡ã€‚'
- en: '**Expressiveness**: Answering queries outside simple EPFO and EFO fragments
    and aiming for the expressiveness of database languages.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¡¨è¾¾èƒ½åŠ›**ï¼šå›ç­”è¶…å‡ºç®€å•EPFOå’ŒEFOç‰‡æ®µçš„æŸ¥è¯¢ï¼Œå¹¶è¿½æ±‚æ•°æ®åº“è¯­è¨€çš„è¡¨è¾¾èƒ½åŠ›ã€‚'
- en: 'Finally, in **Datasets** and **Evaluation**:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œåœ¨**æ•°æ®é›†**å’Œ**è¯„ä¼°**æ–¹é¢ï¼š
- en: The need for larger and **diverse benchmarks** covering more graph modalities,
    more expressive query semantics, more query operators, and query patterns.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éœ€è¦æ›´å¤§ä¸”**å¤šæ ·åŒ–çš„åŸºå‡†**ï¼Œæ¶µç›–æ›´å¤šå›¾æ¨¡å¼ã€æ›´å…·è¡¨ç°åŠ›çš„æŸ¥è¯¢è¯­ä¹‰ã€æ›´å¤šæŸ¥è¯¢æ“ä½œç¬¦å’ŒæŸ¥è¯¢æ¨¡å¼ã€‚
- en: As the existing evaluation protocol appears to be limited (focusing only on
    inferring *hard* answers) there is a need for a more **principled evaluation framework
    and metrics** covering various aspects of the query answering workflow.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±äºç°æœ‰çš„è¯„ä¼°åè®®ä¼¼ä¹æœ‰é™ï¼ˆä»…å…³æ³¨æ¨æ–­*ç¡¬*ç­”æ¡ˆï¼‰ï¼Œéœ€è¦ä¸€ä¸ªæ›´**æœ‰åŸåˆ™çš„è¯„ä¼°æ¡†æ¶å’ŒæŒ‡æ ‡**ï¼Œæ¶µç›–æŸ¥è¯¢å›ç­”å·¥ä½œæµçš„å„ä¸ªæ–¹é¢ã€‚
- en: 'Pertaining to the Neural Graph Storage and NGDB in general, we identify the
    following challenges:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºç¥ç»å›¾å­˜å‚¨å’ŒNGDBçš„ä¸€èˆ¬æƒ…å†µï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºä»¥ä¸‹æŒ‘æˆ˜ï¼š
- en: The need for a **scalable retrieval** mechanism to scale neural reasoning to
    graphs of billions of nodes. Retrieval is tightly connected to the Query Processor
    and its modeling priors. Existing scalable ANN libraries can only work with basic
    L1, L2, and cosine distances that limit the space of possible processors in the
    neural query engine.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: éœ€è¦ä¸€ä¸ª**å¯æ‰©å±•æ£€ç´¢**æœºåˆ¶æ¥å°†ç¥ç»æ¨ç†æ‰©å±•åˆ°æ•°åäº¿èŠ‚ç‚¹çš„å›¾ã€‚æ£€ç´¢ä¸æŸ¥è¯¢å¤„ç†å™¨åŠå…¶å»ºæ¨¡å…ˆéªŒç´§å¯†ç›¸å…³ã€‚ç°æœ‰çš„å¯æ‰©å±•ANNåº“åªèƒ½å¤„ç†åŸºæœ¬çš„L1ã€L2å’Œä½™å¼¦è·ç¦»ï¼Œè¿™é™åˆ¶äº†ç¥ç»æŸ¥è¯¢å¼•æ“ä¸­å¯èƒ½çš„å¤„ç†å™¨ç©ºé—´ã€‚
- en: Currently, all complex query datasets provide a hardcoded query execution plan
    that might not be optimal. There is a need for a **neural query planner** that
    would transform an input query into an optimal execution sequence taking into
    account prediction tasks, query complexity, type of the neural processor, and
    configuration of the Storage layer.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼Œæ‰€æœ‰å¤æ‚æŸ¥è¯¢æ•°æ®é›†æä¾›äº†ä¸€ä¸ªç¡¬ç¼–ç çš„æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ï¼Œå¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„ã€‚éœ€è¦ä¸€ä¸ª**ç¥ç»æŸ¥è¯¢è§„åˆ’å™¨**ï¼Œèƒ½å¤Ÿå°†è¾“å…¥æŸ¥è¯¢è½¬æ¢ä¸ºæœ€ä¼˜æ‰§è¡Œåºåˆ—ï¼Œè€ƒè™‘é¢„æµ‹ä»»åŠ¡ã€æŸ¥è¯¢å¤æ‚æ€§ã€ç¥ç»å¤„ç†å™¨ç±»å‹å’Œå­˜å‚¨å±‚é…ç½®ã€‚
- en: Due to encoder inductiveness and updatability without retraining, there is a
    need to alleviate the issues of **continual learning**, **catastrophic forgetting**,
    and **size generalization** when running inference on much larger graphs than
    training ones.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºç¼–ç å™¨çš„å½’çº³æ€§å’Œå¯æ›´æ–°æ€§è€Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œè¿è¡Œæ¨ç†æ—¶åœ¨æ¯”è®­ç»ƒå›¾æ›´å¤§çš„å›¾ä¸Šå­˜åœ¨éœ€è¦ç¼“è§£**æŒç»­å­¦ä¹ **ã€**ç¾éš¾æ€§é—å¿˜**å’Œ**è§„æ¨¡æ³›åŒ–**çš„é—®é¢˜ã€‚
- en: Learn More
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äº†è§£æ›´å¤š
- en: NGDB is still an emerging concept with many open challenges for future research.
    If you want to learn more about NGDB, feel free to check out
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: NGDBä»ç„¶æ˜¯ä¸€ä¸ªæ–°å…´æ¦‚å¿µï¼Œé¢ä¸´è®¸å¤šæœªæ¥ç ”ç©¶çš„æŒ‘æˆ˜ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºNGDBçš„å†…å®¹ï¼Œå¯ä»¥æŸ¥çœ‹
- en: ğŸ“œ our paper ([arxiv](https://arxiv.org/abs/2303.14617)),
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ“œ æˆ‘ä»¬çš„è®ºæ–‡ ([arxiv](https://arxiv.org/abs/2303.14617))ï¼Œ
- en: ğŸŒ [our website](https://www.ngdb.org/),
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸŒ [æˆ‘ä»¬çš„ç½‘ç«™](https://www.ngdb.org/)ï¼Œ
- en: ğŸ”§ [GitHub repo](https://github.com/neuralgraphdatabases/awesome-logical-query)
    with the most up-to-date list of relevant papers, datasets, and categorization,
    feel free to open issues and PRs.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ”§ [GitHub ä»“åº“](https://github.com/neuralgraphdatabases/awesome-logical-query)åŒ…å«æœ€æ–°çš„ç›¸å…³è®ºæ–‡ã€æ•°æ®é›†å’Œåˆ†ç±»ï¼Œæ¬¢è¿æå‡ºé—®é¢˜å’ŒPRã€‚
- en: We will also be organizing workshops, stay tuned for the updates!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å°†ç»„ç»‡ç ”è®¨ä¼šï¼Œè¯·å…³æ³¨æœ€æ–°åŠ¨æ€ï¼
