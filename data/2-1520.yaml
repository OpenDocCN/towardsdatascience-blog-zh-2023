- en: Mixture-of-Softmaxes for Deep Session-based Recommender Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度会话推荐系统中的 Softmax 混合模型
- en: 原文：[https://towardsdatascience.com/mixture-of-softmaxes-for-deep-session-based-recommender-systems-aea5727e213d](https://towardsdatascience.com/mixture-of-softmaxes-for-deep-session-based-recommender-systems-aea5727e213d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mixture-of-softmaxes-for-deep-session-based-recommender-systems-aea5727e213d](https://towardsdatascience.com/mixture-of-softmaxes-for-deep-session-based-recommender-systems-aea5727e213d)
- en: Modern session-based deep recommender systems can be somehow limited by the
    softmax bottleneck like their language model cousins
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代会话基础的深度推荐系统在某种程度上可能会受到 softmax 瓶颈的限制，就像它们的语言模型类似物一样。
- en: '[](https://biarnes-adrien.medium.com/?source=post_page-----aea5727e213d--------------------------------)[![Adrien
    Biarnes](../Images/105f2bb62cb2bf825d74ea85b14eabfc.png)](https://biarnes-adrien.medium.com/?source=post_page-----aea5727e213d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----aea5727e213d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----aea5727e213d--------------------------------)
    [Adrien Biarnes](https://biarnes-adrien.medium.com/?source=post_page-----aea5727e213d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://biarnes-adrien.medium.com/?source=post_page-----aea5727e213d--------------------------------)[![Adrien
    Biarnes](../Images/105f2bb62cb2bf825d74ea85b14eabfc.png)](https://biarnes-adrien.medium.com/?source=post_page-----aea5727e213d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----aea5727e213d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----aea5727e213d--------------------------------)
    [Adrien Biarnes](https://biarnes-adrien.medium.com/?source=post_page-----aea5727e213d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----aea5727e213d--------------------------------)
    ·15 min read·Jul 18, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----aea5727e213d--------------------------------)
    ·15 分钟阅读·2023年7月18日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1e8ad6bdeba47c5c5c75fc5e30fcb86e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e8ad6bdeba47c5c5c75fc5e30fcb86e.png)'
- en: Photo by [Preethi Viswanathan](https://unsplash.com/@sallybrad2016?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Preethi Viswanathan](https://unsplash.com/@sallybrad2016?utm_source=medium&utm_medium=referral)
    拍摄的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: 'TL;DR:'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'TL;DR:'
- en: The traditional softmax is limited in its capacity to fully model tasks like
    natural language that are highly context-dependent. This limit in expressiveness
    called the Softmax bottleneck can be described through the lenses of matrix factorization
    and the study of the resulting matrix ranks.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的 softmax 在完全建模像自然语言这种高度依赖上下文的任务时能力有限。这种表现力的限制被称为 Softmax 瓶颈，可以通过矩阵分解和研究结果矩阵的秩来描述。
- en: The Mixture of Softmaxes [by Yang et al.](https://arxiv.org/pdf/1711.03953.pdf)
    [1] allows for overcoming the bottleneck by increasing the expressiveness of the
    network without exploding the number of parameters.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Yang 等人提出的 Softmax 混合模型 [by Yang et al.](https://arxiv.org/pdf/1711.03953.pdf)
    [1] 通过增加网络的表现力而不增加参数数量，从而克服了瓶颈。
- en: In this work, I study whether this limitation also applies to deep session-based
    recommender systems and whether the MoS technique can be beneficial. I implemented
    the technique and applied it to a Gru4Rec architecture using [the movielens-25m
    dataset](https://grouplens.org/datasets/movielens/25m/) [3]. The result is that
    it depends…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，我研究了这一限制是否也适用于深度会话推荐系统，并且 MoS 技术是否能带来好处。我实现了这一技术，并将其应用于 Gru4Rec 架构，使用了[Movielens-25m
    数据集](https://grouplens.org/datasets/movielens/25m/) [3]。结果是，这取决于……
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: In a previous role, while working on a large-scale sequence-based deep recommender
    system, I was approached by the product team pointing out an identified use case
    when then the quality of the recommendation was really low. The recommended items
    were not coherent with what the user was watching and let’s just say that they
    were not the cream of the crop of what the company had to offer.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的工作中，当我在一个大规模的序列基础深度推荐系统上工作时，产品团队指出了一个用例，那个时候推荐的质量确实很低。推荐的项目与用户正在观看的内容不一致，可以说它们并不是公司所提供的最优质的内容。
- en: So what was happening? Well, after careful examination, we understood that it
    specifically concerned the items manually pushed by the content team to be displayed
    on the home page (which was even more problematic). The said items were found
    numerously in the user sequences extracted for learning. At first, it was pretty
    disturbing because we knew and previously demonstrated that the more the algorithm
    had examples of user sequences with a given item to learn from, the higher the
    quality of the recommendation for that specific item.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那么到底发生了什么呢？经过仔细检查，我们理解到这特别涉及到由内容团队手动推送到首页显示的条目（这更是一个问题）。这些条目在提取出来用于学习的用户序列中出现了很多。一开始，这让人相当困扰，因为我们知道并且以前已经证明了，算法从包含特定条目的用户序列中学习得越多，该特定条目的推荐质量就越高。
- en: '![](../Images/3405d2f7609cc01d5cea45c95f57ae5a.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3405d2f7609cc01d5cea45c95f57ae5a.png)'
- en: Typical increase in performance with volume — Image by author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 性能随着数据量的典型增长 — 作者提供的图片
- en: In this case, it was a perfect example of more data is not always better. User
    sequences with the given featured items were numerous but not coherent. We were
    switching from one subject (displayed on the home page) to a very different one.
    It was so because of the diversity of the users landing on the home page.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，这是一个数据量更多并不总是更好的完美例子。具有给定特征项的用户序列虽然很多，但却不一致。我们从一个主题（在首页显示的）切换到一个完全不同的主题。这是因为落在首页的用户的多样性。
- en: '![](../Images/161074bcfe97d4fefa170b8a2c69866c.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/161074bcfe97d4fefa170b8a2c69866c.png)'
- en: Image by author
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: It gave me the feeling that this diversity was confusing the algorithm. But
    that was more an intuition than a properly scientifically grounded fact.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我感觉到这种多样性让算法感到困惑。但这更多是一种直觉，而不是一个有科学依据的事实。
- en: 'A few days ago, I stumbled upon the paper “[BREAKING THE SOFTMAX BOTTLENECK:
    A HIGH-RANK RNN LANGUAGE MODEL](https://arxiv.org/pdf/1711.03953.pdf)” [1] (published
    at ICLR 2018) that gave me a more formal framework to understand why most classification
    neural networks are not equipped to handle high contextual diversity. In this
    blog post, we will first take a close look at the problem and explain the underlying
    theory. Then we will move on with an experiment to see whether the Mixture-of-Softmaxes
    technique can improve deep recommender systems which are framed as session-based
    classification tasks.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 几天前，我偶然发现了一篇论文“[突破Softmax瓶颈：高阶RNN语言模型](https://arxiv.org/pdf/1711.03953.pdf)”[1]（发表于ICLR
    2018），这篇论文给了我一个更正式的框架来理解为什么大多数分类神经网络无法处理高上下文多样性。在这篇博客文章中，我们将首先仔细看看这个问题，并解释其基础理论。然后我们将进行一个实验，看看Mixture-of-Softmaxes技术是否能改善被构建为基于会话的分类任务的深度推荐系统。
- en: The problem
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: First, let us recall that in most cases in order to select the correct label,
    a classification neural network has to score every possible option. In order to
    do that we produce a vector (let’s call it **h**) in a chosen output dimension,
    that generally does not exceed three digits, which is compared against other vectors
    representing the labels (the embedding vectors). This comparison is simply a dot
    product between the vectors. A dot product produces a scalar. It is a way to measure
    the similarity of 2 vectors. The result of the comparison with all the items (a
    matrix multiplication) is a vector called the logits with a dimension equal to
    the number of possible output classes (let’s call it **V**). Then the logits go
    through a softmax operation in order to produce the final probability vector.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们回顾一下，在大多数情况下，为了选择正确的标签，分类神经网络必须对每一个可能的选项进行评分。为了做到这一点，我们生成一个向量（我们称之为**h**），它在选定的输出维度中，通常不超过三位数字，这个向量与其他表示标签的向量（嵌入向量）进行比较。这个比较实际上是向量之间的点积。点积产生一个标量，它是一种测量两个向量相似性的方式。与所有条目进行比较的结果（矩阵乘法）是一个称为logits的向量，其维度等于可能的输出类别的数量（我们称之为**V**）。然后，logits通过softmax操作生成最终的概率向量。
- en: '![](../Images/1216d552ab88dd9d23dcf58cd7e42433.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1216d552ab88dd9d23dcf58cd7e42433.png)'
- en: Image by author
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The model I was using in my previous company was a sequence-based classification
    recurrent neural network. Given a sequence of consumed items, we want to predict
    the next consumed item among all the possible ones. It was an implementation of
    the paper “[Session-based Recommendations with Recurrent Neural Networks](https://arxiv.org/abs/1511.06939)”
    by Hidasi et al [2].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我在上一家公司使用的模型是基于序列的分类递归神经网络。给定一系列消费物品，我们希望在所有可能的物品中预测下一个消费物品。这是 Hidasi 等人论文 “[基于会话的推荐与递归神经网络](https://arxiv.org/abs/1511.06939)”
    的一个实现。
- en: '![](../Images/c993eb35f1cd7e3d74c96f6eb166934f.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c993eb35f1cd7e3d74c96f6eb166934f.png)'
- en: Image by author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: The output of the GRU cell before the scoring operation is just a vector in
    a relatively small chosen dimension. But what is a vector? Well, it is just a
    location in a vectorial space. So the goal of the network is to produce vectors
    that are close to each other (eg. small dot product values) when they are part
    of the same sequence.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在评分操作之前，GRU 单元的输出仅是一个相对较小维度的向量。但什么是向量？它只是向量空间中的一个位置。因此，网络的目标是生成在同一序列中彼此接近的向量（例如，小点积值）。
- en: So my question was, how is the algorithm going to handle use cases when the
    consumed items after a specific one are all very different from one another? If
    we consider what we just previously said, all the different consumed items (targets)
    must be close to the sequence item(s) (input). In the end, it is easy to build
    up the intuition that the more diverse the user sequences, eg. the more we jump
    from one subject to a completely different one, the harder it is for the algorithm
    to attain its learning objective. If all the user sequences are very diverse,
    then the items must be close and far away from one another at the same time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我的问题是，当在特定物品之后消费的所有物品彼此非常不同时，算法将如何处理这些情况？如果我们考虑之前说的，所有不同的消费物品（目标）必须接近于序列物品（输入）。最终，很容易形成直觉，即用户序列越多样化，例如，从一个主题跳到一个完全不同的主题，算法实现学习目标的难度就越大。如果所有用户序列非常多样化，那么物品必须同时既接近又远离彼此。
- en: Softmax as a Matrix Factorization
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Softmax 作为矩阵分解
- en: As we explained above, the softmax operation of a language model or a deep recommender
    system framed as a classification problem usually have the same last operations.
    They use a softmax on the logits which is the product of a hidden state **h**
    and an item embedding vector **w:**
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前解释的，将语言模型或深度推荐系统框架化为分类问题的 softmax 操作通常具有相同的最后操作步骤。它们对 logits 使用 softmax，logits
    是隐藏状态**h**和物品嵌入向量**w**的乘积：
- en: '![](../Images/aef23dcbd8a343ef493555654995eb6c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aef23dcbd8a343ef493555654995eb6c.png)'
- en: '[The paper](https://arxiv.org/pdf/1711.03953.pdf) introducing the Mixture-of-Softmaxes
    demonstrates that the above operation can be expressed as a matrix factorization.
    More formally, let **N** be the number of samples in the training dataset, **d**
    the chosen dimension for the item embeddings, and **V** the number of recommendable
    items. We can then define 3 matrices:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[论文](https://arxiv.org/pdf/1711.03953.pdf) 介绍了 Mixture-of-Softmaxes，并展示了上述操作可以表示为矩阵分解。更正式地说，设
    **N** 为训练数据集中样本的数量，**d** 为物品嵌入的选择维度，**V** 为可推荐的物品数量。我们可以定义 3 个矩阵：'
- en: '![](../Images/ae8b53d30a478cdf765476f417f3f15d.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae8b53d30a478cdf765476f417f3f15d.png)'
- en: '**H** ∈ R (N×d), the encoded contexts matrix'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H** ∈ R (N×d)，编码上下文矩阵'
- en: '**W** ∈ R (V×d), the item embeddings matrix'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**W** ∈ R (V×d)，物品嵌入矩阵'
- en: '**A** ∈ R (N×M), the log probabilities of the true data distribution P*'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A** ∈ R (N×M)，真实数据分布 P* 的对数概率'
- en: The demonstration is above the scope of this blog post, but basically what the
    authors manage to demonstrate is that the softmax operation increases the rank
    of the logits matrix by at most 1\. This means that the rank of the output log
    probability matrix is determined by the rank of the logits matrix.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这一演示超出了本文的范围，但基本上，作者展示的是 softmax 操作最多增加 logits 矩阵的秩 1。这意味着输出对数概率矩阵的秩由 logits
    矩阵的秩决定。
- en: So what is the link with the bottleneck?
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么，这与瓶颈有什么联系？
- en: If somehow, we had a way to get the probability matrix of the true contextual
    data distribution P*, we could (depending on the complexity of the task) manage
    to show that the rank of this matrix in the real world is very high. Theoretically,
    the rank of this matrix could reach the size of the vocabulary V.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以某种方式获得了真实上下文数据分布 P* 的概率矩阵，我们可能（根据任务的复杂性）能够展示在现实世界中这个矩阵的秩是非常高的。从理论上讲，这个矩阵的秩可以达到词汇表的大小
    V。
- en: But, as we just explained, in our modelization, the rank of the output matrix
    is determined by the rank of the logits which is the multiplication of matrices
    H and W. Also, for any two matrices X and Y, we have rank(XY) = min(rank(X), rank(Y)).
    In our case, this means that the rank of the logits matrix can not be higher than
    d (the maximum rank of both W and H— the embedding dimension of the items). This
    can be a severe limitation in cases when we are trying to model a highly contextual-dependent
    task.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但正如我们刚刚解释的，在我们的模型化中，输出矩阵的秩由 logits 的秩决定，后者是矩阵 H 和 W 的乘积。此外，对于任何两个矩阵 X 和 Y，我们有
    rank(XY) = min(rank(X), rank(Y))。在我们的情况下，这意味着 logits 矩阵的秩不能超过 d（W 和 H 的最大秩——项目的嵌入维度）。在试图建模高度依赖上下文的任务时，这可能是一个严重的限制。
- en: Why the bottleneck is a problem?
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么瓶颈是一个问题？
- en: As demonstrated by the authors, the vanilla softmax operation can be considered
    a small-rank matrix transformation. As a reminder, the rank of a matrix is the
    dimension of the vector space generated by its columns (or its rows). It determines
    the number of bases (the set of linearly independent vectors) that can be used
    to create the output using any linear combination. For language modeling, one
    could make the interpretation that it translates into the number of fundamental
    semantic meanings that a model can combine. Given the complexity of natural language,
    it is highly unlikely that a small rank is sufficient.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如作者所示，普通的 softmax 操作可以被认为是一个小秩矩阵变换。提醒一下，矩阵的秩是由其列（或行）生成的向量空间的维度。它决定了可以用来创建输出的基（线性无关向量集）的数量。在语言建模中，可以将其解释为模型可以组合的基本语义意义的数量。鉴于自然语言的复杂性，小秩很可能不足以满足需求。
- en: The solution
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'To overcome the softmax bottleneck, the authors of the paper introduce the
    Mixture-of-Softmaxes. MoS formulates the conditional distribution of an output
    class given the context as:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服 softmax 的瓶颈，论文的作者引入了 Mixture-of-Softmaxes（MoS）。MoS 将输出类别的条件分布在给定上下文的情况下表述为：
- en: '![](../Images/01af9cb0d674ceb46ef25c81414c608c.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01af9cb0d674ceb46ef25c81414c608c.png)'
- en: 'K softmaxes are used instead of one. A set of mixture weights **π** (the priors)
    dictate how much attention should be paid to each softmax. Both the mixture weights
    and the logits used by each softmax are dependent on the context **c** and the
    mixture component **k**. This means that MoS introduces two new weight matrices
    **P** ∈ R (Kd × d), and **W** ∈ R (K × d). They allow for the following computations:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 使用了 K 个 softmax，而不是一个。混合权重 **π**（先验）决定了每个 softmax 应该关注的程度。混合权重和每个 softmax 使用的
    logits 都依赖于上下文 **c** 和混合组件 **k**。这意味着 MoS 引入了两个新的权重矩阵 **P** ∈ R (Kd × d)，和 **W**
    ∈ R (K × d)。它们允许以下计算：
- en: '![](../Images/d26a27aebe8ddc759f8b33ceef8b8b3d.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d26a27aebe8ddc759f8b33ceef8b8b3d.png)'
- en: 'In the above, **g** is the equivalent of the hidden state **h** of the vanilla
    softmax. Let’s try to visualize what is happening here. First, we use the projection
    matrix to create the hidden states that will be used by each of the softmax heads
    out of **g**:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 上述公式中，**g** 相当于普通 softmax 的隐藏状态 **h**。让我们试着可视化这里发生的事情。首先，我们使用投影矩阵从 **g** 创建每个
    softmax 头所需的隐藏状态：
- en: '![](../Images/4fe96dbce0524ff2b81da714985f26fb.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fe96dbce0524ff2b81da714985f26fb.png)'
- en: Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Then we compute the set of mixture weights **π** also out of **g**. Note that
    we use the softmax activation to ensure that the mixture weights sum up to 1 for
    every context:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们计算出一组混合权重 **π**，同样是从 **g** 中计算得出的。请注意，我们使用 softmax 激活来确保每个上下文中的混合权重总和为 1：
- en: '![](../Images/cb4aec8864676bd6a34d8a58b15ab2f5.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cb4aec8864676bd6a34d8a58b15ab2f5.png)'
- en: Image by author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'The final computation can be pictured below:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的计算可以如图所示：
- en: '![](../Images/9b940c6dd46c398d5697c4ec24b32d73.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b940c6dd46c398d5697c4ec24b32d73.png)'
- en: Image by author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: So why does it solve the bottleneck issue?
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么为什么它能解决瓶颈问题呢？
- en: 'Recall that the cross-entropy loss (that we use to train the network) applies
    a logarithm transformation on the output probabilities. It means that we are approximating
    the log probabilities of the true data distribution with the following expression:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，交叉熵损失（我们用来训练网络的）对输出概率应用了对数变换。这意味着我们用以下表达式来近似真实数据分布的对数概率：
- en: '![](../Images/5c7b5bc581f3c621ed8474dce1069d1d.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c7b5bc581f3c621ed8474dce1069d1d.png)'
- en: where **Π**k is an (N × N) diagonal matrix with elements being the prior **π**c,k.
    Because it is a nonlinear function (log_sum_exp) of the context vectors and the
    word embeddings, the above function can be arbitrarily high-rank.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 其中**Π**k是一个（N × N）对角矩阵，元素为先验**π**c,k。由于这是上下文向量和词嵌入的非线性函数（log_sum_exp），上述函数可以是任意高阶。
- en: Does the softmax bottleneck apply to deep recommender systems?
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Softmax瓶颈是否适用于深度推荐系统？
- en: The softmax bottleneck indicates that the expressiveness is bounded by the embedding
    dimension d. If d is too small then the softmax does not have enough capacity
    to express the true data distribution. But this is only true if the true data
    distribution complexity requires a high capacity like when modeling natural language.
    Now what about sequential recommendation systems? Is the probability of a user
    consuming a specific item highly dependent on the context? Well, my feeling is
    that it depends on numerous factors like the quality and quantity of the features
    used by the model but also on factors like the one I described in the introduction.
    In the end, what I like to do about those questions is to perform experiments.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Softmax瓶颈表明表达能力受限于嵌入维度d。如果d过小，softmax没有足够的能力来表达真实的数据分布。但这只有在真实的数据分布复杂度需要高容量时才成立，比如建模自然语言。那在顺序推荐系统中呢？用户消费特定项目的概率是否高度依赖上下文？我感觉这依赖于许多因素，比如模型使用的特征的质量和数量，也包括我在引言中描述的因素。最终，我喜欢对这些问题做的就是进行实验。
- en: The experimentation
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验
- en: In the following part, I am going to describe the experiments I performed trying
    to assess whether the Mixture Of Softmaxes can improve the recommendation quality
    of a deep recommender system.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我将描述我进行的实验，尝试评估Mixture Of Softmaxes是否能改善深度推荐系统的推荐质量。
- en: The Model
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: The model I chose to implement is the one introduced earlier known as Gru4Rec.
    Here we implement the vanilla version. We only include the sequence of item identifiers
    and do not use any side information.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择实现的模型是之前介绍的Gru4Rec。在这里，我们实现了基础版本。我们只包含项目标识符的序列，不使用任何附加信息。
- en: '![](../Images/5c12f37937392e70a206c8a8f80c0e42.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c12f37937392e70a206c8a8f80c0e42.png)'
- en: Image by author
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: The Dataset
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: The dataset I chose for these experiments is [the famous MoviLens dataset](https://grouplens.org/datasets/movielens/)
    [3]. More specifically I chose the 25M version which contains 25 million ratings
    of 62,000 movies by 162,000 users. [The zip file](https://files.grouplens.org/datasets/movielens/ml-25m.zip)
    comes with several CSV files but here we are only going to use the ratings.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我为这些实验选择的数据集是[著名的MoviLens数据集](https://grouplens.org/datasets/movielens/) [3]。更具体地说，我选择了25M版本，其中包含162,000个用户对62,000部电影的2,500万条评分。[这个zip文件](https://files.grouplens.org/datasets/movielens/ml-25m.zip)包含几个CSV文件，但我们这里只使用评分数据。
- en: '![](../Images/c5c80806f5cb8298e729b488de7bd467.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5c80806f5cb8298e729b488de7bd467.png)'
- en: First few ratings of the dataframe
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框的前几个评分
- en: Data preprocessing
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'We have a typical example of an explicit user preference dataset. But here
    we want to frame the recommendation as a classification problem. To do so we need
    to:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个典型的显式用户偏好数据集的例子。但在这里，我们想将推荐框架设定为一个分类问题。为此，我们需要：
- en: transform it into an implicit user preference dataset by only keeping the ratings
    greater than 2.0 (chosen arbitrarily) and dropping the rating column
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过仅保留大于2.0的评分（任意选择）并丢弃评分列，将其转化为隐式用户偏好数据集。
- en: split the dataset into a training set and a validation set (temporal split)
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分成训练集和验证集（时间切分）
- en: group the ratings by user id
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按用户ID分组评分
- en: only keep the users with more than one rating (because we need sequences with
    a minimal length of 2 to have a least one input and a target)
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅保留评分大于1的用户（因为我们需要最少长度为2的序列，以便有至少一个输入和一个目标）
- en: for every user, sort the ratings by timestamp and apply a sliding window to
    create the sequences
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个用户，根据时间戳对评分进行排序，并应用滑动窗口来创建序列。
- en: save every sequence in a serialized tensorflow record
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个序列保存为序列化的 tensorflow record
- en: also in parallel, count and save the number of distinct movies in the training
    set (so that we know the size of the vocabulary)
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同时，统计并保存训练集中的不同电影数量（以便我们了解词汇表的大小）
- en: '![](../Images/b42d9d92941f6eaf5040d3f76d94b840.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b42d9d92941f6eaf5040d3f76d94b840.png)'
- en: Image by author
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者提供
- en: Given the size of this data, I had to use a distributed framework (dataflow
    in this case, the google cloud managed version of apache beam) to perform all
    the preprocessing in parallel on 4 different workers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于数据的规模，我必须使用分布式框架（在这种情况下是 dataflow，即 google cloud 管理版的 apache beam）来在 4 个不同的工作节点上并行执行所有预处理。
- en: Results
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: 'As with any other neural network, we have a number of important hyper-parameters
    to tune. In our case, the most important ones are:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他神经网络一样，我们有一些重要的超参数需要调整。在我们的案例中，最重要的超参数是：
- en: the batch size
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量大小
- en: the learning rate
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率
- en: the movie id embedding dimension
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影 ID 嵌入维度
- en: the number of softmax heads
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: softmax 头的数量
- en: Modern recommender system architectures operate in multiple steps in order to
    increase performance. Take a look at [my article on multi-stage recommendations](https://medium.com/mlearning-ai/building-a-multi-stage-recommendation-system-part-1-1-95961ccf3dd8)
    if you want to learn more. The model we are using is generally employed as a candidate
    generation model. This means that the most important metric we want to care about
    is recall. Here, we chose to report Recall@100.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现代推荐系统架构通过多个步骤来提高性能。如果你想了解更多，可以查看[我关于多阶段推荐的文章](https://medium.com/mlearning-ai/building-a-multi-stage-recommendation-system-part-1-1-95961ccf3dd8)。我们使用的模型通常用作候选生成模型。这意味着我们最关心的指标是召回率。在这里，我们选择报告
    Recall@100。
- en: I initially wanted to perform a full grid search on the hyper-parameters but
    given the size of the dataset, it appeared to be very costly. After a few experiments,
    I learned that a relatively low batch size would translate into better performance
    (64 was chosen). Also, I fixed the number of softmax heads to 4 (for cost matters).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我最初想对超参数进行全面的网格搜索，但鉴于数据集的规模，这看起来非常昂贵。经过几次实验，我了解到相对较低的批量大小会带来更好的性能（选择了 64）。此外，我将
    softmax 头的数量固定为 4（出于成本考虑）。
- en: 'I here report the results, for 3 different embedding dimensions (32, 64, 128)
    with the vanilla softmax versus the mixture of softmax:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里报告了三种不同嵌入维度（32、64、128）下普通 softmax 与 softmax 混合模型的结果：
- en: '![](../Images/48c66eb832d917cc4be54e1942a26de6.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48c66eb832d917cc4be54e1942a26de6.png)'
- en: Image by author
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者提供
- en: As we can generally observe with these embedding-based networks, the larger
    the embedding dimension, the better the performance. Also, it is not entirely
    obvious from this graph, but the Mixture-of-Softmaxes performance is a little
    bit better than the vanilla softmax. Now, is the improvement significant? Not
    really, we only score a very low 0.090% improvement for the 32 dimensions version,
    0.333% for the 64 version, and 0.314% for the 128 version.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们通常观察到的，这些基于嵌入的网络中，嵌入维度越大，性能越好。此外，从这个图中并不完全明显，但 Mixture-of-Softmaxes 的性能比普通
    softmax 略好。现在，这种改进是否显著？实际上并不显著，我们只在 32 维版本中获得了非常低的 0.090% 改进，在 64 版本中为 0.333%，在
    128 版本中为 0.314%。
- en: Was this result expected?
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这个结果是预期的吗？
- en: First, as we explained in the introduction, the Mixture-of-Softmaxes allows
    us to overcome the low-rank bottleneck of the vanilla softmax. But is this bottleneck
    a problem in the first place? The authors demonstrated that for language modeling
    it is indeed. Now, for a sequential-based recommendation task, it is not obvious.
    My guess was that it would depend on the contextual complexity of the recommendation.
    Things like sequence lengths and variety of consumption patterns might have a
    significant impact on the effectiveness of MoS.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，正如我们在引言中解释的，Mixture-of-Softmaxes 使我们能够克服普通 softmax 的低秩瓶颈。但是，这个瓶颈本身就是一个问题吗？作者们展示了在语言建模中确实如此。现在，对于基于序列的推荐任务，这一点并不明显。我猜测这可能取决于推荐的上下文复杂性。诸如序列长度和消费模式的多样性等因素可能对
    MoS 的效果有显著影响。
- en: Second, as we explained in the theoretical section, the rank of the log probability
    output matrix is upper-bounded by the embedding dimension of the movie identifiers.
    The replacement of the vanilla softmax with a mixture of softmaxes, theoretically
    removes this limitation. Therefore I was expecting that MoS would be more beneficial
    for the low embedding dimensions than for high dimensions. So what happened?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，正如我们在理论部分解释的那样，日志概率输出矩阵的秩受限于电影标识符的嵌入维度。理论上，用 softmax 混合物替代普通 softmax 可以消除这一限制。因此，我原本期望
    MoS 在低嵌入维度下比高维度下更有益。那么发生了什么呢？
- en: 'Performance breakdown by #observations'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按观察数量划分的性能
- en: Gru4Rec is a collaborative recommender system. And as with any of its cousins,
    its performance on a given item is highly dependent on the volume of data it has
    for the said item. When a new item enters the platform (it is in the cold start
    regime), we do not have a lot of sequences with it and the system does a poor
    job at providing relevant recommendations. Hence, performance is directly correlated
    with the number of training examples per item.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Gru4Rec 是一个协同推荐系统。像任何类似的系统一样，它在给定项目上的表现高度依赖于该项目的数据量。当新项目进入平台（即处于冷启动阶段）时，我们没有很多与之相关的序列，系统在提供相关推荐方面表现不佳。因此，性能与每个项目的训练示例数量直接相关。
- en: '![](../Images/9cd825aa12f5cca4612eae6fe5f023b5.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cd825aa12f5cca4612eae6fe5f023b5.png)'
- en: Image by author
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者提供
- en: I created the bin limits in order to obtain the same volume of observations
    for every bin. As one can see, the more a movie is found in the dataset, the better
    the performance. Now, we also see another trend. This time, the MoS version has
    a lower performance than the vanilla softmax in the low number of views bucket
    (on the most left bucket). This indicates that the increase in modeling complexity
    does not benefit the recommendation on cold start items. MoS increases the requirements
    in terms of data volume. MoS is beneficial only when sufficient data is available
    for an item.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了分箱的限制，以便每个分箱获得相同数量的观察值。如图所示，电影在数据集中出现得越多，性能越好。现在，我们还看到另一个趋势。这一次，MoS 版本在低观看次数分箱（最左侧的分箱）中的表现低于普通
    softmax。这表明建模复杂度的增加对冷启动项目的推荐没有好处。MoS 增加了对数据量的要求。MoS 仅在项目有足够数据时才有益。
- en: Performance breakdown by diversity
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按多样性划分的性能
- en: You might recall that in the introduction I described a specific use case in
    my previous company where the performance was pretty low because of the diversity
    in the training sequences. Another interesting analysis I would like to perform
    is to study the correlation between the effectiveness of MoS and the diversity
    of user sequences. Is MoS more effective when user sequences are very diverse?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得，在介绍中我描述了我之前公司中的一个特定用例，该用例的性能较低，因为训练序列的多样性。另一个我想进行的有趣分析是研究 MoS 的有效性与用户序列的多样性之间的关系。当用户序列非常多样化时，MoS
    是否更有效？
- en: To answer that question, the first thing we need is to be able to quantify the
    diversity of a user sequence, eg. quantify how much a view is different from the
    previous one in the sequence. In order to do that, we are going to rely on the
    user-item interaction matrix.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答这个问题，我们首先需要能够量化用户序列的多样性，例如量化一个视图与序列中前一个视图的不同程度。为此，我们将依赖用户-项目互动矩阵。
- en: '![](../Images/b5ac90d410ea0ac71149c9bbe74e8e0b.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5ac90d410ea0ac71149c9bbe74e8e0b.png)'
- en: Image by author
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者提供
- en: The user-item interaction matrix is a sparse matrix made of ones and zeros.
    The users are represented by the rows and the items by the columns. In each cell,
    we have a 1 if a user has seen a specific movie and 0 otherwise. From this matrix,
    we can compute the collaborative distance between 2 items by simply computing
    the cosine distance between the 2 associated columns. 2 items are close when they
    have been viewed by common users. If we consider that we have N items, the result
    of the overall computation is a N by N squared matrix that gives us the distance
    between any two pairs of items. Finally, in order to determine the diversity of
    a sequence, I simply return the distance between the target and the previous item
    in the sequence. I could have considered the distances between the target and
    all the previous items but the results were good enough like that.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 用户-项交互矩阵是一个由 1 和 0 组成的稀疏矩阵。用户通过行表示，项通过列表示。在每个单元格中，如果用户观看过特定电影，则为 1，否则为 0。从这个矩阵中，我们可以通过计算两个相关列之间的余弦距离来计算两个项之间的协作距离。当两个项被共同用户观看时，它们就接近。如果我们考虑有
    N 个项，则总体计算的结果是一个 N x N 的平方矩阵，给出了任意两个项之间的距离。最后，为了确定序列的多样性，我仅返回目标项与序列中前一个项之间的距离。我本可以考虑目标项与所有前项之间的距离，但结果已经足够好了。
- en: '![](../Images/b84a3b007c1c867f6dc740e18dd5daea.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b84a3b007c1c867f6dc740e18dd5daea.png)'
- en: Image by author
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: As one can see, the higher the diversity in the sequences, the harder it is
    for the algorithm to correctly predict the next item to watch. We could have computed
    the distance between 2 items in a content-based fashion by exploiting the metadata
    of the items, but I am pretty sure that the insights would have been equivalent.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所见，序列中的多样性越高，算法准确预测下一个观看项的难度就越大。我们本可以通过利用项的元数据来以基于内容的方式计算两个项之间的距离，但我相信得出的见解会是类似的。
- en: Also, another insight from the above is that we see that the MoS technique does
    not seem to be effective for the most diverse sequences (the right-most bin).
    This seems rather counter-intuitive because the point of using a high-rank modeling
    technique was to better handle the more complex recommendation settings. So does
    the MoS fails at helping with highly diverse user sequences?
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，另一个从上述数据中获得的见解是，我们发现 MoS 技术似乎对最具多样性的序列（最右侧的桶）效果不佳。这似乎有些违反直觉，因为使用高排名建模技术的目的是更好地处理更复杂的推荐设置。那么
    MoS 是否在处理高度多样化的用户序列时失败了呢？
- en: 'Performance breakdown by #observations x diversity'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '性能按 #观察 x 多样性 细分'
- en: In order to fully answer the above question, we need to break down the performance
    by the combination of volume of data and diversity. Once the Recall@100 is computed
    for every combination, we can study in greater detail MoS impact on performance.
    Let’s first do it for the 32-dimension version.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分回答上述问题，我们需要通过数据量和多样性的组合来细分性能。一旦计算出每个组合的 Recall@100，我们就可以更详细地研究 MoS 对性能的影响。我们首先对
    32 维版本进行分析。
- en: '![](../Images/e17358ab07a1f4793ca09e5c73761f83.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e17358ab07a1f4793ca09e5c73761f83.png)'
- en: As one can see, the diminishment of MoS effectiveness is largely due to the
    low views / high diversity bucket. This makes quite a lot of sense. Introducing
    more complexity in the modelization increases the volume requirements. In a situation
    when the sequences for an item are not numerous and also very diverse, the introduction
    of MoS is not beneficial. On the contrary, when the volume of data is sufficient,
    one can see that the more diverse the user sequences, the more effective the MoS.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所见，MoS 效果的减弱主要是由于低观看次数/高多样性桶。这是相当有道理的。模型复杂性的增加会提高数据量要求。在项的序列不多且非常多样化的情况下，引入
    MoS 并不具有优势。相反，当数据量足够时，可以看到用户序列越多样化，MoS 的效果越明显。
- en: 'Now for the 64-dimension version:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看一下 64 维版本：
- en: '![](../Images/30e15b6ea989f2a1605c574fe5cf9167.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30e15b6ea989f2a1605c574fe5cf9167.png)'
- en: Image by author
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'And for the 128 version:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以及 128 维版本：
- en: '![](../Images/9a3fd7587c9ac3de96e35093d5e58fb2.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a3fd7587c9ac3de96e35093d5e58fb2.png)'
- en: Image by author
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'If we compute the performance by removing all the observations from the first
    low number of views bucket (0 to 814), we observe an overall positive performance
    for MoS:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们通过移除第一个低观看次数桶（0 到 814）中的所有观察来计算性能，我们观察到 MoS 的整体表现是积极的：
- en: +0.618% for the 32-dimension version
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 32 维版本的 +0.618%
- en: +0.459% for the 64-dimension version
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 64 维版本的 +0.459%
- en: +0.320% for the 128-dimension version
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 128维版本的提升为+0.320%
- en: As expected, MoS is more beneficial for low-dimensional embeddings. This is
    because the lower the embedding dimension, the bigger the bottleneck that MoS
    was made to remove.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，MoS 对低维嵌入更有益。这是因为嵌入维度越低，MoS 旨在消除的瓶颈越大。
- en: Conclusion
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'The main takeaways from this work are the following. The MoS effectiveness
    is correlated with:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的主要结论如下。MoS 的有效性与以下因素相关：
- en: data volume. It introduces an additional burden on the data volume requirements
    per item by increasing modeling complexity. Performance is increased when the
    number of observations per item is sufficient.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据量。它通过增加建模复杂性，给每项数据引入额外的数据量要求。当每项的观察数量足够时，性能会得到提升。
- en: diversity in user sequences. It is only effective if the complexity of the session-based
    dataset requires it.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户序列的多样性。仅在会话数据集的复杂性要求时，MoS 才有效。
- en: embedding dimension size. MoS is more effective on low-dimensional embeddings
    than on high-dimensional ones.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入维度大小。MoS 在低维嵌入上的效果优于高维嵌入。
- en: 'PS: You can find [all the code](https://github.com/biarne-a/mos) that served
    this analysis on [my personal GitHub](https://github.com/biarne-a).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 附注：你可以在[我的个人 GitHub](https://github.com/biarne-a)上找到[所有相关代码](https://github.com/biarne-a/mos)。
- en: 'Final note: Although the improvements are pretty small for this dataset. I
    still think improvements might be much more important for some industrial datasets
    having very long sequences and a lot of diversity.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后说明：尽管对于这个数据集的改进相对较小，但我仍然认为，对于一些具有非常长序列和大量多样性的工业数据集，改进可能会更为重要。
- en: '**References**'
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: '[1] Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, William W. Cohen. BREAKING
    THE SOFTMAX BOTTLENECK: A HIGH-RANK RNN LANGUAGE MODEL. [https://arxiv.org/pdf/1711.03953.pdf](https://arxiv.org/pdf/1711.03953.pdf)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, William W. Cohen. 打破 Softmax
    瓶颈：高阶 RNN 语言模型. [https://arxiv.org/pdf/1711.03953.pdf](https://arxiv.org/pdf/1711.03953.pdf)'
- en: '[2] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, Domonkos Tikk.
    Session-based Recommendations with Recurrent Neural Networks. [https://arxiv.org/abs/1511.06939](https://arxiv.org/abs/1511.06939)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, Domonkos Tikk.
    基于会话的推荐系统与递归神经网络. [https://arxiv.org/abs/1511.06939](https://arxiv.org/abs/1511.06939)'
- en: '[3] F. Maxwell Harper and Joseph A. Konstan. 2015\. The MovieLens Datasets:
    History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS)
    5, 4: 19:1–19:19\. [https://doi.org/10.1145/2827872](https://doi.org/10.1145/2827872)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] F. Maxwell Harper 和 Joseph A. Konstan. 2015. MovieLens 数据集：历史与背景. ACM 互动智能系统
    (TiiS) 5, 4: 19:1–19:19. [https://doi.org/10.1145/2827872](https://doi.org/10.1145/2827872)'
