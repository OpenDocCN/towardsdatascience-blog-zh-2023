- en: Unboxing DINOv2, Metaâ€™s new all-purpose computer vision backbone
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‹†è§£ DINOv2ï¼ŒMeta çš„æ–°å‹å…¨èƒ½è®¡ç®—æœºè§†è§‰éª¨å¹²ç½‘
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040?source=collection_archive---------2-----------------------#2023-05-07](https://towardsdatascience.com/unboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040?source=collection_archive---------2-----------------------#2023-05-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/unboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040?source=collection_archive---------2-----------------------#2023-05-07](https://towardsdatascience.com/unboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040?source=collection_archive---------2-----------------------#2023-05-07)
- en: Artificial Intelligence
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: äººå·¥æ™ºèƒ½
- en: Are vision foundational models catching up with LLMs?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è§†è§‰åŸºç¡€æ¨¡å‹æ˜¯å¦æ­£åœ¨è¿½èµ¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼Ÿ
- en: '[](https://michaloleszak.medium.com/?source=post_page-----d8e22c059040--------------------------------)[![MichaÅ‚
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----d8e22c059040--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8e22c059040--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8e22c059040--------------------------------)
    [MichaÅ‚ Oleszak](https://michaloleszak.medium.com/?source=post_page-----d8e22c059040--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michaloleszak.medium.com/?source=post_page-----d8e22c059040--------------------------------)[![MichaÅ‚
    Oleszak](../Images/61b32e70cec4ba54612a8ca22e977176.png)](https://michaloleszak.medium.com/?source=post_page-----d8e22c059040--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d8e22c059040--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d8e22c059040--------------------------------)
    [MichaÅ‚ Oleszak](https://michaloleszak.medium.com/?source=post_page-----d8e22c059040--------------------------------)'
- en: Â·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc58320fab2a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=post_page-c58320fab2a8----d8e22c059040---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d8e22c059040--------------------------------)
    Â·8 min readÂ·May 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8e22c059040&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=-----d8e22c059040---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc58320fab2a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=post_page-c58320fab2a8----d8e22c059040---------------------post_header-----------)
    å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d8e22c059040--------------------------------)
    Â· 8åˆ†é’Ÿé˜…è¯» Â· 2023å¹´5æœˆ7æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd8e22c059040&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040&user=Micha%C5%82+Oleszak&userId=c58320fab2a8&source=-----d8e22c059040---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8e22c059040&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040&source=-----d8e22c059040---------------------bookmark_footer-----------)![](../Images/a82bce14167223d4394f5857aa29d74f.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd8e22c059040&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funboxing-dinov2-metas-new-all-purpose-computer-vision-backbone-d8e22c059040&source=-----d8e22c059040---------------------bookmark_footer-----------)![](../Images/a82bce14167223d4394f5857aa29d74f.png)'
- en: Self-supervised training methods continue to deliver breakthrough after breakthrough.
    Last week, Meta AI released the second version of their self-DIstillation with
    NO labels or DINO model. The model can supposedly be used as a backbone to solve
    virtually any computer vision task without fine-tuning! Have the foundational
    models in computer vision caught up to the level of versatility that Large Language
    Models have held for some time? Letâ€™s take DINO for a walk to see what it can
    do!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç›‘ç£è®­ç»ƒæ–¹æ³•ä¸æ–­å–å¾—çªç ´ã€‚ä¸Šå‘¨ï¼ŒMeta AI å‘å¸ƒäº†ç¬¬äºŒç‰ˆçš„è‡ªæˆ‘è’¸é¦æ¨¡å‹ï¼Œæ— éœ€æ ‡ç­¾æˆ– DINO æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ®è¯´å¯ä»¥ä½œä¸ºè§£å†³å‡ ä¹ä»»ä½•è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„ä¸»å¹²éª¨æ¶ï¼Œè€Œæ— éœ€å¾®è°ƒï¼è®¡ç®—æœºè§†è§‰ä¸­çš„åŸºç¡€æ¨¡å‹æ˜¯å¦å·²ç»èµ¶ä¸Šäº†å¤§å‹è¯­è¨€æ¨¡å‹æ‰€æŒæœ‰çš„å¤šåŠŸèƒ½æ€§æ°´å¹³ï¼Ÿè®©æˆ‘ä»¬æ¥æ¢ç´¢ä¸€ä¸‹
    DINO çš„èƒ½åŠ›å§ï¼
- en: '*If youâ€™re mainly interested in playing with the new DINO, feel free to scroll
    down to the â€œTesting DINOv2â€ section. Before that, we look in more detail at the
    modelâ€™s architecture and training routine.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¦‚æœä½ ä¸»è¦å¯¹ç©æ–°çš„DINOæ„Ÿå…´è¶£ï¼Œå¯ä»¥éšæ„æ»šåŠ¨åˆ°â€œæµ‹è¯•DINOv2â€éƒ¨åˆ†ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°æŸ¥çœ‹æ¨¡å‹çš„æ¶æ„å’Œè®­ç»ƒè¿‡ç¨‹ã€‚*'
- en: ğŸ¦– Self-supervised learning in computer vision
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ğŸ¦– è®¡ç®—æœºè§†è§‰ä¸­çš„è‡ªç›‘ç£å­¦ä¹ 
- en: 'Self-supervision has been gaining popularity in computer vision applications
    for a couple of years now. And to no surprise: the possibility to train models
    without labeled examples allows for using a much larger pool of training data,
    and in some [applications where labels are hard or expensive to get](/self-supervised-learning-in-computer-vision-fd43719b1625),
    it may even enable training where it was previouslyâ€¦'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç›‘ç£å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰åº”ç”¨ä¸­å·²ç»è¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œè¿™å¹¶ä¸ä»¤äººæƒŠè®¶ï¼šæ²¡æœ‰æ ‡æ³¨ç¤ºä¾‹çš„è®­ç»ƒæ¨¡å‹çš„å¯èƒ½æ€§å…è®¸ä½¿ç”¨æ›´å¤§èŒƒå›´çš„è®­ç»ƒæ•°æ®ï¼Œåœ¨ä¸€äº›[æ ‡ç­¾éš¾ä»¥è·å–æˆ–æˆæœ¬é«˜æ˜‚çš„åº”ç”¨ä¸­](/self-supervised-learning-in-computer-vision-fd43719b1625)ï¼Œå®ƒç”šè‡³å¯èƒ½ä½¿å¾—ä¹‹å‰æ— æ³•è¿›è¡Œçš„è®­ç»ƒæˆä¸ºå¯èƒ½â€¦â€¦
