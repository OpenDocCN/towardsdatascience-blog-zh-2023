- en: Why and How to Adjust P-values in Multiple Hypothesis Testing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么以及如何在多重假设检验中调整P值
- en: 原文：[https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05](https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05](https://towardsdatascience.com/why-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8?source=collection_archive---------0-----------------------#2023-05-05)
- en: P-values below a certain threshold are often used as a method to select relevant
    features. Advice below suggests how to use them correctly.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在选择相关特征时，通常会使用低于某个阈值的P值作为一种方法。以下建议说明了如何正确使用它们。
- en: '[](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[![Igor
    Šegota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    [Igor Šegota](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[![Igor
    Šegota](../Images/17c592b71fef9526a0679d47937837f6.png)](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    [Igor Šegota](https://medium.com/@igor-s?source=post_page-----2ccf174cdbf8--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----2ccf174cdbf8---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    ·9 min read·May 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----2ccf174cdbf8---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe5f8ebca4ad8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=post_page-e5f8ebca4ad8----2ccf174cdbf8---------------------post_header-----------)
    发表在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----2ccf174cdbf8--------------------------------)
    · 9分钟阅读 · 2023年5月5日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&user=Igor+%C5%A0egota&userId=e5f8ebca4ad8&source=-----2ccf174cdbf8---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&source=-----2ccf174cdbf8---------------------bookmark_footer-----------)![](../Images/d511c23677ff0b8f644e2dbec2ba25c2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ccf174cdbf8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-and-how-to-adjust-p-values-in-multiple-hypothesis-testing-2ccf174cdbf8&source=-----2ccf174cdbf8---------------------bookmark_footer-----------)![](../Images/d511c23677ff0b8f644e2dbec2ba25c2.png)'
- en: Photo by the author. Taken at Westfield UTC Mall, La Jolla, California.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。拍摄于加州拉荷亚的Westfield UTC购物中心。
- en: Multiple hypothesis testing occurs when we repeatedly test models on a number
    of features, as the probability of obtaining one or more false discoveries increases
    with the number of tests. For example, in the field of genomics, scientists often
    want to test whether any of the thousands of genes have a significantly different
    activity in an outcome of interest. Or whether [jellybeans cause acne](https://xkcd.com/882/).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 多重假设检验发生在我们在多个特征上重复测试模型时，因为随着测试数量的增加，获得一个或多个假发现的概率也会增加。例如，在基因组学领域，科学家们经常想要测试成千上万的基因中是否有任何基因在某个结果中表现出显著不同的活性。或者[糖果是否会导致痤疮](https://xkcd.com/882/)。
- en: 'In this blog post, we will cover few of the popular methods used to account
    for multiple hypothesis testing by adjusting model p-values:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们将介绍几种常用的方法，通过调整模型p值来考虑多重假设检验：
- en: False Positive Rate (FPR)
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假阳性率（FPR）
- en: Family-Wise Error Rate (FWER)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 家庭错误率（FWER）
- en: False Discovery Rate (FDR)
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假阳性率（FDR）
- en: and explain when it makes sense to use them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 并解释何时使用这些方法是有意义的。
- en: 'This document can be summarized in the following image:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这份文档可以总结为以下图像：
- en: '![](../Images/5943b7c02580e3f0811215a96b4c40be.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5943b7c02580e3f0811215a96b4c40be.png)'
- en: Image by the author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Create test data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建测试数据
- en: We will create a simulated example to better understand how various manipulation
    of p-values can lead to different conclusions. To run this code, we need Python
    with `pandas`, `numpy`, `scipy` and `statsmodels` libraries installed.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个模拟示例，以更好地理解如何通过各种p值操作得出不同的结论。要运行此代码，我们需要安装`pandas`、`numpy`、`scipy`和`statsmodels`库的Python环境。
- en: For the purpose of this example, we start by creating a Pandas DataFrame of
    1000 features. 990 of which (99%) will have their values generated from a Normal
    distribution with mean = 0, called a Null model. (In a function `norm.rvs()` used
    below, mean is set using a `loc` argument.) The remaining 1% of the features will
    be generated from a Normal distribution mean = 3, called a Non-Null model. We
    will use these as representing interesting features that we would like to discover.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这个示例，我们从创建一个包含1000个特征的Pandas DataFrame开始。其中990个特征（99%）的值将从均值为0的正态分布中生成，这称为空模型。（在下面使用的函数`norm.rvs()`中，均值是通过`loc`参数设置的。）其余的1%的特征将从均值为3的正态分布中生成，这称为非空模型。我们将用这些特征来表示我们希望发现的有趣特征。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For each of the 1000 features, p-value is a probability of observing the value
    at least as large, if we assume it was generated from a Null distribution.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个1000个特征中的特征，p值是观察到的值至少如此之大（假设它是从空分布生成的）的概率。
- en: 'P-values can be calculated from a cumulative distribution ( `norm.cdf()` from
    `scipy.stats`) which represents the probability of obtaining a value equal to
    or **less than** the one observed. Then to calculate the p-value we calculate
    `1 - norm.cdf()` to find the probability **greater than** the one observed:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: p值可以通过累积分布（`norm.cdf()`来自`scipy.stats`）计算，累积分布表示获得一个值等于或**小于**观察到的值的概率。然后为了计算p值，我们计算`1
    - norm.cdf()`来找到**大于**观察到的值的概率：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/1e09fe5152cdf959d5bb5fa916a04c49.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e09fe5152cdf959d5bb5fa916a04c49.png)'
- en: False Positive Rate
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假阳性率
- en: 'The first concept is called a False Positive Rate and is defined as a fraction
    of null hypotheses that we flag as “significant” (also called Type I errors).
    The p-values we calculated earlier can be interpreted as a false positive rate
    by their very definition: they are probabilities of obtaining a value at least
    as large as a specified value, when we sample a Null distribution.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个概念称为假阳性率，定义为我们标记为“显著”的空假设的比例（也称为第一类错误）。我们之前计算的p值可以按其定义解释为假阳性率：它们是从空分布中获取一个值至少与指定值一样大的概率。
- en: 'For illustrative purposes, we will apply a common (magical 🧙) p-value threshold
    of 0.05, but any threshold can be used:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将应用一个常见的（神奇的🧙）p值阈值0.05，但可以使用任何阈值：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'notice that out of our 9900 null hypotheses, 493 are flagged as “significant”.
    Therefore, a False Positive Rate is: FPR = 493 / (493 + 9407) = 0.053.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在我们的9900个零假设中，493个被标记为“显著”。因此，假阳性率为：FPR = 493 / (493 + 9407) = 0.053。
- en: The main problem with FPR is that in a real scenario we do not a priori know
    which hypotheses are null and which are not. Then, the raw p-value on its own
    (False Positive Rate) is of limited use. In our case when the fraction of non-null
    features is very small, most of the features flagged as significant will be null,
    because there are many more of them. Specifically, out of 92 + 493 = 585 features
    flagged true (“positive”), only 92 are from our non-null distribution. That means
    that a majority or about 84% of reported significant features (493 / 585) are
    false positives!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: FPR的主要问题是，在实际情况中，我们不知道哪些假设是空的，哪些不是。因此，仅凭原始p值（假阳性率）用途有限。在我们的案例中，当非空特征的比例非常小，大多数标记为显著的特征将是空的，因为它们的数量更多。具体来说，在92
    + 493 = 585个标记为真正（“正”）的特征中，只有92个来自我们的非空分布。这意味着大多数或约84%（493 / 585）的报告显著特征是假阳性！
- en: 'So, what can we do about this? There are two common methods of addressing this
    issue: instead of False Positive Rate, we can calculate Family-Wise Error Rate
    (FWER) or a False Discovery Rate (FDR). Each of these methods takes the set of
    raw, unadjusted, p-values as an input, and produces a new set of “adjusted p-values”
    as an output. These “adjusted p-values” represent estimates of *upper bounds*
    on FWER and FDR. They can be obtained from `multipletests()` function, which is
    part of the `statsmodels` Python library:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们可以对此做些什么？有两种常见的方法来解决这个问题：我们可以计算家庭-wise 错误率（FWER）或虚假发现率（FDR），而不是虚假正率。这些方法都以原始未调整的
    p 值集合作为输入，产生一组新的“调整后 p 值”作为输出。这些“调整后 p 值”代表了 *FWER* 和 *FDR* 的 *上界* 估计值。它们可以通过
    `multipletests()` 函数获得，该函数是 `statsmodels` Python 库的一部分：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Family-Wise Error Rate
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 家庭-wise 错误率
- en: Family-Wise Error Rate is a probability of falsely rejecting one or more null
    hypotheses, or in other words flagging true Null as Non-null, or a probability
    of seeing one or more false positives.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 家庭-wise 错误率是错误拒绝一个或多个零假设的概率，换句话说，就是将真实的零假设标记为非零假设的概率，或看到一个或多个虚假正例的概率。
- en: 'When there is only one hypothesis being tested, this is equal to the raw p-value
    (false positive rate). However, the more hypotheses are tested, the more likely
    we are going to get one or more false positives. There are two popular ways to
    estimate FWER: Bonferroni and Holm procedures. Although neither Bonferroni nor
    Holm procedures make any assumptions about the dependence of tests run on individual
    features, they will be overly conservative. For example, in the extreme case when
    all of the features are identical (same model repeated 10,000 times), no correction
    is needed. While in the other extreme, where no features are correlated, some
    type of correction is required.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当仅测试一个假设时，这等于原始 p 值（虚假正率）。然而，测试的假设越多，我们获得一个或多个虚假正例的可能性就越大。估计 FWER 有两种流行的方法：博尼费罗尼和霍尔姆程序。虽然博尼费罗尼和霍尔姆程序都没有对测试在单个特征上运行的依赖性做出任何假设，但它们会过于保守。例如，在所有特征完全相同（相同的模型重复了
    10,000 次）的极端情况下，不需要校正。而在其他极端情况下，如果没有特征相关，则需要某种类型的校正。
- en: Bonferroni procedure
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 博尼费罗尼程序
- en: One of the most popular methods for correcting for multiple hypothesis testing
    is a Bonferroni procedure. The reason this method is popular is because it is
    very easy to calculate, even by hand. This procedure multiplies each p-value by
    the total number of tests performed or sets it to 1 if this multiplication would
    push it past 1.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 修正多重假设检验的最流行方法之一是博尼费罗尼程序。之所以这种方法流行，是因为它非常容易计算，即使是手动计算也很简单。该程序将每个 p 值乘以所进行的测试总数，或者如果这种乘法会使
    p 值超过 1，则将其设置为 1。
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/55e0101586bf95c693bd99efb4c1e5c1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55e0101586bf95c693bd99efb4c1e5c1.png)'
- en: Holm procedure
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 霍尔姆程序
- en: Holm’s procedure provides a correction that is more powerful than Bonferroni’s
    procedure. The only difference is that the p-values are not all multiplied by
    the total number of tests (here, 10000). Instead, each sorted p-value is multiplied
    progressively by a decreasing sequence 10000, 9999, 9998, 9997, …, 3, 2, 1.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 霍尔姆的程序提供了一种比博尼费罗尼程序更强大的校正方法。唯一的区别在于，p 值并不是全部乘以测试总数（这里是 10000）。而是，每个排序后的 p 值依次乘以递减序列
    10000、9999、9998、9997、……、3、2、1。
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/19df8cf11b5389281f44407675a2cfe9.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19df8cf11b5389281f44407675a2cfe9.png)'
- en: 'We can verify this ourselves: the last 10th p-value on this output is multiplied
    by 9991: 7.943832e-06 * 9991 = 0.079367\. Holm’s correction is also the default
    method for adjusting p-values in `p.adjust()` function in R language.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以自己验证这一点：输出中的第十个 p 值被乘以 9991：7.943832e-06 * 9991 = 0.079367。霍尔姆的校正也是 R 语言中
    `p.adjust()` 函数调整 p 值的默认方法。
- en: 'If we again apply our p-value threshold of 0.05, let’s take a look how these
    adjusted p-values affect our predictions:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次应用 p 值阈值 0.05，我们来看看这些调整后的 p 值如何影响我们的预测：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: These results are much different than when we applied the same threshold to
    the raw p-values! Now, only 8 features are flagged as “significant”, and all 8
    are correct — they were generated from our Non-null distribution. This is because
    the probability of getting even one feature flagged incorrectly is only 0.05 (5%).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果与我们将相同阈值应用于原始 p 值时大相径庭！现在，只有 8 个特征被标记为“显著”，而这 8 个特征都是正确的——它们来自于我们的非零分布。这是因为即使有一个特征被错误标记的概率也只有
    0.05（5%）。
- en: 'However, this approach has a downside: it failed to flag other 92 Non-null
    features as significant. While it was very stringent to make sure none of the
    null features slipped in, it was able to find only 8% (8 out of 100) non-null
    features. This can be seen as taking a different extreme than the False Positive
    Rate approach.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法有一个缺点：它未能将其他 92 个非零特征标记为显著。尽管它非常严格，以确保没有零特征被漏入，但它只能找到 8%（100 个中的 8 个）非零特征。这可以被视为比虚假正例率方法采取了不同的极端。
- en: Is there a more middle ground? The answer is “yes”, and that middle ground is
    False Discovery Rate.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 是否有一种更中间的方案？答案是“有”，这种中间方案就是虚假发现率。
- en: False Discovery Rate
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚假发现率
- en: What if we are OK with letting some false positives in, but capturing more than
    single-digit percent of true positives? Maybe we are OK with having *some* false
    positive, just not that many that they overwhelm all of the features we flag as
    significant — as was the case in the FPR example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们可以接受一些虚假正例，但希望捕获更多的真正正例，而不仅仅是个位数的百分比呢？也许我们可以接受*一些*虚假正例，只要这些虚假正例不会淹没我们标记为显著的所有特征——就像在
    FPR 示例中那样。
- en: 'This can be done by controlling for False Discovery Rate (rather than FWER
    or FPR) at a specified threshold level, say 0.05\. False Discovery Rate is defined
    a fraction of false positives among all features flagged as positive: FDR = FP
    / (FP + TP), where FP is the number of False Positives and TP is the number of
    True Positives. By setting FDR threshold to 0.05, we are saying we are OK with
    having 5% (on average) false positives among all of our features we flag as positive.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过在指定的阈值水平（例如 0.05）下控制虚假发现率（而不是 FWER 或 FPR）来完成。虚假发现率定义为所有被标记为正面的特征中虚假正例的比例：FDR
    = FP / (FP + TP)，其中 FP 是虚假正例的数量，TP 是真正正例的数量。通过将 FDR 阈值设置为 0.05，我们表示我们接受在所有被标记为正面的特征中有
    5%（平均）虚假正例。
- en: 'There are several methods to control FDR and here we will describe how to use
    two popular ones: Benjamini-Hochberg and Benjamini-Yekutieli procedures. Both
    of these procedures are similar although more involved than FWER procedures. They
    still rely on sorting the p-values, multiplying them with a specific number, and
    then using a cut-off criterion.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 控制 FDR 有几种方法，我们将在这里描述如何使用两种流行的方法：Benjamini-Hochberg 和 Benjamini-Yekutieli 程序。这两种程序虽然比
    FWER 程序更复杂，但仍然类似。它们仍然依赖于对 p 值进行排序、乘以一个特定的数字，然后使用截断标准。
- en: Benjamini-Hochberg procedure
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Benjamini-Hochberg 程序
- en: 'Benjamini-Hochberg (BH) procedure assumes that each of the tests are *independent*.
    Dependent tests occur, for example, if the features being tested are correlated
    with each other. Let’s calculate the BH-adjusted p-values and compare it to our
    earlier result from FWER using Holm’s correction:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Benjamini-Hochberg (BH) 程序假设每个测试都是*独立的*。依赖的测试会发生，例如，当被测试的特征之间存在相关性时。让我们计算 BH
    调整后的 p 值，并将其与我们之前使用 Holm 校正的 FWER 结果进行比较：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/e13078444fc6c5d26695e9dfb9f3aa33.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e13078444fc6c5d26695e9dfb9f3aa33.png)'
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'BH procedure now correctly flagged 33 out of 100 non-null features as significant
    — an improvement from the 8 with the Holm’s correction. However, it also flagged
    2 null features as significant. So, out of the 35 features flagged as significant,
    the fraction of incorrect features is: 2 / 33 = 0.06 so 6%.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: BH 程序现在正确地将 100 个非零特征中的 33 个标记为显著——相比于 Holm 校正的 8 个，这是一种改进。然而，它也将 2 个零特征标记为显著。因此，在
    35 个标记为显著的特征中，不正确特征的比例是：2 / 33 = 0.06，即 6%。
- en: 'Note that in this case we have 6% FDR rate, even though we aimed to control
    it at 5%. FDR will be controlled at a 5% rate *on average*: sometimes it may be
    lower and sometimes it may be higher.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这种情况下，我们的 FDR 率为 6%，尽管我们旨在将其控制在 5%。FDR 将以 5% 的速率*平均*控制：有时它可能更低，有时可能更高。
- en: Benjamini-Yekutieli procedure
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Benjamini-Yekutieli 程序
- en: 'Benjamini-Yekutieli (BY) procedure controls FDR regardless of whether tests
    are independent or not. Again, it is worth noting that all of these procedures
    try to establish *upper bounds* on FDR (or FWER), so they may be less or more
    conservative. Let’s compare the BY procedure with a BH and Holm procedures above:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Benjamini-Yekutieli (BY) 程序在测试是否独立的情况下都能控制 FDR。再次值得注意的是，所有这些程序都试图建立 FDR（或 FWER）的*上限*，因此它们可能更保守或更宽松。让我们将
    BY 程序与上述 BH 和 Holm 程序进行比较：
- en: '[PRE14]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/5009f6b28842380845296c6dd2c3cdea.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5009f6b28842380845296c6dd2c3cdea.png)'
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: BY procedure is stricter in controlling FDR; in this case even more so than
    the Holm’s procedure for controlling FWER, by flagging only 7 non-null features
    as significant! The main advantage of using it is when we know the data may contain
    a high number of correlated features. However, in that case we may also want to
    consider filtering out correlated features so that we do not need to test all
    of them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: BY 程序在控制 FDR 方面更严格；在这种情况下，甚至比用于控制 FWER 的 Holm 方法更严格，仅标记了 7 个非空特征为显著！使用它的主要优势是当我们知道数据可能包含大量相关特征时。然而，在这种情况下，我们可能还希望考虑过滤相关特征，以便不需要测试所有这些特征。
- en: Summary
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'At the end, the choice of procedure is left to the user and depends on what
    the analysis is trying to do. Quoting Benjamini, Hochberg (Royal Stat. Soc. 1995):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，程序的选择留给用户，取决于分析试图做什么。引用本雅明、霍奇伯格（Royal Stat. Soc. 1995）：
- en: Often the control of the FWER is not quite needed. The control of the FWER is
    important when a conclusion from the various individual inferences is likely to
    be erroneous when at least one of them is.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通常不太需要控制 FWER。在多个单独推断的结论可能出错时，控制 FWER 是重要的。
- en: ''
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This may be the case, for example, when several new treatments are competing
    against a standard, and a single treatment is chosen from the set of treatments
    which are declared significantly better than the standard.
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，在几种新治疗方法与标准进行竞争时，可能会出现这种情况，并且从被声明显著优于标准的治疗方法集合中选择单一治疗方法。
- en: In other cases, where we may be OK to have some false positives, FDR methods
    such as BH correction provide less stringent p-value adjustments and may be preferrable
    if we primarily want to increase the number of true positives that pass a certain
    p-value threshold.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，当我们可以接受一些假阳性时，FDR 方法如 BH 校正提供了不那么严格的 p 值调整，并且如果我们主要想增加通过某个 p 值阈值的真阳性数量，则可能更可取。
- en: There are other adjustment methods not mentioned here, notably a [q-value](https://en.wikipedia.org/wiki/Q-value_(statistics))
    which is also used for FDR control, and at the time of writing exists only as
    an R package.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他未在此提及的调整方法，尤其是一个[q-value](https://en.wikipedia.org/wiki/Q-value_(statistics))，也用于
    FDR 控制，在撰写时仅存在作为 R 包。
