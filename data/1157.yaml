- en: No More OOM-Exceptions During Hyperparameter Searches in TensorFlow
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 中的超参数搜索不再出现 OOM 异常
- en: 原文：[https://towardsdatascience.com/no-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9?source=collection_archive---------3-----------------------#2023-04-01](https://towardsdatascience.com/no-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9?source=collection_archive---------3-----------------------#2023-04-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/no-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9?source=collection_archive---------3-----------------------#2023-04-01](https://towardsdatascience.com/no-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9?source=collection_archive---------3-----------------------#2023-04-01)
- en: Use wrapper functions to avoid OOM-exceptions
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用包装函数来避免 OOM 异常
- en: '[](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)[![Pascal
    Janetzky](../Images/43d68509b63c5f9b3fc9cef3cbfc1a88.png)](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)
    [Pascal Janetzky](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)[![Pascal
    Janetzky](../Images/43d68509b63c5f9b3fc9cef3cbfc1a88.png)](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)
    [Pascal Janetzky](https://pascaljanetzky.medium.com/?source=post_page-----26e6e3069bc9--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F672b95fdf976&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&user=Pascal+Janetzky&userId=672b95fdf976&source=post_page-672b95fdf976----26e6e3069bc9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)
    ·8 min read·Apr 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F26e6e3069bc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&user=Pascal+Janetzky&userId=672b95fdf976&source=-----26e6e3069bc9---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F672b95fdf976&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&user=Pascal+Janetzky&userId=672b95fdf976&source=post_page-672b95fdf976----26e6e3069bc9---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----26e6e3069bc9--------------------------------)
    ·8分钟阅读·2023年4月1日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F26e6e3069bc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&user=Pascal+Janetzky&userId=672b95fdf976&source=-----26e6e3069bc9---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26e6e3069bc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&source=-----26e6e3069bc9---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F26e6e3069bc9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fno-more-oom-exceptions-during-hyperparameter-searches-in-tensorflow-26e6e3069bc9&source=-----26e6e3069bc9---------------------bookmark_footer-----------)'
- en: It’s the year 2023\. Machine learning is no longer hype but at the core of everyday
    products. Ever faster hardware makes it possible to train ever larger machine
    learning models — in shorter times, too. With around 100 papers submitted per
    day on machine learning or related domains to [arXiv](https://arxiv.org/list/cs.LG/pastweek?skip=0&show=635),
    chances are high that at least one-third of them have leveraged the hardware’s
    capabilities to do hyperparameter searches to optimize their used model. And that’s
    straightforward, is it not? Just pick a framework — [Optuna](https://optuna.org),
    [wandb](https://wandb.ai/site), whatever — plug in your normal training loop,
    and…
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是 2023 年。机器学习不再是炒作，而是日常产品的核心。更快的硬件使得训练更大规模的机器学习模型成为可能——而且时间也更短。每天有约 100 篇关于机器学习或相关领域的论文提交到
    [arXiv](https://arxiv.org/list/cs.LG/pastweek?skip=0&show=635)，因此至少三分之一的论文有可能利用硬件的能力来进行超参数搜索，以优化他们使用的模型。这很简单，不是吗？只需选择一个框架——[Optuna](https://optuna.org)、[wandb](https://wandb.ai/site)，随便哪个——将其插入你正常的训练循环中，然后……
- en: OOM error.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: OOM 错误。
- en: At least, that’s what frequently happens with TensorFlow.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 至少，这就是 TensorFlow 经常发生的情况。
- en: '![](../Images/b3e570b3e786fedc8cb8fa13c920d878.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3e570b3e786fedc8cb8fa13c920d878.png)'
- en: Photo by [İsmail Enes Ayhan](https://unsplash.com/@ismailenesayhan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [İsmail Enes Ayhan](https://unsplash.com/@ismailenesayhan?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The current state
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当前状态
- en: 'The lack of a function to properly free GPU memory has spurred many discussions
    and questions in Q&A forums like StackOverflow or GitHub ([1](https://stackoverflow.com/questions/39758094/clearing-tensorflow-gpu-memory-after-model-execution),
    [2](https://github.com/tensorflow/tensorflow/issues/36465), [3](https://stackoverflow.com/questions/69296496/clear-the-graph-and-free-the-gpu-memory-in-tensorflow-2),
    [4](https://discuss.tensorflow.org/t/clear-the-graph-and-free-the-gpu-memory-in-tensorflow-2/4731),
    [5](https://github.com/keras-team/keras/issues/12625), [6](https://stackoverflow.com/questions/75644097/is-there-a-way-to-clear-gpu-memory-after-training-the-tf2-model)).
    For each question, a similar set of workarounds is proposed:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 缺乏适当释放 GPU 内存的功能引发了许多讨论和问题，出现在像 StackOverflow 或 GitHub ([1](https://stackoverflow.com/questions/39758094/clearing-tensorflow-gpu-memory-after-model-execution)、[2](https://github.com/tensorflow/tensorflow/issues/36465)、[3](https://stackoverflow.com/questions/69296496/clear-the-graph-and-free-the-gpu-memory-in-tensorflow-2)、[4](https://discuss.tensorflow.org/t/clear-the-graph-and-free-the-gpu-memory-in-tensorflow-2/4731)、[5](https://github.com/keras-team/keras/issues/12625)、[6](https://stackoverflow.com/questions/75644097/is-there-a-way-to-clear-gpu-memory-after-training-the-tf2-model)）等问答论坛中。每个问题都有一套类似的解决方法：
- en: '- Limit GPU memory growth'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '- 限制 GPU 内存增长'
- en: '- Use the numba library to clear the GPU'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '- 使用 numba 库来清除 GPU'
- en: '- Use native TF functions that *should* do that'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '- 使用原生 TF 函数，这些函数*应该*可以做到这一点'
- en: '- Switch to PyTorch'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '- 切换到 PyTorch'
