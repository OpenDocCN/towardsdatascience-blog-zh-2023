- en: 'TimesNet: The Latest Advance in Time Series Forecasting'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TimesNet：时间序列预测的最新进展
- en: 原文：[https://towardsdatascience.com/timesnet-the-latest-advance-in-time-series-forecasting-745b69068c9c](https://towardsdatascience.com/timesnet-the-latest-advance-in-time-series-forecasting-745b69068c9c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/timesnet-the-latest-advance-in-time-series-forecasting-745b69068c9c](https://towardsdatascience.com/timesnet-the-latest-advance-in-time-series-forecasting-745b69068c9c)
- en: Understand the TimesNet architecture and apply it on a forecasting task with
    Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解TimesNet架构，并使用Python应用于预测任务
- en: '[](https://medium.com/@marcopeixeiro?source=post_page-----745b69068c9c--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----745b69068c9c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----745b69068c9c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----745b69068c9c--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----745b69068c9c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcopeixeiro?source=post_page-----745b69068c9c--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----745b69068c9c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----745b69068c9c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----745b69068c9c--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----745b69068c9c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----745b69068c9c--------------------------------)
    ·10 min read·Oct 10, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----745b69068c9c--------------------------------)
    ·10分钟阅读·2023年10月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9a499aed5a781591ea06eef5f3cb4222.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a499aed5a781591ea06eef5f3cb4222.png)'
- en: Photo by [Rachel Hisko](https://unsplash.com/@rachelhisko?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Rachel Hisko](https://unsplash.com/@rachelhisko?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In previous articles, we have explored the latest advances in state-of-the-art
    forecasting techniques, starting with [N-BEATS](https://medium.com/towards-data-science/the-easiest-way-to-forecast-time-series-using-n-beats-d778fcc2ba60)
    released in 2020, [N-HiTS](https://medium.com/towards-data-science/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5)
    in 2022, and [PatchTST](https://medium.com/towards-data-science/patchtst-a-breakthrough-in-time-series-forecasting-e02d48869ccc)
    in March 2023\. Recall that N-BEATS and N-HiTS rely on the multilayer perceptron
    architecture, while PatchTST leverages the Transformer architecture.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的文章中，我们探索了最新的最先进预测技术，分别是2020年发布的[N-BEATS](https://medium.com/towards-data-science/the-easiest-way-to-forecast-time-series-using-n-beats-d778fcc2ba60)、2022年的[N-HiTS](https://medium.com/towards-data-science/all-about-n-hits-the-latest-breakthrough-in-time-series-forecasting-a8ddcb27b0d5)以及2023年3月的[PatchTST](https://medium.com/towards-data-science/patchtst-a-breakthrough-in-time-series-forecasting-e02d48869ccc)。请注意，N-BEATS和N-HiTS依赖于多层感知机架构，而PatchTST则利用了Transformer架构。
- en: 'As of April 2023, a new model was published in the literature, and it achieves
    state-of-the-art results across multiple tasks in time series analysis, like forecasting,
    imputation, classification and anomaly detection: **TimesNet**.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2023年4月，文献中发布了一种新模型，它在时间序列分析的多个任务中实现了最先进的结果，如预测、填补、分类和异常检测：**TimesNet**。
- en: 'TimesNet was proposed by Wu, Hu, Liu et al in their paper: [TimesNet: Temporal
    2D-Variation Modeling For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: TimesNet由吴、胡、刘等人在他们的论文中提出：[TimesNet：时间序列分析的时间2D-变异建模](https://browse.arxiv.org/pdf/2210.02186.pdf)。
- en: Unlike previous models, it uses a CNN-based architecture to achieve state-of-the-art
    results across different tasks, making it a great candidate for a foundation model
    for time series analysis.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的模型不同，它使用基于CNN的架构，在不同任务中实现了最先进的结果，使其成为时间序列分析的基础模型的优秀候选者。
- en: In this article, we explore the architecture and inner workings of TimesNet.
    Then, we apply the model in a forecasting task, alongside N-BEATS and N-HiTS to
    complete our own little experiment.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们探讨了TimesNet的架构和内部工作原理。接着，我们将模型应用于预测任务，并与N-BEATS和N-HiTS一起完成我们的小实验。
- en: As always, for more details, refer to the [original paper](https://browse.arxiv.org/pdf/2210.02186.pdf).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，更多详细信息请参阅[原始论文](https://browse.arxiv.org/pdf/2210.02186.pdf)。
- en: '**Learn the latest time series analysis techniques with my** [**free time series
    cheat sheet**](https://www.datasciencewithmarco.com/pl/2147608294) **in Python!
    Get the implementation of statistical and deep learning techniques, all in Python
    and TensorFlow!**'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**使用我的** [**免费时间序列备忘单**](https://www.datasciencewithmarco.com/pl/2147608294)
    **在Python中学习最新的时间序列分析技术！获取统计和深度学习技术的实现，全部在Python和TensorFlow中！**'
- en: Let’s get started!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Explore TimesNet
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索TimesNet
- en: The motivation behind TimesNet comes from the realization that many real-life
    time series exhibit *mutli-periodicity*. This means that variations occur at different
    periods.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: TimesNet的动机来自于意识到许多现实生活中的时间序列展示了*多周期性*。这意味着在不同的周期中会发生变化。
- en: For example, temperature outside has both a daily and a yearly period. Usually,
    it is hotter during the day than at night, and hotter during summer than in winter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，外部温度既有日周期也有年周期。通常，白天比夜晚热，夏天比冬天热。
- en: Now, those multiple periods overlap and interact with each other, making it
    difficult to separate and model individually.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这些多个周期相互重叠并相互作用，使得单独分离和建模变得困难。
- en: So, the authors of TimesNet propose to reshape the series in a 2D space to model
    *intraperiod-variation* and *interperiod-variation*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，TimesNet的作者建议将序列重塑为二维空间，以建模*周期内变化*和*周期间变化*。
- en: Going back to our weather example, intraperiod-variation would be how the temperature
    varies within a day, and interperiod-variation would be how the temperature varies
    from day to day, or from year to year.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的天气示例，周期内变化将是温度在一天内的变化，而周期间变化将是温度从一天到另一日，或从一年到另一年的变化。
- en: With all that in mind, let’s dive into the model’s architecture.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这些，让我们深入探讨模型的架构。
- en: The architecture of TimesNet
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TimesNet的架构
- en: Let’s take a look at the architecture of TimesNet.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看TimesNet的架构。
- en: '![](../Images/fddcabd04aad86837a21d001fb1f9e41.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fddcabd04aad86837a21d001fb1f9e41.png)'
- en: 'Architecture of TimesNet. Image by Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou,
    Jianmin Wang and Mingsheng Long from [TimesNet: Temporal 2D-Variation Modeling
    For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 'TimesNet的架构。图像由Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang和Mingsheng
    Long提供，来自[TimesNet: Temporal 2D-Variation Modeling For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
- en: From the figure above, we can see that TimesNet is a stack of multiple *TimesBlock*
    with residual connections.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图中，我们可以看到TimesNet是由多个*TimesBlock*堆叠而成，并具有残差连接。
- en: In each TimesBlock, we can see that the series first goes through a fast Fourier
    transform (FTT) to find the different periods in the data. Then, it is reshaped
    as a 2D vector and sent to an Inception block where it learns and predicts a 2D
    representation of the series. Then, this deep representation must be reshaped
    back to a 1-dimensional vector using *adaptive aggregation*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个TimesBlock中，我们可以看到序列首先经过快速傅里叶变换（FTT）以找到数据中的不同周期。然后，将其重塑为二维向量并发送到Inception块，在那里它学习和预测序列的二维表示。然后，这种深度表示必须通过*自适应聚合*重新变形回一维向量。
- en: There is a lot to understand here, so let’s cover each step in more detail.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多内容需要了解，所以让我们更详细地介绍每个步骤。
- en: Capture multi-periodicity
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 捕捉多周期性
- en: To capture the variations across multiple periods in time series, the authors
    suggest to transform the 1-dimensional series into a 2-dimensional space to simultaneously
    model intraperiod and interperiod variations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉时间序列中多个周期的变化，作者建议将一维序列转换为二维空间，以同时建模周期内变化和周期间变化。
- en: '![](../Images/0eaa094828efbb858b774d945b1e3cda.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0eaa094828efbb858b774d945b1e3cda.png)'
- en: 'Architecture of TimesNet. Image by Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou,
    Jianmin Wang and Mingsheng Long from [TimesNet: Temporal 2D-Variation Modeling
    For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 'TimesNet的架构。图像由Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang和Mingsheng
    Long提供，来自[TimesNet: Temporal 2D-Variation Modeling For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
- en: In the figure above, we can see the how the model represents the variations
    in a 2D space. Inside the red rectangles, we can see the intraperiod-variation,
    which is how the data changes inside a period. Then, the blue rectangle contains
    the interperiod-variation, which is how the data changes from period to period.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图中，我们可以看到模型如何在二维空间中表示变化。在红色矩形内，我们可以看到周期内变化，即数据在一个周期内的变化。然后，蓝色矩形包含周期间变化，即数据从一个周期到另一个周期的变化。
- en: To better understand that, suppose that we have daily data with a weekly period.
    The interperiod-variation is how the data changes from Monday, to Tuesday, to
    Wednesday, and so on.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，假设我们有带有周周期的日数据。周期间变化指的是数据从周一到周二，再到周三等的变化情况。
- en: Then, the interperiod-variation would be how the data varies from Monday in
    week 1, to Monday in week 2, and from Tuesday in week 1, to Tuesday in week 2\.
    In other words, it is the variation of data in the same *phase* at different periods.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，周期间变化指的是数据如何从第1周的周一变化到第2周的周一，从第1周的周二变化到第2周的周二。换句话说，它是同一*相位*在不同周期中的数据变化。
- en: Those variations are then represented in a 2D space, where the interperiod-variation
    is vertical, and the intraperiod-variation is horizontal. This allows the model
    to learn a better representation of the variation in the data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变化随后被表示在2D空间中，其中周期间变化是垂直的，而周期内变化是水平的。这使得模型能够更好地学习数据变化的表示。
- en: Whereas a 1-dimensional vector shows variations between adjacent points, this
    2D representation shows variations between adjacent points and adjacent periods,
    giving a more complete picture of what is happening.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然一维向量显示相邻点之间的变化，但这种2D表示法显示了相邻点和相邻周期之间的变化，提供了更完整的情况。
- en: 'Yet, one question remains: how do we find the periods in our series?'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仍有一个问题：我们如何找到序列中的周期？
- en: Identify the significant periods in your data
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定数据中的显著周期
- en: To identify the multiple periods in time series, the model applied the Fast
    Fourier Transform (FTT).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别时间序列中的多个周期，模型应用了快速傅里叶变换（FTT）。
- en: This is a mathematical operation that transforms a signal into a function of
    frequency and amplitude.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种数学操作，将信号转换为频率和幅度的函数。
- en: '![](../Images/01998c92d2637704def7ba8389662d71.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01998c92d2637704def7ba8389662d71.png)'
- en: 'How the model applies FTT to find the top *k* significant periods in time series.
    Image by Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang and Mingsheng
    Long from [TimesNet: Temporal 2D-Variation Modeling For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '模型如何应用FTT以找到时间序列中的前*k*个显著周期。图片由Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin
    Wang和Mingsheng Long提供，来自[TimesNet: Temporal 2D-Variation Modeling For General
    Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
- en: In the figure above, the authors illustrate how FTT is applied. Once we have
    the frequency and amplitude of each period, the ones with the largest amplitudes
    are considered to be the most relevant.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上图中，作者展示了FTT的应用方式。一旦我们得到了每个周期的频率和幅度，幅度最大的周期被认为是最相关的。
- en: For example, here is the result of performing FTT on the [Etth1 dataset](https://github.com/zhouhaoyi/ETDataset/blob/main/ETT-small/ETTh1.csv).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这是对[Etth1数据集](https://github.com/zhouhaoyi/ETDataset/blob/main/ETT-small/ETTh1.csv)应用FTT的结果。
- en: '![](../Images/8c6261f834ae9c8a3167775f64b93cd5.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c6261f834ae9c8a3167775f64b93cd5.png)'
- en: Result of applying FTT on the Etth1 dataset. We can see that the daily and yearly
    periods are the most significant. Image by the author.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对Etth1数据集应用FTT的结果。我们可以看到，日周期和年周期是最显著的。图片由作者提供。
- en: In the figure above, the Fast Fourier Transform allows us to quickly identify
    a daily and yearly period in our data, since we see higher peaks of amplitude
    at those periods.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 上图中的快速傅里叶变换使我们能够快速识别数据中的日周期和年周期，因为我们在这些周期上看到更高的幅度峰值。
- en: Once FTT is applied, the user can set a parameter *k* to select the top-*k*
    most important periods, which are the ones with the largest amplitude.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用FTT，用户可以设置参数*k*以选择前-*k*个最重要的周期，这些周期是幅度最大的。
- en: TimesNet then creates 2D vectors for each period, and those are sent to a 2D
    kernel to capture the temporal variations.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: TimesNet随后为每个周期创建2D向量，并将其发送到2D卷积核，以捕捉时间变化。
- en: Inside the TimesBlock
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在TimesBlock内部
- en: Once the series has gone through the Fourier transform and 2D tensors were created
    for the top-*k* periods, the data is sent to the Inception block, as shown in
    the figure below.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦序列经过傅里叶变换，并为前-*k*周期创建了2D张量，数据将被发送到下图所示的Inception模块。
- en: '![](../Images/fddcabd04aad86837a21d001fb1f9e41.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fddcabd04aad86837a21d001fb1f9e41.png)'
- en: 'Architecture of TimesNet. Image by Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou,
    Jianmin Wang and Mingsheng Long from [TimesNet: Temporal 2D-Variation Modeling
    For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 'TimesNet的架构。图片由Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang和Mingsheng
    Long提供，来自[TimesNet: Temporal 2D-Variation Modeling For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
- en: Of course, note that all of the steps that we explored are carried out inside
    the TimesBlock.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，请注意我们探索的所有步骤都是在 TimesBlock 内部进行的。
- en: Now, the 2D representation of the data is sent to the **Inception** block.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，数据的 2D 表示被送入**Inception**块。
- en: The Inception module is the building block of the computer vision model [GoogLeNet](https://openaccess.thecvf.com/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf),
    published in 2015.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Inception 模块是计算机视觉模型[GoogLeNet](https://openaccess.thecvf.com/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)的构建块，该模型于2015年发布。
- en: The main idea of the Inception module is to have an efficient representation
    of the data by keeping it sparse. That way, we can technically increase the size
    of a neural network, while keeping it computationally efficient.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Inception 模块的主要思想是通过保持数据稀疏来实现高效表示。这样，我们可以在技术上增加神经网络的大小，同时保持计算效率。
- en: This is achieved by performing various convolutions and pooling operations,
    and then concatenating everything. In the context of TimesNet, this is how the
    Inception module looks like.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过执行各种卷积和池化操作实现的，然后将所有内容连接在一起。在 TimesNet 的背景下，这就是 Inception 模块的样子。
- en: '![](../Images/a4a7627cc60f293116401161f2e0beb8.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4a7627cc60f293116401161f2e0beb8.png)'
- en: The Inception module in TimesNet. Image by the author.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: TimesNet 中的 Inception 模块。图像由作者提供。
- en: You might wonder why the authors chose a vision model to treat time series data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么作者选择了一个视觉模型来处理时间序列数据。
- en: A simple answer to that is that vision models are particularly good at parsing
    2D data, like images.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个问题的简单回答是视觉模型在解析 2D 数据（如图像）方面特别擅长。
- en: The other benefit is that the vision backbone can be changed inside TimesNet.
    While the authors use the Inception block, it can be changed to other vision model
    backbones, and so TimesNet can also benefit from the advances in computer vision.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个好处是可以在 TimesNet 内部更换视觉骨干。虽然作者使用了 Inception 块，但可以更换为其他视觉模型骨干，因此 TimesNet 也可以从计算机视觉的进展中受益。
- en: Now, one element that separates the Inception module in TimesNet from the inception
    module in GoogLeNet is the use of **adaptive aggregation**.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将 Inception 模块从 TimesNet 与 GoogLeNet 中的 Inception 模块区分开来的一个元素是使用了**自适应聚合**。
- en: Adaptive aggregation
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自适应聚合
- en: To perform aggregation, the 2D representation must be reshaped to 1D vectors
    first.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行聚合，必须先将 2D 表示重塑为 1D 向量。
- en: Then, adaptive aggregation is used, because different periods had different
    amplitudes, which indicates how important they are.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用自适应聚合，因为不同周期的幅度不同，这表明它们的重要性。
- en: This is why the output of the FTT is also sent to a softmax layer, so that the
    aggregation is done using the relative important of each period.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么 FTT 的输出也会被送到 softmax 层，以便根据每个周期的相对重要性进行聚合。
- en: The aggregated data is the output of a single TimesBlock. Then, multiple TimesBlock
    are stacked with residual connections to create the TimesNet model.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合数据是单个 TimesBlock 的输出。然后，多个 TimesBlock 通过残差连接堆叠在一起，创建 TimesNet 模型。
- en: Now that we understand how the TimesNet model works, let’s test it on a forecasting
    task, alongside N-BEATS and N-HITS.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了 TimesNet 模型是如何工作的，让我们在预测任务中测试它，并与 N-BEATS 和 N-HITS 进行比较。
- en: Forecast with TimesNet
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TimesNet 进行预测
- en: Let’s now apply the TimesNet model on a forecasting task, and compare its performance
    against N-BEATS and N-HiTS.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在预测任务中应用 TimesNet 模型，并与 N-BEATS 和 N-HiTS 的表现进行比较。
- en: For this little experiment, we use the [Etth1 dataset](https://github.com/zhouhaoyi/ETDataset)
    released under the Creative Commons Attribution license.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个小实验，我们使用了[Etth1 数据集](https://github.com/zhouhaoyi/ETDataset)，该数据集在创作共用授权下发布。
- en: This is a popular benchmark for time series forecasting widely used in literature.
    It tracks the hourly oil temperature of an electricity transformer which reflects
    the condition of the equipment.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在文献中广泛使用的时间序列预测的流行基准。它跟踪电力变压器的每小时油温，反映了设备的状况。
- en: You can access the dataset and the code on [GitHub](https://github.com/marcopeix/time-series-analysis).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[GitHub](https://github.com/marcopeix/time-series-analysis)上访问数据集和代码。
- en: Import libraries and read the data
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入库并读取数据
- en: We start off by importing the required libraries. Here, we use the implementation
    available in [NeuralForecast](https://nixtla.github.io/neuralforecast/) by Nixtla.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入所需的库。在这里，我们使用了 Nixtla 提供的[NeuralForecast](https://nixtla.github.io/neuralforecast/)的实现。
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then, we can read our CSV file.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以读取我们的 CSV 文件。
- en: '[PRE1]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/485be680afc497d5d08c797437f1d4f4.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/485be680afc497d5d08c797437f1d4f4.png)'
- en: First five rows of the Etth1 dataset. Note that the dataset has already the
    format expected by neuralforecast. Image by the author.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Etth1数据集的前五行。注意数据集已经具有neuralforecast期望的格式。图片由作者提供。
- en: 'In the figure above, note that the dataset already has the format expected
    by NeuralForecast. Basically, the package requires three columns:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，请注意数据集已经具有NeuralForecast期望的格式。基本上，该包需要三列：
- en: a date column labelled as *ds*
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标记为*ds*的日期列
- en: an id column to label your series, labelled as *unique_id*
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标记为*unique_id*的ID列来标记你的系列
- en: a value column labelled as *y*
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标记为*y*的值列
- en: Then, we can plot our series.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以绘制我们的系列。
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/da948d2b72d002b8f6c679986b30a4e3.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da948d2b72d002b8f6c679986b30a4e3.png)'
- en: Visualizing the hourly oil temperature in the Etth1 dataset. Image by the author.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化Etth1数据集中的每小时油温。图片由作者提供。
- en: Now, we can move on to forecasting.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以继续进行预测。
- en: Forecast
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测
- en: For our experiment, we use a forecasting horizon of 96 hours, which is a common
    horizon for long-term forecasting in the literature.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的实验，我们使用96小时的预测范围，这是文献中长期预测的常见范围。
- en: We also reserve two windows of 96 time steps to evaluate our models.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还保留两个96时间步的窗口来评估我们的模型。
- en: First, we define a list of models that we want to use to carry out the forecasting
    task. Again, we will use N-BEATS, N-HiTS, and TimesNet.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义一个要用来进行预测任务的模型列表。再次，我们将使用N-BEATS、N-HiTS和TimesNet。
- en: We will keep the default parameters for all models, and limit the maximum number
    of epochs to 50\. Note that by default, TimesNet will select the top 5 most important
    periods in our data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将保持所有模型的默认参数，并将最大训练轮次限制为50。请注意，默认情况下，TimesNet将选择数据中最重要的前5个周期。
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Once this is done, we can instantiate the *NeuralForecasts* object with the
    list of our models and the frequency of our data, which is hourly.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们可以用我们的模型列表和数据的频率（即每小时）来实例化*NeuralForecasts*对象。
- en: '[PRE4]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, we run cross-validation so that we have the predictions and the actual
    values of our dataset. That way, we can evaluate the performance of each model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们进行交叉验证，以获得预测和数据集的实际值。这样，我们可以评估每个模型的性能。
- en: Again, we use two windows of 96 time steps for the evaluation.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们使用两个96时间步的窗口进行评估。
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/3eb99dd01226ce7a1505c8f248f2109d.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3eb99dd01226ce7a1505c8f248f2109d.png)'
- en: First five rows of the predictions DataFrame. Image by the author.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 预测DataFrame的前五行。图片由作者提供。
- en: Once the models are trained and predictions are done, we get the *DataFrame*
    above. We can see the actual values, as well as the predictions coming from each
    model that we specified earlier.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成并进行预测，我们会得到上述*DataFrame*。我们可以看到实际值以及之前指定的每个模型的预测结果。
- en: We can also easily visualize the predictions against the actual values.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以轻松地将预测与实际值进行可视化。
- en: '[PRE6]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/bd875864d12fcffe264c54dfc50b1822.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd875864d12fcffe264c54dfc50b1822.png)'
- en: Visualizing the predictions of each model on the test set. Here, all models
    fail to predict the decrease observed in the test set. Image by the author.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化每个模型在测试集上的预测。这里，所有模型都未能预测到测试集中观察到的下降。图片由作者提供。
- en: In the figure above, it seems that all models fail to predict the decrease in
    oil temperature observed in the test set. Also, N-BEATS and N-HiTS have captured
    some cyclical pattern that is not observed in the predictions of TimesNet.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，所有模型似乎都未能预测到测试集中观察到的油温下降。此外，N-BEATS和N-HiTS捕捉到了一些在TimesNet的预测中未观察到的周期性模式。
- en: Still, we need to evaluate the models by calculating the MSE and MAE to determine
    which model is best.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然，我们需要通过计算MSE和MAE来评估模型，以确定哪个模型最好。
- en: Evaluation
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估
- en: Now, we simply compute the MAE and MSE to find out which model performed best.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们只需计算MAE和MSE，以找出哪个模型表现最佳。
- en: '[PRE7]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/fc278927215ef99d54ee81093117097f.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc278927215ef99d54ee81093117097f.png)'
- en: Peformance metrics of each model forthe long-term forecasting task on the Etth1
    dataset. Image by the author.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型在Etth1数据集上的长期预测任务的性能指标。图片由作者提供。
- en: From the figure above, we can see the N-HiTS achives the lowest MAE, while N-BEATS
    achieves the lowest MSE.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 从上图可以看出，N-HiTS达到了最低的MAE，而N-BEATS达到了最低的MSE。
- en: However, there is a difference of 0.002 in MAE, and a difference of 0.00025
    in MSE. Since the difference in MSE is so small, especially considering the error
    is squared, I would argue that N-HiTS is the champion model for this task.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，MAE的差异为0.002，MSE的差异为0.00025。由于MSE的差异非常小，特别是考虑到误差是平方的，我认为N-HiTS是这个任务的冠军模型。
- en: So, it turns out that TimesNet did not achieve the best performance. However,
    keep in mind that we just conducted a simple experiment with no hyperparameter
    optimization, on one dataset only, and on two windows of 96 time steps.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，事实证明TimesNet并未达到最佳性能。不过，请记住，我们只是进行了一个简单的实验，没有进行超参数优化，只在一个数据集上，且仅在两个96时间步长的窗口上进行。
- en: This is really meant to show you how to work with TimesNet and NeuralForecast,
    so that you can have another tool in your toolbox to solve your next forecasting
    problem.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的旨在向你展示如何使用TimesNet和NeuralForecast，以便你可以在解决下一个预测问题时有更多工具可用。
- en: Conclusion
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: TimesNet is a CNN-based model that leverages the Inception module to achieve
    state-of-the-art performances on many time series analysis tasks, such as forecasting,
    classification, imputation and anomaly detection.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: TimesNet是一个基于CNN的模型，利用Inception模块在许多时间序列分析任务上实现了最先进的性能，如预测、分类、填补和异常检测。
- en: As always, each forecasting problem requires a unique approach and a specific
    model, so make sure to test out TimesNet as well as other models.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，每个预测问题都需要独特的方法和特定的模型，因此请确保测试TimesNet以及其他模型。
- en: Thanks for reading! I hope that you enjoyed it and that you learned something
    new!
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读！希望你喜欢它，并学到了新的东西！
- en: Looking to master time series forecasting? The check out my course [Applied
    Time Series Forecasting in Python](https://www.datasciencewithmarco.com/offers/zTAs2hi6/checkout?coupon_code=ATSFP10).
    This is the only course that uses Python to implement statistical, deep learning
    and state-of-the-art models in 16 guided hands-on projects.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 想掌握时间序列预测？那就看看我的课程[Python中的应用时间序列预测](https://www.datasciencewithmarco.com/offers/zTAs2hi6/checkout?coupon_code=ATSFP10)。这是唯一一个通过16个指导性动手项目使用Python实现统计、深度学习和最先进模型的课程。
- en: Cheers 🍻
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 干杯 🍻
- en: Support me
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持我
- en: Enjoying my work? Show your support with [Buy me a coffee](http://buymeacoffee.com/dswm),
    a simple way for you to encourage me, and I get to enjoy a cup of coffee! If you
    feel like it, just click the button below 👇
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 喜欢我的工作吗？通过[给我买杯咖啡](http://buymeacoffee.com/dswm)来支持我，这是鼓励我的一种简单方式，我也能享受一杯咖啡！如果你愿意的话，只需点击下面的按钮
    👇
- en: '[![](../Images/0b01a9e378012cb5701b0525dcf23def.png)](https://www.buymeacoffee.com/dswm)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/0b01a9e378012cb5701b0525dcf23def.png)](https://www.buymeacoffee.com/dswm)'
- en: References
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang and Mingsheng Long —
    [TimesNet: Temporal 2D-Variation Modeling For General Time Series Analysis](https://browse.arxiv.org/pdf/2210.02186.pdf)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang 和 Mingsheng Long — [TimesNet：用于一般时间序列分析的时序二维变化建模](https://browse.arxiv.org/pdf/2210.02186.pdf)
- en: Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
- en: Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich — [Going
    Deeper With Convolutions](https://openaccess.thecvf.com/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich — [深入卷积网络](https://openaccess.thecvf.com/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)
