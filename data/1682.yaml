- en: 'When to Run Code on CPU and Not GPU: Typical Cases'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时在 CPU 上运行代码而不是 GPU：典型案例
- en: 原文：[https://towardsdatascience.com/when-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66?source=collection_archive---------2-----------------------#2023-05-21](https://towardsdatascience.com/when-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66?source=collection_archive---------2-----------------------#2023-05-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/when-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66?source=collection_archive---------2-----------------------#2023-05-21](https://towardsdatascience.com/when-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66?source=collection_archive---------2-----------------------#2023-05-21)
- en: How to choose the hardware to optimize the computation for your use case
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何选择硬件以优化特定使用案例的计算
- en: '[](https://robertkwiatkowski01.medium.com/?source=post_page-----bc7c64ee3c66--------------------------------)[![Robert
    Kwiatkowski](../Images/94ec06b3647aef0b65fce2dd97972318.png)](https://robertkwiatkowski01.medium.com/?source=post_page-----bc7c64ee3c66--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bc7c64ee3c66--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bc7c64ee3c66--------------------------------)
    [Robert Kwiatkowski](https://robertkwiatkowski01.medium.com/?source=post_page-----bc7c64ee3c66--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://robertkwiatkowski01.medium.com/?source=post_page-----bc7c64ee3c66--------------------------------)[![Robert
    Kwiatkowski](../Images/94ec06b3647aef0b65fce2dd97972318.png)](https://robertkwiatkowski01.medium.com/?source=post_page-----bc7c64ee3c66--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bc7c64ee3c66--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bc7c64ee3c66--------------------------------)
    [Robert Kwiatkowski](https://robertkwiatkowski01.medium.com/?source=post_page-----bc7c64ee3c66--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9f55d2ee5cad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66&user=Robert+Kwiatkowski&userId=9f55d2ee5cad&source=post_page-9f55d2ee5cad----bc7c64ee3c66---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bc7c64ee3c66--------------------------------)
    ·6 min read·May 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbc7c64ee3c66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66&user=Robert+Kwiatkowski&userId=9f55d2ee5cad&source=-----bc7c64ee3c66---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9f55d2ee5cad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66&user=Robert+Kwiatkowski&userId=9f55d2ee5cad&source=post_page-9f55d2ee5cad----bc7c64ee3c66---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bc7c64ee3c66--------------------------------)
    ·6 分钟阅读·2023 年 5 月 21 日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbc7c64ee3c66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66&user=Robert+Kwiatkowski&userId=9f55d2ee5cad&source=-----bc7c64ee3c66---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc7c64ee3c66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66&source=-----bc7c64ee3c66---------------------bookmark_footer-----------)![](../Images/e802259c9d5e0dbc6d15c2285b8ea5bd.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbc7c64ee3c66&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhen-cpu-is-faster-than-gpu-typical-cases-bc7c64ee3c66&source=-----bc7c64ee3c66---------------------bookmark_footer-----------)![](../Images/e802259c9d5e0dbc6d15c2285b8ea5bd.png)'
- en: Photo by [Francesco Vantini](https://unsplash.com/@brostvarta?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Francesco Vantini](https://unsplash.com/@brostvarta?utm_source=medium&utm_medium=referral)
    由 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 提供
- en: With rapidly advancing technologies like Artificial Intelligence (AI), Machine
    Learning (ML), Internet of Things (IoT), Virtual Reality (VR) and sophisticated
    numerical simulations, the demand for computational power is reaching unprecedented
    heights. In most real-life cases, it’s not only the computational power that counts
    but also factors like the hardware size and power consumption.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能（AI）、机器学习（ML）、物联网（IoT）、虚拟现实（VR）以及复杂的数值模拟技术的快速发展，对计算能力的需求达到了前所未有的高度。在大多数现实情况下，不仅计算能力很重要，还有硬件的大小和功耗等因素。
- en: 'When you’re designing a system depending on business and technical requirements,
    you can choose from various computational components like:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当你根据业务和技术要求设计系统时，可以从各种计算组件中进行选择，例如：
- en: Integrated Circuits (ICs)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成电路（ICs）
- en: Microcontrollers (MCs)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微控制器（MCs）
- en: Central Processing Units (CPU)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中央处理单元（CPU）
- en: Graphics Processing Units (GPU)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图形处理单元（GPU）
- en: Specialized chips like Tensor Processing Units (TPU).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专用芯片，如张量处理单元（TPU）。
- en: 'Although this is an ever-evolving landscape of computing, two integral components
    have revolutionized the way we process data and execute complex tasks. These are
    the Central Processing Unit (CPU) and the Graphics Processing Unit (GPU). Both
    computing powerhouses are instrumental in propelling advancements in various fields:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个不断发展的计算领域，但有两个关键组件彻底改变了我们处理数据和执行复杂任务的方式。这些组件是中央处理单元（CPU）和图形处理单元（GPU）。这两大计算强者在推动各个领域的进步方面起着至关重要的作用：
- en: Artificial intelligence (e.g. ChatGPT)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能（例如ChatGPT）
- en: Scientific simulations (e.g. Finite Element Methods, CFD)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科学模拟（例如有限元方法、计算流体力学）
- en: Gaming
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 游戏
- en: Visual effects
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉效果
- en: Therefore, understanding the unique capabilities and performance characteristics
    of CPUs and GPUs is crucial to harness their full potential and optimizing the
    entire system to the business requirements.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，理解CPU和GPU的独特能力和性能特征对于充分发挥它们的潜力以及优化整个系统以满足业务需求至关重要。
- en: 'When talking about reducing the cost of running computations, you should consider
    the following aspects:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到降低计算运行成本时，你应该考虑以下方面：
- en: Hardware Cost
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件成本
- en: Power Consumption
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功耗
- en: Performance Efficiency
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能效率
- en: Maintenance and Upgrades
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护和升级
- en: Regarding purchase cost, CPUs are more affordable than medium- and high-end
    GPUs. However, GPUs consume more energy than CPUs due to their higher core counts
    and memory bandwidth. So if you design a simple IoT device powered from a 5V battery,
    you’ll probably focus on the power consumption and low hardware cost — then CPU
    (or even IC or MC) would be the best choice.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于购买成本，CPU比中高端GPU更实惠。然而，由于GPU具有更高的核心数量和内存带宽，它们的能耗比CPU高。因此，如果你设计的是一个由5V电池供电的简单物联网设备，你可能会关注功耗和低硬件成本——那么CPU（甚至IC或MC）将是最佳选择。
- en: Also, there is an option of using public cloud resources from, e.g. Google,
    Amazon, or Azure to pay only for the usage time. It is the best choice if you
    design a web service or your hardware requires high computational power but is
    restricted by size or a need for remote access and control. However, in mass-production
    devices like smartphones or smartwatches, hardware cost and power consumption
    still play a decisive role.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，还有一个选项是使用来自例如Google、Amazon或Azure等公共云资源，只为使用时间付费。如果你设计的是一个Web服务，或者你的硬件需要高计算能力但受限于尺寸或需要远程访问和控制，那么这将是最佳选择。然而，在像智能手机或智能手表这样的量产设备中，硬件成本和功耗仍然发挥着决定性作用。
- en: 'Now, when considering computational costs, the total expense usually is a function
    of the time required to complete the task end-to-end. A good example is a training
    of a neural network (NN). It is a very computationally intensive task itself.
    From the end-to-end perspective, there are additional steps like data preparation
    and experiments tracking (for the hyperparameters optimization). It creates an
    additional overhead. However, in the phase of development, the training is still
    the bottleneck, so most popular ML frameworks (e.g. pytorch, Keras) support GPU
    calculations to tackle this problem. It is a classical case for utilizing the
    capabilities of GPU — the training of NN is ideal for massive parallelization.
    It is due to its underlying implementation. However, the inference itself (after
    the model is trained) can be done often on the CPU or even Microcontroller. The
    bottleneck after training may be then on the data preparation side (memory side)
    or I/O operations. For both CPUs are often more suitable. That’s why there are
    even dedicated microprocessors for such kind of tasks (e.g. Intel Atom® Processors
    x7000E). So finally, we came here to two different optimal solutions, depending
    on the environment: development (GPU) and production (CPU).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当考虑计算成本时，总体费用通常是完成任务端到端所需时间的函数。一个好的例子是神经网络（NN）的训练。这本身就是一个计算密集型任务。从端到端的角度来看，还包括数据准备和实验跟踪（用于超参数优化）等额外步骤。这带来了额外的开销。然而，在开发阶段，训练仍然是瓶颈，因此大多数流行的
    ML 框架（如 pytorch、Keras）支持 GPU 计算来解决这个问题。这是利用 GPU 能力的经典案例——NN 的训练非常适合大规模并行化。这是由于其底层实现。然而，推理本身（在模型训练之后）通常可以在
    CPU 或甚至微控制器上完成。训练之后的瓶颈可能在数据准备方面（内存方面）或 I/O 操作方面。对于这两者，CPU 通常更为适合。这就是为什么有些专用微处理器用于这种任务（如
    Intel Atom® Processors x7000E）。所以最终，我们来到了两种不同的最佳解决方案，取决于环境：开发（GPU）和生产（CPU）。
- en: As you see, while GPUs excel in heavy parallel processing, there are several
    situations where CPUs outperform them from the end-to-end perspective. It depends
    on the nature of the algorithms and business requirements. If you’re a software
    developer or a system designer/architect, knowing these situations is crucial
    to deliver the optimal solution.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，虽然 GPU 在重度并行处理上表现出色，但在一些情况下 CPU 从端到端的角度来看超越它们。这取决于算法的性质和业务需求。如果你是软件开发人员或系统设计师/架构师，了解这些情况对于提供最佳解决方案至关重要。
- en: In this article, we will explore some of such scenarios.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨一些此类场景。
- en: '**Single-threaded recursive algorithms**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**单线程递归算法**'
- en: There are algorithms that per design are not a subject of parallelization —
    recursive algorithms. In recursion, the current value depends on the previous
    values — one simple but clear example is the algorithm to calculate the Fibonacci
    number. An exemplary implementation is below. It is impossible in this case to
    break the chain of calculations and run them in parallel.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有些算法本身设计上不适合并行化——递归算法。在递归中，当前值依赖于先前的值——一个简单但明确的例子是计算斐波那契数的算法。一个示例实现如下。在这种情况下，无法打破计算链并并行运行它们。
- en: Another example of such algorithm is a recursive calculation of a factorial
    (see below).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个此类算法的例子是递归计算阶乘（见下文）。
- en: '**Memory-Intensive Tasks**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**内存密集型任务**'
- en: There are tasks where the memory access time is a bottleneck, not computations
    themselves. CPUs usually have larger cache sizes (fast memory access element)
    than GPUs and have faster memory subsystems which allow them to excel at manipulating
    frequently accessed data. A simple example can be an element-wise addition of
    large arrays.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有些任务的瓶颈在于内存访问时间，而不是计算本身。CPU 通常具有比 GPU 更大的缓存大小（快速内存访问元素）以及更快的内存子系统，使其在操作频繁访问的数据时表现出色。一个简单的例子是对大型数组的逐元素加法。
- en: However, in many cases, popular frameworks (like Pytorch) will perform such
    calculations on GPU faster by moving the objects to the GPU’s memory and parallelizing
    operations under the hood.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在许多情况下，流行的框架（如 Pytorch）会通过将对象移动到 GPU 的内存中并在后台并行化操作，使这些计算在 GPU 上更快。
- en: We can create a process where we initialize arrays in RAM and move them to the
    GPU for calculations. This additional overhead of transferring data causes end-to-end
    processing time to be longer than when running it directly on the CPU.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个过程，其中初始化 RAM 中的数组并将它们移动到 GPU 进行计算。传输数据的额外开销导致端到端处理时间比直接在 CPU 上运行要长。
- en: That’s when we usually use so-called CUDA-enabled arrays — in this case, using
    Pytorch. You must only make sure that your GPU can handle this size of data. To
    give you an overview — typical, popular GPUs have a memory size of 2–6GB VRAM,
    while the high-end ones have up to 24GB VRAM (GeForce RTX 4090).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这时我们通常使用所谓的CUDA支持数组——在这种情况下，使用Pytorch。你必须确保你的GPU能够处理这种数据大小。给你一个概述——典型的流行GPU的内存大小为2–6GB
    VRAM，而高端的则有高达24GB VRAM（GeForce RTX 4090）。
- en: '**Other Non-parallelizable Algorithms**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**其他不可并行化算法**'
- en: 'There is a group of algorithms that are not recursive but still cannot be parallelized.
    Some examples are:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有一类算法虽然不是递归的，但仍然无法并行化。一些示例如下：
- en: Gradient Descent — used in optimization tasks and machine learning
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降法 — 用于优化任务和机器学习
- en: Hash-chaining — used in cryptography
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hash-chaining — 用于加密
- en: 'The Gradient Descent cannot be parallelized in its vanilla form, because it
    is a sequential algorithm. Every iteration (called a step) depends on the results
    of the previous one. There are, however, some studies on how to implement this
    algorithm in a parallel manner. To learn more check:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降法在其基础形式中无法并行化，因为它是一个顺序算法。每次迭代（称为一步）依赖于前一次的结果。不过，已经有一些关于如何以并行方式实现此算法的研究。欲了解更多，请查看：
- en: '[HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](https://arxiv.org/abs/1106.5730)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HOGWILD!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent](https://arxiv.org/abs/1106.5730)'
- en: '[Parallel Stochastic Gradient Descent with Sound Combiners](https://arxiv.org/pdf/1705.08030.pdf)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Parallel Stochastic Gradient Descent with Sound Combiners](https://arxiv.org/pdf/1705.08030.pdf)'
- en: 'An example of the Hash-chaining algorithm you can find here: [https://www.geeksforgeeks.org/c-program-hashing-chaining/](https://www.geeksforgeeks.org/c-program-hashing-chaining/)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到Hash-chaining算法的示例：[https://www.geeksforgeeks.org/c-program-hashing-chaining/](https://www.geeksforgeeks.org/c-program-hashing-chaining/)
- en: '**Small tasks**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**小任务**'
- en: Another case when CPUs are a better choice is when the data size is very small.
    In such situations, the overhead of transferring data between the RAM and GPU
    memory (VRAM) can outweigh the benefit of GPU parallelism. This is because of
    the very fast access to the CPU cache. It was mentioned previously in a section
    related to memory-intensive tasks.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个CPU更好的选择是数据量非常小的情况。在这种情况下，RAM和GPU内存（VRAM）之间传输数据的开销可能会超过GPU并行处理的好处。这是因为CPU缓存的访问速度非常快。这在与内存密集型任务相关的部分中提到过。
- en: Also, some tasks are simply too small and although the calculations can be run
    in parallel, the benefit to the end user is not visible. In such cases running
    on GPU generates only the additional hardware-related costs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些任务实在太小，尽管计算可以并行运行，但对最终用户的好处不明显。在这种情况下，在GPU上运行仅会产生额外的硬件相关成本。
- en: 'That’s why in IoT, GPUs are not commonly used. Typical IoT tasks are:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在物联网中，GPU不常被使用。典型的物联网任务有：
- en: to capture some sensor data and send them over
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获一些传感器数据并发送出去
- en: to activate other devices (lights, alarms, motors, etc.) after detecting a signal
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在检测到信号后激活其他设备（灯光、警报、马达等）
- en: However, in this field GPUs are still used in so-called edge-computing tasks.
    These are the situations when you have to acquire and process data directly at
    its source instead of sending them over the Internet for heavy processing. A good
    example is [iFACTORY](https://www.bmwgroup.com/en/news/general/2023/BMWGroupIT)
    developed by BMW.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这个领域，GPU仍然用于所谓的边缘计算任务。这些是你必须直接在数据源处获取和处理数据的情况，而不是将其发送到互联网上进行重处理。一个好的例子是宝马开发的[iFACTORY](https://www.bmwgroup.com/en/news/general/2023/BMWGroupIT)。
- en: '**Task with small level of parallelization**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**小规模并行化任务**'
- en: There are numerous use cases where you have to run the code in parallel but
    due to the speed of CPU it is enough to parallelize the process using multi-core
    CPU. GPU excel in situations where you need a massive parallelization (hundreds
    or thousands of parallel operations). In cases where you find that, e.g. 4x or
    6x speed up is enough you can reduce costs by running the code on CPU, each process
    on different core. Nowadays, manufacturers of CPU offer them with between 2 and
    18 cores (e.g. Intel Core i9–9980XE Extreme Edition Processor).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多使用场景需要并行运行代码，但由于CPU的速度，足以使用多核CPU并行化过程。GPU在需要大规模并行化（数百或数千个并行操作）的情况下表现出色。在你发现例如4倍或6倍加速已经足够的情况下，你可以通过在CPU上运行代码、每个进程在不同核心上来降低成本。如今，CPU制造商提供的CPU核心数在2到18个之间（例如，Intel
    Core i9–9980XE Extreme Edition Processor）。
- en: '**Summary**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**'
- en: 'Overall, the rule of thumb when choosing between CPU and GPU is to answer these
    main questions:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，选择CPU和GPU的经验法则是回答以下主要问题：
- en: Can a CPU handle the entire task within the required time?
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU是否能够在要求的时间内完成整个任务？
- en: Can my code be parallelized?
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我的代码可以并行处理吗？
- en: Can I fit all the data on a GPU? If not does it introduce a heave overhead?
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我能将所有数据放入GPU吗？如果不能，这是否会引入较大的开销？
- en: To answer these questions, its crucial to understand well both how your algorithms
    work and what are the business requirements now and how can they change in the
    future.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答这些问题，关键在于深入理解你的算法是如何工作的，以及当前的业务需求是什么，这些需求未来可能会如何变化。
