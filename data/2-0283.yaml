- en: All You Need to Know to Build Your First LLM App
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建你的第一个 LLM 应用所需知道的一切
- en: 原文：[https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac](https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac](https://towardsdatascience.com/all-you-need-to-know-to-build-your-first-llm-app-eb982c78ffac)
- en: A Step-by-Step Tutorial to Document Loaders, Embeddings, Vector Stores and Prompt
    Templates
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一步一步的教程，涵盖文档加载器、嵌入、向量存储和提示模板
- en: '[](https://dmnkplzr.medium.com/?source=post_page-----eb982c78ffac--------------------------------)[![Dominik
    Polzer](../Images/7e48cd15df31a0ab961391c0d57521de.png)](https://dmnkplzr.medium.com/?source=post_page-----eb982c78ffac--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eb982c78ffac--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eb982c78ffac--------------------------------)
    [Dominik Polzer](https://dmnkplzr.medium.com/?source=post_page-----eb982c78ffac--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmnkplzr.medium.com/?source=post_page-----eb982c78ffac--------------------------------)[![Dominik
    Polzer](../Images/7e48cd15df31a0ab961391c0d57521de.png)](https://dmnkplzr.medium.com/?source=post_page-----eb982c78ffac--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eb982c78ffac--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eb982c78ffac--------------------------------)
    [Dominik Polzer](https://dmnkplzr.medium.com/?source=post_page-----eb982c78ffac--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eb982c78ffac--------------------------------)
    ·26 min read·Jun 22, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eb982c78ffac--------------------------------)
    ·阅读时长 26 分钟·2023年6月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/215dfd8fde2517ee28b96285604db80a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/215dfd8fde2517ee28b96285604db80a.png)'
- en: Build your own chatbot with context injection — Image by the author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上下文注入构建自己的聊天机器人 — 作者图像
- en: Table of Contents
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: If you are just looking for a short tutorial that explains how to build a simple
    LLM application, you can skip to section “6\. Creating a Vector store”, there
    you have all the code snippets you need to build up a minimalistic LLM app with
    vector store, prompt template and LLM call.
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你只是想找一个简短的教程，说明如何构建一个简单的 LLM 应用，你可以跳到第 “6\. 创建向量存储” 部分，在那里你可以找到构建最小化 LLM 应用所需的所有代码片段，包括向量存储、提示模板和
    LLM 调用。
- en: '**Intro**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**'
- en: '[Why we need LLMs](#d5e4)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[为什么我们需要 LLM](#d5e4)'
- en: '[Fine-Tuning vs. Context Injection](#f0e7)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[微调 vs. 上下文注入](#f0e7)'
- en: '[What is LangChain?](#b9f0)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[什么是 LangChain？](#b9f0)'
- en: '**Step-by-Step Tutorial**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**逐步教程**'
- en: '[1\. Load documents using LangChain](#dcec)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[1\. 使用 LangChain 加载文档](#dcec)'
- en: '[2\. Split our Documents into Text Chunks](#2e88)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[2\. 将文档拆分成文本块](#2e88)'
- en: '[3\. From Text Chunks to Embeddings](#335e)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[3\. 从文本块到嵌入](#335e)'
- en: '[4\. Define the LLM you want to use](#b5ab)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[4\. 定义你想使用的 LLM](#b5ab)'
- en: '[5\. Define our Prompt Template](#5e34)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[5\. 定义我们的提示模板](#5e34)'
- en: '[6\. Creating a Vector Store](#4cff)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[6\. 创建一个向量存储](#4cff)'
- en: '![](../Images/abb5a66e45437849d1939f663604994d.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/abb5a66e45437849d1939f663604994d.png)'
- en: Table of contents
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 目录
- en: Why we need LLMs
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们需要 LLM
- en: The evolution of language has brought us humans incredibly far to this day.
    It enables us to efficiently share knowledge and collaborate in the form we know
    today. Consequently, most of our collective knowledge continues to be preserved
    and communicated through unorganized written texts.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 语言的发展使我们人类走得非常远。它使我们能够高效地分享知识并以我们今天所知道的形式进行合作。因此，我们大部分的集体知识仍然通过无组织的书面文本保存和传递。
- en: Initiatives undertaken over the past two decades to digitize information and
    processes have often focused on accumulating more and more data in relational
    databases. This approach enables traditional analytical machine learning algorithms
    to process and understand our data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去二十年里，数字化信息和过程的举措通常专注于在关系数据库中积累越来越多的数据。这种方法使传统的分析机器学习算法能够处理和理解我们的数据。
- en: However, despite our extensive efforts to store an increasing amount of data
    in a structured manner, we are still unable to capture and process the entirety
    of our knowledge.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们广泛努力以结构化的方式存储越来越多的数据，但仍然无法捕获和处理我们全部的知识。
- en: '**About 80% of all data in companies is unstructured, like work descriptions,
    resumes, emails, text documents, power point slides, voice recordings, videos
    and social media**'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**大约 80% 的公司数据是非结构化的，例如工作描述、简历、电子邮件、文本文件、PowerPoint 幻灯片、语音录音、视频和社交媒体**'
- en: '![](../Images/161315a8f6daffba557fdcc5d9fb0d5a.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/161315a8f6daffba557fdcc5d9fb0d5a.png)'
- en: Distribution of data in companies — Image by the author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 企业中的数据分布 — 作者提供的图片
- en: The development and advancement leading to GPT3.5 signify a major milestone
    as it empowers us to effectively interpret and analyze diverse datasets, regardless
    of their structure or lack thereof. Nowadays, we have models that can comprehend
    and generate various forms of content, including text, images, and audio files.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: GPT3.5的开发和进步标志着一个重要的里程碑，因为它使我们能够有效地解释和分析各种数据集，无论其结构如何。如今，我们拥有能够理解和生成多种内容形式的模型，包括文本、图像和音频文件。
- en: '**So how can we leverage their capabilities for our needs and data?**'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**那么我们如何利用它们的能力来满足我们的需求和数据呢？**'
- en: Fine-Tuning vs. Context Injection
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调与上下文注入
- en: 'In general, we have two fundamentally different approaches to enable large
    language models to answer questions that the LLM cannot know: **Model fine-tuning**
    and **context injection**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们有两种基本的方法来使大型语言模型回答LLM无法知道的问题：**模型微调**和**上下文注入**
- en: '**Fine-Tuning**'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**微调**'
- en: Fine-tuning refers to training an existing language model with additional data
    to optimise it for a specific task.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 微调指的是使用额外的数据对现有的语言模型进行训练，以使其优化特定任务。
- en: Instead of training a language model from scratch, a pre-trained model such
    as BERT or LLama is used and then adapted to the needs of a specific task by adding
    use case specific training data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于从零开始训练语言模型，使用预训练模型如BERT或LLama，并通过添加特定任务的训练数据来适应特定任务的需求。
- en: A team from Stanford University used the LLM Llama and fine-tuned it by using
    50,000 examples of how a user/model interaction could look like. The result is
    a Chat Bot that interacts with a user and answers queries. This fine-tuning step
    changed the way the model is interacting with the end user.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 斯坦福大学的一个团队使用了LLM Llama，并通过使用50,000个用户/模型交互的示例对其进行了微调。结果是一个与用户互动并回答查询的聊天机器人。这一步微调改变了模型与最终用户的交互方式。
- en: '**→ Misconceptions around fine-tuning**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**→ 关于微调的误解**'
- en: Fine-tuning of PLLMs (Pre-trained Language Models) is a way to adjust the model
    for a specific task, but it doesn’t really allow you to inject your own domain
    knowledge into the model. This is because the model has already been trained on
    a massive amount of general language data, and your specific domain data is usually
    not enough to override what the model has already learned.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: PLLMs（预训练语言模型）的微调是一种调整模型以适应特定任务的方法，但它并不能真正将您的领域知识注入模型。这是因为模型已经在大量的通用语言数据上进行过训练，而您的特定领域数据通常不足以覆盖模型已经学到的内容。
- en: So, when you fine-tune the model, it might occasionally provide correct answers,
    but it will often fail because it heavily relies on the information it learned
    during pre-training, which might not be accurate or relevant to your specific
    task. In other words, fine-tuning helps the model adapt to HOW it communicates,
    but not necessarily WHAT it communicates. (Porsche AG, 2023)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当你微调模型时，它可能偶尔会提供正确的答案，但它通常会失败，因为它在很大程度上依赖于在预训练期间学到的信息，这些信息可能不准确或与您的特定任务无关。换句话说，微调帮助模型适应它的交流方式，但不一定是它交流的内容。（保时捷股份公司，2023）
- en: This is where context injection comes into play.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是上下文注入发挥作用的地方。
- en: '**In-context learning / Context Injection**'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**上下文学习 / 上下文注入**'
- en: When using context injection, we are not modifying the LLM, we focus on the
    prompt itself and inject relevant context into the prompt.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用上下文注入时，我们并没有修改LLM，而是专注于提示本身，并将相关的上下文注入到提示中。
- en: So we need to think about how to provide the prompt with the right information.
    In the figure below, you can see schematically how the whole thing works. We need
    a process that is able to identify the most relevant data. To do this, we need
    to enable our computer to compare text snippets with each other.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要考虑如何为提示提供正确的信息。在下图中，您可以看到整个过程的示意图。我们需要一个能够识别最相关数据的过程。为此，我们需要使计算机能够比较文本片段。
- en: '![](../Images/6e88d7155e335397440e55e00b5b0ea6.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e88d7155e335397440e55e00b5b0ea6.png)'
- en: Similarity search in our unstructured data — Image by the author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非结构化数据中的相似性搜索 — 作者提供的图片
- en: This can be done with embeddings. With embeddings, we translate text into vectors,
    allowing us to represent text in a multidimensional embedding space. Points that
    are closer to each other in space are often used in the same context. To prevent
    this similarity search from taking forever, we store our vectors in a vector database
    and index them.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过嵌入（embeddings）来完成。通过嵌入，我们将文本转换为向量，从而允许我们在多维嵌入空间中表示文本。在空间中彼此更接近的点通常用于相同的上下文。为了防止这种相似性搜索耗时过长，我们将向量存储在向量数据库中并对其进行索引。
- en: Microsoft is showing us how this could work with Bing Chat. Bing combines the
    ability of LLMs to understand language and context with the efficiency of traditional
    web search.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 微软向我们展示了这可能如何在Bing Chat中实现。Bing结合了LLM理解语言和上下文的能力与传统网络搜索的效率。
- en: The objective of the article is to demonstrate the process of creating a straightforward
    solution that allows us to analyse our own texts and documents, and then incorporate
    the insights gained from them into the answers our solution returns to the user.
    I will describe all steps and components you need to implement an end-to-end solution.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章的目标是展示创建一个简单解决方案的过程，使我们能够分析自己的文本和文档，然后将从中获得的见解融入到解决方案返回给用户的答案中。我将描述实现端到端解决方案所需的所有步骤和组件。
- en: So how can we use the capabilities of LLMs to meet our needs? Let’s go through
    it step by step.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何利用LLM的能力来满足我们的需求呢？让我们一步一步地来看看。
- en: Step by Step tutorial — Your first LLM App
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤教程 — 你的第一个LLM应用
- en: In the following, we want to utilize LLMs to respond to inquiries about our
    personal data. To accomplish this, I begin by transferring the content of our
    personal data into a vector database. This step is crucial as it enables us to
    efficiently search for relevant sections within the text. We will use this information
    from our data and the LLMs capabilities to interpret text to answer the user’s
    question.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们希望利用LLM来回应有关我们个人数据的询问。为此，我开始将个人数据的内容转移到向量数据库中。这个步骤至关重要，因为它使我们能够高效地搜索文本中的相关部分。我们将利用来自数据的信息和LLM的能力来解释文本，以回答用户的问题。
- en: We can also guide the chatbot to exclusively answer questions based on the data
    we provide. This way, we can ensure that the chatbot remains focused on the data
    at hand and provides accurate and relevant responses.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以指导聊天机器人仅根据我们提供的数据回答问题。这样，我们可以确保聊天机器人专注于手头的数据，并提供准确且相关的回应。
- en: To implement our use case, we will rely heavily on LangChain.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现我们的用例，我们将大量依赖LangChain。
- en: What is LangChain?
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain是什么？
- en: '**“LangChain is a framework for developing applications powered by language
    models.” (Langchain, 2023)**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**“LangChain 是一个用于开发语言模型驱动应用程序的框架。”（Langchain, 2023）**'
- en: Thus, LangChain is a Python framework that was designed to support the creation
    of various LLM applications such as chatbots, summary tools, and basically any
    tool you want to create to leverage the power of LLMs. The library combines various
    components we will need. We can connect these components in so-called chains.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，LangChain是一个Python框架，旨在支持各种LLM应用程序的创建，如聊天机器人、摘要工具以及基本上任何你想创建以利用LLM能力的工具。该库结合了我们所需的各种组件。我们可以将这些组件连接成所谓的链。
- en: 'The most important modules of Langchain are (Langchain, 2023):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Langchain最重要的模块是（Langchain, 2023）：
- en: '**Models:** Interfaces to various model types'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型：** 各种模型类型的接口'
- en: '**Prompts:** Prompt management, prompt optimization, and prompt serialization'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示：** 提示管理、提示优化和提示序列化'
- en: '**Indexes:** Document loaders, text splitters, vector stores — Enable faster
    and more efficient access to the data'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**索引：** 文档加载器、文本分割器、向量存储 — 实现对数据的更快、更高效的访问'
- en: '**Chains:** Chains go beyond a single LLM call, they allow us to set up sequences
    of calls'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**链：** 链超越了单一的LLM调用，它们允许我们设置调用的序列'
- en: In the image below, you can see where these components come into play. We load
    and process our own unstructured data using the document loaders and text splitters
    from the indexes module. The prompts module allows us to inject the found content
    into our prompt template, and finally, we are sending the prompt to our model
    using the model's module.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，你可以看到这些组件的作用。我们使用索引模块中的文档加载器和文本分割器来加载和处理我们自己的非结构化数据。提示模块允许我们将找到的内容注入到我们的提示模板中，最后，我们通过模型模块将提示发送给我们的模型。
- en: '![](../Images/ef1c2c72aff354412158ff38565e9aa3.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef1c2c72aff354412158ff38565e9aa3.png)'
- en: Components you need for your LLM app — Image by the author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你为LLM应用所需的组件 — 作者提供的图像
- en: '**5\. Agents:** Agents are entities that use LLMs to make choices regarding
    which actions to take. After taking an action, they observe the outcome of that
    action and repeat the process until their task is completed.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 代理：** 代理是使用 LLM 做出关于采取哪些行动的选择的实体。在采取行动后，它们观察该行动的结果，并重复该过程，直到完成任务。'
- en: '![](../Images/e660c81a051ece8e5fb10fce61226cfa.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e660c81a051ece8e5fb10fce61226cfa.png)'
- en: Agents decide autonomously how to perform a particular task — Image by the author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 代理自主决定如何执行特定任务 — 作者提供的图片
- en: We use Langchain in the first step to load documents, analyse them and make
    them efficiently searchable. After we have indexed the text, it should become
    much more efficient to recognize text snippets that are relevant for answering
    the user’s questions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第一步中使用 LangChain 加载文档，分析它们并使其高效可搜索。在我们索引了文本之后，识别与回答用户问题相关的文本片段应该变得更加高效。
- en: What we need for our simple application is of course an LLM. We will use GPT3.5
    via the OpenAI API. Then we need a vector store that allows us to feed the LLM
    with our own data. And if we want to perform different actions for different queries,
    we need an agent that decides what should happen for each query.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的简单应用程序所需的当然是一个 LLM。我们将通过 OpenAI API 使用 GPT3.5。然后我们需要一个向量存储库，以便我们可以将自己的数据提供给
    LLM。如果我们想对不同的查询执行不同的操作，我们还需要一个代理来决定每个查询应该发生什么。
- en: Let’s start from the beginning. We first need to import our own documents.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从头开始。我们首先需要导入我们自己的文档。
- en: The following section describes what modules are included in LangChain’s Loader
    Module to load different types of documents from different sources.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分描述了 LangChain 的 Loader 模块中包含哪些模块，以从不同来源加载不同类型的文档。
- en: 1\. Load documents using Langchain
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 使用 LangChain 加载文档
- en: LangChain is able to load a number of documents from a wide variety of sources.
    You can find a list of possible document loaders in the LangChain [documentation](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html).
    Among them are loaders for HTML pages, S3 buckets, PDFs, Notion, Google Drive
    and many more.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 能够从各种来源加载多个文档。你可以在 LangChain 的[文档](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html)中找到可能的文档加载器列表。其中包括
    HTML 页面、S3 存储桶、PDF 文件、Notion、Google Drive 等等的加载器。
- en: For our simple example, we use data that was probably not included in the training
    data of GPT3.5\. I use the Wikipedia article about GPT4 because I assume that
    GPT3.5 has limited knowledge about GPT4.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的简单示例，我们使用的数据可能未包含在 GPT3.5 的训练数据中。我使用关于 GPT4 的维基百科文章，因为我假设 GPT3.5 对 GPT4
    的知识有限。
- en: 'For this minimal example, I’m not using any of the LangChain loaders, I’m just
    scraping the text directly from Wikipedia [License: CC BY-SA 3.0]using ***BeautifulSoup.***'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '对于这个简单的示例，我没有使用任何 LangChain 加载器，只是直接从维基百科 [许可: CC BY-SA 3.0] 抓取文本，使用了***BeautifulSoup.***'
- en: '**Please note that scraping websites should only be done in accordance with
    the website’s terms of use and the copyright/license status of the text and data
    you wish to use.**'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**请注意，抓取网站内容应仅按照网站的使用条款以及你希望使用的文本和数据的版权/许可状态进行。**'
- en: '[PRE0]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/0ecc028506e2ab4fad286d986afcda92.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ecc028506e2ab4fad286d986afcda92.png)'
- en: 2\. Split our document into text fragments
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 将文档拆分成文本片段
- en: Next, we must divide the text into smaller sections called text chunks. Each
    text chunk represents a data point in the embedding space, allowing the computer
    to determine the similarity between these chunks.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须将文本分成较小的部分，称为文本块。每个文本块代表嵌入空间中的一个数据点，使计算机能够确定这些块之间的相似性。
- en: The following text snippet is utilizing the text splitter module from langchain.
    In this particular case, we specify a chunk size of 100 and a chunk overlap of
    20\. It’s common to use larger text chunks, but you can experiment a bit to find
    the optimal size for your use case. You just need to remember that every LLM has
    a token limit (4000 tokes for GPT 3.5). Since we are inserting the text blocks
    into our prompt, we need to make sure that the entire prompt is no larger than
    4000 tokens.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文本片段利用了 langchain 的文本分割模块。在这种特定情况下，我们指定了 100 的块大小和 20 的块重叠。虽然使用更大的文本块很常见，但你可以尝试一下以找到适合你用例的最佳大小。你只需要记住，每个
    LLM 都有一个令牌限制（GPT 3.5 为 4000 令牌）。由于我们将文本块插入到提示中，我们需要确保整个提示不超过 4000 个令牌。
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/5f30c3e19308d6a95e82e8dbbd2be48a.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f30c3e19308d6a95e82e8dbbd2be48a.png)'
- en: 'This splits our entire text as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这将我们的整个文本分割如下：
- en: '![](../Images/9883b42387e6a80ef31e153685590e63.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9883b42387e6a80ef31e153685590e63.png)'
- en: Langchain text spliter — Image by the author
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Langchain 文本分割器 — 作者提供的图片
- en: 3\. From Text Chunks to Embeddings
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 从文本块到嵌入
- en: Now we need to make the textual components understandable and comparable to
    our algorithms. We must find a way to convert human language into digital form,
    represented by bits and bytes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要使文本组件对我们的算法可理解和可比。我们必须找到一种将人类语言转换为数字形式（由比特和字节表示）的方法。
- en: The image provides a simple example that may seem obvious to most humans. However,
    we need to find a way to make the computer understand that the name “Charles”
    is associated with men rather than women, and if Charles is a man, he is the king
    and not the queen.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图片提供了一个简单的例子，对大多数人类来说可能显而易见。然而，我们需要找到一种方法，让计算机理解“Charles”这个名字与男性相关，而不是女性，并且如果
    Charles 是男性，他是国王而不是女王。
- en: '![](../Images/5e983ecc380357da8438928f5f94f251.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e983ecc380357da8438928f5f94f251.png)'
- en: Making language understandable for our computer — Image by the author
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使语言对我们的计算机可理解 — 作者提供的图片
- en: Over the last few years, new methods and models have emerged that do just that.
    What we want is a way to be able to translate the meaning of words into an n-dimensional
    space, so we are able to compare text chunks with each other and even calculate
    a measure for the similarity of them.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，出现了可以做到这一点的新方法和模型。我们所希望的是一种将单词的含义转换为 n 维空间的方法，以便能够比较文本块之间的相似性，甚至计算它们之间的相似度度量。
- en: Embedding models attempt to learn exactly that by analyzing the context in which
    words are typically used. Since tea, coffee, and breakfast are often used in the
    same context, they are closer to each other in the n-dimensional space than, for
    example, tea and pea. Tea and pea sound similar but are rarely used together.
    (AssemblyAI, 2022)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型通过分析单词通常使用的上下文来尝试学习这一点。由于 tea、coffee 和 breakfast 经常在相同的上下文中使用，它们在 n 维空间中彼此更接近，而不是，例如，tea
    和 pea。Tea 和 pea 听起来相似，但很少一起使用。（AssemblyAI，2022）
- en: '![](../Images/b82fbabaf51da10acdee62bd36353824.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b82fbabaf51da10acdee62bd36353824.png)'
- en: Embeddings analyze the context in which words are used, not the word itself
    — Image by the author
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入分析了单词使用的上下文，而不是单词本身 — 作者提供的图片
- en: The embedding models provide us with a vector for each word in the embedding
    space. Finally, by representing them using vectors, we are able to perform mathematical
    calculations, such as calculating similarities between words as the distance between
    data points.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型为嵌入空间中的每个单词提供了一个向量。最终，通过使用向量表示它们，我们能够执行数学计算，例如计算单词之间的相似性，作为数据点之间的距离。
- en: '![](../Images/e52927d7c78f5f6d5235f1d06ef8a3e9.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e52927d7c78f5f6d5235f1d06ef8a3e9.png)'
- en: Random english words in a two dimensional embeddings space — Image by the author
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 随机的英文单词在二维嵌入空间中 — 作者提供的图片
- en: To convert text into embeddings, there are several ways, e.g. Word2Vec, GloVe,
    fastText or ELMo.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 将文本转换为嵌入有几种方法，例如 Word2Vec、GloVe、fastText 或 ELMo。
- en: '**Embedding Models**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**嵌入模型**'
- en: To capture similarities between words in embeddings, Word2Vec uses a simple
    neural network. We train this model with large amounts of text data and want to
    create a model that is able to assign a point in the n-dimensional embedding space
    to each word and thus describe its meaning in the form of a vector.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉嵌入中单词之间的相似性，Word2Vec 使用了一个简单的神经网络。我们用大量的文本数据训练这个模型，并希望创建一个能够将每个单词分配到 n 维嵌入空间中的点，并以向量的形式描述其含义的模型。
- en: For the training, we assign a neuron in the input layer to each unique word
    in our data set. In the image below, you can see a simple example. In this case,
    the hidden layer contains only two neurons. Two, because we want to map the words
    in a two dimensional embedding space. (The existing models are in reality much
    larger and thus represent the words in higher dimensional spaces — OpenAI’s Ada
    Embedding Model for example, is using 1536 dimensions) After the training process
    the individual weights describe the position in the embedding space.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们将输入层中的每个独特单词分配给一个神经元。在下面的图片中，你可以看到一个简单的例子。在这个例子中，隐藏层只包含两个神经元。两个神经元是因为我们希望将单词映射到二维嵌入空间中。（现有的模型实际上要大得多，因此在更高维空间中表示单词——例如，OpenAI
    的 Ada 嵌入模型使用的是1536维）在训练过程后，单独的权重描述了在嵌入空间中的位置。
- en: 'In this example, our dataset consists of a single sentence: “Google is a tech
    company.” Each word in the sentence serves as an input for the neural network
    (NN). Consequently, our network has five input neurons, one for each word.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们的数据集由一个句子组成：“Google is a tech company.” 句子中的每个词作为神经网络（NN）的输入。因此，我们的网络有五个输入神经元，每个词一个。
- en: During the training process, we focus on predicting the next word for each input
    word. When we begin at the start of the sentence, the input neuron corresponding
    to the word “Google” receives a value of 1, while the remaining neurons receive
    a value of 0\. We aim to train the network to predict the word “is” in this particular
    scenario.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们的重点是预测每个输入词的下一个词。当我们从句子的开头开始时，与“Google”相关的输入神经元接收到值1，而其余神经元接收到值0。我们的目标是训练网络在这种情况下预测出“is”这个词。
- en: '![](../Images/207cc5bc488b08fbaa216e98e65841dd.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/207cc5bc488b08fbaa216e98e65841dd.png)'
- en: 'Word2Vec: Learning word embeddings — Image by the author'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 'Word2Vec: 学习词嵌入 — 图片由作者提供'
- en: In reality, there are multiple approaches to learn embedding models, each with
    its own unique way of predicting outputs during the training process. Two commonly
    used methods are CBOW (Continuous Bag of Words) and Skip-gram.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，有多种方法可以学习嵌入模型，每种方法都有其独特的预测输出的方式。两种常用的方法是CBOW（连续词袋模型）和Skip-gram。
- en: In CBOW, we take the surrounding words as input and aim to predict the middle
    word. Conversely, in Skip-gram, we take the middle word as input and attempt to
    predict the words occurring on its left and right sides. However, I won’t delve
    into the intricacies of these methods. Let’s just say that these approaches provide
    us with embeddings, which are representations that capture the relationships between
    words by analysing the context of huge amounts of text data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在CBOW中，我们将周围的词作为输入，目标是预测中间的词。相反，在Skip-gram中，我们将中间的词作为输入，并尝试预测其左侧和右侧的词。然而，我不会深入探讨这些方法的细节。可以说，这些方法为我们提供了嵌入，这些嵌入是通过分析大量文本数据的上下文来捕捉词语之间关系的表示。
- en: '![](../Images/72da8315043be5325c287969edce53ab.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72da8315043be5325c287969edce53ab.png)'
- en: CBOW vs. Skip-gram — Image by the author
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: CBOW与Skip-gram — 图片由作者提供
- en: If you want to know more about embeddings*, there is a wealth of information
    available on the internet. However, if you prefer a visual and step-by-step guide,
    you might find it helpful to watch Josh* [*Starmer’s StatQuest on Word Embedding
    and Word2Vec*](https://www.youtube.com/watch?v=viZrOnJclY0&t=204s)*.*
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于嵌入的内容*，互联网上有大量的信息。然而，如果你更喜欢视觉和逐步指导，你可能会觉得观看Josh* [*Starmer关于词嵌入和Word2Vec的StatQuest*](https://www.youtube.com/watch?v=viZrOnJclY0&t=204s)*
    *很有帮助。*
- en: '**Back to embedding models**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**回到嵌入模型**'
- en: What I just tried to explain using a simple example in a 2-dimensional embedding
    space also applies to larger models. For instance, the standard Word2Vec vectors
    have 300 dimensions, while OpenAI’s Ada model has 1536 dimensions. These pretrained
    vectors allow us to capture the relationships between words and their meanings
    with such precision that we can perform calculations with them. For example, using
    these vectors, we can find that France + Berlin — Germany = Paris, and also faster
    + warm — fast = warmer. (Tazzyman, n.d.)
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我刚刚用一个简单的二维嵌入空间示例来解释的内容也适用于更大的模型。例如，标准的Word2Vec向量有300维，而OpenAI的Ada模型有1536维。这些预训练的向量使我们能够精确地捕捉词语及其含义之间的关系，以至于我们可以用它们进行计算。例如，使用这些向量，我们可以发现法国
    + 柏林 — 德国 = 巴黎，同时，*快速* + *温暖* — *快速* = *更温暖*。 (Tazzyman, n.d.)
- en: '![](../Images/00d72db50ce28b008b94bcdc04011b8b.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00d72db50ce28b008b94bcdc04011b8b.png)'
- en: Calculate with embeddings — Image by the author
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用嵌入进行计算 — 图片由作者提供
- en: In the following we want to use the OpenAI API not only to use OpenAI’s LLMs,
    but also to leverage their Embedding Models.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来，我们希望使用OpenAI API，不仅使用OpenAI的LLM，还利用它们的嵌入模型。
- en: '*Note: The difference between Embedding Models and LLMs is that Embedding Models
    focus on creating vector representations of words or phrases to capture their
    meanings and relationships, while LLMs are versatile models trained to generate
    coherent and contextually relevant text based on provided prompts or queries.*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：嵌入模型和LLM之间的区别在于，嵌入模型专注于创建词语或短语的向量表示，以捕捉它们的含义和关系，而LLM则是多功能的模型，经过训练可以根据提供的提示或查询生成连贯且符合上下文的文本。*'
- en: '**OpenAI Embedding Models**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**OpenAI嵌入模型**'
- en: Similar to the various LLMs from OpenAI, you can also choose between a variety
    of embedding models, such as Ada, Davinci, Curie, and Babbage. Among them, Ada-002
    is currently the fastest and most cost-effective model, while Davinci generally
    provides the highest accuracy and performance. However, you need to try them out
    yourself and find the optimal model for your use case. If you’re interested in
    a detailed understanding of OpenAI Embeddings, you can refer to the [OpenAI documentation](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 与OpenAI的各种LLM类似，您还可以在Ada、Davinci、Curie和Babbage等各种嵌入模型之间进行选择。其中，Ada-002目前是最快和最具成本效益的模型，而Davinci通常提供最高的准确性和性能。然而，您需要自己尝试，找到适合您使用案例的最佳模型。如果您对OpenAI
    Embeddings有详细了解的兴趣，可以参考[OpenAI文档](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)。
- en: Our goal with the Embedding Models is to convert our text chunks into vectors.
    In the case of the second generation of Ada, these vectors have 1536 output dimensions,
    which means they represent a specific position or orientation within a 1536-dimensional
    space.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Embedding Models的目标是将文本块转换为向量。在第二代Ada的情况下，这些向量具有1536个输出维度，这意味着它们在1536维空间中表示一个特定的位置或方向。
- en: 'OpenAI describes these embedding vector in their documentation as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI在其文档中描述了这些嵌入向量如下：
- en: “Embeddings that are numerically similar are also semantically similar. For
    example, the embedding vector of “canine companions say” will be more similar
    to the embedding vector of “woof” than that of “meow.” (OpenAI, 2022)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: “数值上相似的嵌入也在语义上相似。例如，“canine companions say”的嵌入向量将比“meow”的嵌入向量更接近“woof”的嵌入向量。”（OpenAI，2022）
- en: 'Let’s give it a try. We use OpenAI’s API to translate our text snippets into
    embeddings as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一下。我们使用OpenAI的API将文本片段转换为嵌入，如下所示：
- en: '[PRE2]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/0f1bafc97daecdcd048e21ad373303d3.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f1bafc97daecdcd048e21ad373303d3.png)'
- en: We convert our text, such as the first text chunk containing “2023 text-generating
    language model,” into a vector with 1536 dimensions. By doing this for each text
    chunk, we can observe in a 1536-dimensional space which text chunks are closer
    and more similar to each other.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将文本，例如包含“2023 text-generating language model”的第一个文本块，转换为1536维的向量。通过对每个文本块进行这种处理，我们可以在1536维空间中观察哪些文本块彼此更接近，更相似。
- en: Let’s give it a try. We aim to compare the users’ questions with the text chunks
    by generating embeddings for the question and then comparing it with other data
    points in the space.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一下。我们的目标是通过为问题生成嵌入，并将其与空间中的其他数据点进行比较，从而将用户的问题与文本块进行比较。
- en: '![](../Images/65eb5bd6420dcbd472c3f86a5dd22b4b.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65eb5bd6420dcbd472c3f86a5dd22b4b.png)'
- en: Which text segment is semantically closer to the user’s question? — Image by
    the author
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个文本片段在语义上更接近用户的问题？— 作者提供的图像
- en: When we represent the text chunks and the user’s question as vectors, we gain
    the ability to explore various mathematical possibilities. In order to determine
    the similarity between two data points, we need to calculate their proximity in
    the multidimensional space, which is achieved using distance metrics. There are
    several methods available to compute the distance between points. [Maarten Grootendorst
    has summarized nine of them in one of his Medium posts.](/9-distance-measures-in-data-science-918109d069fa)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将文本块和用户的问题表示为向量时，我们能够探索各种数学可能性。为了确定两个数据点之间的相似度，我们需要计算它们在多维空间中的接近程度，这可以通过距离度量实现。计算点之间距离的方法有很多种。[Maarten
    Grootendorst在他的Medium帖子中总结了其中的九种。](/9-distance-measures-in-data-science-918109d069fa)
- en: 'A commonly used distance metric is cosine similarity. So let’s try to calculate
    the cosine similarity between our question and the text chunks:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的距离度量是余弦相似度。因此，让我们尝试计算问题与文本块之间的余弦相似度：
- en: '[PRE3]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/239863d9e0969e84b130659926f610c0.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/239863d9e0969e84b130659926f610c0.png)'
- en: Now we have the option to choose the number of text chunks we want to provide
    to our LLM in order to answer the question.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以选择我们希望提供给LLM以回答问题的文本块数量。
- en: The next step is to determine which LLM we would like to use.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是确定我们希望使用的LLM。
- en: 4\. Define the model you want to use
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 定义您要使用的模型
- en: Langchain provides a variety of models and integrations, including OpenAI’s
    GPT and Huggingface, among others. If we decide to use OpenAI’s GPT as our Large
    Language Model, the first step is to define our API Key. Currently, OpenAI offers
    some free usage capacity, but once we exceed a certain number of tokens per month,
    we will need to switch to a paid account.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Langchain 提供了各种模型和集成，包括 OpenAI 的 GPT 和 Huggingface 等。如果我们决定使用 OpenAI 的 GPT 作为我们的大型语言模型，第一步是定义我们的
    API 密钥。目前，OpenAI 提供了一些免费的使用额度，但一旦我们超过每月的令牌数量，我们将需要切换到付费账户。
- en: If we use GPT to answer short questions similar to how we would use Google,
    the costs remain relatively low. However, if we use GPT to answer questions that
    require providing extensive context, such as personal data, the query can quickly
    accumulate thousands of tokens. That increases the cost significantly. But don’t
    worry, you can set a cost limit.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们像使用 Google 一样用 GPT 来回答简短的问题，成本会相对较低。然而，如果我们使用 GPT 来回答需要提供大量背景信息的问题，例如个人数据，查询很快就会累积成千上万的令牌。这会显著增加成本。但不用担心，你可以设置一个成本限制。
- en: '**What is a token?**'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是令牌？**'
- en: In simpler terms, a token is basically a word or a group of words. However,
    in English, words can have different forms, such as verb tenses, plurals, or compound
    words. To handle this, we can use sub-word tokenization, which breaks down a word
    into smaller parts like its root, prefix, suffix, and other linguistic elements.
    For example, the word “tiresome” can be split into “tire” and “some,” while “tired”
    can be divided into “tire” and “d.” By doing this, we can recognize that “tiresome”
    and “tired” share the same root and have a similar derivation. (Wang, 2023)
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，令牌基本上是一个单词或一组单词。然而，在英语中，单词可以有不同的形式，比如动词时态、复数或复合词。为了解决这个问题，我们可以使用子词令牌化，它将一个单词拆分成更小的部分，如词根、前缀、后缀和其他语言学元素。例如，单词“tiresome”可以拆分为“tire”和“some”，而“tired”可以分为“tire”和“d”。通过这样做，我们可以识别出“tiresome”和“tired”共享相同的词根，并具有类似的词源。（Wang,
    2023）
- en: OpenAI offers a tokenizer on its website to get a feel for what a token is.
    According to OpenAI one token generally corresponds to ~4 characters of text for
    common English text. This translates to roughly ¾ of a word (so 100 tokens ~=
    75 words). You can find a [Tokenizer App on OpenAI’s website](https://platform.openai.com/tokenizer)
    that gives you an idea of what actually counts as a token.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 在其网站上提供了一个令牌计算器，让你了解什么是令牌。根据 OpenAI 的说法，一个令牌通常对应于大约 4 个常见英文字符。这大约相当于
    ¾ 个单词（因此 100 个令牌 ≈ 75 个单词）。你可以在 [OpenAI 网站上的令牌计算器](https://platform.openai.com/tokenizer)
    找到一个应用，帮助你了解什么实际上算作一个令牌。
- en: '**Set a usage limit**'
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**设置使用限制**'
- en: ''
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you are concerned about the cost, you can find an option in your OpenAI user
    portal to limit the monthly costs.
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你担心成本，你可以在 OpenAI 用户门户中找到一个选项来限制每月费用。
- en: You can find the API key in your user account at OpenAI. The simplest way is
    to search in Google for “OpenAI API key”. This brings you directly to the settings
    page, to create a new key.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 OpenAI 的用户账户中找到 API 密钥。最简单的方法是用 Google 搜索“OpenAI API key”。这会直接带你到设置页面，以创建新的密钥。
- en: 'To use in Python, you have to save the key as a new environment variable with
    the name “OPENAI_API_KEY”:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Python 中使用，你必须将密钥保存为名为 “OPENAI_API_KEY” 的新环境变量：
- en: '[PRE4]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: When you select the LLM you want to use, you can preset a few parameters. The
    [OpenAI Playground](https://platform.openai.com/playground) gives you the possibility
    to play around a bit with the different parameters before you decide what settings
    you want to use.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当你选择要使用的语言模型（LLM）时，可以预设一些参数。 [OpenAI Playground](https://platform.openai.com/playground)
    让你在决定使用什么设置之前，可以先试验一下不同的参数。
- en: On the right side in the Playground WebUI, you will find several parameters
    provided by OpenAI that allow us to influence the output of the LLM. Two parameters
    worth exploring are the model selection and the temperature.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Playground WebUI 的右侧，你会找到 OpenAI 提供的几个参数，这些参数允许我们影响 LLM 的输出。两个值得探索的参数是模型选择和温度。
- en: You have the option to choose from a variety of different models. The Text-davinci-003
    model is currently the largest and most powerful. On the other hand, models like
    Text-ada-001 are smaller, faster, and more cost-effective.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从各种不同的模型中进行选择。目前，Text-davinci-003 模型是最大的、最强大的。另一方面，像 Text-ada-001 这样的模型更小、更快、成本更低。
- en: Below, you can see a summary of [OpenAI’s pricing](https://openai.com/pricing)
    list. Ada is cheaper compared to the most powerful model, Davinci. So if Ada’s
    performance meets our needs, we can not only save money, but also achieve shorter
    response times.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，你可以看到[OpenAI定价](https://openai.com/pricing)列表的总结。Ada的费用低于最强大的模型Davinci。因此，如果Ada的表现满足我们的需求，我们不仅可以节省资金，还能实现更短的响应时间。
- en: You could begin by using Davinci and then evaluate whether we can achieve good
    enough results with Ada as well.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以首先使用Davinci，然后评估是否可以使用Ada获得足够好的结果。
- en: So let’s try it out in Jupyter Notebook. We are using langchain to connect to
    GPT.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们在Jupyter Notebook中试试吧。我们正在使用langchain连接到GPT。
- en: '[PRE5]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If you want to see a list with all attributes, use __dict__:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看包含所有属性的列表，请使用__dict__：
- en: '[PRE6]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/a684aa79cd7cce2dbd32c1d847c4ea65.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a684aa79cd7cce2dbd32c1d847c4ea65.png)'
- en: If we don’t specify a particular model, the langchain connector defaults to
    using “text-davinci-003”.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有指定特定的模型，langchain连接器默认使用“text-davinci-003”。
- en: Now, we can directly invoke the model in Python. Simply call the llm function
    and provide your prompt as input.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以直接在Python中调用模型。只需调用llm函数并将提示作为输入提供。
- en: '![](../Images/3b12ecf96f1efa3c6f40b112aa2b5636.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b12ecf96f1efa3c6f40b112aa2b5636.png)'
- en: You can now ask GPT anything about common human knowledge.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以向GPT提问任何关于常见人类知识的问题。
- en: '![](../Images/f1e05a7a00e093c974d44fd9f31b6716.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1e05a7a00e093c974d44fd9f31b6716.png)'
- en: GPT can only provide limited information on topics that are not included in
    its training data. This includes specific details that are not publicly available
    or events that occurred after the training data was last updated.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: GPT只能提供有限的信息，关于其训练数据中未包含的主题。这包括不公开的具体细节或训练数据最后更新后发生的事件。
- en: '![](../Images/0fcfb9a7848e3a8be48b599bae9d827e.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fcfb9a7848e3a8be48b599bae9d827e.png)'
- en: '**So, how can we make sure that the models are able to respond to questions
    about current events?**'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么，我们如何确保模型能够回答有关当前事件的问题呢？**'
- en: As mentioned before, there’s a way to do this. We need to give the model the
    necessary information within the prompt.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这里有一种方法可以做到这一点。我们需要在提示中提供模型所需的信息。
- en: 'To answer the question about the current Prime Minister of the UK, I feed the
    prompt with information from the Wikipedia article “Prime Ministers of the UK”.
    To summarize the process, we are:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答有关英国现任首相的问题，我使用了来自维基百科文章“英国首相”的信息。为了总结这个过程，我们正在：
- en: Loading the article
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载文章
- en: Split the text into text chunks
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本拆分成文本块
- en: Calculate the embeddings for the text chunks
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算文本块的嵌入
- en: Calculate the similarity between all text chunks and the user’s question
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算所有文本块与用户问题的相似度
- en: '[PRE7]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we try to find the text chunks with the highest similarity to the user’s
    question:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试找到与用户问题最相似的文本块：
- en: '[PRE8]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/ca95025e46092c6aac7cbbb536db9a81.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca95025e46092c6aac7cbbb536db9a81.png)'
- en: The text chunks look quite messy, but let’s give it a shot and see if GPT is
    clever enough to handle it.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 文本块看起来相当混乱，但让我们试试，看GPT是否足够聪明来处理它。
- en: Now that we’ve identified the text segments that potentially hold the relevant
    information, we can test whether our model is capable of answering the question.
    To achieve this, we must construct our prompt in a way that clearly conveys our
    desired task to the model.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经识别出可能包含相关信息的文本段落，我们可以测试我们的模型是否能够回答这个问题。为了实现这一点，我们必须以一种清晰地传达我们期望任务的方式构建我们的提示。
- en: 5\. Define our Prompt Template
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 定义我们的提示模板
- en: Now we have the text snippets that contain the information we are looking for,
    we need to build a prompt. Within the prompt we also specify the desired mode
    for the model to answer questions. When we define the mode we are specifying the
    desired behavior style in which we want the LLM to generate answers.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了包含我们所寻找的信息的文本片段，我们需要构建一个提示。在提示中我们还指定模型回答问题所需的模式。当我们定义模式时，我们在指定LLM生成答案的期望行为风格。
- en: 'The LLM can be utilized for various tasks, and here are a few examples of the
    wide range of possibilities:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: LLM可以用于各种任务，以下是一些广泛可能性的例子：
- en: '**Summarization:** “Summarize the following text into 3 paragraphs for executives:
    [TEXT]'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总结：** “将以下文本总结成3段，以供高管参考：[TEXT]”'
- en: '**Knowledge extraction:** “Based on this article: [TEXT], what should people
    consider before purchasing a home?”'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识提取：** “基于这篇文章：[TEXT]，人们在购买房屋之前应该考虑哪些问题？”'
- en: '**Writing content (e.g. mails, messages, code):** Write an email to Jane asking
    for an update on the document for our project. Use an informal, friendly tone.”'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**撰写内容（例如邮件、消息、代码）：** 写一封邮件给简，询问我们项目文档的最新情况。使用非正式、友好的语气。”'
- en: '**Grammar and style improvements:** “Correct this to standard English and change
    the tone to a friendlier one: [TEXT]'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语法和风格改进：** “将其改为标准英语，并将语气改为更友好的： [TEXT]”'
- en: '**Classification:** “Classify each message as a type of support ticket: [TEXT]”'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类：** “将每条消息分类为支持票据的类型：[TEXT]”'
- en: For our example, we want to implement a solution that extracts data from Wikipedia
    and interacts with the user like a chatbot. We want it to answer questions like
    a motivated, helpful help desk expert.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们希望实现一个从维基百科提取数据并像聊天机器人一样与用户互动的解决方案。我们希望它能够像一个积极、乐于助人的帮助台专家一样回答问题。
- en: 'To guide the LLM in the right direction, I am adding the following instruction
    to the prompt:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了引导 LLM 向正确方向发展，我在提示中添加了以下指令：
- en: '**“You are a chatbot that loves to help people! Answer the following question
    using only the context provided. If you’re unsure and the answer isn’t explicitly
    in the context, say “Sorry, I don’t know how to help you.”**'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**“你是一个喜欢帮助别人的聊天机器人！仅使用提供的上下文回答以下问题。如果你不确定且答案在上下文中没有明确给出，请说‘对不起，我不知道如何帮助你。’”**'
- en: By doing this, I set a limitation that only allows GPT to utilize the information
    stored in our database. This restriction enables us to provide the sources our
    chatbot relied upon to generate the response, which is crucial for traceability
    and establishing trust. Additionally, it helps us address the issue of generating
    unreliable information and allows us to provide answers that can be utilized in
    a corporate setting for decision-making purposes.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我设定了一个限制，只允许 GPT 利用我们数据库中的信息。这种限制使我们能够提供聊天机器人生成回应时所依赖的来源，这对追踪来源和建立信任至关重要。此外，它有助于解决生成不可靠信息的问题，并使我们能够提供可用于公司决策的答案。
- en: As the context, I am simply using the top 50 text chunks with the highest similarity
    to the question. A larger size of the text chunks would probably have been better
    since we can usually answer most questions with one or two text passages. But
    I’ll leave it to you to figure out the best size for your use case.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 作为上下文，我仅使用与问题最相似的前 50 个文本块。更大的文本块可能会更好，因为我们通常可以用一到两个文本段落回答大多数问题。但我将把找到最佳大小的任务留给你来完成。
- en: '[PRE9]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'By using that specific template, I am incorporating both the context and the
    user’s question into our prompt. The resulting response is as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用那个特定模板，我将上下文和用户的问题都纳入了我们的提示中。生成的回应如下：
- en: '![](../Images/90849344b5dd20ee37b89e46d4e84319.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90849344b5dd20ee37b89e46d4e84319.png)'
- en: 'Surprisingly, even this simple implementation seems to have produced some satisfactory
    results. Let’s proceed by asking the system a few more questions regarding British
    prime ministers. I will keep everything unchanged and solely replace the user’s
    question:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 出乎意料的是，即使是这个简单的实现也似乎产生了一些令人满意的结果。让我们继续向系统提出更多关于英国首相的问题。我将保持一切不变，只替换用户的问题：
- en: '[PRE10]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/daf31fbecc5113e76cc4f0649d162f63.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/daf31fbecc5113e76cc4f0649d162f63.png)'
- en: It appears to be functioning to some extent. However, our objective now is to
    transform this slow process into a robust and efficient one. To achieve this,
    we introduce an indexing step where we store our embeddings and indexes in a vector
    store. This will enhance the overall performance and decrease the response time.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 它似乎在某种程度上正在运行。然而，我们现在的目标是将这个缓慢的过程转变为一个强大且高效的过程。为此，我们引入了一个索引步骤，在向量存储中存储我们的嵌入和索引。这将提高整体性能并减少响应时间。
- en: 6\. Creating a vector store (vector database)
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 创建向量存储（向量数据库）
- en: A vector store is a type of data store that is optimized for storing and retrieving
    large quantities of data that can be represented as vectors. These types of databases
    allow for efficient querying and retrieval of subsets of the data based on various
    criteria, such as similarity measures or other mathematical operations.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储是一种优化用于存储和检索可以表示为向量的大量数据的数据存储类型。这些类型的数据库允许根据各种标准（如相似性度量或其他数学操作）高效查询和检索数据的子集。
- en: Converting our text data into vectors is the first step, but it is not enough
    for our needs. If we were to store the vectors in a data frame and search step-by-step
    the similarities between words every time we get a query, the whole process would
    be incredibly slow.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们的文本数据转换为向量是第一步，但这对于我们的需求还不够。如果我们将向量存储在数据框中，并在每次收到查询时逐步搜索单词之间的相似性，那么整个过程将会非常缓慢。
- en: In order to efficiently search our embeddings, we need to index them. Indexing
    is the second important component of a vector database. The index provides a way
    to map queries to the most relevant documents or items in the vector store without
    having to compute similarities between every query and every document.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了高效地搜索我们的嵌入，我们需要对它们进行索引。索引是向量数据库的第二个重要组成部分。索引提供了一种将查询映射到向量存储库中最相关的文档或项目的方法，而无需计算每个查询与每个文档之间的相似性。
- en: 'In recent years, a number of vector stores have been released. Especially in
    the field of LLMs, the attention around vector stores has exploded:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，已经发布了许多向量存储库。尤其在LLM领域，对向量存储库的关注激增：
- en: '![](../Images/105814f00b193fc06addfb2a85f368b1.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/105814f00b193fc06addfb2a85f368b1.png)'
- en: Release Vector Stores in the past years — Image by the author
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来发布的向量存储库 — 图片来自作者
- en: Now let’s just pick one and try it out for our use case. Similar to what we
    did in the previous sections, we are again calculating the embeddings and storing
    them in a vector store. To do this, we are using suitable modules from LangChain
    and chroma as a vector store.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来选择一个并试用一下我们的用例。类似于我们在前面部分所做的，我们再次计算嵌入并将其存储在向量存储库中。为此，我们使用了来自LangChain和chroma的合适模块作为向量存储库。
- en: '**Collect data that we want to use to answer the users’ questions:**'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**收集我们想要用来回答用户问题的数据：**'
- en: '![](../Images/f90d9f156966a818815b8c5b4533d1a8.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f90d9f156966a818815b8c5b4533d1a8.png)'
- en: Image by the author
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: '[PRE11]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**2\. Load the data and define how you want to split the data into text chunks**'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 加载数据并定义如何将数据拆分为文本块**'
- en: '![](../Images/d8ae68a1b459338281e1f039d3ce5ebc.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8ae68a1b459338281e1f039d3ce5ebc.png)'
- en: Image by the author
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: '[PRE12]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**3\. Define the Embeddings Model you want to use to calculate the embeddings
    for your text chunks and store them in a vector store (here: Chroma)**'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 定义要用来计算文本块嵌入的嵌入模型，并将其存储在向量存储库中（这里使用：Chroma）**'
- en: '![](../Images/637ae1d82b4e950d0aeb6f96769eb065.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/637ae1d82b4e950d0aeb6f96769eb065.png)'
- en: Image by the author
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: '[PRE13]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**4\. Calculate the embeddings for the user’s question, find similar text chunks
    in our vector store and use them to build our prompt**'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 计算用户问题的嵌入，找到向量存储库中相似的文本块，并使用它们来构建我们的提示**'
- en: '![](../Images/730fb905ee3a9f4c5af1ae6d7b5f89cf.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/730fb905ee3a9f4c5af1ae6d7b5f89cf.png)'
- en: Image by the author
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自作者
- en: '[PRE14]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/b31e0fadb9e5b7644a8725ae0a7ccc30.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b31e0fadb9e5b7644a8725ae0a7ccc30.png)'
- en: Summary
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: To enable our LLM to analyze and answer questions about our data, we usually
    don’t fine-tune the model. Instead, during the fine-tuning process, the objective
    is to improve the model’s ability to effectively respond to a specific task, rather
    than teaching it new information.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的LLM能够分析和回答有关我们数据的问题，我们通常不会对模型进行微调。相反，在微调过程中，目标是提高模型有效响应特定任务的能力，而不是教它新的信息。
- en: In the case of Alpaca 7B, the LLM (LLaMA) was fine-tuned to behave and interact
    like a chatbot. The focus was on refining the model’s responses, rather than teaching
    it completely new information.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在Alpaca 7B的案例中，LLM（LLaMA）经过微调，以表现和互动像一个聊天机器人。重点是完善模型的回应，而不是教它完全新的信息。
- en: So to be able to answer questions about our own data, we use the Context Injection
    approach. Creating an LLM app with Context Injection is a relatively simple process.
    The main challenge lies in organizing and formatting the data to be stored in
    a vector database. This step is crucial for efficiently retrieving contextually
    similar information and ensuring reliable results.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够回答关于我们自己数据的问题，我们使用上下文注入方法。创建一个具有上下文注入的LLM应用程序是一个相对简单的过程。主要挑战在于组织和格式化要存储在向量数据库中的数据。这一步对于高效检索上下文相似信息并确保可靠结果至关重要。
- en: The goal of the article was to demonstrate a minimalist approach to using embedding
    models, vector stores, and LLMs to process user queries. It shows how these technologies
    can work together to provide relevant and accurate answers, even to constantly
    changing facts.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目标是展示使用嵌入模型、向量存储和LLMs处理用户查询的极简方法。它展示了这些技术如何协同工作，即使面对不断变化的事实，也能提供相关且准确的答案。
- en: '*Enjoyed the story?*'
  id: totrans-229
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*喜欢这个故事吗？*'
- en: '[*Subscribe for free*](https://dmnkplzr.medium.com/subscribe) *to get notified
    when I publish a new story.*'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*免费订阅*](https://dmnkplzr.medium.com/subscribe) *以便在我发布新故事时收到通知。*'
- en: '*Want to read more than 3 free stories a month? — Become a Medium member for
    5$/month. You can support me by using my* [*referral link*](https://dmnkplzr.medium.com/membership)
    *when you sign up. I’ll receive a commission at no extra cost to you.*'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*想每月阅读超过3篇免费故事？— 成为Medium会员，每月5美元。您可以通过使用我的* [*推荐链接*](https://dmnkplzr.medium.com/membership)
    *来支持我。您不会增加额外费用，但我将获得佣金。*'
- en: '*Feel free to reach out to me on* [*LinkedIn*](https://www.linkedin.com/in/polzerdo/)
    *!*'
  id: totrans-232
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*随时通过* [*LinkedIn*](https://www.linkedin.com/in/polzerdo/) *联系我！*'
- en: References
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: AssemblyAI (Director). (2022, January 5). A Complete Overview of Word Embeddings.
    [https://www.youtube.com/watch?v=5MaWmXwxFNQ](https://www.youtube.com/watch?v=5MaWmXwxFNQ)
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: AssemblyAI (导演). (2022年1月5日). 完整的词嵌入概述. [https://www.youtube.com/watch?v=5MaWmXwxFNQ](https://www.youtube.com/watch?v=5MaWmXwxFNQ)
- en: Grootendorst, M. (2021, December 7). 9 Distance Measures in Data Science. Medium.
    [https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa](/9-distance-measures-in-data-science-918109d069fa)
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Grootendorst, M. (2021年12月7日). 数据科学中的9种距离度量. Medium. [https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa](/9-distance-measures-in-data-science-918109d069fa)
- en: Langchain. (2023). Welcome to LangChain — 🦜🔗 LangChain 0.0.189\. [https://python.langchain.com/en/latest/index.html](https://python.langchain.com/en/latest/index.html)
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Langchain. (2023). 欢迎使用 LangChain — 🦜🔗 LangChain 0.0.189\. [https://python.langchain.com/en/latest/index.html](https://python.langchain.com/en/latest/index.html)
- en: Nelson, P. (2023). Search and Unstructured Data Analytics Trends |
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Nelson, P. (2023). 搜索与非结构化数据分析趋势 |
- en: Accenture. Search and Content Analytics Blog. [https://www.accenture.com/us-en/blogs/search-and-content-analytics-blog/search-unstructured-data-analytics-trends](https://www.accenture.com/us-en/blogs/search-and-content-analytics-blog/search-unstructured-data-analytics-trends)
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Accenture. 搜索与内容分析博客. [https://www.accenture.com/us-en/blogs/search-and-content-analytics-blog/search-unstructured-data-analytics-trends](https://www.accenture.com/us-en/blogs/search-and-content-analytics-blog/search-unstructured-data-analytics-trends)
- en: OpenAI. (2022). Introducing text and code embeddings. [https://openai.com/blog/introducing-text-and-code-embeddings](https://openai.com/blog/introducing-text-and-code-embeddings)
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI. (2022). 介绍文本和代码嵌入. [https://openai.com/blog/introducing-text-and-code-embeddings](https://openai.com/blog/introducing-text-and-code-embeddings)
- en: OpenAI (Director). (2023, March 14). What can you do with GPT-4? [https://www.youtube.com/watch?v=oc6RV5c1yd0](https://www.youtube.com/watch?v=oc6RV5c1yd0)
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI (导演). (2023年3月14日). 你可以用GPT-4做什么？ [https://www.youtube.com/watch?v=oc6RV5c1yd0](https://www.youtube.com/watch?v=oc6RV5c1yd0)
- en: 'Porsche AG. (2023, May 17). ChatGPT & enterprise knowledge: “How can I create
    a chatbot for my business unit?” #NextLevelGermanEngineering. [https://medium.com/next-level-german-engineering/chatgpt-enterprise-knowledge-how-can-i-create-a-chatbot-for-my-business-unit-4380f7b3d4c0](https://medium.com/next-level-german-engineering/chatgpt-enterprise-knowledge-how-can-i-create-a-chatbot-for-my-business-unit-4380f7b3d4c0)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 'Porsche AG. (2023年5月17日). ChatGPT与企业知识：“我如何为我的业务部门创建一个聊天机器人？” #NextLevelGermanEngineering.
    [https://medium.com/next-level-german-engineering/chatgpt-enterprise-knowledge-how-can-i-create-a-chatbot-for-my-business-unit-4380f7b3d4c0](https://medium.com/next-level-german-engineering/chatgpt-enterprise-knowledge-how-can-i-create-a-chatbot-for-my-business-unit-4380f7b3d4c0)'
- en: Tazzyman, S. (2023). Neural Network models. NLP-Guidance. [https://moj-analytical-services.github.io/NLP-guidance/NNmodels.html](https://moj-analytical-services.github.io/NLP-guidance/NNmodels.html)
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Tazzyman, S. (2023). 神经网络模型. NLP-Guidance. [https://moj-analytical-services.github.io/NLP-guidance/NNmodels.html](https://moj-analytical-services.github.io/NLP-guidance/NNmodels.html)
- en: Wang, W. (2023, April 12). An In-Depth Look at the Transformer Based Models.
    Medium.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Wang, W. (2023年4月12日). 深入了解基于变换器的模型. Medium.
