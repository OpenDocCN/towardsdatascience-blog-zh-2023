- en: What are Multimodal models?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多模态模型是什么？
- en: 原文：[https://towardsdatascience.com/what-are-multimodal-models-fe118f3ef963?source=collection_archive---------2-----------------------#2023-10-16](https://towardsdatascience.com/what-are-multimodal-models-fe118f3ef963?source=collection_archive---------2-----------------------#2023-10-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-are-multimodal-models-fe118f3ef963?source=collection_archive---------2-----------------------#2023-10-16](https://towardsdatascience.com/what-are-multimodal-models-fe118f3ef963?source=collection_archive---------2-----------------------#2023-10-16)
- en: Give LLMs the ability to see!
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 赋予大型语言模型（LLMs）视觉能力！
- en: '[](https://medium.com/@omermx?source=post_page-----fe118f3ef963--------------------------------)[![Omer
    Mahmood](../Images/0c87da4134bea397c77bc4ba6640e34b.png)](https://medium.com/@omermx?source=post_page-----fe118f3ef963--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fe118f3ef963--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fe118f3ef963--------------------------------)
    [Omer Mahmood](https://medium.com/@omermx?source=post_page-----fe118f3ef963--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@omermx?source=post_page-----fe118f3ef963--------------------------------)[![Omer
    Mahmood](../Images/0c87da4134bea397c77bc4ba6640e34b.png)](https://medium.com/@omermx?source=post_page-----fe118f3ef963--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fe118f3ef963--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fe118f3ef963--------------------------------)
    [Omer Mahmood](https://medium.com/@omermx?source=post_page-----fe118f3ef963--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F62cd989987f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-multimodal-models-fe118f3ef963&user=Omer+Mahmood&userId=62cd989987f6&source=post_page-62cd989987f6----fe118f3ef963---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fe118f3ef963--------------------------------)
    ·6 min read·Oct 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffe118f3ef963&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-multimodal-models-fe118f3ef963&user=Omer+Mahmood&userId=62cd989987f6&source=-----fe118f3ef963---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F62cd989987f6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-multimodal-models-fe118f3ef963&user=Omer+Mahmood&userId=62cd989987f6&source=post_page-62cd989987f6----fe118f3ef963---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----fe118f3ef963--------------------------------)
    ·6分钟阅读·2023年10月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffe118f3ef963&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-multimodal-models-fe118f3ef963&user=Omer+Mahmood&userId=62cd989987f6&source=-----fe118f3ef963---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe118f3ef963&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-multimodal-models-fe118f3ef963&source=-----fe118f3ef963---------------------bookmark_footer-----------)![](../Images/4b7fb0fc89f35adbb6b9d33055d2f0d0.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffe118f3ef963&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-are-multimodal-models-fe118f3ef963&source=-----fe118f3ef963---------------------bookmark_footer-----------)![](../Images/4b7fb0fc89f35adbb6b9d33055d2f0d0.png)'
- en: Screenshot of [Mecari text & image embeddings demo](https://atlas.nomic.ai/map/vertex-mercari)
    running on Atlas by Nomic.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mecari 文本与图像嵌入演示](https://atlas.nomic.ai/map/vertex-mercari)的截图，运行在 Nomic
    的 Atlas 上。'
- en: Who is this post for?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这篇文章适合谁？
- en: '**Reader Audience [🟢⚪️⚪️]:** AI beginners, familiar with popular concepts,
    models and their applications'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**读者群体 [🟢⚪️⚪️]:** 人工智能初学者，熟悉流行概念、模型及其应用'
- en: '**Level [🟢🟢️⚪️]:** Intermediate topic'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平 [🟢🟢️⚪️]:** 中级话题'
- en: '**Complexity [🟢⚪️⚪️]:** Easy to digest, no mathematical formulas or complex
    theory here'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂性 [🟢⚪️⚪️]:** 易于理解，没有数学公式或复杂理论'
- en: ❓Why It Matters
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ❓为什么这很重要
- en: Foundational large language models (LLMs), pre-trained on huge datasets are
    pretty efficient at handling generic, multi-tasking via prompts through zero-shot,
    few-shot or transfer learning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 基础的大型语言模型（LLMs），在巨大的数据集上进行预训练，非常高效地处理通用的多任务，通过零-shot、few-shot 或迁移学习进行提示。
- en: Indeed, examples of these models like [PaLM2](https://ai.google/discover/palm2/)
    and [GPT4](https://openai.com/research/gpt-4) have revolutionised the way we interact
    with computers **using text as an input**, but…
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，像[PaLM2](https://ai.google/discover/palm2/)和[GPT4](https://openai.com/research/gpt-4)这样的模型已经彻底改变了我们与计算机**使用文本作为输入**的交互方式，但…
- en: What if there was a way to extend the intelligence of these models, by enabling
    them to use different modalities of input, such as photos, audio, and video? **Or
    in other words, make them Multimodal!**
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有一种方法可以扩展这些模型的智能，通过使它们能够使用不同的输入模态，如照片、音频和视频，**换句话说，让它们变得多模态！**
- en: It could greatly improve how we search for things on the web, or even understand
    the world around us for example in real world applications such as medicine and
    pathology.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这可以大大改善我们在网上搜索东西的方式，甚至理解我们周围的世界，例如在现实世界应用中，如医学和病理学。
- en: There is a solution! Multimodal deep learning models can combine the embeddings
    from different types of input, enabling, for example, an LLM to “see” what…
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有解决方案！多模态深度学习模型可以结合来自不同类型输入的嵌入，使得例如一个 LLM 能够“看到”什么……
