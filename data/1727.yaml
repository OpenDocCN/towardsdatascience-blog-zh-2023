- en: 'Building Better ML Systems — Chapter 2: Taming Data Chaos'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《构建更好的机器学习系统》—— 第2章：驯服数据混乱
- en: 原文：[https://towardsdatascience.com/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39?source=collection_archive---------8-----------------------#2023-05-24](https://towardsdatascience.com/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39?source=collection_archive---------8-----------------------#2023-05-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39?source=collection_archive---------8-----------------------#2023-05-24](https://towardsdatascience.com/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39?source=collection_archive---------8-----------------------#2023-05-24)
- en: '*About data-centric AI, training data, data labeling and cleaning, synthetic
    data, and a bit of Data Engineering and ETLs.*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*关于数据中心的人工智能、训练数据、数据标注和清洗、合成数据，以及一些数据工程和ETL。*'
- en: '[](https://olga-chernytska.medium.com/?source=post_page-----841d5a04b39--------------------------------)[![Olga
    Chernytska](../Images/3a1a1b5f3c92d3b86283911cd90a9259.png)](https://olga-chernytska.medium.com/?source=post_page-----841d5a04b39--------------------------------)[](https://towardsdatascience.com/?source=post_page-----841d5a04b39--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----841d5a04b39--------------------------------)
    [Olga Chernytska](https://olga-chernytska.medium.com/?source=post_page-----841d5a04b39--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://olga-chernytska.medium.com/?source=post_page-----841d5a04b39--------------------------------)[![Olga
    Chernytska](../Images/3a1a1b5f3c92d3b86283911cd90a9259.png)](https://olga-chernytska.medium.com/?source=post_page-----841d5a04b39--------------------------------)[](https://towardsdatascience.com/?source=post_page-----841d5a04b39--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----841d5a04b39--------------------------------)
    [Olga Chernytska](https://olga-chernytska.medium.com/?source=post_page-----841d5a04b39--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc932e019245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39&user=Olga+Chernytska&userId=cc932e019245&source=post_page-cc932e019245----841d5a04b39---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----841d5a04b39--------------------------------)
    ·12 min read·May 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F841d5a04b39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39&user=Olga+Chernytska&userId=cc932e019245&source=-----841d5a04b39---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc932e019245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39&user=Olga+Chernytska&userId=cc932e019245&source=post_page-cc932e019245----841d5a04b39---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----841d5a04b39--------------------------------)
    ·12分钟阅读·2023年5月24日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F841d5a04b39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39&user=Olga+Chernytska&userId=cc932e019245&source=-----841d5a04b39---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F841d5a04b39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39&source=-----841d5a04b39---------------------bookmark_footer-----------)![](../Images/c2524f7f25bf0d9e8058f1acc2c82fe5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F841d5a04b39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39&source=-----841d5a04b39---------------------bookmark_footer-----------)![](../Images/c2524f7f25bf0d9e8058f1acc2c82fe5.png)'
- en: Photo by [charlesdeluvio](https://unsplash.com/@sloppyperfectionist?utm_source=medium&utm_medium=referral%5C)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [charlesdeluvio](https://unsplash.com/@sloppyperfectionist?utm_source=medium&utm_medium=referral%5C)
    拍摄，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Building Machine Learning systems means much more than iterating through cool
    state-of-the-art algorithms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器学习系统远不仅仅是迭代酷炫的最先进算法。
- en: The research or study project ends with a demo. In the commercial project, the
    model is released to thousands, if not millions, of users who use your model in
    all imaginable and unimaginable ways and expect it to always work quickly, accurately,
    and fairly. A single incorrect prediction could cost someone their life, lead
    to losses in the millions of dollars, or seriously damage the company’s reputation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 研究或学习项目以演示结束。在商业项目中，模型会发布给成千上万，甚至是百万用户，他们以各种可想象和不可想象的方式使用你的模型，并期望其始终快速、准确、公正地工作。一旦预测错误，可能会导致人员伤亡、数百万美元的损失，或严重损害公司的声誉。
- en: 'Throughout this series, we’re discussing important topics that need to be addressed
    to build a good ML system: business value and requirements, data collection and
    labeling, model development, experiment tracking, online and offline evaluation,
    deployment, monitoring, retraining, and much much more.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个系列中，我们讨论了构建良好的机器学习系统所需解决的重要主题：商业价值和需求、数据收集和标注、模型开发、实验跟踪、在线和离线评估、部署、监控、再训练以及更多。
- en: '[In the previous chapter](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32),
    we learned that every project must start with a plan because ML systems are too
    complex to implement in an ad-hoc manner. We reviewed the ML project lifecycle,
    discussed why and how to estimate project business value, how to collect the requirements,
    and then reevaluate with a cold mind whether ML is truly needed. We learned how
    to start small and fail fast using concepts like “PoC” and “MVP”. And finally,
    we talked about the importance of design documents during the planning stage.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[在上一章](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32)中，我们了解到每个项目都必须从计划开始，因为机器学习系统过于复杂，不能随意实现。我们回顾了机器学习项目的生命周期，讨论了为什么以及如何估计项目的商业价值，如何收集需求，然后冷静地重新评估是否真的需要机器学习。我们学习了如何通过“PoC”和“MVP”等概念从小处着手，快速失败。最后，我们谈到了规划阶段设计文档的重要性。'
- en: 'And this chapter is all about data. We’ll be diving into various aspects of
    data in ML systems — data-centric AI, training data, data labeling and cleaning,
    synthetic data, and a bit of Data Engineering and ETLs. This post is the longest
    in the series, but for a good reason: most of a Data Scientist’s working time
    is devoted to data.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章完全关于数据。我们将深入探讨机器学习系统中数据的各个方面——数据中心 AI、训练数据、数据标注和清洗、合成数据，以及一些数据工程和 ETL。本帖是系列中最长的一篇，但原因正当：数据科学家的大部分工作时间都投入在数据上。
- en: So let the story begin.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让故事开始吧。
- en: Data-centric AI
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据中心 AI
- en: 'There are two ways to improve the model accuracy:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 提高模型准确性的两种方法是：
- en: Collect more data or clean your existing data, while keeping the model constant.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集更多数据或清理现有数据，同时保持模型不变。
- en: Use a more advanced algorithm or fine-tune the hyperparameters of your current
    model, while keeping the dataset constant.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用更高级的算法或调整当前模型的超参数，同时保持数据集不变。
- en: The first approach is known as data-centric, and the second one is model-centric.
    Now ML community gravitates towards data-centric AI; many researchers and practitioners
    have concluded that **improving data leads to a larger increase in model accuracy
    than improving the algorithm**. “Garbage in, garbage out”, a phrase you’ve heard
    a million times, is becoming great again.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法被称为数据中心，第二种方法是模型中心。现在机器学习社区倾向于数据中心 AI；许多研究人员和从业者已经得出结论，**改进数据比改进算法更能显著提高模型的准确性**。你听过无数次的“垃圾进，垃圾出”这一说法正在重新焕发光彩。
- en: 'Here is what Andrew Ng, the founder of DeepLearning.AI and Landing AI, says:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 DeepLearning.AI 和 Landing AI 创始人 Andrew Ng 的观点：
- en: '*“Instead of focusing on the code, companies should focus on developing systematic
    engineering practices for improving data in ways that are reliable, efficient,
    and systematic. In other words, companies need to move from a model-centric approach
    to a data-centric approach.”*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*“与其专注于代码，公司应该专注于开发系统化的工程实践，以可靠、高效、系统的方式改进数据。换句话说，公司需要从以模型为中心的方法转向以数据为中心的方法。”*'
- en: Companies that build great AI products also use a data-centric approach. Andrey
    Karpathy, the former director of AI at Tesla, shared that most of his time at
    Tesla was devoted to data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 建立优秀 AI 产品的公司也采用数据中心方法。前特斯拉 AI 总监安德烈·卡帕西（Andrey Karpathy）分享了他在特斯拉的大部分时间都投入在数据上。
- en: '![](../Images/78deba94e9ee3c4d9722ae0245275dce.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/78deba94e9ee3c4d9722ae0245275dce.png)'
- en: '*Image. Great AI companies focus more on data than algorithms.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*图片。优秀的 AI 公司更关注数据而非算法。*'
- en: 'Source: “*[*Building the Software 2.0 Stack” by Andrej Karpathy*](https://www.youtube.com/watch?v=y57wwucbXR8&ab_channel=Databricks)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：“*[*构建软件 2.0 堆栈*](https://www.youtube.com/watch?v=y57wwucbXR8&ab_channel=Databricks)*”作者：Andrej
    Karpathy*。
- en: 'Data-centric AI has become so popular that it has recently evolved into a separate
    discipline that studies techniques to improve datasets. To be on the same page
    with the ML community, I highly recommend that you take this excellent free course
    by MIT: [Introduction to Data-Centric AI](https://dcai.csail.mit.edu/).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据驱动的 AI 已经变得如此流行，以至于它最近演变成了一个研究改进数据集技术的独立学科。为了与 ML 社区保持一致，我强烈建议你参加 MIT 提供的这个优秀的免费课程：[数据驱动
    AI 介绍](https://dcai.csail.mit.edu/)。
- en: Data Pipelines
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据管道
- en: Everything is data. System-generated logs, bank transactions, website data,
    user input data, and customer data are just a few examples that your business
    may work with.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都是数据。系统生成的日志、银行交易、网站数据、用户输入数据和客户数据只是你们业务可能涉及的一些例子。
- en: Data that arrives is often chaotic, unstructured, and dirty. It comes from multiple
    data sources, which can be tricky to merge; sometimes it’s encrypted or may have
    missing snippets. Data can take the form of byte streams, text files, tables,
    images, voice and video recordings; it can be binary or human-readable.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 到达的数据通常是混乱的、无结构的和脏的。它来自多个数据源，这可能会很棘手；有时它是加密的，或者可能缺少某些片段。数据可以是字节流、文本文件、表格、图像、语音和视频录音的形式；它可以是二进制的或人类可读的。
- en: Before Data Scientists and ML Engineers can make any use of it, the data needs
    to be processed, transformed, cleaned, aggregated, and stored.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学家和机器学习工程师可以利用这些数据之前，数据需要经过处理、转换、清理、聚合和存储。
- en: '**A data pipeline is a way to organize the flow of the data.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据管道是一种组织数据流的方法。**'
- en: 'ETL (Extract-Transform-Load) is an example of a data pipeline widely used for
    data analytics and ML. Within the ETL, data is organized in the following way:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ETL（提取-转换-加载）是一个广泛用于数据分析和机器学习的数据管道示例。在 ETL 中，数据以以下方式组织：
- en: First, you determine what data you want to collect and from which sources.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，你需要确定要收集哪些数据以及从哪些来源收集。
- en: Next, you merge these data sources, transform the data to the required format,
    resolve inconsistencies, and fix errors.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，你合并这些数据源，将数据转换为所需格式，解决不一致性，并修复错误。
- en: Afterward, you design data storage and store the processed and cleaned data
    there.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 之后，你设计数据存储，并将处理和清理后的数据存储在那里。
- en: Finally, you automate the entire process to run without human intervention.
    The data pipeline should be automatically triggered periodically or once a specific
    event occurs.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，你自动化整个过程，使其无需人工干预即可运行。数据管道应周期性地或在特定事件发生时自动触发。
- en: 'To dive deeper into ETLs, check out the post [What is ETL process: Overview,
    Tools, and Best Practices](https://nix-united.com/blog/what-is-etl-process-overview-tools-and-best-practices/)
    by NIX United.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解 ETL，请查看 NIX United 的文章 [什么是 ETL 过程：概述、工具和最佳实践](https://nix-united.com/blog/what-is-etl-process-overview-tools-and-best-practices/)。
- en: '![](../Images/5d7e1f332f589ce2c0728bab1f970b0d.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d7e1f332f589ce2c0728bab1f970b0d.png)'
- en: '*Image. ETL pipeline.* [*Image by NIX United*](https://nix-united.com/blog/what-is-etl-process-overview-tools-and-best-practices/)*.*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像。ETL管道。* [*图像由 NIX United 提供*](https://nix-united.com/blog/what-is-etl-process-overview-tools-and-best-practices/)*。*'
- en: That was a high-level overview of data pipelines. This topic is much broader
    and nuanced, so more and more companies are hiring Data Engineers to work with
    data storages and pipelines, and allowing Data Scientists and Machine Learning
    Engineers to focus on data analysis and modeling.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种高层次的数据管道概述。这个话题要广泛得多，更加复杂，因此越来越多的公司正在雇用数据工程师来处理数据存储和管道，同时让数据科学家和机器学习工程师专注于数据分析和建模。
- en: If you are curious about what’s in a Data Engineer skillset, read [Modern Data
    Engineer Roadmap](https://github.com/datastacktv/data-engineer-roadmap) by datastack.tv.
    I love seeing the rise of specialized roles within the field, and I am really
    happy that Data Scientists are not expected to know everything anymore. What a
    relief!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对数据工程师的技能集感到好奇，可以阅读 [现代数据工程师路线图](https://github.com/datastacktv/data-engineer-roadmap)
    由 datastack.tv 提供。我很高兴看到这个领域内专业角色的兴起，也很高兴数据科学家不再需要了解所有的东西了。这真是太让人松了一口气！
- en: 'And one more important thing before we jump into training data and labeling:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入讨论训练数据和标签之前，还有一件重要的事情：
- en: '**If the data pipelines are set up well, your company will benefit from the
    data even without advanced Machine Learning.** So before adopting ML, companies
    usually start with reports, metrics, and basic analytics.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果数据管道设置得当，即使没有先进的机器学习，你的公司也能从数据中受益。** 所以在采用机器学习之前，公司通常会从报告、指标和基础分析开始。'
- en: Training Data
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据
- en: To train the “Cat vs Dog” classifier, you show the model a lot of cat images
    while saying “This is a cat,” and a lot of dog images while saying “This is a
    dog.” Without providing any rules or explanations, you let the model decide what
    to look at to make a prediction. Mathematically, it means that the model adjusts
    its parameters until inputs match their expected outputs for the training data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练“猫与狗”分类器，你需要向模型展示大量的猫图片，同时说“这是一只猫”，并展示大量的狗图片，同时说“这是一只狗”。不提供任何规则或解释，让模型决定如何进行预测。从数学上讲，这意味着模型调整其参数，直到输入与训练数据的预期输出匹配。
- en: '**The model builds its understanding of the world based on training data, with
    the assumption that training data represents the real world and represents it
    correctly.** That’s why the quality of the training data matters a lot.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型基于训练数据建立对世界的理解，假设训练数据代表了现实世界，并且正确地代表了它。** 这就是为什么训练数据的质量非常重要。'
- en: The “Cat vs Dog” model won’t be able to predict breeds or classify other animals
    because this information was not present in the training set.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “猫与狗”模型无法预测品种或分类其他动物，因为这些信息在训练集中不存在。
- en: If there are mistakes in the labels, and some cats are labeled as dogs and vice
    versa, the model will be confused and unable to achieve high accuracy. Non-random
    mistakes can be extremely detrimental to the model. For example, if all chihuahuas
    are labeled as cats, the model will learn to predict chihuahuas as cats.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果标签中存在错误，某些猫被标记为狗，反之亦然，模型会感到困惑，无法达到高准确率。非随机错误对模型可能极具破坏性。例如，如果所有吉娃娃都被标记为猫，模型将学习将吉娃娃预测为猫。
- en: Real-world data contains biases. For instance, [women are paid less](https://www.pewresearch.org/short-reads/2023/03/01/gender-pay-gap-facts/).
    So, if you train a model to predict the salaries of your company employees, the
    model may end up predicting lower salaries for women because that’s exactly what
    it sees within the data and assumes it should be like this.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现实世界的数据包含偏见。例如，[女性薪资更低](https://www.pewresearch.org/short-reads/2023/03/01/gender-pay-gap-facts/)。所以，如果你训练一个模型来预测公司员工的薪资，模型可能会预测女性的薪资较低，因为这正是数据中所体现的，并且模型假设应该是这样。
- en: If some classes or segments are underrepresented or absent in the training data,
    the model won’t be able to learn them well and will produce incorrect predictions.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果某些类别或分段在训练数据中表现不足或缺失，模型将无法很好地学习这些类别，并会产生不正确的预测。
- en: Training data should be Relevant, Uniform, Representative, and Comprehensive.
    The meaning of these terms is explained well in the post [What Is Training Data?
    How It’s Used in Machine Learning](https://learn.g2.com/training-data) by Amal
    Joby.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据应该是相关的、一致的、具有代表性的和全面的。这些术语的含义在Amal Joby的文章[什么是训练数据？它在机器学习中的作用](https://learn.g2.com/training-data)中解释得很好。
- en: After we all agreed that it’s extremely important to train models on high-quality
    data, let me share some practical tips.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们都一致同意在高质量数据上训练模型至关重要之后，让我分享一些实用的技巧。
- en: '**Before collecting training data, understand the business task and then frame
    it as a machine learning problem**: what should be predicted and from what input.
    Almost any business task may be represented in several ways depending on requirements
    and restrictions. While working on a Computer Vision project, I usually choose
    between object detection vs segmentation vs classification and decide on the number
    of classes.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**在收集训练数据之前，了解业务任务，然后将其框定为机器学习问题**：应预测什么，以及从什么输入中预测。几乎任何业务任务都可以根据要求和限制以不同方式表示。在进行计算机视觉项目时，我通常在目标检测、分割和分类之间进行选择，并决定类别数量。'
- en: '**Training data must be very similar to the data your model will ‘see’ in production.**
    Theoretically, models can generalize to unseen data, but in practice, this generalization
    ability is quite limited. For example, if you train a computer vision model for
    an indoor environment, it won’t work well outdoors. Similarly, a sentiment model
    trained on tweets won’t be effective for analyzing classic literature text snippets.
    I’ve personally experienced cases where a computer vision model struggled to generalize
    even with narrower gaps, such as slight changes in lighting, skin tones, weather
    conditions, and compression methods. To overcome differences between the training
    and production data, a popular approach is to use the most recent data from production
    as the training dataset.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练数据必须与模型在生产中‘看到’的数据非常相似。** 从理论上讲，模型可以推广到未见过的数据，但在实践中，这种推广能力是相当有限的。例如，如果你为室内环境训练一个计算机视觉模型，它在户外效果会很差。类似地，在推特上训练的情感模型对于分析经典文学文本片段也不会有效。我个人经历过计算机视觉模型在面对较小的差异时，如光照、肤色、天气条件和压缩方法的微小变化，难以推广的情况。为了克服训练数据和生产数据之间的差异，一种流行的方法是使用生产中的最新数据作为训练数据集。'
- en: '![](../Images/bf9d7689fbb5016855ffa7c30775bc89.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf9d7689fbb5016855ffa7c30775bc89.png)'
- en: '*Image. Example of mismatch between train and production (test) data. Source:*
    [*Google Research Blog*](https://ai.googleblog.com/2020/10/estimating-impact-of-training-data-with.html)*.*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像。训练数据和生产（测试）数据之间的不匹配示例。来源：* [*Google Research Blog*](https://ai.googleblog.com/2020/10/estimating-impact-of-training-data-with.html)*。*'
- en: '**A small, clean dataset is better than a large but dirty one.** For most projects,
    data annotation is a bottleneck. Data labeling is an extremely complicated, slow,
    and expensive process (the next section will be devoted to that). Having a huge,
    clean dataset is a luxury that only gigantic tech companies can afford. All others
    have to choose between size and quality, and you should always opt for quality,
    **especially** for the datasets on which you evaluate your models.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个小而干净的数据集比一个大但脏的数据集更好。** 对于大多数项目而言，数据标注是一个瓶颈。数据标注是一个极其复杂、缓慢且昂贵的过程（下一部分将专门讨论）。拥有一个巨大的干净数据集是只有庞大的科技公司才能负担得起的奢侈品。其他所有公司都必须在规模和质量之间做出选择，你应该始终选择质量，**特别是**对于用于评估模型的数据集。'
- en: '**No one can really tell how much data is needed.** It depends on the complexity
    of the predicted real-world phenomenon, variability in the training data, and
    the required model accuracy. The only way to find this out is by trial and error.
    And because of that…'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有人能真正确定需要多少数据。** 这取决于预测的现实世界现象的复杂性、训练数据的变异性以及所需的模型准确性。找到这个答案的唯一方法是通过反复试验。因此……'
- en: '**Acquire data in chunks.** Start with a small dataset, label it, train a model,
    check the accuracy, analyze errors, and plan the next data collection and labeling
    iteration.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**分块获取数据。** 从一个小数据集开始，标注它，训练一个模型，检查准确性，分析错误，并计划下一轮的数据收集和标注。'
- en: '**Training data is not static.** As you recall from the [previous chapter](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32),
    you are going to train and retrain the model a lot of times during the research
    phase and when the model is already in production. With each new iteration and
    model update, a new training dataset is needed. No rest for the wicked, remember?
    :)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练数据不是静态的。** 正如你从[前一章](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32)中回忆的那样，你将在研究阶段和模型已投入生产时多次训练和重新训练模型。每次新的迭代和模型更新时，都需要一个新的训练数据集。没有休息的机会，记住了吗？
    :)'
- en: Data Labeling
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据标注
- en: Most ML models in production today are supervised. This means that labeled data
    is required for training and evaluating the model. Even in the case of unsupervised
    learning, where the model learns patterns and structures from unlabeled data,
    labeled data is still needed to evaluate the model’s accuracy; otherwise, how
    else would you know that it’s good enough for production?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，大多数生产中的机器学习模型是监督学习。这意味着需要标注数据来训练和评估模型。即使在无监督学习的情况下，模型从未标注的数据中学习模式和结构，仍然需要标注数据来评估模型的准确性；否则，你怎么知道它是否足够好以用于生产？
- en: '**There are two types of labels: human labels and natural labels.**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**标签有两种类型：人工标签和自然标签。**'
- en: Some machine learning tasks are about predicting the future. Examples are predictions
    of stock prices, customer churn, time of arrival, fraudulent transactions, and
    recommendations. Once the future has come, we know the true label. These labels
    are referred to as natural labels, and we only need to collect them when they
    arrive.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器学习任务涉及预测未来。例如，预测股票价格、客户流失、到达时间、欺诈交易和推荐。一旦未来到来，我们就知道真实的标签。这些标签被称为自然标签，我们只需在它们到来时进行收集。
- en: In Computer Vision and NLP, we don’t predict the future, instead, we classify,
    analyze, and retrieve information from images and texts. That’s why we cannot
    obtain natural labels and must heavily rely on human labels.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉和自然语言处理（NLP）中，我们不是预测未来，而是对图像和文本进行分类、分析和检索信息。这就是为什么我们无法获得自然标签，必须严重依赖人工标签。
- en: '**Human data labeling is an extremely complicated, slow, and expensive process.**
    Don’t think of it as a task within a Machine Learning project; it is better to
    approach it as a separate Data Annotation project, with its own scope, budget,
    timeline, team, tools, and KPIs.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工数据标注是一个极其复杂、缓慢且昂贵的过程。** 不要把它当作机器学习项目中的一个任务来考虑；最好将其视为一个独立的数据注释项目，具有自己的范围、预算、时间线、团队、工具和关键绩效指标（KPI）。'
- en: '![](../Images/d9201dd2d272975fd15d308c9f288564.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9201dd2d272975fd15d308c9f288564.png)'
- en: '*Image. Stages of Data Annotation Projects. Source:* [*Best Practices for Managing
    Data Annotation Projects*](https://arxiv.org/abs/2009.11654)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像。数据注释项目的阶段。来源：* [*管理数据注释项目的最佳实践*](https://arxiv.org/abs/2009.11654)'
- en: If you work closely with data annotation, I recommend you to check the 30-page
    report on [Best Practices for Managing Data Annotation Projects](https://arxiv.org/abs/2009.11654)
    by Tina Tseng et al. For a shorter version accompanied by my own insights, continue
    reading this post.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你与数据注释紧密合作，我推荐你查看Tina Tseng等人关于[数据注释项目管理最佳实践](https://arxiv.org/abs/2009.11654)的30页报告。对于较短版本和我自己的见解，请继续阅读这篇文章。
- en: '**The first thing to decide on is: Who is going to label the data?** There
    are three options to consider: crowd, vendor, and in-house labeling team. I remember
    the excitement around crowdsourcing tools like [Amazon Mechanical Turk](https://www.mturk.com/)
    about five years ago. However, it quickly turned out that crowdsourcing labeling
    is only suitable for very simple tasks that require minimal to no workforce training.
    As a result, most companies choose between vendors and in-house labeling teams.
    Startups usually lean towards vendors as it offers a simpler starting point, while
    large AI companies build their own labeling teams to have control over the process
    and achieve higher annotation quality. As an example, [Tesla has 1,000 full-time
    employees within its manual data labeling team](https://techcrunch.com/2021/08/19/top-five-highlights-of-elon-musks-tesla-ai-day/#:~:text=The%20company%20flexed%20its%20over%201%2C000%2Dperson%20manual%20data%20labeling%20team%20and%20walked%20the%20audience%20through%20how%20Tesla%20auto%2Dlabels%20certain%20clips).
    Just saying.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**首先要决定的是：谁来标注数据？** 需要考虑三个选项：众包、供应商和内部标注团队。我记得大约五年前，围绕像[亚马逊机械土耳其](https://www.mturk.com/)这样的众包工具的兴奋。然而，很快发现众包标注只适用于需要最少或不需要员工培训的非常简单的任务。因此，大多数公司在供应商和内部标注团队之间进行选择。初创公司通常倾向于选择供应商，因为这提供了一个更简单的起点，而大型AI公司则建立自己的标注团队，以控制过程并实现更高的标注质量。举例来说，[特斯拉有1000名全职员工在其人工数据标注团队中](https://techcrunch.com/2021/08/19/top-five-highlights-of-elon-musks-tesla-ai-day/#:~:text=The%20company%20flexed%20its%20over%201%2C000%2Dperson%20manual%20data%20labeling%20team%20and%20walked%20the%20audience%20through%20how%20Tesla%20auto%2Dlabels%20certain%20clips)。仅仅是个例子。'
- en: '**Create guidelines and train annotators based on them.** Guidelines are documents
    that provide explanations and visuals of what should be labeled and how. Guidelines
    are then transformed into training materials that annotators must complete before
    undertaking actual labeling tasks. If you work with vendors, make sure their workforce
    training process is set well.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建指导方针并根据它们培训标注者。** 指导方针是提供应标注内容及其方式的解释和视觉示例的文件。然后，将指导方针转化为标注者在进行实际标注任务之前必须完成的培训材料。如果你与供应商合作，请确保他们的员工培训过程设置得当。'
- en: Real-world data is ambiguous and confusing, so allow annotators to say, “I do
    not know how to label this sample.” Then, collect these confusing samples and
    use them to improve the guidelines.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的数据是模糊和混乱的，因此允许标注者说：“我不知道如何标注这个样本。” 然后，收集这些混淆样本，并用它们来改进指导方针。
- en: '**The annotation tool matters**. Annotators are typically paid hourly rates,
    so helping them label faster and more accurately will save you a lot of money.
    On a large scale, it’s especially noticeable whether the annotator labels 100
    samples per hour versus 300\. So choose wisely, and pay attention to the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**标注工具很重要**。标注员通常按小时计费，因此帮助他们更快、更准确地标注会节省你很多钱。在大规模上，标注员每小时标注100个样本与300个样本的差别尤其明显。所以明智选择，并关注以下几点：'
- en: How much time it takes to label a single sample. Some tools were specifically
    developed for NLP tasks; completely different tools are used for 2D or 3D Computer
    Vision.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注单个样本所需的时间。一些工具专门为NLP任务开发；完全不同的工具用于2D或3D计算机视觉。
- en: Whether AI-powered labeling is supported. It is something you want to use. The
    tool may predict segmentation masks with a single user click on an object or allow
    you to deploy your own models to assist the labeling process.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否支持AI驱动的标注。这是你想要使用的功能。该工具可能通过用户点击对象来预测分割掩码，或者允许你部署自己的模型来协助标注过程。
- en: How well it fits your infrastructure. The annotation tool will be integrated
    into the data pipeline. Once data arrives, it is automatically sampled and sent
    to the annotators. They label the data, and labels are automatically stored in
    the database. Some tools may fit your infrastructure better than others, consider
    that.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它与您的基础设施的契合程度。标注工具将集成到数据管道中。一旦数据到达，它会自动采样并发送给标注员。他们标注数据，标签会自动存储在数据库中。一些工具可能比其他工具更适合你的基础设施，考虑一下这一点。
- en: The list of [open-source annotation tools is here](https://github.com/fuzzylabs/awesome-open-mlops#data-annotation),
    and [here is a nice comparison](https://www.v7labs.com/blog/best-image-annotation-tools)
    of some free and paid tools.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[开源标注工具列表在这里](https://github.com/fuzzylabs/awesome-open-mlops#data-annotation)，[这里有一个不错的比较](https://www.v7labs.com/blog/best-image-annotation-tools)介绍了一些免费的和付费的工具。'
- en: '**Estimate the costs and timelines.** You’ll be surprised how slow and expensive
    data labeling can be (I was). Therefore, it’s better to be prepared (and prepare
    your manager in advance).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**估算成本和时间线。** 你会惊讶于数据标注的缓慢和昂贵（我就是）。因此，最好做好准备（并提前准备你的经理）。'
- en: 'Here are the formulas to roughly estimate costs and time:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是大致估算成本和时间的公式：
- en: Labeling Time (in man-hours) = Time to label a sample (in hours) * Dataset size
    (in samples) + Time reserved for training and error correction (in man-hours)
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标注时间（工时）= 标注一个样本的时间（小时） * 数据集大小（样本数量） + 预留的训练和错误修正时间（工时）
- en: Labeling Time (in working days) = Labeling Time (in man-hours) / Number of employees
    / 8 hours
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标注时间（工作天数）= 标注时间（工时） / 员工人数 / 8小时
- en: Costs ($) = Annotator’s hourly rate ($) * Labeling Time (in man-hours)
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 成本（$）= 标注员的小时费率（$） * 标注时间（工时）
- en: '**No matter how hard you try, data labels will inevitably be dirty.** Humans
    make mistakes, they may become distracted, or misunderstand the task. Therefore,
    checking the quality of the labels is a must. And, of course, the algorithm or
    tool you select for this task must also be integrated into the data pipeline.
    I won’t stop repeating that: everything must be automatic.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**无论你多么努力，数据标签不可避免地会出现错误。** 人类会犯错，他们可能会分心或误解任务。因此，检查标签的质量是必需的。当然，你为此选择的算法或工具也必须集成到数据管道中。我会一再强调：一切必须自动化。'
- en: One such tool is [Cleanlab](https://github.com/cleanlab/cleanlab). It was developed
    by MIT graduates and has recently gained great popularity. Cleanlab improves labels
    for images, text, and tabular data using statistical methods and machine learning
    algorithms (for examples of what it can do, check out the [Cleanlab blog](https://cleanlab.ai/blog/)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一个这样的工具是[Cleanlab](https://github.com/cleanlab/cleanlab)。它由麻省理工学院毕业生开发，最近获得了很大的人气。Cleanlab使用统计方法和机器学习算法改进图像、文本和表格数据的标签（有关它能做什么的示例，请查看[Cleanlab博客](https://cleanlab.ai/blog/)）。
- en: 'As a final note on data annotation, I recommend this insightful post by Synced
    — [Data Annotation: The Billion Dollar Business Behind AI Breakthroughs](https://medium.com/syncedreview/data-annotation-the-billion-dollar-business-behind-ai-breakthroughs-d929b0a50d23).
    The title is self-explanatory, and the article is certainly worth a read.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据标注的最后一点，我推荐这篇Synced的深刻文章——[数据标注：AI突破背后的十亿美元生意](https://medium.com/syncedreview/data-annotation-the-billion-dollar-business-behind-ai-breakthroughs-d929b0a50d23)。标题已经很自解释了，文章确实值得一读。
- en: Synthetic Data
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据
- en: Take all the aforementioned challenges with data labeling, add data privacy
    issues and severe [class imbalance](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)
    in real-world data, and you’ll have the reason why synthetic data is becoming
    increasingly popular.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有上述数据标注的挑战，添加数据隐私问题以及现实世界数据中的严重[类别不平衡](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)，你就会明白为什么合成数据变得越来越受欢迎。
- en: Synthetic data is typically generated using some combination of gaming engines,
    generative adversarial networks, and perhaps a touch of magic. In the self-driving
    car industry, synthetic data has already become essential. Check out what [NVIDIA](https://www.youtube.com/watch?v=gPaFgNEF82Q&ab_channel=NVIDIA)
    and [Tesla](https://youtu.be/j0z4FweCy4M?t=5724) are already doing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据通常是使用一些游戏引擎、生成对抗网络的组合，或许再加上一点魔法来生成的。在自动驾驶汽车行业中，合成数据已经变得至关重要。查看一下[NVIDIA](https://www.youtube.com/watch?v=gPaFgNEF82Q&ab_channel=NVIDIA)和[Tesla](https://youtu.be/j0z4FweCy4M?t=5724)已经在做的事情。
- en: Once synthetic data generation is set, one can obtain large diverse datasets
    with extremely accurate labels relatively quickly and inexpensively. Even if the
    synthetic data doesn’t look perfect, it can still be useful for model pre-training.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦合成数据生成设置好，就可以相对快速且经济地获得大量多样化的数据集，并且具有极高的标签准确性。即使合成数据看起来不完美，它仍然可以用于模型的预训练。
- en: 'If you’re interested in expanding your knowledge on this topic, here is a great
    resource: [What Is Synthetic Data?](https://blogs.nvidia.com/blog/2021/06/08/what-is-synthetic-data/)
    by NVIDIA.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对扩展这一主题的知识感兴趣，这里有一个很好的资源：[什么是合成数据？](https://blogs.nvidia.com/blog/2021/06/08/what-is-synthetic-data/)
    由NVIDIA提供。
- en: Conclusion
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this chapter, we discussed a new trend in the industry — data-centric AI,
    an approach to building ML systems that considers clean data to be much more important
    than advanced ML algorithms. We touched on data pipelines, which are designed
    to organize the flow of chaotic and unstructured data so the data can be used
    for analytics. We learned that training data should be relevant, uniform, representative,
    and comprehensive, as models build their understanding of the world based on this
    data. We reviewed two types of labels — human and natural — and navigated through
    the complex, slow, and expensive process of obtaining human labels, and discussed
    best practices to make this process less painful. Lastly, we talked about an alternative
    to real data and human labeling: synthetic data.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们讨论了行业中的新趋势——以数据为中心的人工智能，这是一种构建机器学习系统的方法，认为干净的数据比先进的机器学习算法更重要。我们涉及了数据管道，旨在组织混乱和非结构化的数据流，以便这些数据可以用于分析。我们了解到，训练数据应该是相关的、均匀的、具有代表性的和全面的，因为模型是基于这些数据建立对世界的理解的。我们回顾了两种类型的标签——人工标签和自然标签——并讨论了获取人工标签的复杂、缓慢且昂贵的过程，以及使这一过程不那么痛苦的最佳实践。最后，我们讨论了真实数据和人工标注的替代方案：合成数据。
- en: In the next posts, you will learn about model development, experiment tracking,
    online and offline evaluation, deployment, monitoring, retraining, and much much
    more — all this will help you build better Machine Learning systems.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的帖子中，你将学习到模型开发、实验跟踪、在线和离线评估、部署、监控、再训练等多个方面——这些都将帮助你构建更好的机器学习系统。
- en: 'The next chapter is already available:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章已经可以阅读：
- en: '[](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----841d5a04b39--------------------------------)
    [## Building Better ML Systems — Chapter 3: Modeling. Let the fun begin'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 构建更好的机器学习系统 — 第3章：建模。让乐趣开始](https://towardsdatascience.com/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----841d5a04b39--------------------------------)'
- en: About baselines, experiment tracking, proper test sets, and metrics. About making
    the algorithm work.
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于基准、实验跟踪、适当的测试集和指标。关于让算法发挥作用。
- en: towardsdatascience.com](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----841d5a04b39--------------------------------)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=post_page-----841d5a04b39--------------------------------)'
