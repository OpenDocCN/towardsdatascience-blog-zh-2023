- en: MLOps-Tips and Tricks-75 Code Snippets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps-技巧与窍门-75个代码片段
- en: 原文：[https://towardsdatascience.com/mlops-tips-and-tricks-75-code-snippets-b8f04036d0a0?source=collection_archive---------1-----------------------#2023-03-15](https://towardsdatascience.com/mlops-tips-and-tricks-75-code-snippets-b8f04036d0a0?source=collection_archive---------1-----------------------#2023-03-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mlops-tips-and-tricks-75-code-snippets-b8f04036d0a0?source=collection_archive---------1-----------------------#2023-03-15](https://towardsdatascience.com/mlops-tips-and-tricks-75-code-snippets-b8f04036d0a0?source=collection_archive---------1-----------------------#2023-03-15)
- en: '![](../Images/94790342f00b33d9454657818e9ff29e.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94790342f00b33d9454657818e9ff29e.png)'
- en: Photo by [Aswathy N](https://unsplash.com/@abnair?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影：[Aswathy N](https://unsplash.com/@abnair?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: MLOps and Data Engineering
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps 和数据工程
- en: '[](https://esenthil.medium.com/?source=post_page-----b8f04036d0a0--------------------------------)[![Senthil
    E](../Images/8750e1769db1d2fe3a3f739e95c60e4b.png)](https://esenthil.medium.com/?source=post_page-----b8f04036d0a0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b8f04036d0a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b8f04036d0a0--------------------------------)
    [Senthil E](https://esenthil.medium.com/?source=post_page-----b8f04036d0a0--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://esenthil.medium.com/?source=post_page-----b8f04036d0a0--------------------------------)[![Senthil
    E](../Images/8750e1769db1d2fe3a3f739e95c60e4b.png)](https://esenthil.medium.com/?source=post_page-----b8f04036d0a0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b8f04036d0a0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b8f04036d0a0--------------------------------)
    [Senthil E](https://esenthil.medium.com/?source=post_page-----b8f04036d0a0--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d8fcdc16d73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-tips-and-tricks-75-code-snippets-b8f04036d0a0&user=Senthil+E&userId=1d8fcdc16d73&source=post_page-1d8fcdc16d73----b8f04036d0a0---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b8f04036d0a0--------------------------------)
    ·21 min read·Mar 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb8f04036d0a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-tips-and-tricks-75-code-snippets-b8f04036d0a0&user=Senthil+E&userId=1d8fcdc16d73&source=-----b8f04036d0a0---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d8fcdc16d73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-tips-and-tricks-75-code-snippets-b8f04036d0a0&user=Senthil+E&userId=1d8fcdc16d73&source=post_page-1d8fcdc16d73----b8f04036d0a0---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b8f04036d0a0--------------------------------)
    ·21 min read·2023年3月15日'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb8f04036d0a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-tips-and-tricks-75-code-snippets-b8f04036d0a0&source=-----b8f04036d0a0---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb8f04036d0a0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-tips-and-tricks-75-code-snippets-b8f04036d0a0&source=-----b8f04036d0a0---------------------bookmark_footer-----------)'
- en: 'Introduction:'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍：
- en: MLOps, or Machine Learning Operations, refers to the set of practices that streamline
    the development, deployment, and maintenance of machine learning models, bridging
    the gap between data science and software engineering. This article aims to provide
    valuable tips and tricks for MLOps and data engineering, covering a wide range
    of topics such as model training, data preprocessing, performance optimization,
    monitoring, and deployment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps，或称机器学习运维，是指一套简化机器学习模型开发、部署和维护的实践方法，旨在弥合数据科学与软件工程之间的差距。本文旨在提供有关MLOps和数据工程的宝贵技巧和窍门，涵盖模型训练、数据预处理、性能优化、监控和部署等广泛主题。
- en: '![](../Images/f99a09454277747208c1135f4f67fdcb.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f99a09454277747208c1135f4f67fdcb.png)'
- en: Image by the Author
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图片
- en: '**Dask-ML-Parallelize model training:**'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Dask-ML-并行化模型训练：**'
- en: Use Dask-ML to train and evaluate your machine-learning models in parallel,
    leveraging the full power of your hardware.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Dask-ML并行训练和评估机器学习模型，充分利用硬件的全部能力。
- en: With Dask-ML, you can quickly scale your machine learning workloads across multiple
    cores, processors, or even clusters, making it easy to train and evaluate large
    models on large datasets.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Dask-ML，您可以迅速扩展机器学习工作负载，跨多个核心、处理器甚至集群，轻松训练和评估大型数据集上的大型模型。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[Check for more information.](https://ml.dask.org/)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://ml.dask.org/)'
- en: '**2\. Feature Tools:** Featuretools is an open-source Python library for automated
    feature engineering, allowing you to generate new features from your raw data
    with minimal manual effort.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. Feature Tools：** Featuretools是一个开源Python库，用于自动化特征工程，允许您从原始数据中生成新特征，手动工作量最小化。'
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[For more information please check.](https://www.featuretools.com/)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://www.featuretools.com/)'
- en: '**3\. Tensorboard:** TensorBoard is a powerful visualization tool for TensorFlow
    that allows you to monitor your model’s performance and track various metrics
    during training and evaluation.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. Tensorboard：** TensorBoard是一个强大的可视化工具，用于TensorFlow，允许您监控模型的性能并跟踪训练和评估过程中的各种指标。'
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[For more information please check.](https://www.tensorflow.org/tensorboard)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://www.tensorflow.org/tensorboard)'
- en: '**4\. Tensorflow Serving:**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. Tensorflow Serving：**'
- en: TensorFlow Serving is a high-performance serving system for machine learning
    models, designed for production environments.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Serving是一个高性能的机器学习模型服务系统，专为生产环境设计。
- en: TensorFlow Serving supports multiple models, model versioning, and automatic
    loading and unloading of models, making it easy to manage and serve your machine
    learning models at scale.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Serving支持多个模型、模型版本控制，以及模型的自动加载和卸载，使您能够轻松管理和大规模服务机器学习模型。
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[For more information please check.](https://www.tensorflow.org/tfx/guide/serving)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://www.tensorflow.org/tfx/guide/serving)'
- en: '**5\. Automate hyperparameter tuning with Optuna:** Optuna is a powerful and
    flexible optimization library that can automatically explore and optimize hyperparameters
    for your machine-learning models.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 使用Optuna自动化超参数调优：** Optuna是一个强大且灵活的优化库，可以自动探索和优化机器学习模型的超参数。'
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[For more information please check.](https://optuna.org/)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://optuna.org/)'
- en: '**6\. SHAP:** Use SHAP (SHapley Additive exPlanations) to explain the output
    of your machine learning models and gain insights into their behavior.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\. SHAP：** 使用SHAP（SHapley Additive exPlanations）来解释机器学习模型的输出，并深入了解其行为。'
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[For more information please check.](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html)'
- en: '**7\. Ray:** Ray Tune is a powerful and flexible library for distributed hyperparameter
    tuning, allowing you to leverage the full power of your hardware to optimize your
    machine learning models.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**7\. Ray：** Ray Tune是一个强大且灵活的分布式超参数调优库，使您能够利用硬件的全部能力来优化机器学习模型。'
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[For more information please check.](https://www.ray.io/)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://www.ray.io/)'
- en: '**8\. Experiment tracking with MLflow:** MLflow, you can compare different
    runs, reproduce previous results, and share your work with others, making collaboration
    and iteration more efficient.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**8\. 使用MLflow进行实验跟踪：** 使用MLflow，您可以比较不同的实验，重现以前的结果，并与他人共享您的工作，使协作和迭代更加高效。'
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[For more information please check.](https://mlflow.org/)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://mlflow.org/)'
- en: '**9\. Scikit-learn:** Pipeline: Use Scikit-learn `**Pipeline**` to chain multiple
    preprocessing steps and a final estimator.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**9\. Scikit-learn：** 流水线：使用Scikit-learn的`**Pipeline**`将多个预处理步骤和最终估算器链接在一起。'
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**10\. Scikit-learn:** Grid search: Use `GridSearchCV` to perform hyperparameter
    tuning.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**10\. Scikit-learn：** 网格搜索：使用`GridSearchCV`进行超参数调优。'
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**11\. Joblib:**`joblib` is a popular library for saving and loading Scikit-learn
    models. Use `dump()` to save a model to a file, and `load()` to restore the model
    from the file.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**11\. Joblib：** `joblib`是一个流行的库，用于保存和加载Scikit-learn模型。使用`dump()`将模型保存到文件中，使用`load()`从文件中恢复模型。'
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**12\. Tensorflow:** Simple neural network. Use the Keras API to define a simple
    feedforward neural network with dense (fully connected) layers.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**12\. Tensorflow：** 简单神经网络。使用Keras API定义一个具有密集（全连接）层的简单前馈神经网络。'
- en: '[PRE11]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**13\. Early Stopping**: Code snippet for early stopping'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**13\. 提前停止：** 提前停止的代码片段'
- en: '[PRE12]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**14\. Tensorflow Model-Save and Load:** Use the `save()` method to save the
    model architecture, weights, and optimizer state to a single file. Use `load_model()`
    to restore the saved model from the file.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**14. Tensorflow 模型保存和加载：** 使用`save()`方法将模型结构、权重和优化器状态保存到单个文件中。使用`load_model()`从文件中恢复保存的模型。'
- en: '[PRE13]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**15\. Dask:** Parallelize operations: Use Dask to parallelize operations on
    large datasets.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**15. Dask：** 并行化操作：使用 Dask 对大型数据集进行并行化操作。'
- en: '[PRE14]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '16\. **TPOT: Automated machine learning:** TPOT (Tree-based Pipeline Optimization
    Tool) is a genetic algorithm-based automated machine learning library. Use `TPOTClassifier`
    or `TPOTRegressor` to optimize a machine learning pipeline for your data.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 16. **TPOT：自动化机器学习：** TPOT (基于树的管道优化工具) 是一个基于遗传算法的自动化机器学习库。使用`TPOTClassifier`或`TPOTRegressor`来优化你的数据的机器学习管道。
- en: '[PRE15]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[For more information please check.](http://automl.info/tpot/)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[更多信息请查看。](http://automl.info/tpot/)'
- en: '![](../Images/06a298b5527402f76502fee4aee02988.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06a298b5527402f76502fee4aee02988.png)'
- en: Image by the Author
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**17\. Category Encoders:** Category Encoders is a library that provides various
    encoding methods for categorical variables, such as target encoding, one-hot encoding,
    and ordinal encoding.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**17. 类别编码器：** 类别编码器是一个提供各种类别变量编码方法的库，如目标编码、独热编码和序数编码。'
- en: '[PRE16]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**18\. Imbalanced-learn:** is a library that provides various techniques for
    handling imbalanced datasets, such as oversampling, undersampling, and combination
    methods. Use the appropriate resampling technique, such as SMOTE, to balance your
    dataset before training your model.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**18. Imbalanced-learn：** 是一个提供各种处理不平衡数据集技术的库，如过采样、欠采样和组合方法。使用适当的重采样技术，如 SMOTE，在训练模型之前平衡你的数据集。'
- en: '[PRE17]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[For more information please check.](https://imbalanced-learn.org/stable/)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[更多信息请查看。](https://imbalanced-learn.org/stable/)'
- en: '**19\. Auto-sklearn**: is an automated machine learning library that wraps
    Scikit-learn, providing the automated model and preprocessing selection. Use `AutoSklearnClassifier`
    or `AutoSklearnRegressor` to optimize a machine learning pipeline data.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**19. Auto-sklearn：** 是一个自动化机器学习库，它封装了 Scikit-learn，提供自动化模型和预处理选择。使用`AutoSklearnClassifier`或`AutoSklearnRegressor`来优化机器学习管道数据。'
- en: '[PRE18]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**20\. Scikit-learn: Column Transformer:** ColumnTransformer allows you to
    apply different preprocessing steps to different columns of your input data, which
    is particularly useful when dealing with mixed data types.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**20. Scikit-learn：列变换器：** ColumnTransformer 允许你对输入数据的不同列应用不同的预处理步骤，这在处理混合数据类型时特别有用。'
- en: '[PRE19]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 2**1\. RandomizedSearchCV** is an alternative to GridSearchCV that searches
    the parameter space more efficiently by randomly sampling a fixed number of parameter
    settings. Define a parameter distribution as a dictionary, where the keys are
    the parameter names (including the step name if using a pipeline) and the values
    are distributions from which to sample parameter values. Pass the model (or pipeline)
    and parameter distribution to RandomizedSearchCV and fit the data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 2**1. RandomizedSearchCV** 是 GridSearchCV 的一种替代方法，通过随机抽样固定数量的参数设置来更有效地搜索参数空间。定义一个参数分布字典，其中键是参数名称（包括使用管道时的步骤名称），值是用于抽样参数值的分布。将模型（或管道）和参数分布传递给
    RandomizedSearchCV 并拟合数据。
- en: '[PRE20]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**22\. TensorFlow Data Validation**: Use TensorFlow Data Validation (TFDV)
    to validate and explore your data.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**22. TensorFlow 数据验证：** 使用 TensorFlow Data Validation (TFDV) 来验证和探索你的数据。'
- en: '[PRE21]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**23\. TensorFlow Model Analysis**: Use TensorFlow Model Analysis (TFMA) to
    evaluate your TensorFlow models.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**23. TensorFlow 模型分析：** 使用 TensorFlow Model Analysis (TFMA) 来评估你的 TensorFlow
    模型。'
- en: '[PRE22]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '**24\. TensorFlow Transform:** Use TensorFlow Transform (TFT) to preprocess
    your data for TensorFlow models.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**24. TensorFlow Transform：** 使用 TensorFlow Transform (TFT) 来预处理你的数据，以便用于 TensorFlow
    模型。'
- en: '[PRE23]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '**25\. TensorFlow Extended (TFX)**: Use TensorFlow Extended (TFX) to create
    end-to-end machine learning pipelines.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**25. TensorFlow Extended (TFX)：** 使用 TensorFlow Extended (TFX) 创建端到端的机器学习管道。'
- en: '[PRE24]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/20224b9045d7dc616fa88863bea7c21a.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20224b9045d7dc616fa88863bea7c21a.png)'
- en: Image by the Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**26\. CuPy:** CuPy is a library that provides a NumPy-like interface for GPU-accelerated
    computing. Use CuPy arrays, which have a similar interface to NumPy arrays, to
    perform computations on GPU. Many common NumPy functions are available in CuPy,
    allowing you to perform GPU-accelerated computations with familiar syntax.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**26. CuPy：** CuPy 是一个提供类似于 NumPy 接口的 GPU 加速计算库。使用 CuPy 数组，它们具有类似于 NumPy 数组的接口，在
    GPU 上执行计算。CuPy 提供了许多常见的 NumPy 函数，使你能够使用熟悉的语法进行 GPU 加速计算。'
- en: '[PRE25]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '**27\. RAPIDS** is a suite of GPU-accelerated libraries for data science, including
    cuDF (GPU-accelerated DataFrame library similar to Pandas) and cuML (GPU-accelerated
    machine learning library similar to Scikit-learn). Use cuDF DataFrames to perform
    data manipulation tasks on GPU, and cuML models to train and evaluate machine
    learning models on GPU.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**27\. RAPIDS**是一个用于数据科学的GPU加速库套件，包括cuDF（类似于Pandas的GPU加速数据框库）和cuML（类似于Scikit-learn的GPU加速机器学习库）。使用cuDF
    DataFrames在GPU上执行数据操作任务，使用cuML模型在GPU上训练和评估机器学习模型。'
- en: '[PRE26]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '**28\. FastAPI** is a modern, high-performance web framework for building APIs
    with Python, particularly suitable for machine learning models.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**28\. FastAPI**是一个现代化的高性能Web框架，用于使用Python构建API，特别适合机器学习模型。'
- en: Create an instance of `FastAPI`, and define API endpoints using decorators,
    such as `@app.post()`.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建`FastAPI`的实例，并使用装饰器（如`@app.post()`）定义API端点。
- en: Use `uvicorn` to run your FastAPI application, specifying the host and port.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`uvicorn`运行FastAPI应用，指定主机和端口。
- en: '[PRE27]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '**29\. Streamlit** is a library for quickly creating interactive web applications
    for machine learning and data science, using only Python.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**29\. Streamlit**是一个库，用于快速创建机器学习和数据科学的互动Web应用，仅使用Python。'
- en: Use Streamlit’s simple API to create user interface elements, such as text inputs
    and sliders, and display output or visualizations.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Streamlit的简单API创建用户界面元素，例如文本输入和滑块，并显示输出或可视化。
- en: Run the Streamlit app using the command `streamlit run app.py` in your terminal.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用命令`streamlit run app.py`在终端中运行Streamlit应用。
- en: '[PRE28]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[For more information please check.](https://streamlit.io/)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[有关更多信息，请查看。](https://streamlit.io/)'
- en: '**30\. Docker File:** Create a Dockerfile to define a custom Docker image for
    your machine learning application.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**30\. Docker文件：** 创建一个Dockerfile来定义适用于机器学习应用的自定义Docker镜像。'
- en: '[PRE29]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Use the `FROM` keyword to specify the base image, such as the official Python
    image.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`FROM`关键字指定基础镜像，例如官方Python镜像。
- en: Use the `WORKDIR` keyword to set the working directory for subsequent instructions.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`WORKDIR`关键字设置后续指令的工作目录。
- en: Use the `COPY` keyword to copy files and directories from the host system to
    the image.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`COPY`关键字将文件和目录从主机系统复制到镜像中。
- en: Use the `RUN` keyword to execute commands during the build process, such as
    installing dependencies.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`RUN`关键字在构建过程中执行命令，例如安装依赖项。
- en: Use the `CMD` keyword to define the default command to run when the container
    starts.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`CMD`关键字定义容器启动时要运行的默认命令。
- en: '**31\. Build a docker image:**'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**31\. 构建Docker镜像：**'
- en: '[PRE30]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '**32\. Run a docker container**: Use the `docker run` command to create and
    start a Docker container from an image. Use the `-p` flag to map a host port to
    a container port, allowing external access to services running inside the container.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**32\. 运行Docker容器**：使用`docker run`命令从镜像创建并启动Docker容器。使用`-p`标志将主机端口映射到容器端口，允许外部访问容器内运行的服务。'
- en: '[PRE31]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '**32\. Kubernetes YAML Config File:**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**32\. Kubernetes YAML配置文件：**'
- en: '[PRE32]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Use `apiVersion`, `kind`, and `metadata` to define the Kubernetes resource type
    and metadata.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`apiVersion`、`kind`和`metadata`来定义Kubernetes资源类型和元数据。
- en: Use `spec` to define the desired state of the resource, such as the number of
    replicas, container images, and exposed ports.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`spec`来定义资源的期望状态，例如副本数量、容器镜像和暴露的端口。
- en: Use the `---` separator to define multiple resources in the same file, such
    as a Deployment and a Service.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`---`分隔符在同一文件中定义多个资源，例如一个Deployment和一个Service。
- en: '**33\. kubectl:** Use the `kubectl` command-line tool to manage the Kubernetes
    cluster and resources.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**33\. kubectl:** 使用`kubectl`命令行工具来管理Kubernetes集群和资源。'
- en: '[PRE33]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '**34\. Organize your project:**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**34\. 组织你的项目：**'
- en: '[PRE34]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Use separate directories for data, models, notebooks, and source code.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用单独的目录存储数据、模型、笔记本和源代码。
- en: Further, subdivide directories to separate raw and processed data or different
    types of source code modules.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进一步细分目录以分开原始数据和处理后的数据或不同类型的源代码模块。
- en: '**35\. Model versioning:** Use model versioning tools like DVC or MLflow to
    track different versions of your trained machine learning models.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**35\. 模型版本控制：** 使用版本控制工具如DVC或MLflow来跟踪不同版本的训练过的机器学习模型。'
- en: Store model artifacts (e.g., weights, metadata) in a centralized storage system,
    such as Amazon S3 or Google Cloud Storage.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型工件（例如权重、元数据）存储在集中式存储系统中，例如Amazon S3或Google Cloud Storage。
- en: Use a versioning tool to keep track of model versions, their associated training
    data, and hyperparameters.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用版本控制工具跟踪模型版本、相关训练数据和超参数。
- en: Enable easy model comparison and reproducibility by tracking performance metrics
    and training configurations.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过跟踪性能指标和训练配置来启用模型比较和可重复性。
- en: '**36\. Automated testing:**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**36\. 自动化测试：**'
- en: Use testing libraries like `unittest` or `pytest` to write and run tests.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`unittest`或`pytest`等测试库来编写和运行测试。
- en: Test individual functions and classes with unit tests, and test interactions
    between components with integration tests.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用单元测试测试单个函数和类，用集成测试测试组件之间的交互。
- en: Perform end-to-end tests to ensure the entire system works as expected, including
    model serving and API endpoints.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行端到端测试，以确保整个系统按预期工作，包括模型服务和API端点。
- en: '**37\. Papermill:**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**37\. Papermill：**'
- en: Papermill allows you to parameterize Jupyter Notebooks by injecting new values
    for specific cells.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Papermill允许你通过为特定单元格注入新值来参数化Jupyter Notebooks。
- en: Execute Notebooks programmatically and generate reports with different parameter
    values without manual intervention.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以编程方式执行Notebooks，并生成具有不同参数值的报告，而无需手动干预。
- en: '[PRE35]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '**38\. Environment management:** tools like Conda or virtualenv to create isolated
    environments for projects.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**38\. 环境管理：** 使用Conda或virtualenv等工具为项目创建隔离的环境。'
- en: '[PRE36]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '**39\. Progressive model loading:** Load large models in chunks to reduce memory
    consumption and improve performance.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**39\. 逐步模型加载：** 将大型模型分块加载，以减少内存消耗并提高性能。'
- en: '[PRE37]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '**40\. Feature encoding:**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**40\. 特征编码：**'
- en: Feature encoding techniques transform categorical variables into numerical representations
    that machine learning models can use.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征编码技术将分类变量转换为机器学习模型可以使用的数值表示。
- en: One-hot encoding creates binary columns for each category, while target encoding
    replaces each category with the mean of the target variable for that category.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: One-hot编码为每个类别创建二进制列，而目标编码则用该类别的目标变量均值替换每个类别。
- en: '[PRE38]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '**41\. Data validation:** Validate the quality and consistency of your data
    using data validation frameworks like Great Expectations, Pandera, or custom validation
    functions.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**41\. 数据验证：** 使用数据验证框架，如Great Expectations、Pandera或自定义验证函数，验证数据的质量和一致性。'
- en: '[PRE39]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '**42\. Data versioning:** Use data versioning tools like DVC or Pachyderm to
    track changes to your datasets and ensure reproducibility across different experiments
    and model versions.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**42\. 数据版本控制：** 使用数据版本控制工具，如DVC或Pachyderm，跟踪数据集的变化，并确保在不同实验和模型版本之间的可重复性。'
- en: '[PRE40]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '**43\. Use feature stores:** Implement feature stores like Feast or Hopsworks
    to store, manage, and serve features for machine learning models.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**43\. 使用特征存储：** 实施像Feast或Hopsworks这样的特征存储来存储、管理和提供机器学习模型的特征。'
- en: '[PRE41]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Feature stores can help you centralize the management of your features, ensuring
    consistency and reducing duplication across different models and experiments.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 特征存储可以帮助你集中管理特征，确保一致性并减少不同模型和实验之间的重复。
- en: '**44\. Feature scaling:** Apply feature scaling techniques like MinMax scaling,
    standard scaling, or normalization to ensure that your features have similar scales
    and distributions.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**44\. 特征缩放：** 应用特征缩放技术，如MinMax缩放、标准化缩放或归一化，以确保你的特征具有相似的尺度和分布。'
- en: '[PRE42]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '**45\. Dimensionality reduction:** Apply dimensionality reduction techniques
    like PCA, t-SNE, or UMAP to reduce the number of features in your dataset while
    preserving important patterns and relationships.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**45\. 降维：** 应用降维技术，如PCA、t-SNE或UMAP，以减少数据集中的特征数量，同时保留重要的模式和关系。'
- en: '[PRE43]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '**46\. Pandas chaining:** Chain Pandas operations together to create more readable
    and concise data manipulation code.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**46\. Pandas链式操作：** 将Pandas操作链在一起，以创建更具可读性和简洁的数据处理代码。'
- en: '[PRE44]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '**47\. Use the ‘pipe’ function:** Use the `pipe` function to integrate custom
    functions or operations in your Pandas chaining workflow.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**47\. 使用‘pipe’函数：** 使用`pipe`函数在你的Pandas链式操作工作流中集成自定义函数或操作。'
- en: '[PRE45]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '**48\. Pandas’ built-in plotting**: Use Pandas’ built-in plotting functions
    for quick and easy data visualization.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**48\. Pandas内置绘图：** 使用Pandas的内置绘图函数进行快速且简单的数据可视化。'
- en: '[PRE46]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '**49\. Visualize missing data with Missingno:** Use the Missingno library to
    visualize missing data in your dataset.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**49\. 使用Missingno可视化缺失数据：** 使用Missingno库可视化数据集中缺失的数据。'
- en: '[PRE47]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '**50\. Use SQL Databases:** You can use the `sqlite3` library in Python to
    interact with an SQLite database. For example, you can create a table in an SQLite
    database and insert some data into it:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**50\. 使用SQL数据库：** 你可以在Python中使用`sqlite3`库与SQLite数据库进行交互。例如，你可以在SQLite数据库中创建一个表并插入一些数据：'
- en: '[PRE48]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '**51\. Requests Library:** Use the requests library to make HTTP requests:
    The requests library provides a simple way to make HTTP requests to APIs or websites.
    Here’s an example of how to make a GET request.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**51\. Requests 库：** 使用 requests 库进行 HTTP 请求：requests 库提供了一种简单的方法来向 API 或网站发送
    HTTP 请求。以下是如何进行 GET 请求的示例。'
- en: '[PRE49]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '**52\. OS Library:** Use the os library to manipulate files and directories:
    The os library provides functions for interacting with files and directories.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**52\. OS 库：** 使用 os 库操作文件和目录：os 库提供了与文件和目录交互的功能。'
- en: '[PRE50]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '**53\. Working with JSON:**'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**53\. 处理 JSON：**'
- en: 'Encoding Python data to JSON format:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Python 数据编码为 JSON 格式：
- en: '[PRE51]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Decoding JSON data to Python format:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 将 JSON 数据解码为 Python 格式：
- en: '[PRE52]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '**54\. Working with CSV Files: USing CSV module.**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**54\. 处理 CSV 文件：使用 CSV 模块。**'
- en: '[PRE53]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '**55\. Using SQL Alchemy for Database Access:** SQL Alchemy is a popular Python
    library for working with databases. It provides a simple interface for connecting
    to various databases and executing SQL queries.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**55\. 使用 SQL Alchemy 进行数据库访问：** SQL Alchemy 是一个流行的 Python 库，用于处理数据库。它提供了一个简单的接口，用于连接到各种数据库并执行
    SQL 查询。'
- en: '[PRE54]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '**56\. Feature selection using Recursive Feature Elimination (RFE):**'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**56\. 使用递归特征消除（RFE）进行特征选择：**'
- en: RFE helps identify the most important features, leading to better model performance
    and faster training.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RFE 有助于识别最重要的特征，从而提高模型性能并加快训练速度。
- en: Feature selection can reduce overfitting and improve the generalization of your
    model.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征选择可以减少过拟合并提高模型的泛化能力。
- en: '[PRE55]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '**57\. Use Apache Parquet for efficient storage of columnar data:** Apache
    Parquet is a columnar storage file format that provides efficient compression
    and encoding schemes, making it ideal for storing large datasets used in machine
    learning.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**57\. 使用 Apache Parquet 高效存储列式数据：** Apache Parquet 是一种列式存储文件格式，提供高效的压缩和编码方案，非常适合存储用于机器学习的大型数据集。'
- en: '[PRE56]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '**58\. Use Apache Kafka for real-time data streaming:** Apache Kafka is a distributed
    streaming platform that enables you to build real-time data pipelines and applications.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**58\. 使用 Apache Kafka 进行实时数据流：** Apache Kafka 是一个分布式流处理平台，使您能够构建实时数据管道和应用程序。'
- en: '[PRE57]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '**59\. Partition your data for efficient querying:** Partitioning your data
    can help improve query performance by reducing the amount of data that needs to
    be read for a given query.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**59\. 对数据进行分区以提高查询效率：** 对数据进行分区可以通过减少需要读取的数据量来提高查询性能。'
- en: '[PRE58]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '**60\. Use data augmentation techniques to increase dataset size:** Data augmentation
    involves creating new training examples by applying various transformations to
    the existing data, which can help improve model performance.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**60\. 使用数据增强技术增加数据集大小：** 数据增强涉及通过对现有数据应用各种转换来创建新的训练样本，这有助于提高模型性能。'
- en: '[PRE59]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '**61\. Using Flask for model deployment:** Below is an example of how to use
    Flask to deploy a machine learning model:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**61\. 使用 Flask 部署模型：** 以下是使用 Flask 部署机器学习模型的示例：'
- en: '[PRE60]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '**62\. Using Pytest for testing:**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**62\. 使用 Pytest 进行测试：**'
- en: For example, we have a file called `math_operations.py.`
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们有一个名为`math_operations.py`的文件。
- en: '[PRE61]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Next, create a test module with the same name as your module, but with a `test_`
    prefix. In our case, we''ll create a file called`test_math_operations.py`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个测试模块，名称与您的模块相同，但以`test_`为前缀。在我们的例子中，我们将创建一个名为`test_math_operations.py`的文件：
- en: '[PRE62]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Run the tests using the `pytest` command
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pytest`命令运行测试
- en: '[PRE63]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Pytest will discover and run the test functions in the `test_math_operations.py`
    module.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Pytest 将发现并运行`test_math_operations.py`模块中的测试函数。
- en: '**63\. Use automated data pipelines:** Automated data pipelines can help you
    automate the process of data ingestion, cleaning, and transformation. Some of
    the important tools are'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**63\. 使用自动化数据管道：** 自动化数据管道可以帮助您自动化数据摄取、清洗和转换的过程。一些重要的工具包括'
- en: '[Apache Airflow](https://airflow.apache.org)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache Airflow](https://airflow.apache.org)'
- en: '[Prefect](https://www.prefect.io)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Prefect](https://www.prefect.io)'
- en: '[Apache Beam](https://beam.apache.org)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache Beam](https://beam.apache.org)'
- en: '[Luigi](https://github.com/spotify/luigi)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Luigi](https://github.com/spotify/luigi)'
- en: '[Dagster](https://github.com/dagster-io/dagster)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Dagster](https://github.com/dagster-io/dagster)'
- en: '[Argo Workflows](https://github.com/argoproj/argo-workflows)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Argo Workflows](https://github.com/argoproj/argo-workflows)'
- en: '[NiFi](https://nifi.apache.org)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NiFi](https://nifi.apache.org)'
- en: Apache Airflow Ml pipeline
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Airflow 机器学习管道
- en: '[PRE64]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '**64\. Use Transfer Learning:** Transfer learning can help you reuse and adapt
    pre-trained machine learning models for your own use cases. Here’s an example
    of how to use transfer learning with TensorFlow:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**64\. 使用迁移学习：** 迁移学习可以帮助你重用和调整预训练的机器学习模型以适应你的使用案例。以下是一个如何使用 TensorFlow 进行迁移学习的示例：'
- en: '[PRE65]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '**65\. Use automated machine learning(Auto ML):** By using platforms like H2O.ai
    or Google Cloud AutoML, you can automatically select, train, and deploy models
    based on your data and requirements. Here’s an example of how to use H2O.ai’s
    AutoML platform:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**65\. 使用自动化机器学习（Auto ML）：** 通过使用 H2O.ai 或 Google Cloud AutoML 等平台，你可以根据数据和需求自动选择、训练和部署模型。以下是一个如何使用
    H2O.ai 的 AutoML 平台的示例：'
- en: '[PRE66]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '**66\. Use anomaly detection:** By using libraries like PyOD or TensorFlow,
    you can detect anomalies based on statistical or machine learning techniques.
    Here’s an example of how to use PyOD to detect anomalies in a dataset:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**66\. 使用异常检测：** 通过使用 PyOD 或 TensorFlow 等库，你可以基于统计或机器学习技术检测异常。以下是一个如何使用 PyOD
    在数据集中检测异常的示例：'
- en: '[PRE67]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '**67\. Using Weights and Biases:** Here’s an example of how to use Weights
    & Biases to run and track machine learning experiments.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**67\. 使用权重与偏差：** 下面是一个如何使用权重与偏差来运行和跟踪机器学习实验的示例。'
- en: '[PRE68]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '**68\. Important tools managing machine learning workflows:**'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**68\. 重要的机器学习工作流管理工具：**'
- en: '[Kubeflow](https://www.kubeflow.org)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kubeflow](https://www.kubeflow.org)'
- en: '[Apache Airflow](https://airflow.apache.org)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Apache Airflow](https://airflow.apache.org)'
- en: '[MLFlow](https://mlflow.org)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLFlow](https://mlflow.org)'
- en: '[Seldon](https://www.seldon.io)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Seldon](https://www.seldon.io)'
- en: '[Pachyderm](https://www.pachyderm.com)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pachyderm](https://www.pachyderm.com)'
- en: '[DVC](https://dvc.org)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DVC](https://dvc.org)'
- en: '**69\. Use Data Compression:** Consider using tools and libraries such as zlib,
    gzip, or bz2 for data compression in Python.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**69\. 使用数据压缩：** 在 Python 中考虑使用 zlib、gzip 或 bz2 等工具和库进行数据压缩。'
- en: '[PRE69]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '**70\. Data serialization:** Consider using tools and libraries such as JSON,
    YAML, or protobuf for data serialization in Python.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '**70\. 数据序列化：** 在 Python 中考虑使用 JSON、YAML 或 protobuf 等工具和库进行数据序列化。'
- en: '[PRE70]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '**71\. Data normalization and scaling:** Consider using tools and libraries
    such as scikit-learn, TensorFlow, or PyTorch for data normalization and scaling
    in Python.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**71\. 数据标准化和缩放：** 在 Python 中考虑使用 scikit-learn、TensorFlow 或 PyTorch 等工具和库进行数据标准化和缩放。'
- en: '[PRE71]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '**72\. Data encryption and security:** Consider using tools and libraries such
    as cryptography, Fernet, or PyAesCrypt for data encryption and security in Python.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**72\. 数据加密与安全：** 在 Python 中考虑使用诸如 cryptography、Fernet 或 PyAesCrypt 的工具和库来进行数据加密和安全。'
- en: '[PRE72]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '**73\. Data Validation using Great Expectation:**'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**73\. 使用 Great Expectation 进行数据验证：**'
- en: '[PRE73]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '**74\.** `**logging**` **module:** Use the `logging` module for flexible logging.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**74\.** `**logging**` **模块：** 使用 `logging` 模块进行灵活的日志记录。'
- en: '[PRE74]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '**75\. Use Dask dataframe :** Dask is a powerful library for parallel and distributed
    computing in Python. It allows you to process large datasets that don’t fit into
    memory by breaking them into smaller chunks and processing them in parallel.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**75\. 使用 Dask 数据框：** Dask 是一个用于 Python 的强大库，支持并行和分布式计算。它允许你通过将大型数据集拆分为较小的块并并行处理它们来处理不适合内存的大数据集。'
- en: '[PRE75]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '**Conclusion:**'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**结论：**'
- en: I hope the above tips and tricks are useful. Again there is a lot of tools and
    process in MLOps. The MLOps landscape also keeps changing very fast. It is better
    to keep updating with the latest tools and MLOps processes.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望以上提示和技巧对你有用。MLOps 中还有许多工具和流程，MLOps 领域也在快速变化。最好保持更新，以便了解最新的工具和 MLOps 流程。
- en: 'References:'
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献：
- en: 'Mlflow: An Open Platform to Simplify the Machine Learning Lifecycle. (2021).
    [https://mlflow.org/](https://mlflow.org/)'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Mlflow: 一个简化机器学习生命周期的开放平台。 (2021). [https://mlflow.org/](https://mlflow.org/)'
- en: 'Prometheus: An open-source monitoring system with a dimensional data model.
    (2021). [https://prometheus.io/](https://prometheus.io/)'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Prometheus: 一个具有维度数据模型的开源监控系统。 (2021). [https://prometheus.io/](https://prometheus.io/)'
- en: 'Grafana: The open and composable observability and data visualization platform.
    (2021). [https://grafana.com/](https://grafana.com/)'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Grafana: 开放且可组合的可观察性和数据可视化平台。 (2021). [https://grafana.com/](https://grafana.com/)'
- en: 'Seldon Core: Deploy, scale & monitor your machine learning models in Kubernetes.
    (2021).[https://www.seldon.io/tech/products/core/](https://www.seldon.io/tech/products/core/)'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Seldon Core: 在 Kubernetes 中部署、扩展和监控你的机器学习模型。 (2021). [https://www.seldon.io/tech/products/core/](https://www.seldon.io/tech/products/core/)'
- en: 'Kubeflow: The Machine Learning Toolkit for Kubernetes. (2021). [https://www.kubeflow.org/](https://www.kubeflow.org/)'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Kubeflow: Kubernetes 的机器学习工具包。 (2021). [https://www.kubeflow.org/](https://www.kubeflow.org/)'
- en: 'Dask: Parallel computing with task scheduling. (2021). Retrieved from [https://dask.org/](https://dask.org/)'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Dask: 使用任务调度进行并行计算. (2021). 取自 [https://dask.org/](https://dask.org/)'
- en: 'Great Expectations: Always know what to expect from your data. (2021). [https://greatexpectations.io/](https://greatexpectations.io/)'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 《伟大的期望：始终了解数据中的期望》 (2021). [https://greatexpectations.io/](https://greatexpectations.io/)
- en: 'Airflow: A platform to programmatically author, schedule, and monitor workflows.
    (2021). [https://airflow.apache.org/](https://airflow.apache.org/)'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Airflow: 用于编程创作、调度和监控工作流的平台. (2021). [https://airflow.apache.org/](https://airflow.apache.org/)'
- en: 'TensorFlow Extended: A production-ready ML platform for TensorFlow. (2021).
    [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx)'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'TensorFlow Extended: 为 TensorFlow 提供生产就绪的 ML 平台. (2021). [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx)'
- en: 'Prefect: The New Standard in Dataflow Automation. (2021). [https://www.prefect.io/](https://www.prefect.io/)'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Prefect: 数据流自动化的新标准. (2021). [https://www.prefect.io/](https://www.prefect.io/)'
- en: 'Feast: Feature Store for Machine Learning. (2021). [https://feast.dev/](https://feast.dev/)'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Feast: 机器学习的特征存储. (2021). [https://feast.dev/](https://feast.dev/)'
- en: “Machine Learning Engineering” by Andriy Burkov.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安德烈·布尔科夫**的《机器学习工程》'
- en: “Data Engineering Cookbook” by Andreas Kretz.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**安德烈亚斯·克雷茨**的《数据工程实用指南》'
- en: “Hands-On Data Engineering with Python” by James Lee.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**詹姆斯·李**的《Python 数据工程实战》'
