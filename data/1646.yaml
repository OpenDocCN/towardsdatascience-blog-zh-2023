- en: Optimizing Vector Quantization Methods by Machine Learning Algorithms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化向量量化方法的机器学习算法
- en: 原文：[https://towardsdatascience.com/optimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d?source=collection_archive---------4-----------------------#2023-05-17](https://towardsdatascience.com/optimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d?source=collection_archive---------4-----------------------#2023-05-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/optimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d?source=collection_archive---------4-----------------------#2023-05-17](https://towardsdatascience.com/optimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d?source=collection_archive---------4-----------------------#2023-05-17)
- en: Machine learning optimization of vector quantization methods used in end-to-end
    training of neural networks
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本文简要解释了我们在 ICASSP 2023 会议上发表的论文 [1]。有关更多详细信息，请查看[此链接](https://ieeexplore.ieee.org/abstract/document/10096204)中的论文。
- en: '[](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)[![Mohammad
    Hassan Vali](../Images/b057aa7bd9e1c629fc3743a7f69f013e.png)](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)
    [Mohammad Hassan Vali](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)[![Mohammad
    Hassan Vali](../Images/b057aa7bd9e1c629fc3743a7f69f013e.png)](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)
    [Mohammad Hassan Vali](https://medium.com/@mohammad.vali?source=post_page-----77c436d0749d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习优化向量量化方法，用于神经网络的端到端训练
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840f2c687344&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&user=Mohammad+Hassan+Vali&userId=840f2c687344&source=post_page-840f2c687344----77c436d0749d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)
    ·10 min read·May 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F77c436d0749d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&user=Mohammad+Hassan+Vali&userId=840f2c687344&source=-----77c436d0749d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F840f2c687344&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&user=Mohammad+Hassan+Vali&userId=840f2c687344&source=post_page-840f2c687344----77c436d0749d---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----77c436d0749d--------------------------------)
    ·10分钟阅读·2023年5月17日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F77c436d0749d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&user=Mohammad+Hassan+Vali&userId=840f2c687344&source=-----77c436d0749d---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77c436d0749d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&source=-----77c436d0749d---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77c436d0749d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-vector-quantization-methods-by-machine-learning-algorithms-77c436d0749d&source=-----77c436d0749d---------------------bookmark_footer-----------)'
- en: This post is a short explanation of our paper [1] published at ICASSP 2023 conference.
    For more details, please look at the paper [under this link](https://ieeexplore.ieee.org/abstract/document/10096204).
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/1b6c41b4f07a4b381d9da086ab84a80c.png)'
- en: '![](../Images/1b6c41b4f07a4b381d9da086ab84a80c.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: ·
- en: Photo by [Alina Grubnyak](https://unsplash.com/@alinnnaaaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/ZiQkhI7417A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Alina Grubnyak](https://unsplash.com/@alinnnaaaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，发布于 [Unsplash](https://unsplash.com/photos/ZiQkhI7417A?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Vector Quantization
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量量化
- en: Vector quantization (VQ) is a data compression technique similar to k-means
    algorithm which can model any data distribution. Vector quantization has been
    used in a wide range of applications for speech, image, and video data, such as
    image generation [2], speech and audio coding [3], voice conversion [4,5], music
    generation [6], and text-to-speech synthesis [7,8]. The figure below shows how
    vector quantization (VQ) works. For VQ process, we require a codebook which includes
    a number of codewords. Applying VQ on a data point (gray dots) means to map it
    to the closest codeword (blue dots), i.e. replace the value of data point with
    the closest codeword value. Each voronoi cell (black lines) contains one codeword
    such that all data points located in that cell will be mapped to that codeword,
    since it is the closest codeword to data points located in that voronoi cell.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 向量量化（VQ）是一种数据压缩技术，类似于 k-means 算法，可以对任何数据分布进行建模。向量量化已被广泛应用于语音、图像和视频数据，如图像生成 [2]、语音和音频编码
    [3]、语音转换 [4,5]、音乐生成 [6] 和文本到语音合成 [7,8]。下图展示了向量量化（VQ）的工作原理。对于 VQ 过程，我们需要一个包括多个代码字的码本。对数据点（灰色点）应用
    VQ 意味着将其映射到最近的代码字（蓝色点），即用最近代码字的值替换数据点的值。每个 Voronoi 单元（黑线）包含一个代码字，使得该单元中所有的数据点都将映射到该代码字，因为它是该
    Voronoi 单元中数据点的最近代码字。
- en: '![](../Images/30dacbc81108406f7bfe0f64f3a26d52.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30dacbc81108406f7bfe0f64f3a26d52.png)'
- en: Vector Quantization Operation (image by author)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 向量量化操作（作者提供的图像）
- en: 'In other words, vector quantization maps the input vector x to the closest
    codeword within the codebook (CB) using the following formula:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，向量量化通过以下公式将输入向量 x 映射到码本（CB）中的最近代码字：
- en: '![](../Images/d2801e8776ea39def212b62f395038ab.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2801e8776ea39def212b62f395038ab.png)'
- en: The computational complexity of VQ increases exponentially with the increase
    in the codebook size (increase in VQ bitrate). Hence, this plain form of VQ is
    applicable only for limited bitrates (limited codebook sizes). To solve this challenge
    and apply VQ for higher bitrates and higher dimensional data, we use some variants
    of VQ such as Residual VQ, Additive VQ, and Product VQ. These methods considers
    more than one codebook to apply VQ on the data. We will explain these three VQ
    methods in the following.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: VQ 的计算复杂度随着码本大小（VQ 比特率的增加）的增加而呈指数增长。因此，这种简单形式的 VQ 仅适用于有限的比特率（有限的码本大小）。为了解决这一挑战并将
    VQ 应用于更高的比特率和更高维的数据，我们使用了 VQ 的一些变体，如残差 VQ、加法 VQ 和乘积 VQ。这些方法考虑了多个码本来对数据应用 VQ。我们将在下文中解释这三种
    VQ 方法。
- en: '**Residual Vector Quantization (RVQ)**'
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**残差向量量化（RVQ）**'
- en: Residual VQ quantizes the input vector x by applying M consecutive VQ modules
    on it. According to the following figure, suppose M=3\. We apply the first VQ
    module on input vector x using the first codebook (CB¹). Then, after finding the
    closest codeword form first codebook, we calculate the remainder (R1). Afterwards,
    we pass R1 as input to the next VQ module using the second codebook (CB²). This
    process will continue for M stages where we would find three closest codeword
    coming from separate codebooks. At the end, we quantize the input vector x as
    a summation of M closest codewords.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 残差 VQ 通过对输入向量 x 应用 M 个连续的 VQ 模块来进行量化。根据下图，假设 M=3。我们使用第一个码本（CB¹）对输入向量 x 应用第一个
    VQ 模块。然后，在找到第一个码本中的最近代码字后，我们计算剩余值（R1）。接着，我们将 R1 作为输入传递给使用第二个码本（CB²）的下一个 VQ 模块。这个过程将持续
    M 个阶段，其中我们会找到来自不同码本的三个最近代码字。最后，我们将输入向量 x 量化为 M 个最近代码字的总和。
- en: '![](../Images/69fd7ea5e5d1eb9d65bf47d3894eddc9.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69fd7ea5e5d1eb9d65bf47d3894eddc9.png)'
- en: '**Additive Vector Quantization (AVQ)**'
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**加法向量量化（AVQ）**'
- en: In a similar way as Residual VQ, Additive VQ quantizes the input vector x by
    applying M consecutive VQ modules. However, Additive VQ adopts the complex beam
    searching algorithm to find the closest codewords for the quantization process
    (you can find the details of beam searching algorithm in this paper [9]). According
    to the following figure, we suppose M=3\. In Additive VQ, first we search for
    the closest codeword from the union of all three codebooks (here CB¹, CB², CB³).
    Then, suppose we find the best codeword from CB². After that, we calculate the
    residual (R1) and pass it as input to the next VQ module. Since the first codeword
    is selected from CB², now we search for the closest codeword from the union of
    CB¹ and CB³. After calculating the residual R2, we pass it as input to the last
    VQ module, where we do the search using the last codebook (in this case CB¹) which
    is not yet contributed to the quantization process. At the end, we quantize the
    input vector x as a summation of M closest codewords.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于残差 VQ，加法 VQ 通过应用 M 个连续的 VQ 模块来量化输入向量 x。然而，加法 VQ 采用复杂的束搜索算法来找到量化过程中的最接近代码字（你可以在这篇论文
    [9] 中找到束搜索算法的详细信息）。根据下图，我们假设 M=3。在加法 VQ 中，我们首先从所有三个代码本的联合中搜索最接近的代码字（这里是 CB¹、CB²、CB³）。然后，假设我们从
    CB² 找到最佳代码字。接下来，我们计算残差 (R1) 并将其作为输入传递给下一个 VQ 模块。由于第一个代码字是从 CB² 中选择的，现在我们在 CB¹
    和 CB³ 的联合中搜索最接近的代码字。在计算残差 R2 后，我们将其作为输入传递给最后的 VQ 模块，在这里我们使用尚未参与量化过程的最后一个代码本（在此例中是
    CB¹）进行搜索。最后，我们将输入向量 x 量化为 M 个最接近代码字的和。
- en: '![](../Images/263661bd4201cde99f7aa75e27321c13.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/263661bd4201cde99f7aa75e27321c13.png)'
- en: '**Product Vector Quantization (PVQ)**'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**产品向量量化（PVQ）**'
- en: Product VQ splits the input vector x of dimension D to M independent subspaces
    of dimension D/M. Then it applies M independent VQ modules to the existing subspaces.
    At the end, Product VQ quantizes the input vector x as a concatenation of M closest
    codewords (one per each codebook). The figure below shows the Product VQ when
    M=3.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 产品 VQ 将维度为 D 的输入向量 x 拆分为 M 个独立的维度为 D/M 的子空间。然后，它对这些子空间应用 M 个独立的 VQ 模块。最后，产品
    VQ 将输入向量 x 量化为 M 个最接近的代码字的连接（每个代码本一个）。下图展示了 M=3 时的产品 VQ。
- en: '![](../Images/3a9223cfafc720daab683a4a52f0254a.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a9223cfafc720daab683a4a52f0254a.png)'
- en: '**Codebooks Optimization**'
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**代码本优化**'
- en: Vector quantization (VQ) training means to optimize the codebook(s) such that
    they model the data distribution in a way that the error of quantization (such
    as mean squared error) between data points and codebook elements is minimized.
    To optimize the codebooks for these three above-mentioned variants of VQ (Residual
    VQ, Additive VQ, and Product VQ) there are different approaches which we will
    mention in the following.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 向量量化（VQ）训练意味着优化代码本，使其以一种模型数据分布的方式来最小化数据点与代码本元素之间的量化误差（如均方误差）。为了优化上述三种 VQ 变体（残差
    VQ、加法 VQ 和产品 VQ）的代码本，有不同的方法，我们将在后文中提到。
- en: '1\. K-means Algorithm (traditional approach):'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. K-均值算法（传统方法）：
- en: Based on the literature review, in most of the papers, codebooks for these three
    VQ methods have been optimized by [k-means algorithm](https://en.wikipedia.org/wiki/K-means_clustering).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 根据文献综述，在大多数论文中，这三种 VQ 方法的代码本都是通过 [K-均值算法](https://en.wikipedia.org/wiki/K-means_clustering)
    进行优化的。
- en: '2\. Stochastic Optimization (machine learning algorithms):'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 随机优化（机器学习算法）：
- en: Machine learning optimization algorithms are based on gradient calculation.
    Therefore, it is impossible to optimize vector quantization methods using machine
    learning optimization, since the argmin function in vector quantization function
    (first equation above) is not differentiable. In other words, we cannot pass the
    gradients over vector quantization function in backpropagation. Here we have mentioned
    two solutions to solve this problem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习优化算法是基于梯度计算的。因此，使用机器学习优化来优化向量量化方法是不可能的，因为向量量化函数中的 argmin 函数（上面的第一个方程）是不可微的。换句话说，我们无法在反向传播中将梯度传递过向量量化函数。这里我们提到了两种解决这个问题的方法。
- en: 2.1\. Straight Through Estimator (STE)
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1\. 直接估计器（STE）
- en: STE [10] solves the problem by simply copying the gradients intactly over VQ
    module in backpropagation. Hence, it does not consider the influence of vector
    quantization and leads to a mismatch between the gradients and true behavior of
    the VQ function.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: STE [10] 通过在反向传播过程中简单地将梯度完整地复制到 VQ 模块中来解决问题。因此，它没有考虑向量量化的影响，从而导致梯度与 VQ 函数的真实行为之间的不匹配。
- en: '2.2\. Noise Substitution in Vector Quantization (NSVQ):'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '2.2\. 矢量量化中的噪声替代 (NSVQ):'
- en: The NSVQ technique [11] is our recently proposed method, in which the vector
    quantization error is simulated by adding noise to the input vector, such that
    the simulated noise would gain the shape of original VQ error distribution (you
    can read shortly about NSVQ [in this post](https://medium.com/towards-data-science/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: NSVQ 技术 [11] 是我们最近提出的方法，其中通过向输入向量添加噪声来模拟矢量量化误差，使得模拟噪声获得原始 VQ 误差分布的形状（你可以简要阅读关于
    NSVQ 的内容 [在这篇文章中](https://medium.com/towards-data-science/improving-vector-quantization-in-vector-quantized-variational-autoencoders-vq-vae-915f5814b5ce)）。
- en: NSVQ technique [11] has some advantages over STE method [10] which are listed
    in the following. 1) NSVQ yields more accurate gradients for VQ function. 2) NSVQ
    achieves faster convergence for VQ training (codebook optimization). 3) NSVQ does
    not need any additional hyper-parameter tuning for VQ training (does not require
    additional loss term for VQ training to be added to the global optimization loss
    function).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: NSVQ 技术 [11] 相较于 STE 方法 [10] 具有以下优势。1) NSVQ 为 VQ 函数提供更准确的梯度。2) NSVQ 实现了 VQ 训练（代码本优化）的更快收敛。3)
    NSVQ 无需对 VQ 训练进行额外的超参数调整（不需要在全局优化损失函数中添加额外的损失项）。
- en: Experiments
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验
- en: In our paper, we have used our recently proposed NSVQ technique [11] to optimize
    three above-mentioned variants of VQ by machine learning optimization. To evaluate
    the performance of these three VQ methods and study the trade-offs between accuracy,
    bitrate, and complexity of them, we conducted four different scenarios for experiments.
    We will explain all these scenarios of experiments in the following.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的论文中，我们使用了我们最近提出的 NSVQ 技术 [11] 来优化上述三种 VQ 变体。为了评估这三种 VQ 方法的性能，并研究它们在准确性、比特率和复杂性之间的权衡，我们进行了四种不同场景的实验。我们将在以下部分解释这些实验场景。
- en: 1\. Approximate Nearest Neighbor (ANN) Search
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 近似最近邻（ANN）搜索
- en: In this experiment, we modeled the distribution of SIFT1M dataset [12] (128-D
    image descriptors) by training three VQ methods on its learning set. The SIFT1M
    image descriptors dataset [12] includes 10⁶ base vectors, 10⁵ learning vectors,
    and 10⁴ query vectors for testing purposes. The ground truth contains the set
    of actual nearest neighbors, from the base vectors to the query vectors. In the
    ANN search, we first compress the base vectors using the corresponding learnt
    codebooks trained on the learning set. Then, for each query vector, we find the
    approximate nearest neighbors from the compressed base vectors by performing an
    exhaustive search. To assess the quality of data compression, we calculate the
    *recall metric* at different values for parameter ***T***, which shows whether
    the actual nearest neighbor (from groundtruth) exists in the first ***T*** computed
    nearest neighbors. The figure below illustrates the comparison of three variants
    of VQ optimized by our proposed NSVQ technique with the baseline methods under
    *recall metric*. In general, all three machine learning-based optimized VQ methods
    achieve comparable (even slightly better in case of RVQ) recall values to the
    baselines.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们通过在 SIFT1M 数据集 [12]（128-D 图像描述符）上训练三种 VQ 方法来建模其分布。SIFT1M 图像描述符数据集 [12]
    包括 10⁶ 个基向量、10⁵ 个学习向量和 10⁴ 个测试用的查询向量。实际的最近邻集合从基向量到查询向量。在 ANN 搜索中，我们首先使用在学习集上训练的对应学习到的代码本来压缩基向量。然后，对于每个查询向量，我们通过进行穷尽搜索来从压缩的基向量中找到近似的最近邻。为了评估数据压缩的质量，我们在不同的
    ***T*** 参数值下计算 *召回率度量*，该度量显示实际最近邻（从实际数据中）是否存在于前 ***T*** 个计算的最近邻中。下图展示了使用我们提出的
    NSVQ 技术优化的三种 VQ 变体与基线方法在 *召回率度量* 下的比较。一般来说，所有三种基于机器学习优化的 VQ 方法在召回率值上与基线相当（在 RVQ
    的情况下甚至略好）。
- en: '![](../Images/4d3653f5b7b5e01742b3a668f9b16e2b.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d3653f5b7b5e01742b3a668f9b16e2b.png)'
- en: Comparison of recall values for compression of SIFT1M dataset by applying our
    proposed VQ methods and baselines at 64 bits (8 codebooks each with 256 codewords);
    Recall@T shows whether the actual nearest neighbor (from groundtruth) exists in
    the T computed nearest neighbors. (image by author)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 比较我们提出的 VQ 方法和基线方法在 64 位（每个 8 个代码本，每个有 256 个码字）下对 SIFT1M 数据集的压缩召回值；Recall@T
    显示实际最近邻（从实际数据中）是否存在于 T 个计算的最近邻中。（图片由作者提供）
- en: 2\. Image Compression using VQ-VAE
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 使用 VQ-VAE 的图像压缩
- en: In this experiment, we trained a vector quantized variational autoencoder (VQ-VAE)
    on the training set of CIFAR10 dataset to compress it. To apply the vector quantization
    in the bottleneck of VQ-VAE, we used each of these three VQ methods. After training,
    we reconstructed the test images of CIFAR10 using the trained encoder, decoder,
    and learnt codebooks for each VQ method. To evaluate the quality of reconstructed
    images, we employ Peak Signal to Noise Ratio (Peak SNR) metric. In addition, we
    computed the complexity of each VQ method using Weighted Million Operations Per
    Second (WMOPS) metric, which is under [ITU-T standard](https://en.wikipedia.org/wiki/ITU-T).
    The following figure shows the results of this experiment.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们在CIFAR10数据集的训练集上训练了一个向量量化变分自编码器（VQ-VAE）以进行压缩。为了在VQ-VAE的瓶颈中应用向量量化，我们使用了这三种VQ方法中的每一种。训练后，我们使用训练好的编码器、解码器和学习到的码本重建了CIFAR10的测试图像。为了评估重建图像的质量，我们使用了峰值信噪比（Peak
    SNR）指标。此外，我们使用加权每秒百万操作（WMOPS）指标计算了每种VQ方法的复杂度，该指标符合[ITU-T标准](https://en.wikipedia.org/wiki/ITU-T)。下图展示了这个实验的结果。
- en: '![](../Images/202eabf11a048f6dae696b130a20e8ee.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/202eabf11a048f6dae696b130a20e8ee.png)'
- en: Peak SNR and complexity of proposed VQ methods over 15 k training batches and
    10 individual experiments in the image compression scenario; lines refer to the
    mean values and the corresponding filled areas refer to their 95 % quantiles.
    For all VQ bitrates we used four codebooks i.e. M=4\. (image by author)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像压缩场景下，提出的VQ方法在15k训练批次和10次单独实验中的峰值SNR和复杂度；线条表示均值，对应的填充区域表示其95%分位数。对于所有VQ比特率，我们使用了四个码本，即M=4。（图像由作者提供）
- en: According to the complexity figure (in the right), we found that for the same
    use of computational resources (left vertical red line) and a higher bitrate,
    Product VQ performs better than Residual VQ. In addition, for the same use of
    computational resources (right vertical red line) and a higher bitrate, Residual
    VQ performs better than Additive VQ. Therefore, depending on how much computational
    resources are available, we can conclude which is the best VQ method to use.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 根据复杂度图（右侧），我们发现，对于相同的计算资源使用（左侧垂直红线）和较高的比特率，乘积VQ比残差VQ表现更好。此外，对于相同的计算资源使用（右侧垂直红线）和较高的比特率，残差VQ比加法VQ表现更好。因此，根据可用的计算资源，我们可以得出最适合使用的VQ方法。
- en: 3\. Speech Coding
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 语音编码
- en: In this experiment, we model the spectral envelope of speech signals by three
    VQ methods using the speech codec presented in [13]. To evaluate the quality of
    decoded speech signals, we used perceptual evaluation of speech quality (PESQ)
    and perceptually weighted signal to noise ratio (pSNR) as objective metrics. The
    following figure shows the performance of all three VQ methods under PESQ and
    pSNR criteria. According to the results, we observe that Additive VQ gains higher
    mean and lower variance than both Residual VQ and Product VQ in both metrics.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们使用[13]中提出的语音编解码器，通过三种VQ方法对语音信号的谱包络进行建模。为了评估解码后语音信号的质量，我们使用了语音质量感知评估（PESQ）和感知加权信噪比（pSNR）作为客观指标。下图展示了所有三种VQ方法在PESQ和pSNR标准下的表现。根据结果，我们观察到，在这两个指标中，加法VQ的均值更高且方差更低，相比于残差VQ和乘积VQ。
- en: '![](../Images/fda41b0e398776828c7acfb72c87cb0e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fda41b0e398776828c7acfb72c87cb0e.png)'
- en: Performance of proposed VQ methods in terms of PESQ and pSNR metrics for 16
    bit VQ (with 4 codebooks i.e. M=4) at overall bitrates of 8, 9.6, 13.2, 16.4,
    24.4 and 32 kbit/s in the speech coding scenario; solid lines refer to the mean
    values of PESQ and pSNR, and the corresponding filled areas refer to their 95%
    quantiles. (image by author)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的VQ方法在语音编码场景下，针对16位VQ（具有4个码本，即M=4）在总体比特率为8, 9.6, 13.2, 16.4, 24.4和32 kbit/s时，PESQ和pSNR指标的性能；实线表示PESQ和pSNR的均值，对应的填充区域表示其95%分位数。（图像由作者提供）
- en: 4\. Toy Examples
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 示例
- en: In this experiment, we intend to compare the performance of three VQ methods
    with respect to the correlation in the data. Hence, we prepared two correlated
    and uncorrelated datasets of dimension 64\. Then, we compressed these datasets
    using these three VQ methods. To evaluate the performance, we computed the mean
    squared error (MSE) between each dataset and its quantized version. The following
    figure shows the results for this experiment.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实验中，我们打算比较三种VQ方法在数据相关性方面的表现。因此，我们准备了两个维度为64的相关和不相关的数据集。然后，我们使用这三种VQ方法对这些数据集进行压缩。为了评估性能，我们计算了每个数据集及其量化版本之间的均方误差（MSE）。下图展示了这个实验的结果。
- en: '![](../Images/b18dd11707979378d90e576912295e49.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b18dd11707979378d90e576912295e49.png)'
- en: Vector quantization error for correlated and uncorrelated datasets using all
    three proposed VQ methods (data dimension=64, and for all VQ bitrates we used
    four codebooks i.e. M=4). (image by author)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用三种提出的VQ方法（数据维度=64，所有VQ比特率使用了四个码本，即M=4）对相关和无关数据集进行的向量量化误差。（图片由作者提供）
- en: In correlated dataset, since Residual VQ and Additive VQ take the correlation
    among all data dimensions into account, they have much lower quantization error
    than Product VQ as expected. On the other hand, Product VQ has better performance
    than Additive VQ and Residual VQ for uncorrelated data, since there is no correlation
    among data dimensions and that is exactly what Product VQ presumes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在相关数据集的情况下，由于残差VQ和加法VQ考虑了所有数据维度之间的相关性，它们的量化误差远低于乘积VQ，符合预期。另一方面，对于无关的数据，乘积VQ的表现优于加法VQ和残差VQ，因为数据维度之间没有相关性，这正是乘积VQ的假设。
- en: Conclusions
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Using variants of Vector Quantization (VQ) such as Residual VQ, Additive VQ,
    and Product VQ allows to apply VQ for high bitrates and high dimensional data.
    These VQ methods have been optimized by classic expectation maximization and k-menas
    algorithm so far. In this paper, we optimize these VQ methods by machine learning
    optimization using our recently proposed Noise Substitution in Vector Quantization
    (NSVQ) [11] technique. In addition, NSVQ allows end-to-end optimization of VQ
    methods in Neural Netwroks. We also study the trade-offs between bitrate, accuracy,
    and complexity of these three VQ methods. Hence, our open-source implementation
    [14] helps to make the best choice of VQ method for a particular use-case.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用诸如残差VQ、加法VQ和乘积VQ等向量量化（VQ）变体，允许将VQ应用于高比特率和高维数据。这些VQ方法目前已经通过经典的期望最大化和k-均值算法进行了优化。在本文中，我们通过机器学习优化来优化这些VQ方法，采用了我们最近提出的向量量化噪声替代（NSVQ）[11]技术。此外，NSVQ还允许在神经网络中对VQ方法进行端到端优化。我们还研究了这三种VQ方法之间比特率、准确性和复杂性的权衡。因此，我们的开源实现[14]有助于为特定用例选择最佳的VQ方法。
- en: GitHub Repository
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GitHub 存储库
- en: We provide the PyTorch implementation of these VQ methods in the following webpage.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在以下网页提供了这些VQ方法的PyTorch实现。
- en: '[](https://github.com/MHVali/Additive-Residual-Product-Vector-Quantization-Methods.git?source=post_page-----77c436d0749d--------------------------------)
    [## GitHub - MHVali/Additive-Residual-Product-Vector-Quantization-Methods'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[## GitHub - MHVali/Additive-Residual-Product-Vector-Quantization-Methods](https://github.com/MHVali/Additive-Residual-Product-Vector-Quantization-Methods.git?source=post_page-----77c436d0749d--------------------------------)'
- en: Contribute to MHVali/Additive-Residual-Product-Vector-Quantization-Methods development
    by creating an account on…
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过创建一个帐户来为MHVali/Additive-Residual-Product-Vector-Quantization-Methods的开发做出贡献…
- en: github.com](https://github.com/MHVali/Additive-Residual-Product-Vector-Quantization-Methods.git?source=post_page-----77c436d0749d--------------------------------)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/MHVali/Additive-Residual-Product-Vector-Quantization-Methods.git?source=post_page-----77c436d0749d--------------------------------)'
- en: Acknowledgement
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: Special thanks to my doctoral program supervisor [Prof. Tom Bäckström](https://research.aalto.fi/en/persons/tom-bäckström),
    who supported me and was the other contributor for this work.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢我的博士项目导师[Prof. Tom Bäckström](https://research.aalto.fi/en/persons/tom-bäckström)，他支持了我并为这项工作作出了贡献。
- en: '**References**'
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: '[1] M. H. Vali and T. Bäckström, “Stochastic Optimization of Vector Quantization
    Methods in Application to Speech and Image Processing,” in *Proceedings of ICASSP*,
    2023.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] M. H. Vali 和 T. Bäckström，“向量量化方法在语音和图像处理中的随机优化”，载于 *ICASSP会议论文集*，2023年。'
- en: '[2] A. Razavi, A. van den Oord, and O. Vinyals, “Generating diverse high-fidelity
    images with VQ-VAE-2,” in *Proceedings of NeurIPS*, 2019.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] A. Razavi、A. van den Oord 和 O. Vinyals，“使用VQ-VAE-2生成多样化的高保真图像”，载于 *NeurIPS会议论文集*，2019年。'
- en: '[3] C. Gârbacea, A. van den Oord, Y. Li, F. S. C. Lim, A. Luebs, O. Vinyals,
    and T. C. Walters, “Low bit-rate speech coding with VQ-VAE and a Wavenet decoder,”
    in *Proceedings of ICASSP*, 2019.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] C. Gârbacea、A. van den Oord、Y. Li、F. S. C. Lim、A. Luebs、O. Vinyals 和 T.
    C. Walters，“使用VQ-VAE和Wavenet解码器的低比特率语音编码”，载于 *ICASSP会议论文集*，2019年。'
- en: '[4] B. van Niekerk, L. Nortje, and H. Kamper, “Vector-quantized neural networks
    for acoustic unit discovery in the zerospeech 2020 challenge,” in *Proceedings
    of Interspeech*, 2020.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] B. van Niekerk、L. Nortje 和 H. Kamper，“用于零语音2020挑战中的声学单元发现的向量量化神经网络”，载于
    *Interspeech会议论文集*，2020年。'
- en: '[5] S. Ding and R. Gutierrez-Osuna, “Group latent embedding for vector quantized
    variational autoencoder in non-parallel voice conversion,” in *Proceedings of
    Interspeech*, 2019.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] S. Ding 和 R. Gutierrez-Osuna，“用于非平行语音转换的向量量化变分自编码器的群体潜在嵌入，”见于 *Interspeech
    会议录*，2019年。'
- en: '[6] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford, and I. Sutskever,
    “Jukebox: a generative model for music,” *arXiv preprint arXiv:2005.00341*, 2020.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford 和 I. Sutskever，“Jukebox:
    一种音乐生成模型，” *arXiv 预印本 arXiv:2005.00341*，2020年。'
- en: '[7] A. Tjandra, B. Sisman, M. Zhang, S. Sakti, H. Li, and S. Nakamura, “VQVAE
    unsupervised unit discovery and multi-scale code2spec inverter for Zerospeech
    challenge 2019,” in *Proceedings of Interspeech*, 2019.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] A. Tjandra, B. Sisman, M. Zhang, S. Sakti, H. Li 和 S. Nakamura，“VQVAE 无监督单元发现及多尺度
    code2spec 逆变器用于 Zerospeech 挑战 2019，”见于 *Interspeech 会议录*，2019年。'
- en: '[8] X. Wang, S. Takaki, J. Yamagishi, S. King, and K. Tokuda, “A vector quantized
    variational autoencoder (VQ-VAE) autoregressive neural F0 model for statistical
    parametric speech synthesis,” *IEEE Transactions on Audio, Speech, and Language
    Processing*, 2020.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] X. Wang, S. Takaki, J. Yamagishi, S. King 和 K. Tokuda，“用于统计参数语音合成的向量量化变分自编码器
    (VQ-VAE) 自回归神经 F0 模型，” *IEEE 音频、语音与语言处理学报*，2020年。'
- en: '[9] A. Babenko and V. Lempitsky, “Additive quantization for extreme vector
    compression,” in *Proceedings of CVPR*, 2014.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] A. Babenko 和 V. Lempitsky，“极端向量压缩的加性量化，”见于 *CVPR 会议录*，2014年。'
- en: '[10] Y. Bengio, N. Léonard, and A. Courville, “Estimating or Propagating Gradients
    Through Stochastic Neurons for Conditional Computation,” a*rXiv preprint arXiv:1308.3432,*
    2013.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Y. Bengio, N. Léonard 和 A. Courville，“通过随机神经元估计或传播梯度以进行条件计算，” *arXiv 预印本
    arXiv:1308.3432*，2013年。'
- en: '[11] M. H. Vali and T. Bäckström, “NSVQ: Noise Substitution in Vector Quantization
    for Machine Learning,” *IEEE Access*, vol. 10, 2022.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] M. H. Vali 和 T. Bäckström，“NSVQ: 机器学习中向量量化的噪声替代，” *IEEE Access*，第10卷，2022年。'
- en: '[12] H. Jegou, M. Douze, and C. Schmid, “Product Quantization for Nearest Neighbor
    Search,” *IEEE Transactions on Pattern Analysis and Machine Intelligence*, vol.
    33, no. 1, pp. 117–128, 2010.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] H. Jegou, M. Douze 和 C. Schmid，“用于最近邻搜索的产品量化，” *IEEE 计算机学会模式分析与机器智能学报*，第33卷，第1期，页码
    117–128，2010年。'
- en: '[13] M. H. Vali and T. Bäckström, “End-to-End Optimized Multi-Stage Vector
    Quantization of Spectral Envelopes for Speech and Audio Coding,” in *Proceedings
    of Interspeech*, 2021.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] M. H. Vali 和 T. Bäckström，“端到端优化的多阶段光谱包络向量量化用于语音和音频编码，”见于 *Interspeech
    会议录*，2021年。'
- en: '[14] [https://gitlab.com/speech-interaction-technology-aalto-university/vq-variants](https://gitlab.com/speech-interaction-technology-aalto-university/vq-variants)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] [https://gitlab.com/speech-interaction-technology-aalto-university/vq-variants](https://gitlab.com/speech-interaction-technology-aalto-university/vq-variants)'
