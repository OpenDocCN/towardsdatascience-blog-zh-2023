- en: Building an AI to Recognize my Handwriting — Part I
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立一个能够识别我手写字的人工智能 — 第一部分
- en: 原文：[https://towardsdatascience.com/building-an-ai-to-recognize-my-handwriting-part-i-7bef0d3cdc46](https://towardsdatascience.com/building-an-ai-to-recognize-my-handwriting-part-i-7bef0d3cdc46)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-an-ai-to-recognize-my-handwriting-part-i-7bef0d3cdc46](https://towardsdatascience.com/building-an-ai-to-recognize-my-handwriting-part-i-7bef0d3cdc46)
- en: The theoretical (and practical) starting point
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论（和实践）的出发点
- en: '[](https://jonas-schroeder.medium.com/?source=post_page-----7bef0d3cdc46--------------------------------)[![Jonas
    Schröder](../Images/2ceb59a8a0de7331311c81c32fcaea06.png)](https://jonas-schroeder.medium.com/?source=post_page-----7bef0d3cdc46--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7bef0d3cdc46--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7bef0d3cdc46--------------------------------)
    [Jonas Schröder](https://jonas-schroeder.medium.com/?source=post_page-----7bef0d3cdc46--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jonas-schroeder.medium.com/?source=post_page-----7bef0d3cdc46--------------------------------)[![Jonas
    Schröder](../Images/2ceb59a8a0de7331311c81c32fcaea06.png)](https://jonas-schroeder.medium.com/?source=post_page-----7bef0d3cdc46--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7bef0d3cdc46--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7bef0d3cdc46--------------------------------)
    [Jonas Schröder](https://jonas-schroeder.medium.com/?source=post_page-----7bef0d3cdc46--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7bef0d3cdc46--------------------------------)
    ·12 min read·Apr 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----7bef0d3cdc46--------------------------------)
    ·12分钟阅读·2023年4月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/383b2040b10b7cd8b492bb2bf80f1f94.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/383b2040b10b7cd8b492bb2bf80f1f94.png)'
- en: Image by the Author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Roughly ten years ago, inspired by Tim Ferriss and other authors in the self-help
    genre, I started writing (by hand) regularly in notebooks (the physical kind).
    I must have filled 10–15 books by now. Wouldn’t it be great to have them digitalized?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大约十年前，受到Tim Ferriss和其他自助书籍作者的启发，我开始定期在笔记本（纸质的那种）上手写。我现在已经填满了10到15本笔记本。把它们数字化岂不是很好吗？
- en: 'This article series follows me on my quest to develop an AI that does that:
    that **turns my handwritten notes into proper plain text files**. Judging by the
    way my handwriting looks, this will be very challenging indeed.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本系列文章记录了我开发一个能够**将我的手写笔记转换为正式纯文本文件**的人工智能的过程。根据我的手写字的样子，这将确实非常具有挑战性。
- en: This first article, Part I, will cover the fundamentals. I will start by **explaining
    my motivation a bit further**, followed by introducing the **theoretic outline**
    of how one could approach that.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这第一篇文章，第一部分，将涵盖基础知识。我将首先**进一步解释我的动机**，然后介绍**理论框架**，说明如何可以解决这个问题。
- en: I will briefly introduce **Convolutional Neural Networks (CNNs)**, a special
    type of artifical neural networks designed specifically for image recognition.
    After that, I will try an automated way of “recognizing” words in my handwriting
    with the naive goal of preventing to have to label and annotate my input data
    manually.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我将简要介绍**卷积神经网络（CNNs）**，这是一种专门为图像识别设计的人工神经网络。之后，我将尝试一种自动化的方式来“识别”我的手写字，目的是避免手动标注和注释我的输入数据。
- en: The subsequent parts will be more hands-on and actually use CNNs with training
    data. But I think this Part I serves as a necessary foundation to follow along,
    even when it ends with a bummer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将更加实用，并实际使用CNNs与训练数据。但我认为这第一部分作为必要的基础是有用的，即使它以令人失望的结局告终。
- en: Like many of my articles, **I’ll publish as I progress, dealing with upcoming
    challenges yet unknown**, taking the reader with me on the journey.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 像我许多的文章一样，**我会在进展中发布，处理尚未知道的挑战**，带领读者一起体验这个过程。
- en: Following the feedback I got for my [“Data Scientist turning Quant” series](https://medium.com/@jonas-schroeder/data-scientist-turning-quant-i-why-im-becoming-an-algo-trader-28e852f9cfc4),
    I will **upload the notebooks and files to GitHub** for a better follow-along.
    They are available here ([GitHub link](https://github.com/JonasSchroeder/project_handwriting_recognition))
    and will be updated regularily.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我收到的关于[“数据科学家转量化交易”系列](https://medium.com/@jonas-schroeder/data-scientist-turning-quant-i-why-im-becoming-an-algo-trader-28e852f9cfc4)的反馈，我将**将笔记本和文件上传到GitHub**以便更好地跟随。它们可以在这里找到（[GitHub链接](https://github.com/JonasSchroeder/project_handwriting_recognition)），并将定期更新。
- en: I hope you enjoy reading this as much as I enjoyed producing. Feel free to [contact
    me](https://www.linkedin.com/in/jonas-schröder-914a338a/) for further ideas or
    questions, or to comment on this post.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你阅读这些内容时能像我创作时那样享受。随时欢迎[联系我](https://www.linkedin.com/in/jonas-schröder-914a338a/)获取更多想法或问题，或者对这篇文章进行评论。
- en: Best,
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最好，
- en: '*Jonas*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*乔纳斯*'
- en: 'My Motivation: A Stack of Personal Notebooks'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我的动机：一堆个人笔记本
- en: 'For ten years now, I do something that is called “journaling”. Rather than
    the classical “dear diary”-kind of writing, the purpose is not to summarize details
    of your day every day, things that are mostly irrelevant the next week anyway,
    but rather to write in order to sort your thoughts about stuff. For example: where
    you’re at right now, where you could go, and what challenged you recently. Or
    generally noteworthy experiences. For me it covers a dual purpose: **enabling
    reflection today** as well as **cataloging thought processes for reference in
    the future**.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这十年来，我一直在做一种叫做“日记记录”的事情。与传统的“亲爱的日记”式写作不同，这种记录的目的是为了整理对各种事情的思考，而不是每天总结你的一天细节，这些细节通常在下周就变得无关紧要。比如：你现在的状况，你可能去哪里，以及最近你面临的挑战。或者是一般值得注意的经历。对我来说，它有双重目的：**今天能够反思**以及**将思维过程归档以备未来参考**。
- en: Anyway, I like doing it and over the years I finished something around 15 notebooks.
    They are quite valuable to me as they followed my life, covering worries and challenges
    as well as highlights and life-changing moments. I’m picturing myself reading
    through them in one or two decades, filled with nostalgia. Hence, I want to keep
    them!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，我喜欢这样做，多年来我完成了大约15本笔记本。对我来说，它们非常宝贵，因为它们记录了我的生活，涵盖了担忧和挑战，以及亮点和改变人生的时刻。我想象着在一两十年后翻阅这些笔记本，充满了怀旧之情。因此，我想保留它们！
- en: Right now they are scattered in two different places in Germany, increasing
    the likelihood of losing a maximum of half of them, say in an unexpected fire.
    The more likely threat of course is **time, our old enemy**. CDs stop working
    after 25 years and only god knows how long my notes-on-paper will survive. I once
    found some old writings from my time in school. They were quite pale already.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 目前它们散落在德国的两个不同地方，这增加了在意外火灾中丢失一半的可能性。当然，更可能的威胁是**时间，我们的老敌人**。光盘在25年后会停止工作，而只有上帝知道我的纸质笔记能存活多久。我曾经找到过一些我在学校时写的旧文字。它们已经相当模糊了。
- en: I was thinking about digitalizing them for a while. There are service providers
    for sure! However, since the content is extremely personal, I did not want to
    share it with a third party.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我考虑过将这些内容数字化一段时间了。肯定有服务提供商！然而，由于内容极其个人化，我不想与第三方分享。
- en: Working as a professional Data Scientist, I know of the possibility of building
    and training **my own image recognition and OCR models.** Theoretically I know
    what to do. But I never did it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名专业的数据科学家，我知道可以建立和训练**我自己的图像识别和OCR模型**的可能性。我理论上知道该怎么做。但我从未做过。
- en: Furthermore, I know there are plenty of models available that are already pre-trained
    on handwritings, and that I can tune for my own data set. Sure, running them locally
    wouldn’t be considered third party in this context. However, again, judging by
    my own handwriting, I am pretty sure that there’s no system currently available
    that is “intelligent” enough to understand what I wrote.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我知道有很多模型已经在手写文字上预训练过，并且我可以针对自己的数据集进行调整。当然，在这种情况下，局部运行它们不会被视为第三方。然而，再次根据我自己的笔迹判断，我很确定目前没有任何系统“足够智能”到能理解我写的内容。
- en: 'Long story short, this is my motivation. My goal is as simple: **saving my
    years of work by digitalizing them using AI, while getting hands-on experience
    in building an OCR system.**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 长话短说，这就是我的动力。我的目标很简单：**通过使用AI数字化我多年的工作，同时获取构建OCR系统的实际经验**。
- en: I did not want to read too much about how other people are approaching this
    or about “what you’re supposed to do” as it would hinder my learning experience.
    I am expecting to fail at some point, facing yet another challenge to solve. Repeat.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我不想阅读太多关于其他人如何处理这个问题或“你应该做什么”的内容，因为这会妨碍我的学习体验。我预期会在某个时候失败，面临另一个需要解决的挑战。重复。
- en: Process Outline and Tech Used
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理流程概述和使用的技术
- en: 'Now that my motivation has become clear, it’s time to think about what we actually
    need to achieve it. Simply speaking, I am expecting to have a pipeline consisting
    of three parts: pre-processing, main processing (CNN), post-processing.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我的动机已经明确，是时候考虑我们实际需要做什么了。简单来说，我期望有一个由三部分组成的流程：预处理、主要处理（CNN）和后处理。
- en: '![](../Images/833c6cb4549ce4fc788cd6c9c5b4e85e.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/833c6cb4549ce4fc788cd6c9c5b4e85e.png)'
- en: Image by the Author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Pre-processing
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理
- en: I need labeled image data of my handwriting that are processed in a way that
    increases the system’s speed and performance metrics. There are different ways
    for me to test and experiment with, for example different image sizes or number
    of channels. I will mostly use **OpenCV and Numpy** for preprocessing the data.
    Part II will introduce **LabelImg**, the open source tool I will use to create
    annotated input data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要我的手写图像数据，并以一种提高系统速度和性能指标的方式进行处理。我可以测试和实验不同的方式，例如不同的图像大小或通道数。我将主要使用**OpenCV和Numpy**来预处理数据。第二部分将介绍**LabelImg**，这是我用来创建标注输入数据的开源工具。
- en: Main processing
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主要处理
- en: This is where the magic happens, where input images in form of matrices of floating
    numbers are turned into a vector of predicted probabilities of belonging to a
    certain class. In simpler terms, the output would be something like “image_1 is
    the word ‘Test’ with 90% probability and ‘Toast’ with 10%”.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是魔法发生的地方，在这里，输入图像以浮点数矩阵的形式被转换为一个预测属于某一类别的概率向量。简而言之，输出结果可能类似于“image_1是‘Test’，概率为90%，‘Toast’，概率为10%”。
- en: I’ll use various **Convolutional Neural Networks (CNNs)**, the go-to-architecture
    for image recognition. If you’re new to CNNs, I will briefly describe their main
    properties later in this article. I won’t be using any pre-trained networks, following
    my motivation above and assuming that no person in the world has type of ugly
    handwriting as me.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用各种**卷积神经网络（CNNs）**，这是进行图像识别的首选架构。如果你对CNNs不太熟悉，我将在本文后面简要描述它们的主要属性。我不会使用任何预训练网络，依据我之前的动机，并假设世界上没有人有像我一样难看的手写字。
- en: I will not start fully from scratch, though. Instead I will define and deal
    with the neural networks using **TensorFlow** and **Keras**, and all of their
    available classes and helper functions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，我不会完全从头开始。我将定义并使用**TensorFlow**和**Keras**来处理神经网络，以及它们所有可用的类和辅助函数。
- en: Post-processing
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后处理
- en: At this point we will have a trained CNN that recognized my handwriting more
    or less well. However, this output probably needs to be cleaned and processed
    further, using **various NLP methods**.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此时我们将有一个训练好的CNN，能够或多或少地识别我的手写字。然而，这一输出可能需要进一步清理和处理，使用**各种NLP方法**。
- en: 'Example: The system might predict a word to be “Tost” but this word doesn’t
    exist in the German language. Another model down the pipeline might correct it
    to “Test” based on similarity. The whole post-processing part of the system won’t
    be covered in this nor the next article since I am still very far from knowing
    how to do that.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 例子：系统可能预测一个词为“Tost”，但这个词在德语中并不存在。流程中的另一个模型可能基于相似性将其纠正为“Test”。整个后处理部分在本文及下篇文章中不会涉及，因为我仍然离知道如何实现这一点很远。
- en: So much about the three-part system I am expecting to build. Since CNNs are
    central to Part I and Part II, I will move on to briefly introduce in a very non-scientific,
    pragmatic way what Convolutional Neural Networks (CNNs) are. This summary is mostly
    taken from [Aurélien Géron’s great, great book “Hands-on Machine Learning with
    Scikit-Learn, Keras & TensorFlow, 2nd Edition”](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/),
    my absolute favorite introduction to practical Machine Learning.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我期望构建的三部分系统已经讲了很多。由于卷积神经网络（CNNs）在第一部分和第二部分中占据核心地位，我将以一种非常非科学、务实的方式简要介绍卷积神经网络（CNNs）。这个总结主要取自于[Aurélien
    Géron的《动手机器学习：使用Scikit-Learn、Keras和TensorFlow（第2版）》](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/)，这是我最喜欢的实用机器学习入门书籍。
- en: A Very Short Introduction of CNNs
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs）简短介绍
- en: If you roughly know what Artificial Neural Networks (ANNs) are and how they
    work for classification tasks, you’ll be able to grasp the following quite easily.
    You’ll find a short list of sources about CNNs at the end of this section.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你大致了解什么是人工神经网络（ANNs）及其在分类任务中的工作原理，你将能够很容易地理解接下来的内容。你会在本节末尾找到关于CNN的简短资源列表。
- en: 'CNNs build on studies from the late 1950s of how our brain processes visual
    inputs. These studies resulted into a [Nobel Prize in 1981](https://www.nobelprize.org/prizes/medicine/1981/summary/).
    The researchers’ main finding: **many neurons only react to visual stimuli located
    in a small region of the visual field.** These fields overlap, piecing together
    what we see as a whole. Furthermore, two neurons might share the same receptive
    field but one only reacts to horizontal, the other to vertical lines.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: CNN建立在1950年代末期关于我们大脑如何处理视觉输入的研究基础上。这些研究导致了[1981年诺贝尔奖](https://www.nobelprize.org/prizes/medicine/1981/summary/)。研究人员的主要发现是：**许多神经元只对视觉场中小区域的视觉刺激做出反应**。这些领域相互重叠，拼凑成我们所见的整体。此外，两个神经元可能共享相同的感受野，但一个只对水平线做出反应，另一个则对垂直线做出反应。
- en: Based in these findings, computer scientists started to create neural networks
    designed specifically for the task of image recognition. In 1998, Yann LeCun (currently
    Chief AI Scientist at Meta) created the [LeNet-5](https://en.wikipedia.org/wiki/LeNet)
    architecture for recognizing handwritten characters.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些发现，计算机科学家开始创建专门为图像识别任务设计的神经网络。1998年，Yann LeCun（现为Meta的首席AI科学家）创建了用于识别手写字符的[LeNet-5](https://en.wikipedia.org/wiki/LeNet)架构。
- en: So what differentiates a CNN to other (deep) neural networks? At its core CNNs
    are similar to standard ANNs where higher level neurons take input from the output
    of lower level neurons to detect various patterns in the data, getting from simple
    to complex as the data progresses through the network. However, **CNNs have two
    special building blocks called Convolution Layer and Pooling Layer.**
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，CNN与其他（深度）神经网络有什么不同？本质上，CNN与标准ANN类似，其中高级别的神经元从低级别的神经元输出中获取输入，以检测数据中的各种模式，随着数据在网络中传播，从简单到复杂。然而，**CNN有两个特殊的构建块，称为卷积层和池化层**。
- en: The motivation for such building blocks are quite easy to grasp. Take a relatively
    small image of 100px by 100px. This translates to 10,000 inputs (30,000 if its
    a color image). For a fully connected standard ANN with a first layer of 1,000
    neurons, this would translate to 10,000,000 connections to be fitted. Convolution
    an Pooling Layers allow only partially connecting the layers. Furthermore, CNNs
    recognize patterns regardless of where they appear in the image while standard
    ANNs would have trouble with shifted images. Many, many advantages of using these
    building blocks. Now more about them.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些构建块的动机很容易理解。以一个相对较小的图像100px x 100px为例。这意味着有10,000个输入（如果是彩色图像则为30,000）。对于一个具有1,000个神经元的全连接标准ANN，这将转化为10,000,000个连接需要适配。卷积层和池化层只允许部分连接这些层。此外，CNN能够识别图像中出现的各种模式，而标准ANN则在处理偏移图像时会遇到困难。使用这些构建块有很多优点。现在了解更多关于它们的内容。
- en: Convolution Layer
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层
- en: Following the ideas of the researchers mentioned above, neurons in a convolution
    layer are only connected to the pixels in their receptive field (if it’s the first
    layer) instead of the whole image. In later layers, neurons are only connected
    to the outputs in a small rectangle. It’s a simple idea but hard to describe in
    words alone. The image below could help.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述研究人员的想法，卷积层中的神经元仅与其感受野中的像素相连（如果这是第一层），而不是与整个图像相连。在后续层中，神经元仅与小矩形中的输出相连。这是一个简单的想法，但仅用语言很难描述。下面的图像可能会有所帮助。
- en: '![](../Images/fff293357945e7f1d58d1fca7db08cbd.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fff293357945e7f1d58d1fca7db08cbd.png)'
- en: By Aphex34 — Own work, CC BY-SA 4.0, [https://commons.wikimedia.org/w/index.php?curid=45679374](https://commons.wikimedia.org/w/index.php?curid=45679374)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由Aphex34 — 自作，CC BY-SA 4.0，[https://commons.wikimedia.org/w/index.php?curid=45679374](https://commons.wikimedia.org/w/index.php?curid=45679374)
- en: This receptive field rectangular now slides (known as stride) over the image
    and outputs one value each time, thus reducing the size of the image in next layer.
    The result are filters, also known as convolutions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这个感受野矩形现在滑动（称为步幅）在图像上，每次输出一个值，从而在下一层减少图像的大小。结果是过滤器，也称为卷积。
- en: '![](../Images/205e2cfecf6812685e73ece2e2ec73dd.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/205e2cfecf6812685e73ece2e2ec73dd.png)'
- en: Image by the Author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: During training, the **CNN will learn the most useful filters**, like horizontal
    vs. vertical lines, which can be visualized. These may start out quite simple
    but are later combined to more and more complex filters, as data progresses through
    the network. Filters used on actual images are known as Feature Maps (i.e., the
    dot product of the filter and the overlayed image), highlighting which pixel activated
    the filter.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，**CNN将学习最有用的滤波器**，如水平线与垂直线，这些可以被可视化。这些滤波器可能一开始非常简单，但随着数据在网络中进展，它们会被组合成越来越复杂的滤波器。应用于实际图像的滤波器被称为特征图（Feature
    Maps）（即滤波器和叠加图像的点积），突出显示激活滤波器的像素。
- en: '![](../Images/47441d58aa2831032117e46838158199.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47441d58aa2831032117e46838158199.png)'
- en: Image by the Author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Pooling Layer
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化层
- en: To further reduce computational load, so-called Pooling Layers are used to aggregate
    information from the input to a reduced output, used as input for the next (convolution)
    layer. This process is also known as sub-sampling. Like convolutional layers,
    pooling layers have a limited receptive field and slide over the input image.
    However, the stride is often set in such a way that receptive fields are not overlapping.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步减少计算负担，所谓的池化层用于将输入的信息聚合到一个减少的输出中，作为下一个（卷积）层的输入。这个过程也被称为子采样。像卷积层一样，池化层具有有限的感受野，并在输入图像上滑动。然而，步幅通常设置为使得感受野不重叠。
- en: For example, nowadays commonly used Max Pooling Layers output the maximum value
    of all neurons within it’s sight, thus keeping only the most relevant pixel information.
    The image below visualizes that.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如今常用的最大池化层（Max Pooling Layers）输出其视野内所有神经元的最大值，从而只保留最相关的像素信息。下图可视化了这一点。
- en: '![](../Images/3e0fcac1c038243911d252d6ea56f715.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e0fcac1c038243911d252d6ea56f715.png)'
- en: By Aphex34 — Own work, CC BY-SA 4.0, [https://commons.wikimedia.org/w/index.php?curid=45673581](https://commons.wikimedia.org/w/index.php?curid=45673581)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由Aphex34创作，CC BY-SA 4.0，[https://commons.wikimedia.org/w/index.php?curid=45673581](https://commons.wikimedia.org/w/index.php?curid=45673581)
- en: Pooling layers can be quite destructive as they throw away 80–90% of the information.
    However, they also add some invariance to the data that can reduce the risk of
    overfitting to specific but not generalizable details.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层可能非常具有破坏性，因为它们丢弃了80-90%的信息。然而，它们也为数据添加了一些不变性，从而减少了对特定但不可泛化的细节的过拟合风险。
- en: Output Layer
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出层
- en: Pooling layers often follow convolution layers, a pattern that is repeated a
    couple of times, until the outputs are flattened (from matrices to vector) to
    have as many final outputs as classes expected. For example, if we want to classify
    handwritten digits from 0 to 9, we would use a dense layer at the end with 10
    outputs, and a softmax activation function, if we want to predict the probability
    of an image belonging to each of the ten possibilities.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层通常跟随卷积层，这种模式重复几次，直到输出被展平（从矩阵到向量），以便得到与预期类别一样多的最终输出。例如，如果我们想要分类0到9的手写数字，我们会在最后使用一个具有10个输出的全连接层，以及一个softmax激活函数，如果我们想要预测图像属于十种可能性中的每一种的概率。
- en: The final output after feeding an image of an “8” could be the vector [0.2,0,0,0,0,0,0.1,0,0.7,0],
    meaning that the model predicted “8” to be most likely, but it could have been
    a “0” with 20% and a “6” with 10% probability. Depending on the training images,
    these handwritten digits could be quite close to another.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入“8”的图像之后的最终输出可能是向量[0.2,0,0,0,0,0,0.1,0,0.7,0]，这意味着模型预测“8”的可能性最大，但也可能是“0”有20%以及“6”有10%的概率。根据训练图像，这些手写数字可能非常接近。
- en: So that’s it, all you need to know to follow along. CNNs are a special kind
    of artificial neural networks used for image recognition. They use convolutional
    layers to learn simple and complex patterns about the images, and pooling layers
    to reduce the computational load and risk of overfitting.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，你所需要了解的全部内容就绪。CNNs是一种用于图像识别的特殊人工神经网络。它们使用卷积层学习图像的简单和复杂模式，并使用池化层减少计算负担和过拟合的风险。
- en: Of course there’s more to CNNs and the visual nature of their input data makes
    them naturally easier to understand, well, visually. Here are some further basic
    sources helping you understand how CNNs work.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，CNNs（卷积神经网络）还有更多的内容，它们的输入数据的视觉性质使得它们在视觉上更容易理解。这里有一些进一步的基础资源，帮助你理解CNNs的工作原理。
- en: 'Wikipedia: [https://en.wikipedia.org/wiki/Convolutional_neural_network](https://en.wikipedia.org/wiki/Convolutional_neural_network)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科：[https://en.wikipedia.org/wiki/Convolutional_neural_network](https://en.wikipedia.org/wiki/Convolutional_neural_network)
- en: 'Josh Starmer’s (humorous but nonetheless highly informational) QuestStats:
    [https://www.youtube.com/watch?v=HGwBXDKFk9I](https://www.youtube.com/watch?v=HGwBXDKFk9I)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 'Josh Starmer 的（幽默但 nonetheless 高度信息性的）QuestStats: [https://www.youtube.com/watch?v=HGwBXDKFk9I](https://www.youtube.com/watch?v=HGwBXDKFk9I)'
- en: If you still don’t have enough, 3Blue1Brown’s video goes deeper into what convolutions
    are and how they are used in all sorts of applications, for example for image
    processing (starting 8:22).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仍然觉得不够，3Blue1Brown 的视频深入探讨了卷积是什么以及它们如何在各种应用中使用，例如图像处理（从 8:22 开始）。
- en: Getting Started with My Own Handwriting
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用我自己的手写文字
- en: After outlining what tech we would need and how it theoretically would work,
    it is now time to get more practical aka. start coding. You can see [my code and
    files here](https://github.com/JonasSchroeder/project_handwriting_recognition).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在概述了我们需要的技术及其理论工作方式后，现在是时候变得更实际，即开始编码了。你可以在 [我的代码和文件这里](https://github.com/JonasSchroeder/project_handwriting_recognition)
    查看。
- en: I started by writing a small letter on paper, taking a picture of it, and reading
    it on my computer using OpenCV. Don’t mind that it’s in German. The computer doesn’t
    either (yet).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我开始时在纸上写了一封小信，拍了一张照片，并使用 OpenCV 在我的电脑上读取它。别在意它是德语的。电脑也不会在意（目前还不）。
- en: '![](../Images/feecac08d776ea67c3b1c59ec7e9171e.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/feecac08d776ea67c3b1c59ec7e9171e.png)'
- en: Image by the Author
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Ignoring my actual task for now, **I was looking for a way to automatically
    detect what’s paper and what’s ink**, meaning detecting the text. My goal was
    to find a way to **cut out the words in an automated manner** while ignoring the
    actual meaning of each word for now.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 先暂时忽略我的实际任务，**我在寻找一种自动检测纸张和墨水的方法**，即检测文本。我的目标是找到一种**以自动化的方式裁剪出单词**的方法，而暂时忽略每个单词的实际含义。
- en: I used something called line-text segmentation, by adapting code I found in
    this [notebook on GitHub](https://github.com/computervisionpro/yt/blob/main/line-text-segmentation/tutorial20.ipynb).
    The process in simple terms aims at **identifying lines of text first, then loop
    through lines to identify words**.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了所谓的行文本分割，通过调整我在这个 [GitHub 笔记本](https://github.com/computervisionpro/yt/blob/main/line-text-segmentation/tutorial20.ipynb)
    中找到的代码。简单来说，这个过程旨在**首先识别文本行，然后遍历这些行以识别单词**。
- en: It starts by **binarizing the image** so that each pixel can be either 0 (black)
    or 1 (white). Similar to what a Pooling Layer does, **the next step is dilation**
    where a kernel (aka. receptive field) slides over the image, replacing the image
    pixel by the maximum value in that field before sliding further. The result is
    a “growing” part of the image, thus the name dilation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 它开始于**对图像进行二值化**，使每个像素可以是 0（黑色）或 1（白色）。类似于池化层的作用，**下一步是膨胀**，在这个步骤中，一个核（即接收域）在图像上滑动，将图像像素替换为该领域中的最大值，然后继续滑动。结果是图像的“生长”部分，因此命名为膨胀。
- en: Again, rather than understanding by reading, seeing what’s actually happening
    is easier. The left image shows my letter after binarizing, the right after dilation.
    The effect of dilation is similar to what we would get when using a text marker.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，与通过阅读理解相比，直接看到实际发生的情况更容易。左侧图像显示了我的信件在二值化后的样子，右侧则是经过膨胀处理后的样子。膨胀的效果类似于我们使用文本标记器时的效果。
- en: '![](../Images/62777a11af356059d75d1420803a59b6.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62777a11af356059d75d1420803a59b6.png)'
- en: Image by the Author
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: It’s just a small step to get from this to line detection. I will use OpenCV’s
    findContours function. The blue boxes below are supposed to identify the lines
    in which my text is written. As you can see, that worked better on some parts
    than others. Looping through the lines to mark individual words leads to the image
    with the yellow boxes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一步到线检测只是一个小步骤。我将使用 OpenCV 的 findContours 函数。下方的蓝色框应该标识出我文本所写的行。正如你所见，这在某些部分效果更好。通过循环处理这些行以标记单个单词会生成带有黄色框的图像。
- en: '![](../Images/82b0ea62e4440c2b1241c3d3dd83c0a7.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82b0ea62e4440c2b1241c3d3dd83c0a7.png)'
- en: This looks okay, right? However, it gives me 346 identified words (instead of
    the 58 that are actually present). The **approach lead to duplicates**, identical
    identified areas in my image. Even after removing these obvious duplicates, I
    am left with 94 words. Those are overlapping parts of a word, as the examples
    below show.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来还不错，对吧？然而，它给了我 346 个识别出的单词（而实际上只有 58 个）。**这种方法导致了重复**，在我的图像中出现了相同的识别区域。即使在去除这些明显的重复之后，我仍然剩下
    94 个单词。这些是单词的重叠部分，如下例所示。
- en: '![](../Images/baccd189fd5afa84ffb886e782472668.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/baccd189fd5afa84ffb886e782472668.png)'
- en: Image by the Author
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: I now had snippets of my letter representing words but most of the time I would
    need a lot of manually going through the samples to delete nonsense ones. Furthermore,
    I would need to **create some kind of lookup table** stating that image_00001.jpg
    means “ich” and image_00002.jpg “Dokumente”.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我有了表示单词的信件片段，但大多数时候，我需要大量手动浏览样本以删除无意义的部分。此外，我还需要**创建某种查找表**，说明image_00001.jpg代表“ich”，而image_00002.jpg代表“Dokumente”。
- en: So all in all not much is won in terms of efficiency. We might be smarter but
    not yet further in practical terms.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，在效率方面并没有取得太大进展。我们可能更聪明了，但在实际应用方面尚未取得更大进展。
- en: Summary and Conclusion of Part I
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分的总结与结论
- en: I know, I conclude this first article in my series of building and training
    an AI to recognize my handwriting with a bummer. I am sorry! But by re-interpreting
    this failure as challenge we will get the foundation for a much more optimistic
    second part, I promise!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道，我在这个系列的第一篇文章中以一个难题作为结尾。很抱歉！但通过将这个失败重新解读为挑战，我们将为更加乐观的第二部分奠定基础，我保证！
- en: And it’s not like I wasted time here. I introduced the core technology that
    we will use for this, Convolutional Neural Networks (CNNs), how it works, and
    what this type of network architecture differentiates from more standard ones
    you might knew before. It’s also worth knowing why you get into something, not
    just how. Therefore, I outlined my situation and motivation.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这段时间并没有浪费。我介绍了我们将用于此任务的核心技术——卷积神经网络（CNNs），它是如何工作的，以及这种网络架构与您之前可能了解的标准架构有何不同。了解你为何进入某个领域，而不仅仅是如何进入，是很重要的。因此，我概述了我的情况和动机。
- en: '**The main lesson for now is this:** if we want to train a CNN, we need properly
    labeled input data, and we cannot rely on automated ways of creating these, for
    example the line-word segmentation approach using dilution on binarized input
    images.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**目前的主要教训是：** 如果我们想训练一个CNN，我们需要正确标记的输入数据，不能依赖于自动生成这些数据的方法，例如使用稀释技术的行词分割方法在二值化输入图像上。'
- en: In Part II, I will start training a CNN to recognize the words in the letter
    above. I will introduce LabelImg, an open-source tool I use for annotation, in
    order to create properly labeled training dataset of my handwriting.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二部分中，我将开始训练CNN以识别上述信件中的单词。我会介绍LabelImg，这是一款我用来标注的开源工具，以创建正确标记的我的手写训练数据集。
- en: We will see how well this out-of-the-box CNN works compared to other more famous
    architectures like LeNet-5 and VGGNet, and if and how we can improve accuracy
    by tweaking around the data preprocessing knobs available to us.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看看这种非传统的CNN与LeNet-5和VGGNet等更著名的架构相比效果如何，以及通过调整数据预处理的参数，我们是否能提高准确性。
- en: I hope you had fun reading this and will follow along. I can already say that
    Part II too will end with a bummer aka. another challenge. The flip side is that
    there will be a Part III to (hopefully) resolve that, too.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你读得愉快，并会继续关注。我已经可以说，第二部分也将以一个难题，即另一个挑战告终。好的一面是，将会有第三部分来（希望）解决它。
- en: All the best,
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 祝一切顺利，
- en: Jonas
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 乔纳斯
