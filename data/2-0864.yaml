- en: Exploring Token Probabilities as a Means to Filter GPT-3’s Answers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索令牌概率作为过滤 GPT-3 答案的一种手段
- en: 原文：[https://towardsdatascience.com/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c](https://towardsdatascience.com/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c](https://towardsdatascience.com/exploring-token-probabilities-as-a-means-to-filter-gpt-3s-answers-3e7dfc9ca0c)
- en: To build better GPT-3-powered chatbots
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为了构建更好的 GPT-3 驱动的聊天机器人
- en: '[](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[![LucianoSphere
    (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)
    [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[![LucianoSphere
    (Luciano Abriata, PhD)](../Images/a8ae3085d094749bbdd1169cca672b86.png)](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)
    [LucianoSphere (Luciano Abriata, PhD)](https://lucianosphere.medium.com/?source=post_page-----3e7dfc9ca0c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)
    ·12 min read·Jan 19, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3e7dfc9ca0c--------------------------------)
    ·阅读时间12分钟·2023年1月19日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/9db8b157fe2ab50887c47f5f7f1ac837.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9db8b157fe2ab50887c47f5f7f1ac837.png)'
- en: Log probabilities produced by GPT-3 for each token that makes up the displayed
    sentence, made up to test the system. The picture was composed by the author from
    a screenshot of a web app written to carry out these tests, linked near the end
    of the article.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 为构成显示句子的每个令牌生成的对数概率，旨在测试系统。该图片由作者从一个用于执行这些测试的 Web 应用程序的截图中合成，链接在文章的末尾。
- en: As powerful language models become increasingly prevalent, the need for control
    over the content they generate becomes ever more pressing. These models, trained
    on massive amounts of text data, have the ability to generate highly convincing
    written content, from news articles to social media posts. However, without proper
    oversight, they can also produce misinformation or various kinds of harmful content.
    It is thus crucial that apps using these language models attempt to check the
    veracity of the information generated by these AI systems, in order to prevent
    the spread of false, misleading or harmful information.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着强大的语言模型越来越普及，对它们生成的内容进行控制的需求变得更加紧迫。这些模型在大量文本数据上进行训练，能够生成非常有说服力的书面内容，从新闻文章到社交媒体帖子。然而，如果没有适当的监督，它们也可能产生虚假信息或各种有害内容。因此，使用这些语言模型的应用程序必须尝试检查这些
    AI 系统生成的信息的真实性，以防止传播虚假、误导或有害的信息。
- en: 'Like many others, probably including yourself since you are reading this, I
    have used GPT-3 and ChatGPT quite a bit, and in doing so I have identified that
    very often they reply to questions very convincingly yet incorrectly. Indeed,
    I explored this quite deeply when GPT-3 was released, in the form of examinations
    just like those I would take to a student in a science subject:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 像许多人一样，可能包括你自己，因为你正在阅读这篇文章，我已经大量使用了 GPT-3 和 ChatGPT，在这个过程中我发现它们经常以非常有说服力但却不正确的方式回答问题。事实上，当
    GPT-3 发布时，我在进行深入探索，就像我对学生在科学学科中进行的考试一样：
- en: '[](https://pub.towardsai.net/power-limitations-and-use-cases-of-gpt-3-from-my-tests-and-prototype-apps-you-can-replicate-right-89bfb40daf5e?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Power, Limitations, and Use Cases of Gpt-3 From My Tests and Prototype Apps
    You Can Replicate…'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pub.towardsai.net/power-limitations-and-use-cases-of-gpt-3-from-my-tests-and-prototype-apps-you-can-replicate-right-89bfb40daf5e?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## GPT-3 的能力、限制和使用案例：从我的测试和原型应用中你可以复制的……'
- en: Exemplified with smart chatbots that can even listen and talk naturally command
    programs, or help students as full-time…
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过智能聊天机器人展示，它们甚至可以自然地听和说命令程序，或作为全职助手帮助学生……
- en: pub.towardsai.net](https://pub.towardsai.net/power-limitations-and-use-cases-of-gpt-3-from-my-tests-and-prototype-apps-you-can-replicate-right-89bfb40daf5e?source=post_page-----3e7dfc9ca0c--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[更多详情](https://pub.towardsai.net/power-limitations-and-use-cases-of-gpt-3-from-my-tests-and-prototype-apps-you-can-replicate-right-89bfb40daf5e?source=post_page-----3e7dfc9ca0c--------------------------------)'
- en: 'Recently, and carefully because I was aware of these limitations, I eagerly
    started creating my own chatbots powered by GPT-3\. First by patching some PHP
    libraries and writing the corresponding JavaScript code, and more recently purely
    in JavaScript:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，尽管我意识到这些限制，但我还是迫切开始创建由 GPT-3 驱动的聊天机器人。最初通过修补一些 PHP 库并编写相应的 JavaScript 代码，最近则完全使用
    JavaScript：
- en: '[](https://pub.towardsai.net/core-code-to-build-chatgpt-like-bots-in-20-lines-of-javascript-c2a506e5cc9a?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Core Code to Build ChatGPT-like Bots in < 20 Lines of JavaScript!'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 用少于 20 行 JavaScript 代码构建类似 ChatGPT 的机器人核心代码！](https://pub.towardsai.net/core-code-to-build-chatgpt-like-bots-in-20-lines-of-javascript-c2a506e5cc9a?source=post_page-----3e7dfc9ca0c--------------------------------)'
- en: No more PHP like in my previous examples. By using the modern fetch() function
    right in JavaScript, it’s now easier…
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不再像之前的示例那样使用 PHP。通过直接在 JavaScript 中使用现代 fetch() 函数，现在更容易...
- en: pub.towardsai.net](https://pub.towardsai.net/core-code-to-build-chatgpt-like-bots-in-20-lines-of-javascript-c2a506e5cc9a?source=post_page-----3e7dfc9ca0c--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[更多详情](https://pub.towardsai.net/core-code-to-build-chatgpt-like-bots-in-20-lines-of-javascript-c2a506e5cc9a?source=post_page-----3e7dfc9ca0c--------------------------------)'
- en: Working on that last project, i.e. calling GPT-3 from pure JavaScript, I explored
    more of OpenAI’s reference for the GPT-3 API, and found that one can very easily
    retrieve a series of scores associated to each token produced by the language
    model. It turns these scores are actually probabilities in logarithmic form, delivered
    by GPT-3 token by token together with the text prediction. These probabilities
    measure the “probability” of the different tokens that GPT-3 produced. While these
    probabilities could potentially contain information about how sure GPT-3 is about
    the content produced, this is not given. Therefore I set myself to study this
    here hands-on through a series of new JavaScript apps that you can build upon.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理那个最后的项目，即从纯 JavaScript 调用 GPT-3 时，我深入探索了 OpenAI 的 GPT-3 API 参考，发现可以非常容易地检索到与语言模型生成的每个标记相关联的一系列分数。这些分数实际上是以对数形式表示的概率，由
    GPT-3 一次生成一个标记，并与文本预测一起提供。这些概率衡量了 GPT-3 生成的不同标记的“概率”。虽然这些概率可能包含有关 GPT-3 对生成内容的确定性的信息，但这并非给定。因此，我决定通过一系列新的
    JavaScript 应用程序进行动手研究，你可以在这些应用程序的基础上进行扩展。
- en: More specifically, here I will explore how to retrieve these token probabilities
    and what values they take for texts that I know are either correct or wrong. I
    will also probe the effect of few-shot learning on these scores, to know if it
    actually makes GPT-3 more certain about its answers or not.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我将探讨如何检索这些标记概率以及它们在我知道是正确或错误的文本中的取值。我还将探讨少量学习对这些分数的影响，以了解它是否确实使GPT-3对其答案更有信心。
- en: GPT-3 and token log probabilities
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-3 和标记对数概率
- en: If you are reading this, GPT-3 needs no presentation. But in case, suffice to
    say that GPT-3 stands for Generative Pre-trained Transformer (now in version 3
    but actually consisting in various different models each at different version)
    and that it is a state-of-the-art language model that generates written content
    given an input.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在阅读这篇文章，GPT-3 可能无需介绍。但如果需要介绍，GPT-3 代表生成预训练变换器（目前是第3版，但实际上由多个不同版本的模型组成），它是一个先进的语言模型，根据输入生成书面内容。
- en: When you feed some text into GPT-3 (called a “prompt”) it is split into so-called
    tokens, which are units of variable size ranging from single letters to syllables
    and even words (depending on various things). The tokens are propagated through
    the network, which as a result synthesizes new tokens that together form new words,
    sentences, and paragraphs. These texts usually have meaning and quite good grammatic,
    unless you are dealing with an exotic language that GPT-3 hasn’t seen much upon
    training. However, they are not necessarily accurate in their content, especially
    if you expect it to “think” about a problem or make relationships between concepts,
    or if you ask about things that the model hasn’t seen during training (for example
    it won’t know who I am, so it will probably make something up, see example later
    on).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将一些文本输入到GPT-3中（称为“提示”）时，它会被拆分为所谓的标记，这些标记是从单个字母到音节甚至单词的可变大小的单位（根据各种因素）。这些标记在网络中传播，结果合成出新的标记，这些标记一起形成新的单词、句子和段落。这些文本通常具有意义和相当好的语法，除非你处理的是GPT-3在训练中很少见的异域语言。然而，它们的内容不一定准确，特别是如果你期望它“思考”某个问题或在概念之间建立关系，或者如果你询问模型在训练期间未见过的事物（例如，它不会知道我是谁，所以它可能会编造一些东西，见下例）。
- en: 'One important feature of GPT-3 and other large language models is that they
    are “few-shot learners” which means they can process and “understand” some information
    passed on in a prompt, and then may answer a question or execute a task based
    on this information. There a whole preprint explaining this in the arXiv; and
    I have several example projects where I exploit this feature:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3和其他大型语言模型的一个重要特性是它们是“少样本学习者”，这意味着它们可以处理并“理解”在提示中传递的一些信息，然后可能基于这些信息回答问题或执行任务。arXiv上有一篇完整的预印本解释了这一点；我也有几个示例项目利用了这一特性：
- en: '[](https://arxiv.org/abs/2005.14165?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Language Models are Few-Shot Learners'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://arxiv.org/abs/2005.14165?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## 语言模型是少样本学习者'
- en: Recent work has demonstrated substantial gains on many NLP tasks and benchmarks
    by pre-training on a large corpus of…
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最近的工作表明，通过在大规模语料库上进行预训练，许多自然语言处理任务和基准测试取得了显著的进展…
- en: arxiv.org](https://arxiv.org/abs/2005.14165?source=post_page-----3e7dfc9ca0c--------------------------------)
    [](https://lucianosphere.medium.com/why-you-should-and-how-you-can-inform-your-chatbots-with-custom-data-or-wikipedia-access-500995dc87f3?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## Why you should and how you can inform your chatbots with custom data or Wikipedia
    access
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[arxiv.org](https://arxiv.org/abs/2005.14165?source=post_page-----3e7dfc9ca0c--------------------------------)
    [](https://lucianosphere.medium.com/why-you-should-and-how-you-can-inform-your-chatbots-with-custom-data-or-wikipedia-access-500995dc87f3?source=post_page-----3e7dfc9ca0c--------------------------------)
    [## 为什么你应该以及如何用自定义数据或维基百科访问来告知你的聊天机器人'
- en: Extending my purely web-based, GPT3-powered chatbot to know content fed by me
    or that it retrieves automatically from…
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将我完全基于网络的、由GPT-3驱动的聊天机器人扩展为能够了解我提供的内容或自动检索的内容…
- en: lucianosphere.medium.com](https://lucianosphere.medium.com/why-you-should-and-how-you-can-inform-your-chatbots-with-custom-data-or-wikipedia-access-500995dc87f3?source=post_page-----3e7dfc9ca0c--------------------------------)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[lucianosphere.medium.com](https://lucianosphere.medium.com/why-you-should-and-how-you-can-inform-your-chatbots-with-custom-data-or-wikipedia-access-500995dc87f3?source=post_page-----3e7dfc9ca0c--------------------------------)'
- en: Now, the feature of GPT-3 that I’m touching upon here (and that isn’t much discussed
    on the internet, despite its huge importance) is that besides returning text,
    GPT-3 can return a probability associated to each token that composes the created
    text. These probabilities, actually returned in logarithmic form, measure how
    likely each token is to occur in the context of the output text. Lower log probabilities
    indicate less likely words and higher log probabilities indicate more likely words.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我在这里讨论的GPT-3的一个特性（尽管其重要性巨大，但在互联网上讨论不多）是，除了返回文本之外，GPT-3还可以返回与构成生成文本的每个标记相关的概率。这些概率实际上以对数形式返回，测量每个标记在输出文本上下文中出现的可能性。较低的对数概率表示不太可能的词，较高的对数概率表示更可能的词。
- en: 'According to ChatGPT itself, GPT-3 uses these log probabilities to generate
    text that is coherent and grammatically correct; besides, it uses the log probabilities
    to generate the next word based on the most likely word that can come next, allowing
    it to generate contextually accurate text. What I will investigate here is whether
    this also contains information about the accuracy of the content. Spoiler alert:
    yes, at least a bit; and moreover, few-shot learning not only improves the answers
    themselves but also improves log probabilities.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 根据ChatGPT自身的说法，GPT-3使用这些对数概率来生成连贯且语法正确的文本；此外，它使用对数概率来生成下一个词，基于最有可能的下一个词，从而生成语境上准确的文本。我将在这里调查这是否也包含有关内容准确性的信息。剧透：是的，至少有一点；此外，少量示例学习不仅改善了回答本身，还改善了对数概率。
- en: Retrieving log probabilities upon calling GPT-3’s API
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调用GPT-3的API时获取对数概率
- en: It is important to note that GPT-3, like other language models, is not able
    to tell the difference between true and false information. It simply generates
    text based on the patterns it has learned from the data it was trained on and
    what is fed in the prompt for few-shot learning.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，GPT-3和其他语言模型一样，无法区分真实和虚假的信息。它只是基于从训练数据中学到的模式和提示中提供的少量示例生成文本。
- en: Token log probabilities can in principle help detect incorrect information;
    but, how do we get them?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对数概率原则上可以帮助检测不正确的信息；但我们怎么获取它们呢？
- en: 'Here’s a slight modification of the code I presented recently to call GPT-3’s
    API totally from JavaScript, amended to get the token log probabilities as well:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我最近展示的代码的一个小修改，完全用JavaScript调用GPT-3的API，并修改为获取标记对数概率：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The fetch() call includes everything that’s needed to call GPT-3 and get texts
    and token probabilities. And the prompt includes information for few-shot learning,
    placed before the question “Where is Luciano Abriata from?”
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: fetch()调用包括调用GPT-3并获取文本和标记概率所需的一切。提示包括少量示例学习的信息，放在问题“Luciano Abriata来自哪里？”之前。
- en: Testing token probabilities in different scenarios
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试不同场景下的标记概率
- en: Let’s see what happens if we call the above function with a prompt that only
    includes the question “Where is Luciano Abriata from?”, that is, without any assisting
    information that explains I’m from Argentina.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如果我们用一个只包含问题“Luciano Abriata来自哪里？”的提示调用上述函数，会发生什么，也就是说，没有任何解释我来自阿根廷的辅助信息。
- en: 'We expect GPT-3 will not know where I’m from, as I’m not a celebrity. And indeed,
    it “makes up” that I’m from Italy:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望GPT-3不会知道我来自哪里，因为我不是名人。事实上，它“编造”了我来自意大利：
- en: '![](../Images/5d8ac10729f424b7ac93cf949f9aa10c.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5d8ac10729f424b7ac93cf949f9aa10c.png)'
- en: '(Fun fact: it’s not so much off, because my ancestors were all Italian… here,
    GPT-3 likely made a guess based on my name… but no, I was born and grew up in
    Argentina.)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: （有趣的事实：这并不太偏差，因为我的祖先都是意大利人……在这里，GPT-3可能基于我的名字做出了猜测……但不，我在阿根廷出生和长大。）
- en: 'Now, what do we see in the console log? Lots of interesting outputs, besides
    the output text itself. Let’s analyze the most important elements:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们在控制台日志中看到什么？除了输出文本本身，还有很多有趣的输出。让我们分析一下最重要的元素：
- en: 'First, you see the object **text** which includes the output: *Luciano Abriata
    is from Italy*.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你会看到包含输出的对象**text**：*Luciano Abriata is from Italy*。
- en: But then a few lines above **text**, you see an array containing the tokens
    that make up that text. And a few lines above this, you have **token_logprobs**,
    an array of the same size that lists the log probabilities for each token.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但在**text**的几行上方，你会看到一个包含构成该文本的标记的数组。在这个数组的几行上方，你会看到**token_logprobs**，这是一个相同大小的数组，列出了每个标记的对数概率。
- en: You can see that **token_logprobs** reaches a minimum of -0.49 at token 9, “Italy”,
    while all other tokens are very close to 0 (except those at the end which are
    also negative, but we don’t care about these closing tokens).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到**token_logprobs**在第9个标记“意大利”处达到了-0.49的最低值，而其他所有标记都非常接近0（除了结尾处的标记也为负值，但我们不关心这些结尾标记）。
- en: This is in principle good news, because it means that GPT-3 is providing a clue
    that this piece of information might be wrong, or “made up”. Let’s no rush to
    draw any conclusions yet, though, and let’s explore this further.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这原则上是好消息，因为这意味着GPT-3提供了一个线索，表明这个信息可能是错误的，或者是“编造”的。不过，我们不要急于得出结论，还是进一步探索一下。
- en: 'What if we provide some information in the prompt, and then ask about it? Something
    like this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在提示中提供一些信息，然后询问相关内容会怎样？比如这样：
- en: Luciano Abriata is a scientist born in Argentina, now working in Switzerland.
    He works on structural biology, virtual reality, NMR, scientific writing, programming,
    etc. Where is Luciano Abriata from?
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Luciano Abriata 是一位出生在阿根廷的科学家，目前在瑞士工作。他从事结构生物学、虚拟现实、核磁共振、科学写作、编程等工作。Luciano
    Abriata 是哪里人？
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this case, GPT-3 not only replies correctly saying that I’m from Argentina,
    but it also says this confidently: “Argentina”, again in token 9, has a log probability
    very close to 0:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，GPT-3 不仅正确回答了我来自阿根廷，还自信地说：“阿根廷”，在标记9中，其对数概率非常接近 0：
- en: '![](../Images/4d8d45250450c08e55874e04696ad390.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d8d45250450c08e55874e04696ad390.png)'
- en: More thorough tests by representing token probabilities as colors on the produced
    text
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更全面的测试是通过在生成的文本上用颜色表示标记概率
- en: 'To test the power of log probabilities in flagging potentially incorrect information,
    I wrote this simple web app (link near the end) that processes a prompt with GPT-3
    and displays the produced text colored at each token by its log probability:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试对潜在不准确信息标记的对数概率的威力，我编写了这个简单的网页应用程序（链接在文末附近），它处理一个带有 GPT-3 的提示，并显示每个标记按其对数概率上色的生成文本：
- en: '![](../Images/c8ba6078bdc49f1509dd65c087c58df0.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8ba6078bdc49f1509dd65c087c58df0.png)'
- en: 'In this app, which you can try in a link I provide below, color keys for each
    token are injected via HTML’s <font> tag as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个应用程序中，你可以通过我在下面提供的链接进行尝试，每个标记的颜色键是通过 HTML 的 <font> 标签注入的，如下所示：
- en: log prob. > -0.1 → green
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数概率 > -0.1 → 绿色
- en: -0.3 > log prob. > -0.1 → yellow
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -0.3 > 对数概率 > -0.1 → 黄色
- en: -0.5 > log prob. > -0.3 → orange
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -0.5 > 对数概率 > -0.3 → 橙色
- en: log prob. < -0.5 → red
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数概率 < -0.5 → 红色
- en: 'Let’s analyze this a bit: the question is about a person that I made up, and
    about whom GPT-3 replies rather than saying it doesn’t know, although temperature
    is 0 so it’s not expected to make up stuff… Clearly, one cannot rely on the temperature
    parameter as a way to prevent the generation of fake information.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微分析一下：问题是关于我虚构的一个人，而 GPT-3 只是回答了，而不是说它不知道，尽管温度是 0，所以不应该虚构内容……显然，不能依赖温度参数来防止生成虚假信息。
- en: 'Now, notice that of the 4 most important features invented for this fictional
    character (he’s Italian, a philosopher and professor of philosophy, and at the
    University of Rome La Sapienza) some are flagged strongly:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，请注意对于这个虚构角色（他是意大利人，是哲学家和哲学教授，在罗马大学拉萨比恩扎）的4个最重要特征，有些被强烈标记：
- en: “philosopher and professor of philosophy” averages a log probability of around
    -1, and “Rome La” of around -1.5.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: “哲学家和哲学教授”的对数概率平均值约为 -1，而“罗马 La”的对数概率约为 -1.5。
- en: Meanwhile, “Sapienza” probably remains unflagged, i.e. with high log probability,
    because it is a perfect continuation for “University of Rome La”. Likewise, “Italian”
    probably remains high because it comes soon after “Giulio”, which is a very Italian
    name.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，“Sapienza”可能保持未被标记，即对数概率较高，因为它是“罗马大学 La”的完美延续。同样，“意大利人”可能保持高概率，因为它紧跟在“Giulio”之后，“Giulio”是一个非常意大利的名字。
- en: Thus, it seems like a low log probability is indicative of potentially inaccurate
    information, but a high value doesn’t ensure factual accuracy.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，低对数概率似乎指示潜在的不准确信息，但高值并不能确保事实准确性。
- en: It seems like a low log probability is indicative of potentially inaccurate
    information, but a high value doesn’t ensure factual accuracy.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 低对数概率似乎指示潜在的不准确信息，但高值并不能确保事实准确性。
- en: 'Let’s now try changing “Giulio” by “John”, i.e. asking “Who is John Caranchani?”:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试将“Giulio”改为“John”，即询问“John Caranchani 是谁？”：
- en: '![](../Images/58b1e032a1209968a7f8618143f41a03.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58b1e032a1209968a7f8618143f41a03.png)'
- en: This time it made up that the character is Italian-American, and has flagged
    this information with a quite bad score.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这次它虚构了这个角色是意大利裔美国人，并且以相当差的分数标记了这一信息。
- en: 'One more test, using the typically French name “Philippe”:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 再做一次测试，使用典型的法国名字“Philippe”：
- en: '![](../Images/8f831737ef9279f75346df9f04c835c2.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f831737ef9279f75346df9f04c835c2.png)'
- en: It now makes up that the character is French, and flags this in orange.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在它虚构了这个角色是法国人，并用橙色标记了这一点。
- en: 'Let’s now ask about something different: chemistry. What’s the molecular formula
    of acetic acid?'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来询问一些不同的问题：化学。醋酸的分子式是什么？
- en: '![](../Images/bee9295d58d6631dfa0b46ab79ff0788.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bee9295d58d6631dfa0b46ab79ff0788.png)'
- en: We get a correct answer, and all in green indicating very good scores.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个正确的答案，所有的标记都是绿色，表明分数非常好。
- en: 'What if we make up a molecule? Bizarric acid, for instance:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们虚构一个分子呢？例如 Bizarric 酸：
- en: '![](../Images/aa18983bb3b2b0a6b72e75c65e47e7c0.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa18983bb3b2b0a6b72e75c65e47e7c0.png)'
- en: Looks like it does “realize” that it’s making up stuff. Of course, we’d rather
    prefer that GPT-3 replied “I don’t know” or “Bizarric acid doesn’t exist”. But
    a very bad score is better than nothing.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来它确实“意识到”它在编造东西。当然，我们更希望GPT-3回答“我不知道”或“Bizarric acid不存在”。但一个非常糟糕的分数总比没有好。
- en: Effect of passing information for few-shot learning
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 传递信息进行少量学习的效果
- en: As discussed earlier and in numerous articles everywhere, GPT-3 can extract
    information from pieces of text passed for few-shot learning, and thus reply to
    questions more accurately -at least according to the passed information.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前讨论过的以及在许多文章中提到的，GPT-3可以从传递的文本片段中提取信息进行少量学习，从而更准确地回答问题——至少根据传递的信息来说。
- en: How is it reflected in the token probabilities?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这在令牌概率中是如何体现的？
- en: 'Let’s see an example. I made up a person called Stephan Farconi, and want to
    know where he is from and what he does:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个例子。我虚构了一个名叫Stephan Farconi的人，想知道他来自哪里以及他做什么：
- en: '![](../Images/8384d9b25f6c5df81ba06479707dda8c.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8384d9b25f6c5df81ba06479707dda8c.png)'
- en: As expected, everything was made up and flagged with bad scores.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，一切都是虚构的，并且标记了差分数。
- en: 'Now let’s give GPT-3 some information about this person, and let’s ask again:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们给GPT-3一些关于这个人的信息，再次提问：
- en: '![](../Images/f9dfe6f75072b2efa5fad4707dadb372.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9dfe6f75072b2efa5fad4707dadb372.png)'
- en: The answer is now factually consistent with the information passed, and GPT-3
    flags a part of it (“Greece”) as certain. However, it is not sure about “computer
    scientist”. Note that “scientist” is a good continuation for “computer”, so in
    my interpretation GPT-3 is actually “unsure” about the whole “computer scientist”
    concept.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 答案现在与传递的信息在事实上一致，并且GPT-3将一部分（“希腊”）标记为确定。然而，它对“计算机科学家”不太确定。请注意，“科学家”是“计算机”的良好续接，所以在我看来GPT-3实际上对整个“计算机科学家”概念是“没有把握”的。
- en: Want to try this app?
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 想试试这个应用吗？
- en: 'Here it is:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里：
- en: '[**https://lucianoabriata.altervista.org/tests/gpt-3/js-only/GPT3-JSonly-logprobs-color.html**](https://lucianoabriata.altervista.org/tests/gpt-3/js-only/GPT3-JSonly-logprobs-color.html)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[**https://lucianoabriata.altervista.org/tests/gpt-3/js-only/GPT3-JSonly-logprobs-color.html**](https://lucianoabriata.altervista.org/tests/gpt-3/js-only/GPT3-JSonly-logprobs-color.html)'
- en: Just paste your OpenAI API key for GPT-3, enter a question or prompt and click
    “Send to bot”.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 只需粘贴你的OpenAI API密钥用于GPT-3，输入一个问题或提示，然后点击“发送给机器人”。
- en: Please share your results in the comments! Did the token probabilities reflect
    the actual accuracy of the produced text?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 请在评论中分享你的结果！令牌概率是否反映了生成文本的实际准确性？
- en: Conclusion
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The use of GPT-3 and similar language models in chatbot applications can present
    a significant challenge in terms of generating accurate and reliable information.
    While new methods will hopefully improve on veracity, for the moment an option
    is to utilize token probabilities to measure the “certainty” that GPT-3 has on
    each token that constitutes its output. I showed you that using this information
    it is possible to approximate the level of confidence that GPT-3 has in its generated
    text -but it’s not entirely safe.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在聊天机器人应用中使用GPT-3及类似语言模型可能会在生成准确可靠的信息方面带来重大挑战。虽然新方法有望提高真实性，但目前的一个选项是利用令牌概率来衡量GPT-3对每个构成其输出的令牌的“确定性”。我向你展示了使用这些信息可以近似估计GPT-3在其生成文本中的信心水平，但这并不完全可靠。
- en: From the few examples tested it looks like high scores throughout all tokens
    are indicative of accurate information, but low scores at some tokens do not necessarily
    imply that the information is incorrect. Of course, this is only anecdotal evidence,
    and a much larger study is required to evaluate this seriously. This could be
    an interesting project that a group doing research on AI could carry out relatively
    easy -just needing a sufficient number of persons interacting with the system
    by asking questions and evaluating the answers. (And note, as a further caveat,
    that I chose my thresholds for interpretation of log probabilities somewhat arbitrarily.)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 从测试的几个例子来看，所有令牌的高分似乎表明信息是准确的，但某些令牌的低分并不一定意味着信息是错误的。当然，这仅仅是个案证据，需要更大规模的研究来认真评估。这可能是一个有趣的项目，一个研究AI的团队可以相对容易地进行，只需要足够多的人与系统互动，提出问题并评估答案。（此外，请注意，我选择解释日志概率的阈值是有些随意的。）
- en: I also showed you that few-shot learning helps to improve not only the accuracy
    of the answers, especially for questions that GPT-3 doesn’t “know” about, but
    also their reliability as measured by the token probabilities. However, also here
    we see that providing information through few-shot learning does not guarantee
    high scores in the replies, even when the information in these answers is correct.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我还向你展示了少样本学习不仅能提高回答的准确性，特别是对于GPT-3“不知道”的问题，还能提高其可靠性，这通过令牌概率来衡量。然而，我们也看到，通过少样本学习提供的信息并不能保证回答中的高分，即使这些回答中的信息是正确的。
- en: Overall, token probabilities look promising but, even without a full evaluation,
    it is clear that they are fallible. Therefore, it is crucial to use GPT-3 carefully,
    possibly utilizing token probabilities to improve outputs but without placing
    undue trust in them.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来看，令牌概率看起来很有前景，但即使没有全面评估，也很明显它们是易出错的。因此，谨慎使用GPT-3是至关重要的，可能利用令牌概率来改进输出，但不要过于依赖它们。
- en: '[***www.lucianoabriata.com***](https://www.lucianoabriata.com/) *I write and
    photoshoot about everything that lies in my broad sphere of interests: nature,
    science, technology, programming, etc.* [***Become a Medium member***](https://lucianosphere.medium.com/membership)
    *to access all its stories (affiliate links of the platform for which I get small
    revenues without cost to you) and* [***subscribe to get my new stories***](https://lucianosphere.medium.com/subscribe)
    ***by email****. To* ***consult about small jobs,*** *check my* [***services page
    here***](https://lucianoabriata.altervista.org/services/index.html)*. You can*
    [***contact me here***](https://lucianoabriata.altervista.org/office/contact.html)***.***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[***www.lucianoabriata.com***](https://www.lucianoabriata.com/) *我撰写和拍摄的内容涵盖了我广泛兴趣领域中的一切：自然、科学、技术、编程等。*
    [***成为 Medium 会员***](https://lucianosphere.medium.com/membership) *以访问所有故事（平台的关联链接，我会获得少量收入，不会增加你的费用）以及*
    [***订阅以获取我的新故事***](https://lucianosphere.medium.com/subscribe) ***通过电子邮件****。如需*
    ***咨询小型工作，*** *请查看我的* [***服务页面***](https://lucianoabriata.altervista.org/services/index.html)*。你可以*
    [***在这里联系我***](https://lucianoabriata.altervista.org/office/contact.html)***。***'
