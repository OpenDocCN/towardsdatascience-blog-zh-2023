- en: How to Evaluate the Performance of Your ML/ AI Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何评估你的ML/AI模型的表现
- en: 原文：[https://towardsdatascience.com/how-to-evaluate-the-performance-of-your-ml-ai-models-ba1debc6f2fa](https://towardsdatascience.com/how-to-evaluate-the-performance-of-your-ml-ai-models-ba1debc6f2fa)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-evaluate-the-performance-of-your-ml-ai-models-ba1debc6f2fa](https://towardsdatascience.com/how-to-evaluate-the-performance-of-your-ml-ai-models-ba1debc6f2fa)
- en: An accurate evaluation is the only way to performance improvement
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确的评估是性能改进的唯一途径
- en: '[](https://saraametwalli.medium.com/?source=post_page-----ba1debc6f2fa--------------------------------)[![Sara
    A. Metwalli](../Images/d6861f7bc1879bf68d4b7116c335c7e5.png)](https://saraametwalli.medium.com/?source=post_page-----ba1debc6f2fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ba1debc6f2fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ba1debc6f2fa--------------------------------)
    [Sara A. Metwalli](https://saraametwalli.medium.com/?source=post_page-----ba1debc6f2fa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://saraametwalli.medium.com/?source=post_page-----ba1debc6f2fa--------------------------------)[![Sara
    A. Metwalli](../Images/d6861f7bc1879bf68d4b7116c335c7e5.png)](https://saraametwalli.medium.com/?source=post_page-----ba1debc6f2fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ba1debc6f2fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ba1debc6f2fa--------------------------------)
    [Sara A. Metwalli](https://saraametwalli.medium.com/?source=post_page-----ba1debc6f2fa--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ba1debc6f2fa--------------------------------)
    ·8 min read·May 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----ba1debc6f2fa--------------------------------)
    ·阅读时间8分钟·2023年5月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/179ab3fd989ac42746ac78c4f5aab453.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/179ab3fd989ac42746ac78c4f5aab453.png)'
- en: Photo by [Scott Graham](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Scott Graham](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)拍摄于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Learning by doing is one of the best approaches to learning anything, from tech
    to a new language or cooking a new dish. Once you have learned the basics of a
    field or an application, you can build on that knowledge by acting. Building models
    for various applications is the best way to make your knowledge concrete regarding
    machine learning and artificial intelligence.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实践学习是学习任何事物的最佳方法之一，无论是技术、新语言还是烹饪新菜肴。一旦你掌握了一个领域或应用的基础知识，你可以通过行动来进一步加深理解。构建各种应用的模型是将你对机器学习和人工智能知识变得具体化的最佳方式。
- en: Though both fields (or really sub-fields, since they do overlap) have applications
    in a wide variety of contexts, the steps to learning how to build a model are
    more or less the same regardless of the target application field.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这两个领域（或者说子领域，因为它们确实有重叠）在各种上下文中都有应用，但学习如何构建模型的步骤在不同的目标应用领域中或多或少是相同的。
- en: AI language models such as [ChatGPT](https://openai.com/blog/chatgpt) and [Bard](https://bard.google.com/)
    are gaining popularity and interest from both tech novices and general audiences
    because they can be very useful in our daily lives.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: AI语言模型如[ChatGPT](https://openai.com/blog/chatgpt)和[Bard](https://bard.google.com/)正受到科技新手和普通观众的广泛关注，因为它们在我们的日常生活中非常有用。
- en: Now that more models are being released and presented, one may ask, what makes
    a “*good*” AI/ ML model, and how can we evaluate the performance of one?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着更多模型的发布和展示，人们可能会问，什么才是一个“*好的*”AI/ML模型，我们如何评估它的表现？
- en: This is what we are going to cover in this article. But again, we assume you
    already have an AI or ML model built. Now, you want to evaluate and improve its
    performance (if necessary). But, again, regardless of the type of model you have
    and your end application, you can take steps to evaluate your model and improve
    its performance.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们在本文中将要涵盖的内容。但我们假设你已经构建了一个AI或ML模型。现在，你想要评估并改善其表现（如有必要）。但无论你拥有何种模型和最终应用，你都可以采取措施来评估你的模型并提高其性能。
- en: To help us follow through with the concepts, let’s use the [Wine](https://archive.ics.uci.edu/ml/datasets/Wine)
    dataset from sklearn [1], apply the support vector classifier (SVC), and then
    test its metrics.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们理解这些概念，我们将使用来自sklearn的[Wine](https://archive.ics.uci.edu/ml/datasets/Wine)数据集[1]，应用支持向量分类器（SVC），然后测试其指标。
- en: So, let’s jump right in…
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们马上开始吧…
- en: First, let’s import the libraries we will use (don’t worry about what each of
    those do now, we’ll get to that!).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入我们将使用的库（现在不必担心每个库的功能，我们稍后会讲解！）。
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, we read our dataset, apply the classifier, and evaluate it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们读取数据集，应用分类器，并对其进行评估。
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 1\. Split the dataset for better analysis.
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 将数据集拆分以便更好地分析。
- en: Depending on your stage in the learning process, you may need access to a large
    amount of data that you can use for training and testing, and evaluating. Also,
    you can use different data to train and test your model because that will prevent
    you from genuinely assessing your model’s performance.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你学习过程的阶段，你可能需要访问大量的数据来进行训练、测试和评估。此外，你可以使用不同的数据来训练和测试你的模型，因为这将防止你真正评估模型的性能。
- en: To overcome that challenge, split your data into three smaller random sets and
    use them for training, testing, and validating.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个挑战，将数据分成三个较小的随机集，并将它们用于训练、测试和验证。
- en: A good rule of thumb to do that split is a 60,20,20 approach. You would use
    60% of the data for training, 20% for validation, and 20% for testing. You need
    to shuffle your data before you do the split to ensure a better representation
    of that data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的经验法则是采用60、20、20的方法进行拆分。你可以将60%的数据用于训练，20%用于验证，20%用于测试。你需要在拆分之前打乱数据，以确保数据的更好表示。
- en: I know that may sound complicated, but luckily, ticket-learn came to the rescue
    by offering a function to perform that split for you, train_test_split().
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道这可能听起来很复杂，但幸运的是，`scikit-learn`提供了一个函数来为你执行这个拆分操作，即train_test_split()。
- en: 'So, we can take our dataset and split it like so:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以将数据集拆分如下：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then use the training portion of it as input to the classifier.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将训练部分作为输入传递给分类器。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: At this point, we have some results to “evaluate.”
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经有一些结果可以“评估”。
- en: 2\. Define your evaluation metrics.
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 定义你的评估指标。
- en: 'Before starting the evaluation process, we must ask ourselves an essential
    question about the model we use: ***what would make this model good?***'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始评估过程之前，我们必须问自己一个关于我们使用的模型的关键问题：***什么会使这个模型变得优秀？***
- en: 'The answer to this question depends on the model and how you plan to use it.
    That being said, there are standard evaluation metrics that data scientists use
    when they want to test the performance of an AI/ ML model, including:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的答案取决于模型和你打算如何使用它。也就是说，当数据科学家想要测试AI/ML模型的性能时，会使用一些标准的评估指标，包括：
- en: '**Accuracy** is the percentage of correct predictions by the model out of the
    total prediction. That means, when I run the model, how many predictions are true
    among all predictions? This article goes into depth about testing the accuracy
    of a model.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准确率**是模型在所有预测中正确预测的百分比。这意味着，当我运行模型时，所有预测中有多少是正确的？这篇文章深入探讨了模型准确率的测试。'
- en: '**Precision** is the percentage of true positive predictions by the model out
    of all positive predictions. Unfortunately, precision and accuracy are often confused;
    one way to make the difference between them clear is to think of accuracy as the
    closeness of the predictions to the actual values, while precision is how close
    the correct predictions are to each other. So, accuracy is an absolute measure,
    yet both are important to evaluate the model’s performance.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**精确度**是模型在所有正例预测中真实正例预测的百分比。不幸的是，精确度和准确率经常被混淆；区分它们的一种方法是将准确率视为预测值与实际值的接近程度，而精确度则是正确预测之间的接近程度。因此，准确率是一个绝对指标，但两者都对评估模型性能非常重要。'
- en: '**Recall** is the proportion of true positive predictions from all actual positive
    instances in the dataset. Recall aims to find related predictions within a dataset.
    Mathematically, if we increase the recall, we decrease the precision of the model.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**召回率**是数据集中所有实际正例中真实正例预测的比例。召回率旨在找到数据集中相关的预测。从数学上讲，如果我们提高召回率，就会降低模型的精确度。'
- en: '**F1 score is t**he combination mean of precision and recall, providing a balanced
    measure of a model’s performance using both precision and recall. This video by
    [CodeBasics](https://codebasics.io/) discusses the relation between precision,
    recall, and F1 score and how to find the optimal balance of those evaluation metrics.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**F1 分数**是精确度和召回率的加权均值，提供了使用精确度和召回率来衡量模型性能的平衡指标。由[CodeBasics](https://codebasics.io/)制作的视频讨论了精确度、召回率和F1分数之间的关系，以及如何找到这些评估指标的最佳平衡。'
- en: Video By [CodeBasics](https://codebasics.io/)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 视频由[CodeBasics](https://codebasics.io/)制作
- en: Now, let’s calculate the different metrics for the predicted data. The way we
    will do that is by first displaying the confusion matrix. The confusion matrix
    is simply the actual results of data vs. the predicted results.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们计算预测数据的不同指标。我们将通过首先显示混淆矩阵来实现这一点。混淆矩阵只是数据的实际结果与预测结果的对比。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The confusion matrix to our dataset will look something like,
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据集的混淆矩阵看起来像这样，
- en: '![](../Images/9e3673b3531192ce6e6d186a4cdb84a3.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e3673b3531192ce6e6d186a4cdb84a3.png)'
- en: If we look at this confusion matrix, we can see that the actual value was “1”
    in some cases while the predicted value was “0”. Which means the classifier is
    not a %100 accurate.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看这个混淆矩阵，我们可以看到实际值在某些情况下是“1”，而预测值是“0”。这意味着分类器的准确率不是百分之百。
- en: We can calculate this classifier's accuracy, precision, recall, and f1 score
    using this code.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这段代码计算这个分类器的准确率、精确度、召回率和 F1 分数。
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'For this particular example, the results for those are:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个特定的例子，这些结果是：
- en: Precision = 0.889
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 精确度 = 0.889
- en: Recall = 0.889
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 召回率 = 0.889
- en: Accuracy = 0.889
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确率 = 0.889
- en: F1 score = 0.889
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: F1分数 = 0.889
- en: 'Though you can really use different approaches to evaluate your models, some
    evaluation methods will better estimate the model’s performance based on the model
    type. For example, in addition to the above methods, if the model you’re evaluating
    is a regression (or it includes regression) model, you can also use:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以使用不同的方法来评估你的模型，但一些评估方法会根据模型类型更好地估计模型的性能。例如，除了上述方法之外，如果你评估的模型是回归模型（或包括回归），你还可以使用：
- en: '**- Mean Squared Error (MSE)** mathematically is the average of the squared
    differences between predicted and actual values.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**- 均方误差 (MSE)** 从数学上讲，是预测值与实际值之间平方差的平均值。'
- en: '**- Mean Absolute Error (MAE)** is the average of the absolute differences
    between predicted and actual values.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**- 平均绝对误差 (MAE)** 是预测值与实际值之间绝对差异的平均值。'
- en: Those two metrics are closely related, but implementation-wise, MAE is simpler
    (at least mathematically) than MSE. However, MAE doesn’t do well with significant
    errors, unlike MSE, which emphasizes the errors (because it squares them).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个指标密切相关，但在实现上，MAE（平均绝对误差）比 MSE（均方误差）更简单（至少在数学上）。然而，MAE 对于显著错误表现不佳，而 MSE 强调了这些错误（因为它将误差平方）。
- en: 3\. Validate and tune the model’s hyperparameters.
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 验证和调整模型的超参数。
- en: Before discussing hyperparameters, let’s first differentiate between a hyperparameter
    and a parameter. A parameter is a way a model is defined to solve a problem. In
    contrast, hyperparameters are used to test, validate, and optimize the model’s
    performance. Hyperparameters are often chosen by the data scientists (or the client,
    in some cases) to control and validate the learning process of the model and hence,
    its performance.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论超参数之前，让我们首先区分一下超参数和参数。参数是定义模型以解决问题的方式。与之相对的是，超参数用于测试、验证和优化模型的性能。超参数通常由数据科学家（或在某些情况下由客户）选择，以控制和验证模型的学习过程，从而影响其性能。
- en: 'There are different types of hyperparameters that you can use to validate your
    model; some are general and can be used on any model, such as:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用不同类型的超参数来验证你的模型；其中一些是通用的，可以用于任何模型，例如：
- en: '**Learning Rate:** this hyperparameter controls how much the model needs to
    be changed in response to some error when the model’s parameters are updated or
    altered. Choosing the optimal learning rate is a trade-off with the time needed
    for the training process. If the learning rate is low, then it may slow down the
    training process. In contrast, if the learning rate is too high, the training
    process will be faster, but the model performance may suffer.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习率：** 这个超参数控制模型在更新或更改其参数时需要多少响应来修正某些错误。选择最佳学习率是一个与训练过程所需时间的权衡。如果学习率过低，可能会使训练过程变慢。相反，如果学习率过高，训练过程会更快，但模型性能可能会受到影响。'
- en: '**Batch Size:** The size of your training dataset will significantly affect
    the model’s training time and learning rate. So, finding the optimal batch size
    is a skill that is often developed as you build more models and grow your experience.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量大小：** 你的训练数据集的大小将显著影响模型的训练时间和学习率。因此，找到最佳批量大小是一项随着你构建更多模型和积累经验而逐渐培养的技能。'
- en: '**Number of Epochs:** An epoch is a complete cycle for training the machine
    learning model. The number of epochs to use varies from one model to another.
    Theoretically, more epochs lead to fewer errors in the validation process.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练轮数：** 一次训练轮是训练机器学习模型的一个完整周期。使用的训练轮数因模型而异。从理论上讲，更多的训练轮数会导致验证过程中的错误减少。'
- en: In addition to the above hyperparameters, there are model-specific hyperparameters
    such as regularization strength or the number of hidden layers in implementing
    a neural network. This 15 mins Video by [APMonitor](https://apmonitor.com/pds/index.php/Main/HyperparameterOptimization)
    explores various hyperparameters and their differences.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述超参数，还有一些特定于模型的超参数，如正则化强度或实现神经网络时的隐藏层数。这个由[APMonitor](https://apmonitor.com/pds/index.php/Main/HyperparameterOptimization)
    制作的15分钟视频探讨了各种超参数及其差异。
- en: Video by [APMonitor](https://apmonitor.com/pds/index.php/Main/HyperparameterOptimization)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[APMonitor](https://apmonitor.com/pds/index.php/Main/HyperparameterOptimization)
    制作的视频'
- en: 4\. Iterate and refine
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 迭代和优化
- en: Validating an AI/ ML model is not a linear process but more of an iterative
    one. You go through the data split, the hyperparameters tuning, analyzing, and
    validating the results often more than once. The number of times you repeat that
    process depends on the analysis of the results. For some models, you may only
    need to do this once; for others, you may need to do it a couple of times.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 验证 AI/ML 模型不是一个线性过程，而是一个迭代过程。你需要经过数据划分、超参数调优、分析和验证结果的过程，这一过程往往需要多次重复。你重复这个过程的次数取决于结果的分析。对于某些模型，你可能只需做一次；而对于其他模型，你可能需要做几次。
- en: If you need to repeat the process, you will use the insights from the previous
    evaluation to improve the model’s architecture, training process, or hyperparameter
    settings until you are satisfied with the model’s performance.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要重复过程，你将利用之前评估的洞察来改进模型的架构、训练过程或超参数设置，直到你对模型的性能感到满意为止。
- en: Final Thoughts
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结语
- en: When you start building your own ML and AI models, you will quickly realize
    that choosing and implementing the model is the easy part of the workflow. However,
    testing and evaluation is the part that will take most of the development process.
    Evaluating an AI/ ML model is an iterative and often time-consuming process, and
    it requires careful analysis, experimentation, and fine-tuning to achieve the
    desired performance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始构建自己的 ML 和 AI 模型时，你会迅速意识到，选择和实现模型是工作流中较简单的部分。然而，测试和评估是开发过程中的关键部分。评估 AI/ML
    模型是一个迭代且通常耗时的过程，需要仔细分析、实验和微调，以达到预期的性能。
- en: 'Luckily, the more experience you have building more models, the more systematic
    the process of evaluating your model’s performance will get. And it’s a worthwhile
    skill considering the importance of evaluating your model, such as:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，随着你构建更多模型的经验积累，评估模型性能的过程将变得更加系统化。考虑到评估模型的重要性，这是一项值得掌握的技能，例如：
- en: Evaluating our models allows us to objectively measures the model’s metrics
    which helps in understanding its strengths and weaknesses and provides insights
    into its predictive or decision-making capabilities.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估我们的模型使我们能够客观地衡量模型的指标，这有助于了解其优缺点，并提供对其预测或决策能力的洞察。
- en: If different models that can solve the same problems exist, then evaluating
    them enables us to compare their performance and choose the one that suits our
    application best.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果存在可以解决相同问题的不同模型，那么评估它们使我们能够比较它们的性能，并选择最适合我们应用的模型。
- en: Evaluation provides insights into the model’s weaknesses, allowing for improvements
    through analyzing the errors and areas where the model underperforms.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估提供了对模型弱点的洞察，通过分析错误和模型表现不佳的领域，允许进行改进。
- en: So, have patience and keep building models; it gets better and more efficient
    with the more models you build. Don’t let the process details discourage you.
    It may look like a complex process, but once you understand the steps, it will
    become second nature to you.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，要有耐心，继续构建模型；随着你构建的模型越来越多，模型的效果和效率也会越来越好。不要让过程中的细节让你气馁。虽然过程看起来复杂，但一旦你了解了步骤，它将变成你的第二天性。
- en: Reference
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[1] Lichman, M. (2013). [UCI Machine Learning Repository.](https://archive.ics.uci.edu/ml)
    Irvine, CA: University of California,'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Lichman, M. (2013). [UCI 机器学习库](https://archive.ics.uci.edu/ml) 加州尔湾：加州大学，'
- en: School of Information and Computer Science. (CC BY 4.0)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 信息与计算机科学学院。（CC BY 4.0）
