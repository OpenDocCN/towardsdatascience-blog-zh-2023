- en: Cultural Competencies for Machine Learning Risk Management
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习风险管理的文化能力
- en: 原文：[https://towardsdatascience.com/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf](https://towardsdatascience.com/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf](https://towardsdatascience.com/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf)
- en: '*An organization''s culture is an essential aspect of responsible AI.*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*组织文化是负责任的人工智能的一个重要方面。*'
- en: '[](https://pandeyparul.medium.com/?source=post_page-----c38616c2ccdf--------------------------------)[![Parul
    Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----c38616c2ccdf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c38616c2ccdf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c38616c2ccdf--------------------------------)
    [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----c38616c2ccdf--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pandeyparul.medium.com/?source=post_page-----c38616c2ccdf--------------------------------)[![Parul
    Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----c38616c2ccdf--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c38616c2ccdf--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c38616c2ccdf--------------------------------)
    [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----c38616c2ccdf--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c38616c2ccdf--------------------------------)
    ·8 min read·Sep 15, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c38616c2ccdf--------------------------------)
    ·阅读时间 8 分钟 ·2023年9月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d42f7a8d2151e8b4f44c97de37c88a03.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d42f7a8d2151e8b4f44c97de37c88a03.png)'
- en: '[Photo by Google DeepMind](https://www.pexels.com/photo/an-artist-s-illustration-of-artificial-intelligence-ai-this-image-depicts-ai-safety-research-to-prevent-the-misuse-and-encourage-beneficial-uses-it-was-created-by-artist-khyati-trehan-17485632/)
    available for free on Pexels'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[由 Google DeepMind 提供的照片](https://www.pexels.com/photo/an-artist-s-illustration-of-artificial-intelligence-ai-this-image-depicts-ai-safety-research-to-prevent-the-misuse-and-encourage-beneficial-uses-it-was-created-by-artist-khyati-trehan-17485632/)
    在 Pexels 上免费提供'
- en: In the race for progress, we must tread carefully, for haste in engineering
    and data science can shatter more than just code.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在进步的竞赛中，我们必须小心翼翼，因为工程和数据科学上的匆忙可能会摧毁的不仅仅是代码。
- en: Imagine a world where Artificial Intelligence (AI) powered systems could do
    no wrong, where they flawlessly executed their tasks without a glitch. Sounds
    like a sci-fi dream, doesn't it? Welcome to the real world of AI, where things
    don't always go as planned. An integral part of responsible AI practice involves
    preventing and addressing what we term '***AI incidents***.' This article discusses
    cultural competencies that can prevent and mitigate AI incidents, focusing on
    the concept of promoting responsible AI practices. Subsequently, we will explore
    related business processes in future articles to provide a comprehensive perspective
    on this crucial topic.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个人工智能（AI）系统可以万无一失的世界，它们能够无故障地完美执行任务。这听起来像是科幻梦，对吗？欢迎来到人工智能的现实世界，事情并不总是如计划般顺利。负责任的人工智能实践的一个核心部分涉及预防和处理我们称之为‘***人工智能事件***’的情况。本文讨论了可以防止和缓解人工智能事件的文化能力，重点在于推动负责任的人工智能实践。随后，我们将在未来的文章中探讨相关的业务流程，以提供对这一重要话题的全面视角。
- en: A Note on the Series
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于这一系列的说明
- en: As we embark on this series, it’s important to provide context. I am one of
    the co-authors of ‘[**Machine Learning for High-Risk Applications**,](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)’
    along with [Patrick Hall](https://medium.com/@jphall_22520) and [James Curtis](https://james-curtis.medium.com/).
    This series is designed to offer a concise, reader-friendly companion to the book’s
    extensive content. In each article, we aim to distill the critical insights, concepts,
    and practical strategies presented in the book into easily digestible portions,
    making this knowledge accessible to a broader audience.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在我们开始这一系列文章时，提供背景信息是重要的。我是‘[**高风险应用中的机器学习**](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)’的共同作者之一，另外两位作者是
    [Patrick Hall](https://medium.com/@jphall_22520) 和 [James Curtis](https://james-curtis.medium.com/)。这一系列旨在提供一本简洁、读者友好的书籍内容补充。每篇文章中，我们旨在提炼书中的关键见解、概念和实际策略，将其浓缩成易于消化的部分，使这些知识能够被更广泛的读者所接受。
- en: Defining AI incidents
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义人工智能事件
- en: Addressing AI incidents is crucial before delving into ML safety because we
    can't effectively mitigate what we don't comprehend. AI incidents encompass any
    outcomes stemming from AI systems that could potentially cause harm. The severity
    of these incidents naturally varies depending on the extent of damage they result
    in. These incidents could range from relatively minor inconveniences, such as
    [mall security robots tumbling downstairs](https://www.youtube.com/watch?v=4Pwx3U4vJKw),
    to more catastrophic events, like [self-driving cars causing pedestrian fatalities](https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html)
    and the [large-scale diversion of healthcare resources away from those in dire
    need](https://www.nature.com/articles/d41586-019-03228-6).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨机器学习安全之前，处理人工智能事件至关重要，因为我们无法有效缓解我们不了解的情况。人工智能事件涵盖了任何可能造成伤害的人工智能系统的结果。这些事件的严重性自然会因造成的损害程度而异。这些事件可能从相对较小的不便，比如[购物中心安保机器人跌下楼梯](https://www.youtube.com/watch?v=4Pwx3U4vJKw)，到更为灾难性的事件，例如[无人驾驶汽车导致行人遇难](https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html)以及[大量医疗资源从急需者那里转移](https://www.nature.com/articles/d41586-019-03228-6)。
- en: AI incidents encompass any outcomes stemming from AI systems that could potentially
    cause harm.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人工智能事件涵盖了任何可能造成伤害的人工智能系统的结果。
- en: 'We can categorize the AI incidents into three major groups :'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将人工智能事件分为三个主要类别：
- en: '![](../Images/eb20270c0495f980498a271043ded17f.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb20270c0495f980498a271043ded17f.png)'
- en: '*A taxonomy of AI incidents (adapted by Author from "*[*What to Do When AI
    Fails*](https://www.oreilly.com/radar/what-to-do-when-ai-fails/)*" with permission)*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能事件分类（作者根据"*[*AI 失败时该怎么办*](https://www.oreilly.com/radar/what-to-do-when-ai-fails/)*"进行调整，已获许可）*'
- en: '**Attacks —** Many parts of machine learning systems, like software and prediction
    tools, are vulnerable to cyber and insider attacks. Once an attack happens, we
    lose control, and the attackers may have their own goals related to accuracy,
    bias, privacy, reliability, and more. Researchers have extensively documented
    such attack categories, namely confidentiality, integrity, and availability attacks.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**攻击 —** 机器学习系统的许多部分，如软件和预测工具，都容易受到网络攻击和内部攻击。一旦发生攻击，我们就会失去控制，攻击者可能有自己的目标，涉及准确性、偏见、隐私、可靠性等方面。研究人员已经广泛记录了这些攻击类别，即保密性、完整性和可用性攻击。'
- en: '![](../Images/fa3ec6c2697ebda0cf5f3bff363d76cd.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa3ec6c2697ebda0cf5f3bff363d76cd.png)'
- en: Types of Machine Learning Attacks | Image by the Author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习攻击类型 | 图片由作者提供
- en: '**Failures —** Failures refer to issues within AI systems, which often include
    problems like algorithmic bias, lapses in safety and performance, breaches of
    data privacy, a lack of transparency, or shortcomings in third-party system components.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**失败 —** 失败指的是人工智能系统中的问题，通常包括算法偏见、安全和性能缺陷、数据隐私泄露、透明度不足或第三方系统组件的不足。'
- en: '**Abuses —** AI tools can be abused by people with malicious intent. Hackers
    often use AI to enhance their attacks, such as in autonomous drone strikes. Additionally,
    some governments employ AI for purposes like ethnic profiling, highlighting the
    widespread misuse of AI technology.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滥用 —** 人工智能工具可能被具有恶意意图的人滥用。黑客经常利用人工智能来增强他们的攻击，例如在自主无人机袭击中。此外，一些政府将人工智能用于种族
    Profiling，突显了人工智能技术的广泛滥用。'
- en: 'Cataloging AI Incidents: The AI Incident Database'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能事件目录：人工智能事件数据库
- en: AI incidents can act as catalysts for promoting responsible technological progress
    within companies. When developing machine learning systems, it's crucial to cross-reference
    current plans with past incidents to avert potential future occurrences proactively.
    This aligns with the primary objective of ongoing endeavors to establish AI incident
    databases and their corresponding publications. An excellent example of such an
    endeavor is the [AI Incident Database](https://incidentdatabase.ai/).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能事件可以作为推动公司负责任技术进步的催化剂。在开发机器学习系统时，至关重要的是将当前计划与过去的事件进行交叉检查，以主动防止潜在的未来事件。这与正在进行的努力的主要目标一致，即建立人工智能事件数据库及其相关出版物。一个很好的例子是[人工智能事件数据库](https://incidentdatabase.ai/)。
- en: '![](../Images/c2e5cd9f99e5ce1fa102102438f3a830.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2e5cd9f99e5ce1fa102102438f3a830.png)'
- en: '[https://incidentdatabase.ai/](https://incidentdatabase.ai/)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://incidentdatabase.ai/](https://incidentdatabase.ai/)'
- en: 'As stated on the AI Incident Database website, their mission is clear:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 根据人工智能事件数据库网站的描述，他们的使命是明确的：
- en: '*"The AI Incident Database is dedicated to indexing the collective history
    of harms or near harms realized in the real world by the deployment of artificial
    intelligence systems. Like similar databases in aviation and computer security,
    the AI Incident Database aims to learn from experience so we can prevent or mitigate
    bad outcomes."*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*“AI事件数据库致力于索引人工智能系统部署在现实世界中造成的伤害或近乎伤害的集体历史。像航空和计算机安全领域的类似数据库一样，AI事件数据库旨在从经验中学习，以便我们可以防止或减轻不良结果。”*'
- en: The underlying idea here is that, like other domains, AI can also greatly benefit
    from learning from past mistakes to avoid their recurrence in the future. To achieve
    this effectively, it is imperative to maintain an accurate record of these failures.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的基本思想是，像其他领域一样，AI也可以通过从过去的错误中学习，以避免未来的重复。为了有效实现这一点，保持对这些失败的准确记录是至关重要的。
- en: Mitigating ML Risks through Cultural Competencies
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过文化能力减轻机器学习风险
- en: The culture within an organization plays a pivotal role in ensuring responsible
    AI practices. This article will mainly explore some cultural strategies to achieve
    this goal. In the upcoming articles, we will also cover additional methods for
    mitigating AI-related risks, including business processes and the model risk management
    aspects. Validation, auditing, and incident response teams are crucial alongside
    developers.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 组织内部的文化在确保负责任的AI实践中发挥着关键作用。本文将主要探讨一些文化策略以实现这一目标。在接下来的文章中，我们还将介绍减轻AI相关风险的其他方法，包括业务流程和模型风险管理方面。验证、审计和事件响应团队在开发者之外也是至关重要的。
- en: '*1\. Organizational Accountability*'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*1\. 组织责任*'
- en: '![](../Images/0c49324641b259be001b2ddb55cd7c48.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c49324641b259be001b2ddb55cd7c48.png)'
- en: '[Image by vectorjuice on Freepik](https://www.freepik.com/free-vector/project-delivery-abstract-concept-illustration_20770433.htm#query=responsibility&position=4&from_view=search&track=sph)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片由 vectorjuice 提供于 Freepik](https://www.freepik.com/free-vector/project-delivery-abstract-concept-illustration_20770433.htm#query=responsibility&position=4&from_view=search&track=sph)'
- en: Achieving responsible AI practices in organizations hinges on accountability,
    culture, and adherence to standards like [**Model Risk Management (MRM)**](https://www.fdic.gov/news/financial-institution-letters/2017/fil17022a.pdf)(we'll
    cover it in upcoming articles). Without consequences for ML system failures, attacks,
    or misuse, safety, and performance may be overlooked. Key cultural tenets for
    MRM include written policies and procedures, effective challenge from independent
    experts, accountable leadership (e.g., Chief Model Risk Officer), and aligning
    incentives for responsible ML implementation and not just speedy development.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在组织中实现负责任的AI实践依赖于问责制、文化以及对[**模型风险管理 (MRM)**](https://www.fdic.gov/news/financial-institution-letters/2017/fil17022a.pdf)的遵守（我们将在即将到来的文章中讨论）。如果对机器学习系统的失败、攻击或滥用没有后果，安全性和性能可能会被忽视。MRM的关键文化原则包括书面政策和程序、独立专家的有效挑战、负责任的领导（如首席模型风险官），以及为负责任的机器学习实施而不是仅仅为了快速开发对齐激励措施。
- en: Small organizations can designate individuals or groups for accountability to
    prevent incidents and reward successful systems. Collective accountability can
    lead to no one being responsible for ML risks and incidents.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 小型组织可以指定个人或团队负责问责，以防止事件发生并奖励成功的系统。集体责任可能导致无人对机器学习风险和事件负责。
- en: '*It’s important to have an individual or group held accountable if ML systems
    cause incidents and rewarded if the systems work well. If an organization assumes
    that everyone is accountable for ML risk and AI incidents, the reality is that
    no one is accountable — Machine Learning for High Risk Applications, Chapter 1.*'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如果机器学习系统导致事件，重要的是有个人或团队承担责任，并在系统运行良好时给予奖励。如果组织假设每个人都对机器学习风险和人工智能事件负责，那么实际上没有人负责——《高风险应用的机器学习》，第1章。*'
- en: 2\. Culture of Effective Change
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 有效变革的文化
- en: '![](../Images/7b0a7bd6ea21b367a3c7a281d2587b38.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b0a7bd6ea21b367a3c7a281d2587b38.png)'
- en: '[Image by jcomp on Freepik](https://www.freepik.com/free-photo/hand-word-chance-business_5598002.htm#query=Culture%20of%20Effective%20Change&position=3&from_view=search&track=ais)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片由 jcomp 提供于 Freepik](https://www.freepik.com/free-photo/hand-word-chance-business_5598002.htm#query=Culture%20of%20Effective%20Change&position=3&from_view=search&track=ais)'
- en: A strong culture of effective change involves actively questioning and scrutinizing
    the various steps involved in developing ML (Machine Learning) systems. In a broader
    organizational context, promoting a culture of serious inquiry into ML system
    designs is essential. Such a culture increases the likelihood of developing successful
    ML systems and products while also preventing problems from escalating into harmful
    incidents. It's worth noting that effective challenges should always be constructive
    and respectful, applying uniformly to all personnel involved in ML system development.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 强有力的有效变革文化涉及主动质疑和审查机器学习（ML）系统开发中的各个步骤。在更广泛的组织背景下，促进对机器学习系统设计的严肃探究文化至关重要。这种文化增加了开发成功的机器学习系统和产品的可能性，同时也防止问题升级为有害事件。值得注意的是，有效的挑战应始终具有建设性和尊重，适用于所有参与机器学习系统开发的人员。
- en: Effective challenge fuels innovation and safeguards progress in ML development
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有效的挑战推动创新并保障机器学习开发的进展
- en: To implement effective challenges effectively, it should be structured. This
    could involve regular meetings, perhaps on a weekly basis, where current design
    decisions are critically examined and alternative design choices are thoughtfully
    considered. This structured approach helps ensure that the culture of effective
    challenge becomes integral to the organization's ML development process.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地实施挑战，需要有结构化的安排。这可能包括定期会议，可能是每周一次，在这些会议上对当前设计决策进行严肃审查，并认真考虑替代设计选择。这种结构化的方法有助于确保有效挑战的文化成为组织机器学习开发过程的核心部分。
- en: '*3\. Diverse and Experienced Teams*'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*3\. 多样化且经验丰富的团队*'
- en: '![](../Images/a2af77f88d1b2238f3067b45cf01139d.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2af77f88d1b2238f3067b45cf01139d.png)'
- en: Photo by [Alexander Grey](https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/sbE9zbcuiZs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Alexander Grey](https://unsplash.com/@sharonmccutcheon?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)提供，来源于[Unsplash](https://unsplash.com/photos/sbE9zbcuiZs?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Diverse teams are crucial to unlocking fresh perspectives in designing, developing,
    and testing ML systems. Numerous examples illustrate the adverse outcomes of data
    scientists overlooking ML systems' demographic diversity. Increasing demographic
    diversity within ML teams is a potential remedy to address these oversights.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 多样化的团队对于在设计、开发和测试机器学习系统时获得新视角至关重要。许多例子表明，数据科学家忽视机器学习系统的人口多样性会导致不良结果。增加机器学习团队中的人口多样性是解决这些疏忽的一个潜在补救措施。
- en: In diversity we find innovation, and in expertise we ensure safety, together
    they are the compass guiding responsible AI advancement.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在多样性中我们发现创新，在专业知识中我们确保安全，两者共同指引负责任的人工智能进步。
- en: Dismissing domain experts is a dangerous gamble, as they bring invaluable insights
    and act as a safety net, averting potential disasters arising from misinterpretations
    of domain-specific data or results. The same principle applies to social science
    experts. Countless instances demonstrate the perils of sidelining these experts,
    whether by attempting to [automate decisions requiring specialized knowledge](https://www.wired.com/story/tech-needs-to-listen-to-actual-researchers/)
    or [ignoring their collective wisdom](https://www.technologyreview.com/2020/06/23/1004333/ai-science-publishers-perpetuate-racist-face-recognition)
    entirely in AI projects.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 忽视领域专家是一个危险的赌博，因为他们带来宝贵的见解，并充当安全网，避免因对领域特定数据或结果的误解而导致潜在灾难。社会科学专家也适用同样的原则。无数实例表明，忽视这些专家的危险，不论是试图[自动化需要专业知识的决策](https://www.wired.com/story/tech-needs-to-listen-to-actual-researchers/)还是[完全忽视他们的集体智慧](https://www.technologyreview.com/2020/06/23/1004333/ai-science-publishers-perpetuate-racist-face-recognition)。
- en: 4\. *Drinking Our Own Champagne*
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. *自饮自酿*
- en: '![](../Images/03897edd4217c9bf0e6c7ca109a4c250.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03897edd4217c9bf0e6c7ca109a4c250.png)'
- en: '[Image by macrovector on Freepik](https://www.freepik.com/free-vector/qa-engineer-flat-concept-with-software-developer-symbols-flat-vector-illustration_37366036.htm#query=Testing&position=11&from_view=search&track=sph)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[图像来源于macrovector，Freepik](https://www.freepik.com/free-vector/qa-engineer-flat-concept-with-software-developer-symbols-flat-vector-illustration_37366036.htm#query=Testing&position=11&from_view=search&track=sph)'
- en: '"**Drinking our own champagne**" is the practice of testing our own software
    or products within our organization, akin to "**eating our own dog food**." It''s
    a pre-alpha or pre-beta testing method that helps uncover deployment complexities
    before they impact customers or the public. This approach is crucial for identifying
    elusive issues like concept drift, algorithmic discrimination, shortcut learning,
    and underspecification that often elude standard ML development processes.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '"**喝自己的香槟**" 是在组织内测试我们自己软件或产品的做法，类似于 "**吃自己的狗粮**"。这是一种预Alpha或预Beta测试方法，有助于在影响客户或公众之前发现部署复杂性。这种方法对识别像概念漂移、算法歧视、捷径学习和不足规范这些通常逃避标准机器学习开发过程的难题至关重要。'
- en: If it’s not suitable for our organization, it may not be ready for deployment.
    It’s a sip before you serve.
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果它不适合我们的组织，那么它可能还未准备好部署。这是上菜前的试饮。
- en: '*5\. Moving Fast and Breaking Things*'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*5\. 快速行动与打破常规*'
- en: '![](../Images/1fa967c8ee9ed295ac7a98ebacb96f6d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fa967c8ee9ed295ac7a98ebacb96f6d.png)'
- en: '[Image by rawpixel.com on Freepik](https://www.freepik.com/free-photo/caution-alert-critical-error-failure-notice_16482263.htm#query=careful&position=8&from_view=search&track=sph)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源：rawpixel.com，来自Freepik](https://www.freepik.com/free-photo/caution-alert-critical-error-failure-notice_16482263.htm#query=careful&position=8&from_view=search&track=sph)'
- en: In the field of engineering and data science, the t mantra of "move fast and
    break things" often takes center stage. Nevertheless, this approach can be dangerous,
    especially when applied to vital ML systems such as autonomous vehicles, finance,
    healthcare, and beyond. Even a minor glitch could lead to significant harm on
    a large scale.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在工程和数据科学领域，"快速行动，打破常规"的口号通常占据中心位置。然而，这种方法可能很危险，特别是当它应用于关键的机器学习系统，如自动驾驶汽车、金融、医疗等领域时。即使是一个小故障也可能导致大规模的严重危害。
- en: In the race for progress, we must tread carefully, for haste in engineering
    and data science can shatter more than just code.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在进步的竞赛中，我们必须谨慎行事，因为在工程和数据科学中的急功近利可能会摧毁的不仅仅是代码。
- en: It's crucial to shift our mindset to steer clear of such risks. Rather than
    solely concentrating on model accuracy, we should also prioritize understanding
    the implications and potential risks associated with our work.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须转变思维方式，以避免这些风险。我们应该不仅关注模型的准确性，还要优先了解我们工作的影响和潜在风险。
- en: Conclusion
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In conclusion, our exploration of AI incidents, cultural competencies, and risk
    mitigation strategies underscores the critical importance of responsible AI development.
    Cultivating a culture of effective challenge and accountability within organizations
    ensures a proactive stance in identifying and rectifying potential pitfalls. Furthermore,
    integrating diverse and experienced teams and rigorous in-house testing practices
    strengthens the foundation for responsible AI implementation. Lastly, there is
    a necessity to prioritize comprehensive risk assessment over haste. These measures
    collectively guide us towards a future where AI systems are not only technologically
    advanced but also ethically sound, serving as valuable tools for the betterment
    of society.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们对AI事件、文化能力和风险缓解策略的探索突显了负责任的AI开发的重要性。培养组织内有效挑战和问责制的文化，确保了在识别和纠正潜在陷阱时的积极姿态。此外，整合多样化且经验丰富的团队和严格的内部测试实践，强化了负责任AI实施的基础。最后，必须优先考虑全面的风险评估而非急功近利。这些措施共同指引我们走向一个AI系统不仅在技术上先进，而且在伦理上可靠的未来，为社会的进步提供有价值的工具。
- en: '***> Read the next articles in this series >***'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '***> 阅读本系列的下一篇文章 >***'
- en: '[](/organizational-processes-for-machine-learning-risk-management-14f4444dd07f?source=post_page-----c38616c2ccdf--------------------------------)
    [## Organizational Processes for Machine Learning Risk Management'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/organizational-processes-for-machine-learning-risk-management-14f4444dd07f?source=post_page-----c38616c2ccdf--------------------------------)
    [## 机器学习风险管理的组织流程'
- en: Organizational processes are a key nontechnical determinant of reliability in
    ML systems.
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 组织流程是机器学习系统可靠性的关键非技术决定因素。
- en: 'towardsdatascience.com](/organizational-processes-for-machine-learning-risk-management-14f4444dd07f?source=post_page-----c38616c2ccdf--------------------------------)
    [](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----c38616c2ccdf--------------------------------)
    [## Bridging Domains: Infusing Financial, Privacy, and Software Best Practices
    into ML Risk Management'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 跨域桥接：将金融、隐私和软件最佳实践融入机器学习风险管理](https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f?source=post_page-----c38616c2ccdf--------------------------------)
    [](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----c38616c2ccdf--------------------------------)'
- en: Understanding strategies that go beyond traditional Model Risk Management
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解超越传统模型风险管理的策略
- en: towardsdatascience.com](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----c38616c2ccdf--------------------------------)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 跨域桥接：将金融、隐私和软件最佳实践融入机器学习风险管理](https://towardsdatascience.com/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----c38616c2ccdf--------------------------------)'
- en: References & Further Reading
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料与进一步阅读
- en: '[What to Do When AI Fails](https://www.oreilly.com/radar/what-to-do-when-ai-fails/)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI 失败时该怎么办](https://www.oreilly.com/radar/what-to-do-when-ai-fails/)'
- en: '[Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims](https://arxiv.org/pdf/2004.07213.pdf)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[迈向可信赖的 AI 开发：支持可验证声明的机制](https://arxiv.org/pdf/2004.07213.pdf)'
- en: '[Machine Learning For High-Risk Application, Chapter 1 — Contemporary Machine
    Learning Risk Management](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高风险应用的机器学习，第1章 — 现代机器学习风险管理](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)'
