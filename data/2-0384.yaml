- en: 'Beyond Precision and Recall: A Deep Dive Deep into the Tversky Index'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越精确度和召回率：深入探讨Tversky指数
- en: 原文：[https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7](https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7](https://towardsdatascience.com/beyond-precision-and-recall-a-deep-dive-deep-into-the-tversky-index-2b377c2c30b7)
- en: Exploring an alternative classification metric
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索另一种分类度量标准
- en: '[](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[![Mikhail
    Klassen](../Images/9c4a6cc856fd4061f682e95a1c145c36.png)](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    [Mikhail Klassen](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[![米哈伊尔·克拉森](../Images/9c4a6cc856fd4061f682e95a1c145c36.png)](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)[![数据科学之道](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    [米哈伊尔·克拉森](https://mikhailklassen.medium.com/?source=post_page-----2b377c2c30b7--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    ·7 min read·Sep 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [数据科学之道](https://towardsdatascience.com/?source=post_page-----2b377c2c30b7--------------------------------)
    ·阅读时间7分钟·2023年9月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/007d37c92072ebd8b214107ae1e5014e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/007d37c92072ebd8b214107ae1e5014e.png)'
- en: Photo by [Ricardo Arce](https://unsplash.com/@jrarce?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Ricardo Arce](https://unsplash.com/@jrarce?utm_source=medium&utm_medium=referral)
    提供，[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In the world of data science, metrics are the compass that guide our models
    to success. While many are familiar with the classic measures of precision and
    recall, there are actually a wide range of other options that are worth exploring.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学的世界中，度量标准是指导我们模型成功的指南针。虽然许多人对经典的精确度和召回率度量很熟悉，但实际上还有许多其他值得探索的选项。
- en: In this article, we’ll dive into the Tversky index. This metric, a generalization
    of the Dice and Jaccard coefficients, can be extremely useful when trying to balance
    precision and recall against each other. When implemented as a loss function for
    neural networks, it can be a powerful way to deal with class imbalances.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将深入探讨Tversky指数。这一度量标准是Dice和Jaccard系数的推广，在尝试平衡精确度和召回率时非常有用。当作为神经网络的损失函数实施时，它可以成为处理类别不平衡的强大工具。
- en: A quick refresher on precision and recall
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于精确度和召回率的快速复习
- en: Imagine you are a detective tasked with capturing criminals in your town. In
    truth, there are 10 criminals roaming the streets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你是一名侦探，负责捕捉你镇上的罪犯。实际上，有10个罪犯在街上游荡。
- en: In your first month, you bring in 8 suspects you assume to be criminals. Only
    4 of them end up being guilty, while the other 4 are innocent.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的第一个月里，你带来了8个你认为是罪犯的嫌疑人。只有4人最终被判定有罪，其余4人是无辜的。
- en: If you were a machine learning model, you’d be evaluated against your precision
    and recall.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个机器学习模型，你将根据你的精确度和召回率来进行评估。
- en: '**Precision** asks: “of all those you caught, how many were criminals?”'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度**问道：“在你抓到的所有人中，有多少人是罪犯？”'
- en: '**Recall** asks: “of all the criminals in the town, how many did you catch?”'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**召回率**问道：“在镇上所有的罪犯中，你抓到了多少个？”'
- en: '**Precision** is a metric that captures how accurate your predictions are,
    not counting how many true positives you miss (false negatives). **Recall** measures
    how many of the true positives you capture, irrespective of how many false positives
    you get.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**精确度**是一个度量标准，它衡量你预测的准确性，而不计算你错过了多少个真正的正例（假阴性）。**召回率**衡量你捕获了多少个真正的正例，而不管你有多少个假正例。'
- en: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
- en: How do your detective skills rate against these metrics?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你的侦探技能在这些度量标准中表现如何？
- en: precision = 4 / (4 + 4) = 0.5
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: precision = 4 / (4 + 4) = 0.5
- en: recall = 4 / (4 + 6) = 0.4
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: recall = 4 / (4 + 6) = 0.4
- en: 'Balancing precision and recall: the F1 metric'
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平衡精确度和召回率：F1度量
- en: 'In an ideal world, your classifier has both high precision and high recall.
    As a measure of how well your classifier is doing against both, the F1 statistic
    measures the harmonic mean between the two:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想情况下，你的分类器具有高精度和高召回率。作为衡量分类器在这两个方面表现如何的指标，F1 统计量衡量二者之间的调和平均值：
- en: '![](../Images/7780f4c972fd0400459e034122a091b8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7780f4c972fd0400459e034122a091b8.png)'
- en: This metric is also sometimes called the Dice similarity coefficient (DSC).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指标有时也被称为 Dice 相似性系数（DSC）。
- en: 'Measuring similarity another way: the Jaccard coefficient'
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另一种测量相似性的方法：Jaccard 系数
- en: Another way of measuring the similarity between two sets is the **Jaccard similarity
    coefficient**, which is often used in computer vision applications where the goal
    is to identify objects.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种测量两个集合相似性的方法是 **Jaccard 相似性系数**，它通常用于计算机视觉应用中，目标是识别对象。
- en: '![](../Images/93776d9f2a4381aa34277c333f838c81.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93776d9f2a4381aa34277c333f838c81.png)'
- en: 'An object-detection algorithm predicts a bounding box around a stop sign (red).
    Human annotators have labeled the desired bounding region (green). Credit: [Adrian
    Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/),
    [CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一个目标检测算法预测了一个停牌的边界框（红色）。人工标注者标记了期望的边界区域（绿色）。来源：[Adrian Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)，[CC
    BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)
- en: 'The Jaccard coefficient measures the ratio of the intersection of the two sets
    and their union:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Jaccard 系数测量两个集合的交集与它们并集的比率：
- en: '![](../Images/f36d0ce33b094ef866693b6e7fe8a613.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f36d0ce33b094ef866693b6e7fe8a613.png)'
- en: Depicted visually, the intersection-over-union (IoU) is
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 直观展示，交集与并集的比率（IoU）是
- en: '![](../Images/68c50f484216e713a23508d0a3663211.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68c50f484216e713a23508d0a3663211.png)'
- en: 'The Jaccard similarity coefficient is also known as the intersection-over-union
    (IoU). Credit: [Adrian Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/),
    [CC BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Jaccard 相似性系数也被称为交集与并集的比率（IoU）。来源：[Adrian Rosebrock](http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)，[CC
    BY-SA 4.0](https://commons.wikimedia.org/w/index.php?curid=57718561)
- en: Introducing the Tversky index
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Tversky 指数
- en: The Tversky index is a generalization of the Dice coefficient (F1 metric) and
    the Jaccard coefficient and is also used to compare the similarity of two sets,
    *X* and *Y*.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Tversky 指数是 Dice 系数（F1 指标）和 Jaccard 系数的一个推广，也用于比较两个集合 *X* 和 *Y* 的相似性。
- en: 'The index can be formulated as:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 索引可以被公式化为：
- en: '![](../Images/057b8fea01957d2c7a78a331d79a27d1.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/057b8fea01957d2c7a78a331d79a27d1.png)'
- en: 'If the language of set theory isn’t all that familiar, let’s break it down:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果集合论的语言不太熟悉，让我们来解释一下：
- en: '*| X* ∩ *Y |* represents the number of common elements between sets *X* and
    *Y*.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*| X* ∩ *Y |* 表示集合 *X* 和 *Y* 之间的公共元素数量。'
- en: '*| X* ∖ *Y |* represents the number of elements that are in *X* but not in
    *Y*. It is called the relative complement of *Y* in *X.*'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*| X* ∖ *Y |* 表示在 *X* 中但不在 *Y* 中的元素数量。它被称为 *Y* 在 *X* 中的相对补集。'
- en: '*| Y* ∖ *X |* represents the number of elements that are in *Y* but not in
    *X*. It is called the relative complement of *X* in *Y*.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*| Y* ∖ *X |* 表示在 *Y* 中但不在 *X* 中的元素数量。它被称为 *X* 在 *Y* 中的相对补集。'
- en: '*α* and *β* are parameters that determine the relative importance of false
    positives and false negatives, respectively.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*α* 和 *β* 是参数，用于确定假阳性和假阴性的相对重要性。'
- en: The parameters *α* and *β* are important. If we set *α* = *β* = 0.5, we get
    back the Dice coefficient. If we set *α* = *β* = 1.0, we get the Jaccard coefficient.
    In general, we keep *α* + *β* = 1, and this allows us to shift the weight between
    false negatives and false positives.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 参数 *α* 和 *β* 非常重要。如果我们设置 *α* = *β* = 0.5，我们得到的是 Dice 系数。如果我们设置 *α* = *β* = 1.0，我们得到的是
    Jaccard 系数。通常，我们保持 *α* + *β* = 1，这允许我们在假阴性和假阳性之间调整权重。
- en: True positives, false positives, and false negatives
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 真正例、假阳性和假阴性
- en: 'Now, let’s talk about it in the context of classification. Let’s assume *X*
    is the ground truth and *Y* is our prediction. In such a scenario:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在分类的背景下讨论它。假设 *X* 是真实情况，而 *Y* 是我们的预测。在这种情况下：
- en: '*X* ∩ *Y*: True positives (items correctly predicted as positive)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X* ∩ *Y*：真正例（正确预测为正的项）'
- en: '*X* ∖ *Y*: False negatives (items that were positive but predicted as negative)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X* ∖ *Y*：假阴性（被预测为负但实际上是正的项）'
- en: '*Y* ∖ *X*: False positives (items that were negative but predicted as positive)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y* ∖ *X*：假阳性（实际为负例但被预测为正例的项）'
- en: How does it relate to precision and recall?
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它与精确度和召回率有什么关系？
- en: 'Let’s go back to our definitions of precision and recall:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到精确度和召回率的定义：
- en: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86e004501ee6e7e2cca31918adf79448.png)'
- en: Precision is the fraction of true positive predictions among all the predicted
    positives. It tells us how many of the predicted positive instances are actually
    positive.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 精确度是所有预测为正例中的真正正例的比例。它告诉我们预测为正例的实例中实际有多少是正例。
- en: Recall, also known as the sensitivity or true positive rate (TPR), is the fraction
    of true positive predictions among all the actual positives. It tells us how many
    of the actual positive instances were correctly predicted by the model.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 召回率，也称为敏感性或真正率（TPR），是所有实际正例中真正预测的比例。它告诉我们模型正确预测了多少实际正例。
- en: With these interpretations in mind, let’s link the Tversky index to precision
    and recall.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑这些解释后，让我们将 Tversky 指数与精确度和召回率联系起来。
- en: 'When *α* = 1 and *β* = 0:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当*α* = 1且*β* = 0时：
- en: '![](../Images/26e20271cd771050d2d74030b938560b.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26e20271cd771050d2d74030b938560b.png)'
- en: This is the definition of **Recall**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**召回率**的定义。
- en: 'When *α* = 0 and *β* = 1:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当*α* = 0且*β* = 1时：
- en: '![](../Images/54c843a0469ca561246e2a39d7138141.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54c843a0469ca561246e2a39d7138141.png)'
- en: This is the definition of **Precision**.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**精确度**的定义。
- en: Thus, by tweaking the parameters *α* and *β*, the Tversky index can reflect
    either precision or recall, or any weighted mix of both. This makes the Tversky
    index a flexible metric, allowing one to prioritize recall over precision or vice-versa
    depending on the application’s needs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整参数*α*和*β*，Tversky 指数可以反映出精确度或召回率，或两者的加权混合。这使得 Tversky 指数成为一个灵活的度量标准，根据应用需求，可以优先考虑召回率或精确度。
- en: 'Applied to neural networks: the Tversky loss'
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用于神经网络：Tversky 损失
- en: The Tverksy index can be used as a loss function in machine learning applications.
    In neural networks performing classification tasks, such as semantic image segmentation,
    we can use the Tversky index to define a loss function. This is an alternative
    to the usual categorical cross-entropy that is typically employed.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Tversky 指数可以作为机器学习应用中的损失函数。在执行分类任务的神经网络中，如语义图像分割，我们可以使用 Tversky 指数来定义损失函数。这是对通常使用的分类交叉熵的一种替代。
- en: Since the optimizer always tries to minimize the loss, the Tversky Loss (TL)
    is just defined as
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 由于优化器总是尝试最小化损失，Tversky 损失（TL）仅定义为
- en: '![](../Images/1e9158bdf335ef2345f444aab5f7769e.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e9158bdf335ef2345f444aab5f7769e.png)'
- en: where TI is the Tversky index.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 TI 是 Tversky 指数。
- en: Alternatively, it can be defined as
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，它可以被定义为
- en: '![](../Images/331b239fc8608147d12c3cb29f5c8244.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/331b239fc8608147d12c3cb29f5c8244.png)'
- en: Here it will always assume a value between 0 and 1\. Thus, as the loss approaches
    0, our classifier approaches perfect accuracy.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里它的值始终在 0 和 1 之间。因此，随着损失接近 0，我们的分类器接近完美准确度。
- en: The advantage of using the Tversky Loss is that we can tweak the *α* and *β*
    parameters in order to favor recall or precision.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Tversky 损失的优点是我们可以调整*α*和*β*参数，以偏向召回率或精确度。
- en: The Focal Tversky loss
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 焦点 Tversky 损失
- en: Focal Tversky loss is an advanced loss function designed to address class imbalance
    issues in segmentation tasks, especially in medical imaging. It is defined as
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 焦点 Tversky 损失是一个先进的损失函数，旨在解决分割任务中的类别不平衡问题，特别是在医学成像中。它定义为
- en: '![](../Images/eea60aa8fc5ea3310d1e73e726d248dd.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eea60aa8fc5ea3310d1e73e726d248dd.png)'
- en: By incorporating both the Tversky index, which is a generalization of the Dice
    coefficient that weighs false positives and false negatives differently, and a
    focal modulation (γ)to give more importance to hard-to-segment instances, this
    loss function becomes more sensitive to small and ambiguous structures.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合 Tversky 指数（它是对 Dice 系数的推广，按不同方式权衡假阳性和假阴性）和一个焦点调节（γ），以赋予难以分割的实例更多重要性，这个损失函数对小而模糊的结构变得更敏感。
- en: In scenarios where certain regions or classes are underrepresented or where
    certain misclassifications are costlier than others, standard loss functions like
    categorical cross-entropy may not perform optimally. Under such circumstances,
    a researcher might choose Focal Tversky loss as it prioritizes the learning of
    challenging and rare regions, offering better segmentation performance in the
    presence of imbalances and subtle features.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些区域或类别被低估，或某些误分类的代价高于其他情况时，标准的损失函数如分类交叉熵可能无法达到最佳效果。在这种情况下，研究人员可能会选择Focal Tversky损失，因为它优先学习具有挑战性和稀有的区域，在存在不平衡和细微特征的情况下提供更好的分割性能。
- en: 'For more on the Focal Tversky loss, check out this other article from Towards
    Data Science:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于Focal Tversky损失的信息，请查看这篇来自Towards Data Science的文章：
- en: '[](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
    [## Dealing with class imbalanced image datasets using the Focal Tversky Loss'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
    [## 使用Focal Tversky损失处理类别不平衡的图像数据集'
- en: A comparison of losses in class imbalanced problems and why the Focal Tversky
    Loss might be the best option for you
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在类别不平衡问题中的损失比较，以及为什么Focal Tversky损失可能是最适合你的选择
- en: towardsdatascience.com](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5?source=post_page-----2b377c2c30b7--------------------------------)
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In the landscape of classification metrics, the Tversky Index emerges as a versatile
    and adaptable tool. By bridging the gap between traditional metrics like the Dice
    and Jaccard coefficients, it offers data scientists a more nuanced tool to evaluate
    their models. Its flexibility in balancing false positives and false negatives
    through the α and β parameters ensures that it can be tailored to specific needs.
    As a loss function in neural networks, particularly with a focal parameter, it
    becomes a powerful tool for training deep neural networks as well.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类指标的领域中，Tversky指数作为一种多功能且适应性强的工具脱颖而出。它弥合了传统指标如Dice和Jaccard系数之间的差距，为数据科学家提供了一个更为细致的工具来评估模型。通过α和β参数在平衡假阳性和假阴性方面的灵活性，确保它可以根据具体需求进行调整。作为神经网络中的损失函数，尤其是在带有焦点参数的情况下，它也成为训练深度神经网络的强大工具。
