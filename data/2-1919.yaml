- en: Storing Images in TensorFlow Record Files
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 TensorFlow 记录文件中存储图像
- en: 原文：[https://towardsdatascience.com/storing-images-in-tensorflow-record-files-166d030269fb](https://towardsdatascience.com/storing-images-in-tensorflow-record-files-166d030269fb)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/storing-images-in-tensorflow-record-files-166d030269fb](https://towardsdatascience.com/storing-images-in-tensorflow-record-files-166d030269fb)
- en: How to use TFRecord files, a TensorFlow-specific data format for efficient data
    storage and reading, when dealing with images
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用 TFRecord 文件，这是一种针对 TensorFlow 的高效数据存储和读取的数据格式，在处理图像时
- en: '[](https://pascaljanetzky.medium.com/?source=post_page-----166d030269fb--------------------------------)[![Pascal
    Janetzky](../Images/43d68509b63c5f9b3fc9cef3cbfc1a88.png)](https://pascaljanetzky.medium.com/?source=post_page-----166d030269fb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----166d030269fb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----166d030269fb--------------------------------)
    [Pascal Janetzky](https://pascaljanetzky.medium.com/?source=post_page-----166d030269fb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pascaljanetzky.medium.com/?source=post_page-----166d030269fb--------------------------------)[![Pascal
    Janetzky](../Images/43d68509b63c5f9b3fc9cef3cbfc1a88.png)](https://pascaljanetzky.medium.com/?source=post_page-----166d030269fb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----166d030269fb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----166d030269fb--------------------------------)
    [Pascal Janetzky](https://pascaljanetzky.medium.com/?source=post_page-----166d030269fb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----166d030269fb--------------------------------)
    ·6 min read·Mar 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----166d030269fb--------------------------------)
    ·6 分钟阅读·2023年3月2日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'Did you know that TensorFlow has a custom format to store data? It’s called
    TensorFlowRecords — or TFRecords for short—and builds upon a simple principle:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道 TensorFlow 有一种自定义格式来存储数据吗？它叫做 TensorFlowRecords——简称 TFRecords——并建立在一个简单的原则上：
- en: Store data sequentially (within a file) to access continuous chunks quickly.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将数据按顺序存储（在一个文件中），以便快速访问连续的数据块。
- en: 'This approach is based on [protocol buffers](https://protobuf.dev), a cross-platform
    approach to storing structural data. We do not need to dive deeper into the background
    here; what we need to know is that data is stored in a dictionary-like mapping:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法基于[协议缓冲区](https://protobuf.dev)，这是一种跨平台的结构化数据存储方法。我们不需要深入探讨背景；我们需要知道的是数据以类似字典的映射形式存储：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A single file may hold many such “dictionaries,” called *Examples* in TensorFlow,
    as depicted in the following graphic:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一个文件可以包含许多这样的“字典”，在 TensorFlow 中称为*Examples*，如下图所示：
- en: '![](../Images/69cbaf7ba9b6ffb094a9c292aeea5fa9.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69cbaf7ba9b6ffb094a9c292aeea5fa9.png)'
- en: An overview of the concept behind TensorFlow record files. Image by the author.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 记录文件背后的概念概述。图片由作者提供。
- en: 'Within each *Example* — or dictionary — the individual data entries are stored.
    This format is highly flexible: you can store images, text, audio, and any data
    that can be cast to a byte representation. Further, data types can be mixed, letting
    us keep, e.g., images and bounding boxes along with a textual description. However,
    before going too far too soon, we’ll focus on a single modality: images. The remaining
    modalities, audio and text data, will be covered in upcoming posts.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个*Example*——或字典——内，单独的数据条目被存储。这种格式非常灵活：你可以存储图像、文本、音频以及任何可以转换为字节表示的数据。此外，数据类型可以混合，这使我们可以保留，例如，图像和边界框以及文本描述。然而，在过早深入之前，我们将专注于一种模态：图像。其余的模态，音频和文本数据，将在未来的帖子中涵盖。
- en: Based on my experience, I have found it best to cover such an advanced topic
    with simple examples that best showcase the underlying workflow. In this case,
    we use random (image-shaped) matrices.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，最好用简单的示例来讲解这种高级主题，以最佳展示底层的工作流程。在这种情况下，我们使用随机的（图像形状）矩阵。
- en: Storing images
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存储图片
- en: Creating random data
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建随机数据
- en: 'Consider a dataset of 1000 images, each size 224 by 224 with three color channels.
    Each sample of this imaginary dataset is labeled into one of ten classes, 0 to
    9\. Using only the numpy-library, we can create such a dataset easily:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个包含1000张图片的数据集，每张图片的尺寸为224 x 224，包含三个颜色通道。这个虚拟数据集的每个样本都标记为0到9中的一个类别。仅使用numpy库，我们可以轻松创建这样的数据集：
- en: 'The result of this code snippet is a dataset (here: the numpy array) full of
    image-like data.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的结果是一个充满图像数据的数据集（这里是 numpy 数组）。
- en: Helper functions
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 辅助函数
- en: After we have a working dataset, we must convert it into byte data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们拥有一个可用的数据集后，我们必须将其转换为字节数据。
- en: 'To this end, we create four helper functions (see also [here](https://www.tensorflow.org/tutorials/load_data/tfrecord#data_types_for_tftrainexample)).
    The first three helper functions convert certain data types, such as float, to
    a TFRecord-compatible representation. The last helper function turns an array
    into a string of binary data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们创建了四个辅助函数（也见[这里](https://www.tensorflow.org/tutorials/load_data/tfrecord#data_types_for_tftrainexample)）。前三个辅助函数将某些数据类型（如浮点数）转换为TFRecord兼容的表示。最后一个辅助函数将数组转换为二进制数据字符串：
- en: Creating the TFRecord dataset
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建TFRecord数据集
- en: 'These functions come into play once we begin creating the TFRecords files.
    Here, we need a function that creates the layout of a single *Example*, that is,
    the layout for the internal representation of the image we want to store. Using
    our simplified visual representation from before, such an *Example* has multiple
    slots with data, called *Features*:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数在我们开始创建TFRecords文件时发挥作用。在这里，我们需要一个函数来创建单个*Example*的布局，即我们要存储的图像的内部表示布局。使用之前的简化视觉表示，这样的*Example*具有多个包含数据的槽，称为*Features*：
- en: '![](../Images/1faab92c2b453e66337e78ef1bb1583c.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1faab92c2b453e66337e78ef1bb1583c.png)'
- en: A conceptual overview of how data is stored within an *Example. Image by the
    author.*
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据如何在*Example*中存储的概念性概述。图片由作者提供。
- en: For first-time users, creating such a condensed representation can be overwhelming,
    so let's cover it one by one. First, we need to store information to recover the
    input’s data dimensions. For our image use case, this is the height, width (224),
    and number of channels (3). Each number is an integer, meaning we can store them
    as integer data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一次使用者来说，创建这样的浓缩表示可能会感到不知所措，所以让我们逐一介绍。首先，我们需要存储信息以恢复输入的数据维度。对于我们的图像用例，这些是高度、宽度（224）和通道数（3）。每个数字都是整数，这意味着我们可以将它们存储为整数数据。
- en: Second, we need to store an image’s byte representation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们需要存储图像的字节表示。
- en: 'And third, we need to store the label, which, like the data dimensions, is
    stored as integer data. In code, these three requirements are modeled as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，我们需要存储标签，标签像数据维度一样以整数数据形式存储。在代码中，这三个要求建模如下：
- en: 'Next, we need a function that takes the dataset, consisting of the random images
    and their equally random labels, and prepares them for storage. First, we open
    a writer-object that handles writing the data to disk. Afterward, we use a for-loop
    that goes over the numpy arrays, creates image-label pairs, and stores them in
    a TFRecord file using the previously described method. Finally, after we finish
    iterating over the dataset, we close the writer:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要一个函数，它处理包含随机图像及其同样随机标签的数据集，并为存储做好准备。首先，我们打开一个处理将数据写入磁盘的writer对象。之后，我们使用一个遍历numpy数组的for循环，创建图像-标签对，并使用前面描述的方法将它们存储在TFRecord文件中。最后，在我们完成遍历数据集后，我们关闭writer：
- en: That is it! After calling this function, we have a single file that stores our
    entire dataset!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！调用这个函数后，我们将拥有一个存储整个数据集的文件！
- en: Retrieving images
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检索图像
- en: Extract the byte data
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取字节数据
- en: 'When, at a later point, we want to work with the TFRecords, we need to retrieve
    the stored data. Conceptually, we are now *inversing* the process of storing.
    Here, we prepare the structure but don’t fill it with data yet. Be cautious: the
    placeholders must have the same name and an appropriate data type; otherwise,
    the extraction will fail. Then, for each *Example* in the TFRecord file, we extract
    the content and reshape the image:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在之后的时间点想要处理TFRecords时，我们需要检索存储的数据。从概念上讲，我们现在是*反向*存储过程。在这里，我们准备结构，但尚未填充数据。要小心：占位符必须具有相同的名称和适当的数据类型，否则提取将失败。然后，对于TFRecord文件中的每个*Example*，我们提取内容并重新塑造图像：
- en: Create a dataset
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建数据集
- en: 'After coding the routine for extracting data, we need a way to apply it to
    each sample in the TFRecord file. This process, where we parse the data — i.e.,
    bring it into the correct format — is done by mapping the extraction function
    to each *Example*. Here, we rely on TensorFlow’s *tf.data* API, which has such
    functionality on board:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写提取数据的例程后，我们需要一种方法来将其应用于TFRecord文件中的每个样本。这一过程，即将数据解析为正确格式，是通过将提取函数映射到每个*Example*来完成的。在这里，我们依赖于TensorFlow的*tf.data*
    API，它具有这样的功能：
- en: 'Afterward, we point this function to the previously created TFRecord file (here:
    “*random_images.tfrecords*”) and retrieve the data. Then, as a sanity check, we
    can compare an image’s shape and see if it has been recovered correctly:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将此函数指向之前创建的TFRecord文件（这里是“*random_images.tfrecords*”），并检索数据。然后，作为一个 sanity
    check，我们可以比较图像的形状，看看它是否被正确恢复：
- en: Caveats
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 注意事项
- en: 'What we have covered in this post is how to get image data into a TFRecord
    file. There are two caveats, and respectively assumptions:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这篇文章中涵盖的是如何将图像数据放入TFRecord文件。这里有两个注意事项，分别是前提假设：
- en: First, we began with images already loaded into the memory (our numpy arrays).
    And second, in our setup, all examples had the same shape — which is unlikely
    in real-world applications.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从已经加载到内存中的图像（我们的numpy数组）开始。第二，在我们的设置中，所有示例的形状都是相同的——这在实际应用中不太可能。
- en: 'The first point is straightforward to solve: use one of the many excellent
    libraries that do that. Examples here are the [*imageio*](https://pypi.org/project/imageio/)
    library or [Pillow](https://pypi.org/project/Pillow/). For these libraries, plenty
    of tutorials exist, showing you the steps necessary for loading data.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 第一点很容易解决：使用许多优秀的库之一来完成。这里的例子包括[*imageio*](https://pypi.org/project/imageio/)库或[Pillow](https://pypi.org/project/Pillow/)。对于这些库，存在大量教程，展示了加载数据所需的步骤。
- en: 'The second point is a bit more tricky. The challenge is not the creation of
    the TFRecord files but the data loading i*n combination* with batching. Remember
    that we stored the raw image data and its shape via the previous functions? When
    parsing the TFRecord file, this information allows us to restore the image’s appropriate
    shape. However, now, when combining multiple examples into a batch, we face the
    possibility of having various data dimensions: Image 1 might be 224 by 224 pixels,
    but the next might be 124 by 356 pixels.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 第二点稍微复杂一些。挑战在于TFRecord文件的创建，而不是数据加载与批处理的*结合*。记得我们通过之前的函数存储了原始图像数据及其形状吗？在解析TFRecord文件时，这些信息使我们能够恢复图像的适当形状。然而，现在，当将多个示例组合成一个批次时，我们面临着数据维度各异的可能性：图像1可能是224x224像素，但下一个可能是124x356像素。
- en: 'We have a solution for such cases: TensorFlow’s [*padded_batch()*](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch)
    method. To get you started, here’s the previous dataset creation code (which initially
    did not use any batching; samples were just returned one by one) but this time
    with padded batching:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种情况，我们有一个解决方案：TensorFlow的[*padded_batch()*](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#padded_batch)方法。为了帮助你入门，这里是之前的数据集创建代码（最初没有使用任何批处理；样本是一个一个返回的），但这次使用了填充批处理：
- en: The interesting part begins in line 10, which pads each batch in the dataset
    to a fixed shape specified by the padded_shapes argument. The first element of
    the tuple is padded to [256, None, 3], meaning that the first dimension of the
    tensor is fixed to 256, the second dimension is padded to the minimum supported
    length that fits all examples of this batch, and the third dimension is fixed
    to 3\. The second element of the batch tuple, the labels, do not require padding,
    which is why we write [], meaning that no padding should be applied.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的部分从第10行开始，这一行将数据集中的每个批次填充到由`padded_shapes`参数指定的固定形状。元组的第一个元素填充为[256, None,
    3]，这意味着张量的第一个维度固定为256，第二个维度填充为适合该批次所有示例的最小支持长度，第三个维度固定为3。批次元组的第二个元素，即标签，不需要填充，这就是我们写`[]`的原因，表示不应应用任何填充。
- en: Wrapup
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this post, we covered storing one data modality — images — into TFRecord
    files, a TensorFlow-specific data format for efficient data storage and reading.
    In covering the workflow behind it, we generated a dataset of random “images”
    and equally random labels. We then used this dataset to show how to prepare the
    data for storage using three helper functions. Finally, after writing the data
    to disk using TensorFlow-native methods, we also coded the reverse: extracting
    the data from the file. Conceptually, this involved inversing the storage process
    by filling a placeholder dictionary. In the end, we also briefly discussed two
    caveats and how to solve them.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了将一种数据模态——图像——存储到TFRecord文件中，这是一个用于高效数据存储和读取的TensorFlow专用数据格式。在介绍相关工作流程时，我们生成了一组随机的“图像”和同样随机的标签。然后，我们使用这些数据集展示了如何使用三个辅助函数准备数据以供存储。最后，在使用TensorFlow原生方法将数据写入磁盘后，我们还编写了相反的过程：从文件中提取数据。从概念上讲，这涉及通过填充占位符字典来逆转存储过程。最后，我们还简要讨论了两个注意事项及其解决方法。
