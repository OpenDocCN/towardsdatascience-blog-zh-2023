- en: 'Demystifying Bayesian Models: Unveiling Explanability through SHAP Values'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**揭示贝叶斯模型的奥秘：通过SHAP值揭示可解释性**'
- en: 原文：[https://towardsdatascience.com/demystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0?source=collection_archive---------14-----------------------#2023-05-12](https://towardsdatascience.com/demystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0?source=collection_archive---------14-----------------------#2023-05-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/demystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0?source=collection_archive---------14-----------------------#2023-05-12](https://towardsdatascience.com/demystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0?source=collection_archive---------14-----------------------#2023-05-12)
- en: Exploring PyMC’s Insights with SHAP Framework via an Engaging Toy Example
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**通过一个引人入胜的玩具示例探索PyMC的见解与SHAP框架**'
- en: '[](https://medium.com/@vanillaxiangshuyang?source=post_page-----8405f618f4e0--------------------------------)[![Shuyang
    Xiang](../Images/36a5fd18fd9b7b88cb41094f09b83882.png)](https://medium.com/@vanillaxiangshuyang?source=post_page-----8405f618f4e0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8405f618f4e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8405f618f4e0--------------------------------)
    [Shuyang Xiang](https://medium.com/@vanillaxiangshuyang?source=post_page-----8405f618f4e0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vanillaxiangshuyang?source=post_page-----8405f618f4e0--------------------------------)[![Shuyang
    Xiang](../Images/36a5fd18fd9b7b88cb41094f09b83882.png)](https://medium.com/@vanillaxiangshuyang?source=post_page-----8405f618f4e0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8405f618f4e0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8405f618f4e0--------------------------------)
    [Shuyang Xiang](https://medium.com/@vanillaxiangshuyang?source=post_page-----8405f618f4e0--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9b74bc8c860d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0&user=Shuyang+Xiang&userId=9b74bc8c860d&source=post_page-9b74bc8c860d----8405f618f4e0---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8405f618f4e0--------------------------------)
    ·6 min read·May 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8405f618f4e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0&user=Shuyang+Xiang&userId=9b74bc8c860d&source=-----8405f618f4e0---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9b74bc8c860d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0&user=Shuyang+Xiang&userId=9b74bc8c860d&source=post_page-9b74bc8c860d----8405f618f4e0---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8405f618f4e0--------------------------------)
    · 6分钟阅读 · 2023年5月12日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8405f618f4e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0&user=Shuyang+Xiang&userId=9b74bc8c860d&source=-----8405f618f4e0---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8405f618f4e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0&source=-----8405f618f4e0---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8405f618f4e0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdemystifying-bayesian-models-unveiling-explanability-through-shap-values-8405f618f4e0&source=-----8405f618f4e0---------------------bookmark_footer-----------)'
- en: The Gap between Bayesian Models and Explainability
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**贝叶斯模型与可解释性之间的差距**'
- en: SHAP values (SHapley Additive exPlanations) are a game-theory-based method used
    to increase the transparency and interpretability of machine learning models.
    However, this method, along with other machine learning explainability frameworks,
    has rarely been applied to Bayesian models, which provide a posterior distribution
    capturing uncertainty in parameter estimates instead of point estimates used by
    classical machine learning models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP值（SHapley Additive exPlanations）是一种基于博弈论的方法，用于提高机器学习模型的透明度和可解释性。然而，这种方法以及其他机器学习可解释性框架，鲜有应用于贝叶斯模型，而贝叶斯模型提供了捕捉参数估计不确定性的后验分布，而不是经典机器学习模型使用的点估计。
- en: While Bayesian models offer a flexible framework for incorporating prior knowledge,
    adjusting for data limitations, and making predictions, they are unfortunately
    difficult to interpret using SHAP. SHAP regards the model as a game and each feature
    as a player in that game, but the Bayesian model is not a game. It is rather an
    ensemble of games whose parameters come from the posterior distributions. How
    can we interpret a model when it is more than a game?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然贝叶斯模型提供了一个灵活的框架来整合先验知识、调整数据限制和进行预测，但遗憾的是，使用 SHAP 对其进行解释是困难的。SHAP 将模型视为一个游戏，将每个特征视为该游戏中的一个玩家，但贝叶斯模型不是一个游戏。它更像是一个包含来自后验分布的参数的游戏集合。当模型不仅仅是一个游戏时，我们该如何解释它？
- en: This article attempts to explain a Bayesian model using the SHAP framework through
    a toy example. The model is built on PyMC, a probabilistic programming library
    for Python that allows users to construct Bayesian models with a simple Python
    API and fit them using Markov chain Monte Carlo.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本文尝试通过玩具示例使用 SHAP 框架解释贝叶斯模型。该模型建立在 PyMC 上，PyMC 是一个用于 Python 的概率编程库，允许用户通过简单的
    Python API 构建贝叶斯模型，并使用马尔可夫链蒙特卡罗方法对其进行拟合。
- en: The main idea is to apply SHAP to an ensemble of deterministic models generated
    from a Bayesian network. For each feature, we would obtain one sample of the SHAP
    value from a generated deterministic model. The explainability would be given
    by the samples of all obtained SHAP values. We will illustrate this approach with
    a simple example.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思想是将 SHAP 应用于从贝叶斯网络生成的确定性模型的集合。对于每个特征，我们将从生成的确定性模型中获得一个 SHAP 值样本。可解释性将由所有获得的
    SHAP 值样本提供。我们将通过一个简单的示例来说明这种方法。
- en: All the implementations can be found in this [notebook](https://colab.research.google.com/drive/1BXZoicPYSY8ljNlh46WAYrrDBVRdoyqw#scrollTo=6Bk2sYdgKWMS)
    .
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所有实现都可以在这个[笔记本](https://colab.research.google.com/drive/1BXZoicPYSY8ljNlh46WAYrrDBVRdoyqw#scrollTo=6Bk2sYdgKWMS)中找到。
- en: Bayesian modelization with PyMC
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PyMC 进行贝叶斯建模
- en: Dataset
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: 'Consider the following dataset created by the author, which contains 250 points:
    the variable y depends on x1 and x2, both of which vary between 0 and 5\. The
    image below illustrates the dataset:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下由作者创建的数据集，其中包含 250 个点：变量 y 依赖于 x1 和 x2，两个变量都在 0 到 5 之间变化。下图说明了数据集：
- en: '![](../Images/8270f34dfea06227ff5da7ceac8b3345.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8270f34dfea06227ff5da7ceac8b3345.png)'
- en: 'Image by author: Dataset'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者提供：数据集
- en: 'Let’s quickly explore the data using a pair plot. From this, we can observe
    the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用配对图快速探索数据。从中我们可以观察到以下几点：
- en: The variables x1 and x2 are not correlated.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 变量 x1 和 x2 不相关。
- en: Both variables contribute to the output y to some extent. That is, a single
    variable is not enough to obtain y.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个变量在某种程度上都对输出 y 有贡献。也就是说，单一变量不足以获得 y。
- en: '![](../Images/7ba2e0867684251e8aecdd19b0c04a2e.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ba2e0867684251e8aecdd19b0c04a2e.png)'
- en: 'Image by author: pair plot of the data'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者提供：数据的配对图
- en: Modelization with PyMC
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PyMC 进行建模
- en: Let’s build a Bayesian model with PyMC. Without going into the details that
    you can find in any statistical book, we’ll simply recall that the training process
    of Bayesian machine learning models involves updating the model’s parameters based
    on observed data and prior knowledge using [Bayesian rules](https://en.wikipedia.org/wiki/Bayes%27_theorem).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 PyMC 构建一个贝叶斯模型。在不深入讨论任何统计学书籍中可以找到的细节的情况下，我们只需回顾一下贝叶斯机器学习模型的训练过程涉及根据观察到的数据和先验知识使用[贝叶斯规则](https://en.wikipedia.org/wiki/Bayes%27_theorem)来更新模型的参数。
- en: 'We define the model’s structure as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将模型的结构定义如下：
- en: '![](../Images/e3657c471d6b7dffcd1d435357c57078.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3657c471d6b7dffcd1d435357c57078.png)'
- en: 'Image by author: model structure'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图片作者提供：模型结构
- en: Defining the priors and likelihood above, we’ll use the PyMC standard sampling
    algorithm NUTS designed to automatically tune its parameters, such as the step
    size and the number of leapfrog steps, to achieve efficient exploration of the
    target distribution. It repeats a tree exploration to simulate the trajectory
    of the point in the parameter space and determine whether to accept or reject
    a sample. Such iteration stops either when the maximum number of iterations is
    reached or the level of convergence is achieved.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了先验和似然之后，我们将使用 PyMC 标准采样算法 NUTS，该算法旨在自动调整其参数，例如步长和 leapfrog 步数，以实现对目标分布的有效探索。它通过树探索重复模拟点在参数空间中的轨迹，并确定是否接受或拒绝样本。此类迭代在达到最大迭代次数或达到收敛水平时停止。
- en: You can see in the code below that we set up the priors, define the likelihood,
    and then run the sampling algorithm using PyMC.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在下面的代码中看到，我们设置了先验，定义了似然，然后使用PyMC运行了采样算法。
- en: Let’s build a Bayesian model using PyMC. Bayesian machine learning model training
    involves updating the model’s parameters based on observed data and prior knowledge
    using [Bayesian rules](https://en.wikipedia.org/wiki/Bayes%27_theorem). We won’t
    go into detail here, as you can find it in any statistical book.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用PyMC构建一个贝叶斯模型。贝叶斯机器学习模型训练涉及基于观察数据和先验知识更新模型参数，使用[贝叶斯规则](https://en.wikipedia.org/wiki/Bayes%27_theorem)。我们不会在这里详细介绍，因为你可以在任何统计学书籍中找到。
- en: 'We can define the model’s structure as shown below:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以定义如下的模型结构：
- en: '![](../Images/e3657c471d6b7dffcd1d435357c57078.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e3657c471d6b7dffcd1d435357c57078.png)'
- en: 'Image by author: model structure'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型结构
- en: For the priors and likelihood defined above, we’ll use the PyMC standard sampling
    algorithm NUTS. This algorithm is designed to automatically tune its parameters,
    such as the step size and the number of leapfrog steps, to achieve efficient exploration
    of the target distribution. It repeats a tree exploration to simulate the trajectory
    of the point in the parameter space and determine whether to accept or reject
    a sample. The iteration stops either when the maximum number of iterations is
    reached or the level of convergence is achieved.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对于上述定义的先验和似然，我们将使用PyMC标准采样算法NUTS。该算法旨在自动调整其参数，如步长和跳跃步数，以实现对目标分布的高效探索。它重复进行树形探索，以模拟点在参数空间中的轨迹，并决定是否接受或拒绝样本。迭代在达到最大迭代次数或实现收敛水平时停止。
- en: In the code below, we set up the priors, define the likelihood, and then run
    the sampling algorithm using PyMC.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们设置先验，定义似然，然后使用PyMC运行采样算法。
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The trace plot below displays the posteriors of the parameters in the model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的踪迹图展示了模型中参数的后验分布。
- en: '![](../Images/d9bd6126610e95f170e9945c28f6d69d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9bd6126610e95f170e9945c28f6d69d.png)'
- en: 'Image by author: posterior of the model'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型的后验
- en: Explain the model with SHAP
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SHAP解释模型
- en: We now want to implement SHAP on the model described above. Note that for a
    given input (x1, x2), the model’s output y is a probability conditional on the
    parameters. Thus, we can obtain a deterministic model and corresponding SHAP values
    for all features by drawing one sample from the obtained posteriors. Alternatively,
    if we draw an ensemble of parameter samples, we will get an ensemble of deterministic
    models and, therefore, samples of SHAP values for all features.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在希望在上述模型上实现SHAP。注意，对于给定的输入（x1, x2），模型的输出y是条件概率。因此，通过从获得的后验中绘制一个样本，我们可以获得一个确定性的模型及其所有特征的SHAP值。或者，如果我们绘制一个参数样本的集合，我们将得到一个确定性模型的集合，因此，所有特征的SHAP值样本。
- en: 'The posteriors can be obtained using the following code, where we draw 200
    samples per chain:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下代码获得后验分布，我们每条链绘制200个样本：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is the table of the data variables from the posteriors:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是后验数据变量的表格：
- en: '![](../Images/6b8670693ea9602bb39d4fd5b97f975c.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b8670693ea9602bb39d4fd5b97f975c.png)'
- en: 'Image by author: samples from posteriors'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：后验样本
- en: Next, we compute one pair of SHAP values for each drawn sample of model parameters.
    The code below loops over the parameters, defines one model for each parameter
    sample, and computes the SHAP values of x_test=(2,3) of interest.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们为每个绘制的模型参数样本计算一对SHAP值。下面的代码对参数进行循环，为每个参数样本定义一个模型，并计算感兴趣的x_test=(2,3)的SHAP值。
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The resulting ensemble of the two-dimensional SHAP values of the input is shown
    below:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 输入的二维SHAP值的结果集如下所示：
- en: '![](../Images/d242b0e663af7c769bb68e828be43d6b.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d242b0e663af7c769bb68e828be43d6b.png)'
- en: 'Image by author: SHAP values samples'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：SHAP值样本
- en: 'From the plot above, we can infer the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的图表中，我们可以推断出以下内容：
- en: The SHAP values of both dimensions form more or less a normal distribution.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个维度的SHAP值大致形成一个正态分布。
- en: The first dimension has a positive contribution (-1.75 as median) to the model,
    while the second has a negative contribution (3.45 as median). However, the second
    dimension’s contribution has a bigger absolute value.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个维度对模型有正贡献（中位数为-1.75），而第二个维度有负贡献（中位数为3.45）。不过，第二个维度的贡献绝对值更大。
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This article explores the use of SHAP values, a game-theory-based method for
    increasing transparency and interpretability of machine learning models, in Bayesian
    models. A toy example is used to demonstrate how SHAP can be applied to a Bayesian
    network.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 本文探讨了SHAP值的使用，这是一种基于博弈论的方法，用于提高机器学习模型的透明度和可解释性，应用于贝叶斯模型。通过一个玩具示例演示了SHAP如何应用于贝叶斯网络。
- en: Please note that SHAP is model-agnostic. Therefore, with changes to its implementation,
    it may be possible to apply SHAP directly to the Bayesian model itself in the
    future.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，SHAP是模型无关的。因此，随着其实现方式的变化，未来可能可以直接将SHAP应用于贝叶斯模型本身。
