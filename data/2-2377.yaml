- en: Why Simple Models Are Often Better
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么简单模型往往更好
- en: 原文：[https://towardsdatascience.com/why-simple-models-are-often-better-e2428964811a](https://towardsdatascience.com/why-simple-models-are-often-better-e2428964811a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/why-simple-models-are-often-better-e2428964811a](https://towardsdatascience.com/why-simple-models-are-often-better-e2428964811a)
- en: The significance of Occam’s Razor in data science and machine learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 奥卡姆剃刀在数据科学和机器学习中的重要性
- en: '[](https://thomasdorfer.medium.com/?source=post_page-----e2428964811a--------------------------------)[![Thomas
    A Dorfer](../Images/9258a1735cee805f1d9b02e2adf01096.png)](https://thomasdorfer.medium.com/?source=post_page-----e2428964811a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e2428964811a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e2428964811a--------------------------------)
    [Thomas A Dorfer](https://thomasdorfer.medium.com/?source=post_page-----e2428964811a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://thomasdorfer.medium.com/?source=post_page-----e2428964811a--------------------------------)[![Thomas
    A Dorfer](../Images/9258a1735cee805f1d9b02e2adf01096.png)](https://thomasdorfer.medium.com/?source=post_page-----e2428964811a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e2428964811a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e2428964811a--------------------------------)
    [Thomas A Dorfer](https://thomasdorfer.medium.com/?source=post_page-----e2428964811a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e2428964811a--------------------------------)
    ·8 min read·Jan 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e2428964811a--------------------------------)
    ·8分钟阅读·2023年1月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e1dc823456e970d8e19dbd386739e884.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1dc823456e970d8e19dbd386739e884.png)'
- en: Photo by [Pablo Arroyo](https://unsplash.com/@pablogamedev) on [Unsplash](https://unsplash.com/photos/_SEbdtH4ZLM)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影：[Pablo Arroyo](https://unsplash.com/@pablogamedev) 在 [Unsplash](https://unsplash.com/photos/_SEbdtH4ZLM)
- en: In data science and machine learning, simplicity is an important concept that
    can have significant impact on model characteristics such as performance and interpretability.
    Over-engineered solutions tend to adversely affect these characteristics by increasing
    the likelihood of overfitting, decreasing computational efficiency, and lowering
    the transparency of the model’s output.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学和机器学习中，简洁是一个重要概念，对模型的性能和可解释性等特性有着显著影响。过度工程化的解决方案往往会通过增加过拟合的可能性、降低计算效率和减少模型输出的透明度，从而对这些特性产生不利影响。
- en: The latter is particularly important for areas that require a certain degree
    of interpretability, such as medicine and healthcare, finance, or law. The inability
    to interpret and trust a model’s decision — and to ensure that this decision is
    fair and unbiased — can have serious consequences for individuals whose fate depends
    on it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 后者对于需要一定解释性领域尤为重要，如医学和医疗保健、金融或法律。无法解释和信任模型的决策，并确保这一决策公平无偏，对那些命运依赖于此的个人可能带来严重后果。
- en: This article aims to highlight the importance of giving precedence to simplicity
    when it comes to implementing a data science or machine learning solution. We
    will first introduce the principle of **Occam’s razor**, before delving into the
    advantages of simplicity and ultimately determining when it is necessary to add
    complexity.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在强调在实施数据科学或机器学习解决方案时优先考虑简洁性的重要性。我们将首先介绍**奥卡姆剃刀**的原则，然后深入探讨简洁性的优势，并最终确定何时需要增加复杂性。
- en: Occam’s Razor
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奥卡姆剃刀
- en: Occam’s razor, also known as the *law of parsimony*, is a philosophical problem-solving
    principle attributed to William of Ockham — a 14th century English philosopher
    and theologian. The original principle is often cited as *Entia non sunt multiplicanda
    praeter necessitatem*, which roughly translates to“Entities must not be multiplied
    beyond necessity”.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 奥卡姆剃刀，也称为*简约法则*，是一个哲学问题解决原则，归功于14世纪的英语哲学家和神学家威廉·奥卡姆。原始原则通常被引用为*Entia non sunt
    multiplicanda praeter necessitatem*，大致翻译为“实体不应超出必要性而被增多”。
- en: '![](../Images/7be075709ab568cd25a11c5c40b463cd.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7be075709ab568cd25a11c5c40b463cd.png)'
- en: Photo by [Hair Spies](https://unsplash.com/@hairspies) on [Unsplash](https://unsplash.com/photos/mXw0CfTPUrM)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影：[Hair Spies](https://unsplash.com/@hairspies) 在 [Unsplash](https://unsplash.com/photos/mXw0CfTPUrM)
- en: Within the realm of data science and machine learning, this is typically interpreted
    as something like “Simpler models are generally preferred over complex ones” or
    “All things being equal, the simplest solution tends to be the best”. The *razor*
    in Occam’s razor symbolizes the “shaving away” of unnecessary complexity and assumptions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学和机器学习领域，这通常被解释为“简单模型通常比复杂模型更受青睐”或“在其他条件相同的情况下，最简单的解决方案往往是最好的”。奥卡姆剃刀中的 *剃刀*
    象征着“剃去”不必要的复杂性和假设。
- en: Advantages of Simple Solutions
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单解决方案的优势
- en: Reduced Susceptibility to Overfitting
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 减少过拟合的敏感性
- en: One of the main advantages of simpler models is that they are less susceptible
    to overfitting. Overfitting occurs when a model becomes too complex and starts
    fitting the noise in the training data, rather than the underlying pattern. This
    often leads to poor performance on unseen data, resulting in a lack of generalizability
    and, consequently, limited applicability of the model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 简单模型的主要优势之一是它们不易过拟合。过拟合发生在模型变得过于复杂并开始拟合训练数据中的噪声，而不是潜在的模式。这通常会导致在未见数据上的表现不佳，结果是模型的泛化能力差，应用性有限。
- en: 'There are several techniques that can be applied to obtain a model with a reduced
    susceptibility to overfit:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 可以应用几种技术来获得对过拟合敏感性较低的模型：
- en: '**Cross-validation:** The model is trained on a training set and its performance
    is assessed on an independent validation set. The most common type is k-fold cross-validation,
    whereby the data is divided into *k* subsets, the model is trained on *k-1* subsets
    and eventually evaluated on the remaining subset (the validation set).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉验证：** 模型在训练集上训练，并在独立的验证集上评估其性能。最常见的类型是 k 折交叉验证，其中数据被分成 *k* 个子集，模型在 *k-1*
    个子集上训练，并最终在剩余的子集（验证集）上进行评估。'
- en: '**Data augmentation:** Larger datasets tend to reduce overfitting. However,
    if large data is not available, the current data can be augmented through the
    production of artificial or synthetic data. The exact process here depends on
    the nature of the data. For instance, when dealing with image data, data size
    can be increased by applying transformations to the images such as rotations,
    flipping, rescaling, etc.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据增强：** 较大的数据集往往能减少过拟合。然而，如果没有大数据，可以通过生成人工或合成数据来增强现有数据。具体过程取决于数据的性质。例如，在处理图像数据时，可以通过对图像应用旋转、翻转、缩放等变换来增加数据量。'
- en: '**Regularization:** This technique constrains the model’s parameters by adding
    a penalty term to the loss function. The most common techniques are L1, or Lasso,
    regularization, and L2, or Ridge, regularization. While L1 regularization can
    result in some of the model weights being set to zero, effectively removing these
    features from the model, L2 regularization reduces the weights only asymptotically
    toward zero, resulting in all features being used to determine the model output.
    Moreover, dropout is a frequently used regularization method for neural networks,
    whereby a certain percentage of neurons are randomly set to zero during each training
    iteration. This ensures that the remaining neurons learn more robust features
    since they are no longer able to rely on the dropped-out neurons to carry the
    burden of prediction.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化：** 这种技术通过在损失函数中添加惩罚项来限制模型的参数。最常见的技术是 L1（Lasso）正则化和 L2（Ridge）正则化。L1 正则化可以导致一些模型权重被设置为零，从而有效地从模型中移除这些特征，而
    L2 正则化仅将权重渐近地减少到零，结果是所有特征都被用来决定模型输出。此外，dropout 是一种常用于神经网络的正则化方法，在每次训练迭代中，随机将一定比例的神经元设置为零。这确保了剩余的神经元学习到更强大的特征，因为它们不再依赖被丢弃的神经元来承担预测的负担。'
- en: '**Feature selection:** Removing features that are deemed redundant or irrelevant
    from the training data will inevitably simplify the model and improve its computational
    performance. Features can either be removed manually, based on domain knowledge,
    or through methods such as univariate filtering, tree-based feature importance,
    recursive feature elimination, etc..'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征选择：** 从训练数据中删除被认为是冗余或不相关的特征将不可避免地简化模型并提高其计算性能。特征可以通过领域知识手动删除，也可以通过单变量过滤、基于树的特征重要性、递归特征消除等方法删除。'
- en: '**Dimensionality reduction:** Similar to feature selection, dimensionality
    reduction techniques such as principal component analysis (PCA), linear discriminant
    analysis (LDA), or t-distributed stochastic neighbor embedding (tSNE) reduce the
    input dimensions to the model. However, the features they return are either a
    linear or nonlinear combination of the original features, which would in turn
    reduce the interpretability of the model as it would be hard to determine which
    original features contributed to the model’s decisions.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降维：** 与特征选择类似，降维技术如主成分分析（PCA）、线性判别分析（LDA）或t分布随机邻居嵌入（tSNE）将输入维度减少到模型中。然而，它们返回的特征要么是原始特征的线性组合，要么是非线性组合，这会减少模型的可解释性，因为很难确定哪些原始特征对模型的决策做出了贡献。'
- en: '**Early stopping:** This is a method applied to neural networks that stops
    the model training once its performance on a validation set has started to degrade.
    Essentially, it prevents overfitting by stopping the training before the model
    becomes too complex.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**早停法：** 这是应用于神经网络的一种方法，当模型在验证集上的性能开始下降时，停止模型训练。本质上，它通过在模型变得过于复杂之前停止训练来防止过拟合。'
- en: '**Decrease model complexity:** Choosing a model with fewer parameters and a
    simpler architecture to begin with can also significantly contribute to the prevention
    of overfitting.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少模型复杂性：** 选择一个初始参数较少、架构更简单的模型也可以显著有助于防止过拟合。'
- en: Increased Computational Efficiency
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提高计算效率
- en: Simpler models generally boost computational performance. This boost is mainly
    achieved by the model requiring **fewer parameters**, **fewer computations**,
    and **lower memory usage**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 更简单的模型通常能提升计算性能。这种提升主要通过模型需要**更少的参数**、**更少的计算**和**更低的内存使用**来实现。
- en: This can also result in significant benefits when it comes to model deployment.
    As simpler models tend to have lower inference time and lower memory usage, they
    can be more easily deployed to resource-constrained devices such as smartphones
    and smart watches, potentially establishing a new customer base.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型部署方面，这也可能带来显著的好处。由于更简单的模型通常具有较低的推理时间和内存使用，因此它们可以更容易地部署到资源受限的设备，如智能手机和智能手表，从而可能建立一个新的客户群体。
- en: For instance, in natural language processing, simple n-gram models have been
    demonstrated to perform as well as their neural counterparts, while being considerably
    faster. [Doval & Gómez‐Rodríguez (2019)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6360409/)
    compared recurrent neural networks with n-gram models on a word segmentation task
    and found that the precision of the n-gram models was almost on par with neural
    network approaches. Moreover, n-gram models significantly outperformed recurrent
    neural networks in execution time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在自然语言处理领域，简单的n-gram模型已被证明能够与其神经网络模型表现相当，同时速度明显更快。[Doval & Gómez‐Rodríguez（2019）](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6360409/)比较了递归神经网络和n-gram模型在词汇分割任务上的表现，发现n-gram模型的精度几乎与神经网络方法相当。此外，n-gram模型在执行时间上显著优于递归神经网络。
- en: Similarly, in optical character recognition, a simple k-nearest neighbor (kNN)
    algorithm has been shown to yield similar accuracies — while having significantly
    shorter execution times — as convolutional neural networks (CNNs) for certain
    tasks. For example, [Sharma et al. (2022)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9307347/)
    assessed the performance of various classifiers on a handwritten digit recognition
    task and found that, while a CNN yielded an accuracy of 98.83%, a lightweight
    kNN performed almost just as well at 97.83%, while achieving much better computational
    performance.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在光学字符识别中，简单的k近邻（kNN）算法已被证明在某些任务上具有与卷积神经网络（CNNs）相似的准确度，同时执行时间显著较短。例如，[Sharma等（2022）](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9307347/)评估了各种分类器在手写数字识别任务上的性能，发现虽然CNN的准确度为98.83%，但轻量级kNN的表现几乎一样好，准确度为97.83%，同时具有更好的计算性能。
- en: Increased Interpretability
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提高可解释性
- en: Being able to interpret a model’s decision and to ensure that this decision
    is **not unfair or biased** is critical, particularly in domains wherein the outcome
    can have serious consequences for individual persons.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 能够解释模型的决策，并确保这些决策**不不公平或有偏见**，这是至关重要的，尤其是在那些结果可能对个人造成严重后果的领域。
- en: In **medical imaging**, for instance, it matters that doctors are able to interpret,
    understand, and trust the results of their model. If a radiologist is not able
    to confirm or refute a model’s negative prediction on a cancer diagnosis, they
    may order further tests — some requiring invasive procedures — to establish a
    diagnosis. If these ultimately confirm that the patient does not have cancer,
    it can be argued that, as a result of the model’s lack of interpretability, the
    patient was exposed to unnecessary, invasive procedures, which could have been
    avoided had the radiologist been able to trust the model’s decision in the first
    place.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在**医学影像**领域，例如，医生能够解释、理解并信任他们的模型结果是很重要的。如果放射科医生无法确认或反驳模型对癌症诊断的负面预测，他们可能会要求进一步的检查——一些需要侵入性程序——以确立诊断。如果这些检查最终确认患者没有癌症，可以说，由于模型的不可解释性，患者暴露于不必要的侵入性程序中，而这些程序本可以避免，如果放射科医生能在最初就信任模型的决定。
- en: '![](../Images/b2062c63a6db4fc588ddad736fbb795c.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2062c63a6db4fc588ddad736fbb795c.png)'
- en: Photo by [National Cancer Institute](https://unsplash.com/@nci) on [Unsplash](https://unsplash.com/photos/BDKid0yJcAk)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[国家癌症研究所](https://unsplash.com/@nci)提供，发布在[Unsplash](https://unsplash.com/photos/BDKid0yJcAk)
- en: Similarly, the output of a prediction model can determine whether a cancer patient
    will receive treatment or not. Clearly, these results can have substantial consequences
    for the individuals involved and thus it is critical that the model is simple
    enough to be transparent and trustworthy.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，预测模型的输出可以决定癌症患者是否接受治疗。显然，这些结果对相关个人可能有重大后果，因此模型必须足够简单，以便透明和可信。
- en: In **credit scoring**, an opaque model can yield biased results that are completely
    divorced from reality. Imagine a model, whose aim it is to predict creditworthiness,
    was trained on historical data containing various biases, causing it to favor
    certain groups of people over others. If a person from an underrepresented group
    applies for a loan, the model may decide that they are a high-risk borrower and
    thus deny the application, even though in reality they have a solid credit history.
    This lack of model interpretability can seriously affect individuals who planned
    to purchase a home, start a business, or explore other opportunities that required
    some initial capital.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在**信用评分**中，一个不透明的模型可能会产生与现实完全脱节的偏见结果。想象一个旨在预测信用worthiness的模型，如果它在包含各种偏见的历史数据上训练，就会导致它偏向某些群体。如果一个来自被低估群体的人申请贷款，该模型可能会认为他们是高风险借款人，从而拒绝申请，即使他们实际上有良好的信用记录。这种模型缺乏可解释性可能严重影响那些计划购买房屋、创业或探索需要一些初始资本的机会的个人。
- en: '![](../Images/752eb830a5688c375f414b57fd4029ea.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/752eb830a5688c375f414b57fd4029ea.png)'
- en: Photo by [Etienne Martin](https://unsplash.com/@etiennemartin) on [Unsplash](https://unsplash.com/photos/2_K82gx9Uk8)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[艾蒂安·马丁](https://unsplash.com/@etiennemartin)提供，发布在[Unsplash](https://unsplash.com/photos/2_K82gx9Uk8)
- en: The same principle applies to the field of **criminal justice**. Imagine a model
    used to predict the probability of a person reoffending based on their personal
    information, criminal history, and various other factors. If that model was trained
    on biased data, it may end up favoring groups of higher socioeconomic status and,
    as a result, predict a higher likelihood of recidivism for all other groups. A
    person from a lower socioeconomic status may thus be denied bail and kept in detention
    even though in reality they may have a very low risk of reoffending. Again, working
    with a model that is both simple and transparent would reduce the probability
    of these adverse outcomes.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的原则适用于**刑事司法**领域。想象一个用于预测个人再犯罪概率的模型，这个模型基于个人信息、犯罪历史和各种其他因素。如果该模型在偏见数据上训练，它可能会偏向社会经济地位较高的群体，因此预测其他群体的再犯罪可能性更高。来自低社会经济地位的个人可能因此被拒绝保释并继续拘留，即使实际上他们可能再犯罪的风险非常低。再次强调，使用一个既简单又透明的模型可以减少这些不良结果的概率。
- en: In all these categories listed above, the easiest way to achieve higher interpretability
    is by choosing a simpler model. For example, choosing a decision tree-based algorithm
    over a complex neural network could significantly enhance the transparency of
    the output as the internal tree structure can be easily visualized. This allows
    individual decisions to be traced, which can provide critical insights into how
    a particular prediction came about. This makes decision trees widely applicable
    in areas where prediction errors can have dire consequences, such as those outlined
    above.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述所有类别中，实现更高可解释性的最简单方法是选择更简单的模型。例如，选择基于决策树的算法而不是复杂的神经网络，可以显著提高输出的透明度，因为内部树结构可以轻松可视化。这使得个别决策可以被追溯，从而提供有关特定预测形成过程的关键见解。这使得决策树在预测错误可能产生严重后果的领域（如上述所列）中广泛适用。
- en: When Complexity Is Necessary
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复杂性必要时
- en: While simple is *often* better, this is not always the case. An overly simplistic
    model can miss the relevant relations between features and target variables, ultimately
    leading to underfitting.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然简单*通常*更好，但这并非总是如此。一个过于简单的模型可能会遗漏特征与目标变量之间的相关关系，*最终*导致欠拟合。
- en: When dealing with **large and high-dimensional datasets** whose features have
    **nonlinear relationships** with one another, more complex models such as neural
    networks may be necessary in order to capture the underlying patterns in the data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理具有**非线性关系**的**大规模高维数据集**时，可能需要更复杂的模型，如神经网络，以捕捉数据中的潜在模式。
- en: Some applications may also have **high accuracy requirements** that a simple
    model is not able to meet. When implementing a more complex model to boost performance,
    however, the result is often reduced transparency. Therefore, it is also important
    to find a healthy **trade-off between model performance and interpretability**.
    For instance, in medical imaging, high accuracy is a critical characteristic when
    it comes to detecting abnormalities and making decisions about a patient’s life.
    However, as discussed above, it is equally important that doctors are able to
    understand, interpret, and trust those decisions in order to establish a reliable
    diagnostic procedure.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 某些应用可能还具有**高准确性要求**，简单模型无法满足。当实施更复杂的模型以提高性能时，结果通常是透明度降低。因此，找到**模型性能与可解释性之间的平衡**也很重要。例如，在医学影像中，高准确性对于检测异常和做出有关患者生命的决策至关重要。然而，如上所述，同样重要的是医生能够理解、解释和信任这些决策，以建立可靠的诊断程序。
- en: Conclusion
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: While simple models are certainly not a panacea for all problems, they are the
    preferred choice when a high degree of interpretability and computational efficiency
    is desired. Moreover, they tend to prevent overfitting, leading to higher generalizability
    and applicability of the model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管简单模型确实不是所有问题的万灵药，但在需要高可解释性和计算效率时，它们是首选。此外，它们往往能防止过拟合，从而提高模型的泛化能力和适用性。
- en: In certain situations, however, there is a necessity to increase the level of
    complexity of a solution. This is often the case when dealing with high-dimensional,
    nonlinear data or when a solution requires a high degree of accuracy that would
    otherwise be hard to achieve using a simpler model.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，确实有必要增加解决方案的复杂性。当处理高维非线性数据或当解决方案需要高度准确性而简单模型难以实现时，这种情况尤为常见。
- en: References
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Doval & Gómez‐Rodríguez (2019). “Comparing neural‐ and N‐gram‐based language
    models for word segmentation*”.* J Assoc Inf Sci Technol, 70(2): 187–197.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Doval & Gómez‐Rodríguez (2019). “比较神经网络与N-gram语言模型进行词语分割*”。* J Assoc Inf
    Sci Technol, 70(2): 187–197.'
- en: '[2] Sharma (2022). “A Machine Learning and Deep Learning Approach for Recognizing
    Handwritten Digits*”.* Comput Intell Neurosci, doi: 10.1155/2022/9869948.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Sharma (2022). “识别手写数字的机器学习和深度学习方法*”。* Comput Intell Neurosci, doi: 10.1155/2022/9869948.'
