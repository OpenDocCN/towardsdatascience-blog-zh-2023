- en: 'A Universal Roadmap for Prompt Engineering: The Contextual Scaffolds Framework
    (CSF)'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一种通用的提示工程路线图：背景支架框架（CSF）
- en: 原文：[https://towardsdatascience.com/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a?source=collection_archive---------3-----------------------#2023-10-25](https://towardsdatascience.com/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a?source=collection_archive---------3-----------------------#2023-10-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a?source=collection_archive---------3-----------------------#2023-10-25](https://towardsdatascience.com/a-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a?source=collection_archive---------3-----------------------#2023-10-25)
- en: A general purpose mental model for effective prompt engineering.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种有效提示工程的通用心理模型。
- en: '[](https://medium.com/@hominum_universalis?source=post_page-----fdaf5a9fa86a--------------------------------)[![Giuseppe
    Scalamogna](../Images/ff7b3bec7c26e5684fba26211b6f027a.png)](https://medium.com/@hominum_universalis?source=post_page-----fdaf5a9fa86a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fdaf5a9fa86a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fdaf5a9fa86a--------------------------------)
    [Giuseppe Scalamogna](https://medium.com/@hominum_universalis?source=post_page-----fdaf5a9fa86a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@hominum_universalis?source=post_page-----fdaf5a9fa86a--------------------------------)[![Giuseppe
    Scalamogna](../Images/ff7b3bec7c26e5684fba26211b6f027a.png)](https://medium.com/@hominum_universalis?source=post_page-----fdaf5a9fa86a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fdaf5a9fa86a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fdaf5a9fa86a--------------------------------)
    [Giuseppe Scalamogna](https://medium.com/@hominum_universalis?source=post_page-----fdaf5a9fa86a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe039aa8b7221&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a&user=Giuseppe+Scalamogna&userId=e039aa8b7221&source=post_page-e039aa8b7221----fdaf5a9fa86a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fdaf5a9fa86a--------------------------------)
    ·7 min read·Oct 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffdaf5a9fa86a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a&user=Giuseppe+Scalamogna&userId=e039aa8b7221&source=-----fdaf5a9fa86a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe039aa8b7221&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a&user=Giuseppe+Scalamogna&userId=e039aa8b7221&source=post_page-e039aa8b7221----fdaf5a9fa86a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fdaf5a9fa86a--------------------------------)
    ·7分钟阅读·2023年10月25日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffdaf5a9fa86a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a&user=Giuseppe+Scalamogna&userId=e039aa8b7221&source=-----fdaf5a9fa86a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdaf5a9fa86a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a&source=-----fdaf5a9fa86a---------------------bookmark_footer-----------)![](../Images/11bd757f9b0539829373e16710b28052.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffdaf5a9fa86a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-universal-roadmap-for-prompt-engineering-the-contextual-scaffolds-framework-csf-fdaf5a9fa86a&source=-----fdaf5a9fa86a---------------------bookmark_footer-----------)![](../Images/11bd757f9b0539829373e16710b28052.png)'
- en: Image by Author and Generated with DALL·E 3
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供并通过 DALL·E 3 生成
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: In my recent articles, I explored a new prompt engineering approach for ChatGPT4
    which I referred to as program simulation. The method showcased ChatGPT4’s impressive
    ability to emulate a program state consistently. These explorations heightened
    my appreciation for the nuanced power of language — the weight of words, semantics,
    and overarching context. This article explores some of these nuances and proposes
    a universal framework for prompt engineering, which I’ve christened “The Contextual
    Scaffolds Framework.” As we shall see, this framework generalizes effectively
    and seems capable of pulling techniques like Chain of Thought(CoT), Flattery/Role
    Assignment, Program Simulation and others under one umbrella. Additionally it
    provides an easy to use mental model for effective prompt crafting in a multitude
    of scenarios.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我最近的文章中，我探讨了一种新的 ChatGPT4 提示工程方法，称为程序模拟。该方法展示了 ChatGPT4 一致性地模拟程序状态的惊人能力。这些探索增强了我对语言细腻力量的欣赏——文字的分量、语义和整体上下文。本文探讨了这些细微差别，并提出了一个通用的提示工程框架，我称之为“语境支架框架”。正如我们将看到的，这个框架有效地进行了一般化，并似乎能够将如思维链（CoT）、恭维/角色分配、程序模拟等技术纳入一个范畴。此外，它提供了一个易于使用的心理模型，用于在多种场景中有效地制定提示。
- en: Into the World of Pragmatics
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进入语用学的世界
- en: 'My efforts to examine the nuances of language more closely began with pragmatics,
    a branch of linguistics that examines how context shapes meaning interpretation.
    Two concepts in particular stood out:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我对语言细微差别的更深入研究始于语用学，这是一门研究上下文如何塑造意义解释的语言学分支。特别突出的两个概念是：
- en: 'Implicature: When a speaker implies something without explicitly stating it,
    expecting the listener to infer the intended meaning.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 含义推断：当说话者暗示某些内容而未明确陈述时，期望听者推断出意图的意义。
- en: 'Presupposition: Assumptions or information that dialogue participants believe
    to be shared between the speaker and listener.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预设：对话参与者认为在说话者和听者之间共享的假设或信息。
- en: The central insight from these concepts is that words’ meanings extend well
    beyond their literal definitions. Consider the term “dog.” Beyond its basic definition,
    it carries a wealth of implicit information. We don’t explicitly state that dogs
    exist through time, move through space, eat, hear, bark, etc. The expectation
    is that listeners share this knowledge and extract the appropriate meaning(s)
    given the context at hand. Every linguistic expression, be it a word or novel,
    emits a “meaning aura” — a blend of implicit definitions, implicatures, sentiment,
    and connotations. These “meaning auras” can additionally vary in density, complexity
    and clarity and are often situation dependent.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概念的核心见解是，词语的意义远超其字面定义。考虑“狗”这个词。除了基本定义外，它还蕴含了大量隐含的信息。我们不会明确说明狗是通过时间存在、在空间中移动、吃东西、听声音、吠叫等。期望是听众共享这些知识，并根据当前上下文提取适当的意义。每种语言表达，无论是一个词还是一部小说，都散发出一种“意义光环”——隐含定义、含义推断、情感和内涵的混合。这些“意义光环”还可以在密度、复杂性和清晰度上有所不同，且通常依赖于具体情况。
- en: '**Large Language Models (LLM) and “Meaning Auras”**'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**大型语言模型 (LLM) 和“意义光环”**'
- en: LLMs in some senses systemize the production of “meaning auras” in a conversational
    dialogue with humans. But at their core these models are merely making word by
    word predictions. Is it possible that they have implicitly modeled the interplay
    of “meaning auras”? How might we measure that? While answering these questions
    would necessitate in-depth research, our brief foray into pragmatics does offers
    some immediate practical applicability and can serve as an important building
    block for a universal prompt engineering framework.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些方面，LLM 系统化了与人类对话中的“意义光环”产生。然而，这些模型本质上只是逐字预测。是否有可能它们隐含地建模了“意义光环”的相互作用？我们如何衡量这一点？虽然回答这些问题需要深入研究，但我们对语用学的简要探讨确实提供了一些即时的实际应用，并可以作为通用提示工程框架的重要构建块。
- en: The Contextual Scaffolds Framework (CSF)
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语境支架框架（CSF）
- en: As many have pointed out previously, effective prompt crafting for models like
    ChatGPT-4 hinges on context. But we also need to take into account what our expectations
    are for the model output and how the model should “operate” in order to meet those
    expectations. While bearing in mind the concept of “meaning auras” let’s examine
    an approach where the context of a prompt is broken down categorically. Let’s
    refer to these categories as “scaffolds” and specify two that are broadly applicable.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 正如许多人之前指出的那样，对于像 ChatGPT-4 这样的模型，有效的提示设计依赖于上下文。但我们还需要考虑对模型输出的期望是什么，以及模型应该如何“运作”以满足这些期望。在记住“意义光环”这一概念的同时，我们来看看一种将提示上下文分类的方法。我们将这些类别称为“框架”，并指定两个广泛适用的框架。
- en: '**Expectational Context Scaffold** — Encompasses the user’s aspirations, intent,
    objectives, and specifics of the situation at hand. If the user’s personal context
    is relevant it should be factored in as well.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**期望背景框架** — 包括用户的愿望、意图、目标和具体情况。如果用户的个人背景相关，也应考虑在内。'
- en: '**Operational Context Scaffold** — Establishes the AI’s operational parameters.
    It defines the model’s role, techniques to employ, required external data, and
    the extent of its autonomy and discretion.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**操作背景框架** — 确定 AI 的操作参数。它定义了模型的角色、使用的技术、所需的外部数据以及其自主性和裁量权的范围。'
- en: 'Here is a straightforward visual representation of the framework:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是框架的一个简单的视觉表示：
- en: '![](../Images/aba20fb5c80e673f2206b404c7a2e8b8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aba20fb5c80e673f2206b404c7a2e8b8.png)'
- en: Image by Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Now, let’s see this approach in action with a prompt for ChatGPT-4\. We will
    focus on selecting language for our scaffolds that have semantically rich “meaning
    auras” and are likely to produce the output we are looking for.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一个 ChatGPT-4 的提示来看看这种方法的实际效果。我们将重点选择具有语义丰富的“意义光环”的语言，并且这些语言可能会产生我们期望的输出。
- en: '**Context Scaffolds Prompt**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**背景框架提示**'
- en: '*“My Expectational Context — Your goal is to help me write a story about artificially
    intelligent teddy bears. The audience for my story is adults. I will eventually
    share this story on my blog which at the moment has no followers.*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*“我的期望背景 — 你的目标是帮助我写一个关于人工智能泰迪熊的故事。我的故事的受众是成年人。我最终会在我的博客上分享这个故事，目前我的博客没有任何关注者。”*'
- en: '*Your Operational Context — In an effort to maximize the fulfillment of my
    expectational context, you will behave from this point forward in the dialogue
    like a self-assembling program simulation. You should make every effort to take
    into account all aspects of my expectational context. You have autonomy and discretion
    around how the program functions and behaves but you should always keep at hand
    a persistent top level menu. Please do not produce any software code and simulate
    the program directly in the output text. Once this prompt is received please proceed
    with the simulation.”*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*“你的操作背景 — 为了最大限度地满足我的期望背景，从现在开始，你将在对话中表现得像一个自我组装的程序模拟。你应该尽一切努力考虑到我期望背景的所有方面。你在程序的功能和行为方面有自主性和裁量权，但你应该始终保留一个持续的顶级菜单。请不要生成任何软件代码，而是在输出文本中直接模拟程序。一旦收到此提示，请继续进行模拟。”*'
- en: 'You will all get something a little different, but it should in most cases
    look something like this:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你们会得到一些稍有不同的内容，但在大多数情况下，应该类似于此：
- en: '![](../Images/be5e425228737da6003a2cbcdd4c9773.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be5e425228737da6003a2cbcdd4c9773.png)'
- en: As you can see from the output, ChatGPT-4 launched a program simulation that
    has for the most part fulfilled my “Expectational Context.” I significantly influenced
    this by specifying language in both scaffolds that emit contextually rich “meaning
    auras.”
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，ChatGPT-4 启动了一个程序模拟，大致上满足了我的“期望背景”。我通过在两个框架中指定语言，这些框架发出了丰富的“意义光环”，对其产生了显著影响。
- en: So far, we have defined a straightforward universal framework for prompt crafting.
    Techniques such as Flattery/Role Assignment, Few-shot, and CoT predominantly fall
    under the “Operational Context Scaffold." While I couldn’t identify techniques
    rooted solely in the “Expectational Context Scaffold,” most goal-driven prompt
    language typically fits into this scaffold. So, in some way, we all implicitly
    use the technique by default.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们定义了一个直接的通用提示框架。诸如恭维/角色分配、少样本和 CoT 等技术主要属于“操作背景框架”。虽然我没有找到完全根植于“期望背景框架”的技术，但大多数目标驱动的提示语言通常适合这个框架。所以在某种程度上，我们都默认隐式地使用这种技术。
- en: But is that it? Do we just wrap up the article here or are there some derivative
    insights? Let’s see if we can unpack this further…
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那就这样了吗？我们只是结束这篇文章，还是还有一些派生的见解？让我们看看是否可以进一步解析……
- en: '**Optimization of Context Scaffolds for Prompt Engineering**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示工程的背景框架优化**'
- en: When engaging with a chosen LLM, our ultimate hope is that the model will produce
    output that meets or exceed our expectations. If we look at our scaffolds from
    an optimization perspective, we can envision a framework where the goal is to
    pinpoint one or more “Operational Contexts” that best fulfill the “Expectational
    Context.” For those wary of mathematical jargon, bear with me; this is a brief
    detour.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用选定的LLM时，我们最终希望模型能生成符合或超出我们期望的输出。如果我们从优化的角度看待我们的框架，我们可以设想一个框架，其中的目标是确定一个或多个最佳满足“期望背景”的“操作背景”。对于那些对数学术语感到陌生的人，请耐心等待；这是一个简短的绕道。
- en: 'We could represent such a function as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这样的函数表示如下：
- en: '*O* = *LLM*(*EC*)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*O* = *LLM*(*EC*)'
- en: 'Where:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*O* is a set of optimal Operational Contexts (OCₙ),'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*O* 是一组最佳操作背景（OCₙ），'
- en: '*LLM* is the function embodied by the Large Language Model.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*LLM* 是由大型语言模型体现的函数。'
- en: 'Each element in set *O*, say *OC*ᵢ, represents a different optimal Operational
    Context for the given Expectational Context:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 集合 *O* 中的每个元素，例如 *OC*ᵢ，代表给定期望背景的不同最佳操作背景：
- en: '*O*={*OC*₁,*OC*₂​,…,*OC*ₙ​}'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*O*={*OC*₁,*OC*₂​,…,*OC*ₙ​}'
- en: 'Since our Operational Context and Expectational Context are multi-dimensional
    we should likely model them in a more detailed manner as vectors of attributes:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的操作背景和期望背景是多维的，我们可能需要将它们建模为属性向量以获得更详细的描述：
- en: '*EC*={*e*₁​,*e*₂,…,*e*ₙ​}'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*EC*={*e*₁​,*e*₂,…,*e*ₙ​}'
- en: '*OC*={*o*₁​,*o*₂​,…,*o*ₙ​}'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*OC*={*o*₁​,*o*₂​,…,*o*ₙ​}'
- en: 'Finally the objective function could be expressed as maximizing the utility
    function *U* over all possible *OC*s in set *O* for a given EC:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，目标函数可以表示为在给定的EC下，最大化所有可能的*OC*在集合*O*中的效用函数 *U*：
- en: '![](../Images/d501c7847711564be8bb650f66762d26.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d501c7847711564be8bb650f66762d26.png)'
- en: These mathematical abstractions attempt to systematize the transformation of
    the Expectational Context into an Operational Context, while acknowledging the
    high likelihood of multiple optimal Operational Contexts for a given Expectational
    Context. We will look at the possibility of finetuning models using this type
    of framework in the future, but for now, let’s look at the practical implications
    of these ideas.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数学抽象试图系统化地将期望背景转化为操作背景，同时承认对于给定的期望背景可能存在多个最佳操作背景。我们将在未来探讨使用这种框架对模型进行微调的可能性，但现在，让我们看看这些想法的实际应用。
- en: Suppose you have a good handle on how to articulate your Expectational Context
    Scaffold but are uncertain on what elements to include in your Operational Context
    Scaffold. Can ChatGPT-4 assist?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经很好地掌握了如何表达你的期望背景框架，但不确定在操作背景框架中包含哪些元素。ChatGPT-4可以提供帮助吗？
- en: Let’s craft a prompt accordingly and see what we get back.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们根据此创建一个提示，并查看我们得到的反馈。
- en: '**Open-Ended Operational Context Prompt**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**开放式操作背景提示**'
- en: '*“My Expectational Context — Your goal is to help me write a story about artificially
    intelligent teddy bears. The audience for my story is adults. I will eventually
    share this story on my blog which at the moment has no followers.*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*“我的期望背景 — 你的目标是帮助我写一个关于人工智能泰迪熊的故事。我的故事受众是成年人。我最终会在我的博客上分享这个故事，目前博客没有任何粉丝。”*'
- en: '*Your Operative Context — In an effort to maximize the fulfillment of my expectational
    context, please suggest at least one but no more than five operational contexts
    that you could employ. You might suggest behaving as a person, a team, a type
    of organization, program, or system with one or more specific competences. You
    might suggest the inclusion of external data or request that you be provided training
    examples. You might also suggest the use of specific techniques or approaches.
    You can suggest any combination of the above elements . The operational contexts
    should be rank ordered from most optimal to least optimal. For each please provide
    a rationale that leads to their specific rank.”*'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*你的操作背景 — 为了最大化实现我的期望背景，请建议至少一个但不超过五个你可以使用的操作背景。你可以建议以某种人物、团队、组织类型、程序或系统的身份来进行，并具备一个或多个特定的能力。你还可以建议引入外部数据或要求提供训练示例。你也可以建议使用特定的技术或方法。你可以建议上述任何元素的任意组合。操作背景应按从最优到最不优的顺序排列。对于每一个，请提供一个导致其特定排名的理由。”*'
- en: '![](../Images/b325d18bd1a84427819075f5770166df.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b325d18bd1a84427819075f5770166df.png)'
- en: True to form, ChatGPT4 provides us with 5 operational contexts; 2 are organizational
    entities, 1 is a system and 2 are individuals. The operational contexts have been
    ranked and a rationale for each ranking has been included. Consider the “meaning
    auras” of concepts like “Literary Think Tank” or “Historical and Sci-fi Research
    Institute”. I think you would agree they are context dense and rich with meaning
    and implicatures. With this approach we can arm ourselves with a plethora of operational
    contexts that we may otherwise have not happened upon on our own. And it lowers
    the barrier to effective prompt crafting by narrowing down our starting point
    to focus on articulating the “Expectational Context Scaffold.»
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 诚如预期，ChatGPT-4 为我们提供了 5 种操作上下文；其中 2 种是组织实体，1 种是系统，2 种是个人。这些操作上下文已被排序，并附上了每个排序的理由。考虑一下“文学智囊团”或“历史与科幻研究所”等概念的“意义光环”。我相信你会同意，它们的上下文密集且充满了意义和暗示。通过这种方法，我们可以装备自己以大量操作上下文，这些上下文可能是我们自己无法发现的。这也降低了有效提示创建的门槛，将我们的起点集中在阐述“预期上下文支架”上。
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: As we delve into the intricacies of pragmatics and the concept of “meaning auras”,
    it is evident that context, in its multifaceted form, holds the key to to optimizing
    our interactions with LLMs. The Contextual Scaffolds Framework (CSF) gives us
    a straightforward mental model that can help us articulate context very effectively.
    By differentiating between “Expectational” and “Operational” contexts, the CSF
    provides a clear path for aligning user expectations with the capabilities of
    models like ChatGPT-4\. Additionally the CSF is extensible and as other scaffolds
    become relevant or necessary they can be added or subtracted as needed. Similarly
    each scaffold can be subdivided into component scaffolds that represent distinct
    features for a given context.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们深入探讨语用学和“意义光环”概念的复杂性时，可以明显看出，上下文在其多方面的形式中，掌握了优化我们与大型语言模型（LLMs）互动的关键。上下文支架框架（CSF）为我们提供了一个简单明了的心理模型，帮助我们有效地阐述上下文。通过区分“预期上下文”和“操作上下文”，CSF
    为将用户期望与像 ChatGPT-4 这样的模型的能力对齐提供了清晰的路径。此外，CSF 是可扩展的，当其他支架变得相关或必要时，它们可以根据需要添加或删除。同样，每个支架也可以细分为代表特定上下文的组件支架。
- en: Thanks for reading and I hope you find the CSF a useful model for crafting prompts!
    I am in the midst of additional explorations so be sure to follow me and get notified
    when new articles are published. If you would like to discuss CSF or any of my
    other articles further, do not hesitate to connect with me on [LinkedIn](https://www.linkedin.com/in/giuseppe-scalamogna-8b389145/).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，希望你发现 CSF 是一个有用的提示创建模型！我正在进行额外的探索，务必关注我，并在新文章发布时获取通知。如果你想进一步讨论 CSF 或我的其他文章，请随时通过
    [LinkedIn](https://www.linkedin.com/in/giuseppe-scalamogna-8b389145/) 与我联系。
- en: Unless otherwise noted, all images in this article are by the author.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，本文中的所有图片均为作者原创。
