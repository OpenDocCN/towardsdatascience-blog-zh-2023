- en: Text Data Pre-processing for Time-Series Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列模型中的文本数据预处理
- en: 原文：[https://towardsdatascience.com/text-data-pre-processing-for-time-series-models-162c0d01f5c5?source=collection_archive---------10-----------------------#2023-02-09](https://towardsdatascience.com/text-data-pre-processing-for-time-series-models-162c0d01f5c5?source=collection_archive---------10-----------------------#2023-02-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/text-data-pre-processing-for-time-series-models-162c0d01f5c5?source=collection_archive---------10-----------------------#2023-02-09](https://towardsdatascience.com/text-data-pre-processing-for-time-series-models-162c0d01f5c5?source=collection_archive---------10-----------------------#2023-02-09)
- en: Have you ever thought about how sentiment from text data can be used as a regressor
    in time-series models?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你是否曾考虑过如何将文本数据中的情感用作时间序列模型中的回归变量？
- en: '[](https://petrkorab.medium.com/?source=post_page-----162c0d01f5c5--------------------------------)[![Petr
    Korab](../Images/9f3afb4b8985584981220e30f18e3b69.png)](https://petrkorab.medium.com/?source=post_page-----162c0d01f5c5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----162c0d01f5c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----162c0d01f5c5--------------------------------)
    [Petr Korab](https://petrkorab.medium.com/?source=post_page-----162c0d01f5c5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://petrkorab.medium.com/?source=post_page-----162c0d01f5c5--------------------------------)[![Petr
    Korab](../Images/9f3afb4b8985584981220e30f18e3b69.png)](https://petrkorab.medium.com/?source=post_page-----162c0d01f5c5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----162c0d01f5c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----162c0d01f5c5--------------------------------)
    [Petr Korab](https://petrkorab.medium.com/?source=post_page-----162c0d01f5c5--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F13a053cbaad9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-data-pre-processing-for-time-series-models-162c0d01f5c5&user=Petr+Korab&userId=13a053cbaad9&source=post_page-13a053cbaad9----162c0d01f5c5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----162c0d01f5c5--------------------------------)
    ·6 min read·Feb 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F162c0d01f5c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-data-pre-processing-for-time-series-models-162c0d01f5c5&user=Petr+Korab&userId=13a053cbaad9&source=-----162c0d01f5c5---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F13a053cbaad9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-data-pre-processing-for-time-series-models-162c0d01f5c5&user=Petr+Korab&userId=13a053cbaad9&source=post_page-13a053cbaad9----162c0d01f5c5---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----162c0d01f5c5--------------------------------)
    ·6分钟阅读·2023年2月9日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F162c0d01f5c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-data-pre-processing-for-time-series-models-162c0d01f5c5&user=Petr+Korab&userId=13a053cbaad9&source=-----162c0d01f5c5---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F162c0d01f5c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-data-pre-processing-for-time-series-models-162c0d01f5c5&source=-----162c0d01f5c5---------------------bookmark_footer-----------)![](../Images/c572f7ea6033e1d39e2accc7b85121c6.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F162c0d01f5c5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-data-pre-processing-for-time-series-models-162c0d01f5c5&source=-----162c0d01f5c5---------------------bookmark_footer-----------)![](../Images/c572f7ea6033e1d39e2accc7b85121c6.png)'
- en: Photo by Kaleidico on Unsplash
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由Kaleidico在Unsplash拍摄
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Text data offer qualitative information that can be quantified, aggregated,
    and used as a variable in time-series models. Simple methods of text data representation,
    such as [one-hot encoding](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)
    of categorical variables and word [n-grams](https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/),
    have been used since NLP’s early beginnings. Over time, more complex methods,
    including the [Bag-of-words](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)
    model, found their way to represent text data for machine learning algorithms.
    Based on the distributional hypothesis formulated by Harris [1] and Firth [2],
    modern models such as Word-to-Vec [3] and [4], GloVe [5], and ELMo [6] use vector
    representation of words in their neural network architectures. Since computers
    process text as vectors, it can be used as a variable in time-series econometric
    models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据提供了可以量化、汇总并作为时间序列模型中的变量使用的定性信息。文本数据表示的简单方法，如[独热编码](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)分类变量和词[
    n-gram](https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/)，自自然语言处理（NLP）早期开始就已被使用。随着时间的推移，更多复杂的方法，包括[词袋模型](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)，也开始用于表示机器学习算法中的文本数据。基于哈里斯[1]和弗斯[2]提出的分布假设，现代模型如Word-to-Vec
    [3]和[4]、GloVe [5]和ELMo [6]在其神经网络架构中使用词的向量表示。由于计算机以向量形式处理文本，因此它可以作为时间序列计量经济学模型中的变量。
- en: In this way, we can use qualitative information from the text and use it to
    extend the possibilities of quantitative time-series models.
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通过这种方式，我们可以利用文本中的定性信息，扩展定量时间序列模型的可能性。
- en: 'In this article, you’ll learn more about:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你将学习更多内容：
- en: How to use qualitative information from text for quantitative…
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将文本中的定性信息用于定量分析…
