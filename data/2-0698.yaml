- en: 'Deep Learning in Recommender Systems: A Primer'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推荐系统中的深度学习：入门指南
- en: 原文：[https://towardsdatascience.com/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca](https://towardsdatascience.com/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca](https://towardsdatascience.com/deep-learning-in-recommender-systems-a-primer-96e4b07b54ca)
- en: A tour of the most important technological breakthroughs behind modern industrial
    recommender systems
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代工业推荐系统背后最重要的技术突破概述
- en: '[](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)[](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----96e4b07b54ca--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)
    ·9 min read·Jun 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----96e4b07b54ca--------------------------------)
    ·阅读时间9分钟·2023年6月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b5168e4df2a891b3242b01347e9ac486.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5168e4df2a891b3242b01347e9ac486.png)'
- en: 'Image credit: [Pixabay](https://pixabay.com/illustrations/network-cloud-computing-data-4851119/)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Pixabay](https://pixabay.com/illustrations/network-cloud-computing-data-4851119/)
- en: 'Recommender systems are among the fastest-evolving industrial Machine Learning
    applications today. From a business point of view, this is not a surprise: better
    recommendations bring more users. It’s as simple as that.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是目前发展最快的工业机器学习应用之一。从商业角度来看，这并不奇怪：更好的推荐带来更多的用户。就是这么简单。
- en: The underlying technology however is far from simple. Ever since the rise of
    deep learning — [powered by the commoditization of GPUs](/algorithms-are-not-enough-fdee1d65e536)
    — recommender systems have become more and more complex.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，基础技术远非简单。自从深度学习的兴起——[由GPU的商品化驱动](/algorithms-are-not-enough-fdee1d65e536)——推荐系统变得越来越复杂。
- en: In this post, we’ll take a tour of a handful of the most important modeling
    breakthroughs from the past decade, roughly reconstructing the pivotal points
    marking the rise of deep learning in recommender systems. It’s a story of technological
    breakthroughs, scientific exploration, and an arms race spanning continents and
    cooperations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将回顾过去十年中一些最重要的建模突破，粗略重建标志着深度学习在推荐系统中崛起的关键点。这是一个关于技术突破、科学探索，以及跨越大陆和合作的军备竞赛的故事。
- en: Buckle up. Our tour starts in 2017’s Singapore.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好吧。我们的旅程从2017年的新加坡开始。
- en: NCF (Singapore University, 2017)
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NCF（新加坡大学，2017年）
- en: '![](../Images/fd240f60ca9cd1b84333433f89cc813c.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd240f60ca9cd1b84333433f89cc813c.png)'
- en: 'Image credit: [He et al (2017)](https://arxiv.org/abs/1708.05031)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[He等（2017年）](https://arxiv.org/abs/1708.05031)
- en: Any discussion of deep learning in recommender systems would be incomplete without
    a mention of one of the most important breakthroughs in the field, Neural Collaborative
    Filtering (NCF), introduced in [He et al (2017)](https://arxiv.org/abs/1708.05031)
    from the University of Singapore.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 任何关于推荐系统中深度学习的讨论，如果不提到该领域最重要的突破之一——神经协作过滤（NCF），都将是不完整的。这个突破由[He等（2017年）](https://arxiv.org/abs/1708.05031)在新加坡大学提出。
- en: Prior to NCF, the gold standard in recommender systems was matrix factorization,
    in which we learn latent vectors (aka embeddings) for both users and items, and
    then generate recommendations for a user by taking the dot product between the
    user vector and the item vectors. The closer the dot product is to 1, as we know
    from linear algebra, the better the predicted match. As such, matrix factorization
    can be simply viewed as a linear model of latent factors.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 NCF 之前，推荐系统的黄金标准是矩阵分解，其中我们为用户和项目学习潜在向量（也称为嵌入），然后通过计算用户向量和项目向量之间的点积来生成用户的推荐。正如我们在线性代数中所知，点积越接近
    1，预测的匹配度就越高。因此，矩阵分解可以简单地被视为潜在因素的线性模型。
- en: The key idea in NCF is to replace the inner product in matrix factorization
    with a neural network. In practice, this is done by first concatenating the user
    and item embeddings, and then passing them into a multi-layer perceptron (MLP)
    with a single task head that predicts user engagement such as click. Both the
    MLP weights and the embedding weights (which map ids to their respective embeddings)
    are then learned during model training via backpropagation of loss gradients.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: NCF 中的关键理念是用神经网络替代矩阵分解中的内积。在实践中，这通过首先将用户和项目的嵌入连接起来，然后将它们传递到一个具有单一任务头的多层感知器（MLP）中，任务头预测用户参与度，如点击量。然后，通过反向传播损失梯度，在模型训练期间学习
    MLP 权重和嵌入权重（将 ID 映射到相应的嵌入）。
- en: The hypothesis behind NCF is that user/item interactions aren’t linear, as assumed
    in matrix factorization, but instead non-linear. If that’s true, we should see
    better performance as we add more layers to the MLP. And that’s precisely what
    He et al find. With 4 layers, they’re able to beat the best matrix factorization
    algorithms at the time by around 5% hit rate on the Movielens and Pinterest benchmark
    datasets.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: NCF 背后的假设是用户/项目的互动并非线性，如矩阵分解中假设的那样，而是非线性的。如果这一点成立，我们应该会看到随着 MLP 层数的增加，性能会有所提升。正如
    He 等人发现的那样，使用 4 层，他们能够在 Movielens 和 Pinterest 基准数据集上比当时最好的矩阵分解算法高出约 5% 的命中率。
- en: He et al proved that there’s immense value of deep learning in recommender systems,
    marking the pivotal transition away from matrix factorization and towards deep
    recommenders.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: He 等人证明了深度学习在推荐系统中的巨大价值，标志着从矩阵分解到深度推荐系统的关键过渡。
- en: Wide & Deep (Google, 2016)
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Wide & Deep (Google, 2016)
- en: '![](../Images/66bc799ed29146e926b4c19f07eec6ef.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/66bc799ed29146e926b4c19f07eec6ef.png)'
- en: 'Image credit: [Cheng et al (2016)](https://arxiv.org/abs/1606.07792)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Cheng et al (2016)](https://arxiv.org/abs/1606.07792)
- en: Our tour continues from Singapore to Mountain View, California.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的行程从新加坡继续到加州的山景城。
- en: 'While NCF revolutionized the domain of recommender system, it lacks an important
    ingredient that turned out to be extremely important for the success of recommenders:
    cross features. The idea of cross features has been popularized in Google’s 2016
    paper “[Wide & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792)”.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 NCF 革新了推荐系统领域，但它缺乏一个对推荐系统成功至关重要的成分：交叉特征。交叉特征的理念在 Google 的 2016 年论文 “[Wide
    & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792)” 中得到了普及。
- en: What is a cross feature? It’s a second-order feature that’s created by “crossing”
    two of the original features. For example, in the Google Play Store, first-order
    features include the impressed app, or the list of user-installed apps. These
    two can be combined to create powerful cross-features, such as
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是交叉特征？它是通过“交叉”两个原始特征创建的二阶特征。例如，在 Google Play Store 中，一阶特征包括所需的应用或用户安装的应用列表。这两个特征可以结合起来创建强大的交叉特征，例如
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: which is 1 if the user has Netflix installed and the impressed app is Hulu.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户安装了 Netflix 且所需的应用是 Hulu，则值为 1。
- en: Cross features can also be more generalized such as
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉特征也可以更为广泛，例如
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: and so on. The authors argue that adding cross features of different granularities
    enables both memorization (from more granular crosses) and generalization (from
    less granular crosses).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如此类。作者认为，添加不同粒度的交叉特征能够实现记忆（来自更细粒度的交叉）和泛化（来自较少粒度的交叉）。
- en: The key architectural choice in Wide&Deep is to have both a wide module, which
    is a linear layer that takes all cross features directly as inputs, and a deep
    module, which is essentially an NCF, and then combine both modules into a single
    output task head that learns from user/app engagements.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Wide&Deep 的关键架构选择是同时拥有一个宽模块，这是一个直接将所有交叉特征作为输入的线性层，以及一个深度模块，本质上是一个 NCF，然后将两个模块合并为一个单一的输出任务头，从用户/应用参与度中学习。
- en: 'And indeed, Wide&Deep works remarkably well: the authors find a lift in online
    app acquisitions of 1% by going from deep-only to wide and deep. Consider that
    Google makes tens of Billions in revenue each year from its Play Store, and it’s
    easy to see how impactful Wide&Deep was.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，Wide&Deep的效果非常好：作者发现通过从仅深度模型转向宽度加深度，在线应用获取的提升达到1%。考虑到谷歌每年从Play Store中获得数十亿的收入，很容易看出Wide&Deep的影响力。
- en: DCN (Google, 2017)
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DCN（谷歌，2017）
- en: '![](../Images/70104138435cbf8b93f8dc55dfc9ddd0.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70104138435cbf8b93f8dc55dfc9ddd0.png)'
- en: 'Image credit: [Wang et al (2017)](https://arxiv.org/pdf/1708.05123.pdf)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Wang et al (2017)](https://arxiv.org/pdf/1708.05123.pdf)
- en: 'Wide&Deep has proven the significance of cross features, however it has a huge
    downside: the cross features need to be manually engineered, which is a tedious
    process that requires engineering resources, infrastructure, and domain expertise.
    Cross features à la Wide & Deep are expensive. They don’t scale.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Wide&Deep证明了交叉特征的重要性，但它有一个巨大的缺点：交叉特征需要手动工程，这是一项繁琐的过程，需要工程资源、基础设施和领域专长。Wide&Deep式的交叉特征成本高昂，不具备扩展性。
- en: Enter “[Deep and Cross neural networks](https://arxiv.org/pdf/1708.05123.pdf)”
    (DCN), introduced in a 2017 paper, also from Google. The key idea in DCN is to
    replace the wide component in Wide&Deep with a “cross neural network”, a neural
    network dedicated to learning cross features of arbitrarily high order.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 进入“[深度和交叉神经网络](https://arxiv.org/pdf/1708.05123.pdf)”（DCN），这是2017年谷歌的一篇论文中介绍的。DCN的核心思想是用“交叉神经网络”替代Wide&Deep中的宽度组件，这是一种专门学习任意高阶交叉特征的神经网络。
- en: 'What makes a cross neural network different from a standard MLP? As a reminder,
    in an MLP, each neuron in the next layer is a linear combination of all layers
    in the previous layer:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉神经网络与标准MLP有何不同？作为提醒，在MLP中，下一层的每个神经元都是前一层所有神经元的线性组合：
- en: '![](../Images/62a1b6e50deae84849e47994ce7eb7b1.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62a1b6e50deae84849e47994ce7eb7b1.png)'
- en: 'By contrast, in the cross neural network the next layer is constructed by forming
    second-order combinations of the first layer with itself:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在交叉神经网络中，下一层是通过形成第一层与自身的二阶组合来构建的：
- en: '![](../Images/6eb9f66786bbed85a41d9e5c8ab9cd89.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6eb9f66786bbed85a41d9e5c8ab9cd89.png)'
- en: Hence, a cross neural network of depth L will learn cross features in the form
    of polynomials of degrees up to L. The deeper the neural network, the higher-order
    interactions are learned.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，深度为L的交叉神经网络将以最高L次的多项式形式学习交叉特征。神经网络越深，学习的高阶交互作用也越高。
- en: And indeed, the experiments confirm that DCN works. Compared to a model with
    just the deep component, DCN has a 0.1% lower logloss (which is considered to
    be statistically significant) on the Criteo display ads benchmark dataset. And
    that’s without any manual feature engineering, as in Wide&Deep!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 实验确实确认了DCN的有效性。与仅有深度组件的模型相比，DCN在Criteo展示广告基准数据集上的logloss低了0.1%（这被认为是统计显著的）。而且这是没有任何手动特征工程的，如同Wide&Deep!
- en: (It would have been nice to see a comparison between DCN and Wide&Deep. Alas,
    the authors of DCN didn’t have a good method to manually create cross features
    for the Criteo dataset, and hence skipped this comparison.)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: （如果能看到DCN与Wide&Deep之间的比较就好了。可惜的是，DCN的作者没有找到合适的方法来手动创建Criteo数据集的交叉特征，因此跳过了这个比较。）
- en: DeepFM (Huawei, 2017)
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DeepFM（华为，2017）
- en: '![](../Images/8adc12a29cdf378d7e7ec26f22abb03a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8adc12a29cdf378d7e7ec26f22abb03a.png)'
- en: 'Image credit: [Guo et al (2017)](https://arxiv.org/abs/1703.04247)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Guo et al (2017)](https://arxiv.org/abs/1703.04247)
- en: Next, our tour takes us from 2017’s Google to 2017’s Huawei.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们的旅程将从2017年的谷歌转向2017年的华为。
- en: Huawei’s solution for deep recommendation, “[DeepFM](https://arxiv.org/abs/1703.04247)”,
    also replaces manual feature engineering in the wide component of Wide&Deep with
    a dedicated neural network that learns cross features. However, unlike DCN, the
    wide component is not a cross neural network, but instead a so-called FM (“factorization
    machine”) layer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 华为的深度推荐解决方案“[DeepFM](https://arxiv.org/abs/1703.04247)”同样用一个专门学习交叉特征的神经网络替代了Wide&Deep中的手动特征工程。然而，与DCN不同，宽度组件不是交叉神经网络，而是所谓的FM（“矩阵分解机”）层。
- en: What does the FM layer do? It’s simply taking the dot-products of all pairs
    of embeddings. For example, if a movie recommender takes 4 id-features as inputs,
    such as user id, movie id, actor ids, and director id, then the model learns embeddings
    for all of these id features, and the FM layer computes 6 dot products, corresponding
    to the combinations user-movie, user-actor, user-director, movie-actor, movie-director,
    and actor-director. It’s a comeback of the idea of matrix factorization. The output
    of the FM layer is then combined with the output of the deep component into a
    sigmoid-activated output, resulting in the model’s prediction.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: FM层的作用是什么？它只是计算所有嵌入对的点积。例如，如果电影推荐系统使用4个id特征作为输入，比如用户id、电影id、演员id和导演id，那么模型将学习所有这些id特征的嵌入，FM层计算6个点积，分别对应用户-电影、用户-演员、用户-导演、电影-演员、电影-导演和演员-导演。这是矩阵分解思想的回归。然后，FM层的输出与深度组件的输出结合，通过一个sigmoid激活的输出，产生模型的预测结果。
- en: And indeed, as you may have guessed, DeepFM has been shown to work. The authors
    show that DeepFM beats a host of the competitors (including Google’s Wide&Deep)
    by more than 0.37% and 0.42% in terms of AUC and Logloss, respectively, on company-internal
    data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，正如你可能猜到的，DeepFM已经被证明有效。作者展示了DeepFM在公司内部数据上比一系列竞争者（包括Google的Wide&Deep）在AUC和Logloss上分别高出0.37%和0.42%。
- en: DLRM (Meta, 2019)
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DLRM（Meta，2019）
- en: '![](../Images/6889940b6c0218d3caaf74460184f84b.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6889940b6c0218d3caaf74460184f84b.png)'
- en: 'Image credit: [Naumov et al (2019)](https://arxiv.org/abs/1906.00091)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Naumov et al (2019)](https://arxiv.org/abs/1906.00091)
- en: Let’s leave Google and Huawei for now. The next stop on our tour is 2019’s Meta.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时搁置Google和华为。我们的下一站是2019年的Meta。
- en: 'Meta’s DLRM (“deep learning for recommender systems”) architecture, presented
    in [Naumov et al (2019)](https://arxiv.org/abs/1906.00091), works as follows:
    all categorical features are transformed into embeddings using embedding tables.
    All dense features are being passed into an MLP that computes embeddings for them
    as well. Importantly, all embeddings have the same dimension. Then, we simply
    compute the dot products of all pairs of embeddings, concatenate them into a single
    vector, and pass that vector through a final MLP with a single sigmoid-activated
    task head that produces the prediction.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Meta的DLRM（“用于推荐系统的深度学习”）架构，如[Naumov et al (2019)](https://arxiv.org/abs/1906.00091)所述，工作原理如下：所有类别特征通过嵌入表转换为嵌入。所有稠密特征也被传递到一个MLP中，该MLP为这些特征计算嵌入。重要的是，所有嵌入具有相同的维度。然后，我们简单地计算所有嵌入对的点积，将它们连接成一个单一的向量，并通过一个最终的MLP，该MLP有一个sigmoid激活的任务头，生成预测。
- en: 'DLRM, then, is almost something like a simplified version of DeepFM: if you
    take DeepFM and drop the deep component (keeping just the FM component), you have
    something like DLRM, but without DLRM’s dense MLP.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: DLRM，几乎可以看作是DeepFM的简化版：如果你取下DeepFM的深度组件（仅保留FM组件），你会得到类似DLRM的东西，但没有DLRM的稠密MLP。
- en: In experiments, Naumov et al show that DLRM beats DCN in terms of both training
    and validation accuracy on the Criteo display ads benchmark dataset. This result
    indicates that the deep component in DCN may indeed be redundant, and all that
    we really need in order to make the best possible recommendations are just the
    feature interactions, which in DLRM are captured with the dot products.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验中，Naumov等人展示了DLRM在Criteo展示广告基准数据集上的训练和验证准确率上都优于DCN。这一结果表明，DCN中的深度组件可能确实是多余的，而我们真正需要的只是特征交互，在DLRM中，这些交互通过点积来捕获。
- en: DHEN (Meta, 2022)
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DHEN（Meta，2022）
- en: '![](../Images/6adf06ffcec687055262c4b769443978.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6adf06ffcec687055262c4b769443978.png)'
- en: 'Image credit: [Zhang et al (2022)](https://arxiv.org/abs/2203.11014)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Zhang et al (2022)](https://arxiv.org/abs/2203.11014)
- en: 'In contrast to DCN, the feature interactions in DLRM are limited to be second-order
    only: they’re just dot products of all pairs of embeddings. Going back to the
    movie example (with features user, movie, actors, director), the second-order
    interactions would be user-movie, user-actor, user-director, movie-actor, movie-director,
    and actor-director. A third-order interaction would be something like user-movie-director,
    actor-actor-user, director-actor-user, and so on. Certain users may be fans of
    Steven Spielberg movies starring Tom Hanks, and there should be a cross feature
    for that! Alas, in standard DLRM, there isn’t. That’s a major limitation.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 与 DCN 相比，DLRM 中的特征交互仅限于二阶：它们只是所有嵌入对的点积。回到电影的例子（特征包括用户、电影、演员、导演），二阶交互包括用户-电影、用户-演员、用户-导演、电影-演员、电影-导演以及演员-导演。三阶交互可能是用户-电影-导演、演员-演员-用户、导演-演员-用户，等等。某些用户可能是斯蒂文·斯皮尔伯格执导、汤姆·汉克斯主演电影的粉丝，应该有一个交叉特征！然而，在标准的
    DLRM 中，没有。这是一个主要的限制。
- en: Enter [DHEN](https://arxiv.org/abs/2203.11014), the final landmark paper in
    our tour of modern recommender systems. DHEN stands for “Deep Hierarchical Ensemble
    Network”, and the key idea is to create a “hierarchy” of cross features that grows
    deeper with the number of DHEN layers.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 进入[DHEN](https://arxiv.org/abs/2203.11014)，这是我们现代推荐系统巡演中的最后一篇地标论文。DHEN 代表“深度层次集成网络”，其关键思想是创建一个交叉特征的“层次结构”，随着
    DHEN 层数的增加而变得更深。
- en: 'It’s easiest to understand DHEN with a simple example first. Suppose we have
    two input features going into DHEN, and let’s denote them by A and B (which could
    stand for user ids and video ids, for example). A 2-layer DHEN module would then
    create the entire hierarchy of cross features up to second order, namely:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最容易理解 DHEN 的方法是先用一个简单的例子。假设我们有两个输入特征进入 DHEN，我们用 A 和 B 来表示它们（例如可以是用户 ID 和视频 ID）。一个
    2 层的 DHEN 模块会创建到二阶的整个交叉特征层次结构，即：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'where “x” is either one or a combination of the following 5 interactions:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 其中“x”可以是以下5种交互中的一种或多种组合：
- en: dot product,
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点积，
- en: self-attention,
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自注意力，
- en: convolution,
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积，
- en: 'linear: y = Wx, or'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性：y = Wx，或者
- en: the cross module from DCN.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自 DCN 的交叉模块。
- en: DHEN is a beast, and its computational complexity (due to its recursive nature)
    is nightmare. In order to get it to work, the authors of the DHEN paper had to
    invent a new [distributed training](/distributed-learning-a-primer-790812b817f1)
    paradigm called “Hybrid Sharded Data Parallel”, which achieves 1.2X higher throughput
    than the (then) state-of-the-art.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: DHEN 是一只猛兽，其计算复杂度（由于其递归特性）令人头疼。为了使其正常工作，DHEN 论文的作者不得不发明一种新的[分布式训练](/distributed-learning-a-primer-790812b817f1)范式，称为“混合分片数据并行”，其吞吐量比（当时的）最先进技术高出1.2倍。
- en: 'But most importantly, the beast works: in their experiments on internal click-through
    rate data, the authors measure a 0.27% improvement in NE compared to DLRM, using
    a stack of 8 (!) DHEN layers.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 但最重要的是，这只猛兽确实有效：在他们对内部点击率数据的实验中，作者使用了一堆 8 (!) DHEN 层，相较于 DLRM，NE 提升了 0.27%。
- en: Summary
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: '![](../Images/8adc72dde9170f899402770469b0e632.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8adc72dde9170f899402770469b0e632.png)'
- en: Evolution of the Criteo display ads competition leaderboard. Screenshot from
    [paperswithcode.com](https://paperswithcode.com/sota/click-through-rate-prediction-on-criteo).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Criteo 展示广告竞赛排行榜的演变。截图来自 [paperswithcode.com](https://paperswithcode.com/sota/click-through-rate-prediction-on-criteo)。
- en: 'And this concludes our tour. Allow me to summarize each of these landmarks
    with a single headline:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们的巡演。请允许我用一个标题总结这些地标：
- en: '**NCF**: All we need are embeddings for users and items. The MLP will handle
    the rest.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NCF**：我们只需要用户和项目的嵌入。MLP 会处理其余的。'
- en: '**Wide&Deep**: Cross features matter. In fact, they’re so important we feed
    them directly into the task head.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Wide&Deep**：交叉特征很重要。实际上，它们如此重要，我们将它们直接输入到任务头中。'
- en: '**DCN**: Cross features matter, but shouldn’t be engineered by hand. Let the
    cross neural network handle that.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DCN**：交叉特征很重要，但不应手动工程化。让交叉神经网络来处理这些特征。'
- en: '**DeepFM**: Let’s generate cross features in the FM layer instead, and still
    keep the deep component from Wide&Deep.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DeepFM**：让我们在 FM 层生成交叉特征，同时保留 Wide&Deep 的深度组件。'
- en: '**DRLM**: FM is all we need — and also another, dedicated MLP for dense features.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DRLM**：FM 就是我们需要的一切——还有一个专门的 MLP 用于密集特征。'
- en: '**DHEN**: FM is not enough. We need a hierarchy of higher-order (beyond second
    order), hierarchical feature interactions. And also a bunch of optimizations to
    make it work in practice.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DHEN**：FM 还不够。我们需要一个更高阶的（超越二阶）的层次结构特征交互。还有一系列优化以确保它在实践中有效。'
- en: And the journey is really just getting started. At the time of this writing,
    DCN has evolved into DCN-M, DeepFM has evolved into xDeepFM, and the leaderboard
    of the Criteo competition has been claimed by Huawei’s latest invention, FinalMLP.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 旅程其实才刚刚开始。在撰写本文时，DCN 已经演变成了 DCN-M，DeepFM 也演变成了 xDeepFM，而 Criteo 比赛的排行榜已经被华为最新的发明
    FinalMLP 占据。
- en: Given the huge economic incentive for better recommendations, it’s guaranteed
    that we’ll continue to see new breakthroughs in this domain for the foreseeable
    future. Watch this space.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于对更好推荐的巨大经济激励，未来可预见的时间里我们一定会继续看到这一领域的新突破。敬请关注。
