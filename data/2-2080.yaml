- en: The Unreasonable Effectiveness of General Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通用模型的非凡有效性
- en: 原文：[https://towardsdatascience.com/the-unreasonable-effectiveness-of-general-models-b4e822eaeb27](https://towardsdatascience.com/the-unreasonable-effectiveness-of-general-models-b4e822eaeb27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-unreasonable-effectiveness-of-general-models-b4e822eaeb27](https://towardsdatascience.com/the-unreasonable-effectiveness-of-general-models-b4e822eaeb27)
- en: Testing a generalist model on a ridiculously hard problem
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在一个极其困难的问题上测试通用模型
- en: '[](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)[![Samuele
    Mazzanti](../Images/432477d6418a3f79bf25dec42755d364.png)](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)
    [Samuele Mazzanti](https://medium.com/@mazzanti.sam?source=post_page-----b4e822eaeb27--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)
    ·8 min read·Jan 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4e822eaeb27--------------------------------)
    ·8分钟阅读·2023年1月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e0cce5f765f3d90678879ef2406c1b7d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0cce5f765f3d90678879ef2406c1b7d.png)'
- en: '[Image by Author, made with Excalidraw]'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[作者提供的图像，由 Excalidraw 制作]'
- en: In a [previous article](https://medium.com/towards-data-science/what-is-better-one-general-model-or-many-specialized-models-9500d9f8751d),
    I tried to debunk the somewhat diffuse idea that a bunch of models (each specialized
    on a subset of a dataset) should perform better than a single model.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [上一篇文章](https://medium.com/towards-data-science/what-is-better-one-general-model-or-many-specialized-models-9500d9f8751d)
    中，我尝试揭示一种有些模糊的观点，即一堆模型（每个模型专注于数据集的一个子集）应该比单一模型表现更好。
- en: To do that, I took a portion of a dataset (e.g. only the American customers)
    and trained a model on that group, a.k.a. a **specialized model**. Then, I trained
    a second model on the whole dataset (i.e. on all the customers, regardless of
    their nationality), a.k.a a **general model**. In the end, I compared the performance
    of the two models on a holdout set made only of observations belonging to the
    group.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我取了一部分数据集（例如，仅美国客户），并在该组上训练了一个模型，即 **专用模型**。然后，我在整个数据集（即所有客户，无论其国籍）上训练了第二个模型，即
    **通用模型**。最后，我比较了这两个模型在只包含该组观察结果的保留集上的表现。
- en: 'I repeated this procedure on multiple datasets and on multiple groups of the
    same dataset, for a total of 600 comparisons. **There was a clear winner: the
    general model**.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我在多个数据集和同一数据集的多个组上重复了这个过程，总共进行了600次比较。 **最终的赢家是通用模型**。
- en: 'However, my experiment did not convince some people, who argued that my approach
    was oversimplified. For instance, this was one of the most liked comments under
    my Linkedin post about the article:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我的实验并没有说服一些人，他们认为我的方法过于简化。例如，这是我在 LinkedIn 上关于该文章的帖子下最受欢迎的评论之一：
- en: '![](../Images/4fdb1b7f061a8941066769f1d1c26b1b.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fdb1b7f061a8941066769f1d1c26b1b.png)'
- en: '[Screenshot from the comment section of my [Linkedin post](https://www.linkedin.com/feed/update/urn:li:activity:7015963227549282305/)]'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[从我 [Linkedin 帖子](https://www.linkedin.com/feed/update/urn:li:activity:7015963227549282305/)]
    评论区的截图'
- en: This comment intrigued me, so I decided to follow the suggestion. If you are
    curious to see how it turned out, bear with me.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个评论引起了我的兴趣，所以我决定按照建议去做。如果你想看看结果如何，请耐心等待。
- en: A working hypothesis
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个工作假设
- en: In my previous article, I demonstrated that there is a clear benefit in using
    a general model over specialized models when there is some similarity across the
    groups composing the dataset.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我之前的文章中，我证明了当数据集中组成各组之间存在一定相似性时，使用通用模型相对于专用模型有明显的好处。
- en: However, **as the groups become more and more different from each other**, it
    is reasonable to expect that **the benefit of using a general model gets smaller
    and smaller**. In the most extreme case, i.e. when the groups are completely different
    from each other, the difference between the two approaches should equal zero.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，**随着组之间的差异越来越大**，合理地预期**使用通用模型的好处会越来越小**。在最极端的情况下，即当组之间完全不同时，两种方法之间的差异应该等于零。
- en: 'If my intuition is correct, we could sketch this relationship as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我的直觉是正确的，我们可以将这种关系草图如下：
- en: '![](../Images/9916f64ce2db6b94172f99af9069dea5.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9916f64ce2db6b94172f99af9069dea5.png)'
- en: A sketch of my working hypothesis. You can read the “previous article” [here](/what-is-better-one-general-model-or-many-specialized-models-9500d9f8751d).
    [Image by Author, made with Excalidraw]
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我的工作假设的草图。你可以在[这里](/what-is-better-one-general-model-or-many-specialized-models-9500d9f8751d)阅读“上一篇文章”。[图片由作者提供，使用Excalidraw制作]
- en: But this is just my hypothesis. So let’s try to put it to the test.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 但这只是我的假设。那我们来尝试一下。
- en: Giving our model a hard time
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给我们的模型增加难度
- en: 'Our goal is to answer this question:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是回答这个问题：
- en: What happens if the groups composing a dataset are completely different from
    each other, and we still use a general model?
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果组成一个数据集的组彼此完全不同，而我们仍然使用一个通用模型，会发生什么？
- en: So, the point becomes how to simulate such a scenario.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，问题变成了如何模拟这样的场景。
- en: The most extreme idea is to “glue” different datasets together. And when I say
    “different”, I mean datasets that have **not only different columns, but even
    different tasks**, i.e. they aim to predict different things.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最极端的想法是“粘合”不同的数据集。当我说“不同”时，我指的是数据集**不仅有不同的列，还有不同的任务**，即它们旨在预测不同的内容。
- en: 'Let’s take three datasets for instance:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以三个数据集为例：
- en: '“bank”: each row is a bank’s customer, the task is to predict whether he/she
    will subscribe a term deposit;'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “银行”：每一行代表一个银行客户，任务是预测他/她是否会订阅定期存款；
- en: '“employee”: each row is an employee, the task is to predict whether he/she
    will leave the company;'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “员工”：每一行代表一名员工，任务是预测他/她是否会离开公司；
- en: '“income”: each row is a person, the task is to predict whether his/her income
    is above 50k $.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “收入”：每一行代表一个人，任务是预测他/她的收入是否超过50k美元。
- en: 'Gluing together the target variables of these datasets is easy: since they
    are all binary variables made by 0s and 1s, this is straightforward. But the situation
    becomes more complicated when we try to concatenate the features. Let me explain
    why.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些数据集的目标变量粘合在一起很简单：由于它们都是由0和1组成的二元变量，这很直接。但当我们尝试连接特征时，情况变得更加复杂。我来解释一下原因。
- en: Here is a sample (both rows and columns) of the three datasets.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是三个数据集的一个样本（包括行和列）。
- en: '![](../Images/e8add37e63e1c1e711e4d533ce9e9852.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8add37e63e1c1e711e4d533ce9e9852.png)'
- en: 'Three example datasets: “bank”, “employee” and “income”. [Image by Author]'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 三个示例数据集：“银行”、“员工”和“收入”。[图片由作者提供]
- en: 'As you can see, the datasets have different columns. So, how can we merge them
    together? The first, most naive idea is to use `pd.concat`:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这些数据集有不同的列。那么，我们如何将它们合并在一起？第一个最简单的想法是使用`pd.concat`：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'But, if we did that, we would obtain a dataframe of the following form:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我们这样做，我们将得到以下形式的数据框：
- en: '![](../Images/41a85c6ab8195d7ca888338f31f6d095.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41a85c6ab8195d7ca888338f31f6d095.png)'
- en: 'First attempt: naive concatenation. [Image by Author]'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次尝试：简单的连接。[图片由作者提供]
- en: Pandas by default concatenates only the columns that have the same name. In
    this case, each dataset has different column names, therefore the result has a
    diagonal-like structure. But this is not satisfactory, because it would allow
    the model to cut corners. Indeed, the model would be able to implicitly discern
    one dataset from the other, based on the columns that are not null.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 默认只连接具有相同名称的列。在这种情况下，每个数据集具有不同的列名，因此结果具有类似对角线的结构。但这并不令人满意，因为它会让模型走捷径。事实上，模型能够根据非空列隐式地区分不同的数据集。
- en: To avoid that, **we need a way to “force” the merge of the columns of the different
    datasets**.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，**我们需要一种“强制”合并不同数据集列的方法**。
- en: 'The only way I could think of is renaming the columns of each dataset with
    a progressive number: “feature_01”, “feature_02”, etc. But that wouldn’t work
    because the columns have different types. So we need to make a distinction between
    categorical and numerical features: “cat_feature_01”, “cat_feature_02”, etc. and
    “num_feature_01”, “num_feature_02”, etc. Moreover, I decided to sort the features
    by decreasing importance.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我能想到的唯一方法是用递增的数字重命名每个数据集的列：“feature_01”，“feature_02”等。但这行不通，因为列有不同的类型。所以我们需要区分分类特征和数值特征：“cat_feature_01”，“cat_feature_02”等和“num_feature_01”，“num_feature_02”等。此外，我决定按重要性降序排列特征。
- en: 'This is the resulting output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是得到的输出：
- en: '![](../Images/a3999c3f617d6490fb42bf5cd4354b24.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a3999c3f617d6490fb42bf5cd4354b24.png)'
- en: 'Second attempt: renaming columns with a progressive number. [Image by Author]'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第二次尝试：用递增的数字重命名列。[作者提供的图片]
- en: Maybe you are thinking this is not enough. After all, the model may still recognize
    some categories that belong to a given dataset (for example, “married” in column
    “cat_feature_01” exists only in the “bank” dataset). The same goes for numerical
    features (for example, values between 0 and 1 in column “num_feature_02” exist
    only in the “employee” dataset). This can still be helpful for the model, and
    we want to avoid that.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你会认为这还不够。毕竟，模型可能仍然识别出属于某个数据集的某些类别（例如，列“cat_feature_01”中的“已婚”仅存在于“银行”数据集中）。数值特征也是如此（例如，列“num_feature_02”中的0到1之间的值仅存在于“员工”数据集中）。这对模型仍然可能有帮助，我们希望避免这种情况。
- en: 'Thus, as an additional step, I:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，作为额外步骤，我：
- en: mapped each value of each categorical feature to a different integer (ordinal
    encoding);
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将每个分类特征的每个值映射到不同的整数（序数编码）；
- en: standardized the numerical columns of each original dataset by subtracting their
    mean and dividing by their standard deviation.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过减去均值并除以标准差，对每个原始数据集的数值列进行了标准化。
- en: 'So, this is the ultimate result:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这就是最终结果：
- en: '![](../Images/adb8ab0d7c4f230ebcefd190bf42bab3.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/adb8ab0d7c4f230ebcefd190bf42bab3.png)'
- en: 'Third and last attempt: ordinal encoding, standardization, and then renaming
    columns with a progressive number. [Image by Author]'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 第三次也是最后一次尝试：序数编码、标准化，然后用递增的数字重命名列。[作者提供的图片]
- en: Disclaimer
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 免责声明
- en: 'I know you may think that this procedure —artfully sticking together some totally
    unrelated datasets — is a bit odd. You are right: what we are doing would make
    no sense in a real world setting.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道你可能会觉得这个过程——巧妙地将一些完全不相关的数据集合并在一起——有点奇怪。你是对的：我们所做的在现实世界中没有意义。
- en: But you must keep in mind that this is **a didactical experiment to push the
    capabilities of a general model to its limits, and see if it can still be competitive
    with specialized models**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 但你必须记住，这**是一个教学实验，旨在推动通用模型的能力到极限，并观察它是否仍然能与专用模型竞争**。
- en: This experiment must be intended as a sort of “stress test” of the capabilities
    of tree-based gradient boosting models.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实验必须被视为对基于树的梯度提升模型能力的一种“压力测试”。
- en: Results
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: Now that we have designed a strategy, it’s time to apply it to some real datasets.
    I have used 7 datasets for binary classification with more than 5,000 rows that
    are available in [Pycaret](https://github.com/pycaret/pycaret) (a Python library
    under [MIT license](https://github.com/pycaret/pycaret/blob/master/LICENSE)).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设计了策略，是时候将其应用于一些实际数据集了。我使用了7个用于二分类的具有5000多行的数据集，这些数据集可以在[Pycaret](https://github.com/pycaret/pycaret)（一个[MIT许可证](https://github.com/pycaret/pycaret/blob/master/LICENSE)下的Python库）中找到。
- en: 'These are the datasets, with the respective number of rows and columns:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是数据集，及其相应的行数和列数：
- en: '![](../Images/1525434f90efb6f1ab827f4411f2dcdf.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1525434f90efb6f1ab827f4411f2dcdf.png)'
- en: Pycaret datasets, with their shape. [Image by Author]
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Pycaret数据集及其形状。[作者提供的图片]
- en: 'Then, I applied the procedure described above, which means that I performed
    the following actions for each dataset separately:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我应用了上述程序，这意味着我对每个数据集分别执行了以下操作：
- en: I have renamed each categorical column (sorted in decreasing order of importance)
    as “cat_feature_01”, “cat_feature_02”, … and each numerical column (sorted in
    decreasing order of importance) as “num_feature_01”, “num_feature_02”, …;
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我将每个分类列（按重要性降序排列）重命名为“cat_feature_01”，“cat_feature_02”，…，每个数值列（按重要性降序排列）重命名为“num_feature_01”，“num_feature_02”，…；
- en: 'for each categorical column, I have mapped every value into a distinct integer:
    0, 1, 2, …;'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对每个分类列，我将每个值映射到一个不同的整数：0，1，2，…；
- en: for each numerical column, I have standardized the values by subtracting their
    mean and dividing by their standard deviation;
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每一列数值数据，我已经通过减去均值并除以标准差来标准化值；
- en: I have added a column containing the dataset name.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我添加了一个包含数据集名称的列。
- en: 'Then, I merged all the original datasets to obtain the final dataset. At this
    point, I proceeded with the experiment. This consisted in:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我将所有原始数据集合并以获得最终数据集。在此基础上，我进行了实验。实验内容包括：
- en: training a general model (Catboost, with no parameter tuning) on the full merged
    dataset;
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在合并后的完整数据集上训练一个通用模型（Catboost，未进行参数调优）；
- en: training 7 specialized models (Catboost, with no parameter tuning), one on each
    original dataset;
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练了 7 个专业模型（Catboost，未进行参数调优），每个模型对应一个原始数据集；
- en: compare the performance of the general model and the specialized model on each
    dataset.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较通用模型和专业模型在每个数据集上的表现。
- en: '![](../Images/3366eada72820b9af39c9e6de28d7661.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3366eada72820b9af39c9e6de28d7661.png)'
- en: Procedure of comparing a general and a specialized model on a group of the dataset.
    [Image by Author]
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集的一组上比较通用模型和专业模型的过程。[作者提供的图片]
- en: The first thing that I noticed looking at the results is that the **correlation
    between the predictions made by the general model and the predictions made by
    the specialized models is 98%**, indicating that they produce very similar output.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我在查看结果时注意到的第一件事是**通用模型的预测与专业模型的预测之间的相关性为 98%**，这表明它们产生了非常相似的输出。
- en: But what about performance?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那么性能如何呢？
- en: 'Here is a comparison of the ROC scores of the general model versus the specialized
    models:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通用模型与专业模型 ROC 分数的比较：
- en: '![](../Images/1f05605cbf84d974915079c7a1cdbba1.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f05605cbf84d974915079c7a1cdbba1.png)'
- en: ROC scores compared. [Image by Author]
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 分数对比。[作者提供的图片]
- en: The mean difference between the general model’s ROC score and the specialized
    model’s ROC score is -0.53%. This means that **the specialized models generally
    outperformed the general model**.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通用模型的 ROC 分数与专业模型的 ROC 分数之间的平均差异是 -0.53%。这意味着**专业模型通常优于通用模型**。
- en: However, I must say I am impressed by how tiny the difference is. **We made
    a test in a ridiculously hard setting, and still, the general model was able to
    achieve performance very close to the specialized models**. This is evidence of
    how effective a general model is, even on this insanely difficult problem.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我必须说，我对这种微小差异感到印象深刻。**我们在一个极其困难的设置中进行了测试，通用模型仍然能够达到非常接近专业模型的性能**。这证明了通用模型在这个极其困难的问题上是多么有效。
- en: What about explainability?
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 那么解释性如何呢？
- en: Another concern that I have heard about general models is their alleged lack
    of explainability. In fact, some people claim that a single general model is less
    transparent than many specialized models.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我听到关于通用模型的另一个担忧是其所谓的解释性不足。事实上，有些人声称，一个通用模型的透明度不如多个专业模型。
- en: I don’t agree with this point. In fact, thanks to SHAP values, you can explain
    each group separately from the others, even if the model is unique. We could call
    this process “specialized explainability”.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我不同意这一点。事实上，得益于 SHAP 值，即使模型是唯一的，你也可以分别解释每个组。我们可以称这种过程为“专业化解释性”。
- en: '![](../Images/129b809160a5fc68968df8d30136bbe3.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/129b809160a5fc68968df8d30136bbe3.png)'
- en: Specialized explainability. [Image by Author]
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 专业化解释性。[作者提供的图片]
- en: Let me give an example, using our previous experiment.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我用我们之前的实验做一个例子。
- en: 'If we take each group separately and compute the correlation coefficient between
    the original feature values and the respective SHAP values, this is what we obtain:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们分别考虑每个组并计算原始特征值与相应 SHAP 值之间的相关系数，我们得到的结果是：
- en: '![](../Images/8b8a271f92d16c3d0a402b0bc687a970.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b8a271f92d16c3d0a402b0bc687a970.png)'
- en: Correlation between each merged feature and the respective SHAP values. [Image
    by Author]
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 每个合并特征与相应 SHAP 值之间的相关性。[作者提供的图片]
- en: 'As you can see, the correlation coefficients change a lot across the groups.
    For instance, if we take “num_feature_01” the correlation is positive for the
    group “bank”, whereas it is negative for the group “employee”. This makes a lot
    of sense, in fact:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，不同组之间的相关系数变化很大。例如，如果我们取“num_feature_01”，则“bank”组的相关性为正，而“employee”组的相关性为负。这非常有意义：
- en: For the group “bank”, “num_feature_01” corresponds to the feature “duration”,
    which is how long that person has been an account holder. The target feature is
    whether the client subscribed a term deposit. It is reasonable to expect a positive
    impact of the feature on the prediction.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“银行”组，“num_feature_01”对应于“duration”特征，即账户持有者的持有时间。目标特征是客户是否订阅了定期存款。可以合理地预期该特征对预测有积极影响。
- en: For the group “employee”, “num_feature_01” corresponds to the feature “satisfaction_level”.
    Since the target feature is whether the employee has left, the negative correlation
    is easily explained.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于“员工”组，“num_feature_01”对应于“satisfaction_level”特征。由于目标特征是员工是否离职，因此负相关性可以很容易解释。
- en: Conclusions
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this article, I simulated the most difficult scenario for a general model:
    a case in which the groups composing the dataset are completely different from
    each other.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我模拟了对一般模型而言最困难的情境：一个数据集组成的各组完全不同的案例。
- en: To simulate this situation, **I merged some datasets that had nothing to do
    with each other, nor the features, and not even the prediction task**! I have
    used a trick to make sure that the columns of the different datasets were concatenated
    together even if they had different names.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟这种情况，**我合并了一些完全无关的数据集，包括特征和预测任务**！我使用了一个技巧，以确保不同数据集的列即使名称不同也能连接在一起。
- en: 'Then, I trained a general model on the merged dataset and many specialized
    models: one for each original dataset.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我在合并的数据集上训练了一个一般模型和许多专门模型：每个原始数据集一个。
- en: 'This was a stress test, to see what would happen in a ridiculously hard situation
    for the general model. **Nevertheless, I found out that the difference in performance
    is minimum**: 0.53% average loss in ROC score using a general model instead of
    specialized models.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个压力测试，用来查看在对一般模型来说极端困难的情况下会发生什么。**然而，我发现性能差异最小**：使用一般模型代替专门模型的ROC评分平均损失为0.53%。
- en: Moreover, I used the experiment to show why **explainability should not be a
    concern either**. In fact, after using a general model, one can still explain
    the single groups separately through “specialized explainability”.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我还利用这个实验展示了为什么**可解释性也不应成为问题**。实际上，使用一般模型后，人们仍然可以通过“专门的可解释性”分别解释单独的组。
- en: You can find all the Python code used for this article in [this notebook](https://github.com/smazzanti/general_vs_specialized_models/blob/main/unreasonable-effectiveness-of-general-models.ipynb).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这个笔记本](https://github.com/smazzanti/general_vs_specialized_models/blob/main/unreasonable-effectiveness-of-general-models.ipynb)中找到本文使用的所有Python代码。
- en: '*Thank you for reading!*'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢阅读！*'
- en: '*If you find my work useful, you can subscribe to* [***get an email every time
    that I publish a new article***](https://medium.com/@mazzanti.sam/subscribe) *(usually
    once a month).*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你觉得我的工作有用，可以订阅* [***每次我发布新文章时获取邮件***](https://medium.com/@mazzanti.sam/subscribe)
    *(通常每月一次)。*'
- en: '*If you want to support my work, you can* [***buy me a coffee***](https://ko-fi.com/samuelemazzanti)*.*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你想支持我的工作，可以* [***请我喝杯咖啡***](https://ko-fi.com/samuelemazzanti)*。*'
- en: '*If you’d like,* [***add me on Linkedin***](https://www.linkedin.com/in/samuelemazzanti/)*!*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你愿意，* [***在 LinkedIn 上添加我***](https://www.linkedin.com/in/samuelemazzanti/)*！*'
