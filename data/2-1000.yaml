- en: GPT-3.5 Translates Paragraphs Better
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-3.5 更擅长翻译段落
- en: 原文：[https://towardsdatascience.com/gpt-3-5-translates-paragraphs-better-5ed0031ece08](https://towardsdatascience.com/gpt-3-5-translates-paragraphs-better-5ed0031ece08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/gpt-3-5-translates-paragraphs-better-5ed0031ece08](https://towardsdatascience.com/gpt-3-5-translates-paragraphs-better-5ed0031ece08)
- en: And outperforms Google Translate for the translation of literary works
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并且在翻译文学作品方面优于 Google 翻译
- en: '[](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)[![Benjamin
    Marie](../Images/3ea1ad230cb1e67610418a8e36a5e5dd.png)](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------)
    [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------)
    ·9 min read·May 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------)
    ·9分钟阅读·2023年5月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ef7e5310e5962ca4223e72e1bf1cc46c.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef7e5310e5962ca4223e72e1bf1cc46c.png)'
- en: Image from [Pixabay](https://pixabay.com/vectors/translate-language-translation-6089103/)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [Pixabay](https://pixabay.com/vectors/translate-language-translation-6089103/)
- en: According to [previous studies](https://arxiv.org/pdf/2211.09102.pdf), GPT models
    perform as well as standard machine translation systems, e.g., Google Translate.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 [以往研究](https://arxiv.org/pdf/2211.09102.pdf)，GPT模型的表现与标准机器翻译系统相当，例如 Google
    翻译。
- en: 'These studies mostly focused on sentence-level translation: The default approach
    used in machine translation that translates sentences one by one without any context.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些研究主要集中在句子级翻译：机器翻译中默认的做法是逐句翻译，没有任何上下文。
- en: Translating paragraphs or entire documents represent very difficult challenges
    for standard machine translation systems. These systems usually have to split
    the input or undergo heavy engineering to accept and leverage a longer input.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译段落或整个文档对于标准机器翻译系统来说是非常困难的挑战。这些系统通常需要拆分输入或进行大量工程改造以接受和利用更长的输入。
- en: Yet, intuitively, and following the workflow of human translators, we can expect
    machine translation systems to perform better with context, e.g., translating
    entire documents or paragraphs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从直观上看，并遵循人工翻译者的工作流程，我们可以期待机器翻译系统在处理上下文时表现更好，例如翻译整个文档或段落。
- en: This is where large language models such as GPT models can shine. They can take
    as input prompts significantly longer than typical machine translation systems.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是大型语言模型如 GPT 模型可以大放异彩的地方。它们可以接受比典型机器翻译系统显著更长的提示词输入。
- en: 'But it remains to evaluate the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但仍需评估以下内容：
- en: Whether exploiting more context is useful for improving GPT’s machine translation
    quality.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利用更多上下文是否有助于提高 GPT 的机器翻译质量。
- en: The performance of GPT models when translating long text compared to standard
    machine translation systems.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPT模型在翻译长文本时的表现，与标准机器翻译系统相比。
- en: The evaluation of large language models for translating paragraphs poses several
    challenges.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于翻译段落的大型语言模型的评估面临几个挑战。
- en: '**The automatic metrics used for machine translation evaluation are not designed
    for paragraph-level evaluation.**'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**用于机器翻译评估的自动化指标并未设计用于段落级评估。**'
- en: '**The evaluation data must not have been seen during the training of the evaluated
    systems.**'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估数据在被评估系统训练期间不得出现过。**'
- en: '**The evaluation should be conducted on a diverse set of language pairs to
    have an accurate overview of the large language model’s translation quality.**'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估应在多样的语言对上进行，以准确了解大型语言模型的翻译质量。**'
- en: '**Prompts must be designed to exploit an entire paragraph, i.e., not only sentences
    as done in previous work.**'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提示词必须设计成利用整个段落，即不仅仅是像以往工作中那样的句子。**'
- en: 'These challenges are all tackled by [Karpinska and Iyyer (2023): “Large language
    models effectively leverage document-level context for literary translation, but
    critical errors persist”](https://arxiv.org/pdf/2304.03245.pdf).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战都由[Karpinska 和 Iyyer (2023) 的“**大型语言模型有效利用文档级上下文进行文学翻译，但仍存在关键错误**”](https://arxiv.org/pdf/2304.03245.pdf)解决。
- en: In this blog article, I review and comment on their work. We will see how their
    evaluation of GPT-3.5 shows that “*LLMs produce better translations when provided
    with paragraph-level context*” and can achieve better translation quality than
    state-of-the-art neural machine translation systems for very diverse language
    pairs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我回顾并评论了他们的工作。我们将看到他们对GPT-3.5的评估如何表明“*在提供段落级上下文时，LLMs 产生更好的翻译*”，并且对于非常多样化的语言对，其翻译质量优于最先进的神经机器翻译系统。
- en: Human evaluation of paragraph translations
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 段落翻译的人工评估
- en: The automatic evaluation metrics that are commonly used in machine translation
    are unsuitable. Their correlation with human judgments is unknown when evaluating
    paragraph-level translations.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器翻译中常用的自动化评估指标是不适用的。在评估段落级翻译时，它们与人工判断的相关性尚不明确。
- en: We can’t rely on automatic metrics here.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能依赖自动化指标。
- en: 'Human evaluation remains the primary choice to have an evaluation of high credibility,
    so the authors of this study mainly relied on an MQM framework ([Lommel et al.,
    2014](https://ddd.uab.cat/pub/tradumatica/tradumatica_a2014n12/tradumatica_a2014n12p455.pdf)):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 人工评估仍然是具有高可信度评估的主要选择，因此该研究的作者主要依赖于MQM框架（[Lommel et al., 2014](https://ddd.uab.cat/pub/tradumatica/tradumatica_a2014n12/tradumatica_a2014n12p455.pdf)）：
- en: Mark translation error spans and categorize them
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记翻译错误的范围并对其进行分类
- en: Make preference judgments of which of two translations is of higher quality
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 做出两种翻译中哪一种质量更高的偏好判断
- en: Provide free-form justifications for their preference judgments.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供自由形式的偏好判断理由。
- en: For this evaluation, they collected a total of 720 pairs of translated paragraphs
    for 18 language pairs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在此次评估中，他们收集了总共720对翻译段落，涵盖了18种语言对。
- en: That’s a lot of data! I can’t wait to have a look at the dataset. It will be
    released on GitHub, [here](https://github.com/marzenakrp/LiteraryTranslation).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 数据量真是惊人！我迫不及待想看看数据集。它将发布在GitHub上，[这里](https://github.com/marzenakrp/LiteraryTranslation)。
- en: Machine translation of literary works
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文学作品的机器翻译
- en: For evaluation, this work chose to focus on translating literary works. It may
    seem like an odd choice since most previous work in machine translation focus
    on other genres/domains (news, user-generated texts, …).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估中，这项工作选择专注于翻译文学作品。由于大多数以前的机器翻译工作集中在其他体裁/领域（新闻、用户生成文本等），因此这可能看起来是一个奇怪的选择。
- en: Machine translation of literary texts is understudied and extremely challenging,
    especially with machine translation systems working at sentence-level.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 文学文本的机器翻译研究不足且极具挑战性，特别是对于以句子级别工作的大型机器翻译系统。
- en: In this type of text, contextual nuances are important but can’t be captured
    if the system translates sentences independently. Often, human translators have
    to restructure entire paragraphs to accurately translate into the target language.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种类型的文本中，上下文的细微差别非常重要，但如果系统独立翻译句子，就无法捕捉这些细微差别。通常，人工翻译者必须重组整个段落，以准确翻译成目标语言。
- en: Translation of literary texts is intuitively a task where a system taking a
    document or a paragraph as input would perform better than a system only accepting
    shorter input.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 文学文本的翻译直观上是一个任务，其中系统以文档或段落作为输入会比仅接受较短输入的系统表现更好。
- en: But a major constraint that we have when we evaluate large language models is
    that the data used for evaluation must be recent. This is important for the credibility
    of the evaluation. By using recently published data for evaluation, we avoid translating
    texts that could have been used for training the evaluated model, i.e., we avoid
    data contamination.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 但在评估大型语言模型时，我们面临的一个主要限制是评估使用的数据必须是最新的。这对评估的可信度很重要。通过使用最近发布的数据进行评估，我们可以避免翻译可能用于训练评估模型的文本，即避免数据污染。
- en: '[](/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=post_page-----5ed0031ece08--------------------------------)
    [## The Decontaminated Evaluation of GPT-4'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=post_page-----5ed0031ece08--------------------------------)
    [## GPT-4 的去污染评估'
- en: GPT-4 won’t be your lawyer anytime soon
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GPT-4 很快不会成为你的律师
- en: towardsdatascience.com](/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=post_page-----5ed0031ece08--------------------------------)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=post_page-----5ed0031ece08--------------------------------)'
- en: In this work, most of the translations used for evaluation were published after
    2021\. These particular translations were very probably absent from the training
    data of GPT-3.5 which have been trained on data published before 2022 according
    to OpenAI.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，用于评估的大部分翻译都是在2021年后发布的。这些特定的翻译很可能不在GPT-3.5的训练数据中，因为GPT-3.5是基于2022年之前发布的数据进行训练的，依据OpenAI的说法。
- en: However, the original texts that are translated are much older (published from
    1884 to 2020). They were very likely seen by the systems evaluated in this work
    (GPT-3.5 and Google Translate).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，被翻译的原文要老得多（出版时间从1884年到2020年）。这些原文很可能已被在这项工作中评估的系统（GPT-3.5和Google Translate）见过。
- en: Also, while it is unlikely that the evaluated systems have seen these specific
    translations, they may have seen other translations in other languages, or the
    same language but published earlier.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管被评估的系统不太可能见过这些特定的翻译，但它们可能见过其他语言中的翻译，或者同一语言中但较早发布的翻译。
- en: The data contamination is limited but happens. I don’t think there is a better
    way to completely prevent it for literary texts. But for other genres, such as
    news, this is possible.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据污染有限但仍然存在。我认为完全防止文学文本的数据污染没有更好的办法。但对于新闻等其他类型的文本，这是可能的。
- en: A very diverse set of language pairs
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个非常多样的语言对集合
- en: 'This is one of the strongest points of this work: The authors evaluated very
    diverse language pairs.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这项工作的一个强项：作者评估了非常多样的语言对。
- en: 'As source languages, they selected languages from various families: Indo-European
    (Romance, Germanic, Slavic), Sino-Tibetan, and Japonic. This way, they ensure
    that the evaluation will be able to identify more precisely the strengths and
    weaknesses of GPT-3.5 in translating languages with different morphological features
    and writing systems.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作为源语言，他们选择了来自不同语言家族的语言：印欧语系（罗曼语族、日耳曼语族、斯拉夫语族）、汉藏语系和日琉语系。通过这种方式，他们确保评估能够更准确地识别GPT-3.5在翻译具有不同形态特征和书写系统的语言方面的优缺点。
- en: The languages to translate used for evaluation are English (en), Polish (pl),
    Russian (ru), Czech (cs), French (fr), German (de), Japanese (ja), and Chinese
    (zh).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估的翻译语言包括英语（en）、波兰语（pl）、俄语（ru）、捷克语（cs）、法语（fr）、德语（de）、日语（ja）和中文（zh）。
- en: For the target languages, they selected languages to create pairs of source-target
    languages that are “easy” (similar languages) and “difficult” (dissimilar languages).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于目标语言，他们选择了创建“简单”（相似语言）和“困难”（不相似语言）源目标语言对的语言。
- en: For instance, Czech-Polish is an easy language pair since these languages have
    a lot in common. On the other hand, Japanese-Polish is an extremely difficult
    language pair since these two languages are from very distant language families
    with different grammar and writing systems. There are also a very limited number
    of machine translation studies for this language pair.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，捷克语-波兰语是一个简单的语言对，因为这两种语言有很多共同点。另一方面，日语-波兰语是一个极其困难的语言对，因为这两种语言来自非常不同的语言家族，具有不同的语法和书写系统。对这个语言对的机器翻译研究也非常有限。
- en: The selected target languages for each source language are English (en), Japanese
    (ja), and Polish (pl).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 每种源语言的选定目标语言是英语（en）、日语（ja）和波兰语（pl）。
- en: Prompt engineering for translating with GPT-3.5
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GPT-3.5进行翻译的提示工程
- en: One of the most critical steps when evaluating large language models is designing
    prompts.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 评估大型语言模型时最关键的步骤之一是设计提示。
- en: There are many possible prompts for machine translation. Ideally, we should
    extensively evaluate several of them to assess how impactful is the choice of
    the prompt.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 机器翻译有许多可能的提示。理想情况下，我们应该广泛评估几个提示，以评估提示选择的影响程度。
- en: We also have to keep in mind that the conclusions made by a scientific work
    may only be valid for the very particular prompts that we evaluate.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须记住，科学工作得出的结论可能仅对我们评估的非常特定的提示有效。
- en: Including many prompts in an evaluation is costly since we have to run the inference
    with a large language model for each prompt. In practice, it means that we can
    only select a limited number of prompts to conduct the evaluation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估中包括许多提示是昂贵的，因为我们必须对每个提示运行大型语言模型的推理。实际上，这意味着我们只能选择有限数量的提示进行评估。
- en: They used 5-shot in-context learning to translate with GPT-3.5\. There are 5
    examples of translations in the prompt to indicate more precisely what is expected
    from GPT-3.5.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 他们使用了 5-shot 上下文学习来翻译 GPT-3.5\. 提示中有 5 个翻译示例，更精确地指明了对 GPT-3.5 的期望。
- en: The selected translation examples have a critical impact on the translation
    quality of a language model. As demonstrated by [Vilar et al. (2022)](https://arxiv.org/pdf/2211.09102.pdf),
    the translation quality of examples is what is the most important.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 选定的翻译示例对语言模型的翻译质量有着至关重要的影响。正如 [Vilar et al. (2022)](https://arxiv.org/pdf/2211.09102.pdf)
    所证明的，示例的翻译质量才是最重要的。
- en: 'About the example selection, they wrote:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 关于示例选择，他们写道：
- en: We manually curate the five demonstrations from literary texts for each of the
    18 language pairs, resulting in 90 total demonstration examples. These demonstrations
    are sourced from novels that are not part of our translation dataset, resulting
    in potential differences in topic and style […]
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们从文学文本中手动策划了每对 18 种语言中的五个示例，共计 90 个示例。这些示例来自于不在我们翻译数据集中的小说，因此可能存在主题和风格上的差异
    […]
- en: This is not very detailed. Especially, here I have no idea what “curate” involves.
    The curation criteria are not provided.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是很详细。特别是，我不清楚“策划”涉及什么。策划标准没有提供。
- en: Once selected, they included the examples in three prompts that exploit contexts
    of different sizes.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选择，它们包括了三种提示中的例子，这些例子利用了不同大小的上下文。
- en: Sentence-level Prompt Template
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 句子级提示模板
- en: With this template, the sentences of the paragraphs to translate are given to
    GPT one by one. This is how standard sequence-to-sequence neural machine translation
    systems work.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个模板，待翻译的段落句子会一个接一个地提供给 GPT。这是标准的序列到序列神经机器翻译系统的工作方式。
- en: 'Original text in [SRC LANG]:'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文在 [SRC LANG] 中：
- en: ''
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: source sentence
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 源句子
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Translation into [TRG LANG]:'
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 翻译到 [TRG LANG]：
- en: ''
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: target sentence
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目标句子
- en: '*Note: [SRC LANG] and [TRG LANG] denote the source and target languages, respectively.*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：[SRC LANG]和[TRG LANG]分别表示源语言和目标语言。*'
- en: Sentence-level Translation with Context Prompt Template
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带上下文提示模板的句子级翻译
- en: 'The translation is still performed at sentence-level but the sentences are
    given with their context to GPT-3.5: What precedes and what follows the sentence
    in the paragraph are both in the prompt.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译仍然是在句子级别进行，但句子是带有上下文的提供给 GPT-3.5 的：段落中句子之前和之后的内容都包含在提示中。
- en: 'Original text in [SRC LANG]:'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文在 [SRC LANG] 中：
- en: ''
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: source prefix
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 源前缀
- en: ''
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <translate> src sent </translate>
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <translate> src sent </translate>
- en: ''
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: source suffix
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 源后缀
- en: ''
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Translation into [TRG LANG]:'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 翻译到 [TRG LANG]：
- en: ''
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: target prefix
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目标前缀
- en: ''
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <translated> trg sent </translated>
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: <translated> trg sent </translated>
- en: I found this design quite imaginative but also risky. In my experience, the
    GPT models can easily be confused if we don’t explicitly define the tags. In this
    situation, I wouldn’t be surprised if GPT just translates everything including
    the tags (<translate> and <translated>).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现这个设计非常有创意，但也很冒险。根据我的经验，如果我们没有明确地定义标签，GPT 模型可能会很容易混淆。在这种情况下，如果 GPT 只是翻译所有内容，包括标签（<translate>
    和 <translated>），我也不会感到惊讶。
- en: Paragraph-level Prompt Template
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 段落级提示模板
- en: The template is the same as the first one, but here they provide entire paragraphs
    instead of sentences.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 模板与第一个相同，但这里提供的是整段文本而非句子。
- en: 'Original text in [SRC LANG]:'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文在 [SRC LANG] 中：
- en: ''
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: source paragraph
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 源段落
- en: ''
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Translation into [TRG LANG]:'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 翻译到 [TRG LANG]：
- en: ''
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: target paragraph
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目标段落
- en: Now that we have our prompts, we can use them to evaluate the translation quality
    of GPT-3.5.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了提示，我们可以用它们来评估 GPT-3.5 的翻译质量。
- en: Evaluation of GPT-3.5 for Paragraph Translations
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对 GPT-3.5 段落翻译的评估
- en: 'This evaluation mainly aims at answering two questions:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这次评估主要旨在回答两个问题：
- en: Are large language models such as GPT-3.5 better at translation when translating
    entire paragraphs instead of sentences?
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像 GPT-3.5 这样的语言模型在翻译整段文本时是否比翻译单句时表现更好？
- en: How does GPT-3.5 perform compared to Google Translate when translating entire
    paragraphs?
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与 Google 翻译相比，GPT-3.5 在翻译整段文本时表现如何？
- en: For this evaluation, the authors mainly rely on human evaluation using the MQM
    framework.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这次评估，作者主要依靠使用 MQM 框架的人类评估。
- en: If you are familiar with my work, you already know how critical I can be when
    writing about machine translation evaluation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对我的工作很熟悉，你已经知道我在写机器翻译评估时有多么苛刻。
- en: '[](/scientific-credibility-in-machine-translation-research-pitfalls-and-promising-trends-990ddabe8fb9?source=post_page-----5ed0031ece08--------------------------------)
    [## Scientific Credibility in Machine Translation Research: Pitfalls and Promising
    Trends'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/scientific-credibility-in-machine-translation-research-pitfalls-and-promising-trends-990ddabe8fb9?source=post_page-----5ed0031ece08--------------------------------)
    [## 机器翻译研究中的科学可信度：陷阱与有希望的趋势'
- en: Are we at a turning point? My conclusions from the annotation of 1,000+ scientific
    papers
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们是否处于一个转折点？我从对1000多篇科学论文的注释中得出的结论。
- en: towardsdatascience.com](/scientific-credibility-in-machine-translation-research-pitfalls-and-promising-trends-990ddabe8fb9?source=post_page-----5ed0031ece08--------------------------------)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/scientific-credibility-in-machine-translation-research-pitfalls-and-promising-trends-990ddabe8fb9?source=post_page-----5ed0031ece08--------------------------------)'
- en: 'For this work, the authors evaluated their machine translation systems with
    very high scientific credibility. If you are searching for an example of a good
    machine translation evaluation, this is one of them. *Note: I also recommend reading
    “*[*Prompting PaLM for Translation: Assessing Strategies and Performance*](https://arxiv.org/pdf/2211.09102.pdf)*”
    (Vilar et al., 2022) which is another good example as I detailed in my blog article
    “*[*How Good Is Google PaLM at Translation?*](https://medium.com/towards-data-science/how-good-is-google-palm-at-translation-f4a40c2ce562)*”.*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '对于这项工作，作者以非常高的科学可信度评估了他们的机器翻译系统。如果你在寻找一个优秀的机器翻译评估的例子，这就是其中之一。*注意：我还推荐阅读“*[*Prompting
    PaLM for Translation: Assessing Strategies and Performance*](https://arxiv.org/pdf/2211.09102.pdf)*”（Vilar
    等，2022年），这是另一个好的例子，就像我在博客文章“*[*How Good Is Google PaLM at Translation?*](https://medium.com/towards-data-science/how-good-is-google-palm-at-translation-f4a40c2ce562)*”中详细介绍的那样。*'
- en: They didn’t rely on automatic metrics but still provide metric scores for more
    analysis. All the details to replicate the scores are also provided. This is extremely
    rare.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 他们没有依赖自动化指标，但仍然提供了更多分析的指标分数。所有复现这些分数的细节也一并提供。这非常罕见。
- en: They have even tested the statistical significance of their human evaluation.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 他们甚至测试了他们人工评估的统计显著性。
- en: 'The results:'
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果：
- en: GPT-3.5 is better at translating paragraphs than individual sentences
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-3.5 在翻译段落时比翻译单个句子要好。
- en: GPT-3.5 is better than Google Translate
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-3.5 优于 Google Translate。
- en: But these results vary across language pairs.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 但这些结果在语言对之间有所不同。
- en: For the German-to-Japanese translation direction, translating individual sentences
    yields better results. This is the only exception. According to the authors, this
    is because the data used for this translation direction has very long sentences.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于德语到日语的翻译方向，翻译单个句子的结果更好。这是唯一的例外。根据作者的说法，这是因为用于这个翻译方向的数据有非常长的句子。
- en: What is most surprising to me is that GPT-3.5 is also better than Google Translate
    when translating individual sentences.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 令我最惊讶的是，GPT-3.5 在翻译单个句子时也优于 Google Translate。
- en: 'Automatic metrics also yield very similar results: COMET, BLEURT, BERTScore,
    and COMET-QE all agree that GPT-3.5 is better than Google Translate with any of
    the 3 prompt templates.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化指标也产生了非常相似的结果：COMET、BLEURT、BERTScore 和 COMET-QE 都一致认为 GPT-3.5 在任何 3 种提示模板下都优于
    Google Translate。
- en: The paper presents a very extended analysis of their human evaluation. I won’t
    discuss it more in this article but invite you to read it. It’s very insightful.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 论文展示了对其人工评估的非常详细的分析。我不会在本文中进一步讨论，但邀请你阅读。这非常有洞察力。
- en: Limitations of GPT models for translation
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT 模型在翻译中的局限性。
- en: The paper has a “limitations” section (Section 7) where the authors discussed
    the limits of using GPT models for translation.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中有一个“局限性”部分（第7节），作者在这里讨论了使用GPT模型进行翻译的局限性。
- en: The authors note that the translation errors made when translating paragraphs
    are different from the errors made when translating individual sentences.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 作者指出，翻译段落时出现的翻译错误与翻译单个句子时的错误不同。
- en: When translating paragraphs, GPT-3.5 sometimes skips and forgets part of the
    content of the paragraph, leading to incorrect translation. I also observed similar
    behavior when playing with [ChatGPT for translation](https://medium.com/towards-data-science/translate-with-chatgpt-f85609996a7f).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在翻译段落时，GPT-3.5 有时会跳过和忘记段落的一部分内容，导致翻译不正确。我在使用[ChatGPT 进行翻译](https://medium.com/towards-data-science/translate-with-chatgpt-f85609996a7f)时也观察到了类似的行为。
- en: 'This problem could be corrected by fine-tuning GPT-3.5 for machine translation.
    *Note: Let’s not forget that the GPT-3.5 model evaluated here has not been fine-tuned
    for machine translation.*'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题可以通过对 GPT-3.5 进行机器翻译的微调来纠正。*注意：不要忘记，这里评估的 GPT-3.5 模型尚未针对机器翻译进行微调。*
- en: Other than that, GPT-3.5 still makes some more common type errors such as mistranslations
    and grammatical errors, but much less than Google Translate, as shown by the evaluation.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，GPT-3.5 仍然会出现一些较为常见的错误，例如翻译错误和语法错误，但这些错误远少于谷歌翻译，评估结果表明了这一点。
- en: Limitations of this work
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这项工作的局限性
- en: I struggled to find limitations for this work but there is at least one in my
    opinion.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我努力寻找这项工作的局限性，但在我看来至少有一个。
- en: The impact of the prompt templates is not clear. The specific template chosen
    for paragraph translation performs better than the template chosen for sentence
    translation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 提示模板的影响尚不清楚。用于段落翻译的具体模板比用于句子翻译的模板表现更好。
- en: But can we conclude with this setting that GPT-3.5 performs better when translating
    entire paragraphs?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们是否可以在这种设置下得出结论，即 GPT-3.5 在翻译整段文本时表现更好？
- en: '**If we change the templates, do we still draw the same conclusion?**'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果我们更改模板，我们是否仍会得出相同的结论？**'
- en: We can’t easily answer this question. I expect this limitation to be shared
    by all future work evaluating language models for machine translation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法轻易回答这个问题。我预计这一局限性将会在所有未来评估语言模型的机器翻译研究中出现。
- en: Also, this work focuses on translating literary texts. We can’t be sure that
    this work's conclusion would apply to other genres. I’m eager to read future work
    that will address this gap.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这项工作专注于翻译文学文本。我们不能确定这项工作的结论是否适用于其他类型的文本。我期待阅读未来将填补这一空白的研究。
- en: Conclusion
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This work is a milestone in machine translation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作是机器翻译领域的一个里程碑。
- en: It shows with very high scientific credibility that a large language model can
    outperform more standard neural machine translation systems such as Google Translate.
    It also demonstrates that paragraph-level translation with a large language model
    yields better translation quality than sentence-level translation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，一个大型语言模型可以超越更标准的神经机器翻译系统，如谷歌翻译，具有非常高的科学可信度。同时，它还表明，大型语言模型在段落级别翻译中能提供比句子级别翻译更好的翻译质量。
- en: With this work and [the previous study of PaLM’s translation quality](https://medium.com/towards-data-science/how-good-is-google-palm-at-translation-f4a40c2ce562),
    we have more and more evidence that the future of machine translation will be
    based on large language models.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这项工作和[之前的 PaLM 翻译质量研究](https://medium.com/towards-data-science/how-good-is-google-palm-at-translation-f4a40c2ce562)，我们有越来越多的证据表明，机器翻译的未来将基于大型语言模型。
