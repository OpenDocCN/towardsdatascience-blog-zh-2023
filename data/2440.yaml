- en: To Use or Not to Use Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 是否使用机器学习
- en: 原文：[https://towardsdatascience.com/to-use-or-not-to-use-machine-learning-d28185382c14?source=collection_archive---------6-----------------------#2023-07-28](https://towardsdatascience.com/to-use-or-not-to-use-machine-learning-d28185382c14?source=collection_archive---------6-----------------------#2023-07-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/to-use-or-not-to-use-machine-learning-d28185382c14?source=collection_archive---------6-----------------------#2023-07-28](https://towardsdatascience.com/to-use-or-not-to-use-machine-learning-d28185382c14?source=collection_archive---------6-----------------------#2023-07-28)
- en: How to decide if using ML is a good idea, and how that is changing with GenAI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何决定是否使用机器学习，以及这在生成式AI的影响下是如何变化的
- en: '[](https://annaviaba.medium.com/?source=post_page-----d28185382c14--------------------------------)[![Anna
    Via](../Images/7e8fe5c1a485a789edad3a6d118bcf45.png)](https://annaviaba.medium.com/?source=post_page-----d28185382c14--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d28185382c14--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d28185382c14--------------------------------)
    [Anna Via](https://annaviaba.medium.com/?source=post_page-----d28185382c14--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://annaviaba.medium.com/?source=post_page-----d28185382c14--------------------------------)[![Anna
    Via](../Images/7e8fe5c1a485a789edad3a6d118bcf45.png)](https://annaviaba.medium.com/?source=post_page-----d28185382c14--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d28185382c14--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d28185382c14--------------------------------)
    [Anna Via](https://annaviaba.medium.com/?source=post_page-----d28185382c14--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc1a8933ed8b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-use-or-not-to-use-machine-learning-d28185382c14&user=Anna+Via&userId=c1a8933ed8b&source=post_page-c1a8933ed8b----d28185382c14---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d28185382c14--------------------------------)
    ·8 min read·Jul 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd28185382c14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-use-or-not-to-use-machine-learning-d28185382c14&user=Anna+Via&userId=c1a8933ed8b&source=-----d28185382c14---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc1a8933ed8b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-use-or-not-to-use-machine-learning-d28185382c14&user=Anna+Via&userId=c1a8933ed8b&source=post_page-c1a8933ed8b----d28185382c14---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d28185382c14--------------------------------)
    ·8分钟阅读·2023年7月28日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd28185382c14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-use-or-not-to-use-machine-learning-d28185382c14&user=Anna+Via&userId=c1a8933ed8b&source=-----d28185382c14---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd28185382c14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-use-or-not-to-use-machine-learning-d28185382c14&source=-----d28185382c14---------------------bookmark_footer-----------)![](../Images/8d5c08adb67df49de8a44d9e52766051.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd28185382c14&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fto-use-or-not-to-use-machine-learning-d28185382c14&source=-----d28185382c14---------------------bookmark_footer-----------)![](../Images/8d5c08adb67df49de8a44d9e52766051.png)'
- en: Photo by [Ivan Aleksic](https://unsplash.com/es/@ivalex) on [Unsplash](https://unsplash.com/es/fotos/2RRq1BHPq4E?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [Ivan Aleksic](https://unsplash.com/es/@ivalex) 在 [Unsplash](https://unsplash.com/es/fotos/2RRq1BHPq4E?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Machine Learning is great at solving certain complex problems, usually involving
    difficult relationships between features and outcomes that cannot be easily hard
    coded as heuristics or if-else statements. However, there are some limitations
    or things to have in mind when deciding if ML is a good solution for a given problem
    at hand. In this post we’ll deep dive into the topic **“to use or not to use ML,”**
    first understanding this for “traditional” ML models, and afterwards discussing
    how this picture is changing with the progress of Generative AI.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习擅长解决某些复杂问题，通常涉及特征和结果之间的难以用启发式规则或if-else语句编码的复杂关系。然而，在决定是否使用机器学习作为解决方案时，有一些局限性或需考虑的因素。在这篇文章中，我们将深入探讨**“是否使用机器学习”**这一话题，首先理解“传统”机器学习模型，然后讨论随着生成式AI的进展这一图景如何变化。
- en: 'To clarify some of the points, I’ll use as an example the following initiative:
    *“As a company, I want to know if my clients are satisfied and the main reasons
    for dissatisfaction”*. A “traditional” ML based approach to solve this could be:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了澄清一些要点，我将以以下倡议为例：*“作为一家公司，我想知道我的客户是否满意以及不满的主要原因”*。解决这个问题的“传统”机器学习方法可能是：
- en: Obtain comments clients write about you (app or play store, twitter or other
    social networks, your website…)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取客户对你的评论（应用程序或商店、推特或其他社交网络、你的网站…）
- en: Use a sentiment analysis model to classify the comments into positive / neutral
    / negative.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用情感分析模型将评论分类为积极/中性/消极。
- en: Use topic modeling on the predicted “negative sentiment” comments to understand
    what they are about.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对预测的“消极情绪”评论使用主题建模，以了解其内容。
- en: '![](../Images/ffc441f8fc3babbbb67a76fdab1f0e13.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ffc441f8fc3babbbb67a76fdab1f0e13.png)'
- en: Classification of comments into positive, neutral and negative sentiment (image
    by the author)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 评论的分类分为积极、中性和消极情绪（图像来源于作者）
- en: Does my data have enough quality and volume?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我的数据是否有足够的质量和量？
- en: In supervised ML models, training data is necessary for the model to learn whatever
    it needs to predict (in this example, sentiment from a comment). If data has low
    quality (a lot of typos, missing data, errors…), it will be really hard for the
    model to perform well.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督式机器学习模型中，训练数据对于模型学习预测所需的内容（在这个例子中是评论的情感）是必要的。如果数据质量较低（如拼写错误、缺失数据、错误等），模型很难表现良好。
- en: 'This is typically known as the “garbage in, garbage out” problem: if your data
    is garbage, your model and predictions will be garbage too.'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这通常被称为“垃圾进，垃圾出”问题：如果你的数据是垃圾，你的模型和预测也会是垃圾。
- en: Similarly, you need to have enough volume of data for the model to learn the
    different casuistry that impact whatever needs to be predicted. In this example,
    if you only have a case of negative comment label with concepts like “useless”,
    “disappointed” or similar, the model won’t be able to learn that these words usually
    appear when the label is “negative.”
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你需要有足够的数据量，以便模型学习影响预测所需内容的不同情况。在这个例子中，如果你只有一个带有“无用”、“失望”或类似概念的消极评论标签的案例，模型将无法学习这些词通常在标签为“消极”时出现。
- en: Enough volume of training data should also help ensure you have a good representation
    of the data you will need to perform predictions on. For example, if your training
    data has no representation of a particular geographical area or a particular segment
    of the population, it is more likely the model will fail to perform well for those
    comments at prediction time.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 足够的训练数据量也有助于确保你对需要进行预测的数据有良好的代表性。例如，如果你的训练数据中没有某个特定地理区域或特定人群的代表，那么模型在预测这些评论时表现不佳的可能性会更大。
- en: For some use cases, having enough historic data is also relevant, to ensure
    we are able to compute relevant lagging features or labels (e.g. “customer pays
    the credit during the next year or not”).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些使用案例，拥有足够的历史数据也很重要，以确保我们能够计算相关的滞后特征或标签（例如“客户是否在下一年偿还信用”）。
- en: Are labels clear to define and easy to get?
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标签是否明确易于定义和获取？
- en: 'Again, for traditional supervised ML models, you’ll need a labeled dataset:
    examples for which you know the final outcome of what you want to predict, to
    be able to train your model.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，对于传统的监督式机器学习模型，你需要一个标记数据集：即你知道最终预测结果的示例，以便训练你的模型。
- en: The definition of the label is key. In this example, our label would be the
    sentiment associated with the comment. We could think we only can have “positive”
    or “negative” comments, and then argue we might have “neutral” comments as well.
    In this case from a given comment, it will usually be clear if the label needs
    to be “positive”, “neutral” or “negative”. But imagine we had the labels “very
    positive”, “positive”, “neutral”, “negative” or “very negative”… For a given comment,
    would it be that easy to decide if it is “positive” or “very positive”? This lack
    of clear definition of the label needs to be avoided, as training with a noisy
    label will make it harder for the model to learn.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 标签的定义是关键。在这个例子中，我们的标签将是与评论相关的情感。我们可能认为只有“积极”或“消极”评论，然后争论是否可能有“中性”评论。在这种情况下，从给定评论中，通常会清楚标签是否需要是“积极”、“中性”或“消极”。但如果我们有“非常积极”、“积极”、“中性”、“消极”或“非常消极”的标签呢？对于给定的评论，是否那么容易决定它是“积极”还是“非常积极”？这种标签定义不明确的情况需要避免，因为训练时使用噪声标签会使模型学习更困难。
- en: Now that the definition of the label is clear, we need to be able to get this
    label for a sufficient and quality set of examples, which will form our training
    data. In our example, we could consider manually tagging a set of comments, be
    it within the company or team, be it externalizing the tagging to professional
    annotators (yes, there are people working full time labelling dataset for ML!).
    Costs and feasibility associated with the obtention of these labels needs to be
    considered.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在标签的定义已经明确，我们需要能够为一个足够数量且质量高的示例获取这些标签，这些标签将构成我们的训练数据。在我们的例子中，我们可以考虑手动标记一组评论，无论是在公司或团队内部，还是将标记工作外包给专业注释员（是的，有专门的人全职从事机器学习数据集的标记工作！）。获取这些标签的成本和可行性需要被考虑。
- en: '![](../Images/55e0ce3919aa814f6b65c54efab18ce4.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55e0ce3919aa814f6b65c54efab18ce4.png)'
- en: Label for one example, in our case, a comment (image by the author)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个示例的标签，在我们的例子中，是评论（作者提供的图片）
- en: Will deployment of the solution be feasible?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案的部署是否可行？
- en: To reach final impact, the predictions of the ML model need to be usable. Depending
    on the use case, using the predictions might require specific infrastructures
    (e.g. ML Platform) and experts (e.g. ML Engineers).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现最终的影响，机器学习模型的预测结果需要是可用的。根据用例，使用预测结果可能需要特定的基础设施（例如机器学习平台）和专家（例如机器学习工程师）。
- en: 'In our example, as we want to use our model for analytical purposes we could
    run it offline and exploiting the predictions would be quite simple. However,
    if we wanted to automatically respond to a negative comment in the next 5 minutes
    it is published, this would be another story: the model would need to be deployed
    and integrated to make this possible. Overall, it is important to have a clear
    idea of what the requirements to use the predictions will be, to ensure it will
    be feasible with the team and tools available.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，由于我们希望将模型用于分析目的，我们可以离线运行它，并且利用预测结果会相当简单。然而，如果我们希望在评论发布后的5分钟内自动回应负面评论，那将是另一回事：模型需要被部署和集成才能实现这一目标。总体而言，明确使用预测结果的要求非常重要，以确保团队和现有工具能够实现这些要求。
- en: What is at stake?
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 风险是什么？
- en: 'ML models will always have a level of error in their predictions. Actually,
    it is a classic in ML to say:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的预测总会存在一定程度的误差。实际上，机器学习领域有一个经典的说法：
- en: If the model has no errors, then there is definitely something wrong with the
    data or the model
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果模型没有错误，那么数据或模型肯定存在问题
- en: This is important to understand, as if the use case doesn’t allow for these
    errors to happen, then it might not be a good idea to use ML. In our example,
    imagine instead of comments and sentiment, we were using the model to classify
    emails from customers into “pressing charges or not”. It wouldn’t be a good idea
    to have a model that can misclassify an email that is pressing charges against
    the company due to the terrible consequences this might have for the company.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这一点很重要，因为如果用例不允许这些错误发生，那么使用机器学习可能不是一个好主意。在我们的例子中，假设我们不是处理评论和情感，而是使用模型将客户的电子邮件分类为“是否起诉”。拥有一个可能误分类对公司提出起诉的电子邮件的模型并不是一个好主意，因为这可能对公司造成严重后果。
- en: Is using ML ethically correct?
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器学习是否符合伦理？
- en: There have been many proven cases of predictive models that discriminated based
    on gender, race and other sensitive personal attributes. Because of this, ML teams
    need to be careful on the data and features they are using for their projects,
    but also on questioning if automating certain types of decision actually makes
    sense from an ethical perspective. You can check my previous [blog post](https://medium.com/glovo-engineering/ml-bias-intro-risks-and-solutions-to-discriminatory-predictive-models-9335b7709818)
    on the topic for further details.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 许多经验证的预测模型已经因为基于性别、种族和其他敏感个人属性进行歧视而受到质疑。因此，机器学习团队需要谨慎选择用于项目的数据和特征，同时也需要质疑自动化某些类型决策是否从伦理角度来看是合理的。你可以查看我之前的[博客文章](https://medium.com/glovo-engineering/ml-bias-intro-risks-and-solutions-to-discriminatory-predictive-models-9335b7709818)以获取更多细节。
- en: Will I need explainability?
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我需要解释性吗？
- en: 'ML models act somehow as a black box: you input some information, and they
    magically output predictions. The complexity behind the models is what is behind
    this black box, especially if we compare to simpler algorithms from statistics.
    In our example, we might be okay not being able to understand exactly why a comment
    was predicted as “positive” or as “negative”.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型在某种程度上充当了黑箱：你输入一些信息，它们神奇地输出预测。模型背后的复杂性就是这个黑箱的本质，特别是与统计学中的简单算法相比。在我们的例子中，我们可能不必完全理解为什么一个评论被预测为“积极”或“消极”。
- en: In other use cases, explainability might be a must. For example, in strongly
    regulated sectors like insurances or banks. A bank needs to be able to explain
    why it is granting (or not) a credit to a person even if that decision is based
    on a scoring predictive model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他用例中，解释性可能是必须的。例如，在保险或银行等高度监管的领域。即使决定基于评分预测模型，银行也需要能够解释为什么给予（或不给予）某个人信用。
- en: 'This topic has a strong relationship with the ethics one: if we are not able
    to fully understand the models decisions, it is really hard to know if the model
    has learned to be discriminatory or not.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个话题与伦理问题有很强的关系：如果我们不能完全理解模型的决策，就很难知道模型是否学会了具有歧视性。
- en: Is all this changing with Generative AI?
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 所有这些都随着生成式AI的出现而改变了吗？
- en: With the progress on Generative AI, a variety of companies are offering webpages
    and APIs to consume powerful models. How is this changing the limitations and
    considerations I was mentioning before about ML?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式AI的进步，各种公司提供了网页和API来使用强大的模型。这是如何改变我之前提到的关于机器学习的限制和考虑的？
- en: '**Data related topics (quality, quantity and labels)**: for use cases that
    can leverage existent GenAI models, this is definitely changing. Huge volumes
    of data are already used to train GenAI models. Quality of the data hasn’t been
    controlled in most of these models, but this seems to compensate with the huge
    volume of data they use. Thanks to these models, it might be the case (again,
    for very specific use cases), that we no longer need training data. This is known
    as zero-shot learning (e.g. *“ask ChatGPT what is the sentiment of a given comment”*)
    and few-shot learning (e.g. *“provide some examples of positive, neutral and negative
    comments to ChatGPT, then ask it to provide the sentiment for a new comment”*).
    A good explanation on this can be found in the [deeplearning.ai newsletter](https://www.deeplearning.ai/the-batch/how-prompting-is-changing-machine-learning-development/).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据相关话题（质量、数量和标签）：** 对于能够利用现有生成式AI模型的用例，这种情况正在发生变化。大量数据已经用于训练生成式AI模型。大多数模型的数据质量未被控制，但这似乎被其使用的大量数据所弥补。由于这些模型，这可能会成为事实（再次强调，非常具体的用例），我们可能不再需要训练数据。这被称为零样本学习（例如，*“询问ChatGPT给定评论的情感”*）和少样本学习（例如，*“向ChatGPT提供一些积极、中性和消极评论的例子，然后要求它对新评论提供情感分析”*）。有关此内容的良好解释可以在[deeplearning.ai新闻通讯](https://www.deeplearning.ai/the-batch/how-prompting-is-changing-machine-learning-development/)中找到。'
- en: '**Deployment feasibility**: for the use cases that can leverage existent GenAI
    models, deployment becomes much easier, as many companies and tools are offering
    easy to use APIs to those powerful models. If those models need to be fine-tuned
    or brought in-house for privacy reasons, then deployment will of course get much
    harder.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署可行性：** 对于能够利用现有生成式AI模型的用例，部署变得容易得多，因为许多公司和工具提供了易于使用的API。如果这些模型需要微调或因隐私原因引入内部，那么部署自然会变得更困难。'
- en: '![](../Images/e5b0a50fec9dd97ae0f24a3b96b08a06.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5b0a50fec9dd97ae0f24a3b96b08a06.png)'
- en: “Traditional” ML vs leveraging GenAI models (image by the author)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: “传统”机器学习与利用生成式AI模型（图像由作者提供）
- en: 'Other limitations or considerations are not changing, regardless of leveraging
    GenAI or not:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其他限制或考虑因素不会改变，无论是否利用生成式AI：
- en: '**High stakes:** this will keep being a problem, as GenAI models have a level
    of error in their predictions too. Who hasn’t seen GhatGPT hallucinating or providing
    answers that don’t make sense? What is worse, it is harder to evaluate these models,
    as responses sound always confident regardless of the degree of accuracy they
    have, and evaluation turns subjective (e.g. *“does this response make sense to
    me?”*).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高风险：** 这个问题仍然存在，因为生成式AI模型在预测中也有一定的误差。谁没见过GhatGPT出现幻觉或给出不合理的答案？更糟糕的是，评估这些模型变得更难，因为无论模型的准确度如何，响应总是听起来很自信，评估变得主观（例如，*“这个回答对我来说是否有意义？”*）。'
- en: '**Ethics:** still as important as before. There are proofs GenAI models can
    be biased due to the input data they were used to train with ([link](https://news.mit.edu/2023/large-language-models-are-biased-can-logic-help-save-them-0303)).
    As more companies and functionalities start using these types of models, it is
    important to have the risks this might bring clear.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理：** 依然像以前一样重要。已有证据表明，生成式人工智能模型可能因用于训练的数据输入而存在偏见 ([link](https://news.mit.edu/2023/large-language-models-are-biased-can-logic-help-save-them-0303))。随着越来越多的公司和功能开始使用这些类型的模型，明确它们可能带来的风险是很重要的。'
- en: '**Explainability:** as GenAI models are bigger and more complex than “traditional”
    ML, explainability on their predictions gets even harder. There is ongoing research
    to understand how this explainability could be achieved, but it is still very
    immature ([link](https://techcrunch.com/2023/05/09/openais-new-tool-attempts-to-explain-language-models-behaviors/)).'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性：** 由于生成式人工智能模型比“传统”机器学习更大、更复杂，其预测的可解释性变得更加困难。虽然目前正在进行研究以理解如何实现这种可解释性，但仍然非常不成熟
    ([link](https://techcrunch.com/2023/05/09/openais-new-tool-attempts-to-explain-language-models-behaviors/))。'
- en: Wrapping it up
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this blog post we saw the main things to consider when deciding whether **to
    use or not to use ML** and how that is changing with the progress from Generative
    AI models. The main topics discussed were quality and volume of data, label obtention,
    deployment, stakes, ethics and explainability. I hope this summary is useful when
    considering your next ML (or not) initiative!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我们讨论了在决定是否**使用或不使用机器学习**时需要考虑的主要因素，以及随着生成式人工智能模型的进展这些因素如何变化。讨论的主要主题包括数据的质量和数量、标签获取、部署、风险、伦理和可解释性。我希望这个总结对你考虑下一个机器学习（或不使用）项目时有所帮助！
- en: '**References**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: '[1] [ML bias: intro, risks and solutions to discriminatory predictive models](https://medium.com/glovo-engineering/ml-bias-intro-risks-and-solutions-to-discriminatory-predictive-models-9335b7709818),
    by myself'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [机器学习偏见：介绍、风险及解决方案](https://medium.com/glovo-engineering/ml-bias-intro-risks-and-solutions-to-discriminatory-predictive-models-9335b7709818)，由我自己提供'
- en: '[2] [Beyond Test Sets: how prompting is changing machine learning development](https://www.deeplearning.ai/the-batch/how-prompting-is-changing-machine-learning-development/),
    by deeplearning.ai'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [超越测试集：提示如何改变机器学习开发](https://www.deeplearning.ai/the-batch/how-prompting-is-changing-machine-learning-development/)，由
    deeplearning.ai 提供'
- en: '[3] [Large Language models are biased, can logic help save them?](https://news.mit.edu/2023/large-language-models-are-biased-can-logic-help-save-them-0303),
    by MIT News.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [大型语言模型存在偏见，逻辑能帮助拯救它们吗？](https://news.mit.edu/2023/large-language-models-are-biased-can-logic-help-save-them-0303)，由
    MIT News 提供'
- en: '[4] [OpenAIs OpenAI’s attempts to explain language models behaviors](https://techcrunch.com/2023/05/09/openais-new-tool-attempts-to-explain-language-models-behaviors/),
    TechCrunch'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [OpenAI 解释语言模型行为的尝试](https://techcrunch.com/2023/05/09/openais-new-tool-attempts-to-explain-language-models-behaviors/)，TechCrunch'
