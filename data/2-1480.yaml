- en: 'Master Semantic Search at Scale: Index Millions of Documents with Lightning-Fast
    Inference Times using FAISS and Sentence Transformers'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 以规模化方式掌握语义搜索：使用FAISS和Sentence Transformers在闪电般的推理时间内索引数百万份文档
- en: 原文：[https://towardsdatascience.com/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88](https://towardsdatascience.com/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88](https://towardsdatascience.com/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)
- en: Dive into an end-to-end demo of a high-performance semantic search engine leveraging
    GPU acceleration, efficient indexing techniques, and robust sentence encoders
    on datasets up to 1M documents, achieving 50 ms inference times
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入了解一个高性能的语义搜索引擎的端到端演示，利用GPU加速、高效的索引技术和强大的句子编码器处理多达100万份文档的数据集，实现50毫秒的推理时间
- en: '[](https://medium.com/@luisroque?source=post_page-----fa395e4efd88--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----fa395e4efd88--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fa395e4efd88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fa395e4efd88--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----fa395e4efd88--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisroque?source=post_page-----fa395e4efd88--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----fa395e4efd88--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fa395e4efd88--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fa395e4efd88--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----fa395e4efd88--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fa395e4efd88--------------------------------)
    ·15 min read·Mar 31, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fa395e4efd88--------------------------------)
    ·阅读时间15分钟·2023年3月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In search and information retrieval, semantic search has emerged as a game-changer.
    It allows us to search and retrieve documents based on their meaning or concepts
    rather than just keyword matching. The semantic search leads to more sophisticated
    and relevant results than traditional keyword-based search methods. However, the
    challenge lies in scaling semantic search to handle large corpora of documents
    without being overwhelmed by the computational complexity of analyzing every semantic
    content of a document.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在搜索和信息检索领域，语义搜索已经成为一场变革。它使我们能够根据文档的意义或概念而不仅仅是关键字匹配来进行搜索和检索。与传统的基于关键字的搜索方法相比，语义搜索能够提供更复杂、更相关的结果。然而，挑战在于将语义搜索扩展到处理大量文档的语料库，而不会因分析每个文档的语义内容的计算复杂性而不堪重负。
- en: 'In this article, we rise to the challenge of achieving scalable semantic search
    by harnessing the power of two cutting-edge techniques: FAISS for efficient indexing
    of semantic vectors and Sentence Transformers for encoding sentences into these
    vectors. FAISS is an outstanding library designed for the fast retrieval of nearest
    neighbors in high-dimensional spaces, enabling quick semantic nearest neighbor
    search even at a large scale. Sentence Transformers, a deep learning model, generates
    dense vector representations of sentences, effectively capturing their semantic
    meanings.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们迎接了通过利用两种前沿技术来实现可扩展语义搜索的挑战：FAISS用于高效的语义向量索引，Sentence Transformers用于将句子编码为这些向量。FAISS是一个出色的库，旨在快速检索高维空间中的最近邻，使得即使在大规模下也能迅速进行语义最近邻搜索。Sentence
    Transformers，一个深度学习模型，生成句子的密集向量表示，有效捕捉其语义含义。
- en: This article shows how we can use the synergy of FAISS and Sentence Transformers
    to build a scalable semantic search engine with remarkable performance. By integrating
    FAISS and Sentence Transformers, we can index semantic vectors from an extensive
    corpus of documents, resulting in a rapid and accurate semantic search experience
    at scale. Our approach can enable new applications such as contextualized question-answering
    and advanced recommendation systems with inference times as low as 50 ms when
    searching a corpus of 1M documents. We will guide you through implementing this
    state-of-the-art end-to-end solution and demonstrate its performance on benchmark
    datasets.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示了如何利用FAISS和句子变换器的协同作用，构建一个具有卓越性能的可扩展语义搜索引擎。通过将FAISS和句子变换器集成，我们可以对来自大量文档的语义向量进行索引，从而实现快速准确的语义搜索体验。我们的方法可以实现新的应用，如上下文化问答和先进的推荐系统，当搜索1M文档的语料库时推理时间低至50毫秒。我们将指导你实现这一最先进的端到端解决方案，并在基准数据集上展示其性能。
- en: '![](../Images/6d6e13617bc14df0e964b33fe23e756f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d6e13617bc14df0e964b33fe23e756f.png)'
- en: 'Figure 1: Search is all you need to navigate this world ([source](https://unsplash.com/photos/afW1hht0NSs))'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：搜索是你在这个世界上导航所需的一切（[来源](https://unsplash.com/photos/afW1hht0NSs)）
- en: 'This article belongs to “Large Language Models Chronicles: Navigating the NLP
    Frontier”, a new weekly series of articles that will explore how to leverage the
    power of large models for various NLP tasks. By diving into these cutting-edge
    technologies, we aim to empower developers, researchers, and enthusiasts to harness
    the potential of NLP and unlock new possibilities.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文属于“**大语言模型纪实：导航NLP前沿**”系列，这是一系列每周更新的文章，将探讨如何利用大模型的力量来完成各种NLP任务。通过深入这些前沿技术，我们旨在赋能开发者、研究人员和爱好者，充分利用NLP的潜力，开启新的可能性。
- en: 'Articles published so far:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今已发布的文章：
- en: '[Summarizing the latest Spotify releases with ChatGPT](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[用ChatGPT总结最新的Spotify发布](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
- en: As always, the code is available on my [Github](https://github.com/luisroque/large_laguage_models).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，代码可在我的[Github](https://github.com/luisroque/large_laguage_models)上找到。
- en: Sentence Transformers for Semantic Encoding
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 句子变换器用于语义编码
- en: Deep learning brings forth the power of sentence transformers, which craft dense
    vector representations that capture the essence of a sentence’s meaning. Trained
    on massive amounts of data, these models produce contextualized word embeddings,
    aiming to reconstruct input sentences accurately and draw semantically similar
    sentence pairs closer together.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习带来了句子变换器的力量，它们制作密集的向量表示，捕捉句子意义的本质。这些模型在大量数据上进行训练，生成上下文化的词嵌入，旨在准确重建输入句子，并将语义相似的句子对拉近。
- en: To harness the potential of sentence transformers in semantic encoding, you’ll
    first need to choose a suitable model architecture, such as BERT, RoBERTa, or
    XLNet. With a model in place, we will feed a corpus of documents into it, generating
    fixed-length semantic vectors for each sentence. These vectors are compact numerical
    representations of the core themes and topics within the sentences.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用句子变换器在语义编码中的潜力，你需要首先选择一个合适的模型架构，如BERT、RoBERTa或XLNet。确定模型后，我们将把文档语料库输入其中，为每个句子生成固定长度的语义向量。这些向量是句子核心主题和话题的紧凑数值表示。
- en: 'Let’s take two sentences as examples: ‘The dog chased the cat’ and ‘The cat
    chased the dog.’ When processed through a sentence transformer, their resulting
    semantic vectors will be closely related, even with word order differences, because
    the underlying meaning is similar. On the other hand, a sentence like ‘The sky
    is blue’ will yield a more distant vector due to its contrasting meaning.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以两个句子为例：“狗追逐猫”和“猫追逐狗”。通过句子变换器处理后，它们的语义向量将紧密相关，即使词序不同，因为基本意义相似。另一方面，像“天空是蓝色的”这样的句子会产生更远的向量，因为其含义不同。
- en: Using sentence transformers to encode an entire corpus, we obtain a collection
    of semantic vectors that encapsulate the overarching meanings of the documents.
    To make this transformed representation ready for efficient retrieval, we index
    it using FAISS. Stay tuned, as we’ll dive into this topic in the next section.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用句子变换器对整个语料库进行编码，我们得到一组语义向量，这些向量概括了文档的总体含义。为了使这种变换后的表示准备好进行高效检索，我们使用FAISS对其进行索引。敬请关注，我们将在下一节中深入探讨这个话题。
- en: FAISS for Efficient Indexing
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FAISS用于高效索引
- en: FAISS supports various index structures optimized for different use cases. It
    is a library designed for scenarios where one must quickly find the closest matches
    to a given query vector in a large collection of vectors.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: FAISS支持多种索引结构，以优化不同的使用场景。它是一个设计用于在大量向量中快速找到与给定查询向量最接近的匹配项的库。
- en: 'Inverted files (IVF): Indexes clusters of similar vectors. Suitable for medium-dimensional
    vectors.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 倒排文件（IVF）：对相似向量的簇进行索引。适用于中维向量。
- en: 'Product quantization (PQ): Encodes vectors into quantized subspaces. Suitable
    for high-dimensional vectors.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品量化（PQ）：将向量编码到量化子空间中。适用于高维向量。
- en: 'Cluster-based strategies: Organizes vectors into a hierarchical set of clusters
    for multi-level search. Suitable for very large datasets.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于簇的策略：将向量组织成分层的簇集以进行多级搜索。适用于非常大的数据集。
- en: To use FAISS for semantic search, we first load our vector dataset (semantic
    vectors from sentence transformer encoding) and construct a FAISS index. The specific
    index structure we choose depends on factors like the dimensionality of our semantic
    vectors and desired efficiency. We then index the semantic vectors by passing
    them into the FAISS index, which will efficiently organize them to enable fast
    retrieval.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用FAISS进行语义搜索，我们首先加载我们的向量数据集（来自句子变换器编码的语义向量）并构建FAISS索引。我们选择的具体索引结构取决于语义向量的维度和期望的效率等因素。然后，我们通过将语义向量传递到FAISS索引中对其进行索引，FAISS将高效地组织它们以实现快速检索。
- en: For search, we encode a new sentence into a semantic vector query and pass it
    to the FAISS index. FAISS will retrieve the closest matching semantic vectors
    and return the most similar sentences. Compared to linear search, which scores
    the query vector against every indexed vector, FAISS enables much faster retrieval
    times that typically scale logarithmically with the number of indexed vectors.
    Additionally, the indexes are highly memory-efficient because they compress the
    original dense vectors.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于搜索，我们将新的句子编码成一个语义向量查询并将其传递给FAISS索引。FAISS将检索最接近的语义向量并返回最相似的句子。与线性搜索相比，后者会将查询向量与每个索引向量进行比对，FAISS能够提供更快的检索时间，通常与索引向量的数量呈对数级缩放。此外，这些索引具有高度的内存效率，因为它们压缩了原始密集向量。
- en: Inverted Files Index
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 倒排文件索引
- en: The Inverted Files (IVF) index in FAISS clusters similar vectors into ‘inverted
    files’ and is suitable for medium-dimensional vectors (e.g., 100–1000 dimensions).
    Each inverted file contains a subset of vectors that are close together. At search
    time, FAISS searches only the inverted files closest to the query vector instead
    of searching through all vectors, enabling efficient search even with many vectors.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: FAISS中的倒排文件（IVF）索引将相似的向量聚集到“倒排文件”中，适用于中维向量（例如，100–1000维）。每个倒排文件包含相互接近的向量子集。在搜索时，FAISS仅搜索与查询向量最接近的倒排文件，而不是搜索所有向量，即使有许多向量，也能实现高效搜索。
- en: To construct an IVF index, we specify the number of inverted files (clusters)
    we want and the maximum number of vectors per inverted file. Then, FAISS assigns
    each vector to the closest inverted file until no inverted file exceeds the maximum.
    The inverted files contain representative points that summarize the vectors within
    them. At query time, FAISS computes the distance between the query vector and
    each inverted file representative point and searches only the closest inverted
    files for the closest matching vectors.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建IVF索引，我们需要指定倒排文件（簇）的数量以及每个倒排文件的最大向量数量。然后，FAISS将每个向量分配给最近的倒排文件，直到没有倒排文件超过最大数量。倒排文件包含代表性点，这些点总结了它们内部的向量。在查询时，FAISS计算查询向量与每个倒排文件代表性点之间的距离，并仅搜索与查询向量最接近的倒排文件以找到最匹配的向量。
- en: For example, if we have 1024-dimensional image feature vectors and want to perform
    a fast search over 1 million vectors, we could create an IVF index with 1024 inverted
    files (clusters) and a maximum of 1000 vectors per inverted file. In this approach,
    FAISS would search only the closest inverted files to the query, resulting in
    faster search times than linear search.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们有1024维的图像特征向量并且想要在100万个向量中进行快速搜索，我们可以创建一个包含1024个倒排文件（簇）的IVF索引，每个倒排文件最多包含1000个向量。在这种方法中，FAISS只会搜索与查询最接近的倒排文件，从而比线性搜索更快。
- en: Putting It All Together
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 汇总所有内容
- en: In this section, we will build a scalable semantic search with FAISS and Sentence
    Transformers. We will show you how to evaluate the performance benchmarks of this
    approach and discuss further improvements and applications.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用FAISS和Sentence Transformers构建一个可扩展的语义搜索引擎。我们将展示如何评估这种方法的性能基准，并讨论进一步的改进和应用。
- en: Scalable Semantic Search Engine
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展的语义搜索引擎
- en: To build a scalable semantic search engine, we first initialize the `ScalableSemanticSearch`
    class. This class takes care of encoding sentences using Sentence Transformers
    and indexing them using FAISS for efficient searching. It also provides utility
    methods for saving and loading indices, measuring time, and memory usage.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建一个可扩展的语义搜索引擎，我们首先初始化`ScalableSemanticSearch`类。该类负责使用Sentence Transformers对句子进行编码，并使用FAISS对其进行索引，以实现高效搜索。它还提供了保存和加载索引、测量时间和内存使用的实用方法。
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we encode the large corpus of documents using the encoding method, which
    returns a numpy array of semantic vectors. The method also creates a mapping between
    indices and sentences that will be useful later when retrieving the top results.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用编码方法对大量文档进行编码，该方法返回一个语义向量的numpy数组。该方法还创建了一个索引和句子之间的映射，这在检索前几个结果时会很有用。
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, we build the FAISS index using the build_index method, which takes the
    embeddings as input. This method creates an IndexIVFPQ or IndexFlatL2 index, depending
    on the number of data points in the embeddings.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用build_index方法构建FAISS索引，该方法以嵌入向量作为输入。该方法根据嵌入中的数据点数量创建IndexIVFPQ或IndexFlatL2索引。
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Selecting Indexing Approaches Based on Dataset Size
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于数据集大小选择索引方法
- en: 'We define two indexing approaches: Exact Search with L2 distance and Approximate
    Search with Product Quantization and L2 distance. We will also discuss the rationale
    behind selecting the first approach for smaller datasets (less than 1500 documents)
    and the second for larger datasets.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了两种索引方法：L2距离的精确搜索和产品量化与L2距离的近似搜索。我们还将讨论选择第一种方法用于较小数据集（少于1500个文档）和第二种方法用于较大数据集的原因。
- en: '**1\. Exact Search with L2 distance**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. L2距离的精确搜索**'
- en: Exact Search with L2 distance is an exact search method that computes the L2
    (Euclidean) distance between a query vector and every vector in the dataset. This
    method guarantees to find the exact nearest neighbors but can be slow for large
    datasets, as it performs a linear scan of the data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: L2距离的精确搜索是一种精确搜索方法，它计算查询向量与数据集中每个向量之间的L2（欧几里得）距离。该方法可以保证找到精确的最近邻，但对于大型数据集可能比较慢，因为它执行线性扫描。
- en: '*Use case:* This method is suitable for small datasets where the exact nearest
    neighbors are required, and the computational cost is not a concern.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用案例：* 这种方法适用于需要精确最近邻的小型数据集，并且计算成本不是问题。'
- en: '**2\. Approximate Search with Product Quantization and L2 distance**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 产品量化与L2距离的近似搜索**'
- en: Approximate Search with Product Quantization and L2 distance is an approximate
    nearest neighbor search method that combines an inverted file structure, product
    quantization, and L2 distance to search for similar vectors in large datasets
    efficiently. The method first clusters the dataset using k-means (faiss.IndexFlatL2
    as the quantizer) and then applies product quantization to compress the residual
    vectors. This approach allows for a faster search using less memory than brute-force
    methods.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 近似搜索与产品量化和L2距离是一种近似最近邻搜索方法，它结合了倒排文件结构、产品量化和L2距离，以高效地在大数据集中搜索相似向量。该方法首先使用k-means（faiss.IndexFlatL2作为量化器）对数据集进行聚类，然后应用产品量化来压缩残差向量。这种方法比起蛮力方法使用更少的内存，从而实现更快的搜索速度。
- en: '*Use case:* This method is suitable for large datasets where the exact nearest
    neighbors are not strictly required, and the primary focus is on search speed
    and memory efficiency.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用案例：* 这种方法适用于不严格要求精确最近邻的大型数据集，主要关注搜索速度和内存效率。'
- en: '**The rationale for selecting different approaches based on dataset size**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择不同方法的原因依据数据集大小**'
- en: For datasets containing less than 1500 documents, we set the Exact Search with
    L2 distance approach because the computational cost is not a significant concern
    in this case. Furthermore, this approach guarantees to find the nearest neighbors,
    which is desirable for smaller datasets.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于包含少于1500个文档的数据集，我们设置了L2距离的精确搜索方法，因为在这种情况下计算成本不是一个重大问题。此外，这种方法可以保证找到最近邻，这对于较小的数据集是可取的。
- en: We prefer using the Approximate Search with Product Quantization and L2 distance
    approach for larger datasets because it offers a more efficient search and consumes
    less memory than the exact search method. The Approximate Search approach proves
    to be more suitable for large datasets when prioritizing search speed and memory
    efficiency over finding the exact nearest neighbors.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较大的数据集，我们倾向于使用近似搜索与产品量化和 L2 距离方法，因为它比精确搜索方法更高效，消耗的内存也更少。当优先考虑搜索速度和内存效率而非找到精确的最近邻时，近似搜索方法更适合大数据集。
- en: Search Procedure
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索过程
- en: After building the index, we can perform a semantic search by providing an input
    query and the number of top results to return. The `search` method computes cosine
    similarity between the input sentence and the indexed embeddings and returns the
    indices and scores of the top matching sentences.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建索引后，我们可以通过提供输入查询和返回的结果数量来执行语义搜索。`search` 方法计算输入句子与已索引嵌入之间的余弦相似度，并返回最匹配句子的索引和分数。
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Finally, we can retrieve the top sentences using the `get_top_sentences` method,
    which takes the index to sentence mapping and the top indices as input and returns
    a list of the top sentences.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用 `get_top_sentences` 方法检索最顶级的句子，该方法接受索引到句子的映射和顶级索引作为输入，并返回顶级句子的列表。
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The Complete Model
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完整模型
- en: 'The complete class of our model looks like the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们模型的完整类如下：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: End-to-End Demo
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 端到端演示
- en: This section will provide an end-to-end demo of the scalable semantic search
    engine using the SemanticSearchDemo class and the
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将提供使用 SemanticSearchDemo 类的可扩展语义搜索引擎的端到端演示。
- en: main function from the code above. The goal is to understand how the different
    concepts and components combine to create a practical application.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码中的主函数。目标是理解不同概念和组件如何结合创建一个实用的应用程序。
- en: '**Initializing the SemanticSearchDemo class**: To initialize the SemanticSearchDemo
    class, provide the dataset path, the ScalableSemanticSearch model, an optional
    index path, and an optional subset size. This flexibility enables using different
    datasets, models, and subset sizes.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**初始化 SemanticSearchDemo 类**：要初始化 SemanticSearchDemo 类，需要提供数据集路径、ScalableSemanticSearch
    模型、可选的索引路径和可选的子集大小。这种灵活性使得可以使用不同的数据集、模型和子集大小。'
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Loading data**: The `load_data` function actively reads and processes data
    from a file, then returns a list of sentences. The system uses this data to train
    the semantic search model.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**加载数据**：`load_data` 函数主动读取和处理文件中的数据，然后返回一个句子列表。系统使用这些数据来训练语义搜索模型。'
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Training the model**: The `train` function trains the semantic search model
    on the dataset and returns the training process’s elapsed time and memory usage.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练模型**：`train` 函数在数据集上训练语义搜索模型，并返回训练过程的消耗时间和内存使用情况。'
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Performing inference**: The `infer` function takes a query, a list of sentences
    to search in, and the number of top results to return. It performs inference on
    the model and returns the top matching sentences, elapsed time, and memory usage
    for the inference process.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**进行推理**：`infer` 函数接受一个查询、一组待搜索的句子和返回的结果数量。它对模型进行推理，并返回最匹配的句子、推理过程的消耗时间和内存使用情况。'
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The full class for the demo is below:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 演示的完整类如下：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Performance Evaluation of our Scalable Semantic Search Engine
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们可扩展语义搜索引擎的性能评估
- en: In order to evaluate the performance of our scalable semantic search engine,
    we can measure the time and memory usage for various operations like training,
    inference, and loading indices. The `ScalableSemanticSearch` class provides the
    `timed_train`, `timed_infer`, and `timed_load_index` methods to measure these
    benchmarks.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们可扩展的语义搜索引擎的性能，我们可以测量各种操作的时间和内存使用情况，如训练、推理和加载索引。`ScalableSemanticSearch`
    类提供 `timed_train`、`timed_infer` 和 `timed_load_index` 方法来测量这些基准。
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The plots for both the training and inference performance in terms of execution
    time and memory usage can be found below. We will be discussing and interpreting
    the results in light of the selection of algorithms based on the size of the corpus
    we used.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 关于执行时间和内存使用情况的训练和推理性能图表如下。我们将讨论和解释这些结果，基于我们使用的语料库大小选择的算法。
- en: '![](../Images/7f0a97496eea4a7bc7ca428e5ff5e322.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f0a97496eea4a7bc7ca428e5ff5e322.png)'
- en: 'Figure 2: Training time and memory usage for different dataset sizes'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：不同数据集大小的训练时间和内存使用情况
- en: '![](../Images/190e671ff8caa676573355fb3f30353d.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/190e671ff8caa676573355fb3f30353d.png)'
- en: 'Figure 3: Inference time and memory usage for different dataset sizes'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：不同数据集大小的推断时间和内存使用情况
- en: Exact Search using L2 distance
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 L2 距离的精确搜索
- en: Exact Search using L2 distance is an exhaustive search method that performs
    a linear scan to find the nearest neighbors.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 L2 距离的精确搜索是一种穷举搜索方法，它执行线性扫描以找到最近邻。
- en: '**Theoretical Complexity**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**理论复杂度**'
- en: 'Time Complexity: O(n) — Because it needs to compare the query vector with every
    vector in the dataset.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间复杂度：O(n) — 因为它需要将查询向量与数据集中每个向量进行比较。
- en: 'Memory Complexity: O(n) — It stores all the vectors in the dataset.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存复杂度：O(n) — 它存储数据集中的所有向量。
- en: '**Observed Complexity**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**观察到的复杂度**'
- en: From the plots above, we can observe that for less than 1500 documents, both
    the training time and memory usage increase linearly with the number of documents,
    which matches the expected theoretical complexity.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从上述图表中可以观察到，对于少于 1500 个文档，训练时间和内存使用量都随着文档数量线性增加，这与预期的理论复杂度相符。
- en: Approximate Search using Product Quantization and L2 distance
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用产品量化和 L2 距离的近似搜索
- en: 'Approximate Search using Product Quantization and L2 distance is an approximate
    nearest neighbor search method that employs product quantization and an inverted
    file structure for improved efficiency. The number of clusters (k) is an essential
    factor in this method, and it is calculated using the formula: max(2, min(n_data_points,
    int(np.sqrt(n_data_points)))).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用产品量化和 L2 距离的近似搜索方法是一种近似最近邻搜索方法，它采用产品量化和倒排文件结构来提高效率。聚类数量（k）是此方法中的一个重要因素，计算公式为：max(2,
    min(n_data_points, int(np.sqrt(n_data_points))))。
- en: 'In simpler terms, this formula ensures that:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，这个公式确保了：
- en: There are at least 2 clusters, providing a minimum level of partitioning.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 至少有 2 个聚类，提供了最低水平的分区。
- en: The number of clusters doesn’t exceed the number of data points.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聚类的数量不会超过数据点的数量。
- en: As a heuristic, the square root of the number of data points is used to balance
    search accuracy and computational efficiency.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为启发式方法，使用数据点数量的平方根来平衡搜索精度和计算效率。
- en: '**Theoretical Complexity**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**理论复杂度**'
- en: 'Time Complexity (Training): O(n * k) — The complexity of the k-means clustering
    algorithm used in the training phase.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间复杂度（训练）：O(n * k) — k-means 聚类算法在训练阶段的复杂度。
- en: 'Memory Complexity (Training): O(n + k) — It stores the centroids of clusters
    and residual codes.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存复杂度（训练）：O(n + k) — 它存储聚类的质心和残差码。
- en: 'Time Complexity (Inference): O(k + m) — Where m is the number of nearest clusters
    to be searched. It is faster than linear search due to the hierarchical structure
    and approximation.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间复杂度（推断）：O(k + m) — 其中 m 是要搜索的最近聚类的数量。由于层次结构和近似，它比线性搜索更快。
- en: 'Memory Complexity (Inference): O(n + k) — It requires storing the inverted
    file and the centroids.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存复杂度（推断）：O(n + k) — 需要存储倒排文件和质心。
- en: '**Observed Complexity**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**观察到的复杂度**'
- en: 'From the plots above, we can observe that for more than 1500 documents:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述图表中可以观察到，对于超过 1500 个文档：
- en: 'Training time complexity: The growth is faster than linear, which matches the
    expected theoretical complexity of O(n * k) since k grows with the number of data
    points (n).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练时间复杂度：增长速度快于线性，这与预期的理论复杂度 O(n * k) 相符，因为 k 随着数据点（n）的增加而增长。
- en: 'Training memory complexity: The memory usage increases non-linearly with the
    number of documents, which matches the expected theoretical complexity of O(n
    + k).'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练内存复杂度：内存使用量随着文档数量的增加呈非线性增长，这与预期的理论复杂度 O(n + k) 相符。
- en: 'Inference time complexity: The execution time remains almost constant, which
    is consistent with the expected theoretical complexity of O(k + m), as m is usually
    much smaller than n.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推断时间复杂度：执行时间几乎保持不变，与期望的理论复杂度 O(k + m) 一致，因为 m 通常远小于 n。
- en: 'Inference memory complexity: The memory usage increases linearly with the number
    of documents, which matches the expected theoretical complexity of O(n + k).'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推断内存复杂度：内存使用量随着文档数量线性增加，这与预期的理论复杂度 O(n + k) 相符。
- en: We could also evaluate the accuracy and recall of the search engine by comparing
    the top results against a manually curated set of ground truth results for a given
    query. We can calculate the average accuracy and recall for the entire dataset
    by iterating over various queries and comparing the results.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过将搜索引擎的前几个结果与手动整理的真实结果集进行比较，来评估搜索引擎的准确性和召回率。我们可以通过迭代各种查询并比较结果来计算整个数据集的平均准确性和召回率。
- en: Conclusion
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The demonstrated approach highlights the scalability of semantic search using
    FAISS and Sentence Transformers while revealing enhancement opportunities. For
    instance, integrating advanced transformer models for encoding sentences or testing
    alternative FAISS configurations could speed up the search process. Additionally,
    investigating state-of-the-art models like GPT-4 or BERT variants might improve
    semantic search tasks’ performance and accuracy.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 展示的方法突显了使用 FAISS 和 Sentence Transformers 进行语义搜索的可扩展性，同时揭示了改进机会。例如，集成先进的 Transformer
    模型来对句子进行编码，或测试替代的 FAISS 配置，可能会加快搜索过程。此外，研究最先进的模型，如 GPT-4 或 BERT 变体，可能会提高语义搜索任务的性能和准确性。
- en: 'Several potential applications for the scalable semantic search engine include:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展的语义搜索引擎的几个潜在应用包括：
- en: Retrieving documents in extensive knowledge bases
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在广泛的知识库中检索文档
- en: Answering questions in automated systems
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在自动化系统中回答问题
- en: Providing personalized recommendations
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供个性化推荐
- en: Generating chatbot responses
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成聊天机器人回应
- en: Taking advantage of FAISS and Sentence Transformers, we developed a scalable
    semantic search engine capable of efficiently processing billions of documents
    and delivering accurate search results. This innovative approach can significantly
    influence the future of semantic search and its impact across various industries
    and applications.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 FAISS 和 Sentence Transformers，我们开发了一种可扩展的语义搜索引擎，能够高效处理数十亿份文档并提供准确的搜索结果。这种创新的方法可能会显著影响语义搜索的未来以及其在各个行业和应用中的影响。
- en: As digital data grows, the demand for efficient and accurate semantic search
    engines becomes more critical. Based on FAISS and Sentence Transformers, the scalable
    semantic search engine lays a strong foundation for overcoming these challenges
    and revolutionizing how we search for and access relevant information.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数字数据的增长，对高效且准确的语义搜索引擎的需求变得越来越重要。基于 FAISS 和 Sentence Transformers，可扩展的语义搜索引擎为克服这些挑战奠定了坚实的基础，并革新了我们搜索和获取相关信息的方式。
- en: Future advancements involve incorporating more advanced natural language processing
    and machine learning techniques to enhance search engine capabilities. These improvements
    could encompass unsupervised learning methods for better understanding context,
    intent, and relationships between query words and phrases and approaches for handling
    ambiguity and variations in language use.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的发展涉及整合更先进的自然语言处理和机器学习技术，以增强搜索引擎的能力。这些改进可能包括用于更好理解上下文、意图以及查询词和短语之间关系的无监督学习方法，以及处理语言使用中的歧义和变体的技术。
- en: About me
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: Serial entrepreneur and leader in the AI space. I develop AI products for businesses
    and invest in AI-focused startups.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 连续创业者和 AI 领域的领军人物。我为企业开发 AI 产品，并投资于 AI 相关的初创公司。
- en: '[Founder @ ZAAI](http://zaai.ai) | [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
    | [X/Twitter](https://x.com/luisbrasroque)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[创始人 @ ZAAI](http://zaai.ai) | [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
    | [X/Twitter](https://x.com/luisbrasroque)'
