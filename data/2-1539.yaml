- en: Multi-Dimensional Exploration Is Possible!
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多维探索是可能的！
- en: 原文：[https://towardsdatascience.com/multi-dimensional-exploration-is-possible-212b99171706](https://towardsdatascience.com/multi-dimensional-exploration-is-possible-212b99171706)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/multi-dimensional-exploration-is-possible-212b99171706](https://towardsdatascience.com/multi-dimensional-exploration-is-possible-212b99171706)
- en: (At least mathematically)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: （至少在数学上）
- en: '[](https://medium.com/@manfred.james?source=post_page-----212b99171706--------------------------------)[![Diego
    Manfre](../Images/2189d8e63df449a869526bf8b6c50440.png)](https://medium.com/@manfred.james?source=post_page-----212b99171706--------------------------------)[](https://towardsdatascience.com/?source=post_page-----212b99171706--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----212b99171706--------------------------------)
    [Diego Manfre](https://medium.com/@manfred.james?source=post_page-----212b99171706--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@manfred.james?source=post_page-----212b99171706--------------------------------)[![Diego
    Manfre](../Images/2189d8e63df449a869526bf8b6c50440.png)](https://medium.com/@manfred.james?source=post_page-----212b99171706--------------------------------)[](https://towardsdatascience.com/?source=post_page-----212b99171706--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----212b99171706--------------------------------)
    [Diego Manfre](https://medium.com/@manfred.james?source=post_page-----212b99171706--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----212b99171706--------------------------------)
    ·13 min read·Oct 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----212b99171706--------------------------------)
    ·13分钟阅读·2023年10月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/76898d48bac7cf0039a33ff5a35111e7.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76898d48bac7cf0039a33ff5a35111e7.png)'
- en: Image made by the author using [Midjourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用[Midjourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F)制作
- en: Exploring multi-dimensional worlds is a common theme in sci-fi stories and movies.
    While traveling through such worlds remains a fantasy, math can help us approach
    even an idea as outrageous as this one. If you have ever thought, ‘Another day
    without calculating the determinant of a matrix,’ then hold on. Linear algebra
    might be closer than you realize! Transitioning from complex to simpler data structures
    happens every day on your phone, computer, and streaming apps. These operations
    are real, mathematical multi-dimensional portals. This article explains [Principal
    Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)
    — what it is, why it matters, and how it works.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 探索多维世界是科幻故事和电影中的一个常见主题。虽然穿越这些世界仍然是一种幻想，但数学可以帮助我们接近如此荒诞的想法。如果你曾经想过，“又一天没有计算矩阵的行列式”，那就请稍等。线性代数可能比你想象的更接近现实！在你的手机、电脑和流媒体应用中，复杂到简单的数据结构的转换每天都在发生。这些操作是真实的、数学上的多维门户。本文解释了[主成分分析](https://en.wikipedia.org/wiki/Principal_component_analysis)—它是什么，为什么重要，以及它是如何工作的。
- en: Carl Sagan explains…
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Carl Sagan 解释了……
- en: There is a [video](https://youtu.be/UnURElCzGc0?feature=shared) of [Carl Sagan](https://en.wikipedia.org/wiki/Carl_Sagan)
    on YouTube in which he explains how a visitor from a higher-dimensional world
    would look like to their lower-dimensional counterparts. This beautiful lesson
    is drawn from Sagan’s renowned series, [Cosmos](https://en.wikipedia.org/wiki/Cosmos:_A_Personal_Voyage).
    As with many other excerpts from his show, Sagan masterfully explains how some
    2-dimensional individuals in “flatland” would experience a visit from a 3-dimensional
    apple. In reality, the mathematics behind moving from higher to lower dimensional
    spaces does not go beyond the contents of a linear algebra course. As Sagan puts
    it towards the end of the video, ‘While we cannot imagine the world of four dimensions
    we can perfectly well think about it’.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个[视频](https://youtu.be/UnURElCzGc0?feature=shared)，由[Carl Sagan](https://en.wikipedia.org/wiki/Carl_Sagan)在YouTube上讲解，他解释了来自高维世界的访客会如何看待他们的低维对等物。这个美丽的课程源自Sagan著名的系列节目[宇宙](https://en.wikipedia.org/wiki/Cosmos:_A_Personal_Voyage)。正如他节目中的许多摘录一样，Sagan巧妙地解释了在“平面世界”中的二维个体如何体验来自三维苹果的访问。实际上，从高维到低维空间的数学并不超出线性代数课程的内容。正如Sagan在视频结束时所说的，“虽然我们无法想象四维世界，但我们完全可以思考它。”
- en: '![](../Images/b73181eaf202f276a2a2694a5dc4cdee.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b73181eaf202f276a2a2694a5dc4cdee.png)'
- en: A projection of an apple similar to what Carl Sagan is showing in the [video](https://youtu.be/UnURElCzGc0?feature=shared).
    Image made by the author using [MidJourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个类似于卡尔·萨根在[视频](https://youtu.be/UnURElCzGc0?feature=shared)中展示的苹果投影。图片由作者使用[MidJourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F)制作。
- en: An apple projected in a 2D space might not look exactly like an apple but it
    can give us an idea of its shape and size. The picture below shows an apple and
    a carrot projected onto 2-dimensional surfaces. We might recognize the apple only
    by looking at any of the projections. On the other hand, it might be difficult
    to realize that the lower projection corresponds to a carrot. This means that
    we lose some information every time we project high-dimensional objects onto low-dimensional
    spaces. However, these projections help us think about how a high-dimensional
    object would look in our world.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 投影到2D空间中的苹果可能看起来不像真正的苹果，但它可以给我们苹果的形状和大小的概念。下面的图片展示了一个苹果和一个胡萝卜投影到2维表面上的情况。我们可能仅通过任何一个投影就能识别出苹果。另一方面，可能很难意识到下方的投影对应的是一个胡萝卜。这意味着每次我们将高维对象投影到低维空间时，我们都会丢失一些信息。然而，这些投影帮助我们思考一个高维对象在我们世界中的样子。
- en: '![](../Images/01990a321325b281884455918dd84445.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01990a321325b281884455918dd84445.png)'
- en: Figure 2\. 2D projections of a carrot and an apple. Image made by the author.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 胡萝卜和苹果的2D投影。图片由作者制作。
- en: Depending on which plane we use to project the objects, we will get a different
    idea of their shape and characteristics. So, while it is true that projections
    can help us to think about a higher dimension, the way in which we project is
    crucial for our understanding. Take another look at the lower projection of the
    carrot. Is there a way of knowing that this is a carrot just judging by this projection?
    Probably not. It would be better to choose any of the other two projections. But,
    how can we choose them? If we are trying to think about an object in 10 dimensions,
    how can we choose the best three dimensions that our brain will be able to process?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们用来投影对象的平面不同，我们会对它们的形状和特征有不同的理解。因此，虽然投影可以帮助我们思考更高的维度，但投影的方式对我们的理解至关重要。再看看胡萝卜的下方投影。仅通过这个投影，有办法知道这就是胡萝卜吗？可能没有。选择其他两个投影中的任何一个可能更好。但是，我们如何选择它们呢？如果我们试图思考一个10维的对象，我们如何选择出我们的大脑能够处理的最佳三个维度？
- en: Going beyond apples and carrots
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越苹果和胡萝卜
- en: To understand this, we first need to realize that multi-dimensional spaces are
    not only related to the worlds of carrots and apples. Each dimension can represent
    a particular parameter or characteristic in a set of data points. If we take a
    group of people and measure five of their characteristics we can plot each one
    of these individuals in a 5-dimensional space. Once again, we cannot imagine this
    space but we can think about it if we project each one of these 5-dimensional
    points onto a 3-dimensional or 2-dimensional space that we can visualize. In the
    example below, someone living in a 2-dimensional world can only see that there
    are three spheres if they are projected onto the lower (xy) plane. Otherwise,
    it will only see two which is not a good way of thinking about this group of 3-dimensional
    spheres after all.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这一点，我们首先需要意识到，多维空间不仅与胡萝卜和苹果的世界相关。每个维度可以表示数据点集合中的某个特定参数或特征。如果我们取一组人并测量他们的五个特征，我们可以将这些个体绘制在一个5维空间中。再次强调，我们无法想象这个空间，但我们可以通过将这些5维点投影到一个我们可以可视化的3维或2维空间来思考它。在下面的示例中，生活在2维世界中的人只能看到投影到下方（xy）平面的三个球体。否则，他们只能看到两个，这并不是很好地思考这组3维球体的方式。
- en: '![](../Images/ff959a67265d77137737c5f33dbc4cfd.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff959a67265d77137737c5f33dbc4cfd.png)'
- en: Figure 3\. 2D projections of points in space. Image made by the author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. 空间中点的2D投影。图片由作者制作。
- en: The answer to which are the best dimensions to project data onto is solved with
    [Principal Component Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis).
    The name might seem unrelated to what we have been discussing so far but it originates
    from the fact that in this analysis we are finding which are the principal components
    of a dataset. In this case, components mean dimensions or planes where we can
    project the original data. How does PCA find the best components or dimensions?
    It looks at the variability of each pair of parameters. The bigger their differences,
    the easier is to have a good projection of their true behaviour. The reason why
    we cannot recognize a carrot if we look at its projection on the lower plane is
    because we fail to see the main characteristics of that carrot. Looking at that
    projection we cannot see it is long, thinner at the bottom and with some green
    leaves at the top. We only see a roundish blurb that could represent anything
    else. PCA helps us to look at an object or group of data points in such a way
    we can see their main characteristics.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 投影数据到最佳维度的问题可以通过[主成分分析 (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis)来解决。这个名字可能看起来与我们目前讨论的内容无关，但它源于我们在此分析中寻找数据集的主要成分。在这种情况下，成分意味着可以投影原始数据的维度或平面。PCA
    如何找到最佳成分或维度？它查看每对参数的变异性。差异越大，对其真实行为的良好投影就越容易。我们无法识别胡萝卜的原因是，因为我们无法看到胡萝卜的主要特征。通过查看这种投影，我们无法知道它是长的、底部较细以及顶部有一些绿色叶子。我们只看到一个圆形的模糊物体，可能代表其他任何东西。PCA
    帮助我们以一种可以看到主要特征的方式观察一个物体或数据点组。
- en: Projections into lower-dimensional spaces
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降维投影
- en: A matrix multiplication is a way of projecting points on a lower-dimensional
    space. This means, mathematically going from 3 to 2 dimensions or from 10 to 2
    dimensions. The following picture shows a group of points in 2 dimensions that
    were projected onto one-dimensional lines. This picture is taken from a [Python
    notebook](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb)
    that contains additional details about PCA. The lines in the plot could have been
    defined anywhere. Multiplying a matrix with the original points with a matrix
    that contains unit vectors that define each line will give us the projection of
    the original points onto the lines. So the red and green crosses represent how
    the blue points coming from a 2D world would look like in 1D. Note how the variation
    in the red crosses is bigger than in the green crosses. This means that in the
    green crosses world, the original points will not look as different as they look
    in the red crosses world. The main idea to take here is that even if we have a
    way to move through different dimensions (at least mathematically!), how we project
    the original data will impact the way we see and the way we think about higher-dimensional
    objects.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法是一种将点投影到低维空间的方法。这意味着，从数学上讲，从 3 维降到 2 维，或者从 10 维降到 2 维。下图展示了一组二维中的点如何被投影到一维线上。此图取自一个包含有关
    PCA 的额外细节的[Python 笔记本](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb)。图中的线可以在任何地方定义。将原始点与包含定义每条线的单位向量的矩阵相乘，可以得到原始点在这些线上的投影。因此，红色和绿色的交叉点表示来自二维世界的蓝色点在一维中会是什么样子。注意红色交叉点的变化比绿色交叉点的变化更大。这意味着在绿色交叉点的世界中，原始点看起来不会像在红色交叉点的世界中那样有所不同。这里要注意的主要思想是，即使我们有方法在不同的维度之间移动（至少在数学上是这样！），我们如何投影原始数据会影响我们观察和思考高维对象的方式。
- en: '![](../Images/6d3a3949a41c3ca778185a0f8fbf4afe.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d3a3949a41c3ca778185a0f8fbf4afe.png)'
- en: Figure 4\. Projections of points in 2D onto 1D lines. Image made by the author.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 将二维中的点投影到一维线上的示意图。图像由作者制作。
- en: In an example similar to what we saw in the picture with the carrot and the
    apple, we can imagine a group of points in 3 dimensions and their projections
    in different planes. Once again, depending on the plane that we choose to project
    the points onto we will get different results. This is when PCA comes into play.
    With PCA we can define the best combination of projections so that we will end
    up looking at the biggest variation. So, PCA helps us to have a projection that
    will be more similar to the red crosses than to the green crosses which, in turn,
    will represent a better idea of a group of points in a higher dimension.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个类似于我们在图片中看到的胡萝卜和苹果的例子中，我们可以想象一组3维的点及其在不同平面上的投影。再次根据我们选择的投影平面，我们将得到不同的结果。这时PCA就派上用场了。通过PCA，我们可以定义最佳的投影组合，从而观察到最大的变异。因此，PCA帮助我们获得一个与红色交叉点更相似的投影，而不是绿色交叉点，这反过来会更好地代表在更高维空间中的点集。
- en: 'PCA relies on many of the things you might have studied in a linear algebra
    course. The steps to apply PCA can be summarized as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: PCA依赖于许多你可能在线性代数课程中学习过的内容。应用PCA的步骤可以总结如下：
- en: Covariance matrix
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协方差矩阵
- en: 'Generate a [covariance matrix](https://en.wikipedia.org/wiki/Covariance_matrix#:~:text=In%20probability%20theory%20and%20statistics,of%20a%20given%20random%20vector.):
    the covariance measures how strong the relationship between two variables is.
    If we have a group of points that belong to a 10-dimensional space, then we will
    have 45 different combinations of each pair of dimensions. If we calculate the
    variance for each of these combinations then we can have an idea about the direction
    and the strength of the relationship between two variables. The result of this
    calculation is written in a covariance matrix such as the one shown in the picture.
    Note how each value is repeated twice since each pair of variables can be found
    twice inside the matrix. Take into account that before calculating the covariances,
    the data is generally standardized since each dimension might contain values with
    different scales. Variables with larger scales will dominate the principal components.
    Standardizing the data ensures that all variables have the same scale, allowing
    PCA to give equal weight to each variable.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 生成一个[协方差矩阵](https://en.wikipedia.org/wiki/Covariance_matrix#:~:text=In%20probability%20theory%20and%20statistics,of%20a%20given%20random%20vector.)：协方差测量两个变量之间关系的强度。如果我们有一组属于10维空间的点，那么我们将会有45种不同的维度对组合。如果我们计算这些组合的方差，就可以了解两个变量之间关系的方向和强度。这个计算结果写在协方差矩阵中，如图片所示。注意每个值出现了两次，因为每对变量在矩阵中会出现两次。请注意，在计算协方差之前，数据通常会被标准化，因为每个维度可能包含不同量纲的值。具有较大量纲的变量会主导主成分。标准化数据可以确保所有变量具有相同的量纲，从而使PCA对每个变量给予相等的权重。
- en: '![](../Images/db4b320f368bf18bb0d7ed8e27c77f3c.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db4b320f368bf18bb0d7ed8e27c77f3c.png)'
- en: Figure 5\. Covariance matrix. Image made by the author.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图5. 协方差矩阵。图像由作者制作。
- en: Eigenvectors and eigenvalues
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征向量和特征值
- en: 'Calculate the [eigenvectors and eigenvalues](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors)
    of the covariance matrix: yes! You might have heard this name before in a Linear
    Algebra lecture! And yes! It might sound really strange! However, the key thing
    to understand here is that eigenvectors and eigenvalues tell us something special
    about a particular transformation. Remember how matrix multiplication is essentially
    a transformation in which we take some points and change them through sums and
    multiplications. An eigenvector represents a particular direction that does not
    change after performing a transformation. On the other hand, an eigenvalue represents
    how much the eigenvector is stretched or squished without changing its direction.
    So eigenvectors and eigenvalues are really important because they tell us which
    are the directions that remained unchanged after a transformation.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 计算协方差矩阵的[特征向量和特征值](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors)：是的！你可能在某次线性代数讲座中听到过这个名字！而且，是的！这可能听起来非常陌生！然而，理解的关键在于特征向量和特征值告诉我们关于特定变换的一些特殊信息。记住矩阵乘法本质上是一个变换，我们通过求和和乘法来改变一些点。特征向量代表一个特定的方向，在执行变换后方向保持不变。另一方面，特征值代表特征向量在变换过程中被拉伸或压缩的程度，而方向不变。因此，特征向量和特征值非常重要，因为它们告诉我们在变换后哪些方向保持不变。
- en: 'The following picture shows three different linear transformations applied
    to the same group of data. This linear transformation is a horizontal shear. For
    all the cases shown in the picture, the eigenvector is always the same: (1, 0).
    This means that any point that lies on top of the unit vector (1,0) will remain
    unchanged after the transformation. Note how the points (1,0) and (-1,0) are not
    changed by the transformation and neither is any point that lies on top of the
    eigenvector (1,0) such as (0.25, 0), (-0.75, 0) and so on.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了对同一组数据应用的三种不同线性变换。这种线性变换是水平剪切。在图中显示的所有情况下，特征向量始终是相同的：（1, 0）。这意味着任何位于单位向量（1,0）上的点在变换后将保持不变。注意点（1,0）和（-1,0）没有被变换改变，任何位于特征向量（1,0）上的点，如（0.25,
    0），（-0.75, 0）等，也没有被改变。
- en: '![](../Images/3a0e9b3f1a9e826f8a0b264edd36ebff.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a0e9b3f1a9e826f8a0b264edd36ebff.png)'
- en: Figure 6\. Graphical explanation of an eigenvector. Image made by the author.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图6\. 特征向量的图示解释。图片由作者制作。
- en: Transformation
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换
- en: Use the eigenvectors to transform the original data into a lower-dimensional
    space. The eigenvalues will tell you which are the most important eigenvectors
    to project onto. So in a plot like the one shown in Figure 4, the eigenvector
    corresponding to the red crosses has a higher eigenvalue than the eigenvector
    with the green crosses. This is because the variation in the red crosses is bigger
    than in the green crosses. If we want to have a good idea about the points in
    2D from a 1D point of view, it is better to transform the points using the first
    vector than the second one. You can see how an array of (nx2) corresponding to
    two dimensions is converted into one dimension if it is multiplied by an eigenvector
    of shape (2x1). We can follow the same process if we want to convert an original
    dataset of 10 dimensions into 3 or 2 dimensions.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用特征向量将原始数据转换到较低维空间。特征值会告诉你哪些特征向量最重要，应该投影到这些向量上。因此，在像图4所示的图中，红色交叉点对应的特征向量的特征值高于绿色交叉点的特征向量。这是因为红色交叉点的变异性大于绿色交叉点。如果我们想从一维视角对二维点有一个良好的了解，使用第一个向量来转换点比使用第二个向量更好。你可以看到，一个对应于两个维度的（nx2）数组如果乘以形状为（2x1）的特征向量，就会被转换为一维。如果我们想将一个10维的原始数据集转换为3维或2维，我们可以遵循相同的过程。
- en: Projection
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 投影
- en: Generally, it is useful to project the converted points onto the original dimensions.
    For this example, it means taking the transformed 1D points and plotting them
    back in a 2D space which is what Figure 4 is showing. To project the points onto
    the original dimensions you can multiply the transformed array by the transpose
    of the eigenvectors array. In this case, this means multiplying (nx1) times (1x2).
    This will result in the (nx2) array that is shown in Figure 7\. In this plot,
    Eigenvector 1 and Eigenvector 2 have eigenvalues of 39.2 and 5.3 respectively.
    This means that Eigenvector 1 represents a better projection than Eigenvector
    2 which can be seen in the plot as the spread of the red crosses is bigger than
    the spread in the green crosses.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，将转换后的点投影到原始维度上是有用的。对于这个例子，这意味着将转换后的1D点重新绘制到2D空间中，这就是图4所示的内容。要将点投影到原始维度上，你可以将转换后的数组乘以特征向量数组的转置。在这种情况下，这意味着将（nx1）乘以（1x2）。这将得到图7所示的（nx2）数组。在这个图中，特征向量1和特征向量2的特征值分别为39.2和5.3。这意味着特征向量1比特征向量2代表了更好的投影，可以从图中看到，因为红色交叉点的分布比绿色交叉点的分布更大。
- en: '![](../Images/400b5d845fd5224ce820c4b99f89a883.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/400b5d845fd5224ce820c4b99f89a883.png)'
- en: Figure 7\. Points in 2D projected onto the principal components. Image made
    by the author.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图7\. 二维点投影到主成分上。图片由作者制作。
- en: A numerical carrot
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数值胡萝卜
- en: Let’s apply the previous steps to a problem similar to what we presented at
    the beginning of this article. The following picture shows a 3D distribution of
    points that look like a carrot (see this [Python notebook](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb)
    for more information about how to build this carrot). It also shows the projections
    on each plane. We can see that someone who observes the projection on the XY plane
    will find it difficult to realize that the points actually represent a carrot,
    whereas projections ZX and ZY have a better representation. So, in this case,
    it is clear that if we want to visualize this 3D object in 2D, we better project
    it onto planes ZX or YZ.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将之前的步骤应用到一个类似于本文开头展示的问题中。下图展示了一个3D点分布，看起来像胡萝卜（有关如何构建这个胡萝卜的更多信息，请参见这个[Python笔记本](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb)）。它还展示了每个平面的投影。我们可以看到，观察XY平面上的投影的人会发现很难意识到这些点实际上代表了胡萝卜，而ZX和平面Z的投影有更好的表示效果。因此，在这种情况下，如果我们想在2D中可视化这个3D对象，最好将其投影到ZX或YZ平面上。
- en: '![](../Images/1eba526694229aa7762c75b4e4d9d637.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1eba526694229aa7762c75b4e4d9d637.png)'
- en: Figure 8\. 3D points in the shape of a carrot projected onto different planes.
    Image made by the author.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图8\. 旋转胡萝卜形状的3D点投影到不同平面上。图像由作者制作。
- en: What if the best projection plane is not that obvious? Let’s say that now the
    group of points we want to project looks like the following picture. Note that
    is the same carrot as before but rotated. If we project these points onto the
    three surfaces we have seen before, we will end up with a rotated version of the
    carrot. The best projection is a plane that goes through the middle of the carrot
    and this is precisely the projection that we can get if we apply PCA to the original
    points. By finding the direction in which the variation between the points is
    bigger, PCA can help us visualize data points in high-dimensional spaces. The
    2D picture of a carrot is a good representation of a 3D carrot although it is
    not exactly the same. However, it is better than projecting in any other plane.
    For more information about how to apply PCA in Python using scikit-learn, [review
    this Python notebook](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果最佳投影平面不是那么明显呢？假设现在我们要投影的点群如下图所示。注意这与之前的胡萝卜相同，但已旋转。如果我们将这些点投影到之前看到的三个平面上，我们将得到胡萝卜的旋转版本。最佳投影是通过胡萝卜中间的平面，而这正是我们可以通过对原始点应用PCA来获得的投影。通过找到点之间变化最大的方向，PCA可以帮助我们在高维空间中可视化数据点。尽管2D胡萝卜图像与3D胡萝卜不完全相同，但它仍然是一个很好的表示，胜过其他任何平面。有关如何使用scikit-learn在Python中应用PCA的更多信息，请[查看这个Python笔记本](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb)。
- en: '![](../Images/f24c8ea3b5b5dacabbcbd529cd5dd736.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f24c8ea3b5b5dacabbcbd529cd5dd736.png)'
- en: Figure 9\. 3D points in the shape of a rotated carrot projected onto different
    planes. Image made by the author.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图9\. 旋转胡萝卜形状的3D点投影到不同平面上。图像由作者制作。
- en: '![](../Images/30112a1db31f94abfe83c084f4fef141.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/30112a1db31f94abfe83c084f4fef141.png)'
- en: 'Figure 10\. Left: 3D points in the shape of a rotated carrot projected onto
    a plane defined by 2 principal components. Right: transformation of the 3D carrot
    into 2D according to different planes. The one in color represents the transformation
    according to the principal components. Image made by the author.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图10\. 左侧：旋转胡萝卜形状的3D点投影到由2个主成分定义的平面上。右侧：根据不同平面对3D胡萝卜进行的2D转换。彩色图像表示根据主成分的转换。图像由作者制作。
- en: Applications of PCA
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PCA的应用
- en: One of the most important applications of PCA is related to image processing.
    This means taking an image and analyzing its features to classify it or recognize
    that an image belongs to a certain category. Image recognition algorithms are
    widely used nowadays in our cell phones and cameras. To understand how PCA is
    applied in image processing, we should first take a look at how images are stored
    and handled. This is a very simple example that can help us to understand the
    application of PCA in image processing.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: PCA最重要的应用之一与图像处理相关。这意味着对图像进行分析以分类或识别其所属类别。图像识别算法如今在我们的手机和相机中广泛使用。要了解PCA如何应用于图像处理，我们应首先了解图像如何存储和处理。以下是一个非常简单的示例，帮助我们理解PCA在图像处理中的应用。
- en: Let’s say we have a greyscale image that we want to process. One of the multiple
    ways of doing this is to convert this image into an array that has several rows
    and columns that correspond to the number of pixels in the image (see this [Python
    notebook](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb)
    to learn how to load images and apply PCA to them). So at each pixel, we will
    have a number that typically ranges from 0 to 255 and that represents the intensity
    value. Zero represents black, 255 represents white, and any intermediate value
    is a different shade of grey. This means that the following 50x50 pixel greyscale
    picture can be represented as a 50x50 array.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一张灰度图像需要处理。处理这种图像的多种方法之一是将这张图像转换为一个数组，该数组有多行多列，分别对应图像中的像素数量（请参阅这个[Python笔记本](https://github.com/manfrezord/MediumArticles/blob/eb224fa957ed4c17ecd9c4b206ce2995624d3677/PCA/PCA_Notebook.ipynb)以了解如何加载图像并对其应用PCA）。因此，在每个像素上，我们将有一个通常范围从0到255的数字，代表强度值。零表示黑色，255表示白色，任何中间值是不同的灰度。这意味着以下50x50像素的灰度图像可以表示为一个50x50的数组。
- en: '![](../Images/d0491d4212fbceb4ddd7a12eee1c878e.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d0491d4212fbceb4ddd7a12eee1c878e.png)'
- en: Figure 11\. Grayscale picture of an octopus with a resolution of 50x50 pixels
    (this image was taken from [Pixilart](https://www.pixilart.com/terms))
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图11\. 分辨率为50x50像素的章鱼灰度图（此图像来自[Pixilart](https://www.pixilart.com/terms)）
- en: A 50x50 array can also be understood as 50 points plotted in a space of 50 dimensions.
    While we cannot imagine a space such as this one, we can think about it! Each
    of the 50 points has 50 different characteristics and these characteristics end
    up creating the picture we see in Figure 11\. Similar to what we did before, we
    can try to find which are the principal components of this data. This can help
    us to plot the points in a lower-dimensional space. The following picture shows
    how the projection would look like if we use different numbers of principal components.
    Note how the fewer the components the blurrier the image is. Also, note how we
    can get an image that looks really similar with 25 principal components.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 50x50的数组也可以理解为在50维空间中绘制的50个点。虽然我们无法想象这样的空间，但我们可以思考一下！这50个点每个都有50个不同的特征，这些特征最终形成了我们在图11中看到的图片。与之前类似，我们可以尝试找到这些数据的主成分。这可以帮助我们将点绘制在较低维空间中。下图展示了如果我们使用不同数量的主成分，投影会是什么样子。注意主成分越少，图像越模糊。此外，注意我们可以使用25个主成分得到非常相似的图像。
- en: '![](../Images/65cb6b289973e241c42f3c97c80c04ab.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/65cb6b289973e241c42f3c97c80c04ab.png)'
- en: Figure 12\. Grayscale picture of an octopus according to the number of principal
    components that were used to transform the original picture.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图12\. 根据用于转换原始图片的主成分数量得到的章鱼灰度图。
- en: 'What we are doing with this picture is not different from what we did previously
    with the points in space and the plane. In the case of the picture that is converted
    into 25 principal components, what we are doing is:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对这张图片所做的与之前在空间和平面上的点所做的没有不同。在将图片转换为25个主成分的情况下，我们所做的事情是：
- en: Calculating the principal components of the original data set. This means that
    we built a 50x50 covariance matrix and calculated the eigenvectors and eigenvalues
    from that matrix.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算原始数据集的主成分。这意味着我们构建了一个50x50的协方差矩阵，并从该矩阵中计算了特征向量和特征值。
- en: We extracted the 25 eigenvectors that had the biggest eigenvalues. Then we multiplied
    the original dataset of (nx50) by the array of eigenvectors (50x25). This transformed
    the original data into a 25-dimensional space. In our previous example, this is
    like going from the 3D carrot to the 2D carrot.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们提取了具有最大特征值的25个特征向量。然后我们将原始数据集（nx50）与特征向量数组（50x25）相乘。这将原始数据转换为25维空间。在我们之前的例子中，这就像是从3D胡萝卜变为2D胡萝卜。
- en: Since we are interested in comparing how much information we lost by doing this
    dimensionality reduction, we can project the new dataset into a 50-dimensional
    space. This would be as taking the points in 2D and projecting them in the original
    3D space.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们对通过这种降维方式丢失了多少信息感兴趣，我们可以将新的数据集投影到50维空间中。这就像是将2D中的点投影到原始3D空间中。
- en: Figure 13 shows the comparison between the original image and the projected
    image using 25 principal components. It also shows the transformed image if we
    use a resolution of 50x25 instead of 50x50.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图13展示了使用25个主成分的原始图像与投影图像之间的比较。它还展示了如果我们使用50x25而不是50x50的分辨率所得到的转换图像。
- en: '![](../Images/ea532f905438d11218b41442967908ff.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ea532f905438d11218b41442967908ff.png)'
- en: 'Figure 13\. Left: original picture of an octopus. Middle: transformed image
    using 25 principal components. Right: transformed image projected onto a 50 dimensions
    space.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图13\. 左：章鱼的原始图片。中：使用25个主成分转换后的图像。右：投影到50维空间的转换图像。
- en: Now that we have an image in reduced dimensions we can think about how useful
    this is. Instead of storing and analyzing an array of 50x50=2500 numbers, we are
    actually using an array of 50x25=1250 numbers. This can help us to speed up multiple
    processes and to better understand our data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个降维后的图像，可以考虑这有多么有用。我们不再需要存储和分析50x50=2500个数字的数组，而是使用了50x25=1250个数字的数组。这可以帮助我们加快多个过程的速度，并更好地理解数据。
- en: The following picture shows a dimensionality reduction performed on a portrait
    with a high level of detail. A smaller number of principal components makes the
    image blurrier and more difficult to see. However, we can see that even when using
    half of the original dimensions we can get an image that is still acceptable for
    many applications.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图片展示了对高细节度肖像进行的降维处理。较少的主成分使图像变得模糊，更难以辨认。然而，我们可以看到，即使使用原始尺寸的一半，我们仍然可以得到适用于许多应用的图像。
- en: '![](../Images/330e6d7ff4d65a6f53307993c3f8401f.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/330e6d7ff4d65a6f53307993c3f8401f.png)'
- en: Figure 14\. Greyscale portrait using different principal components (the original
    image was made using [Midjourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F))
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图14\. 使用不同主成分的灰度肖像（原始图像是使用[Midjourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F)制作的）
- en: Conclusion
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Though our everyday experience is rooted in three dimensions, we have seen
    that it is possible to think about data structures in higher dimensions. As outrageous
    as it sounds, math is the portal that connects us to worlds of different dimensions.
    However, more important than this, is that going from lower to higher dimensions
    is not something only related to sci-fi and blockbuster movies. Transforming and
    projecting data in multiple dimensions occur seamlessly in our daily interactions
    with cell phones, apps, and computers. Processing and analyzing data in high-dimensional
    spaces allow us to understand patterns and reach conclusions that are part of
    our daily lives. Even though the process explained in this article is undoubtedly
    a simplification of a more convoluted process, the main idea still holds. So,
    next time you watch a movie in which the main character goes through a magic portal
    into a different dimension, remember that at the very least we have the numerical
    foundation to contemplate such journeys. As Carl Sagan said: ‘While we cannot
    imagine the world of four dimensions we can perfectly well think about it’.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的日常体验根植于三维世界，但我们已经看到，可以在更高维度中思考数据结构。尽管听起来很离奇，但数学是连接我们与不同维度世界的门户。然而，更重要的是，从低维到高维的转换不仅仅与科幻和大片有关。数据在多个维度中的转换和投影在我们与手机、应用程序和计算机的日常互动中无缝发生。在高维空间中处理和分析数据使我们能够理解模式并得出属于我们日常生活的结论。尽管本文所解释的过程无疑是对更复杂过程的简化，但主要思想依然有效。因此，下次你看到主角通过魔法门户进入不同维度的电影时，请记住，至少我们有了数值基础来思考这样的旅程。正如**卡尔·萨根**所说：“虽然我们无法想象四维世界，但我们可以很好地思考它。”
