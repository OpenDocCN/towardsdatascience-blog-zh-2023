- en: 'Integrating Neural Net: Deriving the Normal Distribution CDF'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œçš„åº”ç”¨ï¼šæ¨å¯¼æ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/integrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea?source=collection_archive---------7-----------------------#2023-05-03](https://towardsdatascience.com/integrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea?source=collection_archive---------7-----------------------#2023-05-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/integrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea?source=collection_archive---------7-----------------------#2023-05-03](https://towardsdatascience.com/integrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea?source=collection_archive---------7-----------------------#2023-05-03)
- en: Integrating a function using a neural network (with code)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå‡½æ•°ç§¯åˆ†ï¼ˆå«ä»£ç ï¼‰
- en: '[](https://medium.com/@john_morrow?source=post_page-----ea14574548ea--------------------------------)[![John
    Morrow](../Images/4a8ce62a0b4e1eb1cf77ecaba6b7ddcc.png)](https://medium.com/@john_morrow?source=post_page-----ea14574548ea--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea14574548ea--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea14574548ea--------------------------------)
    [John Morrow](https://medium.com/@john_morrow?source=post_page-----ea14574548ea--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@john_morrow?source=post_page-----ea14574548ea--------------------------------)[![John
    Morrow](../Images/4a8ce62a0b4e1eb1cf77ecaba6b7ddcc.png)](https://medium.com/@john_morrow?source=post_page-----ea14574548ea--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea14574548ea--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea14574548ea--------------------------------)
    [John Morrow](https://medium.com/@john_morrow?source=post_page-----ea14574548ea--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb4bcd051bb38&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea&user=John+Morrow&userId=b4bcd051bb38&source=post_page-b4bcd051bb38----ea14574548ea---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea14574548ea--------------------------------)
    Â·6 min readÂ·May 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea14574548ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea&user=John+Morrow&userId=b4bcd051bb38&source=-----ea14574548ea---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb4bcd051bb38&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea&user=John+Morrow&userId=b4bcd051bb38&source=post_page-b4bcd051bb38----ea14574548ea---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea14574548ea--------------------------------)
    Â·6åˆ†é’Ÿé˜…è¯»Â·2023å¹´5æœˆ3æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea14574548ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea&user=John+Morrow&userId=b4bcd051bb38&source=-----ea14574548ea---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea14574548ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea&source=-----ea14574548ea---------------------bookmark_footer-----------)![](../Images/a4ae015d22dc9fef5466d38897886747.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea14574548ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neural-net-deriving-the-normal-distribution-cdf-ea14574548ea&source=-----ea14574548ea---------------------bookmark_footer-----------)![](../Images/a4ae015d22dc9fef5466d38897886747.png)'
- en: Photo by [Jack Anstey](https://unsplash.com/@jack_anstey?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Jack Anstey](https://unsplash.com/@jack_anstey?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥è‡ª [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '**1\. Introduction**'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1\. å¼•è¨€**'
- en: This article presents a method for training a neural network to derive the integral
    of a function. The technique works not only with analytically-solvable integrals
    but also with integrals that do not have a closed-form solution and are typically
    solved by numerical methods. An example is the normal distributionâ€™s cumulative
    density function (CDF). Equation 1 is this distributionâ€™s probability density
    function (PDF), and Equation 2 is its CDF, the integral of the PDF. Figure 1 is
    a plot of these functions. After being trained, the resulting network can serve
    as a stand-alone function generator that delivers points on the CDF curve given
    points from the domain of the distributionâ€™s PDF.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä»‹ç»äº†ä¸€ç§è®­ç»ƒç¥ç»ç½‘ç»œä»¥æ¨å¯¼å‡½æ•°ç§¯åˆ†çš„æ–¹æ³•ã€‚è¯¥æŠ€æœ¯ä¸ä»…é€‚ç”¨äºè§£æè§£ç§¯åˆ†ï¼Œè¿˜é€‚ç”¨äºæ²¡æœ‰å°é—­å½¢å¼è§£ä¸”é€šå¸¸é€šè¿‡æ•°å€¼æ–¹æ³•æ±‚è§£çš„ç§¯åˆ†ã€‚ä¾‹å¦‚ï¼Œæ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰ã€‚æ–¹ç¨‹
    1 æ˜¯è¯¥åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰ï¼Œæ–¹ç¨‹ 2 æ˜¯å…¶ CDFï¼Œå³ PDF çš„ç§¯åˆ†ã€‚å›¾ 1 æ˜¯è¿™äº›å‡½æ•°çš„å›¾ç¤ºã€‚è®­ç»ƒåï¼Œç”Ÿæˆçš„ç½‘ç»œå¯ä»¥ä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„å‡½æ•°ç”Ÿæˆå™¨ï¼Œæä¾›åœ¨
    CDF æ›²çº¿ä¸Šç»™å®š PDF åˆ†å¸ƒåŸŸä¸­çš„ç‚¹ã€‚
- en: '![](../Images/94fc44bd8cc33bdf637f916c2bdb174d.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94fc44bd8cc33bdf637f916c2bdb174d.png)'
- en: 'Equation 1: **PDF (with u=0, ğœ=1)**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 1ï¼š**æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰ï¼ˆu=0ï¼Œğœ=1ï¼‰**
- en: '![](../Images/edc8ecd01cc6d361ff26ba2a908dc473.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/edc8ecd01cc6d361ff26ba2a908dc473.png)'
- en: 'Equation2: **CDF**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 2ï¼š**ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰**
- en: '![](../Images/20af856a48703278cd9f0085b2662f4c.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20af856a48703278cd9f0085b2662f4c.png)'
- en: Figure 1\. **PDF and CDF of the normal distribution**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1\. **æ­£æ€åˆ†å¸ƒçš„ PDF å’Œ CDF**
- en: '**2\. Integrating neural network**'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2\. ç§¯åˆ†ç¥ç»ç½‘ç»œ**'
- en: 'An integrating neural network is trained to produce the integral of a function
    *y = f(x)*. Expressed in terms of the networkâ€™s input and output:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒä¸€ä¸ªç§¯åˆ†ç¥ç»ç½‘ç»œï¼Œä»¥äº§ç”Ÿå‡½æ•° *y = f(x)* çš„ç§¯åˆ†ã€‚ç”¨ç½‘ç»œçš„è¾“å…¥å’Œè¾“å‡ºè¡¨ç¤ºï¼š
- en: '![](../Images/72fa511f99bc616132acfde0459a19f5.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72fa511f99bc616132acfde0459a19f5.png)'
- en: Equation 3
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 3
- en: where *h* and *x* are the networkâ€™s output and input, respectively. For the
    normal distribution, *f(x)* is given by Equation 1, the PDF of the distribution.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *h* å’Œ *x* åˆ†åˆ«æ˜¯ç½‘ç»œçš„è¾“å‡ºå’Œè¾“å…¥ã€‚å¯¹äºæ­£æ€åˆ†å¸ƒï¼Œ*f(x)* ç”±æ–¹ç¨‹ 1 ç»™å‡ºï¼Œå³è¯¥åˆ†å¸ƒçš„ PDFã€‚
- en: Integration of the function is accomplished by training the neural network such
    that the *derivative of the networkâ€™s output is equal to the functionâ€™s output,
    resulting in the networkâ€™s output becoming the integral of the function*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡è®­ç»ƒç¥ç»ç½‘ç»œå®ç°å‡½æ•°çš„ç§¯åˆ†ï¼Œä½¿å¾— *ç½‘ç»œè¾“å‡ºçš„å¯¼æ•°ç­‰äºå‡½æ•°çš„è¾“å‡ºï¼Œä»è€Œä½¿ç½‘ç»œè¾“å‡ºæˆä¸ºå‡½æ•°çš„ç§¯åˆ†*ã€‚
- en: '**2.1 Neural network training**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.1 ç¥ç»ç½‘ç»œè®­ç»ƒ**'
- en: 'Following are the steps of the training procedure:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒç¨‹åºçš„æ­¥éª¤å¦‚ä¸‹ï¼š
- en: 'Apply a training point, *xáµ¢* , to the function *y = f(x)*:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å°†ä¸€ä¸ªè®­ç»ƒç‚¹ *xáµ¢* åº”ç”¨åˆ°å‡½æ•° *y = f(x)*ï¼š
- en: '![](../Images/0d50d763a59f6dbf18e42ec1cc21d51b.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d50d763a59f6dbf18e42ec1cc21d51b.png)'
- en: Equation 4
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 4
- en: '2\. Also apply *xáµ¢* to the input of the neural network:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. è¿˜å°† *xáµ¢* åº”ç”¨åˆ°ç¥ç»ç½‘ç»œçš„è¾“å…¥ï¼š
- en: (The neural network model comprises a single input, *x*, two hidden layers,
    and a single output, *h*, and is represented by *h(x) = nn_model(x)*.)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆç¥ç»ç½‘ç»œæ¨¡å‹åŒ…æ‹¬ä¸€ä¸ªè¾“å…¥ *x*ï¼Œä¸¤ä¸ªéšè—å±‚å’Œä¸€ä¸ªè¾“å‡º *h*ï¼Œè¡¨ç¤ºä¸º *h(x) = nn_model(x)*ã€‚ï¼‰
- en: '![](../Images/4e9d3afa34ec48afde0aaaf37d792e6a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e9d3afa34ec48afde0aaaf37d792e6a.png)'
- en: Equation 5
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 5
- en: '3\. Take the derivative of h*áµ¢* :'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. æ±‚å– *háµ¢* çš„å¯¼æ•°ï¼š
- en: '![](../Images/440d0ba5cc93ff27f319bfccece30c4a.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/440d0ba5cc93ff27f319bfccece30c4a.png)'
- en: Equation 6
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 6
- en: (Differentiation is provided in TensorFlow and PyTorch via their automatic differentiation
    function. In this article, the neural network is developed with TensorFlow [GradientTape](https://www.tensorflow.org/guide/autodiff).)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆåœ¨ TensorFlow å’Œ PyTorch ä¸­ï¼Œé€šè¿‡å…¶è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½æä¾›å¾®åˆ†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œç¥ç»ç½‘ç»œä½¿ç”¨ TensorFlow [GradientTape](https://www.tensorflow.org/guide/autodiff)
    å¼€å‘ã€‚ï¼‰
- en: '4\. Train the neural network with a loss function (loss 2 in Section 2.2) that
    forces the following relationship:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. ä½¿ç”¨æŸå¤±å‡½æ•°ï¼ˆç¬¬ 2.2 èŠ‚ä¸­çš„æŸå¤± 2ï¼‰è®­ç»ƒç¥ç»ç½‘ç»œï¼Œä»¥å¼ºåˆ¶ä»¥ä¸‹å…³ç³»ï¼š
- en: '![](../Images/c1707bbc428483113966cec2fcf1ff66.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1707bbc428483113966cec2fcf1ff66.png)'
- en: Equation 7
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 7
- en: 'Then after the neural network is trained, since *g = y*, and *s*ubstituting
    *g* and *y* from Equation 6 and Equation 4, respectively:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶ååœ¨ç¥ç»ç½‘ç»œè®­ç»ƒåï¼Œç”±äº *g = y*ï¼Œå¹¶ä¸”å°†æ–¹ç¨‹ 6 å’Œæ–¹ç¨‹ 4 ä¸­çš„ *g* å’Œ *y* ä»£å…¥ï¼š
- en: '![](../Images/befd286c620dd7aa2a595614937418da.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/befd286c620dd7aa2a595614937418da.png)'
- en: Equation 8
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 8
- en: 'Integrating both sides of Equation 8 confirms that the neural networkâ€™s output
    is the integral of the function *f(x)*:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹æ–¹ç¨‹ 8 ä¸¤è¾¹è¿›è¡Œç§¯åˆ†ï¼Œç¡®è®¤ç¥ç»ç½‘ç»œçš„è¾“å‡ºæ˜¯å‡½æ•° *f(x)* çš„ç§¯åˆ†ï¼š
- en: '![](../Images/c55fbd86a0f38112beb5b2c47d8fccf9.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c55fbd86a0f38112beb5b2c47d8fccf9.png)'
- en: Equation 9
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 9
- en: where *C* is the constant of integration.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *C* æ˜¯ç§¯åˆ†å¸¸æ•°ã€‚
- en: '**2.2 Neural network loss function**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.2 ç¥ç»ç½‘ç»œæŸå¤±å‡½æ•°**'
- en: Typically, a neural network is trained with pairs of known input and output
    data. The training input data is presented to the neural network, and the resulting
    output is compared to the training output data using a loss function. The loss
    returned by this function is used via backpropagation to adjust the networkâ€™s
    weights to reduce the loss. An integrating neural network uses a custom loss function
    to constrain the neural network to produce an output that complies with the output
    of the integrated function.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œç¥ç»ç½‘ç»œæ˜¯é€šè¿‡å·²çŸ¥è¾“å…¥å’Œè¾“å‡ºæ•°æ®å¯¹è¿›è¡Œè®­ç»ƒçš„ã€‚è®­ç»ƒè¾“å…¥æ•°æ®å‘ˆç°ç»™ç¥ç»ç½‘ç»œï¼Œç»“æœè¾“å‡ºä¸è®­ç»ƒè¾“å‡ºæ•°æ®é€šè¿‡æŸå¤±å‡½æ•°è¿›è¡Œæ¯”è¾ƒã€‚è¿™ä¸ªå‡½æ•°è¿”å›çš„æŸå¤±ç”¨äºé€šè¿‡åå‘ä¼ æ’­è°ƒæ•´ç½‘ç»œæƒé‡ï¼Œä»¥å‡å°‘æŸå¤±ã€‚æ•´åˆç¥ç»ç½‘ç»œä½¿ç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°æ¥çº¦æŸç¥ç»ç½‘ç»œäº§ç”Ÿä¸ç§¯åˆ†å‡½æ•°è¾“å‡ºä¸€è‡´çš„è¾“å‡ºã€‚
- en: The loss function for the integrating neural network, Figure 2, has three components.
    Loss 2, described in the training procedure above (Section 2.1), forces the output
    of the neural network to comply with the integral of *f(x)*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æ•´åˆç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°ï¼Œå¦‚å›¾2æ‰€ç¤ºï¼Œæœ‰ä¸‰ä¸ªç»„æˆéƒ¨åˆ†ã€‚æŸå¤±å‡½æ•°2ï¼ˆåœ¨ä¸Šæ–‡è®­ç»ƒç¨‹åºç¬¬2.1èŠ‚ä¸­æè¿°ï¼‰å¼ºåˆ¶ç¥ç»ç½‘ç»œçš„è¾“å‡ºç¬¦åˆ*f(x)*çš„ç§¯åˆ†ã€‚
- en: Loss 3 forces the neural network to comply with the initial condition *h(x_init2)
    = h_init2*. For the CDF model, this condition is *h(âˆ’10) = 0*, which sets *C =
    0* (Equation 9). For the purpose of this model, the responses of the PDF and CDF
    at *x = âˆ’10* approximate the responses at *x = âˆ’âˆ*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°3è¿«ä½¿ç¥ç»ç½‘ç»œéµå®ˆåˆå§‹æ¡ä»¶*h(x_init2) = h_init2*ã€‚å¯¹äºCDFæ¨¡å‹ï¼Œè¿™ä¸€æ¡ä»¶ä¸º*h(âˆ’10) = 0*ï¼Œè¿™è®¾ç½®äº†*C = 0*ï¼ˆæ–¹ç¨‹9ï¼‰ã€‚å¯¹äºè¯¥æ¨¡å‹ï¼Œ*x
    = âˆ’10*æ—¶PDFå’ŒCDFçš„å“åº”è¿‘ä¼¼äº*x = âˆ’âˆ*æ—¶çš„å“åº”ã€‚
- en: 'Setting the initial condition in Loss 3 to *h(âˆ’âˆ) = 0* also simplifies the
    CDF calculation. Expanding the definite integral of Equation 2:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸå¤±å‡½æ•°3ä¸­è®¾ç½®åˆå§‹æ¡ä»¶ä¸º*h(âˆ’âˆ) = 0*ï¼Œä¹Ÿç®€åŒ–äº†CDFè®¡ç®—ã€‚å±•å¼€æ–¹ç¨‹2çš„å®šç§¯åˆ†ï¼š
- en: '![](../Images/7851d45aed1c315196b1004b80825ecd.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7851d45aed1c315196b1004b80825ecd.png)'
- en: Equation 10
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹10
- en: 'The initial condition, *h(âˆ’âˆ) = 0*, means that the second term equals zero,
    and the output of the trained neural network is the value of the CDF for the corresponding
    *x* input:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åˆå§‹æ¡ä»¶*h(âˆ’âˆ) = 0*ï¼Œæ„å‘³ç€ç¬¬äºŒé¡¹ä¸ºé›¶ï¼Œè®­ç»ƒåçš„ç¥ç»ç½‘ç»œè¾“å‡ºä¸ºå¯¹åº”*x*è¾“å…¥çš„CDFå€¼ï¼š
- en: '![](../Images/93fb2602d50c605008d27656cac01573.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93fb2602d50c605008d27656cac01573.png)'
- en: Equation 11
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹11
- en: Loss 1, with condition *h(10) = 1*, stabilizes the training process for points
    near the right tail of the distribution. For the purpose of this model, the responses
    of the PDF and CDF at *x = 10* approximate the responses at
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°1ï¼Œæ¡ä»¶ä¸º*h(10) = 1*ï¼Œç¨³å®šäº†è®­ç»ƒè¿‡ç¨‹ï¼Œå°¤å…¶æ˜¯å¯¹åˆ†å¸ƒå³å°¾é™„è¿‘çš„ç‚¹ã€‚å¯¹äºè¯¥æ¨¡å‹ï¼Œ*x = 10*æ—¶PDFå’ŒCDFçš„å“åº”è¿‘ä¼¼äº
- en: x = âˆ.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: x = âˆã€‚
- en: '![](../Images/843aebca813b98102b1a60a320978e94.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/843aebca813b98102b1a60a320978e94.png)'
- en: Figure 2\. **Loss function**
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2\. **æŸå¤±å‡½æ•°**
- en: '**3\. Integrating neural network implementation**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3\. ç¥ç»ç½‘ç»œå®ç°çš„æ•´åˆ**'
- en: Following is the Python code for the integrating neural network implementation
    of the normal distribution CDF. The complete code is available [here](https://github.com/jmorrow1000/integrating-nn).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯å®ç°æ­£æ€åˆ†å¸ƒCDFçš„æ•´åˆç¥ç»ç½‘ç»œçš„Pythonä»£ç ã€‚å®Œæ•´ä»£ç å¯åœ¨[è¿™é‡Œ](https://github.com/jmorrow1000/integrating-nn)è·å–ã€‚
- en: '**3.1 Neural network model definition**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.1 ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰**'
- en: The neural network has two fully-connected hidden layers, each with 512 neurons.
    There is a single input for domain points and a single output for the corresponding
    integral values.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œæœ‰ä¸¤ä¸ªå…¨è¿æ¥çš„éšè—å±‚ï¼Œæ¯ä¸ªå±‚æœ‰512ä¸ªç¥ç»å…ƒã€‚è¾“å…¥ä¸ºåŸŸç‚¹ï¼Œè¾“å‡ºä¸ºå¯¹åº”çš„ç§¯åˆ†å€¼ã€‚
- en: Listing 1\. **TensorFlow neural network model**
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—è¡¨1\. **TensorFlowç¥ç»ç½‘ç»œæ¨¡å‹**
- en: '**3.2 Initialization**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.2 åˆå§‹åŒ–**'
- en: The *xáµ¢* training points from Section 2.1 for loss 2 are defined on line 9,
    below. The order of these points is randomly shuffled on line 11 to promote stable
    training of the neural network. On line 12 the points are applied to the PDF as
    described in Equation 4.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°2ä¸­ç¬¬2.1èŠ‚çš„*xáµ¢*è®­ç»ƒç‚¹åœ¨ä¸‹é¢çš„ç¬¬9è¡Œä¸­å®šä¹‰ã€‚è¿™äº›ç‚¹çš„é¡ºåºåœ¨ç¬¬11è¡Œè¢«éšæœºæ‰“ä¹±ï¼Œä»¥ä¿ƒè¿›ç¥ç»ç½‘ç»œçš„ç¨³å®šè®­ç»ƒã€‚åœ¨ç¬¬12è¡Œï¼Œè¿™äº›ç‚¹è¢«åº”ç”¨äºPDFï¼Œå¦‚æ–¹ç¨‹4æ‰€è¿°ã€‚
- en: The initial conditions for loss 1 and loss 3 are defined in lines 15-16 and
    lines 19-20, respectively.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°1å’ŒæŸå¤±å‡½æ•°3çš„åˆå§‹æ¡ä»¶åˆ†åˆ«åœ¨ç¬¬15-16è¡Œå’Œç¬¬19-20è¡Œä¸­å®šä¹‰ã€‚
- en: Listing 2\. **Initialization**
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—è¡¨2\. **åˆå§‹åŒ–**
- en: '**3.3 Batch training step**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.3 æ‰¹é‡è®­ç»ƒæ­¥éª¤**'
- en: Listing 3 is the training step function applied to each batch of training points.
    The total loss (the sum of loss 1, loss 2, and loss 3) in line 24 is used to update
    the neural networkâ€™s weights via gradient descent (lines 26 -30). Each training
    epoch includes multiple batches, which collectively use all the training points
    in model updates.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—è¡¨ 3 æ˜¯åº”ç”¨äºæ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡çš„è®­ç»ƒæ­¥éª¤å‡½æ•°ã€‚æ€»æŸå¤±ï¼ˆæŸå¤± 1ã€æŸå¤± 2 å’ŒæŸå¤± 3 çš„æ€»å’Œï¼‰åœ¨ç¬¬ 24 è¡Œç”¨äºé€šè¿‡æ¢¯åº¦ä¸‹é™æ›´æ–°ç¥ç»ç½‘ç»œçš„æƒé‡ï¼ˆç¬¬ 26
    - 30 è¡Œï¼‰ã€‚æ¯ä¸ªè®­ç»ƒå‘¨æœŸåŒ…æ‹¬å¤šä¸ªæ‰¹æ¬¡ï¼Œè¿™äº›æ‰¹æ¬¡å…±åŒä½¿ç”¨æ‰€æœ‰è®­ç»ƒç‚¹è¿›è¡Œæ¨¡å‹æ›´æ–°ã€‚
- en: Line 9 produces the neural networkâ€™s response to the *x_init* initial condition.
    The response is compared to the corresponding initial condition, *h_init*, producing
    loss 1 (line 10).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ 9 è¡Œç”Ÿæˆç½‘ç»œå¯¹ *x_init* åˆå§‹æ¡ä»¶çš„å“åº”ã€‚è¯¥å“åº”ä¸ç›¸åº”çš„åˆå§‹æ¡ä»¶ *h_init* è¿›è¡Œæ¯”è¾ƒï¼Œäº§ç”ŸæŸå¤± 1ï¼ˆç¬¬ 10 è¡Œï¼‰ã€‚
- en: Similarly, Line 13 produces the networkâ€™s response to the *x_init2* initial
    condition. The response is compared to the corresponding initial condition, *h_init2*,
    producing loss 3 (line 14).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·åœ°ï¼Œç¬¬ 13 è¡Œç”Ÿæˆç½‘ç»œå¯¹ *x_init2* åˆå§‹æ¡ä»¶çš„å“åº”ã€‚è¯¥å“åº”ä¸ç›¸åº”çš„åˆå§‹æ¡ä»¶ *h_init2* è¿›è¡Œæ¯”è¾ƒï¼Œäº§ç”ŸæŸå¤± 3ï¼ˆç¬¬ 14 è¡Œï¼‰ã€‚
- en: Line 17 produces the networkâ€™s response to training point *xáµ¢* (Equation 5).
    Line 18 extracts the gradient of the response (Equation 6), and lines 19â€“20 compare
    the gradient to *f(xáµ¢)* (Equation 7), producing loss 2.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ 17 è¡Œç”Ÿæˆç½‘ç»œå¯¹è®­ç»ƒç‚¹ *xáµ¢*ï¼ˆæ–¹ç¨‹ 5ï¼‰çš„å“åº”ã€‚ç¬¬ 18 è¡Œæå–å“åº”çš„æ¢¯åº¦ï¼ˆæ–¹ç¨‹ 6ï¼‰ï¼Œç¬¬ 19 - 20 è¡Œå°†æ¢¯åº¦ä¸ *f(xáµ¢)*ï¼ˆæ–¹ç¨‹
    7ï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œäº§ç”ŸæŸå¤± 2ã€‚
- en: Listing 3\. **Batch training step**
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—è¡¨ 3\. **æ‰¹é‡è®­ç»ƒæ­¥éª¤**
- en: 4\. Results
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. ç»“æœ
- en: Figure 3 shows the CDF response (red trace) from the output of the trained neural
    network. As verification of the accuracy of the results, the CDF response from
    the *norm.cdf* function in the Python [SciPy](https://scipy.org) library is included
    (green dots).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3 å±•ç¤ºäº†è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œè¾“å‡ºçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰å“åº”ï¼ˆçº¢è‰²è½¨è¿¹ï¼‰ã€‚ä¸ºäº†éªŒè¯ç»“æœçš„å‡†ç¡®æ€§ï¼ŒåŒ…å«äº† Python [SciPy](https://scipy.org)
    åº“ä¸­ *norm.cdf* å‡½æ•°çš„CDFå“åº”ï¼ˆç»¿è‰²ç‚¹ï¼‰ã€‚
- en: '![](../Images/9168084258ef4ca60bc87b5f9ac90b84.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9168084258ef4ca60bc87b5f9ac90b84.png)'
- en: Figure 3\. **Trained CDF neural network output**
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3\. **è®­ç»ƒåçš„CDFç¥ç»ç½‘ç»œè¾“å‡º**
- en: Figure 4 is the loss from the total loss function v.s. epoch logged during the
    training process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ 4 æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­è®°å½•çš„æ€»æŸå¤±å‡½æ•°éš epoch çš„å˜åŒ–ã€‚ '
- en: '![](../Images/6ef33914bc3c560f3192416eff377c17.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ef33914bc3c560f3192416eff377c17.png)'
- en: Figure 4\. **Training loss**
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4\. **è®­ç»ƒæŸå¤±**
- en: 5\. Conclusion
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. ç»“è®º
- en: This article demonstrates a method for training a neural network to integrate
    a function by using a custom loss function and automatic differentiation. Specifically,
    a neural network is trained to successfully integrate the PDF of the normal distribution
    to produce the CDF.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡å±•ç¤ºäº†ä¸€ç§ä½¿ç”¨è‡ªå®šä¹‰æŸå¤±å‡½æ•°å’Œè‡ªåŠ¨å¾®åˆ†è®­ç»ƒç¥ç»ç½‘ç»œç§¯åˆ†å‡½æ•°çš„æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œè®­ç»ƒç¥ç»ç½‘ç»œæˆåŠŸåœ°ç§¯åˆ†æ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰ä»¥ç”Ÿæˆç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰ã€‚
- en: An upcoming article will present a method for training a neural network to invert
    a function. The inverting network will be used to invert the output of the CDF-trained
    network from this article, then produce samples from the normal distribution.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å³å°†å‘è¡¨çš„ä¸€ç¯‡æ–‡ç« å°†ä»‹ç»ä¸€ç§è®­ç»ƒç¥ç»ç½‘ç»œåè½¬å‡½æ•°çš„æ–¹æ³•ã€‚åè½¬ç½‘ç»œå°†ç”¨äºåè½¬æœ¬æ–‡ä¸­è®­ç»ƒçš„CDFç½‘ç»œçš„è¾“å‡ºï¼Œç„¶åä»æ­£æ€åˆ†å¸ƒç”Ÿæˆæ ·æœ¬ã€‚
- en: '**A pdf of this article is available for download** [**here**](https://github.com/jmorrow1000/integrating-nn)**.**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ¬æ–‡çš„ pdf å¯åœ¨æ­¤å¤„ [**ä¸‹è½½**](https://github.com/jmorrow1000/integrating-nn)**ã€‚**'
- en: '*All images, unless otherwise noted, are by the author.*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…æä¾›ã€‚*'
