- en: ETL testing — How to test your data pipelines the right way
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ETL 测试 — 如何正确测试你的数据管道
- en: 原文：[https://towardsdatascience.com/forget-about-the-new-data-trends-in-2023-d2756add3317?source=collection_archive---------0-----------------------#2023-01-06](https://towardsdatascience.com/forget-about-the-new-data-trends-in-2023-d2756add3317?source=collection_archive---------0-----------------------#2023-01-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/forget-about-the-new-data-trends-in-2023-d2756add3317?source=collection_archive---------0-----------------------#2023-01-06](https://towardsdatascience.com/forget-about-the-new-data-trends-in-2023-d2756add3317?source=collection_archive---------0-----------------------#2023-01-06)
- en: Forget about the new data trends in 2023! This fundamental data engineering
    challenge is still not solved.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 忘掉 2023 年的新数据趋势吧！这个根本的数据工程挑战仍然没有解决。
- en: '[](https://vinodhini-sd.medium.com/?source=post_page-----d2756add3317--------------------------------)[![Vino
    Duraisamy](../Images/065b150b7518e0818ef37dbc423aacda.png)](https://vinodhini-sd.medium.com/?source=post_page-----d2756add3317--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d2756add3317--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d2756add3317--------------------------------)
    [Vino Duraisamy](https://vinodhini-sd.medium.com/?source=post_page-----d2756add3317--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://vinodhini-sd.medium.com/?source=post_page-----d2756add3317--------------------------------)[![Vino
    Duraisamy](../Images/065b150b7518e0818ef37dbc423aacda.png)](https://vinodhini-sd.medium.com/?source=post_page-----d2756add3317--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d2756add3317--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d2756add3317--------------------------------)
    [Vino Duraisamy](https://vinodhini-sd.medium.com/?source=post_page-----d2756add3317--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fff5dbd5e34b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforget-about-the-new-data-trends-in-2023-d2756add3317&user=Vino+Duraisamy&userId=ff5dbd5e34b8&source=post_page-ff5dbd5e34b8----d2756add3317---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d2756add3317--------------------------------)
    ·7 min read·Jan 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd2756add3317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforget-about-the-new-data-trends-in-2023-d2756add3317&user=Vino+Duraisamy&userId=ff5dbd5e34b8&source=-----d2756add3317---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fff5dbd5e34b8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforget-about-the-new-data-trends-in-2023-d2756add3317&user=Vino+Duraisamy&userId=ff5dbd5e34b8&source=post_page-ff5dbd5e34b8----d2756add3317---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d2756add3317--------------------------------)
    · 7 分钟阅读 · 2023年1月6日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2756add3317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforget-about-the-new-data-trends-in-2023-d2756add3317&source=-----d2756add3317---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd2756add3317&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforget-about-the-new-data-trends-in-2023-d2756add3317&source=-----d2756add3317---------------------bookmark_footer-----------)'
- en: It is **2023!** New data paradigms (or buzz words) like ELT, reverse ETL, EtLT,
    Data mesh, Data contracts, FinOps and modern data stack found their way into mainstream
    data conversations. Our data teams are still figuring out what is hype and what
    is not.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**2023年**！ELT、反向ETL、EtLT、数据网格、数据合同、FinOps 和现代数据栈等新数据范式（或流行词汇）已经进入主流数据对话。我们的数据团队仍在弄清楚哪些是炒作，哪些不是。'
- en: There may be 10 new paradigms tomorrow but some of the fundamental challenges
    in data engineering — like **data quality** — are still relevant and not solved
    completely (I don’t think we ever will solve this problem completely). The first
    step in improving data quality is to test changes to our data pipelines vigorously.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 明天可能会有10种新范式，但一些数据工程中的根本挑战——如**数据质量**——仍然相关且尚未完全解决（我认为我们永远无法完全解决这个问题）。提高数据质量的第一步是对我们的数据管道进行严格测试。
- en: In this article, let us review the challenges involved in testing data pipelines
    effectively and how to build a well-rounded testing strategy for your organization.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，让我们探讨在有效测试数据管道时面临的挑战以及如何为您的组织建立一个全面的测试策略。
- en: Why is achieving data quality hard?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么实现数据质量很难？
- en: In software application development world, improving the quality of software
    meant rigorous testing. Similarly in data engineering, we need a comprehensive
    testing strategy to achieve high quality data in production.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件应用开发领域，提高软件质量意味着进行严格的测试。同样，在数据工程中，我们需要一个全面的测试策略，以确保生产中的数据质量。
- en: Most data teams are running against hard deadlines. So data engineering culture
    is such that we end up building pipelines that serve data by the end of the week
    instead of incorporating all the best practices that are valuable in the long
    run.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大多数数据团队都面临紧迫的截止日期。因此，数据工程的文化使得我们最终构建的管道是在一周结束前提供数据，而不是融入长期有价值的最佳实践。
- en: In ETL testing, we compare huge volumes of data (say millions of records) often
    from different source systems. We are comparing transformed data that are a result
    of complex SQL queries or Spark jobs.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在ETL测试中，我们通常需要比较来自不同源系统的大量数据（例如数百万条记录）。我们在比较经过复杂SQL查询或Spark作业处理后的转换数据。
- en: Not all data engineers (and the data engineering leaders) are from software
    engineering background and are strong in SWE development principles and best practices.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不是所有的数据工程师（及数据工程领导者）都有软件工程背景，也不都擅长软件工程开发原则和最佳实践。
- en: Running automated suite of tests and automated deployment/release of data products
    is still not mainstream.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化测试套件和数据产品的自动化部署/发布仍未成为主流。
- en: '![](../Images/97fba55bff6a7298497dba7caed923cb.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97fba55bff6a7298497dba7caed923cb.png)'
- en: 'Source: Created by Author'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：由作者创建
- en: ETL testing is a data-centric testing process. To effectively test our pipelines
    we need production like data (in terms of volume, variety and velocity).
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ETL测试是一个以数据为中心的测试过程。为了有效地测试我们的管道，我们需要类似生产的数据（在体积、多样性和速度方面）。
- en: '![](../Images/45287cd2c724e6bbe0da82b26b116520.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45287cd2c724e6bbe0da82b26b116520.png)'
- en: 'Source: Created by Author'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：由作者创建
- en: Getting access to production like data is hard. Here is how data teams in different
    companies tackle the problem of getting the right data to test the data pipelines.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 获得类似生产的数据很困难。以下是不同公司中的数据团队如何解决获取合适数据以测试数据管道的问题。
- en: '1\. Mock Data:'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 模拟数据：
- en: '**Pros:** This approach is prevalently used by all of us data engineers because
    of ease of mock data creation and availability of synthetic data generation tools
    (such as [Faker](https://fakerjs.dev/)).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：** 这种方法被我们所有数据工程师广泛使用，因为模拟数据的创建容易，而且有合成数据生成工具（如 [Faker](https://fakerjs.dev/)）可用。'
- en: '**Cons:** Mock data does not reflect the production data in terms of volume,
    variety or velocity.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点：** 模拟数据在体积、多样性或速度方面无法反映生产数据。'
- en: '2\. Sample Prod data to Test/Dev Env:'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 从生产数据中抽样到测试/开发环境：
- en: '**Pros:** Easy to copy fraction of production data than to copy huge swathes
    of prod data.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：** 复制部分生产数据比复制大量生产数据要容易。'
- en: '**Cons:** Should use the right sampling strategy to ensure the sample reflects
    real world prod data. Tests that run successfully on sample prod data might fail
    on actual prod data because volume and variety is not guaranteed.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点：** 应使用正确的抽样策略来确保样本反映真实世界的生产数据。成功在样本生产数据上运行的测试可能在实际生产数据上失败，因为数据的体积和多样性无法保证。'
- en: '3\. Copy all of Prod data to Test Env:'
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 复制所有生产数据到测试环境：
- en: '**Pros:** Availability of real world production data for testing.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：** 提供真实世界生产数据用于测试。'
- en: '**Cons:** If prod contains PII data, it might lead to data privacy violations.
    If the prod data is constantly changing, then the copy of prod data in test/dev
    environment will become stale and needs to be constantly updated. Volume and variety
    guaranteed, but not velocity.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点：** 如果生产数据包含个人身份信息（PII），可能会导致数据隐私违规。如果生产数据不断变化，则测试/开发环境中的生产数据副本将变得陈旧，需要不断更新。体积和多样性有保证，但速度没有保证。'
- en: '4\. Copy anonymized prod data to Test Env:'
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 复制匿名化的生产数据到测试环境：
- en: '**Pros:** Availability of real world production data for testing. Compliance
    to all data privacy regulations.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点：** 提供真实世界生产数据用于测试。符合所有数据隐私法规。'
- en: '**Cons:** Again, a constantly changing prod data means the data in test env
    becomes stale and needs to be refreshed often. PII anonymization needs to be run
    every time you copy data out of prod. Manually running anonymization steps every
    time and maintaining a long-running test data environment is error-prone and resource
    intensive.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点**：再次强调，生产数据的持续变化意味着测试环境中的数据变得过时，并需要频繁刷新。每次从生产环境中复制数据时都需要进行PII匿名化。每次手动执行匿名化步骤并维护长期运行的测试数据环境容易出错且资源消耗大。'
- en: '5\. Using a data versioning tool to mirror prod data to Dev/Test Env:'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 使用数据版本控制工具将生产数据镜像到开发/测试环境：
- en: '**Pros**: Availability of real world production data. Automated short-lived
    test environments that are available through git-like API.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**优点**：可用的真实生产数据。通过类似Git的API提供的自动化短期测试环境。'
- en: '**Cons**: Add a new tool (such as [lakeFS](http://lakefs.io)) to your existing
    data stack.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺点**：将一个新工具（如[lakeFS](http://lakefs.io)）添加到现有的数据堆栈中。'
- en: 'Note: If you’re interested in exploring data versioning tools for ETL testing,
    here is a [quick guide](https://lakefs.io/blog/etl-testing/) to using lakeFS for
    your reference.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你对ETL测试中的数据版本控制工具感兴趣，这里有一个[快速指南](https://lakefs.io/blog/etl-testing/)，供你参考。
- en: 'Video tutorial on how to use lakeFS to create different data environments for
    ETL testing. Source: Created by Author.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用lakeFS创建不同数据环境以进行ETL测试的视频教程。来源：作者创建。
- en: Alright, suppose if you have the right data. What next?
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 好了，假设你拥有正确的数据。接下来呢？
- en: A comprehensive list of tests need to be run to ensure the quality and reliability
    of data in the lake house or a ware house.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要运行一系列全面的测试，以确保数据湖或数据仓库中数据的质量和可靠性。
- en: You could run them using a data quality testing tool (such as Great Expectations,
    soda.io, etc.,) or build an in-house test suite. Doesn’t matter!
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用数据质量测试工具（如Great Expectations、soda.io等）进行这些测试，也可以构建一个内部测试套件。无论如何！
- en: Depending on the project, data set and business, different type of tests need
    to be executed. However, here is a checklist of basic tests put together by [Irene](https://www.linkedin.com/in/irene-mikhailouskaya-makaranka-957a7388/)
    on different dimensions of data quality.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据项目、数据集和业务的不同，需要执行不同类型的测试。然而，这里有一个由[Irene](https://www.linkedin.com/in/irene-mikhailouskaya-makaranka-957a7388/)整理的不同数据质量维度的基本测试检查表。
- en: '![](../Images/0b08da2ddc5d205ff1eaee90771cdf6e.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b08da2ddc5d205ff1eaee90771cdf6e.png)'
- en: 'Source: [https://www.scnsoft.com/blog/guide-to-data-quality-management](https://www.scnsoft.com/blog/guide-to-data-quality-management)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://www.scnsoft.com/blog/guide-to-data-quality-management](https://www.scnsoft.com/blog/guide-to-data-quality-management)
- en: '1\. Consistency:'
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 一致性：
- en: Expanding on the above cheatsheet, consistency checks should include comparing
    the source and target systems. In **some** industries, inconsistent data is permissible
    (YES!) and the variance of error should be below the specified threshold. Because
    there might be inconsistencies between different data systems if they are updated
    asynchronously (thanks to micro-services and message queues).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述备忘单的基础上，一致性检查应包括比较源系统和目标系统。在**某些**行业中，不一致的数据是允许的（是的！），并且误差的变化应低于指定阈值。因为不同的数据系统之间可能存在不一致，如果它们是异步更新的（得益于微服务和消息队列）。
- en: For example, when you compare number of customer orders in the last hour between
    source and target, the result may vary. But when you run aggregate tests (i.e.,
    number of orders over a month), the data will converge.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当你比较源和目标中最后一小时的客户订单数量时，结果可能会有所不同。但当你运行汇总测试（即一个月的订单数量）时，数据将会趋于一致。
- en: '2\. Accuracy:'
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 准确性：
- en: Your checks should include data validation and domain value checks. For example,
    ***DOB*** column cannot have a value older than 200 years.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你的检查应包括数据验证和领域值检查。例如，***出生日期***列不能有超过200年的值。
- en: Depending on your domain, data should be in a specific range. Some business
    KPIs cannot have specific values. For example, a column named ***click-through
    ratio*** cannot have values greater than 1.0 and so on.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的领域，数据应在特定范围内。一些业务KPI不能有特定值。例如，一个名为***点击率***的列不能有大于1.0的值，等等。
- en: '3\. Completeness:'
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 完整性：
- en: It should have checks like record count, column count, percentage of missing
    values per column, percentage of null values, range checks (min_value, max_value)
    and basic statistics such as mean, median, variance and data distribution (frequency
    of values in a specific column) and so on.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 应包括记录数、列数、每列缺失值的百分比、空值的百分比、范围检查（min_value、max_value）以及基本统计数据，如均值、中位数、方差和数据分布（特定列中值的频率）等检查。
- en: Again, depending on the business domain, you can have a threshold for error.
    In pharma and finance, the data teams strive for 100% data validation with 0%
    variance in error due to compliance requirements.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，根据业务领域的不同，你可以设定一个错误的阈值。在制药和金融领域，由于合规要求，数据团队力求100%的数据验证和0%的错误差异。
- en: '4\. Data Auditability:'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 数据可审计性：
- en: Comparing the audit logs of source and data systems and making sure each transformation
    or data movement step is captured and matches.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 比较源系统和数据系统的审计日志，确保每个转换或数据移动步骤都被捕捉并匹配。
- en: Data lineage tools support data audits.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据血统工具支持数据审计。
- en: '5\. Orderliness:'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 有序性：
- en: This involves tests around data and column format checks. Data types of columns,
    % of missing columns, % of columns with mismatched names, % of columns with mismatched
    data format (Date in one source maybe in *MMDDYYYY* format and in *DDMMYYYY* format
    in another source).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到对数据和列格式检查的测试。列的数据类型、缺失列的百分比、列名不匹配的百分比、数据格式不匹配的百分比（一个来源中的日期可能是*MMDDYYYY*格式，而另一个来源中的日期可能是*DDMMYYYY*格式）。
- en: '6\. Uniqueness:'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 唯一性：
- en: As the name implies, check which columns should have unique values, % of duplicate
    entries and so on.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如名称所示，检查哪些列应具有唯一值、重复条目的百分比等。
- en: '7\. Timeliness:'
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. 及时性：
- en: Late arriving data is a common challenge that we face. This happens if the data
    point generated at the source system arrives at the landing zone after a delay.
    For example, yesterday’s data might land in today’s date partition and get processed
    with today’s data points. This leads to unexpected data errors.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟到达的数据是我们面临的一个常见挑战。这种情况发生在源系统生成的数据点在延迟后到达目标区域。例如，昨天的数据可能会进入今天的日期分区，并与今天的数据点一起处理。这会导致意外的数据错误。
- en: So, validating the ***created_timestamp*** column in the data with the ***date_partition***
    is crucial too.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，验证数据中的***created_timestamp***列与***date_partition***的一致性也非常关键。
- en: '1\. White box testing:'
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 白盒测试：
- en: The above seven types of tests fall under white box testing. One other type
    would be **unit testing** the complex data transformations. This is to assert
    the KPI definitions and other transformations are as expected.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 上述七种测试类型属于白盒测试。另一种类型是对复杂数据转换进行**单元测试**。这是为了验证KPI定义和其他转换是否符合预期。
- en: '2\. Black box testing:'
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 黑盒测试：
- en: A data pipeline has many moving parts — starting with multiple data sources,
    complex data transformations and concurrent data consumers downstream. So it is
    not sufficient to test only the transformations. End to end testing of ETL pipelines
    is needed to make sure the pipelines are working as expected.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 数据管道包含许多动态部分——从多个数据源、复杂的数据转换到下游的并发数据消费者。因此，仅测试转换是不够的。需要对ETL管道进行端到端测试，以确保管道按预期工作。
- en: '3\. Regression testing:'
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 回归测试：
- en: Suppose if there was a change in one part of the pipeline, it is mandatory to
    ensure there are no regression errors in other parts of the pipeline due to this
    change.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 假设管道的某一部分发生了变化，必须确保其他部分由于这次变化没有出现回归错误。
- en: This is where automated ETL testing is important. That is, after every change,
    a suite of tests (sometimes also called continuous integration tests) need to
    be run. Only if the test suite runs successfully, the change can be pushed to
    production.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是自动化ETL测试重要的地方。也就是说，在每次更改后，需要运行一套测试（有时也称为持续集成测试）。只有当测试套件成功运行时，才能将更改推送到生产环境中。
- en: You can use a tool like [lakeFS to run automated tests and achieve CI/CD for
    your data lake](https://docs.lakefs.io/use_cases/cicd_for_data.html).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用像[lakeFS这样的工具来运行自动化测试，并实现数据湖的CI/CD](https://docs.lakefs.io/use_cases/cicd_for_data.html)。
- en: '[](https://docs.lakefs.io/use_cases/cicd_for_data.html?source=post_page-----d2756add3317--------------------------------)
    [## CI/CD for data lakes'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://docs.lakefs.io/use_cases/cicd_for_data.html?source=post_page-----d2756add3317--------------------------------)
    [## 数据湖的CI/CD'
- en: Data pipelines feed processed data from data lakes to downstream consumers like
    business dashboards and machine…
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据管道将处理后的数据从数据湖传送到下游的消费者，如业务仪表盘和机器…
- en: docs.lakefs.io](https://docs.lakefs.io/use_cases/cicd_for_data.html?source=post_page-----d2756add3317--------------------------------)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[docs.lakefs.io](https://docs.lakefs.io/use_cases/cicd_for_data.html?source=post_page-----d2756add3317--------------------------------)'
- en: '4\. Performance Testing:'
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 性能测试：
- en: In addition to ensuring the quality of data, load testing of ETL pipelines is
    necessary to improve the reliability of data product release.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 除了确保数据质量外，对ETL管道进行负载测试也是提高数据产品发布可靠性所必需的。
- en: So, analyze ETL task run times and the order of execution of the tasks to identify
    bottlenecks. Often times, when the data volume increases, it would slow down the
    pipeline. By monitoring the run time, optimizing the distributed compute job and
    by sizing the hardware requirements, this can be resolved.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，分析ETL任务的运行时间和任务的执行顺序，以识别瓶颈。通常，当数据量增加时，会导致管道变慢。通过监控运行时间、优化分布式计算作业和调整硬件需求，可以解决这个问题。
- en: These are the comprehensive checklist of tests one needs to run. However, most
    of us run a few of them at work. If you are a data engineer, **what is your team’s
    ETL testing strategy like?**
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是需要运行的全面测试清单。然而，我们中的大多数人在工作中只运行其中的一些。如果你是数据工程师，**你们团队的ETL测试策略是怎样的？**
- en: Thanks for Reading!
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you like my work and want to support me…
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢我的工作并想支持我…
- en: The BEST way to support me is by following me on [Medium](https://medium.com/@vinodhini-sd).
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 支持我的**最佳**方式是关注我在[Medium](https://medium.com/@vinodhini-sd)上的账号。
- en: For data engineering best practices, and Python tips for beginners, follow me
    on [LinkedIn](https://www.linkedin.com/in/vinodhini-sd/).
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有关数据工程最佳实践和Python初学者的技巧，请在[LinkedIn](https://www.linkedin.com/in/vinodhini-sd/)上关注我。
- en: Feel free to give claps so I know how helpful this post was for you.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请随意点赞，以便我知道这篇文章对你有多大帮助。
