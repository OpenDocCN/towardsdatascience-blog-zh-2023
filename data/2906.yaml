- en: Balancing Innovation With Safety & Privacy in the Era of Large Language Models
    (LLM)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在大语言模型（LLM）时代平衡创新与安全性和隐私
- en: 原文：[https://towardsdatascience.com/balancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a?source=collection_archive---------2-----------------------#2023-09-20](https://towardsdatascience.com/balancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a?source=collection_archive---------2-----------------------#2023-09-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/balancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a?source=collection_archive---------2-----------------------#2023-09-20](https://towardsdatascience.com/balancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a?source=collection_archive---------2-----------------------#2023-09-20)
- en: A Guide to Implement Safety, and Privacy Mechanisms for your Generative AI applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于为你的生成式 AI 应用实施安全性和隐私机制的指南
- en: '[](https://medium.com/@anjanava.biswas?source=post_page-----a63570e4a24a--------------------------------)[![Anjan
    Biswas](../Images/d8ba1231ad138fdc44a95ce12adeb1e2.png)](https://medium.com/@anjanava.biswas?source=post_page-----a63570e4a24a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a63570e4a24a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a63570e4a24a--------------------------------)
    [Anjan Biswas](https://medium.com/@anjanava.biswas?source=post_page-----a63570e4a24a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anjanava.biswas?source=post_page-----a63570e4a24a--------------------------------)[![Anjan
    Biswas](../Images/d8ba1231ad138fdc44a95ce12adeb1e2.png)](https://medium.com/@anjanava.biswas?source=post_page-----a63570e4a24a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a63570e4a24a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a63570e4a24a--------------------------------)
    [Anjan Biswas](https://medium.com/@anjanava.biswas?source=post_page-----a63570e4a24a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbbc0b48552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbalancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a&user=Anjan+Biswas&userId=dbbc0b48552b&source=post_page-dbbc0b48552b----a63570e4a24a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a63570e4a24a--------------------------------)
    ·12 min read·Sep 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa63570e4a24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbalancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a&user=Anjan+Biswas&userId=dbbc0b48552b&source=-----a63570e4a24a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbbc0b48552b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbalancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a&user=Anjan+Biswas&userId=dbbc0b48552b&source=post_page-dbbc0b48552b----a63570e4a24a---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----a63570e4a24a--------------------------------)
    ·12分钟阅读·2023年9月20日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa63570e4a24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbalancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a&user=Anjan+Biswas&userId=dbbc0b48552b&source=-----a63570e4a24a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa63570e4a24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbalancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a&source=-----a63570e4a24a---------------------bookmark_footer-----------)![](../Images/a667a614c9ee7df2114edacede095dca.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa63570e4a24a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbalancing-innovation-with-safety-privacy-in-the-era-of-large-language-models-llm-a63570e4a24a&source=-----a63570e4a24a---------------------bookmark_footer-----------)![](../Images/a667a614c9ee7df2114edacede095dca.png)'
- en: Photo by [Jason Dent](https://unsplash.com/@jdent?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Jason Dent](https://unsplash.com/@jdent?utm_source=medium&utm_medium=referral)提供，拍摄于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: The AI era has ushered in Large Language Models (aka LLMs) to the technological
    forefront, which has been much of the talk in 2023, and is likely to remain as
    such for many years to come. LLMs are the AI models that are the power house behind
    things like [ChatGPT](https://chat.openai.com/). These AI models, fueled by vast
    amounts of data and computational prowess, have unlocked remarkable capabilities,
    from human-like text generating to assisting with natural language understanding
    (NLU) tasks. They have quickly become the foundation upon which countless applications
    and software services are being built, or at least being augmented with.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: AI时代已将大语言模型（LLMs）推向技术前沿，这在2023年引起了广泛关注，并可能在未来许多年内继续受到关注。LLMs是像[ChatGPT](https://chat.openai.com/)这样的AI模型背后的强大引擎。这些AI模型通过大量的数据和计算能力，实现了从生成类人文本到协助自然语言理解（NLU）任务的卓越能力。它们迅速成为了无数应用程序和软件服务的基础，或至少被用来增强这些服务。
- en: However, as with any groundbreaking innovations, the rise of LLMs brings forth
    a critical question — *“How do we balance this pursuit of technological advancement
    with the imperative of safety and privacy?”.* This is not a mere philosophical
    question, but a challenge that requires proactive and thoughtful action.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如任何突破性创新一样，LLMs的兴起带来了一个关键问题——*“我们如何在追求技术进步的同时平衡安全和隐私的迫切需要？”* 这不仅仅是一个哲学性问题，而是一个需要积极且深思熟虑的行动的挑战。
- en: Safety and privacy
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全和隐私
- en: To prioritize safety and privacy in our LLM powered applications, we’ll be honing
    in on key areas, including controlling the spread of personal data ([personally
    identifiable information](https://www.dol.gov/general/ppii), a.k.a. PII) and harmful
    or toxic content. This is essential whether you’re fine-tuning an LLM with your
    own dataset or simply using an LLM for text generation tasks. *Why does this matter?*
    There are a few reasons as to why it could be important.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们基于LLM的应用程序中优先考虑安全和隐私，我们将重点关注关键领域，包括控制个人数据（[个人身份信息](https://www.dol.gov/general/ppii)，即PII）和有害或有毒内容的传播。无论是用自己的数据集对LLM进行微调，还是仅仅用于文本生成任务，这一点都是至关重要的。*为什么这很重要？*
    有几个原因说明了它的重要性。
- en: Compliance with government regulations that mandates protection of user personal
    information (such as [GDPR](https://gdpr-info.eu/), [CCPA](https://oag.ca.gov/privacy/ccpa),
    [HIPAA Privacy Rule](https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html)
    etc.)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵守政府法规，保护用户个人信息（如[GDPR](https://gdpr-info.eu/)、[CCPA](https://oag.ca.gov/privacy/ccpa)、[HIPAA隐私规则](https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html)等）
- en: Compliance with LLM provider End-User License Agreement (EULA) or Acceptable
    Use Policy (AUP)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵守LLM提供商的最终用户许可协议（EULA）或可接受使用政策（AUP）
- en: Comply with InfoSec policies set within organizations
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵守组织内设定的InfoSec政策
- en: Mitigate possibility of bias and skew in your model; post fine tuning
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少模型中可能存在的偏差和偏颇；进行后期微调
- en: Ensure the ethical use of LLMs and preserve brand reputation
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保道德使用大语言模型（LLMs）并维护品牌声誉
- en: Be prepared for any [AI regulation](https://www.barrons.com/articles/washington-ai-regulation-meetings-senate-33e8c1a5)
    that may be in the horizon
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为任何可能出现的[AI法规](https://www.barrons.com/articles/washington-ai-regulation-meetings-senate-33e8c1a5)做好准备
- en: Considerations for fine tuning
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微调的考虑因素
- en: When preparing for fine-tuning an LLM, the first step is data preparation. Outside
    of research, education, or personal projects, it is likely that you will run into
    situations where your training data may contain PII information. The first step
    here is to identify the existence of these PII entities in the data, and the second
    step is to scrub the data to ensure that these PII entities are anonymized properly.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备对LLM进行微调时，第一步是数据准备。在研究、教育或个人项目之外，您很可能会遇到训练数据中包含PII（个人身份信息）信息的情况。第一步是识别数据中是否存在这些PII实体，第二步是清理数据以确保这些PII实体被妥善匿名化。
- en: '![](../Images/6e37eaa775478d72974668177f2337e8.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e37eaa775478d72974668177f2337e8.png)'
- en: LLM fine tuning
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: LLM微调
- en: Considerations for text generation
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本生成的考虑因素
- en: For text generation using LLMs, there are a couple if things to keep in mind.
    First, we ensure that any prompt containing toxic content are restricted from
    propagating to the LLM, and second we ensure that our prompt is free of any PII
    entities. Consecutively, in some cases, it may be appropriate to run these validations
    **on the text generated by the LLM**, or on the “*machine generated text”.* This
    gives a dual layer of protection in ensuring our ethos of safety and privacy.
    A third aspect is of determining the *intent* of the prompt itself which may,
    to some extent, curtail things like [*prompt injection*](https://arxiv.org/pdf/2306.05499.pdf)attacks*.*
    However, I will primarily focus on PII and toxicity in this article and discuss
    *intent* classification and it’s effect on LLMs in a separate discussion.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用LLMs进行文本生成，需要注意几点。首先，我们确保任何包含有毒内容的提示不会传播到LLM中，其次我们确保提示中不包含任何PII实体。接下来，在某些情况下，可能适合对**由LLM生成的文本**进行这些验证，或者对“*机器生成的文本*”进行验证。这提供了双重保护，以确保我们的安全和隐私原则。第三个方面是确定提示本身的*意图*，这在一定程度上可以遏制诸如[*提示注入攻击*](https://arxiv.org/pdf/2306.05499.pdf)等攻击。然而，我将主要关注PII和毒性问题，并在另一个讨论中讨论*意图*分类及其对LLMs的影响。
- en: '![](../Images/f5438261e7c25eff870f22c2a90bc311.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f5438261e7c25eff870f22c2a90bc311.png)'
- en: Text generation with LLM
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM进行文本生成
- en: Implementation
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现
- en: We will take a two step approach in order to implement a solution for this.
    First, we make use of a **name entity recognition (NER)** model that can identify
    PII entities in the text and allows us to anonymize the entities. PII entities
    usually includes things like person name, location or address, phone number, credit
    card number, SSN and so on. Second, we use a **text classification** model to
    classify if a text is `toxic` or `neutral`. Examples of toxic text typically are
    text that contain abuse, obscenities, harassment, bullying and so forth.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采取两步法来实现这一解决方案。首先，我们使用**命名实体识别（NER）**模型，该模型能够识别文本中的PII实体，并允许我们对这些实体进行匿名化。PII实体通常包括个人姓名、地点或地址、电话号码、信用卡号码、社会安全号码等。其次，我们使用**文本分类**模型来分类文本是`toxic`（有毒）还是`neutral`（中立）。有毒文本的例子通常包括包含辱骂、粗言秽语、骚扰、欺凌等内容的文本。
- en: For the PII NER model, a most common choice would be a [BERT Base model](https://huggingface.co/bert-base-uncased)
    that can be fine tuned to detect specific PII entities. You can also fine tune
    pre-trained [transformer](https://huggingface.co/docs/transformers/index) models
    such as the [Robust DeID](https://huggingface.co/obi/deid_roberta_i2b2) (de-identification)
    pre-trained model which is a [RoBERTa](https://arxiv.org/pdf/1907.11692.pdf) model
    fine-tuned for de-identification of medical notes and mostly focuses on personal
    health information (a.k.a PHI). A much simpler option to begin experimenting would
    be using [spaCy ER (EntityRecognizer)](https://spacy.io/api/entityrecognizer).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PII NER模型，一个最常见的选择是[BERT Base模型](https://huggingface.co/bert-base-uncased)，它可以进行微调以检测特定的PII实体。你也可以对预训练的[transformer](https://huggingface.co/docs/transformers/index)模型进行微调，例如[Robust
    DeID](https://huggingface.co/obi/deid_roberta_i2b2)（去标识化）预训练模型，它是一个[RoBERTa](https://arxiv.org/pdf/1907.11692.pdf)模型，针对医疗笔记的去标识化进行了微调，主要关注个人健康信息（即PHI）。一个更简单的选项是使用[spaCy
    ER（EntityRecognizer）](https://spacy.io/api/entityrecognizer)开始实验。
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: which gives us
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了
- en: '![](../Images/d79f386de85671b87d776398390aa039.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d79f386de85671b87d776398390aa039.png)'
- en: Annotation of PII entities detected by spaCy
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy检测到的PII实体的标注
- en: spaCy `EntityRecognizer` was able to identify three entities — `PERSON` (People,
    including fictional characters), `FAC` (Location or address), and `CARDINAL` (Numerals
    that do not fall under another type). spaCy also gives us the start and end offset
    (character position in the text) of the detected entity which we can use to perform
    anonymization.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy的`EntityRecognizer`能够识别三个实体——`PERSON`（人名，包括虚构人物）、`FAC`（地点或地址）和`CARDINAL`（不属于其他类型的数字）。spaCy还提供了检测到的实体的开始和结束偏移量（文本中的字符位置），我们可以利用这些信息进行匿名化。
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: which gives us
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: But there are a few obvious issues here. spaCy ER’s default entity list is not
    exhaustive to cover for all types of PII entities. For example, in our case we
    would like to detect `555-123-1290` as a `PHONE_NUMBER` as opposed to just part
    of the text as `CARDINAL` leading to incomplete entity detection. Of-course, just
    like the transformer based NER models, spaCy can also be trained with your own
    dataset of custom name entities in order to make it more robust. However, we will
    use **open-source** [**Presidio**](https://microsoft.github.io/presidio/) **SDK**
    which is a more purpose-built toolkit for *data protection* and *de-identification*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里有一些明显的问题。spaCy ER 的默认实体列表并不涵盖所有类型的 PII 实体。例如，在我们的案例中，我们希望将 `555-123-1290`
    识别为 `PHONE_NUMBER`，而不是将其视为文本的一部分，作为 `CARDINAL` 导致实体检测不完整。当然，就像基于转换器的 NER 模型一样，spaCy
    也可以用您自己的自定义名称实体数据集进行训练，以提高其鲁棒性。然而，我们将使用 **开源** [**Presidio**](https://microsoft.github.io/presidio/)
    **SDK**，它是一个更专门的工具包，旨在实现 *数据保护* 和 *去标识化*。
- en: PII detection and anonymization with Presidio
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Presidio 进行 PII 检测和匿名化
- en: The Presidio SDK provides a full set of PII detection capabilities, with a long
    list of [supported PII entities](https://microsoft.github.io/presidio/supported_entities/).
    Presidio primarily uses pattern matching, along with ML capabilities of spaCy
    and [Stanza](https://stanfordnlp.github.io/stanza/). However, Presidio is customizable
    and can be plugged-in to use your transformer based PII entity recognition model,
    or with even cloud based PII capabilities such as [Azure Text Analytics PII detection](https://learn.microsoft.com/en-us/azure/ai-services/language-service/personally-identifiable-information/how-to-call),
    or [Amazon Comprehend PII detection](https://docs.aws.amazon.com/comprehend/latest/dg/how-pii.html).
    It also comes with a built-in customizable anonymizer that can help scrub and
    redact PII entities from text.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Presidio SDK 提供了一整套 PII 检测功能，并支持一长串的 [支持的 PII 实体](https://microsoft.github.io/presidio/supported_entities/)。Presidio
    主要使用模式匹配，同时结合 spaCy 和 [Stanza](https://stanfordnlp.github.io/stanza/) 的 ML 功能。然而，Presidio
    是可定制的，可以插入使用基于转换器的 PII 实体识别模型，或者使用诸如 [Azure 文本分析 PII 检测](https://learn.microsoft.com/en-us/azure/ai-services/language-service/personally-identifiable-information/how-to-call)
    或 [Amazon Comprehend PII 检测](https://docs.aws.amazon.com/comprehend/latest/dg/how-pii.html)
    的云基础 PII 功能。它还配备了一个内置的可自定义匿名化工具，可以帮助清理和编辑文本中的 PII 实体。
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: which gives us
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: and
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![](../Images/f00a219f85855b7d41a62eb8927cf806.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f00a219f85855b7d41a62eb8927cf806.png)'
- en: Annotation of PII entities detected by Presidio
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Presidio 检测到的 PII 实体的注释
- en: As we’ve seen before, it’s a rather trivial task to anonymize the text since
    we have the beginning and end offsets of each of the entities within the text.
    However, we are going to make use of Presidio’s built-in `AnonymizerEngine` to
    help us with this.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所见，由于我们拥有文本中每个实体的开始和结束偏移量，因此匿名化文本是一个相对简单的任务。然而，我们将利用 Presidio 的内置 `AnonymizerEngine`
    来帮助我们完成这项任务。
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: which gives us
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This so far is great, but what if we want the anonymization to be just plain
    masking. In that case we can pass in custom configuration to the `AnonymizerEngine`
    which can perform simple masking of the PII entities. For example, we mask the
    entities with the asterisk (`*`) characters only.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这很好，但如果我们希望匿名化只是简单的掩码呢？在这种情况下，我们可以将自定义配置传递给 `AnonymizerEngine`，它可以对 PII
    实体执行简单的掩码。例如，我们只用星号（`*`）字符来掩盖实体。
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: gives us
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 给我们
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Considerations for anonymization
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 匿名化的考虑事项
- en: There are a few things to keep in mind when you decide to anonymize PII entities
    in the text.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当您决定在文本中匿名化 PII 实体时，需要注意一些事项。
- en: Presidio’s default `AnonymizerEngine` uses a pattern `<ENTITY_LABEL>` to mask
    the PII entities (like `<PHONE_NUMBER>` ). This can potentially cause issues especially
    with LLM fine-tuning. Replacing PII with entity type labels can introduce words
    that carry semantic meaning, potentially affecting the behavior of language models.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Presidio 的默认 `AnonymizerEngine` 使用模式 `<ENTITY_LABEL>` 来掩盖 PII 实体（如 `<PHONE_NUMBER>`）。这可能会引发问题，尤其是在
    LLM 微调时。用实体类型标签替换 PII 可能会引入具有语义意义的词汇，从而潜在地影响语言模型的行为。
- en: '[***Pseudonymization***](https://en.wikipedia.org/wiki/Pseudonymization)is
    a useful tool for data protection, however you should exercise caution performing
    pseudonymization on your training data. For example, replacing all `NAME` entities
    with the pseudonym `John Doe` , or replacing all `DATE` entities with `01-JAN-2000`
    in your fine-tuning data may lead to extreme bias in your fine-tuned model.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[***伪匿名化***](https://en.wikipedia.org/wiki/Pseudonymization)是一个有用的数据保护工具，但在对你的训练数据进行伪匿名化时应谨慎。例如，将所有`NAME`实体替换为伪名`John
    Doe`，或将所有`DATE`实体替换为`01-JAN-2000`，可能会导致你微调后的模型出现极端偏差。'
- en: Be aware of how your LLM reacts to certain characters or patterns in your prompt.
    Some LLMs may need a very specific way of templating prompts to get the most out
    of the model, for example Anthropic recommends using [*prompt tags*](https://docs.anthropic.com/claude/docs/constructing-a-prompt#mark-different-parts-of-the-prompt)*.*
    Being aware of this will help decide how you may want to perform anonymization.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意你的LLM对提示中的某些字符或模式的反应。有些LLM可能需要非常特定的提示模板方式才能充分发挥模型的作用，例如，Anthropic建议使用[*提示标签*](https://docs.anthropic.com/claude/docs/constructing-a-prompt#mark-different-parts-of-the-prompt)*.*
    了解这一点将有助于决定你可能想如何进行匿名化。
- en: There could be other general side effects of anonymized data on model fine-tuning
    such as *loss of context*, *semantic drift*, *model* *hallucinations* and so on.
    It is important to iterate and experiment to see what level of anonymization is
    appropriate for your needs, while minimizing it’s negative effects on the model’s
    performance.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 匿名化数据对模型微调可能会产生其他一般副作用，例如*上下文丧失*、*语义漂移*、*模型* *幻觉*等等。重要的是要进行迭代和实验，以确定适合你需求的匿名化程度，同时尽量减少对模型性能的负面影响。
- en: Toxicity detection with text classification
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过文本分类进行毒性检测
- en: In order to identify whether a text contains toxic content or not, we will use
    a binary classification approach — `0` if the text is neutral, `1` if the text
    is toxic. I decided to train a [DistilBERT base model (uncased)](https://arxiv.org/abs/1910.01108)
    which is a distilled version of a [BERT base model](https://arxiv.org/abs/1810.04805).
    For training data, I used the [Jigsaw dataset](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别文本是否包含毒性内容，我们将使用二分类方法——如果文本是中性的则为`0`，如果文本是有毒的则为`1`。我决定训练一个[DistilBERT基础模型（无大小写）](https://arxiv.org/abs/1910.01108)，这是一个[BERT基础模型](https://arxiv.org/abs/1810.04805)的精简版本。训练数据使用了[Jigsaw数据集](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification)。
- en: I won’t go into the details of how the model was trained and model metrics etc.
    however you can refer to this article on [training a DistilBERT base model](https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7)
    for text-classification tasks. You can see the model training script I wrote [here](https://github.com/annjawn/llm-safety-privacy/blob/main/toxicity.ipynb).
    The model is available in HuggingFace Hub as `[tensor-trek/distilbert-toxicity-classifier](https://huggingface.co/tensor-trek/distilbert-toxicity-classifier)`.
    Let’s run a few sample pieces of text through inference to check what the model
    tells us.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会详细介绍模型的训练过程和模型指标等，但你可以参考这篇关于[训练DistilBERT基础模型](https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7)的文章进行文本分类任务。你可以在[这里](https://github.com/annjawn/llm-safety-privacy/blob/main/toxicity.ipynb)查看我编写的模型训练脚本。该模型可以在HuggingFace
    Hub中找到，地址是`[tensor-trek/distilbert-toxicity-classifier](https://huggingface.co/tensor-trek/distilbert-toxicity-classifier)`。让我们通过推断运行一些示例文本，看看模型会告诉我们什么。
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: which gives us —
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了—
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The model is correctly classifying the text as `NEUTRAL` or `TOXIC` with pretty
    high confidence. This text classification model, in conjunction to our previously
    discussed PII entity classification can now be used to create a mechanism that
    can enforce privacy and safety within our LLM powered applications or services.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型以相当高的置信度正确地将文本分类为`NEUTRAL`或`TOXIC`。这个文本分类模型，与我们之前讨论的PII实体分类结合起来，现在可以用于创建一个机制，以在我们的LLM驱动的应用程序或服务中执行隐私和安全。
- en: Putting things together
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 综合考虑
- en: We’ve tackled *privacy* through a PII entity recognition mechanism, and we tackled
    the *safety* part with a text toxicity classifier. You can think of other mechanisms
    that may be relevant to your organization’s definition of safety & privacy. For
    example, healthcare organizations may be more concerned about PHI instead of PII
    and so forth. Ultimately, the overall implementation approach for this remains
    the same no matter what controls you want to introduce.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过 PII 实体识别机制解决了 *隐私* 问题，通过文本有毒内容分类器解决了 *安全* 部分。你可以考虑其他可能与贵组织的安全和隐私定义相关的机制。例如，医疗组织可能更关心
    PHI 而不是 PII，等等。最终，无论你想引入什么控制措施，整体实施方法保持不变。
- en: With that in mind, it is now time to put everything together into action. We
    want to be able use both the privacy and safety mechanisms in conjunction with
    an LLM for an application where we want to introduce generative AI capabilities.
    I am going to use the popular [LangChain](https://www.langchain.com/) framework’s
    [Python flavor](https://python.langchain.com/docs/get_started/introduction) (also
    available in [JavaScript/TS](https://js.langchain.com/docs/get_started/introduction/))
    to build a generative AI application which will include the two mechanisms. Here’s
    how our overall architecture looks like.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，现在是将一切付诸实践的时候了。我们希望能够将隐私和安全机制与 LLM 结合使用，以便在我们希望引入生成式 AI 功能的应用中使用。我将使用流行的
    [LangChain](https://www.langchain.com/) 框架的 [Python 版本](https://python.langchain.com/docs/get_started/introduction)（也可以在
    [JavaScript/TS](https://js.langchain.com/docs/get_started/introduction/) 中使用）来构建一个包含这两种机制的生成式
    AI 应用。这就是我们的总体架构。
- en: '![](../Images/0184314e1d57b457e6e7fa7e1113517e.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0184314e1d57b457e6e7fa7e1113517e.png)'
- en: Privacy and safety flow with LangChain
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的隐私和安全流程
- en: In the above architecture, the first thing I check is if the text contains toxic
    content with at least more than 80% of model accuracy. If so, the execution of
    the whole LangChain application stops at that point, and the user is shown an
    appropriate message. If the text is classified largely as *neutral,* then I pass
    it onto the next step of identifying PII entities. I then perform anonymization
    on those entities in the text if the confidence score of each of these entity
    detection is more than 50%. Once the text is fully anonymized, it is passed as
    a prompt to the LLM for further text generation by the model. Note that the accuracy
    thresholds (80% and 50%) are arbitrary, you would want to test the accuracy of
    both the detectors (PII & toxicity) on your data and decide on a threshold that
    works best for your use-case. *The lower the threshold, the stricter the system
    becomes, the higher the threshold the weaker the enforcement of these checks*.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述架构中，我首先检查文本是否包含有毒内容，模型准确率至少需达到 80% 以上。如果是，整个 LangChain 应用的执行会在此时停止，并向用户显示适当的消息。如果文本被大致分类为
    *中性*，则我会将其传递到下一步以识别 PII 实体。如果这些实体的检测置信度得分超过 50%，我将对文本中的这些实体进行匿名化。一旦文本完全匿名化，它将作为提示传递给
    LLM 进行模型的进一步文本生成。请注意，准确率阈值（80% 和 50%）是任意的，你需要在你的数据上测试两个检测器（PII 和有毒内容）的准确性，并决定一个适合你用例的阈值。*阈值越低，系统变得越严格；阈值越高，检查的执行力度越弱*。
- en: Another more conservative approach would be to stop the execution if any PII
    entities are detected. This could be useful for applications that are not certified
    to handle PII data at all and you want to ensure, no matter how, text containing
    PII doesn’t end up being fed into the application as an input.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种更保守的方法是如果检测到任何 PII 实体，则停止执行。这对那些完全未获得处理 PII 数据认证的应用可能很有用，你希望确保无论如何，包含 PII
    的文本不会作为输入被喂入应用。
- en: '![](../Images/b387590c1db20c3bec017720c12e683e.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b387590c1db20c3bec017720c12e683e.png)'
- en: Privacy and safety flow with LangChain — ***alternate flow***
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的隐私和安全流程——***备用流程***
- en: LangChain implementation
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain 实现
- en: In order to make it work with LangChain, I created a [custom *chain*](https://python.langchain.com/docs/modules/chains/how_to/custom_chain)called
    `PrivacyAndSafetyChain` . This can be chained with any [LangChain supported LLMs](https://python.langchain.com/docs/modules/model_io/models/llms/)
    to implement a privacy and safety mechanism. This is how it looks like —
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其与 LangChain 配合使用，我创建了一个 [自定义 *链*](https://python.langchain.com/docs/modules/chains/how_to/custom_chain)
    叫做 `PrivacyAndSafetyChain`。这个链可以与任何 [LangChain 支持的 LLMs](https://python.langchain.com/docs/modules/model_io/models/llms/)
    连接，以实现隐私和安全机制。这就是它的样子——
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: By default, `PrivacyAndSafetyChain` performs toxicity detection first. If it
    detects any toxic content then it will error out essentially stopping the chain
    as we discussed earlier. If not, then it passess the entered text to the PII entity
    recognizer and based on what masking character to use, the chain will perform
    anonymization of the text with the detected PII entities. The output of the preceding
    code is as shown below. Since there is no toxic content the chain didn’t stop,
    and it detected `PHONE_NUMBER` and `SSN` and correctly anonymized it.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`PrivacyAndSafetyChain` 首先执行毒性检测。如果检测到任何有毒内容，它将会报错，从而如前所述，停止链条。如果没有检测到，它将把输入的文本传递给
    PII 实体识别器，并根据使用的掩码字符，链条将对检测到的 PII 实体进行文本匿名化。前面的代码输出如下所示。由于没有有毒内容，链条没有停止，它检测到了
    `PHONE_NUMBER` 和 `SSN` 并正确地进行了匿名化。
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Conclusion
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The biggest takeaway in this post is that as we continue to innovate with Large
    Language Models, it becomes imperative to balance the scales of innovation with
    safety and privacy. The enthusiasm surrounding LLMs, and our ever-growing desire
    to integrate them with a whole world of possible use-cases is un-deniable. However,
    the potential pitfalls — like data privacy breaches, unintended biases, or misuse
    — are equally real and warrant our immediate attention. I covered how you can
    establish a mechanism of detecting PII and toxic content going into your LLMs
    and discussed an implementation with LangChain.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的最大收获是，随着我们继续在大型语言模型方面进行创新，平衡创新与安全和隐私变得至关重要。围绕 LLM 的热情以及我们对将其与各种可能用例整合的不断增长的渴望是不可否认的。然而，潜在的陷阱——如数据隐私泄露、无意的偏见或滥用——同样真实，值得我们立即关注。我介绍了如何建立一个检测
    PII 和有毒内容的机制，并讨论了与 LangChain 的实现。
- en: There’s still much research and development that remains to be done— perhaps
    a better architecture, more reliable and seamless way to ensure data privacy and
    safety. The code in this post is trimmed down for brevity, but I encourage you
    to checkout my [GitHub repository](https://github.com/annjawn/llm-safety-privacy/tree/main)
    where I have collated detailed Notebooks on each step along with full source code
    of the custom LangChain that we discussed. Use it, fork it, improve it, go forth
    and innovate!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然有很多研究和开发工作待完成——或许需要更好的架构、更可靠和无缝的数据隐私和安全保障方式。本文中的代码经过简化以便于说明，但我鼓励你查看我的 [GitHub
    仓库](https://github.com/annjawn/llm-safety-privacy/tree/main)，在这里我整理了每个步骤的详细笔记本以及我们讨论的自定义
    LangChain 的完整源代码。使用它、分叉它、改进它，前进并创新！
- en: References
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Jacob Devlin, Ming-Wei Chang et. al. [BERT: Pre-training of Deep Bidirectional
    Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Jacob Devlin, Ming-Wei Chang 等人 [BERT: 语言理解的深度双向变换器预训练](https://arxiv.org/abs/1810.04805)'
- en: '[2] Victor Sanh, Lysandre Debut et. al [DistilBERT, a distilled version of
    BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Victor Sanh, Lysandre Debut 等人 [DistilBERT, BERT 的蒸馏版本：更小、更快、更便宜、更轻量](https://arxiv.org/abs/1910.01108)'
- en: '[3] Dataset — [Jigsaw Multilingual Toxic Comment Classification 2020](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] 数据集 — [Jigsaw 多语言毒性评论分类 2020](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification)'
- en: '*Unless otherwise noted, all images are by the author*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均由作者提供*'
