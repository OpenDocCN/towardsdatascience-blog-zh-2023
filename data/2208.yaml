- en: Async for LangChain and LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain å’Œ LLMs çš„å¼‚æ­¥å¤„ç†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10](https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10](https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10)
- en: How to make LangChain chains work with Async calls to LLMs, speeding up the
    time it takes to run a sequential long chain
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ LangChain é“¾ä¸å¼‚æ­¥è°ƒç”¨çš„ LLMs ä¸€èµ·å·¥ä½œï¼Œä»è€ŒåŠ å¿«è¿è¡Œé¡ºåºé•¿é“¾çš„æ—¶é—´
- en: '[](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[![Gabriel
    Cassimiro](../Images/2cf8a09a706236059c46c7f0f20d4365.png)](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    [Gabriel Cassimiro](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[![Gabriel
    Cassimiro](../Images/2cf8a09a706236059c46c7f0f20d4365.png)](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    [Gabriel Cassimiro](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3692fb93d7e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=post_page-3692fb93d7e5----3818c16062ed---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    Â·6 min readÂ·Jul 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=-----3818c16062ed---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3692fb93d7e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=post_page-3692fb93d7e5----3818c16062ed---------------------post_header-----------)
    å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    Â·6åˆ†é’Ÿé˜…è¯»Â·2023å¹´7æœˆ10æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=-----3818c16062ed---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&source=-----3818c16062ed---------------------bookmark_footer-----------)![](../Images/3d661ccf3f4d03c45b31cfc182d4ecd0.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&source=-----3818c16062ed---------------------bookmark_footer-----------)![](../Images/3d661ccf3f4d03c45b31cfc182d4ecd0.png)'
- en: Image by[hp koch](https://unsplash.com/@iggii?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/pt-br/fotografias/2OuTr9_VaUg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±[hp koch](https://unsplash.com/@iggii?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)æä¾›ï¼Œ[Unsplash](https://unsplash.com/pt-br/fotografias/2OuTr9_VaUg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: In this article, I will cover how to use asynchronous calls to LLMs for long
    workflows using LangChain. We will go through an example with the full code and
    compare Sequential execution with the Async calls.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨å¼‚æ­¥è°ƒç”¨ LLMs æ¥å¤„ç†é•¿å·¥ä½œæµï¼Œä½¿ç”¨ LangChainã€‚æˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªå®Œæ•´ä»£ç çš„ç¤ºä¾‹è¿›è¡Œè®²è§£ï¼Œå¹¶æ¯”è¾ƒé¡ºåºæ‰§è¡Œä¸å¼‚æ­¥è°ƒç”¨çš„å·®å¼‚ã€‚
- en: 'Here is the overview of the content. If youâ€™d like you can jump to the section
    of your interest:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å†…å®¹æ¦‚è§ˆã€‚å¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥è·³è½¬åˆ°ä½ æ„Ÿå…´è¶£çš„éƒ¨åˆ†ï¼š
- en: 'Basics: What is LangChain'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŸºç¡€çŸ¥è¯†ï¼šä»€ä¹ˆæ˜¯ LangChain
- en: How to run a Synchronous chain with LangChain
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ç”¨ LangChain è¿è¡ŒåŒæ­¥é“¾
- en: How to run a single Asynchronous chain with LangChain
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚ä½•è¿è¡Œå•ä¸ªå¼‚æ­¥é“¾ä¸LangChain
- en: Real-world tips for long workflows with Async Chains.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é•¿å·¥ä½œæµç¨‹ä¸­çš„å®ç”¨æŠ€å·§ä¸å¼‚æ­¥é“¾ã€‚
- en: So letâ€™s start!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: 'Basics: What is Langchain'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŸºç¡€çŸ¥è¯†ï¼šä»€ä¹ˆæ˜¯LangChain
- en: LangChain is a framework for developing applications powered by language models.
    That is the official definition of LangChain. This framework was created recently
    and is already used as the industry standard for building tools powered by LLMs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LangChainæ˜¯ä¸€ä¸ªåŸºäºè¯­è¨€æ¨¡å‹å¼€å‘åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚è¿™å°±æ˜¯LangChainçš„å®˜æ–¹å®šä¹‰ã€‚è¿™ä¸ªæ¡†æ¶æ˜¯æœ€è¿‘åˆ›å»ºçš„ï¼Œå·²ç»è¢«ç”¨ä½œå»ºç«‹ç”±LLMæ”¯æŒçš„å·¥å…·çš„è¡Œä¸šæ ‡å‡†ã€‚
- en: It is open-source and well-maintained, with new features being released in a
    very fast time frame.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯å¼€æºçš„ï¼Œå¹¶ä¸”åœ¨éå¸¸å¿«çš„æ—¶é—´æ¡†æ¶å†…å‘å¸ƒæ–°åŠŸèƒ½ã€‚
- en: The official documentation can be found [here](https://python.langchain.com/docs/get_started/introduction.html)
    and the GitHub repository [here](https://github.com/hwchase17/langchain).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å®˜æ–¹æ–‡æ¡£å¯ä»¥åœ¨[è¿™é‡Œ](https://python.langchain.com/docs/get_started/introduction.html)æ‰¾åˆ°ï¼ŒGitHubå­˜å‚¨åº“å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/hwchase17/langchain)æ‰¾åˆ°ã€‚
- en: One downside that we have in this library is that since the features are new
    we cannot use Chat GPT to help effectively to build new code. So this means that
    we have to work in the â€œAncientâ€ way of reading documentation, forums, and tutorials.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™ä¸ªåº“ä¸­é‡åˆ°çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯ï¼Œç”±äºè¿™äº›åŠŸèƒ½æ˜¯æ–°çš„ï¼Œæˆ‘ä»¬ä¸èƒ½æœ‰æ•ˆåœ°ä½¿ç”¨Chat GPTæ¥å¸®åŠ©æ„å»ºæ–°çš„ä»£ç ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¿…é¡»ä»¥â€œå¤è€â€çš„æ–¹å¼é˜…è¯»æ–‡æ¡£ã€è®ºå›å’Œæ•™ç¨‹æ¥å·¥ä½œã€‚
- en: The documentation for LangChain.is really good however there are not a lot of
    examples of some specific things.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: LangChainçš„æ–‡æ¡£ç¡®å®å¾ˆå¥½ï¼Œä½†æ˜¯å…³äºæŸäº›ç‰¹å®šäº‹ç‰©çš„ä¾‹å­å¹¶ä¸å¤šã€‚
- en: I ran into this problem with Async for long chains.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨å¼‚æ­¥é•¿é“¾æ–¹é¢é‡åˆ°äº†è¿™ä¸ªé—®é¢˜ã€‚
- en: 'Here are the main resources I used to learn more about the framework:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ç”¨æ¥äº†è§£æ›´å¤šå…³äºè¿™ä¸ªæ¡†æ¶çš„ä¸»è¦èµ„æºï¼š
- en: 'Deep Learning AI course: [LangChain Chat with your data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/);'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·±åº¦å­¦ä¹ AIè¯¾ç¨‹ï¼š[LangChain Chat with your data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)ï¼›
- en: '[Official Documentation](https://python.langchain.com/docs/get_started/introduction.html);'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/get_started/introduction.html)ï¼›'
- en: '[Youtube channel](https://www.youtube.com/watch?v=_v_fgW2SkkQ&list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5).'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[YouTubeé¢‘é“](https://www.youtube.com/watch?v=_v_fgW2SkkQ&list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)ã€‚'
- en: (ps. They are all free)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆé™„æ³¨ï¼šå®ƒä»¬éƒ½æ˜¯å…è´¹çš„ï¼‰
- en: How to run a Synchronous chain with LangChain
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•è¿è¡ŒLangChainçš„åŒæ­¥é“¾
- en: 'So let me set up the problem I had: I have a data frame with a lot of rows
    and for each of those rows I need to run multiple prompts (chains) to an LLM and
    return the result to my data frame.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘è¯´æ˜æˆ‘é‡åˆ°çš„é—®é¢˜ï¼šæˆ‘æœ‰ä¸€ä¸ªåŒ…å«å¤§é‡è¡Œçš„æ•°æ®æ¡†æ¶ï¼Œå¯¹äºæ¯ä¸€è¡Œï¼Œæˆ‘éœ€è¦è¿è¡Œå¤šä¸ªæç¤ºï¼ˆé“¾ï¼‰åˆ°ä¸€ä¸ªLLMï¼Œå¹¶å°†ç»“æœè¿”å›åˆ°æˆ‘çš„æ•°æ®æ¡†æ¶ä¸­ã€‚
- en: When you have multiple rows, letâ€™s say 10K, running 3 prompts for each and each
    response (if the server is not overloaded) taking about 3â€“5 seconds you end up
    waiting for days for the workflow to be completed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ä½ æœ‰å¤šä¸ªè¡Œæ—¶ï¼Œæ¯”å¦‚1ä¸‡è¡Œï¼Œæ¯ä¸ªè¡Œè¿è¡Œ3ä¸ªæç¤ºï¼Œå¹¶ä¸”æ¯ä¸ªå“åº”ï¼ˆå¦‚æœæœåŠ¡å™¨æ²¡æœ‰è¶…è½½ï¼‰å¤§çº¦éœ€è¦3-5ç§’ï¼Œä½ æœ€ç»ˆä¼šç­‰å¾…æ•°å¤©æ‰èƒ½å®Œæˆå·¥ä½œæµç¨‹ã€‚
- en: Bellow I am going to show the main steps and code to build a synchronous chain
    and time it on a subset of data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æˆ‘å°†å±•ç¤ºä¸»è¦æ­¥éª¤å’Œæ„å»ºåŒæ­¥é“¾çš„ä»£ç ï¼Œå¹¶åœ¨æ•°æ®å­é›†ä¸Šè®¡æ—¶ã€‚
- en: For this example, I am going to use the dataset [Wine Reviews](https://www.kaggle.com/datasets/zynicide/wine-reviews),
    [license](https://creativecommons.org/licenses/by-nc-sa/4.0/). The goal here is
    to extract some information from the written reviews.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œæˆ‘å°†ä½¿ç”¨æ•°æ®é›†[Wine Reviews](https://www.kaggle.com/datasets/zynicide/wine-reviews)ï¼Œ[è®¸å¯è¯](https://creativecommons.org/licenses/by-nc-sa/4.0/)ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯ä»ä¹¦é¢è¯„è®ºä¸­æå–ä¸€äº›ä¿¡æ¯ã€‚
- en: I want to extract a Summary of the review, the main sentiment, and the top 5
    characteristics of each wine.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æƒ³æå–ä¸€ä»½è¯„è®ºæ‘˜è¦ã€ä¸»è¦æƒ…æ„Ÿä»¥åŠæ¯ç§è‘¡è„é…’çš„å‰äº”ä¸ªç‰¹å¾ã€‚
- en: For that, I created two chains, one for the summary and sentiment and another
    that takes the summary as input to extract the characteristics.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘åˆ›å»ºäº†ä¸¤ä¸ªé“¾ï¼Œä¸€ä¸ªç”¨äºæ‘˜è¦å’Œæƒ…æ„Ÿï¼Œå¦ä¸€ä¸ªä½¿ç”¨æ‘˜è¦ä½œä¸ºè¾“å…¥æ¥æå–ç‰¹å¾ã€‚
- en: 'Here is the code to run it:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯è¿è¡Œå®ƒçš„ä»£ç ï¼š
- en: 'Run time (10 examples):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œæ—¶é—´ï¼ˆ10ä¸ªç¤ºä¾‹ï¼‰ï¼š
- en: Summary Chain (Sequential) executed in 22.59 seconds.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‘˜è¦é“¾ï¼ˆé¡ºåºæ‰§è¡Œï¼‰åœ¨22.59ç§’å†…æ‰§è¡Œå®Œæ¯•ã€‚
- en: Characteristics Chain (Sequential) executed in 22.85 seconds.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç‰¹å¾é“¾ï¼ˆé¡ºåºæ‰§è¡Œï¼‰åœ¨22.85ç§’å†…æ‰§è¡Œå®Œæ¯•ã€‚
- en: If you want to understand more about the components I am using I really recommend
    watching the [Deep Learning AI Course](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³æ›´æ·±å…¥åœ°äº†è§£æˆ‘ä½¿ç”¨çš„ç»„ä»¶ï¼Œæˆ‘çœŸçš„æ¨èè§‚çœ‹[æ·±åº¦å­¦ä¹ AIè¯¾ç¨‹](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)ã€‚
- en: The main takeaways from this code are the building blocks for a chain, how to
    run it in a sequential way, and the time it took to finish this loop. It is important
    to remember that it was about 45 seconds for 10 examples and the full dataset
    contains 130K rows. So the Async implementation is the New Hope to run this in
    a reasonable time.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ®µä»£ç çš„ä¸»è¦æ”¶è·æ˜¯é“¾çš„æ„å»ºæ¨¡å—ã€å¦‚ä½•ä»¥é¡ºåºæ–¹å¼è¿è¡Œå®ƒï¼Œä»¥åŠå®Œæˆæ­¤å¾ªç¯æ‰€éœ€çš„æ—¶é—´ã€‚éœ€è¦è®°ä½çš„æ˜¯ï¼Œå¯¹äº 10 ä¸ªç¤ºä¾‹ï¼Œå¤§çº¦éœ€è¦ 45 ç§’ï¼Œè€Œå®Œæ•´çš„æ•°æ®é›†åŒ…å«
    130K è¡Œã€‚å› æ­¤ï¼Œå¼‚æ­¥å®ç°æ˜¯ä»¥åˆç†æ—¶é—´è¿è¡Œçš„â€œæ–°å¸Œæœ›â€ã€‚
- en: So with the problem set up and the baseline established, let's see how we can
    optimize this code to run much faster.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ—¢ç„¶é—®é¢˜å·²ç»è®¾ç½®å¹¶ä¸”åŸºçº¿å·²ç»ç¡®å®šï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•ä¼˜åŒ–è¿™æ®µä»£ç ä»¥ä¾¿æ›´å¿«åœ°è¿è¡Œã€‚
- en: How to run a single Asynchronous chain with LangChain
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ç”¨ LangChain è¿è¡Œå•ä¸ªå¼‚æ­¥é“¾
- en: So for this, we are going to use a resource called Asynchronous calls. To explain
    this, first I will explain briefly what the code is doing and where the time is
    taking too long.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ç§å«åšå¼‚æ­¥è°ƒç”¨çš„èµ„æºã€‚ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘å°†é¦–å…ˆç®€è¦è§£é‡Šä»£ç çš„ä½œç”¨ä»¥åŠå“ªäº›åœ°æ–¹çš„æ—¶é—´æ¶ˆè€—è¿‡é•¿ã€‚
- en: In our example, we go through each row of the data frame, extract some information
    from the rows, add them to our prompt, and call the GPT API to get a response.
    After the response, we just parse it and add it back to the data frame.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬éå†æ•°æ®æ¡†çš„æ¯ä¸€è¡Œï¼Œä»è¡Œä¸­æå–ä¸€äº›ä¿¡æ¯ï¼Œå°†å®ƒä»¬æ·»åŠ åˆ°æç¤ºä¸­ï¼Œç„¶åè°ƒç”¨ GPT API è·å–å“åº”ã€‚æ”¶åˆ°å“åº”åï¼Œæˆ‘ä»¬è§£æå®ƒå¹¶å°†å…¶é‡æ–°æ·»åŠ åˆ°æ•°æ®æ¡†ä¸­ã€‚
- en: '![](../Images/e446a0030466fef8a134fcceada0501a.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e446a0030466fef8a134fcceada0501a.png)'
- en: Image by Author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: The main bottleneck here is when we call the GPT API because our computer has
    to wait idly for the response from that API (about 3 seconds). The rest of the
    steps are fast and can still be optimized but that is not the focus of this article.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»è¦çš„ç“¶é¢ˆåœ¨äºè°ƒç”¨ GPT APIï¼Œå› ä¸ºæˆ‘ä»¬çš„è®¡ç®—æœºå¿…é¡»åœ¨ç­‰å¾…è¯¥ API å“åº”æ—¶é—²ç½®ï¼ˆå¤§çº¦ 3 ç§’ï¼‰ã€‚å…¶ä½™çš„æ­¥éª¤éƒ½å¾ˆå¿«ï¼Œå¯ä»¥ç»§ç»­ä¼˜åŒ–ï¼Œä½†è¿™ä¸æ˜¯æœ¬æ–‡çš„é‡ç‚¹ã€‚
- en: So instead of waiting Idly for the response, what if we sent all the calls to
    the API at the same time? This way we would only have to wait for a single response
    and then process them. This is called Asynchronous calls to the API.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæ—¢ç„¶ä¸éœ€è¦é—²ç­‰å“åº”ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆä¸åŒæ—¶å‘é€æ‰€æœ‰ API è¯·æ±‚å‘¢ï¼Ÿè¿™æ ·æˆ‘ä»¬åªéœ€ç­‰å¾…ä¸€ä¸ªå“åº”ï¼Œç„¶åå¤„ç†æ‰€æœ‰å“åº”ã€‚è¿™å°±æ˜¯æ‰€è°“çš„å¼‚æ­¥ API è°ƒç”¨ã€‚
- en: '![](../Images/e0b1422650d5840a248989d6ca91aedb.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0b1422650d5840a248989d6ca91aedb.png)'
- en: Image by Author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: This way we do the pre-process and post-process sequentially but the calls to
    the API do not have to wait for the last response to come back before sending
    the next one.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é¡ºåºåœ°è¿›è¡Œé¢„å¤„ç†å’Œåå¤„ç†ï¼Œä½†å¯¹ API çš„è°ƒç”¨ä¸å¿…ç­‰åˆ°ä¸Šä¸€ä¸ªå“åº”å›æ¥åå†å‘é€ä¸‹ä¸€ä¸ªè¯·æ±‚ã€‚
- en: 'So here is the code for the Async chains:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯å¼‚æ­¥é“¾çš„ä»£ç ï¼š
- en: In this code, we use the Python syntax of async and await. LangChain also gives
    us the code to run the chain async, with the arun() function. So in the beginning
    we first process each row sequentially (can be optimized) and create multiple
    â€œtasksâ€ that will await the response from the API in parallel and then we process
    the response to the final desired format sequentially (can also be optimized).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™æ®µä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Python çš„ async å’Œ await è¯­æ³•ã€‚LangChain ä¹Ÿæä¾›äº†è¿è¡Œå¼‚æ­¥é“¾çš„ä»£ç ï¼Œä½¿ç”¨ arun() å‡½æ•°ã€‚å› æ­¤ï¼Œå¼€å§‹æ—¶æˆ‘ä»¬é¦–å…ˆé¡ºåºå¤„ç†æ¯ä¸€è¡Œï¼ˆå¯ä»¥ä¼˜åŒ–ï¼‰ï¼Œå¹¶åˆ›å»ºå¤šä¸ªâ€œä»»åŠ¡â€æ¥å¹¶è¡Œç­‰å¾…
    API å“åº”ï¼Œç„¶åé¡ºåºå¤„ç†å“åº”ä»¥è¾¾åˆ°æœ€ç»ˆæ‰€éœ€æ ¼å¼ï¼ˆä¹Ÿå¯ä»¥ä¼˜åŒ–ï¼‰ã€‚
- en: 'Run time (10 examples):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œæ—¶é—´ï¼ˆ10 ä¸ªç¤ºä¾‹ï¼‰ï¼š
- en: Summary Chain (Async) executed in 3.35 seconds.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‘˜è¦é“¾ï¼ˆå¼‚æ­¥ï¼‰æ‰§è¡Œæ—¶é—´ä¸º 3.35 ç§’ã€‚
- en: Characteristics Chain (Async) executed in 2.49 seconds.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç‰¹å¾é“¾ï¼ˆå¼‚æ­¥ï¼‰æ‰§è¡Œæ—¶é—´ä¸º 2.49 ç§’ã€‚
- en: 'Compared to the sequential:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸é¡ºåºæ‰§è¡Œç›¸æ¯”ï¼š
- en: Summary Chain (Sequential) executed in 22.59 seconds.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‘˜è¦é“¾ï¼ˆé¡ºåºï¼‰æ‰§è¡Œæ—¶é—´ä¸º 22.59 ç§’ã€‚
- en: Characteristics Chain (Sequential) executed in 22.85 seconds.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç‰¹å¾é“¾ï¼ˆé¡ºåºï¼‰æ‰§è¡Œæ—¶é—´ä¸º 22.85 ç§’ã€‚
- en: We can see almost a 10x improvement in the run time. So for big workloads, I
    highly recommend using this method. Also my code is full of for loops that can
    also be optimized further to improve performance.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿è¡Œæ—¶é—´å‡ ä¹æé«˜äº† 10 å€ã€‚å› æ­¤ï¼Œå¯¹äºå¤§å‹å·¥ä½œè´Ÿè½½ï¼Œæˆ‘å¼ºçƒˆæ¨èä½¿ç”¨è¿™ç§æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘çš„ä»£ç ä¸­å……æ»¡äº†å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–çš„ for å¾ªç¯ï¼Œä»¥æå‡æ€§èƒ½ã€‚
- en: The full code to this tutorial can be found in this [Github Repo](https://github.com/gabrielcassimiro17/async-langchain).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ•™ç¨‹çš„å®Œæ•´ä»£ç å¯ä»¥åœ¨è¿™ä¸ª [Github Repo](https://github.com/gabrielcassimiro17/async-langchain)
    ä¸­æ‰¾åˆ°ã€‚
- en: Real-world tips for long workflows with Async Chains.
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å¼‚æ­¥é“¾çš„é•¿å·¥ä½œæµçš„å®é™…å»ºè®®ã€‚
- en: When I had to run this, I ran into some limitations and a few roadblocks, that
    I want to share with you.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘è¿è¡Œè¿™äº›ä»£ç æ—¶ï¼Œé‡åˆ°äº†ä¸€äº›é™åˆ¶å’Œéšœç¢ï¼Œæˆ‘æƒ³å’Œä½ ä»¬åˆ†äº«ä¸€ä¸‹ã€‚
- en: Notebooks are not Async Friendly
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬”è®°æœ¬ç”µè„‘ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ
- en: When running async calls on Jupyter Notebooks you may encounter some issues.
    However, just ask Chat GPT and it can probably help you out with that. The code
    I built is to run big workloads in a .py file, so it may need some changes to
    run in a notebook.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Jupyterç¬”è®°æœ¬ä¸­è¿è¡Œå¼‚æ­¥è°ƒç”¨æ—¶ï¼Œä½ å¯èƒ½ä¼šé‡åˆ°ä¸€äº›é—®é¢˜ã€‚ç„¶è€Œï¼Œåªéœ€è¯¢é—®Chat GPTï¼Œå®ƒå¯èƒ½ä¼šå¸®åŠ©ä½ è§£å†³è¿™äº›é—®é¢˜ã€‚æˆ‘ç¼–å†™çš„ä»£ç æ˜¯ä¸ºäº†åœ¨.pyæ–‡ä»¶ä¸­è¿è¡Œå¤§å·¥ä½œè´Ÿè½½ï¼Œæ‰€ä»¥åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œæ—¶å¯èƒ½éœ€è¦ä¸€äº›ä¿®æ”¹ã€‚
- en: Too many output keys
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¾“å‡ºçš„é”®å¤ªå¤šäº†
- en: The First one was that my chain had multiple keys as outputs and at the time
    the arun() only accepted chains that had one key as the output. So to fix this
    I had to break my chain into two separate ones.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯æˆ‘çš„é“¾æœ‰å¤šä¸ªè¾“å‡ºé”®ï¼Œè€Œå½“æ—¶çš„arun()åªæ¥å—å…·æœ‰ä¸€ä¸ªè¾“å‡ºé”®çš„é“¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä¸å¾—ä¸å°†é“¾æ‹†åˆ†æˆä¸¤ä¸ªç‹¬ç«‹çš„é“¾ã€‚
- en: Not all chains can be async
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸æ˜¯æ‰€æœ‰é“¾éƒ½å¯ä»¥å¼‚æ­¥å¤„ç†
- en: I had a logic of using a vector database for examples and comparisons in my
    prompt and that required that the examples were sequentially compared and added
    to the database. This rendered unfeasible the use of async for this link in the
    full chain.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨æç¤ºä¸­ä½¿ç”¨äº†ä¸€ä¸ªå‘é‡æ•°æ®åº“è¿›è¡Œç¤ºä¾‹å’Œæ¯”è¾ƒçš„é€»è¾‘ï¼Œè¿™éœ€è¦å°†ç¤ºä¾‹æŒ‰é¡ºåºæ¯”è¾ƒå¹¶æ·»åŠ åˆ°æ•°æ®åº“ä¸­ã€‚è¿™ä½¿å¾—åœ¨æ•´ä¸ªé“¾ä¸­ä½¿ç”¨å¼‚æ­¥å¤„ç†å˜å¾—ä¸å¯è¡Œã€‚
- en: Lack of content
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†…å®¹ä¸è¶³
- en: For this specific matter, the best content I could find was the [official documentation
    for async](https://python.langchain.com/docs/modules/chains/how_to/async_chain)
    and build from there to my use case. So if you run it and find new things out
    share it with the world!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: é’ˆå¯¹è¿™ä¸ªç‰¹å®šçš„é—®é¢˜ï¼Œæˆ‘æ‰¾åˆ°çš„æœ€å¥½å†…å®¹æ˜¯[å®˜æ–¹å¼‚æ­¥æ–‡æ¡£](https://python.langchain.com/docs/modules/chains/how_to/async_chain)ï¼Œå¹¶æ ¹æ®æˆ‘çš„ç”¨ä¾‹è¿›è¡Œæ„å»ºã€‚æ‰€ä»¥å¦‚æœä½ è¿è¡Œåå‘ç°æ–°ä¸œè¥¿ï¼Œè®°å¾—ä¸å¤§å®¶åˆ†äº«ï¼
- en: Conclusion
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: LangChain is a very powerful tool to create LLM-based applications. I highly
    recommend learning this framework and doing the courses cited above.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: LangChainæ˜¯ä¸€ä¸ªéå¸¸å¼ºå¤§çš„å·¥å…·ï¼Œç”¨äºåˆ›å»ºåŸºäºLLMçš„åº”ç”¨ç¨‹åºã€‚æˆ‘å¼ºçƒˆæ¨èå­¦ä¹ è¿™ä¸ªæ¡†æ¶å¹¶å‚åŠ ä¸Šè¿°æåˆ°çš„è¯¾ç¨‹ã€‚
- en: For the specific topic of running chains, for high workloads we saw the potential
    improvement that Async calls have, so my recommendation is to take the time to
    understand what the code is doing and have a boilerplate class (such as the one
    provided in my code) and run it Asynchronously!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿è¡Œé“¾çš„å…·ä½“ä¸»é¢˜ï¼Œå¯¹äºé«˜å·¥ä½œè´Ÿè½½ï¼Œæˆ‘ä»¬çœ‹åˆ°å¼‚æ­¥è°ƒç”¨çš„æ½œåœ¨æ”¹è¿›ï¼Œæ‰€ä»¥æˆ‘çš„å»ºè®®æ˜¯èŠ±æ—¶é—´ç†è§£ä»£ç åœ¨åšä»€ä¹ˆï¼Œå¹¶æ‹¥æœ‰ä¸€ä¸ªæ¨¡æ¿ç±»ï¼ˆå¦‚æˆ‘æä¾›çš„ä»£ç ä¸­ï¼‰ï¼Œå¹¶ä»¥å¼‚æ­¥æ–¹å¼è¿è¡Œå®ƒï¼
- en: For small workloads or applications that require only one call to an API it
    is not necessary to do it async, but if you have a boilerplate class just add
    a sync function so you can easily use one or the other.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå°å‹å·¥ä½œè´Ÿè½½æˆ–ä»…éœ€è¦ä¸€æ¬¡APIè°ƒç”¨çš„åº”ç”¨ç¨‹åºï¼Œé€šå¸¸ä¸éœ€è¦å¼‚æ­¥å¤„ç†ï¼Œä½†å¦‚æœä½ æœ‰ä¸€ä¸ªæ¨¡æ¿ç±»ï¼Œå¯ä»¥æ·»åŠ ä¸€ä¸ªåŒæ­¥å‡½æ•°ï¼Œä»¥ä¾¿äºä½¿ç”¨å…¶ä¸­ä»»ä½•ä¸€ä¸ªã€‚
- en: Thanks for reading.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ã€‚
- en: The full code can be found [here](https://github.com/gabrielcassimiro17/async-langchain).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæ•´ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/gabrielcassimiro17/async-langchain)æ‰¾åˆ°ã€‚
- en: 'If you like the content and want to support me, you can buy me a coffee:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢è¿™äº›å†…å®¹å¹¶ä¸”æƒ³æ”¯æŒæˆ‘ï¼Œä½ å¯ä»¥è¯·æˆ‘å–å’–å•¡ï¼š
- en: '[](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)
    [## Gabriel Cassimiro is a Data Scientist sharing free content to the community'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Gabriel Cassimiroæ˜¯ä¸€ä½åˆ†äº«å…è´¹å†…å®¹çš„ æ•°æ®ç§‘å­¦å®¶](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)'
- en: Hey ğŸ‘‹ I just created a page here. You can now buy me a coffee!
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å—¨ğŸ‘‹ æˆ‘åˆšåˆ›å»ºäº†ä¸€ä¸ªé¡µé¢ã€‚ä½ ç°åœ¨å¯ä»¥è¯·æˆ‘å–å’–å•¡äº†ï¼
- en: www.buymeacoffee.com](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[åœ¨è¿™é‡Œè´­ä¹°å’–å•¡](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)'
- en: 'Here are a few other articles you might be interested in:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€äº›ä½ å¯èƒ½æ„Ÿå…´è¶£çš„å…¶ä»–æ–‡ç« ï¼š
- en: '[](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----3818c16062ed--------------------------------)
    [## Solving Unity Environment with Deep Reinforcement Learning'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[## ä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ è§£å†³Unityç¯å¢ƒé—®é¢˜](https://solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----3818c16062ed--------------------------------)'
- en: End to End Project with code of a PyTorch implementation of Deep Reinforcement
    Learning Agent.
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¸¦æœ‰PyTorchå®ç°æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»£ç†çš„ç«¯åˆ°ç«¯é¡¹ç›®ä»£ç ã€‚
- en: towardsdatascience.com](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----3818c16062ed--------------------------------)
    [](/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=post_page-----3818c16062ed--------------------------------)
    [## Object detection with Tensorflow model and OpenCV
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[åœ¨è¿™é‡Œè´­ä¹°å’–å•¡](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)
    [## ä½¿ç”¨Tensorflowæ¨¡å‹å’ŒOpenCVè¿›è¡Œç›®æ ‡æ£€æµ‹'
- en: Using a trained model to identify objects on static images and live video
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ¥è¯†åˆ«é™æ€å›¾åƒå’Œå®æ—¶è§†é¢‘ä¸­çš„å¯¹è±¡
- en: towardsdatascience.com](/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=post_page-----3818c16062ed--------------------------------)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=post_page-----3818c16062ed--------------------------------) '
