- en: Async for LangChain and LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain 和 LLMs 的异步处理
- en: 原文：[https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10](https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10](https://towardsdatascience.com/async-calls-for-chains-with-langchain-3818c16062ed?source=collection_archive---------0-----------------------#2023-07-10)
- en: How to make LangChain chains work with Async calls to LLMs, speeding up the
    time it takes to run a sequential long chain
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使 LangChain 链与异步调用的 LLMs 一起工作，从而加快运行顺序长链的时间
- en: '[](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[![Gabriel
    Cassimiro](../Images/2cf8a09a706236059c46c7f0f20d4365.png)](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    [Gabriel Cassimiro](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[![Gabriel
    Cassimiro](../Images/2cf8a09a706236059c46c7f0f20d4365.png)](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    [Gabriel Cassimiro](https://gabrielcassimiro17.medium.com/?source=post_page-----3818c16062ed--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3692fb93d7e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=post_page-3692fb93d7e5----3818c16062ed---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    ·6 min read·Jul 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=-----3818c16062ed---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3692fb93d7e5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=post_page-3692fb93d7e5----3818c16062ed---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3818c16062ed--------------------------------)
    ·6分钟阅读·2023年7月10日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&user=Gabriel+Cassimiro&userId=3692fb93d7e5&source=-----3818c16062ed---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&source=-----3818c16062ed---------------------bookmark_footer-----------)![](../Images/3d661ccf3f4d03c45b31cfc182d4ecd0.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3818c16062ed&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fasync-calls-for-chains-with-langchain-3818c16062ed&source=-----3818c16062ed---------------------bookmark_footer-----------)![](../Images/3d661ccf3f4d03c45b31cfc182d4ecd0.png)'
- en: Image by[hp koch](https://unsplash.com/@iggii?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/pt-br/fotografias/2OuTr9_VaUg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[hp koch](https://unsplash.com/@iggii?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)提供，[Unsplash](https://unsplash.com/pt-br/fotografias/2OuTr9_VaUg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: In this article, I will cover how to use asynchronous calls to LLMs for long
    workflows using LangChain. We will go through an example with the full code and
    compare Sequential execution with the Async calls.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将介绍如何使用异步调用 LLMs 来处理长工作流，使用 LangChain。我们将通过一个完整代码的示例进行讲解，并比较顺序执行与异步调用的差异。
- en: 'Here is the overview of the content. If you’d like you can jump to the section
    of your interest:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是内容概览。如果你愿意，可以跳转到你感兴趣的部分：
- en: 'Basics: What is LangChain'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基础知识：什么是 LangChain
- en: How to run a Synchronous chain with LangChain
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使用 LangChain 运行同步链
- en: How to run a single Asynchronous chain with LangChain
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何运行单个异步链与LangChain
- en: Real-world tips for long workflows with Async Chains.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 长工作流程中的实用技巧与异步链。
- en: So let’s start!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们开始吧！
- en: 'Basics: What is Langchain'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础知识：什么是LangChain
- en: LangChain is a framework for developing applications powered by language models.
    That is the official definition of LangChain. This framework was created recently
    and is already used as the industry standard for building tools powered by LLMs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain是一个基于语言模型开发应用程序的框架。这就是LangChain的官方定义。这个框架是最近创建的，已经被用作建立由LLM支持的工具的行业标准。
- en: It is open-source and well-maintained, with new features being released in a
    very fast time frame.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 它是开源的，并且在非常快的时间框架内发布新功能。
- en: The official documentation can be found [here](https://python.langchain.com/docs/get_started/introduction.html)
    and the GitHub repository [here](https://github.com/hwchase17/langchain).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 官方文档可以在[这里](https://python.langchain.com/docs/get_started/introduction.html)找到，GitHub存储库可以在[这里](https://github.com/hwchase17/langchain)找到。
- en: One downside that we have in this library is that since the features are new
    we cannot use Chat GPT to help effectively to build new code. So this means that
    we have to work in the “Ancient” way of reading documentation, forums, and tutorials.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这个库中遇到的一个缺点是，由于这些功能是新的，我们不能有效地使用Chat GPT来帮助构建新的代码。这意味着我们必须以“古老”的方式阅读文档、论坛和教程来工作。
- en: The documentation for LangChain.is really good however there are not a lot of
    examples of some specific things.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain的文档确实很好，但是关于某些特定事物的例子并不多。
- en: I ran into this problem with Async for long chains.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我在异步长链方面遇到了这个问题。
- en: 'Here are the main resources I used to learn more about the framework:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我用来了解更多关于这个框架的主要资源：
- en: 'Deep Learning AI course: [LangChain Chat with your data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/);'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度学习AI课程：[LangChain Chat with your data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)；
- en: '[Official Documentation](https://python.langchain.com/docs/get_started/introduction.html);'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[官方文档](https://python.langchain.com/docs/get_started/introduction.html)；'
- en: '[Youtube channel](https://www.youtube.com/watch?v=_v_fgW2SkkQ&list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5).'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[YouTube频道](https://www.youtube.com/watch?v=_v_fgW2SkkQ&list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5)。'
- en: (ps. They are all free)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: （附注：它们都是免费的）
- en: How to run a Synchronous chain with LangChain
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何运行LangChain的同步链
- en: 'So let me set up the problem I had: I have a data frame with a lot of rows
    and for each of those rows I need to run multiple prompts (chains) to an LLM and
    return the result to my data frame.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我说明我遇到的问题：我有一个包含大量行的数据框架，对于每一行，我需要运行多个提示（链）到一个LLM，并将结果返回到我的数据框架中。
- en: When you have multiple rows, let’s say 10K, running 3 prompts for each and each
    response (if the server is not overloaded) taking about 3–5 seconds you end up
    waiting for days for the workflow to be completed.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有多个行时，比如1万行，每个行运行3个提示，并且每个响应（如果服务器没有超载）大约需要3-5秒，你最终会等待数天才能完成工作流程。
- en: Bellow I am going to show the main steps and code to build a synchronous chain
    and time it on a subset of data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我将展示主要步骤和构建同步链的代码，并在数据子集上计时。
- en: For this example, I am going to use the dataset [Wine Reviews](https://www.kaggle.com/datasets/zynicide/wine-reviews),
    [license](https://creativecommons.org/licenses/by-nc-sa/4.0/). The goal here is
    to extract some information from the written reviews.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我将使用数据集[Wine Reviews](https://www.kaggle.com/datasets/zynicide/wine-reviews)，[许可证](https://creativecommons.org/licenses/by-nc-sa/4.0/)。这里的目标是从书面评论中提取一些信息。
- en: I want to extract a Summary of the review, the main sentiment, and the top 5
    characteristics of each wine.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我想提取一份评论摘要、主要情感以及每种葡萄酒的前五个特征。
- en: For that, I created two chains, one for the summary and sentiment and another
    that takes the summary as input to extract the characteristics.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我创建了两个链，一个用于摘要和情感，另一个使用摘要作为输入来提取特征。
- en: 'Here is the code to run it:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是运行它的代码：
- en: 'Run time (10 examples):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时间（10个示例）：
- en: Summary Chain (Sequential) executed in 22.59 seconds.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 摘要链（顺序执行）在22.59秒内执行完毕。
- en: Characteristics Chain (Sequential) executed in 22.85 seconds.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 特征链（顺序执行）在22.85秒内执行完毕。
- en: If you want to understand more about the components I am using I really recommend
    watching the [Deep Learning AI Course](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想更深入地了解我使用的组件，我真的推荐观看[深度学习AI课程](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)。
- en: The main takeaways from this code are the building blocks for a chain, how to
    run it in a sequential way, and the time it took to finish this loop. It is important
    to remember that it was about 45 seconds for 10 examples and the full dataset
    contains 130K rows. So the Async implementation is the New Hope to run this in
    a reasonable time.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的主要收获是链的构建模块、如何以顺序方式运行它，以及完成此循环所需的时间。需要记住的是，对于 10 个示例，大约需要 45 秒，而完整的数据集包含
    130K 行。因此，异步实现是以合理时间运行的“新希望”。
- en: So with the problem set up and the baseline established, let's see how we can
    optimize this code to run much faster.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，既然问题已经设置并且基线已经确定，我们来看看如何优化这段代码以便更快地运行。
- en: How to run a single Asynchronous chain with LangChain
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用 LangChain 运行单个异步链
- en: So for this, we are going to use a resource called Asynchronous calls. To explain
    this, first I will explain briefly what the code is doing and where the time is
    taking too long.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将使用一种叫做异步调用的资源。为了说明这一点，我将首先简要解释代码的作用以及哪些地方的时间消耗过长。
- en: In our example, we go through each row of the data frame, extract some information
    from the rows, add them to our prompt, and call the GPT API to get a response.
    After the response, we just parse it and add it back to the data frame.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们遍历数据框的每一行，从行中提取一些信息，将它们添加到提示中，然后调用 GPT API 获取响应。收到响应后，我们解析它并将其重新添加到数据框中。
- en: '![](../Images/e446a0030466fef8a134fcceada0501a.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e446a0030466fef8a134fcceada0501a.png)'
- en: Image by Author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The main bottleneck here is when we call the GPT API because our computer has
    to wait idly for the response from that API (about 3 seconds). The rest of the
    steps are fast and can still be optimized but that is not the focus of this article.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的瓶颈在于调用 GPT API，因为我们的计算机必须在等待该 API 响应时闲置（大约 3 秒）。其余的步骤都很快，可以继续优化，但这不是本文的重点。
- en: So instead of waiting Idly for the response, what if we sent all the calls to
    the API at the same time? This way we would only have to wait for a single response
    and then process them. This is called Asynchronous calls to the API.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，既然不需要闲等响应，我们为什么不同时发送所有 API 请求呢？这样我们只需等待一个响应，然后处理所有响应。这就是所谓的异步 API 调用。
- en: '![](../Images/e0b1422650d5840a248989d6ca91aedb.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0b1422650d5840a248989d6ca91aedb.png)'
- en: Image by Author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: This way we do the pre-process and post-process sequentially but the calls to
    the API do not have to wait for the last response to come back before sending
    the next one.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以顺序地进行预处理和后处理，但对 API 的调用不必等到上一个响应回来后再发送下一个请求。
- en: 'So here is the code for the Async chains:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是异步链的代码：
- en: In this code, we use the Python syntax of async and await. LangChain also gives
    us the code to run the chain async, with the arun() function. So in the beginning
    we first process each row sequentially (can be optimized) and create multiple
    “tasks” that will await the response from the API in parallel and then we process
    the response to the final desired format sequentially (can also be optimized).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们使用了 Python 的 async 和 await 语法。LangChain 也提供了运行异步链的代码，使用 arun() 函数。因此，开始时我们首先顺序处理每一行（可以优化），并创建多个“任务”来并行等待
    API 响应，然后顺序处理响应以达到最终所需格式（也可以优化）。
- en: 'Run time (10 examples):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时间（10 个示例）：
- en: Summary Chain (Async) executed in 3.35 seconds.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 摘要链（异步）执行时间为 3.35 秒。
- en: Characteristics Chain (Async) executed in 2.49 seconds.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 特征链（异步）执行时间为 2.49 秒。
- en: 'Compared to the sequential:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 与顺序执行相比：
- en: Summary Chain (Sequential) executed in 22.59 seconds.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 摘要链（顺序）执行时间为 22.59 秒。
- en: Characteristics Chain (Sequential) executed in 22.85 seconds.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 特征链（顺序）执行时间为 22.85 秒。
- en: We can see almost a 10x improvement in the run time. So for big workloads, I
    highly recommend using this method. Also my code is full of for loops that can
    also be optimized further to improve performance.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到运行时间几乎提高了 10 倍。因此，对于大型工作负载，我强烈推荐使用这种方法。此外，我的代码中充满了可以进一步优化的 for 循环，以提升性能。
- en: The full code to this tutorial can be found in this [Github Repo](https://github.com/gabrielcassimiro17/async-langchain).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的完整代码可以在这个 [Github Repo](https://github.com/gabrielcassimiro17/async-langchain)
    中找到。
- en: Real-world tips for long workflows with Async Chains.
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用异步链的长工作流的实际建议。
- en: When I had to run this, I ran into some limitations and a few roadblocks, that
    I want to share with you.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当我运行这些代码时，遇到了一些限制和障碍，我想和你们分享一下。
- en: Notebooks are not Async Friendly
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 笔记本电脑不支持异步操作
- en: When running async calls on Jupyter Notebooks you may encounter some issues.
    However, just ask Chat GPT and it can probably help you out with that. The code
    I built is to run big workloads in a .py file, so it may need some changes to
    run in a notebook.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在Jupyter笔记本中运行异步调用时，你可能会遇到一些问题。然而，只需询问Chat GPT，它可能会帮助你解决这些问题。我编写的代码是为了在.py文件中运行大工作负载，所以在笔记本中运行时可能需要一些修改。
- en: Too many output keys
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出的键太多了
- en: The First one was that my chain had multiple keys as outputs and at the time
    the arun() only accepted chains that had one key as the output. So to fix this
    I had to break my chain into two separate ones.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个问题是我的链有多个输出键，而当时的arun()只接受具有一个输出键的链。为了解决这个问题，我不得不将链拆分成两个独立的链。
- en: Not all chains can be async
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不是所有链都可以异步处理
- en: I had a logic of using a vector database for examples and comparisons in my
    prompt and that required that the examples were sequentially compared and added
    to the database. This rendered unfeasible the use of async for this link in the
    full chain.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我在提示中使用了一个向量数据库进行示例和比较的逻辑，这需要将示例按顺序比较并添加到数据库中。这使得在整个链中使用异步处理变得不可行。
- en: Lack of content
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内容不足
- en: For this specific matter, the best content I could find was the [official documentation
    for async](https://python.langchain.com/docs/modules/chains/how_to/async_chain)
    and build from there to my use case. So if you run it and find new things out
    share it with the world!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这个特定的问题，我找到的最好内容是[官方异步文档](https://python.langchain.com/docs/modules/chains/how_to/async_chain)，并根据我的用例进行构建。所以如果你运行后发现新东西，记得与大家分享！
- en: Conclusion
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: LangChain is a very powerful tool to create LLM-based applications. I highly
    recommend learning this framework and doing the courses cited above.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain是一个非常强大的工具，用于创建基于LLM的应用程序。我强烈推荐学习这个框架并参加上述提到的课程。
- en: For the specific topic of running chains, for high workloads we saw the potential
    improvement that Async calls have, so my recommendation is to take the time to
    understand what the code is doing and have a boilerplate class (such as the one
    provided in my code) and run it Asynchronously!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于运行链的具体主题，对于高工作负载，我们看到异步调用的潜在改进，所以我的建议是花时间理解代码在做什么，并拥有一个模板类（如我提供的代码中），并以异步方式运行它！
- en: For small workloads or applications that require only one call to an API it
    is not necessary to do it async, but if you have a boilerplate class just add
    a sync function so you can easily use one or the other.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小型工作负载或仅需要一次API调用的应用程序，通常不需要异步处理，但如果你有一个模板类，可以添加一个同步函数，以便于使用其中任何一个。
- en: Thanks for reading.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。
- en: The full code can be found [here](https://github.com/gabrielcassimiro17/async-langchain).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码可以在[这里](https://github.com/gabrielcassimiro17/async-langchain)找到。
- en: 'If you like the content and want to support me, you can buy me a coffee:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这些内容并且想支持我，你可以请我喝咖啡：
- en: '[](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)
    [## Gabriel Cassimiro is a Data Scientist sharing free content to the community'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[## Gabriel Cassimiro是一位分享免费内容的 数据科学家](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)'
- en: Hey 👋 I just created a page here. You can now buy me a coffee!
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 嗨👋 我刚创建了一个页面。你现在可以请我喝咖啡了！
- en: www.buymeacoffee.com](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[在这里购买咖啡](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)'
- en: 'Here are a few other articles you might be interested in:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些你可能感兴趣的其他文章：
- en: '[](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----3818c16062ed--------------------------------)
    [## Solving Unity Environment with Deep Reinforcement Learning'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 使用深度强化学习解决Unity环境问题](https://solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----3818c16062ed--------------------------------)'
- en: End to End Project with code of a PyTorch implementation of Deep Reinforcement
    Learning Agent.
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带有PyTorch实现深度强化学习代理的端到端项目代码。
- en: towardsdatascience.com](/solving-unity-environment-with-deep-reinforcement-learning-836dc181ee3b?source=post_page-----3818c16062ed--------------------------------)
    [](/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=post_page-----3818c16062ed--------------------------------)
    [## Object detection with Tensorflow model and OpenCV
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[在这里购买咖啡](https://www.buymeacoffee.com/cassimiro?source=post_page-----3818c16062ed--------------------------------)
    [## 使用Tensorflow模型和OpenCV进行目标检测'
- en: Using a trained model to identify objects on static images and live video
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用训练好的模型来识别静态图像和实时视频中的对象
- en: towardsdatascience.com](/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=post_page-----3818c16062ed--------------------------------)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/object-detection-with-tensorflow-model-and-opencv-d839f3e42849?source=post_page-----3818c16062ed--------------------------------) '
