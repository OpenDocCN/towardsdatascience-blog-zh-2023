- en: 'Edge Emotion Recognition: Enhancing Human-Machine Interaction through Real-Time
    Speech Analysis'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘情感识别：通过实时语音分析提升人机互动
- en: 原文：[https://towardsdatascience.com/edge-emotion-recognition-enhancing-human-machine-interaction-through-real-time-speech-analysis-235ee97cc5f6](https://towardsdatascience.com/edge-emotion-recognition-enhancing-human-machine-interaction-through-real-time-speech-analysis-235ee97cc5f6)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/edge-emotion-recognition-enhancing-human-machine-interaction-through-real-time-speech-analysis-235ee97cc5f6](https://towardsdatascience.com/edge-emotion-recognition-enhancing-human-machine-interaction-through-real-time-speech-analysis-235ee97cc5f6)
- en: '[](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)[![Rüdiger
    Buchkremer, PhD](../Images/c116ab76808a3b5c892e2917f1a679d7.png)](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------)
    [Rüdiger Buchkremer, PhD](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)[![Rüdiger
    Buchkremer, PhD](../Images/c116ab76808a3b5c892e2917f1a679d7.png)](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------)
    [Rüdiger Buchkremer, PhD](https://medium.com/@ruetsi?source=post_page-----235ee97cc5f6--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------)
    ·13 min read·Jul 23, 2023
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----235ee97cc5f6--------------------------------)
    ·13分钟阅读·2023年7月23日
- en: --
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In the modern world, our conversations with computers have grown exponentially.
    But alas, these technological marvels are oblivious to our emotions, which can
    be inconvenient. In this article, I am trying to unveil the intriguing approaches
    to detecting emotions through advanced technical means. And not just that, I will
    also regale you with the tale of a groundbreaking procedure developed at our innovative
    university research institute that can operate without a network connection. So,
    buckle up and prepare to be enthralled by the wonders of emotion recognition technology!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代世界中，我们与计算机的对话增长了指数级。但可惜的是，这些技术奇迹对我们的情感毫无察觉，这可能会带来不便。在这篇文章中，我将尝试揭示通过先进技术手段检测情感的有趣方法。不仅如此，我还将给你讲述一个我们创新大学研究所开发的突破性程序的故事，该程序可以在没有网络连接的情况下操作。所以，请系好安全带，准备好被情感识别技术的奇迹所吸引吧！
- en: '![](../Images/79d8f4540c56db0ace654d9785a3fcfe.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79d8f4540c56db0ace654d9785a3fcfe.png)'
- en: 'Source: Author, image generated with artificial intelligence (leonardo.ai)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：作者，图像由人工智能生成（leonardo.ai）
- en: '**Background Story**'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**背景故事**'
- en: People express their feelings through more than just the words they say. The
    tone of their voice, the speed they talk, and even the silences in between can
    give clues to **happiness, sadness, anger, fear, disgust, and surprise.**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人们通过不仅仅是他们说的话来表达感情。他们的声音语调、说话速度，甚至是之间的沉默都能提供**幸福、悲伤、愤怒、恐惧、厌恶和惊讶**的线索。
- en: '*But standard computers have no idea what any of that means. They just process
    the basic sounds of speech.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*但标准计算机对这些含义一无所知。它们只是处理基本的语音声音。*'
- en: Lately, I have increasingly had to communicate with computers with either a
    human intermediary providing guidance or responding directly to my inquiries.
    **It bothered me** that these computers seemed utterly unaware of the emotional
    impact this interaction had on me, as they consistently replied in a detached
    and objective manner, which only intensified my frustrations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我越来越多地需要与计算机沟通，要么由人类中介提供指导，要么直接回应我的询问。**这让我烦恼**的是，这些计算机似乎完全没有意识到这种互动对我产生的情感影响，因为它们始终以冷漠和客观的方式回应，这只会加剧我的挫败感。
- en: To address this issue, researchers at our institute embarked on a collaborative
    study, the results of which were recently published by the authors Dominik and
    myself, in a scientific article, which is quite lengthy and technical in nature.
    However, I am delighted to inform you that the link to our original 24-page scientific
    paper, recently published in the Journal of Computer Science Research, can be
    found at the end of the current article.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们研究所的研究人员开展了一项合作研究，结果由Dominik和我在一篇科学文章中发表，这篇文章相当冗长且技术性强。然而，我很高兴地通知您，我们原始的24页科学论文，最近在《计算机科学研究期刊》上发表，链接可以在当前文章的末尾找到。
- en: '**Current Technologies Technical Background**'
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**当前技术背景**'
- en: As the integration of machines into our daily lives continues to progress, a
    growing demand arises for these machines to possess the ability to understand
    human emotions. When we engage with computers, robotics, and AI assistants, it
    is innate for us to express our emotions through various means, such as changes
    in our tone of voice, facial expressions, and gestures, to name a few. However,
    it is worth noting that **most current technologies lack a comprehensive understanding
    of these emotional signals.**
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器在我们日常生活中集成的不断推进，对这些机器能够理解人类情感的需求也在增长。当我们与计算机、机器人和AI助手互动时，我们通过语调变化、面部表情和手势等多种方式表达情感是自然的。然而，值得注意的是，**大多数现有技术缺乏对这些情感信号的全面理解。**
- en: Researchers have developed systems that can effectively recognize emotions from
    a person’s voice to address this issue. Similar to how humans derive meaning from
    variations in speech patterns, these machines are acquiring the capability to
    interpret elements such as pauses, pitch, volume, tempo, and other subtle nuances,
    intending to identify emotions such as joy, sadness, anger, and more.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员已经开发出能够有效识别一个人声音中情感的系统，以解决这个问题。类似于人类如何从语音模式的变化中获取意义，这些机器正逐步获得解释暂停、音调、音量、节奏及其他细微差别的能力，旨在识别如快乐、悲伤、愤怒等情感。
- en: '**One particular approach involves training algorithms utilizing machine learning
    techniques** on a large dataset of emotional speech samples. By uncovering **acoustic
    patterns** associated with various emotional states, these systems can categorize
    basic emotions with an approximately 70% accuracy rate.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**一种特别的方法涉及利用机器学习技术对大量情感语音样本进行算法训练**。通过揭示与各种情感状态相关的**声学模式**，这些系统可以以约70%的准确率对基本情感进行分类。'
- en: '**Other researchers convert speech into visual representations** known as spectrograms,
    colorful images representing soundwave patterns.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**其他研究人员将语音转换为称为频谱图的视觉表示**，频谱图是表示声波模式的彩色图像。'
- en: '**Research milestones**'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**研究里程碑**'
- en: In the early 2000s, cloud computing emerged as a revolutionary milestone, transforming
    business models and sparking innovations worldwide. **However, the reign of cloud
    computing is now facing its twilight**, as a new paradigm known as edge computing
    is stealing the spotlight, driven by evolving demands and requirements.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在2000年代初，云计算作为一项革命性里程碑出现，改变了商业模式并引发了全球创新。**然而，云计算的统治正面临黄昏，** 一种称为边缘计算的新范式正在抢占风头，这一变化受到不断发展的需求和要求的驱动。
- en: Edge computing brings with it the power to meet the needs for low latency, enhanced
    data security, seamless mobility support, and real-time processing, making it
    a formidable competitor to its cloud counterpart.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算具有满足低延迟、增强数据安全性、无缝移动支持和实时处理的能力，使其成为对抗云计算的强大竞争者。
- en: 'Three sub-areas dominate the stage within edge computing: fog computing, cloudlet,
    and mobile edge computing (MEC). While fog computing and cloudlet are still playing
    hard to get in real-world applications, MEC has become the show’s superstar.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算领域主要有三个子领域：雾计算、云端计算和移动边缘计算（MEC）。虽然雾计算和云端计算在实际应用中仍显得难以普及，但MEC已成为明星技术。
- en: '**Picture this:** MEC stations right at or inside near-end devices, ensuring
    everyday use of this cutting-edge technology. MEC means data processing happens
    instantly, right on the end device itself.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**想象一下：** MEC站点就在或位于接近终端设备内部，确保日常使用这项尖端技术。MEC意味着数据处理会立即发生，在终端设备上完成。'
- en: We also have mobile cloud computing (MCC), where end devices perform the processing
    and only send the results back to MEC or MCC servers. **Combining cloud and edge
    computing techniques offers a dazzling array of possibilities**, catering to various
    use cases and taking full advantage of their unique strengths.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有移动云计算（MCC），其中终端设备执行处理，仅将结果发送回MEC或MCC服务器。**结合云计算和边缘计算技术提供了令人眼花缭乱的可能性**，满足各种用例，并充分发挥其独特的优势。
- en: 'Now, let’s shift gears to another riveting topic: speech emotion recognition
    (SER) and the captivating world of feature extraction and pattern recognition.
    Contemporary research is ablaze with discussions on SER, where continuous and
    spectral speech features take center stage, capturing the essence of emotions
    with astonishing accuracy.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们转向另一个引人入胜的话题：语音情感识别（SER）以及特征提取和模式识别的迷人世界。当代研究正热烈讨论SER，其中连续和光谱语音特征成为焦点，以惊人的准确性捕捉情感的本质。
- en: The journey of emotion recognition relies on the portrayal of primary speech
    frequency, loudness, temporal ratios, pauses, and spectral features like the mel
    frequency cepstral coefficient (MFCC) and the so-called mel spectrograms.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 情感识别的旅程依赖于主要语音频率、响度、时间比率、停顿以及像梅尔频率倒谱系数（MFCC）和所谓的梅尔谱图等光谱特征的表现。
- en: '**Mel spectrograms**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**梅尔谱图**'
- en: A captivating star has emerged in the enchanting realm of audio and speech processing
    — the mel spectrogram (mel stands for melody). This mesmerizing visualization
    tool has taken center stage, captivating researchers and enthusiasts alike. Its
    brilliance lies in its ability to depict the frequency content of a sound signal
    over time in a truly unique manner.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在迷人的音频和语音处理领域，一颗迷人的明星已经崭露头角——梅尔谱图（mel 代表旋律）。这个令人着迷的可视化工具已经成为焦点，吸引了研究人员和爱好者。其卓越之处在于能够以一种独特的方式描绘声音信号随时间的频率内容。
- en: By harnessing the mel scale, which mirrors our perception of pitch, the mel
    spectrogram captures the essence of different frequency bands that hold immense
    significance in speech and audio analysis. This prodigious approach offers a rich
    tapestry of insights into the acoustic characteristics of the signal, rendering
    it an indispensable companion in a myriad of applications, including speech recognition
    and music processing.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用梅尔尺度，这一尺度反映了我们对音高的感知，梅尔谱图捕捉了在语音和音频分析中具有重要意义的不同频带的本质。这种卓越的方法提供了丰富的洞察力，揭示了信号的声学特征，使其在诸多应用中成为不可或缺的伙伴，包括语音识别和音乐处理。
- en: In essence, the mel spectrogram serves as a benevolent guide, unraveling the
    mysteries of sound, illuminating the delicate dance between frequencies and time,
    and nourishing our understanding of the captivating world of audio.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，梅尔谱图作为一个仁慈的向导，揭示了声音的奥秘，照亮了频率与时间之间的微妙舞蹈，并滋养了我们对迷人音频世界的理解。
- en: '![](../Images/fdacca4b3da99b8121a03c33fa23584a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdacca4b3da99b8121a03c33fa23584a.png)'
- en: 'Source: Author; upscaled image from Estevez de Andrade & Buchkremer, Journal
    of Computer Science Research (2023)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：作者；图片升级自Estevez de Andrade & Buchkremer，《计算机科学研究杂志》（2023）
- en: '**Machine-learning Techniques**'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**机器学习技术**'
- en: In the quest for classification excellence, various techniques have graced the
    stage, from the classic Gaussian Mixture Model (GMM) and Hidden Markov Model (HMM)
    combo to the enchanting support vector machine (SVM), and the fascinating world
    of neural networks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在追求分类卓越的过程中，诸多技术相继登场，从经典的高斯混合模型（GMM）和隐马尔可夫模型（HMM）组合到迷人的支持向量机（SVM），以及神经网络的迷人世界。
- en: '*The enchantment doesn’t stop there; we are utterly captivated by the mesmerizing
    potential of recurrent neural networks (RNNs) like Long Short-Term Memory (LSTM).
    But wait, the spotlight now shines on convolutional neural networks (CNNs) such
    as AlexNet, VGG16, ResNet, and MobileNetV2, who have taken the lead with their
    remarkable resource and memory efficiency. It’s like witnessing a grand transformation
    — MFCC and Mel spectrograms uniting with CNNs, and the mystical art of transfer
    learning and Multitask Learning amplifying the charm.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*迷人的魅力并未止步于此；我们完全被递归神经网络（RNN）如长短期记忆（LSTM）的迷人潜力所吸引。但请等一下，现在的聚光灯照在了卷积神经网络（CNN）上，例如AlexNet、VGG16、ResNet和MobileNetV2，这些网络凭借其卓越的资源和记忆效率占据了领先地位。这就像目睹了一场盛大的变革——MFCC和梅尔谱图与CNN相结合，以及迁移学习和多任务学习的神秘艺术放大了其魅力。*'
- en: '**And imagine this: the wondrous prospect of running all of this on petite
    computers, wholly liberated from the clutches of big providers.**'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**想象一下：在小型计算机上运行所有这些的美妙前景，完全摆脱了大型供应商的束缚。**'
- en: Not only does this offer us the precious gift of heightened data privacy, but
    it also grants us a newfound sense of independence.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅为我们提供了提升数据隐私的宝贵礼物，还赋予了我们新的独立感。
- en: With this remarkable combination, we can flourish, breaking free from the chains
    that bind us and embracing a world where our autonomy knows no bounds. So let
    us revel in this empowering possibility, where privacy and self-reliance intertwine,
    and seize the opportunity to chart our digital destiny.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 凭借这一非凡组合，我们可以蓬勃发展，打破束缚我们的链条，迎接一个自主无限的世界。因此，让我们陶醉于这种赋权的可能性中，隐私与自我依赖交织在一起，抓住机会规划我们的数字命运。
- en: '**Extract the Right Data with Parameter Sets**'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**通过参数集提取正确的数据**'
- en: Every excellent recognition performance owes its magic to skillfully extracted
    features. This art involves careful selection from a diverse collection. The favored
    machine learning magician is the captivating open-source framework called Speech
    and Music Interpretation by Large-space Extraction (openSMILE). This remarkable
    framework houses the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS)
    and ComParE datasets, pivotal in the grand spectacle. In deep learning, the spotlight
    shifts to CNNs, taking on the role of feature extraction with grace, either serving
    as classifiers or handing over the baton to an SVM, mesmerizing the audience with
    their versatility.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 每一个优秀的识别性能都源于巧妙提取的特征。这项技艺涉及从多样化的集合中仔细选择。备受青睐的机器学习魔术师是迷人的开源框架——大空间提取的语音和音乐解释（openSMILE）。这个出色的框架包含了扩展的日内瓦简约声学参数集（eGeMAPS）和ComParE数据集，在这个宏伟的演出中扮演了重要角色。在深度学习中，聚光灯转向CNN，它们优雅地担任特征提取的角色，既可以作为分类器，也可以将接力棒交给SVM，以其多才多艺迷住观众。
- en: 'In this thrilling act of emotion classification, diverse sets of emotions unfurl,
    each harboring a unique number of emotions. The audience is immersed in emotions
    ranging from five to a staggering twenty. Amongst the many emotions, the classics
    from Ekman’s collection shine bright: **happiness, sadness, anger, fear, disgust,
    and surprise**, accompanied by the enigmatic seventh emotion, neutral.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这激动人心的情感分类过程中，各种情感展现出来，每种情感都包含独特的情感数量。观众沉浸在从五种到惊人的二十种情感中。在众多情感中，Ekman的经典情感格外引人注目：**快乐、悲伤、愤怒、恐惧、厌恶和惊讶**，以及神秘的第七种情感，中立。
- en: '**With edge computing stealing the spotlight and neural networks unleashing
    their magic, the future of emotion recognition holds untold wonders.**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**随着边缘计算的崭露头角和神经网络的魔力释放，情感识别的未来充满了无限可能。**'
- en: '**Our Approach**'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**我们的做法**'
- en: We ventured into emotion recognition in speech, utilizing labeled emotional
    speech data for our prototypical implementation. To ensure a robust dataset, we
    sought audio files ranging from one to twenty seconds in length. Our focus primarily
    revolved around those, as mentioned earlier, six basic emotions commonly referenced
    in emotion databases. However, we did not consider arousal and valence dimensions
    in our work, thus neglecting these criteria during data acquisition.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了语音中的情感识别，利用标注的情感语音数据进行原型实现。为了确保数据集的健壮性，我们寻找了长度在一到二十秒之间的音频文件。我们主要关注那些，正如之前提到的，情感数据库中常见的六种基本情感。然而，我们在工作中并未考虑唤醒度和情感价值维度，因此在数据采集过程中忽略了这些标准。
- en: '**In human speech, emotions often emerge within individual sentences.** Hence,
    the chosen audio length of one to twenty seconds aligns subjectively well, encapsulating
    the majority of spoken sentences.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**在人类语音中，情感通常会在单个句子中出现。** 因此，选择的音频长度在一到二十秒之间主观上较为合适，能够涵盖大多数口语句子。'
- en: '*The selected audio files needed to exclude singing, noise, or similar disturbances
    to maintain clarity and relevance. While the native language of the speaker was
    not a selection criterion, we ensured a balanced representation of both male and
    female spoken sentences across the entirety of the acquired databases. Factors
    such as channel number or sampling rate also held no significance during the data
    acquisition phase, as these parameters are standardized during training.*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*所选音频文件需要排除唱歌、噪声或类似干扰，以保持清晰和相关性。虽然说话者的母语不是选择标准，但我们确保在获取的数据库中男性和女性口语句子的表现是平衡的。通道数量或采样率等因素在数据采集阶段也没有意义，因为这些参数在训练过程中会被标准化。*'
- en: Lastly, for accessibility and clarity purposes, the audio files and databases
    needed to be freely available and identified by appropriate labels.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了可访问性和清晰性，音频文件和数据库需要是自由获取的，并且由适当的标签标识。
- en: 'With these quality criteria in mind, we selected the following audio databases
    that met our standards:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以这些质量标准为基础，我们选择了符合我们标准的以下音频数据库：
- en: '**1)** Ryerson Audiovisual Database of Emotional Speech and Song (RAVDESS)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**1)** 瑞尔森情感语音与歌曲视听数据库 (RAVDESS)'
- en: '**2)** Berlin Database of Emotional Speech (Emo-DB)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**2)** 柏林情感语音数据库 (Emo-DB)'
- en: '**3)** Toronto Emotional Speech Set (TESS)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**3)** 多伦多情感语音集 (TESS)'
- en: '**4)** EMOVO'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**4)** EMOVO'
- en: '**5)** eNTERFACE’05'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**5)** eNTERFACE’05'
- en: In our study, machine learning and deep learning techniques unite, diving into
    the mysterious world of emotion recognition. The quest begins with a shared data
    corpus, handpicked based on predefined criteria meticulously outlined in the existing
    literature. Non-spoken sentences are left out of the equation, as the prototypes
    exclusively focus on speech-emotion recognition (SER). Only pure speech files
    are allowed, even if some musical pieces contain spoken segments accompanied by
    instruments.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，机器学习和深度学习技术相结合，深入探索情感识别的神秘世界。探寻始于共享的数据语料库，依据现有文献中精心列出的预定义标准进行挑选。不包含口语的句子被排除在外，因为原型专注于语音情感识别（SER）。仅允许纯语音文件，即使一些音乐作品包含带有乐器的口语段落。
- en: And speaking of background noise, it can’t be ignored in this melodious journey.
    Real-life communication often happens amidst noisy environments, so audio data
    with background noise is essential for enriching the research. But don’t confuse
    it with music’s background noise, which plays a different role in the grand symphony
    of speech-related scenarios.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 说到背景噪声，它在这段旋律之旅中是不可忽视的。现实生活中的交流常发生在嘈杂的环境中，因此带有背景噪声的音频数据对于丰富研究至关重要。但不要把它与音乐中的背景噪声混淆，音乐背景噪声在与语音相关的场景中扮演着不同的角色。
- en: '**The native language used in the audio files isn’t a restriction either.**
    German, English, Italian, Turkish, Danish, or Chinese — all languages are welcome
    on this captivating stage. Why? Because the six basic emotions described by Darwin
    and Ekman are expressed similarly across cultures, transcending linguistic barriers.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**音频文件中使用的母语也没有限制。** 德语、英语、意大利语、土耳其语、丹麦语或中文——所有语言都欢迎加入这个引人入胜的舞台。为什么？因为达尔文和艾克曼描述的六种基本情感在不同文化中以相似的方式表达，超越了语言障碍。'
- en: '**Open access to labeled data is another key to our enigmatic adventure.**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**对标记数据的开放获取是我们神秘冒险的另一个关键。**'
- en: Without it, the whole journey would be shrouded in mystery, making it impossible
    for others to reproduce the results. Supervised machine-learning algorithms thrive
    on labeled data, after all.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 没有它，整个旅程将充满神秘，使得其他人无法重现结果。毕竟，监督式机器学习算法依赖于标记数据。
- en: Now, let’s talk about the stars of the show — the hyperparameters!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们谈谈这场表演的明星——超参数！
- en: '*Hyperparameters are crucial elements in deep learning and machine learning,
    acting as knobs that control a model’s learning process and performance. They
    are set before training and influence the model’s architecture and complexity.*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*超参数是深度学习和机器学习中的关键元素，像旋钮一样控制模型的学习过程和性能。它们在训练前设定，影响模型的结构和复杂性。*'
- en: '*In machine learning, common hyperparameters include the learning rate, which
    determines how much the model adjusts its parameters during training, and the
    number of hidden layers, which affects the model’s depth and capacity to learn
    complex patterns.*'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*在机器学习中，常见的超参数包括学习率，它决定了模型在训练过程中调整参数的程度，以及隐藏层的数量，这影响了模型的深度和学习复杂模式的能力。*'
- en: '*In deep learning, hyperparameters become even more vital due to the complexity
    of deep neural networks. Specific hyperparameters include the dropout rate, activation
    functions, optimization algorithm, and weight initialization, all playing crucial
    roles in the model’s performance.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*在深度学习中，由于深度神经网络的复杂性，超参数变得尤为重要。具体的超参数包括丢弃率、激活函数、优化算法和权重初始化，它们在模型性能中扮演着至关重要的角色。*'
- en: Deep learning boasts explicit hyperparameters, while machine learning seeks
    to find the optimal values based on predefined criteria. The battle between these
    two approaches unfolds, each vying for the spotlight.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习拥有明确的超参数，而机器学习则寻求基于预定义标准找到最优值。这两种方法之间的较量展开，每种方法都争夺着焦点。
- en: As the journey progresses, we encounter the base models — MobileNetV2, CNN ResNet50,
    and SqueezeNet — all eager to showcase their unique strengths. But remember, the
    path to greatness isn’t without its challenges. Overfitting and underfitting add
    a touch of drama to the story, keeping us on the edge of our seats.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 随着研究的推进，我们遇到了一些基础模型——MobileNetV2、CNN ResNet50和SqueezeNet——它们都渴望展示各自的独特优势。但请记住，通向伟大的道路并非没有挑战。过拟合和欠拟合为故事增添了一丝戏剧性，让我们保持高度关注。
- en: And the plot thickens! The prototypes developed in this study are tailor-made
    for devices equipped with microphones, making them perfect companions for smart
    speakers and TVs. They’re all set to embark on a grand adventure, bringing emotional
    recognition to everyday life.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 情节更加复杂！这项研究中开发的原型设备专为配备麦克风的设备量身定制，使其成为智能音响和电视的完美伴侣。它们已经准备好踏上伟大的冒险，将情感识别带入日常生活。
- en: With real-time capability on the line, the speed advantage of the machine learning
    approach becomes a crucial factor. The race is on as the clock ticks away milliseconds
    of difference.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于实时能力的需求，机器学习方法的速度优势成为关键因素。随着时间的流逝，毫秒的差距决定了比赛的结果。
- en: But wait, there’s more! The study opens the door to endless possibilities, paving
    the way for future investigations into real-time SER and edge computing. Who knows
    what other mysteries lie waiting to be unraveled in emotion recognition?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 但等一下，还有更多！这项研究为未来的实时SER和边缘计算的调查开辟了无尽的可能性。谁知道情感识别中还隐藏着哪些未解之谜？
- en: '**Conclusion**'
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论**'
- en: In our groundbreaking study, cutting-edge speech emotion recognition (SER) systems
    take center stage, revealing their potential for many practical applications.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开创性的研究中，前沿的语音情感识别（SER）系统成为焦点，展示了它们在许多实际应用中的潜力。
- en: '(i) Universal application: SER applications prove their versatility, finding
    a home in call centers, radio broadcasts, podcasts, and television shows. But
    that’s not all! Imagine an intelligent speaker that detects vocal activity and
    emotions in your home, offering personalized products and services based on your
    feelings. Or how about automated highlights in a sports game, tailor-made to match
    the emotions of the moment? The possibilities are endless, reaching even internet-based
    broadcasts like Twitch or Netflix.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: (i) 通用应用：SER应用展示了它们的多功能性，广泛应用于呼叫中心、广播、电台、播客和电视节目。可不仅如此！想象一下一个智能音响，能在你家中检测到声音活动和情绪，根据你的感受提供个性化的产品和服务。或者如何在体育比赛中实现自动化亮点，量身定制以匹配当时的情绪？可能性无穷，甚至可以扩展到像Twitch或Netflix这样的互联网广播。
- en: '(ii) Real-time audience mood capture: Get ready for real-time mood tracking!
    Imagine having a tool to gauge an audience’s emotions at any moment. Political
    talks, product presentations — no setting is too grand for this cutting-edge technology.
    Speakers can now receive instant feedback on the emotions they evoke, revolutionizing
    the art of communication in physical, virtual, or hybrid realms.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: (ii) 实时观众情绪捕捉：准备好实时情绪追踪吧！想象一下拥有一个可以随时评估观众情绪的工具。政治演讲、产品介绍——没有任何场合是这个尖端技术无法涉足的。演讲者现在可以即时获得他们激发的情感反馈，彻底改变了在实体、虚拟或混合环境中沟通的艺术。
- en: '(iii) Individual-focused applications: Emotion recognition goes personal, catering
    to individual users and their emotional needs. Picture a smart speaker or car
    that adjusts music or lighting according to your feelings. In gaming, the algorithm
    can offer relief when it detects anger. And brace yourself for personalized advertising
    in social media or e-commerce platforms, where prices dynamically change based
    on your emotional state. It’s like having your very own emotional concierge!'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: (iii) 以个人为中心的应用：情感识别变得更加个性化，迎合个人用户及其情感需求。想象一下一个智能音响或汽车根据你的情绪调整音乐或照明。在游戏中，当算法检测到愤怒时可以提供缓解。而且，准备好在社交媒体或电子商务平台上看到根据你的情感状态动态变化的个性化广告吧。这就像拥有一个专属的情感管家！
- en: But how did we get here? The study takes us through a systematic literature
    review, developing two prototypes using machine learning and deep learning and
    rigorous model training using a vast data corpus comprising five audio databases.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们是如何来到这里的呢？这项研究通过系统的文献综述，开发了两个使用机器学习和深度学习的原型，并通过一个包含五个音频数据库的大型数据语料库进行了严格的模型训练。
- en: In the machine learning approach, the openSMILE framework works its magic, extracting
    features that are then normalized and used for classification. The Support Vector
    Machine (SVM) is the master classifier, identifying different sounds and seven
    distinct emotions in speech files. The prototype delivers results in under 1000
    milliseconds, captivating us with its speed and accuracy.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习方法中，openSMILE框架施展其魔力，提取特征，然后对这些特征进行标准化并用于分类。支持向量机（SVM）是主要的分类器，能够识别不同的声音和语音文件中的七种不同情感。该原型在1000毫秒内提供结果，以其速度和准确性令人着迷。
- en: But wait, there’s more! The deep learning model introduces Mel spectrograms,
    unlocking a new dimension of emotion recognition. With TensorFlow as its trusty
    companion, the Convolutional Neural Network (CNN) steps into the spotlight, mastering
    feature extraction and classification. The notebook and Raspberry Pi join the
    party, showcasing the model’s portability and efficiency.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，还有更多惊喜！深度学习模型引入了Mel谱图，解锁了情感识别的新维度。在TensorFlow的忠实伴随下，卷积神经网络（CNN）成为焦点，精通特征提取和分类。笔记本电脑和Raspberry
    Pi也加入了这个派对，展示了模型的便携性和效率。
- en: As the study unfolds, we witness the exciting potential of SER systems in enhancing
    human-computer interaction. Imagine a world where our devices understand our emotions,
    offering more human-like and intuitive responses. It’s a glimpse into the future
    of communication!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 随着研究的展开，我们见证了SER系统在增强人机交互方面的激动人心的潜力。想象一下一个我们的设备能够理解我们情感的世界，提供更类似人类和直观的响应。这是对未来沟通的瞥见！
- en: But the story doesn’t end here. The study leaves us hungry for more, hinting
    at future research avenues. Emotions beyond the primary six, exploring arousal
    and valence dimensions, investigating machine actions based on recognized emotions
    — the possibilities are vast. And what about different hyperparameters for model
    training and novel transfer learning techniques? The quest for deeper understanding
    and improved performance has just begun.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 但故事并未就此结束。这项研究让我们渴望更多，暗示了未来研究的方向。情感超越了主要的六种，探索唤醒和效价维度，调查基于识别情感的机器行为——可能性是巨大的。还有不同的模型训练超参数和新颖的迁移学习技术呢？对更深层次理解和改进性能的追求才刚刚开始。
- en: '**Ethical Concerns**'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**伦理问题**'
- en: One major ethical twist in this ride is informed consent and privacy. **Should
    our emotions be fair game for scrutiny without us even knowing?** It’s like a
    peek into our emotional diaries without our say-so. Transparency and getting our
    permission to analyze our emotions are the key checkpoints.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这次旅程中的一个重大伦理问题是知情同意和隐私。**我们的情感是否应该在我们不知情的情况下被审视？** 这就像是在未经允许的情况下窥探我们的情感日记。透明性和获得我们分析情感的许可是关键的检查点。
- en: Now, let’s talk about the adrenaline-pumping prospect of manipulation and exploitation.
    With great power comes great responsibility, and the real-time audience mood capture
    isn’t immune to abuse. Imagine politicians or advertisers exploiting your emotional
    state to their advantage. It’s like having puppeteers pulling emotional strings
    behind the curtain. We need safeguards and regulations in place to keep this tech
    in check.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们谈谈令人兴奋的操控和剥削的前景。权力越大，责任越大，实时观众情绪捕捉也不免受到滥用的风险。想象一下政治家或广告商利用你的情感状态为自己谋取利益。这就像幕后有提线木偶操控情感。我们需要保护措施和规定来确保这项技术受到控制。
- en: Algorithms can be sneaky devils, picking up on existing biases in our world.
    If those biases creep into the tech, **we look at an ethical minefield**. We must
    ensure fairness for all, regardless of race, gender, or background.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 算法可能是狡猾的家伙，会拾取我们世界中的现有偏见。如果这些偏见渗透到技术中，**我们就会面临伦理雷区**。我们必须确保公平对待每个人，无论种族、性别或背景如何。
- en: And what about emotional well-being? Continuous monitoring without our knowledge
    can mess with our minds. Feeling like Big Brother is watching your every emotion
    isn’t exactly a comforting thought. We need to safeguard our mental and emotional
    health on this ride.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 那么情感健康如何呢？在我们不知道的情况下持续监测可能会影响我们的心理。感觉像大哥在监视你的每一个情感，并不是一个令人安慰的想法。我们需要在这次旅程中保护我们的心理和情感健康。
- en: Of course, let’s not forget accuracy and reliability — critical checkpoints
    on our journey.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，别忘了准确性和可靠性——这是我们旅程中的关键检查点。
- en: Emotion recognition ain’t perfect, and relying on it for life-altering decisions
    is like trusting a rollercoaster with a missing bolt. We need assurance that the
    tech won’t leave us hanging upside down with false readings.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 情感识别并不完美，将其用于决定生活中的重大事项就像信任一个缺少螺栓的过山车。我们需要确保这项技术不会因错误的读数让我们悬挂在半空中。
- en: Manipulating emotions for personal gain sounds like a sci-fi dystopia, not our
    ideal theme park. Our choices and decisions should be ours, not puppeteered by
    sneaky emotion-tracking freaks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为个人利益操控情感听起来像科幻末日，而不是我们理想的主题公园。我们的选择和决定应该是我们的，而不是被狡猾的情感追踪者操控。
- en: Cultural sensitivity is a must! Emotions vary across cultures, like flavors
    in a global buffet. We can’t impose a one-size-fits-all emotional norm; that’d
    be like putting peanut butter on everything.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 文化敏感性是必须的！情感在不同文化中各异，就像全球自助餐中的各种风味。我们不能强加一种适合所有人的情感规范；那就像把花生酱涂在所有食物上一样。
- en: And while we’re at it, **let’s talk algorithmic transparency**. It’s like being
    stuck on a ride without knowing how it works. We need clear explanations of how
    this tech reaches its conclusions, so we don’t get stuck in an ethical loop-de-loop.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们提到这个话题，**让我们谈谈算法透明度**。这就像被困在一个不知道如何运作的过山车上。我们需要明确解释这项技术如何得出结论，这样我们就不会陷入伦理的回旋圈。
- en: We need to know who holds our emotional data and what they do with it. It’s
    like handing over the keys to our emotional kingdom; we better understand who’s
    driving.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要知道谁掌握了我们的情感数据以及他们如何处理这些数据。这就像把我们情感王国的钥匙交给别人；我们最好了解是谁在掌舵。
- en: With the proper precautions, we can ensure this tech delivers the wonders it
    promises without leaving us with a stomach-churning ethical hangover.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过适当的预防措施，我们可以确保这项技术实现它所承诺的奇迹，而不会让我们面临令人不安的伦理问题。
- en: '**A Personal Note on the Topic**'
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**关于这个话题的个人备注**'
- en: We take great pride in our achievement of successfully implementing emotion
    recognition techniques on a small computer like the Raspberry Pi.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为成功在像树莓派这样的微型计算机上实现情感识别技术感到非常自豪。
- en: However, it is essential to acknowledge the potential downsides that come with
    it. While I would be delighted if a computer I interact with could better perceive
    my emotions, I also harbor concerns about accidentally detecting my emotions when
    I do not desire such disclosure. Consequently, we must consider the ethical implications
    that lurk in the background of this entire study.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须认识到这一技术可能带来的潜在负面影响。虽然我会很高兴如果我互动的计算机能够更好地感知我的情感，但我也担心在我不希望透露情感时被意外检测到。因此，我们必须考虑这个研究背景中的伦理隐患。
- en: Addressing our research project’s ethical aspects becomes crucial in light of
    these considerations. Through our endeavors, I sincerely hope to illuminate an
    inspiring topic and spark meaningful conversations. Your feedback is awaited as
    we navigate this fascinating exploration together.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些考虑，研究项目的伦理方面变得尤为重要。通过我们的努力，我真诚希望能照亮一个令人振奋的话题，并激发有意义的讨论。我们在一起探索这个迷人的话题时，期待你的反馈。
- en: '**Scientific Article for Further Reading**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**进一步阅读的科学文章**'
- en: '*Andrade, D.E. De; Buchkremer, R. Enhancing Human-Machine Interaction: Real-Time
    Emotion Recognition through Speech Analysis. J. Comput. Sci. Res.* ***2023****,
    5, 22–45, doi:10.30564/jcsr.v5i3.5768.*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*Andrade, D.E. De; Buchkremer, R. 提升人机互动：通过语音分析进行实时情感识别。计算机科学研究杂志* ***2023****,
    5, 22–45, doi:10.30564/jcsr.v5i3.5768.*'
- en: '**If you have found this interesting:**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你觉得这很有趣：**'
- en: '*You can look for my other articles, and you can also connect or reach me on*[***LinkedIn***](https://www.linkedin.com/in/buchkremer/)***.***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可以查看我的其他文章，也可以通过*[***LinkedIn***](https://www.linkedin.com/in/buchkremer/)***与我联系或找到我。***'
