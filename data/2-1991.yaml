- en: 'The Beginning of Information Extraction: Highlight Key Words and Obtain Frequencies'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信息提取的起始：突出关键字并获取频率
- en: 原文：[https://towardsdatascience.com/the-beginning-of-information-extraction-highlight-key-words-and-obtain-frequencies-a03da0a1ba71](https://towardsdatascience.com/the-beginning-of-information-extraction-highlight-key-words-and-obtain-frequencies-a03da0a1ba71)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-beginning-of-information-extraction-highlight-key-words-and-obtain-frequencies-a03da0a1ba71](https://towardsdatascience.com/the-beginning-of-information-extraction-highlight-key-words-and-obtain-frequencies-a03da0a1ba71)
- en: A quick approach for highlighting keywords of interest within a PDF document
    and calculating their frequencies.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种快速的方法，用于在PDF文档中突出显示感兴趣的关键字并计算其频率。
- en: '[](https://ben-mccloskey20.medium.com/?source=post_page-----a03da0a1ba71--------------------------------)[![Benjamin
    McCloskey](../Images/7118f5933f2affe2a7a4d3375452fa4c.png)](https://ben-mccloskey20.medium.com/?source=post_page-----a03da0a1ba71--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a03da0a1ba71--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a03da0a1ba71--------------------------------)
    [Benjamin McCloskey](https://ben-mccloskey20.medium.com/?source=post_page-----a03da0a1ba71--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ben-mccloskey20.medium.com/?source=post_page-----a03da0a1ba71--------------------------------)[![本杰明·麦克洛斯基](../Images/7118f5933f2affe2a7a4d3375452fa4c.png)](https://ben-mccloskey20.medium.com/?source=post_page-----a03da0a1ba71--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a03da0a1ba71--------------------------------)[![数据科学](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a03da0a1ba71--------------------------------)
    [本杰明·麦克洛斯基](https://ben-mccloskey20.medium.com/?source=post_page-----a03da0a1ba71--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a03da0a1ba71--------------------------------)
    ·10 min read·Aug 28, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [数据科学](https://towardsdatascience.com/?source=post_page-----a03da0a1ba71--------------------------------)
    ·10分钟阅读·2023年8月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/47bf25395e329662fb5f9381919d3942.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47bf25395e329662fb5f9381919d3942.png)'
- en: Photo by [Judy Velazquez](https://unsplash.com/@roses_n_basil?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [朱迪·维拉斯克斯](https://unsplash.com/@roses_n_basil?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: With the amount of available information increasing every day, having the ability
    to quickly gather relevant statistics about said information is important for
    relationship mapping and acquiring a new perspective on otherwise redundant data.
    Today we will look at text extraction, also known as information extraction, of
    PDFs and a quick approach to formulating some facts and ideas about different
    corpora. Today’s article dives into the field of Natural Language Processing (NLP),
    which is a computer’s ability to comprehend human language.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着每天可用信息量的增加，能够快速收集相关统计数据对于关系映射和获取对重复数据的新视角变得至关重要。今天我们将深入探讨PDF文本提取，也称为信息提取，以及对不同语料库进行快速事实和想法的形成。今天的文章深入探讨了自然语言处理（NLP）的领域，这是计算机理解人类语言的能力。
- en: Information Extraction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信息提取
- en: '**Information Extraction (IE)**, as defined by Jurafsky et al, is the *“process
    for turning unstructured information embedded in texts into structured data.”*
    [1]. A very quick way of information extraction is not only to search to find
    if a word is located within a body of the text but also to calculate the *frequency*
    of how many times that word is mentioned. This is supported by the assumption
    that **the more a word is mentioned within a body of text, the more important
    it is and its relation to the corpus’s theme.** It’s important to note that stopword
    removal is important for this given process. Why? Well, if you simply calculated
    all of the word frequencies within a corpus, the word *the* will be mentioned
    a lot. Does that make this word important in terms of relaying what information
    is within the text? No, and therefore you want to ensure you are looking at frequencies
    of words that contribute to the semantic meaning of your corpora.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**信息提取（IE）**，正如Jurafsky等人所定义的，是*“将嵌入文本中的非结构化信息转化为结构化数据的过程。”*[1]。一种非常快速的信息提取方法不仅是搜索以查找某个词是否出现在文本中，还包括计算该词提到的*频率*。这一点的支持是基于**一个词在文本中出现得越多，它就越重要，并且与语料库的主题关系越大。**
    重要的是要注意，停用词的去除对于这个过程非常重要。为什么？因为如果你简单地计算语料库中所有单词的频率，像*the*这样的词会被提到很多次。这是否意味着这个词在传达文本信息方面很重要？不，因此你需要确保你关注的是那些有助于语料库语义意义的词汇频率。'
- en: IE can lead to other NLP techniques being used on a document. These techniques
    go beyond the code of this article but I felt they were both interesting and important
    the share.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 信息提取（IE）可以导致在文档中使用其他自然语言处理技术。这些技术超出了本文的代码范围，但我认为它们既有趣又重要，因此值得分享。
- en: The first technique is **Named Entity Recognition (NER).** As detailed by Jurafsky
    et al. *“The task of named entity recognition (NER) is to find each named entity
    recognition mention of a named entity in the text and label its type.”* [1] This
    is similar to the idea of searching for the frequencies of the words within a
    body of text, but NER takes it another step further by using word location as
    well as other literary rules for finding different entities within a body of text.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种技术是**命名实体识别（NER）**。正如Jurafsky等人详细说明的那样，*“命名实体识别（NER）的任务是找到文本中每个命名实体的提及并标注其类型。”*[1]
    这类似于在文本中搜索单词频率的想法，但NER更进一步，通过使用单词的位置以及其他文献规则来寻找文本中的不同实体。
- en: Another technique that can be supported by IE is **Relation Extraction,** which
    is “*finding and classifying semantic relation extraction relations among the
    text entities*.” [1]. The goal is not only to be able to extract how frequently
    different words are in text, and the entity label for which they fall, but also
    how we can relate these different entities together to formulate either the underlying
    semantic meaning, patterns, or summary of a corpus of text.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 信息提取（IE）还可以支持另一种技术，即**关系抽取**，这就是“*在文本实体之间找到并分类语义关系抽取*。”[1]。目标不仅是提取文本中不同词汇出现的频率以及它们所属的实体标签，还要如何将这些不同的实体联系在一起，以形成语料库的潜在语义意义、模式或摘要。
- en: The previous three tasks all relate to the goal of **Event Extraction**. Jurafsky
    et al. go on to state that “E*vent extraction is finding event extraction events
    in which these entities participate*.” [1]. What this says is that by finding
    and extracting different statistics and labels from a body of text, we can begin
    to articulate hypotheses on what event is occurring from these events and how,
    through these entities, different events may be related.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的三个任务都与**事件抽取**的目标相关。Jurafsky等人进一步指出，“*事件抽取是寻找这些实体参与的事件*。”[1]。这意味着，通过从文本中寻找和提取不同的统计数据和标签，我们可以开始阐述关于这些事件发生的假设，并且通过这些实体了解不同事件之间可能存在的关系。
- en: The Process
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过程
- en: '![](../Images/8159545b1b4c139fe00c8330cdfd9684.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8159545b1b4c139fe00c8330cdfd9684.png)'
- en: Process (Image from Author)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 过程（图像来源于作者）
- en: The goal of this process is to get a quick understanding of whether a corpus
    of text not only has information relating to what you are looking for but also
    to give the frequency for understanding if there is enough of said information
    to make comparisons between different documents. Finally, it provides a visualization
    of the queried word highlighted in the text which can help with drawing conclusions
    about relationships and what the text is about based on the surrounding words.
    The entire process was implemented in Python using Google Colab and can be easily
    transferred to any IDE of your choice. Let’s take a look at the code!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程的目标是快速了解一个文本语料库是否不仅包含与您所寻找的信息相关的内容，而且还提供频率数据，以便判断是否有足够的信息来进行不同文档之间的比较。最后，它提供了查询词在文本中高亮显示的可视化，这有助于根据周围的词语得出关于关系和文本内容的结论。整个过程是用Python在Google
    Colab中实现的，可以轻松地转移到您选择的任何IDE中。让我们看看代码吧！
- en: The Code
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: The Python libraries needed for this code are [**PyMuPDF**](https://pypi.org/project/PyMuPDF/)
    and [**Counter**](https://pypi.org/project/Counter/).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码所需的Python库是[**PyMuPDF**](https://pypi.org/project/PyMuPDF/)和[**Counter**](https://pypi.org/project/Counter/)。
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we will create a function called “hightlight_terms” which accepts an input
    pdf, a path to an output pdf, a path to an output text file, and the terms we
    want to be highlighted.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个名为“highlight_terms”的函数，该函数接受一个输入PDF，一个输出PDF的路径，一个输出文本文件的路径，以及我们希望高亮显示的术语。
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once we create the function, we can set up the file paths to our different directories.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了函数，就可以设置文件路径到我们的不同目录。
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: And that’s it, easy as that! This can be super helpful for your analysis in
    getting a quick understanding of how relevant a certain word (or words) is in
    a document. In addition, when viewing the highlighted output PDF, outlining the
    location of a word can help draw your attention and make relationships to other
    words surrounding the queried word.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，简单如斯！这对于分析时快速了解某个词（或词组）在文档中的相关性非常有帮助。此外，当查看高亮显示的输出PDF时，标出词语的位置可以帮助引起您的注意，并与查询词周围的其他词语建立关系。
- en: Example
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: In today’s example, let’s look at a scholarly article from Google Scholar. What
    if, for example, I wanted to know if an article had adequate information about
    *Neural Networks?* We can query the document and then use the queried frequencies
    to make an assessment about whether the document focuses on Neural Networks. The
    first document we will look at is titled *ImageNet Classification with Deep Convolutional
    Neural Networks* [2].
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的示例中，让我们看看来自Google Scholar的一篇学术文章。如果我想知道一篇文章是否有足够的信息关于*Neural Networks*，该怎么办呢？我们可以查询文档，然后使用查询到的频率来评估文档是否集中于神经网络。我们将查看的第一篇文档标题为*ImageNet
    Classification with Deep Convolutional Neural Networks*[2]。
- en: '![](../Images/90c65f51feba69d4bbcabeb2de382308.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/90c65f51feba69d4bbcabeb2de382308.png)'
- en: Let’s say, for example, we are interested in studying Neural Networks and want
    to see where and how many times those words appear within the text. By querying
    *Neural* and *Networks*, we will get a highlighted pdf, as shown below.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，我们对研究神经网络感兴趣，并想查看这些词在文本中出现的次数和位置。通过查询*Neural*和*Networks*，我们将得到一个高亮显示的PDF，如下所示。
- en: '![](../Images/fdf3a14fdd05475fd47ceac46e7036a8.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdf3a14fdd05475fd47ceac46e7036a8.png)'
- en: Additionally, a text file will be created with the frequencies of both *Neural*
    and *Network*, which were 21 and 23, respectively. The frequency number really
    depends on the user whether a word is mentioned enough in a document to deem it
    relevant. With both words appearing over 20 times within the document, I would
    argue they are relevant to its context.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还将创建一个文本文件，记录*Neural*和*Network*这两个词的出现频率，分别为21和23。词频的多少确实取决于用户是否认为某个词在文档中提及的次数足够，以至于被认为是相关的。由于这两个词在文档中出现超过20次，我认为它们与文档的上下文相关。
- en: This process can easily be expanded to multiple documents where you can then
    compare the frequencies of certain words between different documents. In doing
    so, we can compare documents and come to conclusions about which documents are
    more related to the information we are seeking to find.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以轻松扩展到多个文档中，然后可以比较不同文档之间某些词的频率。通过这样做，我们可以比较文档，并得出哪些文档与我们寻求的信息更相关的结论。
- en: Limitations
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制
- en: While the approach is simple and completes the desired task at hand, there are
    a few limitations worth discussing.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种方法简单且能够完成所需的任务，但还是有一些值得讨论的限制。
- en: The assumption that the higher frequency a word has in a corpus means it may
    support the underlying meaning more does not always hold.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词汇在语料库中出现的频率越高就越能支持其潜在含义的假设并不总是成立。
- en: Querying for the wrong words could cause you to not uncover the correct meaning
    of a body of text or find the information you are looking for.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询错误的词汇可能导致你无法揭示文本的正确含义或找到你所寻找的信息。
- en: The methodology is more of a summarization of information extraction and provides
    a starting point for a more in-depth analysis.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该方法论更多地是对信息提取的总结，并为更深入的分析提供了一个起点。
- en: The first limitation around the assumption asserts that the more frequently
    a word is used, the more it supports the underlying meaning of the text depending
    on the author publishing the work and how they wish to express their ideas does
    not always hold true. Additionally, different words can be used to describe the
    same meaning, and by only focusing on a few different words and their high frequencies
    you may find yourself attaching the wrong meaning to a corpus of text.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 关于假设的第一个局限性认为，词汇使用得越频繁，就越能支持文本的潜在含义，这取决于作者的发表方式和他们如何表达自己的观点，并不总是成立。此外，不同的词汇可以用来描述相同的含义，而仅关注几个高频词汇，你可能会发现自己对文本语料库附加了错误的含义。
- en: The second limitation derives from the first regarding the word queries. If
    you are not querying the correct words, you may be missing the important underlying
    meeting of the corpus of text. One way to overcome this could be to convert the
    PDF to a text document using PyMuPDF or PyPDF2 and then calculate the N most frequent
    words. From there you can use those frequencies to find where those words are
    located in the body of text which can help help you find where the most important
    information sits.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个局限性来自于第一个关于词汇查询的限制。如果你没有查询正确的词汇，可能会错过文本语料库的重要潜在含义。克服这一点的一种方法是使用 PyMuPDF 或
    PyPDF2 将 PDF 转换为文本文档，然后计算出现频率最高的 N 个词。从这些频率中，你可以找出这些词在文本中的位置，这有助于你找到最重要的信息所在。
- en: 'The third limitation of today’s methodology is that it does not go more in-depth
    into information extraction. With that being said, this code does set you up nicely
    to begin your text extraction project and can be branched off into a few different
    directions. Here are some possible ways you can move out from this process:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 今日方法论的第三个局限性是它没有深入到信息提取的层面。不过，这段代码确实很好地为你开始文本提取项目奠定了基础，并可以衍生出几个不同的方向。以下是一些你可以从这个过程继续发展的可能方式：
- en: begin comparing documents and selecting documents where a certain word and its
    frequency are higher
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始比较文档，选择某个词及其频率较高的文档。
- en: Asses the highlighted regions of a document and create a script that will extract
    these regions. From there, perform sentiment analysis on each of the sentences.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估文档中突出显示的区域，并创建一个脚本来提取这些区域。然后，对每个句子进行情感分析。
- en: Same approach as just mentioned except now to perform topic modeling analysis.
    Any sentence where a word is highlighted will be used to support the different
    topics within the text.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与刚才提到的方法相同，只不过现在要执行主题建模分析。任何被突出显示的句子都将用于支持文本中的不同主题。
- en: Benefits
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优势
- en: While I mentioned there are limitations to this process, it does still have
    a few benefits and I believe you will find some utility in its use. First, it
    can show us how relevant a word is in different bodies of text. This can be helpful
    in academic research especially when you are studying a certain topic. If I’m
    studying machine learning, and one academic article mentions it more than another,
    I may be more inclined to look at that article first. Once I pick an article,
    this process will then highlight where the words sit in that article. Instead
    of mindlessly having to sift through the literature, this process centers our
    attention right where the information lies within a body of text. Talk about time
    savings!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我提到这个过程存在一些局限性，但它确实有一些好处，我相信你会发现它的使用有些实用之处。首先，它可以展示一个词在不同文本中的相关性。这在学术研究中尤其有帮助，特别是当你在研究某个主题时。如果我在研究机器学习，而一篇学术文章提到它的频率比另一篇高，我可能更倾向于先查看那篇文章。一旦我选择了一篇文章，这个过程将突出显示词汇在该文章中的位置。与其盲目地筛选文献，这个过程将我们的注意力集中在文本中的信息所在之处。说到节省时间！
- en: Another benefit of this process is you can use it to begin highlighting where
    certain sentences are which may be useful if you wish to cite information from
    documents in different pieces of work. Being able to trace back where you found
    said information is not only important for providing proof to the viewers of your
    work of where the information was accumulated from, but also it’s a great way
    to ensure you are not plagiarizing your work. I tutor many students and I have
    used this process to highlight different articles for them so they can see where
    I was getting my work from (based on the topic we were studying) and use the highlighted
    documents as a reference for studying.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的另一个好处是你可以开始标记某些句子的位置，这可能对你引用不同文档中的信息时非常有用。能够追溯到你找到这些信息的地方不仅对提供证据给你的观众很重要，也是一种确保你不会抄袭的好方法。我辅导了许多学生，并且使用这个过程为他们标记不同的文章，以便他们看到我从哪里获得我的工作（根据我们研究的主题），并将标记的文档作为学习的参考。
- en: Finally, this process is a great kickstart to your text extraction project.
    It gathers preliminary statistics to begin shaping the direction of your project
    as well as offers you a visual piece for understanding a body of text and having
    evidence of innate meaning to give to your customer. A real-world example of this
    was, I was developing a project for a customer who worked primarily in the food
    industry. They wanted to know if this giant document (hundreds of pages) they
    were given mentioned any of the goods they were seeking to sell and they also
    wanted to know who those goods were associated with. I was able to query the different
    goods they sell and provide the document back with the products highlighted in
    the document for quick referencing. They really enjoyed it! My only suggestion
    would be to also begin annotating page numbers because that will cut down analysis
    time even more!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个过程是你文本提取项目的绝佳起点。它收集初步统计数据，以开始塑造项目方向，并提供一个可视化的文本理解工具，并为客户提供内在含义的证据。一个真实的例子是，我为一位主要在食品行业工作的客户开发了一个项目。他们想知道他们收到的这份巨大文档（数百页）是否提到他们寻求销售的商品，并且还想知道这些商品与谁相关。我能够查询他们销售的不同商品，并将文档中的产品高亮显示，以便快速参考。他们非常喜欢！我的唯一建议是开始注释页码，这将进一步缩短分析时间！
- en: Conclusion
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Today we looked at how you could analyze a PDF document, and find and locate
    words of interest within the document. Additionally, we can collect the frequencies
    of the queried words to gain a better understanding of the possible meaning of
    a corpus of text and if it is related to what we desire to know more about. Information
    extraction is critical because it can help us not only find relationships between
    different entities but also provide us with insights into possible patterns of
    actions and events conducted by these related entities and across various documents.
    Try this code out and I hope it helps you in your next NLP project!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 今天我们讨论了如何分析PDF文档，找到并定位文档中的感兴趣词汇。此外，我们还可以收集查询词汇的频率，以更好地理解文本语料的可能含义，以及是否与我们想要深入了解的内容相关。信息提取至关重要，因为它不仅帮助我们发现不同实体之间的关系，还能提供关于这些相关实体和不同文档中可能出现的行为模式和事件的洞察。试试这个代码，希望它对你下一个自然语言处理项目有所帮助！
- en: '**If you enjoyed today’s reading, PLEASE give me a follow and let me know if
    there is another topic you would like me to explore! If you do not have a Medium
    account, sign up through my link** [**here**](https://ben-mccloskey20.medium.com/membership)
    **(I receive a small commission when you do this)! Additionally, add me on** [**LinkedIn**](https://www.linkedin.com/in/benjamin-mccloskey-169975a8/),
    **or feel free to reach out! Thanks for reading!**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你喜欢今天的阅读，请关注我，并告诉我是否有其他话题你希望我深入探讨！如果你没有Medium账户，可以通过我的链接** [**这里**](https://ben-mccloskey20.medium.com/membership)
    **注册（这样我会获得小额佣金）！此外，可以在** [**LinkedIn**](https://www.linkedin.com/in/benjamin-mccloskey-169975a8/)
    **上添加我，或者随时联系我！感谢阅读！**'
- en: Sources
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来源
- en: '[https://web.stanford.edu/~jurafsky/slp3/old_oct19/17.pdf](https://web.stanford.edu/~jurafsky/slp3/old_oct19/17.pdf)'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://web.stanford.edu/~jurafsky/slp3/old_oct19/17.pdf](https://web.stanford.edu/~jurafsky/slp3/old_oct19/17.pdf)'
- en: '[https://dl.acm.org/doi/10.5555/2999134.2999257](https://dl.acm.org/doi/10.5555/2999134.2999257)'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://dl.acm.org/doi/10.5555/2999134.2999257](https://dl.acm.org/doi/10.5555/2999134.2999257)'
