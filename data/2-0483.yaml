- en: Chain of Thought Prompting Facilitate LLMs Reasoning Abilities
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思维链提示促进了LLMs的推理能力
- en: 原文：[https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938](https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938](https://towardsdatascience.com/chain-of-thought-prompting-facilitate-llms-reasoning-abilities-313cd7714938)
- en: Demonstrated with examples
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过示例展示
- en: '[](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[![Soner
    Yıldırım](../Images/c589572e9d1ee176cd4f5a0008173f1b.png)](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)[](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    [Soner Yıldırım](https://sonery.medium.com/?source=post_page-----313cd7714938--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)
    ·6 min read·Jun 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----313cd7714938--------------------------------)·阅读时间6分钟·2023年6月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/002f67384a5ad5ec102fb526b86c9eea.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/002f67384a5ad5ec102fb526b86c9eea.png)'
- en: Photo by [Juan Rumimpunu](https://unsplash.com/@earbiscuits?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/nLXOatvTaLo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Juan Rumimpunu](https://unsplash.com/@earbiscuits?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)提供，来源于[Unsplash](https://unsplash.com/photos/nLXOatvTaLo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Large language models (LLMs) are proven to be highly efficient at solving a
    variety of tasks from summarizing documents to writing code in different programming
    languages.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）被证明在解决各种任务方面非常高效，从总结文档到用不同编程语言编写代码。
- en: Moreover, they just get better with newly announced models like ChatGPT and
    GPT-4, unlocking a world of opportunities with LLM-based applications.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，新发布的模型如ChatGPT和GPT-4使得LLMs的表现更加出色，为基于LLM的应用解锁了更多机会。
- en: Contrary to their extraordinary skills, LLMs sometimes fail to demonstrate very
    simple reasoning abilities and fail to solve questions that can easily be tackled
    down by a fourth grader.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大型语言模型（LLMs）具有非凡的技能，但它们有时未能展示非常简单的推理能力，无法解决一个四年级学生都能轻松处理的问题。
- en: A lot of research has been done in this area aiming to understand why LLMs fail
    to perform such tasks and to make them get better.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一领域已经进行了大量研究，旨在理解为何LLMs无法执行此类任务并使其表现更好。
- en: One study that focuses on this particular issue is [chain-of-thought prompting](https://arxiv.org/abs/2201.11903),
    introduced by Google research, brain team.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 关注这个特定问题的一个研究是[思维链提示](https://arxiv.org/abs/2201.11903)，由谷歌研究团队介绍。
- en: Chain-of-thought prompting
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 思维链提示
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A prompting technique with a structure of {input, chain-of-thought, output},
    where chain-of-thought is a series of intermediate natural language reasoning
    steps.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一种结构为{输入、思维链、输出}的提示技术，其中思维链是一系列中间自然语言推理步骤。
- en: The models are given a few examples with input and output (few-shot learning)
    and then asked a question that involves a multi-step or arithmetic reasoning tasks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 模型会接收到一些包含输入和输出的示例（少样本学习），然后被要求解决一个涉及多步骤或算术推理任务的问题。
- en: 'The key takeaways from the [paper](https://arxiv.org/abs/2201.11903):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[论文](https://arxiv.org/abs/2201.11903)的主要结论：'
- en: Chain-of-thought prompting outperforms standard prompting
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思维链提示优于标准提示
- en: The difference between chain-of-thought prompting and standard prompting becomes
    more evident on larger models. The performance increase with chain-of-prompting
    is proportional to the number of parameters of the model.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思维链提示与标准提示之间的区别在于较大的模型上更为明显。思维链提示的性能提升与模型的参数数量成正比。
- en: 'The chain-of-thought prompting technique is simply solving the problem step-by-step.
    Each step is based on logical reasoning. Here is an example:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 思路链提示技术就是逐步解决问题。每一步都基于逻辑推理。这里是一个示例：
- en: 'Question: John has 2 houses. Each house has 3 bedrooms and there are 2 windows
    in each bedroom. Each house has 1 kitchen with 2 windows. Also, each house has
    5 windows that are not in the bedrooms or kitchens.'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 问题：约翰有2栋房子。每栋房子有3间卧室，每间卧室有2个窗户。每栋房子有1个厨房，厨房有2个窗户。此外，每栋房子还有5个窗户不在卧室或厨房中。
- en: How many windows are there in John’s houses?
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 约翰的房子里有多少个窗户？
- en: ''
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Answer: Each house has 3 bedrooms with 2 windows each, which makes it 6 bedroom
    windows. Each house has 1 kitchen with 2 windows, which makes it 2 kitchen windows.
    There are also 5 windows that are not in the kitchen or bedroom. So there are
    6 + 2 + 5 = 13 windows per house. Since there are 2 houses, there are 2 x 13 =
    26 houses in John’s houses.'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 答案：每栋房子有3间卧室，每间卧室有2个窗户，共计6个卧室窗户。每栋房子有1个厨房，厨房有2个窗户，共计2个厨房窗户。还有5个窗户不在厨房或卧室中。因此，每栋房子有6
    + 2 + 5 = 13个窗户。由于有2栋房子，所以约翰的房子里总共有2 x 13 = 26个窗户。
- en: You can follow different steps to reach the correct answer. For such questions,
    there are almost always more than one path to get to the answer.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以遵循不同的步骤来获得正确的答案。对于这类问题，几乎总有多条路径可以到达答案。
- en: 'In standard prompting, we’d just ask the above question to an LLM and expect
    it to give the answer. Let’s try it:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准提示中，我们通常会向语言模型提出上述问题，并期望它给出答案。让我们试试：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Wrong answer!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的答案！
- en: We don’t know how the model gets this answer, which brings us to another advantage
    of chain-of-thought prompting. The model responds with a step-by-step answer,
    which makes the debugging process easier. We can easily spot where things go wrong.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道模型如何得到这个答案，这带来了思路链提示的另一个优点。模型以逐步回答的方式回应，这使得调试过程更容易。我们可以很容易地发现问题所在。
- en: With chain-of-prompting technique, we add a few questions and their answers
    to the prompt to do few-shot prompting. The answers are in the form of a step-by-step
    solution (i.e. demonstrates a chain-of-thought).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通过思路链提示技术，我们在提示中添加了一些问题及其答案，以进行少量示例提示。这些答案以逐步解决方案的形式出现（即展示思路链）。
- en: 'Here is the updated prompt and the response of the model:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是更新后的提示和模型的回应：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Correct answer!
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的答案！
- en: The response is a step-by-step explanation of the thought process of the model
    (chain-of-thought) just like the examples shown in the prompt.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 回应是对模型思考过程的逐步解释（思路链），就像提示中展示的示例一样。
- en: 'Let’s go over another example. Here is the standard prompting version:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个例子。这里是标准提示版本：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Wrong answer!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的答案！
- en: 'Let’s try the same question with chain-of-thought prompting by providing a
    few input-output examples (few-shot learning):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试用思路链提示回答相同的问题，提供一些输入输出示例（少量示例学习）：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Correct answer!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的答案！
- en: Final words
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束语
- en: The chain-of-thought prompting clearly increases the ability of LLMs at certain
    tasks. I suggest reading the entire [paper](https://arxiv.org/abs/2201.11903)
    if you’d like to learn more about the experiments they conducted.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 思路链提示明显提高了语言模型在某些任务上的能力。如果你想了解更多关于他们进行的实验，建议阅读整篇[论文](https://arxiv.org/abs/2201.11903)。
- en: It is important to note that, as also mentioned in the paper, the benefits of
    chain-of-thought prompting only become evident when applied to models with approximately
    100 billion parameters, and it doesn’t significantly enhance the performance of
    smaller models.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，正如论文中提到的，思路链提示的好处只有在应用于大约1000亿参数的模型时才会显现，并且对较小模型的性能提升并不显著。
- en: The experiment results yield to the conclusion that smaller models produce fluent
    but illogical chains of thought, which leads to a worse performance than standard
    prompting.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果得出的结论是，较小的模型会产生流畅但不合逻辑的思路链，这导致其表现比标准提示更差。
- en: References
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Wei, Jason, et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large
    Language Models. ArXiv. [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Wei, Jason, 等（2022）。思路链提示引发大型语言模型的推理。ArXiv。[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
