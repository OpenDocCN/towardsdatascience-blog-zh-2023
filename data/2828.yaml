- en: 'Tensor Quantization: The Untold Story'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量量化：未被讲述的故事
- en: 原文：[https://towardsdatascience.com/tensor-quantization-the-untold-story-d798c30e7646?source=collection_archive---------2-----------------------#2023-09-08](https://towardsdatascience.com/tensor-quantization-the-untold-story-d798c30e7646?source=collection_archive---------2-----------------------#2023-09-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tensor-quantization-the-untold-story-d798c30e7646?source=collection_archive---------2-----------------------#2023-09-08](https://towardsdatascience.com/tensor-quantization-the-untold-story-d798c30e7646?source=collection_archive---------2-----------------------#2023-09-08)
- en: A close look at the implementation details of quantization in machine learning
    frameworks
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 详细了解机器学习框架中量化的实现细节
- en: '[](https://medium.com/@dhruvbird?source=post_page-----d798c30e7646--------------------------------)[![Dhruv
    Matani](../Images/d63bf7776c28a29c02b985b1f64abdd3.png)](https://medium.com/@dhruvbird?source=post_page-----d798c30e7646--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d798c30e7646--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d798c30e7646--------------------------------)
    [Dhruv Matani](https://medium.com/@dhruvbird?source=post_page-----d798c30e7646--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@dhruvbird?source=post_page-----d798c30e7646--------------------------------)[![Dhruv
    Matani](../Images/d63bf7776c28a29c02b985b1f64abdd3.png)](https://medium.com/@dhruvbird?source=post_page-----d798c30e7646--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d798c30e7646--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d798c30e7646--------------------------------)
    [Dhruv Matani](https://medium.com/@dhruvbird?source=post_page-----d798c30e7646--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F63f5d5495279&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensor-quantization-the-untold-story-d798c30e7646&user=Dhruv+Matani&userId=63f5d5495279&source=post_page-63f5d5495279----d798c30e7646---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d798c30e7646--------------------------------)
    ·8 min read·Sep 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd798c30e7646&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensor-quantization-the-untold-story-d798c30e7646&user=Dhruv+Matani&userId=63f5d5495279&source=-----d798c30e7646---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F63f5d5495279&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensor-quantization-the-untold-story-d798c30e7646&user=Dhruv+Matani&userId=63f5d5495279&source=post_page-63f5d5495279----d798c30e7646---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d798c30e7646--------------------------------)
    ·8分钟阅读·2023年9月8日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd798c30e7646&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensor-quantization-the-untold-story-d798c30e7646&user=Dhruv+Matani&userId=63f5d5495279&source=-----d798c30e7646---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd798c30e7646&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensor-quantization-the-untold-story-d798c30e7646&source=-----d798c30e7646---------------------bookmark_footer-----------)![](../Images/a22f43f23f8aac57d5a7eb5b46fcbb6b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd798c30e7646&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftensor-quantization-the-untold-story-d798c30e7646&source=-----d798c30e7646---------------------bookmark_footer-----------)![](../Images/a22f43f23f8aac57d5a7eb5b46fcbb6b.png)'
- en: Co-authored with [Naresh Singh](https://medium.com/@brocolishbroxoli).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 与 [Naresh Singh](https://medium.com/@brocolishbroxoli) 合著。
- en: Table Of Contents
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录
- en: '[Introduction](#1d38)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍](#1d38)'
- en: '[What do the terms scale and zero-point mean for quantization?](#038c)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[量化中的尺度和零点这两个术语是什么意思？](#038c)'
- en: '[Types of Quantization Schemes](#b2df)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[量化方案的类型](#b2df)'
- en: '[Quantization Scale and Zero Point examples](#0dd2)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[量化尺度和零点示例](#0dd2)'
- en: '[Quantization and Activation Normalization](#3046)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[量化与激活归一化](#3046)'
- en: '[Conclusion](#8bf9)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[结论](#8bf9)'
- en: '[References](#390b)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[参考文献](#390b)'
- en: Introduction
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Throughout the rest of this article, we will try to answer the following questions
    with concrete examples.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的剩余部分，我们将尝试通过具体示例回答以下问题。
- en: What do the terms scale and zero-point mean for quantization?
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 量化中的尺度和零点这两个术语是什么意思？
- en: What are the different types of quantization schemes?
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不同的量化方案有哪些类型？
- en: How to compute scale and zero-point for the different quantization schemes
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何计算不同量化方案的尺度和零点
- en: Why is zero-point important for quantization?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么零点对于量化很重要？
- en: How do normalization techniques benefit quantization
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 归一化技术如何有利于量化
- en: What do the terms scale and zero-point mean for quantization?
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量化中的尺度和零点是什么意思？
- en: '**Scale:** When quantizing a floating point range, one would typically represent
    a floating point range [Fmin..Fmax] in the quantized range [Qmin..Qmax]. In this
    case, the scale is the ratio of the floating point range and the quantized range.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**尺度：** 在量化浮点范围时，通常会将浮点范围[Fmin..Fmax]表示为量化范围[Qmin..Qmax]。在这种情况下，尺度是浮点范围和量化范围的比率。'
- en: '![](../Images/5581bf2fe1446f4e490eb3e7364dac38.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5581bf2fe1446f4e490eb3e7364dac38.png)'
- en: We will see an example of how to compute it later.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后将看到如何计算它的示例。
- en: '**Zero-point:** The zero-point for quantization is the representation of floating
    point 0.0 in the quantized range. Specifically, the zero-point is a quantized
    value, and it represents the floating point value 0.0 for all practical purposes.
    We shall see how it’s computed with examples later, along with why such a representation
    is of practical interest to us.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**零点：** 量化的零点是量化范围中浮点0.0的表示。具体来说，零点是一个量化值，它代表浮点值0.0，满足所有实际用途。稍后我们将通过示例看到它是如何计算的，以及这种表示对我们为何具有实际意义。'
- en: Next, let’s take a look at the main quantization schemes used in practice and
    familiarize ourselves with how they are similar and how they differ.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查看实际中使用的主要量化方案，并熟悉它们的相似之处和不同之处。
- en: Types of Quantization Schemes
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量化方案类型
- en: When considering the types of quantization available for use during model compression,
    there are 2 main types to pick from
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑用于模型压缩的量化类型时，有两种主要类型可以选择。
- en: '**Symmetric quantization**: In this case, the zero-point is zero — i.e. 0.0
    of the floating point range is the same as 0 in the quantized range. Typically,
    this is more efficient to compute at runtime but may result in lower accuracy
    if the floating point range is unequally distributed around the floating point
    0.0.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**对称量化：** 在这种情况下，零点是零 —— 即浮点范围的0.0与量化范围中的0相同。通常，这种方法在运行时计算更高效，但如果浮点范围在浮点0.0周围不均匀分布，可能会导致较低的准确度。'
- en: '**Affine (or asymmetric) quantization**: This is the one that has a zero-point
    that is non-zero in value.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**仿射（或非对称）量化：** 这是具有非零值零点的量化方法。'
- en: But before we jump into the details, let’s try to define what zero-point means.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但在深入细节之前，让我们尝试定义一下零点是什么意思。
- en: Quantization Scale and Zero Point examples
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量化尺度和零点示例
- en: Let’s start with a very simple example and build it up.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个非常简单的例子开始，并逐步构建起来。
- en: 'Example-1: Symmetric uint8 quantization'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例-1：对称uint8量化
- en: Let’s say we wish to map the floating point range [0.0 .. 1000.0] to the quantized
    range [0 .. 255]. The range [0 .. 255] is the set of values that can fit in an
    unsigned 8-bit integer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望将浮点范围[0.0 .. 1000.0]映射到量化范围[0 .. 255]。范围[0 .. 255]是一组可以适合无符号8位整数的值。
- en: '![](../Images/850c70ba5537ced2267365e6c52f714b.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/850c70ba5537ced2267365e6c52f714b.png)'
- en: 'To perform this transformation, we want to rescale the floating point range
    so that the following is true:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行这种转换，我们希望重新调整浮点范围，使得以下条件成立：
- en: Floating point 0.0 = Quantized 0
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 浮点0.0 = 量化0
- en: Floating point 1000.0 = Quantized 255
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 浮点1000.0 = 量化255
- en: This is called symmetric quantization because the floating point 0.0 is quantized
    0.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为对称量化，因为浮点0.0被量化为0。
- en: Hence, we define a scale, which is equal to
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们定义一个尺度，其等于
- en: '![](../Images/c82de58dacb9ed664f5ec470c9c1af06.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c82de58dacb9ed664f5ec470c9c1af06.png)'
- en: Where,
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: '![](../Images/33ff9ebd7202cf25d953b8c6b1484bfd.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33ff9ebd7202cf25d953b8c6b1484bfd.png)'
- en: In this case, scale = 3.9215
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，尺度= 3.9215
- en: To convert from a floating point value to a quantized value, we can simply divide
    the floating point value by the scale. For example, the floating point value 500.0
    corresponds to the quantized value
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要将浮点值转换为量化值，我们可以简单地将浮点值除以尺度。例如，浮点值500.0对应于量化值
- en: '![](../Images/87ad1feedc2e3b4ceff1e37848a943ec.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87ad1feedc2e3b4ceff1e37848a943ec.png)'
- en: In this simple example, the 0.0 of the floating point range maps exactly to
    the 0 in the quantized range. This is called symmetric quantization. Let’s see
    what happens when this is not the case.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的例子中，浮点范围的0.0恰好映射到量化范围中的0。这被称为对称量化。让我们看看当情况不是这样时会发生什么。
- en: 'Example-2: Affine uint8 quantization'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例-2：仿射uint8量化
- en: Let’s say we wish to map the floating point range [-20.0 .. 1000.0] to the quantized
    range [0 .. 255].
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望将浮点范围[-20.0 .. 1000.0]映射到量化范围[0 .. 255]。
- en: '![](../Images/def44e61e639cd134c4e764456991cae.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/def44e61e639cd134c4e764456991cae.png)'
- en: In this case, we have a different scaling factor since our *xmin* is different.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，由于我们的*xmin*不同，所以我们有一个不同的缩放因子。
- en: '![](../Images/054faad1712ca2ccce30b743311a235a.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/054faad1712ca2ccce30b743311a235a.png)'
- en: Let’s see what the floating point number 0.0 is represented by in the quantized
    range if we apply the scaling factor to 0.0
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将缩放因子应用于0.0，看看浮点数0.0在量化范围中是如何表示的
- en: '![](../Images/1f7c7e7499505ca2a530c2822ddb729e.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f7c7e7499505ca2a530c2822ddb729e.png)'
- en: Well, this doesn’t quite seem right since, according to the diagram above, we
    would have expected the floating point value -20.0 to map to the quantized value
    0.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这似乎不太对，因为根据上面的图示，我们本来预期浮点值-20.0映射到量化值0。
- en: This is where the concept of zero-point comes in. **The zero-point acts as a
    bias for shifting the scaled floating point value and corresponds to the value
    in the quantized range that represents the floating point value 0.0.** In our
    case, the zero point is the negative of the scaled floating point representation
    of -20.0, which is -(-5) = 5\. The zero point is always the negative of the representation
    of the minimum floating point value since the minimum will always be negative
    or zero. We’ll find out more about why this is the case in the section that explains
    example 4.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是零点概念的所在。**零点作为偏差，用于移动缩放后的浮点值，并对应于表示浮点值0.0的量化范围中的值。** 在我们的案例中，零点是-20.0的缩放浮点表示的负值，即-(-5)
    = 5。零点总是最小浮点值表示的负值，因为最小值总是负数或零。我们将在解释示例4的部分进一步了解为什么会这样。
- en: Whenever we quantize a value, we will always add the zero-point to this scaled
    value to get the actual quantized value in the valid quantization range. In case
    we wish to quantize the value -20.0, we compute it as the scaled value of -20.0
    plus the zero-point, which is -5 + 5 = 0\. Hence, quantized(-20.0, scale=4, zp=5)
    = 0.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们量化一个值时，我们总是会将零点加到这个缩放值上，以获得有效量化范围中的实际量化值。如果我们希望量化值-20.0，我们将其计算为-20.0的缩放值加上零点，即-5
    + 5 = 0。因此，量化(-20.0, scale=4, zp=5) = 0。
- en: '![](../Images/b8df43ccbd85a458a7d4d59729b98f18.png)![](../Images/d74f91262f01c6d0d31cf207cffff488.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8df43ccbd85a458a7d4d59729b98f18.png)![](../Images/d74f91262f01c6d0d31cf207cffff488.png)'
- en: 'Example-3: Affine int8 quantization'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例-3：仿射 int8 量化
- en: What happens if our quantized range is a signed 8-bit integer instead of an
    unsigned 8-bit integer? Well, the range is now [-128 .. 127].
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的量化范围是带符号的8位整数而不是无符号的8位整数会发生什么？好吧，范围现在是[-128 .. 127]。
- en: '![](../Images/2a5ec545adf0c908cafa4d0a9c21bad1.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a5ec545adf0c908cafa4d0a9c21bad1.png)'
- en: In this case, -20.0 in the float range maps to -128 in the quantized range,
    and 1000.0 in the float range maps to 127 in the quantized range.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，浮点范围中的-20.0映射到量化范围中的-128，而浮点范围中的1000.0映射到量化范围中的127。
- en: The way we calculate zero point is that we compute it as if the quantized range
    is [0 .. 255] and then offset it with -128, so the zero point in the new range
    is
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算零点的方法是将量化范围视为[0 .. 255]，然后偏移-128，因此新范围中的零点是
- en: '![](../Images/106ec18c82f700492b347018a489562c.png)![](../Images/1ace2dcbf84ab21bbebf4aa4d7b98e81.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/106ec18c82f700492b347018a489562c.png)![](../Images/1ace2dcbf84ab21bbebf4aa4d7b98e81.png)'
- en: Hence, the zero-point for the new range is -123.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，新范围的零点是-123。
- en: So far, we’ve looked at examples where the floating point range includes the
    value 0.0\. In the next set of examples, we’ll take a look at what happens when
    the floating point range doesn’t include the value 0.0
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们查看了浮点范围包括值0.0的示例。在下一组示例中，我们将查看当浮点范围不包括值0.0时会发生什么。
- en: The importance of 0.0
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 0.0的重要性
- en: Why is it important for the floating point value 0.0 to be represented in the
    floating point range?
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么在浮点范围中表示浮点值0.0很重要？
- en: When using a padded convolution, we expect the border pixels to be padded using
    the value 0.0 in the most common case. Hence, it’s important for 0.0 to be represented
    in the floating point range. Similarly, if the value X is going to be used for
    padding in your network, you need to make sure that the value X is represented
    in the floating point range and that quantization is aware of this.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用填充卷积时，我们期望边缘像素在最常见的情况下使用值0.0进行填充。因此，0.0在浮点范围内的表示是很重要的。同样，如果值X将在网络中用于填充，你需要确保值X在浮点范围内被表示，并且量化是意识到这一点的。
- en: 'Example-4: The untold story — skewed floating point range'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例-4：未讲述的故事 — 歪斜的浮点范围
- en: Now, let’s take a look at what happens if 0.0 isn’t part of the floating point
    range.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如果0.0不在浮点范围内会发生什么。
- en: '![](../Images/7ee42df4a6d2444005594e318c0dfbb5.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ee42df4a6d2444005594e318c0dfbb5.png)'
- en: In this example, we’re trying to quantize the floating point range [40.0 ..
    1000.0] into the quantized range [0 .. 255].
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们试图将浮点范围[40.0 .. 1000.0]量化到量化范围[0 .. 255]。
- en: Since we can’t represent the value 0.0 in the floating point range, we need
    to extend the lower limit of the range to 0.0.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们无法在浮点范围内表示值0.0，我们需要将范围的下限扩展到0.0。
- en: '![](../Images/3b04eb04bfaea206e994e16609f49ec5.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3b04eb04bfaea206e994e16609f49ec5.png)'
- en: We can see that some part of the quantized range is wasted. To determine how
    much, let’s compute the quantized value that the floating point value 40.0 maps
    to.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到量化范围的某些部分被浪费了。为了确定浪费了多少，让我们计算浮点值40.0映射到的量化值。
- en: '![](../Images/08e2bd0a246d71073117f3672df4b756.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08e2bd0a246d71073117f3672df4b756.png)'
- en: Hence, we’re wasting the range [0 .. 9] in the quantized range, which is about
    3.92% of the range. This could significantly affect the model’s accuracy post-quantization.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们在量化范围[0 .. 9]中浪费了约3.92%的范围。这可能会显著影响量化后模型的准确性。
- en: This skewing is necessary if we wish to make sure that the value 0.0 in the
    floating point range can be represented in the quantized range.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望确保浮点范围内的值0.0可以在量化范围内表示，那么这种歪斜是必要的。
- en: Another reason for including the value 0.0 in the floating point range is that
    efficiently comparing a quantized value to check if it’s 0.0 in the floating point
    range is very valuable. Think of operators such as ReLU, which clip all values
    below 0.0 in the floating point range to 0.0.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 将值0.0包含在浮点范围中的另一个原因是有效地比较量化值以检查其是否在浮点范围内的0.0非常有价值。想想像ReLU这样的运算符，它将浮点范围内所有小于0.0的值剪裁为0.0。
- en: It is important for us to be able to **represent the zero-point using the same
    data type** (signed or unsigned int8) **as the quantized values**. This enables
    us to perform these comparisons quickly and efficiently.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说，**使用与量化值相同的数据类型（有符号或无符号的int8）** **表示零点是很重要的**。这使得我们可以快速而有效地进行这些比较。
- en: Next, let’s take a look at how activation normalization helps with model quantization.
    We’ll specifically focus on how the standardization of the activation values allows
    us to use the entire quantized range effectively.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看激活归一化如何帮助模型量化。我们将特别关注激活值的标准化如何使我们有效地使用整个量化范围。
- en: Quantization and Activation Normalization
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量化与激活归一化
- en: Batch/Layer Normalization changes the activation tensor to have zero mean and
    unit variance per channel or per layer.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 批量/层归一化将激活张量的均值调整为零，方差调整为单位，无论是按通道还是按层。
- en: Suppose we have an input tensor with a floating point range of [2000.0 .. 4000.0].
    This is what the quantized range would look like.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个浮点范围为[2000.0 .. 4000.0]的输入张量。这就是量化范围的样子。
- en: '![](../Images/c4127fea06de80d1d7e866f5a177c431.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4127fea06de80d1d7e866f5a177c431.png)'
- en: We observe that half of the quantized range [-127 .. -1] is unused. This is
    problematic since we’re quantizing the entire floating point range using just
    7 of the available 8 bits. This will undoubtedly result in a higher quantization
    error and reduced model accuracy. To address this let’s apply layer normalization
    to the activation tensor.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到量化范围[-127 .. -1]的一半没有使用。这是一个问题，因为我们只使用了可用的8位中的7位来量化整个浮点范围。这无疑会导致更高的量化误差和降低模型的准确性。为了解决这个问题，让我们对激活张量应用层归一化。
- en: After applying layer normalization to an activation tensor, the activation tensor
    will have a floating point range of [-2.0 .. 2.0]. This can be represented in
    the signed int8 range [-128 .. 127]. To ensure symmetry of the distribution, we
    restrict the quantized range to be [-127 .. 127].
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在对激活张量应用层归一化后，激活张量将具有[-2.0 .. 2.0]的浮点范围。这可以表示为带符号的int8范围[-128 .. 127]。为了确保分布的对称性，我们将量化范围限制为[-127
    .. 127]。
- en: '![](../Images/4ed26298d21e7890be02a9a27e2ba69f.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ed26298d21e7890be02a9a27e2ba69f.png)'
- en: Hence, normalization avoids holes or unused parts in the quantized range.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，归一化可以避免量化范围中的空洞或未使用的部分。
- en: Conclusion
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We saw what affine (asymmetric) and symmetric quantization are and how they
    differ. We also learned about what scale and zero-point mean and how to compute
    them for both these types of quantization schemes.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解了什么是仿射（非对称）量化和对称量化，它们的区别是什么。我们还学习了什么是尺度和零点，以及如何为这两种量化方案计算它们。
- en: Next, we saw the need to include float 0.0 in the floating point range and why
    and how this is done in practice. This results in a downside, namely wasted space
    in the quantized range.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们看到需要在浮点范围中包括浮点0.0，并了解为什么以及如何在实践中做到这一点。这导致了一个缺点，即在量化范围内浪费了空间。
- en: Lastly, we saw how normalization helps quantization by bringing the activations
    in a fixed range and avoiding wasted space in the quantized range. In fact, the
    0 mean based normalization can help convert affine quantization to symmetric quantization,
    and that can speed things up during inference.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们看到了归一化如何通过将激活值带入固定范围并避免在量化范围内浪费空间来帮助量化。事实上，基于0均值的归一化可以帮助将仿射量化转换为对称量化，这可以在推理过程中加快速度。
- en: All images in this post are created by the author(s).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中的所有图片均由作者创建。
- en: References
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Efficient Deep Learning Book, Chapter-2: Introduction to Compression Techniques](https://github.com/EfficientDL/book/raw/main/book/%5BEDL%5D%20Chapter%202%20-%20Compression%20Techniques.pdf)'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[高效深度学习书籍，第2章：压缩技术简介](https://github.com/EfficientDL/book/raw/main/book/%5BEDL%5D%20Chapter%202%20-%20Compression%20Techniques.pdf)'
- en: '[Hugging Face: Quantization](https://huggingface.co/docs/optimum/concept_guides/quantization)'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Hugging Face：量化](https://huggingface.co/docs/optimum/concept_guides/quantization)'
- en: '[TensorRT: Quantization](https://docs.nvidia.com/deeplearning/tensorrt/tensorflow-quantization-toolkit/docs/docs/intro_to_quantization.html)'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[TensorRT：量化](https://docs.nvidia.com/deeplearning/tensorrt/tensorflow-quantization-toolkit/docs/docs/intro_to_quantization.html)'
- en: '[Neural Network Distiller: Quantization](https://intellabs.github.io/distiller/algo_quantization.html)'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[神经网络蒸馏：量化](https://intellabs.github.io/distiller/algo_quantization.html)'
- en: '[Lei Mao: Quantization](https://leimao.github.io/article/Neural-Networks-Quantization/)'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[雷毛：量化](https://leimao.github.io/article/Neural-Networks-Quantization/)'
- en: '[Quantizing floats](https://zeux.io/2010/12/14/quantizing-floats/)'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[量化浮点数](https://zeux.io/2010/12/14/quantizing-floats/)'
