- en: Customizing Your Cloud Based Machine Learning Training Environment — Part 1
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义您的基于云的机器学习训练环境 — 第1部分
- en: 原文：[https://towardsdatascience.com/customizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a?source=collection_archive---------7-----------------------#2023-05-21](https://towardsdatascience.com/customizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a?source=collection_archive---------7-----------------------#2023-05-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/customizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a?source=collection_archive---------7-----------------------#2023-05-21](https://towardsdatascience.com/customizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a?source=collection_archive---------7-----------------------#2023-05-21)
- en: How to leverage the power of the cloud without compromising development flexibility
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何利用云的强大功能而不妨碍开发灵活性
- en: '[](https://chaimrand.medium.com/?source=post_page-----2622e10ed65a--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----2622e10ed65a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2622e10ed65a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2622e10ed65a--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----2622e10ed65a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://chaimrand.medium.com/?source=post_page-----2622e10ed65a--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----2622e10ed65a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2622e10ed65a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2622e10ed65a--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----2622e10ed65a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----2622e10ed65a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2622e10ed65a--------------------------------)
    ·8 min read·May 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2622e10ed65a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a&user=Chaim+Rand&userId=9440b37e27fe&source=-----2622e10ed65a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----2622e10ed65a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2622e10ed65a--------------------------------)
    ·8分钟阅读·2023年5月21日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2622e10ed65a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a&user=Chaim+Rand&userId=9440b37e27fe&source=-----2622e10ed65a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2622e10ed65a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a&source=-----2622e10ed65a---------------------bookmark_footer-----------)![](../Images/c0807cb1ec61c0e065e0fc72f8147157.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2622e10ed65a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcustomizing-your-cloud-based-machine-learning-training-environment-part-1-2622e10ed65a&source=-----2622e10ed65a---------------------bookmark_footer-----------)![](../Images/c0807cb1ec61c0e065e0fc72f8147157.png)'
- en: Photo by [Jeremy Thomas](https://unsplash.com/@jeremythomasphoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Jeremy Thomas](https://unsplash.com/@jeremythomasphoto?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Cloud-based machine learning (ML) services offer a great number of conveniences
    to the AI developer, perhaps none as important as the **access** they provide
    to a wide variety of fully provisioned, fully functional, and fully maintained
    ML training environments. For example, managed training services, such as [Amazon
    SageMaker](https://aws.amazon.com/pm/sagemaker/?trk=ps_a134p000007BxdvAAC&trkCampaign=acq_paid_search_brand&sc_channel=PS&sc_campaign=acquisition_IL&sc_publisher=Google&sc_category=Machine+Learning&sc_country=IL&sc_geo=EMEA&sc_outcome=acq&sc_detail=amazon+sagemaker&sc_content=Sagemaker_e&sc_matchtype=e&sc_segment=532435490322&sc_medium=ACQ-P%7CPS-GO%7CBrand%7CDesktop%7CSU%7CMachine+Learning%7CSagemaker%7CIL%7CEN%7CText&s_kwcid=AL%214422%213%21532435490322%21e%21%21g%21%21amazon+sagemaker&ef_id=Cj0KCQiAhMOMBhDhARIsAPVml-HxIwfeABmnxXbZ9ia_5DV_TckDGpMSH2mFhSpu8jrCgntII8hcHB4aAuhfEALw_wcB%3AG%3As)
    and [Google Vertex AI](https://cloud.google.com/vertex-ai), enable users to specify
    (1) the desired instance types (e.g., with the latest available GPUs), (2) an
    ML framework and version, (3) a code source directory, and (4) a training script,
    and will automatically start up the chosen instances with the requested environment,
    run the script to train the AI model, and tear everything down upon completion.
    Among the advantages of such offerings is the potential for significant savings
    in the time and cost of building and maintaining your own training cluster. See
    [here](/6-steps-to-migrating-your-machine-learning-project-to-the-cloud-6d9b6e4f18e0)
    for more on the benefits and considerations of cloud-based training as well as
    a summary of some of the common steps required to migrate an ML workload to the
    cloud.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基于云的机器学习（ML）服务为 AI 开发者提供了许多便利，其中可能没有比**访问**更多样化、完全配置、完全功能和完全维护的 ML 训练环境更重要的。例如，托管训练服务，如
    [Amazon SageMaker](https://aws.amazon.com/pm/sagemaker/?trk=ps_a134p000007BxdvAAC&trkCampaign=acq_paid_search_brand&sc_channel=PS&sc_campaign=acquisition_IL&sc_publisher=Google&sc_category=Machine+Learning&sc_country=IL&sc_geo=EMEA&sc_outcome=acq&sc_detail=amazon+sagemaker&sc_content=Sagemaker_e&sc_matchtype=e&sc_segment=532435490322&sc_medium=ACQ-P%7CPS-GO%7CBrand%7CDesktop%7CSU%7CMachine+Learning%7CSagemaker%7CIL%7CEN%7CText&s_kwcid=AL%214422%213%21532435490322%21e%21%21g%21%21amazon+sagemaker&ef_id=Cj0KCQiAhMOMBhDhARIsAPVml-HxIwfeABmnxXbZ9ia_5DV_TckDGpMSH2mFhSpu8jrCgntII8hcHB4aAuhfEALw_wcB%3AG%3As)
    和 [Google Vertex AI](https://cloud.google.com/vertex-ai)，使用户能够指定（1）所需的实例类型（例如，配备最新可用
    GPU 的实例），（2）ML 框架及版本，（3）代码源目录，以及（4）训练脚本，并会自动启动所选实例，运行脚本以训练 AI 模型，并在完成后拆除所有内容。这些服务的优点之一是可以显著节省构建和维护自己的训练集群的时间和成本。有关云端训练的更多好处和注意事项，请参见
    [这里](/6-steps-to-migrating-your-machine-learning-project-to-the-cloud-6d9b6e4f18e0)。
- en: 'However, coupled with the convenience of using a predefined, fully provisioned,
    fully validated, ML environment comes the potential for limitations on development
    flexibility. This is contrary to a local, “on-prem” environment that you can freely
    define to your heart’s desire. Here are a few scenarios that demonstrate the potential
    limitation:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用预定义、完全配置、完全验证的 ML 环境的便利性也伴随着开发灵活性的潜在限制。这与可以随心所欲自由定义的本地“本地”环境相对。以下是几个示例，展示了可能的限制：
- en: '**Training dependencies**: It is easy to conceive of training flows that have
    dependencies on specific packages (e.g., Linux packages or Python packages) that
    might not be included in the predefined environments provided by your cloud service
    of choice.'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练依赖**：很容易想到那些对特定软件包（例如，Linux 包或 Python 包）有依赖的训练流程，而这些软件包可能不包括在您选择的云服务提供的预定义环境中。'
- en: '**Development platform independence**: You may desire (or require) a development
    environment that is independent of the underlying runtime platform. For example,
    you may want to have the ability to use the same training environment regardless
    of whether you are running on your own PC, on a local (“on-prem”) cluster, or
    in the cloud, and regardless of the cloud service provider and cloud service you
    choose. This can reduce the overhead of needing to adapt to multiple environments
    and might also facilitate debugging issues.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**开发平台独立性**：您可能希望（或需要）一个独立于底层运行平台的开发环境。例如，您可能希望无论是在自己的 PC 上、在本地（“本地”）集群中，还是在云中运行，都能够使用相同的训练环境，并且无论选择哪个云服务提供商和云服务。这可以减少适应多个环境的开销，并可能有助于调试问题。'
- en: '**Personal development preferences**: Engineers (especially seasoned ones)
    can be quite particular about their development habits and development environments.
    The mere possibility of a limitation, introduced by a change to the development
    process, however much its value and importance to the team (e.g., migrating to
    cloud ML), might stir up significant resistance.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**个人发展偏好**：工程师（特别是有经验的工程师）对他们的开发习惯和开发环境可能非常挑剔。即使是由于开发流程的变更而可能带来的限制，无论其对团队的价值和重要性如何（例如，迁移到云端机器学习），也可能引发显著的抵触情绪。'
- en: In this two-part blog post we will cover some of the options available for overcoming
    the potential development limitations of cloud-based training. Specifically, we
    will assume that the training environment is defined by a [Docker](https://www.docker.com/)
    image containing a Python environment and demonstrate a few methods for customizing
    the environment to meet our specific needs.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇分为两部分的博客文章中，我们将介绍一些克服基于云的训练潜在开发限制的选项。具体来说，我们将假设训练环境由一个包含 Python 环境的 [Docker](https://www.docker.com/)
    镜像定义，并演示几种方法来定制环境以满足我们的特定需求。
- en: For the sake of demonstration, we will assume that the training service of choice
    is Amazon SageMaker. However, please note that the general methods apply equally
    to other training services as well and that this choice should not be viewed as
    an endorsement of one cloud-based service over any other. The best option for
    you will likely depend on many factors including the details of your project,
    budgetary considerations, and more.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示的目的，我们将假设所选的训练服务是 Amazon SageMaker。然而，请注意，一般方法同样适用于其他训练服务，并且这种选择不应被视为对某一云服务的偏爱。最适合你的选项可能取决于许多因素，包括项目的细节、预算考虑等。
- en: Throughout the blog we will reference and demonstrate certain library APIs and
    behaviors. Note these are true as of the time of this writing and are subject
    to modification in future versions of the libraries. Please be sure to refer to
    the latest official documentation before trusting anything we write.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在博客中，我们将引用和演示某些库的 API 和行为。请注意，这些信息在撰写时是准确的，并可能会在未来版本的库中有所更改。在信任我们所写的内容之前，请务必参考最新的官方文档。
- en: I would like to thank [Yitzhak Levi](https://www.linkedin.com/in/yitzhak-levi-49a217201/?originalSubdomain=il)
    whose experimentation formed the basis of this blog post.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我想感谢 [Yitzhak Levi](https://www.linkedin.com/in/yitzhak-levi-49a217201/?originalSubdomain=il)，他的实验为这篇博客文章奠定了基础。
- en: Managed Training Example
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 托管训练示例
- en: Let’s begin with a simple demonstration of training in the cloud using a managed
    service. In the code block below we use [Amazon SageMaker](https://aws.amazon.com/pm/sagemaker/?trk=ps_a134p000007BxdvAAC&trkCampaign=acq_paid_search_brand&sc_channel=PS&sc_campaign=acquisition_IL&sc_publisher=Google&sc_category=Machine+Learning&sc_country=IL&sc_geo=EMEA&sc_outcome=acq&sc_detail=amazon+sagemaker&sc_content=Sagemaker_e&sc_matchtype=e&sc_segment=532435490322&sc_medium=ACQ-P%7CPS-GO%7CBrand%7CDesktop%7CSU%7CMachine+Learning%7CSagemaker%7CIL%7CEN%7CText&s_kwcid=AL%214422%213%21532435490322%21e%21%21g%21%21amazon+sagemaker&ef_id=Cj0KCQiAhMOMBhDhARIsAPVml-HxIwfeABmnxXbZ9ia_5DV_TckDGpMSH2mFhSpu8jrCgntII8hcHB4aAuhfEALw_wcB%3AG%3As)
    to run the *train.py* PyTorch (1.13.1) script from the *source_dir* folder on
    a single [*ml.g5.xlarge*](https://aws.amazon.com/ec2/instance-types/g5/) GPU instance
    type. Note that this is a rather simple example of training with Amazon SageMaker;
    for more details be sure to see the official [AWS documentation](https://aws.amazon.com/getting-started/hands-on/machine-learning-tutorial-train-a-model/).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始使用托管服务在云端进行训练的简单演示。在下面的代码块中，我们使用 [Amazon SageMaker](https://aws.amazon.com/pm/sagemaker/?trk=ps_a134p000007BxdvAAC&trkCampaign=acq_paid_search_brand&sc_channel=PS&sc_campaign=acquisition_IL&sc_publisher=Google&sc_category=Machine+Learning&sc_country=IL&sc_geo=EMEA&sc_outcome=acq&sc_detail=amazon+sagemaker&sc_content=Sagemaker_e&sc_matchtype=e&sc_segment=532435490322&sc_medium=ACQ-P%7CPS-GO%7CBrand%7CDesktop%7CSU%7CMachine+Learning%7CSagemaker%7CIL%7CEN%7CText&s_kwcid=AL%214422%213%21532435490322%21e%21%21g%21%21amazon+sagemaker&ef_id=Cj0KCQiAhMOMBhDhARIsAPVml-HxIwfeABmnxXbZ9ia_5DV_TckDGpMSH2mFhSpu8jrCgntII8hcHB4aAuhfEALw_wcB%3AG%3As)
    来运行 *train.py* PyTorch (1.13.1) 脚本，该脚本位于 *source_dir* 文件夹中，并在单个 [*ml.g5.xlarge*](https://aws.amazon.com/ec2/instance-types/g5/)
    GPU 实例类型上运行。请注意，这是使用 Amazon SageMaker 进行训练的一个相对简单的示例；有关更多详细信息，请参阅官方 [AWS 文档](https://aws.amazon.com/getting-started/hands-on/machine-learning-tutorial-train-a-model/)。
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To get a better idea of the potential limitations on development flexibility
    when training in the cloud and how to overcome them, let’s review the steps that
    occur behind the scenes when deploying a training job using a service such as
    Amazon SageMaker.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解在云中训练时开发灵活性的潜在限制以及如何克服这些限制，让我们回顾一下使用诸如 Amazon SageMaker 的服务部署训练作业时发生的步骤。
- en: What Happens Behind the Scenes
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背后的秘密
- en: We will focus here on the primary steps that occur; for the full details please
    see the [official documentation](https://docs.aws.amazon.com/sagemaker/index.html).
    Although we will review the actions that are taken by the SageMaker API, other
    managed training APIs exhibit similar behaviors.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里重点关注主要步骤；有关详细信息，请参见 [官方文档](https://docs.aws.amazon.com/sagemaker/index.html)。尽管我们将回顾
    SageMaker API 执行的操作，但其他托管训练 API 也表现出类似的行为。
- en: '**Step 1**: Tar and upload the code source directory to cloud storage.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**第1步**：将代码源目录打包并上传到云存储。'
- en: '**Step 2**: Provision the requested instance type(s).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**第2步**：配置所请求的实例类型。'
- en: '**Step 3**: Pull the appropriate [pre-built Docker image](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html)
    to the instance(s). The appropriate image is determined by the properties of the
    training job. In the example above, we requested Python 3.9, PyTorch 1.13.1, and
    a GPU instance type in the *us-east-1* [AWS region](https://aws.amazon.com/about-aws/global-infrastructure/regions_az/)
    and will, accordingly, end up with the 763104351884.dkr.ecr.**us-east-1**.amazonaws.com/**pytorch**-training:**1.13.1**-**gpu**-**py39**-cu117-ubuntu20.04-sagemaker
    image.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**第3步**：将适当的 [预构建 Docker 镜像](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html)
    拉取到实例上。适当的镜像由训练作业的属性决定。在上述示例中，我们请求了 Python 3.9、PyTorch 1.13.1 和一个 GPU 实例类型在 *us-east-1*
    [AWS 区域](https://aws.amazon.com/about-aws/global-infrastructure/regions_az/)，因此最终会得到
    763104351884.dkr.ecr.**us-east-1**.amazonaws.com/**pytorch**-training:**1.13.1**-**gpu**-**py39**-cu117-ubuntu20.04-sagemaker
    镜像。'
- en: '**Step 4**: Run the Docker image. The Docker *ENTRYPOINT* is a script (defined
    by the service) that downloads and unpacks the training code from cloud storage
    and runs the user defined training script (more details on this below).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**第4步**：运行 Docker 镜像。Docker *ENTRYPOINT* 是一个脚本（由服务定义），该脚本从云存储中下载并解压训练代码，并运行用户定义的训练脚本（下面有更多细节）。'
- en: '**Step 5**: When the training script has completed, stop and release the instance.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**第5步**：当训练脚本完成时，停止并释放实例。'
- en: Note that we have greatly simplified the actions taken by the service and focused
    on those that will pertain to our discussion. In practice there are many more
    “management” activities that take place behind the scenes that include [accessing
    training data](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html),
    [orchestrating distributed training](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html),
    [recovery from spot interruptions](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html),
    [monitoring and analyzing training](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html),
    and much more.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们大大简化了服务执行的操作，并关注了与我们的讨论相关的那些操作。在实际操作中，还有许多其他“管理”活动在后台进行，包括 [访问训练数据](https://docs.aws.amazon.com/sagemaker/latest/dg/model-access-training-data.html)、[协调分布式训练](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html)、[从点中断中恢复](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)、[监控和分析训练](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html)
    等等。
- en: About the Docker Image
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于 Docker 镜像
- en: The [AWS Deep Learning Containers](https://github.com/aws/deep-learning-containers)
    (DLCs) github repository includes the pre-built AWS Docker images used by the
    SageMaker service. These can be analyzed to get a better understanding of the
    environment in which the training script runs. In particular, the Dockerfile defining
    the image used in the example above is located [here](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu).
    From a cursory review of the file we can see that in addition to standard Linux
    and Python packages (e.g., OpenSSH, pandas, scikit-learn, etc.), the image contains
    several AWS specific packages, such as enhanced version of [PyTorch for AWS](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu#L385)
    and libraries for utilizing [Amazon EFA](https://aws.amazon.com/hpc/efa/). The
    AWS specific enhancements include features for managing and monitoring training
    jobs and, more importantly, optimizations for **maximizing resource utilization
    and runtime performance when running on AWS’s training infrastructures**. Furthermore,
    upon closer analysis of the Dockerfile it becomes clear that its creation required
    diligent work, occasional workarounds, and extensive testing. Barring other considerations
    (see below), our first choice will always be to use the official AWS DLCs when
    training on AWS.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[AWS 深度学习容器](https://github.com/aws/deep-learning-containers)（DLCs）GitHub 仓库包括了由
    SageMaker 服务使用的预构建 AWS Docker 镜像。这些镜像可以用来更好地理解训练脚本运行的环境。特别是，定义上述示例中使用的镜像的 Dockerfile
    位于 [这里](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu)。从对该文件的粗略审查中，我们可以看到，除了标准的
    Linux 和 Python 包（例如，OpenSSH、pandas、scikit-learn 等），该镜像还包含几个 AWS 特定的包，例如 [PyTorch
    for AWS](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu#L385)
    的增强版本和用于利用 [Amazon EFA](https://aws.amazon.com/hpc/efa/) 的库。AWS 特定的增强功能包括用于管理和监控训练任务的特性，更重要的是，当在
    AWS 的训练基础设施上运行时，用于 **最大化资源利用率和运行时性能** 的优化。此外，通过对 Dockerfile 的更详细分析可以明确，其创建需要细致的工作、偶尔的变通和广泛的测试。除其他考虑因素外（见下文），我们在
    AWS 上训练时的首选始终是使用官方 AWS DLCs。'
- en: The [*ENTRYPOINT* in the Dockerfile](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu#L561)
    points to a script called [*start_with_right_hostname.sh*](https://github.com/aws/sagemaker-pytorch-training-toolkit/blob/master/docker/build_artifacts/start_with_right_hostname.sh).
    This calls the [*train.py*](https://github.com/aws/sagemaker-training-toolkit/blob/1f4691ab98967bd32e2860a6afc42001d0945ec9/src/sagemaker_training/cli/train.py)
    script from the [sagemaker-training](https://pypi.org/project/sagemaker-training/)
    Python package which, in turn, calls a [function](https://github.com/aws/sagemaker-training-toolkit/blob/1f4691ab98967bd32e2860a6afc42001d0945ec9/src/sagemaker_training/trainer.py#L61)
    that parses the [*SAGEMAKER_TRAINING_MODULE*](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu#L370)environment
    variables and ultimately runs the PyTorch-specific [entry-point](https://github.com/aws/sagemaker-pytorch-training-toolkit/blob/master/src/sagemaker_pytorch_container/training.py#L152)
    from the [sagemaker-pytorch-training](https://pypi.org/project/sagemaker-pytorch-training/)
    Python package. It is this entry-point that downloads the source code and starts
    up the training as described in step 4 above. Keep in mind that the flow we just
    described and the code to which we linked are valid as of the time of this writing
    and may change as the SageMaker APIs evolve. While we have analyzed the startup
    flow for a SageMaker PyTorch 1.13 training job as configured in the example above,
    the same analysis can be performed for other types of cloud-based training jobs.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Dockerfile*中的*ENTRYPOINT*](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu#L561)
    指向一个名为[*start_with_right_hostname.sh*](https://github.com/aws/sagemaker-pytorch-training-toolkit/blob/master/docker/build_artifacts/start_with_right_hostname.sh)
    的脚本。这个脚本调用了来自[sagemaker-training](https://pypi.org/project/sagemaker-training/)
    Python 包的[*train.py*](https://github.com/aws/sagemaker-training-toolkit/blob/1f4691ab98967bd32e2860a6afc42001d0945ec9/src/sagemaker_training/cli/train.py)
    脚本，该脚本又调用一个解析[*SAGEMAKER_TRAINING_MODULE*](https://github.com/aws/deep-learning-containers/blob/master/pytorch/training/docker/1.13/py3/cu117/Dockerfile.gpu#L370)
    环境变量的[函数](https://github.com/aws/sagemaker-training-toolkit/blob/1f4691ab98967bd32e2860a6afc42001d0945ec9/src/sagemaker_training/trainer.py#L61)，最终运行来自[sagemaker-pytorch-training](https://pypi.org/project/sagemaker-pytorch-training/)
    Python 包的 PyTorch 特定的[入口点](https://github.com/aws/sagemaker-pytorch-training-toolkit/blob/master/src/sagemaker_pytorch_container/training.py#L152)。正是这个入口点下载源代码并启动训练，如上面第4步所述。请记住，我们刚刚描述的流程和我们链接的代码在撰写时是有效的，随着
    SageMaker API 的演变，可能会发生变化。虽然我们已经分析了上述示例中配置的 SageMaker PyTorch 1.13 训练作业的启动流程，但同样的分析也可以应用于其他类型的基于云的训练作业。'
- en: The publicly accessible AWS DLC Dockerfiles and SageMaker Python package source
    code allow us to get a sense of the cloud-based training runtime environment.
    This enables us to gain a better understanding of the capabilities and limitations
    of training in a cloud-based environment and, as we will see in the next sections,
    understand the tools at our disposal for introducing changes and customizations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 公开访问的 AWS DLC Dockerfile 和 SageMaker Python 包源代码使我们能够了解基于云的训练运行时环境。这使我们能够更好地理解在云环境中训练的能力和局限性，并且正如我们在接下来的部分中将看到的，了解我们可以用来引入更改和自定义的工具。
- en: Customizing the Python Environment
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义 Python 环境
- en: The first and simplest way to customize your training environment is by adding
    Python packages. Training scripts will often depend on Python packages (or on
    specific versions of packages) that are not included in the Python environment
    of the cloud service’s default Docker image. The SageMaker APIs address this by
    allowing you to include a *requirements.txt* in the root of the *source_dir* folder
    passed into the SageMaker estimator (see the API call example above). Following
    the downloading and unpacking of the source code (in step 4 above), the SageMaker
    script will search for a *requirements.txt* file and install all of its contents
    using the [pip](https://pypi.org/project/pip/) package installer. See [here](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#using-third-party-libraries)
    for more details on this feature. Other cloud services include similar mechanisms
    for automating installation of package dependencies. This type of solution can
    also be easily accomplished by simply including a designated package installation
    routine at the beginning of your own training script (though this needs to be
    carefully coordinated in a case where you are running multiple processes e.g.,
    with MPI, on a single instance).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义你的训练环境的第一种也是最简单的方法是添加 Python 包。训练脚本通常依赖于 Python 包（或特定版本的包），这些包不包含在云服务默认 Docker
    镜像的 Python 环境中。SageMaker API 通过允许你在传递给 SageMaker 估算器的 *source_dir* 文件夹的根目录中包含一个
    *requirements.txt* 文件来解决这个问题（请参见上面的 API 调用示例）。在下载和解压源代码（上面的步骤 4）之后，SageMaker 脚本将搜索
    *requirements.txt* 文件，并使用 [pip](https://pypi.org/project/pip/) 包安装程序安装其所有内容。有关此功能的更多详细信息，请参见
    [这里](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#using-third-party-libraries)。其他云服务也包括类似的机制来自动安装包依赖。通过在你自己的训练脚本开始时简单地包含一个指定的包安装程序，也可以轻松实现这种解决方案（尽管在运行多个进程（例如，使用
    MPI）在单个实例上时，需要仔细协调）。
- en: 'While this solution is simple and easy to use, it does have some limitations:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个解决方案简单易用，但确实存在一些限制：
- en: Installation Time
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装时间
- en: One thing to take into consideration is the overhead (in time) required to install
    the package dependencies. If we have a long list of dependencies or if any of
    the dependencies require a long installation time, customizing the environment
    in this manner might increase the overall time and cost of training to an unreasonable
    degree and we might find one of the alternative methods we will discuss to better
    suit our needs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的一点是安装包依赖所需的开销（时间）。如果我们有一个很长的依赖列表，或者其中任何依赖项需要很长时间才能安装，以这种方式自定义环境可能会在不合理的程度上增加总体时间和成本，这时我们可能会发现我们将讨论的其他方法更适合我们的需求。
- en: Access to Repository
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问存储库
- en: Another thing to keep in mind about this method is that it relies on access
    to a Python package repository. If the network of your training environment is
    configured to allow free access to the internet, then this is not a problem. However,
    if you are training in a private network environment, such as [Amazon Virtual
    Private Cloud](http://aws.amazon.com/vpc) (Amazon VPC), then this access might
    be restricted. In such cases, you will need to create a private package repository.
    In AWS this can be done using [AWS CodeArtifact](https://aws.amazon.com/codeartifact/)
    or by creating a private PyPI mirror. (Although the use case is a bit different,
    you might find the recipes described [here](https://aws.amazon.com/blogs/machine-learning/private-package-installation-in-amazon-sagemaker-running-in-internet-free-mode/)
    and [here](https://aws.amazon.com/blogs/machine-learning/hosting-a-private-pypi-server-for-amazon-sagemaker-studio-notebooks-in-a-vpc/)
    to be helpful.) In the absence of an accessible package repository, you will need
    to consider one of the alternative customization options we will present.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要注意的是，这种方法依赖于访问 Python 包存储库。如果你的训练环境的网络配置允许自由访问互联网，那么这不是问题。然而，如果你在私有网络环境中进行训练，例如
    [Amazon Virtual Private Cloud](http://aws.amazon.com/vpc)（Amazon VPC），那么这种访问可能会受到限制。在这种情况下，你需要创建一个私有包存储库。在
    AWS 中，可以使用 [AWS CodeArtifact](https://aws.amazon.com/codeartifact/) 或创建一个私有 PyPI
    镜像来完成此操作。（虽然用例有所不同，但你可能会发现 [这里](https://aws.amazon.com/blogs/machine-learning/private-package-installation-in-amazon-sagemaker-running-in-internet-free-mode/)
    和 [这里](https://aws.amazon.com/blogs/machine-learning/hosting-a-private-pypi-server-for-amazon-sagemaker-studio-notebooks-in-a-vpc/)
    描述的方案很有帮助。）如果没有可访问的包存储库，你需要考虑我们将介绍的其他自定义选项。
- en: Conda Package Dependencies
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Conda 包依赖
- en: The customization solution we have presented is great if all of our dependencies
    are pip packages. But what if our dependency exists only as a [conda](https://docs.conda.io/en/latest/)
    package? For example, suppose we wish to use the [s5cmd](https://anaconda.org/conda-forge/s5cmd)
    for [speeding up data streaming from cloud storage](/training-from-cloud-storage-with-s5cmd-5c8fb5c06056).
    When we have full control over the training environment, we can choose to build
    our Python environment using conda and freely install conda package dependencies.
    If we use a Docker container provided by a cloud service, we don’t control the
    Python environment creation and may not enjoy the same freedoms. Point in fact,
    attempting to install [s5cmd](https://anaconda.org/conda-forge/s5cmd) via [subprocess](https://docs.python.org/3/library/subprocess.html)
    on SageMaker (*conda install -y s5cmd*) fails. Even if we were to figure out a
    way to make it work, installing a package in this manner may lead to undesired
    side effects such as overwriting other AWS-optimized packages or generally destabilizing
    the conda environment.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的定制解决方案对于所有依赖项都是pip包的情况非常好。但是，如果我们的依赖项仅作为[conda](https://docs.conda.io/en/latest/)包存在呢？例如，假设我们希望使用[s5cmd](https://anaconda.org/conda-forge/s5cmd)来[加速从云存储中传输数据](/training-from-cloud-storage-with-s5cmd-5c8fb5c06056)。当我们完全控制训练环境时，可以选择使用conda构建Python环境并自由安装conda包依赖项。如果我们使用由云服务提供的Docker容器，我们无法控制Python环境的创建，可能无法享受相同的自由。事实上，尝试在SageMaker上通过[subprocess](https://docs.python.org/3/library/subprocess.html)安装[s5cmd](https://anaconda.org/conda-forge/s5cmd)（*conda
    install -y s5cmd*）会失败。即使我们找到一种方法使其工作，以这种方式安装包可能会导致不希望的副作用，例如覆盖其他AWS优化包或普遍破坏conda环境。
- en: Linux Package Dependencies
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linux软件包依赖关系
- en: In theory, this method could also be extended to support Linux packages. If,
    for example, our training script depended on a specific Linux package or package
    version, we could install it using a [subprocess](https://docs.python.org/3/library/subprocess.html)
    call at the beginning of our script. In practice, many services, including Amazon
    SageMaker, limit the Linux user permissions in a manner that prevents this option.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，这种方法也可以扩展以支持Linux软件包。例如，如果我们的训练脚本依赖于特定的Linux软件包或软件包版本，我们可以在脚本开始时使用[subprocess](https://docs.python.org/3/library/subprocess.html)调用来安装它。实际上，包括Amazon
    SageMaker在内的许多服务限制了Linux用户权限，从而阻止了这种选项。
- en: Summary
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The first solution we have presented for customizing our training environment
    is simple to use and allows us to take full advantage of the Docker images that
    were specially designed and optimized by the cloud service provider. However,
    as we have seen, it has a number of limitations. In the [second part of our post](https://chaimrand.medium.com/customizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812)
    we will discuss two additional approaches that will address these limitations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的第一个用于定制训练环境的解决方案易于使用，并允许我们充分利用由云服务提供商特别设计和优化的Docker镜像。然而，正如我们所看到的，它也有一些限制。在[我们文章的第二部分](https://chaimrand.medium.com/customizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812)中，我们将讨论两种额外的方法来解决这些限制。
