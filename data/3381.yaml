- en: 'TSMixer: The Latest Forecasting Model by Google'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TSMixer：谷歌最新的预测模型
- en: 原文：[https://towardsdatascience.com/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb?source=collection_archive---------3-----------------------#2023-11-14](https://towardsdatascience.com/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb?source=collection_archive---------3-----------------------#2023-11-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb?source=collection_archive---------3-----------------------#2023-11-14](https://towardsdatascience.com/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb?source=collection_archive---------3-----------------------#2023-11-14)
- en: Explore the architecture of TSMixer and implement it in Python for a long-horizon
    multivariate forecasting task
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 TSMixer 的架构，并在 Python 中实现长期多变量预测任务
- en: '[](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd----2fd1e29a8ccb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)
    ·12 min read·Nov 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2fd1e29a8ccb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----2fd1e29a8ccb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd----2fd1e29a8ccb---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)
    ·12 min read·Nov 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2fd1e29a8ccb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----2fd1e29a8ccb---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2fd1e29a8ccb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&source=-----2fd1e29a8ccb---------------------bookmark_footer-----------)![](../Images/e73873566af0876cf840a6284a7f2f21.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2fd1e29a8ccb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&source=-----2fd1e29a8ccb---------------------bookmark_footer-----------)![](../Images/e73873566af0876cf840a6284a7f2f21.png)'
- en: Photo by [Zdeněk Macháček](https://unsplash.com/@zmachacek?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Zdeněk Macháček](https://unsplash.com/@zmachacek?utm_source=medium&utm_medium=referral)在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上拍摄
- en: The field of time series forecasting continues to be in effervescence, with
    many important recent contributions like N-HiTS, PatchTST, TimesNet and of course
    TimeGPT.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列预测领域依然充满活力，近期有许多重要的贡献，如 N-HiTS、PatchTST、TimesNet，当然还有 TimeGPT。
- en: In the meantime, the Transformer architecture unlocked unprecedented performance
    in the field of natural language processing (NLP), but that is not true for time
    series forecasting.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，Transformer 架构在自然语言处理（NLP）领域取得了前所未有的性能，但这并不适用于时间序列预测。
- en: In fact, many Transformer-based model were proposed like Autoformer, Informer,
    FEDformer, and more. Those models are often very long to train and it turns out
    that simple linear models outperform them on many benchmark datasets (see [Zheng
    et al., 2022](https://arxiv.org/pdf/2205.13504.pdf)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，许多基于Transformer的模型如Autoformer、Informer、FEDformer等也被提出。这些模型通常训练时间较长，而简单的线性模型在许多基准数据集上表现优于它们（见[郑等，2022](https://arxiv.org/pdf/2205.13504.pdf)）。
- en: To that point, in September 2023, researchers from Google Cloud AI Research
    proposed **TSMixer**, a Multi-layer Perceptron (MLP) based model that focuses
    on mixing time and feature dimensions to make better predictions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 针对这一点，2023年9月，Google Cloud AI Research的研究人员提出了**TSMixer**，一种基于多层感知器（MLP）的模型，专注于混合时间和特征维度，以做出更好的预测。
- en: 'In their paper [TSMixer: An All-MLP Architecture for Time Series Forecasting](https://arxiv.org/pdf/2303.06053.pdf),
    the authors demonstrate that this model achieves state-of-the-art performance
    on many benchmark datasets, while remaining simple to implement.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '在他们的论文[TSMixer: An All-MLP Architecture for Time Series Forecasting](https://arxiv.org/pdf/2303.06053.pdf)中，作者展示了该模型在许多基准数据集上达到了最先进的性能，同时实现起来也很简单。'
