- en: How to Load Multiple CSV Files into a Pandas DataFrame
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何将多个 CSV 文件加载到 Pandas DataFrame 中
- en: 原文：[https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff](https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff](https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff)
- en: Importing and concatenating multiple CSV files into one pandas DataFrame
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入并连接多个 CSV 文件到一个 pandas DataFrame 中
- en: '[](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    ·5 min read·Jan 31, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    ·5 分钟阅读·2023年1月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/649a65c5a7ba242fecd95611a28a9576.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/649a65c5a7ba242fecd95611a28a9576.png)'
- en: Photo by [Daniel K Cheung](https://unsplash.com/@danielkcheung?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/cPF2nlWcMY4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Daniel K Cheung](https://unsplash.com/@danielkcheung?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来自 [Unsplash](https://unsplash.com/photos/cPF2nlWcMY4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: CSV (Common Separated Values) is a popular file format used to store and exchange
    data. In fact, this type of source is commonly used for relatively small volumes
    of data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: CSV（逗号分隔值）是一种常用的文件格式，用于存储和交换数据。事实上，这种类型的源通常用于相对较小的数据量。
- en: '`pandas` is a commonly used Python package that lets developers process and
    transform data as part of analytical and data science tasks. However, beform perforning
    any task pandas needs to load all the data into memory. This means that the package
    can only be used for relatively small volumes of data — well this depends on the
    capabilities of the host machine but for an average machine, we would only be
    able to load a few GBs of data within memory.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas` 是一个常用的 Python 包，它允许开发人员处理和转换数据，作为分析和数据科学任务的一部分。然而，在执行任何任务之前，pandas
    需要将所有数据加载到内存中。这意味着该包只能用于相对较小的数据量——这取决于主机机器的能力，但对于一台普通的机器，我们只能在内存中加载几 GB 的数据。'
- en: Therefore, loading CSV files in memory and then processing the data with pandas,
    is a very common task given that such files usually consist of data whose size
    can be loaded in-memory.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将 CSV 文件加载到内存中，然后用 pandas 处理数据，是一个非常常见的任务，因为这些文件通常包含可以加载到内存中的数据。
- en: '[**Subscribe to Data Pipeline**](https://thedatapipeline.substack.com/welcome)**,
    a newsletter dedicated to Data Engineering**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[**订阅数据管道**](https://thedatapipeline.substack.com/welcome)**，这是一个专注于数据工程的新闻通讯**'
- en: In this article, we will demonstrate how to load multiple CSV files in a single
    pandas DataFrame. Furthermore, we’ll also showcase how to identify the source
    file in every record so that we can tell which data point belongs to a certain
    data file.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将演示如何将多个 CSV 文件加载到一个 pandas DataFrame 中。此外，我们还将展示如何在每条记录中识别源文件，以便我们可以确定哪个数据点属于某个数据文件。
- en: 'Now let’s assume that we have data points collected in three separate CSV files
    namely `data_1.csv`, `data_2.csv` and `data_3.csv` :'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们在三个分开的 CSV 文件中收集了数据点，即 `data_1.csv`、`data_2.csv` 和 `data_3.csv`：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Concatenating multiple CSV files in a single pandas DataFrame
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在一个 pandas DataFrame 中连接多个 CSV 文件
- en: Now that we have some dummy data in three separate CSV files, we can go ahead
    and import them in one DataFrame.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有三个分开的 CSV 文件中的一些虚拟数据，我们可以继续将它们导入到一个 DataFrame 中。
- en: The first option we have is to read every individual CSV file using `pandas.read_csv()`
    function and concatenate all loaded files into a single DataFrame using `pandas.concatenate()`
    function.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择的第一个选项是使用`pandas.read_csv()`函数读取每个单独的CSV文件，并使用`pandas.concatenate()`函数将所有加载的文件合并为一个单一的DataFrame。
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now the newly constructed DataFrame contains all the data points found in the
    three input CSV files:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在新构建的DataFrame包含了三个输入CSV文件中发现的所有数据点：
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Notice how the index of our DataFrame is reset when loading data from multiple
    files. If instead you’d want to create a new index for the newly created DataFrame,
    all you need to do is ignore the index whilst concatenating the files:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当从多个文件加载数据时，我们的DataFrame的索引会被重置。如果你希望为新创建的DataFrame创建一个新的索引，你只需在合并文件时忽略索引即可：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Avoid specifying explicit file names
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免明确指定文件名
- en: Now let’s assume that we have hundreds of different CSV files that we would
    want to concateante into a single DataFrame. Instead of wasting time and lines
    of code to explicitly write all the individual filenames down, we could instead
    use a whitecard.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们有数百个不同的CSV文件，我们希望将它们合并为一个单一的DataFrame。与其浪费时间和代码行数来明确写出所有单独的文件名，不如使用通配符。
- en: 'We can do so, by taking advantage of `glob` module, which is part of the standard
    libary and offers functionality to support unix style pathname pattern expansion.
    For example, in order to create a list containing of all the files ending with
    `.csv` filename under the current directory, we could use the following code snippet:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用`glob`模块，该模块是标准库的一部分，提供支持Unix样式路径名模式扩展的功能。例如，为了创建一个包含当前目录下所有以`.csv`结尾的文件的列表，我们可以使用以下代码片段：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The full code that reads all csv files under current directory and concatenates
    them in a single pandas DataFrame is shared below:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下面分享了一个完整的代码，该代码读取当前目录下的所有CSV文件，并将它们合并为一个单一的pandas DataFrame：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Another approach — and perhaps a more Pythonic one — is one that takes advantage
    `map` built-in function that lets us run a method or function over an [Iterable](/python-iterables-vs-iterators-688907fd755f)
    (like a Python List) without having to explicitly call a `for` loop:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法——可能更符合Python风格——是利用`map`内置函数，它允许我们在不显式调用`for`循环的情况下，对[Iterable](/python-iterables-vs-iterators-688907fd755f)（如Python列表）运行方法或函数：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Identifying records coming from different files
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 识别来自不同文件的记录
- en: In some other use-cases, knowing the original source file of a given record
    could be a piece of information that we would also need to track.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些其他用例中，知道给定记录的原始来源文件可能是我们需要跟踪的信息。
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we expect that our DataFrame will hold an additional column that specifies
    the corresponding filename from which every record was added into the DataFrame:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们期望我们的DataFrame将包含一个额外的列，用于指定每条记录添加到DataFrame的对应文件名：
- en: '[PRE10]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Final Thoughts
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后想法
- en: In this article, we demonstrated how to load multiple CSV files and concatenate
    them into a single DataFrame in pandas. Additionally, we showcased how you can
    actually perform this import without having to explicitly specify the file names
    to be loaded. Finally, we discussed how you can even create a new column in the
    loaded DataFrame such that you can then identify the source file for each record.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了如何加载多个CSV文件并将它们合并到一个pandas DataFrame中。此外，我们展示了如何在实际执行导入时，不需要明确指定要加载的文件名。最后，我们讨论了如何在加载的DataFrame中创建一个新列，以便识别每条记录的来源文件。
- en: Now that you have loaded your data into pandas, you can take advantage of the
    rich API the package offers and lets you peform analyses, transformations and
    any kind of processing you might have to do. If you are looking to write a pandas
    DataFrame back to a CSV file make sure to follow the guide below 👇.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经将数据加载到pandas中，你可以利用该包提供的丰富API，进行分析、转换以及你可能需要的任何处理。如果你打算将pandas DataFrame写回CSV文件，请确保遵循下面的指南👇。
- en: '[](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)
    [## How to Write Pandas DataFrame to CSV File'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 如何将Pandas DataFrame写入CSV文件](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)'
- en: Taking advantage of all the options available when writing pandas DataFrames
    into CSV files
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用在将pandas DataFrame写入CSV文件时提供的所有选项
- en: towardsdatascience.com](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)'
- en: '[**Subscribe to Data Pipeline**](https://thedatapipeline.substack.com/welcome)**,
    a newsletter dedicated to Data Engineering**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[**订阅Data Pipeline**](https://thedatapipeline.substack.com/welcome)**，一份专注于数据工程的通讯**'
- en: 👇 **Related articles you may also like** 👇
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 👇 **你可能还会喜欢的相关文章** 👇
- en: '[](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [## ETL vs ELT: What’s the Difference?'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [## ETL与ELT：有什么区别？'
- en: A comparison between ETL and ELT in the context of Data Engineering
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据工程中ETL与ELT的比较
- en: towardsdatascience.com](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [## What are CTEs in SQL
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [## SQL中的CTE是什么
- en: Understanding Common Table Expression (CTE) in SQL
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解SQL中的**公用表表达式**（CTE）
- en: towardsdatascience.com](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
    [## What is dbt (data build tool)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
    [## 什么是dbt（数据构建工具）
- en: A gentle introduction to dbt that is taking over the data world
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍正在主宰数据领域的dbt
- en: towardsdatascience.com](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
