- en: How to Load Multiple CSV Files into a Pandas DataFrame
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•å°†å¤šä¸ª CSV æ–‡ä»¶åŠ è½½åˆ° Pandas DataFrame ä¸­
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff](https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff](https://towardsdatascience.com/load-multiple-csv-pandas-9c0c88c5adff)
- en: Importing and concatenating multiple CSV files into one pandas DataFrame
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¼å…¥å¹¶è¿æ¥å¤šä¸ª CSV æ–‡ä»¶åˆ°ä¸€ä¸ª pandas DataFrame ä¸­
- en: '[](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Giorgos
    Myrianthous](../Images/ff4b116e4fb9a095ce45eb064fde5af3.png)](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    [Giorgos Myrianthous](https://gmyrianthous.medium.com/?source=post_page-----9c0c88c5adff--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    Â·5 min readÂ·Jan 31, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c0c88c5adff--------------------------------)
    Â·5 åˆ†é’Ÿé˜…è¯»Â·2023å¹´1æœˆ31æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/649a65c5a7ba242fecd95611a28a9576.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/649a65c5a7ba242fecd95611a28a9576.png)'
- en: Photo by [Daniel K Cheung](https://unsplash.com/@danielkcheung?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/cPF2nlWcMY4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [Daniel K Cheung](https://unsplash.com/@danielkcheung?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    æä¾›ï¼Œæ¥è‡ª [Unsplash](https://unsplash.com/photos/cPF2nlWcMY4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: CSV (Common Separated Values) is a popular file format used to store and exchange
    data. In fact, this type of source is commonly used for relatively small volumes
    of data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: CSVï¼ˆé€—å·åˆ†éš”å€¼ï¼‰æ˜¯ä¸€ç§å¸¸ç”¨çš„æ–‡ä»¶æ ¼å¼ï¼Œç”¨äºå­˜å‚¨å’Œäº¤æ¢æ•°æ®ã€‚äº‹å®ä¸Šï¼Œè¿™ç§ç±»å‹çš„æºé€šå¸¸ç”¨äºç›¸å¯¹è¾ƒå°çš„æ•°æ®é‡ã€‚
- en: '`pandas` is a commonly used Python package that lets developers process and
    transform data as part of analytical and data science tasks. However, beform perforning
    any task pandas needs to load all the data into memory. This means that the package
    can only be used for relatively small volumes of data â€” well this depends on the
    capabilities of the host machine but for an average machine, we would only be
    able to load a few GBs of data within memory.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas` æ˜¯ä¸€ä¸ªå¸¸ç”¨çš„ Python åŒ…ï¼Œå®ƒå…è®¸å¼€å‘äººå‘˜å¤„ç†å’Œè½¬æ¢æ•°æ®ï¼Œä½œä¸ºåˆ†æå’Œæ•°æ®ç§‘å­¦ä»»åŠ¡çš„ä¸€éƒ¨åˆ†ã€‚ç„¶è€Œï¼Œåœ¨æ‰§è¡Œä»»ä½•ä»»åŠ¡ä¹‹å‰ï¼Œpandas
    éœ€è¦å°†æ‰€æœ‰æ•°æ®åŠ è½½åˆ°å†…å­˜ä¸­ã€‚è¿™æ„å‘³ç€è¯¥åŒ…åªèƒ½ç”¨äºç›¸å¯¹è¾ƒå°çš„æ•°æ®é‡â€”â€”è¿™å–å†³äºä¸»æœºæœºå™¨çš„èƒ½åŠ›ï¼Œä½†å¯¹äºä¸€å°æ™®é€šçš„æœºå™¨ï¼Œæˆ‘ä»¬åªèƒ½åœ¨å†…å­˜ä¸­åŠ è½½å‡  GB çš„æ•°æ®ã€‚'
- en: Therefore, loading CSV files in memory and then processing the data with pandas,
    is a very common task given that such files usually consist of data whose size
    can be loaded in-memory.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå°† CSV æ–‡ä»¶åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œç„¶åç”¨ pandas å¤„ç†æ•°æ®ï¼Œæ˜¯ä¸€ä¸ªéå¸¸å¸¸è§çš„ä»»åŠ¡ï¼Œå› ä¸ºè¿™äº›æ–‡ä»¶é€šå¸¸åŒ…å«å¯ä»¥åŠ è½½åˆ°å†…å­˜ä¸­çš„æ•°æ®ã€‚
- en: '[**Subscribe to Data Pipeline**](https://thedatapipeline.substack.com/welcome)**,
    a newsletter dedicated to Data Engineering**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[**è®¢é˜…æ•°æ®ç®¡é“**](https://thedatapipeline.substack.com/welcome)**ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºæ•°æ®å·¥ç¨‹çš„æ–°é—»é€šè®¯**'
- en: In this article, we will demonstrate how to load multiple CSV files in a single
    pandas DataFrame. Furthermore, weâ€™ll also showcase how to identify the source
    file in every record so that we can tell which data point belongs to a certain
    data file.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•å°†å¤šä¸ª CSV æ–‡ä»¶åŠ è½½åˆ°ä¸€ä¸ª pandas DataFrame ä¸­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†å±•ç¤ºå¦‚ä½•åœ¨æ¯æ¡è®°å½•ä¸­è¯†åˆ«æºæ–‡ä»¶ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥ç¡®å®šå“ªä¸ªæ•°æ®ç‚¹å±äºæŸä¸ªæ•°æ®æ–‡ä»¶ã€‚
- en: 'Now letâ€™s assume that we have data points collected in three separate CSV files
    namely `data_1.csv`, `data_2.csv` and `data_3.csv` :'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å‡è®¾æˆ‘ä»¬åœ¨ä¸‰ä¸ªåˆ†å¼€çš„ CSV æ–‡ä»¶ä¸­æ”¶é›†äº†æ•°æ®ç‚¹ï¼Œå³ `data_1.csv`ã€`data_2.csv` å’Œ `data_3.csv`ï¼š
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Concatenating multiple CSV files in a single pandas DataFrame
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨ä¸€ä¸ª pandas DataFrame ä¸­è¿æ¥å¤šä¸ª CSV æ–‡ä»¶
- en: Now that we have some dummy data in three separate CSV files, we can go ahead
    and import them in one DataFrame.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰ä¸‰ä¸ªåˆ†å¼€çš„ CSV æ–‡ä»¶ä¸­çš„ä¸€äº›è™šæ‹Ÿæ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­å°†å®ƒä»¬å¯¼å…¥åˆ°ä¸€ä¸ª DataFrame ä¸­ã€‚
- en: The first option we have is to read every individual CSV file using `pandas.read_csv()`
    function and concatenate all loaded files into a single DataFrame using `pandas.concatenate()`
    function.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€‰æ‹©çš„ç¬¬ä¸€ä¸ªé€‰é¡¹æ˜¯ä½¿ç”¨`pandas.read_csv()`å‡½æ•°è¯»å–æ¯ä¸ªå•ç‹¬çš„CSVæ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨`pandas.concatenate()`å‡½æ•°å°†æ‰€æœ‰åŠ è½½çš„æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€çš„DataFrameã€‚
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now the newly constructed DataFrame contains all the data points found in the
    three input CSV files:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ–°æ„å»ºçš„DataFrameåŒ…å«äº†ä¸‰ä¸ªè¾“å…¥CSVæ–‡ä»¶ä¸­å‘ç°çš„æ‰€æœ‰æ•°æ®ç‚¹ï¼š
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Notice how the index of our DataFrame is reset when loading data from multiple
    files. If instead youâ€™d want to create a new index for the newly created DataFrame,
    all you need to do is ignore the index whilst concatenating the files:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œå½“ä»å¤šä¸ªæ–‡ä»¶åŠ è½½æ•°æ®æ—¶ï¼Œæˆ‘ä»¬çš„DataFrameçš„ç´¢å¼•ä¼šè¢«é‡ç½®ã€‚å¦‚æœä½ å¸Œæœ›ä¸ºæ–°åˆ›å»ºçš„DataFrameåˆ›å»ºä¸€ä¸ªæ–°çš„ç´¢å¼•ï¼Œä½ åªéœ€åœ¨åˆå¹¶æ–‡ä»¶æ—¶å¿½ç•¥ç´¢å¼•å³å¯ï¼š
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Avoid specifying explicit file names
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é¿å…æ˜ç¡®æŒ‡å®šæ–‡ä»¶å
- en: Now letâ€™s assume that we have hundreds of different CSV files that we would
    want to concateante into a single DataFrame. Instead of wasting time and lines
    of code to explicitly write all the individual filenames down, we could instead
    use a whitecard.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å‡è®¾æˆ‘ä»¬æœ‰æ•°ç™¾ä¸ªä¸åŒçš„CSVæ–‡ä»¶ï¼Œæˆ‘ä»¬å¸Œæœ›å°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€çš„DataFrameã€‚ä¸å…¶æµªè´¹æ—¶é—´å’Œä»£ç è¡Œæ•°æ¥æ˜ç¡®å†™å‡ºæ‰€æœ‰å•ç‹¬çš„æ–‡ä»¶åï¼Œä¸å¦‚ä½¿ç”¨é€šé…ç¬¦ã€‚
- en: 'We can do so, by taking advantage of `glob` module, which is part of the standard
    libary and offers functionality to support unix style pathname pattern expansion.
    For example, in order to create a list containing of all the files ending with
    `.csv` filename under the current directory, we could use the following code snippet:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åˆ©ç”¨`glob`æ¨¡å—ï¼Œè¯¥æ¨¡å—æ˜¯æ ‡å‡†åº“çš„ä¸€éƒ¨åˆ†ï¼Œæä¾›æ”¯æŒUnixæ ·å¼è·¯å¾„åæ¨¡å¼æ‰©å±•çš„åŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†åˆ›å»ºä¸€ä¸ªåŒ…å«å½“å‰ç›®å½•ä¸‹æ‰€æœ‰ä»¥`.csv`ç»“å°¾çš„æ–‡ä»¶çš„åˆ—è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ç‰‡æ®µï¼š
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The full code that reads all csv files under current directory and concatenates
    them in a single pandas DataFrame is shared below:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢åˆ†äº«äº†ä¸€ä¸ªå®Œæ•´çš„ä»£ç ï¼Œè¯¥ä»£ç è¯»å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰CSVæ–‡ä»¶ï¼Œå¹¶å°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€çš„pandas DataFrameï¼š
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Another approach â€” and perhaps a more Pythonic one â€” is one that takes advantage
    `map` built-in function that lets us run a method or function over an [Iterable](/python-iterables-vs-iterators-688907fd755f)
    (like a Python List) without having to explicitly call a `for` loop:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§æ–¹æ³•â€”â€”å¯èƒ½æ›´ç¬¦åˆPythoné£æ ¼â€”â€”æ˜¯åˆ©ç”¨`map`å†…ç½®å‡½æ•°ï¼Œå®ƒå…è®¸æˆ‘ä»¬åœ¨ä¸æ˜¾å¼è°ƒç”¨`for`å¾ªç¯çš„æƒ…å†µä¸‹ï¼Œå¯¹[Iterable](/python-iterables-vs-iterators-688907fd755f)ï¼ˆå¦‚Pythonåˆ—è¡¨ï¼‰è¿è¡Œæ–¹æ³•æˆ–å‡½æ•°ï¼š
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Identifying records coming from different files
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯†åˆ«æ¥è‡ªä¸åŒæ–‡ä»¶çš„è®°å½•
- en: In some other use-cases, knowing the original source file of a given record
    could be a piece of information that we would also need to track.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸäº›å…¶ä»–ç”¨ä¾‹ä¸­ï¼ŒçŸ¥é“ç»™å®šè®°å½•çš„åŸå§‹æ¥æºæ–‡ä»¶å¯èƒ½æ˜¯æˆ‘ä»¬éœ€è¦è·Ÿè¸ªçš„ä¿¡æ¯ã€‚
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we expect that our DataFrame will hold an additional column that specifies
    the corresponding filename from which every record was added into the DataFrame:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœŸæœ›æˆ‘ä»¬çš„DataFrameå°†åŒ…å«ä¸€ä¸ªé¢å¤–çš„åˆ—ï¼Œç”¨äºæŒ‡å®šæ¯æ¡è®°å½•æ·»åŠ åˆ°DataFrameçš„å¯¹åº”æ–‡ä»¶åï¼š
- en: '[PRE10]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Final Thoughts
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æœ€åæƒ³æ³•
- en: In this article, we demonstrated how to load multiple CSV files and concatenate
    them into a single DataFrame in pandas. Additionally, we showcased how you can
    actually perform this import without having to explicitly specify the file names
    to be loaded. Finally, we discussed how you can even create a new column in the
    loaded DataFrame such that you can then identify the source file for each record.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åŠ è½½å¤šä¸ªCSVæ–‡ä»¶å¹¶å°†å®ƒä»¬åˆå¹¶åˆ°ä¸€ä¸ªpandas DataFrameä¸­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•åœ¨å®é™…æ‰§è¡Œå¯¼å…¥æ—¶ï¼Œä¸éœ€è¦æ˜ç¡®æŒ‡å®šè¦åŠ è½½çš„æ–‡ä»¶åã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•åœ¨åŠ è½½çš„DataFrameä¸­åˆ›å»ºä¸€ä¸ªæ–°åˆ—ï¼Œä»¥ä¾¿è¯†åˆ«æ¯æ¡è®°å½•çš„æ¥æºæ–‡ä»¶ã€‚
- en: Now that you have loaded your data into pandas, you can take advantage of the
    rich API the package offers and lets you peform analyses, transformations and
    any kind of processing you might have to do. If you are looking to write a pandas
    DataFrame back to a CSV file make sure to follow the guide below ğŸ‘‡.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å·²ç»å°†æ•°æ®åŠ è½½åˆ°pandasä¸­ï¼Œä½ å¯ä»¥åˆ©ç”¨è¯¥åŒ…æä¾›çš„ä¸°å¯ŒAPIï¼Œè¿›è¡Œåˆ†æã€è½¬æ¢ä»¥åŠä½ å¯èƒ½éœ€è¦çš„ä»»ä½•å¤„ç†ã€‚å¦‚æœä½ æ‰“ç®—å°†pandas DataFrameå†™å›CSVæ–‡ä»¶ï¼Œè¯·ç¡®ä¿éµå¾ªä¸‹é¢çš„æŒ‡å—ğŸ‘‡ã€‚
- en: '[](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)
    [## How to Write Pandas DataFrame to CSV File'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[## å¦‚ä½•å°†Pandas DataFrameå†™å…¥CSVæ–‡ä»¶](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)'
- en: Taking advantage of all the options available when writing pandas DataFrames
    into CSV files
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åˆ©ç”¨åœ¨å°†pandas DataFrameå†™å…¥CSVæ–‡ä»¶æ—¶æä¾›çš„æ‰€æœ‰é€‰é¡¹
- en: towardsdatascience.com](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/pandas-to-csv-aab4ac27c455?source=post_page-----9c0c88c5adff--------------------------------)'
- en: '[**Subscribe to Data Pipeline**](https://thedatapipeline.substack.com/welcome)**,
    a newsletter dedicated to Data Engineering**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[**è®¢é˜…Data Pipeline**](https://thedatapipeline.substack.com/welcome)**ï¼Œä¸€ä»½ä¸“æ³¨äºæ•°æ®å·¥ç¨‹çš„é€šè®¯**'
- en: ğŸ‘‡ **Related articles you may also like** ğŸ‘‡
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‡ **ä½ å¯èƒ½è¿˜ä¼šå–œæ¬¢çš„ç›¸å…³æ–‡ç« ** ğŸ‘‡
- en: '[](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [## ETL vs ELT: Whatâ€™s the Difference?'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [## ETLä¸ELTï¼šæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ'
- en: A comparison between ETL and ELT in the context of Data Engineering
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°æ®å·¥ç¨‹ä¸­ETLä¸ELTçš„æ¯”è¾ƒ
- en: towardsdatascience.com](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [## What are CTEs in SQL
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/etl-vs-elt-68e221d78719?source=post_page-----9c0c88c5adff--------------------------------)
    [](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [## SQLä¸­çš„CTEæ˜¯ä»€ä¹ˆ
- en: Understanding Common Table Expression (CTE) in SQL
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç†è§£SQLä¸­çš„**å…¬ç”¨è¡¨è¡¨è¾¾å¼**ï¼ˆCTEï¼‰
- en: towardsdatascience.com](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
    [## What is dbt (data build tool)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/cte-sql-945e4b461de3?source=post_page-----9c0c88c5adff--------------------------------)
    [](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
    [## ä»€ä¹ˆæ˜¯dbtï¼ˆæ•°æ®æ„å»ºå·¥å…·ï¼‰
- en: A gentle introduction to dbt that is taking over the data world
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»‹ç»æ­£åœ¨ä¸»å®°æ•°æ®é¢†åŸŸçš„dbt
- en: towardsdatascience.com](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/dbt-55b35c974533?source=post_page-----9c0c88c5adff--------------------------------)
