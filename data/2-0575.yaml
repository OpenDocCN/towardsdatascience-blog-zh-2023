- en: CountVectorizer to Extract Features from Texts in Python, in Detail
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CountVectorizer提取文本特征的详细教程
- en: 原文：[https://towardsdatascience.com/countvectorizer-to-extract-features-from-texts-in-python-in-detail-0e7147c10753](https://towardsdatascience.com/countvectorizer-to-extract-features-from-texts-in-python-in-detail-0e7147c10753)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/countvectorizer-to-extract-features-from-texts-in-python-in-detail-0e7147c10753](https://towardsdatascience.com/countvectorizer-to-extract-features-from-texts-in-python-in-detail-0e7147c10753)
- en: '![](../Images/07e11611df2a6a84e10f07ef5553f473.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07e11611df2a6a84e10f07ef5553f473.png)'
- en: Photo by [Towfiqu barbhuiya](https://unsplash.com/@towfiqu999999?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 照片来源：[Towfiqu barbhuiya](https://unsplash.com/@towfiqu999999?utm_source=medium&utm_medium=referral)
    于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Everything you need to know to use CountVectorizer efficiently in Sklearn
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用CountVectorizer在Sklearn中高效工作的所有必备知识
- en: '[](https://rashida00.medium.com/?source=post_page-----0e7147c10753--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----0e7147c10753--------------------------------)[](https://towardsdatascience.com/?source=post_page-----0e7147c10753--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----0e7147c10753--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----0e7147c10753--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rashida00.medium.com/?source=post_page-----0e7147c10753--------------------------------)[![Rashida
    Nasrin Sucky](../Images/42bd057e8eca255907c43c29a498f2ca.png)](https://rashida00.medium.com/?source=post_page-----0e7147c10753--------------------------------)[](https://towardsdatascience.com/?source=post_page-----0e7147c10753--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----0e7147c10753--------------------------------)
    [Rashida Nasrin Sucky](https://rashida00.medium.com/?source=post_page-----0e7147c10753--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----0e7147c10753--------------------------------)
    ·7 min read·Oct 21, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----0e7147c10753--------------------------------)
    ·阅读时间7分钟·2023年10月21日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: The most basic data processing that any Natural Language Processing (NLP) project
    requires is to convert the text data to the numeric data. As long as the data
    is in text form we cannot do any kind of computation action on it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 任何自然语言处理（NLP）项目最基本的数据处理是将文本数据转换为数值数据。只要数据是文本形式，我们无法对其进行任何计算操作。
- en: There are multiple methods available for this text-to-numeric data conversion.
    This tutorial will explain one of the most basic vectorizers, the CountVectorizer
    method in the scikit-learn library.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以进行文本到数值数据的转换。本教程将解释其中最基本的向量化方法之一，即scikit-learn库中的CountVectorizer方法。
- en: This method is very simple. It takes the frequency of occurrence of each word
    as the numeric value. An example will make it clear.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法非常简单。它将每个单词的出现频率作为数值。一个例子会让它更清楚。
- en: 'In the following code block:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码块中：
- en: We will import the CountVectorizer method.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将导入CountVectorizer方法。
- en: Call the method.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用该方法。
- en: Fit the text data to the CountVectorizer method and, convert that to an array.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文本数据适配到CountVectorizer方法中，并转换为数组。
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here I have the numeric values representing the text data above.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我有表示上面文本数据的数值。
- en: '**How do we know which values represent which words in the text?**'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**我们如何知道哪些值代表文本中的哪些单词？**'
- en: To make that clear, it will be helpful to convert the array into a DataFrame
    where column names will be the words themselves.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了澄清这一点，将数组转换为DataFrame，其中列名将是单词本身，将会很有帮助。
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/94764d6278f9ff68ed119eb1bdaeacbd.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94764d6278f9ff68ed119eb1bdaeacbd.png)'
- en: Image By Author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Now, it shows clearly. The value of the word ‘also’ is 1 which means ‘also’
    appeared only once in the test. The word ‘aunt’ came twice in the text. So, the
    value of the word ‘aunt’ is 2.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，它显示得很清楚。单词‘also’的值为1，这意味着‘also’在测试中仅出现了一次。单词‘aunt’在文本中出现了两次。所以，单词‘aunt’的值为2。
- en: 'In the last example, all the sentences were in one string. So, we got only
    one row of data for four sentences. Let’s rearrange the text and see what happens:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个例子中，所有的句子都在一个字符串中。所以，我们为四个句子只得到了一个数据行。让我们重新排列文本，看看会发生什么：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Output:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This time we have a two-dimensional array with one individual list for each
    string in the text. Putting this array in a DataFrame:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们有一个二维数组，其中每个字符串在文本中都有一个单独的列表。将这个数组放入DataFrame中：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/6078ed9e6f2bfa6b211dec032da19692.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6078ed9e6f2bfa6b211dec032da19692.png)'
- en: Image By Author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Look carefully at this DataFrame. All the words are there as column names. Each
    row represents a string in the text and the value in the column shows how many
    times the word appeared in the string. If the word doesn’t appear, the value is
    zero.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细查看这个 DataFrame。所有单词都作为列名存在。每一行代表文本中的一个字符串，列中的值显示了单词在该字符串中出现的次数。如果单词没有出现，值为零。
- en: There are some parameters available for [CountVectorizer method](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)
    in sklearn library that are worth checking.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `sklearn` 库的 [CountVectorizer 方法](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)
    中，有一些值得检查的参数。
- en: lowercase
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: lowercase
- en: If you notice by default CountVectorizer method converts all the words to lowercase.
    If you do not want that you need to set lowercase = False.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你注意到，默认情况下 `CountVectorizer` 方法将所有单词转换为小写。如果你不希望这样，你需要将 `lowercase` 设置为 `False`。
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/f02a7874d5534e076a2e241c828d0433.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f02a7874d5534e076a2e241c828d0433.png)'
- en: Image By Author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Now, the words are taken the way it is in the text. The word ‘My’ came twice
    in the DataFrame as ‘My’, and ‘my’.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，单词以文本中的原样形式被取出。单词 ‘My’ 在 DataFrame 中出现了两次，分别为 ‘My’ 和 ‘my’。
- en: stop_words
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: stop_words
- en: The stop_words are the words that we can consider unnecessary for the analytics.
    In our text, I may think ‘also’, ‘is’, and ‘to’ are not necessary words. I can
    simply exclude them which is a very important part of data processing for most
    analytics or machine learning models. Here we have only 4 strings. But in real-world
    analytics, we need to deal with thousands of strings. Thousands of strings may
    involve thousands of words and each word becomes a feature. If we can exclude
    some of the frequently appearing or not so necessary for the model, it will save
    a lot of computational effort.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`stop_words` 是我们认为对分析不必要的单词。在我们的文本中，我可能认为‘also’、‘is’和‘to’是不必要的单词。我可以简单地排除它们，这在大多数分析或机器学习模型的数据处理过程中是非常重要的一部分。这里我们只有4个字符串。但在实际的分析中，我们需要处理成千上万的字符串。成千上万的字符串可能涉及成千上万的单词，每个单词都成为一个特征。如果我们可以排除一些频繁出现的或对模型不那么必要的单词，将节省大量计算工作。'
- en: There are default lists of stop words in CountVectorizer method itself for a
    lot of major languages. Here is an example.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`CountVectorizer` 方法本身为许多主要语言提供了默认的停用词列表。这里是一个例子。'
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/48451efb85beb3f43c23c8a849add729.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48451efb85beb3f43c23c8a849add729.png)'
- en: Image By Author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Look! A lot of the words are gone!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 看！许多单词都被去除了！
- en: 'If you think the words that are gone are not enough for you or too many words
    are gone, please provide your own list of stop_words. For example, if I only want
    ‘also’, ‘is’, ‘am’, and ‘to’ to be excluded, I will provide the list of stop_words
    like this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认为已经去除的单词不够，或者去除了太多单词，请提供你自己的 `stop_words` 列表。例如，如果我只想排除‘also’、‘is’、‘am’
    和 ‘to’，我会像这样提供 `stop_words` 列表：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: max_df
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: max_df
- en: This is another way of eliminating words. If we use max_df = 0.5 that means
    if a word appears in more than 50% of the documents or strings then that will
    be eliminated. An integer value can be used as max_df as well. Max_df = 20 means
    if a word exists in more than 20 documents it will be eliminated.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种去除单词的方式。如果我们使用 `max_df = 0.5`，这意味着如果一个单词出现在超过50%的文档或字符串中，那么该单词将被去除。`max_df`
    也可以使用整数值。例如，`max_df = 20` 意味着如果一个单词存在于超过20个文档中，它将被去除。
- en: 'To demonstrate this, I created a new text:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这一点，我创建了一个新文本：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/87bcda6c7b82b0fa5e88ee8cf2012fc1.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87bcda6c7b82b0fa5e88ee8cf2012fc1.png)'
- en: Image By Author
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: ‘Lilly’ appeared in 4 documents out of 5\. So it is eliminated. Same as ‘is’.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ‘Lilly’ 出现在5个文档中的4个中。因此它被去除了。‘is’ 也是如此。
- en: min_df
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: min_df
- en: This is the opposite of max_df. If a document appears less than a proportion
    or a specified they are eliminated by min_df. In this example, I am using the
    same text as the last example and setting min_df = 2\. So, any word that exists
    in less than 2 documents is eliminated.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这与 `max_df` 相反。如果一个文档出现的比例或指定的次数少于 `min_df`，则该文档会被排除。在这个例子中，我使用了与上一个例子相同的文本，并将
    `min_df` 设置为 `2`。因此，任何在少于2个文档中出现的单词将被去除。
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/48996fc533d77f80db94cd3603d64e54.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48996fc533d77f80db94cd3603d64e54.png)'
- en: Image By Author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: We have only three words left as we already have just 5 documents. This can
    be useful in machine learning projects.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只有3个单词剩下，因为我们只有5个文档。这在机器学习项目中可能很有用。
- en: When we are trying to extract a trend, the words that only exist seldom in a
    couple of documents out of thousands of documents, are not very helpful.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当我们试图提取趋势时，只有在成千上万的文档中的几个文档中偶尔出现的词汇并不太有帮助。
- en: max_features
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`max_features`'
- en: This is another useful feature. When we have thousands of words, it is computationally
    expensive and time-consuming. If we have a total of 10000 words that becomes 10000
    features. Now if you think only the top 2000 words might be good enough based
    on the term frequency, you can simply use max_features = 2000\. Here we even do
    not have that many words. So, I will use max_features = 5.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个有用的功能。当我们有成千上万的词汇时，计算开销大且耗时。如果我们总共有 10000 个词汇，那么就有 10000 个特征。现在，如果你认为根据词频只有前
    2000 个词汇可能足够好，你可以简单地使用 `max_features = 2000`。这里甚至没有这么多词汇。所以，我会使用 `max_features
    = 5`。
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/f8e45d120b386f71038045cf86780d5b.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8e45d120b386f71038045cf86780d5b.png)'
- en: Image By Author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Here we have the top five words that appeared the most.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是出现频率最高的五个词。
- en: Conclusion
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: This article tried to explain the CountVectorizer method and how you can best
    use this method of text processing. The parameters I explained here can make your
    analytics or Natural Language Processing models efficient if used correctly. These
    parameters can be used alone or you can use some of them together with one another
    based on your need. There is a lot of scope for experiment. There are more sophisticated
    methods to vectorize text data nowadays. But this simple method still works in
    many cases.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章尝试解释 CountVectorizer 方法以及如何最好地使用这种文本处理方法。我在这里解释的参数如果正确使用，可以使你的分析或自然语言处理模型更加高效。这些参数可以单独使用，也可以根据需要将其中的一些参数组合在一起。实验的空间很大。现在有更复杂的方法来向量化文本数据，但这种简单的方法在许多情况下仍然有效。
- en: Feel free to follow me on [Twitter](https://twitter.com/rashida048) and like
    my [Facebook](https://www.facebook.com/rashida.smith.161) page.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 随时可以在 [Twitter](https://twitter.com/rashida048) 上关注我，并点赞我的 [Facebook](https://www.facebook.com/rashida.smith.161)
    页面。
- en: 'If you want a video version of this tutorial, here is the link:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要这个教程的视频版本，这里是链接：
- en: More Reading
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多阅读
- en: '[](https://pub.towardsai.net/a-complete-exploratory-data-analysis-in-python-a2148daac072?source=post_page-----0e7147c10753--------------------------------)
    [## A Complete Exploratory Data Analysis in Python'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[完整的 Python 探索性数据分析](https://pub.towardsai.net/a-complete-exploratory-data-analysis-in-python-a2148daac072?source=post_page-----0e7147c10753--------------------------------)
    [## 完整的 Python 探索性数据分析'
- en: Data Cleaning, Analysis, Visualization, Feature Selection, Predictive Modeling
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据清洗、分析、可视化、特征选择、预测建模
- en: pub.towardsai.net](https://pub.towardsai.net/a-complete-exploratory-data-analysis-in-python-a2148daac072?source=post_page-----0e7147c10753--------------------------------)
    [](/30-very-useful-pandas-functions-for-everyday-data-analysis-tasks-f1eae16409af?source=post_page-----0e7147c10753--------------------------------)
    [## 30 Very Useful Pandas Functions for Everyday Data Analysis Tasks
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[30 个非常有用的 Pandas 函数用于日常数据分析任务](https://pub.towardsai.net/a-complete-exploratory-data-analysis-in-python-a2148daac072?source=post_page-----0e7147c10753--------------------------------)
    [](/30-very-useful-pandas-functions-for-everyday-data-analysis-tasks-f1eae16409af?source=post_page-----0e7147c10753--------------------------------)
    [## 30 个非常有用的 Pandas 函数用于日常数据分析任务'
- en: Pandas Cheatsheet
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pandas 备忘单
- en: towardsdatascience.com](/30-very-useful-pandas-functions-for-everyday-data-analysis-tasks-f1eae16409af?source=post_page-----0e7147c10753--------------------------------)
    [](/6-tips-for-dealing-with-null-values-e16d1d1a1b33?source=post_page-----0e7147c10753--------------------------------)
    [## 6 Tips for Dealing With Null Values
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[6 个处理缺失值的技巧](https://towardsdatascience.com/30-very-useful-pandas-functions-for-everyday-data-analysis-tasks-f1eae16409af?source=post_page-----0e7147c10753--------------------------------)
    [](/6-tips-for-dealing-with-null-values-e16d1d1a1b33?source=post_page-----0e7147c10753--------------------------------)
    [## 6 个处理缺失值的技巧'
- en: Includes Iterative Method, Mean and Median Fill with Groupby, Mean and Median
    Fill
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 包括迭代方法、均值和中位数填充与分组、均值和中位数填充
- en: towardsdatascience.com](/6-tips-for-dealing-with-null-values-e16d1d1a1b33?source=post_page-----0e7147c10753--------------------------------)
    [](https://pub.towardsai.net/a-detailed-tutorial-on-polynomial-regression-in-python-overview-implementation-and-overfitting-e319fc7e5b8f?source=post_page-----0e7147c10753--------------------------------)
    [## A Detailed Tutorial on Polynomial Regression in Python, Overview, Implementation,
    and Overfitting
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[详细的 Python 多项式回归教程：概述、实现和过拟合](https://pub.towardsai.net/a-detailed-tutorial-on-polynomial-regression-in-python-overview-implementation-and-overfitting-e319fc7e5b8f?source=post_page-----0e7147c10753--------------------------------) '
- en: Complete code in Python
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整的 Python 代码
- en: pub.towardsai.net](https://pub.towardsai.net/a-detailed-tutorial-on-polynomial-regression-in-python-overview-implementation-and-overfitting-e319fc7e5b8f?source=post_page-----0e7147c10753--------------------------------)
    [](/tensorflow-model-training-using-gradienttape-f2093646ab13?source=post_page-----0e7147c10753--------------------------------)
    [## TensorFlow Model Training Using GradientTape
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[pub.towardsai.net](https://pub.towardsai.net/a-detailed-tutorial-on-polynomial-regression-in-python-overview-implementation-and-overfitting-e319fc7e5b8f?source=post_page-----0e7147c10753--------------------------------)
    [## 使用 GradientTape 进行 TensorFlow 模型训练'
- en: Use of GradientTape to Update the Weights
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 GradientTape 更新权重
- en: towardsdatascience.com](/tensorflow-model-training-using-gradienttape-f2093646ab13?source=post_page-----0e7147c10753--------------------------------)
    [](/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50?source=post_page-----0e7147c10753--------------------------------)
    [## Anomaly Detection in TensorFlow and Keras Using the Autoencoder Method
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/tensorflow-model-training-using-gradienttape-f2093646ab13?source=post_page-----0e7147c10753--------------------------------)
    [## 使用自编码器方法进行 TensorFlow 和 Keras 的异常检测'
- en: A cutting-edge unsupervised method for noise removal, dimensionality reduction,
    anomaly detection, and more
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一种前沿的无监督方法，用于去噪、降维、异常检测等
- en: towardsdatascience.com](/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50?source=post_page-----0e7147c10753--------------------------------)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/anomaly-detection-in-tensorflow-and-keras-using-the-autoencoder-method-5600aca29c50?source=post_page-----0e7147c10753--------------------------------)'
