- en: Understanding Noisy Data and Uncertainty in Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解机器学习中的噪声数据和不确定性
- en: 原文：[https://towardsdatascience.com/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=collection_archive---------8-----------------------#2023-01-23](https://towardsdatascience.com/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=collection_archive---------8-----------------------#2023-01-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=collection_archive---------8-----------------------#2023-01-23](https://towardsdatascience.com/understanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198?source=collection_archive---------8-----------------------#2023-01-23)
- en: The actual reason your machine learning model isn’t working
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你的机器学习模型未能工作的实际原因
- en: '[](https://harrisonfhoffman.medium.com/?source=post_page-----4a2995a84198--------------------------------)[![Harrison
    Hoffman](../Images/5eaa3e2bd0507297eb6c4a7efcf06324.png)](https://harrisonfhoffman.medium.com/?source=post_page-----4a2995a84198--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4a2995a84198--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4a2995a84198--------------------------------)
    [Harrison Hoffman](https://harrisonfhoffman.medium.com/?source=post_page-----4a2995a84198--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://harrisonfhoffman.medium.com/?source=post_page-----4a2995a84198--------------------------------)[![Harrison
    Hoffman](../Images/5eaa3e2bd0507297eb6c4a7efcf06324.png)](https://harrisonfhoffman.medium.com/?source=post_page-----4a2995a84198--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4a2995a84198--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4a2995a84198--------------------------------)
    [Harrison Hoffman](https://harrisonfhoffman.medium.com/?source=post_page-----4a2995a84198--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F38889d0801d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198&user=Harrison+Hoffman&userId=38889d0801d0&source=post_page-38889d0801d0----4a2995a84198---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4a2995a84198--------------------------------)
    ·9 min read·Jan 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4a2995a84198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198&user=Harrison+Hoffman&userId=38889d0801d0&source=-----4a2995a84198---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F38889d0801d0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198&user=Harrison+Hoffman&userId=38889d0801d0&source=post_page-38889d0801d0----4a2995a84198---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4a2995a84198--------------------------------)
    · 9分钟阅读 · 2023年1月23日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4a2995a84198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198&source=-----4a2995a84198---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4a2995a84198&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-noisy-data-and-uncertainty-in-machine-learning-4a2995a84198&source=-----4a2995a84198---------------------bookmark_footer-----------)'
- en: The fields of Artificial Intelligence and Machine Learning are hotter than ever.
    With models like Chat GPT and Stable Diffusion taking the world by storm, AI and
    ML hype has made a resurgence and is catching the attention of [the masses](https://www.google.com/search?tbm=vid&sxsrf=AJOqlzXI5TC9wmd1MTAKaqmrRY_q6b0k3Q%3A1674266462280&q=chatgpt&spell=1&sa=X&ved=2ahUKEwiz-_jNyNf8AhUZk2oFHY1kCZoQBSgAegQIERAB&biw=1185&bih=714&dpr=2).
    With all of this hype, it’s important to remind ourselves who the governor of
    machine learning success is — high-quality data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能和机器学习领域比以往任何时候都更受关注。像 Chat GPT 和 Stable Diffusion 这样的模型掀起了全球热潮，AI 和 ML 的炒作卷土重来，吸引了[大众](https://www.google.com/search?tbm=vid&sxsrf=AJOqlzXI5TC9wmd1MTAKaqmrRY_q6b0k3Q%3A1674266462280&q=chatgpt&spell=1&sa=X&ved=2ahUKEwiz-_jNyNf8AhUZk2oFHY1kCZoQBSgAegQIERAB&biw=1185&bih=714&dpr=2)的关注。面对这些炒作，我们必须提醒自己机器学习成功的真正主宰是谁——高质量的数据。
- en: In the absence of quality training data, supervised machine learning models
    offer no utility. Unfortunately, most real-world data science projects fail because
    unrealistic expectations about model performance are made before the quality of
    the data source is fully understood. This article will attempt to provide intuition
    about noisy data and why machine learning models fail to perform. We will explore
    the nature of supervised learning and deterministic functions, different types
    of model uncertainty, and discuss methods for mitigating this uncertainty and
    managing expectations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在缺乏高质量训练数据的情况下，监督学习模型毫无用处。不幸的是，大多数实际的数据科学项目失败是因为在完全理解数据源的质量之前，对模型性能有不切实际的期望。本文将尝试提供关于噪声数据的直觉，以及为什么机器学习模型无法表现良好的原因。我们将探讨监督学习和确定性函数的本质、不同类型的模型不确定性，并讨论减轻这种不确定性和管理期望的方法。
- en: Supervised Learning Formulation
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习公式
- en: 'At its core, supervised machine learning is all about function approximation.
    We present a model with some inputs (X) and targets (y), and expect the model
    to approximate (or learn) a function that maps X to y by optimizing an objective
    function. More formally, the formulation for supervised learning looks something
    like this:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从根本上讲，监督学习就是函数逼近。我们向模型提供一些输入（X）和目标（y），并期望模型通过优化目标函数来逼近（或学习）一个将 X 映射到 y 的函数。更正式地说，监督学习的公式如下：
