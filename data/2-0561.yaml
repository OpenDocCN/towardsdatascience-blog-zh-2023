- en: Convergence in Probability or Distribution
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率收敛或分布收敛
- en: 原文：[https://towardsdatascience.com/convergence-in-probability-or-distribution-1766e08125cd](https://towardsdatascience.com/convergence-in-probability-or-distribution-1766e08125cd)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/convergence-in-probability-or-distribution-1766e08125cd](https://towardsdatascience.com/convergence-in-probability-or-distribution-1766e08125cd)
- en: What is the difference between the two?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这两者之间有什么区别？
- en: '[](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)[![Shuo
    Wang](../Images/17a7299c0a36d9a4c0d07ebfc9d5c282.png)](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)
    [Shuo Wang](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)[![Shuo
    Wang](../Images/17a7299c0a36d9a4c0d07ebfc9d5c282.png)](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)
    [Shuo Wang](https://r-shuo-wang.medium.com/?source=post_page-----1766e08125cd--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)
    ·6 min read·Sep 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1766e08125cd--------------------------------)
    ·6 min read·2023年9月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/38ca6ca8cbc2275769040cd2e887056b.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38ca6ca8cbc2275769040cd2e887056b.png)'
- en: Image by author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: During your study of statistics, have you encountered the concepts of convergence
    in probability and convergence in distribution? Have you ever pondered why these
    concepts were introduced in the first place? If you have, then this story aims
    to help you answer some of those questions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在你学习统计学的过程中，你是否遇到过概率收敛和分布收敛的概念？你是否曾思考过这些概念最初是为何被引入的？如果有的话，这个故事旨在帮助你回答一些这些问题。
- en: '**Convergence in Probability**'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**概率收敛**'
- en: 'Let’s begin by delving into the concept of convergence in probability, as it
    is the more straightforward concept to grasp. Imagine we have a sequence of random
    variables: *X1*, *X2*, …, *Xn*, and as we let n approach infinity, if the probability
    that *Xn* is very close to x approaches 1, we can conclude that *Xn* converges
    to x in probability.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先**深入**了解概率收敛的概念，因为它是更容易理解的概念。假设我们有一个随机变量序列：*X1*、*X2*、…、*Xn*，当 n 趋近于无穷大时，如果
    *Xn* 很接近 x 的概率趋近于 1，那么我们可以得出结论，*Xn* 在概率上收敛于 x。
- en: '![](../Images/25a2ce3fc83c323a08fb4a0a483aa329.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25a2ce3fc83c323a08fb4a0a483aa329.png)'
- en: Why is it defined in this manner? The rationale behind this definition stems
    from the fact that, regardless of how large n becomes, Xn will never precisely
    equal *x* (the constant). The most we can ascertain is to specify how close *Xn*
    must be to *x* in terms of the probability that *Xn* falls within a certain interval
    around *x*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这样定义？这种定义的合理性源于这样一个事实：无论 n 多大，*Xn* 永远不会精确等于 *x*（常量）。我们能做的最多是确定 *Xn* 必须在多大程度上接近
    *x*，即 *Xn* 落在 *x* 周围某个区间的概率。
- en: Hence, our definition asserts that as n approaches infinity, the likelihood
    of *Xn* differing from *x* by an amount greater than ε diminishes to an infinitesimal
    level, ultimately approaching zero. Moreover, ε can be arbitrarily small.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的定义声称，当 n 趋近于无穷大时，*Xn* 与 *x* 之间的差异大于 ε 的可能性会降低到一个微小的水平，最终接近于零。此外，ε 可以任意小。
- en: An illustrative example of convergence in probability would be the concept of
    the sample mean. Consider the scenario where we repeatedly draw n samples from
    a normal distribution with a mean of 0 and a standard deviation of 0.1\. If we
    calculate the sample mean of these n samples, this resulting sample mean becomes
    a random variable denoted as Xn and possesses its own distribution.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个概率收敛的例子是样本均值的概念。考虑这样一个场景，我们从均值为 0、标准差为 0.1 的正态分布中反复抽取 n 个样本。如果我们计算这些 n 个样本的样本均值，那么得到的样本均值成为一个随机变量，记作
    *Xn*，并且具有其自己的分布。
- en: 'The question then arises: What is the nature of this distribution? When n=1,
    the sample mean is simply equivalent to the individual sample itself, and its
    distribution mirrors the population distribution, specifically the normal distribution
    with a mean of 0 and a standard deviation of 0.1.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么问题来了：这个分布的性质是什么？当 n=1 时，样本均值实际上等同于单个样本本身，其分布反映了总体分布，特别是均值为 0、标准差为 0.1 的正态分布。
- en: But what if *n=1000*? Intuitively, in such cases, we would expect the sample
    mean calculated to be very close to the population mean, which is 0\. It is reasonable
    to assume that when we repeatedly draw 1000 samples and calculate the sample mean,
    the values might cluster around numbers like 0.001, 0.002, -0.001, and so on,
    without significant fluctuations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果 *n=1000* 呢？直观上，在这种情况下，我们会期望计算出的样本均值非常接近总体均值，即 0。可以合理假设，当我们反复抽取 1000 个样本并计算样本均值时，数值可能会聚集在
    0.001、0.002、-0.001 等附近，没有显著波动。
- en: What if n=1,000,000? In this scenario, it’s highly probable that the sample
    means would be extremely close to 0, with any deviation from this value being
    minuscule.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 n=1,000,000 呢？在这种情况下，样本均值非常可能接近 0，任何偏离这个值的情况都极其微小。
- en: This is precisely the essence of convergence in probability. As n increases,
    the distribution of the random variable *Xn* becomes progressively narrower, ultimately
    converging towards a single value.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是概率收敛的本质。随着 n 的增加，随机变量 *Xn* 的分布变得越来越窄，最终收敛到一个单一的值。
- en: '![](../Images/c98a39e7d9b0895e295064f66edcbf4f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c98a39e7d9b0895e295064f66edcbf4f.png)'
- en: The sampling distribution of the sample mean is visualized in a sequence of
    histograms, showcasing samples drawn from a normal distribution for different
    sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 样本均值的抽样分布通过一系列直方图进行了可视化，展示了从正态分布中抽取的样本，样本量分别为[1, 10, 100, 1000]。图片由作者提供。
- en: 'This phenomenon occurs not only with samples drawn from a normal distribution
    but also with the binomial distribution. When we draw n samples from a binomial
    distribution with 1 trial and a probability of success of 0.5, we observe a convergence
    pattern very similar to the previous example:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种现象不仅发生在从正态分布中抽取的样本中，也会在二项分布中出现。当我们从一个试验且成功概率为 0.5 的二项分布中抽取 n 个样本时，我们观察到的收敛模式与前面的例子非常相似：
- en: '![](../Images/fe260b5d0ec160f3075f62b4e23200fd.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe260b5d0ec160f3075f62b4e23200fd.png)'
- en: The sampling distribution of the sample mean is visualized in a sequence of
    histograms, showcasing samples drawn from a binomial distribution for different
    sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 样本均值的抽样分布通过一系列直方图进行了可视化，展示了从二项分布中抽取的样本，样本量分别为[1, 10, 100, 1000]。图片由作者提供。
- en: Regardless of how tightly we attempt to constrain the sample mean within a specific
    interval, we can always identify a sufficiently large n where the probability
    of the sample mean falling within that interval approaches 100%.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们如何努力将样本均值约束在一个特定的区间内，我们总能找到一个足够大的 n，使得样本均值落入该区间的概率接近 100%。
- en: Convergence in Distribution
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布收敛
- en: Conversely, it’s important to note that not every sequence of random variables
    converges to a single number in probability. In many cases, a sequence of random
    variables does not converge to a specific number but instead converges to a random
    variable with its own distinct distribution. In such instances, we refer to this
    behavior as convergence in distribution.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，需要注意的是，并不是每一个随机变量序列都在概率上收敛到一个单一的数字。在许多情况下，随机变量序列不会收敛到特定的数字，而是收敛到一个具有自己独特分布的随机变量。在这种情况下，我们将这种行为称为分布收敛。
- en: '![](../Images/d5c675de23c01ecad4885ea5694a0169.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d5c675de23c01ecad4885ea5694a0169.png)'
- en: CDFn(t) represents the cumulative distribution function of the random variable
    Xn within the given sequence, while CDF(t) signifies the cumulative distribution
    function of a random variable X.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: CDFn(t) 表示给定序列中随机变量 Xn 的累积分布函数，而 CDF(t) 表示随机变量 X 的累积分布函数。
- en: The definition states that when considering a sequence of random variables *Xn*,
    the cumulative distribution function (CDF) of the random variables in this sequence
    converges to the CDF of a random variable *X* as *n* approaches infinity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 定义指出，当考虑一个随机变量序列 *Xn* 时，该序列中的随机变量的累积分布函数（CDF）会随着 *n* 的增加而收敛到随机变量 *X* 的累积分布函数。
- en: 'An illustrative example of this concept is the standardized sample mean. Below,
    you will find the definition of the standardized sample mean:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念的一个说明性例子是标准化样本均值。下面，你会找到标准化样本均值的定义：
- en: '![](../Images/783c3a10e68ad323288653e2b3fd0ac3.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/783c3a10e68ad323288653e2b3fd0ac3.png)'
- en: Z represents the standardized sample mean, where n is the number of samples
    drawn, X_bar is the sample mean, 𝜇 is the population mean, and 𝜎 is the population
    standard deviation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Z 代表标准化样本均值，其中 n 是抽取的样本数量，X_bar 是样本均值，𝜇 是总体均值，𝜎 是总体标准差。
- en: 'When you have drawn n samples from the population, you can obtain the standardized
    sample mean by following these steps: calculate the sample mean from the n samples,
    subtract the population mean from it, multiply the result by the square root of
    the sample size, and then divide by the population standard deviation.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当你从总体中抽取 n 个样本时，可以通过以下步骤获得标准化样本均值：计算这 n 个样本的均值，从中减去总体均值，将结果乘以样本大小的平方根，然后除以总体标准差。
- en: Interestingly, while the sample mean itself converges in probability to the
    population mean, the standardized sample mean converges in distribution to a random
    variable with normal distribution with a mean of zero and a standard deviation
    of one.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，虽然样本均值本身在概率上收敛到总体均值，但标准化样本均值在分布上收敛到均值为零、标准差为一的正态分布随机变量。
- en: Intuitively, we can conceptualize the standardized sample mean as a rescaled
    version of the sample mean. Referring back to the previous illustrations of the
    sample mean convergence, we observe that its distribution gradually resembles
    that of a normal distribution as the sample size increases, only becoming progressively
    narrower. By rescaling the sample mean through multiplication by the square root
    of the sample size, we effectively broaden the distribution, allowing it to maintain
    the shape of a normal distribution.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，我们可以将标准化样本均值概念化为样本均值的重新缩放版本。回到之前样本均值收敛的图示，我们观察到其分布随着样本大小的增加逐渐类似于正态分布，只是逐渐变得更加狭窄。通过将样本均值乘以样本大小的平方根，我们有效地扩展了分布，使其保持正态分布的形状。
- en: 'The visualization below illustrates the convergence of the standardized sample
    mean for samples drawn from both a normal distribution and a binomial distribution:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的可视化图示展示了标准化样本均值在从正态分布和二项分布中抽取样本的收敛情况：
- en: '![](../Images/7d2bb75aef9c7328ab9db039869502e5.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d2bb75aef9c7328ab9db039869502e5.png)'
- en: The sampling distribution of the standardized sample mean is visualized in a
    sequence of histograms, showcasing samples drawn from a normal distribution for
    different sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化样本均值的抽样分布通过一系列直方图进行可视化，展示了不同样本大小下从正态分布中抽取的样本，具体为 [1, 10, 100, 1000]。图片由作者提供。
- en: '![](../Images/43c73f6a84450ebbdb75202679d98652.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43c73f6a84450ebbdb75202679d98652.png)'
- en: The sampling distribution of the standardized sample mean is visualized in a
    sequence of histograms, showcasing samples drawn from a binomial distribution
    for different sample sizes, specifically [1, 10, 100, 1000]. Image by author.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化样本均值的抽样分布通过一系列直方图进行可视化，展示了不同样本大小下从二项分布中抽取的样本，具体为 [1, 10, 100, 1000]。图片由作者提供。
- en: Why do We Care?
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们为什么要关注这个？
- en: 'In a sense, there exists only one overarching form of convergence: convergence
    by distribution. We can regard convergence by probability as a particular instance
    of convergence by distribution, wherein the final distribution becomes degenerate
    and converges to a single value. But why is this distinction significant?'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，存在一种终极的收敛形式：按分布收敛。我们可以将按概率收敛视为按分布收敛的一种特例，其中最终的分布变得退化并收敛到一个单一值。但为什么这种区分很重要呢？
- en: First and foremost, the observation that the sample mean converges to the true
    population mean is what enables us to estimate that population mean. This estimation
    process is a common practice in a wide array of real-life situations. For instance,
    whenever we make generalizations like “neighbors are nosy,” we are implicitly
    relying on the idea that our limited sampling, derived from our own experiences,
    converges to the actual population mean. This principle is known as the Weak Law
    of Large Numbers.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，样本均值收敛于真实总体均值的观察使我们能够估计该总体均值。这种估计过程在各种实际情况中都是常见的。例如，每当我们做出诸如“邻居很爱打听”的概括时，我们实际上是依赖于这样的观点：我们有限的样本来自我们自己的经验，最终会收敛到实际的总体均值。这个原理被称为大数法则。
- en: Even more crucial is the observation that the standardized sample mean converges
    to a normal distribution. It is this fact that empowers us to conduct hypothesis
    tests and make informed assessments regarding the likelihood that a particular
    set of observations arises from mere chance or an underlying causal process. This
    phenomenon is more formally recognized as the Central Limit Theorem.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 更为关键的是标准化样本均值收敛于正态分布的观察。正是这个事实使我们能够进行假设检验，并对特定观察结果是由于偶然性还是潜在因果过程做出明智的评估。这一现象更正式地被称为中心极限定理。
- en: '**Links**'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**链接**'
- en: '[Notebook for convergence illustration](https://github.com/swang225/meinyenura/blob/main/python/research/notebook/sample_mean_std_sample_mean_convergence.ipynb)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[收敛性说明笔记本](https://github.com/swang225/meinyenura/blob/main/python/research/notebook/sample_mean_std_sample_mean_convergence.ipynb)'
