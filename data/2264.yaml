- en: 'AI Entropy: The Vicious Circle of AI-Generated Content'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI熵：AI生成内容的恶性循环
- en: 原文：[https://towardsdatascience.com/ai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f?source=collection_archive---------2-----------------------#2023-07-14](https://towardsdatascience.com/ai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f?source=collection_archive---------2-----------------------#2023-07-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/ai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f?source=collection_archive---------2-----------------------#2023-07-14](https://towardsdatascience.com/ai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f?source=collection_archive---------2-----------------------#2023-07-14)
- en: Understanding and Mitigating Model Collapse
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和缓解模型坍塌
- en: '[](https://medium.com/@davidsweenor?source=post_page-----8aad91a19d4f--------------------------------)[![David
    Sweenor](../Images/7dbb5c549ab67bc78f906fb707969ff6.png)](https://medium.com/@davidsweenor?source=post_page-----8aad91a19d4f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8aad91a19d4f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8aad91a19d4f--------------------------------)
    [David Sweenor](https://medium.com/@davidsweenor?source=post_page-----8aad91a19d4f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@davidsweenor?source=post_page-----8aad91a19d4f--------------------------------)[![David
    Sweenor](../Images/7dbb5c549ab67bc78f906fb707969ff6.png)](https://medium.com/@davidsweenor?source=post_page-----8aad91a19d4f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8aad91a19d4f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8aad91a19d4f--------------------------------)
    [David Sweenor](https://medium.com/@davidsweenor?source=post_page-----8aad91a19d4f--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fec7aed1f3ef1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f&user=David+Sweenor&userId=ec7aed1f3ef1&source=post_page-ec7aed1f3ef1----8aad91a19d4f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8aad91a19d4f--------------------------------)
    ·10 min read·Jul 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8aad91a19d4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f&user=David+Sweenor&userId=ec7aed1f3ef1&source=-----8aad91a19d4f---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fec7aed1f3ef1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f&user=David+Sweenor&userId=ec7aed1f3ef1&source=post_page-ec7aed1f3ef1----8aad91a19d4f---------------------post_header-----------)
    发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8aad91a19d4f--------------------------------)
    ·10 分钟阅读·2023 年 7 月 14 日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8aad91a19d4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f&user=David+Sweenor&userId=ec7aed1f3ef1&source=-----8aad91a19d4f---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8aad91a19d4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f&source=-----8aad91a19d4f---------------------bookmark_footer-----------)![](../Images/b1948e403976ff023d7ca4393874e587.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8aad91a19d4f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-entropy-the-vicious-circle-of-ai-generated-content-8aad91a19d4f&source=-----8aad91a19d4f---------------------bookmark_footer-----------)![](../Images/b1948e403976ff023d7ca4393874e587.png)'
- en: Photo by Author — David E Sweenor
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由作者 — David E Sweenor
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: Imagine if you could clone yourself to be in multiple places at once, handling
    all your responsibilities effortlessly. Remember the sci-fi comedy film *Multiplicity*
    (circa 1996), where Doug Kinney (played by Michael Keaton), clones himself to
    manage his work and personal life. However, as more Dougs are created, each subsequent
    clone exhibits exaggerated traits and diminished intelligence compared to the
    previous version. The clones, initially created to reduce chaos, end up creating
    more confusion and entropy in Kinney’s life.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果你能克隆自己，同时出现在多个地方，轻松处理所有责任。还记得科幻喜剧电影《多重人格》（1996 年），道格·金尼（迈克尔·基顿 饰）克隆自己来管理工作和个人生活。然而，随着越来越多的道格被创建，每个后续克隆体展现出与前一版本相比的夸张特征和降低的智力。最初旨在减少混乱的克隆体，最终在金尼的生活中造成更多混乱和熵。
- en: In the world of artificial intelligence (AI), a similar phenomenon occurs when
    large language models (LLMs) are trained on data generated by earlier versions
    of themselves. Just like the clones in *Multiplicity*, the AI models begin to
    lose touch with the original data distribution, leading to increased chaos and
    confusion–a kind of entropy in the AI world known as “model collapse”.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能（AI）的世界中，当大型语言模型（LLM）在由早期版本生成的数据上训练时，会出现类似的现象。就像《多人复制》中的克隆体一样，AI 模型开始失去对原始数据分布的把握，导致混乱和困惑的增加——这在
    AI 世界中被称为“模型崩溃”。
- en: The Phenomenon of Model Collapse
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型崩溃现象
- en: Just like Doug in *Multiplicity* who faces chaos as he creates more clones,
    AI models face a similar fate when they are recursively trained on data generated
    by earlier versions of themselves. They become dumber and more exaggerated over
    time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 就像《多人复制》中 Doug 在创造更多克隆体时面临的混乱一样，当 AI 模型在由早期版本生成的数据上递归训练时，它们面临类似的命运。随着时间的推移，它们变得更加愚蠢和夸张。
- en: What is Model Collapse?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是模型崩溃？
- en: Model collapse refers to a degenerative process where, over time, AI models
    lose information about the original content (data) distribution. As AI models
    are trained on data generated by their predecessors, they begin to “forget” the
    true underlying data distribution, leading to a narrowing of their generative
    capabilities.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 模型崩溃指的是一个退化过程，随着时间的推移，AI 模型丧失对原始内容（数据）分布的信息。由于 AI 模型是在由其前任生成的数据上训练的，它们开始“遗忘”真实的底层数据分布，导致其生成能力的缩小。
- en: Although the technical explanation of this is beyond the scope of this blog,
    you may notice this in some AI image generators–when they start to produce nearly
    identical images, it is likely that the model has collapsed. Perhaps a more familiar
    example is with AI generated news sites, reviews and content farms. These sites
    are essentially automatically generating factually inaccurate articles and have
    the ability to spread misinformation at an alarming rate.[1]
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然对此的技术解释超出了本博客的范围，但你可能会在一些 AI 图像生成器中注意到这一点——当它们开始生成几乎相同的图像时，可能说明模型已经崩溃。一个更熟悉的例子是
    AI 生成的新闻网站、评论和内容农场。这些网站本质上是自动生成事实不准确的文章，并以惊人的速度传播虚假信息。[1]
- en: Now, some of this may be related to AI hallucinations but it’s also highly likely
    that these AI content generators are scraping articles from other AI generated
    articles and re-writing them automatically. Many of them are instantly recognizable–they’re
    typically full of ads and pop-ups with little to no meaningful content.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这其中的一些现象可能与 AI 幻觉有关，但也很可能这些 AI 内容生成器正在从其他 AI 生成的文章中抓取并自动重写。许多这样的内容立即显而易见——通常充满了广告和弹窗，几乎没有有意义的内容。
- en: This is akin to the clones in *Multiplicity* becoming less intelligent and more
    exaggerated with each generation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像是《多人复制》中的克隆体每一代变得越来越不智能和夸张。
- en: How Does it Happen?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这是如何发生的？
- en: Model collapse can occur due to many factors such as lack of diversity in the
    training data, amplification of biases and model overfitting. When an AI model
    is trained on AI-generated data, it is essentially learning from a reflection
    of itself. This reflection, much like a game of ‘telephone’, becomes more distorted
    with each iteration.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 模型崩溃可能由多种因素引起，比如训练数据的多样性不足、偏见的放大和模型过拟合。当一个 AI 模型在 AI 生成的数据上训练时，它实际上是在学习自己的一种反射。这种反射就像“电话游戏”一样，随着每次迭代变得越来越扭曲。
- en: When we train AI on AI, it becomes dumber and dumber.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当我们在 AI 上训练 AI 时，它变得越来越愚蠢。
- en: For example, take this photo of a surfer.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，看看这张冲浪者的照片。
- en: '![](../Images/635ef37fe79b25bf675baf9d8f41118d.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/635ef37fe79b25bf675baf9d8f41118d.png)'
- en: Photo by Author — David E Sweenor
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作者照片 — 大卫·E·斯威诺
- en: 'Here is one of the four descriptions Midjourney created from the photo:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Midjourney 从照片中创建的四个描述之一：
- en: “statue of lei wearing surfer in honolulu, hawaii, in the style of light bronze
    and pink, [frank frazetta](https://goo.gl/search?artist+frank+frazetta=), traditional
    arts of africa, oceania, and the americas, symmetrical arrangements, twisted branches,
    street art aesthetic, narrative-driven visual storytelling — ar 4:3”
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “在夏威夷檀香山穿着泳衣的冲浪者雕像，风格为浅青铜和粉色，[Frank Frazetta](https://goo.gl/search?artist+frank+frazetta=)，传统的非洲、澳大拉西亚和美洲艺术，对称排列，扭曲的树枝，街头艺术美学，叙事驱动的视觉讲故事
    — ar 4:3”
- en: 'Here are the four AI generated versions of my photo:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我的照片的四个 AI 生成版本：
- en: '![](../Images/0ac99fb1f3e4511f323d30671c86c0bc.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ac99fb1f3e4511f323d30671c86c0bc.png)'
- en: 'Images by Midjourney — Iteration #1 of Original Surfer Photo'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Midjourney拍摄 — 原始冲浪者照片的第一次迭代
- en: Yes, these are quite pink but the first one looks closest to the original and
    I had no idea who Frank Frazetta was but I then asked it to describe that image
    and simply took the first one.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这些确实很粉色，但第一个看起来最接近原始图像，我之前并不知道Frank Frazetta是谁，但我要求它描述那张图片，最后选择了第一张。
- en: “a statue for a surfer on top of a pink surfboard among some flowers, in the
    style of ray tracing, monochromatic compositions, reefwave, low-angle shots, flamboyant,
    vibrant street scenes, rtx on — ar 77:58”
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “一个站在粉色冲浪板上的冲浪者雕像，周围有一些花朵，风格为光线追踪、单色构图、reefwave、低角度拍摄、华丽、多彩的街景，开启rttx — ar 77:58”
- en: Using the above as a description, the four images below were generated.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述描述，下面四张图像被生成了。
- en: '![](../Images/45ea20c678e22d61ab7801fe0e88e4a8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45ea20c678e22d61ab7801fe0e88e4a8.png)'
- en: 'Photos by Midjourney — Iteration #2 of Original Surfer Photo'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Midjourney拍摄 — 原始冲浪者照片的第二次迭代
- en: Now these are quite interesting but do not seem to represent the original in
    any way shape or form. That was only two generations removed from the original…what
    happens if we did this, 100, 1000, or 10,000 times? Now, this is not a perfect
    example of degenerative learning but rather, an example of AI entropy. The system
    tends towards a state of more and more disorder.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些确实很有趣，但似乎并没有以任何方式代表原始图像。这仅仅是与原始图像隔了两代……如果我们这样做100次、1000次或10000次会怎样？现在，这并不是退化学习的完美示例，而是人工智能熵的一个例子。系统趋向于越来越多的混乱状态。
- en: Insights from the Smart People
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 智慧人士的见解
- en: A research paper titled “[The Curse of Recursion:Training Data on Generated
    Data Makes Models Forget](https://arxiv.org/pdf/2305.17493v2.pdf)” the technical
    aspects of model collapse are discussed. The authors demonstrate that it can happen
    across all models, not just generative AI models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇题为“[递归的诅咒：在生成的数据上训练数据使模型遗忘](https://arxiv.org/pdf/2305.17493v2.pdf)”的研究论文讨论了模型崩溃的技术细节。作者展示了这可能发生在所有模型上，而不仅仅是生成性人工智能模型。
- en: Models Become Dumber (Degenerative Learning)
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型变得更蠢（退化学习）
- en: One of the critical insights from the research is the concept of “degenerative
    learning”. In the context of AI models, degenerative learning refers to the process
    where, over time, the models lose their ability to accurately represent the diversity
    and complexity of the original data distribution.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 研究中的一个关键见解是“退化学习”的概念。在人工智能模型的背景下，退化学习指的是随着时间的推移，模型失去准确表示原始数据分布的多样性和复杂性的能力。
- en: 'The authors cited the following example:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作者引用了以下示例：
- en: '![](../Images/b3a04fd5fe4fbfbb2988abaf5f17339d.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3a04fd5fe4fbfbb2988abaf5f17339d.png)'
- en: Example of Model Collapse from Research Paper
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 研究论文中的模型崩溃示例
- en: As you can see, given some input text, if you train each model on data produced
    from previous generations, it becomes nonsensical.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，如果你在基于前几代产生的数据上训练每个模型，它将变得毫无意义。
- en: 'This happens for several reasons including:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这发生的原因有几个，包括：
- en: '**Loss of Rare Events**: As models are trained on data generated by previous
    versions of themselves, they tend to focus on the most common patterns and start
    forgetting rare or improbable events. This is akin to the models losing their
    “long-term memory” –similar to Doug in *Multiplicity*. Oftentimes, rare events
    are important singles in the data–whether they represent anomalies in manufacturing
    processes or fraudulent transactions. Rare events are important to understand
    and maintain. For example, a common practice in text analytics projects is to
    remove “junk” words–these might be pronouns, definite and indefinite articles,
    and so forth. However, for fraud use cases–it is the pronouns that are the signal
    for fraud. Fraudsters tend to speak in the third person rather than the first.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀有事件的丧失**：随着模型在由自身的前一个版本生成的数据上进行训练，它们倾向于关注最常见的模式，并开始忘记稀有或不太可能发生的事件。这类似于模型失去了其“长期记忆”——类似于《多重人格》中的道格。稀有事件通常是数据中的重要信号——无论它们是否代表制造过程中的异常或欺诈交易。理解和维护稀有事件是重要的。例如，在文本分析项目中，常见的做法是去除“垃圾”词——这些可能是代词、定冠词和不定冠词等等。然而，对于欺诈案例来说——代词才是欺诈的信号。欺诈者往往使用第三人称而不是第一人称。'
- en: '**Amplification of Biases**: Each iteration of training on AI-generated data
    can amplify existing biases. Since the model’s output is based on the data it
    was trained on, any bias in the training data can be reinforced and exaggerated
    over time–also similar to the multiple Dougs. We’ve already seen the amplification
    of biases in the traditional AI world which has led to discriminatory hiring,
    racial bias with healthcare or discriminatory tweets. We need to have controls
    in place to detect and mitigate their perpetuation.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏见的放大**：对人工智能生成的数据进行每次训练都可能放大现有偏见。由于模型的输出基于其训练数据，任何训练数据中的偏见都会随着时间的推移得到强化和夸大——这与多个道格的情况类似。我们已经在传统人工智能领域看到了偏见的放大，这导致了歧视性的招聘、医疗领域的种族偏见或歧视性的推文。我们需要制定控制措施来检测和减轻这些偏见的持续存在。'
- en: '**Narrowing of Generative Capabilities**: The generative capabilities of the
    model begin to narrow as it becomes more influenced by its own projections of
    reality. The model starts producing content that is increasingly homogeneous and
    less representative of the diversity and rare events found in the original data.
    As everything begins to regress to the mean and a state of homogeneity, this will
    lead to a loss of originality (we already see it on recipe websites). For LLMs,
    it’s the variation that give each writer or artist their particular tone and style.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成能力的狭窄**：随着模型受到自身现实投影的影响变大，生成能力开始变窄。模型开始生成越来越同质化的内容，代表原始数据中多样性和稀有事件的能力降低。当一切开始回归均值和同质状态时，这将导致原创性的丧失（我们已经在食谱网站上看到了这种现象）。对于大规模语言模型而言，变化赋予每个作者或艺术家独特的语调和风格。'
- en: '**Functional Approximation Error**: The paper mentions that functional approximation
    error can occur if the function approximators are insufficiently expressive. This
    error can be minimized by using more expressive models, but too much expressiveness
    can compound noise and lead to overfitting.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**功能逼近误差**：论文提到，如果函数逼近器表达能力不足，可能会出现功能逼近误差。通过使用更具表达力的模型可以最小化这种误差，但过多的表达力可能会放大噪声并导致过拟合。'
- en: Degenerative learning is characterized as a vicious cycle where the model’s
    ability to learn and represent data accurately deteriorates with each iteration
    of training on AI-generated content.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 退化学习的特点是模型在对人工智能生成内容进行每次训练后，学习和准确表示数据的能力逐渐恶化，形成恶性循环。
- en: This has significant implications for the quality and reliability of the content
    generated by AI models.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这对人工智能模型生成内容的质量和可靠性具有重要影响。
- en: Implications of Model Collapse
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型崩溃的影响
- en: Understanding the phenomenon of model collapse is interesting, but it is equally
    important to recognize its implications. Model collapse can have far-reaching
    consequences, affecting the quality, reliability, and fairness of AI-generated
    content. If not properly accounted for, your organization could be at risk.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 理解模型崩溃现象很有趣，但同样重要的是认识到其影响。模型崩溃可能会产生深远的后果，影响人工智能生成内容的质量、可靠性和公平性。如果没有适当考虑，你的组织可能会面临风险。
- en: Quality and Reliability
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 质量和可靠性
- en: As AI models undergo degenerative learning, the quality and reliability of the
    content they generate can significantly deteriorate. This is because the models
    lose touch with the original data distribution and become more influenced by their
    own projections of reality. For instance, an AI model used for generating news
    articles might start producing content that is not factually accurate, overly
    homogeneous or simply fake news!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能模型进行退化学习，它们生成的内容的质量和可靠性可能会显著下降。这是因为模型与原始数据分布的联系丧失，并且更受自身现实投影的影响。例如，用于生成新闻文章的人工智能模型可能开始生成不准确、过于同质化或完全虚假的内容！
- en: Fairness and Representation
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 公平性和代表性
- en: Model collapse can have serious implications for fairness and representation.
    As models forget rare events and their generative capabilities narrow, content
    related to marginalized communities or less common topics may be underrepresented
    or misrepresented. This can perpetuate biases and stereotypes, and contribute
    to the exclusion of certain voices and perspectives.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 模型崩溃可能对公平性和代表性产生严重影响。随着模型遗忘稀有事件和生成能力变窄，与边缘化群体或较少见主题相关的内容可能会被低估或误呈现。这可能会加剧偏见和刻板印象，助长某些声音和观点的排斥。
- en: Ethical Concerns
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 伦理问题
- en: The ethical concerns surrounding model collapse are significant. When AI-generated
    content is used in decision-making, education, or information dissemination, the
    integrity of the content is paramount. Model collapse can lead to the dissemination
    of biased, inaccurate, or homogenized content, which can have ethical implications,
    especially if it affects people’s lives, opinions, or access to opportunities.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型崩溃的伦理问题是显著的。当AI生成的内容用于决策、教育或信息传播时，内容的完整性至关重要。模型崩溃可能导致传播有偏见、不准确或同质化的内容，这可能带来伦理问题，特别是当这些内容影响到人们的生活、观点或机会时。
- en: Economic and Social Impact
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 经济和社会影响
- en: On an economic and social level, model collapse can affect the trust and adoption
    of AI technologies. If businesses and consumers cannot rely on the content generated
    by AI models, they may be less likely to adopt these technologies. This can have
    economic implications for industries that heavily rely on AI, and social implications
    in terms of public perception and trust in AI.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在经济和社会层面，模型崩溃可能会影响对AI技术的信任和采纳。如果企业和消费者不能依赖AI模型生成的内容，他们可能会更不愿意采纳这些技术。这可能对严重依赖AI的行业产生经济影响，并对公众对AI的认知和信任产生社会影响。
- en: Strategies for Mitigating Model Collapse
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 减轻模型崩溃的策略
- en: 'Model collapse, with its far-reaching implications, necessitates the development
    of strategies to mitigate its effects. Here are some strategies that can be employed
    to prevent or mitigate model collapse in AI systems:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 模型崩溃具有深远的影响，必须制定策略来减轻其影响。以下是可以用来防止或减轻AI系统模型崩溃的一些策略：
- en: Retaining Original Human-Produced Datasets
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保留原始人工生成的数据集
- en: One of the key insights from the research paper is the importance of retaining
    a copy of the original human-produced dataset. Periodically retraining the model
    on this data can help ensure that the model remains grounded in reality and continues
    to represent the diversity and complexity of human experiences. A recent [research
    paper from Microsoft Research](https://arxiv.org/abs/2306.11644) suggested that
    training LLMs on trusted data like textbooks may help improve the accuracy of
    LLMs.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 研究论文中的一个关键见解是保留原始人工生成数据集的重要性。定期在这些数据上重新训练模型可以帮助确保模型保持在现实基础上，并继续代表人类经验的多样性和复杂性。最近的一篇[来自微软研究院的研究论文](https://arxiv.org/abs/2306.11644)建议，在可靠的数据如教科书上训练大型语言模型可能有助于提高其准确性。
- en: Introducing New Human-Generated Datasets
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入新的人工生成数据集
- en: In addition to retaining original datasets, introducing new, clean, human-generated
    datasets into the training process is beneficial. This can help in preventing
    the model from narrowing its generative capabilities and ensure that it continues
    to learn and adapt to new information. As companies begin fine-tuning LLMs on
    their proprietary corporate data, this may help keep LLMs from degrading.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 除了保留原始数据集之外，将新的、干净的人工生成数据集引入训练过程是有益的。这可以帮助防止模型生成能力的缩小，并确保它继续学习和适应新信息。随着公司开始在其专有企业数据上微调大型语言模型，这可能有助于防止模型性能下降。
- en: Monitoring and Regular Evaluation
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控和定期评估
- en: Regularly monitoring and evaluating the performance of AI models is crucial.
    By setting up evaluation metrics and benchmarks, it is possible to detect early
    signs of model collapse. This allows for timely interventions, such as adjusting
    the training data or tuning the model parameters. This is no different from our
    traditional guidance on model monitoring, companies need to implement a MLOps
    framework to continually monitor the models and data for drift. Not only do they
    need to detect this, they’ll need additional mechanisms to ensure that models
    are not hallucinating and are producing results that are in alignment with the
    company’s goals which will be a new capability for many organizations.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 定期监控和评估AI模型的表现至关重要。通过设定评估指标和基准，可以检测到模型崩溃的早期迹象。这允许及时采取干预措施，如调整训练数据或调整模型参数。这与我们传统的模型监控指导没有区别，企业需要实施MLOps框架，以持续监控模型和数据的漂移。不仅需要检测这些问题，还需要额外的机制来确保模型不会产生虚假信息，并生成与公司目标一致的结果，这将是许多组织的新能力。
- en: Diversifying Training Data
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多样化训练数据
- en: Ensuring that the training data is diverse and representative of different perspectives
    and experiences can help in preventing biases and ensuring fairness in AI-generated
    content. This includes ensuring representation of underrepresented communities
    and rare events. This goes without saying, organizations need to understand the
    source data that was used to train the model to ensure that it aligns with reality
    and represents the best of what society could be. Blindly using internet data
    which is full of negativity, bias and misinformation is a recipe for disaster.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 确保训练数据的多样性和代表不同观点与经历的特征有助于防止偏见并确保AI生成内容的公平性。这包括确保少数群体和稀有事件的代表性。不言而喻，组织需要了解用于训练模型的源数据，以确保其与现实对齐并代表社会的最佳面貌。盲目使用充满负面、偏见和虚假信息的互联网数据是灾难的根源。
- en: Community Coordination and Collaboration
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 社区协调与合作
- en: Model collapse is not just a technical challenge but also an ethical and societal
    one. Community-wide coordination involving AI companies, content producers, researchers,
    and policymakers is essential. Sharing information, best practices, and collaborating
    on developing standards and guidelines can be instrumental in addressing model
    collapse. Although guidelines and frameworks are good, similar to the [United
    Nations AI Ethics Framework](https://unite.un.org/news/unite-paper-framework-ethical-ai-united-nations),
    enforcement and buy-in across geopolitical boundaries will be challenging.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 模型崩溃不仅是技术挑战，也是一项伦理和社会挑战。涉及AI公司、内容生产者、研究人员和政策制定者的社区范围内的协调至关重要。共享信息、最佳实践和共同制定标准与指南对于解决模型崩溃问题具有重要作用。尽管指南和框架很重要，但类似于[联合国AI伦理框架](https://unite.un.org/news/unite-paper-framework-ethical-ai-united-nations)，在地缘政治边界上实施和获得支持将面临挑战。
- en: Summary
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In *Multiplicity*, Doug’s attempt to clone himself to manage his responsibilities
    leads to unintended chaos and entropy. This scenario finds a parallel in the world
    of AI, where training models on AI-generated data can lead to a form of entropy
    known as model collapse.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Multiplicity*中，Doug试图通过克隆自己来管理责任，结果导致了意想不到的混乱和熵。这一情景在AI世界中找到了平行点，即在AI生成的数据上训练模型可能导致一种称为模型崩溃的熵。
- en: Just as the clones in the movie become dumber and more chaotic with each generation,
    AI models can lose their ability to accurately represent the diversity and complexity
    of the original data as they train on their own outputs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 就像电影中的克隆随着每一代变得更愚蠢和混乱一样，AI模型在对自身输出进行训练时也可能失去准确代表原始数据多样性和复杂性的能力。
- en: Model collapse, akin to the entropy in *Multiplicity*, has far-reaching implications
    for the quality, reliability, and fairness of AI-generated content. It is a reminder
    that unchecked replication, whether it be clones in a movie or AI training on
    its own data, can lead to a loss of information and an increase in disorder.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 模型崩溃类似于*Multiplicity*中的熵，对AI生成内容的质量、可靠性和公平性具有深远的影响。这提醒我们，无论是电影中的克隆还是AI对自身数据的训练，未经控制的复制都可能导致信息丧失和混乱增加。
- en: However, unlike the uncontrolled cloning in *Multiplicity*, we have the tools
    and knowledge to manage and mitigate model collapse in AI systems. By retaining
    original human-produced datasets, diversifying training data, regularly monitoring
    AI models, and fostering community coordination, we can counteract the entropy
    and ensure that AI remains a reliable and beneficial tool.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与*Multiplicity*中的不受控制的克隆不同，我们拥有管理和缓解AI系统模型崩溃的工具和知识。通过保留原始人类生成的数据集、多样化训练数据、定期监控AI模型以及促进社区协调，我们可以对抗熵，并确保AI保持可靠和有益的工具。
- en: As AI continues to evolve, it is imperative to remember the lessons from *Multiplicity*,
    entropy and the research on model collapse. Through collective efforts, we can
    practice AI responsibly, ensuring that it remains grounded in reality and serves
    the diverse needs of all communities, without descending into chaos.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AI的不断发展，牢记*Multiplicity*中的教训、熵以及模型崩溃的研究至关重要。通过集体努力，我们可以负责任地使用AI，确保其保持现实基础，并服务于所有社区的多样化需求，而不陷入混乱。
- en: In essence, by actively managing the ‘cloning process’ of AI data and being
    mindful of the entropy it can create, we can steer AI development in a direction
    that is both innovative and responsible.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，通过积极管理AI数据的‘克隆过程’并注意其可能产生的熵，我们可以将AI发展引导到创新且负责任的方向上。
- en: 'If you want to learn more about Artificial Intelligence, check out my book
    [Artificial Intelligence: An Executive Guide to Make AI Work for Your Business
    on Amazon](https://www.amazon.com/Artificial-Intelligence-Executive-Guide-Business/dp/B09X4KTYS4).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于人工智能的内容，请查看我的书籍 [《人工智能：让 AI 为您的业务服务的高管指南》在亚马逊上](https://www.amazon.com/Artificial-Intelligence-Executive-Guide-Business/dp/B09X4KTYS4)。
- en: '![](../Images/0fd50d9d9ea23633728882eb0159e973.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fd50d9d9ea23633728882eb0159e973.png)'
- en: Artificial Intelligence Executive Guide on Amazon
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 《人工智能高管指南》在亚马逊上
- en: '[1] Thompson, Stuart A. 2023\. “A.I.-Generated Content Discovered on News Sites,
    Content Farms and Product Reviews.” The New York Times, May 19, 2023, sec. Technology.
    [https://www.nytimes.com/2023/05/19/technology/ai-generated-content-discovered-on-news-sites-content-farms-and-product-reviews.html](https://www.nytimes.com/2023/05/19/technology/ai-generated-content-discovered-on-news-sites-content-farms-and-product-reviews.html).'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Thompson, Stuart A. 2023\. “A.I.-生成内容在新闻网站、内容农场和产品评论中被发现。”《纽约时报》，2023年5月19日，第技术版。[https://www.nytimes.com/2023/05/19/technology/ai-generated-content-discovered-on-news-sites-content-farms-and-product-reviews.html](https://www.nytimes.com/2023/05/19/technology/ai-generated-content-discovered-on-news-sites-content-farms-and-product-reviews.html)'
