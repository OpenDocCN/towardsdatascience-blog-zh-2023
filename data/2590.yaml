- en: Prompt Ensembles Make LLMs More Reliable
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示集使大型语言模型更可靠
- en: 原文：[https://towardsdatascience.com/prompt-ensembles-make-llms-more-reliable-ae57ec35b5f7?source=collection_archive---------1-----------------------#2023-08-14](https://towardsdatascience.com/prompt-ensembles-make-llms-more-reliable-ae57ec35b5f7?source=collection_archive---------1-----------------------#2023-08-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/prompt-ensembles-make-llms-more-reliable-ae57ec35b5f7?source=collection_archive---------1-----------------------#2023-08-14](https://towardsdatascience.com/prompt-ensembles-make-llms-more-reliable-ae57ec35b5f7?source=collection_archive---------1-----------------------#2023-08-14)
- en: Simple strategies for getting the most out of any language model…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从任何语言模型中获取最大收益的简单策略…
- en: '[](https://wolfecameron.medium.com/?source=post_page-----ae57ec35b5f7--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----ae57ec35b5f7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ae57ec35b5f7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ae57ec35b5f7--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----ae57ec35b5f7--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----ae57ec35b5f7--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----ae57ec35b5f7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ae57ec35b5f7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ae57ec35b5f7--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----ae57ec35b5f7--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprompt-ensembles-make-llms-more-reliable-ae57ec35b5f7&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----ae57ec35b5f7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ae57ec35b5f7--------------------------------)
    ·18 min read·Aug 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fae57ec35b5f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprompt-ensembles-make-llms-more-reliable-ae57ec35b5f7&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----ae57ec35b5f7---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[阅读](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprompt-ensembles-make-llms-more-reliable-ae57ec35b5f7&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----ae57ec35b5f7---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ae57ec35b5f7--------------------------------)
    ·18分钟阅读·2023年8月14日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae57ec35b5f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprompt-ensembles-make-llms-more-reliable-ae57ec35b5f7&source=-----ae57ec35b5f7---------------------bookmark_footer-----------)![](../Images/917f4253782589036edfaf468a0ea247.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fae57ec35b5f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fprompt-ensembles-make-llms-more-reliable-ae57ec35b5f7&source=-----ae57ec35b5f7---------------------bookmark_footer-----------)![](../Images/917f4253782589036edfaf468a0ea247.png)'
- en: (Photo by [Manuel Nägeli](https://unsplash.com/@gwundrig?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/7CcPLtywRso?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由 [Manuel Nägeli](https://unsplash.com/@gwundrig?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    在 [Unsplash](https://unsplash.com/photos/7CcPLtywRso?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    拍摄）
- en: Anyone who has worked with large language models (LLMs) will know that prompt
    engineering is an informal and difficult process. Small changes to a prompt can
    cause massive changes to the model’s output, it is difficult (or even impossible
    in some cases) to know the impact that changing a prompt will have, and prompting
    behavior is highly dependent on the type of model being used. The fragile nature
    of prompt engineering is a harsh reality when we think about creating applications
    with LLMs. If we cannot predict how our model will behave, *how can we build a
    dependable system around this model?* Although LLMs are incredibly capable, this
    problem complicates their use in many practical scenarios.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 任何使用过大型语言模型（LLMs）的人都知道，提示工程是一个非正式且困难的过程。对提示的小变化可能会导致模型输出的大幅变化，难以（甚至在某些情况下是不可能的）预测改变提示会产生什么影响，而且提示行为高度依赖于所使用的模型类型。当我们考虑使用LLMs创建应用程序时，提示工程的脆弱性是一种严峻的现实。如果我们无法预测模型的行为，*我们如何围绕这个模型构建一个可靠的系统？*
    尽管LLMs非常强大，但这一问题使得它们在许多实际场景中的应用变得复杂。
- en: “Prompting is a brittle process wherein small modifications to the prompt can
    cause large variations in the model predictions, and therefore significant effort
    is dedicated towards designing a painstakingly perfect prompt for a task.” *—
    from [2]*
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “提示是一个脆弱的过程，其中对提示的小修改可能会导致模型预测的巨大变化，因此需要投入大量精力来设计一个极其完美的任务提示。” *— 摘自 [2]*
- en: Given the fragile nature of LLMs, finding techniques that make these models
    more accurate and reliable has recently become a popular research topic. In this
    overview, we will focus on one technique in particular — *prompt ensembles.* Put
    simply, prompt ensembles are just sets of diverse…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于LLMs的脆弱性，寻找使这些模型更准确可靠的技术最近已成为一个热门研究主题。在本综述中，我们将特别关注一种技术 —— *提示集成。* 简而言之，提示集成就是一组多样化的…
