- en: 'Boosting PyTorch Inference on CPU: From Post-Training Quantization to Multithreading'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提升 PyTorch 在 CPU 上的推理：从训练后量化到多线程
- en: 原文：[https://towardsdatascience.com/boosting-pytorch-inference-on-cpu-from-post-training-quantization-to-multithreading-6820ac7349bb](https://towardsdatascience.com/boosting-pytorch-inference-on-cpu-from-post-training-quantization-to-multithreading-6820ac7349bb)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/boosting-pytorch-inference-on-cpu-from-post-training-quantization-to-multithreading-6820ac7349bb](https://towardsdatascience.com/boosting-pytorch-inference-on-cpu-from-post-training-quantization-to-multithreading-6820ac7349bb)
- en: '[The Kaggle Blueprints](/the-kaggle-blueprints-unlocking-winning-approaches-to-data-science-competitions-24d7416ef5fd)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[Kaggle 蓝图](/the-kaggle-blueprints-unlocking-winning-approaches-to-data-science-competitions-24d7416ef5fd)'
- en: How to reduce inference time on CPU with clever model selection, post-training
    quantization with ONNX Runtime or OpenVINO, and multithreading with ThreadPoolExecutor
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何通过巧妙的模型选择、使用 ONNX Runtime 或 OpenVINO 进行训练后量化以及使用 ThreadPoolExecutor 实现多线程来减少
    CPU 上的推理时间
- en: '[](https://medium.com/@iamleonie?source=post_page-----6820ac7349bb--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page-----6820ac7349bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6820ac7349bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6820ac7349bb--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page-----6820ac7349bb--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@iamleonie?source=post_page-----6820ac7349bb--------------------------------)[![Leonie
    Monigatti](../Images/4044b1685ada53a30160b03dc78f9626.png)](https://medium.com/@iamleonie?source=post_page-----6820ac7349bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6820ac7349bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6820ac7349bb--------------------------------)
    [Leonie Monigatti](https://medium.com/@iamleonie?source=post_page-----6820ac7349bb--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6820ac7349bb--------------------------------)
    ·8 min read·Jun 13, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6820ac7349bb--------------------------------)
    ·8 分钟阅读·2023 年 6 月 13 日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/fc7894bf7fe58528c51d5ad9341c6009.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fc7894bf7fe58528c51d5ad9341c6009.png)'
- en: Welcome to another edition of “[The Kaggle Blueprints](/the-kaggle-blueprints-unlocking-winning-approaches-to-data-science-competitions-24d7416ef5fd)”,
    where we will analyze [Kaggle](https://www.kaggle.com/) competitions’ winning
    solutions for lessons we can apply to our own data science projects.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到另一期 “[Kaggle 蓝图](/the-kaggle-blueprints-unlocking-winning-approaches-to-data-science-competitions-24d7416ef5fd)”
    ，我们将分析 [Kaggle](https://www.kaggle.com/) 竞赛的获胜解决方案，以便将其中的经验应用到我们自己的数据科学项目中。
- en: This edition will review the techniques and approaches from the [“BirdCLEF 2023](https://www.kaggle.com/competitions/birdclef-2023/)”
    competition, which ended in May 2023.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本版将回顾 [“BirdCLEF 2023](https://www.kaggle.com/competitions/birdclef-2023/)”
    竞赛中的技术和方法，该竞赛于 2023 年 5 月结束。
- en: 'Problem Statement: Deep Learning Inference under Limited Time and Computation
    Constraints'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题陈述：在有限时间和计算约束下的深度学习推理
- en: The BirdCLEF competitions are a series of annually recurring competitions on
    Kaggle. The main objective of a BirdCLEF competition is usually to identify a
    specific bird species by sound. The competitors are given short audio files of
    single bird calls and then must predict whether a specific bird was present in
    a longer recording.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: BirdCLEF 竞赛是一系列每年在 Kaggle 上举行的竞赛。BirdCLEF 竞赛的主要目标通常是通过声音识别特定的鸟类。参赛者会获得单只鸟叫的短音频文件，然后必须预测在较长的录音中是否存在特定的鸟类。
- en: In an earlier edition of [The Kaggle Blueprints](/the-kaggle-blueprints-unlocking-winning-approaches-to-data-science-competitions-24d7416ef5fd),
    we have already reviewed the winning approaches to audio classification with Deep
    Learning from last year’s “[BirdCLEF 2022](https://www.kaggle.com/competitions/birdclef-2022/)”
    competition.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期版本的 [《Kaggle 蓝图》](/the-kaggle-blueprints-unlocking-winning-approaches-to-data-science-competitions-24d7416ef5fd)
    中，我们已经回顾了去年的 “[BirdCLEF 2022](https://www.kaggle.com/competitions/birdclef-2022/)”
    竞赛中的音频分类获胜方法。
- en: 'One aspect that was novel in the [“BirdCLEF 2023](https://www.kaggle.com/competitions/birdclef-2023/)”
    competition was the limited time and computational constraints: **Competitors
    were asked to predict roughly 200 10-minute-long recordings** [**on a CPU Notebook
    within 2 hours**](https://www.kaggle.com/competitions/birdclef-2023/overview/code-requirements)**.**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[“BirdCLEF 2023](https://www.kaggle.com/competitions/birdclef-2023/)”竞赛中的一个新颖方面是时间和计算限制：**竞争者被要求在2小时内在CPU笔记本上预测大约200个10分钟的录音**[**](https://www.kaggle.com/competitions/birdclef-2023/overview/code-requirements)**。**'
- en: '[](https://www.kaggle.com/competitions/birdclef-2023?source=post_page-----6820ac7349bb--------------------------------)
    [## BirdCLEF 2023'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/competitions/birdclef-2023?source=post_page-----6820ac7349bb--------------------------------)
    [## BirdCLEF 2023'
- en: Identify bird calls in soundscapes
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别声音景观中的鸟类鸣叫
- en: www.kaggle.com](https://www.kaggle.com/competitions/birdclef-2023?source=post_page-----6820ac7349bb--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.kaggle.com](https://www.kaggle.com/competitions/birdclef-2023?source=post_page-----6820ac7349bb--------------------------------)'
- en: Now, you might be asking why anyone would want to infer a Deep Learning model
    on a CPU instead of a GPU. This is a common practical problem statement [4] as
    oftentimes staff (especially in conservation but also in other industries) have
    budget constraints and thus only have access to limited computing resources. Additionally,
    being able to make predictions quickly is helpful.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么有人会选择在CPU上推理深度学习模型而不是GPU。这是一个常见的实际问题声明[4]，因为工作人员（尤其是在保护工作中，但也包括其他行业）常常面临预算限制，因此只能使用有限的计算资源。此外，能够快速做出预测是有帮助的。
- en: Because covering how to approach audio classification with Deep Learning would
    be repetitive to the [previous The Kaggle Blueprints edition on the BirdCLEF 2022
    competition](/audio-classification-with-deep-learning-in-python-cf752b22ba07),
    we will **focus on the novel aspect of how to speed up inference for Deep Learning
    models on CPU** in this article.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深入探讨如何用深度学习进行音频分类将重复[之前《Kaggle Blueprints》版本关于BirdCLEF 2022竞赛](/audio-classification-with-deep-learning-in-python-cf752b22ba07)的内容，我们将**专注于如何加速CPU上深度学习模型推理的创新方面**。
- en: 'If you are interested in winning approaches to audio classification with Deep
    Learning, check out the previous edition:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对深度学习音频分类的获胜方法感兴趣，可以查看之前的版本：
- en: '[](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)
    [## Audio Classification with Deep Learning in Python'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)
    [## 用Python进行深度学习音频分类'
- en: Fine-tuning image models to tackle domain shift and class imbalance with PyTorch
    and torchaudio in audio data
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调图像模型以应对领域偏移和类别不平衡，使用PyTorch和torchaudio处理音频数据
- en: towardsdatascience.com](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)'
- en: Approaching Deep Learning Inference on CPU
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习推理在CPU上的方法
- en: The main problem with having to infer on CPU within a limited time is that you
    are not able to create large ensembles of powerful and diverse models to squeeze
    out that last few percent of performance. Depending on the used model, some competitors
    even struggled to meet the limited time requirements with a single model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在有限时间内在CPU上进行推理的主要问题是，你无法创建大量强大且多样化的模型来挤出最后几百分点的性能。根据使用的模型，有些竞争者甚至在单个模型下也难以满足有限的时间要求。
- en: However, it is common that an ensemble of weaker models will usually perform
    better than a single powerful model. In the competition write-ups, successful
    competitors shared some tricks of how they sped up the inference on CPU to be
    able to ensemble multiple models.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通常较弱的模型的集合会比单一强大的模型表现更好。在竞赛总结中，成功的竞争者分享了一些技巧，说明他们如何加速在CPU上的推理，以便能够集合多个模型。
- en: 'This article covers the following tricks that were shared in the write-ups:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本文介绍了在总结中分享的一些技巧：
- en: '[Model Selection](#2de6)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型选择](#2de6)'
- en: '[Post-Training Quantization](#984f)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[训练后量化](#984f)'
- en: '[Multithreading](#2cc1)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多线程](#2cc1)'
- en: Model Selection
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型选择
- en: 'The model size heavily impacts the inference time. As a rule of thumb: the
    bigger the model, the longer the inference time.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 模型大小严重影响推理时间。一般规则是：模型越大，推理时间越长。
- en: 'As a rule of thumb: the bigger the model, the longer the inference time.'
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一般规则是：模型越大，推理时间越长。
- en: Thus, when selecting the backbones for the models in their ensembles, competitors
    had to evaluate which models resulted in the best trade-off between performance
    and inference time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在为其模型集合选择骨干网络时，竞争者必须评估哪些模型在性能和推理时间之间提供了最佳的折衷。
- en: While NFNet (`eca_nfnet_l0`) [3, 5, 7, 9, 10, 11, 13, 14, 16] and EfficientNet
    didn’t change as the popular backbones between the [last year’s](https://www.kaggle.com/competitions/birdclef-2022/)
    and this year’s competition, we could see that in this year’s competition, competitors
    preferred smaller versions of EfficientNet.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管NFNet (`eca_nfnet_l0`) [3, 5, 7, 9, 10, 11, 13, 14, 16] 和EfficientNet在去年和今年的比赛中仍然是流行的骨干网络，但我们可以看到，在今年的比赛中，竞争者更倾向于使用EfficientNet的小版本。
- en: While in the [BirdCLEF 2022](https://www.kaggle.com/competitions/birdclef-2022/)
    competition `tf_efficientnet_b0_ns` [8, 11], `tf_efficientnet_b3_ns` [8], `tf_efficientnetv2_s_in21k`
    [11, 16], and `tf_efficientnetv2_m_in21k` [13] were popular, this year the smaller
    versions `tf_efficientnet_b0_ns` [1, 5, 6, 7, 10] and `tf_efficientnetv2_s_in21k`
    [1, 6, 15] were preferably used.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在[BirdCLEF 2022](https://www.kaggle.com/competitions/birdclef-2022/)比赛中，`tf_efficientnet_b0_ns`
    [8, 11]、`tf_efficientnet_b3_ns` [8]、`tf_efficientnetv2_s_in21k` [11, 16]和`tf_efficientnetv2_m_in21k`
    [13]非常受欢迎，但今年较小版本的`tf_efficientnet_b0_ns` [1, 5, 6, 7, 10]和`tf_efficientnetv2_s_in21k`
    [1, 6, 15]更受青睐。
- en: Below you can see a comparison of the model sizes in terms of the number of
    parameters for a selection of popular models in the BirdCLEF competition series.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是BirdCLEF竞赛系列中流行模型的参数数量对比。
- en: '![](../Images/eaf0377d18a6da1792353c7000294d77.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eaf0377d18a6da1792353c7000294d77.png)'
- en: The number of parameters for different neural network architectures.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 不同神经网络架构的参数数量。
- en: As a result, we could see that successful competitors leveraged a combination
    of a larger model (`eca_nfnet_l0`) with smaller models (e.g., `tf_efficientnet_b0_ns`).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以看到，成功的竞争者利用了大型模型（`eca_nfnet_l0`）与小型模型（例如，`tf_efficientnet_b0_ns`）的组合。
- en: Post-Training Quantization
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 后训练量化
- en: 'Another trick to speed up inference on CPU is to apply quantization to the
    model after training: Post-training quantization lowers the precision of the model’s
    weights and activations from floating-point precision (32 bits) to a lower bit
    width representation (e.g., 8 bits).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 提高CPU推理速度的另一个技巧是对训练后的模型应用量化：后训练量化将模型的权重和激活的精度从浮点精度（32位）降低到较低位宽表示（例如8位）。
- en: This technique transforms the model into a more hardware-friendly representation
    and thus improves latency. However, due to the loss in precision of the weight
    and activation representation, it can also lead to slight performance loss.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术将模型转化为更适合硬件的表示，从而提高延迟性能。然而，由于权重和激活表示的精度损失，它也可能导致轻微的性能下降。
- en: Quantization goes hand in hand with hardware. For example, a Kaggle Notebook
    has [4 CPUs (Intel(R) Xeon(R) CPU @ 2.20GHz with x86_64 architecture](https://www.kaggle.com/questions-and-answers/120979)).
    These [Intel CPUs with x86 architecture prefer the quantized data types to be](https://www.intel.com/content/www/us/en/developer/articles/technical/accelerate-pytorch-int8-inf-with-new-x86-backend.html)
    `[INT8](https://www.intel.com/content/www/us/en/developer/articles/technical/accelerate-pytorch-int8-inf-with-new-x86-backend.html)`[.](https://www.intel.com/content/www/us/en/developer/articles/technical/accelerate-pytorch-int8-inf-with-new-x86-backend.html)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 量化与硬件密切相关。例如，一个Kaggle笔记本具有[4个CPU（Intel(R) Xeon(R) CPU @ 2.20GHz，x86_64架构）](https://www.kaggle.com/questions-and-answers/120979)。这些[带有x86架构的Intel
    CPU更倾向于使用量化数据类型](https://www.intel.com/content/www/us/en/developer/articles/technical/accelerate-pytorch-int8-inf-with-new-x86-backend.html)
    `[INT8](https://www.intel.com/content/www/us/en/developer/articles/technical/accelerate-pytorch-int8-inf-with-new-x86-backend.html)`[。](https://www.intel.com/content/www/us/en/developer/articles/technical/accelerate-pytorch-int8-inf-with-new-x86-backend.html)
- en: '*Hint: To display information about the CPU architecture, run the* `[*lscpu*](https://man7.org/linux/man-pages/man1/lscpu.1.html)`
    *command and then check the manufacturer’s homepage to see which quantized input
    data types that specific CPU prefers.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示：要显示有关CPU架构的信息，请运行* `[*lscpu*](https://man7.org/linux/man-pages/man1/lscpu.1.html)`
    *命令，然后检查制造商的主页，以查看特定CPU偏好的量化输入数据类型。*'
- en: 'For an in-depth explanation of post-training quantization and a comparison
    of ONNX Runtime and OpenVINO, I recommend this article:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 关于后训练量化的详细解释以及ONNX Runtime和OpenVINO的比较，我推荐这篇文章：
- en: '[](https://blog.ml6.eu/openvino-vs-onnx-for-transformers-in-production-3e10c01520c8?source=post_page-----6820ac7349bb--------------------------------)
    [## OpenVINO vs ONNX for Transformers in production'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[## OpenVINO 与 ONNX 在生产中的 Transformers](https://blog.ml6.eu/openvino-vs-onnx-for-transformers-in-production-3e10c01520c8?source=post_page-----6820ac7349bb--------------------------------)'
- en: Transformers has revolutionized NLP, making it the first choice for applications
    like machine translation, semantic…
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Transformers 已经彻底改变了自然语言处理（NLP），成为机器翻译、语义理解等应用的首选。
- en: blog.ml6.eu](https://blog.ml6.eu/openvino-vs-onnx-for-transformers-in-production-3e10c01520c8?source=post_page-----6820ac7349bb--------------------------------)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[博客](https://blog.ml6.eu/openvino-vs-onnx-for-transformers-in-production-3e10c01520c8?source=post_page-----6820ac7349bb--------------------------------)'
- en: 'This section will specifically look at two popular techniques of post-training
    quantization:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将特别关注两种流行的训练后量化技术：
- en: '[ONNX Runtime](#c55e)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ONNX Runtime](#c55e)'
- en: '[OpenVINO](#b44e)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenVINO](#b44e)'
- en: ONNX Runtime
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ONNX Runtime
- en: One popular approach to speed-up inference on CPU was to convert the final models
    to [ONNX](https://onnx.ai/) (Open Neural Network Exchange) format [2, 7, 9, 10,
    14, 15].
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 加速 CPU 推理的一个流行方法是将最终模型转换为 [ONNX](https://onnx.ai/)（开放神经网络交换）格式 [2, 7, 9, 10,
    14, 15]。
- en: 'The relevant steps to quantize and accelerate inference on CPU with ONNX Runtime
    are shown below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ONNX Runtime 量化和加速 CPU 推理的相关步骤如下：
- en: '**Preparation:** Install ONNX Runtime'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**准备：** 安装 ONNX Runtime'
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Step 1:** Convert PyTorch Model to ONNX'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 1 步：** 将 PyTorch 模型转换为 ONNX'
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Step 2:** Make predictions with an ONNX Runtime session'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 2 步：** 使用 ONNX Runtime 会话进行预测'
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: OpenVINO
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenVINO
- en: 'The equally popular approach to speed-up inference on CPU was to use OpenVINO
    (Open Visual Inference and Neural network Optimization) [5, 6, 12] as shown in
    [this Kaggle Notebook](https://www.kaggle.com/code/honglihang/openvino-is-all-you-need):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个同样流行的加速 CPU 推理的方法是使用 OpenVINO（开放视觉推理和神经网络优化）[5, 6, 12]，如 [这个 Kaggle Notebook](https://www.kaggle.com/code/honglihang/openvino-is-all-you-need)
    所示：
- en: '[](https://www.kaggle.com/code/honglihang/openvino-is-all-you-need?source=post_page-----6820ac7349bb--------------------------------)
    [## openvino is all you need'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[## openvino 是你所需要的一切](https://www.kaggle.com/code/honglihang/openvino-is-all-you-need?source=post_page-----6820ac7349bb--------------------------------)'
- en: Explore and run machine learning code with Kaggle Notebooks | Using data from
    multiple data sources
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Kaggle Notebooks 探索和运行机器学习代码 | 使用来自多个数据源的数据
- en: www.kaggle.com](https://www.kaggle.com/code/honglihang/openvino-is-all-you-need?source=post_page-----6820ac7349bb--------------------------------)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.kaggle.com](https://www.kaggle.com/code/honglihang/openvino-is-all-you-need?source=post_page-----6820ac7349bb--------------------------------)'
- en: 'The relevant steps to quantize and accelerate a Deep Learning model with OpenVINO
    are shown below:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenVINO 量化和加速深度学习模型的相关步骤如下：
- en: '**Preparation:** Install OpenVINO'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**准备：** 安装 OpenVINO'
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Step 1:** Convert PyTorch Model to ONNX (see Step 1 of [ONNX Runtime](#c55e))'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 1 步：** 将 PyTorch 模型转换为 ONNX（见 [ONNX Runtime](#c55e) 的第 1 步）'
- en: '**Step 2:** Convert ONNX Model to OpenVINO'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 2 步：** 将 ONNX 模型转换为 OpenVINO'
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This will output an XML file and a BIN file — of which we will we using the
    XML file in the next step.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出一个 XML 文件和一个 BIN 文件——我们将在下一步中使用 XML 文件。
- en: '**Step 3:** Quantize to `INT8` using OpenVINO'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 3 步：** 使用 OpenVINO 量化为 `INT8`'
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Step 4:** Make predictions with an OpenVINO inference request'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 4 步：** 使用 OpenVINO 推理请求进行预测'
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Comparison: ONNX vs. OpenVINO vs. Alternatives'
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较：ONNX 与 OpenVINO 与其他替代方案
- en: Both ONNX and OpenVINO are frameworks optimized for deploying models on CPUs.
    [The inference times of a neural network quantized with ONNX and OpenVINO are
    said to be comparable](https://blog.ml6.eu/openvino-vs-onnx-for-transformers-in-production-3e10c01520c8)
    [12].
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ONNX 和 OpenVINO 都是优化用于在 CPU 上部署模型的框架。[量化的神经网络在 ONNX 和 OpenVINO 上的推理时间被认为是相当的](https://blog.ml6.eu/openvino-vs-onnx-for-transformers-in-production-3e10c01520c8)
    [12]。
- en: Some competitors used PyTorch JIT [3] or TorchScript [1] as alternatives to
    speed up inference on CPU. However, other competitors shared that ONNX was considerably
    faster than TorchScript [10].
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一些竞争对手使用 PyTorch JIT [3] 或 TorchScript [1] 作为加速 CPU 推理的替代方案。然而，其他竞争对手表示 ONNX
    比 TorchScript [10] 快得多。
- en: Multithreading with ThreadPoolExecutor
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ThreadPoolExecutor 进行多线程
- en: 'Another popular approach to speed-up inference on CPU was to use multithreading
    with [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html)
    [2, 3, 9, 15] in addition to post-training quantization, as shown in [this Kaggle
    Notebook](https://www.kaggle.com/code/leonshangguan/faster-eb0-sed-model-inference):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种加快 CPU 推断的流行方法是使用多线程和[ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html)
    [2, 3, 9, 15]，此外还包括后训练量化，如[这个Kaggle笔记本](https://www.kaggle.com/code/leonshangguan/faster-eb0-sed-model-inference)所示：
- en: '[](https://www.kaggle.com/code/leonshangguan/faster-eb0-sed-model-inference?source=post_page-----6820ac7349bb--------------------------------)
    [## Faster eb0_SED model inference'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.kaggle.com/code/leonshangguan/faster-eb0-sed-model-inference?source=post_page-----6820ac7349bb--------------------------------)
    [## Faster eb0_SED 模型推断'
- en: Explore and run machine learning code with Kaggle Notebooks | Using data from
    multiple data sources
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Kaggle笔记本中探索和运行机器学习代码 | 使用来自多个数据源的数据
- en: www.kaggle.com](https://www.kaggle.com/code/leonshangguan/faster-eb0-sed-model-inference?source=post_page-----6820ac7349bb--------------------------------)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: www.kaggle.com](https://www.kaggle.com/code/leonshangguan/faster-eb0-sed-model-inference?source=post_page-----6820ac7349bb--------------------------------)
- en: This enabled competitors to run multiple inferences at the same time.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得参赛者能够同时运行多个推断。
- en: In the following example of [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html)
    from the competition, we have a list of audio files to infer.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在比赛中的[ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html)示例中，我们有一个音频文件列表需要推断。
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next, you need to define an inference function that takes an audio file as input
    and returns the predictions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要定义一个推断函数，该函数以音频文件作为输入并返回预测结果。
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: With the list of audios (e.g., `audios`) and the inference function (e.g., `predict()`),
    you now can use [ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html)
    to run multiple inferences at the same time (in parallel) as opposed to sequentially,
    which will give you a nice boost in inference time.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有了音频列表（例如`audios`）和推断函数（例如`predict()`），你现在可以使用[ThreadPoolExecutor](https://docs.python.org/3/library/concurrent.futures.html)来并行运行多个推断，这将显著提高推断速度。
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Summary
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: There are many more lessons to be learned from reviewing the learning resources
    Kagglers have created during the course of the [“BirdCLEF 2023](https://www.kaggle.com/competitions/birdclef-2023/)”
    competition. There are also many different solutions for this type of problem
    statement.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 从审查 Kagglers 在[“BirdCLEF 2023](https://www.kaggle.com/competitions/birdclef-2023/)”比赛过程中创建的学习资源中，可以学习到许多更多的课程。对于这种类型的问题声明，还有许多不同的解决方案。
- en: 'In this article, we focused on the general approach that was popular among
    many competitors:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们关注了许多参赛者所采用的通用方法：
- en: '[Model Selection](#2de6): Select the model size according to the best trade-off
    between performance and inference time. Also, leverage bigger and smaller models
    in your ensemble.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型选择](#2de6)：根据性能和推断时间之间的最佳权衡选择模型大小。同时，在你的集成中利用更大和更小的模型。'
- en: '[Post-Training Quantization](#984f): Post-training quantization can lead to
    faster inference times due to datatypes of the model weights and activations being
    optimized to the hardware. However, this can lead to a slight loss of model performance.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[后训练量化](#984f)：后训练量化可以通过将模型权重和激活的 datatype 优化为硬件来加快推断时间。然而，这可能会导致模型性能的轻微下降。'
- en: '[Multithreading](#2cc1): Run multiple inferences in parallel instead of sequentially.
    This will give you a boost in inference time.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多线程](#2cc1)：并行运行多个推断，而不是按顺序进行。这将提高你的推断时间。'
- en: 'If you are interested in how to approach audio classification with Deep Learning,
    which was the main aspect of this competition, check out the write-up of the [BirdCLEF
    2022](https://www.kaggle.com/competitions/birdclef-2022/) competition:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对如何使用深度学习进行音频分类感兴趣，这是本次比赛的主要内容，请查看[BirdCLEF 2022](https://www.kaggle.com/competitions/birdclef-2022/)比赛的总结：
- en: '[](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)
    [## Audio Classification with Deep Learning in Python'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)
    [## 使用深度学习进行 Python 中的音频分类'
- en: Fine-tuning image models to tackle domain shift and class imbalance with PyTorch
    and torchaudio in audio data
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 PyTorch 和 torchaudio 在音频数据中调整图像模型以应对领域偏移和类别不平衡
- en: towardsdatascience.com](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/audio-classification-with-deep-learning-in-python-cf752b22ba07?source=post_page-----6820ac7349bb--------------------------------)'
- en: Enjoyed This Story?
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 喜欢这个故事吗？
- en: '[*Subscribe for free*](https://medium.com/subscribe/@iamleonie) *to get notified
    when I publish a new story.*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[*免费订阅*](https://medium.com/subscribe/@iamleonie) *以便在我发布新故事时收到通知。*'
- en: '[](https://medium.com/@iamleonie/subscribe?source=post_page-----6820ac7349bb--------------------------------)
    [## Get an email whenever Leonie Monigatti publishes.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://medium.com/@iamleonie/subscribe?source=post_page-----6820ac7349bb--------------------------------](https://medium.com/@iamleonie/subscribe?source=post_page-----6820ac7349bb--------------------------------)
    [## 每当 Leonie Monigatti 发布新内容时，会收到电子邮件通知。]'
- en: Get an email whenever Leonie Monigatti publishes. By signing up, you will create
    a Medium account if you don’t already…
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每当 Leonie Monigatti 发布新内容时，会收到电子邮件通知。通过注册，如果你尚未拥有 Medium 帐户，将创建一个。
- en: medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----6820ac7349bb--------------------------------)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@iamleonie/subscribe?source=post_page-----6820ac7349bb--------------------------------)'
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/804250ab/),[*Twitter*](https://twitter.com/helloiamleonie)*,
    and* [*Kaggle*](https://www.kaggle.com/iamleonie)*!*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/804250ab/)、[*Twitter*](https://twitter.com/helloiamleonie)
    *和* [*Kaggle*](https://www.kaggle.com/iamleonie) *上找到我！*'
- en: References
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Image References
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像参考
- en: If not otherwise stated, all images are created by the author.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图像均由作者创作。
- en: Web & Literature
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络与文献
- en: '[1] adsr (2023). [3rd place solution: SED with attention on Mel frequency bands](https://www.kaggle.com/competitions/birdclef-2023/discussion/414102)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] adsr (2023). [第3名解决方案：在 Mel 频带上的 SED 和注意力](https://www.kaggle.com/competitions/birdclef-2023/discussion/414102)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[2] anonamename (2023). [6th place solution: BirdNET embedding + CNN](https://www.kaggle.com/competitions/birdclef-2023/discussion/412708)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] anonamename (2023). [第6名解决方案：BirdNET 嵌入 + CNN](https://www.kaggle.com/competitions/birdclef-2023/discussion/412708)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[3] atfujita (2023). [4th Place Solution: Knowledge Distillation Is All You
    Need](https://www.kaggle.com/competitions/birdclef-2023/discussion/412753) in
    Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] atfujita (2023). [第4名解决方案：知识蒸馏是你所需要的一切](https://www.kaggle.com/competitions/birdclef-2023/discussion/412753)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[4] [beluga](https://www.kaggle.com/gaborfodor) (2023). [Inference constraints
    — CPU Notebook <= 120 minutes](https://www.kaggle.com/competitions/birdclef-2023/discussion/393059)
    (accessed March 27th, 2023).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [beluga](https://www.kaggle.com/gaborfodor) (2023). [推理约束 — CPU 笔记本 <=
    120 分钟](https://www.kaggle.com/competitions/birdclef-2023/discussion/393059)（访问日期：2023年3月27日）。'
- en: '[5] Harshit Sheoran (2023). [9th Place Solution: 7 CNN Models Ensemble](https://www.kaggle.com/competitions/birdclef-2023/discussion/412794)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Harshit Sheoran (2023). [第9名解决方案：7 个 CNN 模型组合](https://www.kaggle.com/competitions/birdclef-2023/discussion/412794)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[6] HONG LIHANG (2023). [2nd place solution: SED + CNN with 7 models ensemble](https://www.kaggle.com/competitions/birdclef-2023/discussion/412707)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] HONG LIHANG (2023). [第二名解决方案：SED + CNN 结合 7 模型](https://www.kaggle.com/competitions/birdclef-2023/discussion/412707)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[7] HyeongChan Kim (2023). [24th place solution — pre-training & single model
    (5 folds ensemble with ONNX)](https://www.kaggle.com/competitions/birdclef-2023/discussion/412996)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] HyeongChan Kim (2023). [第24名解决方案 — 预训练 & 单模型（5 折组合与 ONNX）](https://www.kaggle.com/competitions/birdclef-2023/discussion/412996)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[8] LeonShangguan (2022). [[Public #1 Private #2] + [Private #7/8 (potential)]
    solutions. The host wins.](https://www.kaggle.com/competitions/birdclef-2022/discussion/326950)
    in Kaggle Discussions (accessed March 13th, 2023)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] LeonShangguan (2022). [[公开 #1 私密 #2] + [私密 #7/8（潜在）] 解决方案。主持人获胜。](https://www.kaggle.com/competitions/birdclef-2022/discussion/326950)
    在 Kaggle 讨论中（访问日期：2023年3月13日）'
- en: '[9] LeonShangguan (2023). [10th place solution](https://www.kaggle.com/competitions/birdclef-2023/discussion/412713)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] LeonShangguan (2023). [第10名解决方案](https://www.kaggle.com/competitions/birdclef-2023/discussion/412713)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[10] moritake04 (2023). [20th place solution: SED + CNN ensemble using onnx](https://www.kaggle.com/competitions/birdclef-2023/discussion/412742)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] moritake04 (2023). [第20名解决方案：使用 onnx 的 SED + CNN 组合](https://www.kaggle.com/competitions/birdclef-2023/discussion/412742)
    在 Kaggle 讨论中（访问日期：2023年6月1日）'
- en: '[11] slime (2022). [3rd place solution](https://www.kaggle.com/competitions/birdclef-2022/discussion/327193)
    in Kaggle Discussions (accessed March 13th, 2023)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] slime (2022). [第3名解决方案](https://www.kaggle.com/competitions/birdclef-2022/discussion/327193)
    在 Kaggle 讨论区（访问日期：2023年3月13日）'
- en: '[12] storm (2023). [top 7th solution — `sumix` augmentation did all the work](https://www.kaggle.com/competitions/birdclef-2023/discussion/412922)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] storm (2023). [第7名解决方案 — `sumix` 增强做了所有的工作](https://www.kaggle.com/competitions/birdclef-2023/discussion/412922)
    在 Kaggle 讨论区（访问日期：2023年6月1日）'
- en: '[13] Volodymyr (2022). [1st place solution models (it’s not all BirdNet)](https://www.kaggle.com/competitions/birdclef-2022/discussion/327047)
    in Kaggle Discussions (accessed March 13th, 2023)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] Volodymyr (2022). [第1名解决方案模型（这不是全部的 BirdNet）](https://www.kaggle.com/competitions/birdclef-2022/discussion/327047)
    在 Kaggle 讨论区（访问日期：2023年3月13日）'
- en: '[14] Volodymyr (2023). [1st place solution: Correct Data is All You Need](https://www.kaggle.com/competitions/birdclef-2023/discussion/412808)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] Volodymyr (2023). [第1名解决方案：正确的数据就是你所需要的一切](https://www.kaggle.com/competitions/birdclef-2023/discussion/412808)
    在 Kaggle 讨论区（访问日期：2023年6月1日）'
- en: '[15] Yevhenii Maslov (2023). [5th place solution](https://www.kaggle.com/competitions/birdclef-2023/discussion/412903)
    in Kaggle Discussions (accessed June 1st, 2023)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[15] Yevhenii Maslov (2023). [第5名解决方案](https://www.kaggle.com/competitions/birdclef-2023/discussion/412903)
    在 Kaggle 讨论区（访问日期：2023年6月1日）'
- en: '[16] yokuyama (2022). [5th place solution](https://www.kaggle.com/competitions/birdclef-2022/discussion/327044)
    in Kaggle Discussions (accessed March 13th, 2023)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[16] yokuyama (2022). [第5名解决方案](https://www.kaggle.com/competitions/birdclef-2022/discussion/327044)
    在 Kaggle 讨论区（访问日期：2023年3月13日）'
