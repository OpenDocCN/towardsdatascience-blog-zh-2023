- en: Five Practical Applications of the LSTM Model for Time Series, with Code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 五种实际应用 LSTM 模型于时间序列的案例，附代码
- en: 原文：[https://towardsdatascience.com/five-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0?source=collection_archive---------0-----------------------#2023-09-22](https://towardsdatascience.com/five-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0?source=collection_archive---------0-----------------------#2023-09-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/five-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0?source=collection_archive---------0-----------------------#2023-09-22](https://towardsdatascience.com/five-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0?source=collection_archive---------0-----------------------#2023-09-22)
- en: How to implement an advanced neural network model in several different time
    series contexts
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何在多个不同的时间序列背景下实现高级神经网络模型
- en: '[](https://mikekeith52.medium.com/?source=post_page-----a7aac0aa85c0--------------------------------)[![Michael
    Keith](../Images/4ebd39b25a1faae3586eb25ec83d3e91.png)](https://mikekeith52.medium.com/?source=post_page-----a7aac0aa85c0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a7aac0aa85c0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a7aac0aa85c0--------------------------------)
    [Michael Keith](https://mikekeith52.medium.com/?source=post_page-----a7aac0aa85c0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mikekeith52.medium.com/?source=post_page-----a7aac0aa85c0--------------------------------)[![Michael
    Keith](../Images/4ebd39b25a1faae3586eb25ec83d3e91.png)](https://mikekeith52.medium.com/?source=post_page-----a7aac0aa85c0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a7aac0aa85c0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a7aac0aa85c0--------------------------------)
    [Michael Keith](https://mikekeith52.medium.com/?source=post_page-----a7aac0aa85c0--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85177a9cbd35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0&user=Michael+Keith&userId=85177a9cbd35&source=post_page-85177a9cbd35----a7aac0aa85c0---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a7aac0aa85c0--------------------------------)
    ·11 min read·Sep 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa7aac0aa85c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0&user=Michael+Keith&userId=85177a9cbd35&source=-----a7aac0aa85c0---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85177a9cbd35&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0&user=Michael+Keith&userId=85177a9cbd35&source=post_page-85177a9cbd35----a7aac0aa85c0---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a7aac0aa85c0--------------------------------)
    ·11 min read·Sep 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa7aac0aa85c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0&user=Michael+Keith&userId=85177a9cbd35&source=-----a7aac0aa85c0---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7aac0aa85c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0&source=-----a7aac0aa85c0---------------------bookmark_footer-----------)![](../Images/570ca4e50b8bc9e41b05c753bd7d1609.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa7aac0aa85c0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-practical-applications-of-the-lstm-model-for-time-series-with-code-a7aac0aa85c0&source=-----a7aac0aa85c0---------------------bookmark_footer-----------)![](../Images/570ca4e50b8bc9e41b05c753bd7d1609.png)'
- en: Photo by [Andrew Svk](https://unsplash.com/@andrew_svk?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [Andrew Svk](https://unsplash.com/@andrew_svk?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: When I wrote [Exploring the LSTM Neural Network Model for Time Series](https://medium.com/towards-data-science/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf)
    in January, 2022, my goal was to showcase how easily the advanced neural network
    could be implemented in Python using [scalecast](https://github.com/mikekeith52/scalecast),
    a time series library I developed to facilitate my own work and projects. I did
    not think that it would be viewed over 10s of thousands of times and appear as
    the first hit on Google when searching “lstm forecasting python” for over a year
    after I published it (when I checked today, it was still number two).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在2022年1月写了[探索LSTM神经网络模型在时间序列中的应用](https://medium.com/towards-data-science/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf)时，我的目标是展示如何使用我开发的时间序列库[scalecast](https://github.com/mikekeith52/scalecast)在Python中轻松实现这个先进的神经网络。我没想到它会被观看超过数万次，并在我发布后超过一年内在Google搜索“lstm
    forecasting python”时排名第一（今天检查时，它仍然是第二）。
- en: 'I haven’t tried to call much attention to that article because I never thought,
    and still don’t think, it is very good. It was never meant to be a guide on the
    best way to implement the LSTM model, but rather a simple exploration of its utility
    for time series forecasting. I tried to answer such questions as: what happens
    when you run the model with default parameters, what happens when you adjust its
    parameters in this way or that, how easily can it be beat by other models on certain
    datasets, etc. However, judging by the blog posts, Kaggle notebooks, and even
    the [Udemy course](https://www.udemy.com/course/uniform-ml-dl/) that I keep seeing
    pop up with the code from that article copied verbatim, it’s clear many people
    were taking the piece for the former value, not the latter. I understand now that
    I did not clearly lay out my intentions.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我并没有尝试引起对那篇文章的过多关注，因为我从未认为，也仍然认为，它不是很好。它从未打算成为实现LSTM模型最佳方法的指南，而只是简单探讨其在时间序列预测中的实用性。我试图回答诸如：当你使用默认参数运行模型时会发生什么，当你以这种或那种方式调整参数时会发生什么，它在某些数据集上被其他模型击败的难易程度等问题。然而，根据博客文章、Kaggle笔记本，甚至我不断看到的[Udemy课程](https://www.udemy.com/course/uniform-ml-dl/)，这篇文章的代码被逐字复制，很明显许多人把它当作前者的价值，而不是后者。我现在明白我没有清晰地表达我的意图。
- en: 'Today, to expand upon that article, I want to showcase how one should apply
    the LSTM neural network model, or at least how I would apply it, to fully realize
    its value for time series forecasting problems. Since I wrote the first article,
    we have been able to add many new and innovative features to the scalecast library
    that make using the LSTM model much more seamless and I will take this space to
    explore some of my favorites. There are five applications for LSTM that I think
    will all work fantastically using the library: **univariate forecasting, multivariate
    forecasting, probabilistic forecasting, dynamic probabilistic forecasting, and
    transfer learning.**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，为了扩展那篇文章，我想展示如何应用LSTM神经网络模型，或者至少是我如何应用它，以充分发挥其在时间序列预测问题中的价值。自从我写了第一篇文章以来，我们已经能够为scalecast库添加许多新的创新功能，使得使用LSTM模型更加无缝，我将在这里探讨一些我最喜欢的功能。我认为LSTM有五种应用会在这个库中表现得非常出色：**单变量预测、多变量预测、概率预测、动态概率预测和迁移学习**。
- en: 'Before starting, be sure to run on terminal or command line:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保在终端或命令行中运行：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The complete notebook developed for this article is located [here.](https://github.com/mikekeith52/scalecast-examples/blob/main/lstm/lstm_latest.ipynb)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为本文开发的完整笔记本位于[这里。](https://github.com/mikekeith52/scalecast-examples/blob/main/lstm/lstm_latest.ipynb)
- en: 'One final note: in each example, I may use the terms “RNN” and “LSTM” interchangeably.
    Alternatively, RNN may be displayed on a given graph of an LSTM forecast. The
    long short-term memory (LSTM) neural network is a type of recurrent neural network
    (RNN), with additional memory-related parameters. In scalecast, the `rnn` model
    class can be used to fit both simple RNN and LSTM cells in models ported from
    [tensorflow](https://www.tensorflow.org/).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点：在每个示例中，我可能会将“RNN”和“LSTM”互换使用。或者，RNN可能会显示在LSTM预测的某个图表上。长短期记忆（LSTM）神经网络是一种递归神经网络（RNN），具有额外的记忆相关参数。在scalecast中，`rnn`模型类可以用来拟合从[tensorflow](https://www.tensorflow.org/)移植过来的简单RNN和LSTM单元。
- en: 1\. Univariate forecasting
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 单变量预测
- en: 'The most common and most obvious way to use the LSTM model is when doing a
    simple univariate forecasting problem. Although the model fits many parameters
    that should make it sophisticated enough to learn trends, seasonality, and short-term
    dynamics in any given time series effectively, I have found that it does much
    better with stationary data (data that doesn’t exhibit trends or seasonality).
    So, with the air passengers dataset — which is available on [Kaggle](https://www.kaggle.com/rakannimer/air-passengers)
    with an Open Database license — we can easily create an accurate and reliable
    forecast using fairly simple hyperparameters, if we simply detrend and de-season
    the data:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LSTM模型最常见且最明显的方式是处理简单的单变量预测问题。尽管该模型拟合了许多参数，使其足够复杂以有效学习任何给定时间序列中的趋势、季节性和短期动态，但我发现它在处理平稳数据（即不表现出趋势或季节性的数据显示）时效果更好。因此，使用可在[Kaggle](https://www.kaggle.com/rakannimer/air-passengers)上获取的航空乘客数据集，我们可以仅通过去趋势和去季节性处理数据，使用相当简单的超参数来创建准确可靠的预测：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We also want to make sure to revert the results to their original level when
    we are done:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还要确保在完成后将结果恢复到其原始水平：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, we can specify the network parameters. For this example, we will use 18
    lags, one layer, a tanh activation function, and 200 epochs. Feel free to explore
    your own, better parameters!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以指定网络参数。在这个示例中，我们将使用18个滞后、一个层、一个tanh激活函数和200个训练周期。随意探索你自己的、更好的参数！
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Combine everything into a pipeline, run the model, and view the results visually:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有内容结合成一个管道，运行模型，并从视觉上查看结果：
- en: '[PRE4]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/81ebede65597a9ee7bfb3243f13595af.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81ebede65597a9ee7bfb3243f13595af.png)'
- en: Image by author
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Good enough and much better than anything I demonstrated in the other article.
    To extend this application, you can try using different lag orders, adding seasonality
    to the model in the form of Fourier terms, finding better series transformations,
    and tuning the model hyperparameters with cross-validation. Some of how to do
    this will be demonstrated in the subsequent sections.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 足够好，比我在另一篇文章中展示的任何内容都要好得多。要扩展这个应用，你可以尝试使用不同的滞后阶数，将季节性以傅里叶项的形式添加到模型中，寻找更好的序列转换，并通过交叉验证来调整模型的超参数。后续部分将演示其中的一些方法。
- en: 2\. Multivariate forecasting
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 多变量预测
- en: Let’s say that we have two series that we expect move together. We can create
    an LSTM model that takes both series into consideration when making predictions
    with the hope that we improve the model’s overall accuracy. This is, of course,
    multivariate forecasting.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个序列，我们预计它们会一起变化。我们可以创建一个LSTM模型，在进行预测时考虑这两个序列，希望提高模型的整体准确性。这就是所谓的多变量预测。
- en: For this example, I will use the Avocados dataset, available on [Kaggle](https://www.kaggle.com/datasets/neuromusic/avocado-prices)
    with an Open Database license. It measures the price and quantity sold of avocados
    on a weekly level over different regions of the United States. We know from economic
    theory that price and demand are closely interrelated, so using price as a leading
    indicator, we might be able to more accurately forecast the amount of avocados
    sold than just by using historical demand in a univariate context.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我将使用可在[Kaggle](https://www.kaggle.com/datasets/neuromusic/avocado-prices)上获取的鳄梨数据集。它测量了不同美国地区的鳄梨价格和销售数量。根据经济理论，我们知道价格和需求是密切相关的，因此使用价格作为领先指标，我们可能会比仅使用历史需求更准确地预测鳄梨的销售量。
- en: 'The first thing we will do is transform each series. We can search for an “optimal”
    set of transformations (meaning transformations that are scored out-of-sample)
    by running the following code:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要做的是转换每个序列。我们可以通过运行以下代码来搜索一组“最佳”转换（即在样本外得分的转换）：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The recommended transformation from this process is a seasonal adjustment,
    assuming 52 periods makes one season, as well as a [robust scale](https://scalecast.readthedocs.io/en/latest/Forecaster/SeriesTransformer.html#src.scalecast.SeriesTransformer.SeriesTransformer.RobustScaleTransform)
    (scaling that is robust to outliers). We can then fit that transformation on the
    series and call a univariate LSTM model to benchmark the multivariate model against.
    This time, we will use a hyperparameter-tuning process by generating a grid of
    possible activation functions, layer sizes, and dropout values:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个过程中推荐的变换是季节调整，假设52个周期构成一个季节，以及一个[鲁棒缩放](https://scalecast.readthedocs.io/en/latest/Forecaster/SeriesTransformer.html#src.scalecast.SeriesTransformer.SeriesTransformer.RobustScaleTransform)（对异常值鲁棒的缩放）。然后，我们可以在系列上拟合该变换，并调用单变量LSTM模型，以便与多变量模型进行基准对比。这一次，我们将使用超参数调优过程，生成可能的激活函数、层大小和丢弃值的网格。
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This function gives a good way to ingest a manageable grid into our object
    but also have enough randomness to have a good candidates of parameters to choose
    from. Now we fit the univariate model:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数提供了一种将可管理的网格输入到我们的对象中的良好方式，同时也有足够的随机性，以便有一个好的参数候选集。现在我们拟合单变量模型：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To extend this into a multivariate context, we can transform the price time
    series with the same set of transformations that we used on the other series.
    Then, we ingest 13 price lags into the `Forecaster` object and fit a new LSTM
    model:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将其扩展到多变量背景下，我们可以用与其他系列相同的变换集来转换价格时间序列。然后，将13个价格滞后值输入`Forecaster`对象中，并拟合一个新的LSTM模型：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can also benchmark a naïve model and plot the results at the original series
    level, along with the out-of-sample test set:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以基准化一个简单模型，并在原始系列水平绘制结果，以及样本外测试集：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/5605031cd04228825bed914a5f0db15c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5605031cd04228825bed914a5f0db15c.png)'
- en: Image by author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者提供的图像
- en: Judging by how all three models clustered together visually, what led to most
    of the accuracy on this particular series were the applied transformations — that’s
    how the naïve model ended up so comparable to both the LSTM models. Still, the
    LSTM models are an improvement, with the multivariate model scoring and r-squared
    of 38.37% and the univariate mode 26.35%, compared to the baseline of -6.46%.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从三种模型的视觉聚类来看，这一系列数据的准确性主要得益于所应用的变换——这也是为什么简单模型与LSTM模型的表现如此接近的原因。不过，LSTM模型确实有所改进，多变量模型的得分和r平方为38.37%，单变量模型为26.35%，而基准为-6.46%。
- en: '![](../Images/ac0ea0981c8f20a4eaa14a3d887c72f0.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac0ea0981c8f20a4eaa14a3d887c72f0.png)'
- en: Image by author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者提供的图像
- en: One thing that might have hindered the LSTM models from performing better on
    this series is how short it is. With only 169 observations, that may not be enough
    history for the model to sufficiently learn the patterns. However, any improvement
    over some naïve or simple model can be considered a success.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 可能阻碍LSTM模型在这一系列数据上表现更好的一个因素是数据集的长度。仅有169个观察值，可能不足以让模型充分学习模式。然而，相较于某些简单模型的改进，任何提升都可以被视为成功。
- en: 3\. Probabilistic forecasting
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 概率预测
- en: Probabilistic forecasting refers to the ability of a model to not only make
    point predictions, but to provide estimates of how far off in either direction
    the predictions are likely to be. Probabilistic forecasting is akin to forecasting
    with [confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval),
    a concept that has been around for a long time. A quickly emerging way to produce
    probabilistic forecasts is by applying a [conformal confidence interval](https://en.wikipedia.org/wiki/Conformal_prediction)
    to the model, using a calibration set to determine the likely dispersion of the
    actual future points. This approach has the advantage of being applicable to any
    machine learning model, regardless of any assumptions that model makes about the
    distribution of its inputs or residuals. It also provides certain coverage guarantees
    that are extremely useful to any ML practitioner. We can apply the conformal confidence
    interval to the LSTM model to produce probabilistic forecasts.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 概率预测是指模型不仅能够进行点预测，还能够提供预测偏差的估计。概率预测类似于使用[置信区间](https://en.wikipedia.org/wiki/Confidence_interval)进行预测，这一概念已经存在很长时间了。产生概率预测的一个新兴方法是通过将[一致性置信区间](https://en.wikipedia.org/wiki/Conformal_prediction)应用于模型，利用校准集来确定实际未来点的可能分布。这种方法的优点在于可以适用于任何机器学习模型，无论该模型对输入或残差的分布做出什么假设。它还提供了对任何机器学习从业者都非常有用的覆盖保证。我们可以将一致性置信区间应用于LSTM模型以产生概率预测。
- en: 'For this example, we will use the monthly housings starts dataset available
    on [FRED](https://fred.stlouisfed.org/series/HOUSTNSA), an open-source database
    of economic time series. I will use data from January, 1959 through December,
    2022 (768 observations). First, we will once again search for the optimal set
    of transformations, but this time using an LSTM model with 10 epochs to score
    each transformation try:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用[FRED](https://fred.stlouisfed.org/series/HOUSTNSA)上提供的月度住房开工数据集，这是一个经济时间序列的开放数据库。我将使用1959年1月到2022年12月的数据（768个观察值）。首先，我们将再次搜索最佳的变换集合，但这次使用一个具有10个周期的LSTM模型来评分每次变换尝试：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will randomly generate a hyperparameter grid again, but this time we can
    make its search space very big, then limit it manually to 10 tries when we the
    model is fit later so that we can cross validate the parameters in a reasonable
    amount of time:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次随机生成一个超参数网格，但这次我们可以将其搜索空间设置得非常大，然后在模型拟合后手动将其限制为10次尝试，以便在合理的时间内对参数进行交叉验证：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now we can build and fit the pipeline:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以构建和拟合管道：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Because we set aside a test-set of sufficient size in the `Forecaster` object,
    the results automatically give us the 90% probabilistic distributions for each
    point estimate:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们在`Forecaster`对象中预留了足够大小的测试集，所以结果自动为每个点估计提供了90%的概率分布：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/2a3a19dd3829be24ee965993d01db4d8.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a3a19dd3829be24ee965993d01db4d8.png)'
- en: Image by author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 4\. Dynamic probabilistic forecasting
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 动态概率预测
- en: The previous example provided a static probabilistic prediction, where each
    upper and lower bound along the forecast is equally far away from the point estimate
    as any other upper and lower bound attached to any other point. When predicting
    the future, it is intuitive that the further out one attempts to forecast, the
    wider the error will disperse — a nuance not captured with the static interval.
    There is a way to achieve a more dynamic probabilistic forecast with the LSTM
    model by using backtesting.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的示例提供了一个静态的概率预测，其中预测的每个上界和下界距离点估计的距离与其他点的上界和下界相等。当预测未来时，直观上看，预测越远，误差的扩散范围就越宽——这一细微差别在静态区间中没有体现。通过使用回测，有一种方法可以实现更动态的概率预测。
- en: 'Backtesting is the process of iteratively refitting the the model, predicting
    it over different forecast horizons, and testing its performance over each iteration.
    Let’s take the pipeline specified in the last example and backtest it 10 times.
    We need at least 10 backtest iterations to build confidence intervals at the 90%
    level:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 回测是一个迭代地重新拟合模型、在不同预测范围内进行预测并测试其性能的过程。让我们以最后一个示例中指定的管道为例，对其进行10次回测。我们需要至少10次回测迭代来构建90%置信区间：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can analyze the absolute values of the residuals over each iteration visually:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过可视化分析每次迭代中残差的绝对值：
- en: '![](../Images/ad7b6e26776b9a10327525a368f252ad.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ad7b6e26776b9a10327525a368f252ad.png)'
- en: Image by author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'What’s interesting about this particular example is that the largest errors
    are not usually on the last steps of the forecast, but actually over steps 14–17\.
    This can happen with series that have odd seasonal patterns. The presence of outliers
    can also affect this pattern. Either way, we can use these results to now replace
    the static confidence intervals with dynamic intervals that are conformal along
    each step:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定示例有趣之处在于，最大的误差通常不在预测的最后几个步骤上，而是在步骤14-17之间。这种情况可能发生在具有奇特季节性模式的序列中。异常值的存在也可能影响这种模式。不管怎样，我们可以利用这些结果现在用动态区间替换静态置信区间，这些动态区间在每一步都是符合的。
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/2a3a19dd3829be24ee965993d01db4d8.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a3a19dd3829be24ee965993d01db4d8.png)'
- en: Image by author
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 5\. Transfer learning
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 转移学习
- en: 'Transfer learning is useful when we wish to use a model outside of the context
    in which it was fit. There are two specific scenarios where I will demonstrate
    its utility: making predictions when new data in a given time series becomes available
    and making predictions on a related time series with similar trends and seasonality.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习在我们希望在模型适配的上下文之外使用模型时很有用。我将演示其实用性的两个具体情景：在给定时间序列中有新数据可用时进行预测，以及对具有类似趋势和季节性的相关时间序列进行预测。
- en: 'Scenario 1: New data from the same series'
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情景 1：来自同一序列的新数据
- en: We can use the same housing dataset as in the previous two examples, but let’s
    say some time has passed and we now have data available through June, 2023.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与之前两个示例相同的住房数据集，但假设已经过去了一段时间，我们现在有数据可用到2023年6月。
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We will remake our pipeline with the same transformations, but this time, use
    a transfer forecast instead of the normal scalecast forecast procedure that fits
    a model:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重新制作管道，使用相同的转换，但这次使用转移预测，而不是适配模型的正常尺度预测过程：
- en: '[PRE17]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Even though the name of the relevant function is still `fit_predict()`, there
    actually is no fitting and only predicting in the pipeline as it is written. This
    greatly reduces the amount of time we would have needed to refit and re-optimize
    the model. We then view the results:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管相关函数的名称仍然是`fit_predict()`，但实际上在管道中没有拟合，只有预测。这大大减少了我们需要重新拟合和重新优化模型的时间。然后我们查看结果：
- en: '[PRE18]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/adf6bc2e2facd4840d2993d657467901.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/adf6bc2e2facd4840d2993d657467901.png)'
- en: Image by author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Scenario 2: A new time series with similar characteristics'
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 情景 2：具有相似特征的新时间序列
- en: 'For the second scenario, we can use the hypothetical situation of wanting to
    use the model trained on the housing dynamics in the United States to predict
    housing starts in Canada. Disclaimer: I don’t know if this is actually a good
    idea — it is just one scenario I thought of to demonstrate how this would be done.
    But I imagine it could be useful and the code involved can be transferred to other
    situations (maybe for situations where you have short series that exhibit similar
    dynamics as a longer series that you have already fit a well-performing model
    to). In that case, the code is actually exactly the same as the **Scenario 1**
    code; the only difference is the data we load into the object:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二种情景，我们可以使用一个假设的情况：希望利用在美国住房动态上训练的模型来预测加拿大的住房开工情况。免责声明：我不知道这是否真的一个好主意——这只是我想到的一个场景，用来演示如何完成这一任务。但我认为这可能会有用，而且相关代码可以转移到其他情况（例如，对于那些你拥有的短时间序列，其动态类似于你已经适配了表现良好的模型的较长序列）。在这种情况下，代码实际上与**情景
    1**的代码完全相同；唯一的区别是我们加载到对象中的数据：
- en: '[PRE19]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/d1b79b8b891e40d0ed7a23bf9d0dfc33.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1b79b8b891e40d0ed7a23bf9d0dfc33.png)'
- en: Image by author
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: I think the forecast looks believable enough for this to be an interesting application
    of LSTM transfer learning.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为该预测看起来足够可信，作为LSTM转移学习的一个有趣应用。
- en: Conclusion
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'For many forecasting use cases, the LSTM model can be an interesting solution.
    In this post, I demonstrated how to apply the LSTM model for five different purposes
    with Python code. If you found it useful, give [scalecast a star on GitHub](https://github.com/mikekeith52/scalecast)
    and be sure to give me a follow here on Medium to be updated on the latest and
    greatest with the package. To provide feedback, constructive criticism or if you
    have questions about this code, feel free to email me: mikekeith52@gmail.com.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多预测用例，LSTM 模型可能是一个有趣的解决方案。在这篇文章中，我演示了如何使用 Python 代码将 LSTM 模型应用于五种不同的目的。如果你觉得这很有用，请在
    GitHub 上给[scalecast 点个星](https://github.com/mikekeith52/scalecast)，并务必在 Medium
    上关注我，以便及时了解包的最新动态。如果你有反馈、建设性的批评或对这段代码有任何疑问，随时可以通过电子邮件联系我：mikekeith52@gmail.com。
