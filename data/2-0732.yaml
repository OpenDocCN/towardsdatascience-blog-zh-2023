- en: '🦜🔗 LangChain: Develop applications powered by Language Models'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 🦜🔗 LangChain：开发由语言模型驱动的应用程序
- en: 原文：[https://towardsdatascience.com/develop-applications-powered-by-language-models-with-langchain-d2f7a1d1ad1a](https://towardsdatascience.com/develop-applications-powered-by-language-models-with-langchain-d2f7a1d1ad1a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/develop-applications-powered-by-language-models-with-langchain-d2f7a1d1ad1a](https://towardsdatascience.com/develop-applications-powered-by-language-models-with-langchain-d2f7a1d1ad1a)
- en: '![](../Images/eadb36548cf05e78b4161169a551f8aa.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eadb36548cf05e78b4161169a551f8aa.png)'
- en: Photo by [Choong Deng Xiang](https://unsplash.com/@dengxiangs?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Choong Deng Xiang](https://unsplash.com/@dengxiangs?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Get started using LangChain with Python to leverage LLMs
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用 LangChain 和 Python 利用 LLM
- en: '[](https://medium.com/@marcellopoliti?source=post_page-----d2f7a1d1ad1a--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----d2f7a1d1ad1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d2f7a1d1ad1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d2f7a1d1ad1a--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----d2f7a1d1ad1a--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcellopoliti?source=post_page-----d2f7a1d1ad1a--------------------------------)[![Marcello
    Politi](../Images/484e44571bd2e75acfe5fef3146ab3c2.png)](https://medium.com/@marcellopoliti?source=post_page-----d2f7a1d1ad1a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d2f7a1d1ad1a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d2f7a1d1ad1a--------------------------------)
    [Marcello Politi](https://medium.com/@marcellopoliti?source=post_page-----d2f7a1d1ad1a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d2f7a1d1ad1a--------------------------------)
    ·12 min read·Apr 26, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d2f7a1d1ad1a--------------------------------)
    ·阅读时间 12 分钟·2023年4月26日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '**LangChain is a framework that enables quick and easy development of applications
    that make use of Large Language Models**, for example, GPT-3.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**LangChain 是一个框架，使得利用大型语言模型（如 GPT-3）快速而轻松地开发应用程序成为可能**。'
- en: The framework, however, introduces additional possibilities, for example, the
    one of easily using external data sources, such as Wikipedia, to amplify the capabilities
    provided by the model. I am sure that you have all probably tried to use Chat-GPT
    and find that it fails to answer about events that occurred beyond a certain date.
    In this case, a search on Wikipedia could help GPT to answer more questions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个框架引入了额外的可能性，例如，轻松使用外部数据源，如维基百科，以增强模型提供的能力。我相信你们可能都尝试过使用 Chat-GPT，并发现它无法回答某个日期之后发生的事件。在这种情况下，维基百科的搜索可以帮助
    GPT 回答更多问题。
- en: LangChain Structure
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain 结构
- en: The framework is organized into six modules each module allows you to manage
    a different aspect of the interaction with the LLM. Let’s see what the modules
    are.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架分为六个模块，每个模块允许你管理与 LLM 交互的不同方面。让我们看看这些模块是什么。
- en: '[**Models**](https://python.langchain.com/en/latest/modules/models.html): Allows
    you to instantiate and use different models.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**模型**](https://python.langchain.com/en/latest/modules/models.html)：允许你实例化和使用不同的模型。'
- en: '[**Prompts**](https://python.langchain.com/en/latest/modules/prompts.html):
    The prompt is how we interact with the model to try to obtain an output from it.
    By now knowing how to write an effective prompt is of critical importance. This
    framework module allows us to better manage prompts. For example, by creating
    templates that we can reuse.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**提示**](https://python.langchain.com/en/latest/modules/prompts.html)：提示是我们与模型互动以尝试获得输出的方式。现在知道如何编写有效的提示至关重要。这个框架模块允许我们更好地管理提示。例如，通过创建可以重用的模板。'
- en: '[**Indexes**](https://python.langchain.com/en/latest/modules/indexes.html):
    The best models are often those that are combined with some of your textual data,
    in order to add context or explain something to the model. This module helps us
    do just that.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**索引**](https://python.langchain.com/en/latest/modules/indexes.html)：最好的模型通常是那些与一些文本数据相结合的模型，以便为模型添加上下文或解释某些内容。这个模块帮助我们做到这一点。'
- en: '[**Chains**](https://python.langchain.com/en/latest/modules/chains.html): Many
    times to solve tasks a single API call to an LLM is not enough. This module allows
    other tools to be integrated. For example, one call can be a composed chain with
    the purpose of getting information from Wikipedia and then giving this information
    as input to the model. This module allows multiple tools to be concatenated in
    order to solve complex tasks.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**链**](https://python.langchain.com/en/latest/modules/chains.html)：很多时候，单次调用
    LLM API 是不够的。该模块允许整合其他工具。例如，一次调用可以是一个复合链，其目的是从维基百科获取信息，然后将这些信息作为输入提供给模型。这个模块允许将多个工具串联起来，以解决复杂的任务。'
- en: '[**Memory**](https://python.langchain.com/en/latest/modules/memory.html): This
    module allows us to create a persisting state between calls of a model. Being
    able to use a model that remembers what has been said in the past will surely
    improve our application.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**记忆**](https://python.langchain.com/en/latest/modules/memory.html)：该模块允许我们在模型调用之间创建持久状态。能够使用一个记住过去所说内容的模型，无疑会提高我们的应用程序的效果。'
- en: '[**Agents**](https://python.langchain.com/en/latest/modules/agents.html): An
    agent is an LLM that makes a decision, takes an action, makes an observation about
    what it has done, and continues in this manner until it can complete its task.
    This module provides a set of agents that can be used.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**代理**](https://python.langchain.com/en/latest/modules/agents.html)：代理是一个
    LLM，它做出决策、采取行动、对自己所做的事情做出观察，并以这种方式继续，直到完成任务。该模块提供了一组可以使用的代理。'
- en: Now let’s go into a little more detail and see how to implement code by taking
    advantage of the different modules.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们更详细地了解一下如何通过利用不同的模块来实现代码。
- en: Models
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: '*Models* allows the use of three different types of language-models, which
    are:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型* 允许使用三种不同类型的语言模型，它们是：'
- en: '**Large Language Models (LLMs):** these foundational machine learning models
    that are able to understand natural language. These accept strings in input and
    generate strings in output.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大型语言模型（LLMs）：** 这些是能够理解自然语言的基础机器学习模型。这些模型接受字符串作为输入，并生成字符串作为输出。'
- en: '**Chat Models:** models powered by LLM but are specialized to chat with the
    user. You can read more [here](https://medium.com/aiguys/reinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58).'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聊天模型：** 这些模型由 LLM 提供支持，但专门用于与用户聊天。你可以在[这里](https://medium.com/aiguys/reinforcement-learning-from-human-feedback-instructgpt-and-chatgpt-693d00cb9c58)阅读更多信息。'
- en: '**Text Embedding Models:** these models are used to project textual data into
    a geometric space. These models take text as input and return a list of numbers,
    the embedding of the text.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本嵌入模型：** 这些模型用于将文本数据投影到几何空间中。这些模型将文本作为输入，并返回一个数字列表，即文本的嵌入。'
- en: '![](../Images/81937b2be62eb65b9c3931398deda8af.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81937b2be62eb65b9c3931398deda8af.png)'
- en: Open AI API Key
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Open AI API 密钥
- en: Let’s start using this module. First, we install and import the libraries. To
    use this library you will need an API KEY from the open AI site.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始使用这个模块。首先，我们需要安装并导入库。要使用这个库，你需要一个来自 Open AI 网站的 API 密钥。
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we are ready to instantiate a LLM model.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备实例化一个 LLM 模型。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '***My Output****:* *A young woman went to a rave she had never heard of. She
    was the only person there with a light in the dark, and the only one who could
    see the good in people. She drank and danced and did anything to make it so. After
    hour after hour of dancing and drinkin'', she got to know one of the people in
    the party. He was a bit of a looking man, with a moustache and a goatee. She said,
    "Hi, I''m the only person there with a light in the dark." He said, "Hi, I''m
    the only person there with a light in the dark.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '***我的输出****:* *一个年轻的女人去了一个她从未听说过的狂欢派对。她是那里唯一一个在黑暗中带有光亮的人，也是唯一一个能够看到人们美好的一面的人。她喝酒、跳舞，做了所有可能的事情来让这一切发生。在几个小时的舞蹈和饮酒之后，她认识了派对上的一个人。他是一个有些吸引人的男人，留着胡须和山羊胡。她说：“嗨，我是那里唯一一个在黑暗中带有光亮的人。”他说：“嗨，我是那里唯一一个在黑暗中带有光亮的人。”*'
- en: With the generate() method you can also feed a list of input and receive multiple
    answers, let’s see how.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 generate() 方法，你还可以输入一个列表并接收多个答案，我们来看看怎么做。
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/2a2fbc6563852fd6091ef5140276f8b6.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a2fbc6563852fd6091ef5140276f8b6.png)'
- en: llm.generate output
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: llm.generate 输出
- en: You can also extract some additional information about the results of the large
    language model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以提取有关大型语言模型结果的一些额外信息。
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '***My Output:*** *{‘token_usage’: {‘completion_tokens’: 527, ‘total_tokens’:
    544, ‘prompt_tokens’: 17}, ‘model_name’: ‘text-ada-001’}*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '***我的输出：*** *{‘token_usage’: {‘completion_tokens’: 527, ‘total_tokens’: 544,
    ‘prompt_tokens’: 17}, ‘model_name’: ‘text-ada-001’}*'
- en: LLMs are not able to understand input texts that are too long. In particular,
    text that contains too many tokens (think about the syllables of words if you
    don’t know what tokens are). Before passing the string into the model you can
    estimate the number of tokens with a simple method.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 无法理解过长的输入文本。特别是，包含太多标记的文本（如果你不知道标记是什么，可以考虑单词的音节）。在将字符串传递给模型之前，你可以使用简单的方法估计标记的数量。
- en: In order to do this you need to install the [tiktoken](https://github.com/openai/tiktoken)
    library.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，你需要安装[tiktoken](https://github.com/openai/tiktoken)库。
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Prompts
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示
- en: Prompting is the new way of programming NLP models. Creating a good prompt though
    is not trivial. Asking the same thing in a different way can lead to a different
    result that is more or less accurate. The prompt can also change depending on
    the use case you are facing. Let’s see how this module can help us create a good
    prompt.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是编程NLP模型的新方式。然而，创建一个好的提示并非易事。以不同的方式提问可能会导致不同的结果，这些结果可能更准确也可能不准确。提示也可以根据你所面对的使用案例而有所不同。让我们看看这个模块如何帮助我们创建一个好的提示。
- en: Prompt Template
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示模板
- en: As the name implies, the prompt template allows us to create templates that
    we can reuse to ask things of our model. The template will contain variables that
    will be the only thing that the user will change from time to time to adapt the
    prompt to its particular use case.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如名称所示，提示模板允许我们创建可以重复使用的模板，以便向我们的模型提出问题。模板将包含变量，这些变量是用户会不时更改的唯一内容，以使提示适应其特定的使用案例。
- en: Let us now see how they can be used.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看它们如何被使用。
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now we can replace the variable ‘product’ within the prompt with whatever string
    we want. This way we can customize the prompt any way we like.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以用我们想要的任何字符串替换提示中的变量‘product’。这样我们就可以根据自己的需要自定义提示。
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '***My Outupt:*** *I want you to act as businessman. You have few passions in
    your life which are:- Money- Data- Basketball. I want to write a Medium Blog post
    about how to make a bucnh of money. What is a good for a title of such post?*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '***我的输出：*** *我希望你充当商人。你生活中有几个热情所在：- 钱- 数据- 篮球。我想写一篇关于如何赚一大笔钱的Medium博客文章。这样的文章标题应该是什么？*'
- en: There are templates that have already been written and you can simply import
    them. To find out what they are you can look at the documentation. Let’s try to
    import one now.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有一些模板被编写好，你可以直接导入它们。要了解这些模板是什么，你可以查看文档。我们现在来尝试导入一个。
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '***My Outupt:*** *PromptTemplate(input_variables=[‘history’, ‘input’], output_parser=None,
    partial_variables={}, template=’The following is a friendly conversation between
    a human and an AI. The AI is talkative and provides lots of specific details from
    its context. If the AI does not know the answer to a question, it truthfully says
    it does not know.\n\nCurrent conversation:\n{history}\nHuman: {input}\nAI:’, template_format=’f-string’,
    validate_template=True)*'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '***我的输出：*** *PromptTemplate(input_variables=[‘history’, ‘input’], output_parser=None,
    partial_variables={}, template=’以下是人类和AI之间的友好对话。AI很健谈，并从其上下文中提供了许多具体细节。如果AI不知道问题的答案，它会如实地说不知道。\n\n当前对话：\n{history}\n人类：{input}\nAI：’,
    template_format=’f-string’, validate_template=True)*'
- en: In this template, we have multiple variables that we can fill in. One of them
    is *history*. We need the history to tell the template about something that happened
    previously so that it has more context. If we want to request the output of the
    model from this template, it is very simple.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模板中，我们有多个可以填写的变量。其中之一是*history*。我们需要历史记录来告诉模板一些先前发生的事情，以便它有更多的上下文。如果我们想从这个模板中请求模型的输出，这非常简单。
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Few shot examples
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 少量示例
- en: Sometimes it happens that we want to question the Machine Learning model about
    things that are particularly tricky. One way to get a more accurate answer, in
    this case, is to show the model similar examples of the correct answer and then
    ask it our question. LangChain provides a method for saving templates that are
    designed specifically to save these examples. Let’s see how to do this.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候我们想向机器学习模型询问特别棘手的事情。此时，获得更准确回答的一种方法是向模型展示正确答案的类似示例，然后提出我们的问题。LangChain 提供了一种保存专门用于保存这些示例的模板的方法。让我们看看如何做到这一点。
- en: 'First of all, let’s create examples. In case I want to create the superlatives
    of the words: tall -> tallest.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一些示例。如果我想创建单词的最高级：tall -> tallest。
- en: '[PRE13]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now we create the template as done before by including two variables, one for
    the base word and one for the superlative.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们创建模板，如之前所做的那样，包含两个变量，一个用于基本词，一个用于最高级词。
- en: '[PRE14]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now we combine everything with the FewShotPromptTemplate class that takes as
    input the examples, the template, the prefix which is usually some instruction
    we want to give to the template, and a suffix which is the form of the template
    output.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将一切结合起来，使用FewShotPromptTemplate类，它接受示例、模板、前缀（通常是我们希望给模板的指令）和一个后缀（即模板输出的形式）作为输入。
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '***My Output:*** *Give the superlative of every input Word: cool Superlative:
    coolest Word: tall Superlative: tallest Word: big Superlative:*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '***我的输出：*** *给出每个输入单词的最高级：cool 最高级：coolest 单词：tall 最高级：tallest 单词：big 最高级：*'
- en: Now you can feed the model and receive the actual output.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以输入模型并获得实际输出。
- en: '[PRE17]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Indexes
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引
- en: This module is the one that allows us to interact with external documents that
    we want to feed to the model. This module is based on the concept of Retriever.
    In fact, the most common thing we want to do with this module is to go and fetch
    the document that most answers our query. Thus an information retrieval system.
    Let’s see what the Retriever interface looks like to understand it better. ( For
    those who don’t already know, an interface is a class that cannot be instantiated,
    if you want to learn more you can read my articles on [design patterns](https://medium.com/towards-data-science/design-patterns-with-python-for-machine-learning-engineers-observer-23cde7ecb2ed)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模块允许我们与外部文档交互，我们想要将其提供给模型。这个模块基于Retriever的概念。实际上，我们最常做的就是去获取最能回答我们查询的文档。因此，这是一个信息检索系统。让我们看看Retriever接口的样子，以便更好地理解它。（对于那些还不知道的人，接口是一个不能实例化的类，如果你想了解更多，你可以阅读我关于[设计模式](https://medium.com/towards-data-science/design-patterns-with-python-for-machine-learning-engineers-observer-23cde7ecb2ed)的文章。）
- en: '[PRE18]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The *get_relevant_documents* method is very simple, you just need to know how
    to read English to understand what it does. The string can be changed to your
    liking, so if you want to modify or implement a custom Retriever it is nothing
    too complicated.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*get_relevant_documents*方法非常简单，你只需了解如何阅读英语即可理解它的作用。字符串可以根据你的喜好进行更改，所以如果你想修改或实现一个自定义的Retriever，也没有什么复杂的。'
- en: Let’s look at a practical example now. We want to create a question-answering
    application about a specific document. That is, the model needs to be able to
    answer questions of mine about a specific document.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一个实际的例子。我们想要创建一个关于特定文档的问答应用程序。也就是说，模型需要能够回答我关于特定文档的问题。
- en: We first need to install *Chroma* which allows us to work with *Vectorstores*,
    we’ll see later what it is for.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要安装*Chroma*，它允许我们与*Vectorstores*一起工作，我们稍后会看到它的用途。
- en: '[PRE19]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Let’s import some classes we will need.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们导入一些我们需要的类。
- en: '[PRE20]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now let’s download a txt document from the web.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们从网络上下载一个txt文档。
- en: '[PRE21]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Let’s load the document with the TextLoader.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用TextLoader加载文档。
- en: '[PRE22]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The *Retriever* always relies on what is called *Vectorstore* retriever. So
    we can instantiate one *Vectorstore retriever* and pass to it our text loader.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*Retriever* 总是依赖于所谓的*Vectorstore*检索器。因此，我们可以实例化一个*Vectorstore retriever*并将我们的文本加载器传递给它。'
- en: '[PRE23]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now that we finally have an index, we can ask questions about the data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们终于有了索引，我们可以对数据提问了。
- en: '[PRE24]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '***My Output:*** *Ohio Senator Sherrod Brown said, “It’s time to bury the label
    ‘Rust Belt.’”*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '***我的输出：*** *俄亥俄州参议员谢罗德·布朗说，“是时候埋葬‘铁锈带’这个标签了。”*'
- en: Chains
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 链
- en: Chains allow us to create more complicated applications. **Often simply using
    an LLM is not enough**, we want to do more. For example, we want to first create
    a template and then give the compiled template as input to the LLM, this can be
    done simply with a chain. It’s easy for me to think of chains as the Pipeline
    that you use in scikit-learn, for example.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 链允许我们创建更复杂的应用程序。**仅仅使用LLM通常是不够的**，我们想要做得更多。例如，我们首先创建一个模板，然后将编译好的模板作为输入提供给LLM，这可以通过链简单实现。对我来说，可以将链想象成你在scikit-learn中使用的Pipeline。
- en: The LLMChain is a chain that does just that, takes an input, formats it within
    a template, and then passes it as input to a template.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: LLMChain就是一个这样的链，它接受输入，将其格式化到模板中，然后将其作为输入传递给模板。
- en: First, let’s create a simple template.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个简单的模板。
- en: '[PRE25]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Now we create a chain by specifying the template and model to be used.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们通过指定要使用的模板和模型来创建一个链。
- en: '[PRE26]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: You can also create a custom chain but I’ll write a more detailed article about
    it.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以创建一个自定义链，但我会写一篇更详细的文章来讲解。
- en: Memory
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存
- en: Every time we interact with a model, it will give us an answer that won’t depend
    on the context because it doesn’t remember past events. It’s kind of like every
    time we are talking to a new model. **In applications we usually want the model
    to have some kind of memory so that it learns to reply to us by improving as it
    goes along depending on what we said before** especially if we are developing
    chatbots. That’s what this module is for.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们与模型互动时，它都会给我们一个答案，这个答案不会依赖于上下文，因为它不会记住过去的事件。这就像每次我们都是在与一个新的模型交谈一样。**在应用程序中，我们通常希望模型具备某种记忆，以便它通过根据之前我们说的话不断改进来学习如何回复我们**，特别是当我们在开发聊天机器人时。这就是这个模块的用途。
- en: Memory can be implemented in a variety of ways. For example, we can take the
    previous N messages, and feed them to the model as a single string or as a string
    sequence for instance. Now let’s look at the simplest type of memory we can implement
    called a buffer.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 内存可以通过多种方式实现。例如，我们可以将之前的N条消息作为一个字符串或字符串序列提供给模型。现在让我们看看我们可以实现的最简单类型的内存，称为缓冲区。
- en: We can use a ChatMessageHistory class that allows us to easily save all the
    messages sent to the model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一个 ChatMessageHistory 类，它允许我们轻松保存所有发送给模型的消息。
- en: '[PRE27]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Now we can retrieve the messages easily.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以轻松检索消息。
- en: '[PRE29]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Now that we understand the concept, we can use a wrapper of the class we just
    used called ConversationBufferMemory that allows us to actually use the message
    history.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了这个概念，我们可以使用我们刚刚使用的类的包装器，称为 ConversationBufferMemory，它允许我们实际使用消息历史记录。
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Let’s see finally how to use this feature in a chain for a chat.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们来看看如何在对话链中使用这个功能。
- en: So let’s start by having a conversation with the model.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们开始与模型进行对话。
- en: '[PRE33]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '![](../Images/7836436ee44205cce342194f148231e1.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7836436ee44205cce342194f148231e1.png)'
- en: '[PRE35]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '![](../Images/a108320e04ad98ef250e62891677400d.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a108320e04ad98ef250e62891677400d.png)'
- en: '[PRE36]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![](../Images/52ae722345c2a49f47f024a439091eb0.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52ae722345c2a49f47f024a439091eb0.png)'
- en: You can retrieve the old messages by accessing the memory.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过访问内存来检索旧消息。
- en: '[PRE37]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Now you can save your messages to load them again and feed the model when you
    want to start a conversation from a certain point.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以保存你的消息，以便在你想从某个特定点开始对话时重新加载它们并提供给模型。
- en: Agents
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理
- en: The kind of chains we have seen, follow predetermined steps like a pipeline.
    But we often don’t know what steps the model has to take to answer a given question,
    because it also depends on what the user answers it from time to time.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到的那种链条，遵循像流水线一样的预定步骤。但是我们通常不知道模型回答特定问题时需要采取哪些步骤，因为这也取决于用户不时给出的回答。
- en: We can have a model use various tools, to improve its answers. A common example
    is to first go and read some information on Wikipedia and then answer a particular
    question.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以让模型使用各种工具来改进其回答。一个常见的例子是首先去维基百科上阅读一些信息，然后回答一个特定的问题。
- en: '[PRE38]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We are going to use two tools in particular SERPAPI which allows the model to
    do browser searches and take information, llm-math to improve its math skills.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两个特定的工具，SERPAPI，它允许模型进行浏览器搜索并获取信息，以及llm-math，以提高其数学技能。
- en: To install SERPAPI you must register on the site and copy the API Token.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装SERPAPI，你必须在网站上注册并复制API Token。
- en: 'This is the website: [https://serpapi.com/](https://serpapi.com/)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这是网站：[https://serpapi.com/](https://serpapi.com/)
- en: Once done we install the library and set the token as an environment variable.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们安装库并将令牌设置为环境变量。
- en: '[PRE39]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now we are ready to instantiate our agent with the tools it will need to use.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好使用它所需的工具来实例化我们的代理了。
- en: 'We, therefore, need 3 things:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要3样东西：
- en: 'LLM: the large language model we want to use'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM：我们想要使用的大型语言模型
- en: 'Tools: we want to use to improve the basic LLM'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具：我们希望用来改进基本LLM的工具
- en: 'Agent: handles the interaction between the LLM and Tools'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理：处理LLM与工具之间的互动
- en: '[PRE40]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Now we can ask our model a question, relying on the fact that it is going to
    use the various tools available to it to answer us.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以向模型提问，依靠它将使用各种可用的工具来回答我们。
- en: '[PRE43]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Final Thoughts
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we introduced LangChain with its various modules. Each module
    is useful for improving the capabilities of large language models and is essential
    for developing applications based on these models. Be careful because the model
    I used in this article is not among the best so the answers may not be optimal,
    plus the answers you get may be very different from mine. The purpose though was
    just to get familiar with this library. I am curious to see all the applications
    that will be developed in the future based on the new Large Language Models. Follow
    me to read my upcoming in-depth articles on these topics! [😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了LangChain及其各种模块。每个模块都对提高大型语言模型的能力有用，并且对于基于这些模型开发应用程序至关重要。请注意，因为我在本文中使用的模型不是最好的，所以回答可能不是最优的，而且你得到的回答可能与我的差异很大。不过，目的是为了熟悉这个库。我很期待看到未来基于新大型语言模型开发的所有应用程序。关注我，阅读我即将发布的关于这些话题的深入文章！
    [😉](https://emojipedia.org/it/apple/ios-15.4/faccina-che-fa-l-occhiolino/)
- en: The End
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束
- en: '*Marcello Politi*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*Marcello Politi*'
- en: '[Linkedin](https://www.linkedin.com/in/marcello-politi/), [Twitter](https://twitter.com/_March08_),
    [Website](https://marcello-politi.super.site/)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[Linkedin](https://www.linkedin.com/in/marcello-politi/)，[Twitter](https://twitter.com/_March08_)，
    [Website](https://marcello-politi.super.site/)'
