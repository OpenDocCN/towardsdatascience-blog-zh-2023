- en: 'Revolutionizing Language Barriers: Mastering Multilingual Audio Transcription
    and Semantic Search'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语言障碍的革命：掌握多语言音频转录和语义搜索
- en: 原文：[https://towardsdatascience.com/revolutionizing-language-barriers-mastering-multilingual-audio-transcription-and-semantic-search-5540f038778d](https://towardsdatascience.com/revolutionizing-language-barriers-mastering-multilingual-audio-transcription-and-semantic-search-5540f038778d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/revolutionizing-language-barriers-mastering-multilingual-audio-transcription-and-semantic-search-5540f038778d](https://towardsdatascience.com/revolutionizing-language-barriers-mastering-multilingual-audio-transcription-and-semantic-search-5540f038778d)
- en: Unlock the potential of cross-language information accessibility with advanced
    transcription and semantic search technologies
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用先进的转录和语义搜索技术，解锁跨语言信息访问的潜力
- en: '[](https://medium.com/@luisroque?source=post_page-----5540f038778d--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----5540f038778d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5540f038778d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5540f038778d--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----5540f038778d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisroque?source=post_page-----5540f038778d--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----5540f038778d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5540f038778d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5540f038778d--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----5540f038778d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5540f038778d--------------------------------)
    ·12 min read·Dec 13, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5540f038778d--------------------------------)
    ·12 min 阅读·2023年12月13日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*This post was co-authored with Rafael Guedes.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章由 Rafael Guedes 共同撰写。*'
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In our ever-connected world, where information has no borders, the ability to
    make it accessible to everyone, regardless of their native language or their capacity
    to learn a new language, is very relevant. Whether you are a content creator or
    lead a worldwide organization, being able to quickly and effortlessly help your
    followers/customers search for specific information in several languages has several
    benefits. For example, it can support customers with the same questions already
    answered in a different language.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们这个互联的世界中，信息没有边界，使其对每个人都可访问，不论他们的母语是什么或他们是否有能力学习新语言，这一能力变得非常重要。无论你是内容创作者还是全球组织的负责人，能够快速而轻松地帮助你的追随者/客户在多种语言中搜索特定信息都有很多好处。例如，它可以帮助客户找到用不同语言已经回答过的相同问题。
- en: Consider a different use case where you frequently have to attend company meetings.
    Often, you might be unable to participate, and many topics discussed may not be
    relevant to you. Wouldn’t it be convenient if you could search for the topics
    that interest you and receive a summary, including the start and end times of
    the relevant discussions? This way, instead of spending an hour in a meeting,
    you could spend just ten to fifteen minutes gathering the necessary information,
    significantly boosting your productivity. Additionally, you might have meetings
    recorded in Portuguese and English. Nevertheless, you are interested in conducting
    your search in English.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个不同的使用场景，你经常需要参加公司会议。通常，你可能无法参与，而讨论的许多话题可能与你无关。如果你能够搜索感兴趣的主题并收到总结，包括相关讨论的开始和结束时间，这将多么方便？这样，你可以用十到十五分钟的时间获取所需的信息，而不是花费一个小时在会议上，这将显著提高你的生产力。此外，你可能有用葡萄牙语和英语录制的会议。然而，你仍然希望用英语进行搜索。
- en: In this article, we will show you how to implement multilingual audio transcription
    and multilingual semantic search so that you can implement it for your use cases.
    For the multilingual audio transcription, we will explain how Whisper and WhisperX
    work, their limitations, and how to use them in Python.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将展示如何实现多语言音频转录和多语言语义搜索，以便你可以将其应用于你的使用场景。对于多语言音频转录，我们将解释 Whisper 和 WhisperX
    的工作原理、它们的局限性以及如何在 Python 中使用它们。
- en: Then, we introduce how multilingual semantic search models are trained and why
    you can get the same information from a vector database regardless of the language
    you queried with. We also provide a detailed implementation of semantic search
    resorting to Postgres and PGVector.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们介绍多语言语义搜索模型如何训练，以及为何您可以从向量数据库中获取相同的信息，无论您用什么语言查询。我们还提供了使用 Postgres 和 PGVector
    进行语义搜索的详细实现。
- en: Finally, we show the results of the above on two use cases. We use two videos,
    one in Portuguese and the other in English, and we query them with the same question
    in Portuguese and English to check if we obtain the same answer.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们展示了上述结果在两个用例中的表现。我们使用了两个视频，一个是葡萄牙语的，另一个是英语的，并用葡萄牙语和英语提出相同的问题，以检查是否能得到相同的答案。
- en: '![](../Images/8ad29296ec3684072a96bc4d0a36c724.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ad29296ec3684072a96bc4d0a36c724.png)'
- en: 'Figure 1: Multilingual audio transcription and multilingual semantic search
    have endless use cases to be explored ([i](https://unsplash.com/photos/black-and-gray-condenser-microphone-pfhld_5yQrs)mage
    by author using DALLE)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 多语言音频转录和多语言语义搜索有无尽的应用场景待探索（[i](https://unsplash.com/photos/black-and-gray-condenser-microphone-pfhld_5yQrs)图像由作者使用
    DALLE 制作）'
- en: As always, the code is available on our [GitHub](https://github.com/zaai-ai/large-language-models).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，代码可以在我们的 [GitHub](https://github.com/zaai-ai/large-language-models) 上找到。
- en: 'WhisperX: A robust architecture for audio transcription'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WhisperX：一个强大的音频转录架构
- en: WhisperX [1] is the evolved form of Whisper [2], a model developed by OpenAI.
    But what are the differences between them?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: WhisperX [1] 是 Whisper [2] 的进化形式，Whisper 是由 OpenAI 开发的模型。但它们之间有什么区别呢？
- en: Whisper and WhisperX are speech recognition models capable of multilingual speech
    recognition, speech translation, spoken language identification, and voice activity
    detection. They rely on a transformer sequence-to-sequence architecture to represent
    various speech-processing tasks as a sequence of tokens to be predicted by the
    decoder.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Whisper 和 WhisperX 是能够进行多语言语音识别、语音翻译、口语语言识别和语音活动检测的语音识别模型。它们依赖于转换器序列到序列架构，将各种语音处理任务表示为一系列由解码器预测的标记。
- en: '![](../Images/6f333564a963146632b3ff13091c5b80.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f333564a963146632b3ff13091c5b80.png)'
- en: 'Figure 2: Whisper Architecture ([i](https://arxiv.org/pdf/2303.00747.pdf)mage
    by author)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: Whisper 架构（[i](https://arxiv.org/pdf/2303.00747.pdf)图像由作者提供）'
- en: Despite the excellent performance of Whisper in different domains and languages,
    it needs to improve when it comes to long audio transcriptions. The main reason
    for this problem is due to the sliding window approach used during training. It
    often results in drifting and hallucinations. It also presents limitations when
    aligning the transcription with the audio timestamps.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Whisper 在不同领域和语言中表现出色，但在长音频转录方面还需要改进。这个问题的主要原因是训练期间使用的滑动窗口方法。这通常导致漂移和幻觉。它在将转录与音频时间戳对齐时也存在限制。
- en: 'WhisperX comes along to solve these problems:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: WhisperX 来解决这些问题：
- en: '**Drifting and Hallucinations** are solved using Voice Activity Detection (VAD)
    and a custom approach to cut and merge the audio chunks. VAD detects the presence
    or absence of human voice and splits the input audio into segments according to
    that classification. After that, it cuts and merges the segments with human voice
    into windows of 30 seconds. It tries to define the boundaries in regions with
    a low probability of speech. The segments are cut in windows of 30 seconds to
    match the duration of the segments which Whisper was trained with.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**漂移和幻觉**是通过语音活动检测 (VAD) 和自定义的方法来解决的，用于剪切和合并音频片段。VAD 检测人声的存在或缺失，并根据该分类将输入音频分成段。之后，它将带有人声的片段剪切并合并为
    30 秒的窗口。它尝试在语音概率较低的区域定义边界。这些片段被剪切成 30 秒的窗口，以匹配 Whisper 训练时使用的片段持续时间。'
- en: '**Transcription Alignment** is solved using Forced Alignment, the last layer
    of the architecture. It uses a phoneme recognition model to identify the smallest
    unit of speech that distinguishes one word from the next, e.g., the element **‘t’**
    in **‘nut’.** It then obtains the start and end times for each word by taking
    the start and end times of the first and last phonemes of the same word for a
    more reliable alignment.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**转录对齐**是通过强制对齐来解决的，这是架构的最后一层。它使用音素识别模型来识别区分一个单词和下一个单词的最小语音单元，例如，**‘t’** 在
    **‘nut’** 中的元素。然后，通过获取同一单词中第一个和最后一个音素的开始和结束时间来获得每个单词的开始和结束时间，以获得更可靠的对齐。'
- en: '![](../Images/b5f4df5be91fe105a84d7660812568fa.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5f4df5be91fe105a84d7660812568fa.png)'
- en: 'Figure 3: WhisperX Architecture ([i](https://arxiv.org/pdf/2303.00747.pdf)mage
    by author)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：WhisperX 架构 ([i](https://arxiv.org/pdf/2303.00747.pdf) 图片由作者提供)
- en: Whisper and WhisperX in practice
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Whisper 和 WhisperX 的实际应用
- en: We can use Whisper or WhisperX to transcribe audio with just a few lines of
    code. We need to install Whisper and WhisperX from `git+https://github.com/openai/whisper.git`
    and `git+https://github.com/m-bain/whisperx.git`, respectively.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Whisper 或 WhisperX 通过几行代码转录音频。我们需要从 `git+https://github.com/openai/whisper.git`
    和 `git+https://github.com/m-bain/whisperx.git` 安装 Whisper 和 WhisperX。
- en: 'Once the installation is done, we start by importing Whisper or WhisperX. Then,
    we load the model and, finally, we transcribe the audio file in `.wav` format.
    The result will be a dictionary with three keys:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们首先导入 Whisper 或 WhisperX。然后，我们加载模型，最后，我们转录 `.wav` 格式的音频文件。结果将是一个包含三个键的字典：
- en: '*‘text’* is a string with the whole transcription.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*‘text’* 是一个包含完整转录文本的字符串。'
- en: '*‘segments’* is a list of segments of text with the start and end time and
    some other metadata.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*‘segments’* 是一个文本片段的列表，包含开始和结束时间以及其他一些元数据。'
- en: '*‘language’* is a string with the language of the audio.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*‘language’* 是一个表示音频语言的字符串。'
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As mentioned before, Whisper has some limitations when aligning the transcription
    with the audio timestamps. Therefore, we use WhisperX to solve that problem.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Whisper 在将转录与音频时间戳对齐时存在一些局限性。因此，我们使用 WhisperX 来解决这个问题。
- en: We load the alignment model, and based on the result from Whisper or WhisperX,
    we correct its alignment.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们加载对齐模型，并根据 Whisper 或 WhisperX 的结果，修正其对齐。
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Semantic Search: A multilingual approach'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语义搜索：一种多语言方法
- en: Semantic search is a search engine technology that matches the meaning of a
    query, as opposed to traditional search approaches that match the keywords of
    a query.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 语义搜索是一种搜索引擎技术，它匹配查询的含义，而不是传统搜索方法匹配查询的关键词。
- en: Semantic search is made effective through the use of Transformers, which are
    crucial for their ability to convert documents in free-text form into numerical
    representations. These representations, called embeddings, are essentially vectors
    stored in vector databases like [PGVector](https://github.com/pgvector/pgvector).
    This process enables semantic search to match queries based on meaning or intent,
    significantly enhancing the accuracy and relevance of search results.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 语义搜索通过使用 Transformers 来实现有效性，Transformers 对于将自由文本形式的文档转换为数值表示至关重要。这些表示，称为嵌入，实际上是存储在像
    [PGVector](https://github.com/pgvector/pgvector) 这样的向量数据库中的向量。这个过程使语义搜索能够基于含义或意图匹配查询，从而显著提高搜索结果的准确性和相关性。
- en: '![](../Images/08715c2cd0ebc51429c891dd8a56c12d.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08715c2cd0ebc51429c891dd8a56c12d.png)'
- en: 'Figure 4: Inner workings of semantic search (image by author)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：语义搜索的内部工作原理（图片由作者提供）
- en: When a user submits a query, it is converted into an embedding. This embedding
    is then utilized by the vector database’s built-in retrieval system, typically
    based on the k-nearest neighbor (kNN) algorithm. The system uses this algorithm
    to identify and rank the k most similar documents to the user’s query based on
    their relevance. This process ensures that the results retrieved are closely aligned
    with the user’s search intent.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户提交查询时，它会被转换成一个嵌入。这个嵌入随后被向量数据库的内置检索系统利用，通常基于 k 最近邻（kNN）算法。该系统使用这个算法来识别和排序与用户查询最相关的
    k 个最相似的文档。这个过程确保检索到的结果与用户的搜索意图紧密对齐。
- en: '![](../Images/3cf499f69eda0150993ec3ce8c54c948.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cf499f69eda0150993ec3ce8c54c948.png)'
- en: 'Figure 5: Semantic search embeddings are applied to text, audio, or images.
    Those embeddings can be stored in vector databases powered by kNN to retrieve
    the most relevant documents based on a user’s query. ([i](https://www.elastic.co/what-is/semantic-search)mage
    by author)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：语义搜索嵌入被应用于文本、音频或图像。这些嵌入可以存储在由 kNN 支持的向量数据库中，以根据用户查询检索最相关的文档。 ([i](https://www.elastic.co/what-is/semantic-search)
    图片由作者提供)
- en: Latest advancements in NLP, particularly in semantic search, have made it possible
    to create identical embeddings for the same sentence in different languages [3].
    This brings a huge advantage for organizations that operate worldwide because
    they can quickly and costlessly extend semantic search to a more significant set
    of languages. This is possible with relatively few samples and low hardware requirements,
    as mentioned by the authors of the approach we will follow.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最新的NLP进展，特别是在语义搜索方面，使得在不同语言中为相同句子创建相同的嵌入成为可能 [3]。这对全球运营的组织带来了巨大的优势，因为他们可以快速且低成本地将语义搜索扩展到更多语言。这是可能的，因为所需的样本相对较少，硬件要求较低，正如我们将遵循的方法的作者所提到的。
- en: Expanding monolingual models, typically based on the English language, involves
    using both a **Teacher** and **Student Model**. These models play distinct yet
    complementary roles in adapting language models to handle multiple languages effectively.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展通常基于英语的单语模型涉及使用**教师模型**和**学生模型**。这些模型在使语言模型能够有效处理多种语言方面扮演着不同但互补的角色。
- en: '**Teacher Model:** This model serves as a reference point or a standard. It
    is typically a well-trained, high-performance model in the source language, often
    English. The Teacher Model has a deep understanding of the language and can produce
    high-quality embedding vectors accurately representing the meanings of various
    texts.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**教师模型：** 该模型作为参考点或标准。它通常是一个在源语言（通常是英语）中经过充分训练的高性能模型。教师模型对语言有深刻的理解，能够生成准确代表各种文本含义的高质量嵌入向量。'
- en: '**Student Model:** The Student Model is designed to learn from the Teacher
    Model. Unlike the Teacher Model, which operates solely in the source language,
    the Student Model works with both the source and translated languages. The primary
    goal of the Student Model is to replicate the performance of the Teacher Model
    in the new language context.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**学生模型：** 学生模型旨在从教师模型中学习。与仅在源语言中操作的教师模型不同，学生模型同时处理源语言和翻译语言。学生模型的主要目标是在新语言环境中复制教师模型的性能。'
- en: 'The reason these models are used and why they work effectively lies in their
    training approach:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型的使用及其有效性的原因在于它们的训练方法：
- en: '**Alignment of Embeddings:** The Student Model is trained to minimize the mean-squared
    error between its embeddings and those produced by the Teacher Model. This process
    ensures that the embeddings produced by the Student Model in both the source and
    translated languages closely match those of the Teacher Model.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入对齐：** 学生模型的训练目标是最小化其嵌入与教师模型生成的嵌入之间的均方误差。这个过程确保了学生模型在源语言和翻译语言中生成的嵌入与教师模型的嵌入紧密匹配。'
- en: '**Language Adaptation:** This training approach enables the Student Model to
    adapt to a new language while maintaining the quality and characteristics of the
    original model. By aligning its understanding with the Teacher Model, the Student
    Model can effectively process and understand the translated language.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**语言适应：** 这种训练方法使学生模型能够适应新语言，同时保持原始模型的质量和特征。通过与教师模型的理解对齐，学生模型能够有效处理和理解翻译语言。'
- en: '**Efficient Learning:** The Student Model doesn’t have to learn from scratch.
    By using the already sophisticated understanding of the Teacher Model, the Student
    Model can achieve high performance with potentially less data and training time
    for the new language.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**高效学习：** 学生模型不必从头开始学习。通过利用教师模型已经成熟的理解，学生模型可以在新语言中以潜在更少的数据和训练时间实现高性能。'
- en: '**Consistency Across Languages:** This method ensures consistency in the model’s
    performance across different languages. It is particularly beneficial in maintaining
    the quality of embeddings, which are crucial for tasks like semantic search, natural
    language understanding, and translation.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**跨语言一致性：** 这种方法确保模型在不同语言中的性能一致。它在保持嵌入质量方面特别有利，而嵌入对语义搜索、自然语言理解和翻译等任务至关重要。'
- en: Although several architectures can be used, the authors used Sentence-BERT [4]
    for the Teacher Model and XLM-RoBERTa [5] for the Student Model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以使用几种架构，但作者们为教师模型使用了Sentence-BERT [4]，为学生模型使用了XLM-RoBERTa [5]。
- en: '![](../Images/c85158814192ffdf58f663ea5d43fd33.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c85158814192ffdf58f663ea5d43fd33.png)'
- en: 'Figure 6: Architecture for multilingual embedding creation where given the
    same sentence in two different languages, the student model can produce vectors
    for both languages that are close to the vector produced by the teacher model
    ([source](https://arxiv.org/pdf/2004.09813.pdf))'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：多语言嵌入创建的架构，其中给定两个不同语言的相同句子，学生模型可以生成与教师模型生成的向量相近的两个语言的向量（[来源](https://arxiv.org/pdf/2004.09813.pdf)）
- en: Implementing Multilingual Semantic Search with PGVector
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PGVector实现多语言语义搜索
- en: In this section, we cover the implementation of PGVector on top of Postgres.
    We also deploy a pgAdmin application to query Postgres and check how our embeddings
    are stored.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了在Postgres上实现PGVector的方法。我们还部署了一个pgAdmin应用程序来查询Postgres，并检查我们的嵌入如何存储。
- en: We resort to LangChain to encode the transcription from Whisper or WhisperX,
    insert it into a table in Postgres, and retrieve the documents most similar to
    a user’s query.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们借助LangChain来编码来自Whisper或WhisperX的转录，将其插入Postgres中的一个表，并检索与用户查询最相似的文档。
- en: Since, for our use case, we need to be able to retrieve information regardless
    of the language of the audio or the user’s query, we use `multi-qa-mpnet-base-dot-v1`
    from `sentence-transformers` to encode the transcription. We chose this model
    because it performs best on multilingual semantic searches (you can check the
    models available for multilingual semantic searches [here](https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models)).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在我们的使用案例中，我们需要能够检索信息，而不论音频的语言或用户查询的语言，因此我们使用`sentence-transformers`中的`multi-qa-mpnet-base-dot-v1`来编码转录。我们选择这个模型是因为它在多语言语义搜索中表现最佳（你可以在[这里](https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models)查看可用的多语言语义搜索模型）。
- en: Set up PGVector
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置PGVector
- en: We deploy Postgres powered by PGVector using Docker. We start by defining the
    docker-compose.yml file with two containers, `postgres` and `pgadmin`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Docker部署由PGVector支持的Postgres。我们首先定义docker-compose.yml文件，包含两个容器，`postgres`和`pgadmin`。
- en: '**Postgres:**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**Postgres：**'
- en: 'Image: `ankane/pgvector` allows us to deploy Postgres with PGVector extension.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像：`ankane/pgvector`允许我们部署带有PGVector扩展的Postgres。
- en: 'Ports: 5432'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口：5432
- en: 'Environment: user and password to interact with Postgres and a database to
    store our embeddings.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境：与Postgres交互的用户名和密码，以及一个存储我们嵌入的数据库。
- en: '**pgAdmin:**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**pgAdmin：**'
- en: 'Image: `dpage/pgadmin4`.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像：`dpage/pgadmin4`。
- en: 'Ports: 5050'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端口：5050
- en: 'Environment: email and password for login.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境：登录用的电子邮件和密码。
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once the docker-compose file is defined, we can start our application by running
    `docker-compose up -d` command in the same directory of the docker-compose file.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了docker-compose文件，我们可以通过在docker-compose文件所在的目录中运行`docker-compose up -d`命令来启动我们的应用程序。
- en: 'With our application running, it is time to create a server in pgAdmin so that
    we can query our embeddings and documents. To accomplish that, we must follow
    these steps:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序运行后，是时候在pgAdmin中创建一个服务器，以便我们可以查询我们的嵌入和文档。为此，我们必须按照以下步骤操作：
- en: Open the pgAdmin web interface in a web browser using [http://localhost:5050/](http://localhost:5050/).
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页浏览器中打开pgAdmin的Web界面，访问[http://localhost:5050/](http://localhost:5050/)。
- en: Log in using the email and password we set in the `PGADMIN_DEFAULT_EMAIL` and
    `PGADMIN_DEFAULT_PASSWORD` environment variables in the docker-compose file.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在docker-compose文件中的`PGADMIN_DEFAULT_EMAIL`和`PGADMIN_DEFAULT_PASSWORD`环境变量中设置的电子邮件和密码进行登录。
- en: Right-click on the *Servers* node, and select *Register →* *Server.*
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键点击*服务器*节点，选择*注册 →* *服务器*。
- en: In the *Create — Server* dialog, insert a name for the server in the *Name*
    field.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*创建 — 服务器*对话框中，在*名称*字段中输入服务器名称。
- en: 'In the *Connection* tab, insert the following information:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*连接*选项卡中，插入以下信息：
- en: '*Host name/address:* `postgres`'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*主机名/地址*：`postgres`'
- en: '*Port*: `5432`'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*端口*：`5432`'
- en: '*Maintenance database*: You can use the `postgres` database for this purpose.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*维护数据库*：你可以使用`postgres`数据库来完成这个任务。'
- en: '*Username*: `POSTGRES_USER` environment variable that we set in the docker-compose
    file.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*用户名*：`POSTGRES_USER`环境变量，我们在docker-compose文件中设置了它。'
- en: '*Password*: `POSTGRES_PASSWORD` environment variable that we set in the docker-compose
    file.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*密码*：`POSTGRES_PASSWORD`环境变量，我们在docker-compose文件中设置了它。'
- en: Click the *Save* button to create the server.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击*保存*按钮以创建服务器。
- en: With the server created, let’s populate the recently created database called
    `postgres` with embeddings and documents.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 创建好服务器后，我们来填充刚刚创建的名为`postgres`的数据库中的嵌入和文档。
- en: 'Note: This pgAdmin is optional; you can skip this step if you do not want to
    query the embeddings.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这个pgAdmin是可选的；如果你不想查询嵌入，可以跳过这一步。
- en: Populate Postgres with LangChain
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain 填充 Postgres
- en: Once the database is set and ready to store embeddings, it is time to define
    an encoder. Afterward, we use LangChain to populate and retrieve the most similar
    documents to a user’s query from the database.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据库设置好并准备好存储嵌入，就该定义编码器了。之后，我们使用 LangChain 来填充和检索数据库中与用户查询最相似的文档。
- en: 'As mentioned above, the encoder is multilingual and can be defined as:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，编码器是多语言的，可以定义为：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'LangChain has integration with PGVector. Therefore, to connect LangChain with
    Postgres, we need to define the string connection as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 与 PGVector 集成。因此，要将 LangChain 连接到 Postgres，我们需要将字符串连接定义如下：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that the `COLLECTION_NAME` must be unique because it will be used as a
    key by PGVector to identify the documents to retrieve from Postgres. For our use
    case, we can think of `COLLECTION_NAME` as the meeting ID, allowing us to retrieve
    information from the meeting the user is interested in.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`COLLECTION_NAME` 必须唯一，因为 PGVector 将使用它作为键来识别从 Postgres 检索的文档。对于我们的用例，我们可以将
    `COLLECTION_NAME` 视为会议 ID，这样可以从用户感兴趣的会议中检索信息。
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With the encoder, connection, and collection name defined, we transform the
    transcription from Whisper or WhisperX into Documents (the expected format from
    LangChain). We also create and populate a table with the embeddings.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义编码器、连接和集合名称之后，我们将来自 Whisper 或 WhisperX 的转录内容转换为文档（LangChain 所期望的格式）。我们还创建并填充了一个包含嵌入的表。
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After creating and populating the table, we can query the database and get
    the most similar documents using LangChain:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建并填充表格后，我们可以查询数据库，并使用 LangChain 获取最相似的文档：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Or we can also go to pdAdmin and query Postgres to check how the embeddings
    and the documents look like:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我们也可以去 pdAdmin 并查询 Postgres 以查看嵌入和文档的样子：
- en: '![](../Images/e76dee9ac0a46a220015bd33a2ea1706.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e76dee9ac0a46a220015bd33a2ea1706.png)'
- en: 'Figure 7: Query in pgAdmin to check the embedding vectors and the documents
    (image by author)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：在 pgAdmin 中查询嵌入向量和文档（作者提供的图像）
- en: Does Multilingual Semantic Search work?
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多语言语义搜索有效吗？
- en: We converted two videos of Luis talking about two different subjects into audio.
    In the first, Luis talks about his previous startup in Portuguese; in the second,
    he talks about Probabilistic Deep Learning. We then query both using Portuguese
    and English and compare the retrieved documents.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 Luis 谈论两个不同主题的两个视频转换为音频。在第一个视频中，Luis 用葡萄牙语谈论他的前一家公司；在第二个视频中，他谈论了概率深度学习。然后，我们使用葡萄牙语和英语查询这两个视频，并比较检索到的文档。
- en: For the Portuguese use case, we used the following queries
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于葡萄牙语用例，我们使用了以下查询
- en: 'Portuguese: `marcas e investimentos`'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 葡萄牙语：`marcas e investimentos`
- en: 'English: `brands and investments`'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英语：`brands and investments`
- en: 'As a result, 4 out of the top 4 most relevant documents retrieved were the
    same in both cases:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，前四个最相关的文档在两个案例中都是相同的：
- en: 'start 81.401 — end 85.26: uma marca baseada em Berlim, portanto ao invés de
    esperarmos que esse investimento chegasse,'
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 开始 81.401 — 结束 85.26：一个总部位于柏林的品牌，因此我们没有等待这个投资到来，
- en: 'start 111.902 — end 117.26: para maturar o produto, para investir em tecnologia
    e para investir no business development.'
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 开始 111.902 — 结束 117.26：为了成熟产品、投资技术和进行业务开发。
- en: 'start 88.58 — end 93.039: Estas duas rondas de investimento que nós já fizemos
    com uma capacidade também diferente start'
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 开始 88.58 — 结束 93.039：这两轮投资我们已经做了，能力也有所不同开始
- en: '28.6 — end 32.64: Portanto, damos toda a componente de infraestrutura logística
    que uma marca precisa.'
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 28.6 — 结束 32.64：因此，我们提供了品牌所需的所有物流基础设施组件。
- en: For the English use case, we used the following queries
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于英语用例，我们使用了以下查询
- en: 'Portuguese: `modelos de aprendizagem profunda`'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 葡萄牙语：`modelos de aprendizagem profunda`
- en: 'English: `deep learning models`'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英语：`deep learning models`
- en: We had to retrieve eight documents for the Portuguese query to find the relevant
    documents. This happens because, in Portuguese, we usually do not translate ‘*Deep
    Learning’;* we use the English expression. Thus, the model probably did not have
    enough data to train with.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须检索八个文档以找到相关的文件。这是因为在葡萄牙语中，我们通常不翻译 *Deep Learning*；我们使用英语表达。因此，模型可能没有足够的数据进行训练。
- en: 'start 45.28 — end 51.9: when we are using deep learning models, usually we
    are relying on maximum likelihood estimation'
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 开始 45.28 — 结束 51.9：当我们使用深度学习模型时，我们通常依赖于最大似然估计
- en: On the other hand, the following queries had the same top 4 results
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，以下查询的前 4 个结果相同
- en: 'Portuguese: `distribuição normal`'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 葡萄牙语：`distribuição normal`
- en: 'English: `normal distribution`'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '英文: `normal distribution`'
- en: It shows that for terms often translated, such as ‘*normal distribution’* to
    *‘distribuição normal’,* our approach produces the relevant outputs.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，对于经常翻译的术语，例如‘*normal distribution*’到*‘distribuição normal’*，我们的方法能够产生相关输出。
- en: Conclusion
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Multilingual audio transcription and semantic search are valuable assets to
    build a more connected world. Our examples are just the tip of the iceberg; many
    more technologies can be combined to tackle different use cases.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 多语言音频转录和语义搜索是构建更加互联世界的重要资产。我们的例子只是冰山一角；还有许多技术可以结合使用，以应对不同的应用场景。
- en: Consider a scenario where a Retrieval-Augmented Generation (RAG) system is employed
    for customer support. Usually, in a customer support system, customers ask questions
    in any language. We could encode these questions with a multilingual model and
    use a retriever to pull relevant past responses from customer care experts for
    context. The Large Language Model (LLM) uses this context to generate an answer
    translated into the customer’s language. This system efficiently reduces the workload
    on customer care experts and provides quick, real-time customer support.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一种使用检索增强生成（RAG）系统进行客户支持的场景。通常，在客户支持系统中，客户用任何语言提问。我们可以用多语言模型对这些问题进行编码，并使用检索器从客户服务专家那里提取相关的过往回答作为上下文。大型语言模型（LLM）使用这些上下文生成翻译成客户语言的答案。该系统有效地减少了客户服务专家的工作负担，并提供了快速、实时的客户支持。
- en: While our approach offers extensive possibilities, it is not a one-size-fits-all
    solution. For instance, in our experiments, the retriever failed to semantically
    link ‘Deep Learning’ with its Portuguese equivalent, ‘Aprendizagem Profunda.’
    Overcoming such limitations requires fine-tuning with specific data or implementing
    rule-based mechanisms to improve document retrieval accuracy, especially across
    different languages.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的方法提供了广泛的可能性，但它并不是万能的解决方案。例如，在我们的实验中，检索器未能将“Deep Learning”与其葡萄牙语对应词“Aprendizagem
    Profunda”语义关联起来。克服这些限制需要使用特定数据进行微调或实施基于规则的机制，以提高文档检索的准确性，特别是在不同语言之间。
- en: 'Keep in touch: [LinkedIn](https://www.linkedin.com/in/luisbrasroque/), [X/Twitter](https://x.com/luisbrasroque),
    [Medium](https://medium.com/@luisroque).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '保持联系: [LinkedIn](https://www.linkedin.com/in/luisbrasroque/), [X/Twitter](https://x.com/luisbrasroque),
    [Medium](https://medium.com/@luisroque)。'
- en: References
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman. WhisperX: Time-Accurate
    Speech Transcription of Long-Form Audio. arXiv:2303.00747, 2023'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Max Bain, Jaesung Huh, Tengda Han, Andrew Zisserman. WhisperX: 精确时间语音转录长篇音频。arXiv:2303.00747,
    2023'
- en: '[2] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey,
    Ilya Sutskever. Robust Speech Recognition via Large-Scale Weak Supervision. ********arXiv:2212.04356,
    2022'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey,
    Ilya Sutskever. 通过大规模弱监督的稳健语音识别。********arXiv:2212.04356, 2022'
- en: '[3] Nils Reimers, Iryna Gurevych. Making Monolingual Sentence Embeddings Multilingual
    using Knowledge Distillation. arXiv:2004.09813, 2020.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Nils Reimers, Iryna Gurevych. 通过知识蒸馏将单语句子嵌入转换为多语种。arXiv:2004.09813, 2020。'
- en: '[4] Nils Reimers, Iryna Gurevych. Sentence-BERT: Sentence Embeddings using
    Siamese BERT-Networks. arXiv:1908.10084, 2019.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Nils Reimers, Iryna Gurevych. Sentence-BERT: 使用Siamese BERT网络的句子嵌入。arXiv:1908.10084,
    2019。'
- en: '[5] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
    Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov.
    Unsupervised Cross-lingual Representation Learning at Scale. arXiv:1911.02116,
    2019.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
    Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov.
    大规模无监督跨语言表示学习。arXiv:1911.02116, 2019。'
