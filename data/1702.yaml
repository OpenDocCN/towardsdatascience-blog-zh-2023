- en: Understanding What We Lose
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解我们失去的东西
- en: 原文：[https://towardsdatascience.com/understanding-what-we-lose-b91e114e281b?source=collection_archive---------4-----------------------#2023-05-23](https://towardsdatascience.com/understanding-what-we-lose-b91e114e281b?source=collection_archive---------4-----------------------#2023-05-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/understanding-what-we-lose-b91e114e281b?source=collection_archive---------4-----------------------#2023-05-23](https://towardsdatascience.com/understanding-what-we-lose-b91e114e281b?source=collection_archive---------4-----------------------#2023-05-23)
- en: '**How We Tackle Catastrophic Forgetting in LLMs**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**我们如何应对大型语言模型中的灾难性遗忘**'
- en: '[](https://medium.com/@matt.tengtrakool?source=post_page-----b91e114e281b--------------------------------)[![Matt
    Tengtrakool](../Images/e5ef621ff9132b6c308e28d3ba2c5110.png)](https://medium.com/@matt.tengtrakool?source=post_page-----b91e114e281b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b91e114e281b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b91e114e281b--------------------------------)
    [Matt Tengtrakool](https://medium.com/@matt.tengtrakool?source=post_page-----b91e114e281b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@matt.tengtrakool?source=post_page-----b91e114e281b--------------------------------)[![Matt
    Tengtrakool](../Images/e5ef621ff9132b6c308e28d3ba2c5110.png)](https://medium.com/@matt.tengtrakool?source=post_page-----b91e114e281b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b91e114e281b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b91e114e281b--------------------------------)
    [Matt Tengtrakool](https://medium.com/@matt.tengtrakool?source=post_page-----b91e114e281b--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F720b7ac13f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-what-we-lose-b91e114e281b&user=Matt+Tengtrakool&userId=720b7ac13f06&source=post_page-720b7ac13f06----b91e114e281b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b91e114e281b--------------------------------)
    ·8 min read·May 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb91e114e281b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-what-we-lose-b91e114e281b&user=Matt+Tengtrakool&userId=720b7ac13f06&source=-----b91e114e281b---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F720b7ac13f06&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-what-we-lose-b91e114e281b&user=Matt+Tengtrakool&userId=720b7ac13f06&source=post_page-720b7ac13f06----b91e114e281b---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b91e114e281b--------------------------------)
    ·8 min read·2023年5月23日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb91e114e281b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-what-we-lose-b91e114e281b&user=Matt+Tengtrakool&userId=720b7ac13f06&source=-----b91e114e281b---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb91e114e281b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-what-we-lose-b91e114e281b&source=-----b91e114e281b---------------------bookmark_footer-----------)![](../Images/5481f36b2e61728417e7195eef4cb913.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb91e114e281b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-what-we-lose-b91e114e281b&source=-----b91e114e281b---------------------bookmark_footer-----------)![](../Images/5481f36b2e61728417e7195eef4cb913.png)'
- en: '*Figure 1: The shared experience of forgetting.* Image generated by DALL·E,
    developed by OpenAI.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1：遗忘的共享体验。* 图像由OpenAI开发的DALL·E生成。'
- en: Forgetting is an intrinsic part of the human experience. We all misplace our
    keys, stumble on a familiar name, or draw a blank on what we had for dinner a
    couple of nights ago. But this apparent lapse in our memory isn’t necessarily
    a failing. Rather, it highlights a sophisticated cognitive mechanism that enables
    our brains to prioritize, sift through, and manage a deluge of information. Forgetting,
    paradoxically, is a testament to our ability to learn and remember.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 遗忘是人类经历的固有部分。我们都会丢失钥匙，忘记一个熟悉的名字，或者记不起几天前晚餐吃了什么。但这种明显的记忆缺失不一定是缺陷。相反，它突显了一个复杂的认知机制，使我们的大脑能够优先排序、筛选和管理大量信息。遗忘，悖论般地，证明了我们学习和记忆的能力。
- en: Just as people forget, so do machine learning models — in particular, Large
    Language Models. These models learn by adjusting internal parameters in response
    to data exposure. However, if new data contrasts with what the model has previously
    learned, it might overwrite or dampen the old information. Even corroborating
    data can finagle and turn the wrong knobs on otherwise good learning weights.
    This phenomenon, known as “catastrophic forgetting,” is a significant challenge
    in training stable and versatile artificial intelligence systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 就像人们会遗忘一样，机器学习模型也会遗忘——特别是大型语言模型。这些模型通过调整内部参数以响应数据暴露来进行学习。然而，如果新数据与模型之前学到的内容相反，它可能会覆盖或削弱旧信息。即使是相符的数据也可能会干扰并调整本来很好的学习权重。这种现象被称为“灾难性遗忘”，是训练稳定和多才多艺的人工智能系统中的一个重大挑战。
- en: '**The Mechanics of Forgetting in LLMs**'
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**LLM 中遗忘的机制**'
- en: At the core, an LLM’s memory lies in its weights. In a neural network, each
    weight essentially constitutes a dimension in the network’s high-dimensional weight
    space. As the learning process unfolds, the network navigates this space, guided
    by a select gradient descent, in a quest to minimize the loss function.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 核心是，LLM 的记忆存在于其权重中。在神经网络中，每个权重本质上构成了网络高维权重空间中的一个维度。随着学习过程的展开，网络在这个空间中导航，依靠选择的梯度下降，旨在最小化损失函数。
- en: 'This loss function, usually a form of cross-entropy loss for classification
    tasks in LLMs, compares the model’s output distribution to the target distribution.
    Mathematically, for a target distribution y and model output ŷ, the cross-entropy
    loss can be expressed as:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个损失函数通常是 LLM 分类任务中的交叉熵损失形式，它将模型的输出分布与目标分布进行比较。从数学角度看，对于目标分布 y 和模型输出 ŷ，交叉熵损失可以表示为：
- en: 'During training, the network tweaks its weights to minimize this loss. Now,
    the central aspect governing how much a weight should change is the learning rate.
    In the stochastic gradient descent update rule:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，网络调整其权重以最小化这个损失。现在，决定一个权重应该改变多少的核心因素是学习率。在随机梯度下降更新规则中：
- en: η is the learning rate. However, the choice of this learning rate can be tricky
    and holds implications for catastrophic forgetting. If η is high, the model is
    highly plastic and can rapidly learn new tasks but risks losing prior knowledge.
    A small η preserves old knowledge but might compromise the learning of new tasks.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: η 是学习率。然而，选择这个学习率可能很棘手，并且对灾难性遗忘有影响。如果 η 较高，模型具有很高的适应性，能够快速学习新任务，但可能会丧失先前的知识。较小的
    η 能保持旧知识，但可能会影响新任务的学习。
- en: Moreover, the complexity rises when we realize that weight updates are not independent.
    Adjusting a weight associated with one feature may inadvertently affect the performance
    of other features, leading to a complex, tangled web of dependencies.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当我们意识到权重更新并不是独立时，复杂性就上升了。调整与某一特征相关的权重可能会无意中影响其他特征的表现，导致复杂的依赖关系网络。
- en: We must also consider the curricular order of tasks or data during training.
    Sequentially introducing tasks could lead to dominance of later tasks, making
    the model biased towards the latest learned task, a direct manifestation of catastrophic
    forgetting.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须考虑训练过程中任务或数据的课程顺序。顺序引入任务可能会导致后续任务的主导地位，使模型偏向最新学习的任务，这是灾难性遗忘的直接表现。
- en: '**Strategies to Counter Catastrophic Forgetting**'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**应对灾难性遗忘的策略**'
- en: We want our LLMs to remember exponentially beyond what we can ourselves. Thus,
    we are striving to build systems that are efficient with their memory yet not
    confined necessarily to our biological standards. In the quest to combat catastrophic
    forgetting in LLMs, researchers have developed several innovative strategies.
    Three of the most prominent strategies include Elastic Weight Consolidation, Progressive
    Neural Networks , and Optimized Fixed Expansion Layers. Each technique incorporates
    a unique mathematical approach to mitigate the forgetting problem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望我们的 LLM 记住的信息超出我们自身的记忆。因此，我们努力构建在内存使用上高效的系统，但不一定受限于我们的生物标准。在与 LLM 中的灾难性遗忘作斗争的过程中，研究人员开发了几种创新策略。最突出的三种策略包括弹性权重巩固、渐进神经网络和优化固定扩展层。每种技术都采用了独特的数学方法来缓解遗忘问题。
- en: '**Elastic Weight Consolidation (EWC): Remembering the Importance of Each Weight**'
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**弹性权重巩固（EWC）：记住每个权重的重要性**'
- en: EWC is inspired by neuroscience and Bayesian inference, and it aims to quantify
    the importance of each weight to the tasks the model has previously learned. The
    fundamental idea is that the weights critical to prior tasks should be altered
    less when new data is encountered.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: EWC受到神经科学和贝叶斯推理的启发，其目标是量化每个权重对模型之前学习的任务的重要性。基本思想是，在遇到新数据时，对先前任务关键的权重应进行较少的调整。
- en: '![](../Images/a9e20e57f47152fbdedb11502ee9387b.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9e20e57f47152fbdedb11502ee9387b.png)'
- en: '*Figure 2 : EWC Schematic Parameter Space,* [https://www.pnas.org/doi/full/10.1073/pnas.1611835114](https://www.pnas.org/doi/full/10.1073/pnas.1611835114)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2：EWC示意参数空间，* [https://www.pnas.org/doi/full/10.1073/pnas.1611835114](https://www.pnas.org/doi/full/10.1073/pnas.1611835114)'
- en: In Figure 2, we can clearly see the pivotal role that Elastic Weight Consolidation
    plays in preventing catastrophic forgetting when we train on task B, without losing
    the knowledge we’ve gained from task A. This diagram shows parameter space, with
    the grey areas signifying optimal performance for task A, and cream-colored regions
    indicating good performance for task B. After we’ve learned task A, our parameter
    values are labeled as θ*A.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在图2中，我们可以清楚地看到弹性权重巩固（Elastic Weight Consolidation）在训练任务B时防止灾难性遗忘所起的关键作用，而不会丧失我们从任务A中获得的知识。该图显示了参数空间，其中灰色区域表示任务A的最佳表现，奶油色区域表示任务B的良好表现。在我们学习任务A之后，我们的参数值标记为θ*A。
- en: If we concentrate only on task B and take steps in the direction of its gradient
    (as shown by the blue arrow), we’ll minimize the loss for task B, but potentially
    wipe out our knowledge of task A — this is the problem of catastrophic forgetting.
    On the other hand, if we constrain all weights with the same coefficient (as illustrated
    by the green arrow), we place a harsh restriction that lets us retain our memory
    of task A, but makes learning task B difficult.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只集中于任务B，并沿其梯度方向采取步骤（如蓝色箭头所示），我们将最小化任务B的损失，但可能会抹去我们对任务A的知识——这就是灾难性遗忘的问题。另一方面，如果我们用相同的系数约束所有权重（如绿色箭头所示），我们会施加一个严厉的限制，使我们保留任务A的记忆，但使得学习任务B变得困难。
- en: This is where EWC steps in — it finds the sweet spot by identifying a solution
    for task B (indicated by the red arrow) that doesn’t drastically impact our knowledge
    of task A. It accomplishes this by specifically determining the importance of
    each weight in relation to task A.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是EWC发挥作用的地方——它通过为任务B（由红色箭头指示）找到一个不会对任务A的知识产生重大影响的解决方案，从而找到最佳平衡点。它通过具体确定每个权重相对于任务A的重要性来实现这一点。
- en: EWC introduces a quadratic penalty to the loss function, constraining the modification
    of important weights. This penalty term is proportional to the square of the difference
    between the current and initial weight values, scaled by an importance factor.
    This importance factor, calculated from the Fisher Information Matrix, serves
    as a heuristic for a weight’s significance to the previously learned tasks.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: EWC在损失函数中引入了一个二次惩罚，限制重要权重的修改。这个惩罚项与当前权重值和初始权重值之间的差异的平方成正比，由重要性因子进行缩放。这个重要性因子通过费舍尔信息矩阵（Fisher
    Information Matrix）计算，作为权重对先前学习任务的意义的启发式指标。
- en: In Elastic Weight Consolidation, a neural network is first trained on Task A,
    after which the Fisher Information Matrix (FIM) is computed and saved along with
    the learned weights. When training the network on Task B, EWC modifies the loss
    function to include a penalty term, computed using the saved FIM and weights,
    which discourages drastic changes to the weights critical for Task A, thus balancing
    learning the new task with preserving knowledge from the previous task. The quadratic
    nature of the penalty ensures that larger deviations from the initial weights
    incur a higher penalty. By assigning greater penalties to weights that contribute
    more to prior tasks, EWC aims to retain their learned knowledge while accommodating
    new information.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在弹性权重巩固中，首先对神经网络进行任务A的训练，然后计算并保存费舍尔信息矩阵（Fisher Information Matrix）及学得的权重。在对网络进行任务B的训练时，EWC修改损失函数以包括一个惩罚项，该惩罚项使用保存的FIM和权重计算，阻止对任务A关键权重的剧烈变化，从而在学习新任务与保留先前任务的知识之间取得平衡。惩罚的二次性质确保了从初始权重的较大偏差会产生更高的惩罚。通过对对先前任务贡献更大的权重赋予更大的惩罚，EWC旨在在适应新信息的同时保留其学习的知识。
- en: '**Progressive Neural Networks (ProgNet): Building Neural Network Towers**'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**渐进神经网络（ProgNet）：构建神经网络塔**'
- en: ProgNets introduce a new architecture that allows the network to expand when
    encountering new tasks. Instead of altering the weights of a single network, it
    adds a new network (or column) for each task, stacking these columns akin to building
    a tower. Each new column is connected to all the previously added columns but
    not the other way around, preserving the knowledge in the older columns.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ProgNets 引入了一种新架构，使网络在遇到新任务时能够扩展。它不是改变单个网络的权重，而是为每个任务添加一个新的网络（或列），将这些列堆叠起来，类似于建造一座塔。每个新列连接到所有以前添加的列，但反向不连接，从而保留旧列中的知识。
- en: Behind ProgNet, each task is learned by a separate column, and the output is
    a function of the inputs from all previous and current columns. The weights of
    previous columns remain frozen, preventing any catastrophic forgetting, while
    the weights of the new column are trained normally.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ProgNet 背后，每个任务由一个独立的列学习，输出是所有先前和当前列输入的函数。先前列的权重保持不变，防止任何灾难性遗忘，而新列的权重正常训练。
- en: '![](../Images/4a0aa65940a17b18bf7ea719b8125570.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a0aa65940a17b18bf7ea719b8125570.png)'
- en: '*Figure 3 : A Block-based ProgNet Model,* [https://arxiv.org/abs/1606.04671](https://arxiv.org/abs/1606.04671)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3 : 基于块的 ProgNet 模型，* [https://arxiv.org/abs/1606.04671](https://arxiv.org/abs/1606.04671)'
- en: '*​​*Imagine Progressive Neural Networks as a constellation of separate processing
    units, each having the ability to discern and harness the most pertinent inputs
    for the tasks they are assigned. Let’s consider an example from Figure 3, where
    output₃ not only interacts with its directly connected hidden layer, h₂, but also
    interfaces with the h₂ layers of prior columns, modifying their outputs through
    its unique lateral parameters. This output₃ unit scans and evaluates the available
    data, strategically omitting inputs that are unnecessary. For instance, if h₂¹
    encapsulates all the needed information, output₃ may choose to neglect the rest.
    On the other hand, if both h₂² and h₂³ carry valuable information, output₃ could
    preferentially focus on these while ignoring h₂¹. These side connections empower
    the network to effectively manage the flow of information across tasks while also
    enabling it to exclude irrelevant data.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*​​*设想渐进神经网络为一组独立的处理单元，每个单元能够识别并利用与其任务相关的最重要输入。以图 3 为例，输出₃不仅与直接连接的隐藏层 h₂ 进行交互，还与之前列的
    h₂ 层进行接口，通过其独特的横向参数修改这些层的输出。这个输出₃ 单元扫描并评估可用数据，战略性地忽略不必要的输入。例如，如果 h₂¹ 包含所有需要的信息，输出₃
    可能选择忽略其他信息。另一方面，如果 h₂² 和 h₂³ 包含有价值的信息，输出₃ 可能会优先关注这些，而忽略 h₂¹。这些侧向连接使网络能够有效管理跨任务的信息流，同时排除无关数据。'
- en: '**Optimized Fixed Expansion Layers (OFELs): A New Room for Each Task**'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**优化固定扩展层（OFELs）：每个任务的新房间**'
- en: The concept behind OFELs is like building a new room in a house for each new
    family member. In the context of neural networks, OFELs add a new layer for each
    task the LLM encounters. This layer expansion allows the network to accommodate
    new information without disrupting what it has already learned.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: OFELs 的概念就像为每个新家庭成员在房子里建一个新房间。在神经网络的背景下，OFELs 为 LLM 遇到的每个任务添加一个新层。这种层的扩展允许网络容纳新信息，而不会干扰已学到的内容。
- en: '![](../Images/27e1421ad69e06b32940cd9bf2df6fd7.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27e1421ad69e06b32940cd9bf2df6fd7.png)'
- en: '*Figure 4 : OFEL diagram,* [https://www.mdpi.com/2073-4425/10/7/553](https://www.mdpi.com/2073-4425/10/7/553)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4 : OFEL 图示，* [https://www.mdpi.com/2073-4425/10/7/553](https://www.mdpi.com/2073-4425/10/7/553)'
- en: OFELs involve modifying the architecture of the network itself. Here, for each
    new task, a new layer is added to the neural network instead of retraining the
    entire network. This modification in architecture helps to encapsulate the knowledge
    required for the new task within that specific layer, minimising the impact on
    the pre-existing weights of the old layers.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: OFELs 涉及到修改网络本身的架构。在这里，对于每个新任务，会在神经网络中添加一个新层，而不是重新训练整个网络。这种架构修改有助于在特定层中封装所需的知识，从而最小化对旧层已有权重的影响。
- en: where g is the activation function. The architecture of OFELs is designed such
    that it allows for the inclusion of a new layer dedicated to the new task, which
    means that the network can process new inputs (x_new) independently of the old
    inputs (x_old). In essence, while the equation presents a comprehensive view of
    the underlying process in the architecture, during inference or prediction for
    a new task, we would typically use only x_new and not require x_old.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 g 是激活函数。OFELs 的架构设计使其能够加入一个专门用于新任务的新层，这意味着网络可以独立处理新输入（`x_new`）与旧输入（`x_old`）。本质上，虽然方程式呈现了架构中底层过程的全面视图，但在推理或预测新任务时，我们通常只会使用`x_new`而不需要`x_old`。
- en: By selectively optimizing the new layers, OFELs strike a delicate balance between
    acquiring knowledge related to the new task and preserving the previously learned
    information. This meticulous optimization process allows the model to adapt to
    novel challenges while retaining its ability to leverage prior knowledge, ultimately
    facilitating more robust and versatile learning.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过有选择地优化新层，OFELs 在获取与新任务相关的知识和保留之前学到的信息之间取得了微妙的平衡。这一精细的优化过程使模型能够适应新挑战，同时保持利用先前知识的能力，从而实现更强大和多样化的学习。
- en: '**Forward Learnings**'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**前瞻性学习**'
- en: Forgetting — whether in humans or LLMs — is a fascinating paradox. On one hand,
    it can be an obstacle to continuous learning and adaptability. On the other, it’s
    an inherent part of how our brains and AI models manage and prioritize information.
    Strategies to counter catastrophic forgetting — Elastic Weight Consolidation,
    Progressive Neural Networks, and Optimized Fixed Expansion Layers — provide insightful
    yet diverse methodologies to preserve the retention capabilities of Large Language
    Models. Each offering distinct solutions, they reflect the resourcefulness and
    adaptability that the field of artificial intelligence must consistently embody.
    However, it is crucial to understand that the problem of catastrophic forgetting
    is not fully solved; there are still untapped avenues in this area demanding rigorous
    exploration, innovation, and creativity.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 遗忘——无论是在人的大脑还是LLMs中——都是一个迷人的悖论。一方面，它可能成为持续学习和适应能力的障碍。另一方面，它是我们大脑和AI模型管理和优先处理信息的固有部分。应对灾难性遗忘的策略——弹性权重巩固、渐进神经网络和优化固定扩展层——提供了富有洞察力但又各不相同的方法，以保留大型语言模型的保留能力。它们各自提供独特的解决方案，反映了人工智能领域必须持续体现的机智和适应性。然而，至关重要的是要理解，灾难性遗忘的问题尚未完全解决；在这一领域仍有待开发的途径，需要深入探索、创新和创造力。
- en: Addressing the challenge of catastrophic forgetting propels us not just towards
    more efficient AI systems, but towards a deeper understanding of learning and
    forgetting — a cognitive function shared by humans and machines alike. Therefore,
    it becomes an actionable imperative for researchers, scientists, practitioners,
    and anyone fascinated by the workings of intelligence, to contribute to this ongoing
    dialogue. The quest to tame the phenomenon of catastrophic forgetting is not merely
    an academic pursuit, but a journey that promises to redefine our relationship
    understanding.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 解决灾难性遗忘的挑战不仅推动我们朝着更高效的AI系统前进，而且朝着对学习和遗忘的更深入理解——这是人类和机器共同拥有的认知功能。因此，对于研究人员、科学家、从业者以及任何对智能工作原理感兴趣的人来说，参与这一持续对话变得至关重要。驯服灾难性遗忘现象的探索不仅仅是学术追求，而是一段承诺重新定义我们关系理解的旅程。
