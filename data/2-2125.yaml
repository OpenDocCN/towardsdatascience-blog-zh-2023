- en: Top 5 Python Libraries for Extracting Text from Images
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从图像中提取文本的前5个Python库
- en: 原文：[https://towardsdatascience.com/top-5-python-libraries-for-extracting-text-from-images-c29863b2f3d](https://towardsdatascience.com/top-5-python-libraries-for-extracting-text-from-images-c29863b2f3d)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/top-5-python-libraries-for-extracting-text-from-images-c29863b2f3d](https://towardsdatascience.com/top-5-python-libraries-for-extracting-text-from-images-c29863b2f3d)
- en: Understand and master OCR tools for text localization and recognition
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和掌握OCR工具，用于文本定位和识别
- en: '[](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)[![Eugenia
    Anello](../Images/537f444252cdc60709e7a19e37734c7b.png)](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)
    [Eugenia Anello](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)[![Eugenia
    Anello](../Images/537f444252cdc60709e7a19e37734c7b.png)](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)
    [Eugenia Anello](https://eugenia-anello.medium.com/?source=post_page-----c29863b2f3d--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)
    ·7 min read·Jul 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c29863b2f3d--------------------------------)
    ·7分钟阅读·2023年7月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/27d080f5ac1e997ff423101454b24b11.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27d080f5ac1e997ff423101454b24b11.png)'
- en: Photo by [Anna Sullivan](https://unsplash.com/@aesullivan2010) on [Unsplash](https://unsplash.com/photos/NFS3ekDQnlg)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Anna Sullivan](https://unsplash.com/@aesullivan2010) 提供，来源于 [Unsplash](https://unsplash.com/photos/NFS3ekDQnlg)
- en: Optical Character Recognition is an old, but still challenging problem that
    involves the detection and recognition of text from unstructured data, including
    images and PDF documents. It has cool applications in banking, e-commerce and
    content moderation in social media.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 光学字符识别是一个古老但依然具有挑战性的问题，它涉及从非结构化数据中检测和识别文本，包括图像和PDF文档。它在银行业务、电子商务和社交媒体内容审查中有很酷的应用。
- en: But as with everything topic in data science, there is a huge amount of resources
    when trying to learn how to solve the OCR task. This is why I am writing this
    tutorial, which can help you on getting started.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，与数据科学中的所有主题一样，学习如何解决OCR任务时有大量资源。这就是为什么我写这个教程，希望它能帮助你入门。
- en: In this article, I am going to show some Python libraries that can allow you
    to fastly extract text from images without struggling too much. The explanation
    of the libraries is followed by a practical example. The dataset used is taken
    from [Kaggle](https://www.kaggle.com/datasets/robikscube/textocr-text-extraction-from-images-dataset?select=annot.csv).
    To simplify the concepts, I am just using an image of the film Rush.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将展示一些Python库，它们可以让你快速提取图像中的文本，而不会过多地挣扎。对库的解释后跟一个实际的示例。使用的数据集来自 [Kaggle](https://www.kaggle.com/datasets/robikscube/textocr-text-extraction-from-images-dataset?select=annot.csv)。为了简化概念，我只使用了一张电影《Rush》的图像。
- en: Let’s get started!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧！
- en: '![](../Images/b9cc6d407101e37a297043f4ad5d2c71.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9cc6d407101e37a297043f4ad5d2c71.png)'
- en: Image from textOCR dataset. [Source](https://textvqa.org/textocr/download/).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来自 textOCR 数据集。 [来源](https://textvqa.org/textocr/download/)。
- en: '**Table of contents:**'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**目录：**'
- en: '**pytesseract**'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**pytesseract**'
- en: '**EasyOCR**'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**EasyOCR**'
- en: '**Keras-OCR**'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Keras-OCR**'
- en: '**TrOCR**'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**TrOCR**'
- en: '**docTR**'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**docTR**'
- en: 1\. pytesseract
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. pytesseract
- en: 'It is one of the most popular Python libraries for optical character recognition.
    It uses [Google’s Tesseract-OCR Engine](https://github.com/tesseract-ocr/tesseract)
    to extract text from images. There are multiple languages supported. Check [here](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html)
    if you want to see if your language is supported. You just need a few lines of
    code to convert the image into text:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最受欢迎的Python光学字符识别库之一。它使用 [Google的Tesseract-OCR引擎](https://github.com/tesseract-ocr/tesseract)
    从图像中提取文本。支持多种语言。如果你想查看你的语言是否被支持，可以查看 [这里](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html)。你只需要几行代码就可以将图像转换为文本：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This is the output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![](../Images/961750fc5f45797f9df4614b37ee09b9.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/961750fc5f45797f9df4614b37ee09b9.png)'
- en: We can also try the bounding box coordinates for each item detected from the
    image.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以尝试获取从图像中检测到的每个项的边界框坐标。
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This is the result:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As you can notice, it estimates the bounding box for each character, not each
    word! In case, we want to extract the box for each word, there is another method
    that should be used instead of image_to_boxes:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它估计了每个字符的边界框，而不是每个单词的边界框！如果我们想提取每个单词的边界框，可以使用另一种方法而不是 image_to_boxes：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/50af5ba434e31508367cb9b7bb7a5b37.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50af5ba434e31508367cb9b7bb7a5b37.png)'
- en: Illustration by Author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: The result returned is not so perfect. For example, it interpreted “AFILM” as
    a unique word. Moreover, it didn’t detect and recognize all the words from the
    input image.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的结果并不是很完美。例如，它将“AFILM”解释为一个唯一的词。此外，它没有检测到和识别输入图像中的所有单词。
- en: 2\. EasyOCR
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. EasyOCR
- en: '![](../Images/94667884ab1bf6bdb533ff145606d4fa.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94667884ab1bf6bdb533ff145606d4fa.png)'
- en: Screenshot from [web demo](https://huggingface.co/spaces/tomofi/EasyOCR)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [网络演示](https://huggingface.co/spaces/tomofi/EasyOCR)的截图
- en: 'It’s the turn of another open-source Python library: EasyOCR. Similarly to
    pytesseract, it supports [80+ languages](https://www.jaided.ai/easyocr/). You
    can try it fastly and easily without writing any code from a web demo. It uses
    the [CRAFT](https://arxiv.org/abs/1904.01941) algorithm to detect the text and
    the [CRNN](https://arxiv.org/abs/1507.05717) as recognition model. Moreover, these
    models are implemented using Pytorch.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 轮到另一个开源 Python 库：EasyOCR。与 pytesseract 类似，它支持 [80+ 种语言](https://www.jaided.ai/easyocr/)。你可以通过网络演示快速轻松地尝试，无需编写任何代码。它使用
    [CRAFT](https://arxiv.org/abs/1904.01941) 算法来检测文本，使用 [CRNN](https://arxiv.org/abs/1507.05717)
    作为识别模型。此外，这些模型是用 Pytorch 实现的。
- en: If you work on Google Colab, I recommend you set up the GPU, which helps speed
    up this framework.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 Google Colab 上工作，我建议你设置 GPU，这有助于加速这个框架。
- en: 'These are the following code lines to exploit this tool:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是利用该工具的代码行：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/b7b7cd05858ec97007ffd7c80728edb4.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7b7cd05858ec97007ffd7c80728edb4.png)'
- en: Illustration by Author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: Without any effort, we have detected and recognized the text using EasyOCR.
    The results are much better compared to pytesseract. For each text detected, we
    also have the bounding box and the confidence level.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们轻松地使用 EasyOCR 检测和识别了文本。与 pytesseract 相比，结果要好得多。对于每个检测到的文本，我们还获得了边界框和置信度水平。
- en: 3\. Keras-OCR
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. Keras-OCR
- en: Keras-OCR is another open-source library specialized in optical character recognition.
    As EasyOCR, it exploits the CRAFT detection model and the CRNN recognition model
    for solving the task. The difference from EasyOCR is that it’s implemented with
    Keras, instead of Pytorch. The only bad point of Keras-OCR is that it ignores
    non-English language.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Keras-OCR 是另一个专门用于光学字符识别的开源库。与 EasyOCR 类似，它利用 CRAFT 检测模型和 CRNN 识别模型来解决任务。与 EasyOCR
    的不同之处在于，它使用 Keras 实现，而不是 Pytorch。Keras-OCR 唯一的缺点是它忽略了非英语语言。
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This is the output of the first word extracted:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是提取的第一个单词的输出：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To visualize all the results, we convert the output into a Pandas Dataframe:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化所有结果，我们将输出转换为 Pandas Dataframe：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/da3f5a9147ea4923272c55d8b3f4fec4.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da3f5a9147ea4923272c55d8b3f4fec4.png)'
- en: Illustration by Author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: Magically, we can see that we have a much clearer and more precise results.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 神奇的是，我们可以看到结果更加清晰和准确。
- en: 4\. TrOCR
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. TrOCR
- en: 'TrOCR is a generative image model, based on transformers, that detect the text
    from the images. It is composed of an **encoder** and a **decoder**: TrOCR uses
    a pre-trained image transformer as an encoder and a pre-trained text transformer
    as a decoder. For additional details, take a look at the [paper](https://arxiv.org/abs/2109.10282).
    There is also good documentation of the library on [Hugging Face’s platform](https://huggingface.co/docs/transformers/model_doc/trocr).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: TrOCR 是一个基于变换器的生成图像模型，用于从图像中检测文本。它由**编码器**和**解码器**组成：TrOCR 使用预训练的图像变换器作为编码器和预训练的文本变换器作为解码器。有关更多详细信息，请查看
    [论文](https://arxiv.org/abs/2109.10282)。在[Hugging Face 平台](https://huggingface.co/docs/transformers/model_doc/trocr)上也有该库的良好文档。
- en: 'First, we load the pre-trained models:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载预训练的模型：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Before passing the image, we need to resize and normalize it. Once the image
    has been transformed, we can extract the text using the `.generate()` method.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在传递图像之前，我们需要调整大小并进行标准化。一旦图像被转换，我们可以使用 `.generate()` 方法提取文本。
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Different from the previous libraries, it returns a meaningless number. Why?
    TrOCR just includes the recognition model, not the detection model. For solving
    the OCR task, there is the need to first detect the objects within the image and,
    then, extract the text from the input. Since it just focuses on the last step,
    it doesn’t reach good performances.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的库不同，它返回一个无意义的数字。为什么？TrOCR仅包括识别模型，而不包括检测模型。为了解决OCR任务，需要首先检测图像中的对象，然后从输入中提取文本。由于它只关注最后一步，因此性能不佳。
- en: 'To make it work well, it would be better to crop specific portions of the image
    using a bounding box, like this:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使其运行良好，最好使用边界框裁剪图像的特定部分，如下所示：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/109b701db42b9c00d5de74714fab079a.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/109b701db42b9c00d5de74714fab079a.png)'
- en: Illustration by Author
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: 'Then, we try to apply again the model:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们尝试再次应用模型：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/cf10f4aa586b1f234e6ed3a4210b0818.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf10f4aa586b1f234e6ed3a4210b0818.png)'
- en: Illustration by Author
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: This is much better! This operation can be repeated for every word/phrase contained
    within the image.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这要好得多！这个操作可以对图像中的每个单词/短语重复进行。
- en: 5\. docTR
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. docTR
- en: 'Finally, we are covering the last Python package for text detection and recognition
    from documents: docTR. It can interpret the document as a PDF or an image and,
    then, pass it to the two stage-approach. In docTR, there is the text detection
    model ([DBNet](https://mindee.github.io/doctr/latest/modules/models.html#doctr-models-detection)
    or [LinkNet](https://mindee.github.io/doctr/latest/modules/models.html#doctr-models-detection))
    followed by the [CRNN](https://mindee.github.io/doctr/latest//modules/models.html#doctr-models-recognition)
    model for text recognition. This library requires both Pytorch and Tensorflow
    installed since the implementation is done with both these deep learning frameworks.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍用于从文档中进行文本检测和识别的最后一个Python包：docTR。它可以将文档解释为PDF或图像，然后传递给两个阶段的方法。在docTR中，有一个文本检测模型（[DBNet](https://mindee.github.io/doctr/latest/modules/models.html#doctr-models-detection)或[LinkNet](https://mindee.github.io/doctr/latest/modules/models.html#doctr-models-detection)）然后是用于文本识别的[CRNN](https://mindee.github.io/doctr/latest//modules/models.html#doctr-models-recognition)模型。该库要求安装Pytorch和Tensorflow，因为实现是用这两个深度学习框架完成的。
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'After, we import the relevant libraries for using docTR and load the model,
    which is a two-step approach. Indeed, we need to specify the DBNet with ResNet-50
    Backbone and CRNN with a VGG-16 backbone for text detection and text recognition:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们导入使用docTR所需的相关库并加载模型，这是一种两步法。确实，我们需要指定带有ResNet-50骨干网的DBNet和带有VGG-16骨干网的CRNN用于文本检测和文本识别：
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, we can finally read the file, use the pre-trained model and export the
    output as a nested dictionary:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以最终读取文件，使用预训练模型并将输出导出为嵌套字典：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This is the very long output:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这是非常长的输出：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For better visualization, it’s better to a double for loop and takes only the
    information we are interested in:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地可视化，最好使用双重循环，只提取我们感兴趣的信息：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/0689b763e189b58a6ad6656532af751b.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0689b763e189b58a6ad6656532af751b.png)'
- en: Illustration by Author
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: That’s great! docTR is another good option to extract valuable information from
    images or PDFs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！docTR是另一个提取图像或PDF中有价值信息的好选项。
- en: 'Final thoughts:'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后的想法：
- en: These are five Python libraries that can be useful for your OCR project. Each
    of these tools has different advantages and disadvantages. Surely, the first thing
    to choosing one of these packages is to consider the language of the data you
    are analyzing. If you consider non-English languages, EasyOCR is probably the
    best choice for language covering and performances. If you have other suggestions,
    comment here. I hope that you have found useful this article for getting started
    with OCR. If you want to look at the complete output returned by these OCR models,
    the GitHub code is [here](https://github.com/eugeniaring/Medium-Articles/blob/main/CV/OCR_libraries.ipynb).
    Have a nice day!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这五个Python库可能对你的OCR项目有用。这些工具各有优缺点。选择这些包的第一件事是考虑你分析的数据的语言。如果你考虑非英语语言，EasyOCR可能是覆盖语言和性能的最佳选择。如果你有其他建议，请在这里评论。希望你觉得这篇文章对开始使用OCR有所帮助。如果你想查看这些OCR模型返回的完整输出，GitHub代码在[这里](https://github.com/eugeniaring/Medium-Articles/blob/main/CV/OCR_libraries.ipynb)。祝你有美好的一天！
- en: '*Disclaimer: This data set is licensed under Attribution 4.0 International
    (*[*CC by 4.0*](https://textvqa.org/textocr/download/)*)*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：该数据集根据[CC 4.0](https://textvqa.org/textocr/download/)国际许可协议授权使用*'
- en: Did you like my article? [*Become a member*](https://eugenia-anello.medium.com/membership)
    *and get unlimited access to new data science posts every day! It’s an indirect
    way of supporting me without any extra cost to you. If you are already a member,*
    [*subscribe*](https://eugenia-anello.medium.com/subscribe) *to get emails whenever
    I publish new data science and Python guides!*
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你喜欢我的文章吗？[*成为会员*](https://eugenia-anello.medium.com/membership) *即可每天无限制访问新的数据科学文章！这是一种支持我的间接方式，且不会增加你的额外成本。如果你已经是会员，*
    [*订阅*](https://eugenia-anello.medium.com/subscribe) *以便每当我发布新的数据科学和 Python 指南时，你都会收到邮件！*
