- en: 'Operator Learning via Physics-Informed DeepONet: Letâ€™s Implement It From Scratch'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€šè¿‡ç‰©ç†å¯å‘çš„ DeepONet è¿›è¡Œç®—å­å­¦ä¹ ï¼šä»å¤´å¼€å§‹å®ç°
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/operator-learning-via-physics-informed-deeponet-lets-implement-it-from-scratch-6659f3179887](https://towardsdatascience.com/operator-learning-via-physics-informed-deeponet-lets-implement-it-from-scratch-6659f3179887)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/operator-learning-via-physics-informed-deeponet-lets-implement-it-from-scratch-6659f3179887](https://towardsdatascience.com/operator-learning-via-physics-informed-deeponet-lets-implement-it-from-scratch-6659f3179887)
- en: A deep dive into the DeepONets, physics-informed neural networks, and physics-informed
    DeepONets
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ·±å…¥æ¢è®¨ DeepONetsã€ç‰©ç†å¯å‘çš„ç¥ç»ç½‘ç»œä»¥åŠç‰©ç†å¯å‘çš„ DeepONets
- en: '[](https://shuaiguo.medium.com/?source=post_page-----6659f3179887--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----6659f3179887--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6659f3179887--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6659f3179887--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----6659f3179887--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shuaiguo.medium.com/?source=post_page-----6659f3179887--------------------------------)[![Shuai
    Guo](../Images/d673c066f8006079be5bf92757e73a59.png)](https://shuaiguo.medium.com/?source=post_page-----6659f3179887--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6659f3179887--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6659f3179887--------------------------------)
    [Shuai Guo](https://shuaiguo.medium.com/?source=post_page-----6659f3179887--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6659f3179887--------------------------------)
    Â·23 min readÂ·Jul 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6659f3179887--------------------------------)
    Â·é˜…è¯»æ—¶é—´23åˆ†é’ŸÂ·2023å¹´7æœˆ7æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e58768fda61ec2f49710623f6f30cdc2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e58768fda61ec2f49710623f6f30cdc2.png)'
- en: Figure 1\. ODE/PDEs are widely used to describe the system processes. In many
    scenarios, those ODE/PDEs accept a function (e.g., the forcing function u(t))
    as input and output another function (e.g., s(t)). Traditionally, numerical solvers
    are used to connect the input and output. More recently, **neural operators**
    are developed to address the same problem but with much higher efficiency. (Image
    by Author)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1\. ODE/PDEs å¹¿æ³›ç”¨äºæè¿°ç³»ç»Ÿè¿‡ç¨‹ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œè¿™äº› ODE/PDEs æ¥å—ä¸€ä¸ªå‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œå¼ºè¿«å‡½æ•° u(t)ï¼‰ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºå¦ä¸€ä¸ªå‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œs(t)ï¼‰ã€‚ä¼ ç»Ÿä¸Šï¼Œæ•°å€¼æ±‚è§£å™¨ç”¨äºè¿æ¥è¾“å…¥å’Œè¾“å‡ºã€‚æœ€è¿‘ï¼Œ**ç¥ç»ç®—å­**çš„å¼€å‘å¤§å¤§æé«˜äº†å¤„ç†æ•ˆç‡ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰
- en: Ordinary and partial differential equations (ODEs/PDEs) are the backbone of
    many disciplines in science and engineering, from physics and biology to economics
    and climate science. They are fundamental tools used to describe physical systems
    and processes, capturing the continuous change of quantities over time and space.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEsï¼‰å’Œåå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEsï¼‰æ˜¯è®¸å¤šç§‘å­¦å’Œå·¥ç¨‹å­¦ç§‘çš„åŸºç¡€ï¼Œä»ç‰©ç†å­¦å’Œç”Ÿç‰©å­¦åˆ°ç»æµå­¦å’Œæ°”å€™ç§‘å­¦ã€‚å®ƒä»¬æ˜¯æè¿°ç‰©ç†ç³»ç»Ÿå’Œè¿‡ç¨‹çš„åŸºæœ¬å·¥å…·ï¼Œæ•æ‰äº†æ•°é‡éšæ—¶é—´å’Œç©ºé—´çš„è¿ç»­å˜åŒ–ã€‚
- en: Yet, a unique trait of many of these equations is that they donâ€™t just take
    single values as inputs, they take functions. For example, consider the case of
    predicting vibrations in a building due to an earthquake. The shaking of the ground,
    which varies over time, can be represented as a function that acts as the input
    to the differential equation describing the buildingâ€™s motion. Similarly, in the
    case of sound waves propagating in a concert hall, the sound waves produced by
    a musical instrument can be an input function with varying volume and pitch over
    time. These varying input functions fundamentally influence the resulting output
    functions â€” the buildingâ€™s vibrations and the acoustic field in the hall, respectively.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™äº›æ–¹ç¨‹çš„ä¸€ä¸ªç‹¬ç‰¹ç‰¹ç‚¹æ˜¯å®ƒä»¬ä¸ä»…æ¥å—å•ä¸€æ•°å€¼ä½œä¸ºè¾“å…¥ï¼Œè¿˜æ¥å—å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘é¢„æµ‹å»ºç­‘ç‰©å› åœ°éœ‡è€Œäº§ç”Ÿçš„æŒ¯åŠ¨ã€‚åœ°é¢çš„éœ‡åŠ¨éšæ—¶é—´å˜åŒ–ï¼Œå¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸ªå‡½æ•°ï¼Œè¯¥å‡½æ•°ä½œä¸ºæè¿°å»ºç­‘ç‰©è¿åŠ¨çš„å¾®åˆ†æ–¹ç¨‹çš„è¾“å…¥ã€‚åŒæ ·ï¼Œåœ¨éŸ³ä¹å…ä¸­å£°æ³¢ä¼ æ’­çš„æƒ…å†µä¸‹ï¼Œä¹å™¨äº§ç”Ÿçš„å£°æ³¢å¯ä»¥æ˜¯ä¸€ä¸ªéšæ—¶é—´å˜åŒ–çš„éŸ³é‡å’ŒéŸ³è°ƒçš„è¾“å…¥å‡½æ•°ã€‚è¿™äº›å˜åŒ–çš„è¾“å…¥å‡½æ•°ä»æ ¹æœ¬ä¸Šå½±å“äº†ç»“æœè¾“å‡ºå‡½æ•°â€”â€”å»ºç­‘ç‰©çš„æŒ¯åŠ¨å’ŒéŸ³ä¹å…çš„å£°å­¦åœºã€‚
- en: 'Traditionally, these ODEs/PDEs are tackled using numerical solvers like finite
    difference or finite element methods. However, these methods come with a bottleneck:
    for every new input function, the solver must be run all over again. This process
    can be computationally intensive and slow, particularly for intricate systems
    or high-dimensional inputs.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿä¸Šï¼Œè¿™äº›ODEs/PDEsé€šå¸¸ä½¿ç”¨æœ‰é™å·®åˆ†æˆ–æœ‰é™å…ƒæ–¹æ³•ç­‰æ•°å€¼æ±‚è§£å™¨æ¥è§£å†³ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä¸€ä¸ªç“¶é¢ˆï¼šæ¯å½“æœ‰æ–°çš„è¾“å…¥å‡½æ•°æ—¶ï¼Œæ±‚è§£å™¨å¿…é¡»é‡æ–°è¿è¡Œä¸€æ¬¡ã€‚è¿™ä¸ªè¿‡ç¨‹å¯èƒ½è®¡ç®—å¯†é›†ä¸”ç¼“æ…¢ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç³»ç»Ÿæˆ–é«˜ç»´è¾“å…¥æƒ…å†µä¸‹ã€‚
- en: 'To address this challenge, a novel framework was introduced by [Lu et al.](https://arxiv.org/abs/1910.03193)
    in 2019: the **Deep Operator Network**, or **DeepONet**. DeepONets aim to learn
    the **operator** that maps input functions to output functions, essentially learning
    to predict the output of these ODEs/PDEs for any given input function without
    having to re-run a numerical solver each time.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œ**Deep Operator Network**ï¼ˆç®€ç§°**DeepONet**ï¼‰çš„åˆ›æ–°æ¡†æ¶ç”±[Lu et al.](https://arxiv.org/abs/1910.03193)äº2019å¹´æå‡ºã€‚DeepONetsæ—¨åœ¨å­¦ä¹ å°†è¾“å…¥å‡½æ•°æ˜ å°„åˆ°è¾“å‡ºå‡½æ•°çš„**ç®—å­**ï¼Œæœ¬è´¨ä¸Šæ˜¯å­¦ä¹ é¢„æµ‹è¿™äº›ODEs/PDEsåœ¨ä»»æ„ç»™å®šè¾“å…¥å‡½æ•°ä¸‹çš„è¾“å‡ºï¼Œè€Œä¸éœ€è¦æ¯æ¬¡éƒ½é‡æ–°è¿è¡Œæ•°å€¼æ±‚è§£å™¨ã€‚
- en: 'But DeepONets, though powerful, inherited the common problems faced by data-driven
    methods: How can we ensure that the predictions of the network are in line with
    the known laws of physics encapsulated in the governing equations?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ DeepONets å¾ˆå¼ºå¤§ï¼Œä½†å®ƒä»¬ç»§æ‰¿äº†æ•°æ®é©±åŠ¨æ–¹æ³•é¢ä¸´çš„å…±åŒé—®é¢˜ï¼šæˆ‘ä»¬å¦‚ä½•ç¡®ä¿ç½‘ç»œçš„é¢„æµ‹ä¸åŒ…å«åœ¨æ§åˆ¶æ–¹ç¨‹ä¸­çš„å·²çŸ¥ç‰©ç†å®šå¾‹ä¸€è‡´ï¼Ÿ
- en: Enter **physics-informed learning**.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›å…¥**ç‰©ç†ä¿¡æ¯åŒ–å­¦ä¹ **é¢†åŸŸã€‚
- en: Physics-informed learning is a rapidly evolving branch of machine learning that
    combines physical principles with data science to enhance the modeling and understanding
    of complex physical systems. It involves leveraging domain-specific knowledge
    and physical laws to guide the learning process and improve the accuracy, generalization,
    and interpretability of machine learning models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰©ç†ä¿¡æ¯åŒ–å­¦ä¹ æ˜¯ä¸€ä¸ªè¿…é€Ÿå‘å±•çš„æœºå™¨å­¦ä¹ åˆ†æ”¯ï¼Œå®ƒå°†ç‰©ç†åŸç†ä¸æ•°æ®ç§‘å­¦ç»“åˆèµ·æ¥ï¼Œä»¥å¢å¼ºå¯¹å¤æ‚ç‰©ç†ç³»ç»Ÿçš„å»ºæ¨¡å’Œç†è§£ã€‚å®ƒæ¶‰åŠåˆ©ç”¨ç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†å’Œç‰©ç†å®šå¾‹æ¥æŒ‡å¯¼å­¦ä¹ è¿‡ç¨‹ï¼Œæé«˜æœºå™¨å­¦ä¹ æ¨¡å‹çš„å‡†ç¡®æ€§ã€æ³›åŒ–èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚
- en: 'Under this framework, in 2021, [Wang et al.](https://arxiv.org/abs/2103.10974)
    introduced a new variant of DeepONets: the **Physics-Informed DeepONet.** This
    innovative approach builds on the foundation of DeepONets by incorporating our
    understanding of physical laws into the learning process. Weâ€™re no longer just
    asking our model to learn from data; weâ€™re guiding it with principles derived
    from centuries of scientific inquiry.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªæ¡†æ¶ä¸‹ï¼Œ2021å¹´ï¼Œ[Wang et al.](https://arxiv.org/abs/2103.10974)æå‡ºäº†DeepONetsçš„æ–°å˜ç§ï¼š**ç‰©ç†ä¿¡æ¯åŒ–
    DeepONet**ã€‚è¿™ç§åˆ›æ–°æ–¹æ³•åœ¨DeepONetsçš„åŸºç¡€ä¸Šï¼Œé€šè¿‡å°†æˆ‘ä»¬å¯¹ç‰©ç†å®šå¾‹çš„ç†è§£èå…¥å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œè¿›è¡Œæ”¹è¿›ã€‚æˆ‘ä»¬ä¸å†åªæ˜¯è®©æ¨¡å‹ä»æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œæ˜¯ç”¨æºäºå‡ ä¸ªä¸–çºªç§‘å­¦æ¢ç©¶çš„åŸç†æ¥æŒ‡å¯¼å®ƒã€‚
- en: This seems to be quite a promising approach! But how should we implement it
    in practice? Thatâ€™s precisely what weâ€™re going to explore today ğŸ¤—
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªéå¸¸æœ‰å‰æ™¯çš„æ–¹æ³•ï¼ä½†æ˜¯æˆ‘ä»¬åº”è¯¥å¦‚ä½•åœ¨å®è·µä¸­å®ç°å®ƒï¼Ÿè¿™æ­£æ˜¯æˆ‘ä»¬ä»Šå¤©è¦æ¢è®¨çš„å†…å®¹ğŸ¤—
- en: In this blog, weâ€™ll discuss the theory behind Physics-Informed DeepONet, and
    walk through how to implement it from scratch. Weâ€™ll also put our developed model
    into action and demonstrate its power through a hands-on case study.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºç‰©ç†ä¿¡æ¯åŒ– DeepONet èƒŒåçš„ç†è®ºï¼Œå¹¶é€æ­¥è®²è§£å¦‚ä½•ä»é›¶å¼€å§‹å®ç°å®ƒã€‚æˆ‘ä»¬è¿˜å°†æŠŠæˆ‘ä»¬å¼€å‘çš„æ¨¡å‹ä»˜è¯¸å®è·µï¼Œé€šè¿‡å®é™…æ¡ˆä¾‹å±•ç¤ºå…¶å¼ºå¤§èƒ½åŠ›ã€‚
- en: 'If you are also interested in using physics-informed DeepONet to solve inverse
    problems, feel free to check out my new blog here: [Solving Inverse Problems With
    Physics-Informed DeepONet: A Practical Guide With Code Implementation](/solving-inverse-problems-with-physics-informed-deeponet-a-practical-guide-with-code-implementation-27795eb4f502)'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¹Ÿæœ‰å…´è¶£ä½¿ç”¨ç‰©ç†ä¿¡æ¯åŒ– DeepONet è§£å†³é€†é—®é¢˜ï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘çš„æ–°åšå®¢ï¼š[åˆ©ç”¨ç‰©ç†ä¿¡æ¯åŒ– DeepONet è§£å†³é€†é—®é¢˜ï¼šå¸¦ä»£ç å®ç°çš„å®ç”¨æŒ‡å—](/solving-inverse-problems-with-physics-informed-deeponet-a-practical-guide-with-code-implementation-27795eb4f502)
- en: Letâ€™s get started!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å§ï¼
- en: '**Table of Content**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**å†…å®¹è¡¨**'
- en: Â· [1\. Case study](#8d5d)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [1\. æ¡ˆä¾‹ç ”ç©¶](#8d5d)
- en: Â· [2\. Physics-informed DeepONet](#ef0e)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [2\. ç‰©ç†ä¿¡æ¯åŒ– DeepONet](#ef0e)
- en: 'âˆ˜ [2.1 DeepONet: An overview](#5221)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [2.1 DeepONetï¼šæ¦‚è¿°](#5221)
- en: âˆ˜ [2.2 Physics-informed Neural Networks (PINNs)](#eda1)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [2.2 ç‰©ç†ä¿¡æ¯åŒ–ç¥ç»ç½‘ç»œï¼ˆPINNsï¼‰](#eda1)
- en: âˆ˜ [2.3 Physics-informed DeepONet](#0fe9)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [2.3 ç‰©ç†ä¿¡æ¯åŒ– DeepONet](#0fe9)
- en: Â· [3\. Implementation of Physics-informed DeepONet](#8657)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [3\. ç‰©ç†ä¿¡æ¯åŒ– DeepONet çš„å®ç°](#8657)
- en: âˆ˜ [3.1 Define the Architecture](#4f1e)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [3.1 å®šä¹‰æ¶æ„](#4f1e)
- en: âˆ˜ [3.2 Define ODE loss](#524a)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [3.2 å®šä¹‰ ODE æŸå¤±](#524a)
- en: âˆ˜ [3.3 Define gradient descent step](#8cf2)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [3.3 å®šä¹‰æ¢¯åº¦ä¸‹é™æ­¥éª¤](#8cf2)
- en: Â· [4\. Data Generation and Organization](#0096)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [4. æ•°æ®ç”Ÿæˆä¸ç»„ç»‡](#0096)
- en: âˆ˜ [4.1 Generation of u(Â·) profiles](#f5af)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [4.1 u(Â·) è½®å»“ç”Ÿæˆ](#f5af)
- en: âˆ˜ [4.2 Generation of Dataset](#5751)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [4.2 æ•°æ®é›†ç”Ÿæˆ](#5751)
- en: âˆ˜ [4.3 Dataset Organization](#51a4)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: âˆ˜ [4.3 æ•°æ®é›†ç»„ç»‡](#51a4)
- en: Â· [5\. Training Physics-informed DeepONet](#9df7)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [5. è®­ç»ƒç‰©ç†ä¿¡æ¯æ·±åº¦è¿ç®—ç½‘ç»œ](#9df7)
- en: Â· [6\. Results Discussion](#9dbe)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [6. ç»“æœè®¨è®º](#9dbe)
- en: Â· [7\. Take-away](#ed8c)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [7. é‡ç‚¹æ€»ç»“](#ed8c)
- en: Â· [Reference](#3c52)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Â· [å‚è€ƒæ–‡çŒ®](#3c52)
- en: 1\. Case study
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. æ¡ˆä¾‹ç ”ç©¶
- en: 'Letâ€™s ground our discussion in a concrete example. In this blog, we will reproduce
    the first case study considered in [Wang et al.](https://arxiv.org/abs/2103.10974)â€™s
    original paper, i.e., an initial value problem described by the following ordinary
    differential equation (ODE):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬åœ¨ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ä¸­æ‰æ ¹è®¨è®ºã€‚åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç° [Wang et al.](https://arxiv.org/abs/2103.10974)
    åŸè®ºæ–‡ä¸­è€ƒè™‘çš„ç¬¬ä¸€ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œå³ç”±ä»¥ä¸‹å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰æè¿°çš„åˆå€¼é—®é¢˜ï¼š
- en: '![](../Images/a2965a8118cbca756dc4b2c9fbbb113a.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2965a8118cbca756dc4b2c9fbbb113a.png)'
- en: with an initial condition s(0) = 0.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å…·æœ‰åˆå§‹æ¡ä»¶ s(0) = 0ã€‚
- en: In this equation, u(*t*) is the input function that varies over time, and s(*t*)
    is the state of the system at time *t* that we are interested in predicting. In
    a physical scenario, u(*t*) could represent a force applied to a system, and s(*t*)
    might represent the system's response, like its displacement or velocity, depending
    on the context. **Our goal here is to learn the mapping between the forcing term
    u(*t*) and the ODE solution s(*t*).**
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªæ–¹ç¨‹ä¸­ï¼Œu(*t*) æ˜¯éšæ—¶é—´å˜åŒ–çš„è¾“å…¥å‡½æ•°ï¼Œè€Œ s(*t*) æ˜¯æˆ‘ä»¬æ„Ÿå…´è¶£çš„åœ¨æ—¶é—´ *t* çš„ç³»ç»ŸçŠ¶æ€ã€‚åœ¨ç‰©ç†åœºæ™¯ä¸­ï¼Œu(*t*) å¯èƒ½ä»£è¡¨æ–½åŠ åœ¨ç³»ç»Ÿä¸Šçš„åŠ›ï¼Œè€Œ
    s(*t*) å¯èƒ½ä»£è¡¨ç³»ç»Ÿçš„å“åº”ï¼Œæ¯”å¦‚ä½ç§»æˆ–é€Ÿåº¦ï¼Œå…·ä½“å–å†³äºä¸Šä¸‹æ–‡ã€‚**æˆ‘ä»¬è¿™é‡Œçš„æœ€ç»ˆç›®æ ‡æ˜¯å­¦ä¹ å¼ºè¿«é¡¹ u(*t*) ä¸ ODE è§£ s(*t*) ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚**
- en: 'Traditional numerical methods such as Eulerâ€™s method or Runge-Kutta methods
    can solve this equation effectively. However, notice that the forcing term u(*t*)
    can take various profiles, as shown by the following figure:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿçš„æ•°å€¼æ–¹æ³•ï¼Œå¦‚æ¬§æ‹‰æ–¹æ³•æˆ–é¾™æ ¼-åº“å¡”æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ±‚è§£æ­¤æ–¹ç¨‹ã€‚ç„¶è€Œï¼Œè¯·æ³¨æ„ï¼Œå¼ºè¿«é¡¹ u(*t*) å¯ä»¥é‡‡å–å„ç§è½®å»“ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
- en: '![](../Images/8d8e59e7ea3b0943a06cc633a209a04a.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d8e59e7ea3b0943a06cc633a209a04a.png)'
- en: Figure 2\. Example profiles of u(t). (Image by author)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 2. u(t) çš„ç¤ºä¾‹è½®å»“ã€‚ ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: Consequently, every time u(*t*) changes, we would need to re-run the entire
    simulation to get the corresponding s(*t*) (as shown in Figure 3), which can be
    computationally intensive and inefficient.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ¯å½“ u(*t*) å˜åŒ–æ—¶ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°è¿è¡Œæ•´ä¸ªæ¨¡æ‹Ÿä»¥è·å–ç›¸åº”çš„ s(*t*)ï¼ˆå¦‚å›¾ 3 æ‰€ç¤ºï¼‰ï¼Œè¿™å¯èƒ½ä¼šè®¡ç®—å¯†é›†ä¸”æ•ˆç‡ä½ä¸‹ã€‚
- en: '![](../Images/9ce7ea3610ea7a93e9691b5640a150a5.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ce7ea3610ea7a93e9691b5640a150a5.png)'
- en: Figure 3\. Corresponding profiles of s(t). They are calculated by using the
    RK45 algorithm to solve the ODE. (Image by author)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 3. s(t) çš„ç›¸åº”è½®å»“ã€‚å®ƒä»¬æ˜¯é€šè¿‡ä½¿ç”¨ RK45 ç®—æ³•æ±‚è§£ ODE è®¡ç®—å¾—å‡ºçš„ã€‚ ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰
- en: So, how can we address this type of problem more efficiently?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•æ›´é«˜æ•ˆåœ°è§£å†³è¿™ç§é—®é¢˜å‘¢ï¼Ÿ
- en: 2\. Physics-informed DeepONet
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. ç‰©ç†ä¿¡æ¯æ·±åº¦è¿ç®—ç½‘ç»œ
- en: As mentioned in the introduction, the physics-informed DeepONet constitutes
    a promising solution to our target problem. In this section, weâ€™ll break down
    its fundamental concepts to make them more comprehensible.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä»‹ç»ä¸­æ‰€è¿°ï¼Œç‰©ç†ä¿¡æ¯ DeepONet æ˜¯è§£å†³æˆ‘ä»¬ç›®æ ‡é—®é¢˜çš„æœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è¯¦ç»†è§£æå…¶åŸºæœ¬æ¦‚å¿µï¼Œä½¿å…¶æ›´æ˜“äºç†è§£ã€‚
- en: Weâ€™ll first discuss the principles underpinning the original DeepONet. Following
    that, weâ€™ll explore the concept of physics-informed neural networks and how it
    brings an added dimension to the problem-solving table. Finally, weâ€™ll demonstrate
    how we can seamlessly integrate these two ideas to construct the physics-informed
    DeepONets.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆè®¨è®ºåŸå§‹ DeepONet çš„åŸºç¡€åŸåˆ™ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„æ¦‚å¿µåŠå…¶å¦‚ä½•ä¸ºé—®é¢˜è§£å†³æä¾›é¢å¤–çš„ç»´åº¦ã€‚æœ€åï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•å°†è¿™ä¸¤ä¸ªæƒ³æ³•æ— ç¼é›†æˆä»¥æ„å»ºç‰©ç†ä¿¡æ¯
    DeepONetã€‚
- en: '2.1 DeepONet: An overview'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 DeepONetï¼šæ¦‚è¿°
- en: DeepONet, short for Deep Operator Network, represents a new frontier in deep
    learning. Unlike traditional machine learning methods that map a set of input
    values to output values, DeepONet is designed to map entire functions to other
    functions. This makes DeepONet particularly powerful when dealing with problems
    that naturally involve functional inputs and outputs. So how exactly it achieves
    that goal?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: DeepONetï¼Œç®€è€Œè¨€ä¹‹å°±æ˜¯æ·±åº¦è¿ç®—ç½‘ç»œï¼Œä»£è¡¨äº†æ·±åº¦å­¦ä¹ çš„æ–°å‰æ²¿ã€‚ä¸ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•å°†ä¸€ç»„è¾“å…¥å€¼æ˜ å°„åˆ°è¾“å‡ºå€¼ä¸åŒï¼ŒDeepONet æ—¨åœ¨å°†æ•´ä¸ªå‡½æ•°æ˜ å°„åˆ°å…¶ä»–å‡½æ•°ã€‚è¿™ä½¿å¾—
    DeepONet åœ¨å¤„ç†è‡ªç„¶æ¶‰åŠå‡½æ•°è¾“å…¥å’Œè¾“å‡ºçš„é—®é¢˜æ—¶ç‰¹åˆ«å¼ºå¤§ã€‚é‚£ä¹ˆå®ƒæ˜¯å¦‚ä½•å®ç°è¿™ä¸€ç›®æ ‡çš„å‘¢ï¼Ÿ
- en: 'To formulate what we want to achieve symbolically:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç¬¦å·åŒ–æˆ‘ä»¬æƒ³è¦å®ç°çš„ç›®æ ‡ï¼š
- en: '![](../Images/5ab62e562bcb715899129c87ad34411b.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ab62e562bcb715899129c87ad34411b.png)'
- en: Figure 4\. Our goal is to train a neural network to approximate the operator
    that maps the forcing term u(Â·) to the target output s(Â·), which are both a function
    of t. (Image by author)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4\. æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œä»¥è¿‘ä¼¼å°†å¼ºè¿«é¡¹u(Â·)æ˜ å°„åˆ°ç›®æ ‡è¾“å‡ºs(Â·)çš„ç®—å­ï¼Œè¿™ä¸¤è€…éƒ½æ˜¯æ—¶é—´çš„å‡½æ•°ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: On the left, we have the *operator* G that maps from an input function u(Â·)
    to an output function s(Â·). On the right, we would like to use a neural network
    to *approximate* the operatorG. Once this can be achieved, we could use the trained
    neural network to perform a fast calculation of s(Â·) given any u(Â·).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å·¦è¾¹æ˜¯å°†è¾“å…¥å‡½æ•°u(Â·)æ˜ å°„åˆ°è¾“å‡ºå‡½æ•°s(Â·)çš„*ç®—å­*Gã€‚å³è¾¹ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥*è¿‘ä¼¼*ç®—å­Gã€‚ä¸€æ—¦å®ç°äº†è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œåœ¨ç»™å®šä»»ä½•u(Â·)çš„æƒ…å†µä¸‹å¿«é€Ÿè®¡ç®—s(Â·)ã€‚
- en: 'For the current case study, both the input function u(Â·) and the output function
    s(Â·) take time coordinate *t* as the sole argument. Therefore, the â€œinputâ€ and
    â€œoutputâ€ of the neural network we aim to build should look like this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå½“å‰çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¾“å…¥å‡½æ•°u(Â·)å’Œè¾“å‡ºå‡½æ•°s(Â·)éƒ½å°†æ—¶é—´åæ ‡*t*ä½œä¸ºå”¯ä¸€å‚æ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›æ„å»ºçš„ç¥ç»ç½‘ç»œçš„â€œè¾“å…¥â€å’Œâ€œè¾“å‡ºâ€åº”å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/1388bbbd27f57b93e2790a6bdad90f3a.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1388bbbd27f57b93e2790a6bdad90f3a.png)'
- en: Figure 5\. The input and output for the neural network model we aim to train.
    (Image by author)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾5\. æˆ‘ä»¬å¸Œæœ›è®­ç»ƒçš„ç¥ç»ç½‘ç»œæ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: Essentially, our neural network should accept the **entire profile** of u(*t*)
    as the first input, as well as a specific time instance *t* as the second input*.*
    Subsequently, it should output the target output function s(Â·) evaluated at time
    instance *t,* i.e., s(*t*).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å®è´¨ä¸Šï¼Œæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œåº”æ¥å—u(*t*)çš„**æ•´ä¸ªè½®å»“**ä½œä¸ºç¬¬ä¸€ä¸ªè¾“å…¥ï¼Œä»¥åŠä¸€ä¸ªç‰¹å®šæ—¶é—´ç‚¹*t*ä½œä¸ºç¬¬äºŒä¸ªè¾“å…¥ã€‚éšåï¼Œå®ƒåº”è¾“å‡ºåœ¨æ—¶é—´ç‚¹*t*è¯„ä¼°çš„ç›®æ ‡è¾“å‡ºå‡½æ•°s(Â·)ï¼Œå³s(*t*)ã€‚
- en: To better understand this setup, we recognize that the value of s(*t*) firstly
    depends on the profile of s(Â·), which in turn depends on u(Â·), and secondly depends
    on at which time instance the s(Â·) is evaluated. This is also why time coordinate
    *t* is necessary to be among the inputs.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å¥½åœ°ç†è§£è¿™ä¸€è®¾ç½®ï¼Œæˆ‘ä»¬è®¤è¯†åˆ°s(*t*)çš„å€¼é¦–å…ˆä¾èµ–äºs(Â·)çš„è½®å»“ï¼Œè€Œs(Â·)çš„è½®å»“åˆä¾èµ–äºu(Â·)ï¼Œå…¶æ¬¡ä¾èµ–äºs(Â·)è¢«è¯„ä¼°çš„æ—¶é—´ç‚¹ã€‚è¿™ä¹Ÿæ˜¯æ—¶é—´åæ ‡*t*éœ€è¦ä½œä¸ºè¾“å…¥ä¹‹ä¸€çš„åŸå› ã€‚
- en: 'There are two questions we need to clear at the moment: first of all, how should
    we input a continuous profile of u(Â·) to the network? And secondly, how should
    we concatenate the two inputs, i.e., *t* and u(Â·).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰æˆ‘ä»¬éœ€è¦å¼„æ¸…æ¥šä¸¤ä¸ªé—®é¢˜ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•å°†u(Â·)çš„è¿ç»­è½®å»“è¾“å…¥ç½‘ç»œï¼Ÿå…¶æ¬¡ï¼Œæˆ‘ä»¬åº”è¯¥å¦‚ä½•æ‹¼æ¥è¿™ä¸¤ä¸ªè¾“å…¥ï¼Œå³*t*å’Œu(Â·)ã€‚
- en: 1ï¸âƒ£ How should we input a *continuous* profile of u(Â·)?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ æˆ‘ä»¬åº”è¯¥å¦‚ä½•è¾“å…¥u(Â·)çš„*è¿ç»­*è½®å»“ï¼Ÿ
- en: 'Well, we donâ€™t actually. A straightforward solution is to represent the function
    u(Â·) discretely. More specifically, we simply evaluate u(Â·) values at sufficient
    but finite many locations and subsequently feed those discrete u(Â·) values into
    the neural network:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œæˆ‘ä»¬å¹¶ä¸è¿™æ ·åšã€‚ä¸€ç§ç›´æ¥çš„è§£å†³æ–¹æ¡ˆæ˜¯ç¦»æ•£è¡¨ç¤ºå‡½æ•°u(Â·)ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬åªæ˜¯è¯„ä¼°u(Â·)åœ¨è¶³å¤Ÿä½†æœ‰é™çš„å¤šä¸ªä½ç½®çš„å€¼ï¼Œç„¶åå°†è¿™äº›ç¦»æ•£çš„u(Â·)å€¼è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¸­ï¼š
- en: '![](../Images/ae58b8b3d7bc0cd4b59923193cc0cea7.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae58b8b3d7bc0cd4b59923193cc0cea7.png)'
- en: Figure 6\. The u(Â·) profile is discretized before being fed into the neural
    network. (Image by author)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾6\. åœ¨è¢«è¾“å…¥åˆ°ç¥ç»ç½‘ç»œä¹‹å‰ï¼Œu(Â·)è½®å»“è¢«ç¦»æ•£åŒ–ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: Those locations are referred to as **sensors** in the original DeepONet paper.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ä½ç½®åœ¨åŸå§‹DeepONetè®ºæ–‡ä¸­è¢«ç§°ä¸º**ä¼ æ„Ÿå™¨**ã€‚
- en: 2ï¸âƒ£ How should we concatenate the input *t* and u(Â·)?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ æˆ‘ä»¬åº”è¯¥å¦‚ä½•å°†è¾“å…¥*t*å’Œu(Â·)æ‹¼æ¥åœ¨ä¸€èµ·ï¼Ÿ
- en: At first sight, we might want to concatenate them directly at the input layer.
    However, it turns out that this naive approach will not only put a constraint
    on what types of neural networks we can use, but also lead to suboptimal prediction
    accuracy in practice. There is a better way though. Time to introduce **DeepONet**.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åˆçœ‹ä¹‹ä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæƒ³ç›´æ¥åœ¨è¾“å…¥å±‚å°†å®ƒä»¬æ‹¼æ¥èµ·æ¥ã€‚ç„¶è€Œï¼Œäº‹å®è¯æ˜ï¼Œè¿™ç§ç®€å•çš„æ–¹æ³•ä¸ä»…ä¼šé™åˆ¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„ç¥ç»ç½‘ç»œç±»å‹ï¼Œè€Œä¸”åœ¨å®è·µä¸­ä¼šå¯¼è‡´æ¬¡ä¼˜çš„é¢„æµ‹å‡†ç¡®åº¦ã€‚ä¸è¿‡ï¼Œè¿˜æœ‰æ›´å¥½çš„æ–¹æ³•ã€‚ç°åœ¨æ˜¯ä»‹ç»**DeepONet**çš„æ—¶å€™äº†ã€‚
- en: 'In a nutshell, DeepONet proposed a new network architecture for performing
    operator learning: it consists of two main components: **a branch network** and
    **a trunk network**. The branch network takes the discrete function values as
    inputs and transforms them into a feature vector. Meanwhile, the trunk network
    takes the coordinate(s) (in our current case study, the coordinate is just *t*.
    For PDEs, it will include both temporal and spatial coordinates) and also converts
    it/them into a feature vector with the same dimensions. These two feature vectors
    are then merged by a dot product, and the end result is used as the prediction
    of s(Â·) evaluated at the input coordinate.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä¹‹ï¼ŒDeepONetæå‡ºäº†ä¸€ç§ç”¨äºç®—å­å­¦ä¹ çš„æ–°ç½‘ç»œæ¶æ„ï¼šå®ƒç”±ä¸¤ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼š**åˆ†æ”¯ç½‘ç»œ**å’Œ**ä¸»å¹²ç½‘ç»œ**ã€‚åˆ†æ”¯ç½‘ç»œå°†ç¦»æ•£å‡½æ•°å€¼ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºç‰¹å¾å‘é‡ã€‚åŒæ—¶ï¼Œä¸»å¹²ç½‘ç»œå°†åæ ‡ï¼ˆåœ¨æˆ‘ä»¬å½“å‰çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œåæ ‡ä»…ä¸º*t*ã€‚å¯¹äºPDEï¼Œå°†åŒ…æ‹¬æ—¶é—´å’Œç©ºé—´åæ ‡ï¼‰ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶ä¹Ÿè½¬æ¢ä¸ºç›¸åŒç»´åº¦çš„ç‰¹å¾å‘é‡ã€‚è¿™ä¸¤ä¸ªç‰¹å¾å‘é‡ç„¶åé€šè¿‡ç‚¹ç§¯è¿›è¡Œåˆå¹¶ï¼Œæœ€ç»ˆç»“æœç”¨ä½œåœ¨è¾“å…¥åæ ‡å¤„è¯„ä¼°s(Â·)çš„é¢„æµ‹å€¼ã€‚
- en: '![](../Images/a38b151038114d79d87742355a9461fd.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a38b151038114d79d87742355a9461fd.png)'
- en: Figure 7\. A DeepONet consists of a **branch net** to handle the input function
    u(Â·) and a **trunk net** to handle the temporal/spatial coordinates. The outputs
    of two nets have the same dimensions and are merged via a dot product. Optionally,
    a bias term can be added after the dot product to further improve the model's
    expressibility. (Image by author)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾7\. DeepONetåŒ…æ‹¬ä¸€ä¸ª**åˆ†æ”¯ç½‘ç»œ**æ¥å¤„ç†è¾“å…¥å‡½æ•°u(Â·)å’Œä¸€ä¸ª**ä¸»å¹²ç½‘ç»œ**æ¥å¤„ç†æ—¶é—´/ç©ºé—´åæ ‡ã€‚ä¸¤ä¸ªç½‘ç»œçš„è¾“å‡ºå…·æœ‰ç›¸åŒçš„ç»´åº¦ï¼Œå¹¶é€šè¿‡ç‚¹ç§¯è¿›è¡Œåˆå¹¶ã€‚å¯é€‰åœ°ï¼Œå¯ä»¥åœ¨ç‚¹ç§¯åæ·»åŠ ä¸€ä¸ªåç½®é¡¹ä»¥è¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰
- en: In the original DeepONet paper, the authors stated that this â€œdivide-and-conquerâ€
    strategy, exemplified in separate â€œbranchâ€ and â€œtrunkâ€ networks, is inspired by
    the *universal approximation theorem for operator*, and serves to introduce a
    strong inductive bias specifically for operator learning. This is also the key
    point that makes DeepONet an effective solution, as claimed by the authors.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŸå§‹DeepONetè®ºæ–‡ä¸­ï¼Œä½œè€…æŒ‡å‡ºï¼Œè¿™ç§åœ¨â€œåˆ†æ”¯â€å’Œâ€œä¸»å¹²â€ç½‘ç»œä¸­ä½“ç°çš„â€œåˆ†è€Œæ²»ä¹‹â€ç­–ç•¥å—åˆ°*ç®—å­é€šç”¨é€¼è¿‘å®šç†*çš„å¯å‘ï¼Œæ—¨åœ¨ä¸ºç®—å­å­¦ä¹ å¼•å…¥å¼ºçš„å½’çº³åç½®ã€‚è¿™ä¹Ÿæ˜¯ä½œè€…å£°ç§°ä½¿DeepONetæˆä¸ºæœ‰æ•ˆè§£å†³æ–¹æ¡ˆçš„å…³é”®ç‚¹ã€‚
- en: If you are curious to learn more about theoritical basis of DeepONet, please
    refer to Appendix A in the original paper.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºDeepONetç†è®ºåŸºç¡€çš„å†…å®¹ï¼Œè¯·å‚è€ƒåŸå§‹è®ºæ–‡çš„é™„å½•Aã€‚
- en: One of the main strengths of DeepONet is its efficiency. Once trained, a DeepONet
    can infer the output function for a new input function in real-time, without the
    need for further training, as long as the new input function is within the range
    of input functions it was trained on. This makes DeepONet a powerful tool in applications
    that require real-time inference.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: DeepONetçš„ä¸»è¦ä¼˜åŠ¿ä¹‹ä¸€æ˜¯å…¶æ•ˆç‡ã€‚ä¸€æ—¦è®­ç»ƒå®Œæˆï¼ŒDeepONetå¯ä»¥å®æ—¶æ¨æ–­æ–°çš„è¾“å…¥å‡½æ•°çš„è¾“å‡ºå‡½æ•°ï¼Œæ— éœ€è¿›ä¸€æ­¥è®­ç»ƒï¼Œåªè¦æ–°çš„è¾“å…¥å‡½æ•°åœ¨å…¶è®­ç»ƒè¿‡çš„è¾“å…¥å‡½æ•°èŒƒå›´å†…ã€‚è¿™ä½¿DeepONetæˆä¸ºéœ€è¦å®æ—¶æ¨æ–­çš„åº”ç”¨ä¸­çš„å¼ºå¤§å·¥å…·ã€‚
- en: Another notable strength of DeepONet lies in its flexibility and versatility.
    While the most common choice for the trunk and branch networks might be fully-connected
    layers, the DeepONet framework permits a high level of architecture customization.
    Depending on the characteristics of the input function u(Â·) and the coordinates,
    a variety of neural network architectures such as CNN, RNN, etc. can also be employed.
    This adaptability makes DeepONet a highly versatile tool.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: DeepONetçš„å¦ä¸€ä¸ªæ˜¾è‘—ä¼˜åŠ¿åœ¨äºå…¶çµæ´»æ€§å’Œå¤šåŠŸèƒ½æ€§ã€‚è™½ç„¶ä¸»å¹²ç½‘ç»œå’Œåˆ†æ”¯ç½‘ç»œæœ€å¸¸è§çš„é€‰æ‹©æ˜¯å…¨è¿æ¥å±‚ï¼Œä½†DeepONetæ¡†æ¶å…è®¸é«˜åº¦çš„æ¶æ„è‡ªå®šä¹‰ã€‚æ ¹æ®è¾“å…¥å‡½æ•°u(Â·)å’Œåæ ‡çš„ç‰¹å¾ï¼Œå¯ä»¥é‡‡ç”¨å„ç§ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¦‚CNNã€RNNç­‰ã€‚è¿™ç§é€‚åº”æ€§ä½¿DeepONetæˆä¸ºä¸€ä¸ªé«˜åº¦å¤šåŠŸèƒ½çš„å·¥å…·ã€‚
- en: 'However, despite these strengths, the limitations of DeepONet are also prominent:
    as a purely data-driven method, DeepONet cannot guarantee that its predictions
    will follow prior knowledge or governing equations that describe the physical
    system under consideration. Consequently, DeepONet may not generalize well, especially
    when faced with input functions that lie outside the distribution of its training
    data, referred to as *out-of-distribution* (OOD) inputs. A common remedy for that
    is simply preparing a large amount of data for training, which might not always
    be feasible in practice, especially in scientific and engineering fields where
    data collection can be expensive or time-consuming.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå°½ç®¡å­˜åœ¨è¿™äº›ä¼˜åŠ¿ï¼ŒDeepONet çš„å±€é™æ€§ä¹Ÿå¾ˆæ˜æ˜¾ï¼šä½œä¸ºä¸€ç§çº¯æ•°æ®é©±åŠ¨çš„æ–¹æ³•ï¼ŒDeepONet ä¸èƒ½ä¿è¯å…¶é¢„æµ‹ç»“æœä¼šéµå¾ªæè¿°æ‰€è€ƒè™‘ç‰©ç†ç³»ç»Ÿçš„å…ˆéªŒçŸ¥è¯†æˆ–æ§åˆ¶æ–¹ç¨‹ã€‚å› æ­¤ï¼ŒDeepONet
    å¯èƒ½æ— æ³•å¾ˆå¥½åœ°æ³›åŒ–ï¼Œå°¤å…¶æ˜¯å½“é¢å¯¹ä½äºè®­ç»ƒæ•°æ®åˆ†å¸ƒä¹‹å¤–çš„è¾“å…¥å‡½æ•°ï¼Œå³*åˆ†å¸ƒå¤–*ï¼ˆOODï¼‰è¾“å…¥æ—¶ã€‚å¯¹æ­¤çš„ä¸€ä¸ªå¸¸è§è§£å†³æ–¹æ¡ˆæ˜¯å‡†å¤‡å¤§é‡è®­ç»ƒæ•°æ®ï¼Œä½†åœ¨å®é™…ä¸­è¿™å¯èƒ½å¹¶ä¸æ€»æ˜¯å¯è¡Œï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®æ”¶é›†å¯èƒ½æ˜‚è´µæˆ–è€—æ—¶çš„ç§‘å­¦å’Œå·¥ç¨‹é¢†åŸŸã€‚
- en: So how should we address these limitations? Time to talk about *physics-informed
    learning*, and more specifically, *physics-informed neural networks* (PINNs).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆæˆ‘ä»¬åº”è¯¥å¦‚ä½•è§£å†³è¿™äº›å±€é™æ€§å‘¢ï¼Ÿæ˜¯æ—¶å€™è®¨è®º*ç‰©ç†ä¿¡æ¯å­¦ä¹ *ï¼Œæ›´å…·ä½“åœ°è¯´ï¼Œæ˜¯*ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ*ï¼ˆPINNsï¼‰äº†ã€‚
- en: 2.2 Physics-informed Neural Networks (PINNs)
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œï¼ˆPINNsï¼‰
- en: In traditional machine learning models, we rely primarily on data to learn the
    underlying patterns. However, in many scientific and engineering fields, governing
    equations (ODE/PDEs) that captured our prior knowledge about the dynamical system
    are available, and they present another source of information we can leverage
    besides the observed data. This additional knowledge source, if incorporated correctly,
    could potentially improve the modelâ€™s performance and generalization ability,
    especially when dealing with limited or noisy data. This is where **physics-informed
    learning** comes into play.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬ä¸»è¦ä¾èµ–æ•°æ®æ¥å­¦ä¹ æ½œåœ¨çš„æ¨¡å¼ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šç§‘å­¦å’Œå·¥ç¨‹é¢†åŸŸï¼Œæ•æ‰æˆ‘ä»¬å¯¹åŠ¨æ€ç³»ç»Ÿçš„å…ˆéªŒçŸ¥è¯†çš„æ§åˆ¶æ–¹ç¨‹ï¼ˆODE/PDEï¼‰æ˜¯å¯ç”¨çš„ï¼Œå®ƒä»¬æä¾›äº†é™¤äº†è§‚å¯Ÿæ•°æ®ä¹‹å¤–çš„å¦ä¸€ç§ä¿¡æ¯æ¥æºã€‚å¦‚æœæ­£ç¡®åœ°å°†è¿™ä¸€é¢å¤–çš„çŸ¥è¯†æºçº³å…¥æ¨¡å‹ä¸­ï¼Œå®ƒå¯èƒ½ä¼šæ”¹å–„æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†æœ‰é™æˆ–å™ªå£°æ•°æ®æ—¶ã€‚è¿™å°±æ˜¯**ç‰©ç†ä¿¡æ¯å­¦ä¹ **çš„ä½œç”¨æ‰€åœ¨ã€‚
- en: When we merge the concept of physics-informed learning and neural networks,
    we would then arrive at **physics-informed neural networks** (PINNs).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å°†ç‰©ç†ä¿¡æ¯å­¦ä¹ ä¸ç¥ç»ç½‘ç»œçš„æ¦‚å¿µç»“åˆæ—¶ï¼Œæˆ‘ä»¬å°†å¾—åˆ°**ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ**ï¼ˆPINNsï¼‰ã€‚
- en: PINNs are a type of neural network where the network is trained to not only
    fit the data but also respect the known physical laws described by differential
    equations. This is achieved by introducing a **ODE/PDE loss**, which measures
    the degree of violation of the governing differential equations. This way, we
    inject the physical laws into the network training process and make it *physically
    informed*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: PINNs æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œï¼Œå…¶ä¸­ç½‘ç»œä¸ä»…ä»…æ˜¯æ‹Ÿåˆæ•°æ®ï¼Œè¿˜è¦å°Šé‡ç”±å¾®åˆ†æ–¹ç¨‹æè¿°çš„å·²çŸ¥ç‰©ç†å®šå¾‹ã€‚è¿™æ˜¯é€šè¿‡å¼•å…¥**ODE/PDE æŸå¤±**æ¥å®ç°çš„ï¼Œå®ƒæµ‹é‡äº†æ§åˆ¶å¾®åˆ†æ–¹ç¨‹çš„è¿åç¨‹åº¦ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å°†ç‰©ç†å®šå¾‹æ³¨å…¥ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ï¼Œä½¿å…¶*ç‰©ç†ä¿¡æ¯åŒ–*ã€‚
- en: '![](../Images/12cd012d9a10794979e59e1e28cfddaf.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12cd012d9a10794979e59e1e28cfddaf.png)'
- en: Figure 8\. The loss function of a physics-informed neural network includes a
    contribution term of PDE loss, which effectively measures if the predicted solution
    satisfies the governing differential equation. Note that the derivative of the
    output with respect to the inputs can be easily calculated thanks to **automatic
    differentiation**. (Image by author)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 8\. ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œçš„æŸå¤±å‡½æ•°åŒ…æ‹¬ PDE æŸå¤±çš„è´¡çŒ®é¡¹ï¼Œè¿™æœ‰æ•ˆåœ°æµ‹é‡äº†é¢„æµ‹è§£æ˜¯å¦æ»¡è¶³æ§åˆ¶å¾®åˆ†æ–¹ç¨‹ã€‚æ³¨æ„ï¼Œç”±äº**è‡ªåŠ¨å¾®åˆ†**çš„å­˜åœ¨ï¼Œç›¸å¯¹äºè¾“å…¥çš„è¾“å‡ºçš„å¯¼æ•°å¯ä»¥å¾ˆå®¹æ˜“åœ°è®¡ç®—å‡ºæ¥ã€‚ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…ï¼‰
- en: Though PINNs have proven to be effective in many applications, they are not
    without limitations. PINNs are typically trained for specific input parameters
    (e.g., boundary and initial conditions, external forcing, etc.). Consequently,
    whenever the input parameters have changed, we would need to retrain the PINN.
    Therefore, they are not particularly effective for real-time inference under different
    operating conditions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ PINNs åœ¨è®¸å¤šåº”ç”¨ä¸­å·²è¢«è¯æ˜æœ‰æ•ˆï¼Œä½†å®ƒä»¬ä¹Ÿä¸æ˜¯æ²¡æœ‰å±€é™æ€§ã€‚PINNs é€šå¸¸æ˜¯é’ˆå¯¹ç‰¹å®šçš„è¾“å…¥å‚æ•°ï¼ˆä¾‹å¦‚è¾¹ç•Œå’Œåˆå§‹æ¡ä»¶ã€å¤–éƒ¨å¼ºè¿«ç­‰ï¼‰è¿›è¡Œè®­ç»ƒçš„ã€‚å› æ­¤ï¼Œæ¯å½“è¾“å…¥å‚æ•°å‘ç”Ÿå˜åŒ–æ—¶ï¼Œæˆ‘ä»¬å°±éœ€è¦é‡æ–°è®­ç»ƒ
    PINNã€‚å› æ­¤ï¼Œå®ƒä»¬åœ¨ä¸åŒæ“ä½œæ¡ä»¶ä¸‹çš„å®æ—¶æ¨æ–­æ•ˆæœä¸æ˜¯ç‰¹åˆ«å¥½ã€‚
- en: Still remember which method is specifically designed for handling varying input
    parameters? Thatâ€™s right, itâ€™s the DeepONet! Time to combine the idea of physical-informed
    learning with DeepONet.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜è®°å¾—å“ªä¸ªæ–¹æ³•æ˜¯ä¸“é—¨ç”¨äºå¤„ç†å˜åŒ–çš„è¾“å…¥å‚æ•°çš„å—ï¼Ÿæ²¡é”™ï¼Œå°±æ˜¯DeepONetï¼ç°åœ¨æ˜¯å°†ç‰©ç†ä¿¡æ¯å­¦ä¹ çš„ç†å¿µä¸DeepONetç»“åˆçš„æ—¶å€™äº†ã€‚
- en: 2.3 Physics-informed DeepONet
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 ç‰©ç†ä¿¡æ¯DeepONet
- en: The main idea behind the *Physics-informed DeepONet* is to combine the strengths
    of both DeepONets and PINNs. Just like a DeepONet, a Physics-informed DeepONet
    is capable of taking a function as an input and producing a function as an output.
    This makes it highly efficient for real-time inference of new input functions,
    without the need for retraining.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç‰©ç†ä¿¡æ¯DeepONet*çš„ä¸»è¦æ€æƒ³æ˜¯ç»“åˆDeepONetså’ŒPINNsçš„ä¼˜ç‚¹ã€‚å°±åƒDeepONetä¸€æ ·ï¼Œç‰©ç†ä¿¡æ¯DeepONetèƒ½å¤Ÿå°†ä¸€ä¸ªå‡½æ•°ä½œä¸ºè¾“å…¥ï¼Œå¹¶äº§ç”Ÿä¸€ä¸ªå‡½æ•°ä½œä¸ºè¾“å‡ºã€‚è¿™ä½¿å¾—å®ƒåœ¨å®æ—¶æ¨æ–­æ–°è¾“å…¥å‡½æ•°æ—¶éå¸¸é«˜æ•ˆï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚'
- en: On the other hand, like a PINN, a Physics-informed DeepONet incorporates known
    physical laws into its learning process. These laws are introduced as additional
    constraints in the loss function during training. This approach allows the model
    to make physically consistent predictions, even when dealing with limited or noisy
    data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼ŒåƒPINNä¸€æ ·ï¼Œç‰©ç†ä¿¡æ¯DeepONetåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­èå…¥äº†å·²çŸ¥çš„ç‰©ç†å®šå¾‹ã€‚è¿™äº›å®šå¾‹ä½œä¸ºé¢å¤–çš„çº¦æŸå¼•å…¥åˆ°è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å‡½æ•°ä¸­ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—æ¨¡å‹å³ä½¿åœ¨å¤„ç†æœ‰é™æˆ–å˜ˆæ‚æ•°æ®æ—¶ï¼Œä¹Ÿèƒ½åšå‡ºç‰©ç†ä¸€è‡´çš„é¢„æµ‹ã€‚
- en: How do we achieve this integration? Similar to the PINNs, we add an extra loss
    contribution to measure how well the predictions of the model adhere to the known
    differential equation. By optimizing this loss function, the model learns to make
    predictions that are both data-consistent (if measurement data is provided during
    training) and physics-consistent.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¦‚ä½•å®ç°è¿™ç§æ•´åˆå‘¢ï¼Ÿç±»ä¼¼äºPINNsï¼Œæˆ‘ä»¬å¢åŠ ä¸€ä¸ªé¢å¤–çš„æŸå¤±é¡¹ï¼Œä»¥è¡¡é‡æ¨¡å‹çš„é¢„æµ‹å¦‚ä½•ç¬¦åˆå·²çŸ¥çš„å¾®åˆ†æ–¹ç¨‹ã€‚é€šè¿‡ä¼˜åŒ–è¿™ä¸ªæŸå¤±å‡½æ•°ï¼Œæ¨¡å‹å­¦ä¼šè¿›è¡Œæ•°æ®ä¸€è‡´ï¼ˆå¦‚æœåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æä¾›äº†æµ‹é‡æ•°æ®ï¼‰å’Œç‰©ç†ä¸€è‡´çš„é¢„æµ‹ã€‚
- en: '![](../Images/fd4998e3fb37d406d81d4671f96e3588.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd4998e3fb37d406d81d4671f96e3588.png)'
- en: Figure 10\. Physics-informed DeepONet uses DeepONet as the backbone architecture
    while leveraging the concept of physics-informed learning to train the model.
    This way, the trained physics-informed DeepONet is both data and physics-consistent.
    (Image by author)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾10\. ç‰©ç†ä¿¡æ¯DeepONetä½¿ç”¨DeepONetä½œä¸ºéª¨å¹²æ¶æ„ï¼ŒåŒæ—¶åˆ©ç”¨ç‰©ç†ä¿¡æ¯å­¦ä¹ çš„æ¦‚å¿µæ¥è®­ç»ƒæ¨¡å‹ã€‚è¿™æ ·ï¼Œè®­ç»ƒåçš„ç‰©ç†ä¿¡æ¯DeepONetæ—¢æ•°æ®ä¸€è‡´åˆç‰©ç†ä¸€è‡´ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰
- en: 'In summary, the Physics-informed DeepONet is a powerful tool that combines
    the best of both worlds: the efficiency of the DeepONet and the accuracy of physics-informed
    learning. It represents a promising approach to solving complex problems in fields
    where both real-time inference and physical consistency are crucial.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ç»“æ¥è¯´ï¼Œç‰©ç†ä¿¡æ¯DeepONetæ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œç»“åˆäº†ä¸¤è€…çš„ä¼˜åŠ¿ï¼šDeepONetçš„é«˜æ•ˆæ€§å’Œç‰©ç†ä¿¡æ¯å­¦ä¹ çš„å‡†ç¡®æ€§ã€‚å®ƒä»£è¡¨äº†ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œç”¨äºè§£å†³é‚£äº›å®æ—¶æ¨æ–­å’Œç‰©ç†ä¸€è‡´æ€§éƒ½è‡³å…³é‡è¦çš„å¤æ‚é—®é¢˜ã€‚
- en: In the next section, we will start working on our case study and turn theory
    into actual code.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å¼€å§‹è¿›è¡Œæ¡ˆä¾‹ç ”ç©¶ï¼Œå¹¶å°†ç†è®ºè½¬åŒ–ä¸ºå®é™…ä»£ç ã€‚
- en: 3\. Implementation of Physics-informed DeepONet
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. ç‰©ç†ä¿¡æ¯DeepONetçš„å®ç°
- en: 'In this section, we will walk through how to define a Physics-informed DeepONet
    model to address our target case study. We will implement it in TensorFlow. Letâ€™s
    start with importing the necessary libraries:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è¯¦ç»†è®²è§£å¦‚ä½•å®šä¹‰ä¸€ä¸ªç‰©ç†ä¿¡æ¯DeepONetæ¨¡å‹ï¼Œä»¥è§£å†³æˆ‘ä»¬çš„ç›®æ ‡æ¡ˆä¾‹ç ”ç©¶ã€‚æˆ‘ä»¬å°†ä½¿ç”¨TensorFlowæ¥å®ç°å®ƒã€‚è®©æˆ‘ä»¬å…ˆå¯¼å…¥å¿…è¦çš„åº“ï¼š
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 3.1 Define the Architecture
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 å®šä¹‰æ¶æ„
- en: 'As discussed previously, physics-informed DeepONet shares the same architecture
    as the original DeepONet. The following function defines the architecture for
    DeepONet:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œç‰©ç†ä¿¡æ¯DeepONetä¸åŸå§‹DeepONetå…·æœ‰ç›¸åŒçš„æ¶æ„ã€‚ä»¥ä¸‹å‡½æ•°å®šä¹‰äº†DeepONetçš„æ¶æ„ï¼š
- en: '[PRE1]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the code above:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼š
- en: We assume that both the trunk and branch networks are fully connected networks,
    with 3 hidden layers, each containing 50 neurons and with tanh activation function.
    This architecture is chosen based on preliminary tests and should serve as a good
    starting point for this problem. Nevertheless, it is straightforward to replace
    it with other architectures (e.g., CNN, RNN, etc.) and other layer hyperparameters.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å‡è®¾ä¸»å¹²ç½‘ç»œå’Œåˆ†æ”¯ç½‘ç»œéƒ½æ˜¯å®Œå…¨è¿æ¥çš„ç½‘ç»œï¼Œæ¯ä¸ªç½‘ç»œæœ‰3ä¸ªéšè—å±‚ï¼Œæ¯å±‚åŒ…å«50ä¸ªç¥ç»å…ƒï¼Œå¹¶ä¸”ä½¿ç”¨tanhæ¿€æ´»å‡½æ•°ã€‚è¿™ä¸ªæ¶æ„æ˜¯åŸºäºåˆæ­¥æµ‹è¯•é€‰æ‹©çš„ï¼Œå¹¶ä¸”åº”è¯¥ä½œä¸ºè¿™ä¸ªé—®é¢˜çš„ä¸€ä¸ªè‰¯å¥½çš„èµ·ç‚¹ã€‚ç„¶è€Œï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°ç”¨å…¶ä»–æ¶æ„ï¼ˆä¾‹å¦‚CNNã€RNNç­‰ï¼‰å’Œå…¶ä»–å±‚è¶…å‚æ•°è¿›è¡Œæ›¿æ¢ã€‚
- en: 'The outputs of trunk and branch networks are merged via a dot product. As suggested
    in the [original DeepONet paper](https://arxiv.org/abs/1910.03193), we add a bias
    term to improve the prediction accuracy. The `BiasLayer()` is a custom-defined
    class to achieve that goal:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸»å¹²ç½‘ç»œå’Œåˆ†æ”¯ç½‘ç»œçš„è¾“å‡ºé€šè¿‡ç‚¹ç§¯åˆå¹¶ã€‚æ­£å¦‚[åŸå§‹ DeepONet è®ºæ–‡](https://arxiv.org/abs/1910.03193)ä¸­å»ºè®®çš„ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªåç½®é¡¹ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚`BiasLayer()`æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰å®šä¹‰çš„ç±»ï¼Œç”¨äºå®ç°è¿™ä¸ªç›®æ ‡ï¼š
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 3.2 Define ODE loss
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 å®šä¹‰ODEæŸå¤±
- en: 'Next, we define a function to compute the ODE loss. Recall that our target
    ODE is:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—ODEæŸå¤±ã€‚å›é¡¾ä¸€ä¸‹æˆ‘ä»¬çš„ç›®æ ‡ODEæ˜¯ï¼š
- en: '![](../Images/a2965a8118cbca756dc4b2c9fbbb113a.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2965a8118cbca756dc4b2c9fbbb113a.png)'
- en: 'Therefore, we can define the function as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼å®šä¹‰è¯¥å‡½æ•°ï¼š
- en: '[PRE3]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the code above:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼š
- en: We used `tf.GradientTape()` to calculate the gradient of s(Â·) with respect to
    *t*. Note that in TensorFlow, `tf.GradientTape()` is used as a context manager,
    and any operations executed within the tapeâ€™s context will be recorded by the
    tape. Here, we explicitly watch the variable *t*.As a result,TensorFlow will automatically
    track all operations that involve *t*,which in this case, itâ€™s a forward running
    of the DeepONet model. Afterward, we use tapeâ€™s `gradient()` method to calculate
    the gradient of s(Â·) with respect to *t*.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`tf.GradientTape()`æ¥è®¡ç®—s(Â·)ç›¸å¯¹äº*t*çš„æ¢¯åº¦ã€‚è¯·æ³¨æ„ï¼Œåœ¨TensorFlowä¸­ï¼Œ`tf.GradientTape()`ä½œä¸ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ä½¿ç”¨ï¼Œä»»ä½•åœ¨tapeä¸Šä¸‹æ–‡ä¸­æ‰§è¡Œçš„æ“ä½œéƒ½ä¼šè¢«tapeè®°å½•ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ˜¾å¼åœ°è§‚å¯Ÿå˜é‡*t*ã€‚å› æ­¤ï¼ŒTensorFlowä¼šè‡ªåŠ¨è·Ÿè¸ªæ¶‰åŠ*t*çš„æ‰€æœ‰æ“ä½œï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒæ˜¯DeepONetæ¨¡å‹çš„å‰å‘ä¼ æ’­ã€‚ä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨tapeçš„`gradient()`æ–¹æ³•æ¥è®¡ç®—s(Â·)ç›¸å¯¹äº*t*çš„æ¢¯åº¦ã€‚
- en: We included an extra input argument `u_t`, which denotes the value of the input
    function u(Â·) evaluated at *t*. This constitutes the right-hand-side term of our
    target ODE, and it is needed for calculating the ODE residual loss.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åŒ…æ‹¬äº†ä¸€ä¸ªé¢å¤–çš„è¾“å…¥å‚æ•°`u_t`ï¼Œå®ƒè¡¨ç¤ºåœ¨*t*æ—¶åˆ»è¯„ä¼°çš„è¾“å…¥å‡½æ•°u(Â·)çš„å€¼ã€‚è¿™æ„æˆäº†æˆ‘ä»¬ç›®æ ‡ODEçš„å³ä¾§é¡¹ï¼Œå¹¶ä¸”å®ƒæ˜¯è®¡ç®—ODEæ®‹å·®æŸå¤±æ‰€éœ€çš„ã€‚
- en: We used `@tf.function` decorator to convert the regular Python function we just
    defined into a TensorFlow graph. It is useful to do that as gradient calculation
    can be quite expensive and executing it in Graph mode can significantly accelerate
    the computations.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`@tf.function`è£…é¥°å™¨å°†æˆ‘ä»¬åˆšåˆšå®šä¹‰çš„å¸¸è§„Pythonå‡½æ•°è½¬æ¢ä¸ºTensorFlowå›¾ã€‚è¿™æ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºæ¢¯åº¦è®¡ç®—å¯èƒ½éå¸¸æ˜‚è´µï¼Œå¹¶ä¸”åœ¨å›¾æ¨¡å¼ä¸‹æ‰§è¡Œå¯ä»¥æ˜¾è‘—åŠ é€Ÿè®¡ç®—ã€‚
- en: 3.3 Define gradient descent step
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 å®šä¹‰æ¢¯åº¦ä¸‹é™æ­¥éª¤
- en: 'Next, we define the function to compile the total loss function and calculate
    the gradients of total loss with respect to the network model parameters:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥ç¼–è¯‘æ€»æŸå¤±å‡½æ•°å¹¶è®¡ç®—æ€»æŸå¤±ç›¸å¯¹äºç½‘ç»œæ¨¡å‹å‚æ•°çš„æ¢¯åº¦ï¼š
- en: '[PRE4]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the code above:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼š
- en: 'We only consider two loss terms: the loss associated with the initial condition
    `IC_loss`, and the ODE residual loss `ODE_loss`. The `IC_loss` is calculated by
    comparing the model-predicted s(*t*=0) with the known initial value of 0, and
    the `ODE_loss` is calculated by calling our previously defined `ODE_residual_calculator`
    function. Data loss can also be calculated and added to the total loss if the
    measured s(*t*) values are available (not implemented in the code above).'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åªè€ƒè™‘ä¸¤ä¸ªæŸå¤±é¡¹ï¼šä¸åˆå§‹æ¡ä»¶ç›¸å…³çš„æŸå¤±`IC_loss`å’ŒODEæ®‹å·®æŸå¤±`ODE_loss`ã€‚`IC_loss`é€šè¿‡å°†æ¨¡å‹é¢„æµ‹çš„s(*t*=0)ä¸å·²çŸ¥çš„åˆå§‹å€¼0è¿›è¡Œæ¯”è¾ƒæ¥è®¡ç®—ï¼Œ`ODE_loss`é€šè¿‡è°ƒç”¨æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„`ODE_residual_calculator`å‡½æ•°æ¥è®¡ç®—ã€‚å¦‚æœæœ‰å¯ç”¨çš„æµ‹é‡s(*t*)å€¼ï¼ˆåœ¨ä¸Šé¢çš„ä»£ç ä¸­æœªå®ç°ï¼‰ï¼Œæ•°æ®æŸå¤±ä¹Ÿå¯ä»¥è®¡ç®—å¹¶æ·»åŠ åˆ°æ€»æŸå¤±ä¸­ã€‚
- en: In general, the total loss is a weighted sum of `IC_loss` and `ODE_loss`, where
    the weights control how much emphasis or priority is given to that individual
    loss terms during the training process. In our case study, it is sufficient to
    simply set both `IC_weight` and `ODE_weight` as 1.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæ€»æŸå¤±æ˜¯`IC_loss`å’Œ`ODE_loss`çš„åŠ æƒå’Œï¼Œå…¶ä¸­æƒé‡æ§åˆ¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹è¿™äº›å•ç‹¬æŸå¤±é¡¹çš„é‡è§†ç¨‹åº¦æˆ–ä¼˜å…ˆçº§ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œå°†`IC_weight`å’Œ`ODE_weight`éƒ½è®¾ç½®ä¸º1å°±è¶³å¤Ÿäº†ã€‚
- en: Similar to how we compute the `ODE_loss`, we also adopted `tf.GradientTape()`
    as the context manager to calculate the gradients. However, here we calculate
    the gradients of the total loss with respect to the network model parameters,
    which are necessary to perform gradient descent.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äºæˆ‘ä»¬è®¡ç®—`ODE_loss`çš„æ–¹å¼ï¼Œæˆ‘ä»¬ä¹Ÿé‡‡ç”¨äº†`tf.GradientTape()`ä½œä¸ºä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¥è®¡ç®—æ¢¯åº¦ã€‚ç„¶è€Œï¼Œè¿™é‡Œæˆ‘ä»¬è®¡ç®—çš„æ˜¯æ€»æŸå¤±ç›¸å¯¹äºç½‘ç»œæ¨¡å‹å‚æ•°çš„æ¢¯åº¦ï¼Œè¿™å¯¹äºæ‰§è¡Œæ¢¯åº¦ä¸‹é™æ˜¯å¿…è¦çš„ã€‚
- en: 'Before we proceed, letâ€™s quickly summarize what we have developed so far:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»§ç»­ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å¿«é€Ÿæ€»ç»“ä¸€ä¸‹æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢æ‰€å¼€å‘çš„å†…å®¹ï¼š
- en: 1ï¸âƒ£ We can initialize a DeepONet model with `create_model()` function.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`create_model()`å‡½æ•°åˆå§‹åŒ–ä¸€ä¸ªDeepONetæ¨¡å‹ã€‚
- en: 2ï¸âƒ£ We can calculate ODE residuals to assess how well the model predictions
    stick to the governing ODE. This is achieved with `ODE_residual_calculator` function.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ æˆ‘ä»¬å¯ä»¥è®¡ç®—ODEæ®‹å·®ï¼Œä»¥è¯„ä¼°æ¨¡å‹é¢„æµ‹ä¸æ‰€æ²»ç†ODEçš„å¥‘åˆç¨‹åº¦ã€‚è¿™æ˜¯é€šè¿‡`ODE_residual_calculator`å‡½æ•°å®ç°çš„ã€‚
- en: 3ï¸âƒ£ We can calculate the total loss as well as its gradients with respect to
    the network model parameters with `train_step`.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`train_step`è®¡ç®—æ€»æŸå¤±åŠå…¶ç›¸å¯¹äºç½‘ç»œæ¨¡å‹å‚æ•°çš„æ¢¯åº¦ã€‚
- en: Now the preparation work is half done ğŸš€ In the next section, we will discuss
    data generation and data organization issues (the strange `X[:, :1]`in the code
    above will hopefully become clear then). After that, we can finally train the
    model and see how it performs.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨å‡†å¤‡å·¥ä½œå®Œæˆäº†ä¸€åŠğŸš€ åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºæ•°æ®ç”Ÿæˆå’Œæ•°æ®ç»„ç»‡çš„é—®é¢˜ï¼ˆä¸Šè¿°ä»£ç ä¸­çš„å¥‡æ€ª`X[:, :1]`ä¼šåœ¨é‚£æ—¶å˜å¾—æ¸…æ™°ï¼‰ã€‚ä¹‹åï¼Œæˆ‘ä»¬ç»ˆäºå¯ä»¥è®­ç»ƒæ¨¡å‹å¹¶æŸ¥çœ‹å…¶è¡¨ç°ã€‚
- en: 4\. Data Generation and Organization
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. æ•°æ®ç”Ÿæˆå’Œç»„ç»‡
- en: In this section, we discuss the generation of synthetic data and how to organize
    it for training the Physics-informed DeepONet model.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºåˆæˆæ•°æ®çš„ç”ŸæˆåŠå…¶åœ¨è®­ç»ƒPhysics-informed DeepONetæ¨¡å‹ä¸­çš„ç»„ç»‡æ–¹å¼ã€‚
- en: 4.1 Generation of u(Â·) profiles
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 ç”Ÿæˆu(Â·)ç‰¹å¾
- en: 'The data used for training, validation, and testing will be synthetically generated.
    The rationale behind this approach is twofold: itâ€™s not only convenient but also
    allows for full control over the dataâ€™s characteristics.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•çš„æ•°æ®å°†æ˜¯åˆæˆç”Ÿæˆçš„ã€‚è¿™æ ·åšçš„ç†ç”±æœ‰ä¸¤ä¸ªï¼šä¸ä»…æ–¹ä¾¿ï¼Œè€Œä¸”å¯ä»¥å®Œå…¨æ§åˆ¶æ•°æ®çš„ç‰¹å¾ã€‚
- en: In the context of our case study, we will generate the input function `u(Â·)`using
    a zero-mean **Gaussian Process**, with a radial basis function (RBF) kernel.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é›¶å‡å€¼çš„**é«˜æ–¯è¿‡ç¨‹**ç”Ÿæˆè¾“å…¥å‡½æ•°u(Â·)ï¼Œå¹¶ä½¿ç”¨å¾„å‘åŸºå‡½æ•°ï¼ˆRBFï¼‰æ ¸ã€‚
- en: A Gaussian Process is a powerful mathematical framework commonly used in machine
    learning to model functions. The RBF kernel is a popular choice for capturing
    the similarity between input points. By using the RBF kernel within the Gaussian
    Process, we ensure that the generated synthetic data exhibits a smooth and continuous
    pattern, which is often desirable in various applications. To learn more about
    Gaussian Process, feel free to checkout my previous [blog](https://medium.com/towards-data-science/implement-a-gaussian-process-from-scratch-2a074a470bce).
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: é«˜æ–¯è¿‡ç¨‹æ˜¯ä¸€ç§å¼ºå¤§çš„æ•°å­¦æ¡†æ¶ï¼Œå¸¸ç”¨äºæœºå™¨å­¦ä¹ ä¸­å»ºæ¨¡å‡½æ•°ã€‚RBFæ ¸æ˜¯æ•æ‰è¾“å…¥ç‚¹ä¹‹é—´ç›¸ä¼¼æ€§çš„çƒ­é—¨é€‰æ‹©ã€‚é€šè¿‡åœ¨é«˜æ–¯è¿‡ç¨‹ä¸­ä½¿ç”¨RBFæ ¸ï¼Œæˆ‘ä»¬ç¡®ä¿ç”Ÿæˆçš„åˆæˆæ•°æ®è¡¨ç°å‡ºå¹³æ»‘å’Œè¿ç»­çš„æ¨¡å¼ï¼Œè¿™åœ¨å„ç§åº”ç”¨ä¸­é€šå¸¸æ˜¯æœ‰åˆ©çš„ã€‚å¦‚éœ€äº†è§£æ›´å¤šå…³äºé«˜æ–¯è¿‡ç¨‹çš„å†…å®¹ï¼Œè¯·éšæ—¶æŸ¥çœ‹æˆ‘ä¹‹å‰çš„[åšå®¢](https://medium.com/towards-data-science/implement-a-gaussian-process-from-scratch-2a074a470bce)ã€‚
- en: 'In scikit-learn, this can be achieved in just a few lines of code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨scikit-learnä¸­ï¼Œè¿™å¯ä»¥é€šè¿‡å‡ è¡Œä»£ç å®ç°ï¼š
- en: '[PRE5]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the code above:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼š
- en: We use `length_scale`to control the shape of the generated function. For a RBF
    kernel, the Figure 11 shows the u(Â·) profile given different kernel length scales.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨`length_scale`æ¥æ§åˆ¶ç”Ÿæˆå‡½æ•°çš„å½¢çŠ¶ã€‚å¯¹äºRBFæ ¸ï¼Œå›¾11å±•ç¤ºäº†ä¸åŒæ ¸é•¿åº¦å°ºåº¦ä¸‹çš„u(Â·)ç‰¹å¾ã€‚
- en: Recall that we need to discretize u(Â·) before feeding it to the DeepONet. This
    is done by specifying a`X_sample` variable, which allocates 100 uniformly distributed
    points within our interested temporal domain.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯·è®°ä½ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å°†u(Â·)è¾“å…¥DeepONetä¹‹å‰å¯¹å…¶è¿›è¡Œç¦»æ•£åŒ–ã€‚è¿™æ˜¯é€šè¿‡æŒ‡å®š`X_sample`å˜é‡æ¥å®Œæˆçš„ï¼Œè¯¥å˜é‡åœ¨æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ—¶é—´åŸŸå†…åˆ†é…100ä¸ªå‡åŒ€åˆ†å¸ƒçš„ç‚¹ã€‚
- en: In scikit-learn, the `GaussianProcessRegressor` object exposes a `sample_y`
    method to allow drawing random samples from the Gaussian process with the length-scale-specified
    kernel. Note that we didnâ€™t call `.fit()` before using the `GaussianProcessRegressor`
    object, which is unlike what we normally do with other scikit-learn regressors.
    This is intentional as we want `GaussianProcessRegressor` to use the **exact**
    `length_scale` we provided. If you call `.fit()` , the `length_scale`will be optimized
    to another value to better fit whatever data is given.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨scikit-learnä¸­ï¼Œ`GaussianProcessRegressor`å¯¹è±¡æä¾›äº†ä¸€ä¸ª`sample_y`æ–¹æ³•ï¼Œç”¨äºä»å…·æœ‰é•¿åº¦å°ºåº¦æŒ‡å®šæ ¸çš„é«˜æ–¯è¿‡ç¨‹æŠ½å–éšæœºæ ·æœ¬ã€‚æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨`GaussianProcessRegressor`å¯¹è±¡ä¹‹å‰å¹¶æ²¡æœ‰è°ƒç”¨`.fit()`ï¼Œè¿™ä¸æˆ‘ä»¬é€šå¸¸å¯¹å…¶ä»–scikit-learnå›å½’å™¨çš„åšæ³•ä¸åŒã€‚è¿™æ˜¯æ•…æ„çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›`GaussianProcessRegressor`ä½¿ç”¨æˆ‘ä»¬æä¾›çš„**ç²¾ç¡®**`length_scale`ã€‚å¦‚æœä½ è°ƒç”¨`.fit()`ï¼Œ`length_scale`å°†è¢«ä¼˜åŒ–ä¸ºå¦ä¸€ä¸ªå€¼ä»¥æ›´å¥½åœ°æ‹Ÿåˆç»™å®šçš„æ•°æ®ã€‚
- en: The output `u_sample` is a matrix with a dimension of sample_num * 100\. Each
    row of `u_sample`represents one profile of u(Â·), which consists of 100 discrete
    values.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¾“å‡º`u_sample`æ˜¯ä¸€ä¸ªç»´åº¦ä¸ºsample_num * 100çš„çŸ©é˜µã€‚`u_sample`çš„æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªu(Â·)çš„ç‰¹å¾ï¼Œå…¶ä¸­åŒ…å«100ä¸ªç¦»æ•£å€¼ã€‚
- en: '![](../Images/c2ac5842757f39f116035a152bcba09c.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2ac5842757f39f116035a152bcba09c.png)'
- en: Figure 11\. Synthetic u(Â·) profiles under different kernel length scales. (Image
    by author)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 11\. åœ¨ä¸åŒæ ¸é•¿åº¦å°ºåº¦ä¸‹çš„åˆæˆ u(Â·) è½®å»“ã€‚ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…ï¼‰
- en: 4.2 Generation of Dataset
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 æ•°æ®é›†ç”Ÿæˆ
- en: Now we have generated the u(Â·) profiles, letâ€™s focus on how to get the dataset
    organized such that it can be fed into the DeepONet model.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ç”Ÿæˆäº† u(Â·) è½®å»“ï¼Œè®©æˆ‘ä»¬å…³æ³¨å¦‚ä½•ç»„ç»‡æ•°æ®é›†ï¼Œä»¥ä¾¿å®ƒå¯ä»¥è¾“å…¥åˆ° DeepONet æ¨¡å‹ä¸­ã€‚
- en: 'Recall that the DeepONet model we developed in the last section requires 3
    inputs:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·è®°ä½ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­å¼€å‘çš„ DeepONet æ¨¡å‹éœ€è¦ 3 ä¸ªè¾“å…¥ï¼š
- en: the time coordinate *t*, which is a scalar between 0 and 1 (letâ€™s not consider
    batch size for the moment);
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ—¶é—´åæ ‡ *t*ï¼Œè¿™æ˜¯ä»‹äº 0 å’Œ 1 ä¹‹é—´çš„æ ‡é‡ï¼ˆæš‚æ—¶ä¸è€ƒè™‘æ‰¹é‡å¤§å°ï¼‰ï¼›
- en: the profile of u(Â·), which is a vector that consists of u(Â·) values evaluated
    at pre-defined, fixed time coordinates between 0 and 1;
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: u(Â·) çš„è½®å»“ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±åœ¨é¢„å®šä¹‰çš„ã€å›ºå®šçš„æ—¶é—´åæ ‡ï¼ˆä»‹äº 0 å’Œ 1 ä¹‹é—´ï¼‰ä¸‹è¯„ä¼°çš„ u(Â·) å€¼ç»„æˆçš„å‘é‡ï¼›
- en: the value of u(*t*), which is again a scalar. This u(*t*) value is used for
    calculating the ODE loss at time coordinate *t*.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: u(*t*) çš„å€¼ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªæ ‡é‡ã€‚è¿™ä¸ª u(*t*) å€¼ç”¨äºåœ¨æ—¶é—´åæ ‡ *t* ä¸‹è®¡ç®— ODE æŸå¤±ã€‚
- en: 'Therefore, we can formulate a single sample like this:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·æ„å»ºä¸€ä¸ªå•ä¸€çš„æ ·æœ¬ï¼š
- en: '![](../Images/9e06a941b6ccf75fa9eea11abc4f72ec.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e06a941b6ccf75fa9eea11abc4f72ec.png)'
- en: (Image by author)
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…ï¼‰
- en: 'Of course, for each u(Â·) profile (marked as green in the above illustration),
    we should consider multiple *t*â€™s (and the corresponding u(*t*)â€™s) to evaluate
    the ODE loss to better impose the physical constraints. In theory, *t* can take
    any value within the considered temporal domain (i.e., between 0 and 1 for our
    case study). However, to simplify things, we will just consider *t* at the same
    temporal locations where u(Â·) profile is discretized. As a result, our updated
    dataset will be like this:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œå¯¹äºæ¯ä¸ª u(Â·) è½®å»“ï¼ˆåœ¨ä¸Šå›¾ä¸­æ ‡è®°ä¸ºç»¿è‰²ï¼‰ï¼Œæˆ‘ä»¬åº”è€ƒè™‘å¤šä¸ª *t*ï¼ˆåŠå…¶å¯¹åº”çš„ u(*t*)ï¼‰æ¥è¯„ä¼° ODE æŸå¤±ï¼Œä»¥æ›´å¥½åœ°æ–½åŠ ç‰©ç†çº¦æŸã€‚ç†è®ºä¸Šï¼Œ*t*
    å¯ä»¥å–è€ƒè™‘çš„æ—¶é—´åŸŸå†…çš„ä»»ä½•å€¼ï¼ˆå³åœ¨æˆ‘ä»¬æ¡ˆä¾‹ç ”ç©¶ä¸­ä¸º 0 å’Œ 1 ä¹‹é—´ï¼‰ã€‚ç„¶è€Œï¼Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªè€ƒè™‘åœ¨ u(Â·) è½®å»“ç¦»æ•£åŒ–çš„ç›¸åŒæ—¶é—´ä½ç½®çš„ *t*ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ›´æ–°åçš„æ•°æ®é›†å°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/c89b66eaa705cd09390e8d33454a29a5.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c89b66eaa705cd09390e8d33454a29a5.png)'
- en: (Image by author)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…ï¼‰
- en: 'Note that the above discussion only considers a single u(Â·) profile. If we
    take into account all the u(Â·) profiles, our final dataset would look like this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä¸Šè¿°è®¨è®ºä»…è€ƒè™‘äº†å•ä¸€çš„ u(Â·) è½®å»“ã€‚å¦‚æœæˆ‘ä»¬è€ƒè™‘æ‰€æœ‰çš„ u(Â·) è½®å»“ï¼Œæˆ‘ä»¬çš„æœ€ç»ˆæ•°æ®é›†å°†å¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/965b81f6b516c9f31326541d2de87f7e.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/965b81f6b516c9f31326541d2de87f7e.png)'
- en: (Image by author)
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆå›¾ç‰‡æ¥æºï¼šä½œè€…ï¼‰
- en: 'where N stands for the number of u(Â·) profiles. Now with that in mind, letâ€™s
    see some code:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ N ä»£è¡¨ u(Â·) è½®å»“çš„æ•°é‡ã€‚ç°åœ¨æœ‰äº†è¿™ä¸ªå‰æï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ä¸€äº›ä»£ç ï¼š
- en: '[PRE6]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the code above, we add one option of computing the corresponding s(Â·) for
    a given u(Â·) profile. **Although we wonâ€™t use s(Â·) values in training, we would
    still need them for testing the model performance.** The calculation of s(Â·) is
    achieved by using `scipy.integrate.solve_ivp`, which is an ODE solver from SciPy
    that is specifically designed to solve initial value problems.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°ä»£ç ä¸­ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªé€‰é¡¹ï¼Œç”¨äºè®¡ç®—ç»™å®š u(Â·) è½®å»“çš„ç›¸åº” s(Â·)ã€‚**è™½ç„¶æˆ‘ä»¬åœ¨è®­ç»ƒä¸­ä¸ä¼šä½¿ç”¨ s(Â·) å€¼ï¼Œä½†æˆ‘ä»¬ä»ç„¶éœ€è¦å®ƒä»¬æ¥æµ‹è¯•æ¨¡å‹æ€§èƒ½ã€‚**
    s(Â·) çš„è®¡ç®—æ˜¯é€šè¿‡ä½¿ç”¨ `scipy.integrate.solve_ivp` å®ç°çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¥è‡ª SciPy çš„ ODE æ±‚è§£å™¨ï¼Œä¸“é—¨è®¾è®¡ç”¨äºè§£å†³åˆå€¼é—®é¢˜ã€‚
- en: Now we can generate the training, validation, and testing dataset. Note that
    for this case study, we will use a length scale of 0.4 to generate the u(Â·) profiles
    and train the physics-informed DeepONet.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥ç”Ÿæˆè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ã€‚è¯·æ³¨æ„ï¼Œå¯¹äºæœ¬æ¡ˆä¾‹ç ”ç©¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ 0.4 çš„é•¿åº¦å°ºåº¦ç”Ÿæˆ u(Â·) è½®å»“ï¼Œå¹¶è®­ç»ƒç‰©ç†ä¿¡æ¯ DeepONetã€‚
- en: '[PRE7]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 4.3 Dataset Organization
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 æ•°æ®é›†ç»„ç»‡
- en: Finally, we convert the NumPy array into the TensorFlow dataset objects to facilitate
    data ingestion.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å°† NumPy æ•°ç»„è½¬æ¢ä¸º TensorFlow æ•°æ®é›†å¯¹è±¡ï¼Œä»¥ä¾¿äºæ•°æ®è¾“å…¥ã€‚
- en: '[PRE8]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the code above, we create two distinct datasets: one for evaluating the
    ODE loss (`train_ds`), and the other for evaluating the initial condition loss
    (`ini_ds`). We have also pre-calculated the mean and variance values for *t* and
    u(Â·). Those values will be used to standardize the inputs.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸¤ä¸ªä¸åŒçš„æ•°æ®é›†ï¼šä¸€ä¸ªç”¨äºè¯„ä¼° ODE æŸå¤±ï¼ˆ`train_ds`ï¼‰ï¼Œå¦ä¸€ä¸ªç”¨äºè¯„ä¼°åˆå§‹æ¡ä»¶æŸå¤±ï¼ˆ`ini_ds`ï¼‰ã€‚æˆ‘ä»¬è¿˜é¢„å…ˆè®¡ç®—äº†
    *t* å’Œ u(Â·) çš„å‡å€¼å’Œæ–¹å·®ã€‚è¿™äº›å€¼å°†ç”¨äºæ ‡å‡†åŒ–è¾“å…¥ã€‚
- en: Thatâ€™s it for data generation and organization. Next up, we will kick off the
    model training and see how it performs.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç”Ÿæˆå’Œç»„ç»‡çš„éƒ¨åˆ†å°±åˆ°è¿™é‡Œã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¯åŠ¨æ¨¡å‹è®­ç»ƒå¹¶æŸ¥çœ‹å…¶è¡¨ç°ã€‚
- en: 5\. Training Physics-informed DeepONet
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. è®­ç»ƒç‰©ç†ä¿¡æ¯ DeepONet
- en: 'As a first step, letâ€™s create a custom class to track loss evolutions:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºç¬¬ä¸€æ­¥ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰ç±»æ¥è·Ÿè¸ªæŸå¤±æ¼”å˜ï¼š
- en: '[PRE9]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we define the main training/validation logic:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸»è¦çš„è®­ç»ƒ/éªŒè¯é€»è¾‘ï¼š
- en: '[PRE10]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Itâ€™s a rather long chunk of code, but it should be self-explanatory as we have
    already covered all the important pieces.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€æ®µç›¸å½“é•¿çš„ä»£ç ï¼Œä½†å®ƒåº”è¯¥æ˜¯è‡ªè§£é‡Šçš„ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»è¦†ç›–äº†æ‰€æœ‰é‡è¦éƒ¨åˆ†ã€‚
- en: 'To visualize the training performance, we can plot the loss convergence curves:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¯è§†åŒ–è®­ç»ƒæ€§èƒ½ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶æŸå¤±æ”¶æ•›æ›²çº¿ï¼š
- en: '[PRE11]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The training results look like this:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '![](../Images/847a256dd8a4e962b37c4816d044ab61.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/847a256dd8a4e962b37c4816d044ab61.png)'
- en: Figure 12\. Loss convergence plot. (Image by author)
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾12\. æŸå¤±æ”¶æ•›å›¾ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰
- en: 'In addition, we can also see how the prediction accuracy for one specific target
    s(Â·) evolves during the training:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŸä¸€ç‰¹å®šç›®æ ‡s(Â·)çš„é¢„æµ‹å‡†ç¡®æ€§å¦‚ä½•å˜åŒ–ï¼š
- en: At the beginning of the training, we can see a visible discrepancy between the
    model prediction and ground truth. However, toward the end of the training, the
    predicted s(Â·) converged to the ground truth. This indicates that our physics-informed
    DeepONet learns properly.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒå¼€å§‹æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹é¢„æµ‹ä¸çœŸå®å€¼ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„å·®å¼‚ã€‚ç„¶è€Œï¼Œåˆ°è®­ç»ƒç»“æŸæ—¶ï¼Œé¢„æµ‹çš„s(Â·)å·²ç»æ”¶æ•›åˆ°çœŸå®å€¼ã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„ç‰©ç†ä¿¡æ¯æ·±åº¦ç½‘ç»œå­¦ä¹ å¾—å¾ˆå……åˆ†ã€‚
- en: 6\. Results Discussion
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. ç»“æœè®¨è®º
- en: Once the training is completed, we can reload the saved weights and assess the
    performance.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥é‡æ–°åŠ è½½ä¿å­˜çš„æƒé‡å¹¶è¯„ä¼°æ€§èƒ½ã€‚
- en: Here we randomly picked three u(Â·) profiles from the testing dataset and compare
    the corresponding s(Â·) predicted by our physics-informed DeepONet as well as calculated
    by the numerical ODE solver. We can see that the predictions and ground truth
    are almost indistinguishable.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éšæœºæŒ‘é€‰äº†ä¸‰ä¸ªu(Â·)è½®å»“ä»æµ‹è¯•æ•°æ®é›†ä¸­ï¼Œå¹¶å°†å…¶å¯¹åº”çš„s(Â·)ä¸æˆ‘ä»¬çš„ç‰©ç†ä¿¡æ¯æ·±åº¦ç½‘ç»œé¢„æµ‹çš„ç»“æœä»¥åŠç”±æ•°å€¼ODEæ±‚è§£å™¨è®¡ç®—çš„çœŸå®å€¼è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œé¢„æµ‹ç»“æœä¸çœŸå®å€¼å‡ ä¹æ— æ³•åŒºåˆ†ã€‚
- en: '![](../Images/f153e6df9a94a771c940ed219fafc0da.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f153e6df9a94a771c940ed219fafc0da.png)'
- en: Figure 13\. Three u(Â·) profiles are randomly selected from the testing dataset,
    which are shown on the upper row. The lower row displays the corresponding s(Â·)
    profiles. We can see that the results predicted by the physics-informed DeepONet
    are indistinguishable from the ground truth, which is calculated by numerical
    ODE solvers. (Image by author)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾13\. ä»æµ‹è¯•æ•°æ®é›†ä¸­éšæœºé€‰æ‹©äº†ä¸‰ä¸ªu(Â·)è½®å»“ï¼Œè¿™äº›è½®å»“æ˜¾ç¤ºåœ¨ä¸Šæ’ã€‚ä¸‹æ’æ˜¾ç¤ºäº†å¯¹åº”çš„s(Â·)è½®å»“ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç‰©ç†ä¿¡æ¯æ·±åº¦ç½‘ç»œé¢„æµ‹çš„ç»“æœä¸ç”±æ•°å€¼ODEæ±‚è§£å™¨è®¡ç®—çš„çœŸå®å€¼å‡ ä¹æ— æ³•åŒºåˆ†ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰
- en: These results are quite incredible, considering the fact that we didnâ€™t even
    use any observational data of s(Â·) (except the initial condition) to train the
    DeepONet. This shows that the governing ODE itself has provided sufficient â€œsupervisionâ€
    signal for the model to make accurate predictions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç»“æœç›¸å½“ä»¤äººæƒŠè®¶ï¼Œè€ƒè™‘åˆ°æˆ‘ä»¬ç”šè‡³æ²¡æœ‰ä½¿ç”¨ä»»ä½•s(Â·)çš„è§‚æµ‹æ•°æ®ï¼ˆé™¤äº†åˆå§‹æ¡ä»¶ï¼‰æ¥è®­ç»ƒDeepONetã€‚è¿™è¡¨æ˜æ§åˆ¶ODEæœ¬èº«ä¸ºæ¨¡å‹æä¾›äº†è¶³å¤Ÿçš„â€œç›‘ç£â€ä¿¡å·ï¼Œä»¥åšå‡ºå‡†ç¡®çš„é¢„æµ‹ã€‚
- en: Another interesting thing to assess is the so-called â€œout-of-distributionâ€ prediction
    capability. Since we enforced the governing equation when training the DeepONet,
    we can expect the trained physics-informed DeepONet to still be able to make decent
    predictions when the u(Â·) profiles lie outside the distribution of the training
    u(Â·)â€™s.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæœ‰è¶£çš„è¯„ä¼°ç‚¹æ˜¯æ‰€è°“çš„â€œåˆ†å¸ƒå¤–â€é¢„æµ‹èƒ½åŠ›ã€‚ç”±äºæˆ‘ä»¬åœ¨è®­ç»ƒDeepONetæ—¶å¼ºåˆ¶æ‰§è¡Œäº†æ§åˆ¶æ–¹ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æœŸè®­ç»ƒå¾—åˆ°çš„ç‰©ç†ä¿¡æ¯æ·±åº¦ç½‘ç»œåœ¨u(Â·)è½®å»“è¶…å‡ºè®­ç»ƒu(Â·)åˆ†å¸ƒæ—¶ä»èƒ½åšå‡ºä¸é”™çš„é¢„æµ‹ã€‚
- en: To test that, we can generate u(Â·) profiles using a different length scale.
    The following results showed three u(Â·) profiles generated with a length scale
    of 0.6, as well as the predicted s(Â·)â€™s. These results are quite nice, considering
    that the physics-informed DeepONet is trained with a length scale of 0.4.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æµ‹è¯•è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸åŒçš„é•¿åº¦å°ºåº¦ç”Ÿæˆu(Â·)è½®å»“ã€‚ä»¥ä¸‹ç»“æœæ˜¾ç¤ºäº†ä½¿ç”¨0.6é•¿åº¦å°ºåº¦ç”Ÿæˆçš„ä¸‰ä¸ªu(Â·)è½®å»“ï¼Œä»¥åŠé¢„æµ‹çš„s(Â·)ã€‚è¿™äº›ç»“æœç›¸å½“ä¸é”™ï¼Œè€ƒè™‘åˆ°ç‰©ç†ä¿¡æ¯æ·±åº¦ç½‘ç»œæ˜¯ç”¨0.4çš„é•¿åº¦å°ºåº¦è®­ç»ƒçš„ã€‚
- en: '![](../Images/8366942ba5deba3bcf17ad845f2af6ba.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8366942ba5deba3bcf17ad845f2af6ba.png)'
- en: Figure 14\. The trained physics-informed DeepONet displayed a certain level
    of out-of-distribution prediction capability. (Image by author)
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14\. è®­ç»ƒå¾—åˆ°çš„ç‰©ç†ä¿¡æ¯æ·±åº¦ç½‘ç»œæ˜¾ç¤ºäº†ä¸€å®šç¨‹åº¦çš„åˆ†å¸ƒå¤–é¢„æµ‹èƒ½åŠ›ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰
- en: However, if we keep reducing the length scale to 0.2, we would notice that visible
    discrepancies start to appear. This indicates that there is a limit on the generalization
    capability of the trained physics-informed DeepONet.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬ç»§ç»­å°†é•¿åº¦å°ºåº¦å‡å°åˆ°0.2ï¼Œæˆ‘ä»¬ä¼šæ³¨æ„åˆ°æ˜æ˜¾çš„å·®å¼‚å¼€å§‹å‡ºç°ã€‚è¿™è¡¨æ˜è®­ç»ƒå¾—åˆ°çš„ç‰©ç†ä¿¡æ¯æ·±åº¦ç½‘ç»œï¼ˆDeepONetï¼‰åœ¨æ³›åŒ–èƒ½åŠ›ä¸Šå­˜åœ¨é™åˆ¶ã€‚
- en: '![](../Images/9632515eaf22aa6a345dbb0c574bbf0e.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9632515eaf22aa6a345dbb0c574bbf0e.png)'
- en: Figure 15\. There is a limit on how far can physics-informed DeepONet generalize.
    (Image by author)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾15\. ç‰©ç†ä¿¡æ¯æ·±åº¦ONetçš„æ³›åŒ–èƒ½åŠ›æ˜¯æœ‰é™çš„ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾åƒï¼‰
- en: Smaller length scales in general lead to more complex u(Â·) profiles, which would
    be quite different than the u(Â·) profiles used for training. This could explain
    why the trained model encountered challenges in making accurate predictions in
    smaller length-scale regions.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: è¾ƒå°çš„é•¿åº¦å°ºåº¦é€šå¸¸ä¼šå¯¼è‡´æ›´å¤æ‚çš„u(Â·)è½®å»“ï¼Œè¿™ä¸ç”¨äºè®­ç»ƒçš„u(Â·)è½®å»“å¯èƒ½æœ‰å¾ˆå¤§ä¸åŒã€‚è¿™å¯ä»¥è§£é‡Šä¸ºä½•è®­ç»ƒåçš„æ¨¡å‹åœ¨è¾ƒå°é•¿åº¦å°ºåº¦åŒºåŸŸé¢„æµ‹å‡†ç¡®æ€§é‡åˆ°æŒ‘æˆ˜ã€‚
- en: '![](../Images/15e2cac7a0a905f565b4bfc01a6d2102.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15e2cac7a0a905f565b4bfc01a6d2102.png)'
- en: Figure 16\. Itâ€™s challenging for our trained model to generalize to smaller
    length-scale regions, as the u(Â·) profiles are more complex and distinct from
    the training data. (Image by author)
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾16\. æˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹åœ¨æ³›åŒ–åˆ°è¾ƒå°é•¿åº¦å°ºåº¦åŒºåŸŸæ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºu(Â·)è½®å»“æ›´å¤æ‚ï¼Œä¸è®­ç»ƒæ•°æ®æœ‰è¾ƒå¤§åŒºåˆ«ã€‚ï¼ˆä½œè€…æä¾›çš„å›¾åƒï¼‰
- en: Overall, we could say that the developed physics-informed DeepONet can properly
    learn the system dynamics and map from input function to output function given
    only the ODE constraints. In addition, physics-informed DeepONet displays a certain
    level of capability to handle â€œout-of-distributionâ€ predictions, indicating that
    training the model to align with the governing ODE improves the modelâ€™s generalization
    capability.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è¯´å¼€å‘çš„ç‰©ç†ä¿¡æ¯æ·±åº¦ONetèƒ½å¤Ÿåœ¨ä»…æœ‰ODEçº¦æŸçš„æƒ…å†µä¸‹æ­£ç¡®å­¦ä¹ ç³»ç»ŸåŠ¨æ€å’Œä»è¾“å…¥å‡½æ•°åˆ°è¾“å‡ºå‡½æ•°çš„æ˜ å°„ã€‚æ­¤å¤–ï¼Œç‰©ç†ä¿¡æ¯æ·±åº¦ONetåœ¨å¤„ç†â€œè¶…åˆ†å¸ƒâ€é¢„æµ‹æ–¹é¢æ˜¾ç¤ºå‡ºä¸€å®šçš„èƒ½åŠ›ï¼Œè¿™è¡¨æ˜è®­ç»ƒæ¨¡å‹ä¸æ§åˆ¶ODEå¯¹é½å¯ä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
- en: 7\. Take-away
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. æ”¶è·
- en: Weâ€™ve come a long way on our exploration of Physics-Informed DeepONet. From
    understanding the fundamental concepts of DeepONet and physics-informed learning,
    to seeing them in action through code implementation, weâ€™ve covered a lot about
    this powerful method of solving differential equations.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨æ¢ç´¢ç‰©ç†ä¿¡æ¯æ·±åº¦ONetçš„è¿‡ç¨‹ä¸­èµ°äº†å¾ˆé•¿ä¸€æ®µè·¯ã€‚ä»ç†è§£æ·±åº¦ONetå’Œç‰©ç†ä¿¡æ¯å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µï¼Œåˆ°é€šè¿‡ä»£ç å®ç°çœ‹åˆ°å®ƒä»¬çš„å®é™…åº”ç”¨ï¼Œæˆ‘ä»¬å·²ç»è¯¦ç»†è®²è§£äº†è¿™ä¸€å¼ºå¤§æ–¹æ³•åœ¨æ±‚è§£å¾®åˆ†æ–¹ç¨‹ä¸­çš„åº”ç”¨ã€‚
- en: 'Here are a few key take-aways:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰å‡ ç‚¹å…³é”®çš„æ”¶è·ï¼š
- en: 1ï¸âƒ£ **DeepONet** is a powerful framework to perform operator learning, thanks
    to its novel architecture of branch and trunk networks.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ **æ·±åº¦ONet**æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ“ä½œç¬¦å­¦ä¹ æ¡†æ¶ï¼Œå¾—ç›Šäºå…¶åˆ›æ–°çš„åˆ†æ”¯å’Œä¸»å¹²ç½‘ç»œæ¶æ„ã€‚
- en: 2ï¸âƒ£ **Physics-Informed Learning** explicitly incorporates governing differential
    equations of the dynamical system into the learning process, thus possessing the
    potential of improving the modelâ€™s interpretability and generalization ability.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ **ç‰©ç†ä¿¡æ¯å­¦ä¹ **æ˜ç¡®åœ°å°†åŠ¨æ€ç³»ç»Ÿçš„æ§åˆ¶å¾®åˆ†æ–¹ç¨‹çº³å…¥å­¦ä¹ è¿‡ç¨‹ï¼Œä»è€Œå…·æœ‰æé«˜æ¨¡å‹è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›çš„æ½œåŠ›ã€‚
- en: 3ï¸âƒ£ **Physics-Informed DeepONet** combines the strengths of DeepONet and physics-informed
    learning, and presents itself as a promising tool for learning functional mappings
    while adhering to the associated governing equations.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£ **ç‰©ç†ä¿¡æ¯æ·±åº¦ONet**ç»“åˆäº†æ·±åº¦ONetå’Œç‰©ç†ä¿¡æ¯å­¦ä¹ çš„ä¼˜åŠ¿ï¼Œå‘ˆç°å‡ºä½œä¸ºå­¦ä¹ åŠŸèƒ½æ˜ å°„çš„æœ‰å‰æ™¯å·¥å…·ï¼ŒåŒæ—¶éµå¾ªç›¸å…³çš„æ§åˆ¶æ–¹ç¨‹ã€‚
- en: Hope you have enjoyed this deep dive into Physics-Informed DeepONet. Next up,
    we will shift our gears toward solving inverse problems with physics-informed
    DeepONet. Stay tuned!
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢è¿™æ¬¡å¯¹**ç‰©ç†ä¿¡æ¯æ·±åº¦ONet**çš„æ·±å…¥æ¢è®¨ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è½¬å‘ä½¿ç”¨ç‰©ç†ä¿¡æ¯æ·±åº¦ONetè§£å†³é€†é—®é¢˜ã€‚æ•¬è¯·å…³æ³¨ï¼
- en: If you find my content useful, you could buy me a coffee [here](https://www.buymeacoffee.com/Shuaiguo09f)
    ğŸ¤— Thank you very much for your support!
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è§‰å¾—æˆ‘çš„å†…å®¹æœ‰ç”¨ï¼Œå¯ä»¥åœ¨[è¿™é‡Œ](https://www.buymeacoffee.com/Shuaiguo09f)è¯·æˆ‘å–æ¯å’–å•¡ğŸ¤— éå¸¸æ„Ÿè°¢ä½ çš„æ”¯æŒï¼
- en: You can find the companion notebook with full code [here](https://github.com/ShuaiGuo16/PI-DeepONet/tree/main)
    *ğŸ’»*
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/ShuaiGuo16/PI-DeepONet/tree/main)æ‰¾åˆ°åŒ…å«å®Œæ•´ä»£ç çš„è¾…åŠ©ç¬”è®°æœ¬
    *ğŸ’»*
- en: ''
  id: totrans-207
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you are also interested in using physics-informed DeepONet to solve inverse
    problems, feel free to check out my new blog here: [Solving Inverse Problems With
    Physics-Informed DeepONet: A Practical Guide With Code Implementation](/solving-inverse-problems-with-physics-informed-deeponet-a-practical-guide-with-code-implementation-27795eb4f502)'
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¹Ÿå¯¹ä½¿ç”¨ç‰©ç†ä¿¡æ¯æ·±åº¦ONetè§£å†³é€†é—®é¢˜æ„Ÿå…´è¶£ï¼Œè¯·éšæ—¶æŸ¥çœ‹æˆ‘çš„æ–°åšå®¢ï¼š[ä½¿ç”¨ç‰©ç†ä¿¡æ¯æ·±åº¦ONetè§£å†³é€†é—®é¢˜ï¼šå¸¦ä»£ç å®ç°çš„å®ç”¨æŒ‡å—](/solving-inverse-problems-with-physics-informed-deeponet-a-practical-guide-with-code-implementation-27795eb4f502)
- en: ''
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'If you would like to keep up to date with the best practices of physics-informed
    learning, please take a look at the design pattern series I am currently running:
    [Unraveling the Design Pattern of Physics-Informed Neural Networks](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)'
  id: totrans-210
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³äº†è§£æœ€æ–°çš„ç‰©ç†çŸ¥è¯†å­¦ä¹ æœ€ä½³å®è·µï¼Œè¯·æŸ¥çœ‹æˆ‘ç›®å‰æ­£åœ¨è¿›è¡Œçš„è®¾è®¡æ¨¡å¼ç³»åˆ—ï¼š[æ­ç¤ºç‰©ç†çŸ¥è¯†é©±åŠ¨ç¥ç»ç½‘ç»œçš„è®¾è®¡æ¨¡å¼](https://medium.com/towards-data-science/unraveling-the-design-pattern-of-physics-informed-neural-networks-series-01-8190df459527)
- en: ''
  id: totrans-211
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can also subscribe to my [newsletter](https://shuaiguo.medium.com/subscribe)
    or follow me on [Medium](https://shuaiguo.medium.com/).
  id: totrans-212
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥è®¢é˜…æˆ‘çš„[é€šè®¯](https://shuaiguo.medium.com/subscribe)æˆ–è€…åœ¨[Medium](https://shuaiguo.medium.com/)ä¸Šå…³æ³¨æˆ‘ã€‚
- en: Reference
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] Lu et al., DeepONet: Learning nonlinear operators for identifying differential
    equations based on the universal approximation theorem of operators. arXiv, 2019.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Luç­‰äººï¼ŒDeepONetï¼šåŸºäºç®—å­é€šç”¨è¿‘ä¼¼å®šç†çš„éçº¿æ€§ç®—å­å­¦ä¹ ï¼Œç”¨äºè¯†åˆ«å¾®åˆ†æ–¹ç¨‹ã€‚arXiv, 2019ã€‚'
- en: '[2] Wang et al., Learning the solution operator of parametric partial differential
    equations with physics-informed DeepOnets. arXiv, 2021.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Wangç­‰äººï¼Œå­¦ä¹ å‚æ•°åå¾®åˆ†æ–¹ç¨‹çš„è§£ç®—ç¬¦ï¼ŒåŸºäºç‰©ç†çŸ¥è¯†çš„DeepOnetsã€‚arXiv, 2021ã€‚'
