- en: Visualizing the Deconvolution Operation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化反卷积操作
- en: 原文：[https://towardsdatascience.com/visualizing-the-deconvolution-operation-8dad71577912?source=collection_archive---------12-----------------------#2023-02-17](https://towardsdatascience.com/visualizing-the-deconvolution-operation-8dad71577912?source=collection_archive---------12-----------------------#2023-02-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/visualizing-the-deconvolution-operation-8dad71577912?source=collection_archive---------12-----------------------#2023-02-17](https://towardsdatascience.com/visualizing-the-deconvolution-operation-8dad71577912?source=collection_archive---------12-----------------------#2023-02-17)
- en: A detailed breakdown of transposed convolutions operation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对转置卷积操作的详细拆解
- en: '[](https://medium.com/@vb.pogribnyi?source=post_page-----8dad71577912--------------------------------)[![Vitalii
    Pogribnyi](../Images/1dbdade2fcbd991225cfb92a67c30de2.png)](https://medium.com/@vb.pogribnyi?source=post_page-----8dad71577912--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8dad71577912--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8dad71577912--------------------------------)
    [Vitalii Pogribnyi](https://medium.com/@vb.pogribnyi?source=post_page-----8dad71577912--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vb.pogribnyi?source=post_page-----8dad71577912--------------------------------)[![Vitalii
    Pogribnyi](../Images/1dbdade2fcbd991225cfb92a67c30de2.png)](https://medium.com/@vb.pogribnyi?source=post_page-----8dad71577912--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8dad71577912--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8dad71577912--------------------------------)
    [Vitalii Pogribnyi](https://medium.com/@vb.pogribnyi?source=post_page-----8dad71577912--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3f609904004d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-deconvolution-operation-8dad71577912&user=Vitalii+Pogribnyi&userId=3f609904004d&source=post_page-3f609904004d----8dad71577912---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8dad71577912--------------------------------)
    ·11 min read·Feb 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8dad71577912&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-deconvolution-operation-8dad71577912&user=Vitalii+Pogribnyi&userId=3f609904004d&source=-----8dad71577912---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3f609904004d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-deconvolution-operation-8dad71577912&user=Vitalii+Pogribnyi&userId=3f609904004d&source=post_page-3f609904004d----8dad71577912---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8dad71577912--------------------------------)
    ·11分钟阅读·2023年2月17日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8dad71577912&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-deconvolution-operation-8dad71577912&user=Vitalii+Pogribnyi&userId=3f609904004d&source=-----8dad71577912---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8dad71577912&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-deconvolution-operation-8dad71577912&source=-----8dad71577912---------------------bookmark_footer-----------)![](../Images/309262e54c0d9444c7d53b0fe05fc099.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8dad71577912&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-deconvolution-operation-8dad71577912&source=-----8dad71577912---------------------bookmark_footer-----------)![](../Images/309262e54c0d9444c7d53b0fe05fc099.png)'
- en: Photo by [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/qppYBtgonqw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/photos/qppYBtgonqw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: '**Introduction**'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: The transposed convolutions are the ones used for generating images, and though
    they’ve been around for a while, and were explained quite nicely — I’ve still
    struggled to understand how exactly they get their job done. The article I’m sharing
    describes a simple experiment illustrating this process. I’ve also included some
    tricks that help to improve the network performance.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 转置卷积用于生成图像，尽管它们已经存在一段时间，并且解释得相当清楚——我仍然难以理解它们是如何完成工作的。本文描述了一个简单的实验来说明这个过程。我还包含了一些提高网络性能的技巧。
- en: 'Overall, there are several topics described in this article a reader may consider
    interesting:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，本文描述了几个读者可能感兴趣的话题：
- en: '- Overall visualization of the deconvolution operation'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '- 反卷积操作的整体可视化'
- en: '- Optimizing the network by separating more important components'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '- 通过分离更重要的组件来优化网络'
- en: '- Addressing a synthetic dataset issue'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '- 解决合成数据集问题'
- en: 'The task for the illustration is the simplest I could think of: build an autoencoder
    for synthetic data. The fact that it is synthetic, may raise some issues. It’s
    true that the models trained on such data may not perform well on real data. But
    we will later see why this is the case and how to fix it. The model consists of
    one convolutional layer for the encoder, and one deconvolution (aka convolution
    transposed) for the decoder.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 插图的任务是我能想到的最简单的任务：为合成数据构建一个自动编码器。尽管它是合成的，可能会引发一些问题。确实，基于这样的数据训练的模型在真实数据上表现可能不佳。但我们稍后会看到这是为什么以及如何解决这个问题。模型由一个用于编码器的卷积层和一个用于解码器的反卷积（即转置卷积）组成。
- en: All the images and chars below are my own.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下所有图像和字符均为我自己的。
- en: '**1\. The Dataset**'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**1\. 数据集**'
- en: 'The data is a set of 1-dimensional Bezier curves looking like the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是看起来像以下内容的一维Bezier曲线集合：
- en: '![](../Images/87797c629623563ad35b65a6cb6a5b29.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87797c629623563ad35b65a6cb6a5b29.png)'
- en: Data examples
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据示例
- en: 'And here is the code that generates the data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是生成数据的代码：
- en: These curves contain 15 points each. Each curve will be fed into the network
    as a 1-d array (instead of passing [x, y] coordinates for each point, only [y]
    is passed).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些曲线包含15个点。每条曲线将作为一维数组（而不是为每个点传递[x, y]坐标，只传递[y]）输入网络。
- en: Every curve can be characterized by two parameters, meaning that our network
    should be able to encode/decode any curve into a vector of size 2.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每条曲线可以用两个参数来表征，这意味着我们的网络应该能够将任何曲线编码/解码成一个大小为2的向量。
- en: '**2\. The Approach**'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**2\. 方法**'
- en: 'Here is an example network one could use to encode the curve:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可以用来编码曲线的示例网络：
- en: '![](../Images/c6dd83d3425eb1f1b3bad12437ceb44e.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6dd83d3425eb1f1b3bad12437ceb44e.png)'
- en: Network architecture
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构
- en: In the image above, the input signal (bottom) is broken into 3 patches of size
    7 (by applying a convolution layer of window size 7 and stride 4). Each patch
    is encoded into a vector of size 3, giving a 3x3 matrix. This matrix is then encoded
    into a vector of size 2; then the operation is repeated inversely in the decoder.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，输入信号（底部）被分成3个7像素大小的补丁（通过应用窗口大小为7且步幅为4的卷积层）。每个补丁被编码成一个大小为3的向量，生成一个3x3矩阵。然后，这个矩阵被编码成一个大小为2的向量；然后在解码器中反向重复这个操作。
- en: 'The network may be broken into 2 parts. The first one will be able to encode/decode
    a part of the curve (the 7 pixels patch); whereas the second will only deal with
    the 3x3 matrix. This way, I will be able to train each part separately. I could
    make a smaller autoencoder that works with 7 pixels patches only:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 网络可以分为两部分。第一部分能够编码/解码曲线的一部分（7像素的补丁）；而第二部分仅处理3x3矩阵。这样，我可以分别训练每一部分。我可以做一个只处理7像素补丁的小型自动编码器：
- en: '![](../Images/454031c98d61cdbb258d78aee89efdde.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/454031c98d61cdbb258d78aee89efdde.png)'
- en: Simplified network architecture
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 简化的网络架构
- en: So I’m going to split each example into patches, and train the network to encode/decode
    the patches. Then, I will assemble this network to produce the whole curve.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我打算将每个示例分成补丁，并训练网络以编码/解码这些补丁。然后，我将组装这个网络来生成整个曲线。
- en: I won’t be further encoding this 3x3 matrix, as this process will not carry
    any new information.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会进一步对这个3x3矩阵进行编码，因为这个过程不会带来任何新信息。
- en: '**3\. The Network**'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**3\. 网络**'
- en: '**Models used**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用的模型**'
- en: 'I will use separate models for the encoder and decoder. And they are quite
    simple:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我将为编码器和解码器使用独立的模型。它们非常简单：
- en: The stride is given as 4 because as referred to by the images in the “Approach”
    section, the filter moves 4 pixels at a time. Since we’re implementing only one
    stage here, this stride is entirely optional; it will only have an effect later
    when we assemble a larger network.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅设置为4是因为在“方法”部分的图像中提到，滤波器每次移动4像素。由于我们这里只实现了一个阶段，这个步幅完全是可选的；它只会在我们组装一个更大的网络时产生影响。
- en: '**Training process**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练过程**'
- en: To start with, I will set up a set of trainings with different seeds.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我将设置一组不同种子值的训练。
- en: 'The code for the training is as simple as it can be:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的代码尽可能简单：
- en: 'Here is how the loss behaves for these experiments:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这些实验中损失的表现：
- en: '![](../Images/758e0a6b3a6af14dbded78fc93fb7bdb.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/758e0a6b3a6af14dbded78fc93fb7bdb.png)'
- en: The image shows the mean and standard deviation of the loss for 10 experiments
    with different seeds.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图像显示了 10 次实验中不同种子下损失的均值和标准差。
- en: 'If I now compare labels with the network outputs visually, it looks like the
    following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我现在将标签与网络输出进行视觉比较，它们看起来如下：
- en: '![](../Images/e064b80ea7765d89aa68f39c714bac38.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e064b80ea7765d89aa68f39c714bac38.png)'
- en: Network evaluation — original curve compared to the network output
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 网络评估 — 原始曲线与网络输出的比较
- en: This doesn’t look bad, seems like the network is working and the loss value
    under 1e-4 is sufficient.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来不错，似乎网络在正常工作，损失值低于 1e-4 是足够的。
- en: Next, I will illustrate how the encoder and decoder work in this example.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将说明编码器和解码器在这个示例中的工作原理。
- en: '**Decoder**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**解码器**'
- en: The decoder is meant to transform the code (3-dimensional vector) into the curve
    patch. As a deconvolution operation, it has a set of filters, each scaled by some
    value, then being summed up; in other words, the weighted sum of the filters should
    match the desired output.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器旨在将代码（3维向量）转换为曲线补丁。作为反卷积操作，它有一组过滤器，每个过滤器按某些值缩放，然后进行求和；换句话说，过滤器的加权和应该匹配期望的输出。
- en: The image below contains two examples of restoring a curve. The example on the
    left was decoded from vector [0.0, 0.1, 0.2] and on the right — [0.1, 0.1, 0.0].
    Each example contains scaled filters on the top and filters without scaling on
    the bottom.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像包含恢复曲线的两个示例。左侧的示例是从向量 [0.0, 0.1, 0.2] 解码的，右侧的是 [0.1, 0.1, 0.0]。每个示例都包含顶部的缩放过滤器和底部的未缩放过滤器。
- en: '![](../Images/0a60a8a4c894190378e9a4e21512fa0b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a60a8a4c894190378e9a4e21512fa0b.png)'
- en: Decoder filters combination
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器过滤器组合
- en: 'Sure enough, we could vary the vector components one at a time and render the
    network output in real-time, forming a cool-looking animation. So here it is:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以一次变化一个向量组件并实时渲染网络输出，形成一个很酷的动画。所以，这里就是：
- en: '![](../Images/024d6890619c382d8fb711a1e1f8c3d0.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/024d6890619c382d8fb711a1e1f8c3d0.png)'
- en: Visualization of the network operation
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 网络操作的可视化
- en: Each of the animations above contains multiple plots. The point on the bottom-left
    shows the input vector. Its X and Y coordinates and size represent the input’s
    first, second, and third components. The bottom-right plot shows raw filters and
    stays the same for all the animations. The top-right plot shows scaled filters
    and output. Since only one parameter is being varied, only one filter is scaled
    and the output matches this filter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 上述每个动画包含多个图。左下角的点显示输入向量。它的 X 和 Y 坐标以及大小代表输入的第一、第二和第三个组件。右下角的图显示原始过滤器，并在所有动画中保持不变。右上角的图显示缩放后的过滤器和输出。由于只有一个参数在变化，因此只有一个过滤器被缩放，输出与该过滤器匹配。
- en: The top-left plot is probably the most interesting because it’s designed to
    show how the output depends on two components simultaneously. Each curve on it
    represents the output for different values of the third component. One may see
    that in the third animation the graph does not move, only different curves become
    bold. In the first two animations, only the middle curve remains bold because
    the third component remains zero, but overall it gives an idea of what the output
    would be if the third component was varied.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 左上角的图可能是最有趣的，因为它旨在显示输出如何同时依赖于两个组件。图上的每一条曲线代表第三个组件不同值的输出。可以看到在第三个动画中，图形没有移动，只有不同的曲线变得更粗。在前两个动画中，只有中间的曲线保持粗体，因为第三个组件保持为零，但总体上这给出了如果第三个组件发生变化，输出会是什么样的一个概念。
- en: 'Here is the case when all components are varied simultaneously:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是所有组件同时变化的情况：
- en: '![](../Images/c563eff8bdbff55c7c3884bc98fda2e0.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c563eff8bdbff55c7c3884bc98fda2e0.png)'
- en: Visualization of the network operation
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 网络操作的可视化
- en: '**Encoder**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**编码器**'
- en: The encoder in this example looks a bit less intuitive, but anyway it somehow
    gets the job done. (Its quality will be reviewed in the following sections)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例中的编码器看起来有点不直观，但无论如何它以某种方式完成了工作。（其质量将在后续章节中进行评估）
- en: '![](../Images/d75602aa169a8e67678970946ec83739.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d75602aa169a8e67678970946ec83739.png)'
- en: Encoder components
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器组件
- en: There are raw filters shown on the left, along with an example input. The plot
    on the right shows these same filters applied to the example input (i.e. every
    point of the input multiplied by every point of a filter). The labels also contain
    each filter’s output (i.e. the sum of every point of filter 1 multiplied by every
    point of the input gives 0.02).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧展示了原始滤波器，以及一个示例输入。右侧的图显示了这些滤波器应用于示例输入的结果（即每个输入点乘以每个滤波器点）。标签还包含每个滤波器的输出（即滤波器1的每个点乘以输入的每个点的总和为0.02）。
- en: 'The example on the plot above would be encoded into a vector (0.02, 0.08, -0.08).
    The decoder would restore the input in the way shown below:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上图中的示例将被编码为一个向量 (0.02, 0.08, -0.08)。解码器将以下面的方式恢复输入：
- en: '![](../Images/6f2d3f0402abd21520b173407fea3bed.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f2d3f0402abd21520b173407fea3bed.png)'
- en: Encoder performance example
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器性能示例
- en: The plot on the left shows deconvolution filers. The one on the right — each
    filter multiplied by its code vector value along with their sum (that is also
    the output of the decoder).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的图显示了解卷积滤波器。右侧的图——每个滤波器乘以其代码向量值以及它们的总和（这也是解码器的输出）。
- en: '**So what’s the problem?**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么问题是什么？**'
- en: 'The solution seems to be working — the network encodes its 7-values input into
    3-values code; then decodes it back with low error. But I see two possibilities
    for improvement:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案似乎有效——网络将其7值输入编码成3值代码；然后再用低误差解码回来。但我看到两个改进的可能性：
- en: 1\. The filters differ a lot when the network is trained with a different seed.
    It means that the network has too much flexibility and we can constrain it.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 当网络使用不同的种子进行训练时，滤波器差异很大。这意味着网络的灵活性过大，我们可以对其进行约束。
- en: 2\. Encoder robustness. How can we make sure that the encoder will work for
    a wide variety of real data?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 编码器的鲁棒性。我们如何确保编码器能适用于各种真实数据？
- en: 'To illustrate the first case, I will simply plot the filters obtained by training
    with different seeds:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明第一种情况，我将简单地绘制通过不同种子训练获得的滤波器：
- en: '![](../Images/13d6c72f2467b52821343c707ced78c5.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13d6c72f2467b52821343c707ced78c5.png)'
- en: Decoder filters
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器滤波器
- en: 'Obviously, we need to account for the filter sign and order: filter 3 on the
    first image and filter 1 on the second are identical. The set of filters, with
    compensation for sign and order, is shown below:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们需要考虑滤波器的符号和顺序：第一幅图中的滤波器3和第二幅图中的滤波器1是相同的。滤波器集合，考虑符号和顺序的补偿，如下所示：
- en: '![](../Images/08f2b5b9947b4eff6076a56207682439.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08f2b5b9947b4eff6076a56207682439.png)'
- en: Decoder filters, reorganized
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器滤波器，重新组织
- en: The filters clearly vary a lot here.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器在这里明显变化很大。
- en: '**3\. The Improvement**'
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**3. 改进**'
- en: '**Code noise**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码噪声**'
- en: 'The fact that different set of filters gives the same result is a sign that
    the filters may be constrained. One way to constrain the filters is to prioritize
    them. Similar to the PCA technique, separate the filters that encode most information
    and those encoding little details. This can be achieved by adding noise to the
    encoded image:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的滤波器集给出相同结果的事实表明滤波器可能受到约束。约束滤波器的一种方法是对其进行优先级排序。类似于PCA技术，分离出编码最多信息的滤波器和编码少量细节的滤波器。这可以通过向编码图像添加噪声来实现：
- en: '![](../Images/c030378c12f09414de499d2c8982f51c.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c030378c12f09414de499d2c8982f51c.png)'
- en: 'On the plot above, the image on the left illustrates a conventional autoencoder:
    input is being encoded onto a 2D plane; then decoded back. The network decodes
    a slightly shifted point from the 2D plane in the middle image. This forces the
    network to encode similar images into points that remain close on the plane. The
    image on the right shows the situation when the point for decoding may drift on
    the Y-axis further than on the X-axis. This forces the network to encode the most
    important feature into the X component because it’s less noisy.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 上图中，左侧的图像展示了一个传统的自编码器：输入被编码到一个2D平面上；然后被解码回来。网络从中间图像的2D平面解码一个稍微偏移的点。这迫使网络将类似的图像编码为在平面上保持接近的点。右侧的图像展示了当解码点可能在Y轴上漂移超过X轴时的情况。这迫使网络将最重要的特征编码到X分量中，因为它的噪声较少。
- en: 'Here is the same concept realized in code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在代码中实现的相同概念：
- en: 'After running the experiment again, I would receive a more consistent set of
    filters:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 重新运行实验后，我将获得一组更一致的滤波器：
- en: '![](../Images/75f206639e4dc299ed8c061b52de875e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75f206639e4dc299ed8c061b52de875e.png)'
- en: Encoder filters after training with noise
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 经过噪声训练后的编码器滤波器
- en: 'And if I compensate for the sign and order as before, in the “what’s the problem”
    section:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我像之前一样补偿符号和顺序，在“问题是什么”部分：
- en: '![](../Images/bf0d38720591701166ac9e2d405f76f4.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf0d38720591701166ac9e2d405f76f4.png)'
- en: Encoder filters after training with noise — reorganized
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器在经过噪声训练后的滤波器——重新组织
- en: One may see clearly that there are filters curvy on one side and sharp on the
    other, and one component is curvy in the middle. Filters 2 and 3 seem to be of
    equal importance because they get encoded sometimes in the first component, and
    sometimes in the second. The third filter, however, is smaller in magnitude and
    is always encoded in the noisiest component, which suggests it’s less important.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 可以清楚地看到，一些滤波器在一侧是曲线的，在另一侧是锐利的，而一个组件在中间是曲线的。滤波器 2 和 3 似乎同等重要，因为它们有时被编码在第一个组件中，有时被编码在第二个组件中。然而，第三个滤波器的幅度较小，并且总是被编码在最嘈杂的组件中，这表明它的重要性较低。
- en: 'The impact of this noise can be checked by comparing models’ performance while
    zeroing out different components of the encoded vector:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声的影响可以通过比较模型在将编码向量的不同组件归零时的表现来检查：
- en: '![](../Images/ef864eef758e22f8a447628c3068448f.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ef864eef758e22f8a447628c3068448f.png)'
- en: Comparison of the models performance with one of their components deactivated
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 模型性能的比较，禁用其一个组件
- en: The plot above shows the loss change by zeroing the of the first, second, or
    third component, for the model with noise on the left and the original model on
    the right. For the original model, disabling each component leads to relatively
    same loss drop.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了通过归零第一个、第二个或第三个组件而导致的损失变化，对于左侧的噪声模型和右侧的原始模型。对于原始模型，禁用每个组件都会导致相对相同的损失下降。
- en: 'Here is how it’s compared visually. Find the model input and output, on the
    plot below. From left to right: full model; model with filter 1 disabled; model
    with filter 2 disabled; model with filter 3 disabled.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是视觉上的比较。请查看图中的模型输入和输出。从左到右：完整模型；禁用滤波器 1 的模型；禁用滤波器 2 的模型；禁用滤波器 3 的模型。
- en: 'The model trained with noise:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 经过噪声训练的模型：
- en: '![](../Images/b906abc759a4bc842f51c472a0c29b21.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b906abc759a4bc842f51c472a0c29b21.png)'
- en: 'Network evaluation, original curve compared to the network output — for models
    having one component disabled, from left to right: full model, no disabled components;
    component 1 disabled; component 2 disabled; component 3 disabled.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 网络评估，原始曲线与网络输出的比较——对于具有一个组件禁用的模型，从左到右：完整模型，没有禁用的组件；组件 1 禁用；组件 2 禁用；组件 3 禁用。
- en: 'And for the original model:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于原始模型：
- en: '![](../Images/e9efe3c979d316dabdcb732c40a96b57.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9efe3c979d316dabdcb732c40a96b57.png)'
- en: 'Network evaluation, original curve compared to the network output — for models
    having one component disabled, from left to right: full model, no disabled components;
    component 1 disabled; component 2 disabled; component 3 disabled.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 网络评估，原始曲线与网络输出的比较——对于具有一个组件禁用的模型，从左到右：完整模型，没有禁用的组件；组件 1 禁用；组件 2 禁用；组件 3 禁用。
- en: The model trained with noise has a noticeably smaller error when only the noisy
    component is disabled.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 经过噪声训练的模型在仅禁用噪声组件时，误差明显较小。
- en: '**Input noise**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入噪声**'
- en: 'Let’s now take another look at the encoder filters. They are not smooth at
    all, and some of them look similar to each other. That’s strange, because the
    purpose of the encoder is to spot a difference in the input, and you can’t spot
    the difference with a set of similar filters. How is the network able to do it?
    Well, the answer is that our synthetic dataset is too perfect to train correct
    filters. The network can easily classify the input by a single point:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们再来看一下编码器滤波器。它们一点也不平滑，而且有些看起来彼此相似。这很奇怪，因为编码器的目的是发现输入的差异，而你不能通过一组相似的滤波器发现差异。网络是如何做到的？答案是我们的合成数据集过于完美，无法训练出正确的滤波器。网络可以通过一个点轻松分类输入：
- en: '![](../Images/046ed8ca0a38c45474f073a9b7bc56a3.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/046ed8ca0a38c45474f073a9b7bc56a3.png)'
- en: Examples with similar point
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 相似点的示例
- en: On each plot above, there is a curve example on the larger plot (referred to
    as ‘original’), and 3 examples that have a similar point to this original example.
    The examples themselves are different, but given the precise value at the point
    (i.e. -0.247 or -0.243), the network is able to make a decision about the whole
    example.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述每个图中，都有一个较大图上的曲线示例（称为“原始”），以及 3 个与这个原始示例具有类似点的示例。这些示例本身不同，但鉴于点上的精确值（例如 -0.247
    或 -0.243），网络能够对整个示例做出决策。
- en: This can easily be fixed by adding noise to the raw input.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过向原始输入中添加噪声来轻松修复。
- en: 'After training the models again, I obtained nice smooth filters:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 重新训练模型后，我得到了平滑的滤波器：
- en: '![](../Images/98d15010cf036d04e45ac96228a4ce46.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98d15010cf036d04e45ac96228a4ce46.png)'
- en: Encoder components — after adding noise
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器组件——添加噪声后
- en: One may see that Filter 1, the noisiest one, grows larger than the other filters.
    My guess is, that it’s trying to make its output larger than the noise, trying
    to decrease its effect. But since I have a tanh activation, its output cannot
    be larger than 1, so the noise is still in effect.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 可以看到，滤波器1，即噪声最强的一个，比其他滤波器增长得更大。我的猜测是，它试图让其输出大于噪声，以减小噪声的影响。但由于我有一个tanh激活函数，它的输出不能大于1，所以噪声仍然存在。
- en: '**4\. The Full Model**'
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**4. 完整模型**'
- en: '**Assembly**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**组装**'
- en: 'Now that we have a working component of the model, we can apply it multiple
    times, so that it works for encoding/decoding the whole 15-points curve. There’s
    nothing special about this, all I need to do is not cut my example into pieces:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有了模型的一个工作组件，我们可以多次应用它，使其适用于对整个15点曲线的编码/解码。这个没有什么特别之处，我只需要避免将示例切成小块：
- en: 'This would give me the following output:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我以下输出：
- en: '![](../Images/ac837fd926e23f1b6339165725be5f45.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac837fd926e23f1b6339165725be5f45.png)'
- en: Overlap issue
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 重叠问题
- en: 'Well, maybe I need to change something. The problem is, the deconvolution will
    sum up the overlapping parts of the image. So these parts on the plot below get
    doubled:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，也许我需要更改一些东西。问题是，反卷积会将图像的重叠部分相加。所以下面图中的这些部分被重复计算：
- en: '![](../Images/eeb0ee2bfac9f952d7a67b017a861f13.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eeb0ee2bfac9f952d7a67b017a861f13.png)'
- en: Overlapping deconvolution windows
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 重叠的反卷积窗口
- en: 'There’s an easy fix for this: I could decrease by half the weights of my filters,
    whose output is overlapped:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个简单的解决方法：我可以将输出重叠的滤波器的权重减半：
- en: 'After this manipulation I will get the following output:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 经过这种操作后，我会得到以下输出：
- en: '![](../Images/72d335a8f77bb7d68e7efcfa7edb22c0.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72d335a8f77bb7d68e7efcfa7edb22c0.png)'
- en: Deconvolution with overlap — updated
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 带有重叠的反卷积——更新版
- en: 'Alternatively, I could reduce the filter values gradually, starting small near
    the center and reducing strongly on the sides:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我可以逐渐减少滤波器的值，从中心附近的小值开始，然后在边缘强烈减少：
- en: 'Which leads to a much smoother output:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致输出更加平滑：
- en: '![](../Images/6def5a9d9de486ed94b02ade1421040e.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6def5a9d9de486ed94b02ade1421040e.png)'
- en: Deconvolution with overlap — final version
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 带有重叠的反卷积——最终版
- en: This leads to another problem — the border points have nothing to overlap with,
    and the decoded image is different from what it should be. There are several possible
    solutions to this. For example, to include padding to the encoded image, so that
    the borders are also encoded, or to ignore these borders (maybe also exclude them
    from the loss calculation). I will stop here because further improvements are
    out of the scope of this article.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这会导致另一个问题——边界点没有重叠的对象，解码图像与实际情况不同。对此有几种可能的解决方案。例如，给编码图像添加填充，使得边界也被编码，或忽略这些边界（也许还可以将它们排除在损失计算之外）。我将在这里停下，因为进一步的改进超出了本文的范围。
- en: '**Conclusion**'
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: This simple example illustrates how deconvolutions do their job and how one
    can employ noise (sometimes of varying magnitude) for training a neural network.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的示例说明了反卷积如何工作，以及如何利用噪声（有时是不同幅度的噪声）来训练神经网络。
- en: 'The described method does work well for larger networks, and the noise magnitude(s)
    become a hyperparameter to experiment with. The method may not work with ReLu
    activations: their output may easily grow way larger than the noise magnitude,
    and the noise loses its effect.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 所描述的方法在较大的网络上表现良好，噪声幅度成为一个需要实验的超参数。该方法可能不适用于ReLu激活函数：它们的输出可能会比噪声幅度大得多，从而使噪声失效。
