- en: 'Building Better ML Systems — Chapter 3: Modeling. Let the Fun Begin'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建更好的机器学习系统 — 第3章：建模。让乐趣开始
- en: 原文：[https://towardsdatascience.com/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=collection_archive---------7-----------------------#2023-08-25](https://towardsdatascience.com/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=collection_archive---------7-----------------------#2023-08-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=collection_archive---------7-----------------------#2023-08-25](https://towardsdatascience.com/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5?source=collection_archive---------7-----------------------#2023-08-25)
- en: '*About baselines, experiment tracking, proper test sets, and metrics. About
    making the algorithm work.*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*关于基线、实验跟踪、适当的测试集和指标。关于让算法发挥作用。*'
- en: '[](https://olga-chernytska.medium.com/?source=post_page-----73059c75e1d5--------------------------------)[![Olga
    Chernytska](../Images/3a1a1b5f3c92d3b86283911cd90a9259.png)](https://olga-chernytska.medium.com/?source=post_page-----73059c75e1d5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----73059c75e1d5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----73059c75e1d5--------------------------------)
    [Olga Chernytska](https://olga-chernytska.medium.com/?source=post_page-----73059c75e1d5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://olga-chernytska.medium.com/?source=post_page-----73059c75e1d5--------------------------------)[![Olga
    Chernytska](../Images/3a1a1b5f3c92d3b86283911cd90a9259.png)](https://olga-chernytska.medium.com/?source=post_page-----73059c75e1d5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----73059c75e1d5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----73059c75e1d5--------------------------------)
    [Olga Chernytska](https://olga-chernytska.medium.com/?source=post_page-----73059c75e1d5--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc932e019245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5&user=Olga+Chernytska&userId=cc932e019245&source=post_page-cc932e019245----73059c75e1d5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----73059c75e1d5--------------------------------)
    ·15 min read·Aug 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F73059c75e1d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5&user=Olga+Chernytska&userId=cc932e019245&source=-----73059c75e1d5---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcc932e019245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5&user=Olga+Chernytska&userId=cc932e019245&source=post_page-cc932e019245----73059c75e1d5---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----73059c75e1d5--------------------------------)
    ·15 min read·2023年8月25日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F73059c75e1d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5&user=Olga+Chernytska&userId=cc932e019245&source=-----73059c75e1d5---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F73059c75e1d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5&source=-----73059c75e1d5---------------------bookmark_footer-----------)![](../Images/7424fc19664fdd5c34bed879937cd285.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F73059c75e1d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5&source=-----73059c75e1d5---------------------bookmark_footer-----------)![](../Images/7424fc19664fdd5c34bed879937cd285.png)'
- en: '[Image Source](https://unsplash.com/photos/vXInUOv1n84)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[图片来源](https://unsplash.com/photos/vXInUOv1n84)'
- en: Hello back. I am glad to see you here again. I really appreciate your desire
    to become a better professional, do better work, and build better ML systems.
    You are cool, keep it up!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你好，很高兴再次见到你。我非常欣赏你想成为更好专业人士、做得更好以及构建更好机器学习系统的愿望。你很棒，继续保持！
- en: In this series, I do my best to help you master the art, science, and (sometimes)
    magic of designing and building Machine Learning systems. Here we talk about business
    value and requirements, data collection and labeling, model development, experiment
    tracking, online and offline evaluation, deployment, monitoring, retraining, and
    much much more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个系列中，我尽力帮助你掌握设计和构建机器学习系统的艺术、科学和（有时的）魔法。在这里，我们讨论业务价值和需求、数据收集与标记、模型开发、实验跟踪、在线和离线评估、部署、监控、再训练，以及更多内容。
- en: 'This is the third chapter and it is devoted to model development. **An ML algorithm
    is only a small part of the ML system.** A perfectly accurate algorithm without
    a well-designed system won’t serve your customers and won’t earn money for your
    company. In this post, instead of giving you an overview of ML algorithms, I will
    show you a different perspective: how to select, develop and evaluate algorithms
    keeping in mind that the algorithm’s primary goal is to bring value to the business.
    And the end of the day, it does not really matter whether you solved the business
    problem with linear regression or with the most advanced neural network.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第三章，专注于模型开发。**一个机器学习算法只是机器学习系统的一小部分。** 没有精心设计的系统，即使是完美准确的算法也无法服务于客户，也不会为公司带来利润。在这篇文章中，我将从一个不同的角度展示：如何选择、开发和评估算法，同时考虑算法的主要目标是为业务带来价值。最终，无论你是用线性回归还是最先进的神经网络解决业务问题，都不重要。
- en: '![](../Images/722adc3df04ba6bb7c853e982baedcfb.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/722adc3df04ba6bb7c853e982baedcfb.png)'
- en: '*An ML algorithm (black box in the middle) is only a small part of the ML system.*
    [*Image source*](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*一个机器学习算法（中间的黑盒）只是机器学习系统的一小部分。* [*图片来源*](https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf)'
- en: Before we move on, let’s have a quick recap of what we’ve already learned.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们快速回顾一下我们已经学到的内容。
- en: '[The first chapter](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32)
    was about planning. We learned that every project must start with a plan because
    ML systems are too complex to implement in an ad-hoc manner. We reviewed the ML
    project lifecycle, discussed why and how to estimate project business value, how
    to collect the requirements, and then reevaluate with a cold mind whether ML is
    truly needed. We learned how to start small and fail fast using concepts like
    “PoC” and “MVP”. And finally, we talked about the importance of design documents
    during the planning stage.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第一章](/building-better-ml-systems-chapter-1-every-project-must-start-with-a-plan-907a36774a32)
    讲的是规划。我们了解到每个项目必须从计划开始，因为机器学习系统过于复杂，不能以临时的方式实施。我们回顾了机器学习项目生命周期，讨论了估算项目业务价值的原因和方法，如何收集需求，然后以冷静的头脑重新评估机器学习是否真的必要。我们学习了如何从小处着手，并利用“PoC”和“MVP”等概念快速失败。最后，我们谈到了在规划阶段设计文档的重要性。'
- en: '[The second chapter](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39)
    was about the data. We discussed a new trend in the industry — data-centric AI,
    an approach to building ML systems that considers clean data to be much more important
    than advanced ML algorithms. We touched on data pipelines, which are designed
    to organize the flow of chaotic and unstructured data so the data can be used
    for analytics. We learned that training data should be relevant, uniform, representative,
    and comprehensive, as models build their understanding of the world based on this
    data. We reviewed two types of labels — human and natural — and navigated through
    the complex, slow, and expensive process of obtaining human labels, and discussed
    best practices to make this process less painful. Lastly, we talked about an alternative
    to real data and human labeling: synthetic data.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二章](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39)
    讲的是数据。我们讨论了行业中的新趋势——数据中心人工智能，这是一种将干净的数据视为比先进的机器学习算法更重要的构建机器学习系统的方法。我们介绍了数据管道，这些管道旨在组织混乱和非结构化数据的流动，以便数据可以用于分析。我们了解到，训练数据应该是相关的、一致的、具有代表性的和全面的，因为模型基于这些数据建立对世界的理解。我们回顾了两种标签——人工标签和自然标签——并探讨了获取人工标签的复杂、缓慢和昂贵的过程，并讨论了使这一过程更少痛苦的最佳实践。最后，我们讨论了真实数据和人工标记的替代品：合成数据。'
- en: If by some chance you’ve missed the previous posts, I encourage you to read
    them before we proceed. I’ll wait for you right here.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不小心错过了之前的帖子，我建议你在继续之前阅读它们。我会在这里等你。
- en: And now, let the fun begin.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始享受乐趣吧。
- en: How to select an ML algorithm
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何选择一个ML算法
- en: There is no algorithm that fits every problem. You need to try several approaches
    and learn your data and domain really-really well until you come up with something
    that works.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 没有一种算法适用于所有问题。你需要尝试几种方法，真正了解你的数据和领域，直到找到有效的方法。
- en: 'Think, brainstorm, talk to your colleagues, ask ChatGPT, and then write down
    three approaches you are going to try: 1) something very simple; 2) something
    very popular; 3) something new and creative.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 思考、头脑风暴、与同事讨论、询问ChatGPT，然后写下你打算尝试的三种方法：1) 一种非常简单的方法；2) 一种非常流行的方法；3) 一种新颖且有创意的方法。
- en: Something very simple. Every complexity introduced in the algorithm must be
    justified. Start with a simple approach (maybe even non-ML), evaluate it, and
    use it as a baseline to compare all your other models to it.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种非常简单的方法。算法中引入的每一种复杂性都必须是有理由的。从一个简单的方法开始（甚至可能是非ML的），评估它，并将其作为基线与其他所有模型进行比较。
- en: Something very popular. If you see, hear, and read that many-many people are
    solving the same business task with a specific algorithm — make sure you add it
    to your experiment list. Utilize collective intelligence! My expectations are
    always high about popular approaches and in most cases, they work pretty well.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种非常流行的方法。如果你看到、听到或读到许多人使用特定算法解决相同的业务任务 — 确保将其添加到你的实验列表中。利用集体智慧！我对流行的方法总是充满期望，在大多数情况下，它们效果很好。
- en: Something new and creative. Just give it a try. Your boss and company will be
    happy if you build a competitive advantage by beating typical popular approaches.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种新颖且有创意的方法。尽管试试看。如果你通过击败典型的流行方法建立了竞争优势，你的老板和公司会很高兴。
- en: '**Word of caution: Do not reinvent the wheel**. There are hundreds of open-source
    libraries and repositories that have implementations for most of the algorithms,
    data sampling strategies, or training loops you may think of. Do not write your
    custom K-means clustering — take the one from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).
    Do not write ResNet50 from scratch — take the one from [PyTorch](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html).
    Before implementing the recent paper, check [PapersWithCode](https://paperswithcode.com/),
    I bet someone already did it.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**提醒：不要重复发明轮子**。有成百上千的开源库和代码库，已经实现了你可能想到的大多数算法、数据采样策略或训练循环。不要自己编写K-means聚类算法
    — 使用[scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)中的现成实现。不要从头开始编写ResNet50
    — 使用[PyTorch](https://pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html)中的现成实现。在实现最新的论文之前，检查一下[PapersWithCode](https://paperswithcode.com/)，我敢打赌有人已经做过了。'
- en: Doing research and inventing something new is exciting. Implementing algorithms
    from scratch, where you understand every single line, is tempting. However, the
    research fits well only within universities and Big Tech companies. For startups
    every dollar matters, so they simply cannot afford to invest in something that
    has a low chance to succeed (and research is literally about 100 trials and 1
    success).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 做研究和发明新东西令人兴奋。从零开始实现算法，理解每一行代码，确实很有吸引力。然而，研究通常适合大学和大型科技公司。对于初创公司来说，每一美元都很重要，因此他们根本无法投资成功几率很低的东西（研究通常涉及100次尝试和1次成功）。
- en: '**Be careful with “state-of-the-art”**. Imagine you are doing object detection
    using [YOLOv7](https://github.com/WongKinYiu/yolov7) and then you hear that [YOLOv8](https://github.com/ultralytics/ultralytics)
    is released, which is expected to be even better. Does it mean that you need to
    upgrade all your production pipelines to support YOLOv8? Not necessarily.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**小心“最先进技术”**。假设你正在使用[YOLOv7](https://github.com/WongKinYiu/yolov7)进行目标检测，然后你听说[YOLOv8](https://github.com/ultralytics/ultralytics)已经发布，预计会更好。这是否意味着你需要升级所有的生产管道以支持YOLOv8？不一定。'
- en: 'In most cases, this “better” means a 1–2% improvement on a static benchmark
    dataset, such as [COCO](https://cocodataset.org/#home). The model accuracy on
    your data may be better, insignificantly better, or even worse, simply because
    your data and your business problem are different in all ways. Also, from [Chapter
    2](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39) of this
    series, you should remember: Improving data leads to a more significant increase
    in model accuracy than improving the algorithm. Come up with ways to clean the
    training data — and you’ll see a 5–10% accuracy increase.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，这种“更好”意味着在静态基准数据集上提升1-2%，例如[COCO](https://cocodataset.org/#home)。由于你的数据和业务问题在各个方面都不同，模型在你数据上的准确性可能更好、略好，甚至更差。此外，从本系列的[第2章](/building-better-ml-systems-chapter-2-taming-data-chaos-841d5a04b39)中，你应该记住：提升数据质量比改善算法能显著提高模型准确性。想办法清理训练数据——你会看到准确率提高5-10%。
- en: How to develop an ML algorithm
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何开发机器学习算法
- en: 'First, go get a baseline. A baseline is a model that you are going to compete
    with. There are two logical choices for the baseline:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，获取一个基准。基准是你将要与之竞争的模型。基准有两个逻辑选择：
- en: An existing model from the production (if you have one). We want to improve
    the existing model, that is why we need to do a comparison with it.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从生产环境中获取一个现有的模型（如果你有的话）。我们想要改进现有的模型，这就是为什么我们需要与之进行比较。
- en: A very simple model that is easy to deploy. If the business task can be solved
    in an easy way, why bother training complex models? Spend a couple of days searching
    for an easy solution and implementing it.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个非常简单且易于部署的模型。如果业务任务可以通过简单的方法解决，何必费劲训练复杂的模型？花几天时间寻找并实现一个简单的解决方案。
- en: And now goes experimentation. You construct all your experiments in order to
    improve upon the baseline. Found a promising algorithm? Great, evaluate and compare
    it to the baseline. Your model is better? Congratulations, now it is your new
    baseline, think of experiments to improve it even more.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在开始实验。你设计所有实验以在基准之上进行改进。找到一个有前途的算法？很好，评估并与基准进行比较。你的模型更好？恭喜你，它现在是你的新基准，考虑进行实验以进一步改进它。
- en: '![](../Images/b6c64bd6f959c049f1876fc1570aee80.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6c64bd6f959c049f1876fc1570aee80.png)'
- en: '*Algorithm development is an iterative process. Image by Author*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*算法开发是一个迭代的过程。图像由作者提供*'
- en: Algorithm development is an iterative process. You finish either when you find
    an algorithm that is good enough for production OR when you run out of time. Both
    scenarios are possible.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 算法开发是一个迭代的过程。你要么找到一个足够好的算法投入生产，要么耗尽时间。两种情况都是可能的。
- en: '**Naturally, most of the ideas you try will fail**. So do not be upset about
    it, and do not take it personally. We all work like that: find a good idea, try
    it, see that the idea is actually bad, and come up with a new, hopefully, good
    idea this time, try it, see that it also does not work, find a new idea,…'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**自然地，你尝试的大多数想法都会失败**。所以不要为此沮丧，也不要把它当成个人问题。我们都是这样工作的：找到一个好点子，试一试，发现这个点子实际上很糟糕，然后想出一个新的、希望这次好的点子，再试一试，发现它也不起作用，再找一个新点子，……'
- en: 'My advice here: time-frame your efforts spent on a single idea. If you cannot
    make the idea work within N days (choose your N in advance), wrap it up and move
    to another one. If you really want to succeed, you need to go through many-many
    different ideas, because, as I said earlier, most of the ideas you try will fail.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我的建议是：给单一想法的努力设定时间框架。如果你不能在N天内（提前选择你的N值）使这个想法奏效，就结束它并转向另一个想法。如果你真的想要成功，你需要经历许多不同的想法，因为，正如我之前所说，大多数你尝试的想法都会失败。
- en: '**Learn your data really-really well.** Visualize samples and labels, plot
    feature distributions, make sure you understand feature meanings, explore samples
    from each class, understand data collection strategy, read data labeling instructions
    given to annotators, … Train yourself to predict what model is expected to predict.
    If you want to create a good algorithm, start thinking like an algorithm (I am
    not joking here). All this will help you to find problems with data, debug the
    model, and come up with experiment ideas.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**真正真正地了解你的数据。** 可视化样本和标签，绘制特征分布，确保你理解特征的含义，探索每个类别的样本，了解数据收集策略，阅读提供给标注员的数据标注说明……训练自己预测模型应该预测的内容。如果你想创建一个好的算法，开始像算法一样思考（我不是在开玩笑）。所有这些都将帮助你发现数据中的问题、调试模型，并提出实验想法。'
- en: '**Split the data into training, validation, and test parts**. Train on the
    training set, choose hyperparameters on the validation set, and evaluate on the
    test set. Make sure there is no overlap or data leakage among the splits. More
    on that is in the post: [Train, Validation, Test Split for Machine Learning](https://blog.roboflow.com/train-test-split/)
    by Jacob Solawetz.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**将数据划分为训练集、验证集和测试集**。在训练集上训练，在验证集上选择超参数，在测试集上评估。确保这些划分之间没有重叠或数据泄漏。有关更多信息，请查看这篇文章：[《机器学习中的训练、验证和测试划分》](https://blog.roboflow.com/train-test-split/)
    作者Jacob Solawetz。'
- en: '**Way to go: take an open-source model, run it with the default parameters,
    and do hyperparameter tuning**. Use algorithms either from ML libraries, such
    as [scikit-learn](https://scikit-learn.org/stable/), [PyTorch](https://pytorch.org/),
    [OpenCV](https://opencv.org/), or from a GitHub repository that has a lot of stars,
    a good readme, and a license that allows using it for commercial purposes. Train
    with the default hyperparameters on your data, and evaluate. Default hyperparameters
    of the algorithm are selected to maximize accuracy on a benchmark dataset (ImageNet,
    COCO), so in most cases, they do not fit well your data and your task. Thoroughly
    learn what each hyperparameter means and how it affects training/inference, so
    you can do hyperparameter optimization. Typical approaches for hyperparameter
    optimizations are [Grad Student Descent](https://sciencedryad.wordpress.com/2014/01/25/grad-student-descent/),
    random/grid/Bayesian searches, and evolutionary algorithms. Never say that the
    algorithm does not work before you did a hyperparameter optimization. To learn
    more, check out this post by Pier Paolo Ippolito: [Hyperparameters Optimization](/hyperparameters-optimization-526348bb8e2d).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法：使用开源模型，先用默认参数运行，然后进行超参数调整**。使用来自机器学习库的算法，例如[scikit-learn](https://scikit-learn.org/stable/)、[PyTorch](https://pytorch.org/)、[OpenCV](https://opencv.org/)，或者来自GitHub上拥有大量stars、良好readme和允许商业使用的许可证的仓库。用默认超参数在你的数据上训练并进行评估。算法的默认超参数是为了在基准数据集（ImageNet,
    COCO）上最大化准确性，因此在大多数情况下，它们不适合你的数据和任务。详细了解每个超参数的含义及其对训练/推理的影响，以便进行超参数优化。典型的超参数优化方法包括[Grad
    Student Descent](https://sciencedryad.wordpress.com/2014/01/25/grad-student-descent/)、随机/网格/贝叶斯搜索和进化算法。永远不要在进行超参数优化之前就声称算法不起作用。欲了解更多信息，请查看Pier
    Paolo Ippolito的这篇文章：[《超参数优化》](/hyperparameters-optimization-526348bb8e2d)。'
- en: '**Work with your data even more: do feature engineering and data augmentations.**
    Feature engineering refers to transforming existing features and creating new
    ones. Feature engineering is a crucial skill, so I am referring you to two great
    posts where you can acquire it:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**更加深入地处理你的数据：进行特征工程和数据增强。** 特征工程指的是转换现有特征和创建新特征。特征工程是一项关键技能，因此我向你推荐两篇可以帮助你掌握这项技能的优秀文章：'
- en: '- [Fundamental Techniques of Feature Engineering for Machine Learning](/feature-engineering-for-machine-learning-3a5e293a5114)
    by Emre Rençberoğlu'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '- [《机器学习特征工程的基本技术》](/feature-engineering-for-machine-learning-3a5e293a5114)
    作者Emre Rençberoğlu'
- en: '- [4 Tips for Advanced Feature Engineering and Preprocessing](/4-tips-for-advanced-feature-engineering-and-preprocessing-ec11575c09ea)
    by Maarten Grootendorst'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '- [《高级特征工程和预处理的4个技巧》](/4-tips-for-advanced-feature-engineering-and-preprocessing-ec11575c09ea)
    作者Maarten Grootendorst'
- en: 'Data augmentation is a technique to create new training samples from the data
    you have, so during training the model “sees” more samples. Increasing the training
    set is the easiest way to increase the model accuracy, so you should do data augmentations
    always when you can. For instance, in the Computer Vision domain, literally, no
    one is training models without basic image augmentations — rotations, scaling,
    cropping, flips, etc. For more details check out my post: [Complete Guide to Data
    Augmentation for Computer Vision](/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07).'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是一种从现有数据中创建新训练样本的技术，使得模型在训练过程中“看到”更多样本。增加训练集是提高模型准确性的最简单方法，因此你应该在可能的情况下始终进行数据增强。例如，在计算机视觉领域，几乎没有人会在没有基本图像增强（如旋转、缩放、裁剪、翻转等）的情况下训练模型。有关更多细节，请查看我的文章：[《计算机视觉数据增强完全指南》](/complete-guide-to-data-augmentation-for-computer-vision-1abe4063ad07)。
- en: 'If you are curious, about how augmentations are done for Natural Language Processing,
    read [Data Augmentation in NLP: Best Practices From a Kaggle Master](https://neptune.ai/blog/data-augmentation-nlp)
    by Shahul ES.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对自然语言处理中的数据增强方法感到好奇，可以阅读Shahul ES的[《NLP中的数据增强：Kaggle大师的最佳实践》](https://neptune.ai/blog/data-augmentation-nlp)。
- en: '**Transfer Learning is your friend. Zero-shot learning is your best friend.**
    Transfer Learning is a popular technique to boost model accuracy. Practically,
    it means that you take a model pre-trained on some dataset and continue training
    it using your data (“transferring knowledge”). Even weights from COCO or ImageNet
    datasets can improve your model, even though your data may look far different
    from COCO/ImageNet images.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**迁移学习是你的朋友。零样本学习是你最好的朋友。** 迁移学习是一种流行的提高模型准确性的技术。实际上，这意味着你使用某个数据集上预训练的模型，继续用你的数据进行训练（“转移知识”）。即使你的数据与COCO或ImageNet数据集的图片看起来相差甚远，来自这些数据集的权重仍然可以改善你的模型。'
- en: 'Zero-shot learning is an algorithm that works on your data without training.
    How? Usually, it is a model pre-trained on a huge billion-sample dataset. Your
    data may look like something this model was already trained on; and the model
    has “seen” so many samples, that it can generalize well to new data. Zero-shot
    learning may sound like a dream, however, there are some super-models out of there:
    [Segment Anything](https://github.com/facebookresearch/segment-anything), most
    of the [Word Embeddings](https://huggingface.co/blog/getting-started-with-embeddings)
    models, ChatGPT.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本学习是一种无需训练即可在你的数据上工作的算法。怎么做到的？通常，它是一个在巨大样本数据集上预训练的模型。你的数据可能类似于这个模型已经训练过的内容；模型已经“见过”了大量样本，因此能够很好地泛化到新数据上。零样本学习听起来可能像是一个梦想，但确实有一些超级模型存在：[Segment
    Anything](https://github.com/facebookresearch/segment-anything)、大多数[词嵌入](https://huggingface.co/blog/getting-started-with-embeddings)模型，ChatGPT。
- en: '![](../Images/c6a900d36326ee6b0a6a19bb587e3b98.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c6a900d36326ee6b0a6a19bb587e3b98.png)'
- en: Model Development Checklist for your convenience. Image by Author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为你的方便准备的模型开发清单。图片来源于作者
- en: 'There is much more left to say about model development, but we need to wrap
    up to reserve some time for Experiment Tracking and Evaluation topics. In case,
    you still feel hungry for knowledge, check out this great post by Andrej Karpathy:
    [A Recipe for Training Neural Networks](http://karpathy.github.io/2019/04/25/recipe).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型开发还有很多要说的，但我们需要总结，以留出时间讨论实验跟踪和评估的话题。如果你仍然渴望知识，可以查看Andrej Karpathy的这篇精彩文章：[训练神经网络的配方](http://karpathy.github.io/2019/04/25/recipe)。
- en: Experiment Tracking
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验跟踪
- en: Experiment tracking is the process of saving information about the experiment
    to some dashboard or file, so you can review it in the future. It is like logging
    in the Software Development. Links to training and test datasets, hyperparameters,
    git hash, metrics on the test data — are examples of what you can possibly track.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实验跟踪是将实验信息保存到某个仪表板或文件中的过程，以便你将来可以查看。这就像软件开发中的日志记录。训练和测试数据集的链接、超参数、git 哈希、测试数据上的指标——这些都是你可能跟踪的内容示例。
- en: '**You must track all the experiments you run**. If for some reason your team
    does not do it, set up a team call right now to discuss the importance of that.
    You will thank me later :)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**你必须跟踪你运行的所有实验**。如果出于某种原因你的团队没有这样做，立即安排一个团队会议讨论这件事的重要性。你会感谢我的 :)'
- en: So, why do we want to do the experiment tracking?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们为什么要进行实验跟踪呢？
- en: '**To compare different experiments to each other**. When you develop a model,
    you train and evaluate a lot of different algorithms, try different data preprocessing
    techniques, use different hyperparameters and come up with various creative tricks.
    At the end of the day, you want to see what you tried, what worked, and what gave
    the best accuracy. Maybe later you’ll want to come back to some experiment and
    review its results with a fresh mind. Model development may last for weeks or
    even months, so without proper experiment tracking you’ll simply forget what you
    did, and have to redo the experiments.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为了比较不同实验之间的差异**。当你开发模型时，你会训练和评估许多不同的算法，尝试不同的数据预处理技术，使用不同的超参数，采用各种创造性的技巧。最终，你希望看到你尝试了什么，哪些有效，哪些获得了最佳准确率。也许以后你会想回到某个实验，重新审视其结果。模型开发可能会持续几周甚至几个月，因此如果没有适当的实验跟踪，你会忘记你做了什么，并且不得不重新做实验。'
- en: '**To reproduce the experiments**. If you cannot reproduce it, it does not count.
    Check yourself: can you come back to your most successful experiment, rerun it
    and get the same accuracy? If the answer is “NO”, it is possible because you don’t
    version control the code and the data, don’t save all hyperparameters, or don’t
    set a random seed.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为了重现实验**。如果你不能重现它，那就不算数。检查一下：你能回到你最成功的实验，重新运行它并获得相同的准确率吗？如果答案是“不能”，可能是因为你没有对代码和数据进行版本控制，没有保存所有超参数，或者没有设置随机种子。'
- en: 'The importance of setting a random seed is well explained in a post by Cecelia
    Shao: [Properly Setting the Random Seed in ML Experiments. Not as Simple as You
    Might Imagine](https://opendatascience.com/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine/).'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 随机种子的设置重要性在Cecelia Shao的文章中解释得很好：[在ML实验中正确设置随机种子。并不像你想象的那么简单](https://opendatascience.com/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine/)。
- en: '**To debug the experiment**. Sometimes experiment does not work: an algorithm
    does not converge, predictions look strange, accuracy is close to random. It is
    literally impossible to understand why it failed if no information about the experiment
    is saved. A saved list of hyperparameters, visualization of samples and augmentations,
    loss plots, etc may give you some clue where the problem lies.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调试实验**。有时实验无法正常工作：算法不收敛，预测结果异常，准确率接近随机。如果没有保存实验信息，几乎不可能理解失败的原因。保存超参数列表、样本和数据增强的可视化、损失图等可能会给你一些线索，帮助你找到问题所在。'
- en: As now you are convinced that experiment tracking is important, let’s talk about
    how to do it practically.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经相信实验追踪的重要性，我们来谈谈如何实际操作。
- en: There are dozens of free and paid experiment tracking tools out there, choose
    something that fits your requirements and budget. Probably, the most popular one
    is [Weights&Biases](https://wandb.ai/site); I’ve worked with it a lot and it’s
    nice. For a review of some other tools, check out [15 Best Tools for ML Experiment
    Tracking and Management](https://neptune.ai/blog/best-ml-experiment-tracking-tools)
    by Patrycja Jenkner.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多免费的和付费的实验追踪工具，你可以选择适合你要求和预算的工具。可能最受欢迎的是[Weights&Biases](https://wandb.ai/site)；我用过很多次，它很好。有关其他工具的评论，请查看[15个最佳ML实验追踪和管理工具](https://neptune.ai/blog/best-ml-experiment-tracking-tools)由Patrycja
    Jenkner撰写。
- en: '**Machine Learning experiment consists of data, code, and hyperparameters**.
    Make sure you use version control tools for the code, such as Github or Gitlab,
    and commit all your changes during development. It is important to be able to
    revert to older code versions to rerun your older experiments. Version control
    your data. The simplest and most popular way is to create a new folder or a new
    file on the disk (ideally on cloud storage, such as [Amazon S3](https://aws.amazon.com/pm/serv-s3/?trk=518a7bef-5b4f-4462-ad55-80e5c177f12b&sc_channel=ps&ef_id=CjwKCAjwloynBhBbEiwAGY25dBdVqyx2J5k5onI9hVa-eoxeKKXeUqCTPI_1no9-SETi0wuWkPCtKBoCTIQQAvD_BwE%3AG%3As&s_kwcid=AL%214422%213%21645186213484%21e%21%21g%21%21s3%2119579892800%21143689755565)
    or [Google Cloud Storage](https://cloud.google.com/storage)) for each new version
    of the dataset. Some people use a tool called [Data Version Control (DVC)](https://dvc.org/).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习实验由数据、代码和超参数组成**。确保你使用版本控制工具管理代码，如Github或Gitlab，并在开发过程中提交所有更改。能够恢复到旧的代码版本以重新运行旧的实验是很重要的。对数据进行版本控制。最简单和最流行的方法是为每个数据集的新版本创建一个新文件夹或文件（最好是在云存储上，例如[Amazon
    S3](https://aws.amazon.com/pm/serv-s3/?trk=518a7bef-5b4f-4462-ad55-80e5c177f12b&sc_channel=ps&ef_id=CjwKCAjwloynBhBbEiwAGY25dBdVqyx2J5k5onI9hVa-eoxeKKXeUqCTPI_1no9-SETi0wuWkPCtKBoCTIQQAvD_BwE%3AG%3As&s_kwcid=AL%214422%213%21645186213484%21e%21%21g%21%21s3%2119579892800%21143689755565)或[Google
    Cloud Storage](https://cloud.google.com/storage))。有些人使用一个叫做[Data Version Control
    (DVC)](https://dvc.org/)的工具。'
- en: '![](../Images/e2bebee36435d021929903dde14724c8.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2bebee36435d021929903dde14724c8.png)'
- en: ML experiment consists of data, code, and hyperparameters. Image by Author
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ML实验由数据、代码和超参数组成。图片由作者提供
- en: What exactly should you track for the experiment? Well, **it is not a bad idea
    to track everything you can** :) Most of the time you won’t use all that information
    unless an experiment failed and failed really hard.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你究竟应该追踪什么呢？嗯，**追踪你能追踪的所有内容并非坏主意** :) 大多数时候，除非实验失败且失败非常严重，否则你不会用到所有这些信息。
- en: 'Here is a list of the things you may want to consider tracking:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是你可能需要考虑追踪的事项列表：
- en: Git hash of the commit
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提交的Git哈希值
- en: Link to training, validation, and test datasets
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练、验证和测试数据集的链接
- en: Hyperparameters and their change over time (model architecture, learning rate,
    batch size, data augmentations,…)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数及其随时间的变化（模型结构、学习率、批量大小、数据增强等）
- en: Loss plots on training and validation sets
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和验证集上的损失图
- en: Metric plots on training and validation sets
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和验证集上的指标图
- en: Metrics on the test set
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集上的指标
- en: Visualization of training samples with labels (with and without augmentations
    applied)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带标签的训练样本可视化（包括和不包括应用的数据增强）
- en: Visualization of errors on the test set
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集上的错误可视化
- en: Environment (OS, CUDA version, package versions, environment variables)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境（操作系统、CUDA 版本、软件包版本、环境变量）
- en: Training speed, memory usage, CPU/GPU utilization
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练速度、内存使用、CPU/GPU 利用率
- en: Set up an experiment tracking once, and enjoy its benefits forever.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一次性设置实验跟踪，享受其永久的好处。
- en: Model Evaluation
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: Before the model is deployed to production, it must be thoroughly evaluated.
    This evaluation is referred to as “offline”. “Online” evaluation, in contrast,
    is about checking the model that is already running in production. Online evaluation
    will be discussed in the next chapter of this series, and today we are focusing
    solely on offline evaluation.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型部署到生产环境之前，必须彻底评估模型。这种评估称为“离线”评估。相比之下，“在线”评估则是检查已经在生产环境中运行的模型。在线评估将在本系列的下一章中讨论，今天我们只关注离线评估。
- en: '**To perform an offline evaluation we need a metric and a dataset.**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**要进行离线评估，我们需要一个指标和一个数据集。**'
- en: The model is evaluated on the test dataset, the one that you’ve put aside while
    training and tuning hyperparameters. It is assumed that 1) the test set is large
    enough and extremely clean; 2) the model has never seen the test data; 3) the
    test data represents production data. If one of the assumptions is violated, evaluation
    is performed incorrectly, and there is a high risk to get an overly optimistic
    metric and deploy a model that is bad.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在测试数据集上进行评估，这是你在训练和调整超参数时留出的数据集。假设 1）测试集足够大且极其干净；2）模型从未见过测试数据；3）测试数据代表生产数据。如果其中一个假设被违反，评估就会不正确，存在获得过于乐观的指标并部署差模型的高风险。
- en: 'Evaluation on a small test set could give you a good metric simply by chance.
    Evaluation on dirty data won’t show a true model performance. While having errors
    in the training set is more forgiving (you can train on clean labels, dirty labels,
    or even no labels), having errors in the test set can be detrimental. Important
    note: a labeled test set is needed for unsupervised models as well. Otherwise,
    how would you know that your model is good enough?'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在小规模测试集上进行评估可能会偶然得到一个好的指标。对脏数据的评估不会展示模型的真实表现。虽然训练集中出现错误更具包容性（你可以在干净标签、脏标签甚至无标签上进行训练），但测试集中出现错误可能是有害的。重要提示：无监督模型也需要标记的测试集。否则，你如何知道你的模型是否足够好？
- en: '**Make sure your model hasn’t “seen” test data**. Always filter out duplicates,
    so the same sample won’t end up in both training and test sets. Do not split data
    randomly, use time-based or user-based splitting instead. Time-based splitting
    means putting older data into the training set and newer — into the test set.
    User-based splitting means having all data from the same user within the same
    split. And be very careful with data leakages, more details on that is in [Data
    Leakage in Machine Learning: How it can be detected and minimize the risk](/data-leakage-in-machine-learning-how-it-can-be-detected-and-minimize-the-risk-8ef4e3a97562)
    by Prerna Singh.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**确保你的模型没有“见过”测试数据**。始终过滤重复项，以避免相同样本出现在训练集和测试集中。不要随机拆分数据，改用基于时间或用户的拆分。基于时间的拆分意味着将较旧的数据放入训练集，将较新的数据放入测试集。基于用户的拆分意味着将同一用户的所有数据放在同一拆分中。要非常小心数据泄漏，更多详细信息请参阅
    Prerna Singh 的 [《机器学习中的数据泄漏：如何检测并减少风险》](/data-leakage-in-machine-learning-how-it-can-be-detected-and-minimize-the-risk-8ef4e3a97562)。'
- en: 'A metric is a number that is assumed to correlate with the model’s true performance:
    the higher the number — the better the model is. You can choose one or a couple
    of metrics. For instance, typical metrics for a classification task are accuracy,
    precision, recall, and F1 score. Choose something simple and, ideally, explainable,
    so non-technical managers and clients can understand.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是一个假定与模型真实表现相关的数字：数字越高，模型越好。你可以选择一个或几个指标。例如，分类任务的典型指标有准确率、精确率、召回率和 F1 分数。选择一些简单且理想情况下可解释的指标，以便非技术经理和客户也能理解。
- en: 'Below are great posts by Shervin Minaee about metrics for various tasks and
    domains:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Shervin Minaee 关于各种任务和领域指标的优秀文章：
- en: '- [20 Popular Machine Learning Metrics. Part 1: Classification & Regression
    Evaluation Metrics](/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '- [20 个流行的机器学习指标。第 1 部分：分类和回归评估指标](/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce)'
- en: '- [20 Popular Machine Learning Metrics. Part 2: Ranking, & Statistical Metrics](/20-popular-machine-learning-metrics-part-2-ranking-statistical-metrics-22c3e5a937b6)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '- [20个热门机器学习指标。第二部分：排序和统计指标](/20-popular-machine-learning-metrics-part-2-ranking-statistical-metrics-22c3e5a937b6)'
- en: '**Use slice-based metrics and evaluate your model for each data segment you
    can think of** (unless you want to get into a scandal like “[Zoom’s Virtual Background
    Feature Isn’t Built for Black Faces](https://onezero.medium.com/zooms-virtual-background-feature-isn-t-built-for-black-faces-e0a97b591955)”).
    For instance, face detection systems must be evaluated separately for people of
    various races, genders, and ages. E-commerce models worth evaluating for desktop
    vs mobile, various countries, and browsers. Double-check whether each segment
    is well represented in the test set. Slice-based metrics also help with [class
    imbalance](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data):
    seeing precisions and recalls for each class separately helps much more than a
    total precision/recall.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用基于切片的指标并评估你能想到的每个数据片段**（除非你想陷入像“[Zoom的虚拟背景功能不适用于黑人面孔](https://onezero.medium.com/zooms-virtual-background-feature-isn-t-built-for-black-faces-e0a97b591955)”这样的丑闻）。例如，面部检测系统必须分别评估不同种族、性别和年龄的人群。电子商务模型值得评估桌面与移动端、不同国家和浏览器的表现。仔细检查每个片段是否在测试集中得到充分代表。基于切片的指标也有助于解决[类别不平衡](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)问题：分别查看每个类别的精确度和召回率比总的精确度/召回率更有意义。'
- en: 'One more way to avoid scandal (this time it’s “Bank ABC’s new credit scoring
    system discriminates unmarried women”), is to use behavioral tests. A great paper,
    [Beyond Accuracy: Behavioral Testing of NLP Models with CheckList](https://arxiv.org/abs/2005.04118),
    suggests using Minimum Functionality, Invariance, and Directional Expectation
    tests in addition to numerical metrics. Even though the paper focuses on Natural
    Language Processing, these types of tests can be easily applied to tabular data
    and images.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 避免丑闻的另一种方法（这次是“银行ABC的新信用评分系统歧视未婚女性”）是使用行为测试。一篇很棒的论文，[超越准确性：使用CheckList对NLP模型进行行为测试](https://arxiv.org/abs/2005.04118)，建议除了数值指标外，还使用最低功能性、不变性和方向期望测试。尽管这篇论文专注于自然语言处理，这些测试类型也可以很容易地应用于表格数据和图像。
- en: In the example of “Bank ABC’s new credit scoring system discriminates unmarried
    women,” an invariance behavioral test could help a lot. Keep all features the
    same but change marital status and gender and check whether model predictions
    changed. If you see a significant difference in the prediction (when it should
    be “invariant”), probably your model absorbed bias in the training data; this
    needs to be fixed, for instance, by totally removing sensitive (discrimination-prone)
    features from the model inputs.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在“银行ABC的新信用评分系统歧视未婚女性”的例子中，不变性行为测试可能会有很大帮助。保持所有特征不变，但改变婚姻状况和性别，并检查模型预测是否发生变化。如果你看到预测有显著差异（而应当是“不变”的），可能说明你的模型在训练数据中吸收了偏见；这需要修正，例如，通过完全移除模型输入中的敏感（易引起歧视的）特征。
- en: '**And finally, visualize the errors**. Find samples in the test set for which
    the model made an error; visualize them and analyze why this happened. It is because
    the test set is still dirty? Are there enough similar samples in the train set?
    Is there any pattern for model errors? This analysis helps find possible labeling
    errors in the test set and bugs during the training as well as come up with ideas
    on how to improve the model performance even further.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**最后，可视化错误**。找到测试集中模型出错的样本；可视化这些样本并分析为何会发生这些错误。这是因为测试集仍然很脏吗？训练集中是否有足够相似的样本？模型错误是否存在某种模式？这种分析有助于发现测试集中可能的标注错误和训练过程中的漏洞，并提出进一步提高模型性能的想法。'
- en: '![](../Images/bf0324df935549a809547ec16dde3e16.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf0324df935549a809547ec16dde3e16.png)'
- en: Model Evaluation Checklist for your convenience. Image by Author
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 方便使用的模型评估检查清单。图片由作者提供
- en: Conclusion
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this chapter, we have learned how to develop models keeping in mind, that
    the ML algorithm is only a PART of the ML system. Model development starts with
    creating a simple baseline model and continues with iterative improvements over
    it. We come up with the most efficient way to go: take an open-source model and
    build experiments around it, instead of reinventing the wheel or falling into
    the research rabbit hole. We discussed the pitfalls of the “state-of-the-art”
    algorithms and the benefits of data augmentations and transfer learning. We agreed
    on the importance of experiment tracking and learned how to set it up. And finally,
    we talked about offline evaluation — metric selection, proper test sets, slice-based
    evaluation, and behavioral tests.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学会了如何在开发模型时考虑到，机器学习算法只是机器学习系统的一部分。模型开发从创建一个简单的基准模型开始，并通过迭代改进不断推进。我们提出了最有效的方式：利用开源模型并围绕它进行实验，而不是重新发明轮子或陷入研究的泥潭。我们讨论了“最先进”算法的陷阱和数据增强及迁移学习的好处。我们一致认为实验跟踪的重要性，并学习了如何设置它。最后，我们讨论了离线评估——指标选择、适当的测试集、基于切片的评估和行为测试。
- en: We are almost there, one more chapter left. In the next (last) post, you will
    learn about deployment, monitoring, online evaluation, and retraining — the final
    piece of knowledge that will help you build better Machine Learning systems.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们快到达目标了，只剩下最后一章。在下一篇（最后一篇）文章中，你将学习关于部署、监控、在线评估和再训练的内容——这些是帮助你构建更好机器学习系统的最后一块知识。
- en: The finale will be available soon. Subscribe to stay tuned.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最终章将很快发布。订阅以保持关注。
