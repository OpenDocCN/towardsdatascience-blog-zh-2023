- en: A Deep Dive into Autoencoders and Their Relationship to PCA and SVD
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入探讨自编码器及其与 PCA 和 SVD 的关系
- en: 原文：[https://towardsdatascience.com/a-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a?source=collection_archive---------3-----------------------#2023-06-13](https://towardsdatascience.com/a-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a?source=collection_archive---------3-----------------------#2023-06-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a?source=collection_archive---------3-----------------------#2023-06-13](https://towardsdatascience.com/a-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a?source=collection_archive---------3-----------------------#2023-06-13)
- en: An in-depth exploration of autoencoders and dimensionality reduction
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对自编码器和降维技术的深入探索
- en: '[](https://reza-bagheri79.medium.com/?source=post_page-----97e37c81898a--------------------------------)[![Reza
    Bagheri](../Images/7c5a7dc9e6e31048ce31c8d49055987c.png)](https://reza-bagheri79.medium.com/?source=post_page-----97e37c81898a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----97e37c81898a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----97e37c81898a--------------------------------)
    [Reza Bagheri](https://reza-bagheri79.medium.com/?source=post_page-----97e37c81898a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://reza-bagheri79.medium.com/?source=post_page-----97e37c81898a--------------------------------)[![Reza
    Bagheri](../Images/7c5a7dc9e6e31048ce31c8d49055987c.png)](https://reza-bagheri79.medium.com/?source=post_page-----97e37c81898a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----97e37c81898a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----97e37c81898a--------------------------------)
    [Reza Bagheri](https://reza-bagheri79.medium.com/?source=post_page-----97e37c81898a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fda2d000eaa4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a&user=Reza+Bagheri&userId=da2d000eaa4d&source=post_page-da2d000eaa4d----97e37c81898a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----97e37c81898a--------------------------------)
    ·46 min read·Jun 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F97e37c81898a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a&user=Reza+Bagheri&userId=da2d000eaa4d&source=-----97e37c81898a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fda2d000eaa4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a&user=Reza+Bagheri&userId=da2d000eaa4d&source=post_page-da2d000eaa4d----97e37c81898a---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----97e37c81898a--------------------------------)
    ·46 分钟阅读·2023 年 6 月 13 日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F97e37c81898a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a&user=Reza+Bagheri&userId=da2d000eaa4d&source=-----97e37c81898a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F97e37c81898a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a&source=-----97e37c81898a---------------------bookmark_footer-----------)![](../Images/e2dacc0a1ecbcd18de0a94b4ba484e25.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F97e37c81898a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-deep-dive-into-autoencoders-and-their-relationship-to-pca-and-svd-97e37c81898a&source=-----97e37c81898a---------------------bookmark_footer-----------)![](../Images/e2dacc0a1ecbcd18de0a94b4ba484e25.png)'
- en: Image by author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: An autoencoder is a type of neural network that learns to reconstruct its input.
    It consists of an encoder network that compresses the input data into a low-dimensional
    space and a decoder network that reconstructs the input data from that space.
    The encoder and decoder are trained jointly to minimize the reconstruction error
    between the input data and its reconstruction.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种神经网络，它学习重建其输入。它由一个编码器网络组成，将输入数据压缩到一个低维空间中，以及一个解码器网络，从该空间中重建输入数据。编码器和解码器被联合训练，以最小化输入数据与其重建之间的重建误差。
- en: Autoencoders can be used for various tasks such as data compression, denoising,
    feature extraction, anomaly detection, and generative modeling. They have applications
    in a wide range of fields such as computer vision, natural language processing,
    and speech recognition. Autoencoders can be also used for dimensionality reduction.
    In fact, one of the main purposes of autoencoders is to learn a compressed representation
    of the input data, which can be used as a form of dimensionality reduction.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器可以用于各种任务，如数据压缩、去噪、特征提取、异常检测和生成建模。它们在计算机视觉、自然语言处理和语音识别等领域有广泛的应用。自编码器还可以用于降维。实际上，自编码器的主要目的是学习输入数据的压缩表示，这可以作为一种降维形式。
- en: In this article, we will discuss the underlying math behind autoencoders and
    will see how they can do dimensionality reduction. We also look at the relationship
    between an autoencoder, principal component analysis (PCA), and singular value
    decomposition (SVD). We will also show how to implement both linear and…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨自编码器背后的基础数学，并了解它们如何进行降维。我们还将研究自编码器、主成分分析（PCA）和奇异值分解（SVD）之间的关系。我们还将展示如何实现线性和…
