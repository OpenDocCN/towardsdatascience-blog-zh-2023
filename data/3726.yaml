- en: A Simple Solution for Managing Cloud-Based ML-Training
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理基于云的机器学习训练的简单解决方案
- en: 原文：[https://towardsdatascience.com/a-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a?source=collection_archive---------10-----------------------#2023-12-21](https://towardsdatascience.com/a-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a?source=collection_archive---------10-----------------------#2023-12-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a?source=collection_archive---------10-----------------------#2023-12-21](https://towardsdatascience.com/a-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a?source=collection_archive---------10-----------------------#2023-12-21)
- en: How to Implement a Custom Training Solution Using Basic (Unmanaged) Cloud Service
    APIs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用基础（非托管）云服务 API 实现自定义训练解决方案
- en: '[](https://chaimrand.medium.com/?source=post_page-----c80a69c6939a--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----c80a69c6939a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c80a69c6939a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c80a69c6939a--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----c80a69c6939a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://chaimrand.medium.com/?source=post_page-----c80a69c6939a--------------------------------)[![Chaim
    Rand](../Images/c52659c389f167ad5d6dc139940e7955.png)](https://chaimrand.medium.com/?source=post_page-----c80a69c6939a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c80a69c6939a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c80a69c6939a--------------------------------)
    [Chaim Rand](https://chaimrand.medium.com/?source=post_page-----c80a69c6939a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----c80a69c6939a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c80a69c6939a--------------------------------)
    ·18 min read·Dec 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc80a69c6939a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a&user=Chaim+Rand&userId=9440b37e27fe&source=-----c80a69c6939a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9440b37e27fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a&user=Chaim+Rand&userId=9440b37e27fe&source=post_page-9440b37e27fe----c80a69c6939a---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c80a69c6939a--------------------------------)
    · 18 分钟阅读 · 2023年12月21日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc80a69c6939a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a&source=-----c80a69c6939a---------------------bookmark_footer-----------)![](../Images/708f7fdb7efc84080b4ea5662f37e3dd.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc80a69c6939a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-simple-solution-for-managing-cloud-based-ml-training-c80a69c6939a&source=-----c80a69c6939a---------------------bookmark_footer-----------)![](../Images/708f7fdb7efc84080b4ea5662f37e3dd.png)'
- en: '`Photo by [Aditya Chinchure](https://unsplash.com/@adityachinchure?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '`照片由 [Aditya Chinchure](https://unsplash.com/@adityachinchure?utm_source=medium&utm_medium=referral)
    提供，发布在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)`'
- en: In previous posts (e.g., [here](/6-steps-to-migrating-your-machine-learning-project-to-the-cloud-6d9b6e4f18e0))
    we have expanded on the benefits of developing AI models in the cloud. Machine
    Learning projects, especially large ones, typically require **access** to specialized
    machinery (e.g., training accelerators), the ability to **scale** at will, an
    appropriate **infrastructure** for maintaining large amounts of data, and **tools**
    for managing large-scale experimentation. Cloud service providers such as [Amazon
    Web Services (AWS)](https://aws.amazon.com/), [Google Cloud Platform (GCP)](https://cloud.google.com/),
    and [Microsoft Azure](https://azure.microsoft.com/) offer a great number of services
    that are targeted at AI development ranging from low-level infrastructure (e.g.,
    GPUs and virtually infinite object-storage) to highly automated tooling for creating
    custom ML models (e.g., [AWS AutoML](https://aws.amazon.com/machine-learning/automl/)).
    Managed training services (such as [Amazon SageMaker](https://aws.amazon.com/sagemaker/),
    [Google Vertex AI](https://cloud.google.com/vertex-ai), and [Microsoft Azure ML](https://azure.microsoft.com/en-us/products/machine-learning))
    in particular, have made training in the cloud especially easy and increased accessibility
    to prospective ML engineers. To use a managed ML service all you need to do is
    specify your desired instance type, choose an ML framework and version, and point
    to your training script, and the service will automatically start up the chosen
    instances with the requested environment, run the script to train the AI model,
    save the resultant artifacts to a persistent storage location, and tear everything
    down upon completion.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的帖子中（例如，[这里](/6-steps-to-migrating-your-machine-learning-project-to-the-cloud-6d9b6e4f18e0)），我们已经扩展了在云中开发AI模型的好处。机器学习项目，特别是大型项目，通常需要**访问**专用设备（例如，训练加速器）、**按需扩展**的能力、用于维护大量数据的适当**基础设施**以及用于管理大规模实验的**工具**。像[Amazon
    Web Services (AWS)](https://aws.amazon.com/)、[Google Cloud Platform (GCP)](https://cloud.google.com/)和[Microsoft
    Azure](https://azure.microsoft.com/)这样的云服务提供商提供了大量针对AI开发的服务，从低级基础设施（例如，GPU和几乎无限的对象存储）到用于创建自定义ML模型的高度自动化工具（例如，[AWS
    AutoML](https://aws.amazon.com/machine-learning/automl/)）。特别是，管理培训服务（如[Amazon
    SageMaker](https://aws.amazon.com/sagemaker/)、[Google Vertex AI](https://cloud.google.com/vertex-ai)和[Microsoft
    Azure ML](https://azure.microsoft.com/en-us/products/machine-learning)）使得在云中进行培训变得特别容易，并提高了潜在ML工程师的可及性。要使用管理的ML服务，您只需指定所需的实例类型，选择ML框架和版本，并指向您的训练脚本，服务将自动启动所选实例并配置所需环境，运行脚本以训练AI模型，将结果保存到持久存储位置，并在完成后拆除一切。
- en: While a managed training service might be the ideal solution for many ML developers,
    as we will see, there are some occasions that warrant running directly on “unmanaged”
    machine instances and training your models in an unmediated fashion. In these
    situations, i.e., in the absence of an official management layer, it may be desirable
    to include a custom solution for controlling and monitoring your training experiments.
    In this post, we will propose a few steps for building a very simple “poor man’s”
    solution for managing training experiments using the APIs of low-level unmanaged
    cloud services.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然管理培训服务可能是许多ML开发人员的理想解决方案，但正如我们将看到的，有些情况下需要直接在“未管理”机器实例上运行并以非中介方式训练您的模型。在这些情况下，即在没有官方管理层的情况下，可能需要包含一个自定义解决方案来控制和监控您的培训实验。在这篇文章中，我们将提出一些步骤，用于使用低级未管理云服务的API构建一个非常简单的“穷人”解决方案来管理培训实验。
- en: We will begin by noting some of the motivations for training on unmanaged machines
    rather than via managed services. Next, we will identify some of the basic training
    management features that we desire. Finally, we will demonstrate one way to implement
    a simple management system using GCPs APIs for [creating VM instances](https://cloud.google.com/compute/docs/instances/create-start-instance).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先说明在未管理机器上进行训练而不是通过管理服务进行训练的一些动机。接下来，我们将识别一些我们期望的基本训练管理功能。最后，我们将演示一种使用GCP
    API来[创建虚拟机实例](https://cloud.google.com/compute/docs/instances/create-start-instance)的简单管理系统的实现方法。
- en: Although we will demonstrate our solution on GCP, similar solutions can be developed
    on alternative cloud platforms, as well. Please do not interpret our choice of
    GCP or any other tool, framework, or service we should mention as an endorsement
    of its use. There are multiple options available for cloud-based training, each
    with their own advantages and disadvantages. The best choice for you will greatly
    depend on the details of your project. Please be sure to reassess the contents
    of this post against the most up-to-date versions of the APIs and documentation
    at the time that you read this.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们将在 GCP 上演示我们的解决方案，但类似的解决方案也可以在其他云平台上开发。请不要将我们选择 GCP 或任何其他工具、框架或服务视为对其使用的推荐。云端训练有多种选择，每种都有其优缺点。对你来说，最佳选择将很大程度上取决于你项目的具体细节。请务必在阅读时对照最新版本的
    API 和文档重新评估本文内容。
- en: Many thanks to my colleague [Yitzhak Levi](https://www.linkedin.com/in/yitzhak-levi-49a217201/)
    for his contributions to this post.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢我的同事 [Yitzhak Levi](https://www.linkedin.com/in/yitzhak-levi-49a217201/) 对本文的贡献。
- en: Motivation — Limitations of Managed Training Services
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机 — 管理训练服务的局限性
- en: High-level solutions will typically prioritize ease-of-use and increased accessibility
    at the cost of reduced control over the underlying flow. Cloud-based managed training
    services are no different. Along with the convenience (as described above), comes
    a certain loss of control over the details of the training startup and execution.
    Here we will mention a few examples which we hope are representative of the types
    of limitations you might encounter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 高级解决方案通常会优先考虑易用性和更高的可访问性，虽然这意味着对底层流程的控制减少。基于云的管理训练服务也不例外。除了上述的便利性之外，还会有对训练启动和执行细节的一定控制丧失。这里我们将提到几个例子，希望能够代表你可能遇到的限制类型。
- en: 1\. Limitations on choice of machine type
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 机器类型选择的限制
- en: The variety of machine types offered in managed training services does not always
    cover all of the machine types supported by the cloud service provider. For example,
    Amazon SageMaker does not (as of the time of this writing) support training on
    instance types from their [DL1](/training-on-aws-with-habana-gaudi-3126e183048)
    and [Inf2](/dl-training-on-aws-inferentia-53e103597a03) families. For a variety
    of reasons (e.g. cost savings) you might need or want to train on these instance
    types. In such cases you will have no choice but to pass on the luxuries of training
    with Amazon SageMaker.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 管理训练服务中提供的机器类型的种类并不总是涵盖云服务提供商支持的所有机器类型。例如，Amazon SageMaker 不支持其 [DL1](/training-on-aws-with-habana-gaudi-3126e183048)
    和 [Inf2](/dl-training-on-aws-inferentia-53e103597a03) 系列的实例类型（截至本文撰写时）。由于各种原因（如节省成本），你可能需要或希望在这些实例类型上进行训练。在这种情况下，你将不得不放弃使用
    Amazon SageMaker 进行训练的奢华。
- en: 2\. Limited control over the underlying machine image
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 对底层机器镜像的控制有限
- en: Managed training workloads typically run inside a dedicated [Docker](https://www.docker.com/)
    container. You can rely on the service to choose the most appropriate container,
    choose a specific container from a list predefined containers built by the service
    provider (e.g. [AWS Deep Learning Containers](https://github.com/aws/deep-learning-containers)),
    or define your own Docker image customized for your specific needs (e.g. see [here](/customizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812)).
    But, while you have quite a bit of control over the Docker image container, you
    have *no* control over the underlying [machine image](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html).
    In most cases this will not be an issue as Docker is purposely designed to reduce
    dependence on the host system. However, there are situations, particularly when
    dealing with specialized HW (as in the case of training), in which we are dependent
    on specific driver installations in the host image.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 管理训练工作负载通常在专用的 [Docker](https://www.docker.com/) 容器内运行。你可以依赖服务选择最合适的容器，从服务提供商预定义的容器列表中选择特定容器（例如
    [AWS Deep Learning Containers](https://github.com/aws/deep-learning-containers)），或者定义适合你特定需求的自定义
    Docker 镜像（例如见 [这里](/customizing-your-cloud-based-machine-learning-training-environment-part-2-b65a6cf91812)）。但是，虽然你对
    Docker 镜像容器有相当大的控制权，但你对底层的 [机器镜像](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)
    *没有* 控制权。在大多数情况下，这不会成为问题，因为 Docker 旨在减少对主机系统的依赖。然而，在处理专用硬件（如训练时）的情况下，我们需要依赖主机镜像中的特定驱动程序安装。
- en: 3\. Limitations on control over multi-node placement
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 对多节点部署控制的限制
- en: It is common to train large models on multiple machine instances in order to
    increase the speed of training. In such scenarios, the networking capacity and
    latency between the machines can have a critical impact on the speed (and cost)
    of training — due to the continuous exchange of data between them. Ideally, we
    would like the instances to be co-located in the same data center. Unfortunately,
    (as of the time of this writing), managed services, such Amazon SageMaker, limit
    your control over device placement. As a result, you might end up with machines
    in two or more [availability zones](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html)
    which could negatively impact your training time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通常为了提高训练速度，会在多个机器实例上训练大型模型。在这种情况下，机器之间的网络容量和延迟会对训练的速度（和成本）产生关键影响——因为它们之间会不断交换数据。理想情况下，我们希望这些实例位于同一数据中心。不幸的是，（截至本文撰写时），像
    Amazon SageMaker 这样的托管服务限制了你对设备位置的控制。因此，你可能会发现机器分布在两个或多个[可用区](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html)，这可能会对你的训练时间产生负面影响。
- en: 4\. User-privilege limitations
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 用户权限限制
- en: Occasionally, training workloads may require root-level to the system host.
    For example, AWS recently announced [Mountpoint for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mountpoint.html),
    a new [FUSE](https://en.wikipedia.org/wiki/Filesystem_in_Userspace)-based solution
    for high throughput access to data storage and a potential method for optimizing
    the flow of data into your training loop. Unfortunately, this solution can be
    used only in a [Docker environment](https://github.com/awslabs/mountpoint-s3/blob/main/docker/README.md)
    if your container is run with the `*--cap-add SYS_ADMIN*` flag, effectively preventing
    its use in a managed service setting.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，训练工作负载可能需要对系统主机进行根级访问。例如，AWS 最近宣布了[Mountpoint for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mountpoint.html)，这是一种基于[FUSE](https://en.wikipedia.org/wiki/Filesystem_in_Userspace)的新解决方案，用于高吞吐量的数据存储访问，并可能优化数据流入你的训练循环。不幸的是，这个解决方案只能在[Docker
    环境](https://github.com/awslabs/mountpoint-s3/blob/main/docker/README.md)中使用，如果你的容器运行时带有`*--cap-add
    SYS_ADMIN*`标志，这实际上阻止了在托管服务设置中使用它。
- en: 5\. Limitations on Docker start-up settings
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. Docker 启动设置的限制
- en: Some training workloads require the ability to configure particular *docker
    run* settings. For example, if your workload stores training data in shared memory
    (e.g., in */dev/shm*) and your data samples are especially large (e.g., high resolution
    3D point clouds) you may need to specify an increase in the amount of shared memory
    allotted to a Docker container. While Docker enables this via the *shm-size* flag,
    your managed service might block your ability to control this.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一些训练工作负载需要能够配置特定的 *docker run* 设置。例如，如果你的工作负载将训练数据存储在共享内存中（例如，在 */dev/shm* 中），并且你的数据样本特别大（例如，高分辨率的
    3D 点云），你可能需要指定增加分配给 Docker 容器的共享内存量。虽然 Docker 通过 *shm-size* 标志来实现这一点，但你的托管服务可能会阻止你控制这一点。
- en: 6\. Limited access to the training environment
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 训练环境访问受限
- en: One of the side effects of managed training is the reduced accessibility to
    the training environment. Sometimes you require the ability to connect directly
    to your training environment, e.g. for the purposes of debugging failures. When
    running a managed training job, you essentially relinquish all control to the
    service including your ability to access your machines at will. Note that some
    solutions support reduced level access to managed environments assuming appropriate
    configuration of the training job (e.g. see [here](https://github.com/aws-samples/sagemaker-ssh-helper)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 托管训练的副作用之一是对训练环境的访问性降低。有时你需要直接连接到你的训练环境，例如，调试故障时。当运行托管训练任务时，你实际上将所有控制权交给了服务，包括你随意访问机器的能力。请注意，一些解决方案支持对托管环境的有限访问，前提是适当配置训练任务（例如，见[这里](https://github.com/aws-samples/sagemaker-ssh-helper)）。
- en: 7\. Lack of notification upon Spot Instance termination
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 缺乏 Spot 实例终止的通知
- en: '[Spot instances](https://aws.amazon.com/ec2/spot/) are unused machines that
    CSPs often offer at discounted prices. The tradeoff is that these machines can
    be abruptly taken away from you. When using an unmanaged Spot Instance that is
    interrupted, you get a [termination notice](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-instance-termination-notices.html)
    that allows you a bit of time to stop your applications gracefully. If you are
    running a training workload you can use this advance notification to capture the
    latest state of you model and copy it to persistent storage so that you can use
    it to resume later on.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[Spot 实例](https://aws.amazon.com/ec2/spot/) 是 CSPs 通常以折扣价格提供的未使用机器。权衡是这些机器可能会被突然撤回。当使用未管理的
    Spot 实例时，你会收到 [终止通知](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-instance-termination-notices.html)，这使你有一点时间优雅地停止应用程序。如果你正在运行培训工作负载，你可以利用这一提前通知捕获模型的最新状态，并将其复制到持久存储中，以便稍后恢复使用。'
- en: One of the compelling features of managed training services is that they [manage
    the Spot life-cycle](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)
    for you, i.e., you can choose to train on lower cost Spot Instances and rely on
    the managed service to automatically resume interrupted jobs when possible. However,
    when using a Spot Instance via a managed service such as Amazon SageMaker, you
    do *not* get a termination notice. Consequently, when you resume your training
    job it will be from the most recent model state that you captured, not the state
    of the model at the time of preemption. Depending on how often you capture intermediate
    checkpoints, this difference can have an impact on your training costs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 托管训练服务的一个引人注目的特性是它们 [管理 Spot 生命周期](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html)
    ，即你可以选择在成本较低的 Spot 实例上进行训练，并依赖托管服务在可能的情况下自动恢复中断的作业。然而，当通过 Amazon SageMaker 等托管服务使用
    Spot 实例时，你不会收到终止通知。因此，当你恢复训练作业时，将从你捕获的最新模型状态开始，而不是预占时模型的状态。根据你捕获中间检查点的频率，这种差异可能会影响你的训练成本。
- en: Cost Considerations
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 成本考虑
- en: Another property of managed training services that is worth noting is the additional
    cost that is often associated with their use. AI development can be an expensive
    undertaking and you might choose to reduce costs by forgoing the convenience of
    a managed training service in exchange for a simpler custom solution.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的另一个托管训练服务的属性是通常与其使用相关的额外成本。AI 开发可能是一项昂贵的任务，你可能会选择通过放弃托管训练服务的便利，换取一个更简单的自定义解决方案，从而减少成本。
- en: The Kubernetes Alternative
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 替代方案
- en: Container orchestration systems are sometimes put forth as an alternative to
    managed training services. The most popular of these (as of the time of this writing)
    is [Kubernetes](https://kubernetes.io/). With its high level of auto-scalability
    and its support for breaking applications into *microservices*,Kubernetes has
    become the platform of choice for many modern-application developers. This is
    particularly true for applications that include complex flows with multiple interdependent
    components, sometimes referred to as Directed Acyclic Graph **(**DAG) workflows.
    Some end-to-end ML development pipelines can be viewed as a DAG workflow (e.g.,
    beginning with data preparation and processing and ending with model deployment).
    And in fact, Kubernetes-based solutions are often applied to ML pipelines. However,
    when it comes to the training phase alone (as in the context of this post), where
    we typically know the precise number and type of instances, it can be argued that
    [Kubernetes](https://kubernetes.io/) provides little added value. The primary
    disadvantage of Kubernetes is that it usually requires reliance on a dedicated
    infrastructure team for its ongoing support and maintenance.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 容器编排系统有时被提出作为托管训练服务的替代方案。在撰写本文时，最受欢迎的选择是 [Kubernetes](https://kubernetes.io/)。凭借其高度的自动扩展性以及对将应用拆分为*微服务*的支持，Kubernetes
    已成为许多现代应用开发人员的首选平台。这对于包含复杂流程及多个相互依赖组件的应用尤为如此，有时称为有向无环图**(**DAG)工作流。一些端到端的 ML 开发管道可以视为
    DAG 工作流（例如，从数据准备和处理开始，到模型部署结束）。实际上，基于 Kubernetes 的解决方案通常应用于 ML 管道。然而，就仅培训阶段而言（如本文所述），我们通常知道实例的确切数量和类型，可以认为
    [Kubernetes](https://kubernetes.io/) 提供的附加价值有限。Kubernetes 的主要缺点是它通常需要依赖专门的基础设施团队进行持续的支持和维护。
- en: Training Management Minimal Requirements
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练管理最小要求
- en: In the absence of a CSP training management service, let’s define some of the
    basic management features that we would like.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有 CSP 训练管理服务的情况下，让我们定义一些我们希望的基本管理功能。
- en: '**Automatic start-up** — We would like the training script to run automatically
    as soon as the instances start up.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动启动** — 我们希望训练脚本在实例启动后自动运行。'
- en: '**Automatic instance termination** — We would like for the machine instances
    to be automatically terminated as soon as the training script completes so that
    we do not pay for time when the machines are not in use.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动实例终止** — 我们希望机器实例在训练脚本完成后自动终止，以便我们不会为机器不使用时支付费用。'
- en: '**Support for multi-instance training** — We require the ability to start-up
    a cluster of co-located instances for multi-node training.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**支持多实例训练** — 我们需要能够启动一个集群，以便进行多节点训练。'
- en: '**Persistent logs** — We would like for training log output to be written to
    persistent storage so that it can be accessed at will even after the training
    machines are terminated.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**持久日志** — 我们希望训练日志输出写入持久存储，以便在训练机器终止后仍然可以随时访问。'
- en: '**Checkpoint capturing** — We would like for training artifacts, including
    periodic checkpoints, to be saved to persistent storage.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检查点捕获** — 我们希望将训练成果，包括定期检查点，保存到持久存储中。'
- en: '**Summary of training** **jobs**— We would like a method for reviewing (and
    comparing) training experiments.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练任务总结** — 我们希望有一种方法来审查（和比较）训练实验。'
- en: '**Restart on spot termination (advanced feature)** — We would like the ability
    to take advantage of discounted [spot instance](https://aws.amazon.com/ec2/spot/)
    capacity to reduce training costs without jeopardizing continuity of development.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在抢占性终止时重启（高级功能）** — 我们希望能够利用折扣 [抢占实例](https://aws.amazon.com/ec2/spot/) 的容量，以降低训练成本而不影响开发的连续性。'
- en: In the next section we will demonstrate how these can be implemented in GCP.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将展示如何在 GCP 中实现这些功能。
- en: Poor Man’s Managed Training on GCP
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 穷人的 GCP 训练管理
- en: 'In this section we will demonstrate a basic solution for training management
    on GCP using Google’s [gcloud command-line utility](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    (based on Google Cloud SDK version 424.0.0) to [create VM instances](https://cloud.google.com/compute/docs/instances/create-start-instance).
    We will begin with a simple VM instance creation command and gradually supplement
    it with additional components that will incorporate our desired management features.
    Note that the gcloud [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    command includes a long list of optional flags that control many elements of the
    instance creation. For the purposes of our demonstration, we will focus only on
    the controls that are relevant to our solution. We will assume: 1) that your environment
    has been [set up](https://cloud.google.com/sdk/gcloud/reference/auth) to use gcloud
    to connect to GCP, 2) that the default network has been appropriately configured,
    and 3) the existence of a [managed service account](https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances)
    with access permissions to the GCP resources we will use.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示一个基本的训练管理解决方案，使用 Google 的 [gcloud 命令行工具](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)（基于
    Google Cloud SDK 版本 424.0.0）来 [创建 VM 实例](https://cloud.google.com/compute/docs/instances/create-start-instance)。我们将从一个简单的
    VM 实例创建命令开始，并逐步补充额外的组件，以纳入我们所需的管理功能。请注意，gcloud [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    命令包含一长串可选标志，这些标志控制实例创建的许多元素。为了演示的目的，我们将仅关注与我们的解决方案相关的控制。我们假设：1）您的环境已 [设置](https://cloud.google.com/sdk/gcloud/reference/auth)
    以使用 gcloud 连接到 GCP，2）默认网络已适当配置，3）存在具有访问权限的 [托管服务账户](https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances)。
- en: 1\. Create a VM Instance
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 创建 VM 实例
- en: The following command will start up a [g2-standard-48](https://gcloud-compute.com/g2-standard-48.html)
    VM instance (containing four [NVIDIA L4](https://www.nvidia.com/en-us/data-center/l4/)
    GPUs) with the public [M112](https://cloud.google.com/deep-learning-vm/docs/release-notes#October_10_2023)
    VM image. Alternatively, you could choose a [custom image](https://cloud.google.com/compute/docs/images/create-custom).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将启动一个[g2-standard-48](https://gcloud-compute.com/g2-standard-48.html)虚拟机实例（包含四个[NVIDIA
    L4](https://www.nvidia.com/en-us/data-center/l4/) GPU），并使用公共[M112](https://cloud.google.com/deep-learning-vm/docs/release-notes#October_10_2023)虚拟机镜像。或者，您可以选择使用[自定义镜像](https://cloud.google.com/compute/docs/images/create-custom)。
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 2\. Auto-start Training
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 自动启动训练
- en: 'As soon as the machine instance is up and running, we’d like to automatically
    start the training workload. In the example below we will demonstrate this by
    passing a [startup script](https://cloud.google.com/compute/docs/instances/startup-scripts/linux)
    to the gcloud [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    command. Our startup script will perform a few basic environment setup steps and
    then run the training job. We start by adjusting the *PATH* environment variable
    to point to our conda environment, then download the tarball containing our source
    code from Google Storage, unpack it, install the project dependencies, and finally
    run our training script. The demonstration assumes that the tarball has already
    been created and uploaded to the cloud and that it contains two files: a requirements
    file (*requirements.txt*) and a stand-alone training script (*train.py*). In practice,
    the precise contents of the startup script will depend on the project.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦机器实例启动并运行，我们希望自动开始训练工作负载。在下面的示例中，我们将通过将[startup script](https://cloud.google.com/compute/docs/instances/startup-scripts/linux)传递给gcloud
    [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)命令来演示这一点。我们的启动脚本将执行一些基本的环境设置步骤，然后运行训练作业。我们首先调整*PATH*环境变量以指向我们的conda环境，然后从Google
    Storage下载包含源代码的tarball，解压它，安装项目依赖项，最后运行我们的训练脚本。演示假设tarball已经创建并上传到云中，并且它包含两个文件：一个要求文件（*requirements.txt*）和一个独立的训练脚本（*train.py*）。实际上，启动脚本的具体内容将取决于项目。
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 3\. Self-destruct on Completion
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 完成后自毁
- en: One of the compelling features of managed training is that you pay only for
    what you need. More specifically, as soon as your training job is completed, the
    training instances will be automatically torn down. One way to implement this
    is to append a self-destruct command to the end of our training script. Note that
    in order to enable self-destruction the instances need to be created with an appropriate
    *scopes* setting. Please see the [API documentation](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    for more details.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 管理培训的一个引人注目的特点是您只需为所需的部分付费。更具体地说，一旦您的训练作业完成，训练实例将自动拆除。实现这一点的一种方法是在训练脚本的末尾附加一个自毁命令。请注意，为了启用自毁功能，实例需要使用适当的*scopes*设置进行创建。有关更多详细信息，请参阅[API文档](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)。
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It is important to keep in mind that despite our intentions, sometimes the instance
    may not be correctly deleted. This could be the result of a specific error that
    causes the startup-script to exit early or a stalling process that prevents it
    from running to completion. We highly recommend introducing a backend mechanism
    that verifies that unused instances are identified and terminated. One way to
    do this is to schedule a periodic [Cloud Function](https://cloud.google.com/functions?hl=en).
    Please see our [recent post](https://medium.com/towards-data-science/using-server-less-functions-to-govern-and-monitor-cloud-based-training-experiments-755c43fba26b)
    in which we proposed using serverless functions to address this problem when training
    on Amazon SageMaker.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的是，尽管我们有意这样做，但有时实例可能不会被正确删除。这可能是由于特定错误导致启动脚本提前退出，或由于进程停滞而阻止其完成运行。我们强烈建议引入后端机制，以验证未使用的实例是否被识别并终止。实现这一点的一种方法是调度定期的[Cloud
    Function](https://cloud.google.com/functions?hl=en)。请参阅我们的[近期文章](https://medium.com/towards-data-science/using-server-less-functions-to-govern-and-monitor-cloud-based-training-experiments-755c43fba26b)，我们在其中提出了使用无服务器函数来解决在Amazon
    SageMaker上训练时出现的问题。
- en: 4\. Write Application Logs to Persistent Storage
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 将应用程序日志写入持久存储
- en: 'Given that the instances that we train on are terminated upon completion, we
    need to ensure that system output is written to persistent logging. This is important
    for monitoring the progress of the job, investigating errors, etc. In GCP this
    is enabled by the [Cloud Logging](https://cloud.google.com/logging?hl=en) offering.
    By default, output logs are collected for each VM instance. These can be accessed
    with the [Logs Explorer](https://cloud.google.com/logging/docs/view/logs-explorer-interface)
    by using the *instance id* associated with the VM. The following is a sample query
    for accessing the logs of a training job:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们训练时的实例在完成后会被终止，我们需要确保系统输出写入持久日志。这对监控作业进度、调查错误等非常重要。在 GCP 中，这是通过 [Cloud Logging](https://cloud.google.com/logging?hl=en)
    提供的。默认情况下，会为每个 VM 实例收集输出日志。可以使用与 VM 关联的*实例 ID*通过 [Logs Explorer](https://cloud.google.com/logging/docs/view/logs-explorer-interface)
    访问这些日志。以下是访问训练作业日志的示例查询：
- en: '[PRE3]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To be able to query the logs, we need to make sure to capture and store the
    *instance id* of each VM. This has to be done before the instance is terminated.
    In the code block below we use the [compute-instances-describe](https://cloud.google.com/sdk/gcloud/reference/compute/instances/describe)
    API to retrieve the instance id of our VM. We write the id to a file and upload
    it to a dedicated *metadata* folder in the path associated with our project in
    Google Storage for future reference:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够查询日志，我们需要确保捕获并存储每个 VM 的*实例 ID*。这必须在实例终止之前完成。在下面的代码块中，我们使用 [compute-instances-describe](https://cloud.google.com/sdk/gcloud/reference/compute/instances/describe)
    API 来检索我们的 VM 的实例 ID。我们将 ID 写入文件，并将其上传到 Google Storage 中与我们项目关联的路径下的专用*元数据*文件夹中以供将来参考：
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We further populate our *metadata* folder with the full contents of our [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    command. This will come in handy later on:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步将*元数据*文件夹填充了我们 [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    命令的全部内容。这将在后续过程中派上用场：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 5\. Save Artifacts in Persistent Storage
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 将工件保存到持久存储中
- en: 'Importantly, we must ensure that all of the training jobs’ artifacts are uploaded
    to persistent storage before the instance is terminated. The easiest way to do
    this is to append a command to our startup script that syncs the entire output
    folder with Google Storage:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，我们必须确保所有训练作业的工件在实例终止之前上传到持久存储中。最简单的方法是将一个命令附加到我们的启动脚本中，该命令将整个输出文件夹与 Google
    Storage 同步：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The problem with this solution is that it will sync the output only at the end
    of training. If for some reason our machine crashes due to some error, we might
    lose all of the intermediate artifacts. A more fault-tolerant solution would involve
    uploading artifacts to Google Storage (e.g. at fixed training step intervals)
    throughout the training job.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案的问题在于它只会在训练结束时同步输出。如果由于某种错误我们的机器崩溃，我们可能会丢失所有中间工件。一个更具容错性的解决方案是，在整个训练作业过程中，将工件上传到
    Google Storage（例如，在固定的训练步骤间隔）：
- en: 6\. Support Multi-node Training
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 支持多节点训练
- en: To run a multi-node training job we can use the [compute-instances-bulk-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/bulk/create)
    API to [create a group of GPU VMs](https://cloud.google.com/compute/docs/gpus/create-gpu-vm-bulk).
    The command below will create two [g2-standard-48](https://gcloud-compute.com/g2-standard-48.html)
    VM instances.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行多节点训练作业，我们可以使用 [compute-instances-bulk-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/bulk/create)
    API 来 [创建一组 GPU VM](https://cloud.google.com/compute/docs/gpus/create-gpu-vm-bulk)。下面的命令将创建两个
    [g2-standard-48](https://gcloud-compute.com/g2-standard-48.html) VM 实例。
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'There are a few important differences from the single VM creation command:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与单个 VM 创建命令相比，有一些重要的区别：
- en: For bulk creation we specify a *region* rather than a *zone*. We chose to force
    all instances to be in a single zone by setting the [*target-distribution-shape*](https://cloud.google.com/compute/docs/instance-groups/regional-mig-distribution-shape)
    flag to *any_single_zone*.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于批量创建，我们指定一个*区域*而不是*区域*。我们选择通过将 [*target-distribution-shape*](https://cloud.google.com/compute/docs/instance-groups/regional-mig-distribution-shape)
    标志设置为 *any_single_zone* 来强制所有实例位于一个区域内。
- en: We have prepended a number of environment variable definitions to our startup
    script. These will be used to properly configure the training script to run on
    all nodes.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在启动脚本中添加了多个环境变量定义。这些将用于正确配置训练脚本以在所有节点上运行。
- en: To delete a VM instance we need to know the *zone* in which it was created.
    Since we do not know this when we run our bulk creation command, we need to extract
    it programmatically in the startup-script.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要删除VM实例，我们需要知道它创建时的*zone*。由于在运行批量创建命令时我们并不知道这一点，我们需要在启动脚本中以编程方式提取它。
- en: We now capture and store the instance ids of *both* of the created VMs.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在捕获并存储*both*创建的VM实例的ID。
- en: In the script below we demonstrate how to use the environment settings to configure
    [data parallel training](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
    in [PyTorch](https://pytorch.org/).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的脚本中，我们演示如何使用环境设置在[PyTorch](https://pytorch.org/)中配置[data parallel training](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)。
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 7\. Experiment Summary Reports
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7. 实验总结报告
- en: 'Managed services typically expose an API and/or a dashboard for reviewing the
    status and outcomes of training jobs. You will likely want to include a similar
    feature in your custom management solution. There are many ways to do this including
    using a [Google Cloud Database](https://cloud.google.com/products/databases?hl=en)
    to maintain training job metadata or using third party tools (such as [neptune.ai](https://neptune.ai/),
    [Comet](https://www.comet.com/site/), or [Weights & Biases](https://wandb.ai/site))
    to record and compare training results. The function below assumes that the training
    application return code was uploaded (from the startup script) to our dedicated
    *metadata* folder, and simply iterates over the jobs in Google Storage:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 托管服务通常会暴露一个API和/或一个仪表盘，以查看训练作业的状态和结果。你可能会想在自定义管理解决方案中包含类似功能。实现此功能的方法有很多，包括使用[Google
    Cloud Database](https://cloud.google.com/products/databases?hl=en)来维护训练作业的元数据，或者使用第三方工具（如
    [neptune.ai](https://neptune.ai/), [Comet](https://www.comet.com/site/), 或 [Weights
    & Biases](https://wandb.ai/site)）来记录和比较训练结果。以下函数假设训练应用程序的返回代码已被上传（来自启动脚本）到我们的专用*metadata*文件夹，并简单地遍历Google
    Storage中的作业：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The code above will generate a table with the following format:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将生成以下格式的表格：
- en: '![](../Images/3753e9bf01d0e1dea9d613cacf4a58f1.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3753e9bf01d0e1dea9d613cacf4a58f1.png)'
- en: Table of Training Experiments (by Author)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 训练实验表（按作者分类）
- en: 8\. Support Spot Instance Usage
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8. 支持Spot实例使用
- en: We can easily modify our single-node creation script to use [Spot VM](https://cloud.google.com/compute/docs/instances/spot)s
    by setting the [*provisioning-model*](https://cloud.google.com/compute/docs/instances/create-use-spot#create)
    flag to *SPOT* and the [*instance-termination-action*](https://cloud.google.com/compute/docs/instances/create-use-spot#create)flag
    to *DELETE*. However, we would like our training management solution to manage
    the full life-cycle of Spot VM utilization, i.e. to identify Spot preemptions
    and restart unfinished jobs when possible. There are many ways of supporting this
    feature. In the example below we define a dedicate Google Storage path, *gs://my-bucket/preempted-jobs/*
    , that maintains a list of names of unfinished training jobs and define a shutdown
    script to identify a Spot preemption and populate our list with the current job
    name. Our shutdown script is a stripped down version of the script recommended
    in the [documentation](https://cloud.google.com/compute/docs/instances/create-use-spot#handle-preemption).
    In practice, you may want to include logic for capturing and uploading the latest
    model state.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将[*provisioning-model*](https://cloud.google.com/compute/docs/instances/create-use-spot#create)标志设置为*SPOT*，以及将[*instance-termination-action*](https://cloud.google.com/compute/docs/instances/create-use-spot#create)标志设置为*DELETE*，轻松修改我们的单节点创建脚本以使用[Spot
    VM](https://cloud.google.com/compute/docs/instances/spot)。不过，我们希望我们的训练管理解决方案能够管理Spot
    VM使用的完整生命周期，即识别Spot抢占并在可能时重新启动未完成的作业。支持此功能的方法有很多。在下面的示例中，我们定义了一个专用的Google Storage路径
    *gs://my-bucket/preempted-jobs/* ，该路径维护一个未完成训练作业名称的列表，并定义一个关闭脚本以识别Spot抢占并将当前作业名称添加到列表中。我们的关闭脚本是[文档](https://cloud.google.com/compute/docs/instances/create-use-spot#handle-preemption)中推荐脚本的精简版本。实际上，你可能希望包含捕获和上传最新模型状态的逻辑。
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We copy the contents of our shutdown script to a *shutdown.sh* file and add
    the [*metadata-from-file*](https://cloud.google.com/compute/docs/shutdownscript#provide_a_shutdown_script_file)flag
    with the location of the script.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将关闭脚本的内容复制到一个*shutdown.sh*文件中，并添加[*metadata-from-file*](https://cloud.google.com/compute/docs/shutdownscript#provide_a_shutdown_script_file)标志，指明脚本的位置。
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Working with shutdown scripts in GCP has [some caveats](https://cloud.google.com/compute/docs/shutdownscript#limitations)
    that you should make sure to be aware of. In particular, the precise behavior
    may vary based on the machine image and other components in the environment. In
    some cases, you might choose to program the shutdown behavior directly into the
    machine image (e.g., see [here](https://stackoverflow.com/questions/61110921/shutdown-script-not-executing-on-a-google-cloud-vm)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GCP 中使用关机脚本有[一些注意事项](https://cloud.google.com/compute/docs/shutdownscript#limitations)，你应该确保了解。特别是，具体行为可能会根据机器镜像和环境中的其他组件有所不同。在某些情况下，你可能会选择将关机行为直接编程到机器镜像中（例如，参见[这里](https://stackoverflow.com/questions/61110921/shutdown-script-not-executing-on-a-google-cloud-vm)）。
- en: The final component to the solution requires a [Cloud Function](https://cloud.google.com/functions?hl=en)
    that traverses the list of items in *gs://my-bucket/preempted-jobs/* and for each
    one retrieves the associated initialization command (e.g., *gs://my-bucket/test-vm/metadata/create-instance.sh*)
    and attempts to rerun it. If it succeeds, it removes the job name from the list.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的解决方案组件需要一个[云函数](https://cloud.google.com/functions?hl=en)，它遍历*gs://my-bucket/preempted-jobs/*中的项目列表，并为每个项目检索相关的初始化命令（例如，*gs://my-bucket/test-vm/metadata/create-instance.sh*），并尝试重新运行。如果成功，它会从列表中移除作业名称。
- en: '[PRE12]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The Cloud Function can be programmed to run periodically and/or we can design
    a mechanism that [triggers](https://cloud.google.com/functions/docs/calling) it
    from the shutdown script.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 云函数可以编程定期运行和/或我们可以设计一个机制来[触发](https://cloud.google.com/functions/docs/calling)它从关机脚本。
- en: '**Multi-node Spot usage**: When applying Spot utilization to multi-node jobs,
    we need to address the possibility that only a subset of nodes will be terminated.
    The easiest way to handle this is to program our application to identify when
    some of the nodes have become unresponsive, discontinue the training loop, and
    proceed to shut down.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**多节点 Spot 使用**：当将 Spot 使用应用于多节点作业时，我们需要解决可能只有一部分节点被终止的问题。处理这个问题最简单的方法是编程让应用程序识别当一些节点变得无响应时，停止训练循环，并继续关机。'
- en: Managed-Training Customization
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 受管理训练定制
- en: One of the advantages of building your own managed training solution is your
    ability to customize it to your specific needs. In the previous section we demonstrated
    how to design a custom solution for managing the Spot VM life cycle. We can similarly
    use tools such as [Cloud Monitoring Alerts](https://cloud.google.com/monitoring/alerts),
    [Cloud Sub/Pub](https://cloud.google.com/pubsub/docs/overview) messaging services,
    and serverless [Cloud Functions](https://cloud.google.com/functions?hl=en), to
    tailor solutions for other challenges, such as cleaning up stalled jobs, identifying
    under-utilized GPU resources, limiting the overall up-time of VMs, and governing
    developer usage patterns. Please see our [recent post](https://chaimrand.medium.com/using-server-less-functions-to-govern-and-monitor-cloud-based-training-experiments-755c43fba26b)
    in which we demonstrated how to apply serverless functions to some of these challenges
    in a managed training setting.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 构建自己的受管理训练解决方案的一个优势是可以根据特定需求进行定制。在上一节中，我们演示了如何设计一个自定义解决方案来管理 Spot VM 生命周期。我们还可以类似地使用[云监控警报](https://cloud.google.com/monitoring/alerts)、[云订阅/发布](https://cloud.google.com/pubsub/docs/overview)消息服务和无服务器[云函数](https://cloud.google.com/functions?hl=en)等工具，来量身定制其他挑战的解决方案，例如清理停滞作业、识别利用不足的
    GPU 资源、限制 VM 的总体运行时间以及管理开发者使用模式。请参见我们的[近期帖子](https://chaimrand.medium.com/using-server-less-functions-to-govern-and-monitor-cloud-based-training-experiments-755c43fba26b)，我们演示了如何将无服务器函数应用于受管理训练环境中的这些挑战。
- en: 'Note that the management solution we have defined addresses each of the limitations
    of managed training that we listed above:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们定义的管理解决方案解决了我们上述列出的受管理训练的每个限制：
- en: The gcloud [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    API exposes all of the VM instance types offered by GCP and allows you to point
    to the machine image of your choice.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: gcloud [compute-instances-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/create)
    API 公开了 GCP 提供的所有 VM 实例类型，并允许你指定你选择的机器镜像。
- en: The gcloud [compute-instances-bulk-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/bulk/create)
    API allows us to start up multiple nodes in a way that ensures that all nodes
    are co-located in the same *zone*.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: gcloud [compute-instances-bulk-create](https://cloud.google.com/sdk/gcloud/reference/compute/instances/bulk/create)
    API 允许我们以确保所有节点在同一*区域*中共同部署的方式启动多个节点。
- en: Our solution supports running in a non-containerized environment. If you choose
    to use containers nonetheless, you can configure them with any setting and any
    user privilege that you want.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的解决方案支持在非容器化环境中运行。如果你选择使用容器，你可以用任何设置和用户权限进行配置。
- en: GCP VMs support SSH access (e.g. via the gcloud [compute-ssh](https://cloud.google.com/compute/docs/connect/standard-ssh)
    command).
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GCP VMs 支持 SSH 访问（例如通过 gcloud [compute-ssh](https://cloud.google.com/compute/docs/connect/standard-ssh)
    命令）。
- en: The Spot VM lifecycle support we described supports capturing and acting on
    [preemption notifications](https://cloud.google.com/compute/docs/instances/spot#preemption-process).
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们描述的 Spot VM 生命周期支持捕获和处理[抢占通知](https://cloud.google.com/compute/docs/instances/spot#preemption-process)。
- en: Having Said All That…
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 说了这么多……
- en: There is no denying the convenience of using managed training services (such
    as [Amazon SageMaker](https://aws.amazon.com/pm/sagemaker/), [Google Vertex AI](https://cloud.google.com/vertex-ai),
    and [Microsoft Azure ML](https://azure.microsoft.com/en-us/products/machine-learning)).
    Not only do they take care of all of the managed requirements we listed above
    for you, but they typically offer additional features such as [hyperparameter
    optimization](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html),
    [platform optimized distributed training libraries](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html),
    [specialized development environments](https://docs.aws.amazon.com/sagemaker/latest/dg/machine-learning-environments.html),
    and more. Indeed, there are sometimes very good reasons to develop your own management
    solution, but it may be a good idea to fully explore all opportunities for using
    existing solutions before taking that path.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用托管训练服务（例如[Amazon SageMaker](https://aws.amazon.com/pm/sagemaker/)、[Google
    Vertex AI](https://cloud.google.com/vertex-ai)和[Microsoft Azure ML](https://azure.microsoft.com/en-us/products/machine-learning/)）的便利性毋庸置疑。它们不仅处理了我们上面列出的所有托管需求，还通常提供额外功能，如[超参数优化](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)、[平台优化的分布式训练库](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html)、[专用开发环境](https://docs.aws.amazon.com/sagemaker/latest/dg/machine-learning-environments.html)等。确实，有时开发自己的管理解决方案是有很好的理由的，但在走这条路之前，完全探索使用现有解决方案的所有机会可能是个好主意。
- en: Summary
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: While the cloud can present an ideal domain for developing AI models, an appropriate
    training management solution is essential for making its use effective and efficient.
    Although CSPs offer dedicated managed training services, they don’t always align
    with our project requirements. In this post, we have shown how a simple management
    solution can be designed by using some of the advanced controls of the lower level,
    unmanaged, machine instance creation APIs. Naturally, one size does *not* fit
    all; the most ideal design will highly depend on the precise details of your AI
    project(s). But we hope that our post has given you some ideas with which to start.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管云计算可以为开发 AI 模型提供理想的领域，但合适的训练管理解决方案对于使其使用有效和高效至关重要。尽管 CSP 提供专门的托管训练服务，但它们并不总是与我们的项目要求对齐。在这篇文章中，我们展示了如何通过使用一些高级控制的低级、未管理的机器实例创建
    API 设计一个简单的管理解决方案。自然，一刀切的方案*不适用于所有情况*；最理想的设计将高度依赖于你 AI 项目的具体细节。但我们希望我们的文章能为你提供一些开始的思路。
