- en: A gentle introduction to Steerable Neural Networks (part 1)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯è°ƒæ•´ç¥ç»ç½‘ç»œçš„æ¸©å’Œä»‹ç»ï¼ˆç¬¬1éƒ¨åˆ†ï¼‰
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f?source=collection_archive---------0-----------------------#2023-11-21](https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f?source=collection_archive---------0-----------------------#2023-11-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f?source=collection_archive---------0-----------------------#2023-11-21](https://towardsdatascience.com/a-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f?source=collection_archive---------0-----------------------#2023-11-21)
- en: What are Steerable Neural Networks and context
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯å¯è°ƒæ•´ç¥ç»ç½‘ç»œåŠå…¶èƒŒæ™¯
- en: '[](https://medium.com/@mat.cip43?source=post_page-----32323d95b03f--------------------------------)[![Matteo
    Ciprian](../Images/61dab88069d99263e941a0e549473bdf.png)](https://medium.com/@mat.cip43?source=post_page-----32323d95b03f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----32323d95b03f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----32323d95b03f--------------------------------)
    [Matteo Ciprian](https://medium.com/@mat.cip43?source=post_page-----32323d95b03f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mat.cip43?source=post_page-----32323d95b03f--------------------------------)[![Matteo
    Ciprian](../Images/61dab88069d99263e941a0e549473bdf.png)](https://medium.com/@mat.cip43?source=post_page-----32323d95b03f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----32323d95b03f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----32323d95b03f--------------------------------)
    [Matteo Ciprian](https://medium.com/@mat.cip43?source=post_page-----32323d95b03f--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F975b976da56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f&user=Matteo+Ciprian&userId=975b976da56a&source=post_page-975b976da56a----32323d95b03f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----32323d95b03f--------------------------------)
    Â·15 min readÂ·Nov 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F32323d95b03f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f&user=Matteo+Ciprian&userId=975b976da56a&source=-----32323d95b03f---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F975b976da56a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f&user=Matteo+Ciprian&userId=975b976da56a&source=post_page-975b976da56a----32323d95b03f---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----32323d95b03f--------------------------------)
    Â·15åˆ†é’Ÿé˜…è¯»Â·2023å¹´11æœˆ21æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F32323d95b03f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f&user=Matteo+Ciprian&userId=975b976da56a&source=-----32323d95b03f---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F32323d95b03f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f&source=-----32323d95b03f---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F32323d95b03f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-introduction-to-steerable-neural-networks-part-1-32323d95b03f&source=-----32323d95b03f---------------------bookmark_footer-----------)'
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: Geometrical deep learning, as a branch of Deep Learning, aims to extend traditional
    AI frameworks such as Convolutional Neural Networks to process 3D or 2D geometric
    objects represented as graphs, manifolds, or point clouds. By incorporating geometric
    relationships and spatial dependencies directly into the learning framework, geometrical
    deep learning harnesses the inherent structural properties of data to eliminate
    the requirement for memory-intensive data augmentation techniques. For all these
    reasons, Geometrical Deep Learning can be seen as valuable tool for tackling complex
    data scenarios in domains such as computer vision, natural language processing,
    and beyond. Concerning the type of task and the type of transformation, a large
    variety of new CNN architectures have been proposed so far as â€œSpherical Neural
    Networksâ€ ([link](https://arxiv.org/abs/1801.10130)), â€œGraph Neural Networksâ€
    (l[ink](https://arxiv.org/pdf/1812.08434.pdf%2523:~:text=Graph%252520neural%252520networks%252520%28GNNs%29%252520are,its%252520neighborhood%252520with%252520arbitrary%252520depth.)),
    and **â€œSteerable Neural Networksâ€.**
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ä½•æ·±åº¦å­¦ä¹ ä½œä¸ºæ·±åº¦å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨æ‰©å±•ä¼ ç»Ÿçš„AIæ¡†æ¶ï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼Œä»¥å¤„ç†è¡¨ç¤ºä¸ºå›¾ã€æµå½¢æˆ–ç‚¹äº‘çš„ä¸‰ç»´æˆ–äºŒç»´å‡ ä½•å¯¹è±¡ã€‚é€šè¿‡ç›´æ¥å°†å‡ ä½•å…³ç³»å’Œç©ºé—´ä¾èµ–æ€§æ•´åˆåˆ°å­¦ä¹ æ¡†æ¶ä¸­ï¼Œå‡ ä½•æ·±åº¦å­¦ä¹ åˆ©ç”¨æ•°æ®çš„å›ºæœ‰ç»“æ„ç‰¹æ€§ï¼Œæ¶ˆé™¤äº†å¯¹å†…å­˜å¯†é›†å‹æ•°æ®å¢å¼ºæŠ€æœ¯çš„éœ€æ±‚ã€‚å‡ºäºæ‰€æœ‰è¿™äº›åŸå› ï¼Œå‡ ä½•æ·±åº¦å­¦ä¹ å¯ä»¥è¢«è§†ä¸ºåœ¨è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå¤„ç†å¤æ‚æ•°æ®åœºæ™¯çš„æœ‰ä»·å€¼å·¥å…·ã€‚å…³äºä»»åŠ¡ç±»å‹å’Œè½¬æ¢ç±»å‹ï¼Œè¿„ä»Šå·²æå‡ºäº†å¤§é‡æ–°çš„CNNæ¶æ„ï¼Œå¦‚â€œçƒå½¢ç¥ç»ç½‘ç»œâ€
    ([é“¾æ¥](https://arxiv.org/abs/1801.10130))ï¼Œ â€œå›¾ç¥ç»ç½‘ç»œâ€ ([é“¾æ¥](https://arxiv.org/pdf/1812.08434.pdf%2523:~:text=Graph%252520neural%252520networks%252520%28GNNs%2529%252520are,its%252520neighborhood%252520with%252520arbitrary%252520depth.))
    å’Œ **â€œå¯è½¬å‘ç¥ç»ç½‘ç»œâ€**ã€‚
- en: '***Steerable Neural Networks*** *have garnered significant interest due to
    their unique ability to extend the capabilities of regular Convolutional Neural
    Networks (CNNs). These networks can be viewed as an evolution of CNNs, where the
    kernel is conditioned to satisfy specific constraints. While CNNs excel at being*
    ***equivariant*** *to translation, Steerable Neural Networks take it a step further
    by offering enhanced flexibility and capturing a* ***wider range of transformations****,
    such as rotation.*'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***å¯è½¬å‘ç¥ç»ç½‘ç»œ*** *å› å…¶å°†å¸¸è§„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰çš„èƒ½åŠ›æ‰©å±•åˆ°æ–°çš„é¢†åŸŸè€Œå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚è¿™äº›ç½‘ç»œå¯ä»¥è¢«è§†ä¸ºCNNsçš„æ¼”å˜ï¼Œå…¶ä¸­æ ¸è¢«æ¡ä»¶åŒ–ä»¥æ»¡è¶³ç‰¹å®šçº¦æŸæ¡ä»¶ã€‚è™½ç„¶CNNsåœ¨å¯¹å¹³ç§»çš„ç­‰å˜æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å¯è½¬å‘ç¥ç»ç½‘ç»œé€šè¿‡æä¾›å¢å¼ºçš„çµæ´»æ€§å’Œæ•è·æ›´å¹¿æ³›çš„è½¬æ¢ï¼Œå¦‚æ—‹è½¬ï¼Œè€Œæ›´è¿›ä¸€æ­¥ã€‚*'
- en: '**This tutorial** will present an introduction to â€œSteerable Neural Networksâ€
    (S-CNNs), trying to convey an intuitive understanding of the mathematical concepts
    behind them and a step-by-step explanation on how to design these networks.The
    tutorial is composed of two articles. This **first** article serves as an introduction
    to steerable neural networks (NNs), explaining their purpose and delving deeper
    into the concepts and formalism underlying S-CNNs. The **second** article ([here](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690))
    discusses at a high level the design of steerable filters and the steerable networks
    as overall.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ¬æ•™ç¨‹** å°†ä»‹ç»â€œå¯è½¬å‘ç¥ç»ç½‘ç»œâ€ï¼ˆS-CNNsï¼‰çš„ç®€ä»‹ï¼Œè¯•å›¾ä¼ è¾¾å¯¹å…¶èƒŒåæ•°å­¦æ¦‚å¿µçš„ç›´è§‚ç†è§£ä»¥åŠå¦‚ä½•è®¾è®¡è¿™äº›ç½‘ç»œçš„é€æ­¥è§£é‡Šã€‚æœ¬**ç¬¬ä¸€ç¯‡**æ–‡ç« ä½œä¸ºä»‹ç»å¯è½¬å‘ç¥ç»ç½‘ç»œçš„èµ·ç‚¹ï¼Œè§£é‡Šå…¶ç›®çš„å¹¶æ·±å…¥æ¢è®¨æ”¯æŒS-CNNsçš„æ¦‚å¿µå’Œå½¢å¼åŒ–ã€‚**ç¬¬äºŒç¯‡**æ–‡ç« ï¼ˆ[è¿™é‡Œ](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-2-56dfc256b690)ï¼‰åœ¨é«˜å±‚æ¬¡ä¸Šè®¨è®ºäº†å¯è½¬å‘æ»¤æ³¢å™¨çš„è®¾è®¡å’Œæ•´ä½“å¯è½¬å‘ç½‘ç»œã€‚'
- en: This work aims at filling the gap between the current scientific literature
    and the wider data science audience. It is ideal for tech professionals as well
    as for researchers in this new branch of machine learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬å·¥ä½œæ—¨åœ¨å¡«è¡¥å½“å‰ç§‘å­¦æ–‡çŒ®ä¸æ›´å¹¿æ³›æ•°æ®ç§‘å­¦å—ä¼—ä¹‹é—´çš„å·®è·ã€‚å®ƒéå¸¸é€‚åˆæŠ€æœ¯ä¸“ä¸šäººå£«ä»¥åŠè¿™ä¸€æ–°çš„æœºå™¨å­¦ä¹ åˆ†æ”¯çš„ç ”ç©¶äººå‘˜ã€‚
- en: '![](../Images/199602fecfa6cfb6243546f2201a27b0.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/199602fecfa6cfb6243546f2201a27b0.png)'
- en: Example of a simple Steerable Neural Network taken from the paper [[3]](https://arxiv.org/abs/1711.07289).
    As possible to see the effect of rotation in the input image is reflected to the
    the output response of the network.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ªè®ºæ–‡[[3]](https://arxiv.org/abs/1711.07289)çš„ä¸€ä¸ªç®€å•å¯è½¬å‘ç¥ç»ç½‘ç»œçš„ç¤ºä¾‹ã€‚å¯ä»¥çœ‹åˆ°è¾“å…¥å›¾åƒçš„æ—‹è½¬æ•ˆæœåæ˜ åœ¨ç½‘ç»œè¾“å‡ºå“åº”ä¸­ã€‚
- en: 'The following papers are taken as reference:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹è®ºæ–‡ä½œä¸ºå‚è€ƒï¼š
- en: '[1] â€œ3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric
    Dataâ€, Weilier et al., ([link](https://arxiv.org/abs/1807.02547));'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] â€œ3D å¯è½¬å‘ CNNï¼šåœ¨ä½“ç§¯æ•°æ®ä¸­å­¦ä¹ æ—‹è½¬ç­‰å˜ç‰¹å¾â€ï¼ŒWeilier ç­‰ï¼Œ([link](https://arxiv.org/abs/1807.02547));'
- en: '[2] â€œSteerable CNNsâ€, Cohen et al. [( link](https://arxiv.org/abs/1612.08498));'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] â€œå¯è½¬å‘ CNNâ€ï¼ŒCohen ç­‰ï¼Œ([link](https://arxiv.org/abs/1612.08498));'
- en: '[3] â€œLearning Steerable Filters for Rotation Equivariant CNNsâ€,Weilier et al.,
    ([link](https://arxiv.org/abs/1711.07289))'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] â€œå­¦ä¹ ç”¨äºæ—‹è½¬ç­‰å˜ CNN çš„å¯è½¬å‘æ»¤æ³¢å™¨â€ï¼ŒWeilier ç­‰ï¼Œ([link](https://arxiv.org/abs/1711.07289))'
- en: '[4] â€œGeneral E(2)-Equivariant Steerable CNNsâ€ Weilier et al., ([link](https://arxiv.org/abs/1911.08251))'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] â€œé€šç”¨ E(2)-ç­‰å˜å¯è½¬å‘ CNNâ€ Weilier ç­‰ï¼Œ([link](https://arxiv.org/abs/1911.08251))'
- en: '[5] â€œScale Steerable Filters for the Locally Scale-Invariant Convolutional
    Neural Networkâ€, Ghosh et al. ([link](https://www.researchgate.net/publication/334480982_Scale_Steerable_Filters_for_the_Locally_Scale-Invariant_Convolutional_Neural_Network?enrichId=rgreq-7fc8b3654779eb94d36221a6e5fab2ff-XXX&enrichSource=Y292ZXJQYWdlOzMzNDQ4MDk4MjtBUzo3ODEyNTQ4ODI1MDg4MDBAMTU2MzI3NzA4NzY1NA%25253D%25253D&el=1_x_3&_esc=publicationCoverPdf))'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] â€œé€‚ç”¨äºå±€éƒ¨å°ºåº¦ä¸å˜å·ç§¯ç¥ç»ç½‘ç»œçš„å°ºåº¦å¯è½¬å‘æ»¤æ³¢å™¨â€ï¼ŒGhosh ç­‰ï¼Œ([link](https://www.researchgate.net/publication/334480982_Scale_Steerable_Filters_for_the_Locally_Scale-Invariant_Convolutional_Neural_Network?enrichId=rgreq-7fc8b3654779eb94d36221a6e5fab2ff-XXX&enrichSource=Y292ZXJQYWdlOzMzNDQ4MDk4MjtBUzo3ODEyNTQ4ODI1MDg4MDBAMTU2MzI3NzA4NzY1NA%25253D%25253D&el=1_x_3&_esc=publicationCoverPdf))'
- en: '[6] â€œA program to build E(n)-equivariant steerable CNNs.â€ Cesa et al. ([link](https://openreview.net/pdf?id=WE4qe9xlnQw))'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] â€œæ„å»º E(n)-ç­‰å˜å¯è½¬å‘ CNN çš„ç¨‹åºã€‚â€ Cesa ç­‰ï¼Œ([link](https://openreview.net/pdf?id=WE4qe9xlnQw))'
- en: 'What are Steerable Neural Networks:'
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯å¯è½¬å‘ç¥ç»ç½‘ç»œï¼š
- en: Steerable neural networks take their name from the particular type of filters
    they use. Such filters are called g-*steerable filters* and they have been inspired
    by the steerable filters which gained popularity in the image recognition field
    for edge detection or oriented texture analysis at the [beginning of the 90â€™s](https://ieeexplore.ieee.org/document/93808).
    Steerable means commonly dirigible, manageable, capable of being managed or controlled.
    Following this convention, the response of a steerable filters is orientable and
    adaptable to a specific orientation of the input (an image for example). Steerability
    is related to another very important property which is called **Equivariance**.
    In an equivariant filter, if the INPUT to the filter is transformed according
    to a precise and well-defined geometric transformation *g* (translation, rotation,
    shift), the OUTPUT (which results from the convolution of the INPUT with the filter)
    is transformed by the same transformation *g*. In general, equivariance does not
    require that the transformations (the one at the input and the one at the output)
    are the same. This concept will be better addressed in the next paragraph but
    for now it allows us to provide a first definition of steerable filter and steerable
    CNN.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å¯è½¬å‘ç¥ç»ç½‘ç»œå¾—åäºå®ƒä»¬ä½¿ç”¨çš„ç‰¹å®šç±»å‹çš„æ»¤æ³¢å™¨ã€‚è¿™äº›æ»¤æ³¢å™¨ç§°ä¸º g-*å¯è½¬å‘æ»¤æ³¢å™¨*ï¼Œå®ƒä»¬çš„çµæ„Ÿæ¥è‡ªäºåœ¨å›¾åƒè¯†åˆ«é¢†åŸŸä¸­ç”¨äºè¾¹ç¼˜æ£€æµ‹æˆ–å®šå‘çº¹ç†åˆ†æçš„å¯è½¬å‘æ»¤æ³¢å™¨ï¼Œè¿™äº›æ»¤æ³¢å™¨åœ¨[90å¹´ä»£åˆ](https://ieeexplore.ieee.org/document/93808)è·å¾—äº†å¹¿æ³›çš„åº”ç”¨ã€‚å¯è½¬å‘é€šå¸¸æŒ‡çš„æ˜¯å¯æ“æ§çš„ã€å¯ç®¡ç†çš„ã€èƒ½å¤Ÿè¢«æ§åˆ¶çš„ã€‚æŒ‰ç…§è¿™ç§æƒ¯ä¾‹ï¼Œå¯è½¬å‘æ»¤æ³¢å™¨çš„å“åº”æ˜¯å¯å®šå‘çš„ï¼Œå¹¶ä¸”å¯ä»¥é€‚åº”è¾“å…¥çš„ç‰¹å®šæ–¹å‘ï¼ˆä¾‹å¦‚ä¸€å¼ å›¾åƒï¼‰ã€‚å¯è½¬å‘æ€§ä¸å¦ä¸€ä¸ªéå¸¸é‡è¦çš„å±æ€§ç›¸å…³ï¼Œè¿™å°±æ˜¯**ç­‰å˜æ€§**ã€‚åœ¨ç­‰å˜æ»¤æ³¢å™¨ä¸­ï¼Œå¦‚æœæ»¤æ³¢å™¨çš„è¾“å…¥ç»è¿‡äº†ä¸€ä¸ªç²¾ç¡®ä¸”æ˜ç¡®çš„å‡ ä½•å˜æ¢
    *g*ï¼ˆå¹³ç§»ã€æ—‹è½¬ã€ç§»åŠ¨ï¼‰ï¼Œåˆ™è¾“å‡ºï¼ˆå³è¾“å…¥ä¸æ»¤æ³¢å™¨å·ç§¯çš„ç»“æœï¼‰ä¹Ÿä¼šç»è¿‡ç›¸åŒçš„å˜æ¢ *g*ã€‚é€šå¸¸ï¼Œç­‰å˜æ€§å¹¶ä¸è¦æ±‚å˜æ¢ï¼ˆè¾“å…¥å’Œè¾“å‡ºçš„å˜æ¢ï¼‰æ˜¯ç›¸åŒçš„ã€‚è¿™ä¸ªæ¦‚å¿µå°†åœ¨ä¸‹ä¸€ä¸ªæ®µè½ä¸­å¾—åˆ°æ›´å¥½çš„é˜è¿°ï¼Œä½†ç›®å‰è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿæä¾›å¯¹å¯è½¬å‘æ»¤æ³¢å™¨å’Œå¯è½¬å‘
    CNN çš„åˆæ­¥å®šä¹‰ã€‚
- en: '*A* ***Steerable CNN filter*** *can be defined as a filter whose kernel is
    structured as a concatenation of different steerable filters. These filters show
    equivariance properties in relation to the* ***operation of convolution*** *with
    respect to a set of well-defined geometric transformations.*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä¸€ä¸ª* ***å¯è½¬å‘ CNN æ»¤æ³¢å™¨*** *å¯ä»¥å®šä¹‰ä¸ºä¸€ä¸ªå…¶å†…æ ¸ç»“æ„ä¸ºä¸åŒå¯è½¬å‘æ»¤æ³¢å™¨çš„ä¸²è”çš„æ»¤æ³¢å™¨ã€‚è¿™äº›æ»¤æ³¢å™¨åœ¨* ***å·ç§¯æ“ä½œ*** *ç›¸å¯¹äºä¸€ç»„å®šä¹‰æ˜ç¡®çš„å‡ ä½•å˜æ¢æ–¹é¢æ˜¾ç¤ºå‡ºç­‰å˜æ€§ç‰¹æ€§ã€‚*'
- en: 'As we can see later, the condition of equivariance on the convolution operation
    leads to the imposition of specific constraints over the *structure of the kernel
    and on its weights*. From this definition it is now possible to define what a
    steerable CNN is: **Steerable Neural Networks** are neural networks composed of
    a series of steerable filters.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬ç¨åå°†çœ‹åˆ°çš„ï¼Œå·ç§¯æ“ä½œä¸Šçš„ç­‰å˜æ€§æ¡ä»¶å¯¼è‡´å¯¹*å†…æ ¸ç»“æ„åŠå…¶æƒé‡*æ–½åŠ ç‰¹å®šçš„çº¦æŸã€‚ä»è¿™ä¸ªå®šä¹‰ä¸­ï¼Œç°åœ¨å¯ä»¥å®šä¹‰ä»€ä¹ˆæ˜¯å¯è½¬å‘ CNNï¼š**å¯è½¬å‘ç¥ç»ç½‘ç»œ**æ˜¯ç”±ä¸€ç³»åˆ—å¯è½¬å‘æ»¤æ³¢å™¨ç»„æˆçš„ç¥ç»ç½‘ç»œã€‚
- en: 'What are S-CNN used for:'
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S-CNN çš„ç”¨é€”ï¼š
- en: The strength of a normal CNN is in its equivariance to translation. However,
    Steerable NNâ€™s are more flexible and can show other types of transformations,
    rotation. In a rotationally equivariant problem, an unmodified CNN is compelled
    to learn rotated versions of the same filter introducing a redundant degree of
    freedom and increasing the risk of overfitting.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: æ™®é€š CNN çš„ä¼˜åŠ¿åœ¨äºå…¶å¯¹å¹³ç§»çš„ç­‰å˜æ€§ã€‚ç„¶è€Œï¼Œå¯å¯¼ç¥ç»ç½‘ç»œæ›´åŠ çµæ´»ï¼Œå¯ä»¥å±•ç¤ºå…¶ä»–ç±»å‹çš„å˜æ¢ï¼Œä¾‹å¦‚æ—‹è½¬ã€‚åœ¨æ—‹è½¬ç­‰å˜é—®é¢˜ä¸­ï¼Œæœªç»ä¿®æ”¹çš„ CNN è¢«è¿«å­¦ä¹ ç›¸åŒæ»¤æ³¢å™¨çš„æ—‹è½¬ç‰ˆæœ¬ï¼Œä»è€Œå¼•å…¥äº†å†—ä½™çš„è‡ªç”±åº¦ï¼Œå¹¶å¢åŠ äº†è¿‡æ‹Ÿåˆçš„é£é™©ã€‚
- en: For this reason, Steerable CNN networks can outperform the classical CNN by
    directly incorporating information about the geometrical transformations acting
    at the input. This property makes S-CNNs particularly useful for several challenging
    tasks where we have to process inputs that have a geometrical description and
    representation such as images, manifolds, or vector fields.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¯å¯¼ CNN ç½‘ç»œå¯ä»¥é€šè¿‡ç›´æ¥æ•´åˆè¾“å…¥å¤„å‡ ä½•å˜æ¢çš„ä¿¡æ¯ï¼Œä¼˜äºç»å…¸ CNNã€‚è¿™ä¸€ç‰¹æ€§ä½¿å¾— S-CNN åœ¨å¤„ç†å…·æœ‰å‡ ä½•æè¿°å’Œè¡¨ç¤ºçš„è¾“å…¥ï¼ˆå¦‚å›¾åƒã€æµå½¢æˆ–å‘é‡åœºï¼‰æ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚
- en: 'Possible practical applications are for example :'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å¯èƒ½çš„å®é™…åº”ç”¨ä¾‹å¦‚ï¼š
- en: '**Challenging 2D image segmentation:**predicting the cell boundaries given
    an input microscope image.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æŒ‘æˆ˜æ€§çš„ 2D å›¾åƒåˆ†å‰²ï¼š** ç»™å®šè¾“å…¥æ˜¾å¾®é•œå›¾åƒé¢„æµ‹ç»†èƒè¾¹ç•Œã€‚'
- en: '**3D model classification:** classifying and recognizing 3D objects.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3D æ¨¡å‹åˆ†ç±»ï¼š** å¯¹ 3D ç‰©ä½“è¿›è¡Œåˆ†ç±»å’Œè¯†åˆ«ã€‚'
- en: '**3D chemical structure classification:** predicting the 3D chemical structure
    of a molecule given its chemical structure. A possible example is the prediction
    of spatial preferences of a group of amino acids given its sequence as explained
    in section 5.4 of the paper [[2]](https://arxiv.org/pdf/1807.02547.pdf).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3D åŒ–å­¦ç»“æ„åˆ†ç±»ï¼š** é¢„æµ‹ç»™å®šåŒ–å­¦ç»“æ„çš„åˆ†å­ 3D åŒ–å­¦ç»“æ„ã€‚ä¸€ä¸ªå¯èƒ½çš„ä¾‹å­æ˜¯æ ¹æ®æ°¨åŸºé…¸åºåˆ—é¢„æµ‹å…¶ç©ºé—´åå¥½ï¼Œå…·ä½“è§è®ºæ–‡çš„ç¬¬ 5.4 èŠ‚ [[2]](https://arxiv.org/pdf/1807.02547.pdf)ã€‚'
- en: '![](../Images/85b13d557a9a2caf33cfc0543a5ccf22.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85b13d557a9a2caf33cfc0543a5ccf22.png)'
- en: Example of application of a a 3D steerable neural network for 3D object recognition.
    The input object (on the top) , and the representation of two different hidden
    layers feature maps. Taken from [Link](https://www.youtube.com/watch?v=ENLJACPHSEA)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 3D å¯å¯¼ç¥ç»ç½‘ç»œåœ¨ 3D ç‰©ä½“è¯†åˆ«ä¸­çš„åº”ç”¨ç¤ºä¾‹ã€‚è¾“å…¥ç‰©ä½“ï¼ˆåœ¨é¡¶éƒ¨ï¼‰ä»¥åŠä¸¤ä¸ªä¸åŒéšè—å±‚ç‰¹å¾å›¾çš„è¡¨ç¤ºã€‚æ‘˜è‡ª [Link](https://www.youtube.com/watch?v=ENLJACPHSEA)
- en: Preliminary definitions and Context
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆæ­¥å®šä¹‰å’ŒèƒŒæ™¯
- en: After introducing Steerable Neural Networks and their applications, letâ€™s dive
    into the theory behind them. This section offers a more formal explanation of
    equivariance and steerability, providing essential definitions and a formal framework
    that will be instrumental in understanding the construction of steerable filters
    in the subsequent article.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»‹ç»äº†å¯å¯¼ç¥ç»ç½‘ç»œåŠå…¶åº”ç”¨åï¼Œè®©æˆ‘ä»¬æ·±å…¥æ¢è®¨å®ƒä»¬èƒŒåçš„ç†è®ºã€‚æœ¬èŠ‚æä¾›äº†ç­‰å˜æ€§å’Œå¯å¯¼æ€§çš„æ›´æ­£å¼è§£é‡Šï¼Œæä¾›äº†ç†è§£åç»­æ–‡ç« ä¸­å¯å¯¼æ»¤æ³¢å™¨æ„é€ æ‰€éœ€çš„åŸºæœ¬å®šä¹‰å’Œæ­£å¼æ¡†æ¶ã€‚
- en: This article relies on an understanding of maps and geometrical transformations,
    for more information look on this other [article](/geometric-transformations-in-computer-vision-an-intuitive-explanation-with-python-examples-b0b6f06e1844).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä¾èµ–äºå¯¹æ˜ å°„å’Œå‡ ä½•å˜æ¢çš„ç†è§£ï¼Œæ›´å¤šä¿¡æ¯è¯·å‚è€ƒè¿™ç¯‡ [æ–‡ç« ](/geometric-transformations-in-computer-vision-an-intuitive-explanation-with-python-examples-b0b6f06e1844)ã€‚
- en: '1\. EQUIVARIANCE:'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. ç­‰å˜æ€§ï¼š
- en: 'Equivariance is a property of particular interest in symmetric problems. As
    stated before, in an equivariant model when the input is acted on by the transformation,
    it also acts on the output such that the application of the transformation can
    be applied before or after the modelâ€™s application with no change in overall behaviour.
    In an everyday setting there are many examples of equivariance. For example, when
    driving, the direction in which a car steers when the wheel is turned is equivariant
    with respect to the direction the car is pointing. Formally, if we have a map
    ğ›™: *X â†’ Y*, where *X*âŠ‚â„áµˆ and *Y*âŠ‚â„áµˆÂ¹ , and *g*, a geometrical transformation belonging
    to the group *G*, ğ›™ is equivariant to *G* if :'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç­‰å˜æ€§æ˜¯å¯¹ç§°é—®é¢˜ä¸­ç‰¹åˆ«æ„Ÿå…´è¶£çš„ç‰¹æ€§ã€‚å¦‚å‰æ‰€è¿°ï¼Œåœ¨ç­‰å˜æ¨¡å‹ä¸­ï¼Œå½“è¾“å…¥ç»è¿‡å˜æ¢ä½œç”¨æ—¶ï¼Œè¾“å‡ºä¹Ÿä¼šå—åˆ°ç›¸åº”ä½œç”¨ï¼Œä»è€Œä½¿å¾—å˜æ¢çš„åº”ç”¨å¯ä»¥åœ¨æ¨¡å‹åº”ç”¨ä¹‹å‰æˆ–ä¹‹åè¿›è¡Œï¼Œè€Œæ•´ä½“è¡Œä¸ºä¸å‘ç”Ÿå˜åŒ–ã€‚åœ¨æ—¥å¸¸ç¯å¢ƒä¸­æœ‰è®¸å¤šç­‰å˜æ€§çš„ä¾‹å­ã€‚ä¾‹å¦‚ï¼Œé©¾é©¶æ—¶ï¼Œå½“è½¬åŠ¨æ–¹å‘ç›˜æ—¶ï¼Œæ±½è½¦çš„è½¬å‘æ–¹å‘ä¸æ±½è½¦æ‰€æŒ‡æ–¹å‘æ˜¯ç­‰å˜çš„ã€‚å½¢å¼ä¸Šï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªæ˜ å°„
    ğ›™: *X â†’ Y*ï¼Œå…¶ä¸­ *X*âŠ‚â„áµˆ å’Œ *Y*âŠ‚â„áµˆÂ¹ï¼Œä»¥åŠ *g*ï¼Œä¸€ä¸ªå±äºç¾¤ä½“ *G* çš„å‡ ä½•å˜æ¢ï¼Œğ›™ å¯¹ *G* æ˜¯ç­‰å˜çš„ï¼Œå¦‚æœï¼š'
- en: '![](../Images/b17fdc06446a51dca6bd81149914f591.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b17fdc06446a51dca6bd81149914f591.png)'
- en: 'Eq.1: Math equation representing the equivariance of ğ›™ with respect to g.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.1: è¡¨ç¤ºğ›™å¯¹gçš„ç­‰å˜æ€§çš„æ•°å­¦æ–¹ç¨‹ã€‚'
- en: 'where *Î â‚€(g) : X â†’ Xâ€™* and *Î â‚(g): Yâ†’ Yâ€™* are two linear maps ( e.g. often
    matrices applied by multiplication) determined by the application of *g* to x.
    A visual example is given by the picture below taken from the paper [[2](https://arxiv.org/abs/1612.08498)].
    In the image *g* is a rotation, specifically â€œ*rotation of -90Â°â€;* it is, therefore,
    denominated *r.* *Î â‚€(r)* operates in the domain of ğ›™ (=X), while *Î â‚(r)* works
    in the codomain of ğ›™ (=Y).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 'å…¶ä¸­*Î â‚€(g) : X â†’ Xâ€™*å’Œ*Î â‚(g): Yâ†’ Yâ€™*æ˜¯ç”±åº”ç”¨*g*åˆ°xç¡®å®šçš„ä¸¤ä¸ªçº¿æ€§æ˜ å°„ï¼ˆä¾‹å¦‚ï¼Œé€šå¸¸æ˜¯é€šè¿‡ä¹˜æ³•åº”ç”¨çš„çŸ©é˜µï¼‰ã€‚ä¸‹å›¾æä¾›äº†ä¸€ä¸ªæ¥è‡ªè®ºæ–‡[[2](https://arxiv.org/abs/1612.08498)]çš„è§†è§‰ç¤ºä¾‹ã€‚åœ¨å›¾åƒä¸­ï¼Œ*g*æ˜¯æ—‹è½¬ï¼Œå…·ä½“ä¸ºâ€œ*æ—‹è½¬-90Â°*â€ï¼Œå› æ­¤è¢«ç§°ä¸º*r*ã€‚*Î â‚€(r)*åœ¨é¢†åŸŸğ›™ï¼ˆ=Xï¼‰ä¸­æ“ä½œï¼Œè€Œ*Î â‚(r)*åœ¨ğ›™ï¼ˆ=Yï¼‰çš„å€¼åŸŸä¸­å·¥ä½œã€‚'
- en: If *X=â„Â²*, 2-D cartesian space, and r is the transformation â€œclock-wise rotation
    of 90*Â°â€,* the matrix *Î â‚€(r)* would be equal to a 2x2 Euler matrix with Î¸=Ï€/2.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ*X=â„Â²*ï¼Œ2ç»´ç¬›å¡å°”ç©ºé—´ï¼Œä¸”ræ˜¯â€œé¡ºæ—¶é’ˆæ—‹è½¬90Â°â€çš„å˜æ¢ï¼Œåˆ™çŸ©é˜µ*Î â‚€(r)*å°†ç­‰äºÎ¸=Ï€/2çš„2x2æ¬§æ‹‰çŸ©é˜µã€‚
- en: One should notice that if ğ›™ is equivariant with respect to G, applying a transformation
    and then computing the map produces the same result as calculating the map and
    then applying the transformation, a property formerly known as commutation.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åº”æ³¨æ„ï¼Œå¦‚æœğ›™å¯¹Gæ˜¯ç­‰å˜çš„ï¼Œé‚£ä¹ˆæ–½åŠ å˜æ¢åå†è®¡ç®—æ˜ å°„ä¼šäº§ç”Ÿä¸å…ˆè®¡ç®—æ˜ å°„å†æ–½åŠ å˜æ¢ç›¸åŒçš„ç»“æœï¼Œè¿™ä¸€å±æ€§ä»¥å‰ç§°ä¸ºäº¤æ¢æ€§ã€‚
- en: '![](../Images/deec9ffe252abc3e89db765ba8e3730f.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/deec9ffe252abc3e89db765ba8e3730f.png)'
- en: 'Fig2A: A visual example of a function Ñ° equivariant to a transformation r.
    Taken from article [[2]](https://arxiv.org/abs/1612.08498).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'Fig2A: å‡½æ•°Ñ°å¯¹å˜æ¢rç­‰å˜çš„è§†è§‰ç¤ºä¾‹ã€‚æ‘˜è‡ªæ–‡ç« [[2]](https://arxiv.org/abs/1612.08498)ã€‚'
- en: '*At this point it is also worth mentioning a special case.* ***Invariance****,*
    a particular type of equivariance where *X=Xâ€™* and *Y=Yâ€™*.In whatever way the
    input is transformed, the output always remains the same. From a deep learning
    prospective, invariant filter could be useful for example for object recognition:
    however an input image is rotated the output of the filter remains the same. One
    should note that the spaces *X* and *Y* may not necessarily have the same dimensionality,
    for example if we are trying to determine the orientation (*Y* as a 2-vector)
    of a car in a picture (*X* as a 2-d array of pixels), then the transformations
    *Î â‚(g)* and *Î â‚€(g)* will be different as they apply to different spaces, even
    when they share the same g.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ­¤æ—¶è¿˜å€¼å¾—æåˆ°ä¸€ä¸ªç‰¹ä¾‹ã€‚* ***ä¸å˜æ€§***ï¼Œä¸€ç§ç‰¹æ®Šç±»å‹çš„ç­‰å˜æ€§ï¼Œå…¶ä¸­*X=Xâ€™*å’Œ*Y=Yâ€™*ã€‚æ— è®ºè¾“å…¥å¦‚ä½•å˜æ¢ï¼Œè¾“å‡ºå§‹ç»ˆä¿æŒä¸å˜ã€‚ä»æ·±åº¦å­¦ä¹ çš„è§’åº¦æ¥çœ‹ï¼Œä¸å˜æ»¤æ³¢å™¨ä¾‹å¦‚åœ¨ç‰©ä½“è¯†åˆ«ä¸­å¯èƒ½æœ‰ç”¨ï¼šæ— è®ºè¾“å…¥å›¾åƒå¦‚ä½•æ—‹è½¬ï¼Œæ»¤æ³¢å™¨çš„è¾“å‡ºå§‹ç»ˆä¿æŒä¸å˜ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ*X*å’Œ*Y*çš„ç©ºé—´å¯èƒ½ä¸å…·æœ‰ç›¸åŒçš„ç»´åº¦ï¼Œä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è¯•å›¾ç¡®å®šå›¾ç‰‡ä¸­æ±½è½¦çš„æ–¹å‘ï¼ˆ*Y*ä½œä¸º2ç»´å‘é‡ï¼‰è€Œ*X*ä½œä¸ºåƒç´ çš„2ç»´æ•°ç»„ï¼Œåˆ™å˜æ¢*Î â‚(g)*å’Œ*Î â‚€(g)*å°†ä¸åŒï¼Œå› ä¸ºå®ƒä»¬é€‚ç”¨äºä¸åŒçš„ç©ºé—´ï¼Œå³ä½¿å®ƒä»¬å…±äº«ç›¸åŒçš„gã€‚'
- en: '2\. STEERABLE FILTERs:'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. å¯æ“æ§æ»¤æ³¢å™¨ï¼š
- en: In contrast to the steerability of a car, steerable filters are a little more
    challenging to intuit. Both, however, share the underlying goal of achieving a
    consistent and predictable response to a specific parameter â€” a response that
    is intimately linked to the inherent transformations of the filter itself.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ±½è½¦çš„å¯æ“æ§æ€§ç›¸æ¯”ï¼Œå¯æ“æ§æ»¤æ³¢å™¨ç¨å¾®éš¾ä»¥ç›´è§‚ç†è§£ã€‚ç„¶è€Œï¼Œä¸¤è€…éƒ½å…±äº«å®ç°å¯¹ç‰¹å®šå‚æ•°ä¸€è‡´å’Œå¯é¢„æµ‹å“åº”çš„åŸºæœ¬ç›®æ ‡â€”â€”è¿™ç§å“åº”ä¸æ»¤æ³¢å™¨æœ¬èº«çš„å›ºæœ‰å˜æ¢å¯†åˆ‡ç›¸å…³ã€‚
- en: 'An intuitive example might be the following: think of a wind vane on a rooftop
    that shows the direction of the wind. Instead of installing a separate sensor
    for every possible wind direction, which would be impractical, you have a wind
    vane that rotates to align with the current wind direction.A steerable filter
    is like a wind vane. It adapts to directions encoded in input signals without
    needing a unique sensor for each possibility. In the same way, steerable filters
    in image processing adapt to different features or orientations in an image without
    requiring a separate filter for every possible orientation of the input. This
    approach offers an intelligent and effective method for modeling systems. In the
    context of machine learning, it enables us to concentrate on constructing valuable
    models without worrying about augmentation or incorporating additional weights
    to handle different orientations.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç›´è§‚çš„ä¾‹å­å¯èƒ½å¦‚ä¸‹ï¼šæƒ³è±¡ä¸€ä¸‹å±‹é¡¶ä¸Šçš„é£å‘æ ‡ï¼Œæ˜¾ç¤ºé£çš„æ–¹å‘ã€‚ä¸å…¶ä¸ºæ¯ç§å¯èƒ½çš„é£å‘å®‰è£…å•ç‹¬çš„ä¼ æ„Ÿå™¨ï¼ˆè¿™æ˜¯ä¸åˆ‡å®é™…çš„ï¼‰ï¼Œä¸å¦‚å®‰è£…ä¸€ä¸ªå¯ä»¥æ—‹è½¬ä»¥ä¸å½“å‰é£å‘å¯¹é½çš„é£å‘æ ‡ã€‚å¯è½¬å‘æ»¤æ³¢å™¨å°±åƒä¸€ä¸ªé£å‘æ ‡ï¼Œå®ƒæ ¹æ®è¾“å…¥ä¿¡å·ä¸­ç¼–ç çš„æ–¹å‘è‡ªé€‚åº”ï¼Œè€Œæ— éœ€ä¸ºæ¯ç§å¯èƒ½çš„è¾“å…¥æ–¹å‘ä½¿ç”¨ç‹¬ç«‹çš„ä¼ æ„Ÿå™¨ã€‚åŒæ ·ï¼Œåœ¨å›¾åƒå¤„ç†ä¸­ï¼Œå¯è½¬å‘æ»¤æ³¢å™¨é€‚åº”å›¾åƒä¸­çš„ä¸åŒç‰¹å¾æˆ–æ–¹å‘ï¼Œè€Œæ— éœ€ä¸ºæ¯ç§å¯èƒ½çš„è¾“å…¥æ–¹å‘ä½¿ç”¨ç‹¬ç«‹çš„æ»¤æ³¢å™¨ã€‚è¿™ç§æ–¹æ³•ä¸ºå»ºæ¨¡ç³»ç»Ÿæä¾›äº†æ™ºèƒ½å’Œæœ‰æ•ˆçš„æ–¹æ³•ã€‚åœ¨æœºå™¨å­¦ä¹ çš„èƒŒæ™¯ä¸‹ï¼Œå®ƒä½¿æˆ‘ä»¬èƒ½å¤Ÿä¸“æ³¨äºæ„å»ºæœ‰ä»·å€¼çš„æ¨¡å‹ï¼Œè€Œä¸å¿…æ‹…å¿ƒå¢å¼ºæˆ–å¢åŠ é¢å¤–çš„æƒé‡ä»¥å¤„ç†ä¸åŒçš„æ–¹å‘ã€‚
- en: While steerability can be applied generally to any set of transformations, we
    will here use rotations to introduce the idea in a more formal way.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¯è½¬å‘æ€§å¯ä»¥æ™®éåº”ç”¨äºä»»ä½•ä¸€ç»„å˜æ¢ï¼Œæˆ‘ä»¬å°†åœ¨æ­¤ä½¿ç”¨æ—‹è½¬æ¥æ›´æ­£å¼åœ°ä»‹ç»è¿™ä¸ªæ¦‚å¿µã€‚
- en: 'Let ğ›™: â„áµˆ â†’â„áµˆÂ¹ be a convolution map whose kernel function is **k**.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 'è®© ğ›™: â„áµˆ â†’â„áµˆÂ¹ æˆä¸ºå…¶æ ¸å‡½æ•°ä¸º **k** çš„å·ç§¯æ˜ å°„ã€‚'
- en: 'Be *x*âˆˆâ„â¿ , given an input signal depending on *x* , *f(x)* âˆˆ â„áµˆ, and outputsignal
    *, f* â‚(x) âˆˆ â„áµˆÂ¹ , we can write: *f* â‚(*x*)= ğ›™( *f(x)*) which means *f* â‚(x)=
    *k(x)* âˆ— *f(x)* .'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº *x*âˆˆâ„â¿ï¼Œç»™å®šä¸€ä¸ªä¾èµ–äº *x* çš„è¾“å…¥ä¿¡å· *f(x)* âˆˆ â„áµˆï¼Œå¹¶ä¸”è¾“å‡ºä¿¡å· *f*â‚(*x*) âˆˆ â„áµˆÂ¹ï¼Œæˆ‘ä»¬å¯ä»¥å†™æˆï¼š*f*â‚(*x*)=
    ğ›™(*f(x)*)ï¼Œè¿™æ„å‘³ç€ *f*â‚(*x*)= *k(x)* âˆ— *f(x)*ã€‚
- en: 'This filter is defined *steerable* with respect to rotations if :'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¯¹æ—‹è½¬çš„è½¬å‘æ»¤æ³¢å™¨å®šä¹‰å¦‚ä¸‹ï¼š
- en: (1) its convolution kernel *k(x)* of each output element, can be expressed as
    a sum of basis functions *Ïˆâ±¼(x),* j*=1,..M*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: (1) æ¯ä¸ªè¾“å‡ºå…ƒç´ çš„å·ç§¯æ ¸ *k(x)* å¯ä»¥è¡¨ç¤ºä¸ºåŸºå‡½æ•° *Ïˆâ±¼(x)* çš„å’Œï¼Œå…¶ä¸­ *j*=1,..M*ã€‚
- en: '(2) the filterâ€™s rotation by an arbitrary angle Î¸ , ***g_Î¸*,** can be expressedin
    terms of rotations applied to each single basis function (this is valid for each
    Î¸). In mathematical terms it means:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: (2) é€šè¿‡ä»»æ„è§’åº¦ Î¸ æ—‹è½¬æ»¤æ³¢å™¨çš„ **g_Î¸** å¯ä»¥ç”¨æ¯ä¸ªåŸºå‡½æ•°çš„æ—‹è½¬è¡¨ç¤ºï¼ˆå¯¹äºæ¯ä¸ª Î¸ å‡é€‚ç”¨ï¼‰ã€‚æ•°å­¦ä¸Šæ¥è¯´ï¼Œè¿™æ„å‘³ç€ï¼š
- en: '![](../Images/7f10890df339ac4edc24ab8c873cee97.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f10890df339ac4edc24ab8c873cee97.png)'
- en: 'Eq.2: Definition of Steerable filter'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.2: å¯è½¬å‘æ»¤æ³¢å™¨çš„å®šä¹‰'
- en: Thanks to this property, it is possible to uniquely orient the filterâ€™s response
    to an input, by modifying the values of *wâ±¼*. Letâ€™s provide an example.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè¿™ä¸€ç‰¹æ€§ï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ *wâ±¼* çš„å€¼æ¥å”¯ä¸€å®šå‘æ»¤æ³¢å™¨å¯¹è¾“å…¥çš„å“åº”ã€‚æˆ‘ä»¬æ¥ä¸¾ä¸ªä¾‹å­ã€‚
- en: 'The simplest illustration of a single steerable filter is in 2D space a filter
    whose kernel function is the directional derivative of a **two-dimensional Gaussian**.
    In this case the *k: â„Â² â†’â„* and *x = (xâ‚,x*â‚‚*)* âˆˆ â„Â² :'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨äºŒç»´ç©ºé—´ä¸­ï¼Œä¸€ä¸ªå¯å®šå‘å•ä¸ªå¯è½¬å‘æ»¤æ³¢å™¨çš„æœ€ç®€å•çš„ä¾‹å­æ˜¯å…¶æ ¸å‡½æ•°ä¸º **äºŒç»´é«˜æ–¯** çš„æ–¹å‘å¯¼æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ*k: â„Â² â†’â„*ï¼Œä¸” *x = (xâ‚,xâ‚‚)*
    âˆˆ â„Â²ï¼š'
- en: '![](../Images/85ffdee84540d25257d4f11173966e62.png)![](../Images/c211bd92826d4b82af2aab13c0061c44.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85ffdee84540d25257d4f11173966e62.png)![](../Images/c211bd92826d4b82af2aab13c0061c44.png)'
- en: 'Eq.3: Directional derivative of a **two-dimensional Gaussian (above)** and
    transformation of a function k RÂ² â†’R under gÎ¸.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.3: **äºŒç»´é«˜æ–¯** çš„æ–¹å‘å¯¼æ•°ï¼ˆä¸Šï¼‰å’Œå‡½æ•° *k* RÂ² â†’R åœ¨ gÎ¸ ä¸‹çš„è½¬æ¢ã€‚'
- en: In the following lines we will show that this filter is steerable in the sense
    explained above.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„å‡ è¡Œä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºè¯¥æ»¤æ³¢å™¨æŒ‰ä¸Šè¿°æ–¹å¼æ˜¯å¯è½¬å‘çš„ã€‚
- en: From the theory we know that, given that *k* codomain is *â„*, we can write the
    rotated filter as Eq.3 (for more info look at Eq.3 in the next session).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç†è®ºä¸Šæˆ‘ä»¬çŸ¥é“ï¼Œé‰´äº *k* çš„å€¼åŸŸæ˜¯ *â„*ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ—‹è½¬åçš„æ»¤æ³¢å™¨å†™æˆ Eq.3ï¼ˆæœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ä¸‹ä¸€èŠ‚ä¸­çš„ Eq.3ï¼‰ã€‚
- en: 'By developing this equation we can show the steerability:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ¨å¯¼è¿™ä¸ªæ–¹ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥å±•ç¤ºå…¶å¯è½¬å‘æ€§ï¼š
- en: '![](../Images/124d0a45e88094b3bbcdb7ab13a1bfd3.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/124d0a45e88094b3bbcdb7ab13a1bfd3.png)'
- en: 'Eq.5: Mathematical proof of steerability of a the directional derivative of
    a **two-dimensional Gaussian**'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.5: **äºŒç»´é«˜æ–¯** çš„æ–¹å‘å¯¼æ•°å¯è½¬å‘çš„æ•°å­¦è¯æ˜'
- en: In this case we have applied the transformation ***g_Î¸*:** â„Â²â†’â„Â² and it is represented
    by the 2D euler matrix (see later induced representation). If we calculate ***k(g_Î¸***
    â»Â¹***(xâ‚,xâ‚‚))*,** we can see, after some algebra, that the generic rotated version
    of this impulsive filter can be expressed as a linear combination of two basis
    functions Ñ±*â‚(xâ‚,x*â‚‚*)* and Ñ±â‚‚*(xâ‚,x*â‚‚*)* with coefficient parameterized by Î¸.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åº”ç”¨äº†å˜æ¢ ***g_Î¸*:** â„Â²â†’â„Â²ï¼Œå¹¶ä¸”å®ƒç”±äºŒç»´æ¬§æ‹‰çŸ©é˜µè¡¨ç¤ºï¼ˆè§ä¸‹æ–‡è¯±å¯¼è¡¨ç¤ºï¼‰ã€‚å¦‚æœæˆ‘ä»¬è®¡ç®— ***k(g_Î¸*** â»Â¹***(xâ‚,xâ‚‚))*,**
    æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›ä»£æ•°è¿ç®—çœ‹åˆ°ï¼Œè¿™ç§å†²æ¿€æ»¤æ³¢å™¨çš„é€šç”¨æ—‹è½¬ç‰ˆæœ¬å¯ä»¥è¡¨ç¤ºä¸ºä¸¤ä¸ªåŸºå‡½æ•° Ñ±*â‚(xâ‚,x*â‚‚*)* å’Œ Ñ±â‚‚*(xâ‚,x*â‚‚*)* çš„çº¿æ€§ç»„åˆï¼Œç³»æ•°ç”±
    Î¸ å‚æ•°åŒ–ã€‚
- en: As possible to see in the equation reported below (Eq.6) , given the linearity
    of convolution, it is always possible to express the convolution of an input function
    f with the Î¸-rotated impulsive response **g_Î¸(k(x,y))=**k_Î¸as a linear combination
    of the convolutions of f with the single basis Ñ±*â‚*,Ñ±â‚‚ of k.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸‹æ–¹ç¨‹ï¼ˆæ–¹ç¨‹6ï¼‰æ‰€ç¤ºï¼Œç”±äºå·ç§¯çš„çº¿æ€§ç‰¹æ€§ï¼Œè¾“å…¥å‡½æ•° f ä¸Î¸æ—‹è½¬çš„å†²æ¿€å“åº” **g_Î¸(k(x,y))=**k_Î¸ çš„å·ç§¯å§‹ç»ˆå¯ä»¥è¡¨ç¤ºä¸º f ä¸ k
    çš„å•ä¸€åŸºå‡½æ•° Ñ±*â‚*ã€Ñ±â‚‚ çš„å·ç§¯çš„çº¿æ€§ç»„åˆã€‚
- en: '![](../Images/ce56b68ee568798c988fc5128821e328.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ce56b68ee568798c988fc5128821e328.png)'
- en: 'Eq.6: Convolution of a steerable filter with f.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹6ï¼šä¸€ä¸ªå¯è½¬å‘æ»¤æ³¢å™¨ä¸ f çš„å·ç§¯ã€‚
- en: This formula highlights the *power of steerable filters in a neural network*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå…¬å¼çªå‡ºäº† *å¯è½¬å‘æ»¤æ³¢å™¨åœ¨ç¥ç»ç½‘ç»œä¸­çš„åŠ›é‡*ã€‚
- en: By incorporating these filters, we have the potential to construct a steerable
    kernel that â€˜steersâ€™ its responses to the orientation of the input. Each basis
    function acts like a versatile tool, permitting the network to efficiently blend
    these functions using learned weights â€˜wâ‚â€™ and â€˜wâ‚‚â€™ to respond accurately to varying
    orientations. For instance, when the network encounters data with varying orientations,
    such as a rotated object in an image, it configures these weights to align the
    kernelâ€™s responses to the orientation of the input data. This adaptability enhances
    efficiency and effectiveness, leading to the same or better outcomes with fewer
    parameters. For this reason this approach can be used as the foundation for a
    more powerful CNN using steerable properties to handle diverse input orientations.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å¼•å…¥è¿™äº›æ»¤æ³¢å™¨ï¼Œæˆ‘ä»¬æœ‰å¯èƒ½æ„é€ ä¸€ä¸ªå¯è½¬å‘çš„æ ¸ï¼Œå®ƒæ ¹æ®è¾“å…¥çš„æ–¹å‘â€œè°ƒæ•´â€å…¶å“åº”ã€‚æ¯ä¸ªåŸºå‡½æ•°åƒä¸€ä¸ªå¤šåŠŸèƒ½å·¥å…·ï¼Œå…è®¸ç½‘ç»œä½¿ç”¨å­¦ä¹ åˆ°çš„æƒé‡â€˜wâ‚â€™å’Œâ€˜wâ‚‚â€™æ¥é«˜æ•ˆåœ°æ··åˆè¿™äº›å‡½æ•°ï¼Œä»¥å‡†ç¡®å“åº”ä¸åŒçš„æ–¹å‘ã€‚ä¾‹å¦‚ï¼Œå½“ç½‘ç»œé‡åˆ°å…·æœ‰ä¸åŒæ–¹å‘çš„æ•°æ®ï¼Œå¦‚å›¾åƒä¸­çš„æ—‹è½¬ç‰©ä½“æ—¶ï¼Œå®ƒé…ç½®è¿™äº›æƒé‡ä»¥ä½¿æ ¸çš„å“åº”ä¸è¾“å…¥æ•°æ®çš„æ–¹å‘å¯¹é½ã€‚è¿™ç§é€‚åº”æ€§æé«˜äº†æ•ˆç‡å’Œæ•ˆæœï¼Œä»è€Œåœ¨å‚æ•°æ›´å°‘çš„æƒ…å†µä¸‹è¾¾åˆ°ç›¸åŒæˆ–æ›´å¥½çš„ç»“æœã€‚å› æ­¤ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥ä½œä¸ºä½¿ç”¨å¯è½¬å‘å±æ€§å¤„ç†å„ç§è¾“å…¥æ–¹å‘çš„æ›´å¼ºå¤§çš„
    CNN çš„åŸºç¡€ã€‚
- en: Specifically, in next article, weâ€™ll explore this further and see how a we can
    use the concept of steerable filter to build equivariant filters.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†è¿›ä¸€æ­¥æ¢è®¨è¿™ä¸ªé—®é¢˜ï¼Œå¹¶äº†è§£å¦‚ä½•ä½¿ç”¨å¯è½¬å‘æ»¤æ³¢å™¨çš„æ¦‚å¿µæ¥æ„å»ºç­‰å˜æ»¤æ³¢å™¨ã€‚
- en: However, before we dive in, some definitions in this context will provide clarity
    and aid our discussion. For this reason in the next paragraph we introduce some
    formalism around convolution.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨æ·±å…¥ä¹‹å‰ï¼Œä¸€äº›å®šä¹‰å°†æä¾›æ¸…æ™°åº¦å¹¶å¸®åŠ©æˆ‘ä»¬çš„è®¨è®ºã€‚å› æ­¤ï¼Œåœ¨ä¸‹ä¸€æ®µä¸­æˆ‘ä»¬å¼•å…¥äº†ä¸€äº›å…³äºå·ç§¯çš„å½¢å¼åŒ–å†…å®¹ã€‚
- en: '3\. FORMALISM:'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. å½¢å¼åŒ–ï¼š
- en: In this part, we try to give to the reader a schematic explanation of all the
    elements considered in the analysis. This formalism will allow us to define more
    formally a CNN and the geometrical transformations which operate at the input
    level. This will allow us in the next [article](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-3-56dfc256b690)
    to understand how Steerable CNNs work.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬è¯•å›¾ç»™è¯»è€…æä¾›ä¸€ä¸ªæ‰€æœ‰åˆ†æå…ƒç´ çš„ç¤ºæ„æ€§è§£é‡Šã€‚è¿™ç§å½¢å¼åŒ–å°†å…è®¸æˆ‘ä»¬æ›´æ­£å¼åœ°å®šä¹‰ CNN åŠå…¶åœ¨è¾“å…¥å±‚æ“ä½œçš„å‡ ä½•å˜æ¢ã€‚è¿™å°†ä½¿æˆ‘ä»¬åœ¨ä¸‹ä¸€ç¯‡ [æ–‡ç« ](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-3-56dfc256b690)
    ä¸­ç†è§£å¯è½¬å‘ CNN çš„å·¥ä½œåŸç†ã€‚
- en: '*The elements:*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*å…ƒç´ ï¼š*'
- en: '**A space S**: The space on which the analysis takes place. Though S can extend
    to an arbitrary number of dimensions, it is easiest to visualize for two or three
    spatial dimensions. If for example we consider an image, the initial space is
    bidimensional and corresponds to the coordinate plane of the pixels (â„¤Â²). If we
    consider a â€œ3D objectâ€ instead, the space S is tridimensional,â„¤Â³. A point *x*âˆˆS
    identifies therefore a position.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸€ä¸ªç©ºé—´ S**ï¼šåˆ†æå‘ç”Ÿçš„ç©ºé—´ã€‚è™½ç„¶ S å¯ä»¥æ‰©å±•åˆ°ä»»æ„æ•°é‡çš„ç»´åº¦ï¼Œä½†æœ€å®¹æ˜“åœ¨äºŒç»´æˆ–ä¸‰ç»´ç©ºé—´ä¸­è¿›è¡Œå¯è§†åŒ–ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬è€ƒè™‘ä¸€å¹…å›¾åƒï¼Œåˆå§‹ç©ºé—´æ˜¯äºŒç»´çš„ï¼Œå¯¹åº”äºåƒç´ çš„åæ ‡å¹³é¢ï¼ˆâ„¤Â²ï¼‰ã€‚å¦‚æœæˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªâ€œ3D
    ç‰©ä½“â€ï¼Œé‚£ä¹ˆç©ºé—´ S æ˜¯ä¸‰ç»´çš„ï¼Œâ„¤Â³ã€‚å› æ­¤ï¼Œä¸€ä¸ªç‚¹ *x*âˆˆS ç¡®å®šäº†ä¸€ä¸ªä½ç½®ã€‚'
- en: '**An INPUT function *f*:** The function *f:* S â†’ *Fâ‚€ =* â„ Í¨ which describes
    the input over our geometrical space (it can be a manifold or a vector field).
    This can be seen as a function from the space S to â„ Í¨, *where each position x
    is connected to the â€œfeatureâ€ f(x), also called* ***the fiber of f at x***. Letâ€™s
    give some examples; a greyscale image can be seen as a function *f:* â„Â² â†’ â„, with
    S=â„Â² *and* c=1\. If we consider a colored 3D manifold, the function will be *f:*
    â„Â³â†’ â„Â³, where each position is assigned an RGB color, S=â„Â³, c=3\.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸€ä¸ªè¾“å…¥å‡½æ•° *f*:** å‡½æ•° *f:* S â†’ *Fâ‚€ =* â„ Í¨ æè¿°äº†æˆ‘ä»¬å‡ ä½•ç©ºé—´ä¸­çš„è¾“å…¥ï¼ˆå®ƒå¯ä»¥æ˜¯æµå½¢æˆ–å‘é‡åœºï¼‰ã€‚è¿™å¯ä»¥çœ‹ä½œæ˜¯ä»ç©ºé—´
    S åˆ° â„ Í¨ çš„ä¸€ä¸ªå‡½æ•°ï¼Œ*å…¶ä¸­æ¯ä¸ªä½ç½® x ä¸â€œç‰¹å¾â€ f(x) ç›¸å…³è”ï¼Œä¹Ÿç§°ä¸º* ***x ç‚¹çš„ f çš„çº¤ç»´***ã€‚ä¸¾äº›ä¾‹å­ï¼Œä¸€ä¸ªç°åº¦å›¾åƒå¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªå‡½æ•°
    *f:* â„Â² â†’ â„ï¼ŒS=â„Â² *ä¸”* c=1ã€‚å¦‚æœè€ƒè™‘ä¸€ä¸ªå½©è‰²çš„ 3D æµå½¢ï¼Œå‡½æ•°å°†æ˜¯ *f:* â„Â³â†’ â„Â³ï¼Œå…¶ä¸­æ¯ä¸ªä½ç½®åˆ†é…ä¸€ä¸ª RGB é¢œè‰²ï¼ŒS=â„Â³ï¼Œc=3\ã€‚'
- en: In practice the function *f* is usually represented as a packed structure of
    *fibers* over some sampling space; for an image in the standard format the fibers
    would be regularly spaced horizontally and vertically (i.e. pixels). The function
    f constitutes the input layer of the neural network (see Fig. 2A, Fig. 2B). From
    now on, this starting layer will be called *Fâ‚€.*
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œå‡½æ•° *f* é€šå¸¸è¡¨ç¤ºä¸ºä¸€äº›é‡‡æ ·ç©ºé—´ä¸Šçš„*çº¤ç»´*çš„æ‰“åŒ…ç»“æ„ï¼›å¯¹äºæ ‡å‡†æ ¼å¼çš„å›¾åƒï¼Œçº¤ç»´å°†æ°´å¹³å’Œå‚ç›´åœ°è§„åˆ™åˆ†å¸ƒï¼ˆå³åƒç´ ï¼‰ã€‚å‡½æ•° f æ„æˆäº†ç¥ç»ç½‘ç»œçš„è¾“å…¥å±‚ï¼ˆè§å›¾
    2Aï¼Œå›¾ 2Bï¼‰ã€‚ä»ç°åœ¨èµ·ï¼Œè¿™ä¸ªèµ·å§‹å±‚å°†è¢«ç§°ä¸º *Fâ‚€*ã€‚
- en: '**A set of transformations G**: Once the objects of the analysis have been
    adequately defined, we can define the set of transformations the network should
    be equivariant to. A single transformation gâˆˆG can be always described as a function
    in relation to the mathematical space on which it is applied. Given the input
    function *f:*Sâ†’â„ Í¨*,* it is possible to characterize **Ï€(g):** â„ Í¨ â†’ â„ Í¨, as â€œt*he
    induced transformation of g in* â„ Í¨,â€*.* The function *f exists in* â„ Í¨, but the
    transformation g operates in S space. **Ï€(g)** describes how *f* (in â„ Í¨ ) transforms
    under the application of g (in S). Considering *g* as a roto-translation composed
    of two components *r* (rotation) and translation *t*, in general, an input function
    *f(x)* transforms under the transformation g as described in Eq.7\.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸€ç»„å˜æ¢ G**: ä¸€æ—¦åˆ†æå¯¹è±¡è¢«é€‚å½“åœ°å®šä¹‰ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ç½‘ç»œåº”è¯¥ä¿æŒç­‰å˜æ€§çš„å˜æ¢é›†ã€‚å•ä¸ªå˜æ¢ gâˆˆG æ€»æ˜¯å¯ä»¥è¢«æè¿°ä¸ºä¸åº”ç”¨å®ƒçš„æ•°å­¦ç©ºé—´ç›¸å…³çš„å‡½æ•°ã€‚ç»™å®šè¾“å…¥å‡½æ•°
    *f:*Sâ†’â„ Í¨*ï¼Œ* å¯ä»¥è¡¨å¾ **Ï€(g):** â„ Í¨ â†’ â„ Í¨ï¼Œä½œä¸ºâ€œ*g åœ¨ â„ Í¨ ä¸­çš„è¯±å¯¼å˜æ¢*â€ã€‚*å‡½æ•° *f å­˜åœ¨äº â„ Í¨ ä¸­ï¼Œä½†å˜æ¢
    g æ“ä½œåœ¨ S ç©ºé—´ä¸­ã€‚**Ï€(g)** æè¿°äº† *f*ï¼ˆåœ¨ â„ Í¨ ä¸­ï¼‰åœ¨åº”ç”¨ gï¼ˆåœ¨ S ä¸­ï¼‰ä¸‹çš„å˜æ¢ã€‚è€ƒè™‘ *g* ä½œä¸ºç”±ä¸¤ä¸ªç»„ä»¶ *r*ï¼ˆæ—‹è½¬ï¼‰å’Œ
    *t*ï¼ˆå¹³ç§»ï¼‰ç»„æˆçš„æ—‹è½¬-å¹³ç§»ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œè¾“å…¥å‡½æ•° *f(x)* åœ¨å˜æ¢ g ä¸‹çš„å˜æ¢å¦‚ Eq.7 æ‰€è¿°\ã€‚'
- en: In the image below, if f is a vector field ,**Ï€(g)** is a matrix of dimension
    cxc while **,** If *f* is a scalar field ( *f :* â„Â² â†’ â„ ) , Ï€(r) = 1.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹å›¾ä¸­ï¼Œå¦‚æœ f æ˜¯ä¸€ä¸ªå‘é‡åœºï¼Œ**Ï€(g)** æ˜¯ä¸€ä¸ª cxc ç»´åº¦çš„çŸ©é˜µï¼Œè€Œ**ï¼Œ** å¦‚æœ *f* æ˜¯ä¸€ä¸ªæ ‡é‡åœºï¼ˆ*f:* â„Â² â†’ â„ï¼‰ï¼ŒÏ€(r)
    = 1ã€‚
- en: The group G of the considered transformations are usually rotations (we will
    speak about ***SO(2)*** networks in this case) or even rotations + translations
    (we will speak about ***SE(2)***networks in this case). Similarly, on three-dimensional
    space, 3D rigid body motions are considered ( ***SO(3)*** or ***SE(3)***).
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: æ‰€è€ƒè™‘çš„å˜æ¢ç»„ G é€šå¸¸æ˜¯æ—‹è½¬ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬å°†è®¨è®º***SO(2)*** ç½‘ç»œï¼‰æˆ–æ—‹è½¬ + å¹³ç§»ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬å°†è®¨è®º ***SE(2)*** ç½‘ç»œï¼‰ã€‚ç±»ä¼¼åœ°ï¼Œåœ¨ä¸‰ç»´ç©ºé—´ä¸­ï¼Œè€ƒè™‘
    3D åˆšä½“è¿åŠ¨ï¼ˆ***SO(3)*** æˆ– ***SE(3)***ï¼‰ã€‚
- en: '![](../Images/128babacefc76ee3231664d01f052142.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/128babacefc76ee3231664d01f052142.png)'
- en: 'Fig 2B: graphical representation of the application of a transformation g on
    a scalar field (left) or on a vector field (right). Taken from paper [[3]](https://arxiv.org/abs/1911.08251).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ 2B: å˜æ¢ g å¯¹æ ‡é‡åœºï¼ˆå·¦ï¼‰æˆ–å‘é‡åœºï¼ˆå³ï¼‰çš„åº”ç”¨çš„å›¾å½¢è¡¨ç¤ºã€‚æ‘˜è‡ªè®ºæ–‡ [[3]](https://arxiv.org/abs/1911.08251)ã€‚'
- en: '![](../Images/64a14ddd551f8bc7c577b7ba069112f3.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64a14ddd551f8bc7c577b7ba069112f3.png)'
- en: 'Eq.7: how f is transformed by the application of the transformation g to x'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.7: f å¦‚ä½•é€šè¿‡å˜æ¢ g åº”ç”¨äº x è€Œè¢«å˜æ¢'
- en: '**Feature maps:** Following the definition of *f* given in the second point,
    the outputs of every layer of the neural network can be seen as the result of
    the application of a function *f â‚™* on the initial space S. Formally this can
    be represented as a function from S to the codomain space *Fâ‚™* , ( *f : S* â†’ *Fâ‚™*),
    where *Fâ‚™*=â„ Í¨ Ê¿*â¿* Ê¾ and c*â¿* is the number of features for the layer *n* .If
    we take fig. 2B as example we can see that the initial signal (input ) can be
    seen as a function *f :* S=â„Â² â†’ *Fâ‚€*= â„Â³ while'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç‰¹å¾å›¾ï¼š** æ ¹æ®ç¬¬äºŒç‚¹ç»™å‡ºçš„ *f* å®šä¹‰ï¼Œç¥ç»ç½‘ç»œæ¯ä¸€å±‚çš„è¾“å‡ºå¯ä»¥çœ‹ä½œæ˜¯å‡½æ•° *f â‚™* åœ¨åˆå§‹ç©ºé—´Sä¸Šçš„åº”ç”¨ç»“æœã€‚å½¢å¼ä¸Šå¯ä»¥è¡¨ç¤ºä¸ºä»Såˆ°å¯¹åŸŸç©ºé—´
    *Fâ‚™* çš„å‡½æ•°ï¼Œï¼ˆ *f : S* â†’ *Fâ‚™*ï¼‰ï¼Œå…¶ä¸­ *Fâ‚™*=â„ Í¨ Ê¿*â¿* Ê¾ å’Œ c*â¿* æ˜¯å±‚ *n* çš„ç‰¹å¾æ•°é‡ã€‚å¦‚æœä»¥å›¾2Bä¸ºä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åˆå§‹ä¿¡å·ï¼ˆè¾“å…¥ï¼‰å¯ä»¥çœ‹ä½œæ˜¯å‡½æ•°
    *f :* S=â„Â² â†’ *Fâ‚€*= â„Â³ã€‚'
- en: '*fâ‚:* S=â„Â² â†’ *Fâ‚*= â„Â².'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*fâ‚:* S=â„Â² â†’ *Fâ‚*= â„Â²ã€‚'
- en: '**NN Filters Ï†n**: A filter can be defined as a map between two contiguous
    layers in this way so **Ï†*:****Fâ‚™â†’ Fâ‚™â‚Šâ‚.* The application of such a filter to
    a layer implies the convolution with the respective kernel *k*. How the convolution
    is defined in this case is crucial to the understanding of steerable NN. For this
    reason we dedicated a paragraph below.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NNæ»¤æ³¢å™¨ Ï†n**: æ»¤æ³¢å™¨å¯ä»¥å®šä¹‰ä¸ºä¸¤ä¸ªè¿ç»­å±‚ä¹‹é—´çš„æ˜ å°„ï¼Œå¦‚**Ï†*:****Fâ‚™â†’ Fâ‚™â‚Šâ‚*ã€‚å°†è¿™ç§æ»¤æ³¢å™¨åº”ç”¨äºä¸€å±‚æ„å‘³ç€ä¸ç›¸åº”çš„å†…æ ¸*k*è¿›è¡Œå·ç§¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹å¦‚ä½•å®šä¹‰å·ç§¯å¯¹ç†è§£å¯å¯¼NNè‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢ä¸“é—¨è®¨è®ºäº†è¿™ä¸€ç‚¹ã€‚'
- en: NN filter and convolution
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NNæ»¤æ³¢å™¨å’Œå·ç§¯
- en: 'In this case, the kernel can be seen as a function *k: S â†’* â„ Í¨ Ê¿*â¿* Ê¾ ËŸ Í¨
    Ê¿*â¿âº Â¹* Ê¾, where each position in *S is connected to a matrix of dimension c*Ê¿*â¿*
    Ê¾ ËŸ cÊ¿*â¿âº Â¹* Ê¾. For clarity, c*â¿* and c*â¿* âº *Â¹* are respectively the dimension
    (number of features) of *Fâ‚™* and *Fâ‚™â‚Šâ‚.*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå†…æ ¸å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªå‡½æ•° *k: S â†’* â„ Í¨ Ê¿*â¿* Ê¾ ËŸ Í¨ Ê¿*â¿âº Â¹* Ê¾ï¼Œå…¶ä¸­ *S ä¸­çš„æ¯ä¸ªä½ç½®éƒ½è¿æ¥åˆ°ä¸€ä¸ªç»´åº¦ä¸º
    c*Ê¿*â¿* Ê¾ ËŸ cÊ¿*â¿âº Â¹* Ê¾ çš„çŸ©é˜µã€‚ä¸ºäº†æ¸…æ™°èµ·è§ï¼Œc*â¿* å’Œ c*â¿* âº *Â¹* åˆ†åˆ«æ˜¯ *Fâ‚™* å’Œ *Fâ‚™â‚Šâ‚* çš„ç»´åº¦ï¼ˆç‰¹å¾æ•°é‡ï¼‰ã€‚'
- en: '*We can define the convolution as following:*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*æˆ‘ä»¬å¯ä»¥å®šä¹‰å·ç§¯å¦‚ä¸‹ï¼š*'
- en: '![](../Images/bd6be8a28fb69390eda6f2f30eb0a5c4.png)![](../Images/2ff2e0ea7f32941591297fa3688147e4.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd6be8a28fb69390eda6f2f30eb0a5c4.png)![](../Images/2ff2e0ea7f32941591297fa3688147e4.png)'
- en: 'Eq.8: Top: Relation which connects layer n and layer n+1\. Down: Definition
    of convolution in the space S'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.8: ä¸Šæ–¹ï¼šè¿æ¥å±‚nå’Œå±‚n+1çš„å…³ç³»ã€‚ä¸‹æ–¹ï¼šç©ºé—´Sä¸­çš„å·ç§¯å®šä¹‰'
- en: The top equation Eq.8 represents the function which connects the layer *n* and
    *n+1*; the one below is the definition of convolution in n-dimensional space S.
    The function Ïƒ*(x)* represents the non-linear function applied at the output of
    the convolution.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šé¢çš„æ–¹ç¨‹ Eq.8 ä»£è¡¨è¿æ¥å±‚ *n* å’Œ *n+1* çš„å‡½æ•°ï¼›ä¸‹é¢çš„æ˜¯nç»´ç©ºé—´Sä¸­çš„å·ç§¯å®šä¹‰ã€‚å‡½æ•° Ïƒ*(x)* ä»£è¡¨åº”ç”¨äºå·ç§¯è¾“å‡ºçš„éçº¿æ€§å‡½æ•°ã€‚
- en: 'In Fig 2B, it is possible to see how, in a discrete domain, the convolution
    between the kernel and the input layer is calculated.Letâ€™s illustrate this with
    a grayscale image denoted as *f â‚€*: â„Â² -> â„. We can apply the filter discussed
    in Section 2, which was a steerable filter with the function'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 'åœ¨å›¾2Bä¸­ï¼Œå¯ä»¥çœ‹åˆ°åœ¨ç¦»æ•£åŸŸä¸­ï¼Œå†…æ ¸ä¸è¾“å…¥å±‚ä¹‹é—´çš„å·ç§¯æ˜¯å¦‚ä½•è®¡ç®—çš„ã€‚æˆ‘ä»¬ç”¨ä¸€ä¸ªç°åº¦å›¾åƒ *f â‚€*: â„Â² -> â„ æ¥è¯´æ˜è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å¯ä»¥åº”ç”¨ç¬¬2èŠ‚ä¸­è®¨è®ºçš„æ»¤æ³¢å™¨ï¼Œè¿™æ˜¯ä¸€ä¸ªå…·æœ‰å‡½æ•°çš„å¯å¯¼æ»¤æ³¢å™¨ã€‚'
- en: '*k(xâ‚, xâ‚‚)* being a 2D Gaussian filter defined as *k:* â„Â² -> â„Â¹ËŸÂ¹=â„.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*k(xâ‚, xâ‚‚)* æ˜¯ä¸€ä¸ªå®šä¹‰ä¸º *k:* â„Â² -> â„Â¹ËŸÂ¹=â„ çš„2Dé«˜æ–¯æ»¤æ³¢å™¨ã€‚'
- en: '**In this case the application of the filter k on f*â‚€* is the classical 2D
    convolution and it can be written as:**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå°†æ»¤æ³¢å™¨kåº”ç”¨äº*f*â‚€* æ˜¯ç»å…¸çš„2Då·ç§¯ï¼Œå¯ä»¥è¡¨ç¤ºä¸ºï¼š**'
- en: '![](../Images/53e163eb2326de5d1342bb6f4b99362f.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53e163eb2326de5d1342bb6f4b99362f.png)'
- en: 'Eq.9: Definition of convolution'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.9: å·ç§¯çš„å®šä¹‰'
- en: 'Differently, in Fig. 2B you can see another example where *f â‚€*: *â„Â²->* â„Â³(rgb
    image for example) and *fâ‚*: *â„Â²-> â„Â²* and *kâ‚€: â„Â²->* â„Â³ËŸ *Â².*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 'ä¸åŒçš„æ˜¯ï¼Œåœ¨å›¾2Bä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°å¦ä¸€ä¸ªä¾‹å­ï¼Œå…¶ä¸­ *f â‚€*: *â„Â²->* â„Â³ï¼ˆä¾‹å¦‚rgbå›¾åƒï¼‰å’Œ *fâ‚*: *â„Â²-> â„Â²* ä»¥åŠ *kâ‚€:
    â„Â²->* â„Â³ËŸ *Â²*ã€‚'
- en: '![](../Images/edef4ef670f224a409fc844be0601fc4.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/edef4ef670f224a409fc844be0601fc4.png)'
- en: '**Fig 2B**: Visual example of filter convolution as defined above having S=RÂ².
    Fâ° is the input space where the signal fâ° exists, in this case RÂ³. As possible
    to notice, the convolution operation has been substitute by correlation operation
    as suggested in [[4]](https://arxiv.org/abs/1911.08251)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**å›¾2B**: å¦‚ä¸Šå®šä¹‰çš„æ»¤æ³¢å™¨å·ç§¯çš„è§†è§‰ç¤ºä¾‹ï¼ŒS=RÂ²ã€‚Fâ°æ˜¯ä¿¡å·fâ°å­˜åœ¨çš„è¾“å…¥ç©ºé—´ï¼Œåœ¨æ­¤æ¡ˆä¾‹ä¸­æ˜¯RÂ³ã€‚å¯ä»¥æ³¨æ„åˆ°ï¼Œå·ç§¯æ“ä½œå·²è¢«ç›¸å…³æ“ä½œæ›¿ä»£ï¼Œå¦‚[[4]](https://arxiv.org/abs/1911.08251)ä¸­æ‰€å»ºè®®ã€‚'
- en: 'Combining all the points weâ€™ve discussed so far, one can visualize a neural
    network within this formalism. Each individual feature map can be interpreted
    as a function *f: S â†’ Fâ‚™*, where *Fâ‚™*= â„Ê¿â¿ Ê¾ and *fâ‚€(x)* represents the networkâ€™s
    input. The filterâ€™s application involves convolving it with its kernel function
    defined in Eq.8\. Itâ€™s worth noting that the main innovation thus far lies in
    the geometric representation of f as a function operating in a positional space
    S, and the definition of convolution within this space.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 'ç»¼åˆæˆ‘ä»¬è¿„ä»Šè®¨è®ºçš„æ‰€æœ‰è¦ç‚¹ï¼Œå¯ä»¥åœ¨è¿™ä¸€å½¢å¼åŒ–æ¡†æ¶å†…å¯è§†åŒ–ç¥ç»ç½‘ç»œã€‚æ¯ä¸ªå•ç‹¬çš„ç‰¹å¾å›¾å¯ä»¥è¢«è§£é‡Šä¸ºä¸€ä¸ªå‡½æ•° *f: S â†’ Fâ‚™*ï¼Œå…¶ä¸­ *Fâ‚™*= â„Ê¿â¿
    Ê¾ å’Œ *fâ‚€(x)* ä»£è¡¨ç½‘ç»œçš„è¾“å…¥ã€‚æ»¤æ³¢å™¨çš„åº”ç”¨æ¶‰åŠä¸å…¶åœ¨Eq.8ä¸­å®šä¹‰çš„æ ¸å‡½æ•°å·ç§¯ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œä¸»è¦çš„åˆ›æ–°åœ¨äºå°† *f* ä½œä¸ºåœ¨ä½ç½®ç©ºé—´
    S ä¸­æ“ä½œçš„å‡½æ•°çš„å‡ ä½•è¡¨ç¤ºï¼Œä»¥åŠåœ¨è¿™ä¸€ç©ºé—´å†…å·ç§¯çš„å®šä¹‰ã€‚'
- en: 'Below, we provide a representation of what a neural network in this context
    looks like:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æˆ‘ä»¬æä¾›çš„ç¥ç»ç½‘ç»œåœ¨è¿™ä¸€èƒŒæ™¯ä¸‹çš„è¡¨ç¤ºï¼š
- en: '![](../Images/0080d2118a618cbfcbc3c6213d0a2c46.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0080d2118a618cbfcbc3c6213d0a2c46.png)'
- en: 'Eq.10: Symbolic representation of a neural network using the formalism expressed
    above.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 'Eq.10: ä½¿ç”¨ä¸Šè¿°å½¢å¼åŒ–è¡¨è¾¾çš„ç¥ç»ç½‘ç»œçš„ç¬¦å·è¡¨ç¤ºã€‚'
- en: We will understand in the next [article](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-3-56dfc256b690)
    how the definition of such formalism will help us in the design of a steerable
    CNN filter.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€ç¯‡[æ–‡ç« ](https://medium.com/@mat.cip43/a-gentle-introduction-to-steerable-neural-networks-part-3-56dfc256b690)ä¸­äº†è§£è¿™ç§å½¢å¼åŒ–å®šä¹‰å¦‚ä½•å¸®åŠ©æˆ‘ä»¬è®¾è®¡å¯å¼•å¯¼çš„CNNæ»¤æ³¢å™¨ã€‚
- en: Conclusions
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this initial segment of our Steerable Neural Networks tutorial, we have established
    the fundamental concepts of Steerable Neural Networks, equivariance, and steerable
    filters. A mathematical framework has also been introduced to provide a rigorous
    foundation for understanding these concepts. Equivariance preserves behavior under
    transformations, while steerable filters adapt intelligently to input orientations.
    This groundwork paves the way for designing equivariant CNN filters, enhancing
    edge detection and orientation-based recognition. The next article will leverage
    these concepts for a deeper dive into Steerable CNN filtersâ€™ mechanics, completing
    our journey into this powerful neural network paradigm.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬ã€Šå¯å¼•å¯¼ç¥ç»ç½‘ç»œã€‹æ•™ç¨‹çš„åˆå§‹éƒ¨åˆ†ï¼Œæˆ‘ä»¬å·²ç»å»ºç«‹äº†å¯å¼•å¯¼ç¥ç»ç½‘ç»œã€ç­‰å˜æ€§å’Œå¯å¼•å¯¼æ»¤æ³¢å™¨çš„åŸºæœ¬æ¦‚å¿µã€‚è¿˜ä»‹ç»äº†ä¸€ä¸ªæ•°å­¦æ¡†æ¶ï¼Œä¸ºç†è§£è¿™äº›æ¦‚å¿µæä¾›äº†ä¸¥æ ¼çš„åŸºç¡€ã€‚ç­‰å˜æ€§åœ¨å˜æ¢ä¸‹ä¿æŒè¡Œä¸ºä¸å˜ï¼Œè€Œå¯å¼•å¯¼æ»¤æ³¢å™¨èƒ½å¤Ÿæ™ºèƒ½åœ°é€‚åº”è¾“å…¥çš„æ–¹å‘ã€‚è¿™ä¸€åŸºç¡€å·¥ä½œä¸ºè®¾è®¡ç­‰å˜CNNæ»¤æ³¢å™¨é“ºå¹³äº†é“è·¯ï¼Œå¢å¼ºäº†è¾¹ç¼˜æ£€æµ‹å’ŒåŸºäºæ–¹å‘çš„è¯†åˆ«ã€‚ä¸‹ä¸€ç¯‡æ–‡ç« å°†åˆ©ç”¨è¿™äº›æ¦‚å¿µæ›´æ·±å…¥åœ°æ¢è®¨å¯å¼•å¯¼CNNæ»¤æ³¢å™¨çš„æœºåˆ¶ï¼Œå®Œæˆæˆ‘ä»¬å¯¹è¿™ä¸€å¼ºå¤§ç¥ç»ç½‘ç»œèŒƒå¼çš„æ¢ç´¢ã€‚
- en: 'âœï¸ ğŸ“„. About the authors:'
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: âœï¸ ğŸ“„. å…³äºä½œè€…ï¼š
- en: '***1ï¸âƒ£ Matteo Ciprian*,** Machine Learning Engineer/Researcher'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '***1ï¸âƒ£ Matteo Ciprian***ï¼Œæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ/ç ”ç©¶å‘˜'
- en: MSc in Telecommunications Engineering at University of Padua. Currently working
    in the field of Sensor Fusion, Signal Processing and applied AI. Experience in
    projects related to AI applications in eHealth and wearable technologies (academic
    research and corporate domains). Specialized in developing Anomaly Detection algorithms,
    as well as advancing techniques in Deep Learning and Sensor Fusion.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¸•å¤šç“¦å¤§å­¦ç”µä¿¡å·¥ç¨‹ç¡•å£«ã€‚å½“å‰ä»äº‹ä¼ æ„Ÿå™¨èåˆã€ä¿¡å·å¤„ç†å’Œåº”ç”¨AIé¢†åŸŸçš„å·¥ä½œã€‚å…·æœ‰ä¸AIåœ¨ç”µå­å¥åº·å’Œå¯ç©¿æˆ´æŠ€æœ¯ä¸­çš„åº”ç”¨ç›¸å…³çš„é¡¹ç›®ç»éªŒï¼ˆåŒ…æ‹¬å­¦æœ¯ç ”ç©¶å’Œä¼ä¸šé¢†åŸŸï¼‰ã€‚ä¸“æ³¨äºå¼€å‘å¼‚å¸¸æ£€æµ‹ç®—æ³•ï¼Œä»¥åŠæ¨è¿›æ·±åº¦å­¦ä¹ å’Œä¼ æ„Ÿå™¨èåˆæŠ€æœ¯ã€‚
- en: Passionate about Philosophy. Content creator in Youtube.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å¯¹å“²å­¦å……æ»¡çƒ­æƒ…ã€‚YouTubeå†…å®¹åˆ›ä½œè€…ã€‚
- en: '**ğŸ”— Links:** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/matteo-ciprian-ba30ab122/)'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**ğŸ”— é“¾æ¥ï¼š** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/matteo-ciprian-ba30ab122/)'
- en: ğŸ“¹ [Youtube](https://www.youtube.com/channel/UCF--7G3kkCmEsdPLm8wyPow)
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ“¹ [Youtube](https://www.youtube.com/channel/UCF--7G3kkCmEsdPLm8wyPow)
- en: ğŸ‘¨â€ğŸ’»[Instagram](https://www.instagram.com/cip_mat/)
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ‘¨â€ğŸ’»[Instagram](https://www.instagram.com/cip_mat/)
- en: 2ï¸âƒ£ ***Robert Schoonmaker*,** Signal Processing/Machine Learning Researcher
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ ***Robert Schoonmaker***ï¼Œä¿¡å·å¤„ç†/æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜
- en: PhD in Computational Condensed Matter Physics from Durham University. Specializes
    in applied machine learning and nonlinear statistics, currently investigating
    the uses of GPU compute methods on synthetic aperture radar and similar systems.
    Experience includes developing symmetric ML methods for use in sensor fusion and
    positioning techniques.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æœä¼¦å¤§å­¦è®¡ç®—å‡èšæ€ç‰©ç†åšå£«ã€‚ä¸“æ³¨äºåº”ç”¨æœºå™¨å­¦ä¹ å’Œéçº¿æ€§ç»Ÿè®¡ï¼Œç›®å‰ç ”ç©¶GPUè®¡ç®—æ–¹æ³•åœ¨åˆæˆå­”å¾„é›·è¾¾åŠç±»ä¼¼ç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚ç»éªŒåŒ…æ‹¬å¼€å‘ç”¨äºä¼ æ„Ÿå™¨èåˆå’Œå®šä½æŠ€æœ¯çš„å¯¹ç§°æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚
- en: '**ğŸ”— Links:** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/robert-schoonmaker-951221b/)'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**ğŸ”— é“¾æ¥ï¼š** ğŸ’¼ [Linkedin](https://www.linkedin.com/in/robert-schoonmaker-951221b/)'
