- en: Understanding NeRFs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 NeRFs
- en: 原文：[https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=collection_archive---------4-----------------------#2023-04-28](https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=collection_archive---------4-----------------------#2023-04-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=collection_archive---------4-----------------------#2023-04-28](https://towardsdatascience.com/understanding-nerfs-2a082e13c6eb?source=collection_archive---------4-----------------------#2023-04-28)
- en: A massive breakthrough in scene representation
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景表示的重大突破
- en: '[](https://wolfecameron.medium.com/?source=post_page-----2a082e13c6eb--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----2a082e13c6eb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2a082e13c6eb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2a082e13c6eb--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----2a082e13c6eb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----2a082e13c6eb--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----2a082e13c6eb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2a082e13c6eb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2a082e13c6eb--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----2a082e13c6eb--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----2a082e13c6eb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2a082e13c6eb--------------------------------)
    ·11 min read·Apr 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----2a082e13c6eb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----2a082e13c6eb---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2a082e13c6eb--------------------------------)
    ·11分钟阅读·2023年4月28日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----2a082e13c6eb---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&source=-----2a082e13c6eb---------------------bookmark_footer-----------)![](../Images/0f3a2a80515f0f2c516a9ede3117054f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2a082e13c6eb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-nerfs-2a082e13c6eb&source=-----2a082e13c6eb---------------------bookmark_footer-----------)![](../Images/0f3a2a80515f0f2c516a9ede3117054f.png)'
- en: (Photo by [nuddle](https://unsplash.com/@nuddle?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/3d-scene?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由 [nuddle](https://unsplash.com/@nuddle?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/s/photos/3d-scene?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: As we have seen with methods like [DeepSDF](https://cameronrwolfe.substack.com/p/3d-generative-modeling-with-deepsdf)
    [2] and [SRNs](https://cameronrwolfe.substack.com/p/scene-representation-networks)
    [4], encoding 3D objects and scenes within the weights of a feed-forward neural
    network is a memory-efficient, implicit representation of 3D data that is both
    accurate and high-resolution. However, the approaches we have seen so far are
    not quite capable of capturing realistic and complex scenes with sufficient fidelity.
    Rather, discrete representations (e.g., triangle meshes or voxel grids) produce
    a more accurate representation, assuming a sufficient allocation of memory.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在像[DeepSDF](https://cameronrwolfe.substack.com/p/3d-generative-modeling-with-deepsdf)
    [2]和[SRNs](https://cameronrwolfe.substack.com/p/scene-representation-networks)
    [4]
- en: This changed with the proposal of Neural Radiance Fields (NeRFs) [1], which
    use a feed-forward neural network to model a continuous representation of scenes
    and objects. The representation used by NeRFs, called a radiance field, is a bit
    different from [prior](https://cameronrwolfe.substack.com/i/94634004/signed-distance-functions)
    [proposals](https://cameronrwolfe.substack.com/i/94842305/occupancy-functions).
    In particular, NeRFs map a five-dimensional coordinate (i.e., spatial location
    and viewing direction) to a volume density and view-dependent RGB color. By accumulating
    this density and appearance information across different viewpoints and locations,
    we can render photorealist, novel views of a scene.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况随着神经辐射场（NeRFs）[1]的提出而发生了变化，该方法使用前馈神经网络来建模场景和物体的连续表示。NeRFs 使用的表示，称为辐射场，与[早期](https://cameronrwolfe.substack.com/i/94634004/signed-distance-functions)
    [提案](https://cameronrwolfe.substack.com/i/94842305/occupancy-functions)略有不同。特别是，NeRFs
    将五维坐标（即空间位置和视角方向）映射到体积密度和视角相关的 RGB 颜色。通过在不同的视角和位置上累积这些密度和外观信息，我们可以渲染出逼真的新视图。
- en: Like [SRNs](https://cameronrwolfe.substack.com/p/scene-representation-networks)
    [4], NeRFs can be trained using only a set of images (along with their associated
    [camera poses](https://cameronrwolfe.substack.com/i/97472888/background)) of an
    underlying scene. Compared with prior approaches, NeRF renderings are better both…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 像[SRNs](https://cameronrwolfe.substack.com/p/scene-representation-networks)
    [4]一样，NeRFs 可以仅使用一组图像（以及其相关的[相机姿态](https://cameronrwolfe.substack.com/i/97472888/background)）对基础场景进行训练。与以前的方法相比，NeRF
    渲染效果更佳。
