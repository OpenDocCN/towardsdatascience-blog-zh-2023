- en: 'ChatGPT Generated Food Industry Reviews: Realism Assessment'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT生成的食品行业评论：现实性评估
- en: 原文：[https://towardsdatascience.com/chatgpt-generated-food-industry-reviews-realism-assessment-2ee28155970f](https://towardsdatascience.com/chatgpt-generated-food-industry-reviews-realism-assessment-2ee28155970f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/chatgpt-generated-food-industry-reviews-realism-assessment-2ee28155970f](https://towardsdatascience.com/chatgpt-generated-food-industry-reviews-realism-assessment-2ee28155970f)
- en: Investigating how review and survey collection by food industry companies can
    be supported by ChatGPT-generated data.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探讨如何通过ChatGPT生成的数据来支持食品行业公司收集评论和调查。
- en: '[](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)[![Benjamin
    McCloskey](../Images/7118f5933f2affe2a7a4d3375452fa4c.png)](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)
    [Benjamin McCloskey](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)[![Benjamin
    McCloskey](../Images/7118f5933f2affe2a7a4d3375452fa4c.png)](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)
    [Benjamin McCloskey](https://ben-mccloskey20.medium.com/?source=post_page-----2ee28155970f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)
    ·13 min read·Jun 9, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----2ee28155970f--------------------------------)
    ·阅读时间13分钟·2023年6月9日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/45ea0b6597515a537982a20603e6b762.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45ea0b6597515a537982a20603e6b762.png)'
- en: Photo by [Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Annie Spratt](https://unsplash.com/@anniespratt?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Where It Started
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 起点
- en: The bulk of my research in the past used *Generative Adversarial Networks (GAN)*
    for creating deepfake images of my dataset. I wanted to do this to increase the
    diversity of information within my dataset, which I predicted would result in
    better object detection models (s[ee more about this research here!](https://journals.sagepub.com/doi/abs/10.1177/15485129231170225?journalCode=dmsa)).
    While a completely different task than deepfake image creation, I wondered; ***is
    there a way to increase the size of the datasets I used containing reviews for
    different companies in the food industry?***
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我过去的大部分研究使用了*生成对抗网络（GAN）*来创建数据集的深度伪造图像。我这样做是为了增加数据集中的信息多样性，我预测这会导致更好的目标检测模型（[了解更多关于这项研究的信息！](https://journals.sagepub.com/doi/abs/10.1177/15485129231170225?journalCode=dmsa)）。虽然这是与深度伪造图像创建完全不同的任务，但我想知道：***是否有办法增加我用于不同食品公司评论的数据集的规模？***
- en: Could I train a GAN? Yes, but GANs are not great at generating tabular data,
    and to me, words in the text are more aligned with data found in spreadsheets.
    Then came ChatGPT. Voila! Could I create new reviews for my dataset by simply
    *asking* ChatGPT to generate them with different prompts?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我能训练一个GAN吗？可以，但GAN在生成表格数据方面表现不佳，而对我而言，文本中的词汇更符合电子表格中的数据。然后出现了ChatGPT。瞧！我是否可以通过简单地*请求*
    ChatGPT用不同的提示生成新的评论来为我的数据集创建新的评论？
- en: Why It Matters
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么这很重要
- en: There are a few reasons we would want to increase the size of a dataset.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要增加数据集规模有几个原因。
- en: Lacking enough data to train a model.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 缺乏足够的数据来训练模型。
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Biased dataset (hence we need to bias it with the underrepresented class of
    data).
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据集存在偏见（因此我们需要用少数类数据来矫正它）。
- en: ''
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Lack of diversity within the dataset
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据集缺乏多样性
- en: The datasets I was creating (with the approval from the company I used in my
    example today) lacked negative reviews, review diversity, and size, warranting
    an implementation of dataset augmentation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建的数据集（获得了今天示例中公司批准）缺乏负面评论、评论多样性和规模，因此需要实施数据集增强。
- en: '**Lacking enough data to train a model**. If you attempt to build a model with
    a lack of data, a multitude of problems could occur. One problem may be the model
    overfits the data and performs poorly on real-world examples.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据不足以训练模型**。如果你试图在缺乏数据的情况下构建模型，可能会出现各种问题。一个问题可能是模型对数据过拟合，并在实际应用中表现不佳。'
- en: '**Biased dataset**. If a dataset is dominated by one class, it lacks representations
    for other classes which will lead to models and analyses unfit for said class.
    We want to have a balanced dataset to ensure our model performs well in operations
    across all classes of data we are interested in investigating.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏见数据集**。如果数据集被某一类主导，则缺乏其他类的代表，这将导致模型和分析不适用于该类。我们希望拥有一个平衡的数据集，以确保我们的模型在我们感兴趣的所有数据类的操作中表现良好。'
- en: '**Lack of diversity within the dataset.** The real world is messy. If our dataset
    lacks diversity, our model will not *generalize* well to changes in the details
    of samples once put into production. **Generalizability** is the model’s ability
    to classify or know a sample belongs to a certain class, even if that sample contains
    features that are distinct from or underrepresented in the class it belongs to.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据集缺乏多样性**。现实世界是混乱的。如果我们的数据集缺乏多样性，一旦投入生产，我们的模型将无法*泛化*到样本细节的变化上。**泛化能力**是模型能够分类或识别样本属于某一类，即使该样本包含与其所属类不同或在该类中未充分代表的特征。'
- en: The Analysis
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析
- en: The following APIs were used for today’s analysis.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的分析使用了以下API。
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The Dataset
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: The original dataset was compiled together with the permission of the company
    (Altomontes Inc) to use the reviews (see these two articles where I show how to
    use Natural Language Processing on the reviews).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集是与公司（Altomontes Inc）授权的情况下汇编的，用于使用评论（请参阅这两篇文章，我展示了如何对评论使用自然语言处理）。
- en: '[](/machine-learning-is-not-just-for-big-tech-using-natural-language-processing-to-support-small-8f571249c073?source=post_page-----2ee28155970f--------------------------------)
    [## Machine Learning is Not Just for Big Tech'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 机器学习不仅仅是为了大科技公司](https://towardsdatascience.com/machine-learning-is-not-just-for-big-tech-using-natural-language-processing-to-support-small-8f571249c073?source=post_page-----2ee28155970f--------------------------------) '
- en: Using Natural Language Processing to Support Small Businesses.
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用自然语言处理来支持小型企业。
- en: towardsdatascience.com](/machine-learning-is-not-just-for-big-tech-using-natural-language-processing-to-support-small-8f571249c073?source=post_page-----2ee28155970f--------------------------------)
    [](/topic-modeling-analysis-for-small-businesses-73ba23474261?source=post_page-----2ee28155970f--------------------------------)
    [## Topic Modeling Analysis for Small Businesses
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/machine-learning-is-not-just-for-big-tech-using-natural-language-processing-to-support-small-8f571249c073?source=post_page-----2ee28155970f--------------------------------)
    [## 针对小型企业的主题建模分析](https://towardsdatascience.com/topic-modeling-analysis-for-small-businesses-73ba23474261?source=post_page-----2ee28155970f--------------------------------)'
- en: Introduction
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: towardsdatascience.com](/topic-modeling-analysis-for-small-businesses-73ba23474261?source=post_page-----2ee28155970f--------------------------------)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/topic-modeling-analysis-for-small-businesses-73ba23474261?source=post_page-----2ee28155970f--------------------------------)'
- en: '**Example of an original review:**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**原始评论示例：**'
- en: '*“Highly recommend!!! I never knew about Altomontes until a friend dropped
    off a meal at my house recently. My husband and I decided to go and check it out
    and while we were there, we met the owner and she was the sweetest person ever!
    She basically gave us a tour. We bought the chicken marsala for dinner and it
    was wonderful! We also bought the Brooklyn pizza for lunch and it was delicious!
    We sampled their coffee and they let us taste a cannoli, biscotti and a cookie.
    Very good! We bought shells, marinara sauce, a bottle of wine, some cheese etc.
    Everything looked good, taste good and we could spend hours there! We will be
    back!! Maybe today?”*'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“强烈推荐！！！我之前从未听说过Altomontes，直到最近一个朋友把餐点送到我家。我的丈夫和我决定去看看，在那里我们遇到了老板，她是最可爱的人！她基本上给我们做了一个参观。我们买了鸡肉玛莎拉作为晚餐，非常棒！我们还买了布鲁克林比萨作为午餐，非常美味！我们品尝了他们的咖啡，他们让我们尝试了卡诺利、饼干和小饼干。非常好！我们买了贝壳面、意大利面酱、一瓶酒、一些奶酪等等。一切看起来都很不错，味道也很好，我们可以在那儿呆几个小时！我们会回来的！！也许今天？”*'
- en: The next two datasets I created using ChatGPT. One contained positive reviews
    about an Italian Market and the goods it sells, while the other contained negative
    reviews about an Italian Market and the goods it sells.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用ChatGPT创建了接下来的两个数据集。一个包含有关意大利市场及其销售商品的积极评论，另一个包含有关意大利市场及其销售商品的负面评论。
- en: '**Example of a ChatGPT-generated positive review:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**ChatGPT生成的正面评论示例：**'
- en: '*“The Pecorino Toscano cheese I bought had a robust and savory taste. Its firm
    and crumbly texture, with a hint of grassiness, made it a great choice for grating,
    shaving, or enjoying on its own.”*'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“我买的佩科里诺托斯卡纳奶酪味道浓郁而美味。其坚硬且易碎的质地，带有一丝草香，使其非常适合磨碎、刮削或单独享用。”*'
- en: '**Example of a ChatGPT-generated negative review:**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**ChatGPT生成的负面评论示例：**'
- en: '*”The prosciutto and arugula pizza I tried had wilted arugula and the prosciutto
    was tough. It wasn’t appetizing.”*'
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“我尝试的火腿和芝麻菜比萨有枯萎的芝麻菜，火腿也很硬。没有胃口。”*'
- en: Once all of the reviews were created and placed into CSV files (find them [here](https://medium.com/towards-data-science/topic-modeling-analysis-for-small-businesses-73ba23474261)),
    I formatted them into a dictionary where each key was the source (source being
    ***original, generated positive***, or ***generated negative*** ) and the items
    were its reviews and a list of tuples where each tuple contained the review and
    its source.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有评论被创建并放入 CSV 文件（在 [这里](https://medium.com/towards-data-science/topic-modeling-analysis-for-small-businesses-73ba23474261)
    找到），我将它们格式化为一个字典，每个键是源（源为 ***原始、生成的正面*** 或 ***生成的负面***）而项目是评论及其来源的元组列表。
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Sentence Assessments
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 句子评估
- en: Realism Assessment
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现实性评估
- en: First, I simply wanted to assess if the reviews seemed “realistic.” This is
    similar to calculating the *coherence* of a given body of text and its connections.
    My initial thought is they will all be deemed realistic, but I thought it would
    be interesting to also visualize the scores from the original reviews, artificial
    positive reviews, and artificial negative reviews.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我只是想评估这些评论是否看起来“现实”。这类似于计算给定文本的 *连贯性* 及其联系。我的初步想法是它们都会被认为是现实的，但我觉得也有必要可视化原始评论、人工正面评论和人工负面评论的得分。
- en: To start this assessment, we are first going to create an *assess_sentence_realism*
    function. This function seeks to look at the cohesiveness of a sentence and if
    the input sentence is “realistic” to how a human would interpret it.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个评估，我们首先要创建一个 *assess_sentence_realism* 函数。这个函数旨在检查一个句子的连贯性，以及输入句子是否“现实”到符合人类的解读方式。
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You will need to download an embedding model to create your word embeddings.
    The model I chose to use was the Google News 300 model (check it out [here](https://huggingface.co/fse/word2vec-google-news-300)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要下载一个嵌入模型来创建你的词嵌入。我选择使用的模型是 Google News 300 模型（查看 [这里](https://huggingface.co/fse/word2vec-google-news-300)）。
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: → **Original Dataset Score:** 0.17
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: → **原始数据集得分：** 0.17
- en: → **ChatGPT-generated Positive Dataset Score:** 0.15
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: → **ChatGPT生成的正面数据集得分：** 0.15
- en: → C**hatGPT-generated Negative Dataset Score:** 0.16
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: → **ChatGPT生成的负面数据集得分：** 0.16
- en: '![](../Images/29b9e7c8486e85ac4e1987444ec88289.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29b9e7c8486e85ac4e1987444ec88289.png)'
- en: Mean Realism Scores (Image from Author)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 平均现实性得分（图像来自作者）
- en: As expected (well maybe), the original reviews were scored to be the most realistic.
    Why could this be? Well, for starters, **they were the real reviews**. One of
    the big reasons I also suspect why ChatGPT scored lower is linked to how over
    time the model was following somewhat of a pattern with the reviews it was creating.
    Some of the reviews were very close to being the same, and ChatGPT would simply
    alter a few words around.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期（也许），原始评论被评为最现实。为什么会这样呢？首先，**它们是真实的评论**。我还怀疑 ChatGPT 得分较低的一个重要原因是，随着时间的推移，模型遵循了一定的评论模式。一些评论几乎相同，ChatGPT
    只是简单地改变了几个词。
- en: (ie. *The* ***pizza*** *was not good and was very dry → The* ***pasta*** w*as
    not good and was very dry)*
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: (即 *The* ***比萨*** *不好且很干 → The* ***意大利面*** *不好且很干)*
- en: There was also a lack of **diversity** in the ChatGPT reviews compared to the
    real reviews, which we can expect (think about it, multiple people made the real
    reviews while one model created the fake reviews). With that being said, the reviews
    created by ChatGPT still scored relatively well compared to the original reviews
    and I would say it's worth a shot to go ahead and train our models with them in
    the future.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 与真实评论相比，ChatGPT 评论的 **多样性** 也有所欠缺，这在预期之中（考虑一下，真实评论是由多人写的，而假评论则是由一个模型生成的）。尽管如此，与原始评论相比，ChatGPT
    生成的评论得分仍然相对较高，我认为值得尝试未来用这些评论来训练我们的模型。
- en: '**Before doing so, let’s also do a similarity assessment between the reviews.**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**在此之前，我们还要进行一次评论的相似性评估。**'
- en: '**Similarity Assessment**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**相似性评估**'
- en: Next, I wanted to look at the similarities between each batch of the generated
    reviews and the original reviews. To do this, we can use *cosine similarity* to
    calculate how similar the different sentence vectors from each source are. First,
    we can create a cosine similarity matrix that will first transform our sentences
    into vectors using TfidVectorizer() and then calculate the cosine similarity between
    the two new sentence vectors.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我想查看每一批生成的评论与原始评论之间的相似性。为此，我们可以使用*余弦相似性*来计算每个来源的不同句子向量之间的相似性。首先，我们可以创建一个余弦相似性矩阵，该矩阵将首先使用TfidVectorizer()将我们的句子转换为向量，然后计算这两个新的句子向量之间的余弦相似性。
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: One problem I had was the datasets were now so big that the calculations were
    taking too long (and sometimes I did not have enough RAM on Google Colab to continue).
    To combat this issue, I randomly sampled 200 reviews from each of the datasets
    for calculating the similarity.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我遇到的一个问题是数据集现在变得非常庞大，以至于计算需要很长时间（有时我在Google Colab上没有足够的RAM继续）。为了解决这个问题，我从每个数据集中随机抽取了200条评论来计算相似性。
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now that we have the randomly selected samples, we can look at cosine similarities
    between different combinations of the datasets.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了随机选择的样本，我们可以查看不同数据集组合之间的余弦相似性。
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/d594f9d323c86bc698842286861e4799.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d594f9d323c86bc698842286861e4799.png)'
- en: Cosine Similarity Results (Image from Author)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似性结果（图片来源：作者）
- en: For the original dataset, the negative reviews were more similar. My hypothesis
    is this is due to my using more prompts to create negative reviews than positive
    reviews. No surprise, the ChatGPT-generated reviews showed the highest signs of
    similarity between themselves.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于原始数据集，负面评论的相似性更高。我的假设是因为我用更多的提示来创建负面评论，而不是正面评论。毫不奇怪，ChatGPT生成的评论显示出它们之间的相似性最高。
- en: Great, we have the cosine similarities, but is there another step we can take
    to assess the similarities of the reviews? There is! Let’s visualize the sentences
    as vectors. To do this, we must embed the sentences (turn them into vectors of
    numbers) and then we can visualize them in 2D space. I used Spacy to embed my
    vectors and visualize them.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，我们已经得到了余弦相似性，但我们还能采取其他步骤来评估评论的相似性吗？可以的！让我们将句子可视化为向量。为此，我们必须将句子嵌入（将它们转化为数字向量），然后可以在二维空间中可视化它们。我使用了Spacy来嵌入我的向量并可视化它们。
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/b9f69002cab2db51681c3d5d439a6204.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9f69002cab2db51681c3d5d439a6204.png)'
- en: Sentence Vectors (Image from Author)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 句子向量（图片来源：作者）
- en: The good news is we can clearly see the embeddings and distributions of the
    sentence vectors closely align. Visual inspection shows there is more variability
    in the distribution of the *original reviews*, supporting the assertion **they
    are more *diverse****.* Since ChatGPT generated positive and negative reviews,
    we would suspect their distributions to be the same. Notice, however, the fake
    negative reviews actually have a wider distribution and more variance than positive
    reviews. *Why might this be?* Probably it is due in part to the fact that I had
    to trick ChatGPT to create the fake negative reviews (ChatGPT is designed to say
    positive statements) and I had to actually provide more prompts to ChatGPT to
    get enough negative reviews vs. positive ones. This helps the dataset because,
    with the additional diversity in the dataset, we can train higher-performing machine
    learning models.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，我们可以清楚地看到句子向量的嵌入和分布紧密对齐。目测显示，*原始评论*的分布变异性更大，这支持了**它们更*多样化*的断言**。由于ChatGPT生成了正面和负面评论，我们会怀疑它们的分布应该是一样的。然而，请注意，假负面评论实际上具有比正面评论更广泛的分布和更多的变异性。*这可能是为什么呢？*
    可能部分原因是因为我不得不欺骗ChatGPT以生成假负面评论（ChatGPT被设计成说正面评价），而且我实际上需要给ChatGPT提供更多的提示来获取足够的负面评论与正面评论。这对数据集有帮助，因为通过数据集的额外多样性，我们可以训练出更高性能的机器学习模型。
- en: '![](../Images/9242966364ffcbedb0fdbfdb78a7c957.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9242966364ffcbedb0fdbfdb78a7c957.png)'
- en: Sentence Vectors by Dataset (Image from Author)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的句子向量（图片来源：作者）
- en: Next, we can inspect the differences in the three different distributions of
    reviews and see if there are any distinguishing patterns.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以检查三种不同分布的评论之间的差异，看看是否存在任何区分性的模式。
- en: '*What do we see*? Visually, we can see that the bulk of the reviews for the
    dataset are centered around the origin and span from -10 to 10\. This is a positive
    sign and supports the use of fake reviews for training prediction models. The
    variances are somewhat the same, however, the original reviews had a wider variance
    in their distribution, both laterally and longitudinally, a proxy that there is
    more diversity in the lexicon within those reviews. The reviews from ChatGPT definitely
    had similar distributions, but the positive reviews had more outliers. As stated,
    these distinctions could be a result of the way I was prompting the system to
    generate reviews.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们看到了什么*？从视觉上看，我们可以看到数据集中大部分评论都集中在原点附近，并且范围从-10到10。这是一个积极的迹象，支持使用虚假评论来训练预测模型。方差基本相同，但原始评论的分布在横向和纵向上都有更宽的方差，这表明这些评论中的词汇多样性更大。ChatGPT的评论分布也非常相似，但正面评论有更多的异常值。如前所述，这些区别可能是由于我提示系统生成评论的方式造成的。'
- en: '**Pitfalls and Shortcomings**'
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**陷阱和不足**'
- en: While increasing the size and diversity of a dataset has many added benefits,
    there are weaknesses and pitfalls to this approach. The newly generated data may
    not be representative or close to the format of the real data. While we can make
    some math calculations and visualizations to support similarity, we can never
    be sure how the reviews will be interpreted in machine language. We could develop
    models for reading surveys and reviews for a company in the food industry with
    this data, but the model may break down when given the unstructured, “dirty” data
    from the real world since we have trained it more on generated fake data that
    follows an underlying pattern.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管增加数据集的大小和多样性有许多额外的好处，但这种方法也存在弱点和陷阱。新生成的数据可能无法代表或接近真实数据的格式。虽然我们可以进行一些数学计算和可视化以支持相似性，但我们永远不能确定评论在机器语言中会被如何解读。我们可以用这些数据为食品行业的公司开发读取调查问卷和评论的模型，但当面对来自现实世界的非结构化“脏”数据时，模型可能会崩溃，因为我们训练的模型更多是基于遵循潜在模式的虚假数据。
- en: 'Another issue is once the fake data is added, we forfeit the ability to do
    various analytical techniques for information extraction for example if I conduct
    topic modeling analysis with this new dataset, the topics won’t be defining just
    the original data. They now will be defining the fake data as well and that tells
    my customer nothing. Why does my customer care if “spaghetti is dry” is a topic
    when I created fake reviews saying stating such a fact? That’s my problem, not
    theirs. To be frank, this process hinders our ability to conduct exploratory data
    analysis (EDA). I see this as the biggest trade: with this data set, we can create
    classification and prediction models which may be suitable for interpreting new
    reviews (maybe even better due to the increase in the size of the dataset but
    you will need to build in processes for testing this) at the expense of not being
    able to extrapolate as much information from the data the company already (if
    we use this dataset).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，一旦加入虚假数据，我们就失去了使用各种分析技术提取信息的能力。例如，如果我用这个新数据集进行主题建模分析，主题将不仅定义原始数据。它们现在也将定义虚假数据，这对我的客户没有任何意义。当我创建了虚假评论声称某个事实时，为什么我的客户会关心“意大利面是否干燥”是一个主题？这是我的问题，而不是他们的问题。坦白说，这个过程阻碍了我们进行探索性数据分析（EDA）的能力。我认为这是最大的权衡：使用这个数据集，我们可以创建分类和预测模型，这些模型可能适用于解释新的评论（可能由于数据集规模的增加而更好，但你需要构建测试过程来验证这一点），代价是无法从公司已经拥有的数据中提取更多信息（如果我们使用这个数据集的话）。
- en: My biggest caution to anyone using generating data is, do not to forget about
    the original data you collected. Do not forget about the original questions and
    problems you are trying to solve. Forgetting this could lead you down a rabbit
    hole of trying to solve a problem that lies in the fake data itself!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我对任何使用生成数据的人最大的警告是，不要忘记你收集的原始数据。不要忘记你试图解决的原始问题和问题。忘记这一点可能会导致你陷入试图解决一个存在于虚假数据中的问题的死胡同！
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: One problem that arises in Data Science is the lack of data and diversity in
    the data. There are various methods for generating new data, and today showed
    how ChatGPT could be used for creating more data for your dataset. Today’s findings
    are especially helpful for those working in the *Food Industry.* Doing this could
    alleviate issues of imbalance and lack of diversity in datasets, leading to models
    which perform better on real-world data post-training.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学中一个常见的问题是数据的缺乏以及数据的多样性不足。生成新数据的方法有很多，今天展示了如何利用ChatGPT来为你的数据集创建更多的数据。今天的发现对那些在*食品行业*工作的人员尤其有帮助。这样做可以缓解数据集中的不平衡和多样性缺乏问题，从而使模型在训练后的真实世界数据上表现更佳。
- en: '***What did today show?***'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '***今天展示了什么？***'
- en: ChatGPT data could be helpful for your next Natural Language Processing Project
    (NLP), especially if you are implementing data science techniques for businesses
    in the food industry. **I would caution it is always good to try to collect the
    real data first.** If you find that you need more data for your dataset, it may
    not hurt to explore options like Generative Adversarial Networks (GAN), or Large
    Language Models (LLM), like ChatGPT. Finally, I always want to foot stomp, especially
    when working with Generative AI, it is important to use these tools ethically
    and in a positive manner for all impact parties.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT数据可能对你的下一个自然语言处理项目（NLP）有帮助，特别是当你为食品行业的业务实施数据科学技术时。**我建议首先尽量收集真实数据。**
    如果你发现你的数据集需要更多数据，可以考虑探索生成对抗网络（GAN）或大型语言模型（LLM），例如ChatGPT。最后，我想特别强调，尤其是在使用生成性人工智能时，重要的是以伦理和积极的方式使用这些工具，以便对所有相关方产生良好的影响。
- en: '**You may be wondering, what does it mean to use these tools ethically?** You
    should use generative AI to help support people and bring a positive impact in
    their lives. There are use cases of people creating deepfakes that are hurtful
    to a person’s image, which is never okay. Additionally, generative AI should never
    be used to trick someone or change their thoughts with fake, untrue data. Today’s
    example is a perfect use case of how we can create data that will be used to train
    models for a company to understand the sentiment of customers'' reviews. It will
    help the company change its goods and processes to cater to the needs of the customer,
    positively impacting both parties!'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**你可能会想，这些工具的伦理使用意味着什么？** 你应该使用生成性人工智能来支持人们，并对他们的生活产生积极影响。有些人使用深度伪造技术来损害他人形象，这是绝对不可接受的。此外，生成性人工智能不应该被用来欺骗他人或用虚假的、不真实的数据改变他们的想法。今天的例子是一个完美的使用案例，展示了我们如何创建数据以训练模型，使公司理解客户评价的情感。这将帮助公司调整其产品和流程，以满足客户需求，从而对双方都产生积极影响！'
- en: '**If you enjoyed today’s reading, PLEASE give me a follow and let me know if
    there is another topic you would like me to explore! If you do not have a Medium
    account, sign up through my link** [**here**](https://ben-mccloskey20.medium.com/membership)
    **(I receive a small commission when you do this)! Additionally, add me on** [**LinkedIn**](https://www.linkedin.com/in/benjamin-mccloskey-169975a8/),
    **or feel free to reach out! Thanks for reading!**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你喜欢今天的阅读，请关注我，并告诉我是否有其他话题你希望我探讨！如果你没有Medium账户，可以通过我的链接** [**这里**](https://ben-mccloskey20.medium.com/membership)
    **注册（这样我会获得少量佣金）！另外，可以在** [**LinkedIn**](https://www.linkedin.com/in/benjamin-mccloskey-169975a8/)
    **上加我，或者随时联系我！感谢阅读！**'
- en: Sources
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来源
- en: Data usage approved by Altomontes Inc.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据使用经Altomontes Inc.批准
- en: '[Full code here](https://github.com/benmccloskey/food_industry)'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[完整代码请见这里](https://github.com/benmccloskey/food_industry)'
