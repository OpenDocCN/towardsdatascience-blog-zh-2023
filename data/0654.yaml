- en: Finding the Fastest Lane at Border Crossings Using Machine Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用机器视觉找到边境通行的最快车道
- en: 原文：[https://towardsdatascience.com/finding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3?source=collection_archive---------14-----------------------#2023-02-16](https://towardsdatascience.com/finding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3?source=collection_archive---------14-----------------------#2023-02-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/finding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3?source=collection_archive---------14-----------------------#2023-02-16](https://towardsdatascience.com/finding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3?source=collection_archive---------14-----------------------#2023-02-16)
- en: Optimizing border crossing with object detection and tracking
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化边境通行的目标检测与跟踪
- en: '[](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)[![Danilo
    Najkov](../Images/e0e8976f1f9f78ae58ba7efcc90a4f00.png)](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)
    [Danilo Najkov](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)[![Danilo
    Najkov](../Images/e0e8976f1f9f78ae58ba7efcc90a4f00.png)](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)
    [Danilo Najkov](https://medium.com/@danilo.najkov?source=post_page-----2e8dec6e03a3--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F19802d0e7d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&user=Danilo+Najkov&userId=19802d0e7d&source=post_page-19802d0e7d----2e8dec6e03a3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)
    ·12 min read·Feb 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e8dec6e03a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&user=Danilo+Najkov&userId=19802d0e7d&source=-----2e8dec6e03a3---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F19802d0e7d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&user=Danilo+Najkov&userId=19802d0e7d&source=post_page-19802d0e7d----2e8dec6e03a3---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2e8dec6e03a3--------------------------------)
    · 12分钟阅读·2023年2月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e8dec6e03a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&user=Danilo+Najkov&userId=19802d0e7d&source=-----2e8dec6e03a3---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e8dec6e03a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&source=-----2e8dec6e03a3---------------------bookmark_footer-----------)![](../Images/af3adda86dc5315b4d508bf6e84bc172.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e8dec6e03a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffinding-the-fastest-lane-at-border-crossings-using-machine-vision-2e8dec6e03a3&source=-----2e8dec6e03a3---------------------bookmark_footer-----------)![](../Images/af3adda86dc5315b4d508bf6e84bc172.png)'
- en: Generated image from the proposed solution of the [“Blace” border crossing camera](http://www.roads.org.mk/411/live-webcast)
    in North Macedonia (public domain)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从[“Blace”边境通行相机](http://www.roads.org.mk/411/live-webcast)（公有领域）生成的图像
- en: Crossing the border can be an exciting part of any road trip, but the frustration
    of long queues at border crossings can quickly take the excitement out of it.
    What if we could determine the fastest lane and position ourselves accordingly?
    Thanks to advancements in machine vision, this is now a possibility. By leveraging
    OpenCV and YOLOv3, a deep learning algorithm, it’s now possible to detect and
    track moving vehicles in real time. In this post, we’ll explore how this technology
    can be used to help people save time and avoid the stress of long queues at border
    crossings.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 穿越边境可以是任何公路旅行中的激动人心的部分，但在边境通行处排长队的挫败感会迅速消磨这种兴奋感。如果我们能确定最快的车道并相应地调整位置呢？感谢机器视觉的进步，这现在已经成为可能。通过利用OpenCV和YOLOv3（一个深度学习算法），现在可以实时检测和追踪移动的车辆。在这篇文章中，我们将探讨如何使用这些技术帮助人们节省时间，避免在边境通行处长时间排队的压力。
- en: '**Contents**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**内容**'
- en: Overview of the problem
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问题概述
- en: The data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据
- en: Object detection
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标检测
- en: – Car detection
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 汽车检测
- en: – Lane detection
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: – 车道检测
- en: Object tracking
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标追踪
- en: Orchestrating everything
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协调所有内容
- en: Limitations
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制
- en: Future work
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来工作
- en: Overview of the problem
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题概述
- en: 'The main idea of this task is to process the raw image data coming from border
    camera live streams to detect and track moving vehicles. The problem can be divided
    into several steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务的主要想法是处理来自边境摄像头实时流的原始图像数据，以检测和追踪移动的车辆。这个问题可以分为几个步骤：
- en: Get raw image data from the border cameras' livestream
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从边境摄像头的直播中获取原始图像数据
- en: Preprocess the image
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理图像
- en: Apply algorithms to find the location of the vehicles
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用算法来寻找车辆的位置
- en: Determine the lane for these vehicles
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定这些车辆的车道
- en: Apply algorithms to determine the speed of the vehicles (and in turn the speed
    of every lane)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用算法来确定车辆的速度（从而确定每条车道的速度）
- en: All of these steps are combined and orchestrated with docker-compose for running
    the solution on multiple border video streams.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些步骤都通过docker-compose结合起来，以便在多个边境视频流上运行解决方案。
- en: The data
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: The video data is sourced from border cameras that are open to the public. The
    solutions proposed here can be used on any live stream *(.m3u8)* of border/toll
    cameras and can be easily adapted for other forms of video. Nearly all the countries
    in the world have some sort of service that allows users to see the live conditions
    of border crossings. For this specific case, I used the live feeds of the cameras
    of my country. You can find the streams on this [link](http://www.roads.org.mk/315/video-kameri).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 视频数据来源于对公众开放的边境摄像头。这些解决方案可以应用于任何边境/收费站摄像头的实时流媒体 *(.m3u8)*，并且可以很容易地适应其他形式的视频。几乎所有国家都有某种服务，让用户能够查看边境通行的实时情况。在这个具体的案例中，我使用了我国家摄像头的实时视频流。你可以通过这个
    [链接](http://www.roads.org.mk/315/video-kameri) 找到这些视频流。
- en: Object detection
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标检测
- en: Before running any algorithms, we need to load the stream and preprocess the
    image. This can be easily done with OpenCV2\. I created a function that resizes
    the image to 416x416 pixels (the format required by the implementation of the
    YOLOv3 model I used)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行任何算法之前，我们需要加载视频流并对图像进行预处理。这可以通过OpenCV2轻松完成。我创建了一个将图像调整为416x416像素的函数（这是我使用的YOLOv3模型实现所要求的格式）。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In a while loop, images are loaded from the stream and are preprocessed using
    the above function. All the following changes will also be done in this while
    loop. Additionally, I check if something has changed from the previous frame,
    as it would be unnecessary to process the image again if nothing has changed.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个循环中，从流媒体中加载图像，并使用上述函数对其进行预处理。所有接下来的更改也将在这个循环中完成。此外，我检查是否与前一帧有所变化，因为如果没有变化，重新处理图像是没有必要的。
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Car detection
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汽车检测
- en: '![](../Images/ebf61150cc4e20d7e4497eca832d44a1.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebf61150cc4e20d7e4497eca832d44a1.png)'
- en: YOLOv3 architecture for detecting objects (credit to the original [YOLOv3 paper](https://arxiv.org/abs/1804.02767))
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv3架构用于检测对象（感谢原始 [YOLOv3 论文](https://arxiv.org/abs/1804.02767)）
- en: Now, we are all set for detecting vehicles in the image. I used YOLOv3 for getting
    the bounding boxes of all the classes that the model was trained on, but kept
    only the ones that are vehicles. The weights and configuration files are required
    for loading this model, and you can download them from the [official website](https://pjreddie.com/darknet/yolo/).
    This function returns the bounding boxes, the confidence of the model for the
    detected object, the class of the object (ex. car, truck, person, etc.), and the
    centers of each of the bounding boxes.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好在图像中检测车辆。我使用了YOLOv3来获取模型训练过的所有类别的边界框，但只保留了车辆的边界框。加载此模型需要权重和配置文件，你可以从[官方网站](https://pjreddie.com/darknet/yolo/)下载。这一函数返回边界框、模型对检测对象的置信度、对象的类别（如汽车、卡车、行人等），以及每个边界框的中心点。
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/6070fbf83d622be655a71e44de616777.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6070fbf83d622be655a71e44de616777.png)'
- en: The output of the algorithm before applying NMS on the [“Blace” border crossing
    camera](http://www.roads.org.mk/411/live-webcast) (public domain)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 算法在对[“Blace”边境检查摄像头](http://www.roads.org.mk/411/live-webcast)（公共领域）应用NMS之前的输出
- en: We have all the information about the bounding boxes, however, when we run the
    application we see that there are a lot of overlapping boxes that need to be removed.
    For this challenge, I used Non-Maximum Suppression (NMS). Non-Maximum Suppression
    (NMS) is a post-processing algorithm used in object detection tasks, specifically
    to remove redundant or overlapping bounding boxes for the same object.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有了关于边界框的所有信息，但是当我们运行应用程序时，发现有很多重叠的框需要去除。为了解决这个问题，我使用了非极大值抑制（NMS）。非极大值抑制（NMS）是一种后处理算法，用于对象检测任务，特别是用于去除同一对象的冗余或重叠的边界框。
- en: NMS is applied to filter out redundant bounding boxes and keep only the most
    appropriate ones. The basic idea behind NMS is to first sort the bounding boxes
    based on their detection confidence score (i.e., the probability that the bounding
    box contains an object). Starting with the bounding box with the highest confidence
    score, NMS suppresses all overlapping bounding boxes that have an Intersection
    over Union (IoU) value greater than a certain threshold (e.g., 0.5).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: NMS用于过滤冗余的边界框，只保留最合适的框。NMS的基本思路是首先根据检测置信度得分（即边界框包含对象的概率）对边界框进行排序。从置信度得分最高的边界框开始，NMS抑制所有交并比（IoU）值大于某个阈值（例如0.5）的重叠边界框。
- en: The following function performs this algorithm. It takes as parameters the bounding
    boxes, the confidence of the bounding boxes, and the threshold we want to filter
    out the duplicates. It returns the IDs of the boxes we need to keep.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数执行此算法。它的参数包括边界框、边界框的置信度和我们想要过滤掉重复项的阈值。它返回我们需要保留的框的ID。
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After using this algorithm, only one bounding box is retained per vehicle. You
    may need to adjust your threshold value to find what works for you.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个算法后，每辆车只保留一个边界框。你可能需要调整阈值以找到适合你的设置。
- en: Lane detection
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 车道检测
- en: 'While there are lane detection algorithms that could be effective for this
    task, they may not be the most efficient option. Since the cameras are fixed and
    lane positions don’t change, it would be a waste of processing time to use such
    algorithms. To address this, I saved the lane positions in a JSON file as a list
    of points. However, before determining the speed of the lanes, one additional
    challenge remains: identifying which lane each car is in.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有一些车道检测算法可能对这个任务有效，但它们可能不是最有效的选择。由于摄像头是固定的，车道位置不会变化，使用这些算法会浪费处理时间。为了解决这个问题，我将车道位置保存到了一个JSON文件中，作为点的列表。然而，在确定车道速度之前，还面临一个额外的挑战：识别每辆车所在的车道。
- en: For this, I created the following functions which find where each car is depending
    on its x-coordinate. It returns the index of the lane in which the car is. If
    the car is outside the lanes it returns -1.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我创建了以下函数，根据车辆的x坐标找到每辆车所在的位置。它返回车道的索引。如果车辆在车道之外，它返回-1。
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have everything ready to see the rate of change in each lane, by implementing
    object tracking.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好通过实施对象跟踪来查看每个车道的变化率。
- en: Object tracking
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象跟踪
- en: Object tracking is the process of locating a specific object or multiple objects
    in a video stream and following their movement over time. The goal of object tracking
    is to maintain the identity of the objects across successive frames of the video,
    despite changes in the object’s position, orientation, size, and appearance. Many
    object-tracking algorithms exist, but for this specific use case, I decided to
    use optical flow, as it works fairly well with streams with a lower frame rate.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 目标跟踪是定位视频流中一个或多个特定物体并跟踪其移动过程。目标跟踪的目标是在视频的连续帧中保持物体的身份，尽管物体的位置、方向、大小和外观可能发生变化。虽然存在许多目标跟踪算法，但对于这个特定的使用案例，我决定使用光流法，因为它在较低帧率的视频流中效果相当好。
- en: Optical flow is a technique that involves analyzing the changes in the intensity
    of adjacent pixels in successive video frames to determine the direction and speed
    of movement of objects in the scene. Optical flow algorithms rely on the assumption
    that the brightness of a pixel in one frame is the same as its corresponding pixel
    in the next frame, allowing for the calculation of the displacement of objects
    between frames.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 光流法是一种技术，通过分析相邻像素在连续视频帧中的强度变化来确定场景中物体的运动方向和速度。光流算法依赖于一个假设，即一个帧中的像素亮度与下一个帧中对应像素的亮度相同，从而允许计算物体在帧之间的位移。
- en: This algorithm is much more complicated, so I will not be explaining it in detail.
    As parameters, it takes the image and previous image, the centers of the cars
    from the YOLOv3 model, the lanes to determine if the movement is happening in
    each lane, and cars in lanes to see if the movement is a result of vehicle movement
    or other factors. It returns a list of speeds for each lane.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法要复杂得多，所以我不会详细解释。作为参数，它接收图像和前一图像、YOLOv3模型中的汽车中心、车道以确定是否有运动发生在每个车道中，以及车道中的汽车以查看运动是否是由车辆运动或其他因素引起的。它返回每个车道的速度列表。
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The output of the optical flow algorithm is saved and compared to the output
    of the previous frame. If there is a significant change in the optical flow values
    for each lane, it is recorded as 1 movement point. This is implemented in the
    following function.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 光流算法的输出被保存并与前一帧的输出进行比较。如果每个车道的光流值发生显著变化，则记录为1个移动点。这在以下函数中实现。
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now that everything is implemented, we can visualize the results. This function
    shows the image with the bounding boxes of each car, and lanes of traffic, and
    prints the speed of lanes in the console.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一切都已实现，我们可以可视化结果。这个功能显示带有每辆车的边界框的图像、交通车道，并在控制台打印车道的速度。
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: After running everything in the main while loop, we get the following video.
    The program outputs that the second lane (lane 2) had the most movement and therefore
    is the fastest.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在主循环中运行一切后，我们得到以下视频。程序输出显示第二车道（车道2）的移动最多，因此速度最快。
- en: '![](../Images/8dc09007c977a239ce532419064c2ab8.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8dc09007c977a239ce532419064c2ab8.png)'
- en: Sped up GIF of around 3 minutes of border footage from the [“Blace” border crossing](http://www.roads.org.mk/411/live-webcast)
    (public domain)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[“Blace”边界穿越](http://www.roads.org.mk/411/live-webcast)的约3分钟加速GIF（公共领域）'
- en: Orchestrating everything
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协调整个过程
- en: Although the algorithm is complete for detecting and tracking vehicles in a
    single border crossing, I wanted to extend the solution to work across multiple
    crossings while still saving the results of speed. To achieve this, I decided
    to run each border camera script as a separate container that communicates within
    a docker-compose. Since running a separate instance of the YOLOv3 model for each
    camera would be inefficient, I created a separate container with a flask app that
    serves the other containers. However, to ensure that multiple requests don’t use
    the same neural network simultaneously, it’s important to incorporate semaphores
    or other locking mechanisms.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个算法对于检测和跟踪单一边界穿越中的车辆已经完整，我希望将解决方案扩展到多个边界穿越，同时仍然保存速度结果。为实现这一目标，我决定将每个边界摄像头脚本作为一个独立的容器运行，该容器在docker-compose中进行通信。由于为每个摄像头运行单独的YOLOv3模型效率低下，我创建了一个带有flask应用程序的独立容器，用于服务其他容器。然而，为了确保多个请求不会同时使用相同的神经网络，重要的是要采用信号量或其他锁定机制。
- en: In addition, I developed a .Net web API that saves the speeds and cars in each
    lane to a database. It is out of this post’s scope to include the full code here,
    but you can find it on my [GitHub repository](https://github.com/dani2221/bordercount).
    With this implementation, the solution can be deployed to multiple border crossings,
    and the resulting data can be efficiently collected and analyzed, providing valuable
    insights into traffic patterns and congestion at different locations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我开发了一个 .Net 网络 API，用于将每条车道的速度和汽车保存到数据库中。由于篇幅限制，这里无法包含完整的代码，但你可以在我的 [GitHub
    仓库](https://github.com/dani2221/bordercount) 中找到它。通过这种实现，该解决方案可以部署到多个边境检查点，生成的数据可以高效地收集和分析，为不同地点的交通模式和拥堵情况提供有价值的见解。
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Limitations
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制
- en: While our algorithm has proven to be highly effective, it is important to acknowledge
    its limitations. Firstly, YOLOv3, the object detection model I utilized, is less
    accurate in low-light conditions, such as at night. As a result, the number of
    vehicles detected will be significantly lower, potentially leading to incorrect
    assumptions about traffic volume. Additionally, the model struggles to detect
    objects at long distances, meaning that there is a cap on the number of vehicles
    that can be detected in long queues.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的算法已被证明非常有效，但重要的是要承认它的局限性。首先，我使用的目标检测模型 YOLOv3 在低光条件下（如夜间）的准确性较差。因此，检测到的车辆数量会显著减少，这可能导致对交通量的错误判断。此外，该模型在长距离检测物体时存在困难，这意味着在长队中可以检测到的车辆数量有限。
- en: Furthermore, it’s important to consider that border crossings can vary significantly
    in design. While the majority of borders may follow a similar layout, there are
    some with more complex features, such as curved lanes and additional barriers.
    These variations can render the algorithm unusable in certain scenarios. It’s
    worth noting that further development and optimization could potentially address
    these limitations, but for now, it’s essential to take these factors into account
    when implementing our solution.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑到边境检查点的设计可以有很大的差异也很重要。虽然大多数边境检查点可能遵循类似的布局，但也有一些具有更复杂特征，例如弯曲车道和额外障碍物。这些变化可能会导致算法在某些情况下无法使用。值得注意的是，进一步的开发和优化可能会解决这些限制，但目前在实施我们的解决方案时必须考虑这些因素。
- en: '![](../Images/2541e9469d4106cdb12d15f8d2a37f77.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2541e9469d4106cdb12d15f8d2a37f77.png)'
- en: Example border checkpoint from the [“Tabanovce” crossing](http://www.roads.org.mk/411/live-webcast)
    (public domain) where the lane speed algorithm cannot be used.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[“Tabanovce” 检查点](http://www.roads.org.mk/411/live-webcast)（公共领域）中无法使用车道速度算法的示例边境检查点。'
- en: Future work
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来工作
- en: While this solution provides an effective means of determining vehicle speed
    and traffic congestion at border checkpoints, there is still room for improvement.
    One area for future work is to explore other object detection models to see if
    they offer improved accuracy in low-light conditions or when detecting objects
    at longer distances.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个解决方案提供了一种有效的方式来确定边境检查点的车辆速度和交通拥堵情况，但仍有改进的空间。未来工作的一个方向是探索其他目标检测模型，看看它们在低光条件下或在检测远距离物体时是否能提供更好的准确性。
- en: Additionally, it may be useful to investigate the feasibility of implementing
    this algorithm at border crossings with more complex layouts. This could involve
    developing new algorithms to address the challenges posed by curved lanes, additional
    barriers, or other features unique to those crossings.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，调查在布局更复杂的边境检查点实施该算法的可行性也可能是有益的。这可能涉及开发新的算法，以应对弯曲车道、额外障碍物或其他特征带来的挑战。
- en: Furthermore, the current solution could be extended to incorporate machine learning
    techniques that could adapt to changing traffic patterns over time. By training
    the model on data collected over an extended period, it could potentially learn
    to adjust its parameters based on traffic conditions, improving its accuracy and
    reliability over time.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，目前的解决方案可以扩展到结合机器学习技术，以适应随时间变化的交通模式。通过对长期收集的数据进行训练，模型可能会学会根据交通状况调整其参数，从而随着时间的推移提高其准确性和可靠性。
- en: Finally, it may be possible to integrate data from other sources, such as social
    media or traffic cameras, to provide a more comprehensive understanding of traffic
    patterns at border crossings. By incorporating data from a range of sources, it
    may be possible to find correlations between traffic patterns and external factors,
    such as weather or public events, providing valuable insights for traffic management
    and future planning. This data can help people better plan their trips, by setting
    departure times in which there is the least expected traffic.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可以考虑整合来自其他来源的数据，如社交媒体或交通摄像头，以提供对边境检查点交通模式的更全面理解。通过结合来自各种来源的数据，可能会发现交通模式与外部因素（如天气或公共事件）之间的关联，为交通管理和未来规划提供有价值的见解。这些数据可以帮助人们更好地规划出行，设置最少预期交通的出发时间。
- en: Conclusion
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In conclusion, by using machine vision algorithms, we have developed an effective
    solution for determining vehicle speed and traffic volume at border crossings.
    You can experiment with the code on [GitHub](https://github.com/dani2221/bordercount)
    and try what results you get with the border crossings near you. Thank you for
    reading!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，通过使用机器视觉算法，我们已经开发出了一种有效的解决方案来确定边境检查点的车辆速度和交通流量。你可以在[GitHub](https://github.com/dani2221/bordercount)上试验代码，并尝试查看你附近边境检查点的结果。感谢你的阅读！
