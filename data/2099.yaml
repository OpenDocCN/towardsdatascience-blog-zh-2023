- en: Visualizing the True Extent of the Curse of Dimensionality
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 直观地展示维度诅咒的真实程度
- en: 原文：[https://towardsdatascience.com/visualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb?source=collection_archive---------6-----------------------#2023-06-29](https://towardsdatascience.com/visualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb?source=collection_archive---------6-----------------------#2023-06-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/visualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb?source=collection_archive---------6-----------------------#2023-06-29](https://towardsdatascience.com/visualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb?source=collection_archive---------6-----------------------#2023-06-29)
- en: Using the Monte Carlo method to visualize the behavior of observations with
    very large numbers of features
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用蒙特卡洛方法来直观展示具有非常多特征的观察值的行为
- en: '[](https://florin-andrei.medium.com/?source=post_page-----5556ff6852bb--------------------------------)[![Florin
    Andrei](../Images/372ac3e80dbc03cbd20295ec1df5fa6f.png)](https://florin-andrei.medium.com/?source=post_page-----5556ff6852bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5556ff6852bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5556ff6852bb--------------------------------)
    [Florin Andrei](https://florin-andrei.medium.com/?source=post_page-----5556ff6852bb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://florin-andrei.medium.com/?source=post_page-----5556ff6852bb--------------------------------)[![Florin
    Andrei](../Images/372ac3e80dbc03cbd20295ec1df5fa6f.png)](https://florin-andrei.medium.com/?source=post_page-----5556ff6852bb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5556ff6852bb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5556ff6852bb--------------------------------)
    [Florin Andrei](https://florin-andrei.medium.com/?source=post_page-----5556ff6852bb--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faeaeb9d7d248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb&user=Florin+Andrei&userId=aeaeb9d7d248&source=post_page-aeaeb9d7d248----5556ff6852bb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5556ff6852bb--------------------------------)
    ·10 min read·Jun 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5556ff6852bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb&user=Florin+Andrei&userId=aeaeb9d7d248&source=-----5556ff6852bb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faeaeb9d7d248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb&user=Florin+Andrei&userId=aeaeb9d7d248&source=post_page-aeaeb9d7d248----5556ff6852bb---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5556ff6852bb--------------------------------)
    ·10 min read·2023年6月29日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5556ff6852bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb&user=Florin+Andrei&userId=aeaeb9d7d248&source=-----5556ff6852bb---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5556ff6852bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb&source=-----5556ff6852bb---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5556ff6852bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvisualizing-the-full-extent-of-the-curse-of-dimensionality-5556ff6852bb&source=-----5556ff6852bb---------------------bookmark_footer-----------)'
- en: Think of a dataset, made of some number of observations, each observation having
    N features. If you convert all features to a numeric representation, you could
    say that each observation is a point in an N-dimensional space.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个数据集，由若干观察值组成，每个观察值都有 N 个特征。如果你将所有特征转换为数值表示，你可以说每个观察值是在一个 N 维空间中的一个点。
- en: When N is low, the relationships between points are just what you would expect
    intuitively. But sometimes N grows very large — this could happen, for example,
    if you’re creating a lot of features via one-hot encoding, etc. For very large
    values of N, observations behave as if they are sparse, or as if the distances
    between them are somehow bigger than what you would expect.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当 N 较低时，点之间的关系就是你直观上所期望的样子。但有时 N 会变得非常大——例如，如果你通过独热编码创建了很多特征等。在 N 的非常大值下，观察值的行为就像是稀疏的，或者它们之间的距离比你期望的要大。
- en: The phenomenon is real. As the number of dimensions N grows, and all else stays
    the same, the N-volume containing your observations really does increase in a
    sense (or at least the number of degrees of freedom becomes larger), and the Euclidian
    distances between observations also increase. The group of points actually does
    become more sparse. This is the geometric basis for [the curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality).
    The behavior of the models and techniques applied to the dataset will be influenced
    as a consequence of these changes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个现象是真实的。随着维度 N 的增加，而其他条件保持不变，包含你观察的 N-体积确实会在某种意义上增加（或者至少自由度变得更大），观察之间的欧几里得距离也会增加。点的分布实际上会变得更加稀疏。这是[维度诅咒](https://en.wikipedia.org/wiki/Curse_of_dimensionality)的几何基础。模型和技术在数据集上的表现会受到这些变化的影响。
- en: 'Many things can go wrong if the number of features is very large. Having more
    features than observations is a typical setup for models overfitting in training.
    Any brute-force search in such a space (e.g. GridSearch) becomes less efficient
    — you need more trials to cover the same linear interval limits. A subtle effect
    has an impact on any models based on distance or vicinity: **as the number of
    dimensions grows to some very large values, if you consider any point in your
    observations, all the other points appear to be far away and somehow nearly equidistant**
    — since these models rely on distance to do their job, the leveling out of differences
    of distance makes their job harder. E.g. clustering doesn’t work as well if all
    points appear to be nearly equidistant.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果特征数量非常大，很多事情可能会出错。特征比观察值多是模型在训练中过拟合的典型设置。在这样的空间中进行任何暴力搜索（例如 GridSearch）变得效率更低——你需要更多的试验才能覆盖相同的线性区间限制。一个微妙的效应会影响任何基于距离或邻近度的模型：**随着维度的增长到非常大的值，如果你考虑观察中的任何一点，所有其他点似乎都远离，并且几乎是等距离的**——由于这些模型依赖于距离来完成工作，距离差异的平衡使得它们的工作变得更加困难。例如，如果所有点似乎几乎等距离，聚类效果不会很好。
- en: For all these reasons, and more, techniques such as PCA, LDA, etc. have been
    created — in an effort to move away from the peculiar geometry of spaces with
    very many dimensions, and to distill the dataset down to a number of dimensions
    more compatible with the actual information contained in it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 出于这些原因，还有更多原因，创建了诸如 PCA、LDA 等技术——旨在远离具有非常多维度的空间的特殊几何，并将数据集精炼到与其中实际信息更兼容的维度数。
- en: It is hard to perceive intuitively the true magnitude of this phenomenon, and
    spaces with more than 3 dimensions are extremely challenging to visualize, so
    let’s do some simple 2D visualizations to help our intuition. There is a geometric
    basis for the reason why dimensionality can become a problem, and this is what
    we will visualize here. If you have not seen this before, the results might be
    surprising — the geometry of high-dimensional spaces is far more complex than
    the typical intuition is likely to suggest.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上很难感知这个现象的真正规模，而超过 3 维的空间极其难以可视化，因此我们来做一些简单的 2D 可视化来帮助我们的直觉。维度如何成为问题的几何基础就是我们要在这里可视化的内容。如果你以前没有见过这些结果，可能会感到惊讶——高维空间的几何远比典型直觉所能建议的要复杂得多。
- en: Volume
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 体积
- en: Consider a square of size 1, centered in the origin. In the square, you inscribe
    a circle.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个大小为 1 的正方形，位于原点。然后在正方形中内切一个圆。
- en: '![](../Images/8b6fe37824cfcf1ab8b63ff554720d6d.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b6fe37824cfcf1ab8b63ff554720d6d.png)'
- en: a circle inscribed in a square
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个内切于正方形的圆
- en: That is the setup in 2 dimensions. Now think in the general, N-dimensional case.
    In 3 dimensions, you have a sphere inscribed in a cube. Beyond that, you have
    an N-sphere inscribed in an N-cube, which is the most general way to put it. For
    simplicity, we will refer to these objects as “sphere” and “cube”, no matter how
    many dimensions they have.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 2 维的设置。现在考虑一般的 N 维情况。在 3 维中，你有一个内切于立方体的球体。再往上，你有一个内切于 N-立方体的 N-球体，这是最一般的描述方式。为了简化，我们将这些对象称为“球体”和“立方体”，不论它们有多少维度。
- en: 'The volume of the cube is fixed, it’s always 1\. The question is: as the number
    of dimensions N varies, what happens to the volume of the sphere?'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 立方体的体积是固定的，总是 1。问题是：当维度 N 变化时，球体的体积会发生什么？
- en: Let’s answer the question experimentally, using the Monte Carlo method. We will
    generate a very large number of points, distributed uniformly but randomly within
    the cube. For each point we calculate its distance to the origin — if that distance
    is less than 0.5 (the radius of the sphere), then the point is inside the sphere.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过实验来回答这个问题，使用蒙特卡洛方法。我们将生成大量点，这些点在立方体内均匀但随机分布。对于每个点，我们计算它到原点的距离——如果该距离小于0.5（球体的半径），那么这个点就在球体内部。
- en: '![](../Images/9a920335608732f55f26e419c8ac29a1.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a920335608732f55f26e419c8ac29a1.png)'
- en: random points
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 随机点
- en: If we divide the number of points inside the sphere by the total number of points,
    that will approximate the ratio of the volume of the sphere and of the volume
    of the cube. Since the volume of the cube is 1, the ratio will be equal to the
    volume of the sphere. The approximation gets better when the total number of points
    is large.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将球体内部的点数除以总点数，这将近似球体体积和立方体体积的比例。由于立方体的体积为1，比例将等于球体的体积。当总点数较大时，近似值会更好。
- en: In other words, the ratio `inside_points / total_points` will approximate the
    volume of the sphere.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，比例`inside_points / total_points`将近似球体的体积。
- en: 'The code is rather straightforward. Since we need many points, explicit loops
    must be avoided. We could use NumPy, but it’s CPU-only and single-threaded, so
    it will be slow. Potential alternatives: CuPy (GPU), Jax (CPU/GPU), PyTorch (CPU/GPU),
    etc. We will use PyTorch — but the NumPy code would look almost identical.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 代码相当直接。由于我们需要很多点，必须避免显式循环。我们可以使用NumPy，但它仅支持CPU并且是单线程的，因此速度较慢。潜在的替代方案：CuPy（GPU）、Jax（CPU/GPU）、PyTorch（CPU/GPU）等。我们将使用PyTorch——但NumPy代码看起来几乎相同。
- en: If you follow the nested `torch` statements, we generate 100 million random
    points, calculate their distances to the origin, count the points inside the sphere,
    and divide the count by the total number of points. The `ratio` array will end
    up containing the volume of the sphere in different numbers of dimensions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你跟随嵌套的`torch`语句，我们生成1亿个随机点，计算它们到原点的距离，统计在球体内的点数，并将点数除以总点数。`ratio`数组将包含不同维度中球体的体积。
- en: The tunable parameters are set for a GPU with 24 GB of memory — adjust them
    if your hardware is different.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可调参数设置为24 GB内存的GPU——如果你的硬件不同，请调整这些参数。
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s visualize the results:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来可视化结果：
- en: '![](../Images/dd4cefdc66a1d4bb48ed82fe7039e87b.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd4cefdc66a1d4bb48ed82fe7039e87b.png)'
- en: the volume of the sphere
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 球体的体积
- en: 'N=1 is trivial: both the “sphere” and the “cube” are just linear segments,
    and they are equal, so the “volume” of the “sphere” is 1\. For N=2 and N=3, you
    should remember the results from high school geometry, and notice that this simulation
    is very close to the exact values.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: N=1是简单的：“球体”和“立方体”都是线段，它们是相等的，所以“球体”的“体积”是1。对于N=2和N=3，你应该记住高中几何的结果，并注意到这个模拟非常接近实际值。
- en: 'But as N increases, something very dramatic happens: the volume of the sphere
    drops like a stone. It is already close to 0 when N=10, and it falls below the
    floating point precision of this simulation shortly after N=20 or so. Beyond that
    point, the code calculates the volume of the sphere to be 0.0 (it’s just an approximation).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但随着N的增加，会发生非常戏剧性的变化：球体的体积急剧下降。当N=10时，它已经接近0，并且在N约为20之后，它会低于此模拟的浮点精度。超过这一点，代码计算球体的体积为0.0（这只是一个近似值）。
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'One interpretation: for large values of N, almost the whole volume of the cube
    is located in the corners. The central region, containing the sphere, becomes
    insignificant in comparison. In high-dimensional spaces, the corners become very
    important. Most of the volume “migrates” into the corners. This happens extremely
    fast as N rises.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解释是：对于较大的N值，几乎整个立方体的体积都集中在角落中。与之相比，包含球体的中心区域变得微不足道。在高维空间中，角落变得非常重要。大部分体积“迁移”到角落。这种变化随着N的增加极其迅速。
- en: 'Another way to look at it: the sphere is the “vicinity” of the origin. **As
    N increases, the points simply disappear from that vicinity. The origin is not
    really all that special, so what happens to its vicinity, must happen to all vicinities
    everywhere.** The very notion of “vicinity” undergoes a big change. Neighborhoods
    empty out along with the rise of N.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种看法：球体是原点的“邻域”。**随着N的增加，点会从那个邻域中消失。原点实际上并没有特别之处，因此原点的邻域发生的情况，必须发生在所有邻域中。**
    “邻域”的概念经历了巨大的变化。随着N的增加，邻域会变得空旷。
- en: 'I’ve run this simulation for the first time years ago, and I vividly remember
    how shocking this result was — how quickly the volume of the sphere dive-bombs
    into 0 as N rises. After checking the code and not finding any errors in it, my
    reaction was: save the work, lock the screen, go outside, take a walk, and think
    about what you’ve just seen. :)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我几年前第一次运行了这个模拟，我清楚地记得这个结果是多么震惊——当N增加时，球体的体积迅速下降到0。检查代码后没有发现错误，我的反应是：保存工作，锁定屏幕，出去散步，思考刚才看到的内容。:)
- en: Linear distance
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性距离
- en: 'Let’s calculate the diagonal of the cube as a function of N. This is trivial,
    since the diagonal is literally `sqrt(N)` so the code is too simple to include
    here. And these are the results:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算立方体的对角线作为N的函数。这是很简单的，因为对角线实际上是`sqrt(N)`，所以代码过于简单，不需要在这里展示。这些是结果：
- en: '![](../Images/a303448442a17f6edf0c4778908dab25.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a303448442a17f6edf0c4778908dab25.png)'
- en: length of diagonal
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对角线长度
- en: Again, for N=2 and N=3 you should recognize the results from geometry (the diagonal
    of the square and of the normal 3-cube). But as N increases, the diagonal also
    increases, and its growth is unbound.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，对于N=2和N=3，你应该能从几何学中识别出结果（正方形和普通三维立方体的对角线）。但随着N的增加，对角线也会增加，其增长是无限的。
- en: This may sound very counterintuitive, but even as the size of the edge of the
    cube remains constant (and equal to 1), its diagonal can grow arbitrarily large,
    as you increase N. Already for N=1000, the diagonal length is around 32\. In theory,
    if the edge of the cube is 1 meter, there will be a space with very many dimensions
    where the diagonal of the cube will be 1 kilometer long.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能听起来非常违反直觉，但即使立方体的边长保持不变（等于1），其对角线也可以随着N的增加而无限变大。已经对于N=1000，对角线长度约为32。如果立方体的边长是1米，那么在非常多维度的空间中，立方体的对角线长度将达到1公里。
- en: '**Even as the distance along the edge remains the same, the diagonal just keeps
    growing unbound, along with the number of dimensions.**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**即使沿边的距离保持不变，对角线也会无限增长，与维度数量一起增长。**'
- en: Every time a new dimension is added to the space, more edges, faces, etc. pop
    into existence, the configuration of the corner region becomes more complex, having
    more degrees of freedom, and the diagonal will measure a bit longer.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每次向空间中添加一个新维度时，更多的边、面等就会出现，角落区域的配置变得更加复杂，具有更多的自由度，对角线的测量会稍微长一点。
- en: Distances between observations
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 观测之间的距离
- en: How about distances between observations or points? Let’s say we generate a
    fixed number of random points, and then we calculate the average distance between
    any two points, and the average distance to the nearest neighbor of any point.
    All points are always contained in the cube. What happens to the average distances
    as N increases? Let’s run another simulation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 观测点或点之间的距离怎么样？假设我们生成固定数量的随机点，然后计算任意两个点之间的平均距离，以及任何点到最近邻居的平均距离。所有点始终都包含在立方体中。随着N的增加，平均距离会发生什么变化？让我们再运行一次模拟。
- en: Please note the conservative approach to memory management. This is important,
    since the data structures used here are quite large.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意内存管理的保守方法。这很重要，因为这里使用的数据结构相当大。
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We use far fewer points here (only 1000) because the size of the main data structures
    increases with `N^2`, so we would run out of memory very quickly if we generate
    too many points. Even so, the approximate results should be close enough to the
    actual values.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的点数远少于此（仅1000个），因为主要数据结构的大小随着`N^2`增加，因此如果生成太多点，我们很快就会耗尽内存。即便如此，近似结果应该足够接近实际值。
- en: 'This is the average distance between any two points, out of 1000, as a function
    of N:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是任何两个点之间的平均距离，基于1000个点，作为N的函数：
- en: '![](../Images/e4d51d670fa79194823529fd7af6831f.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4d51d670fa79194823529fd7af6831f.png)'
- en: average distance between points
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 点之间的平均距离
- en: For small values of N, the average distance is something like 0.5, or 1\. But
    as N increases, the average distance starts growing, and it’s already close to
    18 when N=2000\. The increase is substantial.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小的N值，平均距离大约是0.5或1。然而，随着N的增加，平均距离开始增长，当N=2000时已经接近18。增长是显著的。
- en: 'This is the average distance to the nearest neighbor, as a function of N:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是到最近邻居的平均距离，作为N的函数：
- en: '![](../Images/f1c62f40d60fc4965ee150a5a27876e2.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1c62f40d60fc4965ee150a5a27876e2.png)'
- en: average distance to the nearest neighbor
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 到最近邻居的平均距离
- en: The increase here is even more dramatic, as the values are quite tiny when N
    is below 10 and the points are crowded together in a low-dimensional space. For
    large values of N, the average distance to the nearest neighbor gets actually
    close to the average distance between any two points — in other words, the emptiness
    of the immediate vicinity dominates the measurements.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 增加的效果更为显著，因为当 N 低于 10 时，值相当微小，点在低维空间中挤在一起。对于大的 N 值，最近邻的平均距离实际上接近任何两个点之间的平均距离——换句话说，临近空旷的情况主导了测量结果。
- en: '![](../Images/24558a913cd3b5351f95d1d2fb4794a8.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24558a913cd3b5351f95d1d2fb4794a8.png)'
- en: distance ratios
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 距离比率
- en: This is why we said at the beginning that **points become nearly equidistant
    in high-dimensional spaces** — average distances and shortest distances become
    nearly the same. Here you have proof of it from the simulation, and an intuition
    for the strength of the phenomenon.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么我们一开始说**在高维空间中点变得几乎等距**——平均距离和最短距离变得几乎相同。这里有来自模拟的证据，以及对现象强度的直观理解。
- en: As the number of dimensions N increases, all points recede away from each other,
    even though their coordinates are confined to the same narrow range (-0.5, +0.5).
    The group of points effectively gets more and more sparse by simply creating more
    dimensions. The increase spans a couple of orders of magnitude when dimensions
    increase from a few units to a few thousand. It’s a very large increase.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 随着维度 N 的增加，所有点彼此逐渐远离，即使它们的坐标被限制在相同的狭窄范围（-0.5, +0.5）。通过仅仅增加更多维度，点的群体变得越来越稀疏。当维度从几单位增加到几千单位时，这种增加跨度达到几个数量级。这是一个非常大的增加。
- en: Conclusions
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The curse of dimensionality is a real phenomenon, with a basis in the geometry
    of N-dimensional spaces.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 维度诅咒是一个真实的现象，其基础在于 N 维空间的几何。
- en: All else being equal, as you increase the number of dimensions (or features),
    the points (or observations) move away from each other quickly. There’s effectively
    more room in there, even though linear intervals along axes are the same. All
    vicinities empty out, and each point ends up sitting alone in a high-dimensional
    space.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他条件相同的情况下，当你增加维度（或特征）数量时，点（或观测值）会迅速远离彼此。实际上，虽然轴上的线性间隔保持不变，但这里的空间变得更大了。所有邻域都变得空旷，每个点最终都孤立地坐在一个高维空间中。
- en: This should provide some intuition for the fact that some techniques (clustering,
    various models, etc.) behave differently when the number of features changes substantially.
    Few observations, combined with a large number of features, may lead to sub-optimal
    results — and while the curse of dimensionality is not the only reason for that,
    it can be one of the reasons.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该提供一些直观的理解，即一些技术（如聚类、各种模型等）在特征数量大幅变化时表现不同。少量观测值结合大量特征可能会导致次优结果——尽管维度诅咒不是唯一原因，但它可能是原因之一。
- en: Generally speaking, the number of observations should “keep up” with the number
    of features — the exact rules here depend on many factors.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，观测值的数量应该“跟上”特征的数量——具体规则依赖于许多因素。
- en: If nothing else, this article should provide an intuitive overview of the properties
    of high-dimensional spaces, which are difficult to visualize. Some of the trends
    are shockingly strong, and now you should have some idea of just how strong they
    are.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有其他，这篇文章应该提供了一个对高维空间特性的直观概述，这些特性难以可视化。一些趋势极为强烈，现在你应该对它们的强度有一些了解。
- en: 'All code used in this article is here:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的所有代码都在这里：
- en: '[](https://github.com/FlorinAndrei/misc/blob/master/curse_dimensionality_article/n_sphere.ipynb?source=post_page-----5556ff6852bb--------------------------------)
    [## misc/curse_dimensionality_article/n_sphere.ipynb at master · FlorinAndrei/misc'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/FlorinAndrei/misc/blob/master/curse_dimensionality_article/n_sphere.ipynb?source=post_page-----5556ff6852bb--------------------------------)
    [## misc/curse_dimensionality_article/n_sphere.ipynb 在 master · FlorinAndrei/misc'
- en: random stuff. Contribute to FlorinAndrei/misc development by creating an account
    on GitHub.
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机内容。通过在 GitHub 上创建一个账户来贡献于 FlorinAndrei/misc 的开发。
- en: github.com](https://github.com/FlorinAndrei/misc/blob/master/curse_dimensionality_article/n_sphere.ipynb?source=post_page-----5556ff6852bb--------------------------------)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/FlorinAndrei/misc/blob/master/curse_dimensionality_article/n_sphere.ipynb?source=post_page-----5556ff6852bb--------------------------------)
- en: All images used in this article are created by the author (see the code link
    above).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的所有图像都是作者创作的（见上面的代码链接）。
