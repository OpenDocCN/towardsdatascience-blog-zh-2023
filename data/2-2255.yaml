- en: Use the Partitions, Luke! A Simple and Proven Way to Optimise Your SQL Queries
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分区，卢克！一个简单且经过验证的优化 SQL 查询的方法
- en: 原文：[https://towardsdatascience.com/use-the-partitions-luke-a-simple-and-proven-way-to-optimise-your-sql-queries-43e24ea4c5d0](https://towardsdatascience.com/use-the-partitions-luke-a-simple-and-proven-way-to-optimise-your-sql-queries-43e24ea4c5d0)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/use-the-partitions-luke-a-simple-and-proven-way-to-optimise-your-sql-queries-43e24ea4c5d0](https://towardsdatascience.com/use-the-partitions-luke-a-simple-and-proven-way-to-optimise-your-sql-queries-43e24ea4c5d0)
- en: If you’ve ever written an SQL query that takes ages to run, this is the article
    for you
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果你曾写过一个需要很长时间才能运行的 SQL 查询，那么这篇文章就是为你准备的。
- en: '[](https://medium.com/@mattchapmanmsc?source=post_page-----43e24ea4c5d0--------------------------------)[![Matt
    Chapman](../Images/7511deb8d9ed408ece21031f6614c532.png)](https://medium.com/@mattchapmanmsc?source=post_page-----43e24ea4c5d0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43e24ea4c5d0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43e24ea4c5d0--------------------------------)
    [Matt Chapman](https://medium.com/@mattchapmanmsc?source=post_page-----43e24ea4c5d0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mattchapmanmsc?source=post_page-----43e24ea4c5d0--------------------------------)[![Matt
    Chapman](../Images/7511deb8d9ed408ece21031f6614c532.png)](https://medium.com/@mattchapmanmsc?source=post_page-----43e24ea4c5d0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43e24ea4c5d0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43e24ea4c5d0--------------------------------)
    [Matt Chapman](https://medium.com/@mattchapmanmsc?source=post_page-----43e24ea4c5d0--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43e24ea4c5d0--------------------------------)
    ·8 min read·Dec 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43e24ea4c5d0--------------------------------)
    ·8 分钟阅读·2023年12月7日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/caa41d8a1a68733fba112f4270c57c15.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/caa41d8a1a68733fba112f4270c57c15.png)'
- en: Baby Yoda loves partitions. Do you? Image by [Victor Serban](https://unsplash.com/@victorserban)
    on [Unsplash](https://unsplash.com/photos/green-frog-plush-toy-on-brown-textile-ZFN6UNWhstI)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 宝宝尤达喜欢分区。你呢？图片由 [Victor Serban](https://unsplash.com/@victorserban) 提供，来源于 [Unsplash](https://unsplash.com/photos/green-frog-plush-toy-on-brown-textile-ZFN6UNWhstI)
- en: Data Scientists love SQL, but boy do we suck at writing performant queries (maybe
    because we spent too much time debating whether it’s pronounced “S-Q-L” or “sequel”?).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家们喜欢 SQL，但我们确实很糟糕于编写高性能的查询（也许是因为我们花了太多时间争论“SQL”是读作“S-Q-L”还是“sequel”？）。
- en: In this article, I’m going to show you how to use ***SQL partitions*** to optimise
    your queries and write code that’s quicker and cheaper to run. If you’ve mastered
    the basics of SQL and want to start unlocking higher-level Data Science skills,
    this will be a great addition to your toolkit.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将向你展示如何使用 ***SQL 分区*** 来优化你的查询，并编写更快速、更便宜的代码。如果你已经掌握了 SQL 的基础知识，并希望开始解锁更高级的数据科学技能，这将是你工具箱中的一个很棒的补充。
- en: What’s a partitioned table?
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是分区表？
- en: A partitioned table is a table that’s divided into segments/partitions (who
    saw that coming?).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分区表是将数据表划分为多个段/分区的表（谁能想到呢？）。
- en: In a partitioned table, each segment is stored in a different location on the
    server. This is different from a normal (unpartitioned) SQL table, where the entire
    table sits in a single location.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在分区表中，每个分区存储在服务器上的不同位置。这与普通（未分区）SQL 表不同，后者整个表位于一个位置。
- en: 'Here’s a comparison using dummy data about the daily sales of three of my favourite
    books:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用虚拟数据对比了我最喜欢的三本书的每日销售情况：
- en: '![](../Images/c80814445de2097c783f0c0e84481128.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c80814445de2097c783f0c0e84481128.png)'
- en: Image by author
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Both the unpartitioned and the partitioned table hold the same data; the only
    difference is that the partitioned table splits the data into different segments.
    It’s still a single table (i.e. it’s not three separate tables); it’s just storing
    the data in a different way.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 未分区表和分区表都包含相同的数据；唯一的区别是分区表将数据分成不同的段。它仍然是一个单一的表（即它不是三个单独的表）；只是以不同的方式存储数据。
- en: Why should we care? Well, as we’ll see shortly, we can take advantage of this
    structure to write more efficient SQL queries.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么要关注这个？好吧，正如我们稍后会看到的，我们可以利用这种结构来编写更高效的 SQL 查询。
- en: Creating partitioned tables
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建分区表
- en: Creating a partitioned table is easy as pie.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 创建分区表简直轻而易举。
- en: For example, if we’d use the following code to create a normal (unpartitioned)
    table…
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们使用以下代码来创建一个普通（未分区）表……
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '… we can create a partitioned version by adding a single line at the end of
    the `CREATE TABLE` statement:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: … 我们可以通过在`CREATE TABLE`语句的末尾添加一行来创建一个分区版本：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The column on which were are partitioning is known as the **partitioning key**;
    in this case, we’re partitioning on the `date` column, but any column is fine
    as long as it’s either (1) a date/timestamp field or (2) an integer field.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进行分区的列被称为**分区键**；在这种情况下，我们在`date`列上进行分区，但任何列都可以，只要它是（1）日期/时间戳字段或（2）整数字段。
- en: 'Once we’ve created these two tables, we’ll see that they look identical at
    first glance (e.g., if you run `SELECT *` against each table, the results will
    look the same). If however we look at the tables’ details/metadata, we’ll see
    that the partitioned table includes some extra metadata. Here’s what this looks
    like in BigQuery (the place I’m running my SQL):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了这两个表，我们会发现它们乍一看是相同的（例如，如果你对每个表运行`SELECT *`，结果将是相同的）。然而，如果我们查看表的详细信息/元数据，我们会看到分区表包含了一些额外的元数据。在BigQuery中（我在这里运行SQL），情况是这样的：
- en: '![](../Images/ded7525c32680d28219a206fc6adbfd0.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ded7525c32680d28219a206fc6adbfd0.png)'
- en: Image by author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Why does this matter? Because using partitions reduces the amount of data required
    to process your query
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这有什么重要的？因为使用分区减少了处理查询所需的数据量
- en: And this is great news, because it means that partitions can help you write
    more efficient queries!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这真是个好消息，因为这意味着分区可以帮助你编写更高效的查询！
- en: When you query a normal (unpartitioned) table, the SQL engine typically has
    to scan the entire table in order to find the rows you want. On large tables,
    this can be unnecessarily slow and expensive, as your machine needs to process
    data which are not useful for creating the final output.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当你查询一个普通（未分区）表时，SQL引擎通常需要扫描整个表以找到你所需的行。在大型表中，这可能不必要地慢且昂贵，因为你的机器需要处理对生成最终输出没有用的数据。
- en: 'For example, let’s query the unpartitioned table we created earlier:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们查询一下我们之前创建的未分区表：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/0904eee688705792f43d47a6ea8448d8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0904eee688705792f43d47a6ea8448d8.png)'
- en: Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: In the image above, you can see that **all 9 rows of the table** were read in
    order to return the 6 rows with dates greater than ‘2023–12–01’.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图片中，你可以看到**表中的所有9行**都被读取以返回日期大于‘2023-12-01’的6行。
- en: 'Now let’s run the same query against our partitioned table:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们对分区表运行相同的查询：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/0c8375b3ff38b786b5a1db0fb15a0c72.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c8375b3ff38b786b5a1db0fb15a0c72.png)'
- en: Image by author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: This time, we see that **only 6 rows of the unpartitioned table were read**
    in order to generate the same results. Before executing the main part of the query,
    BigQuery was able to identify the partitions which contained the relevant rows
    and pull selectively from them. It simply didn’t need to read the 3 rows in the
    other partition.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们看到**仅读取了未分区表中的6行**以生成相同的结果。在执行查询的主要部分之前，BigQuery能够识别包含相关行的分区并进行选择性提取。它根本不需要读取其他分区中的3行。
- en: This preliminary step of selecting partitions is known as ***pruning****.* It’s
    much more efficient than normal queries because it means that the SQL engine won’t
    have to read every single row in the table; it will first fetch the partitions
    required, and only then will it execute your query. In fancy SQL lingo, the filter
    we add on the partitioning column is treated as an ***access predicate*** by the
    SQL engine and gets run before executing the main query.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 选择分区的这个初步步骤被称为***修剪***。这比正常查询更高效，因为这意味着SQL引擎无需读取表中的每一行；它会首先获取所需的分区，然后才会执行你的查询。在高阶SQL术语中，我们在分区列上添加的过滤器被SQL引擎视为***访问谓词***，并在执行主查询之前运行。
- en: — Quick interlude —
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: — 快速插曲 —
- en: If you’re enjoying this article, you might like my site [the-sql-gym.com](https://the-sql-gym.com),
    which contains over 100 practice SQL questions. If you want to boost your SQL
    skills, check it out! And let me know if you have any feedback :-)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你喜欢这篇文章，你可能会喜欢我的网站 [the-sql-gym.com](https://the-sql-gym.com)，网站包含了100多个SQL练习题。如果你想提升你的SQL技能，可以去看看！如果有任何反馈，请告诉我
    :-)
- en: '![](../Images/2eecfbe5e0a0711641021e07d3c44cf6.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2eecfbe5e0a0711641021e07d3c44cf6.png)'
- en: 'Image by author. Source: [the-sql-gym.com](https://the-sql-gym.com/)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。来源：[the-sql-gym.com](https://the-sql-gym.com/)
- en: Back to partitioning — Let’s look at a bigger example
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到分区——让我们看一个更大的例子
- en: When we’re working with small tables like the ones above, partitioning might
    seem a bit overkill. But when we upscale to larger tables, it can lead to significant
    performance gains.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理像上面这些小表时，分区可能显得有些过度。但当我们扩展到更大的表时，它可以带来显著的性能提升。
- en: First, let’s create two large tables, each with 1 million rows. The first will
    be an unpartitioned table, and the second will be partitioned by the `id` column,
    with each partition being 10,000 rows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建两个大表，每个表包含100万行。第一个将是未分区表，第二个将按`id`列进行分区，每个分区包含10,000行。
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When we run the following query against the unpartitioned table:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对未分区的表运行以下查询时：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/d1ce2eb7af55144289d1ee37e1f8f5f7.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1ce2eb7af55144289d1ee37e1f8f5f7.png)'
- en: Image by author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: … we see that all 1,000,000 rows of the table are read before the 1,001 records
    are outputted. The whole operation took 650ms (Elapsed time) / 503ms (Slot time
    consumed).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: … 我们看到在输出1,001条记录之前，表中的所有1,000,000行都被读取了。整个操作耗时650毫秒（经过时间）/503毫秒（消耗的槽时间）。
- en: However, when we run the same query against the **partitioned** table, only
    10,000 rows are read (i.e., one single partition).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，当我们对**分区**表运行相同的查询时，只读取了10,000行（即一个单独的分区）。
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/ee7a768edaf85d73975b4acc5dafee94.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee7a768edaf85d73975b4acc5dafee94.png)'
- en: Image by author
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: When querying the unpartitioned table, the operation’s elapsed time was less
    than half of that in the first query (on the unpartitioned large table), and the
    slot time consumed was nearly 95% lower.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当查询未分区的表时，操作的经过时间不到第一个查询（在未分区的大表上）的时间的一半，且消耗的槽时间降低了近95%。
- en: Pretty cool, right?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 很酷，对吧？
- en: Common mistakes when using partitions
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分区时的常见错误
- en: 'If you’d like to start using partitions to improve your tables/queries, there
    are a couple of pitfalls to watch out for:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望开始使用分区来改善你的表/查询，有几个陷阱需要注意：
- en: '**Don’t filter a large partitioned table on a non-partitioning column** — If
    you filter on a column which is NOT the partitioning key, you won’t be able to
    take advantage of the partitioned structure of the table. If you DO need to filter
    on a non-partitioning-key column, I’d recommend that (if possible) you first add
    in a filter on the parititioning key (to prune the unneeded partitions), and then
    apply your second filter. This is because BigQuery (like many SQL engines) executes
    filters in the `WHERE` statement from top to bottom.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不要在非分区列上过滤大分区表** — 如果你在一个非分区键的列上进行过滤，你将无法利用表的分区结构。如果你确实需要在非分区键列上进行过滤，我建议你（如果可能的话）首先添加一个针对分区键的过滤条件（以修剪不需要的分区），然后再应用第二个过滤条件。这是因为
    BigQuery（像许多 SQL 引擎一样）会从上到下执行`WHERE`语句中的过滤条件。'
- en: '**Don’t apply a function on top of the partition keys** — For example, if your
    partitioning key is a column `date`, don’t add a filter like `WHERE CAST(date
    AS STRING) = ''2023-12-02''`. Instead, if you need to include a function in your
    `WHERE` clause, add the function on top of a constant. In that example, you could
    rewrite the filter to `WHERE date = CAST(''2023-01-01'' AS DATE)` to ensure that
    you still take advantage of pruning/partitioning.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不要在分区键上应用函数** — 例如，如果你的分区键是`date`列，不要添加像`WHERE CAST(date AS STRING) = ''2023-12-02''`这样的过滤条件。相反，如果你需要在`WHERE`子句中使用函数，可以将函数应用于常量。在这个例子中，你可以将过滤条件改写为`WHERE
    date = CAST(''2023-01-01'' AS DATE)`，以确保你仍能利用修剪/分区的优势。'
- en: 2 quick notes about partitioning in BigQuery specifically
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于 BigQuery 分区的两个快速提示
- en: 'BigQuery has **a limit of 4,000 partitions per table**. If you’re trying to
    use a partitioning key that will create more than 4,000 partitions, try using
    a different resolution. For example, instead of partitioning by date/day:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery 对每个表有**4,000个分区的限制**。如果你尝试使用一个将创建超过4,000个分区的分区键，请尝试使用不同的分辨率。例如，不要按日期/天分区：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '… you could partition by week:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: … 你可以按周进行分区：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It’s also worth knowing that BigQuery makes it possible to partition based on
    an ingestion time field and a pseudocolumn named `_PARTITIONTIME`. It’s too niche
    for this article, but you can read more about it [here](https://cloud.google.com/bigquery/docs/partitioned-tables#ingestion_time).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，值得了解的是 BigQuery 允许基于摄取时间字段和名为`_PARTITIONTIME`的伪列进行分区。虽然这个话题在本文中不够相关，但你可以在[这里](https://cloud.google.com/bigquery/docs/partitioned-tables#ingestion_time)阅读更多内容。
- en: When NOT to use partitions
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时不使用分区
- en: On smaller tables, partitioning might not lead to a performance boost. Why?
    Because the process of pruning partitions might take longer than simply looking
    through all the rows in the table ([source](https://stackoverflow.com/questions/58743050/whats-a-good-balance-to-decide-when-to-partition-a-table-in-bigquery)).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在较小的表格中，分区可能不会带来性能提升。为什么？因为修剪分区的过程可能比简单地查看表中所有行花费更多时间（[来源](https://stackoverflow.com/questions/58743050/whats-a-good-balance-to-decide-when-to-partition-a-table-in-bigquery)）。
- en: In these cases, ***clustering*** can be a more performant alternative. Stay
    tuned for more on that in my next article!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，***聚类***可能是一个更高效的替代方案。请关注我下一篇文章了解更多内容！
- en: One more thing —
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有一件事——
- en: I’ve started a free newsletter called [AI in Five](https://aiinfive.substack.com/)
    where I share 5 bullet points each week on the latest AI news, coding tips and
    career stories for Data Scientists/Analysts. There’s no hype, no “**data is the
    new oil**” rubbish and no tweets (or should I say ‘x-es’ now?) from Elon — just
    practical tips and insights to help you develop in your career.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经开始了一份免费的通讯，叫做 [AI in Five](https://aiinfive.substack.com/)，每周分享5个要点，涵盖最新的AI新闻、编码技巧和数据科学家/分析师的职业故事。没有炒作，没有“**数据是新的石油**”的废话，也没有来自Elon的推文（或者我现在应该说‘x-es’？）——只有实用的技巧和见解，帮助你在职业生涯中发展。
- en: '[Subscribe here](https://aiinfive.substack.com/) if that sounds up your street!
    Thanks for reading.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[在这里订阅](https://aiinfive.substack.com/) 如果这正是你感兴趣的！感谢阅读。'
- en: '[](https://aiinfive.substack.com/?source=post_page-----43e24ea4c5d0--------------------------------)
    [## AI in Five | Matt Chapman | Substack'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[## AI in Five | Matt Chapman | Substack](https://aiinfive.substack.com/?source=post_page-----43e24ea4c5d0--------------------------------)'
- en: The latest news, career stories and coding tips from the world of Data Science
    and AI, summarised in 5 bullet points…
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最新消息、职业故事和数据科学与人工智能领域的编码技巧，浓缩成5个要点……
- en: aiinfive.substack.com](https://aiinfive.substack.com/?source=post_page-----43e24ea4c5d0--------------------------------)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[aiinfive.substack.com](https://aiinfive.substack.com/?source=post_page-----43e24ea4c5d0--------------------------------)'
