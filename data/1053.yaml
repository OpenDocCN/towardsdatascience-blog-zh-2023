- en: 'Intro to TorchData: A Walkthrough with Conceptual Captions 3M'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TorchData介绍：Conceptual Captions 3M的实操指南
- en: 原文：[https://towardsdatascience.com/intro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41?source=collection_archive---------10-----------------------#2023-03-22](https://towardsdatascience.com/intro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41?source=collection_archive---------10-----------------------#2023-03-22)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/intro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41?source=collection_archive---------10-----------------------#2023-03-22](https://towardsdatascience.com/intro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41?source=collection_archive---------10-----------------------#2023-03-22)
- en: Learn how to use TorchData and DataPipes to efficiently stream large datasets
    like Conceptual Captions 3M.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习如何使用TorchData和DataPipes高效地流式处理像Conceptual Captions 3M这样的巨大数据集。
- en: '[](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)[![Frank
    Odom](../Images/31a2789d5ff0e5299fa623c6668563e3.png)](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)[](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)
    [Frank Odom](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)[![Frank
    Odom](../Images/31a2789d5ff0e5299fa623c6668563e3.png)](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)[](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)
    [Frank Odom](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f77d545fa4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&user=Frank+Odom&userId=6f77d545fa4e&source=post_page-6f77d545fa4e----928144b5bc41---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)
    ·8 min read·Mar 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F928144b5bc41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&user=Frank+Odom&userId=6f77d545fa4e&source=-----928144b5bc41---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f77d545fa4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&user=Frank+Odom&userId=6f77d545fa4e&source=post_page-6f77d545fa4e----928144b5bc41---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)
    ·8分钟阅读·2023年3月22日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F928144b5bc41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&user=Frank+Odom&userId=6f77d545fa4e&source=-----928144b5bc41---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F928144b5bc41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&source=-----928144b5bc41---------------------bookmark_footer-----------)![](../Images/0de5ae5a50936751b7539aca8dd3ab1c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F928144b5bc41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&source=-----928144b5bc41---------------------bookmark_footer-----------)![](../Images/0de5ae5a50936751b7539aca8dd3ab1c.png)'
- en: Photo by [Quinten de Graaf](https://unsplash.com/@quinten149?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Quinten de Graaf](https://unsplash.com/@quinten149?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上。
- en: Overview
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: When working with large datasets, especially in deep learning, it can be impractical
    to download them locally for training. Instead, streaming the dataset directly
    during training can be a more efficient approach. In this tutorial, we will introduce
    the TorchData library and demonstrate how to use it to stream the Conceptual Captions
    3M dataset, which consists of 3 million images with their corresponding captions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理大型数据集时，尤其是在深度学习中，直接将数据集下载到本地进行训练可能不切实际。相反，在训练过程中直接流式传输数据集可能是一种更高效的方法。在本教程中，我们将介绍TorchData库，并演示如何使用它来流式传输Conceptual
    Captions 3M数据集，该数据集包含300万张图片及其对应的说明。
- en: '**Note:** Conceptual Captions is freely available under an open-source license.
    For more information, see the [LICENSE](https://github.com/google-research-datasets/conceptual-captions/blob/master/LICENSE)
    from the [official GitHub repo](https://github.com/google-research-datasets/conceptual-captions).'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** Conceptual Captions在开源许可证下免费提供。有关更多信息，请参阅[许可证](https://github.com/google-research-datasets/conceptual-captions/blob/master/LICENSE)和[官方GitHub仓库](https://github.com/google-research-datasets/conceptual-captions)。'
- en: We’ll start by providing a brief overview of TorchData and its main components.
    Then, we’ll walk through the process of setting up our data pipeline for the Conceptual
    Captions 3M dataset, and finally, we’ll show an example of how to use the pipeline
    to stream the dataset in real-time.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先简要介绍TorchData及其主要组件。接着，我们会演示如何为Conceptual Captions 3M数据集设置数据管道，最后，我们将展示如何使用该管道实时流式传输数据集的示例。
- en: This tutorial is designed to be accessible to absolute beginners, so we’ll take
    the time to explain each concept and code snippet in detail. Let’s get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程旨在对完全初学者友好，因此我们会详细解释每个概念和代码片段。让我们开始吧！
- en: '![](../Images/7f3d6898c60f6b7bc4a811319008af34.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f3d6898c60f6b7bc4a811319008af34.png)'
- en: Photo by [Braden Collum](https://unsplash.com/@bradencollum?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Braden Collum](https://unsplash.com/@bradencollum?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Intro to TorchData
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TorchData简介
- en: 'TorchData is a library of common data loading methods for easily constructing
    flexible and performant data pipelines. An excerpt from the [TorchData README](https://github.com/pytorch/data#torchdata):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: TorchData是一个提供常用数据加载方法的库，用于轻松构建灵活且高效的数据管道。以下是[TorchData README](https://github.com/pytorch/data#torchdata)的摘录：
- en: It introduces composable Iterable-style and Map-style building blocks called
    DataPipes that work well out of the box with PyTorch’s `DataLoader`. These built-in
    DataPipes provide functionalities for loading files (from local or cloud storage),
    parsing, caching, transforming, filtering, and many more utilities.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它引入了可组合的Iterable风格和Map风格的构建块，称为DataPipes，这些构建块与PyTorch的`DataLoader`能够很好地配合使用。这些内置的DataPipes提供了加载文件（来自本地或云存储）、解析、缓存、转换、过滤等多种功能。
- en: DataPipes
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataPipes
- en: '![](../Images/204ac73ab96a4a66ce5bffec893180f6.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/204ac73ab96a4a66ce5bffec893180f6.png)'
- en: Photo by [T K](https://unsplash.com/@realaxer?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[T K](https://unsplash.com/@realaxer?utm_source=medium&utm_medium=referral)拍摄，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: At the core of TorchData are DataPipes, which can be thought of as composable
    building blocks for data pipelines. DataPipes are simply renamed and repurposed
    PyTorch `Dataset`s designed for composed usage. They take in an access function
    over Python data structures, `__iter__` for `IterDataPipes` and `__getitem__`
    for `MapDataPipes`, and return a new access function with a slight transformation
    applied.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: TorchData的核心是DataPipes，它可以被看作是数据管道的可组合构建块。DataPipes实际上是重命名和重新设计的PyTorch `Dataset`，专为组合使用而设计。它们接受对Python数据结构的访问函数，`IterDataPipes`使用`__iter__`，`MapDataPipes`使用`__getitem__`，并返回一个应用了轻微变换的新访问函数。
- en: By chaining together DataPipes, we can create sophisticated data pipelines with
    streamed operation as a first-class citizen. This enables us to handle large datasets
    efficiently and reduce the need for local storage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将DataPipes链接在一起，我们可以创建复杂的数据管道，将流式操作作为一等公民。这使我们能够高效地处理大型数据集，并减少对本地存储的需求。
- en: Example
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例
- en: 'Let’s start with an example to get familiar with the basic concepts. Let’s
    create a basic DataPipe that takes an iterable of integers and doubles their values:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个示例开始，以熟悉基本概念。我们将创建一个基本的DataPipe，它接收一个整数的可迭代对象，并将其值翻倍：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This code defines a custom `DoublingDataPipe` that takes an iterable source
    of data (in our case, a list of integers) and yields each item from the source
    data multiplied by 2\. When we run this code, we should see the doubled values
    printed:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码定义了一个自定义的 `DoublingDataPipe`，它接受一个数据源的可迭代对象（在我们的例子中，是一个整数列表），并生成源数据中每个项的两倍。当我们运行这段代码时，我们应该会看到输出的值是加倍的：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: TorchData also provides lots of built-in pipeline methods, which could have
    made this example much more concise.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: TorchData 还提供了许多内置的管道方法，这本可以使这个例子更加简洁。
- en: The `.map()`, `.filter()`, `.shuffle()`, and `.chain()` methods, to name a few,
    enable us to quickly build powerful and flexible data pipelines without having
    to write custom DataPipes for every operation. They can be applied directly to
    an `IterDataPipe` to perform common data processing tasks, such as applying transformations,
    filtering data, randomizing order, and concatenating multiple DataPipes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`.map()`、`.filter()`、`.shuffle()` 和 `.chain()` 方法等，使我们能够快速构建强大且灵活的数据管道，而无需为每个操作编写自定义
    DataPipes。它们可以直接应用于 `IterDataPipe`，以执行常见的数据处理任务，例如应用转换、过滤数据、随机化顺序和连接多个 DataPipes。'
- en: Let’s explore a few examples. We’ll use the `source_data` list from our previous
    example as the input for our DataPipes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索几个示例。我们将使用之前示例中的 `source_data` 列表作为 DataPipes 的输入。
- en: '`.map()`: Applies a function to each element in the DataPipe.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.map()`: 对 DataPipe 中的每个元素应用一个函数。'
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The entire `DoublingDataPipe` example from earlier is reproduced here in a
    single line of code: `data_pipe.map(lambda x: x * 2)`.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '这里重新列出了之前的 `DoublingDataPipe` 示例的单行代码：`data_pipe.map(lambda x: x * 2)`。'
- en: '2\. `.filter()`: Filters the elements in the DataPipe based on a condition.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '2\. `.filter()`: 根据条件过滤 DataPipe 中的元素。'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '3\. `.shuffle()`: Randomizes the order of elements in the DataPipe.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '3\. `.shuffle()`: 随机打乱 DataPipe 中元素的顺序。'
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '4\. `.chain()`: Concatenates two or more DataPipes.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '4\. `.chain()`: 连接两个或更多 DataPipes。'
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Setting Up Conceptual Captions 3M
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Conceptual Captions 3M
- en: '![](../Images/c8bc5e53a8a2eec26b42be6af9b5e661.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8bc5e53a8a2eec26b42be6af9b5e661.png)'
- en: Photo by [John Schnobrich](https://unsplash.com/@johnschno?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [John Schnobrich](https://unsplash.com/@johnschno?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In this section, we’ll walk through the process of setting up our data pipeline
    for the Conceptual Captions 3M dataset. This dataset consists of 3 million images
    and their corresponding captions, making it impractical to download locally for
    training. Instead, we’ll use TorchData to stream the dataset directly during training.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将逐步介绍如何为 Conceptual Captions 3M 数据集设置数据管道。该数据集包含 300 万张图像及其对应的标题，因此在本地下载以进行训练是不可行的。相反，我们将使用
    TorchData 在训练过程中直接流式传输数据集。
- en: Dependencies
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 依赖项
- en: 'Before diving into the code, let’s first install the required dependencies
    for this tutorial. You’ll need the following Python packages:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入代码之前，我们先安装本教程所需的依赖项。你需要以下 Python 包：
- en: torchdata
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: torchdata
- en: tqdm (for displaying progress bars)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tqdm（用于显示进度条）
- en: aiohttp (for asynchronous HTTP requests)
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: aiohttp（用于异步 HTTP 请求）
- en: Pillow (for handling images)
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pillow（用于处理图像）
- en: 'You can install them using pip:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 pip 安装它们：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Async Helper Functions for Asynchronous Image Download
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异步图像下载的异步助手函数
- en: Since we’ll be streaming images from remote URLs, we need a way to efficiently
    download them in parallel. We’ll use the `aiohttp` library to make asynchronous
    HTTP requests.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将从远程 URL 流式传输图像，我们需要一种有效的方式来并行下载它们。我们将使用 `aiohttp` 库来进行异步 HTTP 请求。
- en: 'First, let’s create a helper function `async_get_image` that takes an `aiohttp.ClientSession`
    and a URL as input and returns the downloaded image:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个助手函数 `async_get_image`，它接受 `aiohttp.ClientSession` 和一个 URL 作为输入，并返回下载的图像：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next, we’ll create another helper function `async_batch_get_images` that takes
    a sequence of URLs, and returns a list of downloaded images. It uses `aiohttp.ClientSession`to
    run multiple requests in parallel with minimal overhead, which is crucial for
    performance when fetching a large number of images from remote URLs in real-time.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建另一个助手函数 `async_batch_get_images`，它接受一个 URL 序列，并返回一组下载的图像。它使用 `aiohttp.ClientSession`
    来并行运行多个请求，以尽量减少开销，这对实时从远程 URL 获取大量图像的性能至关重要。
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ParallelSampleLoader DataPipe
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ParallelSampleLoader DataPipe
- en: '![](../Images/16b48083c503e4759a6046809a906360.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16b48083c503e4759a6046809a906360.png)'
- en: Photo by [Tom Strecker](https://unsplash.com/@tom_stre?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Tom Strecker](https://unsplash.com/@tom_stre?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Now that we have our helper functions for downloading images, let’s create a
    custom `ParallelSampleLoader` DataPipe that takes an `IterDataPipe` of tuples
    containing image URLs and captions, and returns an iterator over the downloaded
    images and their corresponding captions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了下载图像的辅助函数，让我们创建一个自定义的`ParallelSampleLoader` DataPipe，它接受一个包含图像 URL 和说明的元组的`IterDataPipe`，并返回一个迭代器，用于获取下载的图像及其对应的说明。
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Putting It All Together
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 综合
- en: Finally, we’ll create a function `conceptual_captions_3m` that takes a `split`
    argument (either "train" or "val") and returns an `IterDataPipe` of tuples containing
    the downloaded images and their corresponding captions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将创建一个 `conceptual_captions_3m` 函数，它接受一个 `split` 参数（"train" 或 "val"），并返回一个包含下载图像及其对应说明的
    `IterDataPipe`。
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Conceptual Captions 3M
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Conceptual Captions 3M
- en: 'With our data pipeline set up, we can now use it to stream the Conceptual Captions
    3M dataset in real-time. In this example, we’ll use the `conceptual_captions_3m`
    function to create an `IterDataPipe` for the training split and iterate over the
    dataset, printing out the first 10 captions and displaying their corresponding
    image sizes:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 设置好数据管道后，我们现在可以使用它实时流式传输 Conceptual Captions 3M 数据集。在这个示例中，我们将使用 `conceptual_captions_3m`
    函数创建一个用于训练集的 `IterDataPipe`，并迭代数据集，打印出前 10 个说明并显示它们对应的图像尺寸：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here’s another simple example to benchmark how quickly images can be loaded
    through this pipeline. We use the `tqdm` library to create a progress bar, which
    displays the number of samples iterated per second.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有另一个简单的示例，用于基准测试通过此管道加载图像的速度。我们使用 `tqdm` 库创建一个进度条，以显示每秒迭代的样本数量。
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Download speeds are **very** dependent on your internet connection. Virtual
    machines from most cloud providers have extremely fast network connections, which
    makes them ideal for using DataPipes. I ran the benchmark above on my Google Cloud
    VM, which reaches download speeds of roughly 120 images per second. For small-scale
    ML training using a single GPU-enabled machine, that should be more than enough
    speed. (Few ML models train at faster than 120 images/sec, unless you’re using
    more expensive GPU hardware.)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 下载速度**非常**依赖于你的互联网连接。大多数云服务提供商的虚拟机具有极快的网络连接，这使得它们非常适合使用 DataPipes。我在我的 Google
    Cloud 虚拟机上运行了上述基准测试，下载速度大约为每秒 120 张图像。对于使用单个 GPU 启用的机器进行的小规模 ML 训练，这应该是足够快的。（很少有
    ML 模型的训练速度超过每秒 120 张图像，除非你使用更昂贵的 GPU 硬件。）
- en: Conclusion
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: TorchData offers a powerful and flexible way to handle large datasets by providing
    composable DataPipes and built-in pipeline methods. By utilizing these tools,
    you can effectively stream and process your data on-the-fly without the need for
    downloading data to local disk beforehand. This approach not only saves time and
    storage resources, but enables a more seamless integration of the dataset into
    your project. All of the dataset logic is now codified in your Python project,
    and does not require detailed setup instructions in your README (common in many
    projects). By encapsulating the pipeline within your code, TorchData allows for
    better reproducibility and portability, making it an invaluable tool for modern
    machine learning projects dealing with large datasets.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: TorchData 提供了一种强大而灵活的方式来处理大数据集，通过提供可组合的 DataPipes 和内置的管道方法。利用这些工具，你可以有效地实时流式传输和处理数据，无需提前将数据下载到本地磁盘。这种方法不仅节省了时间和存储资源，还能将数据集更无缝地集成到你的项目中。现在，所有的数据集逻辑都已在你的
    Python 项目中编码，不再需要在 README 中详细的设置说明（这是许多项目中的常见情况）。通过将管道封装在代码中，TorchData 允许更好的可重复性和可移植性，使其成为现代机器学习项目中处理大数据集的宝贵工具。
- en: With this tutorial, you should now have a better understanding of how to use
    the TorchData library to create a data pipeline for streaming large datasets like
    Conceptual Captions 3M. This approach can be applied to other large datasets,
    and it can be easily adapted for various data processing and augmentation tasks.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本教程，你现在应该对如何使用 TorchData 库来创建用于流式传输大数据集（如 Conceptual Captions 3M）的数据管道有了更好的理解。这种方法可以应用于其他大型数据集，并且可以轻松地适应各种数据处理和增强任务。
- en: '![](../Images/7bd75bdd41f51055eebf971fa0caee84.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7bd75bdd41f51055eebf971fa0caee84.png)'
- en: Photo by [Vasily Koloda](https://unsplash.com/@napr0tiv?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [瓦西里·科洛达](https://unsplash.com/@napr0tiv?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上。
