- en: Solve a mystery box like a data scientist
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 像数据科学家一样解决神秘盒子
- en: 原文：[https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52](https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52](https://towardsdatascience.com/solve-a-mystery-box-like-a-data-scientist-f9ee9570ba52)
- en: Get data, train ViT, minimize problem; and way too overkill
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取数据，训练 ViT，最小化问题；实在是过度处理
- en: '[](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Dennis
    Bakhuis](../Images/4dc6dca031cdedbb044a1d0a6b142186.png)](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    [Dennis Bakhuis](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Dennis
    Bakhuis](../Images/4dc6dca031cdedbb044a1d0a6b142186.png)](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    [Dennis Bakhuis](https://dennisbakhuis.medium.com/?source=post_page-----f9ee9570ba52--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    ·17 min read·Jan 13, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f9ee9570ba52--------------------------------)
    ·阅读时间17分钟·2023年1月13日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/b9a4946ac13a6d2ed63ff0370c95ba55.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9a4946ac13a6d2ed63ff0370c95ba55.png)'
- en: 'Figure 1: A mystery box, the process of collecting data, and eventually an
    open lock.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：一个神秘盒子、数据收集过程，以及最终打开的锁。
- en: What happens when a data scientist gets a riddle in form of a box? Of course
    he will (try) approach it as a data problem. In this article I will describe the
    whole process, and to be honest, it was not as easy as I thought. As with many
    problems, you can get completely lost and only by talking to a couple of friends,
    I got back on track again.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个数据科学家得到一个以盒子形式出现的谜题时，会发生什么？当然，他会（尝试）将其作为数据问题来解决。在这篇文章中，我将描述整个过程，坦白说，这并不像我想象的那么容易。与许多问题一样，你可能会完全迷失，只有通过与几个朋友交谈，我才得以重新回到正轨。
- en: As a data scientist, I like to approach this problem in a data manner. I realize
    that this method is far from the most obvious solution. But it was a very fun
    endeavor. Collecting too much data, train a transformer model to extract values
    from a video, and eventually use a `minimizer` to find the solution. This article
    is a summary of this (mostly) fun journey!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个数据科学家，我喜欢以数据的方式来解决这个问题。我意识到这种方法远非最明显的解决方案。但这是一个非常有趣的尝试。收集过多的数据，训练一个变压器模型从视频中提取值，最后使用
    `minimizer` 找到解决方案。本文是这个（大部分）有趣旅程的总结！
- en: 'I have divided this article in a couple of (for me) logical steps. Feel free
    to skip to parts you like:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我将这篇文章分成了几个（对我而言）逻辑步骤。你可以随意跳过你喜欢的部分：
- en: What is this “mystery box” you’re talking about
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你提到的这个“神秘盒子”是什么？
- en: A formal problem description
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正式的问题描述
- en: Collecting the required data
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集所需的数据
- en: Processing the data goodness (label, train, inference)
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理数据的善意（标记、训练、推断）
- en: Analyze the dataset and find the goal
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析数据集并找到目标
- en: Going to the location
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往位置
- en: '*All images in this article have been taken or are generated by me unless stated
    otherwise in the separate captions (which is none in this article).*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非在单独的说明中另有说明（在本文中没有），否则本文中的所有图像均由我拍摄或生成。*'
- en: '[All code](https://github.com/dennisbakhuis/mystery_box) for this project is
    shared in Notebooks and is available on my [Github account](https://github.com/dennisbakhuis).
    If you have any comments or questions, I like to hear them through [LinkedIn](https://linkedin.com/in/dennisbakhuis).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[此项目的所有代码](https://github.com/dennisbakhuis/mystery_box)都在 Notebooks 中共享，并且可以在我的
    [Github 账号](https://github.com/dennisbakhuis)上找到。如果你有任何评论或问题，我很乐意通过 [LinkedIn](https://linkedin.com/in/dennisbakhuis)听取。'
- en: What is this “mystery box” you’re talking about?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你提到的这个“神秘盒子”是什么？
- en: For my birthday my friend Sander gave me a mysterious box and with the big grin
    on his face, this would keep me busy for a while.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我生日那天，我的朋友 Sander 给了我一个神秘的盒子，他脸上带着大大的笑容，这将让我忙上一段时间。
- en: The mystery box immediately looked very intriguing (see figure 1). It was clear
    that the box was created by Sander himself as it had the very distinct fused deposition
    modeling (FDM) printing pattern. The front showed a common LCD screen and a red
    button. On the left side, a relatively large padlock was visible. This is one
    of these code padlocks that required a four digit code to open. The padlock keeps
    a sliding lid from opening at the bottom of the box. On the right side is a small
    excess compartment that holds a 9 volt battery. Pretty smart to have the battery
    outside so that it can be exchanged when the power is getting low.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 神秘盒子立刻看起来非常引人入胜（见图 1）。显然，这个盒子是由 Sander 亲自制作的，因为它具有非常明显的熔融沉积建模（FDM）打印图案。正面展示了一个常见的
    LCD 屏幕和一个红色按钮。左侧有一个相对较大的挂锁。这是一个需要四位数字代码才能打开的挂锁。挂锁防止盒子底部的滑盖打开。右侧是一个小的多余空间，用来放置一个
    9 伏特的电池。电池外置是相当聪明的，这样当电量低时可以更换。
- en: '![](../Images/64fec328a8b6c2848e19b61816d78386.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64fec328a8b6c2848e19b61816d78386.png)'
- en: 'Figure 2: This is the mystery box: a 3D printed device with a screen, a button,
    and a padlock.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：这是神秘盒子：一个带有屏幕、按钮和挂锁的 3D 打印设备。
- en: From a creators point of view, the mystery box has a quite interesting design.
    The top side (as seen in figure 2) was used as base during printing as this side
    is much coarser than the others. This makes the excess battery holder also printable
    without support. Still, I am not completely sure how the hole for the LCD screen
    is created. The most simple method would be to print light supports which are
    cut away. For the ledges that are used for the padlock, the remains of the printing
    support are still visible. All with all, a nice project to keep your printer running
    for at least 8 hours.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从创造者的角度来看，神秘盒子有一个相当有趣的设计。顶面（如图 2 所示）在打印过程中作为基础使用，因为这个面比其他面粗糙得多。这使得多余的电池架也可以在没有支撑的情况下打印。尽管如此，我还是不完全确定
    LCD 屏幕的孔是如何创建的。最简单的方法是打印轻质支撑，然后切除。用于挂锁的台阶上的打印支撑残留物仍然可见。总体来说，这是一个不错的项目，可以让你的打印机运行至少
    8 小时。
- en: 'The red button is a kind of toggle press button. When pressing you hear it
    latch and the LCD screen turns on. After a few seconds the box greets you with
    “Hi!!!” a classical gag at the [Physics of Fluids research group](https://pof.tnw.utwente.nl/).
    The next couple of messages shown on the screen are in Dutch. For an overview
    of the screens see figure 3\. Here are some quick translations:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 红色按钮是一种切换按键。按下时你会听到它卡扣的声音，LCD 屏幕会亮起。几秒钟后，盒子会用“Hi!!!”向你打招呼，这是在[流体物理研究组](https://pof.tnw.utwente.nl/)的经典搞笑方式。接下来几条屏幕上的信息是荷兰语。有关屏幕的概述请参见图
    3。以下是一些快速翻译：
- en: Hi!!! -> <low pitched voice> Hi </low pitched voice>
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hi!!! -> <低音调的声音> Hi </低音调的声音>
- en: Van harte gefeliciteerd! -> Sincere gratulations!
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Van harte gefeliciteerd! -> 真诚的祝贺！
- en: Vind de twee punten en ga -> find the two coordinates and go
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vind de twee punten en ga -> 找到两个坐标并前往
- en: naar het midden van de punten… -> to the center of the coordinates…
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: naar het midden van de punten… -> 到坐标的中心…
- en: Zoekt gps… Een moment… -> Searching gps… One moment…
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zoekt gps… Een moment… -> 正在搜索 GPS… 请稍等…
- en: Afstand(p1)-Afstand(p2)=1048m -> Distance(p1)-Distance(p2)=1048m
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Afstand(p1)-Afstand(p2)=1048m -> 距离(p1)-距离(p2)=1048m
- en: '![](../Images/a85c19a920176ede8eda0d9d89fa108d.png)![](../Images/10368af95b1b1e248cbbd335ed33d8da.png)![](../Images/44ad73d3fed17db0650ba714b8e1f176.png)![](../Images/0cd976e47b101c9f15fcead048fbe269.png)![](../Images/eefa6f7b926a318d23cc38f9e52f75eb.png)![](../Images/acb403272a2e6c5765a23f65180e27e1.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a85c19a920176ede8eda0d9d89fa108d.png)![](../Images/10368af95b1b1e248cbbd335ed33d8da.png)![](../Images/44ad73d3fed17db0650ba714b8e1f176.png)![](../Images/0cd976e47b101c9f15fcead048fbe269.png)![](../Images/eefa6f7b926a318d23cc38f9e52f75eb.png)![](../Images/acb403272a2e6c5765a23f65180e27e1.png)'
- en: 'Figure 3: Turning on the device shows various messages in Dutch, including
    a couple of hints.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：打开设备会显示各种荷兰语信息，包括几个提示。
- en: After the two hint screens, the system is busy with searching for a GPS signal.
    This process, the so called ‘time to first fix’ (TTFF) can be lengthy as the device
    always has to do a so called “cold boot”. This can take up to five minutes according
    to the standard.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个提示屏幕之后，系统正在忙于搜索 GPS 信号。这个过程，即所谓的“第一次定位时间”（TTFF），可能很长，因为设备总是需要进行所谓的“冷启动”。根据标准，这可能需要长达五分钟。
- en: 'Finally, after a GPS fix, the box comes into its main operation screen that
    shows us its only output: the distance to point 1 minus the distance to point
    2 which is a integer value in meters.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在 GPS 固定后，盒子进入主操作界面，显示它唯一的输出：点 1 到点 2 的距离差，以米为单位的整数值。
- en: 'Sander also gave some additional clarification of the unit. The unit outputs
    a value which is the difference between two distances: d1 and d2\. These distances
    are the distance between the current location of the box and two unknown coordinates.
    The goal is to find the coordinate exactly between these two unknown coordinates.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 桑德还对单位做了一些额外的说明。该单位输出一个值，该值是两距离*d1*和*d2*之间的差值。这些距离是当前箱子位置与两个未知坐标之间的距离。目标是找到正好位于这两个未知坐标之间的坐标。
- en: This all sounds easy but lets have a look at a more formal description.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来很简单，但让我们看看更正式的描述。
- en: A formal problem description
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正式问题描述
- en: The goal of the puzzle is to bring it to a specific location. If this location
    is correct, the box will show the code for the padlock. What makes this problem
    challenging is that the mystery box does not show the distance to that specific
    location.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 谜题的目标是将其带到一个特定的位置。如果这个位置是正确的，箱子将显示出密码锁的代码。这个问题的挑战在于神秘箱子不会显示到那个特定位置的距离。
- en: The goal location *G* is exactly in the center of a line between two for us
    unknown coordinates *p1* and *p2*. The distances *d1* and *d2* are the distance
    between the current box location *B* and the coordinates *p1* and *p2*. What the
    box outputs on the screen is the difference between *d1* and *d2* which we will
    call *A*. Figure 4 shows a simplified schematic of the problem.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目标位置*G*正好位于两个未知坐标*p1*和*p2*之间的中点。距离*d1*和*d2*是当前箱子位置*B*与坐标*p1*和*p2*之间的距离。箱子在屏幕上显示的是*d1*和*d2*之间的差值，我们称之为*A*。图4展示了问题的简化示意图。
- en: '![](../Images/a00e990bae292802ad00d1ee586501e1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a00e990bae292802ad00d1ee586501e1.png)'
- en: 'Figure 4: A simple problem overview. The goal G is exactly between unknown
    coordinates p1 and p2\. The only information the box returns is A which is the
    difference between distances d1 and d2\. The distances d1 and d2 are respectively
    the distance between the current box location B and coordinates p1 and p2 respectively.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：一个简单的问题概述。目标*G*正好位于未知坐标*p1*和*p2*之间。箱子返回的唯一信息是*A*，即距离*d1*和*d2*之间的差值。距离*d1*和*d2*分别是当前箱子位置*B*与坐标*p1*和*p2*之间的距离。
- en: The schematic in figure 4 shows that we have a vector problem. If we would assume
    a 2d problem space, we need two values for each coordinate to uniquely identify
    a location in the problem space.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图4中的示意图显示我们有一个向量问题。如果我们假设一个二维问题空间，我们需要每个坐标两个值来唯一标识问题空间中的一个位置。
- en: There exists a point on which the difference *A* is zero. This is when the distance
    *d1* is equal to *d2*. In a 2d space this results in a line that is perpendicular
    to the line between *p1* and *p2* (see Figure 5). So technically, if we find two
    different locations on which A is equal to zero, we could connect those points
    and know that the goal is on that line.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一个点，使得差值*A*为零。这是当距离*d1*等于*d2*时。在二维空间中，这会导致一条垂直于*p1*和*p2*之间线的线（见图5）。所以从技术上讲，如果我们找到两个不同的位置，使得*A*为零，我们可以连接这些点并知道目标在那条线上。
- en: '![](../Images/e1766d9c18cb777a4a72e1e4eda3fd9e.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1766d9c18cb777a4a72e1e4eda3fd9e.png)'
- en: 'Figure 5: When A is equal to zero, d1 and d2 are equal. There exists a line
    perpendicular to the goal coordinate for which A is equal to zero. We could find
    this line if we find two different locations for which A is zero.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：当*A*等于零时，*d1*和*d2*相等。存在一条与目标坐标垂直的线，使得*A*等于零。如果我们找到两个不同的位置，使得*A*为零，我们可以找到这条线。
- en: To solve the equation we could try to solve a system of equations (four unknowns
    requires four equations) but our problem is non-linear. This makes some nasty
    equations when trying to isolate terms in the equation (Equation 1). In the equation
    *x* and *y* are the two dimensions of the current box location coordinate. Maybe
    not the most elegant but the equation can be solved numerically by minimizing
    an error function. This is exactly what we are doing in machine learning with
    gradient descent and the more recent forward-forward method.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要解这个方程，我们可以尝试解一个方程组（四个未知数需要四个方程），但我们的问题是非线性的。这会在试图孤立方程中的项时产生一些复杂的方程（方程1）。在方程中，*x*和*y*是当前箱子位置坐标的两个维度。也许不是最优雅的，但这个方程可以通过最小化误差函数来数值求解。这正是我们在机器学习中使用梯度下降和更现代的前向前向方法所做的。
- en: '![](../Images/12531c0988a6e241316ff91965638518.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12531c0988a6e241316ff91965638518.png)'
- en: 'Equation 1: Difference of distances equation for the simplified case.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 方程1：简化情况下的距离差方程。
- en: Until now we have described the problem that is only valid within the flat earth
    society. We used straight lines for our distances and this would mean that we
    need to dig tunnels in our spherical world. Instead of calculating distances on
    a plane, we need to calculate distances on the surface of a sphere. I have updated
    the problem schematic in Figure 6.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 直到现在，我们描述的问题仅在平面地球学会内有效。我们用直线来表示距离，这意味着我们需要在球面世界中挖掘隧道。与其在平面上计算距离，我们需要在球面上计算距离。我已经更新了图
    6 中的问题示意图。
- en: Until now we have described the problem that is only valid within the flat earth
    society.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 直到现在，我们描述的问题仅在平面地球学会内有效。
- en: '![](../Images/3dd6d149f8d5390e3d7e37297a44954a.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dd6d149f8d5390e3d7e37297a44954a.png)'
- en: 'Figure 6: We are not living a a flat earth. The problem is actually on the
    surface of a sphere.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：我们并不生活在平面地球上。问题实际上是在球面上。
- en: 'Calculating the distance between two points of the surface of a sphere is far
    from trivial. This involves applying [the great circle distance formula](https://en.wikipedia.org/wiki/Great-circle_distance),
    which looks rather messy. Luckily, the people invented a new trigonometric function
    to make it look much more elegant: [the Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula).
    If you like a good read on the problem here is a great article on [the underground
    mathematics](https://undergroundmathematics.org/trigonometry-compound-angles/the-great-circle-distance).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 计算球面上两点之间的距离远非简单。这涉及应用[大圆距离公式](https://en.wikipedia.org/wiki/Great-circle_distance)，这看起来相当复杂。幸运的是，人们发明了一种新的三角函数，使其看起来更为优雅：[哈弗辛公式](https://en.wikipedia.org/wiki/Haversine_formula)。如果你喜欢对这个问题的深入阅读，这里有一篇关于[地下数学](https://undergroundmathematics.org/trigonometry-compound-angles/the-great-circle-distance)的好文章。
- en: Using the Haversine formula to calculate a single distance is quite doable,
    however, our mystery box outputs the difference between two distances *A*. This
    makes the final equation to solve extremely nasty and I think that numerically
    solving the equation makes the most sense.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用哈弗辛公式来计算单个距离是相当可行的，然而，我们的神秘箱子输出的是两个距离 *A* 之间的差值。这使得最终的方程式极其复杂，我认为从数值上解决这个方程最为合理。
- en: But before we can solve anything, we need acquire data. In the next section
    I’ll the describe elaborate setup.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们解决任何问题之前，我们需要获取数据。在下一部分，我将详细描述设置过程。
- en: Collecting the required data
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集所需的数据
- en: The biggest problem when trying to approach a physical riddle as a data problem
    is that there is most probably no data. This means that we need to collect our
    own data. From my experience as a physicist, collecting data is no easy task.
    A lot of things can (and probably will) go wrong. To be honest, I have probably
    biked more than 80km for this project.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当尝试将物理谜题作为数据问题来解决时，最大的问题是很可能没有数据。这意味着我们需要收集自己的数据。根据我的物理学经验，收集数据并非易事。很多事情可能会（并且可能确实会）出错。老实说，为了这个项目，我可能已经骑了超过
    80 公里。
- en: A lot of things can (and probably will) go wrong.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 很多事情可能会（且可能确实会）出现问题。
- en: There are multiple ways we can approach the data collection. First, we could
    just move around by bike 🚴 (we are in 🇳🇱 so yes we 🚴 😃), and stop to write down
    the current latitude and longitude and the output of the box *A*. Technically,
    a few points would suffice but where is the fun in that.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过多种方式来收集数据。首先，我们可以骑自行车 🚴（我们在 🇳🇱，所以是的，我们🚴 😃），并停下来记录当前的纬度和经度以及箱子 *A* 的输出。从技术上讲，几个点就足够了，但这样做没什么趣味。
- en: Instead of doing all this manual work, why not do some classic *over-engineering*
    and get a video of the mystery box output and match that to the data of a GPS
    logger. To do this, we need to build some kind of contraption that fixes a camera
    in front of the LCD screen of the box. The most straight forward way I could think
    of is strapping my mobile phone to some sort of container that has the minimum
    distance required to get a sharp image with the camera. A plastic box just had
    the right dimensions so I could put the box in the box and create some box-ception
    (we have to go deeper). The camera need to be sturdy such that the movement between
    camera and LCD screen was at a minimum. This calls for some serious duct-tape.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 与其做这些手动工作，为什么不做一些经典的*过度工程*，获取神秘箱输出的视频，并将其与GPS记录器的数据匹配。为此，我们需要制作一种装置，将相机固定在箱子LCD屏幕前面。我想到的最直接的方法是将手机绑在某种容器上，这样可以在相机上获得清晰的图像。一个塑料盒子刚好有合适的尺寸，因此我可以将箱子放在盒子里，制造一些箱子套箱（我们要更深入）。相机需要稳固，以便相机和LCD屏幕之间的移动最小化。这需要一些严肃的胶带。
- en: Now we have a solution to record the box output as a movie. The regular camera
    app of my phone was not great so I used an app called [HD Camera](https://play.google.com/store/apps/details?id=photo.android.hd.camera&hl=en&gl=US).
    To get the current location we need a GPS logger. For this I downloaded [GPS logger](https://play.google.com/store/apps/details?id=eu.basicairdata.graziano.gpslogger&hl=en&gl=US)
    from the Playstore. With these two apps install I am ready to collect some data.
    The whole setup is shown in Figure 7.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了记录箱子输出为电影的解决方案。我手机的常规相机应用效果不好，所以我使用了一个名为[HD Camera](https://play.google.com/store/apps/details?id=photo.android.hd.camera&hl=en&gl=US)的应用程序。要获取当前位置，我们需要一个GPS记录器。为此，我从Playstore下载了[GPS
    logger](https://play.google.com/store/apps/details?id=eu.basicairdata.graziano.gpslogger&hl=en&gl=US)。安装了这两个应用程序后，我准备好收集一些数据。整个设置如图7所示。
- en: '![](../Images/72f886aa8131325f28f5df6cdfaa7214.png)![](../Images/74de9ef9a4e9648aa7f541fd56b5880b.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72f886aa8131325f28f5df6cdfaa7214.png)![](../Images/74de9ef9a4e9648aa7f541fd56b5880b.png)'
- en: 'Figure 7: Setup for collecting data. The mystery box is box-ceptioned into
    another box. On top of the box a mobile phone is strapped such that the camera
    has clear view of the LCD screen. The mobile phone as two apps active, a camera
    app and a GPS logger. The GPS logger is in floating app mode such that it keeps
    being active and not turned off by the phones power saving settings.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：数据收集的设置。神秘箱子被盒子套箱。盒子上面绑着一个手机，以便相机能清晰地看到LCD屏幕。手机上有两个活动应用，一个相机应用和一个GPS记录器。GPS记录器处于浮动应用模式，以便保持活动状态，不被手机的省电设置关闭。
- en: 'I have already mentioned the many things that can go wrong when doing experiments.
    Here are my confessions of my many mistakes:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经提到过在做实验时可能出错的很多事情。以下是我犯下的许多错误的自白：
- en: During my first ride the battery died. When still recording while the phone
    dies, you lose the recording. This made me add a descent power bank to the setup.
    ( 🚴 ~12 km).
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次骑行时电池耗尽了。当手机在电量耗尽时仍在录制时，你会丢失录音。这让我为设备添加了一个额外的移动电源。（ 🚴 ~12 km）。
- en: Next ride my storage was full. I did not see the error message until late in
    the ride. ( 🚴 ~10 km).
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一次骑行时我的存储满了。我直到骑行快结束时才看到错误信息。（ 🚴 ~10 km）。
- en: During another ride, I did not liked the lighting due to the sun. ( 🚴 ~9 km).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在另一次骑行中，由于阳光我不喜欢光线。（ 🚴 ~9 km）。
- en: Now I liked the footage but somehow I did not have any GPS data. ( 🚴 ~9 km).
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我喜欢这些影像，但不知为何没有GPS数据。（ 🚴 ~9 km）。
- en: Again, no GPS data. but I suspect some battery saving issue. ( 🚴 ~9 km).
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，没有GPS数据。但我怀疑是一些电池节省问题。（ 🚴 ~9 km）。
- en: I made the GPS logger foreground and HD Camera background. Now I had GPS data
    but somehow, the camera App stopped. ( 🚴 ~9 km).
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我把GPS记录器设置为前台，HD相机设置为后台。现在我有了GPS数据，但不知为何，相机应用停止了。（ 🚴 ~9 km）。
- en: After making the GPS logger app a floating app (some multi-task magic) I got
    both, GPS and image data. ( 🚴 ~9 km).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在将GPS记录器应用设置为浮动应用程序（一些多任务魔法）后，我得到了GPS和图像数据。（ 🚴 ~9 km）。
- en: I deleted my repository, including all recordings. ( 🚴 ~9 km).
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我删除了我的代码库，包括所有录音。（ 🚴 ~9 km）。
- en: '![](../Images/1ac68dfbce9f423eef306d7a331e9224.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ac68dfbce9f423eef306d7a331e9224.png)'
- en: 'Figure 8: The setup in my bike crate.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：我自行车箱中的设置。
- en: So in total I biked almost 80 km to get useful footage accompanied by GPS data.
    Next, we are going to investigate this two data sources and combine them such
    that we have *A = f(x,y)*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所以总的来说，我骑行了将近80公里，获取了有用的影像和GPS数据。接下来，我们将深入研究这两个数据源，并将它们结合起来，以便我们有* A = f(x,y)*。
- en: Processing the data goodness
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理数据的好处
- en: Now that we have two data sources, we need to massage them into something useful.
    We will first transform the GPS data into our default DataFrame. Next, we will
    convert the video of 4.7GB also into a table of *A* values. This will be some
    decent data reduction 😃.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了两个数据源，我们需要将它们处理成有用的东西。我们将首先把 GPS 数据转换为默认的 DataFrame。接下来，我们还将把 4.7GB 的视频转换为
    *A* 值的表格。这将是一些相当不错的数据缩减 😃。
- en: Converting GPS logger data
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换 GPS 记录数据
- en: 'While the camera on the phone recorded the changing values of the LCD screen,
    the GPS logger app recorded the current latitude and longitude values. These are
    stored with a recording rate of 1Hz in a so called GPX file, for which a nifty
    library in Python exists. It is conveniently called `gpxpy` and after a pip install
    the data can be loaded in a bliss:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当手机上的相机记录 LCD 屏幕的变化值时，GPS 记录器应用程序记录了当前的纬度和经度值。这些值以 1Hz 的记录速率存储在一个所谓的 GPX 文件中，Python
    中有一个巧妙的库可以处理这些文件。它方便地叫做 `gpxpy`，安装后数据可以轻松加载：
- en: 'Code 1: Importing the GPS data and creating a DataFrame. Easy as pie!'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 1：导入 GPS 数据并创建 DataFrame。简直是小菜一碟！
- en: '![](../Images/958214377ec9021b3ac2acb9aa876e7a.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/958214377ec9021b3ac2acb9aa876e7a.png)'
- en: 'Output 1: Sample of the newly created dataset.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 1：新创建数据集的示例。
- en: 'Now we have a DataFrame with 2133 measurements that include latitude, longitude,
    elevation, and time. To check if these coordinates make any sense we could simply
    create a parametric plot using Matplotlib. However, there is another great library
    in Python specifically for maps called `folium`. Lets visualize what I have biked:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个包含 2133 个测量值的 DataFrame，其中包括纬度、经度、海拔和时间。为了检查这些坐标是否合理，我们可以简单地使用 Matplotlib
    创建一个参数图。然而，Python 还有另一个专门用于地图的优秀库，叫做 `folium`。让我们可视化一下我骑行的路线：
- en: 'Code 2: visualizing the GPS coordinates using Folium.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 2：使用 Folium 可视化 GPS 坐标。
- en: '![](../Images/354671e85a07cc33269963801d004edc.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/354671e85a07cc33269963801d004edc.png)'
- en: 'Output 2: A map of the beautiful Enschede and the exact route I biked.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 2：美丽的恩斯赫德地图和我骑行的确切路线。
- en: In the beautiful Folium map where we use “tamen watercolor” tiles we see exactly
    the ring that I biked to collect the data. Before we store the DataFrame to disk,
    we need fix the timezone in the time column. Currently, the timezone is set to
    “z” and I am not sure what that is. To remove any complications, lets localize
    the time.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在美丽的 Folium 地图上，我们使用了“tamen watercolor”图块，正好显示了我骑行以收集数据的路径。在将 DataFrame 存储到磁盘之前，我们需要修正时间列中的时区。目前，时区设置为“z”，我不确定这是什么。为了避免任何复杂性，我们需要本地化时间。
- en: 'Code 3: Correct time and store DataFrame into a Parquet file.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 3：修正时间并将 DataFrame 存储为 Parquet 文件。
- en: The GPS data is ready to be used. Next, we need to process the video footage
    into something useful.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: GPS 数据已经准备好使用了。接下来，我们需要将视频镜头处理成有用的内容。
- en: Creating training set for image detector
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建图像检测器的训练集
- en: We have a video that shows all output of the mystery box during the bike ride.
    We need to extract the *A* value from each frame and its corresponding time. Using
    this time, we can link the *A* value to its GPS location. To extract the *A* value,
    we will train a [DONUT based model](https://arxiv.org/abs/2111.15664). This is
    an end-to-end based model and does not need any optical character recognition
    (OCR). To train a model we need a labeled dataset. First, lets inspect the video
    data using [OpenCV](https://pypi.org/project/opencv-python/).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个视频展示了骑行过程中神秘盒子的所有输出。我们需要从每一帧中提取 *A* 值及其对应的时间。利用这些时间，我们可以将 *A* 值与其 GPS 位置链接起来。为了提取
    *A* 值，我们将训练一个 [基于 DONUT 的模型](https://arxiv.org/abs/2111.15664)。这是一个端到端的模型，不需要任何光学字符识别（OCR）。为了训练模型，我们需要一个标注好的数据集。首先，让我们使用
    [OpenCV](https://pypi.org/project/opencv-python/) 检查视频数据。
- en: 'Code 4: Import video as stream and check frame rate.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 4：将视频作为流导入并检查帧率。
- en: The video was record with a frame rate of 30 frames per second. The duration
    of the video is about 35 minutes so this would mean more than 63k frames. This
    is a bit much, especially due to most GPS sensors for Arduino have a update frequency
    > 1Hz. Therefore, lets only select one frame each second and put them into a regular
    list.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 该视频的帧率为每秒 30 帧。视频的持续时间大约为 35 分钟，因此总帧数会超过 63k。这有点多，特别是因为大多数 Arduino 的 GPS 传感器更新频率大于
    1Hz。因此，我们只选择每秒一帧，并将它们放入一个常规列表中。
- en: 'Code 5: Extract frames from video at a frame rate of 1 FPS.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 5：以每秒 1 帧的帧率从视频中提取帧。
- en: '![](../Images/63438b1f42ff406aeab82accb94a088e.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63438b1f42ff406aeab82accb94a088e.png)'
- en: 'Output 3: a single frame from the video (left) and the final pre-processed
    frame (right).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 3：视频中的单帧（左）和最终预处理的帧（右）。
- en: We have extracted 2119 frames which is already quite a reduction of the original
    63k we started with. When looking at the frame in Output 3 (left) we see that
    a lot of pixel in the frame are not very interesting to us. In our preprocessing
    we will crop the image such that we are only left with the A value. We will also
    reduce the image to black and white which might help with contrast problems later.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提取了2119帧，这已经是从最初的63k帧中减少了相当多。当查看输出3（左侧）的帧时，我们发现帧中的许多像素对我们并不特别有趣。在预处理过程中，我们将裁剪图像，仅保留A值。我们还会将图像转换为黑白，这可能有助于后续的对比度问题。
- en: 'Code 6: preprocess images such that we isolate the A value.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 代码6：预处理图像，以便我们孤立A值。
- en: Now we only need to save the list. This is a relatively easy task to parallelize
    as it is not depended of the previous input, therefore, we use `[joblib](https://joblib.readthedocs.io/en/latest/parallel.html)`
    for this step.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需要保存列表。这是一个相对容易并行化的任务，因为它不依赖于之前的输入，因此我们使用`[joblib](https://joblib.readthedocs.io/en/latest/parallel.html)`来完成这一步。
- en: 'Code 7: Store the images, parallel of course!'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 代码7：存储图像，当然要并行处理！
- en: We now have a dataset, but it is not yet labeled. To label, I have created a
    tool to label data in Jupyter Lab (or Notebook) which is called `[Pigeon-XT](https://github.com/dennisbakhuis/pigeonXT)`.
    It is the extended version of the Pigeon labeling tool created by Anastasis Germanidis.
    We will label 250 examples, which took me about 15 minutes.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了一个数据集，但它尚未标记。为了标记，我创建了一个工具，用于在Jupyter Lab（或Notebook）中标记数据，称为`[Pigeon-XT](https://github.com/dennisbakhuis/pigeonXT)`。这是Anastasis
    Germanidis创建的Pigeon标记工具的扩展版本。我们将标记250个示例，这花了我大约15分钟。
- en: 'Code 8: Label the data comfortably in our Jupyter Notebook.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 代码8：在我们的Jupyter Notebook中舒适地标记数据。
- en: Now we have a labeled dataset. It is small, about 10% of the complete dataset,
    but we should be able to train a model that we can use to fill in the missing
    portion of the set. To make our life easier we can use the `[datasets](https://github.com/huggingface/datasets)`
    library from 🤗 Huggingface. We can import our data with minor adjustments as an
    Imagefolder dataset.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个标记的数据集。虽然它很小，大约占完整数据集的10%，但我们应该能够训练一个模型，用来填补数据集的缺失部分。为了让我们的工作更轻松，我们可以使用🤗
    Huggingface的`[datasets](https://github.com/huggingface/datasets)`库。我们可以通过一些小调整将数据导入为Imagefolder数据集。
- en: 'Code 9: Create a Huggingface datasets dataset object.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 代码9：创建一个Huggingface数据集对象。
- en: '![](../Images/3727d04be9fa2c29c6e6abe8ac2f6eb5.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3727d04be9fa2c29c6e6abe8ac2f6eb5.png)'
- en: 'Output 4: the dataset object makes handling the data very easy. Maybe it would
    even be better doing the transform using its .map() function.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 输出4：数据集对象使数据处理变得非常容易。也许使用其.map()函数进行转换会更好。
- en: Last but not least, we need to save the dataset. What is nice, is to share your
    dataset on the Huggingface hub. This is extremely easy using the `[huggingface_hub](https://github.com/huggingface/huggingface_hub)`
    package. For this you also need an account on the hub. The amazing thing about
    sharing on the hub is that you can now download this dataset without doing all
    the processing I did above.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们需要保存数据集。值得一提的是，可以在Huggingface中心共享你的数据集。使用`[huggingface_hub](https://github.com/huggingface/huggingface_hub)`包非常简单。为此，你还需要一个中心的账户。在中心共享的神奇之处在于，你现在可以下载这个数据集，而无需进行我上面做的所有处理。
- en: 'Code 10: Save the dataset and push the it to the Huggingface hub.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 代码10：保存数据集并将其推送到Huggingface中心。
- en: Now we have everything to train a model to infere the missing labels. Lets do
    some training 🔥🔥🔥!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了训练模型以推断缺失标签的所有条件。让我们开始训练吧🔥🔥🔥！
- en: Training a 🍩 DONUT model
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练一个🍩 DONUT模型
- en: 'We can finally start with training our model. We will be training a [DONUT](https://arxiv.org/abs/2111.15664)
    based model created by [Naver AI Lab](https://naverlabs.com/). DONUT is a true
    end-to-end model. You input an image and you will get a JSON object with key-value
    pairs out. The most amazing part is that it can do this without OCR. Previous
    state of the art methods such as [LayoutLM](https://arxiv.org/abs/2204.08387)
    use a two-step approach: first use OCR to extract all text and their locations
    and second, input an image and text data in a model to extract information.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于可以开始训练我们的模型了。我们将训练一个基于[DONUT](https://arxiv.org/abs/2111.15664)的模型，该模型由[Naver
    AI Lab](https://naverlabs.com/)创建。DONUT是一个真正的端到端模型。你输入一张图像，它将输出一个包含键值对的JSON对象。最令人惊叹的是，它可以在没有OCR的情况下完成这一切。之前的最新方法，如[LayoutLM](https://arxiv.org/abs/2204.08387)，使用了两步法：首先使用OCR提取所有文本及其位置，其次，将图像和文本数据输入模型以提取信息。
- en: The problem with extracting information from documents is that a lot of information
    is encoded in the layout. The human brain understands the relation between data
    when it is presented as a header, in a table, or as a caption. Using OCR methods,
    this information is lost. Methods like LayoutLM use the image to bring back the
    layout information. DONUT can do this in one go and has OCR build in. From what
    I have seen it works quite good but is very sensitive to changes in documents.
    When a document has minor layout changes, but still the same information to extract,
    DONUT fails quite easily.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从文档中提取信息的问题在于，很多信息被编码在布局中。人脑能够理解以标题、表格或标题的形式呈现的数据之间的关系。使用 OCR 方法，这些信息会丢失。像 LayoutLM
    这样的方式利用图像恢复布局信息。DONUT 可以一次性完成这项工作，并且内置了 OCR。从我所看到的，它的效果还不错，但对文档中的变化非常敏感。当文档有微小的布局变化，但要提取的信息仍然相同时，DONUT
    容易失败。
- en: Our images are not really documents, but they have very clear text and are from
    a layout point of view very constant. Therefore, DONUT would be a great (and overkill)
    method to extract the *A* value. I followed the same procedure as CloveAI team
    did in their [repository](https://github.com/clovaai/donut). [Philipp Schmid](https://www.linkedin.com/in/philipp-schmid-a6a2bb196/)
    wrote a [great article](https://www.philschmid.de/fine-tuning-donut) on how to
    train your own DONUT type model. First we need to prepare our dataset for the
    specific DONUT inputs of the model.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的图像实际上不是文档，但它们文本非常清晰，从布局的角度来看也非常一致。因此，DONUT 将是一个极好的（甚至有些过度）提取 *A* 值的方法。我按照
    CloveAI 团队在他们的 [代码库](https://github.com/clovaai/donut) 中所做的相同步骤进行操作。[Philipp Schmid](https://www.linkedin.com/in/philipp-schmid-a6a2bb196/)
    写了一篇 [很棒的文章](https://www.philschmid.de/fine-tuning-donut) 介绍了如何训练自己的 DONUT 类型模型。首先，我们需要为模型的特定
    DONUT 输入准备数据集。
- en: 'Code 11: converting the JSON objects to tokens DONUT expects.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 11：将 JSON 对象转换为 DONUT 期望的令牌。
- en: Now that the data is in the form expected by DONUT we need to tokenize the data.
    This is a step common to transformer language models such as GPT<n> and BERT but
    now also used for images in Vision Transformers (ViT).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已符合 DONUT 的预期格式，我们需要对数据进行分词。这是一个与 GPT<n> 和 BERT 等转换器语言模型共同的步骤，但现在也用于视觉转换器（ViT）中的图像。
- en: 'Code 12: tokenize the data for input into the model.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 12：为模型输入对数据进行分词。
- en: Now we have everything ready to do some actual training 🔥. Nowadays, this is
    incredibly easy as you do not have to write your training loop anymore. While
    I first was a bit sad as it felt quite cool to write the loop, it was quite repetitive.
    Huggingface gives you the trainer object and it is just perfect for the job.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好进行实际训练了 🔥。如今，这非常简单，因为你不再需要编写训练循环了。虽然我起初有些难过，因为编写循环感觉很酷，但它其实非常重复。Huggingface
    提供了训练器对象，它非常适合这项工作。
- en: 'Code 13: the complete code for the training loop has simplified a lot!'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 13：训练循环的完整代码已经简化了很多！
- en: '![](../Images/01876e94ee685cff3e3f7af27f891153.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01876e94ee685cff3e3f7af27f891153.png)'
- en: 'Output 5: training in progress.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 5：训练进行中。
- en: 'After evaluation of the test dataset we get an evaluation loss of 0.007 which
    is pretty descent. From our 38 test examples 37 were detected correctly. The one
    that is incorrect was missing one digit: 059 instead of 1059\. 37/38 makes an
    accuracy of 97% which is probably enough to label the complete set. Before we
    start inferring the missing values, lets save the model and also push it to the
    hub.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试数据集的评估后，我们得到了 0.007 的评估损失，这相当不错。在我们 38 个测试样本中，有 37 个被正确检测出来。唯一一个不正确的是少了一个数字：059
    而不是 1059。37/38 的准确率为 97%，这可能足以标记完整的集合。在我们开始推断缺失值之前，让我们先保存模型并将其推送到中心。
- en: 'Code 14: save the model and push it to the hub.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 14：保存模型并将其推送到中心。
- en: Now lets do some inferring on the missing labels.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们对缺失的标签进行一些推断。
- en: Use model to infer missing data
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用模型推断缺失数据
- en: 'Finally we can use our model to infere the labels. The images are already prepared
    so we can simply use those. The time of each frame is encoded in its filename
    in seconds. There will be a small mismatch as the frame rate is not exactly 30
    frames per second but the difference will be small. Lets first create a function
    to do the inference for us:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们可以使用我们的模型来推断标签。图像已经准备好，所以我们可以直接使用它们。每个帧的时间以秒为单位编码在其文件名中。由于帧率不是精确的每秒 30
    帧，因此会有小的偏差，但差异会很小。让我们首先创建一个函数来为我们进行推断：
- en: 'Code 15: code for inferring an image.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 15：推断图像的代码。
- en: We could now do inference on each image one by one, however, that would take
    about an hour. Lets do this in parallel but this is far from trivial. For simple
    things, `joblib` is great. However, when using models, serializing large models
    for each iteration makes it slower then doing them just one-by-one. To solve this
    problem I wrote `[tqdm_batch](https://github.com/dennisbakhuis/tqdm_batch)` a
    while ago.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以对每张图片逐一进行推断，但这将花费大约一个小时。让我们并行处理，但这远非简单。对于简单的任务，`joblib` 很棒。然而，在使用模型时，为每次迭代序列化大型模型会比逐个处理更慢。为了解决这个问题，我之前编写了
    `[tqdm_batch](https://github.com/dennisbakhuis/tqdm_batch)`。
- en: Parallel jobs are not trivial. Read my [article](/parallel-batch-processing-in-python-8dcce607d226)🏃🏻💨!
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 并行作业并非易事。阅读我的 [文章](/parallel-batch-processing-in-python-8dcce607d226)🏃🏻💨！
- en: 'Code 16: parallelize the inference step and divide the work between four workers.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 16：并行化推断步骤，并将工作分配给四个工作者。
- en: '![](../Images/427bcf6a9366233992535bfc7428cb41.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/427bcf6a9366233992535bfc7428cb41.png)'
- en: 'Output 6: running 4 workers in parallel using tqdm_batch.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 6：使用 tqdm_batch 运行 4 个工作者并行处理。
- en: Now that we have our A values from the box, we can build our final dataset and
    combine it with GPS data. As always, the prediction was not perfect and we have
    to do some massaging. As a data scientist you actual are an data masseuse.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了来自盒子的 A 值，我们可以构建最终的数据集并将其与 GPS 数据结合起来。像往常一样，预测并不完美，我们需要做一些调整。作为数据科学家，你实际上是一个数据按摩师。
- en: 'Code 15: basic cleaning of or dataset.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 15：对数据集进行基本清理。
- en: Almost there, the only problem are the wrongly detected A values. These can
    be filtered using a rolling filter. We will remove values that have a greater
    difference than 5 meter (arbitrary small number) from the moving average and interpolate
    them with the values left.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎完成了，唯一的问题是错误检测到的 A 值。这些可以使用滚动滤波器进行过滤。我们将删除与移动平均值差异超过 5 米（任意小数）的值，并用剩余值进行插值。
- en: 'Code 16: filtering the noisy data using a moving average filter and an interpolate.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 16：使用移动平均过滤器和插值来过滤噪声数据。
- en: '![](../Images/a7371184d7dcaeb9a64007b84af971b1.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7371184d7dcaeb9a64007b84af971b1.png)'
- en: 'Output 7: final result after applying the filter. Pretty neat!'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 7：应用过滤器后的最终结果。相当不错！
- en: This filtering looks pretty neat. Now we are ready to combine this dataset with
    our previously recorded GPS data.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过滤效果相当不错。现在我们准备将这个数据集与之前记录的 GPS 数据结合起来。
- en: Combining the image and GPS data
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结合图像和 GPS 数据
- en: Combining the A value to the GPS data should not be much of a problem. For each
    row in the GPS dataset we will look for the closest match in time and use the
    A value of that row.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 将 A 值与 GPS 数据结合应该不成问题。对于 GPS 数据集中的每一行，我们将寻找时间上最接近的匹配，并使用该行的 A 值。
- en: 'Code 17: Adding the *A* value to the gps dataset.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 17：将 *A* 值添加到 GPS 数据集中。
- en: This is it! So much effort which was probably never really needed. But we used
    machine learning and that is the only thing that matters!
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了！付出了很多努力，可能其实并不必要。但我们使用了机器学习，这才是最重要的！
- en: we used machine learning and that is the only thing that matters!
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们使用了机器学习，这才是最重要的！
- en: Next, we will use this dataset and try to find the goal coordinate.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用这个数据集并尝试找到目标坐标。
- en: Analyze the dataset and find the goal
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析数据集并找到目标
- en: As previously discussed, we will try to find the two unknown locations *p1*
    and *p2*. If we know these two points, we will also know the goals location which
    should be exactly between those points. To find the locations, we will use the
    `[minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)`
    form `[Scipy](https://scipy.org/)`. While I could write my own Haversine function
    I will just use the `[haversine](https://github.com/mapado/haversine)` package.
    To use `minimize` we need to write an error function. This function will calculate
    the difference between the known *A* and the calculated A for all our values in
    the dataset and sum the absolute differences. The minimize function should minimize
    this error.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将尝试找到两个未知位置 *p1* 和 *p2*。如果我们知道这两个点，我们也将知道目标位置，它应该正好在这两个点之间。为了找到这些位置，我们将使用
    `[minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)`
    来自 `[Scipy](https://scipy.org/)`。虽然我可以自己编写 Haversine 函数，但我将直接使用 `[haversine](https://github.com/mapado/haversine)`
    包。要使用 `minimize`，我们需要编写一个误差函数。这个函数将计算已知的 *A* 和计算出的 A 之间的差异，并对数据集中的所有值求绝对差异的总和。最小化函数应该最小化这个误差。
- en: 'Code 18: lets minimize this shit.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 代码 18：让我们最小化这个问题。
- en: '![](../Images/6a1c1bd318ca766a86d5c51dd0240e0b.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a1c1bd318ca766a86d5c51dd0240e0b.png)'
- en: 'Output 8: The final solution (green) is exactly between points p1 and p2 (blue).
    The goal is also on the perpendicular line of my found zero points.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 8：最终解决方案（绿色）正好位于点 p1 和 p2（蓝色）之间。目标也在我找到的零点的垂直线上。
- en: This is it, I have found the location. The goal is exactly between points p1
    and p2\. This point also connects to a perpendicular line between my previously
    found zero points. But the biggest hint is that the goal location is a [BBQ restaurant](https://marcook.nl/).
    Sander and I are very fond of burgers and this place has a great selection of
    those.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样，我找到了位置。目标正好位于点 p1 和 p2 之间。这个点也连接到我之前找到的零点之间的垂直线上。但最大的提示是目标位置是一家 [BBQ 餐厅](https://marcook.nl/)。桑德和我都很喜欢汉堡，而这个地方有很棒的选择。
- en: '![](../Images/0987263246d81a45b333f840195534f8.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0987263246d81a45b333f840195534f8.png)'
- en: 'Output 9: The difference between my found coordinate and the actual goal is
    93 meters.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 9：我找到的坐标与实际目标之间的差异是 93 米。
- en: The deviation from the actual point and the one I found is 93 meters. This could
    have many reasons. First, the extracted A value only has round numbers. While
    this has an effect, I suspect that this is only a minor effect which should negligible
    when averaging over a larger dataset. Of course, the filtering (smoothing) has
    an effect. Maybe there is some noise added on purpose, not sure if I could have
    noticed that. Anyhow, I am pretty happy with the result.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 实际点与我找到的点之间的偏差是 93 米。这可能有很多原因。首先，提取的 A 值只有整数。这确实有影响，但我怀疑这只是一个较小的影响，平均在较大的数据集上应该可以忽略。当然，过滤（平滑）也有影响。也许故意添加了一些噪声，不确定我是否能注意到。总之，我对结果相当满意。
- en: Going to the location
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前往位置
- en: It took quite some time but now I am finally certain where to location is. I
    took the car and drove to Marcook, a BBQ restaurant just outside of Enschede.
    If I would turn on the mystery box in that location it should show me the code
    to unlock its mysteries.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 花了相当长的时间，但现在我终于确定了位置。我开车去了 Marcook，一家位于恩斯赫德外的烧烤餐厅。如果我在那个位置打开神秘盒子，它应该会显示解锁其谜团的代码。
- en: '![](../Images/9aed31317a2c5f446f5c0642f045d5f7.png)![](../Images/212bb3e05852d0b2e28b7cc236b3b814.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9aed31317a2c5f446f5c0642f045d5f7.png)![](../Images/212bb3e05852d0b2e28b7cc236b3b814.png)'
- en: 'Figure 9: the mystery box unlocks all its mysteries.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：神秘盒子解锁了所有的谜团。
- en: 'Indeed, after waiting a couple of minutes to get a GPS fix the box almost instantly
    responded with ‘proficiat’. Congratulations for making it this far. The next screen
    of the device shows the code: 7631.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，等待了几分钟以获得 GPS 定位后，盒子几乎立刻回应了‘proficiat’。祝贺你走到这一步。设备的下一个屏幕显示代码：7631。
- en: To be honest, this was not an easy challenge. But it was a fun journey and in
    the end we are gonna eat some burgers. Can hardly get any better.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 老实说，这不是一个简单的挑战。但这是一次有趣的旅程，最后我们会吃一些汉堡。几乎没什么能比这更好。
- en: All code for this project is on [Github](https://github.com/dennisbakhuis/mystery_box).
    Most of the smaller datasets are included in the Git repository however the larger
    video is shared through my Dropbox. The dataset used for the ViT training, the
    DONUT processor, and the DONUT model are also shared on the 🤗 [Huggingface hub](https://huggingface.co/bakhuisdennis).
    If you have any questions, feel free to contact me on [LinkedIn](https://linkedin.com/in/dennisbakhuis).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此项目的所有代码都在 [Github](https://github.com/dennisbakhuis/mystery_box) 上。大部分较小的数据集包含在
    Git 仓库中，但较大的视频通过我的 Dropbox 共享。用于 ViT 训练的 dataset、DONUT 处理器和 DONUT 模型也在 🤗 [Huggingface
    hub](https://huggingface.co/bakhuisdennis) 上共享。如果你有任何问题，欢迎通过 [LinkedIn](https://linkedin.com/in/dennisbakhuis)
    联系我。
- en: Last but not least, I want to thank 🙏 *Sander* for the fun experience. I am
    sorry I took so long, but I guess I over-killed it a bit. It sure was fun! Burgers?
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我要感谢 🙏 *桑德* 给予的有趣体验。对不起我花了这么长时间，但我想我有点过度了。这确实很有趣！汉堡？
