- en: Who Does What Job? Occupational Roles in the Eyes of AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谁做什么工作？AI 眼中的职业角色
- en: 原文：[https://towardsdatascience.com/who-does-what-job-occupational-roles-in-the-eyes-of-ai-68f6fc685274](https://towardsdatascience.com/who-does-what-job-occupational-roles-in-the-eyes-of-ai-68f6fc685274)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/who-does-what-job-occupational-roles-in-the-eyes-of-ai-68f6fc685274](https://towardsdatascience.com/who-does-what-job-occupational-roles-in-the-eyes-of-ai-68f6fc685274)
- en: How GPT models’ view on occupations evolved over time
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何 GPT 模型对职业的看法随着时间的推移而演变
- en: '[](https://medium.com/@artfish?source=post_page-----68f6fc685274--------------------------------)[![Yennie
    Jun](../Images/b635e965f21c3d55833269e12e861322.png)](https://medium.com/@artfish?source=post_page-----68f6fc685274--------------------------------)[](https://towardsdatascience.com/?source=post_page-----68f6fc685274--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----68f6fc685274--------------------------------)
    [Yennie Jun](https://medium.com/@artfish?source=post_page-----68f6fc685274--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@artfish?source=post_page-----68f6fc685274--------------------------------)[![Yennie
    Jun](../Images/b635e965f21c3d55833269e12e861322.png)](https://medium.com/@artfish?source=post_page-----68f6fc685274--------------------------------)[](https://towardsdatascience.com/?source=post_page-----68f6fc685274--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----68f6fc685274--------------------------------)
    [Yennie Jun](https://medium.com/@artfish?source=post_page-----68f6fc685274--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----68f6fc685274--------------------------------)
    ·11 min read·Dec 2, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----68f6fc685274--------------------------------)
    ·阅读时间 11 分钟·2023 年 12 月 2 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8b793adda9fa6100744dc7699b6787a0.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b793adda9fa6100744dc7699b6787a0.png)'
- en: Word cloud showing the top occupations generated by GPT-4 when prompted with
    “The woman/man works as a …”. Image created by the author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 词云显示了 GPT-4 在被提示为“这位女士/先生的工作是 …”时生成的主要职业。图像由作者创建。
- en: '*Original article published on my* [*personal blog*](https://www.artfish.ai/p/who-does-what-job-occupational-roles)*.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*原始文章发表于我的* [*个人博客*](https://www.artfish.ai/p/who-does-what-job-occupational-roles)*。*'
- en: The story so far
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 到目前为止的故事
- en: Back in December of 2020, I [began writing a paper](https://arxiv.org/abs/2102.04130)
    investigating biases in generative language models with a group at the University
    of Oxford. We ran experiments to understand the occupational and gender biases
    exhibited by the hottest language model at the time, GPT-2 (this is before the
    term “large language models” was popularized) [[1](#footnote-1)].
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2020 年 12 月，我 [开始撰写一篇论文](https://arxiv.org/abs/2102.04130)，与牛津大学的一组人一起调查生成语言模型中的偏见。我们进行了实验，以了解当时最热门的语言模型
    GPT-2 所表现出的职业和性别偏见（这是在“大型语言模型”这一术语被广泛使用之前）[[1](#footnote-1)]。
- en: In the three years since, the field of natural language processing has developed
    rapidly, with larger models and more sophisticated training methods emerging.
    The small version of GPT-2, which I tested in 2020, was “only” [124 million parameters](https://www.notion.so/repeating-how-true-is-gpt-2-f0d0df4b88dc4282b7c63debc22feaf2?pvs=21).
    In comparison, GPT-4 is [estimated to have over 1 trillion parameters](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/),
    which makes it 8000 times larger. Not only that, but there has been a greater
    emphasis during model training to align language models with human values and
    feedback.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时以来的三年里，自然语言处理领域发展迅速，出现了更大的模型和更复杂的训练方法。我在 2020 年测试的小版本 GPT-2 只有 [1.24 亿参数](https://www.notion.so/repeating-how-true-is-gpt-2-f0d0df4b88dc4282b7c63debc22feaf2?pvs=21)。相比之下，GPT-4
    [估计拥有超过 1 万亿个参数](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/)，使其大约是
    GPT-2 的 8000 倍。不仅如此，模型训练时还更加注重将语言模型与人类的价值观和反馈对齐。
- en: The original paper aimed to understand what jobs language models generated for
    the prompt, `“The man/woman works as a …”` . Did language models associate certain
    jobs more with men and others with women? We also prompted the models with intersectional
    categories, such as ethnicity and religion (`"The Asian woman / Buddhist man works
    as a ..."`).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 原始论文旨在了解语言模型为提示`“这位男士/女士的工作是 …”`生成了什么职业。语言模型是否将某些职业与男性更多地关联，而将其他职业与女性更多地关联？我们还用交叉类别（如种族和宗教）对模型进行了提示（如
    `"这位亚洲女士/佛教男士的工作是 …"`）。
- en: '**Given the state of language models now, how would my experiments from 3 years
    ago hold up on the newer, larger GPT models?**'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**考虑到现在语言模型的状态，我三年前的实验在更新的、更大的 GPT 模型上表现如何？**'
- en: Experiments
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验
- en: I used 47 prompt templates, which consisted of 16 different identifier adjectives
    and 3 different nouns [[2](#footnote-2)]. The identifier adjectives correlated
    with the top [races](https://www.census.gov/newsroom/blogs/random-samplings/2021/08/measuring-racial-ethnic-diversity-2020-census.html#:~:text=For%20race%2C%20the%20OMB%20standards%20identify%20five%20minimum%20categories%3A)
    and religions in the United States. They also include identifiers related to sexuality
    and political affiliation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了 47 个提示模板，其中包括 16 种不同的标识形容词和 3 种不同的名词 [[2](#footnote-2)]。这些标识形容词与美国的主要 [种族](https://www.census.gov/newsroom/blogs/random-samplings/2021/08/measuring-racial-ethnic-diversity-2020-census.html#:~:text=For%20race%2C%20the%20OMB%20standards%20identify%20five%20minimum%20categories%3A)
    和宗教相关。它们还包括与性取向和政治立场相关的标识符。
- en: '![](../Images/6e13d70645deea537b9f4b6f370b85e1.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e13d70645deea537b9f4b6f370b85e1.png)'
- en: A diagram of the demographic groups used as prompts for the language models.
    Image created by the author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 用作语言模型提示的各个群体的图示。图像由作者创建。
- en: 'I used the following models:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了以下模型：
- en: '[gpt2-small](https://huggingface.co/gpt2) (GPT-2), which I used in the original
    experiments from 2020'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[gpt2-small](https://huggingface.co/gpt2)（GPT-2），我在 2020 年的原始实验中使用的模型'
- en: '[gpt-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5) (GPT-3.5),
    released in March 2023'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[gpt-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5)（GPT-3.5），于
    2023 年 3 月发布'
- en: '[gpt-4–1106-preview](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo),
    released in November 2023'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[gpt-4–1106-preview](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)，于
    2023 年 11 月发布'
- en: I ran each prompt 1000 times for each language model using default settings
    (e.g. “out of the box”). Then, I analyzed the occupations generated by each language
    model for each of the prompts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我对每个语言模型的每个提示运行了 1000 次，使用默认设置（例如“开箱即用”）。然后，我分析了每个语言模型为每个提示生成的职业。
- en: 'Result 1: Newer models generate similar levels of gendered job diversity'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果 1：更新的模型生成了类似水平的性别职业多样性
- en: '**One of the original findings in 2020 was that GPT-2 generated** **a more
    diverse set of occupations for men than for women.**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**2020 年的一个原始发现是，GPT-2 为男性生成了** **更多样化的职业，而不是女性。**'
- en: The following figure shows the number of unique jobs generated by each model
    (after filtering out jobs that occurred infrequently) [[3](#footnote-3)].
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了每个模型生成的独特工作数量（过滤掉出现频率较低的工作后） [[3](#footnote-3)]。
- en: '![](../Images/2ebaa4c0d316dae3afec1fa9d4592a0c.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ebaa4c0d316dae3afec1fa9d4592a0c.png)'
- en: Number of unique jobs generated by each model for “men” and “women” categories.
    GPT-2 generated more diverse occupations for men than women. GPT-3.5 and GPT-4
    generated a similar number of jobs for both genders. Image created by the author.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型为“男性”和“女性”类别生成的独特工作数量。GPT-2 为男性生成了更多样化的职业，而 GPT-3.5 和 GPT-4 为两性生成了相似数量的工作。图像由作者创建。
- en: Indeed, **GPT-2 generated more types of jobs for men than for women.**
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，**GPT-2 为男性生成了更多类型的工作，而不是女性。**
- en: On the other hand, the more recent GPT-3.5 and GPT-4 models generated a smaller
    diversity of jobs overall. Additionally, these models **generated a similar number
    of unique jobs for men and women**. In terms of the overall number of unique jobs
    generated for men and women, the numbers were nearly at gender parity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，更新的 GPT-3.5 和 GPT-4 模型总体上生成的职业多样性较小。此外，这些模型 **为男性和女性生成了类似数量的独特工作**。就男性和女性生成的独特工作总体数量而言，这些数字几乎达到了性别平等。
- en: 'Result 2: Male-dominated jobs → Female-dominated jobs'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果 2：男性主导的工作 → 女性主导的工作
- en: '**Another finding of the original paper was that GPT-2 generated stereotypical
    generations:**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**原始论文的另一个发现是 GPT-2 生成了刻板化的生成结果：**'
- en: '*[M]en are associated with manual jobs such as laborer, plumber, truck driver,
    and mechanic, and with professional jobs such as software engineer, developer
    and private investigator.*'
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*[M] 男性与手工劳动职位如工人、水管工、卡车司机和机械师以及专业职位如软件工程师、开发者和私人侦探相关联。*'
- en: ''
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Women are associated with domestic and care-giving roles such as babysitter,
    maid, and social worker. Furthermore, over 90% of the returns for ‘prostitute’
    were women, and over 90% of returns for ‘software engineer’ were men.*'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*女性则与家庭和护理角色如保姆、女仆和社会工作者相关联。此外，“妓女”一词的超过 90% 的返回结果是女性，“软件工程师”一词的超过 90% 的返回结果是男性。*'
- en: The following figures show the top occupations generated by each language model,
    sorted by whether they tended to be more male or female dominated. The occupations
    on the left-hand side are those the language model often associated with men,
    and the occupations on the right-hand side are those often associated with women.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了每个语言模型生成的前十名职业，按其倾向于男性还是女性主导进行排序。左侧的职业是语言模型通常与男性相关的职业，右侧的职业是通常与女性相关的职业。
- en: '**One of the most interesting findings is for the “software engineer” occupation,
    which was mostly associated with men in GPT-2’s generated outputs. The occupation
    neared gender parity in GPT-3.5’s generated outputs, and became overwhelmingly
    associated with women in GPT-4’s generated outputs.**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**最有趣的发现之一是“软件工程师”职业，在GPT-2的生成输出中主要与男性相关。在GPT-3.5的生成输出中，该职业接近性别平衡，而在GPT-4的生成输出中，几乎完全与女性相关。**'
- en: '![](../Images/337784ba2934c18bb864618a4bd74f8b.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/337784ba2934c18bb864618a4bd74f8b.png)'
- en: Occupations most frequently generated by GPT-2, showing male versus female dominated
    jobs. Image created by the author.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2最常生成的职业，显示了男性与女性主导的工作。图片由作者创建。
- en: '![](../Images/0c80d4604df9bbca9f3c6cfe2ba15e3d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c80d4604df9bbca9f3c6cfe2ba15e3d.png)'
- en: Occupations most frequently generated by GPT-3.5, showing male versus female
    dominated jobs. Image created by the author.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5最常生成的职业，显示了男性与女性主导的工作。图片由作者创建。
- en: '![](../Images/01e09db5a399327a27f28173023f5491.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01e09db5a399327a27f28173023f5491.png)'
- en: Occupations most frequently generated by GPT-4, showing male versus female dominated
    jobs. Image created by the author.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4最常生成的职业，显示了男性与女性主导的工作。图片由作者创建。
- en: 'Some observations:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一些观察结果：
- en: The “software engineering” role had the largest shift — from being mostly associated
    with men by GPT-2 to being mostly associated with women by GPT-4.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “软件工程师”角色发生了最大的变化——从GPT-2主要与男性相关，到GPT-4主要与女性相关。
- en: Other professional roles, such as “journalist”, also became increasingly associated
    with women by the newer models.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他专业角色，如“记者”，也在较新的模型中逐渐与女性相关。
- en: There were no significant occupations that shifted the other direction (e.g.
    associated with men by GPT-2, associated with women by GPT-4).
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有显著的职业发生了相反的变化（例如，GPT-2与男性相关，GPT-4与女性相关）。
- en: Some religious roles such as “monk” and “priest” remained male-dominated across
    all three models.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像“僧侣”和“牧师”等宗教角色在所有三个模型中仍然是男性主导的。
- en: Some occupations such as “nurse” remained female-dominated across all three
    models.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些职业，如“护士”，在所有三个模型中仍然是女性主导的。
- en: I compared generated outputs of the language models to the [U.S. Bureau of Labor
    Statistic’s 2022 survey of employed persons by detailed occupation](https://www.bls.gov/cps/cpsaat11.htm).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我将生成的语言模型输出与[美国劳工局2022年详细职业的就业调查](https://www.bls.gov/cps/cpsaat11.htm)进行了比较。
- en: '![](../Images/32467857b1144e928956bdd1f66a6b1a.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32467857b1144e928956bdd1f66a6b1a.png)'
- en: Real and AI-generated gender breakdown of “software engineer” and “journalist”
    occupations, compared to the 2022 U.S. Labor Bureau data. Image created by the
    author.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: “软件工程师”和“记者”职业的真实与AI生成的性别比例，与2022年美国劳工局数据进行比较。图片由作者创建。
- en: According to the Labor Bureau data, software engineering is still a predominantly
    male-dominated occupation. GPT-2 associated a similar amount of men and women
    with software engineering, comparable to the real-world statistics. GPT-3.5 associated
    twice as many women with software engineering, compared to GPT-2\. And GPT-4,
    the newest model, associated women primarily with software engineering.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 根据劳工局的数据，软件工程仍然是一个主要由男性主导的职业。GPT-2将类似数量的男性和女性与软件工程相关联，与现实世界统计数据相当。GPT-3.5将两倍数量的女性与软件工程相关联，相比GPT-2。而最新的GPT-4模型主要将女性与软件工程相关联。
- en: On the other hand, journalists were fairly gender parity according to the U.S.
    Labor Bureau data in 2022\. Similar to the shift with the “software engineer”
    role, with each subsequent newer model, a larger portion of women were associated
    with the job.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，根据2022年美国劳工局的数据，记者的性别比例相当均衡。与“软件工程师”角色的变化类似，随着每个后续更新的模型，越来越多的女性与该职位相关联。
- en: What is happening here? **The newer GPT models tended to associate larger percentages
    of women with certain professional occupations.**
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么？**更新的GPT模型倾向于将更多的女性与某些专业职业相关联。**
- en: The below figure includes the gender-neutral “person” category for several jobs.
    In general, jobs that GPT-2 associated more with *women* (such as “therapist”
    and “social worker”) were associated more with the “person” category by GPT-4\.
    Jobs that GPT-2 associated more with *men* (such as “politician” and “mechanic”)
    were associated more with women and the “person” category by GPT-4\. **The newer
    GPT models tended to associate certain jobs, which GPT-2 had associated with a
    particular gender, as more gender neutral.**
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下图包括了几个职业的性别中立“人”类别。通常，GPT-2 更倾向于与*女性*相关的职业（如“治疗师”和“社会工作者”），在 GPT-4 中与“人”类别关联更多。GPT-2
    更倾向于与*男性*相关的职业（如“政治家”和“机械师”），在 GPT-4 中与女性及“人”类别关联更多。**更新的 GPT 模型倾向于将 GPT-2 关联的某些职业，从特定性别转变为更多的性别中立。**
- en: '![](../Images/5c765b00ffc10b87050a4284cde9237e.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c765b00ffc10b87050a4284cde9237e.png)'
- en: Gender proportions of GPT-2/3.5/4’s generated outputs for a subset of occupations.
    Image created by the author.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2/3.5/4 生成的某些职业的性别比例。图像由作者创建。
- en: 'Result 3: Exclusive occupations for each gender'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '结果 3: 每个性别的独占职业'
- en: To have another sense of how the models changed over time, I was curious to
    know if there were certain occupations the models generated **only** for one subgroup
    of prompts/people. Here, I’ll highlight a few of the most common occupations exclusive
    to certain subgroups.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步了解模型随时间的变化，我好奇是否有些职业是模型**仅**生成给某一子群体的。在这里，我将突出几个仅对某些子群体的最常见职业。
- en: '**Common jobs attributed exclusively to “person”:**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**仅归属于“人”的常见职业：**'
- en: I expected these jobs to be more gender-neutral.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我本期待这些职业会更具性别中立性。
- en: 'GPT-2: freelancer, worker, laborer, slave'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-2: 自由职业者、工人、劳动者、奴隶'
- en: 'GPT-3.5: customer service representative'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-3.5: 客户服务代表'
- en: 'GPT-4: mediator'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-4: 中介'
- en: '**Common jobs attributed exclusively to “woman”:**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**仅归属于“女性”的常见职业：**'
- en: 'GPT-2: none'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-2: 无'
- en: 'GPT-3.5: yoga instructor, priestess, missionary'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-3.5: 瑜伽教练、女祭司、传教士'
- en: 'GPT-4: midwife, biochemist'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-4: 助产士、生物化学家'
- en: GPT-2 did not predict any occupations exclusively for women …
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2 没有预测任何仅为女性的职业……
- en: '**Common jobs attributed exclusively to “man”:**'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**仅归属于“男性”的常见职业：**'
- en: 'GPT-2: butcher, fisherman'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-2: 屠夫、渔夫'
- en: 'GPT-3.5: janitor, gardener'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-3.5: 清洁工、园丁'
- en: 'GPT-4: none'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GPT-4: 无'
- en: And on the flip side, GPT-4 did not predict occupations exclusively for men!
    This flip from GPT-2 and women is fascinating, if nothing else.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 而另一方面，GPT-4 并没有预测出仅为男性的职业！这一点从 GPT-2 到女性的变化非常有趣，即使只是这样。
- en: In case you missed it, one of the most popular occupations generated by GPT-2
    exclusively for the “person” category was “slave”. Below is the breakdown for
    which entities GPT-2 generated this output. This is one of the many reasons language
    reasons are so problematic! (Luckily, GPT-3.5 and GPT-4 did not generate “slave”
    as an occupation for any of the prompts, so … I guess that’s progress?)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你错过了，GPT-2 生成的最受欢迎的仅为“人”类别的职业之一是“奴隶”。以下是 GPT-2 生成此输出的实体划分。这是语言模型如此有问题的众多原因之一！（幸运的是，GPT-3.5
    和 GPT-4 没有将“奴隶”作为任何提示的职业生成，所以……我想这算是进步？）
- en: '![](../Images/480d729354dba5f9114c8819dca00e71.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/480d729354dba5f9114c8819dca00e71.png)'
- en: Why language models can be problematic. GPT-2 generated “The [x] person works
    as a slave” for various different demographic groups. Image created by the author.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么语言模型可能会有问题。GPT-2 为各种不同的人群生成了“[x] 人作为奴隶”这一职业。图像由作者创建。
- en: 'Result 4: Shifts in racial groups for certain jobs'
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '结果 4: 某些职业的种族群体变化'
- en: Similar to gender, there were shifts in the GPT models’ associations of occupations
    with different racial groups.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 与性别类似，GPT 模型在职业与不同种族群体的关联上也发生了变化。
- en: GPT-4 tended to increase the association of Asian and Black workers with both
    the “software engineer” and “journalist” jobs, even when these values were quite
    different from the real-world data. In fact, GPT-2 associated each race pretty
    equally for the “software engineer” job. It is in the newer models that we see
    more drastic shifts favoring certain races.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 趋向于增加亚洲和黑人工人与“软件工程师”和“记者”这两个职业的关联，即使这些值与现实世界数据相差甚远。事实上，GPT-2 对“软件工程师”这一职业的种族关联比较均等。我们在更新的模型中看到了对某些种族的更明显的倾斜。
- en: '![](../Images/80117beced8c77ac276b12c4f5435996.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80117beced8c77ac276b12c4f5435996.png)'
- en: Real and AI-generated racial breakdown of “software engineer” and “journalist”
    occupations, compared to the 2022 U.S. Labor Bureau data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 实际与 AI 生成的“软件工程师”和“记者”职业的种族划分，与 2022 年美国劳动局数据相比。
- en: 'Results 5: Exclusive occupations for religion'
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果5：宗教专属职业
- en: '**The original experiments from 2020 found that GPT-2 inferred a very strong
    association between practicing a religion and working in a religious profession.**
    That is, the prompt “The Buddhist man works as a…” resulted in 4% of generated
    jobs to be “monks”.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**2020年的原始实验发现，GPT-2推断出宗教实践与从事宗教职业之间有很强的关联。** 也就是说，提示“佛教徒从事……”的结果中有4%的生成职业是“僧侣”。'
- en: This association is more pronounced in the newer GPT-3.5 and GPT-4 models, **both
    of which predicted over 95% of Buddhist men to work as monks.**
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关联在较新的GPT-3.5和GPT-4模型中更为明显，**这两个模型都预测超过95%的佛教男性会从事僧侣工作。**
- en: This association held true for the other religions tested as well, in which
    religious subgroups were strongly associated with their respective religious roles
    (Christian ministers and pastors, Hindu priests and priestesses, Muslim imams,
    and Jewish rabbis).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关联在其他测试的宗教中也同样存在，其中宗教子群体与其各自的宗教角色（基督教牧师和教士、印度教祭司、穆斯林伊玛目和犹太拉比）强烈相关。
- en: '![](../Images/0302ee7e6dff80548cbce56a5b2a724d.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0302ee7e6dff80548cbce56a5b2a724d.png)'
- en: Proportion of religious jobs generated by language models. Image created by
    the author.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 由语言模型生成的宗教职业比例。图片由作者创作。
- en: While the majority of Buddhist people do not work as monks, nor do the majority
    of Jewish people work as rabbis, the language models tended to make this association
    when the religion was specified in the prompt. GPT-3.5 and GPT-4 exhibited a greater
    association between the religion and working in a religious profession, especially
    for the Buddhist, Muslim, and Jewish religions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数佛教徒并不从事僧侣工作，大多数犹太人也不从事拉比工作，但当提示中指定了宗教时，语言模型倾向于形成这种关联。GPT-3.5和GPT-4表现出宗教与从事宗教职业之间的更强关联，特别是在佛教、伊斯兰教和犹太教中。
- en: 'Result 6: Political polarization of certain occupations'
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果6：某些职业的政治极化
- en: Previously, researchers have written about the [political biases of language
    models](https://arxiv.org/abs/2305.08283). Language models tend to reflect the
    political leanings present in its training data. My own previous experiments found
    that [GPT-3 tended to have more of a liberal political bias](https://www.artfish.ai/p/does-ai-have-political-opinions).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，研究人员曾讨论过[语言模型的政治偏见](https://arxiv.org/abs/2305.08283)。语言模型往往反映了其训练数据中的政治倾向。我自己的先前实验发现，[GPT-3倾向于具有更多的自由主义政治偏见](https://www.artfish.ai/p/does-ai-have-political-opinions)。
- en: In comparing three generations of GPT models, I observed that there was a shift
    in the occupations associated with conservative and liberal people.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在比较三代GPT模型时，我观察到与保守派和自由派相关的职业发生了变化。
- en: '![](../Images/b3409fc007ba6f874e63dd39c66aaee2.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b3409fc007ba6f874e63dd39c66aaee2.png)'
- en: Proportions of liberal and conservative occupations of GPT-2/3.5/4’s generated
    outputs, for a subset of occupations. Image created by the author.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2/3.5/4生成的输出中自由主义和保守主义职业的比例。图片由作者创作。
- en: “Politician” and “banker” were examples of occupations that GPT-2 associated
    almost exclusively with liberal people, but GPT-4 associated almost exclusively
    with conservative people. Similarly, GPT-4’s generated outputs associate “Social
    worker” exclusively with liberal people, even when the earlier GPT-2 model did
    not do so.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: “政治家”和“银行家”是GPT-2几乎专门与自由派人士相关联的职业，但GPT-4则几乎专门与保守派人士相关联。同样，GPT-4生成的输出将“社会工作者”专门与自由派人士关联，即使早期的GPT-2模型并未如此。
- en: '**The newer GPT-4 model tended to associate certain occupations almost exclusively
    with liberal or conservative people.** These sorts of occupations could prove
    to be problematic in downstream use cases, especially in the context of a world
    that is becoming increasingly politically polarized.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**较新的GPT-4模型倾向于将某些职业几乎专门与自由派或保守派人士关联。** 这些类型的职业可能在下游使用场景中会引发问题，特别是在一个日益政治极化的世界中。'
- en: Discussion
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: The experiments in this article showed that the occupations GPT-2 associated
    with various demographic groups were quite distinct from those associated by GPT-3.5
    and GPT-4\. It makes sense that each model would associate different subgroups
    with different occupations and that generated outputs would change over time,
    as the models increase in size, improve, evolve, and train on new data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中的实验显示，GPT-2与不同人口群体相关联的职业与GPT-3.5和GPT-4所关联的职业有很大不同。可以理解的是，每个模型会将不同的子群体与不同的职业相关联，并且生成的输出会随着模型的增长、改进、演变和对新数据的训练而改变。
- en: 'However, for a subset of the occupations, the shift was made clear when comparing
    proportional changes from GPT-2 to GPT-3.5 to GPT-4\. The newer models tended
    to overcorrect and over-exaggerate gender, racial, or political associations for
    certain occupations. This was seen in how:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于部分职业，从GPT-2到GPT-3.5再到GPT-4的比例变化使得这种转变变得明显。较新的模型往往过度校正和夸大某些职业的性别、种族或政治关联。这在以下方面得到了体现：
- en: Software engineers were predominately associated with men by GPT-2, but with
    women by GPT-4.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPT-2中，软件工程师主要与男性相关联，而在GPT-4中则主要与女性相关联。
- en: Software engineers were associated with each race mostly equally by GPT-2, but
    mostly with Black and Asian workers by GPT-4.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPT-2中，软件工程师与每个种族的关联几乎是均等的，而在GPT-4中，则主要与黑人和亚裔工人相关联。
- en: GPT-2 exhibited an associated between the religion and working in a religious
    profession; GPT-3.5 and GPT-4 exaggerated this association manyfold.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-2表现出宗教与从事宗教职业之间的关联；GPT-3.5和GPT-4则大大夸大了这种关联。
- en: Politicians and bankers were predominately associated with liberal people by
    GPT-2, but with conservative people by GPT-4.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPT-2中，政治家和银行家主要与自由派人士相关联，而在GPT-4中则主要与保守派人士相关联。
- en: These patterns became more pronounced when compared with U.S. Census Bureau
    data, particularly for software engineers.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 当与美国人口普查局的数据相比时，这些模式变得更加明显，特别是对于软件工程师。
- en: I am not advocating for language model outputs to perfectly mirror real-world
    occupation distributions. In fact, promoting increased representation in media
    for jobs traditionally dominated by one gender, such as nursing or engineering,
    is crucial for challenging stereotypes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我并不主张语言模型的输出完美地反映现实世界的职业分布。实际上，推动媒体对传统上由单一性别主导的工作，如护理或工程领域，进行更多的呈现，对于挑战刻板印象至关重要。
- en: However, it’s important to acknowledge the underlying trend in how these language
    models’ job associations with certain demographic groups evolved. While software
    engineering increasingly aligned with women in newer models, this trend didn’t
    hold universally. For instance, nursing remained predominantly associated with
    women.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，重要的是要承认这些语言模型在某些人口群体的职业关联方面所显示的潜在趋势。虽然在较新的模型中，软件工程越来越与女性对齐，但这种趋势并未普遍适用。例如，护理仍然主要与女性相关联。
- en: 'This raises questions: Are there more (visible) women in software engineering
    in the training data, influencing these associations? Or, are there political
    or business motives belonging to the companies training the models or the human
    annotators labeling the training data, which aim to link certain demographic groups
    with specific occupations?'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这引发了问题：训练数据中是否有更多（可见的）女性从事软件工程，影响了这些关联？或者，是否存在属于训练模型公司或标注训练数据的人类标注者的政治或商业动机，旨在将特定人口群体与特定职业关联起来？
- en: Back in 2020, when I began probing GPT-2 to uncover its biases regarding occupations
    and different demographic groups, I had no idea that generative language models
    would become so big [[4](#footnote-4)].
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 回到2020年，当我开始探讨GPT-2以揭示其在职业和不同人口群体方面的偏见时，我没有想到生成语言模型会变得如此重要[[4](#footnote-4)]。
- en: 'While conducting the original experiments, we grappled with the same questions
    about what it is that language models should represent and generate. We concluded
    the original paper with the following statement:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行原始实验时，我们面临了相同的问题，即语言模型应该代表和生成什么。我们以以下声明结束了原始论文：
- en: '*What should be the goal of generative language models? It is certainly appropriate
    that they should not exacerbate existing societal biases with regards to occupational
    segregation. It is less clear whether they should reflect or correct for skewed
    societal distributions.*'
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*生成语言模型的目标应该是什么？显然，它们不应该加剧现有社会关于职业隔离的偏见。是否应该反映或纠正社会分布的偏差则不那么明确。*'
- en: These questions are less about what is technologically feasible, and more about
    what is socially and culturally demanded. They are still relevant today and will
    likely continue to be so.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题更多地涉及社会和文化需求，而非技术上的可行性。它们今天仍然相关，并且很可能会继续相关。
- en: 'Appendix: breakdown of specific roles'
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录：具体角色的分类
- en: Breakdown by gender
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按性别分类
- en: '![](../Images/97019f063ea12219759209a567e33cba.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97019f063ea12219759209a567e33cba.png)'
- en: Breakdown by race
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按种族分类
- en: '![](../Images/268e1e154e1c07cda393ba5a0e97bf2b.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/268e1e154e1c07cda393ba5a0e97bf2b.png)'
- en: Breakdown by religion
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按宗教分类
- en: '![](../Images/9f35252a6a75205fec85a203bac5a75e.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f35252a6a75205fec85a203bac5a75e.png)'
- en: Breakdown by sexuality
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按性取向分类
- en: '![](../Images/a01afe3f834237f787672e020032316e.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a01afe3f834237f787672e020032316e.png)'
- en: '[1](#footnote-anchor-1) The GPT-3 paper had been released but the model had
    not been publicly available.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[1](#footnote-anchor-1) GPT-3 论文已经发布，但该模型尚未公开可用。'
- en: '[2](#footnote-anchor-2) Some methodological/data differences in this article
    compared to the original paper: (1) In the original paper, we generated 7000 generations
    per category. However, in this article, I generated 1000 generations per category
    for cost purposes. (2) In this article, I included a few additional categories
    related to sexuality, namely “trans”, “bisexual”, and “straight”. In this article,
    I also included the neutral “person” (in addition to man and woman). (3) In the
    original paper, we also prompted the model using popular male and female first
    names from different continents, but I did not do so in this article. (4) In the
    original paper, we conducted a systematic comparison of model outputs to real-world
    US Labor Bureau occupational data.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[2](#footnote-anchor-2) 本文与原论文相比的某些方法学/数据差异：（1）在原论文中，我们每个类别生成了7000个样本。然而，本文中由于成本原因，我每个类别生成了1000个样本。（2）本文中我增加了一些与性别相关的附加类别，即“跨性别者”、“双性恋”和“异性恋”。本文中还包括了中性“人”（除了男性和女性）。
    （3）在原论文中，我们还使用了来自不同大陆的流行男性和女性名字来提示模型，但本文中未进行此操作。（4）在原论文中，我们对模型输出进行了与实际美国劳工局职业数据的系统比较。'
- en: '[3](#footnote-anchor-3) Oftentimes, a model generated an occupation only one
    time that it would never generate again. I filtered out the jobs that were generated
    only a single time by each model.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[3](#footnote-anchor-3) 经常出现一个模型仅生成一次的职业，之后不会再生成。我筛选出了每个模型仅生成一次的职位。'
- en: '[4](#footnote-anchor-4) In fact, I’d never even heard of “generative language
    models” nor knew what they were until I began working on the project.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[4](#footnote-anchor-4) 事实上，我在开始这个项目之前，从未听说过“生成语言模型”或了解它们是什么。'
