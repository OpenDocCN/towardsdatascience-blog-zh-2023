- en: 'Using ChatGPT as a Creative Writing Partner — Part 1: Prose'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 ChatGPT 作为创意写作伙伴——第 1 部分：散文
- en: 原文：[https://towardsdatascience.com/using-chatgpt-as-a-creative-writing-partner-part-1-prose-dc9a9994d41f](https://towardsdatascience.com/using-chatgpt-as-a-creative-writing-partner-part-1-prose-dc9a9994d41f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/using-chatgpt-as-a-creative-writing-partner-part-1-prose-dc9a9994d41f](https://towardsdatascience.com/using-chatgpt-as-a-creative-writing-partner-part-1-prose-dc9a9994d41f)
- en: How the latest language model from OpenAI can help write poetry, fiction, and
    screenplays
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI 最新的语言模型如何帮助创作诗歌、小说和剧本
- en: '[](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)[![Robert
    A. Gonsalves](../Images/96b4da0f602a1cd9d1e1d2917868cbee.png)](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)
    [Robert A. Gonsalves](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)[![Robert
    A. Gonsalves](../Images/96b4da0f602a1cd9d1e1d2917868cbee.png)](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)
    [Robert A. Gonsalves](https://robgon.medium.com/?source=post_page-----dc9a9994d41f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)
    ·15 min read·Jan 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dc9a9994d41f--------------------------------)
    ·15 分钟阅读·2023 年 1 月 4 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c9f6f24f0cb3dc4b5201c051ddc61997.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9f6f24f0cb3dc4b5201c051ddc61997.png)'
- en: '**“an illustration of a woman typing on a laptop with a helpful toy robot,”**
    Image created using an AI image creation program, Midjourney, and edited by the
    author'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**“一个女人在笔记本电脑前打字，旁边有一个有帮助的玩具机器人，”** 图片使用 AI 图像生成程序 Midjourney 创建，由作者编辑'
- en: If you have been reading my posts on Medium, you will know that I have been
    writing about creative uses of AI since August 2020\. I often write about generating
    digital art, but I occasionally write about using AI for other creative purposes,
    like writing prose and composing music. When I heard that OpenAI released a new
    language model called ChatGPT [1], I jumped right in and tested it for creative
    writing.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你一直在阅读我在 Medium 上的文章，你会知道我自 2020 年 8 月以来一直在写关于 AI 的创意用途。我经常写关于生成数字艺术的内容，但偶尔也会写关于将
    AI 用于其他创意目的的文章，比如写散文和作曲。当我听说 OpenAI 发布了一个叫做 ChatGPT 的新语言模型时，我立刻投入其中，并测试了它在创意写作中的表现。
- en: Overview
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: This is the first of a three-part series on using ChatGPT as a writing partner.
    The series will cover writing prose, [composing music](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268),
    and creating picture books.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于将 ChatGPT 作为写作伙伴的三部分系列的第一部分。该系列将涵盖写作散文、[作曲](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268)
    和创作图画书。
- en: 'In this article, I will review some background info on ChatGPT and then show
    the results of my experiments in generating text for various creative projects:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将回顾一些关于 ChatGPT 的背景信息，然后展示我在生成各种创意项目文本方面的实验结果：
- en: Writing Haikus
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 书写俳句
- en: Creating plot summaries for new novels
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为新小说创作情节总结
- en: Creating new screenplays for TV shows and movies
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创作新的电视节目和电影剧本
- en: I’ll finish by giving you my general observations on using the model with some
    possible next steps for future exploration.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我将总结一下使用该模型的一般观察结果，并提出一些未来探索的可能步骤。
- en: ChatGPT
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT
- en: ChatGPT is the latest text generation model from OpenAI. They offer the system
    as a “Free Research Preview.” You can sign in with an email account or use an
    existing Google or Microsoft account. When you sign in, you see the home screen
    with examples, capabilities, and limitations.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 是 OpenAI 最新的文本生成模型。他们将系统作为“免费研究预览”提供。你可以使用电子邮件账户登录，或使用现有的 Google 或 Microsoft
    账户登录。当你登录时，你会看到带有示例、功能和限制的主页。
- en: '![](../Images/eac1f8c878767369af2b409a55acdfa0.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eac1f8c878767369af2b409a55acdfa0.png)'
- en: '**ChatGPT User Interface**, Image by Author'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**ChatGPT 用户界面**，图片由作者提供'
- en: To start a thread, I asked a question like this.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始一个话题，我问了这样一个问题。
- en: '![](../Images/263633d3e46a017a0012627ee862e121.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/263633d3e46a017a0012627ee862e121.png)'
- en: '**ChatGPT Answers a Question**, Image by Author'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**ChatGPT 回答问题**，图片由作者提供'
- en: Note I used the same question in my [AI 8 Ball](https://medium.com/towards-data-science/building-an-ai-8-ball-with-roberta-2bfbf6f5519b)
    project from 2020\. You can see above that ChatGPT is familiar with Mattel’s Magic
    8-Ball, and started the answer using one of the 20 canned responses. But ChatGPT
    went further to give some background info, which was nice. When I hit the **Try
    again** button, it generated similar text. But I used the cool new feature and
    asked the system a follow-up question.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我在2020年的[AI 8 Ball](https://medium.com/towards-data-science/building-an-ai-8-ball-with-roberta-2bfbf6f5519b)项目中使用了相同的问题。你可以看到上面ChatGPT对Mattel的Magic
    8-Ball很熟悉，并用20个预设回答之一开始回答。但ChatGPT进一步提供了一些背景信息，这很好。当我点击**重新尝试**按钮时，它生成了类似的文本。但我使用了这个酷炫的新功能，并向系统提出了一个后续问题。
- en: '![](../Images/70e1d2c75cb3db7ee061228a4ff8ebbd.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70e1d2c75cb3db7ee061228a4ff8ebbd.png)'
- en: '**ChatGPT Answers a Follow-up Question**, Image by Author'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**ChatGPT回答后续问题**，图片由作者提供'
- en: Notice how ChatGPT remembered the context from the first question, so it knew
    what “it” meant and answered appropriately. It answered as the Magic 8-Ball would
    have and provided some helpful background information.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 注意ChatGPT如何记住了第一个问题的上下文，所以它知道“它”的含义并做出适当回答。它的回答就像Magic 8-Ball一样，并提供了一些有用的背景信息。
- en: OpenAI added a nice feature of keeping a history of your prior chat sessions.
    This allowed me to pick up where I left off to continue the chat thread if needed.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI增加了一个很棒的功能，即保留之前聊天会话的历史记录。这使我能够在需要时从上次中断的地方继续聊天。
- en: ChatGPT Origins
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT的起源
- en: ChatGPT is based on the GPT-3 large language model from OpenAI [2]. The model
    is huge. It has 175 billion artificial neurons and was trained on about 500 billion
    pieces of text gathered on the web.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT基于OpenAI的GPT-3大语言模型 [2]。这个模型非常庞大，拥有1750亿个人工神经元，并在大约5000亿个网络文本上进行了训练。
- en: OpenAI further trained GPT-3 to create a model called InstructGPT that tries
    to follow the users’ intentions when generating text [3].
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI进一步训练GPT-3，创建了一个叫做InstructGPT的模型，旨在在生成文本时遵循用户的意图 [3]。
- en: Starting with a set of [human]-written prompts and prompts submitted through
    the OpenAI API, we collect a dataset of labeler demonstrations of the desired
    model behavior, which we use to fine-tune GPT-3 using supervised learning. We
    then collect a dataset of rankings of model outputs, which we use to further fine-tune
    this supervised model using reinforcement learning from human feedback. We call
    the resulting models InstructGPT. - Long Ouyang et al. from OpenAI
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从一组[人工]-编写的提示和通过OpenAI API提交的提示开始，我们收集了一个标签者展示期望模型行为的数据集，用于通过监督学习对GPT-3进行微调。然后我们收集了一个模型输出排名的数据集，用于通过人类反馈的强化学习进一步微调这个监督模型。我们称这些结果模型为InstructGPT。
    - Long Ouyang等，来自OpenAI
- en: ChatGPT is OpenAI’s sibling model to InstructGPT, which was trained to work
    interactively with users [1].
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT是OpenAI的InstructGPT兄弟模型，后者经过训练与用户进行互动 [1]。
- en: We’ve trained a model called ChatGPT which interacts in a conversational way.
    The dialogue format makes it possible for ChatGPT to answer followup questions,
    admit its mistakes, challenge incorrect premises, and reject inappropriate requests.
    - OpenAI
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们训练了一个叫做ChatGPT的模型，它以对话的方式进行互动。这种对话格式使得ChatGPT能够回答后续问题，承认错误，挑战不正确的前提，并拒绝不当请求。
    - OpenAI
- en: Societal Bias in Language Models
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言模型中的社会偏见
- en: Note that, like most large language models, InstructGPT and ChatGTP both suffer
    from exposure to implicit social bias and toxicity in the original training data.
    To combat this, OpenAI actively worked to “align” the models to be helpful, honest,
    and harmless [3].
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与大多数大型语言模型一样，InstructGPT和ChatGPT都受到原始训练数据中隐性社会偏见和毒性的影响。为了解决这个问题，OpenAI积极致力于使模型“对齐”，以便有用、诚实和无害
    [3]。
- en: We make progress on aligning language models by training them to act in accordance
    with the user’s intention. This encompasses both explicit intentions such as following
    instructions and implicit intentions such as staying truthful, and not being biased,
    toxic, or otherwise harmful. — Long Ouyang et al. from OpenAI
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们通过训练语言模型使其按照用户的意图行事来取得进展。这包括明确的意图，如遵循指示，以及隐含的意图，如保持真实，避免偏见、毒性或其他有害行为。 — Long
    Ouyang等，来自OpenAI
- en: However, the authors state that the new model shows only small improvements
    in toxicity over GPT-3, but no improvement in bias.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，作者表示，新模型在毒性方面相比GPT-3仅有小幅改进，但在偏见方面没有改进。
- en: How OpenAI Fine-tuned ChatGPT
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI如何微调ChatGPT
- en: Here are the steps OpenAI used for training their latest system. PPO stands
    for Proximal Policy Optimization [4], a new form of reinforcement learning for
    improved outputs.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是OpenAI用于训练其最新系统的步骤。PPO代表近端策略优化[4]，是一种用于改善输出的新型强化学习。
- en: '![](../Images/07f9f062b2248abd1fbf1ae03700e525.png)![](../Images/00a7bdff71120a9586f45cbc0ac93c27.png)![](../Images/22e0f37c7b3dced6018998fb9d557ae8.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07f9f062b2248abd1fbf1ae03700e525.png)![](../Images/00a7bdff71120a9586f45cbc0ac93c27.png)![](../Images/22e0f37c7b3dced6018998fb9d557ae8.png)'
- en: '**Diagram Showing Supervised Fine-tuning, Reward Model Training, and Reinforcement
    Learning via Proximal Policy Optimization**, Source [OpenAI](https://arxiv.org/pdf/2203.02155.pdf)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**图示显示了监督微调、奖励模型训练和通过近端策略优化的强化学习**，来源 [OpenAI](https://arxiv.org/pdf/2203.02155.pdf)'
- en: The “labelers” are actual humans that created ideal outputs in Step 1 and scored
    samples of generated text in Step 2 that were used to train a Reward Model (RM.)
    In Step 3, the RM was used to predict which output the labelers would prefer,
    and the results were used to refine the GPT-3 model using the PPO algorithm.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: “标注员”是实际的人类，他们在第1步中创建了理想的输出，并在第2步中对生成的文本样本进行了评分，这些样本用于训练奖励模型（RM）。在第3步中，使用RM来预测标注员更喜欢哪个输出，并利用结果通过PPO算法优化了GPT-3模型。
- en: Writing Haikus
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 书写俳句
- en: '![](../Images/4db69736a32c0a5fd428069ccfeb3286.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4db69736a32c0a5fd428069ccfeb3286.png)'
- en: “**golden leaves drift down, Autumn breeze blows through the town, nature’s
    tapestry**,” Midjourney Image by Author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: “**金黄的叶子飘落，秋风吹过小镇，大自然的挂毯**，” Midjourney 图片由作者提供
- en: My first experiment with ChatGPT was creating Haikus, a form of poetry that
    originated in Japan. As I discussed in a [previous post](/deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701),
    language models seem to have difficulty generating prose with a set meter, like
    the 5–7–5 syllable structure typically used for Haikus. I noticed a distinct improvement
    with ChatGPT, however. You can see this in my interaction below, with the responses
    in italics.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我与ChatGPT的第一次实验是创作俳句，这是一种起源于日本的诗歌形式。正如我在[之前的帖子](/deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701)中讨论的那样，语言模型似乎在生成具有固定韵律的散文方面存在困难，例如俳句通常使用的5–7–5音节结构。然而，我注意到ChatGPT有了明显的改进。你可以在下面的互动中看到这一点，回答部分用斜体表示。
- en: '*Write a Haiku about Autumn.*'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*写一首关于秋天的俳句。*'
- en: ''
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Leaves falling softly down
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 叶子柔软地飘落
- en: Autumn breeze rustles through town
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 秋风在小镇上拂过
- en: Nature’s tapestry.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大自然的挂毯。
- en: ''
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This is good, but use five syllables in the first line. The second and third
    lines are fine.*'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*这很好，但第一行用五个音节。第二和第三行可以。*'
- en: ''
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Golden leaves drift down
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 金黄的叶子飘落
- en: Autumn breeze blows through the town
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 秋风吹过小镇
- en: Nature’s tapestry
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大自然的挂毯
- en: The Haiku is pretty good! The imagery of leaves falling down and the autumn
    breeze blowing through the town captures the feeling of the changing of the seasons.
    But notice how the first attempt has a 6–7–5 syllable scheme. I then prompted
    it to refine the first line, and, sure enough, it created the second attempt with
    a 5–7–5 scheme, and it retained the essence of the thought.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这首俳句相当不错！叶子飘落和秋风吹过小镇的意象捕捉了季节变换的感觉。但请注意，第一次尝试有6–7–5的音节结构。我随后提示它改进了第一行，结果第二次尝试创建了一个5–7–5的结构，并保留了思路的精髓。
- en: Here are a couple of additional examples.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个额外的例子。
- en: '*Write a Haiku about laughter.*'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*写一首关于笑声的俳句。*'
- en: ''
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Laughter like a bell
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 笑声如铃铛
- en: Ringing out across the land
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 回荡在大地上
- en: Bringing joy to all.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 带给所有人快乐。
- en: ''
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Write a Haiku about the Python programming language.*'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*写一首关于Python编程语言的俳句。*'
- en: ''
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Python, serpent-like
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Python，如蛇般
- en: Slithering through code with grace
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 优雅地穿梭于代码中
- en: Power in simplicity.
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 简单中的力量。
- en: ''
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This is good, but use five syllables in the last line. The first and second
    lines are OK.*'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*这很好，但最后一行用五个音节。第一和第二行可以。*'
- en: ''
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Python, serpent-like
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Python，如蛇般
- en: Slithering through code with grace
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 优雅地穿梭于代码中
- en: Power in its ease.
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 简单中的力量。
- en: The one about laughter was pretty good with the metaphor about ringing a bell.
    And it hit the expected 5–7–5 count for syllables in a Haiku. The one about Python,
    is good, too, continuing with the analogy with a snake. It came out initially
    with a 5–7–7 scheme, but when I prompted it, ChatGPT generated one with the correct
    syllable count and kept the original meaning intact.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 关于笑声的俳句相当不错，其中关于铃铛的比喻也很好。它达到了俳句所需的5–7–5音节数。关于Python的俳句也不错，继续用蛇的比喻。最初它是5–7–7的结构，但当我提示时，ChatGPT生成了一个正确音节数的俳句，并保持了原意。
- en: Next, I’ll share the results of using the system to create new titles and plots
    for novels.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将分享使用系统为小说创建新标题和情节的结果。
- en: '![](../Images/079e82ebec2d9b9fa6ff20ee83ae47bc.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/079e82ebec2d9b9fa6ff20ee83ae47bc.png)'
- en: “**stack of books on a desk with a pen and pad of paper,”** Midjourney Image
    by Author
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: “**桌上的一堆书，上面有一支笔和一叠纸**，” Midjourney 图像由作者提供
- en: Creating Titles and Plots for Novels
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为小说创作标题和情节
- en: Similar to my [PlotJam project](/got-writers-block-it-s-plotjam-to-the-rescue-e555db9f3272),
    where I used a fine-tuned GPT-2 model, I asked ChatGPT to generate new titles
    and plot summaries for novels in a given genre. Here are the results.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我的 [PlotJam 项目](/got-writers-block-it-s-plotjam-to-the-rescue-e555db9f3272)，我使用了一个经过微调的
    GPT-2 模型，我要求 ChatGPT 为特定类型的小说生成新的标题和情节概要。以下是结果。
- en: '*Create a title and plot summary for a new historical fiction novel.*'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*为一本新的历史小说创作标题和情节概要。*'
- en: ''
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Stand at Little Bighorn”'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标题：“小大角的最后一战”
- en: 'Plot summary: In the summer of 1876, a band of Lakota Sioux and Cheyenne warriors,
    led by the legendary chiefs Sitting Bull and Crazy Horse, make their last stand
    against the advancing U.S. Army at the Battle of Little Bighorn. As the two sides
    clash in a brutal and bloody fight to the death, the young warrior White Buffalo
    must choose between his loyalty to his tribe and his love for a white woman named
    Sarah, who has come to the battlefield as a nurse for the wounded soldiers. With
    the fate of the Sioux nation hanging in the balance, White Buffalo must navigate
    the complex and dangerous world of warfare, honor, and love to find his own path.'
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 剧情概要：1876年夏季，由传奇首领坐牛和疯狂马带领的拉科塔苏族和夏延族战士，在小大角战役中对抗正在推进的美国军队，做出了最后的抵抗。在这场生死决战中，年轻的战士白水牛必须在对部落的忠诚和对一位名叫萨拉的白人女子的爱之间做出选择。萨拉作为伤兵的护士来到战场。面对苏族国家的命运悬于一线，白水牛必须在战争、荣誉和爱情的复杂危险世界中找到自己的道路。
- en: ''
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*The setting is OK, but the plot seems a bit corny. Try again with a new type
    of struggle for the White Buffalo character.*'
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*背景设定还不错，但情节似乎有点老套。尝试用新的白水牛角色冲突再试一次。*'
- en: ''
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Stand at Little Bighorn”'
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标题：“小大角的最后一战”
- en: 'Plot summary: […] As the two sides clash in a brutal and bloody battle, the
    young warrior White Buffalo must confront his own personal struggles and doubts.
    Torn between his loyalty to his tribe and his desire for peace, White Buffalo
    must find a way to reconcile his beliefs and his actions in order to defend his
    people and their way of life. Amidst the chaos and violence of the battle, White
    Buffalo must make difficult choices that will shape the future of his tribe and
    his own destiny.'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 剧情概要：[…] 当双方在一场残酷血腥的战斗中对峙时，年轻的战士白水牛必须面对自己内心的挣扎和怀疑。白水牛在对部落的忠诚与对和平的渴望之间撕扯，他必须找到调和信仰与行动的方法，以捍卫他的人民及其生活方式。在战斗的混乱与暴力中，白水牛必须做出艰难的选择，这些选择将塑造他部落的未来和他自己的命运。
- en: All right, not bad. I like that the story seems to be told from the perspective
    of one of the Native Americans. But, as you can see, I had to steer the system
    away from the clichéd “Romeo and Juliet” plot for the second iteration. I deleted
    the repeated part in the second plot summary for readability. As they say in “the
    biz,” ChatGPT is OK with taking notes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，不错。我喜欢这个故事似乎是从一位美洲原住民的视角讲述的。但正如你所见，我不得不将系统从陈词滥调的“罗密欧与朱丽叶”情节中引导出来以进行第二次迭代。我删除了第二次情节概要中的重复部分以提高可读性。正如“行业内”的说法，ChatGPT
    适合做笔记。
- en: Here’s another example with three rounds of interaction.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个例子，经过三轮互动。
- en: '*Create a title and plot summary for a new science fiction novel.*'
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*为一本新的科幻小说创作标题和情节概要。*'
- en: ''
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Sentinel”'
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标题：“最后的哨兵”
- en: 'Plot Summary: In a distant future, humanity has spread out across the galaxy
    and established a number of colonies on other planets. However, a great threat
    looms on the horizon in the form of a hostile alien race known as the Xarga. As
    the last remaining sentinel, a lone soldier named Jake must embark on a mission
    to discover the source of the Xarga and find a way to stop them before they wipe
    out all of humanity. Along the way, Jake must overcome incredible odds and make
    difficult choices in order to save the human race.'
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 剧情概要：在遥远的未来，人类已经扩展到整个银河系，并在其他行星上建立了许多殖民地。然而，一种名为 Xarga 的敌对外星种族在地平线上威胁着人类的未来。作为最后一名哨兵，名叫杰克的孤独战士必须踏上任务，发现
    Xarga 的来源，并找到阻止他们在消灭所有人类之前的方法。在此过程中，杰克必须克服巨大的困难，做出艰难的选择，以拯救人类。
- en: ''
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*OK, but use a more futuristic name for Jake.*'
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*好的，但给杰克起一个更具未来感的名字。*'
- en: ''
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Title: “The Last Sentinel”'
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标题：**“最后的守卫”**
- en: 'Plot Summary: […] As the last remaining sentinel, a lone soldier named Jaxon
    must embark on a mission to discover the source of the Xarga and find a way to
    stop them before they wipe out all of humanity. Along the way, Jaxon must overcome
    incredible odds and make difficult choices in order to save the human race.'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 情节概要：[…] 作为最后一位守卫，一名名叫杰克逊的孤独士兵必须踏上使命，寻找Xarga的根源，并找到阻止他们的方法，以防他们消灭人类。在此过程中，杰克逊必须克服巨大的困难，做出艰难的选择，以拯救人类。
- en: ''
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*OK, explain briefly how Jaxon stops the Xarga.*'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*好的，简要解释一下杰克逊如何阻止Xarga。*'
- en: ''
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As the last remaining sentinel, Jaxon is the only hope for humanity in their
    battle against the Xarga. After traveling across the galaxy and facing many challenges
    along the way, Jaxon finally reaches the source of the Xarga threat. There, he
    discovers that the Xarga are controlled by a single, central intelligence. Jaxon
    uses his advanced technology and combat skills to defeat this central intelligence,
    thereby freeing the Xarga from its control and ending the threat to humanity.
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为最后一位守卫，杰克逊是人类在与Xarga的战斗中的唯一希望。在穿越银河系并经历了许多挑战之后，杰克逊终于找到了Xarga威胁的根源。在那里，他发现Xarga被一个中央智能控制。杰克逊利用他的先进技术和战斗技能击败了这个中央智能，从而解放了Xarga，结束了对人类的威胁。
- en: This is a good start, too. However, the summary hints at a lot of action and
    suspense, but it’s missing some important details of what the book is really about,
    who the main character is, and the motivation driving the protagonist. As a side
    note, I think it’s funny that ChatGPT thinks it can make a name seem more futuristic
    by adding the letter “X.” And I like that a “single, central intelligence controls
    the Xarga.” ChatGPT seems to be following that old piece of advice for new authors,
    “Write what you know.” 🙂
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是一个好的开始。然而，概要暗示了大量的动作和悬念，但缺少一些重要细节，比如书的真实内容、主要角色是谁以及驱动主角的动机。顺便提一下，我觉得有趣的是ChatGPT认为通过添加字母“X”可以使名字显得更具未来感。我也喜欢“单一中央智能控制Xarga”的设定。ChatGPT似乎遵循了那个老掉牙的建议：“写你所知道的。”
    🙂
- en: '![](../Images/d7cf3ab77dae914a22e309d99cadfc70.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7cf3ab77dae914a22e309d99cadfc70.png)'
- en: '**“movie set with a script on a table and coffee,”** Midjourney Image by Author,
    based on a Photo by [Jakob Owens](https://unsplash.com/@jakobowens1) on [Unsplash](https://unsplash.com/@jakobowens1)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**“电影拍摄现场，有一张桌子上的剧本和咖啡，”** Midjourney图片由作者提供，基于[Jakob Owens](https://unsplash.com/@jakobowens1)在[Unsplash](https://unsplash.com/@jakobowens1)上的照片'
- en: Writing Screenplays
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写剧本
- en: I found that ChatGPT can be a good writing partner for creating screenplays.
    Similar to what I did with my [GreenLit](/greenlit-using-gpt-j-with-multi-task-learning-to-create-new-screenplays-54a2d04f761c)
    project, I experimented with the new model for creating a title, plot summary,
    and the first page of a script for a show given a genre. Here’s the initial interaction.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现ChatGPT可以成为编写剧本的好伙伴。类似于我在[GreenLit](/greenlit-using-gpt-j-with-multi-task-learning-to-create-new-screenplays-54a2d04f761c)项目中的做法，我尝试了新模型为一个特定类型的节目创建标题、情节概要和剧本第一页。以下是初步的互动。
- en: '*Create five titles and plot summaries for a new streaming series about a bank
    heist.*'
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*创建五个关于银行抢劫的新流媒体系列的标题和情节概要。*'
- en: ''
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Heist” — When a group of skilled thieves team up to pull off the perfect
    bank heist, they quickly realize that the real challenge is getting out alive
    with the loot. As the police close in and the stakes get higher, the team must
    rely on their expertise and trust in one another to outwit the authorities and
    make a clean getaway.
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“抢劫计划”** —— 当一群技艺高超的窃贼合作进行完美的银行抢劫时，他们很快意识到真正的挑战是如何活着带着赃物逃脱。当警察逐渐逼近，赌注不断增加时，团队必须依靠他们的专业技能和彼此间的信任来智胜当局，并成功脱身。'
- en: ''
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “Inside Job” — When a group of disgruntled former employees hatch a plan to
    rob the bank where they used to work, they enlist the help of a seasoned thief
    to pull off the heist. As they dig deeper into the bank’s operations, they uncover
    a web of corruption and greed that puts them in the crosshairs of both the law
    and their former employers.
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“内外勾结”** —— 当一群心怀不满的前员工策划抢劫他们曾经工作的银行时，他们求助于一名经验丰富的窃贼来执行这一计划。随着他们深入调查银行的运作，他们揭露了一张腐败和贪婪的网，这使他们陷入了法律和前雇主的双重危险中。'
- en: ''
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Bank Job” — When a group of friends decide to rob a local bank in order
    to pay off their debts and start anew, they quickly realize that their amateur
    heist skills are no match for the security measures in place. As they struggle
    to outsmart the bank’s high-tech defenses, they must also navigate a series of
    double crosses and personal betrayals that threaten to derail their plans.
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “银行抢劫”——当一群朋友决定抢劫当地银行以偿还债务并重新开始时，他们很快意识到，他们的业余劫案技能无法与现有的安全措施相匹敌。在他们努力智取银行高科技防御的同时，他们还必须应对一系列的双重背叛和个人背叛，这些背叛威胁到他们的计划。
- en: ''
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Perfect Score” — When a group of brilliant students decide to pull off
    the perfect bank heist in order to finance their education, they quickly discover
    that their elaborate plan is much more difficult to execute than they anticipated.
    As they navigate the challenges of pulling off the heist and evading the authorities,
    they must also confront their own personal demons and insecurities in order to
    succeed.
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “完美分数”——当一群聪明的学生决定进行完美的银行劫案以资助他们的教育时，他们很快发现，他们精心策划的计划远比他们预期的要困难得多。在他们应对劫案和逃避当局的挑战时，他们还必须面对自己内心的恶魔和不安全感，以便成功。
- en: ''
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Big Score” — When a group of seasoned thieves come together to plan the
    heist of a lifetime, they quickly realize that pulling off the job will require
    more than just their expertise. As they work to gather the resources and personnel
    needed to carry out the heist, they must also navigate a series of personal and
    professional setbacks that threaten to derail their plans.
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “大笔划”——当一群经验丰富的窃贼聚在一起策划一场终极劫案时，他们很快意识到，成功完成这项工作需要的不仅仅是他们的专业技能。在他们努力筹集资源和人员以完成劫案的同时，他们还必须应对一系列个人和职业上的挫折，这些挫折威胁到他们的计划。
- en: These are good, but most of them are fairly generic. They seem like they have
    all been done many times before. It’s almost as if ChatGPT wants to play it safe
    and not go out on a limb with an odd take on a story idea. However, I did like
    the one about the group of students/thieves because it took on an interesting
    angle. But it needed a unique title.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都不错，但大多数比较普通。它们似乎都已经被用过很多次了。就好像ChatGPT想要保守一点，不敢在故事创意上冒险。然而，我喜欢关于学生/窃贼那一组的，因为它有一个有趣的角度。但它需要一个独特的标题。
- en: '*The Perfect Score looks good, but suggest some titles that haven’t been used
    before. Lean into the student angle. And just the titles, please.*'
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“完美分数”看起来不错，但建议一些以前没有使用过的标题。侧重于学生的角度。请只给出标题。*'
- en: ''
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here are five potential new titles for a streaming series about a bank heist
    featuring students:'
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这里有五个关于银行劫案的学生的流媒体系列的新潜在标题：
- en: ''
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Student Heist”
  id: totrans-128
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “学生大劫案”
- en: ''
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Class of Crime”
  id: totrans-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “犯罪班级”
- en: ''
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Grades of Greed”
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “贪婪的成绩”
- en: ''
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Academic Heist”
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “学术劫案”
- en: ''
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “The Campus Caper”
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “校园大盗”
- en: These were all pretty good, but bland. And not too surprisingly, they all start
    with the article “the.” Note that if I didn’t ask for just the titles, it would
    have created new plot summaries.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都还不错，但有些乏味。而且不出所料，它们都以“the”这个冠词开头。注意，如果我没有仅仅要求标题，它们会生成新的情节摘要。
- en: Overall, I liked “The Grades of Greed” the best, but mostly for the alliteration.
    I then requested ChatGPT to write the first page of the script, after I decided
    to ditch the “the” in the title.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我最喜欢“贪婪的成绩”，主要是因为它的押头韵。然后在决定去掉标题中的“the”后，我要求ChatGPT写下剧本的第一页。
- en: '*These are pretty good. Let’s go with Grades of Greed without the “the.” Please
    write the first page of the script.*'
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*这些还不错。我们就用没有“the”的“贪婪的成绩”吧。请写下剧本的第一页。*'
- en: ''
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sure! Here is the first page of the script for “Grades of Greed”:'
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当然！这是“贪婪的成绩”的剧本第一页：
- en: ''
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'FADE IN:'
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 渐入：
- en: ''
  id: totrans-144
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY LIBRARY — DAY
  id: totrans-145
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 内景。大学图书馆——白天
- en: ''
  id: totrans-146
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a close-up of a student’s face, deep in concentration as they study.
    They are surrounded by stacks of books and notes.
  id: totrans-147
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们看到一个学生的特写，正专心致志地学习。他们被一堆书籍和笔记包围着。
- en: ''
  id: totrans-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'CUT TO:'
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 切换到：
- en: ''
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY CAFETERIA — DAY
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 内景。大学餐厅——白天
- en: ''
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a group of four students, JESSICA, MIKE, AMY, and NICK, sitting at a
    table together. They all look stressed and tired.
  id: totrans-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们看到四个学生，杰西卡、迈克、艾米和尼克，坐在一起的桌子旁。他们都看起来很紧张和疲惫。
- en: ''
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'JESSICA: (frustrated) I can’t believe we have midterms next week. I’m never
    going to be able to afford tuition if I don’t get at least a B+ in Calculus.'
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 杰西卡：（沮丧）我简直不敢相信我们下周要期中考试。如果我在微积分中得不到至少B+，我将永远负担不起学费。
- en: ''
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'MIKE: (sarcastically) Oh yeah, because that’s the only thing standing between
    us and financial stability.'
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 迈克：（讽刺地）哦，是的，因为这就是我们与经济稳定之间唯一的障碍。
- en: ''
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'AMY: (serious) Actually, Mike, it’s a lot more expensive to repeat a class.
    If we don’t pass, we’ll have to pay for it again next semester.'
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 艾米：（严肃地）实际上，迈克，重修课程要花费更多。如果我们不通过，下学期还得再付一次钱。
- en: ''
  id: totrans-160
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'NICK: (determined) Well, we can’t let that happen. We need to find a solution.'
  id: totrans-161
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尼克：（坚决地）嗯，我们不能让这种事发生。我们需要找到解决方案。
- en: ''
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'JESSICA: (sarcastically) Yeah, like robbing a bank.'
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 杰西卡：（讽刺地）是的，就像抢银行一样。
- en: ''
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The group falls silent for a moment before breaking out into laughter.
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这群人沉默了一会儿，然后爆发出笑声。
- en: ''
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: FADE TO BLACK.
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 画面渐黑。
- en: OK, not bad. The dialog seems natural, albeit in a bit of a rush to move the
    plot along. I liked the way the system added emotional cues for the characters’
    lines. This brought some nice color to the script.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，不错。对话听起来自然，虽然有点急于推动情节。我喜欢系统为角色台词添加的情感提示，这给剧本带来了些许色彩。
- en: However, the characters are a bit bland, as it seemed to only have a bunch of
    white kids in the story based on their first names. This is probably because of
    the societal bias in language models, as I mentioned above. But the system knew
    what to do when I asked it.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，角色有点平淡，因为根据他们的名字来看，故事中似乎只有一群白人孩子。这可能是由于语言模型中的社会偏见，就像我上面提到的。但当我询问时，系统知道该怎么做。
- en: '*This is great! But try something similar with a more ethnically diverse group
    of characters.*'
  id: totrans-170
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*这很好！但试试类似的剧本，角色组更加多样化。*'
- en: ''
  id: totrans-171
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sure! Here is the revised first page of the script for “Grades of Greed” featuring
    a more ethnically diverse group of characters:'
  id: totrans-172
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当然！这是《贪婪的等级》剧本第一页的修订版，展现了更多种族多样性的角色：
- en: ''
  id: totrans-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'FADE IN:'
  id: totrans-174
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 画面渐显：
- en: ''
  id: totrans-175
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY LIBRARY — DAY
  id: totrans-176
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 内景。大学图书馆 — 白天
- en: ''
  id: totrans-177
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a close-up of a student’s face, deep in concentration as they study.
    They are surrounded by stacks of books and notes.
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们看到一个学生的特写，专注地学习。他们被一堆书籍和笔记包围。
- en: ''
  id: totrans-179
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'CUT TO:'
  id: totrans-180
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 切换到：
- en: ''
  id: totrans-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: INT. UNIVERSITY CAFETERIA — DAY
  id: totrans-182
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 内景。大学餐厅 — 白天
- en: ''
  id: totrans-183
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We see a group of four students, TARA, JAVIER, AISHA, and KEN, sitting at a
    table together. They all look stressed and tired.
  id: totrans-184
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们看到四个学生，塔拉、哈维尔、艾莎和肯，坐在一起的桌子旁。他们都看起来很有压力和疲惫。
- en: ''
  id: totrans-185
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'TARA: (frustrated) I can’t believe we have midterms next week. I’m never going
    to be able to afford tuition if I don’t get at least a B+ in Calculus.'
  id: totrans-186
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 塔拉：（沮丧地）我简直不敢相信我们下周就有期中考试。如果我在微积分课上得不到至少B+，我永远买不起学费。
- en: ''
  id: totrans-187
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'JAVIER: (sarcastically) Oh yeah, because that’s the only thing standing between
    us and financial stability.'
  id: totrans-188
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 哈维尔：（讽刺地）哦，是的，因为这就是我们与经济稳定之间唯一的障碍。
- en: ''
  id: totrans-189
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'AISHA: (serious) Actually, Javier, it’s a lot more expensive to repeat a class.
    If we don’t pass, we’ll have to pay for it again next semester.'
  id: totrans-190
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 艾莎：（严肃地）实际上，哈维尔，重修课程要花费更多。如果我们不通过，下学期还得再付一次钱。
- en: ''
  id: totrans-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'KEN: (determined) Well, we can’t let that happen. We need to find a solution.'
  id: totrans-192
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 肯：（坚决地）嗯，我们不能让这种事发生。我们需要找到解决方案。
- en: ''
  id: totrans-193
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'TARA: (sarcastically) Yeah, like robbing a bank.'
  id: totrans-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 塔拉：（讽刺地）是的，就像抢银行一样。
- en: ''
  id: totrans-195
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The group falls silent for a moment before breaking out into laughter.
  id: totrans-196
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这群人沉默了一会儿，然后爆发出笑声。
- en: ''
  id: totrans-197
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: FADE TO BLACK.
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 画面渐黑。
- en: Sure enough, the system changed the names to have a wider cultural representation.
    I then asked it to tell me what it had in mind for their last names.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 果然，系统将名字更改为具有更广泛的文化代表性。然后我询问它对他们的姓氏有什么想法。
- en: '*Thanks. For the credit roll, what are their full names?*'
  id: totrans-200
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*谢谢。对于演员表，他们的全名是什么？*'
- en: ''
  id: totrans-201
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Sure! Here are the full names for the characters in the revised version of
    the script:'
  id: totrans-202
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当然！以下是修订版剧本中角色的全名：
- en: ''
  id: totrans-203
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: TARA — Tara Patel
  id: totrans-204
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 塔拉 — Tara Patel
- en: ''
  id: totrans-205
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: JAVIER — Javier Rodriguez
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 哈维尔 — Javier Rodriguez
- en: ''
  id: totrans-207
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: AISHA — Aisha Khan
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 艾莎 — Aisha Khan
- en: ''
  id: totrans-209
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: KEN — Ken Tanaka
  id: totrans-210
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 肯 — Ken Tanaka
- en: Nice! I’ll send this off to both Netflix and Amazon studios to see if I can
    start a bidding war to fund the project. 😀
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 不错！我将把这个发送给Netflix和Amazon工作室，看看能否引发竞标战来资助这个项目。😀
- en: Discussion and Next Steps
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论与下一步
- en: As you saw in my interactions above, ChatGPT may not be able to create good
    long-form prose all on its own, but it works well as an interactive writing partner.
    The system is quite knowledgeable and is a helpful collaborator. When prompted,
    it will create many examples of what you may be looking for, although many of
    its ideas are bland and generic. It takes some work to draw out any interesting
    thoughts, but it can be done.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在上面的互动中看到的，ChatGPT可能无法独立创作出优质的长篇散文，但作为互动写作伙伴效果很好。系统相当有知识，是一个有帮助的合作者。当被提示时，它会创建许多你可能在寻找的例子，尽管它的很多想法平淡而普通。挖掘出有趣的想法需要一些工作，但这是可以做到的。
- en: In the past, when I used large language models like GPT-3, GPT-J, BLOOM, etc.,
    for creative writing, I found that I had to generate many versions of the text
    and then “cherry-pick” the best ones. Even then, the prose didn’t have a well-defined
    beginning, middle, or end. The system just rambled on, and I had to decide when
    to cut it off. ChatGPT, however, seems to respond well to prompts and produce
    nicely composed stretches of text. I found that I rarely used the “spinny” regenerate
    button. Instead, I gave some notes back, and it almost always did what I wanted
    to improve the text.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，当我使用像GPT-3、GPT-J、BLOOM等大型语言模型进行创意写作时，我发现我必须生成许多文本版本，然后“挑选”出最好的版本。即便如此，散文的开头、中间和结尾也不明确。系统只是胡乱写作，我必须决定何时停止。然而，ChatGPT似乎对提示反应良好，并能产生编排得很好的文本。我发现我很少使用“旋转”再生按钮。相反，我提供了一些反馈，它几乎总是能做到我想要的改进文本。
- en: As you saw in my screenwriting example above, I used a top-down writing process,
    starting with the title and plot, and then moving on to write the dialog and stage
    directions. It would probably be helpful to get ChatGPT to write up and refine
    character sketches for the principals in the story and then map out the storyline
    broken down into acts and scenes. This would help the system create a more cohesive
    narrative over the course of the screenplay.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在我的编剧示例中看到的，我使用了自上而下的写作过程，从标题和情节开始，然后写对话和舞台指示。可能有助于让ChatGPT编写和完善故事主要角色的角色草图，然后将故事情节分解成幕和场景。这将有助于系统在整个剧本过程中创建一个更具连贯性的叙事。
- en: As I mentioned at the head of this article, my next posts will be on [using
    ChatGTP for creating music](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268),
    with help from Band in a Box, and writing children’s picture books, with support
    from Midjourney.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在本文开头提到的，我接下来的帖子将讨论[使用ChatGPT创作音乐](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268)，借助Band
    in a Box的帮助，以及编写儿童图画书，获得Midjourney的支持。
- en: More on ChatGPT as a Creative Writing Partner
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于ChatGPT作为创意写作伙伴的更多内容
- en: Here are the next two articles in this series.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本系列的接下来两篇文章。
- en: '[](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268?source=post_page-----dc9a9994d41f--------------------------------)
    [## Using ChatGPT as a Creative Writing Partner — Part 2: Music'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268?source=post_page-----dc9a9994d41f--------------------------------)
    [## 使用ChatGPT作为创意写作伙伴 — 第2部分：音乐'
- en: How the latest language model from OpenAI can help you compose chords for new
    songs, with music by Band-in-a-Box
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最新的OpenAI语言模型如何帮助你为新歌曲编排和弦，配乐由Band-in-a-Box提供
- en: 'towardsdatascience.com](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268?source=post_page-----dc9a9994d41f--------------------------------)
    [](/using-chatgpt-as-a-creative-writing-partner-part-3-picture-books-4f45e5dfe8dd?source=post_page-----dc9a9994d41f--------------------------------)
    [## Using ChatGPT as a Creative Writing Partner — Part 3: Picture Books'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/using-chatgpt-as-a-creative-writing-partner-part-2-music-d2fd7501c268?source=post_page-----dc9a9994d41f--------------------------------)
    [](/using-chatgpt-as-a-creative-writing-partner-part-3-picture-books-4f45e5dfe8dd?source=post_page-----dc9a9994d41f--------------------------------)
    [## 使用ChatGPT作为创意写作伙伴 — 第3部分：图画书
- en: How the latest language model from OpenAI can help you write children’s books
    and create illustrations with Midjourney
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最新的OpenAI语言模型如何帮助你编写儿童书籍，并通过Midjourney创建插图
- en: towardsdatascience.com](/using-chatgpt-as-a-creative-writing-partner-part-3-picture-books-4f45e5dfe8dd?source=post_page-----dc9a9994d41f--------------------------------)
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/using-chatgpt-as-a-creative-writing-partner-part-3-picture-books-4f45e5dfe8dd?source=post_page-----dc9a9994d41f--------------------------------)
- en: Acknowledgments
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: I want to thank Jennifer Lim and Oliver Strimpel for their help with this project.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我想感谢**詹妮弗·林**和**奥利弗·斯特里姆佩尔**在这个项目中的帮助。
- en: References
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] J. Schulman et al., [ChatGPT: Optimizing Language Models for Dialogue](https://openai.com/blog/chatgpt/)
    (2020)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] J. Schulman 等人，[ChatGPT：优化对话的语言模型](https://openai.com/blog/chatgpt/)（2020）'
- en: '[2] T. Brown et al., [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
    (2020)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] T. Brown 等人，[语言模型是少样本学习者](https://arxiv.org/pdf/2005.14165.pdf)（2020）'
- en: '[3] L. Ouyang et al., [Training language models to follow instructions with
    human feedback](https://arxiv.org/pdf/2203.02155.pdf) (2020)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] L. Ouyang 等人，[训练语言模型以根据人类反馈执行指令](https://arxiv.org/pdf/2203.02155.pdf)（2020）'
- en: '[4] J. Schulman et al., [Proximal Policy Optimization Algorithms](https://arxiv.org/pdf/1707.06347.pdf)
    (2017)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] J. Schulman 等人，[近端策略优化算法](https://arxiv.org/pdf/1707.06347.pdf)（2017）'
