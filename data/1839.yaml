- en: 'Text Tiling Done Right: Building Solid Foundations For Your Personal LLM'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**文本切分正确实施**：为您的个人 LLM 打下坚实的基础'
- en: 原文：[https://towardsdatascience.com/text-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1?source=collection_archive---------3-----------------------#2023-06-04](https://towardsdatascience.com/text-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1?source=collection_archive---------3-----------------------#2023-06-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/text-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1?source=collection_archive---------3-----------------------#2023-06-04](https://towardsdatascience.com/text-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1?source=collection_archive---------3-----------------------#2023-06-04)
- en: How to build a text tiling model from scratch using both semantic and lexical
    similarity
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何从头开始使用语义和词汇相似性构建文本切分模型
- en: '[](https://medium.com/@massi.costacurta?source=post_page-----e70947779ac1--------------------------------)[![Massimiliano
    Costacurta](../Images/599c3469021c53f116cc67c390db6695.png)](https://medium.com/@massi.costacurta?source=post_page-----e70947779ac1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e70947779ac1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e70947779ac1--------------------------------)
    [Massimiliano Costacurta](https://medium.com/@massi.costacurta?source=post_page-----e70947779ac1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@massi.costacurta?source=post_page-----e70947779ac1--------------------------------)[![Massimiliano
    Costacurta](../Images/599c3469021c53f116cc67c390db6695.png)](https://medium.com/@massi.costacurta?source=post_page-----e70947779ac1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e70947779ac1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e70947779ac1--------------------------------)
    [Massimiliano Costacurta](https://medium.com/@massi.costacurta?source=post_page-----e70947779ac1--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F233cb43234c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1&user=Massimiliano+Costacurta&userId=233cb43234c3&source=post_page-233cb43234c3----e70947779ac1---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e70947779ac1--------------------------------)
    ·11 min read·Jun 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe70947779ac1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1&user=Massimiliano+Costacurta&userId=233cb43234c3&source=-----e70947779ac1---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F233cb43234c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1&user=Massimiliano+Costacurta&userId=233cb43234c3&source=post_page-233cb43234c3----e70947779ac1---------------------post_header-----------)
    发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e70947779ac1--------------------------------)
    · 11分钟阅读 · 2023年6月4日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe70947779ac1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1&source=-----e70947779ac1---------------------bookmark_footer-----------)![](../Images/cd5c60bf6539c088ca725c3a559d0bdd.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe70947779ac1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-tiling-done-right-building-solid-foundations-for-your-personal-llm-e70947779ac1&source=-----e70947779ac1---------------------bookmark_footer-----------)![](../Images/cd5c60bf6539c088ca725c3a559d0bdd.png)'
- en: Photo by [Gary Butterfield](https://unsplash.com/@garybpt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Gary Butterfield](https://unsplash.com/@garybpt?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: It’s like everybody’s trying to get their own Large Language Model (LLM) these
    days, tweaking it to work on their private collection of documents. The privacy
    factor plays a big role here, amplifying the demand for more private GPT models.
    However, the journey to crafting a personal chatbot isn’t straightforward and
    you basically have two main options to do that.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在似乎每个人都在尝试获得自己的大型语言模型（LLM），并调整其以适应他们的私人文档集。隐私因素在这里起着重要作用，进一步推动了对更多私人GPT模型的需求。然而，创建个人聊天机器人的过程并不简单，你基本上有两个主要选项来实现这一目标。
- en: Firstly, you could build a custom question-answer dataset from scratch and use
    it to fine-tune your LLM. But let’s face it, this isn’t a feasible option for
    most of us due to the high costs and significant time commitment it requires.
    An alternative, more affordable approach involves generating context on the fly.
    This is done by retrieving relevant sections from your documents based on the
    user’s query, with the help of embeddings. While there’s no shortage of tutorials
    explaining how to do this, few highlight the critical importance of appropriately
    chunking, or ‘tiling’, your documents.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你可以从头开始构建一个定制的问题-答案数据集，并用它来微调你的LLM。但说实话，由于高成本和显著的时间投入，这对大多数人来说并不是一个可行的选项。另一种更具成本效益的方法是动态生成上下文。这是通过基于用户查询从文档中检索相关部分来完成的，借助嵌入技术。尽管有很多教程解释如何做这件事，但很少有人强调适当地切分或“切块”文档的重要性。
- en: 'Here’s why it’s essential: if your document tiles aren’t well cut, your context
    could be off, leading your LLM to provide answers that either completely miss
    the point or, worse, generate false information — a phenomenon often referred
    to as ‘hallucination’ in machine learning. This is where the art of text tiling
    comes into play. It’s all about breaking down a document into coherent, meaningful
    chunks that can facilitate precise, relevant context retrieval. In doing so, you’re
    likely to improve the overall performance of your LLM, making it more adept at
    understanding queries and providing accurate responses.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这之所以至关重要，是因为如果你的文档切分不准确，你的上下文可能会出现偏差，从而导致你的LLM给出的答案完全偏离主题，或者更糟的是，生成虚假的信息——在机器学习中，这种现象通常被称为“幻觉”。这就是文本切分艺术发挥作用的地方。这一过程的核心在于将文档拆分成连贯且有意义的块，以便于精确、相关的上下文检索。这样做，你很可能会提高LLM的整体表现，使其更擅长理解查询并提供准确的回应。
- en: Now, it may surprise you (just like it surprised me) to know that in the world
    of Python programming, there aren’t many options for text tiling. Our primary
    tool available is [nltk.tokenize.texttiling](https://www.nltk.org/_modules/nltk/tokenize/texttiling.html),
    which is not even very well documented. Realizing this lack of variety and the
    potential for improvement, I’ve decided to embark on developing my own text-tiling
    model, leveraging the revolutionary technologies offered by Natural Language Processing
    (NLP) and transformers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，可能会让你感到惊讶（就像我一样惊讶）的是，在Python编程的世界里，文本切分的选项并不多。我们主要的工具是[nltk.tokenize.texttiling](https://www.nltk.org/_modules/nltk/tokenize/texttiling.html)，但这个工具的文档并不完善。意识到这一点的缺乏和改进的潜力，我决定开始开发自己的文本切分模型，利用自然语言处理（NLP）和变换器提供的革命性技术。
- en: Evaluation Mechanism for Text Tiling Models
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本切分模型的评估机制
- en: 'Whenever I embark on developing a new model, I always try and begin with the
    end in mind, then work backwards from there. In this case, our “end” is assessing
    the output of our model. Without a means of evaluation, we can’t measure performance
    and thus can’t make improvements. For this reason, creating an evaluation mechanism
    is essential before even attempting to develop a model. Evaluating text tiling,
    however, poses unique challenges because it relates to the topics found within
    the document(s) at hand. This presents us with two major hurdles:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我开始开发一个新模型时，我总是尝试以最终目标为出发点，然后从那里向后工作。在这种情况下，我们的“终点”是评估模型的输出。如果没有评估手段，我们就无法衡量性能，因此无法进行改进。因此，在尝试开发模型之前，创建一个评估机制是至关重要的。然而，评估文本切分面临独特的挑战，因为它涉及到文档中出现的主题。这给我们带来了两个主要难题：
- en: We don’t have a dataset of documents along with their corresponding tiling.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们没有带有对应切分的数据集。
- en: Even if we had such a dataset, it would be exceptionally difficult to utilize,
    given that partitioning a document by topic is highly subjective.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 即使我们有这样的数据集，由于按主题划分文档高度主观，利用起来也会异常困难。
- en: 'To navigate these issues, we’ll adopt a straightforward approach: create a
    synthetic document. This document will be a concatenation of diverse documents,
    which ensures we know the exact thresholds separating the original documents.
    These thresholds should be identified by our model. In this article, I’ll employ
    one document as an example (which can be found [here](https://github.com/massi82/texttiling/blob/master/doc.txt)).
    Still, this same methodology could be applied to assemble a multitude of documents
    for a comprehensive model test. The composite document is crafted from the concatenation
    of the following Medium articles (to their respective authors, consider this a
    bit of free promotion, you can thank me later 😀):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些问题，我们将采取一种简单的方法：创建一个合成文档。这个文档将是各种文档的拼接，确保我们知道原始文档之间的确切阈值。这些阈值应由我们的模型识别。在这篇文章中，我将用一个文档作为示例（可以在[这里](https://github.com/massi82/texttiling/blob/master/doc.txt)找到）。不过，这种方法也可以用于组装大量文档进行全面的模型测试。这个复合文档是由以下Medium文章拼接而成的（对于这些文章的作者，算是免费推广，稍后可以感谢我😀）：
- en: '[](https://medium.com/@brandeismarshall/3-unsavory-consequences-of-generative-ai-2b9f5c29f52b?source=post_page-----e70947779ac1--------------------------------)
    [## 3 Unsavory Consequences of Generative AI'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[3个生成型AI的令人不快的后果](https://medium.com/@brandeismarshall/3-unsavory-consequences-of-generative-ai-2b9f5c29f52b?source=post_page-----e70947779ac1--------------------------------)
    [## 生成型AI的3个令人不快的后果'
- en: The ‘move fast and break things’ standard operating practices are in hyperdrive.
    Each industry across all sectors are…
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ‘快速行动，打破常规’的标准操作程序正处于极速运转中。各行各业都在…
- en: medium.com](https://medium.com/@brandeismarshall/3-unsavory-consequences-of-generative-ai-2b9f5c29f52b?source=post_page-----e70947779ac1--------------------------------)
    [](https://blossomstreetventures.medium.com/average-contract-value-in-saas-a7f0d02ca350?source=post_page-----e70947779ac1--------------------------------)
    [## Average contract value in SaaS
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[平均合同价值在SaaS](https://medium.com/@brandeismarshall/3-unsavory-consequences-of-generative-ai-2b9f5c29f52b?source=post_page-----e70947779ac1--------------------------------)
    [## 平均合同价值在SaaS'
- en: Average Contract Value is an important metric in SaaS. If it’s trending up and
    to the right, it’s a sign that customers…
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平均合同价值是SaaS中的一个重要指标。如果它在上升并趋向右侧，这表明客户…
- en: blossomstreetventures.medium.com](https://blossomstreetventures.medium.com/average-contract-value-in-saas-a7f0d02ca350?source=post_page-----e70947779ac1--------------------------------)
    [](https://medium.com/wise-well/were-treating-stress-anxiety-and-depression-all-wrong-809566f1b73b?source=post_page-----e70947779ac1--------------------------------)
    [## We’re Treating Stress, Anxiety and Depression All Wrong
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[平均合同价值在SaaS](https://blossomstreetventures.medium.com/average-contract-value-in-saas-a7f0d02ca350?source=post_page-----e70947779ac1--------------------------------)
    [## 我们治疗压力、焦虑和抑郁的方法完全错了'
- en: The best remedy for mental health conditions is obvious but rarely prescribed
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 心理健康问题的最佳疗法显而易见，但很少被开处方
- en: medium.com](https://medium.com/wise-well/were-treating-stress-anxiety-and-depression-all-wrong-809566f1b73b?source=post_page-----e70947779ac1--------------------------------)
    [](https://medium.com/illumination/your-side-hustle-sucks-compared-to-working-for-a-big-company-49664f1ef73?source=post_page-----e70947779ac1--------------------------------)
    [## Your Side Hustle Sucks Compared to Working for a Big Company
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[我们治疗压力、焦虑和抑郁的方法完全错了](https://medium.com/wise-well/were-treating-stress-anxiety-and-depression-all-wrong-809566f1b73b?source=post_page-----e70947779ac1--------------------------------)
    [## 你的副业不如在大公司工作'
- en: For all the freedom you gain, you miss out on many things when working for yourself
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尽管你获得了所有的自由，但在自己工作时你错过了许多东西
- en: medium.com](https://medium.com/illumination/your-side-hustle-sucks-compared-to-working-for-a-big-company-49664f1ef73?source=post_page-----e70947779ac1--------------------------------)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[你在大公司工作的体验远不如你副业的效果](https://medium.com/illumination/your-side-hustle-sucks-compared-to-working-for-a-big-company-49664f1ef73?source=post_page-----e70947779ac1--------------------------------)'
- en: 'Now that we’ve established a method to evaluate our model, we need to define
    how to measure its efficacy. Let’s first consider our synthetic document, which
    has pre-known, clear thresholds. In our case, these thresholds are: (0, 56, 74,
    118, 163). This implies that the first article concludes after 56 sentences, the
    second after 74, and so forth. Our model will likely output a similar yet more
    detailed list of thresholds based on the subtopics it identifies within each article.
    An example output might be: (0, 26, 54, 67, 74, 90, 112, 120, 130, 163).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了评估模型的方法，我们需要定义如何衡量其效能。首先考虑我们的合成文档，其中有预先知道的明确阈值。在我们的例子中，这些阈值为：（0, 56,
    74, 118, 163）。这意味着第一篇文章在56句话后结束，第二篇在74句话后结束，以此类推。我们的模型将根据它在每篇文章中识别的子主题，输出一个类似但更详细的阈值列表。一个示例输出可能是：（0,
    26, 54, 67, 74, 90, 112, 120, 130, 163）。
- en: 'So, how do we evaluate our model’s effectiveness? The most logical method I
    could devise involves computing a sort of “edit distance” between the original
    vector and the model’s output. This process works as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何评估模型的有效性？我能设计出的最合乎逻辑的方法是计算原始向量与模型输出之间的“编辑距离”。这个过程如下：
- en: Identify all the numbers in the model’s output that are closer to the true thresholds
    (excluding the first and the last ones). Using the example above we would end
    up with (54, 74, 120).
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定模型输出中所有接近真实阈值的数字（排除第一个和最后一个）。使用上面的例子，我们将得到（54, 74, 120）。
- en: If there are fewer numbers than the true thresholds, fill the gap with ‘None’
    (not happening in our example).
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果数字少于真实阈值，则用‘None’填补空白（在我们的例子中不会发生）。
- en: Compute the distance between each corresponding threshold, substituting the
    maximum value of the original vector whenever you encounter a ‘None’. In our case
    that would generate (2, 0, 2).
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算每个相应阈值之间的距离，遇到‘None’时用原始向量的最大值代替。在我们的例子中，这将生成（2, 0, 2）。
- en: 'Sum these distances and normalize by dividing by the maximum threshold of the
    original vector multiplied by the vector’s length. This provides a distance ranging
    from 0 to 1 that can be easily transformed into a score by computing: 1-distance.
    In our case: 1-4/163 → 1-0,0245 → **0,975**'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些距离求和，并通过将其除以原始向量的最大阈值乘以向量的长度来标准化。这提供了一个从0到1的距离，可以通过计算：1-距离来轻松转换为分数。在我们的例子中：1-4/163
    → 1-0.0245 → **0.975**
- en: (Optional) Impose a penalty on the score depending on the total number of thresholds.
    This is designed to penalize models that generate too many thresholds. Although
    such thresholds are statistically likely to be close to the real ones, they might
    not necessarily be meaningful.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）根据阈值总数对分数施加惩罚。这是为了惩罚生成过多阈值的模型。尽管这些阈值在统计上可能接近真实值，但它们不一定有意义。
- en: Here is the code implementing the scoring computation as described in the preceding
    steps.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是实现上述步骤中描述的评分计算的`code`。
- en: This function, as it currently stands, is far from perfect. Specifically, it
    tends to produce values that skew towards 1\. However, it will suffice for our
    purpose of comparing the results generated by our model. If you have any suggestions
    for improving its implementation, I would be more than happy to hear them in the
    comments.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数目前远未完美。具体来说，它倾向于产生偏向1的值。然而，它足以用于比较我们模型生成的结果。如果你有任何改进其实现的建议，我非常乐意在评论中听取。
- en: Generating Sentence Similarity Scores
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成句子相似度分数
- en: 'Now that we’ve established a method to assess our model’s performance, we can
    begin to consider how to extract the thresholds. The underlying concept of our
    model is quite straightforward: the tiles of our document are essentially clusters
    of sentences exhibiting some level of similarity. Put differently, pairs of sentences
    within the same tile should yield a high similarity score, while pairs of sentences
    from different tiles should yield a low one. Regardless of the clustering method
    we’ll decide to use, we can safely say that we need a similarity measure for the
    sentences. In NLP, the two most prevalent forms of similarity measures are lexical
    (based on word comparison) and semantic (based on meaning, and more technically
    on embeddings). In our model, we will test different types of similarity scores
    and compare their performance on our test document. Specifically, we will utilize
    the following models/algorithms:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了评估模型性能的方法，我们可以开始考虑如何提取阈值。我们模型的基本概念相当简单：文档的块本质上是具有某种相似性水平的句子簇。换句话说，位于同一块中的句子对应该产生较高的相似度分数，而来自不同块的句子对应该产生较低的分数。无论我们决定使用哪种聚类方法，我们都可以安全地说，我们需要一种句子相似度度量。在自然语言处理（NLP）中，最常见的两种相似度度量形式是词汇（基于词汇比较）和语义（基于意义，更技术性地基于嵌入）。在我们的模型中，我们将测试不同类型的相似度分数，并比较它们在测试文档上的表现。具体而言，我们将利用以下模型/算法：
- en: '[BERT Score](https://huggingface.co/spaces/evaluate-metric/bertscore) (semantic)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BERT 分数](https://huggingface.co/spaces/evaluate-metric/bertscore)（语义）'
- en: '[paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2)
    (semantic)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[paraphrase-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2)（语义）'
- en: '[SequenceMatcher](https://docs.python.org/3/library/difflib.html) (lexical)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SequenceMatcher](https://docs.python.org/3/library/difflib.html)（词汇）'
- en: '[Jaccard Similarity](https://en.wikipedia.org/wiki/Jaccard_index) (lexical)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jaccard 相似度](https://en.wikipedia.org/wiki/Jaccard_index)（词汇）'
- en: The function that computes the similarity scores is essentially a large “IF-ELSE”
    block of code, switching between different approaches based on the input model
    selected by the user.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 计算相似度分数的函数本质上是一个大型的“IF-ELSE”代码块，根据用户选择的输入模型在不同方法之间切换。
- en: For performance optimization, this function accepts two lists of sentences as
    input and returns the corresponding list of similarity measures.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了性能优化，该函数接受两个句子列表作为输入，并返回相应的相似度度量列表。
- en: Next, we need to decide which similarity scores we actually want to calculate.
    One approach could be to compute pairwise similarities by comparing each sentence
    with all others. This method, while comprehensive, is not only inefficient and
    hardly scalable, but also undesirable. The clusters we’re seeking will consist
    of consecutive sentences, meaning that we aren’t interested in identifying connections
    between sentences that are far apart in the document — in fact, we’re aiming to
    avoid this! At the other extreme, we could consider computing similarity only
    between a given sentence and the one that follows it. While it’s reasonable to
    assume that adjacent sentences share the same meaning, this approach carries risks
    too. Consider ‘filling sentences’ — those used to embellish the text but don’t
    convey any specific meaning or contribute to the context. Examples include phrases
    like “I’ll try to say it differently” or “But I digress” (which appears in our
    test document!). Such sentences might create artificial thresholds that we certainly
    want to avoid.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要决定实际要计算哪些相似度分数。一个方法是通过比较每个句子与所有其他句子的对比来计算逐对相似度。这种方法虽然全面，但不仅效率低下且难以扩展，而且也不理想。我们所寻求的簇将由连续的句子组成，这意味着我们不希望识别文档中相距较远的句子之间的联系——实际上，我们的目标是避免这种情况！在另一端，我们可以考虑仅计算给定句子与其后面句子之间的相似度。虽然合理地假设相邻句子具有相同的意义，但这种方法也存在风险。考虑“填充句子”——那些用于修饰文本但不传达任何特定意义或对上下文没有贡献的句子。例子包括“我会尝试不同的说法”或“但是我跑题了”（出现在我们的测试文档中！）。这样的句子可能会产生人为的阈值，我们肯定想要避免这种情况。
- en: We’ll therefore adopt a hybrid approach, where we only compute the similarity
    between each sentence and the K subsequent ones (yes, K is a hyperparameter).
    As illustrated in the figure below, once we’ve set the K parameter, each sentence
    will connect to 2*K sentences — K sentences preceding and K sentences following.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将采用一种混合方法，只计算每个句子与接下来的 K 个句子的相似度（是的，K 是一个超参数）。如下面的图示所示，一旦设置了 K 参数，每个句子将连接到
    2*K 个句子——K 个前面的句子和 K 个后面的句子。
- en: '![](../Images/35f8c03f8faacb2b6f7859325f29ace5.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35f8c03f8faacb2b6f7859325f29ace5.png)'
- en: Image by author.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。
- en: 'The code that generates the similarity scores in this manner is encapsulated
    within the function `create_similarity_graph`:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 生成这种相似度分数的代码封装在函数`create_similarity_graph`中：
- en: 'As the function name suggests, what this function constructs is a graph where
    the nodes represent sentences and the similarity scores serve as the weights of
    the edges. The output format is as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如函数名称所示，这个函数构建的是一个图，其中节点代表句子，相似性分数作为边的权重。输出格式如下：
- en: (Sentence1, Sentence2, sim_ratio1)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: （句子1，句子2，相似度比1）
- en: (Sentence1, Sentence3, sim_ratio2)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: （句子1，句子3，相似度比2）
- en: …
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: (Sentence1, SentenceK, sim_ratioK-1)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: （句子1，句子K，相似度比K-1）
- en: (Sentence2, Sentence3, sim_ratioK)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: （句子2，句子3，相似度比K）
- en: …
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: Indeed, this is essentially a graph in the form of (parent, child, edge_weight).
    It’s also important to note the coefficient `math.exp(-l/2)` at line 27, which
    multiplies the similarity scores. We employ this coefficient to accommodate the
    "distance effect"—the idea that the similarity between two sentences should decrease
    the further apart they are.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，这本质上是一个形式为（父节点，子节点，边权重）的图。还需要注意第27行的系数`math.exp(-l/2)`，它会乘以相似性分数。我们使用这个系数来适应“距离效应”——即两个句子之间的相似性应随着它们的距离增加而减少。
- en: Graph-based Clustering for Text Segmentation
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于图的文本分割
- en: With our similarity scores in hand, the next step is to find an effective way
    to cluster them. The graph structure of our current data suggests a suitable direction
    for selecting the right algorithm. There are numerous options for graph clustering,
    but I have a particular fondness for the [Louvain method for community detection](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html),
    mainly due to its ease of implementation in Python and its ability to efficiently
    handle large-scale data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 有了我们的相似度分数，下一步是找到有效的方式对其进行聚类。当前数据的图结构暗示了选择合适算法的方向。虽然有许多图聚类的选项，但我特别偏爱[Louvain社区检测方法](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html)，主要是因为它在Python中的实现简单且能够高效处理大规模数据。
- en: In the algorithm’s context, a “community” refers to a cluster of nodes densely
    interconnected, while sparsely connected with nodes from other communities. Translating
    this concept into our document tiling task, these “communities” represent the
    tiles we seek. Each tile, or community, is a cluster of highly related sentences
    forming a coherent topic or subtopic within the document.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在算法的上下文中，“社区”指的是一个节点密集互连的簇，同时与其他社区的节点连接稀疏。将这个概念转化到我们的文档分块任务中，这些“社区”就是我们寻求的块。每个块或社区是一个高度相关的句子簇，形成文档中的一个连贯主题或子主题。
- en: Given the above graph structure, extracting communities is a matter of few lines
    of code.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于上述图结构，提取社区仅需几行代码。
- en: While the Louvain algorithm excels at finding communities within our graph,
    it’s essential to remember that these communities may not always correspond to
    coherent sequences of sentences in the context of document tiling. This is because
    the algorithm is not inherently aware that it’s dealing with a textual document
    where sequence and continuity of sentences matter.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Louvain算法在寻找图中的社区方面表现出色，但重要的是要记住，这些社区在文档分块的上下文中可能并不总是对应于连贯的句子序列。这是因为该算法本身并不意识到它处理的是一个文本文档，其中句子的顺序和连续性很重要。
- en: In the process of community detection, the Louvain algorithm might produce clusters
    that include non-sequential sentences. For example, it may generate a cluster
    like (1, 2, 3, 4, 6, 7), leaving out sentence 5\. While this cluster may still
    have high internal similarity, it does not form a logical tile in the document,
    as there’s a “gap” or “jump” from sentence 4 to sentence 6\. This is a crucial
    point to consider when applying graph-based clustering to document tiling. Our
    expectation is to find coherent, uninterrupted segments of text — tiles that represent
    contiguous blocks of related content.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在社区检测过程中，Louvain算法可能会生成包含非连续句子的聚类。例如，它可能会生成一个类似（1，2，3，4，6，7）的聚类，遗漏了句子5。虽然这个聚类可能在内部相似性上仍然很高，但它并未在文档中形成一个逻辑上的块，因为从句子4到句子6有一个“间隙”或“跳跃”。在将基于图的聚类应用于文档分块时，这是一个关键点。我们的期望是找到连贯、不间断的文本段落——即代表相关内容连续块的块。
- en: 'To solve this issue, I incorporated a post-processing step in the code, specifically
    invoking the `compact_clusters` function at line 46\. As I didn''t come across
    any pre-existing algorithm performing this task (if you know one, I''d be glad
    to hear about it), I devised a simple one based on the following steps:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我在代码中加入了一个后处理步骤，特别是在第 46 行调用 `compact_clusters` 函数。由于我没有找到任何现成的算法来执行此任务（如果你知道一个，我很乐意了解），我设计了一个基于以下步骤的简单算法：
- en: For each pair of clusters, identify the range of overlap between them. Considering
    clusters a=(1, 2, 3, 6, 7, 8) and b=(4, 5, 9, 10, 11), the range overlap would
    be (4, 5, 6, 7, 8).
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每一对聚类，识别它们之间的重叠范围。考虑到聚类 a=(1, 2, 3, 6, 7, 8) 和 b=(4, 5, 9, 10, 11)，重叠范围将是
    (4, 5, 6, 7, 8)。
- en: Determine the least number of movements required to eliminate the overlap. In
    our example, we could either transfer (6, 7, 8) from cluster ‘a’ to ‘b’, or move
    (4, 5) from cluster ‘b’ to ‘a’. The optimal choice is the latter, requiring fewer
    movements. In case of a tie, a random decision can be made.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定消除重叠所需的最少移动次数。在我们的示例中，我们可以将 (6, 7, 8) 从聚类 ‘a’ 转移到 ‘b’，或者将 (4, 5) 从聚类 ‘b’ 移动到
    ‘a’。最优选择是后者，因为需要的移动次数更少。如果出现平局，可以做出随机决策。
- en: Reconfigure the clusters accordingly. Following this adjustment, we would have
    a = (1, 2, 3, 4, 5, 6, 7, 8) and b = (9, 10, 11).
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据此调整重新配置聚类。调整后，我们将得到 a = (1, 2, 3, 4, 5, 6, 7, 8) 和 b = (9, 10, 11)。
- en: This approach ensures that the final tiles we produce are not just coherent
    within themselves but also make sense in the context of the original document
    sequence.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法确保了我们生成的最终瓦片不仅在内部是一致的，而且在原始文档序列的上下文中也是有意义的。
- en: 'Here is the implementation of the function:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是函数的实现：
- en: Putting It All Together
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 汇总
- en: 'Now that we have built all our essential functions, it’s a straightforward
    task to write a script that determines the tiles of our target document. It merely
    takes a few lines of code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了所有必要的函数，编写一个确定目标文档瓦片的脚本是很简单的任务。只需几行代码：
- en: 'As previously mentioned, we’re testing only four models, but integrating additional
    ones is as easy as modifying the `get_similarity_scores` function by adding new
    ‘elif’ sections. Given the nature of our problem, it''s also quite insightful
    to construct a visual representation of the calculated tiles. This graphic depiction
    provides an immediate sense of how our algorithms are performing compared to the
    original document. Here is the plotting function I used:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们仅测试了四种模型，但集成更多模型只需通过添加新的 ‘elif’ 部分来修改 `get_similarity_scores` 函数。鉴于我们问题的性质，构建计算瓦片的可视化表示也是很有启发性的。这种图形描述提供了一个立即了解我们算法相对于原始文档表现的方式。这是我使用的绘图函数：
- en: 'And below is the resultant plot:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是结果图：
- en: '![](../Images/4db302b0747856074f0368ae9bc4eba0.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4db302b0747856074f0368ae9bc4eba0.png)'
- en: Image by author.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者。
- en: The first bar illustrates the original document, segmented into the four distinct
    articles that compose it. It’s evident that BERT Score performs impressively,
    perfectly matching all three primary thresholds, while paraphrase-MiniLM-L6-v2
    misses 2 out of 3 (barely missing the second one, and significantly deviating
    on the third). It’s also noteworthy that the two semantic models identify quite
    similar subtopics within the articles, suggesting the potential to employ an ensemble
    approach for determining accurate thresholds in real-world applications. Surprisingly,
    the lexical models didn’t perform too poorly, although Jaccard did introduce spurious
    thresholds that don’t correlate with the document’s structure.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条柱状图展示了原始文档，分割成四篇不同的文章。可以明显看出，BERT Score 的表现非常出色，完美匹配了所有三个主要阈值，而 paraphrase-MiniLM-L6-v2
    在三个阈值中有两个未能匹配（第二个几乎匹配，第三个则偏差较大）。值得注意的是，这两个语义模型在文章中识别出了非常相似的子主题，暗示了可以使用集成方法来确定实际应用中的准确阈值。令人惊讶的是，词汇模型的表现并不差，尽管
    Jaccard 引入了一些与文档结构不相关的虚假阈值。
- en: 'To sum up, here are the scores of the four tested algorithms:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，以下是四种测试算法的得分：
- en: 'BERT Score: **0.9950**'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'BERT Score: **0.9950**'
- en: 'paraphrase-MiniLM-L6-v2: **0.9321**'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'paraphrase-MiniLM-L6-v2: **0.9321**'
- en: 'SequenceMatcher: **0.9208**'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'SequenceMatcher: **0.9208**'
- en: 'Jaccard: **0.9830**'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jaccard: **0.9830**'
- en: Takeaway and next steps
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收获与下一步
- en: 'Based on our short test involving the target document, it’s clear that the
    proposed approach to document tiling exhibits significant promise. As we anticipated,
    the semantic approach shows an advantage over the lexical one for this specific
    task due to its ability to capture deeper, context-based relationships within
    the text. The repository with the working code explained in this article is available
    [here](https://github.com/massi82/texttiling). Possible areas of improvement include:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们涉及目标文档的简短测试，很明显，提出的文档标题方法展示了显著的前景。正如我们预期的那样，由于语义方法能够捕捉文本中更深层次的上下文关系，因此在这个特定任务中相比词汇方法具有优势。本文中解释的工作代码的代码库可在[此处](https://github.com/massi82/texttiling)找到。可能的改进领域包括：
- en: '**Refinement of the Scoring Function**: The current tiling score function exhibits
    a bias towards the value of 1\. Addressing this bias to make the scoring function
    more balanced would improve the reliability of the results and provide a more
    accurate assessment of model performance.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评分函数的优化**：当前的标题评分函数表现出对值1的偏倚。解决这一偏倚，使评分函数更加平衡，将提高结果的可靠性，并提供对模型性能的更准确评估。'
- en: '**Exploration of Additional Models**: We tested only four models in this study.
    Testing additional models, especially different types of semantic models, could
    reveal new insights and further improve performance. This could also include experimenting
    with ensemble approaches that combine the strengths of multiple models.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**探索额外的模型**：本研究中我们只测试了四种模型。测试更多的模型，特别是不同类型的语义模型，可能会揭示新的见解，并进一步提高性能。这也可以包括尝试结合多个模型优点的集成方法。'
- en: '**Validation Across Multiple Documents**: Our test involved just one document.
    Evaluating the performance of our approach over a variety of documents would give
    us a clearer picture of its robustness and generalizability. Different types of
    texts, genres, or topics could affect the performance of the tiling process.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**跨多个文档的验证**：我们的测试仅涉及一个文档。对各种文档进行性能评估将使我们更清楚其稳健性和普遍性。不同类型的文本、体裁或主题可能会影响标题生成过程的表现。'
- en: '**Enhancement of Subtopic Identification**: Although our models identified
    subtopics within the articles, there is potential for refinement. An ensemble
    method or other advanced strategies could be used to improve the accuracy of subtopic
    determination, ensuring that the derived tiles reflect the nuanced structure of
    the document.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**子主题识别的提升**：尽管我们的模型能够识别文章中的子主题，但仍有改进的空间。可以使用集成方法或其他高级策略来提高子主题确定的准确性，确保衍生的标题反映出文档的细致结构。'
- en: Did you enjoy this article? If you’re looking for applications of AI, NLP, Machine
    Learning and Data Analytics in solving real-world problems, you’ll likely enjoy
    my other work as well. My goal is to craft actionable articles that show these
    transformative technologies in practical scenarios. If this is also you, follow
    me on Medium to stay informed about my latest pieces!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你喜欢这篇文章吗？如果你对人工智能、自然语言处理、机器学习和数据分析在解决实际问题中的应用感兴趣，你可能也会喜欢我的其他作品。我的目标是创作能够展示这些变革性技术在实际场景中的可操作性文章。如果这也是你的兴趣，关注我在Medium上的最新作品吧！
