- en: Carbon Emissions of an ML Engineering Team
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个机器学习工程团队的碳排放
- en: 原文：[https://towardsdatascience.com/carbon-emissions-of-an-ml-engineering-team-ce170bd4fae9](https://towardsdatascience.com/carbon-emissions-of-an-ml-engineering-team-ce170bd4fae9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/carbon-emissions-of-an-ml-engineering-team-ce170bd4fae9](https://towardsdatascience.com/carbon-emissions-of-an-ml-engineering-team-ce170bd4fae9)
- en: The hidden cost of development that really matter
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发的隐性成本
- en: '[](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)[![Jake
    Teo](../Images/9687f43822fab69befb750a8ec58516d.png)](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)
    [Jake Teo](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)[![Jake
    Teo](../Images/9687f43822fab69befb750a8ec58516d.png)](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)
    [Jake Teo](https://medium.com/@teosiyang?source=post_page-----ce170bd4fae9--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)
    ·9 min read·Oct 16, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----ce170bd4fae9--------------------------------)
    ·9分钟阅读·2023年10月16日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Everybody is aware of the climate crisis due to global warming as a result of
    human activities. To prevent its catastrophic consequences [1], the world needs
    to reduce our greenhouse gas emissions drastically, with many countries setting
    a target of net zero emissions by 2050.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 由于人为活动导致的全球变暖，大家都意识到了气候危机。为了防止其灾难性后果[1]，世界需要大幅减少我们的温室气体排放，许多国家设定了到2050年实现净零排放的目标。
- en: The technology boom of AI in recent years has also raised concerns about its
    environmental cost. If we only look at its direct contributions, this will come
    through the use of electricity to train and power models. For example, training
    ChatGPT-3 with its 175 billion parameters generated a whopping 502 tonnes of carbon
    equivalent emissions (tCO2e) [2]. The new kid on the block Llama2 outputs a similar
    539 tCO2e for training its family of four models [3]. For context, each of these
    is equivalent to the emissions of a passenger taking a one-way flight from New
    York to San Francisco 500 times.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来AI技术的蓬勃发展也引发了对其环境成本的担忧。如果我们仅仅关注其直接贡献，这将通过电力使用来训练和驱动模型。例如，训练具有1750亿参数的ChatGPT-3产生了高达502吨的碳当量排放（tCO2e）[2]。新兴的Llama2在训练其四个模型时产生了类似的539吨tCO2e[3]。作为对比，每一个模型的排放量相当于一名乘客从纽约到旧金山单程飞行500次的排放量。
- en: I work in a machine learning engineering team, and this question also nudged
    me constantly. How much carbon emissions do we contribute through electricity
    consumption? Are there ways to reduce it? And here starts a first attempt at carbon
    accounting ourselves.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我在一个机器学习工程团队工作，这个问题也时常困扰着我。我们通过电力消耗贡献了多少碳排放？是否有减少的方法？于是，我们开始首次尝试进行碳排放核算。
- en: '![](../Images/a849f3ef32d0a93e1c7acdfa9bb2bc17.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a849f3ef32d0a93e1c7acdfa9bb2bc17.png)'
- en: Photo by [Chris LeBoutillier](https://unsplash.com/@chrisleboutillier?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Chris LeBoutillier](https://unsplash.com/@chrisleboutillier?utm_source=medium&utm_medium=referral)提供，来自[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '**Methods**'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**方法**'
- en: There is no single and direct way to measure our electricity consumption and
    consequently our carbon impact. This is due to the variety of platforms and services
    we use. I will not dive deep into the technical implementations, but at a high
    level, it consists of three methods.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 没有单一直接的方法来测量我们的电力消耗以及随之而来的碳影响。这是因为我们使用的平台和服务多种多样。我不会深入探讨技术实现，但从高层次来看，方法包括三种。
- en: '**Provided**: The exact carbon emission figures are already computed for us.
    This was given by our cloud service provider (CSP).'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**提供**：确切的碳排放数据已经为我们计算好了。这是我们的云服务提供商（CSP）提供的。'
- en: '**Tools**: We used a few software tools like Powermetics, Nvidia-SMI, and Turbostat
    to measure power in Watts, which tracks the CPU and GPU compute for our laptops
    and on-premise server.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**工具**：我们使用了像 Powermetics、Nvidia-SMI 和 Turbostat 这样的几种软件工具来测量功率（瓦特），这些工具跟踪我们笔记本电脑和本地服务器的
    CPU 和 GPU 计算。'
- en: '**Self-Calculated**: When the above is not possible, we use proxy methods to
    calculate. This consists of recording the duration of the compute, estimating
    the percentage utilisation of the chip(s), as well as finding the thermal design
    power (TDP) of each chip type to calculate the power consumed. The rest of the
    platforms are calculated this way.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自我计算**：当上述方法不可行时，我们使用代理方法进行计算。这包括记录计算的持续时间，估计芯片的利用率百分比，以及查找每种芯片类型的热设计功率（TDP）来计算功耗。其余平台以这种方式计算。'
- en: For the latter two methods, power is then converted into energy (kWh), and where
    available, the Power Usage Efficiency (PUE) of the supporting data centres are
    used to obtain a more accurate energy consumption. The Grid Emission Factor (in
    kgCO2e/kWh) of the country or region is then finally used to compute the greenhouse
    gas emissions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于后两种方法，功率会被转换为能量（千瓦时），如果有的话，会使用支持数据中心的电力使用效率（PUE）来获得更准确的能量消耗。最后，使用该国或地区的电网排放因子（kgCO2e/kWh）来计算温室气体排放。
- en: '**Results & Thoughts**'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结果与思考**'
- en: The results are displayed in the pie chart below.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在下面的饼图中。
- en: '![](../Images/6df4af38265170bbd72e27bf57cce2fd.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6df4af38265170bbd72e27bf57cce2fd.png)'
- en: Carbon emissions of each platform we used extrapolated for the whole of 2023\.
    Image by author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的每个平台的碳排放量 extrapolated 为整个 2023 年。图像由作者提供。
- en: It isn’t particularly surprising on the ranking of the platforms in terms of
    carbon usage, but I was surprised with the percentages. I did not expect our development
    laptops and CICD service, with very heavy usage, to produce only a minuscule of
    carbon. While on the next extreme, I also did not expect our on-premise server
    for development and model training to burn x3 more carbon compared to our cloud
    usage.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在碳排放排名方面，平台的排名并不特别令人惊讶，但我对百分比感到惊讶。我没有想到我们的开发笔记本电脑和 CICD 服务在非常重的使用下只产生了微量的碳。与此同时，我也没想到我们的本地开发和模型训练服务器会消耗比我们的云服务多三倍的碳。
- en: In hindsight, we have recently switched to the latest Apple Silicon M2 chip
    for our laptops which is well-known to be highly efficient. Our CICD platform,
    while having thousands of minutes of pipeline runtime, uses the lowest compute
    chips, and is essentially serverless, only running when necessary.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾过去，我们最近将笔记本电脑升级到了最新的 Apple Silicon M2 芯片，这一芯片以高效著称。我们的 CICD 平台虽然拥有数千分钟的流水线运行时间，但使用的是最低计算芯片，实际上是无服务器的，仅在必要时运行。
- en: For our on-premise server, we discovered that idle Nvidia GPU chips still consume
    significant electricity, resulting in a bloated electricity consumption. We will
    need to investigate if there were any misconfigurations, and if not, whether there
    is any way to better manage them.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的本地服务器，我们发现空闲的 Nvidia GPU 芯片仍然消耗大量电力，导致电力消耗膨胀。我们需要调查是否存在任何配置错误，如果没有，是否有更好的管理方法。
- en: '**Green Computing**'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**绿色计算**'
- en: Now that we have a better awareness of our carbon usage, how can we truly transform
    our development team to adopt more green solutions?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对碳排放的认识有了更好的了解，我们如何才能真正改变开发团队，采用更多绿色解决方案呢？
- en: The term green computing has been out there for a while, and it has been organised
    or classified in different forms, but I feel that the six broad themes below will
    help my team manage the green transition with better clarity.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 绿色计算这个术语已经存在了一段时间，并且已被组织或分类成不同的形式，但我认为下面这六个广泛的主题将帮助我的团队更清晰地管理绿色转型。
- en: '![](../Images/cd273f318f90ee2b585bc5325fb76778.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd273f318f90ee2b585bc5325fb76778.png)'
- en: Photo by [Ash from Modern Afflatus](https://unsplash.com/@modernafflatusphotography?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Ash from Modern Afflatus](https://unsplash.com/@modernafflatusphotography?utm_source=medium&utm_medium=referral)
    提供的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '**1\. Green AI**'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1\. 绿色 AI**'
- en: This refers to finding ways to **more efficiently train and infer models with
    little or acceptable loss in quality**. It would basically translate to faster
    training and inference time, as well as smaller model sizes, using less compute
    power. The use of more complex neural networks demands ever larger datasets and
    increasingly advanced, prohibitively expensive and energy-hungry GPU chips.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是寻找**更高效地训练和推断模型以尽量减少质量损失**的方法。它基本上意味着更快的训练和推断时间，以及更小的模型尺寸，使用更少的计算能力。使用更复杂的神经网络需要越来越大的数据集以及日益先进、昂贵且耗能巨大的GPU芯片。
- en: Luckily, this has also been a hotbed for the latest optimisation research. In
    the past few years, I heard from my data scientist colleagues from using more
    efficient architectures in each domain, transfer-learning, compression techniques
    like quantisation or knowledge distillation, [ONNX](https://onnx.ai), to using
    [deepspeed](https://github.com/microsoft/DeepSpeed), [PEFT](https://github.com/huggingface/peft)
    and others in today’s era of large language models. No doubt we will need to keep
    up with the latest implementations the open-source world comes up with as their
    benefits have proven to be significant.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这也是最新优化研究的热点。在过去几年中，我听说我的数据科学家同事们在各个领域使用更高效的架构、迁移学习、量化或知识蒸馏等压缩技术、[ONNX](https://onnx.ai)、使用[deepspeed](https://github.com/microsoft/DeepSpeed)、[PEFT](https://github.com/huggingface/peft)等，以应对当今大语言模型时代的挑战。毫无疑问，我们需要跟上开源世界最新实施的步伐，因为它们的好处已被证明是显著的。
- en: '**2\. Green Apps**'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**2\. 绿色应用**'
- en: Models are useless without the code that builds around them to process the data,
    train the model, and ultimately serve them. Fundamental understanding of **time
    and space complexities**, the algorithms to implement, and also the various pre-built
    functions to apply them is required. Profilers to find bottlenecks in latency
    and memory should also be used.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在没有周围代码来处理数据、训练模型和**最终提供服务**的情况下是无用的。需要对**时间和空间复杂性**、实现的算法以及各种预构建函数有基本的理解。还应使用性能分析工具来查找延迟和内存中的瓶颈。
- en: Another important software engineering skill to build green apps is to understand
    how **tasks and processes are managed, executed, and coordinated**. This requires
    a firm grasp of concepts like parallelism, concurrency, asynchrony, multi-processing
    and threading, queuing, I/O and CPU limiting tasks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个构建绿色应用程序的重要软件工程技能是理解**任务和进程的管理、执行和协调**。这需要对并行性、并发性、异步性、多处理和线程、队列、I/O和CPU限制任务等概念有扎实的掌握。
- en: To take a step further, the **programming language** used also comes into play.
    Python has emerged to be one of the top languages used in data science and general
    programming due to its widespread support and ease of use. However, as an interpreted
    language, it is significantly inferior compared to its compiled cousins like Go
    in terms of energy and speed (about x20) [4]. It is thus worth investing the effort
    to learn a second compiled language to cater for some jobs that require heavy
    processing.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 更进一步，**编程语言**的选择也很重要。由于其广泛的支持和易用性，Python 已成为数据科学和通用编程中使用的顶级语言之一。然而，作为一种解释性语言，与其编译语言如
    Go 相比，在能耗和速度（约 x20）方面显著逊色[4]。因此，值得花费时间学习另一种编译语言，以应对需要大量处理的工作。
- en: '**3\. Green Servers**'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3\. 绿色服务器**'
- en: To train and serve ML applications, compute power is required. This is provided
    by servers hosted either on-premise or in the cloud. If possible, going cloud
    is the best way to stay green since CSPs are incentivised to run their data centres
    efficiently, and you have the flexibility to switch resources based on project
    demands. Either way, we should ensure two key factors; choose the **right hardware**
    for the task, and use the **compute only when required**.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和服务机器学习应用需要计算能力。这由托管在本地或云端的服务器提供。如果可能的话，使用云服务是保持绿色的最佳方式，因为云服务提供商有动力高效运行其数据中心，而且你可以根据项目需求灵活切换资源。无论如何，我们应确保两个关键因素：选择**正确的硬件**来完成任务，以及**仅在需要时使用计算资源**。
- en: Major CSPs all have a diverse selection of servers to choose from. E.g., AWS
    has seven instance families each having a range of different chips, memory and
    other specifications, enough to cater for all scenarios like GPU, CPU, memory-intensive
    processes, or even ARM or x86 architecture. We should choose those that best maximise
    our use case so that compute is efficiently allocated through its hardware specifications.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的 CSP 都提供了多样的服务器供选择。例如，AWS 有七个实例家族，每个家族包含不同的芯片、内存和其他规格，足以满足各种需求，如 GPU、CPU、内存密集型过程，甚至
    ARM 或 x86 架构。我们应选择那些最佳匹配我们的用例的服务器，以便通过其硬件规格高效分配计算资源。
- en: How do we compute only when required? For a start, stock-take and turn off any
    resources that are not in use. You will be surprised how many idle services are
    left from legacy projects. In terms of architecture design, we can choose to use
    serverless compute like AWS lambda which only uses the resource when there is
    traffic, or provide a basic long-live compute with horizontal scaling that responds
    automatically to increased load.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何在需要时才计算？首先，对所有不使用的资源进行盘点并关闭。你会惊讶于遗留项目中还有多少闲置的服务。在架构设计方面，我们可以选择使用类似 AWS lambda
    的无服务器计算，它只有在有流量时才使用资源，或者提供一个基本的长生命周期计算，具有水平扩展功能，可以自动响应负载增加。
- en: '**4\. Green Storage**'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**4\. 绿色存储**'
- en: Storage comes in many forms, e.g. object, block and file storage, container
    registries and databases. We can use two general guides to manage storage efficiently;
    **reduce the storage size** and **choose the right storage type**.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 存储有多种形式，如对象存储、块存储和文件存储、容器注册表和数据库。我们可以使用两个一般性的指南来高效管理存储：**减少存储大小**和**选择合适的存储类型**。
- en: Storage size of data can be reduced simply by compression, some of the common
    ones being [gzip](https://www.gnu.org/software/gzip/) or for archival `tar.gz`,
    which can reduce the size by half. Using a more efficient data structure can also
    be a better alternative. Using a columnar format like [parquet](/csv-files-for-storage-no-thanks-theres-a-better-option-72c78a414d1d)
    not only occupies less space (>50%), but also enables faster queries (x30) due
    to the nature of its columnar structure.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的存储大小可以通过压缩来减少，一些常见的压缩工具包括 [gzip](https://www.gnu.org/software/gzip/) 或用于归档的
    `tar.gz`，它可以将大小减少一半。使用更高效的数据结构也可以是一个更好的替代方案。使用像 [parquet](/csv-files-for-storage-no-thanks-theres-a-better-option-72c78a414d1d)
    这样的列式格式不仅占用空间更少（>50%），而且由于其列式结构的特性，也使查询速度更快（提高30倍）。
- en: Taking the example of object storage, there are storage classes that use less
    energy. In AWS S3, we can choose to keep less important data in one zone rather
    than replicate it across zones. For infrequently access, long-term storage, we
    can place them in “cold storage” (S3 glacier), where tape drives which consume
    a lot less energy compared to SSDs and HDDs are used. Lifecycle policies can also
    be set to automate transit between storage classes or even delete the data when
    a project reaches its conclusion.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以对象存储为例，有一些存储类别使用更少的能源。在 AWS S3 中，我们可以选择将不太重要的数据保留在一个区域，而不是在多个区域中复制。对于不经常访问的长期存储，我们可以将其放入“冷存储”（S3
    glacier），那里使用的磁带驱动器相比 SSD 和 HDD 消耗更少的能源。还可以设置生命周期策略来自动在存储类别之间转换，甚至在项目结束时删除数据。
- en: '**5\. Green Transfers**'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**5\. 绿色传输**'
- en: Data needs to be transmitted to and fro between servers, storage and other devices.
    Network communication requires energy too, to support a complex weave of networking
    devices, data centers, transmission infrastructure and end-user devices. For developers
    like us, we can reduce our carbon impact through the use of **efficient transfer
    protocols**, as well as the **reducing the frequency and distance of transfers**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据需要在服务器、存储和其他设备之间来回传输。网络通信也需要能源，以支持复杂的网络设备、数据中心、传输基础设施和终端用户设备。对于我们这样的开发者，我们可以通过使用**高效的传输协议**以及**减少传输的频率和距离**来降低碳足迹。
- en: Where possible, the http/2 transfer protocol with the gRCP framework should
    be considered, since it can transmit in a more compact binary format rather than
    the traditional text (JSON) payloads in http/1\. Of course with that comes lower
    latency and energy used.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，应考虑使用 http/2 传输协议和 gRCP 框架，因为它可以以更紧凑的二进制格式传输，而不是传统的文本（JSON）有效载荷的 http/1。这样可以降低延迟和能源消耗。
- en: Bringing data closer to the source of usage, and scheduling their transfers
    can also decrease the energy required. For example, dependencies required to run
    our automated test cases can be cached and rebuilt only when new changes are detected.
    Images do not need to be pulled from Dockerhub every time; we can store them in
    our CSP’s registry and only update them periodically when new patches are available.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据更靠近使用源，并安排它们的传输时间，也可以减少所需的能量。例如，运行自动化测试用例所需的依赖项可以缓存，并且仅在检测到新更改时才重新构建。镜像不需要每次都从
    Dockerhub 拉取；我们可以将它们存储在我们的 CSP 注册表中，并在有新补丁时定期更新。
- en: '**6\. Green Templates**'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**6\. 绿色模板**'
- en: This refers to the **reusability and repeatability** of efficient code, infrastructure
    and processes. In essence, this is an indirect form of reducing electricity consumption,
    since the actual implementations are from the previous five themes. However, I
    consider this as the most important one since it is the sum of the team knowledge.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是**高效代码、基础设施和流程的可重用性和可重复性**。本质上，这是一种间接减少电力消耗的方式，因为实际实现来自前五个主题。然而，我认为这是最重要的一点，因为它是团队知识的总和。
- en: It can come in the form of documentation or playbooks that set the standards
    for the team functions and how projects are executed, or cookie-cutter templates
    for repositories, CICD pipelines, infrastructure setups (e.g., Terraform) and
    configurations (e.g., Ansible).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以以文档或剧本的形式出现，设定团队职能和项目执行的标准，或为仓库、CICD 流水线、基础设施设置（例如 Terraform）和配置（例如 Ansible）提供现成模板。
- en: '![](../Images/626caa5ca6f83abf2162ff397acff147.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/626caa5ca6f83abf2162ff397acff147.png)'
- en: Decision quadrant to prioritise high-impact and easy-to-implement solutions.
    Image by author.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 决策象限以优先考虑高影响力和易于实施的解决方案。图片来自作者。
- en: Within each of the six themes, I have given some examples, but that is only
    the tip of the iceberg. The recommendations to implement within each theme are
    numerous and daunting. However, a progressive transition can be done by placing
    each of them in a decision quadrant through estimations of how difficult they
    are to implement in our existing workflows as well as if their impacts are significant
    and synergistic. This will provide some guidance on which ones to prioritise.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这六个主题中的每一个，我都给出了一些示例，但这仅仅是冰山一角。在每个主题中实施的建议众多且令人望而生畏。然而，通过将每个建议放在决策象限中，估算它们在现有工作流程中的实施难度，以及它们的影响是否显著和协同，可以实现渐进式过渡。这将提供一些关于优先考虑哪些建议的指导。
- en: '**Design Principles**'
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**设计原则**'
- en: This transformation is neither straightforward nor easy. Even for passionate
    tree-hugging developers like us who care, we still need to prioritise our business
    needs. One way we can deal with this is **not to think of sustainability and carbon
    efficiency in ML development as antagonistic or mutually exclusive to other needs**.
    This will ensure that you are still aligned to business goals and also get easier
    buy-in with management who are always pressured with delivery.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转变既不直接也不容易。即便是像我们这样热衷于可持续发展的开发者，也必须优先考虑业务需求。我们可以通过**不把可持续性和碳效率在机器学习开发中视为与其他需求对立或相互排斥的概念**来应对这一挑战。这将确保你仍然与业务目标保持一致，同时也能更容易获得管理层的支持，他们总是面临着交付的压力。
- en: We can visualise this as a Venn diagram using AWS’s six design pillars of its
    [Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/?wa-lens-whitepapers.sort-by=item.additionalFields.sortDate&wa-lens-whitepapers.sort-order=desc&wa-guidance-whitepapers.sort-by=item.additionalFields.sortDate&wa-guidance-whitepapers.sort-order=desc),
    where functional or business needs overlap with sustainability.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其可视化为一个维恩图，使用 AWS 的六个设计支柱来构建其[架构良好框架](https://aws.amazon.com/architecture/well-architected/?wa-lens-whitepapers.sort-by=item.additionalFields.sortDate&wa-lens-whitepapers.sort-order=desc&wa-guidance-whitepapers.sort-by=item.additionalFields.sortDate&wa-guidance-whitepapers.sort-order=desc)，其中功能或业务需求与可持续性重叠。
- en: '![](../Images/ba1e5b364e7c079b85b26117f459e50b.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba1e5b364e7c079b85b26117f459e50b.png)'
- en: Reimagining the Well-Architected Framework. Image by author.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 重新构想架构良好框架。图片来自作者。
- en: 'In fact, if you think about it, there are more often than not, synergistic
    impacts. Let’s take some examples:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果你仔细思考，通常会发现协同影响。让我们来看一些例子：
- en: Compressing your data storage can reduce x2 size and results in terms of cost
    savings and bandwidth, and also less energy to store and transfer them
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 压缩数据存储可以减少 x2 大小，从而节省成本和带宽，同时也减少了存储和传输所需的能量。
- en: Quantisation of neural network models has better performance in terms of faster
    inference, and hence consuming less energy
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络模型的量化在推理速度方面表现更好，从而消耗更少的能量。
- en: Removing unused dependencies in your docker images will improve security through
    the reduction of potentially exploitable surface area, increase the speed of deployment
    with its smaller size, and reduce the energy to store and transfer them to and
    from your registry.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除 Docker 镜像中的未使用依赖项将通过减少潜在的可利用表面积来提高安全性，增加由于镜像体积较小而导致的部署速度，并减少存储和传输到及从你的注册中心所需的能量。
- en: Conclusion
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: All-in-all, this was a good kickstart of our journey to reduce our carbon impact
    in the engineering team. There will be a lot more work to identify, quantify,
    standardise and educate each recommendation that falls under each theme of green
    computing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这为我们工程团队减少碳足迹的旅程提供了一个良好的开端。接下来还会有大量的工作需要识别、量化、标准化和教育每个绿色计算主题下的推荐措施。
- en: I would like to hear about your journey in measuring and reducing your carbon
    footprint in your development team. Please share in the comments below!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望听到你在测量和减少开发团队碳足迹方面的旅程。请在下面的评论中分享！
- en: '***Acknowledgements****: This carbon accounting attempt is a personal project
    done together with my peers,* [*Yang Kewen*](https://medium.com/u/a874892260e0?source=post_page-----ce170bd4fae9--------------------------------)
    *and* [*Chong-Yaw Wee*](https://medium.com/u/13e5c1d5b037?source=post_page-----ce170bd4fae9--------------------------------)*.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '***致谢***：这次碳核算尝试是我与我的同行* [*杨可文*](https://medium.com/u/a874892260e0?source=post_page-----ce170bd4fae9--------------------------------)
    *和* [*钟耀威*](https://medium.com/u/13e5c1d5b037?source=post_page-----ce170bd4fae9--------------------------------)*
    一起完成的个人项目。*'
- en: '***Disclaimer****: Opinions and recommendations expressed here are done in
    the author’s personal capacity.*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '***免责声明***：这里表达的意见和建议仅代表作者个人观点。*'
- en: References
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] UN Environment Programme. Facts about the climate emergency. [https://www.unep.org/facts-about-climate-emergency](https://www.unep.org/facts-about-climate-emergency)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] 联合国环境规划署. 关于气候紧急情况的事实. [https://www.unep.org/facts-about-climate-emergency](https://www.unep.org/facts-about-climate-emergency)'
- en: '[2] Standfort University. Artificial Intelligence Index Report 2023\. Chapter
    2, Technical Performance. [https://aiindex.stanford.edu/report/](https://aiindex.stanford.edu/report/)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] 斯坦福大学. 人工智能指数报告2023. 第二章，技术性能. [https://aiindex.stanford.edu/report/](https://aiindex.stanford.edu/report/)'
- en: '[3] Touvron, et. al. 2023\. Llama 2: Open Foundation and Fine-Tuned Chat Models.
    *arXiv:2307.09288\.* [https://browse.arxiv.org/pdf/2307.09288.pdf](https://browse.arxiv.org/pdf/2307.09288.pdf)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Touvron 等. 2023. Llama 2: 开放基础与微调聊天模型. *arXiv:2307.09288\.* [https://browse.arxiv.org/pdf/2307.09288.pdf](https://browse.arxiv.org/pdf/2307.09288.pdf)'
- en: '[4] Pereira, et. al. 2017\. Energy efficiency across programming languages:
    how do energy, time, and memory relate? *Proceedings of the 10th ACM SIGPLAN International
    Conference on Software Language Engineering*. pp 256–267.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Pereira 等. 2017. 编程语言的能源效率：能源、时间和内存如何相关？*第10届 ACM SIGPLAN 国际软件语言工程会议论文集*.
    第256–267页。'
