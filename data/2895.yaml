- en: 'Unlocking the Power of Facial Blurring in Media: A Comprehensive Exploration
    and Model Comparison'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 媒体中面部模糊的力量解锁：全面探索与模型比较
- en: 原文：[https://towardsdatascience.com/unlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513?source=collection_archive---------3-----------------------#2023-09-18](https://towardsdatascience.com/unlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513?source=collection_archive---------3-----------------------#2023-09-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513?source=collection_archive---------3-----------------------#2023-09-18](https://towardsdatascience.com/unlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513?source=collection_archive---------3-----------------------#2023-09-18)
- en: Comparison of various face detection and blurring algorithms
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 各种人脸检测和模糊算法的比较
- en: '[](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)[![Danilo
    Najkov](../Images/e0e8976f1f9f78ae58ba7efcc90a4f00.png)](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)[](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)
    [Danilo Najkov](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)[![Danilo
    Najkov](../Images/e0e8976f1f9f78ae58ba7efcc90a4f00.png)](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)[](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)
    [Danilo Najkov](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F19802d0e7d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&user=Danilo+Najkov&userId=19802d0e7d&source=post_page-19802d0e7d----261031603513---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)
    ·12 min read·Sep 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F261031603513&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&user=Danilo+Najkov&userId=19802d0e7d&source=-----261031603513---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F19802d0e7d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&user=Danilo+Najkov&userId=19802d0e7d&source=post_page-19802d0e7d----261031603513---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)
    ·12 min read·2023年9月18日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F261031603513&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&user=Danilo+Najkov&userId=19802d0e7d&source=-----261031603513---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F261031603513&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&source=-----261031603513---------------------bookmark_footer-----------)![](../Images/7ec96f1f4a35203a82b0f809c11a43be.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F261031603513&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&source=-----261031603513---------------------bookmark_footer-----------)![](../Images/7ec96f1f4a35203a82b0f809c11a43be.png)'
- en: Processed photo by [OSPAN ALI](https://unsplash.com/@ospanali?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 处理过的照片由 [OSPAN ALI](https://unsplash.com/@ospanali?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In today’s data-driven world, ensuring the privacy and anonymity of individuals
    is of paramount importance. From protecting personal identities to complying with
    stringent regulations like GDPR, the need for efficient and reliable solutions
    to anonymize faces in various media formats has never been greater.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今数据驱动的世界中，确保个人隐私和匿名性至关重要。从保护个人身份到遵守严格的法规，如GDPR，对各种媒体格式中人脸匿名化的高效可靠解决方案的需求从未如此迫切。
- en: Contents
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内容
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍
- en: Face Detection
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测
- en: '- Haar Cascade'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- Haar Cascade'
- en: '- MTCNN'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- MTCNN'
- en: '- YOLO'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- YOLO'
- en: Face Blurring
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸模糊
- en: '- Gaussian Blur'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 高斯模糊'
- en: '- Pixelization'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 像素化'
- en: Results and Discussion
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果与讨论
- en: '- Real-Time performance'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 实时性能'
- en: '- Scenario-based evaluation'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 基于场景的评估'
- en: '- Privacy'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- 隐私'
- en: Usage in videos
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频中的使用
- en: Web Application
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web应用程序
- en: Conclusion
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结论
- en: Introduction
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'In this project, we explore and compare several solutions for the topic of
    face blurring and develop a web application that allows for easy evaluation. Let’s
    explore the diverse applications driving the demand for such a system:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们探讨并比较了多种人脸模糊解决方案，并开发了一个允许轻松评估的web应用程序。让我们深入了解推动对这种系统需求的多样化应用：
- en: Preserving Privacy
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护隐私
- en: 'Navigating Regulatory Landscapes: With the regulatory landscape evolving rapidly,
    industries and regions worldwide are enforcing stricter norms to safeguard individuals’
    identities.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导航法规环境：随着法规环境的迅速变化，全球各地的行业和地区正在实施更严格的规范，以保护个人身份。
- en: 'Training Data Confidentiality: Machine learning models thrive on diverse and
    well-prepared training data. However, sharing such data often requires careful
    anonymization.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据保密性：机器学习模型依赖于多样化且准备充分的训练数据。然而，分享这些数据通常需要仔细的匿名化处理。
- en: 'This solution can be distilled into two essential components:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案可以归结为两个基本组成部分：
- en: '**Face Detection**'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸检测**'
- en: '**Face Blurring Techniques**'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸模糊技术**'
- en: Face detection
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测
- en: To address the anonymization challenge, the first step is to locate the area
    in the image where a face is present. For this purpose, I tested three models
    for image detection.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决匿名化挑战，第一步是定位图像中存在人脸的区域。为此，我测试了三个图像检测模型。
- en: Haar Cascade
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Haar Cascade
- en: '![](../Images/718074f086356a231521438c3ac97d63.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/718074f086356a231521438c3ac97d63.png)'
- en: Figure 1\. Haar-like features ([source](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)
    — original paper)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 类似Haar的特征 ([source](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)
    — 原始论文)
- en: Haar Cascade is a machine learning method used for object detection, such as
    faces, in images or videos. It operates by utilizing a set of trained features
    called ‘Haar-like features’ (Figure 1), which are simple rectangular filters that
    focus on variations in pixel intensity within regions of the image. These features
    can capture edges, angles, and other characteristics commonly found in faces.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Haar Cascade是一种用于图像或视频中物体检测的机器学习方法，如人脸。它通过利用一组训练过的特征，称为‘类似Haar的特征’（图1），这些特征是简单的矩形滤波器，集中于图像区域内像素强度的变化。这些特征可以捕捉边缘、角度及其他在脸部常见的特征。
- en: The training process involves providing the algorithm with positive examples
    (images containing faces) and negative examples (images without faces). The algorithm
    then learns to differentiate between these examples by adjusting the weights of
    the features. After training, the Haar Cascade essentially becomes a hierarchy
    of classifiers, with each stage progressively refining the detection process.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程包括向算法提供正面示例（包含人脸的图像）和负面示例（不包含人脸的图像）。算法通过调整特征的权重来学习区分这些示例。训练后，Haar Cascade本质上成为一个分类器的层级结构，每个阶段逐步细化检测过程。
- en: For face detection, I utilized a pre-trained Haar Cascade model trained on [forward-facing
    images of faces](https://github.com/kipr/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于人脸检测，我使用了一个在[正面人脸图像](https://github.com/kipr/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)上训练的预训练Haar
    Cascade模型。
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: MTCNN
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MTCNN
- en: '![](../Images/6a604819c3e72d536a3710a48dcadc6b.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a604819c3e72d536a3710a48dcadc6b.png)'
- en: Figure 2\. Face detection process in MTCNN ([source](https://arxiv.org/abs/1604.02878)
    — original paper)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. MTCNN中的人脸检测过程 ([source](https://arxiv.org/abs/1604.02878) — 原始论文)
- en: MTCNN (Multi-Task Cascaded Convolutional Networks) stands as a sophisticated
    and highly accurate algorithm for face detection, surpassing the capabilities
    of Haar Cascades. Designed to excel in scenarios with diverse face sizes, orientations,
    and lighting conditions, MTCNN leverages a series of neural networks, each tailored
    to execute specific tasks within the face detection process.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: MTCNN（多任务级联卷积网络）是一个复杂且高度准确的人脸检测算法，超越了 Haar Cascades 的能力。MTCNN 设计用于在具有多样化面部尺寸、方向和光照条件的场景中表现优异，利用一系列神经网络，每个网络都专门执行人脸检测过程中的特定任务。
- en: '**Phase One — Proposal Generation**: MTCNN initiates the process by generating
    a multitude of potential face regions (bounding boxes) through a small neural
    network.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一阶段 — 提议生成**：MTCNN 通过一个小型神经网络开始生成大量潜在人脸区域（边界框）的过程。'
- en: '**Phase Two — Refinement**: Candidates generated in the first phase undergo
    filtering in this step. A second neural network evaluates the proposed bounding
    boxes, adjusting their positions for a more precise alignment with the true face
    boundaries. This aids in enhancing accuracy.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二阶段 — 精细化**：在第一阶段生成的候选区域在此步骤中进行筛选。第二个神经网络评估提议的边界框，并调整其位置，以更精确地对齐真实的人脸边界。这有助于提高准确性。'
- en: '**Phase Three — Facial Feature Points**: This stage identifies facial landmarks,
    such as eye corners, nose, and mouth. The neural network is employed to accurately
    pinpoint these features.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三阶段 — 面部特征点**：此阶段识别面部标志点，如眼角、鼻子和嘴巴。使用神经网络准确定位这些特征。'
- en: MTCNN’s cascaded architecture allows it to swiftly discard regions devoid of
    faces early in the process, concentrating computations on areas with a higher
    probability of containing faces. Its ability to handle different scales (zoom
    levels) of faces and rotations makes it highly suitable for intricate scenarios
    compared to Haar Cascades. However, its computational intensity stems from its
    neural network-based sequential approach.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: MTCNN 的级联架构使其能够在过程早期迅速剔除没有人脸的区域，将计算集中在更可能包含人脸的区域。它处理不同尺度（缩放级别）的人脸和旋转的能力使其相比
    Haar Cascades 更适用于复杂场景。然而，其计算强度源于其基于神经网络的顺序处理方法。
- en: For the implementation of MTCNN, I utilized the [mtcnn](https://pypi.org/project/mtcnn/)
    library.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施 MTCNN 时，我使用了 [mtcnn](https://pypi.org/project/mtcnn/) 库。
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: YOLOv5
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YOLOv5
- en: '![](../Images/4fd920a67df66fda40de057af89bd0bb.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4fd920a67df66fda40de057af89bd0bb.png)'
- en: Figure 3\. YOLO Object Detection Process ([source](https://arxiv.org/abs/1506.02640)
    — original paper)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. YOLO 物体检测过程 ([source](https://arxiv.org/abs/1506.02640) — 原始论文)
- en: 'YOLO (You Only Look Once) is an algorithm employed for detecting a multitude
    of objects, including faces. Unlike its predecessors, YOLO performs detection
    in a single pass through a neural network, rendering it faster and more suitable
    for real-time applications and videos. The process of detecting faces in media
    with YOLO can be distilled in four parts:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO（You Only Look Once）是一种用于检测多种物体的算法，包括人脸。与其前身不同，YOLO 在通过神经网络的单次传递中进行检测，使其速度更快，更适合实时应用和视频。使用
    YOLO 在媒体中检测人脸的过程可以分为四个部分：
- en: '**Image Grid Division**: The input image is divided into a grid of cells. Each
    cell is responsible for predicting objects located within its boundaries. For
    every cell, YOLO predicts bounding boxes, object probabilities, and class probabilities.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像网格划分**：输入图像被划分为一个网格单元。每个单元负责预测位于其边界内的物体。对于每个单元，YOLO 预测边界框、物体概率和类别概率。'
- en: '**Bounding Box Prediction**: Within each cell, YOLO predicts one or more bounding
    boxes along with their corresponding probabilities. These bounding boxes represent
    potential object locations. Each bounding box is defined by its center coordinates,
    width, height, and the probability that an object exists within that bounding
    box.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边界框预测**：在每个单元内，YOLO 预测一个或多个边界框及其对应的概率。这些边界框代表潜在的物体位置。每个边界框由其中心坐标、宽度、高度以及物体存在于该边界框内的概率定义。'
- en: '**Class Prediction**: For each bounding box, YOLO predicts the probabilities
    for various classes (e.g., ‘face,’ ‘car,’ ‘dog’) to which the object may belong.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类别预测**：对于每个边界框，YOLO 预测物体可能属于的各种类别的概率（例如，“人脸”，“汽车”，“狗”）。'
- en: '**Non-Maximum Suppression (NMS)**: To eliminate duplicate bounding boxes, YOLO
    applies NMS. This process discards redundant bounding boxes by evaluating their
    probabilities and overlap with other boxes, retaining only the most confident
    and non-overlapping ones.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非最大抑制（NMS）**：为了消除重复的边界框，YOLO 应用 NMS。这个过程通过评估边界框的概率和与其他框的重叠情况来丢弃冗余的边界框，只保留最有信心且没有重叠的框。'
- en: The key advantage of YOLO lies in its speed. Since it processes the entire image
    in a single forward pass through the neural network, it’s significantly faster
    than algorithms involving sliding windows or region proposals. However, this speed
    might come at a slight trade-off with precision, especially for smaller objects
    or crowded scenes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO的主要优势在于其速度。由于它通过神经网络进行一次前向传播来处理整个图像，因此比涉及滑动窗口或区域提议的算法快得多。然而，这种速度可能会在精度上有些妥协，尤其是在较小的物体或拥挤的场景中。
- en: YOLO can be adapted for face detection by training it on face-specific data
    and modifying its output classes to include only one class (‘face’). For this,
    I utilized the ‘[yoloface](https://github.com/elyha7/yoloface)’ library, built
    upon YOLOv5.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO 可以通过在面部特定数据上进行训练并将输出类别修改为仅包括一个类别（‘face’）来适应面部检测。为此，我利用了基于 YOLOv5 构建的‘[yoloface](https://github.com/elyha7/yoloface)’库。
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Face blurring
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面部模糊
- en: After identifying the bounding boxes around potential faces in the image, the
    next step is to blur them to remove their identities. For this task, I developed
    two implementations. A reference image for demonstration is provided in Figure
    4.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像中识别出潜在面部的边界框后，下一步是对它们进行模糊处理以去除其身份信息。为此任务，我开发了两种实现方法。图4提供了一个演示用的参考图像。
- en: '![](../Images/76d8d15e8b87064972fde45479f0b64d.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76d8d15e8b87064972fde45479f0b64d.png)'
- en: Figure 4\. Reference image By [Ethan Hoover](https://unsplash.com/photos/0YHIlxeCuhg)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图4\. 参考图像，来自[Ethan Hoover](https://unsplash.com/photos/0YHIlxeCuhg)的[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Gaussian Blur
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高斯模糊
- en: '![](../Images/bc158115ae16b6a1d0ba165e0d707cc8.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc158115ae16b6a1d0ba165e0d707cc8.png)'
- en: Figure 5\. Blurred reference image (Figure 4) with Gaussian Blur
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图5\. 应用高斯模糊的模糊参考图像（图4）
- en: Gaussian blur is an image processing technique used to reduce image noise and
    smudge details. This is particularly useful in the domain of face blurring as
    it erases specifics from that portion of the image. It computes an average of
    pixel values in the neighborhood around each pixel. This average is centered around
    the pixel being blurred and calculated using a Gaussian distribution, giving more
    weight to nearby pixels and less weight to distant ones. The result is a softened
    image with reduced high-frequency noise and fine details. The outcome of applying
    Gaussian Blur is depicted in Figure 5.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯模糊是一种图像处理技术，用于减少图像噪声和模糊细节。这在面部模糊领域尤为有用，因为它擦除了图像中那部分的具体信息。它通过计算每个像素周围邻域的像素值的平均值来完成这一操作。这个平均值以被模糊的像素为中心，并使用高斯分布计算，使得附近的像素权重更大，而远离的像素权重更小。结果是图像变得更柔和，高频噪声和细节减少。应用高斯模糊的结果如图5所示。
- en: 'Gaussian Blur takes three parameters:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯模糊有三个参数：
- en: Image portion to be blurred.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要进行模糊处理的图像部分。
- en: 'Kernel size: the matrix used for the blurring operation. A larger kernel size
    leads to stronger blurring.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内核大小：用于模糊操作的矩阵。较大的内核大小会导致更强的模糊效果。
- en: 'Standard deviation: A higher value enhances the blurring effect.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标准差：较高的值会增强模糊效果。
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Pixelization
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 像素化
- en: '![](../Images/1361eb7226b0368d220488b2dd515a54.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1361eb7226b0368d220488b2dd515a54.png)'
- en: Figure 6\. Blurred reference image (Figure 4) with Pixelization
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图6\. 应用像素化的模糊参考图像（图4）
- en: Pixelization is an image processing technique where the pixels in an image are
    replaced with larger blocks of a single color. This effect is achieved by dividing
    the image into a grid of cells, where each cell corresponds to a group of pixels.
    The color or intensity of all pixels in the cell is then taken as the average
    value of the colors of all pixels in that cell, and this average value is applied
    to all pixels in the cell. This process creates a simplified appearance, reducing
    the level of fine details in the image. The result of applying pixelization is
    shown in Figure 6\. As you can observe, pixelization significantly complicates
    the identification of a person’s identity.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 像素化是一种图像处理技术，其中图像中的像素被替换为较大的单一颜色块。这种效果通过将图像划分为网格单元来实现，每个单元对应一组像素。然后，将单元中所有像素的颜色或强度作为该单元中所有像素颜色的平均值，这个平均值应用于单元中的所有像素。这一过程创建了简化的外观，减少了图像中细节的层次。像素化的结果如图
    6 所示。正如你所观察到的，像素化显著地使得识别个人身份变得复杂。
- en: Pixelization takes one main parameter, which determines how many grouped pixels
    should represent a specific area. For instance, if we have a (10,10) section of
    the image containing a face, it will be replaced with a 10x10 group of pixels.
    A smaller number leads to greater blurring.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 像素化有一个主要参数，决定了多少组像素应该代表一个特定区域。例如，如果我们有一个包含面部的（10,10）图像区域，它将被替换为一个 10x10 的像素组。较小的数字会导致更大的模糊效果。
- en: '[PRE4]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Results and discussion
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果与讨论
- en: 'I will evaluate the different algorithms from two perspectives: Real-Time performance
    analysis and specific image scenarios.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从两个角度评估不同的算法：实时性能分析和特定图像场景。
- en: Real-Time performance
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时性能
- en: Using the same reference image (Figure 4), the time required for each face detection
    algorithm to locate the bounding box of the face in the image was measured. The
    results are based on the average value of 10 measurements for each algorithm.
    The time needed for the blurring algorithms is negligible and will not be considered
    in the evaluation process.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的参考图像（见图 4），测量每个面部检测算法定位图像中面部边界框所需的时间。结果基于每个算法的 10 次测量的平均值。模糊算法所需的时间微不足道，将不在评估过程中考虑。
- en: '![](../Images/241812e44e3f13fd89b590b23e1da35e.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/241812e44e3f13fd89b590b23e1da35e.png)'
- en: Figure 4\. Average time in seconds needed for each algorithm to detect face
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 每个算法检测面部所需的平均时间（秒）
- en: It can be observed that YOLOv5 achieves the best performance (speed) due to
    its single-pass processing through the neural network. In contrast, methods like
    MTCNN require sequential traversal through multiple neural networks. This further
    complicates the process of parallelizing the algorithm.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 可以观察到，由于 YOLOv5 通过神经网络的单次处理实现了最佳性能（速度）。相比之下，像 MTCNN 这样的方法需要通过多个神经网络的顺序遍历，这进一步使得算法并行化的过程变得复杂。
- en: Scenario-based performance
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景基础性能
- en: 'To evaluate the performance of the aforementioned algorithms, in addition to
    the reference image (Figure 4), I have selected several images that test the algorithms
    in various scenarios:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估上述算法的性能，除了参考图像（见图 4）外，我选择了几张在不同场景下测试算法的图像：
- en: Reference image (Figure 4)
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参考图像（见图 4）
- en: Group of people close together — to assess the algorithm’s ability to capture
    different face sizes, some closer and some further away (Figure 8)
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 紧密聚集的人群 —— 评估算法捕捉不同面部大小的能力，一些面部较近，一些较远（见图 8）
- en: Side-view faces — testing the algorithms’ capability to detect faces not looking
    directly at the camera (Figure 10)
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 侧视面部 —— 测试算法检测未直接面向摄像头的面部的能力（见图 10）
- en: Flipped face, 180 degrees — testing the algorithms’ ability to detect a face
    rotated by 180 degrees (Figure 11)
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 翻转面部，180 度 —— 测试算法检测旋转 180 度的面部的能力（见图 11）
- en: Flipped face, 90 degrees — testing the algorithms’ ability to detect a face
    rotated by 90 degrees, sideways (Figure 12)
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 翻转面部，90 度 —— 测试算法检测旋转 90 度的面部的能力（见图 12）
- en: '![](../Images/53e0e0aedf75d1a8c0d7039229f53530.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53e0e0aedf75d1a8c0d7039229f53530.png)'
- en: Figure 8\. Group of people by [Nicholas Green](https://unsplash.com/photos/nPz8akkUmDI)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8\. [Nicholas Green](https://unsplash.com/photos/nPz8akkUmDI) 的人群照片，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '![](../Images/881174753c52dee6f608b65d1cd22392.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/881174753c52dee6f608b65d1cd22392.png)'
- en: Figure 9\. Mutiple faces by [Naassom Azevedo](https://unsplash.com/photos/Q_Sei-TqSlc)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. 多个面部由 [Naassom Azevedo](https://unsplash.com/photos/Q_Sei-TqSlc) 提供，来源于
    [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '![](../Images/e1667ef7b5fe1cb9fd1efe1cac461d51.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e1667ef7b5fe1cb9fd1efe1cac461d51.png)'
- en: Figure 10\. Side-view faces by [Kraken Images](https://unsplash.com/photos/376KN_ISplE)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10\. 侧面视图面部由 [Kraken Images](https://unsplash.com/photos/376KN_ISplE) 提供，来源于
    [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '![](../Images/a8b0b3781ac4f72a23d6787cbf1c98d3.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a8b0b3781ac4f72a23d6787cbf1c98d3.png)'
- en: Figure 11\. Flipped face 180 degrees from Figure 4.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11\. 图 4 的面部翻转 180 度。
- en: '![](../Images/9f2e95cb2f68ad9a0479030d421e3c9f.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f2e95cb2f68ad9a0479030d421e3c9f.png)'
- en: Figure 12\. Flipped face 90 degrees from Figure 4.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12\. 图 4 的面部翻转 90 度。
- en: '**Haar Cascade**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**Haar Cascade**'
- en: The Haar Cascade algorithm generally performs well in anonymizing faces, with
    a few exceptions. It successfully detects the reference image (Figure 4) and the
    ‘Multiple faces’ scenario (Figure 9) excellently. In the ‘Group of people’ scenario
    (Figure 8), it handles the task decently, though there are faces that are not
    entirely detected or are farther away. Haar Cascade encounters challenges with
    faces not directly facing the camera (Figure 10) and rotated faces (Figures 11
    and 12), where it fails to recognize faces entirely.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Haar Cascade 算法通常在匿名化面部方面表现良好，尽管有一些例外。它成功地检测了参考图像（图 4）和‘多个面部’场景（图 9）。在‘人群’场景（图
    8）中，虽然处理得不错，但有些面部未完全检测到或较远。Haar Cascade 在面对不直接对着相机的面部（图 10）和旋转面部（图 11 和 12）时遇到挑战，未能完全识别面部。
- en: '![](../Images/ab8f6f2c241c691d4657e7206c1c169d.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab8f6f2c241c691d4657e7206c1c169d.png)'
- en: Figure 13\. Results with Haar Cascade
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13\. Haar Cascade 的结果
- en: '**MTCNN**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**MTCNN**'
- en: MTCNN manages to achieve very similar results to Haar Cascade, with the same
    strengths and weaknesses. Additionally, MTCNN struggles to detect the face in
    Figure 9 with a darker skin tone.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: MTCNN 实现的结果与 Haar Cascade 非常相似，具有相同的优缺点。此外，MTCNN 在检测图 9 中肤色较深的面部时存在困难。
- en: '![](../Images/8def97a683be399043e98530536d933c.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8def97a683be399043e98530536d933c.png)'
- en: Figure 14\. Results with MTCNN
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14\. MTCNN 的结果
- en: '**YOLOv5**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**YOLOv5**'
- en: YOLOv5 yields slightly different results from Haar Cascade and MTCNN. It successfully
    detects one of the faces where people are not looking directly at the camera (Figure
    10), as well as the face rotated by 180 degrees (Figure 11). However, in the ‘Group
    of people’ image (Figure 8), it doesn’t detect the faces farther away as effectively
    as the previously mentioned algorithms.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv5 与 Haar Cascade 和 MTCNN 的结果略有不同。它成功地检测到其中一个未直接对着相机的面部（图 10）以及旋转 180 度的面部（图
    11）。然而，在‘人群’图像（图 8）中，它未能像前述算法那样有效地检测到较远的面部。
- en: '![](../Images/28688ebc82f93acee48e312e71e44606.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28688ebc82f93acee48e312e71e44606.png)'
- en: Figure 15\. Results with YOLOv5
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15\. YOLOv5 的结果
- en: Privacy
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐私
- en: When addressing the challenge of privacy in image processing, a crucial aspect
    to consider is the delicate balance between rendering faces unrecognizable while
    maintaining the natural appearance of the images.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理图像隐私挑战时，重要的是要考虑如何在保持图像自然外观的同时使面部无法识别。
- en: '**Gaussian Blur**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯模糊**'
- en: Gaussian blur effectively blurs the facial region in an image (as depicted in
    Figure 5). Nevertheless, its success is dependent upon the parameters of the Gaussian
    distribution employed for the blurring effect. In Figure 5, it’s evident that
    facial features remain discernible, suggesting the necessity for higher standard
    deviation and kernel sizes to achieve optimal results.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯模糊有效地模糊了图像中的面部区域（如图 5 所示）。然而，它的成功依赖于用于模糊效果的高斯分布参数。在图 5 中，面部特征仍然可辨识，这表明需要更高的标准差和卷积核大小以获得最佳结果。
- en: '**Pixelization**'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**像素化**'
- en: Pixelization (as illustrated in Figure 6) often appears more visually pleasing
    to the human eye due to its familiarity as a face-blurring method compared to
    Gaussian blur. The number of pixels employed for pixelization plays a pivotal
    role in this context as a smaller pixel count renders the face less recognizable
    but may result in a less natural appearance.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 像素化（如图 6 所示）由于其作为面部模糊方法的熟悉感，通常在视觉上对人眼更为愉悦，与高斯模糊相比。像素化中使用的像素数量在此上下文中起着关键作用，因为较小的像素数量使面部不那么可识别，但可能导致外观不那么自然。
- en: Overall there has been a preference for pixelization over the Gaussian Blur
    algorithm. It lies in its familiarity and contextual naturalness, striking a balance
    between privacy and aesthetics.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来看，相较于高斯模糊算法，像素化方法更受青睐。这主要由于其熟悉性和上下文的自然性，在隐私和美学之间取得了平衡。
- en: '**Reverse Engineering**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**逆向工程**'
- en: With the rise of AI tools, it becomes imperative to anticipate the potential
    for reverse engineering techniques aimed at removing privacy filters from blurred
    images. Nevertheless, the very act of blurring a face irreversibly replaces specific
    facial details with more generalized ones. As of now, AI tools are only capable
    of reverse engineering a blurred face when presented with clear reference images
    of that same person. Paradoxically, this contradicts the need for reverse engineering
    in the first place, as it presupposes knowledge of the individual’s identity.
    Thus, face blurring stands as an efficient and necessary means of safeguarding
    privacy in the face of evolving AI capabilities.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AI工具的兴起，预测逆向工程技术可能会去除模糊图像中的隐私过滤器变得尤为重要。然而，模糊面部的行为不可逆地用更一般化的面部细节替代了特定的面部细节。目前，AI工具只能在提供清晰的参考图像时逆向工程模糊的面部。这与逆向工程的需求本身相矛盾，因为它假设了对个体身份的了解。因此，面部模糊作为保护隐私的一种有效且必要的手段，面对不断发展的AI能力仍然是必不可少的。
- en: Usage in videos
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在视频中的应用
- en: Since videos are essentially a sequence of images, it is relatively straightforward
    to modify each algorithm to perform anonymization for videos. However, here, processing
    time becomes crucial. For a given 30-second video recorded at 60 frames per second
    (images per second), the algorithms would need to process 1800 frames. In this
    context, algorithms like MTCNN would not be feasible, despite their improvements
    in certain scenarios. Hence, I decided to implement video anonymization using
    the YOLO model.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 由于视频本质上是图像的序列，因此修改每个算法以对视频进行匿名化相对简单。然而，在这里，处理时间变得至关重要。对于一个30秒的视频，录制帧率为60帧每秒（每秒图像），算法需要处理1800帧。在这种情况下，像MTCNN这样的算法将不可行，尽管它们在某些场景下有所改进。因此，我决定使用YOLO模型来实现视频匿名化。
- en: '[PRE5]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Web application
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络应用
- en: For a simplified evaluation of the different algorithms, I created a web application
    where users can upload any image or video, select the face detection and blurring
    algorithm, and after processing, the result is returned to the user. The implementation
    was done using Flask with Python on the backend, utilizing the mentioned libraries
    as well as OpenCV, and React.js on the frontend for user interaction with the
    models. The complete code is available at [this link](https://github.com/dani2221/dpns).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对不同算法进行简化评估，我创建了一个网络应用程序，用户可以上传任何图像或视频，选择人脸检测和模糊算法，处理后将结果返回给用户。该实现使用Flask与Python进行后端开发，利用上述库以及OpenCV，前端则使用React.js与模型进行用户交互。完整代码可在[这个链接](https://github.com/dani2221/dpns)找到。
- en: Conclusion
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Within the scope of this post, various face detection algorithms, including
    Haar Cascade, MTCNN, and YOLOv5, were explored, compared, and analyzed across
    different aspects. The project also focused on image-blurring techniques.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本帖的范围内，探索、比较和分析了包括Haar Cascade、MTCNN和YOLOv5在内的各种人脸检测算法。该项目还关注了图像模糊技术。
- en: Haar Cascade proved to be an efficient method in certain scenarios, exhibiting
    generally good temporal performance. MTCNN stood out as an algorithm with solid
    face detection capabilities in various conditions, although it struggled with
    faces that are not typically in a conventional orientation. YOLOv5, with its real-time
    face detection capabilities, emerged as an excellent choice for scenarios where
    time is a critical factor (such as videos), albeit with slightly reduced accuracy
    in group settings.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Haar Cascade在某些场景下证明是一种高效的方法，通常表现出良好的时间性能。MTCNN作为一种在各种条件下具有强大人脸检测能力的算法脱颖而出，尽管它在面对不典型的面部姿态时表现不佳。YOLOv5凭借其实时人脸检测能力，在时间是关键因素（例如视频）的场景中成为了一个出色的选择，尽管在群体设置中的准确性略有下降。
- en: All algorithms and techniques were integrated into a single web application.
    This application provides easy access and utilization of all face detection and
    blurring methods, along with the ability to process videos using blurring techniques.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 所有算法和技术都集成到一个单一的网络应用中。该应用程序提供了对所有人脸检测和模糊方法的简便访问和利用，并能够使用模糊技术处理视频。
- en: This post is a conclusion of my work for the “Digital Processing of Images”
    course at the Faculty of Computer Science and Engineering in Skopje. Thanks for
    reading!
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章是我在斯科普里的计算机科学与工程学院“数字图像处理”课程工作的总结。感谢阅读！
