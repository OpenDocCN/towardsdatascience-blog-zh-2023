- en: Understanding LLM Hallucinations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解LLM幻觉
- en: 原文：[https://towardsdatascience.com/llm-hallucinations-ec831dcd7786?source=collection_archive---------4-----------------------#2023-05-08](https://towardsdatascience.com/llm-hallucinations-ec831dcd7786?source=collection_archive---------4-----------------------#2023-05-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/llm-hallucinations-ec831dcd7786?source=collection_archive---------4-----------------------#2023-05-08](https://towardsdatascience.com/llm-hallucinations-ec831dcd7786?source=collection_archive---------4-----------------------#2023-05-08)
- en: Opinion
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 意见
- en: How LLMs can make stuff up and what to do about it
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM如何编造信息以及应对方法
- en: '[](https://franklyai.medium.com/?source=post_page-----ec831dcd7786--------------------------------)[![Frank
    Neugebauer](../Images/0da70d082d0f9c7ad8ccf574ed215df2.png)](https://franklyai.medium.com/?source=post_page-----ec831dcd7786--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ec831dcd7786--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ec831dcd7786--------------------------------)
    [Frank Neugebauer](https://franklyai.medium.com/?source=post_page-----ec831dcd7786--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://franklyai.medium.com/?source=post_page-----ec831dcd7786--------------------------------)[![Frank
    Neugebauer](../Images/0da70d082d0f9c7ad8ccf574ed215df2.png)](https://franklyai.medium.com/?source=post_page-----ec831dcd7786--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ec831dcd7786--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ec831dcd7786--------------------------------)
    [Frank Neugebauer](https://franklyai.medium.com/?source=post_page-----ec831dcd7786--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F29e3b5503cd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-hallucinations-ec831dcd7786&user=Frank+Neugebauer&userId=29e3b5503cd1&source=post_page-29e3b5503cd1----ec831dcd7786---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ec831dcd7786--------------------------------)
    ·6 min read·May 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fec831dcd7786&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-hallucinations-ec831dcd7786&user=Frank+Neugebauer&userId=29e3b5503cd1&source=-----ec831dcd7786---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F29e3b5503cd1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-hallucinations-ec831dcd7786&user=Frank+Neugebauer&userId=29e3b5503cd1&source=post_page-29e3b5503cd1----ec831dcd7786---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ec831dcd7786--------------------------------)
    · 6分钟阅读 · 2023年5月8日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fec831dcd7786&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-hallucinations-ec831dcd7786&user=Frank+Neugebauer&userId=29e3b5503cd1&source=-----ec831dcd7786---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fec831dcd7786&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-hallucinations-ec831dcd7786&source=-----ec831dcd7786---------------------bookmark_footer-----------)![](../Images/95f952aadd9b08c63fbd537fcf27100e.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fec831dcd7786&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fllm-hallucinations-ec831dcd7786&source=-----ec831dcd7786---------------------bookmark_footer-----------)![](../Images/95f952aadd9b08c63fbd537fcf27100e.png)'
- en: Photo by [Ahmad Dirini](https://unsplash.com/@ahmadirini?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Ahmad Dirini](https://unsplash.com/@ahmadirini?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Main Objectives
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要目标
- en: Working with large language models is not without risks including responses
    based on what’s called a LLM “hallucination.” Hallucinations can be a serious
    problem for LLMs because they can lead to the spread of misinformation, expose
    confidential information, and create unrealistic expectations about what LLMs
    can do. Understanding hallucinations and being critical of the information that
    they generate helps explain and mitigate problems such hallucinations can cause.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大型语言模型存在一定风险，包括基于所谓的LLM“幻觉”生成的回应。幻觉可能对LLM造成严重问题，因为它们可能导致虚假信息的传播、暴露机密信息，并且对LLM的能力产生不切实际的期望。理解幻觉并对其生成的信息持批判态度，有助于解释和缓解幻觉可能引发的问题。
- en: What’s a LLM Hallucination?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是LLM幻觉？
- en: LLMs are a type of artificial intelligence (AI) that are trained on massive
    datasets of text and code. They can generate text, translate languages, write
    different kinds of creative content, and answer questions in informative ways.
    However, LLMs are also prone to “hallucinating,” which means that they can generate
    text that is factually incorrect or nonsensical. As has been spoken about regularly,
    “LLMs can be confidently full of sh**.” Such hallucinations happen because LLMs
    are trained on data that is often incomplete or contradictory. As a result, they
    may learn to associate certain words or phrases with certain concepts, even if
    those associations are…
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大语言模型）是一种人工智能（AI），它们在大量的文本和代码数据集上进行训练。它们可以生成文本、翻译语言、编写各种创意内容，并以信息性的方式回答问题。然而，LLMs也容易出现“幻觉”，即生成的文本可能在事实性上不准确或毫无意义。正如经常提到的，“LLMs可能充满了胡言乱语。”这种幻觉发生的原因是LLMs在训练时使用的数据通常是不完整或自相矛盾的。因此，它们可能会学会将某些词汇或短语与某些概念关联起来，即使这些关联…
