- en: 'Dimension Reduction: Facing the Curse of Dimensionality'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维度缩减：面对维度诅咒
- en: 原文：[https://towardsdatascience.com/dimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199?source=collection_archive---------4-----------------------#2023-04-13](https://towardsdatascience.com/dimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199?source=collection_archive---------4-----------------------#2023-04-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/dimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199?source=collection_archive---------4-----------------------#2023-04-13](https://towardsdatascience.com/dimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199?source=collection_archive---------4-----------------------#2023-04-13)
- en: Comparison of PCA and dynamic factor model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PCA 与动态因子模型的比较
- en: '[](https://medium.com/@Vgraff?source=post_page-----63a743e4b199--------------------------------)[![Victor
    Graff](../Images/b6e06690f2b7952c62eaed4cc693ba5b.png)](https://medium.com/@Vgraff?source=post_page-----63a743e4b199--------------------------------)[](https://towardsdatascience.com/?source=post_page-----63a743e4b199--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----63a743e4b199--------------------------------)
    [Victor Graff](https://medium.com/@Vgraff?source=post_page-----63a743e4b199--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@Vgraff?source=post_page-----63a743e4b199--------------------------------)[![Victor
    Graff](../Images/b6e06690f2b7952c62eaed4cc693ba5b.png)](https://medium.com/@Vgraff?source=post_page-----63a743e4b199--------------------------------)[](https://towardsdatascience.com/?source=post_page-----63a743e4b199--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----63a743e4b199--------------------------------)
    [Victor Graff](https://medium.com/@Vgraff?source=post_page-----63a743e4b199--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6802a7b0402e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199&user=Victor+Graff&userId=6802a7b0402e&source=post_page-6802a7b0402e----63a743e4b199---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----63a743e4b199--------------------------------)
    ·10 min read·Apr 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F63a743e4b199&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199&user=Victor+Graff&userId=6802a7b0402e&source=-----63a743e4b199---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[跟进](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6802a7b0402e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199&user=Victor+Graff&userId=6802a7b0402e&source=post_page-6802a7b0402e----63a743e4b199---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----63a743e4b199--------------------------------)
    ·10 分钟阅读·2023 年 4 月 13 日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F63a743e4b199&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199&source=-----63a743e4b199---------------------bookmark_footer-----------)![](../Images/442e566f7cd383d1c6d57a443390e89e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F63a743e4b199&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdimension-reduction-facing-the-curse-of-dimensionality-63a743e4b199&source=-----63a743e4b199---------------------bookmark_footer-----------)![](../Images/442e566f7cd383d1c6d57a443390e89e.png)'
- en: Photo by [Kolleen Gladden](https://unsplash.com/@rockthechaos?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kolleen Gladden](https://unsplash.com/@rockthechaos?utm_source=medium&utm_medium=referral)
    的照片，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Many data scientists are forced to deal with the challenge of dimension. Data
    sets can contain huge amounts of variables, making them complex to understand
    and compute. For example an asset manager can be overwhelmed with the many dynamic
    variables associated with its portfolio, and processing a large amount of data
    can lead to computational issues. Reducing the dimension is a way to extract the
    information from a large number of variables into a smaller set of reduced variables,
    without loosing too much of the explainability. In other words, dimension reduction
    methods can be considered as the research of a sub-space which minimises the reconstitution
    error.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据科学家不得不面对维度的挑战。数据集可能包含大量变量，使得理解和计算变得复杂。例如，资产管理者可能会被与其投资组合相关的许多动态变量所困扰，处理大量数据可能导致计算问题。降维是一种将大量变量的信息提取到较小的降维变量集合中的方法，而不会丧失过多的解释性。换句话说，降维方法可以被认为是寻找一个最小化重构误差的子空间。
- en: 'Several methods exist to proceed with this information extraction, each adapted
    to different use cases. This article aims at providing a detailed comparison of
    two of these methods: the principal component analysis (PCA) and the dynamic factor
    model (DFM). The PCA can be used for any type of structured dataset, while the
    dynamic factor model is used for time series application, as it embeds the evolution
    of the series over time.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几种方法来进行信息提取，每种方法都适用于不同的用例。本文旨在提供这两种方法的详细比较：主成分分析（PCA）和动态因子模型（DFM）。PCA可以用于任何类型的结构化数据集，而动态因子模型则用于时间序列应用，因为它嵌入了时间序列的演变。
- en: The analysis is made on economic and financial data. The data used for this
    study is a replication of the data used for the article *measuring uncertainty
    and its impact on the economy* by Clark, Todd; Carriero, Andrea; Marcellino, Massimiliano
    and is available on the [Harvard dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2FENTXDD).
    It consists of 18 macro economical variables and 12 financial variables. It covers
    the evolution of these variables from 1960 to 2014\. The data is transformed to
    ensure stationarity, before being processed with the algorithms for dimension
    reduction.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分析基于经济和金融数据。用于本研究的数据是克拉克、托德；卡里耶罗、安德烈亚；马切利诺、马西米利亚诺的文章*测量不确定性及其对经济的影响*中使用数据的复制版，数据可在[Harvard
    dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2FENTXDD)上获取。数据包括18个宏观经济变量和12个金融变量，涵盖了这些变量从1960年到2014年的演变。在通过降维算法处理之前，数据被转换以确保平稳性。
- en: The entire code is available on [Github](https://github.com/graffv/Comparison_PCA_DFM/blob/main/PCA%20-%20DFM%20comparison.ipynb).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 整个代码可在[Github](https://github.com/graffv/Comparison_PCA_DFM/blob/main/PCA%20-%20DFM%20comparison.ipynb)上获取。
- en: Principal Component Analysis (PCA)
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）
- en: The theory
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论
- en: The PCA can be seen as an unsupervised method for dimension reduction. Let’s
    say we have a large number of variables. All of them seem of interest for the
    analysis, but there is no obvious way to aggregate these variables into categories.
    In this case, the algorithm will be in charge reducing the dimension without specific
    input from the modeler. In other words, the algorithm will create a smaller number
    of variables, called the reduced components, that shall be able to closely reproducing
    the initial variables.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: PCA可以看作是一种无监督的降维方法。假设我们有大量的变量。所有这些变量似乎都对分析有用，但没有明显的方法将这些变量汇总成类别。在这种情况下，算法将负责在没有模型师特定输入的情况下进行降维。换句话说，算法将创建更少的变量，称为降维成分，这些成分能够接近地重现初始变量。
- en: The method of the PCA lies on the covariance of the variables. If two variables
    are highly covariant, it means that they follow the same trend. The first one
    is then highly efficient in reproducing the second, making it possible to keep
    only the first variable without loosing the ability to recreate the second one
    if needed. The PCA creates a subset of variables that maximises the covariance
    with the initial variable set, in order to store as much information as possible
    in a lower dimension.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: PCA的方法基于变量的协方差。如果两个变量高度协方差，这意味着它们遵循相同的趋势。第一个变量在重现第二个变量方面非常高效，使得只保留第一个变量而不丧失在需要时重建第二个变量的能力成为可能。PCA创建一个变量子集，最大化与初始变量集的协方差，以便在较低维度中存储尽可能多的信息。
- en: 'The idea of the method is to compute an orthogonal basis of the space created
    by the original set of variables. The vectors creating this basis are the eigenvectors
    of the variance-covariance matrix. Reducing the dimension is then easily done
    by selecting the eigenvectors that are most representative of the initial data:
    those that contain most of the covariance. The amount of covariance stored by
    the vectors is quantified by the eigenvalues: the larger the eigenvalue, the more
    interesting its associated vectors.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的思路是计算由原始变量集创建的空间的正交基。创建这个基的向量是方差-协方差矩阵的特征向量。通过选择最能代表初始数据的特征向量，即包含最多协方差的特征向量，可以轻松地减少维度。特征值量化了向量存储的协方差量：特征值越大，其相关的向量就越有趣。
- en: 'The process of the PCA algorithm is as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 算法的过程如下：
- en: 1\. Computing the covariance matrix
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 计算协方差矩阵
- en: '![](../Images/999c7da8504b6b8386f7426b96621622.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/999c7da8504b6b8386f7426b96621622.png)'
- en: 2\. Computing its eigenvectors and eigenvalues
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 计算其特征向量和特征值
- en: 3\. Sorting the eigenvalues to keep vectors with most embedded information
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 对特征值进行排序，以保留包含最多信息的向量
- en: The ratio of each eigenvalue over the sum of all eigenvalues represents the
    amount of covariance contained in its associated eigenvector. The remaining task
    is to determine the number of eigenvectors to keep. Different parameters come
    into consideration for this selection, as we will see in the next section.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每个特征值与所有特征值之和的比率表示其相关特征向量中包含的协方差量。剩下的任务是确定保留的特征向量数量。我们将在下一节中看到为此选择的不同参数。
- en: Application to the data
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用到数据
- en: Python makes it straightforward to define the PCA model, as it is contained
    in the library [*sklearn*](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)
    ready for use. The attribute *n_components* can be at first set to a large value
    in order to compare the eigenvalues, and then to select the right number of components
    to keep. Once fitted, the eigenvalues are displayed in descending order, to help
    us make the decision. The plot below shows the ratio of covariance embedded by
    each eigenvalues.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Python 使得定义 PCA 模型变得简单，因为它包含在库 [*sklearn*](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)
    中。属性 *n_components* 可以初步设置为一个较大的值，以便比较特征值，然后选择保留的组件数量。一旦拟合，特征值将按降序显示，以帮助我们做出决策。下面的图显示了每个特征值所包含的协方差比率。
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/faa9b39c47a8468accb26fadd63d0b36.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/faa9b39c47a8468accb26fadd63d0b36.png)'
- en: The usual rule to select the right number of eigenvectors is to look at the
    “elbow” represented by the plot of the values. Taking the number of vectors up
    to the elbow gives an interesting trade-off between the information retained and
    the resulting dimension. In this case, we keep the first two components.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适特征向量数量的通常规则是查看图中表示的“肘部”。取到肘部的向量数量提供了信息保留和结果维度之间的有趣折衷。在这种情况下，我们保留前两个组件。
- en: The ratio of covariance of the first two components is 69.6% and 9.7%. Thus,
    by keeping only two components, we retain almost 80% of the information contained
    in the initial data, while reducing the dimension from 30 to 2!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个组件的协方差比率为 69.6% 和 9.7%。因此，通过仅保留两个组件，我们保留了初始数据中几乎 80% 的信息，同时将维度从 30 减少到 2！
- en: To sum up, the PCA is a great tool for dimension reduction. It is easy to deploy
    and it produces good results in terms of information retained, while seriously
    decreasing the dimension. Nonetheless, the PCA works as a black box that prevents
    any meaningful understanding of the resulting components. Also, the PCA works
    on any type of structured data but does not embed the dynamic of the data, if
    in the form of a time series.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，PCA 是一种很好的降维工具。它易于部署，并且在保留信息方面产生了良好的结果，同时显著减少了维度。然而，PCA 像一个黑箱，阻止了对结果组件的有意义理解。此外，PCA
    适用于任何类型的结构化数据，但如果数据以时间序列的形式存在，则不包含数据的动态性。
- en: The next section covers the dynamic factor models, which represent a potential
    solution to counter these limitations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将讨论动态因子模型，它们可能是应对这些局限性的潜在解决方案。
- en: Dynamic Factor Model (DFM)
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态因子模型（DFM）
- en: The theory
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论
- en: The dynamic factor model is used to observe the evolution of N variables over
    time (assembled in a vector Xt) with a reduced number of dynamic common factors.
    The strength of this method is that it embeds the co-movement of a large number
    of variables into a smaller number of components.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 动态因子模型用于观察 N 个变量随时间的演变（这些变量组合成一个向量 Xt），并使用较少数量的动态公共因子。这种方法的优势在于它将大量变量的共同运动嵌入到较少的成分中。
- en: This method is suited for time series application. As a result, they are widely
    used in finance and economics, where many essential variables co-evolve over time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法适用于时间序列应用。因此，它们在金融和经济学中被广泛使用，因为许多关键变量随时间共同演变。
- en: The DFM defines the vector Xt as a linear combination of past and current values
    of the reduced factors (ft). The factors are themselves dynamic, i.e. defined
    in an auto regressive way. The number of reduced components is q, and the lag
    of the auto regression is p.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: DFM 将向量 Xt 定义为减少因子（ft）过去和当前值的线性组合。这些因子本身是动态的，即以自回归方式定义。减少的成分数量为 q，自回归的滞后为 p。
- en: '![](../Images/aab6ab4b5de77c8067d70309ef48018f.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aab6ab4b5de77c8067d70309ef48018f.png)'
- en: Each λ is a (N x q) matrix with q the number of reduced components, each ft
    is a (q x 1) vector and each ψ is a (q x q) matrix. The “dynamic” is captured
    in the fact that each reduced vector ft follows a vector autoregressive process,
    thus is itself computed based on past values of f. Moreover, the vector X is impacted
    by present and past data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 λ 是一个 (N x q) 矩阵，其中 q 是减少的成分数量，每个 ft 是一个 (q x 1) 向量，每个 ψ 是一个 (q x q) 矩阵。动态性体现在每个减少的向量
    ft 遵循向量自回归过程，因此它本身是基于 f 的过去值计算的。此外，向量 X 受当前和过去数据的影响。
- en: A very important aspect of the DFM is that the number of components is defined
    ahead of the computation, based on qualitative knowledge of the data. This can
    be an interesting feature in case the variables are easily categorised, but it
    can also be a challenge if no meaningful category appears.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: DFM 的一个非常重要的方面是组件的数量是在计算前基于对数据的定性知识定义的。如果变量容易分类，这可以是一个有趣的特征，但如果没有出现有意义的类别，这也可能是一个挑战。
- en: Once the number of factors is defined, the main method to estimate the components
    is to use a Gaussian maximum likelihood estimator (MLE). ε and η are assumed to
    follow a gaussian distribution, and the MLE aims at maximizing the probability
    of achieving the sample data (Xt, ft), by tuning the gaussian parameters (the
    mean and standard deviation). Fortunately, this step is directly implemented in
    the Python libraries, making the computation easy.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦因子的数量被定义，估计成分的主要方法是使用高斯最大似然估计器（MLE）。ε 和 η 被假设为遵循高斯分布，MLE 的目标是通过调整高斯参数（均值和标准差）来最大化获得样本数据（Xt,
    ft）的概率。幸运的是，这一步骤在 Python 库中直接实现，使得计算变得容易。
- en: Once estimated, the components thus computed represent the category they were
    assigned to. This results in as many components as the categories we have defined.
    This allows us to reduce the dimension in an efficient and qualitatively meaningful
    way.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦估计完成，这些计算出的成分将代表它们被分配的类别。这就意味着我们得到的成分数量与我们定义的类别数量相同。这使我们能够以高效且有意义的方式减少维度。
- en: Application to the data
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据应用
- en: 'The DFM will be applied to the same dataset as previously presented. Good news
    here: we directly have two obvious categories: macro economics and finance.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: DFM 将应用于与之前展示的相同数据集。这里有个好消息：我们直接有两个明显的类别：宏观经济学和金融。
- en: 'Python contains a DFM model in its *statsmodels* library: [DynamicFactorMQ](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.dynamic_factor_mq.DynamicFactorMQ.html).
    To compute the model, a few parameters are needed. First, and obviously, the initial
    data that we aim to reduce. Second, a dictionary that associates each variable
    with its category (technically, each variable can be in more than one category,
    but we won’t cover this case here).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的 *statsmodels* 库中包含了一个 DFM 模型：[DynamicFactorMQ](https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.dynamic_factor_mq.DynamicFactorMQ.html)。为了计算模型，需要几个参数。首先，显然是我们旨在减少的初始数据。其次，一个将每个变量与其类别关联起来的字典（从技术上讲，每个变量可以属于多个类别，但我们在这里不讨论这种情况）。
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then, we define the order of the lag of the VAR model associated to each factor
    ft, i.e. how many time steps backward influence the current state of the factor.
    In our case, a lag of one seems sufficient. Increasing the lag obviously increases
    the computational constraint, but can have significant impact in the efficiency
    of the model by providing longer time information at each step.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义与每个因子ft相关的VAR模型的滞后阶数，即多少个时间步骤向后影响因子的当前状态。在我们的案例中，一个滞后似乎足够。增加滞后显然会增加计算约束，但通过在每一步提供更长时间的信息，可以显著影响模型的效率。
- en: 'Finally, the idiosyncratic component needs to be defined. This component represents
    the part of the vector Xt that cannot be explained by current and past values
    of ft. This component can be seen as the residuals in a linear regression. It
    can be either fitted as an AR(1) model, or as white noise. On an economic point
    of view, this choice is significant: do we estimate that the residuals of the
    models are autoregressive (i.e. present and past values are correlated) or independent
    and identically distributed? For economics studies, an uncorrelated idiosyncratic
    term is often unrealistic because the measurement method would usually induce
    correlated errors.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，需要定义特定成分。这个成分表示向量Xt中不能通过ft的当前值和过去值解释的部分。这个成分可以看作是线性回归中的残差。它可以拟合为AR(1)模型或白噪声。从经济学角度来看，这一选择是重要的：我们估计模型的残差是自回归的（即现值和过去值相关）还是独立同分布的？对于经济学研究来说，一个不相关的特定成分通常是不现实的，因为测量方法通常会引入相关误差。
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Comparison of the methods
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法比较
- en: 'The next question that clearly arises is: which method should be used? Well,
    as expected, it depends on what we are looking for.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的问题显然是：应该使用哪种方法？如预期的那样，这取决于我们要寻找的内容。
- en: Let’s summarise the pros and cons of each model.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下每个模型的优缺点。
- en: '**PCA**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**主成分分析（PCA）**'
- en: Can be applied on any type of structure data
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以应用于任何类型的结构化数据
- en: No *ex ante* knowledge on the data required for computation
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算时无需对数据有*先验*知识
- en: Rule of thumb to select the reduced components
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择降维成分的经验法则
- en: Unsupervised process
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督过程
- en: '**DFM**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**动态因子模型（DFM）**'
- en: Application on time series data
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用于时间序列数据
- en: Qualitative knowledge of the data to determine the categories embedded in the
    reduced factors
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据的定性知识，以确定嵌入在降维因子中的类别
- en: Pre-determined number of reduced components
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预先确定的降维成分数量
- en: At first sight, PCA seems to gather more interest than the DFM, but there’s
    more to see to make the decision. The main difference between these two is the
    possibility of the DFM to provide a meaningful explanation of its results.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，PCA似乎比DFM更受关注，但要做出决定还需要进一步观察。这两者之间的主要区别在于DFM能够提供其结果的有意义解释。
- en: Readability
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可读性
- en: First, let’s have a look at the created components.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们来看一下创建的组件。
- en: '![](../Images/9f586cfdcfed2e62a8cd6be6f22da72a.png)![](../Images/812e1de4d22dbea8b75bc9cbbb29cefa.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f586cfdcfed2e62a8cd6be6f22da72a.png)![](../Images/812e1de4d22dbea8b75bc9cbbb29cefa.png)'
- en: 'These two plots show the evolution of the two selected factors for each model.
    Interestingly enough, both models seem to separate a variable of trend (blue)
    and another one of volatility (orange). DFM gives us the advantage of the meaning
    behind this observation: it is of no surprise to see macro variables (e.g. GDP,
    housing price, etc.) increase over time. Also, financial variables are known to
    be much more volatile. The PCA seems to capture the same kind of information,
    but again, we are unable to make anything more than assumptions to explain this
    phenomenon. Advantage to DFM on this point.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个图显示了每个模型中两个选择因子的演变。有趣的是，这两个模型似乎都将一个变量分离为趋势（蓝色）和另一个变量分离为波动性（橙色）。DFM给我们提供了这一观察结果背后的含义：看到宏观变量（例如
    GDP、房价等）随着时间的推移而增加并不奇怪。此外，金融变量被认为波动性更大。PCA似乎捕捉到了相同类型的信息，但我们仍然只能对这种现象做出假设。DFM在这一点上有优势。
- en: Accuracy
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确性
- en: 'Let’s get back to the purpose of the dimension reduction methods: being a good
    substitute for the original data in lower dimension. Therefore, we need to make
    sure that the models can accurately reproduce the original data.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到降维方法的目的：作为较低维度下原始数据的良好替代。因此，我们需要确保模型能够准确地重现原始数据。
- en: Python provides, for both algorithms, an accessible way to reproduce the initial
    variables. For the PCA, after transforming the data into its reduced space, the
    *inverse_transform* method provides the representation of each initial variable
    processed by the model. The DFM model contains all representations into its *fittedvalues*
    attribute.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Python 为这两种算法提供了一种便捷的方法来重现初始变量。对于 PCA，将数据转换为其降维空间后，*inverse_transform* 方法提供了由模型处理的每个初始变量的表示。DFM
    模型将所有表示包含在其 *fittedvalues* 属性中。
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can then easily plot this representation of the data from each model. In
    the below plot, we show an example for the unemployment rate variable.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松绘制每个模型的数据表示。下面的图中，我们展示了失业率变量的一个例子。
- en: '![](../Images/3d254727c726e70616b95852e26338a2.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d254727c726e70616b95852e26338a2.png)'
- en: On this example, the DFM is obviously a better fit as it is constantly closer
    to the original data, containing much less variations. To make a more global and
    quantitative assessment, let’s compute the residuals of both models, on the entire
    dataset.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，DFM 显然更适合，因为它始终更接近原始数据，变化更少。为了进行更全面和定量的评估，让我们计算两个模型在整个数据集上的残差。
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/e605055725e2c7b23028c7291676a03b.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e605055725e2c7b23028c7291676a03b.png)'
- en: Sum of residuals
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 残差和
- en: The DFM is clearly more performant than the PCA on reproducing the initial data.
    The categorisation and dynamic embedded in the model seems to have accurately
    captured the information of the initial variable set.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在重现初始数据方面，DFM 明显比 PCA 更具性能。模型中的分类和动态似乎准确捕捉了初始变量集的信息。
- en: Conclusion
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'We have compared two methods for dimension reduction, both presenting advantages
    and drawbacks. We saw that, in the presented case the DFM model is a better fit,
    but PCA is also of great interest. Let’s summarise:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了两种降维方法，各有优缺点。我们看到，在所呈现的情况下，DFM 模型更适合，但 PCA 也非常有价值。让我们总结一下：
- en: When to prefer PCA?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 何时偏好 PCA？
- en: There’s no time dynamic in the data
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中没有时间动态。
- en: There’s no obvious categorisation of the initial data
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始数据没有明显的分类。
- en: There’s little qualitative knowledge of the initial data
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对初始数据的定性知识很少。
- en: When to prefer DFM?
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 何时偏好 DFM？
- en: Time dynamic is an important feature of the data
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间动态是数据的一个重要特征。
- en: Understanding of the reduced components is required for analysis
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析需要对降维组件的理解。
- en: Categorisation of the data is easily found
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的分类很容易找到。
- en: To sum up, no algorithm surpasses the other one in all contexts. It is the role
    of the modeller to assess what’s best in every situation. Moreover, as we have
    seen, both models are easy to implement on Python. Implementing both helps increasing
    the understanding of the data and leads to better solutions.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，没有哪种算法在所有情况下都优于另一种。建模者的角色是评估每种情况中什么是最好的。此外，正如我们所见，两种模型都易于在 Python 上实现。实现这两者有助于增加对数据的理解，并带来更好的解决方案。
- en: I hope this article was of interest and helped you understand the differences
    between these two models. Please feel free to give me any feedback or thoughts
    on this!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这篇文章对你有所帮助，并能帮助你理解这两种模型之间的差异。请随时给我任何反馈或想法！
- en: References
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Clark, Todd; Carriero, Andrea; Marcellino, Massimiliano, 2017, “Replication
    Data for: “Measuring Uncertainty and Its Impact on the Economy””, [https://doi.org/10.7910/DVN/ENTXDD](https://doi.org/10.7910/DVN/ENTXDD),
    Harvard Dataverse, V3'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 'Clark, Todd; Carriero, Andrea; Marcellino, Massimiliano, 2017, “Replication
    Data for: “Measuring Uncertainty and Its Impact on the Economy””, [https://doi.org/10.7910/DVN/ENTXDD](https://doi.org/10.7910/DVN/ENTXDD),
    Harvard Dataverse, V3'
