- en: Synergy of LLM and GUI, Beyond the Chatbot
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 和 GUI 的协同作用，超越聊天机器人
- en: 原文：[https://towardsdatascience.com/synergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801?source=collection_archive---------3-----------------------#2023-10-20](https://towardsdatascience.com/synergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801?source=collection_archive---------3-----------------------#2023-10-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/synergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801?source=collection_archive---------3-----------------------#2023-10-20](https://towardsdatascience.com/synergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801?source=collection_archive---------3-----------------------#2023-10-20)
- en: Use OpenAI GPT function calling to drive your mobile app
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 OpenAI GPT 功能调用来驱动你的移动应用
- en: '[](https://medium.com/@hgwvandam?source=post_page-----c8b0e08c6801--------------------------------)[![Hans
    van Dam](../Images/52846b7417b271767597c468edfaec46.png)](https://medium.com/@hgwvandam?source=post_page-----c8b0e08c6801--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c8b0e08c6801--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c8b0e08c6801--------------------------------)
    [Hans van Dam](https://medium.com/@hgwvandam?source=post_page-----c8b0e08c6801--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@hgwvandam?source=post_page-----c8b0e08c6801--------------------------------)[![汉斯·范·达姆](../Images/52846b7417b271767597c468edfaec46.png)](https://medium.com/@hgwvandam?source=post_page-----c8b0e08c6801--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c8b0e08c6801--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c8b0e08c6801--------------------------------)
    [汉斯·范·达姆](https://medium.com/@hgwvandam?source=post_page-----c8b0e08c6801--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6ce6c6116a37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsynergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801&user=Hans+van+Dam&userId=6ce6c6116a37&source=post_page-6ce6c6116a37----c8b0e08c6801---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c8b0e08c6801--------------------------------)
    ·10 min read·Oct 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc8b0e08c6801&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsynergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801&user=Hans+van+Dam&userId=6ce6c6116a37&source=-----c8b0e08c6801---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6ce6c6116a37&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsynergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801&user=Hans+van+Dam&userId=6ce6c6116a37&source=post_page-6ce6c6116a37----c8b0e08c6801---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c8b0e08c6801--------------------------------)
    ·10分钟阅读·2023年10月20日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc8b0e08c6801&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsynergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801&user=Hans+van+Dam&userId=6ce6c6116a37&source=-----c8b0e08c6801---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8b0e08c6801&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsynergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801&source=-----c8b0e08c6801---------------------bookmark_footer-----------)![](../Images/b2eeddb143ab661dbdb4d222a2359114.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc8b0e08c6801&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsynergy-of-llm-and-gui-beyond-the-chatbot-c8b0e08c6801&source=-----c8b0e08c6801---------------------bookmark_footer-----------)![](../Images/b2eeddb143ab661dbdb4d222a2359114.png)'
- en: Image created using Midjourney
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 Midjourney 创建
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: We introduce a radical UX approach to optimally blend Conversational AI and
    Graphical User Interface (GUI) interaction in the form of a Natural Language Bar.
    It sits at the bottom of every screen, allowing users to interact with your entire
    app from a single entry point. Users always have the choice between language and
    direct manipulation. They do not have to search where and how to accomplish tasks
    and can express their intentions in their own language, while the GUI's speed,
    compactness, and affordance are fully preserved. Definitions of the screens of
    a GUI are sent along with the user’s request to the Large Language Model (LLM),
    letting the LLM navigate the GUI toward the user’s intention. We built upon a
    concept introduced in a [previous article](https://medium.com/towards-data-science/speech-and-natural-language-input-for-your-mobile-app-using-llms-e79e23d3c5fd).
    We further optimized the concept and implemented a Flutter sample app available
    [here for you to try](https://langbar-1d3b9.web.app/home). The full Flutter code
    is [available on GitHub](https://github.com/hansvdam/langbar), so you can explore
    the concept in your own context. A short video explaining the functionality is
    available [here](https://youtu.be/vJy0HI_mH7w). This article is intended for product
    owners, UX designers, and mobile developers.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了一种激进的用户体验（UX）方法，以最佳方式将对话式人工智能（Conversational AI）与图形用户界面（GUI）交互融合，形式为自然语言条。它位于每个屏幕的底部，允许用户通过一个入口点与整个应用程序进行交互。用户始终可以选择语言或直接操作。他们无需搜索如何完成任务，可以用自己的语言表达意图，同时保持GUI的速度、紧凑性和可操作性。GUI的屏幕定义与用户的请求一起发送到大型语言模型（LLM），让LLM引导GUI朝向用户的意图。我们在[上一篇文章](https://medium.com/towards-data-science/speech-and-natural-language-input-for-your-mobile-app-using-llms-e79e23d3c5fd)中介绍了这一概念，并在此基础上进行了优化，实施了一个Flutter示例应用程序，[点击这里试用](https://langbar-1d3b9.web.app/home)。完整的Flutter代码[可以在GitHub上找到](https://github.com/hansvdam/langbar)，因此你可以在自己的上下文中探索这一概念。一个简短的视频解释了该功能，[点击这里观看](https://youtu.be/vJy0HI_mH7w)。本文面向产品负责人、UX设计师和移动开发人员。
- en: '![](../Images/0a3b8a05a683c5d85b0b430b54a6e8f3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a3b8a05a683c5d85b0b430b54a6e8f3.png)'
- en: Background
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: 'Natural language interfaces and Graphical User Interfaces (GUIs) connect the
    human user to the abilities of the computer system. Natural language allows humans
    to communicate with each other about things outside of immediacy while pointing
    allows communication about concrete items in the world. Pointing requires less
    cognitive effort for one''s communicative counterpart than producing and processing
    natural language. It also leaves less room for confusion. Natural language, however,
    can convey information about the entire world: concrete, abstract, past, present,
    future, and the meta-world, offering random access to everything.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言接口和图形用户界面（GUIs）将人类用户与计算机系统的能力连接起来。自然语言允许人们在即时性之外交流，而指点允许对世界上具体事物进行沟通。指点相对于产生和处理自然语言来说，要求对方的认知努力更少，也减少了混淆的可能。然而，自然语言可以传达关于整个世界的信息：具体的、抽象的、过去的、现在的、未来的，以及元世界，提供对一切的随机访问。
- en: With the rise of ChatGPT the interpreting quality of NLP has reached a high
    level, and using ‘function calling’ it is now feasible to make complete natural
    language interfaces to computer systems that make little misinterpretations. The
    current trend in the LLM community focuses on chat interfaces as the main conversational
    user interface. This approach stems from chat being the primary form of written
    human-to-human interaction, preserving conversational history in a scrolling window.
    Many sorts of information are suitable for graphical representation. A common
    approach is to weave GUI elements into the chat conversation. The cost of this,
    however, is that the chat history becomes bulky, and the state management of GUI
    elements in a chat history is non-trivial. Also, by fully adopting the chat paradigm,
    we lose the option of offering menu-driven interaction paths to the users, so
    they are left more in the dark with respect to the abilities of the app.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ChatGPT的兴起，自然语言处理（NLP）的解读质量已达到了高水平，利用‘功能调用’，现在可以创建完整的自然语言接口，减少误解的发生。当前LLM社区的趋势集中在聊天界面作为主要的对话用户界面。这种方法源于聊天是书面的人际交互的主要形式，并在滚动窗口中保留对话历史。许多信息适合图形表示。一种常见的方法是将GUI元素融入聊天对话中。然而，这样的成本是聊天历史变得庞大，并且在聊天历史中管理GUI元素的状态是复杂的。此外，通过完全采用聊天范式，我们失去了向用户提供菜单驱动交互路径的选项，使他们在应用程序的功能方面更加模糊。
- en: 'The approach taken here can be applied to a whole range of apps, such as banking-,
    shopping- and travel apps. Mobile apps have their most important feature on the
    front screen, but features on other tabs or screens buried in menus may be challenging
    for users to find. When users can express their requests in their own language,
    they can naturally be taken to the screen that is most likely to satisfy their
    needs. When the most important feature is on the front screen, the number of options
    available for this core feature may be overwhelming to all present in the form
    of GUI elements. Natural language approaches this from the other end: the users
    have the initiative and express precisely what they want. Combining the two leads
    to an optimum, where both approaches complement each other, and users can pick
    the best option to suit their task or subtask.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这里采用的方法可以应用于各种应用程序，例如银行、购物和旅行应用。移动应用的最重要功能位于主屏幕上，但其他选项卡或菜单中的功能可能让用户很难找到。当用户可以用自己的语言表达请求时，他们自然会被引导到最有可能满足需求的屏幕上。当最重要的功能在主屏幕上时，针对这一核心功能的可选项数量可能会使人不知所措。自然语言从另一端接近这一点：用户主动表达他们想要的内容。将这两者结合起来，可以实现最佳状态，即两者互补，用户可以选择最适合其任务或子任务的选项。
- en: The Natural Language Bar
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言条
- en: The Natural Language Bar (NLB) allows users to type or say what they want from
    the app. Along with their request, the definitions of all screens of the app are
    sent to the LLM using a technique coined ‘function calling’ by OpenAI. In our
    concept, we see a GUI screen as a function that can be called in our app, where
    the widgets for user input on the screen are regarded as parameters of that function.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言条（NLB）允许用户输入或说出他们想要从应用程序中得到什么。与他们的请求一起，所有屏幕的定义都通过 OpenAI 创造的“函数调用”技术发送到
    LLM。在我们的概念中，我们将 GUI 屏幕视为应用程序中的一个函数，其中屏幕上的用户输入小部件被视为该函数的参数。
- en: 'We will take a banking app as an example to illustrate the concept. When the
    user issues a request in natural language, the LLM responds by telling the navigation
    component in our app which screen to open and which values to set. This is illustrated
    in the following figure:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以银行应用程序为例来说明这一概念。当用户用自然语言发出请求时，LLM 会告诉我们应用中的导航组件打开哪个屏幕以及设置哪些值。这在以下图中进行了说明：
- en: '![](../Images/f3ff34ebf888a5fa1fda9756b41dc8f9.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f3ff34ebf888a5fa1fda9756b41dc8f9.png)'
- en: 'Some interaction examples are given in the following images:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像提供了一些交互示例：
- en: '![](../Images/4119fda107a1bd1053a0ef8aa5a89368.png)![](../Images/e1aef9c7e25d7333951c96323448d083.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4119fda107a1bd1053a0ef8aa5a89368.png)![](../Images/e1aef9c7e25d7333951c96323448d083.png)'
- en: 'The following image shows a derived conclusion by the LLM. It concludes that
    the best available way to help the user is by showing the banking offices near
    you:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了 LLM 得出的结论。它得出的最佳方式是展示您附近的银行网点：
- en: '![](../Images/bf14eecf3794e7ae8d2652fefb275bf1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf14eecf3794e7ae8d2652fefb275bf1.png)'
- en: 'The following example shows that even significantly shortened expressions may
    lead to the desired result for the user:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了即使显著缩短的表达也可能达到用户期望的结果：
- en: '![](../Images/cbb1cde97e82f5609659676c47ae3b61.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cbb1cde97e82f5609659676c47ae3b61.png)'
- en: So free typing can also be a very fast interaction mode. The correct interpretation
    of such shorthands depends on the non-ambiguity of the intention behind it. In
    this case, the app has no other screen than transfers that this could be meant
    for so the LLM could make a non-ambiguous decision.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，自由输入也可以是一种非常快速的交互模式。这种缩略语的正确解释取决于其背后意图的明确性。在这种情况下，应用程序没有其他屏幕可以转移，因此 LLM 可以做出明确的决定。
- en: 'Another bonus feature is that the interaction has a history, so users can continue
    to type to correct the previous intent:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个额外功能是交互有历史记录，因此用户可以继续输入以纠正之前的意图：
- en: '![](../Images/d4ac0c69257c231b582c59a763a6b4ba.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4ac0c69257c231b582c59a763a6b4ba.png)'
- en: So the LLM can combine several messages, one correcting or enhancing the other,
    to produce the desired function call. This can be very convenient for a trip-planning
    app where users initially just mention the origin and destination and, in subsequent
    messages, refine it with extra requirements, like the date, the time, only direct
    connections, only first-class, etc.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，LLM 可以结合几条消息，其中一条纠正或增强另一条，以产生所需的函数调用。这对于旅行规划应用程序非常方便，用户最初只提到出发地和目的地，然后在后续消息中添加额外的要求，如日期、时间、仅直达连接、仅头等舱等。
- en: '[Click here](https://langbar-1d3b9.web.app/home) to try the sample app for
    yourself. Speech input does work in a Chrome browser and on Android and iOS native.
    The provided speech recognition of the platform is used, so there’s room for improvement
    if the quality is insufficient for your purpose.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[点击这里](https://langbar-1d3b9.web.app/home)亲自尝试示例应用程序。语音输入在Chrome浏览器以及Android和iOS本地环境中有效。使用的是平台提供的语音识别，因此如果质量不足以满足您的目的，还有改进的空间。'
- en: How it works
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理
- en: When the user asks a question in the Natural Language Bar, a [JSON schema](https://www.tutorialspoint.com/json/json_schema.htm)
    is added to the prompt to the LLM. The JSON schema defines the structure and purposes
    of all screens and their input elements. The LLM attempts to map the user’s natural
    language expression onto one of these screen definitions. It returns a JSON object
    so your code can make a ‘function call’ to activate the applicable screen.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在自然语言栏中提出问题时，会向LLM的提示中添加一个[JSON模式](https://www.tutorialspoint.com/json/json_schema.htm)。JSON模式定义了所有屏幕及其输入元素的结构和目的。LLM尝试将用户的自然语言表达映射到这些屏幕定义中的一个。它返回一个JSON对象，以便您的代码可以进行‘函数调用’以激活相应的屏幕。
- en: 'The correspondence between functions and screens is illustrated in the following
    figure:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 功能和屏幕之间的对应关系在下图中进行了说明：
- en: '![](../Images/662292075e3dc3cc890e19bdce69cba4.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/662292075e3dc3cc890e19bdce69cba4.png)'
- en: A full function specification is available for your inspection [here](https://gist.github.com/hansvdam/3783bfc35e19e96849187e634272b366).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的功能规范可以在[这里](https://gist.github.com/hansvdam/3783bfc35e19e96849187e634272b366)查看。
- en: 'The Flutter implementation of the Natural Language Bar is based on [LangChain
    Dart](https://langchaindart.com), the Dart version of the LangChain ecosystem.
    All prompt engineering happens on the client side. It makes more sense to keep
    screens, navigation logic, and function templates together. The function templates
    are knit into the navigation structure since there is a one-to-one relationship.
    The following shows the code for activating and navigating to the credit card
    screen:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言栏的Flutter实现基于[LangChain Dart](https://langchaindart.com)，这是LangChain生态系统的Dart版本。所有提示工程都发生在客户端。将屏幕、导航逻辑和功能模板保存在一起更有意义。由于一对一关系，功能模板被整合到导航结构中。以下展示了激活并导航到信用卡屏幕的代码：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'At the top, we see that this is a route: a destination in the routing system
    of the app that can be activated through a hyperlink. The description is the portion
    the LLM will use to match the screen to the user’s intent. The parameters below
    it (credit card limit and action to take) define the fields of the screen in natural
    language so the LLM can extract them from the user’s question. Then, the pageBuilder-item
    determines how the screen should be activated using the query parameters of the
    deep link. One can recognize these in [https://langbar-1d3b9.web.app/home](https://langbar-1d3b9.web.app/home):
    type: ‘credit card limit to 10000’ in the NLB, and the address bar of the browser
    will read: [https://langbar-1d3b9.web.app/creditcard?limit=10000](https://langbar-1d3b9.web.app/creditcard?limit=10000).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部，我们看到这是一个路由：应用程序路由系统中的一个目标，可以通过超链接激活。描述部分是LLM用来将屏幕与用户意图匹配的部分。下面的参数（信用卡额度和要采取的操作）定义了自然语言中的屏幕字段，以便LLM可以从用户的问题中提取这些字段。然后，pageBuilder-item决定如何使用深层链接的查询参数来激活屏幕。可以在[https://langbar-1d3b9.web.app/home](https://langbar-1d3b9.web.app/home)中识别这些参数：在NLB中输入‘信用卡额度为10000’，浏览器的地址栏将显示：[https://langbar-1d3b9.web.app/creditcard?limit=10000](https://langbar-1d3b9.web.app/creditcard?limit=10000)。
- en: A LangChain agent was used, which makes this approach independent of GPT, so
    it can also be applied using other LLMs like Llama, Gemini, Falcon, etc. Moreover,
    it makes it easy to add LLM-based assistance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用了LangChain代理，这使得这种方法独立于GPT，因此也可以使用其他LLM如Llama、Gemini、Falcon等。此方法还便于添加基于LLM的辅助功能。
- en: History Panel
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 历史面板
- en: 'The Natural Language Bar offers a collapsible interaction history panel so
    the user can easily repeat previous statements. This way, the interaction history
    is preserved, similarly to chat interfaces, but in a compacted, collapsible form,
    saving screen real estate and preventing clutter. Previous language statements
    by the user are shown using the language the user has used. System responses are
    incorporated as a hyperlink on that user statement so they can be clicked on to
    reactivate the corresponding screen again:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言栏提供了一个可折叠的互动历史面板，用户可以轻松重复以前的陈述。这样，互动历史会被保存，类似于聊天界面，但以紧凑、可折叠的形式出现，节省屏幕空间并防止混乱。用户之前的语言陈述会以用户使用的语言显示。系统响应会作为超链接包含在用户陈述中，可以点击以重新激活对应的屏幕：
- en: '![](../Images/ceb4b22e68363745dc5939e4642a3faa.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ceb4b22e68363745dc5939e4642a3faa.png)'
- en: 'When the LLM cannot fully determine the screen to activate, system responses
    are shown explicitly, in which case the history panel expands automatically. This
    can happen when the user has provided too little information, when the user’s
    request is outside of the scope of the app, or when an error occurs:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM无法完全确定要激活的屏幕时，系统响应会被明确显示，此时历史面板会自动展开。这种情况可能发生在用户提供的信息过少、用户的请求超出应用程序的范围，或发生错误时：
- en: '![](../Images/2fdf9cc916a64a8f85fa770ca3d22c06.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2fdf9cc916a64a8f85fa770ca3d22c06.png)'
- en: Future
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来
- en: The history panel is an excellent place to offer customer support and context-sensitive
    help in chatbot form. At the time of writing, there is a lively discussion and
    evolution of RAG (Retrieval Augmented Generation) techniques that let chatbots
    answer user questions based on a large body of text content provided by your organization.
    Besides that, the Natural Language Bar is a good starting point to imagine what
    more power and ease one can give to applications using natural language.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 历史面板是提供客户支持和上下文敏感帮助的绝佳场所，采用聊天机器人形式。写作时，有关RAG（检索增强生成）技术的讨论和演变非常活跃，这些技术使聊天机器人能够根据贵组织提供的大量文本内容回答用户的问题。此外，自然语言栏是想象如何利用自然语言赋予应用程序更多力量和便捷的良好起点。
- en: Customer Support
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 客户支持
- en: The history panel of interactions is a good place to embed customer-support
    conversations. Such conversations occupy more vertical space than most examples
    in this text. In a customer support conversation, your organization’s answers
    are linguistic expressions, whether produced by a chatbot or a human service operator.
    They need to be fully displayed rather than embedded in a hyperlink. But that
    is fine since otherwise, this space would be consumed elsewhere. Your organization
    probably already has a chatbot on the website or the app. It is logical to unify
    it with the history panel of the natural language bar.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 互动的历史面板是嵌入客户支持对话的好地方。这些对话占用的垂直空间比文本中大多数示例更多。在客户支持对话中，贵组织的回答是语言表达，无论是由聊天机器人还是人工服务人员生成。它们需要完全显示，而不是嵌入超链接中。但这没关系，因为否则这些空间会被其他地方占用。贵组织可能已经在网站或应用程序上拥有一个聊天机器人。将其与自然语言栏的历史面板统一是合乎逻辑的。
- en: Context-sensitive Help
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上下文敏感的帮助
- en: In the context described above, we maintain a history of linguistic interaction
    with our app. In the future, we may (invisible) add a trace of direct user interaction
    with the GUI to this history sequence. Context-sensitive help could be given by
    combining the history trace of user interaction with RAG on the help documentation
    of the app. User questions will then be answered more in the context of the current
    state of the app.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述描述的背景下，我们保持与应用程序的语言互动历史。未来，我们可能（隐形地）将直接用户交互的轨迹添加到该历史序列中。通过将用户交互的历史轨迹与RAG结合在应用程序的帮助文档中，可以提供上下文敏感的帮助。用户的问题将更能根据应用程序当前状态得到回答。
- en: Beyond static assistance for Mobile Apps
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越移动应用程序的静态辅助
- en: 'The current proposal is an MVP. It offers a static template for interpreting
    a user’s linguistic requests in the context of an app. This technique opens a
    broad spectrum of future improvements:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当前提议是一个MVP（最简可行产品）。它提供了一个静态模板，用于在应用程序的上下文中解释用户的语言请求。这种技术为未来的广泛改进打开了广阔的前景：
- en: When users pose a question when they are on a specific screen, we may be able
    to dynamically add more specific interpretation templates (functions) to the prompt
    that depend on the state of that screen, like ‘Why is the submit button greyed
    out/disabled?’.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当用户在特定屏幕上提问时，我们可能能够动态地将更多具体的解释模板（功能）添加到提示中，这些模板依赖于该屏幕的状态，例如‘为什么提交按钮变灰/禁用？’。
- en: Function calling using a Natural Language Bar can be used as an assistant for
    creative applications, e.g. to execute procedures on selections like ‘make the
    same size’, or ‘turn into a reusable component’. Microsoft Copilot 365 is already
    using similar features. The approach taken in this article can also enable your
    organization to take advantage of such functions.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自然语言栏进行功能调用可以作为创意应用的助手，例如执行像‘调整为相同大小’或‘转变为可重用组件’这样的操作。微软Copilot 365已经在使用类似的功能。本文中采用的方法也可以帮助您的组织利用这些功能。
- en: Natural language interaction with every aspect of your system will rapidly become
    a major component of every UI. When using ‘function calling,’ you must include
    your system abilities in the prompt, but soon, more economical and powerful methods
    will hit the market. For instance, OpenAI has recently opened up [model finetuning
    with function calling](https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples),
    allowing you to create an LLM version with the abilities of your system baked
    in. Even when those abilities are very extensive, the load on the prompt remains
    limited.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 与系统每个方面的自然语言交互将迅速成为每个UI的主要组成部分。在使用‘功能调用’时，您必须在提示中包含系统能力，但很快会有更经济和更强大的方法上市。例如，OpenAI最近开放了[模型微调与功能调用](https://platform.openai.com/docs/guides/fine-tuning/fine-tuning-examples)，允许您创建一个具有系统能力的LLM版本。即使这些能力非常广泛，提示的负担仍然有限。
- en: Conclusion
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: LLMs can be an excellent glue for interacting with GUI-based apps in natural
    language through ‘function calling’. A Natural Language Bar was introduced that
    enables users to type or speak their intentions. The system will respond by navigating
    to the right screen and prefilling the correct values. The sample app allows you
    to actually feel what that is like, and the available source code makes it possible
    to quickly apply this to your own app if you use Flutter. The Natural Language
    Bar is not for Flutter or mobile apps only but can be applied to any application
    with a GUI. Its greatest strength is that it opens up the entirety of the functionality
    of the app for the user from a single access point, without the user having to
    know how to do things, where to find them, or even having to know the jargon of
    the app. From an app development perspective, you can offer all this to the user
    by simply documenting the purpose of your screens and the input widgets on them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs可以通过‘功能调用’成为与基于GUI的应用程序进行自然语言交互的绝佳桥梁。引入了一个自然语言栏，允许用户输入或说出他们的意图。系统将通过导航到正确的屏幕并预填正确的值来回应。示例应用程序使您实际体验到这一点，提供的源代码使得如果您使用Flutter，可以快速将其应用到自己的应用程序中。自然语言栏不仅适用于Flutter或移动应用程序，还可以应用于任何具有GUI的应用程序。它的最大优势是可以从一个单一的访问点打开应用程序的全部功能，而无需用户知道如何操作、在哪里找到功能，甚至不需要了解应用程序的术语。从应用开发的角度来看，您只需简单地记录屏幕的目的和屏幕上的输入小部件，就可以向用户提供这一切。
- en: Please share your ideas in the comments. I’m really curious.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 请在评论中分享您的想法。我非常好奇。
- en: Follow me on [LinkedIn](https://www.linkedin.com/in/hans-van-dam-71a7866/) or
    [UXX.AI](https://uxx.ai)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 请在[LinkedIn](https://www.linkedin.com/in/hans-van-dam-71a7866/)或[UXX.AI](https://uxx.ai)上关注我。
- en: Special thanks to [David Miguel Lozano](https://www.linkedin.com/in/davidmigloz/)
    for helping me with [LangChain Dart](https://github.com/davidmigloz/langchain_dart)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢[David Miguel Lozano](https://www.linkedin.com/in/davidmigloz/)帮助我完成[LangChain
    Dart](https://github.com/davidmigloz/langchain_dart)。
- en: 'Some interesting articles: [multimodal dialog](https://masterofcode.com/blog/multimodal-conversation-design-tutorial-part-2-best-practices-use-cases-and-future-outlook),
    [google blog on GUIs and LLMs](https://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html),
    [interpreting GUI interaction as language](https://pure.tue.nl/ws/files/3655721/200612175.pdf),
    [LLM Powered Assistants](https://nickarner.com/notes/llm-powered-assistants-for-complex-interfaces-february-26-2023/),
    [Language and GUI](https://medium.com/swlh/a-natural-language-user-interface-is-just-a-user-interface-4a6d898e9721),
    [Chatbot and GUI](https://medium.com/@aradzinski/the-future-ai-based-cx-has-nothing-to-do-with-chatbots-c8be20352f9d)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一些有趣的文章：[多模态对话](https://masterofcode.com/blog/multimodal-conversation-design-tutorial-part-2-best-practices-use-cases-and-future-outlook)、[谷歌关于GUI和LLM的博客](https://ai.googleblog.com/2023/05/enabling-conversational-interaction-on.html)、[将GUI交互解释为语言](https://pure.tue.nl/ws/files/3655721/200612175.pdf)、[LLM驱动的助手](https://nickarner.com/notes/llm-powered-assistants-for-complex-interfaces-february-26-2023/)、[语言与GUI](https://medium.com/swlh/a-natural-language-user-interface-is-just-a-user-interface-4a6d898e9721)、[聊天机器人与GUI](https://medium.com/@aradzinski/the-future-ai-based-cx-has-nothing-to-do-with-chatbots-c8be20352f9d)
- en: '*All images in this article, unless otherwise noted, are by the author*'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，本文中的所有图片均由作者提供*'
