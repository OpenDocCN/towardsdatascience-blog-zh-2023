- en: The Good, The Bad, and the Ugly of Pd.Get_Dummies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pd.Get_Dummies çš„åˆ©ä¸å¼Š
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/the-good-the-bad-and-the-ugly-of-pd-get-dummies-75c87e2aadc9](https://towardsdatascience.com/the-good-the-bad-and-the-ugly-of-pd-get-dummies-75c87e2aadc9)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/the-good-the-bad-and-the-ugly-of-pd-get-dummies-75c87e2aadc9](https://towardsdatascience.com/the-good-the-bad-and-the-ugly-of-pd-get-dummies-75c87e2aadc9)
- en: This is for the pd.get_dummies diehards
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é’ˆå¯¹ pd.get_dummies çš„æ­»å¿ ç²‰
- en: '[](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)[![Adam
    Ross Nelson](../Images/030b86a8c8bbd40c6acf60d1e387950c.png)](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)
    [Adam Ross Nelson](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)[![äºšå½“Â·ç½—æ–¯Â·å°¼å°”æ£®](../Images/030b86a8c8bbd40c6acf60d1e387950c.png)](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)
    [äºšå½“Â·ç½—æ–¯Â·å°¼å°”æ£®](https://adamrossnelson.medium.com/?source=post_page-----75c87e2aadc9--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)
    Â·5 min readÂ·Jul 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----75c87e2aadc9--------------------------------)
    Â·5 åˆ†é’Ÿé˜…è¯»Â·2023å¹´7æœˆ26æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Howdy folks ğŸ¤ 
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å®¶å¥½ ğŸ¤ 
- en: Okay, I get it. One of the easiest ways to convert a categorial to an array
    of dummies in Python is with the Pandas `pd.get_dummies()`. Why would you take
    the time to import `OneHotEncoder`from sklearn, execute a `.fit_transform()` etc,
    etc, etc? Talk about tedious!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†ã€‚åœ¨ Python ä¸­ï¼Œå°†åˆ†ç±»æ•°æ®è½¬æ¢ä¸ºè™šæ‹Ÿå˜é‡æ•°ç»„æœ€ç®€å•çš„æ–¹æ³•ä¹‹ä¸€æ˜¯ä½¿ç”¨ Pandas çš„ `pd.get_dummies()`ã€‚ä¸ºä»€ä¹ˆè¿˜è¦èŠ±æ—¶é—´å¯¼å…¥
    `OneHotEncoder` ä» sklearnï¼Œæ‰§è¡Œ `.fit_transform()` ç­‰ç­‰ï¼ŸçœŸæ˜¯ç¹çï¼
- en: This article will first introduce a simple data set for demonstration purposes
    that consists of a testing set that contains categoricals not found in the training
    set. Then, it will demonstrate how using `pd.get_dummies()` can lead to problems
    with the demonstration data. And, finally show how to avoid that problem with
    sklearnâ€™s `OneHotEncoder`.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¯‡æ–‡ç« é¦–å…ˆä»‹ç»ä¸€ä¸ªç®€å•çš„æ•°æ®é›†ï¼Œç”¨äºæ¼”ç¤ºç›®çš„ï¼Œå…¶ä¸­æµ‹è¯•é›†åŒ…å«åœ¨è®­ç»ƒé›†ä¸­æœªå‘ç°çš„åˆ†ç±»æ•°æ®ã€‚ç„¶åï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `pd.get_dummies()` å¯èƒ½ä¼šå¯¼è‡´æ¼”ç¤ºæ•°æ®å‡ºç°é—®é¢˜ã€‚æœ€åï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨
    sklearn çš„ `OneHotEncoder` é¿å…è¿™ä¸ªé—®é¢˜ã€‚
- en: '![](../Images/fa8e91379f5a2edc4d962a235f228a29.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa8e91379f5a2edc4d962a235f228a29.png)'
- en: 'Image Credit: Authorâ€™s illustration using text to image in Canva. Prompted:
    â€œThree panda bears dressed as country western cowboys.â€'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼šä½œè€…åœ¨ Canva ä¸Šä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒçš„æ’å›¾ã€‚æç¤ºï¼šâ€œä¸‰åªç©¿ç€ä¹¡æ‘è¥¿éƒ¨ç‰›ä»”æœè£…çš„ç†ŠçŒ«ã€‚â€
- en: A simple dataset for demonstration
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¼”ç¤ºç”¨çš„ç®€å•æ•°æ®é›†
- en: Here we have a simple dataset that includes a categorical feature called OS.
    The OS column lists computer operating systems. We will use this fictional data
    for purposes of demonstration. In `train_df` will be fictional demonstration training
    data. While in `test_df` we have fictional demonstration testing data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªåä¸º OS çš„åˆ†ç±»ç‰¹å¾ã€‚OS åˆ—åˆ—å‡ºäº†è®¡ç®—æœºæ“ä½œç³»ç»Ÿã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›è™šæ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚åœ¨ `train_df`
    ä¸­åŒ…å«è™šæ‹Ÿæ¼”ç¤ºè®­ç»ƒæ•°æ®ï¼Œè€Œåœ¨ `test_df` ä¸­åŒ…å«è™šæ‹Ÿæ¼”ç¤ºæµ‹è¯•æ•°æ®ã€‚
- en: In our fictional demonstration case, the testing set contains categorical values
    not present in the training set. This mis-match will cause problems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„è™šæ‹Ÿæ¼”ç¤ºæ¡ˆä¾‹ä¸­ï¼Œæµ‹è¯•é›†åŒ…å«åœ¨è®­ç»ƒé›†ä¸­ä¸å­˜åœ¨çš„åˆ†ç±»å€¼ã€‚è¿™ç§ä¸åŒ¹é…ä¼šå¯¼è‡´é—®é¢˜ã€‚
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In our training data, we have three operating systems: Windows, MacOS, and
    Linux. But in our testing data, we have the additional categories including Android,
    Unix, and iOS.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸‰ç§æ“ä½œç³»ç»Ÿï¼šWindowsã€MacOS å’Œ Linuxã€‚ä½†åœ¨æˆ‘ä»¬çš„æµ‹è¯•æ•°æ®ä¸­ï¼Œè¿˜åŒ…æ‹¬ Androidã€Unix å’Œ iOS
    ç­‰é¢å¤–ç±»åˆ«ã€‚
- en: A model â€˜fitâ€™ on `pd.get_dummies(train_df)` will not work with with testing
    data from `pd.get_dummies(test_df)` . The results will not match â€” because of
    the mis-matched categories.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `pd.get_dummies(train_df)` æ‹Ÿåˆçš„æ¨¡å‹å°†æ— æ³•ä¸ `pd.get_dummies(test_df)` çš„æµ‹è¯•æ•°æ®ä¸€èµ·ä½¿ç”¨ã€‚ç»“æœå°†ä¸åŒ¹é…â€”â€”å› ä¸ºç±»åˆ«ä¸åŒ¹é…ã€‚
- en: '![](../Images/928ac32f04f9d59aa60f5d4c932fcc7f.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/928ac32f04f9d59aa60f5d4c932fcc7f.png)'
- en: 'Image Credit: Authorâ€™s illustration created in Canva using Canva stock images.
    An art supply dummy.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼šä½œè€…åœ¨ Canva ä¸Šä½¿ç”¨ Canva åº“å›¾åƒåˆ›å»ºçš„æ’å›¾ã€‚è‰ºæœ¯ç”¨å“è™šæ‹Ÿæ¨¡å‹ã€‚
- en: The Problem with pd.get_dummies()
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pd.get_dummies() çš„é—®é¢˜
- en: When applying the `pd.get_dummies()` function to both our training and testing
    datasets here is what youâ€™ll get.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å½“å°†`pd.get_dummies()`å‡½æ•°åº”ç”¨äºæˆ‘ä»¬çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†æ—¶ï¼Œä½ ä¼šå¾—åˆ°è¿™æ ·çš„ç»“æœã€‚
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you evaluate the `train_encoded` and `test_encoded` DataFrames, you'll notice
    that they do not have the same number of columns. This is because the 'Android'
    category, present only in the testing set, has created an additional column in
    `test_encoded`. This inconsistency in the number of features between training
    and testing datasets can cause significant problems when building and evaluating
    machine learning models, which expect the same feature space in both datasets.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¯„ä¼°`train_encoded`å’Œ`test_encoded` DataFramesï¼Œä½ ä¼šæ³¨æ„åˆ°å®ƒä»¬çš„åˆ—æ•°ä¸åŒã€‚è¿™æ˜¯å› ä¸ºæµ‹è¯•é›†ä¸­ä»…å­˜åœ¨çš„'Android'ç±»åˆ«åœ¨`test_encoded`ä¸­åˆ›å»ºäº†ä¸€ä¸ªé¢å¤–çš„åˆ—ã€‚è¿™ç§è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ç‰¹å¾æ•°é‡çš„ä¸ä¸€è‡´å¯èƒ½åœ¨æ„å»ºå’Œè¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶é€ æˆé‡å¤§é—®é¢˜ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹æœŸæœ›ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„ç‰¹å¾ç©ºé—´ç›¸åŒã€‚
- en: '![](../Images/380c309a5fac4b5da8a646a4858c2347.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/380c309a5fac4b5da8a646a4858c2347.png)'
- en: 'Image Credit: Authorâ€™s screen grabs, produced with code shown here.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼šä½œè€…çš„å±å¹•æˆªå›¾ï¼Œä½¿ç”¨æ­¤å¤„æ˜¾ç¤ºçš„ä»£ç ç”Ÿæˆã€‚
- en: The Solution with OneHotEncoder
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨OneHotEncoderçš„è§£å†³æ–¹æ¡ˆ
- en: Now, letâ€™s see how `OneHotEncoder` from sklearn solves this problem. When using
    `OneHotEncoder`, the encoder learns the categories during the `.fit()` or `.fit_transform()`
    method on the training data. Then, during the `.transform()` method, it creates
    columns for all learned categories. If a new category is found in the testing
    data there are two options. First you can ignore the new unseen categories.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹sklearnçš„`OneHotEncoder`å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å½“ä½¿ç”¨`OneHotEncoder`æ—¶ï¼Œç¼–ç å™¨åœ¨è®­ç»ƒæ•°æ®çš„`.fit()`æˆ–`.fit_transform()`æ–¹æ³•æœŸé—´å­¦ä¹ ç±»åˆ«ã€‚ç„¶åï¼Œåœ¨`.transform()`æ–¹æ³•æœŸé—´ï¼Œå®ƒä¸ºæ‰€æœ‰å­¦ä¹ åˆ°çš„ç±»åˆ«åˆ›å»ºåˆ—ã€‚å¦‚æœåœ¨æµ‹è¯•æ•°æ®ä¸­å‘ç°äº†æ–°ç±»åˆ«ï¼Œåˆ™æœ‰ä¸¤ä¸ªé€‰é¡¹ã€‚é¦–å…ˆï¼Œä½ å¯ä»¥å¿½ç•¥æ–°çš„æœªè§ç±»åˆ«ã€‚
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that we set `handle_unknown='ignore'` to tell the encoder to ignore (rather
    than throw an error for) any category in the testing set that it didn't see in
    the training set.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬è®¾ç½®äº†`handle_unknown='ignore'`ä»¥å‘Šè¯‰ç¼–ç å™¨å¿½ç•¥ï¼ˆè€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯ï¼‰åœ¨æµ‹è¯•é›†ä¸­çœ‹åˆ°çš„ä½†åœ¨è®­ç»ƒé›†ä¸­æœªè§çš„ä»»ä½•ç±»åˆ«ã€‚
- en: Also note, new as of 2023, sklearn offers a `.set_output(transform="pandas")`
    option that will ensure the encoder returns a Pandas DataFrame (complete with
    easier to read and interpret column names) instead of a the more minimalist NumPy
    array.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜è¦æ³¨æ„ï¼Œè‡ª2023å¹´èµ·ï¼Œsklearnæä¾›äº†`.set_output(transform="pandas")`é€‰é¡¹ï¼Œè¿™å°†ç¡®ä¿ç¼–ç å™¨è¿”å›ä¸€ä¸ªPandas
    DataFrameï¼ˆå…·æœ‰æ›´æ˜“è¯»å’Œè§£é‡Šçš„åˆ—åï¼‰ï¼Œè€Œä¸æ˜¯æ›´ç®€æ´çš„NumPyæ•°ç»„ã€‚
- en: By handling unknown categories with `handle_unknown='ignore'`, `OneHotEncoder`
    ensures that the training and testing data have the same feature space, regardless
    of what categorical values appear in the testing data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä½¿ç”¨`handle_unknown='ignore'`å¤„ç†æœªçŸ¥ç±»åˆ«ï¼Œ`OneHotEncoder`ç¡®ä¿è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®å…·æœ‰ç›¸åŒçš„ç‰¹å¾ç©ºé—´ï¼Œæ— è®ºæµ‹è¯•æ•°æ®ä¸­å‡ºç°äº†ä»€ä¹ˆç±»åˆ«å€¼ã€‚
- en: The Additional Benefits of OneHotEncoder
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OneHotEncoderçš„é™„åŠ å¥½å¤„
- en: Sklearnâ€™s `OneHotEncoder` is not only super helpful for handling unseen categories
    in your testing data; it also provides additional functionality that can also
    be useful. Her are two of these additional options and how to use them.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Sklearnçš„`OneHotEncoder`ä¸ä»…åœ¨å¤„ç†æµ‹è¯•æ•°æ®ä¸­æœªè§ç±»åˆ«æ—¶éå¸¸æœ‰ç”¨ï¼Œå®ƒè¿˜æä¾›äº†å…¶ä»–ä¸€äº›é™„åŠ åŠŸèƒ½ï¼Œè¿™äº›åŠŸèƒ½ä¹Ÿå¯èƒ½å¾ˆæœ‰ç”¨ã€‚ä»¥ä¸‹æ˜¯å…¶ä¸­ä¸¤ä¸ªé™„åŠ é€‰é¡¹åŠå…¶ä½¿ç”¨æ–¹æ³•ã€‚
- en: min_frequency
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: min_frequency
- en: The `min_frequency` is another powerful option that allows you to specify a
    minimum frequency threshold. Categories with a frequency below this threshold
    get recoded as â€œinfrequent.â€ This could be useful when you have categories that
    only appear a few times and may not offer enough information to help the model
    and that may only serve to over-complicate the model with unhelpful features that
    undermine performance without adding any predictive value.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`min_frequency`æ˜¯å¦ä¸€ä¸ªå¼ºå¤§çš„é€‰é¡¹ï¼Œå®ƒå…è®¸ä½ æŒ‡å®šä¸€ä¸ªæœ€ä½é¢‘ç‡é˜ˆå€¼ã€‚é¢‘ç‡ä½äºæ­¤é˜ˆå€¼çš„ç±»åˆ«ä¼šè¢«é‡æ–°ç¼–ç ä¸ºâ€œç½•è§â€ã€‚è¿™åœ¨ä½ æœ‰ä¸€äº›åªå‡ºç°å‡ æ¬¡çš„ç±»åˆ«æ—¶éå¸¸æœ‰ç”¨ï¼Œè¿™äº›ç±»åˆ«å¯èƒ½æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å¸®åŠ©æ¨¡å‹ï¼Œå¯èƒ½ä¼šä½¿æ¨¡å‹å¤æ‚åŒ–ï¼Œå¢åŠ æ— ç”¨çš„ç‰¹å¾ï¼Œä»è€Œé™ä½æ€§èƒ½è€Œæ²¡æœ‰ä»»ä½•é¢„æµ‹ä»·å€¼ã€‚'
- en: 'Hereâ€™s how you can set a `min_frequency` of 2:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¦‚ä½•è®¾ç½®`min_frequency`ä¸º2çš„ï¼š
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: max_categories
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: max_categories
- en: Also useful is `max_categories`. The `max_categories` argument allows you to
    limit the number of output columns in the dummy array. The encoder will take the
    most frequent categories for encoding.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªæœ‰ç”¨çš„é€‰é¡¹æ˜¯`max_categories`ã€‚`max_categories`å‚æ•°å…è®¸ä½ é™åˆ¶è™šæ‹Ÿæ•°ç»„ä¸­çš„è¾“å‡ºåˆ—æ•°ã€‚ç¼–ç å™¨å°†é€‰æ‹©æœ€å¸¸è§çš„ç±»åˆ«è¿›è¡Œç¼–ç ã€‚
- en: This option is beneficial and helpful when dealing with features that have many
    categories which would ordinarily result in a high number of dimensions. Possibly
    high enough to significantly reduce training efficiency while increasing model
    complexity all while returning very little value in the form of higher predictive
    power. In short this reduces the dimensionality of your data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé€‰é¡¹åœ¨å¤„ç†å…·æœ‰è®¸å¤šç±»åˆ«çš„ç‰¹å¾æ—¶ç‰¹åˆ«æœ‰ç›Šï¼Œè¿™äº›ç‰¹å¾é€šå¸¸ä¼šå¯¼è‡´ç»´åº¦æ•°ç›®å¾ˆé«˜ã€‚è¿™å¯èƒ½ä¼šæ˜¾è‘—é™ä½è®­ç»ƒæ•ˆç‡ï¼ŒåŒæ—¶å¢åŠ æ¨¡å‹å¤æ‚æ€§ï¼Œå¹¶ä¸”å‡ ä¹æ²¡æœ‰æé«˜é¢„æµ‹èƒ½åŠ›çš„ä»·å€¼ã€‚ç®€è€Œè¨€ä¹‹ï¼Œè¿™å‡å°‘äº†æ•°æ®çš„ç»´åº¦ã€‚
- en: 'Hereâ€™s how to limit the encoding to the top 4 most frequent categories:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é™åˆ¶ç¼–ç åˆ°å‰4ä¸ªæœ€é¢‘ç¹ç±»åˆ«çš„æ–¹æ³•ï¼š
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Conclusion
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In the grander scheme of things, using `pd.get_dummies()` instead of a true
    fit and transform procedure, there are worse sins in the field of data science.
    However, if you have been holding out as a diehard for `pd.get_dummies()` now
    you know the good, the bad and the ugly â€” after reading this article, you should
    consider shifting your practice.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ›´å®è§‚çš„è§’åº¦æ¥çœ‹ï¼Œä½¿ç”¨`pd.get_dummies()`è€Œä¸æ˜¯çœŸæ­£çš„æ‹Ÿåˆå’Œè½¬æ¢è¿‡ç¨‹ï¼Œåœ¨æ•°æ®ç§‘å­¦é¢†åŸŸè¿˜æœ‰æ›´ä¸¥é‡çš„é”™è¯¯ã€‚ç„¶è€Œï¼Œå¦‚æœä½ ä¸€ç›´åšæŒä½¿ç”¨`pd.get_dummies()`ï¼Œç°åœ¨ä½ å·²ç»äº†è§£äº†å®ƒçš„ä¼˜ç‚¹ã€ç¼ºç‚¹å’Œä¸è¶³â€”â€”é˜…è¯»å®Œè¿™ç¯‡æ–‡ç« åï¼Œä½ åº”è¯¥è€ƒè™‘è°ƒæ•´ä½ çš„åšæ³•ã€‚
- en: While `pd.get_dummies()` can be a quick and easy way to create dummy variables
    in Python, it can lead to problems when your testing data contains categories
    not seen in your training data. On the other hand, sklearn's `OneHotEncoder` handles
    this scenario elegantly, ensuring consistent feature spaces across datasets. It's
    worth the extra lines of code to avoid potential pitfalls down the line.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶`pd.get_dummies()`åœ¨Pythonä¸­åˆ›å»ºè™šæ‹Ÿå˜é‡æ˜¯å¿«é€Ÿä¸”ç®€ä¾¿çš„ï¼Œä½†å½“ä½ çš„æµ‹è¯•æ•°æ®åŒ…å«åœ¨è®­ç»ƒæ•°æ®ä¸­æœªè§è¿‡çš„ç±»åˆ«æ—¶ï¼Œå¯èƒ½ä¼šå¯¼è‡´é—®é¢˜ã€‚å¦ä¸€æ–¹é¢ï¼Œsklearnçš„`OneHotEncoder`ä¼˜é›…åœ°å¤„ç†äº†è¿™ç§æƒ…å†µï¼Œç¡®ä¿äº†æ•°æ®é›†é—´ä¸€è‡´çš„ç‰¹å¾ç©ºé—´ã€‚å€¼å¾—å¤šå†™å‡ è¡Œä»£ç ï¼Œä»¥é¿å…æ½œåœ¨çš„é™·é˜±ã€‚
- en: Thanks For Reading
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»
- en: Are you ready to learn more about careers in data science? I perform one-on-one
    career coaching and have a weekly email list that helps data professional job
    candidates. [Contact me to learn more](https://coaching.adamrossnelson.com/).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å‡†å¤‡å¥½äº†è§£æ›´å¤šæ•°æ®ç§‘å­¦é¢†åŸŸçš„èŒä¸šäº†å—ï¼Ÿæˆ‘æä¾›ä¸€å¯¹ä¸€çš„èŒä¸šæŒ‡å¯¼ï¼Œå¹¶æœ‰æ¯å‘¨çš„ç”µå­é‚®ä»¶åˆ—è¡¨ï¼Œå¸®åŠ©æ•°æ®ä¸“ä¸šçš„æ±‚èŒè€…ã€‚[è”ç³»æˆ‘äº†è§£æ›´å¤š](https://coaching.adamrossnelson.com/)ã€‚
- en: 'Thanks for reading. Send me your thoughts and ideas. You can write just to
    say hey. And if you really need to tell me how I got it wrong I look forward to
    chatting soon. Twitter: [@adamrossnelson](https://twitter.com/adamrossnelson)
    LinkedIn: [Adam Ross Nelson](https://www.linkedin.com/in/arnelson/).'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 'æ„Ÿè°¢é˜…è¯»ã€‚è¯·æŠŠä½ çš„æƒ³æ³•å’Œå»ºè®®å‘ç»™æˆ‘ã€‚ä½ å¯ä»¥åªæ˜¯è¯´å£°ä½ å¥½ã€‚å¦‚æœä½ çœŸçš„éœ€è¦å‘Šè¯‰æˆ‘å“ªé‡Œåšé”™äº†ï¼Œæˆ‘æœŸå¾…å¾ˆå¿«ä¸ä½ èŠèŠã€‚Twitter: [@adamrossnelson](https://twitter.com/adamrossnelson)
    LinkedIn: [Adam Ross Nelson](https://www.linkedin.com/in/arnelson/)ã€‚'
