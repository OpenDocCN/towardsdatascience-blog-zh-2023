- en: Building a Batch Data Pipeline with Athena and MySQL
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Athenaå’ŒMySQLæ„å»ºæ‰¹é‡æ•°æ®ç®¡é“
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/building-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c?source=collection_archive---------6-----------------------#2023-10-20](https://towardsdatascience.com/building-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c?source=collection_archive---------6-----------------------#2023-10-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/building-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c?source=collection_archive---------6-----------------------#2023-10-20](https://towardsdatascience.com/building-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c?source=collection_archive---------6-----------------------#2023-10-20)
- en: An End-To-End Tutorial for Beginners
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆå­¦è€…çš„ç«¯åˆ°ç«¯æ•™ç¨‹
- en: '[](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)[![ğŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)
    [ğŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe06a48b3dd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=post_page-e06a48b3dd48----7e60575ff39c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)
    Â·16 min readÂ·Oct 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e60575ff39c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=-----7e60575ff39c---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe06a48b3dd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=post_page-e06a48b3dd48----7e60575ff39c---------------------post_header-----------)
    å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)
    Â·16åˆ†é’Ÿé˜…è¯»Â·2023å¹´10æœˆ20æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e60575ff39c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=-----7e60575ff39c---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e60575ff39c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&source=-----7e60575ff39c---------------------bookmark_footer-----------)![](../Images/368293b91e4bc0283007a555789b6479.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e60575ff39c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&source=-----7e60575ff39c---------------------bookmark_footer-----------)![](../Images/368293b91e4bc0283007a555789b6479.png)'
- en: Photo by [Redd F](https://unsplash.com/@raddfilms?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [Redd F](https://unsplash.com/@raddfilms?utm_source=medium&utm_medium=referral)
    æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In this story I will speak about one of the most popular ways to run data transformation
    tasks â€” batch data processing. This data pipeline design pattern becomes incredibly
    useful when we need to process data in chunks making it very efficient for ETL
    jobs that require scheduling. I will demonstrate how it can be achieved by building
    a data transformation pipeline using MySQL and Athena. We will use infrastructure
    as code to deploy it in the cloud.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªæ•…äº‹ä¸­ï¼Œæˆ‘å°†è®²è¿°ä¸€ç§æœ€å—æ¬¢è¿çš„æ•°æ®è½¬æ¢ä»»åŠ¡è¿è¡Œæ–¹å¼â€”â€”æ‰¹é‡æ•°æ®å¤„ç†ã€‚å½“æˆ‘ä»¬éœ€è¦åˆ†å—å¤„ç†æ•°æ®æ—¶ï¼Œè¿™ç§æ•°æ®ç®¡é“è®¾è®¡æ¨¡å¼å˜å¾—éå¸¸æœ‰ç”¨ï¼Œä½¿å…¶åœ¨éœ€è¦è°ƒåº¦çš„ETLä»»åŠ¡ä¸­éå¸¸é«˜æ•ˆã€‚æˆ‘å°†æ¼”ç¤ºå¦‚ä½•é€šè¿‡ä½¿ç”¨MySQLå’ŒAthenaæ„å»ºæ•°æ®è½¬æ¢ç®¡é“æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨åŸºç¡€è®¾æ–½å³ä»£ç åœ¨äº‘ä¸­éƒ¨ç½²å®ƒã€‚
- en: Imagine that you have just joined a company as a Data Engineer. Their data stack
    is modern, event-driven, cost-effective, flexible, and can scale easily to meet
    the growing data resources you have. External data sources and data pipelines
    in your data platform are managed by the data engineering team using a flexible
    environment setup with CI/CD GitHub integration.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹ä½ åˆšåˆšåŠ å…¥ä¸€å®¶å…¬å¸æ‹…ä»»æ•°æ®å·¥ç¨‹å¸ˆã€‚ä»–ä»¬çš„æ•°æ®æ ˆç°ä»£ã€äº‹ä»¶é©±åŠ¨ã€æˆæœ¬æ•ˆç›Šé«˜ã€çµæ´»ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ‰©å±•ä»¥æ»¡è¶³ä¸æ–­å¢é•¿çš„æ•°æ®èµ„æºã€‚æ•°æ®å¹³å°ä¸­çš„å¤–éƒ¨æ•°æ®æºå’Œæ•°æ®ç®¡é“ç”±æ•°æ®å·¥ç¨‹å›¢é˜Ÿç®¡ç†ï¼Œä½¿ç”¨å…·æœ‰CI/CD
    GitHubé›†æˆçš„çµæ´»ç¯å¢ƒè®¾ç½®ã€‚
- en: As a data engineer you need to create a business intelligence dashboard that
    displays the geography of company revenue streams as shown below. Raw payment
    data is stored in the server database (MySQL). You want to build a batch pipeline
    that extracts data from that database daily, then use AWS S3 to store data files
    and Athena to process it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºæ•°æ®å·¥ç¨‹å¸ˆï¼Œä½ éœ€è¦åˆ›å»ºä¸€ä¸ªä¸šåŠ¡æ™ºèƒ½ä»ªè¡¨ç›˜ï¼Œå±•ç¤ºå…¬å¸çš„æ”¶å…¥æµåœ°ç†åˆ†å¸ƒï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚åŸå§‹æ”¯ä»˜æ•°æ®å­˜å‚¨åœ¨æœåŠ¡å™¨æ•°æ®åº“ï¼ˆMySQLï¼‰ä¸­ã€‚ä½ æƒ³å»ºç«‹ä¸€ä¸ªæ‰¹å¤„ç†ç®¡é“ï¼Œæ¯å¤©ä»æ•°æ®åº“ä¸­æå–æ•°æ®ï¼Œç„¶åä½¿ç”¨AWS
    S3å­˜å‚¨æ•°æ®æ–‡ä»¶ï¼Œå¹¶ç”¨Athenaå¤„ç†è¿™äº›æ•°æ®ã€‚
