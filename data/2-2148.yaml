- en: Tree of Thoughts Prompting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思维树提示
- en: 原文：[https://towardsdatascience.com/tree-of-thoughts-prompting-65a3e51f9ac4](https://towardsdatascience.com/tree-of-thoughts-prompting-65a3e51f9ac4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tree-of-thoughts-prompting-65a3e51f9ac4](https://towardsdatascience.com/tree-of-thoughts-prompting-65a3e51f9ac4)
- en: Solving multi-step problems with LLMs via deliberate planning and exploration…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过有意规划和探索来解决LLMs的多步骤问题……
- en: '[](https://wolfecameron.medium.com/?source=post_page-----65a3e51f9ac4--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----65a3e51f9ac4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----65a3e51f9ac4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----65a3e51f9ac4--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----65a3e51f9ac4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----65a3e51f9ac4--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----65a3e51f9ac4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----65a3e51f9ac4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----65a3e51f9ac4--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----65a3e51f9ac4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----65a3e51f9ac4--------------------------------)
    ·20 min read·Dec 22, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----65a3e51f9ac4--------------------------------)
    ·20 min 阅读·2023年12月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/3a1d8bce28681223f010bacd921267e1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a1d8bce28681223f010bacd921267e1.png)'
- en: (Photo by [Johann Siemens](https://unsplash.com/@emben?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/green-tree-on-grassland-during-daytime-EPy0gBJzzZU?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由 [Johann Siemens](https://unsplash.com/@emben?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    提供，刊登在 [Unsplash](https://unsplash.com/photos/green-tree-on-grassland-during-daytime-EPy0gBJzzZU?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)）
- en: As large language models (LLMs) first started to gain in popularity, they were
    criticized for their shortcomings in solving complex, reasoning-based problems.
    Although scaling up these models (i.e., more parameters and more data) provided
    a near-uniform performance improvement across tasks, we saw virtually no boost
    in performance on reasoning-based tasks with modern LLMs. This changed with the
    proposal of advanced prompting techniques, such as chain of thought prompting
    [2] and self-consistency [3]. Such methods showed us that LLMs are more than capable
    of reasoning and solving complex, multi-step problems. They just have to be properly
    prompted to fully leverage these abilities.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当大型语言模型（LLMs）首次开始受到关注时，它们因在解决复杂推理问题方面的不足而受到批评。尽管扩大这些模型的规模（即更多的参数和数据）在各项任务中提供了近乎一致的性能提升，但我们几乎没有看到现代LLMs在推理任务上的性能提升。这一情况随着先进提示技术的提出而改变，如思维链提示[2]和自一致性[3]。这些方法向我们展示了LLMs完全有能力进行推理和解决复杂的多步骤问题。它们只需要正确的提示来充分发挥这些能力。
- en: “It is perhaps surprising that underlying all this progress is still the original
    autoregressive mechanism for generating text, which makes token-level decisions
    one by one and in a left-to-right fashion.” *— from [1]*
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “也许令人惊讶的是，所有这些进展背后仍然是最初的自回归文本生成机制，该机制逐个生成令牌，并按从左到右的方式进行决策。” *— 摘自 [1]*
- en: Even if proper prompting can enable LLMs to solve complex problems, these techniques
    are lacking. Namely, we typically *i)* provide a prompt to the LLM and *ii)* expect
    the model to use next token prediction to generate a full solution. Certain approaches
    may generate solutions in a step-by-step fashion (e.g., least-to-most prompting
    [8]), but the LLM still follows a single reasoning path instead of exploring several
    potential solutions. For complex problems in which initial decisions can completely
    derail a solution, such an approach will fall short, which is an issue given that
    LLMs are now commonly used as general purpose problem solvers in a variety of
    practical applications. Put simply, *we need a prompting approach that performs
    more deliberate planning and exploration when solving problems*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 即使适当的提示可以使大型语言模型（LLMs）解决复杂问题，这些技术仍然存在不足。即，我们通常*（i）* 给LLM提供一个提示，并*（ii）* 期望模型通过下一个词预测生成完整的解决方案。某些方法可能以逐步的方式生成解决方案（例如，最少到最多提示[8]），但LLM仍然遵循单一的推理路径，而不是探索多种潜在解决方案。对于那些初步决策可能完全破坏解决方案的复杂问题，这种方法将难以奏效，这一点尤其值得注意，因为LLM现在常被用作各种实际应用中的通用问题解决者。简单来说，*我们需要一种在解决问题时能够进行更周密规划和探索的提示方法*。
- en: In [1], authors propose such an approach — called Tree of Thoughts prompting
    — that solves problems by explicitly decomposing them into a series of *thoughts*,
    or intermediate steps. Similar to chain of thoughts prompting, tree of thoughts
    prompting generates a solution that is simply a sequence of individual thoughts.
    However, this approach goes further by allowing multiple reasoning path to be
    considered at once — *forming a tree of potential thoughts or reasoning paths*
    — and exploring this entire solution space via LLM-powered self-evaluation. With
    tree of thoughts prompting, the LLM can deliberately plan its solution, test various
    intermediate reasoning paths, and even perform backtracking, allowing the model
    to explore the solution space and eventually generate the correct output.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在[1]中，作者提出了一种被称为“思维树提示”的方法，它通过明确地将问题分解为一系列*思维*，即中间步骤，来解决问题。类似于链式思维提示，思维树提示生成的解决方案仅仅是一个单独思维的序列。然而，这种方法更进一步，允许同时考虑多条推理路径——*形成一个潜在思维或推理路径的树状结构*——并通过LLM驱动的自我评估探索整个解决方案空间。通过思维树提示，LLM可以刻意规划其解决方案，测试各种中间推理路径，甚至进行回溯，从而探索解决方案空间，并最终生成正确的输出。
- en: Connections to Research in Other Fields and Generations
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与其他领域和生成方法的研究联系
- en: “A genuine problem-solving process involves the repeated use of available information
    to initiate exploration, which discloses, in turn, more information until a way
    to attain the solution is finally discovered.” *— from [12]*
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “一个真正的问题解决过程涉及反复使用可用信息来启动探索，这反过来又揭示了更多信息，直到最终发现解决方案的方法。” *——摘自[12]*
- en: '**Analogy to humans.** To explain their technique, authors in [1] draw upon
    analysis of the human decision making process. In particular, humans seems to
    have two separate modes of making decisions:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**类比于人类。** 为了解释他们的技术，[1]中的作者借鉴了对人类决策过程的分析。特别是，人类似乎有两种不同的决策模式：'
- en: A fast, automatic, and unconscious mode
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种快速、自动、无意识的模式
- en: A slow, deliberate, conscious mode
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种缓慢、刻意、有意识的模式
- en: Authors in [1] argue that techniques like chain of thought prompting seem to
    mimic the first mode outlined above, as the LLM just generates text in a left-to-right
    manner without deliberate planning or deconstruction of the problem. The main
    motivation behind tree of thoughts prompting is to inject deliberate planning
    and exploration into the problem-solving process by deconstructing each problem
    into a tree of smaller steps that are individually explored.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]中的作者认为，链式思维提示等技术似乎模仿了上述第一种模式，因为LLM只是以从左到右的方式生成文本，而没有进行刻意的规划或问题的解构。树状思维提示的主要动机是通过将每个问题分解成一个由较小步骤组成的树状结构，这些步骤被逐一探索，从而将刻意的规划和探索注入到问题解决过程中。'
- en: '**Inspired by early work in AI.** The planning process followed by tree of
    thoughts prompting is inspired by AI research from the mid 20th century [12, 13]!
    This work argues that problem solving can be formulated as searching through a
    combinatorial space represented as a tree. Within this space, multiple active
    chains of thought are maintained, each representing an individual path within
    the larger tree. As we will see, this formulation allows us to explicitly decompose
    a solution to a complex problem, as well as leverage established graph algorithms
    (e.g., breadth-first and depth-first search) to find a viable solution.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**受到早期人工智能工作的启发。** 思维树提示所遵循的规划过程受到20世纪中期人工智能研究的启发 [12, 13]！这项工作认为，问题解决可以被表述为在表示为树的组合空间中进行搜索。在这个空间内，保持多个活跃的思维链，每个链表示在大树中的一条路径。正如我们将看到的，这种表述使我们能够明确地分解复杂问题的解决方案，并利用已有的图算法（例如广度优先和深度优先搜索）找到可行的解决方案。'
- en: The Basics of Prompting
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示的基础知识
- en: '![](../Images/327bed0d26f518d52af5f3e3403d23a2.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/327bed0d26f518d52af5f3e3403d23a2.png)'
- en: (from [10])
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于 [10])
- en: The generic text-to-text format of LLMs is incredibly powerful. To solve any
    problem, we can simply *i)* write a textual prompt that describes the problem
    and *ii)* generate a relevant output/solution with the language model. For this
    reason, LLMs are considered to be foundation models, or models that can singlehandedly
    be adapted to solve a wide variety of tasks. Such an ability is largely due to
    in-context learning. Namely, pre-trained LLMs have the ability to use data injected
    into their prompt as context to produce a more accurate output; see below.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的通用文本到文本格式非常强大。要解决任何问题，我们可以简单地 *i)* 编写一个描述问题的文本提示，以及 *ii)* 使用语言模型生成相关的输出/解决方案。因此，LLM被认为是基础模型，即能够单独适应解决各种任务的模型。这种能力很大程度上得益于上下文学习。即，预训练的LLM有能力利用注入到提示中的数据作为上下文，产生更准确的输出；见下文。
- en: '![](../Images/41eb51e0e550a602172de70487bb02a1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41eb51e0e550a602172de70487bb02a1.png)'
- en: (from [5])
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于 [5])
- en: However, the effectiveness of in-context learning is highly related to the prompt
    that is used to solve a problem. Many different prompting approaches — including
    tree of thoughts prompting [1] — exist, but the process of choosing the correct
    prompting technique or writing the correct prompt can be quite difficult. For
    this reason, we will now take a brief look at the basics of prompt engineering,
    providing useful context that will make the various prompting techniques explored
    within this overview more understandable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，上下文学习的有效性与用于解决问题的提示高度相关。存在许多不同的提示方法——包括思维树提示 [1]——但选择正确的提示技术或编写正确的提示可能相当困难。因此，我们现在将简要介绍提示工程的基础知识，提供有用的背景，使本概述中探索的各种提示技术更加易于理解。
- en: What is prompt engineering?
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是提示工程？
- en: “Prompt engineering is a relatively new discipline for developing and optimizing
    prompts to efficiently use LMs for a wide variety of applications and research
    topics.” *— from [2]*
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “提示工程是一个相对较新的学科，用于开发和优化提示，以高效地利用语言模型进行各种应用和研究主题。” *— 来源于 [2]*
- en: 'Prompt engineering refers to the process of iteratively tweaking a prompt for
    a language model with the goal of discovering a prompt that accurately solves
    a desired task. Typically, the prompt engineering process is empirical, meaning
    that we discover the best prompts by measuring their performance on related tasks.
    Prompting is a new field that is full of heuristics and a variety of different
    techniques. As such, we can maximizes our chances of success by following an approach
    similar to any other engineering problem:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程指的是不断调整语言模型的提示，以发现能够准确解决预期任务的提示的过程。通常，提示工程的过程是经验性的，这意味着我们通过测量提示在相关任务上的表现来发现最佳提示。提示是一个充满启发式方法和各种不同技术的新领域。因此，我们可以通过遵循类似于其他工程问题的方法来最大化成功的机会：
- en: Track and version different prompts
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跟踪和版本化不同的提示
- en: Setup extensive benchmarks to measure prompt performance
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置广泛的基准以衡量提示的表现
- en: Test different ideas to see what yields the best results
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试不同的想法，看看哪些能产生最佳结果
- en: '![](../Images/1cf3383b3e08206dde875ac86b5209fb.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cf3383b3e08206dde875ac86b5209fb.png)'
- en: (created by the author)
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: (由作者创建)
- en: '**Context window.** One major consideration when writing a prompt is the size
    of the underlying LLM’s context window. As shown in the figure above, all LLMs
    are trained using inputs of a certain size (i.e., referred to as the size of the
    context window or context length), which — *along with memory constraints* — limits
    the total amount of data that can be provided to an LLM within a prompt. Practically,
    this means that we must be selective about the data that is included in a prompt.
    Next, we will overview the components of a prompt, as well as the kinds of information
    that might be provided to guide an LLM towards a correct solution.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文窗口**。编写提示时一个主要的考虑因素是底层LLM的上下文窗口的大小。如上图所示，所有LLM都是使用一定大小的输入进行训练的（即，上下文窗口或上下文长度的大小），这
    — *连同内存限制* — 限制了在提示中可以提供给LLM的数据总量。实际上，这意味着我们必须对提示中包含的数据进行选择。接下来，我们将概述提示的组成部分，以及可能提供的信息类型，以引导LLM找到正确的解决方案。'
- en: Structure of a Prompt
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示的结构
- en: '![](../Images/beb9d2fea239480e760f94ac918df4fd.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/beb9d2fea239480e760f94ac918df4fd.png)'
- en: Example prompt that uses all structural components, indicators are bolded for
    visibility (created by author)
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 使用所有结构组件的示例提示，指示符已加粗以便于查看（由作者创建）
- en: A variety of prompting techniques exist, but each of these techniques utilize
    a (relatively) common structure. The various components of prompts that one might
    encounter are depicted within the figure above and outlined below.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多种提示技术，但这些技术都采用（相对）常见的结构。图中展示了可能遇到的提示的各种组件，并在下文中进行了概述。
- en: '*Input Data*: the input data being processed by the LLM.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输入数据*：LLM正在处理的输入数据。'
- en: '*Exemplars*: input-output examples that demonstrate correctly solving a desired
    problem.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*示例*：演示如何正确解决所需问题的输入输出示例。'
- en: '*Instruction*: a detailed, textual description of the LLM’s expected behavior.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指令*：对LLM期望行为的详细文本描述。'
- en: '*Indicators*: textual tags that are used to organize and structure the different
    components of a prompt.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指示符*：用于组织和结构化提示不同组件的文本标签。'
- en: '*Context*: any extra context that may be useful to provide to the LLM (e.g.,
    chunks of information retrieved from a vector database).'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*上下文*：可能对LLM有用的任何额外上下文（例如，从向量数据库中检索的信息块）。'
- en: Notably, not all of these components are necessary when writing a prompt. Several
    of the techniques explored in this overview will only use a subset of the above
    components, but each of them can be leveraged to provide extra, useful information
    to the LLM when necessary.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，并非所有这些组成部分在编写提示时都是必要的。本概述中探讨的几种技术将只使用上述组件的子集，但每种技术都可以在必要时用来提供额外的有用信息给LLM。
- en: Hierarchy of Prompting Techniques
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示技术的层级
- en: '![](../Images/c19b48e280ef0d331ae859260fe05b63.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c19b48e280ef0d331ae859260fe05b63.png)'
- en: Writing prompts is an iterative process that should start simple and only add
    complexity when needed
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 编写提示是一个迭代过程，应该从简单开始，仅在需要时添加复杂性。
- en: Now that we have a basic understanding of in-context learning and prompt engineering,
    we need to take a deeper dive into some common techniques for prompting a language
    model. We will start with simpler techniques, such as zero and few-shot prompting,
    then move on to more complex techniques like chain of thought prompting [2] and
    self-consistency [3]. As always, we should remember that simplicity is best when
    writing prompts — *we should start as simple as possible, then use test-driven
    development to decide when extra complexity is necessary*. In other words, we
    can create a large benchmark of prompt examples based upon our desired application,
    then measure performance on this benchmark as we iterate and test different prompting
    variants. For a more extensive (and practical) guide on prompting, check out the
    article [here](/practical-prompt-engineering-74e96130abc4).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对上下文学习和提示工程有了基本了解，我们需要深入探讨一些常见的语言模型提示技术。我们将从简单的技术开始，例如零-shot和少-shot提示，然后转向更复杂的技术，如思维链提示
    [2] 和自一致性 [3]。一如既往，我们应该记住编写提示时的最佳方法是简单 — *我们应尽可能从简单开始，然后使用测试驱动开发来决定何时需要额外的复杂性*。换句话说，我们可以基于我们期望的应用创建一个大规模的提示示例基准，然后在我们迭代和测试不同的提示变体时测量在该基准上的表现。有关提示的更全面（和实用）的指南，请查看文章
    [这里](/practical-prompt-engineering-74e96130abc4)。
- en: Zero and Few-Shot Prompting
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零-shot和少-shot提示
- en: '![](../Images/435484d0ebb6e733be1ce6e4f10b9c4a.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/435484d0ebb6e733be1ce6e4f10b9c4a.png)'
- en: (from [5])
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [5]）
- en: '**Zero-shot prompting** is one of the simplest techniques that we can use for
    prompting a language model and originally became popular when leveraged by GPT-2
    to achieve impressive performance across a wide variety of different natural language
    benchmarks. To form a zero-shot prompt, we need to provide two pieces of information
    (see above):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**零样本提示** 是我们可以用于提示语言模型的最简单技术之一，它最初因 GPT-2 利用这一技术在各种自然语言基准测试中表现出色而广受欢迎。要形成零样本提示，我们需要提供两项信息（见上文）：'
- en: A task description
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任务描述
- en: Our input data
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的输入数据
- en: Here, the language model is expected to leverage its knowledge base and the
    provided task description to solve a problem without any explicit exemplars or
    detailed instructions. Although many language models can perform relatively well
    when prompted in a zero-shot manner, we typically need to provide extra details
    to the model to get more reliable and accurate results.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，语言模型预计利用其知识库和提供的任务描述来解决问题，而无需任何明确的示例或详细指令。尽管许多语言模型在零样本提示下表现相对良好，但我们通常需要向模型提供额外的细节以获得更可靠和准确的结果。
- en: '![](../Images/a076f2b60c041ac46ad4dac743393f24.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a076f2b60c041ac46ad4dac743393f24.png)'
- en: (from [5])
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [5])
- en: '**Few-shot prompting** goes beyond zero-shot prompting by adding “exemplars”
    of the model’s desired output to the prompt; see above. In addition to a task
    description, we provide several examples of correct input-output pairs. By adding
    this context to the prompt, we can provide the language model with more concrete
    details about the output that is expected. This technique was popularized with
    GPT-3 [5], where language models were first shown to be highly capable in-context
    learners. Put simply, the model can learn from these exemplars and improve in
    accuracy as more are provided.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**少样本提示** 通过在提示中添加模型期望输出的“示例”来超越零样本提示；见上文。除了任务描述，我们还提供几个正确的输入输出对的示例。通过将这些上下文添加到提示中，我们可以为语言模型提供更具体的输出细节。这一技术在
    GPT-3 [5] 中得到推广，当时首次显示语言模型在上下文学习方面具有很高的能力。简而言之，模型可以从这些示例中学习，并随着示例的增多提高准确性。'
- en: '![](../Images/70f3003c2bef9561f9f10cdd5e7af031.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70f3003c2bef9561f9f10cdd5e7af031.png)'
- en: (from [5])
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [5])
- en: Instruction Prompting
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指令提示
- en: Zero and few-shot learning are simple techniques that work surprisingly well,
    but sometimes they will not yield sufficient levels of performance. Plus, few-shot
    learning has the added limitation of increasing the size of the prompt. If these
    techniques are not working for our use case, the next technique we can try is
    instruction prompting. Instead of demonstrating correct behavior via a task description
    and several examples of correct output, instruction prompting includes a detailed
    instruction — *or explanation of the correct behavior* — within the prompt that
    is given to the language model; see below.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 零样本和少样本学习是效果惊人的简单技术，但有时它们不会产生足够的性能水平。而且，少样本学习还增加了提示的大小。如果这些技术不适用于我们的用例，我们可以尝试的下一种技术是指令提示。指令提示与其包含任务描述和几个正确输出示例不同，它在提示中包含详细的指令
    —— *或对正确行为的解释* —— 并将其提供给语言模型；见下文。
- en: '![](../Images/5c767c1403ef488e5b031cab7a6278fd.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c767c1403ef488e5b031cab7a6278fd.png)'
- en: Examples of instruction prompts with indicators (created by author)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 带有指示器的指令提示示例（由作者创建）
- en: Plus, instruction prompting and few-shot prompting are not mutually exclusive!
    We can easily combine an instruction prompt with several few-shot exemplars to
    yield improved performance. In fact, the task descriptions used by zero and few-shot
    prompting techniques are actually quite similar to an instruction anyways.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 而且，指令提示和少样本提示并非相互排斥！我们可以轻松将指令提示与几个少样本示例结合，以提高性能。实际上，零样本和少样本提示技术使用的任务描述实际上与指令本身非常相似。
- en: '![](../Images/fcb8e86ff879e44dbe1001f914783ddc.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcb8e86ff879e44dbe1001f914783ddc.png)'
- en: (from [6])
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [6])
- en: '**Alignment is necessary.** Crafting thoughtful instructions is a highly effective
    and token-efficient prompting technique. However, not all language models are
    good instruction followers. For example, pre-trained (base) LLMs do not naturally
    have the ability to follow detailed instructions. This ability is typically developed
    via an alignment process that fine-tunes the LLM’s ability to follow instructions;
    see above. Many modern LLMs (e.g., GPT-4) are incredibly steerable (i.e., adept
    at following detailed instructions), making instruction prompting one of the most
    effective techniques for working with such models, as shown below.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**对齐是必要的。** 制定深思熟虑的指令是一种非常有效且令牌高效的提示技术。然而，并非所有语言模型都擅长遵循指令。例如，预训练的（基础）LLM 本身并不具备自然跟随详细指令的能力。这种能力通常通过对齐过程来发展，对齐过程微调了
    LLM 跟随指令的能力；见上文。许多现代 LLM（如 GPT-4）非常可引导（即擅长跟随详细指令），使得指令提示成为与这些模型合作的最有效技术之一，如下所示。'
- en: '![](../Images/2ea6b795c5f8b1dbcc7dbb29511be0dd.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ea6b795c5f8b1dbcc7dbb29511be0dd.png)'
- en: GPT-4 is steerable and can easily follow complex instructions within a prompt
    (created by author)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 是可引导的，并且可以轻松跟随提示中的复杂指令（由作者创建）
- en: Advanced Prompting Techniques
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级提示技术
- en: Sometimes, few-shot and instruction prompting are not enough to accomplish a
    desired task. In particular, language models tend to struggle with complex reasoning
    problems, such as commonsense reasoning problems that require multiple steps or
    mathematical puzzles. However, numerous advanced prompting techniques — *including
    tree of thoughts prompting* — have been developed to expand the scope of difficult
    problems that can be solved with an LLM. In this section, we will focus on one
    technique — chain of thought (CoT) prompting [2] (and its several variants) —
    that is especially effective in practice and forms the basis of the methodology
    used for tree of thoughts prompting.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，少量提示和指令提示不足以完成期望的任务。特别是，语言模型往往在处理复杂推理问题时表现不佳，例如需要多个步骤的常识推理问题或数学难题。然而，已经开发了众多高级提示技术——*包括思维树提示*——以扩展可以用
    LLM 解决的困难问题的范围。在本节中，我们将重点介绍一种技术——思维链（CoT）提示 [2]（及其几种变体）——这种技术在实践中特别有效，并形成了思维树提示方法的基础。
- en: '![](../Images/2331d9c97643ed9e9f81bcc4b9f6f225.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2331d9c97643ed9e9f81bcc4b9f6f225.png)'
- en: (from [2])
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于 [2])
- en: '**What is CoT prompting?** By leveraging in-context learning abilities, CoT
    prompting encourages a language model to more effectively solve complex problems
    by outputting along with its solution a corresponding “chain of thought” (i.e.,
    a step-by-step explanation for how the problem was solved). The model can be prompted
    to generate a chain of thought via a few-shot learning approach that provides
    several chain of thought exemplars; see above. The CoT technique is most effective
    when the map from input to output is highly non-trivial; e.g., math or multi-step
    reasoning problems. In such cases, introducing a chain of thought allows the model
    to follow smaller, intermediate steps towards the correct final solution. In practice,
    CoT prompting was found to drastically improve LLM performance on various styles
    of reasoning tasks; see below.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是 CoT 提示？** 通过利用上下文学习能力，CoT 提示鼓励语言模型通过输出解决方案及相应的“思维链”（即问题解决的逐步解释）来更有效地解决复杂问题。可以通过几-shot
    学习方法提供几个思维链示例来提示模型生成思维链；见上文。CoT 技术在输入到输出的映射非常复杂时效果最佳；例如数学或多步骤推理问题。在这种情况下，引入思维链允许模型沿着更小的中间步骤接近正确的最终解决方案。在实践中，发现
    CoT 提示在各种推理任务中的 LLM 性能显著提升；见下文。'
- en: '![](../Images/0eddb5bfece671d7753dff40fb4d7e85.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0eddb5bfece671d7753dff40fb4d7e85.png)'
- en: (from [2])
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于 [2])
- en: '**Variants of CoT prompting.** Given the practical utility of CoT prompting
    (i.e., it can be used to solve complex, multi-step problems with which LLMs typically
    struggle!), several variants of this technique were developed shortly after its
    proposal, such as zero-shot CoT [7] and least-to-most prompting [8]; see below.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**CoT 提示的变体。** 鉴于 CoT 提示的实际效用（即，它可以用来解决 LLM 通常难以应对的复杂多步骤问题！），在其提出后不久，开发了几种变体，例如零-shot
    CoT [7] 和从少到多提示 [8]；见下文。'
- en: '![](../Images/073813a7f951995847770b84c4e187f3.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/073813a7f951995847770b84c4e187f3.png)'
- en: (from [7, 8])
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: (来源于 [7, 8])
- en: The CoT prompting variant that is most relevant to tree of thought prompting
    is self-consistency [3]. This approach leverages an approach that is similar to
    that of CoT prompting. A single model is prompted — using the same (CoT) prompt
    — to generate output several different times. Then, the final answer is generated
    by taking a majority vote of the model’s outputs as shown in the figure below.
    Such an approach is found to yield similar benefits to CoT prompting, as well
    as improve performance and reliability on more difficult problems.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 与思维树提示最相关的 CoT 提示变体是自一致性 [3]。这种方法利用了类似于 CoT 提示的方法。一个模型使用相同的（CoT）提示多次生成输出。然后，通过对模型输出进行多数投票来生成最终答案，如下图所示。这种方法被发现与
    CoT 提示具有类似的好处，并且在更困难的问题上提高了性能和可靠性。
- en: '![](../Images/91c2fff87b46d260ed2ead99e193a8ed.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91c2fff87b46d260ed2ead99e193a8ed.png)'
- en: (from [3])
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [3]）
- en: '**Existing limitations.** Techniques like CoT prompting and self-consistency
    do a lot to expand the scope of problems that are solvable with LLMs. Without
    them, solving multi-step reasoning problems would be quite difficult. However,
    these prompting techniques do not come without limitations. For example, not all
    problems have a solution space that is amenable to a majority vote, and a majority
    vote has been shown in prior work to be a poor heuristic for improving LLM accuracy
    even for problems that can be formulated in this manner.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**现有的限制。** 技术如 CoT 提示和自一致性大大扩展了可用 LLM 解决的问题范围。如果没有这些技术，解决多步骤推理问题将会非常困难。然而，这些提示技术并非没有局限性。例如，并非所有问题都有适合多数投票的解空间，而且已有研究表明，即使对于可以以这种方式表述的问题，多数投票也被证明是改善
    LLM 准确性的一个糟糕启发式方法。'
- en: “We see 9.5% average variation in accuracy and that the Jaccard index over errors
    is 69% higher than if prompt errors were i.i.d. Majority vote (MV) is the primary
    unsupervised aggregation strategy in prior work but it does not account for either
    property, making it unreliable.” *— from [9]*
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我们观察到准确率的平均变化为 9.5%，且误差的 Jaccard 指数比如果提示误差是 i.i.d. 的情况高出 69%。多数投票（MV）是先前工作中的主要无监督聚合策略，但它没有考虑到这两个特性，使其不可靠。”
    *— 来源 [9]*
- en: More broadly, solving a complex task may require extensive planning, strategic
    lookahead, backtracking, and even exploration of numerous viable solutions in
    parallel. Techniques like CoT prompting follow a left-to-right, continuous generation
    approach that uses next-token prediction to output a solution in a single attempt.
    Such an approach, although highly effective in certain scenarios, fails to solve
    tasks that require strategic planning and exploration. But, this is where tree
    of thoughts prompting comes in! Similar to CoT prompting, tree of thoughts prompting
    breaks problems down into smaller parts (i.e., a chain of thought) but goes further
    by combining this with the ability to explore multiple solution paths in parallel,
    forming a tree instead of a single chain!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 更广泛地说，解决复杂任务可能需要广泛的规划、战略前瞻、回溯，甚至同时探索大量可行的解决方案。技术如 CoT 提示遵循从左到右的连续生成方法，利用下一个标记预测一次性输出解决方案。这种方法虽然在某些场景下非常有效，但无法解决需要战略规划和探索的任务。但是，这正是思维树提示派上用场的地方！与
    CoT 提示类似，思维树提示将问题分解为更小的部分（即思维链），但进一步结合了并行探索多条解决路径的能力，形成一个树而不是单一链条！
- en: Understanding Tree of Thoughts Prompting
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解思维树提示
- en: '![](../Images/519177305d31cc997885b41e641585b4.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/519177305d31cc997885b41e641585b4.png)'
- en: (from [1])
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [1]）
- en: 'The effectiveness of CoT prompting comes from its ability to break a complex
    problem solution into a sequence of smaller and simpler steps. Tree of thoughts
    (ToT) prompting similarly breaks a problem into a sequence of smaller steps —
    or *thoughts* — that are solved individually. However, the approach does not constrain
    the model to output these steps all at once. Rather, each thought is generated
    or solved independently and passed to the next step for solving the problem, which
    allows the model to:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: CoT 提示的有效性来自于将复杂问题的解决方案拆分成一系列更小、更简单步骤的能力。思维树（ToT）提示类似地将问题拆分成一系列更小的步骤——或*思路*——逐一解决。然而，这种方法并不限制模型一次性输出这些步骤。相反，每个思路是独立生成或解决的，并传递到下一步骤来解决问题，这使得模型能够：
- en: Explore multiple choices for each problem-solving thought.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索每个问题解决思路的多种选择。
- en: Evaluate whether certain thoughts bring the model closer to a final solution.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估某些思路是否使模型更接近最终解决方案。
- en: Perform backtracking when certain thoughts are found to be a dead end.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当某些思维被发现是死胡同时进行回溯。
- en: Search over a combinatorial space of possible problem-solving steps to find
    the best final solution.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在可能的问题解决步骤的组合空间中进行搜索，以找到最佳的最终解决方案。
- en: With ToT prompting, an entire tree of thoughts (shown above) is formed by allowing
    exploration of different thoughts throughout the problem-solving process. During
    exploration, the LLM can evaluate progress made by each thought towards a final
    solution via a language-based process. Then, by leveraging widely-used search
    algorithms (e.g., [breadth-first search or depth-first search](https://www.geeksforgeeks.org/difference-between-bfs-and-dfs/)),
    ToT prompting can be augmented with lookahead and backtracking techniques, allowing
    the solution space of any problem to be thoroughly explored.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通过ToT提示，可以形成整个思维树（如上图所示），允许在解决问题的过程中探索不同的思维。在探索过程中，LLM可以通过基于语言的过程评估每个思维在最终解决方案中的进展。然后，通过利用广泛使用的搜索算法（例如，[广度优先搜索或深度优先搜索](https://www.geeksforgeeks.org/difference-between-bfs-and-dfs/)），ToT提示可以增强前瞻性和回溯技术，从而彻底探索任何问题的解决空间。
- en: “While existing methods sample continuous language sequences for problem solving,
    ToT actively maintains a tree of thoughts, where each thought is a coherent language
    sequence that serves as an intermediate step toward problem solving.” *— from
    [1]*
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “虽然现有方法为问题解决采样连续的语言序列，但ToT主动维护一棵思维树，其中每个思维是一个连贯的语言序列，作为问题解决的中间步骤。” *— 引自 [1]*
- en: '![](../Images/e7e16e5564811b23a3c33bbbe8ab4fbd.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e7e16e5564811b23a3c33bbbe8ab4fbd.png)'
- en: (from [1])
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: （引自 [1]）
- en: '**What does the tree represent?** When using ToT prompting, we explore several
    *paths* — each comprised of individual *thoughts* — that represent potential solutions
    to a problem. Together, each of these paths and their individual thoughts form
    a tree that explores a problem’s solution space; see above. In this tree, each
    node is simply a partial solution (or thought) to our problem, while each connection
    is a operator that modifies this partial solution to yield the next thought within
    a problem-solving path. An example of decomposing a problem-solving chain of thought
    (i.e., a single path in a tree of thoughts) in this way is shown below.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**树代表什么？** 使用ToT提示时，我们探索几个*路径*——每条路径由单独的*思维*组成——这些路径代表问题的潜在解决方案。所有这些路径及其单独的思维共同形成了一棵树，探索问题的解决空间；见上文。在这棵树中，每个节点只是我们问题的部分解决方案（或思维），而每个连接是一个操作符，它修改这个部分解决方案，产生问题解决路径中的下一个思维。下面展示了如何以这种方式分解问题解决思维链（即思维树中的单条路径）的示例。'
- en: '![](../Images/785585ad1e86b1c2a3e4c85c34ed7f0c.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/785585ad1e86b1c2a3e4c85c34ed7f0c.png)'
- en: Using operators to iteratively modify a partial solution until a final solution
    is found (from [2])
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用操作符迭代修改部分解决方案，直到找到最终解决方案（引自 [2]）
- en: Tree of Thoughts Problem Solving Framework
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维树问题解决框架
- en: At this point, we have talked about the generic idea behind ToT prompting, but
    *how do we use this technique in a practical application*? The implementation
    of ToT prompting looks a bit different depending upon the problem we are trying
    to solve, but any instantiation of ToT prompting has to concretely define four
    standard problem-solving components, which are outlined below.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了ToT提示的通用理念，但*我们如何在实际应用中使用这种技术*？ToT提示的实现因我们要解决的问题而有所不同，但任何ToT提示的实例必须具体定义四个标准问题解决组件，如下所述。
- en: '![](../Images/3fab7b46ecb54f3ac9463963e8c15e16.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fab7b46ecb54f3ac9463963e8c15e16.png)'
- en: (from [1])
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: （引自 [1]）
- en: '**Thought decomposition.** Unlike CoT prompting, ToT explicitly decomposes
    a problem into intermediate steps or thoughts, which are combined together to
    form a solution to the underlying problem. Depending on the problem, this decomposition
    can take a variety of different forms, such as outputting a few words or a single
    line of an equation. As shown above, the definition of a thought is different
    for each of the three separate tasks that are considered in [1].'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**思维分解。** 与CoT提示不同，ToT明确将问题分解为中间步骤或思维，这些思维组合在一起形成对基础问题的解决方案。根据问题的不同，这种分解可以采取各种不同的形式，例如输出几个词或一行方程式。如上图所示，每个任务中的思维定义在
    [1] 中有所不同。'
- en: “A thought should be small enough so that LMs can generate promising and diverse
    samples (e.g. generating a whole book is usually too big to be coherent), yet
    big enough so that LMs can evaluate its prospect toward problem solving (e.g.
    generating one token is usually too small to evaluate).” *— from [1]*
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “一个思想应该足够小，以便 LMs 可以生成有前途和多样的样本（例如，生成整本书通常太大而无法连贯），但也要足够大，以便 LMs 可以评估其解决问题的前景（例如，生成一个标记通常太小而无法评估）。"*
    — 来自 [1]*
- en: '**Thought generation.** Once we have decided what will constitute a thought,
    we need to determine how thoughts should be generated during ToT prompting. In
    [1], authors propose two basic techniques for thought generation:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**思想生成。** 一旦我们决定了什么构成一个思想，我们需要确定在 ToT 提示过程中如何生成思想。在 [1] 中，作者提出了两种基本的思想生成技术：'
- en: '*Sampling*: generating several thoughts independently with the same prompt'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*采样*：用相同的提示独立生成多个思想'
- en: '*Proposing*: generating several thoughts sequentially with a “propose prompt”'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提议*：用“提议提示”顺序生成多个思想'
- en: The sampling approach works best when the thought space is rich, as several
    independently-generated thoughts are unlikely to be duplicates. If the thought
    space is more constrained, then the proposing technique can be used to generate
    several thoughts while avoiding duplicates.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 采样方法在思想空间丰富时效果最好，因为几种独立生成的思想不太可能重复。如果思想空间更加受限，那么可以使用提议技术生成多个思想，同时避免重复。
- en: '**State evaluation.** Once we have defined our thoughts and chosen how they
    will be generated, we need to define a heuristic for evaluating the quality of
    certain chains of thought. Otherwise, there is no way to know whether we are making
    progress towards a final solution. Given several thoughts that have been generated,
    authors in [1] use an LLM to reason about the quality of each thought. In particular,
    two different strategies are followed:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**状态评估。** 一旦我们定义了我们的思想并选择了它们的生成方式，我们需要定义一种启发式方法来评估某些思路链的质量。否则，我们无法知道是否在朝着最终解决方案取得进展。给定几个已生成的思想，[1]
    中的作者使用 LLM 来推理每个思想的质量。特别地，遵循两种不同的策略：'
- en: '*Value*: independently assign a scalar value (i.e., rating from 1–10) or classification
    (i.e., sure, likely, or impossible to reach a solution) to each state.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*价值*：独立地给每种状态分配一个标量值（即，1–10 的评分）或分类（即，确定、可能或不可能达成解决方案）。'
- en: '*Vote*: compare different solutions and select the one that is most promising.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*投票*：比较不同的解决方案，并选择最有前景的一个。'
- en: Although both approaches can work well, voting is best when a successful solution
    to a problem is hard to directly value (e.g., creative writing tasks). In both
    cases, the LLM can be prompted multiple times in a manner similar to self-consistency
    to achieve more reliable evaluations of each state.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这两种方法都可以很好地工作，但当一个问题的成功解决方案难以直接评估时（例如创意写作任务），投票是最好的选择。在这两种情况下，可以多次提示 LLM，类似于自一致性，以实现对每种状态的更可靠评估。
- en: '![](../Images/b24037b39c9f46511ff770ec66e4b964.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b24037b39c9f46511ff770ec66e4b964.png)'
- en: (from [1])
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: '**Search algorithm.** The final component of ToT prompting is the search algorithm
    that is used to explore the solution space. Although many potential search algorithms
    can be used, we see in [1] that authors focus on two basic algorithms — *BFS and
    DFS* — with formulations shown above.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**搜索算法。** ToT 提示的最终组件是用于探索解决方案空间的搜索算法。尽管可以使用许多潜在的搜索算法，但我们在 [1] 中看到，作者专注于两种基本算法
    — *BFS 和 DFS* — 其公式如上所示。'
- en: Experimental Analysis
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验分析
- en: 'Authors in [1] propose three new tasks that are used to evaluate the ToT prompting
    technique: Game of 24, Creative Writing, and 5x5 Crosswords. For each of these
    tasks, we will first overview the implementation of ToT prompting, which follows
    the four-part framework outlined above. Then, we will outline the experimental
    results, highlighting the effectiveness of ToT prompting on problems that require
    extensive planning or search. Notably, alternatives like CoT prompting and self-consistency
    tend to fall short of solving such complex tasks.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 中的作者提出了三项新任务，用于评估 ToT 提示技术：24 游戏、创意写作和 5x5 填字游戏。对于每个任务，我们将首先概述 ToT 提示的实施，这遵循上述的四部分框架。然后，我们将概述实验结果，突出
    ToT 提示在需要大量规划或搜索的问题上的有效性。值得注意的是，像 CoT 提示和自一致性这样的替代方法往往无法解决这些复杂任务。'
- en: Game of 24
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 24 游戏
- en: '![](../Images/cc57f162b707e737bab167289b4f1f25.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc57f162b707e737bab167289b4f1f25.png)'
- en: (from [1])
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [1]）
- en: The implementation of ToT prompting for the Game of 24 task is shown above.
    In this task, the LLM is given four numbers and expected to generate a sequence
    of arithmetic operations — *where each number is only used once* — that result
    in the number 24\. This task is always decomposed into three thoughts, each of
    which is an intermediate equation. The same prompt is used to generate each of
    the three thoughts in a candidate solution, and we evaluate states with a value
    prompt that classifies intermediate solutions as *sure*, *likely*, or *impossible*
    to reach a correct final solution. Then, a BFS algorithm is applied to find the
    resulting solution, keeping the best five (i.e., `b=5`) candidate solutions at
    each step.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 上述展示了 ToT 提示在 24 游戏任务中的实现。在此任务中，LLM 给定四个数字，并期望生成一系列算术运算——*每个数字只使用一次*——以得到数字
    24。此任务始终被分解为三个思考，每个思考都是一个中间方程。相同的提示用于生成候选解决方案中的每三个思考，并通过一个值提示来评估状态，该提示将中间解决方案分类为
    *确定*、*可能* 或 *不可能* 得到正确的最终解决方案。然后，应用 BFS 算法来寻找结果解决方案，在每一步保持最好的五个（即 `b=5`）候选解决方案。
- en: '![](../Images/9c8f0c99abbe8cb4098c9c09c6ca108f.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c8f0c99abbe8cb4098c9c09c6ca108f.png)'
- en: (from [1])
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [1]）
- en: '**Performance.** ToT prompting is compared to several baselines, including
    standard few-shot prompting (IO), CoT prompting, and CoT-based self-consistency
    (CoT-SC). As shown above, all baselines perform quite poorly on this task (i.e.,
    <10% success rate), while ToT prompting achieves up to a 74% success rate. Interestingly,
    the success rate improves with higher settings of `b` for BFS. Furthermore, we
    see based on error analysis in [1] that most solutions with CoT prompting fail
    after the first step, while failures with ToT prompting are distributed uniformly
    among intermediate steps. Such a finding demonstrates the benefit of ToT prompting,
    as it can evaluate intermediate states prior to producing a final output, allowing
    multiple viable solution paths to be explored.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能。** ToT 提示与几种基线方法进行了比较，包括标准的少量示例提示（IO）、CoT 提示和基于 CoT 的自一致性（CoT-SC）。如上所示，所有基线方法在此任务中的表现都相当差（即成功率<10%），而
    ToT 提示的成功率高达74%。有趣的是，随着 BFS 的 `b` 设置值增加，成功率也有所提高。此外，基于 [1] 中的错误分析，我们发现大多数使用 CoT
    提示的解决方案在第一步之后失败，而 ToT 提示的失败则均匀分布在各个中间步骤之间。这一发现表明 ToT 提示的好处，因为它可以在生成最终输出之前评估中间状态，从而允许探索多个可行的解决路径。'
- en: Creative Writing
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创意写作
- en: '![](../Images/7d7c5194629bc530ab8ad2a5f1874f93.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7d7c5194629bc530ab8ad2a5f1874f93.png)'
- en: (from [1])
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [1]）
- en: The creative writing task explored in [1] provides four random sentences as
    input to the LLM and expects a passage containing four paragraphs that each end
    in the four input sentences to be outputted. The quality of outputs is judged
    either using GPT-4 (with a zero-shot prompt) or human evaluations. For this task,
    ToT prompting requires two intermediate thoughts. First, the LLM generates five
    different writing plans and uses a zero-shot voting prompt to select the best
    one. Then, five different passages are generated based upon the selected plan,
    and the best passage is identified by using (again) a zero-shot voting prompt;
    see above.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 中探讨的创意写作任务提供了四个随机句子作为输入，并期望生成包含四个段落的文章，每个段落以这四个输入句子结尾。输出质量通过 GPT-4（使用零-shot
    提示）或人工评估来判断。在此任务中，ToT 提示需要两个中间思考。首先，LLM 生成五个不同的写作计划，并使用零-shot 投票提示选择最佳计划。然后，根据选定的计划生成五个不同的段落，并通过（再次）零-shot
    投票提示确定最佳段落；见上文。'
- en: '![](../Images/4b96d87d0267897eeb3df7c2f5eee708.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b96d87d0267897eeb3df7c2f5eee708.png)'
- en: (from [1])
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [1]）
- en: '**Performance.** As shown in the figure above, ToT generates more coherent
    passages than few-shot and CoT prompting on average, as judged by both GPT-4 and
    human evaluators. When an iterative refinement procedure is applied to improve
    result quality, we see that both few-shot and ToT prompting perform comparably.
    Such a procedure can be thought of as a new approach to thought generation, where
    new thoughts are generated by prompting the LLM to refine old thoughts instead
    of generating them from scratch.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能。** 如上图所示，ToT 提示生成的段落比少量示例和 CoT 提示的段落更连贯，这一点得到了 GPT-4 和人工评估者的共同判断。当应用迭代改进程序以提高结果质量时，我们发现少量示例提示和
    ToT 提示的表现相当。这种程序可以被视为一种新的思考生成方法，其中通过提示 LLM 来改进旧思考，而不是从头生成新思考。'
- en: 5x5 Crosswords
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5x5 填字游戏
- en: '![](../Images/347ab512c387af4731adee5c06dc9d46.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/347ab512c387af4731adee5c06dc9d46.png)'
- en: (from [1])
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: （摘自 [1]）
- en: The final task considered in [1] is a mini crossword puzzle, which explores
    the ability of ToT prompting to discover solutions to problems that require a
    greater number of intermediate steps. The input for this task provides five horizontal
    clues and five vertical clues, while the output should be a 5x5 grid of letters
    that solve the crossword puzzle. Success is judged based upon the portion of correct
    letters, words, and games achieved by each prompting technique.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]中考虑的最终任务是一个迷你填字游戏，旨在探索 ToT 提示发现需要更多中间步骤的问题的能力。该任务的输入提供了五个水平提示和五个垂直提示，而输出应该是一个5x5字母网格，以解决填字谜题。成功是根据每种提示技术在字母、单词和游戏方面的正确程度来判断的。'
- en: '**ToT setup.** For mini crossword, ToT prompting is implemented with DFS. Each
    thought considers a single word clue. Thoughts are generated sequentially and
    cannot change any currently-filled words or letters. To find new candidates, the
    LLM takes all existing thoughts as input, generates letter constraints for remaining
    word clues based on these thoughts, and uses a proposal prompt to come up with
    candidates for the word should be filled next and where it should go. Interestingly,
    the LLM is also prompted to provide a confidence level for each thought, allowing
    thoughts to be explored in order of confidence. Intermediate states are evaluated
    based upon whether it is possible to arrive at a viable final solution. If not,
    DFS backtracks to the parent node within the tree of thoughts and continues to
    explore. This entire process is depicted in the figure above.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**ToT 设置。** 对于迷你填字游戏，ToT 提示使用深度优先搜索（DFS）进行实现。每个思路都考虑单个单词提示。思路是按顺序生成的，并且不能改变任何当前已填写的单词或字母。为了找到新的候选答案，LLM
    将所有现有的思路作为输入，根据这些思路生成剩余单词提示的字母约束，并使用提议提示来提出下一个应填写的单词及其位置。值得注意的是，LLM 还会被提示为每个思路提供一个置信度级别，从而可以按照置信度的顺序探索思路。中间状态的评估基于是否可以得到一个可行的最终解决方案。如果不能，DFS
    将回溯到思路树中的父节点并继续探索。整个过程如上图所示。'
- en: '![](../Images/d179f028083002abade74d578fe1588f.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d179f028083002abade74d578fe1588f.png)'
- en: (from [1])
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[1]）
- en: '**Performance.** As shown in the table above, ToT prompting drastically outperforms
    few-shot and CoT prompting in terms of success rate on the mini crosswords benchmark.
    Even still, ToT prompting only globally solves 4 out of 20 total puzzles that
    were tested, revealing that there is significant room for improvement on such
    tasks. However, the ability of ToT prompting to backtrack and explore different
    solutions via DFS is a massive differentiator.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**性能。** 如上表所示，ToT 提示在迷你填字游戏基准测试中的成功率远远优于少量样本和 CoT 提示。即便如此，ToT 提示只在测试的20个谜题中全球解决了4个，显示出在此类任务上仍有很大的改进空间。然而，ToT
    提示通过 DFS 回溯和探索不同解决方案的能力是一个巨大的区分因素。'
- en: “Such an improvement is not surprising, given IO and CoT lack mechanisms to
    try different clues, make changes to decisions, or backtrack.” *— from [1]*
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “这种改进并不令人惊讶，因为 IO 和 CoT 缺乏尝试不同提示、修改决策或回溯的机制。”*— 来自 [1]*
- en: Closing Remarks
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束语
- en: Recent research on prompting techniques has drastically expanded the scope of
    problems that are solvable via an LLM. However, most prompting techniques are
    constrained by the autoregressive nature of language generation — *they tend to
    follow a left-to-right approach that lacks deliberate planning and opportunities
    for exploring alternative solutions to a problem*. ToT prompting solves this issue
    by abstracting the solution to a problem as a tree of intermediate steps that
    can be independently explored and evaluated using known algorithms and heuristics.
    The idea behind ToT prompting is incredibly generic and can be instantiated differently
    depending on the underlying problem. We see several examples of this in [1], where
    ToT prompting is shown to more effectively solve multi-step reasoning problems
    compared to CoT prompting and related variants.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最近关于提示技术的研究大大扩展了通过 LLM 可解决的问题范围。然而，大多数提示技术受到语言生成的自回归性质的限制——*它们倾向于遵循从左到右的方法，缺乏深思熟虑的规划和探索问题替代解决方案的机会*。ToT
    提示通过将问题的解决方案抽象为一个可以使用已知算法和启发式方法独立探索和评估的中间步骤树来解决这个问题。ToT 提示的理念非常通用，可以根据底层问题进行不同的实例化。在[1]中，我们可以看到若干示例，其中
    ToT 提示被证明比 CoT 提示及相关变体更有效地解决了多步骤推理问题。
- en: Connect with me!
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与我联系！
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. If you liked this overview, subscribe
    to my [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/),
    where I help readers understand AI research via overviews of relevant topics from
    the ground up. You can also follow me on [X](https://twitter.com/cwolferesearch)
    and [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/), or
    check out my [other writings](https://medium.com/@wolfecameron) on medium!
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢阅读本文。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/)
    的 AI 总监。我研究深度学习的实证和理论基础。如果你喜欢这个概述，可以订阅我的 [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/)，我在这里帮助读者从基础开始理解
    AI 研究。你也可以在 [X](https://twitter.com/cwolferesearch) 和 [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/)
    上关注我，或者查看我在 medium 上的 [其他文章](https://medium.com/@wolfecameron)！
- en: Bibliography
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Yao, Shunyu, et al. “Tree of thoughts: Deliberate problem solving with
    large language models.” *arXiv preprint arXiv:2305.10601* (2023).'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Yao, Shunyu, et al. “思想树：与大型语言模型进行深思熟虑的问题解决。” *arXiv 预印本 arXiv:2305.10601*
    (2023)。'
- en: '[2] Wei, Jason, et al. “Chain-of-thought prompting elicits reasoning in large
    language models.” *Advances in Neural Information Processing Systems* 35 (2022):
    24824–24837.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Wei, Jason, et al. “思维链提示引发大型语言模型中的推理。” *神经信息处理系统进展* 35 (2022): 24824–24837。'
- en: '[3] Wang, Xuezhi, et al. “Self-consistency improves chain of thought reasoning
    in language models.” *arXiv preprint arXiv:2203.11171* (2022).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Wang, Xuezhi, et al. “自洽性改善了语言模型中的思维链推理。” *arXiv 预印本 arXiv:2203.11171*
    (2022)。'
- en: '[4]Radford, Alec, et al. “Language Models are Unsupervised Multitask Learners.”'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Radford, Alec, et al. “语言模型是无监督的多任务学习者。”'
- en: '[5] Brown, Tom, et al. “Language models are few-shot learners.” *Advances in
    neural information processing systems* 33 (2020): 1877–1901.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Brown, Tom, et al. “语言模型是少样本学习者。” *神经信息处理系统进展* 33 (2020): 1877–1901。'
- en: '[6] Ouyang, Long, et al. “Training language models to follow instructions with
    human feedback.” *Advances in Neural Information Processing Systems* 35 (2022):
    27730–27744.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Ouyang, Long, et al. “通过人类反馈训练语言模型以遵循指令。” *神经信息处理系统进展* 35 (2022): 27730–27744。'
- en: '[7] Kojima, Takeshi, et al. “Large language models are zero-shot reasoners.”
    *Advances in neural information processing systems* 35 (2022): 22199–22213.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Kojima, Takeshi, et al. “大型语言模型是零样本推理者。” *神经信息处理系统进展* 35 (2022): 22199–22213。'
- en: '[8] Zhou, Denny, et al. “Least-to-most prompting enables complex reasoning
    in large language models.” *arXiv preprint arXiv:2205.10625* (2022).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Zhou, Denny, et al. “从少到多的提示使大型语言模型能够进行复杂推理。” *arXiv 预印本 arXiv:2205.10625*
    (2022)。'
- en: '[9] Arora, Simran, et al. “Ask me anything: A simple strategy for prompting
    language models.” *arXiv preprint arXiv:2210.02441* (2022).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Arora, Simran, et al. “问我任何事：一种简单的语言模型提示策略。” *arXiv 预印本 arXiv:2210.02441*
    (2022)。'
- en: '[10] Raffel, Colin, et al. “Exploring the limits of transfer learning with
    a unified text-to-text transformer.” *The Journal of Machine Learning Research*
    21.1 (2020): 5485–5551.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Raffel, Colin, et al. “探索统一文本到文本变换器的迁移学习极限。” *机器学习研究期刊* 21.1 (2020): 5485–5551。'
- en: '[11] Saravia, Elvis, et al. “Prompt Engineering Guide”, [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
    (2022).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] Saravia, Elvis, et al. “提示工程指南”， [https://github.com/dair-ai/Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)
    (2022)。'
- en: '[12] A. Newell, J. C. Shaw, and H. A. Simon. Report on a general problem solving
    program. In IFIP congress, volume 256, page 64\. Pittsburgh, PA, 1959.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] A. Newell, J. C. Shaw, and H. A. Simon. 关于一般问题解决程序的报告。在 IFIP 会议，卷 256，第
    64 页。宾夕法尼亚州匹兹堡，1959。'
- en: '[13] A. Newell, H. A. Simon, et al. Human problem solving. Prentice-Hall, 1972.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] A. Newell, H. A. Simon, et al. 人类问题解决。普伦蒂斯-霍尔，1972。'
