- en: How Much Forecasting Performance Do You Lose During Model Selection?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在模型选择过程中，你会损失多少预测性能？
- en: 原文：[https://towardsdatascience.com/how-much-forecasting-performance-do-you-lose-during-model-selection-923889e2f2dc](https://towardsdatascience.com/how-much-forecasting-performance-do-you-lose-during-model-selection-923889e2f2dc)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-much-forecasting-performance-do-you-lose-during-model-selection-923889e2f2dc](https://towardsdatascience.com/how-much-forecasting-performance-do-you-lose-during-model-selection-923889e2f2dc)
- en: How often does cross-validation pick the best forecasting model? What happens
    when it doesn’t?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证多频繁地选择最佳预测模型？当它未能选择最佳模型时会发生什么？
- en: '[](https://vcerq.medium.com/?source=post_page-----923889e2f2dc--------------------------------)[![Vitor
    Cerqueira](../Images/9e52f462c6bc20453d3ea273eb52114b.png)](https://vcerq.medium.com/?source=post_page-----923889e2f2dc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----923889e2f2dc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----923889e2f2dc--------------------------------)
    [Vitor Cerqueira](https://vcerq.medium.com/?source=post_page-----923889e2f2dc--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://vcerq.medium.com/?source=post_page-----923889e2f2dc--------------------------------)[![Vitor
    Cerqueira](../Images/9e52f462c6bc20453d3ea273eb52114b.png)](https://vcerq.medium.com/?source=post_page-----923889e2f2dc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----923889e2f2dc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----923889e2f2dc--------------------------------)
    [Vitor Cerqueira](https://vcerq.medium.com/?source=post_page-----923889e2f2dc--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----923889e2f2dc--------------------------------)
    ·5 min read·Jan 6, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----923889e2f2dc--------------------------------)
    ·阅读时间5分钟·2023年1月6日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/39b7e74a9c3a5f831df25ddcdefda989.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39b7e74a9c3a5f831df25ddcdefda989.png)'
- en: Photo by [Héctor J. Rivas](https://unsplash.com/@hjrc33?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Héctor J. Rivas](https://unsplash.com/@hjrc33?utm_source=medium&utm_medium=referral)
    拍摄的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Suppose you have a forecasting problem. You need to select a model to solve
    it. [You may want to test a few alternatives with cross-validation](/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个预测问题。你需要选择一个模型来解决它。[你可能想用交叉验证测试一些替代方案](/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a)。
- en: Have you ever wondered what’s the chance that cross-validation selects the best
    possible model? And, if not, how poorer is the model that is picked?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾想过交叉验证选择到最佳模型的几率有多大？如果没有选择到最佳模型，那么选择到的模型会差多少？
- en: Let’s find out.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们找出答案。
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Cross-validation, for time series or otherwise, solves two problems:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证，无论是时间序列还是其他类型，都解决了两个问题：
- en: '**Performance estimation.** How well is the model going to perform in new data?
    You can use these estimations to assess whether the model can be deployed;'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能估计。** 模型在新数据上的表现如何？你可以使用这些估计来评估模型是否可以部署；'
- en: '**Model Selection.** Use the above estimates to rank a pool of available models.
    For example, different configurations of a learning algorithm for hyper-parameter
    tuning. In this case, you select the model with the best performance estimates.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型选择。** 使用上述估计来对可用模型池进行排名。例如，不同配置的学习算法用于超参数调整。在这种情况下，你选择具有最佳性能估计的模型。'
- en: Wait! Aren’t these two problems the same?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 等等！这两个问题不是一样的吗？
- en: Not really. A given method (say, [TimeSeriesSplits](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html))
    may provide good performance estimates, on average. But it can be poor for ranking
    the available models, thereby poor for model selection.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 并不是完全如此。某个特定方法（例如，[TimeSeriesSplits](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)）可能提供良好的性能估计，平均而言。但在对可用模型进行排名时，它可能表现较差，从而在模型选择上表现不佳。
- en: Example
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 例子
- en: 'Let me give an example. Suppose you want to compare four models: *M1*, *M2*,
    *M3*, and *M4*. These are shown in the x-axis of Figure 1 below.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我举个例子。假设你想比较四个模型：*M1*、*M2*、*M3*和*M4*。它们显示在下面图1的x轴上。
- en: The true test loss of these models is displayed in blue bars. Their ranking
    is *M1* > *M2* > *M3* > *M4*. So, *M1* is the best model because it shows the
    lowest error (say, the mean absolute error).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型的真实测试损失以蓝色条形图显示。它们的排名是*M1* > *M2* > *M3* > *M4*。因此，*M1*是最佳模型，因为它显示了最低的误差（比如说，平均绝对误差）。
- en: Then, two cross-validation methods (*CV1* and *CV2*) are used to estimate the
    error of each model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用两种交叉验证方法（*CV1* 和 *CV2*）来估计每个模型的误差。
- en: '![](../Images/5cfdaa5ac8d9a69c342a8bae8172f02a.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5cfdaa5ac8d9a69c342a8bae8172f02a.png)'
- en: 'Figure 1: The goal of cross-validation is to approximate the true error (blue
    bars). CV1 (light green blue) provides, on average, better estimations than CV2
    (dark green). But CV2 ranks the models perfectly, unlike CV1.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：交叉验证的目标是接近真实误差（蓝色条）。CV1（浅绿色蓝色）平均提供了比CV2（深绿色）更好的估计。但CV2能够完美地排名模型，而CV1则不能。
- en: '*CV1* produces the best estimations (nearest to the true error), on average.
    But, the estimated ranking (*M2* > *M1* > *M4* > *M3*) is different than the actual
    one. It is also worse than the ranking produced by *CV2*.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*CV1* 平均产生最好的估计（最接近真实误差）。但，估计的排名（*M2* > *M1* > *M4* > *M3*）与实际的排名不同。它也比*CV2*产生的排名更差。'
- en: Despite providing worse performance estimates, *CV2* outputs a perfect ranking
    of the models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管提供了较差的性能估计，*CV2* 输出了模型的完美排名。
- en: This example shows that one CV technique can be better for performance estimation
    (*CV1*), but another for model selection (*CV2*).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子表明，一种CV技术可能在性能估计上更好（*CV1*），但另一种在模型选择上更好（*CV2*）。
- en: Performance Loss During Model Selection
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型选择中的性能损失
- en: 'Suppose you’re doing model selection for forecasting. Two questions may come
    to your mind:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在进行预测模型选择。你可能会想到两个问题：
- en: What’s the chance that cross-validation selects the best model? The one that
    will have the best performance in the test set.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交叉验证选择最佳模型的机会有多大？即在测试集上表现最佳的模型。
- en: What happens when it doesn’t? How poorer is the performance of the selected
    model?
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有发生这种情况会怎样？所选模型的表现会差多少？
- en: Testing Different Cross-Validation Approaches
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试不同的交叉验证方法
- en: We can answer these questions by simulating a realistic scenario. First, apply
    cross-validation to select a model using the training data. Then, check how this
    model does in a test set.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过模拟一个现实的场景来回答这些问题。首先，使用训练数据应用交叉验证来选择一个模型。然后，检查这个模型在测试集上的表现。
- en: Let’s do this step-by-step.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步来做。
- en: I prepared 50 different forecasting models. These include different configurations
    of linear models, and decision trees, among others. [The models are trained with
    a supervised learning approach called auto-regression.](/machine-learning-for-forecasting-transformations-and-feature-extraction-bbbea9de0ac2)
    Without going into details, the recent past values are used as explanatory variables.
    The target variables are future observations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我准备了50个不同的预测模型。这些包括不同配置的线性模型、决策树等。 [这些模型使用了一种名为自回归的监督学习方法进行训练。](/machine-learning-for-forecasting-transformations-and-feature-extraction-bbbea9de0ac2)
    不详细说明，最近的过去值被用作解释变量。目标变量是未来的观测值。
- en: Then, I applied several cross-validation techniques to select the best model.
    These include [TimeSeriesSplits](/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a)
    (a.k.a. Time Series Cross-Validation), [MonteCarloCV](https://medium.com/towards-data-science/monte-carlo-cross-validation-for-time-series-ed01c41e2995),
    or [K-fold Cross-validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).
    You can check a description for each method [in a previous article](https://medium.com/@vcerq/9-techniques-for-cross-validating-time-series-data-7828fc3f781d).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我应用了几种交叉验证技术来选择最佳模型。这些包括 [TimeSeriesSplits](/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a)（即时间序列交叉验证）、
    [MonteCarloCV](https://medium.com/towards-data-science/monte-carlo-cross-validation-for-time-series-ed01c41e2995)
    或 [K-fold Cross-validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)。你可以在[之前的文章](https://medium.com/@vcerq/9-techniques-for-cross-validating-time-series-data-7828fc3f781d)中查看每种方法的描述。
- en: I repeated this process for almost 3000 different time series.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我重复了这个过程近3000个不同的时间序列。
- en: Here are the results.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下。
- en: Cross-validation Selection Accuracy
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证选择准确率
- en: The selection accuracy is the percentage of times a cross-validation approach
    picks the best model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 选择准确率是指交叉验证方法选择最佳模型的次数百分比。
- en: '![](../Images/80625c7c26117114b581529f09c3a7de.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80625c7c26117114b581529f09c3a7de.png)'
- en: 'Figure 2: Accuracy of different cross-validation methods for selecting the
    best forecasting model. The description of each method is available [in a previous
    article](https://medium.com/@vcerq/9-techniques-for-cross-validating-time-series-data-7828fc3f781d).
    Image by Author.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：不同交叉验证方法在选择最佳预测模型时的准确度。每种方法的描述请参见[之前的文章](https://medium.com/@vcerq/9-techniques-for-cross-validating-time-series-data-7828fc3f781d)。图像来源于作者。
- en: The scores range from 7% to 10%.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 分数范围从7%到10%。
- en: Sounds low, right? Still, if you were to select a model at random you’d expect
    a 2% accuracy (1 over 50 possible models). So, 7% to 10% is way better than that.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很低对吧？然而，如果你随机选择一个模型，你的期望准确度是2%（50个可能模型中有一个）。因此，7%到10%要好得多。
- en: Yet, all methods will probably fail to select the best model. Then, comes the
    second question.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，所有方法可能都无法选择最佳模型。接下来就是第二个问题。
- en: How good is the selected model?
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择的模型有多好？
- en: To answer this question, we compare the selected model with the model that should
    have been selected.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这个问题，我们将所选模型与应该选择的模型进行比较。
- en: We can measure the percentage difference in error between these two. The difference
    is 0 when the best model is selected by cross-validation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以测量这两个模型之间错误的百分比差异。当交叉验证选择最佳模型时，差异为0。
- en: '![](../Images/a88956776f6c10350d79706e8b67b7bb.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a88956776f6c10350d79706e8b67b7bb.png)'
- en: 'Figure 3: Average percentage difference in error (and respective standard deviation)
    between the selected model and the best possible model. Image by Author.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：所选模型与最佳模型之间的平均百分比误差差异（及其标准差）。图像来源于作者。
- en: Most estimators select a model that performs about 0.3% worse than the best
    possible model, on average. There are some differences here and there. But, by
    and large, different cross-validation methods show similar performance for model
    selection.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数估计器选择的模型比最佳模型平均表现差0.3%。这里有一些差异，但总体而言，不同的交叉验证方法在模型选择上表现相似。
- en: The exception is *Holdout*, which represents [a single split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).
    This corroborates the recommendation I put forth in [a previous article](https://medium.com/towards-data-science/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a).
    Unless the time series is large, carry out many splits if you can.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例外的是*Holdout*，它代表了[单次拆分](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)。这印证了我在[之前的文章](https://medium.com/towards-data-science/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a)中提出的建议。除非时间序列很大，否则如果可以的话，请进行多次拆分。
- en: You can check the full experiments in the [article](https://arxiv.org/pdf/2104.00584.pdf)
    in reference [1]. These can be reproduced using the code available in [my Github](https://github.com/vcerqueira/model_selection_forecasting).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[文章](https://arxiv.org/pdf/2104.00584.pdf)中查看完整实验，这些实验可以通过[我的Github](https://github.com/vcerqueira/model_selection_forecasting)上的代码重现。
- en: Take Aways
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要结论
- en: Model selection is the process of using cross-validation for selecting a model
    from a pool of alternatives;
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型选择是利用交叉验证从多个替代模型中选择一个模型的过程；
- en: With 50 alternative models, cross-validation has a 7%-10% chance of picking
    the best one;
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于50个替代模型，交叉验证有7%-10%的概率选择最佳模型；
- en: When the best model is not picked, the selected model will perform about 0.3–0.35%
    worse, on average;
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当没有选择最佳模型时，所选模型的表现会比最佳模型差0.3–0.35%，平均而言；
- en: Several cross-validation splits are important for better model selection.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个交叉验证拆分对更好的模型选择非常重要。
- en: Thanks for reading and see you in the next story!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，下次故事见！
- en: Related Articles
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关文章
- en: '[4 Things to Do When Applying Cross-Validation with Time Series](https://medium.com/towards-data-science/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[应用时间序列交叉验证时要做的4件事](https://medium.com/towards-data-science/4-things-to-do-when-applying-cross-validation-with-time-series-c6a5674ebf3a)'
- en: '[Monte Carlo Cross-Validation for Time Series](/monte-carlo-cross-validation-for-time-series-ed01c41e2995)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[时间序列的蒙特卡罗交叉验证](/monte-carlo-cross-validation-for-time-series-ed01c41e2995)'
- en: Further Readings
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[1] Cerqueira, Vitor, Luis Torgo, and Carlos Soares. “Model Selection for Time
    Series Forecasting: Empirical Analysis of Different Estimators.” *arXiv preprint
    arXiv:2104.00584* (2021).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Cerqueira, Vitor, Luis Torgo, 和 Carlos Soares. “时间序列预测的模型选择：不同估计器的实证分析。”
    *arXiv预印本 arXiv:2104.00584* (2021)。'
- en: '[2] Arlot, Sylvain, and Alain Celisse. “A survey of cross-validation procedures
    for model selection.” *Statistics surveys* 4 (2010): 40–79.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Arlot, Sylvain 和 Alain Celisse. “模型选择的交叉验证程序综述。” *统计调查* 4 (2010): 40–79.'
