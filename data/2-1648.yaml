- en: Philosophy and Data Science —Thinking deeply about data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哲学与数据科学——深刻思考数据
- en: 原文：[https://towardsdatascience.com/philosophy-and-data-science-thinking-deeply-about-data-f9b3960c9897](https://towardsdatascience.com/philosophy-and-data-science-thinking-deeply-about-data-f9b3960c9897)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/philosophy-and-data-science-thinking-deeply-about-data-f9b3960c9897](https://towardsdatascience.com/philosophy-and-data-science-thinking-deeply-about-data-f9b3960c9897)
- en: 'Part 1 : Determinism'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1部分：决定论
- en: '[](https://medium.com/@jarom.hulet?source=post_page-----f9b3960c9897--------------------------------)[![Jarom
    Hulet](../Images/0fdeb1a2df90cccdd8f2f4b84d5e54eb.png)](https://medium.com/@jarom.hulet?source=post_page-----f9b3960c9897--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f9b3960c9897--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f9b3960c9897--------------------------------)
    [Jarom Hulet](https://medium.com/@jarom.hulet?source=post_page-----f9b3960c9897--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jarom.hulet?source=post_page-----f9b3960c9897--------------------------------)[![Jarom
    Hulet](../Images/0fdeb1a2df90cccdd8f2f4b84d5e54eb.png)](https://medium.com/@jarom.hulet?source=post_page-----f9b3960c9897--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f9b3960c9897--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f9b3960c9897--------------------------------)
    [Jarom Hulet](https://medium.com/@jarom.hulet?source=post_page-----f9b3960c9897--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f9b3960c9897--------------------------------)
    ·10 min read·Nov 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f9b3960c9897--------------------------------)
    ·阅读时间10分钟·2023年11月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/341332e6a89eedefdad2b419a0230be7.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/341332e6a89eedefdad2b419a0230be7.png)'
- en: Photo by ‘HH’ on Pexels.com
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于Pexels.com上的‘HH’
- en: Data science is a very technical, in-the-weeds type of work. We are often laser
    focused on very specific problems — which is good. We add most of our value by
    combining our focused attention and our skills to solve problems. But, I think
    it is a good practice to occasionally step back and try to take in the bigger
    picture.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学是一项非常技术性、深入细节的工作。我们通常会非常专注于具体的问题——这很好。我们通过将专注的注意力和技能结合起来解决问题来创造最大价值。但是，我认为偶尔退一步，试图看到更大的图景，是一种很好的实践。
- en: Studying philosophy is a tool that I have found to be quite effective in helping
    me think deeply about data science. As a casual student of philosophy, I’ve observed
    that some fields of philosophical thinking are nicely intertwined with data science.
    Specifically, I’ve found that metaphysics, causality and epistemology have a lot
    of theories that are very applicable.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 学习哲学是我发现对深入思考数据科学非常有效的工具。作为一个哲学的业余学生，我观察到一些哲学思维领域与数据科学有很好的交织。具体来说，我发现形而上学、因果关系和认识论有很多理论是非常适用的。
- en: This is the first installment of a multi-part series that discuss various philosophical
    viewpoints and their implications on data and data science. I’m going to start
    with the fascinating metaphysical theory of **determinism.**
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个多部分系列的第一篇，讨论了各种哲学观点及其对数据和数据科学的影响。我将从迷人的**决定论**的形而上学理论开始。
- en: What is determinism?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是决定论？
- en: Determinism is a philosophical theory about the nature of our universe. There
    are multiple different nuanced versions of determinism¹, but the overarching idea
    is that there is no randomness in our universe. Every event has a set of causes
    which entirely explain the event, and these causes themselves have a set of causes.
    The chain of causes is unbroken from the beginning of universe (or maybe there
    is no beginning of universe²?).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 决定论是关于我们宇宙本质的哲学理论。决定论有多种不同的细微版本¹，但总体想法是我们宇宙中没有随机性。每一个事件都有一组原因，这些原因完全解释了事件，而这些原因本身也有一组原因。从宇宙开始（或者可能宇宙没有开始²？）起，因果链是不断裂的。
- en: 'Below is a quote from Laplace that encapsulates a deterministic viewpoint on
    the physical world:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是拉普拉斯的名言，它概括了对物理世界的决定论观点：
- en: '*“We may regard the present state of the universe as the effect of its past
    and the cause of its future. An intellect which at a certain moment would know
    all forces that set nature in motion, and all positions of all items of which
    nature is composed, if this intellect were also vast enough to submit these data
    to analysis, it would embrace in a single formula the movements of the greatest
    bodies of the universe and those of the tiniest atom; for such an intellect nothing
    would be uncertain and the future just like the past would be present before its
    eyes.”*'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“我们可以将宇宙的现状视为其过去的结果和未来的原因。如果某一时刻有一个智力能够知道所有使自然运动的力量，以及自然中所有物体的所有位置，如果这个智力也足够庞大以将这些数据进行分析，它将会在一个公式中包含宇宙中最大物体和最小原子的运动；对于这样的智力来说，没有什么是不确定的，未来就像过去一样，会展现在它的眼前。”*'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Pierre-Simon Laplace, A Philosophical Essay on Probabilities (1814)*'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*皮埃尔-西蒙·拉普拉斯，《概率的哲学论文》（1814）*'
- en: 'I’ve found that determinism pops up in the following data science topics (I’m
    sure there are a lot more — let me know what I’ve missed!):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现确定论在以下数据科学主题中出现（我相信还有很多其他的——如果我遗漏了什么，请告诉我！）：
- en: Probability theory
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率论
- en: The concept of irreducible error
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可约错误的概念
- en: The theoretical ‘god’ model
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理论上的‘神’模型
- en: Causality and design of experiments
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果关系和实验设计
- en: Random numbers
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机数
- en: Probability Theory
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率论
- en: The study of probability is largely about understanding how random variables
    behave. A random variable represents the outcome of a process with randomness
    in it. For example, the roll of a die. We can know a lot about how probable certain
    outcomes are, but we cannot predict the outcome of a single throw with certainty—
    presumably because of randomness.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 概率的研究主要是了解随机变量的行为。随机变量表示一个包含随机性的过程的结果。例如，掷骰子。我们可以了解某些结果的概率，但我们无法确定单次投掷的结果——大概是由于随机性。
- en: The theory of determinism rejects that there is any randomness in the universe.
    Why then do we have the field of probability, in which we study *random* variables?
    Of course, a indeterminist would say that there *is* randomness in the universe.
    But, a determinist would likely say that the whole field of probability was created
    because of the **‘epistemic limits’** of humanity.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 确定论理论拒绝宇宙中存在任何随机性。那么我们为什么有研究*随机*变量的概率领域呢？当然，非确定论者会说宇宙中*确实*存在随机性。但确定论者可能会说整个概率领域是由于人类**“认知极限”**而创建的。
- en: '**Epistemic limits** bridge the gap between perceived randomness in the universe
    and the theory of determinism. These limits can be defined as the boundaries of
    what can be known or understood. If the universe is truly deterministic, we could
    *hypothetically* know the outcome of every dice roll (think about Laplace’s quote
    above). If we were able to gather and understand the causal relationship between
    all variables that impact each throw, we could calculate with 100% confidence
    the outcome of the roll (if the universe is deterministic). Imagine, though how
    much we would have to know to make such a calculation! The imperfections of the
    die, the exact placement of the die in my hand, exactly how I shake my hand, the
    barometric pressure that day, the hardness of the landing surface etc.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**认知极限**弥合了宇宙中感知的随机性与确定论理论之间的差距。这些极限可以定义为可以知道或理解的界限。如果宇宙是完全确定的，我们可以*假设性地*知道每次掷骰子的结果（考虑一下拉普拉斯的引述）。如果我们能够收集和理解所有影响每次掷骰子的变量之间的因果关系，我们可以以100%的信心计算出掷骰子的结果（如果宇宙是确定的）。但想象一下，我们需要知道多少才能做这样的计算！骰子的缺陷、骰子在我手中的准确位置、我摇动手的方式、那天的气压、着陆面地面的硬度等等。'
- en: Epistemic limits bridge the gap between perceived randomness in the universe
    and the theory of determinism.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 认知极限弥合了宇宙中感知的随机性与确定论理论之间的差距。
- en: A determinist is okay with things appearing random because she would feel that
    the reason things seem random is because of our epistemic limits. Because of these
    limits, probability is still a very useful field of study regardless of whether
    or not determinism correctly describes the nature of our universe.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 确定论者可以接受事物看起来随机，因为她会认为事物看起来随机的原因是由于我们的认知极限。由于这些极限，概率仍然是一个非常有用的研究领域，无论确定论是否正确描述了我们宇宙的本质。
- en: Irreducible error
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不可约错误
- en: Machine learning models attempt to make predictions given a set of data. Typically,
    these models are only estimates or approximations of how a system works. In other
    words, models are often wrong to some degree — we call this error. Determinism
    has theoretical implications on model error!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型试图在给定数据集的情况下进行预测。通常，这些模型只是对系统如何运作的估计或近似。换句话说，模型往往存在一定程度的错误——我们称之为误差。确定性对模型误差具有理论影响！
- en: 'A model’s error can come from a combination of three different sources:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的误差可能来源于三种不同的来源：
- en: Model approximation
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型近似
- en: Unavailable data
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不可用的数据
- en: Random noise
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机噪声
- en: '*model approximation*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型近似*'
- en: '![](../Images/87033769a83b5daa26e2b2370892be82.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87033769a83b5daa26e2b2370892be82.png)'
- en: image by author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: When we create a predictive model, we are estimating the true relationships
    between our target and predictors. We hope we have a close approximation. This
    is why you may hear ‘estimate the model’ and ‘train the model’ used interchangeably.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建一个预测模型时，我们是在估计目标和预测变量之间的真实关系。我们希望得到一个接近的近似值。这就是为什么你可能会听到“估计模型”和“训练模型”被交替使用。
- en: For example, when we estimate a linear regression model, we assume that all
    of our predictors have a linear relationship with our target variable. Violations
    of this assumption (even small violations) result in at least some amount of error.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当我们估计线性回归模型时，我们假设所有预测变量与目标变量之间有线性关系。对这一假设的违反（即使是小的违反）会导致至少一些误差。
- en: '*Unavailable data*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*不可用的数据*'
- en: '![](../Images/8e065352dc9bb1c8c2245244bd05684f.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e065352dc9bb1c8c2245244bd05684f.png)'
- en: image by author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: This type of error comes from missing data that is necessary to describe the
    system. It can be missing because it is unobservable or impossible to accurately
    quantify (e.g. driver mood to predict speeding) or because it is simply not available
    (website was not set up to capture how long a potential customer spent on the
    checkout page to predict probability of completing a purchase).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的误差来自于描述系统所需的缺失数据。它可能因为不可观察或无法准确量化（例如，预测超速的驾驶员情绪）而缺失，或者因为根本无法获得（例如，网站未设置以捕捉潜在客户在结账页面上花费的时间来预测完成购买的概率）。
- en: '*Random noise*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*随机噪声*'
- en: Randomness (assuming it exists) is the third cause of model error. Randomness
    by definition cannot be predicted, even given all of the necessary features and
    a perfect machine learning approach.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 随机性（假设存在）是模型误差的第三个原因。随机性根据定义是无法预测的，即使拥有所有必要的特征和完美的机器学习方法。
- en: '*Irreducible error*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*不可减少的误差*'
- en: Now that we understand the sources of error in a model, let’s talk about the
    nature of that error. Generally speaking, error (no matter the source) can be
    categorized as reducible or irreducible.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了模型误差的来源，让我们谈谈这种误差的性质。一般而言，误差（无论来源如何）可以被分类为可减少的或不可减少的。
- en: '**Reducible error** can be *reduced* with improvements to how the model learns
    from the training data.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可减少的误差**可以通过改进模型从训练数据中学习的方式来*减少*。'
- en: '**Irreducible error** is the amount of error that cannot be eliminated no matter
    how well our model is fit to the training data. I think of irreducible error as
    being further subdivided into ‘**local irreducible error**’ and ‘**universal irreducible
    error³.’**'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不可减少的误差**是无论我们的模型如何拟合训练数据，都无法消除的误差。我认为不可减少的误差进一步划分为‘**局部不可减少的误差**’和‘**普遍不可减少的误差³**’。'
- en: '**A.** I define **local irreducible error** as error that cannot be reduced
    because of the limits of data science tools or what data are locally or readily
    available. For example, error that persists after having thoroughly tested all
    available machine learning algorithms. Or error that persists because we do not
    have access to all data points that explain the target variable. Local irreducible
    error exists because we don’t live in a perfect world, it recognizes that there
    is only so much we can do with the tools and data that we are given.'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**A.** 我定义**局部不可减少的误差**为由于数据科学工具的限制或本地或 readily 可用的数据限制而无法减少的误差。例如，在彻底测试所有可用的机器学习算法后仍然存在的误差。或者因为我们无法访问所有解释目标变量的数据点而存在的误差。局部不可减少的误差存在是因为我们生活在一个不完美的世界中，它承认我们只能在给定的工具和数据下做这么多事情。'
- en: '**B. Universal irreducible error** is the error that persists when local constraints
    are lifted. We have to dive into a hypothetical world to get here. This is the
    error that we would observe if we had the perfect machine learning algorithm and
    all of the data that we need to fully explain our target variable.'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**B. 普遍不可减少的误差** 是指在局部约束解除后仍然存在的误差。我们必须进入一个假设的世界来理解这一点。这是指如果我们拥有完美的机器学习算法和完全解释目标变量所需的所有数据时，我们将观察到的误差。'
- en: '**Diagram of error taxonomy:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**误差分类图：**'
- en: '![](../Images/20574806be38d42d9d79be60fdbb94ce.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20574806be38d42d9d79be60fdbb94ce.png)'
- en: image by author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '![](../Images/2b704be15b7a991d60c8c0344782e9ea.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2b704be15b7a991d60c8c0344782e9ea.png)'
- en: image by author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: With an understanding of the sources and classifications of model error, let’s
    finally get to how determinism ties into everything!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过了解模型误差的来源和分类，我们终于可以探讨决定论如何与一切相关！
- en: Here is a thought experiment — if we have a perfect model structure (i.e. *f(x)
    = f’(x)*), and *x* is the exhaustive set of **all** features needed to predict
    *y*, would our model still have irreducible error? Or in the terms I created,
    would the ‘universal irreducible error’ be greater than 0? Determinism says ‘no!’
    Our model would be 100% accurate, because randomness does not exist. If error
    is not coming from other sources, there is no error! Universal irreducible error
    is always 0 in a deterministic world!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个思想实验——如果我们有一个完美的模型结构（即 *f(x) = f’(x)*），并且 *x* 是预测 *y* 所需的 **所有** 特征的详尽集合，那么我们的模型仍会有不可减少的误差吗？或者用我创建的术语，‘普遍不可减少的误差’是否大于0？决定论说‘不！’我们的模型将是100%准确的，因为随机性不存在。如果误差不来自其他来源，那么就没有误差！在决定论的世界里，普遍不可减少的误差总是0！
- en: Of course, we can’t go much past a thought experiment with this one because
    a ‘perfect model’ isn’t possible given humanity’s current epistemic limits.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们无法超越思想实验，因为鉴于人类目前的认知限制，‘完美模型’是不可能的。
- en: The ‘god’ model
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ‘神’模型
- en: Under the previous section, we discussed a hypothetical model that has the perfect
    formulation and has a complete, comprehensive list of predictors. This is what
    I refer to as a ‘god’ model⁴, meaning a deistic level of knowledge would be required
    to create such a model.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了一个具有完美公式和完整、全面预测变量列表的假设模型。这就是我所说的‘神’模型⁴，即需要一种自然神论水平的知识来创建这样的模型。
- en: Under determinism, ‘god’ models are a theoretical possibility. Since randomness
    doesn’t exist, a perfect model will have perfect predictions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定论下，‘神’模型是一个理论上的可能性。由于随机性不存在，一个完美的模型将会有完美的预测。
- en: Going back to epistemic limits, the only reason we cannot create ‘god’ models
    is because of our limits, not because of the nature of the universe.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 回到认知限制，我们无法创建‘神’模型的唯一原因是我们的限制，而不是宇宙的本质。
- en: Causality and design of experiments
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因果关系与实验设计
- en: Determinism mandates that everything is strictly causal. Some philosophers feel
    that causality is a human construct⁵. To accept determinism, one must accept that
    causality is a real phenomenon. (Note that this statement is not commutative—
    you don’t have to accept determinism to accept causality)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 决定论要求一切都是严格因果的。一些哲学家认为因果关系是人类构建的⁵。要接受决定论，必须接受因果关系是一个真实现象。（注意，这个声明不是可交换的——你不需要接受决定论才能接受因果关系）
- en: This has implications in how we think of the design and execution of experiments.
    Would you expect that a perfectly controlled experiment would have zero error?
    In other words, if we could completely isolate individual causes, and run the
    same experiment a million times, would you expect the exact same results, without
    any variation ever? If ‘yes’, you are well on your way to becoming a determinist!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这对我们如何考虑实验的设计和执行有着深远的影响。你是否期望一个完全受控的实验会有零误差？换句话说，如果我们能够完全隔离各个原因，并进行一百万次相同的实验，你是否期望得到完全相同的结果，永远没有任何变化？如果答案是‘是’，那么你就离成为一个决定论者不远了！
- en: Venturing into a perfect hypothetical world is a useful tool, but reality requires
    that we adapt to its imperfections. Of course we cannot perfectly control experiments
    — this is why the field of experimental design has provisions for handling apparent
    randomness and errors. Depending on our opinion of the universe though, we can
    see these accommodations as necessary only because of our epistemic limits (under
    determinism) or necessary because randomness is inherent in the universe.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 探索一个完美的假设世界是一个有用的工具，但现实要求我们适应其不完美之处。当然，我们不能完美地控制实验——这就是为什么实验设计领域有处理表面随机性和错误的规定。根据我们对宇宙的看法，我们可以将这些适应措施视为由于我们的认识限制（在决定论下）而必要，或者是由于随机性在宇宙中固有而必要。
- en: Random numbers
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机数
- en: There are random number generators that use *random* processes (e.g. atmospheric
    noise) to make numbers that cannot be replicated. These *random* numbers require
    hardware to capture.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有些随机数生成器使用*随机*过程（例如，大气噪声）来生成无法复制的数字。这些*随机*数需要硬件来捕捉。
- en: Most data professionals (who don’t mind or even want their random numbers to
    be replicated — think about setting a seed) only need to use pseudorandom numbers.
    Pseudorandom numbers appear random, but are created by deterministic algorithms
    and do not need anything more than a computer program to generate.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据专业人员（那些不介意甚至希望他们的随机数被复制——想想设置种子）只需要使用伪随机数。伪随机数看起来是随机的，但由确定性算法创建，不需要比计算机程序更多的东西来生成。
- en: If determinism is true, all ‘random numbers’ are actually pseudorandom numbers
    —remember, randomness doesn’t exist! Of course, going back again (I’m so sorry)
    to epistemic limits, the distinction between *random* numbers and pseudorandom
    numbers is meaningful because we can easily replicate pseudorandom numbers while
    *random* numbers would require a god-like level of knowledge to replicate. Sorry
    hackers, determinism is unlikely to be useful to you on this front… at least for
    now!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果决定论是真的，所有的‘随机数’实际上都是伪随机数——记住，随机性并不存在！当然，再次回到（非常抱歉）认识限制，*随机*数和伪随机数之间的区别是有意义的，因为我们可以很容易地复制伪随机数，而*随机*数需要类似于神的知识水平才能复制。抱歉黑客们，决定论在这一方面不太可能对你们有用……至少目前如此！
- en: Conclusion
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: With just a little bit of ‘big picture thought’ deterministic ideas and implications
    show up a lot in data science. This line of thinking may not help you solve a
    specific, technical problem at work. But, I believe that having deep thoughts
    about how data and the universe are connected will make you a more well-rounded,
    insightful data scientist.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一点‘宏观思考’，确定性思想和其含义在数据科学中经常出现。这种思维方式可能对解决工作中的具体技术问题没有帮助。但是，我相信对数据和宇宙如何连接进行深刻思考将使你成为一个更全面、更有洞察力的数据科学家。
- en: Notes
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 备注
- en: In this article I only cover a basic and general idea of determinism. There
    are many different versions of determinism. Also, I do not argue for or against
    determinism — there are multiple alternatives to the theory of determinism — indeterminism,
    agent causation, dualism etc.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本文中，我只涉及了决定论的基本和一般概念。决定论有许多不同的版本。此外，我并不主张或反对决定论——决定论的理论有多个替代方案——非决定论、代理因果关系、二元论等。
- en: Whether or not the universe has a beginning or is infinite is a question that
    philosophers have debated for literally thousands of years. Aristotle believed
    that observing chains of motion indicated that the universe was eternal because
    the chain can not have a beginning. Many medieval philosophers, like Thomas Aquinas,
    held that there was a first motion and that motion was God. Stephen Hawking opined
    that the universe started at the big bang and therefore has a definite starting
    point.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于宇宙是否有一个开始或是否无限的问题，哲学家们已经争论了数千年。亚里士多德认为，观察运动链表明宇宙是永恒的，因为链条不能有开始。许多中世纪哲学家，如托马斯·阿奎那，认为存在一个初始运动，而这个运动就是上帝。斯蒂芬·霍金认为宇宙在大爆炸时开始，因此有一个明确的起点。
- en: I further subdivide irreducible error into ‘local’ and ‘universal’ to help me
    think about error more thoroughly. Since these are terms that I made up, further
    searches on the internet probably won’t lead to anything!
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我将不可约错误进一步细分为‘局部’和‘普遍’以帮助我更全面地思考错误。由于这些是我自己创造的术语，进一步在互联网上搜索可能不会带来什么结果！
- en: While the ‘god’ model doesn’t really have any practical applications, it is
    a device that helps me think about the full spectrum of possible models. On the
    left (simplest and probably worst prediction) we have taking the average of our
    target variable and all the way to the right we have the ‘god’ model. To illustrate
    in the context of a regression problem, the average model will likely have a test
    R-squared near 0 while the ‘god’ model will have a test R-squared of 1 always.
    When I develop models I like to ask myself where I think my model lands on this
    spectrum.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然‘神’模型实际上没有任何实际应用，但它是一个帮助我思考所有可能模型的工具。在左侧（最简单且可能最差的预测）我们有目标变量的平均值，而右侧则是‘神’模型。为了在回归问题的背景下说明这一点，平均模型的测试R平方值可能接近0，而‘神’模型的测试R平方值总是1。当我开发模型时，我喜欢问自己我的模型在这个范围内大致处于什么位置。
- en: The Humean Regularity Theory suggests that we observe patterns and deduce causation
    when there isn’t necessarily a causal tie. David Hume believed we could not directly
    observe causation, so we have no reason to assert that causation is anything other
    than us noticing patterns.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 休谟的规律理论认为我们观察到模式并推断因果关系时，并不一定存在因果联系。大卫·休谟认为我们不能直接观察因果关系，因此我们没有理由认为因果关系是除了我们注意到模式以外的其他东西。
- en: Determinism and free will — while well outside of the scope of this article,
    if you are interested in determinism, you should study the philosophy of free
    will. Determinism’s implications on free will and accountability are fascinating,
    but I couldn’t think of a way that they tied into data science!
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决 determinism 和自由意志 — 尽管这超出了本文的范围，如果你对决定论感兴趣，你应该研究自由意志的哲学。决定论对自由意志和责任的影响非常有趣，但我无法想到它们如何与数据科学相关！
