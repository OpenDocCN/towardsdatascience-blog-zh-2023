- en: Cracking Open the OpenAI (Python) API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç ´è§£OpenAIï¼ˆPythonï¼‰API
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971](https://towardsdatascience.com/cracking-open-the-openai-python-api-230e4cae7971)
- en: '**A complete beginner-friendly introduction with example code**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**ä¸€ä¸ªå®Œæ•´çš„åˆå­¦è€…å‹å¥½ä»‹ç»ï¼Œé™„ç¤ºä¾‹ä»£ç **'
- en: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[![Shaw
    Talebi](../Images/1449cc7c08890e2078f9e5d07897e3df.png)](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)[](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    Â·12 min readÂ·Jul 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----230e4cae7971--------------------------------)
    Â·é˜…è¯»æ—¶é—´12åˆ†é’ŸÂ·2023å¹´7æœˆ21æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c856f26ccf574ede1e5d700f75668e9.png)'
- en: Photo by [Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±[Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)æä¾›ï¼Œæ¥æºäº[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This is the 2nd article in a [series](/a-practical-introduction-to-llms-65194dda1148)
    on using Large Language Models (LLMs) in practice. Here I present a beginner-friendly
    introduction to the OpenAI API. This allows you to go beyond restrictive chat
    interfaces like ChatGPT and to get more out of LLMs for your unique use cases.
    Python example code is provided below and at the [GitHub repository](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å…³äºåœ¨å®è·µä¸­ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„[ç³»åˆ—æ–‡ç« ](/a-practical-introduction-to-llms-65194dda1148)çš„ç¬¬äºŒç¯‡ã€‚è¿™é‡Œæˆ‘æä¾›äº†ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„OpenAI
    APIä»‹ç»ã€‚è¿™ä½¿ä½ èƒ½å¤Ÿè¶…è¶ŠåƒChatGPTè¿™æ ·çš„é™åˆ¶æ€§èŠå¤©ç•Œé¢ï¼Œå¹¶ä¸ºä½ çš„ç‹¬ç‰¹ç”¨ä¾‹æ›´å¥½åœ°åˆ©ç”¨LLMsã€‚ä¸‹é¢æä¾›äº†Pythonç¤ºä¾‹ä»£ç å’Œ[GitHubä»“åº“](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)ã€‚
- en: 'Table of Contents:'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç›®å½•ï¼š
- en: Whatâ€™s an API?
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯APIï¼Ÿ
- en: OpenAIâ€™s (Python) API
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAIçš„ï¼ˆPythonï¼‰API
- en: Getting Started (4 Steps)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼€å§‹ä½¿ç”¨ï¼ˆ4ä¸ªæ­¥éª¤ï¼‰
- en: Example Code
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ä»£ç 
- en: In the [first article](/a-practical-introduction-to-llms-65194dda1148) of this
    series, I described [**Prompt Engineering**](/cracking-open-the-openai-python-api-230e4cae7971)
    as the **most accessible way to use LLMs** in practice. The easiest (and most
    popular) way to do this is via tools like ChatGPT, which provide an intuitive,
    no-cost, and no-code way to interact with an LLM.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[ç¬¬ä¸€ç¯‡æ–‡ç« ](/a-practical-introduction-to-llms-65194dda1148)ä¸­ï¼Œæˆ‘æè¿°äº†[**æç¤ºå·¥ç¨‹**](/cracking-open-the-openai-python-api-230e4cae7971)ä½œä¸º**ä½¿ç”¨LLMsçš„æœ€ä¾¿æ·æ–¹æ³•**ã€‚æœ€ç®€å•ï¼ˆä¹Ÿæ˜¯æœ€æµè¡Œï¼‰çš„æ–¹æ³•æ˜¯é€šè¿‡åƒChatGPTè¿™æ ·çš„å·¥å…·ï¼Œå®ƒä»¬æä¾›äº†ç›´è§‚ã€æ— éœ€æˆæœ¬å’Œæ— éœ€ç¼–ç çš„LLMäº¤äº’æ–¹å¼ã€‚
- en: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## A Practical Introduction to LLMs'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
    [## LLMsçš„å®ç”¨å…¥é—¨'
- en: 3 levels of using LLMs in practice
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å®è·µä¸­ä½¿ç”¨LLMsçš„3ä¸ªå±‚æ¬¡
- en: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-practical-introduction-to-llms-65194dda1148?source=post_page-----230e4cae7971--------------------------------)
- en: However, this **ease of use comes at a cost**. Namely, the chat UI is restrictive
    and does not translate well to many practical use cases e.g. building your own
    customer support bot, real-time sentiment analysis of customer reviews, etc.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™ç§**ä½¿ç”¨ç®€ä¾¿æ€§æ˜¯æœ‰ä»£ä»·çš„**ã€‚å³èŠå¤©ç•Œé¢å…·æœ‰é™åˆ¶ï¼Œä¸”ä¸é€‚ç”¨äºè®¸å¤šå®é™…åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æ„å»ºè‡ªå·±çš„å®¢æˆ·æ”¯æŒæœºå™¨äººã€å®æ—¶åˆ†æå®¢æˆ·è¯„è®ºæƒ…æ„Ÿç­‰ã€‚
- en: In these cases, we can take Prompt Engineering one step further and interact
    with LLMs *programmatically*. One way we can do this is via an API.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†æç¤ºå·¥ç¨‹è¿›ä¸€æ­¥æ¨è¿›ï¼Œé€šè¿‡*ç¼–ç¨‹æ–¹å¼*ä¸LLMsäº’åŠ¨ã€‚å®ç°è¿™ä¸€ç‚¹çš„ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡APIã€‚
- en: '**1) Whatâ€™s an API?**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**1) ä»€ä¹ˆæ˜¯APIï¼Ÿ**'
- en: An **application programming interface (API)** allows you to interact with a
    remote application programmatically. While this might sound technical and scary,
    the idea is super simple. Consider the following analogy.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**åº”ç”¨ç¨‹åºç¼–ç¨‹æ¥å£ï¼ˆAPIï¼‰**å…è®¸ä½ ä»¥ç¼–ç¨‹æ–¹å¼ä¸è¿œç¨‹åº”ç”¨ç¨‹åºè¿›è¡Œäº¤äº’ã€‚è™½ç„¶è¿™å¯èƒ½å¬èµ·æ¥æŠ€æœ¯æ€§å¾ˆå¼ºä¸”æœ‰äº›å“äººï¼Œä½†å…¶å®éå¸¸ç®€å•ã€‚è€ƒè™‘ä»¥ä¸‹ç±»æ¯”ã€‚'
- en: Imagine you have an intense craving for the [pupusas](https://en.wikipedia.org/wiki/Pupusa)
    you ate during that summer in El Salvador. Unfortunately, youâ€™re back at home
    and donâ€™t know where to find good Salvadoran food. Lucky for you, however, you
    have a super-foodie friend that knows every restaurant in town.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹ä½ å¯¹åœ¨è¨å°”ç“¦å¤šé‚£ä¸ªå¤å¤©åƒçš„[æ™®æ™®è¨](https://en.wikipedia.org/wiki/Pupusa)äº§ç”Ÿäº†å¼ºçƒˆçš„æ¸´æœ›ã€‚ä¸å¹¸çš„æ˜¯ï¼Œä½ å›åˆ°äº†å®¶é‡Œï¼Œä¸çŸ¥é“åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°å¥½çš„è¨å°”ç“¦å¤šé£Ÿç‰©ã€‚ç„¶è€Œï¼Œä½ æœ‰ä¸€ä¸ªè¶…çº§åƒè´§æœ‹å‹ï¼Œä»–çŸ¥é“åŸé‡Œæ¯ä¸€å®¶é¤é¦†ã€‚
- en: So, you send your friend the text.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼Œä½ ç»™ä½ çš„æœ‹å‹å‘äº†çŸ­ä¿¡ã€‚
- en: â€œAny good pupusa spots in town?â€
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œåŸé‡Œæœ‰å¥½çš„æ™®æ™®è¨åº—å—ï¼Ÿâ€
- en: Then, a couple of minutes later, you get the response.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå‡ åˆ†é’Ÿåï¼Œä½ ä¼šæ”¶åˆ°å›å¤ã€‚
- en: â€œYes! Flavors of El Salvador has the best pupusas!â€
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæ˜¯çš„ï¼è¨å°”ç“¦å¤šé£å‘³çš„é¤å…æœ‰æœ€æ£’çš„æ™®æ™®è¨ï¼â€
- en: While this may seem irrelevant to APIs, this is essentially how they work. You
    send a **request** to a remote application i.e. text your super-foodie friend.
    Then, the remote application sends back a **response** i.e. the text back from
    your friend.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™ä¼¼ä¹ä¸ API æ— å…³ï¼Œä½†è¿™åŸºæœ¬ä¸Šå°±æ˜¯å®ƒä»¬çš„å·¥ä½œåŸç†ã€‚ä½ å‘è¿œç¨‹åº”ç”¨ç¨‹åºå‘é€ä¸€ä¸ª**è¯·æ±‚**ï¼Œå³ç»™ä½ çš„è¶…çº§åƒè´§æœ‹å‹å‘çŸ­ä¿¡ã€‚ç„¶åï¼Œè¿œç¨‹åº”ç”¨ç¨‹åºä¼šè¿”å›ä¸€ä¸ª**å“åº”**ï¼Œå³ä½ æœ‹å‹çš„å›å¤ã€‚
- en: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d55d67b38e544c96a386e920f92da133.png)'
- en: A visual analogy of how APIs work. Image by author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: API å·¥ä½œçš„å¯è§†åŒ–ç±»æ¯”ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: The difference between an API and the above analogy is instead of sending the
    request with your phoneâ€™s texting app, you use your favorite programming language
    e.g. Python, JavaScript, Ruby, Java, etc. This is great if you are developing
    software where some external information is required because the information retrieval
    can be automated.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: API ä¸ä¸Šè¿°ç±»æ¯”ä¹‹é—´çš„åŒºåˆ«åœ¨äºï¼Œä½ ä¸æ˜¯ç”¨æ‰‹æœºçš„çŸ­ä¿¡åº”ç”¨å‘é€è¯·æ±‚ï¼Œè€Œæ˜¯ä½¿ç”¨ä½ å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€ï¼Œä¾‹å¦‚ Pythonã€JavaScriptã€Rubyã€Java
    ç­‰ã€‚å¦‚æœä½ æ­£åœ¨å¼€å‘éœ€è¦å¤–éƒ¨ä¿¡æ¯çš„è½¯ä»¶ï¼Œè¿™éå¸¸å¥½ï¼Œå› ä¸ºä¿¡æ¯æ£€ç´¢å¯ä»¥è‡ªåŠ¨åŒ–ã€‚
- en: '**2) OpenAIâ€™s (Python) API**'
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**2) OpenAI çš„ï¼ˆPythonï¼‰API**'
- en: We can use APIs to interact with Large Language Models. A popular one is OpenAIâ€™s
    API, where instead of typing prompts into the ChatGPT web interface, you can send
    them to and from OpenAI using Python.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ API ä¸å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚ä¸€ä¸ªæµè¡Œçš„ API æ˜¯ OpenAI çš„ APIï¼Œä½ å¯ä»¥ä½¿ç”¨ Python å‘ OpenAI å‘é€å’Œæ¥æ”¶æç¤ºï¼Œè€Œä¸æ˜¯åœ¨
    ChatGPT ç½‘ç»œç•Œé¢ä¸­è¾“å…¥æç¤ºã€‚
- en: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49422df67ac7d25c8846a1ee770af4ad.png)'
- en: Visualization of how API calls to OpenAI works. Image by author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: API è°ƒç”¨åˆ° OpenAI çš„å¯è§†åŒ–ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: This gives virtually anyone access to state-of-the-art LLMs (and other ML models)
    without having to provision the computational resources needed to run them. The
    downside, of course, is OpenAI doesnâ€™t do this as a charity. Each API call costs
    money, but more on that in a bit.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—å‡ ä¹ä»»ä½•äººéƒ½å¯ä»¥è®¿é—®æœ€å…ˆè¿›çš„LLMï¼ˆå’Œå…¶ä»–MLæ¨¡å‹ï¼‰ï¼Œè€Œæ— éœ€æä¾›è¿è¡Œå®ƒä»¬æ‰€éœ€çš„è®¡ç®—èµ„æºã€‚å½“ç„¶ï¼Œç¼ºç‚¹æ˜¯ OpenAI å¹¶ä¸æ˜¯å‡ºäºæ…ˆå–„ç›®çš„æä¾›è¿™äº›æœåŠ¡ã€‚æ¯æ¬¡
    API è°ƒç”¨éƒ½ä¼šæ”¶è´¹ï¼Œä½†ç¨åä¼šè¯¦ç»†è¯´æ˜ã€‚
- en: Some **notable features** of the API (not available with ChatGPT) are listed
    below.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: API çš„ä¸€äº›**æ˜¾è‘—ç‰¹æ€§**ï¼ˆChatGPT ä¸æä¾›ï¼‰å¦‚ä¸‹ã€‚
- en: '**Customizable system message** (this is set to something like â€œ*I am ChatGPT,
    a large language model trained by OpenAI, based on the GPT-3.5 architecture. My
    knowledge is based on information available up until September 2021\. Todayâ€™s
    date is July 13, 2023.*â€ for ChatGPT)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¯å®šåˆ¶çš„ç³»ç»Ÿæ¶ˆæ¯**ï¼ˆå¯¹äº ChatGPTï¼Œè¿™è®¾ç½®ä¸ºç±»ä¼¼äºâ€œ*æˆ‘æ˜¯ ChatGPTï¼Œä¸€ä¸ªç”± OpenAI è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº GPT-3.5
    æ¶æ„ã€‚æˆ‘çš„çŸ¥è¯†åŸºäºæˆªè‡³ 2021 å¹´ 9 æœˆçš„ä¿¡æ¯ã€‚ä»Šå¤©çš„æ—¥æœŸæ˜¯ 2023 å¹´ 7 æœˆ 13 æ—¥ã€‚*â€çš„å†…å®¹ï¼‰'
- en: '**Adjust input parameters** such as maximum response length, number of responses,
    and temperature (i.e. the â€œrandomnessâ€ of the response).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è°ƒæ•´è¾“å…¥å‚æ•°**ï¼Œå¦‚æœ€å¤§å“åº”é•¿åº¦ã€å“åº”æ•°é‡å’Œæ¸©åº¦ï¼ˆå³å“åº”çš„â€œéšæœºæ€§â€ï¼‰ã€‚'
- en: Include **images** and **other file types** in prompts
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æç¤ºä¸­**åŒ…å«å›¾åƒ**å’Œ**å…¶ä»–æ–‡ä»¶ç±»å‹**ã€‚
- en: Extract helpful word **embeddings** for downstream tasks
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æå–å¯¹ä¸‹æ¸¸ä»»åŠ¡æœ‰å¸®åŠ©çš„è¯è¯­**åµŒå…¥**ã€‚
- en: '**Input audio** for transcription or translation'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¾“å…¥éŸ³é¢‘**ä»¥è¿›è¡Œè½¬å½•æˆ–ç¿»è¯‘ã€‚'
- en: Model **fine-tuning** functionality
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¨¡å‹**å¾®è°ƒ**åŠŸèƒ½
- en: The OpenAI API has [several models](https://platform.openai.com/docs/models)
    from which to choose. The *best* model to pick will depend on your particular
    use case. Below is a list of the current models available [[1](https://platform.openai.com/docs/models)].
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API æä¾›äº†[å¤šä¸ªæ¨¡å‹](https://platform.openai.com/docs/models)ä¾›é€‰æ‹©ã€‚é€‰æ‹©å“ªä¸ª*æœ€ä½³*æ¨¡å‹å–å†³äºä½ çš„å…·ä½“ç”¨ä¾‹ã€‚ä¸‹é¢æ˜¯å½“å‰å¯ç”¨æ¨¡å‹çš„åˆ—è¡¨[[1](https://platform.openai.com/docs/models)]ã€‚
- en: '![](../Images/98ce3333b2824ace053715e0867ed296.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98ce3333b2824ace053715e0867ed296.png)'
- en: List of available models via the OpenAI API as of Jul 2023\. Image by author.
    [[1](https://platform.openai.com/docs/models)]
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ—å‡ºäº†æˆªè‡³ 2023 å¹´ 7 æœˆçš„ OpenAI API å¯ç”¨æ¨¡å‹ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚[[1](https://platform.openai.com/docs/models)]
- en: '***Note****: Each item listed above is accompanied by a set of models which
    vary in size and cost. Check* [*documentation*](https://platform.openai.com/docs/models)
    *for the most recent information.*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '***æ³¨æ„***ï¼šä¸Šè¿°æ¯é¡¹å†…å®¹éƒ½æœ‰ä¸€ç»„æ¨¡å‹ï¼Œæ¨¡å‹çš„å¤§å°å’Œæˆæœ¬å„ä¸ç›¸åŒã€‚æŸ¥çœ‹* [*æ–‡æ¡£*](https://platform.openai.com/docs/models)
    *è·å–æœ€æ–°ä¿¡æ¯ã€‚*'
- en: '**Pricing & Tokens**'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å®šä»·ä¸ Token**'
- en: While the OpenAI API gives developers easy access to SOTA ML models, one obvious
    downside is that it **costs money**. Pricing is done on a per-token basis (no,
    I donâ€™t mean NFTs or something you use at the arcade).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ OpenAI API ä¸ºå¼€å‘è€…æä¾›äº†å¯¹æœ€å…ˆè¿›æœºå™¨å­¦ä¹ æ¨¡å‹çš„ä¾¿æ·è®¿é—®ï¼Œä½†ä¸€ä¸ªæ˜æ˜¾çš„ç¼ºç‚¹æ˜¯**éœ€è¦ä»˜è´¹**ã€‚å®šä»·æ˜¯æŒ‰ token è®¡ç®—çš„ï¼ˆä¸ï¼Œæˆ‘ä¸æ˜¯æŒ‡
    NFTs æˆ–å…¶ä»–ä½ åœ¨æ¸¸æˆå…ç”¨çš„ä¸œè¥¿ï¼‰ã€‚
- en: '**Tokens**, in the context of LLMs, are essentially **a set of numbers representing
    a set of words and characters**. For example, â€œTheâ€ could be a token, â€œ endâ€ (with
    the space) could be another, and â€œ.â€ another.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**Token**ï¼Œåœ¨ LLM çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæœ¬è´¨ä¸Šæ˜¯**ä»£è¡¨ä¸€ç»„å•è¯å’Œå­—ç¬¦çš„ä¸€ç»„æ•°å­—**ã€‚ä¾‹å¦‚ï¼Œâ€œTheâ€ å¯èƒ½æ˜¯ä¸€ä¸ª tokenï¼Œâ€œ endâ€ï¼ˆå¸¦ç©ºæ ¼ï¼‰å¯èƒ½æ˜¯å¦ä¸€ä¸ªï¼Œ"."
    ä¹Ÿæ˜¯ä¸€ä¸ªã€‚'
- en: Thus, the text â€œThe End.â€ would consist of 3 tokens say (73, 102, 6).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ–‡æœ¬ â€œThe End.â€ å°†ç”± 3 ä¸ª token ç»„æˆï¼Œä¾‹å¦‚ï¼ˆ73, 102, 6ï¼‰ã€‚
- en: '![](../Images/1f13c26b8c5b663dd2903f54a9249d13.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f13c26b8c5b663dd2903f54a9249d13.png)'
- en: Toy example showing one possible token mapping between text and integers. Image
    by author.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªç©å…·ç¤ºä¾‹ï¼Œå±•ç¤ºäº†æ–‡æœ¬ä¸æ•´æ•°ä¹‹é—´çš„ä¸€ç§å¯èƒ½çš„ token æ˜ å°„ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚
- en: This is a critical step because **LLMs (i.e. neural networks) do not â€œunderstandâ€
    text directly**. The text must be converted into a numerical representation so
    that the model can perform mathematical operations on the input. Hence, the tokenization
    step.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œå› ä¸º**LLMï¼ˆå³ç¥ç»ç½‘ç»œï¼‰ä¸ç›´æ¥â€œç†è§£â€æ–‡æœ¬**ã€‚æ–‡æœ¬å¿…é¡»è½¬æ¢ä¸ºæ•°å­—è¡¨ç¤ºï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥å¯¹è¾“å…¥æ‰§è¡Œæ•°å­¦æ“ä½œã€‚å› æ­¤ï¼Œéœ€è¦è¿›è¡Œ token
    åŒ–æ­¥éª¤ã€‚
- en: The price of an API call depends on the number of tokens used in the prompt
    and the model being prompted. The price per model is available on [OpenAIâ€™s website](https://openai.com/pricing).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: API è°ƒç”¨çš„ä»·æ ¼å–å†³äºæç¤ºä¸­ä½¿ç”¨çš„ token æ•°é‡å’Œæ‰€è°ƒç”¨çš„æ¨¡å‹ã€‚æ¯ä¸ªæ¨¡å‹çš„ä»·æ ¼å¯ä»¥åœ¨ [OpenAI çš„ç½‘ç«™](https://openai.com/pricing)
    ä¸Šæ‰¾åˆ°ã€‚
- en: '**3) Getting Started (4 Steps)**'
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**3) å¼€å§‹ä½¿ç”¨ï¼ˆ4 æ­¥éª¤ï¼‰**'
- en: Now that we have a basic understanding of the OpenAI API letâ€™s see how to use
    it. Before we can start coding, we need to set up four things.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯¹ OpenAI API æœ‰äº†åŸºæœ¬äº†è§£ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨å®ƒã€‚åœ¨å¼€å§‹ç¼–ç ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®å››ä»¶äº‹ã€‚
- en: '**3.1) Make an Account (you get a $5 API credit for 1st three months)**'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.1) åˆ›å»ºè´¦æˆ·ï¼ˆå‰ 3 ä¸ªæœˆæœ‰ $5 çš„ API é¢åº¦ï¼‰**'
- en: To make an account go to the [OpenAI API Overview page](https://platform.openai.com/overview),
    and click â€œSign Upâ€ in the top right corner
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¦åˆ›å»ºè´¦æˆ·ï¼Œè¯·è®¿é—® [OpenAI API æ¦‚è§ˆé¡µé¢](https://platform.openai.com/overview)ï¼Œå¹¶ç‚¹å‡»å³ä¸Šè§’çš„â€œæ³¨å†Œâ€
- en: '*Note* â€” If youâ€™ve used ChatGPT before, then you probably already have an OpenAI
    account. If so, click â€œLog inâ€'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ³¨æ„* â€” å¦‚æœä½ ä»¥å‰ä½¿ç”¨è¿‡ ChatGPTï¼Œé‚£ä¹ˆä½ å¯èƒ½å·²ç»æœ‰ä¸€ä¸ª OpenAI å¸æˆ·ã€‚å¦‚æœæ˜¯ï¼Œè¯·ç‚¹å‡»â€œç™»å½•â€'
- en: '**3.2) Add Payment Method**'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.2) æ·»åŠ æ”¯ä»˜æ–¹å¼**'
- en: If your account is more than 3 months old or the free $5 API credit is not enough
    for you, you will need to add a payment method before making API calls.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çš„è´¦æˆ·å·²ç»è¶…è¿‡ 3 ä¸ªæœˆï¼Œæˆ–è€…å…è´¹çš„ $5 API é¢åº¦ä¸å¤Ÿç”¨ï¼Œä½ éœ€è¦åœ¨è°ƒç”¨ API ä¹‹å‰æ·»åŠ æ”¯ä»˜æ–¹å¼ã€‚
- en: Click your profile image and select the manage account option.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç‚¹å‡»ä½ çš„å¤´åƒå¹¶é€‰æ‹©ç®¡ç†è´¦æˆ·é€‰é¡¹ã€‚
- en: Then add a payment method by clicking the â€œBillingâ€ tab and then â€œPayment methodsâ€.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åç‚¹å‡»â€œè´¦å•â€æ ‡ç­¾ï¼Œå†ç‚¹å‡»â€œæ”¯ä»˜æ–¹å¼â€æ¥æ·»åŠ æ”¯ä»˜æ–¹å¼ã€‚
- en: '**3.3) Set Usage Limits**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.3) è®¾ç½®ä½¿ç”¨é™åˆ¶**'
- en: Next, I recommend setting usage limits so that you **avoid being billed more
    than you budget for**.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘å»ºè®®è®¾ç½®ä½¿ç”¨é™åˆ¶ï¼Œä»¥**é¿å…è¢«è´¦å•è¶…å‡ºé¢„ç®—**ã€‚
- en: To do this, go to the â€œUsage limitsâ€ under the â€œBillingâ€ tab. Here you can set
    a â€œSoftâ€ and â€œHardâ€ limit.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œè¯·è½¬åˆ°â€œè´¦å•â€æ ‡ç­¾ä¸‹çš„â€œä½¿ç”¨é™åˆ¶â€ã€‚åœ¨è¿™é‡Œä½ å¯ä»¥è®¾ç½®â€œè½¯é™åˆ¶â€å’Œâ€œç¡¬é™åˆ¶â€ã€‚
- en: If you hit your monthly **soft limit,** OpenAI will send you an **email notification**.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¾¾åˆ°æ¯æœˆçš„**è½¯é™åˆ¶**ï¼ŒOpenAI ä¼šå‘ä½ å‘é€**ç”µå­é‚®ä»¶é€šçŸ¥**ã€‚
- en: If you hit your **hard limit,** any additional API **requests will be denied**
    (thus, you wonâ€™t be charged more than this).
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¾¾åˆ°äº†**ç¡¬é™åˆ¶**ï¼Œä»»ä½•é¢å¤–çš„ API **è¯·æ±‚å°†è¢«æ‹’ç»**ï¼ˆå› æ­¤ï¼Œä½ ä¸ä¼šè¢«é¢å¤–æ”¶è´¹ï¼‰ã€‚
- en: '**3.4) Get API Secret Key**'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**3.4) è·å– API ç§˜é’¥**'
- en: Click on â€œView API keysâ€
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç‚¹å‡»â€œæŸ¥çœ‹ API å¯†é’¥â€
- en: If this is your first time, you will need to make a new secret key. To do this,
    click â€œCreate new secret keyâ€
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™æ˜¯ä½ ç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼Œä½ éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°çš„ç§˜é’¥ã€‚ä¸ºæ­¤ï¼Œç‚¹å‡»â€œåˆ›å»ºæ–°çš„ç§˜é’¥â€
- en: Next, you can give your key a custom name. Here I used â€œmy-first-keyâ€.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œä½ å¯ä»¥ç»™ä½ çš„å¯†é’¥ä¸€ä¸ªè‡ªå®šä¹‰åç§°ã€‚æˆ‘åœ¨è¿™é‡Œä½¿ç”¨äº†â€œmy-first-keyâ€ã€‚
- en: Then, click â€œCreate secret keyâ€
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œç‚¹å‡»â€œåˆ›å»ºå¯†é’¥â€
- en: '**4) Example Code: Chat Completion API**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**4) ç¤ºä¾‹ä»£ç ï¼šèŠå¤©å®Œæˆ API**'
- en: With all the setup done, we are (finally) ready to make our first API call.
    Here we will use the [openai Python library](https://github.com/openai/openai-python),
    which makes integrating OpenAIâ€™s models into your Python code super easy. You
    can download the package via [pip](https://pypi.org/project/openai/)*.* The below
    example code (and bonus code) is available on the [GitHub repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)
    for this article.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰è®¾ç½®å®Œæˆåï¼Œæˆ‘ä»¬ï¼ˆç»ˆäºï¼‰å‡†å¤‡å¥½è¿›è¡Œç¬¬ä¸€æ¬¡ API è°ƒç”¨ã€‚è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨ [openai Python åº“](https://github.com/openai/openai-python)ï¼Œå®ƒä½¿å°†
    OpenAI çš„æ¨¡å‹é›†æˆåˆ°ä½ çš„ Python ä»£ç ä¸­å˜å¾—éå¸¸ç®€å•ã€‚ä½ å¯ä»¥é€šè¿‡ [pip](https://pypi.org/project/openai/)
    ä¸‹è½½è¿™ä¸ªåŒ…ã€‚ä¸‹é¢çš„ç¤ºä¾‹ä»£ç ï¼ˆä»¥åŠé¢å¤–ä»£ç ï¼‰å¯ä»¥åœ¨ [GitHub ä»“åº“](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/openai-api)ä¸­æ‰¾åˆ°ã€‚
- en: '***A quick note on Completions API deprecations* â€”** OpenAI is moving away
    from the freeform prompt paradigm and toward chat-based API calls. According to
    a blog from OpenAI, the chat-based paradigm provides better responses, given its
    structured prompt interface, compared to the previous paradigm [[2](https://openai.com/blog/gpt-4-api-general-availability)].'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '***å…³äº Completions API åºŸå¼ƒçš„å¿«é€Ÿè¯´æ˜* â€”** OpenAI æ­£åœ¨ä»è‡ªç”±å½¢å¼çš„æç¤ºèŒƒå¼è½¬å‘åŸºäºèŠå¤©çš„ API è°ƒç”¨ã€‚æ ¹æ® OpenAI
    çš„åšå®¢ï¼ŒåŸºäºèŠå¤©çš„èŒƒå¼æä¾›äº†æ›´å¥½çš„å“åº”ï¼Œé‰´äºå…¶ç»“æ„åŒ–æç¤ºç•Œé¢ï¼Œç›¸æ¯”äºä»¥å‰çš„èŒƒå¼ [[2](https://openai.com/blog/gpt-4-api-general-availability)]ã€‚'
- en: While older OpenAI (GPT-3) models are still available via the â€œfreeformâ€ paradigm,
    the more recent (and powerful) models (i.e. GPT-3.5-turbo and GPT-4) are only
    available via chat-based calls.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æ—§ç‰ˆ OpenAIï¼ˆGPT-3ï¼‰æ¨¡å‹ä»ç„¶å¯ä»¥é€šè¿‡â€œè‡ªç”±å½¢å¼â€èŒƒå¼ä½¿ç”¨ï¼Œä½†æ›´è¿‘æœŸï¼ˆå’Œæ›´å¼ºå¤§çš„ï¼‰æ¨¡å‹ï¼ˆå³ GPT-3.5-turbo å’Œ GPT-4ï¼‰åªèƒ½é€šè¿‡åŸºäºèŠå¤©çš„è°ƒç”¨è·å¾—ã€‚
- en: Letâ€™s start with a super simple API call. Here we will pass **two inputs** into
    the ***openai.ChatCompletions.create()*** method i.e. **model** and **messages**.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»ä¸€ä¸ªè¶…çº§ç®€å•çš„ API è°ƒç”¨å¼€å§‹ã€‚è¿™é‡Œæˆ‘ä»¬å°†**ä¸¤ä¸ªè¾“å…¥**ä¼ é€’ç»™***openai.ChatCompletions.create()*** æ–¹æ³•ï¼Œå³**model**å’Œ**messages**ã€‚
- en: '**model** â€” defines the name of the language model we want to use (we can choose
    from the models listed earlier in the article.)'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**model** â€” å®šä¹‰äº†æˆ‘ä»¬æƒ³è¦ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹çš„åç§°ï¼ˆæˆ‘ä»¬å¯ä»¥ä»æœ¬æ–‡å‰é¢åˆ—å‡ºçš„æ¨¡å‹ä¸­é€‰æ‹©ã€‚ï¼‰'
- en: '**messages** â€” sets the â€œprecedingâ€ chat dialogue as a list of dictionaries.
    The dictionaries have two key-value pairs (e.g. {â€œroleâ€: â€œuserâ€, â€œcontentâ€: â€œListen
    to yourâ€}.) **First**, â€œroleâ€ defines *who is talking* (e.g. â€œroleâ€:â€userâ€). This
    can either be the â€œuserâ€, â€œassistantâ€, or â€œsystemâ€. **Second**, â€œcontentâ€ defines
    *what the role is saying* (e.g. â€œcontentâ€: â€œListen to yourâ€). While this may feel
    more restrictive than a freeform prompt interface, we can get creative with input
    messages to optimize responses for a particular use case (more on this later).'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ¶ˆæ¯** â€” å°†â€œå‰é¢çš„â€èŠå¤©å¯¹è¯è®¾ç½®ä¸ºå­—å…¸åˆ—è¡¨ã€‚è¿™äº›å­—å…¸æœ‰ä¸¤ä¸ªé”®å€¼å¯¹ï¼ˆä¾‹å¦‚ {â€œroleâ€: â€œuserâ€, â€œcontentâ€: â€œListen
    to yourâ€}ï¼‰ã€‚**é¦–å…ˆ**ï¼Œâ€œroleâ€å®šä¹‰äº†*è°åœ¨è®²è¯*ï¼ˆä¾‹å¦‚ â€œroleâ€:â€userâ€ï¼‰ã€‚è¿™å¯ä»¥æ˜¯â€œç”¨æˆ·â€ã€â€œåŠ©æ‰‹â€æˆ–â€œç³»ç»Ÿâ€ã€‚**å…¶æ¬¡**ï¼Œâ€œcontentâ€å®šä¹‰äº†*è§’è‰²åœ¨è¯´ä»€ä¹ˆ*ï¼ˆä¾‹å¦‚
    â€œcontentâ€: â€œListen to yourâ€ï¼‰ã€‚è™½ç„¶è¿™å¯èƒ½æ¯”è‡ªç”±å½¢å¼çš„æç¤ºç•Œé¢æ›´å…·é™åˆ¶æ€§ï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ›æ„è¾“å…¥æ¶ˆæ¯æ¥ä¼˜åŒ–ç‰¹å®šç”¨ä¾‹çš„å“åº”ï¼ˆç¨åä¼šè¯¦ç»†è¯´æ˜ï¼‰ã€‚'
- en: This is what our first API call looks like in Python.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘ä»¬ç¬¬ä¸€æ¬¡åœ¨ Python ä¸­è°ƒç”¨ API çš„æ ·å­ã€‚
- en: '[PRE0]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The API response is stored in the *chat_completion* variable. Printing *chat_completion*,
    we see that it is like a dictionary consisting of 6 key-value pairs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: API å“åº”å­˜å‚¨åœ¨*chat_completion*å˜é‡ä¸­ã€‚æ‰“å°*chat_completion*ï¼Œæˆ‘ä»¬çœ‹åˆ°å®ƒåƒä¸€ä¸ªåŒ…å« 6 ä¸ªé”®å€¼å¯¹çš„å­—å…¸ã€‚
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The meaning of each field is listed below.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªå­—æ®µçš„å«ä¹‰åˆ—åœ¨ä¸‹é¢ã€‚
- en: '**â€˜Idâ€™** = unique ID for the API response'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€˜Idâ€™** = API å“åº”çš„å”¯ä¸€ ID'
- en: '**â€˜Objectâ€™** = name of API object that sent the response'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€˜Objectâ€™** = å‘é€å“åº”çš„ API å¯¹è±¡çš„åç§°'
- en: '**â€˜Createdâ€™** = unix timestamp of when the API request was processed'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€˜Createdâ€™** = å¤„ç† API è¯·æ±‚æ—¶çš„ Unix æ—¶é—´æˆ³'
- en: '**â€˜Modelâ€™** = name of the model used'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€˜Modelâ€™** = ä½¿ç”¨çš„æ¨¡å‹åç§°'
- en: '**â€˜Choicesâ€™** = model response formatted in JSON (i.e. dictionary-like)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€˜Choicesâ€™** = æ¨¡å‹å“åº”æ ¼å¼ä¸º JSONï¼ˆå³ç±»ä¼¼å­—å…¸çš„å½¢å¼ï¼‰'
- en: '**â€˜Usageâ€™** = token count meta-data formatted in JSON (i.e. dictionary-like)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€˜Usageâ€™** = ä»¥ JSON æ ¼å¼ï¼ˆå³ç±»ä¼¼å­—å…¸çš„å½¢å¼ï¼‰æ˜¾ç¤ºçš„ä»¤ç‰Œè®¡æ•°å…ƒæ•°æ®'
- en: However, the main thing we care about here is the â€˜**Choices**â€™ field since
    this is **where the model response is stored**. In this case, we see the â€œassistantâ€
    role responds with the message *â€œ****heart.â€***
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæœ€å…³å¿ƒçš„æ˜¯â€˜**Choices**â€™å­—æ®µï¼Œå› ä¸ºè¿™æ˜¯**æ¨¡å‹å“åº”å­˜å‚¨çš„ä½ç½®**ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çœ‹åˆ°â€œåŠ©æ‰‹â€è§’è‰²ç”¨æ¶ˆæ¯*â€œ****heart.â€*ä½œå‡ºå“åº”ã€‚
- en: Yay! We made our 1st API call. Now letâ€™s start playing with the model input
    parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å¤ªå¥½äº†ï¼æˆ‘ä»¬å®Œæˆäº†ç¬¬ä¸€æ¬¡ API è°ƒç”¨ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹è°ƒæ•´æ¨¡å‹è¾“å…¥å‚æ•°ã€‚
- en: max_tokens
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: max_tokens
- en: First, we can set the **maximum number of tokens** allowed in the model response
    using the *max_tokens* input parameter. This can be helpful for many reasons depending
    on the use case. In this case, I just want a one-word response, so Iâ€™ll set it
    to 1 token.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨*max_tokens*è¾“å…¥å‚æ•°è®¾ç½®æ¨¡å‹å“åº”ä¸­å…è®¸çš„**æœ€å¤§ä»¤ç‰Œæ•°**ã€‚è¿™åœ¨è®¸å¤šæƒ…å†µä¸‹éƒ½å¯èƒ½æ˜¯æœ‰å¸®åŠ©çš„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘åªæƒ³è¦ä¸€ä¸ªå•è¯çš„å“åº”ï¼Œå› æ­¤æˆ‘å°†å…¶è®¾ç½®ä¸º1ä¸ªä»¤ç‰Œã€‚
- en: '[PRE2]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: n
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: n
- en: Next, we can set the **number of responses** we would like to receive from the
    model. Again, this can be helpful for many reasons depending on the use case.
    For example, if we want to generate a set of responses from which we can select
    the one we like best.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®æˆ‘ä»¬å¸Œæœ›ä»æ¨¡å‹ä¸­æ¥æ”¶çš„**å“åº”æ•°é‡**ã€‚è¿™åœ¨è®¸å¤šæƒ…å†µä¸‹éƒ½å¯èƒ½æ˜¯æœ‰å¸®åŠ©çš„ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆä¸€ç»„å“åº”ï¼Œä»ä¸­é€‰æ‹©æˆ‘ä»¬æœ€å–œæ¬¢çš„ä¸€ä¸ªã€‚
- en: '[PRE3]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that **not all the completions are identical**. This may be a good thing
    or a bad thing based on the use case (e.g. creative use cases vs. process automation
    use cases). Therefore, it can be advantageous to adjust the *diversity* of chat
    completions for a given prompt.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„åˆ°**å¹¶éæ‰€æœ‰çš„å®Œæˆéƒ½æ˜¯ç›¸åŒçš„**ã€‚è¿™å¯èƒ½æ˜¯å¥½äº‹ä¹Ÿå¯èƒ½æ˜¯åäº‹ï¼Œå…·ä½“å–å†³äºä½¿ç”¨æ¡ˆä¾‹ï¼ˆä¾‹å¦‚åˆ›æ„ä½¿ç”¨æ¡ˆä¾‹ä¸è¿‡ç¨‹è‡ªåŠ¨åŒ–ä½¿ç”¨æ¡ˆä¾‹ï¼‰ã€‚å› æ­¤ï¼Œä¸ºç»™å®šçš„æç¤ºè°ƒæ•´èŠå¤©å®Œæˆçš„*å¤šæ ·æ€§*å¯èƒ½æ˜¯æœ‰åˆ©çš„ã€‚
- en: temperature
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: temperature
- en: It turns out we can do this by tuning the **temperature** parameter. Put simply,
    this **adjusts the â€œrandomnessâ€ of chat completions**.Values for this parameter
    **range from 0 to 2**, where 0 makes completions more predictable, and 2 makes
    them less predictable [[3](https://platform.openai.com/docs/api-reference/chat/create)].
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒæ•´**æ¸©åº¦**å‚æ•°æ¥å®ç°è¿™ä¸€ç‚¹ã€‚ç®€è€Œè¨€ä¹‹ï¼Œè¿™**è°ƒæ•´äº†èŠå¤©å®Œæˆçš„â€œéšæœºæ€§â€**ã€‚æ­¤å‚æ•°çš„å€¼**èŒƒå›´ä»0åˆ°2**ï¼Œå…¶ä¸­0ä½¿å®Œæˆæ›´å¯é¢„æµ‹ï¼Œè€Œ2åˆ™ä½¿å…¶ä¸é‚£ä¹ˆå¯é¢„æµ‹[[3](https://platform.openai.com/docs/api-reference/chat/create)]ã€‚
- en: Conceptually, we can think of temp=0 will default to the most likely next word
    while temp=2 will enable completions that are relatively unlikely. Letâ€™s see what
    this looks like.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ¦‚å¿µä¸Šè®²ï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºtemp=0å°†é»˜è®¤ç”Ÿæˆæœ€å¯èƒ½çš„ä¸‹ä¸€ä¸ªè¯ï¼Œè€Œtemp=2å°†ç”Ÿæˆç›¸å¯¹ä¸å¤ªå¯èƒ½çš„å®Œæˆã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯ä»€ä¹ˆæ ·çš„ã€‚
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As expected, when temp=0, all 5 completions are identical and produce something
    â€œvery likely.â€ Now letâ€™s see what happens when we **turn up the temperature**.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œå½“temp=0æ—¶ï¼Œæ‰€æœ‰5ä¸ªå®Œæˆæ˜¯ç›¸åŒçš„ï¼Œå¹¶äº§ç”Ÿâ€œéå¸¸å¯èƒ½â€çš„ç»“æœã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å½“æˆ‘ä»¬**æé«˜æ¸©åº¦**æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆã€‚
- en: '[PRE5]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Again, as expected, the chat completions with temp=2 were much more diverse
    and â€œout of pocket.â€
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œtemp=2æ—¶çš„èŠå¤©å®Œæˆæ›´åŠ å¤šæ ·åŒ–ï¼Œä¸”â€œå‡ºä¹æ„æ–™â€ã€‚
- en: 'messages roles: Lyric Completion Assistant'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯è§’è‰²ï¼šæ­Œè¯å®ŒæˆåŠ©æ‰‹
- en: Finally, we can leverage the different roles in this chat-based prompting paradigm
    to adjust the language model responses even further.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è¿™ç§åŸºäºèŠå¤©çš„æç¤ºèŒƒå¼ä¸­çš„ä¸åŒè§’è‰²æ¥è¿›ä¸€æ­¥è°ƒæ•´è¯­è¨€æ¨¡å‹çš„å“åº”ã€‚
- en: 'Recall from earlier that we can include content from 3 different roles in our
    prompts: **system**, **user**, and **assistant**. The **system** message **sets
    the context (or task) for model completions** *e.g. â€œYou are a friendly chatbot
    that does not want to destroy all humansâ€ or â€œSummarize user prompts in max 10
    wordsâ€.*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å›é¡¾ä¸€ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æç¤ºä¸­åŒ…å«æ¥è‡ª3ä¸ªä¸åŒè§’è‰²çš„å†…å®¹ï¼š**ç³»ç»Ÿ**ã€**ç”¨æˆ·**å’Œ**åŠ©æ‰‹**ã€‚**ç³»ç»Ÿ**æ¶ˆæ¯**è®¾ç½®äº†æ¨¡å‹å®Œæˆçš„ä¸Šä¸‹æ–‡ï¼ˆæˆ–ä»»åŠ¡ï¼‰**
    *ä¾‹å¦‚â€œä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„èŠå¤©æœºå™¨äººï¼Œä¸æƒ³æ‘§æ¯æ‰€æœ‰äººç±»â€æˆ–â€œå°†ç”¨æˆ·æç¤ºæ€»ç»“ä¸ºæœ€å¤š10ä¸ªè¯â€ã€‚*
- en: '**User** and **assistant** messages can be used in at least two ways. **One**,
    to generate examples for **in-context learning**, and **two**, to store and update
    **conversation history** for a real-time chatbot. Here we will use both ways to
    create a lyric completion assistant.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æˆ·**å’Œ**åŠ©æ‰‹**æ¶ˆæ¯å¯ä»¥è‡³å°‘ä»¥ä¸¤ç§æ–¹å¼ä½¿ç”¨ã€‚**ä¸€ç§**ï¼Œç”Ÿæˆ**ä¸Šä¸‹æ–‡å­¦ä¹ **çš„ç¤ºä¾‹ï¼›**å¦ä¸€ç§**ï¼Œå­˜å‚¨å’Œæ›´æ–°**å¯¹è¯å†å²**ä»¥ä¾›å®æ—¶èŠå¤©æœºå™¨äººä½¿ç”¨ã€‚è¿™é‡Œæˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸¤ç§æ–¹å¼æ¥åˆ›å»ºä¸€ä¸ªæ­Œè¯å®ŒæˆåŠ©æ‰‹ã€‚'
- en: We start by making the **system message** *â€œI am Roxette lyric completion assistant.
    When given a line from a song, I will provide the next line in the song.â€* Then,
    provide **two examples of** **user and assistant messages**. Followed by the same
    **user prompt** used in the preceding examples i.e.*â€œListen to yourâ€.*
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆè®¾ç½®**ç³»ç»Ÿæ¶ˆæ¯**ä¸º *â€œæˆ‘æ˜¯Roxetteæ­Œè¯å®ŒæˆåŠ©æ‰‹ã€‚å½“ç»™å‡ºä¸€è¡Œæ­Œè¯æ—¶ï¼Œæˆ‘å°†æä¾›æ­Œæ›²ä¸­çš„ä¸‹ä¸€è¡Œã€‚â€* ç„¶åï¼Œæä¾›**ä¸¤ä¸ªç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯çš„ç¤ºä¾‹**ã€‚æ¥ç€ä½¿ç”¨ä¸ä¹‹å‰ç¤ºä¾‹ä¸­ç›¸åŒçš„**ç”¨æˆ·æç¤º**å³
    *â€œå¬å¬ä½ çš„â€*ã€‚
- en: Hereâ€™s what that looks like in code.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åœ¨ä»£ç ä¸­æ˜¯è¿™æ ·çš„ã€‚
- en: '[PRE6]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Comparing the output to the [actual lyrics](https://www.azlyrics.com/lyrics/roxette/listentoyourheart.html)
    to the hit Roxette song, we see they are an exact match. This is due to the combination
    of all the different inputs we provided to the model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”è¾ƒä¸[å®é™…æ­Œè¯](https://www.azlyrics.com/lyrics/roxette/listentoyourheart.html)çš„è¾“å‡ºï¼Œæˆ‘ä»¬çœ‹åˆ°å®ƒä»¬å®Œå…¨åŒ¹é…ã€‚è¿™æ˜¯ç”±äºæˆ‘ä»¬æä¾›ç»™æ¨¡å‹çš„æ‰€æœ‰ä¸åŒè¾“å…¥çš„ç»„åˆã€‚
- en: 'To see what this looks like when we â€œ*crank the temperature*,â€ check out the
    bonus code on [GitHub](https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/openai-api/openai-api-demo.ipynb).
    (Warning: it gets weird)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æŸ¥çœ‹å½“æˆ‘ä»¬â€œ*å¢åŠ æ¸©åº¦*â€æ—¶çš„æ•ˆæœï¼Œè¯·æŸ¥çœ‹ [GitHub](https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/openai-api/openai-api-demo.ipynb)
    ä¸Šçš„é™„åŠ ä»£ç ã€‚ (è­¦å‘Šï¼šä¼šå˜å¾—æœ‰äº›å¥‡æ€ª)
- en: Conclusion
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Here I gave a beginner-friendly guide to the OpenAI Python API with example
    code. The biggest upside of using OpenAIâ€™s API is you can work with powerful LLMs
    without worrying about provisioning computational resources. The **downsides**,
    however, are **API calls cost money** and potential **security concerns** of sharing
    some types of data with a 3rd party (OpenAI).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘æä¾›äº†ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„ OpenAI Python API æŒ‡å—ï¼Œå…¶ä¸­åŒ…å«ç¤ºä¾‹ä»£ç ã€‚ä½¿ç”¨ OpenAI çš„ API æœ€å¤§çš„å¥½å¤„æ˜¯ä½ å¯ä»¥ä½¿ç”¨å¼ºå¤§çš„
    LLMsï¼Œè€Œä¸å¿…æ‹…å¿ƒè®¡ç®—èµ„æºçš„é…ç½®ã€‚ç„¶è€Œï¼Œ**ç¼ºç‚¹**æ˜¯ **API è°ƒç”¨éœ€è¦ä»˜è´¹**ï¼Œä»¥åŠä¸ç¬¬ä¸‰æ–¹ï¼ˆOpenAIï¼‰å…±äº«æŸäº›ç±»å‹æ•°æ®çš„æ½œåœ¨ **å®‰å…¨é—®é¢˜**ã€‚
- en: To avoid these downsides, we can turn to open-source LLM solutions. This will
    be the focus of the [next article](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    in this series, where weâ€™ll explore the Hugging Face Transformers library.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†é¿å…è¿™äº›ç¼ºç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥è½¬å‘å¼€æºçš„ LLM è§£å†³æ–¹æ¡ˆã€‚è¿™å°†æ˜¯æœ¬ç³»åˆ—ä¸­ [ä¸‹ä¸€ç¯‡æ–‡ç« ](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    çš„é‡ç‚¹ï¼Œæˆ‘ä»¬å°†åœ¨å…¶ä¸­æ¢ç´¢ Hugging Face Transformers åº“ã€‚
- en: 'ğŸ‘‰ **More on LLMs**: [Introduction](/a-practical-introduction-to-llms-65194dda1148)
    | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [Fine-tuning](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [Build an LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [Text Embeddings](/text-embeddings-classification-and-semantic-search-8291746220be)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 'ğŸ‘‰ **æ›´å¤šå…³äº LLMs çš„å†…å®¹**: [ç®€ä»‹](/a-practical-introduction-to-llms-65194dda1148) |
    [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)
    | [Prompt Engineering](https://medium.com/towards-data-science/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)
    | [å¾®è°ƒ](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)
    | [æ„å»º LLM](/how-to-build-an-llm-from-scratch-8c477768f1f9) | [QLoRA](/qlora-how-to-fine-tune-an-llm-on-a-single-gpu-4e44d6b5be32)
    | [RAG](https://medium.com/towards-data-science/how-to-improve-llms-with-rag-abdc132f76ac)
    | [æ–‡æœ¬åµŒå…¥](/text-embeddings-classification-and-semantic-search-8291746220be)'
- en: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![Shaw Talebi](../Images/02eefb458c6eeff7cd29d40c212e3b22.png)'
- en: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----230e4cae7971--------------------------------)'
- en: Large Language Models (LLMs)
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰
- en: '[View list](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----230e4cae7971--------------------------------)13
    stories![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----230e4cae7971--------------------------------)13ç¯‡æ•…äº‹![](../Images/82e865594c68f5307e75665842d197bb.png)![](../Images/b9436354721f807e0390b5e301be2119.png)![](../Images/59c8db581de77a908457dec8981f3c37.png)'
- en: Resources
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: èµ„æº
- en: '**Connect**: [My website](https://shawhintalebi.com/) | [Book a call](https://calendly.com/shawhintalebi)
    | [Ask me anything](https://shawhintalebi.com/contact/)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**è”ç³»**: [æˆ‘çš„ç½‘ç«™](https://shawhintalebi.com/) | [é¢„çº¦ç”µè¯](https://calendly.com/shawhintalebi)
    | [é—®æˆ‘ä»»ä½•é—®é¢˜](https://shawhintalebi.com/contact/)'
- en: '**Socials**: [YouTube ğŸ¥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç¤¾äº¤åª’ä½“**: [YouTube ğŸ¥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA)
    | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)'
- en: '**Support**: [Buy me a coffee](https://www.buymeacoffee.com/shawhint) â˜•ï¸'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ”¯æŒ**: [è¯·æˆ‘å–å’–å•¡](https://www.buymeacoffee.com/shawhint) â˜•ï¸'
- en: '[](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
    [## Get FREE access to every new story I write'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
    [## å…è´¹è·å–æˆ‘å†™çš„æ¯ä¸€ç¯‡æ–°æ•…äº‹'
- en: Get FREE access to every new story I write P.S. I do not share your email with
    anyone By signing up, you will create aâ€¦
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…è´¹è·å–æˆ‘å†™çš„æ¯ä¸€ç¯‡æ–°æ•…äº‹ P.S. æˆ‘ä¸ä¼šå°†ä½ çš„ç”µå­é‚®ä»¶åˆ†äº«ç»™ä»»ä½•äºº æ³¨å†Œåï¼Œä½ å°†åˆ›å»ºä¸€ä¸ªâ€¦
- en: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----230e4cae7971--------------------------------)
- en: '[1] [OpenAI Models documentation](https://platform.openai.com/docs/models)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [OpenAI æ¨¡å‹æ–‡æ¡£](https://platform.openai.com/docs/models)'
- en: '[2] [GPT-4 Availability & Completions API Deprecation](https://openai.com/blog/gpt-4-api-general-availability)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [GPT-4 å¯ç”¨æ€§ä¸å®Œæˆ API åºŸå¼ƒ](https://openai.com/blog/gpt-4-api-general-availability)'
- en: '[3] Temperature definition from [API reference](https://platform.openai.com/docs/api-reference/chat/create)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] æ¸©åº¦å®šä¹‰æ¥è‡ªäº [API å‚è€ƒ](https://platform.openai.com/docs/api-reference/chat/create)'
