- en: Analyze Scientific Publications with E-utilities and Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用 E-utilities 和 Python 分析科学出版物
- en: 原文：[https://towardsdatascience.com/analyze-scientific-publications-with-e-utilities-and-python-56f76de22959?source=collection_archive---------3-----------------------#2023-05-19](https://towardsdatascience.com/analyze-scientific-publications-with-e-utilities-and-python-56f76de22959?source=collection_archive---------3-----------------------#2023-05-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/analyze-scientific-publications-with-e-utilities-and-python-56f76de22959?source=collection_archive---------3-----------------------#2023-05-19](https://towardsdatascience.com/analyze-scientific-publications-with-e-utilities-and-python-56f76de22959?source=collection_archive---------3-----------------------#2023-05-19)
- en: How to gather data about scientific literature and discover trends
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何收集科学文献数据并发现趋势
- en: '[](https://neuraljojo.medium.com/?source=post_page-----56f76de22959--------------------------------)[![Jozsef
    Meszaros](../Images/6a2bd76b1ccc00305c19cb6d41d1771e.png)](https://neuraljojo.medium.com/?source=post_page-----56f76de22959--------------------------------)[](https://towardsdatascience.com/?source=post_page-----56f76de22959--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----56f76de22959--------------------------------)
    [Jozsef Meszaros](https://neuraljojo.medium.com/?source=post_page-----56f76de22959--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://neuraljojo.medium.com/?source=post_page-----56f76de22959--------------------------------)[![Jozsef
    Meszaros](../Images/6a2bd76b1ccc00305c19cb6d41d1771e.png)](https://neuraljojo.medium.com/?source=post_page-----56f76de22959--------------------------------)[](https://towardsdatascience.com/?source=post_page-----56f76de22959--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----56f76de22959--------------------------------)
    [Jozsef Meszaros](https://neuraljojo.medium.com/?source=post_page-----56f76de22959--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F71417ba6ebf5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-scientific-publications-with-e-utilities-and-python-56f76de22959&user=Jozsef+Meszaros&userId=71417ba6ebf5&source=post_page-71417ba6ebf5----56f76de22959---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----56f76de22959--------------------------------)
    ·15 min read·May 19, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56f76de22959&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-scientific-publications-with-e-utilities-and-python-56f76de22959&user=Jozsef+Meszaros&userId=71417ba6ebf5&source=-----56f76de22959---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F71417ba6ebf5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-scientific-publications-with-e-utilities-and-python-56f76de22959&user=Jozsef+Meszaros&userId=71417ba6ebf5&source=post_page-71417ba6ebf5----56f76de22959---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----56f76de22959--------------------------------)
    · 15分钟阅读 · 2023年5月19日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56f76de22959&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-scientific-publications-with-e-utilities-and-python-56f76de22959&user=Jozsef+Meszaros&userId=71417ba6ebf5&source=-----56f76de22959---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56f76de22959&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-scientific-publications-with-e-utilities-and-python-56f76de22959&source=-----56f76de22959---------------------bookmark_footer-----------)![](../Images/a7ae68b0dc6ab28cdb570c4867252f35.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56f76de22959&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanalyze-scientific-publications-with-e-utilities-and-python-56f76de22959&source=-----56f76de22959---------------------bookmark_footer-----------)![](../Images/a7ae68b0dc6ab28cdb570c4867252f35.png)'
- en: Photo by [Alex Block](https://unsplash.com/@alexblock?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Alex Block](https://unsplash.com/@alexblock?utm_source=medium&utm_medium=referral)
    摄影于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Staying on top of scientific research trends is essential for any scientist,
    science writer, or aspiring start-up founder. When it comes to searching biomedical
    science literature, most people will turn to Google Scholar, PubMed, or their
    favorite reference manager. As you might expect, these public-facing search tools
    offer ease of use but sacrifice efficiency, control, and scalability. Thus, they
    are generally not readily useful when it comes to data science. Instead, you’ll
    want to use the E-utilities offered by the National Center of Biotechnology Information
    (NCBI).[1] The scientific articles available from NCBI are stored within the PubMed
    database, which primarily covers life science research, but also a few journals
    related to chemistry and physics.[2]
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 跟上科学研究趋势对于任何科学家、科学作家或有志于创办初创企业的人都至关重要。谈到搜索生物医学科学文献，大多数人会转向Google Scholar、PubMed或他们喜欢的参考管理工具。正如你可能预期的，这些面向公众的搜索工具提供了易用性，但牺牲了效率、控制和可扩展性。因此，它们通常在数据科学中并不实用。相反，你将需要使用由国家生物技术信息中心（NCBI）提供的E-utilities。[1]
    NCBI提供的科学文章存储在PubMed数据库中，该数据库主要涵盖生命科学研究，但也包括一些化学和物理相关的期刊。[2]
- en: For data science applications, web-based search engines and popular reference
    managers won’t cut it
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于数据科学应用，基于网页的搜索引擎和流行的参考管理工具无法满足需求。
- en: The information on how to efficiently use NCBI for data science is strewn about
    various governmental and academic websites. Many of the resources were uploaded
    in the 1990’s, focused on searching for genetic sequences rather than primary
    literature publications, and accompanied by code examples written only in Perl.
    There was once a course on using NCBI’s E-Utilities that was hosted at NIH during
    the early 2000’s, for which Powerpoint “slidesets” along with obligatory clip-art
    illustrations are available [here](https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/).
    In this article, I will convey the lessons I have learned compiling information
    from these various sources and regular trial-and-error.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何高效使用NCBI进行数据科学的信息散布在各种政府和学术网站上。许多资源上传于1990年代，集中于遗传序列的搜索而非原始文献出版物，并且代码示例仅用Perl编写。曾经有一门关于使用NCBI
    E-Utilities的课程在2000年代初由NIH主办，Powerpoint“幻灯片集”以及必要的剪贴画插图可在[此处](https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/)获得。在本文中，我将传达我从这些各种来源中编纂的信息以及常规的反复试验中学到的经验。
- en: '**Note:** There are many types of data searchable from within NCBI, including
    genetic sequences, phylogenetic trees, 3-D structures, and other information.
    This article will be focused exclusively on searching **primary** **literature**.'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** NCBI中可搜索的数据类型很多，包括遗传序列、系统发育树、3-D结构及其他信息。本文将专注于搜索**原始** **文献**。'
- en: What kind of data science questions can be answered using NCBI?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NCBI可以回答哪些数据科学问题？
- en: 'There are many kinds of science questions answerable using NCBI. You could,
    for instance, create a cluster-map of author-provided keywords for articles to
    examine publishing trends over time, as I demonstrate at the end of this article.
    Additionally, you could build LLMs and NLP models using abstracts and text from
    publications to assist with making connections between literature. Here are the
    three steps I will cover in the article:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多种科学问题可以通过NCBI回答。例如，你可以创建一个作者提供的关键词的聚类图，以检查随时间变化的出版趋势，正如我在本文末尾演示的那样。此外，你还可以使用摘要和出版物中的文本构建LLMs和NLP模型，以帮助在文献之间建立联系。以下是我将在文章中覆盖的三个步骤：
- en: (1) querying the databases,
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 查询数据库，
- en: (2) returning results for multiple publications, and
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 返回多个出版物的结果，以及
- en: (3) retrieving similar articles and full text versions of articles.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 检索相似文章和文章的全文版本。
- en: At the end, I will provide a full documented code example to see how to carry
    out these three steps for a relatively large corpus (~10,000 articles) and an
    accompanying data visualization.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我将提供一个完整的文档代码示例，展示如何对一个相对较大的语料库（约10,000篇文章）进行这三个步骤，并附上数据可视化。
- en: Querying NCBI databases
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询NCBI数据库
- en: To query an NCBI database effectively, you’ll want to learn about certain E-utilities,
    define your search fields, and choose your search parameters — which control the
    way results are returned to your browser or in our case, we’ll use Python to query
    the databases.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效地查询NCBI数据库，你需要了解某些E-utilities，定义你的搜索字段，并选择你的搜索参数——这些参数控制结果如何返回到你的浏览器中，或者在我们的案例中，我们将使用Python来查询数据库。
- en: Four most useful E-utilities
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 四个最有用的E-utilities
- en: There are **nine E-utilities** available from NCBI, and they are all implemented
    as server-side fast CGI programs. This means you will access them by creating
    URLs which end in **.cgi** and specify query parameters after a question-mark,
    with parameters separated by ampersands. All of them, except for **EFetch**, will
    give you **either XML or JSON** outputs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: NCBI提供了**九个E-utilities**，它们都实现为服务器端的快速CGI程序。这意味着你将通过创建以**.cgi**结尾的URL来访问它们，并在问号后指定查询参数，参数之间用&符号分隔。除了**EFetch**之外，它们都会提供**XML或JSON**输出。
- en: '`**ESearch**`generates a list of ID numbers that meet your search query'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`**ESearch**`生成符合你搜索查询的ID号码列表'
- en: 'The following E-Utilities can be used with one or more ID numbers:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下E-Utilities可以与一个或多个ID号码一起使用：
- en: '`**ESummary**`journal, author list, grants, dates, references, publication
    type'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`**ESummary**`期刊、作者列表、资助、日期、参考文献、出版类型'
- en: '`**EFetch**`**XML ONLY** all of what `**ESummary**` provides as well as an
    abstract, list of grants used in the research, institutions of authors, and MeSH
    keywords'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`**EFetch**`**仅XML**，提供`**ESummary**`的所有内容，以及摘要、用于研究的资助列表、作者机构和MeSH关键词'
- en: '`**ELink**`provides a list of links to related citations using computed similarity
    score ***as well as providing a link to the published item*** [your gateway to
    the full-text of the article]'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`**ELink**`提供与相关引文的链接列表，使用计算出的相似度分数***同时提供已发布项目的链接*** [你通向文章全文的门户]'
- en: 'The NCBI hosts 38 databases across their servers, related to a variety of data
    that goes beyond literature citations. To get a complete list of current databases,
    you can use **EInfo** withoutsearch terms:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: NCBI在其服务器上托管了38个数据库，这些数据库涉及各种数据，超出了文献引用的范围。要获取当前数据库的完整列表，你可以使用**EInfo**而无需搜索词：
- en: '`[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi)`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi)`'
- en: Each database will vary in how it can be accessed and the information it returns.
    For our purposes, we’ll focus on the *pubmed* and *pmc* databases because these
    are where scientific literature are searched and retrieved.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个数据库在如何访问及返回的信息方面会有所不同。为了我们的目的，我们将重点关注*pubmed*和*pmc*数据库，因为这些是搜索和检索科学文献的地方。
- en: The two most important things to learn about searching NCBI are **search fields**
    and **outputs**. The **search fields are numer**ous and will depend on the database.
    The outputs are more straightforward and learning how to use the outputs is essential,
    especially for doing large searches.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 了解搜索NCBI的两个最重要的方面是**搜索字段**和**输出**。**搜索字段**种类繁多，将取决于数据库。输出则更为直接，学习如何使用输出是至关重要的，特别是进行大规模搜索时。
- en: Search fields
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索字段
- en: 'You won’t be able to truly harness the potential of E-utilities without knowing
    about the available search fields. You can find a full list of these search fields
    on the [NLM website](https://www.nlm.nih.gov/bsd/mms/medlineelements.html) along
    with a description of each, but for the ***most accurate list of search terms
    specific to a database***, you’ll want to parse your own XML list using this link:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你将无法真正利用E-utilities的潜力，如果你不了解可用的搜索字段。你可以在[NLM网站](https://www.nlm.nih.gov/bsd/mms/medlineelements.html)上找到这些搜索字段的完整列表及其描述，但要获取***特定数据库的最准确搜索词列表***，你需要使用这个链接解析自己的XML列表：
- en: '`[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi?db=pubmed](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi?db=pubmed)`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`[https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi?db=pubmed](https://eutils.ncbi.nlm.nih.gov/entrez/eutils/einfo.fcgi?db=pubmed)`'
- en: with the **db** flag set to the database (we will use *pubmed* for this article,
    but literature is also available through *pmc*).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**db**标志设置为数据库（本文将使用*pubmed*，但文献也可以通过*pmc*获取）。'
- en: '![](../Images/f468c29de103dbfc12170620a136f19f.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f468c29de103dbfc12170620a136f19f.png)'
- en: 'A list of search fields for querying PubMed MEDLINE records. (Source: [https://www.nlm.nih.gov/bsd/mms/medlineelements.html](https://www.nlm.nih.gov/bsd/mms/medlineelements.html)`)`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 用于查询PubMed MEDLINE记录的搜索字段列表。（来源：[https://www.nlm.nih.gov/bsd/mms/medlineelements.html](https://www.nlm.nih.gov/bsd/mms/medlineelements.html)）`
- en: One especially useful search field is the Medline Subject Headings (**MeSH**).[3]
    Indexers, who are experts in the field, maintain the PubMed database and use MeSH
    terms to reflect the subject matter of journal articles as they are published.
    Each indexed publication is typically described by 10 to 12 carefully selected
    MeSH terms by the indexers. If no search terms are specified, then queries will
    be executed against every search term available in the database queried.[4]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别有用的搜索字段是 Medline 主题词 (**MeSH**)。索引专家维护 PubMed 数据库，并使用 MeSH 术语来反映期刊文章的主题。每篇被索引的出版物通常由
    10 到 12 个由索引专家精心挑选的 MeSH 术语描述。如果未指定搜索词，则查询将针对数据库中所有可用的搜索词执行。
- en: Query parameters
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询参数
- en: 'Each of the E-utilities accepts multiple query parameters through the URL line
    which you can use to control the type and amount of output returned from a query.
    This is where you can set the number of search results retrieved or the dates
    searched. Here are a list of the more important parameters:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 E-utility 都通过 URL 行接受多个查询参数，你可以用来控制从查询返回的输出类型和数量。这是你可以设置检索结果数量或搜索日期的地方。以下是一些更重要的参数列表：
- en: '**Database parameter:**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据库参数：**'
- en: '`db` should be set to the database you are interested in searching — *pubmed*
    or *pmc* for scientific literature'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`db` 应设置为你感兴趣的数据库 — *pubmed* 或 *pmc* 用于科学文献'
- en: '**Date parameters:** You can get more control over the date by using search
    fields, [pdat] for example for the publication date, but date parameters provide
    a more convenient way to constrain results.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**日期参数：** 你可以通过使用搜索字段（例如 [pdat] 代表出版日期）来获得对日期的更多控制，但日期参数提供了一种更方便的方式来限制结果。'
- en: '`reldate` the days to be searched relative to the current date, set reldate=1
    for the most recent day'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reldate` 相对于当前日期的天数，设置 reldate=1 以查询最近的一天'
- en: '`mindate` and `maxdate` specify date according to the format YYYY/MM/DD, YYYY,
    or YYYY/MM **(a query must contain both** `mindate` **and** `maxdate` **parameters)**'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mindate` 和 `maxdate` 根据格式 YYYY/MM/DD、YYYY 或 YYYY/MM 指定日期 **（查询必须同时包含 `mindate`
    和 `maxdate` 参数）**'
- en: '`datetype` sets the type of date when you query by date — options are ‘mdat’
    (modification date), ‘pdat’ (publication date) and ‘edat’ (Entrez date)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`datetype` 设置按日期查询时的日期类型 — 选项包括 ‘mdat’（修改日期）、‘pdat’（出版日期）和 ‘edat’（Entrez 日期）'
- en: '**Retrieval parameters:**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**检索参数：**'
- en: '`rettype` the type of information to return (for literature searches, use the
    default setting)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rettype` 返回的信息类型（对于文献搜索，使用默认设置）'
- en: '`retmode` format of the output (XML is the default, though all E-utilities
    except fetch do support JSON)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retmode` 输出格式（XML 为默认格式，虽然除 fetch 外的所有 E-utilities 都支持 JSON）'
- en: '`retmax` is the maximum number of records to return — ***the default is 20
    and the maximum value is 10,000*** (ten thousand)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retmax` 是返回记录的最大数量 — ***默认值为 20，最大值为 10,000***（一万）'
- en: '`retstart` given a list of hits for a query, `retstart` specifies the index
    (useful for when your search exceeds the ten thousand maximum)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retstart` 给定查询的命中列表，`retstart` 指定索引（当搜索超出一万最大值时很有用）'
- en: '`cmd` this is only relevant to `**ELink**` and is used to specify whether to
    return IDs of similar articles or URLs to full-texts'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cmd` 仅与 `**ELink**` 相关，用于指定是否返回类似文章的 IDs 或全文的 URLs'
- en: Use Python to execute queries and store results
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 执行查询并存储结果
- en: Once we know about the E-Utilities, have chosen our search fields, and decided
    upon query parameters, we’re ready to execute queries and store the results —
    even for multiple pages.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们了解了 E-Utilities，选择了搜索字段，并决定了查询参数，我们就准备好执行查询并存储结果 — 甚至是多个页面的结果。
- en: While you don’t specifically need to use Python to use the E-utilities, it does
    make it much easier to parse, store, and analyze the results of your queries.
    Here’s how to get started on your data science project.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你不需要专门使用 Python 来使用 E-utilities，但它确实使解析、存储和分析查询结果变得更加容易。下面是如何开始你的数据科学项目。
- en: Let’s say you want to search MeSH terms for the term “myoglobin” between 2022
    and 2023\. You’ll set your **retmax** to 50 for now, but remember ***the max is
    10,000 and you can query at a rate of 3/s.***
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你要在 2022 年和 2023 年之间搜索“肌红蛋白”的 MeSH 术语。你现在将 **retmax** 设置为 50，但请记住 ***最大值为
    10,000，查询速率为 3/s。***
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/fcd81481c9d922509e560a15b150f2a0.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcd81481c9d922509e560a15b150f2a0.png)'
- en: The output of the **esearch** query from above.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 上述 **esearch** 查询的输出。
- en: The results are returned as a list of IDs, which can be used in a subsequent
    search within the database you queried. Note that **“count”** shows there are
    154 results for this query, which you could use if you wanted to get a total count
    of publications for a certain set of search terms. If you wanted to return IDs
    for all the publication, you’d set the **retmax** parameter to the count, or 154\.
    In general, I set this to a very high number so I can retrieve all of the results
    and store them.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 结果以ID列表的形式返回，可以在你查询的数据库中进行后续搜索。注意，**“count”**显示这个查询有154个结果，你可以用来获取某组搜索词的总出版物数。如果你想返回所有出版物的ID，你需要将**retmax**参数设置为计数值或154。一般来说，我将其设置为一个非常大的数字，以便能够检索所有结果并进行存储。
- en: '**Boolean searching** is easy with PubMed and it only requires adding `+OR+`,
    `+NOT+`, or `+AND+` to the URL between search terms. For example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在PubMed中，**布尔搜索**很简单，只需在搜索词之间添加`+OR+`、`+NOT+`或`+AND+`到网址中即可。例如：
- en: '`[http://eutils.ncbi.nlm.nih.gov/entrez//eutils/esearch.fcgi/?db=pubmed&term=**CEO[cois]+OR+CTO[cois]+OR+CSO[cois]**&mindate=2022&maxdate=2023&retmax=10000](http://eutils.ncbi.nlm.nih.gov/entrez//eutils/esearch.fcgi/?db=pubmed&term=CEO%5Bcois%5D+OR+CTO%5Bcois%5D+OR+CSO%5Bcois%5D&mindate=2022&maxdate=2023&retmax=10000)`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`[http://eutils.ncbi.nlm.nih.gov/entrez//eutils/esearch.fcgi/?db=pubmed&term=**CEO[cois]+OR+CTO[cois]+OR+CSO[cois]**&mindate=2022&maxdate=2023&retmax=10000](http://eutils.ncbi.nlm.nih.gov/entrez//eutils/esearch.fcgi/?db=pubmed&term=CEO%5Bcois%5D+OR+CTO%5Bcois%5D+OR+CSO%5Bcois%5D&mindate=2022&maxdate=2023&retmax=10000)`'
- en: These search strings can constructed using Python. In the following steps, we’ll
    parse the results using Python’s *json package* to get the IDs for each of the
    publications returned. The IDs can then be used to create a string — this string
    of IDs can be used by the other E-Utilities to return information about the publications.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些搜索字符串可以使用Python构造。在接下来的步骤中，我们将使用Python的*json包*解析结果，以获取每篇返回出版物的ID。这些ID可以用于创建一个字符串——这个ID字符串可以被其他E-Utilities使用，以返回关于出版物的信息。
- en: Use ESummary to return information about publications
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ESummary来返回关于出版物的信息。
- en: The purpose of **ESummary** is to return data that you might expect to see in
    a paper’s citation (date of publication, page numbers, authors, etc). Once you
    have a result in the form of a list of IDs from **ESearch** (in the step above),
    you can join this list into a long URL.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**ESummary**的目的是返回你可能期望在论文引用中看到的数据（出版日期、页码、作者等）。一旦你获得了**ESearch**形式的ID列表（在上一步中），你可以将这个列表拼接成一个长网址。'
- en: The limit for a URL is 2048 characters, and each publication’s ID is 8 characters
    long, so to be safe, you should split your list of links up into batches of 250
    if you have a list larger than 250 IDs. See my notebook at the bottom of the article
    for an example.
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: URL的限制是2048个字符，每篇出版物的ID长度为8个字符，因此，为了安全起见，如果你的ID列表超过250个，你应该将链接列表分成250个一批。有关示例，请参见文章底部的笔记本。
- en: 'The results from an **ESummary** are returned in JSON format and can include
    a link to the paper’s full-text:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**ESummary**的结果以JSON格式返回，并可能包括链接到论文全文的链接。'
- en: '[PRE1]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can again use json to parse *summary_list*. When using the json package,
    you can browse the fields of each individual article by using summary[‘result’][id
    as string], as in the example below:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次使用json来解析*summary_list*。使用json包时，可以通过summary[‘result’][id as string]来浏览每篇文章的字段，如下例所示：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We can create a dataframe to capture the ID for each article along with the
    name of the journal, the publication date, title of the article, a URL for retrieving
    the full text, as well as the first and last author.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个数据框架来捕捉每篇文章的ID，以及期刊名称、出版日期、文章标题、检索全文的网址以及第一作者和最后一作者。
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Below is a list of all the different fields that **ESummary** returns so you
    can make your own database:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是**ESummary**返回的所有不同字段的列表，以便你可以创建自己的数据库：
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Use EFetch when you want abstracts, keywords, and other details (XML output
    only)
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当你需要摘要、关键词和其他细节（仅限XML输出）时，请使用EFetch。
- en: 'We can use **EFetch** to return similar fields as **ESummary**, with the caveat
    that the ***result is returned in XML only***. There are several interesting additional
    fields in **EFetch** which include: the abstract, author-selected keywords, the
    Medline Subheadings (MeSH terms), grants that sponsored the research, conflict
    of interest statements, a list of chemicals used in the research, and a complete
    list of all the references cited by the paper. Here’s how you would use BeautifulSoupto
    obtain some of these items:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用**EFetch**返回类似于**ESummary**的字段，但有个警告是***结果仅以XML格式返回***。**EFetch**中还有几个有趣的附加字段，包括：摘要、作者选择的关键词、Medline子标题（MeSH术语）、资助研究的拨款、冲突声明、研究中使用的化学品列表，以及论文引用的所有参考文献的完整列表。以下是如何使用BeautifulSoup获取这些项目的一部分：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we can use this table to search abstracts, conflict of interest statements,
    or make visuals that connect different fields of research using MeSH headings
    and reference lists. There are of course many other tags that you could explore,
    returned by **EFetch**, here’s how you can see them all using BeautifulSoup:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用这个表格来搜索摘要、冲突声明，或使用MeSH主题和参考列表制作连接不同研究领域的可视化图表。还有许多其他标签你可以探索，由**EFetch**返回，以下是如何使用BeautifulSoup查看所有这些标签：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Using ELink to retrieve similar publications, and full-text links**'
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**使用ELink检索相似出版物和全文链接**'
- en: 'You may want to find articles similar to the ones returned by your search query.
    These articles are grouped according to a similarity score using a probabilistic
    topic-based model.[5] To retrieve the similarity scores for a given ID, you must
    pass **cmd=neighbor_score** in your call to **ELink**. Here’s an example for one
    article:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想找一些与你的搜索查询返回的文章相似的文章。这些文章根据使用概率主题模型的相似度评分进行分组。[5] 要检索给定ID的相似度评分，你必须在调用**ELink**时传递**cmd=neighbor_score**。以下是一个文章的示例：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The other function of **ELink** is to provide full-text links to an article
    based on its ID, which can be returned if you pass **cmd=prlinks** to **ELink**
    instead.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**ELink**的另一个功能是根据文章的ID提供全文链接，如果你将**cmd=prlinks**传递给**ELink**，则可以返回这些链接。'
- en: If you wish to access only those full-text links that are free to the public,
    you will want to use links that contain “pmc” (PubMed Central). Accessing articles
    behind a paywall may require subscription through a University—**before downloading
    a large corpus of full-text articles through a paywall, you should consult with
    your organization’s librarians.**
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你只希望访问那些对公众免费的全文链接，你需要使用包含“pmc”（PubMed Central）的链接。访问付费墙后的文章可能需要通过大学订阅——**在通过付费墙下载大量全文文章之前，你应该咨询你所在组织的图书管理员。**
- en: 'Here is a code snippet of how you could retrieve the links for a publication:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个如何检索出版物链接的代码片段：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can also retrieve links for multiple publications in one call to **ELink**,
    as I show below:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在一次调用**ELink**时检索多个出版物的链接，如下所示：
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Example data visualization: Scientific publications from C-suite authors'
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例数据可视化：来自C-suite作者的科学出版物
- en: Occasionally, a scientific publication will be authored by someone who is a
    CEO, CSO, or CTO of a company. With PubMed, we have the ability to analyze the
    latest life science industry trends. Conflict of interest statements, which were
    introduced as a search term in PubMed during 2017,[6] give a lens into which author-provided
    keywords are appearing in publications where a C-suite executive is disclosed
    as an author. In other words, the keywords chosen by the authors to describe their
    finding. To carry out this function, simply include **CEO[cois]+OR+CSO[cois]+OR+CTO[cois]**
    assearch term in your URL, retrieve all of the results returned, and extract the
    keywords from the resulting XML output for each publication. Each publication
    contains between 4–8 keywords. Once the corpus is generated, you can quantify
    keyword frequency per year within the corpus as ***the number of publications
    in a year specifying a keyword, divided by the number of publications for that
    year.***
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，科学出版物的作者可能是公司的CEO、CSO或CTO。利用PubMed，我们可以分析最新的生命科学行业趋势。冲突声明（在2017年作为搜索词引入PubMed）提供了一个视角，了解哪些作者提供的关键词出现在声明了C-suite执行官身份的出版物中。换句话说，就是作者用来描述其发现的关键词。要实现这个功能，只需在URL中包含**CEO[cois]+OR+CSO[cois]+OR+CTO[cois]**作为搜索词，检索所有返回的结果，然后从每个出版物的XML输出中提取关键词。每个出版物包含4到8个关键词。一旦生成语料库，你可以按***每年指定关键词的出版物数量除以该年的出版物总数***来量化关键词的频率。
- en: For example, if 10 publications list the keyword “cancer” and there are 1000
    publications that year, the keyword frequency would be 0.001\. Using the seaborn
    clustermap module with the keyword frequencies you can generate a visualization
    where darker bands indicate a larger value of keyword frequency/year (I have dropped
    COVID-19 and SARS-COV-2 from the visualization as they were both represented at
    frequencies far greater 0.05, predictably). Each year, approximately 1000–1500
    papers were returned.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果10篇出版物列出了关键词“癌症”，而该年共有1000篇出版物，那么关键词频率将是0.001。使用seaborn clustermap模块和关键词频率，你可以生成一个可视化图，其中较深的色带表示关键词频率/年值较大（我已经从可视化中去掉了COVID-19和SARS-COV-2，因为它们的频率远大于0.05，正如预期的那样）。每年，大约有1000到1500篇论文被检索出来。
- en: '![](../Images/4c46cca20553c590a80efa73168b43ff.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c46cca20553c590a80efa73168b43ff.png)'
- en: Clustermap of author-specified keyword frequencies for publications with a C-suite
    author listed, generated by the author using Seaborn’s clustermap module.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Seaborn的clustermap模块生成的，列出C-suite作者的出版物的作者指定关键词频率的热图。
- en: 'From this visualization, several insights about the corpus of publications
    with C-suite authors listed becomes clear. First, one of the most distinct clusters
    (at the bottom) contains keywords that have been strongly represented in the corpus
    for the past five years: cancer, machine learning, biomarkers, artificial intelligence
    — just to name a few. Clearly, industry is heavily active and publishing in these
    areas. A second cluster, near the middle of the figure, shows keywords that disappeared
    from the corpus after 2018, including physical activity, public health, children,
    mass spectrometry, and mhealth (or mobile health). It’s not to say that these
    areas are not being developed in industry, just that the publication activity
    has slowed. Looking at the bottom right of the figure, you can extract terms which
    have appeared more recently in the corpus, including liquid biopsy and precision
    medicine — which are indeed two very “hot” areas of medicine at the moment. By
    examining the publications further, you could extract the names of the companies
    and other information of interest. Below is the code I wrote to generate this
    visual:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个可视化中，几个关于列出C-suite作者的出版物的数据洞察变得清晰。首先，一个最为明显的簇（位于底部）包含了在过去五年中在数据集中强烈出现的关键词：癌症、机器学习、生物标志物、人工智能——仅举几个例子。显然，行业在这些领域非常活跃并进行大量出版。第二个簇，位于图中部附近，展示了自2018年后从数据集中消失的关键词，包括身体活动、公共卫生、儿童、质谱和mhealth（或移动健康）。这并不是说这些领域在行业中没有发展，只是出版活动有所减缓。查看图的右下角，你可以提取出最近在数据集中出现的术语，包括液体活检和精准医学——这些确实是目前医学领域的两个非常“热门”的领域。通过进一步检查出版物，你可以提取出公司的名称和其他感兴趣的信息。下面是我编写的生成此可视化的代码：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Conclusion
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: After reading this article, you should be ready to go from crafting highly tailored
    search queries of the scientific literature all the way to generating data visualizations
    for closer scrutiny. While there are other more complex ways to access and store
    articles using additional features of the various E-utilities, I have tried to
    present the most straightforward set of operations that should apply to most use
    cases for a data scientist interested in scientific publishing trends. By familiarizing
    yourself with the E-utilities as I have presented here, you will go far toward
    understanding the trends and connections within scientific literature. As mentioned,
    there are many items beyond publications that can be unlocked through mastering
    the E-utilities and how they operate within the larger universe of NCBI databases.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完这篇文章后，你应该能够从制定高度定制的科学文献搜索查询，到生成数据可视化以进行更深入的审查。虽然有其他更复杂的方法可以使用各种E-utilities的附加功能来访问和存储文章，但我尝试展示了最简单的一组操作，应该适用于对科学出版趋势感兴趣的数据科学家。通过熟悉我所呈现的E-utilities，你将能更好地理解科学文献中的趋势和联系。如前所述，通过掌握E-utilities及其在NCBI数据库广阔宇宙中的操作，还有许多其他项目可以解锁。
- en: To learn more about accessing NCBI, [you can download course materials for a
    set of NIH courses that were held up until 2008](https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/)
    or check out the references below. To stay up-to-date about changes to the E-Utilities,
    including a potentially new API, you may want to sign up for the NCBI’s very 1990’s
    looking mailing list, [at this website](https://www.ncbi.nlm.nih.gov/mailman/listinfo/utilities-announce/).
    Lastly, searching arxiv.org for “PubMed” will return a handful of results that
    can motivate research projects using this data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于访问NCBI的信息，[你可以下载2008年之前举办的一系列NIH课程的材料](https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/)或查看下面的参考资料。要保持对E-Utilities的更新，包括可能的新API，你可能想要订阅NCBI那看起来非常90年代的邮件列表，[请访问这个网站](https://www.ncbi.nlm.nih.gov/mailman/listinfo/utilities-announce/)。最后，在arxiv.org上搜索“PubMed”将返回一些结果，这些结果可以激发利用这些数据的研究项目。
- en: References
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [https://www.nlm.nih.gov/bsd/difference.html#:~:text=MEDLINE%20is%20the%20largest%20subset,Journal%20Categories%20filter%20called%20MEDLINE](https://www.nlm.nih.gov/bsd/difference.html#:~:text=MEDLINE%20is%20the%20largest%20subset,Journal%20Categories%20filter%20called%20MEDLINE)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://www.nlm.nih.gov/bsd/difference.html#:~:text=MEDLINE%20is%20the%20largest%20subset,Journal%20Categories%20filter%20called%20MEDLINE](https://www.nlm.nih.gov/bsd/difference.html#:~:text=MEDLINE%20is%20the%20largest%20subset,Journal%20Categories%20filter%20called%20MEDLINE)'
- en: '[2] Chapman D. Advanced search features of PubMed. J Can Acad Child Adolesc
    Psychiatry. 2009 Feb;18(1):58–9\. PMID: 19270851; PMCID: PMC2651214.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Chapman D. PubMed的高级搜索功能。J Can Acad Child Adolesc Psychiatry. 2009年2月；18(1):58–9\.
    PMID: 19270851; PMCID: PMC2651214.'
- en: '[3] Sayers E. The E-utilities In-Depth: Parameters, Syntax and More. 2009 May
    29 [Updated 2022 Nov 30]. In: Entrez Programming Utilities Help [Internet]. Bethesda
    (MD): National Center for Biotechnology Information (US); 2010-. Available from:
    [https://www.ncbi.nlm.nih.gov/books/NBK25499/](https://www.ncbi.nlm.nih.gov/books/NBK25499/)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Sayers E. E-utilities深入探讨：参数、语法及更多内容。2009年5月29日 [更新于2022年11月30日]。见：Entrez编程实用工具帮助
    [互联网]。Bethesda (MD): 国家生物技术信息中心 (US); 2010-. 可从 [https://www.ncbi.nlm.nih.gov/books/NBK25499/](https://www.ncbi.nlm.nih.gov/books/NBK25499/)
    获得'
- en: '[4] [https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/Oct.2007/slides/Lecture1.pdf](https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/Oct.2007/slides/Lecture1.pdf)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/Oct.2007/slides/Lecture1.pdf](https://ftp.ncbi.nlm.nih.gov/pub/PowerTools/eutils/Oct.2007/slides/Lecture1.pdf)'
- en: '[5] Lin J, Wilbur WJ. PubMed related articles: a probabilistic topic-based
    model for content similarity. BMC Bioinformatics. 2007 Oct 30;8:423\. doi: 10.1186/1471–2105–8–423\.
    PMID: 17971238; PMCID: PMC2212667\. Available from: [https://pubmed.ncbi.nlm.nih.gov/17971238/](https://pubmed.ncbi.nlm.nih.gov/17971238/)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Lin J, Wilbur WJ. PubMed相关文献：基于主题的内容相似性概率模型。BMC Bioinformatics. 2007年10月30日；8:423\.
    doi: 10.1186/1471–2105–8–423\. PMID: 17971238; PMCID: PMC2212667\. 可从 [https://pubmed.ncbi.nlm.nih.gov/17971238/](https://pubmed.ncbi.nlm.nih.gov/17971238/)
    获得'
- en: '[6] [https://library.mskcc.org/blog/2019/07/conflict-of-interest-statement-field-in-pubmed/](https://library.mskcc.org/blog/2019/07/conflict-of-interest-statement-field-in-pubmed/)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [https://library.mskcc.org/blog/2019/07/conflict-of-interest-statement-field-in-pubmed/](https://library.mskcc.org/blog/2019/07/conflict-of-interest-statement-field-in-pubmed/)'
