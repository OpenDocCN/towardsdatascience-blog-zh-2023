- en: How Meta’s AI Generates Music Based on a Reference Melody
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Meta的人工智能如何基于参考旋律生成音乐
- en: 原文：[https://towardsdatascience.com/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783?source=collection_archive---------2-----------------------#2023-06-23](https://towardsdatascience.com/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783?source=collection_archive---------2-----------------------#2023-06-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783?source=collection_archive---------2-----------------------#2023-06-23](https://towardsdatascience.com/how-metas-ai-generates-music-based-on-a-reference-melody-de34acd783?source=collection_archive---------2-----------------------#2023-06-23)
- en: MusicGen, analyzed
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MusicGen，分析
- en: '[](https://medium.com/@maxhilsdorf?source=post_page-----de34acd783--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----de34acd783--------------------------------)[](https://towardsdatascience.com/?source=post_page-----de34acd783--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----de34acd783--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----de34acd783--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maxhilsdorf?source=post_page-----de34acd783--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----de34acd783--------------------------------)[](https://towardsdatascience.com/?source=post_page-----de34acd783--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----de34acd783--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----de34acd783--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd0c085a74ae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-metas-ai-generates-music-based-on-a-reference-melody-de34acd783&user=Max+Hilsdorf&userId=d0c085a74ae8&source=post_page-d0c085a74ae8----de34acd783---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----de34acd783--------------------------------)
    ·10 min read·Jun 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fde34acd783&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-metas-ai-generates-music-based-on-a-reference-melody-de34acd783&user=Max+Hilsdorf&userId=d0c085a74ae8&source=-----de34acd783---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd0c085a74ae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-metas-ai-generates-music-based-on-a-reference-melody-de34acd783&user=Max+Hilsdorf&userId=d0c085a74ae8&source=post_page-d0c085a74ae8----de34acd783---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----de34acd783--------------------------------)
    ·10分钟阅读·2023年6月23日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fde34acd783&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-metas-ai-generates-music-based-on-a-reference-melody-de34acd783&user=Max+Hilsdorf&userId=d0c085a74ae8&source=-----de34acd783---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde34acd783&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-metas-ai-generates-music-based-on-a-reference-melody-de34acd783&source=-----de34acd783---------------------bookmark_footer-----------)![](../Images/c46f4b570f4f5b87a647a152468cb6be.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fde34acd783&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-metas-ai-generates-music-based-on-a-reference-melody-de34acd783&source=-----de34acd783---------------------bookmark_footer-----------)![](../Images/c46f4b570f4f5b87a647a152468cb6be.png)'
- en: Image by author.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。
- en: MusicGen by Meta
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Meta的MusicGen
- en: On June 13th, 2023, Meta (formerly Facebook) made waves in the music and AI
    communities with the release of their generative music model, MusicGen. This model
    not only surpasses Google’s MusicLM, which was launched earlier this year, in
    terms of capabilities but is also trained on licensed music data and open-sourced
    for non-commercial use.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年6月13日，Meta（前身为Facebook）在音乐和人工智能领域引起了轰动，发布了他们的生成音乐模型MusicGen。这个模型不仅在能力上超越了今年早些时候发布的Google
    MusicLM，还使用了许可的音乐数据进行训练，并且为了非商业用途进行了开源。
- en: This means that you can not only read the [research paper](https://arxiv.org/abs/2306.05284)
    or listen to [demos](https://ai.honu.io/papers/musicgen/) but also copy their
    code from [GitHub](https://github.com/facebookresearch/audiocraft) or experiment
    with the model in a web app on [HuggingFace](https://huggingface.co/spaces/facebook/MusicGen).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着你不仅可以阅读[研究论文](https://arxiv.org/abs/2306.05284)或听[示例](https://ai.honu.io/papers/musicgen/)，还可以从[GitHub](https://github.com/facebookresearch/audiocraft)复制它们的代码，或者在[HuggingFace](https://huggingface.co/spaces/facebook/MusicGen)的网页应用中实验该模型。
- en: In addition to generating audio from a text prompt, MusicGen can also generate
    music based on a given reference melody, a feature known as melody conditioning.
    In this blog post, I will demonstrate how Meta implemented this useful and fascinating
    functionality into their model. But before we delve into that, let’s first understand
    how melody conditioning works in practice.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 除了根据文本提示生成音频外，MusicGen还可以基于给定的参考旋律生成音乐，这一功能被称为旋律条件。在这篇博客文章中，我将展示Meta如何将这一有用且迷人的功能实现到他们的模型中。但在我们**深入探讨**之前，让我们首先了解旋律条件在实践中的工作原理。
- en: Showcase
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 展示
- en: Base Track
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础曲目
- en: The following is a short electronic music snippet that I produced for this article.
    It features electronic drums, a dominant 808 bass and two syncopated synths. When
    listening to it, try to identify the “main melody” of the track.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我为本文制作的短电子音乐片段。它包含电子鼓、突出的808低音和两个切分的合成器。在聆听时，试着识别曲目的“主旋律”。
