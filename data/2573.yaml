- en: Text Classification with Transformer Encoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Transformer 编码器进行文本分类
- en: 原文：[https://towardsdatascience.com/text-classification-with-transformer-encoders-1dcaa50dabae?source=collection_archive---------4-----------------------#2023-08-11](https://towardsdatascience.com/text-classification-with-transformer-encoders-1dcaa50dabae?source=collection_archive---------4-----------------------#2023-08-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/text-classification-with-transformer-encoders-1dcaa50dabae?source=collection_archive---------4-----------------------#2023-08-11](https://towardsdatascience.com/text-classification-with-transformer-encoders-1dcaa50dabae?source=collection_archive---------4-----------------------#2023-08-11)
- en: Step-by-step explanation of utilizing Transformer encoders to classify text
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用 Transformer 编码器进行文本分类的逐步说明
- en: '[](https://medium.com/@marcellusruben?source=post_page-----1dcaa50dabae--------------------------------)[![Ruben
    Winastwan](../Images/15ad0dd03bf5892510abdf166a1e91e1.png)](https://medium.com/@marcellusruben?source=post_page-----1dcaa50dabae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1dcaa50dabae--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1dcaa50dabae--------------------------------)
    [Ruben Winastwan](https://medium.com/@marcellusruben?source=post_page-----1dcaa50dabae--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@marcellusruben?source=post_page-----1dcaa50dabae--------------------------------)[![Ruben
    Winastwan](../Images/15ad0dd03bf5892510abdf166a1e91e1.png)](https://medium.com/@marcellusruben?source=post_page-----1dcaa50dabae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1dcaa50dabae--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1dcaa50dabae--------------------------------)
    [Ruben Winastwan](https://medium.com/@marcellusruben?source=post_page-----1dcaa50dabae--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5dae9da73c9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-with-transformer-encoders-1dcaa50dabae&user=Ruben+Winastwan&userId=5dae9da73c9b&source=post_page-5dae9da73c9b----1dcaa50dabae---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1dcaa50dabae--------------------------------)
    ·15 min read·Aug 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1dcaa50dabae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-with-transformer-encoders-1dcaa50dabae&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----1dcaa50dabae---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5dae9da73c9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-with-transformer-encoders-1dcaa50dabae&user=Ruben+Winastwan&userId=5dae9da73c9b&source=post_page-5dae9da73c9b----1dcaa50dabae---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1dcaa50dabae--------------------------------)
    · 15 分钟阅读 · 2023年8月11日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1dcaa50dabae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-with-transformer-encoders-1dcaa50dabae&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----1dcaa50dabae---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dcaa50dabae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-with-transformer-encoders-1dcaa50dabae&source=-----1dcaa50dabae---------------------bookmark_footer-----------)![](../Images/e7af55b2adc4de88204e68d923263996.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1dcaa50dabae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-classification-with-transformer-encoders-1dcaa50dabae&source=-----1dcaa50dabae---------------------bookmark_footer-----------)![](../Images/e7af55b2adc4de88204e68d923263996.png)'
- en: Photo by [Mel Poole](https://unsplash.com/@melpoole?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/lBsvzgYnzPU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Mel Poole](https://unsplash.com/@melpoole?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来自 [Unsplash](https://unsplash.com/photos/lBsvzgYnzPU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Transformer is, without a doubt, one of the most important breakthroughs in
    the field of deep learning. The encoder-decoder architecture of this model has
    proven to be powerful in cross-domain applications.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 无疑是深度学习领域最重要的突破之一。该模型的编码器-解码器架构在跨领域应用中表现出强大的能力。
- en: Initially, Transformer was used solely for language modeling tasks, such as
    machine translation, text generation, text classification, question-answering,
    etc. However, recently, Transformer has also been used for computer vision tasks,
    such as image classification, object detection, and semantic segmentation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，Transformer 仅用于语言建模任务，如机器翻译、文本生成、文本分类、问答等。然而，最近 Transformer 也被用于计算机视觉任务，如图像分类、物体检测和语义分割。
- en: Given its popularity and the existence of numerous Transformer-based sophisticated
    models such as BERT, Vision-Transformer, Swin-Transformer, and the GPT family,
    it is crucial for us to understand the inner workings of the Transformer architecture.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于其受欢迎程度以及存在许多基于 Transformer 的复杂模型，如 BERT、Vision-Transformer、Swin-Transformer
    和 GPT 系列，我们必须深入了解 Transformer 架构的内部工作原理。
- en: In this article, we will dissect only the encoder part of Transformer, which
    can be used mainly for classification purposes. Specifically, we will use the
    Transformer encoders to classify texts. Without further ado, let’s first take
    a look at the dataset that we’re going to use in this article.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将仅剖析 Transformer 的编码器部分，该部分主要用于分类目的。具体来说，我们将使用 Transformer 编码器来对文本进行分类。事不宜迟，让我们首先看看本文将使用的数据集。
- en: About the Dataset
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于数据集
