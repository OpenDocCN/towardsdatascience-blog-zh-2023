- en: How to Build an Interconnected Multi-Page Streamlit App
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•æ„å»ºä¸€ä¸ªäº’è”çš„å¤šé¡µé¢ Streamlit åº”ç”¨
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f?source=collection_archive---------8-----------------------#2023-07-24](https://towardsdatascience.com/how-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f?source=collection_archive---------8-----------------------#2023-07-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f?source=collection_archive---------8-----------------------#2023-07-24](https://towardsdatascience.com/how-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f?source=collection_archive---------8-----------------------#2023-07-24)
- en: From planning to execution â€” how I built GPT lab
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»è§„åˆ’åˆ°æ‰§è¡Œâ€”â€”æˆ‘æ˜¯å¦‚ä½•æ„å»º GPT å®éªŒå®¤çš„
- en: '[](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)[![Dave
    Lin](../Images/630f84748ac5ea04912ca28cffdbfd15.png)](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)
    [Dave Lin](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)[![Dave
    Lin](../Images/630f84748ac5ea04912ca28cffdbfd15.png)](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)
    [Dave Lin](https://medium.com/@dclin?source=post_page-----3114c313f88f--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b1d830863a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&user=Dave+Lin&userId=6b1d830863a3&source=post_page-6b1d830863a3----3114c313f88f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)
    Â·9 min readÂ·Jul 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3114c313f88f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&user=Dave+Lin&userId=6b1d830863a3&source=-----3114c313f88f---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6b1d830863a3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&user=Dave+Lin&userId=6b1d830863a3&source=post_page-6b1d830863a3----3114c313f88f---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3114c313f88f--------------------------------)
    Â·9åˆ†é’Ÿé˜…è¯»Â·2023å¹´7æœˆ24æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3114c313f88f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&user=Dave+Lin&userId=6b1d830863a3&source=-----3114c313f88f---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3114c313f88f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&source=-----3114c313f88f---------------------bookmark_footer-----------)![](../Images/e492690c6892273adc45a13ebb488b40.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3114c313f88f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-build-an-interconnected-multi-page-streamlit-app-3114c313f88f&source=-----3114c313f88f---------------------bookmark_footer-----------)![](../Images/e492690c6892273adc45a13ebb488b40.png)'
- en: Photo by [ClÃ©ment HÃ©lardot](https://unsplash.com/@clemhlrdt?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [ClÃ©ment HÃ©lardot](https://unsplash.com/@clemhlrdt?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) ä¸Šæä¾›
- en: '*Note: This article was originally featured on* [*Streamlit blog*](https://blog.streamlit.io/how-to-build-an-interconnected-multi-page-streamlit-app/)*.
    I wanted to share it here for the Medium community to see.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ³¨æ„ï¼šæœ¬æ–‡æœ€åˆå‘å¸ƒäº* [*Streamlit åšå®¢*](https://blog.streamlit.io/how-to-build-an-interconnected-multi-page-streamlit-app/)*ã€‚æˆ‘å¸Œæœ›åœ¨è¿™é‡Œä¸
    Medium ç¤¾åŒºåˆ†äº«ã€‚*'
- en: Wow! What an incredible three months since I first published my blog post on
    [the lessons learned from building GPT Lab](https://www.notion.so/Building-GPT-Lab-with-Streamlit-2b8e8694a1384373a0bf176506d79444?pvs=21)!
    ğŸš€
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å“‡ï¼è‡ªä»æˆ‘é¦–æ¬¡å‘å¸ƒå…³äº [æ„å»º GPT å®éªŒå®¤çš„ç»éªŒæ•™è®­](https://www.notion.so/Building-GPT-Lab-with-Streamlit-2b8e8694a1384373a0bf176506d79444?pvs=21)
    çš„åšå®¢æ–‡ç« ä»¥æ¥ï¼Œè¿™ä¸‰ä¸ªæœˆçœŸæ˜¯ä»¤äººéš¾ä»¥ç½®ä¿¡ï¼ ğŸš€
- en: Thanks to your tremendous support, GPT Lab has received over 9K app views, 1150+
    unique signed-in users, 900+ sessions with assistants, 650+ prompts tested, and
    180+ assistants created. The app has also been featured in the Streamlit App Gallery
    alongside other great apps.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢ä½ ä»¬çš„å·¨å¤§æ”¯æŒï¼ŒGPT Lab å·²è·å¾—è¶…è¿‡ 9K çš„åº”ç”¨æŸ¥çœ‹æ¬¡æ•°ã€1150+ çš„ç‹¬ç‰¹ç™»å½•ç”¨æˆ·ã€900+ æ¬¡ä¸åŠ©æ‰‹çš„ä¼šè¯ã€650+ ä¸ªæµ‹è¯•è¿‡çš„æç¤ºä»¥åŠ
    180+ ä¸ªåˆ›å»ºçš„åŠ©æ‰‹ã€‚è¯¥åº”ç”¨è¿˜åœ¨ Streamlit åº”ç”¨ç”»å»Šä¸­ä¸å…¶ä»–ä¼˜ç§€åº”ç”¨ä¸€èµ·å±•ç¤ºã€‚
- en: '[http://gptlab.streamlit.app/?embed=true](http://gptlab.streamlit.app/?embed=true)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://gptlab.streamlit.app/?embed=true](http://gptlab.streamlit.app/?embed=true)'
- en: Many of you have asked me, â€œHow did you plan and build such a large application
    with Streamlit?â€ Eager to answer, Iâ€™ve decided to open-source GPT Lab.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä»¬ä¸­çš„è®¸å¤šäººé—®æˆ‘ï¼Œâ€œä½ æ˜¯å¦‚ä½•è§„åˆ’å’Œæ„å»ºå¦‚æ­¤å¤§å‹çš„ Streamlit åº”ç”¨çš„ï¼Ÿâ€è¿«ä¸åŠå¾…åœ°æƒ³å›ç­”ï¼Œæˆ‘å†³å®šå°† GPT Lab å¼€æºã€‚
- en: In this post, Iâ€™ll share insights into the strategies and thought processes
    behind this ambitious project. I hope it will inspire you to push Streamlit to
    its limits and bring your ambitious apps to life.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†åˆ†äº«å…³äºè¿™ä¸ªé›„å¿ƒå‹ƒå‹ƒé¡¹ç›®çš„ç­–ç•¥å’Œæ€ç»´è¿‡ç¨‹çš„è§è§£ã€‚æˆ‘å¸Œæœ›è¿™èƒ½æ¿€åŠ±ä½ ä»¬å°† Streamlit æ¨å‘æé™ï¼Œå¹¶å°†ä½ ä»¬é›„å¿ƒå‹ƒå‹ƒçš„åº”ç”¨å˜ä¸ºç°å®ã€‚
- en: '*ğŸ’¡ Want to skip ahead? Check out the* [*app*](https://gptlab.streamlit.app/)
    *and the* [*code*](https://github.com/dclin/gptlab-streamlit)*.*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*ğŸ’¡ æƒ³è·³åˆ°ä¸‹ä¸€éƒ¨åˆ†ï¼ŸæŸ¥çœ‹* [*åº”ç”¨ç¨‹åº*](https://gptlab.streamlit.app/) *å’Œ* [*ä»£ç *](https://github.com/dclin/gptlab-streamlit)*ã€‚*'
- en: Planning a large Streamlit app
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è§„åˆ’ä¸€ä¸ªå¤§å‹çš„ Streamlit åº”ç”¨
- en: 'Building large Streamlit apps, such as GPT Lab, requires careful planning rather
    than just throwing code together. For GPT Lab, I focused on planning these four
    key aspects:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ„å»ºå¤§å‹ Streamlit åº”ç”¨ï¼Œä¾‹å¦‚ GPT Labï¼Œéœ€è¦ä»”ç»†çš„è§„åˆ’ï¼Œè€Œä¸ä»…ä»…æ˜¯å°†ä»£ç æ‹¼å‡‘åœ¨ä¸€èµ·ã€‚å¯¹äº GPT Labï¼Œæˆ‘ä¸“æ³¨äºè§„åˆ’è¿™å››ä¸ªå…³é”®æ–¹é¢ï¼š
- en: '**Feature and UX.** What will the app do? What kind of user experience do we
    aim to provide?'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**åŠŸèƒ½å’Œç”¨æˆ·ä½“éªŒã€‚** åº”ç”¨ç¨‹åºå°†åšä»€ä¹ˆï¼Ÿæˆ‘ä»¬æ—¨åœ¨æä¾›ä»€ä¹ˆæ ·çš„ç”¨æˆ·ä½“éªŒï¼Ÿ'
- en: '**Data model.** How will data be persisted? What should be stored in the database
    versus session state variables?'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**æ•°æ®æ¨¡å‹ã€‚** æ•°æ®å°†å¦‚ä½•æŒä¹…åŒ–ï¼Ÿåº”è¯¥å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„å†…å®¹ä¸ä¼šè¯çŠ¶æ€å˜é‡ä¸­çš„å†…å®¹åº”è¯¥å¦‚ä½•åŒºåˆ†ï¼Ÿ'
- en: '**Code structure.** How should the app be architected to ensure modularity,
    maintainability, and scalability?'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä»£ç ç»“æ„ã€‚** åº”è¯¥å¦‚ä½•æ„å»ºåº”ç”¨ä»¥ç¡®ä¿æ¨¡å—åŒ–ã€å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§ï¼Ÿ'
- en: '**Session states.** Which session state variables are needed to link the user
    interface?'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ä¼šè¯çŠ¶æ€ã€‚** éœ€è¦å“ªäº›ä¼šè¯çŠ¶æ€å˜é‡æ¥é“¾æ¥ç”¨æˆ·ç•Œé¢ï¼Ÿ'
- en: Understanding these aspects offered a clearer view of what I was trying to build
    and provided a framework to approach the complex task systematically.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£è¿™äº›æ–¹é¢æä¾›äº†æˆ‘æ‰€å°è¯•æ„å»ºçš„æ›´æ¸…æ™°çš„è§†å›¾ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªç³»ç»Ÿæ€§å¤„ç†å¤æ‚ä»»åŠ¡çš„æ¡†æ¶ã€‚
- en: Letâ€™s dive into each aspect in more detail.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°æ¢è®¨æ¯ä¸ªæ–¹é¢ã€‚
- en: 'Feature and UX: Creating initial spec and low-fi UX mocks'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠŸèƒ½å’Œç”¨æˆ·ä½“éªŒï¼šåˆ›å»ºåˆå§‹è§„èŒƒå’Œä½ä¿çœŸç”¨æˆ·ä½“éªŒæ¨¡å‹
- en: To start, I created a simple specification document (or â€œspecâ€) outlining the
    overall scope and approach. I also included a sitemap detailing the use cases
    I wanted to support. The spec provided me with a clear roadmap to follow and a
    means to measure my progress.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„è§„èŒƒæ–‡æ¡£ï¼ˆæˆ–ç§°ä¸ºâ€œè§„èŒƒâ€ï¼‰ï¼Œæ¦‚è¿°äº†æ•´ä½“èŒƒå›´å’Œæ–¹æ³•ã€‚æˆ‘è¿˜åŒ…æ‹¬äº†ä¸€ä¸ªç«™ç‚¹åœ°å›¾ï¼Œè¯¦ç»†è¯´æ˜äº†æˆ‘æƒ³æ”¯æŒçš„ç”¨ä¾‹ã€‚è¯¥è§„èŒƒä¸ºæˆ‘æä¾›äº†æ˜ç¡®çš„è·¯çº¿å›¾ä»¥åŠè¡¡é‡è¿›å±•çš„æ‰‹æ®µã€‚
- en: 'Hereâ€™s an excerpt from the original spec:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯åŸå§‹è§„èŒƒçš„æ‘˜å½•ï¼š
- en: '***Scope***'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***èŒƒå›´***'
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Build a platform that allows generative AI (GA) bot enthusiasts to build their
    own GPT-3 prompt-based chatbot for their friends and families. The goal is to
    test the hypothesis that enough GA bot enthusiasts would want to build their niche-domain
    bots.*'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*æ„å»ºä¸€ä¸ªå¹³å°ï¼Œå…è®¸ç”Ÿæˆå¼ AI (GA) æœºå™¨äººçˆ±å¥½è€…ä¸ºä»–ä»¬çš„æœ‹å‹å’Œå®¶äººåˆ›å»ºè‡ªå·±çš„åŸºäº GPT-3 çš„èŠå¤©æœºå™¨äººã€‚ç›®æ ‡æ˜¯éªŒè¯è¶³å¤Ÿå¤šçš„ GA æœºå™¨äººçˆ±å¥½è€…æ˜¯å¦æ„¿æ„æ„å»ºä»–ä»¬çš„åˆ©åŸºé¢†åŸŸæœºå™¨äººã€‚*'
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***Approach***'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***æ–¹æ³•***'
- en: ''
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*A public Streamlit site that allows users to interact with one of the four
    pre-trained coach bots or create and interact with their bots.*'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ä¸€ä¸ªå…¬å…±çš„ Streamlit ç½‘ç«™ï¼Œå…è®¸ç”¨æˆ·ä¸å››ä¸ªé¢„è®­ç»ƒçš„æ•™ç»ƒæœºå™¨äººä¸­çš„ä¸€ä¸ªäº’åŠ¨ï¼Œæˆ–åˆ›å»ºå¹¶ä¸ä»–ä»¬çš„æœºå™¨äººäº’åŠ¨ã€‚*'
- en: As with most development projects, I made some changes. But the original sitemap
    remained intact for the most part, as I was able to implement most of the planned
    features.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¤§å¤šæ•°å¼€å‘é¡¹ç›®ä¸€æ ·ï¼Œæˆ‘åšäº†ä¸€äº›ä¿®æ”¹ã€‚ä½†åŸå§‹çš„ç«™ç‚¹åœ°å›¾å¤§éƒ¨åˆ†ä¿æŒä¸å˜ï¼Œå› ä¸ºæˆ‘èƒ½å¤Ÿå®ç°å¤§å¤šæ•°è®¡åˆ’ä¸­çš„åŠŸèƒ½ã€‚
- en: 'Here is the final version of the sitemap:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç«™ç‚¹åœ°å›¾çš„æœ€ç»ˆç‰ˆæœ¬ï¼š
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I canâ€™t overstate the importance of feature planning. It provides a roadmap,
    a way to measure progress, and a starting point for thinking about the data model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸èƒ½è¿‡åˆ†å¼ºè°ƒåŠŸèƒ½è§„åˆ’çš„é‡è¦æ€§ã€‚å®ƒæä¾›äº†ä¸€ä¸ªè·¯çº¿å›¾ã€è¡¡é‡è¿›å±•çš„æ–¹æ³•ä»¥åŠæ€è€ƒæ•°æ®æ¨¡å‹çš„èµ·ç‚¹ã€‚
- en: 'Data model: Determining the schema'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æ¨¡å‹ï¼šç¡®å®šæ¨¡å¼
- en: From the start, I recognized that a backend data store was crucial for persisting
    user, assistant, and session records. After considering my options, I decided
    on Google Firestore due to its scalability, real-time capabilities, and generous
    free tier. To support future expansions, I strategically designed the data model.
    Although the current app only uses a fraction of its potential, itâ€™s possible
    to add prompt version controls to GPT Lab. This would enable users to edit or
    revert their assistants.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸€å¼€å§‹ï¼Œæˆ‘å°±è®¤è¯†åˆ°åç«¯æ•°æ®å­˜å‚¨å¯¹äºæŒä¹…åŒ–ç”¨æˆ·ã€åŠ©æ‰‹å’Œä¼šè¯è®°å½•è‡³å…³é‡è¦ã€‚åœ¨è€ƒè™‘äº†æˆ‘çš„é€‰æ‹©åï¼Œæˆ‘å†³å®šä½¿ç”¨ Google Firestoreï¼Œå› ä¸ºå®ƒå…·æœ‰å¯æ‰©å±•æ€§ã€å®æ—¶èƒ½åŠ›å’Œæ…·æ…¨çš„å…è´¹å±‚ã€‚ä¸ºäº†æ”¯æŒæœªæ¥çš„æ‰©å±•ï¼Œæˆ‘æˆ˜ç•¥æ€§åœ°è®¾è®¡äº†æ•°æ®æ¨¡å‹ã€‚å°½ç®¡å½“å‰åº”ç”¨ç¨‹åºä»…ä½¿ç”¨äº†å…¶æ½œåŠ›çš„ä¸€éƒ¨åˆ†ï¼Œä½†å¯ä»¥åœ¨
    GPT Lab ä¸­æ·»åŠ æç¤ºç‰ˆæœ¬æ§åˆ¶ã€‚è¿™å°†ä½¿ç”¨æˆ·èƒ½å¤Ÿç¼–è¾‘æˆ–æ¢å¤ä»–ä»¬çš„åŠ©æ‰‹ã€‚
- en: '*ğŸ’¡ NOTE: In the app backend and data model, assistants are referred to as bots,
    despite my previous insistence on not calling them bots in the user interface
    ğŸ˜….*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*ğŸ’¡ æ³¨æ„ï¼šåœ¨åº”ç”¨ç¨‹åºåå°å’Œæ•°æ®æ¨¡å‹ä¸­ï¼ŒåŠ©æ‰‹è¢«ç§°ä¸ºæœºå™¨äººï¼Œå°½ç®¡æˆ‘ä¹‹å‰åšæŒä¸åœ¨ç”¨æˆ·ç•Œé¢ä¸­ç§°å…¶ä¸ºæœºå™¨äºº ğŸ˜…ã€‚*'
- en: 'Now, letâ€™s explore the four main Firestore collections in GPT Lab: users, user_hash,
    bots, and sessions.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ·±å…¥æ¢è®¨ GPT Lab ä¸­çš„å››ä¸ªä¸»è¦ Firestore é›†åˆï¼šusersã€user_hashã€bots å’Œ sessionsã€‚
- en: '**Users and user_hash**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**ç”¨æˆ·å’Œ user_hash**'
- en: The users collection is where the app stores information about its users. To
    protect user privacy, the app doesnâ€™t store any personally identifiable information
    (PII) about users. Instead, each user is associated only with the one-way hash
    value of their OpenAI API key. The metric fields are incremented whenever a user
    creates an assistant or starts/ends a session with an assistant. This allows for
    basic analytics gathering within the app.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·é›†åˆæ˜¯åº”ç”¨ç¨‹åºå­˜å‚¨æœ‰å…³ç”¨æˆ·ä¿¡æ¯çš„åœ°æ–¹ã€‚ä¸ºäº†ä¿æŠ¤ç”¨æˆ·éšç§ï¼Œåº”ç”¨ç¨‹åºä¸ä¼šå­˜å‚¨ä»»ä½•ä¸ªäººå¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰ã€‚ç›¸åï¼Œæ¯ä¸ªç”¨æˆ·ä»…ä¸å…¶ OpenAI API å¯†é’¥çš„å•å‘å“ˆå¸Œå€¼ç›¸å…³è”ã€‚æ¯å½“ç”¨æˆ·åˆ›å»ºåŠ©æ‰‹æˆ–å¼€å§‹/ç»“æŸä¸åŠ©æ‰‹çš„ä¼šè¯æ—¶ï¼ŒæŒ‡æ ‡å­—æ®µä¼šé€’å¢ã€‚è¿™å…è®¸åœ¨åº”ç”¨ç¨‹åºå†…è¿›è¡ŒåŸºæœ¬çš„åˆ†ææ”¶é›†ã€‚
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Google Firestore doesnâ€™t provide a way to ensure the uniqueness of a document
    field value within a collection, so I created a separate collection called user_hash.
    This ensures that each unique API key has only one associated user record. Each
    user document is uniquely associated with a user_hash document, and each user_hash
    document may be associated with a user document. The data model is flexible enough
    to accommodate users who change their API keys in the future (users can log in
    with their old API key and then swap it out for a new one).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Google Firestore ä¸æä¾›ç¡®ä¿é›†åˆä¸­æ–‡æ¡£å­—æ®µå€¼å”¯ä¸€æ€§çš„æ–¹æ³•ï¼Œå› æ­¤æˆ‘åˆ›å»ºäº†ä¸€ä¸ªåä¸º user_hash çš„å•ç‹¬é›†åˆã€‚è¿™ç¡®ä¿æ¯ä¸ªå”¯ä¸€çš„ API
    å¯†é’¥åªæœ‰ä¸€ä¸ªå…³è”çš„ç”¨æˆ·è®°å½•ã€‚æ¯ä¸ªç”¨æˆ·æ–‡æ¡£å”¯ä¸€åœ°å…³è”åˆ°ä¸€ä¸ª user_hash æ–‡æ¡£ï¼Œæ¯ä¸ª user_hash æ–‡æ¡£å¯èƒ½ä¸ä¸€ä¸ªç”¨æˆ·æ–‡æ¡£ç›¸å…³è”ã€‚æ•°æ®æ¨¡å‹è¶³å¤Ÿçµæ´»ï¼Œä»¥é€‚åº”æœªæ¥æ›´æ”¹
    API å¯†é’¥çš„ç”¨æˆ·ï¼ˆç”¨æˆ·å¯ä»¥ä½¿ç”¨æ—§çš„ API å¯†é’¥ç™»å½•ï¼Œç„¶åæ›´æ¢ä¸ºæ–°çš„å¯†é’¥ï¼‰ã€‚
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bots**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœºå™¨äºº**'
- en: The bots collection stores configurations for AI assistants. The crux of each
    AI assistant is its large language model (LLM), model configurations, and prompts.
    To enable proper version control of prompts and model configurations in the future,
    model_configs and prompts are modeled as subcollections (part of GPT Labâ€™s vision
    is to be the repository of your prompts).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨äººé›†åˆå­˜å‚¨ AI åŠ©æ‰‹çš„é…ç½®ã€‚æ¯ä¸ª AI åŠ©æ‰‹çš„æ ¸å¿ƒæ˜¯å…¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€æ¨¡å‹é…ç½®å’Œæç¤ºã€‚ä¸ºäº†åœ¨æœªæ¥å®ç°æç¤ºå’Œæ¨¡å‹é…ç½®çš„é€‚å½“ç‰ˆæœ¬æ§åˆ¶ï¼Œmodel_configs
    å’Œ prompts è¢«å»ºæ¨¡ä¸ºå­é›†åˆï¼ˆGPT Lab çš„æ„¿æ™¯ä¹‹ä¸€æ˜¯æˆä¸ºä½ æç¤ºçš„å­˜å‚¨åº“ï¼‰ã€‚
- en: To minimize subcollection reads (so you donâ€™t need to constantly query the subcollections
    for the active record), the document IDs of the active subcollection are also
    stored at the document level. The session_type field indicates whether the assistant
    is in a brainstorming or coaching session, which affects the session message truncation
    technique.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æœ€å°åŒ–å­é›†åˆè¯»å–ï¼ˆä»¥ä¾¿æ— éœ€ä¸æ–­æŸ¥è¯¢å­é›†åˆä»¥è·å–æ´»åŠ¨è®°å½•ï¼‰ï¼Œæ´»åŠ¨å­é›†åˆçš„æ–‡æ¡£ ID ä¹Ÿåœ¨æ–‡æ¡£çº§åˆ«å­˜å‚¨ã€‚session_type å­—æ®µæŒ‡ç¤ºåŠ©æ‰‹æ˜¯å¦å¤„äºå¤´è„‘é£æš´æˆ–è¾…å¯¼ä¼šè¯ä¸­ï¼Œè¿™ä¼šå½±å“ä¼šè¯æ¶ˆæ¯çš„æˆªæ–­æŠ€æœ¯ã€‚
- en: Finally, the metric fields are incremented when a user starts or ends a session
    with an assistant.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå½“ç”¨æˆ·å¼€å§‹æˆ–ç»“æŸä¸åŠ©æ‰‹çš„ä¼šè¯æ—¶ï¼ŒæŒ‡æ ‡å­—æ®µä¼šé€’å¢ã€‚
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: S**essions**
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: S**essions**
- en: 'The sessions collection stores session data. It contains two types of sessions:
    lab sessions (used for testing prompts) and assistant sessions (used for chatting
    with created assistants). To reduce the need for frequent retrieval of the bot
    document, its information is cached within the session document. This makes conceptual
    sense, as the bot document could drift if an editing assistant use case were ever
    implemented.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: sessions é›†åˆå­˜å‚¨ä¼šè¯æ•°æ®ã€‚å®ƒåŒ…å«ä¸¤ç§ç±»å‹çš„ä¼šè¯ï¼šå®éªŒå®¤ä¼šè¯ï¼ˆç”¨äºæµ‹è¯•æç¤ºï¼‰å’ŒåŠ©æ‰‹ä¼šè¯ï¼ˆç”¨äºä¸åˆ›å»ºçš„åŠ©æ‰‹èŠå¤©ï¼‰ã€‚ä¸ºäº†å‡å°‘å¯¹æœºå™¨äººæ–‡æ¡£é¢‘ç¹æ£€ç´¢çš„éœ€è¦ï¼Œå®ƒçš„ä¿¡æ¯ä¼šåœ¨ä¼šè¯æ–‡æ¡£ä¸­ç¼“å­˜ã€‚è¿™æ˜¯æœ‰é“ç†çš„ï¼Œå› ä¸ºå¦‚æœå®ç°ç¼–è¾‘åŠ©æ‰‹çš„ç”¨ä¾‹ï¼Œæœºå™¨äººæ–‡æ¡£å¯èƒ½ä¼šå‡ºç°åå·®ã€‚
- en: The `messages_str` field stores the most recent payload sent to OpenAI's LLM.
    This feature allows users to resume their previous assistant sessions. The `messages`
    subcollection stores the actual chat messages. Note that lab session chat messages
    arenâ€™t stored.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`messages_str` å­—æ®µå­˜å‚¨å‘é€åˆ° OpenAI LLM çš„æœ€æ–°æœ‰æ•ˆè´Ÿè½½ã€‚æ­¤åŠŸèƒ½å…è®¸ç”¨æˆ·æ¢å¤ä¹‹å‰çš„åŠ©æ‰‹ä¼šè¯ã€‚`messages` å­é›†åˆå­˜å‚¨å®é™…çš„èŠå¤©æ¶ˆæ¯ã€‚æ³¨æ„ï¼Œå®éªŒå®¤ä¼šè¯èŠå¤©æ¶ˆæ¯ä¸ä¼šè¢«å­˜å‚¨ã€‚'
- en: To ensure user confidentiality and privacy, OpenAI request payloads and session
    messages are encrypted before being saved in the database. This data model allows
    users to restart a previous session and continue chatting with the assistant.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç¡®ä¿ç”¨æˆ·çš„æœºå¯†æ€§å’Œéšç§ï¼ŒOpenAI è¯·æ±‚æœ‰æ•ˆè´Ÿè½½å’Œä¼šè¯æ¶ˆæ¯åœ¨ä¿å­˜åˆ°æ•°æ®åº“ä¹‹å‰ä¼šè¢«åŠ å¯†ã€‚è¿™ç§æ•°æ®æ¨¡å‹å…è®¸ç”¨æˆ·é‡æ–°å¯åŠ¨ä»¥å‰çš„ä¼šè¯å¹¶ç»§ç»­ä¸åŠ©æ‰‹èŠå¤©ã€‚
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By carefully considering all potential use cases from the beginning, I created
    a data model that is future-proof and able to accommodate the evolving needs and
    features of the app. In the following section, weâ€™ll examine the structure of
    the backend application code to see how it supports and implements this robust
    data model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»ä¸€å¼€å§‹å°±ä»”ç»†è€ƒè™‘æ‰€æœ‰æ½œåœ¨çš„ç”¨ä¾‹ï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ªæœªæ¥-proof çš„æ•°æ®æ¨¡å‹ï¼Œèƒ½å¤Ÿæ»¡è¶³åº”ç”¨ç¨‹åºä¸æ–­å‘å±•çš„éœ€æ±‚å’ŒåŠŸèƒ½ã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥äº†è§£åç«¯åº”ç”¨ç¨‹åºä»£ç çš„ç»“æ„ï¼Œä»¥äº†è§£å®ƒå¦‚ä½•æ”¯æŒå’Œå®ç°è¿™ä¸ªå¼ºå¤§çš„æ•°æ®æ¨¡å‹ã€‚
- en: 'Code structure: Structuring for scalability and modularity'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»£ç ç»“æ„ï¼šä¸ºäº†å¯æ‰©å±•æ€§å’Œæ¨¡å—åŒ–è¿›è¡Œç»“æ„åŒ–
- en: I created GPT Lab to empower users with low or no technical skills to build
    their own prompt-based LLM-based AI applications, without having to worry about
    the underlying infrastructure. My goal is to eventually offer backend APIs that
    connect usersâ€™ custom front-end apps (whether using Streamlit or not) with their
    AI assistants. This motivated me to design a decoupled architecture that separates
    the front-end Streamlit application from the backend logic.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åˆ›å»º GPT Lab æ˜¯ä¸ºäº†èµ‹èƒ½é‚£äº›æŠ€æœ¯æ°´å¹³ä½æˆ–æ²¡æœ‰æŠ€æœ¯æŠ€èƒ½çš„ç”¨æˆ·ï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿæ„å»ºè‡ªå·±çš„åŸºäºæç¤ºçš„ LLM AI åº”ç”¨ï¼Œè€Œæ— éœ€æ‹…å¿ƒåº•å±‚åŸºç¡€è®¾æ–½ã€‚æˆ‘çš„ç›®æ ‡æ˜¯æœ€ç»ˆæä¾›åç«¯
    APIï¼Œå°†ç”¨æˆ·çš„è‡ªå®šä¹‰å‰ç«¯åº”ç”¨ï¼ˆæ— è®ºæ˜¯å¦ä½¿ç”¨ Streamlitï¼‰ä¸ä»–ä»¬çš„ AI åŠ©æ‰‹è¿æ¥ã€‚è¿™æ¿€åŠ±æˆ‘è®¾è®¡äº†ä¸€ä¸ªè§£è€¦æ¶æ„ï¼Œå°†å‰ç«¯ Streamlit åº”ç”¨ä¸åç«¯é€»è¾‘åˆ†å¼€ã€‚
- en: 'The backend code was structured as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åç«¯ä»£ç çš„ç»“æ„å¦‚ä¸‹ï¼š
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The modules are as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å—å¦‚ä¸‹ï¼š
- en: '**api_util_firebase** handles CRUD operations with the Firestore database.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api_util_firebase** å¤„ç†ä¸ Firestore æ•°æ®åº“çš„ CRUD æ“ä½œã€‚'
- en: '**api_util_openai** interacts with OpenAIâ€™s models, provides a unified chat
    model to upstream models, prunes chat messages, and tries to detect and prevent
    prompt injection attacks.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api_util_openai** ä¸ OpenAI çš„æ¨¡å‹è¿›è¡Œäº¤äº’ï¼Œå‘ä¸Šæ¸¸æ¨¡å‹æä¾›ç»Ÿä¸€çš„èŠå¤©æ¨¡å‹ï¼Œä¿®å‰ªèŠå¤©æ¶ˆæ¯ï¼Œå¹¶å°è¯•æ£€æµ‹å’Œé˜²æ­¢æç¤ºæ³¨å…¥æ”»å‡»ã€‚'
- en: '**api_util_users**, **api_util_sessions**, and **api_util_bots** are interfaces
    to their corresponding Firestore collections. They interact with api_util_firebase
    and api_util_openai and implement GPT Lab-specific business logic.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**api_util_users**ã€**api_util_sessions** å’Œ **api_util_bots** æ˜¯å®ƒä»¬å„è‡ª Firestore
    é›†åˆçš„æ¥å£ã€‚å®ƒä»¬ä¸ api_util_firebase å’Œ api_util_openai è¿›è¡Œäº¤äº’ï¼Œå¹¶å®ç° GPT Lab ç‰¹å®šçš„ä¸šåŠ¡é€»è¾‘ã€‚'
- en: This design enables separate development, testing, and scaling of different
    parts of the code. It also establishes an easier migration path to convert the
    backend util_collections modules into Google Cloud Functions, which can be exposed
    via API Gateways.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§è®¾è®¡ä½¿å¾—ä»£ç çš„ä¸åŒéƒ¨åˆ†å¯ä»¥ç‹¬ç«‹å¼€å‘ã€æµ‹è¯•å’Œæ‰©å±•ã€‚å®ƒè¿˜å»ºç«‹äº†ä¸€ä¸ªæ›´ç®€å•çš„è¿ç§»è·¯å¾„ï¼Œå°†åç«¯ util_collections æ¨¡å—è½¬æ¢ä¸º Google
    Cloud Functionsï¼Œè¿™äº›å‡½æ•°å¯ä»¥é€šè¿‡ API Gateways å…¬å¼€ã€‚
- en: 'Session states: Managing UI and user flow'
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¼šè¯çŠ¶æ€ï¼šç®¡ç† UI å’Œç”¨æˆ·æµç¨‹
- en: 'As explained in the [first blog article](https://blog.streamlit.io/building-gpt-lab-with-streamlit/#2-developing-advanced-uis-with-ui-functions-rendered-by-session-states),
    I used session state variables to control and manage functionalities on Streamlit
    pages. The following illustrates how these variables are utilized throughout the
    app:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚åœ¨ [ç¬¬ä¸€ç¯‡åšå®¢æ–‡ç« ](https://blog.streamlit.io/building-gpt-lab-with-streamlit/#2-developing-advanced-uis-with-ui-functions-rendered-by-session-states)
    ä¸­è§£é‡Šçš„ï¼Œæˆ‘ä½¿ç”¨äº†ä¼šè¯çŠ¶æ€å˜é‡æ¥æ§åˆ¶å’Œç®¡ç† Streamlit é¡µé¢ä¸Šçš„åŠŸèƒ½ã€‚ä»¥ä¸‹è¯´æ˜äº†è¿™äº›å˜é‡åœ¨æ•´ä¸ªåº”ç”¨ä¸­çš„ä½¿ç”¨æ–¹å¼ï¼š
- en: '*home.py*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*home.py*'
- en: '**user** controls whether to render the OpenAI API key module'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç”¨æˆ·** æ§åˆ¶æ˜¯å¦æ¸²æŸ“ OpenAI API å¯†é’¥æ¨¡å—'
- en: pages/1_lounge.py
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: pages/1_lounge.py
- en: '**user** controls whether to render the OpenAI API key module, enable assistant
    selections, and show the My Assistants tab.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç”¨æˆ·** æ§åˆ¶æ˜¯å¦æ¸²æŸ“ OpenAI API å¯†é’¥æ¨¡å—ï¼Œå¯ç”¨åŠ©æ‰‹é€‰æ‹©ï¼Œå¹¶æ˜¾ç¤ºæˆ‘çš„åŠ©æ‰‹æ ‡ç­¾é¡µã€‚'
- en: After users choose to interact with an assistant, the assistant details are
    stored in **bot_info**.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨æˆ·é€‰æ‹©ä¸åŠ©æ‰‹äº’åŠ¨åï¼ŒåŠ©æ‰‹è¯¦ç»†ä¿¡æ¯ä¼šå­˜å‚¨åœ¨ **bot_info** ä¸­ã€‚
- en: pages/2_assistant.py
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: pages/2_assistant.py
- en: '**user** controls whether to render the OpenAI API key module.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç”¨æˆ·** æ§åˆ¶æ˜¯å¦æ¸²æŸ“ OpenAI API å¯†é’¥æ¨¡å—ã€‚'
- en: '**bot_info**, **session_id**, and **session_ended** determine which screen
    variation to display.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bot_info**ã€**session_id** å’Œ **session_ended** å†³å®šæ˜¾ç¤ºå“ªä¸ªå±å¹•å˜ä½“ã€‚'
- en: '**bot_info** does not exist: check to see if assistant_id is in the URL parameter.
    Else, prompt users to search for an assistant.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bot_info** ä¸å­˜åœ¨ï¼šæ£€æŸ¥ assistant_id æ˜¯å¦åœ¨ URL å‚æ•°ä¸­ã€‚å¦‚æœæ²¡æœ‰ï¼Œåˆ™æç¤ºç”¨æˆ·æœç´¢åŠ©æ‰‹ã€‚'
- en: '**bot_info** and **session_id** exist, and **session_ended** is false: display
    the chat session screen.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bot_info** å’Œ **session_id** å­˜åœ¨ï¼Œå¹¶ä¸” **session_ended** ä¸º falseï¼šæ˜¾ç¤ºèŠå¤©ä¼šè¯å±å¹•ã€‚'
- en: '**bot_info** and **session_id** exist, and **session_ended** is true: display
    the chat session recap screen.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**bot_info** å’Œ **session_id** å­˜åœ¨ï¼Œå¹¶ä¸” **session_ended** ä¸º trueï¼šæ˜¾ç¤ºèŠå¤©ä¼šè¯å›é¡¾å±å¹•ã€‚'
- en: In the chat session, **session_msg_list** stores the conversation.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨èŠå¤©ä¼šè¯ä¸­ï¼Œ**session_msg_list** å­˜å‚¨å¯¹è¯å†…å®¹ã€‚
- en: pages/3_lab.py
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: pages/3_lab.py
- en: '**user** gates whether to render the OpenAI API key module and whether to allow
    users to start creating assistants in the lab.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç”¨æˆ·** æ§åˆ¶æ˜¯å¦æ¸²æŸ“ OpenAI API å¯†é’¥æ¨¡å—ä»¥åŠæ˜¯å¦å…è®¸ç”¨æˆ·åœ¨å®éªŒå®¤ä¸­å¼€å§‹åˆ›å»ºåŠ©æ‰‹ã€‚'
- en: '**lab_active_step** controls which lab session state to render:'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**lab_active_step** æ§åˆ¶æ¸²æŸ“å“ªä¸ªå®éªŒå®¤ä¼šè¯çŠ¶æ€ï¼š'
- en: 'If 1: render step 1 UI to set assistant initial prompt and model.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä¸º 1ï¼šæ¸²æŸ“æ­¥éª¤ 1 UI ä»¥è®¾ç½®åŠ©æ‰‹çš„åˆå§‹æç¤ºå’Œæ¨¡å‹ã€‚
- en: 'If 2: render step 2 UI to test chat with assistant.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä¸º 2ï¼šæ¸²æŸ“æ­¥éª¤ 2 UI æµ‹è¯•ä¸åŠ©æ‰‹çš„èŠå¤©ã€‚
- en: 'If 3: render step 3 UI to finalize assistant details. On create, the bot record
    is created in Firestore DB, and the document ID is saved to lab_bot_id.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä¸º 3ï¼šæ¸²æŸ“æ­¥éª¤ 3 UI å®ŒæˆåŠ©æ‰‹è¯¦ç»†ä¿¡æ¯ã€‚åˆ›å»ºæ—¶ï¼Œæœºå™¨äººè®°å½•ä¼šåœ¨ Firestore DB ä¸­åˆ›å»ºï¼Œå¹¶å°†æ–‡æ¡£ ID ä¿å­˜åˆ° lab_bot_idã€‚
- en: 'If 4 and lab_bot_id is set: render step 4 UI to show assistant creation confirmation.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦‚æœä¸º 4 ä¸” lab_bot_id å·²è®¾ç½®ï¼šæ¸²æŸ“æ­¥éª¤ 4 UI æ˜¾ç¤ºåŠ©æ‰‹åˆ›å»ºç¡®è®¤ã€‚
- en: During the test chat session, **lab_msg_list** stores the test messages. By
    using separate **lab_bot_id** and **bot_info**, I can allow users to jump back
    and forth between lounge/assistant and lab without losing progress in each.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨æµ‹è¯•èŠå¤©ä¼šè¯æœŸé—´ï¼Œ**lab_msg_list** å­˜å‚¨æµ‹è¯•æ¶ˆæ¯ã€‚é€šè¿‡ä½¿ç”¨å•ç‹¬çš„ **lab_bot_id** å’Œ **bot_info**ï¼Œæˆ‘å¯ä»¥è®©ç”¨æˆ·åœ¨ä¼‘æ¯å®¤/åŠ©æ‰‹å’Œå®éªŒå®¤ä¹‹é—´æ¥å›è·³è½¬ï¼Œè€Œä¸ä¼šä¸¢å¤±æ¯ä¸ªéƒ¨åˆ†çš„è¿›åº¦ã€‚
- en: With the upfront planning done, the rest of the execution was a lot more manageable.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å®Œæˆå‰æœŸè§„åˆ’åï¼Œæ¥ä¸‹æ¥çš„æ‰§è¡Œå˜å¾—æ›´åŠ å¯æ§ã€‚
- en: Wrapping up
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: In this post, I covered the upfront planning required for creating GPT Lab,
    including the features, data model, code, and session state. I hope this inspires
    you to build your own ambitious Streamlit apps.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æ¶µç›–äº†åˆ›å»º GPT å®éªŒå®¤æ‰€éœ€çš„å‰æœŸè§„åˆ’ï¼ŒåŒ…æ‹¬åŠŸèƒ½ã€æ•°æ®æ¨¡å‹ã€ä»£ç å’Œä¼šè¯çŠ¶æ€ã€‚æˆ‘å¸Œæœ›è¿™èƒ½æ¿€åŠ±ä½ æ„å»ºè‡ªå·±çš„é›„å¿ƒå‹ƒå‹ƒçš„ Streamlit
    åº”ç”¨ç¨‹åºã€‚
- en: Connect with me on [Twitter](https://twitter.com/dclin) or [Linkedin](https://www.linkedin.com/in/d2clin/).
    Iâ€™d love to hear from you.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ [Twitter](https://twitter.com/dclin) æˆ– [Linkedin](https://www.linkedin.com/in/d2clin/)
    ä¸æˆ‘è”ç³»ã€‚æˆ‘å¾ˆæœŸå¾…ä½ çš„åé¦ˆã€‚
- en: Happy Streamlit-ing! ğŸˆ
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ä½ ä½¿ç”¨ Streamlit æ„‰å¿«ï¼ ğŸˆ
