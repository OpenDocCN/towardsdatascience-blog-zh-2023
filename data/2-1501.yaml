- en: Matrix Approximation in Data Streams
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æµä¸­çš„çŸ©é˜µè¿‘ä¼¼
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/matrix-approximation-in-data-streams-7585720e8671](https://towardsdatascience.com/matrix-approximation-in-data-streams-7585720e8671)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/matrix-approximation-in-data-streams-7585720e8671](https://towardsdatascience.com/matrix-approximation-in-data-streams-7585720e8671)
- en: Approximate a matrix without having all of its rows
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åœ¨æ²¡æœ‰æ‰€æœ‰è¡Œçš„æƒ…å†µä¸‹è¿‘ä¼¼çŸ©é˜µ
- en: '[](https://medium.com/@mina.ghashami?source=post_page-----7585720e8671--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----7585720e8671--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7585720e8671--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7585720e8671--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----7585720e8671--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mina.ghashami?source=post_page-----7585720e8671--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----7585720e8671--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7585720e8671--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7585720e8671--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----7585720e8671--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7585720e8671--------------------------------)
    Â·13 min readÂ·Sep 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7585720e8671--------------------------------)
    Â·13 åˆ†é’Ÿé˜…è¯»Â·2023å¹´9æœˆ17æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/dc927665ca6a15dbc7eedcdf011561fe.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc927665ca6a15dbc7eedcdf011561fe.png)'
- en: 'Image credit: unsplash.com'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼šunsplash.com
- en: Matrix approximation is a heavily studied sub-field in data mining and machine
    learning. A large set of data analysis tasks rely on obtaining a *low rank approximation*of
    matrices. Examples are dimensionality reduction, anomaly detection, data de-noising,
    clustering, and recommendation systems. In this article, we look into the problem
    of matrix approximation, and how to compute it when the whole data is not available
    at hand!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ©é˜µè¿‘ä¼¼æ˜¯æ•°æ®æŒ–æ˜å’Œæœºå™¨å­¦ä¹ ä¸­ä¸€ä¸ªå¹¿æ³›ç ”ç©¶çš„å­é¢†åŸŸã€‚è®¸å¤šæ•°æ®åˆ†æä»»åŠ¡ä¾èµ–äºè·å¾—çŸ©é˜µçš„*ä½ç§©è¿‘ä¼¼*ã€‚ä¾‹å¦‚ï¼Œé™ç»´ã€å¼‚å¸¸æ£€æµ‹ã€æ•°æ®å»å™ªã€èšç±»å’Œæ¨èç³»ç»Ÿã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨çŸ©é˜µè¿‘ä¼¼çš„é—®é¢˜ï¼Œä»¥åŠåœ¨æ•°æ®ä¸å®Œå…¨æ—¶å¦‚ä½•è®¡ç®—å®ƒï¼
- en: The content of this article is partly taken from my [lecture](https://web.stanford.edu/class/cs246/slides/17-matrix_sketching.pdf)
    at [Stanford -CS246 course](https://web.stanford.edu/class/cs246/). I hope you
    find it useful. Please find the full content [here](https://web.stanford.edu/class/cs246/slides/17-matrix_sketching.pdf).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡å†…å®¹éƒ¨åˆ†å–è‡ªæˆ‘åœ¨ [æ–¯å¦ç¦å¤§å­¦-CS246è¯¾ç¨‹](https://web.stanford.edu/class/cs246/) çš„[è®²åº§](https://web.stanford.edu/class/cs246/slides/17-matrix_sketching.pdf)ã€‚å¸Œæœ›å¯¹ä½ æœ‰ç”¨ã€‚å®Œæ•´å†…å®¹è¯·è§
    [æ­¤å¤„](https://web.stanford.edu/class/cs246/slides/17-matrix_sketching.pdf)ã€‚
- en: Data as a matrix
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®ä½œä¸ºçŸ©é˜µ
- en: Most data generated on web can be represented as a matrix, where each row of
    the matrix is a data point. For example, in routers every packet sent across the
    network is a data point that can be represented as a row in a matrix of all data
    points. In retail, every purchase made is a row in the matrix of all transactions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°åœ¨ç½‘ä¸Šç”Ÿæˆçš„æ•°æ®å¯ä»¥è¡¨ç¤ºä¸ºçŸ©é˜µï¼Œå…¶ä¸­çŸ©é˜µçš„æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªæ•°æ®ç‚¹ã€‚ä¾‹å¦‚ï¼Œåœ¨è·¯ç”±å™¨ä¸­ï¼Œæ¯ä¸ªé€šè¿‡ç½‘ç»œå‘é€çš„åŒ…éƒ½æ˜¯ä¸€ä¸ªæ•°æ®ç‚¹ï¼Œå¯ä»¥è¡¨ç¤ºä¸ºæ‰€æœ‰æ•°æ®ç‚¹çŸ©é˜µä¸­çš„ä¸€è¡Œã€‚åœ¨é›¶å”®ä¸­ï¼Œæ¯æ¬¡è´­ä¹°éƒ½æ˜¯æ‰€æœ‰äº¤æ˜“çŸ©é˜µä¸­çš„ä¸€è¡Œã€‚
- en: '![](../Images/c2174d5fadd7df8c1421ee119c9792c1.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2174d5fadd7df8c1421ee119c9792c1.png)'
- en: 'Figure 1: Data as a matrix â€” Image by the author'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1ï¼šæ•°æ®ä½œä¸ºçŸ©é˜µ â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: At the same time, almost all data generated over web is of a *streaming nature;*
    meaning the data is generated by an external source at a rapid rate which we have
    no control over. Think of all searches users make on Google search engine in a
    every second. We call this data the *streaming data*; because just like a stream
    it pours in.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ­¤åŒæ—¶ï¼Œå‡ ä¹æ‰€æœ‰åœ¨ç½‘ä¸Šç”Ÿæˆçš„æ•°æ®éƒ½æ˜¯*æµå¼æ€§è´¨çš„*ï¼›è¿™æ„å‘³ç€æ•°æ®ç”±å¤–éƒ¨æºä»¥æˆ‘ä»¬æ— æ³•æ§åˆ¶çš„å¿«é€Ÿé€Ÿç‡ç”Ÿæˆã€‚æƒ³è±¡ä¸€ä¸‹ç”¨æˆ·æ¯ç§’åœ¨Googleæœç´¢å¼•æ“ä¸Šè¿›è¡Œçš„æ‰€æœ‰æœç´¢ã€‚æˆ‘ä»¬ç§°è¿™ç§æ•°æ®ä¸º*æµå¼æ•°æ®*ï¼›å› ä¸ºå®ƒåƒæºªæµä¸€æ ·æºæºä¸æ–­åœ°æ¶Œå…¥ã€‚
- en: 'Some examples of typical streaming web-scale data are as following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›å…¸å‹æµå¼ç½‘é¡µè§„æ¨¡æ•°æ®çš„ç¤ºä¾‹å¦‚ä¸‹ï¼š
- en: '![](../Images/e077ae79ff78e06cf0eeb9950c667107.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e077ae79ff78e06cf0eeb9950c667107.png)'
- en: 'Figure 2: Size of typical streaming web-scale data â€” Image by the author'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2ï¼šå…¸å‹çš„æµå¼ç½‘é¡µè§„æ¨¡æ•°æ®çš„å¤§å° â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: Think of streaming data as a matrix *A* containing *n* rows in *d*-dimensional
    space, where typically *n >> d.* Often *n* is in order of billions and increasing.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æµæ•°æ®è§†ä¸ºåŒ…å«*n* è¡Œã€*d* ç»´ç©ºé—´ä¸­çš„çŸ©é˜µ*A*ï¼Œå…¶ä¸­é€šå¸¸ *n >> d*ã€‚é€šå¸¸ *n* æ˜¯ä»¥åäº¿ä¸ºå•ä½å¹¶ä¸æ–­å¢åŠ çš„ã€‚
- en: Data streaming model
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æµæ¨¡å‹
- en: In streaming model, data arrives at high speed, one row at a time, and algorithms
    must process the items fast, or they are lost forever.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æµæ¨¡å‹ä¸­ï¼Œæ•°æ®ä»¥é«˜é€Ÿåˆ°è¾¾ï¼Œä¸€æ¬¡ä¸€è¡Œï¼Œç®—æ³•å¿…é¡»å¿«é€Ÿå¤„ç†è¿™äº›é¡¹ç›®ï¼Œå¦åˆ™å®ƒä»¬å°†æ°¸è¿œä¸¢å¤±ã€‚
- en: '![](../Images/10a27202839bd9b4ebaadd879632b4aa.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10a27202839bd9b4ebaadd879632b4aa.png)'
- en: 'Figure 3: Data streaming model â€” Image by the author'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾3ï¼šæ•°æ®æµæ¨¡å‹ â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: In data streaming model, algorithms can only make one pass over the data and
    they work with a small memory to do their processing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•°æ®æµæ¨¡å‹ä¸­ï¼Œç®—æ³•åªèƒ½å¯¹æ•°æ®è¿›è¡Œä¸€æ¬¡éå†ï¼Œå¹¶ä¸”éœ€è¦ä½¿ç”¨è¾ƒå°çš„å†…å­˜è¿›è¡Œå¤„ç†ã€‚
- en: Rank-k approximation
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç§©-k è¿‘ä¼¼
- en: '*Rank-k approximation* of a matrix *A* is a smaller matrix *B* of rank *k*
    such that *B* approximates *A accurately.* Figure 2 demonstrates this notion.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ©é˜µ*A*çš„*ç§©-k è¿‘ä¼¼*æ˜¯ä¸€ä¸ªç§©ä¸º*k*çš„è¾ƒå°çŸ©é˜µ*B*ï¼Œä½¿å¾—*B*å¯¹*A*è¿›è¡Œå‡†ç¡®çš„è¿‘ä¼¼ã€‚å›¾2å±•ç¤ºäº†è¿™ä¸€æ¦‚å¿µã€‚
- en: '![](../Images/53dc66610adbfedd4d744da8ee67bd13.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53dc66610adbfedd4d744da8ee67bd13.png)'
- en: 'Figure 4: Getting a much smaller sketch B from A â€” Image by the author'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾4ï¼šä»*A*è·å–æ›´å°çš„è‰å›¾*B* â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: '*B* is often called a sketch of *A.* Note, in data streaming model, B will
    be much smaller than A such that it fits in memory. In addition, rank(B) << rank(A).
    For example, if A is a term-document matrix with 10 billion documents and 1 million
    words then B would probably be a 1000 by million matrix; i.e. 10 million times
    less rows!'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*B*é€šå¸¸è¢«ç§°ä¸º*A*çš„è‰å›¾ã€‚æ³¨æ„ï¼Œåœ¨æ•°æ®æµæ¨¡å‹ä¸­ï¼Œ*B*ä¼šæ¯”*A*å°å¾—å¤šï¼Œä»¥ä¾¿é€‚åˆå†…å­˜ã€‚æ­¤å¤–ï¼Œrank(B) << rank(A)ã€‚ä¾‹å¦‚ï¼Œå¦‚æœ*A*æ˜¯ä¸€ä¸ªåŒ…å«
    100 äº¿æ–‡æ¡£å’Œ 100 ä¸‡è¯çš„æœ¯è¯­-æ–‡æ¡£çŸ©é˜µï¼Œé‚£ä¹ˆ*B*å¯èƒ½æ˜¯ä¸€ä¸ª 1000Ã—100 ä¸‡çš„çŸ©é˜µï¼›å³ï¼Œå°‘ 1000 ä¸‡è¡Œï¼'
- en: 'The rank-k approximation has to approximate A â€œ*accurately*â€. While accurately
    is a vague notion, we can quantify it via various error definitions:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç§©-k è¿‘ä¼¼å¿…é¡»â€œ*å‡†ç¡®*â€åœ°è¿‘ä¼¼*A*ã€‚è™½ç„¶å‡†ç¡®æ˜¯ä¸€ä¸ªæ¨¡ç³Šçš„æ¦‚å¿µï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡å„ç§è¯¯å·®å®šä¹‰æ¥é‡åŒ–å®ƒï¼š
- en: '1ï¸âƒ£ **Covariance error**:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ **åæ–¹å·®è¯¯å·®**ï¼š
- en: 'The covariance error is the Frobenius norm or L2 norm of differences between
    covariance of A and covariance of B. This error is mathematically defined as following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åæ–¹å·®è¯¯å·®æ˜¯çŸ©é˜µ A çš„åæ–¹å·®ä¸çŸ©é˜µ B çš„åæ–¹å·®ä¹‹é—´å·®å¼‚çš„ Frobenius èŒƒæ•°æˆ– L2 èŒƒæ•°ã€‚è¿™ä¸ªè¯¯å·®åœ¨æ•°å­¦ä¸Šå®šä¹‰å¦‚ä¸‹ï¼š
- en: '![](../Images/658c13473308fa953a1b50cc5155ef34.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/658c13473308fa953a1b50cc5155ef34.png)'
- en: covariance error definition â€” Image by the author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åæ–¹å·®è¯¯å·®å®šä¹‰ â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: '2ï¸âƒ£ **Projection error**:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ **æŠ•å½±è¯¯å·®**ï¼š
- en: 'The projection error is the norm of the residual when data points in A are
    projected onto the subspace of B. This residual norm is measured as either L2
    norm or Frobenius norm:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ•å½±è¯¯å·®æ˜¯å½“*A*ä¸­çš„æ•°æ®ç‚¹è¢«æŠ•å½±åˆ°*B*çš„å­ç©ºé—´æ—¶çš„æ®‹å·®çš„èŒƒæ•°ã€‚è¿™ä¸ªæ®‹å·®èŒƒæ•°è¢«æµ‹é‡ä¸º L2 èŒƒæ•°æˆ– Frobenius èŒƒæ•°ï¼š
- en: '![](../Images/310d422bb40a8df456d5b33e90b82a46.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/310d422bb40a8df456d5b33e90b82a46.png)'
- en: projection error definition â€” Image by the author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ•å½±è¯¯å·®å®šä¹‰ â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: These errors assess the quality of the approximation; the smaller they are the
    better the approximation is. But how small can they be?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›è¯¯å·®è¯„ä¼°äº†è¿‘ä¼¼çš„è´¨é‡ï¼›å®ƒä»¬è¶Šå°ï¼Œè¿‘ä¼¼æ•ˆæœè¶Šå¥½ã€‚ä½†å®ƒä»¬å¯ä»¥å°åˆ°ä»€ä¹ˆç¨‹åº¦å‘¢ï¼Ÿ
- en: When we compute these errors, we must have a baseline to compare them against.
    The baseline, everyone uses in field of matrix sketching is the rank-k approximation
    created by *Singular Value Decomposition (SVD)*! SVD computes the best rank-k
    approximation! Meaning it causes the smallest error on both â€œ*covariance errorâ€*
    and â€œ*projection error*â€.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬è®¡ç®—è¿™äº›è¯¯å·®æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»æœ‰ä¸€ä¸ªåŸºå‡†æ¥è¿›è¡Œæ¯”è¾ƒã€‚åœ¨çŸ©é˜µè‰å›¾é¢†åŸŸï¼Œæ¯ä¸ªäººä½¿ç”¨çš„åŸºå‡†æ˜¯ç”±*å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰*åˆ›å»ºçš„ç§©-k è¿‘ä¼¼ï¼SVD è®¡ç®—æœ€ä½³çš„ç§©-k
    è¿‘ä¼¼ï¼è¿™æ„å‘³ç€å®ƒåœ¨â€œ*åæ–¹å·®è¯¯å·®*â€å’Œâ€œ*æŠ•å½±è¯¯å·®*â€ä¸Šé€ æˆçš„è¯¯å·®æœ€å°ã€‚
- en: 'The best rank-k approximation to A is denoted as Aâ‚–. Therefore, the least error
    caused by SVD is :'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹*A*çš„æœ€ä½³ç§©-k è¿‘ä¼¼è®°ä½œAâ‚–ã€‚å› æ­¤ï¼ŒSVDå¼•èµ·çš„æœ€å°è¯¯å·®æ˜¯ï¼š
- en: '![](../Images/037bdb52e3a227e51d760b95a27eef7a.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/037bdb52e3a227e51d760b95a27eef7a.png)'
- en: least rank k approximation error â€” Image by the author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å°ç§©kè¿‘ä¼¼è¯¯å·® â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'SVD, decomposes a matrix *A* into three matrices:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: SVD å°†çŸ©é˜µ*A*åˆ†è§£ä¸ºä¸‰ä¸ªçŸ©é˜µï¼š
- en: The left singular matrix *U*
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å·¦å¥‡å¼‚çŸ©é˜µ *U*
- en: The singular values matrix S
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¥‡å¼‚å€¼çŸ©é˜µ *S*
- en: The right singular matrix V
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å³å¥‡å¼‚çŸ©é˜µ V
- en: U and V are orthonormal, meaning that their columns are of unit norm and they
    are orthogonal; i.e. the dot product of every two columns in U (similarly in V)
    is zero. The matrix S is diagonal; only entries on the diagonal are non-zeros
    and they are sorted in descending order.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: U å’Œ V æ˜¯æ­£äº¤çš„ï¼Œæ„å‘³ç€å®ƒä»¬çš„åˆ—æ˜¯å•ä½èŒƒæ•°ä¸”å®ƒä»¬å½¼æ­¤æ­£äº¤ï¼›å³ U ä¸­æ¯ä¸¤åˆ—ï¼ˆV ä¸­ä¹Ÿæ˜¯ï¼‰ä¹‹é—´çš„ç‚¹ç§¯ä¸ºé›¶ã€‚çŸ©é˜µ S æ˜¯å¯¹è§’çŸ©é˜µï¼›åªæœ‰å¯¹è§’çº¿ä¸Šçš„æ¡ç›®æ˜¯éé›¶çš„ï¼Œå¹¶ä¸”æŒ‰é™åºæ’åˆ—ã€‚
- en: '![](../Images/4e10bfbec83481719adb175f24178a92.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e10bfbec83481719adb175f24178a92.png)'
- en: 'Figure 5: Singular value decomposition â€” Image by the author'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5ï¼šå¥‡å¼‚å€¼åˆ†è§£ â€” å›¾ç‰‡æ¥è‡ªä½œè€…
- en: 'SVD computes the best rank-k approximation by taking the first k columns of
    U and V and the first k entries of S:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: SVD é€šè¿‡å– U å’Œ V çš„å‰ k åˆ—ä»¥åŠ S çš„å‰ k é¡¹æ¥è®¡ç®—æœ€ä½³çš„ç§©-k è¿‘ä¼¼ï¼š
- en: '![](../Images/674b0fccc2d859376d7e9d4bb285847c.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/674b0fccc2d859376d7e9d4bb285847c.png)'
- en: 'Figure 6: Rank k approximation by SVD â€” Image by the author'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 6ï¼šSVD çš„ç§© k è¿‘ä¼¼ â€” å›¾ç‰‡æ¥è‡ªä½œè€…
- en: As we mentioned, the Aâ‚– computed in this way has the lowest approximation error
    among any matrices B with rank k or lower. However, SVD is a very time-consuming
    method, it requires runtime O(ndÂ²) if A is n-by-d, and it is not applicable to
    matrices in data streaming fashion. In addition, SVD is not efficient for sparse
    matrices; it does not utilize sparsity of the matrix in computing approximation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚å‰æ‰€è¿°ï¼Œä»¥è¿™ç§æ–¹å¼è®¡ç®—çš„ Aâ‚– åœ¨ä»»ä½•ç§©ä¸º k æˆ–æ›´ä½çš„çŸ©é˜µ B ä¸­å…·æœ‰æœ€ä½çš„è¿‘ä¼¼è¯¯å·®ã€‚ç„¶è€Œï¼ŒSVD æ˜¯ä¸€ç§éå¸¸è€—æ—¶çš„æ–¹æ³•ï¼Œå¦‚æœ A æ˜¯ nÃ—dï¼Œåˆ™éœ€è¦è¿è¡Œæ—¶é—´
    O(ndÂ²)ï¼Œå¹¶ä¸”ä¸é€‚ç”¨äºæ•°æ®æµä¸­çš„çŸ©é˜µã€‚æ­¤å¤–ï¼ŒSVD å¯¹ç¨€ç–çŸ©é˜µæ•ˆç‡ä¸é«˜ï¼›å®ƒåœ¨è®¡ç®—è¿‘ä¼¼æ—¶æ²¡æœ‰åˆ©ç”¨çŸ©é˜µçš„ç¨€ç–æ€§ã€‚
- en: â“Now the question is how do we compute matrix approximation in streaming fashion
    ?
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: â“ç°åœ¨çš„é—®é¢˜æ˜¯æˆ‘ä»¬å¦‚ä½•ä»¥æµå¼æ–¹å¼è®¡ç®—çŸ©é˜µè¿‘ä¼¼ï¼Ÿ
- en: '**There are three main family of methods in streaming matrix approximations:**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**æµå¼çŸ©é˜µè¿‘ä¼¼æ–¹æ³•ä¸»è¦æœ‰ä¸‰å¤§ç±»ï¼š**'
- en: 1ï¸âƒ£ Row sampling based
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 1ï¸âƒ£ åŸºäºè¡ŒæŠ½æ ·
- en: 2ï¸âƒ£ Random projection based
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 2ï¸âƒ£ éšæœºæŠ•å½±æ–¹æ³•
- en: 3ï¸âƒ£ Iterative sketching
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 3ï¸âƒ£ è¿­ä»£è‰å›¾æ³•
- en: '**Row sampling based methods**'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**åŸºäºè¡ŒæŠ½æ ·çš„æ–¹æ³•**'
- en: 'These methods sample a subset of â€œimportantâ€ rows with respect to a well-defined
    probability distribution. These methods differ is in how they define the notion
    of â€œimportanceâ€. The generic framework is that they construct the sketch B as
    following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ–¹æ³•ä»ç›¸å¯¹äºè‰¯å¥½å®šä¹‰çš„æ¦‚ç‡åˆ†å¸ƒçš„â€œé‡è¦â€è¡Œä¸­è¿›è¡ŒæŠ½æ ·ã€‚è¿™äº›æ–¹æ³•çš„ä¸åŒä¹‹å¤„åœ¨äºå®ƒä»¬å¦‚ä½•å®šä¹‰â€œé‡è¦æ€§â€çš„æ¦‚å¿µã€‚é€šç”¨æ¡†æ¶æ˜¯å®ƒä»¬æŒ‰ä»¥ä¸‹æ–¹å¼æ„å»ºè‰å›¾ Bï¼š
- en: They first assign a probability to each row in the streaming matrix *A*
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ƒä»¬é¦–å…ˆç»™æµå¼çŸ©é˜µ*A*ä¸­çš„æ¯ä¸€è¡Œåˆ†é…ä¸€ä¸ªæ¦‚ç‡
- en: Then they sample *l* rows from *A* (often with replacement) to construct *B*
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åä»–ä»¬ä»*A*ä¸­æŠ½å–*l*è¡Œï¼ˆé€šå¸¸æ˜¯æœ‰æ”¾å›çš„ï¼‰æ¥æ„å»º*B*
- en: Lastly, they rescale *B* appropriately to make it an unbiased estimate of *A*
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ€åï¼Œå®ƒä»¬å°† *B* é€‚å½“ç¼©æ”¾ï¼Œä½¿å…¶æˆä¸º *A* çš„æ— åä¼°è®¡
- en: '![](../Images/abb1b4fd0514a3f347059642385d0014.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/abb1b4fd0514a3f347059642385d0014.png)'
- en: 'Figure 7: Row sampling with replacement to build sketch B â€” Image by the author'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7ï¼šæœ‰æ”¾å›çš„è¡ŒæŠ½æ ·ä»¥æ„å»ºè‰å›¾ B â€” å›¾ç‰‡æ¥è‡ªä½œè€…
- en: Note, the probability assigned to rows in step 1, is in fact the â€œimportanceâ€
    of the row. Think of â€œimportanceâ€ of an item as the weight associated to the item
    e.g. for file records, the weight can be size of the files. Or for IP addresses,
    the weight can be the number of times the IP address makes a request.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæ­¥éª¤ 1 ä¸­åˆ†é…ç»™è¡Œçš„æ¦‚ç‡å®é™…ä¸Šæ˜¯è¡Œçš„â€œé‡è¦æ€§â€ã€‚å°†â€œé‡è¦æ€§â€è§†ä¸ºä¸é¡¹ç›¸å…³çš„æƒé‡ï¼Œä¾‹å¦‚ï¼Œå¯¹äºæ–‡ä»¶è®°å½•ï¼Œæƒé‡å¯ä»¥æ˜¯æ–‡ä»¶çš„å¤§å°ã€‚æˆ–è€…å¯¹äº IP åœ°å€ï¼Œæƒé‡å¯ä»¥æ˜¯
    IP åœ°å€å‘å‡ºè¯·æ±‚çš„æ¬¡æ•°ã€‚
- en: 'In matrices, each item is a row vector, and its weight is the squared of its
    norm; also called *L2 norm*. There is a row sampling algorithm that samples with
    respect to L2 norm of rows in a one pass over data. This algorithm is called â€œ*L2-norm
    row sampling*â€, and its pseudocode is as following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çŸ©é˜µä¸­ï¼Œæ¯ä¸ªé¡¹éƒ½æ˜¯ä¸€ä¸ªè¡Œå‘é‡ï¼Œå…¶æƒé‡æ˜¯å…¶èŒƒæ•°çš„å¹³æ–¹ï¼›ä¹Ÿç§°ä¸º *L2 èŒƒæ•°*ã€‚æœ‰ä¸€ç§è¡ŒæŠ½æ ·ç®—æ³•æ ¹æ®è¡Œçš„ L2 èŒƒæ•°åœ¨æ•°æ®çš„ä¸€æ¬¡éå†ä¸­è¿›è¡ŒæŠ½æ ·ã€‚è¿™ä¸ªç®—æ³•è¢«ç§°ä¸ºâ€œ*L2
    èŒƒæ•°è¡ŒæŠ½æ ·*â€ï¼Œå…¶ä¼ªä»£ç å¦‚ä¸‹ï¼š
- en: '![](../Images/c4351950a8a133bb15b461a8547faac1.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4351950a8a133bb15b461a8547faac1.png)'
- en: 'Figure 8: L2-norm row sampling algorithm â€” Image by the author'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 8ï¼šL2 èŒƒæ•°è¡ŒæŠ½æ ·ç®—æ³• â€” å›¾ç‰‡æ¥è‡ªä½œè€…
- en: 'This algorithm samples *l = O(k/ÎµÂ²)* rows with replacement and achieves the
    following error bound:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç®—æ³•ä»¥æœ‰æ”¾å›çš„æ–¹å¼æŠ½æ · *l = O(k/ÎµÂ²)* è¡Œï¼Œå¹¶å®ç°ä»¥ä¸‹è¯¯å·®ç•Œé™ï¼š
- en: '![](../Images/c4f00ca30599e08831b10004abfa0dee.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4f00ca30599e08831b10004abfa0dee.png)'
- en: 'Figure 9: Error guarantee of L2-norm row sampling â€” Image by the author'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 9ï¼šL2 èŒƒæ•°è¡ŒæŠ½æ ·çš„è¯¯å·®ä¿è¯ â€” å›¾ç‰‡æ¥è‡ªä½œè€…
- en: Note, this is a weak error bound, as it is bounded by total Frobenius norm of
    A, which can be a large number! There is an extension of this algorithm that performs
    better; letâ€™s take a look at it.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ä¸ªè¾ƒå¼±çš„è¯¯å·®ç•Œé™ï¼Œå› ä¸ºå®ƒå—é™äºçŸ©é˜µAçš„FrobeniusèŒƒæ•°ï¼Œæ€»ä½“æ¥è¯´å¯èƒ½æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æ•°å€¼ï¼æœ‰ä¸€ä¸ªæ”¹è¿›çš„ç®—æ³•è¡¨ç°æ›´å¥½ï¼›æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒã€‚
- en: '**Extension**: There is a variation of this algorithm that samples both rows
    and columns! It is called â€œ*CUR*â€ algorithm and it performs better than â€œ*L2-norm
    row samplingâ€* method. The *CUR* method creates three matrices C, U and R by sampling
    rows and columns of A. Here is how it works:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ‰©å±•**ï¼šæœ‰ä¸€ç§å˜ä½“ç®—æ³•åŒæ—¶é‡‡æ ·è¡Œå’Œåˆ—ï¼å®ƒè¢«ç§°ä¸ºâ€œ*CUR*â€ç®—æ³•ï¼Œå¹¶ä¸”æ¯”â€œ*L2-èŒƒæ•°è¡Œé‡‡æ ·*â€æ–¹æ³•è¡¨ç°æ›´å¥½ã€‚*CUR*æ–¹æ³•é€šè¿‡ä»Aä¸­é‡‡æ ·è¡Œå’Œåˆ—æ¥åˆ›å»ºä¸‰ä¸ªçŸ©é˜µCã€Uå’ŒRã€‚å®ƒçš„å·¥ä½œåŸç†å¦‚ä¸‹ï¼š'
- en: 'Step 1: *CUR* first samples few columns of *A*, each with the probability proportional
    to the norm of the columns. This makes the matrix *C*.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤1ï¼š*CUR*é¦–å…ˆä»*A*ä¸­é‡‡æ ·å‡ åˆ—ï¼Œæ¯åˆ—çš„é‡‡æ ·æ¦‚ç‡ä¸è¯¥åˆ—çš„èŒƒæ•°æˆæ­£æ¯”ã€‚è¿™å½¢æˆäº†çŸ©é˜µ*C*ã€‚
- en: '![](../Images/f850303fc206dc110d8bea962fbe599b.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f850303fc206dc110d8bea962fbe599b.png)'
- en: 'Figure 10: CUR algorithm step 1â€” Image by the author'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾10ï¼šCURç®—æ³•æ­¥éª¤1â€”â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'Step 2: Then *CUR* samples few rows of *A*, each with probability proportional
    to the norm of the rows. This forms matrix *R*.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤2ï¼šç„¶å*CUR*ä»*A*ä¸­éšæœºæŠ½å–å‡ è¡Œï¼Œæ¯è¡Œçš„æŠ½å–æ¦‚ç‡ä¸è¯¥è¡Œçš„èŒƒæ•°æˆæ­£æ¯”ã€‚è¿™å½¢æˆäº†çŸ©é˜µ*R*ã€‚
- en: 'Step 3: The CUR then computes the pseudo-inverse of the intersection of C and
    R. This is called matrix U.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤3ï¼šCURç„¶åè®¡ç®—Cå’ŒRçš„äº¤é›†çš„ä¼ªé€†ã€‚è¿™è¢«ç§°ä¸ºçŸ©é˜µUã€‚
- en: '![](../Images/2d65f393f1a9bdf84c008271097e31b6.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d65f393f1a9bdf84c008271097e31b6.png)'
- en: 'Figure 11: CUR algorithm step 2,3â€” Image by the author'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾11ï¼šCURç®—æ³•æ­¥éª¤2,3â€”â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Finally, the product of these three matrices, i.e. *C.U.R* approximates *A*,
    and provides a low-rank approximation. This algorithm achieves the following error
    bound sampling *l = O(k log k/ÎµÂ²)* rows and columns.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆï¼Œè¿™ä¸‰ä¸ªçŸ©é˜µçš„ä¹˜ç§¯ï¼Œå³*C.U.R*ï¼Œè¿‘ä¼¼äº*A*ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªä½ç§©è¿‘ä¼¼ã€‚è¯¥ç®—æ³•åœ¨é‡‡æ ·*l = O(k log k/ÎµÂ²)*è¡Œå’Œåˆ—æ—¶è¾¾åˆ°äº†ä»¥ä¸‹è¯¯å·®ç•Œé™ã€‚
- en: '![](../Images/1e4dcb2aafc66e61401b8c4ec1791d95.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e4dcb2aafc66e61401b8c4ec1791d95.png)'
- en: 'Figure 12: CUR Error guarantee â€” Image by the author'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾12ï¼šCURè¯¯å·®ä¿è¯â€”â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Note, how this is a much tighter bound as compared to *L2-norm row sampling.*
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œä¸*L2-èŒƒæ•°è¡Œé‡‡æ ·*ç›¸æ¯”ï¼Œè¿™ä¸ªç•Œé™è¦ç´§å¾—å¤šã€‚
- en: '**Summary:** The row sampling family of methods (CUR included) samples rows
    (and columns) to form a low-rank approximation; therefore they are very intuitive
    and form interpretable approximations.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ€»ç»“ï¼š** è¡Œé‡‡æ ·æ–¹æ³•å®¶æ—ï¼ˆåŒ…æ‹¬CURï¼‰é€šè¿‡é‡‡æ ·è¡Œï¼ˆå’Œåˆ—ï¼‰æ¥å½¢æˆä½ç§©è¿‘ä¼¼ï¼Œå› æ­¤å®ƒä»¬éå¸¸ç›´è§‚å¹¶å½¢æˆå¯è§£é‡Šçš„è¿‘ä¼¼ã€‚'
- en: In the next section, we see another family of methods that are data oblivious.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦ä¸€ç±»æ•°æ®æ— å…³çš„æ–¹æ³•ã€‚
- en: '**Random projection based methods**'
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**åŸºäºéšæœºæŠ•å½±çš„æ–¹æ³•**'
- en: The key idea of these group of methods is that if points in a vector space are
    projected onto a randomly selected subspace of suitably high dimension, then the
    distances between points are approximately preserved*.*
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ–¹æ³•ç»„çš„å…³é”®æ€æƒ³æ˜¯ï¼Œå¦‚æœå°†å‘é‡ç©ºé—´ä¸­çš„ç‚¹æŠ•å½±åˆ°ä¸€ä¸ªéšæœºé€‰æ‹©çš„é€‚å½“é«˜ç»´å­ç©ºé—´ä¸­ï¼Œåˆ™ç‚¹ä¹‹é—´çš„è·ç¦»å¤§è‡´ä¿æŒä¸å˜*ã€‚*
- en: '**Johnson-Lindenstrauss Transform (JLT)** specifies this nicely as following:
    ***d*** datapoints in any dimension (e.g. n-dimensional space for nâ‰«d) can get
    embedded into roughly ***log d*** dimensional space, such that their pair-wise
    distances are preserved to some extent.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**Johnson-Lindenstrausså˜æ¢ï¼ˆJLTï¼‰**å¾ˆå¥½åœ°æè¿°äº†è¿™ä¸€ç‚¹ï¼š***d***ä¸ªæ•°æ®ç‚¹åœ¨ä»»ä½•ç»´åº¦ï¼ˆä¾‹å¦‚ï¼Œå¯¹äºnâ‰«dçš„nç»´ç©ºé—´ï¼‰ä¸­å¯ä»¥è¢«åµŒå…¥åˆ°å¤§çº¦***log
    d***ç»´çš„ç©ºé—´ä¸­ï¼Œä½¿å¾—å®ƒä»¬çš„æˆå¯¹è·ç¦»åœ¨æŸç§ç¨‹åº¦ä¸Šå¾—ä»¥ä¿æŒã€‚'
- en: 'A more precise and mathematical definition of JLT is as following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: JLTçš„æ›´ç²¾ç¡®å’Œæ•°å­¦åŒ–çš„å®šä¹‰å¦‚ä¸‹ï¼š
- en: '![](../Images/fa42af817b3ba58390a124621bb9dd9e.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa42af817b3ba58390a124621bb9dd9e.png)'
- en: 'Figure 13: JLT definition â€” Image by the author'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾13ï¼šJLTå®šä¹‰â€”â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'There are many ways to construct a matrix S that preserve pair-wise distances.
    All such matrices are called to have the *JLT property*. The image below, shows
    few well-known ways of creating such matrix S:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è®¸å¤šæ–¹æ³•å¯ä»¥æ„é€ ä¸€ä¸ªçŸ©é˜µSï¼Œä»¥ä¿æŒæˆå¯¹è·ç¦»ã€‚æ‰€æœ‰è¿™äº›çŸ©é˜µéƒ½ç§°ä¸ºå…·æœ‰*JLTå±æ€§*ã€‚ä¸‹å›¾å±•ç¤ºäº†ä¸€äº›åˆ›å»ºè¿™æ ·çš„çŸ©é˜µSçš„å¸¸è§æ–¹æ³•ï¼š
- en: '![](../Images/40fec39e26e49d953b0503b0d5d96494.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/40fec39e26e49d953b0503b0d5d96494.png)'
- en: Image by the author
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'One simple construction of *S,* as shown above,is to pick entries of *S* to
    be independent random variables drawn from *N(0,1),* and rescale S by âˆš(1/r):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œ*S*çš„ä¸€ä¸ªç®€å•æ„é€ æ˜¯ä»*N(0,1)*ä¸­æŠ½å–ç‹¬ç«‹éšæœºå˜é‡ä½œä¸º*S*çš„æ¡ç›®ï¼Œç„¶åå°†SæŒ‰âˆš(1/r)è¿›è¡Œç¼©æ”¾ï¼š
- en: '![](../Images/0eb53e2113540584d8817b5bcf163dbc.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0eb53e2113540584d8817b5bcf163dbc.png)'
- en: 'Figure 14: JLT matrix â€” Image by the author'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾14ï¼šJLTçŸ©é˜µâ€”â€” å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: 'This matrix has the *JLT property* [6]*,* and we use it to design a random
    projection method as following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªçŸ©é˜µå…·æœ‰ *JLT å±æ€§* [6]*ï¼Œæˆ‘ä»¬ç”¨å®ƒæ¥è®¾è®¡éšæœºæŠ•å½±æ–¹æ³•å¦‚ä¸‹ï¼š
- en: '![](../Images/9ee91d359bb577156591f1798af06386.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9ee91d359bb577156591f1798af06386.png)'
- en: 'Figure 15: Random projection method â€” Image by the author'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾15ï¼šéšæœºæŠ•å½±æ–¹æ³• â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: 'Note the second step, projects data points from a high n-dimensional space
    into a lower r-dimensional space. Itâ€™s easy to show [6]that this method produces
    an unbiased sketch:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ç¬¬äºŒæ­¥ï¼Œå®ƒå°†æ•°æ®ç‚¹ä»é«˜ç»´ç©ºé—´æŠ•å½±åˆ°ä½ç»´ç©ºé—´ã€‚å¾ˆå®¹æ˜“è¯æ˜ [6] è¯¥æ–¹æ³•ç”Ÿæˆäº†æ— åçš„è‰å›¾ï¼š
- en: '![](../Images/bb25673959486234e80ad3ab294d0d4a.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb25673959486234e80ad3ab294d0d4a.png)'
- en: 'Figure 16: Random projection provides an unbiased approximationâ€” Image by the
    author'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾16ï¼šéšæœºæŠ•å½±æä¾›äº†æ— åçš„è¿‘ä¼¼ â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: The random projection method achieves the following error guarantee if it sets
    *r = O(k/Îµ + k log k).* Note that they achieve better bound than row sampling
    methods.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæŠ•å½±æ–¹æ³•åœ¨è®¾ç½® *r = O(k/Îµ + k log k)* æ—¶èƒ½è¾¾åˆ°ä»¥ä¸‹è¯¯å·®ä¿è¯ã€‚è¯·æ³¨æ„ï¼Œå®ƒä»¬çš„ç•Œé™ä¼˜äºè¡Œé‡‡æ ·æ–¹æ³•ã€‚
- en: '![](../Images/0b86a215b239461b2af2ae74e967a33c.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b86a215b239461b2af2ae74e967a33c.png)'
- en: 'Figure 17: Random projection error boundâ€” Image by the author'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾17ï¼šéšæœºæŠ•å½±è¯¯å·®ç•Œé™ â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: There is a similar line of work to random projection that achieves better time
    bound. It is called *Hashing techniques* [5]. This method take a matrix S which
    has only one non-zero entries per column and that entry is either 1 or -1\. They
    compute the approximation as *B = SA.*
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ç±»ä¸éšæœºæŠ•å½±ç±»ä¼¼çš„å·¥ä½œå¯ä»¥å®ç°æ›´å¥½çš„æ—¶é—´ç•Œé™ã€‚å®ƒè¢«ç§°ä¸º *å“ˆå¸ŒæŠ€æœ¯* [5]ã€‚è¿™ç§æ–¹æ³•é‡‡ç”¨ä¸€ä¸ªæ¯åˆ—åªæœ‰ä¸€ä¸ªéé›¶æ¡ç›®çš„çŸ©é˜µ Sï¼Œè€Œè¯¥æ¡ç›®æ˜¯1æˆ–-1ã€‚å®ƒä»¬è®¡ç®—è¿‘ä¼¼å€¼ä¸º
    *B = SA*ã€‚
- en: '![](../Images/b5950efa90c38aa8d34de9166328aaf4.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5950efa90c38aa8d34de9166328aaf4.png)'
- en: Hashing technique â€” Image by the author
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å“ˆå¸ŒæŠ€æœ¯ â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: '**Summary**: Random projection methods are computationally efficient, and are
    data oblivious as their computation involves only a random matrix S. Compare it
    to row sampling methods that need to access data to form a sketch.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ€»ç»“**ï¼šéšæœºæŠ•å½±æ–¹æ³•è®¡ç®—æ•ˆç‡é«˜ï¼Œå¹¶ä¸”æ•°æ®æ— å…³ï¼Œå› ä¸ºå…¶è®¡ç®—ä»…æ¶‰åŠä¸€ä¸ªéšæœºçŸ©é˜µ Sã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè¡Œé‡‡æ ·æ–¹æ³•éœ€è¦è®¿é—®æ•°æ®ä»¥å½¢æˆè‰å›¾ã€‚'
- en: '**Iterative Sketching**'
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**è¿­ä»£è‰å›¾**'
- en: These methods work over a stream A=<a1,a2,â€¦> where each item is read once, get
    processed quickly and not read again. Upon reading each item, they update the
    sketch B.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ–¹æ³•åœ¨æµ A=<a1,a2,â€¦> ä¸Šå·¥ä½œï¼Œå…¶ä¸­æ¯ä¸ªé¡¹ç›®è¢«è¯»å–ä¸€æ¬¡ï¼Œè¿…é€Ÿå¤„ç†ä¸”ä¸å†è¯»å–ã€‚è¯»å–æ¯ä¸ªé¡¹ç›®æ—¶ï¼Œå®ƒä»¬æ›´æ–°è‰å›¾ Bã€‚
- en: '![](../Images/4ec8205e7236541afe7681edcecf06b3.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ec8205e7236541afe7681edcecf06b3.png)'
- en: 'Figure 18: Iterative sketching methods â€” Image by the author'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾18ï¼šè¿­ä»£è‰å›¾æ–¹æ³• â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: State of the art method in this group is called â€œ*Frequent Directions*â€, and
    it is based on *Misra-Gries algorithm* for finding frequent items in a data stream.
    In what follows, we first see how Misra-Gries algorithm for finding frequent items
    work, then we extend it to matrices.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç»„çš„æœ€å…ˆè¿›æ–¹æ³•ç§°ä¸ºâ€œ*é¢‘ç¹æ–¹å‘*â€ï¼ŒåŸºäº *Misra-Gries ç®—æ³•* æŸ¥æ‰¾æ•°æ®æµä¸­çš„é¢‘ç¹é¡¹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é¦–å…ˆäº†è§£ Misra-Gries ç®—æ³•å¦‚ä½•æŸ¥æ‰¾é¢‘ç¹é¡¹ï¼Œç„¶åå°†å…¶æ‰©å±•åˆ°çŸ©é˜µã€‚
- en: Misra-Gries algorithm for finding frequent items
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Misra-Gries ç®—æ³•ç”¨äºæŸ¥æ‰¾é¢‘ç¹é¡¹
- en: Suppose there is a stream of items, and we want to find frequency *f(i)* of
    each item.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æœ‰ä¸€ä¸ªé¡¹ç›®æµï¼Œæˆ‘ä»¬æƒ³æ‰¾åˆ°æ¯ä¸ªé¡¹ç›®çš„é¢‘ç‡ *f(i)*ã€‚
- en: '![](../Images/54d29ccd557f9d13039452fd568f5703.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54d29ccd557f9d13039452fd568f5703.png)'
- en: 'Figure 19: frequent item counting over streams â€” Image by the author'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾19ï¼šæµä¸­çš„é¢‘ç¹é¡¹è®¡æ•° â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: If we keep ***d*** counters, we can count frequency of every item. But itâ€™s
    not good enough as for certain domains such IP addresses, queries, etc. the number
    of unique items are way too many.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ä¿æŒ ***d*** ä¸ªè®¡æ•°å™¨ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—æ¯ä¸ªé¡¹çš„é¢‘ç‡ã€‚ä½†è¿™ä¸å¤Ÿå¥½ï¼Œå› ä¸ºåœ¨æŸäº›é¢†åŸŸï¼Œå¦‚ IP åœ°å€ã€æŸ¥è¯¢ç­‰ï¼Œå”¯ä¸€é¡¹çš„æ•°é‡å¤ªå¤šäº†ã€‚
- en: '![](../Images/206173be287481bc8955b9da0bedef23.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/206173be287481bc8955b9da0bedef23.png)'
- en: 'Figure 20: d counters for item frequency estimation â€” Image by the author'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾20ï¼šç”¨äºé¡¹é¢‘ç‡ä¼°è®¡çš„dä¸ªè®¡æ•°å™¨ â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: 'So letâ€™s Letâ€™s keep *l* counters where *lâ‰ªd.* If a new item arrives in the
    stream that is in the counters, we add 1 to its count:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥è®©æˆ‘ä»¬ä¿æŒ *l* ä¸ªè®¡æ•°å™¨ï¼Œå…¶ä¸­ *lâ‰ªd*ã€‚å¦‚æœæµä¸­åˆ°è¾¾çš„æ–°é¡¹ç›®åœ¨è®¡æ•°å™¨ä¸­ï¼Œæˆ‘ä»¬å°†å…¶è®¡æ•°åŠ 1ï¼š
- en: '![](../Images/3a394fab3373e54819d58c3b2995ae35.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a394fab3373e54819d58c3b2995ae35.png)'
- en: 'Figure 21: incrementing counter of an item â€” image by the author'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾21ï¼šå¢åŠ é¡¹çš„è®¡æ•°å™¨ â€” ä½œè€…æä¾›çš„å›¾ç‰‡
- en: If the new item is not in the counters and we have space, we create a counter
    for it and set it to 1.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ–°é¡¹ç›®ä¸åœ¨è®¡æ•°å™¨ä¸­ä¸”æˆ‘ä»¬æœ‰ç©ºé—´ï¼Œæˆ‘ä»¬ä¸ºå…¶åˆ›å»ºä¸€ä¸ªè®¡æ•°å™¨å¹¶å°†å…¶è®¾ç½®ä¸º1ã€‚
- en: '![](../Images/0708aad8dd0be90b5b604c637ae20f16.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0708aad8dd0be90b5b604c637ae20f16.png)'
- en: 'Figure 22: setting counter for a new item â€” Image by the author'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 22ï¼šä¸ºæ–°é¡¹ç›®è®¾ç½®è®¡æ•°å™¨ â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: 'But if we donâ€™t have space for the new item (here the new item is the brown
    box), we get the median counter i.e. counter at position *l/2*:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†å¦‚æœæˆ‘ä»¬æ²¡æœ‰ç©ºé—´å®¹çº³æ–°é¡¹ç›®ï¼ˆè¿™é‡Œçš„æ–°é¡¹ç›®æ˜¯æ£•è‰²ç›’å­ï¼‰ï¼Œæˆ‘ä»¬è·å¾—ä¸­ä½æ•°è®¡æ•°å™¨ï¼Œå³ä½ç½®ä¸º*l/2*çš„è®¡æ•°å™¨ï¼š
- en: '![](../Images/db530dd4cd999766870474f0a0d4254e.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db530dd4cd999766870474f0a0d4254e.png)'
- en: 'Figure 23: subtracting middle counter from every one.â€” Image by the author'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 23ï¼šä»æ¯ä¸€ä¸ªè®¡æ•°å™¨ä¸­å‡å»ä¸­é—´è®¡æ•°å™¨ã€‚â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: 'and subtract it from all counters. For all counters that get negative, we reset
    them to zero. So it becomes as following:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¶ä»æ‰€æœ‰è®¡æ•°å™¨ä¸­å‡å»å®ƒã€‚å¯¹äºæ‰€æœ‰å˜æˆè´Ÿå€¼çš„è®¡æ•°å™¨ï¼Œæˆ‘ä»¬å°†å…¶é‡ç½®ä¸ºé›¶ã€‚æ‰€ä»¥å®ƒå˜æˆå¦‚ä¸‹ï¼š
- en: '![](../Images/6cf66db80be1c254e6e4e3bf4f034900.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6cf66db80be1c254e6e4e3bf4f034900.png)'
- en: 'Figure 24: half of counters are zero â€” Image by the author'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 24ï¼šä¸€åŠè®¡æ•°å™¨ä¸ºé›¶ â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: As we see, now we have space for the new item, so we continue processing the
    streamğŸ™‚.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œç°åœ¨æˆ‘ä»¬æœ‰ç©ºé—´å®¹çº³æ–°é¡¹ç›®ï¼Œæ‰€ä»¥æˆ‘ä»¬ç»§ç»­å¤„ç†æµğŸ™‚ã€‚
- en: 'At any time in the stream, the approximated counts for items are what we have
    kept so far, for example:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æµçš„ä»»ä½•æ—¶åˆ»ï¼Œé¡¹ç›®çš„è¿‘ä¼¼è®¡æ•°æ˜¯æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢ä¿ç•™çš„è®¡æ•°ï¼Œä¾‹å¦‚ï¼š
- en: '![](../Images/27582695b5d02ddba678f230d04bac92.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27582695b5d02ddba678f230d04bac92.png)'
- en: 'Figure 25: estimating count of an item â€” Image by the author'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 25ï¼šä¼°è®¡é¡¹ç›®è®¡æ•° â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: 'This method undercounts so for any item i, its approximated frequency is lesser
    or equal to its true frequency:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•ä¼šä½ä¼°è®¡æ•°ï¼Œå› æ­¤å¯¹äºä»»ä½•é¡¹ç›® iï¼Œå…¶è¿‘ä¼¼é¢‘ç‡å°äºæˆ–ç­‰äºå…¶çœŸå®é¢‘ç‡ï¼š
- en: '![](../Images/9acefc419d289c334bc6c37b25734dd8.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9acefc419d289c334bc6c37b25734dd8.png)'
- en: At the same time, its approximated frequency is lower bounded because each time
    we decrease, we decrease by at most count of the counter at position *l/2 i.e.,*
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ­¤åŒæ—¶ï¼Œå®ƒçš„è¿‘ä¼¼é¢‘ç‡æ˜¯ä¸‹ç•Œçš„ï¼Œå› ä¸ºæ¯æ¬¡æˆ‘ä»¬å‡å°‘æ—¶ï¼Œæœ€å¤šå‡å°‘*l/2*ä½ç½®è®¡æ•°å™¨çš„è®¡æ•°ã€‚
- en: '![](../Images/546c48ec031b97d17e06bd9c22111c61.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/546c48ec031b97d17e06bd9c22111c61.png)'
- en: 'At any point that we have seen ***n*** elements in stream, we have:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æµä¸­çœ‹åˆ°***n***ä¸ªå…ƒç´ çš„ä»»ä½•ç‚¹ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: '![](../Images/ac227771f0be7275d8fb40c84e90ca74.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac227771f0be7275d8fb40c84e90ca74.png)'
- en: 'So the error guarantee it provides is as following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå®ƒæä¾›çš„é”™è¯¯ä¿è¯å¦‚ä¸‹ï¼š
- en: '![](../Images/ede440a1b30bc4c853a4dd087778ee65.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ede440a1b30bc4c853a4dd087778ee65.png)'
- en: Misra-Gries error bound â€” Image by the author
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Misra-Gries é”™è¯¯ç•Œé™ â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: So Misra-Gries produces a non-zero approximated frequency for all items that
    their true frequency is larger than *2n/l* . As an example, to find items that
    appear more than 20% of the time we got to take *l = 10* counters and run Misra-Gries
    algorithm.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼ŒMisra-Gries å¯¹æ‰€æœ‰çœŸå®é¢‘ç‡å¤§äº*2n/l*çš„é¡¹ç›®ç”Ÿæˆä¸€ä¸ªéé›¶è¿‘ä¼¼é¢‘ç‡ã€‚ä¾‹å¦‚ï¼Œè¦æ‰¾åˆ°å‡ºç°è¶…è¿‡ 20% çš„é¡¹ç›®ï¼Œæˆ‘ä»¬å¿…é¡»é‡‡å–*l = 10*è®¡æ•°å™¨å¹¶è¿è¡Œ
    Misra-Gries ç®—æ³•ã€‚
- en: 'Frequent Directions: an extension of Misra-Gries'
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é¢‘ç¹æ–¹å‘ï¼šMisra-Gries çš„æ‰©å±•
- en: Now, letâ€™s extend Misra-Gries to vectors and matrices. In matrix case, the stream
    items are **row vectors** in ***d*** dimension. At any time ***n*** in the stream,
    all rows together form a tall matrix *A* of *n* rows. The goal is to find the
    **most important directions** of A. These correspond to top singular vectors of
    A. The more important a direction is the more frequent it is among data points,
    thatâ€™s why we call the next algorithm **Frequent Directions** [2,3].
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°† Misra-Gries æ‰©å±•åˆ°å‘é‡å’ŒçŸ©é˜µã€‚åœ¨çŸ©é˜µçš„æƒ…å†µä¸‹ï¼Œæµä¸­çš„é¡¹ç›®æ˜¯***d***ç»´çš„**è¡Œå‘é‡**ã€‚åœ¨æµä¸­çš„ä»»ä½•æ—¶åˆ»***n***ï¼Œæ‰€æœ‰è¡Œä¸€èµ·å½¢æˆä¸€ä¸ª*æœ‰*n*è¡Œçš„é«˜çŸ©é˜µ*A*ã€‚ç›®æ ‡æ˜¯æ‰¾åˆ°*A*çš„**æœ€é‡è¦æ–¹å‘**ã€‚è¿™äº›æ–¹å‘å¯¹åº”äº*A*çš„å‰å‡ ä¸ªå¥‡å¼‚å‘é‡ã€‚ä¸€ä¸ªæ–¹å‘è¶Šé‡è¦ï¼Œå®ƒåœ¨æ•°æ®ç‚¹ä¸­å‡ºç°çš„é¢‘ç‡å°±è¶Šé«˜ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬ç§°ä¸‹ä¸€ä¸ªç®—æ³•ä¸º**é¢‘ç¹æ–¹å‘**
    [2,3]çš„åŸå› ã€‚
- en: 'The pseudocode for *Frequent Directions* algorithm is as following:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '*é¢‘ç¹æ–¹å‘*ç®—æ³•çš„ä¼ªä»£ç å¦‚ä¸‹ï¼š'
- en: '![](../Images/561c183c6cd15343f8b9d982a2a4bddf.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/561c183c6cd15343f8b9d982a2a4bddf.png)'
- en: 'Figure 26: FrequentDirectionsâ€” Image by the author'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 26ï¼šFrequentDirections â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: 'As we see, the algorithm takes input matrix *A* and the sketch size *l* as
    inputs. Then, in the first step (i.e. in the first line highlighted in blue) the
    algorithm initializes sketch *B* as an empty matrix of *l* rows. Then for every
    row in the stream *A*, the algorithm insert it into *B* until *B* is full:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œè¯¥ç®—æ³•ä»¥çŸ©é˜µ*A*å’Œè‰å›¾å¤§å°*l*ä½œä¸ºè¾“å…¥ã€‚ç„¶åï¼Œåœ¨ç¬¬ä¸€æ­¥ï¼ˆå³ç¬¬ä¸€è¡Œçªå‡ºæ˜¾ç¤ºçš„è“è‰²éƒ¨åˆ†ï¼‰ï¼Œç®—æ³•å°†è‰å›¾*B*åˆå§‹åŒ–ä¸ºç©ºçŸ©é˜µï¼Œå…·æœ‰*l*è¡Œã€‚ç„¶åå¯¹äºæµä¸­çš„æ¯ä¸€è¡Œ*A*ï¼Œç®—æ³•å°†å…¶æ’å…¥*B*ä¸­ï¼Œç›´åˆ°*B*æ»¡ä¸ºæ­¢ï¼š
- en: '![](../Images/a2fbac30a27748109eb50e886b82d496.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a2fbac30a27748109eb50e886b82d496.png)'
- en: 'Figure 27: when sketch B is full â€” Image by the author'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 27ï¼šå½“è‰å›¾ B æ»¡æ—¶ â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: We then compute *SVD* of *B*; this produces left singular matrix *U*, singular
    values matrix *S* and right singular matrix *V*. Note *U*, and *V* provide rotation
    of subspaces as they are orthonormal matrices.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬è®¡ç®—*B*çš„*SVD*ï¼›è¿™å°†äº§ç”Ÿå·¦å¥‡å¼‚çŸ©é˜µ*U*ã€å¥‡å¼‚å€¼çŸ©é˜µ*S*å’Œå³å¥‡å¼‚çŸ©é˜µ*V*ã€‚æ³¨æ„ï¼Œ*U*å’Œ*V*æä¾›äº†å­ç©ºé—´çš„æ—‹è½¬ï¼Œå› ä¸ºå®ƒä»¬æ˜¯æ­£äº¤çŸ©é˜µã€‚
- en: '![](../Images/1175b22b2c060f147b19d1a8c06428b7.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1175b22b2c060f147b19d1a8c06428b7.png)'
- en: 'Figure 28: SVD of B â€” Image by the author'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ 28: B çš„ SVD â€” ä½œè€…æä¾›çš„å›¾åƒ'
- en: We then reduce *B*â€™s rank by subtracting the squared of middle singular value
    from squared of all singular values! Note, this step resembles the part in Misra-Gries
    where we subtract middle counter from all counters. Subtracting squared of middle
    singular value from squared of all singular values makes half of singular values
    go to zero.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬é€šè¿‡ä»æ‰€æœ‰å¥‡å¼‚å€¼çš„å¹³æ–¹ä¸­å‡å»ä¸­é—´å¥‡å¼‚å€¼çš„å¹³æ–¹æ¥é™ä½*B*çš„ç§©ï¼æ³¨æ„ï¼Œè¿™ä¸€æ­¥ç±»ä¼¼äºMisra-Griesä¸­çš„éƒ¨åˆ†æ“ä½œï¼Œæˆ‘ä»¬ä»æ‰€æœ‰è®¡æ•°å™¨ä¸­å‡å»ä¸­é—´è®¡æ•°å™¨ã€‚ä»æ‰€æœ‰å¥‡å¼‚å€¼çš„å¹³æ–¹ä¸­å‡å»ä¸­é—´å¥‡å¼‚å€¼çš„å¹³æ–¹ä½¿å¾—ä¸€åŠçš„å¥‡å¼‚å€¼å˜ä¸ºé›¶ã€‚
- en: '![](../Images/105b9e0fd0dcc1737c05d7b47ea2d5f4.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/105b9e0fd0dcc1737c05d7b47ea2d5f4.png)'
- en: 'Figure 29: lowering rank of B â€” Image by the author'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ 29: é™ä½ B çš„ç§© â€” ä½œè€…æä¾›çš„å›¾åƒ'
- en: We then multiply *S* (the singular value matrix) by *V* transposed (right singular
    matrix) and assign it to *B*. In other words, we reconstruct *B* by dropping the
    left singular matrix *U*. The effect of this operation is a new matrix *B* which
    has half of its rows as empty. Thatâ€™s good news, as it has room for next upcoming
    rows in the stream matrix *A.*
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†*S*ï¼ˆå¥‡å¼‚å€¼çŸ©é˜µï¼‰ä¹˜ä»¥*V* è½¬ç½®ï¼ˆå³å¥‡å¼‚çŸ©é˜µï¼‰å¹¶å°†å…¶åˆ†é…ç»™*B*ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬é€šè¿‡å»æ‰å·¦å¥‡å¼‚çŸ©é˜µ*U*æ¥é‡æ„*B*ã€‚è¿™ç§æ“ä½œçš„æ•ˆæœæ˜¯å¾—åˆ°ä¸€ä¸ªæ–°çš„çŸ©é˜µ*B*ï¼Œå…¶ä¸€åŠçš„è¡Œä¸ºç©ºã€‚è¿™æ˜¯å¥½æ¶ˆæ¯ï¼Œå› ä¸ºå®ƒä¸ºæµçŸ©é˜µ*A*ä¸­çš„ä¸‹ä¸€è¡Œæä¾›äº†ç©ºé—´ã€‚
- en: '**Error guarantee**: Similar to the frequent items case, this method has the
    following error guarantees where *l* is the sketch size and *k* is the rank:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**è¯¯å·®ä¿è¯**ï¼šç±»ä¼¼äºé¢‘ç¹é¡¹çš„æƒ…å†µï¼Œè¯¥æ–¹æ³•å…·æœ‰ä»¥ä¸‹è¯¯å·®ä¿è¯ï¼Œå…¶ä¸­*l*æ˜¯è‰å›¾å¤§å°ï¼Œ*k*æ˜¯ç§©ï¼š'
- en: '![](../Images/26af11f02db213823a89fd08a730206a.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26af11f02db213823a89fd08a730206a.png)'
- en: FrequentDirections covariance error bound â€” Image by the author
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: FrequentDirections åæ–¹å·®è¯¯å·®ç•Œé™ â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: '![](../Images/3e84e4752ba2fe64ba053b39926b8c0e.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e84e4752ba2fe64ba053b39926b8c0e.png)'
- en: FrequentDirections projection error bound â€” Image by the author
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: FrequentDirections æŠ•å½±è¯¯å·®ç•Œé™ â€” ä½œè€…æä¾›çš„å›¾åƒ
- en: Compare the second error bound to that of random projection and row sampling.
    Note how this is a tighter and better error bound.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”è¾ƒç¬¬äºŒä¸ªè¯¯å·®ç•Œé™ä¸éšæœºæŠ•å½±å’Œè¡Œé‡‡æ ·çš„è¯¯å·®ç•Œé™ã€‚æ³¨æ„è¿™æ˜¯ä¸€ä¸ªæ›´ç´§å‡‘å’Œæ›´å¥½çš„è¯¯å·®ç•Œé™ã€‚
- en: '**Experiments**: It is shown in experiments [2,4] that *Frequent Directions*
    algorithm outperforms every other streaming algorithm discussed above. Below is
    the experiments with respect to covariance error bound:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**å®éªŒ**ï¼šå®éªŒ[2,4]è¡¨æ˜ï¼Œ*Frequent Directions* ç®—æ³•ä¼˜äºä¸Šè¿°è®¨è®ºçš„æ‰€æœ‰å…¶ä»–æµå¼ç®—æ³•ã€‚ä»¥ä¸‹æ˜¯ä¸åæ–¹å·®è¯¯å·®ç•Œé™ç›¸å…³çš„å®éªŒï¼š'
- en: '![](../Images/053c83c270c62d2990bfd0ecab32cd13.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/053c83c270c62d2990bfd0ecab32cd13.png)'
- en: 'Figure 30: Experiments in covariance error â€” Image from [2]'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ 30: åæ–¹å·®è¯¯å·®ä¸­çš„å®éªŒ â€” æ¥è‡ª [2] çš„å›¾åƒ'
- en: 'and this is the experiment with respect to the projection error bound:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å…³äºæŠ•å½±è¯¯å·®ç•Œé™çš„å®éªŒï¼š
- en: '![](../Images/275ca9112d6e71ab891f32ca8da25aa4.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/275ca9112d6e71ab891f32ca8da25aa4.png)'
- en: 'Figure 31: Experiments in projection error â€” Image from [2]'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ 31: æŠ•å½±è¯¯å·®ä¸­çš„å®éªŒ â€” æ¥è‡ª [2] çš„å›¾åƒ'
- en: This concludes the article. As we see, Frequent Directions not only outperform
    all other methods in approximation errors, but it uses the least amount of space.
    In other words, it is space optimal with respect to the error bound it achieves.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡åˆ°æ­¤ç»“æŸã€‚æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼Œ*Frequent Directions* ä¸ä»…åœ¨è¿‘ä¼¼è¯¯å·®ä¸­ä¼˜äºæ‰€æœ‰å…¶ä»–æ–¹æ³•ï¼Œè€Œä¸”ä½¿ç”¨çš„ç©ºé—´æœ€å°‘ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒåœ¨å®ç°çš„è¯¯å·®ç•Œé™æ–¹é¢æ˜¯ç©ºé—´æœ€ä¼˜çš„ã€‚
- en: Summary
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: 'Low-rank matrix approximation in data streams is the problem of computing a
    low-rank approximation to a matrix whose its rows arrive in a streaming fashion.
    This entails not having access to all rows of the matrix at once, and not knowing
    the size of the matrix as. There are three main category of methods for computing
    such approximation: row sampling â€” random projection â€” iterative sketching. While
    the first group is the most intuitive set of methods as they sample the actual
    data points, the second group is the most efficient in run-time. The state-of-the-art
    (SOTA) is in the third group and itâ€™s called Frequent Directions. This method
    is based on an old method from frequent item estimation, and it is space optimal
    with respect to the error bound it achieves.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®æµä¸­çš„ä½ç§©çŸ©é˜µè¿‘ä¼¼æ˜¯è®¡ç®—ä½ç§©çŸ©é˜µè¿‘ä¼¼çš„é—®é¢˜ï¼Œå…¶ä¸­çŸ©é˜µçš„è¡Œä»¥æµå¼æ–¹å¼åˆ°è¾¾ã€‚è¿™æ„å‘³ç€æ— æ³•ä¸€æ¬¡æ€§è®¿é—®çŸ©é˜µçš„æ‰€æœ‰è¡Œï¼Œä¹Ÿä¸çŸ¥é“çŸ©é˜µçš„å¤§å°ã€‚æœ‰ä¸‰ç§ä¸»è¦çš„è¿‘ä¼¼æ–¹æ³•ç±»åˆ«ï¼šè¡Œé‡‡æ ·â€”â€”éšæœºæŠ•å½±â€”â€”è¿­ä»£è‰å›¾ã€‚è™½ç„¶ç¬¬ä¸€ç»„æ–¹æ³•æ˜¯æœ€ç›´è§‚çš„ï¼Œå› ä¸ºå®ƒä»¬é‡‡æ ·å®é™…æ•°æ®ç‚¹ï¼Œç¬¬äºŒç»„æ–¹æ³•åœ¨è¿è¡Œæ—¶æ•ˆç‡æœ€é«˜ã€‚æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ˆSOTAï¼‰å±äºç¬¬ä¸‰ç»„ï¼Œç§°ä¸ºé¢‘ç¹æ–¹å‘ã€‚è¯¥æ–¹æ³•åŸºäºé¢‘ç¹é¡¹ä¼°è®¡çš„æ—§æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨è¯¯å·®ç•Œé™æ–¹é¢å…·æœ‰ç©ºé—´æœ€ä¼˜æ€§ã€‚
- en: 'If you have any questions or suggestions, feel free to reach out to me:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ï¼š
- en: 'Email: mina.ghashami@gmail.com'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ç”µå­é‚®ä»¶ï¼šmina.ghashami@gmail.com
- en: 'LinkedIn: [https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: LinkedInï¼š[https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)
- en: References
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[Fast monte carlo algorithms for matrices i: approximating matrix multiplication,
    p. drineas, et al, 2006](https://www.stat.berkeley.edu/~mmahoney/pubs/matrix1_SICOMP.pdf)'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[å¿«é€Ÿè’™ç‰¹å¡ç½—çŸ©é˜µç®—æ³• Iï¼šçŸ©é˜µä¹˜æ³•çš„è¿‘ä¼¼ï¼ŒP. Drineas ç­‰ï¼Œ2006](https://www.stat.berkeley.edu/~mmahoney/pubs/matrix1_SICOMP.pdf)'
- en: '[Frequent Directions: Simple and Deterministic Matrix Sketching](https://arxiv.org/abs/1501.01711)'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[é¢‘ç¹æ–¹å‘ï¼šç®€å•ä¸”ç¡®å®šæ€§çš„çŸ©é˜µè‰å›¾](https://arxiv.org/abs/1501.01711)'
- en: '[https://github.com/edoliberty/frequent-directions](https://github.com/edoliberty/frequent-directions)'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/edoliberty/frequent-directions](https://github.com/edoliberty/frequent-directions)'
- en: '[Improved Practical Matrix Sketching with Guarantees](https://arxiv.org/abs/1501.06561)'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[å…·æœ‰ä¿è¯çš„æ”¹è¿›å®ç”¨çŸ©é˜µè‰å›¾](https://arxiv.org/abs/1501.06561)'
- en: '[Low Rank Approximation and Regression in Input Sparsity Time](https://arxiv.org/abs/1207.6365)'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[è¾“å…¥ç¨€ç–æ—¶é—´ä¸‹çš„ä½ç§©è¿‘ä¼¼å’Œå›å½’](https://arxiv.org/abs/1207.6365)'
- en: '[Improved Approximation Algorithms for Large Matrices via Random Projections](https://ieeexplore.ieee.org/document/4031351)'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[é€šè¿‡éšæœºæŠ•å½±æ”¹è¿›çš„å¤§çŸ©é˜µè¿‘ä¼¼ç®—æ³•](https://ieeexplore.ieee.org/document/4031351)'
