- en: Build Deployable Machine Learning Pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建可部署的机器学习管道
- en: 原文：[https://towardsdatascience.com/build-deployable-machine-learning-pipelines-a6d7035816a6](https://towardsdatascience.com/build-deployable-machine-learning-pipelines-a6d7035816a6)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/build-deployable-machine-learning-pipelines-a6d7035816a6](https://towardsdatascience.com/build-deployable-machine-learning-pipelines-a6d7035816a6)
- en: Leverage Kedro to build production-ready machine learning pipelines
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用Kedro构建生产就绪的机器学习管道
- en: '[](https://johnadeojo.medium.com/?source=post_page-----a6d7035816a6--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----a6d7035816a6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a6d7035816a6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a6d7035816a6--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----a6d7035816a6--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johnadeojo.medium.com/?source=post_page-----a6d7035816a6--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----a6d7035816a6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a6d7035816a6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a6d7035816a6--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----a6d7035816a6--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a6d7035816a6--------------------------------)
    ·8 min read·Jun 30, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----a6d7035816a6--------------------------------)
    ·8分钟阅读·2023年6月30日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ec434ef42ac9cdfcc488fd5ed7688ab9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec434ef42ac9cdfcc488fd5ed7688ab9.png)'
- en: 'Image by Author: Generated with Midjourney'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：使用Midjourney生成
- en: Background — Notebooks are not “Deployable”
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景 — 笔记本不能“部署”
- en: Many data scientists’ initial encounters with coding take place through notebook-style
    user interfaces. Notebooks are indispensable for exploration — a critical aspect
    of our workflow. However, they’re not designed to be production-ready. This is
    a key issue I’ve observed among numerous clients, some of whom inquire about ways
    to productionise their notebooks. Rather than productionising your notebooks,
    the optimal route to production readiness is to craft modular, maintainable, and
    reproducible code.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据科学家最初接触编码的方式是通过笔记本风格的用户界面。笔记本对于探索至关重要——这是我们工作流程的一个关键方面。然而，它们并不是为生产环境准备的。这是我在众多客户中观察到的一个关键问题，其中一些人询问如何将笔记本投入生产。与其将笔记本投入生产，最优的生产准备路径是编写模块化、可维护和可重复的代码。
- en: 'In this article, I present an example of a modular ML pipeline for training
    a model to classify fraudulent credit card transactions. By the conclusion of
    this article, I hope that you will:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我展示了一个用于训练模型以分类欺诈信用卡交易的模块化机器学习管道示例。希望在本文结束时，你能：
- en: Gain an appreciation and understanding of modular ML pipelines.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 了解和掌握模块化机器学习管道。
- en: Feel inspired to build one for yourself.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 感到受启发，自己动手构建一个吧。
- en: If you want to reap the benefits of deploying your machine learning models for
    maximum effect, writing modular code is an important step to take.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想最大化地发挥机器学习模型的效益，编写模块化代码是一个重要的步骤。
- en: First a quick definition of [modular](https://en.wikipedia.org/wiki/Modular_programming)
    code. Modular code is software design paradigm that emphasizes separating a program
    out into independent, interchangeable modules. We should aim to approach this
    state with our machine learning pipelines.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先对[模块化](https://en.wikipedia.org/wiki/Modular_programming)代码进行一个简要定义。模块化代码是一种软件设计范式，强调将程序分解为独立的、可互换的模块。我们应该力求在我们的机器学习管道中达到这种状态。
- en: Quick Detour — The project, the Data, and Approach
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速绕道 — 项目、数据和方法
- en: The machine learning project is sourced from [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).
    The dataset consists of 284,807 anonymised credit card transactions for which
    492 are fraudulent. The task is to build a classifier to detect the fraudulent
    transactions.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该机器学习项目的数据来源于[Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)。数据集包含284,807个匿名信用卡交易记录，其中492个为欺诈交易。任务是构建一个分类器来检测欺诈交易。
- en: The Data for this project is licensed for any purpose including commercial use
    under the [Open Data Commons](https://opendatacommons.org/licenses/dbcl/1-0/).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的数据在[开放数据公共许可证](https://opendatacommons.org/licenses/dbcl/1-0/)下许可用于任何目的，包括商业用途。
- en: I have used a deep learning approach leveraging the [Ludwig](https://ludwig.ai/latest/)
    , an open-source framework for declarative deep learning. I won’t go into the
    details of Ludwig here, however I have previously written an article on the [framework](https://medium.com/towards-data-science/ludwig-a-friendlier-deep-learning-framework-946ee3d3b24).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了利用[Ludwig](https://ludwig.ai/latest/)的深度学习方法，这是一个开源的声明式深度学习框架。我在这里不会详细介绍Ludwig，不过我之前写过一篇关于[框架](https://medium.com/towards-data-science/ludwig-a-friendlier-deep-learning-framework-946ee3d3b24)的文章。
- en: The Ludwig deep neural network is configured with a **.yaml** file. For those
    that are curious you can find this in the [model registry GitHub](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/model_1a.yaml).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Ludwig深度神经网络通过**.yaml**文件进行配置。对那些感兴趣的人，你可以在[模型注册GitHub](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/model_1a.yaml)找到它。
- en: Building Modular Pipelines with Kedro
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kedro构建模块化管道
- en: Building modular machine learning pipelines has been made easier with open-source
    tools, my favourite of these is [Kedro](https://kedro.org/). Not only because
    I have seen this used successfully in industry, but also because it helped me
    develop my software engineering skills.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用开源工具使得构建模块化机器学习管道变得更加容易，我最喜欢的工具之一是[Kedro](https://kedro.org/)。不仅因为我见证了它在行业中的成功应用，还因为它帮助我提升了我的软件工程技能。
- en: Kedro is an open-source framework (licensed under Apache 2.0) for creating reproducible,
    maintainable and modular data science code. I came across it while I was developing
    the AI strategy for a bank, considering which tools my team could utilise to build
    production-ready code.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Kedro是一个开源框架（根据Apache 2.0许可证）用于创建可重复、可维护和模块化的数据科学代码。我是在为一家银行开发AI策略时发现它的，考虑到我的团队可以利用哪些工具来构建生产就绪的代码。
- en: '*Disclaimer: I have no affiliation with Kedro or McKinsey’s QuantumBlack, the
    creators of this open-source tool.*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：我与Kedro或McKinsey的QuantumBlack（该开源工具的创建者）没有任何关联。*'
- en: The Model Training Pipeline
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练管道
- en: '![](../Images/521cb43a198ee7b9415263cf30f40f77.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/521cb43a198ee7b9415263cf30f40f77.png)'
- en: 'Image by Author: End-to-end model training pipeline generated with Kedro viz'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：使用Kedro可视化生成的端到端模型训练管道
- en: Kedro conveniently allows you to visualise your pipelines, a fantastic feature
    that can help bring clarity to your code. The pipeline is standard for machine
    learning so I will only briefly touch on each aspect.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Kedro方便地允许你可视化你的管道，这是一个很棒的功能，可以帮助你清晰地理解你的代码。这个管道在机器学习中是标准的，因此我只会简单介绍每个方面。
- en: '**Import Data**: Import the credit card transaction data from an external source.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**导入数据**：从外部来源导入信用卡交易数据。'
- en: '**Split Data**: Use random split to split the data into training and holdout
    sets.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**拆分数据**：使用随机拆分将数据分成训练集和保留集。'
- en: '**Run Experiment**: Uses the Ludwig framework to train a deep neural network
    on the train data set. The Ludwig experiment API conveniently saves model artefacts
    for every experiment run.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**运行实验**：使用Ludwig框架在训练数据集上训练深度神经网络。Ludwig实验API方便地为每次实验运行保存模型工件。'
- en: '**Run Predictions**: Uses the model trained in the previous step to run predictions
    on the holdout dataset.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**运行预测**：使用前一步训练的模型对保留数据集进行预测。'
- en: '**Model Diagnostics**: Produces two diagnostic charts. First, the tracking
    the cross-entropy loss over each epoch. Second, the [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)
    measuring the model’s performance on the holdout dataset.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型诊断**：生成两个诊断图表。首先是跟踪每个周期的交叉熵损失。其次是测量模型在保留数据集上的性能的[ROC曲线](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)。'
- en: '![](../Images/5b057563d48b3bc1b69a199f33954e1d.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b057563d48b3bc1b69a199f33954e1d.png)'
- en: 'Image by Author: Loss Curve from model training process'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：模型训练过程中的损失曲线
- en: '![](../Images/b9023e2e090e82f08b52fe22fbc91d82.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9023e2e090e82f08b52fe22fbc91d82.png)'
- en: 'Image by Author: ROC Curve from model evaluation on the holdout dataset'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片：在保留数据集上模型评估的ROC曲线
- en: Core Components of the Pipeline
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道的核心组件
- en: Now that we have established a high-level view, let’s get into some of the core
    components of this pipeline.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了一个高层次的视图，让我们深入探讨这个管道的一些核心组件。
- en: Project Structure
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目结构
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Kedro provides a templated directory structure that is established when you
    initiate a project. From this base, you can programmatically add more pipelines
    to your directory structure. This standardised structure ensures that every machine
    learning project is identical and easy to document, thereby facilitating ease
    of maintenance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Kedro 提供了一个模板化的目录结构，这个结构在你启动项目时就已经建立。从这个基础上，你可以以编程方式将更多的管道添加到你的目录结构中。这种标准化的结构确保了每个机器学习项目的一致性和易于文档化，从而便于维护。
- en: Data Management
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据管理
- en: Data plays a crucial role in machine learning. The ability to track your data
    becomes even more essential when employing machine learning models in a commercial
    setting. You often find yourself facing audits, or the necessity to productionise
    or reproduce your pipeline on someone else’s machine.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在机器学习中扮演着至关重要的角色。当在商业环境中使用机器学习模型时，跟踪数据的能力变得尤为重要。你经常会面临审计，或者需要在他人的机器上生产化或重现你的管道。
- en: Kedro offers two methods for enforcing best practices in data management. The
    first is a directory structure, designed for machine learning workloads, providing
    distinct locations for the intermediate tables produced during data transformation
    and the model artefacts. The second method is the [data catalogue](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/conf/base/catalog.yml).
    As part of the Kedro workflow, you are required to register datasets within a
    .yaml configuration file, thereby enabling you to leverage these datasets in your
    pipelines. This approach may initially seem unusual, but it allows you and others
    working on your pipeline to track data with ease.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kedro 提供了两种方法来强制执行数据管理的最佳实践。第一种是目录结构，专为机器学习工作负载设计，为数据转换过程中生成的中间表和模型工件提供了明确的位置。第二种方法是[data
    catalogue](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/conf/base/catalog.yml)。作为
    Kedro 工作流的一部分，你需要在 .yaml 配置文件中注册数据集，从而在管道中利用这些数据集。这种方法初看可能不寻常，但它使你和其他参与管道工作的人员能够轻松跟踪数据。
- en: Orchestration — Nodes and Pipelines
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度 — 节点和管道
- en: This is really where the magic happens. Kedro provides you with pipeline functionality
    straight out of the box.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是魔法发生的地方。Kedro 提供了开箱即用的管道功能。
- en: The initial building block of your pipeline is the [nodes](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/nodes.py).
    Each executable piece of code can be encapsulated within a Node, which is simply
    a Python function that accepts an input and yields an output. You can then structure
    a [pipeline](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/pipeline.py)
    as a series of nodes. Pipelines are easily constructed by invoking the node and
    specifying the inputs and outputs. Kedro determines the execution order.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的初始构建块是[nodes](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/nodes.py)。每个可执行的代码片段可以封装在一个节点中，节点只是一个接受输入并产生输出的
    Python 函数。然后，你可以将一个[管道](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/pipeline.py)结构化为一系列节点。通过调用节点并指定输入和输出，可以轻松构建管道。Kedro
    会确定执行顺序。
- en: Once pipelines are constructed, they are registered in the provided **pipeline_registry.py**
    file. The beauty of this approach is that you can create multiple pipelines. This
    is particularly beneficial in machine learning, where you might have a data processing
    pipeline, a model training pipeline, an inference pipeline, and so forth.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦管道构建完成，它们会被注册在提供的**pipeline_registry.py**文件中。这种方法的美妙之处在于，你可以创建多个管道。这在机器学习中尤其有用，你可能会有一个数据处理管道、一个模型训练管道、一个推理管道等。
- en: Once set up, it’s straightforward enough to modify aspects of your pipeline.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置完成，修改管道的各个方面就会变得相当简单。
- en: Code snippet showing example of nodes.py script
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 显示 nodes.py 脚本示例的代码片段
- en: Code snippet showing example of Pipeline script
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 显示 Pipeline 脚本示例的代码片段
- en: Configuration
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置
- en: Kedro’s best practices stipulate that all configurations should be handled through
    the provided [**parameters.yml**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/conf/base/parameters.yml)
    file. From a machine learning perspective, hyperparameters fall into this category.
    This approach streamlines experimentation, as you can simply substitute one **parameters.yml**
    file with a set of hyperparameters for another, which is also much easier to track.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Kedro 的最佳实践规定所有配置应通过提供的 [**parameters.yml**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/conf/base/parameters.yml)
    文件来处理。从机器学习的角度来看，超参数也属于这一类别。这种方法简化了实验过程，因为你可以简单地用另一组超参数替换一个 **parameters.yml**
    文件，这也更容易追踪。
- en: I have also included the locations of my Ludwig deep neural network [**model.yaml**](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/model_1a.yaml)
    and the data source within the **parameters.yml** configuration. Should the model
    or the location of the data change — for instance, when moving between developers’
    machines — it would be incredibly straightforward to adjust these settings.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我还在 **parameters.yml** 配置中包含了我的 Ludwig 深度神经网络 [**model.yaml**](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/model_1a.yaml)
    和数据源的位置。如果模型或数据位置发生变化——例如，在开发者之间转移时——调整这些设置会非常简单。
- en: Code snippet showing the contents of the parameters.yml file
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 显示`parameters.yml`文件内容的代码片段
- en: Reproducibility
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可复现性
- en: Kedro includes a [**requirements.txt**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/requirements.txt)
    file as part of the templated structure. This makes it really straightforward
    to monitor your environment and exact library versions. However, should you prefer,
    you can employ other environment management methods, such as an **environment.yml**
    file.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Kedro 包含一个 [**requirements.txt**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/requirements.txt)
    文件作为模板结构的一部分。这使得监控你的环境和确切的库版本变得非常简单。然而，如果你愿意，你可以使用其他环境管理方法，如 **environment.yml**
    文件。
- en: Establishing a Workflow
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立工作流
- en: 'If you’re developing machine learning pipelines and considering using Kedro,
    it can initially present a steep learning curve, but adopting a standard workflow
    will simplify the process. Here’s my suggested workflow:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在开发机器学习管道并考虑使用 Kedro，起初可能会有陡峭的学习曲线，但采用标准工作流会简化这一过程。以下是我建议的工作流：
- en: '**Establish your working environment**: I prefer using Anaconda for this task.
    I typically use an [**environment.yml**](https://github.com/john-adeojo/kedro-project/blob/main/environment.yml)
    file, containing all the dependencies needed for my environment, and employ the
    Anaconda Powershell command line to [create](https://gist.github.com/john-adeojo/fa22082328e65d0260fefd9b149e4b69)
    my environment from this.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**建立你的工作环境**：我更喜欢使用 Anaconda 来完成这项任务。我通常使用一个 [**environment.yml**](https://github.com/john-adeojo/kedro-project/blob/main/environment.yml)
    文件，其中包含我环境所需的所有依赖项，并使用 Anaconda Powershell 命令行来 [创建](https://gist.github.com/john-adeojo/fa22082328e65d0260fefd9b149e4b69)
    我的环境。'
- en: '**Create a Kedro project**: Once you have Kedro installed — which should hopefully
    be declared in your **environment.yml** — you can [create](https://docs.kedro.org/en/stable/get_started/new_project.html)
    a Kedro project through the [Anaconda](https://www.anaconda.com/) command line
    interface.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建 Kedro 项目**：一旦你安装了 Kedro——希望它已在你的 **environment.yml** 中声明——你可以通过 [Anaconda](https://www.anaconda.com/)
    命令行界面 [创建](https://docs.kedro.org/en/stable/get_started/new_project.html) 一个 Kedro
    项目。'
- en: '**Explore in Jupyter Notebooks**: I construct an initial pipeline in Jupyter
    notebooks, a process familiar to most data scientists. The only difference is
    that, once your pipeline is built, you should tidy it up so that each cell could
    serve as one Node in your Kedro pipeline.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在 Jupyter Notebooks 中探索**：我在 Jupyter notebooks 中构建初始管道，这个过程对大多数数据科学家来说都很熟悉。唯一的不同之处在于，一旦你的管道构建完成，你应该整理它，以便每个单元格可以作为你
    Kedro 管道中的一个节点。'
- en: '**Register your data**: Record the input and outputs for each data processing
    or data ingestion step in the data [catalogue](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/conf/base/catalog.yml).'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注册你的数据**：在数据 [catalogue](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/conf/base/catalog.yml)
    中记录每个数据处理或数据摄取步骤的输入和输出。'
- en: '**Add your pipeline**: After conducting your exploration in notebooks, you’ll
    want to [create a pipeline](https://docs.kedro.org/en/stable/tutorial/create_a_pipeline.html#:~:text=Note,the%20starter%20project.).
    This is achieved through the command line interface. Running this command will
    add an additional folder to ‘pipelines’, bearing the name of the pipeline you’ve
    just created. It’s within this folder that you’ll construct your nodes and pipelines.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**添加你的管道**：在笔记本中进行探索后，你会想要 [创建一个管道](https://docs.kedro.org/en/stable/tutorial/create_a_pipeline.html#:~:text=Note,the%20starter%20project.)。这是通过命令行界面完成的。运行此命令将会在
    ‘pipelines’ 中添加一个额外的文件夹，文件夹名称为你刚刚创建的管道名称。在这个文件夹中，你将构建你的节点和管道。'
- en: '**Define your pipeline**: This is the stage where you start transferring the
    code from your Jupyter notebooks into the [**node.py**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/nodes.py)
    file in your pipeline folder, ensuring that nodes you intend to be part of a pipeline
    have inputs and outputs. Once the nodes are set up, proceed to define your pipeline
    in the [**pipeline.py**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/pipeline.py)
    file.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义你的管道**：这是将代码从你的 Jupyter 笔记本迁移到你管道文件夹中的 [**node.py**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/nodes.py)
    文件的阶段，确保你希望成为管道一部分的节点都有输入和输出。一旦节点设置完毕，接下来在 [**pipeline.py**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipelines/train_model/pipeline.py)
    文件中定义你的管道。'
- en: '**Register your pipelines**: The [**pipeline_registry.py**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipeline_registry.py)
    file offers a template for you to register your newly created pipeline.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注册你的管道**： [**pipeline_registry.py**](https://github.com/john-adeojo/kedro-project/blob/main/fraud-detection/src/fraud_detection_model/pipeline_registry.py)
    文件提供了一个模板，用于注册你新创建的管道。'
- en: '**Run your project**: Once established, you can [run](https://docs.kedro.org/en/stable/nodes_and_pipelines/run_a_pipeline.html)
    any pipeline through the CLI and also [visualise](https://docs.kedro.org/en/stable/visualisation/index.html)
    your project.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**运行你的项目**：一旦建立完成，你可以通过 CLI [运行](https://docs.kedro.org/en/stable/nodes_and_pipelines/run_a_pipeline.html)
    任何管道，还可以 [可视化](https://docs.kedro.org/en/stable/visualisation/index.html) 你的项目。'
- en: Production-ready pipelines fit into a wider ecosystem of machine learning operations.
    Read my article on MLOps for a deeper dive.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 生产就绪的管道适应于更广泛的机器学习操作生态系统。阅读我的关于 MLOps 的文章，进行更深入的了解。
- en: '[](/building-machine-learning-operations-for-businesses-6d0bfbbf2139?source=post_page-----a6d7035816a6--------------------------------)
    [## Building Machine Learning Operations for Businesses'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/building-machine-learning-operations-for-businesses-6d0bfbbf2139?source=post_page-----a6d7035816a6--------------------------------)
    [## 为企业构建机器学习操作'
- en: A Blueprint for Effective MLOps to Support Your AI Strategy
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持你的 AI 战略的有效 MLOps 蓝图
- en: towardsdatascience.com](/building-machine-learning-operations-for-businesses-6d0bfbbf2139?source=post_page-----a6d7035816a6--------------------------------)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/building-machine-learning-operations-for-businesses-6d0bfbbf2139?source=post_page-----a6d7035816a6--------------------------------)
- en: Conclusion
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Kedro is an excellent framework for delivering production-ready machine learning
    pipelines. Beyond the functionality discussed in this article, there are numerous
    integrations with other open-source libraries, as well as packages for documentation
    and testing. Kedro doesn’t solve every issue related to model deployment — for
    instance, model versioning is likely better handled by another tool such as DVC.
    However, it will assist data scientists in a commercial setting to produce more
    maintainable, modular, and reproducible code that is ready for production. There
    is a relatively steep learning curve for complete novices, but the documentation
    is clear and includes guided tutorials. As with any of these packages, the best
    way to learn is to dive in and experiment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Kedro 是一个出色的框架，用于交付生产就绪的机器学习管道。除了本文讨论的功能外，还有许多与其他开源库的集成，以及用于文档和测试的包。Kedro 并不能解决与模型部署相关的所有问题——例如，模型版本控制可能更适合使用其他工具如
    DVC 处理。然而，它将帮助商业环境中的数据科学家生成更可维护、模块化和可重复的生产就绪代码。对于完全的新手来说，学习曲线相对较陡，但文档清晰，并包括引导教程。与这些包中的任何一个一样，最好的学习方法是直接动手试验。
- en: Link to the full [GitHub repo](https://github.com/john-adeojo/kedro-project/tree/main)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 [GitHub 仓库](https://github.com/john-adeojo/kedro-project/tree/main) 链接
- en: '*Follow me on* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/) *上关注我*'
- en: '*Subscribe to medium to get more insights from me:*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*订阅medium以获得更多我的见解：*'
- en: '[](https://johnadeojo.medium.com/membership?source=post_page-----a6d7035816a6--------------------------------)
    [## Join Medium with my referral link — John Adeojo'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 通过我的推荐链接加入Medium — 约翰·阿德约](https://johnadeojo.medium.com/membership?source=post_page-----a6d7035816a6--------------------------------)'
- en: I share data science projects, experiences, and expertise to assist you on your
    journey You can sign up to medium via…
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我分享数据科学项目、经验和专业知识，以帮助你在旅程中前行。你可以通过以下方式注册medium…
- en: johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----a6d7035816a6--------------------------------)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----a6d7035816a6--------------------------------)'
- en: '*Should you be interested in integrating AI or data science into your business
    operations, we invite you to schedule a complimentary initial consultation with
    us:*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你有兴趣将AI或数据科学整合到你的业务运营中，我们邀请你安排一次免费的初步咨询：*'
- en: '[](https://www.data-centric-solutions.com/book-online?source=post_page-----a6d7035816a6--------------------------------)
    [## Book Online | Data-Centric Solutions'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 在线预约 | 数据驱动解决方案](https://www.data-centric-solutions.com/book-online?source=post_page-----a6d7035816a6--------------------------------)'
- en: Discover our expertise in helping businesses achieve ambitious goals with a
    free consultation. Our data scientists and…
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过免费咨询，发现我们在帮助企业实现雄心勃勃的目标方面的专业知识。我们的数据科学家和…
- en: www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----a6d7035816a6--------------------------------)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----a6d7035816a6--------------------------------)'
