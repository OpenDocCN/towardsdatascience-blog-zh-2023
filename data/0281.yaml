- en: Building an Exercise Rep Counter Using Ideas from Signal Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¿¡å·å¤„ç†æ€æƒ³æ„å»ºé”»ç‚¼æ¬¡æ•°è®¡æ•°å™¨
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/building-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81?source=collection_archive---------16-----------------------#2023-01-17](https://towardsdatascience.com/building-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81?source=collection_archive---------16-----------------------#2023-01-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/building-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81?source=collection_archive---------16-----------------------#2023-01-17](https://towardsdatascience.com/building-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81?source=collection_archive---------16-----------------------#2023-01-17)
- en: Designing a class-specific rep counter using a zero-crossing approach
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é›¶äº¤å‰æ–¹æ³•è®¾è®¡ç‰¹å®šç±»åˆ«çš„è®¡æ•°å™¨
- en: '[](https://medium.com/@aakashagrawal?source=post_page-----fcdf14e76f81--------------------------------)[![Aakash
    Agrawal](../Images/29c88586046f4b51d40cc0336f696cef.png)](https://medium.com/@aakashagrawal?source=post_page-----fcdf14e76f81--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fcdf14e76f81--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fcdf14e76f81--------------------------------)
    [Aakash Agrawal](https://medium.com/@aakashagrawal?source=post_page-----fcdf14e76f81--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@aakashagrawal?source=post_page-----fcdf14e76f81--------------------------------)[![Aakash
    Agrawal](../Images/29c88586046f4b51d40cc0336f696cef.png)](https://medium.com/@aakashagrawal?source=post_page-----fcdf14e76f81--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fcdf14e76f81--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fcdf14e76f81--------------------------------)
    [Aakash Agrawal](https://medium.com/@aakashagrawal?source=post_page-----fcdf14e76f81--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93ce827b6548&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81&user=Aakash+Agrawal&userId=93ce827b6548&source=post_page-93ce827b6548----fcdf14e76f81---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fcdf14e76f81--------------------------------)
    Â·7 min readÂ·Jan 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffcdf14e76f81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81&user=Aakash+Agrawal&userId=93ce827b6548&source=-----fcdf14e76f81---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93ce827b6548&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81&user=Aakash+Agrawal&userId=93ce827b6548&source=post_page-93ce827b6548----fcdf14e76f81---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fcdf14e76f81--------------------------------)
    Â·7 åˆ†é’Ÿé˜…è¯»Â·2023å¹´1æœˆ17æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffcdf14e76f81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81&user=Aakash+Agrawal&userId=93ce827b6548&source=-----fcdf14e76f81---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffcdf14e76f81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81&source=-----fcdf14e76f81---------------------bookmark_footer-----------)![](../Images/17dff657731d9290868db138567c9e84.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffcdf14e76f81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-an-exercise-rep-counter-using-ideas-from-signal-processing-fcdf14e76f81&source=-----fcdf14e76f81---------------------bookmark_footer-----------)![](../Images/17dff657731d9290868db138567c9e84.png)'
- en: photo by [Karsten Winegeart](https://unsplash.com/@karsten116) on Unsplash.com
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç…§ç‰‡ç”± [Karsten Winegeart](https://unsplash.com/@karsten116) åœ¨ Unsplash.com æä¾›
- en: '*In this blog post, I discuss a very new and unique approach for building a
    real-time exercise rep counter, one that employs signal processing ideas on top
    of pose estimation. This approach can be easily adapted to build rep-counters
    for other classes.*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘è®¨è®ºäº†ä¸€ç§éå¸¸æ–°é¢–å’Œç‹¬ç‰¹çš„æ–¹æ³•æ¥æ„å»ºå®æ—¶é”»ç‚¼æ¬¡æ•°è®¡æ•°å™¨ï¼Œè¿™ç§æ–¹æ³•åœ¨å§¿æ€ä¼°è®¡çš„åŸºç¡€ä¸Šåº”ç”¨äº†ä¿¡å·å¤„ç†çš„æ€æƒ³ã€‚è¿™ç§æ–¹æ³•å¯ä»¥è½»æ¾åœ°é€‚åº”äºæ„å»ºå…¶ä»–ç±»åˆ«çš„è®¡æ•°å™¨ã€‚*'
- en: From engaging fitness-related activities by counting the number of times a particular
    movement was done to measuring biological events (such as heartbeat and pulse
    count), Rep counting has countless applications, and research in this field has
    garnered a lot of traction in the last few years. In this blog, I discuss one
    of the approaches to building a fast and accurate rep counter using some trivial
    concepts in the Signal Processing domain.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿›è¡Œå¥èº«æ´»åŠ¨æ—¶è®¡æ•°æŸç§è¿åŠ¨çš„æ¬¡æ•°ï¼Œåˆ°æµ‹é‡ç”Ÿç‰©äº‹ä»¶ï¼ˆå¦‚å¿ƒè·³å’Œè„‰æè®¡æ•°ï¼‰ï¼Œé‡å¤è®¡æ•°æœ‰ç€æ— æ•°çš„åº”ç”¨ï¼Œè¿‘å¹´æ¥åœ¨è¿™ä¸€é¢†åŸŸçš„ç ”ç©¶è·å¾—äº†å¤§é‡å…³æ³¨ã€‚åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘è®¨è®ºäº†ä½¿ç”¨ä¿¡å·å¤„ç†é¢†åŸŸçš„ä¸€äº›ç®€å•æ¦‚å¿µæ¥æ„å»ºä¸€ä¸ªå¿«é€Ÿè€Œå‡†ç¡®çš„é‡å¤è®¡æ•°å™¨çš„æ–¹æ³•ã€‚
- en: I will swiftly cover the basics first and then walk through the signal-based
    formula for rep-counting. Implementation of the approach can be found [here](https://github.com/aakash2016/blog-codes/tree/master/signal-rep-count).
    Letâ€™s start by discussing a few concepts from the world of signal processing which
    we could potentially leverage to build a rep-counter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å°†é¦–å…ˆè¿…é€Ÿè¦†ç›–åŸºç¡€çŸ¥è¯†ï¼Œç„¶åä»‹ç»åŸºäºä¿¡å·çš„é‡å¤è®¡æ•°å…¬å¼ã€‚è¯¥æ–¹æ³•çš„å®ç°å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/aakash2016/blog-codes/tree/master/signal-rep-count)æ‰¾åˆ°ã€‚è®©æˆ‘ä»¬ä»ä¿¡å·å¤„ç†é¢†åŸŸè®¨è®ºä¸€äº›å¯ä»¥ç”¨æ¥æ„å»ºé‡å¤è®¡æ•°å™¨çš„æ¦‚å¿µå¼€å§‹ã€‚
- en: '**Zero-Crossing**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**é›¶äº¤å‰**'
- en: A reference point where the mathematical function or a waveform crosses an intercept
    of the axis (intercept need not be 0). The term is usually used in electronics
    when referring to points in periodic voltages and currents where there is no signal.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°å­¦å‡½æ•°æˆ–æ³¢å½¢ç©¿è¶Šè½´çš„äº¤ç‚¹çš„å‚è€ƒç‚¹ï¼ˆäº¤ç‚¹ä¸ä¸€å®šæ˜¯0ï¼‰ã€‚è¯¥æœ¯è¯­é€šå¸¸ç”¨äºç”µå­å­¦ä¸­ï¼ŒæŒ‡çš„æ˜¯å‘¨æœŸæ€§ç”µå‹å’Œç”µæµä¸­çš„æ²¡æœ‰ä¿¡å·çš„ç‚¹ã€‚
- en: '![](../Images/e4eebb9f7966da4e789da9c2b167e090.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4eebb9f7966da4e789da9c2b167e090.png)'
- en: 'Fig: Zero Crossing. Image by Author.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ï¼šé›¶äº¤å‰ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: '**Peak Detection**'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å³°å€¼æ£€æµ‹**'
- en: Detecting peaks (or positions) in a signal or a waveform where there is a sudden
    deviation (you observe spikes) from normal behavior. A technique to detect such
    deviation is by computing the **z-score**, which captures the mean and standard
    deviation of the signal to compute deviation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¿¡å·æˆ–æ³¢å½¢ä¸­æ£€æµ‹å³°å€¼ï¼ˆæˆ–ä½ç½®ï¼‰ï¼Œå³è§‚å¯Ÿåˆ°çš„çªç„¶åç¦»ï¼ˆä½ ä¼šçœ‹åˆ°å°–å³°ï¼‰æ­£å¸¸è¡Œä¸ºã€‚æ£€æµ‹è¿™ç§åå·®çš„æŠ€æœ¯æ˜¯é€šè¿‡è®¡ç®—**z-score**ï¼Œå®ƒæ•æ‰ä¿¡å·çš„å‡å€¼å’Œæ ‡å‡†å·®æ¥è®¡ç®—åå·®ã€‚
- en: '![](../Images/8cf1a829ccb41956cd8ce4673b3ebbb1.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8cf1a829ccb41956cd8ce4673b3ebbb1.png)'
- en: 'Fig: z-score formula. Image by Author.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ï¼šz-scoreå…¬å¼ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: At any position in the signal, the z-score algorithm essentially computes a
    trailing average and a trailing standard deviation of the preceding window of
    data points.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨ä¿¡å·çš„ä»»ä½•ä½ç½®ï¼Œz-scoreç®—æ³•æœ¬è´¨ä¸Šè®¡ç®—å‰ä¸€ä¸ªæ•°æ®ç‚¹çª—å£çš„æ»åå¹³å‡å€¼å’Œæ»åæ ‡å‡†å·®ã€‚
- en: A peak in the signal can be identified by computing the range ***trailing average
    +/- (threshold * trailing standard deviation);*** if the current point has a value
    outside the range, then it's considered part of an anomaly.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é€šè¿‡è®¡ç®—èŒƒå›´ ***æ»åå¹³å‡å€¼ +/- (é˜ˆå€¼ * æ»åæ ‡å‡†å·®);*** æ¥è¯†åˆ«ä¿¡å·ä¸­çš„å³°å€¼ï¼›å¦‚æœå½“å‰ç‚¹çš„å€¼è¶…å‡ºäº†èŒƒå›´ï¼Œåˆ™è®¤ä¸ºå®ƒæ˜¯å¼‚å¸¸çš„ä¸€éƒ¨åˆ†ã€‚
- en: More details and mathematics of the algo can be found [here](https://stackoverflow.com/a/22640362/18635156).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç®—æ³•çš„æ›´å¤šç»†èŠ‚å’Œæ•°å­¦å†…å®¹å¯ä»¥åœ¨[è¿™é‡Œ](https://stackoverflow.com/a/22640362/18635156)æ‰¾åˆ°ã€‚
- en: Rep Counting <> Signal Processing
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é‡å¤è®¡æ•° <> ä¿¡å·å¤„ç†
- en: 'A natural question that might come to a reader''s mind is how zero-crossing
    and peak detection algorithms can be used for rep-counting. Letâ€™s see:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¯»è€…è‡ªç„¶ä¼šäº§ç”Ÿä¸€ä¸ªé—®é¢˜ï¼Œå³é›¶äº¤å‰å’Œå³°å€¼æ£€æµ‹ç®—æ³•å¦‚ä½•ç”¨äºé‡å¤è®¡æ•°ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹ï¼š
- en: Assumptions
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‡è®¾
- en: Consider a human/object to be composed of some set of keypoints (points of interest).
    For example, these keypoints can be human body joints like shoulders, hips, etc.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è®¤ä¸ºä¸€ä¸ªäºº/ç‰©ä½“ç”±ä¸€ç»„å…³é”®ç‚¹ï¼ˆå…³æ³¨ç‚¹ï¼‰ç»„æˆã€‚ä¾‹å¦‚ï¼Œè¿™äº›å…³é”®ç‚¹å¯ä»¥æ˜¯è‚©è†€ã€è‡€éƒ¨ç­‰äººä½“å…³èŠ‚ã€‚
- en: To simplify, I limit the problem to exercise rep-counting because of the ease
    of availability of keypoints in the human body (the idea can easily be extended
    to other objects where keypoints are readily available). We can use open-source
    pose-estimation models to compute the spatial location of body keypoints. I use
    Tensorflowâ€™s [**Movenet**](https://www.tensorflow.org/hub/tutorials/movenet) pose
    estimation model for the purpose of illustration in this blog. This model is quite
    fast and accurate.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘å°†é—®é¢˜é™åˆ¶ä¸ºè¿åŠ¨é‡å¤è®¡æ•°ï¼Œå› ä¸ºäººä½“å…³é”®ç‚¹çš„å¯è·å¾—æ€§è¾ƒé«˜ï¼ˆè¿™ä¸€æ€è·¯å¯ä»¥å¾ˆå®¹æ˜“åœ°æ‰©å±•åˆ°å…¶ä»–å…³é”®ç‚¹æ˜“äºè·å¾—çš„å¯¹è±¡ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¼€æºå§¿æ€ä¼°è®¡æ¨¡å‹æ¥è®¡ç®—èº«ä½“å…³é”®ç‚¹çš„ç©ºé—´ä½ç½®ã€‚æˆ‘åœ¨è¿™ç¯‡åšå®¢ä¸­ä½¿ç”¨äº†Tensorflowçš„[**Movenet**](https://www.tensorflow.org/hub/tutorials/movenet)å§¿æ€ä¼°è®¡æ¨¡å‹è¿›è¡Œè¯´æ˜ã€‚è¿™ä¸ªæ¨¡å‹ç›¸å½“å¿«é€Ÿå’Œå‡†ç¡®ã€‚
- en: We **assume** any repetitive movement, for example, an exercise, as a set of
    sinusoidal waveforms of keypoints or functions (metrics) over keypoints. These
    Metrics include angles and distances between a combination of different body keypoints.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬**å‡è®¾**ä»»ä½•é‡å¤çš„è¿åŠ¨ï¼Œä¾‹å¦‚é”»ç‚¼ï¼Œéƒ½å¯ä»¥çœ‹ä½œæ˜¯å…³é”®ç‚¹æˆ–å‡½æ•°ï¼ˆåº¦é‡ï¼‰åœ¨å…³é”®ç‚¹ä¸Šçš„ä¸€ç»„æ­£å¼¦æ³¢å½¢ã€‚è¿™äº›åº¦é‡åŒ…æ‹¬ä¸åŒèº«ä½“å…³é”®ç‚¹ç»„åˆä¹‹é—´çš„è§’åº¦å’Œè·ç¦»ã€‚
- en: Algorithm
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç®—æ³•
- en: The underlying idea is to detect the Zero-Crossing points of these signal metrics
    in a moving temporal window in real-time.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: åŸºæœ¬æ€æƒ³æ˜¯åœ¨å®æ—¶ç§»åŠ¨çš„æ—¶é—´çª—å£ä¸­æ£€æµ‹è¿™äº›ä¿¡å·åº¦é‡çš„é›¶äº¤å‰ç‚¹ã€‚
- en: 'Rep Counting using zero-crossing is a two-phase process:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é›¶äº¤å‰ç‚¹è¿›è¡Œé‡å¤è®¡æ•°æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„è¿‡ç¨‹ï¼š
- en: 'Phase 1: Reference Computation'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é˜¶æ®µ 1ï¼šå‚è€ƒè®¡ç®—
- en: This phase is a **one-time** activity for a given exercise. We first find a
    zero-crossing line, aka reference line using a reference video (for exercise rep-counter,
    it can be a trainer's video). Most of the steps will be common in the rep-counting
    phase.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªé˜¶æ®µæ˜¯ç»™å®šé”»ç‚¼çš„**ä¸€æ¬¡æ€§**æ´»åŠ¨ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨å‚è€ƒè§†é¢‘æ‰¾åˆ°ä¸€ä¸ªé›¶äº¤å‰çº¿ï¼Œä¹Ÿå°±æ˜¯å‚è€ƒçº¿ï¼ˆå¯¹äºé”»ç‚¼é‡å¤è®¡æ•°å™¨ï¼Œå®ƒå¯ä»¥æ˜¯æ•™ç»ƒçš„è§†é¢‘ï¼‰ã€‚å¤§å¤šæ•°æ­¥éª¤å°†åœ¨é‡å¤è®¡æ•°é˜¶æ®µä¸­ä½¿ç”¨ã€‚
- en: '**a)** We use the Movenet pose estimation model to observe human body keypoints
    in real-time. Consider the following reference:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**a)** æˆ‘ä»¬ä½¿ç”¨Movenetå§¿åŠ¿ä¼°è®¡æ¨¡å‹å®æ—¶è§‚å¯Ÿäººä½“å…³é”®ç‚¹ã€‚è¯·è€ƒè™‘ä»¥ä¸‹å‚è€ƒï¼š'
- en: '![](../Images/328b71d9a2c121d1e94f0ff32d5a3bd9.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/328b71d9a2c121d1e94f0ff32d5a3bd9.png)'
- en: 'Fig: Body keypoint estimation using the Movenet model. Trainer performing Jumping
    Jacks. GIF by Author.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ï¼šä½¿ç”¨Movenetæ¨¡å‹è¿›è¡Œèº«ä½“å…³é”®ç‚¹ä¼°è®¡ã€‚æ•™ç»ƒæ­£åœ¨åšè·³è·ƒæ°å…‹ã€‚GIFç”±ä½œè€…æä¾›ã€‚
- en: '**b)** We then compute the **Metrics** using a combination of different body
    keypoints. Metric can be distances or angles between keypoints. Some metric examples:
    left shoulder to left palm distance (euclidean/y-axis), the angle subtended at
    the left shoulder, etc.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**b)** ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸åŒèº«ä½“å…³é”®ç‚¹çš„ç»„åˆè®¡ç®—**åº¦é‡**ã€‚åº¦é‡å¯ä»¥æ˜¯å…³é”®ç‚¹ä¹‹é—´çš„è·ç¦»æˆ–è§’åº¦ã€‚ä¸€äº›åº¦é‡ç¤ºä¾‹ï¼šå·¦è‚©åˆ°å·¦æŒçš„è·ç¦»ï¼ˆæ¬§å‡ é‡Œå¾—/yè½´ï¼‰ã€å·¦è‚©å¤„çš„å¤¹è§’ç­‰ã€‚'
- en: The idea would be to use metrics that would cover a wide range of movements.
    I usually prefer doing exercises facing the front camera; hence, choosing euclidean
    and y-axis distance metrics suffices. If you wish to build the rep counter for
    side-facing exercises as well, you might need to consider x-axis distances as
    well. I also normalize the metrics by shoulder-to-shoulder distance so that the
    rep-counting doesn't get affected by the distance from the camera.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæƒ³æ³•æ˜¯ä½¿ç”¨èƒ½å¤Ÿè¦†ç›–å¹¿æ³›è¿åŠ¨èŒƒå›´çš„åº¦é‡ã€‚æˆ‘é€šå¸¸æ›´å–œæ¬¢é¢å¯¹å‰ç½®æ‘„åƒå¤´è¿›è¡Œé”»ç‚¼ï¼›å› æ­¤ï¼Œé€‰æ‹©æ¬§å‡ é‡Œå¾—è·ç¦»å’Œyè½´è·ç¦»åº¦é‡å³å¯ã€‚å¦‚æœæ‚¨å¸Œæœ›ä¸ºä¾§é¢é”»ç‚¼å»ºç«‹é‡å¤è®¡æ•°å™¨ï¼Œæ‚¨å¯èƒ½éœ€è¦è€ƒè™‘xè½´è·ç¦»ã€‚æˆ‘è¿˜é€šè¿‡è‚©è†€åˆ°è‚©è†€çš„è·ç¦»æ¥è§„èŒƒåŒ–åº¦é‡ï¼Œä»¥ä¾¿é‡å¤è®¡æ•°ä¸ä¼šå—åˆ°æ‘„åƒå¤´è·ç¦»çš„å½±å“ã€‚
- en: '**c)** Frame-level pose estimation results in a jitter in body keypoints which
    results in a jitter in the computed metrics. We use a low-pass filter to make
    metrics smooth and remove the jitter in the metric distances and angles, which
    makes the reference calculation and rep counting more accurate. More details on
    the technique can be found [here](https://medium.com/towards-data-science/towards-a-more-applicative-pose-estimation-bf18bc311228).
    Ensure that the body keypoints are well within the frame before metrics computation.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**c)** å¸§çº§å§¿åŠ¿ä¼°è®¡ä¼šå¯¼è‡´èº«ä½“å…³é”®ç‚¹çš„æŠ–åŠ¨ï¼Œä»è€Œå¯¼è‡´è®¡ç®—åº¦é‡çš„æŠ–åŠ¨ã€‚æˆ‘ä»¬ä½¿ç”¨ä½é€šæ»¤æ³¢å™¨ä½¿åº¦é‡å¹³æ»‘ï¼Œå¹¶å»é™¤åº¦é‡è·ç¦»å’Œè§’åº¦ä¸­çš„æŠ–åŠ¨ï¼Œè¿™ä½¿å¾—å‚è€ƒè®¡ç®—å’Œé‡å¤è®¡æ•°æ›´åŠ å‡†ç¡®ã€‚æœ‰å…³è¯¥æŠ€æœ¯çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[è¿™é‡Œ](https://medium.com/towards-data-science/towards-a-more-applicative-pose-estimation-bf18bc311228)ã€‚ç¡®ä¿åœ¨è®¡ç®—åº¦é‡ä¹‹å‰èº«ä½“å…³é”®ç‚¹åœ¨æ¡†æ¶å†…ã€‚'
- en: '**d)** Next, we filter out stationary metric signals. We compute the standard
    deviation of these signals and remove signals below a fixed threshold. If none
    of the metrics get filtered out, we use the top 3 metrics with the highest deviation.
    For the exercise rep counter, we consider a total of **18** metrics. For the above
    reference and a threshold standard deviation of **0.4**, we end up with **8**
    metrics that contribute most to the repetitiveness.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**d)** æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç­›é€‰å‡ºé™æ­¢çš„åº¦é‡ä¿¡å·ã€‚æˆ‘ä»¬è®¡ç®—è¿™äº›ä¿¡å·çš„æ ‡å‡†å·®ï¼Œå¹¶å»é™¤ä½äºå›ºå®šé˜ˆå€¼çš„ä¿¡å·ã€‚å¦‚æœæ²¡æœ‰åº¦é‡è¢«ç­›é€‰å‡ºå»ï¼Œæˆ‘ä»¬ä½¿ç”¨æ ‡å‡†å·®æœ€å¤§çš„å‰3ä¸ªåº¦é‡ã€‚å¯¹äºé”»ç‚¼é‡å¤è®¡æ•°å™¨ï¼Œæˆ‘ä»¬è€ƒè™‘æ€»å…±**18**ä¸ªåº¦é‡ã€‚å¯¹äºä¸Šè¿°å‚è€ƒå’Œæ ‡å‡†å·®é˜ˆå€¼ä¸º**0.4**çš„æƒ…å†µï¼Œæˆ‘ä»¬æœ€ç»ˆå¾—åˆ°**8**ä¸ªå¯¹é‡å¤æ€§è´¡çŒ®æœ€å¤§çš„åº¦é‡ã€‚'
- en: '![](../Images/ed602d66069f7def06cee821799ca88d.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed602d66069f7def06cee821799ca88d.png)'
- en: 'Fig: Metric waveforms. Image by Author.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ï¼šåº¦é‡æ³¢å½¢ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚
- en: '**e)** Finally, we sum all remaining non-stationary metrics temporally and
    compute the reference line using the mean of the summed-up signal. We save idâ€™s
    of these metrics and the reference line (the mean) in a ***config dictionary***
    to be later used during rep-counting. The reference line for the trainer video:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**e)** æœ€åï¼Œæˆ‘ä»¬å°†æ‰€æœ‰å‰©ä½™çš„éå¹³ç¨³åº¦é‡åœ¨æ—¶é—´ä¸Šç›¸åŠ ï¼Œå¹¶è®¡ç®—ä½¿ç”¨æ€»å’Œä¿¡å·çš„å‡å€¼ä½œä¸ºå‚è€ƒçº¿ã€‚æˆ‘ä»¬å°†è¿™äº›åº¦é‡å’Œå‚è€ƒçº¿ï¼ˆå‡å€¼ï¼‰çš„IDä¿å­˜åˆ°ä¸€ä¸ª***é…ç½®å­—å…¸***ä¸­ï¼Œä»¥ä¾¿åœ¨é‡å¤è®¡æ•°æ—¶ä½¿ç”¨ã€‚æ•™ç»ƒè§†é¢‘çš„å‚è€ƒçº¿ï¼š'
- en: '![](../Images/39587bc9fa645345b11ec6fdf9c2e55e.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39587bc9fa645345b11ec6fdf9c2e55e.png)'
- en: 'Fig: Overall signal waveform for the reference video. Image by Author.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ï¼šå‚è€ƒè§†é¢‘çš„æ•´ä½“ä¿¡å·æ³¢å½¢ã€‚å›¾ç‰‡æ¥æºï¼šä½œè€…ã€‚
- en: A careful look at the reference video illustrates that there are 6 reps in total.
    These reps actually correspond to the peaks observed in the overall signal above.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä»”ç»†æŸ¥çœ‹å‚è€ƒè§†é¢‘å¯ä»¥çœ‹å‡ºï¼Œæ€»å…±æœ‰6ä¸ªé‡å¤ã€‚è¿™äº›é‡å¤å®é™…ä¸Šå¯¹åº”äºä¸Šé¢æ•´ä½“ä¿¡å·ä¸­è§‚å¯Ÿåˆ°çš„å³°å€¼ã€‚
- en: 'Phase 2: Rep Counting'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é˜¶æ®µ2ï¼šé‡å¤è®¡æ•°
- en: Most of the steps in this phase are common to the reference computation phase.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€é˜¶æ®µçš„å¤§éƒ¨åˆ†æ­¥éª¤ä¸å‚è€ƒè®¡ç®—é˜¶æ®µæ˜¯ç›¸åŒçš„ã€‚
- en: '**a)** Given a test video, we start by computing the keypoints and normalized
    metrics in real-time (same as the previous step).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**a)** ç»™å®šä¸€ä¸ªæµ‹è¯•è§†é¢‘ï¼Œæˆ‘ä»¬é¦–å…ˆå®æ—¶è®¡ç®—å…³é”®ç‚¹å’Œå½’ä¸€åŒ–åº¦é‡ï¼ˆä¸å‰ä¸€æ­¥ç›¸åŒï¼‰ã€‚'
- en: '**b)** We use the config dict from the reference computation phase to figure
    out the desired non-stationary metrics for this exercise and then sum up these
    metrics temporally to create a combined overall signal.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**b)** æˆ‘ä»¬ä½¿ç”¨å‚è€ƒè®¡ç®—é˜¶æ®µçš„é…ç½®å­—å…¸æ¥ç¡®å®šæ­¤ç»ƒä¹ æ‰€éœ€çš„éå¹³ç¨³åº¦é‡ï¼Œç„¶åå°†è¿™äº›åº¦é‡åœ¨æ—¶é—´ä¸Šç›¸åŠ ï¼Œåˆ›å»ºä¸€ä¸ªç»¼åˆçš„æ•´ä½“ä¿¡å·ã€‚'
- en: '**c)** We create a fixed-size **moving window** in real-time and check for
    its **intersection with the reference line, aka the zero-crossing line**. For
    any repetitive movement, there are usually two states, one when going to the upstate
    of the exercise and the other when coming to the downstate, and either one of
    them is a normal state.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**c)** æˆ‘ä»¬å®æ—¶åˆ›å»ºä¸€ä¸ªå›ºå®šå¤§å°çš„**ç§»åŠ¨çª—å£**ï¼Œå¹¶æ£€æŸ¥å®ƒä¸**å‚è€ƒçº¿ï¼Œå³é›¶äº¤å‰çº¿**çš„**äº¤é›†**ã€‚å¯¹äºä»»ä½•é‡å¤çš„åŠ¨ä½œï¼Œé€šå¸¸æœ‰ä¸¤ç§çŠ¶æ€ï¼Œä¸€ç§æ˜¯è¿åŠ¨çš„ä¸Šå‡çŠ¶æ€ï¼Œå¦ä¸€ç§æ˜¯ä¸‹é™çŠ¶æ€ï¼Œä»»æ„ä¸€ç§éƒ½æ˜¯æ­£å¸¸çŠ¶æ€ã€‚'
- en: Hence, for a single rep, there are two intersections of the overall signal waveform
    with the reference line. The first intersection gives the idea that the person
    has reached upstate of the exercise, and the second intersection gives us the
    idea that the person is back to the normal state and the rep is complete.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¯¹äºä¸€ä¸ªé‡å¤åŠ¨ä½œï¼Œæ•´ä½“ä¿¡å·æ³¢å½¢ä¸å‚è€ƒçº¿æœ‰ä¸¤ä¸ªäº¤ç‚¹ã€‚ç¬¬ä¸€ä¸ªäº¤ç‚¹è¡¨æ˜è¯¥äººå·²ç»è¾¾åˆ°åŠ¨ä½œçš„ä¸Šå‡çŠ¶æ€ï¼Œç¬¬äºŒä¸ªäº¤ç‚¹åˆ™è¡¨æ˜è¯¥äººå›åˆ°æ­£å¸¸çŠ¶æ€ï¼Œè¿™ä¸ªé‡å¤åŠ¨ä½œå®Œæˆäº†ã€‚
- en: That's it!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼
- en: Results
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“æœ
- en: Letâ€™s see the performance of the approach on a test video.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æŸ¥çœ‹è¿™ç§æ–¹æ³•åœ¨æµ‹è¯•è§†é¢‘ä¸Šçš„è¡¨ç°ã€‚
- en: '![](../Images/17e5df810fad9cba9f5a07e5f88a4e01.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17e5df810fad9cba9f5a07e5f88a4e01.png)'
- en: 'Fig: Rep Counting using the zero-crossing technique. GIF by Author.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ï¼šä½¿ç”¨é›¶äº¤å‰æŠ€æœ¯è¿›è¡Œçš„é‡å¤è®¡æ•°ã€‚GIFæ¥æºï¼šä½œè€…ã€‚
- en: The results look decent, right? ğŸ˜. Here is the overall signal waveform for the
    above test video. Intuitively, the four peaks correspond to the four reps.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœçœ‹èµ·æ¥ä¸é”™ï¼Œå¯¹å§ï¼ŸğŸ˜ã€‚è¿™æ˜¯ä¸Šè¿°æµ‹è¯•è§†é¢‘çš„æ•´ä½“ä¿¡å·æ³¢å½¢ã€‚ç›´è§‚åœ°çœ‹ï¼Œå››ä¸ªå³°å€¼å¯¹åº”äºå››ä¸ªé‡å¤ã€‚
- en: '![](../Images/b70dc4a2e04752d4a19fba1e06bbeb70.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b70dc4a2e04752d4a19fba1e06bbeb70.png)'
- en: 'Fig: Overall signal waveform for the test video. Image by Author.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ï¼šæµ‹è¯•è§†é¢‘çš„æ•´ä½“ä¿¡å·æ³¢å½¢ã€‚å›¾ç‰‡æ¥æºï¼šä½œè€…ã€‚
- en: '**Pros of the approach**'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ–¹æ³•çš„ä¼˜ç‚¹**'
- en: The algorithm is quite **fast** and **accurate.**
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç®—æ³•ç›¸å½“**å¿«é€Ÿ**å’Œ**å‡†ç¡®**ã€‚
- en: The idea is **instinctive**, and the implementation is simple.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæƒ³æ³•æ˜¯**ç›´è§‚çš„**ï¼Œå®ç°èµ·æ¥å¾ˆç®€å•ã€‚
- en: The approach is easily integrable in a production setting.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿™ç§æ–¹æ³•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æ˜“äºé›†æˆã€‚
- en: '**Cons of the approach**'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ–¹æ³•çš„ç¼ºç‚¹**'
- en: Not a **generic** rep-counter (however, the idea can be adapted for other classes).
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸æ˜¯ä¸€ä¸ª**é€šç”¨çš„**é‡å¤è®¡æ•°å™¨ï¼ˆä½†è¿™ä¸ªæƒ³æ³•å¯ä»¥é€‚ç”¨äºå…¶ä»–ç±»åˆ«ï¼‰ã€‚
- en: Need to calculate the zero-crossing line using a reference video for each exercise/class;
    hence, difficult to **scale** to a big corpus of exercises.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: éœ€è¦ä½¿ç”¨æ¯ä¸ªç»ƒä¹ /ç±»åˆ«çš„å‚è€ƒè§†é¢‘æ¥è®¡ç®—é›¶äº¤å‰çº¿ï¼Œå› æ­¤éš¾ä»¥**æ‰©å±•**åˆ°å¤§é‡çš„ç»ƒä¹ æ•°æ®ã€‚
- en: In places the background is noisy, pose estimation might work poorly and hence
    result in poor rep-count results.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨èƒŒæ™¯å™ªå£°è¾ƒå¤§çš„åœ°æ–¹ï¼Œå§¿æ€ä¼°è®¡å¯èƒ½æ•ˆæœä¸å¥½ï¼Œä»è€Œå¯¼è‡´é‡å¤è®¡æ•°ç»“æœä¸ä½³ã€‚
- en: It might not work for exercises wherein the overall signal becomes flat due
    to different metrics eventually averaging out each other.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºé‚£äº›æ•´ä½“ä¿¡å·ç”±äºä¸åŒåº¦é‡æœ€ç»ˆç›¸äº’å¹³å‡è€Œå˜å¾—å¹³å¦çš„ç»ƒä¹ ï¼Œè¿™å¯èƒ½ä¸èµ·ä½œç”¨ã€‚
- en: In this blog, I highlighted the zero-crossing idea to count the reps; however,
    another technique known as **peak detection**, which we briefly discussed at the
    start, can also be employed to detect reps in real time.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘å¼ºè°ƒäº†ä½¿ç”¨é›¶äº¤å‰ç‚¹æ¥è®¡æ•°é‡å¤æ¬¡æ•°çš„æƒ³æ³•ï¼›ç„¶è€Œï¼Œå¦ä¸€ç§æŠ€æœ¯â€”â€”**å³°å€¼æ£€æµ‹**ï¼Œæˆ‘ä»¬åœ¨å¼€å§‹æ—¶ç®€è¦è®¨è®ºè¿‡ï¼Œä¹Ÿå¯ä»¥ç”¨æ¥å®æ—¶æ£€æµ‹é‡å¤æ¬¡æ•°ã€‚
- en: Useful References
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ‰ç”¨çš„å‚è€ƒèµ„æ–™
- en: '[1]. [Usage of Low pass filters to make pose estimation more effective](https://medium.com/towards-data-science/towards-a-more-applicative-pose-estimation-bf18bc311228)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]. [ä½¿ç”¨ä½é€šæ»¤æ³¢å™¨ä½¿å§¿æ€ä¼°è®¡æ›´æœ‰æ•ˆ](https://medium.com/towards-data-science/towards-a-more-applicative-pose-estimation-bf18bc311228)'
- en: '[2]. [Robust peak detection algorithm (using z-scores)](https://stackoverflow.com/questions/22583391/peak-signal-detection-in-realtime-timeseries-data/22640362#22640362)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]. [é²æ£’çš„å³°å€¼æ£€æµ‹ç®—æ³•ï¼ˆä½¿ç”¨ z-åˆ†æ•°ï¼‰](https://stackoverflow.com/questions/22583391/peak-signal-detection-in-realtime-timeseries-data/22640362#22640362)'
- en: '[3]. [MoveNet: Ultrafast and accurate pose detection model](https://www.tensorflow.org/hub/tutorials/movenet)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[3]. [MoveNet: è¶…å¿«é€Ÿä¸”å‡†ç¡®çš„å§¿æ€æ£€æµ‹æ¨¡å‹](https://www.tensorflow.org/hub/tutorials/movenet)'
- en: '[4]. The implementation of the approach can be found [here](https://github.com/aakash2016/blog-codes);
    please read the instructions in the repository for usage.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[4]. è¯¥æ–¹æ³•çš„å®ç°å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/aakash2016/blog-codes)æ‰¾åˆ°ï¼›è¯·é˜…è¯»åº“ä¸­çš„è¯´æ˜ä»¥è·å–ä½¿ç”¨æ–¹æ³•ã€‚'
- en: I hope you got the gist of how we can use signal-processing techniques for building
    a class-specific rep-counter. I would like to know the feedback of anyone reading
    this blog. I would be happy to answer any doubts/questions on any of the concepts
    mentioned above. Feedback is greatly welcomed. You can reach me via [Linkedin](https://www.linkedin.com/in/akash2016123/).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ èƒ½ç†è§£å¦‚ä½•ä½¿ç”¨ä¿¡å·å¤„ç†æŠ€æœ¯æ¥æ„å»ºä¸€ä¸ªç‰¹å®šç±»åˆ«çš„é‡å¤è®¡æ•°å™¨ã€‚æˆ‘å¾ˆæƒ³äº†è§£é˜…è¯»è¿™ç¯‡åšå®¢çš„äººçš„åé¦ˆã€‚æˆ‘å¾ˆä¹æ„å›ç­”æœ‰å…³ä¸Šè¿°æ¦‚å¿µçš„ä»»ä½•ç–‘é—®/é—®é¢˜ã€‚æ¬¢è¿åé¦ˆã€‚ä½ å¯ä»¥é€šè¿‡
    [Linkedin](https://www.linkedin.com/in/akash2016123/) è”ç³»æˆ‘ã€‚
- en: Thank You!
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è°¢è°¢ï¼
