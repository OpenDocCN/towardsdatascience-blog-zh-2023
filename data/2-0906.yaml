- en: Five Hidden Causes of Data Leakage You Should Be Aware of
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你应该注意的五个数据泄露的隐藏原因
- en: 原文：[https://towardsdatascience.com/five-hidden-causes-of-data-leakage-you-should-be-aware-of-e44df654f185](https://towardsdatascience.com/five-hidden-causes-of-data-leakage-you-should-be-aware-of-e44df654f185)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/five-hidden-causes-of-data-leakage-you-should-be-aware-of-e44df654f185](https://towardsdatascience.com/five-hidden-causes-of-data-leakage-you-should-be-aware-of-e44df654f185)
- en: And How They Sabotage Machine Learning Models
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以及它们如何破坏机器学习模型
- en: '[](https://donatoriccio.medium.com/?source=post_page-----e44df654f185--------------------------------)[![Donato
    Riccio](../Images/0af2a026e72a023db4635522cbca50eb.png)](https://donatoriccio.medium.com/?source=post_page-----e44df654f185--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e44df654f185--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e44df654f185--------------------------------)
    [Donato Riccio](https://donatoriccio.medium.com/?source=post_page-----e44df654f185--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://donatoriccio.medium.com/?source=post_page-----e44df654f185--------------------------------)[![Donato
    Riccio](../Images/0af2a026e72a023db4635522cbca50eb.png)](https://donatoriccio.medium.com/?source=post_page-----e44df654f185--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e44df654f185--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e44df654f185--------------------------------)
    [Donato Riccio](https://donatoriccio.medium.com/?source=post_page-----e44df654f185--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e44df654f185--------------------------------)
    ·8 min read·Apr 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e44df654f185--------------------------------)
    ·8 分钟阅读·2023年4月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/cd2be5f86610dde00f6fbf97f8484e3e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd2be5f86610dde00f6fbf97f8484e3e.png)'
- en: Photo by [Linh Pham](https://unsplash.com/@linharex?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Linh Pham](https://unsplash.com/@linharex?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Data leakage is a sneaky issue that often plagues machine learning models. The
    term leakage refers to test data *leaking* into the training set. It happens when
    the model is trained on data that it shouldn’t have access to during training,
    leading to overfitting and poor performance on unseen data. It’s like training
    a student for a test using the test answers — they’ll do great on that specific
    test, but not so well on others. The goal of machine learning is to create models
    that can generalize and make accurate predictions on new, unseen data. Data leakage
    undermines this goal, and it’s important to be aware of and prepare against it.
    In this article, we’ll take a closer look at what data leakage is, its potential
    causes, and ways to prevent it with practical examples using Python and scikit-learn,
    and cases from research.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄露是一个隐蔽的问题，通常困扰机器学习模型。泄露这个术语指的是测试数据*泄漏*到训练集中。当模型在训练过程中接触到不应有的数据时，就会发生这种情况，导致过拟合和在未见过数据上的表现不佳。这就像用考试答案来训练学生一样——他们在特定的考试中表现出色，但在其他考试中表现就不那么好。机器学习的目标是创建能够泛化并在新的、未见过的数据上做出准确预测的模型。数据泄露破坏了这一目标，因此了解和准备应对它非常重要。在本文中，我们将深入探讨什么是数据泄露，它的潜在原因，以及如何通过使用
    Python 和 scikit-learn 的实际示例以及研究中的案例来防止它。
- en: Consequences of Data Leakage
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据泄露的后果
- en: '**Overfitting.** One of the most significant consequences of data leakage is
    overfitting. Overfitting occurs when a model is trained to fit the training data
    so well that it is not able to generalize to new data. When data leakage occurs,
    the model will have a high accuracy on the the train and test set that you used
    while developing it. However, when the model is deployed, it will not perform
    as well because it cannot generalize its classification rules to unseen data.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合。** 数据泄露的一个重大后果是过拟合。过拟合发生在模型被训练得过于贴合训练数据，以至于无法对新数据进行泛化。当数据泄露发生时，模型在开发过程中使用的训练集和测试集上的准确率很高。然而，当模型被部署时，它的表现不会那么好，因为它无法将其分类规则泛化到未见过的数据。'
- en: '**Misleading Performance Metrics.** Data leakage can also result in misleading
    performance metrics. The model may appear to have high accuracy because it has
    seen some of the test data during training. It’s thus very difficult to evaluate
    the model and understand its performance.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**误导性的性能指标。** 数据泄露还可能导致误导性的性能指标。模型可能会表现出高准确率，因为它在训练过程中看到了部分测试数据。因此，很难评估模型并理解其性能。'
- en: Data leakage before splitting
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 划分前的数据泄露
- en: 'The first case we are presenting is the simplest one, but probably the most
    common: when preprocessing is performed before the train/test split.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们呈现的第一个案例是最简单的，但可能是最常见的：在训练/测试划分之前进行预处理。
- en: You want to use a StandardScaler to standardize your data, so you load your
    dataset, standardize it, create a train and test set, and run the model. Right?
    Wrong.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你想使用StandardScaler来标准化数据，因此你加载数据集，进行标准化，创建训练集和测试集，然后运行模型。对吗？错了。
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The mean and standard deviation are computed on the whole column, and thus they
    include pieces of information from the test set. Using these values in the standardization
    process means the test data is *leaking* into the train data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 均值和标准差是在整列上计算的，因此它们包括了测试集中的信息。使用这些值进行标准化处理意味着测试数据正在*泄漏*到训练数据中。
- en: 'The solution: Pipelines'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案：管道
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this version, a pipeline is used to encapsulate the preprocessing step, which
    is then fit and evaluated on the training set only. In this case, **StandardScaler**
    is used as a preprocessing step, which standardizes the feature by subtracting
    the mean and scaling to unit variance. When you call the *fit* method, sklearn
    is standardizing each set separately. This ensures that the test set is not used
    to inform the preprocessing step, avoiding data leakage.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个版本中，使用了管道来封装预处理步骤，然后仅在训练集上进行拟合和评估。在这种情况下，**StandardScaler**被用作预处理步骤，它通过减去均值并缩放到单位方差来标准化特征。当你调用*fit*方法时，sklearn会分别标准化每个数据集。这确保了测试集不会用于指导预处理步骤，从而避免了数据泄露。
- en: Data leakage when using cross-validation
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用交叉验证时的数据泄露
- en: The second example is a very common mistake that often goes unnoticed. Your
    dataset is unbalanced, and you’ve read how you should use oversampling to “fix”
    it. After some googling, you find SMOTE, an algorithm that uses the nearest neighbors
    to generate new samples in order to balance the minority class. Let’s apply this
    technique to a dataset called credit_g, from the library PMLB.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个例子是一个非常常见的错误，通常被忽视。你的数据集是不平衡的，你已经了解过应该如何使用过采样来“修复”它。经过一些搜索，你发现了SMOTE，这是一种使用最近邻生成新样本以平衡少数类的算法。我们将这个技术应用于名为credit_g的数据集，来自PMLB库。
- en: The dataset is unbalanced, with a 70/30 ratio between the classes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集是不平衡的，类别之间的比例为70/30。
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As a baseline result, we show the AUC score without applying any transformation.
    Running a Logistic Regression model gives a mean ROC AUC score of 0.75.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基线结果，我们展示了不应用任何变换的AUC分数。运行逻辑回归模型的平均ROC AUC分数为0.75。
- en: Let’s now apply SMOTE.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们应用SMOTE。
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'After applying SMOTE you’re happy to see that the AUC score increased from
    0.75 to 0.84! However, all that glitters is not gold: you just caused data leakage.
    In the code above, the transformation was applied before running cross-validation,
    which splits train and test sets on different folds. This is a very common scenario
    that can trick beginners into thinking that SMOTE increased their model performance.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 应用SMOTE后，你会很高兴地看到AUC分数从0.75提高到0.84！然而，所有的光芒都不是金子：你刚刚造成了数据泄露。在上面的代码中，变换在运行交叉验证之前应用，这将训练和测试集分割到不同的折中。这是一个非常常见的场景，可能会误导初学者认为SMOTE提高了他们的模型性能。
- en: Let’s now take a look at a corrected version of the code, where SMOTE is applied
    after the cross-validation split.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一下修正后的代码，其中SMOTE在交叉验证划分之后应用。
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Applying SMOTE correctly actually made the model worse.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正确应用SMOTE实际上使模型更糟。
- en: As [Samuele Mazzanti](https://medium.com/u/e16f3bb86e03?source=post_page-----e44df654f185--------------------------------)
    highlighted in his article [Your Dataset Is Imbalanced? Do Nothing!](/your-dataset-is-imbalanced-do-nothing-abf6a0049813),
    oversampling is not necessary to handle unbalanced datasets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[Samuele Mazzanti](https://medium.com/u/e16f3bb86e03?source=post_page-----e44df654f185--------------------------------)在他的文章[你的数据集不平衡？什么都不要做！](/your-dataset-is-imbalanced-do-nothing-abf6a0049813)中强调的那样，过采样并不是处理不平衡数据集的必要手段。
- en: Data leakage in time series
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列中的数据泄露
- en: Time series data has unique characteristics that make it different from other
    types of data, which can lead to specific challenges when splitting the data,
    preparing features, and evaluating models. Here, we’ll elaborate on these challenges
    and suggest best practices to minimize data leakage in time series analysis.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据具有独特的特性，使其与其他类型的数据不同，这可能导致在划分数据、准备特征和评估模型时出现特定的挑战。在这里，我们将详细阐述这些挑战，并建议最佳实践以最小化时间序列分析中的数据泄露。
- en: '**Incorrect train-test split**: In time series data, it’s essential to maintain
    the temporal order of observations when splitting the dataset into training and
    test sets. A random split can introduce leakage, as it may include future information
    in the training set. To avoid this, you should use a time-based split, ensuring
    that all data points in the training set come before those in the test set. You
    can also use techniques such as time-series cross-validation or walk-forward validation
    to assess your model’s performance more accurately.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**不正确的训练-测试划分**：在时间序列数据中，将数据集分为训练集和测试集时，必须保持观察的时间顺序。随机划分可能会引入数据泄漏，因为它可能将未来的信息包含在训练集中。为了避免这种情况，应使用基于时间的划分，确保训练集中的所有数据点都在测试集的数据点之前。你还可以使用时间序列交叉验证或前向验证等技术，以更准确地评估模型的性能。'
- en: '**Feature engineering**: You should avoid using future information that wouldn’t
    be available at the time of prediction. For instance, calculating technical indicators,
    lagged variables, or rolling statistics should be done only using past data, not
    future data. To prevent data leakage during feature engineering, you can use techniques
    like applying time-based window functions, ensuring that the calculation window
    only includes data available up to the prediction time. This also applies to external
    data. Sometimes, time series models incorporate external data sources that may
    contain future information. Make sure that the indicators are lagged appropriately,
    so they don’t provide information from the future and always verify that external
    data sources maintain the same temporal order as your primary time series dataset.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征工程**：你应该避免使用在预测时无法获得的未来信息。例如，计算技术指标、滞后变量或滚动统计数据时，只应使用过去的数据，而不是未来的数据。为了在特征工程过程中防止数据泄漏，你可以使用诸如应用基于时间的窗口函数等技术，确保计算窗口只包含到预测时间为止的数据。这也适用于外部数据。有时，时间序列模型会结合可能包含未来信息的外部数据源。确保指标适当地滞后，以免提供未来的信息，并始终验证外部数据源是否与主要时间序列数据集保持相同的时间顺序。'
- en: Data leakage in image data
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像数据中的数据泄漏
- en: When you’re working with medical data there are often multiple images taken
    from the same patient. In this case, you can’t just split the dataset randomly
    to train a model, because you might accidentally end up with images from the same
    person in both the training and test sets. Instead, you need to use a *per-subject*
    split.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理医学数据时，通常会从同一患者那里获取多张图像。在这种情况下，你不能仅仅随机划分数据集来训练模型，因为你可能会不小心将同一人的图像放在训练集和测试集中。相反，你需要使用*按受试者划分*的方法。
- en: So what’s a per-subject split? It just means that you keep all the images from
    the same person together, either in the training or test set. This way, your model
    can’t cheat by learning from images of the same person in both sets.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么是按受试者划分？这意味着你将同一人的所有图像放在一起，要么在训练集中，要么在测试集中。这样，你的模型就不能通过从两个集合中的同一人的图像中学习而作弊。
- en: 'There is a [study](https://arxiv.org/abs/2202.12267) that looked at the difference
    between random splits and per-subject splits. They test it on three different
    datasets and find that random splits lead to inflated test accuracy because of
    data leakage. On the other hand, per-subject splits give more accurate results.
    The datasets used are the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有一项[研究](https://arxiv.org/abs/2202.12267)探讨了随机划分与按受试者划分之间的差异。他们在三个不同的数据集上进行测试，发现随机划分会导致测试准确度虚高，因为数据泄漏。另一方面，按受试者划分则能得到更准确的结果。使用的数据集如下：
- en: '**AIIMS dataset**: Contains 18,480 2D OCT images of healthy and cancerous breast
    tissue from 45 subjects (22 cancer patients and 23 healthy subjects).'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**AIIMS 数据集**：包含来自 45 名受试者（22 名癌症患者和 23 名健康受试者）的 18,480 张健康和癌症乳腺组织的 2D OCT
    图像。'
- en: '**Srinivasan’s dataset**: An ophthalmology dataset with 3,231 2D OCT images
    of age-related macular degeneration (AMD), diabetic macular edema (DME), and normal
    subjects, including 15 subjects per class.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Srinivasan 数据集**：一个眼科学数据集，包括 3,231 张年龄相关性黄斑变性（AMD）、糖尿病性黄斑水肿（DME）和正常受试者的 2D
    OCT 图像，每类包括 15 名受试者。'
- en: '**Kermany’s dataset**: A large open-access ophthalmology dataset featuring
    images from 5,319 patients with choroidal neovascularization (CNV), diabetic macular
    edema (DME), drusen, and normal retina images. The dataset is available in different
    versions, with variations in the number of images, organization, and data overlap
    between training and testing sets.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kermany的数据集**：一个大型开放获取的眼科数据集，包含来自5,319名患者的脉络膜新生血管（CNV）、糖尿病性黄斑水肿（DME）、视网膜上皮下层（drusen）和正常视网膜图像。该数据集有不同版本，图像数量、组织和训练与测试集之间的数据重叠有所不同。'
- en: The results speak for themselves.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 结果不言自明。
- en: '![](../Images/dc7493873a07f08f8668283ed7199230.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc7493873a07f08f8668283ed7199230.png)'
- en: Comparison of different split strategies. [Source.](https://arxiv.org/abs/2202.12267)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 不同分割策略的比较。[来源。](https://arxiv.org/abs/2202.12267)
- en: 'The models are evaluated on the Matthews Correlation Coefficient, defined as
    follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 模型通过Matthews相关系数进行评估，定义如下：
- en: '![](../Images/4acaa48e86486e538022e93f55db2e05.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4acaa48e86486e538022e93f55db2e05.png)'
- en: Matthews Correlation Coefficient. Image by author.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Matthews相关系数。图像由作者提供。
- en: As you can imagine, when we randomly split the data, we got a score that was
    too good to be true. And that’s because images from the same person look very
    similar, so the model had an easier time recognizing images from people it had
    already seen in the training data. In the real world, we need models that can
    reliably identify diseases in new patients.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可以想象的那样，当我们随机分割数据时，得到的分数好得令人难以置信。这是因为来自同一个人的图像看起来非常相似，因此模型在识别训练数据中已经见过的人时更容易。在现实世界中，我们需要能够可靠识别新患者疾病的模型。
- en: 'Data leakage is a common problem that can affect even the most skilled data
    scientists when building machine learning models. Next, we’ll take a look at another
    case from research. In 2017, Andrew Ng and his team published a groundbreaking
    paper titled *“CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays
    with Deep Learning.”* The paper introduced an algorithm that used deep learning
    to detect pneumonia in chest X-rays, achieving performance on par with expert
    radiologists. The following image is taken from the paper.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄露是一个常见的问题，即使是最熟练的数据科学家在构建机器学习模型时也会受到影响。接下来，我们将看看另一个研究案例。2017年，Andrew Ng及其团队发表了一篇开创性的论文，标题为*“CheXNet：利用深度学习在胸部X光片中进行放射科医师级的肺炎检测。”*
    这篇论文介绍了一种利用深度学习检测胸部X光片中肺炎的算法，其性能与专家放射科医师相当。以下图像来自论文。
- en: '![](../Images/d9a5181036c178ce5ed7ebe1043df275.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d9a5181036c178ce5ed7ebe1043df275.png)'
- en: ChestXNet original paper. First version. [Source](https://arxiv.org/pdf/1711.05225v1.pdf).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ChestXNet原始论文。第一个版本。[来源](https://arxiv.org/pdf/1711.05225v1.pdf)。
- en: Do you notice something wrong?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你注意到有什么问题吗？
- en: In the [first version](https://arxiv.org/pdf/1711.05225v1.pdf) of the study
    they trained the model splitting the data randomly. Since multiple scans from
    the same patient were included, this potential data leakage raised concerns about
    the reliability and generalizability of CheXNet’s results. The authors acknowledged
    the issue and later released a new version, correcting the issue. The following
    image is taken from the [corrected version.](https://arxiv.org/pdf/1711.05225.pdf)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究的[第一个版本](https://arxiv.org/pdf/1711.05225v1.pdf)中，他们训练模型时随机划分数据。由于包含了同一患者的多个扫描图像，这种潜在的数据泄露引发了对CheXNet结果可靠性和泛化能力的担忧。作者认识到这个问题，后来发布了新版本，纠正了这个问题。以下图像来自[修正版本。](https://arxiv.org/pdf/1711.05225.pdf)
- en: '![](../Images/45dea89bd87a5d709a5b301b7cd7ff70.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/45dea89bd87a5d709a5b301b7cd7ff70.png)'
- en: ChestXNet original paper. Most recent version. [Source](https://arxiv.org/pdf/1711.05225.pdf).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ChestXNet原始论文。最新版本。[来源](https://arxiv.org/pdf/1711.05225.pdf)。
- en: Conclusion
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Data leakage is a sneaky issue that can affect machine learning models at various
    stages of development. As we’ve explored in this article, it can lead to overfitting,
    misleading performance metrics, and ultimately, a model that doesn’t generalize
    well to unseen data. Whether you’re working with tabular data, time series, or
    images, it’s important to be aware of it to build successful models. Here are
    some key takeaways from the article:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 数据泄露是一个隐蔽的问题，会在开发的各个阶段影响机器学习模型。正如我们在本文中探讨的，它可能导致过拟合、误导性的性能指标，以及*最终*一个对未见数据无法良好泛化的模型。无论你是在处理表格数据、时间序列还是图像，都需要意识到这一点，以构建成功的模型。以下是本文的一些关键要点：
- en: If your model suddenly starts performing too well after making some changes,
    it’s always a good idea to check for any data leakage.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的模型在进行某些更改后突然表现过于出色，检查是否有数据泄露总是个好主意。
- en: Avoid preprocessing the entire dataset before splitting it into training and
    test sets. Instead, use pipelines to encapsulate preprocessing steps.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免在将数据集拆分为训练集和测试集之前对整个数据集进行预处理。相反，使用管道来封装预处理步骤。
- en: When using cross-validation, be cautious with techniques like oversampling or
    any other transformation. Apply them only to the training set in each fold to
    prevent leakage.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用交叉验证时，对如过采样或其他任何变换技术要小心。只对每个折中的训练集应用这些技术，以防止数据泄露。
- en: For time series data, maintain the temporal order of observations and use techniques
    like time-based splits and time-series cross-validation.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于时间序列数据，保持观察的时间顺序，并使用诸如基于时间的拆分和时间序列交叉验证等技术。
- en: In image data or datasets with multiple records from the same subject, use per-subject
    splits to avoid leakage.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于图像数据或具有多个记录的同一受试者的数据集，使用每个受试者的拆分以避免数据泄露。
- en: By keeping these points in mind, you’ll be better equipped to build more robust
    and accurate machine learning models.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这些要点，你将能够更好地构建更强大和更准确的机器学习模型。
- en: '*Enjoyed this article? Get weekly data science interview questions delivered
    to your inbox by subscribing to my newsletter,* [*The Data Interview*](https://thedatainterview.substack.com/)*.*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*喜欢这篇文章？通过订阅我的新闻通讯，每周获取数据科学面试问题*，[*《数据面试》*](https://thedatainterview.substack.com/)*。*'
- en: '*Also, you can find me on* [*LinkedIn*](https://www.linkedin.com/in/driccio/)*.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*你也可以在* [*LinkedIn*](https://www.linkedin.com/in/driccio/)*上找到我。*'
