- en: Five Ways To Handle Large Action Spaces in Reinforcement Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理大型行动空间的五种方法
- en: 原文：[https://towardsdatascience.com/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=collection_archive---------2-----------------------#2023-08-18](https://towardsdatascience.com/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=collection_archive---------2-----------------------#2023-08-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=collection_archive---------2-----------------------#2023-08-18](https://towardsdatascience.com/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472?source=collection_archive---------2-----------------------#2023-08-18)
- en: Action spaces, particularly in combinatorial optimization problems, may grow
    unwieldy in size. This article discusses five strategies to handle them.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行动空间，尤其是在组合优化问题中，可能会变得异常庞大。本文讨论了处理这些问题的五种策略。
- en: '[](https://wvheeswijk.medium.com/?source=post_page-----8ba6b6ca7472--------------------------------)[![Wouter
    van Heeswijk, PhD](../Images/9c996bccd6fdfb6d9aa8b50b93338eb9.png)](https://wvheeswijk.medium.com/?source=post_page-----8ba6b6ca7472--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8ba6b6ca7472--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8ba6b6ca7472--------------------------------)
    [Wouter van Heeswijk, PhD](https://wvheeswijk.medium.com/?source=post_page-----8ba6b6ca7472--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wvheeswijk.medium.com/?source=post_page-----8ba6b6ca7472--------------------------------)[![Wouter
    van Heeswijk, PhD](../Images/9c996bccd6fdfb6d9aa8b50b93338eb9.png)](https://wvheeswijk.medium.com/?source=post_page-----8ba6b6ca7472--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8ba6b6ca7472--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8ba6b6ca7472--------------------------------)
    [Wouter van Heeswijk, PhD](https://wvheeswijk.medium.com/?source=post_page-----8ba6b6ca7472--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33f45c9ab481&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=post_page-33f45c9ab481----8ba6b6ca7472---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8ba6b6ca7472--------------------------------)
    ·14 min read·Aug 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8ba6b6ca7472&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----8ba6b6ca7472---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33f45c9ab481&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=post_page-33f45c9ab481----8ba6b6ca7472---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8ba6b6ca7472--------------------------------)
    ·14 分钟阅读·2023年8月18日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8ba6b6ca7472&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472&user=Wouter+van+Heeswijk%2C+PhD&userId=33f45c9ab481&source=-----8ba6b6ca7472---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ba6b6ca7472&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472&source=-----8ba6b6ca7472---------------------bookmark_footer-----------)![](../Images/faed2a6acffe7d9d787734e7815479db.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8ba6b6ca7472&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffive-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472&source=-----8ba6b6ca7472---------------------bookmark_footer-----------)![](../Images/faed2a6acffe7d9d787734e7815479db.png)'
- en: And…action! [Photo by [Jakob Owens](https://unsplash.com/@jakobowens1?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧！[照片由 [Jakob Owens](https://unsplash.com/@jakobowens1?utm_source=medium&utm_medium=referral)
    提供，发布于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)]
- en: 'Handling large action spaces remains a fairly open problem in Reinforcement
    Learning. Researchers have made great strides in terms of handling large *state*
    spaces, with convolutional networks and transformers being some recent high-profile
    examples. However, there are three so-called **curses of dimensionality**: state,
    outcome, and action [1]. As of yet, the latter is still rather understudied.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习中，处理大规模动作空间仍然是一个相当开放的问题。研究人员在处理大规模*状态*空间方面取得了巨大进展，卷积网络和变压器是一些近期的高调例子。然而，有三个所谓的**维度诅咒**：状态、结果和动作[1]。到目前为止，后者仍然研究不足。
- en: Still, there is a growing body of methods that attempt to handle large action
    spaces. This article presents five ways that handle the latter at scale, focusing
    in particular on the **high-dimensional discrete action spaces** that are often
    encountered in combinatorial optimization problems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，仍然有越来越多的方法尝试处理大规模动作空间。本文介绍了五种在规模上处理后者的方法，特别关注**高维离散动作空间**，这些空间常在组合优化问题中遇到。
- en: 'Refresher: three curses of dimensionality'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾：三种维度诅咒
- en: 'A quick refresher on the three curses of dimensionality is in order. Assuming
    we express the problem at hand as a system of [Bellman equations](https://medium.com/towards-data-science/why-reinforcement-learning-doesnt-need-bellman-s-equation-c9c2e51a0b7),
    note there are **three sets to evaluate** — in practice in the form of nested
    loops — each of which may be prohibitively large:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有必要对三种维度诅咒做一个简要回顾。假设我们将手头的问题表示为[贝尔曼方程](https://medium.com/towards-data-science/why-reinforcement-learning-doesnt-need-bellman-s-equation-c9c2e51a0b7)系统，请注意有**三组需要评估**—在实践中表现为嵌套循环—每一组可能都过于庞大。
