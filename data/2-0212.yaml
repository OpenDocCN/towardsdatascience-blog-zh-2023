- en: A Performant Recommender System Without Cold Start Problem
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 没有冷启动问题的高效推荐系统
- en: 原文：[https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b](https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b](https://towardsdatascience.com/a-performant-recommender-system-without-cold-start-problem-69bf2f0f0b9b)
- en: '[Recommendation System](https://medium.com/tag/recommendation-system)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[推荐系统](https://medium.com/tag/recommendation-system)'
- en: When collaboration and content-based recommenders merge
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当协同过滤和基于内容的推荐系统合并时
- en: '[](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Dr.
    Robert Kübler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    [Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Dr.
    Robert Kübler](../Images/3b8d8b88f76c0c43d9c305e3885e7ab9.png)](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    [Dr. Robert Kübler](https://dr-robert-kuebler.medium.com/?source=post_page-----69bf2f0f0b9b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    ·11 min read·Jan 31, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----69bf2f0f0b9b--------------------------------)
    ·阅读时间11分钟·2023年1月31日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c0e674a93dd06ef0ac51647be57bbd22.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c0e674a93dd06ef0ac51647be57bbd22.png)'
- en: Photo by [Ivan Aleksic](https://unsplash.com/@ivalex?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Ivan Aleksic](https://unsplash.com/@ivalex?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Perhaps the most famous recommender system is the so-called **matrix factorization**.
    In this **collaborative** recommender, users and items are represented with an
    **embedding**, which is nothing more but a vector of numbers. The intuition is
    that the dot product of the user and the item embedding should result in the rating
    that the user would give this item.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 也许最著名的推荐系统是所谓的**矩阵分解**。在这种**协同过滤**推荐系统中，用户和项目都通过**嵌入**表示，这不过是一个数字向量。直观的理解是，用户和项目嵌入的点积应等于用户对该项目的评分。
- en: If you are not yet familiar with these concepts, I recommend (😉) reading my
    other article before you proceed since I explain many concepts and code snippets
    there.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对这些概念还不熟悉，我建议（😉）在继续之前阅读我的另一篇文章，因为我在其中解释了许多概念和代码片段。
- en: '[](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## Introduction to Embedding-Based Recommender Systems'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## 嵌入式推荐系统简介'
- en: Learn to build a simple recommender in TensorFlow
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习如何在 TensorFlow 中构建一个简单的推荐系统
- en: towardsdatascience.com](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/introduction-to-embedding-based-recommender-systems-956faceb1919?source=post_page-----69bf2f0f0b9b--------------------------------)
- en: The Cold Start Problem
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 冷启动问题
- en: Purely collaborative recommender systems such as matrix factorization have the
    advantage that you can usually immediately build them even without having too
    much data about your users and movies/articles/items you want to recommend. You
    only have to know who rated what and how; for example, user *B* gave movie *Y*
    a rating of 2 stars.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 纯粹的协同过滤推荐系统，如矩阵分解，有一个优点，即使没有太多关于用户和你想推荐的电影/文章/项目的数据，你也通常可以立即构建它们。你只需要知道谁对什么进行了评分以及评分情况；例如，用户*B*对电影*Y*的评分为2星。
- en: '![](../Images/1445f7bebc146490dd07c4960680fa87.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1445f7bebc146490dd07c4960680fa87.png)'
- en: Image by the author.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。
- en: However, they fall short when you have **new** **users or items** that you want
    to make predictions for since the model had no possibility of learning anything
    for them, leaving you with basically random recommendations for them — the dreaded
    **cold start problem**. Let us assume that another user *E* registers, and we
    also add a new movie *W* to the database.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当你有**新**的**用户或项目**时，它们就不够用了，因为模型没有机会学习这些内容，从而基本上为这些用户或项目提供了随机推荐——这就是令人头疼的**冷启动问题**。假设另一个用户*E*注册了，我们还在数据库中添加了一个新电影*W*。
- en: '![](../Images/75385b2e5f953f3aa8c5b5e144ba238e.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/75385b2e5f953f3aa8c5b5e144ba238e.png)'
- en: Image by the author.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: In this article, I will show you a simple way to mitigate the cold start problem
    by incorporating more features about the users and items — this is the **content-based**
    component we will bake into our model. Using actual content data, such as user
    age or a movie genre, produces models that can deal with new users or movies in
    a better way.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将展示一种通过结合更多关于用户和项目的特征来缓解冷启动问题的简单方法——这就是我们将加入到模型中的**基于内容的**组件。使用实际内容数据，如用户年龄或电影类型，生成的模型能更好地处理新用户或新电影。
- en: Back to MovieLens
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到 MovieLens
- en: As in my last article, I will use the [MovieLens](https://movielens.org/) dataset
    that provides us with user-movie ratings. Furthermore, it even contains some more
    user and movie features, and while we ignored these in the last article, we will
    use them today to build an even better model!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 和我上一篇文章一样，我将使用 [MovieLens](https://movielens.org/) 数据集，它提供了用户-电影评分。此外，它还包含了一些用户和电影特征，尽管我们在上一篇文章中忽略了这些特征，但今天我们将利用这些特征来构建更好的模型！
- en: '*You can find the code on* [*my Github*](https://github.com/Garve/Towards-Data-Science---Notebooks/blob/main/TDS%20-%20A%20Performant%20Recommender%20System%20Without%20Cold%20Start%C2%A0Problem.ipynb)*.*'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*你可以在* [*我的 Github*](https://github.com/Garve/Towards-Data-Science---Notebooks/blob/main/TDS%20-%20A%20Performant%20Recommender%20System%20Without%20Cold%20Start%C2%A0Problem.ipynb)*找到代码*。'
- en: Following the last article let us
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随上一篇文章让我们
- en: grab the data using tensorflow-datasets
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 tensorflow-datasets 获取数据
- en: make a dataframe out of it and change some column types, and
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其制作成数据框并更改一些列类型，然后
- en: sort it according to the time to conduct a temporal train-test split
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按时间排序以进行时间上的训练-测试分割
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `filtered_data` dataframe
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`filtered_data` 数据框'
- en: '![](../Images/b1d25ca050a152a9e1bba81fdee26380.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b1d25ca050a152a9e1bba81fdee26380.png)'
- en: Image by the author.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: tells us that besides **user_id, movie_id** and the target **user_rating** we
    have the **user features**
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 告诉我们除了**user_id、movie_id**和目标**user_rating**之外，我们还有**用户特征**
- en: bucketized_user_age
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: bucketized_user_age
- en: user_gender
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_gender
- en: user_occupation_label
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_occupation_label
- en: user_occupation_text
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_occupation_text
- en: user_zip_code
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: user_zip_code
- en: and the **movie features**
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以及**电影特征**
- en: movie_genres
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: movie_genres
- en: movie_title
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: movie_title
- en: 'Using some stereotypes:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一些刻板印象：
- en: Intuitively, these features should help a lot since a model could learn things
    like “Women like dramas” or “Young people dislike old movies”.
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从直观上看，这些特征应该非常有帮助，因为模型可以学习“女性喜欢戏剧”或“年轻人不喜欢老电影”之类的内容。
- en: We will now find out how to use all of these additional features via a simple
    network architecture called **LightFM**. The name was chosen by [Maciej Kula](https://www.linkedin.com/in/maciej-kula-57283147/)
    in his well-written paper **Metadata Embeddings for User and Item Cold-start Recommendations**
    [1]. Please give it a read!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将了解如何通过一个简单的网络架构**LightFM**来使用所有这些额外特征。这个名字是由 [Maciej Kula](https://www.linkedin.com/in/maciej-kula-57283147/)
    在他写得很好的论文 **Metadata Embeddings for User and Item Cold-start Recommendations**
    [1] 中选择的。请阅读一下！
- en: LightFM is a hybrid of a collaborative as well as a content-based recommender
    since it uses ratings as well as user and item features.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: LightFM 是一种混合型推荐系统，因为它使用评分以及用户和项目特征。
- en: The Simple Idea of LightFM
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LightFM 的简单想法
- en: Let us first recap what our simple matrix factorization looked like, omitting
    biases. In our old recommender, we used the **user_id** and **movie_id**, embedded
    both, and computed the dot product to calculate the rating.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先回顾一下我们简单的矩阵分解是怎样的，省略偏差。在我们旧的推荐系统中，我们使用了**user_id**和**movie_id**，将两者进行嵌入，然后计算点积来计算评分。
- en: '![](../Images/8e6ee1d11d43d46b20f23f4f6241ff41.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e6ee1d11d43d46b20f23f4f6241ff41.png)'
- en: Matrix factorization architecture, image by the author.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵分解架构，图片由作者提供。
- en: 'For **LightFM**, it works like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**LightFM**，它是这样工作的：
- en: We **embed all the features** that we have, user and movie features.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们**嵌入所有特征**，包括用户特征和电影特征。
- en: The user (movie) embedding is the **sum of all these user (movie) feature embeddings**.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户（电影）嵌入是**所有这些用户（电影）特性嵌入的总和**。
- en: 'That’s it already! For some subset of features, the network architecture could
    look like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！对于某些特定的特性，网络架构可能看起来像这样：
- en: '![](../Images/1026153ed5733b5d7693965251cdd499.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1026153ed5733b5d7693965251cdd499.png)'
- en: LightFM architecture, image by the author.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: LightFM 架构，图片由作者提供。
- en: Advantages
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优势
- en: The good thing about this approach is that even if you get a new user or movie
    into the database, you can create meaningful embeddings as long as you know their
    features (*contents*). You will not know the embeddings for the IDs — the main
    problem in the matrix factorization approach — but we hope that the other embeddings
    make up for it. In a cold start setting, **user_id** or **movie_id** are unknown,
    but we can still give them some default embedding.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法的好处是，即使你将新用户或电影添加到数据库中，只要知道它们的特性（*内容*），你也可以创建有意义的嵌入。你不会知道 ID 的嵌入——这是矩阵分解方法中的主要问题——但我们希望其他嵌入可以弥补这一点。在冷启动设置中，**user_id**
    或 **movie_id** 是未知的，但我们仍然可以给它们一些默认的嵌入。
- en: Implementation in TensorFlow
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中的实现
- en: With only the two IDs as input, it is sufficient to explicitly type out an input,
    encoding, embedding, and bias. However, for our number of features, it makes sense
    to define some config first and then use loops.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 仅用两个 ID 作为输入，明确指定输入、编码、嵌入和偏差就足够了。然而，对于我们的特性数量，先定义一些配置然后使用循环是有意义的。
- en: '***Note:*** *We will omit* ***movie_title*** *and* ***movie_genres*** *since
    we have to treat them differently than the rest. However, I will tell you things
    you can do to incorporate these features as well.*'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***注意：*** *我们将省略* ***movie_title*** *和* ***movie_genres*** *，因为我们必须以不同于其他特性的方式处理它们。然而，我会告诉你如何将这些特性也纳入其中。*'
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We now have an extensive configuration dictionary that tells us about each feature
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个详细的配置字典，它告诉我们每个特性的信息。
- en: which input *dtype* the input layer needs,
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入层需要的*dtype*，
- en: if the features belong to the movie or user features,
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特性是否属于电影或用户特性，
- en: which lookup layer is needed, i.e. `IntegerLookup` for integer features and
    `StringLookup` for string features,
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要哪个查找层，即`IntegerLookup`用于整数特性，`StringLookup`用于字符串特性，
- en: and the vocabulary, i.e., the unique classes per feature.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及词汇表，即每个特性的唯一类。
- en: 'Then, we can define a TensorFlow model that does what we have seen in the LightFM
    architecture image:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以定义一个 TensorFlow 模型来实现我们在 LightFM 架构图中看到的内容：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I know this is quite hefty. But there should be no big surprises if you also
    read my other article about embedding-based recommenders. We are ready to train
    the model!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道这很繁重。但如果你也阅读了我关于基于嵌入的推荐系统的其他文章，应该没有大惊小怪的地方。我们准备好训练模型了！
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The performance on the test set:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集上的表现：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can also try out the matrix factorization in this setting; you only have
    to change the `features_config` dictionary to
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以尝试在这种设置中进行矩阵分解；你只需将`features_config`字典更改为
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: by deleting some rows and then executing the rest of the code. The results,
    in this case, are a test MSE of 1.322 and an MAE of 0.953, which is much worse
    than the LightFM results. This looks great!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过删除一些行，然后执行剩余的代码。在这种情况下，结果是测试 MSE 为 1.322 和 MAE 为 0.953，这比 LightFM 结果差得多。这看起来很棒！
- en: Dealing With The Movie Genre
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理电影类型
- en: So far, we have ignored the perhaps extremely informative column **movie_genres**
    because it is a bit harder to handle than the categorical variables since here
    we have a list of integers instead of just one integer. So, we have to make up
    some logic to deal with this.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们忽略了可能极具信息量的列**movie_genres**，因为它比分类变量更难处理，因为这里我们有一个整数列表而不是单个整数。所以，我们必须制定一些逻辑来处理这个问题。
- en: '![](../Images/c13e6726a3bb9b84eab7d7aa1cf3504c.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c13e6726a3bb9b84eab7d7aa1cf3504c.png)'
- en: Image by the author.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: The easiest thing to do with this is to make an embedding for each genre and
    then take the mean of them. You can use the `GlobalAveragePooling1D` layer for
    this.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 处理这个最简单的方法是为每个类型创建一个嵌入，然后取它们的均值。你可以使用`GlobalAveragePooling1D`层来实现这一点。
- en: 'In order to realize this idea in code, do the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在代码中实现这个想法，请执行以下操作：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The rest stays the same. You only have to add the feature **movie_genres** to
    the model during fit, evaluation, and testing as well. The shape of the genres
    is a bit difficult since the lists don’t have the same length, so TensorFlow has
    trouble turning this into a regular tensor. Luckily, TensorFlow still got us covered
    by providing **ragged tensors** via `tf.ragged.constant` that can handle these
    variable-size tensors.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 其余部分保持不变。在拟合、评估和测试模型时，你只需将特征**movie_genres**添加到模型中。由于类型的形状有点困难，因为列表的长度不同，所以TensorFlow在将其转换为常规张量时遇到问题。幸运的是，TensorFlow通过提供**ragged
    tensors**（通过`tf.ragged.constant`）来处理这些可变大小的张量。
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Fitting and evaluating the model on the test set shows yet another improvement,
    although smaller than expected. The MSE is about 1.0, and MAE is about 0.807.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试集上拟合和评估模型显示了另一个改进，尽管小于预期。MSE约为1.0，MAE约为0.807。
- en: '![](../Images/60f1b2ab0d69716a5356a9344c469ac5.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60f1b2ab0d69716a5356a9344c469ac5.png)'
- en: All of my results combined. Image by the author.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 所有结果的综合。图片由作者提供。
- en: Dealing with the Movie Title
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理电影标题
- en: Another interesting feature we have ignored so far since it contains information
    about the movie franchise. With this information, we could make it easy for the
    model to learn that some users like all the Batman movies a lot, for example.
    *Coding this is homework for you, though.* One way to do this is to split the
    title strings into a list of words and then proceed as we did with the genres.
    You can even use sentence encoders, transformer-like architecture, LSTMs, or anything
    else to turn a text into an embedding.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的特征是我们迄今为止忽略的，因为它包含关于电影系列的信息。有了这些信息，我们可以使模型更容易学习一些用户非常喜欢所有的蝙蝠侠电影。例如，*编码这个是你的作业*。一种方法是将标题字符串分割成单词列表，然后按照我们对待类型的方法进行处理。你甚至可以使用句子编码器、类似变换器的架构、LSTM或其他任何方法将文本转换为嵌入。
- en: Making Predictions
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进行预测
- en: 'You can make a prediction by providing all the necessary features like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过提供所有必要的特征来进行预测，方法如下：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, you can see that some unknown user who is young, has gender 0, occupation
    label 12, living in the 65712 zip code area, and is a writer would probably like
    the movie with id 1 that belongs to the genres 1, 2, and 3.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到一个年轻的未知用户，该用户性别为0，职业标签为12，居住在65712邮政编码区域，且是一名作家，他可能会喜欢ID为1的电影，该电影属于1、2和3这些类型。
- en: More Interesting Insights From The Paper
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来自论文的更多有趣见解
- en: My small experiment showed that LightFM could increase the model performance,
    as also stated in [1]. This is great, although something you might have expected
    already since **LightFM is a generalized version of matrix factorization**.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我的一个小实验表明，LightFM可以提高模型性能，正如[1]中所述。这很棒，尽管这可能是你已经预料到的，因为**LightFM是矩阵分解的一个推广版本**。
- en: 'In this regard, the paper author writes the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，论文作者写道：
- en: “In both cold-start and low-density scenarios, LightFM performs at least as
    well as pure content-based models, substantially outperforming them when either
    (1) collaborative information is available in the training set or (2) user features
    are included in the model.”
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “在冷启动和低密度场景下，LightFM的表现至少与纯内容模型一样好，当（1）训练集中有协同信息或（2）模型中包含用户特征时，它的表现会大幅超越这些模型。”
- en: “When collaborative data is abundant (warm-start, dense user-item matrix), LightFM
    performs at least as well as the MF model.”
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “当协同数据丰富（热启动，密集的用户-项目矩阵）时，LightFM的表现至少与MF模型一样好。”
- en: “Embeddings produced by LightFM encode important semantic information about
    features and can be used for related recommendation tasks such as tag recommendations.”
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “LightFM生成的嵌入编码了关于特征的重要语义信息，可用于相关的推荐任务，如标签推荐。”
- en: 'There is no proof of these statements, but he reached this conclusion by testing
    it on two datasets. Both datasets have **binary labels,** though, meaning that
    either the item was useful for the user or not. With binary labels, he chose the
    AUC as his evaluation metric and summarized his findings in this table:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这些陈述没有证明，但他通过在两个数据集上测试得出了这个结论。这两个数据集都有**二进制标签，** 意味着该项目对用户有用或无用。对于二进制标签，他选择了AUC作为评估指标，并在此表格中总结了他的发现：
- en: '![](../Images/c105fc4e74e6fa3f59a2c3392a8dfa3c.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c105fc4e74e6fa3f59a2c3392a8dfa3c.png)'
- en: From the paper, MF = Matrix Factorization. Higher numbers are better.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中，MF = 矩阵分解。数字越高越好。
- en: Here, we can also see that LightFM outperforms the other methods in the cold
    start and even the warm start setting. It is good to see that LightFM is not worse
    than MF in the warm start setting, but the main selling point is that **LightFM
    completely destroys MF in the cold setting**.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们还可以看到 LightFM 在冷启动甚至热启动设置中超越了其他方法。很高兴看到 LightFM 在热启动设置中不比 MF 差，但主要的卖点是**LightFM
    在冷启动设置中完全击败了 MF**。
- en: '***Remember:*** *An AUC of 0.5 means random guessing in the sense that the
    probability that a randomly picked* ***relevant item*** *for some user* ***scores
    higher******than a*** *randomly chosen* ***non-relevant item*** *for this user
    is* ***50%****.*'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***记住：*** *AUC 为 0.5 意味着随机猜测，即某用户随机挑选的* ***相关项目*** *的评分高于该用户的* ***随机选择的非相关项目***
    *的概率为* ***50%****。*'
- en: Conclusion
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we have discussed how purely collaborative recommender systems,
    such as matrix factorization, have trouble when seeing new users or items, referred
    to as the cold start problem.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们讨论了纯协同推荐系统（例如矩阵分解）在面对新用户或新项目时遇到的问题，这被称为冷启动问题。
- en: We can mitigate this problem once we have more information about users and items
    since the model can learn some general patterns, such as that young people dislike
    old movies. So, if we have a new user and know they are young, a good model should
    score older movies lower than newer ones.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得更多关于用户和项目的信息，我们可以缓解这个问题，因为模型可以学习一些一般性的模式，例如年轻人不喜欢老电影。因此，如果我们有一个新用户，并且知道他们年轻，好的模型应该将老电影的评分低于新电影。
- en: Still, if this new user keeps rating movies, the model can adjust and learn
    to display old movies like [Nosferatu](https://en.wikipedia.org/wiki/Nosferatu)
    if the user’s behavior indicates that this might be a good fit.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，如果这个新用户继续评分，模型可以调整并学会显示像 [诺斯费拉图](https://en.wikipedia.org/wiki/Nosferatu)
    这样的老电影，如果用户的行为表明这可能是一个合适的选择。
- en: 'A model with these desirable properties feels a bit *Bayesian* to me:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 具有这些理想特性的模型对我来说感觉有点*贝叶斯*：
- en: The user and item feature embeddings serve as a kind of prior that has a great
    influence on the predictions as long as we don’t have interaction data. As interactions
    come in, this prior gets changed.
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 用户和项目特征嵌入作为一种先验，对预测具有很大的影响，只要我们没有互动数据。随着互动数据的到来，这种先验会发生变化。
- en: However, it is an interesting question whether the user and item features lose
    their relevance once we have a **dense rating matrix**, e.g., if each user rated
    95% of all movies.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一个有趣的问题是，一旦我们拥有**密集评分矩阵**，例如每个用户评分了95%的所有电影，用户和项目特征是否失去相关性。
- en: Anyway, LightFM is a good candidate for such a model, as indicated by my and
    the paper author’s experiments. LightFM beats MF, especially in the cold start
    setting on our selected datasets. If the cold start is not an issue, the improvements
    are minor and might even be just statistical noise.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 不管怎样，LightFM 是一个很好的候选模型，这一点从我和论文作者的实验中可以看出。LightFM 在我们的选定数据集上表现优于 MF，特别是在冷启动设置中。如果冷启动不是问题，改进是微小的，甚至可能只是统计噪声。
- en: '**You can also try the paper** [**author’s implementation of LightFM**](https://github.com/lyst/lightfm)**.**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**你也可以尝试论文** [**作者对 LightFM 的实现**](https://github.com/lyst/lightfm)**。**'
- en: References
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] M. Kula, [Metadata Embeddings for User and Item Cold-start Recommendations](https://arxiv.org/abs/1507.08439)
    (2015), arXiv preprint arXiv:1507.08439'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] M. Kula, [用户和项目冷启动推荐的元数据嵌入](https://arxiv.org/abs/1507.08439) (2015)，arXiv
    预印本 arXiv:1507.08439'
- en: I hope that you learned something new, interesting, and useful today. Thanks
    for reading!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你今天学到了一些新的、有趣的和有用的东西。感谢阅读！
- en: '*If you have any questions, write me on* [*LinkedIn*](https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/)*!*'
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如果你有任何问题，可以在* [*LinkedIn*](https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/)*上联系我！*'
- en: And if you want to dive deeper into the world of algorithms, give my new publication
    **All About Algorithms** a try! I’m still searching for writers!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想深入了解算法的世界，可以尝试我的新出版物**关于算法的一切**！我仍在寻找作者！
- en: '[](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## All About Algorithms'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
    [## 关于算法的一切'
- en: From intuitive explanations to in-depth analysis, algorithms come to life with
    examples, code, and awesome…
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从直观解释到深入分析，算法通过示例、代码和精彩的方式展现出活力……
- en: medium.com](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/all-about-algorithms?source=post_page-----69bf2f0f0b9b--------------------------------)
