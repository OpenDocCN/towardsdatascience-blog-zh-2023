- en: A Cornerstone of RL — TD(λ) and 3 Big Names
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习的基石——TD(λ) 与 3 个大名鼎鼎的人物
- en: 原文：[https://towardsdatascience.com/a-cornerstone-of-rl-td-%CE%BB-and-3-big-names-2e547b37c05?source=collection_archive---------8-----------------------#2023-09-14](https://towardsdatascience.com/a-cornerstone-of-rl-td-%CE%BB-and-3-big-names-2e547b37c05?source=collection_archive---------8-----------------------#2023-09-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-cornerstone-of-rl-td-%CE%BB-and-3-big-names-2e547b37c05?source=collection_archive---------8-----------------------#2023-09-14](https://towardsdatascience.com/a-cornerstone-of-rl-td-%CE%BB-and-3-big-names-2e547b37c05?source=collection_archive---------8-----------------------#2023-09-14)
- en: How Monte Carlo, SARSA, and Q-learning can be derived from TD(λ)
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何从 TD(λ) 推导 Monte Carlo、SARSA 和 Q-learning
- en: '[](https://medium.com/@byjameskoh?source=post_page-----2e547b37c05--------------------------------)[![James
    Koh, PhD](../Images/8e7af8b567cdcf24805754801683b426.png)](https://medium.com/@byjameskoh?source=post_page-----2e547b37c05--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2e547b37c05--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2e547b37c05--------------------------------)
    [James Koh, PhD](https://medium.com/@byjameskoh?source=post_page-----2e547b37c05--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@byjameskoh?source=post_page-----2e547b37c05--------------------------------)[![James
    Koh, PhD](../Images/8e7af8b567cdcf24805754801683b426.png)](https://medium.com/@byjameskoh?source=post_page-----2e547b37c05--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2e547b37c05--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2e547b37c05--------------------------------)
    [James Koh, PhD](https://medium.com/@byjameskoh?source=post_page-----2e547b37c05--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F780706b02d58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-cornerstone-of-rl-td-%CE%BB-and-3-big-names-2e547b37c05&user=James+Koh%2C+PhD&userId=780706b02d58&source=post_page-780706b02d58----2e547b37c05---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2e547b37c05--------------------------------)
    ·13 min read·Sep 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e547b37c05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-cornerstone-of-rl-td-%25CE%25BB-and-3-big-names-2e547b37c05&user=James+Koh%2C+PhD&userId=780706b02d58&source=-----2e547b37c05---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F780706b02d58&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-cornerstone-of-rl-td-%CE%BB-and-3-big-names-2e547b37c05&user=James+Koh%2C+PhD&userId=780706b02d58&source=post_page-780706b02d58----2e547b37c05---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2e547b37c05--------------------------------)
    · 13 分钟阅读 · 2023 年 9 月 14 日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2e547b37c05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-cornerstone-of-rl-td-%25CE%25BB-and-3-big-names-2e547b37c05&user=James+Koh%2C+PhD&userId=780706b02d58&source=-----2e547b37c05---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e547b37c05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-cornerstone-of-rl-td-%25CE%25BB-and-3-big-names-2e547b37c05&source=-----2e547b37c05---------------------bookmark_footer-----------)![](../Images/e98fb2371203cb541956d91ac9f47d66.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2e547b37c05&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-cornerstone-of-rl-td-%25CE%25BB-and-3-big-names-2e547b37c05&source=-----2e547b37c05---------------------bookmark_footer-----------)![](../Images/e98fb2371203cb541956d91ac9f47d66.png)'
- en: Photo by [Loïc Barré](https://unsplash.com/@loicbarre?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Loïc Barré](https://unsplash.com/@loicbarre?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Fundamentals are most important. Before diving into modern algorithms in Reinforcement
    Learning (RL), it is vital to grasp the foundational principles upon which they
    are built.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基础知识是最重要的。在深入了解强化学习（RL）中的现代算法之前，掌握它们所基于的基础原则至关重要。
- en: In the realm of RL, this means we must appreciate the concept of Temporal Difference
    (TD) learning, which generalizes to TD(λ). Using a *single* codebase with just
    a few lines, I will show how a generalized form of a classic RL problem can be
    solved via
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在强化学习（RL）领域，这意味着我们必须理解时间差分（TD）学习的概念，它可以推广到 TD(λ)。使用一个*单一*的代码库和几行代码，我将展示如何通过
- en: Monte Carlo,
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Monte Carlo，
- en: SARSA,
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SARSA，
- en: Q-learning, and
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Q-learning 和
- en: TD(λ) with 0 < λ < 1.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 0 < λ < 1 的 TD(λ)。
- en: The results are presented as gifs, using utility functions that you can easily
    reuse. As a teaser, you will be able to generate the following yourself by the
    end of this article!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 结果以 gif 的形式呈现，使用了可以轻松重用的工具函数。作为预告，你将在本文结束时能够自己生成以下内容！
- en: Our agent (represented by a smiley face 😃) starts at the blue grid, and tries
    to reach the yellow grid. The red grid lead to a severe negative reward and terminates
    the…
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的代理（由一个笑脸 😃 表示）从蓝色网格开始，尝试到达黄色网格。红色网格会导致严重的负奖励并终止…
