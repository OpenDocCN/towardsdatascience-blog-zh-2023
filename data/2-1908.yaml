- en: Stacking Time Series Models to Improve Accuracy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 堆叠时间序列模型以提高准确性
- en: 原文：[https://towardsdatascience.com/stacking-time-series-models-to-improve-accuracy-7977c6667d29](https://towardsdatascience.com/stacking-time-series-models-to-improve-accuracy-7977c6667d29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/stacking-time-series-models-to-improve-accuracy-7977c6667d29](https://towardsdatascience.com/stacking-time-series-models-to-improve-accuracy-7977c6667d29)
- en: Extracting signals from RNN, ARIMA, and Prophet models to forecast with Catboost
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从RNN、ARIMA和Prophet模型中提取信号，以便用Catboost进行预测
- en: '[](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)[![Michael
    Keith](../Images/4ebd39b25a1faae3586eb25ec83d3e91.png)](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------)
    [Michael Keith](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)[![Michael
    Keith](../Images/4ebd39b25a1faae3586eb25ec83d3e91.png)](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------)
    [Michael Keith](https://mikekeith52.medium.com/?source=post_page-----7977c6667d29--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------)
    ·7 min read·Feb 28, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----7977c6667d29--------------------------------)
    ·阅读时长7分钟·2023年2月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/d4a54a6899fe0dff94fe8914297c3a54.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4a54a6899fe0dff94fe8914297c3a54.png)'
- en: Photo by [Robert Sachowski](https://unsplash.com/@rsachowski?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Robert Sachowski](https://unsplash.com/@rsachowski?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上。
- en: Research around powerful time series models is robust. There are many options
    available, far beyond the classical techniques like ARIMA. Lately, recurrent neural
    networks and LSTMs have reached the top of many researchers’ interests. Going
    by the number of downloads listed on [PePy](https://pepy.tech/project/prophet),
    the Prophet model is probably the most widely used model by time series forecasters,
    due to its low barrier of entry. Which of these options is best for your series?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 关于强大的时间序列模型的研究非常丰富。可供选择的选项很多，远远超出了传统的ARIMA技术。最近，递归神经网络和LSTM模型已成为许多研究人员关注的重点。根据[PePy](https://pepy.tech/project/prophet)上列出的下载数量，Prophet模型可能是时间序列预测者使用最广泛的模型，因为它的入门门槛较低。对于你的时间序列来说，哪种选项最合适呢？
- en: Maybe the answer is that you should try all of them and combine their various
    strengths. A common technique to do this is known as stacking. The popular machine
    learning library, scikit-learn, offers a [StackingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html)
    that can be employed for time series tasks. I have [previously demonstrated how
    to use it](https://medium.com/towards-data-science/expand-your-time-series-arsenal-with-these-models-10c807d37558)
    for just such a case.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 也许答案是你应该尝试所有这些模型，并结合它们的各种优点。一个常见的技术是堆叠。流行的机器学习库scikit-learn提供了一个[StackingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html)，可以用于时间序列任务。我[之前演示了如何使用它](https://medium.com/towards-data-science/expand-your-time-series-arsenal-with-these-models-10c807d37558)来处理这种情况。
- en: 'There is a limitation to the StackingRegressor, however; it only accepts other
    scikit-learn model classes and APIs. So, a model like ARIMA, which is unavailable
    in scikit-learn, or deep networks from tensorflow, becomes unavailable to place
    in the stack. There is a solution. In this post, I will show how to extend stacking
    methods for time series using the [scalecast](https://github.com/mikekeith52/scalecast)
    package and a Jupyter [notebook](https://scalecast-examples.readthedocs.io/en/latest/misc/stacking/custom_stacking.html).
    The dataset used is available [open access](https://github.com/Mcompetitions/M4-methods/issues/16)
    on GitHub. The following requirements are needed:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，StackingRegressor 有一个限制；它只接受其他 scikit-learn 模型类和 API。因此，像 ARIMA 这样的模型（在 scikit-learn
    中不可用）或来自 tensorflow 的深度网络将无法放入堆栈中。这里有一个解决方案。在这篇文章中，我将展示如何使用 [scalecast](https://github.com/mikekeith52/scalecast)
    包和一个 Jupyter [notebook](https://scalecast-examples.readthedocs.io/en/latest/misc/stacking/custom_stacking.html)
    扩展时间序列的堆叠方法。使用的数据集可以在 GitHub 上 [open access](https://github.com/Mcompetitions/M4-methods/issues/16)
    获取。需要以下要求：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Dataset Overview
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集概述
- en: 'The dataset is hourly and split into a train set (700 observations) and test
    set (48 observations). My notebook uses the H1 series, but modifying it to utilize
    any of the hourly series from the M4 dataset is straightforward. This is how to
    read the data and store it in a `Forecaster` object:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集是按小时划分的，分为训练集（700 个观测值）和测试集（48 个观测值）。我的 notebook 使用了 H1 系列，但修改为利用 M4 数据集中任何一个小时序列是很直接的。这是如何读取数据并将其存储在
    `Forecaster` 对象中的：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is a plot of the series:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该序列的图表：
- en: '![](../Images/f401c9799631034696a0527e7bcc829b.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f401c9799631034696a0527e7bcc829b.png)'
- en: Image by author
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Applied Models
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用模型
- en: Before we start staking models, we need to generate predictions from them. I
    chose to use a Naive model as a benchmark against ARIMA, LSTM, and Prophet models.
    In the subsequent sections, I go through why I made each selection, but other
    decisions could be made that are just as interesting or even more so.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始堆叠模型之前，我们需要从它们生成预测。我选择使用简单模型作为 ARIMA、LSTM 和 Prophet 模型的基准。在接下来的部分中，我将解释为什么做出每个选择，但也可以做出其他决策，这些决策同样有趣，甚至更具吸引力。
- en: Naive Benchmark
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 简单基准测试
- en: To benchmark all models, we can call a seasonal naive estimation, which propagates
    the last 24 observed values in any given hourly series forward. In scalecast,
    this is done pretty easily.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对所有模型进行基准测试，我们可以调用季节性简单估计方法，该方法将给定小时序列中的最后24个观测值向前传播。在 scalecast 中，这非常简单。
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ARIMA
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ARIMA
- en: Autoregressive Integrated Moving Average is a popular and simple time series
    technique that uses a series’ lags and errors to make predictions about its future
    in a linear fashion. Through an exploratory data analysis (which you can see in
    the linked [notebook](https://scalecast-examples.readthedocs.io/en/latest/misc/stacking/custom_stacking.html)),
    I determined the series was not stationary and that it was highly seasonal. I
    ultimately chose to apply a seasonal ARIMA model of order (5,1,4) x (1,1,1,24).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归积分滑动平均是一种流行且简单的时间序列技术，它利用序列的滞后值和误差以线性方式预测未来。通过探索性数据分析（您可以在链接的 [notebook](https://scalecast-examples.readthedocs.io/en/latest/misc/stacking/custom_stacking.html)
    中看到），我确定序列不是平稳的，并且具有很强的季节性。我最终选择应用了一个季节性 ARIMA 模型，订单为 (5,1,4) x (1,1,1,24)。
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: LSTM
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LSTM
- en: 'If ARIMA is on the simpler side of time series models, [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)
    is one of the more advanced methods. It is a deep learning technique with many
    parameters, including an attention mechanism that finds long and short-term patterns
    in sequential data, which theoretically makes it an ideal choice for time series.
    It is difficult to set up this model using tensorflow, but not too bad in scalecast
    (see [this article](https://medium.com/towards-data-science/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf)).
    I applied two LSTM models: one with a Tanh activation function and one with ReLu.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 ARIMA 属于时间序列模型中的简单方法，[LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)
    是更先进的方法之一。这是一种深度学习技术，具有许多参数，包括一个注意力机制，可以在序列数据中找到长期和短期的模式，这使其理论上成为时间序列的理想选择。使用
    tensorflow 设置这个模型很困难，但在 scalecast 中并不太难（请参见 [这篇文章](https://medium.com/towards-data-science/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf)）。我应用了两个
    LSTM 模型：一个使用 Tanh 激活函数，一个使用 ReLu。
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Prophet
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prophet
- en: Despite its extreme popularity, the Prophet model has been [maligned recently](https://www.microprediction.com/blog/prophet).
    There are claims that it is underwhelming in accuracy, mainly due to how unrealistically
    it extrapolates trends and that it doesn’t consider local patterns through modeling
    autoregressively. However, it does some things uniquely. For one, it automatically
    applies holiday effects to models. It also considers several types of seasonality.
    It does this all with minimum specification needed from the user. I like the idea
    of using it as a signal, even if it is not ideal for generating point predictions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Prophet模型极受欢迎，但它最近却被[贬低](https://www.microprediction.com/blog/prophet)。有人声称它的准确性令人失望，主要是因为它对趋势的外推过于不现实，并且它没有通过自回归建模考虑局部模式。然而，它确实有一些独特之处。比如，它会自动将节假日效应应用到模型中。它还考虑了几种季节性类型。它以用户需要的最少规格完成这些功能。我喜欢将它作为一个信号使用，即使它不适合生成点预测。
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Compare Results
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较结果
- en: Now that we have predictions generated for each model, let's see how they performed
    on the validation set, which are the last 48 observations in our training set
    (this is still separate from the test set mentioned earlier).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为每个模型生成了预测结果，让我们看看它们在验证集上的表现，这些是我们训练集中的最后48个观测值（这仍然与之前提到的测试集分开）。
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/2a7e19fb3374c21513b3d8cde09abeee.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a7e19fb3374c21513b3d8cde09abeee.png)'
- en: Image by author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'The good news here is that each model out-performed the naive method. The ARIMA
    model performed the best with a percentage error of 4.7%, followed by Prophet.
    Let''s see all forecasts plotted against the validation set:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是每个模型都优于朴素方法。ARIMA模型表现最佳，百分比误差为4.7%，其次是Prophet。让我们查看所有预测与验证集的对比图：
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/16529891e70fd018f0bfc795c16964f9.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16529891e70fd018f0bfc795c16964f9.png)'
- en: Image by author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: All of these models performed reasonably on this series, without large deviations
    between any of them. Let’s stack them!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些模型在这个系列上表现得相当合理，之间没有大的偏差。让我们进行模型叠加！
- en: Stacking Models
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型叠加
- en: Every stacking model needs a final estimator, which will filter through the
    other models’ various estimates to create a new set of predictions. We will stack
    our previously explored results with a boosted tree estimator called [Catboost](https://catboost.ai).
    Catboost is a powerful procedure that we hope will flesh out the best signals
    from each of the already-applied models.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每个叠加模型都需要一个最终估计器，该估计器将筛选其他模型的各种估计值，以创建一组新的预测。我们将用一个叫做[Catboost](https://catboost.ai)的增强树估计器来叠加我们之前探索的结果。Catboost是一个强大的程序，我们希望它能从每个已经应用的模型中提取最佳信号。
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The above code adds the predictions from each of the evaluated models into
    the `Forecaster` object. It calls these predictions “signals.” They are treated
    the same as any other covariate stored in this same object. We also add the last
    48 series’ lags as additional regressors that the Catboost model can use to make
    its forecast. Let’s now call three Catboost models: 1 that uses all available
    signals and series lags, one that only uses the signals, and one that uses only
    the lags.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将每个评估模型的预测结果添加到`Forecaster`对象中。它将这些预测称为“信号”。这些信号与存储在同一对象中的其他协变量一样对待。我们还将最后48个系列的滞后添加为Catboost模型可以用来进行预测的额外回归量。现在我们将调用三个Catboost模型：一个使用所有可用的信号和系列滞后，一个仅使用信号，还有一个仅使用滞后。
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s tap into that test set we kept separate from the Forecaster object at
    the beginning of the analysis and compare the results of all applied models. This
    time, we will look at two measures: SMAPE and Mean Absolute Scaled Error (MASE).
    These are the two metrics that were used in the actual M4 competition.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们利用在分析开始时与Forecaster对象分开的测试集，比较所有应用模型的结果。这次，我们将关注两个指标：SMAPE和平均绝对尺度误差（MASE）。这两个指标在实际的M4竞赛中被使用。
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/c20085add01772635dd715cbd05d4e8d.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c20085add01772635dd715cbd05d4e8d.png)'
- en: Image by author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'By combining signals from a diverse class of models, we have generated two
    estimators that outperform the others: the Catboost model that was trained using
    all signals and 48 series lags followed by the Catboost model that just used the
    signals. These both scored an error of about 2.8% out of sample. We can see these
    two models plotted with the actuals from the test set.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合来自不同类别模型的信号，我们生成了两个优于其他模型的估计器：一个使用所有信号和48个系列滞后的Catboost模型，以及一个仅使用信号的Catboost模型。这两个模型的误差大约为2.8%。我们可以看到这两个模型与测试集中的实际数据进行对比的图示。
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/26cf88caea4e6acf646451780e2bffd3.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/26cf88caea4e6acf646451780e2bffd3.png)'
- en: Image by author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Which Signals Were Most Important?
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 哪些信号最为重要？
- en: To round out the analysis, we can use shapley scores to determine which signals
    were the most important in this stack. [Shapley scores](https://christophm.github.io/interpretable-ml-book/shapley.html)
    are considered one of the state-of-the-art methods to determine the inputs’ predictive
    power in a given machine learning model. Higher scores mean the inputs were more
    important in that particular model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完善分析，我们可以使用 Shapley 分数来确定在这个模型堆叠中哪些信号最为重要。[Shapley 分数](https://christophm.github.io/interpretable-ml-book/shapley.html)被认为是确定输入在给定机器学习模型中的预测能力的最先进方法之一。分数越高，表示这些输入在该模型中越重要。
- en: '[PRE12]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/70806022263aa125dea516fb8b33e938.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/70806022263aa125dea516fb8b33e938.png)'
- en: Image by author
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The above screenshot only shows the first-few most important predictors, but
    we can see from this that the ARIMA signal was most important, followed by the
    series’ first lag and then the Prophet signal. The RNN models also scored higher
    than many of the included lags. This can be a good starting place if we want to
    train a more parsimonious model in the future.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图仅显示了前几个最重要的预测因子，但我们可以从中看出，ARIMA 信号最为重要，其次是系列的第一个滞后项，然后是 Prophet 信号。RNN
    模型的得分也高于许多包含的滞后项。如果我们希望将来训练一个更简洁的模型，这可以是一个很好的起点。
- en: Conclusion
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this post, I demonstrated the power of stacking models in a time-series context
    and how using diverse model classes led to higher accuracy on the explored series.
    This is all made easy with the scalecast package. If you found the analysis interesting,
    please give that package a star on [GitHub](https://github.com/mikekeith52/scalecast).
    Thank you for following along!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我展示了在时间序列上下文中堆叠模型的威力，以及如何通过使用多样的模型类别提高探索系列的准确性。所有这些都通过 scalecast 包轻松实现。如果你觉得这个分析有趣，请在[GitHub](https://github.com/mikekeith52/scalecast)上给这个包一个星标。感谢你的关注！
