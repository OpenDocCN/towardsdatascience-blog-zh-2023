- en: How to Use Large Language Models (LLM) in Your Own Domains
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在自己的领域中使用大型语言模型（LLM）
- en: 原文：[https://towardsdatascience.com/how-to-use-large-language-models-llm-in-your-own-domains-b4dff2d08464](https://towardsdatascience.com/how-to-use-large-language-models-llm-in-your-own-domains-b4dff2d08464)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-use-large-language-models-llm-in-your-own-domains-b4dff2d08464](https://towardsdatascience.com/how-to-use-large-language-models-llm-in-your-own-domains-b4dff2d08464)
- en: A few canonical and research-proven techniques to adapt large language models
    to domain specific tasks and the intuition of why they are effective.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一些经典的、经过研究验证的技术，用于将大型语言模型适应于领域特定任务，以及为什么这些技术有效的直觉。
- en: '[](https://eileen-code4fun.medium.com/?source=post_page-----b4dff2d08464--------------------------------)[![Eileen
    Pangu](../Images/cbdab572af709b6e6b52cb3a078f220d.png)](https://eileen-code4fun.medium.com/?source=post_page-----b4dff2d08464--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4dff2d08464--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4dff2d08464--------------------------------)
    [Eileen Pangu](https://eileen-code4fun.medium.com/?source=post_page-----b4dff2d08464--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://eileen-code4fun.medium.com/?source=post_page-----b4dff2d08464--------------------------------)[![Eileen
    Pangu](../Images/cbdab572af709b6e6b52cb3a078f220d.png)](https://eileen-code4fun.medium.com/?source=post_page-----b4dff2d08464--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b4dff2d08464--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b4dff2d08464--------------------------------)
    [Eileen Pangu](https://eileen-code4fun.medium.com/?source=post_page-----b4dff2d08464--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4dff2d08464--------------------------------)
    ·9 min read·Mar 20, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----b4dff2d08464--------------------------------)
    ·阅读时间9分钟·2023年3月20日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/692a8d93c1ea132c6b6c0f7ed0224264.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/692a8d93c1ea132c6b6c0f7ed0224264.png)'
- en: 'Source: [https://unsplash.com/](https://unsplash.com/)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://unsplash.com/](https://unsplash.com/)
- en: Ever since being popularized by ChatGPT in late 2022, large language models
    (LLM) have attracted intense interest from the research and industry communities.
    While general chatbot is an obvious application of large language models, enterprises
    are thinking about how to integrate large language models into their business
    workflows to leverage this latest AI advance. **A fundamental premise of business
    specific integration though, is to be able to adapt the large language models
    to the bespoke business domain**, since LLMs are usually trained on open internet
    information, which contains too much noise and is not always closely relevant
    to the specific business context.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自从2022年底ChatGPT普及以来，大型语言模型（LLM）吸引了研究和工业界的极大关注。虽然通用聊天机器人是大型语言模型的明显应用，但企业们正在考虑如何将大型语言模型集成到其业务工作流程中，以利用这一最新的AI进展。**然而，业务特定集成的一个基本前提是能够将大型语言模型适应于定制的业务领域**，因为LLM通常在开放互联网信息上进行训练，这些信息包含过多噪声，并不总是与具体业务背景紧密相关。
- en: While there are many good blog posts out there already detailing large language
    models themselves, there seems to be a lack of solid introduction on how to leverage
    LLMs. In this blog post, we examine a few canonical ways of adapting LLMs to domain
    specific tasks from recent research literature. The goal is to spark some inspiration
    to actually democratize LLMs and make them accessible to the wider world.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已有许多优秀的博客文章详细介绍了大型语言模型本身，但似乎缺乏关于如何利用LLM的实质性介绍。在这篇博客文章中，我们探讨了从近期研究文献中获取的一些经典方法，将LLM适应于领域特定任务。目标是激发一些灵感，真正实现LLM的民主化，使其对更广泛的世界开放。
- en: The scenario this blog post postulates is that you somehow get hold of a general
    purpose large language model that is already pretrained. You can access all the
    parameters in the model. The model may come from open-source, commercial options,
    partnerships with other organizations (Google’s PaLM and OpenAI’s GPT-3), or train-from-scratch
    by your organization. Now you have a variety of tasks (Q&A, summarization, reasoning,
    etc) of a specific business context that you want to base on the large language
    model.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇博客文章设想的场景是，你以某种方式获得了一个已经预训练的通用大型语言模型。你可以访问模型中的所有参数。模型可能来自开源、商业选项、与其他组织的合作（如谷歌的PaLM和OpenAI的GPT-3），或由你的组织从头开始训练。现在你有一系列特定业务背景下的任务（如问答、摘要、推理等），你希望基于大型语言模型来完成这些任务。
- en: Traditional Fine-tuning
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 传统的微调
- en: The traditional method of adapting a general machine learning model to a specific
    task is to use the labeled data from the specific domain to uptrain the general
    model end-to-end. During the uptraining, parts of or all the learnable parameters
    in the model are fine-tuned via backpropagation. This type of fine-tuning is often
    undesirable with large language models. The LLMs nowadays are way too big. Some
    have hundreds of billions of parameters. The end-to-end fine-tuning not only consumes
    a huge amount of computational resources, but also requires decent size of domain
    specific labeled data, which is expensive to acquire. As the field of AI advances,
    models are likely only getting larger, making it increasingly cumbersome to always
    fine-tuning the entire model end-to-end for every single bespoke task.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 将通用机器学习模型调整到特定任务的传统方法是使用来自特定领域的标记数据来端到端地训练通用模型。在上训练过程中，模型中的部分或所有可学习参数都通过反向传播进行微调。这种类型的微调在大型语言模型中往往是不受欢迎的。如今的
    LLM 大得多，一些拥有数百亿个参数。端到端微调不仅消耗大量计算资源，而且还需要大量特定领域的标记数据，这些数据获取起来很昂贵。随着人工智能领域的进步，模型可能只会变得更大，这使得对每个单独的定制任务进行端到端的微调变得越来越繁琐。
- en: One form of end-to-end fine-tuning that is often desired, though, is instruction
    fine-tuning [1]. Large language models are often training on general text. **A
    simple analogy is that the LLM is like a person who has read tons of books (Make
    a note of this analogy. We’ll keep referring back to it subsequently to build
    out our intuition).** But he does not know what to do with all that knowledge.
    The purpose of instruction fine-tuning is to get the model into the habit of performing
    some common tasks. This is done by prefixing the input with templated instructions
    such as `“answer the following question”`, `“summarize the following document”`,
    `“compute the results of”`, `“translate this sentence”`, etc. The output is then
    the expected outcome of those instructions. Using this kind of input/output pairs
    to fine-tuning the model end-to-end will make the model more amenable to “taking
    action” on future input. Note that instruction fine-tuning does not need to be
    domain specific unless your domain requires an unusual “action”. And it’s likely
    that the pretrained large language model you have is already instruction-fine-tuned
    (such as Google’s Flan-PaLM).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，一种常常被期望的端到端微调形式是指令微调[1]。大型语言模型通常在一般文本上进行训练。**一个简单的类比是，LLM 就像一个阅读了大量书籍的人（请记住这个类比，我们会在后续继续参考它以建立我们的直觉）。**但他不知道如何利用这些知识。指令微调的目的是让模型养成执行一些常见任务的习惯。这是通过在输入前添加模板化的指令，如`“回答以下问题”`、`“总结以下文档”`、`“计算结果”`、`“翻译这句话”`等来实现的。输出则是这些指令的预期结果。使用这种输入/输出对来进行端到端的微调，将使模型更容易对未来的输入“采取行动”。请注意，指令微调不需要特定于某个领域，除非你的领域需要不寻常的“行动”。而且，你所拥有的预训练大型语言模型可能已经经过指令微调（例如
    Google 的 Flan-PaLM）。
- en: Prompting
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提示
- en: Before going into the methods of adapting LLMs to domain specific tasks, we
    need to introduce the idea of prompting, which the rest of the blog post is based
    on.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨将 LLM 调整到领域特定任务的方法之前，我们需要介绍提示的概念，剩下的博客内容基于这一概念。
- en: Prompting is how we interact with LLMs. LLMs are effectively sequence to sequence
    text generators. You can think of them as recurrent neural networks if that helps
    build the intuition though note that nowadays the start of the art LLMs are built
    on Transformer, more specifically, the decoder part of Transformer, which is not
    RNN. Prompt is the input sequence to the model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是我们与 LLM 互动的方式。LLM 实际上是序列到序列的文本生成器。如果这有助于建立直觉，你可以将它们视为递归神经网络，但请注意，如今最先进的 LLM
    是基于 Transformer，特别是 Transformer 的解码器部分，这不是 RNN。提示是输入序列到模型中。
- en: Going back to our “knowledgeable person” analogy above, prompting is the act
    of asking the person questions. Obviously, to get useful answers, your questions
    need to be good. There are some resources online about how to ask clear and specific
    questions to elicit a good answer from LLMs. Those are useful tips, but they are
    not the type of fine-tuning prompts we’ll cover in this blog post.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们上面的“知识渊博的人”类比，提示就是向这个人提问的行为。显然，为了获得有用的答案，你的问题需要足够好。网上有一些资源关于如何提出清晰和具体的问题以从
    LLM 中获得良好的答案。这些是有用的技巧，但它们不是我们在这篇博客中将要讨论的微调提示类型。
- en: Come to think of it, why does “prompting” work? Because the model is trained
    to condition its output on the input sequence. In the case of LLMs trained on
    the open internet, all the human “knowledge” is packed inside the model and reincarnated
    as numbers. Prompting is to set up the mathematical conditions so that an appropriate
    output can be constructed. The best mathematical conditions may not be in the
    traditional sense of “being clear and specific”, albeit that’s nonetheless a good
    general rule. And most importantly, as you may have guessed it, **those mathematical
    conditions are domain specific and they are what you should focus on tuning to
    adapt the LLM to your domain.** The model parameters themselves, however, stay
    unchanged. Using our “knowledgeable person” analogy again, the person is knowledgeable
    already. So no need to change him. In fact, since he has acquired all the human
    knowledge, he already possesses the latent knowledge of your domain as your domain
    is ultimately built on human knowledge.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 想一想，为什么“提示”有效？因为模型被训练以使其输出基于输入序列。在训练于开放互联网的LLMs的情况下，所有的人类“知识”都被打包在模型中，并以数字形式重生。提示是为了设定数学条件，以便可以构建出适当的输出。最佳的数学条件可能不在传统意义上的“清晰和具体”，尽管这仍然是一个很好的通用规则。而且最重要的是，正如你可能猜到的，**这些数学条件是特定于领域的，你应该专注于调整这些条件以使LLM适应你的领域。**
    模型参数本身保持不变。再用我们的“知识丰富的人”类比，他已经是知识丰富的，所以不需要改变他。事实上，由于他已经掌握了所有人类知识，他已经具备了你领域的潜在知识，因为你的领域最终建立在人的知识之上。
- en: The Art and Science of Prompting
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提示的艺术与科学
- en: So how should we prompt the model in a way that fine-tunes it to the specific
    business domain? The following are a few canonical ways.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们应该如何提示模型以便将其微调到特定的业务领域呢？以下是几种经典的方法。
- en: '**Few-shot Exemplars**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**少样本示例**'
- en: The simplest and yet very effective way is to provide a few examples as prompts.
    The academic term is few-shot learning by exemplars [2]. To illustrate with a
    simple example, let’s say the task you want to perform is arithmetic calculation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单而又非常有效的方法是提供一些示例作为提示。学术术语是通过示例进行的少样本学习[2]。为了简单说明，假设你想执行的任务是算术计算。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now if you just feed the above input to LLM, you probably won’t get the correct
    result. Because the “knowledgeable person”, though possesses the ability to do
    arithmetics, does not know that he is asked to do arithmetics. So what you need
    to do is to encode a few examples of what you want from LLM all in the input.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你只将上述输入提供给LLM，你可能不会得到正确的结果。因为“知识丰富的人”虽然具备算术能力，但并不知道他被要求做算术。因此，你需要在输入中编码一些你想从LLM获得的示例。
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The final output is just answering the last question in the input. However,
    LLMs can condition on the prior text in the input to get a hint of “what to do”.
    Obviously, the final interface of your task is just accepting the real question
    from users. The examples are prepended to the user question behind the scene.
    You’ll then need to experiment a bit to find a few reasonably good examples to
    use as prefix of the model input.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的输出只是回答输入中的最后一个问题。然而，LLMs可以根据输入中的前文来获取“做什么”的提示。显然，你任务的最终界面只是接受用户的实际问题。示例在幕后被添加到用户问题之前。你需要进行一些实验，以找到几个相对好的示例，作为模型输入的前缀。
- en: '**Chain-of-Thoughts**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**链式思维**'
- en: 'Building on the few-shot exemplars above, we want to tell the LLMs not only
    “what to do” but also “how to do it”. This can be achieved via chain-of-thoughts
    prompting. The intuition is that if the “knowledgeable person” sees a few examples
    of how to do the task, he will mimic the “reasoning” as well. So the above arithmetics
    scenario becomes:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上述少样本示例，我们不仅想告诉LLMs“做什么”，还想告诉他们“如何做”。这可以通过链式思维提示来实现。直觉是，如果“知识丰富的人”看到几个如何做任务的示例，他也会模仿“推理”过程。所以上述算术场景变成了：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Research [2] has shown that chain-of-thoughts prompting significantly boost
    the performance of LLMs. And you get to pick whether you want to surface the reasoning
    part — `“Starting with 2 apples, then add 3, the result is 5”` — to end users.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 研究[2]表明，链式思维提示显著提高了LLMs的性能。你可以选择是否要将推理部分展示给最终用户——`“从2个苹果开始，然后加上3，结果是5”`。
- en: To further improve the results of chain-of-thoughts, recognize that there are
    usually multiple reasoning paths to the same result. Humans can solve a problem
    in multiple ways, and if multiple solutions lead to the same result, we have better
    confidence on the result. This intuition can again be incorporated. LLMs are probabilistic
    models. The output is sampled each time. So if you run it multiple times, the
    output may be different. What we are interested in is the outputs where the reasonings
    are different while the final answers are the same. This models the human thought
    process of deliberately solving the problems in multiple ways and gaining confidence
    from the “self-consistency” [3] of the output.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步改善思维链的结果，认识到通常有多条推理路径可以达到相同结果。人类可以以多种方式解决问题，如果多个解决方案得出相同结果，我们对结果的信心会更强。这种直觉可以再次被融入。LLMs（大规模语言模型）是概率模型。每次输出都是从样本中生成的。因此，如果你运行多次，输出可能会不同。我们感兴趣的是那些推理不同但最终答案相同的输出。这模拟了人类通过多种方式故意解决问题并从输出的“自我一致性”[3]中获得信心的思维过程。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Simply put, the final result with the largest number of distinct reasonings
    wins. `Output1` and `output3` above nail the final correct answer `5`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，最终结果中拥有最多不同推理方式的选项胜出。上面的`Output1`和`output3`准确地得出了最终正确答案`5`。
- en: '**Learnable Prompts**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**可学习的提示**'
- en: The above methods only use a few examples from your domain specific labeled
    dataset. But if you have more data, you naturally want to make good use of them.
    The other question you should ask is how can you be sure that the examples you
    pick are mathematically the best. This is where learnable prompts come in.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法仅使用了来自你领域特定标记数据集的一些示例。但如果你有更多数据，你自然会希望充分利用它们。你还应该问的另一个问题是如何确保你选择的示例在数学上是最优的。这就是可学习提示发挥作用的地方。
- en: The key insight is that the prefix in your input does not have to come from
    a fixed vocabulary. At the end of the day, each token in the input is transformed
    into an embedding before feeding to the model. An embedding is just a vector of
    numbers. And the best numbers can be learned.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 关键洞察是输入中的前缀不必来自固定的词汇。归根结底，每个输入标记在馈入模型之前都会被转化为嵌入。嵌入只是一个数字向量。最佳的数字是可以学习的。
- en: What you’ll do is to have a set of prefix tokens before the real input. Those
    prefix tokens can be initialized by sampling words from your domain specific vocabulary.
    The embeddings of those prefix tokens will then be updated via backpropagation.
    The model parameters themselves are still frozen. But the gradients are propagated
    from the expected-vs-actual output delta, via the model parameters, all the way
    to the input layer where those prefix token embeddedings are updated. After running
    the training over your domain specific labeled dataset, those learned token embeddings
    become your fixed input prefix at inference time. In a sense, this is a kind of
    soft prompt where the input prefix is no longer constrained to be drawn empirically
    from a fixed vocabulary. Rather, they are optimized mathematically for your domain.
    This is called prompt tuning [4] (Figure-1).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做的是在真实输入之前有一组前缀标记。这些前缀标记可以通过从你领域特定词汇中采样词语来初始化。然后，通过反向传播更新这些前缀标记的嵌入。模型参数本身仍然是冻结的。但梯度从预期与实际输出的差异开始，通过模型参数，一直到输入层，更新那些前缀标记的嵌入。经过在你领域特定标记数据集上的训练，这些学习到的标记嵌入就成为推理时的固定输入前缀。从某种意义上说，这是一种软提示，其中输入前缀不再受限于从固定词汇中经验性地提取。相反，它们是为你的领域在数学上优化的。这被称为提示调优[4]（图-1）。
- en: '![](../Images/025102b3ab513b772765307170caaabd.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/025102b3ab513b772765307170caaabd.png)'
- en: 'Figure-1 Prompt Tuning: trainable prefix is concatenated with domain specific
    input to form the model input. The gradients are propagated from output layer
    via model parameters to the input layer to update the trainable prefix. The rest
    of the parameters in this whole architecture stay unchanged.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图-1 提示调优：可训练前缀与领域特定输入连接形成模型输入。梯度从输出层通过模型参数传播到输入层，以更新可训练前缀。在整个架构中，其余参数保持不变。
- en: Epilogue
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 结语
- en: This blog post provides an intuitive explanation of the common and effective
    fine-tuning mechanisms that you can employ to adapt large language models (LLMs)
    to your domain specific tasks in a data-efficient and compute-efficient way. This
    is a rapidly changing field. New research results are coming out at a dazzling
    pace. But hopefully this blog post provides some solid ground for you to get started
    with making use of LLMs.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇博客文章提供了对常见且有效的微调机制的直观解释，这些机制可以帮助你以数据高效和计算高效的方式将大型语言模型（LLMs）适配到你特定领域的任务中。这是一个快速变化的领域，新研究成果以令人眼花缭乱的速度不断出现。希望这篇博客文章为你开始利用LLMs提供了坚实的基础。
- en: References
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Scaling instruction-finetuned language models [https://arxiv.org/abs/2210.11416](https://arxiv.org/abs/2210.11416)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 扩展指令微调语言模型 [https://arxiv.org/abs/2210.11416](https://arxiv.org/abs/2210.11416)'
- en: '[2] Language Models are Few-Shot Learners [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] 语言模型是少样本学习者 [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
- en: '[3] Self-Consistency Improves Chain of Thought Reasoning in Language Models
    [https://arxiv.org/abs/2203.11171](https://arxiv.org/abs/2203.11171)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] 自一致性改善了语言模型中的链式思维推理 [https://arxiv.org/abs/2203.11171](https://arxiv.org/abs/2203.11171)'
- en: '[4] The Power of Scale for Parameter-Efficient Prompt Tuning [https://arxiv.org/abs/2104.08691](https://arxiv.org/abs/2104.08691)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] 参数高效提示调优的规模效应 [https://arxiv.org/abs/2104.08691](https://arxiv.org/abs/2104.08691)'
