- en: Measuring The Speed of New Pandas 2.0 Against Polars and Datatable — Still Not
    Good Enough
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量新 Pandas 2.0 相对于 Polars 和 Datatable 的速度——仍然不够好
- en: 原文：[https://towardsdatascience.com/measuring-the-speed-of-new-pandas-2-0-against-polars-and-datatable-still-not-good-enough-e44dc78f6585](https://towardsdatascience.com/measuring-the-speed-of-new-pandas-2-0-against-polars-and-datatable-still-not-good-enough-e44dc78f6585)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/measuring-the-speed-of-new-pandas-2-0-against-polars-and-datatable-still-not-good-enough-e44dc78f6585](https://towardsdatascience.com/measuring-the-speed-of-new-pandas-2-0-against-polars-and-datatable-still-not-good-enough-e44dc78f6585)
- en: Even though the new PyArrow backend for Pandas is bringing exciting features,
    it still looks disappointing in terms of speed.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尽管新的 PyArrow 后端为 Pandas 带来了令人兴奋的功能，但在速度方面仍然令人失望。
- en: '[](https://ibexorigin.medium.com/?source=post_page-----e44dc78f6585--------------------------------)[![Bex
    T.](../Images/516496f32596e8ad56bf07f178a643c6.png)](https://ibexorigin.medium.com/?source=post_page-----e44dc78f6585--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e44dc78f6585--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e44dc78f6585--------------------------------)
    [Bex T.](https://ibexorigin.medium.com/?source=post_page-----e44dc78f6585--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ibexorigin.medium.com/?source=post_page-----e44dc78f6585--------------------------------)[![Bex
    T.](../Images/516496f32596e8ad56bf07f178a643c6.png)](https://ibexorigin.medium.com/?source=post_page-----e44dc78f6585--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e44dc78f6585--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e44dc78f6585--------------------------------)
    [Bex T.](https://ibexorigin.medium.com/?source=post_page-----e44dc78f6585--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e44dc78f6585--------------------------------)
    ·7 min read·Mar 29, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e44dc78f6585--------------------------------)
    ·7 分钟阅读·2023年3月29日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/741230d22d003ff7576c9b047ca76d76.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/741230d22d003ff7576c9b047ca76d76.png)'
- en: Image by author via Midjourney
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像来自 Midjourney
- en: People have been complaining about Pandas' speed ever since they tried reading
    their first gigabyte-sized dataset with `read_csv` and realized they had to wait
    for - *gasp* - five seconds. And yes, I was one of those complainers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自从第一次尝试用 `read_csv` 读取一个大小为一千兆字节的数据集，并意识到需要等待 - *喘息* - 五秒钟以来，人们一直在抱怨 Pandas
    的速度。是的，我也是那些抱怨者之一。
- en: Five seconds might not sound a lot, but when loading the dataset itself takes
    that much runtime, it usually means subsequent operations will take as long. And
    since spee is one of the most essential things in quick, dirty data exploration,
    you can get *very* frustrated.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 五秒钟听起来可能不多，但当加载数据集本身需要这么长时间时，通常意味着后续操作也会需要这么久。而且，由于速度是快速、简便的数据探索中最重要的因素之一，这可能让你感到*非常*沮丧。
- en: For this reason, folks at PyData recently announced the planned release of Pandas
    2.0 with the freshly minted PyArrow backend. For those totally unaware, PyArrow,
    on its own, is a nifty little library designed for high-performance, memory-efficient
    manipulation of arrays.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，PyData 的人员最近宣布了计划发布带有全新 PyArrow 后端的 Pandas 2.0。对于完全不了解的人，PyArrow 本身是一个设计用于高性能、内存高效处理数组的小巧库。
- en: 'People sincerely hope the new backend will bring considerable speed-ups over
    the vanilla Pandas. This article will test that glimmer of hope by comparing the
    PyArrow backend against two of the fastest DataFrame libraries: Datatable and
    Polars.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 人们真心希望新的后端能带来比原生 Pandas 更显著的加速。本文将通过将 PyArrow 后端与两种最快的数据框库 Datatable 和 Polars
    进行比较来测试这一希望的光芒。
- en: Haven't people already done this?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 难道这些人还没有做过这个吗？
- en: What is the point of doing this benchmark when H20 currently runs the popular
    [**Database-like Ops Benchmark**](https://h2oai.github.io/db-benchmark/) that
    measures the computation speed of almost 15 libraries on three data manipulation
    operations over three different dataset sizes? My benchmark couldn't possibly
    be as complete.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 既然 H20 目前已经运行了受欢迎的 [**Database-like Ops Benchmark**](https://h2oai.github.io/db-benchmark/)
    来测量几乎 15 个库在三种不同数据集大小上的三个数据操作的计算速度，那做这个基准测试还有什么意义？我的基准测试不可能做到那么全面。
- en: Well, for one, the benchmark didn't include Pandas with the PyArrow backend
    and was last updated in 2021, which was ages ago.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，首先，这个基准测试没有包括带有 PyArrow 后端的 Pandas，并且最后一次更新是在 2021 年，那已经很久了。
- en: Secondly, the benchmark was run on a monster of a machine with 40 CPU cores
    hopped up on 128 GB RAM and 20 GB GPU to boot ([cuDF](https://github.com/rapidsai/cudf),
    anyone?). The general populace doesn't usually have access to such machines, so
    it is important to see the differences between the libraries on everyday devices
    like mine. It features a modest CPU with a dozen cores and 32 gigs of RAM.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，基准测试在一台拥有40个CPU核心、128 GB内存和20 GB GPU的超级机器上运行（[cuDF](https://github.com/rapidsai/cudf)，有人用过吗？）。普通用户通常无法使用这样的机器，因此比较在像我这样日常设备上的库之间的差异非常重要。它配备了一个拥有十几个核心的中等性能CPU和32
    GB的内存。
- en: Lastly, I advocate for total transparency in the process, so I will explain
    the benchmark code in detail and present it as a GitHub Gist to run on your own
    machine.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我提倡过程中的完全透明，所以我将详细解释基准测试代码，并将其作为GitHub Gist提供，供您在自己的机器上运行。
- en: Installation and setup
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装和设置
- en: We start by installing the RC (release candidate) of Pandas 2.0 along with the
    latest versions of PyArrow, Datatable, and Polars.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先安装Pandas 2.0的RC（候选版本），以及最新版本的PyArrow、Datatable和Polars。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'I created a synthetic dataset with NumPy and Faker libraries to simulate typical
    features in a census dataset and saved it in CSV and Parquet formats. Here are
    the paths to the files:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用NumPy和Faker库创建了一个合成数据集，以模拟人口普查数据集中的典型特征，并将其保存为CSV和Parquet格式。以下是文件路径：
- en: '[PRE8]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Check out [this GitHub gist](https://gist.github.com/BexTuychiev/92a1fbbed96fa52cec47fe2cd725cf3e)
    to see the code that generated the data.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 查看[这个 GitHub gist](https://gist.github.com/BexTuychiev/92a1fbbed96fa52cec47fe2cd725cf3e)以查看生成数据的代码。
- en: There are 50 million rows of seven features, clocking up the file size to about
    2.5 GBs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有5000万行七个特征，使文件大小达到约2.5 GB。
- en: Benchmark results
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试结果
- en: 'Before showing the code, let''s see the good stuff — the benchmark results:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在展示代码之前，我们先看看好东西——基准测试结果：
- en: '![](../Images/2e45560dbd6baf259a966f20b883c57c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e45560dbd6baf259a966f20b883c57c.png)'
- en: Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Right off the bat, we can see that PyArrow Pandas comes in last (or second to
    last in `groupby`) across all categories.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，我们可以看到PyArrow Pandas在所有类别中都排在最后（或在`groupby`中倒数第二）。
- en: Please, don't mistake the nonexistent bars in reading and writing parquet categories
    for 0 runtimes. Those operations aren't supported in Datatable.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 请不要将阅读和写入Parquet类别中的不存在的条形图误认为是0运行时间。这些操作在Datatable中不受支持。
- en: In other categories, Datatable and Polars share the top spot, with Polars having
    a slight edge.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他类别中，Datatable和Polars并列第一，Polars稍微占有优势。
- en: Writing to CSVs has always been a slow process for Pandas, and I guess a new
    backend isn't enough to change that.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 写入CSV文件一直是Pandas的慢速过程，我猜新后端不足以改变这一点。
- en: Should you switch?
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你应该切换吗？
- en: So, time for the million-dollar question — should you switch to the faster Polars
    or Datatable?
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，百万美元的问题是——你应该切换到更快的Polars还是Datatable？
- en: And the answer is the *I-so-hate* "it depends." Are you willing to sacrifice
    Pandas' almost two-decade maturity and, let's admit it, stupidly easy and familiar
    syntax for superior speed?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是*我非常讨厌*的“这要看情况”。你是否愿意为了更快的速度牺牲Pandas近二十年的成熟度，以及说实话，愚蠢的容易和熟悉的语法？
- en: In that case, keep in mind that the time you spend learning the syntax of a
    new library may balance out its performance gains.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，请记住，你花时间学习新库的语法可能会平衡其性能提升。
- en: But, if all you do is work with massive datasets, learning either of these fast
    libraries may be well worth the effort in the long run.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果你只是处理大量数据集，那么学习这些快速库中的任何一个可能从长远来看都值得付出努力。
- en: If you decide to stick with Pandas, give [the Enhancing Performance](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)
    page of the Pandas user guide a thorough, attentive read. It outlines some tips
    and tricks to add extra fuel to the Pandas engine without resorting to third-party
    libraries.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你决定继续使用Pandas，请仔细阅读[Pandas用户指南的性能提升](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)页面。它概述了一些技巧和窍门，以在不依赖第三方库的情况下为Pandas引擎增加额外的动力。
- en: 'Also, if you are stuck with a large CSV file and still want to use Pandas,
    you should memorize the following code snippet:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你被困在一个大的CSV文件中，仍然想使用Pandas，你应该记住以下代码片段：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: It reads the file with the speed of Datatable, and the conversion to a Pandas
    DataFrame is almost instantaneous.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 它以Datatable的速度读取文件，将其转换为Pandas DataFrame几乎是瞬间完成的。
- en: Benchmark code
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准测试代码
- en: OK, let's finally see the code.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，最后来看代码吧。
- en: 'The first thing to do after importing the libraries is to define a DataFrame
    to store the benchmark results. This will make things much easier during plotting:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 导入库后，首先要做的是定义一个DataFrame来存储基准测试结果。这将使绘图过程变得更简单。
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: It has three columns, one for the task name, another for the library name, and
    another for storing the runtime.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 它有三列，一列用于任务名称，另一列用于库名称，还有一列用于存储运行时间。
- en: 'Then, we define a `timer` decorator that performs the following tasks:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义一个`timer`装饰器，执行以下任务：
- en: Measures the runtime of the decorated function.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量装饰函数的运行时间。
- en: Extracts the function's name and the value of its `library` parameter.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取函数的名称和其`library`参数的值。
- en: Stores the runtime, function name, and library name into the passed results
    DataFrame.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将运行时间、函数名称和库名称存储到传递的结果DataFrame中。
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The idea is to define a single general function like `read_csv` that reads
    CSV files with either of the three libraries, which can be controlled with a parameter
    like `library`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是定义一个通用函数，如`read_csv`，用于读取三种库中的任意一个的CSV文件，可以通过像`library`这样的参数进行控制：
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Notice how we are decorating the function with `timer(results_df)`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们是如何用`timer(results_df)`装饰函数的。
- en: 'We define functions for the rest of the tasks in a similar way (see the function
    bodies from [the Gist](https://gist.github.com/BexTuychiev/dba8d1f876e1d601f530c0e8b16d5a85)):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以类似的方式定义其他任务的函数（参见[the Gist](https://gist.github.com/BexTuychiev/dba8d1f876e1d601f530c0e8b16d5a85)中的函数体）：
- en: '[PRE13]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, we run the functions for each of the libraries:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们为每个库运行这些函数：
- en: '[PRE14]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To escape memory errors, I avoided loops and ran the benchmark in a Jupyter
    Notebook three times, changing the `l` variable.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免内存错误，我避免了循环，并在Jupyter Notebook中运行了三次基准测试，改变了`l`变量。
- en: 'Then, we create the figure of the benchmark with the following simple bar chart
    in lovely Seaborn:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用可爱的Seaborn创建基准图形，展示以下简单的柱状图：
- en: '[PRE15]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/2e45560dbd6baf259a966f20b883c57c.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e45560dbd6baf259a966f20b883c57c.png)'
- en: Image by author
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Things are changing
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事情正在发生变化
- en: For years now, Pandas have stood on the shoulders of NumPy as it boomed in popularity.
    NumPy was kind enough to lend its features for fast computations and array manipulations.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，Pandas依赖于NumPy的肩膀，因为NumPy在流行度上迅猛增长。NumPy慷慨地借用了其快速计算和数组操作的功能。
- en: But this approach was limited because of NumPy's terrible support for text and
    missing values. Pandas couldn't use native Python data types like lists and dictionaries
    because that would be a laughing stock on a massive scale.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 但这种方法受限于NumPy对文本和缺失值的糟糕支持。Pandas不能使用本地Python数据类型如列表和字典，因为那样会在大规模上成为笑柄。
- en: So, Pandas has been moving away from NumPy on the sly for a few years now. For
    example, it introduced PyArrow datatypes for strings in 2020 already. It has been
    using extensions written in other languages, such as C++ and Rust, for other complex
    data types like dates with time zones or categoricals.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Pandas在过去几年中已悄然远离NumPy。例如，它在2020年就引入了PyArrow数据类型用于字符串。它还使用了用其他语言编写的扩展，如C++和Rust，用于日期（含时区）或分类数据等复杂数据类型。
- en: Now, Pandas 2.0 has a fully-fledged backend to support all data types with Apache
    Arrow's PyArrow implementation. Apart from the apparent speed improvements, it
    provides much better support for missing values, interoperability, and a wider
    range of data types.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Pandas 2.0拥有一个全面的后端，支持所有数据类型，基于Apache Arrow的PyArrow实现。除了明显的速度提升外，它还提供了更好的缺失值支持、互操作性和更广泛的数据类型支持。
- en: So, even though the backend will still be slower than other DataFrame libraries,
    I am eagerly awaiting its official release. Thank you for reading!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，即使后端仍然比其他DataFrame库慢，我仍然热切期待其正式发布。感谢阅读！
- en: 'Here are a few pages to learn more about Pandas 2.0 and the PyArrow backend:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些页面可以了解更多关于Pandas 2.0和PyArrow后端的信息：
- en: '[https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i](https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i](https://datapythonista.me/blog/pandas-20-and-the-arrow-revolution-part-i)'
- en: '[https://levelup.gitconnected.com/welcoming-pandas-2-0-194094e4275b](https://levelup.gitconnected.com/welcoming-pandas-2-0-194094e4275b)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://levelup.gitconnected.com/welcoming-pandas-2-0-194094e4275b](https://levelup.gitconnected.com/welcoming-pandas-2-0-194094e4275b)'
- en: '[https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html](https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html](https://pandas.pydata.org/docs/dev/whatsnew/v2.0.0.html)'
- en: Loved this article and, let’s face it, its bizarre writing style? Imagine having
    access to dozens more just like it, all written by a brilliant, charming, witty
    author (that’s me, by the way :).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 喜欢这篇文章以及它那奇特的写作风格？想象一下，获取更多类似的文章，全部由一位才华横溢、迷人幽默的作者（对了，那就是我 :）。
- en: For only 4.99$ membership, you will get access to not just my stories, but a
    treasure trove of knowledge from the best and brightest minds on Medium. And if
    you use [my referral link](https://ibexorigin.medium.com/membership), you will
    earn my supernova of gratitude and a virtual high-five for supporting my work.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 只需4.99美元的会员费用，你将不仅能访问我的故事，还能获取来自 Medium 上最聪明、最杰出思想者的宝贵知识。如果你使用[我的推荐链接](https://ibexorigin.medium.com/membership)，你将获得我超级感激的心意和一个虚拟的击掌，以支持我的工作。
- en: '[](https://ibexorigin.medium.com/membership?source=post_page-----e44dc78f6585--------------------------------)
    [## Join Medium with my referral link — Bex T.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ibexorigin.medium.com/membership?source=post_page-----e44dc78f6585--------------------------------)
    [## 通过我的推荐链接加入 Medium — Bex T.'
- en: Get exclusive access to all my ⚡premium⚡ content and all over Medium without
    limits. Support my work by buying me a…
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 独享所有⚡高级⚡内容，并在 Medium 上无限畅游。通过购买我一杯…
- en: ibexorigin.medium.com](https://ibexorigin.medium.com/membership?source=post_page-----e44dc78f6585--------------------------------)
    ![](../Images/a01b5e4fb641db5f35b8172a4388e821.png)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ibexorigin.medium.com](https://ibexorigin.medium.com/membership?source=post_page-----e44dc78f6585--------------------------------)
    ![](../Images/a01b5e4fb641db5f35b8172a4388e821.png)
