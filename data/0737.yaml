- en: Parsing Irregular Spreadsheet Tables in Humanitarian Datasets (with Some Help
    from GPT-3)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨äººé“ä¸»ä¹‰æ•°æ®é›†ä¸­è§£æä¸è§„åˆ™ç”µå­è¡¨æ ¼ï¼ˆå€ŸåŠ© GPT-3 çš„å¸®åŠ©ï¼‰
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24](https://towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24](https://towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24)
- en: Processing Irregular Excel Tables Without Using Hard-coded Rules
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤„ç†ä¸è§„åˆ™ Excel è¡¨æ ¼ï¼Œæ— éœ€ä½¿ç”¨ç¡¬ç¼–ç è§„åˆ™
- en: '[](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)[](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)[![é©¬ä¿®Â·å“ˆé‡Œæ–¯](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)[](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)[![æ•°æ®ç§‘å­¦å‰æ²¿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)
    [é©¬ä¿®Â·å“ˆé‡Œæ–¯](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----57efb3d80d45---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)
    Â·26 min readÂ·Feb 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----57efb3d80d45---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----57efb3d80d45---------------------post_header-----------)
    å‘å¸ƒäº [æ•°æ®ç§‘å­¦å‰æ²¿](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)
    Â· 26 åˆ†é’Ÿé˜…è¯» Â· 2023å¹´2æœˆ24æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----57efb3d80d45---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&source=-----57efb3d80d45---------------------bookmark_footer-----------)![](../Images/0fbcce7550af12dc6d701ff00255fbc1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&source=-----57efb3d80d45---------------------bookmark_footer-----------)![](../Images/0fbcce7550af12dc6d701ff00255fbc1.png)'
- en: Created by DALL-E2 with prompt â€œA painting of 10 wood tablesâ€. There are 9 tables
    in the image above.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ç”± DALL-E2 æ ¹æ®æç¤ºâ€œ10 å¼ æœ¨æ¡Œçš„ç”»ä½œâ€åˆ›ä½œã€‚ä¸Šå›¾ä¸­æœ‰ 9 å¼ æ¡Œå­ã€‚
- en: '***TL;DR***'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '***ç®€çŸ­è¯´æ˜***'
- en: '*As part of a* [*previous study*](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)
    *using data from the* [*Humanitarian Data Exchange*](https://data.humdata.org/)*,
    I had to analyze thousands of Excel files where tables within those files were
    often difficult to parse into database tables. Irregular layouts with merged cells,
    hierarchical columns, and annotations are difficult to anticipate with rule-based
    parsing when files originate from hundreds of organizations across the world.
    In this article, I explore using GPT-3 zero- single- and single-shot with reasoning
    completion to reformat irregular (small) tables, as well as fine-tuning the model
    to predict table attributes which can then be used for accurate parsing.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä½œä¸º* [*ä¹‹å‰çš„ç ”ç©¶*](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)
    *çš„ä¸€éƒ¨åˆ†ï¼Œä½¿ç”¨äº†æ¥è‡ª* [*äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢*](https://data.humdata.org/) *çš„æ•°æ®ï¼Œæˆ‘ä¸å¾—ä¸åˆ†ææˆåƒä¸Šä¸‡çš„Excelæ–‡ä»¶ï¼Œè¿™äº›æ–‡ä»¶ä¸­çš„è¡¨æ ¼å¸¸å¸¸éš¾ä»¥è§£ææˆæ•°æ®åº“è¡¨ã€‚æ–‡ä»¶æ¥è‡ªå…¨çƒæ•°ç™¾ä¸ªç»„ç»‡æ—¶ï¼Œåˆå¹¶å•å…ƒæ ¼ã€ä¸è§„åˆ™å¸ƒå±€ã€å±‚æ¬¡åŒ–åˆ—å’Œæ³¨é‡Šéš¾ä»¥é€šè¿‡åŸºäºè§„åˆ™çš„è§£ææ¥é¢„è§ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æ¢è®¨äº†ä½¿ç”¨GPT-3çš„é›¶-shotã€å•-shotå’Œæ¨ç†è¡¥å…¨æ¥é‡æ–°æ ¼å¼åŒ–ä¸è§„åˆ™ï¼ˆå°å‹ï¼‰è¡¨æ ¼ï¼Œå¹¶å¾®è°ƒæ¨¡å‹ä»¥é¢„æµ‹è¡¨æ ¼å±æ€§ï¼Œä»è€Œç”¨äºå‡†ç¡®è§£æã€‚*'
- en: There have been quite a few times on my travels when Iâ€™ve needed to review a
    large number of Excel files to understand what data they contain, how well it
    is structured, and the work required to clean it into a form where we can get
    to the juicy stuff like training models. For the most part this is fairly straightforward,
    as long as the data is regular with nice neat column headings. However, life is
    never that easy and itâ€™s often the case the tables in these files can be in a
    less-than-perfect format to parse into neat data frames that can be uploaded into
    relational databases. Excel supports a lot of features such as pivot tables and
    cell merging, which human beings use to create a wide variety of layouts, with
    blank rows, random text here and there, and more!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘çš„æ—…è¡Œä¸­ï¼Œæœ‰ä¸å°‘æ¬¡éœ€è¦æŸ¥çœ‹å¤§é‡Excelæ–‡ä»¶ï¼Œä»¥äº†è§£å®ƒä»¬åŒ…å«çš„æ•°æ®ã€æ•°æ®çš„ç»“æ„å¦‚ä½•ï¼Œä»¥åŠå°†å…¶æ¸…ç†æˆå¯ä»¥å¤„ç†çš„å½¢å¼æ‰€éœ€çš„å·¥ä½œã€‚å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œåªè¦æ•°æ®è§„åˆ™ä¸”åˆ—æ ‡é¢˜æ•´é½ï¼Œè¿™ä¸ªè¿‡ç¨‹ç›¸å½“ç®€å•ã€‚ç„¶è€Œï¼Œç°å®ä»æœªé‚£ä¹ˆç®€å•ï¼Œè¿™äº›æ–‡ä»¶ä¸­çš„è¡¨æ ¼å¾€å¾€ä»¥ä¸å®Œç¾çš„æ ¼å¼å­˜åœ¨ï¼Œéš¾ä»¥è§£ææˆå¯ä»¥ä¸Šä¼ åˆ°å…³ç³»æ•°æ®åº“çš„æ•°æ®æ¡†ã€‚Excelæ”¯æŒè®¸å¤šåŠŸèƒ½ï¼Œå¦‚æ•°æ®é€è§†è¡¨å’Œå•å…ƒæ ¼åˆå¹¶ï¼Œäººä»¬ä½¿ç”¨è¿™äº›åŠŸèƒ½åˆ›å»ºå„ç§å„æ ·çš„å¸ƒå±€ï¼ŒåŒ…æ‹¬ç©ºç™½è¡Œã€éšæœºæ–‡æœ¬ç­‰ç­‰ï¼
- en: Here is an example to illustrate â€¦
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜â€¦â€¦
- en: '![](../Images/b8a93c73e798926ce23cb65154d977a4.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8a93c73e798926ce23cb65154d977a4.png)'
- en: Example of an irregular table in Excel, with blank top rows, labels and merged
    cells. Perfectly readable for humans, but a challenge to parse for data science.
    This file was sourced from the [Humanitarian Data Exchange](https://data.humdata.org/dataset/kenya-number-of-acreage-under-irrigation-in-bomet-county)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Excelä¸­çš„ä¸è§„åˆ™è¡¨æ ¼ç¤ºä¾‹ï¼Œå¸¦æœ‰ç©ºç™½é¡¶éƒ¨è¡Œã€æ ‡ç­¾å’Œåˆå¹¶å•å…ƒæ ¼ã€‚å¯¹äººç±»æ¥è¯´å®Œå…¨å¯è¯»ï¼Œä½†å¯¹æ•°æ®ç§‘å­¦æ¥è¯´æ˜¯è§£æçš„æŒ‘æˆ˜ã€‚è¯¥æ–‡ä»¶æ¥è‡ª[äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢](https://data.humdata.org/dataset/kenya-number-of-acreage-under-irrigation-in-bomet-county)
- en: If we read the above file directly into Pandas â€¦
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ç›´æ¥å°†ä¸Šè¿°æ–‡ä»¶è¯»å…¥Pandasä¸­â€¦â€¦
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We get this â€¦
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¾—åˆ°è¿™ä¸ªâ€¦â€¦
- en: '![](../Images/5089756e01020858fd71468ba8fd5fab.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5089756e01020858fd71468ba8fd5fab.png)'
- en: Example of Pandas dataframe after parsing a table on an Excel sheet, where there
    are blank rows and merged cells to indicate hierarchical columns. Example data
    from the [Humanitarian Data Exchange](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Pandasæ•°æ®æ¡†åœ¨è§£æExcelè¡¨æ ¼åçš„ç¤ºä¾‹ï¼Œå…¶ä¸­åŒ…å«ç©ºè¡Œå’Œåˆå¹¶å•å…ƒæ ¼ï¼Œä»¥æŒ‡ç¤ºå±‚æ¬¡åˆ—ã€‚ç¤ºä¾‹æ•°æ®æ¥è‡ª[äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)
- en: Loading this into a database would result in near-unusable data because â€¦
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å…¶åŠ è½½åˆ°æ•°æ®åº“ä¸­ä¼šå¯¼è‡´æ•°æ®å‡ ä¹æ— æ³•ä½¿ç”¨ï¼Œå› ä¸ºâ€¦â€¦
- en: There is a table title in the top-right cell
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å³ä¸Šè§’å•å…ƒæ ¼ä¸­æœ‰ä¸€ä¸ªè¡¨æ ¼æ ‡é¢˜ã€‚
- en: 'Column â€˜Unnamed: 1â€™ title is actually whatâ€™s in the first column row 5 â€œWhat
    is the average size of land you own that â€¦â€'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'åˆ—â€˜Unnamed: 1â€™çš„æ ‡é¢˜å®é™…ä¸Šæ˜¯ç¬¬ä¸€åˆ—ç¬¬5è¡Œçš„å†…å®¹â€œä½ æ‹¥æœ‰çš„åœŸåœ°çš„å¹³å‡é¢ç§¯æ˜¯å¤šå°‘â€¦â€¦â€'
- en: Columns â€˜Unnamed:2â€™ and â€˜Unnamed:3â€™ are aggregate totals split into â€™Nâ€™ numeric
    and â€˜%â€™ percentage values
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ—â€˜Unnamed:2â€™å’Œâ€˜Unnamed:3â€™æ˜¯åˆ†ä¸ºâ€™Nâ€˜ æ•°å€¼å’Œâ€˜%â€™ ç™¾åˆ†æ¯”å€¼çš„æ±‡æ€»æ€»æ•°ã€‚
- en: Most columns are hierarchical, with merged cells above unmerged cells
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°åˆ—æ˜¯å±‚æ¬¡åŒ–çš„ï¼Œåˆå¹¶å•å…ƒæ ¼ä½äºæœªåˆå¹¶å•å…ƒæ ¼ä¹‹ä¸Šã€‚
- en: Itâ€™s not *that* bad, right?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿä¸*é‚£ä¹ˆ*ç³Ÿç³•ï¼Œå¯¹å§ï¼Ÿ
- en: It is of course possible to provide parameters to [Pandas read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)
    that will convert hierarchical columns to indexes, which can then be collapsed
    into a single row. Alternatively, we might manipulate in [Openpxyl](https://openpyxl.readthedocs.io/en/stable/)
    using information from Excel itself about merged cells. However, these methods
    require knowledge of the table â€” specifically where the headings finish and the
    data starts and how hierarchical columns are structured â€” a luxury we might not
    always have if processing thousands of spreadsheets. Maintaining rule-based parsing
    for large volumes of files can be time-consuming and brittle, requiring continued
    maintenance as new layouts appear on the scene.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œå¯ä»¥å‘[Pandas read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)æä¾›å‚æ•°ï¼Œå°†å±‚æ¬¡åˆ—è½¬æ¢ä¸ºç´¢å¼•ï¼Œç„¶åå¯ä»¥å°†å…¶åˆå¹¶ä¸ºä¸€è¡Œã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨[Openpyxl](https://openpyxl.readthedocs.io/en/stable/)ä¸­å…³äºExcelè‡ªèº«çš„åˆå¹¶å•å…ƒæ ¼çš„ä¿¡æ¯è¿›è¡Œæ“ä½œã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¯¹è¡¨æ ¼æœ‰äº†è§£â€”â€”ç‰¹åˆ«æ˜¯æ ‡é¢˜åœ¨å“ªé‡Œç»“æŸã€æ•°æ®ä»å“ªé‡Œå¼€å§‹ä»¥åŠå±‚æ¬¡åˆ—çš„ç»“æ„â€”â€”è¿™æ˜¯æˆ‘ä»¬åœ¨å¤„ç†æˆåƒä¸Šä¸‡çš„ç”µå­è¡¨æ ¼æ—¶å¯èƒ½ä¸æ€»æ˜¯æ‹¥æœ‰çš„å¥¢ä¾ˆå“ã€‚å¯¹å¤§é‡æ–‡ä»¶è¿›è¡ŒåŸºäºè§„åˆ™çš„è§£æå¯èƒ½è€—æ—¶ä¸”è„†å¼±ï¼Œéœ€è¦éšç€æ–°å¸ƒå±€çš„å‡ºç°è€ŒæŒç»­ç»´æŠ¤ã€‚
- en: As it happens, I am not alone! Parsing irregular tables is a challenge being
    actively researched. For example, Microsoft authors have shown some great results
    using Convolutional Neural Networks to develop an algorithm called â€˜TableSenseâ€™
    [[1](https://arxiv.org/abs/2106.13500)]. This technique treats Excel sheets in
    a similar way to images but with richer featurization as each cell can have a
    range of attributes and data types, as well as formatting and merging characteristics.
    Very cool. I hope fantastic work like this will be included in Microsoftâ€™s products
    soon, but until then I wanted to explore some other approaches.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶å®ï¼Œæˆ‘å¹¶ä¸æ˜¯å”¯ä¸€ä¸€ä¸ªé‡åˆ°è¿™ä¸ªé—®é¢˜çš„äººï¼è§£æä¸è§„åˆ™è¡¨æ ¼æ˜¯ä¸€é¡¹æ­£åœ¨ç§¯æç ”ç©¶çš„æŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼Œå¾®è½¯çš„ä½œè€…å±•ç¤ºäº†åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œå¼€å‘çš„ä¸€ä¸ªåä¸ºâ€˜TableSenseâ€™çš„ç®—æ³•çš„å‡ºè‰²æˆæœ[[1](https://arxiv.org/abs/2106.13500)]ã€‚è¿™ç§æŠ€æœ¯å°†Excelè¡¨æ ¼è§†ä½œå›¾åƒæ¥å¤„ç†ï¼Œä½†å…·æœ‰æ›´ä¸°å¯Œçš„ç‰¹å¾åŒ–ï¼Œå› ä¸ºæ¯ä¸ªå•å…ƒæ ¼å¯èƒ½å…·æœ‰å¤šç§å±æ€§å’Œæ•°æ®ç±»å‹ï¼Œè¿˜åŒ…æ‹¬æ ¼å¼åŒ–å’Œåˆå¹¶ç‰¹å¾ã€‚éå¸¸é…·ã€‚æˆ‘å¸Œæœ›åƒè¿™æ ·çš„ç²¾å½©å·¥ä½œèƒ½å°½å¿«çº³å…¥å¾®è½¯çš„äº§å“ä¸­ï¼Œä½†åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘æƒ³æ¢ç´¢ä¸€äº›å…¶ä»–çš„æ–¹æ³•ã€‚
- en: 'Itâ€™s also worth noting that my use-case is not just to identify the range in
    a sheet where the table is (see [training data for the Microsoft paper above](https://github.com/microsoft/TableSense/blob/main/dataset/Table%20range%20annotations.txt)),
    but elements in the table so irregular formats can be converted to something that
    can be easily imported into a database. The main challenge is hierarchical columns
    in Excel, flattening these into a single row that captures information from overlying
    merged cells. Sounds simple to fix, but the challenge is: where do the headings
    stop and the data start? This is obvious to us humans, but itâ€™s surprising how
    something so simple can be quite noisy in the real world when processing sheets
    using code.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘çš„ä½¿ç”¨æ¡ˆä¾‹ä¸ä»…ä»…æ˜¯è¯†åˆ«è¡¨æ ¼åœ¨å·¥ä½œè¡¨ä¸­çš„èŒƒå›´ï¼ˆå‚è§[å¾®è½¯è®ºæ–‡çš„è®­ç»ƒæ•°æ®](https://github.com/microsoft/TableSense/blob/main/dataset/Table%20range%20annotations.txt)ï¼‰ï¼Œè¿˜åŒ…æ‹¬è¡¨æ ¼ä¸­çš„å…ƒç´ ï¼Œä»¥ä¾¿å°†ä¸è§„åˆ™çš„æ ¼å¼è½¬æ¢ä¸ºå¯ä»¥è½»æ¾å¯¼å…¥æ•°æ®åº“çš„æ ¼å¼ã€‚ä¸»è¦æŒ‘æˆ˜æ˜¯Excelä¸­çš„å±‚æ¬¡åˆ—ï¼Œå°†è¿™äº›å±‚æ¬¡åˆ—å±•å¹³æˆä¸€ä¸ªå•ç‹¬çš„è¡Œï¼Œä»è€Œæ•æ‰ä¸Šå±‚åˆå¹¶å•å…ƒæ ¼ä¸­çš„ä¿¡æ¯ã€‚å¬èµ·æ¥è§£å†³èµ·æ¥å¾ˆç®€å•ï¼Œä½†æŒ‘æˆ˜æ˜¯ï¼šæ ‡é¢˜åœ¨å“ªé‡Œç»“æŸï¼Œæ•°æ®ä»å“ªé‡Œå¼€å§‹ï¼Ÿè¿™å¯¹æˆ‘ä»¬äººç±»æ¥è¯´æ˜¾è€Œæ˜“è§ï¼Œä½†ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå½“ç”¨ä»£ç å¤„ç†å·¥ä½œè¡¨æ—¶ï¼Œè¿™æ ·ç®€å•çš„äº‹æƒ…åœ¨ç°å®ä¸–ç•Œä¸­å¯èƒ½ä¼šå˜å¾—éå¸¸å˜ˆæ‚ã€‚
- en: Given all the recent attention for generative AI and Large Language Models (LLMs),
    I wondered if perhaps [OpenAIâ€™s GPT-3](https://openai.com/blog/gpt-3-apps/) might
    be up to the challenge. These models are trained on huge amounts of data extracted
    from the internet, which includes tables and CSV files, so they might be useful
    in handling some of the nuances of tables put together by us crazy humans.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: é‰´äºæœ€è¿‘å¯¹ç”Ÿæˆå¼ AI å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…³æ³¨ï¼Œæˆ‘æƒ³çŸ¥é“ä¹Ÿè®¸[OpenAI çš„ GPT-3](https://openai.com/blog/gpt-3-apps/)å¯èƒ½ä¼šæ¥å—è¿™ä¸ªæŒ‘æˆ˜ã€‚è¿™äº›æ¨¡å‹åœ¨ä»äº’è”ç½‘æå–çš„å¤§é‡æ•°æ®ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬è¡¨æ ¼å’ŒCSVæ–‡ä»¶ï¼Œå› æ­¤å®ƒä»¬å¯èƒ½åœ¨å¤„ç†æˆ‘ä»¬è¿™äº›ç–¯ç‹‚äººç±»æ‹¼å‡‘çš„è¡¨æ ¼çš„æŸäº›ç»†èŠ‚æ–¹é¢ä¼šå¾ˆæœ‰ç”¨ã€‚
- en: Prompting GPT-3 to Tidy Up (a Small) Table
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æç¤º GPT-3 æ¸…ç†ï¼ˆä¸€ä¸ªå°çš„ï¼‰è¡¨æ ¼
- en: We will first try to solve our problem as zero- and few-shot tasks for GPT-3,
    before moving on to using fine-tuning techniques.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆå°è¯•å°†é—®é¢˜ä½œä¸ºé›¶æ ·æœ¬å’Œå°‘é‡æ ·æœ¬ä»»åŠ¡è§£å†³ï¼Œç„¶åå†è½¬å‘ä½¿ç”¨å¾®è°ƒæŠ€æœ¯ã€‚
- en: '![](../Images/23eef763f4af285bab56ce5104601dbc.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23eef763f4af285bab56ce5104601dbc.png)'
- en: Zero-shot, one-shot and few-shot tasks, contrasted with traditional fine-tuning.
    The panels above show four methods for performing a task with a language model.
    From Brown et al [[2](https://arxiv.org/pdf/2005.14165.pdf)]
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: é›¶æ ·æœ¬ã€å•æ ·æœ¬å’Œå°‘æ ·æœ¬ä»»åŠ¡ï¼Œä¸ä¼ ç»Ÿçš„å¾®è°ƒå¯¹æ¯”ã€‚ä¸Šé¢çš„é¢æ¿å±•ç¤ºäº†ç”¨è¯­è¨€æ¨¡å‹æ‰§è¡Œä»»åŠ¡çš„å››ç§æ–¹æ³•ã€‚æ¥æºäº Brown ç­‰äºº [[2](https://arxiv.org/pdf/2005.14165.pdf)]ã€‚
- en: GPT-3 is trained on text scraped from the web, so we cannot prompt it with Excel
    (yet!), therefore we first have to convert our sheet into a form that is occurs
    on the web, CSV string â€¦
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 æ˜¯åœ¨ä»ç½‘ç»œä¸ŠæŠ“å–çš„æ–‡æœ¬ä¸Šè®­ç»ƒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸èƒ½ç”¨ Excel æç¤ºå®ƒï¼ˆè¿˜ä¸è¡Œï¼ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆå¿…é¡»å°†æˆ‘ä»¬çš„è¡¨æ ¼è½¬æ¢æˆä¸€ç§ç½‘ç»œä¸Šå¸¸è§çš„å½¢å¼ï¼Œä¾‹å¦‚
    CSV å­—ç¬¦ä¸²â€¦â€¦
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Side note**: I also tried with Markdown and HTML tables, but got best results
    for my use-case with CSV.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™„æ³¨**ï¼šæˆ‘è¿˜å°è¯•äº† Markdown å’Œ HTML è¡¨æ ¼ï¼Œä½†å‘ç° CSV åœ¨æˆ‘çš„ç”¨ä¾‹ä¸­æ•ˆæœæœ€å¥½ã€‚'
- en: Itâ€™s worth noting that for this analysis the tables we are dealing with are
    *thin,* ie having < 100 columns. This means the first 10 rows can be represented
    easily in a GPT-3 prompt. This is fine for most of the Excel tables I have been
    analyzing for the Humanitarian Data Exchange, but might not extend to other scenarios.
    Also, this analysis doesnâ€™t consider cases where there are multiple tables on
    the same Excel sheet â€¦ that is for a later blog post. ğŸ™‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¯¹äºè¿™é¡¹åˆ†æï¼Œæˆ‘ä»¬å¤„ç†çš„è¡¨æ ¼æ˜¯*ç¨€ç–çš„*ï¼Œå³åˆ—æ•°å°‘äº 100ã€‚è¿™æ„å‘³ç€å‰ 10 è¡Œå¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨ GPT-3 æç¤ºä¸­è¡¨ç¤ºã€‚è¿™å¯¹æˆ‘åœ¨æ´åŠ©æ•°æ®äº¤æ¢ä¸­åˆ†æçš„å¤§å¤šæ•°
    Excel è¡¨æ ¼æ¥è¯´æ˜¯åˆé€‚çš„ï¼Œä½†å¯èƒ½ä¸é€‚ç”¨äºå…¶ä»–æƒ…å†µã€‚æ­¤å¤–ï¼Œè¿™é¡¹åˆ†æä¸è€ƒè™‘åŒä¸€ Excel å·¥ä½œè¡¨ä¸Šæœ‰å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µâ€¦â€¦è¿™å°†æ˜¯ç¨ååšå®¢æ–‡ç« çš„å†…å®¹ã€‚ğŸ™‚
- en: '**Zero-Shot Prompt**'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**é›¶æ ·æœ¬æç¤º**'
- en: Letâ€™s now see if GPT-3 can reformat our untidy table with just a single prompt,
    a [zero-shot task](https://arxiv.org/pdf/2005.14165.pdf) [2] where we are providing
    no examples, just a CSV file of the table we want to be reformatted â€¦
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹ GPT-3 æ˜¯å¦å¯ä»¥ä»…é€šè¿‡ä¸€ä¸ªæç¤ºé‡æ–°æ ¼å¼åŒ–æˆ‘ä»¬å‡Œä¹±çš„è¡¨æ ¼ï¼Œè¿™æ˜¯ä¸€é¡¹[é›¶æ ·æœ¬ä»»åŠ¡](https://arxiv.org/pdf/2005.14165.pdf)
    [2]ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ç¤ºä¾‹ï¼Œåªæ˜¯æä¾›äº†è¦é‡æ–°æ ¼å¼åŒ–çš„ CSV æ–‡ä»¶â€¦â€¦
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/d0bff692e6f0aa17d92fe2902f2d8efe.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d0bff692e6f0aa17d92fe2902f2d8efe.png)'
- en: It discarded unnecessary rows and converted the data to a nice regular table
    with column headings, but look closely and youâ€™ll see itâ€™s lost some key information,
    such as the breakdown by Male/Female. Classic [hallucination](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))
    territory, it looks very plausible but is wrong.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä¸¢å¼ƒäº†ä¸å¿…è¦çš„è¡Œï¼Œå°†æ•°æ®è½¬æ¢ä¸ºä¸€ä¸ªè§„èŒƒçš„è¡¨æ ¼ï¼Œå¸¦æœ‰åˆ—æ ‡é¢˜ï¼Œä½†ä»”ç»†è§‚å¯Ÿä¼šå‘ç°ï¼Œå®ƒä¸¢å¤±äº†ä¸€äº›å…³é”®ä¿¡æ¯ï¼Œå¦‚æŒ‰æ€§åˆ«çš„åˆ†ç±»ã€‚è¿™æ˜¯ç»å…¸çš„[å¹»è§‰](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))ç°è±¡ï¼Œçœ‹èµ·æ¥å¾ˆå¯ä¿¡ï¼Œä½†å´æ˜¯é”™è¯¯çš„ã€‚
- en: Letâ€™s play with the [temperature](https://platform.openai.com/docs/api-reference/completions/create)
    parameter. Lower values make the model more deterministic (giving the same results
    every time for the same prompt) whereas higher values are more random. With a
    higher temperature value, we get â€¦
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ç©ç©[æ¸©åº¦](https://platform.openai.com/docs/api-reference/completions/create)å‚æ•°ã€‚è¾ƒä½çš„å€¼ä½¿æ¨¡å‹æ›´åŠ ç¡®å®šæ€§ï¼ˆå¯¹äºç›¸åŒçš„æç¤ºæ¯æ¬¡éƒ½ç»™å‡ºç›¸åŒçš„ç»“æœï¼‰ï¼Œè€Œè¾ƒé«˜çš„å€¼åˆ™æ›´éšæœºã€‚ä½¿ç”¨æ›´é«˜çš„æ¸©åº¦å€¼ï¼Œæˆ‘ä»¬å¾—åˆ°â€¦â€¦
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/f9ec19a4d12334d819089ceb85fdbbad.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9ec19a4d12334d819089ceb85fdbbad.png)'
- en: '*Looks* nice! Almost all of the correct column headings from merged cells in
    our CSV, which is pretty amazing actually. However, spot-checking a few cells
    shows that though many are correct, some are not. Also, â€˜Overallâ€™ has been split
    into Male and Female in the above which is incorrect.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*çœ‹èµ·æ¥*ä¸é”™ï¼å‡ ä¹æ‰€æœ‰çš„æ­£ç¡®åˆ—æ ‡é¢˜éƒ½æ¥è‡ªæˆ‘ä»¬ CSV æ–‡ä»¶ä¸­çš„åˆå¹¶å•å…ƒæ ¼ï¼Œè¿™å®é™…ä¸Šç›¸å½“æƒŠäººã€‚ç„¶è€Œï¼ŒæŠ½æŸ¥å‡ ä¸ªå•å…ƒæ ¼æ˜¾ç¤ºï¼Œå°½ç®¡è®¸å¤šæ˜¯æ­£ç¡®çš„ï¼Œä½†ä¹Ÿæœ‰ä¸€äº›ä¸æ­£ç¡®ã€‚æ­¤å¤–ï¼Œä¸Šé¢çš„â€œæ€»ä½“â€è¢«åˆ†æˆäº†ç”·æ€§å’Œå¥³æ€§ï¼Œè¿™æ˜¯ä¸æ­£ç¡®çš„ã€‚'
- en: Another issue here is that calling GPT-3 exactly the same prompt will produce
    different results because of the high temperature value â€¦
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œè°ƒç”¨ GPT-3 å®Œå…¨ç›¸åŒçš„æç¤ºä¼šäº§ç”Ÿä¸åŒçš„ç»“æœï¼Œå› ä¸ºé«˜æ¸©å€¼â€¦â€¦
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/7274d124424e64c6d953449273ad69d4.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7274d124424e64c6d953449273ad69d4.png)'
- en: Not unreasonable, albeit with incorrect values, but an entirely different layout.
    Reproducibility is very important for our task, we should be able to process the
    tabular data in exactly the same way with each processing run.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ— é“ç†ï¼Œå°½ç®¡å€¼ä¸æ­£ç¡®ï¼Œä½†å¸ƒå±€å®Œå…¨ä¸åŒã€‚å¯é‡å¤æ€§å¯¹æˆ‘ä»¬çš„ä»»åŠ¡éå¸¸é‡è¦ï¼Œæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿåœ¨æ¯æ¬¡å¤„ç†è¿è¡Œä¸­ä»¥å®Œå…¨ç›¸åŒçš„æ–¹å¼å¤„ç†è¡¨æ ¼æ•°æ®ã€‚
- en: So high temperatures are not a good option for this use-case it seems.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥é«˜æ¸©ä¼¼ä¹ä¸æ˜¯è¿™ä¸ªç”¨ä¾‹çš„å¥½é€‰æ‹©ã€‚
- en: What about if we provide more context in the table? CSV isnâ€™t very expressive,
    for example, merged columns in hierarchical headers tell humans that the columns
    are grouped, but a CSV file doesnâ€™t capture this â€¦
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åœ¨è¡¨æ ¼ä¸­æä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¼šæ€ä¹ˆæ ·ï¼ŸCSV å¹¶ä¸æ˜¯å¾ˆå…·è¡¨ç°åŠ›ï¼Œä¾‹å¦‚ï¼Œå±‚çº§æ ‡é¢˜ä¸­çš„åˆå¹¶åˆ—å‘Šè¯‰äººç±»è¿™äº›åˆ—æ˜¯åˆ†ç»„çš„ï¼Œä½† CSV æ–‡ä»¶å¹¶æœªæ•æ‰åˆ°è¿™ä¸€ç‚¹â€¦â€¦
- en: '![](../Images/3e5d8eb9550c0dd1d246816daeccfb5d.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e5d8eb9550c0dd1d246816daeccfb5d.png)'
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the above example, GPT-3 must infer that blank columns to the right of merged
    row titles correspond with those titles, and many times it actually does this.
    However, we can help a little since we know whether a cell is merged in our Excel
    file.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼ŒGPT-3 å¿…é¡»æ¨æ–­å‡ºåˆå¹¶çš„è¡Œæ ‡é¢˜å³ä¾§çš„ç©ºç™½åˆ—ä¸è¿™äº›æ ‡é¢˜å¯¹åº”ï¼Œå¹¶ä¸”å¾ˆå¤šæ—¶å€™å®ƒç¡®å®èƒ½å¤Ÿåšåˆ°è¿™ä¸€ç‚¹ã€‚ç„¶è€Œï¼Œç”±äºæˆ‘ä»¬çŸ¥é“ Excel æ–‡ä»¶ä¸­å“ªäº›å•å…ƒæ ¼æ˜¯åˆå¹¶çš„ï¼Œæˆ‘ä»¬å¯ä»¥ç¨å¾®å¸®åŠ©ä¸€ä¸‹ã€‚
- en: To represent this in CSV we can unmerge merged cells and populate with their
    merged value â€¦
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åœ¨ CSV ä¸­è¡¨ç¤ºè¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥å–æ¶ˆåˆå¹¶åˆå¹¶çš„å•å…ƒæ ¼ï¼Œå¹¶ç”¨å…¶åˆå¹¶å€¼å¡«å…… â€¦
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/1790b27c754b07ba4517a577447e222c.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1790b27c754b07ba4517a577447e222c.png)'
- en: Table where merged cells are unmerged and populated with merged value, to provide
    context in CSV file format
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨æ ¼ä¸­åˆå¹¶çš„å•å…ƒæ ¼è¢«å–æ¶ˆåˆå¹¶ï¼Œå¹¶ç”¨åˆå¹¶å€¼å¡«å……ï¼Œä»¥åœ¨ CSV æ–‡ä»¶æ ¼å¼ä¸­æä¾›ä¸Šä¸‹æ–‡ã€‚
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The CSV file now captures overlying merged column headings. Letâ€™s see if this
    improves things, first with temperature=0.0 â€¦
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: CSV æ–‡ä»¶ç°åœ¨æ•è·äº†å åŠ çš„åˆå¹¶åˆ—æ ‡é¢˜ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯å¦èƒ½æ”¹å–„æƒ…å†µï¼Œé¦–å…ˆæ¸©åº¦=0.0 â€¦
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/780e6bd57ae7ca6db636a442ddae67c0.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/780e6bd57ae7ca6db636a442ddae67c0.png)'
- en: And the same, but with temperature=1.0, just for fun â€¦
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ ·çš„ï¼Œä½†æ¸©åº¦=1.0ï¼Œåªæ˜¯ä¸ºäº†å¥½ç© â€¦
- en: '![](../Images/f2a7e421879c0e4b08e1525b6576b50e.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2a7e421879c0e4b08e1525b6576b50e.png)'
- en: A bit better, but there is always *something* a bit off. A missing category,
    cell values shifted, and neither table is usable if we require an accurate representation
    of the source data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨å¾®å¥½äº†ä¸€äº›ï¼Œä½†æ€»æ˜¯*æœ‰äº›*åœ°æ–¹ä¸å¤ªå¯¹ã€‚ç¼ºå¤±çš„ç±»åˆ«ï¼Œå•å…ƒæ ¼å€¼åç§»ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦å‡†ç¡®è¡¨ç¤ºæºæ•°æ®ï¼Œä¸¤ä¸ªè¡¨æ ¼éƒ½æ— æ³•ä½¿ç”¨ã€‚
- en: 'At this point, I experimented with various combinations of:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤æ—¶ï¼Œæˆ‘å°è¯•äº†å„ç§ç»„åˆï¼š
- en: Prompts
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æç¤º
- en: Temperature
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸©åº¦
- en: Using Markdown, HTML, and CSV to define the input table
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Markdownã€HTML å’Œ CSV å®šä¹‰è¾“å…¥è¡¨æ ¼
- en: Prompting GPT-3 to generate the python for parsing rather than parsing the tables
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æç¤º GPT-3 ç”Ÿæˆç”¨äºè§£æçš„ Python ä»£ç ï¼Œè€Œä¸æ˜¯è§£æè¡¨æ ¼
- en: Occasionally the process was able to generate a table where column heading and
    values were perfect, but typically this required high temperature values and so
    wasnâ€™t reproducible. For the most part, results looked plausible but the data
    was incorrect.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶è¯¥è¿‡ç¨‹èƒ½å¤Ÿç”Ÿæˆåˆ—æ ‡é¢˜å’Œæ•°å€¼å®Œç¾çš„è¡¨æ ¼ï¼Œä½†é€šå¸¸è¿™éœ€è¦é«˜æ¸©åº¦å€¼ï¼Œå› æ­¤ä¸å¯é‡å¤ã€‚å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œç»“æœçœ‹èµ·æ¥åˆç†ï¼Œä½†æ•°æ®ä¸æ­£ç¡®ã€‚
- en: In fairness, we are really asking a lot of GPT-3 with what is a complicated
    zero-shot task. I am really impressed at how well it did, and perhaps with some
    better prompting and reframing of the problem â€” or GPT-4! â€” results may improve,
    but I wasnâ€™t able to achieve what was required.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å…¬å¹³åœ°è¯´ï¼Œæˆ‘ä»¬çœŸçš„å¯¹ GPT-3 æå‡ºäº†å¾ˆé«˜çš„è¦æ±‚ï¼Œè¿™æ˜¯ä¸€é¡¹å¤æ‚çš„é›¶æ ·æœ¬ä»»åŠ¡ã€‚æˆ‘å¯¹å®ƒçš„è¡¨ç°æ„Ÿåˆ°éå¸¸æ»¡æ„ï¼Œä¹Ÿè®¸é€šè¿‡æ›´å¥½çš„æç¤ºå’Œé—®é¢˜çš„é‡æ–°æ¡†å®š â€”â€” æˆ– GPT-4ï¼â€”â€”
    ç»“æœå¯èƒ½ä¼šæœ‰æ‰€æ”¹å–„ï¼Œä½†æˆ‘æ²¡æœ‰èƒ½å¤Ÿå®ç°æ‰€éœ€çš„ç»“æœã€‚
- en: '**Single-Shot Prompt**'
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**å•æ¬¡æç¤º**'
- en: Now, letâ€™s provide an example in the prompt. I took a similar Excel file from
    the Humanitarian Data Exchange â€¦
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨æç¤ºä¸­æä¾›ä¸€ä¸ªç¤ºä¾‹ã€‚æˆ‘ä»äººé“æ•°æ®äº¤æ¢è·å–äº†ä¸€ä¸ªç±»ä¼¼çš„ Excel æ–‡ä»¶ â€¦
- en: '![](../Images/b6734984ce006423ea85a20d05d2a155.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6734984ce006423ea85a20d05d2a155.png)'
- en: Table we will use for our example in single-shot prompt. This file was sourced
    from the [Humanitarian Data Exchange](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨å•æ¬¡æç¤ºä¸­ä½¿ç”¨çš„è¡¨æ ¼ã€‚æ­¤æ–‡ä»¶æ¥æºäº [äººé“æ•°æ®äº¤æ¢](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)
- en: We want this to be processed to look like this â€¦
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›è¿™è¢«å¤„ç†æˆå¦‚ä¸‹æ‰€ç¤º â€¦
- en: '![](../Images/7ee9f834c88fea08684d2810cfe5bd4f.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ee9f834c88fea08684d2810cfe5bd4f.png)'
- en: What our sample file should like after reformatting
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ç¤ºä¾‹æ–‡ä»¶åœ¨é‡æ–°æ ¼å¼åŒ–åçš„æ ·å­
- en: Obviously, this is an unrealistic â€˜Real worldâ€™ example, as the format and content
    are very similar to the table we are trying to process, but itâ€™s a good first
    test.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç„¶ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸åˆ‡å®é™…çš„â€œçœŸå®ä¸–ç•Œâ€ç¤ºä¾‹ï¼Œå› ä¸ºæ ¼å¼å’Œå†…å®¹ä¸æˆ‘ä»¬å°è¯•å¤„ç†çš„è¡¨æ ¼éå¸¸ç›¸ä¼¼ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åˆæ­¥æµ‹è¯•ã€‚
- en: Converting our input table to CSV and unmerging merged cells as described above,
    we get â€¦
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æˆ‘ä»¬çš„è¾“å…¥è¡¨æ ¼è½¬æ¢ä¸º CSV å¹¶å–æ¶ˆåˆå¹¶åˆå¹¶çš„å•å…ƒæ ¼ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬å¾—åˆ° â€¦
- en: '![](../Images/f68f7f17e4a196691c5f3dd6e854da4e.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f68f7f17e4a196691c5f3dd6e854da4e.png)'
- en: We can now construct our single-shot prompt (assuming a temperature of zero
    for reproducibility) â€¦
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥æ„å»ºæˆ‘ä»¬çš„å•æ¬¡æç¤ºï¼ˆå‡è®¾æ¸©åº¦ä¸ºé›¶ä»¥ä¾¿å¯é‡å¤ï¼‰ â€¦
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here is the generated prompt â€¦
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç”Ÿæˆçš„æç¤º â€¦
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: And here is the completion from GPT-3 converted to a dataframe for easier display
    â€¦
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ GPT-3 çš„å®Œæˆç»“æœï¼Œè½¬æ¢ä¸ºæ•°æ®æ¡†ä»¥ä¾¿æ›´å®¹æ˜“æ˜¾ç¤º â€¦
- en: '![](../Images/dce195b89914d22ee19d93cb75f89cf2.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dce195b89914d22ee19d93cb75f89cf2.png)'
- en: Generated table from single-shot prompt to reformat table with hierarchical
    headers (completion was a CSV, converted to a pandas dataframe here for easier
    display)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å•æ¬¡æç¤ºç”Ÿæˆçš„è¡¨æ ¼ï¼Œé‡æ–°æ ¼å¼åŒ–å…·æœ‰å±‚æ¬¡ç»“æ„æ ‡é¢˜çš„è¡¨æ ¼ï¼ˆå®Œæˆç»“æœæ˜¯ CSVï¼Œè¿™é‡Œä¸ºä¾¿äºå±•ç¤ºè½¬æ¢ä¸º pandas æ•°æ®æ¡†ï¼‰
- en: Nice! When provided an example, GPT-3 was able to reformat our new table perfectly.
    However, this isnâ€™t a great test because the example and test tables were very
    similar in structure and content, but itâ€™s interesting to note that even though
    the example did not have the Male/Female hierarchy, GPT-3 was able to collapse
    this extra level correctly.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼å½“æä¾›ä¸€ä¸ªç¤ºä¾‹æ—¶ï¼ŒGPT-3 èƒ½å¤Ÿå®Œç¾åœ°é‡æ–°æ ¼å¼åŒ–æˆ‘ä»¬çš„æ–°è¡¨æ ¼ã€‚ç„¶è€Œï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æµ‹è¯•ï¼Œå› ä¸ºç¤ºä¾‹è¡¨æ ¼å’Œæµ‹è¯•è¡¨æ ¼åœ¨ç»“æ„å’Œå†…å®¹ä¸Šéå¸¸ç›¸ä¼¼ï¼Œä½†æœ‰è¶£çš„æ˜¯ï¼Œå³ä½¿ç¤ºä¾‹ä¸­æ²¡æœ‰ç”·æ€§/å¥³æ€§çš„å±‚çº§ï¼ŒGPT-3
    ä»èƒ½æ­£ç¡®åœ°æŠ˜å è¿™ä¸ªé¢å¤–çš„å±‚çº§ã€‚
- en: Letâ€™s use the same example table to reformat a table that has a different layout
    and content data â€¦
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„ç¤ºä¾‹è¡¨æ ¼æ¥é‡æ–°æ ¼å¼åŒ–ä¸€ä¸ªå…·æœ‰ä¸åŒå¸ƒå±€å’Œå†…å®¹æ•°æ®çš„è¡¨æ ¼ â€¦
- en: '![](../Images/9e175fd03da4432492fa789dfb8f5f06.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e175fd03da4432492fa789dfb8f5f06.png)'
- en: When processed with the same code results in this â€¦
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç›¸åŒçš„ä»£ç å¤„ç†å¾—åˆ°çš„æ˜¯ â€¦
- en: '![](../Images/4362466354eb63c092183ca9952b5ba1.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4362466354eb63c092183ca9952b5ba1.png)'
- en: Which is close, the headings are spot on, but the farm column has shifted to
    the left. Our single-shot prompt does quite well for reformatting very similar
    tables, but slight variation leads to poor results.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆæ¥è¿‘ï¼Œæ ‡é¢˜å®Œå…¨æ­£ç¡®ï¼Œä½†å†œåœºåˆ—å‘å·¦ç§»åŠ¨äº†ã€‚æˆ‘ä»¬çš„å•æ¬¡æç¤ºåœ¨é‡æ–°æ ¼å¼åŒ–éå¸¸ç›¸ä¼¼çš„è¡¨æ ¼æ—¶è¡¨ç°ä¸é”™ï¼Œä½†ç¨å¾®çš„å˜åŒ–å¯¼è‡´äº†è¾ƒå·®çš„ç»“æœã€‚
- en: Single-Shot, with reasoning
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å•æ¬¡æç¤ºï¼Œå¸¦æœ‰æ¨ç†
- en: There has been quite a bit of research already around prompt engineering. A
    really great resource can be found in the OpenAI Cookbookâ€™s [Techniques to Improve
    Reliability](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
    [3]. One of the most effective methods to improve results is to include reasoning
    in the example prompt [[4](https://arxiv.org/abs/2205.11916)]. Using our previous
    table, letâ€™s adjust the prompt to include reasoning â€¦
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºæç¤ºå·¥ç¨‹å·²ç»æœ‰ç›¸å½“å¤šçš„ç ”ç©¶ã€‚ä¸€ä¸ªéå¸¸å¥½çš„èµ„æºå¯ä»¥åœ¨ OpenAI Cookbook çš„ [æå‡å¯é æ€§çš„æŠ€æœ¯](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
    [3] ä¸­æ‰¾åˆ°ã€‚æé«˜ç»“æœçš„æœ€æœ‰æ•ˆæ–¹æ³•ä¹‹ä¸€æ˜¯åŒ…å«æ¨ç†åœ¨ç¤ºä¾‹æç¤ºä¸­ [[4](https://arxiv.org/abs/2205.11916)]ã€‚ä»¥æˆ‘ä»¬ä¹‹å‰çš„è¡¨æ ¼ä¸ºä¾‹ï¼Œè°ƒæ•´æç¤ºä»¥åŒ…æ‹¬æ¨ç†
    â€¦
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The full prompt looks like this â€¦
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæ•´çš„æç¤ºå¦‚ä¸‹ â€¦
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Which results in this completion from GPT-3 for our input table â€¦
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´ GPT-3 å¯¹æˆ‘ä»¬è¾“å…¥è¡¨æ ¼çš„å®Œæˆç»“æœæ˜¯ â€¦
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Itâ€™s correct! The reformatted table is exactly what we wanted â€¦
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆæ­£ç¡®ï¼é‡æ–°æ ¼å¼åŒ–åçš„è¡¨æ ¼æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ â€¦
- en: '![](../Images/b44674a075c338a587502b102c6d2ca1.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b44674a075c338a587502b102c6d2ca1.png)'
- en: Results are improved if we provide reasoning in the single-shot prompt
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬åœ¨å•æ¬¡æç¤ºä¸­æä¾›æ¨ç†ï¼Œç»“æœä¼šæœ‰æ‰€æ”¹å–„
- en: That said, the task we have provided isnâ€™t that great because even though the
    content is different to the provided example, the heading layout is still quite
    similar. In fact, if we tweak the table we want to reformat a little and add an
    extra column â€˜Organicâ€™ â€¦
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æä¾›çš„ä»»åŠ¡å¹¶ä¸æ˜¯å¾ˆå¥½ï¼Œå› ä¸ºå°½ç®¡å†…å®¹ä¸æä¾›çš„ç¤ºä¾‹ä¸åŒï¼Œä½†æ ‡é¢˜å¸ƒå±€ä»ç„¶ç›¸ä¼¼ã€‚äº‹å®ä¸Šï¼Œå¦‚æœæˆ‘ä»¬ç¨å¾®è°ƒæ•´ä¸€ä¸‹è¦é‡æ–°æ ¼å¼åŒ–çš„è¡¨æ ¼å¹¶æ·»åŠ ä¸€ä¸ªé¢å¤–çš„â€œæœ‰æœºâ€åˆ—
    â€¦
- en: '![](../Images/886cf8bea9babb627b68d1e2fa6fb8d2.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/886cf8bea9babb627b68d1e2fa6fb8d2.png)'
- en: Adding an extra column to the input
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å‘è¾“å…¥ä¸­æ·»åŠ ä¸€ä¸ªé¢å¤–çš„åˆ—
- en: The prediction is now incorrect â€¦
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: é¢„æµ‹ç°åœ¨ä¸æ­£ç¡® â€¦
- en: '![](../Images/cbfa4266f749d5f3981baee97d382890.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cbfa4266f749d5f3981baee97d382890.png)'
- en: Only off by just *one* extra comma in the title row, but this results in everything
    being shifted to the right.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: åªæ˜¯æ ‡é¢˜è¡Œä¸­å¤šäº†*ä¸€ä¸ª*é¢å¤–çš„é€—å·ï¼Œè¿™å¯¼è‡´æ‰€æœ‰å†…å®¹å‘å³ç§»åŠ¨ã€‚
- en: We might continue to engineer the prompt with more reasoning or apply [more
    advanced techniques](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
    to automatically structure our prompt workflow, but the real issue is that one
    example isnâ€™t really enough to capture all the variations of table formats we
    might encounter. Itâ€™s amazing how well GPT-3 does even with one example, but itâ€™s
    not yet good enough for production for this task (at least how it has been framed
    so far).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯èƒ½ä¼šç»§ç»­é€šè¿‡æ›´å¤šæ¨ç†æ¥ä¼˜åŒ–æç¤ºï¼Œæˆ–åº”ç”¨ [æ›´é«˜çº§çš„æŠ€æœ¯](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
    è‡ªåŠ¨æ„å»ºæˆ‘ä»¬çš„æç¤ºå·¥ä½œæµï¼Œä½†çœŸæ­£çš„é—®é¢˜æ˜¯ä¸€ä¸ªç¤ºä¾‹å¹¶ä¸è¶³ä»¥æ•æ‰æˆ‘ä»¬å¯èƒ½é‡åˆ°çš„æ‰€æœ‰è¡¨æ ¼æ ¼å¼å˜ä½“ã€‚å°½ç®¡ GPT-3 åœ¨ä»…æœ‰ä¸€ä¸ªç¤ºä¾‹çš„æƒ…å†µä¸‹è¡¨ç°å¾—éå¸¸å¥½ï¼Œä½†å¯¹äºè¿™ä¸ªä»»åŠ¡æ¥è¯´ï¼Œå®ƒè¿˜ä¸å¤Ÿå¥½ï¼ˆè‡³å°‘å°±ç›®å‰çš„æ¡†æ¶è€Œè¨€ï¼‰ã€‚
- en: Few-Shot â€¦. err, or not
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å°‘é‡ç¤ºä¾‹â€¦. æˆ–è€…è¯´ä¸æ˜¯
- en: The next approach might be to provide more than a single example. However, table
    excerpts require a lot of tokens (more on this later), so if we have to provide
    multiple examples in a prompt, plus the tokens in the result, we start to hit
    the Open APIs token limits. For the davinci model this is currently set at [4,000](https://platform.openai.com/docs/models/gpt-3)
    tokens. Also, since we are charged by token it can get expensive to send and receive
    a lot of tokens for a small non-profit like [DataKind](https://www.datakind.org/).
    There are also performance implications with longer prompts, so few-shot prompts
    were not explored for this task.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹ä¸€ä¸ªæ–¹æ³•å¯èƒ½æ˜¯æä¾›å¤šä¸ªç¤ºä¾‹ã€‚ç„¶è€Œï¼Œè¡¨æ ¼ç‰‡æ®µéœ€è¦å¤§é‡çš„ä»¤ç‰Œï¼ˆç¨åä¼šè¯¦ç»†è¯´æ˜ï¼‰ï¼Œæ‰€ä»¥å¦‚æœæˆ‘ä»¬å¿…é¡»åœ¨æç¤ºä¸­æä¾›å¤šä¸ªç¤ºä¾‹ï¼Œå†åŠ ä¸Šç»“æœä¸­çš„ä»¤ç‰Œï¼Œå°±ä¼šè§¦åŠOpen
    APIçš„ä»¤ç‰Œé™åˆ¶ã€‚å¯¹äºdavinciæ¨¡å‹ï¼Œç›®å‰çš„é™åˆ¶ä¸º[4,000](https://platform.openai.com/docs/models/gpt-3)ä¸ªä»¤ç‰Œã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬æŒ‰ä»¤ç‰Œæ”¶è´¹ï¼Œå¯¹äºåƒ[DataKind](https://www.datakind.org/)è¿™æ ·çš„å°å‹éè¥åˆ©ç»„ç»‡ï¼Œå‘é€å’Œæ¥æ”¶å¤§é‡ä»¤ç‰Œå¯èƒ½ä¼šå˜å¾—æ˜‚è´µã€‚æ›´é•¿çš„æç¤ºè¿˜æœ‰æ€§èƒ½å½±å“ï¼Œå› æ­¤å¯¹äºè¿™ä¸ªä»»åŠ¡æ²¡æœ‰æ¢ç´¢å°‘æ ·æœ¬æç¤ºã€‚
- en: So I decided to skip few-shot for now.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥æˆ‘å†³å®šæš‚æ—¶è·³è¿‡å°‘æ ·æœ¬å­¦ä¹ ã€‚
- en: Fine-tuning
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¾®è°ƒ
- en: It was interesting to explore zero- and single-shot prompts, and had that worked
    for this use-case it would have been an amazing result. In future, as models improve
    this may well become a viable option, but for now, it might make sense to reframe
    the task a little.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢ç´¢é›¶æ ·æœ¬å’Œå•æ ·æœ¬æç¤ºå¾ˆæœ‰è¶£ï¼Œå¦‚æœè¿™äº›æ–¹æ³•åœ¨è¿™ä¸ªç”¨ä¾‹ä¸­æœ‰æ•ˆï¼Œå°†ä¼šå–å¾—æƒŠäººçš„ç»“æœã€‚æœªæ¥ï¼Œéšç€æ¨¡å‹çš„æ”¹è¿›ï¼Œè¿™å¯èƒ½ä¼šæˆä¸ºä¸€ä¸ªå¯è¡Œçš„é€‰é¡¹ï¼Œä½†ç›®å‰ï¼Œé‡æ–°å®šä¹‰ä»»åŠ¡å¯èƒ½æ›´æœ‰æ„ä¹‰ã€‚
- en: 'Another approach is to provide *lots* of examples through [fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
    As OpenAI note:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡[å¾®è°ƒ](https://platform.openai.com/docs/guides/fine-tuning)æä¾›*å¤§é‡*ç¤ºä¾‹ã€‚æ­£å¦‚OpenAIæ‰€è¿°ï¼š
- en: '*Fine-tuning lets you get more out of the models available through the API
    by providing:*'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¾®è°ƒå¯ä»¥é€šè¿‡æä¾›ä»¥ä¸‹å†…å®¹æ¥è®©ä½ æ›´å¥½åœ°åˆ©ç”¨APIæä¾›çš„æ¨¡å‹ï¼š*'
- en: '*Higher quality results than prompt design*'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ¯”æç¤ºè®¾è®¡äº§ç”Ÿæ›´é«˜è´¨é‡çš„ç»“æœ*'
- en: '*Ability to train on more examples than can fit in a prompt*'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*èƒ½å¤Ÿåœ¨æ¯”æç¤ºä¸­èƒ½å®¹çº³çš„æ›´å¤šç¤ºä¾‹ä¸Šè¿›è¡Œè®­ç»ƒ*'
- en: '*Token savings due to shorter prompts*'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç”±äºæç¤ºè¾ƒçŸ­è€ŒèŠ‚çœä»¤ç‰Œ*'
- en: '*Lower latency requests*'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ›´ä½å»¶è¿Ÿçš„è¯·æ±‚*'
- en: At first, I considered fine-tuning by providing GPT-3 (i) prompts of the raw
    table (with merged cells unmerged) and; (ii) completions being the reformatted
    table. The challenge with this approach however is that it still uses a lot of
    tokens, especially as we are now going to use hundreds of examples.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: èµ·åˆï¼Œæˆ‘è€ƒè™‘é€šè¿‡æä¾›GPT-3ï¼ˆiï¼‰åŸå§‹è¡¨æ ¼çš„æç¤ºï¼ˆåˆå¹¶å•å…ƒæ ¼æœªåˆå¹¶ï¼‰å’Œï¼ˆiiï¼‰ä½œä¸ºé‡æ–°æ ¼å¼åŒ–è¡¨æ ¼çš„å®Œæˆé¡¹æ¥è¿›è¡Œå¾®è°ƒã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•çš„æŒ‘æˆ˜åœ¨äºï¼Œå®ƒä»ç„¶ä½¿ç”¨äº†å¤§é‡çš„ä»¤ç‰Œï¼Œå°¤å…¶æ˜¯æˆ‘ä»¬ç°åœ¨éœ€è¦ä½¿ç”¨æ•°ç™¾ä¸ªç¤ºä¾‹ã€‚
- en: Instead of passing in raw table excerpts, letâ€™s try using attributes of that
    table and have GPT-3 predict key further attributes which we can use for parsing
    â€¦
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä¼ é€’åŸå§‹è¡¨æ ¼ç‰‡æ®µï¼Œä¸å¦‚å°è¯•ä½¿ç”¨è¯¥è¡¨æ ¼çš„å±æ€§ï¼Œå¹¶è®©GPT-3é¢„æµ‹æˆ‘ä»¬å¯ä»¥ç”¨æ¥è§£æçš„å…³é”®è¿›ä¸€æ­¥å±æ€§â€¦â€¦
- en: Reframing the Task â€” Using Table Attributes as Prompts
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é‡æ–°å®šä¹‰ä»»åŠ¡ â€” ä½¿ç”¨è¡¨æ ¼å±æ€§ä½œä¸ºæç¤º
- en: As a human (well, *mostly* human), when I scan a table in Excel I am able to
    pick out the structure by looking at the values and making a decision about where
    the data resides.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€ä¸ªäººï¼ˆå¥½å§ï¼Œ*å¤§éƒ¨åˆ†*æ˜¯äººï¼‰ï¼Œå½“æˆ‘æ‰«æExcelä¸­çš„è¡¨æ ¼æ—¶ï¼Œæˆ‘å¯ä»¥é€šè¿‡æŸ¥çœ‹å€¼æ¥è¯†åˆ«ç»“æ„ï¼Œå¹¶å†³å®šæ•°æ®çš„ä½ç½®ã€‚
- en: '![](../Images/0b92fbbdfffa07263c0ca4bafb60f3c6.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b92fbbdfffa07263c0ca4bafb60f3c6.png)'
- en: Identifying the data section in a table is key to parsing into a regular tabular
    structure
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šè¡¨æ ¼ä¸­çš„æ•°æ®éƒ¨åˆ†æ˜¯å°†å…¶è§£ææˆè§„åˆ™è¡¨æ ¼ç»“æ„çš„å…³é”®
- en: Once I know the row at which data begins, itâ€™s straightforward to deduce heading
    hierarchies from the rows above and collapse them into a single header row in
    order to create a nice, regular table to use â€¦
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘çŸ¥é“æ•°æ®å¼€å§‹çš„è¡Œï¼Œå°±å¾ˆå®¹æ˜“ä»ä¸Šé¢çš„è¡Œæ¨æ–­å‡ºæ ‡é¢˜å±‚æ¬¡ï¼Œå¹¶å°†å®ƒä»¬åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„æ ‡é¢˜è¡Œï¼Œä»¥åˆ›å»ºä¸€ä¸ªæ•´é½ã€è§„åˆ™çš„è¡¨æ ¼æ¥ä½¿ç”¨â€¦â€¦
- en: '![](../Images/81f481c588bb27c7779ca9dfc6c34b54.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81f481c588bb27c7779ca9dfc6c34b54.png)'
- en: Processed table with flat headings, easily imported into a relational database
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†åçš„è¡¨æ ¼å…·æœ‰å¹³é¢æ ‡é¢˜ï¼Œå®¹æ˜“å¯¼å…¥å…³ç³»æ•°æ®åº“
- en: Identifying where the data begins at first seems trivial with a bit of manipulation
    in [openpyxl](https://openpyxl.readthedocs.io/en/stable/) or [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html).
    However, if working through tens of thousands of spreadsheets with different heading
    layouts, blank rows, and more, it can be challenging to develop a set of rules
    which can be used to identify exactly where the data starts in every sheet.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šæ•°æ®çš„å¼€å§‹ä½ç½®ä¹ä¸€çœ‹ä¼¼ä¹å¾ˆç®€å•ï¼Œåªéœ€åœ¨ [openpyxl](https://openpyxl.readthedocs.io/en/stable/)
    æˆ– [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)
    ä¸­ç¨ä½œå¤„ç†å³å¯ã€‚ç„¶è€Œï¼Œå¦‚æœéœ€è¦å¤„ç†æˆåƒä¸Šä¸‡çš„å…·æœ‰ä¸åŒæ ‡é¢˜å¸ƒå±€ã€ç©ºç™½è¡Œç­‰çš„ç”µå­è¡¨æ ¼ï¼Œå¼€å‘ä¸€å¥—ç”¨äºå‡†ç¡®è¯†åˆ«æ¯ä¸ªå·¥ä½œè¡¨ä¸­æ•°æ®å¼€å§‹ä½ç½®çš„è§„åˆ™å°†æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚
- en: 'Itâ€™s complicated because:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆå¤æ‚ï¼Œå› ä¸ºï¼š
- en: Column headings can have a high degree of variability and look like data
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ—æ ‡é¢˜å¯èƒ½æœ‰å¾ˆé«˜çš„å˜åŒ–æ€§ï¼Œçœ‹èµ·æ¥åƒæ•°æ®ã€‚
- en: Blank cells and annotations can confusing parsing rules easily
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç©ºç™½å•å…ƒæ ¼å’Œæ³¨é‡Šå®¹æ˜“æ··æ·†è§£æè§„åˆ™ã€‚
- en: Data isnâ€™t always numeric, it can be categorical and look a lot like column
    headings
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®ä¸æ€»æ˜¯æ•°å­—çš„ï¼Œå®ƒå¯ä»¥æ˜¯åˆ†ç±»çš„ï¼Œçœ‹èµ·æ¥å¾ˆåƒåˆ—æ ‡é¢˜ã€‚
- en: Some column headings are numbers and can look like data, for example, years
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€äº›åˆ—æ ‡é¢˜æ˜¯æ•°å­—ï¼Œå¯èƒ½çœ‹èµ·æ¥åƒæ•°æ®ï¼Œä¾‹å¦‚å¹´ä»½ã€‚
- en: So what table attributes/features should we use to predict the row number where
    data first occurs?
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªäº›è¡¨æ ¼å±æ€§/ç‰¹å¾æ¥é¢„æµ‹æ•°æ®é¦–æ¬¡å‡ºç°çš„è¡Œå·å‘¢ï¼Ÿ
- en: I came up with a short list of table attributes I thought might might be useful
    â€¦
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åˆ—å‡ºäº†ä¸€ä¸ªæˆ‘è®¤ä¸ºå¯èƒ½æœ‰ç”¨çš„è¡¨æ ¼å±æ€§çš„ç®€çŸ­æ¸…å•â€¦â€¦
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Which gives output like this â€¦
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šäº§ç”Ÿè¿™æ ·çš„è¾“å‡ºâ€¦â€¦
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: These will be our prompts for fine-tuning the model.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å°†æ˜¯æˆ‘ä»¬ç”¨äºå¾®è°ƒæ¨¡å‹çš„æç¤ºã€‚
- en: To create completions for the fine-tuning file, I used the Humanitarian Data
    Exchange dataset for Kenya (see [here](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)
    for more details of how I extracted Excel files). Parsing files and looping through
    sheets in each, I generated prompts.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åˆ›å»ºå¾®è°ƒæ–‡ä»¶çš„è¡¥å…¨ï¼Œæˆ‘ä½¿ç”¨äº†è‚¯å°¼äºšçš„äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢æ•°æ®é›†ï¼ˆæœ‰å…³å¦‚ä½•æå– Excel æ–‡ä»¶çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è§[è¿™é‡Œ](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)ï¼‰ã€‚è§£ææ–‡ä»¶å¹¶å¾ªç¯éå†æ¯ä¸ªå·¥ä½œè¡¨ï¼Œæˆ‘ç”Ÿæˆäº†æç¤ºã€‚
- en: I used the following logic to create estimates of the row data starts on a sheet
    using the table parameters above â€¦
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨äº†ä»¥ä¸‹é€»è¾‘æ¥ä¼°ç®—æ•°æ®å¼€å§‹çš„è¡Œå·ï¼Œä½¿ç”¨äº†ä¸Šè¿°è¡¨æ ¼å‚æ•°â€¦â€¦
- en: '[PRE17]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This rule-based approach actually does a pretty good job, but it is not perfect,
    hence the need for GPT-3\. However, itâ€™s handy for creating a test set where most
    of the completions are accurate, I then only have to adjust a few where the logic
    above does not hold.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§åŸºäºè§„åˆ™çš„æ–¹æ³•å®é™…ä¸Šè¡¨ç°å¾—ç›¸å½“ä¸é”™ï¼Œä½†å®ƒå¹¶ä¸å®Œç¾ï¼Œå› æ­¤éœ€è¦ GPT-3ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒåœ¨åˆ›å»ºä¸€ä¸ªå¤§å¤šæ•°è¡¥å…¨éƒ½å‡†ç¡®çš„æµ‹è¯•é›†æ—¶å¾ˆæœ‰ç”¨ï¼Œæˆ‘åªéœ€è°ƒæ•´å‡ ä¸ªé€»è¾‘ä¸æˆç«‹çš„éƒ¨åˆ†å³å¯ã€‚
- en: For my training set, I used one table per organization from multiple Excel sheets
    labelled â€˜Kenyaâ€™ from 10 humanitarian provider organizations, where the prediction
    of the first data row was made using the rule-based approach above. I then reviewed
    this list and compared with the actual sheets to make corrections where the spreadsheet
    table started on a different row. I excluded cases where there were multiple tables
    on a sheet for this study, after which I had 232 fine-tuning prompts like this
    â€¦
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘çš„è®­ç»ƒé›†ï¼Œæˆ‘ä½¿ç”¨äº†æ¥è‡ª 10 ä¸ªäººé“ä¸»ä¹‰æä¾›ç»„ç»‡çš„å¤šä¸ªæ ‡è®°ä¸ºâ€œKenyaâ€çš„ Excel è¡¨æ ¼ä¸­çš„æ¯ä¸ªç»„ç»‡çš„ä¸€ä¸ªè¡¨æ ¼ï¼Œå…¶ä¸­ä½¿ç”¨ä¸Šè¿°åŸºäºè§„åˆ™çš„æ–¹æ³•è¿›è¡Œäº†é¦–æ¬¡æ•°æ®è¡Œçš„é¢„æµ‹ã€‚æˆ‘éšåå®¡æŸ¥äº†è¿™ä»½æ¸…å•ï¼Œå¹¶ä¸å®é™…çš„å·¥ä½œè¡¨è¿›è¡Œäº†æ¯”è¾ƒï¼Œä»¥çº æ­£ç”µå­è¡¨æ ¼è¡¨æ ¼å¼€å§‹äºä¸åŒçš„è¡Œçš„æƒ…å†µã€‚æˆ‘æ’é™¤äº†æœ¬ç ”ç©¶ä¸­å­˜åœ¨å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µï¼Œæ­¤åæˆ‘å¾—åˆ°äº†
    232 ä¸ªè¿™æ ·çš„å¾®è°ƒæç¤ºâ€¦â€¦
- en: '[PRE18]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Side Note**: In the above you might notice Iâ€™ve added a â€˜meta_dataâ€™ element
    to each prompt. This isnâ€™t part of the required JSONL prompt record, but I include
    this to be able to easily associate each prompt with a file for debugging. The
    prompt file still seems to be accepted by OpenAI with this extra data, I think
    as long as there are â€˜promptâ€™ and â€˜completionâ€™ elements, itâ€™s happy!'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™„æ³¨**ï¼šåœ¨ä¸Šé¢çš„å†…å®¹ä¸­ï¼Œä½ å¯èƒ½æ³¨æ„åˆ°æˆ‘ä¸ºæ¯ä¸ªæç¤ºæ·»åŠ äº†ä¸€ä¸ªâ€œmeta_dataâ€å…ƒç´ ã€‚è¿™ä¸æ˜¯ JSONL æç¤ºè®°å½•çš„å¿…è¦éƒ¨åˆ†ï¼Œä½†æˆ‘è¿™æ ·åšæ˜¯ä¸ºäº†èƒ½å¤Ÿè½»æ¾å°†æ¯ä¸ªæç¤ºä¸æ–‡ä»¶å…³è”ä»¥ä¾¿äºè°ƒè¯•ã€‚åŒ…å«è¿™äº›é¢å¤–æ•°æ®çš„æç¤ºæ–‡ä»¶ä¼¼ä¹ä»ç„¶è¢«
    OpenAI æ¥å—ï¼Œæˆ‘è®¤ä¸ºåªè¦æœ‰â€œpromptâ€å’Œâ€œcompletionâ€å…ƒç´ ï¼Œå®ƒå°±ä¼šæ¥å—ï¼'
- en: I then fine-tuned a DaVinci model â€¦
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘å¾®è°ƒäº†ä¸€ä¸ª DaVinci æ¨¡å‹â€¦â€¦
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: I manually checked fine-tuning status as follows â€¦
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ‰‹åŠ¨æ£€æŸ¥äº†å¾®è°ƒçŠ¶æ€ï¼Œå¦‚ä¸‹æ‰€ç¤ºâ€¦â€¦
- en: '[PRE20]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Then once finished, retrieved the model â€¦
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå®Œæˆåï¼Œæ£€ç´¢äº†æ¨¡å‹â€¦â€¦
- en: '[PRE21]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: For the test set I used one table from each Excel file sourced from organizations
    not in the training set (labeled â€˜Kenyaâ€™), first running the rule-based prediction
    above to generate prompts and completions and then correcting where this returned
    incorrect values. Again, excluding cases where multiple tables were specified
    on an excel sheet. This gave me a test set of 72 prompts.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæµ‹è¯•é›†ï¼Œæˆ‘ä½¿ç”¨äº†æ¥è‡ªè®­ç»ƒé›†ä¹‹å¤–ç»„ç»‡ï¼ˆæ ‡è®°ä¸ºâ€˜è‚¯å°¼äºšâ€™ï¼‰çš„æ¯ä¸ª Excel æ–‡ä»¶ä¸­çš„ä¸€ä¸ªè¡¨æ ¼ï¼Œé¦–å…ˆè¿è¡Œä¸Šè¿°åŸºäºè§„åˆ™çš„é¢„æµ‹ç”Ÿæˆæç¤ºå’Œå®Œæˆé¡¹ï¼Œç„¶åçº æ­£è¿”å›çš„é”™è¯¯å€¼ã€‚å†æ¬¡æ’é™¤æŒ‡å®šäº†å¤šä¸ªè¡¨æ ¼çš„
    Excel è¡¨æ ¼ã€‚è¿™ç»™æˆ‘æä¾›äº† 72 ä¸ªæç¤ºçš„æµ‹è¯•é›†ã€‚
- en: '[PRE22]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '**Side Note:** In [my previous blog post](https://medium.com/towards-data-science/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)
    to predict HXL tags, I had to filter completions by log probability, but in this
    study it wasnâ€™t required.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™„æ³¨ï¼š** åœ¨[æˆ‘ä¹‹å‰çš„åšå®¢æ–‡ç« ](https://medium.com/towards-data-science/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)ä¸­é¢„æµ‹
    HXL æ ‡ç­¾æ—¶ï¼Œæˆ‘å¿…é¡»é€šè¿‡å¯¹æ•°æ¦‚ç‡è¿‡æ»¤å®Œæˆé¡¹ï¼Œä½†åœ¨è¿™é¡¹ç ”ç©¶ä¸­æ²¡æœ‰å¿…è¦ã€‚'
- en: GPT-3 predicted the first data row on sheets in our test set with the following
    results â€¦
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 åœ¨æˆ‘ä»¬çš„æµ‹è¯•é›†ä¸­é¢„æµ‹äº†ç¬¬ä¸€è¡Œæ•°æ®çš„ç»“æœå¦‚ä¸‹â€¦â€¦
- en: '[PRE23]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: So GPT-3 does a nice job of predicting where the first data row is.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ GPT-3 åœ¨é¢„æµ‹ç¬¬ä¸€è¡Œæ•°æ®çš„ä½ç½®ä¸Šè¡¨ç°ä¸é”™ã€‚
- en: Putting it All Together
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»¼åˆèµ·æ¥
- en: '**Step 1 â€” Read in our data**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 1 â€” è¯»å–æˆ‘ä»¬çš„æ•°æ®**'
- en: '![](../Images/9f631ffdb4c440854098cc64a07b849b.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f631ffdb4c440854098cc64a07b849b.png)'
- en: Example spreadsheet, with varying hierarchical headers and notes in cells
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ç”µå­è¡¨æ ¼ï¼Œå…·æœ‰ä¸åŒçš„å±‚çº§æ ‡é¢˜å’Œå•å…ƒæ ¼ä¸­çš„å¤‡æ³¨
- en: '**Step 2 â€” Unmerge merged columns and populate with merged value**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 2 â€” å–æ¶ˆåˆå¹¶çš„åˆ—å¹¶å¡«å……åˆå¹¶å€¼**'
- en: '![](../Images/e9623db509bee6348ad8d47e1441e67a.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9623db509bee6348ad8d47e1441e67a.png)'
- en: Pandas dataframe of sheet after being processed by function â€˜pad_merged_cellsâ€™
    to unmerge and fill with merged values
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas æ•°æ®æ¡†åœ¨é€šè¿‡â€˜pad_merged_cellsâ€™å‡½æ•°å¤„ç†åï¼Œç”¨äºå–æ¶ˆåˆå¹¶å¹¶å¡«å……åˆå¹¶å€¼
- en: '**Step 3 â€” Calculate table parameters to generate GPT-3 prompt**'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 3 â€” è®¡ç®—è¡¨æ ¼å‚æ•°ä»¥ç”Ÿæˆ GPT-3 æç¤º**'
- en: '[PRE24]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '**Step 4 â€” Call GPT-3 to predict where the data row starts**'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 4 â€” è°ƒç”¨ GPT-3 é¢„æµ‹æ•°æ®è¡Œçš„èµ·å§‹ä½ç½®**'
- en: '[PRE25]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '**Step 5 â€” now we have the row data begins, concatenate column headings above
    this into one row**'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 5 â€” ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†æ•°æ®è¡Œçš„å¼€å§‹ä½ç½®ï¼Œå°†ä¸Šæ–¹çš„åˆ—æ ‡é¢˜è¿æ¥æˆä¸€è¡Œ**'
- en: '![](../Images/457ae2d038f5792578767b18b888aef2.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/457ae2d038f5792578767b18b888aef2.png)'
- en: Parsed sheet, with collapsed hierarchical columns, no random labels. This can
    now be imported into a database
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: è§£æåçš„è¡¨æ ¼ï¼Œå…·æœ‰æŠ˜å çš„å±‚çº§åˆ—ï¼Œæ²¡æœ‰éšæœºæ ‡ç­¾ã€‚ç°åœ¨å¯ä»¥å¯¼å…¥åˆ°æ•°æ®åº“ä¸­ã€‚
- en: This is a nice table we can upload into a relational database. See references
    section below for the full code.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥ä¸Šä¼ åˆ°å…³ç³»æ•°æ®åº“çš„å¥½è¡¨æ ¼ã€‚æœ‰å…³å®Œæ•´ä»£ç ï¼Œè¯·å‚è§ä¸‹é¢çš„å‚è€ƒéƒ¨åˆ†ã€‚
- en: Admittedly, it would be easy to manually parse this sheet manually, even specify
    some rules related to the table parameters we found, but the point of the above
    process is that it can be applied to a wide range of table layouts needed for
    analyzing the thousands of Excel sheets in the Humanitarian Data Exchange datasets.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: è¯šç„¶ï¼Œæ‰‹åŠ¨è§£æè¿™ä¸ªè¡¨æ ¼å¹¶æŒ‡å®šä¸€äº›ä¸æˆ‘ä»¬å‘ç°çš„è¡¨æ ¼å‚æ•°ç›¸å…³çš„è§„åˆ™æ˜¯å¾ˆå®¹æ˜“çš„ï¼Œä½†ä¸Šè¿°è¿‡ç¨‹çš„é‡ç‚¹æ˜¯å®ƒå¯ä»¥åº”ç”¨äºäººé“ä¸»ä¹‰æ•°æ®äº¤æ¢æ•°æ®é›†ä¸­æˆåƒä¸Šä¸‡çš„ Excel
    è¡¨æ ¼çš„å¹¿æ³›è¡¨æ ¼å¸ƒå±€ã€‚
- en: Conclusions and Future Work
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®ºä¸æœªæ¥å·¥ä½œ
- en: Though there is great potential in zero- and single-shot prompting in general,
    they did not work out just yet for this particular task when prompted with CSV
    tables. As Large Language Models advance this will likely change â€” Iâ€™m excited
    to see what GPT-4 might be capable of â€” but for now, it seems that fine-tuning
    is a better option, predicting key table attributes which can be used in reformatting.
    This method does of course require some pre-processing in order to determine table
    parameters for the prompt. Itâ€™s also worth noting that in using table â€˜featuresâ€™
    it starts to look more like a classification task than text completion, and might
    be better framed that way. Irrespective, the technique performs well using the
    Humanitarian Data Exchange Excel files.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡é›¶æ¬¡å’Œä¸€æ¬¡æç¤ºå…·æœ‰å¾ˆå¤§çš„æ½œåŠ›ï¼Œä½†åœ¨ç”¨ CSV è¡¨æ ¼è¿›è¡Œæç¤ºæ—¶ï¼Œè¿™ç§æ–¹æ³•å°šæœªå¯¹è¿™ä¸ªç‰¹å®šä»»åŠ¡å¥æ•ˆã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥ï¼Œè¿™ç§æƒ…å†µå¯èƒ½ä¼šæ”¹å˜â€”â€”æˆ‘å¾ˆæœŸå¾…
    GPT-4 çš„è¡¨ç°â€”â€”ä½†ç›®å‰çœ‹æ¥ï¼Œå¾®è°ƒæ˜¯æ›´å¥½çš„é€‰æ‹©ï¼Œå®ƒå¯ä»¥é¢„æµ‹å…³é”®çš„è¡¨æ ¼å±æ€§ï¼Œç”¨äºé‡æ–°æ ¼å¼åŒ–ã€‚å½“ç„¶ï¼Œè¿™ç§æ–¹æ³•éœ€è¦ä¸€äº›é¢„å¤„ç†ï¼Œä»¥ç¡®å®šæç¤ºçš„è¡¨æ ¼å‚æ•°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨è¡¨æ ¼â€˜ç‰¹å¾â€™æ—¶ï¼Œå®ƒæ›´åƒæ˜¯åˆ†ç±»ä»»åŠ¡è€Œä¸æ˜¯æ–‡æœ¬å®Œæˆï¼Œå¯èƒ½ä¼šæ›´é€‚åˆè¿™æ ·æ¡†æ¶ã€‚ä¸è¿‡ï¼Œæ— è®ºå¦‚ä½•ï¼Œè¿™ç§æŠ€æœ¯åœ¨ä½¿ç”¨äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢
    Excel æ–‡ä»¶æ—¶è¡¨ç°è‰¯å¥½ã€‚
- en: I think it would be really interesting to extend this work to also handle cases
    where Excel sheets have multiple tables on any given sheet. This would require
    more table features than Iâ€™ve used in this study, such as cell formatting and
    column (rather than row) attributes.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºå°†è¿™é¡¹å·¥ä½œæ‰©å±•åˆ°å¤„ç† Excel å·¥ä½œè¡¨ä¸Šæœ‰å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µå°†éå¸¸æœ‰è¶£ã€‚è¿™éœ€è¦æ¯”æˆ‘åœ¨è¿™é¡¹ç ”ç©¶ä¸­ä½¿ç”¨çš„æ›´å¤šçš„è¡¨æ ¼ç‰¹å¾ï¼Œæ¯”å¦‚å•å…ƒæ ¼æ ¼å¼å’Œåˆ—ï¼ˆè€Œä¸æ˜¯è¡Œï¼‰å±æ€§ã€‚
- en: More fun ahead!
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šæœ‰è¶£å†…å®¹æ•¬è¯·æœŸå¾…ï¼
- en: References
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] Haoyu Dong et al, [TableSense: Spreadsheet Table Detection with Convolutional
    Neural Networks](https://arxiv.org/abs/2106.13500) (2021)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Haoyu Dong ç­‰äººï¼Œ[TableSense: ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œç”µå­è¡¨æ ¼è¡¨æ ¼æ£€æµ‹](https://arxiv.org/abs/2106.13500)
    (2021)'
- en: '[2] Brown et al, [Language Models are Few Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
    (2020).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Brown ç­‰äººï¼Œ[è¯­è¨€æ¨¡å‹æ˜¯å°‘æ ·æœ¬å­¦ä¹ è€…](https://arxiv.org/pdf/2005.14165.pdf) (2020)ã€‚'
- en: '[3] [OpenAI Cookbook: Techniques to improve reliability](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [OpenAI Cookbook: æé«˜å¯é æ€§çš„æŠ€æœ¯](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)'
- en: '[4] Kojima et al, [Large Language Models are Zero-shot reasoners](https://arxiv.org/abs/2205.11916)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Kojima ç­‰äººï¼Œ[å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯é›¶æ ·æœ¬æ¨ç†è€…](https://arxiv.org/abs/2205.11916)'
- en: Code for this analysis can be found in [this notebook](https://github.com/datakind/gpt-3-meta-data-discovery/blob/main/gpt-3-table-parsing.ipynb).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåˆ†æçš„ä»£ç å¯ä»¥åœ¨[è¿™ä¸ªç¬”è®°æœ¬](https://github.com/datakind/gpt-3-meta-data-discovery/blob/main/gpt-3-table-parsing.ipynb)ä¸­æ‰¾åˆ°ã€‚
