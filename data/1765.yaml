- en: How Google Used Fake Datasets to Train Generative Music AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用虚假数据集训练生成音乐 AI
- en: 原文：[https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19?source=collection_archive---------3-----------------------#2023-05-28](https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19?source=collection_archive---------3-----------------------#2023-05-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19?source=collection_archive---------3-----------------------#2023-05-28](https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19?source=collection_archive---------3-----------------------#2023-05-28)
- en: '[](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd0c085a74ae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&user=Max+Hilsdorf&userId=d0c085a74ae8&source=post_page-d0c085a74ae8----def6f3f71f19---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)
    ·6 min read·May 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdef6f3f71f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&user=Max+Hilsdorf&userId=d0c085a74ae8&source=-----def6f3f71f19---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd0c085a74ae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&user=Max+Hilsdorf&userId=d0c085a74ae8&source=post_page-d0c085a74ae8----def6f3f71f19---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)
    ·6分钟阅读·2023年5月28日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdef6f3f71f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&user=Max+Hilsdorf&userId=d0c085a74ae8&source=-----def6f3f71f19---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdef6f3f71f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&source=-----def6f3f71f19---------------------bookmark_footer-----------)![](../Images/ed2c5ce433310ba9f1ace3de4d277849.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdef6f3f71f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&source=-----def6f3f71f19---------------------bookmark_footer-----------)![](../Images/ed2c5ce433310ba9f1ace3de4d277849.png)'
- en: Photo by [James Stamler](https://unsplash.com/@jamesstamler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [James Stamler](https://unsplash.com/@jamesstamler?utm_source=medium&utm_medium=referral)
    提供，刊登在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In this post, we explore Google’s innovative approach to training their remarkable
    text-to-music models, including MusicLM and Noise2Music. We’ll delve into the
    concept of “fake” datasets and how they were utilized in these breakthrough models.
    If you’re curious about the inner workings of these techniques and their impact
    on advancing music AI, you’ve come to the right place.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们探讨了谷歌在训练其卓越的文本到音乐模型（如 MusicLM 和 Noise2Music）时的创新方法。我们将深入探讨“虚假”数据集的概念及其在这些突破性模型中的应用。如果你对这些技术的内部工作原理及其在推动音乐
    AI 方面的影响感兴趣，你来对地方了。
- en: '**The Lack of Labeled Music Data**'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**缺乏标记音乐数据**'
- en: Large language models (LLMs) like ChatGPT or Bard are trained on huge amounts
    of unstructured text data. Although it can be computationally expensive to collect
    the content of millions of websites, there is an abundance of training data on
    the public web. In contrast, text-to-image models like DALL-E 2 require a totally
    different kind of dataset consisting of pairs of images with corresponding descriptions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 像ChatGPT或Bard这样的大型语言模型（LLMs）是在大量非结构化文本数据上进行训练的。虽然收集数百万个网站的内容可能会很昂贵，但公共网络上有大量的训练数据。相比之下，像DALL-E
    2这样的文本到图像模型则需要一种完全不同的数据集，由图像和对应描述的配对组成。
- en: In the same way, text-to-music models rely on songs with descriptions of their
    musical content. However, unlike images, labeled music is really hard to find
    on the internet. Sometimes, metadata like instrumentation, genre, or mood, are
    available, but full-text in-depth descriptions are exceptionally hard to obtain.
    This poses a serious problem for researchers and companies trying to collect data
    to train generative music models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，文本到音乐的模型依赖于带有音乐内容描述的歌曲。然而，与图像不同的是，标注过的音乐在互联网上真的很难找到。有时，像乐器编排、风格或情绪这样的元数据是可以获取的，但完整的深入描述却异常难以获得。这给试图收集数据以训练生成音乐模型的研究人员和公司带来了严重问题。
