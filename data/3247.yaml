- en: How Human Labor Enables Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人类劳动如何促进机器学习
- en: 原文：[https://towardsdatascience.com/how-human-labor-enables-machine-learning-367feee8bc91?source=collection_archive---------2-----------------------#2023-10-31](https://towardsdatascience.com/how-human-labor-enables-machine-learning-367feee8bc91?source=collection_archive---------2-----------------------#2023-10-31)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-human-labor-enables-machine-learning-367feee8bc91?source=collection_archive---------2-----------------------#2023-10-31](https://towardsdatascience.com/how-human-labor-enables-machine-learning-367feee8bc91?source=collection_archive---------2-----------------------#2023-10-31)
- en: Much of the division between technology and human activity is artificial — how
    do people make our work possible?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术与人类活动之间的大部分分隔是人为的——人们是如何让我们的工作成为可能的？
- en: '[](https://medium.com/@s.kirmer?source=post_page-----367feee8bc91--------------------------------)[![Stephanie
    Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page-----367feee8bc91--------------------------------)[](https://towardsdatascience.com/?source=post_page-----367feee8bc91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----367feee8bc91--------------------------------)
    [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page-----367feee8bc91--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@s.kirmer?source=post_page-----367feee8bc91--------------------------------)[![Stephanie
    Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page-----367feee8bc91--------------------------------)[](https://towardsdatascience.com/?source=post_page-----367feee8bc91--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----367feee8bc91--------------------------------)
    [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page-----367feee8bc91--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa8dc77209ef3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-human-labor-enables-machine-learning-367feee8bc91&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=post_page-a8dc77209ef3----367feee8bc91---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----367feee8bc91--------------------------------)
    ·8 min read·Oct 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F367feee8bc91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-human-labor-enables-machine-learning-367feee8bc91&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=-----367feee8bc91---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa8dc77209ef3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-human-labor-enables-machine-learning-367feee8bc91&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=post_page-a8dc77209ef3----367feee8bc91---------------------post_header-----------)
    发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----367feee8bc91--------------------------------)
    ·8分钟阅读·2023年10月31日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F367feee8bc91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-human-labor-enables-machine-learning-367feee8bc91&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=-----367feee8bc91---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F367feee8bc91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-human-labor-enables-machine-learning-367feee8bc91&source=-----367feee8bc91---------------------bookmark_footer-----------)![](../Images/312c447d8f15ac8994a2be525e99e76d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F367feee8bc91&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-human-labor-enables-machine-learning-367feee8bc91&source=-----367feee8bc91---------------------bookmark_footer-----------)![](../Images/312c447d8f15ac8994a2be525e99e76d.png)'
- en: Photo by [Dominik Scythe](https://unsplash.com/@drscythe?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Dominik Scythe](https://unsplash.com/@drscythe?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: We don’t talk enough about how much manual, human work we rely upon to make
    the exciting advances in ML possible. The truth is, the division between technology
    and human activity is artificial. All the inputs that make models are the result
    of human effort, and all the outputs in one way or another exist to have an impact
    on people. I’m using today’s column to talk about some of the specific areas in
    which we overlook how important people are to what we do — and not just the data
    scientists who write the code.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们并没有足够谈论我们依赖多少人工工作来实现机器学习领域的激动人心的进展。事实是，技术和人工活动之间的划分是人为的。所有使模型产生的输入都是人类努力的结果，而所有输出以某种方式存在于影响人们。我今天使用这一专栏来谈论我们在某些特定领域忽视了人们对我们所做工作的重要性——不仅仅是那些编写代码的数据科学家。
- en: The division between technology and human activity is artificial, because all
    the inputs that make models are the result of human effort, and all the outputs
    in one way or another exist to have an impact on people.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 技术与人工活动之间的划分是人为的，因为所有使模型产生的输入都是人类努力的结果，而所有输出以某种方式存在于影响人们。
- en: Generating Data
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成数据
- en: You almost certainly already know this one — LLMs require extraordinary quantities
    of text data to train. We often think about this in hundreds or thousands of gigabytes
    of data on a hard drive, but this is a bit abstract. Some reports indicate that
    GPT-4 had on the order of *1 trillion* words in its training data. Every one of
    those words was written by a person, out of their own creative capability. For
    context, book 1 in the Game of Thrones series was about 292,727 words. So, the
    training data for GPT-4 was about *3,416,152 copies of that book long*. And this
    is only an example from text modeling — other kinds of models, like those that
    generate or classify multimedia, use similarly massive volumes of those sorts
    of data too.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你几乎肯定已经知道这一点——LLMs需要巨量的文本数据进行训练。我们通常以硬盘上的数百或数千GB的数据来考虑这个问题，但这有点抽象。一些报告指出，GPT-4的训练数据大约有*1万亿*个单词。每一个单词都是由一个人用他们自己的创造能力写出的。作为参考，《冰与火之歌》系列的第一本书大约有292,727个单词。因此，GPT-4的训练数据大约是*3,416,152本书的长度*。而这只是文本建模的一个例子——其他类型的模型，例如那些生成或分类多媒体的模型，也使用类似规模的海量数据。
- en: There are a few things to consider when this data is concerned. First, all that
    data is generated by people, it doesn’t just appear on our hard drives by magic.
    Respecting and acknowledging the people who create our data is important just
    as a matter of ethics, because they have put in work and created value that we
    are benefiting from. But there are also more selfish reasons why we ought to know
    where our data comes from. We have a responsibility as data scientists to know
    what material we are giving to our models as exemplars, and to understand it in
    great depth. If we ignore the provenance of our data, we open ourselves up to
    being unpleasantly surprised by how our models behave when faced with the real
    world. For example, training LLMs on internet forums or social media data leads
    these models to a risk of replicating the worst of these spaces, including racism,
    hate speech, and more. In somewhat less extreme examples, we know that [models
    are flavored by the training data they get](https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到这些数据时，有几个方面需要考虑。首先，所有这些数据都是由人生成的，它不会凭空出现在我们的硬盘上。尊重和认可那些创造我们数据的人的工作是重要的，这是伦理问题，因为他们付出了努力，创造了我们正在受益的价值。但我们也有更自私的理由需要了解我们的数据来源。作为数据科学家，我们有责任了解我们向模型提供的材料作为示例，并深入理解它。如果我们忽视数据的来源，我们可能会在面对现实世界时，对我们的模型行为感到不愉快的惊讶。例如，在互联网论坛或社交媒体数据上训练LLMs会使这些模型面临复制这些空间最糟糕现象的风险，包括种族主义、仇恨言论等。在稍微不那么极端的例子中，我们知道[模型受其训练数据的影响](https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/)。
- en: If we ignore the provenance of our data, we open ourselves up to being unpleasantly
    surprised by how our models behave when faced with the real world.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果我们忽视数据的来源，我们可能会在面对现实世界时，对我们的模型行为感到不愉快的惊讶。
- en: Labeling Data
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标记数据
- en: Human help is required to label data. But, what are labels exactly? At its core,
    labeling data means using human discernment to assign values or judgments to what
    we uncover in the data. No matter how data is collected or created, a great many
    of the machine learning use cases for such data require labeling of some kind.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据标注需要人工帮助。但是，标签到底是什么？从根本上说，标注数据意味着使用人类的洞察力为我们在数据中发现的内容分配值或判断。无论数据如何收集或创建，大多数机器学习用例都需要某种形式的标注。
- en: This may mean simply deciding whether a datapoint is good or bad, determining
    whether words are positive or negative, creating derived values, dividing records
    into categories, determining what tags apply to an image or video, or endless
    others. One common example is identifying what text is in an image or other multimedia
    to improve character recognition models. [If you have used captcha](https://www.hcaptcha.com/labeling),
    I bet this sounds familiar — you’ve done data labeling work.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能意味着简单地决定一个数据点是好是坏，确定词语是积极的还是消极的，创建衍生值，将记录划分为不同类别，确定哪些标签适用于图像或视频，或者其他无尽的任务。一个常见的例子是识别图像或其他多媒体中的文本，以改善字符识别模型。[如果你使用过验证码](https://www.hcaptcha.com/labeling)，我敢打赌这听起来很熟悉——你已经做过数据标注工作。
- en: LLMs themselves, in theory, don’t require labeling, because we infer the quality
    of human-ness of the texts from the fact that these texts were already generated
    by real people and thus must be as ‘similar to human output’ as they can possibly
    be, in essence. Basically, because a human wrote it, then it’s by definition an
    acceptable example for the model to try and learn and emulate. This is where we
    use things like semantic embedding — the model learns how the language patterns
    work in human-generated text and quantifies these into mathematical representations.
    But we are still choosing which text goes in to the model’s processes, as I described
    earlier, and we have a responsibility to understand and assess that text.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，LLM本身不需要标注，因为我们从这些文本已经由真实人类生成的事实中推断出人类的质量，因此这些文本在本质上必须尽可能类似于人类输出。基本上，因为是人类写的，那么它在定义上就是一个可接受的示例供模型学习和模仿。这就是我们使用语义嵌入的地方——模型学习人类生成文本中的语言模式如何工作，并将这些模式量化为数学表示。但是正如我之前所描述的，我们仍然在选择哪些文本进入模型的过程，我们有责任理解和评估这些文本。
- en: Teaching Models
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教学模型
- en: Reinforcement learning uses human intervention for tasks around tuning — meaning,
    we’re adjusting how the model responds to prompts slightly, once it’s basically
    got the hang of returning a coherent answer, whether that’s text, or images, or
    video, or other things. After some mainly automated element of pre-training or
    base training, [many models are fine tuned by human beings, making sometimes subtle
    determinations of whether model is doing what was desired.](https://www.youtube.com/watch?v=bZQun8Y4L2A)
    This is a very hard task, because the nuances of what we actually want from the
    model can be really complicated. It’s basically copy-editing an LLM in a pass-fail
    fashion, at a massive scale.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习使用人工干预来调整任务——意味着我们在模型基本上掌握了返回连贯答案的方式后，稍微调整模型对提示的响应，无论是文本、图像、视频还是其他内容。在一些主要的自动化预训练或基础训练之后，[许多模型由人类进行微调，做出有时微妙的判断，判断模型是否达到了期望。](https://www.youtube.com/watch?v=bZQun8Y4L2A)
    这是一项非常艰巨的任务，因为我们实际希望模型做到的细微差别可能非常复杂。这基本上是在大规模上以通过或不通过的方式进行LLM的校对。
- en: As I have discussed before, many modern models are seeking to produce the content
    that will be most pleasing to a human user- something that will seem right and
    appealing to a human being. What better way to train this then, than asking human
    beings to look at the results of an intermediate stage of training and decide
    whether the results are fitting this description, and tell the model so it can
    make more appropriate choices? Not only is that the most effective way, but it
    may be the only way it can work.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前讨论的，许多现代模型寻求生成对人类用户最令人愉悦的内容——那些看起来正确且吸引人的东西。那么，有什么比让人类查看训练的中间阶段结果并决定结果是否符合描述，再告诉模型以便它做出更合适的选择，更好的训练方式呢？这不仅是最有效的方法，也可能是唯一有效的方法。
- en: It’s basically copy-editing an LLM in a pass-fail fashion.
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这基本上是在以通过或不通过的方式进行LLM的校对。
- en: Why this matters
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么这很重要
- en: Ok, so what? Is it enough to be conscientious about the fact that real people
    do a lot of hard work to make our models possible? Pat them on the back and say
    thanks? No, not quite, because we need to interrogate what the human influence
    means for the results we generate. As data scientists, we need to be curious about
    the interaction between what we build and the rest of the world in which it lives.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，那又怎样呢？仅仅意识到真实的人们付出了大量的努力来实现我们的模型，这就够了吗？拍拍他们的背，表示感谢？不完全是，因为我们需要审视人类的影响对我们生成的结果意味着什么。作为数据科学家，我们需要对我们构建的东西与其所在世界之间的互动保持好奇心。
- en: Because of all these areas of influence, human choices shape the model capabilities
    and judgments. We embed human bias into the models, because humans create, control,
    and judge all the material involved. We decide that this bit of text will be provided
    to the model for training, or that this specific response from the model is worse
    than another, and the model solidifies these choices of ours into mathematical
    representations that it can reuse and replicate.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于所有这些影响领域，人类的选择塑造了模型的能力和判断。我们将人类的偏见嵌入到模型中，因为人类创造、控制并判断所有相关材料。我们决定哪些文本将提供给模型进行训练，或者模型的哪个具体回应比另一个更差，而模型将这些选择固化为可以重复和再利用的数学表示。
- en: This element of bias is inevitable, but it’s not necessarily bad. Looking to
    create something free of all human influence suggests that human influence and
    human beings themselves are problems to be avoided, which isn’t a fair assessment
    in my opinion. At the same time, we should be realistic about the fact that human
    bias is part of our models, and resist the temptation to view models as beyond
    our human foibles. Things like how we assign labels, for example, lead us to imbue
    meanings into the data consciously or subconsciously. We leave traces of our thought
    processes and our histories in the data we create, whether it’s original creative
    content, data labels, or judgments of model output.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这种偏见元素是不可避免的，但并不一定是坏事。试图创造一个完全摆脱人类影响的东西暗示人类的影响和人类本身是需要避免的问题，这在我看来是不公平的评估。同时，我们也应该现实地认识到人类偏见是我们模型的一部分，并抵制将模型视为超越我们人类缺陷的诱惑。例如，我们如何分配标签，导致我们有意识或无意识地赋予数据意义。无论是原创创意内容、数据标签，还是模型输出的判断，我们都在创建的数据中留下了我们思维过程和历史的痕迹。
- en: Looking to create something free of all human influence suggests that human
    influence and human beings themselves are problems to be avoided, which isn’t
    a fair assessment in my opinion.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 试图创造一个完全摆脱人类影响的东西暗示人类的影响和人类本身是需要避免的问题，这在我看来是不公平的评估。
- en: In addition, often in the machine learning space human effort is perceived as
    in service of “real” work instead of meaningful on its own. People who produce
    original work stop being seen as uniquely creative individuals, but just get folded
    into “content generators” in service of the model. We lose track of the humanity
    and real reason that this content exists, which is to serve and empower humanity.
    As with the previous point, we end up devaluing people in favor of idolizing technology,
    which I think is foolish. The models are the product of people and exist to serve
    people, they aren’t an independent end unto themselves. If you build a model that
    is never used and never gets run, what is the point?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在机器学习领域，人类的努力通常被视为服务于“真实”工作的，而不是自身具有意义。那些产生原创作品的人不再被视为独特的创造性个体，而只是被归入服务于模型的“内容生成者”。我们忽视了这些内容存在的本质人性和真实原因，即服务和赋能人类。与之前的观点一样，我们最终贬低了人们而崇拜技术，我认为这是愚蠢的。模型是人们的产物，旨在服务于人们，它们不是独立的目标。如果你构建了一个从未被使用和运行的模型，那还有什么意义呢？
- en: Is data a renewable resource?
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据是可再生资源吗？
- en: 'There is another interesting issue: the risk of running out of pristine human
    generated content as a limiter on model capability. That is, as our society begins
    to use LLMs to generate our data, and Dall-E to generate our images, and we stop
    incentivizing real people to be creative without these technologies, then the
    trillions of words and mountains of images we need to train new versions of these
    models will become contaminated with artificially generated content. That content,
    of course, is derived from human content, but it’s not the same. We don’t yet
    have very good ways to differentiate content that’s generated by people without
    models, so we’re going to struggle to know whether our training data for future
    models has this contamination in it, and how much.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的问题是：人类生成的纯净内容的风险成为模型能力的限制因素。也就是说，当我们的社会开始使用LLM生成数据，使用Dall-E生成图像，并且我们停止激励真实的人在没有这些技术的情况下进行创作时，我们需要训练新版本这些模型的万亿字词和山岳般的图像将被人为生成的内容所污染。那种内容，当然，来源于人类内容，但并不完全一样。我们尚未拥有很好的方法来区分由没有模型的人生成的内容，所以我们将难以判断我们未来模型的训练数据是否存在这种污染，以及污染的程度。
- en: Some people argue this is not actually a big deal, and that training models
    on at least some proportion artificial content won’t be a problem, but others
    theorize that when [we start to cannibalize artificially generated content in
    this way, the underlying processes of training will be existentially altered,
    in the form of something called Model Collapse](https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/).
    This is in some ways an example of the essential problem that your model affects
    the world that your model relies on, so the model is definitionally changed by
    its own behavior. This isn’t just true of LLMs, as data scientists know too well.
    Any model can work itself out of a job by affecting how people behave, resulting
    in performance drift due to underlying data relationships shifting.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有人认为这其实不是什么大问题，训练模型时使用至少一部分人工内容不会有问题，但也有其他理论认为，当[我们开始以这种方式掠夺人工生成的内容时，训练的基本过程将以称为模型崩溃的形式被根本性改变](https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/)。在某些方面，这是模型影响了模型所依赖的世界的根本问题的一个例子，因此模型的行为定义上改变了模型本身。数据科学家对此也深有体会。这不仅仅适用于LLM，任何模型都可能通过影响人们的行为来使自己失业，从而导致由于基础数据关系的变化而性能漂移。
- en: Your model affects the world that your model relies on, so the model is definitionally
    changed by its own behavior.
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你的模型影响了模型所依赖的世界，因此模型的行为定义上改变了模型本身。
- en: Even if we aren’t training on actually artificial data, also, there are many
    scholars considering whether our human composition and creative processes will
    change due to our exposure to artificially created content. If you read a whole
    lot of LLM generated text, either while writing and getting a model’s advice or
    just around the internet in general, [is that going to subtly change how you write](https://arxiv.org/abs/2309.05196)?
    It’s too early to know on a community level, but it’s a serious concern.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们没有在实际的人工数据上进行训练，还有许多学者在考虑我们的人的组成和创造过程是否会因接触到人工生成的内容而发生变化。如果你大量阅读LLM生成的文本，无论是在写作时获取模型的建议还是在互联网的一般环境中，[这是否会微妙地改变你的写作方式](https://arxiv.org/abs/2309.05196)？在社区层面上现在还为时尚早，但这是一个严重的问题。
- en: Human influence is a fact of machine learning—it’s a philosophical issue. We
    think of machine learning as a pure scientific enterprise, something that acts
    upon us, and this is one of the reasons it seems terrifying to some. But in reality,
    the systems that are being created are the product of human intervention, and
    human creativity. Creating and curating data makes all the rest of machine learning
    possible. In some ways, this should be comforting to us, because we have control
    over what we do with machine learning and how we do it. The process of machine
    learning is taking relationships between pieces of data and calculating them into
    mathematical representations, but the data is produced by people and is under
    our control. Machine learning and AI aren’t some alien, abstract force — **they’re
    just us.**
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 人类影响是机器学习的一个事实——这是一个哲学问题。我们将机器学习视为一种纯科学事业，认为它作用于我们，这也是它对某些人来说似乎令人恐惧的原因之一。但实际上，正在创建的系统是人类干预和创造力的产物。创建和策划数据使得所有其他机器学习的可能性成为可能。在某种程度上，这应该让我们感到安慰，因为我们可以控制我们如何使用机器学习以及如何使用它。机器学习的过程是将数据片段之间的关系计算成数学表示，但数据是由人类产生的，并且在我们的控制之下。机器学习和人工智能不是某种外星的、抽象的力量——**它们只是我们。**
- en: '*See more of my work at* [*www.stephaniekirmer.com*](http://www.stephaniekirmer.com/)*.*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看更多我的作品请访问* [*www.stephaniekirmer.com*](http://www.stephaniekirmer.com/)*.*'
- en: 'Articles and references linked above, for easy access:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上述文章和参考资料，方便访问：
- en: '[https://www.youtube.com/watch?v=bZQun8Y4L2A](https://www.youtube.com/watch?v=bZQun8Y4L2A)
    The State of GPT, Microsoft Build Conference 2023, Andrej Karpathy'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=bZQun8Y4L2A](https://www.youtube.com/watch?v=bZQun8Y4L2A)
    GPT 状况，微软 Build 大会 2023，Andrej Karpathy'
- en: '[www.technologyreview.com%2F2023%2F08%2F07%2F1077324%2Fai-language-models-are-rife-with-political-biases%2F](https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/)
    MIT Technology Review, [Melissa Heikkilä](https://www.technologyreview.com/author/melissa-heikkila/),
    August 2023'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[www.technologyreview.com%2F2023%2F08%2F07%2F1077324%2Fai-language-models-are-rife-with-political-biases%2F](https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/)
    MIT 技术评论，[Melissa Heikkilä](https://www.technologyreview.com/author/melissa-heikkila/)，2023
    年 8 月'
- en: '[https://www.hcaptcha.com/labeling](https://www.hcaptcha.com/labeling)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.hcaptcha.com/labeling](https://www.hcaptcha.com/labeling)'
- en: '[https://files.eric.ed.gov/fulltext/EJ1390465.pdf](https://files.eric.ed.gov/fulltext/EJ1390465.pdf)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://files.eric.ed.gov/fulltext/EJ1390465.pdf](https://files.eric.ed.gov/fulltext/EJ1390465.pdf)'
- en: '[https://arxiv.org/abs/2309.05196](https://arxiv.org/abs/2309.05196)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/2309.05196](https://arxiv.org/abs/2309.05196)'
- en: '[https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/](https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/](https://bdtechtalks.com/2023/06/19/chatgpt-model-collapse/)'
