- en: How to Use Googleâ€™s PaLM 2 API with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•ä½¿ç”¨Googleçš„PaLM 2 APIä¸Python
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-use-google-palm-2-api-with-python-373bc564251c?source=collection_archive---------2-----------------------#2023-08-14](https://towardsdatascience.com/how-to-use-google-palm-2-api-with-python-373bc564251c?source=collection_archive---------2-----------------------#2023-08-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-use-google-palm-2-api-with-python-373bc564251c?source=collection_archive---------2-----------------------#2023-08-14](https://towardsdatascience.com/how-to-use-google-palm-2-api-with-python-373bc564251c?source=collection_archive---------2-----------------------#2023-08-14)
- en: Customize and integrate Googleâ€™s LLM in your application.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªå®šä¹‰å¹¶å°†Googleçš„LLMé›†æˆåˆ°ä½ çš„åº”ç”¨ç¨‹åºä¸­ã€‚
- en: '[](https://eliselandman.medium.com/?source=post_page-----373bc564251c--------------------------------)[![Elise
    Landman](../Images/1cd86aa9df340e430820a48f4d26de5a.png)](https://eliselandman.medium.com/?source=post_page-----373bc564251c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----373bc564251c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----373bc564251c--------------------------------)
    [Elise Landman](https://eliselandman.medium.com/?source=post_page-----373bc564251c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://eliselandman.medium.com/?source=post_page-----373bc564251c--------------------------------)[![Elise
    Landman](../Images/1cd86aa9df340e430820a48f4d26de5a.png)](https://eliselandman.medium.com/?source=post_page-----373bc564251c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----373bc564251c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----373bc564251c--------------------------------)
    [Elise Landman](https://eliselandman.medium.com/?source=post_page-----373bc564251c--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbd14e538474&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-google-palm-2-api-with-python-373bc564251c&user=Elise+Landman&userId=dbd14e538474&source=post_page-dbd14e538474----373bc564251c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----373bc564251c--------------------------------)
    Â·11 min readÂ·Aug 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F373bc564251c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-google-palm-2-api-with-python-373bc564251c&user=Elise+Landman&userId=dbd14e538474&source=-----373bc564251c---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdbd14e538474&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-google-palm-2-api-with-python-373bc564251c&user=Elise+Landman&userId=dbd14e538474&source=post_page-dbd14e538474----373bc564251c---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----373bc564251c--------------------------------)
    Â·11åˆ†é’Ÿé˜…è¯»Â·2023å¹´8æœˆ14æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F373bc564251c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-google-palm-2-api-with-python-373bc564251c&user=Elise+Landman&userId=dbd14e538474&source=-----373bc564251c---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F373bc564251c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-google-palm-2-api-with-python-373bc564251c&source=-----373bc564251c---------------------bookmark_footer-----------)![](../Images/83e8ff5e480e20067392de2c2d57db3d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F373bc564251c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-use-google-palm-2-api-with-python-373bc564251c&source=-----373bc564251c---------------------bookmark_footer-----------)![](../Images/83e8ff5e480e20067392de2c2d57db3d.png)'
- en: Image by Alexandre DebiÃ¨ve from [Unsplash](https://unsplash.com/photos/FO7JIlwjOtU).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± Alexandre DebiÃ¨ve æä¾›ï¼Œæ¥æºäº [Unsplash](https://unsplash.com/photos/FO7JIlwjOtU)ã€‚
- en: 'Generative AI is all over the place. We see more and more companies investing
    in this **powerful technology** as it becomes increasingly clear how much **potential**
    it has. And as Gartner states: in the near future, [Generative AI] will become
    a competitive advantage and differentiator.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå‹äººå·¥æ™ºèƒ½æ— å¤„ä¸åœ¨ã€‚æˆ‘ä»¬çœ‹åˆ°è¶Šæ¥è¶Šå¤šçš„å…¬å¸æŠ•èµ„äºè¿™é¡¹**å¼ºå¤§æŠ€æœ¯**ï¼Œå› ä¸ºå®ƒçš„**æ½œåŠ›**å˜å¾—è¶Šæ¥è¶Šæ˜æ˜¾ã€‚æ­£å¦‚Gartneræ‰€è¯´ï¼šåœ¨ä¸ä¹…çš„å°†æ¥ï¼Œ[ç”Ÿæˆå‹äººå·¥æ™ºèƒ½]å°†æˆä¸ºç«äº‰ä¼˜åŠ¿å’Œå·®å¼‚åŒ–çš„å…³é”®ã€‚
- en: â€œin the near future, [Generative AI] will become a competitive advantage and
    differentiator.â€
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œåœ¨ä¸ä¹…çš„å°†æ¥ï¼Œ[ç”Ÿæˆå‹äººå·¥æ™ºèƒ½]å°†æˆä¸ºç«äº‰ä¼˜åŠ¿å’Œå·®å¼‚åŒ–çš„å…³é”®ã€‚â€
- en: 'Unfortunately, developing Generative AI models is not only a complex work of
    engineering, but it is usually quite a pricey project. Luckily, we do not have
    to develop these ourselves â€” we can reuse what has been pre-developed for us:
    with APIs! Therefore, letâ€™s not wait any longer â€” letâ€™s jump right into how we
    can leverage Generative AI by **integrating** it into our application.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å¹¸çš„æ˜¯ï¼Œå¼€å‘ç”Ÿæˆæ€§ AI æ¨¡å‹ä¸ä»…æ˜¯å¤æ‚çš„å·¥ç¨‹å·¥ä½œï¼Œè€Œä¸”é€šå¸¸æ˜¯ä¸€ä¸ªç›¸å½“æ˜‚è´µçš„é¡¹ç›®ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬ä¸å¿…è‡ªå·±å¼€å‘è¿™äº›æ¨¡å‹ â€” æˆ‘ä»¬å¯ä»¥é‡ç”¨å·²ç»ä¸ºæˆ‘ä»¬é¢„å…ˆå¼€å‘çš„ï¼šé€šè¿‡
    APIsï¼æ‰€ä»¥ï¼Œä¸è¦å†ç­‰äº† â€” è®©æˆ‘ä»¬ç›´æ¥æ·±å…¥äº†è§£å¦‚ä½•é€šè¿‡**é›†æˆ**ç”Ÿæˆæ€§ AI åˆ°æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºä¸­æ¥åˆ©ç”¨å®ƒã€‚
- en: 'For this article, weâ€™ll be looking at **Googleâ€™s answer to LLMs**: the **PaLM
    2** API. PaLM 2 is Googleâ€™s newest version of their **Pathways Language Model**,
    a large language model which uses around five times more training data than their
    initial model released in 2022.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæœ¬æ–‡ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹**è°·æ­Œå¯¹ LLM çš„å›ç­”**ï¼š**PaLM 2** APIã€‚PaLM 2 æ˜¯è°·æ­Œæœ€æ–°ç‰ˆæœ¬çš„**Pathways è¯­è¨€æ¨¡å‹**ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨çš„è®­ç»ƒæ•°æ®é‡çº¦æ˜¯ä»–ä»¬åœ¨
    2022 å¹´å‘å¸ƒçš„åˆå§‹æ¨¡å‹çš„äº”å€ã€‚
- en: In this article I will be going through **some code examples** and showing you
    how to authenticate to Google Cloud and use, as well as customize the **PaLM 2
    APIs** with Python 3.11.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä»‹ç»**ä¸€äº›ä»£ç ç¤ºä¾‹**å¹¶å±•ç¤ºå¦‚ä½•è®¤è¯åˆ° Google Cloudï¼Œä½¿ç”¨ä»¥åŠè‡ªå®šä¹‰**PaLM 2 APIs**ï¼Œå¹¶ä½¿ç”¨ Python 3.11ã€‚
- en: 1 | Getting Started
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 | å…¥é—¨
- en: The PaLM 2 APIs can be accessed through **Google Cloudâ€™s** [**Vertex AI**](https://cloud.google.com/vertex-ai)
    platform. Therefore, before we can make any API calls, we will need to set up
    our Google Cloud account. You can [sign up here](https://console.cloud.google.com/)
    and get [$300 in free credits](https://cloud.google.com/free/docs/free-cloud-features#free-trial)
    to start playing around with the services.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: PaLM 2 APIs å¯ä»¥é€šè¿‡**Google Cloud**çš„ [**Vertex AI**](https://cloud.google.com/vertex-ai)
    å¹³å°è®¿é—®ã€‚å› æ­¤ï¼Œåœ¨æˆ‘ä»¬è¿›è¡Œä»»ä½• API è°ƒç”¨ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®æˆ‘ä»¬çš„ Google Cloud è´¦æˆ·ã€‚ä½ å¯ä»¥ [åœ¨è¿™é‡Œæ³¨å†Œ](https://console.cloud.google.com/)
    å¹¶è·å¾— [$300 çš„å…è´¹é¢åº¦](https://cloud.google.com/free/docs/free-cloud-features#free-trial)
    æ¥å¼€å§‹ä½¿ç”¨è¿™äº›æœåŠ¡ã€‚
- en: As soon as your account and project are set up, we can go ahead and [create
    a service account](https://cloud.google.com/iam/docs/service-accounts-create)
    which we will use to authenticate to the Vertex AI APIs. We use service accounts,
    because we can ensure **access control** to our Google Cloud resources by giving
    them only specific IAM permissions. For our use case, we will give the service
    account the `Vertex AI User` role. This might be too broad for your use case,
    so I recommend checking the [available access roles](https://cloud.google.com/vertex-ai/docs/general/access-control)
    and choose which one fits your needs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦ä½ çš„è´¦æˆ·å’Œé¡¹ç›®è®¾ç½®å®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­ [åˆ›å»ºä¸€ä¸ªæœåŠ¡è´¦æˆ·](https://cloud.google.com/iam/docs/service-accounts-create)ï¼Œæˆ‘ä»¬å°†ç”¨å®ƒæ¥è®¤è¯åˆ°
    Vertex AI APIsã€‚æˆ‘ä»¬ä½¿ç”¨æœåŠ¡è´¦æˆ·ï¼Œæ˜¯å› ä¸ºæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»…ç»™äºˆå®ƒä»¬ç‰¹å®šçš„ IAM æƒé™æ¥ç¡®ä¿å¯¹ Google Cloud èµ„æºçš„**è®¿é—®æ§åˆ¶**ã€‚å¯¹äºæˆ‘ä»¬çš„ç”¨ä¾‹ï¼Œæˆ‘ä»¬å°†æˆäºˆæœåŠ¡è´¦æˆ·
    `Vertex AI User` è§’è‰²ã€‚è¿™å¯èƒ½å¯¹ä½ çš„ç”¨ä¾‹æ¥è¯´è¿‡äºå®½æ³›ï¼Œæ‰€ä»¥æˆ‘å»ºè®®ä½ æ£€æŸ¥ [å¯ç”¨çš„è®¿é—®è§’è‰²](https://cloud.google.com/vertex-ai/docs/general/access-control)
    å¹¶é€‰æ‹©é€‚åˆä½ éœ€æ±‚çš„è§’è‰²ã€‚
- en: After having created the service account and given it the right permissions,
    we can go ahead and [generate a service account key](https://cloud.google.com/iam/docs/keys-create-delete).
    Select JSON as the key type and save the file in a safe place.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åˆ›å»ºäº†æœåŠ¡è´¦æˆ·å¹¶èµ‹äºˆå…¶æ­£ç¡®çš„æƒé™åï¼Œæˆ‘ä»¬å¯ä»¥ç»§ç»­ [ç”Ÿæˆä¸€ä¸ªæœåŠ¡è´¦æˆ·å¯†é’¥](https://cloud.google.com/iam/docs/keys-create-delete)ã€‚é€‰æ‹©
    JSON ä½œä¸ºå¯†é’¥ç±»å‹ï¼Œå¹¶å°†æ–‡ä»¶ä¿å­˜åœ¨å®‰å…¨çš„ä½ç½®ã€‚
- en: Great â€” we are ready to get hands-on! ğŸ‘
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ â€” æˆ‘ä»¬å‡†å¤‡åŠ¨æ‰‹æ“ä½œäº†ï¼ğŸ‘
- en: 2 | Authenticate to Google Cloud
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 | è®¤è¯åˆ° Google Cloud
- en: In this example, we will authenticate using [OAuth 2.0](https://oauth.net/2/)
    and request an access token with the help of the service account key we generated
    in the previous step.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [OAuth 2.0](https://oauth.net/2/) è¿›è¡Œè®¤è¯ï¼Œå¹¶å€ŸåŠ©æˆ‘ä»¬åœ¨å‰ä¸€æ­¥ç”Ÿæˆçš„æœåŠ¡è´¦æˆ·å¯†é’¥è¯·æ±‚è®¿é—®ä»¤ç‰Œã€‚
- en: 'To facilitate this process, we can make use of the `[google-auth](https://pypi.org/project/google-auth/)`
    Python library, as shown in the code sample below:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¾¿åˆ©è¿™ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `[google-auth](https://pypi.org/project/google-auth/)` Python
    åº“ï¼Œå¦‚ä¸‹é¢çš„ä»£ç ç¤ºä¾‹æ‰€ç¤ºï¼š
- en: Authenticate to Google Cloud using the google-auth Python library.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ google-auth Python åº“è®¤è¯åˆ° Google Cloudã€‚
- en: This code sample uses the service account key file â€œkey.jsonâ€ to request and
    generate an access token we can use for the Google Cloud APIs. After having obtained
    our access token, we can start using it to make calls to the Vertex AI PaLM 2
    APIs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªä»£ç ç¤ºä¾‹ä½¿ç”¨æœåŠ¡è´¦æˆ·å¯†é’¥æ–‡ä»¶â€œkey.jsonâ€æ¥è¯·æ±‚å’Œç”Ÿæˆä¸€ä¸ªè®¿é—®ä»¤ç‰Œï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥è®¿é—® Google Cloud APIsã€‚åœ¨è·å¾—è®¿é—®ä»¤ç‰Œåï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹ä½¿ç”¨å®ƒè°ƒç”¨
    Vertex AI PaLM 2 APIsã€‚
- en: 3 | Calling the PaLM 2 API
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 | è°ƒç”¨ PaLM 2 API
- en: 'As of today, there are two different PaLM 2 models available in Google Cloud:
    **PaLM 2 for Text** (i. e. `[text-bison](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview)`)
    and **PaLM 2 for Chat** (i. e. `[chat-bison](https://cloud.google.com/vertex-ai/docs/generative-ai/chat/chat-prompts)`).
    The documentation suggests using `text-bison` for text tasks that can be completed
    with one response, and `chat-bison` for text tasks that require more conversational,
    back-and-forth interactions.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æˆªè‡³ä»Šå¤©ï¼ŒGoogle Cloudä¸­æä¾›äº†ä¸¤ç§ä¸åŒçš„PaLM 2æ¨¡å‹ï¼š**PaLM 2 for Text**ï¼ˆå³`[text-bison](https://cloud.google.com/vertex-ai/docs/generative-ai/text/text-overview)`ï¼‰å’Œ**PaLM
    2 for Chat**ï¼ˆå³`[chat-bison](https://cloud.google.com/vertex-ai/docs/generative-ai/chat/chat-prompts)`ï¼‰ã€‚æ–‡æ¡£å»ºè®®å¯¹å¯ä»¥ç”¨ä¸€ä¸ªå›å¤å®Œæˆçš„æ–‡æœ¬ä»»åŠ¡ä½¿ç”¨`text-bison`ï¼Œå¯¹éœ€è¦æ›´å¤šå¯¹è¯äº’åŠ¨çš„æ–‡æœ¬ä»»åŠ¡ä½¿ç”¨`chat-bison`ã€‚
- en: Letâ€™s start with the `text-bison` model. For these examples, we will be using
    the Python `[requests](https://pypi.org/project/requests/)` library to make the
    API calls. You can also use the [Vertex AI SDK](https://cloud.google.com/python/docs/reference/aiplatform/latest/index.html),
    if you prefer.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»`text-bison`æ¨¡å‹å¼€å§‹ã€‚å¯¹äºè¿™äº›ç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Pythonçš„`[requests](https://pypi.org/project/requests/)`åº“æ¥è¿›è¡ŒAPIè°ƒç”¨ã€‚å¦‚æœä½ æ„¿æ„ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨[Vertex
    AI SDK](https://cloud.google.com/python/docs/reference/aiplatform/latest/index.html)ã€‚
- en: 'PaLM 2 for Text: Sentiment Analysis'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PaLM 2 for Textï¼šæƒ…æ„Ÿåˆ†æ
- en: 'The PaLM 2 for Text model can be used for various **text-related tasks**: including
    summarization, answering questions, sentiment analysis, etc. It takes the following
    parameters as input:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: PaLM 2 for Textæ¨¡å‹å¯ç”¨äºå„ç§**ä¸æ–‡æœ¬ç›¸å…³çš„ä»»åŠ¡**ï¼šåŒ…æ‹¬æ‘˜è¦ã€å›ç­”é—®é¢˜ã€æƒ…æ„Ÿåˆ†æç­‰ã€‚å®ƒæ¥å—ä»¥ä¸‹å‚æ•°ä½œä¸ºè¾“å…¥ï¼š
- en: '`prompt`: instructions of the task we want the model to perform.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`ï¼šæˆ‘ä»¬å¸Œæœ›æ¨¡å‹æ‰§è¡Œçš„ä»»åŠ¡çš„æŒ‡ä»¤ã€‚'
- en: '`temperature`: controls the â€œcreativityâ€ of the model. If we want our model
    to be more open-ended and creative in its replies, we should increase the temperature.
    If we want it to be more deterministic, the temperature should be lower. Values
    range between 0 and 1.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temperature`ï¼šæ§åˆ¶æ¨¡å‹çš„â€œåˆ›é€ æ€§â€ã€‚å¦‚æœæˆ‘ä»¬å¸Œæœ›æ¨¡å‹åœ¨å›å¤ä¸­æ›´å…·å¼€æ”¾æ€§å’Œåˆ›é€ æ€§ï¼Œåˆ™åº”æé«˜æ¸©åº¦ã€‚å¦‚æœæˆ‘ä»¬å¸Œæœ›æ¨¡å‹æ›´å…·ç¡®å®šæ€§ï¼Œåˆ™æ¸©åº¦åº”é™ä½ã€‚å€¼çš„èŒƒå›´åœ¨0åˆ°1ä¹‹é—´ã€‚'
- en: '`maxOutputTokens`: number of tokens to be generated in the output (1 token
    = 4 characters). Values range between 1 and 1024.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxOutputTokens`ï¼šç”Ÿæˆè¾“å‡ºçš„tokenæ•°é‡ï¼ˆ1ä¸ªtoken = 4ä¸ªå­—ç¬¦ï¼‰ã€‚å€¼çš„èŒƒå›´åœ¨1åˆ°1024ä¹‹é—´ã€‚'
- en: '`topK`: changes the probability of how the model selects tokens for generating
    output. In each token selection step, the `topK` tokens with the highest probabilities
    are sampled and then further filtered with `topP`. The higher the value, the more
    random the responses will be. Values range between 1 and 40.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`topK`ï¼šæ”¹å˜æ¨¡å‹é€‰æ‹©ç”Ÿæˆè¾“å‡ºçš„tokençš„æ¦‚ç‡ã€‚åœ¨æ¯ä¸ªtokené€‰æ‹©æ­¥éª¤ä¸­ï¼Œå…·æœ‰æœ€é«˜æ¦‚ç‡çš„`topK`ä¸ªtokenè¢«é‡‡æ ·ï¼Œç„¶åè¿›ä¸€æ­¥é€šè¿‡`topP`ç­›é€‰ã€‚å€¼è¶Šé«˜ï¼Œå“åº”è¶Šéšæœºã€‚å€¼çš„èŒƒå›´åœ¨1åˆ°40ä¹‹é—´ã€‚'
- en: '`topP`: changes the probability of how the model selects tokens for generating
    output. Tokens are selected until the sum of their probabilities equals `topP`.
    The higher the value, the more random the response is. Values range between 0
    and 1.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`topP`ï¼šæ”¹å˜æ¨¡å‹é€‰æ‹©ç”Ÿæˆè¾“å‡ºçš„tokençš„æ¦‚ç‡ã€‚tokençš„é€‰æ‹©ç›´åˆ°å…¶æ¦‚ç‡æ€»å’Œç­‰äº`topP`ã€‚å€¼è¶Šé«˜ï¼Œå“åº”è¶Šéšæœºã€‚å€¼çš„èŒƒå›´åœ¨0åˆ°1ä¹‹é—´ã€‚'
- en: '*For more details on the parameters see* [*this documentation*](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart#parameter_definitions)*.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ‰å…³å‚æ•°çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è§* [*æ­¤æ–‡æ¡£*](https://cloud.google.com/vertex-ai/docs/generative-ai/start/quickstarts/api-quickstart#parameter_definitions)*ã€‚*'
- en: 'In this first example, we will perform sentiment analysis on some **sample
    product reviews**:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç¬¬ä¸€ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†å¯¹ä¸€äº›**ç¤ºä¾‹äº§å“è¯„è®º**è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼š
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The instructions (i. e. the prompt) we will give the model need to be clearly
    stating the task we want the model to perform, as well as the output we expect
    it to generate. In our case, we ask it to go through each of the reviews in the
    `sentences` list and **tell us what the sentiment of these is**. We also instruct
    it to provide the output as a Python list.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç»™æ¨¡å‹çš„æŒ‡ä»¤ï¼ˆå³æç¤ºï¼‰éœ€è¦æ¸…æ¥šåœ°è¯´æ˜æˆ‘ä»¬å¸Œæœ›æ¨¡å‹æ‰§è¡Œçš„ä»»åŠ¡ï¼Œä»¥åŠæˆ‘ä»¬æœŸæœ›å®ƒç”Ÿæˆçš„è¾“å‡ºã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬è¦æ±‚å®ƒéå†`sentences`åˆ—è¡¨ä¸­çš„æ¯ä¸ªè¯„è®ºï¼Œå¹¶**å‘Šè¯‰æˆ‘ä»¬è¿™äº›è¯„è®ºçš„æƒ…æ„Ÿ**ã€‚æˆ‘ä»¬è¿˜æŒ‡ç¤ºå®ƒå°†è¾“å‡ºæä¾›ä¸ºPythonåˆ—è¡¨ã€‚
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Lastly, we need to define the **input parameter values**:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰**è¾“å…¥å‚æ•°å€¼**ï¼š
- en: We set the `temperature` to `0` because for this task, we want to avoid the
    model being too creative. With a lower temperature, we configure the the model
    be more likely to output exactly the structure we requested.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†`temperature`è®¾ç½®ä¸º`0`ï¼Œå› ä¸ºå¯¹äºè¿™ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬å¸Œæœ›é¿å…æ¨¡å‹è¿‡äºåˆ›æ„ã€‚é€šè¿‡é™ä½æ¸©åº¦ï¼Œæˆ‘ä»¬ä½¿å¾—æ¨¡å‹æ›´æœ‰å¯èƒ½è¾“å‡ºæˆ‘ä»¬è¯·æ±‚çš„ç¡®åˆ‡ç»“æ„ã€‚
- en: We set `256` as `maxOutputTokens`, because it is approximately equivalent to
    200 words and is a good length for our task.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†`256`è®¾ç½®ä¸º`maxOutputTokens`ï¼Œå› ä¸ºå®ƒå¤§çº¦ç›¸å½“äº200ä¸ªå•è¯ï¼Œå¹¶ä¸”æ˜¯é€‚åˆæˆ‘ä»¬ä»»åŠ¡çš„é•¿åº¦ã€‚
- en: We set `topK` to 40, because this is the modelâ€™s default value.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†`topK`è®¾ç½®ä¸º40ï¼Œå› ä¸ºè¿™æ˜¯æ¨¡å‹çš„é»˜è®¤å€¼ã€‚
- en: We set `topK` to 0.95, because this is the modelâ€™s default value.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†`topK`è®¾ç½®ä¸º0.95ï¼Œå› ä¸ºè¿™æ˜¯æ¨¡å‹çš„é»˜è®¤å€¼ã€‚
- en: 'We can now make the API call, similarly to any other API call we would make
    with the `[requests](https://pypi.org/project/requests/)` library, as shown below:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥åƒè¿›è¡Œä»»ä½•å…¶ä»–APIè°ƒç”¨ä¸€æ ·å‘å‡ºAPIè°ƒç”¨ï¼Œä½¿ç”¨`[requests](https://pypi.org/project/requests/)`åº“ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: Make an API call to the Google Cloud PaLM 2 for Text API.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å‘Google Cloud PaLM 2 for Text APIå‘å‡ºAPIè°ƒç”¨ã€‚
- en: 'We can get the output of the response with `response.json()[â€œpredictionsâ€][0][â€œcontentâ€]`:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡`response.json()[â€œpredictionsâ€][0][â€œcontentâ€]`æ¥è·å–å“åº”çš„è¾“å‡ºï¼š
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Neat! Now, letâ€™s do the exact same and try to set the `temperature` parameter
    to `1.0`. This will imply that our modelâ€™s output will become increasingly more
    creative. The output we get looks as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆæ£’ï¼ç°åœ¨ï¼Œè®©æˆ‘ä»¬åšå®Œå…¨ç›¸åŒçš„æ“ä½œå¹¶å°è¯•å°†`temperature`å‚æ•°è®¾ç½®ä¸º`1.0`ã€‚è¿™å°†æ„å‘³ç€æˆ‘ä»¬çš„æ¨¡å‹è¾“å‡ºå°†å˜å¾—è¶Šæ¥è¶Šå¯Œæœ‰åˆ›æ„ã€‚æˆ‘ä»¬å¾—åˆ°çš„è¾“å‡ºå¦‚ä¸‹ï¼š
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Indeed, we can see that the output is more creative than before and did not
    properly listen to our prompt mentioning that the â€œoutput should be in a python
    listâ€. Therefore, this a great learning that a **good choice of parameter values
    is very important** to obtain the desired output from the model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: çš„ç¡®ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¾“å‡ºæ¯”ä»¥å‰æ›´å…·åˆ›æ„ï¼Œå¹¶ä¸”æ²¡æœ‰æ­£ç¡®éµå¾ªæˆ‘ä»¬æåˆ°çš„â€œè¾“å‡ºåº”è¯¥æ˜¯ä¸€ä¸ªpythonåˆ—è¡¨â€çš„æç¤ºã€‚å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æ•™è®­ï¼Œå³**é€‰æ‹©åˆé€‚çš„å‚æ•°å€¼éå¸¸é‡è¦**ï¼Œä»¥ä»æ¨¡å‹ä¸­è·å¾—æœŸæœ›çš„è¾“å‡ºã€‚
- en: 'Now you might be asking yourself : â€œ*does this mean I cannot be sure that the
    model output is in the correct format?*â€ There are various mechanisms you can
    set in place in order to test your modelâ€™s output and check whether it corresponds
    to the format you expected. From understanding and correctly configuring the modelâ€™s
    input parameters, to refining your prompt (i. e. prompt engineering), as well
    as implementing additional static tests that can validate the outputâ€™s structure.
    It is highly recommended to apply these techniques, as Generative AI can make
    mistakes and we want to be sure to tackle them before they happen.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ å¯èƒ½ä¼šé—®è‡ªå·±ï¼šâ€œ*è¿™æ˜¯å¦æ„å‘³ç€æˆ‘ä¸èƒ½ç¡®å®šæ¨¡å‹è¾“å‡ºæ˜¯å¦ç¬¦åˆæ­£ç¡®çš„æ ¼å¼ï¼Ÿ*â€ æœ‰å¤šç§æœºåˆ¶å¯ä»¥è®¾ç½®ä»¥æµ‹è¯•æ¨¡å‹çš„è¾“å‡ºå¹¶æ£€æŸ¥å…¶æ˜¯å¦ç¬¦åˆä½ é¢„æœŸçš„æ ¼å¼ã€‚ä»ç†è§£å¹¶æ­£ç¡®é…ç½®æ¨¡å‹çš„è¾“å…¥å‚æ•°ï¼Œåˆ°ä¼˜åŒ–ä½ çš„æç¤ºï¼ˆå³æç¤ºå·¥ç¨‹ï¼‰ï¼Œä»¥åŠå®æ–½é¢å¤–çš„é™æ€æµ‹è¯•ä»¥éªŒè¯è¾“å‡ºçš„ç»“æ„ã€‚å¼ºçƒˆå»ºè®®åº”ç”¨è¿™äº›æŠ€æœ¯ï¼Œå› ä¸ºç”Ÿæˆå¼AIå¯èƒ½ä¼šå‡ºé”™ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨å®ƒä»¬å‘ç”Ÿä¹‹å‰å°±è§£å†³è¿™äº›é—®é¢˜ã€‚
- en: 'PaLM 2 for Text: Text Generation'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'PaLM 2 for Text: æ–‡æœ¬ç”Ÿæˆ'
- en: In our next example, letâ€™s ask PaLM 2 to **generate a welcome text** for new
    customers landing on an e-commerce website. We want to welcome them and offer
    a 20% discount code on their first purchase. For this use case, we want our model
    to come up with something a bit more creative. Therefore, we will set the `temperature`
    to `0.5`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªç¤ºä¾‹ä¸­ï¼Œè®©æˆ‘ä»¬è¦æ±‚PaLM 2ä¸ºæ–°å®¢æˆ·ç”Ÿæˆ**æ¬¢è¿æ–‡æœ¬**ï¼Œä»–ä»¬æ­£åœ¨è®¿é—®ä¸€ä¸ªç”µå­å•†åŠ¡ç½‘ç«™ã€‚æˆ‘ä»¬æƒ³æ¬¢è¿ä»–ä»¬ï¼Œå¹¶åœ¨é¦–æ¬¡è´­ä¹°æ—¶æä¾›20%çš„æŠ˜æ‰£ç ã€‚å¯¹äºè¿™ä¸ªç”¨ä¾‹ï¼Œæˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ¨¡å‹æå‡ºä¸€äº›æ›´å…·åˆ›æ„çš„å†…å®¹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†`temperature`è®¾ç½®ä¸º`0.5`ã€‚
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå¦‚ä¸‹ï¼š
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Nice! It even gave us the output in markdown format. Letâ€™s again try to adjust
    the `temperature` by setting it to `1.0` . The output is the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼å®ƒç”šè‡³ä»¥markdownæ ¼å¼ç»™å‡ºäº†è¾“å‡ºã€‚è®©æˆ‘ä»¬å†æ¬¡å°è¯•å°†`temperature`è°ƒæ•´ä¸º`1.0`ã€‚è¾“å‡ºå¦‚ä¸‹ï¼š
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can again see how much more creative our model is compared to the previous
    output. It even came up with an offer expiration date, without us explicitly telling
    it to do so.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å†æ¬¡å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„æ¨¡å‹ç›¸æ¯”ä¹‹å‰çš„è¾“å‡ºå˜å¾—æ›´åŠ å¯Œæœ‰åˆ›æ„ã€‚å®ƒç”šè‡³æå‡ºäº†ä¸€ä¸ªä¼˜æƒ è¿‡æœŸæ—¥æœŸï¼Œè€Œæˆ‘ä»¬å¹¶æ²¡æœ‰æ˜ç¡®è¦æ±‚å®ƒè¿™æ ·åšã€‚
- en: 'PaLM 2 for Chat: Conversational Assistant'
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'PaLM 2 for Chat: å¯¹è¯åŠ©æ‰‹'
- en: 'In the last example, we will test the PaLM 2 for Chat API which is more focused
    on generating a **conversational experience**. The model weâ€™ll be using is called
    `chat-bison`. It takes the following parameters as input:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ€åä¸€ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†æµ‹è¯•ä¸“æ³¨äºç”Ÿæˆ**å¯¹è¯ä½“éªŒ**çš„PaLM 2 for Chat APIã€‚æˆ‘ä»¬å°†ä½¿ç”¨çš„æ¨¡å‹ç§°ä¸º`chat-bison`ã€‚å®ƒæ¥å—ä»¥ä¸‹å‚æ•°ä½œä¸ºè¾“å…¥ï¼š
- en: '`messages`: contains the messages and messaging history with the bot.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`messages`ï¼šåŒ…å«ä¸èŠå¤©æœºå™¨äººä¹‹é—´çš„æ¶ˆæ¯å’Œæ¶ˆæ¯å†å²è®°å½•ã€‚'
- en: '`context`: defines â€œguidelinesâ€ for the botâ€™s behavior. For example: what the
    botâ€™s name is, what its role is, vocabulary to include/exclude, etc.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`context`ï¼šå®šä¹‰èŠå¤©æœºå™¨äººè¡Œä¸ºçš„â€œæŒ‡å—â€ã€‚ä¾‹å¦‚ï¼šèŠå¤©æœºå™¨äººçš„åç§°æ˜¯ä»€ä¹ˆï¼Œå®ƒçš„è§’è‰²æ˜¯ä»€ä¹ˆï¼ŒåŒ…å«/æ’é™¤çš„è¯æ±‡ç­‰ã€‚'
- en: '`examples`: sample input and output of how the bot should respond in the conversation.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`examples`ï¼šç¤ºä¾‹è¾“å…¥å’Œè¾“å‡ºï¼Œå±•ç¤ºäº†èŠå¤©æœºå™¨äººåœ¨å¯¹è¯ä¸­çš„å“åº”æ–¹å¼ã€‚'
- en: as well as `temperature`, `maxOutputTokens`, `topK` and `topP` which do the
    same as for the `text-bison` model in the previous section.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»¥åŠ`temperature`ã€`maxOutputTokens`ã€`topK`å’Œ`topP`ï¼Œå®ƒä»¬çš„ä½œç”¨ä¸å‰ä¸€èŠ‚ä¸­çš„`text-bison`æ¨¡å‹ç›¸åŒã€‚
- en: '*For more details on the parameters and what they exactly do, see* [*this documentation*](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-chat#generative-ai-text-chat-drest)*.*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ‰å…³å‚æ•°åŠå…¶å…·ä½“ä½œç”¨çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§* [*æ­¤æ–‡æ¡£*](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text-chat#generative-ai-text-chat-drest)*ã€‚*'
- en: Letâ€™s create a chatbot which will serve as a **customer support agent** for
    an online gardening store â€œ**GardenWorld**â€. The bot should respond to questions
    around plant and flower types, gardening tools, etc. We want the bot to always
    be friendly and welcoming to customers, and it should greet customers with â€œHoowdy
    gardener! ğŸŒ±â€ as well as motivate customers to sign up to the newsletter to receive
    a 10% discount code on their first purchase.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ¥åˆ›å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œä½œä¸ºåœ¨çº¿å›­è‰ºå•†åº—â€œ**GardenWorld**â€çš„**å®¢æˆ·æ”¯æŒä»£è¡¨**ã€‚è¿™ä¸ªæœºå™¨äººåº”å½“èƒ½å¤Ÿå›ç­”æœ‰å…³æ¤ç‰©å’ŒèŠ±å‰ç±»å‹ã€å›­è‰ºå·¥å…·ç­‰é—®é¢˜ã€‚æˆ‘ä»¬å¸Œæœ›æœºå™¨äººå§‹ç»ˆå¯¹å®¢æˆ·å‹å¥½å’Œçƒ­æƒ…ï¼Œå¹¶ä¸”åº”è¯¥ç”¨â€œHoowdy
    gardener! ğŸŒ±â€æ¥é—®å€™å®¢æˆ·ï¼Œå¹¶æ¿€åŠ±å®¢æˆ·æ³¨å†Œæ–°é—»é€šè®¯ä»¥è·å¾—é¦–æ¬¡è´­ä¹°çš„10%æŠ˜æ‰£ç ã€‚
- en: 'We can define this by setting the `context` and the `examples` parameters as
    shown below:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¾ç½®`context`å’Œ`examples`å‚æ•°æ¥å®šä¹‰è¿™äº›ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We will give our model three examples of what its output should look like. Of
    course, the **more examples** we give, the more the bot can be **customized**
    and the **better** the model will be able to learn what we expect from it. Since
    our use case is very simple, these three examples should give the bot enough information
    to provide us with the right answer structure. We will set the `temperature` to
    `1.0`, `maxOutputTokens` to `256`, `topK` to `40` and `topP` to `0.95`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ç»™æ¨¡å‹ä¸‰ä¸ªç¤ºä¾‹ï¼Œè¯´æ˜è¾“å‡ºåº”æ˜¯ä»€ä¹ˆæ ·çš„ã€‚å½“ç„¶ï¼Œ**æˆ‘ä»¬æä¾›çš„ç¤ºä¾‹è¶Šå¤š**ï¼Œæœºå™¨äººå¯ä»¥**å®šåˆ¶**çš„ç¨‹åº¦å°±è¶Šé«˜ï¼Œæ¨¡å‹å°†èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ æˆ‘ä»¬æœŸæœ›çš„å†…å®¹ã€‚ç”±äºæˆ‘ä»¬çš„ç”¨ä¾‹éå¸¸ç®€å•ï¼Œè¿™ä¸‰ä¸ªç¤ºä¾‹åº”è¯¥èƒ½ç»™æœºå™¨äººè¶³å¤Ÿçš„ä¿¡æ¯æ¥æä¾›æ­£ç¡®çš„ç­”æ¡ˆç»“æ„ã€‚æˆ‘ä»¬å°†`temperature`è®¾ç½®ä¸º`1.0`ï¼Œ`maxOutputTokens`è®¾ç½®ä¸º`256`ï¼Œ`topK`è®¾ç½®ä¸º`40`ï¼Œ`topP`è®¾ç½®ä¸º`0.95`ã€‚
- en: Now, letâ€™s start the conversation by saying â€œ**Hi!**â€.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å¼€å§‹å¯¹è¯ï¼Œå…ˆè¯´â€œ**Hi!**â€ã€‚
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then we can make the API call:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥è¿›è¡ŒAPIè°ƒç”¨ï¼š
- en: Make an API call to the Google Cloud PaLM 2 for Chat API.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å‘Google Cloud PaLM 2è¿›è¡ŒèŠå¤©APIè°ƒç”¨ã€‚
- en: 'After a few seconds, we get the following response back:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ç§’é’Ÿåï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹å›å¤ï¼š
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Nice! Our model did exactly what we asked it to do: it used the correct greeting
    (even including the emoji ğŸŒ±) and mentioned the 10% discount code.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼æˆ‘ä»¬çš„æ¨¡å‹å‡†ç¡®åœ°å®Œæˆäº†æˆ‘ä»¬çš„è¦æ±‚ï¼šå®ƒä½¿ç”¨äº†æ­£ç¡®çš„é—®å€™è¯­ï¼ˆç”šè‡³åŒ…æ‹¬äº†è¡¨æƒ…ç¬¦å·ğŸŒ±ï¼‰ï¼Œå¹¶æåˆ°äº†10%æŠ˜æ‰£ç ã€‚
- en: 'In order to continue our conversation with the bot, we will have to update
    the **conversation history** accordingly. We can define two simple functions which
    we can invoke after every API call:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç»§ç»­ä¸æœºå™¨äººå¯¹è¯ï¼Œæˆ‘ä»¬éœ€è¦ç›¸åº”åœ°æ›´æ–°**å¯¹è¯å†å²**ã€‚æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸¤ä¸ªç®€å•çš„å‡½æ•°ï¼Œåœ¨æ¯æ¬¡APIè°ƒç”¨åè°ƒç”¨å®ƒä»¬ï¼š
- en: Functions to update the chatbots message history.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´æ–°èŠå¤©æœºå™¨äººçš„æ¶ˆæ¯å†å²çš„åŠŸèƒ½ã€‚
- en: '`update_history()` will add the most recent bot reply to the `messages` list.
    Then we can use `send_message()` to send a new question to the bot â€œ**I need a
    nice houseplant that is easy to take care of. What can you recommend?**â€.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`update_history()`å°†æœ€æ–°çš„æœºå™¨äººå›å¤æ·»åŠ åˆ°`messages`åˆ—è¡¨ä¸­ã€‚ç„¶åæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`send_message()`å‘æœºå™¨äººå‘é€ä¸€ä¸ªæ–°é—®é¢˜â€œ**æˆ‘éœ€è¦ä¸€æ ªæ˜“äºç…§æ–™çš„æ¼‚äº®å®¤å†…æ¤ç‰©ã€‚ä½ æœ‰ä»€ä¹ˆæ¨èï¼Ÿ**â€ã€‚'
- en: 'Now our `messages` variable looks as following, with the most recent message
    at the end of the list:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„`messages`å˜é‡å¦‚ä¸‹æ‰€ç¤ºï¼Œæœ€æ–°çš„æ¶ˆæ¯ä½äºåˆ—è¡¨æœ«å°¾ï¼š
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can include the `messages` history in the next API call and the response
    we get back is the following:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨ä¸‹ä¸€æ¬¡APIè°ƒç”¨ä¸­åŒ…å«`messages`å†å²è®°å½•ï¼Œå¾—åˆ°çš„å›å¤æ˜¯ï¼š
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: It suggested us to choose the â€œ[Snake Plant](https://www.almanac.com/plant/snake-plants)â€
    which is a houseplant known to be easy to take care of. Letâ€™s also add this message
    to the `messages` history.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒå»ºè®®æˆ‘ä»¬é€‰æ‹©â€œ[è›‡å°¾å…°](https://www.almanac.com/plant/snake-plants)â€ï¼Œè¿™æ˜¯ä¸€ç§è¢«è®¤ä¸ºæ˜“äºç…§æ–™çš„å®¤å†…æ¤ç‰©ã€‚è®©æˆ‘ä»¬å°†è¿™æ¡æ¶ˆæ¯ä¹Ÿæ·»åŠ åˆ°`messages`å†å²è®°å½•ä¸­ã€‚
- en: 'Then, letâ€™s ask one last question â€œ**Any alternatives you can suggest? Also,
    can I get a discount?**â€. The response we get back is:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬æå‡ºæœ€åä¸€ä¸ªé—®é¢˜â€œ**ä½ èƒ½å»ºè®®ä¸€äº›æ›¿ä»£æ–¹æ¡ˆå—ï¼Ÿå¦å¤–ï¼Œæˆ‘å¯ä»¥è·å¾—æŠ˜æ‰£å—ï¼Ÿ**â€æˆ‘ä»¬å¾—åˆ°çš„å›å¤æ˜¯ï¼š
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Great! As we see above, the bot suggested our discount code, and thanks to the
    `messages` history, it remembered the question we asked previously and suggested
    a â€œ[ZZ plant](https://www.gardenersworld.com/how-to/grow-plants/how-to-grow-zz-plant-zamioculcas-zamiifolia/)â€
    an alternative plant which is easy to care for.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¥½ï¼å¦‚ä¸Šæ‰€ç¤ºï¼Œæœºå™¨äººå»ºè®®äº†æˆ‘ä»¬çš„æŠ˜æ‰£ç ï¼Œæ„Ÿè°¢`messages`å†å²è®°å½•ï¼Œå®ƒè®°ä½äº†æˆ‘ä»¬ä¹‹å‰æå‡ºçš„é—®é¢˜ï¼Œå¹¶å»ºè®®äº†ä¸€ä¸ªå®¹æ˜“æ‰“ç†çš„æ¤ç‰©â€œ[ZZ plant](https://www.gardenersworld.com/how-to/grow-plants/how-to-grow-zz-plant-zamioculcas-zamiifolia/)â€ã€‚
- en: 'The results show us, how **easily** and **quickly** we can get a **custom chatbot**
    up and running: only by giving three `examples` and a high-level `context` , the
    bot was able to **understand** what we expected from it and correctly return the
    information during the conversation. Imagine we would provide it with hundreds,
    or even thousands of additional `examples` â€” the potential is huge!'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå±•ç¤ºäº†æˆ‘ä»¬å¦‚ä½•**è½»æ¾**ä¸”**è¿…é€Ÿ**åœ°è®©ä¸€ä¸ª**è‡ªå®šä¹‰èŠå¤©æœºå™¨äºº**è¿è¡Œèµ·æ¥ï¼šåªéœ€æä¾›ä¸‰ä¸ª`ç¤ºä¾‹`å’Œä¸€ä¸ªé«˜å±‚æ¬¡çš„`ä¸Šä¸‹æ–‡`ï¼Œæœºå™¨äººå°±èƒ½å¤Ÿ**ç†è§£**æˆ‘ä»¬çš„æœŸæœ›ï¼Œå¹¶åœ¨å¯¹è¯ä¸­æ­£ç¡®è¿”å›ä¿¡æ¯ã€‚æƒ³è±¡ä¸€ä¸‹å¦‚æœæˆ‘ä»¬æä¾›æ•°ç™¾ç”šè‡³æ•°åƒä¸ªé¢å¤–çš„`ç¤ºä¾‹`â€”â€”æ½œåŠ›å·¨å¤§ï¼
- en: 4 | Conclusion
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 | ç»“è®º
- en: In this article we have seen how **easy** it is to make use of the Google Cloud
    **PaLM 2 APIs**, using both the `text-bison` and `chat-bison` models. We have
    seen how we can **authenticate** remotely to our Google Cloud project using the
    Python `[google-auth](https://pypi.org/project/google-auth/)` library and make
    calls to the APIs using the `[requests](https://pypi.org/project/requests/)` library.
    Lastly, we have seen how these APIs can be **customized** by adjusting and playing
    around with the input parameters.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°åˆ©ç”¨ Google Cloud çš„**PaLM 2 APIs**æ˜¯å¤šä¹ˆ**ç®€å•**ï¼Œä½¿ç”¨äº†`text-bison`å’Œ`chat-bison`æ¨¡å‹ã€‚æˆ‘ä»¬äº†è§£åˆ°å¦‚ä½•ä½¿ç”¨
    Python çš„`[google-auth](https://pypi.org/project/google-auth/)`åº“è¿›è¡Œè¿œç¨‹**è®¤è¯**ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨`[requests](https://pypi.org/project/requests/)`åº“è°ƒç”¨è¿™äº›
    APIsã€‚æœ€åï¼Œæˆ‘ä»¬çœ‹åˆ°å¦‚ä½•é€šè¿‡è°ƒæ•´å’Œç©è½¬è¾“å…¥å‚æ•°æ¥**å®šåˆ¶**è¿™äº› APIsã€‚
- en: I hope this article was informative for you and gave you some inspiration and
    ideas on how to get started using the PaLM 2 APIs! ğŸª´ğŸ¤–
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰å¸®åŠ©ï¼Œå¹¶ç»™ä½ ä¸€äº›çµæ„Ÿå’Œå…³äºå¦‚ä½•å¼€å§‹ä½¿ç”¨ PaLM 2 APIs çš„æƒ³æ³•ï¼ ğŸª´ğŸ¤–
- en: ğŸ”œğŸ”œ In the upcoming **part 2 of this article**, we will focus on **Prompt Engineering
    with PaLM 2 APIs** and cover how we can make our input prompts and model parameter
    selections better.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ”œğŸ”œ åœ¨å³å°†åˆ°æ¥çš„**ç¬¬äºŒéƒ¨åˆ†**ä¸­ï¼Œæˆ‘ä»¬å°†ä¸“æ³¨äº**ä½¿ç”¨ PaLM 2 APIs è¿›è¡Œæç¤ºå·¥ç¨‹**ï¼Œå¹¶æ¢è®¨å¦‚ä½•æ›´å¥½åœ°ä¼˜åŒ–è¾“å…¥æç¤ºå’Œæ¨¡å‹å‚æ•°é€‰æ‹©ã€‚
- en: '*Feedback or questions? Feel free to reach out in the comment section!* ğŸ’¬'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*åé¦ˆæˆ–é—®é¢˜ï¼Ÿè¯·éšæ—¶åœ¨è¯„è®ºåŒºè”ç³»æˆ‘ï¼* ğŸ’¬'
- en: ğŸ“š Keen on learning more? Check out [Generative AI on Google Cloud](https://cloud.google.com/ai/generative-ai)
    or try out the free [Generative AI Learning Path](https://www.cloudskillsboost.google/journeys/118)
    on Google Cloud Skills Boost.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“š æƒ³äº†è§£æ›´å¤šï¼ŸæŸ¥çœ‹ [Google Cloud ä¸Šçš„ç”Ÿæˆ AI](https://cloud.google.com/ai/generative-ai)
    æˆ–å°è¯• Google Cloud Skills Boost ä¸Šå…è´¹çš„ [ç”Ÿæˆ AI å­¦ä¹ è·¯å¾„](https://www.cloudskillsboost.google/journeys/118)ã€‚
- en: References
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] Gartner, [Gartner Experts Answer the Top Generative AI Questions for Your
    Enterprise](https://www.gartner.com/en/topics/generative-ai), Accessed 13 August
    2023.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Gartner, [Gartner ä¸“å®¶å›ç­”æ‚¨çš„ä¼ä¸šç”Ÿæˆ AI é¡¶çº§é—®é¢˜](https://www.gartner.com/en/topics/generative-ai)ï¼Œè®¿é—®æ—¥æœŸï¼š2023å¹´8æœˆ13æ—¥ã€‚'
- en: '[2] CB Insights, [The State of Generative AI in 7 Charts](https://www.cbinsights.com/research/generative-ai-funding-top-startups-investors/),
    2 August 2023.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] CB Insights, [ç”Ÿæˆ AI çš„ç°çŠ¶ï¼š7 å¼ å›¾è¡¨](https://www.cbinsights.com/research/generative-ai-funding-top-startups-investors/)ï¼Œ2023å¹´8æœˆ2æ—¥ã€‚'
- en: '[3] Google Cloud, [Overview of Generative AI Support on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview),
    Accessed 13 August 2023.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Google Cloud, [Vertex AI ä¸Šç”Ÿæˆ AI æ”¯æŒæ¦‚è§ˆ](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)ï¼Œè®¿é—®æ—¥æœŸï¼š2023å¹´8æœˆ13æ—¥ã€‚'
