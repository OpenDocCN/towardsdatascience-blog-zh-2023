- en: Getting started with JAX
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 JAX
- en: 原文：[https://towardsdatascience.com/getting-started-with-jax-a6f8d8d0e20](https://towardsdatascience.com/getting-started-with-jax-a6f8d8d0e20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/getting-started-with-jax-a6f8d8d0e20](https://towardsdatascience.com/getting-started-with-jax-a6f8d8d0e20)
- en: Powering the future of high-performance numerical computing and ML research
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推动高性能数值计算和机器学习研究的未来
- en: '[](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)[![Pier
    Paolo Ippolito](../Images/981abb84149adab275473b76bdbde66f.png)](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)
    [Pier Paolo Ippolito](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)[![Pier
    Paolo Ippolito](../Images/981abb84149adab275473b76bdbde66f.png)](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)
    [Pier Paolo Ippolito](https://pierpaoloippolito28.medium.com/?source=post_page-----a6f8d8d0e20--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)
    ·5 min read·Jul 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a6f8d8d0e20--------------------------------)
    ·阅读时间 5 分钟·2023 年 7 月 7 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/17e806ec59ab7110eb1eb8acbdca9117.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17e806ec59ab7110eb1eb8acbdca9117.png)'
- en: Photo by [Lance Asper](https://unsplash.com/@lance_asper?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Lance Asper](https://unsplash.com/@lance_asper?utm_source=medium&utm_medium=referral)
    提供的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: JAX is a Python library developed by Google to perform high-performance numerical
    computing on any type of device (CPU, GPU, TPU, etc…). One of the main applications
    of JAX is Machine Learning and Deep Learning research development, although the
    library is mainly designed to provide all the necessary capabilities to perform
    general-purpose scientific computing tasks (highly dimensional matrices operations,
    etc…).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: JAX 是 Google 开发的一个 Python 库，用于在任何类型的设备（CPU、GPU、TPU 等）上进行高性能数值计算。JAX 的主要应用之一是机器学习和深度学习研究开发，尽管该库主要设计用于提供执行通用科学计算任务（高度维度矩阵操作等）的所有必要功能。
- en: Considering the focus specifically on high-performance computing, JAX has been
    designed to be extremely fast being built on top of XLA (Accelerated Linear Algebra).
    XLA is in fact a compiler designed to speed up linear algebra operations and can
    be used to work behind also other frameworks such as TensorFlow and Pytorch. Additionally,
    JAX arrays have been designed to follow the same principles as Numpy, making it
    really easy to migrate old Numpy code to JAX and take advantage of performance
    speed-ups through GPUs and TPUs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到特别关注高性能计算，JAX 被设计为在 XLA（加速线性代数）的基础上极其快速。XLA 实际上是一个编译器，旨在加速线性代数操作，并且可以在 TensorFlow
    和 Pytorch 等其他框架的后台工作。此外，JAX 数组被设计为遵循与 Numpy 相同的原则，使得迁移旧的 Numpy 代码到 JAX 变得非常容易，并通过
    GPU 和 TPU 获得性能提升。
- en: 'Some of the main characteristics of JAX are:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: JAX 的主要特点包括：
- en: '**Just in Time (JIT) compilation**: JIT and accelerated hardware are what can
    enable JAX to be much faster than plain Numpy. Using the *jit()* function can
    be possible to compile and cache custom functions with the XLA kernel. Using caching
    we will increase the overall execution time we first run the function, to then
    drastically reduce the time for the successive runs. When using caching it is
    important to make sure to clear the caches when needed in order to avoid stale
    results (e.g. global variables changing).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**即时编译（JIT）**：JIT 和加速硬件使 JAX 比普通的 Numpy 快得多。使用 *jit()* 函数可以编译并缓存自定义函数与 XLA
    内核。通过缓存，我们将增加首次运行函数的总体执行时间，从而大幅减少随后的运行时间。在使用缓存时，确保在需要时清除缓存以避免过时结果（例如，全局变量变化）是很重要的。'
- en: '**Automatic Parallelization:** Asynchronous Dispatch enables JAX vectors to
    be lazily evaluated, materializing content just when accessed (control is returned
    to the program before computation completion). Additionally, in order to make
    possible graph optimization, JAX arrays are immutable (similar concepts with lazy
    evaluation and graph optimization applies to [Apache Spark](/getting-started-with-apache-spark-cb703e1b3ee9)).
    The *pmap()* function can be used to parallelize computations on multiple GPUs/TPUs.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动并行化**：异步调度使得 JAX 向量可以延迟计算，仅在访问时才生成内容（在计算完成之前控制权返回程序）。此外，为了实现图优化，JAX 数组是不可变的（类似的概念包括延迟计算和图优化，适用于
    [Apache Spark](/getting-started-with-apache-spark-cb703e1b3ee9)）。*pmap()* 函数可以用于在多个
    GPU/TPU 上并行计算。'
- en: '**Automatic Vectorization**: Automatic vectorization to parallelize operations
    can be performed using the *vmap()* function. During vectorization, an algorithm
    is transformed from operating with a single value to a set of values.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动矢量化**：可以使用 *vmap()* 函数进行自动矢量化以并行化操作。在矢量化过程中，算法从对单个值的操作转变为对一组值的操作。'
- en: '**Automatic Differentiation**: The *grad()* function can be used to automatically
    calculate the gradient (derivative) of functions. In particular, JAX Automatic
    Differentiation enables the development of general-purpose differential programs
    outside the spectrum of Deep Learning. Making it possible to differentiate through
    recursion, branches, loops, perform higher-order differentiation (e.g. Jacobians
    and Hessians), and using both forward and reverse mode differentiation.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动微分**：*grad()* 函数可以用于自动计算函数的梯度（导数）。特别是，JAX 自动微分使得在深度学习领域之外开发通用的微分程序成为可能。可以通过递归、分支、循环进行微分，执行高阶微分（例如，雅可比矩阵和海森矩阵），并使用前向和反向模式微分。'
- en: Therefore JAX is able to provide us with all the necessary foundations to build
    advanced Deep Learning models but not out-of-the-box high-level utils for some
    of the most common Deep Learning operations (e.g. loss/activation functions, layers,
    etc…). For example, model parameters learned during ML training can be stored
    in a Pytree structure in JAX. Considering all the advantages provided by JAX different
    DL-oriented frameworks have been built on top of it such as Haiku (used by DeepMind)
    and Flax (used by Google Brain).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，JAX 能为我们提供构建先进深度学习模型所需的所有基础，但没有提供一些最常见深度学习操作（例如，损失/激活函数、层等）的开箱即用的高级工具。例如，在
    ML 训练过程中学到的模型参数可以存储在 JAX 的 Pytree 结构中。考虑到 JAX 提供的所有优势，不同的深度学习框架已经在其基础上构建，例如 Haiku（由
    DeepMind 使用）和 Flax（由 Google Brain 使用）。
- en: Demonstration
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 演示
- en: As part of this article, we are now going to see how to solve a simple classification
    problem using JAX and the [Kaggle Mobile Price Classification dataset](https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification)
    [1] to predict in which price range a phone will be. All the code used throughout
    this article (and more!) is available on [my GitHub](https://github.com/pierpaolo28)
    and [Kaggle accounts](https://www.kaggle.com/pierpaolo28).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本文的一部分，我们将看到如何使用 JAX 和 [Kaggle 移动价格分类数据集](https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification)
    [1] 来解决一个简单的分类问题，以预测手机的价格范围。本文中使用的所有代码（以及更多！）都可以在 [我的 GitHub](https://github.com/pierpaolo28)
    和 [Kaggle 账户](https://www.kaggle.com/pierpaolo28) 上找到。
- en: First of all, we need to make sure to have JAX installed in our environment.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要确保在环境中安装了 JAX。
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: At this point, we are ready to import the necessary libraries and datasets (Figure
    1). In order to simplify our analysis, instead of using all the classes in our
    label we filter the data to use just 2 classes and subset the number of features.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们已经准备好导入必要的库和数据集（图 1）。为了简化分析，我们不使用所有标签中的类别，而是过滤数据以仅使用 2 个类别，并减少特征的数量。
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/650db3e4167067f50af65e416b5a9563.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/650db3e4167067f50af65e416b5a9563.png)'
- en: 'Figure 1: Mobile Price Classification Dataset (Image by Author).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：移动价格分类数据集（图片由作者提供）。
- en: Once cleaned the dataset, we can now divide it into training and test subsets
    and standardize the input features so that to make sure they all lie within the
    same ranges. At this point, the input data is also converted in JAX arrays.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集清理完成后，我们可以将其划分为训练集和测试集，并标准化输入特征，以确保它们都位于相同范围内。此时，输入数据也被转换为 JAX 数组。
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In order to predict the price range of the phones, we are going to create a
    Logistic Regression model from scratch. To do so, we first need to create a couple
    of helper functions (one to create the Sigmoid activation function, and another
    for the binary loss function).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测手机的价格范围，我们将从零开始创建一个逻辑回归模型。为此，我们首先需要创建几个辅助函数（一个用于创建 Sigmoid 激活函数，另一个用于二元损失函数）。
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We are now ready to create our training loop and plot the results (Figure 2).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备创建训练循环并绘制结果（图 2）。
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/6204d9b6d257691a91df3ceb667ba819.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6204d9b6d257691a91df3ceb667ba819.png)'
- en: 'Figure 2: Logistic Regression Training History (Image by Author).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: 逻辑回归训练历史（作者提供的图片）。'
- en: Once happy with the results, we can then test the model against our test set
    (Figure 3).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦对结果感到满意，我们可以将模型在我们的测试集上进行测试（图 3）。
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/effce9fd630a04de06c437405e3f83b1.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/effce9fd630a04de06c437405e3f83b1.png)'
- en: 'Figure 3: Classification Report on Test Data (Image by Author).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 测试数据分类报告（作者提供的图片）。'
- en: Conclusion
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: As demonstrated in this brief example, JAX has a very intuitive API that closely
    follows Numpy conventions while making it possible to use the same code for CPU/GPU/TPU
    usage. Making use of these building blocks it can then be possible to create highly
    customizable Deep Learning models optimized by design for performance.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如本简要示例所示，JAX 具有非常直观的 API，紧密遵循 Numpy 的约定，同时使得在 CPU/GPU/TPU 上使用相同的代码成为可能。利用这些构建块，可以创建高可定制的深度学习模型，这些模型在设计时已优化以提高性能。
- en: Contacts
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系方式
- en: 'If you want to keep updated with my latest articles and projects [follow me
    on Medium](https://pierpaoloippolito28.medium.com/subscribe) and subscribe to
    my [mailing list](http://eepurl.com/gwO-Dr). These are some of my contacts details:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想保持更新我的最新文章和项目，请[在 Medium 上关注我](https://pierpaoloippolito28.medium.com/subscribe)并订阅我的[邮件列表](http://eepurl.com/gwO-Dr)。以下是我的一些联系方式：
- en: '[Linkedin](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Linkedin](https://uk.linkedin.com/in/pier-paolo-ippolito-202917146)'
- en: '[Personal Website](https://pierpaolo28.github.io/)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[个人网站](https://pierpaolo28.github.io/)'
- en: '[Medium Profile](https://towardsdatascience.com/@pierpaoloippolito28)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Medium 个人主页](https://towardsdatascience.com/@pierpaoloippolito28)'
- en: '[GitHub](https://github.com/pierpaolo28)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[GitHub](https://github.com/pierpaolo28)'
- en: '[Kaggle](https://www.kaggle.com/pierpaolo28)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kaggle](https://www.kaggle.com/pierpaolo28)'
- en: Bibliography
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] “Mobile Price Classification” (ABHISHEK SHARMA). Accessed at: [https://thecleverprogrammer.com/2021/03/05/mobile-price-classification-with-machine-learning/](https://thecleverprogrammer.com/2021/03/05/mobile-price-classification-with-machine-learning/)
    (MIT License: [https://github.com/alifrmf/Mobile-Price-Prediction-Classification-Analysis/tree/main](https://github.com/alifrmf/Mobile-Price-Prediction-Classification-Analysis/tree/main))'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] “移动价格分类”（ABHISHEK SHARMA）。访问地址：[https://thecleverprogrammer.com/2021/03/05/mobile-price-classification-with-machine-learning/](https://thecleverprogrammer.com/2021/03/05/mobile-price-classification-with-machine-learning/)（MIT
    许可证: [https://github.com/alifrmf/Mobile-Price-Prediction-Classification-Analysis/tree/main](https://github.com/alifrmf/Mobile-Price-Prediction-Classification-Analysis/tree/main)）'
