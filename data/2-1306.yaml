- en: Image Registration for Medical Datasets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 医学数据集的图像配准
- en: 原文：[https://towardsdatascience.com/image-registration-for-medical-datasets-ee605ff8eb2e](https://towardsdatascience.com/image-registration-for-medical-datasets-ee605ff8eb2e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/image-registration-for-medical-datasets-ee605ff8eb2e](https://towardsdatascience.com/image-registration-for-medical-datasets-ee605ff8eb2e)
- en: From SimpleElastix to Spatial Transformer Networks
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 SimpleElastix 到空间变换网络
- en: '[](https://charlieoneill.medium.com/?source=post_page-----ee605ff8eb2e--------------------------------)[![Charlie
    O''Neill](../Images/17aa117fc5787f93ff1f547b919786c8.png)](https://charlieoneill.medium.com/?source=post_page-----ee605ff8eb2e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ee605ff8eb2e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ee605ff8eb2e--------------------------------)
    [Charlie O''Neill](https://charlieoneill.medium.com/?source=post_page-----ee605ff8eb2e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://charlieoneill.medium.com/?source=post_page-----ee605ff8eb2e--------------------------------)[![Charlie
    O''Neill](../Images/17aa117fc5787f93ff1f547b919786c8.png)](https://charlieoneill.medium.com/?source=post_page-----ee605ff8eb2e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ee605ff8eb2e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ee605ff8eb2e--------------------------------)
    [Charlie O''Neill](https://charlieoneill.medium.com/?source=post_page-----ee605ff8eb2e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ee605ff8eb2e--------------------------------)
    ·31 min read·Feb 22, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ee605ff8eb2e--------------------------------)
    ·阅读时间 31 分钟·2023年2月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ec059b4593a0bbe23845d204100454c1.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec059b4593a0bbe23845d204100454c1.png)'
- en: Photo by [Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Image registration is a fundamental task in image processing that involves aligning
    two or more images to a common coordinate system. By doing so, corresponding pixels
    in the images represent homologous points in the real world, enabling comparison
    and analysis of the images. One common application of image registration is in
    medical imaging, where multiple scans or images of the same patient are taken
    over time, with variations due to differences in time, position, or other factors.
    Registering these images can reveal subtle changes or patterns that may be indicative
    of disease progression or treatment efficacy.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准是图像处理中的一项基础任务，涉及将两个或多个图像对齐到一个共同的坐标系统中。通过这样做，图像中的对应像素表示现实世界中的同源点，从而使图像的比较和分析成为可能。图像配准的一个常见应用是在医学成像中，其中对同一患者进行多次扫描或拍摄，由于时间、位置或其他因素的不同而产生变化。配准这些图像可以揭示出可能指示疾病进展或治疗效果的微妙变化或模式。
- en: Image registration involves finding a spatial transformation that maps points
    in one image to corresponding points in the other image(s), so that the images
    can be superimposed on each other. The spatial transformation is typically parameterised
    by a set of control points, which are used to warp one image to match the other.
    The quality of the registration is measured by a similarity metric, which quantifies
    the degree of correspondence between the images.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准涉及寻找一种空间变换，将一个图像中的点映射到另一个图像中的对应点，以便可以将图像重叠在一起。空间变换通常由一组控制点参数化，这些控制点用于将一个图像扭曲以匹配另一个图像。配准的质量通过相似度度量来衡量，该度量量化了图像之间的对应程度。
- en: In recent years, there has been a growing interest in medical image registration
    due to the availability of advanced imaging modalities, increasing computing power,
    and the need for more accurate and efficient analysis of medical images. Image
    registration has become a prerequisite for a wide range of medical image analysis
    tasks, including segmentation of anatomical structures, computer-aided diagnosis,
    monitoring of disease progression, surgical intervention, and treatment planning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，由于先进成像技术的出现、计算能力的提升以及对更准确和高效医学图像分析的需求，医学图像配准引起了越来越多的关注。图像配准已经成为广泛医学图像分析任务的前提条件，包括解剖结构的分割、计算机辅助诊断、疾病进展监测、外科干预和治疗规划。
- en: Despite the significant amount of research that has focused on developing image
    registration algorithms, there has been relatively little attention paid to the
    accessibility, interoperability, and extensibility of these algorithms. Scientific
    source code is often not published, is difficult to use because it has not been
    written with other researchers in mind, or lacks proper documentation. This has
    limited the adoption and use of image registration algorithms, hindering scientific
    advancement and reproducibility.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大量研究集中在开发图像配准算法上，但对这些算法的可访问性、互操作性和扩展性关注较少。科学源代码通常未公开，因未考虑其他研究人员的需求而难以使用，或缺乏适当的文档。这限制了图像配准算法的采用和使用，阻碍了科学进步和可重复性。
- en: To address these challenges, several open-source libraries for medical image
    registration have been developed, with SimpleElastix being one of the most popular.
    SimpleElastix is an extension of SimpleITK, an open-source library for medical
    image analysis, that allows users to configure and run the Elastix registration
    algorithm entirely in Python, Java, R, Octave, Ruby, Lua, Tcl, and C#. SimpleElastix
    offers a simple parameter interface, modular architecture, and a range of transforms,
    metrics, and optimizers, making it easy to use and computationally efficient.
    It also provides a range of features such as stochastic sampling, multi-threading,
    and code optimization to make registration run faster without sacrificing robustness.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战，开发了几个开源医学图像配准库，其中 SimpleElastix 是最受欢迎的之一。SimpleElastix 是 SimpleITK
    的扩展，SimpleITK 是一个开源医学图像分析库，允许用户完全在 Python、Java、R、Octave、Ruby、Lua、Tcl 和 C# 中配置和运行
    Elastix 配准算法。SimpleElastix 提供了一个简单的参数接口、模块化架构和多种变换、度量和优化器，使其易于使用且计算高效。它还提供了一系列功能，如随机采样、多线程和代码优化，以加快配准速度，而不牺牲鲁棒性。
- en: Here, I’ll explore the process of image registration using SimpleElastix, focusing
    on the specific example of registering fundus images from geographic atrophy patients.
    I’ll also provide a step-by-step guide to implementing this registration process,
    along with an exploration of other techniques such as optical flow and spatial
    transformer networks. Hopefully, this will give you a better understanding of
    the importance of image registration in medical imaging and the tools available
    to implement it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将深入探讨使用 SimpleElastix 进行图像配准的过程，重点介绍注册来自地理萎缩患者的视网膜图像的具体示例。我还将提供实施这一配准过程的逐步指南，并探讨其他技术，如光流和空间变换网络。希望这能让你更好地理解医学成像中图像配准的重要性以及实施它的工具。
- en: Setup
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置
- en: The task is taking fundus images (photographs of the inner surface of an eye)
    from geographic atrophy patients (a type of eye disease) and registering these
    images *inter-patient* i.e. images from the same patient are only registered to
    that patient. For context, geographic atrophy (GA) is characterised by the loss
    of retinal pigment epithelium cells, which are responsible for supporting and
    nourishing the photoreceptor cells in the macula, the central part of the retina
    that is responsible for sharp, detailed vision. The loss of RPE cells results
    in the formation of one or more areas of atrophy, or “holes,” in the macula, which
    can cause central vision loss and affect a person’s ability to perform everyday
    tasks such as reading, driving, and recognising faces. You’ll notice these areas
    of atrophy in the fundus images below.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 任务是处理来自地理萎缩患者（眼病的一种）的视网膜图像，并将这些图像进行*患者间*注册，即仅将来自同一患者的图像注册到该患者。为了解释一下，地理萎缩（GA）特征是视网膜色素上皮细胞的丧失，这些细胞负责支持和滋养黄斑中的视网膜感光细胞。视网膜色素上皮细胞的丧失会导致黄斑中出现一个或多个萎缩区或“孔洞”，这可能导致中心视力丧失，影响个人进行日常活动，如阅读、驾驶和面孔识别。你将在下面的视网膜图像中注意到这些萎缩区域。
- en: You can get the images to follow along with the code from [this Kaggle dataset](https://www.kaggle.com/datasets/andrewmvd/fundus-image-registration).
    First, we need to import the appropriate modules.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[这个 Kaggle 数据集](https://www.kaggle.com/datasets/andrewmvd/fundus-image-registration)中获取与代码一起使用的图像。首先，我们需要导入适当的模块。
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, let’s write a function to handle retrieving the images. Since we only
    want to register fundus images to the same eye, we specify which patient and which
    laterality we want to load in:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们编写一个函数来处理图像的检索。由于我们只想将视网膜图像注册到同一只眼睛，我们需要指定要加载的患者和侧别：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When evaluating our registration algorithm, our evaluation metric will be some
    function that computes the distance between the registered images and the template
    image. We want to be able to track a few of these metrics. Some common ones include:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估我们的配准算法时，我们的评估指标将是一个计算注册图像与模板图像之间距离的函数。我们希望能够追踪这些指标中的一些。常见的指标包括：
- en: '*L1 loss*, also known as mean absolute error, measures the average magnitude
    of the element-wise differences between two images. It is robust to outliers and
    gives equal weight to all pixels, making it a good choice for image registration.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*L1 损失*，也称为平均绝对误差，测量两张图像之间逐元素差异的平均幅度。它对离群值具有鲁棒性，并对所有像素赋予相等的权重，使其成为图像配准的一个不错选择。'
- en: '*RMSE*, or root mean square error, is the square root of the mean of the squared
    differences between two images. It gives more weight to larger differences, making
    it sensitive to outliers. RMSE is commonly used in image registration to measure
    the overall difference between two images.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*均方根误差*（RMSE）是两张图像之间平方差的均值的平方根。它对较大的差异赋予更多权重，使其对离群值非常敏感。RMSE 常用于图像配准，以测量两张图像之间的总体差异。'
- en: '*Normalised cross-correlation* is a measure of the similarity between two images,
    taking into account their intensities. It is normalised to ensure that the result
    is between -1 and 1, where 1 indicates a perfect match. Normalised cross-correlation
    is often used in image registration to assess the quality of the registration,
    especially when dealing with images with different intensities.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*归一化互相关* 是一种衡量两张图像之间相似度的指标，考虑了它们的强度。它被归一化以确保结果在 -1 和 1 之间，其中 1 表示完全匹配。归一化互相关常用于图像配准，以评估配准质量，特别是在处理强度不同的图像时。'
- en: '*Similarity* is a measure of the overlap between two images, taking into account
    both the intensities and spatial information. Common similarity metrics used in
    image registration include mutual information, normalised mutual information,
    and the Jensen-Shannon divergence. These metrics provide a measure of the information
    shared between two images, making them well suited for assessing the quality of
    image registration.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*相似度* 是衡量两张图像之间重叠程度的指标，考虑了强度和空间信息。常见的用于图像配准的相似度指标包括互信息、归一化互信息和詹森-香农散度。这些指标提供了两张图像之间共享信息的度量，使其非常适合评估图像配准的质量。'
- en: 'The following function takes a list of registered images, as well as the template
    image, and calculates the above metrics for each image:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数接受一个注册图像的列表以及模板图像，并计算每张图像的上述指标：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Given these losses, it’s probably a good idea to have some sort of function
    that shows us the best and worst registered images, based on the loss. This is
    somewhat similar to viewing individual examples from a confusion matrix in a classification
    task.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些损失，最好有某种函数可以根据损失显示最佳和最差注册图像。这在某种程度上类似于在分类任务中查看混淆矩阵的个别示例。
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It’s probably a good idea to write a summary function which will show the aggregate
    improvement our registration has achieved:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个汇总函数，显示我们的配准算法所取得的整体改进，这可能是个好主意。
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we’ll write a thin wrapper for any registration algorithm to allow
    us to easily apply and evaluate it:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将为任何配准算法编写一个简洁的包装器，以便我们能够轻松地应用和评估它：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Exploratory data analysis
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: Let’s get some images and see what we’re dealing with.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们获取一些图像，看看我们要处理的是什么。
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A good idea is probably to examine which of the images are most different from
    the template image. We can recycle the functions from above to do this. Let’s
    just calculate the losses between the un-registered images and the template, and
    then look at the most dissimilar ones (highest losses).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的主意是检查哪些图像与模板图像的差异最大。我们可以重复使用上述函数来实现这一点。让我们计算未注册图像与模板之间的损失，然后查看差异最大（损失最高）的图像。
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/2264d3da9d9869fae59fa27f5499ceb4.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2264d3da9d9869fae59fa27f5499ceb4.png)'
- en: Image by author.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: 'For comparison, here is the template image:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作为比较，这里是模板图像：
- en: '[PRE8]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/49c1777f2a850576776e2d5e97990d1c.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49c1777f2a850576776e2d5e97990d1c.png)'
- en: Image by author.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: Finding the optimal template image
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找最佳模板图像
- en: 'Obviously, choosing the first fundus image as the *fixed* or “template” image
    may not be ideal. What if the first image is poor quality, or rotated, or in general
    very different from the majority of images to be registered? This will lead to
    poor results, large affine transformations and high “dead” image areas. Hence,
    we need some way to pick a template image. There are a few different ideas for
    how we might do this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，选择第一张眼底图像作为 *固定* 或“模板”图像可能并不理想。如果第一张图像质量差，或者旋转，或者与大多数需要配准的图像差异很大，这将导致结果不佳、大的仿射变换和高的“死”图像区域。因此，我们需要某种方法来选择模板图像。我们可以有几种不同的想法来实现这一点：
- en: Calculate the cumulative L2 distance between each image and all other images
    in the dataset, and pick the one with the lowest result. This represents the image
    that is “closest” to all the other images.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算每张图像与数据集中所有其他图像的累积L2距离，并选择结果最低的那一张。这代表了与所有其他图像“最接近”的图像。
- en: Repeat the process from above, but this time create a histogram of cumulative
    L2 distances. Pick the *k* best images, take the average, and use this as a template.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复上述过程，但这次创建一个累积L2距离的直方图。选择最好的 *k* 张图像，取平均值，并将其作为模板。
- en: Let’s begin with the first idea. This function loops over each image, calculating
    aggregate L2 distance with all other images.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一个想法开始。这个函数循环遍历每张图像，计算与所有其他图像的聚合L2距离。
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s have a look at the four images with the lowest total RMSEs:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看四张总RMSE最低的图像：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/92c7b613ccec8e2171747547cda6f71f.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/92c7b613ccec8e2171747547cda6f71f.png)'
- en: Image by author.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'Now let’s try the second method. First, let’s have a look at the histogram
    of total RMSEs:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们尝试第二种方法。首先，看看总RMSE的直方图：
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/73b5d1b50d1ae2549515021ab3d74784.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/73b5d1b50d1ae2549515021ab3d74784.png)'
- en: Image by author.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'We could probably take the best 15 images (all with RMSEs below 10):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择最好的15张图像（所有图像的RMSE都低于10）：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/1babcc32348a92c057f0b98d4233267e.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1babcc32348a92c057f0b98d4233267e.png)'
- en: Image by author.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Obviously, the more images we use to take the average of, the blurrier the final
    image.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，我们用来取平均的图像越多，最终图像就会越模糊。
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../Images/fbcd06c810c5224433123aef3f4131f5.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fbcd06c810c5224433123aef3f4131f5.png)'
- en: Let’s pick the best 8 images, and make that our template image.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们选择最好的8张图像，并将其作为我们的模板图像。
- en: Algorithms
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法
- en: 'Here are the actual workhorses of the project: the registration algorithms
    themselves.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是项目中的实际工作马驹：注册算法本身。
- en: Rigid
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 刚性
- en: Rigid registration is a fundamental technique in medical image analysis that
    involves aligning two or more images by applying translations, rotations, and
    scalings. It is a process of transforming images in a way that preserves the distance
    between corresponding points in the images. The aim of rigid registration is to
    find the best transformation that minimizes the difference between the images
    while maintaining the anatomical consistency of the underlying structures. Rigid
    registration has several applications, including image fusion, image-guided surgery,
    and longitudinal studies, and serves as a critical preprocessing step for more
    advanced registration techniques.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 刚性配准是医学图像分析中的一种基本技术，它通过应用平移、旋转和缩放来对齐两张或多张图像。这是一个将图像变换的过程，目的是保持图像中对应点之间的距离不变。刚性配准的目标是找到最佳变换，以最小化图像之间的差异，同时保持基础结构的解剖一致性。刚性配准有多个应用，包括图像融合、图像引导手术和纵向研究，并且是更高级配准技术的关键预处理步骤。
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/e432a3126646f040006f0d3a7102bf3e.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e432a3126646f040006f0d3a7102bf3e.png)'
- en: 'Our metrics are worse compared to the original images. Let’s see what’s actually
    happening:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 与原始图像相比，我们的指标较差。让我们看看实际发生了什么：
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/e6c0abfdc49aa06d24b87226ebf999ae.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6c0abfdc49aa06d24b87226ebf999ae.png)'
- en: Image by author.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Interesting. So the metrics are generally worse, but it appears this way because
    the metrics are comparing large black areas on shifted images. We should probably
    include the same metrics as above, but exclude completely black pixels from the
    comparison.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣。因此，指标通常较差，但这样出现的原因是因为这些指标比较的是移动图像上的大黑色区域。我们可能需要包括与上述相同的指标，但排除完全黑色的像素进行比较。
- en: '[PRE19]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/ee749aa5f979e01d84d008d9bc3f4e37.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ee749aa5f979e01d84d008d9bc3f4e37.png)'
- en: Not really much better. The only metric where it is definitely better is SSIM
    excluding black pixels. A theory about why this might be the case is that by excluding
    black pixels, we are also excluding the retina, which is already very well aligned
    with the majority of images, and hence “dampens” the metrics for the well-aligned
    images.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上没有显著改善。唯一绝对更好的指标是排除黑色像素的SSIM。关于为什么会这样的一种理论是，通过排除黑色像素，我们也在排除视网膜，视网膜已经与大多数图像非常对齐，因此“抑制”了对齐良好的图像的指标。
- en: Optical flow
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 光流
- en: Optical flow is a fundamental technique in computer vision that estimates the
    motion of objects between two consecutive frames of a video sequence. It is based
    on the assumption that the pixel intensities of an object remain constant across
    frames, and that the apparent motion of the object is solely due to its real motion.
    The optical flow can be represented as a 2D vector field (u,v) that assigns a
    velocity vector to each pixel in the image.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 光流是计算机视觉中的一种基本技术，它估计视频序列中两个连续帧之间物体的运动。其假设是物体的像素强度在帧之间保持不变，并且物体的表观运动仅由于其实际运动。光流可以表示为一个2D矢量场（u,v），将一个速度矢量分配给图像中的每个像素。
- en: The optical flow field can be computed by solving a system of equations that
    relates the image brightness change to the motion of the pixels. These equations
    can be solved using various methods, such as Lucas-Kanade, Horn-Schunck, or Farneback,
    each with its own advantages and limitations. Once the optical flow field is computed,
    it can be used to register images by warping one image to align with the other.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 光流场可以通过求解将图像亮度变化与像素运动相关联的方程组来计算。这些方程可以使用不同的方法求解，例如Lucas-Kanade、Horn-Schunck或Farneback，每种方法都有其自身的优点和局限性。一旦计算出光流场，它可以用于通过将一幅图像扭曲以对齐另一幅图像来实现图像配准。
- en: Optical flow has a wide range of applications, including object tracking, motion
    analysis, video stabilization, and video compression. However, optical flow estimation
    is sensitive to image noise, occlusions, and large displacements, which can lead
    to errors and inaccuracies in the motion estimation. Ongoing research is focused
    on improving the accuracy, robustness, and efficiency of optical flow methods
    to enhance their applicability in real-world scenarios.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 光流具有广泛的应用，包括物体跟踪、运动分析、视频稳定和视频压缩。然而，光流估计对图像噪声、遮挡和大位移非常敏感，这可能导致运动估计中的错误和不准确性。当前的研究集中在提高光流方法的准确性、鲁棒性和效率，以增强其在实际场景中的适用性。
- en: 'Let’s have a look at how this works:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这如何工作：
- en: '[PRE21]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/cd5341247222200f7a7c65400b0d9d2f.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd5341247222200f7a7c65400b0d9d2f.png)'
- en: Image by author.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: The above code demonstrates image registration using optical flow. First, the
    code loads a sequence of images and a template. Then, the images are converted
    to grayscale, and the optical flow between the first image and the template is
    computed using the TVL1 algorithm. The resulting optical flow vectors are used
    to register the template to the first image.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码演示了使用光流进行图像配准。首先，代码加载一系列图像和模板。然后，将图像转换为灰度，并使用TVL1算法计算第一幅图像和模板之间的光流。计算出的光流矢量用于将模板图像配准到第一幅图像上。
- en: To do this, the code generates a grid of row and column coordinates for the
    template image and applies the optical flow vectors to the row and column coordinates
    to obtain the corresponding locations in the first image. These transformed coordinates
    are then used to warp the template image to the first image using a spline-based
    image warping function.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这一点，代码生成了模板图像的行和列坐标网格，并将光流矢量应用于这些行和列坐标，以获取第一幅图像中的相应位置。然后使用基于样条的图像变形函数，将这些变换后的坐标用于将模板图像扭曲到第一幅图像上。
- en: The code then generates RGB images to display the unregistered sequence, the
    registered sequence, and the target image (i.e., the first image). The unregistered
    sequence is an RGB image with the first and template images overlaid. The registered
    sequence is an RGB image with the warped template image and the first image overlaid.
    The target image is an RGB image with only the first image.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 代码然后生成RGB图像，以显示未配准序列、配准序列和目标图像（即第一幅图像）。未配准序列是一个RGB图像，其中第一幅图像和模板图像叠加在一起。配准序列是一个RGB图像，其中扭曲后的模板图像和第一幅图像叠加在一起。目标图像是一个仅包含第一幅图像的RGB图像。
- en: Finally, the code displays the three RGB images using Matplotlib subplots. The
    first subplot shows the unregistered sequence, the second subplot shows the registered
    sequence, and the third subplot shows the target image. The resulting plot provides
    a visual comparison of the unregistered and registered sequences, highlighting
    the effectiveness of the optical flow-based registration method.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，代码使用 Matplotlib 子图显示了三张 RGB 图像。第一个子图显示了未配准的序列，第二个子图显示了已配准的序列，第三个子图显示了目标图像。生成的图提供了未配准和已配准序列的视觉比较，突出了基于光流的配准方法的有效性。
- en: The estimated vector field (u,v) can also be displayed with a quiver plot.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 估计的向量场（u,v）也可以通过箭头图进行显示。
- en: '[PRE22]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/14eaf5a71a12c8c204fac88fe94655b5.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14eaf5a71a12c8c204fac88fe94655b5.png)'
- en: Image by author.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: Let’s implement the algorithm.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实现算法。
- en: '[PRE23]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](../Images/160f0414e4834a5f76a065549093e58e.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/160f0414e4834a5f76a065549093e58e.png)'
- en: 'Significantly better performance! Let’s visualise:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 显著提高了性能！让我们可视化一下：
- en: '[PRE25]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](../Images/86fd18f3a7b1f9cde4a2e8233f62ae87.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86fd18f3a7b1f9cde4a2e8233f62ae87.png)'
- en: Image by author.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: It seems like the optical flow is “cheating” somewhat on the harder images by
    just completely deforming them. Let’s see if we can improve on this.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来光流在较难的图像上有些“作弊”，通过完全变形图像来实现。让我们看看是否可以改进这一点。
- en: SimpleElastix
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SimpleElastix
- en: SimpleElastix is an open-source, multi-platform software library that provides
    a simple interface for performing medical image registration. Image registration
    is the process of aligning two or more images by finding a spatial mapping between
    them. SimpleElastix offers a wide range of pre-implemented registration components,
    including transforms, similarity metrics, and optimizers, which can be easily
    combined to create a registration pipeline. The library supports various types
    of registration, including rigid, affine, non-rigid, and groupwise registration,
    and allows users to register images in different modalities, such as MRI, CT,
    PET, and microscopy.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: SimpleElastix 是一个开源的多平台软件库，提供了一个简单的接口来执行医学图像配准。图像配准是通过在图像之间找到空间映射来对齐两张或更多张图像的过程。SimpleElastix
    提供了广泛的预实现配准组件，包括变换、相似性度量和优化器，这些组件可以轻松组合以创建配准管道。该库支持各种类型的配准，包括刚性、仿射、非刚性和组配准，并允许用户在不同的成像模态中配准图像，如
    MRI、CT、PET 和显微镜。
- en: One of the key advantages of SimpleElastix is its ease of use. It provides a
    user-friendly, high-level interface that requires minimal coding knowledge and
    can be used through a Python or C++ interface. Additionally, the library includes
    advanced features such as multi-resolution optimization, regularization, and spatial
    constraints, which enhance the accuracy and robustness of the registration. SimpleElastix
    is widely used in medical imaging research and clinical practice and has been
    validated in numerous studies. It is a valuable tool for a wide range of applications,
    including image-guided surgery, longitudinal studies, and image analysis.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: SimpleElastix 的一个关键优点是其易用性。它提供了一个用户友好的高级接口，要求的编码知识很少，并且可以通过 Python 或 C++ 接口使用。此外，该库包括高级功能，如多分辨率优化、正则化和空间约束，这些功能提高了配准的准确性和鲁棒性。SimpleElastix
    在医学影像研究和临床实践中被广泛使用，并在许多研究中得到了验证。它是一个有价值的工具，适用于广泛的应用，包括图像引导手术、纵向研究和图像分析。
- en: Rigid registration
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 刚性配准
- en: As discussed above, a rigid transformation is capable of aligning objects that
    are related by translation and rotation. For example, when aligning images of
    a patient’s bones, a rigid transformation is often sufficient to align these structures.
    It is advantageous to use a simple transformation when possible, as this reduces
    the number of possible solutions and minimizes the risk of non-rigid local minima
    that could compromise the accuracy of the registration results. This approach
    can be seen as a means of incorporating domain expertise into the registration
    process.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，刚性变换能够对齐通过平移和旋转相关的对象。例如，在对齐患者骨骼的图像时，刚性变换通常足以对齐这些结构。尽可能使用简单的变换是有利的，因为这减少了可能的解决方案数量，并且最小化了可能影响配准结果准确性的非刚性局部极小值的风险。这种方法可以看作是在配准过程中融入领域专长的一种手段。
- en: 'Let’s look at a single registered image:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看单个已配准的图像：
- en: '[PRE26]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/0c99e80aef332c70925809d155164f07.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c99e80aef332c70925809d155164f07.png)'
- en: Image by author.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: 'Now let’s use the architecture above to apply and validate the rigid registration:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用上面的架构来应用和验证刚性注册：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Visualise the results:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化结果：
- en: '[PRE29]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](../Images/de6eed7e789d0563df80a39fef1c0c4f.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de6eed7e789d0563df80a39fef1c0c4f.png)'
- en: Image by author.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: 'And finally, let’s examine the metrics:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们审视这些度量：
- en: '[PRE30]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![](../Images/efe4730b919c596f0f8fb8661bb88397.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/efe4730b919c596f0f8fb8661bb88397.png)'
- en: Whilst L1 losses are similar, the rigid registration with `SimpleElastix` drastically
    improves the NCC and structural similarity loss.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 L1 损失相似，`SimpleElastix` 的刚性注册显著改善了 NCC 和结构相似性损失。
- en: Affine registration
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 仿射注册
- en: Very similar to rigid registration, the affine transform allows us to shear
    and scale in addition to rotation and translation. Often, affine registration
    is used as an initial preprocessing step before non-rigid transformations.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 非常类似于刚性注册，仿射变换允许我们在旋转和平移之外进行剪切和缩放。通常，仿射注册作为非刚性变换之前的初步预处理步骤使用。
- en: '[PRE31]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](../Images/a0a1b4358b559c526cf973f74d2ba166.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0a1b4358b559c526cf973f74d2ba166.png)'
- en: Image by author.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: '[PRE33]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![](../Images/74fe54e3ec38b81d43bed4eace85e327.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74fe54e3ec38b81d43bed4eace85e327.png)'
- en: Slightly better than rigid transformation.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 略好于刚性变换。
- en: Non-rigid registration
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非刚性注册
- en: Non-rigid registration techniques are able to align images that require localised
    deformations, making them more suitable for accommodating the anatomical, physiological,
    and pathological variations between patients.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 非刚性注册技术能够对齐需要局部变形的图像，使其更适合处理患者之间的解剖、生理和病理变化。
- en: To parameterise a free-form deformation (FFD) field, B-splines are commonly
    employed. The registration of FFD fields is much more complex than that of simpler
    transformations. The increased dimensionality of the parameter space makes it
    challenging to solve the problem, and as such, a multi-resolution approach is
    recommended. Starting with an affine initialisation can also be helpful to make
    the registration easier. In SimpleElastix, implementing a multi-resolution approach
    is straightforward.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了参数化自由形状变形 (FFD) 场，通常使用 B-splines。FFD 场的注册比简单变换复杂得多。参数空间维度的增加使得解决这个问题具有挑战性，因此推荐使用多分辨率方法。以仿射初始化开始也有助于简化注册。在
    SimpleElastix 中，实施多分辨率方法非常简单。
- en: The code below runs multi-resolution affine initialisation and then applies
    a B-spline non-rigid registration transform.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码运行多分辨率仿射初始化，然后应用 B-spline 非刚性注册变换。
- en: '[PRE34]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![](../Images/5a18457634cf154be8b20903c704db92.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a18457634cf154be8b20903c704db92.png)'
- en: Image by author.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: '![](../Images/2e6fff40254972ccbca4d97d3804927d.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e6fff40254972ccbca4d97d3804927d.png)'
- en: So SSIM is slightly worse than affine, but NCC is definitely better.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 所以 SSIM 比仿射变换稍差，但 NCC 绝对更好。
- en: Groupwise registration
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 群体注册
- en: Groupwise registration methods are used in medical imaging to address the uncertainties
    associated with registering one image to a chosen reference frame. Instead, all
    images in a population are simultaneously registered to a mean frame of reference
    that is at the center of the population. This approach uses a 3D or 4D B-spline
    deformation model and a similarity metric that minimizes intensity variance while
    ensuring that the average deformation across images is zero. The method can also
    incorporate temporal smoothness of the deformations and a cyclic transform in
    the time dimension, which is useful in cases where the anatomical motion has a
    cyclic nature, such as in cardiac or respiratory motion. By using this method,
    bias towards a specific reference frame is eliminated, resulting in more accurate
    and unbiased registration of the images. However, this method is too computationally
    intensive without parallel processing, and so is not covered here for the sake
    of efficiency.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 群体注册方法在医学影像中用于解决将一张图像注册到选定参考框架时的不确定性。相反，所有图像同时注册到一个位于群体中心的平均参考框架。该方法使用三维或四维
    B-spline 变形模型和一个相似度度量，该度量最小化强度方差，同时确保所有图像的平均变形为零。该方法还可以结合变形的时间平滑性和时间维度上的循环变换，这在解剖运动具有周期性特征的情况下非常有用，例如心脏或呼吸运动。通过使用此方法，消除了对特定参考框架的偏倚，从而实现了图像的更准确和无偏注册。然而，该方法计算量巨大，未进行并行处理，因此在这里为了效率而未作介绍。
- en: 2D Voxelmorph with Spatial Transformer Network
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2D Voxelmorph 和空间变换网络
- en: '[PRE37]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The Spatial Transformer Network (STN) is a neural network architecture that
    can learn to spatially transform images in order to improve the performance of
    downstream tasks. In particular, the STN is capable of learning to automatically
    crop, rotate, scale, and skew input images in a way that is optimal for the task
    at hand. This is achieved by learning to estimate a set of affine transformation
    parameters for each input image, which can be used to warp the image into a new
    configuration.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 空间变换网络（STN）是一种神经网络架构，能够学习在空间上变换图像，以提高下游任务的性能。特别地，STN能够自动学习裁剪、旋转、缩放和扭曲输入图像，以适应当前任务的最佳方式。这是通过学习估计每个输入图像的一组仿射变换参数来实现的，这些参数可用于将图像扭曲成新的配置。
- en: 'In the code below, the STN is implemented as a module within a larger neural
    network, which consists of several convolutional layers and fully connected layers.
    The STN consists of two components: a localisation network, and a regressor.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，STN作为一个模块实现于一个更大的神经网络中，该网络包括几个卷积层和全连接层。STN由两个组件组成：定位网络和回归器。
- en: The localisation network is a set of convolutional layers that are used to extract
    a set of features from the input image. These features are then fed into the regressor,
    which is a set of fully connected layers that are used to estimate the affine
    transformation parameters. In the provided code, the regressor consists of two
    linear layers with ReLU activation functions.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 定位网络是一组卷积层，用于从输入图像中提取一组特征。这些特征随后被输入到回归器中，回归器是一组用于估计仿射变换参数的全连接层。在提供的代码中，回归器由两个带ReLU激活函数的线性层组成。
- en: The STN module also includes a `stn` method, which takes an input image as input
    and applies the learned affine transformation to the image using bilinear interpolation.
    The `stn` method is called within the forward method of the larger neural network,
    which is used to make predictions on the transformed input.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: STN模块还包括一个`stn`方法，该方法接受输入图像并通过双线性插值将学习到的仿射变换应用于图像。`stn`方法在更大神经网络的前向方法中被调用，用于对变换后的输入进行预测。
- en: Overall, the STN module provides a powerful tool for learning to perform spatial
    transformations on input images, which can be used to improve the performance
    of a wide range of image processing and computer vision tasks.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，STN模块提供了一个强大的工具，用于学习对输入图像进行空间变换，这可以用于提高各种图像处理和计算机视觉任务的性能。
- en: '[PRE38]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We’re also going to try a different differentiable loss that may be better
    suited to image registration than the previous metrics. The given code defines
    a custom loss function called voxelmorph loss, used for 2D image registration.
    The loss function consists of two components: a reconstruction loss and a smoothness
    penalty.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将尝试一种不同的可微分损失，这种损失可能比之前的度量方法更适合图像配准。给定的代码定义了一种名为voxelmorph损失的自定义损失函数，用于2D图像配准。该损失函数由两个组件组成：重建损失和平滑惩罚。
- en: The reconstruction loss measures the dissimilarity between the source image
    and the target image. It is computed as the mean absolute difference between the
    two images, weighted by the target weight. The source and target images are the
    input images to the registration network, with the source image being transformed
    to align with the target image.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 重建损失衡量源图像与目标图像之间的不同。它计算为两幅图像之间的绝对差的平均值，并按目标权重加权。源图像和目标图像是配准网络的输入图像，其中源图像被变换以对齐目标图像。
- en: The smoothness penalty encourages smooth transformations by penalizing spatially
    varying deformations between the source and target images. The penalty is computed
    by taking the mean absolute difference of the gradients of the target image in
    the x and y directions, weighted by the smoothness weight. This penalty term helps
    to avoid sharp changes in the deformation field, which can lead to overfitting
    and poor generalization to new images.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑惩罚通过惩罚源图像和目标图像之间的空间变化形变来鼓励平滑变换。该惩罚通过计算目标图像在x和y方向上梯度的绝对差的平均值来计算，并按平滑权重加权。这个惩罚项有助于避免形变场中的急剧变化，这可能导致过拟合并对新图像的泛化能力差。
- en: The overall voxelmorph loss is the sum of the reconstruction loss and the smoothness
    penalty. The loss is optimized using a gradient-based optimizer during training
    to improve the accuracy of the registration network.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 总体的voxelmorph损失是重建损失和平滑惩罚的总和。通过在训练期间使用基于梯度的优化器来优化损失，以提高配准网络的准确性。
- en: Voxelmorph loss is a widely used loss function in medical image registration
    due to its ability to handle large deformations, multi-modal images, and inter-subject
    variability. It is particularly useful for deformable registration of images,
    where the goal is to align images with significant shape variations. The smoothness
    penalty term in the loss function helps to regularise the deformation field and
    improve the accuracy of the registration.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Voxelmorph 损失函数因其处理大变形、多模态图像和个体差异的能力而在医学图像配准中被广泛使用。它对于图像的可变形配准尤为有用，其目标是对齐具有显著形状变化的图像。损失函数中的平滑性惩罚项有助于规范化变形场，并提高配准的准确性。
- en: '[PRE39]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The code below defines a PyTorch dataset class, called `FundusDataset`, that
    is used to load and preprocess training images for use in a neural network. The
    dataset class takes a list of training images and a target image as input and
    returns an image and its corresponding target image for use during training.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码定义了一个 PyTorch 数据集类，名为 `FundusDataset`，用于加载和预处理用于神经网络的训练图像。数据集类接受训练图像列表和目标图像作为输入，并返回一个图像及其对应的目标图像，以便在训练过程中使用。
- en: '[PRE40]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, let’s write a brief training loop:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写一个简短的训练循环：
- en: '[PRE41]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Finally, we define a Python function, called `convert_image_np`, that converts
    a PyTorch tensor to a numpy image. The function takes the PyTorch tensor as input,
    and applies a standard normalisation procedure by subtracting a mean value and
    dividing by a standard deviation value. The resulting numpy image is then clipped
    to lie between 0 and 1.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们定义了一个名为 `convert_image_np` 的 Python 函数，将 PyTorch 张量转换为 numpy 图像。该函数以 PyTorch
    张量为输入，应用标准归一化程序，通过减去均值并除以标准差值来完成归一化。生成的 numpy 图像随后被裁剪到 0 和 1 之间。
- en: The code then defines a function, called `visualize_stn`, that is used to visualize
    the output of a spatial transformer network (STN) layer during training. The resulting
    input and transformed numpy images are plotted side-by-side using the subplots()
    function from the matplotlib library. The plot shows the input images on the left
    and the corresponding transformed images on the right.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 代码接着定义了一个名为 `visualize_stn` 的函数，用于在训练过程中可视化空间变换网络（STN）层的输出。使用 matplotlib 库中的
    subplots() 函数将生成的输入和变换后的 numpy 图像并排绘制。图中左侧显示输入图像，右侧显示对应的变换图像。
- en: '[PRE42]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![](../Images/8bcbb2a1adad260829ba71b4475343d8.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8bcbb2a1adad260829ba71b4475343d8.png)'
- en: Image by author.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Clearly, the network has moved the images somewhat, but struggles with the fundus
    images that are too far removed from the template image.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，网络已经在某种程度上移动了图像，但对于与模板图像差异过大的眼底图像仍然存在困难。
- en: Supersizing registration
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超大规模配准
- en: For completeness, I include a few things here that I tried to get the STN to
    work better.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，我在这里包括了一些我尝试过的事情，以使 STN 的效果更好。
- en: Image augmentation
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像增强
- en: I had a hunch that image augmentation can improve the performance of an STN
    in learning image registration transforms by increasing the diversity and quantity
    of training data. STNs rely on large amounts of training data to learn the complex
    spatial transformations between images. However, obtaining a sufficiently large
    and diverse dataset of medical images can be challenging due to factors such as
    limited patient data and variability in imaging modalities. In addition to this,
    I only have limited data per patient, so training an STN is only feasible for
    a lot of patients combined.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我直觉上认为，图像增强可以通过增加训练数据的多样性和数量来改善 STN 在学习图像配准变换中的性能。STN 依赖大量的训练数据来学习图像之间的复杂空间变换。然而，由于患者数据有限和成像模式的变异等因素，获取足够大且多样的医学图像数据集可能具有挑战性。此外，我每个患者的数据有限，因此训练
    STN 仅对许多患者的组合数据可行。
- en: Image augmentation offers a solution to this problem by generating synthetic
    training data by applying a variety of image transformations to existing images.
    This increases the size and diversity of the training dataset, and enables the
    STN to learn more robust and generalisable registration transforms. Image augmentation
    can also help the STN to learn transformations that are invariant to certain imaging
    conditions such as changes in illumination, contrast, and noise.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图像增强通过对现有图像应用多种图像变换来生成合成训练数据，提供了一个解决方案。这增加了训练数据集的大小和多样性，使 STN 能够学习更强大且具有更好泛化能力的配准变换。图像增强还可以帮助
    STN 学习对某些成像条件如光照、对比度和噪声变化不变的变换。
- en: Common image augmentation techniques include random rotations, translations,
    scaling, and flipping, as well as more complex transformations such as elastic
    deformations and intensity changes. These transformations are applied randomly
    during training to generate a wide range of transformed images that are similar
    to the original images. The augmented images are then used to train the STN, which
    improves its ability to generalise to new images.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的图像增强技术包括随机旋转、平移、缩放和翻转，以及更复杂的变换，如弹性形变和强度变化。这些变换在训练过程中随机应用，以生成与原始图像相似的各种变换图像。然后使用增强的图像来训练
    STN，从而提高其对新图像的泛化能力。
- en: '[PRE43]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: You could then apply this function to the images list and pass in the extended
    dataset for training.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以将这个函数应用到图像列表中，并传入扩展的数据集进行训练。
- en: Clustering models with k-nearest neighbours
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 k 最近邻的聚类模型
- en: The below code is an implementation of k-means clustering on a set of images
    stored as NumPy arrays. The aim of the code is to find the optimal number of clusters
    that best represent the set of images.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码实现了对存储为 NumPy 数组的一组图像进行 k-means 聚类。代码的目的是找到最佳的簇数，以最佳地表示图像集。
- en: The code begins by converting the list of images to a 2D NumPy array and then
    reshaping the array to a 2D shape. This is done to create a dataset that can be
    fed into the k-means clustering algorithm. The k-means algorithm is then run for
    a range of values of k, where k is the number of clusters to be generated. For
    each value of k, the algorithm is run, and the within-cluster sum of squares (WCSS)
    is calculated. The WCSS is a measure of how spread out the data points are within
    each cluster, and it is used to evaluate the quality of the clustering. The WCSS
    value is stored in a list, and the loop is repeated for all values of k.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 代码首先将图像列表转换为 2D NumPy 数组，然后将数组重塑为 2D 形状。这是为了创建一个可以输入到 k-means 聚类算法的数据集。然后，对一系列的
    k 值（其中 k 是要生成的簇的数量）运行 k-means 算法。对于每个 k 值，运行算法，并计算簇内平方和（WCSS）。WCSS 是衡量每个簇内数据点分散程度的指标，用于评估聚类质量。WCSS
    值存储在一个列表中，并对所有 k 值重复此过程。
- en: Once the WCSS values are calculated, an elbow plot is generated to visualize
    the relationship between the number of clusters and the WCSS value. The elbow
    plot shows a curve that descends and reaches an elbow point where the rate of
    decrease in WCSS value starts to level off. The optimal number of clusters is
    chosen as the value at which the curve starts to level off.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算出 WCSS 值，就会生成一个肘部图来可视化簇数与 WCSS 值之间的关系。肘部图展示了一个下降的曲线，并到达一个肘部点，在此点 WCSS 值的下降速度开始平缓。最佳的簇数被选择为曲线开始平缓的值。
- en: '[PRE44]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![](../Images/8b45025890e19cca686dd4c80693149f.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b45025890e19cca686dd4c80693149f.png)'
- en: Image by author.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'From this plot, an optimal number of clusters is probably three. Let’s use
    this to group our images:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个图中来看，最佳的簇数可能是三个。让我们用这个来对我们的图像进行分组：
- en: '[PRE45]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![](../Images/e552ba78a2b8af5ba8500e956f30fa22.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e552ba78a2b8af5ba8500e956f30fa22.png)'
- en: Image by author.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: 'This looks good. Let’s create a new list for each cluster:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来不错。让我们为每个簇创建一个新列表：
- en: '[PRE46]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Doesn’t really help. This also goes against the overall idea of an STN, which
    is that it uses the convolutional layers to determine which transforms to apply
    to which images i.e. some images will require significantly higher weights in
    the transform than others.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上没有帮助。这也违背了 STN 的整体思想，即使用卷积层来确定应用于哪些图像的变换，即一些图像在变换中需要显著更高的权重。
- en: Conclusion
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In conclusion, the evaluation of medical image registration techniques indicates
    that while modern approaches such as Spatial Transformer Networks (STNs) offer
    promising results, they require a substantial investment to achieve the desired
    outcomes. In comparison, traditional techniques like SimpleElastix prove to be
    more effective and efficient. Despite implementing various strategies to enhance
    the STN’s performance, the model failed to learn sufficient weights to shift the
    target, demonstrating the need for alternative loss functions. One such approach
    could involve ignoring black pixels resulting from affine transforms. Additionally,
    pointwise registration, which utilizes biological markers such as the retina or
    blood vessels to guide the registration process, could prove more beneficial for
    specific applications. Therefore, further research is necessary to determine the
    most appropriate registration approach, based on the specific problem and available
    resources.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，对医学图像配准技术的评估表明，虽然现代方法如空间变换网络（STNs）提供了有希望的结果，但需要大量投资才能实现预期效果。相比之下，传统技术如SimpleElastix被证明更有效且高效。尽管实施了各种策略来提高STN的性能，但模型未能学习到足够的权重来调整目标，显示出需要替代的损失函数。一种方法可能是忽略由于仿射变换产生的黑色像素。此外，点对点配准利用视网膜或血管等生物标记来指导配准过程，对特定应用可能更有利。因此，需要进一步研究以确定最合适的配准方法，基于具体问题和可用资源。
- en: References
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: The data is from the Kaggle *Retina Fundus Image Registration Dataset*, which
    is licensed under the Attribution 4.0 International (CC BY 4.0).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来自Kaggle *视网膜基金图像配准数据集*，该数据集的许可证为国际署名 4.0 (CC BY 4.0)。
- en: 'Kaggle: [Retina Fundus Image Registration](https://www.kaggle.com/datasets/andrewmvd/fundus-image-registration)
    Dataset'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Kaggle: [视网膜基金图像配准](https://www.kaggle.com/datasets/andrewmvd/fundus-image-registration)
    数据集'
- en: Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). Spatial transformer networks.
    *Advances in neural information processing systems*, *28*.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). 空间变换网络。*神经信息处理系统的进展*, *28*。
- en: Hill, D. L., Batchelor, P. G., Holden, M., & Hawkes, D. J. (2001). Medical image
    registration. *Physics in medicine & biology*, *46*(3), R1.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hill, D. L., Batchelor, P. G., Holden, M., & Hawkes, D. J. (2001). 医学图像配准。*医学与生物物理学*,
    *46*(3), R1。
- en: Brown, L. G. (1992). A survey of image registration techniques. *ACM computing
    surveys (CSUR)*, *24*(4), 325–376.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Brown, L. G. (1992). 图像配准技术的综述。*ACM计算机调查（CSUR）*, *24*(4), 325–376。
- en: 'Lee, M. C., Oktay, O., Schuh, A., Schaap, M., & Glocker, B. (2019). Image-and-spatial
    transformer networks for structure-guided image registration. In *Medical Image
    Computing and Computer Assisted Intervention–MICCAI 2019: 22nd International Conference,
    Shenzhen, China, October 13–17, 2019, Proceedings, Part II 22* (pp. 337–345).
    Springer International Publishing.'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Lee, M. C., Oktay, O., Schuh, A., Schaap, M., & Glocker, B. (2019). 图像和空间变换网络用于结构引导的图像配准。在*医学图像计算与计算机辅助干预–MICCAI
    2019: 第22届国际会议，深圳，中国，2019年10月13–17日，会议录，第22部分*（第337–345页）。Springer International
    Publishing。'
- en: 'Pytorch: [Spatial Transformer Networks Tutorial](https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html)'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Pytorch: [空间变换网络教程](https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html)'
