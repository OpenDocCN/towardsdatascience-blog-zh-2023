- en: How to Program a Neural Network
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚ä½•ç¼–ç¨‹ä¸€ä¸ªç¥ç»ç½‘ç»œ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-program-a-neural-network-f28e3f38e811](https://towardsdatascience.com/how-to-program-a-neural-network-f28e3f38e811)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/how-to-program-a-neural-network-f28e3f38e811](https://towardsdatascience.com/how-to-program-a-neural-network-f28e3f38e811)
- en: A step-by-step guide to implementing a neural network from scratch
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»å¤´å®ç°ç¥ç»ç½‘ç»œçš„é€æ­¥æŒ‡å—
- en: '[](https://medium.com/@callum.bruce1?source=post_page-----f28e3f38e811--------------------------------)[![Callum
    Bruce](../Images/4833a199a9449434777fdf5ce913a9cb.png)](https://medium.com/@callum.bruce1?source=post_page-----f28e3f38e811--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f28e3f38e811--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f28e3f38e811--------------------------------)
    [Callum Bruce](https://medium.com/@callum.bruce1?source=post_page-----f28e3f38e811--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@callum.bruce1?source=post_page-----f28e3f38e811--------------------------------)[![Callum
    Bruce](../Images/4833a199a9449434777fdf5ce913a9cb.png)](https://medium.com/@callum.bruce1?source=post_page-----f28e3f38e811--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f28e3f38e811--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f28e3f38e811--------------------------------)
    [Callum Bruce](https://medium.com/@callum.bruce1?source=post_page-----f28e3f38e811--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f28e3f38e811--------------------------------)
    Â·14 min readÂ·Sep 23, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f28e3f38e811--------------------------------)
    Â·é˜…è¯»æ—¶é—´ 14 åˆ†é’ŸÂ·2023 å¹´ 9 æœˆ 23 æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/79509eca917d69c1d6ca7ef6178adf3d.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79509eca917d69c1d6ca7ef6178adf3d.png)'
- en: A neural network with three hidden layers
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæœ‰ä¸‰ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œ
- en: In this article, we will build a neural network from scratch and use it to classify
    handwritten digits.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä»å¤´å¼€å§‹æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå¹¶ä½¿ç”¨å®ƒæ¥åˆ†ç±»æ‰‹å†™æ•°å­—ã€‚
- en: Why reinvent the wheel/neural network, I hear you say? Canâ€™t I just use my favourite
    machine learning framework and be done with it? Yes, there are many off-the-shelf
    frameworks that you can use to build a neural network (Keras, PyTorch, and TensorFlow
    to name a few). The thing with using one of these is that they make it easy for
    us to treat neural networks like black boxes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆè¦é‡æ–°å‘æ˜è½®å­/ç¥ç»ç½‘ç»œï¼Œæˆ‘å¬åˆ°ä½ è¯´ï¼Ÿéš¾é“æˆ‘ä¸èƒ½ç›´æ¥ä½¿ç”¨æˆ‘æœ€å–œæ¬¢çš„æœºå™¨å­¦ä¹ æ¡†æ¶æ¥è§£å†³é—®é¢˜å—ï¼Ÿæ˜¯çš„ï¼Œä½ å¯ä»¥ä½¿ç”¨è®¸å¤šç°æˆçš„æ¡†æ¶æ¥æ„å»ºç¥ç»ç½‘ç»œï¼ˆæ¯”å¦‚ Kerasã€PyTorch
    å’Œ TensorFlowï¼‰ã€‚ä½¿ç”¨è¿™äº›æ¡†æ¶çš„é—®é¢˜åœ¨äºï¼Œå®ƒä»¬è®©æˆ‘ä»¬å¾ˆå®¹æ˜“å°†ç¥ç»ç½‘ç»œå½“ä½œé»‘ç®±å¤„ç†ã€‚
- en: This isnâ€™t always a bad thing. Often we need this level of abstraction so that
    we can get to work on the problem at hand, but we should still strive to at least
    have a basic understanding of what is going on under the hood if we are to use
    neural networks in our work.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¹¶ä¸æ€»æ˜¯åäº‹ã€‚æˆ‘ä»¬é€šå¸¸éœ€è¦è¿™ç§ç¨‹åº¦çš„æŠ½è±¡ï¼Œä»¥ä¾¿èƒ½å¤Ÿå¤„ç†æ‰‹å¤´çš„é—®é¢˜ï¼Œä½†å¦‚æœæˆ‘ä»¬è¦åœ¨å·¥ä½œä¸­ä½¿ç”¨ç¥ç»ç½‘ç»œï¼Œä»ç„¶åº”è¯¥åŠªåŠ›è‡³å°‘å¯¹å…¶å†…éƒ¨è¿ä½œæœ‰ä¸€ä¸ªåŸºæœ¬äº†è§£ã€‚
- en: Building a neural network from scratch is, in my opinion, the best way to foster
    a deep understanding of how they work.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å¤´å¼€å§‹æ„å»ºç¥ç»ç½‘ç»œåœ¨æˆ‘çœ‹æ¥æ˜¯åŸ¹å…»æ·±åˆ»ç†è§£å…¶å·¥ä½œåŸç†çš„æœ€ä½³æ–¹å¼ã€‚
- en: By the end of this article, you will have learned about the feedforward and
    backpropagation algorithms, what an activation function is, what the difference
    between an epoch and a batch is, and how to train a neural network. We will finish
    with an example by training a neural network to recognise handwritten digits.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æœ¬æ–‡ç»“æŸæ—¶ï¼Œä½ å°†äº†è§£å‰é¦ˆå’Œåå‘ä¼ æ’­ç®—æ³•ï¼Œæ¿€æ´»å‡½æ•°æ˜¯ä»€ä¹ˆï¼Œepoch å’Œ batch ä¹‹é—´çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Œä»¥åŠå¦‚ä½•è®­ç»ƒç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬å°†é€šè¿‡è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«æ‰‹å†™æ•°å­—æ¥å®Œæˆæœ¬ä¾‹ã€‚
- en: All code used in this article is available here on [GitHub](https://github.com/c-bruce/artificial_neural_network)
    [1].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡ä¸­ä½¿ç”¨çš„æ‰€æœ‰ä»£ç å¯ä»¥åœ¨ [GitHub](https://github.com/c-bruce/artificial_neural_network)
    [1] ä¸Šæ‰¾åˆ°ã€‚
- en: What is a neural network?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ç¥ç»ç½‘ç»œï¼Ÿ
- en: Neural networks, or artificial neural networks, are a type of machine learning
    algorithm. They form the core of many deep learning and artificial intelligence
    systems like computer vision, forecasting and speech recognition.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œï¼Œæˆ–äººå·¥ç¥ç»ç½‘ç»œï¼Œæ˜¯ä¸€ç§æœºå™¨å­¦ä¹ ç®—æ³•ã€‚å®ƒä»¬æ˜¯è®¸å¤šæ·±åº¦å­¦ä¹ å’Œäººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œä¾‹å¦‚è®¡ç®—æœºè§†è§‰ã€é¢„æµ‹å’Œè¯­éŸ³è¯†åˆ«ã€‚
- en: The structure of artificial neural networks is sometimes compared to the structure
    of biological neural networks in the brain. I would always urge caution not to
    draw too much from this comparison. Sure, artificial neural networks look a bit
    like biological neural networks but it is quite a big leap to start comparing
    them to something as complex as a human brain.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: äººå·¥ç¥ç»ç½‘ç»œçš„ç»“æ„æœ‰æ—¶ä¸å¤§è„‘ä¸­çš„ç”Ÿç‰©ç¥ç»ç½‘ç»œçš„ç»“æ„è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘æ€»æ˜¯å»ºè®®å¯¹è¿™ç§æ¯”è¾ƒä¿æŒè°¨æ…ã€‚ç¡®å®ï¼Œäººå·¥ç¥ç»ç½‘ç»œçœ‹èµ·æ¥æœ‰ç‚¹åƒç”Ÿç‰©ç¥ç»ç½‘ç»œï¼Œä½†å°†å®ƒä»¬ä¸åƒäººè„‘è¿™æ ·å¤æ‚çš„ä¸œè¥¿è¿›è¡Œæ¯”è¾ƒæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„é£è·ƒã€‚
- en: A neural network is made up of several layers of neurons. Each layer of neurons
    is activated based on the activations in the previous layer, a set of weights
    connecting the previous layer to the current layer and a set of biases applied
    to the neurons in the current layer.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œç”±å‡ å±‚ç¥ç»å…ƒç»„æˆã€‚æ¯ä¸€å±‚ç¥ç»å…ƒçš„æ¿€æ´»åŸºäºå‰ä¸€å±‚çš„æ¿€æ´»ã€è¿æ¥å‰ä¸€å±‚ä¸å½“å‰å±‚çš„æƒé‡é›†åˆï¼Œä»¥åŠæ–½åŠ åœ¨å½“å‰å±‚ç¥ç»å…ƒä¸Šçš„åç½®é›†åˆã€‚
- en: '![](../Images/f38cca749159b2f7552d2330aa156b09.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f38cca749159b2f7552d2330aa156b09.png)'
- en: General structure of a neural network containing two hidden layers. Neurons
    are shaded by their activations (larger activation magnitude = darker neuron).
    Positive weights in red. Negative weights in blue. Line width indicates weight
    magnitude.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…å«ä¸¤ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œçš„ä¸€èˆ¬ç»“æ„ã€‚ç¥ç»å…ƒæ ¹æ®å…¶æ¿€æ´»ç¨‹åº¦ç€è‰²ï¼ˆæ¿€æ´»é‡è¶Šå¤§ï¼Œç¥ç»å…ƒè¶Šæš—ï¼‰ã€‚æ­£æƒé‡ç”¨çº¢è‰²è¡¨ç¤ºï¼Œè´Ÿæƒé‡ç”¨è“è‰²è¡¨ç¤ºã€‚çº¿å®½è¡¨ç¤ºæƒé‡å¤§å°ã€‚
- en: The first layer is the input layer. Input layer activations come from the input
    to the neural network. The final layer is the output layer. The activations in
    the output layer are the output of the neural network. The layers in between are
    called hidden layers.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€å±‚æ˜¯è¾“å…¥å±‚ã€‚è¾“å…¥å±‚çš„æ¿€æ´»æ¥è‡ªç¥ç»ç½‘ç»œçš„è¾“å…¥ã€‚æœ€åä¸€å±‚æ˜¯è¾“å‡ºå±‚ã€‚è¾“å‡ºå±‚çš„æ¿€æ´»æ˜¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºã€‚ä¸­é—´çš„å±‚ç§°ä¸ºéšè—å±‚ã€‚
- en: A neural network is a generalized approximation of a function. Like any other
    function, when we give it an input it returns an output.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œæ˜¯å¯¹å‡½æ•°çš„å¹¿ä¹‰è¿‘ä¼¼ã€‚åƒå…¶ä»–ä»»ä½•å‡½æ•°ä¸€æ ·ï¼Œå½“æˆ‘ä»¬ç»™å®ƒä¸€ä¸ªè¾“å…¥æ—¶ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ªè¾“å‡ºã€‚
- en: The novel thing about neural networks is *how* they get from the input to the
    output. The process is driven by how network weights and biases influence neuron
    activations and how these propagate through the network to eventually arrive at
    the output layer. The feedforward algorithm is used by neural networks to transform
    from our input into an output.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç¥ç»ç½‘ç»œçš„æ–°é¢–ä¹‹å¤„åœ¨äº*å¦‚ä½•*ä»è¾“å…¥åˆ°è¾“å‡ºã€‚è¿™ä¸ªè¿‡ç¨‹ç”±ç½‘ç»œæƒé‡å’Œåç½®å¦‚ä½•å½±å“ç¥ç»å…ƒæ¿€æ´»ä»¥åŠè¿™äº›æ¿€æ´»å¦‚ä½•åœ¨ç½‘ç»œä¸­ä¼ æ’­ï¼Œæœ€ç»ˆåˆ°è¾¾è¾“å‡ºå±‚æ¥é©±åŠ¨ã€‚ç¥ç»ç½‘ç»œä½¿ç”¨å‰é¦ˆç®—æ³•å°†è¾“å…¥è½¬æ¢ä¸ºè¾“å‡ºã€‚
- en: For a neural network to provide useful output we must first train it. When we
    train a neural network all that we are doing is iteratively adjusting the weights
    and biases to improve the accuracy of the output. We work out which direction
    and by how much we need to nudge the weights and biases using backpropagation
    and gradient descent.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä½¿ç¥ç»ç½‘ç»œæä¾›æœ‰ç”¨çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¿…é¡»é¦–å…ˆå¯¹å…¶è¿›è¡Œè®­ç»ƒã€‚å½“æˆ‘ä»¬è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬æ‰€åšçš„å°±æ˜¯é€šè¿‡åå‘ä¼ æ’­å’Œæ¢¯åº¦ä¸‹é™è¿­ä»£è°ƒæ•´æƒé‡å’Œåç½®ï¼Œä»¥æé«˜è¾“å‡ºçš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬è®¡ç®—éœ€è¦å°†æƒé‡å’Œåç½®å‘å“ªä¸ªæ–¹å‘å’Œè°ƒæ•´å¤šå°‘ã€‚
- en: Feedforward algorithm
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‰é¦ˆç®—æ³•
- en: The feedforward algorithm transforms our neural network input into meaningful
    output. As its name suggests, the algorithm â€œfeeds forwardâ€ information from one
    layer to the next.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å‰é¦ˆç®—æ³•å°†æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œè¾“å…¥è½¬åŒ–ä¸ºæœ‰æ„ä¹‰çš„è¾“å‡ºã€‚é¡¾åæ€ä¹‰ï¼Œè¯¥ç®—æ³•å°†ä¿¡æ¯â€œå‘å‰ä¼ é€’â€ä»ä¸€å±‚åˆ°ä¸‹ä¸€å±‚ã€‚
- en: To understand how it achieves this, letâ€™s first zoom in and look at how information
    is passed from one layer to a single neuron in the next layer.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ç†è§£å®ƒæ˜¯å¦‚ä½•å®ç°çš„ï¼Œè®©æˆ‘ä»¬å…ˆæ”¾å¤§æ¥çœ‹ä¿¡æ¯æ˜¯å¦‚ä½•ä»ä¸€å±‚ä¼ é€’åˆ°ä¸‹ä¸€å±‚çš„ä¸€ä¸ªç¥ç»å…ƒçš„ã€‚
- en: '![](../Images/abb01642c9f7285b915f83047f7374c3.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/abb01642c9f7285b915f83047f7374c3.png)'
- en: Weights connecting neurons in layer 0 with the first neuron in layer 1
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿æ¥å±‚0ä¸­ç¥ç»å…ƒä¸å±‚1ä¸­ç¬¬ä¸€ä¸ªç¥ç»å…ƒçš„æƒé‡
- en: 'The activation of the first neuron in the second layer, *a*â‚€â½Â¹â¾,is calculated
    by taking a weighted sum of the activations from the previous layer plus a bias
    and passing this through an activation function, *Ïƒ*(*x*):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒå±‚ä¸­ç¬¬ä¸€ä¸ªç¥ç»å…ƒçš„æ¿€æ´»*a*â‚€â½Â¹â¾æ˜¯é€šè¿‡å¯¹å‰ä¸€å±‚çš„æ¿€æ´»è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå†åŠ ä¸Šåç½®ï¼Œå¹¶é€šè¿‡æ¿€æ´»å‡½æ•°*Ïƒ*(*x*)æ¥è®¡ç®—çš„ï¼š
- en: Equation for calculating *a*â‚€â½Â¹â¾
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—*a*â‚€â½Â¹â¾çš„æ–¹ç¨‹
- en: The superscript with round brackets denotes the layer index, starting from 0
    for the input layer. Activation (*a*)*,* and bias (*b*) subscriptsdenote neuron
    index. The first and second numbers in the weight (*w*) subscripts denote the
    index of the neuron the weight connects to (in the current layer) and from (in
    the previous layer) respectively.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å¸¦åœ†æ‹¬å·çš„ä¸Šæ ‡è¡¨ç¤ºå±‚ç´¢å¼•ï¼Œä» 0 å¼€å§‹ï¼Œè¡¨ç¤ºè¾“å…¥å±‚ã€‚æ¿€æ´»ï¼ˆ*a*ï¼‰å’Œåç½®ï¼ˆ*b*ï¼‰ä¸‹æ ‡è¡¨ç¤ºç¥ç»å…ƒç´¢å¼•ã€‚æƒé‡ï¼ˆ*w*ï¼‰ä¸‹æ ‡ä¸­çš„å‰ä¸¤ä¸ªæ•°å­—è¡¨ç¤ºæƒé‡è¿æ¥çš„ç¥ç»å…ƒçš„ç´¢å¼•ï¼ˆå½“å‰å±‚ä¸­çš„ï¼‰å’Œä»ï¼ˆå‰ä¸€å±‚ä¸­çš„ï¼‰ç´¢å¼•ã€‚
- en: The activation function determines if a neuron should be activated based on
    the input it receives. Common activation functions include sigmoid, tanh, rectified
    linear unit (ReLU), and softmax. To keep things simple, in our implementation,
    we will always use the sigmoid activation function.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ¿€æ´»å‡½æ•°å†³å®šä¸€ä¸ªç¥ç»å…ƒæ˜¯å¦åº”æ ¹æ®æ¥æ”¶åˆ°çš„è¾“å…¥è€Œè¢«æ¿€æ´»ã€‚å¸¸è§çš„æ¿€æ´»å‡½æ•°åŒ…æ‹¬ sigmoidã€tanhã€ä¿®æ­£çº¿æ€§å•å…ƒï¼ˆReLUï¼‰å’Œ softmaxã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œåœ¨æˆ‘ä»¬çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬å°†å§‹ç»ˆä½¿ç”¨
    sigmoid æ¿€æ´»å‡½æ•°ã€‚
- en: '![](../Images/644584ee1f184d127aec522e9821bccb.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/644584ee1f184d127aec522e9821bccb.png)'
- en: Sigmoid, tanh and ReLU activation functions
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoidã€tanh å’Œ ReLU æ¿€æ´»å‡½æ•°
- en: 'The equation we used to calculate *a*â‚€â½Â¹â¾ can be vectorised so that we can
    calculate all activations in the second layer:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç”¨æ¥è®¡ç®— *a*â‚€â½Â¹â¾ çš„æ–¹ç¨‹å¯ä»¥å‘é‡åŒ–ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥è®¡ç®—ç¬¬äºŒå±‚ä¸­çš„æ‰€æœ‰æ¿€æ´»å€¼ï¼š
- en: Vectorised equation for calculating ***a***â½Â¹â¾
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®— ***a***â½Â¹â¾ çš„å‘é‡åŒ–æ–¹ç¨‹
- en: Now we have neuron activations for the second layer ***a***â½Â¹â¾, we can use the
    same calculation to find ***a***â½Â²â¾ and again for ***a***â½Â³â¾ and so onâ€¦
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†ç¬¬äºŒå±‚çš„ç¥ç»å…ƒæ¿€æ´»å€¼ ***a***â½Â¹â¾ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç›¸åŒçš„è®¡ç®—æ¥æ‰¾åˆ° ***a***â½Â²â¾ï¼Œç„¶åæ˜¯ ***a***â½Â³â¾ï¼Œä»¥æ­¤ç±»æ¨â€¦â€¦
- en: 'Letâ€™s look at how this can be implemented in Python:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨ Python ä¸­å®ç°è¿™ä¸€ç‚¹ï¼š
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `Network` class contains all the information about our neural network. We
    initialise it by passing a list of integers relating to the number of neurons
    in each layer. For example, `network = Network([10, 3, 3, 2])` will create a network
    with ten neurons in the input layer, two hidden layers each containing three neurons
    and an output layer with two neurons.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`Network` ç±»åŒ…å«æœ‰å…³æˆ‘ä»¬ç¥ç»ç½‘ç»œçš„æ‰€æœ‰ä¿¡æ¯ã€‚æˆ‘ä»¬é€šè¿‡ä¼ é€’ä¸€ä¸ªæ•´æ•°åˆ—è¡¨æ¥åˆå§‹åŒ–å®ƒï¼Œè¯¥åˆ—è¡¨ä¸æ¯å±‚çš„ç¥ç»å…ƒæ•°é‡ç›¸å…³ã€‚ä¾‹å¦‚ï¼Œ`network = Network([10,
    3, 3, 2])` å°†åˆ›å»ºä¸€ä¸ªè¾“å…¥å±‚æœ‰åä¸ªç¥ç»å…ƒã€ä¸¤ä¸ªéšè—å±‚æ¯ä¸ªåŒ…å«ä¸‰ä¸ªç¥ç»å…ƒï¼Œä»¥åŠä¸€ä¸ªè¾“å‡ºå±‚æœ‰ä¸¤ä¸ªç¥ç»å…ƒçš„ç½‘ç»œã€‚'
- en: The `__init_*` methods initialise values for activations, weights and biases.
    Activations and biases are initially all zero. Weights are given a random value
    between -1 and 1.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`__init_*` æ–¹æ³•åˆå§‹åŒ–æ¿€æ´»å€¼ã€æƒé‡å’Œåç½®ã€‚æ¿€æ´»å€¼å’Œåç½®æœ€åˆéƒ½æ˜¯é›¶ã€‚æƒé‡è¢«èµ‹äºˆä¸€ä¸ªåœ¨ -1 å’Œ 1 ä¹‹é—´çš„éšæœºå€¼ã€‚'
- en: The `feedforward` method loops through the layers calculating activations in
    each subsequent layer.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`feedforward` æ–¹æ³•å¾ªç¯éå†å„å±‚ï¼Œè®¡ç®—æ¯ä¸ªåç»­å±‚çš„æ¿€æ´»å€¼ã€‚'
- en: 'Below is an example using `feedforward` to calculate the output of our `[10,
    3, 3, 2]` network given a random input. The output is inspected by printing the
    activations in the final layer:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œä½¿ç”¨`feedforward`è®¡ç®—æˆ‘ä»¬ `[10, 3, 3, 2]` ç½‘ç»œåœ¨ç»™å®šéšæœºè¾“å…¥æ—¶çš„è¾“å‡ºã€‚é€šè¿‡æ‰“å°æœ€ç»ˆå±‚çš„æ¿€æ´»å€¼æ¥æ£€æŸ¥è¾“å‡ºï¼š
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: That's it! We have successfully implemented the feedforward algorithm! Lets
    turn our attention to backpropagation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼æˆ‘ä»¬å·²ç»æˆåŠŸå®ç°äº†å‰å‘ä¼ æ’­ç®—æ³•ï¼è®©æˆ‘ä»¬å°†æ³¨æ„åŠ›è½¬å‘åå‘ä¼ æ’­ã€‚
- en: Backpropagation algorithm
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­ç®—æ³•
- en: The backpropagation algorithm is the process through which a neural network
    learns from its mistakes.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­ç®—æ³•æ˜¯ç¥ç»ç½‘ç»œä»é”™è¯¯ä¸­å­¦ä¹ çš„è¿‡ç¨‹ã€‚
- en: In the above implementation of the feedforward algorithm, we initialise network
    weights with a random number between -1 and 1 and set all biases to equal 0\.
    With this initial setup, the output produced by the network for any given input
    will be essentially random.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°å‰å‘ä¼ æ’­ç®—æ³•çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬å°†ç½‘ç»œæƒé‡åˆå§‹åŒ–ä¸º -1 å’Œ 1 ä¹‹é—´çš„éšæœºæ•°ï¼Œå¹¶å°†æ‰€æœ‰åç½®è®¾ç½®ä¸º 0ã€‚ä½¿ç”¨è¿™ç§åˆå§‹è®¾ç½®ï¼Œç½‘ç»œå¯¹ä»»ä½•ç»™å®šè¾“å…¥ç”Ÿæˆçš„è¾“å‡ºæœ¬è´¨ä¸Šæ˜¯éšæœºçš„ã€‚
- en: 'What we need is a way to update the weights and biases so that the output of
    the network becomes more meaningful. To do this we use gradient descent:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•æ¥æ›´æ–°æƒé‡å’Œåç½®ï¼Œä½¿ç½‘ç»œçš„è¾“å‡ºå˜å¾—æ›´æœ‰æ„ä¹‰ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™ï¼š
- en: Gradient descent update step
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢¯åº¦ä¸‹é™æ›´æ–°æ­¥éª¤
- en: Where ***a****â‚™*is a vector of input parameters. The subscript *n* denotes iteration.
    *f(****a****â‚™)* is a multi-variable cost function and âˆ‡*f(****a****) is* the gradient
    of that cost function. ğ›¾ is the learning rate which determines by how much ***a****â‚™*should
    be adjusted each iteration. I previously wrote an [article about gradient descent](https://medium.com/towards-data-science/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2)
    [2] which goes into much more detail on gradient descent than I do here.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ ***a****â‚™* æ˜¯ä¸€ä¸ªè¾“å…¥å‚æ•°çš„å‘é‡ã€‚ä¸‹æ ‡ *n* è¡¨ç¤ºè¿­ä»£æ¬¡æ•°ã€‚*f(****a****â‚™)* æ˜¯ä¸€ä¸ªå¤šå˜é‡ä»£ä»·å‡½æ•°ï¼Œâˆ‡*f(****a****)*
    æ˜¯è¯¥ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ã€‚ğ›¾ æ˜¯å­¦ä¹ ç‡ï¼Œå®ƒå†³å®šäº†æ¯æ¬¡è¿­ä»£ä¸­ ***a****â‚™* åº”è°ƒæ•´çš„å¹…åº¦ã€‚æˆ‘ä¹‹å‰å†™è¿‡ä¸€ç¯‡å…³äºæ¢¯åº¦ä¸‹é™çš„ [æ–‡ç« ](https://medium.com/towards-data-science/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2)
    [2]ï¼Œå…¶ä¸­è¯¦ç»†è®¨è®ºäº†æ¢¯åº¦ä¸‹é™ã€‚
- en: '[](/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2?source=post_page-----f28e3f38e811--------------------------------)
    [## PID Controller Optimization: A Gradient Descent Approach'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2?source=post_page-----f28e3f38e811--------------------------------)
    [## PID æ§åˆ¶å™¨ä¼˜åŒ–ï¼šä¸€ç§æ¢¯åº¦ä¸‹é™æ–¹æ³•'
- en: Using machine learning to solve engineering optimization problems
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æœºå™¨å­¦ä¹ è§£å†³å·¥ç¨‹ä¼˜åŒ–é—®é¢˜
- en: towardsdatascience.com](/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2?source=post_page-----f28e3f38e811--------------------------------)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2?source=post_page-----f28e3f38e811--------------------------------)
- en: In the case of a neural network, ***a****â‚™*contains all of the network weights
    and biases, and *f(****a****â‚™)* is the network cost (note *f(****a****â‚™)* â‰¡*C)*.
    Here we define network cost using the L2-norm cost function calculated from the
    expected network output, *Å·* and the actual network output, *y*. Both *Å·* and
    *y* are vectors containing *n* values where *n* is the number of neurons in the
    output layer.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¥ç»ç½‘ç»œçš„æƒ…å†µä¸‹ï¼Œ***a****â‚™* åŒ…å«äº†æ‰€æœ‰ç½‘ç»œçš„æƒé‡å’Œåç½®ï¼Œ*f(****a****â‚™)* æ˜¯ç½‘ç»œä»£ä»·ï¼ˆæ³¨æ„ *f(****a****â‚™)*
    â‰¡ *C*ï¼‰ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ L2-èŒƒæ•°ä»£ä»·å‡½æ•°æ¥å®šä¹‰ç½‘ç»œä»£ä»·ï¼Œè¯¥å‡½æ•°æ˜¯æ ¹æ®æœŸæœ›ç½‘ç»œè¾“å‡º *Å·* å’Œå®é™…ç½‘ç»œè¾“å‡º *y* è®¡ç®—çš„ã€‚*Å·* å’Œ *y* éƒ½æ˜¯åŒ…å«
    *n* ä¸ªå€¼çš„å‘é‡ï¼Œå…¶ä¸­ *n* æ˜¯è¾“å‡ºå±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡ã€‚
- en: L2-norm cost function
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: L2-èŒƒæ•°ä»£ä»·å‡½æ•°
- en: Now we know how to calculate the cost function but we donâ€™t yet know how to
    calculate the gradient of the cost function.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çŸ¥é“å¦‚ä½•è®¡ç®—ä»£ä»·å‡½æ•°ï¼Œä½†è¿˜ä¸çŸ¥é“å¦‚ä½•è®¡ç®—ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ã€‚
- en: Finding the gradient of the cost function is at the core of backpropagation.
    The gradient of the cost function tells us in which direction, and by how much,
    we need to nudge the weights and biases in our network to improve the accuracy
    of its output.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—ä»£ä»·å‡½æ•°çš„æ¢¯åº¦æ˜¯åå‘ä¼ æ’­çš„æ ¸å¿ƒã€‚ä»£ä»·å‡½æ•°çš„æ¢¯åº¦å‘Šè¯‰æˆ‘ä»¬éœ€è¦å°†ç½‘ç»œä¸­çš„æƒé‡å’Œåç½®å‘å“ªä¸ªæ–¹å‘ä»¥åŠè°ƒæ•´å¤šå°‘ï¼Œä»¥æé«˜è¾“å‡ºçš„å‡†ç¡®æ€§ã€‚
- en: Gradient of the cost function
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ä»·å‡½æ•°çš„æ¢¯åº¦
- en: To find these partial derivatives, neural networks employ [the chain rule](https://en.wikipedia.org/wiki/Chain_rule).
    This handy piece of high school calculus is a key to how neural networks work.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ‰¾åˆ°è¿™äº›åå¯¼æ•°ï¼Œç¥ç»ç½‘ç»œé‡‡ç”¨äº† [é“¾å¼æ³•åˆ™](https://en.wikipedia.org/wiki/Chain_rule)ã€‚è¿™æ®µé«˜ä¸­å¾®ç§¯åˆ†çš„å†…å®¹æ˜¯ç¥ç»ç½‘ç»œå·¥ä½œçš„å…³é”®ã€‚
- en: 'To demonstrate how the chain rule is used in the backpropagation algorithm
    we will consider a network containing a single neuron in each layer:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¼”ç¤ºé“¾å¼æ³•åˆ™åœ¨åå‘ä¼ æ’­ç®—æ³•ä¸­çš„åº”ç”¨ï¼Œæˆ‘ä»¬å°†è€ƒè™‘ä¸€ä¸ªæ¯å±‚åŒ…å«ä¸€ä¸ªç¥ç»å…ƒçš„ç½‘ç»œï¼š
- en: '![](../Images/da2a39beb27b374c280ef8644e3ca660.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da2a39beb27b374c280ef8644e3ca660.png)'
- en: Neural network with a single neuron in each layer
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯å±‚åŒ…å«ä¸€ä¸ªç¥ç»å…ƒçš„ç¥ç»ç½‘ç»œ
- en: I have introduced a simplified version of the notation introduced earlier since
    we donâ€™t need to index neurons in each layer in this example. Below, I also introduce
    a new variable, *z* which encapsulates the input to the activation function.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¼•å…¥äº†ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬çš„ç¬¦å·è¡¨ç¤ºï¼Œå› ä¸ºåœ¨è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬ä¸éœ€è¦ä¸ºæ¯å±‚ä¸­çš„ç¥ç»å…ƒç¼–å·ã€‚ä¸‹é¢ï¼Œæˆ‘è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°å˜é‡ *z*ï¼Œå®ƒå°è£…äº†æ¿€æ´»å‡½æ•°çš„è¾“å…¥ã€‚
- en: We start backpropagation from layer *L* which is the output layer and iterate
    back through the layers.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»è¾“å‡ºå±‚ *L* å¼€å§‹åå‘ä¼ æ’­ï¼Œå¹¶è¿­ä»£åœ°å‘åé€šè¿‡å„å±‚ã€‚
- en: 'For the output layer, we have:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¾“å‡ºå±‚ï¼Œæˆ‘ä»¬æœ‰ï¼š
- en: C, aâ½*á´¸*â¾ and zâ½*á´¸*â¾ for the output layer of the single neuron per layer network
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: å•å±‚ç¥ç»å…ƒç½‘ç»œè¾“å‡ºå±‚çš„ Cã€aâ½*á´¸*â¾ å’Œ zâ½*á´¸*â¾
- en: 'Now that we have defined *C*, *a*â½*á´¸*â¾ and *z*â½*á´¸*â¾ for the output layer, we
    can calculate their derivatives and apply the chain rule to find âˆ‚*C/*âˆ‚*w*â½*á´¸*â¾:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»ä¸ºè¾“å‡ºå±‚å®šä¹‰äº† *C*ã€*a*â½*á´¸*â¾ å’Œ *z*â½*á´¸*â¾ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å®ƒä»¬çš„å¯¼æ•°å¹¶åº”ç”¨é“¾å¼æ³•åˆ™æ¥æ‰¾åˆ° âˆ‚*C/*âˆ‚*w*â½*á´¸*â¾ï¼š
- en: Applying the chain rule to calculate âˆ‚*C/*âˆ‚wâ½*á´¸*â¾
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨é“¾å¼æ³•åˆ™æ¥è®¡ç®— âˆ‚*C/*âˆ‚wâ½*á´¸*â¾
- en: 'and similarly for âˆ‚*C/*âˆ‚*b*â½*á´¸*â¾:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº âˆ‚*C/*âˆ‚*b*â½*á´¸*â¾ ä¹Ÿæ˜¯ç±»ä¼¼çš„ï¼š
- en: Applying the chain rule to calculate âˆ‚*C/*âˆ‚*b*â½*á´¸*â¾
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨é“¾å¼æ³•åˆ™æ¥è®¡ç®— âˆ‚*C/*âˆ‚*b*â½*á´¸*â¾
- en: 'and âˆ‚*C/*âˆ‚aâ½*á´¸*â»Â¹â¾:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œ âˆ‚*C/*âˆ‚aâ½*á´¸*â»Â¹â¾ï¼š
- en: Applying the chain rule to calculate âˆ‚*C/*âˆ‚aâ½*á´¸*â»Â¹â¾
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨é“¾å¼æ³•åˆ™è®¡ç®— âˆ‚*C/*âˆ‚aâ½*á´¸*â»Â¹â¾
- en: 'Now that we have an expression for âˆ‚*C/*âˆ‚aâ½*á´¸*â»Â¹â¾ we can iterate back through
    the network to find how sensitive the cost function is to previous weights and
    biases:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº† âˆ‚*C/*âˆ‚aâ½*á´¸*â»Â¹â¾ çš„è¡¨è¾¾å¼ï¼Œæˆ‘ä»¬å¯ä»¥åå‘è¿­ä»£é€šè¿‡ç½‘ç»œæ‰¾åˆ°æˆæœ¬å‡½æ•°å¯¹ä¹‹å‰çš„æƒé‡å’Œåç½®çš„æ•æ„Ÿæ€§ï¼š
- en: Sensitivity of the cost function to wâ½*á´¸*â»Â¹â¾ and bâ½*á´¸*â»Â¹â¾
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æˆæœ¬å‡½æ•°å¯¹ wâ½*á´¸*â»Â¹â¾ å’Œ bâ½*á´¸*â»Â¹â¾ çš„æ•æ„Ÿæ€§
- en: The equations we have defined for calculating the sensitivities to weight and
    biases in this simplified one-neuron-per-layer network stay essentially the same
    when we have more than one neuron per layer.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸ºè®¡ç®—è¿™ç§ç®€åŒ–çš„æ¯å±‚ä¸€ä¸ªç¥ç»å…ƒç½‘ç»œä¸­å¯¹æƒé‡å’Œåç½®çš„æ•æ„Ÿæ€§å®šä¹‰çš„æ–¹ç¨‹ï¼Œåœ¨æ¯å±‚æœ‰å¤šä¸ªç¥ç»å…ƒæ—¶åŸºæœ¬ä¿æŒä¸å˜ã€‚
- en: What changes is the derivative of the cost function with respect to the activations
    in the *L-1*áµ—Ê° layer. This is because the cost function is influenced by these
    activations via multiple paths through the network.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å˜åŒ–çš„æ˜¯å…³äº *L-1*áµ—Ê° å±‚æ¿€æ´»å€¼çš„æˆæœ¬å‡½æ•°çš„å¯¼æ•°ã€‚è¿™æ˜¯å› ä¸ºæˆæœ¬å‡½æ•°é€šè¿‡ç½‘ç»œçš„å¤šä¸ªè·¯å¾„å—åˆ°è¿™äº›æ¿€æ´»å€¼çš„å½±å“ã€‚
- en: 'We define the derivative of the cost function with respect to activations in
    the *L-1*áµ—Ê° layer as:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æˆæœ¬å‡½æ•°å¯¹ *L-1*áµ—Ê° å±‚æ¿€æ´»å€¼çš„å¯¼æ•°å®šä¹‰ä¸ºï¼š
- en: Derivative of the cost function with respect to the káµ—Ê° activation in the L-1áµ—Ê°
    layer
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æˆæœ¬å‡½æ•°å…³äº L-1áµ—Ê° å±‚ä¸­ç¬¬ káµ—Ê° æ¿€æ´»çš„å¯¼æ•°
- en: where the subscripts *j* and *k* denote activations in the *L*áµ—Ê° and *L-1*áµ—Ê°
    layers respectively.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ä¸‹æ ‡ *j* å’Œ *k* åˆ†åˆ«è¡¨ç¤ºåœ¨ *L*áµ—Ê° å’Œ *L-1*áµ—Ê° å±‚çš„æ¿€æ´»å€¼ã€‚
- en: 'The backpropagation algorithm is implemented in a method called `backpropagation`
    belonging to the `Network` class:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘ä¼ æ’­ç®—æ³•åœ¨ `Network` ç±»ä¸­çš„ `backpropagation` æ–¹æ³•ä¸­å®ç°ï¼š
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that this method is vectorized to account for multiple neurons in each
    layer. dcost_dweights and dcost_dbiases are stored in arrays that are the same
    shape as the weights and biases arrays defined earlier. This makes applying gradient
    descent using these partial derivatives trivial. I also think it makes the code
    more readable.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œè¿™ä¸ªæ–¹æ³•è¿›è¡Œäº†çŸ¢é‡åŒ–å¤„ç†ï¼Œä»¥é€‚åº”æ¯å±‚å¤šä¸ªç¥ç»å…ƒã€‚dcost_dweights å’Œ dcost_dbiases å­˜å‚¨åœ¨ä¸ä¹‹å‰å®šä¹‰çš„æƒé‡å’Œåç½®æ•°ç»„ç›¸åŒå½¢çŠ¶çš„æ•°ç»„ä¸­ã€‚è¿™ä½¿å¾—ä½¿ç”¨è¿™äº›åå¯¼æ•°è¿›è¡Œæ¢¯åº¦ä¸‹é™å˜å¾—éå¸¸ç®€å•ã€‚æˆ‘è¿˜è®¤ä¸ºè¿™ä½¿å¾—ä»£ç æ›´å…·å¯è¯»æ€§ã€‚
- en: As we step back through the network we apply the chain rule for each layer and
    calculate the sensitivity of the cost function to the weight and biases from each
    layer using the equations introduced in this section.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å‘åéå†ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸€å±‚åº”ç”¨é“¾å¼æ³•åˆ™ï¼Œå¹¶ä½¿ç”¨æœ¬èŠ‚ä¸­ä»‹ç»çš„æ–¹ç¨‹è®¡ç®—æˆæœ¬å‡½æ•°å¯¹æ¯å±‚æƒé‡å’Œåç½®çš„æ•æ„Ÿæ€§ã€‚
- en: Training a neural network to classify handwritten digits
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¥åˆ†ç±»æ‰‹å†™æ•°å­—
- en: Having implemented the feedforward and backpropagation algorithms it is time
    to bring everything together and train a neural network for recognising handwritten
    digits.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å®ç°äº†å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ç®—æ³•ä¹‹åï¼Œæ˜¯æ—¶å€™å°†æ‰€æœ‰å†…å®¹æ•´åˆèµ·æ¥ï¼Œè®­ç»ƒä¸€ä¸ªç”¨äºè¯†åˆ«æ‰‹å†™æ•°å­—çš„ç¥ç»ç½‘ç»œäº†ã€‚
- en: To do this, we need a dataset of handwritten digits labelled with their corresponding
    value. Generating this dataset ourselves would be labour-intensive. Fortunately,
    databases already exist that can be used for this digit recognition problem. We
    will use the ModifiedNational Institute of Standards and Technology (MNIST) database*
    [3], a large database of labelled handwritten digits, for training our neural
    network.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ ‡æ³¨äº†ç›¸åº”å€¼çš„æ‰‹å†™æ•°å­—æ•°æ®é›†ã€‚è‡ªå·±ç”Ÿæˆè¿™ä¸ªæ•°æ®é›†å°†ä¼šéå¸¸è´¹åŠ›ã€‚å¹¸è¿çš„æ˜¯ï¼Œå·²ç»å­˜åœ¨å¯ä»¥ç”¨äºè¿™ä¸ªæ•°å­—è¯†åˆ«é—®é¢˜çš„æ•°æ®åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ä¿®æ”¹ç‰ˆå›½å®¶æ ‡å‡†ä¸æŠ€æœ¯ç ”ç©¶æ‰€ï¼ˆMNISTï¼‰æ•°æ®åº“*
    [3]ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§å‹çš„æ ‡æ³¨æ‰‹å†™æ•°å­—æ•°æ®åº“ï¼Œç”¨äºè®­ç»ƒæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œã€‚
- en: '![](../Images/51074ebf5befa172c202becf4f5a722c.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51074ebf5befa172c202becf4f5a722c.png)'
- en: A random selection of samples from the MNIST database
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä» MNIST æ•°æ®åº“ä¸­éšæœºé€‰æ‹©çš„æ ·æœ¬
- en: The MNIST database contains 70000 labelled greyscale images of size 28 x 28
    pixels (784 total). Each labelled image in the database is called a *sample*.
    The MNIST database is split into *training* and *testing* subsets containing 60000
    and 10000 samples respectively.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST æ•°æ®åº“åŒ…å« 70000 ä¸ªæ ‡æ³¨çš„ç°åº¦å›¾åƒï¼Œå¤§å°ä¸º 28 x 28 åƒç´ ï¼ˆæ€»å…± 784ï¼‰ã€‚æ•°æ®åº“ä¸­çš„æ¯ä¸ªæ ‡æ³¨å›¾åƒç§°ä¸º *æ ·æœ¬*ã€‚MNIST æ•°æ®åº“è¢«åˆ’åˆ†ä¸º
    *è®­ç»ƒ* å’Œ *æµ‹è¯•* å­é›†ï¼Œå…¶ä¸­åŒ…å« 60000 å’Œ 10000 ä¸ªæ ·æœ¬ï¼Œåˆ†åˆ«ç”¨äºè®­ç»ƒå’Œæµ‹è¯•ã€‚
- en: As their names suggest, the training subset is used to train the network and
    the testing subset is used to test network accuracy. This way we can test network
    accuracy using samples that the network has never seen before.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚å®ƒä»¬çš„åå­—æ‰€ç¤ºï¼Œè®­ç»ƒå­é›†ç”¨äºè®­ç»ƒç½‘ç»œï¼Œæµ‹è¯•å­é›†ç”¨äºæµ‹è¯•ç½‘ç»œçš„å‡†ç¡®æ€§ã€‚è¿™æ ·æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç½‘ç»œä»æœªè§è¿‡çš„æ ·æœ¬æ¥æµ‹è¯•å…¶å‡†ç¡®æ€§ã€‚
- en: Next, we split the training subset into *batches*. For this example, I decided
    that each batch should contain 100 samples. There are 600 batches in total. The
    reason we split the training subset up into batches is that we donâ€™t update network
    weights and biases after every sample. Instead, we update it after every batch.
    This way, when we apply gradient descent, rather than nudging weights and biases
    using a gradient based on a single sample, we use a gradient which is the average
    gradient calculated using all samples in a batch.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è®­ç»ƒå­é›†åˆ†å‰²æˆ*æ‰¹æ¬¡*ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘å†³å®šæ¯ä¸ªæ‰¹æ¬¡åŒ…å«100ä¸ªæ ·æœ¬ã€‚æ€»å…±æœ‰600ä¸ªæ‰¹æ¬¡ã€‚æˆ‘ä»¬å°†è®­ç»ƒå­é›†åˆ†æˆæ‰¹æ¬¡çš„åŸå› æ˜¯æˆ‘ä»¬ä¸ä¼šåœ¨æ¯ä¸ªæ ·æœ¬åæ›´æ–°ç½‘ç»œçš„æƒé‡å’Œåç½®ã€‚ç›¸åï¼Œæˆ‘ä»¬æ˜¯åœ¨æ¯ä¸ªæ‰¹æ¬¡åæ›´æ–°çš„ã€‚è¿™æ ·ï¼Œå½“æˆ‘ä»¬åº”ç”¨æ¢¯åº¦ä¸‹é™æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯åŸºäºä¸€ä¸ªæ‰¹æ¬¡æ‰€æœ‰æ ·æœ¬è®¡ç®—çš„å¹³å‡æ¢¯åº¦ï¼Œè€Œä¸æ˜¯åŸºäºå•ä¸ªæ ·æœ¬çš„æ¢¯åº¦æ¥è°ƒæ•´æƒé‡å’Œåç½®ã€‚
- en: An *epoch* contains all batches in the training subset. An epoch loops through
    all of these batches. Choosing to train our network with a single epoch means
    that the network will only â€œseeâ€ each sample from the training subset once. Increasing
    the number of epochs means that the network will train on, and therefore â€œseeâ€,
    each sample several times.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª*å‘¨æœŸ*åŒ…å«è®­ç»ƒå­é›†ä¸­çš„æ‰€æœ‰æ‰¹æ¬¡ã€‚ä¸€ä¸ªå‘¨æœŸä¼šéå†æ‰€æœ‰è¿™äº›æ‰¹æ¬¡ã€‚é€‰æ‹©ç”¨ä¸€ä¸ªå‘¨æœŸè®­ç»ƒæˆ‘ä»¬çš„ç½‘ç»œæ„å‘³ç€ç½‘ç»œåªä¼šâ€œçœ‹åˆ°â€è®­ç»ƒå­é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬ä¸€æ¬¡ã€‚å¢åŠ å‘¨æœŸæ•°æ„å‘³ç€ç½‘ç»œå°†å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå¤šæ¬¡è®­ç»ƒï¼Œä»è€Œâ€œçœ‹åˆ°â€æ¯ä¸ªæ ·æœ¬å¤šæ¬¡ã€‚
- en: '![](../Images/d39aaaa868b459bc69eef9ab96fec460.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d39aaaa868b459bc69eef9ab96fec460.png)'
- en: Training workflow diagram
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå·¥ä½œæµç¨‹å›¾
- en: A full definition of the `Network` class including all methods used in the training
    workflow is shown below. The `train_network` method is responsible for orchestrating
    the training workflow.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹æ–¹æ˜¾ç¤ºäº†`Network`ç±»çš„å®Œæ•´å®šä¹‰ï¼ŒåŒ…æ‹¬åœ¨è®­ç»ƒå·¥ä½œæµç¨‹ä¸­ä½¿ç”¨çš„æ‰€æœ‰æ–¹æ³•ã€‚`train_network`æ–¹æ³•è´Ÿè´£åè°ƒè®­ç»ƒå·¥ä½œæµç¨‹ã€‚
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that we use the AdaGrad gradient descent algorithm for updating network
    weights and biases. Adagrad adds a little more complexity than vanilla gradient
    descent but performs much better for this application.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨AdaGradæ¢¯åº¦ä¸‹é™ç®—æ³•æ¥æ›´æ–°ç½‘ç»œçš„æƒé‡å’Œåç½®ã€‚Adagradæ¯”ä¼ ç»Ÿæ¢¯åº¦ä¸‹é™ç®—æ³•å¤æ‚ä¸€äº›ï¼Œä½†åœ¨è¿™ä¸ªåº”ç”¨ä¸­è¡¨ç°æ›´å¥½ã€‚
- en: Next we need to define the shape of the network. The 784 pixel values in each
    sample make up the activations in the input layer so the size of the input layer
    is set to 784\. Since we are categorising digits between 0 and 9 we also know
    that the output layer must contain 10 neurons. For the hidden layers, I found
    that two hidden layers each with 32 neurons worked well for this problem.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ç½‘ç»œçš„å½¢çŠ¶ã€‚æ¯ä¸ªæ ·æœ¬ä¸­çš„784ä¸ªåƒç´ å€¼æ„æˆè¾“å…¥å±‚çš„æ¿€æ´»ï¼Œå› æ­¤è¾“å…¥å±‚çš„å¤§å°è®¾ç½®ä¸º784ã€‚ç”±äºæˆ‘ä»¬æ­£åœ¨å¯¹0åˆ°9çš„æ•°å­—è¿›è¡Œåˆ†ç±»ï¼Œæˆ‘ä»¬ä¹ŸçŸ¥é“è¾“å‡ºå±‚å¿…é¡»åŒ…å«10ä¸ªç¥ç»å…ƒã€‚å¯¹äºéšè—å±‚ï¼Œæˆ‘å‘ç°ä¸¤ä¸ªæ¯å±‚32ä¸ªç¥ç»å…ƒçš„éšè—å±‚å¯¹è¿™ä¸ªé—®é¢˜æ•ˆæœå¾ˆå¥½ã€‚
- en: In total, there are 26432 weights and 74 biases in this network. This means
    that when we train the network we are optimizing in a 26506 dimension parameter
    space!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼Œè¿™ä¸ªç½‘ç»œä¸­æœ‰26432ä¸ªæƒé‡å’Œ74ä¸ªåç½®ã€‚è¿™æ„å‘³ç€åœ¨è®­ç»ƒç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬æ˜¯åœ¨ä¸€ä¸ª26506ç»´çš„å‚æ•°ç©ºé—´ä¸­è¿›è¡Œä¼˜åŒ–ï¼
- en: Donâ€™t let the scale of this optimization task intimidate you. We have already
    done the hard work by implementing the feedforward and backpropagation algorithms
    and by defining the training workflow.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦è¢«è¿™é¡¹ä¼˜åŒ–ä»»åŠ¡çš„è§„æ¨¡å“å€’ã€‚æˆ‘ä»¬å·²ç»é€šè¿‡å®ç°å‰é¦ˆå’Œåå‘ä¼ æ’­ç®—æ³•ä»¥åŠå®šä¹‰è®­ç»ƒå·¥ä½œæµç¨‹å®Œæˆäº†è‰°å·¨çš„å·¥ä½œã€‚
- en: Before training the network, a little bit of preparation work on the training
    data is required to split it up into batches. We can then call train_network to
    train the network. Finally, once the network is trained, we calculate network
    accuracy by checking the output of the network against the testing subset to see
    how many samples the network categorizes correctly.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®­ç»ƒç½‘ç»œä¹‹å‰ï¼Œéœ€è¦å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œä¸€äº›å‡†å¤‡å·¥ä½œï¼Œä»¥å°†å…¶åˆ†å‰²æˆæ‰¹æ¬¡ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥è°ƒç”¨`train_network`æ¥è®­ç»ƒç½‘ç»œã€‚æœ€åï¼Œä¸€æ—¦ç½‘ç»œè®­ç»ƒå®Œæˆï¼Œæˆ‘ä»¬é€šè¿‡æ£€æŸ¥ç½‘ç»œå¯¹æµ‹è¯•å­é›†çš„è¾“å‡ºï¼Œæ¥è®¡ç®—ç½‘ç»œå‡†ç¡®ç‡ï¼Œä»¥æŸ¥çœ‹ç½‘ç»œæ­£ç¡®åˆ†ç±»äº†å¤šå°‘æ ·æœ¬ã€‚
- en: '[PRE4]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After training the network, network accuracy comes out to be 94.2%. Not bad
    for a neural network built from scratch!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå®Œæˆåï¼Œç½‘ç»œçš„å‡†ç¡®ç‡ä¸º94.2%ã€‚å¯¹äºä¸€ä¸ªä»é›¶å¼€å§‹æ„å»ºçš„ç¥ç»ç½‘ç»œæ¥è¯´ï¼Œè¿™å¹¶ä¸ç®—å·®ï¼
- en: Summary
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: In this article, I have shown you how to build a simple neural network from
    scratch using Python.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Pythonä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œã€‚
- en: We covered the implementation of the feedforward and backpropagation algorithms
    in detail, introduced the training workflow and trained a neural network with
    26432 weights and 74 biases to recognize handwritten digits from the MNIST database,
    achieving 94.2% network accuracy.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¯¦ç»†è®²è§£äº†å‰é¦ˆå’Œåå‘ä¼ æ’­ç®—æ³•çš„å®ç°ï¼Œä»‹ç»äº†è®­ç»ƒå·¥ä½œæµç¨‹ï¼Œå¹¶ç”¨26432ä¸ªæƒé‡å’Œ74ä¸ªåç½®è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥è¯†åˆ«MNISTæ•°æ®åº“ä¸­çš„æ‰‹å†™æ•°å­—ï¼Œè¾¾åˆ°äº†94.2%çš„ç½‘ç»œå‡†ç¡®ç‡ã€‚
- en: Better accuracy can be achieved by refining our implementation. For example,
    using the ReLU activation function for the hidden layers and softmax for the output
    layer has been shown to improve network accuracy [4].
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ”¹è¿›æˆ‘ä»¬çš„å®ç°å¯ä»¥è·å¾—æ›´å¥½çš„å‡†ç¡®æ€§ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°ç”¨äºéšè—å±‚ï¼Œsoftmax ç”¨äºè¾“å‡ºå±‚ï¼Œå·²è¢«è¯æ˜èƒ½æé«˜ç½‘ç»œçš„å‡†ç¡®æ€§ [4]ã€‚
- en: Similarly, we could select a different form of gradient descent for adjusting
    the weights and biases which may lead us to find a more optimum minimum in our
    26506 dimension parameter space.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸åŒå½¢å¼çš„æ¢¯åº¦ä¸‹é™æ¥è°ƒæ•´æƒé‡å’Œåå·®ï¼Œè¿™å¯èƒ½ä½¿æˆ‘ä»¬åœ¨ 26506 ç»´å‚æ•°ç©ºé—´ä¸­æ‰¾åˆ°æ›´ä¼˜çš„æœ€å°å€¼ã€‚
- en: The process of flattening each sample into a 1D array also throws away a lot
    of important information. More advanced convolutional neural networks retain information
    about neighbouring pixels in images and typically perform better than the basic
    network type implemented here.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¯ä¸ªæ ·æœ¬å±•å¹³æˆä¸€ç»´æ•°ç»„çš„è¿‡ç¨‹ä¹Ÿä¼šä¸¢å¼ƒå¤§é‡é‡è¦ä¿¡æ¯ã€‚æ›´å…ˆè¿›çš„å·ç§¯ç¥ç»ç½‘ç»œä¿ç•™äº†å›¾åƒä¸­é‚»è¿‘åƒç´ çš„ä¿¡æ¯ï¼Œé€šå¸¸æ¯”è¿™é‡Œå®ç°çš„åŸºæœ¬ç½‘ç»œç±»å‹è¡¨ç°æ›´å¥½ã€‚
- en: When I set out writing this article my aim was to produce a concise resource
    that somebody new to neural networks would be able to read and gain a basic understanding
    of how they work. I hope I have achieved this and in some small way encouraged
    you to continue learning about this extremely interesting topic.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘å¼€å§‹å†™è¿™ç¯‡æ–‡ç« æ—¶ï¼Œæˆ‘çš„ç›®æ ‡æ˜¯åˆ¶ä½œä¸€ä¸ªç®€æ˜çš„èµ„æºï¼Œè®©åˆšæ¥è§¦ç¥ç»ç½‘ç»œçš„äººèƒ½å¤Ÿé˜…è¯»å¹¶è·å¾—å¯¹å…¶å·¥ä½œåŸç†çš„åŸºæœ¬ç†è§£ã€‚æˆ‘å¸Œæœ›æˆ‘è¾¾åˆ°äº†è¿™ä¸ªç›®æ ‡ï¼Œå¹¶åœ¨æŸç§ç¨‹åº¦ä¸Šé¼“åŠ±ä½ ç»§ç»­å­¦ä¹ è¿™ä¸ªæå…·è¶£å‘³çš„ä¸»é¢˜ã€‚
- en: Has this article helped you develop a deeper understanding of how neural networks
    work? Let me know in the comments.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¯‡æ–‡ç« æ˜¯å¦å¸®åŠ©ä½ æ›´æ·±å…¥åœ°ç†è§£äº†ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†ï¼Ÿè¯·åœ¨è¯„è®ºä¸­å‘Šè¯‰æˆ‘ã€‚
- en: '**Enjoyed reading this article?**'
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**å–œæ¬¢è¿™ç¯‡æ–‡ç« å—ï¼Ÿ**'
- en: ''
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Follow](/@callum.bruce1) and [subscribe](/@callum.bruce1/subscribe) for more
    content like this â€” share it with your network â€” try developing your own neural
    network or experiment with more advanced convolutional neural networks.'
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](/@callum.bruce1) å’Œ [è®¢é˜…](/@callum.bruce1/subscribe) è·å–æ›´å¤šç±»ä¼¼å†…å®¹ â€” ä¸ä½ çš„ç½‘ç»œåˆ†äº«
    â€” å°è¯•å¼€å‘ä½ è‡ªå·±çš„ç¥ç»ç½‘ç»œæˆ–å°è¯•æ›´å…ˆè¿›çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚'
- en: '*All images unless otherwise noted are by the author.*'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰å›¾ç‰‡å‡ç”±ä½œè€…æä¾›ã€‚*'
- en: '*Yann LeCun and Corinna Cortes hold the copyright for the MNIST database. The
    MNIST database is made available under the terms of the* [*Creative Commons Attribution-Share
    Alike 3.0 license*](https://creativecommons.org/licenses/by-sa/3.0/)*.*'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*Yann LeCun å’Œ Corinna Cortes æ‹¥æœ‰ MNIST æ•°æ®åº“çš„ç‰ˆæƒã€‚MNIST æ•°æ®åº“æ ¹æ®* [*Creative Commons
    Attribution-Share Alike 3.0 license*](https://creativecommons.org/licenses/by-sa/3.0/)*çš„æ¡æ¬¾æä¾›ã€‚*'
- en: References
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] GitHub (2023), [artificial_neural_network](https://github.com/c-bruce/artificial_neural_network)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] GitHub (2023), [artificial_neural_network](https://github.com/c-bruce/artificial_neural_network)'
- en: '[2] Bruce, C. (2023). [PID Controller Optimization: A Gradient Descent Approach](https://medium.com/towards-data-science/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2).
    *Medium*'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Bruce, C. (2023). [PID Controller Optimization: A Gradient Descent Approach](https://medium.com/towards-data-science/pid-controller-optimization-a-gradient-descent-approach-58876e14eef2).
    *Medium*'
- en: '[3] Deng, L. (2012). [The MNIST database of handwritten digit images for machine
    learning research](https://ieeexplore.ieee.org/document/6296535). *IEEE Signal
    Processing Magazine*, *29*(6), 141â€“142'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Deng, L. (2012). [The MNIST database of handwritten digit images for machine
    learning research](https://ieeexplore.ieee.org/document/6296535). *IEEE Signal
    Processing Magazine*, *29*(6), 141â€“142'
- en: '[4] Nwankpa, C., Ijomah, W.L., Gachagan, A., & Marshall, S. (2018). [Activation
    Functions: Comparison of trends in Practice and Research for Deep Learning](https://arxiv.org/abs/1811.03378).
    *ArXiv, abs/1811.03378*'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Nwankpa, C., Ijomah, W.L., Gachagan, A., & Marshall, S. (2018). [Activation
    Functions: Comparison of trends in Practice and Research for Deep Learning](https://arxiv.org/abs/1811.03378).
    *ArXiv, abs/1811.03378*'
