- en: ML Engineering with DynamoDB
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 DynamoDB 进行 ML 工程
- en: 原文：[https://towardsdatascience.com/ml-engineering-with-dynamodb-398ff2e6394e](https://towardsdatascience.com/ml-engineering-with-dynamodb-398ff2e6394e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/ml-engineering-with-dynamodb-398ff2e6394e](https://towardsdatascience.com/ml-engineering-with-dynamodb-398ff2e6394e)
- en: How to leverage this powerhouse NoSQL database for online inference
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何利用这个强大的 NoSQL 数据库进行在线推理
- en: '[](https://medium.com/@achad?source=post_page-----398ff2e6394e--------------------------------)[![Avi
    Chad-Friedman](../Images/d703a18c3cce123cbeeac789dc597598.png)](https://medium.com/@achad?source=post_page-----398ff2e6394e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----398ff2e6394e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----398ff2e6394e--------------------------------)
    [Avi Chad-Friedman](https://medium.com/@achad?source=post_page-----398ff2e6394e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@achad?source=post_page-----398ff2e6394e--------------------------------)[![Avi
    Chad-Friedman](../Images/d703a18c3cce123cbeeac789dc597598.png)](https://medium.com/@achad?source=post_page-----398ff2e6394e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----398ff2e6394e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----398ff2e6394e--------------------------------)
    [Avi Chad-Friedman](https://medium.com/@achad?source=post_page-----398ff2e6394e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----398ff2e6394e--------------------------------)
    ·5 min read·Feb 7, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----398ff2e6394e--------------------------------)
    ·5 分钟阅读·2023 年 2 月 7 日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Why consider DynamoDB?
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么考虑 DynamoDB？
- en: When working with offline, batch ML systems, SQL-based workflows against a data
    warehouse like Snowflake constitute the backbone of business analytics, [descriptive
    statistics](/anomaly-detection-in-sql-2bcd8648f7a8), and predictive modeling.
    This is an ideal state, where complex transformations can be pushed to distributed
    database engines and features are defined in the same language where they’re marshaled
    for inference.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理离线批量 ML 系统时，基于 SQL 的数据仓库工作流程如 Snowflake 构成了业务分析、[描述性统计](/anomaly-detection-in-sql-2bcd8648f7a8)和预测建模的核心。这是一种理想状态，其中复杂的转换可以推送到分布式数据库引擎，而特征则在用于推理的相同语言中定义。
- en: Avoid leaving this eden, unless you’re pushed out by the (real) requirement
    for real-time inference against real-time features. If you find yourself in this
    new, messy world, especially where relevant features change at high-volumes and
    you need low-latency reads and writes, you might need NoSQL.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 避免离开这个乐园，除非你被（真实的）实时推理需求推出来。如果你发现自己处于这个新的、混乱的世界，尤其是当相关特征高频变动时，并且你需要低延迟的读取和写入，你可能需要
    NoSQL。
- en: AWS DynamoDB is an [extremely scalable](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf),
    managed NoSQL database. Like other NoSQL databases, it trades consistency for
    availability, making it an ideal data store on top of which to build a low-latency
    ML predictor. The goal of this post is to demonstrate some design patterns with
    which you can build production workflows flexible enough to handle common ML access
    patterns.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: AWS DynamoDB 是一个 [极具扩展性](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)
    的托管 NoSQL 数据库。像其他 NoSQL 数据库一样，它用一致性换取可用性，使其成为构建低延迟 ML 预测器的理想数据存储。本文的目标是展示一些设计模式，帮助你构建足够灵活的生产工作流程，以处理常见的
    ML 访问模式。
- en: '![](../Images/509e98e06ba6dc121d8d2fc4b316fb54.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/509e98e06ba6dc121d8d2fc4b316fb54.png)'
- en: Imagine generated by author on [https://imgflip.com/](https://imgflip.com/)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作者生成的图片来自 [https://imgflip.com/](https://imgflip.com/)
- en: '**Primer on indexes in DynamoDB**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**DynamoDB 中的索引简介**'
- en: Key values stores are fast, because the access pattern is simple. Elements in
    a set are accessed by a primary key. In Dynamo this is a combination of partition
    and sort keys, which must be unique per row. The partition and sort key together
    comprise a compound primary key and determine respectively (and intuitively) where
    and in what order the data will be stored.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 键值存储系统速度很快，因为访问模式很简单。集合中的元素通过主键进行访问。在 Dynamo 中，这是一组分区键和排序键的组合，每行必须唯一。分区键和排序键共同构成一个复合主键，分别直观地确定了数据存储的位置和顺序。
- en: Local secondary indexes operate within the confines of a single partition. They’re
    useful in cases where you want to sort or filter a partition in multiple ways.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本地二级索引在单个分区的范围内操作。在你想要以多种方式对分区进行排序或过滤的情况下，它们很有用。
- en: Global secondary indexes do not need to share the same partition key as the
    primary index. They can help create flexible and efficient access patterns, within
    a single table, as we’ll see in part 2 of our ML product scenario.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 全局二级索引不需要与主索引共享相同的分区键。它们可以帮助在单个表中创建灵活且高效的访问模式，正如我们将在ML产品场景的第二部分中看到的那样。
- en: GSIs are updated with eventually consistency, which means a write can succeed
    to DynamoDB before all indexes are updated. This is an intentional design tradeoff
    and part of what makes DynamoDB so powerful. When storing high-throughput data
    (e.g. telemetry stuff, high-volume transactions), writing quickly and possibly
    dirtily is a good tradeoff.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: GSI（全局二级索引）是以最终一致性的方式更新的，这意味着写入操作可能在所有索引更新之前成功写入DynamoDB。这是一个有意的设计权衡，也是DynamoDB如此强大的部分原因。当存储高吞吐量的数据（例如遥测数据、大量交易）时，快速且可能不完全干净的写入是一个好的权衡。
- en: Inference for a single customer using a time series feature
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用时间序列特征对单个客户进行推断
- en: Imagine you have a model, which predicts whether a customer will make a purchase
    given their last 30 days days of history. Your product manager asks you to use
    this model to determine whether a promotional banner should be displayed on the
    website during a browser (why not; I’m not a PM).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个模型，它预测客户是否会在过去30天的历史记录的基础上进行购买。你的产品经理要求你使用这个模型来决定是否在浏览器上展示促销横幅（为什么不呢；我不是产品经理）。
- en: How can DynamoDB support this prediction pipeline?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB如何支持这个预测管道？
- en: We design a table that supports efficient access to the features we need per
    customer.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们设计一个表，支持每个客户所需特征的高效访问。
- en: We write purchases in real-time (likely through some queue service) to the table.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实时地（可能通过某种队列服务）将购买记录写入表中。
- en: An inference application queries this table upon receiving a request from the
    website.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推断应用在接收到来自网站的请求时查询这个表。
- en: To start, let’s illustrate what the data and feature engineering would like
    like in a more familiar relational model. At inference time, the model needs to
    access the past 30 days of purchases for the customer.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们在一个更熟悉的关系模型中展示数据和特征工程的样子。在推断时，模型需要访问客户过去30天的购买记录。
- en: How can you efficiently replicate this set up in DynamoDB? The model predicts
    at the customer level, using features for that customer, so a natural (and efficient)
    place to start is to partition the data on the customer_id. DynamoDB will store
    data for each customer ID continuously; within each primary key partition, we
    want to efficiently fetch the purchases relevant to our prediction. A local secondary
    index allows us to do just that.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何在DynamoDB中高效地复制这个设置？模型在客户层面进行预测，使用该客户的特征，因此一个自然（且高效）的起点是按customer_id分区数据。DynamoDB将为每个客户ID连续存储数据；在每个主键分区内，我们希望高效地获取与预测相关的购买数据。一个本地二级索引可以让我们做到这一点。
- en: Let’s use the values in this table in a real-time inference application. The
    mocked out model here is a logistic regression with the single, self-explanatory
    feature *total_purchase_volume_30d*. We serve the prediction to the front end
    through a FastAPI endpoint, which marshals the data from DynamoDB and feeds it
    into a predictive model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个实时推断应用中使用这个表中的值。这里模拟的模型是一个逻辑回归，具有单一且易于理解的特征*total_purchase_volume_30d*。我们通过FastAPI端点将预测结果提供给前端，FastAPI从DynamoDB中获取数据，并将其输入到预测模型中。
- en: Extending this to multiple predictions at once
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将其扩展到同时进行多个预测
- en: So far so good. We’re able to hit a single API endpoint with a customer ID and
    access that customer’s prediction with low latency. In fact, your PM is so pleased
    with the performance of the promotion, she wants to expand it to an email blast.
    She wants each blast to target customers who are likely to purchase in the next
    30 days, segmented by customers who have made purchases in particular categories.
    One email blast may target jewelry shoppers and another funky shirts (winging
    it, here).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利。我们能够用一个客户ID命中一个API端点，并以低延迟访问该客户的预测。事实上，你的产品经理对促销活动的表现非常满意，她希望将其扩展到邮件群发。她希望每次群发都针对可能在接下来的30天内购买的客户，并根据在特定类别中进行过购买的客户进行细分。一封邮件群发可能针对珠宝购物者，另一封则可能针对有趣的衬衫（这里随便说说）。
- en: The ML pipeline now has to support returning predictions for all customers who
    have purchased in each category . The problem is there are a ton of customers;
    let’s say tens of millions. Furthermore, the majority haven’t made a purchase
    in the last 30 days. Our current data design necessitates a *scan* over all customers,
    filtering for transactions in the category we care about. This sort of scan on
    a large table is exorbitantly expensive, as it requires reading each item in the
    table; and exorbitantly annoying as you’ll need to paginate through tons of results.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，机器学习管道需要支持为每个类别中所有已购买的客户返回预测。问题在于客户数量庞大；假设有数千万个客户。此外，大多数客户在过去30天内没有进行购买。我们当前的数据设计要求对所有客户进行*扫描*，过滤出我们关心的类别中的交易。这种对大型表格进行扫描的操作代价极其高昂，因为它需要读取表格中的每一项；同时也极其麻烦，因为你需要分页浏览大量结果。
- en: 'Luckily, we can extend the table with a Global Secondary Index (GSI) to support
    this use case efficiently. GSI data is stored independently from the primary index
    and, therefore, *does not need to share the same partition.* This is key in supporting
    our use case: our strategy is to query for all items in the table under a particular
    category, filter out the relevant customers, and then leverage the primary index
    to make our predictions. *Note: we leverage the “ProjectionType” attribute to
    limit the amount of data stored in the secondary index (we only need customer
    IDs in this scenario). This will keep costs down and speed up reads and writes.*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们可以通过扩展表格并添加全局二级索引（GSI）来有效支持这种用例。GSI 数据与主索引独立存储，因此*不需要共享相同的分区*。这对于支持我们的用例至关重要：我们的策略是查询表中某一特定类别下的所有项，筛选出相关客户，然后利用主索引进行预测。*注意：我们利用“ProjectionType”属性来限制存储在二级索引中的数据量（在这种情况下，我们只需要客户
    ID）。这将降低成本并加快读写速度。*
- en: The prediction loop below implements the strategy outlined above. A simple query
    against the GSI quickly returns all purchases in the table in the category specified
    by the API parameter `category_name`. We deduplicate the customer IDs returned
    and then leverage them in a `BatchGetItem` request (which cuts down on network
    round trip time) to get all purchases for those customers, using the primary key
    and local secondary index. The feature marshaling and prediction can then take
    place entirely in memory.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的预测循环实现了上述策略。针对 GSI 的简单查询可以快速返回表中由 API 参数 `category_name` 指定的类别中的所有购买记录。我们去重返回的客户
    ID，然后利用这些 ID 发起一个 `BatchGetItem` 请求（这可以减少网络往返时间），以获取这些客户的所有购买记录，使用主键和本地二级索引。特征数据的封送处理和预测可以完全在内存中进行。
- en: Conclusion
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Through two ML product use-cases, we’ve seen how to leverage local and global
    indexes in DynamoDB to efficiently store and access feature data. You can even
    get fancier, [simulating a full set of relations via secondary indexes](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-relational-modeling.html).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 通过两个机器学习产品用例，我们已了解如何利用 DynamoDB 中的本地和全局索引来高效存储和访问特征数据。你甚至可以更进一步，[通过二级索引模拟一整套关系](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-relational-modeling.html)。
- en: Feature engineering in SQL is more intuitive and less verbose, so use it where
    you can. But DynamoDB’s low-latency, eventually consistent model makes it an attractive
    option for high-volume online inference.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SQL 中进行特征工程更直观且冗余较少，因此尽可能使用它。然而，DynamoDB 的低延迟、最终一致性模型使其成为高量在线推断的有吸引力的选项。
