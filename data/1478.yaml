- en: Hyperbolic Deep Reinforcement Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 双曲深度强化学习
- en: 原文：[https://towardsdatascience.com/hyperbolic-deep-reinforcement-learning-b2de787cf2f7?source=collection_archive---------1-----------------------#2023-04-30](https://towardsdatascience.com/hyperbolic-deep-reinforcement-learning-b2de787cf2f7?source=collection_archive---------1-----------------------#2023-04-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/hyperbolic-deep-reinforcement-learning-b2de787cf2f7?source=collection_archive---------1-----------------------#2023-04-30](https://towardsdatascience.com/hyperbolic-deep-reinforcement-learning-b2de787cf2f7?source=collection_archive---------1-----------------------#2023-04-30)
- en: RL meets hyperbolic geometry
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RL 遇上双曲几何
- en: Many RL problems have hierarchical tree-like nature. Hyperbolic geometry offers
    a powerful prior for such problems.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 许多强化学习问题具有层次树状结构。双曲几何为这些问题提供了强大的先验知识。
- en: '[](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)[![Michael
    Bronstein](../Images/1aa876fce70bb07bef159fecb74e85bf.png)](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)
    [Michael Bronstein](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)[![Michael
    Bronstein](../Images/1aa876fce70bb07bef159fecb74e85bf.png)](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)
    [Michael Bronstein](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b1129ddd572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&user=Michael+Bronstein&userId=7b1129ddd572&source=post_page-7b1129ddd572----b2de787cf2f7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)
    ·17 min read·Apr 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2de787cf2f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&user=Michael+Bronstein&userId=7b1129ddd572&source=-----b2de787cf2f7---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b1129ddd572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&user=Michael+Bronstein&userId=7b1129ddd572&source=post_page-7b1129ddd572----b2de787cf2f7---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)
    · 17 分钟阅读 · 2023年4月30日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2de787cf2f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&user=Michael+Bronstein&userId=7b1129ddd572&source=-----b2de787cf2f7---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2de787cf2f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&source=-----b2de787cf2f7---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2de787cf2f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&source=-----b2de787cf2f7---------------------bookmark_footer-----------)'
- en: Many problems in Reinforcement Learning manifest a hierarchical tree-like nature.
    Hyperbolic spaces, which can be conceptualised as continuous analogies of trees,
    are thus suitable candidates to parameterise the agent’s deep model. In this post,
    we overview the basics of hyperbolic geometry, show empirically that it provides
    a good inductive bias for many RL problems, and describe a practical regularisation
    procedure allowing to resolve numerical instabilities in end-to-end optimisation
    with hyperbolic latent spaces. Our approach shows a near-universal performance
    improvement across a broad range of common benchmarks both with on-policy and
    off-policy RL algorithms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习中的许多问题展现出层次树状的特征。双曲空间可以被概念化为树的连续类比，因此是参数化智能体深度模型的合适候选者。在这篇文章中，我们概述了双曲几何的基础，实证展示了它为许多RL问题提供了良好的归纳偏置，并描述了一种实用的正则化程序，解决了在使用双曲潜在空间的端到端优化中出现的数值不稳定性。我们的方法在广泛的常见基准测试中表现出了几乎普遍的性能提升，无论是在策略内还是策略外的RL算法中。
- en: '![](../Images/b6bdc310bab65aab0cc8849bfb1a4359.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b6bdc310bab65aab0cc8849bfb1a4359.png)'
- en: Stable Diffusion prompted with “Hyperbolic Atari Breakout game, icon design,
    flat design, vector art” (courtesy of [David Ha](https://twitter.com/hardmaru?lang=en))
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 提示：“双曲 Atari Breakout 游戏，图标设计，平面设计，矢量艺术”（由 [David Ha](https://twitter.com/hardmaru?lang=en)
    提供）
- en: '*This post was co-authored with* [*Edoardo Cetin*](https://aladoro.github.io/)*,*
    [*Ben Chamberlain*](https://twitter.com/DrBPChamberlain)*, and* [*Jonathan Hunt*](https://twitter.com/jjh)
    *and is based on the paper E. Cetin et al.,* [*Hyperbolic deep reinforcement learning*](https://arxiv.org/pdf/2210.01542.pdf)
    *(2023) ICLR. For more details, find us at ICLR 2023!*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*这篇文章由* [*Edoardo Cetin*](https://aladoro.github.io/)*，* [*Ben Chamberlain*](https://twitter.com/DrBPChamberlain)*，和*
    [*Jonathan Hunt*](https://twitter.com/jjh) *共同撰写，并基于论文 E. Cetin 等，* [*Hyperbolic
    deep reinforcement learning*](https://arxiv.org/pdf/2210.01542.pdf) *(2023) ICLR。更多详情，请在
    ICLR 2023 上找到我们！*'
- en: Basics of Reinforcement Learning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习基础
- en: RL problems can be described as a Markov Decision Process (MDP), where the agent
    observes some *state* *s*∈*S* from…
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: RL 问题可以被描述为马尔可夫决策过程 (MDP)，其中智能体观察某个 *状态* *s*∈*S* 从…
