- en: Evaluation of Machine Learning Classifiers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习分类器的评估
- en: 原文：[https://towardsdatascience.com/evaluation-of-machine-learning-classifiers-3912e7f5cf74](https://towardsdatascience.com/evaluation-of-machine-learning-classifiers-3912e7f5cf74)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/evaluation-of-machine-learning-classifiers-3912e7f5cf74](https://towardsdatascience.com/evaluation-of-machine-learning-classifiers-3912e7f5cf74)
- en: '**Explanation of Bias-Variance Analysis, Regularization, Performance Metrics,
    and an Implementation of Harmonic Classifier**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**偏倚-方差分析、正则化、性能指标的解释及和谐分类器的实现**'
- en: '[](https://azad-wolf.medium.com/?source=post_page-----3912e7f5cf74--------------------------------)[![J.
    Rafid Siddiqui, PhD](../Images/02280890ed87239c75cbcbfa7c5d686c.png)](https://azad-wolf.medium.com/?source=post_page-----3912e7f5cf74--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3912e7f5cf74--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3912e7f5cf74--------------------------------)
    [J. Rafid Siddiqui, PhD](https://azad-wolf.medium.com/?source=post_page-----3912e7f5cf74--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://azad-wolf.medium.com/?source=post_page-----3912e7f5cf74--------------------------------)[![J.
    Rafid Siddiqui, PhD](../Images/02280890ed87239c75cbcbfa7c5d686c.png)](https://azad-wolf.medium.com/?source=post_page-----3912e7f5cf74--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3912e7f5cf74--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3912e7f5cf74--------------------------------)
    [J. Rafid Siddiqui, PhD](https://azad-wolf.medium.com/?source=post_page-----3912e7f5cf74--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3912e7f5cf74--------------------------------)
    ·10 min read·Jan 15, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----3912e7f5cf74--------------------------------)
    ·10分钟阅读·2023年1月15日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/1af4c25b061e3dd486d1b8d39f776bc6.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1af4c25b061e3dd486d1b8d39f776bc6.png)'
- en: 'Figure 1: A depiction of Results from a Bias-Variance Analysis (Source: Author)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：偏倚-方差分析结果的示意图（来源：作者）
- en: In the previous articles, we have discussed various Machine Learning methods
    for classification tasks. We have also used terms like *Regularization*, *Overfitting*
    and *Underfitting* repeatedly. In this article, we shall go through these terms
    in detail and show how you can circumvent such problems. Furthermore, we shall
    also discuss various metrics for measuring the performance of a classifier.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的文章中，我们讨论了各种用于分类任务的机器学习方法。我们也重复使用了*正则化*、*过拟合*和*欠拟合*等术语。在本文中，我们将详细介绍这些术语，并展示如何规避这些问题。此外，我们还将讨论各种用于衡量分类器性能的指标。
- en: '**1.** **Bias-Variance Analysis**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.** **偏倚-方差分析**'
- en: Bias-Variance Analysis is a process for the evaluation of a Machine Learning
    Classifier. Every Classifier can suffer from either a *High Bias* or a *High Variance*
    problem depending on the conditions of the training. Knowing about these common
    problems and preventing them can help one build better, more general, and high-performance
    models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 偏倚-方差分析是评估机器学习分类器的一个过程。每个分类器都可能出现*高偏倚*或*高方差*问题，这取决于训练条件。了解这些常见问题并加以防范，可以帮助构建更好、更通用且高性能的模型。
- en: '**High Bias (Underfitting)**'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高偏倚（欠拟合）**'
- en: When a classifier is highly biased towards a certain type of prediction (e.g.,
    a certain class) regardless of the change in the input data then we call such
    model suffering from a *High Bias* problem. For example, if we train a linear
    model on a training-set which is not linearly separable, then such model would
    perform badly even on the training-set. So we shall call such a model an underfit
    model because it doesn’t fully capture the structure of the dataset. An example
    of such an underfitting problem is shown in figure 2.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个分类器对某种类型的预测（例如某个类别）存在高度偏倚，而无论输入数据如何变化，这种模型就会出现*高偏倚*问题。例如，如果我们在一个无法线性分离的训练集上训练一个线性模型，那么该模型即使在训练集上也会表现得很糟糕。因此，我们称这样的模型为欠拟合模型，因为它没有完全捕捉数据集的结构。图2展示了一个欠拟合问题的示例。
- en: '![](../Images/b338014df64904ef6e6e3be27335864c.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b338014df64904ef6e6e3be27335864c.png)'
- en: 'Figure 2: An Example of a model suffering from an Underfitting Problem (Source:
    Author)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：一个模型出现欠拟合问题的示例（来源：作者）
- en: As you may have noticed, such a model works badly on both the training-set and
    the test-set. This is because the model is not equipped with sufficient parameters
    to deal with the non-linearity in the data. It could also mean that there isn’t
    enough data. In cases where sample size is too small for training, model would
    not converge to the optimum point and resulting model would suffer from underfitting
    problem.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这样的模型在训练集和测试集上表现都很差。这是因为模型没有足够的参数来处理数据中的非线性。也可能是数据量不足。在样本量过小的情况下，模型无法收敛到最佳点，
    resulting model 会遭遇欠拟合问题。
- en: · **High Variance (Overfitting)**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: · **高方差（过拟合）**
- en: Another common problem while training a Machine Learning Classifier happens
    when model performs well on training-set, however, when it is tested on a different
    set of examples than the ones it has already been trained on, its performance
    deteriorates significantly. This problem is called a *High Variance* or an *Overfitting*
    problem. It is named this a way because the model has a high variance in the prediction
    outputs. In other words, model can’t handle the variance in the input samples
    for a given class and instead of producing a steady prediction for a given class,
    it produces a varied predictions for the same class. An example of such *Overfitting*
    problem is shown in figure 3.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 训练机器学习分类器时常见的另一个问题是，当模型在训练集上表现良好时，但当它在不同于已训练过的样本的测试集上进行测试时，其性能显著下降。这种问题被称为*高方差*或*过拟合*问题。之所以这样命名，是因为模型在预测输出中具有高方差。换句话说，模型无法处理给定类别输入样本中的方差，而是为同一类别产生不同的预测。图3展示了这种*过拟合*问题的一个示例。
- en: '![](../Images/bff23cdac8157063063919fae87d8130.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bff23cdac8157063063919fae87d8130.png)'
- en: 'Figure 3: An Example of a model suffering from an Overfitting Problem (Source:
    Author)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：一个遭遇过拟合问题的模型示例（来源：作者）
- en: · **Learning Curves (Diagnostics)**
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: · **学习曲线（诊断）**
- en: Now that you know what the High Bias and the High Variance problems are, you
    may be wondering how one can find out that the model is suffering from which problem.
    In two-dimensional data such the one in the examples, we can easily see that from
    naked eye by plotting the data and the decision boundary of a classifier, however,
    when data is multidimensional, it is not feasible to do so. Therefore, one needs
    a general diagnostic method for finding the exact problem. *Learning Curves* is
    such a criterion which one can use to find-out the type of the problem. More specifically,
    we plot the objective function value for a sample set of data instances drawn
    randomly from the training-set. We then increase the number of samples iteratively
    and keep plotting the objective function value for new set of data samples. This
    gives us a curve for how the model is behaving for training-set. In addition to
    the training-set, we also use a c*ross-validation* set for verification of the
    performance. We create a separate data split in addition to the train-test-split
    and call it *Cross-Validation* set. All the parameter tuning, and evaluations
    are then performed and compared against this *Cross-Validation* set while in the
    training phase. We repeat the aforementioned process of plotting the learning
    curve for c*ross-validation* set as well. An example result of such learning curves
    can be shown in figure 4.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道了高偏差和高方差的问题，你可能会想，如何判断模型遭遇了哪种问题。在像示例中这样的二维数据中，我们可以通过绘制数据和分类器的决策边界来轻松看出。然而，当数据是多维的时，这样做是不切实际的。因此，需要一种通用的诊断方法来找出具体的问题。*学习曲线*就是一种可以用来发现问题类型的标准。更具体地说，我们绘制从训练集中随机抽取的数据实例的目标函数值。然后，我们逐步增加样本数量，并不断绘制新数据样本的目标函数值。这为我们提供了模型在训练集上的表现曲线。除了训练集外，我们还使用*交叉验证*集来验证性能。我们在训练-测试拆分之外创建一个单独的数据拆分，并称之为*交叉验证*集。所有的参数调优和评估都在训练阶段对这个*交叉验证*集进行比较。我们还重复上述过程，为*交叉验证*集绘制学习曲线。图4展示了这种学习曲线的一个示例结果。
- en: '![](../Images/c520e121522ef6ba3256d080755c8a3e.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c520e121522ef6ba3256d080755c8a3e.png)'
- en: 'Figure 4: An Example of Learning Curves for Underfitting, Overfitting and Best
    Fitting respectively (Source: Author)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：分别为欠拟合、过拟合和最佳拟合的学习曲线示例（来源：作者）
- en: If we observe Learning Curves, we shall see that when both the curves (i.e.,
    **Jₜ** and **Jcᵥ**) don’t converge we have an underfitting problem which means
    that the model hasn’t learned anything and won’t classify accurately both on the
    training and the test data. However, when we see that the curve **Jₜ** on training
    data shows a clear convergence while the curve for cross-validation set (**Jcᵥ**)
    shows divergence then, we have an overfitting problem. The larger is the gap between
    the final cost values of the training and cross-validation sets, the greater is
    the probability that the model is suffering from an overfitting problem, and it
    won’t work for new examples than the ones it has already been trained on. In case
    of a best fit, both curves would converge which would indicate that the model
    is balanced and would work well for both the training and the test examples. It
    is to be noted that in complex datasets, both curves might not converge to absolute
    zero, and there might be a small gap between the two curves, however, it would
    not be a significant gap and distance from the absolute convergence point should
    not be too much.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们观察学习曲线，我们会发现当两条曲线（即**Jₜ**和**Jcᵥ**）都不收敛时，我们就有了欠拟合问题，这意味着模型没有学习任何东西，并且无法准确分类训练数据和测试数据。然而，当我们看到训练数据的曲线**Jₜ**明显收敛，而交叉验证集的曲线（**Jcᵥ**）则出现发散时，那么我们就有了过拟合问题。训练集和交叉验证集最终成本值之间的差距越大，模型过拟合的概率就越大，模型在新的示例上的表现将不如在已经训练过的示例上的表现。如果模型拟合最佳，两条曲线将收敛，这表明模型平衡，对训练和测试样本的表现都很好。需要注意的是，在复杂的数据集中，两条曲线可能不会完全收敛到绝对零点，两者之间可能存在小的差距，但这不应该是显著的差距，距离绝对收敛点不应过大。
- en: '**2.** **Solutions**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**2.** **解决方案**'
- en: In the previous section, we discussed multiple problems that a Machine Learning
    Classifier can suffer from, here we list some of the mitigation strategies for
    overcoming these problems.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了机器学习分类器可能遇到的多个问题，这里列出了一些克服这些问题的缓解策略。
- en: · **Using Better Data**
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: · **使用更好的数据**
- en: Most of the problems while building a Machine Learning model stem from bad data.
    If the dataset is too small, has too much noise and/or it contains contradictory/misleading
    data points then the best course of action is to find better data. A dataset which
    is unbalanced and has a few instances of a certain class compared to the other
    classes can also cause overfitting problem. In case of an overfitting problem,
    increasing the size of the data could solve the problem if the problem originated
    due to lack of data. Normalizing and stratifying the data can also help if the
    problem is arising due to unbalanced data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器学习模型时的大多数问题源于数据质量不佳。如果数据集过小、噪声过多和/或包含矛盾/误导性数据点，则最佳的解决方案是寻找更好的数据。不平衡的数据集以及某一类实例相对于其他类别的少量实例也可能导致过拟合问题。如果过拟合问题是由于数据不足引起的，则增加数据量可以解决这个问题。如果问题由于数据不平衡引起的，那么归一化和分层数据也可以有所帮助。
- en: · **Regularization**
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: · **正则化**
- en: One way to handle the overfitting problem is to introduce a Regularization term
    in the objective function which would relax the constraints a bit resulting in
    accommodation for variability in the data. More specifically, we can add a term
    in the objective function (e.g., L1/L2 norm of weights) which would result in
    less penalty for slightly deviant points in the training-set occurring due to
    noise. An example of such regularization can be seen in figure 5.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 处理过拟合问题的一种方法是引入目标函数中的正则化项，这将稍微放松约束，从而适应数据中的变异。更具体地说，我们可以在目标函数中添加一个项（例如，权重的 L1/L2
    范数），这样对于训练集中由于噪声产生的轻微偏差点，将会减少惩罚。这样的正则化示例可以在图 5 中看到。
- en: '![](../Images/fd43058008ac689a4dc6cda9d05da9cb.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd43058008ac689a4dc6cda9d05da9cb.png)'
- en: 'Figure 5: An Example of Effect of using Regularization for solving Overfitting
    problem (Source: Author)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：使用正则化解决过拟合问题的效果示例（来源：作者）
- en: If we observe the effect of a Regularization on Classification boundary, we
    will notice that it widens it and thus allows accommodation for noisy points which
    would have otherwise wrongly classified due to a tight decision boundary. However,
    this may come at the cost of decreased performance on the training-set as can
    be observed from figure 5\. So, it is a matter of choice and is controlled by
    a parameter *Lambda* which determines how much weight is to be given for a Regularization
    term while constructing a classifier. The optimum value of *Lambda* can also be
    learned by plotting the Learning Curves on training and cross-validation sets
    against variations in *Lambda* parameter while keeping the data size the same.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们观察正则化对分类边界的影响，我们会注意到它会使分类边界变宽，从而允许噪声点的容纳，否则这些点由于决策边界过紧会被错误分类。然而，这可能会以训练集性能下降为代价，正如图5所示。因此，这取决于选择，由一个参数*Lambda*控制，该参数决定在构建分类器时应给予正则化项多少权重。*Lambda*的最佳值也可以通过在训练和交叉验证集上绘制学习曲线，并在保持数据大小相同的情况下，绘制*Lambda*参数的变化来学习。
- en: · **Constructing Better Feature Space**
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: · **构建更好的特征空间**
- en: There are cases when the problem arises due to bad/insufficient feature space.
    In such cases, one must construct a better feature space. For example, in case
    of an underfitting problem, such as the one we depicted earlier (i.e., a linear
    classifier on a non-linear dataset), it would be necessary to increase the number
    and type of feature. We can see the results of adding more features (i.e., a 3rd
    degree polynomial model) in figure 3\. The model becomes good at classifying the
    training-set and therefore, solves the underfitting problem. However, we also
    saw that it started to suffer from an overfitting problem and became too restrictive
    for certain data samples. We have also discussed how we can mitigate the overfitting
    problem in the previous sections. However, in some cases, simply changing the
    feature space to a more suitable one can improve the performance drastically and
    can provide a more general model which works robustly for even unseen data. If
    we observe the data closely, we should see that it is a repetitive pattern, and
    we can model it using a harmonic classifier. In-fact, if we model it with a harmonic
    classifier (e.g., a sine wave) we can obtain a model which would work for any
    new sample and thus provide us with a general solution. An example of such *Harmonic*
    classifier fitted on the data is shown in figure 6\. As we can see, it not only
    learns and classifies the training-set with just one cycle but it is robust for
    any number of cycles.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当问题由于不良/不足的特征空间而出现时，我们必须构建一个更好的特征空间。例如，在之前提到的欠拟合问题（即，在非线性数据集上使用线性分类器）中，必须增加特征的数量和类型。我们可以在图3中看到添加更多特征（即3阶多项式模型）的结果。模型在分类训练集方面表现良好，因此解决了欠拟合问题。然而，我们也看到它开始遭遇过拟合问题，并且对某些数据样本过于限制。我们在前面的部分讨论了如何减轻过拟合问题。然而，在某些情况下，仅仅将特征空间更改为更合适的空间可以显著提高性能，并提供一个对未见数据也能稳健工作的更通用的模型。如果我们仔细观察数据，我们应该会看到它是一个重复的模式，我们可以使用谐波分类器来建模。事实上，如果我们用谐波分类器（例如，正弦波）来建模，我们可以获得一个适用于任何新样本的模型，从而提供一个通用的解决方案。图6中展示了一个*谐波*分类器拟合数据的例子。正如我们所见，它不仅能够仅用一个周期来学习和分类训练集，而且对任何数量的周期都很稳健。
- en: '![](../Images/4d015479f58624e6a908f3cb161d797c.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d015479f58624e6a908f3cb161d797c.png)'
- en: 'Figure 6: Results of a Harmonic Classifier on Non-Linear Data (Source: Author)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：谐波分类器在非线性数据上的结果（来源：作者）
- en: '**3.** **Performance Metrics**'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**3.** **性能指标**'
- en: '![](../Images/48dc16aec5a16780071b5efc7b4d38ed.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48dc16aec5a16780071b5efc7b4d38ed.png)'
- en: 'Figure 7: Performance Metrics for Binary Classification Problem (Source: Author)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：二分类问题的性能指标（来源：作者）
- en: Once a classifier has been trained, one needs a measure to find out how good
    is the classification performance. There can be a multitude of metrics which can
    be used for such performance evaluation. Accuracy is a commonly used metric for
    many tasks; however, it is a bad metric when the dataset is unbalanced. If dataset
    has only a few instances of a certain class, accuracy would be highly biased towards
    the majority class. In such cases, a different metric must be used. As in figure
    7, we construct a set of metrics, e.g., *True Positive Rate (TPR)* and *False
    Positive Rate (FPR)* by counting the frequency of the classified labels. *TPR
    (recall/sensitivity)* measures the prediction accuracy of the classifier for the
    positive class (i.e., class 1) and *FPR* measures the prediction performance of
    the classifier performance of the negative class (i.e., the class 0). There is
    always a tradeoff between high *recall/TPR* and low *FPR*. For example, if we
    take an example of an object detector/classifier then *TPR* tells us how often
    the detector finds the object correctly among the ones it was shown and *FPR*
    measures how often it wrongly detects the object when there wasn’t an object in
    the scene.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦分类器训练完成，就需要一个度量来评估分类性能的好坏。可以使用多种指标进行这种性能评估。准确率是许多任务中常用的指标；然而，当数据集不平衡时，它是一种不好的指标。如果数据集中只有少量某一类的实例，准确率将会严重偏向于多数类。在这种情况下，必须使用其他指标。如图7所示，我们构建了一组指标，例如*真正例率（TPR）*和*假正例率（FPR）*，通过计算分类标签的频率来进行评估。*TPR（召回率/敏感性）*衡量分类器对正类（即类1）的预测准确率，而*FPR*衡量分类器对负类（即类0）的预测性能。高*召回率/TPR*与低*FPR*之间总是存在权衡。例如，如果我们以目标检测器/分类器为例，那么*TPR*告诉我们检测器在所显示的对象中正确找到对象的频率，而*FPR*则衡量检测器在场景中没有对象时错误检测对象的频率。
- en: Furthermore, performance of a classifier depends heavily on the threshold used
    on the probability to classify the point into a class. For example, in case of
    a binary classifier, we may use a threshold (e.g., 0.5) on the output probability
    and classify the point to either in class ***0*** or in class ***1*** depending
    on the value of the output probability. However, 0.5 is an arbitrary value and
    differs in different classification scenarios. So, in order to find the optimum
    threshold — at which performance of a classifier is the maximum, one can vary
    the threshold from **0** to ***1*** and observe the performance metrics (e.g.,
    *TPR*, *FPR* etc.). This process is called *Receiver Operating Characteristic
    Analysis* (*ROC*) and is performed by plotting the *ROC* curves. A *ROC* curve
    is obtained by plotting the *FPR* against the *TPR* while varying the threshold
    of a classifier. The area under the such curve provides the measure of performance
    (i.e., the greater the area, the greater is the classification performance). A
    No-Skill classifier (i.e., the one which either returns a random class or a constant
    class as prediction output) is plotted as a diagonal line. Any output curve close
    to a No-Skill Classifier is considered as a bad classifier which has no classification
    ability. A perfect classifier is represented by a square curve in the upper left
    corner. An example output of such *ROC* curves can be seen in figure 8.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，分类器的性能在很大程度上依赖于用于将点分类到某一类的概率阈值。例如，在二分类器的情况下，我们可能会使用一个阈值（例如0.5）对输出概率进行分类，并根据输出概率的值将点分类为***0***类或***1***类。然而，0.5是一个任意值，在不同的分类场景中可能有所不同。因此，为了找到最佳阈值——即分类器性能最佳的阈值，可以将阈值从**0**调整到***1***，并观察性能指标（例如*TPR*、*FPR*等）。这个过程称为*接收操作特性分析*（*ROC*），通过绘制*ROC*曲线来执行。*ROC*曲线是通过绘制*FPR*与*TPR*的关系来获得的，同时调整分类器的阈值。曲线下方的面积提供了性能度量（即，面积越大，分类性能越好）。一个无技能分类器（即返回随机类别或常量类别作为预测输出的分类器）被绘制为对角线。任何接近无技能分类器的输出曲线都被认为是没有分类能力的坏分类器。完美分类器由位于左上角的方形曲线表示。这种*ROC*曲线的示例输出可以在图8中看到。
- en: '![](../Images/62767b254f7e0d696a934b6343ef075b.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62767b254f7e0d696a934b6343ef075b.png)'
- en: 'Figure 8: ROC Curves and Precision-Recall Curves (Source: Author)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：ROC曲线和精确度-召回曲线（来源：作者）
- en: In addition to the *ROC* curves, there is another metric called “*Precision-Recall*”
    curves. It is obtained by plotting the *TPR* against Precision/*PPV (Positive
    Predictive Value).* Precision measures the correctness of the classification.
    If we take our previous object detection analogy, then precision measures how
    often the classifier correctly classifies the object among the ones that it detects.
    Same as *TPR vs FPR*, there is a tradeoff between *TPR* and *Precision*. High
    *TPR* may come at the cost of loss of *Precision*. *Precision-Recall* curves are
    particularly useful for unbalanced data. The interpretation of the *Precision-Recall*
    is similar to *ROC* curves, However, the perfect classifier performance lies in
    the upper right corner and No-Skill Classifier (e.g., a majority classifier or
    random classifier) appears as a flat line around 0.5.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 除了*ROC*曲线，还有另一种指标称为“*精确度-召回率*”曲线。它是通过绘制*TPR*与精确度/*PPV（正预测值）*的关系来获得的。精确度衡量分类的正确性。如果我们以之前的目标检测类比，那么精确度衡量的是分类器在检测到的对象中正确分类的频率。与*TPR
    vs FPR*一样，*TPR*和*精确度*之间也存在权衡。高*TPR*可能会以损失*精确度*为代价。*精确度-召回率*曲线对于不平衡数据特别有用。*精确度-召回率*的解释类似于*ROC*曲线。然而，完美的分类器性能位于右上角，而无技能分类器（例如，大多数分类器或随机分类器）则显示为0.5附近的平坦线。
- en: '**4.** **Conclusions**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**4.** **结论**'
- en: In this article, we discussed the problems which occur while training a Machine
    Learning Classifier. We explained how to diagnose the type of these problems.
    Then we explained various mitigation strategies for dealing with such problems.
    We have also discussed various performance metrics for evaluating a Machine Learning
    Classifier. Evaluation methods are an important aspect of a Machine Learning modelling
    paradigm and can be useful for robust training of models and hyperparameter optimization.
    You can further practice with the methods and concepts with the code in the link
    below.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们讨论了在训练机器学习分类器时出现的问题。我们解释了如何诊断这些问题的类型。然后，我们解释了应对这些问题的各种缓解策略。我们还讨论了评估机器学习分类器的各种性能指标。评估方法是机器学习建模范式的一个重要方面，对模型的稳健训练和超参数优化有帮助。你可以通过下面链接中的代码进一步练习这些方法和概念。
- en: '**Code:**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[https://www.github.com/azad-academy/MLBasics-Evaluation](https://www.github.com/azad-academy/MLBasics-Evaluation)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.github.com/azad-academy/MLBasics-Evaluation](https://www.github.com/azad-academy/MLBasics-Evaluation)'
- en: '**Become a Patreon Supporter:**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**成为Patreon支持者：**'
- en: '[https://www.patreon.com/azadacademy](https://www.patreon.com/azadacademy)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.patreon.com/azadacademy](https://www.patreon.com/azadacademy)'
- en: '**Find me on Substack:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**在Substack上找到我：**'
- en: '[https://azadwolf.substack.com](https://azadwolf.substack.com)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://azadwolf.substack.com](https://azadwolf.substack.com)'
- en: '**Follow Twitter for Updates:**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**关注Twitter以获取更新：**'
- en: '[https://twitter.com/azaditech](https://twitter.com/azaditech)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://twitter.com/azaditech](https://twitter.com/azaditech)'
