- en: Why Your RAG Is Not Reliable in a Production Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆä½ çš„ RAG åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä¸å¯é 
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/why-your-rag-is-not-reliable-in-a-production-environment-9e6a73b3eddb](https://towardsdatascience.com/why-your-rag-is-not-reliable-in-a-production-environment-9e6a73b3eddb)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/why-your-rag-is-not-reliable-in-a-production-environment-9e6a73b3eddb](https://towardsdatascience.com/why-your-rag-is-not-reliable-in-a-production-environment-9e6a73b3eddb)
- en: And how you should tune it properly
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»¥åŠä½ åº”è¯¥å¦‚ä½•æ­£ç¡®è°ƒæ•´å®ƒ
- en: '[](https://ahmedbesbes.medium.com/?source=post_page-----9e6a73b3eddb--------------------------------)[![Ahmed
    Besbes](../Images/93804d9291439715e578f204b79c9bdd.png)](https://ahmedbesbes.medium.com/?source=post_page-----9e6a73b3eddb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e6a73b3eddb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e6a73b3eddb--------------------------------)
    [Ahmed Besbes](https://ahmedbesbes.medium.com/?source=post_page-----9e6a73b3eddb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ahmedbesbes.medium.com/?source=post_page-----9e6a73b3eddb--------------------------------)[![Ahmed
    Besbes](../Images/93804d9291439715e578f204b79c9bdd.png)](https://ahmedbesbes.medium.com/?source=post_page-----9e6a73b3eddb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9e6a73b3eddb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9e6a73b3eddb--------------------------------)
    [Ahmed Besbes](https://ahmedbesbes.medium.com/?source=post_page-----9e6a73b3eddb--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e6a73b3eddb--------------------------------)
    Â·7 min readÂ·Oct 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9e6a73b3eddb--------------------------------)
    Â·é˜…è¯»æ—¶é—´ 7 åˆ†é’ŸÂ·2023å¹´10æœˆ12æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/96beae64de9f7f71263e41a7767a45fe.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96beae64de9f7f71263e41a7767a45fe.png)'
- en: Photo by [Ivan Jermakov](https://unsplash.com/@ivanjermakov?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[Ivan Jermakov](https://unsplash.com/@ivanjermakov?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: With the rise of LLMs, the Retrieval Augmented Generation (RAG) [framework](https://arxiv.org/abs/2005.11401)
    also gained popularity by making it possible to build question-answering systems
    over data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ LLM çš„å…´èµ·ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰[æ¡†æ¶](https://arxiv.org/abs/2005.11401) ä¹Ÿå› èƒ½å¤Ÿåœ¨æ•°æ®ä¸Šæ„å»ºé—®ç­”ç³»ç»Ÿè€Œè·å¾—äº†å¹¿æ³›å…³æ³¨ã€‚
- en: Weâ€™ve all seen those demos of chatbots conversing with PDFs or emails.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éƒ½è§è¿‡é‚£äº›èŠå¤©æœºå™¨äººä¸ PDF æˆ–ç”µå­é‚®ä»¶å¯¹è¯çš„æ¼”ç¤ºã€‚
- en: While these systems are certainly impressive, they might not be reliable in
    production without tweaking and experimentation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™äº›ç³»ç»Ÿç¡®å®ä»¤äººå°è±¡æ·±åˆ»ï¼Œä½†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¦‚æœä¸è¿›è¡Œè°ƒæ•´å’Œå®éªŒï¼Œå®ƒä»¬å¯èƒ½ä¸å¤Ÿå¯é ã€‚
- en: '***In this post, I explore the problems behind the RAG framework and go over
    some tips to improve its performance. This goes from leveraging document metadata
    to fine-tuning hyperparameters.***'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æ¢è®¨äº† RAG æ¡†æ¶èƒŒåçš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€äº›æå‡å…¶æ€§èƒ½çš„æŠ€å·§ã€‚è¿™äº›æŠ€å·§åŒ…æ‹¬åˆ©ç”¨æ–‡æ¡£å…ƒæ•°æ®å’Œè°ƒæ•´è¶…å‚æ•°ã€‚***'
- en: These findings are based on my experience as an ML engineer whoâ€™s still learning
    about this tech and building RAGs in the pharmaceutical industry.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å‘ç°åŸºäºæˆ‘ä½œä¸ºä¸€å ML å·¥ç¨‹å¸ˆçš„ç»éªŒï¼Œæˆ‘ä»åœ¨å­¦ä¹ è¿™é¡¹æŠ€æœ¯å¹¶åœ¨åˆ¶è¯è¡Œä¸šæ„å»º RAGã€‚
- en: Without much further ado, letâ€™s have a look ğŸ”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹ä¸å®œè¿Ÿï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€çœ‹ ğŸ”
- en: If youâ€™re interested in practical tips to increase your productivity in building
    ML systems, you feel free to subscribe to my [newsletter](https://thetechbuffet.substack.com/).
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¯¹æé«˜æ„å»º ML ç³»ç»Ÿçš„ç”Ÿäº§åŠ›æ„Ÿå…´è¶£ï¼Œå¯ä»¥éšæ—¶è®¢é˜…æˆ‘çš„ [é€šè®¯](https://thetechbuffet.substack.com/)ã€‚
- en: I send weekly insights in programming and system design to help you ship AI
    products faster.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘æ¯å‘¨å‘é€å…³äºç¼–ç¨‹å’Œç³»ç»Ÿè®¾è®¡çš„è§è§£ï¼Œå¸®åŠ©ä½ æ›´å¿«åœ°æ¨å‡º AI äº§å“ã€‚
- en: RAG in a nutshell âš™ï¸
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAG ç®€è¦ä»‹ç» âš™ï¸
- en: Letâ€™s get the basics right first.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬è¦å¼„æ¸…æ¥šåŸºæœ¬æ¦‚å¿µã€‚
- en: Hereâ€™s how RAG works.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ RAG çš„å·¥ä½œåŸç†ã€‚
- en: It first takes an input question and retrieves relevant documents to it from
    an external database. Then, it passes those chunks as a context in a prompt to
    help an LLM generate an *augmented* answer.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒé¦–å…ˆæ¥å—ä¸€ä¸ªè¾“å…¥é—®é¢˜ï¼Œå¹¶ä»å¤–éƒ¨æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚ç„¶åï¼Œå®ƒå°†è¿™äº›ç‰‡æ®µä½œä¸ºä¸Šä¸‹æ–‡ä¼ é€’ç»™æç¤ºï¼Œä»¥å¸®åŠ© LLM ç”Ÿæˆä¸€ä¸ª *å¢å¼ºçš„* å›ç­”ã€‚
- en: 'Thatâ€™s basically saying:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åŸºæœ¬ä¸Šæ˜¯è¯´ï¼š
- en: '*â€œHey LLM, hereâ€™s my question, and here are some pieces of text to help you
    understand the problem. Give me an answer.â€*'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*â€œå˜¿ LLMï¼Œè¿™é‡Œæ˜¯æˆ‘çš„é—®é¢˜ï¼Œè¿˜æœ‰ä¸€äº›æ–‡æœ¬ç‰‡æ®µå¸®åŠ©ä½ ç†è§£é—®é¢˜ã€‚ç»™æˆ‘ä¸€ä¸ªå›ç­”ã€‚â€*'
- en: '![](../Images/fa22dfd8e1aebc6a46efc827dcf82c0a.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fa22dfd8e1aebc6a46efc827dcf82c0a.png)'
- en: Image by the author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: You should not be fooled by the simplicity of this diagram.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦è¢«è¿™ä¸ªå›¾è¡¨çš„ç®€å•æ€§æ‰€æ¬ºéª—ã€‚
- en: 'In fact, RAG hides a certain complexity and involves the following components
    behind the scenes:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹å®ä¸Šï¼ŒRAG éšè—äº†æŸäº›å¤æ‚æ€§ï¼Œå¹¶ä¸”æ¶‰åŠä»¥ä¸‹ç»„ä»¶ï¼š
- en: 'Loaders to parse external data in different formats: PDFs, websites, Doc files,
    etc.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è§£æä¸åŒæ ¼å¼çš„å¤–éƒ¨æ•°æ®çš„åŠ è½½å™¨ï¼šPDFã€ç½‘ç«™ã€Doc æ–‡ä»¶ç­‰ã€‚
- en: Splitters to chunk the raw data into smaller pieces of text
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºå°†åŸå§‹æ•°æ®åˆ†å‰²æˆè¾ƒå°æ–‡æœ¬å—çš„åˆ†å‰²å™¨
- en: An embedding model to convert the chunks into vectors
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºå°†æ–‡æœ¬å—è½¬æ¢ä¸ºå‘é‡çš„åµŒå…¥æ¨¡å‹
- en: A vector database to store the vectors and query them
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºå­˜å‚¨å’ŒæŸ¥è¯¢å‘é‡çš„å‘é‡æ•°æ®åº“
- en: A prompt to combine the question and the retrieved documents
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºå°†é—®é¢˜å’Œæ£€ç´¢åˆ°çš„æ–‡æ¡£ç»“åˆçš„æç¤º
- en: An LLM to generate the answer
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”¨äºç”Ÿæˆç­”æ¡ˆçš„ LLM
- en: If you like diagrams, hereâ€™s another for you.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å–œæ¬¢å›¾ç¤ºï¼Œè¿™é‡Œæœ‰å¦ä¸€ä¸ªç»™ä½ ã€‚
- en: A tad more complex but it illustrates the indexing and retrieval processes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ç¨å¾®å¤æ‚ä¸€ç‚¹ï¼Œä½†å®ƒå±•ç¤ºäº†ç´¢å¼•å’Œæ£€ç´¢è¿‡ç¨‹ã€‚
- en: '![](../Images/883ab9133ece2fa4c0037256a7a67418.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/883ab9133ece2fa4c0037256a7a67418.png)'
- en: Image modified by the author
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ä¿®æ”¹çš„å›¾åƒ
- en: Phew!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: å“å‘€ï¼
- en: Donâ€™t worry though, you can still prototype your RAG very quickly.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡åˆ«æ‹…å¿ƒï¼Œä½ ä»ç„¶å¯ä»¥å¾ˆå¿«åŸå‹åŒ–ä½ çš„ RAGã€‚
- en: Frameworks like [LangChain](https://www.langchain.com/) abstracted most of the
    steps involved in building a RAG and it became easy to prototype those systems.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åƒ[LangChain](https://www.langchain.com/)è¿™æ ·çš„æ¡†æ¶æŠ½è±¡äº†æ„å»º RAG æ¶‰åŠçš„å¤§éƒ¨åˆ†æ­¥éª¤ï¼Œä½¿å¾—åŸå‹è®¾è®¡è¿™äº›ç³»ç»Ÿå˜å¾—å®¹æ˜“ã€‚
- en: How easy is that? 5-line-of-code easy.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ‰å¤šç®€å•ï¼Ÿäº”è¡Œä»£ç å°±æå®šäº†ã€‚
- en: '![](../Images/e6e3739a9cd5b8aa3d08e942a5b00d40.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e6e3739a9cd5b8aa3d08e942a5b00d40.png)'
- en: 'Of course, thereâ€™s always a problem with the apparent simplicity of such code
    snippets: depending on your use case, they donâ€™t always work as-is and need very
    careful tuning.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œè¿™ç§ä»£ç ç‰‡æ®µçš„æ˜æ˜¾ç®€åŒ–æ€»æ˜¯æœ‰é—®é¢˜çš„ï¼šæ ¹æ®ä½ çš„ä½¿ç”¨æƒ…å†µï¼Œå®ƒä»¬å¹¶ä¸æ€»æ˜¯èƒ½æŒ‰åŸæ ·å·¥ä½œï¼Œéœ€è¦éå¸¸ä»”ç»†çš„è°ƒæ•´ã€‚
- en: Theyâ€™re great as quick-starts but theyâ€™re certainly not a reliable solution
    for an industrialized application.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒä»¬ä½œä¸ºå¿«é€Ÿå¯åŠ¨çš„å·¥å…·å¾ˆæ£’ï¼Œä½†ç»å¯¹ä¸æ˜¯å·¥ä¸šåŒ–åº”ç”¨çš„å¯é è§£å†³æ–¹æ¡ˆã€‚
- en: The problems with RAG
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAG çš„é—®é¢˜
- en: If you start building RAG systems with little to no tuning, you may be surprised.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¼€å§‹æ„å»º RAG ç³»ç»Ÿè€Œå‡ ä¹æ²¡æœ‰è°ƒæ•´ï¼Œä½ å¯èƒ½ä¼šæ„Ÿåˆ°æƒŠè®¶ã€‚
- en: Hereâ€™s what I noticed during the first weeks of using LangChain and building
    RAGs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘åœ¨ä½¿ç”¨ LangChain å’Œæ„å»º RAG çš„å‰å‡ å‘¨æ‰€æ³¨æ„åˆ°çš„æƒ…å†µã€‚
- en: '**1 â€” The retrieved documents are not always relevant to the question.**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**1 â€” æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸æ€»æ˜¯ä¸é—®é¢˜ç›¸å…³ã€‚**'
- en: If you closely look at the chunks that the database retrieves, you will sometimes
    notice that theyâ€™re not exactly relevant to the problem. Theyâ€™re certainly similar
    to the question to some extent but in many cases, theyâ€™re not fully aligned with
    what the user asks for. Moreover, these chunks can often be redundant and overlapping
    which makes the generated answer â€¦ repetitive.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä»”ç»†æŸ¥çœ‹æ•°æ®åº“æ£€ç´¢åˆ°çš„å—ï¼Œä½ æœ‰æ—¶ä¼šæ³¨æ„åˆ°å®ƒä»¬å¹¶ä¸å®Œå…¨ä¸é—®é¢˜ç›¸å…³ã€‚å®ƒä»¬ä¸é—®é¢˜åœ¨æŸç§ç¨‹åº¦ä¸Šç›¸ä¼¼ï¼Œä½†åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œå®ƒä»¬å¹¶æ²¡æœ‰å®Œå…¨å¯¹å‡†ç”¨æˆ·çš„è¯·æ±‚ã€‚æ­¤å¤–ï¼Œè¿™äº›å—å¾€å¾€å†—ä½™ä¸”é‡å ï¼Œè¿™ä½¿å¾—ç”Ÿæˆçš„ç­”æ¡ˆâ€¦â€¦é‡å¤ã€‚
- en: Hereâ€™s a small experiment that shows that the most similar documents to the
    query (in the embedding space) are neither the most relevant ones nor the most
    semantically similar (how surprising is that!).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªå°å®éªŒï¼Œå±•ç¤ºäº†ä¸æŸ¥è¯¢ï¼ˆåœ¨åµŒå…¥ç©ºé—´ï¼‰æœ€ç›¸ä¼¼çš„æ–‡æ¡£æ—¢ä¸æ˜¯æœ€ç›¸å…³çš„ï¼Œä¹Ÿä¸æ˜¯æœ€è¯­ä¹‰ç›¸ä¼¼çš„ï¼ˆè¿™çœŸä»¤äººæƒŠè®¶ï¼ï¼‰ã€‚
- en: In this example, the model disregarded the sentiment of the sentence and wasnâ€™t
    even robust to plural (adding an â€œsâ€ decreases the similarity by 8%)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ¨¡å‹å¿½ç•¥äº†å¥å­çš„æƒ…æ„Ÿï¼Œå¹¶ä¸”å¯¹å¤æ•°å½¢å¼ï¼ˆæ·»åŠ â€œsâ€å°†ç›¸ä¼¼åº¦é™ä½äº† 8%ï¼‰ä¹Ÿä¸å¤Ÿé²æ£’ã€‚
- en: '![](../Images/0712ca4a3ee2e3aef95fbb18d94d77d8.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0712ca4a3ee2e3aef95fbb18d94d77d8.png)'
- en: '**2 â€” RAG systems lack basic world knowledge** If you instruct a RAG to only
    rely on an external database to provide answers, it may surprise you by inventing
    facts or refusing to answer simple questions.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**2 â€” RAG ç³»ç»Ÿç¼ºä¹åŸºæœ¬çš„ä¸–ç•ŒçŸ¥è¯†** å¦‚æœä½ æŒ‡ç¤º RAG ä»…ä¾èµ–å¤–éƒ¨æ•°æ®åº“æ¥æä¾›ç­”æ¡ˆï¼Œå®ƒå¯èƒ½ä¼šé€šè¿‡ç¼–é€ äº‹å®æˆ–æ‹’ç»å›ç­”ç®€å•é—®é¢˜æ¥è®©ä½ æ„Ÿåˆ°æƒŠè®¶ã€‚'
- en: I built a RAG once on tennis-related Reddit posts. While it successfully answered
    questions about the Wimbledon Open of that time, it was unable to answer general
    questions on tennis rules.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ›¾ç»åœ¨ä¸ç½‘çƒç›¸å…³çš„ Reddit å¸–å­ä¸Šæ„å»ºè¿‡ä¸€ä¸ª RAGã€‚è™½ç„¶å®ƒæˆåŠŸå›ç­”äº†æœ‰å…³å½“æ—¶æ¸©å¸ƒå°”ç™»å…¬å¼€èµ›çš„é—®é¢˜ï¼Œä½†å¯¹ç½‘çƒè§„åˆ™çš„ä¸€èˆ¬é—®é¢˜å´æ— èƒ½ä¸ºåŠ›ã€‚
- en: I know youâ€™re not supposed to ask questions beyond the scope of the data you
    feed the system, but if you deploy a RAG-based service, you should expect anything
    from the users.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘çŸ¥é“ä½ ä¸åº”è¯¥é—®è¶…å‡ºç³»ç»Ÿæ•°æ®èŒƒå›´çš„é—®é¢˜ï¼Œä½†å¦‚æœä½ éƒ¨ç½²äº†åŸºäº RAG çš„æœåŠ¡ï¼Œä½ åº”è¯¥å¯¹ç”¨æˆ·æå‡ºçš„ä»»ä½•é—®é¢˜åšå¥½å‡†å¤‡ã€‚
- en: '**3 â€” Speed**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**3 â€” é€Ÿåº¦**'
- en: Depending on the type of database you use and the size of the LLM, your RAG
    can be painfully slow. This can degrade the user experience. You should make your
    benchmarks first before building your solution.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®ä½ ä½¿ç”¨çš„æ•°æ®åº“ç±»å‹å’ŒLLMçš„å¤§å°ï¼Œä½ çš„RAGå¯èƒ½ä¼šéå¸¸æ…¢ã€‚è¿™ä¼šé™ä½ç”¨æˆ·ä½“éªŒã€‚ä½ åº”è¯¥åœ¨æ„å»ºè§£å†³æ–¹æ¡ˆä¹‹å‰å…ˆåšä¸€äº›åŸºå‡†æµ‹è¯•ã€‚
- en: '**4 â€” A lossy process**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**4 â€” ä¸€ä¸ªæœ‰æŸçš„è¿‡ç¨‹**'
- en: Given how RAG splits the raw data into chunks, embeds those chunks, and retrieves
    the top K similar ones, the intrinsic information is gradually lost and distilled.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºRAGå°†åŸå§‹æ•°æ®åˆ†å‰²æˆå—ï¼ŒåµŒå…¥è¿™äº›å—ï¼Œå¹¶æ£€ç´¢æœ€ç›¸ä¼¼çš„Kä¸ªï¼Œå›ºæœ‰çš„ä¿¡æ¯ä¼šé€æ¸ä¸§å¤±å’Œæç‚¼ã€‚
- en: Therefore, it becomes impossible to retain all the information from the external
    documents and provide a perfect answer to the question.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œä¿ç•™å¤–éƒ¨æ–‡æ¡£ä¸­çš„æ‰€æœ‰ä¿¡æ¯å¹¶æä¾›å®Œç¾çš„ç­”æ¡ˆå‡ ä¹æ˜¯ä¸å¯èƒ½çš„ã€‚
- en: 'This is important to keep in mind: weâ€™re dealing with a lot of approximations
    here.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è®°ä½è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼šæˆ‘ä»¬åœ¨è¿™é‡Œå¤„ç†çš„æ˜¯å¾ˆå¤šè¿‘ä¼¼å€¼ã€‚
- en: Tips to improve the performance of your RAG
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æå‡RAGæ€§èƒ½çš„æŠ€å·§
- en: RAGs can show strange behaviors if you blindly plug them into your data.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ç›²ç›®åœ°å°†RAGæ¥å…¥æ•°æ®ï¼Œå®ƒå¯èƒ½ä¼šè¡¨ç°å‡ºå¥‡æ€ªçš„è¡Œä¸ºã€‚
- en: You can however solve these issues by applying some tips and best practices.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥é€šè¿‡åº”ç”¨ä¸€äº›æŠ€å·§å’Œæœ€ä½³å®è·µæ¥è§£å†³è¿™äº›é—®é¢˜ã€‚
- en: ğŸ‘‰ **Inspect and clean your data**
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‰ **æ£€æŸ¥å’Œæ¸…ç†æ•°æ®**
- en: The good old â€œgarbage in, garbage outâ€ principle still applies to RAG.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: â€œåƒåœ¾è¿›ï¼Œåƒåœ¾å‡ºâ€çš„åŸåˆ™ä»ç„¶é€‚ç”¨äºRAGã€‚
- en: If you feed documents that are noisy (Hello HTML tags!), not consistent with
    each other, confusing, or even redundant, the generated answer will suffer and
    reflect these defects.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æä¾›çš„æ–‡æ¡£æ˜¯å™ªå£°è¾ƒå¤§çš„ï¼ˆä¾‹å¦‚HTMLæ ‡ç­¾ï¼ï¼‰ã€å½¼æ­¤ä¸ä¸€è‡´ã€ä»¤äººå›°æƒ‘ï¼Œç”šè‡³æ˜¯é‡å¤çš„ï¼Œé‚£ä¹ˆç”Ÿæˆçš„ç­”æ¡ˆå°†ä¼šå—åˆ°å½±å“ï¼Œå¹¶åæ˜ å‡ºè¿™äº›ç¼ºé™·ã€‚
- en: Be cautious when selecting the data your RAG will tap into.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é€‰æ‹©RAGå°†ä½¿ç”¨çš„æ•°æ®æ—¶è¦å°å¿ƒã€‚
- en: For example, instead of combining FAQs that are inherently short with long PDFs,
    you could create two vector stores instead.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œä¸å…¶å°†å›ºæœ‰è¾ƒçŸ­çš„FAQä¸é•¿PDFåˆå¹¶ï¼Œä¸å¦‚åˆ›å»ºä¸¤ä¸ªå‘é‡å­˜å‚¨ã€‚
- en: 'Hereâ€™s a quick sanity check to assess the data quality: do the exercise for
    a question or two. If you find it hard to get an answer with the support of the
    data you have at your disposal, donâ€™t expect the RAG to perform better.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªå¿«é€Ÿçš„è´¨é‡æ£€æŸ¥æ¥è¯„ä¼°æ•°æ®è´¨é‡ï¼šå°è¯•å›ç­”ä¸€ä¸¤ä¸ªé—®é¢˜ã€‚å¦‚æœä½ å‘ç°å¾ˆéš¾ç”¨ç°æœ‰çš„æ•°æ®æ”¯æŒå¾—åˆ°ç­”æ¡ˆï¼Œé‚£å°±ä¸è¦æŒ‡æœ›RAGè¡¨ç°å¾—æ›´å¥½ã€‚
- en: ğŸ‘‰ **Finetune the chunk size, the top_k, and the chunk overlap**
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‰ **å¾®è°ƒå—å¤§å°ã€top_kå’Œå—é‡å **
- en: These parameters are **very** important since chunking is the core part of a
    RAG system. (Remember, the documents we retrieve from the store are **chunks**!)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å‚æ•°**éå¸¸**é‡è¦ï¼Œå› ä¸ºåˆ†å—æ˜¯RAGç³»ç»Ÿçš„æ ¸å¿ƒéƒ¨åˆ†ã€‚ï¼ˆè®°ä½ï¼Œæˆ‘ä»¬ä»å­˜å‚¨ä¸­æ£€ç´¢åˆ°çš„æ–‡æ¡£æ˜¯**å—**ï¼ï¼‰
- en: These parameters impact the quality of the retrieved results and consequently,
    the generated answer.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å‚æ•°å½±å“æ£€ç´¢ç»“æœçš„è´¨é‡ï¼Œä»è€Œå½±å“ç”Ÿæˆçš„ç­”æ¡ˆã€‚
- en: For example, a small chunk size might not catch enough context, while a big
    chunk size might introduce a lot of irrelevant noise.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå°å—å¤§å°å¯èƒ½æ— æ³•æ•æ‰åˆ°è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ï¼Œè€Œå¤§å—å¤§å°å¯èƒ½å¼•å…¥å¤§é‡æ— å…³çš„å™ªå£°ã€‚
- en: There is no miraculous magic number I can give you here. The best solution is
    to run experiments and validate these hyperparameters on a test set. (Yes, building
    a test set is important!)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ²¡æœ‰ä»€ä¹ˆç¥å¥‡çš„æ•°å­—å¯ä»¥ç»™ä½ ã€‚æœ€å¥½çš„è§£å†³æ–¹æ¡ˆæ˜¯è¿›è¡Œå®éªŒå¹¶åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯è¿™äº›è¶…å‚æ•°ã€‚ï¼ˆæ˜¯çš„ï¼Œæ„å»ºæµ‹è¯•é›†å¾ˆé‡è¦ï¼ï¼‰
- en: Thereâ€™s also this [guide](https://www.pinecone.io/learn/chunking-strategies/)
    on chunking strategies from Pinecone thatâ€™s worth reading.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Pineconeæœ‰ä¸€ä¸ªå…³äºåˆ†å—ç­–ç•¥çš„[æŒ‡å—](https://www.pinecone.io/learn/chunking-strategies/)ï¼Œå€¼å¾—é˜…è¯»ã€‚
- en: ğŸ‘‰ **Leverage your document metadata**
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‰ **åˆ©ç”¨æ–‡æ¡£å…ƒæ•°æ®**
- en: Itâ€™s sometimes useful to filter over the available metadata (for example the
    date) after the documents are retrieved from the database. This provides another
    filtering dimension and doesnâ€™t cost anything.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶å€™åœ¨ä»æ•°æ®åº“æ£€ç´¢åˆ°æ–‡æ¡£åï¼ŒåŸºäºå¯ç”¨çš„å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æ—¥æœŸï¼‰è¿›è¡Œè¿‡æ»¤æ˜¯æœ‰ç”¨çš„ã€‚è¿™æä¾›äº†å¦ä¸€ç§è¿‡æ»¤ç»´åº¦ï¼Œè€Œä¸”ä¸éœ€è¦é¢å¤–è´¹ç”¨ã€‚
- en: 'ğŸ‘‰ **Tweak your system prompt** to give your RAG a default behavior or specific
    instructions. Hereâ€™s a system prompt I used in one of my projects:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‰ **è°ƒæ•´ä½ çš„ç³»ç»Ÿæç¤º**ä»¥ç»™RAGä¸€ä¸ªé»˜è®¤è¡Œä¸ºæˆ–ç‰¹å®šæŒ‡ä»¤ã€‚è¿™æ˜¯æˆ‘åœ¨ä¸€ä¸ªé¡¹ç›®ä¸­ä½¿ç”¨çš„ç³»ç»Ÿæç¤ºï¼š
- en: '[PRE0]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ğŸ‘‰ **Transform the input query**
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ‘‰ **è½¬æ¢è¾“å…¥æŸ¥è¯¢**
- en: If you donâ€™t express yourself clearly enough, the RAG might not find the relevant
    documents it needs to build a useful context. One way to solve that could be to
    **rephrase** the query by the LLM and try again.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¡¨è¾¾å¾—ä¸å¤Ÿæ¸…æ¥šï¼ŒRAGå¯èƒ½æ‰¾ä¸åˆ°å®ƒéœ€è¦çš„ç›¸å…³æ–‡æ¡£æ¥å»ºç«‹æœ‰ç”¨çš„ä¸Šä¸‹æ–‡ã€‚è§£å†³è¿™ä¸€é—®é¢˜çš„ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡LLM**é‡æ–°è¡¨è¿°**æŸ¥è¯¢ï¼Œç„¶åå†è¯•ä¸€æ¬¡ã€‚
- en: Another solution could be to try the [HyDE](https://boston.lti.cs.cmu.edu/luyug/HyDE/HyDE.pdf)
    method that takes the query, generates a hypothetical response, and uses both
    for retrieval in the embedding space.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ç§è§£å†³æ–¹æ¡ˆå¯èƒ½æ˜¯å°è¯•[HyDE](https://boston.lti.cs.cmu.edu/luyug/HyDE/HyDE.pdf)æ–¹æ³•ï¼Œå®ƒæ¥å—æŸ¥è¯¢ï¼Œç”Ÿæˆä¸€ä¸ªå‡è®¾æ€§å›åº”ï¼Œå¹¶åœ¨åµŒå…¥ç©ºé—´ä¸­ä½¿ç”¨è¿™ä¸¤è€…è¿›è¡Œæ£€ç´¢ã€‚
- en: Query transformation is an exciting area that could improve RAG systems since
    LLMs tend to work better over smaller queries.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥è¯¢è½¬æ¢æ˜¯ä¸€ä¸ªä»¤äººå…´å¥‹çš„é¢†åŸŸï¼Œå®ƒå¯èƒ½ä¼šæ”¹å–„RAGç³»ç»Ÿï¼Œå› ä¸ºLLMså¾€å¾€åœ¨è¾ƒå°çš„æŸ¥è¯¢ä¸Šè¡¨ç°æ›´å¥½ã€‚
- en: Conclusion
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Thatâ€™s it for today!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä»Šå¤©å°±åˆ°è¿™é‡Œï¼
- en: I hope youâ€™ve enjoyed this post and learned something useful about RAGs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œå¹¶ä»ä¸­å­¦åˆ°äº†æœ‰å…³RAGçš„ä¸€äº›æœ‰ç”¨ä¿¡æ¯ã€‚
- en: As this technology is relatively new, many optimization techniques will emerge
    making this framework more reliable and ready for industrialized applications.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè¿™é¡¹æŠ€æœ¯ç›¸å¯¹è¾ƒæ–°ï¼Œè®¸å¤šä¼˜åŒ–æŠ€æœ¯å°†ä¼šå‡ºç°ï¼Œä½¿è¿™ä¸ªæ¡†æ¶æ›´åŠ å¯é ï¼Œå¹¶å‡†å¤‡å¥½ç”¨äºå·¥ä¸šåŒ–åº”ç”¨ã€‚
- en: If you too are building RAGs, Iâ€™m curious to know which optimization techniques
    you use. Please let me know in the comments.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ ä¹Ÿåœ¨æ„å»ºRAGï¼Œæˆ‘å¾ˆå¥½å¥‡ä½ ä½¿ç”¨äº†å“ªäº›ä¼˜åŒ–æŠ€æœ¯ã€‚è¯·åœ¨è¯„è®ºä¸­å‘Šè¯‰æˆ‘ã€‚
- en: Until next time ğŸ‘‹!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹æ¬¡è§ğŸ‘‹ï¼
