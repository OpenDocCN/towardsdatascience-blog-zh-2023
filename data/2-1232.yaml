- en: How to Rewrite and Optimize Your SQL Queries to Pandas in 5 Simple Examples
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在 5 个简单示例中将 SQL 查询重写和优化为 Pandas
- en: 原文：[https://towardsdatascience.com/how-to-rewrite-and-optimize-your-sql-queries-to-pandas-in-5-simple-examples-6983cae8426e](https://towardsdatascience.com/how-to-rewrite-and-optimize-your-sql-queries-to-pandas-in-5-simple-examples-6983cae8426e)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-rewrite-and-optimize-your-sql-queries-to-pandas-in-5-simple-examples-6983cae8426e](https://towardsdatascience.com/how-to-rewrite-and-optimize-your-sql-queries-to-pandas-in-5-simple-examples-6983cae8426e)
- en: PROGRAMMING
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编程
- en: Transitioning from SQL to Pandas to improve your data analysis workflow
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 SQL 过渡到 Pandas 以改善你的数据分析工作流程
- en: '[](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)[![Byron
    Dolon](../Images/9ff32138c7b1913be24cc7ab971752b0.png)](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)
    [Byron Dolon](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)[![Byron
    Dolon](../Images/9ff32138c7b1913be24cc7ab971752b0.png)](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)
    [Byron Dolon](https://byrondolon.medium.com/?source=post_page-----6983cae8426e--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)
    ·9 min read·Jun 1, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6983cae8426e--------------------------------)
    ·9 分钟阅读·2023年6月1日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/802af72a42f8761f0a4ee55bcb3d5954.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/802af72a42f8761f0a4ee55bcb3d5954.png)'
- en: Image by Author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Data analysts, engineers, and scientists alike are familiar with SQL. The querying
    language is still widely used across the board for working with relational databases
    of any kind.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析师、工程师和科学家都熟悉 SQL。该查询语言仍广泛用于处理任何类型的关系数据库。
- en: However, more and more nowadays, especially for data analysts the technical
    requirements are going up and people are expected to at least know the basics
    of a programming language. When working with data, Python and Pandas specifically
    are a common addition to the list of requirements in a job description.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在越来越多的情况，尤其是对于数据分析师，技术要求在上升，人们预计至少要了解一种编程语言的基础知识。在处理数据时，Python 和 Pandas
    特别是常见的工作要求之一。
- en: While Pandas may be new to data people familiar with SQL, the concepts for selecting,
    filtering on, and aggregating data in SQL are easily transferable to Pandas. In
    this piece, let’s take a look at some common SQL queries and how you can write
    and optimize them in Pandas instead.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Pandas 对于熟悉 SQL 的数据人员来说可能是新的，但在 SQL 中选择、过滤和聚合数据的概念可以很容易地转移到 Pandas 中。在这篇文章中，让我们看看一些常见的
    SQL 查询以及如何在 Pandas 中编写和优化它们。
- en: Feel free to follow along in a notebook or IDE of your own. You can download
    the dataset from Kaggle [here](https://www.kaggle.com/datasets/deepanshuverma0154/sales-dataset-of-ecommerce-electronic-products?resource=download),
    available free for use under the CC0 1.0 Universal (CC0 1.0) Public Domain Dedication
    license.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 随意在你自己的笔记本或 IDE 中跟随操作。你可以从 Kaggle [这里](https://www.kaggle.com/datasets/deepanshuverma0154/sales-dataset-of-ecommerce-electronic-products?resource=download)
    下载数据集，该数据集在 CC0 1.0 Universal (CC0 1.0) 公共领域献身许可证下免费使用。
- en: Just import and run the following code and let’s get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 只需导入并运行以下代码，开始吧！
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Simple examples of SQL and their Pandas equivalents
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SQL 的简单示例及其 Pandas 等效方法
- en: Querying a whole table
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询整个表
- en: We can dive right into it by looking at the classic SELECT ALL from a table.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接开始，看看经典的 SELECT ALL from 一个表。
- en: 'Here’s the SQL:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '这是 SQL:'
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: And here’s the pandas
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Pandas 代码
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/b7ed16647269553597becebeb6b3a5a5.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b7ed16647269553597becebeb6b3a5a5.png)'
- en: Pandas code output — Image by author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 代码输出 — 作者提供的图片
- en: All you need to do is call the DataFrame in Pandas to return the whole table
    and all its columns.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做的就是调用 Pandas 中的 DataFrame 来返回整个表及其所有列。
- en: You may also want to just look at a small subset of your table as a quick check
    before writing a more complicated query. In SQL, you’d use `LIMIT 10` or something
    similar to get only a select number of rows. In Pandas, similarly, you can call
    `df.head(10)` or `df.tails(10)` to get the first or last 10 rows of the table.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还希望在编写更复杂的查询之前快速检查表中的一个小子集。在 SQL 中，你可以使用 `LIMIT 10` 或类似的方式仅获取选定数量的行。在 Pandas
    中，你可以调用 `df.head(10)` 或 `df.tail(10)` 来获取表的前 10 行或最后 10 行。
- en: Querying a table without null values
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询没有空值的表
- en: 'To add to our initial select query, in addition to just limiting the number
    of rows, you would put conditions to filter the table inside a WHERE clause in
    SQL. For example, if you’d want all rows in the table without any null values
    in the `Order_ID` column, the SQL would look like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要在最初的选择查询中添加条件，除了限制行数之外，你还可以在 SQL 的 WHERE 子句中放入过滤表的条件。例如，如果你想要所有 `Order_ID`
    列中没有任何空值的行，SQL 查询将如下所示：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In Pandas, you have two options:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pandas 中，你有两个选项：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/8e24f10217698d40c468436f73d038a3.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e24f10217698d40c468436f73d038a3.png)'
- en: Pandas code output — Image by author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 代码输出 — 作者提供的图片
- en: Now, the table we get back doesn’t have any null values from the `Order_ID`
    column (which you can compare to the first output above). Both options will return
    a table without the null values, but they work slightly differently.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们得到的表没有 `Order_ID` 列中的任何空值（你可以与上面的第一个输出进行比较）。这两种方法都会返回没有空值的表，但它们的工作方式略有不同。
- en: You can use the native `dropna` method in Pandas to return the DataFrame without
    any null rows, specifying in the `subset` parameter which columns you’d like to
    drop nulls from.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 Pandas 中的 `dropna` 方法返回没有任何空行的 DataFrame，指定 `subset` 参数中要从中删除空值的列。
- en: Alternatively, the `loc` method lets you pass a mask or boolean label you can
    specify to filter the DataFrame. Here, we pass `df["Order_ID"].notna()`, which
    if you would call it on its own would return a Series of True and False values
    that can map to the original DataFrame rows for whether the `Order_ID` is null.
    When we pass it to the `loc` method, it instead returns the DataFrame where `df["Order_ID"].notna()`
    evaluates to True (so all rows where the `Order_ID` column isn’t null.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，`loc` 方法允许你传递一个掩码或布尔标签来过滤 DataFrame。在这里，我们传递 `df["Order_ID"].notna()`，如果你单独调用它，将返回一个
    True 和 False 值的系列，这些值可以映射到原始 DataFrame 行，以确定 `Order_ID` 是否为空。当我们将它传递给 `loc` 方法时，它会返回
    `df["Order_ID"].notna()` 评估为 True 的 DataFrame（即所有 `Order_ID` 列不是空的行）。
- en: Querying specific columns from a table
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询表中的特定列
- en: 'Next, instead of selecting all columns from the table, let’s instead select
    just a few specific columns. In SQL, you’d write the column names in the SELECT
    part of the query like this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将选择表中的几个特定列，而不是选择所有列。在 SQL 中，你可以在查询的 SELECT 部分中写入列名，如下所示：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In Pandas, we’d write the code like this:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pandas 中，我们将代码写成这样：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/102a928216a9a5b874dda7b8030104cc.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/102a928216a9a5b874dda7b8030104cc.png)'
- en: Pandas code output — Image by author
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 代码输出 — 作者提供的图片
- en: 'To select a specific subset of columns, you can pass a list of the column names
    into the DataFrame in Pandas. You can also define the list separately like this
    for clarity:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择特定的列子集，你可以将列名列表传递给 Pandas 中的 DataFrame。你也可以像这样单独定义列表以便清晰：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Assigning a list of target columns that you can then pass into a DataFrame can
    make working with a table over time when you need to make changes in your code
    a little easier. For example, you could have a function return the columns you
    need as a list, or append and remove columns to the list as needed depending on
    what kind of output the user needs.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 分配一个目标列列表，然后将其传递到 DataFrame 中，可以使在需要对代码进行更改时处理表变得更加容易。例如，你可以让一个函数返回你需要的列作为列表，或者根据用户需要的输出来追加和删除列表中的列。
- en: The GROUP BY in SQL and Pandas
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SQL 和 Pandas 中的 GROUP BY
- en: 'We can now move on to aggregating data. In SQL, we do this by passing a column
    to the SELECT and GROUP BY clauses that we want to group on and then adding the
    column to an aggregate measure like COUNT in the SELECT clause as well. As an
    example, doing so will let us group all the individual `Order_ID` rows in the
    original table for each `Product` and count how many there are. The query can
    look like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始聚合数据。在 SQL 中，我们通过将要分组的列传递给 SELECT 和 GROUP BY 子句来实现这一点，然后在 SELECT 子句中将该列添加到像
    COUNT 这样的聚合度量中。例如，这样做将允许我们对原始表中每个 `Product` 的所有单独的 `Order_ID` 行进行分组，并计算它们的数量。查询可能如下所示：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In Pandas, it would look like this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pandas中，它会像这样显示：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/241f0b75bb7b93365d2e4f48e1e62239.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/241f0b75bb7b93365d2e4f48e1e62239.png)'
- en: Pandas code output — Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas代码输出 — 图片由作者提供
- en: 'The output is a Pandas Series where the table is grouped the products and there’s
    a count of all the `Order_ID` for each product. In addition to our previous query
    in Pandas where we included a filter, we now do three things:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个Pandas Series，其中表格按产品进行分组，并显示每个产品的`Order_ID`计数。除了我们之前在Pandas中包含过滤条件的查询外，我们现在要做三件事：
- en: Add `groupby` and pass a column (or list of columns) that you want to group
    the DataFrame on;
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`groupby`并传递你想要对DataFrame进行分组的列（或列列表）；
- en: Pass the name of the column in square brackets on the raw grouped DataFrame;
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在原始分组的DataFrame上用方括号传递列名；
- en: Call the `count` (or any other aggregate) method to perform the aggregation
    on the DataFrame for the target column.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用`count`（或任何其他聚合）方法对DataFrame中的目标列进行聚合。
- en: For better readability, we can assign the condition to a variable (this will
    come in handy later) and format the query so it’s easier to read.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地阅读，我们可以将条件赋值给一个变量（这在后面会派上用场），并格式化查询，使其更易读。
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: A complete SQL query translated and efficiently written in Pandas
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个完整的SQL查询在Pandas中翻译并高效编写
- en: Now that we have most of the components of a complete SQL query, let’s take
    a look at a more complicated one and see what it would look like in Pandas.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经具备了完整SQL查询的大部分组件，让我们看看一个更复杂的查询在Pandas中的样子。
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here, we add a little to our previous query by including multiple filter conditions
    as well as an ORDER BY so that the table returned in our query is sorted by the
    measure we’re aggregating on. Since there are a few more components to this query,
    let’s take a look step by step at how we’d implement this in Pandas.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在之前的查询中添加了一些内容，包括多个过滤条件以及ORDER BY，以便查询返回的表按照我们正在聚合的度量进行排序。由于查询中有更多组件，让我们逐步看看如何在Pandas中实现这个查询。
- en: First, instead of passing multiple conditions when we call the `loc` method,
    let’s instead define a list of conditions and assign them to a variable `FILTER_CONDITIONS`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们不直接在调用`loc`方法时传递多个条件，而是定义一个条件列表，并将其赋值给变量`FILTER_CONDITIONS`。
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As before, a condition passed into `loc` should be a Pandas mask that evaluates
    to either true or false. It’s possible to pass multiple conditions to `loc`, but
    the syntax should look like this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如之前所述，传递给`loc`的条件应该是一个Pandas掩码，其结果为真或假。可以将多个条件传递给`loc`，但语法应如下所示：
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'However, just passing a list of conditions like this won’t work:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，像这样直接传递条件列表是不可行的：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You’ll get an error if you try the above because each condition should be separated
    by the `&` operator for “and” conditions (or the `|` operator if you need “or”
    conditions). Instead, we can write some quick code to return the conditions in
    the correct format. We’ll make use of the `functools.reduce` method to put the
    conditions together.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试上述操作会出现错误，因为每个条件应通过`&`操作符（用于“且”条件）或`|`操作符（用于“或”条件）分隔。相反，我们可以编写一些快速代码来以正确的格式返回条件。我们将使用`functools.reduce`方法将条件组合在一起。
- en: 'If you want to see what it looks like in a notebook and see what it looks like
    to combine some strings using the `reduce` function, try this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在笔记本中查看它的样子，并查看使用`reduce`函数组合字符串的效果，可以尝试这个：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This outputs the string like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出如下字符串：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Going back to our actual Pandas conditions, we can write this instead (without
    the string formatting and just using our defined list of conditions in the `FILTER_CONDITIONS`
    variable).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们实际的Pandas条件，我们可以改写为（不使用字符串格式化，仅使用我们在`FILTER_CONDITIONS`变量中定义的条件列表）。
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'What `reduce` does is apply a function cumulatively to the elements present
    in an iterable, or in our case run the `lambda` function over the items in our
    `FILTER_CONDITIONS` list which combines each of them with the `&` operator. This
    runs until there are no conditions left, or in this case, for all three conditions
    it would effectively return:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`reduce`的作用是将一个函数累积地应用于一个可迭代对象中的元素，或者在我们的例子中，对`FILTER_CONDITIONS`列表中的每一项运行`lambda`函数，并用`&`操作符将它们组合起来。这会一直运行，直到没有条件剩下，或者在这种情况下，对于所有三个条件，它将有效地返回：'
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, let’s add the list of conditions to create a final group by query
    in Pandas:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们将条件列表添加到Pandas中以创建最终的分组查询：
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You’ll notice two additional differences from the previous query:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到与之前的查询有两个额外的区别：
- en: Instead of specifying the specific column to count on, we can simply call the
    `size` method which will return the number of rows in the DataFrame (as before
    where every `Order_ID` value was unique and meant to represent one row when we
    counted on it);
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与其指定要计数的特定列，我们可以简单地调用 `size` 方法，它会返回 DataFrame 中的行数（就像之前每个 `Order_ID` 值都是唯一的，并且意味着我们计数时的每一行一样）；
- en: There are a few different ways to do the ORDER BY in Pandas- one way is to simply
    call `sort_values` and pass `ascending=False` to sort on descending order.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Pandas 中有几种不同的方法来进行排序，其中一种方法是简单地调用 `sort_values` 并传递 `ascending=False` 以按降序排序。
- en: 'If you wanted to use the previous syntax for aggregating the data it would
    look like this:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用之前的语法来聚合数据，它将如下所示：
- en: '[PRE20]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](../Images/60a5fc51f777d90503c1a3fcde57f3a7.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/60a5fc51f777d90503c1a3fcde57f3a7.png)'
- en: Pandas code output — Image by author
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 代码输出 — 图片由作者提供
- en: The output of both methods will be the same as before, which is a Series with
    the column you’re grouping on and the counts for each product.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法的输出将与之前相同，即一个 Series，其中包含你分组的列和每个产品的计数。
- en: If instead, you wanted to output a DataFrame, you can call the `reset_index`
    method on the series to get the original column names back for which column you
    grouped on and the column you’re aggregating on (in this case we grouped on “Product”
    and are counting the “Order_ID”.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要输出 DataFrame，可以在系列上调用 `reset_index` 方法，以获取你分组的列和你聚合的列的原始列名（在这种情况下，我们按“Product”分组，并计数“Order_ID”）。
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/2424825fd9300c03675c23d2ab7faad7.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2424825fd9300c03675c23d2ab7faad7.png)'
- en: Pandas code output — Image by author
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 代码输出 — 图片由作者提供
- en: 'And there we have it! All the components of a full SQL query but finally written
    in Pandas. Some of the things we can do further to optimize this process for working
    with data over time include:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！所有完整 SQL 查询的组件，但最终用 Pandas 编写。为了进一步优化处理数据的过程，我们可以做以下一些事情：
- en: Putting the different lists of columns to SELECT or GROUP BY to their own variables
    or functions (so you or a user can modify them over time);
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将不同的列列表（用于 SELECT 或 GROUP BY）放入它们自己的变量或函数中（这样你或用户可以随着时间的推移修改它们）；
- en: Move the logic to combine the list of columns for a filter condition to its
    own function so the end user doesn’t need to be confused over what the `reduce`
    logic is doing;
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将合并列列表的逻辑移到自己的函数中，以便最终用户不会对 `reduce` 逻辑感到困惑；
- en: After passing `reset_index` we can rename the output column (or columns if we’re
    aggregating on multiple) for clarity, for example to “Count_Order_ID”.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用 `reset_index` 之后，我们可以重命名输出列（如果我们在多个列上聚合，则重命名多个列），以便更清晰，例如命名为“Count_Order_ID”。
- en: Thanks for taking the time to read this piece! If you haven’t already, hit the
    follow button to stay up to date with more tech pieces by me. Also, if you enjoy
    my content I’d love it if you **sign up for Medium using my referral link below.**
    This’ll let me get a portion of your monthly subscription AND you’ll get access
    to some exclusive features only available to Medium members.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢你花时间阅读这篇文章！如果你还没有，请点击关注按钮，以便及时了解我更多的技术文章。此外，如果你喜欢我的内容，我会很高兴如果你**通过下面的推荐链接注册
    Medium**。这样我可以获得你月订阅的一部分，而且你将可以访问一些只有 Medium 会员才能使用的独家功能。
- en: '[](https://byrondolon.medium.com/membership?source=post_page-----6983cae8426e--------------------------------)
    [## Join Medium with my referral link — Byron Dolon'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://byrondolon.medium.com/membership?source=post_page-----6983cae8426e--------------------------------)
    [## 通过我的推荐链接加入 Medium — Byron Dolon'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为 Medium 会员，你的会员费的一部分将分配给你阅读的作者，你可以访问每一个故事…
- en: byrondolon.medium.com](https://byrondolon.medium.com/membership?source=post_page-----6983cae8426e--------------------------------)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: byrondolon.medium.com](https://byrondolon.medium.com/membership?source=post_page-----6983cae8426e--------------------------------)
- en: M**ore by me:** *-* [*5 Practical Tips for Aspiring Data Analysts*](https://byrondolon.medium.com/5-practical-tips-for-aspiring-data-analysts-9917006d4dae?sk=019edbddaca4d313665caafe4b747d26)
    *-* [*Mastering Ecommerce Data Analysis*](https://python.plainenglish.io/mastering-analysis-for-e-commerce-with-pandas-e4219a87b10c?sk=9aa8fd1024b89e89e4b0904c8d00d242)
    *-* [*Check for a Substring in a Pandas DataFrame*](/check-for-a-substring-in-a-pandas-dataframe-column-4b949f64852?sk=bfb5bbab11ae45c47bfb316d931c3b56)
    *-* [*7 Best Repositories on Github to Learn Python*](https://medium.com/towards-data-science/top-7-repositories-on-github-to-learn-python-44a3a7accb44)
    *-* [*5 (and a half) Lines of Code for Understanding Your Data with Pandas*](/5-and-a-half-lines-of-code-for-understanding-your-data-with-pandas-aedd3bec4c89?sk=7007a1ae248cf7ea4ef5fcd4af7ae72b)
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**更多来自我：** *-* [*5 个实用技巧助你成为数据分析师*](https://byrondolon.medium.com/5-practical-tips-for-aspiring-data-analysts-9917006d4dae?sk=019edbddaca4d313665caafe4b747d26)
    *-* [*掌握电子商务数据分析*](https://python.plainenglish.io/mastering-analysis-for-e-commerce-with-pandas-e4219a87b10c?sk=9aa8fd1024b89e89e4b0904c8d00d242)
    *-* [*在 Pandas DataFrame 中检查子字符串*](/check-for-a-substring-in-a-pandas-dataframe-column-4b949f64852?sk=bfb5bbab11ae45c47bfb316d931c3b56)
    *-* [*学习 Python 的 7 个最佳 GitHub 仓库*](https://medium.com/towards-data-science/top-7-repositories-on-github-to-learn-python-44a3a7accb44)
    *-* [*5（又半）行代码助你理解 Pandas 数据*](/5-and-a-half-lines-of-code-for-understanding-your-data-with-pandas-aedd3bec4c89?sk=7007a1ae248cf7ea4ef5fcd4af7ae72b)'
