- en: 'The Dreaded Antagonist: Data Leakage in Machine Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 恐怖的对手：机器学习中的数据泄漏
- en: 原文：[https://towardsdatascience.com/the-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc?source=collection_archive---------6-----------------------#2023-05-19](https://towardsdatascience.com/the-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc?source=collection_archive---------6-----------------------#2023-05-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc?source=collection_archive---------6-----------------------#2023-05-19](https://towardsdatascience.com/the-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc?source=collection_archive---------6-----------------------#2023-05-19)
- en: Probably one of the most underappreciated concepts in Machine Learning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可能是机器学习中最被低估的概念之一
- en: '[](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)[![Andreas
    Lukita](../Images/8660ca1fea5da34ce3475281c1f52152.png)](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)
    [Andreas Lukita](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)[![Andreas
    Lukita](../Images/8660ca1fea5da34ce3475281c1f52152.png)](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)
    [Andreas Lukita](https://medium.com/@andreas030503?source=post_page-----5f08679852cc--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F955ef38ea7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&user=Andreas+Lukita&userId=955ef38ea7b&source=post_page-955ef38ea7b----5f08679852cc---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)
    ·13 min read·May 19, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f08679852cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&user=Andreas+Lukita&userId=955ef38ea7b&source=-----5f08679852cc---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F955ef38ea7b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&user=Andreas+Lukita&userId=955ef38ea7b&source=post_page-955ef38ea7b----5f08679852cc---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5f08679852cc--------------------------------)
    · 13分钟阅读 · 2023年5月19日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f08679852cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&user=Andreas+Lukita&userId=955ef38ea7b&source=-----5f08679852cc---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f08679852cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&source=-----5f08679852cc---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f08679852cc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc&source=-----5f08679852cc---------------------bookmark_footer-----------)'
- en: I have attended more than 5 Business Analytics and Machine Learning courses,
    both in-person and online. Surprisingly, only one has scratched the surface of
    data leakage, briefly.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我参加了超过5门商务分析和机器学习课程，包括面对面课程和在线课程。令人惊讶的是，只有一门课程稍微触及了数据泄漏的话题。
- en: '![](../Images/27869387f3796925a3534d992a08e29b.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27869387f3796925a3534d992a08e29b.png)'
- en: Photo by [Luis Tosta](https://unsplash.com/@luis_tosta?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Luis Tosta](https://unsplash.com/@luis_tosta?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: When talking about data leakage without the context of machine learning, oftentimes
    we refer to it as the scenario when confidential information is transferred to
    a third party without proper security measures or permission, leading to a breach
    of privacy and security[¹](#21ca).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论数据泄漏时，在没有机器学习背景的情况下，我们通常指的是机密信息在没有适当安全措施或许可的情况下转移到第三方，导致隐私和安全的泄露[¹](#21ca)。
- en: 'While the concept is somewhat similar, this is not quite the explanation in
    the context of machine learning. Here’s what it means in the world of machine
    learning:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个概念有些类似，但在机器学习的背景下并不完全是这样。这在机器学习领域的含义是：
- en: Data leakage occurs when information from the test dataset is mistakenly included
    in the training dataset.[²](#0b31)
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据泄漏发生在测试数据集的信息错误地被包含在训练数据集中。[²](#0b31)
- en: '**The result?** Unrealistically good performance metrics during training, but
    poor performance when the model is actually put to use.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**结果是什么？** 训练过程中性能指标表现得不切实际地好，但当模型真正投入使用时表现很差。'
- en: '**In simpler terms,** the model memorized information that it should not have
    access to, leading to artificially inflated performance metrics during training.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**简单来说，** 模型记住了它不该访问的信息，导致训练过程中性能指标被人为地夸大。'
- en: '**Still can’t wrap your head around it?** Well, picture this. You are studying
    for your upcoming math exam. You do lots of practice questions to get better each
    day. Then, you find out that the exam questions have been accidentally leaked
    online. You have access to this critical information and decide to practice on
    this paper (You train yourself on this dataset that is not supposed to be known
    before the exam, and thus, you “memorize” the pattern of the question). The result?
    You become overly familiar with the test question and you get unrealistically
    good performance metrics for that piece of paper, but when you are actually put
    to use in the real world… (let’s not touch on that).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**还是无法理解？** 好吧，想象一下。你正在为即将到来的数学考试复习。你做了很多练习题以便每天进步。然后，你发现考试题目不小心泄露到了网上。你获得了这些关键信息，并决定在这张试卷上练习（你在这个考试前不应知道的数据集上训练自己，因此，你“记住”了题目模式）。结果？你对这张试卷变得过于熟悉，表现指标异常优秀，但当你真的投入到实际情况中时……（我们还是不提了）。'
- en: '**Table of Contents**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**目录**'
- en: Types of Data Leakage in Machine Learning ([**Target Leakage**](#9db8), [**Train-Test
    Contamination, Leakage during Data Preprocessing**](#501a))
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中的数据泄漏类型（[**目标泄漏**](#9db8)，[**训练-测试污染，数据预处理中的泄漏**](#501a)）
- en: '[**Consequences of Data Leakage in Machine Learning**](#91a0)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**机器学习中数据泄漏的后果**](#91a0)'
- en: Preventing Data Leakage in Machine Learning ([**Manual Review**](#29c5), **Data
    cleaning and preprocessing**, [**Using pipeline**](#fde0), [**Proper validation
    techniques**](#7dbc))
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预防机器学习中的数据泄漏（[**手动审查**](#29c5)，**数据清理和预处理**，[**使用管道**](#fde0)，[**适当的验证技术**](#7dbc)）
- en: '[**Real-world Dataset Examples: The Titanic Dataset**](#7912)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**现实世界数据集示例：泰坦尼克号数据集**](#7912)'
- en: '[**Data Leakage 1st illustration: Including target survived as feature**](#35b6)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据泄漏第一种示例：将目标存活作为特征包含**](#35b6)'
- en: '[**Data Leakage 2nd illustration: Mixing up records of training and testing
    data**](#b38e)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据泄漏第二种示例：混淆训练和测试数据的记录**](#b38e)'
- en: '[**Data Leakage 3rd illustration: Wrong data preprocessing steps**](#c37d)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据泄漏第三种示例：错误的数据预处理步骤**](#c37d)'
- en: '[**Data Leakage 4th illustration: Including the feature cabin as part of the
    feature in the model**](#eb28)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据泄漏第四种示例：将特征舱位包含为模型中的一部分**](#eb28)'
- en: Target Leakage
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标泄漏
- en: 'As for **Target Leakage**, it might not be so easy and straightforward to recognize.
    Picture this: you are building a model to predict whether your customers will
    cancel their monthly subscriptions to your service (i.e., churn out). At first
    glance, including the **“number of customer service calls”** made by the customeras
    a feature in our model does not seem problematic at all, as you may reason out
    that more customer service calls are linked to a higher probability of churning
    out.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 关于**目标泄漏**，识别可能不会那么简单明了。想象一下：你正在构建一个模型来预测客户是否会取消他们的月度订阅服务（即流失）。乍一看，将**“客户服务电话的数量”**作为特征包含在模型中似乎并没有问题，因为你可能认为更多的客户服务电话与更高的流失概率相关。
- en: However, upon closer inspection, it is found that the **“number of customer
    service calls“** is the result of customers churning out, instead of a contributing
    feature. Customers who have already decided to churn out merely call to settle
    any outstanding issues before eventually canceling their subscriptions. Hence,
    this information would not be available to us at the time of predicting whether
    a customer would churn out (In other words, we only know this information for
    customers that have already decided to churn out).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，经过仔细检查发现，**“客户服务电话数量”** 是客户流失的结果，而不是一个贡献特征。已经决定流失的客户只是打电话解决未结清的问题，然后最终取消订阅。因此，在预测客户是否会流失时，这些信息是不可用的（换句话说，我们只知道已经决定流失的客户的信息）。
- en: '**Including Target Variable as part of Feature Variables, or any proxy that
    is directly or indirectly derived from the Target Variable, could lead to data
    leakage.**'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**将目标变量作为特征变量的一部分，或任何直接或间接从目标变量派生的代理变量，可能导致数据泄漏。**'
- en: Train-Test Contamination and Leakage during Data Preprocessing
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练-测试污染和数据预处理中的泄漏
- en: These situations refer to the case when the same preprocessing steps are applied
    to both train and test datasets. For instance, when we do data preprocessing steps
    such as feature scaling, estimating missing values, and removing outliers, we
    should ensure that we do not **“learn”** from the test dataset as shown below[³](#f24a).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些情况指的是对训练集和测试集应用相同的预处理步骤。例如，当我们进行特征缩放、估计缺失值和去除异常值等数据预处理步骤时，我们应该确保不会像下面所示的那样从测试数据集中“学习”[³](#f24a)。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, we separate our dataset into training and testing early before the preprocessing
    steps such that we are able to **fit** only the training dataset. Note that we
    **should not** **fit** on the entire dataset (both train and test) as this would
    result in data leakage (our model learns what it is not supposed to learn, in
    other words, this information about the testing dataset is not known at the time
    of prediction).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在预处理步骤之前将数据集分成训练集和测试集，以便我们只能**拟合**训练数据集。请注意，我们**不应该**在整个数据集（包括训练集和测试集）上**拟合**，因为这会导致数据泄漏（我们的模型学会了它不应该学习的东西，换句话说，在预测时对测试数据集的信息是不知道的）。
- en: '**Fit on training data, transform on both training and testing data.**'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**在训练数据上拟合，在训练和测试数据上转换。**'
- en: Consequences of Data Leakage in Machine Learning
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中数据泄漏的后果
- en: The consequences of not detecting the presence of data leakage in a machine-learning
    project are immense — they give false hope. Ever experience when your training
    performance is ridiculously high whereas your testing dataset performs very poorly?
    Data leakage might be the culprit. The keywords here are overfitting and the inability
    to generalize. This is because the model has learned to memorize noise and irrelevant
    information, resulting in poor performance when faced with a real test dataset[²](#0b31).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习项目中未能检测到数据泄漏的后果是巨大的——它们带来了虚假的希望。有没有遇到过训练性能极高而测试数据集表现非常差的情况？数据泄漏可能是罪魁祸首。这里的关键字是过拟合和无法泛化。这是因为模型学会了记忆噪声和无关信息，导致在面对真实测试数据集时表现不佳[²](#0b31)。
- en: The eventual outcome?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果？
- en: '**You make an inaccurate model evaluation and unreliable predictions. What
    a waste of resources!**'
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**你会做出不准确的模型评估和不可靠的预测。真是资源浪费！**'
- en: 'Preventing Data Leakage: Manual Review'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 防止数据泄漏：手动审查
- en: Yes, we all get it. Manual review is inefficient and can be very time-consuming.
    However, putting in the time to study the relationship between features and target
    variable is perhaps the most consistent way to detect data leakage, and hence,
    be very well worth it. When a feature has a very high correlation with the target,
    for example, we should be skeptical to investigate the relationship further. Sometimes,
    doing Exploratory Data Analysis (EDA) might help with uncovering the correlation
    between features and targets. Moreover, having a well-rounded domain knowledge
    and expertise can help to determine whether or not a feature should or should
    not be included in the model. Remember, when in doubt, always ask yourself this
    guiding question
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我们都明白。手动审核效率低下且非常耗时。然而，花时间研究特征与目标变量之间的关系，也许是检测数据泄漏最一致的方式，因此，非常值得。当一个特征与目标变量的相关性非常高时，我们应该怀疑并进一步调查这种关系。有时，进行探索性数据分析（EDA）可能有助于揭示特征与目标之间的相关性。此外，全面的领域知识和专业技能可以帮助确定一个特征是否应该包含在模型中。记住，当有疑问时，总是要问自己这个指导性问题。
- en: '**“Does this feature contain information that would not be available at the
    time of prediction?”**'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**“这个特征是否包含在预测时不可用的信息？”**'
- en: If the answer to the above question is a “yes”, then including that feature
    could result in data leakage.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果上述问题的答案是“是”，那么包括该特征可能会导致数据泄漏。
- en: 'Preventing Data Leakage: Pipeline is King'
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 防止数据泄漏：管道是王道
- en: None of the Business Analytics and Machine Learning courses that I attended
    before has any mention of building a Machine Learning Preprocessing Pipeline.
    The most common practice is to write spaghetti code all around the place without
    any standardization of workflow. While this may be familiar to many people, it
    is simply not the best practice — one reason being the possibility of introducing
    data leakage into the model. The first time I was exposed to the idea of leveraging
    a pipeline came from the book *Data Cleaning and Exploration with Machine Learning*[⁴](#0654).
    The way of writing the code by embedding each preprocessing step as variable arguments
    into the `make_pipeline` method and separating the steps for numerical, categorical,
    and binary variables respectively are some key lessons I picked up from the book.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前参加的商业分析和机器学习课程中，没有提到构建机器学习预处理管道。最常见的做法是编写到处都是的“意大利面条”代码，而没有任何工作流程标准化。虽然这对很多人来说可能很熟悉，但这并不是最佳实践——其中一个原因是可能会将数据泄漏引入模型。我第一次接触到利用管道的想法是来自于书籍*Data
    Cleaning and Exploration with Machine Learning*[⁴](#0654)。从这本书中，我学到的关键经验包括通过将每个预处理步骤作为变量参数嵌入到`make_pipeline`方法中，并分别为数值型、分类变量和二进制变量分开处理。
- en: Simply put, a pipeline is a set of linear sequences of data preprocessing steps,
    executed one after another. Pipelines offer a clear and orderly chaining process
    for automating a machine learning project’s workflow. We can leverage the scikit-learn
    Pipeline class[⁵](#60b9), which takes a list of tuples as input, where each tuple
    represents a single step in the pipeline. The first element of each tuple is a
    string that represents the name of the step, and the second element is an instance
    of a scikit-learn transformer or estimator object. Of course, there is an alternative
    shorthand to this, which is `**make_pipeline**` which does not require us to name
    the estimators (We are all lazy creatures). Remember, the estimators need to have
    both `**fit**` and `**transform**` method.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，管道是一系列线性的数据预处理步骤，依次执行。管道提供了一个清晰有序的链式过程，用于自动化机器学习项目的工作流程。我们可以利用 scikit-learn
    的 Pipeline 类[⁵](#60b9)，它接受一个元组列表作为输入，每个元组代表管道中的一个步骤。每个元组的第一个元素是表示步骤名称的字符串，第二个元素是
    scikit-learn 转换器或估计器对象的实例。当然，还有一个简化的方法，就是`**make_pipeline**`，它不要求我们命名估计器（我们都是懒惰的生物）。记住，估计器需要具有`**fit**`和`**transform**`方法。
- en: '**Why bother with Pipeline?**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么要使用 Pipeline？**'
- en: '**Pipeline handles all the data processing processes automatically. It also
    makes sure that each step is only fitted on the training data, which prevents
    data leakage and guarantees that the stages are carried out in the proper order.**'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**管道自动处理所有数据处理过程。它还确保每个步骤仅在训练数据上进行拟合，从而防止数据泄漏，并确保各阶段按正确顺序进行。**'
- en: 'Here’s an example: we want to do data preprocessing for different data types
    in our dataset, namely numerical, categorical, and binary features, each with
    different steps. We can leverage on `**make_pipeline**` to lay out the process
    in an orderly manner, and let the Pipeline takes care of all the jobs behind the
    scene. This would return a `**Pipeline**` object which has several attributes
    and methods we can call. For example, we could call `**fit**(X_train, y_train)`
    and `**score**(X_test, y_test)` to fit and evaluate the model respectively.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个示例：我们需要对数据集中不同类型的数据进行数据预处理，即数值型、分类型和二元特征，每种特征都有不同的步骤。我们可以利用`**make_pipeline**`将过程按顺序安排，让Pipeline处理所有后台工作。这将返回一个`**Pipeline**`对象，该对象具有多个属性和方法可供调用。例如，我们可以调用`**fit**(X_train,
    y_train)`和`**score**(X_test, y_test)`来分别拟合和评估模型。
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Preventing Data Leakage: Cross-Validation'
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 防止数据泄漏：交叉验证
- en: This section is inspired by the book *Data Cleaning and Exploration with Machine
    Learning*[⁴](#0654). Another thing I picked up from the book is marrying the concept
    of Pipeline and Cross-Validation. Yes, they are not exclusive! The selection of
    train and test datasets is very critical and could lead to data leakage if not
    done correctly. When we do not perform cross-validation to evaluate our model,
    we run the risk of overfitting the training data and getting poor performance
    on new, unseen data. It could be by chance that the once-off train test split
    that we performed resulted in our model learning a specific feature exclusive
    to that split, which might not be generalizable.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 本节内容受到《*数据清洗与机器学习探索*》[⁴](#0654)一书的启发。我从书中获得的另一个观点是将Pipeline和交叉验证的概念结合起来。是的，它们并不是互相排斥的！训练和测试数据集的选择非常关键，如果做得不对可能会导致数据泄漏。当我们不执行交叉验证来评估模型时，我们面临着对训练数据过拟合以及在新的、未见过的数据上表现不佳的风险。我们进行的一次性训练测试拆分可能使模型学习到某个特定特征，这个特征可能对该拆分是独有的，而不具有普遍性。
- en: '**Why bother with Cross-Validation?**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么要进行交叉验证？**'
- en: '**Cross-validation allows us to obtain a more precise prediction of how well
    our model will perform on brand-new, untested data. By using cross-validation,
    we can test the effectiveness of our model on more than one subset of the data.**'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**交叉验证使我们能够更精确地预测模型在全新、未测试数据上的表现。通过使用交叉验证，我们可以在多个数据子集上测试模型的有效性。**'
- en: We can leverage **scikit-learn** K-fold CV to achieve this.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用**scikit-learn**的K折交叉验证来实现这一点。
- en: How does K-fold CV work in short? The data is first divided into **k** equal-sized
    folds, after which the model is trained on **k-1** folds before being tested on
    the last fold. Each fold serves as the testing set once during the course of this
    operation, which is repeated k times. At the end of the iteration, an estimate
    of the model’s performance is generated by averaging the outcomes of the k iterations.
    When k is set to 1, this means we are falling back to the usual train test split.
    We train our model on the entire dataset and test it on a separate dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: K折交叉验证的工作原理是什么？数据首先被分成**k**个大小相等的折叠，然后在**k-1**个折叠上训练模型，再在最后一个折叠上测试模型。在这个过程中，每个折叠都作为一次测试集，这个过程重复进行k次。在迭代结束时，通过对k次迭代结果的平均来估算模型的性能。当k设置为1时，这意味着我们回退到通常的训练测试拆分。我们在整个数据集上训练模型，并在一个独立的数据集上进行测试。
- en: The good news is, we can pick up from where we left off in the Pipeline.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，我们可以从Pipeline中未完成的地方继续进行。
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Real-World Dataset Example: The Titanic Dataset'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真实世界数据集示例：泰坦尼克号数据集
- en: Titanic. Classic. The Titanic dataset is a classic machine learning problem,
    where we’re given a set of features for each passenger, such as their age, gender,
    ticket class, place of embarkation, and whether they had family members on board[⁶](#d470).
    Using these features, the goal is to train a machine-learning model to predict
    whether a passenger `**survived**` or not. Here is a short and quick version of
    the prediction without delving into hyperparameter tuning and feature selection.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 泰坦尼克号。经典。泰坦尼克号数据集是经典的机器学习问题，我们为每个乘客提供了一组特征，例如他们的年龄、性别、票务等级、登船地点，以及他们是否有家人在船上[⁶](#d470)。使用这些特征，目标是训练一个机器学习模型来预测乘客是否`**幸存**`。以下是一个简短的预测版本，未涉及超参数调整和特征选择。
- en: '***Using the following code to clean up the raw dataset.***'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '***使用以下代码清理原始数据集。***'
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let me explain the idea behind the preprocessing steps I have implemented:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我解释一下我所实现的数据预处理步骤的理念：
- en: Impute the missing data from `Embarked` column with the most frequent entries
    using `SimpleImputer` class from scikit-learn.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 的 `SimpleImputer` 类用最频繁的条目填补 `Embarked` 列中的缺失数据。
- en: Impute the missing data from `Age` column with a list of mean values based on
    the conditions of whether the person has family members onboard. (i.e. if the
    person has no family member onboard, then we impute the mean that is calculated
    based on the other passengers who also have no family members onboard)
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用基于乘客是否有家人随行的条件的均值列表来填补 `Age` 列中的缺失数据。（即，如果乘客没有家人随行，则我们用其他没有家人随行的乘客的均值进行填补）
- en: Engineered a feature `IsAlone` to denote whether the passenger has any family
    members onboard
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个特征 `IsAlone` 用于表示乘客是否有家人随行
- en: Engineered a feature `Title` to denote the title of the passenger
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个特征 `Title` 用于表示乘客的头衔
- en: Engineered a feature `AgeGroup` to categorize 5 different age group generations.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个特征 `AgeGroup` 用于将乘客划分为5个不同的年龄组。
- en: '**Data Leakage 1st illustration: Including target** `**survived**` **as feature**'
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据泄漏第1种示例：将目标** `**survived**` **作为特征**'
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As you might have expected, including the target variable `survived` as a feature
    effectively make our model useless as it now has an accuracy of 100.0% on the
    validation data. There is no point in doing any prediction. This mistake is easy
    to spot and less common.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能预期的那样，将目标变量 `survived` 作为特征有效地使我们的模型变得毫无用处，因为它在验证数据上的准确率现在是100.0%。进行预测没有意义。这种错误很容易发现，但不常见。
- en: 'Data Leakage 2nd illustration: Mixing up records of training and testing data'
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据泄漏第2种示例：混淆训练数据和测试数据的记录
- en: If testing data is accidentally included in the training set, the model may
    be trained on this leaked information and thus perform unrealistically well on
    the test set. The following is an ***intentionally made-up example*** of including
    part of the test set into the training set.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果测试数据被意外地包含在训练集中，模型可能会在这些泄漏的信息上进行训练，从而在测试集上表现得不切实际。以下是一个***故意编造的例子***，展示了如何将部分测试集包含到训练集中。
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Data Leakage 3rd illustration: Wrong data preprocessing steps'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据泄漏第3种示例：错误的数据预处理步骤
- en: Here, we are supposed to separate the dataset into training and testing dataset
    before the preprocessing steps. If we do the preprocessing steps before splitting
    the dataset, we might accidentally learn from the testing dataset, leading to
    overly inflated model performance.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们应该在预处理步骤之前将数据集分成训练集和测试集。如果我们在拆分数据集之前进行预处理步骤，我们可能会意外地从测试数据集中学习，从而导致模型性能被过度夸大。
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The correct step is to `fit_transform` on the training dataset, and `transform`
    on the testing dataset.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的步骤是对训练数据集进行 `fit_transform`，对测试数据集进行 `transform`。
- en: 'Data Leakage 4th illustration: Including the feature cabin as part of the feature
    in the model'
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据泄漏第4种示例：将舱位特征作为模型的一部分
- en: This data leakage problem is not easy to spot and perhaps needs some domain
    knowledge to understand. The main question to ask is **“Does this feature contain
    information that would not be available at the time of prediction?”** If the answer
    to this question is a yes, then high chance there could be data leakage in play.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据泄漏问题不容易发现，可能需要一些领域知识来理解。主要问题是**“这个特征是否包含在预测时不可用的信息？”** 如果答案是肯定的，那么很有可能存在数据泄漏。
- en: In the context of this, the “prediction” is being done after the passengers
    have already boarded the ship and the event has occurred. The goal is to predict
    whether a passenger would have survived or not based on the available data (i.e.
    passenger class, age, etc.) after the event has already taken place. At the time
    of prediction, cabin number information is not available since it was only assigned
    to passengers after they boarded the ship.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，“预测”是在乘客已经登船且事件已经发生后进行的。目标是基于事件发生后的现有数据（即乘客等级、年龄等）预测乘客是否会生存。在预测时，舱位号信息不可用，因为它仅在乘客登船后才分配给乘客。
- en: Not every passenger had their cabin number recorded in the dataset, in fact,
    we have a large number of missing data. The cabin number may not be accurate or
    complete even for those that do have the record. Thus, we cannot utilize cabin
    number as a predictor when developing a model to estimate survival because it
    could not be correct or available for all passengers.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 不是每位乘客的舱号在数据集中都有记录，实际上，我们有大量缺失的数据。即使对于那些有记录的乘客，舱号也可能不准确或不完整。因此，我们在开发估算生存模型时不能将舱号作为预测因子，因为它可能并不对所有乘客都准确或可用。
- en: Imagine that we decide to use the cabin number as one of the predictors in the
    model. While training the model, it uses the cabin number to make predictions
    and gets really good at it. But when we try to use the model in the real world,
    we may not have the cabin number for all passengers, or the cabin number we have
    might be wrong. This means that even if the model was very accurate during training,
    it may not do well in a real-world deployment case.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们决定将舱号作为模型中的一个预测因子。在训练模型时，它使用舱号进行预测，并且表现得非常好。但是，当我们尝试在现实世界中使用模型时，我们可能没有所有乘客的舱号，或者我们拥有的舱号可能是错误的。这意味着即使模型在训练过程中非常准确，它在实际应用中可能表现不好。
- en: One possible solution is to drop this feature and exclude it from the model
    building.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可能的解决方案是删除这个特征，并在模型构建中排除它。
- en: Afterword
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 后记
- en: Preventing data leakage is indeed a challenging task. Studying the relationship
    between features and target variable is key to uncovering this problem. Next time
    when you see an insanely high performance from your model, maybe it’s better to
    learn to sit back and observe, cause not everything needs a reaction.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 防止数据泄露确实是一个具有挑战性的任务。研究特征与目标变量之间的关系是揭示这个问题的关键。下次当你看到模型的性能异常高时，也许更好地学会坐下来观察，因为不是所有事情都需要反应。
- en: Thank you for reading, and happy modeling!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读，祝建模愉快！
- en: If you pick up something useful from this article, do consider giving me a [***Follow***](https://medium.com/@andreas030503)
    on Medium. Easy, 1 article a week to keep yourself updated and stay ahead of the
    curve!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从这篇文章中获得了有用的信息，请考虑在 Medium 上给我一个 [***关注***](https://medium.com/@andreas030503)。简单，每周一篇文章，保持更新，领先一步！
- en: '***You can connect with me on LinkedIn:*** [***https://www.linkedin.com/in/andreaslukita7/***](https://www.linkedin.com/in/andreaslukita7/)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '***你可以在 LinkedIn 上与我联系:*** [***https://www.linkedin.com/in/andreaslukita7/***](https://www.linkedin.com/in/andreaslukita7/)'
- en: '***References:***'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '***参考文献:***'
- en: Forcepoint. *What is Data Leakage? Data Leakage Defined, Explained, and Explored*.
    [https://www.forcepoint.com/cyber-edu/data-leakage](https://www.forcepoint.com/cyber-edu/data-leakage)
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Forcepoint. *什么是数据泄露？数据泄露的定义、解释和探索*。 [https://www.forcepoint.com/cyber-edu/data-leakage](https://www.forcepoint.com/cyber-edu/data-leakage)
- en: Analytics Vidhya. *Data Leakage And Its Effect On The Performance of An ML Model*.
    [https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/](https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/)
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Analytics Vidhya. *数据泄露及其对机器学习模型性能的影响*。 [https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/](https://www.analyticsvidhya.com/blog/2021/07/data-leakage-and-its-effect-on-the-performance-of-an-ml-model/)
- en: JFrog. *Be Careful from Data Leakage — Potential Pitfalls in your Machine Learning
    Model*. [https://jfrog.com/community/data-science/be-careful-from-data-leakage-2/](https://jfrog.com/community/data-science/be-careful-from-data-leakage-2/)
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: JFrog. *小心数据泄露——你的机器学习模型中的潜在陷阱*。 [https://jfrog.com/community/data-science/be-careful-from-data-leakage-2/](https://jfrog.com/community/data-science/be-careful-from-data-leakage-2/)
- en: 'Data Cleaning and Exploration with Machine Learning by Michael Walker: [https://www.packtpub.com/product/data-cleaning-and-exploration-with-machine-learning/9781803241678](https://www.packtpub.com/product/data-cleaning-and-exploration-with-machine-learning/9781803241678)'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Michael Walker 的《机器学习中的数据清理与探索》：[https://www.packtpub.com/product/data-cleaning-and-exploration-with-machine-learning/9781803241678](https://www.packtpub.com/product/data-cleaning-and-exploration-with-machine-learning/9781803241678)
- en: Scikit-learn Pipeline. [https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline)
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Scikit-learn Pipeline. [https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline)
- en: Titanic Dataset. [https://www.openml.org/search?type=data&status=active&id=40945&sort=runs](https://www.openml.org/search?type=data&status=active&id=40945&sort=runs)
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Titanic 数据集。 [https://www.openml.org/search?type=data&status=active&id=40945&sort=runs](https://www.openml.org/search?type=data&status=active&id=40945&sort=runs)
- en: '[https://github.com/datasciencedojo/datasets/blob/master/titanic.csv](https://github.com/datasciencedojo/datasets/blob/master/titanic.csv)'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://github.com/datasciencedojo/datasets/blob/master/titanic.csv](https://github.com/datasciencedojo/datasets/blob/master/titanic.csv)'
