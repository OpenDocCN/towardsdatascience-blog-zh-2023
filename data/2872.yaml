- en: 3 Easy Methods For Improving Your Large Language Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改善大型语言模型的3种简单方法
- en: 原文：[https://towardsdatascience.com/3-easy-methods-for-improving-your-large-language-model-68670fde9ffa?source=collection_archive---------1-----------------------#2023-09-15](https://towardsdatascience.com/3-easy-methods-for-improving-your-large-language-model-68670fde9ffa?source=collection_archive---------1-----------------------#2023-09-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/3-easy-methods-for-improving-your-large-language-model-68670fde9ffa?source=collection_archive---------1-----------------------#2023-09-15](https://towardsdatascience.com/3-easy-methods-for-improving-your-large-language-model-68670fde9ffa?source=collection_archive---------1-----------------------#2023-09-15)
- en: Enhancing the power of Llama 2
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强Llama 2的能力
- en: '[](https://medium.com/@maartengrootendorst?source=post_page-----68670fde9ffa--------------------------------)[![Maarten
    Grootendorst](../Images/58e24b9cf7e10ff1cd5ffd75a32d1a26.png)](https://medium.com/@maartengrootendorst?source=post_page-----68670fde9ffa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----68670fde9ffa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----68670fde9ffa--------------------------------)
    [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----68670fde9ffa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maartengrootendorst?source=post_page-----68670fde9ffa--------------------------------)[![Maarten
    Grootendorst](../Images/58e24b9cf7e10ff1cd5ffd75a32d1a26.png)](https://medium.com/@maartengrootendorst?source=post_page-----68670fde9ffa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----68670fde9ffa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----68670fde9ffa--------------------------------)
    [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----68670fde9ffa--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22405c3b2875&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F3-easy-methods-for-improving-your-large-language-model-68670fde9ffa&user=Maarten+Grootendorst&userId=22405c3b2875&source=post_page-22405c3b2875----68670fde9ffa---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----68670fde9ffa--------------------------------)
    ·12 min read·Sep 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68670fde9ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F3-easy-methods-for-improving-your-large-language-model-68670fde9ffa&user=Maarten+Grootendorst&userId=22405c3b2875&source=-----68670fde9ffa---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F22405c3b2875&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F3-easy-methods-for-improving-your-large-language-model-68670fde9ffa&user=Maarten+Grootendorst&userId=22405c3b2875&source=post_page-22405c3b2875----68670fde9ffa---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----68670fde9ffa--------------------------------)
    ·12分钟阅读·2023年9月15日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F68670fde9ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F3-easy-methods-for-improving-your-large-language-model-68670fde9ffa&user=Maarten+Grootendorst&userId=22405c3b2875&source=-----68670fde9ffa---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68670fde9ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F3-easy-methods-for-improving-your-large-language-model-68670fde9ffa&source=-----68670fde9ffa---------------------bookmark_footer-----------)![](../Images/4bc4b72c825e1d128f2e168a5aabf27e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F68670fde9ffa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F3-easy-methods-for-improving-your-large-language-model-68670fde9ffa&source=-----68670fde9ffa---------------------bookmark_footer-----------)![](../Images/4bc4b72c825e1d128f2e168a5aabf27e.png)'
- en: Large Language Models (LLMs) are here to stay. With the recent release of Llama
    2, open-source LLMs are approaching the performance of ChatGPT and with proper
    tuning can even exceed it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）已经成为长期存在的技术。随着Llama 2的发布，开源LLMs的性能正接近ChatGPT，并且经过适当调整甚至可以超越它。
- en: Using these LLMs is often not as straightforward as it seems especially if you
    want to fine-tune the LLM to your specific use case.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些LLMs往往不像看起来那么简单，特别是当你想将LLM微调以适应你的特定用例时。
- en: 'In this article, we will go through 3 of the most common methods for improving
    the performance of any LLM:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将探讨提高任何LLM性能的3种最常见的方法：
- en: Prompt Engineering
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示工程
- en: Retrieval Augmented Generation (RAG)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）
- en: Parameter Efficient Fine-Tuning (PEFT)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数高效微调（PEFT）
- en: '![](../Images/a22e11f94a498add3609ac5a4fa81b26.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a22e11f94a498add3609ac5a4fa81b26.png)'
- en: There are many more methods but these are the easiest and can result in major
    improvements without much work.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 还有很多其他方法，但这些是最简单的，而且能在不费太多力气的情况下带来重大改进。
- en: These 3 methods start from the least complex method, the so-called low-hanging
    fruits, to one of the more complex methods for improving your LLM.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这3种方法从最简单的方法开始，即所谓的低悬果，到提升你的LLM的更复杂的方法。
- en: To get the most out of LLMs, you can even combine all three methods!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大程度地发挥LLM的效果，你甚至可以将这三种方法结合使用！
