- en: 'Language Models and Friends: Gorilla, HuggingGPT, TaskMatrix, and More'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语言模型及其相关：Gorilla、HuggingGPT、TaskMatrix及更多
- en: 原文：[https://towardsdatascience.com/language-models-and-friends-gorilla-hugginggpt-taskmatrix-and-more-b88c1200afd3](https://towardsdatascience.com/language-models-and-friends-gorilla-hugginggpt-taskmatrix-and-more-b88c1200afd3)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/language-models-and-friends-gorilla-hugginggpt-taskmatrix-and-more-b88c1200afd3](https://towardsdatascience.com/language-models-and-friends-gorilla-hugginggpt-taskmatrix-and-more-b88c1200afd3)
- en: What happens when we give LLMs access to thousands of deep learning models?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当我们给LLMs访问成千上万的深度学习模型时，会发生什么？
- en: '[](https://wolfecameron.medium.com/?source=post_page-----b88c1200afd3--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----b88c1200afd3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b88c1200afd3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b88c1200afd3--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----b88c1200afd3--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----b88c1200afd3--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----b88c1200afd3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b88c1200afd3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b88c1200afd3--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----b88c1200afd3--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b88c1200afd3--------------------------------)
    ·18 min read·Sep 4, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b88c1200afd3--------------------------------)
    ·阅读时间18分钟·2023年9月4日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6d46238c8cde54e36f1961a4a4509706.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d46238c8cde54e36f1961a4a4509706.png)'
- en: (Photo by [Mike Arney](https://unsplash.com/@mikearney?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/rJ5vHo8gr2U?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （图片由 [Mike Arney](https://unsplash.com/@mikearney?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来自 [Unsplash](https://unsplash.com/photos/rJ5vHo8gr2U?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: Recently, we have witnessed a rise of foundation models to popularity within
    deep learning research. Pre-trained large language models (LLMs) have led to a
    new paradigm, in which a single model can be used — with surprising success —
    to solve many different problems. Despite the popularity of generic LLMs, however,
    fine-tuning models in a task-specific manner tends to outperform approaches that
    leverage foundation models. Put simply, *specialized models are still very hard
    to beat*! With this being said, we might start to wonder whether the powers of
    foundation models and specialized deep learning models can be combined. Within
    this overview, we will study recent research that integrates LLMs with other,
    specialized deep learning models by learning to call their associated APIs. The
    resulting framework uses the language model as a centralized controller that forms
    a plan for solving a complex, AI-related tasks and delegates specialized portions
    of the solution process to more appropriate models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我们见证了基础模型在深度学习研究中日益流行。预训练的大型语言模型（LLMs）引领了一个新范式，在这种范式中，一个模型可以用来——以令人惊讶的成功——解决许多不同的问题。然而，尽管通用LLMs很受欢迎，但任务特定的微调模型往往比利用基础模型的方法表现更佳。简单来说，*专业化模型仍然很难被超越*！话虽如此，我们可能会开始想知道，基础模型和专业深度学习模型的能力是否可以结合起来。在这次概述中，我们将研究近期的研究，这些研究通过学习调用其关联的API，将LLMs与其他专业化深度学习模型结合起来。结果框架将语言模型作为一个集中控制器，用于制定解决复杂AI相关任务的计划，并将解决方案过程中的专业部分委派给更合适的模型。
- en: “By providing only the model descriptions, HuggingGPT can continuously and conveniently
    integrate diverse expert models from AI communities, without altering any structure
    or prompt settings. This open and continuous manner brings us one step closer
    to realizing artificial general intelligence.” *— from [2]*
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “通过仅提供模型描述，HuggingGPT能够持续且方便地整合来自AI社区的各种专家模型，而无需改变任何结构或提示设置。这种开放和持续的方式使我们离实现人工通用智能更进一步。”
    *— 引自 [2]*
- en: '![](../Images/148b806f6b456c06470705386cf075fd.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/148b806f6b456c06470705386cf075fd.png)'
- en: (from [2, 3])
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: （引自 [2, 3]）
- en: Background
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: Before exploring how language models can be integrated with other deep learning
    models, we need to cover a few background ideas, such as LLM tools, information
    retrieval, and self-instruct [11]. For more generic background information on
    language models, check out the following resources.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索语言模型如何与其他深度学习模型集成之前，我们需要涵盖一些背景概念，如LLM工具、信息检索和自我指导 [11]。有关语言模型的更多通用背景信息，请查看以下资源。
- en: Language Modeling Basics (GPT and GPT-2) [[link](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)]
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言建模基础（GPT和GPT-2） [[link](https://cameronrwolfe.substack.com/p/language-models-gpt-and-gpt-2)]
- en: The Importance of Scale for Language Models (GPT-3) [[link](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)]
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型规模的重要性（GPT-3） [[link](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)]
- en: Modern [[link](https://cameronrwolfe.substack.com/p/modern-llms-mt-nlg-chinchilla-gopher)]
    and Specialized [[link](https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica)]
    LLMs
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代 [[link](https://cameronrwolfe.substack.com/p/modern-llms-mt-nlg-chinchilla-gopher)]
    和专业 [[link](https://cameronrwolfe.substack.com/p/specialized-llms-chatgpt-lamda-galactica)]
    LLMs
- en: Basic [[link](https://cameronrwolfe.substack.com/p/practical-prompt-engineering-part)]
    and Advanced [[link](https://cameronrwolfe.substack.com/p/advanced-prompt-engineering)]
    Prompt Engineering
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础的 [[link](https://cameronrwolfe.substack.com/p/practical-prompt-engineering-part)]
    和高级的 [[link](https://cameronrwolfe.substack.com/p/advanced-prompt-engineering)]
    提示工程
- en: Using tools with LLMs
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用工具与LLMs
- en: “By empowering LLMs to use tools, we can grant access to vastly larger and changing
    knowledge bases and accomplish complex computational tasks.” *— from [3]*
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “通过赋予LLMs使用工具的能力，我们可以访问更广泛且不断变化的知识库，并完成复杂的计算任务。” *— 摘自[3]*
- en: Although language models have a large number of impressive capabilities, they
    are not perfect and can’t accomplish all tasks on their own. In many cases, combining
    existing models with tools (e.g., search engines, calculators, calendars, etc.)
    can drastically expand the scope of their capabilities. In a prior overview, we
    explored the Toolformer [1] — a fine-tuning technique for teaching LLMs to use
    a small set of simple, textual APIs — and how tools can be used to improve the
    performance of LLMs without too much effort; see [here](https://cameronrwolfe.substack.com/p/teaching-language-models-to-use-tools)
    for more details.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管语言模型拥有许多令人印象深刻的能力，但它们并不完美，不能独立完成所有任务。在许多情况下，将现有模型与工具（例如搜索引擎、计算器、日历等）结合使用，可以大幅扩展它们的能力范围。在之前的综述中，我们探讨了Toolformer
    [1]——一种用于教会LLMs使用一小组简单文本API的微调技术——以及如何在不费太大力气的情况下使用工具来提高LLMs的表现；更多细节请见[这里](https://cameronrwolfe.substack.com/p/teaching-language-models-to-use-tools)。
- en: Although models like the Toolformer are effective, they only consider a small
    set of very simple APIs. These APIs barely scratch the surface of the total number
    of tools that can be made available to LLMs. Imagine, for example, if we were
    able to integrate an LLM with any API that is available via the internet — *we
    could unlock an entire realm of new applications and possibilities*!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管像Toolformer这样的模型很有效，但它们只考虑了一小组非常简单的API。这些API仅仅触及了可以提供给LLMs的工具总数的表面。例如，想象一下，如果我们能够将LLM与任何通过互联网提供的API集成——*我们可能会解锁一个全新的应用和可能性的领域*！
- en: '![](../Images/974424ccd78da3e54cc81bc533937092.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/974424ccd78da3e54cc81bc533937092.png)'
- en: Popular apps on the ChatGPT plus plugin store
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT Plus 插件商店中的热门应用
- en: '**(Almost) anything is possible!** This trend towards providing language models
    with widespread access to a variety of APIs online is being explored via the ChatGPT
    plugins store; see above. By leveraging these APIs, we can do much more than just
    provide LLMs access to simple tools like calculators! We can easily think of several
    high-impact applications that become possible with this approach. For example,
    we could use language models with tool integrations for:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**（几乎）任何事都有可能！** 这种将语言模型与各种在线API广泛接入的趋势正在通过ChatGPT插件商店进行探索；见上文。通过利用这些API，我们可以做的不仅仅是为LLMs提供简单的工具，如计算器！我们可以轻松想到几个通过这种方法变得可能的高影响力应用。例如，我们可以使用集成工具的语言模型进行：'
- en: Forming a vacation itinerary and booking all needed tickets and reservations
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定假期行程并预订所有必要的票和预订
- en: Curating and purchasing the week’s grocery list for curbside pickup
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 策划并购买本周的食品杂货清单以便路边取货
- en: Finding and reserving a table at a restaurant for the upcoming weekend
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找并预订即将到来的周末餐厅的桌子
- en: Discovering and purchasing relevant products on any e-commerce store
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何电子商务商店发现并购买相关产品
- en: The scope of possibilities is nearly endless! By using language as a standardized
    medium of communication, we can work with foundation models like ChatGPT to accomplish
    surprisingly complex tasks. All we have to do is [prompt the model](https://cameronrwolfe.substack.com/i/123558334/using-tools-is-getting-easier)
    to produce the API calls that are relevant to our request.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 可能性范围几乎是无限的！通过将语言作为一种标准化的交流媒介，我们可以与基础模型如ChatGPT合作，完成令人惊讶的复杂任务。我们所要做的就是[提示模型](https://cameronrwolfe.substack.com/i/123558334/using-tools-is-getting-easier)生成与我们请求相关的API调用。
- en: '**Deep learning APIs.** In this overview, we will consider integrating LLMs
    with a particular kind of API — those that provide access to open-source deep
    learning models on platforms like [HuggingFace](https://huggingface.co/). The
    AI/ML community places a heavy emphasis on open-source software, meaning that
    many of the most powerful deep learning models are freely available online. Usually,
    these models come with well-written descriptions, called [model cards](https://huggingface.co/docs/hub/model-cards),
    that can be used to provide all needed information about any model to an LLM.
    Then, these models can be easily integrated with an LLM via basic prompting techniques.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度学习API。** 在本概述中，我们将考虑将LLMs与一种特定类型的API集成——这些API提供对平台如[HuggingFace](https://huggingface.co/)上的开源深度学习模型的访问。AI/ML社区对开源软件给予了高度重视，这意味着许多最强大的深度学习模型在线上免费提供。通常，这些模型附带有良好撰写的描述，称为[模型卡](https://huggingface.co/docs/hub/model-cards)，可以用来为LLM提供任何模型所需的所有信息。然后，这些模型可以通过基本的提示技术轻松与LLM集成。'
- en: The Self-Instruct Framework
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自我指令框架
- en: '![](../Images/2280d72a970d106dfe6795787aa44492.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2280d72a970d106dfe6795787aa44492.png)'
- en: (from [11])
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[11]）
- en: The self-instruct framework, proposed in [11], pioneers the idea of using LLMs
    to train themselves by generating synthetic [instruction tuning](https://twitter.com/cwolferesearch/status/1652064977493057545?s=20)
    data that can be used for fine-tuning. Beginning with a single input-output pair
    associated with a certain task or instruction, self-instruct prompts an off-the-shelf
    LLM to generate new tasks, as well as valid instructions and responses to go with
    each of them. After filtering is performed to remove low-quality data, we can
    fine-tune any language model on the resulting instruction tuning dataset. Interestingly,
    we find that models fine-tuned over this data tend to match the performance of
    those trained over human-curated datasets. Although self-instruct works well,
    several improvements to the overall framework were also proposed by [Alpaca](https://cameronrwolfe.substack.com/i/114077195/alpaca-an-instruction-following-llama-model)
    [12]; see [here](https://github.com/tatsu-lab/stanford_alpaca#data-generation-process).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 自我指令框架，在[11]中提出，开创了利用大型语言模型（LLMs）通过生成合成的[指令调优](https://twitter.com/cwolferesearch/status/1652064977493057545?s=20)数据来进行自我训练的想法。这些数据可以用于微调。从与特定任务或指令相关的单一输入-输出对开始，自我指令会提示一个现成的LLM生成新的任务，以及与每个任务相关的有效指令和响应。在进行过滤以去除低质量数据后，我们可以在生成的指令调优数据集上对任何语言模型进行微调。有趣的是，我们发现，基于这些数据进行微调的模型往往能达到与那些在人工策划数据集上训练的模型相匹配的性能。尽管自我指令效果良好，[Alpaca](https://cameronrwolfe.substack.com/i/114077195/alpaca-an-instruction-following-llama-model)
    [12]也提出了一些对整体框架的改进；详情见[这里](https://github.com/tatsu-lab/stanford_alpaca#data-generation-process)。
- en: Information Retrieval
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信息检索
- en: As we have seen in prior overviews, the quality of foundation language models
    tends to [improve with scale](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)
    — large pre-training datasets and models lead to the best results. However, we
    can only store so much information within the fixed set of weights contained within
    a language model. *Even massive models have a finite number of parameters*. Additionally,
    the limited context window of modern LLMs limits us to injecting only a small
    amount of information into the model’s prompt. So, *what should we do if we want
    to provide our LLM access to a large bank of information*? We need to adopt some
    form of information retrieval.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在之前的概述中看到的，基础语言模型的质量往往随着[规模的增加而提升](https://twitter.com/cwolferesearch/status/1635693551584522256?s=20)——大型预训练数据集和模型会带来最佳结果。然而，我们只能在语言模型中固定的权重集合中存储有限的信息。*即使是大规模模型也有有限数量的参数*。此外，现代LLM的有限上下文窗口限制了我们只能将少量信息注入到模型的提示中。那么，*如果我们想让LLM访问大量的信息库，该怎么办*？我们需要采用某种形式的信息检索。
- en: '![](../Images/5e97b5971a5abe3703fce7e0bb495196.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e97b5971a5abe3703fce7e0bb495196.png)'
- en: (from [13])
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[13]）
- en: '**Vector databases.** One popular form of information retrieval can be performed
    by integrating an LLM with a vector database that stores large amounts of textual
    information. At a high level, this integration with a vector database (e.g., [Pinecone](https://www.pinecone.io/),
    [Milvus](https://milvus.io/), [Weaviate](https://weaviate.io/), [Redis](https://redis.io/docs/stack/search/reference/vectors/),
    etc.) is formed by:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**向量数据库。** 一种流行的信息检索形式可以通过将LLM与存储大量文本信息的向量数据库集成来完成。在高级别上，这种与向量数据库（例如，[Pinecone](https://www.pinecone.io/)、[Milvus](https://milvus.io/)、[Weaviate](https://weaviate.io/)、[Redis](https://redis.io/docs/stack/search/reference/vectors/)等）的集成包括：'
- en: Chunking the text into small parts.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本分块成小部分。
- en: Producing an [embedding](https://platform.openai.com/docs/guides/embeddings)
    for each chunk of text.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个文本片段生成[嵌入](https://platform.openai.com/docs/guides/embeddings)。
- en: Storing these embeddings in a vector database.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些嵌入存储在向量数据库中。
- en: Performing [vector similarity search](https://www.pinecone.io/learn/what-is-similarity-search/)
    (based on these embeddings) to find relevant chunks of text to include in a prompt.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行[向量相似性搜索](https://www.pinecone.io/learn/what-is-similarity-search/)（基于这些嵌入）来查找相关的文本片段以包含在提示中。
- en: The net result is that we can quickly find relevant textual information to provide
    as extra context within a prompt, allowing the LLM to draw upon information beyond
    the maximum size of its [context window](https://cameronrwolfe.substack.com/i/117151147/what-is-prompt-engineering).
    Even though we still cannot provide all of the information we have to the model,
    we can use vector similarity search to quickly identify the most relevant parts.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果是，我们可以快速找到相关的文本信息，作为提示中的额外上下文，使LLM能够利用超出其[上下文窗口](https://cameronrwolfe.substack.com/i/117151147/what-is-prompt-engineering)的额外信息。尽管我们仍然无法将所有信息提供给模型，但我们可以使用向量相似性搜索快速识别最相关的部分。
- en: '![](../Images/ae22a82180d5746f39716592a36462e4.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ae22a82180d5746f39716592a36462e4.png)'
- en: (from [14])
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[14]）
- en: '**Is this the only way?** Many other methods have been proposed for information
    retrieval — there is an entire (incredibly active) area of research dedicated
    to these techniques. We can even use LLMs to generate relevant information (instead
    of retrieving it) via [generated knowledge prompting](https://cameronrwolfe.substack.com/i/118401596/knowledge-augmentation);
    see above. The article [here](https://jxmo.io/posts/retrieval) does a great job
    of summarizing existing techniques for information retrieval. Overall, many different
    techniques exist, and we have a lot of options for choosing how an LLM could be
    augmented with external sources of information.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**这就是唯一的方法吗？** 许多其他方法已被提出用于信息检索——这方面有一个专门的（非常活跃的）研究领域。我们甚至可以使用LLMs生成相关信息（而不是检索）通过[生成知识提示](https://cameronrwolfe.substack.com/i/118401596/knowledge-augmentation)；见上文。文章[这里](https://jxmo.io/posts/retrieval)很好地总结了现有的信息检索技术。总体而言，存在许多不同的技术，我们有很多选择来决定如何用外部信息源来增强LLM。'
- en: '![](../Images/881b7efa2f23420367f1f066e78e63c9.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/881b7efa2f23420367f1f066e78e63c9.png)'
- en: (from [3])
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: （来自[3]）
- en: '**Why should we care?** Information retrieval is great, but we might be wondering
    why this is relevant to the topic of integrating LLMs with other deep learning
    models. Well, *what if we want to provide access to any model available online?*
    There are thousands of models available on ML communities like HuggingFace! As
    such, we can’t provide a description for all of these models to the LLM. Rather,
    we need to use some form of information retrieval to determine the most relevant
    subset of models that we should include in the LLM’s prompt; see above.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们为什么要关心这个问题？** 信息检索非常重要，但我们可能会想知道这与将LLMs与其他深度学习模型整合的主题有何相关。好吧，*如果我们想要提供对任何在线可用模型的访问呢？*
    在像HuggingFace这样的ML社区中，有成千上万的模型！因此，我们不能为所有这些模型提供描述给LLM。相反，我们需要使用某种形式的信息检索来确定我们应该包含在LLM提示中的最相关的模型子集；见上文。'
- en: Integrating LLMs with Other Models
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将LLMs与其他模型集成
- en: Now that we have some relevant background information under our belt, we will
    take a look at recent publications that augment LLMs with other deep learning
    models. Although each approach is different [2, 3], all of such techniques aim
    to teach an LLM how to call APIs associated with other, specialized models. Then,
    the LLM can act as a controller (or brain) that coordinates the solution of a
    problem by planning and delegating subtasks to different APIs.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了一些相关背景信息，我们将查看最近的出版物，这些出版物增强了LLMs与其他深度学习模型的结合。虽然每种方法有所不同 [2, 3]，但所有这些技术的目标都是教会LLM如何调用与其他专业模型相关的API。然后，LLM可以作为一个控制器（或大脑），通过规划和将子任务委派给不同的API来协调问题的解决。
- en: '[HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580)
    [2]'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[HuggingGPT: 用ChatGPT及其在Hugging Face的朋友解决AI任务](https://arxiv.org/abs/2303.17580)
    [2]'
- en: '![](../Images/0f5a9059b8ceb94524d253c8fa344899.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f5a9059b8ceb94524d253c8fa344899.png)'
- en: (from [2])
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [2])
- en: LLMs have become popular recently, but research in deep learning has produced
    a variety of incredibly useful models in recent years for solving specific tasks
    like image recognition, video action detection, text classification, and much
    more. Unlike language models, these models are narrow experts, meaning that they
    can accurately solve a specific task given a fixed input-output format. But, they
    are not useful for anything beyond the specific task that they are trained to
    solve. *What if we want to repurpose these models as components for solving more
    open-ended AI-related tasks?*
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最近LLMs变得流行，但近年来深度学习研究已经产生了多种非常有用的模型，用于解决特定任务，如图像识别、视频动作检测、文本分类等等。这些模型不同于语言模型，它们是狭义的专家，这意味着它们可以在固定的输入输出格式下准确地解决特定任务。但它们对于超出其训练解决的特定任务范围的内容没有用处。*如果我们想将这些模型重新利用作为解决更多开放式AI相关任务的组件呢？*
- en: “LLMs [can] act as a controller to manage existing AI models to solve complicated
    AI tasks and language could be a generic interface to empower this.” *— from [2]*
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “LLMs [可以] 作为一个控制器来管理现有的AI模型以解决复杂的AI任务，而语言可以是一个通用接口来实现这一点。” *— 来自 [2]*
- en: In [2], authors explore using LLMs as a generic interface for connecting deep
    learning models together. HuggingGPT [2] is inspired by the idea of allowing an
    LLM to coordinate with external models with a variety of different specialized
    capabilities. Put simply, the LLM serves as the “brain” of a problem solving system,
    which plans how to solve a problem and coordinates efforts between different deep
    learning models that solve necessary subtasks for this problem. To teach an LLM
    how to do this, we need high-quality descriptions of each model. Luckily, we don’t
    need to perform any prompt engineering to create these descriptions — they are
    [widely available](https://huggingface.co/docs/hub/model-cards#what-are-model-cards)
    via ML communities like HuggingFace!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [2] 中，作者探索了将LLMs用作连接深度学习模型的通用接口。HuggingGPT [2] 的灵感来自于允许LLM与具有不同专业能力的外部模型进行协调的想法。简单来说，LLM作为问题解决系统的“大脑”，计划如何解决问题，并协调不同深度学习模型之间的努力，这些模型解决了该问题所需的子任务。为了教会LLM如何做到这一点，我们需要每个模型的高质量描述。幸运的是，我们不需要进行任何提示工程来创建这些描述——它们通过像HuggingFace这样的ML社区
    [广泛提供](https://huggingface.co/docs/hub/model-cards#what-are-model-cards)！
- en: '![](../Images/e0fcfdc306dd4a77dc18fee2cb1de78c.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0fcfdc306dd4a77dc18fee2cb1de78c.png)'
- en: (from [2])
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: (来自 [2])
- en: '**How does this work?** HuggingGPT [2] decomposes problems into four parts:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**这怎么运作？** HuggingGPT [2] 将问题分解为四个部分：'
- en: '*Task planning:* use the LLM to decompose a user’s request into solvable tasks.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*任务规划*：使用LLM将用户请求分解为可解决的任务。'
- en: '*Model selection*: select models from HuggingFace to use for solving tasks.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型选择*：从HuggingFace中选择用于解决任务的模型。'
- en: '*Task execution*: run each selected model and return results to the LLM.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*任务执行*：运行每个选定的模型并将结果返回给LLM。'
- en: '*Response generation*: use the LLM to generate a final response for the user.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*响应生成*：使用LLM为用户生成最终响应。'
- en: As we might expect, leveraging the capabilities of models available online gives
    HuggingGPT the ability to solve a wide variety of complex problems!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们可能预期的那样，利用在线模型的能力赋予了HuggingGPT解决各种复杂问题的能力！
- en: “HuggingGPT can automatically generate plans from user requests and use external
    models, and thus can integrate multimodal perceptual capabilities and handle multiple
    complex AI tasks.” *— from [2]*
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “HuggingGPT可以根据用户请求自动生成计划，并使用外部模型，因此可以整合多模态感知能力并处理多个复杂的AI任务。” *— 来自 [2]*
- en: Quite impressively, HuggingGPT does not need to be fine-tuned at all to learn
    how to coordinate and use these models! Rather, it leverages [few-shot learning](https://cameronrwolfe.substack.com/i/117151147/few-shot-learning)
    and [instruction prompting](https://cameronrwolfe.substack.com/i/117151147/instruction-prompting)
    to perform each of its required tasks for solving a problem; see below. For these
    prompts to work well, we need a [steerable](https://twitter.com/cwolferesearch/status/1645535868021805056?s=20)
    LLM (e.g., ChatGPT or GPT-4) that can follow directions closely and obey strict
    output formats (e.g., decomposing a problem into json-formatted tasks).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 相当令人印象深刻的是，HuggingGPT 完全不需要微调就能学习如何协调和使用这些模型！相反，它利用了 [少量学习](https://cameronrwolfe.substack.com/i/117151147/few-shot-learning)
    和 [指令提示](https://cameronrwolfe.substack.com/i/117151147/instruction-prompting)
    来执行解决问题所需的每一个任务；见下文。为了使这些提示发挥良好效果，我们需要一个 [可调节](https://twitter.com/cwolferesearch/status/1645535868021805056?s=20)
    的 LLM（例如 ChatGPT 或 GPT-4），它能够严格遵守指令并执行严格的输出格式（例如，将问题分解为 json 格式的任务）。
- en: '![](../Images/25b92c38063c7b317570c9c7867ce8fe.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/25b92c38063c7b317570c9c7867ce8fe.png)'
- en: (from [2])
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [2]）
- en: Notably, we should observe that the set of available models to be used is directly
    injected into the task planning prompt provided to HuggingGPT; see the example
    above. Obviously, there are too many models available online to include them all
    in the prompt. To decide which models should be included as an option in the prompt,
    HuggingGPT selects a group of models based on their task type (i.e., do they solve
    a task that’s relevant to the current problem), ranks them according to downloads
    (i.e., the number of users that downloaded or used this model on HuggingFace),
    then provides the top-`K` models as options to the LLM.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们应当观察到，供 HuggingGPT 使用的可用模型集直接注入到任务规划提示中；见上例。显然，网上有太多模型可用，无法将它们全部包含在提示中。为了决定应将哪些模型作为选项包含在提示中，HuggingGPT
    根据任务类型（即，它们是否解决与当前问题相关的任务）选择一组模型，根据下载量（即，在 HuggingFace 上下载或使用该模型的用户数量）对它们进行排名，然后将排名前
    `K` 的模型提供给 LLM 作为选项。
- en: '![](../Images/cc6a7e9c0c67a80808dee11b80f7de45.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc6a7e9c0c67a80808dee11b80f7de45.png)'
- en: (from [2])
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [2]）
- en: '**Resource dependencies.** After HuggingGPT decomposes a user’s request into
    several problem-solving steps, we need to execute each model in the specified
    plan. However, when we execute each model specified by HuggingGPT, some models
    may be dependent upon the output of others, which is referred to as a “resource
    dependency” in [2]. To handle these cases, models with dependencies await the
    output of models upon which they are dependent before executing. Models with no
    dependencies can execute in parallel to make the task execution step of HuggingGPT
    faster. Interestingly, the task-planning structure produced by the LLM not only
    changes the order of execution for each model, but also the manner in which we
    evaluate HuggingGPT’s output. For example, authors in [2] use GPT-4 to evaluate
    the quality of more complex task plans; see above.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源依赖。** 在 HuggingGPT 将用户请求分解为几个解决步骤后，我们需要在指定的计划中执行每个模型。然而，当我们执行 HuggingGPT
    指定的每个模型时，一些模型可能依赖于其他模型的输出，这在 [2] 中被称为“资源依赖”。为了处理这些情况，具有依赖关系的模型会等待它们所依赖的模型的输出后再执行。没有依赖关系的模型可以并行执行，从而加快
    HuggingGPT 的任务执行步骤。有趣的是，LLM 生成的任务规划结构不仅改变了每个模型的执行顺序，还改变了我们评估 HuggingGPT 输出的方式。例如，[2]
    中的作者使用 GPT-4 来评估更复杂任务计划的质量；见上文。'
- en: '**Does it perform well?** The evaluation of HuggingGPT performed in [2] focuses
    solely upon assessing the task-planning capabilities of a few different LLMs,
    as the quality of task planning largely determines the success of the overall
    problem-solving framework for HuggingGPT. As shown in the figures below, LLMs
    like GPT-3.5 (and less powerful models to a certain extent) seem to be capable
    of effectively decomposing user requests into a valid task plan.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**它表现得好吗？** 在 [2] 中对 HuggingGPT 的评估专注于评估几个不同 LLM 的任务规划能力，因为任务规划的质量在很大程度上决定了
    HuggingGPT 整体问题解决框架的成功。如下面的图所示，像 GPT-3.5 这样的 LLM（以及在一定程度上较弱的模型）似乎能够有效地将用户请求分解为有效的任务计划。'
- en: '![](../Images/8846660756e5615f37fdca76941f1d6a.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8846660756e5615f37fdca76941f1d6a.png)'
- en: (from [2])
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: （来源 [2]）
- en: 'Much work is required to improve the evaluation of such techniques — the analysis
    provided in [2] is far from comprehensive. Additionally, although HuggingGPT works
    well, it only considers a small, well-documented set of model APIs that are directly
    injected into the LLM’s prompt. Compared to fine-tuning, this framework requires
    a lot of prompt engineering to work well. Although we avoid the need for a fine-tuning
    dataset, the framework is highly-dependent upon the capabilities of the underlying
    model. As such, we might wonder: *how can we generalize this approach to work
    more reliably for a larger number of models?*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 需要大量工作来改进对这些技术的评估 — [2] 中提供的分析远非全面。此外，尽管 HuggingGPT 表现良好，但它只考虑了一小部分直接注入 LLM
    提示中的、文档完善的模型 API。与微调相比，这一框架需要大量的提示工程来有效运作。尽管我们避免了对微调数据集的需求，但这一框架在很大程度上依赖于基础模型的能力。因此，我们可能会想：*我们如何将这种方法推广到更多模型中以更可靠地工作？*
- en: '[Gorilla: Large Language Models Connected with Massive APIs](https://arxiv.org/abs/2305.15334)
    [3]'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[猩猩：与大量 API 连接的大型语言模型](https://arxiv.org/abs/2305.15334) [3]'
- en: “Supporting a web scale collection of potentially millions of changing APIs
    requires rethinking our approach to how we integrate tools.” *— from [3]*
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “支持可能数百万个不断变化的 API 的网络规模集合需要重新思考我们整合工具的方法。” *— 引自 [3]*
- en: Integrating LLMs with a smaller, fixed set of other models is cool, but *what
    if we could teach LLMs to use any model API that is available online?* To do this,
    we could just use retrieval techniques that *i)* identify relevant model APIs
    and *ii)* provide their documentation to the LLM.With this approach, LLMs would
    have access to much more than a small set of curated tools! Rather, models could
    access the vast suite of changing APIs in the cloud. Unfortunately, however, even
    powerful LLMs (e.g., [GPT-4](https://openai.com/research/gpt-4) or [Claude](https://www.anthropic.com/index/introducing-claude))
    struggle to leverage APIs in this way due a tendency to pass incorrect arguments
    or hallucinate calls to APIs that do not exist; see below.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 将 LLM 与一组较小且固定的其他模型进行整合是很酷的，但*如果我们能够教会 LLM 使用任何在线可用的模型 API 呢？* 为此，我们可以使用检索技术
    *i)* 识别相关模型 API 和 *ii)* 将它们的文档提供给 LLM。通过这种方法，LLM 将能够访问比少量精心挑选的工具更多的资源！而是，模型可以访问云中不断变化的大量
    API。然而，尽管如此，即便是强大的 LLM（例如，[GPT-4](https://openai.com/research/gpt-4) 或 [Claude](https://www.anthropic.com/index/introducing-claude)）也难以以这种方式利用
    API，因为它们倾向于传递不正确的参数或虚构调用不存在的 API；见下文。
- en: '![](../Images/417b6d4d7ef841b4bec898eec0ebaca3.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/417b6d4d7ef841b4bec898eec0ebaca3.png)'
- en: (from [3])
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: （引自 [3]）
- en: In [3], authors adopt fine-tuning approach, based upon the self-instruct [11]
    framework, to make LLMs more capable of leveraging a large group of external deep
    learning APIs. Going beyond proposals like HuggingGPT [2], authors in [3] consider
    over 1,600 different model APIs. This set of model APIs is much larger than those
    considered in prior work, has overlapping functionality (i.e., many models perform
    similar tasks), and even includes a variety of models with less-than-perfect documentation.
    To learn how to leverage these APIs, work in [3] fine-tunes a [LLaMA-7B](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone)
    [5] model over a large dataset of valid API calls. The resulting model, which
    can effectively leverage many of these APIs, is called Gorilla.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [3] 中，作者采用了基于自我指导 [11] 框架的微调方法，以使 LLM 更有能力利用大量外部深度学习 API。超越像 HuggingGPT [2]
    这样的提案， [3] 中的作者考虑了超过 1,600 个不同的模型 API。这些模型 API 的集合比之前工作的模型 API 要大得多，功能重叠（即，许多模型执行类似的任务），甚至包括一些文档不完美的模型。为了学习如何利用这些
    API， [3] 的工作在一个有效 API 调用的大型数据集上对 [LLaMA-7B](https://cameronrwolfe.substack.com/p/llama-llms-for-everyone)
    [5] 模型进行了微调。最终的模型，能够有效利用这些 API，被称为猩猩。
- en: '**Creating the dataset.** To fine-tune Gorilla, a massive corpus of API calls
    is created by leveraging [HuggingFace Hub](https://huggingface.co/docs/hub/index),
    [PyTorch Hub](https://pytorch.org/hub/), and [TensorFlow Hub](https://www.tensorflow.org/hub).
    Across all three hubs, 1,645 total model APIs are selected, spanning numerous
    domains from computer vision, to audio, to reinforcement learning and more. After
    storing the relevant information for each API in a json object (i.e., includes
    information like domain, framework, description of functionality, and API signature),
    we can follow a self-instruct approach by using GPT-4 to generate ten user question
    prompts and associated responses to go along with each API. After filtering incorrect
    API calls, the result is just a large dataset of real-world use cases that leverage
    each of the different model APIs to solve various questions. This dataset is perfect
    for fine-tuning an LLM; see below.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**创建数据集。** 为了微调 Gorilla，我们利用 [HuggingFace Hub](https://huggingface.co/docs/hub/index)、[PyTorch
    Hub](https://pytorch.org/hub/) 和 [TensorFlow Hub](https://www.tensorflow.org/hub)
    创建了一个大规模的 API 调用语料库。在所有三个中心中，选择了总共 1,645 个模型 API，涵盖了从计算机视觉到音频、强化学习等多个领域。在将每个 API
    的相关信息存储在一个 json 对象中（即包含领域、框架、功能描述和 API 签名等信息）后，我们可以通过使用 GPT-4 生成十个用户问题提示和相关回答来遵循自我指导的方法。经过过滤错误的
    API 调用后，结果就是一个大数据集，涵盖了利用不同模型 API 解决各种问题的实际用例。这个数据集非常适合微调 LLM；见下文。'
- en: '![](../Images/df6988b67a5e072d37761d39b97848fd.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df6988b67a5e072d37761d39b97848fd.png)'
- en: (from [3])
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: (来源 [3])
- en: '**Retrieval-aware fine-tuning.** Instead of performing “normal” supervised
    fine-tuning, Gorilla leverages a “retrieval-aware” fine-tuning variant. This might
    sound fancy, but the practical implementation is simple! For every call to a model
    API in the fine-tuning dataset, we add up-to-date documentation for this API within
    the data. Then, we follow a similar approach at test-time by appending API documentation
    to our prompt, which teaches the LLM to dynamically determine the proper usage
    of each API based on documentation; see below.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**检索感知的微调。** 不同于执行“普通”的监督微调，Gorilla 利用了一种“检索感知”的微调变体。这听起来可能很高端，但实际实现非常简单！对于微调数据集中的每次模型
    API 调用，我们在数据中添加了最新的 API 文档。然后，我们在测试时采取类似的方法，将 API 文档附加到我们的提示中，这教会 LLM 动态确定每个 API
    的正确使用方法；见下文。'
- en: '![](../Images/36060ed2f73a3f72ec7d533b20cf9814.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/36060ed2f73a3f72ec7d533b20cf9814.png)'
- en: (from [3])
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: (来源 [3])
- en: 'Retrieval aware fine-tuning is a technique that teaches the LLM to better leverage
    API documentation when determining how to solve a problem. Such a dynamic approach
    allows the LLM to:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 检索感知微调是一种技术，教会 LLM 在确定如何解决问题时更好地利用 API 文档。这种动态方法允许 LLM：
- en: Adapt to real-time changes in an API’s documentation at test time
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在测试时适应 API 文档中的实时变化
- en: Develop improved [in-context learning](https://cameronrwolfe.substack.com/i/123558334/different-types-of-learning)
    abilities for making API calls
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发展改进的 [上下文学习](https://cameronrwolfe.substack.com/i/123558334/different-types-of-learning)
    能力以进行 API 调用
- en: Hallucinate less by paying better attention to info in an API’s documentation
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过更好地关注 API 文档中的信息来减少幻觉
- en: '![](../Images/47b1634b19f3f7caa3cceb282398e98e.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47b1634b19f3f7caa3cceb282398e98e.png)'
- en: (from [3])
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (来源 [3])
- en: Retrieval-aware fine-tuning makes Gorilla an incredibly capable interface for
    leveraging a variety of different deep learning models — the resulting LLM can
    use a massive number of different APIs to solve a problem. Plus, *the model can
    actually adapt to changes in documentation for any of its APIs!* See the figure
    above for an example of adapting to changes in API documentation.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 检索感知的微调使 Gorilla 成为利用各种不同深度学习模型的极其强大的接口——生成的 LLM 可以使用大量不同的 API 来解决问题。此外，*模型实际上可以适应任何
    API 的文档变化！* 请参见上图以获取适应 API 文档变化的示例。
- en: '![](../Images/68e77fe9b67a30251f29b1f400d24524.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68e77fe9b67a30251f29b1f400d24524.png)'
- en: (from [3])
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: (来源 [3])
- en: '**Using Gorilla.** Although we know which API to include in the prompt when
    constructing the fine-tuning dataset, we don’t know the proper API to use when
    we receive an arbitrary prompt from a user during inference. To determine the
    correct API to use, we can just adopt an information retrieval technique that
    i*)* embeds the user’s prompt (or other relevant information) and *ii)* performs
    vector similarity search to find the most relevant API documentation. This way,
    we can easily and efficiently identify the best API to use for solving a problem.
    Alternatively, we could use Gorilla in a zero-shot manner by passing a user’s
    prompt directly to the model without any information retrieval or extra information.
    Either way, the goal of Gorilla is to generate an accurate call to the most appropriate
    API for solving a user’s prompt; see above.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用Gorilla。** 尽管我们知道在构建微调数据集时应该在提示中包含哪些API，但当我们在推理过程中接收到用户的任意提示时，并不知道应该使用哪个合适的API。为了确定正确的API，我们可以采用信息检索技术，*i)*
    嵌入用户的提示（或其他相关信息），以及 *ii)* 执行向量相似性搜索以找到最相关的API文档。通过这种方式，我们可以轻松高效地确定用于解决问题的最佳API。或者，我们可以通过将用户的提示直接传递给模型，而无需任何信息检索或额外信息，以零-shot
    方式使用Gorilla。无论哪种方式，Gorilla的目标都是生成准确的调用，以使用最合适的API来解决用户的提示；详见上文。'
- en: '![](../Images/1a77a531138ffceeffa423410151e21b.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a77a531138ffceeffa423410151e21b.png)'
- en: (from [3])
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [3]）
- en: As demonstrated by the experimental results above, Gorilla is an incredibly
    capable interface for deep learning APIs. Compared to larger and more powerful
    models (e.g., GPT-3.5, Claude, and GPT-4), we see that Gorilla is much more capable
    of generating accurate API calls, meaning that the model hallucinates calls to
    nonexistent API calls less and tends to pass correct input arguments!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如上实验结果所示，Gorilla是一个极其有能力的深度学习API接口。与更大、更强大的模型（例如GPT-3.5、Claude和GPT-4）相比，我们发现Gorilla在生成准确的API调用方面更具能力，这意味着模型产生虚假的API调用的情况较少，并且更倾向于传递正确的输入参数！
- en: Other notable techniques…
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他值得注意的技术……
- en: HuggingGPT [2] and Gorilla [3] have garnered a lot of public recognition and
    discussion over the last few months, but many other techniques have been proposed
    that consider using LLMs to coordinate efforts of several different deep learning
    models. A brief list of other interesting techniques is outlined below.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: HuggingGPT [2] 和 Gorilla [3] 在过去几个月中获得了大量公众认可和讨论，但也有许多其他技术被提出，考虑使用LLMs来协调多个不同深度学习模型的工作。下面概述了一些其他有趣的技术。
- en: '![](../Images/ddd333ea9879da314c195a681c3148c5.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ddd333ea9879da314c195a681c3148c5.png)'
- en: (from [7])
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [7]）
- en: '**TaskMatrix [7]** is a position paper — meaning that it presents a position
    or outlook on a notable issue — that considers the integration of [foundation
    models](https://crfm.stanford.edu/) (e.g., LLMs like ChatGPT) with millions of
    different APIs. Notably, this work argues that foundation models lack domain knowledge
    needed to accurately solve specialized tasks, but many existing, task-specific
    models are available that can solve a specified task with impressive accuracy.
    Integrating these specialized/expert models with an LLM may be difficult due to
    compatibility issues, but authors in [7] extensively discuss and consider the
    idea. In many ways, HuggingGPT and Gorilla are practical realization of ideas
    discussed in [7].'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**TaskMatrix [7]** 是一篇立场论文——这意味着它对一个显著问题提出了立场或观点——考虑了将[基础模型](https://crfm.stanford.edu/)（例如，像ChatGPT这样的LLMs）与数百万种不同的API进行集成。值得注意的是，这项工作认为基础模型缺乏解决专业任务所需的领域知识，但已有许多现有的、任务特定的模型可以以令人印象深刻的准确性解决指定的任务。由于兼容性问题，将这些专业/专家模型与LLM集成可能会很困难，但[7]中的作者广泛讨论并考虑了这一想法。在许多方面，HuggingGPT和Gorilla是[7]中讨论的想法的实际实现。'
- en: '![](../Images/1bc37f481090bf0c4c474d0b61a19a57.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1bc37f481090bf0c4c474d0b61a19a57.png)'
- en: (from [8])
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [8]）
- en: '**API Bank [8]** provides a better benchmark for evaluating tool-augmented
    LLMs. In particular, the benchmark considers over 50 APIs that are commonly integrated
    with LLMs and 264 annotated dialogues — including 568 API calls in total — to
    go along with these tools. The benchmark is designed to evaluate LLMs’ ability
    to create a task plan (i.e., step-by-step guide of which API calls to execute),
    determine the correct APIs to use, and execute API calls to answer a provided
    question. Unsurprisingly, preliminary experiments show that GPT-4 has the strongest
    capabilities in leveraging external tools to answer user-provided questions. Although
    this work does not consider deep learning model APIs in particular, the task framework
    used mirrors approaches seen in this overview.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**API Bank [8]** 提供了一个更好的基准来评估工具增强的LLM。特别是，该基准考虑了50多个通常与LLM集成的API和264个标注对话——包括总计568次API调用——以配合这些工具。该基准旨在评估LLM创建任务计划（即，逐步指南，说明要执行哪些API调用）、确定正确的API以及执行API调用以回答提供的问题的能力。毫无意外，初步实验显示，GPT-4在利用外部工具回答用户提供的问题方面具有最强的能力。尽管这项工作没有特别考虑深度学习模型API，但所使用的任务框架与本综述中看到的方法相似。'
- en: '![](../Images/040ed37bc0f391d1fb184eb01b925f77.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/040ed37bc0f391d1fb184eb01b925f77.png)'
- en: (from [9])
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [9]）
- en: '**ToolkenGPT [9]** attempts to mitigate fine-tuning requirements for tool-following
    foundation models by assigning a specific token — and associated [token embedding](https://twitter.com/cwolferesearch/status/1659608479089278978?s=20)
    — to each tool, allowing LLMs to generate tool requests in a similar manner to
    generating a normal word token. Such an approach is found to be quite flexible
    for leveraging a variety of external tools.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**ToolkenGPT [9]** 尝试通过为每个工具分配一个特定的令牌——以及相关的[token embedding](https://twitter.com/cwolferesearch/status/1659608479089278978?s=20)——来减轻工具跟随基础模型的微调要求，使LLM能够以类似生成普通词令牌的方式生成工具请求。这种方法被发现对于利用各种外部工具非常灵活。'
- en: '![](../Images/8a437ee2c50c80b2410ac08042356052.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a437ee2c50c80b2410ac08042356052.png)'
- en: (from [10])
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: （来自 [10]）
- en: '**Tool Manipulation with Open-Source LLMs [10].** In most cases, we see that
    closed-source LLMs (e.g., GPT-4) are more [steerable](https://twitter.com/cwolferesearch/status/1645535868021805056?s=20)
    and can, therefore, better manipulate external tools. In [10], however, the authors
    analyze whether open-source LLMs can be fine-tuned to match the performance of
    powerful, closed-source LLMs in this particular skill. A variety of open-source
    LLMs are refined using human feedback and supervision to improve their tool-following
    capabilities. Interestingly, we see that several open-source models can achieve
    competitive performance with GPT-4 given sufficient fine-tuning. In this overview,
    we have seen with models like Gorilla that open-source LLMs (e.g., LLaMA) are
    incredibly powerful given the correct fine-tuning procedure.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用开源LLM的工具操作 [10]。** 在大多数情况下，我们发现闭源LLM（例如，GPT-4）更具[可操控性](https://twitter.com/cwolferesearch/status/1645535868021805056?s=20)，因此能够更好地操作外部工具。然而，在
    [10] 中，作者分析了开源LLM是否可以通过微调来匹配强大闭源LLM在这一特定技能上的表现。各种开源LLM通过人类反馈和监督进行优化，以提升其工具跟随能力。有趣的是，我们看到在充分微调的情况下，若干开源模型可以与GPT-4达到竞争性表现。在本综述中，我们看到像Gorilla这样的模型表明，给定正确的微调程序，开源LLM（例如，LLaMA）可以非常强大。'
- en: Closing Remarks
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结束语
- en: “There is a clear and pressing need for a mechanism that can leverage foundation
    models to propose task solution outlines and then automatically match some of
    the sub-tasks in the outlines to the off-the-shelf models and systems with special
    functionalities to complete them.” *— from [7]*
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “目前迫切需要一种机制，可以利用基础模型提出任务解决方案的框架，然后自动将框架中的一些子任务与具有特殊功能的现成模型和系统进行匹配，以完成这些任务。”
    *— 来自 [7]*
- en: Within this overview, we have seen that LLM are capable of integrating with
    other deep learning models via their APIs. In the case of HuggingGPT [2], this
    can be done using an in-context learning approach, in which we prompt the LLM
    with descriptions of existing models and their functionality. Notably, however,
    HuggingGPT works best with powerful, closed-source models like ChatGPT. If we
    want to teach open-source models (e.g., LLaMA) to call deep learning model APIs
    when solving complex problems, we need to adopt a fine-tuning approach, as proposed
    by Gorilla [3]. Either way, these techniques are incredibly powerful, as they
    strike a balance between the strengths of narrow expert and foundation models.
    We can draw upon the power of both by relying upon LLMs to perform high-level
    reasoning and form problem-solving plans, while delegating certain sub-tasks to
    specialized models that are more reliable and accurate.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个概述中，我们已经看到，LLM 能够通过其 API 与其他深度学习模型集成。以 HuggingGPT [2] 为例，这可以通过一种上下文学习方法实现，其中我们向
    LLM 提供现有模型及其功能的描述。然而，值得注意的是，HuggingGPT 最适合与强大的闭源模型如 ChatGPT 一起使用。如果我们想要教会开源模型（例如，LLaMA）在解决复杂问题时调用深度学习模型
    API，我们需要采用 Gorilla [3] 提出的微调方法。无论如何，这些技术都非常强大，因为它们在狭窄专家模型和基础模型的优势之间取得了平衡。我们可以通过依赖
    LLM 进行高级推理和形成问题解决计划，同时将某些子任务委派给更可靠和准确的专业模型，从而发挥两者的优势。
- en: Connect with me!
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与我联系！
- en: Thanks so much for reading this article. I am [Cameron R. Wolfe](https://cameronrwolfe.me/),
    Director of AI at [Rebuy](https://www.rebuyengine.com/). I study the empirical
    and theoretical foundations of deep learning. If you liked this overview, subscribe
    to my [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/),
    where I help readers understand AI research via overviews of relevant topics from
    the ground up. You can also follow me on [X](https://twitter.com/cwolferesearch)
    and [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/), or
    check out my [other writings](https://medium.com/@wolfecameron) on medium!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢您阅读这篇文章。我是 [Cameron R. Wolfe](https://cameronrwolfe.me/)，[Rebuy](https://www.rebuyengine.com/)
    的 AI 总监。我研究深度学习的经验和理论基础。如果您喜欢这个概述，请订阅我的 [Deep (Learning) Focus newsletter](https://cameronrwolfe.substack.com/)，在这里我通过从基础上概述相关主题来帮助读者理解
    AI 研究。您还可以在 [X](https://twitter.com/cwolferesearch) 和 [LinkedIn](https://www.linkedin.com/in/cameron-r-wolfe-ph-d-04744a238/)
    上关注我，或者查看我在 Medium 上的 [其他文章](https://medium.com/@wolfecameron)！
- en: Bibliography
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Schick, Timo, et al. “Toolformer: Language models can teach themselves
    to use tools.” *arXiv preprint arXiv:2302.04761* (2023).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Schick, Timo, 等. “Toolformer: Language models can teach themselves to use
    tools.” *arXiv preprint arXiv:2302.04761* (2023).'
- en: '[2] Shen, Yongliang, et al. “Hugginggpt: Solving ai tasks with chatgpt and
    its friends in huggingface.” *arXiv preprint arXiv:2303.17580* (2023).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Shen, Yongliang, 等. “Hugginggpt: Solving ai tasks with chatgpt and its
    friends in huggingface.” *arXiv preprint arXiv:2303.17580* (2023).'
- en: '[3] Patil, Shishir G., et al. “Gorilla: Large Language Model Connected with
    Massive APIs.” *arXiv preprint arXiv:2305.15334* (2023).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Patil, Shishir G., 等. “Gorilla: Large Language Model Connected with Massive
    APIs.” *arXiv preprint arXiv:2305.15334* (2023).'
- en: '[4] Wei, Jason, et al. “Chain of thought prompting elicits reasoning in large
    language models.” *arXiv preprint arXiv:2201.11903* (2022).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Wei, Jason, 等. “Chain of thought prompting elicits reasoning in large language
    models.” *arXiv preprint arXiv:2201.11903* (2022).'
- en: '[5] Touvron, Hugo, et al. “Llama: Open and efficient foundation language models.”
    *arXiv preprint arXiv:2302.13971* (2023).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Touvron, Hugo, 等. “Llama: Open and efficient foundation language models.”
    *arXiv preprint arXiv:2302.13971* (2023).'
- en: '[6] Wang, Yizhong, et al. “Self-Instruct: Aligning Language Model with Self
    Generated Instructions.” *arXiv preprint arXiv:2212.10560* (2022).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Wang, Yizhong, 等. “Self-Instruct: Aligning Language Model with Self Generated
    Instructions.” *arXiv preprint arXiv:2212.10560* (2022).'
- en: '[7] Liang, Yaobo, et al. “Taskmatrix. ai: Completing tasks by connecting foundation
    models with millions of apis.” *arXiv preprint arXiv:2303.16434* (2023).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] Liang, Yaobo, 等. “Taskmatrix. ai: Completing tasks by connecting foundation
    models with millions of apis.” *arXiv preprint arXiv:2303.16434* (2023).'
- en: '[8] Li, Minghao, et al. “Api-bank: A benchmark for tool-augmented llms.” *arXiv
    preprint arXiv:2304.08244* (2023).'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] Li, Minghao, 等. “Api-bank: A benchmark for tool-augmented llms.” *arXiv
    preprint arXiv:2304.08244* (2023).'
- en: '[9] Hao, Shibo, et al. “ToolkenGPT: Augmenting Frozen Language Models with
    Massive Tools via Tool Embeddings.” *arXiv preprint arXiv:2305.11554* (2023).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] Hao, Shibo, 等. “ToolkenGPT: Augmenting Frozen Language Models with Massive
    Tools via Tool Embeddings.” *arXiv preprint arXiv:2305.11554* (2023).'
- en: '[10] Xu, Qiantong, et al. “On the Tool Manipulation Capability of Open-source
    Large Language Models.” *arXiv preprint arXiv:2305.16504* (2023).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] Xu, Qiantong, 等. “On the Tool Manipulation Capability of Open-source Large
    Language Models.” *arXiv preprint arXiv:2305.16504* (2023).'
- en: '[11] Wang, Yizhong, et al. “Self-Instruct: Aligning Language Model with Self
    Generated Instructions.” *arXiv preprint arXiv:2212.10560* (2022).'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[11] 王一中等人. “Self-Instruct: 将语言模型与自生成指令对齐.” *arXiv 预印本 arXiv:2212.10560* (2022)。'
- en: '[12] Taori, Rohan et al. “Stanford Alpaca: An Instruction-following LLaMA model.”
    (2023).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[12] 塔奥里等人. “斯坦福 Alpaca: 一种跟随指令的 LLaMA 模型.” (2023)。'
- en: '[13] Trivedi, Harsh, et al. “Interleaving Retrieval with Chain-of-Thought Reasoning
    for Knowledge-Intensive Multi-Step Questions.” *arXiv preprint arXiv:2212.10509*
    (2022).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[13] 特里维迪等人. “将检索与思维链推理交替用于知识密集型多步骤问题.” *arXiv 预印本 arXiv:2212.10509* (2022)。'
- en: '[14] Liu, Jiacheng, et al. “Generated knowledge prompting for commonsense reasoning.”
    *arXiv preprint arXiv:2110.08387* (2021).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[14] 刘嘉诚等人. “生成知识提示用于常识推理.” *arXiv 预印本 arXiv:2110.08387* (2021)。'
