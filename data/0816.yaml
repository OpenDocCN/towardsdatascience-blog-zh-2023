- en: 'Anomaly Detection using Sigma Rules (Part 4): Flux Capacitor Design'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Sigma 规则进行异常检测（第4部分）：Flux 电容器设计
- en: 原文：[https://towardsdatascience.com/anomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72?source=collection_archive---------12-----------------------#2023-03-02](https://towardsdatascience.com/anomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72?source=collection_archive---------12-----------------------#2023-03-02)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/anomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72?source=collection_archive---------12-----------------------#2023-03-02](https://towardsdatascience.com/anomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72?source=collection_archive---------12-----------------------#2023-03-02)
- en: We implement a Spark structured streaming stateful mapping function to handle
    temporal proximity correlations in cyber security logs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们实现了一个 Spark 结构化流式状态映射函数，以处理网络安全日志中的时间相关性。
- en: '[](https://medium.com/@jean-claude.cote?source=post_page-----70cb5c2cfb72--------------------------------)[![Jean-Claude
    Cote](../Images/aea2df9c7b95fc85cc336f64d64b0a76.png)](https://medium.com/@jean-claude.cote?source=post_page-----70cb5c2cfb72--------------------------------)[](https://towardsdatascience.com/?source=post_page-----70cb5c2cfb72--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----70cb5c2cfb72--------------------------------)
    [Jean-Claude Cote](https://medium.com/@jean-claude.cote?source=post_page-----70cb5c2cfb72--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jean-claude.cote?source=post_page-----70cb5c2cfb72--------------------------------)[![Jean-Claude
    Cote](../Images/aea2df9c7b95fc85cc336f64d64b0a76.png)](https://medium.com/@jean-claude.cote?source=post_page-----70cb5c2cfb72--------------------------------)[](https://towardsdatascience.com/?source=post_page-----70cb5c2cfb72--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----70cb5c2cfb72--------------------------------)
    [Jean-Claude Cote](https://medium.com/@jean-claude.cote?source=post_page-----70cb5c2cfb72--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F444ed0089012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72&user=Jean-Claude+Cote&userId=444ed0089012&source=post_page-444ed0089012----70cb5c2cfb72---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----70cb5c2cfb72--------------------------------)
    ·6 min read·Mar 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70cb5c2cfb72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72&user=Jean-Claude+Cote&userId=444ed0089012&source=-----70cb5c2cfb72---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F444ed0089012&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72&user=Jean-Claude+Cote&userId=444ed0089012&source=post_page-444ed0089012----70cb5c2cfb72---------------------post_header-----------)
    发布于 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----70cb5c2cfb72--------------------------------)
    · 6 分钟阅读 · 2023年3月2日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70cb5c2cfb72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72&user=Jean-Claude+Cote&userId=444ed0089012&source=-----70cb5c2cfb72---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70cb5c2cfb72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72&source=-----70cb5c2cfb72---------------------bookmark_footer-----------)![](../Images/40a85d33f19a0342f755fd98ac14df78.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70cb5c2cfb72&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fanomaly-detection-using-sigma-rules-part-4-flux-capacitor-design-70cb5c2cfb72&source=-----70cb5c2cfb72---------------------bookmark_footer-----------)![](../Images/40a85d33f19a0342f755fd98ac14df78.png)'
- en: Image by Robert Wilson from [Pixabay](https://pixabay.com/photos/large-vintage-variable-capacitor-2307278/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自 [Pixabay](https://pixabay.com/photos/large-vintage-variable-capacitor-2307278/)
    的 Robert Wilson
- en: This is the 4th article of our series. Refer to [part 1](/anomaly-detection-using-sigma-rules-part-1-leveraging-spark-sql-streaming-246900e95457)
    , [part 2](/anomaly-detection-using-sigma-rules-part-2-spark-stream-stream-join-6bb4734e912f)
    and [part 3](https://medium.com/towards-data-science/anomaly-detection-using-sigma-rules-part-3-temporal-correlation-using-bloom-filters-a45ffd5e9069)
    for some context.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们系列文章的第4篇。有关更多背景信息，请参考 [第1部分](/anomaly-detection-using-sigma-rules-part-1-leveraging-spark-sql-streaming-246900e95457)
    、[第2部分](/anomaly-detection-using-sigma-rules-part-2-spark-stream-stream-join-6bb4734e912f)
    和 [第3部分](https://medium.com/towards-data-science/anomaly-detection-using-sigma-rules-part-3-temporal-correlation-using-bloom-filters-a45ffd5e9069)。
- en: In this article, we will detail the design of a custom Spark flatMapWithGroupState
    function. We chose to write this function in Scala since Spark is itself written
    in Scala. We named this function Flux Capacitor. Electric capacitors accumulate
    electric charges and later release them. Similarly, our flatMapWithGroupState
    will accumulate tags (evaluated true/false Sigma expressions) and later release
    them.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将详细介绍自定义 Spark flatMapWithGroupState 函数的设计。我们选择用 Scala 编写这个函数，因为 Spark
    本身是用 Scala 编写的。我们将这个函数命名为 Flux Capacitor。电容器积累电荷并随后释放它们。类似地，我们的 flatMapWithGroupState
    将积累标签（评估为真/假的 Sigma 表达式），然后释放它们。
- en: Our Flux Capacitor function is easy to configure and let’s the user specify
    how and when each individual tag is stored and retrieved. In our implementation,
    we encapsulated the tag while updating and retrieving behavior in a tag evaluator
    class hierarchy.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 Flux Capacitor 函数易于配置，允许用户指定每个标签的存储和检索方式。在我们的实现中，我们将标签的更新和检索行为封装在一个标签评估器类层次结构中。
- en: Tag Evaluators
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标签评估器
- en: '![](../Images/84cc8f4d80932f84b4b0e86482e92afd.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/84cc8f4d80932f84b4b0e86482e92afd.png)'
- en: Unless otherwise specified, all tags will be evaluated by the transitory evaluator.
    This evaluator is a no-op, it simply passes the current tag value through. The
    cacheable evaluator is a base class capable of storing and retrieving tags in
    the bloom filter. This base class has two template methods, `makeBloomPutKey`
    and `makeBloomGetKey`, letting sub-classes dictate how tags are stored and retrieved.
    The default tag uses the same key to get and put values in the bloom. The key
    is simply the concatenation of the rule and tag name. When a user passes the following
    specification to the Flux Capacitor, default tag evaluator objects are create
    to handle storing and retrieval of the tags.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，所有标签将由过渡评估器进行评估。这个评估器是一个无操作的评估器，它仅仅将当前标签值传递出去。可缓存评估器是一个能够在布隆过滤器中存储和检索标签的基类。这个基类有两个模板方法，`makeBloomPutKey`
    和 `makeBloomGetKey`，让子类决定标签的存储和检索方式。默认标签使用相同的键在布隆过滤器中存取值。这个键只是规则和标签名称的拼接。当用户将以下规范传递给
    Flux Capacitor 时，将创建默认标签评估器对象来处理标签的存储和检索。
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We designed our Flux Capacitor specification to resemble Sigma rules. However,
    this specification only describe how tags are handled in the Flux Capacitor.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计的 Flux Capacitor 规范类似于 Sigma 规则。然而，这个规范仅描述了 Flux Capacitor 中标签的处理方式。
- en: 'The ordered evaluator specializes the default evaluator by introducing a “dependent
    tag”. The dependent tag has to be evaluated first, and only when the dependent
    tag is true will the ordered tag be in turn evaluated. This evaluator is used
    when the user specifies `ordered: true`.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '有序评估器通过引入“依赖标签”来专业化默认评估器。依赖标签必须首先被评估，只有当依赖标签为真时，有序标签才会被评估。当用户指定 `ordered: true`
    时，将使用此评估器。'
- en: The other side of the hierarchy handles parent/child relationships. Contrary
    to the default tag, the parent evaluator’s put key is made of `rule name + tag
    name + parent id` and the get key is made of `rule name + tag name + current id`.
    The specification for parent/child let the user specify which column name holds
    the parent ID and which column name holds the current message ID. In this example
    `parent_id` and `id` are the columns representing a parent/child relationship.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 层级结构的另一侧处理父子关系。与默认标签相反，父评估器的 put 键由 `规则名称 + 标签名称 + 父 ID` 组成，而 get 键由 `规则名称 +
    标签名称 + 当前 ID` 组成。父子关系的规范允许用户指定哪个列名包含父 ID，哪个列名包含当前消息 ID。在这个例子中，`parent_id` 和 `id`
    是表示父子关系的列。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As explained in our previous article, the ancestor evaluator specializes the
    parent evaluator by storing itself in the bloom thus propagating itself down the
    parent/child hierarchy.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一篇文章中所解释的，祖先评估器通过将自身存储在布隆过滤器中，从而沿父子层级传播自身，专业化了父评估器。
- en: Rule Evaluators
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规则评估器
- en: So far we’ve only applied one Sigma rule at a time. We did this intentionally
    to keep things simple. However, in reality we want to apply multiple Sigma rules
    simultaneously. When we process a log source and parse it’s contents, we want
    to apply all Sigma rules that apply it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只应用了一个Sigma规则。我们这样做是为了保持简单。然而，实际上我们希望同时应用多个Sigma规则。当我们处理日志源并解析其内容时，我们希望应用所有适用的Sigma规则。
- en: To keep things organized, we represent each rule and it’s associated tags in
    a column of type [MapType](https://spark.apache.org/docs/2.0.2/api/java/index.html?org%2Fapache%2Fspark%2Fsql%2Ftypes%2FMapType.html=).
    The keys in this map are the rule names and the values are maps of tag name to
    tag value (true/false).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持组织性，我们在[MapType](https://spark.apache.org/docs/2.0.2/api/java/index.html?org%2Fapache%2Fspark%2Fsql%2Ftypes%2FMapType.html=)类型的列中表示每个规则及其相关的标签。这个映射中的键是规则名称，值是标签名称到标签值（true/false）的映射。
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: By using maps, we can keep the schema of the input and output rows constant.
    Any new Sigma rule that is later introduce will simply be added to this map and
    will not affect the overall input and output row schemas.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用映射，我们可以保持输入和输出行的模式不变。任何稍后引入的新Sigma规则将简单地添加到这个映射中，而不会影响整体输入和输出行模式。
- en: Our Flux Capacitor specification reflects this. The specification applies to
    a list of rule names. Each of those rule specification state how to update the
    tags for that rule.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的Flux Capacitor规范反映了这一点。规范适用于一系列规则名称。每个规则规范都说明了如何更新该规则的标签。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In our implementation, each rule specification is handled by a class `Rule.`
    The `Rules` class valuates each `Rule` in turn.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实现中，每个规则规范由一个`Rule`类处理。`Rules`类依次评估每个`Rule`。
- en: The Mapping Function
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 映射函数
- en: 'The Spark Dataframe `flatMapGroupsWithState` invokes a user-provided function
    on each group while maintaining a user-defined per-group state between invocations.
    The signature of the function takes a key, an input row iterator (per group) and
    a state, and returns an output row iterator. Our Flux Capacitor function is as
    follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Dataframe `flatMapGroupsWithState`在每个组上调用用户提供的函数，同时在调用之间维护用户定义的每组状态。该函数的签名接受一个键、一个输入行迭代器（每组）和一个状态，并返回一个输出行迭代器。我们的Flux
    Capacitor函数如下：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The first time the function is called, we will have no state. In that case,
    we create a Guava bloom filter with a false positive probably of 1%.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次调用函数时，我们将没有状态。在这种情况下，我们创建一个假阳性概率为1%的Guava布隆过滤器。
- en: We then load the specification from a YAML string. We will see later how the
    user passes this specification to the function. The specification is parsed and
    provided to the `Rules`class. The `Rules`class creates the corresponding tag evaluators.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们从YAML字符串加载规范。稍后我们将看到用户如何将这个规范传递给函数。规范被解析并提供给`Rules`类。`Rules`类创建相应的标签评估器。
- en: Next, we apply the `evaluateRow` to every input row of this group of rows resulting
    in a list of output rows.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将`evaluateRow`应用于这一组输入行，生成一个输出行的列表。
- en: Invoking `evaluateRow` modifies the bloom filter (some of the tags will have
    been stored in the bloom). Thus, we persist the bloom using `state.update(bloom)`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`evaluateRow`会修改布隆过滤器（一些标签将被存储在布隆中）。因此，我们使用`state.update(bloom)`来持久化布隆。
- en: Finally, we return an iterator to the output rows.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们返回一个输出行的迭代器。
- en: Applying the Flux Capacitor
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用Flux Capacitor
- en: From a users perspective, using the Flux Capacitor to perform anomaly detection
    is quite simple.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户的角度来看，使用Flux Capacitor进行异常检测是非常简单的。
- en: Let’s suppose the user has already created a dataframe `taggedEventsDF`. In
    later articles, we will show how the sigma compiler can be leveraged to create
    this dataframe.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 假设用户已经创建了一个dataframe `taggedEventsDF`。在后续的文章中，我们将展示如何利用sigma编译器创建这个dataframe。
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once the FluxCapacitorMapFunction is created, it needs to be passed to the Spark
    `flatMapGroupsWithState`. The user also needs to specify which of the columns
    holds the host ID.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了FluxCapacitorMapFunction，它需要传递给Spark的`flatMapGroupsWithState`。用户还需要指定哪个列包含主机ID。
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We associate a bloom per host, so our grouping key `groupByKey`is the `host_id`column.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个主机关联一个布隆过滤器，因此我们的分组键`groupByKey`是`host_id`列。
- en: Spark needs to know how to serialize and deserialize the state. We create Spark
    encoders for the output rows and for the bloom filter (state).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Spark需要知道如何序列化和反序列化状态。我们为输出行和布隆过滤器（状态）创建Spark编码器。
- en: We specify a mode of Append, rather than Update or Complete. In Append mode,
    every row we output is added to the result table which is desired in anomaly detections.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定了一种附加模式，而不是更新或完成。在附加模式下，我们输出的每一行都被添加到结果表中，这在异常检测中是所期望的。
- en: Finally, we pass our `flux.processBatch` to the `flatMapGroupsWithState` function.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将我们的`flux.processBatch`传递给`flatMapGroupsWithState`函数。
- en: Conclusion
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this article we showed how we implemented a configurable and re-usable stateful
    mapping function capable of handling multiple use cases: temporal proximity correlation
    (ordered and un-ordered) and parent/child relationships (including ancestors).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们展示了如何实现一个可配置且可重用的有状态映射函数，能够处理多种用例：时间邻近相关性（有序和无序）以及父子关系（包括祖先）。
- en: Currently, our state never times out, we are always using the same bloom filter,
    thus the bloom filter will eventually fill up. In our next article, we will address
    this issue with a forgetful bloom filer and optimize the performance of the Flux
    Capacitor.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们的状态永远不会超时，我们始终使用相同的布隆过滤器，因此布隆过滤器最终会被填满。在我们的下一篇文章中，我们将用一个会忘记的布隆过滤器来解决这个问题，并优化Flux
    Capacitor的性能。
- en: All images unless otherwise noted are by the author
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除非另有说明，所有图片均由作者提供
