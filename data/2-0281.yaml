- en: All You Need to Know about In-Context Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äº†è§£ä¸Šä¸‹æ–‡å­¦ä¹ çš„æ‰€æœ‰ä¿¡æ¯
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/all-you-need-to-know-about-in-context-learning-55bde1180610](https://towardsdatascience.com/all-you-need-to-know-about-in-context-learning-55bde1180610)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/all-you-need-to-know-about-in-context-learning-55bde1180610](https://towardsdatascience.com/all-you-need-to-know-about-in-context-learning-55bde1180610)
- en: '| IN CONTEXT LEARNING | LARGE LANGUAGE MODELS| LLMs'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '| ä¸Šä¸‹æ–‡å­¦ä¹  | å¤§å‹è¯­è¨€æ¨¡å‹ | LLMs'
- en: What is and how does it work what makes Large Language Models so powerful
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelsï¼‰ï¼Œå®ƒä»¬æ˜¯å¦‚ä½•è¿ä½œçš„ï¼Œä½¿å…¶å¦‚æ­¤å¼ºå¤§çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)[](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)[](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)
    Â·19 min readÂ·Jul 25, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[æ•°æ®ç§‘å­¦å‰æ²¿](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)
    Â·é˜…è¯»æ—¶é—´19åˆ†é’ŸÂ·2023å¹´7æœˆ25æ—¥
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/7f1b46371aebe6ca8e4684f7f9be78fa.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f1b46371aebe6ca8e4684f7f9be78fa.png)'
- en: Photo by [ğŸ‡¸ğŸ‡® Janko FerliÄ](https://unsplash.com/ko/@itfeelslikefilm?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[ğŸ‡¸ğŸ‡® Janko FerliÄ](https://unsplash.com/ko/@itfeelslikefilm?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: â€œFor me context is the key â€” from that comes the understanding of everything.â€
    â€” Kenneth Noland
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œå¯¹æˆ‘æ¥è¯´ï¼Œä¸Šä¸‹æ–‡æ˜¯å…³é”®â€”â€”ä»ä¸­äº§ç”Ÿäº†å¯¹ä¸€åˆ‡çš„ç†è§£ã€‚â€ â€” **è‚¯å°¼æ–¯Â·è¯ºå…°**
- en: In-context learning (ICL) is one of the most surprising model skills. Observed
    with GPT-3 it caught the authorsâ€™ attention. **Exactly what is ICL? More importantly,
    what gives rise to it?**
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ˜¯æœ€ä»¤äººæƒŠè®¶çš„æ¨¡å‹æŠ€èƒ½ä¹‹ä¸€ã€‚è§‚å¯Ÿåˆ°GPT-3æ—¶å¼•èµ·äº†ä½œè€…çš„æ³¨æ„ã€‚**ICLåˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿæ›´é‡è¦çš„æ˜¯ï¼Œæ˜¯ä»€ä¹ˆä¿ƒä½¿äº†å®ƒçš„äº§ç”Ÿï¼Ÿ**
- en: 'This article is divided into different sections, for each section we will answer
    these questions:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡åˆ†ä¸ºä¸åŒçš„éƒ¨åˆ†ï¼Œæ¯éƒ¨åˆ†å°†å›ç­”è¿™äº›é—®é¢˜ï¼š
- en: What is In-Context Learning (ICL)? Why this is interesting? Why it is useful?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ï¼Ÿä¸ºä»€ä¹ˆè¿™å¾ˆæœ‰è¶£ï¼Ÿå®ƒæœ‰ä»€ä¹ˆç”¨å¤„ï¼Ÿ
- en: 'The mystery of ICL: how does it work? Is the training data? is the prompt?
    it is the architecture?'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICLçš„å¥¥ç§˜ï¼šå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿæ˜¯è®­ç»ƒæ•°æ®ï¼Ÿæ˜¯æç¤ºï¼Ÿè¿˜æ˜¯æ¶æ„ï¼Ÿ
- en: What is the future of ICL? What are the remaining challenges?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICLçš„æœªæ¥æ˜¯ä»€ä¹ˆï¼Ÿè¿˜å­˜åœ¨å“ªäº›æŒ‘æˆ˜ï¼Ÿ
- en: Check the list of references at the end of the article, I provide also some
    suggestions to deepen the topics.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹æ–‡ç« æœ«å°¾çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼Œæˆ‘ä¹Ÿæä¾›äº†ä¸€äº›å»ºè®®ï¼Œä»¥ä¾¿æ·±å…¥æ¢è®¨è¿™äº›ä¸»é¢˜ã€‚
- en: What is In-Context Learning (ICL)?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ï¼Ÿ
- en: '![](../Images/4b4d54bbb67cef241a1909f3d3526037.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b4d54bbb67cef241a1909f3d3526037.png)'
- en: Photo by [Dmitry Ratushny](https://unsplash.com/@ratushny?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[Dmitry Ratushny](https://unsplash.com/@ratushny?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: â€œThe limits of my language mean the limits of my world.â€ â€” Ludwig Wittgenstein
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œæˆ‘çš„è¯­è¨€çš„é™åˆ¶æ„å‘³ç€æˆ‘çš„ä¸–ç•Œçš„é™åˆ¶ã€‚â€ â€” **è·¯å¾·ç»´å¸ŒÂ·ç»´ç‰¹æ ¹æ–¯å¦**
- en: Before [Large Language Models](https://en.wikipedia.org/wiki/Large_language_mode)
    (LLMs) were published, an artificial intelligence model was limited to the data
    it was trained on. In other words, [LLMs](https://en.wikipedia.org/wiki/Large_language_model)
    could only solve tasks for which their training was designed.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[å¤§å‹è¯­è¨€æ¨¡å‹](https://en.wikipedia.org/wiki/Large_language_mode)ï¼ˆLLMsï¼‰å‘å¸ƒä¹‹å‰ï¼Œäººå·¥æ™ºèƒ½æ¨¡å‹ä»…é™äºå…¶è®­ç»ƒæ•°æ®ã€‚æ¢å¥è¯è¯´ï¼Œ[LLMs](https://en.wikipedia.org/wiki/Large_language_model)åªèƒ½è§£å†³ä¸ºå…¶è®­ç»ƒè®¾è®¡çš„ä»»åŠ¡ã€‚
- en: '[GPT-3](https://arxiv.org/abs/2005.14165) and todayâ€™s [LLMs](https://en.wikipedia.org/wiki/Large_language_mode),
    on the other hand, show a new capability: the ability to learn new skills and
    solve new tasks simply by providing new examples in the input (prompt). Also,
    in this case, we are not training the model; there is no [gradient update](https://en.wikipedia.org/wiki/Gradient_descent)
    or change in model parameters. This skill is called [In-Context Learning (ICL)](https://en.wikipedia.org/wiki/Prompt_engineering).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€æ–¹é¢ï¼Œ[GPT-3](https://arxiv.org/abs/2005.14165)å’Œä»Šå¤©çš„[LLMs](https://en.wikipedia.org/wiki/Large_language_mode)å±•ç¤ºäº†ä¸€ç§æ–°èƒ½åŠ›ï¼šé€šè¿‡åœ¨è¾“å…¥ï¼ˆæç¤ºï¼‰ä¸­æä¾›æ–°çš„ç¤ºä¾‹æ¥å­¦ä¹ æ–°æŠ€èƒ½å’Œè§£å†³æ–°ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰è®­ç»ƒæ¨¡å‹ï¼›æ²¡æœ‰[æ¢¯åº¦æ›´æ–°](https://en.wikipedia.org/wiki/Gradient_descent)æˆ–æ¨¡å‹å‚æ•°çš„å˜åŒ–ã€‚è¿™é¡¹æŠ€èƒ½è¢«ç§°ä¸º[ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰](https://en.wikipedia.org/wiki/Prompt_engineering)ã€‚
- en: '![](../Images/b4e3700d502d9da8a95015beac0410c8.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b4e3700d502d9da8a95015beac0410c8.png)'
- en: 'image source: [here](https://arxiv.org/abs/2005.14165)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2005.14165)
- en: To be more specific, the way to interact with a model is to provide natural
    language instructions in a prompt. Although this may seem limited, different examples
    up to a certain number of [tokens](https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens)
    ([context windows](https://www.linkedin.com/pulse/whats-context-window-anyway-caitie-doogan-phd/))
    can be entered in a prompt. In addition, despite being placed in this textual
    template, it can also allow the model [to solve mathematical exercises](https://arxiv.org/abs/2212.10535).
    In fact, in the prompt, we can insert examples of word corrections, arithmetic
    exercises, translations, programming, and whatnot.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å…·ä½“æ¥è¯´ï¼Œä¸æ¨¡å‹äº¤äº’çš„æ–¹å¼æ˜¯æä¾›è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä½œä¸ºæç¤ºã€‚è™½ç„¶è¿™å¯èƒ½çœ‹èµ·æ¥æœ‰é™ï¼Œä½†å¯ä»¥åœ¨æç¤ºä¸­è¾“å…¥ä¸€å®šæ•°é‡çš„[ä»¤ç‰Œ](https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/tokens)ï¼ˆ[ä¸Šä¸‹æ–‡çª—å£](https://www.linkedin.com/pulse/whats-context-window-anyway-caitie-doogan-phd/)ï¼‰ã€‚æ­¤å¤–ï¼Œå°½ç®¡å¤„äºè¿™ä¸ªæ–‡æœ¬æ¨¡æ¿ä¸­ï¼Œå®ƒä¹Ÿå¯ä»¥å…è®¸æ¨¡å‹[è§£å†³æ•°å­¦é¢˜](https://arxiv.org/abs/2212.10535)ã€‚äº‹å®ä¸Šï¼Œåœ¨æç¤ºä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ’å…¥å•è¯çº æ­£ã€ç®—æœ¯ç»ƒä¹ ã€ç¿»è¯‘ã€ç¼–ç¨‹ç­‰ç¤ºä¾‹ã€‚
- en: '![](../Images/668ff5c0b2b29f0af73c35b6890623ca.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/668ff5c0b2b29f0af73c35b6890623ca.png)'
- en: 'image source: [here](https://arxiv.org/abs/2301.00234)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2301.00234)
- en: 'Now, we can give a formal definition of what is [ICL](https://en.wikipedia.org/wiki/Prompt_engineering):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç»™å‡º[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)çš„æ­£å¼å®šä¹‰ï¼š
- en: In-context learning is a paradigm that allows language models to learn tasks
    given only a few examples in the form of demonstration. ([source](https://arxiv.org/abs/2301.00234))
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ä¸Šä¸‹æ–‡å­¦ä¹ æ˜¯ä¸€ç§èŒƒå¼ï¼Œå®ƒå…è®¸è¯­è¨€æ¨¡å‹ä»…é€šè¿‡å‡ ä¸ªç¤ºä¾‹è¿›è¡Œä»»åŠ¡å­¦ä¹ ï¼ˆ[æ¥æº](https://arxiv.org/abs/2301.00234)ï¼‰ã€‚
- en: Simply put, by giving a model a list of input-output pairs that demonstrate
    a task, the model reads the training examples to figure out the input and output
    distribution, manages to map the inputs and outputs, and generates an appropriate
    response.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€å•æ¥è¯´ï¼Œé€šè¿‡ç»™æ¨¡å‹ä¸€ç»„å±•ç¤ºä»»åŠ¡çš„è¾“å…¥è¾“å‡ºå¯¹ï¼Œæ¨¡å‹é˜…è¯»è®­ç»ƒç¤ºä¾‹ä»¥æ‰¾å‡ºè¾“å…¥å’Œè¾“å‡ºçš„åˆ†å¸ƒï¼ŒæˆåŠŸæ˜ å°„è¾“å…¥å’Œè¾“å‡ºï¼Œå¹¶ç”Ÿæˆé€‚å½“çš„å“åº”ã€‚
- en: '[As shown in this study](https://arxiv.org/abs/2211.09066) that this simple
    idea helps the model to perform certain tasks more easily. Explaining the model
    with unambiguous instructions on how to perform the tasks allows the model to
    better understand and perform the tasks more easily. Using these few examples
    is then competitive ([ICL](https://en.wikipedia.org/wiki/Prompt_engineering))
    is competitive against training models with many more labeled data.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¦‚æœ¬ç ”ç©¶æ‰€ç¤º](https://arxiv.org/abs/2211.09066)ï¼Œè¿™ä¸€ç®€å•çš„æƒ³æ³•æœ‰åŠ©äºæ¨¡å‹æ›´è½»æ¾åœ°æ‰§è¡ŒæŸäº›ä»»åŠ¡ã€‚é€šè¿‡ç”¨æ˜ç¡®çš„æŒ‡ä»¤è§£é‡Šå¦‚ä½•æ‰§è¡Œä»»åŠ¡ï¼Œå¯ä»¥ä½¿æ¨¡å‹æ›´å¥½åœ°ç†è§£å¹¶æ›´è½»æ¾åœ°æ‰§è¡Œè¿™äº›ä»»åŠ¡ã€‚ä½¿ç”¨è¿™äº›å°‘é‡ç¤ºä¾‹ç›¸è¾ƒäºä½¿ç”¨æ›´å¤šæ ‡è®°æ•°æ®è®­ç»ƒæ¨¡å‹å…·æœ‰ç«äº‰åŠ›ï¼ˆ[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ï¼‰ã€‚'
- en: This has led to the emergence of various strategies to exploit [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    (prompt engineering) since changing the prompt allows for better performance than
    [having to do fine-tuning for a specific task](https://arxiv.org/abs/2211.09066).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¿ƒä½¿äº†å„ç§ç­–ç•¥çš„å‡ºç°ï¼Œä»¥åˆ©ç”¨[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ï¼ˆæç¤ºå·¥ç¨‹ï¼‰ï¼Œå› ä¸ºæ”¹å˜æç¤ºèƒ½å¤Ÿæ¯”[ä¸ºç‰¹å®šä»»åŠ¡è¿›è¡Œå¾®è°ƒ](https://arxiv.org/abs/2211.09066)è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚
- en: '![](../Images/8c175a1a8e3657a5f80c1019545eaedb.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c175a1a8e3657a5f80c1019545eaedb.png)'
- en: 'image source: [here](https://arxiv.org/abs/2211.09066)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2211.09066)
- en: '[](/speak-to-me-how-many-words-a-model-is-reading-331e3af86d27?source=post_page-----55bde1180610--------------------------------)
    [## Speak to me: How many words a model is reading'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/speak-to-me-how-many-words-a-model-is-reading-331e3af86d27?source=post_page-----55bde1180610--------------------------------)
    [## å‘Šè¯‰æˆ‘ï¼šæ¨¡å‹æ­£åœ¨é˜…è¯»å¤šå°‘å•è¯]'
- en: Why and how to overcome the inner limit of a Large Language Model
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆä»¥åŠå¦‚ä½•å…‹æœå¤§å‹è¯­è¨€æ¨¡å‹çš„å†…åœ¨é™åˆ¶
- en: towardsdatascience.com](/speak-to-me-how-many-words-a-model-is-reading-331e3af86d27?source=post_page-----55bde1180610--------------------------------)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[åœ¨å¦‚ä½•é˜…è¯»æ¨¡å‹çš„å•è¯æ•°é‡](/speak-to-me-how-many-words-a-model-is-reading-331e3af86d27?source=post_page-----55bde1180610--------------------------------)'
- en: '[This behavior also seems to emerge only at scale](https://arxiv.org/abs/2206.07682),
    i.e., it appears that [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    emerges [only with a certain number of parameters](https://en.wikipedia.org/wiki/Neural_scaling_law).
    In fact, for some capabilities, it appears that the model has random performance
    up to a certain number of parameters, and then abruptly its performance improves.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¿™ç§è¡Œä¸ºä¼¼ä¹ä¹Ÿä»…åœ¨è§„æ¨¡æ‰©å¤§æ—¶å‡ºç°](https://arxiv.org/abs/2206.07682)ï¼Œå³ï¼Œ[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ä¼¼ä¹ä»…åœ¨[å‚æ•°æ•°é‡è¾¾åˆ°ä¸€å®šæ°´å¹³](https://en.wikipedia.org/wiki/Neural_scaling_law)æ—¶å‡ºç°ã€‚å®é™…ä¸Šï¼Œå¯¹äºæŸäº›èƒ½åŠ›ï¼Œæ¨¡å‹çš„è¡¨ç°ä¼¼ä¹åœ¨è¾¾åˆ°æŸä¸ªå‚æ•°æ•°é‡ä¹‹å‰æ˜¯éšæœºçš„ï¼Œç„¶åçªç„¶æœ‰æ‰€æ”¹å–„ã€‚'
- en: '![](../Images/fd41f594bcec315652fa7c8f69a46357.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd41f594bcec315652fa7c8f69a46357.png)'
- en: 'image source: [here](https://arxiv.org/abs/2206.07682)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2206.07682)
- en: '[](/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9?source=post_page-----55bde1180610--------------------------------)
    [## Emergent Abilities in AI: Are We Chasing a Myth?'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[## AIä¸­çš„æ–°å…´èƒ½åŠ›ï¼šæˆ‘ä»¬åœ¨è¿½é€ä¸€ä¸ªç¥è¯å—ï¼Ÿ](/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9?source=post_page-----55bde1180610--------------------------------)'
- en: Changing Perspective on Large Language Models emerging properties
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä»æ–°å…´å±æ€§çš„è§’åº¦çœ‹å¤§å‹è¯­è¨€æ¨¡å‹
- en: towardsdatascience.com](/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9?source=post_page-----55bde1180610--------------------------------)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[åœ¨AIä¸­çš„æ–°å…´èƒ½åŠ›ï¼šæˆ‘ä»¬åœ¨è¿½é€ä¸€ä¸ªç¥è¯å—ï¼Ÿ](/emergent-abilities-in-ai-are-we-chasing-a-myth-fead754a1bf9?source=post_page-----55bde1180610--------------------------------)'
- en: 'In brief, behavior is both researched and studied because [it has definite
    advantages](https://arxiv.org/abs/2301.00234):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€è€Œè¨€ä¹‹ï¼Œè¡Œä¸ºä¹‹æ‰€ä»¥è¢«ç ”ç©¶å’Œå­¦ä¹ ï¼Œæ˜¯å› ä¸º[å®ƒæœ‰æ˜æ˜¾çš„ä¼˜åŠ¿](https://arxiv.org/abs/2301.00234)ï¼š
- en: The examples are written in natural language, so communication with the template
    is interpretable and understandable to humans. it is much easier to integrate
    human knowledge because you only need to change the prompt.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ä»¥è‡ªç„¶è¯­è¨€ç¼–å†™ï¼Œå› æ­¤ä¸æ¨¡æ¿çš„é€šä¿¡æ˜¯å¯è§£é‡Šä¸”æ˜“äºç†è§£çš„ã€‚æ•´åˆäººç±»çŸ¥è¯†è¦å®¹æ˜“å¾—å¤šï¼Œå› ä¸ºä½ åªéœ€æ›´æ”¹æç¤ºå³å¯ã€‚
- en: Also [in context learnin](https://en.wikipedia.org/wiki/Prompt_engineering)g
    it remembers how humans learn because it recalls the process of learning by [analogy](https://en.wikipedia.org/wiki/Analogy).
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¦å¤–ï¼Œ[ä¸Šä¸‹æ–‡å­¦ä¹ ](https://en.wikipedia.org/wiki/Prompt_engineering)è®°å¿†äº†äººç±»çš„å­¦ä¹ æ–¹å¼ï¼Œå› ä¸ºå®ƒå›å¿†äº†é€šè¿‡[ç±»æ¯”](https://en.wikipedia.org/wiki/Analogy)çš„å­¦ä¹ è¿‡ç¨‹ã€‚
- en: it is training-free, we do not have to train the model (unlike [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning)).
    This means it is much cheaper as a [computational cost](https://en.wikipedia.org/wiki/Computational_complexity).
    This is really efficient since the skill can be acquired instantly.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®ƒæ˜¯æ— è®­ç»ƒçš„ï¼Œæˆ‘ä»¬ä¸éœ€è¦è®­ç»ƒæ¨¡å‹ï¼ˆä¸[ç›‘ç£å­¦ä¹ ](https://en.wikipedia.org/wiki/Supervised_learning)ä¸åŒï¼‰ã€‚è¿™æ„å‘³ç€å®ƒåœ¨[è®¡ç®—æˆæœ¬](https://en.wikipedia.org/wiki/Computational_complexity)ä¸Šè¦ä¾¿å®œå¾—å¤šã€‚è¿™éå¸¸é«˜æ•ˆï¼Œå› ä¸ºæŠ€èƒ½å¯ä»¥ç«‹å³è·å¾—ã€‚
- en: It also means that the model can be used as-a-service, and can thus be deployed
    for many tasks. In fact, the tasks can be taught by everyday users.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿæ„å‘³ç€æ¨¡å‹å¯ä»¥ä½œä¸ºæœåŠ¡ä½¿ç”¨ï¼Œå› æ­¤å¯ä»¥éƒ¨ç½²ç”¨äºè®¸å¤šä»»åŠ¡ã€‚å®é™…ä¸Šï¼Œè¿™äº›ä»»åŠ¡å¯ä»¥ç”±æ—¥å¸¸ç”¨æˆ·æ•™æˆã€‚
- en: '[ICL](https://en.wikipedia.org/wiki/Prompt_engineering) provides the model
    to [generalize](https://developers.google.com/machine-learning/crash-course/generalization/video-lecture),
    allowing the model to learn underlying patterns and rules that are present in
    the examples and then apply them to new situations. Moreover, it provides the
    model with versatility, since it can be applied to many different types of skills.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ä½¿æ¨¡å‹èƒ½å¤Ÿ[æ³›åŒ–](https://developers.google.com/machine-learning/crash-course/generalization/video-lecture)ï¼Œå…è®¸æ¨¡å‹å­¦ä¹ ç¤ºä¾‹ä¸­çš„æ½œåœ¨æ¨¡å¼å’Œè§„åˆ™ï¼Œç„¶åå°†å…¶åº”ç”¨äºæ–°æƒ…å†µã€‚æ­¤å¤–ï¼Œå®ƒè¿˜ä¸ºæ¨¡å‹æä¾›äº†å¤šæ ·æ€§ï¼Œå› ä¸ºå®ƒå¯ä»¥åº”ç”¨äºè®¸å¤šä¸åŒç±»å‹çš„æŠ€èƒ½ã€‚'
- en: It looks amazing, but how it works?
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥å¾ˆæƒŠäººï¼Œä½†å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ
- en: 'The mystery of ICL: how does it work?'
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ICLçš„è°œå›¢ï¼šå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ
- en: '![](../Images/c9a184a494833d37feeb23b3928d720c.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9a184a494833d37feeb23b3928d720c.png)'
- en: Photo by [ğ“´ğ“˜ğ“¡ğ“š ğ•ğ”¸ğ•€](https://unsplash.com/@kirklai?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±[ğ“´ğ“˜ğ“¡ğ“š ğ•ğ”¸ğ•€](https://unsplash.com/@kirklai?utm_source=medium&utm_medium=referral)æä¾›ï¼Œæ¥æºäº[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: â€œUsually, if you want to fine-tune these models, you need to collect domain-specific
    data and do some complex engineering. But now we can just feed it an input, five
    examples, and it accomplishes what we want. So, in-context learning is an unreasonably
    efficient learning phenomenon that needs to be understood,â€ AkyÃ¼rek says. ([source](https://news.mit.edu/2023/large-language-models-in-context-learning-0207))
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œé€šå¸¸ï¼Œå¦‚æœä½ æƒ³å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½ éœ€è¦æ”¶é›†ç‰¹å®šé¢†åŸŸçš„æ•°æ®å¹¶è¿›è¡Œä¸€äº›å¤æ‚çš„å·¥ç¨‹å·¥ä½œã€‚ä½†ç°åœ¨æˆ‘ä»¬åªéœ€è¾“å…¥äº”ä¸ªç¤ºä¾‹ï¼Œå®ƒå°±èƒ½å®Œæˆæˆ‘ä»¬æƒ³è¦çš„ç»“æœã€‚æ‰€ä»¥ï¼Œ*ä¸Šä¸‹æ–‡å­¦ä¹ *æ˜¯ä¸€ç§å¼‚å¸¸é«˜æ•ˆçš„å­¦ä¹ ç°è±¡ï¼Œéœ€è¦åŠ ä»¥ç†è§£ï¼Œâ€AkyÃ¼rekè¯´ã€‚
    ([source](https://news.mit.edu/2023/large-language-models-in-context-learning-0207))
- en: 'As much as [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) seems almost
    magical, it also has its limitations. [GPT-3](https://en.wikipedia.org/wiki/GPT-3)
    for example had shown what seemed incredible reasoning capabilities. Yet some
    datasets that required reasoning, such as the Winograd dataset did not show [ICL](https://en.wikipedia.org/wiki/Prompt_engineering):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡*[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)*ä¼¼ä¹å‡ ä¹æ˜¯ç¥å¥‡çš„ï¼Œä½†å®ƒä¹Ÿæœ‰å…¶å±€é™æ€§ã€‚ä¾‹å¦‚ï¼Œ[GPT-3](https://en.wikipedia.org/wiki/GPT-3)å±•ç¤ºäº†çœ‹ä¼¼æƒŠäººçš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä¸€äº›éœ€è¦æ¨ç†çš„æ•°æ®é›†ï¼Œä¾‹å¦‚
    Winograd æ•°æ®é›†ï¼Œå¹¶æ²¡æœ‰æ˜¾ç¤º*[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)*çš„æ•ˆæœï¼š
- en: A Winograd schema is a pair of sentences that differ in only one or two words
    and that contain an ambiguity that is resolved in opposite ways in the two sentences
    and requires the use of world knowledge and reasoning for its resolution. ([source](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html))
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Winograd æ–¹æ¡ˆæ˜¯ä¸€å¯¹ä»…åœ¨ä¸€ä¸¤ä¸ªè¯ä¸Šæœ‰æ‰€ä¸åŒçš„å¥å­ï¼Œè¿™äº›å¥å­ä¸­åŒ…å«äº†ä¸€ä¸ªæ¨¡ç³Šæ€§ï¼Œè¯¥æ¨¡ç³Šæ€§åœ¨ä¸¤ä¸ªå¥å­ä¸­ä»¥ç›¸åçš„æ–¹å¼å¾—åˆ°è§£å†³ï¼Œå¹¶ä¸”éœ€è¦ä½¿ç”¨ä¸–ç•ŒçŸ¥è¯†å’Œæ¨ç†æ¥è§£å†³ã€‚
    ([source](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html))
- en: In fact, there was no improvement with the use of a few examples in the prompt.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: äº‹å®ä¸Šï¼Œä½¿ç”¨å‡ ä¸ªç¤ºä¾‹è¿›è¡Œæç¤ºå¹¶æ²¡æœ‰å¸¦æ¥æ”¹è¿›ã€‚
- en: '![](../Images/77e88cac98ec8e0f298a32e423cc5387.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/77e88cac98ec8e0f298a32e423cc5387.png)'
- en: 'image source: [here](https://arxiv.org/abs/2005.14165)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2005.14165)
- en: 'These facts and other seemingly contradictory behaviors have led researchers
    to ask: **where does ICL originate? Why works better than fine-tuning? Can ICL
    be improved by changing the prompt?**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›äº‹å®å’Œå…¶ä»–çœ‹ä¼¼çŸ›ç›¾çš„è¡Œä¸ºä½¿ç ”ç©¶äººå‘˜æå‡ºäº†é—®é¢˜ï¼š**ICLçš„èµ·æºæ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå®ƒæ¯”å¾®è°ƒæ›´æœ‰æ•ˆï¼Ÿé€šè¿‡æ”¹å˜æç¤ºï¼ŒICLèƒ½å¦å¾—åˆ°æ”¹å–„ï¼Ÿ**
- en: Meanwhile, one must remember that most skills are learned during pre-training.
    The first step of training an [LLM](https://en.wikipedia.org/wiki/Large_language_model)
    that requires huge amounts of text and is typically conducted by simply asking
    the model to predict a word in a sequence given the previous part of the sequence.
    This step is the most expensive, time-consuming, and resource-intensive one. During
    [alignment](https://jasonwei20.github.io/files/FLAN%20talk%20external.pdf) (the
    transition from GPT 3.5 to [ChatGPT](https://openai.com/blog/chatgpt)) the model
    only improves its ability to exploit this knowledge and how to interact with humans.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åŒæ—¶ï¼Œå¿…é¡»è®°ä½å¤§å¤šæ•°æŠ€èƒ½æ˜¯åœ¨é¢„è®­ç»ƒæœŸé—´å­¦åˆ°çš„ã€‚è®­ç»ƒä¸€ä¸ª*[LLM](https://en.wikipedia.org/wiki/Large_language_model)*çš„ç¬¬ä¸€æ­¥éœ€è¦å¤§é‡çš„æ–‡æœ¬ï¼Œé€šå¸¸é€šè¿‡ç®€å•åœ°è¦æ±‚æ¨¡å‹é¢„æµ‹ç»™å®šåºåˆ—å‰éƒ¨åˆ†çš„å•è¯æ¥è¿›è¡Œã€‚è¿™ä¸€æ­¥æ˜¯æœ€æ˜‚è´µã€æœ€è€—æ—¶å’Œæœ€èµ„æºå¯†é›†çš„ã€‚åœ¨*[alignment](https://jasonwei20.github.io/files/FLAN%20talk%20external.pdf)*ï¼ˆä»
    GPT 3.5 åˆ°*[ChatGPT](https://openai.com/blog/chatgpt)ï¼‰æœŸé—´ï¼Œæ¨¡å‹åªæ˜¯æé«˜äº†åˆ©ç”¨è¿™äº›çŸ¥è¯†çš„èƒ½åŠ›å’Œå¦‚ä½•ä¸äººç±»äº’åŠ¨ã€‚
- en: '[](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----55bde1180610--------------------------------)
    [## The Infinite Babel Library of LLMs'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----55bde1180610--------------------------------)
    [## å¤§è¯­è¨€æ¨¡å‹çš„æ— é™å·´åˆ«å›¾ä¹¦é¦†'
- en: 'Open-source, data, and attention: How the future of LLMs will change'
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¼€æºã€æ•°æ®å’Œæ³¨æ„åŠ›ï¼šå¤§è¯­è¨€æ¨¡å‹æœªæ¥çš„å˜åŒ–
- en: towardsdatascience.com](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----55bde1180610--------------------------------)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/the-infinite-babel-library-of-llms-90e203b2f6b0?source=post_page-----55bde1180610--------------------------------)'
- en: 'Use what you see: the pre-training impact on ICL'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åˆ©ç”¨ä½ æ‰€çœ‹åˆ°çš„ï¼šé¢„è®­ç»ƒå¯¹ ICL çš„å½±å“
- en: 'During pre-training, [LLMs](https://en.wikipedia.org/wiki/Large_language_model)
    are thus exposed to an enormous amount of text: from Wikipedia, books (fiction
    and nonfiction), scientific articles, tweets, Reddit posts, blog posts, internet
    dumps, and so on.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é¢„è®­ç»ƒæœŸé—´ï¼Œ[LLMs](https://en.wikipedia.org/wiki/Large_language_model) å› æ­¤æ¥è§¦åˆ°äº†å¤§é‡çš„æ–‡æœ¬ï¼šæ¥è‡ªç»´åŸºç™¾ç§‘ã€ä¹¦ç±ï¼ˆå°è¯´å’Œéå°è¯´ï¼‰ã€ç§‘å­¦æ–‡ç« ã€æ¨æ–‡ã€Reddit
    å¸–å­ã€åšå®¢å¸–å­ã€äº’è”ç½‘æ•°æ®ç­‰ã€‚
- en: '[In a 2022 article](https://arxiv.org/abs/2212.10559), it was proposed that
    [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) can be considered a kind
    of implicit [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)).
    The main difference is that while [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    is produced only by forward computation while fine-tuning also has a backpropagation
    step (in which parameters are updated). **This confirms that** [**ICL**](https://en.wikipedia.org/wiki/Prompt_engineering)
    **must originate during pretraining, but how does it impact pretraining?**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[åœ¨2022å¹´ä¸€ç¯‡æ–‡ç« ä¸­](https://arxiv.org/abs/2212.10559)ï¼Œæå‡ºäº†[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)å¯ä»¥è¢«è§†ä¸ºä¸€ç§éšå¼çš„[å¾®è°ƒ](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning))ã€‚ä¸»è¦åŒºåˆ«åœ¨äºï¼Œè™½ç„¶[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ä»…é€šè¿‡å‰å‘è®¡ç®—äº§ç”Ÿï¼Œè€Œå¾®è°ƒè¿˜åŒ…å«ä¸€ä¸ªåå‘ä¼ æ’­æ­¥éª¤ï¼ˆåœ¨è¯¥æ­¥éª¤ä¸­å‚æ•°è¢«æ›´æ–°ï¼‰ã€‚**è¿™ç¡®è®¤äº†**
    [**ICL**](https://en.wikipedia.org/wiki/Prompt_engineering) **å¿…é¡»åœ¨é¢„è®­ç»ƒæœŸé—´äº§ç”Ÿï¼Œä½†å®ƒå¦‚ä½•å½±å“é¢„è®­ç»ƒï¼Ÿ**'
- en: '[As one article showed](https://aclanthology.org/2022.naacl-main.380/), the
    pretraining dataset is critical for a model to develop [ICL](https://en.wikipedia.org/wiki/Prompt_engineering).
    According to the authors, the source domain is more important than the size of
    the [corpus](https://en.wikipedia.org/wiki/Text_corpus). Also, putting several
    [corpora](https://en.wikipedia.org/wiki/Text_corpus) together can lead to the
    emergence of [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) (if two corpora
    alone do not give ICL, joining them together can give [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)).
    Another important factor is the domain relevance of the [corpus](https://en.wikipedia.org/wiki/Text_corpus):
    training only on a news [corpus](https://en.wikipedia.org/wiki/Text_corpus) allows
    relative in-context learning ability on a news-related downstream task. Finally,
    the authors note, that although [perplexity](https://en.wikipedia.org/wiki/Perplexity)
    (one of the most commonly used metrics for tracking [LLMs](https://en.wikipedia.org/wiki/Large_language_model))
    and [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) generally correlate,
    perplexity alone does not reflect a modelâ€™s ability for [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    (comparing two [LLMs](https://en.wikipedia.org/wiki/Large_language_model), the
    model with the lowest perplexity is not necessarily the one with the highest [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)).'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ­£å¦‚ä¸€ç¯‡æ–‡ç« æ‰€ç¤º](https://aclanthology.org/2022.naacl-main.380/)ï¼Œé¢„è®­ç»ƒæ•°æ®é›†å¯¹æ¨¡å‹å¼€å‘[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)è‡³å…³é‡è¦ã€‚æ ¹æ®ä½œè€…çš„è¯´æ³•ï¼Œæºé¢†åŸŸæ¯”[è¯­æ–™åº“](https://en.wikipedia.org/wiki/Text_corpus)çš„å¤§å°æ›´ä¸ºé‡è¦ã€‚æ­¤å¤–ï¼Œå°†å¤šä¸ª[è¯­æ–™åº“](https://en.wikipedia.org/wiki/Text_corpus)ç»“åˆèµ·æ¥å¯ä»¥ä¿ƒä½¿[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)çš„å‡ºç°ï¼ˆå¦‚æœä¸¤ä¸ªè¯­æ–™åº“å•ç‹¬æ— æ³•äº§ç”ŸICLï¼Œå°†å®ƒä»¬ç»“åˆèµ·æ¥å¯ä»¥äº§ç”Ÿ[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ï¼‰ã€‚å¦ä¸€ä¸ªé‡è¦å› ç´ æ˜¯[è¯­æ–™åº“](https://en.wikipedia.org/wiki/Text_corpus)çš„é¢†åŸŸç›¸å…³æ€§ï¼šä»…åœ¨æ–°é—»[è¯­æ–™åº“](https://en.wikipedia.org/wiki/Text_corpus)ä¸Šè¿›è¡Œè®­ç»ƒåªèƒ½åœ¨ä¸æ–°é—»ç›¸å…³çš„ä¸‹æ¸¸ä»»åŠ¡ä¸­å®ç°ç›¸å¯¹çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ã€‚æœ€åï¼Œä½œè€…æŒ‡å‡ºï¼Œå°½ç®¡[å›°æƒ‘åº¦](https://en.wikipedia.org/wiki/Perplexity)ï¼ˆè·Ÿè¸ª[LLMs](https://en.wikipedia.org/wiki/Large_language_model)çš„æœ€å¸¸ç”¨æŒ‡æ ‡ä¹‹ä¸€ï¼‰å’Œ[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)é€šå¸¸å­˜åœ¨ç›¸å…³æ€§ï¼Œä½†å›°æƒ‘åº¦æœ¬èº«å¹¶ä¸èƒ½åæ˜ æ¨¡å‹åœ¨[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)æ–¹é¢çš„èƒ½åŠ›ï¼ˆæ¯”è¾ƒä¸¤ä¸ª[LLMs](https://en.wikipedia.org/wiki/Large_language_model)æ—¶ï¼Œå›°æƒ‘åº¦æœ€ä½çš„æ¨¡å‹ä¸ä¸€å®šæ˜¯[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)æœ€é«˜çš„æ¨¡å‹ï¼‰ã€‚'
- en: '[This was further confirmed](https://arxiv.org/abs/2205.05055) by the fact
    that the dataset must be several in rare classes to allow ICL. According to the
    authors, the training data examples should appear in clusters (i.e. there should
    be several for each class) and be a certain variety of classes.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[è¿™åœ¨è¿›ä¸€æ­¥ç¡®è®¤](https://arxiv.org/abs/2205.05055)äº†æ•°æ®é›†å¿…é¡»åœ¨ç¨€æœ‰ç±»åˆ«ä¸­å­˜åœ¨å¤šä¸ªå®ä¾‹ä»¥å…è®¸ICLã€‚æ ¹æ®ä½œè€…çš„è¯´æ³•ï¼Œè®­ç»ƒæ•°æ®ç¤ºä¾‹åº”ä»¥ç°‡çš„å½¢å¼å‡ºç°ï¼ˆå³ï¼Œæ¯ä¸ªç±»åˆ«åº”æœ‰å¤šä¸ªç¤ºä¾‹ï¼‰ï¼Œå¹¶ä¸”åº”å…·æœ‰ä¸€å®šçš„ç±»åˆ«å¤šæ ·æ€§ã€‚'
- en: '![](../Images/fe8746fa845491858ad4fcabf22a1b63.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe8746fa845491858ad4fcabf22a1b63.png)'
- en: 'image source: [here](https://arxiv.org/abs/2205.05055)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2205.05055)
- en: '[Another study states](https://arxiv.org/abs/2303.07895) instead that in-context
    learning appears when the pretraining distribution (the training data) is an implicit
    mixture. The examples for pretraining are extracted from a mixture of tasks, and
    the association between examples and tasks is latent. So then once the model is
    trained, it manages on its own to uncover the latent task in the demonstration.
    For example, a series of tweets with positive and negative content represent a
    latent task of sentiment analysis.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¦ä¸€é¡¹ç ”ç©¶æŒ‡å‡º](https://arxiv.org/abs/2303.07895)åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ å‡ºç°æ—¶ï¼Œé¢„è®­ç»ƒåˆ†å¸ƒï¼ˆè®­ç»ƒæ•°æ®ï¼‰æ˜¯ä¸€ç§éšå¼æ··åˆã€‚é¢„è®­ç»ƒç¤ºä¾‹æ˜¯ä»ä»»åŠ¡æ··åˆä¸­æå–çš„ï¼Œè€Œç¤ºä¾‹å’Œä»»åŠ¡ä¹‹é—´çš„å…³è”æ˜¯æ½œåœ¨çš„ã€‚å› æ­¤ï¼Œä¸€æ—¦æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå®ƒèƒ½å¤Ÿè‡ªè¡Œæ­ç¤ºç¤ºä¾‹ä¸­çš„æ½œåœ¨ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œä¸€ç³»åˆ—åŒ…å«æ­£é¢å’Œè´Ÿé¢å†…å®¹çš„æ¨æ–‡ä»£è¡¨äº†æƒ…æ„Ÿåˆ†æçš„æ½œåœ¨ä»»åŠ¡ã€‚'
- en: In short, these articles claim that [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    appears if the dataset is diverse, they present a diverse number of class numbers
    (but simultaneously several examples per class), they cover multiple domains,
    and best if these examples represent a latent task of [NLP](https://en.wikipedia.org/wiki/Natural_language_processing).
    Since [LLMs](https://en.wikipedia.org/wiki/Large_language_model) are generally
    trained with a huge amount of text, these premises are met.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ç®€è€Œè¨€ä¹‹ï¼Œè¿™äº›æ–‡ç« å£°ç§°ï¼Œ[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ä¼šå‡ºç°å¦‚æœæ•°æ®é›†å¤šæ ·åŒ–ï¼Œå®ƒä»¬å‘ˆç°äº†å¤šæ ·çš„ç±»åˆ«æ•°é‡ï¼ˆä½†åŒæ—¶æ¯ä¸ªç±»åˆ«æœ‰å¤šä¸ªç¤ºä¾‹ï¼‰ï¼Œæ¶µç›–å¤šä¸ªé¢†åŸŸï¼Œå¹¶ä¸”æœ€å¥½è¿™äº›ç¤ºä¾‹ä»£è¡¨ä¸€ä¸ª[è‡ªç„¶è¯­è¨€å¤„ç†](https://en.wikipedia.org/wiki/Natural_language_processing)çš„æ½œåœ¨ä»»åŠ¡ã€‚ç”±äº[LLMs](https://en.wikipedia.org/wiki/Large_language_model)é€šå¸¸ä½¿ç”¨å¤§é‡æ–‡æœ¬è¿›è¡Œè®­ç»ƒï¼Œå› æ­¤æ»¡è¶³è¿™äº›å‰æã€‚
- en: '[](/say-once-repeating-words-is-not-helping-ai-58f38035f66e?source=post_page-----55bde1180610--------------------------------)
    [## Say Once! Repeating Words Is Not Helping AI'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[## è¯´ä¸€æ¬¡ï¼é‡å¤è¯æ±‡æ— åŠ©äºAI](https://say-once-repeating-words-is-not-helping-ai-58f38035f66e?source=post_page-----55bde1180610--------------------------------)'
- en: How and why is repeating tokens harming LLMs? Why is this a problem?
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é‡å¤æ ‡è®°å¦‚ä½•ä»¥åŠä¸ºä½•å¯¹LLMé€ æˆä¼¤å®³ï¼Ÿè¿™æ˜¯ä¸ªé—®é¢˜å—ï¼Ÿ
- en: towardsdatascience.com](/say-once-repeating-words-is-not-helping-ai-58f38035f66e?source=post_page-----55bde1180610--------------------------------)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](https://say-once-repeating-words-is-not-helping-ai-58f38035f66e?source=post_page-----55bde1180610--------------------------------)'
- en: 'How you use what you learn: can you recall what you learned?'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½ å¦‚ä½•ä½¿ç”¨ä½ å­¦åˆ°çš„çŸ¥è¯†ï¼šä½ èƒ½å›å¿†èµ·ä½ å­¦åˆ°çš„å†…å®¹å—ï¼Ÿ
- en: 'Some researchers have attempted [to develop a framework](https://arxiv.org/abs/2111.02080)
    for understanding how [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    emerges during pretraining. According to the authors, an [LLM](https://en.wikipedia.org/wiki/Large_language_model)
    uses [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) to â€œlocateâ€ concepts
    that are needed to perform the task. The idea is that during training the model
    acquires latent concepts and then finds it again during [ICL](https://en.wikipedia.org/wiki/Prompt_engineering).
    To find them again, the [LLM](https://en.wikipedia.org/wiki/Large_language_model)
    can use all or some components of a prompt: format, inputs, outputs, and input-output
    mapping.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›ç ”ç©¶äººå‘˜å°è¯•[å¼€å‘æ¡†æ¶](https://arxiv.org/abs/2111.02080)ä»¥ç†è§£[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•å‡ºç°ã€‚æ ¹æ®ä½œè€…çš„è¯´æ³•ï¼Œ[LLM](https://en.wikipedia.org/wiki/Large_language_model)ä½¿ç”¨[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)æ¥â€œå®šä½â€æ‰§è¡Œä»»åŠ¡æ‰€éœ€çš„æ¦‚å¿µã€‚è¿™ä¸ªæƒ³æ³•æ˜¯ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹è·å¾—äº†æ½œåœ¨æ¦‚å¿µï¼Œç„¶ååœ¨[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)è¿‡ç¨‹ä¸­å†æ¬¡æ‰¾åˆ°å®ƒä»¬ã€‚ä¸ºäº†å†æ¬¡æ‰¾åˆ°è¿™äº›æ¦‚å¿µï¼Œ[LLM](https://en.wikipedia.org/wiki/Large_language_model)å¯ä»¥ä½¿ç”¨æç¤ºçš„å…¨éƒ¨æˆ–éƒ¨åˆ†ç»„ä»¶ï¼šæ ¼å¼ã€è¾“å…¥ã€è¾“å‡ºå’Œè¾“å…¥-è¾“å‡ºæ˜ å°„ã€‚
- en: 'As explained, [in a blog post by the authors](https://ai.stanford.edu/blog/understanding-incontext/),
    the model learns several concepts during training, after which the model uses
    the training examples to understand that the task in the prompt required either
    [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) or [topic
    classification](https://developers.google.com/machine-learning/guides/text-classification?hl=it)
    and at this point applies the mapping to the test input:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚[ä½œè€…åœ¨åšå®¢æ–‡ç« ä¸­è§£é‡Šçš„](https://ai.stanford.edu/blog/understanding-incontext/)ï¼Œæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ äº†å¤šä¸ªæ¦‚å¿µï¼Œç„¶åæ¨¡å‹ä½¿ç”¨è®­ç»ƒç¤ºä¾‹æ¥ç†è§£æç¤ºä¸­çš„ä»»åŠ¡éœ€è¦è¿›è¡Œ[æƒ…æ„Ÿåˆ†æ](https://en.wikipedia.org/wiki/Sentiment_analysis)æˆ–[ä¸»é¢˜åˆ†ç±»](https://developers.google.com/machine-learning/guides/text-classification?hl=it)ï¼Œæ­¤æ—¶å°†æ˜ å°„åº”ç”¨äºæµ‹è¯•è¾“å…¥ï¼š
- en: In this paper, we study how in-context learning can emerge when pretraining
    documents have long-range coherence. Here, the LM must infer a latent document-level
    concept to generate coherent next tokens during pretraining. At test time, in-context
    learning occurs when the LM also infers a shared latent concept between examples
    in a prompt. ([source](https://arxiv.org/abs/2111.02080))
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å½“é¢„è®­ç»ƒæ–‡æ¡£å…·æœ‰é•¿ç¨‹è¿è´¯æ€§æ—¶ï¼Œå¦‚ä½•å‡ºç°ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¯­è¨€æ¨¡å‹å¿…é¡»æ¨æ–­å‡ºæ½œåœ¨çš„æ–‡æ¡£çº§æ¦‚å¿µï¼Œä»¥åœ¨é¢„è®­ç»ƒæœŸé—´ç”Ÿæˆè¿è´¯çš„ä¸‹ä¸€ä¸ªæ ‡è®°ã€‚åœ¨æµ‹è¯•æ—¶ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ å‘ç”Ÿåœ¨è¯­è¨€æ¨¡å‹è¿˜æ¨æ–­å‡ºæç¤ºä¸­ç¤ºä¾‹ä¹‹é—´çš„å…±äº«æ½œåœ¨æ¦‚å¿µæ—¶ã€‚ï¼ˆ[æ¥æº](https://arxiv.org/abs/2111.02080)ï¼‰
- en: '![](../Images/39f467017195bea30d100863084d5721.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39f467017195bea30d100863084d5721.png)'
- en: 'image source: [here](https://arxiv.org/abs/2111.02080)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2111.02080)
- en: '**Yes but what is a concept?** for the authors is â€œ*a latent variable that
    contains various document-level statistics.*â€ So a concept for a topic (for example,
    news) is the distribution of words (what words are used), format (how they are
    written), relationships between articles and topics, and so on.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ˜¯çš„ï¼Œä½†ä»€ä¹ˆæ˜¯æ¦‚å¿µï¼Ÿ** å¯¹äºä½œè€…æ¥è¯´ï¼Œæ¦‚å¿µæ˜¯â€œ*ä¸€ä¸ªåŒ…å«å„ç§æ–‡æ¡£çº§ç»Ÿè®¡ä¿¡æ¯çš„æ½œåœ¨å˜é‡*â€ã€‚å› æ­¤ï¼ŒæŸä¸ªè¯é¢˜çš„æ¦‚å¿µï¼ˆä¾‹å¦‚æ–°é—»ï¼‰æ˜¯å•è¯çš„åˆ†å¸ƒï¼ˆä½¿ç”¨äº†å“ªäº›å•è¯ï¼‰ã€æ ¼å¼ï¼ˆå¦‚ä½•ä¹¦å†™ï¼‰ã€æ–‡ç« ä¸è¯é¢˜ä¹‹é—´çš„å…³ç³»ç­‰ã€‚'
- en: The body of texts that are provided to the model are not random words, but the
    texts have their own [internal coherence](https://en.wikipedia.org/wiki/Coherence_(linguistics)).
    In other words, similar texts have similar semantic information (the same topic)
    and formatting (alternate programming documentation explanations and code snippets).
    By learning to predict a word given those precedences, the [LLM](https://en.wikipedia.org/wiki/Large_language_model)
    also models internal consistency and allows it to infer latent concepts that are
    in the prompt
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æä¾›ç»™æ¨¡å‹çš„æ–‡æœ¬ä¸æ˜¯éšæœºçš„å•è¯ï¼Œè€Œæ˜¯æ–‡æœ¬å…·æœ‰å…¶è‡ªèº«çš„[å†…éƒ¨è¿è´¯æ€§](https://en.wikipedia.org/wiki/Coherence_(linguistics))ã€‚æ¢å¥è¯è¯´ï¼Œç±»ä¼¼çš„æ–‡æœ¬å…·æœ‰ç›¸ä¼¼çš„è¯­ä¹‰ä¿¡æ¯ï¼ˆç›¸åŒçš„è¯é¢˜ï¼‰å’Œæ ¼å¼ï¼ˆä¸åŒçš„ç¼–ç¨‹æ–‡æ¡£è§£é‡Šå’Œä»£ç ç‰‡æ®µï¼‰ã€‚é€šè¿‡å­¦ä¹ æ ¹æ®è¿™äº›å‰ä¾‹é¢„æµ‹ä¸€ä¸ªå•è¯ï¼Œ[LLM](https://en.wikipedia.org/wiki/Large_language_model)ä¹Ÿå»ºæ¨¡å†…éƒ¨ä¸€è‡´æ€§ï¼Œå¹¶ä½¿å…¶èƒ½å¤Ÿæ¨æ–­å‡ºæç¤ºä¸­çš„æ½œåœ¨æ¦‚å¿µã€‚
- en: 'In the authors'' words:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…çš„è¯ï¼š
- en: '**1\. Pretrain**: To predict the next token during pretraining, the LM must
    infer (â€œlocateâ€) the latent concept for the document using evidence from the previous
    sentences.'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**1\. é¢„è®­ç»ƒ**ï¼šä¸ºäº†åœ¨é¢„è®­ç»ƒæœŸé—´é¢„æµ‹ä¸‹ä¸€ä¸ªæ ‡è®°ï¼Œè¯­è¨€æ¨¡å‹å¿…é¡»åˆ©ç”¨å‰é¢çš„å¥å­ä¸­çš„è¯æ®æ¥æ¨æ–­ï¼ˆâ€œå®šä½â€ï¼‰æ–‡æ¡£çš„æ½œåœ¨æ¦‚å¿µã€‚'
- en: ''
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**2\. In-context learning**: If the LM also infers the *prompt concept* (the
    latent concept shared by examples in the prompt) using in-context examples in
    the prompt, then in-context learning occurs! ([source](https://ai.stanford.edu/blog/understanding-incontext/))'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2\. ä¸Šä¸‹æ–‡å­¦ä¹ **ï¼šå¦‚æœè¯­è¨€æ¨¡å‹è¿˜é€šè¿‡æç¤ºä¸­çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹æ¨æ–­å‡º*æç¤ºæ¦‚å¿µ*ï¼ˆæç¤ºä¸­ç¤ºä¾‹å…±äº«çš„æ½œåœ¨æ¦‚å¿µï¼‰ï¼Œé‚£ä¹ˆå°±ä¼šå‘ç”Ÿä¸Šä¸‹æ–‡å­¦ä¹ ï¼ï¼ˆ[æ¥æº](https://ai.stanford.edu/blog/understanding-incontext/)ï¼‰'
- en: So for the authors, this process of â€œlocatingâ€ can be seen as [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference),
    in which the [LLMs](https://en.wikipedia.org/wiki/Large_language_model) infer
    concepts in the prompt (a concept that is shared by all the examples presented
    to it in the input prompt). Once he has inferred the concept he can then produce
    the correct answer
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä½œè€…æ¥è¯´ï¼Œè¿™ç§â€œå®šä½â€è¿‡ç¨‹å¯ä»¥è§†ä¸º[è´å¶æ–¯æ¨æ–­](https://en.wikipedia.org/wiki/Bayesian_inference)ï¼Œå…¶ä¸­[LLMs](https://en.wikipedia.org/wiki/Large_language_model)æ¨æ–­æç¤ºä¸­çš„æ¦‚å¿µï¼ˆæ‰€æœ‰ç¤ºä¾‹åœ¨è¾“å…¥æç¤ºä¸­å…±äº«çš„æ¦‚å¿µï¼‰ã€‚ä¸€æ—¦ä»–æ¨æ–­å‡ºæ¦‚å¿µï¼Œä»–å°±å¯ä»¥äº§ç”Ÿæ­£ç¡®çš„ç­”æ¡ˆã€‚
- en: 'In formula:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å…¬å¼ä¸­ï¼š
- en: '![](../Images/8718900b9ea981fa05ea2b6b7117f0bf.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8718900b9ea981fa05ea2b6b7117f0bf.png)'
- en: 'image source: [here](https://arxiv.org/abs/2111.02080)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2111.02080)
- en: 'Ask nicely: effect of the prompt'
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¯·ç¤¼è²Œæé—®ï¼šæç¤ºçš„æ•ˆæœ
- en: In recent work, [Min et al.](https://arxiv.org/abs/2202.12837) defined the characteristics
    of a prompt for ICL and how the various components of the prompt affect the performance
    of the model in doing ICL
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿‘æœŸçš„å·¥ä½œä¸­ï¼Œ[Minç­‰äºº](https://arxiv.org/abs/2202.12837)å®šä¹‰äº†ICLæç¤ºçš„ç‰¹å¾ä»¥åŠæç¤ºçš„å„ç§ç»„ä»¶å¦‚ä½•å½±å“æ¨¡å‹åœ¨ICLä¸­çš„è¡¨ç°ã€‚
- en: '![](../Images/3dda25ecd69fc81d7b1be593488a2917.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dda25ecd69fc81d7b1be593488a2917.png)'
- en: 'image source: [here](https://arxiv.org/abs/2202.12837)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2202.12837)
- en: 'Considering a demonstration as input-output pairs ( (x1, y1)â€¦(xk, yk)) there
    are four formal aspects:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: è®¤ä¸ºæ¼”ç¤ºä½œä¸ºè¾“å…¥è¾“å‡ºå¯¹ï¼ˆ(x1, y1)â€¦(xk, yk)ï¼‰æœ‰å››ä¸ªæ­£å¼æ–¹é¢ï¼š
- en: '**The input-label mapping**. an input x is correctly paired with its label
    y.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¾“å…¥-æ ‡ç­¾æ˜ å°„**ã€‚ä¸€ä¸ªè¾“å…¥xä¸å…¶æ ‡ç­¾yæ­£ç¡®é…å¯¹ã€‚'
- en: '**The distribution of the input text**, the distribution from where input x
    is extracted.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¾“å…¥æ–‡æœ¬çš„åˆ†å¸ƒ**ï¼Œå³ä»ä¸­æå–è¾“å…¥xçš„åˆ†å¸ƒã€‚'
- en: '**The label space** is the space of the y outputs.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ‡ç­¾ç©ºé—´**æ˜¯yè¾“å‡ºçš„ç©ºé—´ã€‚'
- en: '**The format**, specifically the pairing of the input-output pairs'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ ¼å¼**ï¼Œç‰¹åˆ«æ˜¯è¾“å…¥-è¾“å‡ºå¯¹çš„é…å¯¹'
- en: '[For the authors](https://arxiv.org/abs/2202.12837), the format, the distribution
    of the input, and label spaces are important. In contrast, input-label mapping
    matters little to [ICL](https://en.wikipedia.org/wiki/Prompt_engineering). [According
    to Stanford AI Lab](https://ai.stanford.edu/blog/understanding-incontext/), this
    would stem from the fact, that the model is already exposed to input-output matching
    during pretraining so it would not need the input-label mapping in the demonstration.
    Instead, the other elements are needed to be able to locate the concepts it has
    learned (in short perform [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference)).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº[ä½œè€…ä»¬](https://arxiv.org/abs/2202.12837)è€Œè¨€ï¼Œæ ¼å¼ã€è¾“å…¥å’Œæ ‡ç­¾ç©ºé—´çš„åˆ†å¸ƒéå¸¸é‡è¦ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè¾“å…¥-æ ‡ç­¾æ˜ å°„å¯¹[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)å‡ ä¹æ²¡æœ‰å½±å“ã€‚[æ ¹æ®æ–¯å¦ç¦äººå·¥æ™ºèƒ½å®éªŒå®¤](https://ai.stanford.edu/blog/understanding-incontext/)çš„è¯´æ³•ï¼Œè¿™æºäºæ¨¡å‹åœ¨é¢„è®­ç»ƒæœŸé—´å·²ç»æ¥è§¦è¿‡è¾“å…¥-è¾“å‡ºåŒ¹é…ï¼Œå› æ­¤åœ¨æ¼”ç¤ºæ—¶ä¸éœ€è¦è¾“å…¥-æ ‡ç­¾æ˜ å°„ã€‚ç›¸åï¼Œå…¶ä»–å…ƒç´ æ˜¯å¿…éœ€çš„ï¼Œä»¥ä¾¿èƒ½å¤Ÿå®šä½å…¶å·²å­¦ä¹ çš„æ¦‚å¿µï¼ˆç®€è€Œè¨€ä¹‹ï¼Œæ‰§è¡Œ[è´å¶æ–¯æ¨æ–­](https://en.wikipedia.org/wiki/Bayesian_inference)ï¼‰ã€‚
- en: '![](../Images/6b897bdf4114db6d6f1cb57c2d7ca69d.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b897bdf4114db6d6f1cb57c2d7ca69d.png)'
- en: 'image source: [here](https://arxiv.org/abs/2202.12837)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2202.12837)
- en: '[Another paper states](https://arxiv.org/abs/2205.12685) that actually input-label
    mapping, while [according to another](https://arxiv.org/abs/2303.03846) it is
    true that it is important but if the model is large enough it can learn the mapping
    on its own.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¦ä¸€ç¯‡è®ºæ–‡æŒ‡å‡º](https://arxiv.org/abs/2205.12685)ï¼Œå®é™…ä¸Šè¾“å…¥-æ ‡ç­¾æ˜ å°„æ˜¯é‡è¦çš„ï¼Œ[æ ¹æ®å¦ä¸€ç¯‡è®ºæ–‡](https://arxiv.org/abs/2303.03846)ï¼Œè™½ç„¶ç¡®å®é‡è¦ï¼Œä½†å¦‚æœæ¨¡å‹è¶³å¤Ÿå¤§ï¼Œå®ƒå¯ä»¥è‡ªè¡Œå­¦ä¹ æ˜ å°„ã€‚'
- en: For other authors, it is important that the demonstrations are different, simple,
    and similar anyway (at least in terms of structure). For another paper, the [order
    of the demonstrations is important](https://aclanthology.org/2022.acl-long.556/).
    Whereas, [Liu et al](https://aclanthology.org/2022.deelio-1.10.pdf), show that
    the choice of examples strongly impacts [ICL](https://en.wikipedia.org/wiki/Prompt_engineering).
    So one should choose examples that are close to an [embedding space](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture).
    In fact, one technique that shows results is when one provides a question to embed
    it and looks for examples that are close in distance in the [embedding](https://en.wikipedia.org/wiki/Embedding).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå…¶ä»–ä½œè€…è€Œè¨€ï¼Œæ¼”ç¤ºçš„å¤šæ ·æ€§ã€ç®€æ´æ€§ä»¥åŠç»“æ„ä¸Šçš„ç›¸ä¼¼æ€§éƒ½æ˜¯é‡è¦çš„ã€‚å¯¹äºå¦ä¸€ç¯‡è®ºæ–‡ï¼Œ[æ¼”ç¤ºçš„é¡ºåºå¾ˆé‡è¦](https://aclanthology.org/2022.acl-long.556/)ã€‚ç„¶è€Œï¼Œ[åˆ˜ç­‰äºº](https://aclanthology.org/2022.deelio-1.10.pdf)æ˜¾ç¤ºï¼Œç¤ºä¾‹çš„é€‰æ‹©å¯¹[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)æœ‰å¾ˆå¤§å½±å“ã€‚å› æ­¤ï¼Œåº”é€‰æ‹©æ¥è¿‘[åµŒå…¥ç©ºé—´](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture)çš„ç¤ºä¾‹ã€‚äº‹å®ä¸Šï¼Œä¸€ç§æœ‰æ•ˆçš„æŠ€æœ¯æ˜¯æä¾›ä¸€ä¸ªé—®é¢˜ä»¥è¿›è¡ŒåµŒå…¥ï¼Œå¹¶å¯»æ‰¾åœ¨[åµŒå…¥](https://en.wikipedia.org/wiki/Embedding)ä¸­è·ç¦»è¾ƒè¿‘çš„ç¤ºä¾‹ã€‚
- en: '![](../Images/1192be99f7221b72a5ae571369b3d2a8.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1192be99f7221b72a5ae571369b3d2a8.png)'
- en: 'image source: [here](https://aclanthology.org/2022.deelio-1.10.pdf)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://aclanthology.org/2022.deelio-1.10.pdf)
- en: '[](https://levelup.gitconnected.com/the-ai-college-student-goes-back-to-the-bench-daa6d9bdfb14?source=post_page-----55bde1180610--------------------------------)
    [## The AI college student goes back to the bench'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://levelup.gitconnected.com/the-ai-college-student-goes-back-to-the-bench-daa6d9bdfb14?source=post_page-----55bde1180610--------------------------------)
    [## äººå·¥æ™ºèƒ½å¤§å­¦ç”Ÿå›åˆ°åŸºç¡€]'
- en: How LLM can solve college exams and why this is important
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹å¦‚ä½•è§£å†³å¤§å­¦è€ƒè¯•åŠå…¶é‡è¦æ€§
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/the-ai-college-student-goes-back-to-the-bench-daa6d9bdfb14?source=post_page-----55bde1180610--------------------------------)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[levelup.gitconnected.com](https://levelup.gitconnected.com/the-ai-college-student-goes-back-to-the-bench-daa6d9bdfb14?source=post_page-----55bde1180610--------------------------------)'
- en: A closed look to attention
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¯¹æ³¨æ„åŠ›æœºåˆ¶çš„æ·±å…¥æ¢è®¨
- en: 'We have seen so far the role of the training dataset and the prompt, now it
    is time to closer look at the effect of architecture. An [LLM](https://en.wikipedia.org/wiki/Large_language_model)
    is a transformer, and the [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
    is mainly based on [multi-head self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning)).
    Because [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) is one of the
    most interesting behaviors of [LLMs](https://en.wikipedia.org/wiki/Large_language_model),
    many authors have focused on trying to find a mechanistic answer to how [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    occurs:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢å·²ç»çœ‹åˆ°è®­ç»ƒæ•°æ®é›†å’Œæç¤ºçš„ä½œç”¨ï¼Œç°åœ¨æ˜¯æ—¶å€™æ›´ä»”ç»†åœ°ç ”ç©¶æ¶æ„çš„æ•ˆæœäº†ã€‚ä¸€ä¸ª[LLM](https://en.wikipedia.org/wiki/Large_language_model)æ˜¯ä¸€ä¸ªå˜æ¢å™¨ï¼Œè€Œ[å˜æ¢å™¨](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))ä¸»è¦åŸºäº[å¤šå¤´è‡ªæ³¨æ„åŠ›](https://en.wikipedia.org/wiki/Attention_(machine_learning))ã€‚ç”±äº[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)æ˜¯[LLMs](https://en.wikipedia.org/wiki/Large_language_model)æœ€æœ‰è¶£çš„è¡Œä¸ºä¹‹ä¸€ï¼Œè®¸å¤šä½œè€…ä¸“æ³¨äºå°è¯•æ‰¾åˆ°[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)å‘ç”Ÿçš„æœºåˆ¶æ€§ç­”æ¡ˆï¼š
- en: If we can understand the internal structures that cause Transformer models to
    produce the outputs they do, then we may be able to address current safety problems
    more systematically, as well as anticipating safety problems in future more powerful
    models. ([source](https://arxiv.org/abs/2209.11895))
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å¯ä»¥ç†è§£å¯¼è‡´å˜æ¢å™¨æ¨¡å‹äº§ç”Ÿå…¶è¾“å‡ºçš„å†…éƒ¨ç»“æ„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯èƒ½èƒ½å¤Ÿæ›´ç³»ç»Ÿåœ°è§£å†³å½“å‰çš„å®‰å…¨é—®é¢˜ï¼Œå¹¶é¢„æµ‹æœªæ¥æ›´å¼ºå¤§çš„æ¨¡å‹ä¸­çš„å®‰å…¨é—®é¢˜ã€‚ ([source](https://arxiv.org/abs/2209.11895))
- en: '![](../Images/470625884f8f80cbbb190a076b5eeb81.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/470625884f8f80cbbb190a076b5eeb81.png)'
- en: 'image source: [here](https://arxiv.org/abs/1706.03762)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/1706.03762)
- en: '[Researchers at Anthropic identified circuits](https://arxiv.org/abs/2209.11895)
    they called **induction heads**. An induction head is a circuit consisting of
    [two attention heads](https://en.wikipedia.org/wiki/Attention_(machine_learning))
    in different layers cooperating with each other to copy or complete patterns.
    Basically, the first attention head copies information from the previous token
    to the next one. The second attention head then has information about what happened
    previous to the present token. Then this mechanism can search the sequence where
    the present token A and sees the next token B, so the pattern once it sees A is
    more likely to produce output B.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[Anthropic çš„ç ”ç©¶äººå‘˜è¯†åˆ«äº†ä»–ä»¬ç§°ä¸º**å½’çº³å¤´**çš„ç”µè·¯](https://arxiv.org/abs/2209.11895)ã€‚å½’çº³å¤´æ˜¯ä¸€ä¸ªç”±[ä¸¤ä¸ªæ³¨æ„åŠ›å¤´](https://en.wikipedia.org/wiki/Attention_(machine_learning))åœ¨ä¸åŒå±‚ä¸­åä½œä»¥å¤åˆ¶æˆ–å®Œæˆæ¨¡å¼çš„ç”µè·¯ã€‚åŸºæœ¬ä¸Šï¼Œç¬¬ä¸€ä¸ªæ³¨æ„åŠ›å¤´å°†ä¿¡æ¯ä»å‰ä¸€ä¸ªæ ‡è®°å¤åˆ¶åˆ°ä¸‹ä¸€ä¸ªæ ‡è®°ã€‚ç¬¬äºŒä¸ªæ³¨æ„åŠ›å¤´åˆ™æ‹¥æœ‰å…³äºå½“å‰æ ‡è®°ä¹‹å‰å‘ç”Ÿçš„äº‹æƒ…çš„ä¿¡æ¯ã€‚ç„¶åï¼Œè¿™ä¸ªæœºåˆ¶å¯ä»¥æœç´¢å½“å‰æ ‡è®°Aæ‰€åœ¨çš„åºåˆ—ï¼Œå¹¶æŸ¥çœ‹ä¸‹ä¸€ä¸ªæ ‡è®°Bï¼Œå› æ­¤ä¸€æ—¦çœ‹åˆ°Aï¼Œæ¨¡å¼æ›´æœ‰å¯èƒ½ç”Ÿæˆè¾“å‡ºBã€‚'
- en: '![](../Images/1c3b8ddbce7d102d33057ae158f67070.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c3b8ddbce7d102d33057ae158f67070.png)'
- en: 'image source: [here](https://arxiv.org/abs/2209.11895)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2209.11895)
- en: '[For the authors](https://arxiv.org/abs/2209.11895), however, it is not a simple
    copying mechanism. In fact, in [inductive reasoning](https://en.wikipedia.org/wiki/Inductive_reasoning),
    we can infer that A is followed by B, if previously in context we saw that A most
    likely followed by B. For the authors then these induction heads crystallize this
    inference mechanism, which is not based on the training data but on the context:
    [A][B]â€¦[A]â†’[B]'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¯¹äºä½œè€…ä»¬](https://arxiv.org/abs/2209.11895)æ¥è¯´ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ç§ç®€å•çš„å¤åˆ¶æœºåˆ¶ã€‚å®é™…ä¸Šï¼Œåœ¨[å½’çº³æ¨ç†](https://en.wikipedia.org/wiki/Inductive_reasoning)ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ¨æ–­å‡ºAåé¢è·Ÿç€Bï¼Œå¦‚æœåœ¨ä¸Šä¸‹æ–‡ä¸­æˆ‘ä»¬çœ‹åˆ°Aæœ€æœ‰å¯èƒ½è·Ÿç€Bã€‚å¯¹ä½œè€…ä»¬è€Œè¨€ï¼Œè¿™äº›å½’çº³å¤´ä½¿è¿™ç§æ¨ç†æœºåˆ¶å¾—ä»¥å…·ä½“åŒ–ï¼Œè¿™ç§æœºåˆ¶ä¸æ˜¯åŸºäºè®­ç»ƒæ•°æ®ï¼Œè€Œæ˜¯åŸºäºä¸Šä¸‹æ–‡ï¼š[A][B]â€¦[A]â†’[B]'
- en: '[For Anthropic](https://arxiv.org/abs/2209.11895) these induction heads play
    an important role in [ICL](https://en.wikipedia.org/wiki/Prompt_engineering).
    In fact, the fact that they can learn and repeat arbitrary sequences can be thought
    of as a simplified form of few-shot learning. In [a large model](https://en.wikipedia.org/wiki/Large_language_model),
    this effect is amplified, since they can work on abstract representations. Thus:
    â€œ, t*he very same heads that do this sequence copying also take on a more expanded
    role of analogical sequence copying or in-context nearest neighbors*â€.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¯¹äº Anthropic](https://arxiv.org/abs/2209.11895)ï¼Œè¿™äº›å½’çº³å¤´åœ¨[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ä¸­æ‰®æ¼”äº†é‡è¦è§’è‰²ã€‚äº‹å®ä¸Šï¼Œå®ƒä»¬èƒ½å¤Ÿå­¦ä¹ å’Œé‡å¤ä»»æ„åºåˆ—ï¼Œå¯ä»¥è¢«è§†ä¸ºä¸€ç§ç®€åŒ–çš„å°‘æ ·æœ¬å­¦ä¹ å½¢å¼ã€‚åœ¨[å¤§å‹æ¨¡å‹](https://en.wikipedia.org/wiki/Large_language_model)ä¸­ï¼Œè¿™ç§æ•ˆæœä¼šè¢«æ”¾å¤§ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥å¤„ç†æŠ½è±¡è¡¨ç¤ºã€‚å› æ­¤ï¼šâ€œ*è¿›è¡Œåºåˆ—å¤åˆ¶çš„ç›¸åŒå¤´éƒ¨ä¹Ÿæ‰¿æ‹…äº†ç±»æ¯”åºåˆ—å¤åˆ¶æˆ–ä¸Šä¸‹æ–‡æœ€è¿‘é‚»çš„æ›´å¹¿æ³›è§’è‰²*â€ã€‚'
- en: 'Now, this mechanism is also interesting because it also promotes another kind
    of sequence completion: [A*][B*] â€¦ [A] â†’ [B]. In this case A* and B* are not the
    same tokens A and B but tokens that are similar in [embedding space](https://en.wikipedia.org/wiki/Embedding)
    (for example, the same word in different languages).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè¿™ä¸€æœºåˆ¶ä¹Ÿå¾ˆæœ‰è¶£ï¼Œå› ä¸ºå®ƒè¿˜ä¿ƒè¿›äº†å¦ä¸€ç§åºåˆ—å®Œæˆï¼š[A*][B*] â€¦ [A] â†’ [B]ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒA*å’ŒB*ä¸æ˜¯ç›¸åŒçš„ä»¤ç‰ŒAå’ŒBï¼Œè€Œæ˜¯åœ¨[åµŒå…¥ç©ºé—´](https://en.wikipedia.org/wiki/Embedding)ä¸­ç›¸ä¼¼çš„ä»¤ç‰Œï¼ˆä¾‹å¦‚ï¼Œä¸åŒè¯­è¨€ä¸­çš„ç›¸åŒå•è¯ï¼‰ã€‚
- en: These induction heads seem to appear as the [LLM](https://en.wikipedia.org/wiki/Large_language_model)
    improves its skill in ICL. Also, [for Anthrophic](https://arxiv.org/abs/2209.11895)
    in small [LMs](https://en.wikipedia.org/wiki/Large_language_model), one can observe
    this relationship with [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    (for them the induction heads are the driver of [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)).
    In addition, reverse engineering of these induction heads can be done for them,
    and this seems like a promising line of research to understand how they are formed
    and how they impact [ICL](https://en.wikipedia.org/wiki/Prompt_engineering).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¼•å¯¼å¤´ä¼¼ä¹åœ¨[LLM](https://en.wikipedia.org/wiki/Large_language_model)æé«˜å…¶ICLæŠ€èƒ½æ—¶å‡ºç°ã€‚åŒæ—¶ï¼Œåœ¨å°å‹[LMs](https://en.wikipedia.org/wiki/Large_language_model)ä¸­ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°è¿™ç§å…³ç³»ä¸[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ï¼ˆå¯¹å®ƒä»¬æ¥è¯´ï¼Œå¼•å¯¼å¤´æ˜¯[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)çš„é©±åŠ¨å› ç´ ï¼‰ã€‚æ­¤å¤–ï¼Œè¿™äº›å¼•å¯¼å¤´çš„é€†å‘å·¥ç¨‹å¯ä»¥å®Œæˆï¼Œè¿™ä¼¼ä¹æ˜¯ç†è§£å®ƒä»¬å¦‚ä½•å½¢æˆä»¥åŠå¦‚ä½•å½±å“[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ã€‚
- en: '![](../Images/89d1bccf2e12244a91bab946d0f5db4d.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89d1bccf2e12244a91bab946d0f5db4d.png)'
- en: 'image source: [here](https://arxiv.org/abs/2209.11895)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2209.11895)
- en: '[ICL](https://en.wikipedia.org/wiki/Prompt_engineering) in each case is linked
    and emerges through attention. This has a quadratic (in computational terms) cost,
    though. Several models with simplified forms of [attention](https://en.wikipedia.org/wiki/Attention_(machine_learning))
    (linear or logarithmic) were tested; however, this led to a decrease in expressiveness
    and impacted the [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) ability
    of the model. Therefore, although an alternative to [multi-head self-attention](https://en.wikipedia.org/wiki/Attention_(machine_learning))
    is sought, the authors take care that their proposed model is capable of [ICL](https://en.wikipedia.org/wiki/Prompt_engineering).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯ä¸ªæ¡ˆä¾‹ä¸­çš„[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)éƒ½æ˜¯é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å…³è”å¹¶äº§ç”Ÿçš„ã€‚ä¸è¿‡ï¼Œè¿™æœ‰ä¸€ä¸ªäºŒæ¬¡ï¼ˆè®¡ç®—æœ¯è¯­ä¸­ï¼‰çš„æˆæœ¬ã€‚ä¸€äº›å…·æœ‰ç®€åŒ–å½¢å¼çš„[æ³¨æ„åŠ›](https://en.wikipedia.org/wiki/Attention_(machine_learning))ï¼ˆçº¿æ€§æˆ–å¯¹æ•°ï¼‰æ¨¡å‹è¢«æµ‹è¯•è¿‡ï¼›ç„¶è€Œï¼Œè¿™å¯¼è‡´äº†è¡¨ç°åŠ›çš„ä¸‹é™ï¼Œå¹¶å½±å“äº†æ¨¡å‹çš„[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)èƒ½åŠ›ã€‚å› æ­¤ï¼Œè™½ç„¶å¯»æ±‚[å¤šå¤´è‡ªæ³¨æ„åŠ›](https://en.wikipedia.org/wiki/Attention_(machine_learning))çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ä½œè€…ä»¬ç¡®ä¿ä»–ä»¬æå‡ºçš„æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œ[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ã€‚
- en: '[](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----55bde1180610--------------------------------)
    [## Welcome Back 80s: Transformers Could Be Blown Away by Convolution'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----55bde1180610--------------------------------)
    [## æ¬¢è¿å›åˆ°80å¹´ä»£ï¼šå·ç§¯å¯èƒ½ä¼šè¶…è¶Šå˜æ¢å™¨'
- en: The Hyena model shows how convolution could be faster than self-attention
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Hyenaæ¨¡å‹å±•ç¤ºäº†å·ç§¯å¦‚ä½•æ¯”è‡ªæ³¨æ„åŠ›æ›´å¿«
- en: levelup.gitconnected.com](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----55bde1180610--------------------------------)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: levelup.gitconnected.com](https://levelup.gitconnected.com/welcome-back-80s-transformers-could-be-blown-away-by-convolution-21ff15f6d1cc?source=post_page-----55bde1180610--------------------------------)
- en: Learning to learn the context
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å­¦ä¼šå­¦ä¹ ä¸Šä¸‹æ–‡
- en: Clearly, since the [transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
    is trained through [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)
    there is a relationship between the latter and [ICL](https://en.wikipedia.org/wiki/Prompt_engineering).
    Using [linear regression](https://en.wikipedia.org/wiki/Linear_regression) as
    a starting point, [AkyÃ¼rek suggests](https://arxiv.org/abs/2211.15661) that transformers
    implicitly treat [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) as an
    optimization problem.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜¾ç„¶ï¼Œç”±äº[å˜æ¢å™¨](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))æ˜¯é€šè¿‡[æ¢¯åº¦ä¸‹é™](https://en.wikipedia.org/wiki/Gradient_descent)è®­ç»ƒçš„ï¼Œå› æ­¤åè€…ä¸[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ä¹‹é—´å­˜åœ¨å…³ç³»ã€‚ä»¥[çº¿æ€§å›å½’](https://en.wikipedia.org/wiki/Linear_regression)ä¸ºèµ·ç‚¹ï¼Œ[AkyÃ¼rekå»ºè®®](https://arxiv.org/abs/2211.15661)å˜æ¢å™¨éšå¼åœ°å°†[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)è§†ä¸ºä¸€ä¸ªä¼˜åŒ–é—®é¢˜ã€‚
- en: '[Oswald](https://arxiv.org/abs/2212.07677) showed that [transformer layers](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
    can theoretically implement [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)
    on the in-context data. According to [Oswald](https://arxiv.org/abs/2212.07677),
    in-context learning mimics [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)
    in certain cases. [This paper](https://arxiv.org/abs/2212.07677) showed that there
    is an [ICL](https://en.wikipedia.org/wiki/Prompt_engineering) and gradient descent
    relationship.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[Oswald](https://arxiv.org/abs/2212.07677)å±•ç¤ºäº†[å˜æ¢å™¨å±‚](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))ç†è®ºä¸Šå¯ä»¥åœ¨ä¸Šä¸‹æ–‡æ•°æ®ä¸Šå®ç°[æ¢¯åº¦ä¸‹é™](https://en.wikipedia.org/wiki/Gradient_descent)ã€‚æ ¹æ®[Oswald](https://arxiv.org/abs/2212.07677)çš„è¯´æ³•ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ åœ¨æŸäº›æƒ…å†µä¸‹æ¨¡ä»¿[æ¢¯åº¦ä¸‹é™](https://en.wikipedia.org/wiki/Gradient_descent)ã€‚[è¿™ç¯‡è®ºæ–‡](https://arxiv.org/abs/2212.07677)å±•ç¤ºäº†[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)å’Œæ¢¯åº¦ä¸‹é™ä¹‹é—´çš„å…³ç³»ã€‚'
- en: '![](../Images/128ac013ae9e45af341a022694e50030.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/128ac013ae9e45af341a022694e50030.png)'
- en: 'Image source: [here](https://arxiv.org/abs/2212.07677)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2212.07677)
- en: The results above, and [AkyÃ¼rekâ€™s results](https://arxiv.org/abs/2211.15661),
    mean that models doing in-context learning are not just matching previous patterns,
    but instead are also learning how to perform other tasks (an extension of what
    was said with induction heads). In fact, [AkyÃ¼rek](https://arxiv.org/abs/2211.15661)
    provided prompts containing synthetic data to prevent the model from having already
    seen the data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°ç»“æœï¼Œä»¥åŠ[AkyÃ¼rekçš„ç»“æœ](https://arxiv.org/abs/2211.15661)ï¼Œæ„å‘³ç€è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ çš„æ¨¡å‹ä¸ä»…ä»…æ˜¯åŒ¹é…å…ˆå‰çš„æ¨¡å¼ï¼Œè€Œæ˜¯è¿˜å­¦ä¼šäº†å¦‚ä½•æ‰§è¡Œå…¶ä»–ä»»åŠ¡ï¼ˆè¿™æ˜¯å¯¹è¯±å¯¼å¤´æ‰€è¯´å†…å®¹çš„æ‰©å±•ï¼‰ã€‚å®é™…ä¸Šï¼Œ[AkyÃ¼rek](https://arxiv.org/abs/2211.15661)æä¾›äº†åŒ…å«åˆæˆæ•°æ®çš„æç¤ºï¼Œä»¥é˜²æ¨¡å‹å·²ç»è§è¿‡è¿™äº›æ•°æ®ã€‚
- en: '[AkyÃ¼rekâ€™s hypothesis](https://arxiv.org/abs/2211.15661) is then the models
    internally perform sort of machine learning algorithms (which in part echoes but
    extends the idea that the model does Bayesian inference). In the article, they
    state that the model implements in its hidden states a linear model, and this
    is learned during training.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[AkyÃ¼rekçš„å‡è®¾](https://arxiv.org/abs/2211.15661)æ˜¯æ¨¡å‹åœ¨å†…éƒ¨æ‰§è¡ŒæŸç§æœºå™¨å­¦ä¹ ç®—æ³•ï¼ˆè¿™åœ¨æŸç§ç¨‹åº¦ä¸Šå‘¼åº”ä½†æ‰©å±•äº†æ¨¡å‹è¿›è¡Œè´å¶æ–¯æ¨æ–­çš„æƒ³æ³•ï¼‰ã€‚åœ¨æ–‡ç« ä¸­ï¼Œä»–ä»¬è¡¨ç¤ºæ¨¡å‹åœ¨å…¶éšè—çŠ¶æ€ä¸­å®ç°äº†ä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼Œå¹¶ä¸”è¿™ä¸€ç‚¹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¾—åˆ°äº†å­¦ä¹ ã€‚'
- en: â€œIn this case, we tried to recover the actual solution to the linear model,
    and we could show that the parameter is written in the hidden states. This means
    the linear model is in there somewhere,â€ AkyÃ¼rek says. ([source](https://news.mit.edu/2023/large-language-models-in-context-learning-0207))
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°è¯•æ¢å¤çº¿æ€§æ¨¡å‹çš„å®é™…è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬èƒ½å¤Ÿè¯æ˜å‚æ•°è¢«å†™åœ¨éšè—çŠ¶æ€ä¸­ã€‚è¿™æ„å‘³ç€çº¿æ€§æ¨¡å‹æŸå¤„ç¡®å®å­˜åœ¨ï¼Œâ€AkyÃ¼rekè¯´ã€‚ï¼ˆ[æ¥æº](https://news.mit.edu/2023/large-language-models-in-context-learning-0207)ï¼‰
- en: '[In an intriguing experiment](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html),
    Google tested whether models via [ICL](https://en.wikipedia.org/wiki/Prompt_engineering)
    can override previous [prior knowledge](https://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition),
    for the authors this is also an example of the emergent property of broad [LLMs](https://en.wikipedia.org/wiki/Large_language_model).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[åœ¨ä¸€ä¸ªæœ‰è¶£çš„å®éªŒä¸­](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html)ï¼ŒGoogleæµ‹è¯•äº†é€šè¿‡[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿè¦†ç›–å…ˆå‰çš„[å…ˆéªŒçŸ¥è¯†](https://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition)ï¼Œå¯¹ä½œè€…æ¥è¯´ï¼Œè¿™ä¹Ÿæ˜¯å¹¿æ³›çš„[LLMs](https://en.wikipedia.org/wiki/Large_language_model)çš„ä¸€ä¸ªæ–°å…´ç‰¹æ€§ä¾‹å­ã€‚'
- en: In one of the experiments, the authors performed regular [ICL](https://en.wikipedia.org/wiki/Prompt_engineering),
    flipped ICL (where labels are flipped), and semantically-unrelated label ICL (SUL-ICL)
    where labels are words that are not semantically related.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å…¶ä¸­ä¸€ä¸ªå®éªŒä¸­ï¼Œä½œè€…è¿›è¡Œäº†å¸¸è§„çš„[ICL](https://en.wikipedia.org/wiki/Prompt_engineering)ã€ç¿»è½¬çš„ICLï¼ˆæ ‡ç­¾è¢«ç¿»è½¬ï¼‰å’Œè¯­ä¹‰ä¸ç›¸å…³çš„æ ‡ç­¾ICLï¼ˆSUL-ICLï¼‰ï¼Œå…¶ä¸­æ ‡ç­¾æ˜¯æ²¡æœ‰è¯­ä¹‰ç›¸å…³æ€§çš„è¯æ±‡ã€‚
- en: '![](../Images/2807e4985bd1bae2dd2215dc62c8d9df.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2807e4985bd1bae2dd2215dc62c8d9df.png)'
- en: 'image source: [here](https://arxiv.org/abs/2303.03846)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2303.03846)
- en: This article shows some interesting things. When the labels are flipped (but
    the ground-truth evaluation is kept the same) if the model is able to override
    its prior knowledge it should have a decrease. The result is that the performance
    of small models stays flat, while there is a drop for [large models](https://en.wikipedia.org/wiki/Large_language_model).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¯‡æ–‡ç« å±•ç¤ºäº†ä¸€äº›æœ‰è¶£çš„ç°è±¡ã€‚å½“æ ‡ç­¾è¢«ç¿»è½¬ï¼ˆä½†çœŸå®è¯„ä»·ä¿æŒä¸å˜ï¼‰æ—¶ï¼Œå¦‚æœæ¨¡å‹èƒ½å¤Ÿè¦†ç›–å…¶å…ˆéªŒçŸ¥è¯†ï¼Œåˆ™åº”å‡ºç°æ€§èƒ½ä¸‹é™ã€‚ç»“æœæ˜¯å°æ¨¡å‹çš„æ€§èƒ½ä¿æŒå¹³ç¨³ï¼Œè€Œ[å¤§æ¨¡å‹](https://en.wikipedia.org/wiki/Large_language_model)åˆ™å‡ºç°äº†ä¸‹é™ã€‚
- en: These results indicate that large models can override prior knowledge from pre-training
    when contradicting input-label mappings are presented in-context. Small models
    canâ€™t do this, making this ability an emergent phenomena of model scale. ([source](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html))
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™äº›ç»“æœè¡¨æ˜ï¼Œå½“çŸ›ç›¾çš„è¾“å…¥-æ ‡ç­¾æ˜ å°„åœ¨è¯­å¢ƒä¸­å‡ºç°æ—¶ï¼Œå¤§å‹æ¨¡å‹å¯ä»¥è¦†ç›–é¢„è®­ç»ƒä¸­çš„å…ˆéªŒçŸ¥è¯†ã€‚å°æ¨¡å‹æ— æ³•åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½¿è¿™ä¸€èƒ½åŠ›æˆä¸ºæ¨¡å‹è§„æ¨¡çš„çªç°ç°è±¡ã€‚([source](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html))
- en: '![](../Images/15b8229c8301c802ce1b0c2a46c4b578.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15b8229c8301c802ce1b0c2a46c4b578.png)'
- en: 'image source: [here](https://arxiv.org/abs/2303.03846)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2303.03846)
- en: Second, the model can also learn from input-label mappings when provided in
    the demonstration of semantically-irrelevant labels (â€œfoo/barâ€ instead of â€œnegative/positiveâ€
    for sentiment analysis). A model that relies only on [prior knowledge](https://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition)
    should have a performance drop because it cannot exploit the semantic meaning
    of labels for predictions. In fact, small models have a drop in prediction, while
    [LLMs](https://en.wikipedia.org/wiki/Large_language_model) do not. For the authors,
    this means that while small models rely on [prior knowledge](https://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition),
    â€œ*large models, on the other hand, have the ability to learn input-label mappings
    in context when the semantic nature of labels is removed.*â€
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶æ¬¡ï¼Œå½“åœ¨è¯­ä¹‰æ— å…³çš„æ ‡ç­¾ï¼ˆä¾‹å¦‚â€œfoo/barâ€è€Œä¸æ˜¯â€œè´Ÿé¢/æ­£é¢â€ç”¨äºæƒ…æ„Ÿåˆ†æï¼‰çš„æ¼”ç¤ºä¸­æä¾›è¾“å…¥-æ ‡ç­¾æ˜ å°„æ—¶ï¼Œæ¨¡å‹ä¹Ÿå¯ä»¥å­¦ä¹ ã€‚ä»[å…ˆéªŒçŸ¥è¯†](https://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition)ä¸­ä»…ä¾èµ–çš„æ¨¡å‹åº”è¯¥ä¼šæœ‰æ€§èƒ½ä¸‹é™ï¼Œå› ä¸ºå®ƒæ— æ³•åˆ©ç”¨æ ‡ç­¾çš„è¯­ä¹‰æ„ä¹‰è¿›è¡Œé¢„æµ‹ã€‚äº‹å®ä¸Šï¼Œå°æ¨¡å‹çš„é¢„æµ‹èƒ½åŠ›ä¸‹é™ï¼Œè€Œ[LLM](https://en.wikipedia.org/wiki/Large_language_model)åˆ™æ²¡æœ‰ã€‚å¯¹ä½œè€…è€Œè¨€ï¼Œè¿™æ„å‘³ç€è™½ç„¶å°æ¨¡å‹ä¾èµ–äº[å…ˆéªŒçŸ¥è¯†](https://en.wikipedia.org/wiki/Prior_knowledge_for_pattern_recognition)ï¼Œä½†â€œ*å¤§å‹æ¨¡å‹åœ¨è¯­å¢ƒä¸­æœ‰èƒ½åŠ›å­¦ä¹ è¾“å…¥-æ ‡ç­¾æ˜ å°„ï¼Œå½“æ ‡ç­¾çš„è¯­ä¹‰æ€§è´¨è¢«ç§»é™¤æ—¶ã€‚*â€
- en: '![](../Images/d166a16fd271cee5b30b5c7c55da4a41.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d166a16fd271cee5b30b5c7c55da4a41.png)'
- en: 'image source: [here](https://arxiv.org/abs/2303.03846)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºï¼š[è¿™é‡Œ](https://arxiv.org/abs/2303.03846)
- en: '[The authors also took a look](https://arxiv.org/abs/2303.03846) at what is
    the effect of instruction tuning on ICL. During instruction tuning, instructions
    are given to the model that often contains questions and answers. So this process
    involves natural language labels, and the authors wondered whether it impacts
    an [LLMâ€™s](https://en.wikipedia.org/wiki/Large_language_model) ability to learn
    input-label mappings or exploit semantic prior knowledge. The experiments show
    that: â€œinstruction tuning improves the ability to learn input-label mappings,
    it strengthens the usage of semantic prior knowledge more.â€'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä½œè€…ä»¬è¿˜ç ”ç©¶äº†](https://arxiv.org/abs/2303.03846)æŒ‡ä»¤è°ƒæ•´å¯¹ ICL çš„å½±å“ã€‚åœ¨æŒ‡ä»¤è°ƒæ•´è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šæ¥æ”¶åˆ°åŒ…å«é—®é¢˜å’Œç­”æ¡ˆçš„æŒ‡ä»¤ã€‚å› æ­¤ï¼Œè¿™ä¸ªè¿‡ç¨‹æ¶‰åŠè‡ªç„¶è¯­è¨€æ ‡ç­¾ï¼Œä½œè€…ä»¬æƒ³çŸ¥é“è¿™æ˜¯å¦ä¼šå½±å“[LLM](https://en.wikipedia.org/wiki/Large_language_model)å­¦ä¹ è¾“å…¥-æ ‡ç­¾æ˜ å°„æˆ–åˆ©ç”¨è¯­ä¹‰å…ˆéªŒçŸ¥è¯†çš„èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼šâ€œæŒ‡ä»¤è°ƒæ•´æé«˜äº†å­¦ä¹ è¾“å…¥-æ ‡ç­¾æ˜ å°„çš„èƒ½åŠ›ï¼Œå®ƒå¢å¼ºäº†å¯¹è¯­ä¹‰å…ˆéªŒçŸ¥è¯†çš„ä½¿ç”¨ã€‚â€'
- en: 'So these results show that it is not only the architecture, the amount of data,
    and the prompt that influence ICL, but [for Google also the number of parameters
    themselves](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œè¿™äº›ç»“æœè¡¨æ˜ï¼Œä¸ä»…æ˜¯æ¶æ„ã€æ•°æ®é‡å’Œæç¤ºå½±å“ ICLï¼Œ[å¯¹äº Google æ¥è¯´ï¼Œå‚æ•°çš„æ•°é‡æœ¬èº«](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html)ä¹Ÿå¾ˆé‡è¦ï¼š
- en: These results underscore how the in-context learning behavior of language models
    can change depending on the scale of the language model, and that larger language
    models have an emergent ability to map inputs to many types of labels, a form
    of true symbolic reasoning in which inputâ€“label mappings can be learned for arbitrary
    symbols. ([source](https://arxiv.org/pdf/2303.03846.pdf))
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™äº›ç»“æœå¼ºè°ƒäº†è¯­è¨€æ¨¡å‹çš„è¯­å¢ƒå­¦ä¹ è¡Œä¸ºå¦‚ä½•æ ¹æ®è¯­è¨€æ¨¡å‹çš„è§„æ¨¡è€Œå˜åŒ–ï¼Œä»¥åŠæ›´å¤§çš„è¯­è¨€æ¨¡å‹å…·æœ‰å°†è¾“å…¥æ˜ å°„åˆ°å¤šç§ç±»å‹æ ‡ç­¾çš„çªç°èƒ½åŠ›ï¼Œè¿™æ˜¯ä¸€ç§çœŸæ­£çš„ç¬¦å·æ¨ç†å½¢å¼ï¼Œå…¶ä¸­è¾“å…¥-æ ‡ç­¾æ˜ å°„å¯ä»¥ä¸ºä»»æ„ç¬¦å·å­¦ä¹ ã€‚
    ([source](https://arxiv.org/pdf/2303.03846.pdf))
- en: '[](https://salvatore-raieli.medium.com/scaling-isnt-everything-how-bigger-models-fail-harder-d64589be4f04?source=post_page-----55bde1180610--------------------------------)
    [## Scaling Isnâ€™t Everything: How Bigger Models Fail Harder'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://salvatore-raieli.medium.com/scaling-isnt-everything-how-bigger-models-fail-harder-d64589be4f04?source=post_page-----55bde1180610--------------------------------)
    [## æ‰©å±•å¹¶éä¸€åˆ‡ï¼šæ›´å¤§æ¨¡å‹å¦‚ä½•æ›´å®¹æ˜“å¤±è´¥'
- en: Are Large Language Models really understanding programming languages?
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯å¦çœŸçš„ç†è§£ç¼–ç¨‹è¯­è¨€ï¼Ÿ
- en: salvatore-raieli.medium.com](https://salvatore-raieli.medium.com/scaling-isnt-everything-how-bigger-models-fail-harder-d64589be4f04?source=post_page-----55bde1180610--------------------------------)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[salvatore-raieli.medium.com](https://salvatore-raieli.medium.com/scaling-isnt-everything-how-bigger-models-fail-harder-d64589be4f04?source=post_page-----55bde1180610--------------------------------)'
- en: Conclusions, challenges, and perspective
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®ºã€æŒ‘æˆ˜å’Œå‰æ™¯
- en: '![](../Images/986b2920355032f6fc74247aeef7d0a9.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/986b2920355032f6fc74247aeef7d0a9.png)'
- en: Photo by [Nadine Shaabana](https://unsplash.com/@nadineshaabana?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[Nadine Shaabana](https://unsplash.com/@nadineshaabana?utm_source=medium&utm_medium=referral)
    åœ¨ [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) ä¸Šä¼ çš„ç…§ç‰‡'
- en: â€œSeparate text from context and all that remains is a con.â€ â€• **Stewart Stafford**
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œå°†æ–‡æœ¬ä¸ä¸Šä¸‹æ–‡åˆ†å¼€ï¼Œå‰©ä¸‹çš„åªæ˜¯éª—å±€ã€‚â€ â€• **æ–¯å›¾å°”ç‰¹Â·æ–¯å¡”ç¦å¾·**
- en: ''
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: â€œWords are never good or bad on their own, context makes them so.â€ â€• **Abhijit
    Naskar**
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: â€œå•è¯æœ¬èº«ä»æ¥æ²¡æœ‰å¥½åä¹‹åˆ†ï¼Œæ˜¯ä¸Šä¸‹æ–‡è®©å®ƒä»¬å¦‚æ­¤ã€‚â€ â€• **é˜¿æ¯”å‰ç‰¹Â·çº³æ–¯å¡å°”**
- en: In-context learning is one of the most interesting and elusive behaviors of
    [LLMs](https://en.wikipedia.org/wiki/Large_language_model). First admired with
    the publication of GPT-3, it has excited the community about its possible applications.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨-context å­¦ä¹ æ˜¯ [LLMs](https://en.wikipedia.org/wiki/Large_language_model) æœ€æœ‰è¶£ä¸”éš¾ä»¥æ‰æ‘¸çš„è¡Œä¸ºä¹‹ä¸€ã€‚GPT-3
    å‘å¸ƒæ—¶é¦–æ¬¡å—åˆ°èµèµï¼Œå®ƒè®©ç¤¾åŒºå¯¹å…¶æ½œåœ¨åº”ç”¨å……æ»¡å…´å¥‹ã€‚
- en: ICL in simple terms is the ability to learn from analogy. It only takes a few
    examples in a demonstration for the model to make a prediction. Which allows the
    model unprecedented versatility and the possibility of developing endless applications.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ICL ç®€å•æ¥è¯´å°±æ˜¯ä»ç±»æ¯”ä¸­å­¦ä¹ çš„èƒ½åŠ›ã€‚åªéœ€åœ¨æ¼”ç¤ºä¸­æä¾›å‡ ä¸ªä¾‹å­ï¼Œæ¨¡å‹å°±èƒ½åšå‡ºé¢„æµ‹ã€‚è¿™ä½¿æ¨¡å‹å…·å¤‡å‰æ‰€æœªæœ‰çš„å¤šåŠŸèƒ½æ€§å’Œæ— é™åº”ç”¨çš„å‘å±•å¯èƒ½ã€‚
- en: Despite this, we still do not understand precisely how it originates during
    training. We have seen the importance of training data, the prompt, or attention
    itself. Today, with the idea of wanting to replace attention-based models with
    new architectures we need to understand how to preserve ICL.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬ä»ç„¶ä¸å®Œå…¨ç†è§£å®ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•äº§ç”Ÿã€‚æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†è®­ç»ƒæ•°æ®ã€æç¤ºæˆ–æ³¨æ„åŠ›æœ¬èº«çš„é‡è¦æ€§ã€‚ä»Šå¤©ï¼Œéšç€å¸Œæœ›ç”¨æ–°æ¶æ„å–ä»£åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹çš„æƒ³æ³•ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£å¦‚ä½•ä¿ç•™
    ICLã€‚
- en: 'Research in ICL is very active, some of the lines of research are:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ICL ç ”ç©¶éå¸¸æ´»è·ƒï¼Œä¸€äº›ç ”ç©¶æ–¹å‘åŒ…æ‹¬ï¼š
- en: '**New Pretraining Strategie**s, as mentioned if a training strategy increases
    performance classically (decrease in perplexity) it does not mean that it increases
    the ICL skills of the model. Therefore, focused strategies are sought to increase
    a modelâ€™s ICL skills.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–°é¢„è®­ç»ƒç­–ç•¥**ï¼Œå¦‚å‰æ‰€è¿°ï¼Œå¦‚æœä¸€ç§è®­ç»ƒç­–ç•¥ä¼ ç»Ÿä¸Šæé«˜äº†æ€§èƒ½ï¼ˆå›°æƒ‘åº¦ä¸‹é™ï¼‰ï¼Œå¹¶ä¸æ„å‘³ç€å®ƒæé«˜äº†æ¨¡å‹çš„ ICL æŠ€èƒ½ã€‚å› æ­¤ï¼Œæ­£åœ¨å¯»æ‰¾ä¸“æ³¨äºæé«˜æ¨¡å‹
    ICL æŠ€èƒ½çš„ç­–ç•¥ã€‚'
- en: '**ICL Ability Distillation**, ICL seems to emerge with the scale of the model,
    but if one were able to distill these skills into smaller models we would have
    savings in computational cost, memory, and infrastructure. Therefore, distillation
    seems promising for smaller models with ICL. [Preliminary studies look promising](https://arxiv.org/abs/2212.08410).'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ICL èƒ½åŠ›è’¸é¦**ï¼ŒICL ä¼¼ä¹éšç€æ¨¡å‹çš„è§„æ¨¡è€Œå‡ºç°ï¼Œä½†å¦‚æœèƒ½å¤Ÿå°†è¿™äº›æŠ€èƒ½è’¸é¦åˆ°è¾ƒå°çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å°†èŠ‚çœè®¡ç®—æˆæœ¬ã€å†…å­˜å’ŒåŸºç¡€è®¾æ–½ã€‚å› æ­¤ï¼Œè’¸é¦å¯¹äºå…·æœ‰
    ICL çš„è¾ƒå°æ¨¡å‹ä¼¼ä¹å¾ˆæœ‰å‰æ™¯ã€‚[åˆæ­¥ç ”ç©¶æ˜¾ç¤ºå‰æ™¯å…‰æ˜](https://arxiv.org/abs/2212.08410)ã€‚'
- en: '**ICL Robustness.** As we have seen ICL skills are not stable, permutations
    and changes in the format of the demonstration impact ICL. [In one study it is
    shown](https://arxiv.org/abs/2209.07661) that increasing robustness comes at the
    cost of decreasing accuracy, so we need studies that delve into how ICL works.
    A better theoretical understanding can help develop a more robust ICL.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ICL é²æ£’æ€§**ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€è§ï¼ŒICL æŠ€èƒ½å¹¶ä¸ç¨³å®šï¼Œæ¼”ç¤ºæ ¼å¼çš„æ’åˆ—å’Œå˜åŒ–ä¼šå½±å“ ICLã€‚[æœ‰ä¸€é¡¹ç ”ç©¶è¡¨æ˜](https://arxiv.org/abs/2209.07661)ï¼Œæé«˜é²æ£’æ€§ä¼šä»¥é™ä½å‡†ç¡®åº¦ä¸ºä»£ä»·ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ·±å…¥ç ”ç©¶
    ICL çš„å·¥ä½œæœºåˆ¶ã€‚æ›´å¥½çš„ç†è®ºç†è§£å¯ä»¥å¸®åŠ©å¼€å‘æ›´é²æ£’çš„ ICLã€‚'
- en: '**ICL Efficiency and Scalability.** ICL requires different examples in the
    demonstration. In theory, more examples improve ICL. Increasing the number of
    examples has a computational cost, which comes from calculating attention (efficiency).
    The other challenge is that you cannot add more examples than the context window
    allows (scalability). [As we saw in a previous article](/speak-to-me-how-many-words-a-model-is-reading-331e3af86d27),
    research has been very active in how to extend the context window (and what strategies
    have been used), although it is unclear whether the model can then exploit it.
    Also, in some cases, inverse scaling was seen, where the model instead of following
    in-context instruction regurgitated memorized data.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ICLçš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚** ICLéœ€è¦åœ¨æ¼”ç¤ºä¸­ä½¿ç”¨ä¸åŒçš„ç¤ºä¾‹ã€‚ç†è®ºä¸Šï¼Œæ›´å¤šçš„ç¤ºä¾‹å¯ä»¥æ”¹å–„ICLã€‚å¢åŠ ç¤ºä¾‹çš„æ•°é‡æœ‰è®¡ç®—æˆæœ¬ï¼Œè¿™æ¥è‡ªäºè®¡ç®—æ³¨æ„åŠ›ï¼ˆæ•ˆç‡ï¼‰ã€‚å¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ï¼Œä½ ä¸èƒ½æ·»åŠ è¶…è¿‡ä¸Šä¸‹æ–‡çª—å£å…è®¸çš„ç¤ºä¾‹ï¼ˆå¯æ‰©å±•æ€§ï¼‰ã€‚[æ­£å¦‚æˆ‘ä»¬åœ¨ä¹‹å‰çš„æ–‡ç« ä¸­çœ‹åˆ°çš„](/speak-to-me-how-many-words-a-model-is-reading-331e3af86d27)ï¼Œç ”ç©¶åœ¨å¦‚ä½•æ‰©å±•ä¸Šä¸‹æ–‡çª—å£ï¼ˆä»¥åŠä½¿ç”¨äº†å“ªäº›ç­–ç•¥ï¼‰æ–¹é¢éå¸¸æ´»è·ƒï¼Œå°½ç®¡å°šä¸æ¸…æ¥šæ¨¡å‹æ˜¯å¦èƒ½å¤Ÿåˆ©ç”¨å®ƒã€‚æ­¤å¤–ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå‡ºç°äº†é€†å‘æ‰©å±•ï¼Œå…¶ä¸­æ¨¡å‹ä¸æ˜¯éµå¾ªä¸Šä¸‹æ–‡ä¸­çš„æŒ‡ä»¤ï¼Œè€Œæ˜¯é‡å¤äº†è®°å¿†çš„æ•°æ®ã€‚'
- en: Another line of research is the development of techniques that can improve ICL
    by acting on the format of the prompt. Several interesting approaches have been
    proposed over time (including Chain of thought (COT), Self-consistency COT, Tree
    of Thoughts, and so on). These approaches have shown success in being able to
    improve model performance for mathematical exercises and other reasoning problems.
    All this is done simply through modifications of the prompt. In this article,
    I have focused on more mechanistic aspects of the model, training data, the prompt,
    and how ICL emerges. In the next article, I will discuss these approaches in detail.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªç ”ç©¶æ–¹å‘æ˜¯å¼€å‘å¯ä»¥é€šè¿‡è°ƒæ•´æç¤ºæ ¼å¼æ¥æé«˜ICLï¼ˆIn-context Learningï¼Œæƒ…å¢ƒå­¦ä¹ ï¼‰çš„æŠ€æœ¯ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œå·²ç»æå‡ºäº†å‡ ç§æœ‰è¶£çš„æ–¹æ³•ï¼ˆåŒ…æ‹¬æ€ç»´é“¾ï¼ˆCOTï¼‰ã€è‡ªä¸€è‡´æ€§COTã€æ€ç»´æ ‘ç­‰ï¼‰ã€‚è¿™äº›æ–¹æ³•åœ¨æ”¹å–„æ•°å­¦ç»ƒä¹ å’Œå…¶ä»–æ¨ç†é—®é¢˜çš„æ¨¡å‹æ€§èƒ½æ–¹é¢å·²æ˜¾ç¤ºå‡ºæˆåŠŸã€‚æ‰€æœ‰è¿™äº›éƒ½æ˜¯é€šè¿‡ç®€å•åœ°ä¿®æ”¹æç¤ºå®ç°çš„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å…³æ³¨äº†æ¨¡å‹çš„æ›´æœºæ¢°åŒ–çš„æ–¹é¢ã€è®­ç»ƒæ•°æ®ã€æç¤ºä»¥åŠICLæ˜¯å¦‚ä½•å‡ºç°çš„ã€‚åœ¨ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è¯¦ç»†è®¨è®ºè¿™äº›æ–¹æ³•ã€‚
- en: What do guys think? Let me know in the comments
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤§å®¶æ€ä¹ˆçœ‹ï¼Ÿåœ¨è¯„è®ºä¸­å‘Šè¯‰æˆ‘å§ã€‚
- en: 'If you have found this interesting:'
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è§‰å¾—è¿™å¾ˆæœ‰è¶£ï¼š
- en: '*You can look for my other articles, you can also* [***subscribe***](https://salvatore-raieli.medium.com/subscribe)
    *to get notified when I publish articles, you can* [***become a Medium member***](https://medium.com/@salvatore-raieli/membership)
    *to access all its stories (affiliate links of the platform for which I get small
    revenues without cost to you) and you can also connect or reach me on*[***LinkedIn***](https://www.linkedin.com/in/salvatore-raieli/)***.***'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä½ å¯ä»¥æŸ¥çœ‹æˆ‘çš„å…¶ä»–æ–‡ç« ï¼Œä¹Ÿå¯ä»¥* [***è®¢é˜…***](https://salvatore-raieli.medium.com/subscribe)
    *ä»¥ä¾¿åœ¨æˆ‘å‘å¸ƒæ–‡ç« æ—¶æ”¶åˆ°é€šçŸ¥ï¼Œä½ ä¹Ÿå¯ä»¥* [***æˆä¸ºMediumä¼šå‘˜***](https://medium.com/@salvatore-raieli/membership)
    *æ¥è®¿é—®æ‰€æœ‰æ•…äº‹ï¼ˆè¿™æ˜¯å¹³å°çš„ä¼šå‘˜é“¾æ¥ï¼Œæˆ‘ä»ä¸­è·å¾—å°‘é‡æ”¶å…¥ï¼Œä½†å¯¹ä½ æ²¡æœ‰è´¹ç”¨ï¼‰ï¼Œä½ è¿˜å¯ä»¥åœ¨*[***LinkedIn***](https://www.linkedin.com/in/salvatore-raieli/)***ä¸Šä¸æˆ‘è”ç³»ã€‚***'
- en: '*Here is the link to my GitHub repository, where I am planning to collect code
    and many resources related to machine learning, artificial intelligence, and more.*'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*è¿™é‡Œæ˜¯æˆ‘çš„GitHubä»“åº“çš„é“¾æ¥ï¼Œæˆ‘è®¡åˆ’åœ¨è¿™é‡Œæ”¶é›†ä¸æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ç­‰ç›¸å…³çš„ä»£ç å’Œè®¸å¤šèµ„æºã€‚*'
- en: '[](https://github.com/SalvatoreRa/tutorial?source=post_page-----55bde1180610--------------------------------)
    [## GitHub - SalvatoreRa/tutorial: Tutorials on machine learning, artificial intelligence,
    data scienceâ€¦'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[## GitHub - SalvatoreRa/tutorial: æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€æ•°æ®ç§‘å­¦çš„æ•™ç¨‹â€¦](https://github.com/SalvatoreRa/tutorial?source=post_page-----55bde1180610--------------------------------)'
- en: Tutorials on machine learning, artificial intelligence, data science with math
    explanation and reusable code (in pythonâ€¦
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å…³äºæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€æ•°æ®ç§‘å­¦çš„æ•™ç¨‹ï¼ŒåŒ…æ‹¬æ•°å­¦è§£é‡Šå’Œå¯é‡å¤ä½¿ç”¨çš„ä»£ç ï¼ˆç”¨Pythonç¼–å†™â€¦ï¼‰ã€‚
- en: github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----55bde1180610--------------------------------)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/SalvatoreRa/tutorial?source=post_page-----55bde1180610--------------------------------)'
- en: Reference
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: Here is the list of the principal references I consulted to write this article,
    only the first name for an article is cited. I suggest also them if you want to
    deepen on the topic.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æˆ‘æ’°å†™æœ¬æ–‡æ—¶å‚è€ƒçš„ä¸»è¦æ–‡çŒ®åˆ—è¡¨ï¼Œä»…å¼•ç”¨äº†æ–‡ç« çš„ç¬¬ä¸€ä¸ªåå­—ã€‚å¦‚æœä½ æƒ³æ·±å…¥äº†è§£è¿™ä¸ªè¯é¢˜ï¼Œæˆ‘ä¹Ÿæ¨èè¿™äº›æ–‡çŒ®ã€‚
- en: Brown, 2020, Language Models are Few-Shot Learners, [link](https://arxiv.org/abs/2005.14165)
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Brown, 2020, è¯­è¨€æ¨¡å‹æ˜¯å°‘æ ·æœ¬å­¦ä¹ è€…ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2005.14165)
- en: Dong, 2022, A Survey on In-context Learning, [link](https://arxiv.org/abs/2301.00234)
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dong, 2022, å…³äºæƒ…å¢ƒå­¦ä¹ çš„è°ƒæŸ¥ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2301.00234)
- en: Zhao, A Survey of Large Language Models, [link](https://arxiv.org/abs/2303.18223)
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: èµµï¼Œã€Šå¤§è¯­è¨€æ¨¡å‹è°ƒæŸ¥ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2303.18223)
- en: Xie, 2022, How does in-context learning work? A framework for understanding
    the differences from traditional supervised learning. [link](https://ai.stanford.edu/blog/understanding-incontext/)
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è°¢ï¼Œ2022å¹´ï¼Œã€Šä¸Šä¸‹æ–‡å­¦ä¹ æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿç†è§£ä¸ä¼ ç»Ÿç›‘ç£å­¦ä¹ çš„å·®å¼‚çš„æ¡†æ¶ã€‹ï¼Œ[é“¾æ¥](https://ai.stanford.edu/blog/understanding-incontext/)
- en: Wei, 2022, Emergent Abilities of Large Language Models, [link](https://arxiv.org/abs/2206.07682)
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é­ï¼Œ2022å¹´ï¼Œã€Šå¤§è¯­è¨€æ¨¡å‹çš„çªç°èƒ½åŠ›ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2206.07682)
- en: Zhou, 2022, Teaching Algorithmic Reasoning via In-context Learning, [link](https://arxiv.org/abs/2211.09066)
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‘¨ï¼Œ2022å¹´ï¼Œã€Šé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ æ•™æˆç®—æ³•æ¨ç†ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2211.09066)
- en: '[Vinita Silaparasetty](https://medium.com/u/8f22c49c614?source=post_page-----55bde1180610--------------------------------),
    What is Prompt Engineering?, [link](https://medium.com/@vinitasilaparasetty/what-is-prompt-engineering-8221e0aa619d)'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Vinita Silaparasetty](https://medium.com/u/8f22c49c614?source=post_page-----55bde1180610--------------------------------)ï¼Œã€Šä»€ä¹ˆæ˜¯æç¤ºå·¥ç¨‹ï¼Ÿã€‹ï¼Œ[é“¾æ¥](https://medium.com/@vinitasilaparasetty/what-is-prompt-engineering-8221e0aa619d)'
- en: '[Fareed Khan](https://medium.com/u/b856005e5ecd?source=post_page-----55bde1180610--------------------------------),
    Prompt Engineering Complete Guide, [link](https://medium.com/@fareedkhandev/prompt-engineering-complete-guide-2968776f0431)'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Fareed Khan](https://medium.com/u/b856005e5ecd?source=post_page-----55bde1180610--------------------------------)ï¼Œã€Šæç¤ºå·¥ç¨‹å®Œå…¨æŒ‡å—ã€‹ï¼Œ[é“¾æ¥](https://medium.com/@fareedkhandev/prompt-engineering-complete-guide-2968776f0431)'
- en: '[Paul DelSignore](https://medium.com/u/6202cb40e768?source=post_page-----55bde1180610--------------------------------),
    The Dark Side Of Prompt Engineering, [link](https://medium.com/the-generator/the-dark-side-of-prompt-engineering-33b8087ffd59)'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Paul DelSignore](https://medium.com/u/6202cb40e768?source=post_page-----55bde1180610--------------------------------)ï¼Œã€Šæç¤ºå·¥ç¨‹çš„é»‘æš—é¢ã€‹ï¼Œ[é“¾æ¥](https://medium.com/the-generator/the-dark-side-of-prompt-engineering-33b8087ffd59)'
- en: '[Babar M Bhatti](https://medium.com/u/10dee34829b?source=post_page-----55bde1180610--------------------------------),
    The Art and Science of Crafting Effective Prompts for LLMs, [link](https://thebabar.medium.com/the-art-and-science-of-crafting-effective-prompts-for-llms-e04447e8f96a)'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Babar M Bhatti](https://medium.com/u/10dee34829b?source=post_page-----55bde1180610--------------------------------)ï¼Œã€Šä¸ºLLMsåˆ¶ä½œæœ‰æ•ˆæç¤ºçš„è‰ºæœ¯ä¸ç§‘å­¦ã€‹ï¼Œ[é“¾æ¥](https://thebabar.medium.com/the-art-and-science-of-crafting-effective-prompts-for-llms-e04447e8f96a)'
- en: Dai, 2022, Why Can GPT Learn In-Context? Language Models Implicitly Perform
    Gradient Descent as Meta-Optimizers, [link](https://arxiv.org/abs/2212.10559)
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ´ï¼Œ2022å¹´ï¼Œã€Šä¸ºä»€ä¹ˆGPTèƒ½åœ¨ä¸Šä¸‹æ–‡ä¸­å­¦ä¹ ï¼Ÿè¯­è¨€æ¨¡å‹éšå¼åœ°æ‰§è¡Œæ¢¯åº¦ä¸‹é™ä½œä¸ºå…ƒä¼˜åŒ–å™¨ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2212.10559)
- en: Shin, 2022, On the Effect of Pretraining Corpora on In-context Learning by a
    Large-scale Language Model, [link](https://aclanthology.org/2022.naacl-main.380/)
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¾›ï¼Œ2022å¹´ï¼Œã€Šå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒè¯­æ–™å¯¹ä¸Šä¸‹æ–‡å­¦ä¹ çš„å½±å“ã€‹ï¼Œ[é“¾æ¥](https://aclanthology.org/2022.naacl-main.380/)
- en: '[Cameron R. Wolfe, Ph.D.](https://medium.com/u/28aa6026c553?source=post_page-----55bde1180610--------------------------------),
    Language Model Scaling Laws and GPT-3, [link](/language-model-scaling-laws-and-gpt-3-5cdc034e67bb)'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Cameron R. Wolfe, Ph.D.](https://medium.com/u/28aa6026c553?source=post_page-----55bde1180610--------------------------------)ï¼Œã€Šè¯­è¨€æ¨¡å‹çš„æ‰©å±•æ³•åˆ™ä¸GPT-3ã€‹ï¼Œ[é“¾æ¥](/language-model-scaling-laws-and-gpt-3-5cdc034e67bb)'
- en: Xie, 2021, An Explanation of In-context Learning as Implicit Bayesian Inference
    , [link](https://arxiv.org/abs/2111.02080)
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è°¢ï¼Œ2021å¹´ï¼Œã€Šå°†ä¸Šä¸‹æ–‡å­¦ä¹ è§£é‡Šä¸ºéšå¼è´å¶æ–¯æ¨æ–­ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2111.02080)
- en: HuszÃ¡r, 2022, Implicit Bayesian Inference in Large Language Models, [link](https://www.inference.vc/implicit-bayesian-inference-in-sequence-models/)
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: HuszÃ¡rï¼Œ2022å¹´ï¼Œã€Šå¤§è¯­è¨€æ¨¡å‹ä¸­çš„éšå¼è´å¶æ–¯æ¨æ–­ã€‹ï¼Œ[é“¾æ¥](https://www.inference.vc/implicit-bayesian-inference-in-sequence-models/)
- en: 'Min, 2022, Rethinking the Role of Demonstrations: What Makes In-Context Learning
    Work?, [link](https://arxiv.org/abs/2202.12837)'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é—µï¼Œ2022å¹´ï¼Œã€Šé‡æ–°æ€è€ƒç¤ºèŒƒçš„ä½œç”¨ï¼šä»€ä¹ˆä½¿å¾—ä¸Šä¸‹æ–‡å­¦ä¹ æœ‰æ•ˆï¼Ÿã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2202.12837)
- en: Chan, 2022, Data Distributional Properties Drive Emergent In-Context Learning
    in Transformers, [link](https://arxiv.org/abs/2205.05055)
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é™ˆï¼Œ2022å¹´ï¼Œã€Šæ•°æ®åˆ†å¸ƒå±æ€§é©±åŠ¨å˜å‹å™¨ä¸­çš„çªç°ä¸Šä¸‹æ–‡å­¦ä¹ ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2205.05055)
- en: Liu, 2023, What Makes Good In-Context Examples for GPT-3?, [link](https://aclanthology.org/2022.deelio-1.10/)
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ˜ï¼Œ2023å¹´ï¼Œã€Šä»€ä¹ˆæ ·çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹å¯¹GPT-3æœ‰æ•ˆï¼Ÿã€‹ï¼Œ[é“¾æ¥](https://aclanthology.org/2022.deelio-1.10/)
- en: '[Priyanka](https://medium.com/u/29db232e8826?source=post_page-----55bde1180610--------------------------------),
    Perplexity of Language Models, [link](https://medium.com/@priyankads/perplexity-of-language-models-41160427ed72)'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Priyanka](https://medium.com/u/29db232e8826?source=post_page-----55bde1180610--------------------------------)ï¼Œã€Šè¯­è¨€æ¨¡å‹çš„å›°æƒ‘åº¦ã€‹ï¼Œ[é“¾æ¥](https://medium.com/@priyankads/perplexity-of-language-models-41160427ed72)'
- en: Olsson, 2022, In-context Learning and Induction Heads, link
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¥¥å°”æ¾ï¼Œ2022å¹´ï¼Œã€Šä¸Šä¸‹æ–‡å­¦ä¹ ä¸å½’çº³å¤´ã€‹ï¼Œ[é“¾æ¥]
- en: Wies, 2023, The Learnability of In-Context Learning, [link](https://arxiv.org/abs/2303.07895)
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wies, 2023ï¼Œã€Šä¸Šä¸‹æ–‡å­¦ä¹ çš„å¯å­¦ä¹ æ€§ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2303.07895)
- en: AkyÃ¼rek, 2022, What learning algorithm is in-context learning? Investigations
    with linear models, [link](https://arxiv.org/abs/2211.15661)
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AkyÃ¼rek, 2022ï¼Œã€Šä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å­¦ä¹ çš„å­¦ä¹ ç®—æ³•ï¼Ÿçº¿æ€§æ¨¡å‹çš„ç ”ç©¶ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2211.15661)
- en: Oswald, 2022, Transformers learn in-context by gradient descent, [link](https://arxiv.org/abs/2212.07677)
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Oswald, 2022ï¼Œã€Šå˜å‹å™¨é€šè¿‡æ¢¯åº¦ä¸‹é™åœ¨ä¸Šä¸‹æ–‡ä¸­å­¦ä¹ ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2212.07677)
- en: Wei, 2023, Larger language models do in-context learning differently, [link](https://arxiv.org/abs/2303.03846)
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wei, 2023ï¼Œã€Šæ›´å¤§çš„è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„è¡¨ç°ä¸åŒã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2303.03846)
- en: Google blog, Larger language models do in-context learning differently, [link](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html)
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google åšå®¢ï¼Œã€Šæ›´å¤§çš„è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„è¡¨ç°ä¸åŒã€‹ï¼Œ[é“¾æ¥](https://ai.googleblog.com/2023/05/larger-language-models-do-in-context.html)
- en: Zewe, Solving a machine-learning mystery, [link](https://news.mit.edu/2023/large-language-models-in-context-learning-0207)
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zeweï¼Œã€Šè§£å†³æœºå™¨å­¦ä¹ çš„è°œå›¢ã€‹ï¼Œ[é“¾æ¥](https://news.mit.edu/2023/large-language-models-in-context-learning-0207)
- en: Kaddour, 2023, Challenges and Applications of Large Language Models, [link](https://arxiv.org/abs/2307.10169)
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kaddour, 2023ï¼Œã€Šå¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‘æˆ˜ä¸åº”ç”¨ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2307.10169)
- en: Magister, 2022, Teaching Small Language Models to Reason, [link](https://arxiv.org/abs/2212.08410)
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Magister, 2022ï¼Œã€Šæ•™å°å‹è¯­è¨€æ¨¡å‹æ¨ç†ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2212.08410)
- en: Chen, 2022, On the Relation between Sensitivity and Accuracy in In-context Learning,
    [link](https://arxiv.org/abs/2209.07661)
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chen, 2022ï¼Œã€Šä¸Šä¸‹æ–‡å­¦ä¹ ä¸­æ•æ„Ÿæ€§ä¸å‡†ç¡®æ€§ä¹‹é—´çš„å…³ç³»ã€‹ï¼Œ[é“¾æ¥](https://arxiv.org/abs/2209.07661)
