- en: 'Inspecting Data Science Predictions: Individual + Negative Case Analysis'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查数据科学预测：个人 + 负面案例分析
- en: 原文：[https://towardsdatascience.com/inspecting-data-science-predictions-individual-negative-case-analysis-d2e4ddbcf830](https://towardsdatascience.com/inspecting-data-science-predictions-individual-negative-case-analysis-d2e4ddbcf830)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/inspecting-data-science-predictions-individual-negative-case-analysis-d2e4ddbcf830](https://towardsdatascience.com/inspecting-data-science-predictions-individual-negative-case-analysis-d2e4ddbcf830)
- en: How to inspect specific predictions and conduct negative case analyses
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何检查特定的预测并进行负面案例分析
- en: '[](https://adamrossnelson.medium.com/?source=post_page-----d2e4ddbcf830--------------------------------)[![Adam
    Ross Nelson](../Images/030b86a8c8bbd40c6acf60d1e387950c.png)](https://adamrossnelson.medium.com/?source=post_page-----d2e4ddbcf830--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d2e4ddbcf830--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d2e4ddbcf830--------------------------------)
    [Adam Ross Nelson](https://adamrossnelson.medium.com/?source=post_page-----d2e4ddbcf830--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://adamrossnelson.medium.com/?source=post_page-----d2e4ddbcf830--------------------------------)[![Adam
    Ross Nelson](../Images/030b86a8c8bbd40c6acf60d1e387950c.png)](https://adamrossnelson.medium.com/?source=post_page-----d2e4ddbcf830--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d2e4ddbcf830--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d2e4ddbcf830--------------------------------)
    [Adam Ross Nelson](https://adamrossnelson.medium.com/?source=post_page-----d2e4ddbcf830--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d2e4ddbcf830--------------------------------)
    ·14 min read·Jul 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----d2e4ddbcf830--------------------------------)
    ·14分钟阅读·2023年7月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: 'Somewhere around 40 to 43% of the time when I am showing new learners how to
    use the `.predict()` methods I get the following question:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当我向新学习者展示如何使用`.predict()`方法时，大约有40%到43%的时间会得到以下问题：
- en: '**Where are the predictions?**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测在哪里？**'
- en: I wish this was a question learners would ask more often. It is an insightful
    question, especially for folks who are newer to Python, data science, and who
    may be seeing the `.predict()` method for the first time.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这是学习者们更多提问的问题。这是一个深刻的问题，特别是对于那些刚接触Python、数据科学，并且可能第一次看到`.predict()`方法的人。
- en: For sure the number of groups who ask this question is less than half, but possibly,
    the proportion is lower than 30 or 20%. I don’t keep precise track.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '-   确实，提出这个问题的群体数量少于一半，但可能这个比例低于30%或20%。我并没有精确跟踪。'
- en: In part one of this deep dive, this article will first show how to build a simple
    predictive model, second how to generate predictions, and third cover how to inspect
    predictions more closely.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本深度分析的第一部分，本文将首先展示如何构建一个简单的预测模型，其次展示如何生成预测，最后介绍如何更仔细地检查预测。
- en: For part two of this deep dive this article will also show why it is useful
    to know how to inspect individual predictions plus also why it is necessary to
    inspect individual predictions. Having the ability to inspect individual predictions
    opens a range of analytical avenues, for example not the least of which is the
    negative case analysis.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本深度分析的第二部分，本文还将展示为什么了解如何检查个别预测是有用的，以及为什么有必要检查个别预测。具备检查个别预测的能力可以开启一系列分析途径，例如负面案例分析。
- en: 'Part One: Predict Methods'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分：预测方法
- en: 'If you are not yet familiar with building predictive model I suggest you consider
    reading one or more other articles that cover this topic. Chapter 11 of [*Confident
    Data Science: Discovering The Essential Skills of Data Science*](https://a.co/d/hS2cbou)
    (by, Me) shows how to build predictive models.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你还不熟悉构建预测模型，我建议你考虑阅读一篇或多篇涉及此主题的其他文章。我所著的[*Confident Data Science: Discovering
    The Essential Skills of Data Science*](https://a.co/d/hS2cbou)第11章展示了如何构建预测模型。'
- en: 'For example, in [Fake Birds & Machine Learning: Using the popular bird variety
    data to demonstrate nearest neighbors classification](/fake-birds-machine-learning-acc553312a8f)
    I shared code that trained a machine learning model that can predict bird species
    variety based on a bird’s weight, length, location, and color. This fake birds
    example demonstrated predictive modeling with the [fake bird species data](/how-to-make-fictional-data-7a79ce86a350).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在[假鸟与机器学习：使用流行的鸟类数据演示最近邻分类](/fake-birds-machine-learning-acc553312a8f)中，我分享了训练机器学习模型的代码，该模型可以根据鸟的重量、长度、位置和颜色预测鸟类品种。这个假鸟示例展示了如何使用[假鸟品种数据](/how-to-make-fictional-data-7a79ce86a350)进行预测建模。
- en: A Simple Predictive Model
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个简单的预测模型
- en: To help us focus on inspecting specific individual predictions this subsection
    will speed through the creation of a predictive model. To be speedy this subsection
    skips optimizing hyper parameters and also skips a few data preparation steps.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们专注于检查特定的个体预测，本小节将快速创建一个预测模型。为了加快速度，本小节省略了优化超参数和一些数据准备步骤。
- en: Also to speed things along we look at evaluation through alternate methods aside
    from the more traditional `accuracy_score`, `classification_report`, and `confusion_matrix`
    functions from SciKit Learn.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加快速度，我们还会通过其他方法评估，而不仅仅使用传统的`accuracy_score`、`classification_report`和`confusion_matrix`函数。
- en: For this simple, speedy, predictive model, lets take a look at automobile data.
    Speedy pun intended here!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个简单、快速的预测模型，我们来看看汽车数据。这里的“快速”确实是有意的！
- en: Usually we would like a set of data that consists of more than a few hundred
    observations. However, I am fond of using this automobile data, from Seaborn,
    because almost everyone understands or knows a few basics about automobiles.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通常我们希望有一个包含几百个观察值的数据集。然而，我喜欢使用这个来自Seaborn的汽车数据，因为几乎每个人都理解或知道一些关于汽车的基本知识。
- en: '**First, open the data.** As is customary for many boot camp demonstrations,
    or demonstration articles online you first open the data.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**第一步，打开数据。** 和许多训练营演示或在线演示文章一样，你首先打开数据。'
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Second, prepare the data.** After that you prepare a target variable. For
    this demonstration we’ll create a target variable to predict that will equal 1
    when the vehicle was manufactured in the United States and then 0 when manufactured
    elsewhere.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**第二步，准备数据。** 之后你准备一个目标变量。在本演示中，我们将创建一个目标变量，用于预测当车辆在美国制造时为1，其他地方制造时为0。'
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Third, train, test, and split.** Another customary step is to also train,
    test, and split (`train, test, split`) the data as follows.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**第三步，训练、测试和拆分。** 另一个惯例步骤是训练、测试和拆分（`train, test, split`）数据，如下所示。'
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Fourth, train the model.** Now the data are ready for training.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**第四步，训练模型。** 现在数据已经准备好进行训练。'
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Generating Predictions With the Model
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用模型生成预测
- en: '**Fifth, generate predictions from the trained model.** Once trained the model
    is ready to generate predictions.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**第五步，从训练好的模型中生成预测。** 一旦训练完成，模型就可以生成预测。'
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Sixth, begin the exploration/evaluation process.** Once generated, the predictions
    are ready for inspection. Here I will indulge in less-common inspection options.
    In the bootcamp context, of course, I share the standard `accuracy_score`, `classification_report`,
    and `confusion_matrix` functions from SciKit Learn (along with the equivalents
    for mean square errors and root mean squared errors). However, I also believe
    it is important to show alternate methods. I find learners appreciate seeing the
    alternate methods.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**第六步，开始探索/评估过程。** 一旦生成预测，就可以进行检查。在这里，我将沉溺于一些不常见的检查选项。在训练营的背景下，我当然会分享标准的`accuracy_score`、`classification_report`和`confusion_matrix`函数（以及均方误差和均方根误差的等效函数）。不过，我也认为展示其他方法很重要。我发现学习者更喜欢看到其他方法。'
- en: Showing alternate methods help leaners understand what `accuracy_score`, `classification_report`,
    and `confusion_matrix` do, how they do it, and how to explain what they do. It
    is important to be able to explain this to others when there are questions about
    the work.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 展示其他方法有助于学习者理解`accuracy_score`、`classification_report`和`confusion_matrix`的功能、工作原理以及如何解释它们的作用。在有问题时，能够向他人解释这些内容非常重要。
- en: More fundamentally, learning, knowing, and using alternate methods let data
    scientists replicate (and verify) more traditional approaches. In other words,
    this empowers learners to do more than merely just trust the traditional out-of-the-box
    options. No need to rely on trust when you can also independently verify the results.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 更根本地，学习、了解和使用替代方法使数据科学家能够复制（并验证）更传统的方法。换句话说，这使得学习者能够做的不仅仅是信任传统的现成选项。当你可以独立验证结果时，无需仅仅依赖信任。
- en: Once you have the predictions you can begin inspecting the predictions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你得到预测结果，就可以开始检查这些预测。
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The beauty of this code is that it is much more complex than it looks. Consider
    how firstly, it compares each prediction (found in `pred`) with the corresponding
    actual values (all found in `y_test`). The comparison `pred == y_test` will return
    a Boolean array (a series of `True` and `False` values), where `True` indicates
    that the prediction matches the actual value, and `False` indicates a mismatch.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的美妙之处在于它比看起来复杂得多。首先考虑，它将每个预测（在 `pred` 中找到）与相应的实际值（在 `y_test` 中找到）进行比较。比较
    `pred == y_test` 将返回一个布尔数组（即一系列 `True` 和 `False` 值），其中 `True` 表示预测与实际值匹配，而 `False`
    表示不匹配。
- en: Here is the magic. . . then, the `.mean()` function applied to this array essentially
    finds the proportion of correct predictions. Here is how. In Python, when calculating
    the mean of a Boolean array, `True` values are considered as 1 and `False` values
    as 0\. This effectively calculates the proportion of correct predictions (or the
    accuracy of the model), as it divides the number of `True` values (the number
    correct predictions are the sum of all values True = 1 while False = 0) by the
    total number of predictions. In this way the math works out such that the formula
    for the mean is equivalent to the formula for proportion True.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是魔法……然后，应用于此数组的 `.mean()` 函数实际上找到了正确预测的比例。具体如下。在 Python 中，当计算布尔数组的均值时，`True`
    值被视为 1，`False` 值被视为 0。这实际上计算了正确预测的比例（或模型的准确度），因为它将 `True` 值的数量（正确预测的总和是所有值中的 True
    = 1，而 False = 0）除以总预测数。这样，数学计算结果使得均值公式等同于 True 比例的公式。
- en: Finally, this code also multiplies by 100 to make a readable percentage. And
    an f-string reports the results. If you’re following along, with the same random
    states, you should find an accuracy rate of about 84%.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这段代码还将结果乘以 100 以生成可读的百分比，并且使用 f-string 报告结果。如果你跟随相同的随机状态，你应该会发现准确率大约为 84%。
- en: Another option is to use `pd.crosstab()` to show what would also be a confusion
    matrix as follows.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用 `pd.crosstab()` 来显示如下的混淆矩阵。
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Which then produces a version of the following.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就会产生如下版本。
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: From these results we see the model correctly identified/predicted 40 vehicles
    as having been manufactured in the United States, correctly identified/predicted
    27 vehicles manufactured abroad, and incorrectly identified/predicted around 12
    other vehicles (9 false negatives + 3 false positives).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些结果中，我们可以看到模型正确地识别/预测了 40 辆车辆在美国制造，正确识别/预测了 27 辆在国外制造的车辆，并且错误识别/预测了大约 12 辆其他车辆（9
    个假阴性 + 3 个假阳性）。
- en: Inspecting Individual Predictions More Closely
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更仔细地检查单个预测
- en: The core of this article is to explain how to inspect individual predictions.
    This article answers the question I often get from bootcamp learners who are seeing
    the `.predict()` method for the first time.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的核心是解释如何检查单个预测。本文回答了我经常从训练营学习者那里得到的问题，即他们第一次看到 `.predict()` 方法时的疑问。
- en: '**Where are the predictions?**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测在哪里？**'
- en: '![](../Images/997982370f4880b2de5569a68ff0e0e8.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/997982370f4880b2de5569a68ff0e0e8.png)'
- en: 'Image Credit: Author’s illustration created in Canva using Canva stock images.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者在 Canva 上使用 Canva 的库存图片制作的插图。
- en: A good first step in conducting this closer examination is to append the true
    target values, plus the predicted target values, to the original training data.
    When you do this, you can compare results side-by-side and in context along with
    each predictor variable.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 进行更详细检查的一个好步骤是将真实目标值和预测目标值附加到原始训练数据中。这样，你可以将结果并排比较，并结合每个预测变量进行上下文分析。
- en: An interesting side note for folks coming from other programming languages.
    Stata’s equivalent to SciKit Learn’s `.predict()` method automatically appends
    the predictions to the original data. In Python, that merger / concatenation requires
    some additional work.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于来自其他编程语言的用户来说，值得一提的是，Stata 中与 SciKit Learn 的 `.predict()` 方法等效的功能会自动将预测结果附加到原始数据中。在
    Python 中，这种合并/连接需要额外的工作。
- en: The following code can accomplish this merger / concatenation.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可以实现这种合并/连接。
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: For a result that will resemble the following.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于将类似于以下结果的结果。
- en: '![](../Images/4d16c635db3add5b48e0219d27e75ab4.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d16c635db3add5b48e0219d27e75ab4.png)'
- en: 'Image Credit: Screen grab from Jupyter Notebook generated with the code shown
    here.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Jupyter Notebook 中生成的屏幕截图，代码如图所示。
- en: This output shows the first and last five observations along with a column called
    `isUS` (which show the true values 1 = manufactured in the United States and 0
    = manufactured abroad) and another column called `preds` (which show the predicted
    values 1 = predicted to have been manufactured in the United States and 0 = predicted
    to have been manufactured in the United States).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 该输出显示了前五个和最后五个观察数据以及一个名为`isUS`的列（显示真实值1 = 在美国制造，0 = 在国外制造）和另一列名为`preds`（显示预测值1
    = 预测在美国制造，0 = 预测在国外制造）。
- en: Observations numbers 4 and 77 show mismatched actual values and predicted values.
    Observation number 4 is a false negative, which means the model incorrectly predicted
    the vehicle to have been manufactured abroad. While observation number 77 is a
    false positive, which means the model incorrectly predicted the vehicle to have
    been manufactured in the United States.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 观察数据编号4和77显示了实际值和预测值的不匹配。观察数据编号4是一个假阴性，这意味着模型错误地预测了车辆是在国外制造的。而观察数据编号77是一个假阳性，这意味着模型错误地预测了车辆是在美国制造的。
- en: 'Part Two: Utility of Detailed Inspections'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：详细检查的实用性
- en: Questions to Ask During Inspection
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查期间需要提出的问题
- en: Inspecting individual predictions from a model is not just about confirming
    whether or not they were correct. It’s also a process of inquiry that can yield
    important insights and inform further model refinement. When inspecting individual
    predictions, it’s beneficial to ask several key questions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 检查模型的个别预测不仅仅是确认它们是否正确。这也是一个调查过程，可以产生重要的见解并指导进一步的模型改进。在检查个别预测时，提出几个关键问题是很有帮助的。
- en: Would a domain expert agree with the (wrong) predictions?
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 领域专家是否会同意（错误）的预测？
- en: How would a causal observer have predicted the outcome? Would the casual observer
    agree with the (wrong) prediction?
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个因果观察者会如何预测结果？因果观察者是否会同意（错误）的预测？
- en: Are there other features or predictors, not included in the model, that might
    have helped the model produce a better result in this specific (wrong) case?
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否有其他特征或预测因子，没有包含在模型中，可能有助于模型在这一特定（错误）案例中产生更好的结果？
- en: Would subject matter experts agree with feature importances? Could different
    or more thorough data preparation resulted in different feature importances with
    which subject matter might better agree?
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主题专家是否会同意特征的重要性？不同或更彻底的数据准备是否可能导致不同的特征重要性，从而可能更符合主题专家的看法？
- en: What features may have contributed to this particular (wrong) prediction?
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些特征可能导致了这一特定的（错误）预测？
- en: Are there any patterns among incorrect predictions?
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误预测中是否存在任何模式？
- en: How confident was the model in this prediction?
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型在这一预测中有多自信？
- en: All of these questions can help in evaluating the existing model and inform
    further development and revision ahead.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些问题都有助于评估现有模型，并为未来的发展和修订提供指导。
- en: Negative Case + Other Data Sources
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负面案例 + 其他数据源
- en: The process of digging into the questions proposed above is the process of conducting
    an individual negative case analysis. For the first question, whether domain experts
    would agree, your work could involve preparing an export of the data for you to
    share with domain experts.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 探索上述问题的过程就是进行个别负面案例分析的过程。对于第一个问题，即领域专家是否会同意，你的工作可能涉及准备数据导出，以便与领域专家共享。
- en: This kind of export can let domain experts review the results on their own time
    and then report back to you their thoughts, observations, and ideas. The following
    code produces an HTML file, consisting of only the incorrect predictions, that
    anyone can review in any web browser.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这种导出方式允许领域专家在自己的时间里审查结果，然后向你反馈他们的想法、观察和建议。以下代码生成一个只包含错误预测的HTML文件，任何人都可以在任何网页浏览器中查看。
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This same export could be shared with other trusted advisors or colleagues who
    are not necessarily subject matter experts. A lay person’s input may be valuable
    also.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的导出文件可以与其他值得信赖的顾问或同事分享，即使他们不一定是主题专家。外行人的意见也可能有价值。
- en: For the third question on whether other features or predictors, not included
    in the model, that might have helped the model produce a better result in specific
    (wrong) cases, most models come with at least one method that can assist in evaluating
    feature importance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第三个问题，即模型中未包含的其他特征或预测变量是否可能在特定（错误）情况下帮助模型产生更好的结果，大多数模型至少有一种方法可以协助评估特征重要性。
- en: However as it turns out, the K-Nearest Neighbors (KNN) algorithm does not directly
    provide a feature importances metric or function. This is not an oversight. The
    KNN approach makes predictions based solely on the similarity between feature
    vectors without weighting individual features. This means we need an indirect
    method of evaluating feature importance, some kind of proxy. I provide such a
    proxy below.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，事实证明，K-近邻（KNN）算法并不直接提供特征重要性度量或函数。这并不是一个疏漏。KNN方法仅根据特征向量之间的相似性做出预测，而不对单个特征加权。这意味着我们需要一种间接评估特征重要性的方法，即某种代理方法。我在下面提供了这样的代理。
- en: Alternatively, another model that supports feature importance, such as a decision
    tree or random forest, could be used. Absent building another model however, it’s
    possible to gauge the importance of features by seeing how the model performance
    changes when rotating through feature holdouts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用支持特征重要性的模型，如决策树或随机森林。然而，如果不建立另一个模型，也可以通过观察在轮流处理特征时模型性能的变化来评估特征的重要性。
- en: Rotating through each feature, to hold that feature out during training, is
    a procedure that requires a simple for loop as shown below. Any reduction in performance,
    while a given feature is absent, can be taken as a meaningful measure of feature
    importance. Here is code that can help in the process of measuring feature importance
    by rotating through multiple models while iterating through and in turn holding
    out each feature.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过轮流使用每个特征，以在训练过程中排除该特征，这是一个只需简单for循环的过程，如下所示。任何特征缺失时的性能下降都可以作为特征重要性的有意义衡量标准。这里的代码可以帮助在通过多个模型轮流处理每个特征的过程中衡量特征重要性。
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this example, if you are following along you will see results that show displacement
    and weight as the most important features / predictors. When excluded, weight
    reduces model accuracy by 3.8%. However when excluded, displacement reduces the
    model accuracy by 2.5%.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，如果你跟随进行，你会看到结果显示位移和重量是最重要的特征/预测变量。排除时，重量会使模型准确率降低3.8%。而当排除位移时，模型准确率降低2.5%。
- en: Further Enriching Opportunities for Feedback
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步丰富反馈机会
- en: Related to, and perhaps in addition to sharing the sheer outcomes with others
    as described above, it can also be helpful to add columns that show prediction
    probabilities. Building on the code above, this next code block provides outputs
    with the addition of two columns containing the prediction probabilities.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了如上所述与他人分享结果外，还可以通过添加显示预测概率的列来提供帮助。在上述代码的基础上，下面的代码块提供了两个包含预测概率的列的输出。
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/2382a73cbc708c83ba466ed15133673a.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2382a73cbc708c83ba466ed15133673a.png)'
- en: 'Image Credit: Screen grab from Jupyter Notebook generated with the code shown
    here.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Jupyter Notebook屏幕截图，由此处显示的代码生成。
- en: If you have not studied KNN here is a smidge more on how KNN works. The K-Nearest
    Neighbors (KNN) algorithm determines class probabilities based on the majority
    vote of the nearest neighbors within the training data set’s hyper space. Essentially,
    it counts the number of data points belonging to each class among the ‘k’ nearest
    neighbors. The class with the most neighbors is the prediction for the new point.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有学习KNN，这里有一点关于KNN如何工作的额外信息。K-最近邻（KNN）算法基于训练数据集中超空间内最近邻的多数票决定类别概率。本质上，它计算‘k’个最近邻中属于每个类别的数据点数量。邻居最多的类别是新点的预测。
- en: Thus, when determining probabilities, KNN calculates the fraction of the ‘k’
    nearest neighbors that belong to each class. For example, if you set k=7 as we
    have here and three of the seven nearest neighbors to a test point belong to Class
    A, and four belong to Class B, then the KNN algorithm would assign a probability
    of 0.4285 (3 out of 7) to the test point being of Class A and a probability of
    0.5714 (4 out of 7) to Class B.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在确定概率时，KNN计算属于每个类别的‘k’个最近邻的比例。例如，如果你将k设置为7，如我们所示，并且七个最近邻中有三个属于A类，四个属于B类，那么KNN算法将为测试点分配0.4285（7中3）的A类概率和0.5714（7中4）的B类概率。
- en: From this output we see that the false negative in observation number 4 was
    off by a high margin. While the false positive in observation number 77 was a
    close call. While no model is perfect you might consider the misclassification
    in observation number 77 as a lost cause. However, the misclassification in observation
    number 4 might be worth a closer look as a significant opportunity to improve
    model performance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们看到观察编号4中的假阴性误差很大。而观察编号77中的假阳性误差接近。虽然没有模型是完美的，但你可能会认为观察编号77中的误分类是无望的。然而，观察编号4中的误分类可能值得更仔细的查看，作为一个显著的改进模型性能的机会。
- en: We can also take the descriptive statistics from our probability columns as
    another look at model performance. The following code will show these statistics.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以从概率列中的描述性统计数据中对模型性能进行另一种观察。以下代码将显示这些统计数据。
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Which will show a version of the following output.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示以下输出的一个版本。
- en: '![](../Images/f193bff6c5e2d74926853c18f3a7e2c0.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f193bff6c5e2d74926853c18f3a7e2c0.png)'
- en: 'Image Credit: Screen grab from Jupyter Notebook generated with the code shown
    here.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：Jupyter Notebook的屏幕截图，由这里显示的代码生成。
- en: This result shows that for at least one of the incorrect results the model was
    100% certain of its incorrect predictions. It will be worth exploring that observation
    more closely. It would seem that there may be an opportunity to improve a prediction
    that was not only wrong, but could have been no further wrong.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果表明，至少在一个错误结果中，模型对其错误预测的确定度达到了100%。进一步探讨这个观察结果将是值得的。看起来可能有机会改进一个不仅错误，而且错误程度无法更大的预测。
- en: Conclusion + Review
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论 + 回顾
- en: In part one of this deep dive, I first showed how to build a simple predictive
    model, second how to generate predictions, and third I covered how to inspect
    individual specific predictions more closely.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇深度分析的第一部分，我首先展示了如何构建一个简单的预测模型，其次展示了如何生成预测，第三部分则更详细地介绍了如何检查单个特定预测。
- en: For part two of this deep dive this article I also showed why it is useful to
    know how to inspect individual predictions. Having the ability to inspect individual
    predictions opens a range of analytical avenues.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇深度分析的第二部分，我还展示了为何了解如何检查单个预测是有用的。能够检查单个预测打开了一系列分析途径。
- en: On some views, this article did what many books, video courses, and bootcamp
    educational programs skip over. They tend to skip over and overly simplify evaluation
    of model performance following `.predict()` methods.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些观点下，本文做了许多书籍、视频课程和训练营教育项目所忽略的内容。他们往往忽略和过于简化了`.predict()`方法之后的模型性能评估。
- en: In this article we learned and explored the need to question and inspect model
    predictions. The article provides and discusses multiple example code blocks and
    strategies that effectively explore prediction results in depth.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们学习并探讨了质疑和检查模型预测的必要性。文章提供并讨论了多个示例代码块和策略，深入探讨了预测结果。
- en: To set things up we sped through (pun intended) the setup for a predictive model
    involving automobile data from Seaborn. Along the way we also explored the concepts
    of prediction confidence, feature importance, reporting results, and sharing results
    with others for an opportunity to get feedback from lay people and domain or subject
    matter experts.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置，我们快速完成了一个涉及 Seaborn 的汽车数据预测模型的设置过程。在这个过程中，我们还探讨了预测信心、特征重要性、报告结果以及与他人分享结果以获取来自普通人和领域或主题专家的反馈的概念。
- en: Stepping back, this deep, deep, deep, dive serves as a testament to the incredible
    power of machine learning and data science. The complex interplay between — the
    data, the models, the predictions, the scientists, the code, the notebooks, the
    domain experts, and more.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 退一步看，这次深度的探讨见证了机器学习和数据科学的巨大力量。数据、模型、预测、科学家、代码、笔记本、领域专家等之间复杂的相互作用。
- en: Most prominently this article also prepared readers in ways that can help connect
    the tech with human understanding and intuition. The ability to explore predictions
    at a high level of detail, such as those shown here, also show the fascinating
    landscape of data science.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，这篇文章也以能帮助将技术与人类理解和直觉连接起来的方式为读者做好了准备。能够以高水平的细节探索预测，例如这里展示的内容，也展示了数据科学的迷人景观。
- en: In our work we can uncover insights hidden in vast pools of data, and it is
    here that we can harness those insights to drive decisions, innovations, and progress.
    As this article has emphasized, effective utilization of machine learning goes
    beyond simply developing and deploying algorithms at speed or scale.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的工作中，我们可以发掘隐藏在大量数据中的见解，正是在这里我们可以利用这些见解来推动决策、创新和进步。正如这篇文章所强调的，机器学习的有效利用不仅仅是快速或大规模地开发和部署算法。
- en: Instead our work requires a curious and critical mind that is willing to question,
    inspect, and understand all of the details. All of them. I’m the kind of data
    scientist who strives to leave no stone unturned. This journey through `.predict()`
    method results is just one instance of that wider quest.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们的工作需要一个好奇且批判性的思维，愿意质疑、检查并理解所有细节。所有细节。我是那种力求不留死角的数据科学家。对`.predict()`方法结果的这一探索只是这一更广泛追求的一个实例。
- en: This article is an invitation to dive deeper into the heart of your data, to
    seek out its truths, and to question its narratives. The code blocks and strategies
    presented here, and in all of my articles, are more than just instructions — they
    are catalysts for your learning and creativity.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章是邀请你深入探索数据的核心，寻找其中的真相，并质疑其叙述。这里和我所有文章中呈现的代码块和策略，不仅仅是指令——它们是你学习和创造力的催化剂。
- en: I encourage you to take this code, experiment with it, and apply it to new datasets.
    Break it, fix it, improve it. Each dataset has a different story to tell, and
    each exploration will yield different insights. The world of data is a vast, complex,
    and beautiful place. Dive in, explore, and let the data guide your journey.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你拿这段代码进行实验，并将其应用到新的数据集上。破坏它，修复它，改进它。每个数据集都有不同的故事要讲，每次探索都会带来不同的见解。数据的世界是一个广阔、复杂且美丽的地方。*深入其中，探索并让数据引导你的旅程*。
- en: Thanks For Reading
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读
- en: Are you ready to learn more about careers in data science? I perform one-on-one
    career coaching and have a weekly email list that helps data professional job
    candidates. [Contact me to learn more](https://coaching.adamrossnelson.com/).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你准备好了解更多关于数据科学职业的信息了吗？我提供一对一职业辅导，并有一个每周邮件列表，帮助数据专业的求职者。[联系我们了解更多](https://coaching.adamrossnelson.com/)。
- en: 'Thanks for reading. Send me your thoughts and ideas. You can write just to
    say hey. And if you really need to tell me how I got it wrong I look forward to
    chatting soon. Twitter: [@adamrossnelson](https://twitter.com/adamrossnelson)
    LinkedIn: [Adam Ross Nelson](https://www.linkedin.com/in/arnelson/).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '感谢阅读。把你的想法和意见发给我。你可以只是打个招呼。如果你真的需要告诉我哪里做得不好，我期待不久后与你聊天。Twitter: [@adamrossnelson](https://twitter.com/adamrossnelson)
    LinkedIn: [Adam Ross Nelson](https://www.linkedin.com/in/arnelson/)。'
