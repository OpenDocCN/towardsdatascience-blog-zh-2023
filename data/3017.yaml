- en: 'Optical Flow with RAFT: Part 2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAFT中的光流：第2部分
- en: 原文：[https://towardsdatascience.com/optical-flow-with-raft-part-2-f0376a972c25?source=collection_archive---------8-----------------------#2023-10-03](https://towardsdatascience.com/optical-flow-with-raft-part-2-f0376a972c25?source=collection_archive---------8-----------------------#2023-10-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/optical-flow-with-raft-part-2-f0376a972c25?source=collection_archive---------8-----------------------#2023-10-03](https://towardsdatascience.com/optical-flow-with-raft-part-2-f0376a972c25?source=collection_archive---------8-----------------------#2023-10-03)
- en: Unpacking a Deep Optical Flow Model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解密深度光流模型
- en: '[](https://medium.com/@itberrios6?source=post_page-----f0376a972c25--------------------------------)[![Isaac
    Berrios](../Images/e36cdbfc91b71ceb91c6e4191e1e0833.png)](https://medium.com/@itberrios6?source=post_page-----f0376a972c25--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0376a972c25--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0376a972c25--------------------------------)
    [Isaac Berrios](https://medium.com/@itberrios6?source=post_page-----f0376a972c25--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@itberrios6?source=post_page-----f0376a972c25--------------------------------)[![Isaac
    Berrios](../Images/e36cdbfc91b71ceb91c6e4191e1e0833.png)](https://medium.com/@itberrios6?source=post_page-----f0376a972c25--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f0376a972c25--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f0376a972c25--------------------------------)
    [Isaac Berrios](https://medium.com/@itberrios6?source=post_page-----f0376a972c25--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffbadc8e8ee44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptical-flow-with-raft-part-2-f0376a972c25&user=Isaac+Berrios&userId=fbadc8e8ee44&source=post_page-fbadc8e8ee44----f0376a972c25---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0376a972c25--------------------------------)
    ·10 min read·Oct 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff0376a972c25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptical-flow-with-raft-part-2-f0376a972c25&user=Isaac+Berrios&userId=fbadc8e8ee44&source=-----f0376a972c25---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ffbadc8e8ee44&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptical-flow-with-raft-part-2-f0376a972c25&user=Isaac+Berrios&userId=fbadc8e8ee44&source=post_page-fbadc8e8ee44----f0376a972c25---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----f0376a972c25--------------------------------)
    ·10分钟阅读·2023年10月3日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff0376a972c25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptical-flow-with-raft-part-2-f0376a972c25&user=Isaac+Berrios&userId=fbadc8e8ee44&source=-----f0376a972c25---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff0376a972c25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptical-flow-with-raft-part-2-f0376a972c25&source=-----f0376a972c25---------------------bookmark_footer-----------)![](../Images/5575917b4ef6fceae3fe047ad5c9c16c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff0376a972c25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptical-flow-with-raft-part-2-f0376a972c25&source=-----f0376a972c25---------------------bookmark_footer-----------)![](../Images/5575917b4ef6fceae3fe047ad5c9c16c.png)'
- en: Photo by [Kevin Hansen](https://unsplash.com/@kevinhansenfoto?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Kevin Hansen](https://unsplash.com/@kevinhansenfoto?utm_source=medium&utm_medium=referral)提供，来源于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In this post we will take an alternative look at [RAFT](https://arxiv.org/pdf/2003.12039.pdf).
    The head on approach in part 1 was able to break down the details of the network,
    but here we will visualize these details and build valuable intuition. [In part
    1](/optical-flow-with-raft-part-1-f984b4a33993) we aimed to understand RAFT so
    that we can use it as is; in part 2 we will aim to understand RAFT in a manner
    that allows us to leverage different parts of its architecture for our own models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将以另一种方式来看待[RAFT](https://arxiv.org/pdf/2003.12039.pdf)。第1部分中的直接方法能够详细解析网络的细节，但在这里我们将可视化这些细节并建立有价值的直觉。[在第1部分](/optical-flow-with-raft-part-1-f984b4a33993)中，我们的目标是理解RAFT，以便我们可以直接使用它；而在第2部分，我们将旨在以一种方式理解RAFT，使我们能够利用其架构的不同部分来构建自己的模型。
- en: 'Here’s an overview of the post:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是本文的概览：
- en: '**Motivation**'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动机**'
- en: '**RAFT Architecture**'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RAFT架构**'
- en: '**The Lookup Operator**'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查找操作符**'
- en: '**Iterative Updates**'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代更新**'
- en: '**Conclusion**'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结论**'
- en: '**Motivation**'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**动机**'
- en: The concepts from RAFT are utilized in many subsequent works, and understanding
    RAFT is key to understanding these new approaches. How can you know which parts
    of RAFT can or should be leveraged? Why do many subsequent works make use of the
    correlation volume? Answers to these questions come from grasping the inner workings
    of RAFT, it’s not always enough to understand what a paper presents at face value,
    sometimes we need to go deeper and RAFT is no exception.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: RAFT 的概念被许多后续工作利用，理解 RAFT 是理解这些新方法的关键。你如何知道 RAFT 的哪些部分可以或应该被利用？为什么许多后续工作使用相关体？这些问题的答案来自于掌握
    RAFT 的内部工作原理，仅仅了解论文表面内容通常是不够的，有时我们需要深入探讨，RAFT 也不例外。
- en: RAFT Architecture
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAFT 架构
- en: To begin let’s get a quick refresher on RAFT, its architecture can be broken
    down into its three fundamental blocks and it is shown below.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，快速回顾一下 RAFT，其架构可以分解为三个基本模块，如下所示。
- en: '![](../Images/ba7083f8d850dff02dfa034d097a49cb.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ba7083f8d850dff02dfa034d097a49cb.png)'
- en: Figure 1\. Architecture of RAFT. Modified from [Source](https://arxiv.org/pdf/2003.12039.pdf).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. RAFT 的架构。修改自 [来源](https://arxiv.org/pdf/2003.12039.pdf)。
- en: Feature Extraction
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征提取
- en: The **Feature Encoder** is a Convolutional Neural Network (CNN) that extracts
    features from images *I₁* and *I₂* using shared weights. The **Context encoder**
    extracts both context and hidden features, both of which are input into the iterative
    update block.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征编码器**是一个卷积神经网络（CNN），利用共享权重从图像 *I₁* 和 *I₂* 中提取特征。**上下文编码器**提取上下文和隐藏特征，这些特征都被输入到迭代更新模块中。'
- en: '![](../Images/b271f2ab7872d61354a8e84e538bbcbe.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b271f2ab7872d61354a8e84e538bbcbe.png)'
- en: 'Function mappings for the feature network f and the context network g. Source:
    Author.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 特征网络 f 和上下文网络 g 的函数映射。来源：作者。
- en: '![](../Images/464cbe1c3c517286214c66e6d7dcf357.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/464cbe1c3c517286214c66e6d7dcf357.png)'
- en: Computation of the 4D correlation Volume. Modified from [Source](https://arxiv.org/pdf/2003.12039.pdf).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 4D 相关体的计算。修改自 [来源](https://arxiv.org/pdf/2003.12039.pdf)。
- en: Visual Similarity
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视觉相似性
- en: 'The dot product of the two feature maps forms a 4D **all-pairs correlation
    volume**, where each pixel of *g¹* maps to all pixels of *g²*, each of these mappings
    is referred to as a **2D response map**. *Where g¹ and g² are extracted feature
    map tensors from I₁ and I₂, respectively.* Average Pooling is performed over the
    last two dimensions of the correlation volume with kernel sizes: 1, 2, 4, 8.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 两个特征图的点积形成一个 4D **全对相关体**，其中 *g¹* 的每个像素映射到 *g²* 的所有像素，这些映射被称为 **2D 响应图**。*其中
    g¹ 和 g² 分别是从 I₁ 和 I₂ 中提取的特征图张量。* 在相关体的最后两个维度上执行平均池化，卷积核大小为：1、2、4、8。
- en: '![](../Images/4a6d33f0bc89d459238bf26e1345bbe9.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a6d33f0bc89d459238bf26e1345bbe9.png)'
- en: 'Figure 2\. Left: Relationship of a single pixel in *I₁* to all pixels of *I₂.*
    Right: 2D response maps of various correlation volumes in the correlation pyramid.
    [Source](https://arxiv.org/pdf/2003.12039.pdf).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 左：*I₁* 中单个像素与 *I₂* 中所有像素的关系。右：相关金字塔中各种相关体的 2D 响应图。[来源](https://arxiv.org/pdf/2003.12039.pdf)。
- en: We stack these correlation volumes into a 5D **correlation pyramid** with each
    level relating the fine pixels of *g¹* to the increasingly coarse pixel features
    of *g²*. This allows us to capture information about both large and small pixel
    displacements. The **lookup operator** extracts correlation features from the
    correlation volume. It takes a fine feature pixel of *g¹* along with its corresponding
    optical flow field and computes its new apparent location, this is known as its
    **correspondence**. It then forms a 2D grid around it with a predefined radius
    *r*, and subsequently performs [subpixel](https://dsp.stackexchange.com/questions/34103/subpixel-what-is-it)
    [bilinear resampling](https://en.wikipedia.org/wiki/Bilinear_interpolation#Application_in_image_processing)
    along the grid to get new grid values. This resampled feature grid contains flow
    (descent) direction information, the lookup operator does this for each pixel
    in each layer of the pyramid. These pixel wise feature grids are referred to as
    **correlation features** which are then reshaped and input into the **iterative
    update block**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些相关体积堆叠成一个 5D **相关金字塔**，每一层将 *g¹* 的精细像素与 *g²* 的逐渐粗糙的像素特征相关联。这使我们能够捕获关于大规模和小规模像素位移的信息。**查找操作符**
    从相关体积中提取相关特征。它获取 *g¹* 的一个精细特征像素及其对应的光流场，并计算其新的明显位置，这称为其 **对应关系**。然后，它在预定义半径 *r*
    周围形成一个 2D 网格，并随后沿网格执行 [亚像素](https://dsp.stackexchange.com/questions/34103/subpixel-what-is-it)
    [双线性重采样](https://en.wikipedia.org/wiki/Bilinear_interpolation#Application_in_image_processing)
    以获得新的网格值。这个重采样的特征网格包含流（下降）方向信息，查找操作符对金字塔中每层的每个像素执行此操作。这些逐像素特征网格称为 **相关特征**，然后被重新塑形并输入到
    **迭代更新块**。
- en: Iterative Updates
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代更新
- en: 'The iterative update block takes four inputs: context features, correlation
    features, current flow estimate, and hidden features. The flow and correlation
    features are encoded together as motion features since they both describe the
    relative motion of the feature pixels. The context features do not change, they
    function as a stable reference for the update block to use. The block itself consists
    of a [ConvGRU](https://arxiv.org/pdf/1511.06432.pdf) that computes a set amount
    of recurrent updates followed by a Flow Head that consists of convolutional layers
    to convert the hidden state to a flow estimate at 1/8 the original input resolution.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代更新块接受四个输入：上下文特征、相关特征、当前流估计和隐藏特征。流和相关特征被一起编码为运动特征，因为它们都描述了特征像素的相对运动。上下文特征保持不变，作为更新块的稳定参考。该块本身由一个
    [ConvGRU](https://arxiv.org/pdf/1511.06432.pdf) 组成，该网络计算一定数量的递归更新，随后由一个包含卷积层的流头将隐藏状态转换为原始输入分辨率的
    1/8 的流估计。
- en: '![](../Images/9cd5d3879b2b09b1701845575fe6e931.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cd5d3879b2b09b1701845575fe6e931.png)'
- en: Figure 3\. RAFT Update Block for large architecture with different sub-blocks
    highlighted. Blue-Feature extraction block, Red — Recurrent Update Block, Green
    — Flow Head. Modified from [Source](https://arxiv.org/pdf/2003.12039.pdf).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. RAFT 更新块用于大型架构，突出显示了不同的子块。蓝色—特征提取块，红色—递归更新块，绿色—流头。修改自 [Source](https://arxiv.org/pdf/2003.12039.pdf)。
- en: 'The update operator functions like an Optimization Algorithm, meaning that
    it starts from an initial flow ***f₀*** and iteratively computes new flow values
    *Δfₖ* that are added to the previous flow estimate: *fₖ₊₁ = fₖ + Δfₖ* until it
    converges to a fixed value: ***fₖ → f****. As we perform the iterative updates,
    both the flow estimate and the correlation features (not the correlation pyramid)
    are continuously being refined. Once the iterations are exhausted the flow estimate
    is upsampled from 1/8 to the original resolution.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 更新操作符的功能类似于优化算法，这意味着它从初始流 ***f₀*** 开始，并迭代计算新的流值 *Δfₖ*，这些值被添加到先前的流估计中：*fₖ₊₁ =
    fₖ + Δfₖ*，直到收敛到一个固定值：***fₖ → f****。在执行迭代更新时，流估计和相关特征（不是相关金字塔）会持续被精炼。一旦迭代耗尽，流估计将从
    1/8 上采样到原始分辨率。
- en: Convex Upsampling
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 凸上采样
- en: '**Convex Upsampling** estimates each fine pixel as the [convex combination](https://www.math.ucla.edu/~baker/149/handouts/cc_convex/node4.html)
    of its neighboring 3x3 grid of coarse pixels. The weights are parameterized by
    a neural network that is able to learn optimal weights for each fine pixel. An
    example is shown below.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**凸上采样** 通过将每个精细像素估计为其邻近的 3x3 粗像素网格的 [凸组合](https://www.math.ucla.edu/~baker/149/handouts/cc_convex/node4.html)。权重由一个神经网络参数化，该网络能够为每个精细像素学习最佳权重。下方显示了一个示例。'
- en: '![](../Images/85c37d6ee2a54440ef1ef992fc8238d0.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/85c37d6ee2a54440ef1ef992fc8238d0.png)'
- en: 'Figure 4\. Top: Comparison of Bilinear VS Convex Upsampling. Bottom: Convex
    Upsampling example at a single full res pixel (purple). [Source](https://arxiv.org/pdf/2003.12039.pdf).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 上：双线性 VS 凸采样的比较。下：单个全分辨率像素（紫色）的凸采样示例。 [来源](https://arxiv.org/pdf/2003.12039.pdf)。
- en: Learning the Flow Offset
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习光流偏移量
- en: It’s important to remember that RAFT doesn’t necessarily estimate the flow,
    it estimates the *flow offset* from a starting point, and the output is an accumulation
    of these flow offsets. The first estimate is an update of the previous flow of
    **0** at the pixel locations of *I₁*. Information about *I₁* comes from the initial
    hidden state and the context features, this provides continuous feedback in the
    update block that guides the learning to enable RAFT to estimate the flow offset
    rather than estimate the flow afresh
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，RAFT 不一定估计光流，它估计的是从起始点的 *光流偏移量*，输出的是这些光流偏移量的累积。第一次估计是对 *I₁* 像素位置上 **0**
    的先前光流的更新。*I₁* 的信息来自初始隐藏状态和上下文特征，这为更新块提供了持续的反馈，指导学习，使 RAFT 能够估计光流偏移量，而不是重新估计光流。
- en: RAFT doesn’t estimate the flow, its update block estimates the flow offset from
    a starting point and the model outputs the accumulation of flow offsets
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: RAFT 不直接估计光流，它的更新块从起始点估计光流偏移量，模型输出的是光流偏移量的累积。
- en: During training, the recurrent updates of the network mimic the steps of an
    Optimization Algorithm, where each new flow estimate *fₖ₊₁ = fₖ + Δfₖ* is increasingly
    scrutinized by the objective function forcing the network to learn more conservative
    estimates for *Δfₖ* as the number of iterations increases. The objective function
    captures all flow updates and is the sum of weighted *l1* distances between the
    flow predictions and ground truth, with exponentially increasing weights.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，网络的递归更新模拟了优化算法的步骤，其中每个新的光流估计 *fₖ₊₁ = fₖ + Δfₖ* 被目标函数越来越严格地审视，迫使网络随着迭代次数的增加学习更保守的
    *Δfₖ* 估计。目标函数捕捉所有光流更新，是光流预测与真实值之间的加权 *l1* 距离的总和，权重呈指数增长。
- en: '![](../Images/383fe7364b5d7933ecc3cd10277d536c.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/383fe7364b5d7933ecc3cd10277d536c.png)'
- en: Loss for RAFT, γ = 0.8\. [Source](https://arxiv.org/pdf/2003.12039.pdf).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: RAFT 的损失，γ = 0.8。 [来源](https://arxiv.org/pdf/2003.12039.pdf)。
- en: This imitation of an Optimization Algorithm along with the radius of the lookup
    operator work together to constrain the search space for each update. which in
    turn reduces the risk of over-fitting, leads to faster training and, improves
    generalization.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种优化算法的模仿以及查找操作符的半径协同作用，限制了每次更新的搜索空间，从而减少了过拟合的风险，加快了训练速度，并且提高了泛化能力。
- en: Unpacking RAFT
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解读 RAFT
- en: Now we can start unpacking RAFT and gain insight as to how it makes predictions.
    The code for this tutorial is located on [GitHub](https://github.com/itberrios/CV_projects/blob/main/RAFT/RAFT_dive.ipynb)
    where the RAFT code has been modified to output its intermediate feature maps
    at each major block. The test images are of a counter-clockwise rotating ceiling
    fan, which provides flows in almost all directions. To get a large flow displacement
    we will skip a couple of images in the sequence, this will make the flow features
    more obvious and easier to study.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以开始解读 RAFT，并深入了解它如何进行预测。这个教程的代码位于 [GitHub](https://github.com/itberrios/CV_projects/blob/main/RAFT/RAFT_dive.ipynb)，在这里
    RAFT 代码已被修改，以在每个主要块处输出其中间特征图。测试图像是逆时针旋转的吊扇，这会产生几乎所有方向的光流。为了获得较大的光流位移，我们将跳过序列中的几个图像，这将使光流特征更加明显，便于研究。
- en: '![](../Images/4adb00bf6d078b255e1f8c66f077a6d0.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4adb00bf6d078b255e1f8c66f077a6d0.png)'
- en: 'Figure 5\. Predicted Optical Flow. Source: Author.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 预测的光流。来源：作者。
- en: Now let’s inspect the maps from the Feature Encoder Block.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查来自特征编码器块的图。
- en: '![](../Images/b503bd5f9ee96b974c97d463bf3d6220.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b503bd5f9ee96b974c97d463bf3d6220.png)'
- en: 'Figure 6\. Feature Maps (0–127) from the Feature encoder block. Source: Author.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6\. 来自特征编码器块的特征图（0–127）。来源：作者。
- en: The Feature Encoder produces *fmap 1* and *fmap 2,* they both look like noise,
    but in reality they hold crucial information for the flow estimate. The hidden
    feature maps resemble the input image *I₁*, and they directly seed the hidden
    state of the ConvGRU in the update block providing valuable information about
    the pixels in *I₁*. The context feature maps have some resemblance of the input
    image in that they highlight the strong features such as corners and edges. The
    original paper suggests that the context features improve the networks ability
    to accurately discern the spatial motion boundaries.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 特征编码器生成了*fmap 1*和*fmap 2*，它们看起来像噪声，但实际上包含了对流动估计至关重要的信息。隐藏的特征图类似于输入图像*I₁*，它们直接初始化了
    ConvGRU 更新块的隐藏状态，提供了关于*I₁*中像素的宝贵信息。上下文特征图与输入图像有些相似，突出显示了诸如角落和边缘等强特征。原始论文建议，上下文特征提高了网络准确识别空间运动边界的能力。
- en: The Correlations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关性
- en: The Correlation Pyramid is crucial for computing accurate optical flow, since
    it is able to capture the correspondences of pixels from *I₁* to *I₂*. As we will
    see shortly, **the Correlation Volume is the backbone of RAFT**, and we will visualize
    its superb ability to capture pixel displacement. We will approach this by inspecting
    several test pixels and see how their 2D response maps are able to capture the
    relative displacements. We can only see features, yet information about the pixel
    displacements will still be evident.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 相关金字塔对于计算准确的光流至关重要，因为它能够捕捉从*I₁*到*I₂*的像素对应关系。正如我们将看到的，**相关体积是 RAFT 的核心**，我们将可视化其出色的像素位移捕捉能力。我们将通过检查几个测试像素来接近这一点，并查看它们的二维响应图如何捕捉相对位移。我们只能看到特征，但像素位移的信息仍然会显现。
- en: The **Correlation Pyramid** captures the correspondences of pixels in the image
    sequence across multiple levels of resolution.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**相关金字塔**捕捉了图像序列中像素在多个分辨率级别上的对应关系。'
- en: The figure below shows the estimated flow of a test image with a few annotated
    test pixels.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个测试图像的估计流动，并标注了一些测试像素。
- en: '![](../Images/f902c4b6f07dd5992db526543609a8fc.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f902c4b6f07dd5992db526543609a8fc.png)'
- en: 'Figure 7\. Flow image with annotated test pixels. Source: Author.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7\. 带注释测试像素的流动图像。来源：作者。
- en: 'The estimated horizontal and vertical flow field components for each pixel
    are:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 每个像素的水平和垂直流场分量的估计值是：
- en: 'Pixel 0: (-49.4, -4.3)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '像素 0: (-49.4, -4.3)'
- en: 'Pixel 1: (-5.8, -26.4)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '像素 1: (-5.8, -26.4)'
- en: 'Pixel 2: (23.5, -9.3)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '像素 2: (23.5, -9.3)'
- en: Accessing the Correlation Features
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问相关特征
- en: To access the correlation maps for a given test pixel, we add the following
    function to the corr.py script which obtains the integer index for a given test
    pixel at any pyramid level.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问给定测试像素的相关图，我们将以下函数添加到 corr.py 脚本中，以获得任何金字塔级别下给定测试像素的整数索引。
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once we obtain the test pixel index we can obtain its 2D response map, resampled
    correlation features, and correspondence for each pyramid level.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得了测试像素索引，我们可以获取其二维响应图、重新采样的相关特征和每个金字塔级别的对应关系。
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Visualizing the Correlation Features
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化相关特征
- en: For each pixel, the 2D response map GIFs of the first pyramid level for the
    first 15 updates are shown below in figures 8-10\. The correspondence is denoted
    by the red square. The large correlation values (bright spots) indicate the relative
    pixel location in *I₂*. Notice how the correspondence converges around the high
    correlation value as the network learns the flow offsets. Even though these are
    large displacements, the all-pairs correlation at the first pyramid level is still
    able to capture them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个像素，图 8-10 中展示了前 15 次更新的第一个金字塔级别的二维响应图 GIF。对应关系由红色方框标记。大的相关值（亮点）指示了*I₂*中的相对像素位置。注意，随着网络学习流动偏移，对应关系如何围绕高相关值收敛。尽管这些是大位移，但在第一个金字塔级别上的所有对相关性仍能捕捉到它们。
- en: '![](../Images/9b9f909bb8dc4e9c80e17e81a37ad73d.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b9f909bb8dc4e9c80e17e81a37ad73d.png)'
- en: 'Figure 8\. Pyramid level 1, 2D Correlation Response map for pixel 0\. Source:
    Author.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8\. 金字塔级别 1，像素 0 的二维相关响应图。来源：作者。
- en: '![](../Images/844f559361369f87bbcce34eeacc2c90.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/844f559361369f87bbcce34eeacc2c90.png)'
- en: 'Figure 9\. Pyramid level 1, 2D Correlation Response map for pixel 1\. Source:
    Author.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. 金字塔级别 1，像素 1 的二维相关响应图。来源：作者。
- en: '![](../Images/c448c644aebe747cf566e489f19037d3.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c448c644aebe747cf566e489f19037d3.png)'
- en: 'Figure 10\. Pyramid level 1, 2D Correlation Response map for pixel 2\. Source:
    Author.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10\. 金字塔级别 1，像素 2 的二维相关响应图。来源：作者。
- en: The Correlation Pyramid is able to capture all levels of correlation, but it’s
    not always obvious. As we go up the pyramid level, things start to become more
    abstract and it becomes increasingly difficult to determine what RAFT is actually
    doing and the fact that we are looking at correlations of extracted features makes
    things even more ambiguous.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 相关金字塔能够捕捉所有层级的相关性，但这并不总是显而易见的。随着金字塔层级的提升，事物开始变得更加抽象，确定RAFT实际在做什么变得越来越困难，此外，我们看到的是提取特征的相关性，使得事情更加模糊。
- en: Retrieving the Descent Direction
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检索下降方向
- en: 'The correspondence is used to propose the descent direction via the lookup
    operator. The correlation lookup operator places a grid of radius *r* around the
    new correspondence location: *x’ = (u + f¹(u) + v + f²(v))*, where *(****f¹****,*
    ***f²****)* is the current flow field estimate. The the grid around x’ is used
    to bilinearly resample from the correlation volume. These resampled grids are
    the correlation features that are fed into the Update Operator to predict the
    next flow estimate. The image below shows the first pyramid level 2D correlation
    response at pixel 1 along with its corresponding bilinearly resampled grid; the
    top row is the first iteration with a zero flow initialization and the bottom
    row is the second iteration.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配点通过查找操作符来提出下降方向。相关查找操作符在新的匹配点位置周围放置一个半径为*r*的网格：*x’ = (u + f¹(u) + v + f²(v))*，其中*(****f¹****,*
    ***f²****)*是当前的流场估计。围绕x’的网格用于从相关体中进行双线性重采样。这些重采样网格是输入到更新操作符中的相关特征，以预测下一个流估计。下图显示了第一个金字塔层级2D相关响应在像素1的情况以及其对应的双线性重采样网格；上排是第一次迭代，流初始化为零；下排是第二次迭代。
- en: '![](../Images/f9308199d73b8c7e95ff70a223754e6d.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f9308199d73b8c7e95ff70a223754e6d.png)'
- en: 'Figure 11\. Pixel 1 Zoomed Correlation Response and Bilinearly Resampled grid.
    Top: iteration 0, Bottom: iteration 1\. Correspondence is in (rows, cols). Source:
    Author.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11\. 像素 1 放大后的相关响应和双线性重采样网格。上排：迭代 0，下排：迭代 1。匹配点在(行，列)。来源：作者。
- en: Notice in the top row, how the correlation response on the left is the same
    as the resampled grid on the right, this is due to the zero flow initialization.
    We also notice something very important about the bilinearly resampled grid in
    the top right, the largest value is directly to the left of the center. If we
    move three pixels to the right and one pixel up, or (3, -1), then we would land
    on this large value. This is the ***proposed*** descent direction that has been
    retrieved from the correlation volumes. In the iterative update block the network
    uses this information to formulate the actual descent direction *Δfₖ*.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意上排中，左侧的相关响应与右侧的重采样网格相同，这是由于零流初始化造成的。我们还注意到关于右上角的双线性重采样网格的一个非常重要的点，最大值直接位于中心的左侧。如果我们向右移动三像素并向上移动一像素，即(3,
    -1)，那么我们就会落在这个大值上。这是从相关体中检索出的***建议***下降方向。在迭代更新块中，网络利用这些信息来制定实际的下降方向*Δfₖ*。
- en: On the bottom row, we can see that the correspondence has moved roughly from
    (39, 34) to (41.93, 33.3), which is a displacement of (2.93, -0.7), showing that
    the network has actually utilized the proposed descent direction. In the resampled
    grid on the bottom right, we see that the largest value is in the center and aligned
    with the correspondence, indicating that the network already has a flow prediction
    that is close to convergence.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下排中，我们可以看到匹配点大致从(39, 34)移动到(41.93, 33.3)，这是一个(2.93, -0.7)的位移，显示网络确实利用了建议的下降方向。在右下角的重采样网格中，我们看到最大值位于中心并与匹配点对齐，这表明网络已经有一个接近收敛的流预测。
- en: Motion Features
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运动特征
- en: The motion features are the convolutional encoding of the correlation features
    and the current flow estimate. They provide pixel flow information to be refined
    by the update block. Some of the motion feature maps at each iteration are displayed
    below.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 运动特征是相关特征和当前流估计的卷积编码。它们提供了需要由更新块细化的像素流信息。以下展示了每次迭代的一些运动特征图。
- en: '![](../Images/740100ab4278f039ce2ce90d8cf04c36.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/740100ab4278f039ce2ce90d8cf04c36.png)'
- en: 'Figure 12\. Motions Feature map at different iterations. Yes, I cherry picked
    the interesting features. Source: Author.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12\. 不同迭代下的运动特征图。是的，我挑选了有趣的特征。来源：作者。
- en: It seems like the motion features correspond to pixels with large movements,
    and different feature maps seems to correspond to different pixel flows this is
    apparent with features 126 and 127 on the right of figure 12\. They all converge
    in a similar manner to the actual flow predictions.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来，运动特征与具有大幅度移动的像素对应，不同的特征图似乎对应于不同的像素流，这在图12右侧的特征126和127中表现得尤为明显。它们都以类似的方式收敛到实际流动预测。
- en: '**Conclusion**'
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: In this post we have learned about RAFT and its inner workings. We have seen
    how the extracted hidden features provide useful information about *I₁* while
    the extracted context features provide reference info about the strong features
    of *I₁*. We have visualized how the correlation volume is able to capture information
    about small and large pixel displacements. It turns out that the correlation concepts
    from RAFT are used in many subsequent works, the intuition built from the visualizations
    reinforces this pattern. If you have made it this far congratulations! You now
    have a deeper understanding of RAFT than what is presented at surface level.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们学习了RAFT及其内部工作原理。我们看到提取的隐藏特征提供了关于 *I₁* 的有用信息，而提取的上下文特征则提供了关于 *I₁* 强特征的参考信息。我们已经可视化了相关体如何捕捉到小范围和大范围像素位移的信息。事实证明，RAFT中的相关概念被许多后续工作所采用，从可视化中建立的直觉加强了这种模式。如果你已经读到这里，恭喜你！你现在对RAFT有了比表面层次更深入的理解。
- en: References
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Teed, Z., & Deng, J. (2020). Raft: Recurrent all-pairs field transforms
    for optical flow. *Computer Vision — ECCV 2020*, 402–419\. [https://doi.org/10.1007/978-3-030-58536-5_24](https://doi.org/10.1007/978-3-030-58536-5_24)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Teed, Z., & Deng, J. (2020). Raft: Recurrent all-pairs field transforms
    for optical flow. *计算机视觉 — ECCV 2020*, 402–419\. [https://doi.org/10.1007/978-3-030-58536-5_24](https://doi.org/10.1007/978-3-030-58536-5_24)'
