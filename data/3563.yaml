- en: Almost Everything You Want to Know About Partition Size of Dask Dataframes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于Dask数据框分区大小的几乎所有信息
- en: 原文：[https://towardsdatascience.com/almost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674?source=collection_archive---------11-----------------------#2023-12-01](https://towardsdatascience.com/almost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674?source=collection_archive---------11-----------------------#2023-12-01)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/almost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674?source=collection_archive---------11-----------------------#2023-12-01](https://towardsdatascience.com/almost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674?source=collection_archive---------11-----------------------#2023-12-01)
- en: '**And how to utilize it effectively in XGBoost model**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**以及如何在XGBoost模型中有效利用它**'
- en: '[](https://medium.com/@mik.sarafanov?source=post_page-----ac1b136d7674--------------------------------)[![Mikhail
    Sarafanov](../Images/88869a3c6f664785c90539dd7aab6d74.png)](https://medium.com/@mik.sarafanov?source=post_page-----ac1b136d7674--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ac1b136d7674--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ac1b136d7674--------------------------------)
    [Mikhail Sarafanov](https://medium.com/@mik.sarafanov?source=post_page-----ac1b136d7674--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mik.sarafanov?source=post_page-----ac1b136d7674--------------------------------)[![Mikhail
    Sarafanov](../Images/88869a3c6f664785c90539dd7aab6d74.png)](https://medium.com/@mik.sarafanov?source=post_page-----ac1b136d7674--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ac1b136d7674--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ac1b136d7674--------------------------------)
    [Mikhail Sarafanov](https://medium.com/@mik.sarafanov?source=post_page-----ac1b136d7674--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c78c40898&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falmost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674&user=Mikhail+Sarafanov&userId=209c78c40898&source=post_page-209c78c40898----ac1b136d7674---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ac1b136d7674--------------------------------)
    ·7 min read·Dec 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac1b136d7674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falmost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674&user=Mikhail+Sarafanov&userId=209c78c40898&source=-----ac1b136d7674---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c78c40898&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falmost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674&user=Mikhail+Sarafanov&userId=209c78c40898&source=post_page-209c78c40898----ac1b136d7674---------------------post_header-----------)
    发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ac1b136d7674--------------------------------)
    ·7 min read·2023年12月1日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac1b136d7674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falmost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674&user=Mikhail+Sarafanov&userId=209c78c40898&source=-----ac1b136d7674---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac1b136d7674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falmost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674&source=-----ac1b136d7674---------------------bookmark_footer-----------)![](../Images/6162b6b47f392693f9bcc37cc103e84f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac1b136d7674&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Falmost-everything-you-want-to-know-about-partition-size-of-dask-dataframes-ac1b136d7674&source=-----ac1b136d7674---------------------bookmark_footer-----------)![](../Images/6162b6b47f392693f9bcc37cc103e84f.png)'
- en: Preview image (by author)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 预览图（作者提供）
- en: Recently, my colleagues and I have been working on a big high-loaded service
    that utilizes the [Xgboost](https://xgboost.readthedocs.io/en/stable/tutorials/dask.html)
    machine learning model and Dask as the tool for distributed data processing and
    forecast generating. Here I would like to share findings that we have been able
    to maximize the use of Dask for the purpose of data preparation and ML model fitting.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我和我的同事们一直在处理一个使用 [Xgboost](https://xgboost.readthedocs.io/en/stable/tutorials/dask.html)
    机器学习模型和 Dask 作为分布式数据处理和预测生成工具的大型高负载服务。在这里，我想分享我们如何最大化利用 Dask 进行数据准备和机器学习模型拟合的发现。
- en: '**What is Dask?**'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**什么是Dask？**'
- en: '[Dask](https://www.dask.org/) is a library for distributed processing of large
    amounts of data. The basic concept behind it is to divide large arrays into small
    parts (partitions).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[Dask](https://www.dask.org/)是一个用于大规模数据分布式处理的库。其基本概念是将大型数组划分为小部分（分区）。'
- en: 'This is how Dask Dataframes are stored and processed: tables can be split into
    small data frames (look at this as pandas DataFrames) so that there is no need
    to store the entire table in RAM. The entire source table may be too large to
    load into memory, but individual partitions can. In addition, such data storage
    allows efficient utilization of multiple processor cores to parallelize computations.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Dask Dataframes如何存储和处理：表可以被拆分成小的数据帧（可以将其视作pandas DataFrames），这样无需将整个表存储在RAM中。整个源表可能太大而无法加载到内存中，但单个分区可以。此外，这种数据存储允许有效利用多个处理器核心来并行计算。
- en: At the same time, the size of these partitions (chunks) is determined by the
    developer. Thus, the same dataframe can be divided into several partitions using
    for example ‘Split 1’ or ‘Split 2’ (Figure 1).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，这些分区（块）的大小由开发者确定。因此，相同的数据帧可以使用例如‘Split 1’或‘Split 2’（见图1）分成几个分区。
- en: '![](../Images/541332b83eae5329024d552cd75a1d85.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/541332b83eae5329024d552cd75a1d85.png)'
- en: Figure 1\. Splitting Dask dataframe into partitions (image by author)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. 将Dask数据帧拆分为分区（图片由作者提供）
- en: Choosing the optimal partition size is crucial, because if it is not optimal,
    the processing of the data can slow down. The optimal partition size depends on
    the size of the overall dataset, as well as on the resources of the server (or
    laptop) — the number of CPUs and available RAM.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳的分区大小至关重要，因为如果分区大小不佳，数据处理可能会变慢。最佳分区大小取决于整体数据集的大小以及服务器（或笔记本电脑）的资源——CPU数量和可用RAM。
- en: '**Disclaimer:** Further on, for convenience, we will measure the size of the
    dataset by the number of rows. All tables will consist of 4 columns (3 features
    + 1 target). When implementing the algorithm in the system, we built all dependencies
    not on the number of rows in the tables, but on the total number of elements (rows
    x columns).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**免责声明：** 为了方便起见，接下来我们将通过行数来衡量数据集的大小。所有表将由4列组成（3个特征+1个目标）。在系统中实现算法时，我们构建的所有依赖项不是基于表中的行数，而是基于元素的总数（行数
    x 列数）。'
- en: '**The problem**'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**问题**'
- en: Dask can be used to compute simple statistics and aggregations, but Dask can
    also be used to train big machine learning models (using a lot of data). For example,
    XGBoost. Since the service we were developing might require us to train a model
    on 2–10 million records using only 8–16 GB of RAM (in the case of small virtual
    machines), we decided to conduct experiments.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Dask可以用于计算简单统计数据和聚合，但Dask也可以用于训练大型机器学习模型（使用大量数据）。例如，XGBoost。由于我们正在开发的服务可能需要我们在仅有8-16
    GB RAM（在小型虚拟机情况下）下对2-10百万条记录进行模型训练，因此我们决定进行实验。
- en: 'Even in the case of calculating simple statistics, the size of partitions is
    very important because it can significantly slow down the calculation algorithm
    in two cases:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是在计算简单统计数据的情况下，分区的大小也非常重要，因为它在两种情况下可能显著减慢计算算法：
- en: '**Partitions are too large** so it takes too much time and resources to process
    them in RAM'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分区过大**，导致在RAM中处理这些分区需要耗费过多的时间和资源'
- en: '**Partitions are too small** so to process all of them Dask needs to load these
    tables into RAM too often — more time is spent on synchronization and uploading/downloading
    than on the calculations themselves'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分区过小**，以至于Dask需要过于频繁地将这些表加载到RAM中——更多的时间花在同步和上传/下载上，而不是在计算本身上'
- en: Thus, using the same computing resources can significantly degrade the performance
    of the program by choosing a non-optimal partition size (Figure 2). Figure 2 shows
    the time to fit the XGBoost model on Dask dataframes with different partition
    sizes. The average execution time over 5 runs is shown.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用相同的计算资源选择非最佳的分区大小会显著降低程序的性能（见图2）。图2显示了在不同分区大小的Dask数据帧上拟合XGBoost模型的时间。显示的是5次运行的平均执行时间。
- en: '![](../Images/e211905900d041620463667f5c46022c.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e211905900d041620463667f5c46022c.png)'
- en: Figure 2\. Influence of partition size on XGBoost model fitting velocity. The
    original dataframe for these experiments contains 500,000 rows and 4 columns (image
    by author)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 分区大小对XGBoost模型拟合速度的影响。这些实验的原始数据帧包含500,000行和4列（图片由作者提供）
- en: In this post, the **algorithm for optimal size for Dask Dataframes partitions
    search** is discussed. All tables shown in this post are used to fit the Dask
    Xgboost machine learning model. We will also share some tips that you may find
    helpful.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本文讨论了**Dask数据框分区的最佳大小算法**。本文中展示的所有表格都用于拟合Dask Xgboost机器学习模型。我们还将分享一些您可能会觉得有用的技巧。
- en: '**Documentation tips**'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**文档提示**'
- en: In the official Dask documentation there are web pages with tips on how to handle
    Dask objects (dataframes, arrays, etc.) correctly such as [Dask DataFrames Best
    Practices](https://docs.dask.org/en/stable/dataframe-best-practices.html).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在官方的Dask文档中，有关于如何正确处理Dask对象（数据框、数组等）的网页，例如[最佳Dask数据框实践](https://docs.dask.org/en/stable/dataframe-best-practices.html)。
- en: 'On this page, in particular, you can see such advice:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在此页面上，您可以看到以下建议：
- en: You should aim for partitions that have around 100MB of data each.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目标应该是每个分区的数据量大约为100MB。
- en: However, this advice is rough and does not take into account the computing specifications
    of the server, the size of the source dataset and the specifics of solving the
    problem.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些建议比较粗略，并未考虑服务器的计算规格、源数据集的大小以及问题解决的具体情况。
- en: '**Experiment setup**'
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**实验设置**'
- en: 'As mentioned above, it is assumed that the optimal partition size depends on
    the following three conditions:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，假定最佳分区大小取决于以下三个条件：
- en: Size of full dataset;
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全数据集的大小；
- en: CPU resources (number of processes) which XGBoost and Dask can use;
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost和Dask可以使用的CPU资源（进程数）；
- en: Available Random-access memory (RAM).
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可用的随机存取内存（RAM）。
- en: 'Thus, during the experiments, the number of computing resources was varied,
    as well as the size of the source dataset. Considered cases:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在实验过程中，计算资源的数量以及源数据集的大小均有所变化。考虑的情况：
- en: 'Partition size, thousands of rows: **[5, 10, 50, 100, 200, 300, 400, 500, 600,
    700, 800, 900, 1000]** (13 cases)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分区大小，千行：**[5, 10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]**（13种情况）
- en: 'Size of full dataset, thousands of rows: **[100, 200, 300, 400, 500, 600, 1000,
    2000, 3000, 4000]** (10 cases)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全数据集的大小，千行：**[100, 200, 300, 400, 500, 600, 1000, 2000, 3000, 4000]**（10种情况）
- en: 'CPU resources (workers): **[2, 3, 4]** (3 cases)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU资源（工作者）：**[2, 3, 4]**（3种情况）
- en: 'Available Random-access memory (RAM) per worker: **[1GB, 2GB, 4GB]** (3 cases)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个工作者可用的随机存取内存（RAM）：**[1GB, 2GB, 4GB]**（3种情况）
- en: 'Note: [Worker in Dask](https://distributed.dask.org/en/latest/worker.html)
    is a process in a computer (on a server) that uses the computing resources allocated
    to it and runs in isolation and in parallel relative to other workers.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注：[Dask中的工作者](https://distributed.dask.org/en/latest/worker.html)是计算机（服务器）上的一个进程，它使用分配给它的计算资源，并在与其他工作者隔离并行运行。
- en: Thus, 1170 (13 x 10 x 3 x 3) cases were analyzed. **To obtain more robust estimates
    of execution time, each case was launched 5 times. The metrics (execution time)
    were then averaged.**
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，分析了1170（13 x 10 x 3 x 3）种情况。**为了获得更稳健的执行时间估计，每种情况被运行了5次。然后对指标（执行时间）进行了平均。**
- en: As part of the investigation, we wanted to find out the limits of the dataset
    size at which the virtual machine would not be able to handle the load in order
    to scale the service more successfully.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在调查过程中，我们希望了解数据集大小的限制，以便虚拟机无法处理负载，从而更成功地扩展服务。
- en: '**Results**'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结果**'
- en: First, consider the general visualizations from the experiments. We performed
    runs with different numbers of CPU cores and amounts of RAM, as well as varying
    the size of the original dataset and the size of the partitions. After completing
    the experiments, we prepared a table showing only the optimal solutions (partition
    sizes). Optimal partition sizes are those at which the execution time with given
    conditions (RAM, CPU and source dataset size) was minimal. The correlation matrices
    of the collected metrics are shown in Figure 3.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，考虑实验的一般可视化结果。我们进行了不同CPU核心数量和RAM容量的运行，同时改变了原始数据集的大小和分区的大小。完成实验后，我们准备了一张表格，仅显示最佳解决方案（分区大小）。最佳分区大小是指在给定条件（RAM、CPU和源数据集大小）下，执行时间最短的大小。收集到的指标的相关性矩阵见图3。
- en: '![](../Images/9b73c7691d69963f279eca714bac9648.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b73c7691d69963f279eca714bac9648.png)'
- en: Figure 3\. Correlation matrices of experiment results (image by author)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. 实验结果的相关性矩阵（作者提供的图像）
- en: From the graph you can see that the biggest influence on the execution time
    was obviously the size of the source dataset. The number of workers and amount
    of RAM also have a significant effect on the fit time. Chunk size has a relatively
    weak effect. However, this could be due to the fact that the dependence between
    execution time and partition size is nonlinear, which is confirmed by the curve
    from Figure 2\. Also, Figure 4 confirms that the measurements were made correctly,
    because the results are consistent with our expectations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以看出，对执行时间影响最大的是源数据集的大小。工作线程的数量和内存量对拟合时间也有显著影响。块大小的影响相对较弱。然而，这可能是因为执行时间与分区大小之间的依赖关系是非线性的，这一点从图
    2 的曲线中得到了确认。此外，图 4 证实了测量结果是正确的，因为结果与我们的预期一致。
- en: Let’s look at the animation with 3d graphs (Animation 1).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下带有 3d 图表的动画（动画 1）。
- en: '![](../Images/8c3609781e62bf3d33f1cda67ad40768.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8c3609781e62bf3d33f1cda67ad40768.png)'
- en: Animation 1\. Graph of the different test cases, where each frame is a fixed
    size of the source dataset. Optimal surfaces for each case are shown (by author)
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 动画 1\. 不同测试案例的图表，其中每一帧表示源数据集的固定大小。每种情况的最佳表面显示在图中（由作者提供）
- en: 'In the animation, the optimal (for each combination of Processes number and
    RAM per worker) cases are circled in red. That is, the conditions in which the
    execution time of the algorithm was minimal for a given size of dataset, number
    of cores, RAM and partition size are shown. The graphs also show piecewise constant
    optimal surfaces in gray (NB: surface is global for all cases).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在动画中，最佳（对于每种进程数量和每个工作线程的内存组合）情况用红色圈出。即显示了在给定数据集大小、核心数量、内存和分区大小下算法执行时间最小的条件。图表还显示了灰色的分段常数最佳表面（注意：表面对于所有情况都是全局的）。
- en: From the animation it can be seen that in some frames there is no data on experiments
    (no dots) (Figure 4). This means that the proposed computational resources were
    insufficient to run the model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从动画中可以看出，在某些帧中没有实验数据（没有点）（图 4）。这意味着所提议的计算资源不足以运行模型。
- en: '![](../Images/b5e51a0290a96c89d73ba7bb83ab086a.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5e51a0290a96c89d73ba7bb83ab086a.png)'
- en: Figure 4\. Modeling results for a dataset of 4 million rows. There are no results
    for RAM less than 4 (image by author)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 对一个包含 400 万行的数据集的建模结果。对于小于 4 的内存没有结果（图片由作者提供）
- en: From the picture it can be observed that with this dataset size, **if the number
    of cores is small, then the larger partitions should be formed**. Note that this
    dependence does not hold for all cases.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以观察到，对于这种数据集大小，**如果核心数量较少，则应形成较大的分区**。请注意，这种依赖关系并不适用于所有情况。
- en: Based on the results of launches with insufficient computational resources,
    the following visualization was prepared (Figure 5).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 基于计算资源不足的启动结果，准备了以下可视化（图 5）。
- en: '![](../Images/2bca7d7b9d8d34fbcae10ea0f6643511.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2bca7d7b9d8d34fbcae10ea0f6643511.png)'
- en: Figure 5\. Limit of data volume, exceeding which does not allow to start model
    fitting. The number of objects is calculated as the number of rows in the table
    multiplied by the number of columns (image by author)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 数据量的限制，超过此限制则无法开始模型拟合。对象数量的计算方法是将表格中的行数乘以列数（图片由作者提供）
- en: 'Also, based on the statistics collected on failed runs, a conclusion (tip)
    was reached: if the amount of memory is limited, it is more reliable to use a
    small partition size.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，根据失败运行收集的统计数据得出结论（提示）：如果内存有限，使用较小的分区大小更可靠。
- en: '**Discussion**'
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**讨论**'
- en: Based on this research, several tips for more effective configuration of the
    system based on the Dask XGBoost model were formed. Note that this study was conducted
    in order to run Dask more efficiently on relatively small servers (not having
    hundreds of gigabytes of RAM and tens of CPUs).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这项研究，形成了针对 Dask XGBoost 模型系统更有效配置的若干提示。请注意，本研究的目的是为了在相对较小的服务器上更高效地运行 Dask（这些服务器没有数百吉字节的内存和几十个
    CPU）。
- en: The experiment revealed the optimal hyperplanes. They are modeled using [Gaussian
    processes](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor).
    Based on this algorithm the optimal partition sizes are automatically selected
    (Animation 2).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 实验揭示了最佳超平面。它们通过[高斯过程](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor)进行建模。基于这一算法，最佳分区大小会被自动选择（动画
    2）。
- en: '![](../Images/18d2a6daae39d15d2cd674a3ae13c6f5.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/18d2a6daae39d15d2cd674a3ae13c6f5.png)'
- en: Animation 2\. Optimal surface for different conditions (CPU, RAM and source
    dataset size). Each frame display conditions for particular source dataset size
    (by author)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 动画 2\. 不同条件下的最佳面（CPU、RAM 和源数据集大小）。每一帧显示特定源数据集大小的条件（作者提供）
- en: As can be seen from the animation, on average, **the optimal partition size
    decreases when the number of rows in the source dataset increases**.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从动画中可以看出，**当源数据集中的行数增加时，最佳分区大小通常会减少**。
- en: '**Conclusion (& tips)**'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结论（和建议）**'
- en: I hope you were interested in reading about what size patrician proved to be
    the optimal size for training the XGBoost model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你对了解哪个大小的分区被证明是训练 XGBoost 模型的最佳大小感兴趣。
- en: 'I realize that this article has gotten very “technical”. Therefore, for those
    who managed to read it to the end, I will give some tips:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我意识到这篇文章变得非常“技术化”。因此，对于那些读到最后的人，我将提供一些建议：
- en: If you are measuring execution time, always run the calculations several times
    and average the results since runtimes are stochastic;
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在测量执行时间，始终运行多次计算并取结果的平均值，因为运行时间是随机的；
- en: If you are in doubt about what size of partitions to choose, it is better to
    make a mistake to a smaller extent (otherwise the algorithm will not just run
    for a long time, but may crash with an error);
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你对选择什么大小的分区感到困惑，最好犯一个较小的错误（否则算法不仅会运行很长时间，还可能因错误而崩溃）；
- en: To initialize a cluster locally in Dask, the *cluster = LocalCluster()* and
    *Client(cluster)* [commands are used](https://docs.dask.org/en/stable/deploying-python.html).
    We strongly recommend to initialize such a cluster only once in code using the
    Singleton pattern. You can see how it can be implemented in Python [here](https://stackoverflow.com/questions/6760685/creating-a-singleton-in-python).
    Otherwise, you will initialize a new cluster every launch;
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Dask 中本地初始化集群时，使用 *cluster = LocalCluster()* 和 *Client(cluster)* [命令](https://docs.dask.org/en/stable/deploying-python.html)。我们强烈建议仅在代码中使用单例模式初始化这样的集群。你可以在
    [这里](https://stackoverflow.com/questions/6760685/creating-a-singleton-in-python)
    查看如何在 Python 中实现它。否则，每次启动时你都会初始化一个新集群；
- en: On average, the optimal partition size decreases when the number of rows in
    the source dataset increases
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均来说，当源数据集中的行数增加时，最佳分区大小会减少
- en: The story about Dask and machine learning was presented by [Mikhail Sarafanov](https://github.com/Dreamlone)
    and the [Wiredhut team](https://wiredhut.com/)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Dask 和机器学习的故事由 [Mikhail Sarafanov](https://github.com/Dreamlone) 和 [Wiredhut
    团队](https://wiredhut.com/) 提供
