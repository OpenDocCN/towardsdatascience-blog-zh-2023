- en: The Best Resources to Learn Reinforcement Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å­¦ä¹ å¼ºåŒ–å­¦ä¹ çš„æœ€ä½³èµ„æº
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/best-free-courses-and-resources-to-learn-reinforcement-learning-ed6633608cb2](https://towardsdatascience.com/best-free-courses-and-resources-to-learn-reinforcement-learning-ed6633608cb2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/best-free-courses-and-resources-to-learn-reinforcement-learning-ed6633608cb2](https://towardsdatascience.com/best-free-courses-and-resources-to-learn-reinforcement-learning-ed6633608cb2)
- en: Explore some of the best (mostly free) tutorials, courses, books, and more on
    this ever-evolving field
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¢ç´¢ä¸€äº›æœ€ä½³çš„ï¼ˆå¤§å¤šæ•°å…è´¹ï¼‰æ•™ç¨‹ã€è¯¾ç¨‹ã€ä¹¦ç±ç­‰ï¼Œæ¶‰åŠè¿™ä¸ªä¸æ–­å‘å±•çš„é¢†åŸŸ
- en: '[](https://ebrahimpichka.medium.com/?source=post_page-----ed6633608cb2--------------------------------)[![Ebrahim
    Pichka](../Images/8add6e8e875d9e921caf7f5eaa77d545.png)](https://ebrahimpichka.medium.com/?source=post_page-----ed6633608cb2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ed6633608cb2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ed6633608cb2--------------------------------)
    [Ebrahim Pichka](https://ebrahimpichka.medium.com/?source=post_page-----ed6633608cb2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ebrahimpichka.medium.com/?source=post_page-----ed6633608cb2--------------------------------)[![Ebrahim
    Pichka](../Images/8add6e8e875d9e921caf7f5eaa77d545.png)](https://ebrahimpichka.medium.com/?source=post_page-----ed6633608cb2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ed6633608cb2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ed6633608cb2--------------------------------)
    [Ebrahim Pichka](https://ebrahimpichka.medium.com/?source=post_page-----ed6633608cb2--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ed6633608cb2--------------------------------)
    Â·18 min readÂ·Jan 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----ed6633608cb2--------------------------------)
    Â·18åˆ†é’Ÿé˜…è¯»Â·2023å¹´1æœˆ12æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c3c16062645885f673f4c7437c3f51da.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3c16062645885f673f4c7437c3f51da.png)'
- en: Learning Robot â€” [image by Author, generated by [**Midjourney**](https://www.midjourney.com/)
    **AI**]
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å­¦ä¹ æœºå™¨äºº â€” [ä½œè€…æä¾›çš„å›¾åƒï¼Œç”Ÿæˆè‡ª[**Midjourney**](https://www.midjourney.com/) **AI**]
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: Reinforcement learning (RL) is a paradigm of AI methodologies in which an agent
    learns to interact with its environment in order to maximize the expectation of
    reward signals received from its environment. Unlike supervised learning, in which
    the agent is given labeled examples and learns to predict an output based on input,
    RL involves the agent actively taking actions in its environment and receiving
    feedback in the form of rewards or punishments. This feedback is used to adjust
    the agentâ€™s behavior and improve its performance over time.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ˜¯ä¸€ç§äººå·¥æ™ºèƒ½æ–¹æ³•è®ºï¼Œåœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ™ºèƒ½ä½“å­¦ä¹ ä¸å…¶ç¯å¢ƒäº’åŠ¨ï¼Œä»¥æœ€å¤§åŒ–ä»ç¯å¢ƒä¸­è·å¾—çš„å¥–åŠ±ä¿¡å·çš„æœŸæœ›å€¼ã€‚ä¸ç›‘ç£å­¦ä¹ ä¸åŒï¼Œåè€…ä¸­æ™ºèƒ½ä½“ä¼šè·å¾—æ ‡è®°çš„ä¾‹å­å¹¶æ ¹æ®è¾“å…¥é¢„æµ‹è¾“å‡ºï¼ŒRLæ¶‰åŠæ™ºèƒ½ä½“ä¸»åŠ¨åœ¨å…¶ç¯å¢ƒä¸­é‡‡å–è¡ŒåŠ¨ï¼Œå¹¶ä»¥å¥–åŠ±æˆ–æƒ©ç½šçš„å½¢å¼æ¥æ”¶åé¦ˆã€‚è¿™äº›åé¦ˆç”¨äºè°ƒæ•´æ™ºèƒ½ä½“çš„è¡Œä¸ºï¼Œå¹¶éšç€æ—¶é—´çš„æ¨ç§»æé«˜å…¶è¡¨ç°ã€‚
- en: RL has been applied to a wide range of domains, including robotics, natural
    language processing, and finance. In the gaming industry, RL has been used to
    develop advanced game-playing agents, such as the **AlphaGo [1]** algorithm that
    defeated a human champion in the board game Go. In the healthcare industry, RL
    has been used to optimize treatment plans for patients with chronic diseases,
    such as diabetes. RL has also been used in the field of robotics, allowing robots
    to learn and adapt to new environments and tasks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ å·²è¢«åº”ç”¨äºå¹¿æ³›çš„é¢†åŸŸï¼ŒåŒ…æ‹¬æœºå™¨äººæŠ€æœ¯ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œé‡‘èã€‚åœ¨æ¸¸æˆè¡Œä¸šä¸­ï¼Œå¼ºåŒ–å­¦ä¹ è¢«ç”¨äºå¼€å‘é«˜çº§æ¸¸æˆä»£ç†ï¼Œä¾‹å¦‚**AlphaGo [1]**ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨å›´æ£‹æ¯”èµ›ä¸­å‡»è´¥äº†äººç±»å† å†›ã€‚åœ¨åŒ»ç–—è¡Œä¸šä¸­ï¼Œå¼ºåŒ–å­¦ä¹ è¢«ç”¨äºä¼˜åŒ–æ…¢æ€§ç—…æ‚£è€…çš„æ²»ç–—è®¡åˆ’ï¼Œä¾‹å¦‚ç³–å°¿ç—…ã€‚å¼ºåŒ–å­¦ä¹ è¿˜è¢«åº”ç”¨äºæœºå™¨äººé¢†åŸŸï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿå­¦ä¹ å¹¶é€‚åº”æ–°çš„ç¯å¢ƒå’Œä»»åŠ¡ã€‚
- en: '![](../Images/68971bb9b5632381875db9b9be9016dc.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68971bb9b5632381875db9b9be9016dc.png)'
- en: Maze Robot â€” [Image by author, generated by [**Midjourney AI**](https://midjourney.com/)]
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: è¿·å®«æœºå™¨äºº â€” [ç”±ä½œè€…æä¾›çš„å›¾åƒï¼Œç”Ÿæˆè‡ª[**Midjourney AI**](https://midjourney.com/)]
- en: One of the most iconic recent breakthroughs in RL is the development of [chatGPT](https://openai.com/blog/chatgpt/)
    [2] by OpenAI, a natural language processing system that can hold intelligent
    conversations with humans. chatGPT was trained on a large dataset of human conversations
    and can generate coherent and contextually appropriate responses to user inputs.
    This system demonstrates the potential for RL to be used to improve natural language
    processing systems and create more human-like AI assistants.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘åœ¨å¼ºåŒ–å­¦ä¹ é¢†åŸŸæœ€å…·æ ‡å¿—æ€§çš„çªç ´ä¹‹ä¸€æ˜¯ [chatGPT](https://openai.com/blog/chatgpt/) [2] çš„å¼€å‘ï¼Œç”± OpenAI
    æä¾›ï¼Œè¿™æ˜¯ä¸€ç§èƒ½å¤Ÿä¸äººç±»è¿›è¡Œæ™ºèƒ½å¯¹è¯çš„è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿã€‚chatGPT åœ¨å¤§é‡äººç±»å¯¹è¯æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå¯ä»¥ç”Ÿæˆè¿è´¯ä¸”ç¬¦åˆä¸Šä¸‹æ–‡çš„ç”¨æˆ·è¾“å…¥å“åº”ã€‚è¯¥ç³»ç»Ÿå±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ åœ¨æ”¹è¿›è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿå’Œåˆ›é€ æ›´å…·äººæ€§åŒ–çš„
    AI åŠ©æ‰‹æ–¹é¢çš„æ½œåŠ›ã€‚
- en: As RL continues to advance and make an impact in various fields, it has become
    increasingly important for professionals and researchers to have a strong understanding
    of this technique. If youâ€™re interested in learning about RL, youâ€™re in luck!
    There are a variety of resources available online that can help you get started
    and become proficient in this exciting field. In this blog post, weâ€™ll highlight
    some of the best, mostly free, resources for learning about RL, including tutorials,
    courses, books, and more. Whether youâ€™re a beginner looking to get your feet wet
    or an experienced practitioner looking to deepen your understanding, these resources
    will have something for you.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€å¼ºåŒ–å­¦ä¹ çš„ä¸æ–­è¿›æ­¥å¹¶åœ¨å„ä¸ªé¢†åŸŸäº§ç”Ÿå½±å“ï¼Œä¸“ä¸šäººå£«å’Œç ”ç©¶äººå‘˜å¯¹è¯¥æŠ€æœ¯çš„æ·±åˆ»ç†è§£å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚å¦‚æœä½ å¯¹å­¦ä¹ å¼ºåŒ–å­¦ä¹ æ„Ÿå…´è¶£ï¼Œä½ å¾ˆå¹¸è¿ï¼åœ¨çº¿ä¸Šæœ‰å¤šç§èµ„æºå¯ä»¥å¸®åŠ©ä½ å…¥é—¨å¹¶åœ¨è¿™ä¸€æ¿€åŠ¨äººå¿ƒçš„é¢†åŸŸä¸­å˜å¾—ç†Ÿç»ƒã€‚åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†çªå‡ºä¸€äº›æœ€ä½³çš„ã€ä¸»è¦å…è´¹çš„å­¦ä¹ å¼ºåŒ–å­¦ä¹ èµ„æºï¼ŒåŒ…æ‹¬æ•™ç¨‹ã€è¯¾ç¨‹ã€ä¹¦ç±ç­‰ã€‚æ— è®ºä½ æ˜¯åˆå­¦è€…è¿˜æ˜¯ç»éªŒä¸°å¯Œçš„ä»ä¸šè€…ï¼Œè¿™äº›èµ„æºéƒ½ä¼šé€‚åˆä½ ã€‚
- en: In this post, we are going to first start by introducing the best **online courses,
    lectures, and tutorials** available for RL on the internet. Then we will introduce
    the best and most popular **books** and **textbooks** in the field. And at last,
    we will also include some useful extra resources and GitHub repositories on the
    topic.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†é¦–å…ˆä»‹ç»äº’è”ç½‘ä¸Šæœ€ä½³çš„ **åœ¨çº¿è¯¾ç¨‹ã€è®²åº§å’Œæ•™ç¨‹**ï¼Œç„¶åä»‹ç»è¯¥é¢†åŸŸæœ€å¥½çš„å’Œæœ€å—æ¬¢è¿çš„ **ä¹¦ç±** å’Œ **æ•™ç§‘ä¹¦**ã€‚æœ€åï¼Œæˆ‘ä»¬è¿˜å°†åŒ…æ‹¬ä¸€äº›æœ‰ç”¨çš„é¢å¤–èµ„æºå’Œ
    GitHub ä»“åº“ã€‚
- en: Online Courses
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨çº¿è¯¾ç¨‹
- en: While there are numerous courses available on the subject, weâ€™ve carefully selected
    a list of the most comprehensive and high-quality options that are mostly free.
    These courses cover a wide range of topics in RL, from the basics to advanced
    concepts, and are taught by experts in the field. Whether youâ€™re a beginner looking
    to get your feet wet or an experienced practitioner looking to deepen your understanding,
    these courses will have something for you. Keep reading to discover some of the
    top online courses for learning about RL! Please note that this is not an exhaustive
    list, but rather a curated selection of the most highly recommended courses available.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æœ‰å¾ˆå¤šå…³äºè¯¥ä¸»é¢˜çš„è¯¾ç¨‹å¯ä¾›é€‰æ‹©ï¼Œä½†æˆ‘ä»¬ç²¾å¿ƒæŒ‘é€‰äº†ä¸€äº›æœ€å…¨é¢ä¸”é«˜è´¨é‡çš„å…è´¹è¯¾ç¨‹ã€‚è¿™äº›è¯¾ç¨‹æ¶µç›–äº†å¼ºåŒ–å­¦ä¹ ä»åŸºç¡€åˆ°é«˜çº§æ¦‚å¿µçš„å¹¿æ³›ä¸»é¢˜ï¼Œç”±é¢†åŸŸä¸“å®¶æˆè¯¾ã€‚æ— è®ºä½ æ˜¯åˆå­¦è€…è¿˜æ˜¯ç»éªŒä¸°å¯Œçš„ä»ä¸šè€…ï¼Œè¿™äº›è¯¾ç¨‹éƒ½èƒ½æ»¡è¶³ä½ çš„éœ€æ±‚ã€‚ç»§ç»­é˜…è¯»ï¼Œå‘ç°ä¸€äº›å­¦ä¹ å¼ºåŒ–å­¦ä¹ çš„é¡¶çº§åœ¨çº¿è¯¾ç¨‹å§ï¼è¯·æ³¨æ„ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªè¯¦å°½çš„æ¸…å•ï¼Œè€Œæ˜¯ä¸€ä¸ªç²¾é€‰çš„é«˜åº¦æ¨èè¯¾ç¨‹åˆ—è¡¨ã€‚
- en: '[1 - Reinforcement Learning Specialization â€” by Coursera](https://www.coursera.org/specializations/reinforcement-learning)'
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[1 - å¼ºåŒ–å­¦ä¹ ä¸“ä¸šåŒ–è¯¾ç¨‹ â€” ç”± Coursera æä¾›](https://www.coursera.org/specializations/reinforcement-learning)'
- en: '![](../Images/824c6d4295fb942cdef4c6aa3500ec37.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/824c6d4295fb942cdef4c6aa3500ec37.png)'
- en: Photo from [Reinforcement Learning Specialization](https://www.coursera.org/specializations/reinforcement-learning)
    website by Courseraâ€” [**[SOURCE]**](https://www.coursera.org/specializations/reinforcement-learning)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª [å¼ºåŒ–å­¦ä¹ ä¸“ä¸šåŒ–è¯¾ç¨‹](https://www.coursera.org/specializations/reinforcement-learning)
    ç½‘ç«™çš„ç…§ç‰‡ï¼Œç”± Coursera æä¾›â€” [**[æ¥æº]**](https://www.coursera.org/specializations/reinforcement-learning)
- en: The Reinforcement Learning Specialization on Coursera, offered by the University
    of Alberta and the Alberta Machine Intelligence Institute, is a comprehensive
    program designed to teach you the foundations of reinforcement learning. This
    specialization consists of three courses and one capstone project that cover a
    wide range of topics in RL, including RL fundamentals, value-based methods, policy
    gradient methods, model-based RL, deep RL, etc. Throughout the course, youâ€™ll
    have the opportunity to apply what youâ€™ve learned through hands-on programming
    assignments and a final project. The course is taught by experienced instructors
    and academics who are experts in the field of RL and includes a mix of lectures,
    readings, and interactive exercises. This specialization is suitable for students
    with a background in machine learning or a related field and is a great resource
    for anyone looking to gain a solid understanding of RL.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Courseraä¸Šçš„å¼ºåŒ–å­¦ä¹ ä¸“ä¸šè¯¾ç¨‹ï¼Œç”±é˜¿å°”ä¼¯å¡”å¤§å­¦åŠé˜¿å°”ä¼¯å¡”æœºå™¨æ™ºèƒ½ç ”ç©¶æ‰€æä¾›ï¼Œæ˜¯ä¸€ä¸ªå…¨é¢çš„é¡¹ç›®ï¼Œæ—¨åœ¨æ•™æˆå¼ºåŒ–å­¦ä¹ çš„åŸºç¡€ã€‚è¯¥ä¸“ä¸šè¯¾ç¨‹åŒ…æ‹¬ä¸‰é—¨è¯¾ç¨‹å’Œä¸€ä¸ªé¡¶ç‚¹é¡¹ç›®ï¼Œæ¶µç›–äº†å¼ºåŒ–å­¦ä¹ çš„å¹¿æ³›ä¸»é¢˜ï¼ŒåŒ…æ‹¬RLåŸºç¡€ã€åŸºäºä»·å€¼çš„æ–¹æ³•ã€ç­–ç•¥æ¢¯åº¦æ–¹æ³•ã€åŸºäºæ¨¡å‹çš„RLã€æ·±åº¦RLç­‰ã€‚åœ¨è¯¾ç¨‹ä¸­ï¼Œä½ å°†æœ‰æœºä¼šé€šè¿‡å®è·µç¼–ç¨‹ä½œä¸šå’Œæœ€ç»ˆé¡¹ç›®æ¥åº”ç”¨æ‰€å­¦å†…å®¹ã€‚è¯¾ç¨‹ç”±åœ¨å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„ç»éªŒä¸°å¯Œçš„è®²å¸ˆå’Œå­¦è€…æˆè¯¾ï¼ŒåŒ…å«è®²åº§ã€é˜…è¯»å’Œäº’åŠ¨ç»ƒä¹ ã€‚è¿™ä¸€ä¸“ä¸šè¯¾ç¨‹é€‚åˆå…·æœ‰æœºå™¨å­¦ä¹ æˆ–ç›¸å…³é¢†åŸŸèƒŒæ™¯çš„å­¦ç”Ÿï¼Œä¹Ÿæ˜¯ä»»ä½•å¸Œæœ›æ·±å…¥ç†è§£RLçš„äººçš„æå¥½èµ„æºã€‚
- en: Although it is not technically free, you could always apply for Courseraâ€™s financial
    aid to waive the course fee if you were not to afford it. However, considering
    the content quality and material, it would be totally worthwhile.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æŠ€æœ¯ä¸Šå¹¶éå®Œå…¨å…è´¹ï¼Œä½†å¦‚æœä½ è´Ÿæ‹…ä¸èµ·ï¼Œå¯ä»¥ç”³è¯·Courseraçš„è´¢æ”¿æ´åŠ©æ¥å…é™¤è¯¾ç¨‹è´¹ç”¨ã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°å†…å®¹è´¨é‡å’Œææ–™ï¼Œè¿™ç»å¯¹æ˜¯å€¼å¾—çš„ã€‚
- en: 'Link to the course:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹é“¾æ¥ï¼š
- en: '[](https://www.coursera.org/specializations/reinforcement-learning?source=post_page-----ed6633608cb2--------------------------------)
    [## Reinforcement Learning'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[## å¼ºåŒ–å­¦ä¹ ](https://www.coursera.org/specializations/reinforcement-learning?source=post_page-----ed6633608cb2--------------------------------)'
- en: Master the Concepts of Reinforcement Learning. Implement a complete RL solution
    and understand how to apply AI tools toâ€¦
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æŒæ¡å¼ºåŒ–å­¦ä¹ çš„æ¦‚å¿µã€‚å®ç°ä¸€ä¸ªå®Œæ•´çš„RLè§£å†³æ–¹æ¡ˆï¼Œå¹¶äº†è§£å¦‚ä½•åº”ç”¨AIå·¥å…·æ¥â€¦â€¦
- en: www.coursera.org](https://www.coursera.org/specializations/reinforcement-learning?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[é“¾æ¥åˆ°è¯¾ç¨‹](https://www.coursera.org/specializations/reinforcement-learning?source=post_page-----ed6633608cb2--------------------------------)'
- en: '[2 - Reinforcement Learning Lecture Series 2021 â€” by DeepMind x UCL](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021)'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[2 - 2021å¹´å¼ºåŒ–å­¦ä¹ è®²åº§ç³»åˆ— â€” ç”±DeepMindä¸UCLè”åˆå‘ˆç°](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021)'
- en: '![](../Images/2a7973e51478cad2a9ac44bd0ee64973.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a7973e51478cad2a9ac44bd0ee64973.png)'
- en: Photo from DeepMind official website by DeepMind â€” [**[SOURCE]**](https://twitter.com/DeepMind/status/1435974267112464385)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥æºï¼šDeepMindå®˜æ–¹ç½‘é¡µï¼Œç”±DeepMindæä¾› â€” [**[æ¥æº]**](https://twitter.com/DeepMind/status/1435974267112464385)
- en: The â€œReinforcement Learning Lecture Seriesâ€ is a series of lectures on the topic
    of reinforcement learning, presented by DeepMind and UCL. This course covers a
    wide range of topics within the field of reinforcement learning, including foundational
    concepts such as Markov decision processes and dynamic programming, as well as
    more advanced techniques such as model-based and model-free learning and off-policy,
    value-/policy-based algorithms, function approximation, and deep RL. The lectures
    are offered by renowned academics and researchers from Deepmind and UCL. The lectures
    are aimed at researchers and practitioners interested in learning about the latest
    developments and applications in reinforcement learning. The course is offered
    online and is open to anyone who is interested in learning about this exciting
    and rapidly-evolving field.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: â€œå¼ºåŒ–å­¦ä¹ è®²åº§ç³»åˆ—â€æ˜¯ç”±DeepMindå’ŒUCLå‘ˆç°çš„ä¸€ç³»åˆ—å…³äºå¼ºåŒ–å­¦ä¹ çš„è®²åº§ã€‚è¯¥è¯¾ç¨‹æ¶µç›–äº†å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„å¹¿æ³›ä¸»é¢˜ï¼ŒåŒ…æ‹¬é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å’ŒåŠ¨æ€è§„åˆ’ç­‰åŸºç¡€æ¦‚å¿µï¼Œä»¥åŠæ›´é«˜çº§çš„æŠ€æœ¯ï¼Œå¦‚åŸºäºæ¨¡å‹å’Œæ— æ¨¡å‹å­¦ä¹ ã€ç¦»ç­–ç•¥ã€åŸºäºä»·å€¼/ç­–ç•¥çš„ç®—æ³•ã€å‡½æ•°é€¼è¿‘å’Œæ·±åº¦RLã€‚è®²åº§ç”±DeepMindå’ŒUCLçš„çŸ¥åå­¦è€…å’Œç ”ç©¶äººå‘˜æä¾›ï¼Œæ—¨åœ¨å¸®åŠ©ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…äº†è§£å¼ºåŒ–å­¦ä¹ çš„æœ€æ–°å‘å±•å’Œåº”ç”¨ã€‚è¯¾ç¨‹åœ¨çº¿æä¾›ï¼Œä»»ä½•å¯¹è¿™ä¸€æ¿€åŠ¨äººå¿ƒä¸”è¿…é€Ÿå‘å±•çš„é¢†åŸŸæ„Ÿå…´è¶£çš„äººéƒ½å¯ä»¥å‚åŠ ã€‚
- en: DeepMind x UCL RL Lecture Series â€” Introduction to Reinforcement Learning
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: DeepMindä¸UCLå¼ºåŒ–å­¦ä¹ è®²åº§ç³»åˆ— â€” å¼ºåŒ–å­¦ä¹ ç®€ä»‹
- en: 'Link to the course:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹é“¾æ¥ï¼š
- en: '[](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021?source=post_page-----ed6633608cb2--------------------------------)
    [## Reinforcement Learning Lecture Series 2021'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021?source=post_page-----ed6633608cb2--------------------------------)
    [## å¼ºåŒ–å­¦ä¹ è®²åº§ç³»åˆ— 2021'
- en: Taught by DeepMind researchers, this series was created in collaboration with
    University College London (UCL) to offerâ€¦
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¯¥ç³»åˆ—ç”±DeepMindç ”ç©¶äººå‘˜æˆè¯¾ï¼Œä¸ä¼¦æ•¦å¤§å­¦å­¦é™¢ï¼ˆUCLï¼‰åˆä½œåˆ›å»ºï¼Œæ—¨åœ¨æä¾›â€¦
- en: www.deepmind.com](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: www.deepmind.com](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2021?source=post_page-----ed6633608cb2--------------------------------)
- en: There is also an older version of this series from 2018 which could be [found
    here](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2018).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 2018å¹´ä¹Ÿæœ‰è¿™ä¸ªç³»åˆ—çš„æ—§ç‰ˆæœ¬ï¼Œå¯ä»¥åœ¨[è¿™é‡Œæ‰¾åˆ°](https://www.deepmind.com/learning-resources/reinforcement-learning-lecture-series-2018)ã€‚
- en: '[3 - Stanford CS234: Reinforcement Learning â€” Winter 2019](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[3 - æ–¯å¦ç¦CS234ï¼šå¼ºåŒ–å­¦ä¹  â€” 2019å†¬å­£](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)'
- en: The CS234 Reinforcement Learning course from Stanford is a comprehensive study
    of reinforcement learning, taught by Prof. Emma Brunskill. This course covers
    a wide range of topics in RL, including foundational concepts such as MDPs and
    Monte Carlo methods, as well as more advanced techniques like temporal difference
    learning and deep reinforcement learning. The course is designed for students
    who have a background in machine learning and are interested in learning about
    the latest techniques and applications in reinforcement learning. The course is
    offered through a series of video lectures, which are available on YouTube through
    the provided link.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¯å¦ç¦å¤§å­¦çš„CS234å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹æ˜¯å¯¹å¼ºåŒ–å­¦ä¹ çš„å…¨é¢ç ”ç©¶ï¼Œç”±Emma Brunskillæ•™æˆæˆè¯¾ã€‚è¯¥è¯¾ç¨‹æ¶µç›–äº†å¼ºåŒ–å­¦ä¹ çš„å¹¿æ³›ä¸»é¢˜ï¼ŒåŒ…æ‹¬åŸºç¡€æ¦‚å¿µå¦‚MDPå’Œè’™ç‰¹å¡æ´›æ–¹æ³•ï¼Œä»¥åŠæ›´é«˜çº§çš„æŠ€æœ¯å¦‚æ—¶é—´å·®åˆ†å­¦ä¹ å’Œæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚è¯¾ç¨‹è®¾è®¡é¢å‘æœ‰æœºå™¨å­¦ä¹ èƒŒæ™¯çš„å­¦ç”Ÿï¼Œæ—¨åœ¨æ•™æˆæœ€æ–°çš„å¼ºåŒ–å­¦ä¹ æŠ€æœ¯å’Œåº”ç”¨ã€‚è¯¾ç¨‹é€šè¿‡ä¸€ç³»åˆ—çš„è§†é¢‘è®²åº§æä¾›ï¼Œå¯ä»¥é€šè¿‡æä¾›çš„é“¾æ¥åœ¨YouTubeä¸Šè§‚çœ‹ã€‚
- en: 'Link to the course: [https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹é“¾æ¥ï¼š[https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u](https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)
- en: '[4 - Introduction to Reinforcement Learning with David Silver](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver)'
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[4 - ä¸David Silverçš„å¼ºåŒ–å­¦ä¹ ä»‹ç»](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver)'
- en: '![](../Images/76f1c87f5bcb13b3cbc355d032fcc71b.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/76f1c87f5bcb13b3cbc355d032fcc71b.png)'
- en: Photo from [Introduction to Reinforcement Learning with David Silver](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver)
    â€” [**[SOURCE]**](https://www.deepmind.com)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº[ã€Šä¸David Silverçš„å¼ºåŒ–å­¦ä¹ ä»‹ç»ã€‹](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver)
    â€” [**[æ¥æº]**](https://www.deepmind.com)
- en: The Introduction to Reinforcement Learning with David Silver course is a comprehensive
    introduction to the field of reinforcement learning, taught by Professor David
    Silver. Silver is a leading researcher in the field of reinforcement learning
    and artificial intelligence, and has been a key contributor to the development
    of AlphaGo, the first computer program to defeat a professional human player in
    the game of Go. He is also among the authors of some of the key research papers
    in RL such as Deep Q-Learning and DDPG algorithm. The course covers the fundamental
    concepts and techniques of reinforcement learning, including dynamic programming,
    Monte Carlo methods, and temporal difference learning. It also covers more advanced
    topics such as exploration-exploitation trade-offs, function approximation, and
    deep reinforcement learning. Overall, the course provides a solid foundation in
    reinforcement learning and is suitable for anyone interested in learning more
    about this exciting and rapidly-evolving field of artificial intelligence.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ã€Šä¸å¤§å«Â·è¥¿å°”å¼—çš„å¼ºåŒ–å­¦ä¹ ç®€ä»‹ã€‹è¯¾ç¨‹æ˜¯å¯¹å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„å…¨é¢ä»‹ç»ï¼Œç”±å¤§å«Â·è¥¿å°”å¼—æ•™æˆè®²æˆã€‚è¥¿å°”å¼—æ˜¯å¼ºåŒ–å­¦ä¹ å’Œäººå·¥æ™ºèƒ½é¢†åŸŸçš„é¢†å…ˆç ”ç©¶è€…ï¼Œå¹¶ä¸”åœ¨AlphaGoçš„å¼€å‘ä¸­å‘æŒ¥äº†å…³é”®ä½œç”¨ï¼ŒAlphaGoæ˜¯ç¬¬ä¸€ä¸ªåœ¨å›´æ£‹ä¸­æˆ˜èƒœèŒä¸šäººç±»ç©å®¶çš„è®¡ç®—æœºç¨‹åºã€‚ä»–è¿˜æ˜¯ä¸€äº›å…³é”®ç ”ç©¶è®ºæ–‡çš„ä½œè€…ï¼Œå¦‚æ·±åº¦Qå­¦ä¹ å’ŒDDPGç®—æ³•ã€‚è¯¾ç¨‹æ¶µç›–äº†å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’ŒæŠ€æœ¯ï¼ŒåŒ…æ‹¬åŠ¨æ€è§„åˆ’ã€è’™ç‰¹å¡æ´›æ–¹æ³•å’Œæ—¶åºå·®åˆ†å­¦ä¹ ã€‚å®ƒè¿˜æ¶‰åŠæ›´é«˜çº§çš„ä¸»é¢˜ï¼Œå¦‚æ¢ç´¢-åˆ©ç”¨æƒè¡¡ã€å‡½æ•°é€¼è¿‘å’Œæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é—¨è¯¾ç¨‹ä¸ºå¼ºåŒ–å­¦ä¹ æä¾›äº†åšå®çš„åŸºç¡€ï¼Œé€‚åˆä»»ä½•å¯¹è¿™ä¸ªæ¿€åŠ¨äººå¿ƒå’Œå¿«é€Ÿå‘å±•çš„äººå·¥æ™ºèƒ½é¢†åŸŸæ„Ÿå…´è¶£çš„äººã€‚
- en: 'Link to the course:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹é“¾æ¥ï¼š
- en: '[](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver?source=post_page-----ed6633608cb2--------------------------------)
    [## Introduction to Reinforcement Learning with David Silver'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver?source=post_page-----ed6633608cb2--------------------------------)
    [## ä¸å¤§å«Â·è¥¿å°”å¼—çš„å¼ºåŒ–å­¦ä¹ ç®€ä»‹'
- en: This classic 10 part course, taught by Reinforcement Learning (RL) pioneer David
    Silver, was recorded in 2015 andâ€¦
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¿™é—¨ç»å…¸çš„10éƒ¨åˆ†è¯¾ç¨‹ç”±å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å…ˆé©±å¤§å«Â·è¥¿å°”å¼—è®²æˆï¼Œå½•åˆ¶äº2015å¹´â€¦â€¦
- en: www.deepmind.com](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: www.deepmind.com](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver?source=post_page-----ed6633608cb2--------------------------------)
- en: '[Introduction to Reinforcement Learning with David Silver](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸å¤§å«Â·è¥¿å°”å¼—çš„å¼ºåŒ–å­¦ä¹ ç®€ä»‹](https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver)'
- en: '[5 - UC Berkeley CS 285: Deep Reinforcement Learning â€” Fall 2021](https://www.youtube.com/playlist?list=PL_iWQOsE6TfXxKgI1GgyV1B_Xa0DxE5eH)'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[5 - UC Berkeley CS 285: æ·±åº¦å¼ºåŒ–å­¦ä¹  â€” 2021å¹´ç§‹å­£](https://www.youtube.com/playlist?list=PL_iWQOsE6TfXxKgI1GgyV1B_Xa0DxE5eH)'
- en: The UC Berkeley CS 285 Deep Reinforcement Learning course is a graduate-level
    course that covers the field of reinforcement learning, with a focus on deep learning
    techniques. The course is taught by Prof. Sergey Levine and is designed for students
    who have a strong background in machine learning and are interested in learning
    about the latest techniques and applications in reinforcement learning. The course
    covers a wide range of topics, including foundational concepts such as Markov
    decision processes and temporal difference learning, as well as advanced techniques
    like deep Q-learning and policy gradient methods. The course is offered through
    a series of video lectures, which are available on YouTube through the provided
    link.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: UC Berkeley CS 285æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹æ˜¯ä¸€ä¸ªç ”ç©¶ç”Ÿçº§åˆ«çš„è¯¾ç¨‹ï¼Œæ¶µç›–äº†å¼ºåŒ–å­¦ä¹ é¢†åŸŸï¼Œé‡ç‚¹æ˜¯æ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚è¯¥è¯¾ç¨‹ç”±Sergey Levineæ•™æˆè®²æˆï¼Œæ—¨åœ¨ä¸ºå…·æœ‰æ‰å®æœºå™¨å­¦ä¹ èƒŒæ™¯å¹¶å¸Œæœ›äº†è§£å¼ºåŒ–å­¦ä¹ æœ€æ–°æŠ€æœ¯å’Œåº”ç”¨çš„å­¦ç”Ÿè®¾è®¡ã€‚è¯¾ç¨‹æ¶µç›–äº†å¹¿æ³›çš„ä¸»é¢˜ï¼ŒåŒ…æ‹¬é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å’Œæ—¶åºå·®åˆ†å­¦ä¹ ç­‰åŸºç¡€æ¦‚å¿µï¼Œä»¥åŠæ·±åº¦Qå­¦ä¹ å’Œç­–ç•¥æ¢¯åº¦æ–¹æ³•ç­‰é«˜çº§æŠ€æœ¯ã€‚è¯¥è¯¾ç¨‹é€šè¿‡ä¸€ç³»åˆ—è§†é¢‘è®²åº§æä¾›ï¼Œè§†é¢‘å¯é€šè¿‡æä¾›çš„é“¾æ¥åœ¨YouTubeä¸Šè§‚çœ‹ã€‚
- en: 'Link to the course: [https://www.youtube.com/playlist?list=PL_iWQOsE6TfXxKgI1GgyV1B_Xa0DxE5eH](https://www.youtube.com/playlist?list=PL_iWQOsE6TfXxKgI1GgyV1B_Xa0DxE5eH)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹é“¾æ¥ï¼š[https://www.youtube.com/playlist?list=PL_iWQOsE6TfXxKgI1GgyV1B_Xa0DxE5eH](https://www.youtube.com/playlist?list=PL_iWQOsE6TfXxKgI1GgyV1B_Xa0DxE5eH)
- en: There is also an older series of the course from Fall 2020 [here](https://www.youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ç³»åˆ—æ—§çš„2020å¹´ç§‹å­£è¯¾ç¨‹ [åœ¨è¿™é‡Œ](https://www.youtube.com/playlist?list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc)ã€‚
- en: '[6 - Deep RL BootCamp â€” UC Berkeley](https://sites.google.com/view/deep-rl-bootcamp/lectures)'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[6 - æ·±åº¦å¼ºåŒ–å­¦ä¹ è®­ç»ƒè¥ â€” åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡](https://sites.google.com/view/deep-rl-bootcamp/lectures)'
- en: '![](../Images/b2b4ae7f0067779b95a0e3593f7b4364.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2b4ae7f0067779b95a0e3593f7b4364.png)'
- en: Photo from [Deep RL BootCamp â€” UC Berkeley](https://sites.google.com/view/deep-rl-bootcamp/lectures)
    official websiteâ€” [**[SOURCE]**](https://sites.google.com/view/deep-rl-bootcamp/lectures)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª [æ·±åº¦å¼ºåŒ–å­¦ä¹ è®­ç»ƒè¥ â€” åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡](https://sites.google.com/view/deep-rl-bootcamp/lectures)
    å®˜æ–¹ç½‘ç«™çš„ç…§ç‰‡â€” [**[æ¥æº]**](https://sites.google.com/view/deep-rl-bootcamp/lectures)
- en: The Deep RL Bootcamp is an intensive two-day course on deep reinforcement learning,
    taught by leading researchers in the field. The course covers a wide range of
    topics, including value-based methods, policy gradient algorithms, model-based
    reinforcement learning, exploration and uncertainty, and deep reinforcement learning
    in the real world. It features a mix of lectures and hands-on exercises, giving
    attendees the opportunity to learn about the latest techniques and apply them
    to real-world problems. The course is designed for researchers and practitioners
    with a background in machine learning and/or reinforcement learning and is suitable
    for those looking to gain a deeper understanding of the field and advance their
    research or career in this exciting area of artificial intelligence.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦å¼ºåŒ–å­¦ä¹ è®­ç»ƒè¥æ˜¯ä¸€ä¸ªä¸ºæœŸä¸¤å¤©çš„å¯†é›†è¯¾ç¨‹ï¼Œç”±è¯¥é¢†åŸŸçš„é¢†å…ˆç ”ç©¶äººå‘˜æ•™æˆã€‚è¯¾ç¨‹æ¶µç›–äº†å¹¿æ³›çš„ä¸»é¢˜ï¼ŒåŒ…æ‹¬åŸºäºä»·å€¼çš„æ–¹æ³•ã€ç­–ç•¥æ¢¯åº¦ç®—æ³•ã€åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ã€æ¢ç´¢ä¸ä¸ç¡®å®šæ€§ï¼Œä»¥åŠæ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚è¯¾ç¨‹ç»“åˆäº†è®²åº§å’Œå®è·µç»ƒä¹ ï¼Œä¸ºå­¦å‘˜æä¾›äº†äº†è§£æœ€æ–°æŠ€æœ¯å¹¶å°†å…¶åº”ç”¨äºç°å®é—®é¢˜çš„æœºä¼šã€‚è¯¾ç¨‹æ—¨åœ¨ä¸ºå…·æœ‰æœºå™¨å­¦ä¹ å’Œ/æˆ–å¼ºåŒ–å­¦ä¹ èƒŒæ™¯çš„ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…è®¾è®¡ï¼Œé€‚åˆé‚£äº›å¸Œæœ›æ·±å…¥ç†è§£è¯¥é¢†åŸŸå¹¶åœ¨äººå·¥æ™ºèƒ½è¿™ä¸€æ¿€åŠ¨äººå¿ƒçš„é¢†åŸŸä¸­æ¨è¿›ç ”ç©¶æˆ–èŒä¸šå‘å±•çš„äººå£«ã€‚
- en: 'Link to the course:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: é“¾æ¥åˆ°è¯¾ç¨‹ï¼š
- en: '[## Deep RL Bootcamp - Lectures'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[## æ·±åº¦å¼ºåŒ–å­¦ä¹ è®­ç»ƒè¥ - è®²åº§'
- en: Lectures
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è®²åº§
- en: Lecturessites.google.com](https://sites.google.com/view/deep-rl-bootcamp/lectures?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[Lecturessites.google.com](https://sites.google.com/view/deep-rl-bootcamp/lectures?source=post_page-----ed6633608cb2--------------------------------)'
- en: '[7 - Deep Reinforcement Learning Course by HuggingFace](https://simoninithomas.github.io/deep-rl-course/)'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[7 - HuggingFace çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹](https://simoninithomas.github.io/deep-rl-course/)'
- en: '![](../Images/56ea80246a7a73b22f1213eb43627681.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56ea80246a7a73b22f1213eb43627681.png)'
- en: Photo from HuggingFace [Deep RL Course official website](https://simoninithomas.github.io/deep-rl-course/)
    by **Simon Thomas**â€” [**[SOURCE]**](https://simoninithomas.github.io/deep-rl-course/)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª HuggingFace çš„ç…§ç‰‡ [æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹å®˜æ–¹ç½‘ç«™](https://simoninithomas.github.io/deep-rl-course/)
    ç”±**è¥¿è’™Â·æ‰˜é©¬æ–¯**æä¾›â€” [**[æ¥æº]**](https://simoninithomas.github.io/deep-rl-course/)
- en: The Deep RL course by Hugging Face is an in-depth and interactive learning experience
    that covers the most important topics in deep reinforcement learning. The course
    is divided into units that cover various aspects of the field such as the Q-learning
    algorithm, policy gradients, and advanced topics like exploration, multi-agent
    RL, and meta-learning. Each unit includes a combination of video lectures, interactive
    coding tutorials, and quizzes to help learners understand and apply the concepts.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹æ˜¯ä¸€ç§æ·±å…¥ä¸”äº’åŠ¨çš„å­¦ä¹ ä½“éªŒï¼Œæ¶µç›–äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­æœ€é‡è¦çš„ä¸»é¢˜ã€‚è¯¾ç¨‹åˆ†ä¸ºå¤šä¸ªå•å…ƒï¼Œæ¶‰åŠè¯¥é¢†åŸŸçš„å„ä¸ªæ–¹é¢ï¼Œå¦‚ Q
    å­¦ä¹ ç®—æ³•ã€ç­–ç•¥æ¢¯åº¦ä»¥åŠæ¢ç´¢ã€å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å’Œå…ƒå­¦ä¹ ç­‰é«˜çº§ä¸»é¢˜ã€‚æ¯ä¸ªå•å…ƒåŒ…æ‹¬è§†é¢‘è®²åº§ã€äº’åŠ¨ç¼–ç æ•™ç¨‹å’Œæµ‹éªŒï¼Œå¸®åŠ©å­¦ä¹ è€…ç†è§£å’Œåº”ç”¨è¿™äº›æ¦‚å¿µã€‚
- en: The course also includes hands-on projects that allow learners to apply their
    knowledge to real-world problems. These projects include creating an RL agent
    to play a game, training an RL agent to navigate a virtual environment, and building
    an RL agent to play a game of chess. These projects provide an opportunity for
    learners to get hands-on experience working with RL models, and gain an understanding
    of the challenges and complexities of working with these models.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è¯¾ç¨‹è¿˜åŒ…æ‹¬å®è·µé¡¹ç›®ï¼Œä½¿å­¦ä¹ è€…èƒ½å¤Ÿå°†æ‰€å­¦çŸ¥è¯†åº”ç”¨äºç°å®é—®é¢˜ã€‚è¿™äº›é¡¹ç›®åŒ…æ‹¬åˆ›å»ºä¸€ä¸ª RL ä»£ç†æ¥ç©æ¸¸æˆï¼Œè®­ç»ƒä¸€ä¸ª RL ä»£ç†åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å¯¼èˆªï¼Œä»¥åŠæ„å»ºä¸€ä¸ª
    RL ä»£ç†æ¥ä¸‹æ£‹ã€‚è¿™äº›é¡¹ç›®ä¸ºå­¦ä¹ è€…æä¾›äº†åŠ¨æ‰‹æ“ä½œ RL æ¨¡å‹çš„æœºä¼šï¼Œå¹¶å¸®åŠ©ä»–ä»¬ç†è§£ä½¿ç”¨è¿™äº›æ¨¡å‹çš„æŒ‘æˆ˜å’Œå¤æ‚æ€§ã€‚
- en: The course also includes explanations of the theoretical foundations of RL,
    providing an understanding of the mathematical concepts and algorithms used in
    the field. The course is designed to be accessible to people with different backgrounds
    and levels of experience, from those new to the field to experienced practitioners.
    The course is taught by Simon Thomas, who is a researcher and expert in the field
    of deep reinforcement learning, and the course content is regularly updated to
    keep up with the latest advancements in the field.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è¯¾ç¨‹è¿˜åŒ…æ‹¬äº†å¼ºåŒ–å­¦ä¹ çš„ç†è®ºåŸºç¡€çš„è®²è§£ï¼Œæä¾›äº†å¯¹æ•°å­¦æ¦‚å¿µå’Œç®—æ³•çš„ç†è§£ã€‚è¯¾ç¨‹æ—¨åœ¨å¯¹ä¸åŒèƒŒæ™¯å’Œç»éªŒæ°´å¹³çš„äººç¾¤å¼€æ”¾ï¼Œä»åˆå­¦è€…åˆ°ç»éªŒä¸°å¯Œçš„ä»ä¸šè€…ã€‚è¯¾ç¨‹ç”±æ·±åº¦å¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„ç ”ç©¶å‘˜å’Œä¸“å®¶Simon
    Thomasè®²æˆï¼Œè¯¾ç¨‹å†…å®¹ä¼šå®šæœŸæ›´æ–°ï¼Œä»¥è·Ÿä¸Šé¢†åŸŸçš„æœ€æ–°è¿›å±•ã€‚
- en: 'Links to the course:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¾ç¨‹é“¾æ¥ï¼š
- en: '[](https://simoninithomas.github.io/deep-rl-course/?source=post_page-----ed6633608cb2--------------------------------)
    [## Deep Reinforcement Learning Course'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[Simoninithomas.github.io](https://simoninithomas.github.io/deep-rl-course/?source=post_page-----ed6633608cb2--------------------------------)
    [## æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹'
- en: Deep Reinforcement Learning Course is a free course about Deep Reinforcement
    Learning from beginner to expert.
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹æ˜¯ä¸€ä¸ªå…è´¹çš„è¯¾ç¨‹ï¼Œå†…å®¹æ¶µç›–ä»åˆå­¦è€…åˆ°ä¸“å®¶çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚
- en: simoninithomas.github.io](https://simoninithomas.github.io/deep-rl-course/?source=post_page-----ed6633608cb2--------------------------------)
    [](https://huggingface.co/deep-rl-course/unit0/introduction?source=post_page-----ed6633608cb2--------------------------------)
    [## Welcome to the ğŸ¤— Deep Reinforcement Learning Course - Hugging Face Course
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[Simoninithomas.github.io](https://simoninithomas.github.io/deep-rl-course/?source=post_page-----ed6633608cb2--------------------------------)
    [Hugging Face Deep Reinforcement Learning Course](https://huggingface.co/deep-rl-course/unit0/introduction?source=post_page-----ed6633608cb2--------------------------------)
    [## æ¬¢è¿æ¥åˆ°ğŸ¤— æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ - Hugging Faceè¯¾ç¨‹'
- en: 'Welcome to the most fascinating topic in Artificial Intelligence: Deep Reinforcement
    Learning. This course will teachâ€¦'
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¬¢è¿æ¥åˆ°äººå·¥æ™ºèƒ½ä¸­æœ€è¿·äººçš„è¯é¢˜ï¼šæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‚è¿™ä¸ªè¯¾ç¨‹å°†æ•™ä½ â€¦
- en: 'huggingface.co](https://huggingface.co/deep-rl-course/unit0/introduction?source=post_page-----ed6633608cb2--------------------------------)
    [](https://github.com/huggingface/deep-rl-class?source=post_page-----ed6633608cb2--------------------------------)
    [## GitHub - huggingface/deep-rl-class: This repo contains the syllabus of the
    Hugging Face Deepâ€¦'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hugging Face Deep Reinforcement Learning Course](https://huggingface.co/deep-rl-course/unit0/introduction?source=post_page-----ed6633608cb2--------------------------------)
    [GitHub - huggingface/deep-rl-class](https://github.com/huggingface/deep-rl-class?source=post_page-----ed6633608cb2--------------------------------)
    [## GitHub - huggingface/deep-rl-classï¼šè¯¥ä»“åº“åŒ…å«äº†Hugging Faceæ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹çš„æ•™å­¦å¤§çº²â€¦'
- en: This repository contains the Deep Reinforcement Learning Course mdx files and
    notebooks. The website is hereâ€¦
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æœ¬ä»“åº“åŒ…å«äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹çš„mdxæ–‡ä»¶å’Œç¬”è®°æœ¬ã€‚ç½‘ç«™åœ¨è¿™é‡Œâ€¦
- en: github.com](https://github.com/huggingface/deep-rl-class?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[GitHub - huggingface/deep-rl-class](https://github.com/huggingface/deep-rl-class?source=post_page-----ed6633608cb2--------------------------------)'
- en: 8 - Lectures by Pieter Abbeel
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 - Pieter Abbeel çš„è®²åº§
- en: '[Pieter Abbeel](http://people.eecs.berkeley.edu/~pabbeel/) is a renowned computer
    scientist and roboticist who is currently a professor at the University of California,
    Berkeley. He is known for his research in the field of robotics, particularly
    in the areas of reinforcement learning, learning from demonstration, and robot
    manipulation. He has made notable contributions to the field of robotic grasping
    and manipulation, developing algorithms for robots to learn to grasp and manipulate
    objects using trial-and-error.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pieter Abbeel](http://people.eecs.berkeley.edu/~pabbeel/) æ˜¯ä¸€ä½è‘—åçš„è®¡ç®—æœºç§‘å­¦å®¶å’Œæœºå™¨äººä¸“å®¶ï¼Œç›®å‰åœ¨åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡æ‹…ä»»æ•™æˆã€‚ä»–ä»¥åœ¨æœºå™¨äººé¢†åŸŸçš„ç ”ç©¶è€Œé—»åï¼Œç‰¹åˆ«æ˜¯åœ¨å¼ºåŒ–å­¦ä¹ ã€ä»ç¤ºèŒƒå­¦ä¹ å’Œæœºå™¨äººæ“æ§æ–¹é¢ã€‚ä»–åœ¨æœºå™¨äººæŠ“å–å’Œæ“æ§é¢†åŸŸåšå‡ºäº†æ˜¾è‘—è´¡çŒ®ï¼Œå¼€å‘äº†è®©æœºå™¨äººé€šè¿‡åå¤è¯•éªŒå­¦ä¹ æŠ“å–å’Œæ“æ§ç‰©ä½“çš„ç®—æ³•ã€‚'
- en: He also has been a pioneer in the field of apprenticeship learning, which allows
    robots to learn from human demonstrations. He has published over 150 papers, many
    of which can be accessed on his personal website and also has a set of video lectures
    available on youtube. He has also been involved in the development of open-source
    software for robotics and machine learning and is the co-author of the popular
    open-source software library [OpenAI Gym](https://www.gymlibrary.dev/), which
    is widely used in the field of reinforcement learning.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–ä¹Ÿæ˜¯ apprenticeship learning é¢†åŸŸçš„å…ˆé©±ï¼Œè¿™ä½¿å¾—æœºå™¨äººå¯ä»¥ä»äººç±»ç¤ºèŒƒä¸­å­¦ä¹ ã€‚ä»–å·²å‘è¡¨äº†è¶…è¿‡150ç¯‡è®ºæ–‡ï¼Œå…¶ä¸­è®¸å¤šå¯ä»¥åœ¨ä»–çš„ä¸ªäººç½‘ç«™ä¸Šæ‰¾åˆ°ï¼Œè¿˜åœ¨YouTubeä¸Šæœ‰ä¸€ç³»åˆ—è§†é¢‘è®²åº§ã€‚ä»–è¿˜å‚ä¸äº†æœºå™¨äººå’Œæœºå™¨å­¦ä¹ å¼€æºè½¯ä»¶çš„å¼€å‘ï¼Œå¹¶ä¸”æ˜¯æµè¡Œçš„å¼€æºè½¯ä»¶åº“[OpenAI
    Gym](https://www.gymlibrary.dev/)çš„å…±åŒä½œè€…ï¼Œè¯¥åº“åœ¨å¼ºåŒ–å­¦ä¹ é¢†åŸŸè¢«å¹¿æ³›ä½¿ç”¨ã€‚
- en: His online lectures, which are available on YouTube are one of the high quality
    material available in reinforcement learning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–åœ¨YouTubeä¸Šçš„åœ¨çº¿è®²åº§æ˜¯å¼ºåŒ–å­¦ä¹ é¢†åŸŸä¸­å¯ç”¨çš„é«˜è´¨é‡èµ„æ–™ä¹‹ä¸€ã€‚
- en: '**His â€œFoundations of Deep RL â€” lecture seriesâ€ on his own YouTube channel:**'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»–çš„â€œæ·±åº¦RLåŸºç¡€â€”â€”è®²åº§ç³»åˆ—â€åœ¨ä»–è‡ªå·±çš„YouTubeé¢‘é“ä¸Šï¼š**'
- en: '**His Lectures from CS188 Artificial Intelligence UC Berkeley, Spring 2013:**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä»–çš„CS188äººå·¥æ™ºèƒ½UC Berkeleyè®²åº§ï¼Œ2013å¹´æ˜¥å­£ï¼š**'
- en: '[9 - Spinning Up in Deep RL by OpenAI](https://spinningup.openai.com/en/latest/user/introduction.html)'
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[9 - Spinning Up in Deep RL by OpenAI](https://spinningup.openai.com/en/latest/user/introduction.html)'
- en: '![](../Images/81473f1d7bd636a3a62ca8f18fabcf72.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81473f1d7bd636a3a62ca8f18fabcf72.png)'
- en: Photo from [Spinning Up in Deep RL official website](https://spinningup.openai.com/en/latest/user/introduction.html)
    by **OpenAI**â€” [**[SOURCE]**](https://spinningup.openai.com/)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡æ¥æºäº [Spinning Up in Deep RLå®˜æ–¹ç½‘é¡µ](https://spinningup.openai.com/en/latest/user/introduction.html)
    ç”±**OpenAI**æä¾›â€”â€” [**[SOURCE]**](https://spinningup.openai.com/)
- en: '[Spinning Up in Deep RL](https://spinningup.openai.com/en/latest/user/introduction.html)
    is developed and maintained by OpenAI. It is a resource for people who want to
    learn about deep reinforcement learning (RL) and how to apply it. The website
    provides a comprehensive introduction to RL and its algorithms and includes tutorials
    and guides on how to implement and run RL experiments. The website also includes
    a set of resources such as papers, videos, and code examples to help users learn
    about RL.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[Spinning Up in Deep RL](https://spinningup.openai.com/en/latest/user/introduction.html)
    æ˜¯ç”±OpenAIå¼€å‘å’Œç»´æŠ¤çš„èµ„æºã€‚å®ƒæ˜¯ä¸€ä¸ªæ—¨åœ¨å­¦ä¹ æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åŠå…¶åº”ç”¨çš„èµ„æºã€‚è¯¥ç½‘ç«™æä¾›äº†å¯¹RLåŠå…¶ç®—æ³•çš„å…¨é¢ä»‹ç»ï¼Œå¹¶åŒ…æ‹¬æœ‰å…³å¦‚ä½•å®æ–½å’Œè¿è¡ŒRLå®éªŒçš„æ•™ç¨‹å’ŒæŒ‡å—ã€‚ç½‘ç«™è¿˜åŒ…æ‹¬ä¸€äº›èµ„æºï¼Œå¦‚è®ºæ–‡ã€è§†é¢‘å’Œä»£ç ç¤ºä¾‹ï¼Œä»¥å¸®åŠ©ç”¨æˆ·äº†è§£RLã€‚'
- en: The website is based on the software library OpenAI Baselines, which is an implementation
    of RL algorithms in Python with PyTorch and TensorFlow. The library includes implementations
    of popular RL algorithms such as DQN, PPO, A2C, and TRPO. The website provides
    detailed instructions and code examples on how to use the library to train RL
    agents and run experiments.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç½‘ç«™åŸºäºOpenAI Baselinesè½¯ä»¶åº“ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨Pythonå®ç°çš„RLç®—æ³•åº“ï¼Œæ”¯æŒPyTorchå’ŒTensorFlowã€‚è¯¥åº“åŒ…æ‹¬äº†DQNã€PPOã€A2Cå’ŒTRPOç­‰æµè¡Œçš„RLç®—æ³•å®ç°ã€‚ç½‘ç«™æä¾›äº†å¦‚ä½•ä½¿ç”¨è¯¥åº“æ¥è®­ç»ƒRLæ™ºèƒ½ä½“å’Œè¿è¡Œå®éªŒçš„è¯¦ç»†è¯´æ˜å’Œä»£ç ç¤ºä¾‹ã€‚
- en: The website is designed to be accessible to people with different levels of
    experience and provides a step-by-step guide to getting started with RL. The website
    is divided into sections, including an introduction to RL, tutorials on how to
    use the library, and a section on advanced topics such as multi-agent RL, exploration,
    and meta-learning. The website also provides a set of Jupyter notebooks that users
    can run and modify, allowing them to experiment with different RL algorithms and
    environments.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ç½‘ç«™æ—¨åœ¨é€‚åˆä¸åŒç»éªŒæ°´å¹³çš„äººï¼Œå¹¶æä¾›äº†é€æ­¥æŒ‡å—ä»¥å¼€å§‹å­¦ä¹ RLã€‚ç½‘ç«™åˆ†ä¸ºå¤šä¸ªéƒ¨åˆ†ï¼ŒåŒ…æ‹¬RLä»‹ç»ã€å¦‚ä½•ä½¿ç”¨åº“çš„æ•™ç¨‹ä»¥åŠå…³äºé«˜çº§ä¸»é¢˜å¦‚å¤šæ™ºèƒ½ä½“RLã€æ¢ç´¢å’Œå…ƒå­¦ä¹ çš„éƒ¨åˆ†ã€‚ç½‘ç«™è¿˜æä¾›äº†ä¸€ç»„Jupyterç¬”è®°æœ¬ï¼Œç”¨æˆ·å¯ä»¥è¿è¡Œå’Œä¿®æ”¹è¿™äº›ç¬”è®°æœ¬ï¼Œä»è€Œå®éªŒä¸åŒçš„RLç®—æ³•å’Œç¯å¢ƒã€‚
- en: 'The link to the website:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘ç«™é“¾æ¥ï¼š
- en: '[](https://spinningup.openai.com/en/latest/index.html?source=post_page-----ed6633608cb2--------------------------------)
    [## Welcome to Spinning Up in Deep RL! - Spinning Up documentation'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://spinningup.openai.com/en/latest/index.html?source=post_page-----ed6633608cb2--------------------------------)
    [## æ¬¢è¿æ¥åˆ°Spinning Up in Deep RLï¼ - Spinning Upæ–‡æ¡£'
- en: Edit description
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¼–è¾‘æè¿°
- en: spinningup.openai.com](https://spinningup.openai.com/en/latest/index.html?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[spinningup.openai.com](https://spinningup.openai.com/en/latest/index.html?source=post_page-----ed6633608cb2--------------------------------)'
- en: 10 - Phil Taborâ€™s RL Courses
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 - Phil Taborçš„RLè¯¾ç¨‹
- en: Phil Tabor is a machine learning engineer and educator who specializes in the
    field of reinforcement learning. He is known for his practical approach to teaching
    and has a special focus on the hands-on aspect of the field. He has created several
    courses on machine learning and artificial intelligence on Udemy, with a focus
    on reinforcement learning. He also has a YouTube channel [â€œMachine Learning with
    Philâ€](https://www.youtube.com/@MachineLearningwithPhil) where he uploads videos
    on various reinforcement learning topics such as Q-learning, policy gradients,
    and more advanced topics. He also uploads code-along videos to help learners understand
    the concept and apply them.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Phil Tabor æ˜¯ä¸€ä½æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œæ•™è‚²è€…ï¼Œä¸“æ³¨äºå¼ºåŒ–å­¦ä¹ é¢†åŸŸã€‚ä»–ä»¥å®é™…çš„æ•™å­¦æ–¹æ³•è€Œé—»åï¼Œç‰¹åˆ«æ³¨é‡è¯¥é¢†åŸŸçš„åŠ¨æ‰‹å®è·µã€‚ä»–åœ¨ Udemy ä¸Šåˆ›å»ºäº†å¤šä¸ªå…³äºæœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„è¯¾ç¨‹ï¼Œé‡ç‚¹æ˜¯å¼ºåŒ–å­¦ä¹ ã€‚ä»–è¿˜æ‹¥æœ‰ä¸€ä¸ª
    YouTube é¢‘é“ [â€œMachine Learning with Philâ€](https://www.youtube.com/@MachineLearningwithPhil)ï¼Œåœ¨è¿™ä¸ªé¢‘é“ä¸Šä»–ä¸Šä¼ äº†å…³äºå„ç§å¼ºåŒ–å­¦ä¹ ä¸»é¢˜çš„è§†é¢‘ï¼Œå¦‚
    Q å­¦ä¹ ã€ç­–ç•¥æ¢¯åº¦ä»¥åŠæ›´å¤šé«˜çº§ä¸»é¢˜ã€‚ä»–è¿˜ä¸Šä¼ äº†ä»£ç è·Ÿéšè§†é¢‘ï¼Œå¸®åŠ©å­¦ä¹ è€…ç†è§£æ¦‚å¿µå¹¶åº”ç”¨å®ƒä»¬ã€‚
- en: His more practical approach to the field makes it rather much different than
    other available content. Aside from his paid courses on Udemy which are very comprehensive
    and well-framed, he has tons of free content on his [YouTube channel](https://www.youtube.com/@MachineLearningwithPhil)
    which are not much less than his paid ones.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ä»–å¯¹è¯¥é¢†åŸŸçš„å®è·µæ€§æ–¹æ³•ä½¿å…¶ä¸å…¶ä»–ç°æœ‰å†…å®¹å¤§ç›¸å¾„åº­ã€‚é™¤äº†åœ¨ Udemy ä¸Šçš„ä»˜è´¹è¯¾ç¨‹å¤–ï¼Œä»–è¿˜åœ¨ [YouTube é¢‘é“](https://www.youtube.com/@MachineLearningwithPhil)
    ä¸Šæä¾›äº†å¤§é‡å…è´¹å†…å®¹ï¼Œè¿™äº›å†…å®¹ä¸ä»˜è´¹è¯¾ç¨‹çš„è´¨é‡ç›¸å·®æ— å‡ ã€‚
- en: '**Youtube channel:** [https://www.youtube.com/@MachineLearningwithPhil](https://www.youtube.com/@MachineLearningwithPhil)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**YouTube é¢‘é“ï¼š** [https://www.youtube.com/@MachineLearningwithPhil](https://www.youtube.com/@MachineLearningwithPhil)'
- en: '**Udemy:** [https://www.udemy.com/user/phil-tabor/](https://www.udemy.com/user/phil-tabor/)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**Udemy:** [https://www.udemy.com/user/phil-tabor/](https://www.udemy.com/user/phil-tabor/)'
- en: Books
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¹¦ç±
- en: 'There are tons of great books published about reinforcement learning however
    5 of the most popular and comprehensive ones are listed below:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºå¼ºåŒ–å­¦ä¹ å·²ç»å‡ºç‰ˆäº†å¤§é‡ä¼˜ç§€ä¹¦ç±ï¼Œä½†ä»¥ä¸‹æ˜¯äº”æœ¬æœ€å—æ¬¢è¿å’Œæœ€å…¨é¢çš„ä¹¦ç±ï¼š
- en: '[1\. Richard Sutton and Andrew Barto, â€œ**Reinforcement Learning: An Introductionâ€**
    (2nd Edition)](http://incompleteideas.net/book/RLbook2020.pdf) â€” Most Recommended*'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[1\. Richard Sutton å’Œ Andrew Barto, â€œ**å¼ºåŒ–å­¦ä¹ ï¼šå¯¼è®º**ï¼ˆç¬¬äºŒç‰ˆï¼‰](http://incompleteideas.net/book/RLbook2020.pdf)
    â€” æœ€æ¨è*'
- en: '[Reinforcement Learning: An Introduction](http://incompleteideas.net/book/RLbook2020.pdf)
    (2nd Edition) by Richard Sutton and Andrew Barto is a must-have resource for anyone
    interested in the field of reinforcement learning. This book provides a comprehensive
    introduction to the fundamental concepts and algorithms of reinforcement learning,
    making it an essential resource for students, researchers, and practitioners.
    The second edition includes new chapters on recent developments in the field and
    updates to existing material, making it even more current and relevant.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¼ºåŒ–å­¦ä¹ ï¼šå¯¼è®º](http://incompleteideas.net/book/RLbook2020.pdf)ï¼ˆç¬¬äºŒç‰ˆï¼‰ï¼Œç”± Richard Sutton
    å’Œ Andrew Barto ç¼–è‘—ï¼Œæ˜¯ä»»ä½•å¯¹å¼ºåŒ–å­¦ä¹ é¢†åŸŸæ„Ÿå…´è¶£çš„äººå¿…å¤‡çš„èµ„æºã€‚è¿™æœ¬ä¹¦å¯¹å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œç®—æ³•æä¾›äº†å…¨é¢çš„ä»‹ç»ï¼Œä½¿å…¶æˆä¸ºå­¦ç”Ÿã€ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…çš„åŸºæœ¬èµ„æºã€‚ç¬¬äºŒç‰ˆåŒ…æ‹¬äº†å…³äºè¯¥é¢†åŸŸæœ€è¿‘å‘å±•çš„æ–°ç« èŠ‚å’Œå¯¹ç°æœ‰ææ–™çš„æ›´æ–°ï¼Œä½¿å…¶æ›´åŠ å½“å‰å’Œç›¸å…³ã€‚'
- en: The book starts with an introduction to the basic concepts of RL and lays out
    the RL problem along with a history of the field and its relationship to other
    fields such as psychology, neuroscience, and control theory. It then delves into
    the foundational algorithms and concepts of the field, including Multiarm bandits,
    Markov decision processes, dynamic programming, and Monte Carlo methods.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ¬ä¹¦ä»å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µä»‹ç»å¼€å§‹ï¼Œæ¦‚è¿°äº†å¼ºåŒ–å­¦ä¹ é—®é¢˜ä»¥åŠè¯¥é¢†åŸŸçš„å†å²å’Œå®ƒä¸å¿ƒç†å­¦ã€ç¥ç»ç§‘å­¦å’Œæ§åˆ¶ç†è®ºç­‰å…¶ä»–é¢†åŸŸçš„å…³ç³»ã€‚ç„¶åæ·±å…¥æ¢è®¨äº†è¯¥é¢†åŸŸçš„åŸºç¡€ç®—æ³•å’Œæ¦‚å¿µï¼ŒåŒ…æ‹¬å¤šè‡‚èµŒåšæœºã€é©¬å°”ç§‘å¤«å†³ç­–è¿‡ç¨‹ã€åŠ¨æ€è§„åˆ’å’Œè’™ç‰¹å¡æ´›æ–¹æ³•ã€‚
- en: The book also covers advanced topics such as temporal-difference learning, planning
    and learning with function approximators, and exploration and exploitation in
    reinforcement learning. Additional chapters discuss the application of reinforcement
    learning in various domains, including robotics, game playing, and healthcare.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ¬ä¹¦è¿˜æ¶µç›–äº†é«˜çº§ä¸»é¢˜ï¼Œå¦‚æ—¶é—´å·®å­¦ä¹ ã€è§„åˆ’ä¸å‡½æ•°é€¼è¿‘å™¨å­¦ä¹ ï¼Œä»¥åŠå¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢ä¸åˆ©ç”¨ã€‚é™„åŠ ç« èŠ‚è®¨è®ºäº†å¼ºåŒ–å­¦ä¹ åœ¨å„ç§é¢†åŸŸçš„åº”ç”¨ï¼ŒåŒ…æ‹¬æœºå™¨äººæŠ€æœ¯ã€æ¸¸æˆç©æ³•å’ŒåŒ»ç–—ä¿å¥ã€‚
- en: The book also includes chapters on recent developments in the field such as
    deep reinforcement learning, policy gradient methods, and inverse reinforcement
    learning. The final chapters cover the challenges and future of the field, including
    safety and reliability, multi-agent reinforcement learning, and the role of reinforcement
    learning in artificial general intelligence.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ä¹¦è¿˜åŒ…æ‹¬å…³äºæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€æ”¿ç­–æ¢¯åº¦æ–¹æ³•å’Œé€†å¼ºåŒ–å­¦ä¹ ç­‰é¢†åŸŸæœ€æ–°å‘å±•çš„ç« èŠ‚ã€‚æœ€åå‡ ç« è®¨è®ºäº†è¯¥é¢†åŸŸçš„æŒ‘æˆ˜å’Œæœªæ¥ï¼ŒåŒ…æ‹¬å®‰å…¨æ€§å’Œå¯é æ€§ã€å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä»¥åŠå¼ºåŒ–å­¦ä¹ åœ¨äººå·¥é€šç”¨æ™ºèƒ½ä¸­çš„ä½œç”¨ã€‚
- en: '**Book Chapters:**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¹¦ç±ç« èŠ‚ï¼š**'
- en: The Reinforcement Learning Problem
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ é—®é¢˜
- en: Multi-arm Bandits
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¤šè‡‚èµŒåšæœº
- en: Finite Markov Decision Processes
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ‰é™é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹
- en: Dynamic Programming
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŠ¨æ€è§„åˆ’
- en: Monte Carlo Methods
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è’™ç‰¹å¡æ´›æ–¹æ³•
- en: Temporal-Difference Learning
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ—¶é—´å·®åˆ†å­¦ä¹ 
- en: Eligibility Traces
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: èµ„æ ¼è¿½è¸ª
- en: Planning and Learning with Tabular Methods
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”¨è¡¨æ ¼æ–¹æ³•è§„åˆ’å’Œå­¦ä¹ 
- en: On-policy Approximation of Action Values
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨æ”¿ç­–ä¸‹çš„è¡ŒåŠ¨ä»·å€¼è¿‘ä¼¼
- en: Off-policy Approximation of Action Values
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åœ¨æ”¿ç­–å¤–çš„è¡ŒåŠ¨ä»·å€¼è¿‘ä¼¼
- en: Policy Approximation
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ”¿ç­–è¿‘ä¼¼
- en: Psychology
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¿ƒç†å­¦
- en: Neuroscience
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç¥ç»ç§‘å­¦
- en: Applications and Case Studies
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åº”ç”¨å’Œæ¡ˆä¾‹ç ”ç©¶
- en: Prospects
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å±•æœ›
- en: '[2\. Mykel J. Kochenderfer, â€œ**Decision Making Under Uncertainty: Theory and
    Application**](https://mitpress.mit.edu/9780262029254/decision-making-under-uncertainty/)**â€**'
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[2\. Mykel J. Kochenderferï¼Œâ€œ**ä¸ç¡®å®šæ€§å†³ç­–ï¼šç†è®ºä¸åº”ç”¨**](https://mitpress.mit.edu/9780262029254/decision-making-under-uncertainty/)**â€**'
- en: '[Decision Making Under Uncertainty: Theory and Application](https://mitpress.mit.edu/9780262029254/decision-making-under-uncertainty/),
    by Mykel J. Kochenderfer, is a comprehensive guide to decision-making under uncertainty,
    with a focus on reinforcement learning. The book covers the fundamental concepts
    of decision theory, Markov decision processes, and reinforcement learning algorithms,
    providing the reader with a solid foundation in these areas.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[ä¸ç¡®å®šæ€§å†³ç­–ï¼šç†è®ºä¸åº”ç”¨](https://mitpress.mit.edu/9780262029254/decision-making-under-uncertainty/)ï¼Œç”±Mykel
    J. Kochenderferç¼–è‘—ï¼Œæ˜¯å…³äºåœ¨ä¸ç¡®å®šæ€§ä¸‹è¿›è¡Œå†³ç­–çš„å…¨é¢æŒ‡å—ï¼Œé‡ç‚¹ä»‹ç»äº†å¼ºåŒ–å­¦ä¹ ã€‚æœ¬ä¹¦æ¶µç›–äº†å†³ç­–ç†è®ºã€é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å’Œå¼ºåŒ–å­¦ä¹ ç®—æ³•çš„åŸºæœ¬æ¦‚å¿µï¼Œä¸ºè¯»è€…åœ¨è¿™äº›é¢†åŸŸæä¾›äº†åšå®çš„åŸºç¡€ã€‚'
- en: The book also delves into advanced topics such as planning under uncertainty,
    safe reinforcement learning, and the use of decision-making methods in real-world
    applications. The author explains the concepts in a clear and concise manner,
    with the help of examples and exercises to help the reader understand and apply
    the material.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ä¹¦è¿˜æ·±å…¥æ¢è®¨äº†è¯¸å¦‚ä¸ç¡®å®šæ€§è§„åˆ’ã€å®‰å…¨å¼ºåŒ–å­¦ä¹ ä»¥åŠåœ¨ç°å®åº”ç”¨ä¸­ä½¿ç”¨å†³ç­–æ–¹æ³•ç­‰é«˜çº§ä¸»é¢˜ã€‚ä½œè€…ç”¨ä¾‹å­å’Œç»ƒä¹ æ¥æ¸…æ™°è€Œç®€æ´åœ°è§£é‡Šæ¦‚å¿µï¼Œå¸®åŠ©è¯»è€…ç†è§£å’Œåº”ç”¨ææ–™ã€‚
- en: The book is intended for a broad audience, including researchers and practitioners
    in the fields of artificial intelligence, operations research, and control systems.
    Itâ€™s also suitable for advanced undergraduate and graduate students in these areas.
    The book provides a thorough introduction to the theory and application of decision-making
    under uncertainty, with a focus on reinforcement learning, making it an essential
    resource for anyone interested in this field.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ä¹¦é¢å‘å¹¿æ³›çš„å—ä¼—ï¼ŒåŒ…æ‹¬äººå·¥æ™ºèƒ½ã€è¿ç­¹å­¦å’Œæ§åˆ¶ç³»ç»Ÿé¢†åŸŸçš„ç ”ç©¶äººå‘˜å’Œå®è·µè€…ã€‚å®ƒè¿˜é€‚åˆè¿™äº›é¢†åŸŸçš„é«˜å¹´çº§æœ¬ç§‘ç”Ÿå’Œç ”ç©¶ç”Ÿã€‚æœ¬ä¹¦å…¨é¢ä»‹ç»äº†åœ¨ä¸ç¡®å®šæ€§ä¸‹è¿›è¡Œå†³ç­–çš„ç†è®ºå’Œåº”ç”¨ï¼Œç‰¹åˆ«æ˜¯å¼ºåŒ–å­¦ä¹ ï¼Œæ˜¯ä»»ä½•å¯¹è¿™ä¸€é¢†åŸŸæ„Ÿå…´è¶£çš„äººçš„é‡è¦èµ„æºã€‚
- en: '**Book Chapters:**'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¹¦ç±ç« èŠ‚ï¼š**'
- en: Introduction
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼•è¨€
- en: Probabilistic Models
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¦‚ç‡æ¨¡å‹
- en: Decision Problems
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å†³ç­–é—®é¢˜
- en: Sequential Problems
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¡ºåºé—®é¢˜
- en: Model Uncertainty
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¨¡å‹ä¸ç¡®å®šæ€§
- en: State Uncertainty
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: çŠ¶æ€ä¸ç¡®å®šæ€§
- en: Cooperative Decision Making
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆä½œå†³ç­–åˆ¶å®š
- en: Probabilistic Surveillance Video Search
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¦‚ç‡ç›‘è§†è§†é¢‘æœç´¢
- en: Dynamic Models for Speech Applications
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¯­éŸ³åº”ç”¨çš„åŠ¨æ€æ¨¡å‹
- en: Optimized Airborne Collision Avoidance
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¼˜åŒ–ç©ºä¸­ç¢°æ’è§„é¿
- en: Multi-agent Planning for Persistent Surveillance
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æŒç»­ç›‘è§†çš„å¤šæ™ºèƒ½ä½“è§„åˆ’
- en: Integrating Automation with Humans
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸äººç±»é›†æˆè‡ªåŠ¨åŒ–
- en: '[3\. Phil Winder, â€œ**Reinforcement Learning**](https://www.oreilly.com/library/view/reinforcement-learning/9781492072386/)**â€**'
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[3\. Phil Winderï¼Œâ€œ**å¼ºåŒ–å­¦ä¹ **](https://www.oreilly.com/library/view/reinforcement-learning/9781492072386/)**â€**'
- en: â€œReinforcement Learningâ€ by Phil Winder is an in-depth examination of one of
    the most exciting and rapidly growing areas of machine learning. The book provides
    a comprehensive introduction to the theory and practice of reinforcement learning,
    covering a wide range of topics that are essential for understanding and working
    with this powerful technique.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Phil Winderçš„ã€Š**å¼ºåŒ–å­¦ä¹ **ã€‹æ˜¯å¯¹æœºå™¨å­¦ä¹ é¢†åŸŸä¸­æœ€ä»¤äººå…´å¥‹å’Œå¿«é€Ÿå‘å±•çš„é¢†åŸŸä¹‹ä¸€çš„æ·±å…¥ç ”ç©¶ã€‚è¯¥ä¹¦å…¨é¢ä»‹ç»äº†å¼ºåŒ–å­¦ä¹ çš„ç†è®ºå’Œå®è·µï¼Œæ¶µç›–äº†ç†è§£å’Œä½¿ç”¨è¿™ä¸€å¼ºå¤§æŠ€æœ¯æ‰€éœ€çš„å¹¿æ³›ä¸»é¢˜ã€‚
- en: The book starts with the fundamentals of Markov decision processes, which form
    the mathematical foundation of reinforcement learning. It then delves into Q-learning,
    a popular algorithm for finding the optimal action-value function in a given environment.
    The book also covers policy gradients, a class of algorithms that allow for the
    optimization of policies directly, rather than value functions. Additionally,
    it covers the recent advancements in deep reinforcement learning and how it can
    be applied to solve complex problems.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ¬ä¹¦ä»é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹çš„åŸºæœ¬æ¦‚å¿µå¼€å§‹ï¼Œè¿™äº›æ¦‚å¿µæ„æˆäº†å¼ºåŒ–å­¦ä¹ çš„æ•°å­¦åŸºç¡€ã€‚æ¥ç€ï¼Œå®ƒæ·±å…¥æ¢è®¨äº†Qå­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºåœ¨ç»™å®šç¯å¢ƒä¸­æ‰¾åˆ°æœ€ä¼˜åŠ¨ä½œä»·å€¼å‡½æ•°çš„æµè¡Œç®—æ³•ã€‚ä¹¦ä¸­è¿˜æ¶‰åŠäº†ç­–ç•¥æ¢¯åº¦ï¼Œè¿™æ˜¯ä¸€ç±»å…è®¸ç›´æ¥ä¼˜åŒ–ç­–ç•¥è€Œä¸æ˜¯ä»·å€¼å‡½æ•°çš„ç®—æ³•ã€‚æ­¤å¤–ï¼Œè¿˜æ¶µç›–äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æœ€æ–°è¿›å±•ä»¥åŠå¦‚ä½•å°†å…¶åº”ç”¨äºè§£å†³å¤æ‚é—®é¢˜ã€‚
- en: The book also includes numerous practical examples and exercises that help readers
    apply the concepts to real-world problems. This book is ideal for machine learning
    practitioners, researchers, and students who are interested in understanding and
    working with reinforcement learning. It provides a clear and accessible introduction
    to the field, making it an essential resource for anyone looking to get started
    with reinforcement learning or deepen their understanding of this powerful technique.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æœ¬ä¹¦è¿˜åŒ…å«äº†å¤§é‡çš„å®é™…ç¤ºä¾‹å’Œç»ƒä¹ ï¼Œå¸®åŠ©è¯»è€…å°†æ¦‚å¿µåº”ç”¨äºç°å®é—®é¢˜ä¸­ã€‚è¿™æœ¬ä¹¦éå¸¸é€‚åˆæœºå™¨å­¦ä¹ ä»ä¸šè€…ã€ç ”ç©¶äººå‘˜å’Œå¸Œæœ›ç†è§£å¹¶ä»äº‹å¼ºåŒ–å­¦ä¹ çš„å­¦ç”Ÿã€‚å®ƒæä¾›äº†ä¸€ä¸ªæ¸…æ™°è€Œæ˜“äºç†è§£çš„å…¥é—¨ä»‹ç»ï¼Œä½¿å…¶æˆä¸ºä»»ä½•å¸Œæœ›å¼€å§‹å¼ºåŒ–å­¦ä¹ æˆ–æ·±åŒ–å¯¹è¿™ä¸€å¼ºå¤§æŠ€æœ¯ç†è§£çš„äººçš„é‡è¦èµ„æºã€‚
- en: '**Book Chapters:**'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¹¦ç±ç« èŠ‚ï¼š**'
- en: Why Reinforcement Learning?
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆé€‰æ‹©å¼ºåŒ–å­¦ä¹ ï¼Ÿ
- en: Markov Decision Processes, Dynamic Programming, and Monte Carlo Methods
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ã€åŠ¨æ€è§„åˆ’å’Œè’™ç‰¹å¡ç½—æ–¹æ³•
- en: Temporal-Difference Learning, Q-Learning, and n-Step Algorithms
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ—¶é—´å·®åˆ†å­¦ä¹ ã€Qå­¦ä¹ å’Œnæ­¥ç®—æ³•
- en: Deep Q-Networks
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·±åº¦Qç½‘ç»œ
- en: Policy Gradient Methods
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­–ç•¥æ¢¯åº¦æ–¹æ³•
- en: Beyond Policy Gradients
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¶…è¶Šç­–ç•¥æ¢¯åº¦
- en: Learning All Possible Policies with Entropy Methods
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç†µæ–¹æ³•å­¦ä¹ æ‰€æœ‰å¯èƒ½çš„ç­–ç•¥
- en: Improving How an Agent Learns
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ”¹å–„ä»£ç†å­¦ä¹ çš„æ–¹å¼
- en: Practical Reinforcement Learning
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®ç”¨å¼ºåŒ–å­¦ä¹ 
- en: Operational Reinforcement Learning
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ“ä½œæ€§å¼ºåŒ–å­¦ä¹ 
- en: Conclusions and the Future
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»“è®ºä¸æœªæ¥
- en: '[4\. Alexander Zai and Brandon Brown, â€œ**Deep Reinforcement Learning in Action**](https://www.manning.com/books/deep-reinforcement-learning-in-action)**â€**'
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[4\. Alexander Zaiå’ŒBrandon Brownï¼Œ**ã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ å®æˆ˜ã€‹**](https://www.manning.com/books/deep-reinforcement-learning-in-action)**'
- en: â€œDeep Reinforcement Learning in Actionâ€ by Alexander Zai and Brandon Brown is
    an in-depth guide that takes the reader through the process of building intelligent
    systems using deep reinforcement learning. The book starts by introducing the
    basic concepts and algorithms of reinforcement learning, including Q-learning
    and policy gradients. It then goes on to cover more advanced topics such as actor-critic
    methods and deep Q-networks (DQN), which are used to improve the performance of
    reinforcement learning algorithms.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Alexander Zaiå’ŒBrandon Brownçš„ã€Š**æ·±åº¦å¼ºåŒ–å­¦ä¹ å®æˆ˜**ã€‹æ˜¯ä¸€æœ¬æ·±å…¥æŒ‡å¯¼è¯»è€…ä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ æ„å»ºæ™ºèƒ½ç³»ç»Ÿçš„æŒ‡å—ã€‚è¯¥ä¹¦é¦–å…ˆä»‹ç»äº†å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œç®—æ³•ï¼ŒåŒ…æ‹¬Qå­¦ä¹ å’Œç­–ç•¥æ¢¯åº¦ã€‚éšåï¼Œä¹¦ä¸­æ¶µç›–äº†æ›´é«˜çº§çš„è¯é¢˜ï¼Œå¦‚æ¼”å‘˜-è¯„è®ºå®¶æ–¹æ³•å’Œæ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰ï¼Œè¿™äº›æ–¹æ³•ç”¨äºæé«˜å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„æ€§èƒ½ã€‚
- en: One of the key features of the book is its emphasis on hands-on examples and
    exercises. Throughout the book, the authors provide code snippets and sample projects
    that illustrate how to implement reinforcement learning algorithms in practice.
    These examples and exercises are designed to help readers understand the material
    and apply it to their own projects.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦çš„ä¸€ä¸ªå…³é”®ç‰¹ç‚¹æ˜¯å¼ºè°ƒåŠ¨æ‰‹å®ä¾‹å’Œç»ƒä¹ ã€‚åœ¨æ•´æœ¬ä¹¦ä¸­ï¼Œä½œè€…æä¾›äº†ä»£ç ç‰‡æ®µå’Œç¤ºä¾‹é¡¹ç›®ï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨å®è·µä¸­å®ç°å¼ºåŒ–å­¦ä¹ ç®—æ³•ã€‚è¿™äº›ç¤ºä¾‹å’Œç»ƒä¹ æ—¨åœ¨å¸®åŠ©è¯»è€…ç†è§£ææ–™å¹¶å°†å…¶åº”ç”¨äºè‡ªå·±çš„é¡¹ç›®ã€‚
- en: In addition to covering the fundamentals of reinforcement learning, the book
    also covers recent advances in the field such as double DQN, prioritized replay,
    and A3C. These techniques are used to improve the performance of reinforcement
    learning algorithms and make them more efficient. The book is intended for readers
    with some experience in machine learning and deep learning, but no prior experience
    with reinforcement learning is required. The authors provide a comprehensive and
    accessible introduction to the field, making it an ideal choice for both beginners
    and experienced practitioners.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†æ¶µç›–å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†å¤–ï¼Œæœ¬ä¹¦è¿˜ä»‹ç»äº†è¯¥é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œå¦‚åŒé‡ DQNã€ä¼˜å…ˆé‡æ”¾å’Œ A3Cã€‚è¿™äº›æŠ€æœ¯ç”¨äºæé«˜å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„æ€§èƒ½å¹¶ä½¿å…¶æ›´é«˜æ•ˆã€‚æœ¬ä¹¦é€‚åˆæœ‰ä¸€å®šæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç»éªŒçš„è¯»è€…ï¼Œä½†ä¸éœ€è¦æœ‰å¼ºåŒ–å­¦ä¹ çš„å…ˆå‰ç»éªŒã€‚ä½œè€…æä¾›äº†å…¨é¢ä¸”æ˜“äºç†è§£çš„é¢†åŸŸä»‹ç»ï¼Œä½¿å…¶æˆä¸ºåˆå­¦è€…å’Œæœ‰ç»éªŒçš„ä»ä¸šè€…çš„ç†æƒ³é€‰æ‹©ã€‚
- en: '**Book Chapters:**'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¹¦ç±ç« èŠ‚ï¼š**'
- en: What is reinforcement learning
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ 
- en: 'Modeling reinforcement learning problems: Markov decision processes'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ é—®é¢˜å»ºæ¨¡ï¼šé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹
- en: 'Predicting the best states and actions: Deep Q-networks'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é¢„æµ‹æœ€ä½³çŠ¶æ€å’ŒåŠ¨ä½œï¼šæ·±åº¦ Q ç½‘ç»œ
- en: 'Learning to pick the best policy: Policy gradient methods'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å­¦ä¹ é€‰æ‹©æœ€ä½³ç­–ç•¥ï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³•
- en: Tackling more complex problems with actor-critic methods
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¼”å‘˜-è¯„è®ºå®¶æ–¹æ³•è§£å†³æ›´å¤æ‚çš„é—®é¢˜
- en: 'Alternative optimization methods: Evolutionary algorithms'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ›¿ä»£ä¼˜åŒ–æ–¹æ³•ï¼šè¿›åŒ–ç®—æ³•
- en: 'Distributional DQN: Getting the full story'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†å¸ƒå¼ DQNï¼šå…¨é¢äº†è§£
- en: Curiosity-driven exploration
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŸºäºå¥½å¥‡å¿ƒçš„æ¢ç´¢
- en: Multi-agent reinforcement learning
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ 
- en: 'Interpretable reinforcement learning: Attention and relational model'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯è§£é‡Šçš„å¼ºåŒ–å­¦ä¹ ï¼šæ³¨æ„åŠ›å’Œå…³ç³»æ¨¡å‹
- en: 'conclusion: A review and roadmap'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»“è®ºï¼šå›é¡¾ä¸æœªæ¥è·¯çº¿å›¾
- en: '[5\. Maxim Lapan, â€œ**Deep Reinforcement Learning Hands-On**](https://www.packtpub.com/product/deep-reinforcement-learning-hands-on-second-edition/9781838826994)**â€**'
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[5\. Maxim Lapan, â€œ**æ·±åº¦å¼ºåŒ–å­¦ä¹ å®æˆ˜**](https://www.packtpub.com/product/deep-reinforcement-learning-hands-on-second-edition/9781838826994)**â€**'
- en: Deep Reinforcement Learning Hands-Onâ€ by Maxim Lapan is an updated edition of
    the popular guide to understanding and implementing deep reinforcement learning
    (DRL) techniques. This book is designed to provide readers with a solid understanding
    of the key concepts and techniques behind DRL and to equip them with the practical
    skills needed to build and train their own DRL models.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Maxim Lapan çš„ã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ å®æˆ˜ã€‹æ˜¯å¯¹ç†è§£å’Œå®ç°æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰æŠ€æœ¯çš„æµè¡ŒæŒ‡å—çš„æ›´æ–°ç‰ˆã€‚æœ¬ä¹¦æ—¨åœ¨ä¸ºè¯»è€…æä¾›å¯¹ DRL èƒŒåå…³é”®æ¦‚å¿µå’ŒæŠ€æœ¯çš„æ‰å®ç†è§£ï¼Œå¹¶è£…å¤‡ä»–ä»¬å»ºç«‹å’Œè®­ç»ƒè‡ªå·±çš„
    DRL æ¨¡å‹æ‰€éœ€çš„å®è·µæŠ€èƒ½ã€‚
- en: The book covers a wide range of topics, including the basics of reinforcement
    learning and its connection to neural networks, advanced DRL algorithms such as
    Q-Learning, SARSA, and DDPG, and the use of DRL in real-world applications such
    as robotics, gaming, and autonomous vehicles. Additionally, the book includes
    practical examples and hands-on exercises, allowing readers to apply the concepts
    and techniques covered in the book to real-world problems.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦æ¶µç›–äº†å¹¿æ³›çš„ä¸»é¢˜ï¼ŒåŒ…æ‹¬å¼ºåŒ–å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†åŠå…¶ä¸ç¥ç»ç½‘ç»œçš„è”ç³»ã€é«˜çº§ DRL ç®—æ³•å¦‚ Q-Learningã€SARSA å’Œ DDPGï¼Œä»¥åŠ DRL åœ¨ç°å®ä¸–ç•Œåº”ç”¨ä¸­çš„ä½¿ç”¨ï¼Œå¦‚æœºå™¨äººæŠ€æœ¯ã€æ¸¸æˆå’Œè‡ªåŠ¨é©¾é©¶æ±½è½¦ã€‚æ­¤å¤–ï¼Œæœ¬ä¹¦è¿˜åŒ…æ‹¬å®é™…ç¤ºä¾‹å’ŒåŠ¨æ‰‹ç»ƒä¹ ï¼Œè®©è¯»è€…èƒ½å¤Ÿå°†ä¹¦ä¸­æ‰€æ¶µç›–çš„æ¦‚å¿µå’ŒæŠ€æœ¯åº”ç”¨äºå®é™…é—®é¢˜ã€‚
- en: With its focus on both theory and practice, â€œDeep Reinforcement Learning Hands-Onâ€
    is the perfect guide for anyone looking to gain a deep understanding of DRL and
    start building their own DRL models.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ å®æˆ˜ã€‹ä»¥å…¶å¯¹ç†è®ºå’Œå®è·µçš„å…³æ³¨ï¼Œæ˜¯ä»»ä½•å¸Œæœ›æ·±å…¥äº†è§£ DRL å¹¶å¼€å§‹æ„å»ºè‡ªå·± DRL æ¨¡å‹çš„äººçš„å®Œç¾æŒ‡å—ã€‚
- en: '**Book Chapters:**'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä¹¦ç±ç« èŠ‚ï¼š**'
- en: What Is Reinforcement Learning?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ ï¼Ÿ
- en: OpenAI Gym
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI Gym
- en: Deep Learning with PyTorch
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ PyTorch çš„æ·±åº¦å­¦ä¹ 
- en: The Cross-Entropy Method
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº¤å‰ç†µæ–¹æ³•
- en: Tabular Learning and the Bellman Equation
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¡¨æ ¼å­¦ä¹ ä¸è´å°”æ›¼æ–¹ç¨‹
- en: Deep Q-Networks
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ·±åº¦ Q ç½‘ç»œ
- en: Higher-Level RL Libraries
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é«˜çº§å¼ºåŒ–å­¦ä¹ åº“
- en: DQN Extensions
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DQN æ‰©å±•
- en: Ways to Speed up RL
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŠ é€Ÿ RL çš„æ–¹æ³•
- en: Stocks Trading Using RL
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ RL è¿›è¡Œè‚¡ç¥¨äº¤æ˜“
- en: Policy Gradients â€” an Alternative
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç­–ç•¥æ¢¯åº¦ â€” ä¸€ç§æ›¿ä»£æ–¹æ¡ˆ
- en: The Actor-Critic Method
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ¼”å‘˜-è¯„è®ºå®¶æ–¹æ³•
- en: Asynchronous Advantage Actor-Critic
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼‚æ­¥ä¼˜åŠ¿æ¼”å‘˜-è¯„è®ºå®¶
- en: Training Chatbots with RL
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒèŠå¤©æœºå™¨äºº
- en: The TextWorld Environment
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TextWorld ç¯å¢ƒ
- en: Web Navigation
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Web Navigation
- en: Continuous Action Space
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿ç»­åŠ¨ä½œç©ºé—´
- en: RL in Robotics
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ åœ¨æœºå™¨äººæŠ€æœ¯ä¸­çš„åº”ç”¨
- en: Trust Regions â€” PPO, TRPO, ACKTR, and SAC
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¿¡ä»»åŒºåŸŸ â€” PPO, TRPO, ACKTR å’Œ SAC
- en: Black-Box Optimization in RL
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ ä¸­çš„é»‘ç®±ä¼˜åŒ–
- en: Advanced Exploration
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é«˜çº§æ¢ç´¢
- en: Beyond Model-Free â€” Imagination
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¶…è¶Šæ— æ¨¡å‹ â€” æƒ³è±¡åŠ›
- en: AlphaGo Zero
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AlphaGo Zero
- en: RL in Discrete Optimization
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ åœ¨ç¦»æ•£ä¼˜åŒ–ä¸­çš„åº”ç”¨
- en: Multi-agent RL
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ 
- en: 'Bonus: Other Useful Resources'
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é™„åŠ ï¼šå…¶ä»–æœ‰ç”¨çš„èµ„æº
- en: '[**The Best Tools for Reinforcement Learning in Python**](https://neptune.ai/blog/the-best-tools-for-reinforcement-learning-in-python)'
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[**Pythonä¸­çš„æœ€ä½³å¼ºåŒ–å­¦ä¹ å·¥å…·**](https://neptune.ai/blog/the-best-tools-for-reinforcement-learning-in-python)'
- en: This post by neptune.ai provides an overview of the popular tools and libraries
    used in RL with Python to help readers decide which tools are best suited for
    their specific use case. it covers a variety of popular RL libraries such as TensorFlow,
    PyTorch, and OpenAI Baselines, as well as other tools such as OpenAI Gym, and
    RL Toolbox. The post also covers other topics such as visualization tools, model
    management tools and experiment tracking tools which are useful for RL. The blog
    post is well-organized and easy to follow. It includes code examples and links
    to the relevant documentation for each tool, making it a useful resource for anyone
    interested in getting started with RL in Python.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç¯‡æ¥è‡ªneptune.aiçš„æ–‡ç« æ¦‚è¿°äº†åœ¨Pythonä¸­ä½¿ç”¨çš„æµè¡Œå¼ºåŒ–å­¦ä¹ å·¥å…·å’Œåº“ï¼Œå¸®åŠ©è¯»è€…å†³å®šå“ªäº›å·¥å…·æœ€é€‚åˆä»–ä»¬çš„ç‰¹å®šç”¨ä¾‹ã€‚å®ƒæ¶µç›–äº†å„ç§æµè¡Œçš„RLåº“ï¼Œå¦‚TensorFlowã€PyTorchå’ŒOpenAI
    Baselinesï¼Œä»¥åŠå…¶ä»–å·¥å…·ï¼Œå¦‚OpenAI Gymå’ŒRL Toolboxã€‚æ–‡ç« è¿˜æ¶‰åŠäº†å¦‚å¯è§†åŒ–å·¥å…·ã€æ¨¡å‹ç®¡ç†å·¥å…·å’Œå®éªŒè·Ÿè¸ªå·¥å…·ç­‰å¯¹RLæœ‰ç”¨çš„å…¶ä»–ä¸»é¢˜ã€‚åšå®¢æ–‡ç« ç»„ç»‡è‰¯å¥½ï¼Œæ˜“äºè·Ÿéšã€‚å®ƒåŒ…æ‹¬ä»£ç ç¤ºä¾‹å’Œæ¯ä¸ªå·¥å…·çš„ç›¸å…³æ–‡æ¡£é“¾æ¥ï¼Œä½¿å…¶æˆä¸ºä»»ä½•å¸Œæœ›å¼€å§‹ä½¿ç”¨Pythonè¿›è¡ŒRLçš„äººçš„æœ‰ç”¨èµ„æºã€‚
- en: '[](https://neptune.ai/blog/the-best-tools-for-reinforcement-learning-in-python?source=post_page-----ed6633608cb2--------------------------------)
    [## The Best Tools for Reinforcement Learning in Python You Actually Want to Try
    - neptune.ai'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://neptune.ai/blog/the-best-tools-for-reinforcement-learning-in-python?source=post_page-----ed6633608cb2--------------------------------)
    [## Pythonä¸­çš„æœ€ä½³å¼ºåŒ–å­¦ä¹ å·¥å…·ï¼Œä½ å®é™…æƒ³å°è¯•çš„ - neptune.ai'
- en: Nowadays, Deep Reinforcement Learning (RL) is one of the hottest topics in the
    Data Science community. The fastâ€¦
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼Œæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ˜¯æ•°æ®ç§‘å­¦ç•Œæœ€çƒ­é—¨çš„è¯é¢˜ä¹‹ä¸€ã€‚è¿™ä¸ªå¿«é€Ÿâ€¦
- en: neptune.ai](https://neptune.ai/blog/the-best-tools-for-reinforcement-learning-in-python?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: neptune.ai](https://neptune.ai/blog/the-best-tools-for-reinforcement-learning-in-python?source=post_page-----ed6633608cb2--------------------------------)
- en: '[**awesome-deep-rl**](https://github.com/kengz/awesome-deep-rl#tutorials)'
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[**awesome-deep-rl**](https://github.com/kengz/awesome-deep-rl#tutorials)'
- en: This GitHub repository is a curated list of resources for deep reinforcement
    learning (RL) and contains a comprehensive list of **papers**, **tutorials**,
    **videos**, and other resources on various topics related to deep RL, such as
    Q-learning, policy gradients, exploration, meta-learning, and more. It also includes
    links to popular RL libraries and frameworks, such as TensorFlow, PyTorch, and
    OpenAI Baselines, as well as other tools and resources that are useful for RL.
    The repository is well-organized and easy to navigate, making it a useful resource
    for anyone interested in learning about deep RL.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªGitHubä»“åº“æ˜¯ä¸€ä¸ªé’ˆå¯¹æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ç²¾é€‰èµ„æºåˆ—è¡¨ï¼ŒåŒ…å«äº†å…³äºæ·±åº¦RLçš„**è®ºæ–‡**ã€**æ•™ç¨‹**ã€**è§†é¢‘**å’Œå…¶ä»–å„ç§ä¸»é¢˜çš„èµ„æºï¼Œå¦‚Q-learningã€ç­–ç•¥æ¢¯åº¦ã€æ¢ç´¢ã€å…ƒå­¦ä¹ ç­‰ã€‚å®ƒè¿˜åŒ…æ‹¬æµè¡Œçš„RLåº“å’Œæ¡†æ¶çš„é“¾æ¥ï¼Œå¦‚TensorFlowã€PyTorchå’ŒOpenAI
    Baselinesï¼Œä»¥åŠå…¶ä»–å¯¹RLæœ‰ç”¨çš„å·¥å…·å’Œèµ„æºã€‚è¯¥ä»“åº“ç»„ç»‡è‰¯å¥½ï¼Œæ˜“äºæµè§ˆï¼Œä½¿å…¶æˆä¸ºä»»ä½•å¯¹æ·±åº¦RLæ„Ÿå…´è¶£çš„äººçš„æœ‰ç”¨èµ„æºã€‚
- en: '[](https://github.com/kengz/awesome-deep-rl?source=post_page-----ed6633608cb2--------------------------------#tutorials)
    [## GitHub - kengz/awesome-deep-rl: A curated list of awesome Deep Reinforcement
    Learning resources.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/kengz/awesome-deep-rl?source=post_page-----ed6633608cb2--------------------------------#tutorials)
    [## GitHub - kengz/awesome-deep-rl: ä¸€ä¸ªç²¾é€‰çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ èµ„æºåˆ—è¡¨ã€‚'
- en: 'A curated list of awesome Deep Reinforcement Learning resources. - GitHub -
    kengz/awesome-deep-rl: A curated list ofâ€¦'
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'è¿™æ˜¯ä¸€ä¸ªç²¾é€‰çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ èµ„æºåˆ—è¡¨ã€‚ - GitHub - kengz/awesome-deep-rl: ä¸€ä¸ªç²¾é€‰çš„â€¦'
- en: github.com](https://github.com/kengz/awesome-deep-rl?source=post_page-----ed6633608cb2--------------------------------#tutorials)
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/kengz/awesome-deep-rl?source=post_page-----ed6633608cb2--------------------------------#tutorials)
- en: '[Awesome Deep Reinforcement Learning in Finance](https://wire.insiderfinance.io/awesome-deep-reinforcement-learning-in-finance-f319f4302897)'
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[é‡‘èé¢†åŸŸçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç²¾å½©èµ„æº](https://wire.insiderfinance.io/awesome-deep-reinforcement-learning-in-finance-f319f4302897)'
- en: this article provides an overview of the use of deep reinforcement learning
    (RL) in the field of finance. The article includes a curated list of resources
    for learning more about RL in finance, including papers, videos, and tutorials.
    The article discusses the potential applications of RL in finance such as portfolio
    management, algorithmic trading, and risk management. It also highlights some
    of the challenges and limitations of using RL in finance, such as the lack of
    data and the difficulty of evaluating the performance of RL models.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æ¦‚è¿°äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨ã€‚æ–‡ç« åŒ…æ‹¬ä¸€ä¸ªç²¾å¿ƒç­–åˆ’çš„èµ„æºåˆ—è¡¨ï¼Œä¾›æ·±å…¥å­¦ä¹ é‡‘èä¸­çš„RLï¼ŒåŒ…æ‹¬è®ºæ–‡ã€è§†é¢‘å’Œæ•™ç¨‹ã€‚æ–‡ç« è®¨è®ºäº†RLåœ¨é‡‘èä¸­çš„æ½œåœ¨åº”ç”¨ï¼Œå¦‚æŠ•èµ„ç»„åˆç®¡ç†ã€ç®—æ³•äº¤æ˜“å’Œé£é™©ç®¡ç†ã€‚è¿˜çªå‡ºäº†ä¸€äº›ä½¿ç”¨RLåœ¨é‡‘èä¸­é¢ä¸´çš„æŒ‘æˆ˜å’Œå±€é™æ€§ï¼Œå¦‚æ•°æ®ä¸è¶³å’Œè¯„ä¼°RLæ¨¡å‹æ€§èƒ½çš„å›°éš¾ã€‚
- en: '[](https://wire.insiderfinance.io/awesome-deep-reinforcement-learning-in-finance-f319f4302897?source=post_page-----ed6633608cb2--------------------------------)
    [## Awesome Deep Reinforcement Learning in Finance'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[## ä»¤äººæƒŠå¹çš„é‡‘èæ·±åº¦å¼ºåŒ–å­¦ä¹ ](https://wire.insiderfinance.io/awesome-deep-reinforcement-learning-in-finance-f319f4302897?source=post_page-----ed6633608cb2--------------------------------)'
- en: A curated list of awesome deep reinforcement learning strategies & tools in
    finance
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªç²¾å¿ƒç­–åˆ’çš„é‡‘èæ·±åº¦å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¸å·¥å…·åˆ—è¡¨
- en: wire.insiderfinance.io](https://wire.insiderfinance.io/awesome-deep-reinforcement-learning-in-finance-f319f4302897?source=post_page-----ed6633608cb2--------------------------------)
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[wire.insiderfinance.io](https://wire.insiderfinance.io/awesome-deep-reinforcement-learning-in-finance-f319f4302897?source=post_page-----ed6633608cb2--------------------------------)'
- en: Refernces
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] â€” Silver, D., Huang, A., Maddison, C. *et al.* Mastering the game of Go
    with deep neural networks and tree search. *Nature* **529**, 484â€“489 (2016). [https://doi.org/10.1038/nature16961](https://doi.org/10.1038/nature16961)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] â€” Silver, D., Huang, A., Maddison, C. *et al.* åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œå’Œæ ‘æœç´¢æŒæ¡å›´æ£‹æ¸¸æˆã€‚*Nature*
    **529**, 484â€“489 (2016). [https://doi.org/10.1038/nature16961](https://doi.org/10.1038/nature16961)'
- en: '[2] â€” [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] â€” [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
