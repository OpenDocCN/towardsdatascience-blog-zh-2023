- en: Why Convolve? Understanding Convolution and Feature Extraction in Deep Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么卷积？理解卷积和深度网络中的特征提取
- en: 原文：[https://towardsdatascience.com/why-convolve-understanding-convolution-and-feature-extraction-in-deep-networks-ee45d1fdd17c](https://towardsdatascience.com/why-convolve-understanding-convolution-and-feature-extraction-in-deep-networks-ee45d1fdd17c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/why-convolve-understanding-convolution-and-feature-extraction-in-deep-networks-ee45d1fdd17c](https://towardsdatascience.com/why-convolve-understanding-convolution-and-feature-extraction-in-deep-networks-ee45d1fdd17c)
- en: '**An Explanation of 1D/2D Convolution, its Role in Feature Learning, and a
    Visualization Tool**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**1D/2D 卷积的解释、它在特征学习中的作用及一个可视化工具**'
- en: '[](https://azad-wolf.medium.com/?source=post_page-----ee45d1fdd17c--------------------------------)[![J.
    Rafid Siddiqui, PhD](../Images/02280890ed87239c75cbcbfa7c5d686c.png)](https://azad-wolf.medium.com/?source=post_page-----ee45d1fdd17c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ee45d1fdd17c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ee45d1fdd17c--------------------------------)
    [J. Rafid Siddiqui, PhD](https://azad-wolf.medium.com/?source=post_page-----ee45d1fdd17c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://azad-wolf.medium.com/?source=post_page-----ee45d1fdd17c--------------------------------)[![J.
    Rafid Siddiqui, PhD](../Images/02280890ed87239c75cbcbfa7c5d686c.png)](https://azad-wolf.medium.com/?source=post_page-----ee45d1fdd17c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ee45d1fdd17c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ee45d1fdd17c--------------------------------)
    [J. Rafid Siddiqui, PhD](https://azad-wolf.medium.com/?source=post_page-----ee45d1fdd17c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ee45d1fdd17c--------------------------------)
    ·9 min read·Feb 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ee45d1fdd17c--------------------------------)
    ·9分钟阅读·2023年2月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f66c4e50e3736ce4f33b148180814a20.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f66c4e50e3736ce4f33b148180814a20.png)'
- en: 'Figure 1: 1D/2D Convolutions and an Interactive Visualization Tool (Source:
    Author)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1: 1D/2D 卷积及交互式可视化工具（来源：作者）'
- en: It is a common practice nowadays to construct deep neural networks with a set
    of convolution layers. However, it was not always like this, earlier neural networks
    and other machine learning frameworks didn’t employ convolutions. Feature extraction
    and learning were two separate fields of study until recently. This is why it
    is important to understand how Convolution works and why it took such an important
    place in deep learning architectures. In this article we shall explore the Convolution
    thoroughly and you would be able to understand the concept more deeply with an
    interactive tool.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，构建深度神经网络时常常会用到一组卷积层。然而，早期的神经网络和其他机器学习框架并没有使用卷积。特征提取和学习曾经是两个独立的研究领域，直到最近。这就是为什么理解卷积的工作原理及其在深度学习架构中占据重要位置的原因。在这篇文章中，我们将深入探讨卷积，你将能够通过一个交互式工具更深入地理解这个概念。
- en: '**Introduction**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**引言**'
- en: Convolution is the process of changing the shape of one function by applying
    another function. It is an operation on two functions just like any other arithmetic
    operation, however it is applied on functions and not on function values. Therefore,
    it produces a third function as a result. More formally, a Convolution ***C=f(x)*g(x)***
    is an operation between a function ***f*** and a function ***g*** and is represented
    by a convolution operator *****. In terms of mathematical formulation, Convolution
    is the integral of the product of the function ***f*** with the function ***g***
    which is mirrored on the x-axis and is shifted by a time step ***t***.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是通过应用另一个函数来改变一个函数的形状的过程。这是一种对两个函数进行的操作，就像其他算术操作一样，然而它作用于函数而不是函数值。因此，它产生一个第三个函数作为结果。更正式地说，卷积
    ***C=f(x)*g(x)*** 是函数 ***f*** 和函数 ***g*** 之间的一种操作，由卷积算符 ***** 表示。在数学公式中，卷积是函数
    ***f*** 与函数 ***g*** 的乘积的积分，其中函数 ***g*** 在 x 轴上被镜像并按时间步 ***t*** 进行平移。
- en: '![](../Images/2ebc2f13944c12e590397521339b7105.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ebc2f13944c12e590397521339b7105.png)'
- en: Note that the output function is the function of ***t*** while the input function
    ***f*** is the function of ***x***. A number of timesteps are performed, — usually
    equal to the number of samples of function values of the ***f*** function. At
    each timestep, Convolution function computes the area under the curve of the function
    ***f*** by taking the function values of ***G*** as weights. The sign of ***t***
    determines the direction of the movement. For a positive value of ***t*** the
    direction of movement is towards + ∞ and for a negative value, movement is towards
    the — ∞. Intuitively, a Convolution functions provides a moving weighted average
    of the function values of ***f***.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，输出函数是***t***的函数，而输入函数***f***是***x***的函数。执行了一定数量的时间步长 —— 通常等于***f***函数值的样本数。在每个时间步长上，卷积函数通过将***G***的函数值作为权重来计算函数***f***曲线下的面积。***t***的符号决定了移动的方向。对于***t***的正值，移动方向是朝向
    + ∞，而对于负值，移动方向是朝向 — ∞。直观地说，卷积函数提供了***f***函数值的加权移动平均。
- en: The Convolution operator can also be thought of as a form of an Integral Transform.
    An Integral Transform in calculus is a type of function transform ***T*** which
    is applied on an input function ***f*** using a Kernel function ***K***.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积算子也可以被看作是一种积分变换。在微积分中，积分变换是一种将输入函数***f***与内核函数***K***结合应用的函数变换***T***。
- en: '![](../Images/93dbd558417b07162e8da63ce85ce393.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/93dbd558417b07162e8da63ce85ce393.png)'
- en: '**Convolution on Data Samples**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据样本的卷积**'
- en: The design on the Kernel function determines the output of the transform. Most
    commonly, a symmetric Kernel function is used which makes the product in the equation
    commutative. The size of the Kernel function determines the spread of the convolution.
    A large Kernel size includes more neighboring points and gives an output which
    is affected by a large number of neighbors.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 内核函数的设计决定了变换的输出。最常使用的是对称内核函数，这使得方程中的乘积具有交换性。内核函数的大小决定了卷积的扩展范围。较大的内核大小包含更多的邻近点，并且输出受大量邻居的影响。
- en: '![](../Images/1e7a0a34e3f31379afcd85cc6afd050e.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e7a0a34e3f31379afcd85cc6afd050e.png)'
- en: 'Figure 2: An example effect of a convolution operator on Random points representing
    Statistical Data (Source: Author)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：卷积算子对表示统计数据的随机点的示例效果（来源：作者）
- en: If we take an example set of Data as in figure 2 and apply a Convolution Kernel
    with a constant value of *0.25* then we obtain a normally distributed curve as
    can be seen in the figure 2\. This shows that a Convolution function with a constant
    value output, produces a normalizing curve of the Data. Now if we extend this
    concept and create a Kernel function of size 10 populated with only values 0.1,
    and apply it on the same data then we see a result as in figure 3\. As we can
    see that the result is a smoothen curve. This is due to the fact that we have
    created a moving average kernel with a window of 10 neigboring points. Each value
    in the Kernel function provided a probability weight for computing the weighted
    average at a given point.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以图2中的数据集为例，并应用一个常数值为*0.25*的卷积内核，则会得到一个如图2所示的正态分布曲线。这表明，具有常数值输出的卷积函数会产生数据的标准化曲线。现在，如果我们扩展这个概念，并创建一个大小为10、仅填充0.1值的内核函数，并将其应用于相同的数据，那么我们会看到图3中的结果。如图所示，结果是一个平滑的曲线。这是因为我们创建了一个具有10个邻近点的移动平均内核。内核函数中的每个值为计算给定点的加权平均提供了一个概率权重。
- en: '![](../Images/a7f7c0baf189592787e7d671e19580dc.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a7f7c0baf189592787e7d671e19580dc.png)'
- en: 'Figure 3: Convolution of Data points with a constant Kernel (Source: Author)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：使用常数内核的数据显示（来源：作者）
- en: These weights that we provided need not to be all same in a Kernel function.
    Infact most of the time they are not constant values. So, we can construct a Kernel
    function which gradually increases the values starting from 0–0.5 until the middle
    of the kernel and then gradually decreases back to zero. Such Kernel would produce
    a result as in figure 4\. The result shows that it did a better job at smoothing
    the data curve. This is because we have approximated a most common smoothing Kernel
    called ‘*Gaussian Kernel*’.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供的这些权重在内核函数中不必全部相同。实际上，大多数时候它们并不是常数值。因此，我们可以构造一个内核函数，该函数的值从0逐渐增加到0.5，直到内核的中间，然后逐渐减少回零。这种内核会产生图4中的结果。结果显示，它在平滑数据曲线方面做得更好。这是因为我们近似了一个最常见的平滑内核——*高斯内核*。
- en: '![](../Images/62079dfa2dc94dcee5a8a88ed5aecc3d.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/62079dfa2dc94dcee5a8a88ed5aecc3d.png)'
- en: 'Figure 4: Effect of a Gaussian Convolution Kernel on Data points (Source: Author)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：高斯卷积核对数据点的影响（来源：作者）
- en: So far you have seen the effect of Convolution as a smoothing operator, however,
    as you shall see in the later sections, the application of a Convolution operator
    is not limited to smoothing. Convolution is a general operator which can be modified
    to do many different forms of computations performed on the function values. The
    effect that one can create from a Convolution operation depends entirely on the
    construction of the kernel function.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经看到卷积作为平滑操作的效果，然而，正如你将在后续章节中看到的，卷积操作的应用不仅限于平滑。卷积是一个通用操作符，可以被修改来执行对函数值进行多种不同形式的计算。通过卷积操作可以创建的效果完全取决于卷积核函数的构造。
- en: '**1D Convolution**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**一维卷积**'
- en: In the previous section, we discussed the Convolution and its effects on the
    data. The examples we used were of 1D data. In this section, we extend it and
    show how Convolution behaves for various 1D signals. Application of Convolution
    on 1D signals is the most obvious application and it is infact where the concept
    has originated. A 1D signal is a function of an independent variable (e.g., time)
    which is sampled to obtain a set of discrete values for a dependent variable as
    an output. A discrete sampling range is often used to observe the function. The
    sampling range gives one a viewing window showing the shape of the function within
    that range. A Convolution operation between two signals is whereby the second
    signal changes the shape of the first signal. As you may see in the figure 5 how
    one curve affects another curve and produces a third curve which combines the
    both (sort of an average — roughly speaking).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们讨论了卷积及其对数据的影响。我们使用的示例是1D数据。在本节中，我们将扩展并展示卷积在各种1D信号中的表现。卷积在1D信号上的应用是最明显的应用，实际上这就是概念的起源。1D信号是独立变量（例如时间）的函数，通过采样获得一组离散的依赖变量值作为输出。离散采样范围通常用于观察函数。采样范围提供了一个视窗，显示该范围内函数的形状。两个信号之间的卷积操作是第二个信号改变第一个信号形状的过程。正如你在图5中看到的那样，一条曲线如何影响另一条曲线并产生结合两者的第三条曲线（粗略地说类似于平均）。
- en: '![](../Images/54818fcd28724fab349a41cd57e4a202.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54818fcd28724fab349a41cd57e4a202.png)'
- en: 'Figure 5: Depiction of a Convolution Operation (Source:Author)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：卷积操作的描述（来源：作者）
- en: In this case the Convolution happened between two similar functions. The convolving
    function only had difference in amplitude and its phase was shifted. However,
    it may not be the case in general. Convolution function can take various different
    forms and can produce different results accordingly. Some examples of such Convolution
    kernel functions and their effect on various different functions are shown in
    figure 6\. You may see the ‘averaging effect’ on square wave when it is Convolved
    with either a sinewave or a DC kernel. In case of two opposite phases, the waves
    do not cancel each other as opposed to destructive interference of two waves,
    rather an average output of two phases is obtained. When employed on a complex
    signal made up of multiple simple sine, cosine waves and noise components, the
    convolved signal is smooth and helps in reduction of noise. Smoothing is the most
    common effect of a Convolution operation; however, kernel function can be used
    to highlight, differentiate or suppress various segments of a function as well.
    We shall see how this can be useful in the later section.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，卷积发生在两个相似的函数之间。卷积函数仅在幅度上有所不同，其相位已被移动。然而，通常情况可能并非如此。卷积函数可以采取各种不同的形式，并产生不同的结果。图6中展示了一些卷积核函数及其对不同函数的影响。你可以看到，当方波与正弦波或直流核卷积时，‘平均效果’。在两个相位相反的情况下，波并不会像两波的破坏性干涉那样相互抵消，而是得到两个相位的平均输出。当应用于由多个简单的正弦、余弦波和噪声组件组成的复杂信号时，卷积信号会变得平滑，有助于减少噪声。平滑是卷积操作最常见的效果；然而，卷积核函数也可以用来突出、区分或抑制函数的不同部分。我们将在后续章节中看到这些如何发挥作用。
- en: '![](../Images/0fa34839a528eeac20b7b5b834e05e81.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fa34839a528eeac20b7b5b834e05e81.png)'
- en: 'Figure 6: Results of 1D Convolutions, First Row: Effects on a Square Wave Signal,
    Second Row: Effect on interaction of various forms of Sinosoidal waves (Source:
    Author)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：一维卷积的结果，第一行：对方波信号的影响，第二行：各种正弦波相互作用的影响（来源：作者）
- en: '**2D Convolution**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**二维卷积**'
- en: A 2D Convolution is just an extension of a 1D Convolution with an added dimension.
    The operation is performed not only in one dimension but is done in both directions.
    An image is an example of a 2D function and its values (i.e., R,G,B) represent
    a set of discrete samples of the function obtained as a result of quantization.
    These samples are arranged in a set of 2D matrices whereby each matrix represent
    a color Channel. The Kernel function for such data structure is also a 2D matrix
    and a set of kernel matrices are called a *filter*. The convolution operation
    is performed iteratively by moving a sliding window on the image across all color
    channels and a respective kernel is applied.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 2D卷积只是1D卷积的扩展，增加了一个维度。操作不仅在一个维度上进行，而是在两个方向上进行。图像是2D函数的一个例子，其值（即R、G、B）表示经过量化得到的函数离散样本。这些样本排列在一组2D矩阵中，每个矩阵代表一个颜色通道。这样的数据结构的内核函数也是一个2D矩阵，一组内核矩阵称为*滤波器*。卷积操作通过在所有颜色通道上移动滑动窗口迭代执行，并应用相应的内核。
- en: '![](../Images/3dfafce96b00919cee119e4713a49ed6.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dfafce96b00919cee119e4713a49ed6.png)'
- en: 'Figure 7: Depiction of a 2D Convolution process (Source: Author)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：2D卷积过程的描述（来源：作者）
- en: In figure 7 you can see the process of a 2D Convolution when applied on an image.
    For each pixel, a neighborhood window, equivalent to the size of the kernel is
    extracted. A set of zero padding pixels are inserted, in case it is a pixel at
    the boundary of an image. A dot product of the neighborhood window and the kernel
    matrix gives the pixel value for the respective position in the new convolved
    image. It can be seen from the figure that the convolved image has higher values
    in the diagonal of the viewing window. This is what a kernel of this kind does
    to an image. It is an example of an edge detector which finds diagonal edges in
    the image. The same process is repeated for each pixel in the image by sliding
    the kernel across all the image and obtaining a new convolved image of the same
    size. Notice we haven’t flipped the kernel matrix; it is because this kernel is
    symmetric. In the case of a non-symmetric kernel construction, flipping/mirroring
    is needed before taking the dot-product.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在图7中，你可以看到2D卷积应用于图像的过程。对于每个像素，提取一个与内核大小相同的邻域窗口。若像素在图像边界上，则插入一组零填充像素。邻域窗口和内核矩阵的点积给出新卷积图像中相应位置的像素值。从图中可以看到，卷积图像在视窗对角线上具有更高的值。这就是这种类型的内核对图像所做的。它是一个边缘检测器的示例，能够找到图像中的对角边缘。对图像中的每个像素重复相同的过程，通过在图像上滑动内核并获得相同大小的新卷积图像。注意我们没有翻转内核矩阵；这是因为该内核是对称的。如果内核构造为非对称，则在计算点积之前需要翻转/镜像。
- en: '![](../Images/9b1241a6c2d8cc6f6daef8c5a4880397.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b1241a6c2d8cc6f6daef8c5a4880397.png)'
- en: 'Figure 8: An example application of Convolution Operation, First Row: Image
    Blurring, Second Row: Edge Detection (Source:Author)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：卷积操作的示例应用，第一行：图像模糊，第二行：边缘检测（来源：作者）
- en: As it was mentioned earlier, Convolution process is not limited to a particular
    operation but it can be used to do various different kinds of operations. In figure
    8 we show two example applications of a Convolution operation. When an image is
    convolved with a Gaussian kernel it produces a blurring effect on the image. However,
    when an edge detection kernel, such as the one we showed earlier is applied, it
    produces an output image which only highlights the edges in the image. Kernel
    coefficients determine the output of the image. These coefficients can be hand-crafted
    or can be learned through a learning framework.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，卷积过程不仅限于某一特定操作，它可以用于执行各种不同类型的操作。在图8中，我们展示了卷积操作的两个示例应用。当图像与高斯内核卷积时，会产生模糊效果。然而，当应用边缘检测内核（例如我们之前展示的那种）时，会生成一个仅突出图像边缘的输出图像。内核系数决定了图像的输出。这些系数可以是手工制作的，也可以通过学习框架学习得到。
- en: '**Feature Learning with 2D Convolution**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**2D卷积的特征学习**'
- en: In the previous section, we saw how 2D convolution works for images. In this
    section we shall explore how one can utilize this to extract features. A feature
    in image processing is an invariant pattern of pixels which can describe an object.
    A set of features extracted from an image of an object can be used to uniquely
    identify the object. Convolution Kernels provide a robust way to construct features
    because they are batch operation machines. A range of operations that would otherwise
    be required for extraction of features (e.g., a set of edges), require only one
    matrix multiplication and a sum operation. This reduces computation cost and provides
    a general framework for extracting features by constructing and applying a large
    variety of feature kernels. In the figure 9, there are four edge detection kernels
    shown, each specialized in detecting a certain edge orientation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们看到2D卷积如何应用于图像。在这一节中，我们将探讨如何利用卷积提取特征。图像处理中的特征是描述物体的像素不变模式。可以从物体图像中提取的一组特征可以用来唯一地识别该物体。卷积核提供了一种稳健的特征构建方式，因为它们是批量操作的机器。否则需要的特征提取操作（例如，一组边缘）只需一次矩阵乘法和一个加法操作。这降低了计算成本，并提供了一个通用的特征提取框架，通过构建和应用各种特征核。在图9中，显示了四个边缘检测核，每个核专门用于检测某种边缘方向。
- en: '![](../Images/08a29eaa14f09ebbd76451b352148a6a.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08a29eaa14f09ebbd76451b352148a6a.png)'
- en: 'Figure 9: An example of a Feature Extraction Process on a 2D color image (Source:
    Author)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：2D彩色图像上的特征提取过程示例（来源：作者）
- en: The sliding window shown determines the size of a feature. A number of features
    can be extracted from the image depending on the stride of a sliding window. A
    small window with a unit-pixel stride provides a set of local features while a
    small of number of larger windows construct a global feature space.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 显示的滑动窗口决定了特征的大小。根据滑动窗口的步幅，可以从图像中提取出多个特征。一个具有单位像素步幅的小窗口提供一组局部特征，而少量较大的窗口构建全局特征空间。
- en: In a deep neural network (e.g., a CNN), it is controlled by specifying a number
    of features learned at each layer. Also a deep network learns the parameters of
    the kernels as part of the overall parameter learning. So, there is no need to
    hand-construct the features however, conceptually, the learned features are same
    to what has been described earlier. For example, instead of constructing a crude
    hand-crafted kernel for vertical edges which are usually not so frequent in real-world
    images, it can learn a non-linear Kernel which can find the curvature of an object.
    The features learned at the convolution layers provide a basis for a set of fully
    connected classification layers in the later part of a deep neural network.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度神经网络（例如CNN）中，它通过指定每层学习到的特征数量来控制。此外，深度网络将卷积核的参数学习作为整体参数学习的一部分。因此，无需手动构建特征，然而，从概念上讲，学习到的特征与之前描述的特征是相同的。例如，代替为垂直边缘构造粗糙的手工制作的核（这些在现实世界的图像中通常不那么频繁），它可以学习一个非线性核，这可以找到物体的曲率。在卷积层学习到的特征为深度神经网络后续部分的一组全连接分类层提供了基础。
- en: '**Final Remarks**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**最终说明**'
- en: In this article, we have explored the concept of Convolution, its various types
    and discussed how it can be used to extract features from images. Convolution
    is a general-purpose computation mechanism. It can leverage the power of GPU processing
    due to its coherence with the GPU architecture. Computations can be split into
    batches and can be performed independently. Feature learning using Convolution
    provides a robust and automatic extraction of features from images which deep
    neural networks employ. In-fact, feature learning is perhaps the most crucial
    part of an object classification deep convolutional neural network. Learned kernels
    capture the complex patterns better and Features learned are more diverse.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们探讨了卷积的概念、其各种类型，并讨论了如何利用卷积从图像中提取特征。卷积是一种通用计算机制。由于与GPU架构的兼容性，它可以利用GPU处理的强大能力。计算可以被拆分成批次并独立执行。利用卷积进行特征学习可以提供对图像中特征的稳健和自动化提取，这正是深度神经网络所采用的。实际上，特征学习可能是物体分类深度卷积神经网络中最关键的部分。学习到的核更好地捕捉复杂的模式，并且学习到的特征更加多样。
- en: You can improve the understanding of the concept and practice further with a
    visualization tool that you can find from the below link.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过下面链接找到的可视化工具来进一步提高对概念的理解和实践。
- en: '![](../Images/9afa14e8a5945f686b9cdffe1d86f0c7.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9afa14e8a5945f686b9cdffe1d86f0c7.png)'
- en: 'Figure 10: Visualization Tool for 2D Convolution (Source: Author)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：2D 卷积的可视化工具（来源：作者）
- en: '**Code:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**代码：**'
- en: '[https://www.github.com/azad-academy/DL-Convolutions](https://www.github.com/azad-academy/DL-Convolutions)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.github.com/azad-academy/DL-Convolutions](https://www.github.com/azad-academy/DL-Convolutions)'
- en: '**Become a Patreon Supporter:**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**成为 Patreon 支持者：**'
- en: '[https://www.patreon.com/azadacademy](https://www.patreon.com/azadacademy)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.patreon.com/azadacademy](https://www.patreon.com/azadacademy)'
- en: '**Find me on Substack:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**在 Substack 上找到我：**'
- en: '[https://azadwolf.substack.com](https://azadwolf.substack.com)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://azadwolf.substack.com](https://azadwolf.substack.com)'
- en: '**Follow Twitter for Updates:**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**关注 Twitter 获取更新：**'
- en: '[https://twitter.com/azaditech](https://twitter.com/azaditech)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://twitter.com/azaditech](https://twitter.com/azaditech)'
- en: '**Get the Book:**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**获取书籍：**'
- en: '[https://www.amazon.com/dp/B0BT4YBZQC](https://www.amazon.com/dp/B0BT4YBZQC)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.amazon.com/dp/B0BT4YBZQC](https://www.amazon.com/dp/B0BT4YBZQC)'
