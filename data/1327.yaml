- en: 4 Autonomous AI Agents you need to know
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 ä¸ªä½ éœ€è¦äº†è§£çš„è‡ªä¸» AI ä»£ç†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/4-autonomous-ai-agents-you-need-to-know-d612a643fa92?source=collection_archive---------0-----------------------#2023-04-16](https://towardsdatascience.com/4-autonomous-ai-agents-you-need-to-know-d612a643fa92?source=collection_archive---------0-----------------------#2023-04-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/4-autonomous-ai-agents-you-need-to-know-d612a643fa92?source=collection_archive---------0-----------------------#2023-04-16](https://towardsdatascience.com/4-autonomous-ai-agents-you-need-to-know-d612a643fa92?source=collection_archive---------0-----------------------#2023-04-16)
- en: â€œWestworldâ€ simulation, Camel, BabyAGI, AutoGPT â­ with the power of LangChain
    â­
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: â€œWestworldâ€ æ¨¡æ‹Ÿå™¨ã€Camelã€BabyAGIã€AutoGPT â­ å…·å¤‡ LangChain â­ çš„åŠ›é‡
- en: '[](https://sophiamyang.medium.com/?source=post_page-----d612a643fa92--------------------------------)[![Sophia
    Yang, Ph.D.](../Images/c133f918245ea4857dc46df3a07fc2b1.png)](https://sophiamyang.medium.com/?source=post_page-----d612a643fa92--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d612a643fa92--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d612a643fa92--------------------------------)
    [Sophia Yang, Ph.D.](https://sophiamyang.medium.com/?source=post_page-----d612a643fa92--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://sophiamyang.medium.com/?source=post_page-----d612a643fa92--------------------------------)[![Sophia
    Yang, Ph.D.](../Images/c133f918245ea4857dc46df3a07fc2b1.png)](https://sophiamyang.medium.com/?source=post_page-----d612a643fa92--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d612a643fa92--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d612a643fa92--------------------------------)
    [Sophia Yang, Ph.D.](https://sophiamyang.medium.com/?source=post_page-----d612a643fa92--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae9cae9cbcd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-autonomous-ai-agents-you-need-to-know-d612a643fa92&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=post_page-ae9cae9cbcd2----d612a643fa92---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d612a643fa92--------------------------------)
    Â·9 min readÂ·Apr 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd612a643fa92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-autonomous-ai-agents-you-need-to-know-d612a643fa92&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=-----d612a643fa92---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fae9cae9cbcd2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-autonomous-ai-agents-you-need-to-know-d612a643fa92&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=post_page-ae9cae9cbcd2----d612a643fa92---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d612a643fa92--------------------------------)
    Â·9 min readÂ·Apr 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd612a643fa92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-autonomous-ai-agents-you-need-to-know-d612a643fa92&user=Sophia+Yang%2C+Ph.D.&userId=ae9cae9cbcd2&source=-----d612a643fa92---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd612a643fa92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-autonomous-ai-agents-you-need-to-know-d612a643fa92&source=-----d612a643fa92---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd612a643fa92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-autonomous-ai-agents-you-need-to-know-d612a643fa92&source=-----d612a643fa92---------------------bookmark_footer-----------)'
- en: Autonomous AI agents have been the hottest topic. Itâ€™s truly impressive how
    rapidly things have progressed and unfolded in this area. Are autonomous AI agents
    the future, particularly in the area of prompt engineering? AI experts including
    Andrej Karpathy referred to AutoGPTs as the *Next frontier of prompt engineering.*
    I think so as well. What do you think?
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªä¸» AI ä»£ç†å·²ç»æˆä¸ºæœ€çƒ­é—¨çš„è¯é¢˜ã€‚ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯è¿™ä¸€é¢†åŸŸçš„è¿›å±•å¦‚æ­¤è¿…é€Ÿã€‚è‡ªä¸» AI ä»£ç†æ˜¯å¦æ˜¯æœªæ¥ï¼Œç‰¹åˆ«æ˜¯åœ¨æç¤ºå·¥ç¨‹é¢†åŸŸï¼ŸåŒ…æ‹¬ Andrej Karpathy
    åœ¨å†…çš„ AI ä¸“å®¶ç§° AutoGPTs ä¸º*æç¤ºå·¥ç¨‹çš„ä¸‹ä¸€å‰æ²¿*ã€‚æˆ‘ä¹Ÿæ˜¯è¿™æ ·è®¤ä¸ºçš„ã€‚ä½ æ€ä¹ˆçœ‹ï¼Ÿ
- en: 'In the simplest form, Autonomous AI agents run on a loop to generate self-directed
    instructions and actions at each iteration. As a result, they do not rely on humans
    to guide their conversations, and they are highly scalable. There are at least
    4 notable Autonomous AI agents projects that came out in the last two weeks, and
    in this article, we are going to dive into each of them:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ€ç®€å•çš„å½¢å¼ä¸­ï¼Œè‡ªä¸»AIä»£ç†ä»¥å¾ªç¯çš„æ–¹å¼ç”Ÿæˆè‡ªæˆ‘æŒ‡å¯¼çš„æŒ‡ä»¤å’Œè¡ŒåŠ¨ã€‚å› æ­¤ï¼Œå®ƒä»¬ä¸ä¾èµ–äºäººç±»æ¥æŒ‡å¯¼å¯¹è¯ï¼Œå¹¶ä¸”å…·æœ‰å¾ˆé«˜çš„å¯æ‰©å±•æ€§ã€‚è¿‡å»ä¸¤å‘¨å†…è‡³å°‘æœ‰4ä¸ªæ˜¾è‘—çš„è‡ªä¸»AIä»£ç†é¡¹ç›®å‡ºç°ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨æ¯ä¸€ä¸ªï¼š
- en: '**â€œWestworldâ€ simulation** â€” released on Apr. 7'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**â€œè¥¿éƒ¨ä¸–ç•Œâ€æ¨¡æ‹Ÿ** â€” å‘å¸ƒäº4æœˆ7æ—¥'
- en: '**Camel** â€” released on Mar. 21'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Camel** â€” å‘å¸ƒäº3æœˆ21æ—¥'
- en: '**BabyAGI** â€” released on Apr. 3'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BabyAGI** â€” å‘å¸ƒäº4æœˆ3æ—¥'
- en: '**AutoGPT** â€” released on Mar. 30'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AutoGPT** â€” å‘å¸ƒäº3æœˆ30æ—¥'
- en: 'Project 1: â€œWestworldâ€ simulation'
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¡¹ç›®1ï¼šâ€œè¥¿éƒ¨ä¸–ç•Œâ€æ¨¡æ‹Ÿ
- en: '![](../Images/deee0bd4d160e8d03875b5a9f2445515.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/deee0bd4d160e8d03875b5a9f2445515.png)'
- en: 'Figure 1\. Generative agents create believable simulacra of human behavior.
    Source: [https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1\. ç”Ÿæˆä»£ç†åˆ›å»ºå¯ä¿¡çš„äººç±»è¡Œä¸ºæ¨¡æ‹Ÿã€‚æ¥æºï¼š[https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)
- en: 'Researchers from Stanford and Google created an interactive sandbox environment
    with 25 generative AI agents that can simulate human behavior. They walk in the
    park, join for coffee at a cafe, and share news with colleagues. They demonstrated
    surprisingly good social behaviors:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ªæ–¯å¦ç¦å¤§å­¦å’Œè°·æ­Œçš„ç ”ç©¶äººå‘˜åˆ›å»ºäº†ä¸€ä¸ªäº’åŠ¨æ²™ç›’ç¯å¢ƒï¼Œå…¶ä¸­åŒ…å«25ä¸ªç”ŸæˆAIä»£ç†ï¼Œè¿™äº›ä»£ç†å¯ä»¥æ¨¡æ‹Ÿäººç±»è¡Œä¸ºã€‚ä»–ä»¬åœ¨å…¬å›­æ•£æ­¥ï¼Œåœ¨å’–å•¡é¦†å–å’–å•¡ï¼Œå’ŒåŒäº‹åˆ†äº«æ–°é—»ã€‚ä»–ä»¬å±•ç¤ºäº†ä»¤äººæƒŠè®¶çš„è‰¯å¥½ç¤¾äº¤è¡Œä¸ºï¼š
- en: '*â€œFor example, starting with only a single user-specified notion that one agent
    wants to throw a Valentineâ€™s Day party, the agents autonomously spread invitations
    to the party over the next two days, make new acquaintances, ask each other out
    on dates to the party, and coordinate to show up for the party together at the
    right time.â€*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*â€œä¾‹å¦‚ï¼Œä»ä¸€ä¸ªä»£ç†æƒ³è¦ä¸¾åŠæƒ…äººèŠ‚æ´¾å¯¹çš„å•ä¸€ç”¨æˆ·æŒ‡å®šæ¦‚å¿µå¼€å§‹ï¼Œä»£ç†ä»¬åœ¨æ¥ä¸‹æ¥çš„ä¸¤å¤©é‡Œè‡ªä¸»åœ°å‘æ´¾å¯¹å‘é€é‚€è¯·ï¼Œç»“è¯†æ–°æœ‹å‹ï¼Œäº’ç›¸é‚€è¯·å‚åŠ æ´¾å¯¹ï¼Œå¹¶åè°ƒåœ¨åˆé€‚çš„æ—¶é—´ä¸€èµ·åˆ°åœºã€‚â€*'
- en: 'These believable simulations of human behavior are possible because of an **agent
    architecture** (see Figure 2) that extends a large language model with three important
    architecture basics: memory, reflection, and planning.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¯ä¿¡çš„äººç±»è¡Œä¸ºæ¨¡æ‹Ÿä¹‹æ‰€ä»¥å¯èƒ½ï¼Œæ˜¯å› ä¸ºæœ‰ä¸€ä¸ª**ä»£ç†æ¶æ„**ï¼ˆè§å›¾2ï¼‰ï¼Œå®ƒæ‰©å±•äº†ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶åŒ…æ‹¬ä¸‰ä¸ªé‡è¦çš„æ¶æ„åŸºç¡€ï¼šè®°å¿†ã€åæ€å’Œè§„åˆ’ã€‚
- en: '![](../Images/362b538fa816834ab387594f806c8ae7.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/362b538fa816834ab387594f806c8ae7.png)'
- en: 'Figure 2\. Generative agent architecture. Source: [https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾2\. ç”Ÿæˆä»£ç†æ¶æ„ã€‚æ¥æºï¼š[https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)
- en: '**1) Memory and Retrieval**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**1) è®°å¿†ä¸æ£€ç´¢**'
- en: The memory stream contains a list of observations for each agent with timestamps.
    Observations can be behaviors performed by the agent or behaviors that the agent
    perceives from others. The memory stream is long. However, not all observations
    in the memory stream are important.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è®°å¿†æµåŒ…å«æ¯ä¸ªä»£ç†çš„è§‚å¯Ÿåˆ—è¡¨åŠæ—¶é—´æˆ³ã€‚è§‚å¯Ÿå¯ä»¥æ˜¯ä»£ç†æ‰§è¡Œçš„è¡Œä¸ºæˆ–ä»£ç†ä»å…¶ä»–äººé‚£é‡Œæ„ŸçŸ¥åˆ°çš„è¡Œä¸ºã€‚è®°å¿†æµå¾ˆé•¿ï¼Œä½†è®°å¿†æµä¸­çš„æ‰€æœ‰è§‚å¯Ÿéƒ½ä¸ä¸€å®šé‡è¦ã€‚
- en: 'To retrieve the most important memory to pass on to the language model, there
    are three factors to consider:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ£€ç´¢æœ€é‡è¦çš„è®°å¿†ä»¥ä¼ é€’ç»™è¯­è¨€æ¨¡å‹ï¼Œéœ€è¦è€ƒè™‘ä¸‰ä¸ªå› ç´ ï¼š
- en: '**Recency**: recent memories are more important'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è¿‘æœŸæ€§**ï¼šè¿‘æœŸè®°å¿†æ›´ä¸ºé‡è¦'
- en: '**Importance**: memories the agent believes to be important. For example, breaking
    up with someone is a more important memory than eating breakfast.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é‡è¦æ€§**ï¼šä»£ç†è®¤ä¸ºé‡è¦çš„è®°å¿†ã€‚ä¾‹å¦‚ï¼Œä¸æŸäººåˆ†æ‰‹çš„è®°å¿†æ¯”åƒæ—©é¤çš„è®°å¿†æ›´é‡è¦ã€‚'
- en: '**Relevance**: memories that are related to the situation, a query memory.
    For example, when discussing what to study for a chemistry test, schoolwork memories
    are more important.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç›¸å…³æ€§**ï¼šä¸æƒ…å†µç›¸å…³çš„è®°å¿†ï¼Œå³æŸ¥è¯¢è®°å¿†ã€‚ä¾‹å¦‚ï¼Œåœ¨è®¨è®ºåŒ–å­¦è€ƒè¯•çš„å­¦ä¹ å†…å®¹æ—¶ï¼Œå­¦ä¸šè®°å¿†æ›´ä¸ºé‡è¦ã€‚'
- en: '![](../Images/893c865577c687308a0cc9075cc6e738.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/893c865577c687308a0cc9075cc6e738.png)'
- en: 'Figure 3\. The memory stream comprises a large number of observations. Retrieval
    identifies a subset of these observations that should be passed to the language
    model. Source: [https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾3\. è®°å¿†æµåŒ…å«å¤§é‡è§‚å¯Ÿã€‚æ£€ç´¢è¯†åˆ«åº”ä¼ é€’ç»™è¯­è¨€æ¨¡å‹çš„è¿™äº›è§‚å¯Ÿå­é›†ã€‚æ¥æºï¼š[https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)
- en: '**2) Reflection**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**2) åæ€**'
- en: 'Reflections are high-level abstract thoughts to help agents generalize and
    make inferences. Reflections get generated periodically with the following two
    questions: â€œwhat are 3 most salient high-level questions we can answer about the
    subjects in the statements?â€, â€œWhat 5 high-level insights can you infer from the
    above statements?â€'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åæ€æ˜¯é«˜å±‚æ¬¡çš„æŠ½è±¡æ€è€ƒï¼Œå¸®åŠ©ä»£ç†è¿›è¡Œæ¦‚æ‹¬å’Œæ¨æ–­ã€‚åæ€ä¼šå®šæœŸç”Ÿæˆï¼Œå›ç­”ä»¥ä¸‹ä¸¤ä¸ªé—®é¢˜ï¼šâ€œæˆ‘ä»¬èƒ½å›ç­”å…³äºé™ˆè¿°ä¸­ä¸»é¢˜çš„ 3 ä¸ªæœ€çªå‡ºçš„é«˜å±‚æ¬¡é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿâ€ã€â€œä»ä»¥ä¸Šé™ˆè¿°ä¸­ä½ èƒ½æ¨æ–­å‡º
    5 ä¸ªé«˜å±‚æ¬¡çš„è§è§£æ˜¯ä»€ä¹ˆï¼Ÿâ€
- en: '![](../Images/a646968cfa7730b9628824572b8f41f2.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a646968cfa7730b9628824572b8f41f2.png)'
- en: 'Figure 4\. A reflection tree. Source: [https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 4\. åæ€æ ‘ã€‚æ¥æºï¼š[https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)
- en: '**3) Planning**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**3) è§„åˆ’**'
- en: Planning is important because the actions should not just be focused on in the
    moment but also over a longer time horizon so that they can be coherent and believable.
    A plan is also stored in the memory stream. Agents can create actions based on
    the plan and they can react and update the plan according to the other observations
    in the memory stream.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è§„åˆ’å¾ˆé‡è¦ï¼Œå› ä¸ºè¡ŒåŠ¨ä¸ä»…è¦å…³æ³¨å½“å‰æ—¶åˆ»ï¼Œè¿˜è¦åœ¨æ›´é•¿æ—¶é—´èŒƒå›´å†…ï¼Œä»¥ç¡®ä¿å®ƒä»¬å…·æœ‰è¿è´¯æ€§å’Œå¯ä¿¡åº¦ã€‚è®¡åˆ’ä¹Ÿä¼šè¢«å­˜å‚¨åœ¨è®°å¿†æµä¸­ã€‚ä»£ç†å¯ä»¥åŸºäºè®¡åˆ’åˆ›å»ºè¡ŒåŠ¨ï¼Œå¹¶æ ¹æ®è®°å¿†æµä¸­çš„å…¶ä»–è§‚å¯Ÿç»“æœå¯¹è®¡åˆ’è¿›è¡Œååº”å’Œæ›´æ–°ã€‚
- en: '![](../Images/63bf0c85ab8dfd5f91e8a79dd144126b.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63bf0c85ab8dfd5f91e8a79dd144126b.png)'
- en: 'Figure 5\. Valentineâ€™s Day party. Source: [https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 5\. æƒ…äººèŠ‚æ´¾å¯¹ã€‚æ¥æºï¼š[https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)
- en: The possibilities for applications of this are immense and maybe even a little
    scary. Imagine an assistant who observes and watches your every move, makes plans
    for you, and even perhaps executes plans for you. Itâ€™d automatically adjust the
    lights, brew the coffee, and reserve dinner for you before you even tell it to
    do anything.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›åº”ç”¨çš„å¯èƒ½æ€§æ˜¯å·¨å¤§çš„ï¼Œç”šè‡³å¯èƒ½æœ‰ç‚¹å“äººã€‚æƒ³è±¡ä¸€ä¸‹ä¸€ä¸ªåŠ©æ‰‹ï¼Œå®ƒè§‚å¯Ÿå¹¶ç›‘æ§ä½ çš„æ¯ä¸€ä¸ªåŠ¨ä½œï¼Œä¸ºä½ åˆ¶å®šè®¡åˆ’ï¼Œç”šè‡³å¯èƒ½ä¸ºä½ æ‰§è¡Œè®¡åˆ’ã€‚å®ƒä¼šåœ¨ä½ ç”šè‡³è¿˜æ²¡å‘Šè¯‰å®ƒåšä»€ä¹ˆä¹‹å‰ï¼Œè‡ªåŠ¨è°ƒæ•´ç¯å…‰ã€ç…®å’–å•¡ï¼Œå¹¶ä¸ºä½ é¢„å®šæ™šé¤ã€‚
- en: â­LangChain Implementationâ­
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: â­LangChain å®ç°â­
- en: â€¦Coming soonâ€¦
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: â€¦æ•¬è¯·æœŸå¾…â€¦
- en: I heard LangChain is working on this ;) Will add it once itâ€™s implemented.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¬è¯´ LangChain æ­£åœ¨å¼€å‘è¿™ä¸ª ;) å®ç°åä¼šæ·»åŠ ä¸Šã€‚
- en: 'Project 2: Camel'
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¡¹ç›® 2ï¼šéª†é©¼
- en: 'CAMEL (Communicative Agents for â€œMindâ€ Exploration of Large Scale Language
    Model Society) proposes a *role-playing* agent framework where two AI agents communicate
    with each other:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: CAMELï¼ˆæ²Ÿé€šå‹ä»£ç†ç”¨äºâ€œå¤§è„‘â€æ¢ç´¢å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ç¤¾ä¼šï¼‰æå‡ºäº†ä¸€ä¸ª*è§’è‰²æ‰®æ¼”*ä»£ç†æ¡†æ¶ï¼Œå…¶ä¸­ä¸¤ä¸ª AI ä»£ç†å½¼æ­¤äº¤æµï¼š
- en: '1) **AI user agent**: give instructions to the AI assistant with the goal of
    completing the task.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 1) **AI ç”¨æˆ·ä»£ç†**ï¼šç»™ AI åŠ©æ‰‹æŒ‡ç¤ºï¼Œä»¥å®Œæˆä»»åŠ¡ä¸ºç›®æ ‡ã€‚
- en: '2) **AI assistant agent**: follow AI userâ€™s instructions and respond with solutions
    to the task.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 2) **AI åŠ©æ‰‹ä»£ç†**ï¼šæ ¹æ® AI ç”¨æˆ·çš„æŒ‡ç¤ºæ‰§è¡Œä»»åŠ¡å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚
- en: '3) **task-specifier agent**: there is actually another agent called the task-specifier
    agent to brainstorm a specific task for the AI user and AI assistant to complete.
    This helps write a concrete task prompt without the user spending time defining
    it.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 3) **ä»»åŠ¡æŒ‡å®šä»£ç†**ï¼šå®é™…ä¸Šè¿˜æœ‰å¦ä¸€ä¸ªä»£ç†ç§°ä¸ºä»»åŠ¡æŒ‡å®šä»£ç†ï¼Œç”¨äºä¸º AI ç”¨æˆ·å’Œ AI åŠ©æ‰‹åˆ¶å®šç‰¹å®šä»»åŠ¡ã€‚è¿™æœ‰åŠ©äºå†™å‡ºå…·ä½“çš„ä»»åŠ¡æç¤ºï¼Œè€Œç”¨æˆ·æ— éœ€èŠ±æ—¶é—´å®šä¹‰å®ƒã€‚
- en: In this example (Figure 6), a human has an idea of developing a trading bot.
    The AI user is a stock trader and The AI assistant is a Python programmer. The
    **task-specific agent** first comes up with a specific task with task details
    (monitor social media sentiment and trade stock based on the sentiment analysis
    results). Then the **AI user agent** becomes the task planner, the **AI assistant
    agent** becomes the task executor, and they prompt each other in a loop until
    some termination conditions are met.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ˆå›¾ 6ï¼‰ï¼Œä¸€ä¸ªäººæœ‰ä¸€ä¸ªå¼€å‘äº¤æ˜“æœºå™¨äººçš„æƒ³æ³•ã€‚AI ç”¨æˆ·æ˜¯ä¸€ä¸ªè‚¡ç¥¨äº¤æ˜“å‘˜ï¼Œè€Œ AI åŠ©æ‰‹æ˜¯ä¸€ä¸ª Python ç¨‹åºå‘˜ã€‚**ä»»åŠ¡ç‰¹å®šä»£ç†**é¦–å…ˆæå‡ºä¸€ä¸ªå…·ä½“ä»»åŠ¡åŠä»»åŠ¡ç»†èŠ‚ï¼ˆç›‘æ§ç¤¾äº¤åª’ä½“æƒ…ç»ªå¹¶æ ¹æ®æƒ…ç»ªåˆ†æç»“æœè¿›è¡Œè‚¡ç¥¨äº¤æ˜“ï¼‰ã€‚ç„¶åï¼Œ**AI
    ç”¨æˆ·ä»£ç†**æˆä¸ºä»»åŠ¡è§„åˆ’è€…ï¼Œ**AI åŠ©æ‰‹ä»£ç†**æˆä¸ºä»»åŠ¡æ‰§è¡Œè€…ï¼Œå®ƒä»¬å¾ªç¯äº’ç›¸æç¤ºï¼Œç›´åˆ°æ»¡è¶³æŸäº›ç»ˆæ­¢æ¡ä»¶ã€‚
- en: '![](../Images/7cd368031f5bfe2eb8b066ac1652e1b5.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7cd368031f5bfe2eb8b066ac1652e1b5.png)'
- en: 'Figure 6\. Role-playing framework. Source: [https://arxiv.org/abs/2303.17760](https://arxiv.org/abs/2303.17760)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 6\. è§’è‰²æ‰®æ¼”æ¡†æ¶ã€‚æ¥æºï¼š[https://arxiv.org/abs/2303.17760](https://arxiv.org/abs/2303.17760)
- en: The essence of Camel lies in its prompt engineering, i.e., inception prompting.
    The prompts are actually carefully defined to assign roles, prevent flipping roles,
    prohibit harm and false information, and encourage consistent conversation. See
    detailed prompts in the [Camel paper](https://arxiv.org/abs/2303.17760).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Camel çš„ç²¾é«“åœ¨äºå…¶æç¤ºå·¥ç¨‹ï¼Œå³åˆå§‹æç¤ºã€‚æç¤ºå®é™…ä¸Šæ˜¯ç»è¿‡ç²¾å¿ƒå®šä¹‰çš„ï¼Œä»¥åˆ†é…è§’è‰²ã€é˜²æ­¢è§’è‰²ç¿»è½¬ã€ç¦æ­¢ä¼¤å®³å’Œè™šå‡ä¿¡æ¯ï¼Œå¹¶é¼“åŠ±ä¸€è‡´çš„å¯¹è¯ã€‚è¯·å‚è§ [Camel
    è®ºæ–‡](https://arxiv.org/abs/2303.17760) ä¸­çš„è¯¦ç»†æç¤ºã€‚
- en: â­LangChain Implementationâ­
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: â­LangChain å®ç°â­
- en: 'The [LangChain implementation](https://python.langchain.com/en/latest/use_cases/agents/camel_role_playing.html)
    used the prompts mentioned in the [Camel paper](https://arxiv.org/abs/2303.17760)
    and defined three agents: task_specify_agent, assistant_agent, and user_agent.
    It then uses a while loop to loop through the conversation between the assistant
    agent and the user agent:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[LangChain å®ç°](https://python.langchain.com/en/latest/use_cases/agents/camel_role_playing.html)
    ä½¿ç”¨äº†åœ¨ [Camel è®ºæ–‡](https://arxiv.org/abs/2303.17760) ä¸­æåˆ°çš„æç¤ºï¼Œå¹¶å®šä¹‰äº†ä¸‰ä¸ªä»£ç†ï¼štask_specify_agentã€assistant_agent
    å’Œ user_agentã€‚ç„¶åï¼Œå®ƒä½¿ç”¨ä¸€ä¸ª while å¾ªç¯æ¥éå†åŠ©æ‰‹ä»£ç†å’Œç”¨æˆ·ä»£ç†ä¹‹é—´çš„å¯¹è¯ï¼š'
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The results look quite reasonable!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœçœ‹èµ·æ¥ç›¸å½“åˆç†ï¼
- en: '![](../Images/3196d2cebee252808b1a0dd31f25e05d.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3196d2cebee252808b1a0dd31f25e05d.png)'
- en: In Camel, the AI assistantâ€™s executions are simply answers from the language
    model without actually using any tools to run the Python code. I wonder if LangChain
    has plans to integrate Camel with all the amazing LangChain tools ğŸ¤”
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Camel ä¸­ï¼ŒAI åŠ©æ‰‹çš„æ‰§è¡Œåªæ˜¯æ¥è‡ªè¯­è¨€æ¨¡å‹çš„ç­”æ¡ˆï¼Œè€Œä¸å®é™…ä½¿ç”¨ä»»ä½•å·¥å…·æ¥è¿è¡Œ Python ä»£ç ã€‚æˆ‘æƒ³çŸ¥é“ LangChain æ˜¯å¦è®¡åˆ’å°† Camel
    ä¸æ‰€æœ‰ä»¤äººæƒŠå¹çš„ LangChain å·¥å…·é›†æˆ ğŸ¤”
- en: ğŸ‹ Real-world use cases ğŸ‹
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‹ çœŸå®ä¸–ç•Œçš„åº”ç”¨æ¡ˆä¾‹ ğŸ‹
- en: Make a game
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ¶ä½œä¸€ä¸ªæ¸¸æˆ
- en: Infiltrate communication networks
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¸—é€é€šä¿¡ç½‘ç»œ
- en: 'Project 3: BabyAGI'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¡¹ç›® 3ï¼šBabyAGI
- en: 'Yohei Nakajima announced the â€œTask-driven Autonomous Agentâ€ on March 28 and
    then open-sourced the BabyAGI project on April 3\. The key feature of BabyAGI
    is just three agents: Task Execution Agent, Task Creation Agent, and Task Prioritization
    Agent.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Yohei Nakajima åœ¨ 3 æœˆ 28 æ—¥å®£å¸ƒäº†â€œä»»åŠ¡é©±åŠ¨çš„è‡ªä¸»ä»£ç†â€ï¼Œå¹¶åœ¨ 4 æœˆ 3 æ—¥å¼€æºäº† BabyAGI é¡¹ç›®ã€‚BabyAGI çš„å…³é”®ç‰¹æ€§åªæœ‰ä¸‰ä¸ªä»£ç†ï¼šä»»åŠ¡æ‰§è¡Œä»£ç†ã€ä»»åŠ¡åˆ›å»ºä»£ç†å’Œä»»åŠ¡ä¼˜å…ˆçº§ä»£ç†ã€‚
- en: 1) The **task execution agent** completes the first task from the task list
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1) **ä»»åŠ¡æ‰§è¡Œä»£ç†** å®Œæˆä»»åŠ¡åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªä»»åŠ¡
- en: 2) The **task creation agent** creates new tasks based on the objective and
    result of the previous task.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2) **ä»»åŠ¡åˆ›å»ºä»£ç†** æ ¹æ®å‰ä¸€ä¸ªä»»åŠ¡çš„ç›®æ ‡å’Œç»“æœåˆ›å»ºæ–°ä»»åŠ¡ã€‚
- en: 3) The **task prioritization agent** then reorders the tasks.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3) **ä»»åŠ¡ä¼˜å…ˆçº§ä»£ç†** ç„¶åé‡æ–°æ’åºä»»åŠ¡ã€‚
- en: And then this simple process gets repeated over and over.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œè¿™ä¸ªç®€å•çš„è¿‡ç¨‹è¢«é‡å¤äº†ä¸€éåˆä¸€éã€‚
- en: In a LangChain webinar, Yohei mentioned that designed BabyAGI in a way to emulate
    how he works. Specifically, he starts each morning by tackling the first item
    on his to-do list and then works through his tasks. If a new task arises, he simply
    adds it to his list. At the end of the day, he reevaluates and reprioritizes his
    list. This same approach was then mapped onto the agent.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ LangChain çš„ç½‘ç»œç ”è®¨ä¼šä¸Šï¼ŒYohei æåˆ°ä»–è®¾è®¡ BabyAGI çš„æ–¹å¼æ˜¯æ¨¡æ‹Ÿä»–è‡ªå·±çš„å·¥ä½œæ–¹å¼ã€‚å…·ä½“æ¥è¯´ï¼Œä»–æ¯å¤©æ—©æ™¨å¼€å§‹æ—¶å¤„ç†å¾…åŠäº‹é¡¹åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ªé¡¹ç›®ï¼Œç„¶åç»§ç»­å¤„ç†ä»–çš„ä»»åŠ¡ã€‚å¦‚æœå‡ºç°æ–°ä»»åŠ¡ï¼Œä»–ä¼šç®€å•åœ°å°†å…¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚åœ¨ä¸€å¤©ç»“æŸæ—¶ï¼Œä»–ä¼šé‡æ–°è¯„ä¼°å¹¶é‡æ–°æ’åºä»–çš„åˆ—è¡¨ã€‚è¿™ç§ç›¸åŒçš„æ–¹æ³•éšåè¢«æ˜ å°„åˆ°ä»£ç†ä¸­ã€‚
- en: '![](../Images/bb3dbaf7e49b4892b31ec0793115e396.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb3dbaf7e49b4892b31ec0793115e396.png)'
- en: Figure 7\. BabyAGI flow chart. Source:[https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)
    (funny thing that GPT-4 wrote this research paper)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 7\. BabyAGI æµç¨‹å›¾ã€‚æ¥æºï¼š[https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)
    ï¼ˆæœ‰è¶£çš„æ˜¯ GPT-4 å†™äº†è¿™ç¯‡ç ”ç©¶è®ºæ–‡ï¼‰
- en: â­BabyAGI + LangChainâ­
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: â­BabyAGI + LangChainâ­
- en: BabyAGI is easy to run within the LangChain framework. Check out the [code](https://python.langchain.com/en/latest/use_cases/agents/baby_agi.html)
    here. It basically creates a BabyAGI controller which composes of three chains
    TaskCreationChain, TaskPrioritizationChain, and ExecutionChain, and runs them
    in a (potentially-)infinite loop. With Langchain, you can define the max iterations,
    so that it doesnâ€™t run forever and spend all the money on OpenAI API.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: BabyAGI åœ¨ LangChain æ¡†æ¶å†…è¿è¡Œå¾ˆç®€å•ã€‚æŸ¥çœ‹ [ä»£ç ](https://python.langchain.com/en/latest/use_cases/agents/baby_agi.html)ã€‚å®ƒåŸºæœ¬ä¸Šåˆ›å»ºäº†ä¸€ä¸ª
    BabyAGI æ§åˆ¶å™¨ï¼Œè¯¥æ§åˆ¶å™¨ç”±ä¸‰ä¸ªé“¾ TaskCreationChainã€TaskPrioritizationChain å’Œ ExecutionChain
    ç»„æˆï¼Œå¹¶ä»¥ï¼ˆæ½œåœ¨çš„ï¼‰æ— é™å¾ªç¯è¿è¡Œã€‚é€šè¿‡ LangChainï¼Œä½ å¯ä»¥å®šä¹‰æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè¿™æ ·å®ƒå°±ä¸ä¼šæ°¸è¿œè¿è¡Œå¹¶èŠ±è´¹æ‰€æœ‰çš„é’±åœ¨ OpenAI API ä¸Šã€‚
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is the result from 2 iteration runs:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ 2 æ¬¡è¿­ä»£è¿è¡Œçš„ç»“æœï¼š
- en: '![](../Images/94af43bf8694d1d9f2461330a3b903bd.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94af43bf8694d1d9f2461330a3b903bd.png)'
- en: â­BabyAGI + LangChain Toolsâ­ = Superpower
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: â­BabyAGI + LangChain å·¥å…·â­ = è¶…èƒ½åŠ›
- en: As you can see from the example above, BabyAGI only â€œexecutesâ€ things with an
    LLM response. With the power of LangChain tools, the execution step can use various
    tools for example Google Search to actually search for information online. Here
    is an example, where the â€œexecutionâ€ uses Google Search to search for the current
    weather conditions in San Francisco.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä¸Šé¢çš„ç¤ºä¾‹æ‰€ç¤ºï¼ŒBabyAGI ä»…â€œæ‰§è¡Œâ€æ¥è‡ª LLM çš„å“åº”ã€‚å€ŸåŠ© LangChain å·¥å…·çš„å¼ºå¤§åŠŸèƒ½ï¼Œæ‰§è¡Œæ­¥éª¤å¯ä»¥ä½¿ç”¨å„ç§å·¥å…·ï¼Œä¾‹å¦‚ Google
    æœç´¢ï¼Œå®é™…åœ¨çº¿æœç´¢ä¿¡æ¯ã€‚è¿™é‡Œæ˜¯ä¸€ä¸ªä¾‹å­ï¼Œå…¶ä¸­â€œæ‰§è¡Œâ€ä½¿ç”¨ Google æœç´¢æ¥æŸ¥æ‰¾æ—§é‡‘å±±å½“å‰çš„å¤©æ°”çŠ¶å†µã€‚
- en: '![](../Images/04eeb5bcb8758ae69f8a7af0d42f7ae4.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04eeb5bcb8758ae69f8a7af0d42f7ae4.png)'
- en: The potential for applications of BabyAGI is also immense! We can just tell
    it an objective and it will execute for you. The only thing I think itâ€™s missing
    is an interface to accept user feedback. For example, before BabyAGI makes an
    appointment for me, Iâ€™d like it to check with me first. I think Yohei is actually
    working on this to allow for real-time input for the system to dynamically adjust
    task prioritization.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: BabyAGI çš„åº”ç”¨æ½œåŠ›ä¹Ÿéå¸¸å·¨å¤§ï¼æˆ‘ä»¬åªéœ€å‘Šè¯‰å®ƒä¸€ä¸ªç›®æ ‡ï¼Œå®ƒå°±ä¼šä¸ºä½ æ‰§è¡Œã€‚æˆ‘è®¤ä¸ºå®ƒå”¯ä¸€ç¼ºå°‘çš„å°±æ˜¯æ¥å—ç”¨æˆ·åé¦ˆçš„æ¥å£ã€‚ä¾‹å¦‚ï¼Œåœ¨ BabyAGI ä¸ºæˆ‘é¢„çº¦ä¹‹å‰ï¼Œæˆ‘å¸Œæœ›å®ƒèƒ½å…ˆä¸æˆ‘ç¡®è®¤ã€‚æˆ‘è®¤ä¸º
    Yohei å®é™…ä¸Šæ­£åœ¨è‡´åŠ›äºæ­¤ï¼Œä»¥ä¾¿ç³»ç»Ÿèƒ½å¤ŸåŠ¨æ€è°ƒæ•´ä»»åŠ¡ä¼˜å…ˆçº§ã€‚
- en: ğŸ‹ Real-world use cases ğŸ‹
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‹ ç°å®ä¸–ç•Œçš„åº”ç”¨æ¡ˆä¾‹ ğŸ‹
- en: 'Project 4: AutoGPT'
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¡¹ç›® 4ï¼šAutoGPT
- en: 'AutoGPT is a lot like BabyAGI combined with LangChain tools. It follows similar
    logic as BabyAGI: itâ€™s an infinite loop of generating thoughts, reasoning, generating
    plans, criticizing, planning the next action, and executing.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: AutoGPT å¾ˆåƒ BabyAGI å’Œ LangChain å·¥å…·çš„ç»“åˆä½“ã€‚å®ƒéµå¾ªä¸ BabyAGI ç±»ä¼¼çš„é€»è¾‘ï¼šç”Ÿæˆæ€æƒ³ã€æ¨ç†ã€åˆ¶å®šè®¡åˆ’ã€æ‰¹è¯„ã€è§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨å¹¶æ‰§è¡Œï¼Œæ˜¯ä¸€ä¸ªæ— é™å¾ªç¯ã€‚
- en: In the executing step, AutoGPT can execute many [commands](https://github.com/Significant-Gravitas/Auto-GPT/blob/6a93537c426759708f0e91a125587512c05f354c/autogpt/commands.py#L34-L141)
    such as Google Search, browse websites, write to files, and execute Python files.
    And it can even start and delete GPT agents?! Thatâ€™s pretty cool!
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ‰§è¡Œæ­¥éª¤ä¸­ï¼ŒAutoGPT å¯ä»¥æ‰§è¡Œè®¸å¤š [å‘½ä»¤](https://github.com/Significant-Gravitas/Auto-GPT/blob/6a93537c426759708f0e91a125587512c05f354c/autogpt/commands.py#L34-L141)ï¼Œä¾‹å¦‚
    Google æœç´¢ã€æµè§ˆç½‘ç«™ã€å†™å…¥æ–‡ä»¶å’Œæ‰§è¡Œ Python æ–‡ä»¶ã€‚å®ƒç”šè‡³å¯ä»¥å¯åŠ¨å’Œåˆ é™¤ GPT ä»£ç†ï¼Ÿï¼è¿™çœŸæ˜¯å¤ªé…·äº†ï¼
- en: 'When running AutoGPT, there are two initial inputs that will prompt you to
    enter: 1) AIâ€™s role and 2) AIâ€™s goal. Here Iâ€™m just using the given example â€”
    building a business.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œ AutoGPT æ—¶ï¼Œæœ‰ä¸¤ä¸ªåˆå§‹è¾“å…¥å°†æç¤ºä½ è¾“å…¥ï¼š1ï¼‰AI çš„è§’è‰²å’Œ 2ï¼‰AI çš„ç›®æ ‡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘åªæ˜¯ä½¿ç”¨äº†ç»™å®šçš„ç¤ºä¾‹â€”â€”å»ºç«‹ä¸€ä¸ªä¸šåŠ¡ã€‚
- en: '![](../Images/a430b307ea780f1cea72d1c0350cbe89.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a430b307ea780f1cea72d1c0350cbe89.png)'
- en: 'It was able to generate thoughts, reasoning, a plan, criticism, plan the next
    action, and execute (Google search in this case):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒèƒ½å¤Ÿç”Ÿæˆæ€æƒ³ã€æ¨ç†ã€è®¡åˆ’ã€æ‰¹è¯„ã€è§„åˆ’ä¸‹ä¸€æ­¥è¡ŒåŠ¨å¹¶æ‰§è¡Œï¼ˆåœ¨æ­¤æ¡ˆä¾‹ä¸­ä¸º Google æœç´¢ï¼‰ï¼š
- en: '![](../Images/4be08a054151f6c12b6ad250722c90b8.png)![](../Images/d0c632a8370b16c695ad5a5e2f441401.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4be08a054151f6c12b6ad250722c90b8.png)![](../Images/d0c632a8370b16c695ad5a5e2f441401.png)'
- en: One thing I really like about AutoGPT is that it allows human interaction (sort
    of). When it wants to run Google commands, it asks for authorization, so that
    you can stop the loop before spending too much money on OpenAI API tokens. Itâ€™d
    be nice though if it also allows conversation with humans for us to give better
    directions and feedback in real-time.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘éå¸¸å–œæ¬¢ AutoGPT çš„ä¸€ç‚¹æ˜¯ï¼Œå®ƒå…è®¸äººç±»äº’åŠ¨ï¼ˆæŸç§ç¨‹åº¦ä¸Šï¼‰ã€‚å½“å®ƒéœ€è¦è¿è¡Œ Google å‘½ä»¤æ—¶ï¼Œå®ƒä¼šè¯·æ±‚æˆæƒï¼Œè¿™æ ·ä½ å¯ä»¥åœ¨èŠ±è´¹è¿‡å¤š OpenAI
    API ä»£å¸ä¹‹å‰åœæ­¢å¾ªç¯ã€‚ä¸è¿‡ï¼Œå¦‚æœå®ƒè¿˜èƒ½ä¸äººç±»å¯¹è¯ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥å®æ—¶æä¾›æ›´å¥½çš„æŒ‡ç¤ºå’Œåé¦ˆï¼Œé‚£å°±æ›´å¥½äº†ã€‚
- en: â­LangChain Implementationâ­
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: â­LangChain å®ç°â­
- en: â€¦Coming soonâ€¦
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: â€¦æ•¬è¯·æœŸå¾…â€¦
- en: I heard LangChain is working on this ;) Will add it once itâ€™s implemented.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¬è¯´ LangChain æ­£åœ¨å¼€å‘è¿™ä¸€åŠŸèƒ½ ;) ä¸€æ—¦å®ç°ï¼Œå°†ä¼šæ·»åŠ è¿›æ¥ã€‚
- en: ğŸ‹ Real-world use cases ğŸ‹
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ğŸ‹ ç°å®ä¸–ç•Œçš„åº”ç”¨æ¡ˆä¾‹ ğŸ‹
- en: 'Write and execute Python code:'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¼–å†™å’Œæ‰§è¡Œ Python ä»£ç ï¼š
- en: 'More:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ›´å¤šï¼š
- en: Conclusion
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this article, we explore four prominent autonomous AI agents projects. Despite
    being in their early stages of development, they have already showcased impressive
    outcomes and potential applications. However, it is worth noting that all these
    projects come with significant limitations and risks, such as the possibility
    of an agent getting stuck in a loop, hallucination and security issues, as well
    as ethical concerns. Nevertheless, autonomous agents undoubtedly represent a promising
    field for the future, and I am excited to see further progress and advancements
    in this area.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†å››ä¸ªæ˜¾è‘—çš„è‡ªä¸» AI ä»£ç†é¡¹ç›®ã€‚å°½ç®¡è¿™äº›é¡¹ç›®è¿˜å¤„äºæ—©æœŸå¼€å‘é˜¶æ®µï¼Œä½†å®ƒä»¬å·²ç»å±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æˆæœå’Œæ½œåœ¨åº”ç”¨ã€‚ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›é¡¹ç›®éƒ½å­˜åœ¨æ˜¾è‘—çš„å±€é™æ€§å’Œé£é™©ï¼Œä¾‹å¦‚ä»£ç†å¯èƒ½é™·å…¥å¾ªç¯ã€å¹»è§‰å’Œå®‰å…¨é—®é¢˜ä»¥åŠä¼¦ç†é—®é¢˜ã€‚å°½ç®¡å¦‚æ­¤ï¼Œè‡ªä¸»ä»£ç†æ— ç–‘ä»£è¡¨äº†æœªæ¥çš„ä¸€ä¸ªæœ‰å‰é€”çš„é¢†åŸŸï¼Œæˆ‘æœŸå¾…çœ‹åˆ°è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥è¿›å±•å’Œå‘å±•ã€‚
- en: '**References:**'
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**å‚è€ƒèµ„æ–™ï¼š**'
- en: '**â€œWestworldâ€ simulation**'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**â€œè¥¿éƒ¨ä¸–ç•Œâ€æ¨¡æ‹Ÿ**'
- en: '[https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/pdf/2304.03442.pdf](https://arxiv.org/pdf/2304.03442.pdf)'
- en: '[https://reverie.herokuapp.com/arXiv_Demo/](https://reverie.herokuapp.com/arXiv_Demo/)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://reverie.herokuapp.com/arXiv_Demo/](https://reverie.herokuapp.com/arXiv_Demo/)'
- en: '**Camel**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**éª†é©¼**'
- en: '[https://www.camel-ai.org/](https://www.camel-ai.org/)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.camel-ai.org/](https://www.camel-ai.org/)'
- en: '[https://arxiv.org/abs/2303.17760](https://arxiv.org/abs/2303.17760)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/2303.17760](https://arxiv.org/abs/2303.17760)'
- en: '[https://python.langchain.com/en/latest/use_cases/agents/camel_role_playing.html](https://python.langchain.com/en/latest/use_cases/agents/camel_role_playing.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://python.langchain.com/en/latest/use_cases/agents/camel_role_playing.html](https://python.langchain.com/en/latest/use_cases/agents/camel_role_playing.html)'
- en: '**BabyAGI**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**BabyAGI**'
- en: '[https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)'
- en: '[https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/](https://yoheinakajima.com/task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications/)'
- en: '[https://python.langchain.com/en/latest/use_cases/agents/baby_agi.html](https://python.langchain.com/en/latest/use_cases/agents/baby_agi.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://python.langchain.com/en/latest/use_cases/agents/baby_agi.html](https://python.langchain.com/en/latest/use_cases/agents/baby_agi.html)'
- en: '[https://python.langchain.com/en/latest/use_cases/agents/baby_agi_with_agent.html](https://python.langchain.com/en/latest/use_cases/agents/baby_agi_with_agent.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://python.langchain.com/en/latest/use_cases/agents/baby_agi_with_agent.html](https://python.langchain.com/en/latest/use_cases/agents/baby_agi_with_agent.html)'
- en: '**AutoGPT**'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**AutoGPT**'
- en: '[https://github.com/Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)'
- en: . . .
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: . . .
- en: By [Sophia Yang](https://www.linkedin.com/in/sophiamyang/) on April 16, 2023
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ç”± [Sophia Yang](https://www.linkedin.com/in/sophiamyang/) äº2023å¹´4æœˆ16æ—¥å‘å¸ƒ
- en: Sophia Yang is a Senior Data Scientist. Connect with me on [LinkedIn](https://www.linkedin.com/in/sophiamyang/),
    [Twitter](https://twitter.com/sophiamyang), and [YouTube](https://www.youtube.com/SophiaYangDS)
    and join the DS/ML [Book Club](https://dsbookclub.github.io/) â¤ï¸
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Sophia Yang æ˜¯ä¸€ä½é«˜çº§æ•°æ®ç§‘å­¦å®¶ã€‚å¯ä»¥é€šè¿‡ [LinkedIn](https://www.linkedin.com/in/sophiamyang/)ã€[Twitter](https://twitter.com/sophiamyang)
    å’Œ [YouTube](https://www.youtube.com/SophiaYangDS) ä¸æˆ‘è”ç³»ï¼Œå¹¶åŠ å…¥ DS/ML [è¯»ä¹¦ä¿±ä¹éƒ¨](https://dsbookclub.github.io/)
    â¤ï¸
