- en: Keeping Robots from Going Off the Ethical Rails
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让机器人不偏离伦理轨道
- en: 原文：[https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13](https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13](https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13)
- en: '![](../Images/fd2fba06a7d547e47de2ec841a83e141.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd2fba06a7d547e47de2ec841a83e141.png)'
- en: Image created by author using Dall-E 2
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 Dall-E 2 创建
- en: The key to building transparent AI software systems
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建透明的 AI 软件系统的关键
- en: '[](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[![Claire
    Longo](../Images/5a04940feeba1412688b4f38ec1fe974.png)](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    [Claire Longo](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[![Claire
    Longo](../Images/5a04940feeba1412688b4f38ec1fe974.png)](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    [Claire Longo](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f6936fe85bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&user=Claire+Longo&userId=1f6936fe85bb&source=post_page-1f6936fe85bb----7dc089b53917---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    ·8 min read·Apr 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7dc089b53917&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&user=Claire+Longo&userId=1f6936fe85bb&source=-----7dc089b53917---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f6936fe85bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&user=Claire+Longo&userId=1f6936fe85bb&source=post_page-1f6936fe85bb----7dc089b53917---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    · 8 min 阅读 · 2023年4月13日'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7dc089b53917&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&source=-----7dc089b53917---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7dc089b53917&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&source=-----7dc089b53917---------------------bookmark_footer-----------)'
- en: An AI algorithm is a software system that has the ability to automate or perform
    tasks that typically require human intelligence. These systems often include more
    than just a trained model. They can also include explicit algorithm functionality,
    such as business rules, that integrate the model’s output into the larger AI system
    to complete an end-to-end task.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: AI 算法是一种具有自动化或执行通常需要人类智能的任务能力的软件系统。这些系统通常不仅仅包括一个训练好的模型。它们还可能包括明确的算法功能，例如业务规则，将模型的输出整合到更大的
    AI 系统中，以完成端到端的任务。
- en: To properly implement ethical AI systems, the software used to deploy the models
    must include the ability to measure and mitigate the live algorithm behavior from
    end-to-end. By intentionally building in methods to audit AI, we can ensure a
    good robot doesn’t go off the rails — and if it does, we’ll have the tools to
    course correct it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确实施伦理AI系统，用于部署模型的软件必须具备从端到端测量和缓解实时算法行为的能力。通过有意地构建审计AI的方法，我们可以确保好的机器人不会偏离轨道——如果发生偏离，我们将有工具来进行纠正。
- en: Ethical AI Software Infrastructure
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 伦理AI软件基础设施
- en: So what does it take to build ethics into an AI’s software infrastructure? How
    can we approach preemptively designing these systems to ensure we will have the
    ability to audit AI models for bias?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，要将伦理融入AI的软件基础设施中需要什么？我们如何预先设计这些系统以确保能够审计AI模型的偏差？
- en: A truly auditable AI system should have enough transparency that users and creators
    can answer the questions “*what data went into the model, what predictions came
    out, and what adjustments were made to it down the road before the output was
    used?”* If bias or quality issues are detected, the levers built into an ethical
    AI system can be used to mitigate any bias or correct quality the issues that
    arise.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个真正可审计的AI系统应具备足够的透明度，以便用户和创作者可以回答“*数据输入模型、预测结果、以及在输出被使用前对其进行的调整是什么？”* 如果发现偏差或质量问题，可以利用伦理AI系统中的杠杆来缓解任何偏差或纠正出现的质量问题。
- en: '![](../Images/fcab682676a67de763bf36884ed18a98.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcab682676a67de763bf36884ed18a98.png)'
- en: An auditable AI system design (diagram by author)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 可审计的AI系统设计（作者绘图）
- en: This proposed system design is a generalized infrastructure that could be adapted
    for many business use-cases relying on live AI.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 该提议的系统设计是一个通用基础设施，可适用于许多依赖实时AI的业务用例。
- en: 'This design provides core functionality that ensures the model operates in
    a responsible, ethical, and unbiased manner. It includes:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 该设计提供了核心功能，确保模型以负责任、伦理和无偏的方式运行。它包括：
- en: A **data collection system** with coverage for all system-generated data
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**数据收集系统**，覆盖所有系统生成的数据
- en: A **metric and monitoring system** to track model performance and bias in live
    models to provide both data and model ML Observability..
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**指标和监控系统**，用于跟踪模型性能和实时模型中的偏差，以提供数据和模型ML可观测性。
- en: '**Multiple levers to pull to mitigate any potential bias:** a targeted model
    retraining loop for updating the model with better data compelements a rules engine
    for programming in explicit logic such as model overrides or bias mitigation and
    a human-in-the-loop quality check system.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多个杠杆来缓解潜在的偏差：** 一个针对性的模型再训练循环，用于更新模型以获得更好的数据，补充一个用于编程明确逻辑的规则引擎，例如模型覆盖或偏差缓解，以及一个人机交互的质量检查系统。'
- en: Data Collection
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据收集
- en: 'The data required to completely audit an AI system is extensive. It includes:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 完全审计AI系统所需的数据量非常庞大。它包括：
- en: Features (the model input)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特性（模型输入）
- en: Predictions (the model output)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测（模型输出）
- en: SHAP or some representation of feature importance to provide pointwise prediction
    explainability. This allows us to trace why a specific prediction was made.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP或某种特征重要性表示，以提供逐点预测解释。这使我们能够追踪特定预测的原因。
- en: Any business logic or rules applied to augment the prediction
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何用于增强预测的业务逻辑或规则
- en: Any human decisions applied to augment the prediction
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何用于增强预测的人类决策
- en: Isolated demographic data that can be linked to predictions for monitoring bias
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以链接到预测以监控偏差的孤立人口数据
- en: 💡Notice the protected demographic data is kept isolated from the system in this
    design. This data is only used to measure model performance to detect bias. It
    should never be intermingled with model inputs as that could cause bias to be
    encoded into the model. Some core attributes to consider appear below.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 💡注意在此设计中保护的人口数据与系统隔离。这些数据仅用于测量模型性能以检测偏差，绝不应与模型输入混合，否则可能会导致偏差被编码到模型中。下面列出了一些核心属性需考虑。
- en: '![](../Images/715d1a6a48a16ba71fa4c64b4fb96f36.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/715d1a6a48a16ba71fa4c64b4fb96f36.png)'
- en: Diagram by author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作者绘图
- en: Bias Measurement and Monitoring
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差测量和监控
- en: Once that data is collected, metrics and visualizations can be used to quantify
    and monitor for bias trends in the live system. Standard fairness and bias metrics
    to consider are
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦收集了这些数据，指标和可视化工具可以用来量化和监控实时系统中的偏差趋势。需要考虑的标准公平性和偏差指标包括
- en: 'Recall Parity: measures how “sensitive” the model is for one group compared
    to another, or the model’s ability to predict true positives correctly.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召回率平衡：衡量模型对一个组与另一个组的“敏感性”或模型正确预测真实正类的能力。
- en: 'False Positive Rate Parity: measures whether a model incorrectly predicts the
    positive class for the sensitive group as compared to the base group.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性率平衡：衡量模型在敏感组相对于基础组中错误预测正类的情况。
- en: '[Disparate Impact](https://arize.com/blog-course/fairness-bias-metrics/#what-are-the-prevailing-model-fairness-metrics):
    a quantitative measure of the adverse treatment of protected classes'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[差别影响](https://arize.com/blog-course/fairness-bias-metrics/#what-are-the-prevailing-model-fairness-metrics)：对受保护类别的不利待遇的定量度量'
- en: A model may appear to perform well on average, but digging deeper it’s possible
    to look beyond the average model performance and isolate performance across demographic
    groups. Tacking the accuracy per group gives visibility into how fair the model
    is serving the population as a whole.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型可能在平均水平上表现良好，但深入挖掘可以超越平均模型表现，隔离不同人口组的表现。按组分析准确性能提供模型对整体人群服务公平性的可见性。
- en: Bias Mitigation
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏见缓解
- en: The **rules engine**, also known as a rule-based system or an expert system,
    is a type of algorithm that uses a predefined set of rules to make decisions or
    solve problems. These rules, often represented as IF-THEN statements, capture
    the domain-specific knowledge and expertise in a structured and organized manner.
    In real life AI applications, the model predictions are often fed into a rules
    engine, where business decisions are made around how to use the prediction or
    how to augment it. If bias is detected, new rules can be encoded to override it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**规则引擎**，也称为基于规则的系统或专家系统，是一种使用预定义规则集来做决策或解决问题的算法。这些规则通常以IF-THEN语句表示，以结构化和有组织的方式捕捉领域特定的知识和专业技能。在实际AI应用中，模型预测通常会被输入到规则引擎中，围绕如何使用预测或如何增强预测进行业务决策。如果检测到偏见，可以编码新的规则来覆盖它。'
- en: Many AI systems include an automated pipeline for collecting new data and retraining
    the model on the new data to update it with the freshest information. This keeps
    the model healthy and performant. This same retraining loop can be used to remove
    bias from models. The retraining data can be collected in a targeted way to focus
    on providing more data or better examples for the model to learn from on areas
    where it is failing.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 许多AI系统包括一个自动化管道，用于收集新数据并在新数据上重新训练模型，以更新最新信息。这保持了模型的健康和性能。这种相同的重新训练循环可以用于从模型中去除偏见。可以以有针对性的方式收集重新训练数据，以专注于提供更多数据或更好的示例，让模型在失败的领域学习。
- en: The **human in the loop** component provides the ability to quality check the
    AI’s output before it is used. This functionality also needs to be part of the
    software design so the human decision data can be collected, especially in use-cases
    that cannot or should not be fully automated. AI is often most effective as a
    human assistant, not a complete task automation tool. Building in infrastructure
    to support human interaction and decision making allows us humans to override
    bias or harmful patterns when they are detected.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**人类在环**组件提供了在使用AI输出之前进行质量检查的能力。此功能也需要成为软件设计的一部分，以便可以收集人类决策数据，特别是在不能或不应该完全自动化的用例中。AI通常在作为人类助手时最为有效，而不是一个完整的任务自动化工具。构建支持人类互动和决策的基础设施使我们能够在发现偏见或有害模式时进行覆盖。'
- en: Wait, What Is Bias in AI?
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 等等，AI中的偏见是什么？
- en: So how can an AI algorithm be biased, unfair, or unethical? The bias is often
    not hard coded. It’s not explicitly written by a software engineer or data scientist.
    Instead, the algorithms learn automatically from scanning large datasets. These
    AI models work to learn patterns from a large set of data, and encode those patterns
    mathematically. Those mathematical patterns are then saved as a “model” and used
    to make inferences on new data. Under this paradigm, these models can learn harmful
    and unfair patterns simply if these patterns exist in the data provided to it.
    They will then perpetuate these harmful patterns by relying on them when making
    predictions. With data available widely on the internet, even old patterns and
    historical biases could get encoded into these models if we’re not careful.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，人工智能算法如何会有偏见、不公平或不道德呢？偏见通常不是硬编码的。它不是由软件工程师或数据科学家明确编写的。相反，算法通过扫描大量数据集自动学习。这些人工智能模型旨在从大量数据中学习模式，并将这些模式以数学方式编码。这些数学模式然后被保存为“模型”，用于对新数据进行推断。在这种范式下，这些模型如果提供的数据中存在有害和不公平的模式，就可能学习到这些有害的模式。它们会在预测时依赖这些模式，从而延续这些有害模式。由于互联网上的数据广泛存在，如果不加小心，旧的模式和历史偏见也可能被编码到这些模型中。
- en: So when thinking about patterns that get encoded into AI algorithms, there are
    two kinds of patterns to consider. Explicit and implicit patterns. Explicit patterns
    are rules hard coded in. These patterns are a purposeful choice by an organization,
    and typically represented as IF-THEN statements in code. Implicit patterns are
    learned by the model from data provided to it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑编码到人工智能算法中的模式时，有两种模式需要考虑。显式模式和隐式模式。显式模式是硬编码的规则。这些模式是组织的有意选择，通常表示为代码中的IF-THEN语句。隐式模式是模型从提供给它的数据中学习到的。
- en: AI Development Lifecycle
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能开发生命周期
- en: 'To add further context to this discussion, it is helpful to break down the
    **AI project lifecycle** to understand where bias or quality issues could be introduced.
    There are two core phases of the AI project lifecycle to focus on: *Research and
    Development (R&D)*, and *Operationalization*.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步阐明这一讨论，了解**人工智能项目生命周期**的详细内容非常有帮助，以便了解可能引入偏见或质量问题的地方。人工智能项目生命周期有两个核心阶段：*研究与开发（R&D）*和*落地实施*。
- en: '![](../Images/74817d7554b18b8942c9869169d3015c.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74817d7554b18b8942c9869169d3015c.png)'
- en: Diagram by author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图示
- en: R&D Phase
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研发阶段
- en: '![](../Images/4f0990d971d52626538eb2b886107e9e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f0990d971d52626538eb2b886107e9e.png)'
- en: Image created by author using Dall-E 2
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用Dall-E 2创建的图像
- en: In the R&D phase, scientists or researchers work to create the model. They collect
    raw data, transform the data into meaningful model features, experiment and test
    various modeling approaches and parameters, and evaluate the model’s performance
    based on its ability to optimize a specific outcome of choice. During these steps,
    there are many considerations these model creators will take to prevent and test
    for bias in their model. They work to collect unbiased data and carefully measure
    model performance across protected demographics to ensure fairness. However, bias
    can still creep in. So we’ll want to be able to monitor and track this model’s
    behavior once it’s live.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在研发阶段，科学家或研究人员致力于创建模型。他们收集原始数据，将数据转换为有意义的模型特征，实验和测试各种建模方法和参数，并根据优化特定结果的能力评估模型的性能。在这些步骤中，模型创建者会考虑许多因素来防止和测试模型中的偏见。他们努力收集无偏见的数据，并仔细测量模型在受保护人群中的表现，以确保公平。然而，偏见仍然可能渗入。因此，我们需要能够监控和跟踪模型上线后的行为。
- en: Operationalization Phase
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 落地实施阶段
- en: '![](../Images/264f54138a0dcdd82639ea77d4bb8134.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/264f54138a0dcdd82639ea77d4bb8134.png)'
- en: Image created by author using Dall-E 2
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用Dall-E 2创建的图像
- en: Once the model is created and we have our good robot, the project will move
    into the next phase — where said good robot is operationalized. That’s where the
    engineers come in. This phase of development focuses on transforming the chosen
    model into a practical and functional system that produces predictions from the
    model that an end-user can access and rely on and use live. This process involves
    constructing software systems that integrate the model’s core functionality and
    adhere to best practices for production code, ensuring the system is scalable
    and maintainable. This is whereethical AI by design comes in. This system can
    be designed to not only produce predictions from the model, but to also safeguard
    these algorithms if designed with ethical AI in mind.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型创建完成，我们拥有了优良的机器人，项目将进入下一阶段——即将该优良机器人投入实际操作。这就是工程师的工作所在。这一开发阶段专注于将选定的模型转化为一个实用且功能齐全的系统，使最终用户可以访问、依赖并实时使用模型生成的预测。这个过程包括构建集成模型核心功能的软件系统，并遵循生产代码的最佳实践，确保系统具有可扩展性和可维护性。这是设计伦理人工智能的关键环节。该系统不仅可以基于模型生成预测，还可以在设计时考虑伦理人工智能来保护这些算法。
- en: An [auditable AI system](https://arize.com/blog-course/transparent-ethical-ai-software-systems/)
    collects data from the model itself as well as the patterns around explicit decisions
    regarding how the model’s output is used. This allows for a holistic view of the
    algorithm’s behavior and facilitates monitoring the system as a whole.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[可审计的人工智能系统](https://arize.com/blog-course/transparent-ethical-ai-software-systems/)从模型本身以及与模型输出使用相关的明确决策模式中收集数据。这使得能够全面了解算法的行为，并促进对整个系统的监控。'
- en: This algorithmic transparency should be at the forefront of the design of any
    AI system from the beginning of the design. This means that the ability to measure
    and mitigate bias needs to be baked into the software, and not an afterthought.
    If an algorithm with potential bias is deployed without these mechanisms in place,
    it will be difficult to detect and correct any harmful patterns.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 算法透明度应当在任何人工智能系统设计的最前沿。这意味着衡量和减轻偏见的能力需要融入软件中，而不是事后的考虑。如果部署的算法存在潜在的偏见而没有这些机制，将很难检测和纠正任何有害的模式。
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: It’s likely many AI systems will need to be audited at some point, whether it’s
    for bias, or simply interpretability or quality. It’s possible to get ahead of
    this by thoughtfully designing infrastructure that provides enough visibility
    into the data, and opportunity for algorithm improvements. Let’s keep those robots
    from going off the rails.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能许多人工智能系统在某个时点需要被审计，无论是为了偏见，还是仅仅为了可解释性或质量。通过深思熟虑地设计提供足够数据可见性和算法改进机会的基础设施，可以提前应对这个问题。让我们保持这些机器人不偏离轨道。
- en: 'For deeper reading on this subject, here are a few of my favorite books and
    resources on ethical AI:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个主题的深入阅读，以下是我最喜欢的一些关于伦理人工智能的书籍和资源：
- en: '[A Summary and Review of the Ethical Algorithm](https://hackernoon.com/a-summary-and-review-of-the-ethical-algorithm)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[伦理算法的总结与评论](https://hackernoon.com/a-summary-and-review-of-the-ethical-algorithm)'
- en: '[Invisible Women: Data Bias In a World Designed for Men](https://carolinecriadoperez.com/book/invisible-women/)
    by Caroline Criado Perez'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[隐形女性：一个为男性设计的世界中的数据偏见](https://carolinecriadoperez.com/book/invisible-women/)
    由**卡罗琳·克里亚多-佩雷斯**撰写'
- en: '[Weapons of Math Destruction](https://www.penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil/)
    by Cathy O’Neil'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数学毁灭武器](https://www.penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil/)
    由**凯西·奥尼尔**撰写'
- en: '[Ethical Machines: Your Concise Guide To Totally Unbiased, Transparent and
    Respectful AI](https://www.reidblackman.com/ethical-machines/) by Reid Blackman'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[伦理机器：完全无偏见、透明且尊重的人工智能简明指南](https://www.reidblackman.com/ethical-machines/)
    由**里德·布莱克曼**撰写'
