- en: Keeping Robots from Going Off the Ethical Rails
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®©æœºå™¨äººä¸åç¦»ä¼¦ç†è½¨é“
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13](https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13](https://towardsdatascience.com/keeping-robots-from-going-off-the-ethical-rails-7dc089b53917?source=collection_archive---------16-----------------------#2023-04-13)
- en: '![](../Images/fd2fba06a7d547e47de2ec841a83e141.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fd2fba06a7d547e47de2ec841a83e141.png)'
- en: Image created by author using Dall-E 2
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”±ä½œè€…ä½¿ç”¨ Dall-E 2 åˆ›å»º
- en: The key to building transparent AI software systems
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ„å»ºé€æ˜çš„ AI è½¯ä»¶ç³»ç»Ÿçš„å…³é”®
- en: '[](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[![Claire
    Longo](../Images/5a04940feeba1412688b4f38ec1fe974.png)](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    [Claire Longo](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[![Claire
    Longo](../Images/5a04940feeba1412688b4f38ec1fe974.png)](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    [Claire Longo](https://statistician-in-stilettos.medium.com/?source=post_page-----7dc089b53917--------------------------------)'
- en: Â·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f6936fe85bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&user=Claire+Longo&userId=1f6936fe85bb&source=post_page-1f6936fe85bb----7dc089b53917---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    Â·8 min readÂ·Apr 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7dc089b53917&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&user=Claire+Longo&userId=1f6936fe85bb&source=-----7dc089b53917---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1f6936fe85bb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&user=Claire+Longo&userId=1f6936fe85bb&source=post_page-1f6936fe85bb----7dc089b53917---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7dc089b53917--------------------------------)
    Â· 8 min é˜…è¯» Â· 2023å¹´4æœˆ13æ—¥'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7dc089b53917&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&source=-----7dc089b53917---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7dc089b53917&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fkeeping-robots-from-going-off-the-ethical-rails-7dc089b53917&source=-----7dc089b53917---------------------bookmark_footer-----------)'
- en: An AI algorithm is a software system that has the ability to automate or perform
    tasks that typically require human intelligence. These systems often include more
    than just a trained model. They can also include explicit algorithm functionality,
    such as business rules, that integrate the modelâ€™s output into the larger AI system
    to complete an end-to-end task.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: AI ç®—æ³•æ˜¯ä¸€ç§å…·æœ‰è‡ªåŠ¨åŒ–æˆ–æ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡èƒ½åŠ›çš„è½¯ä»¶ç³»ç»Ÿã€‚è¿™äº›ç³»ç»Ÿé€šå¸¸ä¸ä»…ä»…åŒ…æ‹¬ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ã€‚å®ƒä»¬è¿˜å¯èƒ½åŒ…æ‹¬æ˜ç¡®çš„ç®—æ³•åŠŸèƒ½ï¼Œä¾‹å¦‚ä¸šåŠ¡è§„åˆ™ï¼Œå°†æ¨¡å‹çš„è¾“å‡ºæ•´åˆåˆ°æ›´å¤§çš„
    AI ç³»ç»Ÿä¸­ï¼Œä»¥å®Œæˆç«¯åˆ°ç«¯çš„ä»»åŠ¡ã€‚
- en: To properly implement ethical AI systems, the software used to deploy the models
    must include the ability to measure and mitigate the live algorithm behavior from
    end-to-end. By intentionally building in methods to audit AI, we can ensure a
    good robot doesnâ€™t go off the rails â€” and if it does, weâ€™ll have the tools to
    course correct it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ­£ç¡®å®æ–½ä¼¦ç†AIç³»ç»Ÿï¼Œç”¨äºéƒ¨ç½²æ¨¡å‹çš„è½¯ä»¶å¿…é¡»å…·å¤‡ä»ç«¯åˆ°ç«¯æµ‹é‡å’Œç¼“è§£å®æ—¶ç®—æ³•è¡Œä¸ºçš„èƒ½åŠ›ã€‚é€šè¿‡æœ‰æ„åœ°æ„å»ºå®¡è®¡AIçš„æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿å¥½çš„æœºå™¨äººä¸ä¼šåç¦»è½¨é“â€”â€”å¦‚æœå‘ç”Ÿåç¦»ï¼Œæˆ‘ä»¬å°†æœ‰å·¥å…·æ¥è¿›è¡Œçº æ­£ã€‚
- en: Ethical AI Software Infrastructure
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¼¦ç†AIè½¯ä»¶åŸºç¡€è®¾æ–½
- en: So what does it take to build ethics into an AIâ€™s software infrastructure? How
    can we approach preemptively designing these systems to ensure we will have the
    ability to audit AI models for bias?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œè¦å°†ä¼¦ç†èå…¥AIçš„è½¯ä»¶åŸºç¡€è®¾æ–½ä¸­éœ€è¦ä»€ä¹ˆï¼Ÿæˆ‘ä»¬å¦‚ä½•é¢„å…ˆè®¾è®¡è¿™äº›ç³»ç»Ÿä»¥ç¡®ä¿èƒ½å¤Ÿå®¡è®¡AIæ¨¡å‹çš„åå·®ï¼Ÿ
- en: A truly auditable AI system should have enough transparency that users and creators
    can answer the questions â€œ*what data went into the model, what predictions came
    out, and what adjustments were made to it down the road before the output was
    used?â€* If bias or quality issues are detected, the levers built into an ethical
    AI system can be used to mitigate any bias or correct quality the issues that
    arise.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªçœŸæ­£å¯å®¡è®¡çš„AIç³»ç»Ÿåº”å…·å¤‡è¶³å¤Ÿçš„é€æ˜åº¦ï¼Œä»¥ä¾¿ç”¨æˆ·å’Œåˆ›ä½œè€…å¯ä»¥å›ç­”â€œ*æ•°æ®è¾“å…¥æ¨¡å‹ã€é¢„æµ‹ç»“æœã€ä»¥åŠåœ¨è¾“å‡ºè¢«ä½¿ç”¨å‰å¯¹å…¶è¿›è¡Œçš„è°ƒæ•´æ˜¯ä»€ä¹ˆï¼Ÿâ€* å¦‚æœå‘ç°åå·®æˆ–è´¨é‡é—®é¢˜ï¼Œå¯ä»¥åˆ©ç”¨ä¼¦ç†AIç³»ç»Ÿä¸­çš„æ æ†æ¥ç¼“è§£ä»»ä½•åå·®æˆ–çº æ­£å‡ºç°çš„è´¨é‡é—®é¢˜ã€‚
- en: '![](../Images/fcab682676a67de763bf36884ed18a98.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fcab682676a67de763bf36884ed18a98.png)'
- en: An auditable AI system design (diagram by author)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: å¯å®¡è®¡çš„AIç³»ç»Ÿè®¾è®¡ï¼ˆä½œè€…ç»˜å›¾ï¼‰
- en: This proposed system design is a generalized infrastructure that could be adapted
    for many business use-cases relying on live AI.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æè®®çš„ç³»ç»Ÿè®¾è®¡æ˜¯ä¸€ä¸ªé€šç”¨åŸºç¡€è®¾æ–½ï¼Œå¯é€‚ç”¨äºè®¸å¤šä¾èµ–å®æ—¶AIçš„ä¸šåŠ¡ç”¨ä¾‹ã€‚
- en: 'This design provides core functionality that ensures the model operates in
    a responsible, ethical, and unbiased manner. It includes:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥è®¾è®¡æä¾›äº†æ ¸å¿ƒåŠŸèƒ½ï¼Œç¡®ä¿æ¨¡å‹ä»¥è´Ÿè´£ä»»ã€ä¼¦ç†å’Œæ— åçš„æ–¹å¼è¿è¡Œã€‚å®ƒåŒ…æ‹¬ï¼š
- en: A **data collection system** with coverage for all system-generated data
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª**æ•°æ®æ”¶é›†ç³»ç»Ÿ**ï¼Œè¦†ç›–æ‰€æœ‰ç³»ç»Ÿç”Ÿæˆçš„æ•°æ®
- en: A **metric and monitoring system** to track model performance and bias in live
    models to provide both data and model ML Observability..
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€ä¸ª**æŒ‡æ ‡å’Œç›‘æ§ç³»ç»Ÿ**ï¼Œç”¨äºè·Ÿè¸ªæ¨¡å‹æ€§èƒ½å’Œå®æ—¶æ¨¡å‹ä¸­çš„åå·®ï¼Œä»¥æä¾›æ•°æ®å’Œæ¨¡å‹MLå¯è§‚æµ‹æ€§ã€‚
- en: '**Multiple levers to pull to mitigate any potential bias:** a targeted model
    retraining loop for updating the model with better data compelements a rules engine
    for programming in explicit logic such as model overrides or bias mitigation and
    a human-in-the-loop quality check system.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤šä¸ªæ æ†æ¥ç¼“è§£æ½œåœ¨çš„åå·®ï¼š** ä¸€ä¸ªé’ˆå¯¹æ€§çš„æ¨¡å‹å†è®­ç»ƒå¾ªç¯ï¼Œç”¨äºæ›´æ–°æ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„æ•°æ®ï¼Œè¡¥å……ä¸€ä¸ªç”¨äºç¼–ç¨‹æ˜ç¡®é€»è¾‘çš„è§„åˆ™å¼•æ“ï¼Œä¾‹å¦‚æ¨¡å‹è¦†ç›–æˆ–åå·®ç¼“è§£ï¼Œä»¥åŠä¸€ä¸ªäººæœºäº¤äº’çš„è´¨é‡æ£€æŸ¥ç³»ç»Ÿã€‚'
- en: Data Collection
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æ”¶é›†
- en: 'The data required to completely audit an AI system is extensive. It includes:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œå…¨å®¡è®¡AIç³»ç»Ÿæ‰€éœ€çš„æ•°æ®é‡éå¸¸åºå¤§ã€‚å®ƒåŒ…æ‹¬ï¼š
- en: Features (the model input)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‰¹æ€§ï¼ˆæ¨¡å‹è¾“å…¥ï¼‰
- en: Predictions (the model output)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é¢„æµ‹ï¼ˆæ¨¡å‹è¾“å‡ºï¼‰
- en: SHAP or some representation of feature importance to provide pointwise prediction
    explainability. This allows us to trace why a specific prediction was made.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAPæˆ–æŸç§ç‰¹å¾é‡è¦æ€§è¡¨ç¤ºï¼Œä»¥æä¾›é€ç‚¹é¢„æµ‹è§£é‡Šã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿè¿½è¸ªç‰¹å®šé¢„æµ‹çš„åŸå› ã€‚
- en: Any business logic or rules applied to augment the prediction
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»»ä½•ç”¨äºå¢å¼ºé¢„æµ‹çš„ä¸šåŠ¡é€»è¾‘æˆ–è§„åˆ™
- en: Any human decisions applied to augment the prediction
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»»ä½•ç”¨äºå¢å¼ºé¢„æµ‹çš„äººç±»å†³ç­–
- en: Isolated demographic data that can be linked to predictions for monitoring bias
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯ä»¥é“¾æ¥åˆ°é¢„æµ‹ä»¥ç›‘æ§åå·®çš„å­¤ç«‹äººå£æ•°æ®
- en: ğŸ’¡Notice the protected demographic data is kept isolated from the system in this
    design. This data is only used to measure model performance to detect bias. It
    should never be intermingled with model inputs as that could cause bias to be
    encoded into the model. Some core attributes to consider appear below.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ’¡æ³¨æ„åœ¨æ­¤è®¾è®¡ä¸­ä¿æŠ¤çš„äººå£æ•°æ®ä¸ç³»ç»Ÿéš”ç¦»ã€‚è¿™äº›æ•°æ®ä»…ç”¨äºæµ‹é‡æ¨¡å‹æ€§èƒ½ä»¥æ£€æµ‹åå·®ï¼Œç»ä¸åº”ä¸æ¨¡å‹è¾“å…¥æ··åˆï¼Œå¦åˆ™å¯èƒ½ä¼šå¯¼è‡´åå·®è¢«ç¼–ç åˆ°æ¨¡å‹ä¸­ã€‚ä¸‹é¢åˆ—å‡ºäº†ä¸€äº›æ ¸å¿ƒå±æ€§éœ€è€ƒè™‘ã€‚
- en: '![](../Images/715d1a6a48a16ba71fa4c64b4fb96f36.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/715d1a6a48a16ba71fa4c64b4fb96f36.png)'
- en: Diagram by author
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ç»˜å›¾
- en: Bias Measurement and Monitoring
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åå·®æµ‹é‡å’Œç›‘æ§
- en: Once that data is collected, metrics and visualizations can be used to quantify
    and monitor for bias trends in the live system. Standard fairness and bias metrics
    to consider are
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ”¶é›†äº†è¿™äº›æ•°æ®ï¼ŒæŒ‡æ ‡å’Œå¯è§†åŒ–å·¥å…·å¯ä»¥ç”¨æ¥é‡åŒ–å’Œç›‘æ§å®æ—¶ç³»ç»Ÿä¸­çš„åå·®è¶‹åŠ¿ã€‚éœ€è¦è€ƒè™‘çš„æ ‡å‡†å…¬å¹³æ€§å’Œåå·®æŒ‡æ ‡åŒ…æ‹¬
- en: 'Recall Parity: measures how â€œsensitiveâ€ the model is for one group compared
    to another, or the modelâ€™s ability to predict true positives correctly.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¬å›ç‡å¹³è¡¡ï¼šè¡¡é‡æ¨¡å‹å¯¹ä¸€ä¸ªç»„ä¸å¦ä¸€ä¸ªç»„çš„â€œæ•æ„Ÿæ€§â€æˆ–æ¨¡å‹æ­£ç¡®é¢„æµ‹çœŸå®æ­£ç±»çš„èƒ½åŠ›ã€‚
- en: 'False Positive Rate Parity: measures whether a model incorrectly predicts the
    positive class for the sensitive group as compared to the base group.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‡é˜³æ€§ç‡å¹³è¡¡ï¼šè¡¡é‡æ¨¡å‹åœ¨æ•æ„Ÿç»„ç›¸å¯¹äºåŸºç¡€ç»„ä¸­é”™è¯¯é¢„æµ‹æ­£ç±»çš„æƒ…å†µã€‚
- en: '[Disparate Impact](https://arize.com/blog-course/fairness-bias-metrics/#what-are-the-prevailing-model-fairness-metrics):
    a quantitative measure of the adverse treatment of protected classes'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[å·®åˆ«å½±å“](https://arize.com/blog-course/fairness-bias-metrics/#what-are-the-prevailing-model-fairness-metrics)ï¼šå¯¹å—ä¿æŠ¤ç±»åˆ«çš„ä¸åˆ©å¾…é‡çš„å®šé‡åº¦é‡'
- en: A model may appear to perform well on average, but digging deeper itâ€™s possible
    to look beyond the average model performance and isolate performance across demographic
    groups. Tacking the accuracy per group gives visibility into how fair the model
    is serving the population as a whole.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ¨¡å‹å¯èƒ½åœ¨å¹³å‡æ°´å¹³ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†æ·±å…¥æŒ–æ˜å¯ä»¥è¶…è¶Šå¹³å‡æ¨¡å‹è¡¨ç°ï¼Œéš”ç¦»ä¸åŒäººå£ç»„çš„è¡¨ç°ã€‚æŒ‰ç»„åˆ†æå‡†ç¡®æ€§èƒ½æä¾›æ¨¡å‹å¯¹æ•´ä½“äººç¾¤æœåŠ¡å…¬å¹³æ€§çš„å¯è§æ€§ã€‚
- en: Bias Mitigation
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åè§ç¼“è§£
- en: The **rules engine**, also known as a rule-based system or an expert system,
    is a type of algorithm that uses a predefined set of rules to make decisions or
    solve problems. These rules, often represented as IF-THEN statements, capture
    the domain-specific knowledge and expertise in a structured and organized manner.
    In real life AI applications, the model predictions are often fed into a rules
    engine, where business decisions are made around how to use the prediction or
    how to augment it. If bias is detected, new rules can be encoded to override it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**è§„åˆ™å¼•æ“**ï¼Œä¹Ÿç§°ä¸ºåŸºäºè§„åˆ™çš„ç³»ç»Ÿæˆ–ä¸“å®¶ç³»ç»Ÿï¼Œæ˜¯ä¸€ç§ä½¿ç”¨é¢„å®šä¹‰è§„åˆ™é›†æ¥åšå†³ç­–æˆ–è§£å†³é—®é¢˜çš„ç®—æ³•ã€‚è¿™äº›è§„åˆ™é€šå¸¸ä»¥IF-THENè¯­å¥è¡¨ç¤ºï¼Œä»¥ç»“æ„åŒ–å’Œæœ‰ç»„ç»‡çš„æ–¹å¼æ•æ‰é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å’Œä¸“ä¸šæŠ€èƒ½ã€‚åœ¨å®é™…AIåº”ç”¨ä¸­ï¼Œæ¨¡å‹é¢„æµ‹é€šå¸¸ä¼šè¢«è¾“å…¥åˆ°è§„åˆ™å¼•æ“ä¸­ï¼Œå›´ç»•å¦‚ä½•ä½¿ç”¨é¢„æµ‹æˆ–å¦‚ä½•å¢å¼ºé¢„æµ‹è¿›è¡Œä¸šåŠ¡å†³ç­–ã€‚å¦‚æœæ£€æµ‹åˆ°åè§ï¼Œå¯ä»¥ç¼–ç æ–°çš„è§„åˆ™æ¥è¦†ç›–å®ƒã€‚'
- en: Many AI systems include an automated pipeline for collecting new data and retraining
    the model on the new data to update it with the freshest information. This keeps
    the model healthy and performant. This same retraining loop can be used to remove
    bias from models. The retraining data can be collected in a targeted way to focus
    on providing more data or better examples for the model to learn from on areas
    where it is failing.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šAIç³»ç»ŸåŒ…æ‹¬ä¸€ä¸ªè‡ªåŠ¨åŒ–ç®¡é“ï¼Œç”¨äºæ”¶é›†æ–°æ•°æ®å¹¶åœ¨æ–°æ•°æ®ä¸Šé‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œä»¥æ›´æ–°æœ€æ–°ä¿¡æ¯ã€‚è¿™ä¿æŒäº†æ¨¡å‹çš„å¥åº·å’Œæ€§èƒ½ã€‚è¿™ç§ç›¸åŒçš„é‡æ–°è®­ç»ƒå¾ªç¯å¯ä»¥ç”¨äºä»æ¨¡å‹ä¸­å»é™¤åè§ã€‚å¯ä»¥ä»¥æœ‰é’ˆå¯¹æ€§çš„æ–¹å¼æ”¶é›†é‡æ–°è®­ç»ƒæ•°æ®ï¼Œä»¥ä¸“æ³¨äºæä¾›æ›´å¤šæ•°æ®æˆ–æ›´å¥½çš„ç¤ºä¾‹ï¼Œè®©æ¨¡å‹åœ¨å¤±è´¥çš„é¢†åŸŸå­¦ä¹ ã€‚
- en: The **human in the loop** component provides the ability to quality check the
    AIâ€™s output before it is used. This functionality also needs to be part of the
    software design so the human decision data can be collected, especially in use-cases
    that cannot or should not be fully automated. AI is often most effective as a
    human assistant, not a complete task automation tool. Building in infrastructure
    to support human interaction and decision making allows us humans to override
    bias or harmful patterns when they are detected.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**äººç±»åœ¨ç¯**ç»„ä»¶æä¾›äº†åœ¨ä½¿ç”¨AIè¾“å‡ºä¹‹å‰è¿›è¡Œè´¨é‡æ£€æŸ¥çš„èƒ½åŠ›ã€‚æ­¤åŠŸèƒ½ä¹Ÿéœ€è¦æˆä¸ºè½¯ä»¶è®¾è®¡çš„ä¸€éƒ¨åˆ†ï¼Œä»¥ä¾¿å¯ä»¥æ”¶é›†äººç±»å†³ç­–æ•°æ®ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸èƒ½æˆ–ä¸åº”è¯¥å®Œå…¨è‡ªåŠ¨åŒ–çš„ç”¨ä¾‹ä¸­ã€‚AIé€šå¸¸åœ¨ä½œä¸ºäººç±»åŠ©æ‰‹æ—¶æœ€ä¸ºæœ‰æ•ˆï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä»»åŠ¡è‡ªåŠ¨åŒ–å·¥å…·ã€‚æ„å»ºæ”¯æŒäººç±»äº’åŠ¨å’Œå†³ç­–çš„åŸºç¡€è®¾æ–½ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨å‘ç°åè§æˆ–æœ‰å®³æ¨¡å¼æ—¶è¿›è¡Œè¦†ç›–ã€‚'
- en: Wait, What Is Bias in AI?
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç­‰ç­‰ï¼ŒAIä¸­çš„åè§æ˜¯ä»€ä¹ˆï¼Ÿ
- en: So how can an AI algorithm be biased, unfair, or unethical? The bias is often
    not hard coded. Itâ€™s not explicitly written by a software engineer or data scientist.
    Instead, the algorithms learn automatically from scanning large datasets. These
    AI models work to learn patterns from a large set of data, and encode those patterns
    mathematically. Those mathematical patterns are then saved as a â€œmodelâ€ and used
    to make inferences on new data. Under this paradigm, these models can learn harmful
    and unfair patterns simply if these patterns exist in the data provided to it.
    They will then perpetuate these harmful patterns by relying on them when making
    predictions. With data available widely on the internet, even old patterns and
    historical biases could get encoded into these models if weâ€™re not careful.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œäººå·¥æ™ºèƒ½ç®—æ³•å¦‚ä½•ä¼šæœ‰åè§ã€ä¸å…¬å¹³æˆ–ä¸é“å¾·å‘¢ï¼Ÿåè§é€šå¸¸ä¸æ˜¯ç¡¬ç¼–ç çš„ã€‚å®ƒä¸æ˜¯ç”±è½¯ä»¶å·¥ç¨‹å¸ˆæˆ–æ•°æ®ç§‘å­¦å®¶æ˜ç¡®ç¼–å†™çš„ã€‚ç›¸åï¼Œç®—æ³•é€šè¿‡æ‰«æå¤§é‡æ•°æ®é›†è‡ªåŠ¨å­¦ä¹ ã€‚è¿™äº›äººå·¥æ™ºèƒ½æ¨¡å‹æ—¨åœ¨ä»å¤§é‡æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œå¹¶å°†è¿™äº›æ¨¡å¼ä»¥æ•°å­¦æ–¹å¼ç¼–ç ã€‚è¿™äº›æ•°å­¦æ¨¡å¼ç„¶åè¢«ä¿å­˜ä¸ºâ€œæ¨¡å‹â€ï¼Œç”¨äºå¯¹æ–°æ•°æ®è¿›è¡Œæ¨æ–­ã€‚åœ¨è¿™ç§èŒƒå¼ä¸‹ï¼Œè¿™äº›æ¨¡å‹å¦‚æœæä¾›çš„æ•°æ®ä¸­å­˜åœ¨æœ‰å®³å’Œä¸å…¬å¹³çš„æ¨¡å¼ï¼Œå°±å¯èƒ½å­¦ä¹ åˆ°è¿™äº›æœ‰å®³çš„æ¨¡å¼ã€‚å®ƒä»¬ä¼šåœ¨é¢„æµ‹æ—¶ä¾èµ–è¿™äº›æ¨¡å¼ï¼Œä»è€Œå»¶ç»­è¿™äº›æœ‰å®³æ¨¡å¼ã€‚ç”±äºäº’è”ç½‘ä¸Šçš„æ•°æ®å¹¿æ³›å­˜åœ¨ï¼Œå¦‚æœä¸åŠ å°å¿ƒï¼Œæ—§çš„æ¨¡å¼å’Œå†å²åè§ä¹Ÿå¯èƒ½è¢«ç¼–ç åˆ°è¿™äº›æ¨¡å‹ä¸­ã€‚
- en: So when thinking about patterns that get encoded into AI algorithms, there are
    two kinds of patterns to consider. Explicit and implicit patterns. Explicit patterns
    are rules hard coded in. These patterns are a purposeful choice by an organization,
    and typically represented as IF-THEN statements in code. Implicit patterns are
    learned by the model from data provided to it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è€ƒè™‘ç¼–ç åˆ°äººå·¥æ™ºèƒ½ç®—æ³•ä¸­çš„æ¨¡å¼æ—¶ï¼Œæœ‰ä¸¤ç§æ¨¡å¼éœ€è¦è€ƒè™‘ã€‚æ˜¾å¼æ¨¡å¼å’Œéšå¼æ¨¡å¼ã€‚æ˜¾å¼æ¨¡å¼æ˜¯ç¡¬ç¼–ç çš„è§„åˆ™ã€‚è¿™äº›æ¨¡å¼æ˜¯ç»„ç»‡çš„æœ‰æ„é€‰æ‹©ï¼Œé€šå¸¸è¡¨ç¤ºä¸ºä»£ç ä¸­çš„IF-THENè¯­å¥ã€‚éšå¼æ¨¡å¼æ˜¯æ¨¡å‹ä»æä¾›ç»™å®ƒçš„æ•°æ®ä¸­å­¦ä¹ åˆ°çš„ã€‚
- en: AI Development Lifecycle
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: äººå·¥æ™ºèƒ½å¼€å‘ç”Ÿå‘½å‘¨æœŸ
- en: 'To add further context to this discussion, it is helpful to break down the
    **AI project lifecycle** to understand where bias or quality issues could be introduced.
    There are two core phases of the AI project lifecycle to focus on: *Research and
    Development (R&D)*, and *Operationalization*.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è¿›ä¸€æ­¥é˜æ˜è¿™ä¸€è®¨è®ºï¼Œäº†è§£**äººå·¥æ™ºèƒ½é¡¹ç›®ç”Ÿå‘½å‘¨æœŸ**çš„è¯¦ç»†å†…å®¹éå¸¸æœ‰å¸®åŠ©ï¼Œä»¥ä¾¿äº†è§£å¯èƒ½å¼•å…¥åè§æˆ–è´¨é‡é—®é¢˜çš„åœ°æ–¹ã€‚äººå·¥æ™ºèƒ½é¡¹ç›®ç”Ÿå‘½å‘¨æœŸæœ‰ä¸¤ä¸ªæ ¸å¿ƒé˜¶æ®µï¼š*ç ”ç©¶ä¸å¼€å‘ï¼ˆR&Dï¼‰*å’Œ*è½åœ°å®æ–½*ã€‚
- en: '![](../Images/74817d7554b18b8942c9869169d3015c.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/74817d7554b18b8942c9869169d3015c.png)'
- en: Diagram by author
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„å›¾ç¤º
- en: R&D Phase
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç ”å‘é˜¶æ®µ
- en: '![](../Images/4f0990d971d52626538eb2b886107e9e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f0990d971d52626538eb2b886107e9e.png)'
- en: Image created by author using Dall-E 2
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ä½¿ç”¨Dall-E 2åˆ›å»ºçš„å›¾åƒ
- en: In the R&D phase, scientists or researchers work to create the model. They collect
    raw data, transform the data into meaningful model features, experiment and test
    various modeling approaches and parameters, and evaluate the modelâ€™s performance
    based on its ability to optimize a specific outcome of choice. During these steps,
    there are many considerations these model creators will take to prevent and test
    for bias in their model. They work to collect unbiased data and carefully measure
    model performance across protected demographics to ensure fairness. However, bias
    can still creep in. So weâ€™ll want to be able to monitor and track this modelâ€™s
    behavior once itâ€™s live.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç ”å‘é˜¶æ®µï¼Œç§‘å­¦å®¶æˆ–ç ”ç©¶äººå‘˜è‡´åŠ›äºåˆ›å»ºæ¨¡å‹ã€‚ä»–ä»¬æ”¶é›†åŸå§‹æ•°æ®ï¼Œå°†æ•°æ®è½¬æ¢ä¸ºæœ‰æ„ä¹‰çš„æ¨¡å‹ç‰¹å¾ï¼Œå®éªŒå’Œæµ‹è¯•å„ç§å»ºæ¨¡æ–¹æ³•å’Œå‚æ•°ï¼Œå¹¶æ ¹æ®ä¼˜åŒ–ç‰¹å®šç»“æœçš„èƒ½åŠ›è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚åœ¨è¿™äº›æ­¥éª¤ä¸­ï¼Œæ¨¡å‹åˆ›å»ºè€…ä¼šè€ƒè™‘è®¸å¤šå› ç´ æ¥é˜²æ­¢å’Œæµ‹è¯•æ¨¡å‹ä¸­çš„åè§ã€‚ä»–ä»¬åŠªåŠ›æ”¶é›†æ— åè§çš„æ•°æ®ï¼Œå¹¶ä»”ç»†æµ‹é‡æ¨¡å‹åœ¨å—ä¿æŠ¤äººç¾¤ä¸­çš„è¡¨ç°ï¼Œä»¥ç¡®ä¿å…¬å¹³ã€‚ç„¶è€Œï¼Œåè§ä»ç„¶å¯èƒ½æ¸—å…¥ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦èƒ½å¤Ÿç›‘æ§å’Œè·Ÿè¸ªæ¨¡å‹ä¸Šçº¿åçš„è¡Œä¸ºã€‚
- en: Operationalization Phase
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è½åœ°å®æ–½é˜¶æ®µ
- en: '![](../Images/264f54138a0dcdd82639ea77d4bb8134.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/264f54138a0dcdd82639ea77d4bb8134.png)'
- en: Image created by author using Dall-E 2
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…ä½¿ç”¨Dall-E 2åˆ›å»ºçš„å›¾åƒ
- en: Once the model is created and we have our good robot, the project will move
    into the next phase â€” where said good robot is operationalized. Thatâ€™s where the
    engineers come in. This phase of development focuses on transforming the chosen
    model into a practical and functional system that produces predictions from the
    model that an end-user can access and rely on and use live. This process involves
    constructing software systems that integrate the modelâ€™s core functionality and
    adhere to best practices for production code, ensuring the system is scalable
    and maintainable. This is whereethical AI by design comes in. This system can
    be designed to not only produce predictions from the model, but to also safeguard
    these algorithms if designed with ethical AI in mind.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ¨¡å‹åˆ›å»ºå®Œæˆï¼Œæˆ‘ä»¬æ‹¥æœ‰äº†ä¼˜è‰¯çš„æœºå™¨äººï¼Œé¡¹ç›®å°†è¿›å…¥ä¸‹ä¸€é˜¶æ®µâ€”â€”å³å°†è¯¥ä¼˜è‰¯æœºå™¨äººæŠ•å…¥å®é™…æ“ä½œã€‚è¿™å°±æ˜¯å·¥ç¨‹å¸ˆçš„å·¥ä½œæ‰€åœ¨ã€‚è¿™ä¸€å¼€å‘é˜¶æ®µä¸“æ³¨äºå°†é€‰å®šçš„æ¨¡å‹è½¬åŒ–ä¸ºä¸€ä¸ªå®ç”¨ä¸”åŠŸèƒ½é½å…¨çš„ç³»ç»Ÿï¼Œä½¿æœ€ç»ˆç”¨æˆ·å¯ä»¥è®¿é—®ã€ä¾èµ–å¹¶å®æ—¶ä½¿ç”¨æ¨¡å‹ç”Ÿæˆçš„é¢„æµ‹ã€‚è¿™ä¸ªè¿‡ç¨‹åŒ…æ‹¬æ„å»ºé›†æˆæ¨¡å‹æ ¸å¿ƒåŠŸèƒ½çš„è½¯ä»¶ç³»ç»Ÿï¼Œå¹¶éµå¾ªç”Ÿäº§ä»£ç çš„æœ€ä½³å®è·µï¼Œç¡®ä¿ç³»ç»Ÿå…·æœ‰å¯æ‰©å±•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚è¿™æ˜¯è®¾è®¡ä¼¦ç†äººå·¥æ™ºèƒ½çš„å…³é”®ç¯èŠ‚ã€‚è¯¥ç³»ç»Ÿä¸ä»…å¯ä»¥åŸºäºæ¨¡å‹ç”Ÿæˆé¢„æµ‹ï¼Œè¿˜å¯ä»¥åœ¨è®¾è®¡æ—¶è€ƒè™‘ä¼¦ç†äººå·¥æ™ºèƒ½æ¥ä¿æŠ¤è¿™äº›ç®—æ³•ã€‚
- en: An [auditable AI system](https://arize.com/blog-course/transparent-ethical-ai-software-systems/)
    collects data from the model itself as well as the patterns around explicit decisions
    regarding how the modelâ€™s output is used. This allows for a holistic view of the
    algorithmâ€™s behavior and facilitates monitoring the system as a whole.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[å¯å®¡è®¡çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿ](https://arize.com/blog-course/transparent-ethical-ai-software-systems/)ä»æ¨¡å‹æœ¬èº«ä»¥åŠä¸æ¨¡å‹è¾“å‡ºä½¿ç”¨ç›¸å…³çš„æ˜ç¡®å†³ç­–æ¨¡å¼ä¸­æ”¶é›†æ•°æ®ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿå…¨é¢äº†è§£ç®—æ³•çš„è¡Œä¸ºï¼Œå¹¶ä¿ƒè¿›å¯¹æ•´ä¸ªç³»ç»Ÿçš„ç›‘æ§ã€‚'
- en: This algorithmic transparency should be at the forefront of the design of any
    AI system from the beginning of the design. This means that the ability to measure
    and mitigate bias needs to be baked into the software, and not an afterthought.
    If an algorithm with potential bias is deployed without these mechanisms in place,
    it will be difficult to detect and correct any harmful patterns.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç®—æ³•é€æ˜åº¦åº”å½“åœ¨ä»»ä½•äººå·¥æ™ºèƒ½ç³»ç»Ÿè®¾è®¡çš„æœ€å‰æ²¿ã€‚è¿™æ„å‘³ç€è¡¡é‡å’Œå‡è½»åè§çš„èƒ½åŠ›éœ€è¦èå…¥è½¯ä»¶ä¸­ï¼Œè€Œä¸æ˜¯äº‹åçš„è€ƒè™‘ã€‚å¦‚æœéƒ¨ç½²çš„ç®—æ³•å­˜åœ¨æ½œåœ¨çš„åè§è€Œæ²¡æœ‰è¿™äº›æœºåˆ¶ï¼Œå°†å¾ˆéš¾æ£€æµ‹å’Œçº æ­£ä»»ä½•æœ‰å®³çš„æ¨¡å¼ã€‚
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: Itâ€™s likely many AI systems will need to be audited at some point, whether itâ€™s
    for bias, or simply interpretability or quality. Itâ€™s possible to get ahead of
    this by thoughtfully designing infrastructure that provides enough visibility
    into the data, and opportunity for algorithm improvements. Letâ€™s keep those robots
    from going off the rails.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¯èƒ½è®¸å¤šäººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨æŸä¸ªæ—¶ç‚¹éœ€è¦è¢«å®¡è®¡ï¼Œæ— è®ºæ˜¯ä¸ºäº†åè§ï¼Œè¿˜æ˜¯ä»…ä»…ä¸ºäº†å¯è§£é‡Šæ€§æˆ–è´¨é‡ã€‚é€šè¿‡æ·±æ€ç†Ÿè™‘åœ°è®¾è®¡æä¾›è¶³å¤Ÿæ•°æ®å¯è§æ€§å’Œç®—æ³•æ”¹è¿›æœºä¼šçš„åŸºç¡€è®¾æ–½ï¼Œå¯ä»¥æå‰åº”å¯¹è¿™ä¸ªé—®é¢˜ã€‚è®©æˆ‘ä»¬ä¿æŒè¿™äº›æœºå™¨äººä¸åç¦»è½¨é“ã€‚
- en: 'For deeper reading on this subject, here are a few of my favorite books and
    resources on ethical AI:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹è¿™ä¸ªä¸»é¢˜çš„æ·±å…¥é˜…è¯»ï¼Œä»¥ä¸‹æ˜¯æˆ‘æœ€å–œæ¬¢çš„ä¸€äº›å…³äºä¼¦ç†äººå·¥æ™ºèƒ½çš„ä¹¦ç±å’Œèµ„æºï¼š
- en: '[A Summary and Review of the Ethical Algorithm](https://hackernoon.com/a-summary-and-review-of-the-ethical-algorithm)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ä¼¦ç†ç®—æ³•çš„æ€»ç»“ä¸è¯„è®º](https://hackernoon.com/a-summary-and-review-of-the-ethical-algorithm)'
- en: '[Invisible Women: Data Bias In a World Designed for Men](https://carolinecriadoperez.com/book/invisible-women/)
    by Caroline Criado Perez'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[éšå½¢å¥³æ€§ï¼šä¸€ä¸ªä¸ºç”·æ€§è®¾è®¡çš„ä¸–ç•Œä¸­çš„æ•°æ®åè§](https://carolinecriadoperez.com/book/invisible-women/)
    ç”±**å¡ç½—ç³Â·å…‹é‡Œäºšå¤š-ä½©é›·æ–¯**æ’°å†™'
- en: '[Weapons of Math Destruction](https://www.penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil/)
    by Cathy Oâ€™Neil'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ•°å­¦æ¯ç­æ­¦å™¨](https://www.penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil/)
    ç”±**å‡¯è¥¿Â·å¥¥å°¼å°”**æ’°å†™'
- en: '[Ethical Machines: Your Concise Guide To Totally Unbiased, Transparent and
    Respectful AI](https://www.reidblackman.com/ethical-machines/) by Reid Blackman'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ä¼¦ç†æœºå™¨ï¼šå®Œå…¨æ— åè§ã€é€æ˜ä¸”å°Šé‡çš„äººå·¥æ™ºèƒ½ç®€æ˜æŒ‡å—](https://www.reidblackman.com/ethical-machines/)
    ç”±**é‡Œå¾·Â·å¸ƒè±å…‹æ›¼**æ’°å†™'
