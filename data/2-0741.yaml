- en: Direction Improves Graph Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方向改善图学习
- en: 原文：[https://towardsdatascience.com/direction-improves-graph-learning-170e797e94fe](https://towardsdatascience.com/direction-improves-graph-learning-170e797e94fe)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/direction-improves-graph-learning-170e797e94fe](https://towardsdatascience.com/direction-improves-graph-learning-170e797e94fe)
- en: GNNs on Directed Graphs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有向图上的图神经网络
- en: How a wise use of direction when doing message passing on heterophilic graphs
    can result in very significant gains.
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研究在异质图上进行消息传递时合理使用方向可以带来非常显著的提升。
- en: '[](https://michael-bronstein.medium.com/?source=post_page-----170e797e94fe--------------------------------)[![Michael
    Bronstein](../Images/1aa876fce70bb07bef159fecb74e85bf.png)](https://michael-bronstein.medium.com/?source=post_page-----170e797e94fe--------------------------------)[](https://towardsdatascience.com/?source=post_page-----170e797e94fe--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----170e797e94fe--------------------------------)
    [Michael Bronstein](https://michael-bronstein.medium.com/?source=post_page-----170e797e94fe--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://michael-bronstein.medium.com/?source=post_page-----170e797e94fe--------------------------------)[![Michael
    Bronstein](../Images/1aa876fce70bb07bef159fecb74e85bf.png)](https://michael-bronstein.medium.com/?source=post_page-----170e797e94fe--------------------------------)[](https://towardsdatascience.com/?source=post_page-----170e797e94fe--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----170e797e94fe--------------------------------)
    [迈克尔·布朗斯坦](https://michael-bronstein.medium.com/?source=post_page-----170e797e94fe--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----170e797e94fe--------------------------------)
    ·10 min read·Jun 8, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----170e797e94fe--------------------------------)
    ·10分钟阅读·2023年6月8日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '*Graph Neural Networks (GNNs) are highly effective at modelling relational
    data. However, current GNN models frequently assume the input graph to be undirected,
    overlooking the inherent directionality of many real-world graphs, such as social,
    transportation, transaction, and citation networks. In this blog post, we explore
    the impact of edge directionality in the context of heterophilic graphs and outline
    Dir-GNN, a novel message-passing scheme for directed graphs allowing a separate
    aggregation of incoming and outgoing edges. Despite its simplicity, this scheme
    significantly improves performance on multiple real-world heterophilic directed
    graphs.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*图神经网络（GNNs）在建模关系数据方面非常有效。然而，当前的 GNN 模型通常假设输入图是无向的，忽略了许多实际图（如社交网络、交通网络、交易网络和引用网络）固有的方向性。在这篇博文中，我们探讨了在异质图的背景下边的方向性影响，并概述了
    Dir-GNN，一种针对有向图的全新消息传递方案，允许单独聚合进入和离开边。尽管其简单性，该方案在多个实际异质有向图上显著提高了性能。*'
- en: '![](../Images/f963a2136e394c365df0a6f3421821bb.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f963a2136e394c365df0a6f3421821bb.png)'
- en: Based on Shutterstock.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 Shutterstock。
- en: '*This post was co-authored with* [*Emanuele Rossi*](https://emanuelerossi.co.uk/)
    *and is based on the paper E. Rossi et al., “*[*Edge Directionality Improves Learning
    on Heterophilic Graphs*](https://arxiv.org/abs/2305.10498)*” (2023) arXiv:2305.10498,
    a collaboration with* [*Bertrand Charpentier*](https://twitter.com/Bertrand_Charp)*,*
    [*Francesco Di Giovanni*](https://twitter.com/Francesco_dgv)*,* [*Fabrizio Frasca*](https://twitter.com/ffabffrasca)
    *and* [*Stephan Günnemann*](https://twitter.com/guennemann) *[1]. The code for
    the paper can be found* [*here*](https://github.com/emalgorithm/directed-graph-neural-network)*.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文由* [*埃曼纽尔·罗西*](https://emanuelerossi.co.uk/) *共同撰写，基于论文 E. Rossi et al.,
    “*[*边的方向性改善异质图上的学习*](https://arxiv.org/abs/2305.10498)*” (2023) arXiv:2305.10498，与*
    [*贝特朗·夏尔潘捷*](https://twitter.com/Bertrand_Charp)*、* [*弗朗西斯科·迪·乔瓦尼*](https://twitter.com/Francesco_dgv)*、*
    [*法布里齐奥·弗拉斯卡*](https://twitter.com/ffabffrasca) *和* [*斯特凡·古恩曼*](https://twitter.com/guennemann)
    *[1] 合作完成。论文的代码可以在* [*这里*](https://github.com/emalgorithm/directed-graph-neural-network)*找到。*'
- en: Many interesting real-world graphs, encountered in modelling social, transportation,
    financial transactions, or academic citation networks, are *directed*. The direction
    of the edges often conveys crucial insights, otherwise lost if one considers only
    the connectivity pattern of the graph.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 许多有趣的实际图，例如在建模社交、交通、金融交易或学术引用网络时遇到的图，都是*有向的*。边的方向通常传达了关键的见解，否则如果仅考虑图的连接模式，这些见解将会丧失。
- en: In contrast, most Graph Neural Networks (GNNs) that have made remarkable strides
    in a variety of graph ML applications, operate under the assumption that the input
    graph is *undirected*. Making the input graph undirected has become so prevalent
    over the years that PyTorch-Geometric, one of the most popular GNN libraries,
    includes a general utility function that automatically makes graphs undirected
    when loading datasets [2].
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，大多数在各种图机器学习应用中取得显著进展的图神经网络（GNNs）假设输入图是*无向*的。多年来，使输入图成为无向图已变得非常普遍，以至于流行的GNN库之一PyTorch-Geometric在加载数据集时包含了一个通用工具函数，该函数会自动将图转换为无向图[2]。
- en: This inclination towards undirected graphs comes from two “primordial sins”
    of GNNs. First, undirected graphs have symmetric Laplacians with orthogonal eigenvectors
    offering a natural generalisation of the Fourier transform, on which early spectral
    GNNs relied to function properly. Second, early datasets used to benchmark GNNs
    were predominantly *homophilic* graphs [3], such as Cora and Pubmed [4]. On such
    datasets disregarding the direction by converting the directed graph into an undirected
    one appears to be advantageous, early evidence whereof has helped cement the “undirected”
    paradigm.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对无向图的这种倾向源于GNNs的两个“原罪”。首先，无向图具有对称的拉普拉斯算子和正交特征向量，提供了傅里叶变换的自然推广，而早期的谱GNN依赖于此以正常运作。其次，早期用于基准测试GNNs的数据集主要是*同质性*图[3]，如Cora和Pubmed[4]。在这些数据集中，通过将定向图转换为无向图来忽略方向似乎是有利的，早期证据有助于巩固“无向”范式。
- en: '![](../Images/802b62d61a82b5ffdcc4969b8f64763d.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/802b62d61a82b5ffdcc4969b8f64763d.png)'
- en: Direction is largely useless in homophilic graphs (left), an observation that
    has led to the majority of current GNNs disregarding this information. In contrast,
    in the heterophilic setting (right), the use of direction can bring large gains
    (10% to 15%) if used correctly, as proposed in our Dir-GNN framework.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在同质性图（左）中，方向大多无用，这一观察导致了大多数当前的GNNs忽视了这一信息。相反，在异质性设置中（右），如果使用得当，方向性可以带来大幅收益（10%到15%），正如我们在Dir-GNN框架中提出的那样。
- en: We challenge this *status quo* in our recent paper [5], showing that directionality
    can bring extensive gains in heterophilic settings.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在最近的论文[5]中挑战了这一*现状*，表明方向性可以在异质性设置中带来广泛的收益。
- en: Measuring Homophily in Directed Graphs
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在定向图中测量同质性
- en: 'The homophily of a graph is typically measured as the fraction of neighbours
    with the same label as the node itself, averaged across all nodes (*node homophily*).
    For directed graphs, we propose the *weighted node homophily*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图的同质性通常被测量为与节点本身具有相同标签的邻居的比例，平均遍及所有节点（*节点同质性*）。对于定向图，我们提出了*加权节点同质性*：
- en: h(S) = 1/*n* Σ*ᵤ* ( Σ*ᵥ* *sᵤᵥ* * **I**[*yᵤ* = *yᵥ*] ) / Σ*ᵥ* *sᵤᵥ*
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: h(S) = 1/*n* Σ*ᵤ* ( Σ*ᵥ* *sᵤᵥ* * **I**[*yᵤ* = *yᵥ*] ) / Σ*ᵥ* *sᵤᵥ*
- en: where **I** denotes the indicator function, *n* is the number of nodes, and
    **S** is a general adjacency matrix, which can be picked up as 𝐀or𝐀ᵀ, or as higher-order
    matrices, such as 𝐀𝐀ᵀor 𝐀² for directed graphs, or as the symmetric matrix 𝐀ᵤ=
    (𝐀+ 𝐀ᵀ) / 2 and its higher-order counterpart 𝐀ᵤ², if the graph is considered as
    undirected.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 其中**I**表示指示函数，*n*是节点数量，**S**是一般邻接矩阵，可以选择𝐀或𝐀ᵀ，或者更高阶矩阵，例如𝐀𝐀ᵀ或𝐀²（对于定向图），或对称矩阵𝐀ᵤ=
    (𝐀+ 𝐀ᵀ) / 2及其高阶对应矩阵𝐀ᵤ²（如果图被视为无向图）。
- en: Even when 1-hop neighbours are heterophilic [6], the situation may change when
    going to farther nodes. Compared to the undirected case, there are four distinct
    2-hops in directed graphs represented by the matrices 𝐀²,(𝐀ᵀ)², 𝐀𝐀ᵀ, and𝐀ᵀ𝐀, which
    can manifest different levels of (weighted) homophily.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 即使当1-hop邻居存在异质性[6]时，情况也可能在转到更远的节点时发生变化。与无向图相比，定向图中有四种不同的2-hops，分别由矩阵𝐀²、(𝐀ᵀ)²、𝐀𝐀ᵀ和𝐀ᵀ𝐀表示，这些矩阵可以体现出不同程度的（加权）同质性。
- en: Given that GNNs operate through multiple-hop aggregations, they can leverage
    the homophily of any 2-hop (or even further hops) of a graph. To have a comprehensive
    metric capturing the maximum homophily a GNN can leverage in principle, we introduce
    the notion of *effective homophily*, defined as the maximum weighted node homophily
    at any hop of the graph.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GNNs通过多跳聚合进行操作，它们可以利用图中任何2-hop（甚至更远的跳数）的同质性。为了获得一个全面的度量来捕捉GNN原则上可以利用的最大同质性，我们引入了*有效同质性*的概念，定义为图中任何跳数的最大加权节点同质性。
- en: Empirically, we observe that the effective homophily of directed homophilic
    datasets is left unchanged when making the graph undirected. In heterophilic graphs,
    in contrast, this conversion decreases the effective homophily by almost 30% on
    average.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从经验上看，当将图转为无向图时，有向同质数据集的有效同质性保持不变。相反，在异质图中，这种转换平均减少了约30%的有效同质性。
- en: '![](../Images/e93a90887fc2f2557d348a6e429f3db4.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e93a90887fc2f2557d348a6e429f3db4.png)'
- en: We compare the weighted homophily of both directed and undirected diffusion
    matrices for a variety of both homophilic and heterophilic datasets. The effective
    homophily of the directed graph *(h*⁽ᵉᶠᶠ⁾) is much larger than that of the undirected
    graph (*h*⁽ᵉᶠᶠ⁾*)* for heterophilic datasets, suggesting a potential gain from
    using directionality effectively.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了多种同质和异质数据集的有向和无向扩散矩阵的加权同质性。对于异质数据集，有向图的有效同质性*(h*⁽ᵉᶠᶠ⁾)比无向图的*(h*⁽ᵉᶠᶠ⁾*)*大得多，表明有效利用方向性可能带来潜在的收益。
- en: '![](../Images/de78f679d34fcfba9897ef76104c451b.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de78f679d34fcfba9897ef76104c451b.png)'
- en: In synthetic experiments, we again observe that the effective homophily of directed
    [stochastic block model](https://en.wikipedia.org/wiki/Stochastic_block_model)
    graphs is consistently higher compared to their undirected counterparts. Interestingly,
    this gap widens for graphs that are less homophilic.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在合成实验中，我们再次观察到，有向的[随机块模型](https://en.wikipedia.org/wiki/Stochastic_block_model)图的有效同质性始终高于其无向对应物。有趣的是，对于较少同质的图，这一差距会扩大。
- en: A Toy Example
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个玩具示例
- en: In particular, we observe that 𝐀𝐀ᵀ and𝐀ᵀ𝐀consistently appear to be the “most
    homophilic matrices” for heterophilic graphs.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，我们观察到𝐀𝐀ᵀ和𝐀ᵀ𝐀在异质图中始终出现为“最同质的矩阵”。
- en: 'To provide an intuition about why this is the case, imagine we are trying to
    predict the publication year of a specific academic paper, for instance, the Kipf
    & Welling 2016 GCN paper, given the directed citation network and the year of
    publication of the other papers. Consider two different kinds of 2-hop relationships:
    one where we look at papers cited by the papers that our paper of interest *v*
    cites (represented by the *v*th row of the matrix 𝐀²), and another where we look
    at papers that cite the same sources as our paper (represented by (𝐀𝐀ᵀ)*ᵥ*).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一个直观的理解，想象我们正在尝试预测一篇特定学术论文的出版年份，例如Kipf & Welling 2016年GCN论文，给定有向引用网络和其他论文的出版年份。考虑两种不同的2跳关系：一种是查看我们关注的论文
    *v* 引用的论文的引用（由矩阵 𝐀² 的 *v* 行表示），另一种是查看引用与我们论文相同来源的论文（由(𝐀𝐀ᵀ)*ᵥ*表示）。
- en: In the first case (𝐀²), let us start from the GCN paper and follow its citations
    twice. We land on a paper by Frasconi *et al.* from 1998\. This older paper does
    not give us much helpful information about when our GCN paper was published because
    it is too far in the past.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下（𝐀²），我们从GCN论文开始，并跟随其引用两次。我们最终找到了一篇1998年由Frasconi *et al.* 发表的论文。这篇较旧的论文并没有提供很多关于我们的GCN论文发布时间的有用信息，因为它时间跨度过长。
- en: '![](../Images/1ffd5785667b110be7ad4ce35249372c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ffd5785667b110be7ad4ce35249372c.png)'
- en: Toy example of a directed citation network.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有向引用网络的玩具示例。
- en: In the second case (𝐀𝐀ᵀ), we begin with the GCN paper, follow a citation, and
    then come back to a paper that cites the same source, like the 2017 GAT paper.
    This paper is much closer to our GCN paper’s publication year and thus provides
    a better clue. More generally, nodes that share more references, like in our second
    example, will have higher scores in 𝐀𝐀ᵀ, and thus contribute more to our final
    prediction.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种情况下（𝐀𝐀ᵀ），我们从GCN论文开始，跟随一个引用，然后返回到引用相同来源的论文，例如2017年的GAT论文。这篇论文与我们的GCN论文出版年份更接近，因此提供了更好的线索。更一般地，分享更多引用的节点，如我们第二个例子中的节点，在𝐀𝐀ᵀ中的分数更高，因此对我们的最终预测贡献更大。
- en: Now, consider an undirected 2-hop relationship (𝐀ᵤ²), which is just the average
    of the four possible 2-hop matrices. This includes our first type (like Frasconi
    et al.), which was not very helpful. Therefore, the highly useful 𝐀𝐀ᵀ matrix gets
    diluted by less informative matrices, like 𝐀², leading to a less homophilic operator,
    resulting in a less reliable predictor overall.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑一个无向2跳关系（𝐀ᵤ²），这只是四种可能的2跳矩阵的平均值。这包括我们的第一种类型（如Frasconi et al.），这并不是非常有用。因此，高度有用的𝐀𝐀ᵀ矩阵被较少信息的矩阵（如𝐀²）稀释，导致一个较少同质的运算符，从而总体上导致一个较不可靠的预测器。
- en: While we have used a citation network in our example, this intuition applies
    more broadly. In a social network, for instance, an influencer’s characteristics
    are more likely to resemble those of users who share many followers with them,
    represented by 𝐀ᵀ𝐀. Similarly, in a transaction network, two accounts sending
    money to the same set of accounts (captured by 𝐀𝐀ᵀ), are likely to exhibit similar
    behaviour.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在示例中使用了引用网络，但这种直觉具有更广泛的适用性。在社交网络中，例如，影响者的特征更可能与那些有很多共同关注者的用户类似，由 𝐀ᵀ𝐀 表示。类似地，在交易网络中，两个账户向同一组账户汇款（由
    𝐀𝐀ᵀ 捕获），很可能表现出类似的行为。
- en: 'Dir-GNN: Directed Graph Neural Network'
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dir-GNN：有向图神经网络
- en: 'In order to leverage directionality effectively, we propose the *Directed Graph
    Neural Network* (Dir-GNN) framework, which extends MPNNs to directed graphs by
    performing separate aggregations over the in- and out-neighbours of a node:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效利用方向性，我们提出了 *有向图神经网络*（Dir-GNN）框架，它通过对节点的入邻居和出邻居进行独立聚合，将 MPNNs 扩展到有向图：
- en: '**m***ᵤ*⁽ᵏ⁾ᵢₙ = AGGᵢₙ({{**x***ᵥ*⁽ᵏ⁻¹⁾, **x***ᵤ*⁽ᵏ⁻¹⁾) : (*u*,*v*) ∈ E }})'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**m***ᵤ*⁽ᵏ⁾ᵢₙ = AGGᵢₙ({{**x***ᵥ*⁽ᵏ⁻¹⁾, **x***ᵤ*⁽ᵏ⁻¹⁾) : (*u*,*v*) ∈ E }})'
- en: '**m***ᵤ*⁽ᵏ⁾ₒᵤₜ = AGGₒᵤₜ({{**x***ᵥ*⁽ᵏ⁻¹⁾, **x***ᵤ*⁽ᵏ⁻¹⁾) : (*v*,*u*) ∈ E }})'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**m***ᵤ*⁽ᵏ⁾ₒᵤₜ = AGGₒᵤₜ({{**x***ᵥ*⁽ᵏ⁻¹⁾, **x***ᵤ*⁽ᵏ⁻¹⁾) : (*v*,*u*) ∈ E }})'
- en: '**x***ᵤ*⁽ᵏ⁾ = COM(**x***ᵤ*⁽ᵏ⁻¹⁾, **m***ᵤ*⁽ᵏ⁾ᵢₙ, **m***ᵤ*⁽ᵏ⁾ₒᵤₜ)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**x***ᵤ*⁽ᵏ⁾ = COM(**x***ᵤ*⁽ᵏ⁻¹⁾, **m***ᵤ*⁽ᵏ⁾ᵢₙ, **m***ᵤ*⁽ᵏ⁾ₒᵤₜ)'
- en: where the aggregation maps AGGᵢₙ and AGGₒᵤₜ, as well as the combination maps
    COM are learnable (usually a small neural network). Importantly, AGGᵢₙ and AGGₒᵤₜ
    can have independent sets of parameters to allow for different aggregations over
    in- and out-edges [7].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，聚合映射 AGGᵢₙ 和 AGGₒᵤₜ，以及组合映射 COM 是可学习的（通常是一个小的神经网络）。重要的是，AGGᵢₙ 和 AGGₒᵤₜ 可以拥有独立的参数集，以允许对入边和出边进行不同的聚合
    [7]。
- en: 'Interestingly, this procedural pattern resembles the one implemented by a natural
    extension of the classical Weisefiler-Lehman graph isomorphism test (1-WL) to
    directed graphs [8]. This connection is instrumental: in terms of discriminative
    power, we show that Dir-GNN is *strictly more powerful* than standard MPNNs, which
    either convert the graph to undirected or propagate messages only in the direction
    of the edges.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这种程序模式类似于经典 Weisefiler-Lehman 图同构测试（1-WL）对有向图的自然扩展 [8]。这一联系非常重要：在区分能力方面，我们证明了
    Dir-GNN *严格比*标准 MPNNs 更强大，后者要么将图转换为无向图，要么仅沿边的方向传播消息。
- en: 'Our framework is also flexible: it is easy to define directed counterparts
    of specific architectures such as GCN, GraphSAGE or GAT. For example, we can define
    Dir-GCN as:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的框架也很灵活：定义特定架构（如 GCN、GraphSAGE 或 GAT）的有向对应物很容易。例如，我们可以定义 Dir-GCN 为：
- en: 𝐗⁽ᵏ⁾ = σ(𝐒ₒᵤₜ𝐗⁽ᵏ⁻¹⁾𝐖ₒᵤₜ⁽ᵏ⁾ + (𝐒ₒᵤₜ)ᵀ𝐗⁽ᵏ⁻¹⁾𝐖ᵢₙ⁽ᵏ⁾)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 𝐗⁽ᵏ⁾ = σ(𝐒ₒᵤₜ𝐗⁽ᵏ⁻¹⁾𝐖ₒᵤₜ⁽ᵏ⁾ + (𝐒ₒᵤₜ)ᵀ𝐗⁽ᵏ⁻¹⁾𝐖ᵢₙ⁽ᵏ⁾)
- en: where 𝐒ₒᵤₜ= **D**ₒᵤₜ⁻¹ᐟ² 𝐀 **D**ᵢₙ⁻¹ᐟ² and **D**ᵢₙ and **D**ₒᵤₜ represent the
    diagonal in- and out-degree matrices, respectively.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 𝐒ₒᵤₜ= **D**ₒᵤₜ⁻¹ᐟ² 𝐀 **D**ᵢₙ⁻¹ᐟ²，**D**ᵢₙ 和 **D**ₒᵤₜ 分别表示对角线的入度和出度矩阵。
- en: We also show that Dir-GNN, when iteratively applied over multiple layers, leads
    to more homophilic aggregations. Unlike other models, Dir-GNN can access the four
    2-hop matrices 𝐀²,(𝐀ᵀ)², 𝐀𝐀ᵀ and𝐀ᵀ𝐀 and learn to weigh them differently. In contrast,
    a model operating on the undirected graph has only access to 𝐀ᵤ², while models
    propagating information exclusively along in- or out-edges are limited to (𝐀ᵀ)²
    and 𝐀² respectively.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还展示了 Dir-GNN 在多层迭代应用时，能导致更具同质性的聚合。与其他模型不同，Dir-GNN 可以访问四个 2-hop 矩阵 𝐀²、(𝐀ᵀ)²、𝐀𝐀ᵀ
    和 𝐀ᵀ𝐀，并学会对它们进行不同的加权。相比之下，操作在无向图上的模型仅能访问 𝐀ᵤ²，而仅沿入边或出边传播信息的模型分别限于 (𝐀ᵀ)² 和 𝐀²。
- en: Dir-GNN, thanks to its separate aggregation of the two directions, is therefore
    the only model operating on 𝐀𝐀ᵀ and𝐀ᵀ𝐀, which we have shown to be the most homophilic
    matrices and therefore the most reliable predictor.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Dir-GNN 对两个方向的独立聚合，因此它是唯一一个在 𝐀𝐀ᵀ 和 𝐀ᵀ𝐀 上操作的模型，我们已经证明这两个矩阵是最具同质性的，因此最可靠的预测器。
- en: Experimental Results
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验结果
- en: We first compared GraphSAGE and its directed extension (Dir-SAGE) on a synthetic
    task requiring directionality information. The results confirm that only Dir-SAGE(in+out),
    with access to both in- and out-edges, is able to almost perfectly solve the task.
    The model acting on the undirected version of the graph performs no better than
    chance, while the models acting on only in- or out-edges perform similarly obtaining
    around 75% accuracy.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在一个需要方向信息的合成任务上比较了GraphSAGE及其有向扩展（Dir-SAGE）。结果确认，只有Dir-SAGE(in+out)在访问到入边和出边的情况下，能够几乎完美地解决该任务。作用于无向图版本的模型表现得与随机情况相当，而仅对入边或出边的模型表现相似，准确率约为75%。
- en: '![](../Images/61df1d1dc8d2c047317f8b4a9fdff250.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61df1d1dc8d2c047317f8b4a9fdff250.png)'
- en: When examining the performance of GraphSAGE and its Dir- extensions on a synthetic
    task requiring directionality information, only Dir-SAGE (in+out), which utilises
    information from both directions, is capable of solving the task.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查GraphSAGE及其Dir-扩展在一个需要方向性信息的合成任务上的表现时，只有利用双向信息的Dir-SAGE (in+out)才能解决该任务。
- en: We further validated our approach with an ablation study comparing GCN, GraphSAGE
    and GAT base models with their Dir- extensions. On heterophilic datasets, using
    directionality brings exceptionally large gains (10% to 20% absolute) in accuracy
    across all three base GNN models. Moreover, Dir-GNN beats state-of-the-art models
    designed especially for heterophilic graphs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步通过消融研究验证了我们的方法，将GCN、GraphSAGE和GAT基础模型与它们的Dir-扩展进行比较。在异质数据集上，使用方向性在所有三个基础GNN模型中带来了异常大的准确率提升（10%到20%绝对提升）。此外，Dir-GNN击败了专门为异质图设计的最先进模型。
- en: These results suggest that, when present, using the edge direction can significantly
    improve learning on heterophilic graphs. In contrast, discarding it is so harmful
    that not even complex architectures can make up for this loss of information.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，当存在时，使用边的方向可以显著提高异质图上的学习效果。相比之下，忽略方向性是非常有害的，即使是复杂的架构也无法弥补信息的丧失。
- en: '![](../Images/960453d1168ece3d3bc3cf0e774e1312.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/960453d1168ece3d3bc3cf0e774e1312.png)'
- en: New state-of-the-art results on heterophilic graphs, by using direction wisely.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在异质图上，通过明智地使用方向性取得了新的最先进结果。
- en: On the other hand, on homophilic datasets using directionality leaves the performance
    unchanged (or even slightly hurts). This is in line with our findings that using
    directionality as in our framework generally increases the effective homophily
    of heterophilic datasets, while leaving it almost unchanged for homophilic datasets.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在同质数据集上使用方向性则表现不变（甚至稍有负面影响）。这与我们的发现一致，即在我们的框架中使用方向性通常会增加异质数据集的有效同质性，而对同质数据集几乎没有影响。
- en: In conclusion, our paper showcases the benefit of leveraging directionality
    in GNNs, particularly in the case of heterophilic graphs. We hope that these findings
    will instigate a paradigm shift, elevating direction as a first-class citizen
    in GNNs. In short, **think twice before making your graph undirected!**
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们的论文展示了在GNN中利用方向性的好处，特别是在异质图的情况下。我们希望这些发现能引发范式转变，将方向性提升为GNN中的一等公民。简而言之，**在使图无向之前三思而后行！**
- en: '[1] The title of this post, “Direction improves graph learning,” is an intentional
    play on a previous work J. Gasteiger, S. Weissenberger, and S. Günnemann, [Diffusion
    improves graph learning](https://proceedings.neurips.cc/paper_files/paper/2019/file/23c894276a2c5a16470e6a31f4618d73-Paper.pdf)
    (2019), *NeurIPS* by one of the authors, which showed that a diffusion-based graph
    rewiring scheme (DIGL) improves the performance of GNNs in homophilic settings.
    Here, we focus on the *heterophilic* case.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 本帖标题“方向提升图学习”是对J. Gasteiger、S. Weissenberger和S. Günnemann的先前工作[Diffusion
    improves graph learning](https://proceedings.neurips.cc/paper_files/paper/2019/file/23c894276a2c5a16470e6a31f4618d73-Paper.pdf)（2019年）的故意戏仿，该工作展示了基于扩散的图重连方案（DIGL）在同质环境中提高了GNN的性能。在这里，我们关注的是*异质*情况。'
- en: '[2] [This Pytorch-Geometric routine](https://github.com/pyg-team/pytorch_geometric/blob/66b17806b1f4a2008e8be766064d9ef9a883ff03/torch_geometric/io/npz.py#L26)
    is used to load datasets stored in an npz format. It makes some directed datasets,
    such as [Cora-ML](https://github.com/pyg-team/pytorch_geometric/blob/6fa2ee7bfef32311df73ca78266c18c4449a7382/torch_geometric/datasets/citation_full.py#L99)
    and [Citeseer-Full](https://github.com/pyg-team/pytorch_geometric/blob/6fa2ee7bfef32311df73ca78266c18c4449a7382/torch_geometric/datasets/citation_full.py#L99),
    automatically undirected without any option to get the directed version instead.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [这个 Pytorch-Geometric 例程](https://github.com/pyg-team/pytorch_geometric/blob/66b17806b1f4a2008e8be766064d9ef9a883ff03/torch_geometric/io/npz.py#L26)
    用于加载存储在 npz 格式中的数据集。它将一些定向数据集，如 [Cora-ML](https://github.com/pyg-team/pytorch_geometric/blob/6fa2ee7bfef32311df73ca78266c18c4449a7382/torch_geometric/datasets/citation_full.py#L99)
    和 [Citeseer-Full](https://github.com/pyg-team/pytorch_geometric/blob/6fa2ee7bfef32311df73ca78266c18c4449a7382/torch_geometric/datasets/citation_full.py#L99)，自动转换为非定向版本，并且没有选项获取定向版本。'
- en: '[3] *Homophily* refers to the assumption that nodes with similar properties
    (typically labels and sometimes features) tend to be connected. In homophilic
    graphs, the neighbourhood of a node looks like a node itself, often allowing to
    predict the property of a node from a simple aggregation (e.g., averaging) of
    the neighbours. Graphs violating this assumption are called *heterophilic*.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] *同质性* 指的是节点具有类似属性（通常是标签，有时是特征）趋向于连接在一起的假设。在同质图中，一个节点的邻域看起来就像是一个节点本身，通常允许通过对邻居的简单聚合（例如，平均）来预测节点的属性。违反这一假设的图称为*异质性图*。'
- en: '[4] The Cora dataset was introduced by [Andrew McCallum](https://people.cs.umass.edu/~mccallum/data.html)
    in the late 1990s and is for GNNs what the MNIST Digits dataset is for CNNs.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Cora 数据集由 [Andrew McCallum](https://people.cs.umass.edu/~mccallum/data.html)
    于 1990 年代末期引入，它对 GNNs 的意义相当于 MNIST Digits 数据集对 CNNs 的意义。'
- en: '[5] E. Rossi et al., “[Edge Directionality Improves Learning on Heterophilic
    Graphs](https://arxiv.org/abs/2305.10498)” (2023) *arXiv*:2305.10498.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] E. Rossi 等人，“[边的方向性改善了在异质图上的学习](https://arxiv.org/abs/2305.10498)”（2023）*arXiv*:2305.10498。'
- en: '[6] Heterophily is not necessarily bad *per se*. Consider for example the following
    toy directed graph with three classes (blue, orange, green):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] 异质性并不一定是*本质上*不好的。例如，考虑以下具有三类（蓝色、橙色、绿色）的玩具定向图：'
- en: '![](../Images/8ab1835f1dea39d99e6cf03f99d23ecb.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ab1835f1dea39d99e6cf03f99d23ecb.png)'
- en: Looking at the *compatibility matrices* for different adjacency matrices (position
    *ij* in the compatibility matrix captures the fraction of edges from nodes with
    label *i* to nodes with label *j*, weighted according to the given adjacency matrix).
    Homophilic adjacency matrices have more mass in the diagonal of their compatibility,
    as it contains edges between nodes with the same label. While in our example both
    the directed (𝐀) and undirected (𝐀ᵤ) 1-hops are maximally heterophilic, the directed
    2-hops (𝐀𝐀ᵀ and𝐀ᵀ𝐀) are more homophilic than the undirected 2-hop (𝐀ᵤ²).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 查看不同邻接矩阵的*兼容性矩阵*（兼容性矩阵中的位置*ij* 捕获了从标签为 *i* 的节点到标签为 *j* 的节点的边的比例，按给定邻接矩阵加权）。同质邻接矩阵在其兼容性矩阵的对角线上的质量更高，因为它包含了标签相同的节点之间的边。而在我们的示例中，定向（𝐀）和非定向（𝐀ᵤ）的一跳都是极度异质的，而定向的两跳（𝐀𝐀ᵀ
    和 𝐀ᵀ𝐀）比非定向的两跳（𝐀ᵤ²）更具同质性。
- en: '[7] It is important to note that we are not the first to deal with directed
    graphs and to propose separate aggregation of in- and out-neighbours. However,
    our contribution is providing a more comprehensive treatment of directed graphs,
    which includes a general framework (Dir-GNN), overarching empirical evidence for
    the benefit of directionality, particularly in the context of heterophily, and
    a starting point to analyse the expressiveness of models for directed graphs.
    See the “Related Work” section in our paper [5] for a more thorough overview of
    related previous works.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] 重要的是要注意，我们不是第一个处理定向图并提出单独聚合入邻居和出邻居的人。然而，我们的贡献在于提供了对定向图的更全面的处理，包括一个通用框架（Dir-GNN）、关于方向性好处的全面实证证据，特别是在异质性背景下，以及分析定向图模型表达能力的起点。有关相关先前工作的更详细概述，请参阅我们论文中的“相关工作”部分
    [5]。'
- en: '[8] While several extensions of the [WL test](https://medium.com/towards-data-science/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49)
    on directed graphs have been proposed, the variant discussed by M. Grohe, K. Kersting,
    M. Mladenov, and P. Schweitzer, [Color refinement and its applications](https://www.lics.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaabbtcqu),
    in “An Introduction to Lifted Probabilistic Inference” (2021), *MIT Press*, treats
    in- and out-neighbours separately.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] 尽管已经提出了多个关于[WL测试](https://medium.com/towards-data-science/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49)在有向图上的扩展，但M.
    Grohe、K. Kersting、M. Mladenov和P. Schweitzer讨论的变体，[色彩细化及其应用](https://www.lics.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaabbtcqu)中，“An
    Introduction to Lifted Probabilistic Inference”（2021），*MIT Press*，将入邻居和出邻居分开处理。'
- en: '*We are grateful to Christopher Morris and Chaitanya K. Joshi for insightful
    discussions and for pointing us to related works. For additional articles about
    deep learning on graphs, see Michael’s* [*other posts*](https://towardsdatascience.com/graph-deep-learning/home)
    *in Towards Data Science,* [*subscribe*](https://michael-bronstein.medium.com/subscribe)
    *to his posts and* [*YouTube channel*](https://www.youtube.com/c/MichaelBronsteinGDL)*,
    get* [*Medium membership*](https://michael-bronstein.medium.com/membership)*,
    or follow him on* [*Twitter*](https://twitter.com/mmbronstein)*.*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们感谢Christopher Morris和Chaitanya K. Joshi的深刻讨论，并指出了相关工作。有关图上深度学习的更多文章，请参见Michael的*
    [*其他文章*](https://towardsdatascience.com/graph-deep-learning/home) *在Towards Data
    Science中，* [*订阅*](https://michael-bronstein.medium.com/subscribe) *他的文章和* [*YouTube频道*](https://www.youtube.com/c/MichaelBronsteinGDL)*，获取*
    [*Medium会员资格*](https://michael-bronstein.medium.com/membership)*，或在* [*Twitter*](https://twitter.com/mmbronstein)*上关注他*。'
