- en: Tired of QR codes? Build your own fiducial marker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 厌倦了二维码？自己制作一个标志性标记
- en: 原文：[https://towardsdatascience.com/tired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25?source=collection_archive---------7-----------------------#2023-11-04](https://towardsdatascience.com/tired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25?source=collection_archive---------7-----------------------#2023-11-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/tired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25?source=collection_archive---------7-----------------------#2023-11-04](https://towardsdatascience.com/tired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25?source=collection_archive---------7-----------------------#2023-11-04)
- en: '*QR codes are everywhere: want to create a more original solution? Let’s build
    our own fiducial marker and learn how to detect and decode it.*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*二维码无处不在：想要创建一个更原创的解决方案吗？让我们制作自己的标志性标记，并学习如何检测和解码它。*'
- en: '[](https://medium.com/@vincent.vandenbussche?source=post_page-----aab81cce1f25--------------------------------)[![Vincent
    Vandenbussche](../Images/b2febfc63ca0efbda0af5501f6080ab7.png)](https://medium.com/@vincent.vandenbussche?source=post_page-----aab81cce1f25--------------------------------)[](https://towardsdatascience.com/?source=post_page-----aab81cce1f25--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----aab81cce1f25--------------------------------)
    [Vincent Vandenbussche](https://medium.com/@vincent.vandenbussche?source=post_page-----aab81cce1f25--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vincent.vandenbussche?source=post_page-----aab81cce1f25--------------------------------)[![Vincent
    Vandenbussche](../Images/b2febfc63ca0efbda0af5501f6080ab7.png)](https://medium.com/@vincent.vandenbussche?source=post_page-----aab81cce1f25--------------------------------)[](https://towardsdatascience.com/?source=post_page-----aab81cce1f25--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----aab81cce1f25--------------------------------)
    [Vincent Vandenbussche](https://medium.com/@vincent.vandenbussche?source=post_page-----aab81cce1f25--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6c53f1364ba9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25&user=Vincent+Vandenbussche&userId=6c53f1364ba9&source=post_page-6c53f1364ba9----aab81cce1f25---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----aab81cce1f25--------------------------------)
    ·15 min read·Nov 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faab81cce1f25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25&user=Vincent+Vandenbussche&userId=6c53f1364ba9&source=-----aab81cce1f25---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6c53f1364ba9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25&user=Vincent+Vandenbussche&userId=6c53f1364ba9&source=post_page-6c53f1364ba9----aab81cce1f25---------------------post_header-----------)
    发布于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----aab81cce1f25--------------------------------)
    · 15分钟阅读 · 2023年11月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faab81cce1f25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25&user=Vincent+Vandenbussche&userId=6c53f1364ba9&source=-----aab81cce1f25---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faab81cce1f25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25&source=-----aab81cce1f25---------------------bookmark_footer-----------)![](../Images/034b82301b9043a84d0d625806359cd3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faab81cce1f25&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftired-of-qr-codes-build-you-own-fiducial-marker-aab81cce1f25&source=-----aab81cce1f25---------------------bookmark_footer-----------)![](../Images/034b82301b9043a84d0d625806359cd3.png)'
- en: Photo by [Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Michael Dziedzic](https://unsplash.com/@lazycreekimages?utm_source=medium&utm_medium=referral)提供，发布于[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: In this post, let’s learn how to build a new [fiducial marker](https://en.wikipedia.org/wiki/Fiducial_marker)
    and how to detect it by training an object detection model. Then, we will learn
    how to decode our marker using image processing techniques.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，让我们学习如何制作一个新的[标志性标记](https://en.wikipedia.org/wiki/Fiducial_marker)以及如何通过训练对象检测模型来检测它。然后，我们将学习如何使用图像处理技术解码我们的标记。
- en: 'Let’s break it down to three steps:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其分解为三个步骤：
- en: Creating a fiducial marker
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建标志性标记
- en: Detecting the marker in an image
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像中检测标记
- en: Decoding the marker
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码标记
- en: Creating a fiducial marker
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建基准标记
- en: There are a lot of fiducial markers for computer vision already existing, the
    most famous being the QR code. There are other QR codes, more or less used, more
    or less robust, that can be used too. Below is a non-exhaustive list of codes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 目前已经存在很多用于计算机视觉的基准标记，最著名的是二维码。还有其他二维码，使用程度和鲁棒性各不相同，也可以使用。下面是一个不完全的代码列表。
- en: '![](../Images/81730a80093a1d4d5ab082f253112dff.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81730a80093a1d4d5ab082f253112dff.png)'
- en: Some of the most famous fiducial markers with their names and creation dates
    (source [https://www.mdpi.com/1424-8220/21/16/5407](https://www.mdpi.com/1424-8220/21/16/5407),
    under CC-BY license)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最著名的基准标记及其名称和创建日期（来源 [https://www.mdpi.com/1424-8220/21/16/5407](https://www.mdpi.com/1424-8220/21/16/5407)，在CC-BY许可下）
- en: 'As we can see in the above image, fiducial markers can be quite different but
    they all have the same purpose: containing easily decodable information.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，基准标记可以有很大不同，但它们都有相同的目的：包含易于解码的信息。
- en: What is a good fiducial marker?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是好的基准标记？
- en: 'Ideally, a good fiducial marker has the following properties:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，一个好的基准标记具有以下属性：
- en: 'Easy to detect: before being able to decode a marker, you have to be able to
    accurately detect it in an image'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于检测：在能够解码标记之前，你必须能够准确地在图像中检测到它。
- en: 'Easy to decode: it has to be easy to decode a marker and without any ambiguity
    (i.e., a decoded marker yields a unique value)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于解码：标记必须易于解码且没有任何歧义（即，解码后的标记产生唯一的值）
- en: Based on those properties, let’s now build our very own marker from the existing
    ones.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这些属性，现在让我们从现有的标记中构建我们自己的标记。
- en: Designing our fiducial marker
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计我们的基准标记
- en: 'I personally like the RUNE-tag (for very arbitrary reasons):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人喜欢 RUNE 标记（出于非常随意的理由）：
- en: The circular shape and dots have something that makes it softer than square
    markers
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 圆形和点的形状使其比方形标记更柔和
- en: It seems very distinguishable, making it most likely easy to detect for an object
    detection model
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这看起来非常明显，使得对象检测模型很可能容易检测到。
- en: 'It is easily customizable: we can tweak the number of dots per circle as well
    as the number of circles to make it suit our needs and expected aesthetics'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它很容易自定义：我们可以调整每个圆圈上的点数以及圆圈的数量，以满足我们的需求和期望的美学。
- en: 'But it is not flawless in its original form: two rotated markers may or may
    not lead to the same decoding.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但它在原始形式下并不完美：两个旋转的标记可能会导致相同或不同的解码结果。
- en: '![](../Images/1ea0d86b63988b544c57bfad0ce0d0c2.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ea0d86b63988b544c57bfad0ce0d0c2.png)'
- en: 'The only difference between these two tags are a 90° rotation: they can’t be
    discriminated. Image by author.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个标签之间的唯一区别是90°的旋转：它们无法被区分。图像作者提供。
- en: 'To mitigate this issue, we will add one condition to the marker: one and only
    one sector has no black dots, as shown below.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻这个问题，我们将对标记添加一个条件：一个且只有一个扇区没有黑点，如下所示。
- en: '![](../Images/b2b822cdc907f2af757ccecc8918c18b.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b2b822cdc907f2af757ccecc8918c18b.png)'
- en: A tag with only one row with no black dot, allowing to solve the rotation problem.
    Image by author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一个只有一行且没有黑点的标签，可以解决旋转问题。图像作者提供。
- en: 'Such a marker can be decoded easily: let’s consider that each sector can take
    three possible values: 0, 1 or 2 depending on the three possible cases:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的标记可以很容易解码：假设每个扇区可以有三种可能的值：0、1或2，具体取决于三种可能的情况：
- en: 'A small black dot: 0'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个小黑点：0
- en: 'A large black dot: 1'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个大黑点：1
- en: 'Both dots: 2'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个点：2
- en: '![](../Images/8d0fdf64496a6f6efff68dd92e2c837d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d0fdf64496a6f6efff68dd92e2c837d.png)'
- en: 'A representation of a few sectors: the sector 0 is the only one with no black
    dots, while other always have at least one black dot. Image by author.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一些扇区的表示：扇区0是唯一一个没有黑点的，而其他扇区总是至少有一个黑点。图像作者提供。
- en: More generally speaking, considering a marker with *C* circle layers, a sector
    can take up to 2ᶜ−1 values (because having no black dots is reserved for the sector
    0).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，考虑一个具有 *C* 圆圈层的标记，一个扇区可以有最多 2ᶜ−1 种值（因为没有黑点的情况保留给扇区 0）。
- en: At the end, for a marker with *d+1* dots, the number of possible combinations
    is equal to (2ᶜ— 1)ᵈ. For a 2 circle layers and 20 dots per circle tag, it means
    3¹⁹ ~ 1.16 billion possible values.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，对于一个有 *d+1* 个点的标记，可能的组合数等于 (2ᶜ— 1)ᵈ。对于一个2个圆圈层和每个圆圈20个点的标签，这意味着 3¹⁹ ~ 11.6亿个可能值。
- en: Building our fiducial marker
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建我们的基准标记
- en: Let’s explain here a piece of code used to generate a random fiducial marker
    image.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们解释一段用于生成随机基准标记图像的代码。
- en: Gist of the method used to generate random tag. See link to fully working code
    at the end of the article.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 生成随机标签的方法概要。有关完整工作的代码链接，请参见文章末尾。
- en: As you can see, the first step is to generate a list of random values. Considering
    *C* the number of circle layers and *d+1* the number of dots per circle, we generate
    a list of *d* values between 0 and 2ᶜ−1 using numpy.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，第一步是生成一个随机值列表。考虑到*C*为圆圈层数和*d+1*为每层圆圈的点数，我们使用numpy生成一个在0到2ᶜ−1之间的*d*个值的列表。
- en: 'Based on this list of random values, we compute the dot values: 0 for a white
    dot, 1 for a black dot. Finally, we draw the final tag, given a pixel size, and
    we save the output as an image. Of course, a link to the fully working code repository
    is available and documented at the end of the article.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这个随机值列表，我们计算点值：0表示白色点，1表示黑色点。最后，我们绘制最终标签，给定一个像素大小，并将输出保存为图像。当然，完整的代码库链接在文章末尾提供并记录。
- en: 'We have chosen a marker design and we know how to generate such a marker. To
    be able to use such a marker in real conditions, we need a solution able to detect
    and decode such a marker in an image. This is really simple, sequential 2-step
    pipeline:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了一个标记设计，并知道如何生成这样的标记。为了能够在实际条件下使用这样的标记，我们需要一个能够在图像中检测和解码这种标记的解决方案。这非常简单，分为两个步骤：
- en: Detecting the marker with object detection
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用目标检测检测标记
- en: Decoding the detected marker
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码检测到的标记
- en: Let’s now go to the first step of this pipeline.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们进入这个管道的第一步。
- en: Detecting the marker
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测标记
- en: So, the first step is to detect the presence and location of a marker in a given
    image. To do so, there are many object detection models out there. We will use
    here a [YOLOv8 model](https://github.com/ultralytics/ultralytics), which is really
    easy to train and use in a production environment.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先的步骤是检测给定图像中标记的存在和位置。为此，有许多目标检测模型。我们将在这里使用一个[YOLOv8模型](https://github.com/ultralytics/ultralytics)，它非常容易训练和在生产环境中使用。
- en: 'But before being able to actually train an object detection model, we need
    data: images from different backgrounds and environments containing tags from
    different zoom levels and perspectives.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 但在实际训练目标检测模型之前，我们需要数据：来自不同背景和环境的图像，包含来自不同缩放级别和视角的标签。
- en: Instead of collecting and labeling data, which can be very time consuming, we
    will here generate and use synthetic data to train a model on this data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将生成和使用合成数据来训练模型，而不是收集和标记数据，这可能非常耗时。
- en: Generating the data
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成数据
- en: 'We only need two ingredients to generate synthetic data to train an object
    detection model:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要两个要素来生成合成数据，以训练一个目标检测模型：
- en: Various background images, free of rights, that can be taken from [Unsplash](https://unsplash.com)
    for example
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种免费使用的背景图像，例如可以从[Unsplash](https://unsplash.com)获取。
- en: Marker images, that we will randomly generate on the fly
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将随机生成的标记图像
- en: With those two ingredients, all we need is to apply some augmentation using
    [Albumentations](https://albumentations.ai/) to generate a lot of unique, synthetically
    generated images with their associated labels.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这两个要素，我们所需要做的就是使用[Albumentations](https://albumentations.ai/)进行一些增强，生成大量独特的合成图像及其相关标签。
- en: Let’s provide here a piece of code allowing to generate images, given a path
    to background images and marker features such as the number of circle layers and
    dots per circle.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 下面提供了一段代码，允许生成图像，给定背景图像的路径和标记特征，如圆圈层数和每层圆圈中的点数。
- en: Gist of the code used to generate synthetic data. See link to fully working
    code at the end of the article.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 生成合成数据的代码概要。有关完整工作的代码链接，请参见文章末尾。
- en: 'This is quite a long code, feel free to dig in, but in a few words it does
    the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一段相当长的代码，随意深入了解，但简单来说，它做了以下几件事：
- en: Generate a random tag, the image boundaries are the bounding box labels
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成一个随机标签，图像边界是边界框标签。
- en: Apply transformations such as affine, perspective or scale transformations,
    thanks to Albumentations
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用如仿射、透视或缩放等变换，感谢Albumentations。
- en: Randomly insert this tag in a randomly selected background image
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机将该标签插入到随机选择的背景图像中
- en: Do it as many times as needed
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需要多次执行
- en: With this method, we can easily generate a large enough dataset with hundreds
    or thousands of images. Below are a few examples of the created images with labels
    as red bounding boxes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们可以轻松生成足够大的数据集，包含数百或数千张图像。以下是一些创建的图像示例，带有红色边界框标签。
- en: '![](../Images/37c5b7f6a6bfa0839344af22ded275dd.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37c5b7f6a6bfa0839344af22ded275dd.png)'
- en: A few generated images with the labels as red bounding boxes. Image by author.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一些生成的图像，其中标签为红色边框。图像由作者提供。
- en: As we can see, the generated images are quite various, as we have backgrounds
    and augmentations added such as blurring and perspective.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，生成的图像相当多样，因为我们添加了背景和增广处理，如模糊和透视。
- en: Of course, we do not use the same background images for the train and validation
    sets, so that the model evaluation remains as unbiased as possible.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们不会对训练集和验证集使用相同的背景图像，以确保模型评估尽可能不受偏见影响。
- en: A python script allowing to generate images and associated labels in the right
    folders for YOLO model training is available in the github repository.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一种允许在正确的文件夹中生成图像及其相关标签的 Python 脚本已在 GitHub 仓库中提供。
- en: Training and evaluating the model
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和评估模型
- en: Using the previously created dataset, we can now train an object detection model
    on this data. Thanks to the YOLOv8 library, just a few lines of code are needed
    to train a new model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用之前创建的数据集，我们现在可以在这些数据上训练一个目标检测模型。借助 YOLOv8 库，只需几行代码即可训练一个新模型。
- en: Code gist for YOLOv8 small model training over 100 epochs. See link to fully
    working code at the end of the article.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8 小模型在 100 个周期上的训练代码 gist。有关完整代码的链接见文章末尾。
- en: As we can see, all we have to do is to instantiate a model and train it on the
    data. After 100 epochs (or less if you hit early stopping condition while training,
    as I did after about 80 epochs here), I got a mAP@50 of about 0.5, as we can see
    from the generated results below.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们只需要实例化一个模型并在数据上进行训练。经过 100 个周期（如果在训练过程中遇到早停条件，则可以更少，比如我在这里大约 80 个周期后），我得到了约
    0.5 的 mAP@50，如下面生成的结果所示。
- en: '![](../Images/2301eed6eee7f8854aef835726b31a70.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2301eed6eee7f8854aef835726b31a70.png)'
- en: Results generated by the YOLOv8 library. The resulting mAP@50 is about 0.5\.
    Image by author.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8 库生成的结果。结果的 mAP@50 约为 0.5。图像由作者提供。
- en: While the results are far from being perfect, they are good enough for a dataset
    trained with only synthetic data. Let’s now test this model on real conditions
    with a webcam feed.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管结果远未完美，但对于仅使用合成数据训练的数据集来说已经足够好。现在让我们用网络摄像头的实况测试这个模型。
- en: 'To do so, we can use the code in the following gist:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们可以使用以下 gist 中的代码：
- en: Code gist for YOLOv8 model inference on webcam feed. See link to fully working
    code at the end of the article.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOv8 模型在网络摄像头实况上的推理代码 gist。有关完整代码的链接见文章末尾。
- en: 'This code is quite straightforward:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码相当直接：
- en: We load the model and get the webcam feed
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们加载模型并获取网络摄像头的实况
- en: For each new image, we compute the model inference and display any detected
    bounding box
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每张新图像，我们计算模型推理并显示任何检测到的边界框
- en: We stop the feed upon hitting the escape key
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当按下 Escape 键时，我们停止实况
- en: I ran this code with an image of a marker on my phone, and as we can see in
    the image below it worked pretty well.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我用我手机上的标记图像运行了这段代码，正如我们在下面的图像中看到的那样，它效果非常好。
- en: '![](../Images/9e394c5ad09069b6ba25a7128bd9354f.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e394c5ad09069b6ba25a7128bd9354f.png)'
- en: Detection result of a YOLO model trained on synthetic data only, tested on my
    webcam feed. Image by author.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 仅在合成数据上训练的 YOLO 模型的检测结果，在我的网络摄像头实况上测试。图像由作者提供。
- en: While it does not detect perfectly the marker in all configurations, it worked
    good enough for a model trained on synthetic data only. To get better results,
    I believe the data augmentation could be tweaked a bit, and of course real, labeled
    data would be very helpful.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然它在所有配置中并不能完美地检测标记，但对于仅使用合成数据训练的模型来说已经足够好。为了获得更好的结果，我相信可以稍微调整数据增广，当然真实的标记数据将会非常有帮助。
- en: 'Now that we have the first part of the pipeline done, let’s move to the second
    step: tag decoding.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们完成了管道的第一部分，让我们进入第二步：标签解码。
- en: Decoding the marker
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解码标记
- en: We now have fully working codes to both generate and detect our new fiducial
    marker.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有了生成和检测新基准标记的完全可用的代码。
- en: Once you can detect a tag in an image, next step is of course to decode it.
    Let’s start from a cropped image of a detected marker, thanks to our previously
    trained model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你可以在图像中检测到标签，下一步当然是解码它。让我们从经过我们之前训练的模型检测到的标记的裁剪图像开始。
- en: '![](../Images/8f7046a6f75b011ae8d3556f15c66a92.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8f7046a6f75b011ae8d3556f15c66a92.png)'
- en: Cropped image from our object detection model. Let’s decode this marker.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 来自我们目标检测模型的裁剪图像。让我们解码这个标记。
- en: 'I developed a decoding algorithm made of the following steps:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我开发了一个由以下步骤组成的解码算法：
- en: Blob detection to detect the dots
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斑点检测以检测点
- en: Outer circle detection and ellipse fitting
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外圆检测和椭圆拟合
- en: Dots selection for homography computation
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于单应性计算的点选择
- en: Homography matrix computation and image unwarping
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单应性矩阵计算和图像展开
- en: And finally, marker decoding
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，进行标记解码
- en: 'The main idea is the following: as soon as I can match a detected marker with
    a reference marker (knowing the number of circle layers and dots per circle),
    I can decode it quite easily by checking the image is white or black. But to do
    so, I first need to unwarp the image to make it match the reference marker.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思路如下：只要我能将检测到的标记与参考标记匹配（知道每圈的圆层数和每圈的点数），我就可以通过检查图像是白色还是黑色来相对容易地解码它。但为了做到这一点，我首先需要将图像展开以使其与参考标记匹配。
- en: Let’s go through these steps together.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一起回顾这些步骤。
- en: Detecting the dots
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测点
- en: The first task is to detect the dots in the image detected by the YOLO model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先任务是检测 YOLO 模型检测到的图像中的点。
- en: 'From the input cropped image, we will apply the following list of image processings
    using [OpenCV](https://opencv.org/):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从输入的裁剪图像中，我们将使用 [OpenCV](https://opencv.org/) 应用以下图像处理列表：
- en: Convert the image to grayscale
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像转换为灰度图
- en: Binarize the image with [Otsu’s algorithm](https://en.wikipedia.org/wiki/Otsu%27s_method)
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 [Otsu 算法](https://en.wikipedia.org/wiki/Otsu%27s_method) 二值化图像
- en: Find the dots with a blob detector
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用斑点检测器查找点
- en: 'This is what the code in the following gist does:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 gist 中的代码完成了这些操作：
- en: Code to detect the dots from the cropped image. See link to fully working code
    at the end of the article.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 从裁剪图像中检测点的代码。请查看文章末尾的链接以获取完整的代码。
- en: As we can see, a lot of parameters are set for the blob detector, such as a
    minimum and maximum area, as well as a minimum circularity, in order maximize
    as much as possible the effective detection of actual marker dots. It took quite
    some time to fine-tune these parameters, but feel free to play with those.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，为了最大化实际标记点的有效检测，设置了许多参数，如最小和最大面积，以及最小圆度。这些参数的微调花费了不少时间，但可以随意调整这些参数。
- en: Using this code on our input cropped image yields the following blob detection.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此代码处理我们的裁剪图像会得到以下的斑点检测结果。
- en: '![](../Images/337b88033b7cdb78dc1bba4c09947af0.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/337b88033b7cdb78dc1bba4c09947af0.png)'
- en: 'Resulting blob detection on the input cropped image: the dots are well detected.
    Image by author.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 输入裁剪图像上的斑点检测结果：点检测得很好。图像作者提供。
- en: As we can see, the dots are well detected. Next step is to detect the outer
    circle.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，点检测得很好。下一步是检测外圆。
- en: Detecting the outer circle
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检测外圆
- en: Now, we need to detect the outermost circle layer (no matter the number of circles
    in a tag, this solution would generalize). This will allow us to then find the
    dots on the outer circle, so that we can finally unwarp the image.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要检测最外层的圆圈（无论标签中的圆圈数量，这种解决方案都可以推广）。这将允许我们找到外圆上的点，以便我们最终展开图像。
- en: 'To compute the ellipse, all we do is keep the larger dots (named *keypoints*
    in OpenCV) and fit an ellipse equation out of those points. This is what does
    the following code:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算椭圆，我们所做的就是保留较大的点（在 OpenCV 中称为*关键点*），并从这些点拟合椭圆方程。这就是以下代码的功能：
- en: Code allowing to compute the ellipse equation from the detected dots. Note that
    this code always computes a center estimation, that will be useful in a few steps.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 代码允许从检测到的点计算椭圆方程。请注意，此代码始终计算一个中心估计，这在接下来的几个步骤中会很有用。
- en: 'When I apply this code and display the detected points as a scatter plot on
    which I display the fitted ellipse, I get the following result:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当我应用此代码并将检测到的点作为散点图展示，并展示拟合的椭圆时，得到如下结果：
- en: '![](../Images/886b210336c3c6aa9b391ed1b88d9f1c.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/886b210336c3c6aa9b391ed1b88d9f1c.png)'
- en: Scatter plot of the detected blobs and the fitted ellipse of the outermost circle.
    Image by author.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 检测到的斑点的散点图和最外圈的拟合椭圆。图像作者提供。
- en: As we can see, the fitted ellipse is well defined and consistent with the dots
    positions. Note that, since we are fitting an ellipse, no matter how deformed
    is the detected marker because of perspective, it would be able to work.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，拟合的椭圆定义明确且与点的位置一致。请注意，由于我们在拟合椭圆，无论检测到的标记由于透视而变形程度如何，它都能正常工作。
- en: 'Now we need to find the dots that are actually on this ellipse. It is quite
    easy: we only need to find the dots locations that fulfill the ellipse equation
    (with a given threshold) that we just computed. This is done with the following
    piece of code:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要找到实际上在这个椭圆上的点。这很简单：我们只需找到满足我们刚刚计算出的椭圆方程（带有给定阈值）的点位置即可。这是通过以下代码实现的：
- en: Gist of the code used return keypoints on the ellipse. See link to fully working
    code at the end of the article.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 用于返回椭圆上关键点的代码要点。请参见文章末尾的链接以获取完整代码。
- en: Now that we know where are the dots, and which ones are on the outermost circle,
    we can use them to compute the homography matrix and unwarp the image.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道点的位置，以及哪些点在最外圈上，我们可以使用这些点来计算单应性矩阵并解扭曲图像。
- en: Selecting dots for homography computation
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为单应性计算选择点
- en: The goal now is to find a few matching points with the reference image, in order
    to compute the homography matrix.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的目标是找到一些与参考图像匹配的点，以便计算单应性矩阵。
- en: '![](../Images/7775a1be9adaed2f3bb45fc1bd005bf7.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7775a1be9adaed2f3bb45fc1bd005bf7.png)'
- en: Image of a reference tag, with all dots filled. Image by author.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 参考标签的图像，所有点都填充。作者提供的图像。
- en: Based on this reference image above, we need to unwarp the detected blob with
    the right homography matrix.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上面的参考图像，我们需要使用正确的单应性矩阵来解扭曲检测到的斑点。
- en: In order to compute the homography matrix, we can simply use the OpenCV function
    *findHomography*. This function needs as input at least 4 matching points in the
    reference image and the input image, so that it can find the homography matrix.
    This homography matrix would then allow us to unwarp the detected image and match
    it with the reference.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算单应性矩阵，我们可以简单地使用 OpenCV 函数*findHomography*。此函数需要参考图像和输入图像中至少4个匹配点作为输入，以便找到单应性矩阵。这个单应性矩阵将允许我们解扭曲检测到的图像，并与参考图像匹配。
- en: 'From our detected blobs on the outermost circle, it is impossible to know where
    the dots were on the original reference image. So we will just select the longest
    chain of nearest neighboors dots in the outermost circle, so that we can match
    them with the reference. To do so, there are two steps:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们检测到的最外圈上的斑点来看，无法确定这些点在原始参考图像上的位置。因此，我们将选择最外圈中最近邻点的最长链条，以便与参考图像匹配。为此，有两个步骤：
- en: Computing the adjacency matrix, so that we know, for each dot, what are its
    adjacent dots (if any)
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算邻接矩阵，以便我们知道每个点的相邻点（如果有的话）
- en: From the adjacency matrix, computing the longest chain of adjacent dots
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从邻接矩阵中计算相邻点的最长链条
- en: 'For the first step, we can use the following code:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一步，我们可以使用以下代码：
- en: Code for the adjacency matrix computation. See link to fully working code at
    the end of the article.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 计算邻接矩阵的代码。请参见文章末尾的链接以获取完整代码。
- en: 'This code will compute the adjacency matrix, as a python dict: for each existing
    dot index on the outermost circle as a key, a list of found adjacent dots indexes
    is the value.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将计算邻接矩阵，作为一个 Python 字典：对于最外圈上每个现有的点索引作为键，相应的值是找到的相邻点索引列表。
- en: 'From this adjacency matrix, it is now quite easy to find the longest chain
    of adjacent neighbors. To do so, I used the following code:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个邻接矩阵中，现在很容易找到最长的相邻点链条。为此，我使用了以下代码：
- en: Gist of the code used for longest chain of adjacent dots computation. See link
    to fully working code at the end of the article.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 用于计算相邻点最长链条的代码要点。请参见文章末尾的链接以获取完整代码。
- en: This code will efficiently find the longest chain of adjacent dots, and return
    the list of their indexes.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将高效地找到相邻点的最长链条，并返回它们的索引列表。
- en: 'If we have at least 4 dots in this output, we can theoretically compute the
    homography matrix. Unfortunately, in most cases it won’t be really accurate, as
    the dots are almost on the same line, not allowing the compute accurately the
    homography matrix. To solve this problem, we will add one more dot: a symmetrically
    placed dot with respect to the center: this will give a much more accurate homography
    computation.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在这个输出中至少有4个点，我们可以理论上计算单应性矩阵。不幸的是，在大多数情况下，这不会非常准确，因为这些点几乎在同一条线上，无法准确计算单应性矩阵。为了解决这个问题，我们将添加一个额外的点：一个相对于中心对称放置的点：这将使单应性计算更准确。
- en: 'We can find a symmetrical dot with respect to the center (computed while doing
    the ellipse fitting) with the following code:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用以下代码找到相对于中心的对称点（在进行椭圆拟合时计算得到）：
- en: Code to find a symmetric dot, given the input longest chain and all the keypoints
    on ellipse. See link to fully working code at the end of the article.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 找到对称点的代码，给定输入的最长链和椭圆上的所有关键点。请参见文章末尾的链接以获取完整的工作代码。
- en: 'Note that since we are on an ellipse, using the center estimation to find the
    symmetrical point to a given dot is not a 100% reliable method: it may output
    a wrong dot. This is something that we will keep in mind of when computing the
    decoding.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于我们处于椭圆上，使用中心估计来找到给定点的对称点并不是100%可靠的方法：它可能会输出错误的点。这一点在计算解码时我们会记住。
- en: At the end, we end up with the results in the following image, where the blue
    circles are the ones of the longest chain, and the red ones are the supposed symmetrical
    dots (one of them being part of the longest chain).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们得到以下图像中的结果，其中蓝色圆圈是最长链上的点，红色圆圈是预期的对称点（其中一个是最长链的一部分）。
- en: '![](../Images/e99b0f52b75c4382d2b81c39069ee66c.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e99b0f52b75c4382d2b81c39069ee66c.png)'
- en: Result of the dots selection. In blue circle are the longest chain dots (except
    the left most). In red circle are the detected symmetrical dots. The central red
    dot is the estimated ellipse center. Image by author.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 点选择的结果。蓝色圆圈中的点是最长链上的点（除了最左侧的点）。红色圆圈中的点是检测到的对称点。中央的红点是估计的椭圆中心。图片由作者提供。
- en: As we can see, we indeed selected the chain of 7 adjacent dots. and we selected
    another dot to be the symmetrical one of the leftmost dot in the chain.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们确实选择了7个相邻点的链，并选择了另一个点作为链中最左侧点的对称点。
- en: Unwarping the image
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解开图像
- en: 'So now that we have selected a few dots in the input image, let’s get the matching
    dots in the reference image and compute the homography matrix. To do so, we need
    the following inputs:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经在输入图像中选择了一些点，接下来让我们在参考图像中找到匹配的点并计算单应性矩阵。为此，我们需要以下输入：
- en: 'The positions of the selected dots in the cropped image: that’s what we just
    computed'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 裁剪图像中所选点的位置：这是我们刚刚计算的内容
- en: 'The equivalent positions of these dots in the reference image: that needs to
    be computed, knowing the reference marker'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些点在参考图像中的等效位置：需要计算，知道参考标记
- en: To compute these points locations, we will use the following code, allowing
    to compute the dots locations.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算这些点的位置，我们将使用以下代码，允许计算点的位置。
- en: Gist of the code used to generate the reference points locations for homography
    computation. See link to fully working code at the end of the article.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成参考点位置以计算单应性矩阵的代码要点。请参见文章末尾的链接以获取完整的工作代码。
- en: 'Note that we have given one more degree of freedom with a parameter named *symmetry_index_offset*:
    this will allow to handle possible errors in the symmetrical dot computation,
    by adding an offset to the symmetrical dot location.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们通过一个名为*symmetry_index_offset*的参数增加了一个自由度：这将允许处理对称点计算中的可能错误，通过将偏移量添加到对称点的位置。
- en: 'With the right dots locations in both the cropped image and the reference image,
    we can now compute the homography matrix and unwarp the image. To make sure we
    don’t make mistakes with the symmetrical dot, we will do that for an offset value
    in the range [-2, 2] with a step of 1, as we can see in the code snippet below:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 通过正确的点位置在裁剪图像和参考图像中，我们现在可以计算单应性矩阵并解开图像。为了确保我们在对称点上没有犯错误，我们将在[-2, 2]的范围内以1为步长进行计算，如下面的代码片段所示：
- en: Gist of the code for homography computation and image unwarping. See link to
    fully working code at the end of the article.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 单应性矩阵计算和图像解开的代码要点。请参见文章末尾的链接以获取完整的工作代码。
- en: What we do here is that we just compute the homography matrix with the OpenCV
    *functionfindHomography* and then unwarp the image with *warpPerspective*. And
    we do so for 5 values of offset, so that we end up with 5 unwarped images.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里做的是用OpenCV的*functionfindHomography*计算单应性矩阵，然后用*warpPerspective*解开图像。我们对5个偏移值执行此操作，以便得到5张解开的图像。
- en: 'The resulting images are the following:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图像如下：
- en: '![](../Images/a0d545aad406c7d1835421d4a0824e65.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0d545aad406c7d1835421d4a0824e65.png)'
- en: Resulting unwarped images. Only the one with a -1 offset is correctly unwarped.
    Image by author.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 结果解开的图像。只有-1偏移量的图像正确解开。图片由作者提供。
- en: 'As we can see, depending on the offset the unwarping result is quite different.
    Even if it’s quite easy with a visual inspection to understand that the offset
    of -1 is the right one, we want this check to be automated. We will handle this
    is in the next step: the actual marker decoding.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，根据偏移量，未校正结果相差甚远。尽管通过视觉检查很容易理解 -1 的偏移量是正确的，但我们希望将这一检查自动化。我们将在下一步中处理这个问题：实际的标记解码。
- en: Decoding the marker
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解码标记
- en: From a given unwarped image, the last step is finally to decode the marker.
    We are really close, and this step is probably the easiest.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 从给定的未校正图像开始，最后一步是解码标记。我们非常接近，这一步可能是最简单的。
- en: 'All we have to do is to check, for each expected dot location, the color of
    the unwarped image. Since the image went through an Otsu binarization, this is
    quite straightforward. We will just check if there is any black pixel in an area
    of 3x3 pixels around an expected dot location: if yes, then there is a dot; if
    no, then there is no dot.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的就是检查每个预期点的位置，未校正图像的颜色。由于图像经过了 Otsu 二值化，这非常简单。我们只需检查预期点位置周围 3x3 像素区域内是否有黑色像素：如果有，则存在点；如果没有，则不存在点。
- en: Gist of the code used compute the list code from the unwarped image. See link
    to fully working code at the end of the article.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 计算未校正图像的列表代码所使用的代码概要。请参阅文章末尾的完整代码链接。
- en: This is what the above code does basically. Then depending on the position,
    we assign a value. So that the output of this function is just a list of values.
    Finally, we look for a -1 value (meaning the expected sector with no black dot,
    check the section *Designing our fiducial marker* for a reminder about that),
    and rearrange the array to put it at the last index location.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上是上面代码所做的。然后根据位置，我们分配一个值。这样，这个函数的输出就是一个值的列表。最后，我们寻找一个 -1 值（表示预期的区域没有黑点，请参考
    *设计我们的基准标记* 部分以获取相关提醒），并重新排列数组，将其放在最后一个索引位置。
- en: 'For example, here are the computed codes for each of the 5 unwarped images:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是每个未校正图像计算出的代码：
- en: 'Offset -2: [0, 2, 0, -1, 1, -1, 0, 0, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 0, -1]'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '偏移量 -2: [0, 2, 0, -1, 1, -1, 0, 0, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 0, -1]'
- en: 'Offset -1: [2, 2, 2, 0, 2, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 2, 2, 0, -1]'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '偏移量 -1: [2, 2, 2, 0, 2, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 2, 2, 0, -1]'
- en: 'Offset 0: [0, -1, 2, 2, 0, 0, -1, 0, 0, -1, 0, 1, 2, 2, 0, 2, 2, 2, 0, -1]'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '偏移量 0: [0, -1, 2, 2, 0, 0, -1, 0, 0, -1, 0, 1, 2, 2, 0, 2, 2, 2, 0, -1]'
- en: 'Offset 1: [-1, 2, 2, 2, 2, 0, -1, -1, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, -1]'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '偏移量 1: [-1, 2, 2, 2, 2, 0, -1, -1, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, -1]'
- en: 'Offset 2: [-1, 2, 1, 2, 1, 0, 1, -1, -1, -1, -1, 0, 0, 0, 2, 2, 0, 0, 2, -1]'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '偏移量 2: [-1, 2, 1, 2, 1, 0, 1, -1, -1, -1, -1, 0, 0, 0, 2, 2, 0, 0, 2, -1]'
- en: 'As we can see, there is only one image with one and only one -1 value, at the
    last index location: the unwarped image using an offset of -1\. This is our well
    unwarped image (as we could see with a visual inspection), allowing to actually
    decode the marker.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，只有一张图像在最后一个索引位置只有一个 -1 值：使用 -1 偏移量的未校正图像。这是我们已经很好地校正的图像（如视觉检查所见），能够实际解码标记。
- en: 'This code list being unique for each possible marker, you can either stop here,
    or compute a unique integer value. A unique value can be computed really easily
    with the following code snippet:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个代码列表对于每个可能的标记都是唯一的，你可以在这里停止，或者计算一个唯一的整数值。可以通过以下代码片段很容易地计算出唯一值：
- en: Gist of the code used compute the decoded final value from the list code. See
    link to fully working code at the end of the article.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 计算解码最终值所使用的代码概要。请参阅文章末尾的完整代码链接。
- en: In our case, this would return -1 for all the wrongly unwarped images, and a
    value of 377667386 for the actual marker.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，这将返回 -1 对于所有错误校正的图像，并返回 377667386 对于实际标记。
- en: That’s it, we went all the way from an input image to an actual unique code!
    Let’s now recap and reflect on the limitations of what we did.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样，我们从输入图像一路走到了实际的唯一代码！现在让我们总结一下，并反思我们所做的工作中的局限性。
- en: Creating a full pipeline
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个完整的流程
- en: Now that we have all the building blocks, we just have to put them together
    to get a nice, custom fiducial marker decoder, that can replace a QR code!
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有所有的构建模块，我们只需要将它们组合起来，以获得一个漂亮的、自定义的基准标记解码器，它可以替代 QR 代码！
- en: 'As a recap, here are the steps in a fully working pipeline:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，以下是一个完整工作流程中的步骤：
- en: From an input image, detect the markers with object detection
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从输入图像中，使用对象检测来检测标记
- en: For each object detected, crop the image and do the next steps
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个检测到的对象，裁剪图像并进行下一步
- en: Detect the dots with Otsu binarization and blob detection
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Otsu 二值化和斑点检测来检测点
- en: Find the outermost dots with ellipse fitting
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用椭圆拟合找到最外层的点
- en: Compute the homography matrix using the longest chain of nearest neighboors
    dots and a symmetrical dot
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最近邻点和对称点的最长链计算同质变换矩阵
- en: Unwarp the image using the homography matrix
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用同质变换矩阵去畸变图像
- en: Decode the tag using the reference image
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用参考图像解码标记
- en: And that’s it! I won’t make you write all the code on your own, everything is
    available [on the github repo](https://github.com/vincent-vdb/medium_posts/tree/main/fiducial_marker/python),
    as well as a pre-trained object detection model.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我不会让你自己编写所有代码，一切都可以在[github 仓库](https://github.com/vincent-vdb/medium_posts/tree/main/fiducial_marker/python)中找到，还有一个预训练的目标检测模型。
- en: You will find in this repo python scripts to run substeps (e.g. generate synthetic
    images, train an object detection model, etc…) as well as a python script that
    runs the full pipeline with your webcam as input, so that you can test it out!
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你会在这个仓库中找到用于运行子步骤（例如生成合成图像、训练目标检测模型等）的 python 脚本，以及一个使用你的摄像头作为输入运行完整流程的 python
    脚本，这样你就可以进行测试！
- en: Final thoughts
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后想法
- en: I hope you enjoyed this post and you learned something from it! I personally
    loved this project, because it uses machine learning as well as good old image
    processing.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这篇文章并从中学到了东西！我个人非常喜欢这个项目，因为它结合了机器学习和传统的图像处理。
- en: 'Still, the algorithm I developed has a few limitations that I would love to
    overcome. Indeed, not all markers can be decoded:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我开发的算法仍然有一些限制，我希望能克服它们。确实，并非所有标记都可以解码：
- en: A marker with no more than 2 adjacent dots on the outermost circle would not
    be decoded properly
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外圈上没有超过2个相邻点的标记将无法正确解码
- en: 'Same for a marker with no symmetrical dots from the longest chain: it would
    give unreliable results because an inaccurate homography matrix'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于没有对称点的标记，它会给出不可靠的结果，因为同质变换矩阵不准确。
- en: Another limitation is the fact that sometimes the homography is mirroring the
    image during the unwarping, causing the list code to be reversed, and thus the
    final decoded integer value is different.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个限制是有时在去畸变过程中，同质变换会镜像图像，导致列表代码被反转，从而最终解码的整数值不同。
- en: If you have any idea to overcome those limitations, you are more than welcome
    to send me a message or even propose a pull request!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何想法来克服这些限制，欢迎给我发消息或提议拉取请求！
- en: 'On another topic, the decoding here only gives a integer value. This is up
    to you to match this integer value with anything relevant (a link, an item, an
    image…) in your app to make it really useful. I believe it would be possible to
    decode such a marker as a list of ASCII characters directly, but I didn’t try
    it out myself: again, any contribution is more than welcome.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个话题是，这里的解码只给出一个整数值。你需要将这个整数值与应用中的任何相关内容（如链接、项目、图像等）匹配，以使其真正有用。我相信可以直接将这样的标记解码为
    ASCII 字符列表，但我自己没有尝试过：再次强调，任何贡献都是非常欢迎的。
- en: References
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Original RUNE-Tag paper:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 原始 RUNE-Tag 论文：
- en: 'F. Bergamasco, A. Albarelli, E. Rodolà and A. Torsello, “RUNE-Tag: A high accuracy
    fiducial marker with strong occlusion resilience,” *CVPR 2011*, Colorado Springs,
    CO, USA, 2011, pp. 113–120, doi: 10.1109/CVPR.2011.5995544.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 'F. Bergamasco, A. Albarelli, E. Rodolà 和 A. Torsello，"RUNE-Tag: 高精度的具有强遮挡恢复能力的基准标记"，*CVPR
    2011*，科罗拉多斯普林斯，美国，2011，第113–120页，doi: 10.1109/CVPR.2011.5995544。'
- en: 'Original RUNE-Tag repository: [https://github.com/artursg/RUNEtag](https://github.com/artursg/RUNEtag)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '原始 RUNE-Tag 仓库: [https://github.com/artursg/RUNEtag](https://github.com/artursg/RUNEtag)'
