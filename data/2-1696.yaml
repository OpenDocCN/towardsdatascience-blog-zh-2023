- en: Is it Time to Start Talking About Prompt Architecture in LLMs?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 是时候开始讨论 LLMs 中的提示架构了吗？
- en: 原文：[https://towardsdatascience.com/prompt-architecture-bd8a07117dab](https://towardsdatascience.com/prompt-architecture-bd8a07117dab)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/prompt-architecture-bd8a07117dab](https://towardsdatascience.com/prompt-architecture-bd8a07117dab)
- en: From prompt engineering to prompt architecture
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从提示工程到提示架构
- en: '[](https://donatoriccio.medium.com/?source=post_page-----bd8a07117dab--------------------------------)[![Donato
    Riccio](../Images/0af2a026e72a023db4635522cbca50eb.png)](https://donatoriccio.medium.com/?source=post_page-----bd8a07117dab--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bd8a07117dab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bd8a07117dab--------------------------------)
    [Donato Riccio](https://donatoriccio.medium.com/?source=post_page-----bd8a07117dab--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://donatoriccio.medium.com/?source=post_page-----bd8a07117dab--------------------------------)[![Donato
    Riccio](../Images/0af2a026e72a023db4635522cbca50eb.png)](https://donatoriccio.medium.com/?source=post_page-----bd8a07117dab--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bd8a07117dab--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bd8a07117dab--------------------------------)
    [Donato Riccio](https://donatoriccio.medium.com/?source=post_page-----bd8a07117dab--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bd8a07117dab--------------------------------)
    ·7 min read·Oct 28, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bd8a07117dab--------------------------------)
    ·7 min read·2023年10月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/f118c2e6e264afa9690d8ddeaca23aba.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f118c2e6e264afa9690d8ddeaca23aba.png)'
- en: Image by the author. (AI generated)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。（AI生成）
- en: Summarize.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 总结。
- en: It started with a single word.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一切始于一个词。
- en: Not happy with the results, we tried again.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对结果不满意，我们再次尝试。
- en: Summarize the most important points of the article*.*
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 总结文章中最重要的要点*。*
- en: Prompt engineering teaches us that more specific prompts are better.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程教会我们，更具体的提示更好。
- en: Identify the three most important arguments made in the article and evaluate
    the strength of the author’s argument based on the evidence provided. Are there
    any points where you feel the argument could be stronger or more convincing?
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 确定文章中提出的三个最重要的论点，并根据提供的证据评估作者论点的力度。是否有任何地方你认为论点可以更强或更有说服力？
- en: Over time, we learned to include more details to guide our favorite LLMs to
    provide the best answers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，我们学会了包括更多细节，以引导我们喜欢的 LLMs 提供最佳答案。
- en: '![](../Images/4eafc6b535fb758a0ee39002ebc806d7.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4eafc6b535fb758a0ee39002ebc806d7.png)'
- en: A recent prompt architecture called Least to Most prompting. [1]
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 最近出现了一种叫做 Least to Most prompting 的提示架构。[1]
- en: Prompt engineering techniques are becoming more complex and elaborate systems,
    sometimes made of many components. The definition of *prompt engineering* might
    be limiting in defining such intricate systems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程技术变得越来越复杂和精细，有时由许多组件构成。*提示工程* 的定义可能无法准确描述如此复杂的系统。
- en: 'In this article, I want to propose a more accurate label for multi-component
    systems that interface with LLMs:'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在这篇文章中，我想提出一个更准确的标签，用于描述与 LLMs 接口的多组件系统：
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Prompt Architecture.
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提示架构。
- en: The history of prompt engineering
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示工程的历史
- en: Modern language models have developed an impressive capacity to take on novel
    tasks after seeing only a couple of examples. This ability is called **in-context
    learning,** and it’s the main reason why we prompt engineering works so well.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现代语言模型在仅看到几个示例后，展现出处理新任务的惊人能力。这种能力被称为**上下文学习**，这是我们提示工程如此有效的主要原因。
- en: Researchers think in-context learning works because pretraining teaches the
    model the general skills needed for language tasks. Then, at test time, it just
    has to recognize the pattern and apply its skills. Bigger models do this even
    better, making them surprisingly adaptable at various natural language tasks.
    [2]
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员认为，*上下文学习* 的有效性在于预训练使模型掌握了语言任务所需的一般技能。然后，在测试时，它只需识别模式并应用其技能。更大的模型做得更好，使它们在各种自然语言任务中适应性强。[2]
- en: In the past, you’d need thousands of labeled examples to fine-tune a language
    model for a new task. But with in-context learning, you can give the model the
    task description in its context window, and it can figure out the new task. We
    call this **zero-shot learning.**
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，你需要数千个标记示例来微调语言模型以处理新任务。但通过上下文学习，你可以将任务描述提供给模型，并让其在上下文窗口中搞定新任务。我们称之为**零-shot学习**。
- en: '![](../Images/00cf2a5bef153e79f78e55e93bad8e05.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00cf2a5bef153e79f78e55e93bad8e05.png)'
- en: In few-shot prompting, some examples of the desired output are added to the
    prompt. Image by author.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在少量示例提示中，将一些期望输出的示例添加到提示中。图片由作者提供。
- en: '**Few-shot learning** works by providing a few examples to the model in its
    context. The model then adapts at test time to recognize and continue the pattern.
    No weight updates are needed. This rapid adaptation ability improves as models
    grow in size, allowing large models like GPT-3 to learn new tasks from just a
    few examples. The model can generalize pretty well after seeing just a handful
    of examples.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**少量学习**通过在上下文中提供几个示例来工作。模型在测试时适应这种模式，无需权重更新。这种快速适应能力随着模型规模的增长而提高，使得像GPT-3这样的大型模型能够仅通过几个示例学习新任务。模型在看到少量示例后可以很好地进行泛化。'
- en: These techniques offer a general framework for interacting with LLMs more thoughtfully.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术提供了一个更周到地与LLM互动的通用框架。
- en: '**Role prompting** is a prompt engineering technique that I’m sure you’ve tried
    at least once in your ChatGPT experience, used for more specific tasks. Here,
    the AI system is assigned a specific role at the start of the prompt. This additional
    information provides context that can enhance the model’s comprehension and lead
    to more effective responses. [3]'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**角色提示**是一种提示工程技术，我相信你在使用ChatGPT时至少尝试过一次，它用于更具体的任务。在这里，AI系统在提示开始时被分配一个特定角色。这些额外信息提供了背景，有助于模型的理解并产生更有效的回应。[3]'
- en: The prompt is initiated with a directive designating the AI’s role, and then
    continues with a question or task that the AI should respond to within the framework
    of the assigned role.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 提示以指定AI角色的指令设计启动，然后继续提出AI应在分配角色框架内回应的问题或任务。
- en: '![](../Images/6da585282c768e6eec0cc0489f1c14cf.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6da585282c768e6eec0cc0489f1c14cf.png)'
- en: Role prompting. Image by author. [Prompt source.](https://github.com/f/awesome-chatgpt-prompts)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 角色提示。图片由作者提供。[提示来源。](https://github.com/f/awesome-chatgpt-prompts)
- en: Providing context through role prompting assists the AI in understanding and
    answering appropriately. It guides the model to respond as expected from someone
    with expertise in a particular domain. For example, you ask prompt the model to
    be a doctor to get a more medically relevant response.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过角色提示提供背景，有助于AI理解并做出恰当的回答。它指导模型以特定领域专家的身份回应。例如，你可以提示模型扮演医生角色，以获得更具医学相关性的回答。
- en: '![](../Images/648d13c73972d75a2bafd06f04e631ff.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/648d13c73972d75a2bafd06f04e631ff.png)'
- en: One of my favorite prompts. Image by author. [Prompt source.](https://www.engraved.blog/building-a-virtual-machine-inside/)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我最喜欢的提示之一。图片由作者提供。[提示来源。](https://www.engraved.blog/building-a-virtual-machine-inside/)
- en: Enabling complex reasoning in Large Language Models
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用大语言模型中的复杂推理
- en: LLMs still struggle with logical reasoning and multi-step problem-solving. **Chain
    of Thought** prompting is a technique to get these models to show their work and
    reason through problems step-by-step.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在逻辑推理和多步骤问题解决上仍然存在困难。**思维链**提示是一种让这些模型逐步展示其工作过程并解决问题的技术。
- en: Demonstrating the desired reasoning process prompts the model to replicate that
    logical thought process on novel problems. **CoT** improves performance on multi-step
    reasoning tasks like math and logic puzzles that usually confuse these models.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 演示期望的推理过程，提示模型在新问题上复制这种逻辑思维过程。**CoT**在多步骤推理任务上表现更好，如数学和逻辑谜题，这些任务通常会让这些模型感到困惑。
- en: '![](../Images/6503911fd27c8b36a9a3a2d59ea0d765.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6503911fd27c8b36a9a3a2d59ea0d765.png)'
- en: Chain of Thought prompting. [4]
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链提示。[4]
- en: Recent work has advanced prompt engineering into systems with multiple elements
    and inference phases.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究将提示工程推进到具有多个元素和推理阶段的系统中。
- en: Here is where we cross the line between prompt engineering and prompt architecture.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这里是我们跨越提示工程和提示架构之间界限的地方。
- en: '![](../Images/293c0f6019424ae6f15e36a70f7b9365.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/293c0f6019424ae6f15e36a70f7b9365.png)'
- en: Self-consistency prompt architecture. [5]
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 自我一致性提示架构。[5]
- en: Complex reasoning tasks typically admit multiple valid reasoning paths that
    lead to the correct solution.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂的推理任务通常允许多条有效的推理路径来得出正确的解决方案。
- en: '**Self-consistency prompting** first samples a diverse set of candidate outputs
    from the model, generating multiple possible reasoning paths. It then aggregates
    the answers and chooses the most common answer among the final answer set. If
    different reasoning paths lead to the same definitive answer, there is greater
    confidence that the answer is correct. [5]'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**自我一致性提示**首先从模型中抽样出一组多样的候选输出，生成多个可能的推理路径。然后它汇总答案并选择最终答案集中最常见的答案。如果不同的推理路径得出相同的明确答案，则对答案的正确性有更大的信心。[5]'
- en: '![](../Images/395f63339339f8db9265d59f46dd4ac3.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/395f63339339f8db9265d59f46dd4ac3.png)'
- en: Before answering a physics question, the model asks itself about physics principles.[6]
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在回答物理问题之前，模型会问自己关于物理原理的问题。[6]
- en: '**Step-back prompting** further develops the idea of solving a problem by decomposing
    it in intermediate steps. It’s a prompt architecture that improves reasoning capabilities
    by having the mode*l take a step back* to formulate an abstract version of the
    question before attempting to answer it.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**退后提示**进一步发展了解决问题的思路，即通过中间步骤分解问题。这是一种提示架构，通过让模型*退后一步*来制定问题的抽象版本，从而提高推理能力，然后再尝试回答问题。'
- en: Step-back prompting first asks the LLM a more general question about key ideas.
    The LLM answers with core facts and concepts. With this broad knowledge, the LLM
    then uses the specific original question to give the final response. Tests across
    benchmarks show stepping back helps large models reason better and make fewer
    mistakes. [6]
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 退后提示首先让LLM对关键概念提出一个更一般的问题。LLM用核心事实和概念作答。通过这种广泛的知识，LLM然后使用具体的原始问题来给出最终回应。基准测试显示，退后提示帮助大型模型更好地推理并减少错误。[6]
- en: '![](../Images/c66c8223f8af9d86dddb649a920862be.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c66c8223f8af9d86dddb649a920862be.png)'
- en: Chain of Verification prompt architecture. [7]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 验证链提示架构。[7]
- en: '**Chain of Verification** (CoVe) is a prompt architecture that seeks to reduce
    hallucinations in LLMs. CoVe first has the model generate an initial response
    to a query, which may contain inaccuracies or hallucinations. Next, we prompt
    the LLM to create a set of verification questions to fact-check potential errors
    in its initial response. The LLM then answers these verification questions independently,
    without conditioning on the original response to avoid repeating hallucinations.
    The goal is to generate a revised, verified response, incorporating the verification
    question-answer pairs to correct any inconsistencies with the initial response.
    [7]'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证链**（CoVe）是一种提示架构，旨在减少大型语言模型中的幻觉。CoVe首先让模型生成对查询的初始回应，该回应可能包含不准确或幻觉。接下来，我们提示LLM创建一组验证问题，以核实初始回应中的潜在错误。然后，LLM独立回答这些验证问题，不依赖于原始回应，以避免重复幻觉。目标是生成一个修订后的、经过验证的回应，结合验证问题-答案对来纠正初始回应中的任何不一致之处。[7]'
- en: Prompt architectures for autonomous agents and advanced applications
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自主代理和高级应用的提示架构
- en: Prompt architecture also enables complex applications that are impossible with
    engineering a single prompt.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 提示架构还支持复杂的应用程序，这些应用程序无法通过单一提示的工程技术实现。
- en: '![](../Images/96fa2942932682636daf5a091e13a946.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96fa2942932682636daf5a091e13a946.png)'
- en: ReAct prompt architecture. [8]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct提示架构。[8]
- en: In **ReAct** prompting, the model mixes thoughts and actions to solve complex
    tasks. Thoughts are plans and reason steps that resemble human reasoning. Actions
    gather information externally through APIs or environments. Observations return
    relevant information. ReAct also increases model interpretability by exposing
    thought processes to assess reasoning correctness. Humans can also edit thoughts
    to control model behavior. [8]
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在**ReAct**提示中，模型将思想和行动混合以解决复杂任务。思想是计划和推理步骤，类似于人类推理。行动通过API或环境收集外部信息。观察返回相关信息。ReAct还通过暴露思维过程来提高模型的可解释性，以评估推理的正确性。人类也可以编辑思维来控制模型的行为。[8]
- en: Choosing the Right Prompt Architecture
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择合适的提示架构
- en: For a conversational chatbot, more straightforward prompt engineering techniques
    are often sufficient as a first try. If those fail, you can escalate to methods
    like **Step Back** or **Self-Consistency** prompting to improve reasoning without
    adding too much complexity.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于对话型聊天机器人来说，通常更直接的提示工程技术作为初步尝试就足够了。如果这些方法失败了，你可以升级到像**退后**或**自我一致性**的提示方法，以在不增加太多复杂性的情况下提高推理能力。
- en: Look into **CoVe** if building an application where reducing hallucinations
    is your priority, or even more advanced methods like **Zero Resource Hallucination
    Prevention.** [9] However, **CoVe** a multi-step interaction that might be tedious
    for a chat. In this case, **Retrieval Augmented Generation (RAG)** may be a better
    option to reduce hallucinations. [10]
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如果构建一个减少幻觉的应用程序是你的优先事项，可以考虑**CoVe**，或者像**零资源幻觉预防**这样的更高级方法。[9] 然而，**CoVe** 是一种多步骤的交互，可能对聊天来说有些繁琐。在这种情况下，**检索增强生成（RAG）**
    可能是减少幻觉的更好选择。[10]
- en: '![](../Images/98bd0e7da95925ced4a35a83b3fbdc13.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98bd0e7da95925ced4a35a83b3fbdc13.png)'
- en: High-level overview of RAG. Image by the author.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: RAG的高级概述。图片由作者提供。
- en: These methods reveal exciting insights about LLMs, but RAG better suits real
    applications.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法揭示了有关LLM的令人兴奋的见解，但RAG更适合实际应用。
- en: Remember that building an application with advanced prompt architectures will
    be more expensive since each query will use more tokens to generate the final
    response.
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 记住，使用高级提示架构构建应用程序将更昂贵，因为每个查询将使用更多的令牌来生成最终响应。
- en: If you aim to build autonomous agents — intelligent, goal-oriented systems —
    try ReAct prompting. React allows the LLM to interact with the world by mixing
    thoughts and actions.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的目标是构建自主代理——智能、目标导向的系统——可以尝试ReAct提示。React允许LLM通过混合思考和行动与世界互动。
- en: Models are growing more capable of solving complex tasks without help. Prompts
    will become even more complex, enabling more advanced use cases for large language
    models.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在无需帮助的情况下解决复杂任务的能力不断提高。提示将变得更加复杂，为大语言模型启用更高级的用例。
- en: Experience lets you develop intuition for which techniques work best in different
    situations.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 经验让你培养直觉，以了解不同情况下哪些技术效果最好。
- en: The future of interacting with LLMs
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与LLM互动的未来
- en: Advanced prompt architectures elevate LLMs to perform tasks impossible with
    just one inference.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 高级提示架构提升了LLM的能力，使其能够完成仅通过一次推理无法实现的任务。
- en: '**Prompt architecture** is also an exciting way to understand what’s inside
    LLMs beyond improving their practical use. Some are too complicated or expensive
    for practical, real-world applications anyway.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示架构**也是了解LLM内部运作的一个令人兴奋的方式，超越了提高其实际用途的范畴。有些架构过于复杂或昂贵，不适合实际的现实世界应用。'
- en: Prompt architecture lets us peek inside the black box of LLMs.
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提示架构让我们窥视LLM的黑箱内部。
- en: Prompt architecture is not an evolution of prompt engineering — **it’s a radically
    different technique.**
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 提示架构不是提示工程的演变——**这是一种截然不同的技术。**
- en: While **prompt engineering** uses a single inference step that anyone can perform
    in a chat interface, **prompt architecture** requires multiple inferences and
    logical steps that often need complex code to be implemented.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然**提示工程**使用单步推理，任何人在聊天界面中都可以执行，但**提示架构**需要多个推理和逻辑步骤，通常需要复杂的代码来实现。
- en: Looking into both reveals new capabilities for large language models.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 深入了解这两者揭示了大语言模型的新能力。
- en: In my view, the distinction is necessary.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，这种区分是必要的。
- en: '*If you enjoyed this article, join* [***Text Generation***](https://textgeneration.substack.com/)
    *— our newsletter has two weekly posts with the latest insights on Generative
    AI and Large Language Models.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢这篇文章，请加入* [***文本生成***](https://textgeneration.substack.com/) *——我们的通讯每周有两篇最新的生成AI和大语言模型见解的文章。*'
- en: '*Also, you can find me on* [***LinkedIn***](https://www.linkedin.com/in/driccio/)***.***'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*另外，你可以在* [***LinkedIn***](https://www.linkedin.com/in/driccio/) ***上找到我。***'
- en: References
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [[2205.10625v3] Least-to-Most Prompting Enables Complex Reasoning in Large
    Language Models (arxiv.org)](https://arxiv.org/abs/2205.10625v3)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [[2205.10625v3] 从少到多提示启用大语言模型中的复杂推理 (arxiv.org)](https://arxiv.org/abs/2205.10625v3)'
- en: '[2] [[2205.11916] Large Language Models are Zero-Shot Reasoners (arxiv.org)](https://arxiv.org/abs/2205.11916)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [[2205.11916] 大语言模型是零样本推理器 (arxiv.org)](https://arxiv.org/abs/2205.11916)'
- en: '[3] [[2308.07702] Better Zero-Shot Reasoning with Role-Play Prompting (arxiv.org)](https://arxiv.org/abs/2308.07702)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [[2308.07702] 通过角色扮演提示改善零样本推理 (arxiv.org)](https://arxiv.org/abs/2308.07702)'
- en: '[4] [[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language
    Models (arxiv.org)](https://arxiv.org/abs/2201.11903)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [[2201.11903] 连锁思维提示引发大语言模型的推理 (arxiv.org)](https://arxiv.org/abs/2201.11903)'
- en: '[5] [[2203.11171] Self-Consistency Improves Chain of Thought Reasoning in Language
    Models (arxiv.org)](https://arxiv.org/abs/2203.11171)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [[2203.11171] 自一致性改善语言模型中的思维链推理 (arxiv.org)](https://arxiv.org/abs/2203.11171)'
- en: '[6] [[2310.06117] Take a Step Back: Evoking Reasoning via Abstraction in Large
    Language Models (arxiv.org)](https://arxiv.org/abs//2310.06117)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [[2310.06117] 退一步思考：通过抽象激发大型语言模型的推理能力 (arxiv.org)](https://arxiv.org/abs//2310.06117)'
- en: '[7] [[2309.11495] Chain-of-Verification Reduces Hallucination in Large Language
    Models (arxiv.org)](https://arxiv.org/abs/2309.11495)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [[2309.11495] 验证链减少大型语言模型中的幻觉 (arxiv.org)](https://arxiv.org/abs/2309.11495)'
- en: '[8] [[2210.03629] ReAct: Synergizing Reasoning and Acting in Language Models
    (arxiv.org)](https://arxiv.org/abs/2210.03629)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [[2210.03629] ReAct：在语言模型中协同推理与行动 (arxiv.org)](https://arxiv.org/abs/2210.03629)'
- en: '[9] [[2309.02654] Zero-Resource Hallucination Prevention for Large Language
    Models (arxiv.org)](https://arxiv.org/abs/2309.02654)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[9] [[2309.02654] 零资源幻觉预防用于大型语言模型 (arxiv.org)](https://arxiv.org/abs/2309.02654)'
- en: '[10] [What is retrieval-augmented generation? | IBM Research Blog](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[10] [什么是检索增强生成？ | IBM 研究博客](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)'
