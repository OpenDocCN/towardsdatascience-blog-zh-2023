- en: How Self-RAG Could Revolutionize Industrial LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何自我RAG可能会彻底改变工业LLMs
- en: 原文：[https://towardsdatascience.com/how-self-rag-could-revolutionize-industrial-llms-b33d9f810264?source=collection_archive---------4-----------------------#2023-11-14](https://towardsdatascience.com/how-self-rag-could-revolutionize-industrial-llms-b33d9f810264?source=collection_archive---------4-----------------------#2023-11-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-self-rag-could-revolutionize-industrial-llms-b33d9f810264?source=collection_archive---------4-----------------------#2023-11-14](https://towardsdatascience.com/how-self-rag-could-revolutionize-industrial-llms-b33d9f810264?source=collection_archive---------4-----------------------#2023-11-14)
- en: Let’s face it — vanilla RAG is pretty dumb. There’s no guarantee responses returned
    are relevant. Learn how Self-RAG can significantly help
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们面对现实 —— 普通的RAG相当愚蠢。不能保证返回的响应是相关的。了解如何自我RAG可以大大帮助
- en: '[](https://skanda-vivek.medium.com/?source=post_page-----b33d9f810264--------------------------------)[![Skanda
    Vivek](../Images/9d25bee2fb75176ca7f7ea6eff7d7ab5.png)](https://skanda-vivek.medium.com/?source=post_page-----b33d9f810264--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b33d9f810264--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b33d9f810264--------------------------------)
    [Skanda Vivek](https://skanda-vivek.medium.com/?source=post_page-----b33d9f810264--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://skanda-vivek.medium.com/?source=post_page-----b33d9f810264--------------------------------)[![Skanda
    Vivek](../Images/9d25bee2fb75176ca7f7ea6eff7d7ab5.png)](https://skanda-vivek.medium.com/?source=post_page-----b33d9f810264--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b33d9f810264--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b33d9f810264--------------------------------)
    [Skanda Vivek](https://skanda-vivek.medium.com/?source=post_page-----b33d9f810264--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F220d9bbb8014&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-self-rag-could-revolutionize-industrial-llms-b33d9f810264&user=Skanda+Vivek&userId=220d9bbb8014&source=post_page-220d9bbb8014----b33d9f810264---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b33d9f810264--------------------------------)
    ·7 min read·Nov 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb33d9f810264&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-self-rag-could-revolutionize-industrial-llms-b33d9f810264&user=Skanda+Vivek&userId=220d9bbb8014&source=-----b33d9f810264---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[跟进](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F220d9bbb8014&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-self-rag-could-revolutionize-industrial-llms-b33d9f810264&user=Skanda+Vivek&userId=220d9bbb8014&source=post_page-220d9bbb8014----b33d9f810264---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b33d9f810264--------------------------------)
    ·7 分钟阅读·Nov 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb33d9f810264&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-self-rag-could-revolutionize-industrial-llms-b33d9f810264&user=Skanda+Vivek&userId=220d9bbb8014&source=-----b33d9f810264---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb33d9f810264&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-self-rag-could-revolutionize-industrial-llms-b33d9f810264&source=-----b33d9f810264---------------------bookmark_footer-----------)![](../Images/69621ace143918aee012edf5e1d62323.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb33d9f810264&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-self-rag-could-revolutionize-industrial-llms-b33d9f810264&source=-----b33d9f810264---------------------bookmark_footer-----------)![](../Images/69621ace143918aee012edf5e1d62323.png)'
- en: Self-RAG Demo | Skanda Vivek
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自我RAG演示 | Skanda Vivek
- en: Large language models (LLMs) are all set to revolutionize various industries.
    Let’s take the example of the financial sector, wherein LLMs can be used to pore
    over troves of documents and find trends in a fraction of time and at a fraction
    of the cost of analysts doing the same task. But here’s the catch — the answers
    you get are only partial and incomplete many times. Take, for example, the case
    where you have a document containing company X’s annual revenue over the past
    15 years, but in different sections. In the standard Retrieval Augmented Generation
    (RAG) architecture as pictured below, you typically retrieve the top-k documents,
    or choose documents within a fixed context length.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）即将彻底改变各个行业。以金融行业为例，LLMs 可以用来快速查阅大量文档，并在分析师完成相同任务的时间和成本的极小部分内发现趋势。但问题在于，你得到的答案往往是不完整的。例如，假设你有一份包含公司X过去15年的年度收入的文档，但这些信息分散在不同的部分。在下面所示的标准检索增强生成（RAG）架构中，你通常会检索前k个文档，或者选择固定上下文长度内的文档。
- en: '![](../Images/4041cfd00e99aed333dcc5090fda5094.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4041cfd00e99aed333dcc5090fda5094.png)'
- en: RAG Prototype | Skanda Vivek
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: RAG原型 | Skanda Vivek
- en: However, this can have several issues. One issue is wherein the top-k documents
    do not contain all the answers — maybe for example only corresponding to the last
    5 or 10 years. The other issue is that computing similarity between document chunks
    and prompt…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这可能会有几个问题。其中一个问题是，前k个文档可能没有包含所有答案——例如，可能只对应过去的5年或10年。另一个问题是计算文档块和提示之间的相似性…
