- en: 'Unsupervised Learning with K-Means Clustering: Generate Color Palettes from
    Images'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习与 K-Means 聚类：从图像生成颜色调色板
- en: 原文：[https://towardsdatascience.com/unsupervised-learning-with-k-means-clustering-generate-color-palettes-from-images-94bb8e6a1416](https://towardsdatascience.com/unsupervised-learning-with-k-means-clustering-generate-color-palettes-from-images-94bb8e6a1416)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/unsupervised-learning-with-k-means-clustering-generate-color-palettes-from-images-94bb8e6a1416](https://towardsdatascience.com/unsupervised-learning-with-k-means-clustering-generate-color-palettes-from-images-94bb8e6a1416)
- en: A comprehensive guide to unsupervised ML and the K-Means algorithm with a demo
    of a clustering use case for grouping image pixels by color
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这是关于无监督机器学习和 K-Means 算法的全面指南，包含了一个基于颜色对图像像素进行分组的聚类用例的演示
- en: '[](https://nroy0110.medium.com/?source=post_page-----94bb8e6a1416--------------------------------)[![Nabanita
    Roy](../Images/83ab7766a28c79371ebf9517e1f273d2.png)](https://nroy0110.medium.com/?source=post_page-----94bb8e6a1416--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94bb8e6a1416--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94bb8e6a1416--------------------------------)
    [Nabanita Roy](https://nroy0110.medium.com/?source=post_page-----94bb8e6a1416--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://nroy0110.medium.com/?source=post_page-----94bb8e6a1416--------------------------------)[![Nabanita
    Roy](../Images/83ab7766a28c79371ebf9517e1f273d2.png)](https://nroy0110.medium.com/?source=post_page-----94bb8e6a1416--------------------------------)[](https://towardsdatascience.com/?source=post_page-----94bb8e6a1416--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----94bb8e6a1416--------------------------------)
    [Nabanita Roy](https://nroy0110.medium.com/?source=post_page-----94bb8e6a1416--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94bb8e6a1416--------------------------------)
    ·13 min read·Apr 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----94bb8e6a1416--------------------------------)
    ·阅读时间13分钟·2023年4月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/cf06c65cce12f976b12ba19ea8fc1473.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf06c65cce12f976b12ba19ea8fc1473.png)'
- en: Photo by [Billy Huynh](https://unsplash.com/@billy_huy?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[Billy Huynh](https://unsplash.com/@billy_huy?utm_source=medium&utm_medium=referral)
    的照片，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Unsupervised learning is a method in which underlying patterns in data can be
    discovered without providing extra information (or labels/targets) to a machine
    learning algorithm. In this article, I have documented a pretty cool application
    of the K-Means clustering algorithm that I recently found out while reading some
    image-processing articles along with an introduction to unsupervised clustering
    approaches in machine learning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习是一种方法，在这种方法中，可以发现数据中的潜在模式，而无需向机器学习算法提供额外的信息（或标签/目标）。在本文中，我记录了最近在阅读一些图像处理文章时发现的一个相当酷的
    K-Means 聚类算法应用，以及无监督聚类方法在机器学习中的介绍。
- en: '**Key Takeaways from this Article:**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**本文的关键要点：**'
- en: '1️⃣ Unsupervised ML: Introduction, Classifications, and Applications'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 1️⃣ 无监督机器学习：介绍、分类和应用
- en: 2️⃣ Comprehensive Understanding of KMeans Clustering
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 2️⃣ K-Means 聚类的全面理解
- en: 3️⃣ A Step-by-Step K-Means Clustering Application using Scikit Learn Python
    Libary to Generate Color Palette from a Given Image
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 3️⃣ 使用 Scikit Learn Python 库进行逐步的 K-Means 聚类应用，以从给定图像生成颜色调色板
- en: 4️⃣ Read and process Images using Pillow, Requests and Numpy
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 4️⃣ 使用 Pillow、Requests 和 Numpy 读取和处理图像
- en: Let’s Dive into Unsupervised Learning First
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让我们首先深入了解无监督学习
- en: Machine Learning (ML), a technique in which machines can be trained to assimilate
    and learn from given data, can be broadly classified into supervised, unsupervised,
    and reinforcement learning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML），一种通过给定数据来训练机器以吸收和学习的技术，通常可以分为监督学习、无监督学习和强化学习。
- en: '![](../Images/4bc9157e3b35d7f16017be6ea7e05b91.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4bc9157e3b35d7f16017be6ea7e05b91.png)'
- en: 'Image Source: Author'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**✅ *Supervised learning*** is where the machine is taught to learn by providing
    samples with metadata (which in ML terminology is called labels) to help the identification
    process. For example, in fraud detection use-cases, transactions are labeled fraud
    or genuine manually by analysts and then they are used to train an ML model. This
    ML model learns from examples of patterns or behaviors in fraudulent transactions
    and is enabled to apply the learning to a new transaction and assess if it matches
    the patterns of the fraud or genuine transactions that were used for learning.
    Then, the model associates the new transaction with either of the classes, fraud
    or genuine, depending on the identified patterns, and makes a prediction. Often,
    these predictions are associated with a confidence interval or probability to
    scores to indicate how well the pattern matched with the unseen sample. Higher
    scores indicate the ML model thinks that the prediction is likely to be correct.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**✅ *监督学习***是通过提供带有元数据（在机器学习术语中称为标签）的样本来教机器学习的过程，以帮助识别过程。例如，在欺诈检测用例中，事务由分析师手动标记为欺诈或真实，然后用于训练机器学习模型。这个机器学习模型从欺诈事务的模式或行为示例中学习，并能够将学习应用到新的事务中，评估它是否符合用于学习的欺诈或真实事务的模式。然后，模型将新事务与欺诈或真实类别之一关联，根据识别的模式进行预测。通常，这些预测会与置信区间或概率得分相关，以指示模式与未见样本的匹配程度。较高的得分表示机器学习模型认为预测可能是正确的。'
- en: '**✅ *Unsupervised learning*** also finds such patterns hidden in the provided
    sample. The difference is that there are no labels/classes associated. Unsupervised
    techniques are great for exploring data and understanding behaviors that are otherwise
    difficult to recognize by humans from a huge dataset. *They are widely used for
    text categorization (like news articles), anomaly detection, satellite & spatial
    image processing, medical image analysis, customer segmentation, and recommendation
    engines to name a few.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**✅ *无监督学习***也会发现样本中隐藏的这些模式。不同之处在于没有标签/类别。无监督技术非常适合于探索数据和理解那些从庞大的数据集中难以被人类识别的行为。*它们广泛应用于文本分类（如新闻文章）、异常检测、卫星与空间图像处理、医学图像分析、客户细分和推荐引擎等。*'
- en: Unsupervised learning is used for three main tasks— *clustering, association,
    and dimensionality reduction.*
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习用于三个主要任务—— *聚类、关联和降维。*
- en: '***Clustering*** is a technique in which samples are grouped automatically.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***聚类***是一种自动将样本分组的技术。'
- en: '***Association*** is a technique used to find relationships between features
    in a dataset.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***关联***是一种用于发现数据集中特征之间关系的技术。'
- en: '***Dimensionality Reduction*** is a technique used to reduce the number of
    features in the dataset when it is high.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***降维***是一种用于减少数据集中高维特征数量的技术。'
- en: In this article, I will focus on clustering as a grouping technique.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我将重点关注聚类作为一种分组技术。
- en: Clustering in Machine Learning
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中的**聚类**
- en: Clustering could be performed for multiple applications, for example, assessing
    how similar or dissimilar are data-points from each other, how dense are the data
    points in a vector space, extracting topics, and so on. Primarily, there are four
    types of clustering techniques -
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类可以用于多个应用，例如评估数据点之间的相似或不同、数据点在向量空间中的密集程度、提取主题等。主要有四种类型的聚类技术——
- en: '![](../Images/0b9ff0506563862bd8a58b3abf33dc44.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b9ff0506563862bd8a58b3abf33dc44.png)'
- en: 'Image Source: Author'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '***Centroid-based Clustering*** is where groups of data points are identified
    by the average distance from a centroid. There could be multiple centroids and
    an initial centroid is optimized over multiple passes. This technique is simple,
    efficient, and effective, however, it is sensitive to initial hyperparameter configurations.
    **K-Means clustering is the most-popular clustering algorithm that belongs to
    this school of techniques.**'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***基于中心点的聚类***是通过计算数据点到中心点的平均距离来识别数据点的组。可以有多个中心点，并且初始中心点会在多个迭代中进行优化。这种技术简单、高效且有效，但对初始超参数配置敏感。**K均值聚类是最受欢迎的属于这种技术的聚类算法。**'
- en: '***Density-based Clustering*** groups high-density areas into clusters. These
    are useful for spatial data processing. For example, this technique could be used
    to locate areas with a high concentration of COVID-19-infected households, locate
    densely populated areas, or deforestation. **DBSCAN (Density-Based Spatial Clustering
    of Applications with Noise) is the most common algorithm that is used for detecting
    density-based clusters.** Usually, these algorithms ignore outliers.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***基于密度的聚类*** 将高密度区域分组为簇。这对于空间数据处理非常有用。例如，这种技术可以用来定位COVID-19感染家庭的高密度区域、定位人口密集区或进行森林砍伐分析。**DBSCAN（基于密度的空间聚类与噪声）是最常用于检测基于密度的簇的算法。**
    通常，这些算法会忽略异常值。'
- en: '***Distribution-based Clustering*** is used for detecting if the data has a
    particular distribution (probability distribution e.g. Gaussian) embedded subsets
    of the dataset. This technique is recommended if a particular type of distribution
    is known to be embedded in the data.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***基于分布的聚类*** 用于检测数据中是否嵌入了特定的分布（例如高斯分布）。如果已知数据中嵌入了某种特定类型的分布，推荐使用这种技术。'
- en: '***Hierarchical Clustering*** is used to detect if there are hierarchical relationships
    or taxonomies embedded in the data. This technique can be further classified into
    ‘top-down’ and ‘bottom-up’ approaches. **Dendrograms** are a data visualization
    technique that helps in the interpretation of the results of hierarchical clustering
    by creating taxonomy maps. Applications of hierarchical clustering are in understanding
    and charting evolution in life-sciences use-cases using DNA sequences, and tracking
    infected clusters during Covid 19, modeled into regions and drilled down into
    sub-regions.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***层次聚类*** 用于检测数据中是否存在层次关系或分类法。这种技术可以进一步分为“自上而下”和“自下而上”方法。**树状图** 是一种数据可视化技术，通过创建分类地图来帮助解释层次聚类的结果。层次聚类的应用包括使用DNA序列理解和绘制生命科学领域的进化过程，以及在Covid-19期间跟踪感染簇，将其建模为区域并细化为子区域。'
- en: There are other approaches and definitions to types of clustering including
    **Partitional/Exclusive Clustering** (where every data point is assigned to exactly
    one cluster), **Overlapping/Non-exclusive Clustering** (where a data point can
    be assigned to multiple clusters), **Fuzzy or Non-Fuzzy** Approaches as well as
    **Partial** (where a data point might not have any cluster assigned)or **Complete
    Clustering techniques** (where all data points have one or more clusters assigned).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类的其他方法和定义包括**划分/排他性聚类**（每个数据点被分配到一个且只有一个簇）、**重叠/非排他性聚类**（一个数据点可以被分配到多个簇）、**模糊或非模糊**
    方法以及**部分**（数据点可能没有被分配到任何簇）或**完全聚类技术**（所有数据点都有一个或多个簇分配）。
- en: In the next section, I will focus on elaborating more on the K-Means clustering
    technique, the scikit-learn implementation, and the pros-cons of the algorithm.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我将重点讲解K均值聚类技术、scikit-learn实现以及该算法的优缺点。
- en: Introduction to K-Means Clustering
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K均值聚类介绍
- en: K-Means clustering is one of the most popular centroid-based clustering methods
    with partitioned clusters. The number of clusters is predefined, usually denoted
    by *k*. All data points are assigned to one and exactly one of these *k* clusters.
    Below is a demonstration of how (random) data points in a 2-dimensional space
    are clustered into 4 groups after 3 iterations (as set on the right-hand side).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: K均值聚类是最受欢迎的基于中心点的聚类方法之一，其具有划分簇。簇的数量是预定义的，通常用 *k* 表示。所有数据点都被分配到这 *k* 个簇中的一个且仅一个。下面演示了在二维空间中（随机）数据点在经过3次迭代（如右侧所设定）后被划分成4组的过程。
- en: '![](../Images/04645a77bdb5ee6eb23a40e08a3e3927.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04645a77bdb5ee6eb23a40e08a3e3927.png)'
- en: 'A KMeans Clustering Simulator by [METU — Middle East Technical University](https://www.metu.edu.tr/)
    | Image Source & Simulator Link: [https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由[中东技术大学（METU）](https://www.metu.edu.tr/)提供的K均值聚类模拟器 | 图片来源与模拟器链接：[https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/)
- en: Each cluster obtained from training a K-Means model contains a centroid (marked
    by the larger circle markers in the image above) and each data point is assigned
    to the cluster with the closest centroid. The centroid of a cluster is the mean
    of all the data points in that cluster. In short, the K-Means algorithm groups
    the data points into *k* clusters by minimizing the distance between the centroid
    and each data point in an iterative manner. Commonly, [Euclidean Distance](https://en.wikipedia.org/wiki/Euclidean_distance)
    is used to measure the distance between the centroid and the data point.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练K均值模型获得的每个簇包含一个质心（在上图中由较大的圆圈标记）并且每个数据点被分配到距离最近的质心的簇中。簇的质心是该簇中所有数据点的均值。简而言之，K均值算法通过迭代地最小化质心与每个数据点之间的距离，将数据点分成*k*个簇。通常，[欧几里得距离](https://en.wikipedia.org/wiki/Euclidean_distance)用于测量质心与数据点之间的距离。
- en: If you are familiar with the Cost Functions in ML, you would know that evaluation
    of this function estimates the error in the predictions made by an ML model, and
    enhancing a model’s performance incorporates strategies to minimize this function
    for optimal impact. In clustering, the cost function sums the distortions of the
    clusters.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉机器学习中的成本函数，你会知道这个函数的评估估计了机器学习模型预测的误差，并且提升模型性能包括了最小化该函数的策略以实现最终效果。在聚类中，成本函数求和了各个簇的扭曲度。
- en: In terms of K-Means clustering, the distortion is the squared distance (given
    that Euclidean Distance is being used) between all the points to their closest
    cluster center. To obtain optimal clusters, the distortion function needs to be
    minimized.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 就K均值聚类而言，扭曲度是所有点到其最近簇中心的平方距离（假设使用了欧几里得距离）。为了获得最佳簇，扭曲函数需要被最小化。
- en: '![](../Images/f7c53036ed985aa61edeef71c3cec7c6.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7c53036ed985aa61edeef71c3cec7c6.png)'
- en: 'Distortion Function | Image Source: Author | Reference: [http://cs229.stanford.edu/notes2020spring/cs229-notes7a.pdf](http://cs229.stanford.edu/notes2020spring/cs229-notes7a.pdf)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 扭曲函数 | 图像来源：作者 | 参考文献：[http://cs229.stanford.edu/notes2020spring/cs229-notes7a.pdf](http://cs229.stanford.edu/notes2020spring/cs229-notes7a.pdf)
- en: The K-Means algorithm minimizes *J* with respect to *c* keeping *µ* fixed (when
    the data points are (re)distributed to the fixed centroids based on the distance)
    and then minimizes J with respect to *µ* keeping *c* fixed (when the centroids
    are (re)updated after (re)distributing the data points based on the distance).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: K均值算法最小化*J*关于*c*，保持*µ*固定（当数据点根据距离被（重新）分配到固定的质心时），然后最小化*J*关于*µ*，保持*c*固定（当质心在根据距离（重新）分配数据点之后（重新）更新时）。
- en: A variant of K-Means is K-Median which relies on the [Manhattan distance](https://wikipedia.org/wiki/Taxicab_geometry)
    from the centroid to a data point.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: K均值的一个变体是K-中位数，它依赖于从质心到数据点的[曼哈顿距离](https://wikipedia.org/wiki/Taxicab_geometry)。
- en: '**The K-Means Algorithm:**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**K均值算法：**'
- en: '![](../Images/19d93d1f18899400d852df3e48e17053.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19d93d1f18899400d852df3e48e17053.png)'
- en: 'Image Source: Author'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：作者
- en: '*Step 1:* Randomly initialize centroids for each of the *k* clusters'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤1:* 随机初始化每个*k*簇的质心'
- en: '*Step 2:* Assign each point to the closest centroid to group data points to
    the initial *k* clusters.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2:* 将每个点分配给最近的质心，将数据点分组到初始的*k*簇中。'
- en: '*Step 3:* Recompute the centroid by getting the average of all points in each
    of the *k* clusters. Since the centroids are recomputed and therefore have been
    updated, the data points are also reassigned to the closest centroid thereafter.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤3:* 通过计算每个*k*簇中所有点的平均值来重新计算质心。由于质心被重新计算并因此被更新，数据点随后也会被重新分配到最近的质心。'
- en: '*Step 4:* Recompute centroids and reassign data points to updated centroids
    *(i.e. repeat step 3)* until the points stop changing clusters.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤4:* 重新计算质心并将数据点重新分配到更新后的质心（即重复步骤3），直到点不再改变簇。'
- en: '**Scikit-Learn’s K-Means Implementation:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**Scikit-Learn的K均值实现：**'
- en: '![](../Images/435d8bee27dd7ce1b3f6323f9394aa71.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/435d8bee27dd7ce1b3f6323f9394aa71.png)'
- en: 'Image Source: [https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：[https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- en: '[**K-Means implementation**](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    **in Scikit-Learn has the following key hyperparameters:**'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[**K均值实现**](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
    **在Scikit-Learn中的关键超参数包括：**'
- en: '*n_clusters*: The number of clusters that the user has to provide'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*n_clusters*: 用户必须提供的簇的数量'
- en: '*init*: The strategy to initialize the centroids. Even though they are randomly
    chosen, to speed up convergence and obtain optimal clusters, strategies like the
    K-means++ technique could be applied. Otherwise, ‘random’ uses randomly initiated
    clusters. K-Means++ selects a centroid at random and then places the remaining
    *k−1* centroids such that they are maximally far away from another. [Here’s the
    paper for delving further into K-Means++.](https://dl.acm.org/doi/10.5555/1283383.1283494)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*init*: 初始化质心的策略。尽管这些质心是随机选择的，为了加速收敛并获得最佳的聚类，可以应用像 K-means++ 技术这样的策略。否则，‘random’
    使用随机初始化的聚类。K-Means++ 随机选择一个质心，然后将剩余的 *k−1* 个质心放置在彼此尽可能远的位置。[这里有一篇深入探讨 K-Means++
    的论文。](https://dl.acm.org/doi/10.5555/1283383.1283494)'
- en: '*n_init*: Number of times the k-means algorithm is run with different centroid
    seeds. If this is set to 1, then the clusters might emerge highly imbalanced for
    sparse data. To mitigate this issue, *n_init* number of times the clustering algorithm
    is applied and the cluster distributions with the best inertia (performance evaluation
    metric for clustering) are returned.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*n_init*: K-means 算法运行的次数，每次使用不同的质心种子。如果设置为 1，则对于稀疏数据，簇可能会出现高度不平衡。为了解决这个问题，*n_init*
    次数的聚类算法被应用，并返回具有最佳惯性（用于聚类的性能评估指标）的簇分布。'
- en: '*max_iter*: Maximum number of times the centroids can be recomputed. This comes
    in handy for large datasets where the time taken to process is high but a low
    max_iter can also result in sub-optimal clusters when the algorithm is terminated
    before convergence is reached.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*max_iter*: 质心可以被重新计算的最大次数。这对于处理时间较长的大数据集非常有用，但低的 max_iter 也可能导致在算法收敛之前被终止，从而导致亚最佳簇。'
- en: '*algorithm*: A choice between Lloyd or Elkan. The ‘Lloyd’s algorithm’ is generally
    used for K-Means. In Wikipedia, it is stated that this algorithm (by [Stuart P.
    Lloyd, Bell Labs, 1957](https://en.wikipedia.org/wiki/Lloyd%27s_algorithm)) is
    used for finding evenly spaced sets of points in subsets of [Euclidean spaces](https://en.wikipedia.org/wiki/Euclidean_space)
    (i.e. establish centroids) and partitions of these subsets into well-shaped and
    uniformly sized convex cells (assignment and clustering data points related to
    the centroids).'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*algorithm*: 选择 Lloyd 或 Elkan。‘Lloyd’s algorithm’ 通常用于 K-Means。在维基百科中指出，这种算法（由
    [Stuart P. Lloyd, Bell Labs, 1957](https://en.wikipedia.org/wiki/Lloyd%27s_algorithm)）用于在
    [欧几里得空间](https://en.wikipedia.org/wiki/Euclidean_space) 的子集（即建立质心）中寻找均匀分布的点集，并将这些子集划分为形状良好且大小均匀的凸单元（分配和聚类与质心相关的数据点）。'
- en: '**Now, let’s look at the key attributes available for training:**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**现在，让我们来看看训练中可用的关键属性：**'
- en: '*cluster_centers_* : array of co-ordinates of centroids'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*cluster_centers_* : 质心的坐标数组'
- en: '*labels_* : labels for each data point'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*labels_* : 每个数据点的标签'
- en: '*inertia_*: sum of squared distances of samples to their closest cluster center,
    weighted by the sample weights if provided. This is often used for assessing how
    well the clusters are formed.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*inertia_*: 样本到其最近簇中心的平方距离之和，如果提供了样本权重，则按样本权重加权。这通常用于评估簇的形成情况。'
- en: Note that, unlike supervised approaches, the model is fitted on only the training
    data. Therefore, the *fit*, *fit_transform*, and *fit_predict* methods will only
    take one argument, that is, the dataset under observation.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与监督学习方法不同，模型仅在训练数据上进行拟合。因此，*fit*、*fit_transform* 和 *fit_predict* 方法将只接受一个参数，即观察的数据集。
- en: A detailed overview of all the available hyperparameters, attributes, and methods
    is [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 所有可用超参数、属性和方法的详细概述见[此处](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)。
- en: '**✅ Why is the K-Means algorithm so popular?**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**✅ 为什么 K-Means 算法如此受欢迎？**'
- en: Simple, fast, efficient, and explainable
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单、快速、高效且易于解释
- en: Scales easily for large datasets
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大数据集，易于扩展
- en: Convergence for the common similarity measures like Euclidean distance, correlations,
    and cosine similarity is guaranteed
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于常见的相似性度量，如欧几里得距离、相关性和余弦相似性，收敛是有保证的
- en: Flexible and can be generalized to suit a variety of cluster sizes, shapes,
    and density
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灵活且可以推广以适应各种簇大小、形状和密度
- en: '**⚠️Challenges:**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**⚠️ 挑战：**'
- en: Manually set the number of clusters (*k*)
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动设置簇的数量 (*k*)
- en: Centroids are susceptible to outliers
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 质心容易受到异常值的影响
- en: K-means finds roughly circular clusters and performs poorly for varying sizes
    and densities. However, this can be eliminated by applying generalizing strategies.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: K-means 聚类算法主要适用于大致圆形的聚类，对于大小和密度变化较大的数据表现较差。然而，通过应用泛化策略，可以消除这一问题。
- en: Color Palette Generator
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 色彩调色板生成器
- en: 'A typical clustering process includes:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的聚类过程包括：
- en: ➡️ preparing the data ➡️ vectorizing them (for example similarity scores embeddings
    for texts or RGB values in the case of images) ➡️ running the chosen clustering
    algorithm ➡️ interpreting the results ➡️ making adjustments by retraining the
    model with updated data or hyperparameters.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ➡️ 准备数据 ➡️ 向量化数据（例如文本的相似性评分嵌入或图像的 RGB 值） ➡️ 运行所选择的聚类算法 ➡️ 解释结果 ➡️ 通过使用更新的数据或超参数重新训练模型来进行调整。
- en: '**💡 *In this project, given an image, the objective is to cluster the pixel
    RGB values, apply the clustering algorithm and obtain the cluster centers that
    represent the palette colors. Bonus: Sort palette colors & use them in Python’s
    data visualization libraries.***'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**💡 *在这个项目中，给定一张图片，目标是对像素 RGB 值进行聚类，应用聚类算法并获得代表调色板颜色的聚类中心。附加任务：对调色板颜色进行排序，并在
    Python 的数据可视化库中使用它们。***'
- en: '![](../Images/a0c81ce5b5518b3362f04aec00ed6163.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0c81ce5b5518b3362f04aec00ed6163.png)'
- en: 'Image Source: Author'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**Let’s begin👍**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**让我们开始吧👍**'
- en: '**Step 1: Get the image data**'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1：获取图像数据**'
- en: 'First and foremost, we need an image and get the RGB values for each pixel.
    To represent a color on the screen, each pixel actually consists of three color
    components: **red (R), green (G), and blue (B)**. These are frequently referred
    to as the pixel’s RGB value.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一张图片并获取每个像素的 RGB 值。为了在屏幕上表示颜色，每个像素实际上由三个颜色组件组成：**红色 (R)、绿色 (G) 和蓝色 (B)**。这些通常被称为像素的
    RGB 值。
- en: '**Some Notes:**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**一些注意事项：**'
- en: 🔴RGB value of (255, 0, 0) is a red pixel
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 🔴RGB 值 (255, 0, 0) 是一个红色像素
- en: 🟢RGB value of (0, 255, 0) is a green pixel
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 🟢RGB 值 (0, 255, 0) 是一个绿色像素
- en: 🔵RGB value of (0, 0, 255) is a blue pixel
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 🔵RGB 值 (0, 0, 255) 是一个蓝色像素
- en: ⚪RGB of (255, 255, 255) is a white pixel
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ⚪RGB 值 (255, 255, 255) 是一个白色像素
- en: ⚫RGB of (0, 0, 0) is a black pixel
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ⚫RGB 值 (0, 0, 0) 是一个黑色像素
- en: Here is how it is done in Python using Pillow Python Library. In *line 5*, I
    read an image using ***Image.open()*** and in *line 15*, I converted the image
    into a [Numpy array](https://numpy.org/doc/stable/reference/generated/numpy.array.html)
    of RGB codes and finally, put the values into a [Pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)
    in *line 18*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何使用 Pillow Python 库在 Python 中完成这项工作的。在 *第 5 行*，我使用 ***Image.open()*** 读取了图片，在
    *第 15 行*，我将图片转换为 [Numpy array](https://numpy.org/doc/stable/reference/generated/numpy.array.html)
    的 RGB 代码，最后在 *第 18 行*，将这些值放入 [Pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)
    中。
- en: 'Image Source: Author'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: You can simply use the ***image_variable_name*** (img in my case) to view the
    image or use **display(img)** or **img.show()** to show the image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以简单地使用 ***image_variable_name***（在我的例子中是 img）来查看图像，或者使用 **display(img)** 或
    **img.show()** 来显示图像。
- en: '![](../Images/f0634a8b9eddfbf3315ef9e6b4561f84.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0634a8b9eddfbf3315ef9e6b4561f84.png)'
- en: 'Image Source: Author'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 'Here is how the RGB DataFrame turned out:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: RGB DataFrame 的结果如下：
- en: '![](../Images/6a59006d249a30a8f5cc09e190dc384f.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a59006d249a30a8f5cc09e190dc384f.png)'
- en: 'Image Source: Author'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Besides, to read images from an URL, here’s the implementation where I used
    the [requests](https://pypi.org/project/requests/) library to fetch the image.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了从 URL 读取图片，下面是我使用 [requests](https://pypi.org/project/requests/) 库来获取图片的实现。
- en: 'Image Source: Author'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Next, follow the previous steps to get the RGB values and convert them to a
    DataFrame to proceed.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，按照之前的步骤获取 RGB 值并将其转换为 DataFrame 以继续处理。
- en: '**Step 2: Clustering using SkLearn’s K-Means Implementation**'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2：使用 SkLearn 的 K-Means 实现进行聚类**'
- en: 'Now that I have the RGB values, I am using [K-Means clustering algorithm in
    scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).
    The parameters I have used are as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经有了 RGB 值，我正在使用 [scikit-learn 中的 K-Means 聚类算法](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)。我使用的参数如下：
- en: '*n_cluster*: integer indicating the number of clusters. I have used 6\. This
    is also indicative of the number of colors in the palette since we will be picking
    out the cluster centers (~ RGB values) to represent the colors in the palette.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n_cluster*：表示聚类数量的整数。我使用了 6。这个数量也表示调色板中的颜色数量，因为我们将选择聚类中心（~ RGB 值）来代表调色板中的颜色。'
- en: '*random_state*: random seed for centroid initialization. I have used 0.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*random_state*：用于质心初始化的随机种子。我使用了 0。'
- en: '*init*: centroid initialization method. I have used k-mean++ which selects
    initial cluster centroids using sampling based on an empirical probability distribution
    of the points’ contribution to the overall inertia and then makes several trials
    at each sampling step to choose the best centroid among them.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*init*：质心初始化方法。我使用了k-means++，它通过基于点对整体惯性的贡献的经验概率分布来选择初始簇质心，然后在每个采样步骤进行多次试验，以选择最佳的质心。'
- en: '*n_init*: Number of times the k-means algorithm is run with different centroid
    seeds. Since I selected *init*: *K-means++*, *n_init* is automatically set to
    1.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n_init*：k-means算法用不同的质心种子运行的次数。由于我选择了*init*: *K-means++*，*n_init*被自动设置为1。'
- en: Besides, I have used the defaults for *max_iter (300)* and *algorithm(Lloyd)*.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我使用了*max_iter (300)*和*algorithm(Lloyd)*的默认值。
- en: Next, I used ***fit()*** method to fit the model on the RGB DataFrame in *line
    9*.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我使用了***fit()***方法将模型拟合到*line 9*中的RGB DataFrame。
- en: On successful training for the model, I accessed the *cluster_centers_* attribute*,*
    converted them to integers, and put them in *list*. This nested list is the palette’s
    color’s RGB values where each element is a list of R, G, and B values of the color
    it represents.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 模型成功训练后，我访问了*cluster_centers_*属性，将其转换为整数，并放入*list*中。这个嵌套列表是调色板颜色的RGB值，其中每个元素都是一个包含R、G和B值的列表。
- en: 'Image Source: Author'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：作者
- en: '**Step 3 (optional): Reorder the cluster centers i.e. your palette colors**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤3（可选）：重新排序簇质心，即你的调色板颜色**'
- en: This is an optional step where I have ordered the colors based on the Value
    in their HSV representatives where H — Hue, S — Saturation, and V — Value. By
    accessing the last element of the [h, s, v] list after conversion using [colorsys’s](https://docs.python.org/3/library/colorsys.html)
    rgb_to_hsv() method, I chose to order the list by the “Value” which describes
    the brightness or intensity of the color. It is expressed by an integer between
    0 to 100 (percent), where 0 is completely black, and 100 is the brightest and
    reveals the most color.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可选步骤，我根据其HSV表示中的值对颜色进行了排序，其中H — 色调，S — 饱和度，V — 值。通过使用[colorsys](https://docs.python.org/3/library/colorsys.html)的rgb_to_hsv()方法转换后，访问[h,
    s, v]列表的最后一个元素，我选择按“值”排序，该值描述了颜色的亮度或强度。它由0到100（百分比）之间的整数表示，其中0是完全黑色，100是最亮的，显示出最丰富的颜色。
- en: 'Image Source: Author'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：作者
- en: Here is a summary to compare the palette before and after sorting.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个总结，用于比较排序前后的调色板。
- en: '![](../Images/06f4b38e027140ee70fe902282a01f76.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/06f4b38e027140ee70fe902282a01f76.png)'
- en: 'Image Source: Author'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：作者
- en: The detailed code is in the notebook but here below is how I used Plotly to
    generate the palette.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 详细代码在笔记本中，但下面是我如何使用Plotly生成调色板的。
- en: 'Image Source: Author'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：作者
- en: '**Step 4: Cluster Analysis**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤4：簇分析**'
- en: In case you are curious about the pixels that were grouped together in the image,
    here’s how you can visualize them. Use the ***predict()*** method to predict the
    closest cluster to each sample in your data. Since this can be performed on your
    training data because we are not evaluating the performance, but rather assessing
    patterns in the data — the unlabelled training or unseen set, hence, to assign
    the data points in the RGB DataFrame, I passed it to the ***predict()*** in *line
    1*. Then, added the predicted array of cluster numbers back to the dataset.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对图像中分组在一起的像素感到好奇，这里有一种可视化它们的方法。使用***predict()***方法预测数据中每个样本最接近的簇。由于我们不是在评估性能，而是在评估数据中的模式，所以可以在训练数据上执行此操作
    —— 即未标记的训练数据或未见过的数据集，因此，我将其传递给了*line 1*中的***predict()***。然后，将预测的簇编号数组添加回数据集。
- en: 'Image Source: Author'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：作者
- en: In *line 3*, I used the lambda function to map the individual R, G, and B values
    in each column of the RGB DataFrame and convert the RGB value to the corresponding
    Hex code since it is easier to plot using [Seaborn’s color_palette() method](https://seaborn.pydata.org/generated/seaborn.color_palette.html)
    in a single line of code. Below, is the function that is used to convert from
    RGB to Hex.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在*line 3*中，我使用了lambda函数来映射RGB DataFrame中每列的单个R、G和B值，并将RGB值转换为相应的Hex代码，因为使用[Seaborn的color_palette()方法](https://seaborn.pydata.org/generated/seaborn.color_palette.html)绘制起来更简单。下面是用于将RGB转换为Hex的函数。
- en: 'Image Source: Author'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图像来源：作者
- en: Finally, I wrapped the visualizing process of each cluster in a for loop (*lines
    4 to 6*) where for each cluster number, beginning from 0 to the palette size/number
    of clusters ([exclusive](https://www.geeksforgeeks.org/python-range-function/)),
    the corresponding Hex codes (up to 10 as specified with [:10])are shown using
    ***seaborn.color_palette()*** method in *line 6*.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我将每个簇的可视化过程包裹在一个 for 循环中（*第 4 到第 6 行*），对于每个簇编号，从 0 到调色板大小/簇数（[排除](https://www.geeksforgeeks.org/python-range-function/)），使用
    ***seaborn.color_palette()*** 方法在 *第 6 行* 显示相应的 Hex 代码（最多 10 个，如 [:10] 指定的）。
- en: 'Here’s the color palette or cluster centers to compare & associate with the
    clusters:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这是颜色调色板或簇中心，用于比较和关联簇：
- en: '![](../Images/04488d97005621b1c43a6f8bc982c2d8.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/04488d97005621b1c43a6f8bc982c2d8.png)'
- en: 'Image Source: Author'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Below are the colors in each cluster. *Note that the palette is sorted as shown
    before and they correspond to clusters 3, 0, 5, 2, 4, and 1, respectively.*
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是每个簇中的颜色。 *请注意，调色板按之前显示的顺序排序，它们分别对应于簇 3、0、5、2、4 和 1。*
- en: '![](../Images/214f643ccb7c1de868daa3ddb43316b9.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/214f643ccb7c1de868daa3ddb43316b9.png)'
- en: 'Image Source: Author'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**Step 5: Using Palette with the Popular Visualization Libraries**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 5 步：使用流行的可视化库中的调色板**'
- en: 'To do so, I converted the RGB values to a list of Hex values which can directly
    be passed as a list of colors in the visualization methods. Here’s the code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我将 RGB 值转换为可以直接作为颜色列表传递到可视化方法中的 Hex 值列表。以下是代码：
- en: 'Image Source: Author'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**Seaborn**'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Seaborn**'
- en: Here’s an example of using the palette on a Seaborn barplot. In Seaborn, we
    can set the palette as in *line 3* or directly pass the *list_hex*.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在 Seaborn 条形图上使用调色板的示例。在 Seaborn 中，我们可以像在 *第 3 行* 中那样设置调色板，或者直接传递 *list_hex*。
- en: 'Image Source: Author'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '![](../Images/9cf3f9daebb0da658e5058b719e359e8.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9cf3f9daebb0da658e5058b719e359e8.png)'
- en: 'Image Source: Author'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**2\. Plotly**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. Plotly**'
- en: Here’s an example of using the palette on a Plotly barplot. I have used the
    *list_hex* for the parameter color_discrete_sequence as in *line 3.*
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在 Plotly 条形图上使用调色板的示例。我使用了 *list_hex* 作为参数 color_discrete_sequence，如 *第 3
    行* 所示。
- en: 'Image Source: Author'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 'Image Source: Author'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '**3\. Matplotlib**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. Matplotlib**'
- en: Here’s an example of using the palette on a Matplotlib barplot where I passed
    the *list_hex* for the parameter color in *line 8*.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在 Matplotlib 条形图上使用调色板的示例，其中我将 *list_hex* 作为参数 color 传递在 *第 8 行*。
- en: 'Image Source: Author'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: '![](../Images/16164744f9378348eabe81173227da41.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16164744f9378348eabe81173227da41.png)'
- en: 'Image Source: Author'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: Hope you enjoyed this clustering exercise 🙂. ***Here’s the complete*** [***Notebook***](https://github.com/royn5618/Medium_Blog_Codes/blob/master/color_palette_generator/color_palette_generator.ipynb)
    ***and a demo below!***
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你喜欢这个聚类练习 🙂。 ***这是完整的*** [***笔记本***](https://github.com/royn5618/Medium_Blog_Codes/blob/master/color_palette_generator/color_palette_generator.ipynb)
    ***和下面的演示！***
- en: 'Video Source: Author'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 视频来源：作者
- en: 'References:'
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[Clustering Algorithms](https://developers.google.com/machine-learning/clustering/clustering-algorithms)
    | Google'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[聚类算法](https://developers.google.com/machine-learning/clustering/clustering-algorithms)
    | Google'
- en: '[What is unsupervised learning? | IBM](https://www.ibm.com/topics/unsupervised-learning#:~:text=the%20next%20step-,What%20is%20unsupervised%20learning%3F,the%20need%20for%20human%20intervention)'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[什么是无监督学习？ | IBM](https://www.ibm.com/topics/unsupervised-learning#:~:text=the%20next%20step-,What%20is%20unsupervised%20learning%3F,the%20need%20for%20human%20intervention)'
- en: '[The HSV Color Model in Graphic Design](https://www.lifewire.com/what-is-hsv-in-design-1078068)'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[图形设计中的 HSV 颜色模型](https://www.lifewire.com/what-is-hsv-in-design-1078068)'
- en: '[Digital Image Basics](https://www.shsu.edu/~csc_dsb/DigitalImage/DigitalImages.html)'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[数字图像基础](https://www.shsu.edu/~csc_dsb/DigitalImage/DigitalImages.html)'
- en: '[What does the parameter n_init actually do?](https://stackoverflow.com/questions/46359490/python-scikit-learn-k-means-what-does-the-parameter-n-init-actually-do)
    | StackOverFlow'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[n_init 参数实际上做了什么？](https://stackoverflow.com/questions/46359490/python-scikit-learn-k-means-what-does-the-parameter-n-init-actually-do)
    | StackOverFlow'
- en: '[How Could One Implement the K-Means++ Algorithm?](https://stackoverflow.com/questions/5466323/how-could-one-implement-the-k-means-algorithm)
    | StackOverFlow'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[如何实现 K-Means++ 算法？](https://stackoverflow.com/questions/5466323/how-could-one-implement-the-k-means-algorithm)
    | StackOverFlow'
- en: '[Lecture 2 — The k-means clustering problem](https://cseweb.ucsd.edu/~dasgupta/291-unsup/lec2.pdf)
    | University of California San Diego'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[讲座 2 — k-means 聚类问题](https://cseweb.ucsd.edu/~dasgupta/291-unsup/lec2.pdf)
    | 加州大学圣地亚哥分校'
- en: '[Lecture 10: k-means clustering](http://www.cs.yale.edu/homes/el327/datamining2013aFiles/10_k_means_clustering.pdf)
    | Yale'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[第10讲：k-means 聚类](http://www.cs.yale.edu/homes/el327/datamining2013aFiles/10_k_means_clustering.pdf)
    | 耶鲁大学'
- en: '[CS229 Lecture notes | Andrew Ng](http://cs229.stanford.edu/notes2020spring/cs229-notes7a.pdf)'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[CS229 讲义 | Andrew Ng](http://cs229.stanford.edu/notes2020spring/cs229-notes7a.pdf)'
- en: 🔍Looking for Supervised Machine Learning Articles?
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 🔍 寻找监督学习相关文章？
- en: '[](/a-simplified-explanation-of-supervised-machine-learning-for-electrical-and-electronics-engineers-6d533cdedc6d?source=post_page-----94bb8e6a1416--------------------------------)
    [## A Simplified Explanation of Supervised Machine Learning for Electrical and
    Electronics Engineers'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/a-simplified-explanation-of-supervised-machine-learning-for-electrical-and-electronics-engineers-6d533cdedc6d?source=post_page-----94bb8e6a1416--------------------------------)
    [## 电气和电子工程师的监督学习简化解释'
- en: If you landed up in Electrical or Electronics engineering domain (like I was
    once myself), you are probably dealing…
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如果你进入了电气或电子工程领域（就像我曾经一样），你可能正在处理……
- en: 'towardsdatascience.com](/a-simplified-explanation-of-supervised-machine-learning-for-electrical-and-electronics-engineers-6d533cdedc6d?source=post_page-----94bb8e6a1416--------------------------------)
    [](/predicting-hazardous-seismic-bumps-using-supervised-classification-algorithms-part-i-2c5d21f379bc?source=post_page-----94bb8e6a1416--------------------------------)
    [## Predicting Hazardous Seismic Bumps Part I : EDA, Feature Engineering & Splitting
    Unbalanced Dataset'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/a-simplified-explanation-of-supervised-machine-learning-for-electrical-and-electronics-engineers-6d533cdedc6d?source=post_page-----94bb8e6a1416--------------------------------)
    [](/predicting-hazardous-seismic-bumps-using-supervised-classification-algorithms-part-i-2c5d21f379bc?source=post_page-----94bb8e6a1416--------------------------------)
    [## 预测危险的地震突发 Part I：探索性数据分析、特征工程与不平衡数据集拆分
- en: This article demonstrates exploratory data analysis (EDA), feature engineering,
    and splitting strategies for unbalanced…
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本文展示了探索性数据分析（EDA）、特征工程以及不平衡数据集的拆分策略……
- en: 'towardsdatascience.com](/predicting-hazardous-seismic-bumps-using-supervised-classification-algorithms-part-i-2c5d21f379bc?source=post_page-----94bb8e6a1416--------------------------------)
    [](/predicting-hazardous-seismic-bumps-part-ii-training-supervised-classifier-models-and-8b9104b611b0?source=post_page-----94bb8e6a1416--------------------------------)
    [## Predicting Hazardous Seismic Bumps Part II: Training & Tuning Supervised ML
    Classifiers and Model…'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/predicting-hazardous-seismic-bumps-using-supervised-classification-algorithms-part-i-2c5d21f379bc?source=post_page-----94bb8e6a1416--------------------------------)
    [](/predicting-hazardous-seismic-bumps-part-ii-training-supervised-classifier-models-and-8b9104b611b0?source=post_page-----94bb8e6a1416--------------------------------)
    [## 预测危险的地震突发 Part II：训练与调优监督机器学习分类器和模型……
- en: This article demonstrates predicting hazardous seismic bumps using binary classifiers,
    tuning model hyperparameters…
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本文展示了使用二分类器预测危险的地震突发，调整模型超参数……
- en: towardsdatascience.com](/predicting-hazardous-seismic-bumps-part-ii-training-supervised-classifier-models-and-8b9104b611b0?source=post_page-----94bb8e6a1416--------------------------------)
    [](/predicting-fake-news-using-nlp-and-machine-learning-scikit-learn-glove-keras-lstm-7bbd557c3443?source=post_page-----94bb8e6a1416--------------------------------)
    [## Predicting Fake News using NLP and Machine Learning | Scikit-Learn | GloVe
    | Keras | LSTM
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/predicting-hazardous-seismic-bumps-part-ii-training-supervised-classifier-models-and-8b9104b611b0?source=post_page-----94bb8e6a1416--------------------------------)
    [](/predicting-fake-news-using-nlp-and-machine-learning-scikit-learn-glove-keras-lstm-7bbd557c3443?source=post_page-----94bb8e6a1416--------------------------------)
    [## 使用 NLP 和机器学习预测假新闻 | Scikit-Learn | GloVe | Keras | LSTM
- en: towardsdatascience.com](/predicting-fake-news-using-nlp-and-machine-learning-scikit-learn-glove-keras-lstm-7bbd557c3443?source=post_page-----94bb8e6a1416--------------------------------)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/predicting-fake-news-using-nlp-and-machine-learning-scikit-learn-glove-keras-lstm-7bbd557c3443?source=post_page-----94bb8e6a1416--------------------------------)
- en: '*Thanks for visiting!*'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢访问！*'
- en: '**My Links:** [Medium](https://medium.com/@nroy0110) | [LinkedIn](https://www.linkedin.com/in/nabanita-roy/)
    | [GitHub](https://github.com/royn5618)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**我的链接：** [Medium](https://medium.com/@nroy0110) | [LinkedIn](https://www.linkedin.com/in/nabanita-roy/)
    | [GitHub](https://github.com/royn5618)'
