- en: ‘Talk’ to Your SQL Database Using LangChain and Azure OpenAI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain 和 Azure OpenAI 与您的 SQL 数据库“对话”
- en: 原文：[https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2?source=collection_archive---------0-----------------------#2023-09-28](https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2?source=collection_archive---------0-----------------------#2023-09-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2?source=collection_archive---------0-----------------------#2023-09-28](https://towardsdatascience.com/talk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2?source=collection_archive---------0-----------------------#2023-09-28)
- en: Explore the power of natural language processing using LLMs for your database
    queries
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索使用 LLM 处理数据库查询的自然语言处理的强大功能
- en: '[](https://medium.com/@cleancoder?source=post_page-----bb79ad22c5e2--------------------------------)[![Satwiki
    De](../Images/868c965bef6bae0c451744bc325eed10.png)](https://medium.com/@cleancoder?source=post_page-----bb79ad22c5e2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb79ad22c5e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb79ad22c5e2--------------------------------)
    [Satwiki De](https://medium.com/@cleancoder?source=post_page-----bb79ad22c5e2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@cleancoder?source=post_page-----bb79ad22c5e2--------------------------------)[![Satwiki
    De](../Images/868c965bef6bae0c451744bc325eed10.png)](https://medium.com/@cleancoder?source=post_page-----bb79ad22c5e2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb79ad22c5e2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb79ad22c5e2--------------------------------)
    [Satwiki De](https://medium.com/@cleancoder?source=post_page-----bb79ad22c5e2--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd4bbc4d61092&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftalk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2&user=Satwiki+De&userId=d4bbc4d61092&source=post_page-d4bbc4d61092----bb79ad22c5e2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb79ad22c5e2--------------------------------)
    ·10 min read·Sep 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb79ad22c5e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftalk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2&user=Satwiki+De&userId=d4bbc4d61092&source=-----bb79ad22c5e2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd4bbc4d61092&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftalk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2&user=Satwiki+De&userId=d4bbc4d61092&source=post_page-d4bbc4d61092----bb79ad22c5e2---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb79ad22c5e2--------------------------------)
    · 10 分钟阅读 · 2023年9月28日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb79ad22c5e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftalk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2&user=Satwiki+De&userId=d4bbc4d61092&source=-----bb79ad22c5e2---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb79ad22c5e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftalk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2&source=-----bb79ad22c5e2---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb79ad22c5e2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftalk-to-your-sql-database-using-langchain-and-azure-openai-bb79ad22c5e2&source=-----bb79ad22c5e2---------------------bookmark_footer-----------)'
- en: Langchain is an open source framework for developing applications which can
    process natural language using LLMs (Large Language Models).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个开源框架，用于开发可以使用 LLM（大型语言模型）处理自然语言的应用程序。
- en: The ***Agent*** component of LangChain is a wrapper around LLM, which decides
    the best steps or actions to take to solve a problem. The Agent typically has
    access to a set of functions called ***Tools*** (or Toolkit) and it can decide
    which Tool to use based on the user input. Each agent can perform various NLP
    tasks, such as parsing, calculations, translation etc.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的 ***Agent*** 组件是一个 LLM 的封装器，它决定解决问题的最佳步骤或行动。Agent 通常可以访问一组称为 ***Tools***（或工具包）的功能，并且可以根据用户输入决定使用哪个工具。每个代理都可以执行各种
    NLP 任务，例如解析、计算、翻译等。
- en: An ***Agent Executor*** is a runnable interface of the Agent and its set of
    Tools. The agent executor is responsible for calling the agent, getting the action
    and action input, calling the tool that the action references with the corresponding
    input, getting the output of the tool, and then passing all that information back
    into the Agent to get the next action it should take. Usually it is an iterative
    process until the Agent reaches the Final Answer or output.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '***Agent Executor*** 是 Agent 及其工具集的可运行接口。Agent 执行器负责调用 Agent、获取操作和操作输入、调用操作引用的工具及其对应输入、获取工具的输出，然后将所有这些信息传回
    Agent 以获取下一步操作。通常这是一个迭代过程，直到 Agent 达到最终答案或输出。'
- en: In this article, I will show you how we can use ***LangChain Agent*** and ***Azure
    OpenAI gpt-35-turbo model*** to query your SQL database using natural language
    (without writing any SQL at all!) and get useful data insights. We will use [SQL
    Database Toolkit and Agent](https://python.langchain.com/docs/integrations/toolkits/sql_database)
    which can convert user input into appropriate SQL query and run it in Database
    to get an answer.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将展示如何使用 ***LangChain Agent*** 和 ***Azure OpenAI gpt-35-turbo 模型*** 通过自然语言查询你的
    SQL 数据库（无需编写任何 SQL！）并获取有用的数据洞察。我们将使用 [SQL Database Toolkit and Agent](https://python.langchain.com/docs/integrations/toolkits/sql_database)，它可以将用户输入转换为适当的
    SQL 查询，并在数据库中执行以获取答案。
- en: This is an exploratory article. It aims to provide an overview of the currently
    available tools and identify any challenge during the process.
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是一篇探索性文章。它旨在提供对当前可用工具的概述，并在过程中识别任何挑战。
- en: '![](../Images/58a5e9d9807e7f7a8770e0f7fe6397fe.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58a5e9d9807e7f7a8770e0f7fe6397fe.png)'
- en: Image by author (created using Bing Image creator)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片（使用 Bing 图像创作者创建）
- en: Scope of Requirement
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 需求范围
- en: For this exploration, we will only read data from the DB and avoid any insert,
    update or delete operations. This is to preserve the data integrity in the DB.
    We will focus on how we can answer questions using the data available in the DB.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次探索中，我们只读取数据库中的数据，避免任何插入、更新或删除操作。这是为了保持数据库中的数据完整性。我们将重点关注如何利用数据库中可用的数据来回答问题。
- en: '*However the SQL Agent does not guarantee that it will not perform any DML
    operations on your database based on specific questions. One way to ensure that
    any accidental DML operation does not happen is to create a database user with
    only* `*read*` *access and use it in following code.*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*不过，SQL Agent 不保证它不会根据特定的问题对你的数据库执行任何 DML 操作。确保不发生任何意外 DML 操作的一种方法是创建一个仅具有*
    `*read*` *权限的数据库用户，并在以下代码中使用它。*'
- en: Let’s take an e-retail company’s order and inventory system database for example.
    The inventory keeps track of products across multiple categories e.g. kitchen,
    gardening, stationary, bath etc. The order system records purchase history including
    order status, delivery date etc. for each product.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个电子零售公司的订单和库存系统数据库为例。库存跟踪多个类别的产品，例如厨房、园艺、文具、浴室等。订单系统记录每个产品的购买历史，包括订单状态、交货日期等。
- en: 'Following can be some of the questions from the end users of this application:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下可能是该应用程序的最终用户提出的一些问题：
- en: Quantity of kitchen products were sold last month.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上个月销售的厨房产品数量。
- en: How many orders have not been shipped yet?
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有多少订单尚未发货？
- en: How many orders were delivered late last month?
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上个月有多少订单延迟交付？
- en: What are the top 3 products sold last month?
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上个月销售的前三大产品是什么？
- en: Set up
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置
- en: '**Python>=3.8** and an IDE for our exploration. I use VS Code.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Python>=3.8** 和一个 IDE 进行我们的探索。我使用 VS Code。'
- en: I use [Azure OpenAI gpt-35-turbo](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35)
    as LLM here. This model is part of GPT-3.5 family, which can understand and generate
    natural language and code. To follow along, you need an Azure subscription with
    OpenAI service enabled. Know more [here](https://azure.microsoft.com/en-in/products/cognitive-services/openai-service).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我在这里使用 [Azure OpenAI gpt-35-turbo](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35)
    作为 LLM。这个模型是 GPT-3.5 系列的一部分，可以理解和生成自然语言及代码。要跟随本指南，你需要一个启用了 OpenAI 服务的 Azure 订阅。了解更多
    [here](https://azure.microsoft.com/en-in/products/cognitive-services/openai-service)。
- en: I use an Azure SQL database here. However you can use an on-prem SQL DB too.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我在这里使用一个 Azure SQL 数据库。然而，你也可以使用本地 SQL 数据库。
- en: Database
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据库
- en: 'I created a database named as `retailshopdb` with following Tables and relationships:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了一个名为`retailshopdb`的数据库，包含以下表格和关系：
- en: Category
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类别
- en: Product
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 产品
- en: Orders
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 订单
- en: '![](../Images/0a01abef276c66b45260e815e1eea53a.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a01abef276c66b45260e815e1eea53a.png)'
- en: Image by author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Along with ‘Id’ columns being the primary keys for each table, the tables have
    foreign key relationships with each other e.g. CategoryId is a foreign key in
    Product table, and ProductId is a foreign key in Orders table. These relationships
    are crucial for the LangChain agent to construct the SQL query as per end user’s
    question.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了‘Id’列作为每个表的主键外，这些表还有相互之间的外键关系，例如 CategoryId 是 Product 表中的外键，ProductId 是 Orders
    表中的外键。这些关系对于 LangChain 代理根据最终用户的问题构造 SQL 查询至关重要。
- en: Azure OpenAI
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure OpenAI
- en: If you have an Azure OpenAI resource created in your subscription, navigate
    to Azure OpenAI studio. Create a `deployment` for `gpt-35-turbo` model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在订阅中创建了 Azure OpenAI 资源，请导航到 Azure OpenAI Studio。为 `gpt-35-turbo` 模型创建一个
    `deployment`。
- en: '![](../Images/996e8596678ca87575eeff03859929cd.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/996e8596678ca87575eeff03859929cd.png)'
- en: Image by author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Code & Output Analysis
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码与输出分析
- en: Let’s start with some base code to access the LLM from in VS code python notebook.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一些基础代码开始，以便在 VS Code Python 笔记本中访问 LLM。
- en: Initialize the notebook by installing required libraries and setting required
    environment variables.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过安装所需的库并设置所需的环境变量来初始化笔记本。
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 2\. Connect to the DB.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 连接到数据库。
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 3\. Initialize LangChain `chat_model` instance which provides an interface to
    invoke a LLM provider using chat API. The reason to select chat model is the `gpt-35-turbo`
    model is optimized for chat, hence we use `AzureChatOpenAI` class here to initialize
    the instance.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 初始化 LangChain `chat_model` 实例，它提供了使用聊天 API 调用 LLM 提供者的接口。选择聊天模型的原因是 `gpt-35-turbo`
    模型已针对聊天进行了优化，因此我们在这里使用 `AzureChatOpenAI` 类来初始化实例。
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that `temperature` is set as 0\. Temperature is a parameter that controls
    the “creativity” or randomness of the text generated. A lower temperature (0 being
    the lowest) makes the output more “focused” or deterministic. Since we’re dealing
    with Database here, it’s important that LLM generates factual response.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请注意，`temperature` 设置为 0。温度是一个控制生成文本的“创造力”或随机性的参数。较低的温度（0 为最低）使输出更“专注”或确定。由于我们处理的是数据库，LLM
    生成的响应必须是事实性的。
- en: 4\. Create a Prompt Template.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 创建提示模板。
- en: '***Prompt*** is the input that we send to the LLM to generate an output. ***Prompt
    can also be designed to contain instructions, context, examples (one shot or few
    shot)*** which can be crucial for generating accurate output, as well as setting
    the tone and formatting your output data.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '***提示*** 是我们发送给 LLM 以生成输出的输入。***提示也可以设计为包含指令、上下文、示例（单次或少次）***，这些都对生成准确的输出至关重要，同时也可以设置语气和格式化输出数据。'
- en: Using Prompt Template is a good way to structure these properties including
    the end user’s input to be provided to the LLM. We use LangChain’s `ChatPromptTemplate`
    module here, which is based on ChatML (Chat Markup Language).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提示模板是结构化这些属性的好方法，包括提供给 LLM 的最终用户输入。我们在这里使用 LangChain 的 `ChatPromptTemplate`
    模块，它基于 ChatML（聊天标记语言）。
- en: This is a base prompt template to start with. Over time, we will update this
    template as needed —
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基础提示模板，供我们开始使用。随着时间的推移，我们会根据需要更新此模板 —
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now initialize the `create_sql_agent` which is designed to interact with SQL
    Database as below. The agent is equipped with toolkit to connect to your SQL database
    and read both the metadata and content of the tables.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在初始化 `create_sql_agent`，它设计用于与 SQL 数据库交互，如下所示。该代理配备了与 SQL 数据库连接并读取表的元数据和内容的工具包。
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note that we use `ZERO_SHOT_REACT_DESCRIPTION` here as the value of `agent_type`
    parameter, which instructs that the agent *does not use memory.*
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在这里使用 `ZERO_SHOT_REACT_DESCRIPTION` 作为 `agent_type` 参数的值，这指示代理 *不使用记忆*。
- en: All set to run our testing —
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪进行测试 —
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice in the following cell output how the LangChain Agent Executor is using
    the flow of `Action` , `Observation` and `Thought` in an iterative manner, until
    it reaches a `Final Answer`.
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意在以下单元格输出中，LangChain Agent Executor 如何以迭代的方式使用 `Action`、`Observation` 和 `Thought`
    流，直到达到 `Final Answer`。
- en: '![](../Images/dc80bc8bb758a01f49c71be0e5e9e208.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc80bc8bb758a01f49c71be0e5e9e208.png)'
- en: Image by author
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '*Output: 10*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出: 10*'
- en: This is a correct answer.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个正确的答案。
- en: Let’s have some fun, shall we? Replace ‘Quantity’ with ‘how many’ in the same
    question, which should produce the same answer.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来点乐趣吧？将问题中的‘Quantity’替换为‘how many’，这应该会产生相同的答案。
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: But this is what we get —
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 但这就是我们得到的结果 —
- en: '![](../Images/6df046e7da8416c6f52e628bf429474d.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6df046e7da8416c6f52e628bf429474d.png)'
- en: Image by author
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '*Output: ‘2 kitchen products were sold in the current month.’*'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出: ‘本月销售了 2 件厨房产品。’*'
- en: '***This output is not correct!***The Agent makes a mistake in the SQL query
    creation. Instead of doing `SUM(ProductOrderedQuantity)` to get the output, it
    does a `COUNT(*)` on the JOIN result which gives the wrong output.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '***这个输出不正确！*** 代理在创建 SQL 查询时犯了错误。它没有执行 `SUM(ProductOrderedQuantity)` 来获取输出，而是对
    JOIN 结果执行了 `COUNT(*)`，这导致了错误的输出。'
- en: '**Why changing the prompt input slightly produces different outputs?**'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**为什么稍微改变提示输入会产生不同的输出？**'
- en: ''
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: OpenAI models are non-deterministic, meaning that identical inputs can yield
    different outputs. Setting temperature to 0 will make the outputs mostly deterministic,
    but a small amount of variability may remain due to GPU floating point math.
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenAI 模型是非确定性的，这意味着相同的输入可能会产生不同的输出。将温度设置为 0 会使输出大多是确定性的，但由于 GPU 浮点运算，可能仍会存在少量的变异。
- en: Running another test with a different input—
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的输入运行另一个测试 —
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/b17c40ba6c5169f621273cd1cb3666e5.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b17c40ba6c5169f621273cd1cb3666e5.png)'
- en: Image by author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '*Output: ‘There are 15 orders that have not been shipped yet.’*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：‘还有 15 个订单尚未发货。’*'
- en: '***This is again incorrect result.*** *The agent takes into account ‘Completed’
    orders as well, when our question implies only the orders which have not been
    shipped.*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '***这又是错误的结果。*** *代理也考虑了‘已完成’的订单，而我们的提问仅涉及尚未发货的订单。*'
- en: Let’s see what modifications we can make to produce accurate outputs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看可以做哪些修改以生成准确的输出。
- en: Play with Prompt Engineering
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 玩转 Prompt Engineering
- en: The LangChain agent can read table metadata from SQL Database using its Toolkit,
    and to some extent it can interpret the column names as well. But there are still
    some gap in reasoning, which we can try to mitigate using Prompt Engineering technique.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 代理可以使用其工具包从 SQL 数据库中读取表格元数据，并且在一定程度上可以解释列名。但是仍然存在一些推理上的差距，我们可以尝试使用
    Prompt Engineering 技术来弥补这些差距。
- en: 'We started with a base prompt template having a single line of instruction.
    Let’s include some additional information to provide more context about our use
    case to the LLM in order to form better SQL query. Here are the information I
    added in the System message on a high-level:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个基础提示模板开始，该模板只有一行指令。让我们添加一些额外的信息，以便向 LLM 提供更多关于我们用例的上下文，以形成更好的 SQL 查询。以下是我在系统消息中添加的高层次信息：
- en: Information about Table columns
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 表格列的信息
- en: ‘Meaning’ of Order Status values
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 订单状态值的‘含义’
- en: Most specific information at the end
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最具体的信息在最后
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now run the first input again—
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在重新运行第一个输入 —
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/df0a705e4289d08e6deddb162df978fd.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df0a705e4289d08e6deddb162df978fd.png)'
- en: Image by author
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '*Output: 10*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：10*'
- en: The reasoning has improved! By providing additional context to the LLM, we were
    able to get an accurate output.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 推理得到了改善！通过向 LLM 提供额外的上下文，我们能够获得准确的输出。
- en: Now test all user inputs —
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在测试所有用户输入 —
- en: '![](../Images/80a87b16e47fddd1f271be3bfc8b9171.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/80a87b16e47fddd1f271be3bfc8b9171.png)'
- en: After-thoughts . . .
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思考之后 . . .
- en: All this looks good for play, but what if we want to actually build a solution
    and release it for end users consumption? This is a great idea for use cases like
    chatbot on your own database, however any like any typical software development,
    we also need to think and decide about some crucial design aspects before building
    LLM-based systems.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切在测试时看起来都很不错，但如果我们想实际构建一个解决方案并将其发布供最终用户使用呢？这是一个很好的想法，适用于类似于在自己数据库上运行聊天机器人的用例，但像任何典型的软件开发一样，在构建基于
    LLM 的系统之前，我们还需要考虑和决定一些关键的设计方面。
- en: Scalability
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性
- en: 'In this example, I have used 3 tables with total ~30 rows. The avg. latency
    to produce an output which involves joining all 3 tables is ~5 secs. As of today,
    I didn’t find any information in official docs on the maximum size of database
    we can use with this Agent. However there are few parameters we can think of to
    determine our requirements:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我使用了 3 个表，总共约 30 行。涉及连接所有 3 个表的输出的平均延迟约为 5 秒。截至目前，我在官方文档中没有找到关于我们可以使用的数据库最大大小的信息。然而，我们可以考虑一些参数来确定我们的需求：
- en: What is the Latency required by your application? If you’re building a chatbot,
    then your expected latency might not go beyond a certain number.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的应用程序需要的延迟是多少？如果您正在构建一个聊天机器人，那么您的预期延迟可能不会超过某个数值。
- en: What is your Database size? Also take into account the size of individual tables
    which you want to use for query.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的数据库大小是多少？还要考虑您希望用于查询的各个表的大小。
- en: Note that you don’t need to pass entire Database to the Agent Toolkit. There
    is option to select specific tables to work with the Toolkit. A good option is
    to identify subsets of tables for separate use cases, and create multiple Agents
    pointing to different subset of tables.
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请注意，你不需要将整个数据库传递给 Agent Toolkit。可以选择特定的表与 Toolkit 一起使用。一个好的选择是为不同的用例识别表的子集，并创建多个指向不同表子集的
    Agent。
- en: 3\. Rate and quota limit of your Azure OpenAI resource. If you’re using another
    LLM provider, then look for limitations/restrictions there too.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. Azure OpenAI 资源的速率和配额限制。如果你使用的是其他 LLM 提供商，也请查看那里可能存在的限制/约束。
- en: Reliability
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可靠性
- en: How can we ensure that we get accurate response consistently? How do we make
    sure the system does not hallucinate or produce completely unexpected content?
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何确保始终获得准确的响应？如何确保系统不会出现幻觉或产生完全意外的内容？
- en: There is ongoing research on improving reliability and robustness of LLMs. Using
    use case specific prompts we can help improve the reasoning for our use case,
    which is also sometimes termed as ‘temporary or in-context learning’.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当前正在研究如何提高 LLM 的可靠性和鲁棒性。通过使用特定用例的提示，我们可以帮助改善我们的用例的推理，这有时也被称为“临时学习”或“上下文学习”。
- en: Remember that we are not training LLMs here. From a perspective of building
    products using the pre-trained LLMs, we can only tweak our code, model parameters
    and prompts that are built on top of these LLMs, but tweak them in a targeted
    way.
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请记住，我们在这里不是在训练 LLM。从使用预训练 LLM 构建产品的角度，我们只能有针对性地调整我们的代码、模型参数和构建在这些 LLM 上的提示。
- en: Development in an iterative manner and also evaluation along the way can take
    us to the right direction to develop an overall working system.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 以迭代方式进行开发，并在过程中进行评估，可以将我们引向正确的方向，开发一个整体有效的系统。
- en: Logging and Monitoring
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日志记录和监控
- en: 'Like any other typical software development, enabling logging and continuous
    monitoring of the LLM-based applications is a good practice. Monitoring can not
    only capture system-related metrics like performance, latency, request-response
    rates, but also the inputs and outputs from our system, which can help us determining
    the consistency of the system. Some useful information we can gather from Monitoring
    and use to improve our system:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 像其他典型的软件开发一样，启用日志记录和持续监控 LLM 基础的应用程序是一种好习惯。监控不仅可以捕获系统相关的指标，如性能、延迟、请求-响应率，还可以捕获我们系统的输入和输出，这可以帮助我们确定系统的一致性。从监控中收集的一些有用信息可以用来改进我们的系统：
- en: Frequent, similar questions from end user, and outputs generated for these questions
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 终端用户频繁提出类似问题，以及这些问题生成的输出
- en: Hallucination rate of LLM
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM 的幻觉率
- en: Conclusion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: The Software Engineering world is changing rapidly with LLMs’ immense generative
    capability, and there are many solutions coming up in this space. We have an opportunity
    to adopt this technology, and harness its power to create products while also
    keeping a check on reliability of LLM-backed systems. It is always a good idea
    to start small, build a proof-of-concept app and see if it fits your requirement.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程领域正在迅速变化，LLM 的巨大生成能力带来了许多解决方案。我们有机会采用这项技术，利用其力量创建产品，同时保持对 LLM 支持系统的可靠性的检查。通常，从小处开始，建立一个概念验证应用程序，看看它是否符合你的需求，总是一个好主意。
- en: 'References:'
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献：
- en: '[https://community.openai.com/t/run-same-query-many-times-different-results/140588](https://community.openai.com/t/run-same-query-many-times-different-results/140588)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://community.openai.com/t/run-same-query-many-times-different-results/140588](https://community.openai.com/t/run-same-query-many-times-different-results/140588)'
- en: '[https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai_api)'
- en: '[https://mlops.community/concepts-for-reliability-of-llms-in-production/](https://mlops.community/concepts-for-reliability-of-llms-in-production/)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://mlops.community/concepts-for-reliability-of-llms-in-production/](https://mlops.community/concepts-for-reliability-of-llms-in-production/)'
- en: '*Please follow me if you want to read more such content about new and exciting
    technology. Please leave your feedback in the comment section.*'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你想阅读更多关于新兴技术的内容，请关注我。请在评论区留下你的反馈。*'
