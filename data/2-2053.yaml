- en: 'The Power of OpenAI’s Function Calling in Data Pipelines: A Comprehensive Guide'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI的函数调用在数据管道中的力量：全面指南
- en: 原文：[https://towardsdatascience.com/the-power-of-openais-function-calling-in-language-learning-models-a-comprehensive-guide-cce8cd84dc3c](https://towardsdatascience.com/the-power-of-openais-function-calling-in-language-learning-models-a-comprehensive-guide-cce8cd84dc3c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-power-of-openais-function-calling-in-language-learning-models-a-comprehensive-guide-cce8cd84dc3c](https://towardsdatascience.com/the-power-of-openais-function-calling-in-language-learning-models-a-comprehensive-guide-cce8cd84dc3c)
- en: 'Transforming Data Pipelines with OpenAI’s Function Calling Feature: Implementing
    an Email Sending Workflow Using PostgreSQL and FastAPI'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用OpenAI的函数调用功能改造数据管道：使用PostgreSQL和FastAPI实现电子邮件发送工作流
- en: '[](https://medium.com/@luisroque?source=post_page-----cce8cd84dc3c--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----cce8cd84dc3c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cce8cd84dc3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cce8cd84dc3c--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----cce8cd84dc3c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@luisroque?source=post_page-----cce8cd84dc3c--------------------------------)[![Luís
    Roque](../Images/e281d470b403375ba3c6f521b1ccf915.png)](https://medium.com/@luisroque?source=post_page-----cce8cd84dc3c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cce8cd84dc3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cce8cd84dc3c--------------------------------)
    [Luís Roque](https://medium.com/@luisroque?source=post_page-----cce8cd84dc3c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cce8cd84dc3c--------------------------------)
    ·11 min read·Jun 22, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cce8cd84dc3c--------------------------------)
    ·阅读时间11分钟·2023年6月22日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: The exciting world of AI has taken another leap forward by the introduction
    of function calling capabilities in OpenAI’s latest Large Language Models (LLMs).
    This new feature enhances the interaction between humans and AI, transforming
    it from a simple question-and-answer format to a more dynamic and active dialogue.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: AI的激动人心的世界通过OpenAI最新的大型语言模型（LLMs）引入的函数调用能力又迈进了一步。这个新功能增强了人类与AI之间的互动，将其从简单的问答形式转变为更具动态性和主动性的对话。
- en: But what exactly are these function calling capabilities? At their core, they
    allow the LLM to call predefined functions during a conversation based on the
    input instructions. This could be anything from sending an email to fetching data
    from a database based on the context of the conversation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这些函数调用能力到底是什么呢？本质上，它们允许LLM在对话中根据输入指令调用预定义的函数。这可以是任何操作，从发送电子邮件到根据对话的上下文从数据库中提取数据。
- en: The benefits and applications of using function calling capabilities are vast.
    It significantly increases the dynamic utility of AI in various applications,
    from customer service to how we build data pipelines.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用函数调用能力的好处和应用广泛。它显著提升了AI在各种应用中的动态效用，从客户服务到数据管道的构建。
- en: Imagine a customer service AI that can answer questions and perform actions
    such as booking appointments, sending information to an email address, or updating
    customer details in real time. Or consider a data pipeline where the LLM agent
    can fetch, update, and manipulate data on command.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下一个客户服务AI，它可以回答问题并执行诸如预约、向电子邮件地址发送信息或实时更新客户详情等操作。或者考虑一个数据管道，其中LLM代理可以根据命令获取、更新和处理数据。
- en: In the upcoming sections, we will explore these applications further and provide
    a step-by-step guide on leveraging this new capability by building an email-sending
    pipeline.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将进一步探讨这些应用，并提供一个逐步指南，介绍如何通过构建一个发送电子邮件的管道来利用这一新能力。
- en: '![](../Images/55187b6c2b616d891dc92fe4e5836f25.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55187b6c2b616d891dc92fe4e5836f25.png)'
- en: 'Figure 1: LLMs are becoming intelligent agents that we can work with ([image
    source](https://unsplash.com/photos/cbRuQDMNr4E))'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：LLMs正成为我们可以合作的智能代理（[图片来源](https://unsplash.com/photos/cbRuQDMNr4E)）
- en: As always, the code is available on my [Github](https://github.com/luisroque/large_laguage_models).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，代码可以在我的 [Github](https://github.com/luisroque/large_laguage_models) 上找到。
- en: Understanding the New Function Calling Capability and Comparing It to LangChain
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解新的函数调用能力并与LangChain进行比较
- en: We want to understand what OpenAI’s newly introduced function calling feature
    brings to the AI race. For that, let’s understand what differentiates it from
    other tools and frameworks in the market, like LangChain. We already introduced
    LangChain in the first article of this series. It is a popular framework for developing
    AI-powered applications. The function calling feature and LangChain bring unique
    advantages and capabilities to the table and are built around making AI more usable,
    versatile, and dynamic.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要了解 OpenAI 新引入的函数调用功能在 AI 竞赛中带来了什么。为此，让我们深入了解它与市场上其他工具和框架（如 LangChain）的区别。我们在本系列的第一篇文章中已经介绍了
    LangChain。它是一个用于开发 AI 驱动应用程序的流行框架。函数调用功能和 LangChain 带来了独特的优势和能力，旨在使 AI 更加可用、多样和动态。
- en: We already know that the function calling feature adds an extra layer of interactivity
    to AI applications. It enables the model to call predefined functions within a
    conversation, enhancing the LLM’s dynamism and reactivity. This new feature can
    potentially simplify the process of adding functionality to AI applications. Developers
    would need to define these functions, and the model could then execute them as
    part of the conversation, depending on the context. The primary advantage here
    is its direct integration with the OpenAI models, which facilitates ease of use,
    quick setup, and a lower learning curve for developers familiar with the OpenAI
    ecosystem.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道，函数调用功能为 AI 应用程序增加了一层额外的互动性。它使模型能够在对话中调用预定义的函数，增强了 LLM 的活力和反应能力。这个新功能可能会简化将功能添加到
    AI 应用程序的过程。开发者需要定义这些函数，然后模型可以根据上下文在对话中执行它们。这里的主要优势是与 OpenAI 模型的直接集成，这便于使用、快速设置，并且降低了熟悉
    OpenAI 生态系统的开发者的学习曲线。
- en: On the other hand, LangChain offers a comprehensive and versatile framework
    designed for developing more complex, data-aware, and agentic AI applications.
    It allows a language model to interact with its environment and make decisions
    based on high-level directives. Its modules provide abstractions and standard
    interfaces for building applications, including models, prompts, memory, indexes,
    chains, agents, and callbacks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，LangChain 提供了一个全面且多功能的框架，旨在开发更复杂、数据感知和自主的 AI 应用程序。它允许语言模型与其环境互动，并根据高级指令做出决策。其模块提供了构建应用程序的抽象和标准接口，包括模型、提示、记忆、索引、链、代理和回调。
- en: LangChain’s approach facilitates building applications where an LLM can persist
    its state across different interactions, sequence and chain calls to different
    utilities, and even interact with external data sources. We can see these as function
    calling capabilities on steroids. Thus, it is particularly useful for developers
    building complex, multi-step applications that leverage language models. The downside
    of the added complexity is that it creates a steeper learning curve to use it
    fully.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的方法促进了构建应用程序，其中 LLM 可以在不同的交互中保持其状态，顺序调用和链式调用不同的实用程序，甚至与外部数据源互动。我们可以将这些视为增强的函数调用能力。因此，它对开发者特别有用，尤其是那些构建复杂、多步骤应用程序并利用语言模型的开发者。增加的复杂性带来的缺点是使用起来的学习曲线更陡峭。
- en: Use Case — Transforming Data Pipelines
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例 — 转换数据管道
- en: In my view, data pipelines are among the most exciting application areas for
    the new function calling capabilities in LLMs. Data pipelines are a critical component
    of any data-driven organization that collects, processes, and distributes data.
    Typically, these processes are static, predefined, and require manual intervention
    for any changes or updates. This is where the dynamic behavior of an LLM that
    we discussed above creates an opportunity.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，数据管道是 LLMs 新函数调用能力最令人兴奋的应用领域之一。数据管道是任何数据驱动组织中一个关键组件，它负责收集、处理和分发数据。通常，这些过程是静态的、预定义的，并且需要人工干预以进行任何更改或更新。这正是我们上面讨论的
    LLM 动态行为创造机会的地方。
- en: Traditionally, database querying requires specific knowledge of query languages
    like SQL. With LLMs’ ability to call functions, services, and databases directly,
    users can retrieve data conversationally without the need for explicit query formulation.
    An LLM could translate a user’s request into a database query, fetch the data,
    and return it in a user-friendly format, all in real time. This feature could
    democratize data access across different roles within an organization.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，数据库查询需要特定的查询语言知识，如SQL。借助LLM直接调用函数、服务和数据库的能力，用户可以通过对话检索数据，而不需要显式的查询表述。LLM可以将用户的请求转换为数据库查询，获取数据，并以用户友好的格式实时返回。这一功能可以使组织内的不同角色都能平等地访问数据。
- en: Another aspect that could change is data transformation. It often requires separate
    data cleaning and processing steps before analysis. An LLM could streamline this
    process by performing data cleaning and manipulation tasks interactively based
    on the user’s instructions. Moreover, manipulating real-time data during a conversation
    allows for more exploratory and iterative data analysis.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能发生变化的方面是数据转换。数据转换通常需要在分析之前进行单独的数据清理和处理步骤。LLM可以通过根据用户的指示交互式地执行数据清理和操作任务来简化这一过程。此外，在对话中处理实时数据允许进行更多的探索性和迭代性数据分析。
- en: A third use case is data monitoring. It involves regular checks to ensure the
    accuracy and consistency of data in a data pipeline. With LLMs, monitoring tasks
    can become more interactive and efficient. For instance, an LLM can alert users
    to data inconsistencies during conversations and take corrective actions immediately.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个用例是数据监控。它涉及定期检查以确保数据管道中数据的准确性和一致性。借助LLM，监控任务可以变得更加互动和高效。例如，LLM可以在对话中提醒用户数据不一致，并立即采取纠正措施。
- en: Finally, the LLMs can also automate the creation and distribution of data reports.
    Users can instruct the LLM to generate a report based on specific criteria, and
    the LLM can fetch the data, create the report, and even send it to the relevant
    recipients.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，LLM 还可以自动创建和分发数据报告。用户可以指示 LLM 根据特定标准生成报告，LLM 可以获取数据，创建报告，甚至将其发送给相关的接收者。
- en: Building an Email Sending Pipeline with OpenAI Function Calling Capabilities
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用 OpenAI 函数调用能力构建电子邮件发送管道
- en: We aim to create a pipeline that sends an email to a user. While this may sound
    straightforward, the beauty of this process lies in the interplay of the different
    components controlled by the LLM. The AI model doesn’t merely generate an email
    body; it dynamically interacts with a database to retrieve user information, composes
    a contextually appropriate email, and then instructs a service to send it.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是创建一个发送电子邮件给用户的流程。虽然这听起来很简单，但这个过程的美在于由LLM控制的不同组件之间的相互作用。AI模型不仅仅生成电子邮件正文；它还动态地与数据库互动以检索用户信息，撰写上下文适当的邮件，然后指示服务发送邮件。
- en: 'Our pipeline consists of three main components: PostgreSQL, FastAPI, and the
    OpenAI LLM. We use PostgreSQL to store our user data. This data includes user
    names and their associated email addresses. It serves as our source of truth for
    user information. FastAPI is a modern, high-performance web framework for building
    APIs with Python. We use a FastAPI service to simulate the process of sending
    an email. When the service receives a request to send an email, it returns a response
    confirming the email has been sent. The LLM serves as the orchestrator of the
    entire process. It controls the conversation, determines the necessary actions
    based on the context, interacts with the PostgreSQL database to fetch user information,
    crafts an email message, and instructs the FastAPI service to send the email.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的管道由三个主要组件组成：PostgreSQL、FastAPI 和 OpenAI LLM。我们使用 PostgreSQL 存储用户数据。这些数据包括用户名及其关联的电子邮件地址。它作为我们用户信息的真实来源。FastAPI
    是一个现代、高性能的 Python Web 框架，用于构建 API。我们使用 FastAPI 服务来模拟发送电子邮件的过程。当服务接收到发送电子邮件的请求时，它会返回一个确认电子邮件已发送的响应。LLM
    作为整个过程的协调者。它控制对话，根据上下文确定必要的操作，与 PostgreSQL 数据库互动以获取用户信息，撰写电子邮件内容，并指示 FastAPI 服务发送电子邮件。
- en: Implementing PostgreSQL Database
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施 PostgreSQL 数据库
- en: The first component of our pipeline is the PostgreSQL database where we store
    our user data. Setting up a PostgreSQL instance is made easy and reproducible
    with Docker, a platform that allows us to containerize and isolate our database
    environment.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们管道的第一个组件是 PostgreSQL 数据库，我们在其中存储用户数据。使用 Docker 设置 PostgreSQL 实例变得简单且可重复，Docker
    是一个允许我们容器化和隔离数据库环境的平台。
- en: You first need to install Docker to set up a PostgreSQL Docker container. Once
    installed, you can pull the PostgreSQL image and run it as a container. We map
    the container’s port 5432 to the host’s port 5432 to access the database. In a
    production environment, please set your password as an environment variable and
    do not set them directly in a command as below. We are doing this way to speed
    up our process.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先需要安装 Docker 来设置 PostgreSQL Docker 容器。安装后，你可以拉取 PostgreSQL 镜像并将其作为容器运行。我们将容器的端口
    5432 映射到主机的端口 5432，以访问数据库。在生产环境中，请将密码设置为环境变量，不要像下面这样直接在命令中设置。我们这样做是为了加快我们的过程。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'With our PostgreSQL instance running, we can now create a database and a table
    to store our user data. We’ll use an initialization script to create a `users`table
    with `username` and `email`columns and populate it with some dummy data. This
    script is placed in a directory which is then mapped to the `/docker-entrypoint-initdb.d`
    directory in the container. PostgreSQL executes any scripts found in this directory
    upon startup. Here’s what the script (`user_init.sql`) looks like:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 PostgreSQL 实例运行后，我们现在可以创建一个数据库和一个表来存储我们的用户数据。我们将使用一个初始化脚本来创建一个 `users`
    表，其中包含 `username` 和 `email` 列，并用一些虚拟数据填充它。这个脚本被放置在一个目录中，然后映射到容器中的 `/docker-entrypoint-initdb.d`
    目录。PostgreSQL 在启动时执行此目录下的任何脚本。以下是脚本（`user_init.sql`）的样子：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The LLM is capable of understanding SQL commands and can be used to query the
    PostgreSQL database. When the LLM receives a request that involves fetching user
    data, it can formulate a SQL query to fetch the necessary data from the database.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 能够理解 SQL 命令并用于查询 PostgreSQL 数据库。当 LLM 收到涉及获取用户数据的请求时，它可以生成一个 SQL 查询来从数据库中获取所需的数据。
- en: 'For instance, if you ask the LLM to send an email to `user10`, the LLM can
    formulate the query :'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你要求 LLM 发送一封电子邮件给 `user10`，LLM 可以生成如下查询：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This allows it to fetch `user10` email address from the `users` table. The LLM
    can then use this email address to instruct the FastAPI service to send the email.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这使它能够从 `users` 表中获取 `user10` 的电子邮件地址。LLM 然后可以使用这个电子邮件地址指示 FastAPI 服务发送电子邮件。
- en: In the next section, we will guide you through the implementation of the FastAPI
    service that sends the emails.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将指导你实现发送电子邮件的 FastAPI 服务。
- en: Creating the FastAPI Email Service
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 FastAPI 电子邮件服务
- en: Our second component is a FastAPI service. This service will simulate the process
    of sending emails. It’s a straightforward API that receives a POST request containing
    the recipient’s name, email, and the email body. It will return a response confirming
    the email was sent. We will again use Docker to ensure our service is isolated
    and reproducible.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个组件是 FastAPI 服务。该服务将模拟发送电子邮件的过程。这是一个直接的 API，接收包含收件人姓名、电子邮件和电子邮件正文的 POST
    请求。它将返回一个确认电子邮件已发送的响应。我们将再次使用 Docker 确保我们的服务是隔离和可重复的。
- en: 'First, you need to install Docker (if not already installed). Then, create
    a new directory for your FastAPI service and move into it. Here, create a new
    Python file (e.g., `main.py`) and add the following code:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要安装 Docker（如果尚未安装）。然后，创建一个新的目录用于你的 FastAPI 服务并进入该目录。在这里，创建一个新的 Python 文件（例如，`main.py`）并添加以下代码：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code defines a FastAPI application with a single endpoint `/send_email/`.
    This endpoint accepts POST requests and expects a JSON body containing the recipient’s
    name, email, and the email body.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码定义了一个 FastAPI 应用程序，包含一个单独的端点 `/send_email/`。该端点接受 POST 请求，并期望一个包含收件人姓名、电子邮件和电子邮件正文的
    JSON 数据。
- en: 'Next, create a Dockerfile in the same directory with the following content:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在相同的目录中创建一个 Dockerfile，内容如下：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This Dockerfile instructs Docker to create an image based on the`python:3.9-slim-buster`
    image, a light image ideal for efficiently running python applications. It then
    copies our `main.py` file into the `/app/` directory in the image.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Dockerfile 指示 Docker 创建一个基于 `python:3.9-slim-buster` 镜像的镜像，这是一个理想的轻量级镜像，用于高效运行
    Python 应用程序。然后，它将我们的 `main.py` 文件复制到镜像中的 `/app/` 目录下。
- en: 'You can build the Docker image using the command:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令构建 Docker 镜像：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'And then run it with:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行它：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The LLM interacts with the FastAPI service using a POST request. When the LLM
    decides to send an email, it generates a function call to the `send_email` function.
    The arguments of this function call contain the name, email, and the email body.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 使用 POST 请求与 FastAPI 服务进行交互。当 LLM 决定发送电子邮件时，它生成对 `send_email` 函数的函数调用。此函数调用的参数包含名称、电子邮件和电子邮件正文。
- en: The function call is processed by our Python script, which extracts the function
    arguments and uses them to send a POST request to our FastAPI service. The FastAPI
    service responds with a message indicating the email was successfully sent.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用由我们的 Python 脚本处理，该脚本提取函数参数，并用它们向我们的 FastAPI 服务发送 POST 请求。FastAPI 服务回应一个消息，指示电子邮件已成功发送。
- en: Now, we have all components of our pipeline. The next section will tie everything
    together, explaining how the LLM orchestrates the interaction between the PostgreSQL
    database and the FastAPI service to send an email.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经有了管道的所有组件。下一部分将把所有内容串联在一起，解释 LLM 如何协调 PostgreSQL 数据库和 FastAPI 服务之间的交互以发送电子邮件。
- en: Integrating with OpenAI LLM
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 OpenAI LLM 集成
- en: The last piece of our pipeline is the OpenAI LLM integration. The LLM serves
    as the orchestrator, interpreting our commands, querying the database for user
    information, and instructing the FastAPI service to send emails.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们管道的最后一部分是 OpenAI LLM 集成。LLM 作为协调者，解释我们的命令，查询数据库以获取用户信息，并指示 FastAPI 服务发送电子邮件。
- en: Our script uses OpenAI’s API to make chat-based completions with the LLM. Each
    completion request consists of a series of messages and optionally a list of function
    specifications that the model could call. We start the conversation with a user
    message, which provides a prompt to the assistant.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的脚本使用 OpenAI 的 API 进行基于聊天的完成。每个完成请求由一系列消息和可选的函数规格列表组成，模型可以调用这些函数。我们以用户消息开始对话，这为助手提供了提示。
- en: 'Here’s the `chat_completion_request` function we use to send a request to the
    API:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们用来向 API 发送请求的 `chat_completion_request` 函数：
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We use the `Chat` class to manage the conversation history. It has methods
    to add a new message to the history and display the entire conversation:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `Chat` 类来管理对话历史。它有方法可以将新消息添加到历史记录中，并显示整个对话：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In our use case, the LLM needs to interact with our PostgreSQL database and
    FastAPI service. We define these functions and include them in our completion
    request. Here’s how we define our `sql_query_email` and `send_email`functions:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的使用案例中，LLM 需要与我们的 PostgreSQL 数据库和 FastAPI 服务进行交互。我们定义这些函数并将其包含在我们的完成请求中。这是我们如何定义
    `sql_query_email` 和 `send_email` 函数的：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: When we make a completion request, the LLM responds with its intended actions.
    If the response includes a function call, our script executes that function. For
    example, if the LLM decides to call the `sql_query_email`function, our script
    retrieves the user’s email from the database and then adds the result to the conversation
    history. When the `send_email`function is called, our script sends an email using
    the FastAPI service.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们发出完成请求时，LLM 以其预期的操作作出响应。如果响应包括函数调用，我们的脚本会执行该函数。例如，如果 LLM 决定调用 `sql_query_email`
    函数，我们的脚本会从数据库中检索用户的电子邮件，然后将结果添加到对话历史记录中。当调用 `send_email` 函数时，我们的脚本会使用 FastAPI
    服务发送电子邮件。
- en: 'The main loop of our script checks for function calls in the LLM’s response
    and acts accordingly:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们脚本的主循环检查 LLM 响应中的函数调用并相应地采取行动：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'When we run the script, we get the following output:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行脚本时，我们得到以下输出：
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s break down what happened for us to get this output. Our prompt was *“Send
    an email to user10 saying that he needs to pay the monthly subscription fee.”.*
    Note that there is no information about the `user10`email in our message. The
    LLM identified the missing information and understood that our function `query_email`would
    allow it to query a database to get the email from that user. After getting the
    email, it got two things right once again: first, it should generate the body
    of the email, and second, it should call the `send_email`function to trigger the
    email using the FastAPI email service.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解析一下我们得到这个输出的过程。我们的提示是 *“给 user10 发送一封邮件，说明他需要支付每月订阅费。”* 请注意，我们的消息中没有关于 `user10`
    的电子邮件信息。LLM 识别到缺失的信息，并明白我们的函数 `query_email` 可以从数据库中获取该用户的电子邮件。在获取电子邮件后，它再次正确地完成了两件事：首先，它生成了电子邮件的正文，其次，它调用
    `send_email` 函数来触发通过 FastAPI 邮件服务发送电子邮件。
- en: Conclusion
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This article explored the function calling feature by implementing a case study
    where the LLM coordinates a pipeline involving a PostgreSQL database and a FastAPI
    email service. The LLM successfully navigated the task of retrieving a user’s
    email from the database and instructing the email service to send a personalized
    message, all in response to a single prompt.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本文通过实施一个案例研究探讨了函数调用功能，其中LLM协调了一个涉及PostgreSQL数据库和FastAPI电子邮件服务的管道。LLM成功地完成了从数据库中检索用户电子邮件并指示电子邮件服务发送个性化消息的任务，所有这些都是对单一提示的响应。
- en: The implications of function calling in AI models could be enormous, opening
    up new possibilities for automating and streamlining processes. Data pipelines
    could change from static and engineering heavy to dynamic entities, allowing non-technical
    users to quickly get their hands on the latest data using natural language.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI模型中，函数调用的影响可能是巨大的，开启了自动化和简化流程的新可能性。数据管道可能会从静态和工程密集型的状态转变为动态实体，使得非技术用户能够通过自然语言快速获取最新数据。
- en: About me
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: Serial entrepreneur and leader in the AI space. I develop AI products for businesses
    and invest in AI-focused startups.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 连续创业者和AI领域的领军人物。我为企业开发AI产品，并投资于专注于AI的初创公司。
- en: '[Founder @ ZAAI](http://zaai.ai) | [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
    | [X/Twitter](https://x.com/luisbrasroque)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[创始人 @ ZAAI](http://zaai.ai) | [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)
    | [X/Twitter](https://x.com/luisbrasroque)'
- en: 'Large Language Models Chronicles: Navigating the NLP Frontier'
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**大语言模型编年史：探索NLP前沿**'
- en: 'This article belongs to “Large Language Models Chronicles: Navigating the NLP
    Frontier”, a new weekly series of articles that will explore how to leverage the
    power of large models for various NLP tasks. By diving into these cutting-edge
    technologies, we aim to empower developers, researchers, and enthusiasts to harness
    the potential of NLP and unlock new possibilities.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本文属于“**大语言模型编年史：探索NLP前沿**”系列文章的第一篇，这是一个新的每周系列，将探讨如何利用大型模型的力量来处理各种NLP任务。通过深入研究这些前沿技术，我们旨在赋能开发者、研究人员和爱好者，利用NLP的潜力，解锁新的可能性。
- en: 'Articles published so far:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止发布的文章：
- en: '[Summarizing the latest Spotify releases with ChatGPT](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[使用ChatGPT总结最新的Spotify发布](https://medium.com/towards-data-science/summarizing-the-latest-spotify-releases-with-chatgpt-553245a6df88)'
- en: '[Master Semantic Search at Scale: Index Millions of Documents with Lightning-Fast
    Inference Times using FAISS and Sentence Transformers](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[掌握大规模语义搜索：使用FAISS和句子变换器以闪电般的推理速度索引百万级文档](https://medium.com/towards-data-science/master-semantic-search-at-scale-index-millions-of-documents-with-lightning-fast-inference-times-fa395e4efd88)'
- en: '[Unlock the Power of Audio Data: Advanced Transcription and Diarization with
    Whisper, WhisperX, and PyAnnotate](https://medium.com/towards-data-science/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281)'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[释放音频数据的力量：使用Whisper、WhisperX和PyAnnotate进行高级转录和分话](https://medium.com/towards-data-science/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281)'
- en: '[Whisper JAX vs PyTorch: Uncovering the Truth about ASR Performance on GPUs](https://medium.com/towards-data-science/whisper-jax-vs-pytorch-uncovering-the-truth-about-asr-performance-on-gpus-8794ba7a42f5)'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Whisper JAX与PyTorch：揭示ASR在GPU上的性能真相](https://medium.com/towards-data-science/whisper-jax-vs-pytorch-uncovering-the-truth-about-asr-performance-on-gpus-8794ba7a42f5)'
- en: '[Vosk for Efficient Enterprise-Grade Speech Recognition: An Evaluation and
    Implementation Guide](https://medium.com/towards-data-science/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c)'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Vosk高效企业级语音识别：评估与实施指南](https://medium.com/towards-data-science/vosk-for-efficient-enterprise-grade-speech-recognition-an-evaluation-and-implementation-guide-87a599217a6c)'
- en: '[Testing the Massively Multilingual Speech (MMS) Model that Supports 1162 Languages](https://medium.com/towards-data-science/testing-the-massively-multilingual-speech-mms-model-that-supports-1162-languages-5db957ee1602)'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[测试支持1162种语言的大规模多语言语音（MMS）模型](https://medium.com/towards-data-science/testing-the-massively-multilingual-speech-mms-model-that-supports-1162-languages-5db957ee1602)'
- en: '[Harnessing the Falcon 40B Model, the Most Powerful Open-Source LLM](https://medium.com/towards-data-science/harnessing-the-falcon-40b-model-the-most-powerful-open-source-llm-f70010bc8a10)'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[利用最强大的开源LLM——Falcon 40B模型](https://medium.com/towards-data-science/harnessing-the-falcon-40b-model-the-most-powerful-open-source-llm-f70010bc8a10)'
