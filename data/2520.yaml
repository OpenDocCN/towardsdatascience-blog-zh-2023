- en: Advanced Prompt Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级提示工程
- en: 原文：[https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01?source=collection_archive---------0-----------------------#2023-08-07](https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01?source=collection_archive---------0-----------------------#2023-08-07)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01?source=collection_archive---------0-----------------------#2023-08-07](https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01?source=collection_archive---------0-----------------------#2023-08-07)
- en: What to do when few-shot learning isn’t enough…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 当少样本学习不够用时该怎么办……
- en: '[](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)[![Cameron
    R. Wolfe, Ph.D.](../Images/52bb88d7cf1105501be2fae5ccbe7a03.png)](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)
    [Cameron R. Wolfe, Ph.D.](https://wolfecameron.medium.com/?source=post_page-----f07f9e55fe01--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----f07f9e55fe01---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)
    ·17 min read·Aug 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff07f9e55fe01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----f07f9e55fe01---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F28aa6026c553&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=post_page-28aa6026c553----f07f9e55fe01---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f07f9e55fe01--------------------------------)
    · 17分钟阅读 · 2023年8月7日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff07f9e55fe01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&user=Cameron+R.+Wolfe%2C+Ph.D.&userId=28aa6026c553&source=-----f07f9e55fe01---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff07f9e55fe01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&source=-----f07f9e55fe01---------------------bookmark_footer-----------)![](../Images/c81386dd2900922e3779e5a589170682.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff07f9e55fe01&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&source=-----f07f9e55fe01---------------------bookmark_footer-----------)![](../Images/c81386dd2900922e3779e5a589170682.png)'
- en: (Photo by [Mike Tinnion](https://unsplash.com/@m15ky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/3ym6i13Y9LU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText))
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: （照片由[Mike Tinnion](https://unsplash.com/@m15ky?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄，来源于[Unsplash](https://unsplash.com/photos/3ym6i13Y9LU?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)）
- en: The popularization of large language models (LLMs) has completely shifted how
    we solve problems as humans. In prior years, solving any task (e.g., reformatting
    a document or classifying a sentence) with a computer would require a program
    (i.e., a set of commands precisely written according to some programming language)
    to be created. With LLMs, solving such problems requires no more than a textual
    prompt. For example, we can prompt an LLM to reformat any document via a prompt
    similar to the one shown below.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的普及彻底改变了我们解决问题的方式。在过去的几年里，使用计算机解决任何任务（例如，重新格式化文档或分类句子）都需要创建一个程序（即，根据某种编程语言精确编写的一组命令）。而有了LLMs，解决这些问题只需一个文本提示。例如，我们可以通过类似下面的提示来要求LLM重新格式化任何文档。
- en: '![](../Images/f0e2c7c36f265458b3c1eaa3d0a17396.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f0e2c7c36f265458b3c1eaa3d0a17396.png)'
- en: Using prompting to reformat an XML document (created by author)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提示重新格式化一个XML文档（由作者创建）
- en: As demonstrated in the example above, the generic text-to-text format of LLMs
    makes it easy for us to solve a wide variety of problems. We first saw a glimpse
    of this potential with the proposal of [GPT-3](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)
    [18], showing that sufficiently-large language models can use [few-shot learning](https://cameronrwolfe.substack.com/i/117151147/few-shot-learning)
    to solve many tasks with surprising accuracy. However, as the research surrounding
    LLMs progressed, we began to move beyond these basic (but still very effective!)
    prompting techniques like zero/few-shot learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如上例所示，LLMs的通用文本到文本格式使我们能够轻松解决各种问题。我们最早在[GPT-3](https://cameronrwolfe.substack.com/p/language-model-scaling-laws-and-gpt)
    [18]的提案中窥见了这种潜力，显示出足够大的语言模型可以利用[少量学习](https://cameronrwolfe.substack.com/i/117151147/few-shot-learning)以令人惊讶的准确性解决许多任务。然而，随着对LLMs的研究进展，我们开始超越这些基本（但仍然非常有效！）的提示技术，如零样本/少量样本学习。
- en: '[Instruction-following LLMs](https://cameronrwolfe.substack.com/i/117151147/instruction-prompting)
    (e.g., [InstructGPT](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    and [ChatGPT](https://openai.com/blog/chatgpt)) led us to explore whether language
    models could…'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[指令跟随型语言模型](https://cameronrwolfe.substack.com/i/117151147/instruction-prompting)（例如，[InstructGPT](https://cameronrwolfe.substack.com/i/93578656/training-language-models-to-follow-instructions-with-human-feedback)
    和 [ChatGPT](https://openai.com/blog/chatgpt)）使我们探讨了语言模型是否能够……'
