- en: PCA vs Autoencoders for a Small Dataset in Dimensionality Reduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小数据集的降维：PCA与自编码器
- en: 原文：[https://towardsdatascience.com/pca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0?source=collection_archive---------7-----------------------#2023-02-16](https://towardsdatascience.com/pca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0?source=collection_archive---------7-----------------------#2023-02-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0?source=collection_archive---------7-----------------------#2023-02-16](https://towardsdatascience.com/pca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0?source=collection_archive---------7-----------------------#2023-02-16)
- en: 'Neural Networks and Deep Learning Course: Part 45'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络和深度学习课程：第45部分
- en: '[](https://rukshanpramoditha.medium.com/?source=post_page-----67b15318dea0--------------------------------)[![Rukshan
    Pramoditha](../Images/b80426aff64ff186cb915795644590b1.png)](https://rukshanpramoditha.medium.com/?source=post_page-----67b15318dea0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67b15318dea0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67b15318dea0--------------------------------)
    [Rukshan Pramoditha](https://rukshanpramoditha.medium.com/?source=post_page-----67b15318dea0--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://rukshanpramoditha.medium.com/?source=post_page-----67b15318dea0--------------------------------)[![Rukshan
    Pramoditha](../Images/b80426aff64ff186cb915795644590b1.png)](https://rukshanpramoditha.medium.com/?source=post_page-----67b15318dea0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----67b15318dea0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----67b15318dea0--------------------------------)
    [Rukshan Pramoditha](https://rukshanpramoditha.medium.com/?source=post_page-----67b15318dea0--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff90a3bb1d400&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=post_page-f90a3bb1d400----67b15318dea0---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----67b15318dea0--------------------------------)
    ·8 min read·Feb 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F67b15318dea0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----67b15318dea0---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff90a3bb1d400&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=post_page-f90a3bb1d400----67b15318dea0---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----67b15318dea0--------------------------------)
    · 8 分钟阅读 · 2023年2月16日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F67b15318dea0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0&user=Rukshan+Pramoditha&userId=f90a3bb1d400&source=-----67b15318dea0---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67b15318dea0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0&source=-----67b15318dea0---------------------bookmark_footer-----------)![](../Images/40244380e27388a744474a8be2aa482a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F67b15318dea0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpca-vs-autoencoders-for-a-small-dataset-in-dimensionality-reduction-67b15318dea0&source=-----67b15318dea0---------------------bookmark_footer-----------)![](../Images/40244380e27388a744474a8be2aa482a.png)'
- en: Photo by [Robert Katzki](https://unsplash.com/@ro_ka?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/jbtfM0XBeRc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Robert Katzki](https://unsplash.com/@ro_ka?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/photos/jbtfM0XBeRc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: '***Can general machine learning algorithms outperform neural networks with
    small datasets?***'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '***一般的机器学习算法能在小数据集上超越神经网络吗？***'
- en: In general, deep learning algorithms such as neural networks require a massive
    amount of data to achieve reasonable performance. So, neural networks like autoencoders
    can benefit from very large datasets that we use to train the models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，深度学习算法如神经网络需要大量的数据才能获得合理的性能。因此，像自编码器这样的神经网络可以从我们用来训练模型的非常大的数据集中获益。
- en: Sometimes, general machine learning algorithms can outperform neural network
    algorithms when they are trained with very small datasets.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，当通用机器学习算法在非常小的数据集上训练时，它们可能会优于神经网络算法。
- en: Autoencoders can also be used in dimensionality reduction applications, even
    though they are widely used in other popular applications such as image denoising,
    image generation, image colorization, image compression, image super-resolution,
    etc.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器也可以用于降维应用，尽管它们在其他流行应用中也被广泛使用，例如图像去噪、图像生成、图像着色、图像压缩、图像超分辨率等。
- en: Earlier, we compared the performance of autoencoders in dimensionality reduction
    against PCA by training the models on the *very large* MNIST dataset. There, the
    autoencoder model easily outperformed the PCA model [ref¹] because the MNIST data
    is large and non-linear.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 早些时候，我们通过在*非常大的* MNIST 数据集上训练模型，比较了自编码器在降维方面与 PCA 的性能。在那里，自编码器模型轻松超越了 PCA 模型
    [ref¹]，因为 MNIST 数据集大且非线性。
- en: 'ref¹: [*How Autoencoders Outperform PCA in Dimensionality Reduction*](/how-autoencoders-outperform-pca-in-dimensionality-reduction-1ae44c68b42f)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 'ref¹: [*自编码器如何在降维中超越 PCA*](/how-autoencoders-outperform-pca-in-dimensionality-reduction-1ae44c68b42f)'
- en: Autoencoders work well with large and non-linear…
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自编码器在处理大型和非线性数据时表现良好…
