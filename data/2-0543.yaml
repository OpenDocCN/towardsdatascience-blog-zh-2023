- en: Comprehensive Time Series Exploratory Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 综合时间序列探索性分析
- en: 原文：[https://towardsdatascience.com/comprehensive-time-series-exploratory-analysis-78bf40d16083](https://towardsdatascience.com/comprehensive-time-series-exploratory-analysis-78bf40d16083)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/comprehensive-time-series-exploratory-analysis-78bf40d16083](https://towardsdatascience.com/comprehensive-time-series-exploratory-analysis-78bf40d16083)
- en: A deep dive into air quality data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入分析空气质量数据
- en: '[](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)[![Erich
    Silva](../Images/448dee1644d3f3e092bbbcfbbf07592d.png)](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)[](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)
    [Erich Silva](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)[![Erich
    Silva](../Images/448dee1644d3f3e092bbbcfbbf07592d.png)](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)[](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)
    [Erich Silva](https://medium.com/@erich.hs?source=post_page-----78bf40d16083--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)
    ·18 min read·Nov 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----78bf40d16083--------------------------------)
    ·阅读时间18分钟·2023年11月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/a6c9e51ca7e3e5d265d6379258366dc9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6c9e51ca7e3e5d265d6379258366dc9.png)'
- en: Photo by [Jason Blackeye](https://unsplash.com/@jeisblack?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/collections/55366/my-first-collection/981603704225affe48a9007fc5094d84?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Jason Blackeye](https://unsplash.com/@jeisblack?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)拍摄的照片，刊登在[Unsplash](https://unsplash.com/collections/55366/my-first-collection/981603704225affe48a9007fc5094d84?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: Here you are with a dataset indexed by time stamps. Your data might be about
    storage demand and supply, and you are tasked with predicting the ideal replenishment
    intervals for a strategic product. Or maybe you need to translate historical sales
    information into key actionable insights for your team. Perhaps your data is financial,
    with information about historical interest rates and a selection of stock prices.
    Maybe you are tasked with modelling market volatility and need to quantify monetary
    risk over an investment horizon. From social sciences and energy distribution
    or from healthcare to environmental studies. The examples are numerous. But what
    do these scenarios have in common? One, you have a time series task at hand. And
    two, you will certainly benefit from starting with a **succinct yet comprehensive
    exploratory analysis**.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你面临一个按时间戳索引的数据集。你的数据可能涉及存储需求和供应，你的任务是预测一个战略产品的理想补货间隔。或者你需要将历史销售信息转化为团队的关键行动洞察。也许你的数据是财务数据，包括历史利率和一系列股票价格。也许你需要建模市场波动性，并量化投资期限内的货币风险。从社会科学和能源分配到医疗保健和环境研究，例子数不胜数。但这些场景有什么共同点？第一，你有一个时间序列任务。第二，你肯定会从开始时进行**简明而全面的探索性分析**中受益。
- en: Table of Contents
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: '[The Goal of this Article](#d55f)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[本文的目标](#d55f)'
- en: '[Dataset Description](#f0f7)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据集描述](#f0f7)'
- en: '[Libraries and Dependencies](#d791)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[库和依赖](#d791)'
- en: '[Getting Started](#85bf)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[开始使用](#85bf)'
- en: '[The Big Picture](#b967)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[全局视角](#b967)'
- en: '[A Detailed View](#fa99)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[详细视图](#fa99)'
- en: '[Missing Values](#9720)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[缺失值](#9720)'
- en: '[Intermittency](#ce22)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[间歇性](#ce22)'
- en: '[Seasonality](#3002)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[季节性](#3002)'
- en: '[Pearson Correlation](#773d)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[皮尔逊相关](#773d)'
- en: '[Stationarity](#0270)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[平稳性](#0270)'
- en: '[First-Order Differencing](#4564)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一阶差分](#4564)'
- en: '[Autocorrelation](#18ad)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自相关](#18ad)'
- en: '[References](#9856)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[参考文献](#9856)'
- en: The Goal of this Article
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本文的目标
- en: But what does it mean to perform an **exploratory time series analysis**? Different
    from other data science problems, gathering insights from time series data can
    be tricky and everything but straightforward. Your data might have important underlying
    trends and seasons or be suitable for nested forecasting within its intricate
    cyclical patterns. Differentiating abnormal outliers caused by a failure in your
    data generation process from actual anomalies that hold key information can be
    challenging. And dealing with missing values might not be as simple as you expect.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但进行**探索性时间序列分析**意味着什么呢？与其他数据科学问题不同，从时间序列数据中获取见解可能是棘手的，一切都不是简单的。你的数据可能具有重要的潜在趋势和季节性，或适合于其复杂的周期模式中的嵌套预测。区分由于数据生成过程中的失败造成的异常离群值与实际的异常情况（它们包含关键信息）可能是具有挑战性的。处理缺失值也可能不像你预期的那么简单。
- en: This article will outline a process that has worked for me when studying time
    series datasets. You will follow me along as I explore the measurements of fine
    particulate matter, also known as PM 2.5, one of the main contributors to air
    pollution and air quality indices. I will focus on laying out some best practices
    with specific attention to detail to generate sharp and highly informative visualizations
    and statistical summaries.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将概述一个在研究时间序列数据集时对我有效的过程。你将跟随我探索细颗粒物的测量值，即 PM 2.5，它是空气污染和空气质量指数的主要来源之一。我将专注于制定一些最佳实践，特别注意细节，以生成清晰且高度信息化的可视化和统计摘要。
- en: Dataset Description
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集描述
- en: The data studied here are from four monitoring stations in the city of Vancouver,
    British Columbia, Canada. They hold one-hour average measurements of fine particulate
    matter PM 2.5 (fine particles with diameters of 2.5 microns and smaller) in µg/m3
    (micrograms per cubic meter) with values from January 1st, 2016, to July 3rd,
    2022.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这里研究的数据来自加拿大不列颠哥伦比亚省温哥华市的四个监测站。它们包含从 2016 年 1 月 1 日到 2022 年 7 月 3 日的 PM 2.5（直径为
    2.5 微米及以下的细颗粒）的一小时平均测量值，单位为 µg/m3（每立方米微克）。
- en: PM 2.5 primarily comes from the burn of fossil fuels, and in cities, it normally
    originates from car traffic and construction sites. Another major source of the
    pollutant are forest and grass fires, and they are easily carried away by the
    wind [1].
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: PM 2.5 主要来自燃烧化石燃料，在城市中，通常源自汽车交通和建筑工地。另一个主要的污染源是森林和草地火灾，它们很容易被风吹走 [1]。
- en: The image below shows the approximate location of the stations we will explore.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了我们将要探索的站点的大致位置。
- en: '![](../Images/0b4d72407c13441c051091b24c3cbbab.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b4d72407c13441c051091b24c3cbbab.png)'
- en: '**Figure 1.** Vancouver map with air monitoring stations. Author customized
    map created in Google Maps.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1.** 温哥华地图及空气监测站。作者在 Google Maps 中定制的地图。'
- en: The dataset is from the [British Columbia Data Catalogue](https://catalogue.data.gov.bc.ca/),
    and as stated by the publisher, it has not been quality-assured [5]. For the version
    you will see here, I have preprocessed some minor problems, such as assigning
    negative measurements (only 6 out of 57k observations) as missing values and generating
    a master DataFrame with the stations of our choice.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集来自 [British Columbia Data Catalogue](https://catalogue.data.gov.bc.ca/)，根据发布者的说法，它尚未经过质量保证
    [5]。对于你将在这里看到的版本，我已经处理了一些小问题，例如将负值测量（仅 6 个观察值中的 57k）标记为缺失值，并生成了一个包含我们选择的站点的主 DataFrame。
- en: Libraries and Dependencies
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 库和依赖
- en: We will use Python 3.9 and the plotting libraries [Matplotlib](https://matplotlib.org/)
    and [Seaborn](https://seaborn.pydata.org/) for our visualizations. For statistical
    tests and data exploration, we will work with the [statsmodels](https://www.statsmodels.org/stable/index.html)
    Python module and the [SciPy](https://scipy.org/) library. All our data manipulation
    and auxiliary tasks will be handled with [Pandas](https://pandas.pydata.org/)
    and [Numpy](https://numpy.org/).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Python 3.9 以及绘图库 [Matplotlib](https://matplotlib.org/) 和 [Seaborn](https://seaborn.pydata.org/)
    来进行可视化。对于统计测试和数据探索，我们将使用 [statsmodels](https://www.statsmodels.org/stable/index.html)
    Python 模块和 [SciPy](https://scipy.org/) 库。所有的数据处理和辅助任务将使用 [Pandas](https://pandas.pydata.org/)
    和 [Numpy](https://numpy.org/) 处理。
- en: These packages are natively available in popular Python distributions and hosted
    notebooks, such as Anaconda and Miniconda, Google Collab or Kaggle Notebooks.
    So every code example here should be easily reproducible in your environment of
    choice.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些软件包在流行的 Python 发行版和托管的笔记本中原生提供，如 Anaconda 和 Miniconda、Google Colab 或 Kaggle
    Notebooks。因此，本文中的每个代码示例都应该在你选择的环境中轻松复现。
- en: Getting Started
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用
- en: Starting by importing our libraries, we will call `matplotlib.dates.mdates`
    , and the `datetime` module to help us work with our DateTime index. To generate
    consistent visualizations, I also like to start by defining our plot styles and
    the color palette. So let's begin with.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从导入我们的库开始，我们将调用`matplotlib.dates.mdates`和`datetime`模块来帮助我们处理DateTime索引。为了生成一致的可视化，我还喜欢先定义我们的图表样式和颜色调色板。那么让我们开始吧。
- en: '![](../Images/864c9f40735c096e63f46c16ca015f61.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/864c9f40735c096e63f46c16ca015f61.png)'
- en: '**Figure 2.** Seaborn “mako” color palette. Image by the author.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2.** Seaborn “mako” 颜色调色板。图片由作者提供。'
- en: After reading the .csv file, we will define the timestamp `DATE_PS` as a NumPy
    `datetime64` object and set it as our DataFrame index. This common step will enable
    some Pandas time series functionalities, such as the one used below to create
    datepart features in our dataset.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在读取.csv文件后，我们将定义时间戳`DATE_PS`为NumPy的`datetime64`对象，并将其设为我们的DataFrame索引。这一步将启用一些Pandas时间序列功能，例如下文中用于在数据集中创建日期部分特征的功能。
- en: '![](../Images/cc600cbc111b60724441fcdba4ac9979.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc600cbc111b60724441fcdba4ac9979.png)'
- en: '**Figure 3.** Master DataFrame slice with datepart features. Image by the author.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3.** 带有日期部分特征的主DataFrame切片。图片由作者提供。'
- en: The Big Picture
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全景视图
- en: Here is an ample view of where we will dive in — This is where we spend some
    time to get a first grasp of our data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们将深入探讨的广阔视图——这是我们花一些时间初步了解数据的地方。
- en: For this visualization, we will use Seaborn relational plots that will read
    from an aggregated long version of our DataFrame. For that, we will use Pandas
    `melt` and `resample` methods with a mean aggregation in 24 hours intervals. This
    will reduce our data granularity from hourly to daily average measurements, and
    it is done to reduce the time it takes to generate the plot.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个可视化，我们将使用Seaborn的关系图，它将从我们DataFrame的聚合长格式中读取。为此，我们将使用Pandas的`melt`和`resample`方法，并在24小时间隔内进行均值聚合。这将把数据粒度从每小时减少到每日平均测量值，从而减少生成图表所需的时间。
- en: '![](../Images/391f62107bd34f7ed8a3c8e2d0ef102d.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/391f62107bd34f7ed8a3c8e2d0ef102d.png)'
- en: '**Figure 4\.** PM 2.5 time series plot of monitoring stations. Image by the
    author.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**图4.** 监测站PM 2.5时间序列图。图片由作者提供。'
- en: 'With a clear picture of all four stations along the entire span of our time
    series, it is already possible to start taking some notes:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在整个时间序列跨度内清晰地了解所有四个车站的数据，我们已经可以开始做一些记录：
- en: There are some major anomalies, and they seem to be prevalent during summer
    and early autumn.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在一些主要的异常情况，它们似乎在夏季和初秋期间较为普遍。
- en: These anomalies appear to result from large-scale events, as they affect all
    four stations approximately during the same periods.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些异常似乎是由于大规模事件引起的，因为它们影响了所有四个车站，且大致发生在相同的时间段内。
- en: If you look carefully, **I have included a faded gray scatter plot of all stations
    within every chart**. With this subtle detail, it is possible to see that the
    anomaly present in 2017, for example, had a major effect in both North Vancouver
    stations (they reached higher PM 2.5 values), while the opposite is true for the
    2018 event. This technique also ensures that all four line charts are within the
    same Y-axis range.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果仔细观察，**我在每个图表中都包含了一张淡灰色的散点图，显示了所有车站的数据**。通过这个细微的细节，可以看到例如2017年的异常在北温哥华的两个车站产生了重大影响（它们的PM
    2.5值更高），而2018年的情况则相反。这种技术还确保所有四个折线图都在相同的Y轴范围内。
- en: 'Some good practices that you can take from this first plot:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从第一个图表中可以汲取一些好的实践：
- en: Matplotlib allows for highly customizable axis ticker locators and formatters.
    In this example, I have used a `MonthLocator` from the `mdates` module to create
    **minor month locators** in the X-axis, which help with overall readability.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matplotlib允许高度自定义的轴刻度定位器和格式化器。在这个例子中，我使用了`mdates`模块中的`MonthLocator`来创建X轴上的**小月定位器**，这有助于整体可读性。
- en: The exact expected dates range from our plot is passed to the plot title or
    subtitle. “Expected” because our visualization might be truncated due to missing
    values on either end of the plotted period, and this practice can help identify
    those problems. It is also a good documentation practice to report your findings.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的图表标题或副标题中传递了从图表中预期的准确日期范围。之所以用“预期”是因为我们的可视化可能由于绘图周期两端的缺失值而被截断，这种做法可以帮助识别这些问题。这也是一个好的文档实践，记录你的发现。
- en: Great start, but let’s narrow down our view slightly. In the next section, we
    will look at shorter periods of time, but now with our original hourly granularity.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 很好的开始，但让我们稍微缩小视图。在下一节中，我们将查看较短的时间段，但现在保持原有的每小时粒度。
- en: A Detailed View
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 详细视图
- en: From now on, we will start defining some functions we can quickly call to generate
    tailored visualizations. You can think of it as a means of setting up an *analytical
    toolset* that will be extremely helpful moving forward.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将开始定义一些可以快速调用以生成定制可视化的函数。你可以将其视为建立一个*分析工具集*，这将在未来非常有帮助。
- en: This first function will help us look at individual time series within a specific
    period in time. We will start by looking at the year 2017 for the North Vancouver
    Mahon Park Station.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个函数将帮助我们查看特定时间段内的单独时间序列。我们将从查看2017年的北温哥华马洪公园站开始。
- en: '![](../Images/812ff71eedf73c5eaa96dcefe8b48a02.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/812ff71eedf73c5eaa96dcefe8b48a02.png)'
- en: '**Figure 5.** North Vancouver Mahon Park PM 2.5 plot for 2017\. Image by the
    author.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 5.** 2017年北温哥华马洪公园PM 2.5图。图像由作者提供。'
- en: We can see here that there are localized smaller spikes in addition to the major
    anomalies. There were also periods of higher volatility (where variance increases
    during a short time span) at the beginning of the year and in December 2017.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，除了主要异常外，还有局部较小的波动。在2017年年初和12月，也有较高波动性（在短时间内方差增加）的时期。
- en: Let’s dive in a bit further and look outside the anomaly range so we can analyze
    our values within a narrower span in the Y-axis.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步深入，查看异常范围之外的情况，以便在Y轴上分析我们在更窄范围内的值。
- en: '![](../Images/2e78a2e70348757efe3101fc5e2e91ce.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2e78a2e70348757efe3101fc5e2e91ce.png)'
- en: '**Figure 6.** North Vancouver Mahon Park PM 2.5 plot for 15 Apr to 1 Jul 2017\.
    Image by the author.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 6.** 2017年4月15日至7月1日的北温哥华马洪公园PM 2.5图。图像由作者提供。'
- en: We can see some missing values here. The `fill=True` parameter of our function
    helps identify that and is a good way to give visual emphasis to missingness in
    our data. Those small interruptions that are initially hard to notice are now
    clearly visible.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这里有一些缺失值。我们函数的`fill=True`参数有助于识别这些缺失值，并且是给数据中缺失情况提供视觉重点的好方法。这些最初难以察觉的小中断现在变得非常明显。
- en: Another detail you might have noticed is the X-axis's custom date format. For
    the plot above, I have enhanced our `plot_sequence()` function with custom major
    and minor locators and formatters. This new functionality now adapts our plot
    to the visualization’s time span and formats the X-axis accordingly. Below is
    the code snippet that was included in the function.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个你可能注意到的细节是X轴的自定义日期格式。对于上面的图，我增强了我们的`plot_sequence()`函数，添加了自定义的主要和次要定位器及格式化程序。这个新功能现在使我们的图表适应可视化的时间跨度，并相应地格式化X轴。下面是包含在函数中的代码片段。
- en: Now we know that our dataset has interruptions, so let's take a better look
    at that.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道我们的数据集有中断，所以让我们更好地查看一下。
- en: Missing Values
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缺失值
- en: 'For tabular data problems, in this section, we would probably be focused on
    defining MAR (Missing At Random) from MNAR (Missing Not At Random). Instead, knowing
    the nature of our data (sensorial temporal measurements), we know that interruptions
    in the data stream are probably not intended. Hence, in these cases, it is more
    important to distinguish isolated from continuously missing values and missing
    values from completely missing samples. The possibilities here are vast, and if
    you want to learn more, I have dedicated an article to that:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 对于表格数据问题，在本节中，我们可能会专注于将MAR（随机缺失）与MNAR（非随机缺失）区分开来。相反，了解我们数据的性质（传感器时间测量），我们知道数据流中的中断可能不是有意的。因此，在这些情况下，区分孤立的缺失值与连续缺失值，以及完全缺失样本中的缺失值是更重要的。这里的可能性很广泛，如果你想了解更多，我专门撰写了一篇文章：
- en: '[](/handling-gaps-in-time-series-dc47ae883990?source=post_page-----78bf40d16083--------------------------------)
    [## Handling Gaps in Time Series'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/handling-gaps-in-time-series-dc47ae883990?source=post_page-----78bf40d16083--------------------------------)
    [## 时间序列中的缺口处理'
- en: Missingness analysis and evaluation methods for short and long sequences imputation
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 短序列和长序列插补的缺失分析和评估方法
- en: towardsdatascience.com](/handling-gaps-in-time-series-dc47ae883990?source=post_page-----78bf40d16083--------------------------------)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/handling-gaps-in-time-series-dc47ae883990?source=post_page-----78bf40d16083--------------------------------)
- en: For now, let’s start by looking at a **missing values heatmap**. Again we will
    define a function for that.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们先从查看**缺失值热图**开始。我们将为此定义一个函数。
- en: '![](../Images/a72564713c437fe887ef281cb73ccf2a.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a72564713c437fe887ef281cb73ccf2a.png)'
- en: '**Figure 7.** Missing values heatmap. Image by the author.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 7.** 缺失值热图。图片由作者提供。'
- en: 'Heatmaps are great as they allow us to quantify missingness and **localize
    them in the time axis**. From here, we can denote:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 热图很有用，因为它们允许我们量化缺失情况并**在时间轴上本地化它们**。从这里，我们可以标记：
- en: We don’t have completely missing samples (where missing values occur simultaneously
    for a time period). That’s expected as the data streaming from the monitoring
    stations happens independently.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们没有完全缺失的样本（缺失值在一个时间段内同时出现）。这是可以预期的，因为来自监测站的数据流是独立的。
- en: There are long sequences of missing values early on in our timeline, and data
    availability seems to improve as time goes by.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在时间轴的早期有很长的缺失值序列，随着时间的推移，数据的可用性似乎有所改善。
- en: 'Some statistical analysis in the latter sections will be problematic with missing
    values. Therefore we will use simple techniques to treat them as we see fit, such
    as:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续部分的一些统计分析中，缺失值会带来问题。因此，我们将使用简单的技术来处理这些缺失值，比如：
- en: Pandas `ffill()` and `bfill()` methods. They are used to carry forward or backwards,
    respectively, the nearest available value.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pandas `ffill()` 和 `bfill()` 方法。它们分别用于向前或向后填充最近的可用值。
- en: Linear or spline interpolation with Pandas `interpolate()` method. It uses neighbouring
    observations to draw a curve to fill in a missing interval.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pandas `interpolate()` 方法进行线性或样条插值。它利用相邻观察值绘制曲线来填充缺失的区间。
- en: Intermittency
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 间歇性
- en: From the nature of our data, we should not expect negative values. As mentioned
    in the beginning, I treated them as missing when preprocessing the data. Let’s
    call our summary statistics to confirm that.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们数据的特性，我们不应期望出现负值。如开头所述，我在数据预处理时将其视为缺失值。让我们调用汇总统计来确认这一点。
- en: '![](../Images/51e391457d564a5562c43407669238b3.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/51e391457d564a5562c43407669238b3.png)'
- en: '**Figure 8.** Summary statistics. Image by the author.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 8.** 汇总统计。图片由作者提供。'
- en: We see that our minimum measurements are zeros for each station, which leads
    us to the next question. **Is our time series intermittent**?
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到每个站点的最小测量值为零，这引出了下一个问题。**我们的时间序列是否间歇性**？
- en: Intermittency is characterized when your data has a large number of values that
    are exactly zero. This behaviour poses specific challenges and must be taken into
    account during model selection. So how often do we see zero values in our data?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据中有大量值恰好为零时，这种现象被称为间歇性。这种行为带来了特定的挑战，必须在模型选择过程中加以考虑。那么，我们的数据中零值出现的频率有多高呢？
- en: '![](../Images/832ea9b9837e6f59807365e88645494f.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/832ea9b9837e6f59807365e88645494f.png)'
- en: '**Figure 9.** Zero values count. Image by the author.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 9.** 零值计数。图片由作者提供。'
- en: We can see that the amount of zeros is negligible, so we don’t have intermittent
    series. This is an easy but crucial check, especially if your goal is forecasting.
    It might be hard for some models to predict an absolute zero, and that can be
    a problem if you want to forecast demand, for example. You don’t want to plan
    out the delivery of, let’s say, three products to your client if, in fact, he
    is expecting none.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到零值的数量可以忽略不计，因此我们没有间歇性序列。这是一个简单但至关重要的检查，特别是如果你的目标是预测的话。对于某些模型来说，预测绝对零可能比较困难，例如，如果你想预测需求，这可能会成为一个问题。你不想计划向你的客户交付三件产品，如果实际上他什么都不期望的话。
- en: Seasonality
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 季节性
- en: Understanding the cycles in your time series is fundamental to planning the
    modeling phase. You might be losing key information of smaller cycles if you decide
    to aggregate your data too much, or it can help you determine the feasibility
    of forecasting on a smaller granularity.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 了解时间序列中的周期对规划建模阶段至关重要。如果你决定过度聚合数据，你可能会丢失较小周期的关键信息，或者这可以帮助你确定在更小粒度下进行预测的可行性。
- en: We will use some box plots to start looking into that. But first, we will temporarily
    remove the top 5% percentile so we can look at the data on a better scale.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一些箱线图来开始查看这些数据。但首先，我们会暂时移除前5%的百分位数，以便以更好的尺度查看数据。
- en: In this next function, we will use a series of boxplots to investigate the cycles
    within our data. We will also map our color palette to the median values so it
    can serve as another neat visual clue.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个函数中，我们将使用一系列箱线图来调查数据中的周期。我们还将把我们的颜色调色板映射到中位数值，以便作为另一个精美的视觉提示。
- en: '![](../Images/feb650bae5cc5093760808797184beec.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/feb650bae5cc5093760808797184beec.png)'
- en: '**Figure 10.** PM 2.5 hourly values. Image by the author.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 10.** PM 2.5 每小时值。图片由作者提供。'
- en: 'This first plot returns hourly measurements. Here we can see:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个初步图表返回每小时的测量值。这里我们可以看到：
- en: Consistently higher values for PM 2.5 from 9 AM to 2 PM.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从早上9点到下午2点，PM 2.5值 consistently higher。
- en: Stations outside North Vancouver also show a peak from 8 PM to 10 PM.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 北温哥华以外的站点也在晚上8点到10点出现峰值。
- en: Early mornings hold the lowest values for PM 2.5 from 2 AM to 5 AM.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 早晨2点到5点的PM 2.5值最低。
- en: Now looking at weekly seasonality and the difference in values across the week.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在查看周季节性以及一周内的值差异。
- en: '![](../Images/abb65cc19357834cc48f4025374b6a6e.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/abb65cc19357834cc48f4025374b6a6e.png)'
- en: '**Figure 11.** PM 2.5 daily values. Image by the author.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**图11**。PM 2.5每日值。图片由作者提供。'
- en: 'From here, we see:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里我们可以看到：
- en: Lower PM 2.5 values during weekends.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周末的PM 2.5值较低。
- en: A slightly higher trend for pollution levels on Tuesdays.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期二污染水平有略微上升的趋势。
- en: And finally, looking at the month-to-month trend.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，查看月度趋势。
- en: '![](../Images/05164ab242973a9c07c5f9029b02fd44.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05164ab242973a9c07c5f9029b02fd44.png)'
- en: '**Figure 12.** PM 2.5 monthly values. Image by the author.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**图12**。PM 2.5月度值。图片由作者提供。'
- en: 'Where we can observe:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到：
- en: Consistently higher values for PM 2.5 in August for all years.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有年份中8月的PM 2.5值 consistently higher。
- en: The southern stations have lower PM 2.5 values in June and July, while the North
    Vancouver ones show lower measurements in January.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 南部站点在6月和7月的PM 2.5值较低，而北温哥华的站点在1月显示出较低的测量值。
- en: 'Finally, more good practices from these plots:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从这些图表中得出的更多良好实践：
- en: Do not make naive use of your color palette, as they might mislead you to equivocate
    interpretations. Had we simply passed `pallette=”mako”` to our boxplots, it would
    have been mapped to our X-axis and not to our variable of interest.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要简单使用你的颜色调色板，因为它们可能会误导你得出相同的解释。如果我们只是将`pallette=”mako”`传递给我们的箱线图，它会映射到X轴，而不是我们感兴趣的变量。
- en: Grid plots are powerful containers of information for low-dimensional data,
    and they can be quickly set up with Seaborn `relplot()` or Matplotlib `subplots()`.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网格图是低维数据的强大信息容器，可以通过Seaborn的`relplot()`或Matplotlib的`subplots()`快速设置。
- en: You can make use of the Seaborn `boxplot()` `order` parameter to reorder your
    X-axis accordingly. I used it to reorganize the day-of-week X labels in a meaningful
    order.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以利用Seaborn的`boxplot()` `order`参数来重新排序你的X轴。我用它重新排列了周几的X标签，使之有意义。
- en: A more elaborate view of seasonalities can be attained from a trend-season decomposition
    from our time series. This, however, will be left for a future article where we
    can dive deeper into time series similarity and model selection. If that is a
    topic you are interested in, **make sure to follow me here on Medium to receive
    my future publications**.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细的季节性视图可以通过我们时间序列的趋势-季节分解获得。然而，这将留到未来的文章中，我们可以更深入地探讨时间序列相似性和模型选择。如果你对此感兴趣，**确保关注我在Medium上的未来出版物**。
- en: For now, let’s try a quick look at one of our well-known statistical coefficients
    to investigate the **linear relationship** between our four stations.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们快速查看我们熟知的统计系数，以调查四个站点之间的**线性关系**。
- en: Pearson Correlation
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pearson相关
- en: R programmers might be familiar with the following plot. A **correlogram** is
    a concise and highly informative visualization that is implemented at multiple
    R libraries, such as the `ggpairs()` in the `GGally` package. The upper diagonal
    of a correlogram shows us bivariate correlations, or Pearson correlation coefficients
    between numeric variables in our data. In the lower diagonal, we see scatterplots
    with regression curves fitted to our data. Finally, in the main diagonal, we have
    histograms and a density curve of each variable.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: R程序员可能对以下图表很熟悉。一个**相关图**是一种简洁且信息丰富的可视化，已在多个R库中实现，例如`GGally`包中的`ggpairs()`。相关图的上对角线显示了双变量相关性，即我们数据中数值变量之间的Pearson相关系数。在下对角线中，我们可以看到带有回归曲线的散点图。最后，在主对角线上，我们展示了每个变量的直方图和密度曲线。
- en: The following code is an adapted implementation using the Seaborn `PairGrid()`
    plot and yet another function for our analytical toolset.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是使用Seaborn `PairGrid()`图表的改编实现，并且是我们分析工具集中的另一个函数。
- en: '![](../Images/eb6d69d7e6c13f9f109b8467b5f5d425.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eb6d69d7e6c13f9f109b8467b5f5d425.png)'
- en: '**Figure 13.** PM 2.5 Correlogram on all four stations. Image by the author.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**图13**。所有四个站点的PM 2.5相关图。图片由作者提供。'
- en: As expected, our stations are highly correlated, especially the ones closer
    to each other, such as both in North Vancouver.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们的站点高度相关，尤其是那些彼此更近的站点，例如北温哥华的两个站点。
- en: It is important to note that to alleviate the computational time, our data was
    aggregated in 6-hours periods. If you experiment with this plot with bigger aggregation
    periods, you will see an increase in the correlation coefficients, as mean aggregations
    tend to smoothen out the outliers present in the data.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，为了减轻计算时间，我们的数据被聚合成6小时的时间段。如果你在这个图上尝试更大的聚合时间段，你会看到相关系数的增加，因为均值聚合往往会平滑数据中的异常值。
- en: If you were already introduced to time series analysis, you might now be thinking
    about other kinds of correlation that are worth checking. But first, we need to
    test our time series for **stationarity**.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经了解了时间序列分析，你现在可能会考虑其他值得检查的相关性。但首先，我们需要测试我们的时间序列是否**平稳**。
- en: Stationarity
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平稳性
- en: A stationary time series is one whose statistical properties do not change over
    time. In other words, it has a constant mean, variance, and autocorrelation independent
    of time [4].
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 平稳时间序列是指其统计特性随时间不变。换句话说，它具有一个恒定的均值、方差和自相关性，与时间无关[4]。
- en: '**Several forecasting models rely on time series stationarity**, hence the
    importance of testing for it in this exploratory phase. Our next function will
    make use of statsmodels implementation of two commonly used tests for stationarity,
    the *Augmented Dickey-Fuller* (“ADF”) test and the *Kwiatkowski-Phillips-Schmidt-Shin*
    (“KPSS”) test.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**多个预测模型依赖于时间序列平稳性**，因此在这一探索阶段测试其平稳性至关重要。我们的下一个函数将利用statsmodels实现的两个常用平稳性测试，即*Augmented
    Dickey-Fuller*（"ADF"）测试和*Kwiatkowski-Phillips-Schmidt-Shin*（"KPSS"）测试。'
- en: I will leave both tests’ hypotheses below. Note that they have opposing null
    hypotheses, so we will create a “Decision” column for an easy interpretation of
    their results. You can read more about both tests in the [statsmodels documentation](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我将把两个测试的假设列在下面。请注意，它们有相反的原假设，因此我们将创建一个“决策”列，以便于解释它们的结果。你可以在[statsmodels文档](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)中了解更多关于这两个测试的信息。
- en: '**Augmented Dickey-Fuller (ADF)** test hypothesis:'
  id: totrans-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Augmented Dickey-Fuller (ADF)** 测试假设：'
- en: ''
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **H0**: A unit root is present in the time series sample (**Non-stationary**)'
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '• **H0**: 时间序列样本中存在单位根 (**非平稳**)'
- en: ''
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **Ha**: There is no root unit present in the time series sample (**Stationary**)'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '• **Ha**: 时间序列样本中不存在单位根 (**平稳**)'
- en: ''
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Kwiatkowski-Phillips-Schmidt-Shin (KPSS)** test hypothesis:'
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Kwiatkowski-Phillips-Schmidt-Shin (KPSS)** 测试假设：'
- en: ''
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **H0**: The data is stationary around a constant (**Stationary**)'
  id: totrans-140
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '• **H0**: 数据围绕常数是平稳的 (**平稳**)'
- en: ''
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '• **Ha**: A unit root is present in the time series sample (**Non-stationary**)'
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '• **Ha**: 时间序列样本中存在单位根 (**非平稳**)'
- en: Now an opportune question to ask is on which scale we should check for stationarity.
    The answer will highly depend on how you will model your data, and one of the
    goals of a comprehensive exploratory analysis is exactly to help you with that
    decision.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一个恰当的问题是我们应该在什么尺度上检查平稳性。答案将高度依赖于你如何建模数据，而全面的探索性分析的一个目标正是帮助你做出这个决定。
- en: For illustration purposes, in the following example, we will take a look at
    the months of January 2016 and January 2022 for the Vancouver International Airport
    Station and see if there was a change in behavior from 2016 to 2022 in the data.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明目的，在接下来的例子中，我们将查看2016年1月和2022年1月的温哥华国际机场站数据，看看数据在2016年至2022年间是否有行为上的变化。
- en: You might remember from our Missing Values section that we can use Pandas `ffill()`,
    `bfill()`, and `interpolate()` methods to quickly impute interruptions in the
    series. You can see that I have defined a dedicated argument `fillna` to our function
    to select from either of these methods to quickly work around missing values,
    as both tests only accept complete samples.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得我们在“缺失值”部分提到过，我们可以使用Pandas的`ffill()`、`bfill()`和`interpolate()`方法来快速填补序列中的中断。你可以看到，我在我们的函数中定义了一个专用的`fillna`参数，以便选择这几种方法中的任意一种，快速处理缺失值，因为这两个测试只接受完整样本。
- en: Now coming back to our results.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在回到我们的结果。
- en: '![](../Images/bf5b4a7ec60ce8f9a3fc71af93ca4c23.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf5b4a7ec60ce8f9a3fc71af93ca4c23.png)'
- en: '**Figure 14.** ADF and KPSS stationarity test results for Jan 2016\. Image
    by the author.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 14.** 2016年1月ADF和KPSS平稳性测试结果。图片由作者提供。'
- en: '![](../Images/437dc51467485b08b088d10547764b9f.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/437dc51467485b08b088d10547764b9f.png)'
- en: '**Figure 15.** ADF and KPSS stationarity test results for Jan 2022\. Image
    by the author.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 15.** 2022年1月ADF和KPSS平稳性测试结果。图片由作者提供。'
- en: 'We can see that for 2016 both tests indicated Non-Stationarity, but for 2022
    the results diverged. The [statsmodels documentation](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)
    clearly lists the interpretations for the results when the ADF and KPSS tests
    are performed together [6]:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，2016 年的两个测试都指示非平稳性，但 2022 年的结果则有所不同。[statsmodels 文档](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)
    清楚地列出了当 ADF 和 KPSS 测试一起进行时的结果解释[6]：
- en: '• **Case 1**: **Both tests conclude that the series is not stationary** — The
    series is not stationary'
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: • **案例 1**：**两个测试均得出系列不是平稳的结论** — 该系列不是平稳的
- en: ''
  id: totrans-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**• Case 2**: **Both tests conclude that the series is stationary** — The series
    is stationary'
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**• 案例 2**：**两个测试均得出系列是平稳的结论** — 该系列是平稳的'
- en: ''
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**• Case 3**: **KPSS indicates stationarity** and **ADF indicates non-stationarity**
    — The series is trend stationary. **Trend needs to be removed** to make series
    strict stationary. The detrended series is checked for stationarity.'
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**• 案例 3**：**KPSS 指示平稳性** 和 **ADF 指示非平稳性** — 该系列是趋势平稳的。**需要去除趋势** 以使系列严格平稳。去趋势后的系列平稳性进行了检查。'
- en: ''
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**• Case 4**: **KPSS indicates non-stationarity** and **ADF indicates stationarity**
    — The series is difference stationary. **Differencing is to be used** to make
    series stationary. The differenced series is checked for stationarity.'
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**• 案例 4**：**KPSS 指示非平稳性** 和 **ADF 指示平稳性** — 该系列是差分平稳的。**需要使用差分** 使系列平稳。差分系列的平稳性进行了检查。'
- en: If you repeat this operation for all four stations across multiple months, you
    will see that *Case 4* is predominant in the data. This leads us to our next section
    about **first-order differencing to make our data stationary**.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对所有四个站点进行多个月份的重复操作，你会发现 *案例 4* 在数据中占主导地位。这将引导我们进入下一个部分，即 **使用一阶差分使数据平稳**。
- en: First-Order Differencing
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一阶差分
- en: As one of the most common transformation techniques, applying first- or second-order
    differencing to a time series is widely used to make the data suitable for statistical
    models that can only be used on stationary time series. Here we will look at the
    technique applied to one of the previous examples in the month of January 2016\.
    But first, let’s take a look at the original data before the transformation with
    our `plot_sequence()` function.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最常见的转换技术之一，对时间序列应用一阶或二阶差分被广泛使用，以使数据适合只能用于平稳时间序列的统计模型。在这里，我们将查看该技术在 2016 年
    1 月的一个示例中的应用。但首先，让我们用我们的 `plot_sequence()` 函数查看转换前的原始数据。
- en: '![](../Images/f6e5630d6aca9426311c27297bee9d2d.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6e5630d6aca9426311c27297bee9d2d.png)'
- en: '**Figure 16.** Vancouver International Airport PM 2.5 plot for Jan 2016\. Image
    by the author.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 16.** 温哥华国际机场 2016 年 1 月的 PM 2.5 图。图片由作者提供。'
- en: We can see that the variance in the period changes significantly from the beginning
    to the end of the month. The mean PM 2.5 also seems to go from a higher to a lower,
    more stable value. These are some of the characteristics that confirm the non-stationarity
    of the series.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，期间方差从月初到月底显著变化。均值 PM 2.5 也似乎从较高值变为较低且更稳定的值。这些是确认系列非平稳性的特征之一。
- en: Again, Pandas has a quite convenient method to differentiate our data. We will
    call `.diff()` to our DataFrame and instantiate it as a first-order differentiated
    version of our data. So let’s plot the same period again.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，Pandas 提供了一个非常方便的方法来对数据进行差分。我们将调用 `.diff()` 方法来创建数据的第一阶差分版本。然后再次绘制相同的时间段。
- en: '![](../Images/8e7d8e28adffd3a0893264a4ff99629d.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e7d8e28adffd3a0893264a4ff99629d.png)'
- en: '**Figure 17.** Vancouver International Airport differentiated PM 2.5 plot for
    Jan 2016\. Image by the author.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 17.** 温哥华国际机场 2016 年 1 月的 PM 2.5 差分图。图片由作者提供。'
- en: Besides the still oscillating variance, the data is now clearly more stable
    around a mean value. We can once again call our `stationarity_test()` function
    to check for stationarity on the differentiated data.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 除了仍然存在的波动方差外，数据现在在均值附近明显更加稳定。我们可以再次调用我们的 `stationarity_test()` 函数来检查差分数据的平稳性。
- en: '![](../Images/b09ca4706b8991fd1210efa77464357e.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b09ca4706b8991fd1210efa77464357e.png)'
- en: '**Figure 18.** ADF and KPSS stationarity test results for differentiated data.
    Image by the author.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 18.** 差分数据的 ADF 和 KPSS 平稳性测试结果。图片由作者提供。'
- en: 'There we have it. We can put another check on our comprehensive exploratory
    time series analysis, as we have now confirmed that:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是结果。我们可以对我们全面的探索性时间序列分析进行另一项检查，因为我们现在已确认：
- en: We are dealing with non-stationary time series.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们处理的是非平稳时间序列。
- en: First-order differencing is an appropriate transformation technique to make
    it stationary.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一阶差分是使时间序列平稳的合适变换技术。
- en: And that finally leads us to our last section.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这最终将引导我们进入最后一节。
- en: Autocorrelation
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自相关
- en: 'Once our data is stationary, we can investigate other key time series attributes:
    **partial autocorrelation** and **autocorrelation**. In formal terms:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的数据平稳了，我们可以研究其他关键的时间序列属性：**部分自相关**和**自相关**。用正式术语来说：
- en: The **autocorrelation function (ACF)** measures the linear relationship between
    lagged values of a time series. In other words, it measures the correlation of
    the time series with itself. *[2]*
  id: totrans-177
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**自相关函数（ACF）** 测量时间序列滞后值之间的线性关系。换句话说，它测量时间序列与自身的相关性。*[2]*'
- en: ''
  id: totrans-178
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The **partial autocorrelation function (PACF)** measures the correlation between
    lagged values in a time series when we remove the influence of correlated lagged
    values in between. Those are known as confounding variables. *[3]*
  id: totrans-179
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**部分自相关函数（PACF）** 测量在移除中间相关滞后值的影响后，时间序列中滞后值之间的相关性。这些被称为混杂变量。*[3]*'
- en: Both metrics can be visualized with statistical plots known as correlograms.
    But first, it is important to develop a better understanding of them.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个指标可以通过称为相关图的统计图进行可视化。但首先，重要的是要对它们有更好的理解。
- en: 'Since this article is focused on exploratory analysis and these concepts are
    fundamental to statistical forecasting models, I will keep the explanation brief,
    but bear in mind that these are highly important ideas to build a solid intuition
    upon when working with time series. For a comprehensive read, I recommend the
    great kernel “[Time Series: Interpreting ACF and PACF](https://www.kaggle.com/code/iamleonie/time-series-interpreting-acf-and-pacf)”
    by the Kaggle Notebooks Grandmaster [Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----78bf40d16083--------------------------------).'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本文主要集中在探索性分析上，并且这些概念是统计预测模型的基础，因此我会简要说明，但请记住，这些都是建立稳固直觉的重要理念，尤其是在处理时间序列时。如果需要全面阅读，我推荐
    Kaggle Notebooks 大师[Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----78bf40d16083--------------------------------)的精彩核实文章“[时间序列：解读
    ACF 和 PACF](https://www.kaggle.com/code/iamleonie/time-series-interpreting-acf-and-pacf)”。
- en: As noted above, autocorrelation measures how the time series correlates with
    itself on previous *q* lags. You can think of it as a measurement of the linear
    relationship of a subset of your data with a copy of itself shifted back by *q*
    periods. **Autocorrelation, or ACF, is an important metric to determine the order
    *q* of Moving Average (MA) models**.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，自相关测量时间序列如何与其之前的 *q* 滞后值相关。你可以将其视为数据子集与其自身向后移动 *q* 周期的拷贝之间的线性关系的度量。**自相关，或
    ACF，是确定移动平均（MA）模型阶数 *q* 的重要指标**。
- en: On the other hand, partial autocorrelation is the correlation of the time series
    with its *p* lagged version, but now solely regarding its **direct effects**.
    For example, if I want to check the partial autocorrelation of the *t-3* to *t-1*
    time period with my current *t0* value, I won’t care about how *t-3* influences
    *t-2* and *t-1* or how *t-2* influences *t-1*. I’ll be exclusively focused on
    the direct effects of *t-3*, *t-2*, and *t-1* on my current time stamp, *t0*.
    **Partial autocorrelation, or PACF, is an important metric to determine the order
    *p* of Autoregressive (AR) models.**
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，部分自相关是时间序列与其 *p* 滞后版本的相关性，但现在仅涉及其**直接影响**。例如，如果我想检查 *t-3* 到 *t-1* 时间段的部分自相关与当前
    *t0* 值的关系，我不会关注 *t-3* 如何影响 *t-2* 和 *t-1*，或者 *t-2* 如何影响 *t-1*。我将专注于 *t-3*、*t-2*
    和 *t-1* 对当前时间戳 *t0* 的直接影响。**部分自相关，或 PACF，是确定自回归（AR）模型阶数 *p* 的重要指标。**
- en: With these concepts cleared out, we can now come back to our data. Since the
    two metrics are often analyzed together, our last function will combine the PACF
    and ACF plots in a grid plot that will return correlograms for multiple variables.
    It will make use of statsmodels `plot_pacf()` and `plot_acf()` functions, and
    map them to a Matplotlib `subplots()` grid.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 理解了这些概念后，我们现在可以回到我们的数据上。由于这两个指标通常一起分析，我们的最后一个函数将会将 PACF 和 ACF 图结合到一个网格图中，这将返回多个变量的相关图。它将利用
    statsmodels 的`plot_pacf()`和`plot_acf()`函数，并将它们映射到 Matplotlib 的`subplots()`网格中。
- en: Notice how both statsmodels functions use the same arguments, except for the
    `method` parameter that is exclusive to the `plot_pacf()` plot.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，两个 statsmodels 函数使用了相同的参数，唯一的例外是 `plot_pacf()` 图的 `method` 参数。
- en: Now you can experiment with different aggregations of your data, but remember
    that when resampling the time series, each lag will then represent a different
    jump back in time. For illustrative purposes, let's analyze the PACF and ACF for
    all four stations in the month of January 2016, with a 6-hours aggregated dataset.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以尝试不同的数据聚合，但请记住，当重新采样时间序列时，每个滞后将代表不同的时间回溯。为了说明这一点，我们来分析 2016 年 1 月所有四个站点的
    PACF 和 ACF，使用 6 小时聚合的数据集。
- en: '![](../Images/83ab8f91f04bb1b626dd485efbdb8e54.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/83ab8f91f04bb1b626dd485efbdb8e54.png)'
- en: '**Figure 19.** PACF and ACF Correlograms for Jan 2016\. Image by the author.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 19.** 2016 年 1 月的 PACF 和 ACF 相关图。图像由作者提供。'
- en: Correlograms return the correlation coefficients ranging from -1.0 to 1.0 and
    a shaded area indicating the significance threshold. Any value that extends beyond
    that should be considered statistically significant.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 相关图返回的相关系数范围从 -1.0 到 1.0，并且有一个阴影区域表示显著性阈值。任何超出该范围的值都应被视为统计显著的。
- en: 'From the results above, we can finally conclude that on a 6-hours aggregation:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述结果，我们最终可以得出结论，在 6 小时聚合下：
- en: Lags 1, 2, 3 (t-6h, t-12h, and t-18h) and sometimes 4 (t-24h) have significant
    PACF.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滞后 1、2、3（t-6h、t-12h 和 t-18h）以及有时滞后 4（t-24h）具有显著的 PACF。
- en: Lags 1 and 4 (t-6h and t-24h) show significant ACF for most cases.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滞后 1 和 4（t-6h 和 t-24h）在大多数情况下显示出显著的 ACF。
- en: 'And take note of some final good practices:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 并注意一些最终的好实践：
- en: Plotting correlograms for large periods of time series with high granularity
    (For example, plotting a whole-year correlogram for a dataset with hourly measurements)
    should be avoided, as the significance threshold narrows down to zero with increasingly
    higher sample sizes.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免对长时间段的时间序列进行高粒度的相关图绘制（例如，对具有每小时测量数据集绘制一整年的相关图），因为随着样本量的增加，显著性阈值会缩小到零。
- en: I defined an `x_label` parameter to our function to make it easy to annotate
    the X-axis with the time period represented by each lag. It is common to see correlograms
    without that information, but having easy access to it can avoid misinterpretations
    of the results.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我为我们的函数定义了一个 `x_label` 参数，以便轻松地在 X 轴上标注每个滞后所代表的时间段。通常会看到没有这些信息的相关图，但轻松访问这些信息可以避免对结果的误解。
- en: Statsmodels `plot_acf()` and `plot_pacf()` default values are set to include
    the 0-lag correlation coefficient in the plot. Since the correlation of a number
    with itself is always one, I have set our plots to start from the first lag with
    the parameter `zero=False`. It also improves the scale of the Y-axis, making the
    lags we actually need to analyze more readable.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Statsmodels 的 `plot_acf()` 和 `plot_pacf()` 默认值设置为在图中包含 0 滞后相关系数。由于一个数字与其自身的相关性始终为
    1，我已将我们的图从第一个滞后开始绘制，参数为 `zero=False`。这也改善了 Y 轴的刻度，使我们实际需要分析的滞后更加易读。
- en: With that, we have thoroughly explored our time series. With a toolset of visualizations
    and analytical functions, we could draw a comprehensive understanding of our data.
    You have also learned some of the best practices when exploring time series datasets
    and how to present them succinctly and polishedly with high-quality plots.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们已经全面探索了我们的时间序列。借助一系列可视化和分析功能，我们可以对数据有一个全面的理解。你还学习了一些在探索时间序列数据集时的最佳实践，以及如何用高质量的图表简洁且精炼地呈现这些数据。
- en: Enjoyed this Story?
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 喜欢这个故事吗？
- en: '*You can follow me here on Medium for more articles about data science, machine
    learning, visualization, and data analytics.*'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可以在 Medium 上关注我，获取更多关于数据科学、机器学习、可视化和数据分析的文章。*'
- en: '*You can also find me on* [*LinkedIn*](https://www.linkedin.com/in/erich-hs/)
    *and on* [*X*](https://twitter.com/EhsErich)*, where I share shorter versions
    of these contents.*'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*你还可以在* [*LinkedIn*](https://www.linkedin.com/in/erich-hs/) *和* [*X*](https://twitter.com/EhsErich)
    *上找到我，我会在这些平台上分享这些内容的简短版本。*'
- en: '[](https://medium.com/subscribe/@erich.hs?source=post_page-----78bf40d16083--------------------------------)
    [## Get an email whenever Erich Silva publishes.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 订阅 Erich Silva 的邮件更新](https://medium.com/subscribe/@erich.hs?source=post_page-----78bf40d16083--------------------------------)'
- en: Get an email whenever Erich Silva publishes. By signing up, you will create
    a Medium account if you don't already have…
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 订阅邮件更新，以便每当 Erich Silva 发布新内容时，你都会收到邮件。如果你还没有 Medium 帐户，将会创建一个…
- en: medium.com](https://medium.com/subscribe/@erich.hs?source=post_page-----78bf40d16083--------------------------------)
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/subscribe/@erich.hs?source=post_page-----78bf40d16083--------------------------------)'
- en: References
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考
- en: '[1] “Department of Health — Fine Particles (PM 2.5) Questions and Answers.”
    Accessed October 14, 2022\. [https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm](https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] “卫生部门—细颗粒物（PM 2.5）问答。” 访问日期：2022年10月14日。 [https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm](https://www.health.ny.gov/environmental/indoors/air/pmq_a.htm)'
- en: '[2] Peixeiro, Marco. “3\. Going on a Random Walk.” Essay. In *Time Series Forecasting
    in Python*, 30–58\. O’Reilly Media, 2022.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Peixeiro, Marco. “3\. 随机游走。” 论文。收录于*《Python中的时间序列预测》*，第30–58页。O’Reilly
    Media，2022年。'
- en: '[3] Peixeiro, Marco. “5\. Modeling an Autoregressive Process.” Essay. In *Time
    Series Forecasting in Python*, 81–100\. O’Reilly Media, 2022.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] Peixeiro, Marco. “5\. 建模自回归过程。” 论文。收录于*《Python中的时间序列预测》*，第81–100页。O’Reilly
    Media，2022年。'
- en: '[4] Peixeiro, Marco. “8\. Accounting for Seasonality.” Essay. In *Time Series
    Forecasting in Python*, 156–79\. O’Reilly Media, 2022.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Peixeiro, Marco. “8\. 季节性调整。” 论文。收录于*《Python中的时间序列预测》*，第156–179页。O’Reilly
    Media，2022年。'
- en: '[5] Services, Ministry of Citizens’. “The BC Data Catalogue.” Province of British
    Columbia. Province of British Columbia, February 2, 2022\. [https://www2.gov.bc.ca/gov/content/data/bc-data-catalogue](https://www2.gov.bc.ca/gov/content/data/bc-data-catalogue)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] 服务部，公民事务部。“BC 数据目录。” 英属哥伦比亚省。英属哥伦比亚省，2022年2月2日。 [https://www2.gov.bc.ca/gov/content/data/bc-data-catalogue](https://www2.gov.bc.ca/gov/content/data/bc-data-catalogue)'
- en: '[6] “Stationarity and Detrending (ADF/KPSS).” statsmodels. Accessed October
    17, 2022\. [https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] “平稳性和去趋势（ADF/KPSS）。” statsmodels。访问日期：2022年10月17日。 [https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html](https://www.statsmodels.org/dev/examples/notebooks/generated/stationarity_detrending_adf_kpss.html)'
