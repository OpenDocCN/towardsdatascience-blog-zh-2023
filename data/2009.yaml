- en: Word2Vec, GloVe, and FastText, Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Word2Vec、GloVe 和 FastText 解析
- en: 原文：[https://towardsdatascience.com/word2vec-glove-and-fasttext-explained-215a5cd4c06f?source=collection_archive---------3-----------------------#2023-06-20](https://towardsdatascience.com/word2vec-glove-and-fasttext-explained-215a5cd4c06f?source=collection_archive---------3-----------------------#2023-06-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/word2vec-glove-and-fasttext-explained-215a5cd4c06f?source=collection_archive---------3-----------------------#2023-06-20](https://towardsdatascience.com/word2vec-glove-and-fasttext-explained-215a5cd4c06f?source=collection_archive---------3-----------------------#2023-06-20)
- en: How computers understand words
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算机如何理解词汇
- en: '[](https://medium.com/@dataemporium?source=post_page-----215a5cd4c06f--------------------------------)[![Ajay
    Halthor](../Images/1be821c8d8ed336b9ecedcf94f960ede.png)](https://medium.com/@dataemporium?source=post_page-----215a5cd4c06f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----215a5cd4c06f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----215a5cd4c06f--------------------------------)
    [Ajay Halthor](https://medium.com/@dataemporium?source=post_page-----215a5cd4c06f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@dataemporium?source=post_page-----215a5cd4c06f--------------------------------)[![Ajay
    Halthor](../Images/1be821c8d8ed336b9ecedcf94f960ede.png)](https://medium.com/@dataemporium?source=post_page-----215a5cd4c06f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----215a5cd4c06f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----215a5cd4c06f--------------------------------)
    [Ajay Halthor](https://medium.com/@dataemporium?source=post_page-----215a5cd4c06f--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb0a3e7e495ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-glove-and-fasttext-explained-215a5cd4c06f&user=Ajay+Halthor&userId=b0a3e7e495ca&source=post_page-b0a3e7e495ca----215a5cd4c06f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----215a5cd4c06f--------------------------------)
    ·10 min read·Jun 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F215a5cd4c06f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-glove-and-fasttext-explained-215a5cd4c06f&user=Ajay+Halthor&userId=b0a3e7e495ca&source=-----215a5cd4c06f---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb0a3e7e495ca&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-glove-and-fasttext-explained-215a5cd4c06f&user=Ajay+Halthor&userId=b0a3e7e495ca&source=post_page-b0a3e7e495ca----215a5cd4c06f---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----215a5cd4c06f--------------------------------)
    ·10分钟阅读·2023年6月20日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F215a5cd4c06f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-glove-and-fasttext-explained-215a5cd4c06f&user=Ajay+Halthor&userId=b0a3e7e495ca&source=-----215a5cd4c06f---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F215a5cd4c06f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-glove-and-fasttext-explained-215a5cd4c06f&source=-----215a5cd4c06f---------------------bookmark_footer-----------)![](../Images/9c0e7688b42e45235291764ce07ad479.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F215a5cd4c06f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fword2vec-glove-and-fasttext-explained-215a5cd4c06f&source=-----215a5cd4c06f---------------------bookmark_footer-----------)![](../Images/9c0e7688b42e45235291764ce07ad479.png)'
- en: Photo by [Growtika](https://unsplash.com/@growtika?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Growtika](https://unsplash.com/@growtika?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Computers don’t understand words like we do. They prefer to work with numbers.
    So, to help computers understand words and their meanings, we use something called
    embeddings. These embeddings numerically represent words as mathematical vectors.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机不像我们一样理解词汇。它们更倾向于处理数字。因此，为了帮助计算机理解词汇及其含义，我们使用一种叫做嵌入的方法。这些嵌入以数学向量的形式数值化地表示词汇。
- en: The cool thing about these embeddings is that if we learn them properly, words
    that have similar meanings will have similar numeric values. In other words, their
    numbers will be closer to each other. This allows computers to grasp the connections
    and similarities between different words based on their numeric representations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些嵌入的酷炫之处在于，如果我们正确学习它们，那么具有相似含义的词汇将具有相似的数值。换句话说，它们的数值会更接近。这使得计算机可以基于数值表示理解不同词汇之间的联系和相似性。
- en: One prominent method for learning word embeddings is Word2Vec. In this article,
    we will delve into the intricacies of Word2Vec and explore its various architectures
    and variants.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一种学习词嵌入的显著方法是Word2Vec。在本文中，我们将深入探讨Word2Vec的复杂性，并探讨其各种架构和变体。
- en: Word2Vec
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Word2Vec
- en: '![](../Images/729bbfa94374af6bfcda2475c9a71f4f.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/729bbfa94374af6bfcda2475c9a71f4f.png)'
- en: 'Figure 1: Word2Vec architectures ([Source](https://arxiv.org/abs/1301.3781))'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：Word2Vec架构（[来源](https://arxiv.org/abs/1301.3781)）
- en: In the early days, sentences were represented with n-gram vectors. These vectors
    aimed to capture the essence of a sentence by considering sequences of words.
    However, they had some limitations. N-gram vectors were often large and sparse,
    which made them computationally challenging to create. This created…
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期，句子通过n-gram向量表示。这些向量旨在通过考虑单词序列来捕捉句子的本质。然而，它们存在一些局限性。n-gram向量通常很大且稀疏，这使得它们在计算上难以创建。这就产生了…
