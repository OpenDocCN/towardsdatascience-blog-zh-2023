- en: 'Causal Python: Five Novel Causal Ideas At NeurIPS 2023'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因果 Python：2023年NeurIPS大会上的五个新颖因果观点
- en: 原文：[https://towardsdatascience.com/causal-python-five-novel-causal-ideas-at-neurips-2023-13bb68c5ed56](https://towardsdatascience.com/causal-python-five-novel-causal-ideas-at-neurips-2023-13bb68c5ed56)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/causal-python-five-novel-causal-ideas-at-neurips-2023-13bb68c5ed56](https://towardsdatascience.com/causal-python-five-novel-causal-ideas-at-neurips-2023-13bb68c5ed56)
- en: New exciting ideas that marry causality with generative modeling, conformal
    prediction and topology.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 令人兴奋的新想法，将因果关系与生成建模、保形预测和拓扑学结合起来。
- en: '[](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)[![Aleksander
    Molak](../Images/7fca5018f6ce88297fae31cef1fe0e6c.png)](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)[](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)
    [Aleksander Molak](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)[![Aleksander
    Molak](../Images/7fca5018f6ce88297fae31cef1fe0e6c.png)](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)[](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)
    [Aleksander Molak](https://aleksander-molak.medium.com/?source=post_page-----13bb68c5ed56--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)
    ·7 min read·Sep 24, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----13bb68c5ed56--------------------------------)
    ·阅读时间7分钟·2023年9月24日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e58678914a0248374537c9066bfa9234.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e58678914a0248374537c9066bfa9234.png)'
- en: Image by [**Pixabay** at **Pexels.com**](https://www.pexels.com/photo/binocular-blue-sky-daylight-discovery-221538/)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[**Pixabay** at **Pexels.com**](https://www.pexels.com/photo/binocular-blue-sky-daylight-discovery-221538/)
- en: NeurIPS is considered one of the most important and prestigious conferences
    on artificial intelligence and machine learning globally due to its rigorous paper
    review process and high quality of accepted research.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: NeurIPS被认为是全球最重要和最负盛名的人工智能和机器学习会议之一，因为其严格的论文审查过程和高质量的研究。
- en: With its multidisciplinary focus, the conference covers an extensive range of
    topics related to developing intelligent systems and machine learning algorithms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 会议具有跨学科的关注点，涵盖了与开发智能系统和机器学习算法相关的广泛话题。
- en: The number of causality-related papers accepted at NeurIPS grew exponentially
    over the last couple of years.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，NeurIPS大会上接受的与因果关系相关的论文数量呈指数增长。
- en: In this article we introduce five causal papers accepted at the 2023 edition
    of the conference that drew my attention as bringing important new insights to
    the field.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们介绍了2023年会议上接受的五篇因果论文，这些论文引起了我的注意，带来了对该领域的重要新见解。
- en: Note that this is a subjective and certainly an incomplete list. One of the
    reasons for this is that at the time of writing NeurIPS still hasn’t published
    the full list of papers accepted at the conference.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是一个主观且肯定不完整的列表。原因之一是，在撰写时，NeurIPS尚未发布会议接受论文的完整列表。
- en: That said, I am convinced that the ideas presented in the papers introduced
    below have a chance to move our field forward.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我相信下面介绍的论文中的想法有可能推动我们的领域向前发展。
- en: Let’s start!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧！
- en: Conformal meta-learners
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保形元学习者
- en: Conformal prediction is a family of uncertainty quantification techniques originally
    proposed by Vladimir Vovk.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 保形预测是一类不确定性量化技术，最初由Vladimir Vovk提出。
- en: Conformal prediction is model-free (no distributional assumptions are needed)
    and provides frequentist coverage guarantees. In other words, it guarantees that
    the true outcome will fall into the prediction intervals (or sets) with high probability
    under the *exchangeability* assumption¹.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 保形预测是无模型的（无需分布假设），并提供频率学覆盖保证。换句话说，它保证在*可交换性*假设下，真实结果将以高概率落入预测区间（或集合）¹。
- en: '![](../Images/cf4e6ae535cd22c446a29f0b4f86af65.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cf4e6ae535cd22c446a29f0b4f86af65.png)'
- en: '**Figure 1.** Depiction of conformal meta-learners. Source: [https://bit.ly/44Z9U9L](https://bit.ly/44Z9U9L)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1.** 保形元学习者的描述。来源：[https://bit.ly/44Z9U9L](https://bit.ly/44Z9U9L)'
- en: In their new paper **Conformal Meta-learners for Predictive Inference of Individual
    Treatment Effects** just accepted at NeurIPS 2022, Ahmed Alaa and colleagues propose
    a new framework for conformal meta-learners.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的新论文**《用于个体治疗效应预测推断的符合性元学习器》**中，Ahmed Alaa及其同事提出了一种新的符合性元学习框架，该论文刚刚被NeurIPS
    2022接受。
- en: Their approach enables direct inference on the target parameter (individualized
    treatment effect; **ITE**), an important improvement over previous methods.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的方法使得直接推断目标参数（个体化治疗效应；**ITE**）成为可能，这是对先前方法的重要改进。
- en: The authors evaluate the method’s performance in a series of experiments using
    synthetic and semi-synthetic data and measure the performance in terms of achieved
    coverage, root mean squared error and interval length.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作者在一系列使用合成数据和半合成数据的实验中评估了该方法的性能，并以实现的覆盖率、均方根误差和区间长度来衡量性能。
- en: Conclusions? Conformalized *DR-learner** achieves superior performance in most
    settings.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 结论？符合性*DR-learner*在大多数设置中表现优越。
- en: One of the limitations of the framework is that it requires the propensity score
    to be known, which may be limiting in some cases.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架的一个局限性是它要求已知倾向评分，这在某些情况下可能是限制性的。
- en: This work opens an exciting new direction for combining causal methods with
    the coverage guarantees offered by conformal predictors.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作为将因果方法与符合性预测器提供的覆盖保证相结合开辟了一个令人兴奋的新方向。
- en: 🟡 Read the [**paper**](https://bit.ly/44Z9U9L)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 阅读[**论文**](https://bit.ly/44Z9U9L)
- en: 🟡 Check the [**code**](https://bit.ly/3LBpwsX)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 查看[**代码**](https://bit.ly/3LBpwsX)
- en: '* Looking to learn about meta-learners and DR-learner? Check chapters 9 and
    10 of [Causal Inference and Discovery in Python](https://amzn.to/3EQeRH9) or take
    a look the book’s free [GitHub repo here](https://bit.ly/3t3dulL).'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* 想了解关于元学习器和DR-learner的内容？请查看[Causal Inference and Discovery in Python](https://amzn.to/3EQeRH9)的第9章和第10章，或者查看该书的免费[GitHub
    仓库](https://bit.ly/3t3dulL)。'
- en: Causal normalizing flows
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 因果归一化流
- en: Normalizing flows is a class of neural models that can express complex distributions
    by transforming simple ones.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化流是一类神经模型，通过将简单分布转换为复杂分布来表示复杂分布。
- en: In particular, autoregressive normalizing flows estimate the distribution of
    variable X as a function of the variables preceding it. If we want to express
    one variable as a function of the variables preceding it, we first need to order
    these variables somehow.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，自回归归一化流将变量X的分布估计为其前面变量的函数。如果我们想要将一个变量表示为其前面变量的函数，我们首先需要以某种方式对这些变量进行排序。
- en: Note that this setting resembles **structural causal models** (**SCM**s), where
    each variable is expressed as a function of its parents.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这种设置类似于**结构性因果模型**（**SCM**），其中每个变量被表示为其父变量的函数。
- en: '![](../Images/4b32075445e5c4acd50adb95152542a8.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b32075445e5c4acd50adb95152542a8.png)'
- en: '**Figure 2\.** Example of the linear SCM written (a) in its usual recursive'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2**. 线性SCM的示例（a）以其通常的递归形式书写'
- en: formulation; (b) without recursions, with each step made explicit; (c) without
    recursions, as a single
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 公式；（b）没有递归，每一步都明确；（c）没有递归，作为一个单一的
- en: 'function; and (d) writing u as a function of x. Source: [https://bit.ly/3ZvwbuD](https://bit.ly/3ZvwbuD)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 函数；以及（d）将u写作x的函数。来源：[https://bit.ly/3ZvwbuD](https://bit.ly/3ZvwbuD)
- en: Normalizing flows has been previously used for causal discovery (e.g. **CAREFL**
    (Khemakhem et al., 2021) used in **DECI** (Geffner et al., 2022); see Molak (2023),
    chapter 13 for details).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化流以前曾用于因果发现（例如，**CAREFL**（Khemakhem等，2021）用于**DECI**（Geffner等，2022）；有关详细信息，请参见Molak（2023），第13章）。
- en: 'In their new paper **Causal Normalizing Flows: From Theory to Practice***,*
    Adrián Javaloy and colleagues have taken these ideas to the next level. They show
    that causal models can be identified from observational data, given causal ordering
    and recovered using normalizing flows.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的新论文**《因果归一化流：从理论到实践》**中，Adrián Javaloy及其同事将这些想法提升到了一个新水平。他们展示了在给定因果排序的情况下，因果模型可以从观察数据中识别，并使用归一化流进行恢复。
- en: Next, they propose an implementation of *do*-operator in causal normalizing
    flows that allow us to answer interventional and counterfactual queries.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，他们提出了一种在因果归一化流中实现*do*操作符的方法，这使我们能够回答干预性和反事实查询。
- en: Finally, they demonstrate the effectiveness of their method on mixed (continuous/discrete)
    data with an incomplete graph.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，他们在一个不完整图上的混合（连续/离散）数据上展示了他们方法的有效性。
- en: What an exciting time to be alive!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 真是一个令人兴奋的时代！
- en: 🟡 Read the [**paper**](https://bit.ly/3ZvwbuD)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 阅读[**论文**](https://bit.ly/3ZvwbuD)
- en: 🟡 Check the [**code**](https://bit.ly/3PQuBAe)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 查看[**代码**](https://bit.ly/3PQuBAe)
- en: '[](/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715?source=post_page-----13bb68c5ed56--------------------------------)
    [## Causal Python — Level Up Your Causal Discovery Skills in Python (2023)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715?source=post_page-----13bb68c5ed56--------------------------------)
    [## 因果Python — 提升你在Python中的因果发现技能（2023）'
- en: …and unlock the potential of the best Causal Discovery package in Python!
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: …并解锁Python中最佳因果发现包的潜力！
- en: towardsdatascience.com](/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715?source=post_page-----13bb68c5ed56--------------------------------)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715?source=post_page-----13bb68c5ed56--------------------------------)'
- en: Generative models for partial counterfactual identification
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部分反事实识别的生成模型
- en: Counterfactuals are placed on the third rung of the Pearl’s *Ladder of Causation*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 反事实被置于Pearl的*因果阶梯*的第三层。
- en: This makes them the most difficult to work with as we need a very rich description
    of the **structural causal model** (**SCM**) of interest in order to address counterfactual
    queries.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得它们最难处理，因为我们需要非常丰富的**结构因果模型**（**SCM**）描述，以解决反事实查询。
- en: '![](../Images/7debb32ab53ec76a7ec7e8eb80e14bab.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7debb32ab53ec76a7ec7e8eb80e14bab.png)'
- en: '**Figure 3\.** Symbolic representation of the Pearlian ladder of causation.
    Counterfactual queries require the richest representation of the SCM. Source:
    [https://bit.ly/45UzGgx](https://bit.ly/45UzGgx)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3.** Pearl因果阶梯的符号表示。反事实查询需要SCM的最丰富表示。来源：[https://bit.ly/45UzGgx](https://bit.ly/45UzGgx)'
- en: So-called *symbolic identifiability* is not always available and other assumptions
    that can make answering counterfactual queries feasible (e.g. monotonicity) might
    be difficult to meet in certain scenarios or only work in discrete cases.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所谓的*符号可识别性*并不总是可用，其他可以使回答反事实查询可行的假设（例如单调性）在某些场景下可能难以满足，或仅在离散情况下有效。
- en: The new paper, **Partial Counterfactual Identification of Continuous Outcomes
    with a Curvature Sensitivity Model** by Valentyn Melnychuk and colleagues presents
    a novel approach that goes beyond these limitations.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Valentyn Melnychuk及其同事的新论文**《具有曲率敏感性模型的连续结果的部分反事实识别》**提出了一种超越这些限制的新方法。
- en: The authors take the topological perspective (for earlier works see e.g. Ibeling
    & Icard, 2021) on this challenge and propose a Curvature Sensitivity Model (**CSM**)
    that allows for partial counterfactual identification
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者从拓扑学的角度（有关早期工作的参考见例如Ibeling & Icard, 2021）来看待这一挑战，并提出了一种曲率敏感性模型（**CSM**），允许进行部分反事实识别。
- en: of continuous outcomes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 连续结果。
- en: In other words, the method enables us to find informative bounds for counterfactual
    queries under continuous outcomes when we don’t have full information about the
    data generating process.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，该方法使我们能够在没有关于数据生成过程的完整信息时，为连续结果下的反事实查询找到有信息量的界限。
- en: The authors suggest that the assumptions the solution relies on should be realistic
    for a broad category of use cases, from physics to medicine, and that the method
    has a potential to be relevant for decision-making in safety-critical settings.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 作者建议，解决方案所依赖的假设应在从物理学到医学的广泛用例中是现实的，并且该方法在安全关键环境中的决策中具有潜在的相关性。
- en: 'As a side note: the proposed method also relies on normalizing flows.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 作为附注：所提出的方法还依赖于归一化流。
- en: 🟡 Read the [**paper**](https://bit.ly/45UzGgx)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 阅读[**论文**](https://bit.ly/45UzGgx)
- en: 🟡 Check the [**code**](https://bit.ly/3t65znM)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 查看[**代码**](https://bit.ly/3t65znM)
- en: Passive data, active causal strategies and language models
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 被动数据、主动因果策略和语言模型
- en: If you follow me on [LinkedIn](https://bit.ly/3RycjoP) or [Twitter/X](https://bit.ly/3rzaY6i),
    you may remember a [post](https://bit.ly/46pTI2c) about this paper.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你关注我在[LinkedIn](https://bit.ly/3RycjoP)或[Twitter/X](https://bit.ly/3rzaY6i)，你可能会记得关于这篇论文的[帖子](https://bit.ly/46pTI2c)。
- en: Actually, this paper was one of the papers that inspired me and my colleagues
    to organize the **AAAI 2024** [workshop on large language models and causality](https://bit.ly/3rj5f4K).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这篇论文是激励我和我的同事组织**AAAI 2024** [关于大型语言模型和因果性的研讨会](https://bit.ly/3rj5f4K)的论文之一。
- en: But, to the point!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，言归正传！
- en: '![](../Images/1ef8b1135f6c0a3ded5c07a16f18ce68.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ef8b1135f6c0a3ded5c07a16f18ce68.png)'
- en: '**Figure 4.** The causal DAG environment and experimental results. (a) The
    constraints imposed on'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**图4.** 因果DAG环境和实验结果。(a) 施加的约束'
- en: the causal DAG structures when creating the training dataset, and when evaluating
    the agent on test
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建训练数据集时，以及在测试时评估代理时，因果 DAG 结构
- en: structures. During training, D is not allowed to be an ancestor of E (even indirectly),
    though they
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 结构。在训练期间，D 不允许成为 E 的祖先（即使是间接的），尽管它们
- en: may be correlated due to confounding variables. In evaluation environments,
    D is the most impactful
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 可能由于混淆变量而相关。在评估环境中，D 是最有影响力的
- en: ancestor of E (see text). (b) Rewards obtained by the agent when evaluated in
    interactive settings, as a
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: E 的祖先（见文本）。(b) 在互动设置中评估时，代理获得的奖励，作为
- en: percentage of the optimal rewards. In both evaluation settings, the agent still
    achieves close to optimal
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最优奖励的百分比。在这两种评估设置中，代理仍然接近最优
- en: reward. © Analyzing the agent’s behavior in more detail, by plotting the proportion
    of the agent’s
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励。© 更详细地分析代理的行为，通过绘制代理的比例
- en: actions that match the optimal behavior, or baselines based on heuristics from
    the interventions or
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与最优行为相匹配的行动，或基于干预或
- en: correlational statistics. The agent matches the optimal strategy significantly
    more closely than it
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 相关统计数据。代理的策略与最优策略的匹配显著更接近。
- en: 'matches the heuristic baselines. Source: [https://bit.ly/3Rt4cd3](https://bit.ly/3Rt4cd3)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 与启发式基准匹配。来源：[https://bit.ly/3Rt4cd3](https://bit.ly/3Rt4cd3)
- en: In their paper **Passive Learning of Active Causal Strategies in Agents and
    Language Models**, DeepMind’s Andrew Lampinen and colleagues demonstrate that
    agents and (large) language models (**LLM**s) can learn active causal strategies
    from passive (observational) data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文**《代理和语言模型中的被动学习主动因果策略》**中，DeepMind 的 Andrew Lampinen 和同事们展示了代理和（大规模）语言模型（**LLM**s）可以从被动（观察）数据中学习主动因果策略。
- en: These strategies can generalize to out-of-distribution data (!), but *only*
    under certain conditions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些策略可以泛化到分布外的数据（！），但*仅*在某些条件下。
- en: As the authors propose, the agents “*acquire generalizable strategies for discovering
    and exploiting causal structures, as long as they can intervene at test time*”.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如作者提出的，代理“*获得了用于发现和利用因果结构的可泛化策略，只要他们可以在测试时进行干预*”。
- en: In-prompt explanations are *critical* for enabling generalization in LLMs. This
    work does not imply passive learning surpasses active learning or solves confounding
    in LLMs entirely. However, it marks an important step toward expanding language
    models’ causal capabilities.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 提示中的解释对 LLMs 的泛化能力至关重要。此工作并不意味着被动学习超越主动学习或完全解决 LLMs 中的混淆。然而，它标志着扩展语言模型因果能力的重要一步。
- en: I can’t wait to see more research continuing down this exciting path!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我迫不及待想看到更多的研究继续在这个激动人心的路径上前进！
- en: 🟡 Read the [**paper**](https://bit.ly/3Rt4cd3)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 阅读 [**论文**](https://bit.ly/3Rt4cd3)
- en: Generalized sensitivity analysis
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广义敏感性分析
- en: Sensitivity analysis is instrumental for causal analysts whenever we cannot
    exclude the possibility of the existence of hidden confounding.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们不能排除存在隐藏混淆的可能性时，敏感性分析对于因果分析师至关重要。
- en: Traditional methods for sensitivity analysis often come with limitations (e.g.
    they assume a linear model or a single binary treatment).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的敏感性分析方法通常存在局限性（例如，它们假设线性模型或单一的二元处理）。
- en: In their new paper*,* **Sharp Bounds for Generalized Causal Sensitivity Analysis***,*
    Dennis Frauen and colleagues propose a novel unified
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的新论文中*，* **《广义因果敏感性分析的锐界》**，*Dennis Frauen 和同事们提出了一种新的统一
- en: framework for causal sensitivity analysis under unobserved confounding.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 用于未观察混淆下因果敏感性分析的框架。
- en: '![](../Images/bafae26b34a4921edd63a954bbfd49c8.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bafae26b34a4921edd63a954bbfd49c8.png)'
- en: '**Figure 5.** Bounding interventional distributions under the proposed model.
    Source: [https://bit.ly/3PLVBkl](https://bit.ly/3PLVBkl)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 5.** 在所提出模型下的干预分布界限。来源：[https://bit.ly/3PLVBkl](https://bit.ly/3PLVBkl)'
- en: The framework provides us with sharp bounds for a spectrum of causal effects,
    including (conditional) average treatment effects (**CATE**), effects for mediation,
    path analysis, and distributional effects.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架为一系列因果效应提供了锐界，包括（条件）平均处理效应（**CATE**）、中介效应、路径分析和分布效应。
- en: Moreover, the proposed approach works with discrete, continuous, and time-varying
    treatments.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，所提出的方法适用于离散、连续和时间变化的处理。
- en: Best part? The paper comes with a rich code repo.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最棒的部分？论文附带了一个丰富的代码库。
- en: 'To cite [Károly Zsolnai-Fehér](https://users.cg.tuwien.ac.at/zsolnai/):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '引用 [Károly Zsolnai-Fehér](https://users.cg.tuwien.ac.at/zsolnai/):'
- en: '*What a time to be alive!*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*真是一个活着的好时光！*'
- en: 🟡 Read the [**paper**](https://bit.ly/3PLVBkl)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 阅读 [**论文**](https://bit.ly/3PLVBkl)
- en: 🟡 Check the [**code**](https://bit.ly/3rp0UNg)
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 🟡 检查 [**代码**](https://bit.ly/3rp0UNg)
- en: '[](https://causalpython.io/?source=post_page-----13bb68c5ed56--------------------------------)
    [## Causal Python || Your go-to resource for learning about Causality in Python'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 因果Python || 你学习Python中因果关系的首选资源](https://causalpython.io/?source=post_page-----13bb68c5ed56--------------------------------)'
- en: Free weekly emails on causality and machine learning
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每周免费邮件关于因果关系和机器学习
- en: causalpython.io](https://causalpython.io/?source=post_page-----13bb68c5ed56--------------------------------)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[causalpython.io](https://causalpython.io/?source=post_page-----13bb68c5ed56--------------------------------)'
- en: Footnotes
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 脚注
- en: ¹ Here ***exchangeability*** has a different meaning than in the potential outcomes
    framework. We can think of it as a milder version of the IID assumption. See [here](https://bit.ly/3rtcjvB)
    for more details.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 在这里，***可交换性***的含义与潜在结果框架中的不同。我们可以将其视为IID假设的一个较温和版本。有关更多细节，请参见 [这里](https://bit.ly/3rtcjvB)。
- en: References
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Geffner, T., Antorán, J., Foster, A., Gong, W., Ma, C., Kıcıman, E., Sharma,
    A., Lamb, A., Kukla, M., Pawlowski, N., Allamanis, M., & Zhang, C. (2022). Deep
    End-to-end Causal Inference. *arXiv.*
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Geffner, T., Antorán, J., Foster, A., Gong, W., Ma, C., Kıcıman, E., Sharma,
    A., Lamb, A., Kukla, M., Pawlowski, N., Allamanis, M., & Zhang, C. (2022). 深度端到端因果推断。*arXiv*
- en: Ibeling, D., Icard, T. (2021). A Topological Perspective on Causal Inference.
    *35th Conference on Neural Information Processing Systems*.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Ibeling, D., Icard, T. (2021). 关于因果推断的拓扑视角。*第35届神经信息处理系统大会*。
- en: Khemakhem, I., Monti, R., Leech, R. &amp; Hyvarinen, A. (2021). Causal Autoregressive
    Flows . *Proceedings of The 24th International Conference on Artificial Intelligence
    and Statistics*, in *Proceedings of Machine Learning Research*, 130, 3520–3528\.
    [https://proceedings.mlr.press/v130/khemakhem21a.html](https://proceedings.mlr.press/v130/khemakhem21a.html).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Khemakhem, I., Monti, R., Leech, R. & Hyvarinen, A. (2021). 因果自回归流。*第24届国际人工智能与统计会议论文集*，在*机器学习研究论文集*，130，3520–3528\.
    [https://proceedings.mlr.press/v130/khemakhem21a.html](https://proceedings.mlr.press/v130/khemakhem21a.html)。
- en: 'Molak, A. (2023). *Causal Inference and Discovery in Python: Unlock the secrets
    of modern causal machine learning with DoWhy, EconML, PyTorch and more*. Packt
    Publishing.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Molak, A. (2023). *Python中的因果推断与发现：解锁现代因果机器学习的秘密，包括DoWhy、EconML、PyTorch等*。Packt
    Publishing。
