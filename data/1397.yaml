- en: A Gentle Intro to Chaining LLMs, Agents, and utils via LangChain
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《温和介绍：通过 LangChain 链接 LLMs、代理和工具》
- en: 原文：[https://towardsdatascience.com/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=collection_archive---------0-----------------------#2023-04-21](https://towardsdatascience.com/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=collection_archive---------0-----------------------#2023-04-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=collection_archive---------0-----------------------#2023-04-21](https://towardsdatascience.com/a-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81?source=collection_archive---------0-----------------------#2023-04-21)
- en: '*#LLM for beginners*'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*#初学者的 LLM*'
- en: Understand the basics of agents, tools, and prompts and some learnings along
    the way
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解代理、工具和提示的基础知识以及一些学习经验
- en: '[](https://varshitasher.medium.com/?source=post_page-----16cd385fca81--------------------------------)[![Dr.
    Varshita Sher](../Images/a3f2e9bf1dc1d8cbe018e54f9341f608.png)](https://varshitasher.medium.com/?source=post_page-----16cd385fca81--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16cd385fca81--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16cd385fca81--------------------------------)
    [Dr. Varshita Sher](https://varshitasher.medium.com/?source=post_page-----16cd385fca81--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://varshitasher.medium.com/?source=post_page-----16cd385fca81--------------------------------)[![Varshita
    Sher 博士](../Images/a3f2e9bf1dc1d8cbe018e54f9341f608.png)](https://varshitasher.medium.com/?source=post_page-----16cd385fca81--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16cd385fca81--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16cd385fca81--------------------------------)
    [Varshita Sher 博士](https://varshitasher.medium.com/?source=post_page-----16cd385fca81--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8ca36def59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=post_page-f8ca36def59----16cd385fca81---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16cd385fca81--------------------------------)
    ·20 min read·Apr 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16cd385fca81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=-----16cd385fca81---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8ca36def59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=post_page-f8ca36def59----16cd385fca81---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16cd385fca81--------------------------------)
    ·20分钟阅读·2023年4月21日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16cd385fca81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81&user=Dr.+Varshita+Sher&userId=f8ca36def59&source=-----16cd385fca81---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16cd385fca81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81&source=-----16cd385fca81---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16cd385fca81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-gentle-intro-to-chaining-llms-agents-and-utils-via-langchain-16cd385fca81&source=-----16cd385fca81---------------------bookmark_footer-----------)'
- en: 'Audience: For those feeling overwhelmed with the giant (yet brilliant) library…'
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 受众：对于那些被庞大（但卓越）库感到不知所措的人…
- en: '![](../Images/4c6806a457e762ae481cc1f29a02d4bd.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c6806a457e762ae481cc1f29a02d4bd.png)'
- en: Image generated by Author using [DALL.E 2](https://openai.com/product/dall-e-2)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用[DALL.E 2](https://openai.com/product/dall-e-2)生成的图像
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: I’d be lying if I said I have got the entire LangChain library covered — in
    fact, I am far from it. But the buzz surrounding it was enough to shake me out
    of my writing hiatus and give it a go 🚀.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我说我掌握了整个 LangChain 库，那我就是在撒谎——实际上，我远远没有做到。但是，围绕它的热议足以让我摆脱写作 hiatus，去尝试一下 🚀。
- en: The initial motivation was to see what was it that LangChain was adding (on
    a practical level) that set it apart from the chatbot I built last month using
    the `ChatCompletion.create()` function from the `openai` package. Whilst doing
    so, I realized I needed to understand the building blocks for LangChain first
    before moving on to the more complex parts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最初的动机是看看LangChain在实践中添加了什么（在实际水平上），这使它不同于上个月我用`openai`包中的`ChatCompletion.create()`函数构建的聊天机器人。在这样做的过程中，我意识到需要先理解LangChain的基础构建块，然后再转向更复杂的部分。
- en: This is what this article does. Heads-up though, there will be more parts coming
    as I am truly fascinated by the library and will continue to explore to see what
    all can be built through it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是本文所做的事情。请注意，随着我对这个库的着迷和持续探索，将会有更多的部分出现。
- en: Let’s begin by understanding the fundamental building blocks of LangChain —
    i.e. Chains. If you’d like to follow along, here’s the [GitHub repo](https://github.com/V-Sher/LangChain-Tutorial).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从理解LangChain的基本构建块 —— 即链条开始。如果你想跟进，请查看这个[GitHub仓库](https://github.com/V-Sher/LangChain-Tutorial)。
- en: What are chains in LangChain?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain中的链条是什么？
- en: Chains are what you get by connecting one or more large language models (LLMs)
    in a logical way. (Chains can be built of entities other than LLMs but for now,
    let’s stick with this definition for simplicity).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 链条是通过以逻辑方式连接一个或多个大型语言模型（LLMs）而得到的。 （虽然链条可以由除LLMs以外的实体构建，但现在让我们暂时使用这个定义以简化问题）。
- en: OpenAI is a type of LLM (provider) that you can use but there are others like
    Cohere, Bloom, Huggingface, etc.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI是一种LLM（提供者），你可以使用它，但还有其他像Cohere、Bloom、Huggingface等。
- en: '*Note: Pretty much most of these LLM providers will need you to request an
    API key in order to use them. So make sure you do that before proceeding with
    the remainder of this blog. For example:*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：几乎所有这些LLM提供者都需要您申请API密钥才能使用它们。所以请确保在继续阅读本博客的其余部分之前，您已经这样做了。例如：*'
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*P.S. I am going to use OpenAI for this tutorial because I have a key with
    credits that expire in a month’s time, but feel free to replace it with any other
    LLM. The concepts covered here will be useful regardless.*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*P.S. 我将在本教程中使用OpenAI，因为我有一个一个月后过期的积分密钥，但请随意替换为任何其他LLM。无论如何，这里涵盖的概念都将是有用的。*'
- en: Chains can be simple (i.e. Generic) or specialized (i.e. Utility).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 链条可以简单（例如通用）或专业化（例如实用）。
- en: 'Generic — A single LLM is the simplest chain. It takes an input prompt and
    the name of the LLM and then uses the LLM for text generation (i.e. output for
    the prompt). Here’s an example:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通用 — 单个LLM是最简单的链条。它接受一个输入提示和LLM的名称，然后使用LLM进行文本生成（即输出提示的结果）。这里是一个例子：
- en: Let’s build a basic chain — create a prompt and get a prediction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们构建一个基本的链条 —— 创建一个提示并获取预测结果
- en: Prompt creation (using `PromptTemplate`) is a bit fancy in Lanchain but this
    is probably because there are quite a few different ways prompts can be created
    depending on the use case (we will cover `AIMessagePromptTemplate`,
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在Lanchain中，使用`PromptTemplate`创建提示（Prompt）有点花哨，但这可能是因为根据用例的不同，可以有多种不同的方式来创建提示（我们将涵盖`AIMessagePromptTemplate`等等）。
- en: '`HumanMessagePromptTemplate` etc. in the next blog post). Here’s a simple one
    for now:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`HumanMessagePromptTemplate`等等将在下一篇博客文章中涵盖。现在先看一个简单的例子：'
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Note: If you require multiple* `*input_variables*`*, for instance:* `*input_variables=["product",
    "audience"]*` *for a template such as* `*“What is a good name for a company that
    makes {product} for {audience}”*`*, you need to do* `print(prompt.format(product="podcast
    player", audience="children”)` to get the updated prompt.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：如果您需要多个* `*input_variables*`，例如：* `*input_variables=["product", "audience"]*`
    *用于模板，例如* `*“一个公司的好名字，为{product}制作{audience}”*`，则需要执行* `print(prompt.format(product="podcast
    player", audience="children”)` *以获取更新后的提示。'
- en: Once you have built a prompt, we can call the desired LLM with it. To do so,
    we create an `LLMChain` instance (in our case, we use `OpenAI`'s large language
    model `text-davinci-003`). To get the prediction (i.e. AI-generated text), we
    use `run` function with the name of the `product`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您建立了一个提示，我们就可以调用所需的LLM。为此，我们创建一个`LLMChain`实例（在我们的例子中，我们使用`OpenAI`的大型语言模型`text-davinci-003`）。要获取预测结果（即AI生成的文本），我们使用`run`函数和`product`的名称。
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If you had more than one input_variables, then you won’t be able to use `run`.
    Instead, you’ll have to pass all the variables as a `dict`. For example, `llmchain({“product”:
    “podcast player”, “audience”: “children”})`.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你有多个输入变量，那么就不能使用`run`。相反，你需要将所有变量作为`dict`传递。例如，`llmchain({"product": "podcast
    player", "audience": "children"})`。'
- en: '*Note 1: According to* [*OpenAI*](https://openai.com/blog/introducing-chatgpt-and-whisper-apis),`*davinci*`
    *text-generation models are 10x more expensive than their chat counterparts i.e*
    `*gpt-3.5-turbo*`*, so I tried to switch from a text model to a chat model (i.e.
    from* `*OpenAI*` *to* `*ChatOpenAI*`*) and the results are pretty much the same.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意 1：根据* [*OpenAI*](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)，`*davinci*`
    *文本生成模型的费用是其聊天对应模型的 10 倍，即* `*gpt-3.5-turbo*`*，因此我尝试从文本模型切换到聊天模型（即从* `*OpenAI*`
    *到* `*ChatOpenAI*`*），结果差别不大。*'
- en: '*Note 2: You might see some tutorials using* `*OpenAIChat*`*instead of* `*ChatOpenAI*`*.
    The former is* [*deprecated*](https://github.com/hwchase17/langchain/issues/1556#issuecomment-1463224442)
    *and will no longer be supported and we are supposed to use* `*ChatOpenAI*`*.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意 2：你可能会看到一些教程使用* `*OpenAIChat*`*而不是* `*ChatOpenAI*`*。前者已经* [*弃用*](https://github.com/hwchase17/langchain/issues/1556#issuecomment-1463224442)
    *并且将不再受支持，我们应使用* `*ChatOpenAI*`*。*'
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This concludes our section on simple chains. It is important to note that we
    rarely use generic chains as standalone chains. More often they are used as building
    blocks for Utility chains (as we will see next).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分关于简单链的介绍到此为止。需要注意的是，我们很少将通用链作为独立链使用。更常见的是它们作为实用链的构建块（正如我们接下来会看到的）。
- en: 2\. Utility — These are specialized chains, comprised of many LLMs to help solve
    a specific task. For example, LangChain supports some end-to-end chains (such
    as `[AnalyzeDocumentChain](https://python.langchain.com/docs/use_cases/question_answering/how_to/analyze_document)`
    for summarization, QnA, etc) and some specific ones (such as `[GraphQnAChain](https://python.langchain.com/en/latest/modules/chains/index_examples/graph_qa.html#querying-the-graph)`
    for creating, querying, and saving graphs). We will look at one specific chain
    called `PalChain` in this tutorial for digging deeper.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 实用工具 — 这些是专门的链，由许多 LLM 组成，以帮助解决特定任务。例如，LangChain 支持一些端到端的链（如`[AnalyzeDocumentChain](https://python.langchain.com/docs/use_cases/question_answering/how_to/analyze_document)`
    用于总结、问答等）和一些特定的链（如`[GraphQnAChain](https://python.langchain.com/en/latest/modules/chains/index_examples/graph_qa.html#querying-the-graph)`
    用于创建、查询和保存图形）。在本教程中，我们将深入探讨一个名为 `PalChain` 的特定链。
- en: PAL stands for [Programme Aided Language Model](https://arxiv.org/pdf/2211.10435.pdf).
    `PALChain` reads complex math problems (described in natural language) and generates
    programs (for solving the math problem) as the intermediate reasoning steps, but
    offloads the solution step to a runtime such as a Python interpreter.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: PAL 代表 [程序辅助语言模型](https://arxiv.org/pdf/2211.10435.pdf)。`PALChain` 读取复杂的数学问题（用自然语言描述）并生成程序（用于解决数学问题）作为中间推理步骤，但将解决步骤委托给如
    Python 解释器等运行时。
- en: 'To confirm this is in fact true, we can inspect the `_call()` in the base code
    [here](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py).
    Under the hood, we can see this chain:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认这一点，我们可以检查基础代码中的 `_call()` [这里](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py)。在底层，我们可以看到这个链：
- en: '[first uses a generic](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L58)
    `[LLMChain](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L58)`
    [to understand the query](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L58)
    we pass to it and get a prediction. Thus, this chain requires passing an LLM at
    the time of initializing (we are going to use the same OpenAI LLM as before).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[首先使用一个通用链](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L58)
    `[LLMChain](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L58)`
    [来理解我们传递的查询](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L58)
    并获取预测。因此，这个链在初始化时需要传递一个 LLM（我们将使用之前的 OpenAI LLM）。'
- en: s[econd, it uses Python REPL](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L63-L64)
    to solve the function/program outputted by the LLM.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第二，使用 Python REPL](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/base.py#L63-L64)
    来解决 LLM 输出的函数/程序。'
- en: '*P.S. It is a good practice to inspect* `*_call()*` *in* `*base.py*` *for any
    of the chains in LangChain to see how things are working under the hood.*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*附注：检查* `*_call()*` *在* `*base.py*` *中是一个好习惯，可以查看 LangChain 中的任何链如何在底层工作。*'
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Note1:* `*verbose*` *can be set to* `*False*` *if you do not need to see the
    intermediate step.*'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意1：如果你不需要看到中间步骤，`*verbose*` *可以设置为* `*False*`*。*'
- en: Now some of you may be wondering — *but what about the prompt? We certainly
    didn’t pass one as we did for the generic* `*llmchain*` *we built.* The fact is,
    it is automatically loaded when using `.from_math_prompt()`. You can check the
    default prompt using `palchain.prompt.template` or you can directly inspect the
    prompt file [here](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/math_prompt.py).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有些人可能会想 — *但提示呢？我们肯定没有像我们建立的通用* `*llmchain*` *那样传递它。* 实际上，当使用`.from_math_prompt()`时，它会自动加载。您可以使用`palchain.prompt.template`检查默认提示，或者直接查看提示文件[这里](https://github.com/hwchase17/langchain/blob/master/langchain/chains/pal/math_prompt.py)。
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '*Note: Most of the utility chains will have their prompts pre-defined as part
    of the library (check them out* [*here*](https://github.com/hwchase17/langchain/tree/master/langchain/chains)*).
    They are, at times, quite detailed (read: lots of tokens) so there is definitely
    a trade-off between cost and the quality of response from the LLM.*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：大多数实用链条的提示作为库的一部分是预定义的（在这里查看* [*这里*](https://github.com/hwchase17/langchain/tree/master/langchain/chains)*）。它们有时非常详细（即：有很多令牌），因此在成本和LLM响应质量之间肯定存在权衡。*'
- en: Are there any Chains that don’t need LLMs and prompts?
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 是否存在不需要LLM和提示的链条？
- en: '*Even though PalChain requires an LLM (and a corresponding prompt) to parse
    the user’s question written in natural language, there are some chains in LangChain
    that don’t need one. These are mainly transformation chains that preprocess the
    prompt, such as removing extra spaces, before inputting it into the LLM. You can
    see another example* [*here*](https://python.langchain.com/en/latest/modules/chains/generic/transformation.html)*.*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*尽管PalChain需要一个LLM（以及相应的提示）来解析用户用自然语言编写的问题，但在LangChain中有一些链条不需要。这些主要是预处理提示的转换链条，例如删除额外的空格，然后将其输入LLM。你可以在另一个例子中看到*
    [*这里*](https://python.langchain.com/en/latest/modules/chains/generic/transformation.html)*。*'
- en: Can we get to the good part and start creating chains?
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们能进入精彩部分并开始创建链条吗？
- en: Of course, we can! We have all the basic building blocks we need to start chaining
    together LLMs logically such that input from one can be fed to the next. To do
    so, we will use `SimpleSequentialChain`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当然可以！我们已经有了开始逻辑地将LLM连接在一起的基本构建块。为此，我们将使用`SimpleSequentialChain`。
- en: The documentation has some great examples on this, for example, you can see
    [here](https://python.langchain.com/en/latest/modules/chains/generic/transformation.html)
    how to have two chains combined where chain#1 is used to clean the prompt (remove
    extra whitespaces, shorten prompt, etc) and chain#2 is used to call an LLM with
    this clean prompt. Here’s [another one](https://js.langchain.com/docs/modules/chains/foundational/sequential_chains/#simplesequentialchain)
    where chain#1 is used to generate a synopsis for a play and chain#2 is used to
    write a review based on this synopsis.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 文档中有一些很好的例子，例如，你可以在[这里](https://python.langchain.com/en/latest/modules/chains/generic/transformation.html)看到如何组合两个链条，其中链条#1用于清理提示（删除额外空格，缩短提示等），而链条#2用于使用这个干净的提示调用LLM。这里还有[另一个例子](https://js.langchain.com/docs/modules/chains/foundational/sequential_chains/#simplesequentialchain)，其中链条#1用于为一部戏剧生成简介，而链条#2则用于基于此简介撰写评论。
- en: While these are excellent examples, I want to focus on something else. If you
    remember before, I mentioned that chains can be composed of entities other than
    LLMs. More specifically, I am interested in chaining agents and LLMs together.
    *But first, what are agents?*
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些都是很好的例子，但我想专注于其他事情。如果你还记得，我提到链条可以由除了LLM以外的实体组成。更具体地说，我对将代理和LLM组合在一起很感兴趣。*但首先，什么是代理？*
- en: Using agents for dynamically calling LLMs
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用代理动态调用LLM
- en: It will be much easier to explain what an agent does vs. what it is.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对于解释代理的作用与其是什么，将会更加容易。
- en: Say, we want to know the weather forecast for tomorrow. If were to use the simple
    ChatGPT API and give it a prompt `Show me the weather for tomorrow in London`,
    it won’t know the answer because it does not have access to real-time data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想知道明天的天气预报。如果我们使用简单的ChatGPT API并给它一个提示`Show me the weather for tomorrow
    in London`，它不会知道答案，因为它无法访问实时数据。
- en: '![](../Images/a379c0d1313089f343dc25f6510660a3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a379c0d1313089f343dc25f6510660a3.png)'
- en: Wouldn’t it be useful if we had an arrangement where we could utilize an LLM
    for understanding our query (i.e prompt) in natural language and then call the
    weather API on our behalf to fetch the data needed? This is exactly what an agent
    does (amongst other things, of course).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能有一个安排，利用 LLM 理解我们的查询（即提示），然后代表我们调用天气 API 来获取所需数据，那不是很有用吗？这正是代理所做的（当然还有其他事情）。
- en: An agent has access to an LLM and a suite of tools for example Google Search,
    Python REPL, math calculator, weather APIs, etc.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 代理可以访问 LLM 和一套工具，例如 Google 搜索、Python REPL、数学计算器、天气 API 等。
- en: There are quite a few agents that LangChain supports — see [here](https://python.langchain.com/docs/modules/agents/agent_types/)
    for the complete list, but quite frankly the most common one I came across in
    tutorials and YT videos was `zero-shot-react-description`. This agent uses [ReAct](https://arxiv.org/abs/2210.03629)
    (Reason + Act) framework to pick the most usable tool (from a list of tools),
    based on what the input query is.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 支持很多代理——完整列表请见[这里](https://python.langchain.com/docs/modules/agents/agent_types/)，但坦率说，我在教程和
    YouTube 视频中最常见的代理是 `zero-shot-react-description`。这个代理使用了[ReAct](https://arxiv.org/abs/2210.03629)（Reason
    + Act）框架，根据输入查询从工具列表中选择最合适的工具。
- en: '*P.S.:* [*Here’s*](https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/)
    *a nice article that goes in-depth into the ReAct framework.*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*P.S.:* [*这里*](https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/)
    *有一篇深入探讨 ReAct 框架的好文章。*'
- en: Let’s initialize an agent using `initialize_agent` and pass it the `tools` and
    `LLM` it needs. There’s a long list of tools available [here](https://python.langchain.com/docs/integrations/tools/)
    that an agent can use to interact with the outside world. For our example, we
    are using the same math-solving tool as above, called `pal-math`. This one requires
    an LLM at the time of initialization, so we pass to it the same OpenAI LLM instance
    as before.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `initialize_agent` 初始化一个代理，并传递它所需的 `tools` 和 `LLM`。代理可以使用的工具清单可以在[这里](https://python.langchain.com/docs/integrations/tools/)找到。对于我们的例子，我们使用了上面提到的同一个数学解决工具，叫做
    `pal-math`。这个工具在初始化时需要一个 LLM，因此我们传递给它之前相同的 OpenAI LLM 实例。
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Let’s test it out on the same example as above:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在上述相同的例子上测试一下：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*Note 1: At each step, you’ll notice that an agent does one of three things
    — it either has an* `*observation*`*, a* `*thought*`*, or it takes an* `*action*`*.
    This is mainly due to the ReAct framework and the associated prompt that the agent
    is using:*'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意1：在每一步，你会注意到代理做了三件事之一——它要么有一个* `*observation*`*，要么有一个* `*thought*`*，要么采取一个*
    `*action*`*。这主要是由于 ReAct 框架和代理使用的相关提示：*'
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*Note2: You might be wondering what’s the point of getting an agent to do the
    same thing that an LLM can do. Some applications will require not just a predetermined
    chain of calls to LLMs/other tools, but potentially an unknown chain that depends
    on the user’s input [*[*Source*](https://python.langchain.com/en/latest/modules/agents.html#agents)*].
    In these types of chains, there is an “agent” which has access to a suite of tools.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意2：你可能会想，为什么要让代理做 LLM 可以做的事情。一些应用不仅需要一个预定的 LLM/其他工具调用链，可能还需要一个取决于用户输入的未知链
    [*[*来源*](https://python.langchain.com/en/latest/modules/agents.html#agents)*]。在这些类型的链中，有一个“代理”，可以访问一套工具。*'
- en: For instance,* [*here’s*](https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/agent_vectorstore.html#create-the-agent)
    *an example of an agent that can fetch the correct documents (from the vectorstores)
    for* `*RetrievalQAChain*` *depending on whether the question refers to document
    A or document B.*
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，* [*这是*](https://python.langchain.com/en/latest/modules/agents/agent_executors/examples/agent_vectorstore.html#create-the-agent)
    *一个代理的示例，它可以根据问题是指文档 A 还是文档 B，获取正确的文档（从向量存储中）。*
- en: For fun, I tried making the input question more complex (using Demi Moore’s
    age as a placeholder for Dad’s actual age).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有趣，我尝试使输入问题更复杂（用 Demi Moore 的年龄作为 Dad 实际年龄的占位符）。
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Unfortunately, the answer was slightly off as the agent was not using the latest
    age for Demi Moore (since Open AI models were trained on data until 2020). This
    can be easily fixed by including another tool —
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，答案有些偏差，因为代理没有使用最新的 Demi Moore 年龄（由于 OpenAI 模型的训练数据截至到 2020 年）。这可以通过包含另一个工具轻松修复——
- en: '`tools = load_tools([“pal-math”, **"serpapi"**], llm=llm)`. `serpapi` is useful
    for answering questions about current events.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`tools = load_tools([“pal-math”, **"serpapi"**], llm=llm)`。`serpapi` 对于回答当前事件的问题非常有用。'
- en: '*Note: It is important to add as many tools as you think may be relevant to
    the user query. The problem with using a single tool is that the agent keeps trying
    to use the same tool even if it’s not the most relevant for a particular observation/action
    step.*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意: 添加尽可能多的相关工具对用户查询是很重要的。使用单一工具的问题在于，即使它不适用于特定的观察/行动步骤，代理也会继续尝试使用相同的工具。*'
- en: Here’s another example of a tool you can use — `podcast-api`. You need to [get
    your own API key](https://www.listennotes.com/api/pricing/) and plug it into the
    code below.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个你可以使用的工具示例——`podcast-api`。你需要[获取你自己的 API 密钥](https://www.listennotes.com/api/pricing/)并将其插入下面的代码中。
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*Note1: There is a* [*known error*](https://github.com/hwchase17/langchain/pull/1833)
    *with using this API where you might see,* `*openai.error.InvalidRequestError:
    This model’s maximum context length is 4097 tokens, however you requested XXX
    tokens (XX in your prompt; XX for the completion). Please reduce your prompt;
    or completion length.*` *This happens when the response returned by the API might
    be too big. To work around this, the documentation suggests returning fewer search
    results, for example, by updating the question to* `"Show me episodes for money
    saving tips, return only 1 result"`.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意1: 有一个* [*已知错误*](https://github.com/hwchase17/langchain/pull/1833) *，在使用这个
    API 时你可能会看到，`*openai.error.InvalidRequestError: This model’s maximum context length
    is 4097 tokens, however you requested XXX tokens (XX in your prompt; XX for the
    completion). Please reduce your prompt; or completion length.*` *当 API 返回的响应可能过大时会发生这种情况。为了解决这个问题，文档建议返回更少的搜索结果，例如，通过将问题更新为*
    “Show me episodes for money saving tips, return only 1 result”。'
- en: '*Note2: While tinkering around with this tool, I noticed some inconsistencies.
    The responses aren’t always complete the first time around, for instance here
    are the input and responses from two consecutive runs:*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意2: 在使用这个工具时，我注意到了一些不一致的地方。响应第一次生成时并不总是完整的，例如，以下是两次连续运行的输入和响应：*'
- en: '*Input: “Podcasts for getting better at French”*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*输入: “提高法语水平的播客”*'
- en: '*Response 1: “The best podcast for learning French is the one with the highest
    review score.”'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*回应 1: “学习法语的最佳播客是评价分数最高的那个。”*'
- en: 'Response 2: ‘The best podcast for learning French is “FrenchPod101”.*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*回应 2: “学习法语的最佳播客是‘FrenchPod101’。”*'
- en: Under the hood, the tool is first using an LLMChain for [building the API URL](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/base.py#L115)
    based on our input instructions (something along the lines of `[https://listen-api.listennotes.com/api/v2/search?q=french&type=podcast&page_size=3](https://listen-api.listennotes.com/api/v2/search?q=french&type=podcast&page_size=3%29)`[)](https://listen-api.listennotes.com/api/v2/search?q=french&type=podcast&page_size=3%29)
    and [making the API call](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/base.py#L116).
    Upon receiving the response, it uses another LLMChain that [summarizes the response](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/base.py#L117)
    to get the answer to our original question. You can check out the prompts [here](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/prompt.py)
    for both LLMchains which describe the process in more detail.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，这个工具首先使用 LLMChain 来[构建 API URL](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/base.py#L115)，根据我们的输入指令（类似于
    `[https://listen-api.listennotes.com/api/v2/search?q=french&type=podcast&page_size=3](https://listen-api.listennotes.com/api/v2/search?q=french&type=podcast&page_size=3%29)`）和[进行
    API 调用](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/base.py#L116)。接收到响应后，它使用另一个
    LLMChain 来[总结响应](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/base.py#L117)，以获得对我们原始问题的回答。你可以在[这里](https://github.com/hwchase17/langchain/blob/master/langchain/chains/api/prompt.py)查看两个
    LLMchains 的提示，它们详细描述了这个过程。
- en: I am inclined to guess the inconsistent results seen above are resulting from
    the summarization step because I have separately debugged and tested the API URL
    (created by LLMChain#1) via Postman and received the right response. To further
    confirm my doubts, I also stress-tested the summarization chain as a standalone
    chain with an empty API URL hoping it would throw an error but got the response
    *“Investing’ podcasts were found, containing 3 results in total.”* 🤷‍♀ I’d be
    curious to see if others had better luck than me with this tool!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我倾向于猜测上述不一致的结果是由于总结步骤造成的，因为我已经通过Postman单独调试并测试了由LLMChain#1创建的API URL，并且得到了正确的响应。为了进一步确认我的疑虑，我还对总结链进行了压力测试，作为一个独立链使用了一个空的API
    URL，希望它能抛出一个错误，但得到了*“发现了‘投资’播客，总共有3个结果。”* 🤷‍♀ 我很好奇其他人是否在使用这个工具时比我更幸运！
- en: 'Use Case 2: Combine chains to create an age-appropriate gift generator'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例 2：结合链创建一个适合年龄的礼物生成器
- en: 'Let’s put our knowledge of agents and sequential chaining to good use and create
    our own sequential chain. We will combine:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们充分利用代理和顺序链的知识，创建我们自己的顺序链。我们将结合：
- en: 'Chain #1 — The `agent` we just created that can solve [age problems](https://www.cliffsnotes.com/study-guides/algebra/algebra-i/word-problems/age-problems)
    in math.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '链 #1 — 我们刚创建的`agent`，能够解决数学中的[年龄问题](https://www.cliffsnotes.com/study-guides/algebra/algebra-i/word-problems/age-problems)。'
- en: 'Chain #2 — An LLM that takes the age of a person and suggests an appropriate
    gift for them.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '链 #2 — 一个LLM，它接受一个人的年龄并建议一个适合他们的礼物。'
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now that we have both chains ready we can combine them using `SimpleSequentialChain`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了两个链，我们可以使用`SimpleSequentialChain`将它们结合起来。
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'A couple of things to note:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意几点：
- en: We need not explicitly pass `input_variables` and `output_variables` for `SimpleSequentialChain`
    as the underlying assumption is that the output from chain 1 is passed as input
    to chain 2.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不需要为`SimpleSequentialChain`明确传递`input_variables`和`output_variables`，因为其基本假设是链1的输出作为链2的输入。
- en: 'Finally, we can run it with the same math problem as before:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以用之前的数学问题来运行它：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: There might be times when you need to pass along some additional context to
    the second chain, in addition to what it is receiving from the first chain. For
    instance, I want to set a budget for the gift, depending on the age of the person
    that is returned by the first chain. We can do so using `SimpleMemory`.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你可能需要将一些额外的上下文传递给第二个链，而不仅仅是从第一个链接收的内容。例如，我想根据第一个链返回的年龄为礼物设定预算。我们可以使用`SimpleMemory`来实现。
- en: First, let’s update the prompt for `chain_two` and pass to it a second variable
    called `budget` inside `input_variables`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们更新`chain_two`的提示，并在`input_variables`中传递一个名为`budget`的第二个变量。
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If you compare the `template` we had for `SimpleSequentialChain` with the one
    above, you’ll notice that I have also updated the first input’s variable name
    from `age` → `output`. This is a crucial step, failing which an error would be
    raised at the time of [chain validation](https://github.com/hwchase17/langchain/blob/master/langchain/chains/sequential.py#L41)
    — `*Missing required input keys: {age}, only had {input, output, budget}*`.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你比较我们为`SimpleSequentialChain`准备的`template`与上述的模板，你会注意到我还将第一个输入的变量名从`age`更新为`output`。这是一个关键步骤，如果失败，将在[链验证](https://github.com/hwchase17/langchain/blob/master/langchain/chains/sequential.py#L41)时引发错误
    — `*缺少必需的输入键：{age}，只有 {input, output, budget}*`。
- en: This is because the output from the first entity in the chain (i.e. `agent`)
    will be the input for the second entity in the chain (i.e. `chain_two`) and therefore
    the variable names must match**.** Upon inspecting `agent`’s output keys, we see
    that the output variable is called `output`, hence the update.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为链中的第一个实体（即`agent`）的输出将作为第二个实体（即`chain_two`）的输入，因此变量名必须匹配**。** 检查`agent`的输出键时，我们发现输出变量叫做`output`，因此进行了更新。
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Next, let’s update the kind of chain we are making. We can no longer work with
    `SimpleSequentialChain` because it only works in cases where this is a single
    input and single output. Since `chain_two` is now taking two `input_variables`,
    we need to use `SequentialChain` which is tailored to handle multiple inputs and
    outputs.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们更新我们正在制作的链的类型。我们不能再使用`SimpleSequentialChain`，因为它仅适用于单输入单输出的情况。由于`chain_two`现在需要两个`input_variables`，我们需要使用`SequentialChain`，它专门处理多个输入和输出。
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'A couple of things to note:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意几点：
- en: Unlike `SimpleSequentialChain`, passing `input_variables` parameter is mandatory
    for `SequentialChain`. It is a list containing the name of the input variables
    that the first entity in the chain (i.e. `agent` in our case) expects.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与`SimpleSequentialChain`不同，对于`SequentialChain`，传递`input_variables`参数是强制性的。它是一个包含链中第一个实体（即我们案例中的`agent`）期望的输入变量名称的列表。
- en: Now some of you may be wondering how to know the exact name used in the input
    prompt that the `agent` is going to use. We certainly did not write the prompt
    for this agent (as we did for `chain_two`)! It's actually pretty straightforward
    to find it out by inspecting the prompt template of the `llm_chain` that the agent
    is made up of.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，你们中的一些人可能想知道如何知道`agent`将要使用的输入提示中使用的确切名称。我们确实没有为这个`agent`（如我们为`chain_two`所做的那样）编写过提示！事实上，通过检查`llm_chain`的提示模板，找出它其实非常简单。
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see toward the end of the prompt, the questions being asked by the
    end-user is stored in an input variable by the name `input`. If for some reason
    you had to manipulate this name in the prompt, make sure you are also updating
    the `input_variables` at the time of the creation of `SequentialChain`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可以在提示的最后看到的那样，最终用户提出的问题存储在一个名为`input`的输入变量中。如果因某种原因您必须在提示中操纵这个名称，请确保在创建`SequentialChain`时同时更新`input_variables`。
- en: 'Finally, you could have found out the same information without going through
    the whole prompt:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以在不查看整个提示的情况下找到相同的信息：
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`[SimpleMemory](https://github.com/hwchase17/langchain/blob/master/langchain/memory/simple.py#L6)`
    is an easy way to store context or other bits of information that shouldn’t ever
    change between prompts. It requires one parameter at the time of initialization
    — `memories`. You can pass elements to it in `dict` form. For instance, `SimpleMemory(memories={“budget”:
    “100 GBP”})`.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[SimpleMemory](https://github.com/hwchase17/langchain/blob/master/langchain/memory/simple.py#L6)`
    是一种存储上下文或其他信息片段的简便方法，这些信息在提示之间不应更改。它在初始化时需要一个参数 — `memories`。您可以以`dict`形式传递元素给它。例如，`SimpleMemory(memories={“budget”:
    “100 GBP”})`。'
- en: Finally, let’s run the new chain with the same prompt as before. You will notice,
    the final output has some luxury gift recommendations such as weekend getaways
    in accordance with the higher budget in our updated prompt.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们用与之前相同的提示运行新链。您会注意到，最终输出包括一些奢侈礼品推荐，例如周末度假，与我们更新的提示中的更高预算相匹配。
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Conclusion
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Hopefully, the learnings I have shared through this post have made you more
    comfortable in taking a deep dive into the library. This article just scratched
    the surface, there is so much more to cover. For instance, how to build a QnA
    chatbot over your own datasets, and how to optimize memory for these chatbots
    so that you can cherry-pick/summarize conversations to send in the prompt rather
    than sending all previous chat history as part of the prompt.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 希望通过本文分享的学习内容能让您更轻松地深入了解这个库。本文只是皮毛，还有很多内容可以探讨。例如，如何在自己的数据集上构建问答聊天机器人，以及如何优化这些聊天机器人的记忆，以便您可以选择性地/总结性地发送对话，而不是将所有以前的聊天历史作为提示的一部分发送出去。
- en: As always if there’s an easier way to do/explain some of the things mentioned
    in this article, do let me know. In general, refrain from unsolicited destructive/trash/hostile
    comments!
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，如果有更简单的方法来执行/解释本文中提到的一些内容，请告诉我。总的来说，避免未经请求的破坏性/垃圾/敌对的评论！
- en: Until next time ✨
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 直到下次见 ✨
- en: '*I enjoy writing step-by-step beginner’s guides, how-to tutorials, decoding
    terminology used in ML/AI, etc. If you want full access to all my articles (and
    others on Medium), then you can sign up using* [***my link***](https://varshitasher.medium.com/membership)*here****.***'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*我喜欢撰写逐步初学者指南、如何教程、解码ML/AI术语等。如果您希望全面访问我的所有文章（以及Medium上的其他文章），可以使用* [***我的链接***](https://varshitasher.medium.com/membership)*在这里注册*。'
- en: '[](/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf?source=post_page-----16cd385fca81--------------------------------)
    [## Step by step guide to explaining your ML project during a data science interview.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf?source=post_page-----16cd385fca81--------------------------------)
    [## 逐步指南：在数据科学面试中解释您的ML项目。'
- en: With a bonus sample script at the end that lets you show off your tech skills
    discreetly!
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并附带一个示例脚本，让您可以悄悄展示您的技术技能！
- en: towardsdatascience.com](/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf?source=post_page-----16cd385fca81--------------------------------)
    [](/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1?source=post_page-----16cd385fca81--------------------------------)
    [## Time Series Modeling using Scikit, Pandas, and Numpy
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[时间序列建模使用 Scikit、Pandas 和 Numpy](https://towardsdatascience.com/step-by-step-guide-to-explaining-your-ml-project-during-a-data-science-interview-81dfaaa408bf?source=post_page-----16cd385fca81--------------------------------)
    [](/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1?source=post_page-----16cd385fca81--------------------------------)
    [## 时间序列建模使用 Scikit、Pandas 和 Numpy'
- en: Intuitive use of seasonality to improve model accuracy.
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 直观地使用季节性来提高模型准确性。
- en: towardsdatascience.com](/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1?source=post_page-----16cd385fca81--------------------------------)
    [](/hands-on-introduction-to-github-actions-for-data-scientists-f422631c9ea7?source=post_page-----16cd385fca81--------------------------------)
    [## Hands-On Introduction to Github Actions for Data Scientists
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据科学家实用的 GitHub Actions 介绍](https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1?source=post_page-----16cd385fca81--------------------------------)
    [](/hands-on-introduction-to-github-actions-for-data-scientists-f422631c9ea7?source=post_page-----16cd385fca81--------------------------------)
    [## 使用 GitHub Actions 进行动手实践的介绍'
- en: Learn how to automate experiment tracking with Weights & Biases, unit testing,
    artifact creation, and lots more…
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习如何使用 Weights & Biases 自动化实验跟踪、单元测试、工件创建以及更多内容…
- en: 'towardsdatascience.com](/hands-on-introduction-to-github-actions-for-data-scientists-f422631c9ea7?source=post_page-----16cd385fca81--------------------------------)
    [](/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16?source=post_page-----16cd385fca81--------------------------------)
    [## Deploying an End to End Deep Learning Project with few clicks: Part 2'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据科学家实用的 GitHub Actions 介绍](https://towardsdatascience.com/hands-on-introduction-to-github-actions-for-data-scientists-f422631c9ea7?source=post_page-----16cd385fca81--------------------------------)
    [](/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16?source=post_page-----16cd385fca81--------------------------------)
    [## 使用少量点击部署端到端深度学习项目：第2部分'
- en: Taking model from Jupyter notebook to Flask app, testing API endpoint using
    Postman, and Heroku deployment
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将模型从 Jupyter notebook 转移到 Flask 应用程序，使用 Postman 测试 API 端点，并进行 Heroku 部署
- en: towardsdatascience.com](/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16?source=post_page-----16cd385fca81--------------------------------)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[将端到端深度学习项目部署到 Heroku](https://towardsdatascience.com/deploying-an-end-to-end-deep-learning-project-with-few-clicks-part-2-89009cff6f16?source=post_page-----16cd385fca81--------------------------------)'
