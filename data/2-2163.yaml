- en: Two Ways to Download and Access Llama 2 Locally
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 两种本地下载和访问 Llama 2 的方法
- en: 原文：[https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4](https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4](https://towardsdatascience.com/two-ways-to-download-and-access-llama-2-locally-8a432ed232a4)
- en: A step-by-step guide to using Llama 2 on your PC
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在你的 PC 上使用 Llama 2 的逐步指南
- en: '[](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[![Ana
    Bildea, PhD](../Images/60567c2b09bd0be5b25e508905dfe4c6.png)](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    [Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    ·10 min read·Sep 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8a432ed232a4--------------------------------)
    ·10 分钟阅读·2023年9月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8096320260dd4a194856f7b6ae2ee973.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8096320260dd4a194856f7b6ae2ee973.png)'
- en: Image by the author (Dreamstudio)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者（Dreamstudio）
- en: Motivation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: Meta’s latest release, Llama 2, is gaining popularity and is incredibly interesting
    for various use cases. It offers pre-trained and fine-tuned Llama 2 language models
    in different sizes, from 7B to 70B parameters. Llama 2 performs well in various
    tests, like reasoning, coding, proficiency, and knowledge benchmarks, which makes
    it very promising.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Meta 最新发布的 Llama 2 正在获得越来越多的关注，并且对各种使用场景都非常有趣。它提供了不同大小的预训练和微调的 Llama 2 语言模型，从
    7B 到 70B 参数。Llama 2 在推理、编码、能力和知识基准等各种测试中表现良好，这使它非常有前景。
- en: 'In this article, we’ll guide you through the step-by-step process of downloading
    Llama 2 on your PC. You have two options: the official Meta AI website or HuggingFace.
    We’ll also show you how to access it, so you can leverage its powerful capabilities
    for your projects. Let’s dive in!'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将逐步指导你在 PC 上下载 Llama 2 的过程。你有两个选项：官方的 Meta AI 网站或 HuggingFace。我们还会展示如何访问它，以便你可以利用其强大的功能来支持你的项目。让我们开始吧！
- en: Prerequisites
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前提条件
- en: '[Jupyter Notebook](https://jupyter.org/)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Jupyter Notebook](https://jupyter.org/)'
- en: Nvidia T4 Graphics Processing Unit (GPU)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nvidia T4 图形处理单元 (GPU)
- en: Virtual Environment (Virtualenv)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟环境 (Virtualenv)
- en: '[HuggingFace](https://huggingface.co/) account, libraries, & Llama models'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HuggingFace](https://huggingface.co/) 账户、库以及 Llama 模型'
- en: Python 3.10
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.10
- en: What to Consider Before Downloading Locally
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本地下载前需要考虑的事项
- en: Before you download the model to your local machine, consider a few things.
    First, make sure your computer has enough processing power and storage (loading
    a model from an SSD disk is much faster). Second, be prepared for some initial
    setup to get the model running. Lastly, if you’re using this for work, check your
    company’s policies on downloading external software.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型下载到本地机器之前，考虑一些事项。首先，确保你的计算机有足够的处理能力和存储空间（从 SSD 磁盘加载模型要快得多）。其次，准备进行一些初始设置以使模型运行。最后，如果你是出于工作需要使用此模型，请检查公司关于下载外部软件的政策。
- en: Why Download Llama 2 Locally?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要本地下载 Llama 2？
- en: 'There are a few good reasons why you might want to download the model to your
    own computer such as:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能有几个很好的理由希望将模型下载到自己的计算机上，例如：
- en: '**Reduced Latency** By hosting Llama 2 in your environment, you minimize the
    latency associated with API calls to external servers.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少延迟** 通过在你的环境中托管 Llama 2，你可以将与外部服务器的 API 调用相关的延迟降到最低。'
- en: '**Data Privacy** You can keep your private and sensitive information on your
    own ecosystem (on-premise or external cloud provider).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据隐私** 你可以将私人和敏感信息保存在自己的生态系统中（本地或外部云提供商）。'
- en: '**Customization and Control** You have more control over the model. You can
    optimize the configuration of your machine, work on optimization techniques, fine-tune
    the model, and further integrate it into your ecosystem.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定制和控制** 您对模型拥有更多控制权。您可以优化机器的配置，进行优化技术的工作，对模型进行微调，并进一步将其集成到您的生态系统中。'
- en: '**Offline Access** Depending on the use case the model may be hosted in a secure
    environment with no internet connection.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离线访问** 根据使用情况，模型可能托管在没有互联网连接的安全环境中。'
- en: Choosing Where to Get “Llama 2”
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择获取“Llama 2”的来源
- en: Deciding where to get “Llama 2” is your choice based on what works best for
    you. Here are a few things to consider in order to make your choice.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 决定从哪里获取“Llama 2”是基于对您最合适的选择。以下是一些考虑因素，以帮助您做出选择。
- en: 'Meta’s GitHub:'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Meta的GitHub：
- en: When you get “Llama 2” from Meta’s GitHub, you’re getting it directly from the
    source. This gives you access to the newest updates. However, if you encounter
    issues, the community might not be as reactive as the one on HuggingFace. The
    documentation is good, but trying out the examples might need more coding.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当您从Meta的GitHub获取“Llama 2”时，您直接从源头获取。这使您可以访问最新的更新。然而，如果遇到问题，社区可能不会像HuggingFace那样反应迅速。文档很好，但尝试示例可能需要更多编码。
- en: 'Hugging Face:'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face：
- en: Using Hugging Face is easy because it has a user-friendly platform with a reactive
    and strong community to assist you. It is compatible with multiple frameworks
    making it easier to integrate the model into your existing technology stack.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Hugging Face 非常简单，因为它具有用户友好的平台和反应迅速且强大的社区支持。它兼容多个框架，使得将模型集成到现有技术栈中变得更加容易。
- en: Therefore, I will suggest getting the model directly from Meta’s GitHub if you
    are looking for customization and insights, or from Hugging Face for its ease
    of use, community support, and compatibility with various frameworks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果您需要定制和见解，建议直接从Meta的GitHub获取模型；如果需要易用性、社区支持和与各种框架的兼容性，可以选择Hugging Face。
- en: 1️⃣ Download Llama 2 from the Meta website
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1️⃣ 从Meta网站下载Llama 2
- en: 'Step 1: Request download'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：请求下载
- en: 'One option to download the model weights and tokenizer of Llama 2 is the [Meta
    AI website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/).
    Before you can download the model weights and tokenizer you have to read and agree
    to the License Agreement and submit your request by giving your email address.
    Fill in the following information and accept the terms:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下载Llama 2模型权重和分词器的一个选项是[Meta AI网站](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)。在下载模型权重和分词器之前，您必须阅读并同意许可协议，并通过提供您的电子邮件地址提交请求。填写以下信息并接受条款：
- en: '![](../Images/f355ed05cf573afd2cd1008e4a0b33e4.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f355ed05cf573afd2cd1008e4a0b33e4.png)'
- en: Image by the author
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Once your request has been approved, you will be provided with a `signed URL`
    via email.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的请求被批准，您将通过电子邮件收到一个`signed URL`。
- en: 'Just a quick heads up! The link provided for downloading the model weights
    and tokenizer will only be valid for 24 hours and have a limited number of downloads.
    So, if you see any errors like “403: Forbidden,” don’t worry! You can simply request
    a new link by going back to the Meta AI website.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '提个小提醒！提供的下载模型权重和分词器的链接仅在24小时内有效，并且下载次数有限。因此，如果您看到诸如“403: Forbidden”的错误，请不要担心！您可以通过返回Meta
    AI网站请求一个新链接。'
- en: 'Step 2: Get the download.sh script'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2：获取download.sh脚本
- en: 'Before proceeding, ensure that you have both `wget` and `md5sum` installed.
    You find the download.sh script required for model download in [Meta’s GitHub
    repository](https://github.com/facebookresearch/llama.git). Clone the repository
    and go to `llama` directory as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请确保您已经安装了`wget`和`md5sum`。您可以在[Meta的GitHub仓库](https://github.com/facebookresearch/llama.git)找到所需的download.sh脚本。克隆该仓库并按如下方式进入`llama`目录：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Ensure that you give execution permissions to the script by typing the following
    command:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 通过输入以下命令确保您赋予脚本执行权限：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Step 3: Start the download process'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3：启动下载过程
- en: To initiate the download process, you have to run the `download.sh` script.
    Throughout the process, you will be prompted to provide the URL that was sent
    by email as well as the model you want to download.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动下载过程，您需要运行`download.sh`脚本。在此过程中，系统会提示您提供通过电子邮件发送的URL以及您希望下载的模型。
- en: 'You have the option to download two distinct types of models:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择下载两种不同类型的模型：
- en: '***pretrained*** — Llama-2–7b, Llama-2–13b, Llama-2–70b'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***预训练*** — Llama-2–7b, Llama-2–13b, Llama-2–70b'
- en: '***fine-tuned chat*** — Llama-2–7b-chat, Llama-2–13b-chat, Llama-2–70b-chat'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***微调的聊天*** — Llama-2–7b-chat，Llama-2–13b-chat，Llama-2–70b-chat'
- en: In my case, I’ll get Llama-2–7b & Llama-2–7b-chat.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 就我而言，我会获得 Llama-2–7b 和 Llama-2–7b-chat。
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/5657df14b6be6c74df1d12f3360013a6.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5657df14b6be6c74df1d12f3360013a6.png)'
- en: If the download was successful you should find both the tokenizer and the models
    llama-2–7b and llama-2–7b-chat.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果下载成功，你应该能找到分词器和模型 llama-2–7b 及 llama-2–7b-chat。
- en: '![](../Images/19983a212b2f144d840de1e53e655039.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19983a212b2f144d840de1e53e655039.png)'
- en: Image by the author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '**Step 4: Prepare the local environment**'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**步骤 4：准备本地环境**'
- en: 'For optimal isolation, it’s advisable to establish a fresh local environment;
    personally, I use the Conda environment management system for this use case. Let’s
    initiate the creation of a new Conda environment:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得最佳隔离，建议建立一个全新的本地环境；我个人使用 Conda 环境管理系统。让我们开始创建新的 Conda 环境：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Replace `yourenvname` with the name you want to give to the environment, and
    `3.10` with the preferred Python version. After creating the environment, you
    can activate it with:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 用你想要给环境的名称替换 `yourenvname`，用首选的 Python 版本替换 `3.10`。创建环境后，你可以用以下命令激活它：
- en: '[PRE4]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, navigate to the cloned repository and install the needed libraries mentioned
    in the `requirements.txt`
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，导航到克隆的仓库并安装 `requirements.txt` 中提到的所需库。
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here’s one more thing you need to do: install the project package in a way
    that lets you change the code and see the effects right away, without having to
    install it again. To make this happen, run this command:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一件事你需要做：以允许你更改代码并立即查看效果的方式安装项目包，而不必重新安装。要实现这一点，请运行以下命令：
- en: '[PRE6]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now that we’ve prepared everything, let’s go ahead and run the model to see
    what happens.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经准备好了，让我们运行模型看看会发生什么。
- en: 4\. Run inference with `torchrun`
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 使用 `torchrun` 运行推理
- en: Torchrun, a utility in PyTorch, simplifies distributed training by automating
    worker assignments, handling failures, supporting elastic setups, and offering
    features beyond `torch.distributed.launch` including custom entry points, parameter
    passing, and log capture.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Torchrun 是 PyTorch 中的一个工具，通过自动分配工作者、处理故障、支持弹性设置和提供超越 `torch.distributed.launch`
    的功能（包括自定义入口点、参数传递和日志捕获）来简化分布式训练。
- en: 'In the cloned repository you should see two examples: `example_chat_completion.py`and
    `example_text_completion.py.`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在克隆的仓库中，你应该看到两个示例：`example_chat_completion.py` 和 `example_text_completion.py`。
- en: Since both scripts are designed for distributed training, we are required to
    set up a few variables. You can simply export them as below or add them to your
    `.bashrc`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两个脚本都设计用于分布式训练，我们需要设置一些变量。你可以像下面这样简单地导出它们，或将它们添加到 `.bashrc` 中。
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`RANK`: The rank of the current process in the distributed training group.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RANK`：分布式训练组中当前进程的等级。'
- en: '`WORLD_SIZE`: The total number of processes in the distributed group.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WORLD_SIZE`：分布式组中的总进程数。'
- en: '`MASTER_ADDR`: The address of the master node that coordinates the training.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MASTER_ADDR`：协调训练的主节点地址。'
- en: '`MASTER_PORT`: The port number used to communicate with the master node.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MASTER_PORT`：用于与主节点通信的端口号。'
- en: 'To execute `torchrun`, we need to:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行 `torchrun`，我们需要：
- en: define the `nproc-per-node` as the number of available GPUs,
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 `nproc-per-node` 定义为可用的 GPU 数量，
- en: provide the `script.py`,
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供 `script.py`，
- en: indicate the model checkpoint directory via `ckpt_dir`,
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 `ckpt_dir` 指定模型检查点目录，
- en: specify the tokenizer’s path using `tokenizer_path`.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `tokenizer_path` 指定分词器的路径。
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s run `example_text_completion.py` where the initial prompt is :'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行 `example_text_completion.py`，其中初始提示为：
- en: '![](../Images/f1122b768da07bf26d25a4ff783e2d6e.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1122b768da07bf26d25a4ff783e2d6e.png)'
- en: Image by the author
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/592106ab554f61bddbcd56e988247ae1.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/592106ab554f61bddbcd56e988247ae1.png)'
- en: Image by the author
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: And that’s all. You made it! Now you have the option to change the prompt and
    experiment with other models 😃.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。你成功了！现在你可以更改提示并尝试其他模型 😃。
- en: '**A short recap:**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**简短回顾：**'
- en: Visit the **Meta Official Site** and ask for download permission.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 访问 **Meta 官方网站** 并申请下载权限。
- en: ''
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Visit [**the Llama 2 repository**](https://github.com/facebookresearch/llama)
    in GitHub and download the **download.sh** script.
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 访问 [**Llama 2 仓库**](https://github.com/facebookresearch/llama) 在 GitHub 上并下载
    **download.sh** 脚本。
- en: ''
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Execute the download.sh** and provide the signed URL send by email :'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**执行 download.sh** 并提供通过电子邮件发送的签名 URL：'
- en: https://download.llamameta.net/*?YOUR_SIGNED_URL and select the model weights
    to download
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: https://download.llamameta.net/*?YOUR_SIGNED_URL 并选择要下载的模型权重
- en: ''
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Prepapare the environment**'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**准备环境**'
- en: ''
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Run interference** with torchrun'
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**使用 torchrun 进行干预**'
- en: 2️⃣ Download Llama 2 from HuggingFace
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2️⃣ 从 HuggingFace 下载 Llama 2
- en: 'Step 1: Request the download'
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1：请求下载
- en: To begin, make sure you ask for a download on the [Meta AI website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)
    using the exact email address linked to your Hugging Face account. Accept the
    [license terms](https://ai.meta.com/llama/license/) and [acceptable use policy](https://ai.meta.com/llama/use-policy/).
    Once that’s done, you can ask for access to any of the models available on [Hugging
    Face](https://huggingface.co/meta-llama).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，确保你在 [Meta AI 网站](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)
    上用与你的 Hugging Face 帐户关联的确切电子邮件地址请求下载。接受[许可条款](https://ai.meta.com/llama/license/)和[可接受使用政策](https://ai.meta.com/llama/use-policy/)。完成后，你可以申请访问
    [Hugging Face](https://huggingface.co/meta-llama) 上的任何可用模型。
- en: Below you can find the list containing the models that are currently available.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是当前可用模型的列表。
- en: '![](../Images/2bae9ef762dc58f83c6bf7d9a9140975.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2bae9ef762dc58f83c6bf7d9a9140975.png)'
- en: cc. Hugging Face
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: cc. Hugging Face
- en: You’ll receive an email from HuggingFace confirming the grated access.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你将收到来自 HuggingFace 的确认访问许可的电子邮件。
- en: 'Step 2: Get the token from HuggingFace'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2：从 HuggingFace 获取令牌
- en: In case you don’t have a HuggingFace account yet, you will need to create one.
    After creating the account, log in to HuggingFace. Once logged in, locate the
    `Profile` option positioned in the upper right corner and select `Settings`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有 HuggingFace 账户，你需要创建一个。创建账户后，登录 HuggingFace。登录后，找到右上角的`Profile`选项并选择`Settings`。
- en: '![](../Images/de689ce4ccfa73399e2774658b8f29cb.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de689ce4ccfa73399e2774658b8f29cb.png)'
- en: Image by the author
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Choose the `Access Tokens` option and click the `New token` button in order
    to generate the token.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 选择`Access Tokens`选项并点击`New token`按钮以生成令牌。
- en: '![](../Images/64575ff4e6fb9986513ef26906dc9ace.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/64575ff4e6fb9986513ef26906dc9ace.png)'
- en: Image by the author
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Simply copy the token and return to your notebook. In the next step, we’ll see
    how to access and download the model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 只需复制令牌并返回到你的笔记本中。在下一步中，我们将看到如何访问和下载模型。
- en: 'Step 3: Authenticate to HuggingFace'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3：对 HuggingFace 进行身份验证
- en: First, install `huggingface_hub`module developed by Hugging Face that enables
    you to interact with the Hugging Face Model Hub. The hub hosts various pre-trained
    models. Note that`huggingface_hub.login()` requires the `ipywidgets` package.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，安装 Hugging Face 开发的 `huggingface_hub` 模块，它使你能够与 Hugging Face Model Hub 进行交互。该中心托管各种预训练模型。请注意，`huggingface_hub.login()`
    需要 `ipywidgets` 包。
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, import `huggingface_hub` and login to Hugging Face as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，导入 `huggingface_hub` 并按如下方式登录 Hugging Face：
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When you run `huggingface_hub.login()`, you’ll be asked to provide your Hugging
    Face authentication token. Once you’ve successfully authenticated, you can download
    llama models. Paste your token and click login. If authenticated you should see
    the following message.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行 `huggingface_hub.login()` 时，你会被要求提供你的 Hugging Face 身份验证令牌。成功认证后，你可以下载 llama
    模型。粘贴你的令牌并点击登录。如果认证成功，你应该会看到以下消息。
- en: After you’ve been authenticated, you can go ahead and download one of the llama
    models. I will go for `meta-llama/Llama-2–7b-chat-hf` .
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在身份验证通过后，你可以继续下载其中一个 llama 模型。我会选择`meta-llama/Llama-2–7b-chat-hf`。
- en: 'Step 4: Download the Llama 2 Model'
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 4：下载 Llama 2 模型
- en: Begin by installing the needed libraries.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 首先安装所需的库。
- en: 'You can check the GPU available as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按如下方式检查可用的 GPU：
- en: To check your GPU details such as the driver version, CUDA version, GPU name,
    or usage metrics run the command `!nvidia-smi` in a cell.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查你的 GPU 详细信息，如驱动版本、CUDA 版本、GPU 名称或使用指标，请在单元格中运行命令 `!nvidia-smi`。
- en: 'Then, to download the model, we need to import all necessary libraries from
    PyTorch and Hugging Face’s Transformers, initialize the Llama-2–7b chat model
    and its tokenizer, and save them to our disk. Check the following example:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了下载模型，我们需要从 PyTorch 和 Hugging Face 的 Transformers 导入所有必要的库，初始化 Llama-2–7b
    聊天模型及其标记器，并将它们保存到磁盘。请查看以下示例：
- en: Once the cell is executed you should see the models in the `huggingface` directory.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 执行完单元格后，你应该会在`huggingface`目录下看到模型。
- en: Check the directory before moving further. What should be in there?
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步操作之前检查目录。里面应该有什么？
- en: '`config.json`: Think of this as the manual for how your model operates.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`config.json`：将其视为模型操作的手册。'
- en: '`pytorch_model.bin`: This is your model''s brain in PyTorch format.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytorch_model.bin`：这是你的模型在 PyTorch 格式中的“大脑”。'
- en: 'Essential tokenizer files: `special_tokens_map.json` and `tokenizer_config.json`
    are like the dictionaries for your model''s language.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必需的分词器文件：`special_tokens_map.json` 和 `tokenizer_config.json` 就像是你模型语言的词典。
- en: '`tokenizer.model` llama 2 tokenizer'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer.model` Llama 2 分词器'
- en: 'Step 5: Load the Llama 2 model from the disk'
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 5 步：从磁盘加载 Llama 2 模型
- en: In case you have already your Llama 2 models on the disk, you should load them
    first.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经将 Llama 2 模型存储在磁盘上，你应该先加载它们。
- en: 'To do so, you need :'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，你需要：
- en: '`LlamaForCausalLM` which is like the brain of "Llama 2",'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LlamaForCausalLM` 就像是 "Llama 2" 的大脑，'
- en: '`LlamaTokenizer` which helps "Llama 2" understand and break down words.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LlamaTokenizer` 有助于 "Llama 2" 理解和分解单词。'
- en: the path of the models
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的路径
- en: We have reached the last step — testing the interference.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经到了最后一步——测试干预。
- en: 'Step6: Run interference using HuggingFace pipelines'
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 6 步：使用 HuggingFace 管道进行干预
- en: We can assess interference by using the HuggingFace transformers’ pipeline.
    By leveraging pipelines, you can quickly navigate through complex tasks.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用 HuggingFace transformers 的管道来评估干预。利用管道，你可以快速完成复杂任务。
- en: '`text-generation`: Specifies that the pipeline is for generating text.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text-generation`：指定管道用于生成文本。'
- en: '`model`: The pre-trained model you’re using for text generation.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`：你用于文本生成的预训练模型。'
- en: '`tokenizer`: The tokenizer used to process input text and decode model outputs.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tokenizer`：用于处理输入文本和解码模型输出的分词器。'
- en: '`device_map=”auto”`: This attempts to run the model on the best available device
    (e.g., GPU if available, otherwise CPU).'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device_map=”auto”`：这尝试在最佳可用设备上运行模型（例如，若可用则为 GPU，否则为 CPU）。'
- en: '`max_new_tokens=512`: Limits the generated output to 512 tokens.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_new_tokens=512`：限制生成的输出为 512 个标记。'
- en: '`num_return_sequences=1`: Requests only one generated sequence.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_return_sequences=1`：只请求一个生成的序列。'
- en: '`eos_token_id=tokenizer.eos_token_id`: the end-of-sequence token ID.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eos_token_id=tokenizer.eos_token_id`：序列结束标记 ID。'
- en: '*In my case, I wanted a few suggestions for a few rock bands, and the outcome
    is really good.*'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*以我的情况为例，我想要一些摇滚乐队的建议，结果非常好。*'
- en: '![](../Images/1317429912fe58f6b9a5566cdf76a850.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1317429912fe58f6b9a5566cdf76a850.png)'
- en: '**A short recap of downloading Llama from HuggingFace:**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**从 HuggingFace 下载 Llama 的简短回顾：**'
- en: Visit the **Meta Official Site** and ask for download permission.
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 访问**Meta 官方网站**并申请下载权限。
- en: ''
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Get the token from HuggingFace
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从 HuggingFace 获取令牌
- en: ''
  id: totrans-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Authenticate to HuggingFace
  id: totrans-154
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 认证 HuggingFace
- en: ''
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Download the Llama 2 Model
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 下载 Llama 2 模型
- en: ''
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Load the Llama 2 model from the disk
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从磁盘加载 Llama 2 模型
- en: ''
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Run interference using HuggingFace pipelines
  id: totrans-160
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用 HuggingFace 管道进行干预
- en: 'Final thoughts :'
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最后的思考：
- en: In this tutorial, we have seen how to download the Llama 2 models to our local
    PC. You have the option to further enhance the model’s performance by employing
    methods such as quantization, distillation, and other approaches that I will discuss
    in a subsequent article. It’s crucial to execute all these steps within a fresh
    virtual environment. Be sure to monitor the usage of your computer’s memory during
    the process. A lot of weird errors can hide behind memory issues. If you want
    to download a quantized model be aware you may need to downgrade the `bitsandbytes`
    library to 0.39.1
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们已经看到如何将 Llama 2 模型下载到本地 PC。你还可以通过使用量化、蒸馏等方法进一步提升模型的性能，我将在后续文章中讨论这些方法。务必在新的虚拟环境中执行所有这些步骤。在此过程中，请确保监控计算机的内存使用情况。很多奇怪的错误可能隐藏在内存问题后面。如果你想下载量化模型，请注意你可能需要将
    `bitsandbytes` 库降级到 0.39.1
- en: Ever tried clicking the “clap” button on Medium more than once? ❤️
  id: totrans-163
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 曾经尝试在 Medium 上点击“点赞”按钮多次吗？❤️
- en: ''
  id: totrans-164
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Let’s be friends! ✋. Don’t forget to [subscribe](https://medium.com/subscribe/@anna.bildea)!
  id: totrans-165
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 让我们成为朋友吧！✋ 别忘了 [订阅](https://medium.com/subscribe/@anna.bildea)!
- en: ''
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Find me on* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/)
    *&* [*X*](https://twitter.com/AnaBildea)!'
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/ana-bildea-phd-2339b728/) *和*
    [*X*](https://twitter.com/AnaBildea) *找到我！*'
- en: '*If you find my story compelling and wish to show support for my writing, I
    invite you to consider becoming a Medium member, where you can access a vast collection
    of Generative AI, Data Engineering, and Data Science articles.*'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你觉得我的故事很吸引人，并希望支持我的写作，我邀请你考虑成为 Medium 会员，你可以访问大量的生成 AI、数据工程和数据科学文章。*'
- en: '[](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)
    [## Join Medium with my referral link — Bildea Ana'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)
    [## 使用我的推荐链接加入 Medium — Bildea Ana'
- en: As a Medium member, a portion of your membership fee goes to writers you read,
    and you get full access to every story…
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作为 Medium 的会员，你的部分会员费将用于支持你阅读的作者，你也可以完全访问所有故事…
- en: medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[medium.com](https://medium.com/@anna.bildea/membership?source=post_page-----8a432ed232a4--------------------------------)'
- en: See my collection of Generative AI, MLOps, and Responsible AI articles.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 查看我关于生成式人工智能、MLOps 和负责任人工智能的文章合集。
- en: '![Ana Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![Ana Bildea, 博士](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea, 博士](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: Generative AI
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式人工智能
- en: '[View list](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----8a432ed232a4--------------------------------)11
    stories![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@anna.bildea/list/generative-ai-30d313b29b80?source=post_page-----8a432ed232a4--------------------------------)11篇故事![](../Images/df56a4e1a4785f73007a1ba8d1191b78.png)![](../Images/b6a7ab27a61a2cd49de8c07ee38f5999.png)![](../Images/8c3c51cf26b3db2c54205da85ad9fe2e.png)![Ana
    Bildea, 博士](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea, 博士](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: MLOps - AI in Production
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLOps - 人工智能生产
- en: '[View list](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----8a432ed232a4--------------------------------)4
    stories![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)![Ana
    Bildea, PhD](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@anna.bildea/list/mlops-ai-in-production-04b6c81c50c8?source=post_page-----8a432ed232a4--------------------------------)4篇故事![](../Images/8fbedcb9f3f75894caff649172adece1.png)![](../Images/d5014b3b3843fc4b2172bef517cccaa4.png)![](../Images/2dba051abf51711268415c3f1e055a60.png)![Ana
    Bildea, 博士](../Images/acaa243e5f1e9f9254c32b65042c822b.png)'
- en: '[Ana Bildea, PhD](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ana Bildea, 博士](https://medium.com/@anna.bildea?source=post_page-----8a432ed232a4--------------------------------)'
- en: Responsible AI
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的人工智能
- en: '[View list](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----8a432ed232a4--------------------------------)1
    story![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@anna.bildea/list/responsible-ai-10009e82f412?source=post_page-----8a432ed232a4--------------------------------)1篇故事![](../Images/46a362cef2c3ddcc9e9a1134400f8a6d.png)'
