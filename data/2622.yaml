- en: Researching a Multilingual FEMA Disaster Bot Using LangChain and GPT-4
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LangChain 和 GPT-4 研究多语言 FEMA 灾难机器人
- en: 原文：[https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17](https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17](https://towardsdatascience.com/researching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd?source=collection_archive---------5-----------------------#2023-08-17)
- en: Some pros and cons of Retrieval-Augmented Generation (RAG) for high-risk chat
    applications
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高风险聊天应用程序中检索增强生成（RAG）的优缺点
- en: '[](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----4591f26d8dcd--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----4591f26d8dcd---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    ·54 min read·Aug 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----4591f26d8dcd---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----4591f26d8dcd---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4591f26d8dcd--------------------------------)
    ·54分钟阅读·2023年8月17日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----4591f26d8dcd---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&source=-----4591f26d8dcd---------------------bookmark_footer-----------)![](../Images/37138d88da2ef33806c505f6c3bcb47e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4591f26d8dcd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fresearching-a-multilingual-fema-disaster-bot-using-langchain-and-gpt-4-4591f26d8dcd&source=-----4591f26d8dcd---------------------bookmark_footer-----------)![](../Images/37138d88da2ef33806c505f6c3bcb47e.png)'
- en: Image generated by [DALL-E2](https://openai.com/dall-e-2) using prompt “A photo
    of a raging river flooding around a robot”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [DALL-E2](https://openai.com/dall-e-2) 使用提示“一个激流围绕一个机器人泛滥的照片”生成
- en: '*TL;DR*'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*简要概述*'
- en: '*In this article, we explore how to build a multilingual* [*US Federal Emergency
    Management Agency (FEMA)*](https://www.fema.gov/about) *disaster chatbot to help
    people prepare for and survive disasters such as floods, tornados, wildfires,
    earthquakes, and winter storms. A chat interface was created from 34 FEMA PDF
    documents using LangChain and GPT-4\. As amazing as this popular pattern is, care
    is needed with high-risk applications such as disaster response bots. Though Large
    Language Model (LLM) hallucinations are minimized, common issues with semantic
    search of documents can lead to critical information being excluded in chat responses.
    We tested a few simple techniques to improve performance for this specific analysis,
    such as incorporating document metadata into embeddings, enriching user questions
    with LLM zero-shot context classification, and automatic language detection and
    translation using Google Translate to better support languages like Swahili. The
    techniques applied were pretty basic, but the ability of the prototype bot to
    surface information efficiently from FEMA PDF documents shows promise. Obviously,
    testing and validation would be needed if using this technique for high-risk situations,
    ideally using automated LLM techniques to create question-and-answer validation
    data.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*在本文中，我们探讨了如何构建一个多语言的* [*美国联邦应急管理局 (FEMA)*](https://www.fema.gov/about) *灾难聊天机器人，以帮助人们准备和应对诸如洪水、龙卷风、野火、地震和冬季风暴等灾难。我们使用
    LangChain 和 GPT-4 从 34 个 FEMA PDF 文档中创建了一个聊天界面。尽管这种流行模式非常令人惊叹，但在高风险应用如灾难响应机器人中仍需谨慎。虽然大语言模型
    (LLM) 的幻觉现象已被最小化，但文档的语义搜索常见问题可能导致聊天响应中遗漏关键信息。我们测试了一些简单的技术来提高这种特定分析的性能，比如将文档元数据纳入嵌入、通过
    LLM 零样本上下文分类丰富用户问题，以及使用谷歌翻译进行自动语言检测和翻译，以更好地支持像斯瓦希里语这样的语言。应用的技术非常基础，但原型机器人的信息提取能力从
    FEMA PDF 文档中显示了希望。显然，如果将这种技术用于高风险情况，需进行测试和验证，理想情况下使用自动化的 LLM 技术创建问答验证数据。*'
- en: A few weeks ago we had a major flooding event in Vermont. The small brook that
    gurgles cheerfully past our house turned into a raging monster hellbent on destruction.
    Luckily we weren’t damaged badly, but sadly, many lost property and livelihoods.
    At one point during the flood, it looked like we might have to evacuate so I started
    checking the [US Federal Emergency Management Agency (FEMA)](https://www.fema.gov/about)
    website for advice. I had already prepared somewhat, but when trouble arrived
    I wanted to reconfirm a few things. FEMA has really excellent, concise resources
    in PDF documents and web pages which I started searching, but I wondered ...
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 几周前，我们在佛蒙特州经历了一次严重的洪水事件。流经我们房子的那条小溪变成了一个愤怒的怪物，狂暴地破坏一切。幸运的是，我们没有受到严重损害，但遗憾的是，许多人失去了财产和生计。在洪水的某个时刻，看起来我们可能需要撤离，于是我开始查看
    [美国联邦应急管理局 (FEMA)](https://www.fema.gov/about) 网站上的建议。我已经有了一些准备，但当麻烦来临时，我想重新确认一些事情。FEMA
    的 PDF 文档和网页资源非常优秀且简明，我开始搜索，但我在想……
- en: '***In an emergency, is there a faster way to get helpful information that doesn’t
    require searching and reading multiple documents?***'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***在紧急情况下，有没有比搜索和阅读多个文档更快的方法来获取有用信息？***'
- en: One obvious solution might be to ask a chatbot. I think chatbots can get a bit
    overused at times, but this does seem like a solid use case as a conversational
    interface can be more efficient when time is of the essence.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个明显的解决方案可能是询问聊天机器人。我认为聊天机器人有时可能会被过度使用，但在时间紧迫的情况下，这确实是一个很好的应用场景，因为对话界面可能更为高效。
- en: It is not a new idea, organisations such as the American Red Cross have developed
    bots like [Clara](https://www.redcross.org/get-help/disaster-relief-and-recovery-services/meet-clara.html)
    for disaster response. However, a promising new pattern has recently emerged to
    use Generative AI Large Language Models (LLMs) such as [OpenAI’s GPT-4](https://openai.com/research/gpt-4),
    [Meta’s LLAMA 2](https://ai.meta.com/llama/), and a growing plethora of models
    on [HuggingFace](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).
    These models can be used to index a specified set of documents and interact with
    them conversationally. [Called Retrieval-Augmented Generation (RAG)](https://huggingface.co/blog/ray-rag),
    there are hundreds of tutorials on the web demonstrating it with the amazing [LangChain](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)
    Python package and I fully expect this technique to appear soon in software we
    use every day. What’s interesting is that it restricts responses to the provided
    content and so is less prone to hallucinations which can prevent using LLMs in
    critical situations such as disaster response.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是一个新想法，像美国红十字会这样的组织已经开发了类似于[Clara](https://www.redcross.org/get-help/disaster-relief-and-recovery-services/meet-clara.html)的灾害响应机器人。然而，最近出现了一种有前景的新模式，利用生成式人工智能大型语言模型（LLMs），如[OpenAI的GPT-4](https://openai.com/research/gpt-4)、[Meta的LLAMA
    2](https://ai.meta.com/llama/)以及在[HuggingFace](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)上不断增长的众多模型。这些模型可以用来索引指定的文档集，并与其进行对话。[这种方法称为检索增强生成（RAG）](https://huggingface.co/blog/ray-rag)，网上有数百个教程展示了使用令人惊叹的[LangChain](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)
    Python 包，我完全预期这种技术很快会出现在我们每天使用的软件中。有趣的是，它将响应限制在提供的内容范围内，从而减少了幻觉的发生，这有助于在灾害响应等关键情况下使用LLMs。
- en: But how safe is it in cases where the information retrieved might save lives?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但在信息检索可能拯救生命的情况下，这种方法的安全性如何呢？
- en: In this article, I briefly explore creating a LangChain GPT-4 chat interface
    for asking questions about disaster safety based on a set of documents from the
    [US Federal Emergency Management Agency (FEMA)](https://www.fema.gov/about). We
    will encounter some of the limitations that need to be considered if using this
    technique in high-risk situations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我简要探讨了创建一个LangChain GPT-4聊天界面，用于基于[美国联邦应急管理署（FEMA）](https://www.fema.gov/about)的一组文档询问有关灾害安全的问题。我们将遇到一些需要考虑的限制，如果在高风险情况下使用这种技术的话。
- en: FEMA Disaster Preparation and Safety PDF Documents
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FEMA灾害准备和安全PDF文档
- en: For this study, I downloaded 34 PDFs from FEMA (listed [here](https://github.com/datakind/stay_safe_bot/blob/main/docs_data/fema_docs.csv))
    which cover a wide range of disaster-related topics for preparing and reacting
    to emergencies such as wildfires, tornadoes, floods, earthquakes, and winter storms.
    This isn’t the full set of amazing resources FEMA offer, but should suffice to
    test our chat interface.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这项研究，我从FEMA下载了34个PDF文件（[列表在这里](https://github.com/datakind/stay_safe_bot/blob/main/docs_data/fema_docs.csv)），这些文件涵盖了广泛的灾害相关话题，包括如何准备和应对野火、龙卷风、洪水、地震和冬季风暴。这不是FEMA提供的所有惊人资源，但应该足够测试我们的聊天界面。
- en: Indexing Documents For Information Retrieval
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引文档以进行信息检索
- en: Once downloaded, we can use LangChain to read the PDF documents. Documents are
    split into chunks of text, and each is given a fingerprint (embeddings) using
    an embedding model. In this analysis, we will use [OpenAI’s embeddings](https://platform.openai.com/docs/guides/embeddings),
    but LangChain supports [many others](https://python.langchain.com/docs/integrations/text_embedding/).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下载后，我们可以使用LangChain读取PDF文档。文档被分割成文本块，并使用嵌入模型给每个块分配一个指纹（嵌入）。在这项分析中，我们将使用[OpenAI的嵌入](https://platform.openai.com/docs/guides/embeddings)，但LangChain支持[许多其他模型](https://python.langchain.com/docs/integrations/text_embedding/)。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Looking at data extracted for one document [https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)
    …
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 查看为一个文档提取的数据[https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)
    …
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can see that it has split the document by page. As it happens this is not
    an unreasonable approach for the FEMA documents we are processing, which are very
    concise guides where each page is a discrete topic, but for other applications,
    it is usually better to split text at a more granular level using [LangChain’s
    text_splitter](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到它按页面拆分了文档。实际上，这对于我们正在处理的 FEMA 文档并非不合理，这些文档非常简洁，每页都是一个独立的主题，但对于其他应用，通常更好的是在更细的级别拆分文本，使用[LangChain
    的 text_splitter](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)。
- en: We can now use our text excerpts to create a database of embeddings …
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用我们的文本摘录来创建嵌入数据库...
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have chosen a simple option to persist the embeddings to the file system,
    but it’s worth noting that [Chroma supports more options](https://python.langchain.com/docs/integrations/vectorstores/chroma)
    should you have a large number of documents, where performance may be an issue.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了一个简单的选项将嵌入持久化到文件系统，但值得注意的是，[Chroma 支持更多选项](https://python.langchain.com/docs/integrations/vectorstores/chroma)，如果你有大量文档，性能可能是一个问题。
- en: Setting up our conversational interface
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置我们的对话界面
- en: We will use just one PDF to start with so it’s easier to verify results …
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用一个 PDF，这样更容易验证结果...
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the above, we have chosen GPT-4 for the chat model where the API key was
    defined in a `.env` file with variable `OPENAI_API_KEY.` LangChain offers support
    for [many other](https://python.langchain.com/docs/integrations/chat/) models
    also.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述内容中，我们选择了 GPT-4 作为聊天模型，其中 API 密钥在 `.env` 文件中定义，变量为 `OPENAI_API_KEY`。LangChain
    还支持[许多其他](https://python.langchain.com/docs/integrations/chat/)模型。
- en: With just a few lines of code, we have set up a conversational interface onto
    a set of documents, which includes all the power of LLMs. I have developed chatbots
    over the years and can say that this concise pattern reduces a LOT of complexity.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几行代码，我们就建立了一个对文档的对话界面，这包括了 LLM 的所有功能。我多年来开发了聊天机器人，可以说这种简洁的模式大大减少了复杂性。
- en: Kudos to the amazing LangChain package!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对出色的 LangChain 包致以赞誉！
- en: Asking our first question
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提出我们的第一个问题
- en: Since we would also like to see the documents referenced in order to validate
    chat responses, we need to make a slight adjustment to a LangChain method in order
    to account for an issue when retrieving matched documents when also using chat
    memory (The solution was suggested [here](https://github.com/langchain-ai/langchain/issues/2256#issuecomment-1665188576))
    ...
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们还希望查看引用的文档以验证聊天响应，我们需要对 LangChain 方法进行一些调整，以解决在使用聊天记忆时检索匹配文档时出现的问题（解决方案已在[这里](https://github.com/langchain-ai/langchain/issues/2256#issuecomment-1665188576)建议）...
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: OK, now we are ready to ask a question about our one PDF document!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们准备好对我们的一个 PDF 文档提问了！
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: That seems very reasonable, let’s see what content was used to generate this
    summary …
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎很合理，让我们看看用于生成此摘要的内容...
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The answer *looks* great and has summarized brilliantly the excerpts that were
    matched. However, it seems to have missed a page in the [source document](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf).
    This PDF is a short document where **everything** in it is relevant to flood preparation,
    so losing pages is actually significant.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 答案*看起来*很棒，并且出色地总结了匹配的摘录。然而，它似乎遗漏了 [源文档](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)中的一页。这个
    PDF 是一个简短的文档，其中**所有内容**都与洪水准备有关，因此遗漏页面实际上是很重要的。
- en: It goes to show that blindly accepting LLM patterns on the web may give amazing-looking
    results, but work is needed to make them truly useful.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，盲目接受网络上的 LLM 模式可能会得到看起来很棒的结果，但需要进行工作才能使其真正有用。
- en: Document Context (Metadata) Can Be Important
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文档上下文（元数据）可能很重要
- en: For this scenario, we have a document that relates to one topic, flooding, even
    if individual text sections might not mention it explicitly. We might get better
    results if we provide some context with each text excerpt, ie some document metadata.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们有一个与一个主题相关的文档，即洪水，即使个别文本部分可能没有明确提到它。如果我们在每个文本摘录中提供一些上下文，即一些文档元数据，可能会获得更好的结果。
- en: For our simple test, let’s try prefixing all text excerpts with the filename
    (fema-protect-your-home-flooding.pdf) with punctuation and suffix removed, plus
    a text saying “This snippet relates to”. The final prefix will be “This snippet
    relates to fema protect your home flooding:”, which provides the LLM a bit more
    context …
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的简单测试，试着将所有文本摘录前缀加上文件名（fema-protect-your-home-flooding.pdf），去掉标点和后缀，再加上“此摘录相关于”这段文字。最终前缀将是“此摘录相关于
    fema protect your home flooding:”，这为LLM提供了更多的背景信息……
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Bingo! That does now seem to have captured the important pages from the PDF
    and summarized them nicely. Obviously, a very crude approach, a more formal method
    using metadata instead of just the filename would be better. It might also be
    more elegant to [use a template](https://github.com/langchain-ai/langchain/issues/1136)
    rather than just prefixing, but it does illustrate how a little context like this
    can help.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 成功了！这似乎确实捕获了PDF中的重要页面，并很好地总结了它们。显然，这是一种非常粗略的方法，使用元数据而不仅仅是文件名的更正式方法会更好。使用[模板](https://github.com/langchain-ai/langchain/issues/1136)可能也更优雅，而不仅仅是前缀，但它确实展示了这样一点背景如何帮助。
- en: What about if we now use all documents in our set …
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如果我们现在使用所有文档集中的文档呢……
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: That’s done a great job, it surfaced information from our key articles in [https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf),
    plus an article from [https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf](https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf),
    the only other document in the set which mentions flooding.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 做得很好，它从[https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf](https://www.fema.gov/sites/default/files/2020-11/fema_protect-your-home_flooding.pdf)中的关键文章提取了信息，还包括[https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf](https://www.fema.gov/sites/default/files/documents/fema_protect-your-property-storm-surge.pdf)中的一篇文章，这是文档集中唯一提到洪水的其他文档。
- en: Retrieval Prompt Length
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检索提示长度
- en: At this point, it’s worth noting that the final summarization prompt which turns
    document excerpts into a nice answer can be quite long depending on the size and
    number of excerpts. A continual battle with LLMs is to achieve our goals without
    breaching token limits. Though it hasn’t had a significant effect for our use
    case, other scenarios might need to employ [contextual compression methods](https://blog.langchain.dev/improving-document-retrieval-with-contextual-compression/).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，需要注意的是，最终的总结提示将文档摘录转化为漂亮的答案可能会相当长，具体取决于摘录的大小和数量。与LLM的持续战斗是实现我们的目标而不超出令牌限制。尽管对我们的用例没有重大影响，但其他场景可能需要采用[上下文压缩方法](https://blog.langchain.dev/improving-document-retrieval-with-contextual-compression/)。
- en: Question Context Can Be Important
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题背景可能很重要
- en: We intentionally mixed documents related to (i) **planning** for disasters,
    and (ii) **reacting immediately** to dangerous events. This can result in confusing
    responses that mix both contexts …
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们故意混合了与（i）**灾害规划**和（ii）**立即反应**相关的文档。这可能会导致混淆的响应，将两种背景混合在一起……
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The answer is now a bit of a mixed bag, with some points relating to immediate
    action “Move your car to higher ground” and some to preparation “Purchase flood
    insurance”. When people are stressed during an emergency, they probably aren’t
    thinking of prompt engineering and so we can expect slightly ambiguous inputs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的答案有点混乱，有些点涉及立即行动“将你的车移到高地”，有些点涉及准备“购买洪水保险”。当人们在紧急情况下感到压力时，他们可能不会考虑即时工程，因此我们可以期待稍微模糊的输入。
- en: We could of course solve this problem by using more document metadata to split
    into sub-groups, but this requires work if that metadata is not available. Another
    option is to provide more context to the question to indicate if the user is interested
    in disaster preparation, or needs help immediately. We could build a classifier
    for this, but in these days of powerful LLMs let’s use zero-shot classification
    with GPT-4 …
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以通过使用更多的文档元数据来将其拆分为子组来解决此问题，但如果没有这些元数据，则需要工作。另一种选择是向问题提供更多背景，以指示用户是否对灾害准备感兴趣，或需要立即帮助。我们可以为此建立一个分类器，但在这些强大的LLM时代，我们可以使用GPT-4的零样本分类……
- en: '[PRE16]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Nice! With very minimal effort, we can easily determine whether a question relates
    to planning or taking immediate action.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！只需很少的努力，我们就可以轻松确定问题是涉及规划还是立即行动。
- en: We can now prefix the user question with this …
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以用这个前缀来前置用户问题……
- en: '[PRE18]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Which gives …
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这给……
- en: '[PRE19]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Great, worked nicely and didn’t try to sell us any insurance, it gave advice
    that could be acted upon immediately.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，效果很好，没有试图推销任何保险，给出的建议可以立即付诸实践。
- en: Let’s test the converse …
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下反向情况…
- en: '[PRE20]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Perfect, it provided forest fire preparation information.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 完美，它提供了森林火灾准备信息。
- en: Obviously, this would need a lot of testing for anything high-risk that could
    be used in a real emergency, but it illustrates one way we can enhance performance
    by enriching the user’s prompt.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这需要对任何高风险的真实紧急情况进行大量测试，但它说明了我们可以通过丰富用户的提示来提升性能的一种方法。
- en: Making Sure Answers Only Come from the Provided Documents
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保答案仅来自提供的文档
- en: For an application where the information can affect safety, it’s important that
    the information presented *only* comes from the documents provided. Hallucinations
    containing incorrect information could have some really dire effects.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个信息可能影响安全性的应用程序，确保提供的信息*仅*来自提供的文档是非常重要的。包含错误信息的幻觉可能会产生非常严重的后果。
- en: Let’s try asking something totally unrelated to disasters …
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试问一些与灾难完全无关的问题…
- en: '[PRE22]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Which gives …
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这会提供…
- en: '[PRE23]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Though I am a bit sad not finding out how to make some yummy cake, LangChain
    took care of this scenario nicely and determines that the question does not relate
    to the information in the PDF guides provided.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我有点遗憾没能找到如何做一些美味的蛋糕，但 LangChain 很好地处理了这个场景，并判断出问题与提供的 PDF 指南中的信息无关。
- en: That’s good, no major hallucinations! The last thing I’d want in a disaster
    is to be told to make a sponge cake and fly a spaceship or something. 😊
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，没有重大幻觉！在灾难中，我最不希望的就是被告知去做海绵蛋糕或飞宇宙飞船之类的事。😊
- en: Conversation History
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对话历史
- en: One great feature of LangChain is that it seamlessly takes care of conversation
    history. With one line of code, the model can pick up on previous questions …
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 的一个很棒的功能是它无缝地处理对话历史。只需一行代码，模型就能拾起之前的问题…
- en: '[PRE24]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Then ask it a question referring to ‘It’ (the hurricane) …
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然后问它一个指向“它”（飓风）的提问…
- en: '[PRE25]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Perfect, it maintains a history and knows what I’m referring to. Under pressure,
    one might expect a user to ask follow-up questions, so this ability — implemented
    with 2 lines of code! — is very important.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 完美，它保持了历史记录，并知道我在指什么。在压力下，用户可能会提出后续问题，因此这种能力——用 2 行代码实现！——是非常重要的。
- en: Translation
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 翻译
- en: To make the chatbot more versatile, we can explore multilingual support. Many
    major LLMs such as [GPT-4 offer native support for top languages](https://openai.com/research/gpt-4),
    but performance can vary depending on the language.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使聊天机器人更加多功能，我们可以探索多语言支持。许多主要的 LLM，如 [GPT-4 提供了对主要语言的本地支持](https://openai.com/research/gpt-4)，但性能可能会因语言而异。
- en: Let’s start with Portuguese …
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从葡萄牙语开始…
- en: '[PRE26]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Which is the right information. However, with Swahili …
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 哪个信息是正确的。然而，对于斯瓦希里语…
- en: '[PRE28]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The results *look* very plausible but are missing important information. Text
    excerpts matched are missing some key flood sections and we also have snippets
    related to wildfires when we asked about floods. Basically, using embeddings created
    from English documents with Swahili questions doesn’t perform well. Not unreasonable,
    though it did work well for a Latin language Portuguese.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 结果*看起来*非常可信，但缺少重要信息。匹配的文本摘录缺少一些关键的洪水部分，当我们询问洪水时，还得到了与野火相关的片段。基本上，使用从英语文档创建的嵌入来处理斯瓦希里语问题效果不好。不过，使用拉丁语言的葡萄牙语效果很好，这并不令人意外。
- en: Perhaps a more robust approach would be to first detect language and translate
    it into English with [Google Translate](https://translate.google.com/), then convert
    the response back into the prompt language.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 也许更稳健的方法是先检测语言，再用 [Google Translate](https://translate.google.com/) 将其翻译成英语，然后将响应转换回提示语言。
- en: Let’s add this to our chat interface …
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个添加到我们的聊天界面中…
- en: '[PRE30]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Much better, using Google Translate to translate Swahili automatically to English
    and then translating the answer back to Swahili gives us all the required information
    from our set of PDFs. For a risk-critical use-case like disaster response, this
    would need a LOT of testing with native speakers to ensure safety of course, but
    it shows promise towards being multilingual.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 更好，使用 Google Translate 将斯瓦希里语自动翻译成英语，然后将回答翻译回斯瓦希里语，能从我们的 PDF 文件集中获得所有所需的信息。对于灾难响应等风险关键的用例，当然需要与母语者进行大量测试以确保安全，但这在多语言支持方面显示出了前景。
- en: Asking a Wider Set of Questions
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提出更广泛的问题
- en: OK, let’s take the final version for a spin and ask more disaster-related questions
    …
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们试用一下最终版本，提出更多与灾难相关的问题……
- en: '[PRE32]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: I think those are pretty amazing, spot checking a few and they seem to capture
    key content in the PDF documents used.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这些非常惊人，抽查了一些，它们似乎能够捕捉到所用PDF文档中的关键信息。
- en: '[ Based on the above, my disaster kit now has Ear plugs! ]'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[基于上述内容，我的灾难包现在有耳塞了！]'
- en: Evaluating Performance
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能评估
- en: In this analysis, we have only spot-checked how well our chat interface is returning
    critical information for a small set of FEMA PDF documents. This is good to illustrate
    some concepts, but for a production application, we would need something better
    than spot-checking. Luckily, LangChain has provided a set of [evaluators](https://python.langchain.com/docs/guides/evaluation/),
    and of particular interest is a [Streamlit application](https://blog.langchain.dev/auto-eval-of-question-answering-tasks/)
    that generates question-answer pairs automatically and then uses these to evaluate
    retrieval chains, allowing developers to experiment with some of the parameters
    involved. I haven’t yet tried this yet, but the idea of generating evaluation
    data automatically using LLMs seems a great way to build scaffolding for a more
    systematic approach for testing our FEMA disaster bot.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项分析中，我们仅仅对我们的聊天界面在返回一小部分FEMA PDF文档的关键信息方面进行了抽查。这对于说明一些概念是有帮助的，但对于生产应用程序，我们需要比抽查更好的方法。幸运的是，LangChain
    提供了一组[评估工具](https://python.langchain.com/docs/guides/evaluation/)，特别值得关注的是一个[Streamlit
    应用](https://blog.langchain.dev/auto-eval-of-question-answering-tasks/)，它可以自动生成问答对，然后利用这些数据来评估检索链，从而允许开发者实验一些相关的参数。我还没有尝试过，但使用LLM自动生成评估数据的想法似乎是为测试我们的FEMA灾难机器人构建更系统化方法的好办法。
- en: Conclusions
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Using a set of 34 PDF documents on the FEMA website, we were easily able to
    build a multilingual conversational interface using LangChain and GPT-4 that was
    able to answer a wide range of questions related to disaster preparedness and
    safety protocols. However, using this common document retrieval LangChain pattern
    for a high-risk safety critical chatbot faces the same challenges as found with
    semantic search. Even with advanced LLM embeddings capturing more nuance in natural
    language, it’s still quite easy to *lose* important content.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用FEMA网站上的34份PDF文档，我们能够轻松地构建一个多语言对话界面，使用LangChain和GPT-4，能够回答广泛的灾难准备和安全协议相关的问题。然而，对于高风险安全关键的聊天机器人，使用这种通用文档检索的LangChain模式面临着与语义搜索相同的挑战。即使使用先进的LLM嵌入捕捉自然语言中的更多细微差别，仍然很容易*丢失*重要内容。
- en: 'For our FEMA disaster bot use case, this was due to:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的FEMA灾难机器人用例，这种情况是由于：
- en: '**Mixed context documents** — Without including document metadata, responses
    mixed information from different contexts. Simply prefixing document names improved
    performance for our scenario, and more sophisticated metadata strategies could
    be applied. Also, adding a zero-shot LLM classifier to enrich the user question
    was helpful.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合上下文文档** — 在没有包含文档元数据的情况下，响应混合了来自不同上下文的信息。简单地在文档名称前加前缀提高了我们场景中的性能，并且可以应用更复杂的元数据策略。此外，添加一个零样本LLM分类器来丰富用户问题也是有帮助的。'
- en: '**Underrepresented languages in LLMs** —Relying on LLM translation can result
    in poor performance for less well-represented languages such as Swahili. Adding
    automatic Google translation improved performance for our use case.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMs中的低代表性语言** — 依赖LLM翻译可能会导致对于代表性较少的语言（如斯瓦希里语）性能较差。添加自动Google翻译提高了我们用例中的性能。'
- en: We explored crude methods to address the above issues, but for a production
    chatbot, more advanced techniques and other mitigation found through testing and
    validation would be required.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索了粗略的方法来解决上述问题，但对于生产聊天机器人，需要通过测试和验证找到更先进的技术和其他缓解措施。
- en: Still though, pretty amazing what LLMs can do these days!
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，LLM现在能做的事情确实令人惊叹！
- en: '**References**'
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**参考资料**'
- en: You can find a notebook with all code [here](https://github.com/datakind/stay_safe_bot).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://github.com/datakind/stay_safe_bot)找到包含所有代码的笔记本。
