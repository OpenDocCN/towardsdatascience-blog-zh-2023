- en: 'From Evaluation to Enlightenment: Delving into Out-of-Sample Predictions in
    Cross-Validation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从评估到启示：深入了解交叉验证中的样本外预测
- en: 原文：[https://towardsdatascience.com/from-evaluation-to-enlightenment-delving-into-out-of-sample-predictions-in-cross-validation-2db0850463c8](https://towardsdatascience.com/from-evaluation-to-enlightenment-delving-into-out-of-sample-predictions-in-cross-validation-2db0850463c8)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/from-evaluation-to-enlightenment-delving-into-out-of-sample-predictions-in-cross-validation-2db0850463c8](https://towardsdatascience.com/from-evaluation-to-enlightenment-delving-into-out-of-sample-predictions-in-cross-validation-2db0850463c8)
- en: Uncovering Insights and Overcoming Limitations through Out-of-Fold Predictions.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过折叠外预测揭示洞察和克服局限性。
- en: '[](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)[![Ning
    Jia](../Images/46382d350365292176be9b59ebf3061f.png)](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2db0850463c8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2db0850463c8--------------------------------)
    [Ning Jia](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)[![宁佳](../Images/46382d350365292176be9b59ebf3061f.png)](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2db0850463c8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2db0850463c8--------------------------------)
    [宁佳](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2db0850463c8--------------------------------)
    ·6 min read·Jun 28, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2db0850463c8--------------------------------)
    ·6 分钟阅读·2023年6月28日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: Understanding cross-validation and applying it in practical daily work is a
    must-have skill for every data scientist. While the primary purpose of cross-validation
    is to assess model performance and fine-tune hyperparameters, it offers additional
    outputs that should be noticed. By obtaining and combining predictions for each
    fold, we can generate model predictions for the entire training set, commonly
    known as **out-of-sample or out-of-fold predictions**.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 理解交叉验证并将其应用于实际工作是每个数据科学家的必备技能。虽然交叉验证的主要目的是评估模型性能和微调超参数，但它还提供了额外的输出值得注意。通过获取和结合每个折叠的预测，我们可以生成整个训练集的模型预测，这通常被称为**样本外预测或折叠外预测**。
- en: It is crucial not to dismiss these predictions, as they hold a wealth of valuable
    information about the modelling approach and the dataset itself. By thoroughly
    exploring them, you may uncover answers to questions such as why the model is
    not working as expected, how to enhance feature engineering, and whether there
    are any inherent limitations within the data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 不应忽视这些预测，因为它们包含了关于建模方法和数据集本身的宝贵信息。通过深入探索这些预测，你可能会发现诸如模型为何无法按预期工作、如何提升特征工程、以及数据中是否存在固有的局限性等问题的答案。
- en: 'The general approach is straightforward: investigate the samples where the
    model exhibits high confidence but makes mistakes. In the post, I will show how
    these predictions help me in three real-world projects.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 总体方法很简单：调查模型在高置信度下却犯错误的样本。在本文中，我将展示这些预测如何帮助我在三个实际项目中。
- en: Finding data limitations
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找数据局限性
- en: I worked on a predictive maintenance project where the goal was to predict vehicle
    failures in advance. One of the approaches I explored was training a binary classifier.
    It was a relatively simple and direct method.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾参与一个预测性维护项目，其目标是提前预测车辆故障。我探索的一种方法是训练一个二分类器。这是一种相对简单直接的方法。
- en: After training using time series cross-validations, I examined the out-of-sample
    predictions. Specifically, I focused on the false positives and negatives, the
    samples the model struggled to learn. These incorrect predictions are not always
    caused by the model’s fault. It’s possible that some samples have conflicts with
    each other and confuse the model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用时间序列交叉验证进行训练后，我检查了样本外预测。具体而言，我关注了假阳性和假阴性，即模型难以学习的样本。这些错误预测并不总是由模型自身的缺陷引起的。也有可能是某些样本之间存在冲突，导致模型混淆。
- en: I found several false negative cases labelled failures, and the model rarely
    treats them as failures. This observation piqued my curiosity. Upon further investigation,
    I discovered many accurate negative samples nearly identical to them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现几个标记为故障的假阴性案例，模型很少将它们视为故障。这一观察引起了我的好奇心。经过进一步调查，我发现许多与这些假阴性样本几乎相同的准确负样本。
- en: Figure 1 below compares false and true negatives by data visualization. I won’t
    go into details. The idea is to run the nearest-neighbours algorithms based on
    Euclidean distance or Mahalanobis distance in the raw data space; I found samples
    extremely close to those false negative samples are all true negatives. In other
    words, these failure instances are surrounded by many good instances.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图 1 通过数据可视化比较了假阴性和真阴性。我不会详细讲解。这个想法是基于欧几里得距离或马氏距离在原始数据空间中运行最近邻算法；我发现与这些假阴性样本非常接近的样本都是实际的真阴性。换句话说，这些故障实例被许多好的实例所包围。
- en: '![](../Images/16a1508ce530c0229d28fd4102277171.png)![](../Images/ad7c20e762fa37f1e13ada4a82d1e3f5.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/16a1508ce530c0229d28fd4102277171.png)![](../Images/ad7c20e762fa37f1e13ada4a82d1e3f5.png)'
- en: Figure 1\. Comparison of one false negative and one true negative. (Image by
    the Author)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1\. 一个假阴性与一个真阴性的比较。（图像来源于作者）
- en: 'We now face a typical limitation of a dataset: confusing samples. Either the
    labels are wrong, or we need more info (more dimensions) to separate them. There
    is a possible third way: how about transferring the entire space to a new space
    where confusing samples can be distinguished easily? It won’t work here. First,
    the confusion happened in the raw input data. It’s like for an image classification
    dataset, one image is labelled dog, and the other almost identical one is labelled
    cat. Second, the way of thinking is model-centric and generally increases model
    complexity.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在面临数据集的一个典型限制：混淆样本。要么标签错误，要么我们需要更多信息（更多维度）来进行区分。还有可能的第三种方法：将整个空间转换到一个新的空间，在那里混淆样本可以更容易地区分？在这里行不通。首先，混淆发生在原始输入数据中。就像在图像分类数据集中，一张图像标记为狗，另一张几乎相同的图像标记为猫。其次，这种思维方式是以模型为中心的，通常会增加模型的复杂性。
- en: After bringing these up to the client, they confirmed labels were correct. However,
    they also admitted that some vehicles that appeared to be functioning well could
    unexpectedly experience failures without any preceding symptoms, which is quite
    challenging to forecast. The false negative samples I found perfectly showcased
    these unexpected failures.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在向客户提出这些问题后，他们确认了标签是正确的。然而，他们也承认一些看似运行良好的车辆可能会在没有任何前兆的情况下突然出现故障，这很难预测。我发现的假阴性样本完美地展示了这些意外故障。
- en: By conducting this analysis of the out-of-sample predictions from cross-validations,
    I not only gained a deeper understanding of the problem and the data but also
    provided the clients with tangible examples that showcased the limitations of
    the dataset. This served as valuable insight for both myself and the clients.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对交叉验证中样本外预测的分析，我不仅对问题和数据有了更深刻的理解，还为客户提供了展示数据集局限性的具体例子。这对我和客户都是宝贵的见解。
- en: Inspiring feature engineering
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启发性特征工程
- en: In this project, the client wanted to use the vehicle’s on-road data to classify
    certain events, such as lane changes by the vehicle itself or acceleration and
    lane changes by the proceeding vehicles. The data is mainly time series data collected
    from different sonar sensors. Some critical info is the relative speed of surrounding
    objects and the distances (in x and y directions) of the own vehicle to the surrounding
    vehicles and lanes. There are also camera recordings by which the annotators label
    the events.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，客户希望使用车辆的道路数据来分类某些事件，例如车辆本身的变道或前方车辆的加速和变道。数据主要是从不同声呐传感器收集的时间序列数据。一些关键的信息是周围物体的相对速度和自车与周围车辆及车道的距离（在
    x 和 y 方向上的距离）。还有通过摄像机录制的事件，由标注人员进行标注。
- en: When performing the classification on events of ahead vehicle changing lane,
    I encountered a couple of interesting instances that the model labelled as the
    event was happening, but the ground truth disagreed. In data science terms, they
    were false positives with very high probability predictions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在对前方车辆变道事件进行分类时，我遇到了几个有趣的情况：模型将事件标记为正在发生，但实际情况却不一致。从数据科学的角度来看，它们是具有非常高概率预测的假阳性。
- en: To provide the client with a visual representation of model predictions, I presented
    them with short animations, as depicted in Figure 2\. The model would mistakenly
    label the ahead vehicle ‘changing lane’ around 19:59 to 20:02.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向客户提供模型预测的可视化表示，我向他们展示了短动画，如图2所示。模型会错误地将前方车辆标记为‘换车道’的时间段大约是19:59到20:02。
- en: '![](../Images/244d259262d6219a13f0eecf4c5a9f93.png)![](../Images/87cc09cbd87ead908461e926464d41ac.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/244d259262d6219a13f0eecf4c5a9f93.png)![](../Images/87cc09cbd87ead908461e926464d41ac.png)'
- en: Figure 2\. Animation of event detections. (Image by the Author)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图2\. 事件检测的动画。 （图片由作者提供）
- en: To solve this mystery, I watched the video associated with these instances.
    It turned out the roads were curved at those moments! Suppose the lanes were straight,
    then the model was correct. The model made wrong predictions because it had never
    learned that the lanes could be curved.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个谜题，我观看了与这些实例相关的视频。结果发现道路在那些时刻是弯曲的！假设车道是直的，那么模型就是正确的。模型做出错误预测是因为它从未学习过车道可能是弯曲的。
- en: The data didn’t contain any information on the distance of surrounding vehicles
    to the lances. Therefore, the model was trained to use surrounding vehicles’ distances
    to the own vehicle and the distance of the own vehicle to the lanes to figure
    out their relative position to the lanes. To fix these situations, the model must
    know the curvature of the lanes. After talking to the client, I uncovered the
    curvature info in the dataset and built explicit features measuring the distances
    of the surrounding vehicles and lanes based on geometry formulas. Now the model
    performance boosts and it won’t make such false positives.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据中没有包含有关周围车辆与车道之间距离的信息。因此，模型被训练使用周围车辆到自身车辆的距离以及自身车辆到车道的距离来确定它们相对于车道的位置。为了修复这些情况，模型必须知道车道的曲率。与客户沟通后，我在数据集中发现了曲率信息，并基于几何公式构建了测量周围车辆和车道距离的显式特征。现在，模型性能提升，不会再产生这种误报。
- en: Correcting label errors
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 纠正标签错误
- en: In the third example, we aimed to predict specific machine test results (pass
    or fail), which can be framed as a binary classification problem.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三个示例中，我们旨在预测特定的机器测试结果（通过或失败），这可以被框定为一个二分类问题。
- en: I developed a classifier with very high performance, suggesting the dataset
    should have enough relevant information to predict the target. To improve the
    model and understand the dataset better, let’s focus on the out-of-sample predictions
    from cross-validations where the model makes mistakes. The false positives and
    negatives are gold mines worth exploring.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我开发了一个性能非常高的分类器，表明数据集应该有足够的相关信息来预测目标。为了改进模型并更好地理解数据集，让我们关注交叉验证中的样本外预测，其中模型会犯错误。假阳性和假阴性是值得深入探索的宝贵资源。
- en: '![](../Images/cd04b00426757dfbdf6a252736e1eb2d.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd04b00426757dfbdf6a252736e1eb2d.png)'
- en: Figure 3\. A Confusion Matrix. (Image by the Author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图3\. 混淆矩阵。 （图片由作者提供）
- en: 'Figure 3 is a confusion matrix with a relatively high threshold. The three
    false positives imply the model will label them failures, but the ground truth
    labels them good. We may improve feature engineering to fix them like in the above
    example, or ask this question: what if the given labels are wrong and the model
    is actually correct? People make mistakes. Just like values from other columns
    could be outliers or missing, the target column itself could also be noisy and
    prone to inaccuracies.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图3 是一个阈值相对较高的混淆矩阵。这三个假阳性意味着模型会将它们标记为失败，但实际情况是它们是好的。我们可以像上述示例那样通过改进特征工程来修复它们，或者提出这个问题：如果给定的标签是错误的，而模型实际上是正确的呢？人们会犯错。就像其他列的值可能是异常值或缺失值一样，目标列本身也可能嘈杂并容易出现不准确。
- en: I couldn’t easily show these three samples are wrong with the evidence from
    the nearest-neighbours approach because the data space was sparse. Then I discussed
    how the data were labelled with the client. We agreed that some criteria to determine
    the test results were flawed and that some samples’ labels were potentially wrong
    or unknown. After the cleaning, these three samples’ labels were corrected, and
    the model performance was boosted.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我不能轻易地通过最近邻方法的证据来展示这三个样本是错误的，因为数据空间很稀疏。于是我与客户讨论了数据标注的问题。我们一致认为，用于确定测试结果的一些标准存在缺陷，并且一些样本的标签可能是错误的或未知的。经过清理后，这三个样本的标签得到了修正，模型性能得到了提升。
- en: 'We cannot always blame the data quality. But remember, these two things are
    **equally important for your data science jobs: improving the model and fixing
    the data**. Don’t spend all your energy on modelling and assume all the data provided
    is error-free. Instead, dedicating attention to both aspects is crucial. Out-of-sample
    predictions from cross-validation are a powerful tool for finding problems in
    the data.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能总是责怪数据质量。但请记住，这两个方面**对于你的数据科学工作同样重要：改善模型和修正数据**。不要把所有精力都放在建模上，假设所有提供的数据都是无误的。相反，关注这两个方面是至关重要的。来自交叉验证的样本外预测是发现数据问题的强大工具。
- en: For more information, [labelerrors.com](https://labelerrors.com/) lists label
    errors from popular benchmarking datasets.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多信息，[labelerrors.com](https://labelerrors.com/)列出了流行基准数据集中的标签错误。
- en: Conclusion
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Cross-validation serves multiple purposes beyond just providing a score. Apart
    from the numerical evaluation, it offers the opportunity to extract valuable insights
    from out-of-fold predictions. By closely examining the successful predictions,
    we can better understand the model’s strengths and identify the most influential
    features. Similarly, analyzing the unsuccessful predictions sheds light on the
    limitations of both the data and the model, inspiring ideas for potential improvements.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证不仅仅提供一个评分，它还有多个用途。除了数值评估外，它还提供了从预测结果中提取有价值见解的机会。通过仔细分析成功的预测，我们可以更好地理解模型的优势，并识别出最具影响力的特征。同样，分析失败的预测可以揭示数据和模型的局限性，并激发潜在的改进思路。
- en: I hope this tool proves invaluable in enhancing your data science skills.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这个工具能在提升你的数据科学技能方面发挥重要作用。
- en: If you think this article deserves a clap, I’d love it. You can clap multiple
    times if you like; thanks!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认为这篇文章值得点赞，我会非常开心。如果你喜欢，可以多点几次；谢谢！
- en: '![Ning Jia](../Images/a991f2292a9316c1aee531472f6da462.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![宁佳](../Images/a991f2292a9316c1aee531472f6da462.png)'
- en: '[Ning Jia](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[宁佳](https://medium.com/@ning.jia?source=post_page-----2db0850463c8--------------------------------)'
- en: Data Science for Time Series
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列的数据科学
- en: '[View list](https://medium.com/@ning.jia/list/data-science-for-time-series-7691e7b85020?source=post_page-----2db0850463c8--------------------------------)6
    stories![](../Images/0498dccb91b7201e8a61ffa180eb19ea.png)![](../Images/a0d1ff4cc1ce2f7a5a06038f0c0c20c0.png)![](../Images/784992138eb651932ed73ba2bc8b0908.png)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@ning.jia/list/data-science-for-time-series-7691e7b85020?source=post_page-----2db0850463c8--------------------------------)6个故事！[](../Images/0498dccb91b7201e8a61ffa180eb19ea.png)![](../Images/a0d1ff4cc1ce2f7a5a06038f0c0c20c0.png)![](../Images/784992138eb651932ed73ba2bc8b0908.png)'
