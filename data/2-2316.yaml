- en: Well Log Measurement Prediction Using Neural Networks with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras进行测井数据预测的神经网络
- en: 原文：[https://towardsdatascience.com/well-log-measurement-prediction-using-neural-networks-with-keras-ef7dfed94077](https://towardsdatascience.com/well-log-measurement-prediction-using-neural-networks-with-keras-ef7dfed94077)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/well-log-measurement-prediction-using-neural-networks-with-keras-ef7dfed94077](https://towardsdatascience.com/well-log-measurement-prediction-using-neural-networks-with-keras-ef7dfed94077)
- en: An example of predicting bulk density (RHOB) with Keras and illustrating impacts
    of normalisation on prediction results
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Keras预测体积密度（RHOB）的示例，并说明归一化对预测结果的影响
- en: '[](https://andymcdonaldgeo.medium.com/?source=post_page-----ef7dfed94077--------------------------------)[![Andy
    McDonald](../Images/df11d647be032aeb3d31852affb33a64.png)](https://andymcdonaldgeo.medium.com/?source=post_page-----ef7dfed94077--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ef7dfed94077--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ef7dfed94077--------------------------------)
    [Andy McDonald](https://andymcdonaldgeo.medium.com/?source=post_page-----ef7dfed94077--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://andymcdonaldgeo.medium.com/?source=post_page-----ef7dfed94077--------------------------------)[![Andy
    McDonald](../Images/df11d647be032aeb3d31852affb33a64.png)](https://andymcdonaldgeo.medium.com/?source=post_page-----ef7dfed94077--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ef7dfed94077--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ef7dfed94077--------------------------------)
    [Andy McDonald](https://andymcdonaldgeo.medium.com/?source=post_page-----ef7dfed94077--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ef7dfed94077--------------------------------)
    ·11 min read·Oct 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ef7dfed94077--------------------------------)
    ·阅读时间11分钟·2023年10月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/529d75975080d8031f4c76ffef5de671.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/529d75975080d8031f4c76ffef5de671.png)'
- en: Image representing neural networks combined with natural landscapes. Image generated
    by DALL-E 3.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 代表神经网络与自然景观相结合的图像。图像由DALL-E 3生成。
- en: Large amounts of data are acquired daily from wells around the world. However,
    the quality of that data can vary significantly from missing data to data impacted
    by sensor failure and borehole conditions. This can have knock-on consequences
    on other parts of a subsurface project, such as delays and inaccurate assumptions
    and conclusions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 全球每天都有大量数据从井中获取。然而，这些数据的质量可能会显著变化，从缺失数据到受到传感器故障和钻孔条件影响的数据。这可能对地下项目的其他部分产生连锁反应，例如延误和不准确的假设与结论。
- en: As missing data is one of the most common issues we face with well log data
    quality, numerous methods and techniques have been developed to estimate values
    and fill in the gaps. This includes the application of machine learning technology
    — which has increased in popularity over the past few decades with libraries such
    as TensorFlow and PyTorch.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缺失数据是我们在测井数据质量中最常遇到的问题之一，因此已经开发了许多方法和技术来估计值并填补空白。这包括应用机器学习技术——在过去几十年中随着TensorFlow和PyTorch等库的普及而越来越受欢迎。
- en: In this tutorial, we will be using Keras, which is a high-level neural networks
    API that runs on top of TensorFlow. We will use it to illustrate the process of
    building a machine-learning model to allow predictions of bulk density (RHOB).
    This is a commonly acquired logging measurement, however, it can be significantly
    impacted by bad hole conditions or, in some cases, tools can fail, resulting in
    no measurements over key intervals.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用Keras，它是一个运行在TensorFlow之上的高级神经网络API。我们将利用它来演示构建机器学习模型的过程，从而允许预测体积密度（RHOB）。这是一个常见的测井测量，但它可能会受到孔眼条件不良的显著影响，或者在某些情况下，工具可能会出现故障，导致关键区间没有测量数据。
- en: We will start with a very simple model, that does not account for normalising
    the inputs, a common step in the machine learning workflow. Then, we will then
    build a second model with normalised inputs and illustrate its impact on the final
    prediction result.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个非常简单的模型开始，该模型不考虑输入的归一化，这是机器学习工作流程中的一个常见步骤。然后，我们将建立一个具有归一化输入的第二个模型，并说明其对最终预测结果的影响。
- en: Importing Libraries and Loading Data
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入库和加载数据
- en: The first step in this tutorial is to import the libraries we will be working
    with.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的第一步是导入我们将使用的库。
- en: 'For this tutorial, we need 4 libraries:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们需要4个库：
- en: '[**Pandas**](https://pandas.pydata.org/): Loading and manipulating our dataset'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Pandas**](https://pandas.pydata.org/): 用于加载和操作我们的数据集'
- en: '[**sklearn.model_selection:**](https://scikit-learn.org/stable/) To create
    our training and testing data split'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**sklearn.model_selection:**](https://scikit-learn.org/stable/) 用于创建我们的训练和测试数据划分'
- en: '[**Tensorflow**](https://www.tensorflow.org/): To build and run our neural
    network'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Tensorflow**](https://www.tensorflow.org/): 用于构建和运行我们的神经网络'
- en: '[**matplotlib**](https://matplotlib.org/): To visualise prediction results'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**matplotlib**](https://matplotlib.org/): 用于可视化预测结果'
- en: 'These are imported as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是按以下方式导入的：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once we have imported the libraries, we need to load the data we will train
    and test our model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦导入了库，我们需要加载将用于训练和测试模型的数据。
- en: For this tutorial, we will use a dataset containing a series of well log measurements
    from 3 wells in the Volve Field, located off the west coast of Norway. This data
    comes from the publically available Equinor Volve Dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们将使用一个包含来自挪威西海岸Volve油田3口井的系列测井数据的数据集。这些数据来自公开的Equinor Volve数据集。
- en: Full details of this dataset can be found at the end of the article.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的完整详细信息可以在文章末尾找到。
- en: 'To read our CSV file, we simply call upon:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要读取我们的CSV文件，我们只需调用：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: When we view the dataframe, we can see what logging measurements are contained
    within it, and also the first and last 5 rows of the data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看数据框时，我们可以看到其中包含哪些测井数据，以及数据的前5行和最后5行。
- en: '![](../Images/905ce64a12aed9d2cc1ced90d082c4f3.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/905ce64a12aed9d2cc1ced90d082c4f3.png)'
- en: Dataframe view of three selected Volve wells for Neural Network modelling. Image
    by the author.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 用于神经网络建模的三个选定Volve井的数据框视图。图像由作者提供。
- en: For this tutorial, we will assume that all data preparation steps have been
    carried out and that the data has been quality-checked by a petrophysicist/geoscientist.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们将假设所有的数据准备步骤已经完成，并且数据已由岩石物理学家/地球科学家进行了质量检查。
- en: However, if we want to double-check that we have columns full of data and no
    null rows, we can call upon `df.describe()`. When we do this, we need to check
    that we have 24,111 for the count row in all columns/measurements.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，如果我们想要再次检查是否所有列都充满了数据且没有空值行，我们可以调用`df.describe()`。当我们这样做时，我们需要检查所有列/测量中的计数行是否为24,111。
- en: '**It should be noted that ensuring we have quality data before applying machine
    learning is very important, as it could lead to errors and other issues.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**值得注意的是，在应用机器学习之前确保数据质量非常重要，因为这可能导致错误和其他问题。**'
- en: Splitting Data into Training and Testing
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据拆分为训练和测试
- en: For this tutorial, we will attempt to predict Bulk Density (RHOB). This logging
    measurement can sometimes be missing from well-logging datasets for various reasons.
    Some of these reasons include the data not being required for the objectives of
    drilling that well, or it could be simply excluded to save on drilling and logging
    costs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本教程，我们将尝试预测体积密度（RHOB）。由于各种原因，这种测井测量有时会在测井数据集中缺失。这些原因包括数据对钻井目标并不重要，或者为了节省钻井和测井成本，数据被简单地排除在外。
- en: Consequently, we often have to use existing well log datasets containing the
    RHOB measurement to build a machine learning model that can be used to predict
    the measurement within other wells where it was not acquired.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们通常需要使用现有的测井数据集，其中包含RHOB测量，以构建一个机器学习模型，该模型可以用于预测其他井中的测量结果，尽管这些井中并未获取这些测量。
- en: Our next step is to split our data in two.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是将数据拆分为两个部分。
- en: The data placed in the `X` variable is the data that will be used as input for
    our model, and `y`, which contains our target output — in this case, RHOB.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`X`变量中放置的数据将作为我们模型的输入，而`y`包含我们的目标输出——在这种情况下是RHOB。'
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We could carry on with the data as is and build, train and predict using it,
    however, we would not really be able to understand how well our model is performing.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续使用现有的数据进行构建、训练和预测，但我们将无法真正了解模型的表现情况。
- en: This is where we split our data into two subsets. A subset for training the
    model, and a subset for validating and tuning the model. Ideally, we would have
    a third dataset for testing how well our model performs on completely unseen data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将数据拆分为两个子集的地方。一个子集用于训练模型，另一个子集用于验证和调整模型。理想情况下，我们还会有第三个数据集，用于测试模型在完全未见数据上的表现。
- en: However, for this example, we will stick with two subsets.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，在这个例子中，我们将坚持使用两个子集。
- en: To split our data, we call upon the `train_test_split` method from sklearn,
    and pass in our `X` and `y` variables.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了拆分数据，我们调用 sklearn 的 `train_test_split` 方法，并传入我们的 `X` 和 `y` 变量。
- en: We will also set the split to be 70% for training, and the remaining 30% for
    validating and fine-tuning our data. This can be varied depending on the size
    of your dataset. For example, with smaller datasets, you may want a larger training
    subset.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将设置拆分比例为 70% 进行训练，其余 30% 用于验证和微调数据。这个比例可以根据数据集的大小进行调整。例如，对于较小的数据集，您可能希望有更大的训练子集。
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We can check that the split has worked by checking the length of X_train and
    `X_test`
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检查 X_train 和 `X_test` 的长度来验证拆分是否成功。
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Which returns a tuple with the sizes of the subsets:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回一个包含子集大小的元组：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In a standard workflow, we would normally normalise/standardise our data to
    account for the varying data ranges. However, for our first model, we will run
    with un-normalised data and then apply normalisation in our second model to see
    if it improves the results.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准工作流程中，我们通常会对数据进行归一化/标准化，以考虑不同的数据范围。然而，对于我们的第一个模型，我们将使用未归一化的数据，然后在第二个模型中应用归一化，以查看是否能改善结果。
- en: Building and Training a Keras Model
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建和训练 Keras 模型
- en: When building models with keras there are two main ways of creating a neural
    network model. These are the Sequential API and Functional API methods.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 keras 构建模型时，有两种主要的方式来创建神经网络模型。这些是 Sequential API 和 Functional API 方法。
- en: With the Sequential method, we simply stack layers on top of each other in a
    linear manner, whereas the Functional API offers more flexibility and can be used
    to create more complex models which have multiple inputs and outputs and shared
    layers.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Sequential 方法，我们只需将层线性地堆叠在一起，而 Functional API 提供了更多灵活性，可以用于创建具有多个输入和输出及共享层的更复杂模型。
- en: For this tutorial, we will be using the Sequential API, as it is the simplest
    to use and get started with.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用 Sequential API，因为它是最简单的使用方法，容易上手。
- en: Defining The Keras Neural Network Model
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义 Keras 神经网络模型
- en: To get started with the Sequential API, we first create our model as follows.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Sequential API，我们首先创建模型如下。
- en: It is often best to start simple and small when building neural networks, gradually
    increasing the complexity until you are happy with the results.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建神经网络时，最好从简单和小规模开始，逐渐增加复杂性，直到对结果满意。
- en: For this example, we are going to create a very simple Neural Network consisting
    of a single hidden layer with 8 neurons and `relu` as the activation function
    of `relu` . This layer transforms our input data by applying several weights,
    biases and the activation function and then passes it to the final output layer.
    This layer is set up to provide a numerical output representing the Acoustic Shear
    Slowness curve.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将创建一个非常简单的神经网络，由一个包含 8 个神经元的隐藏层组成，`relu` 作为激活函数。这个层通过应用多个权重、偏差和激活函数来转换输入数据，然后将其传递到最终的输出层。这个层设置为提供一个代表声学剪切迟缓曲线的数值输出。
- en: 'To find out more about the different activation functions and how they work,
    I recommend checking out the following page:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于不同激活函数及其工作原理的信息，我建议查看以下页面：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Compiling The Keras Neural Network Model
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编译 Keras 神经网络模型
- en: Once we have defined our model, we next need to compile it. This configures
    and sets up how the model will learn.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了模型，接下来需要对其进行编译。这将配置和设置模型如何学习。
- en: To keep our model simple, we will use Mean Absolute Error (MAE) as the loss
    function (which is used to quantify how well the model is performing against the
    target feature) and the metric (also used to judge how our model is performing
    — but can be a more human-friendly score if using different loss functions).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持模型简单，我们将使用平均绝对误差（MAE）作为损失函数（用于量化模型对目标特征的表现）和指标（也用于判断模型表现——但如果使用不同的损失函数，它可以是更易于理解的评分）。
- en: We will also set the optimizer to ‘Adam’. This is a common optimszer model and
    is used to determine how the model will update its weights based on the selected
    loss function.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将优化器设置为‘Adam’。这是一个常见的优化器模型，用于根据选择的损失函数确定模型如何更新其权重。
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Fitting / Training The Keras Neural Network Model
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拟合/训练 Keras 神经网络模型
- en: The final step of creating our model is to “fit” our model to the training data.
    This will begin the training process of our defined model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 创建模型的最后一步是将模型“拟合”到训练数据中。这将开始我们定义模型的训练过程。
- en: We will also set the number epochs to 30\. This represents a complete pass of
    the data through the neural network. After each pass, the model weights are updated
    in order to minimise the selected loss function.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将设置训练的周期数为30。这代表数据在神经网络中的一次完整传递。每次传递后，模型权重会被更新，以最小化所选的损失函数。
- en: When building models, saving the model fit results to a history variable is
    a good idea. This will allow us to plot the results and keep a record of the training
    history.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建模型时，将模型拟合结果保存到历史变量中是一个好主意。这将允许我们绘制结果并记录训练历史。
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Once we start running the model, we will get the following text output detailing
    the progress of the model and how well each epoch is performing.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们开始运行模型，我们将获得以下文本输出，详细说明模型的进展以及每个周期的表现。
- en: '![](../Images/2a49772b62807cfeeccec6777aefff17.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a49772b62807cfeeccec6777aefff17.png)'
- en: Keras Neural Network model training output. Image by the author.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Keras神经网络模型训练输出。图像由作者提供。
- en: Once the model has completed, we can view the history in graphical form by generating
    a matplotlib figure like so.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 模型完成后，我们可以通过生成一个matplotlib图形来以图形形式查看历史记录。
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/61e4db38de7410b67f511b721c8ba137.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61e4db38de7410b67f511b721c8ba137.png)'
- en: Keras Neural Network model loss curves during training. Image by the author.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Keras神经网络模型训练过程中的损失曲线。图像由作者提供。
- en: In the image above, the blue curve (loss) and the orange curve (mae) represent
    the training loss and performance metric (MAE).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图像中，蓝色曲线（损失）和橙色曲线（mae）分别表示训练损失和性能指标（MAE）。
- en: Both curves decrease sharply at the beginning, suggesting that the model is
    learning and improving its performance in the initial epochs. However, as the
    number of epochs increases, the decrease in the loss and metric becomes more gradual.
    This may indicate that our model has reached convergence and arrived at its final
    solution.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 两条曲线在开始时急剧下降，这表明模型正在学习并改善其在初始周期中的表现。然而，随着周期数的增加，损失和指标的下降变得更加缓慢。这可能表明我们的模型已达到收敛并得到了最终解决方案。
- en: Applying the Keras Model to the Test Data
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Keras模型应用于测试数据
- en: Once our model has been trained, we can apply the model and predict the values
    within the target feature of the test subset.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的模型经过训练，我们可以应用该模型并预测测试子集目标特征中的值。
- en: This is done by calling upon the following code.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过调用以下代码来完成的。
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once we run this line, we will see Keras making its prediction.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们运行这一行，我们将看到Keras进行预测。
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Assessing Model Performance
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: After our model has made its prediction, we can now evaluate how well it performs
    on the test data by calling upon a couple of metrics available within Keras.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型进行预测后，我们可以通过调用Keras中的几个指标来评估其在测试数据上的表现。
- en: These are the Mean Absolute Error (MAE)— which represents the average absolute
    difference between the actual and predicted values — and the Root Mean Square
    Error (RMSE) — which represents the average error magnitude between the actual
    and predicted values.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是平均绝对误差（MAE）——表示实际值和预测值之间的平均绝对差异——和均方根误差（RMSE）——表示实际值和预测值之间的平均误差幅度。
- en: In order to pass our predicted variable into these metrics, we first need to
    remove any extra dimensions of size from the generated result. This ensures that
    the shapes of `y_test` and `y_pred` are the same.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们预测的变量传递到这些指标中，我们首先需要去除生成结果中的任何额外维度。这确保了`y_test`和`y_pred`的形状是相同的。
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: When we view the metrics, we get the following scores back.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看指标时，我们得到以下分数。
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This tells us that, on average, our predicted result is 0.0757 g/cc off from
    the actual result, and that the RMSE of 0.1105 indicates that we have some instances
    where our results are significantly different from the actual values.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们，平均而言，我们的预测结果与实际结果相差0.0757 g/cc，RMSE为0.1105，表明我们有一些结果与实际值差异显著的实例。
- en: Visualising the Error Results
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 误差结果的可视化
- en: It is all good and well to look at metrics. However, judging how well our model
    performs from just these two numbers alone can be difficult.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅查看指标虽然很好，但仅凭这两个数字来判断我们模型的表现可能会很困难。
- en: One way we can visualise our results is with a simple scatter plot of the actual
    and true measurements.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过实际和真实测量值的简单散点图来可视化我们的结果。
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can then call upon our plot by passing in the actual and predicted values.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过传入实际值和预测值来调用我们的图表。
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When we run this, we get back the following plot.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这个时，我们会得到以下图表。
- en: '![](../Images/ebe5480892c2a536022134f4e7fbfbfe.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebe5480892c2a536022134f4e7fbfbfe.png)'
- en: Scatter plot of predicted measurements vs actual measurements. Image by the
    author.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 预测测量值与实际测量值的散点图。图片由作者提供。
- en: Overall, the model is doing a good job of predicting bulk density (RHOB) — based
    on most data points sitting close to the 1:1 relationship line. However, there
    are a few areas where we could benefit from some improvement in the model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，模型在预测体积密度（RHOB）方面表现良好——大多数数据点接近1:1关系线。然而，还有一些领域可以通过改进模型来受益。
- en: We can see a higher spread of values between 2.2g/cc and 2.6 g/cc, indicating
    that our model is under-predicting bulk density in this range.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到在2.2g/cc到2.6 g/cc之间的数值分布更广，这表明我们的模型在这个范围内低估了体积密度。
- en: Improving the Keras Model By Applying MinMaxScaler to the Input Data
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过对输入数据应用MinMaxScaler来改进Keras模型
- en: Some machine learning models, including Neural Networks, perform better when
    the data is normalised to a standard range.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器学习模型，包括神经网络，当数据归一化到标准范围时表现更好。
- en: In well log measurements, we sometimes have data scaled from 0 to 0.5, and others
    that reach the 10s of thousands. This can result in some input curves having more
    weight compared to others.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在井测量中，我们有时会有数据缩放从0到0.5，而其他数据达到几万。这可能导致某些输入曲线比其他曲线具有更大的权重。
- en: To give each input curve equal footing when it comes to modelling, we need to
    change the input data to a standard range. Additionally, it can also improve model
    training times and model prediction accuracy.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在建模时让每个输入曲线具有相同的基础，我们需要将输入数据更改为标准范围。此外，这也可以提高模型训练时间和模型预测准确性。
- en: One way to normalise the values is by using the [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)
    from [sklearn](https://scikit-learn.org/stable/index.html).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化值的一种方法是使用[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)来自[sklearn](https://scikit-learn.org/stable/index.html)。
- en: This function will scale the data between 0 and 1.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数会将数据缩放到0和1之间。
- en: Once the `MinMaxScaler` has been imported, we can then fit and transform our
    `X_train` and `X_test` data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`MinMaxScaler`被导入，我们就可以拟合和转换我们的`X_train`和`X_test`数据。
- en: We do not need to change the target feature.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要改变目标特征。
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We can then pass in our newly scaled variables and re-run the model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以传入我们新缩放的变量并重新运行模型。
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Again, Keras will report on the model's progress as it is running.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，Keras将在运行时报告模型的进展。
- en: Right away, we notice that the mae values are smaller than the original run.
    Hopefully, this should mean a better model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们立即注意到，mae值比原始运行时更小。希望这意味着模型更好。
- en: '![](../Images/5a85771be9fa2cb02ef75b22488e41bb.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a85771be9fa2cb02ef75b22488e41bb.png)'
- en: Keras progress during prediction with scaled inputs. Image by the author.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用缩放输入进行预测时Keras的进展。图片由作者提供。
- en: And then, we can make a new prediction by re-assessing the key metrics.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过重新评估关键指标来进行新的预测。
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This gives us an MAE of 0.0292 g/cc and an RMSE of 0.0455\. This indicates that
    our model has improved by applying our MinMaxScaler.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了0.0292 g/cc的MAE和0.0455的RMSE。这表明，通过应用我们的MinMaxScaler，模型得到了改进。
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We can further confirm this by passing our new prediction results into the scatter
    plot and comparing the results with the previous model.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将新的预测结果传入散点图并将结果与之前的模型进行比较来进一步确认这一点。
- en: '![](../Images/9a6ebe5f7a041fa33090f639e982a30e.png)![](../Images/f05ba3abaa89a2d4c516d4506fd460ed.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a6ebe5f7a041fa33090f639e982a30e.png)![](../Images/f05ba3abaa89a2d4c516d4506fd460ed.png)'
- en: Comparison of Keras predictions before (left) and after (right) normalisation
    with MinMaxScaler. Note the different scales when comparing. Image by the author.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Keras预测的比较，归一化前（左）和归一化后（右）使用MinMaxScaler。比较时请注意不同的尺度。图片由作者提供。
- en: Even though the plots are on different scales, we can see a significant improvement
    around the 2.2g/cc and 2.6 g/cc range. This confirms that applying the normalisation
    to our data has resulted in a better prediction result.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管图表的尺度不同，我们可以看到在2.2g/cc和2.6 g/cc范围内有显著改善。这证实了将归一化应用于数据已产生更好的预测结果。
- en: Summary
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this tutorial, we have seen how to build a very simple Keras Neural Network
    model to predict a common well log measurement using other available well log
    data. This can be extremely useful when we have missing data or data impacted
    by poor borehole conditions, such as washout.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们已经看到如何构建一个非常简单的 Keras 神经网络模型，以使用其他可用的井日志数据来预测常见的井日志测量。这在数据缺失或受差井条件（如洗井）影响的数据的情况下极其有用。
- en: Even though this tutorial stops after one revision to the model, it is always
    wise to try different variations of the model setup and different combinations
    of inputs.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本教程在对模型进行一次修订后停止，但尝试不同的模型设置变体和不同的输入组合总是明智的。
- en: Remember, the whole process of building a successful machine-learning model
    involves multiple iterations to arrive at the final model. Even after the model
    has been deployed, it can still be revised when new data becomes available.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，构建成功的机器学习模型的整个过程涉及多次迭代以达到最终模型。即使模型已经部署，也可以在有新数据时进行修订。
- en: Finally, making predictions using machine learning technologies should not be
    seen as a direct substitute for domain expertise. Instead, domain expertise should
    be used in conjunction with the modelling and prediction process. This ensures
    that accuracy is maintained and any erroneous results are caught.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用机器学习技术进行预测不应被视为领域专业知识的直接替代品。相反，领域专业知识应与建模和预测过程相结合。这可以确保准确性，并捕捉到任何错误结果。
- en: Dataset Used
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集使用情况
- en: The data used within this tutorial is a subset of the Volve Dataset that Equinor
    released in 2018\. Full details of the dataset, including the licence, can be
    found at the link below
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中使用的数据是 Equinor 在 2018 年发布的 Volve 数据集的一个子集。数据集的详细信息，包括许可证，可以在以下链接找到
- en: '[](https://www.equinor.com/energy/volve-data-sharing?source=post_page-----ef7dfed94077--------------------------------)
    [## Volve field data set'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.equinor.com/energy/volve-data-sharing?source=post_page-----ef7dfed94077--------------------------------)
    [## Volve 领域数据集'
- en: Equinor has released a complete set of data from the Volve field, 2008-2016\.
    Click here to download for study, research…
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Equinor 已发布 2008-2016 年 Volve 领域的完整数据集。点击此处下载以供研究、学习……
- en: www.equinor.com](https://www.equinor.com/energy/volve-data-sharing?source=post_page-----ef7dfed94077--------------------------------)
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: www.equinor.com](https://www.equinor.com/energy/volve-data-sharing?source=post_page-----ef7dfed94077--------------------------------)
- en: 'The Volve data license is based on CC BY 4.0 license. Full details of the license
    agreement can be found here:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Volve 数据许可证基于 CC BY 4.0 许可证。许可证协议的详细信息可以在这里找到：
- en: '[https://cdn.sanity.io/files/h61q9gi9/global/de6532f6134b9a953f6c41bac47a0c055a3712d3.pdf?equinor-hrs-terms-and-conditions-for-licence-to-data-volve.pdf](https://cdn.sanity.io/files/h61q9gi9/global/de6532f6134b9a953f6c41bac47a0c055a3712d3.pdf?equinor-hrs-terms-and-conditions-for-licence-to-data-volve.pdf=)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cdn.sanity.io/files/h61q9gi9/global/de6532f6134b9a953f6c41bac47a0c055a3712d3.pdf?equinor-hrs-terms-and-conditions-for-licence-to-data-volve.pdf](https://cdn.sanity.io/files/h61q9gi9/global/de6532f6134b9a953f6c41bac47a0c055a3712d3.pdf?equinor-hrs-terms-and-conditions-for-licence-to-data-volve.pdf=)'
- en: '*Thanks for reading. Before you go, you should definitely subscribe to my content
    and get my articles in your inbox.* [***You can do that here!***](https://andymcdonaldgeo.medium.com/subscribe)*Also,
    if you have enjoyed this content and want to show your appreciation, consider
    giving it a few claps.*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*感谢阅读。在您离开之前，您绝对应该订阅我的内容，将我的文章送入您的收件箱。* [***您可以在这里进行订阅！***](https://andymcdonaldgeo.medium.com/subscribe)*此外，如果您喜欢这些内容并想表示感谢，请考虑为它点赞。*'
