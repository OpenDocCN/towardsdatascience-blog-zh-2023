- en: A Guide to Building Effective Training Pipelines for Maximum Results
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高效训练管道构建指南
- en: 原文：[https://towardsdatascience.com/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee](https://towardsdatascience.com/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee](https://towardsdatascience.com/a-guide-to-building-effective-training-pipelines-for-maximum-results-6fdaef594cee)
- en: '[THE FULL STACK 7-STEPS MLOPS FRAMEWORK](https://towardsdatascience.com/tagged/full-stack-mlops)'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[完整的 7 步 MLOps 框架](https://towardsdatascience.com/tagged/full-stack-mlops)'
- en: 'Lesson 2: Training Pipelines. ML Platforms. Hyperparameter Tuning.'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2课：训练管道。ML 平台。超参数调整。
- en: '[](https://pauliusztin.medium.com/?source=post_page-----6fdaef594cee--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----6fdaef594cee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6fdaef594cee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6fdaef594cee--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----6fdaef594cee--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/?source=post_page-----6fdaef594cee--------------------------------)[![Paul
    Iusztin](../Images/d07551a78fa87940220b49d9358f3166.png)](https://pauliusztin.medium.com/?source=post_page-----6fdaef594cee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6fdaef594cee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6fdaef594cee--------------------------------)
    [Paul Iusztin](https://pauliusztin.medium.com/?source=post_page-----6fdaef594cee--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6fdaef594cee--------------------------------)
    ·19 min read·May 9, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6fdaef594cee--------------------------------)
    ·19分钟阅读·2023年5月9日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/27d8728645d28e45ee8757d4bedf42c2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/27d8728645d28e45ee8757d4bedf42c2.png)'
- en: Photo by [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 [Hassan Pasha](https://unsplash.com/@hpzworkz?utm_source=medium&utm_medium=referral)
    在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This tutorial represents **lesson 2 out of a 7-lesson course** that will walk
    you step-by-step through how to **design, implement, and deploy an ML system**
    using **MLOps good practices**. During the course, you will build a production-ready
    model to forecast energy consumption levels for the next 24 hours across multiple
    consumer types from Denmark.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程代表了**7 节课程中的第 2 节**，将逐步指导你如何**设计、实现和部署一个 ML 系统**，使用**MLOps 的最佳实践**。在课程期间，你将构建一个生产就绪的模型，以预测未来
    24 小时内来自丹麦的多个消费者类型的能源消耗水平。
- en: '*By the end of this course, you will understand all the fundamentals of designing,
    coding and deploying an ML system using a batch-serving architecture.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*通过本课程的学习，你将掌握设计、编码和部署一个使用批量服务架构的 ML 系统的所有基本知识。*'
- en: This course *targets mid/advanced machine learning engineers* who want to level
    up their skills by building their own end-to-end projects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本课程*针对中级/高级机器学习工程师*，旨在通过构建自己的端到端项目来提升技能。
- en: '*Nowadays, certificates are everywhere. Building advanced end-to-end projects
    that you can later show off is the best way to get recognition as a professional
    engineer.*'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*如今，证书随处可见。构建高级的端到端项目并展示出来是获得专业认可的最佳方式。*'
- en: 'Table of Contents:'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目录：
- en: Course Introduction
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程简介
- en: Course Lessons
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 课程内容
- en: Data Source
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据来源
- en: 'Lesson 2: Training Pipelines. ML Platforms. Hyperparameter Tuning.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2课：训练管道。ML 平台。超参数调整。
- en: 'Lesson 2: Code'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2课：代码
- en: Conclusion
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结论
- en: References
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考文献
- en: Course Introduction
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 课程简介
- en: '***At the end of this 7 lessons course, you will know how to:***'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '***在这 7 节课的课程结束时，你将学会如何：***'
- en: design a batch-serving architecture
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个批量服务架构
- en: use Hopsworks as a feature store
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Hopsworks 作为特征存储
- en: design a feature engineering pipeline that reads data from an API
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个从 API 读取数据的特征工程管道
- en: build a training pipeline with hyper-parameter tunning
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个带有超参数调整的训练管道
- en: use W&B as an ML Platform to track your experiments, models, and metadata
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 W&B 作为 ML 平台来跟踪你的实验、模型和元数据
- en: implement a batch prediction pipeline
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个批量预测管道
- en: use Poetry to build your own Python packages
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Poetry 构建你自己的 Python 包
- en: deploy your own private PyPi server
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署你自己的私有 PyPi 服务器
- en: orchestrate everything with Airflow
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Airflow 协调一切
- en: use the predictions to code a web app using FastAPI and Streamlit
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预测结果编写一个基于 FastAPI 和 Streamlit 的网页应用
- en: use Docker to containerize your code
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Docker 容器化你的代码
- en: use Great Expectations to ensure data validation and integrity
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Great Expectations 确保数据验证和完整性
- en: monitor the performance of the predictions over time
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控预测性能的时间变化
- en: deploy everything to GCP
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有内容部署到 GCP
- en: build a CI/CD pipeline using GitHub Actions
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GitHub Actions 构建 CI/CD 管道
- en: If that sounds like a lot, don't worry, after you will cover this course you
    will understand everything I said before. Most importantly, you will know WHY
    I used all these tools and how they work together as a system.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来很多，不用担心，完成本课程后你将理解我之前所说的一切。最重要的是，你会知道**我为什么使用所有这些工具**，以及它们如何作为一个系统协同工作。
- en: '**If you want to get the most out of this course,** [**I suggest you access
    the GitHub repository**](https://github.com/iusztinpaul/energy-forecasting) **containing
    all the lessons'' code. This course is designed to read and replicate the code
    along the articles quickly.**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你想从这门课程中获得最大收益，** [**我建议你访问包含所有课程代码的 GitHub 仓库**](https://github.com/iusztinpaul/energy-forecasting)
    **。本课程旨在让你快速阅读和复制文章中的代码。**'
- en: By the end of the course, you will know how to implement the diagram below.
    Don't worry if something doesn't make sense to you. I will explain everything
    in detail.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在课程结束时，你将知道如何实现下图所示的内容。如果有些地方对你来说不太明白，不用担心，我会详细解释一切。
- en: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4b5c3b0b8e2162ea8fd268ca745199ec.png)'
- en: Diagram of the architecture you will build during the course [Image by the Author].
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 课程期间你将构建的架构图 [作者提供的图像]。
- en: By the **end of Lesson 2**, you will know how to implement and integrate the
    **training pipeline** and **ML platform**.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在**第二课结束时**，你将知道如何实现和集成**训练管道**和**ML平台**。
- en: '**Note:** This is the most extended lesson, as I couldn''t logically split
    the training pipeline from the ML platform. Enjoy!'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 这是最长的一节课，因为我无法从ML平台中逻辑性地分离出训练管道。享受吧！'
- en: 'Course Lessons:'
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 课程内容：
- en: '[Batch Serving. Feature Stores. Feature Engineering Pipelines.](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[批量服务。特征存储。特征工程管道。](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)'
- en: '**Training Pipelines. ML Platforms. Hyperparameter Tuning.**'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练管道。ML平台。超参数调整。**'
- en: '[Batch Prediction Pipeline. Package Python Modules with Poetry.](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[批量预测管道。使用 Poetry 打包 Python 模块。](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)'
- en: '[Private PyPi Server. Orchestrate Everything with Airflow.](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[私有 PyPi 服务器。使用 Airflow 协调一切。](https://medium.com/towards-data-science/unlocking-mlops-using-airflow-a-comprehensive-guide-to-ml-system-orchestration-880aa9be8cff)'
- en: '[Data Validation for Quality and Integrity using GE. Model Performance Continuous
    Monitoring.](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[使用 GE 进行数据质量和完整性验证。模型性能持续监控。](/ensuring-trustworthy-ml-systems-with-data-validation-and-real-time-monitoring-89ab079f4360)'
- en: '[Consume and Visualize your Model’s Predictions using FastAPI and Streamlit.
    Dockerize Everything.](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[使用 FastAPI 和 Streamlit 消耗和可视化你的模型预测。将一切 Docker 化。](https://medium.com/towards-data-science/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243)'
- en: '[Deploy All the ML Components to GCP. Build a CI/CD Pipeline Using Github Actions.](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[将所有 ML 组件部署到 GCP。使用 GitHub Actions 构建 CI/CD 管道。](https://medium.com/towards-data-science/seamless-ci-cd-pipelines-with-github-actions-on-gcp-your-tools-for-effective-mlops-96f676f72012)'
- en: '[[Bonus] Behind the Scenes of an ‘Imperfect’ ML Project — Lessons and Insights](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[[附赠] ‘不完美’ ML 项目的幕后故事——课程和见解](https://medium.com/towards-data-science/imperfections-unveiled-the-intriguing-reality-behind-our-mlops-course-creation-6ff7d52ecb7e)'
- en: 'If you want to grasp this lesson fully, we recommend you check out the previous
    lesson, which talks about designing a batch-serving architecture, building a FE
    pipeline, and loading features into the feature store:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想充分掌握本课内容，我们建议您查看之前的课程，该课程讨论了设计批量服务架构、构建特征工程管道和将特征加载到特征存储中：
- en: '[](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f?source=post_page-----6fdaef594cee--------------------------------)
    [## A Framework for Building a Production-Ready Feature Engineering Pipeline'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 构建生产就绪特征工程管道的框架'
- en: 'Lesson 1: Batch Serving. Feature Stores. Feature Engineering Pipelines.'
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第1课：批量服务。特征存储。特征工程管道。
- en: towardsdatascience.com](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f?source=post_page-----6fdaef594cee--------------------------------)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f?source=post_page-----6fdaef594cee--------------------------------)'
- en: Data Source
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据来源
- en: We used a free & open API that provides hourly energy consumption values for
    all the energy consumer types within Denmark [1].
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个免费的开放 API，提供丹麦所有能源消费者类型的小时能耗值 [1]。
- en: They provide an intuitive interface where you can easily query and visualize
    the data. [You can access the data here](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1].
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 他们提供了一个直观的界面，您可以轻松查询和可视化数据。[您可以在这里访问数据](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour)
    [1]。
- en: 'The data has 4 main attributes:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有4个主要属性：
- en: '**Hour UTC:** the UTC datetime when the data point was observed.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小时 UTC：** 数据点观察到的 UTC 日期时间。'
- en: '**Price Area:** Denmark is divided into two price areas: DK1 and DK2 — divided
    by the Great Belt. DK1 is west of the Great Belt, and DK2 is east of the Great
    Belt.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价格区域：** 丹麦分为两个价格区域：DK1 和 DK2——由大贝尔特分隔。DK1 在大贝尔特以西，DK2 在大贝尔特以东。'
- en: '**Consumer Type:** The consumer type is the Industry Code DE35, owned and maintained
    by Danish Energy.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费者类型：** 消费者类型是由丹麦能源公司拥有和维护的行业代码 DE35。'
- en: '**Total Consumption:** Total electricity consumption in kWh'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总消耗：** 以 kWh 计的总电力消耗'
- en: '**Note:** The observations have a lag of 15 days! But for our demo use case,
    that is not a problem, as we can simulate the same steps as it would be in real-time.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 观察值有15天的滞后！但对于我们的演示用例来说，这不是问题，因为我们可以模拟实时中的相同步骤。'
- en: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0bc098121320b6b981889d8d712952d.png)'
- en: A screenshot from our web app showing how we forecasted the energy consumption
    for area = 1 and consumer_type = 212 [Image by the Author].
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 web 应用程序的截图，显示了我们如何预测区域 = 1 和消费者类型 = 212 的能耗 [作者图像]。
- en: 'The data points have an hourly resolution. For example: “2023–04–15 21:00Z”,
    “2023–04–15 20:00Z”, “2023–04–15 19:00Z”, etc.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点具有小时分辨率。例如：“2023–04–15 21:00Z”，“2023–04–15 20:00Z”，“2023–04–15 19:00Z”等。
- en: We will model the data as multiple time series. Each unique **price area** and
    **consumer type tuple represents its** unique time series.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据建模为多个时间序列。每个唯一的**价格区域**和**消费者类型**组合代表一个独特的时间序列。
- en: Thus, we will build a model that independently forecasts the energy consumption
    for the next 24 hours for every time series.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将构建一个模型，独立预测每个时间序列未来24小时的能耗。
- en: '*Check out the video below to better understand what the data looks like* 👇'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看下面的视频以更好地理解数据的样子* 👇'
- en: Course & data source overview [Video by the Author].
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 课程和数据源概述 [作者视频]。
- en: 'Lesson 2: **Training Pipelines. ML Platforms. Hyperparameter Tuning.**'
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2课：**训练管道。机器学习平台。超参数调整。**
- en: The Goal of Lesson 2
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2课的目标
- en: This lesson will teach you how to build the training pipeline and use an ML
    platform, as shown in the diagram below 👇
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 本课将教您如何构建训练管道并使用机器学习平台，如下图所示 👇
- en: '![](../Images/0596cb714571c8febed92fc310c1a6f4.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0596cb714571c8febed92fc310c1a6f4.png)'
- en: Diagram of the final architecture with the Lesson 2 components highlighted in
    blue [Image by the Author].
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最终架构图，带有第2课组件用蓝色突出显示 [作者图像]。
- en: More concretely, we will show you how to use the data from the Hopsworks feature
    store to train your model.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们将展示如何使用 Hopsworks 特征存储中的数据来训练您的模型。
- en: Also, we will show you how to build a forecasting model using LightGBM and Sktime
    that will predict the energy consumption levels for the next 24 hours between
    multiple consumer types across Denmark.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将展示如何使用 LightGBM 和 Sktime 构建一个预测模型，该模型将预测丹麦多个消费者类型未来24小时的能耗水平。
- en: Another critical step we will cover is how to use W&B as an ML platform that
    will track your experiments, register your models & configurations as artifacts,
    and perform hyperparameter tuning to find the best configuration for your model.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将覆盖的另一个关键步骤是如何使用 W&B 作为 ML 平台来跟踪你的实验，注册模型和配置为工件，并执行超参数调优以找到模型的最佳配置。
- en: Finally, based on the best config found in the hyperparameter tuning step, we
    will train the final model on the whole dataset and load it into the Hopsworks
    model registry to be used further by the batch prediction pipeline.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，根据超参数调优步骤中找到的最佳配置，我们将用整个数据集训练最终模型，并将其加载到 Hopsworks 模型注册表中，以便后续批量预测管道使用。
- en: '***NOTE:***This course is not about time series forecasting or hyperparameter
    tuning. This is an ML engineering course where I want to show you how multiple
    pieces come together into a single system. Thus, I will keep things straight to
    the point for the DS part of the code without going into too much detail.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意：*** 本课程不涉及时间序列预测或超参数调优。这是一门 ML 工程课程，我希望展示多个部分如何汇聚成一个完整的系统。因此，我将直接切入代码的
    DS 部分，而不深入细节。'
- en: Theoretical Concepts & Tools
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理论概念与工具
- en: '**Sktime:** Sktimeis a Python package that provides tons of functionality for
    time series. It follows the same interface as Sklearn, hence its name. Using Sktime,
    we can quickly wrap LightGBM and perform forecasting for 24 hours in the future,
    cross-validation, and more. [Sktime official documentation](https://www.sktime.net/en/latest/index.html)
    [3]'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sktime：** Sktime 是一个 Python 包，提供大量时间序列功能。它遵循与 Sklearn 相同的接口，因此得名。使用 Sktime，我们可以快速封装
    LightGBM 并执行未来 24 小时的预测、交叉验证等。[Sktime 官方文档](https://www.sktime.net/en/latest/index.html)
    [3]'
- en: '**LightGBM:** LightGBM is a boosting tree-based model. It is built on top of
    Gradient Boosting and XGBoost, offering performance and speed improvements. Starting
    with XGBoost or LightGBM is a common practice. [LightGBM official documentation](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)
    [4]'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**LightGBM：** LightGBM 是一个基于提升树的模型。它建立在梯度提升和 XGBoost 之上，提供性能和速度的提升。以 XGBoost
    或 LightGBM 开始是一个常见的做法。[LightGBM 官方文档](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)
    [4]'
- en: If you want to learn more about LightGBM, check out my article, where I [explain
    in 15 minutes everything you need to know, from decision trees to LightGBM](https://medium.com/mlearning-ai/decision-trees-from-0-to-xgboost-lightgbm-a5f6827dfa23).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于 LightGBM 的信息，可以查看我的文章，其中我 [在 15 分钟内解释了从决策树到 LightGBM 的一切](https://medium.com/mlearning-ai/decision-trees-from-0-to-xgboost-lightgbm-a5f6827dfa23)。
- en: '**ML Platform:** An ML platform is a tool that allows you to easily track your
    experiments, log metadata about your training, upload and version artifacts, data
    lineage and more. An ML platform is a must in any training pipeline. You can intuitively
    see an ML platform as your central research & experimentation hub.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**ML 平台：** ML 平台是一种工具，使你能够轻松跟踪实验、记录训练元数据、上传和版本化工件、数据血缘等。ML 平台在任何训练管道中都是必不可少的。你可以直观地将
    ML 平台视为你的中央研究与实验中心。'
- en: '**Weights & Biases:** W&B is a popular serverless ML platform. We choose them
    as our ML platform because of 3 main reasons:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**Weights & Biases：** W&B 是一个流行的无服务器 ML 平台。我们选择它作为我们的 ML 平台是因为 3 个主要原因：'
- en: their tool is fantastic & very intuitive to use
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他们的工具非常棒且非常直观。
- en: they provide a generous freemium version for personal research and projects
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它提供了慷慨的免费版供个人研究和项目使用。
- en: it is serverless — no pain in deploying & maintaining your tools
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它是无服务器的——无需担心部署和维护工具。
- en: '**Training Pipeline:** The training pipeline is a logical construct (a single
    script, an application, or more) that takes curated and validated data as input
    (a result from the data and feature engineering pipelines) and outputs a working
    model as an artifact. Usually, the model is uploaded into a model registry that
    can later be accessed by various inference pipelines (the batch prediction pipeline
    from our series is an example of a concrete implementation of an inference pipeline).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练管道：** 训练管道是一个逻辑结构（一个脚本、一个应用程序或更多），它接受经过策划和验证的数据作为输入（来自数据和特征工程管道的结果），并输出一个作为工件的工作模型。通常，模型会被上传到一个模型注册表中，后来可以被各种推理管道访问（我们系列中的批量预测管道是推理管道的具体实现示例）。'
- en: 'Lesson 2: Code'
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 2 课：代码
- en: '[You can access the GitHub repository here.](https://github.com/iusztinpaul/energy-forecasting)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[你可以在这里访问 GitHub 仓库。](https://github.com/iusztinpaul/energy-forecasting)'
- en: '**Note:** All the installation instructions are in the READMEs of the repository.
    Here we will jump straight to the code.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 所有安装说明都在仓库的 README 文件中。这里我们直接跳到代码部分。'
- en: '*All the code within Lesson 2 is located under the* [***training-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/training-pipeline)*folder.*'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*第2课中的所有代码都位于* [***training-pipeline***](https://github.com/iusztinpaul/energy-forecasting/tree/main/training-pipeline)*文件夹下。*'
- en: 'The files under the [**training-pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/training-pipeline)folderare
    structured as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[**training-pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/training-pipeline)
    文件夹中的文件结构如下：'
- en: '![](../Images/1df1548f211cb1fc256f23c4f77a28c4.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1df1548f211cb1fc256f23c4f77a28c4.png)'
- en: A screenshot that shows the structure of the training-pipeline folder [Image
    by the Author].
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 显示 training-pipeline 文件夹结构的截图 [作者提供的图片]。
- en: All the code is located under the [**training_pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/training-pipeline/training_pipeline)directory
    (note the "_" instead of "-")**.**
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码都位于 [**training_pipeline**](https://github.com/iusztinpaul/energy-forecasting/tree/main/training-pipeline/training_pipeline)目录下（注意使用"_"而非"-"）**。**
- en: Directly storing credentials in your git repository is a huge security risk.
    That is why you will inject sensitive information using a **.env** file.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 直接将凭证存储在你的 git 仓库中是一个巨大的安全隐患。这就是为什么你将通过 **.env** 文件注入敏感信息的原因。
- en: The **.env.default** is an example of all the variables you must configure.
    It is also helpful to store default values for attributes that are not sensitive
    (e.g., project name).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**.env.default** 是你必须配置的所有变量的示例。它还可以用来存储不敏感的属性的默认值（例如，项目名称）。'
- en: '![](../Images/1b4f40ca19a12ac8ff070610a8530d46.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1b4f40ca19a12ac8ff070610a8530d46.png)'
- en: A screenshot of the .env.default file [Image by the Author].
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: .env.default 文件的截图 [作者提供的图片]。
- en: '***Prepare Credentials***'
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '***准备凭证***'
- en: First of all, we have to create a **.env** filewhere we will add all our credentials.
    I already showed you in [Lesson 1](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)
    how to set up your **.env** file. Also, I explained in [Lesson 1](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)
    how the variables from the **.env** file are loaded from your **ML_PIPELINE_ROOT_DIR**
    directory into a **SETTINGS** Python dictionary to be used throughout your code.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须创建一个 **.env** 文件，添加所有凭证。我已经在 [第1课](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)中展示了如何设置
    **.env** 文件。另外，我在 [第1课](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)中解释了
    **.env** 文件中的变量如何从你的 **ML_PIPELINE_ROOT_DIR** 目录加载到 **SETTINGS** Python 字典中，以便在你的代码中使用。
- en: Thus, if you want to replicate what I have done, I strongly recommend checking
    out [Lesson 1](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你想复制我所做的工作，我强烈建议你查看 [第1课](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)。
- en: '*If you only want a light read, you can completely skip the “****Prepare Credentials****”
    step.*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你只想进行轻度阅读，可以完全跳过“****准备凭证****”步骤。*'
- en: 'In Lesson 2, we will use two services:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2课中，我们将使用两个服务：
- en: '[Hopsworks](https://www.hopsworks.ai/)'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Hopsworks](https://www.hopsworks.ai/)'
- en: '[Weights & Biases](https://wandb.ai/)'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Weights & Biases](https://wandb.ai/)'
- en: '[***Hopsworks***](https://www.hopsworks.ai/) ***(free)***'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[***Hopsworks***](https://www.hopsworks.ai/) ***(免费)***'
- en: We already showed you in [Lesson 1](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)
    how to set up the credentials for **Hopsworks**. Please visit the ["Prepare Credentials"
    section from Lesson 1](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f),
    where we showed you in detail how to set up the API KEY for Hopsworks.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在 [第1课](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)中展示了如何为
    **Hopsworks** 设置凭证。请访问 [第1课的“准备凭证”部分](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)，在那里我们详细介绍了如何为
    Hopsworks 设置 API KEY。
- en: '[***Weights & Biases***](https://wandb.ai/) ***(free)***'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[***Weights & Biases***](https://wandb.ai/) ***(免费)***'
- en: To keep the lessons compact, we assume that you already read and applied the
    steps for preparing the credentials for Hopsworks from [Lesson 1](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持课程简洁，我们假设你已经阅读并应用了[第1课](https://medium.com/towards-data-science/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)中准备Hopsworks凭据的步骤。
- en: The good news is that 90% of the steps are similar to the ones for configuring
    **Hopsworks**, except for how you can get your API key from W&B.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，90%的步骤与配置**Hopsworks**的步骤类似，除了如何从W&B获取API密钥。
- en: First, create an account on W&B. After, create a team (aka entity) and a project
    (or use your default ones, if you have any).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在W&B上创建一个账户。然后，创建一个团队（即实体）和一个项目（或者使用你已有的默认项目）。
- en: '***Then, check the image below to see how to get your own W&B API KEY 👇***'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '***然后，查看下面的图片，了解如何获取你自己的W&B API密钥 👇***'
- en: '![](../Images/42df4ffff19dc073c2ff162ff980c136.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/42df4ffff19dc073c2ff162ff980c136.png)'
- en: Go to your W&B account. After, in the top-right corner, click your profile account,
    then "User settings." Once in your user settings, scroll down until you reach
    the "Danger Zone" card. Then, under the "API keys," hit the "New key" button.
    Copy your API key, and that is it. You have your API key [Image by the Author].
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 前往你的W&B账户。在右上角，点击你的个人资料账户，然后选择“用户设置”。进入用户设置后，向下滚动直到你看到“危险区域”卡片。然后，在“API密钥”下，点击“新密钥”按钮。复制你的API密钥，就完成了。你现在有了你的API密钥
    [图片由作者提供]。
- en: 'Once you have all your W&B credentials, go to your **.env** file and replace
    them as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你拥有了所有的W&B凭据，前往你的**.env**文件并按如下方式替换它们：
- en: '**WANDB_ENTITY:** your entity/team name (ours: *“teaching-mlops”*)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WANDB_ENTITY：** 你的实体/团队名称（我们的：*“teaching-mlops”*）'
- en: '**WANDB_PROJECT:** your project name (ours: *“energy_consumption”*)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WANDB_PROJECT：** 你的项目名称（我们的：*“energy_consumption”*）'
- en: '**WANDB_API_KEY**: your API key'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WANDB_API_KEY**：你的API密钥'
- en: Loading the Data From the Feature Store
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从特征存储中加载数据
- en: As always, the first step is to access the data used to train and test the model.
    We already have all the data in the Hopsworks feature store. Thus, downloading
    it becomes a piece of cake.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，第一步是访问用于训练和测试模型的数据。我们已经在Hopsworks特征存储中拥有所有数据。因此，下载它变得轻而易举。
- en: The code snippet below has the **load_dataset_from_feature_store**() IO function
    under the [**training_pipeline/data.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/data.py)
    file. You will use this function to download the data for a given **feature_view_version**
    and **training_dataset_version.**
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码片段包含了**load_dataset_from_feature_store**() IO函数，它位于[**training_pipeline/data.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/data.py)文件中。你将使用这个函数下载特定的**feature_view_version**和**training_dataset_version**的数据。
- en: '**NOTE:** By giving a specific data version, you will always know with what
    data you trained and evaluated the model. Thus, you can consistently reproduce
    your results.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 通过提供特定的数据版本，你将始终知道你使用了哪些数据来训练和评估模型。因此，你可以一致地重现你的结果。'
- en: 'Using the function below, we perform the following steps:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用下面的函数，我们执行以下步骤：
- en: We access the Hopsworks feature store.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们访问Hopsworks特征存储。
- en: We get a reference to the given version of the feature view.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获取给定版本的特征视图的引用。
- en: We get a reference to the given version of the training data.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获取给定版本的训练数据的引用。
- en: We log to W&B all the metadata that relates to the used dataset.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将所有与使用的数据集相关的元数据记录到W&B。
- en: Now that we downloaded the dataset, we run it through the **prepare_data()**
    function. We will detail it a bit later. For now, notice that we split the data
    between train and test.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经下载了数据集，我们将其传递给**prepare_data()**函数。稍后我们将详细介绍它。目前，请注意我们将数据分为训练集和测试集。
- en: We log to W&B all the metadata related to how we split the dataset, plus some
    basic statistics for every split, such as split size and features.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将所有与数据集拆分相关的元数据记录到W&B中，以及每个拆分的一些基本统计信息，如拆分大小和特征。
- en: '**Important observation:** Using W&B, you log all the metadata that describes
    how you extracted and prepared the data. By doing so, you can easily understand
    for every experiment the origin of its data.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要观察：** 使用W&B，你可以记录所有描述你如何提取和准备数据的元数据。通过这样做，你可以轻松了解每次实验的数据来源。'
- en: By using **run.use_artifact("<artifact_name>"),** you can link different artifacts
    between them. In our example, by calling **run.use_artifact(“energy_consumption_denmark_feature_view:latest”)**
    we linked this W&B run with an artifact created in a different W&B run.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 **run.use_artifact("<artifact_name>")**，你可以在不同的工件之间建立联系。在我们的示例中，通过调用 **run.use_artifact(“energy_consumption_denmark_feature_view:latest”)**，我们将这个
    W&B 运行与在不同 W&B 运行中创建的工件关联起来。
- en: Check out the video below to see how the W&B runs & artifacts look like in the
    W&B interface 👇
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看下面的视频，以了解 W&B 运行和工件在 W&B 界面中的样子 👇
- en: W&B artifacts overview [Video by the Author].
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: W&B 工件概述 [作者的视频]。
- en: Now, let's dig into the **prepare_data()** function.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解 **prepare_data()** 函数。
- en: '*I want to highlight that in the* ***prepare_data()*** *function, we won''t
    perform any feature engineering steps.*'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*我想强调的是，在* ***prepare_data()*** *函数中，我们不会执行任何特征工程步骤。*'
- en: As you can see below, in this function, you will restructure the data to be
    compatible with the **sktime** interface, pick the target, and split the data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，在这个函数中，你将重构数据以兼容 **sktime** 界面，选择目标，并拆分数据。
- en: The data is modeled for hierarchical time series, translating to multiple independent
    observations of the same variable in different contexts. In our example, we observe
    the energy consumption for various areas and energy consumption types.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 数据被建模为层次时间序列，转化为同一变量在不同上下文中的多个独立观察。在我们的示例中，我们观察了不同区域和能源消耗类型的能源消耗情况。
- en: Sktime, for hierarchical time series, expects the data to be modeled using multi-indexes,
    where the datetime index is the last. To learn more about hierarchical forecasting,
    check out [Sktime's official tutorial](https://github.com/sktime/sktime/blob/main/examples/01c_forecasting_hierarchical_global.ipynb)
    [7].
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 对于层次时间序列，Sktime 期望数据使用多重索引建模，其中日期时间索引是最后一个。要了解更多有关层次预测的信息，请查看 [Sktime 官方教程](https://github.com/sktime/sktime/blob/main/examples/01c_forecasting_hierarchical_global.ipynb)
    [7]。
- en: Also, we can safely split the data using **sktime's temporal_train_test_split()**
    function. The test split has the length of the given **fh (=forecast horizon)**.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以安全地使用 **sktime's temporal_train_test_split()** 函数拆分数据。测试集的长度为给定的 **fh (=forecast
    horizon)**。
- en: One key observation is that the test split isn't sampled randomly but based
    on the latest observation. For example, if you have data from the 1st of May 2023
    until the 7th of May 2023 with a frequency of 1 hour, then the test split with
    a length of 24 hours will contain all the values from the last day of the data,
    which is 7th of May 2023.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键观察点是测试集拆分不是随机抽样的，而是基于最新的观察数据。例如，如果你的数据从 2023 年 5 月 1 日到 2023 年 5 月 7 日，频率为
    1 小时，则长度为 24 小时的测试集将包含数据的最后一天，即 2023 年 5 月 7 日的所有值。
- en: '**Building the Forecasting Model**'
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**构建预测模型**'
- en: '**Baseline model**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**基准模型**'
- en: Firstly, you will create a naive baseline model to use as a reference. This
    model predicts the last value based on a given seasonal periodicity.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你将创建一个朴素基准模型作为参考。该模型基于给定的季节性周期性预测最后一个值。
- en: For example, if **seasonal_periodicity = 24 hours**, it will return the value
    from "**present - 24 hours"**.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果 **seasonal_periodicity = 24 hours**，它将返回从“**当前 - 24 小时**”的值。
- en: Using a baseline is a healthy practice that helps you compare your fancy ML
    model to something simpler. The ML model is useless if you can't beat the baseline
    model with your fancy model.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基准模型是一个健康的实践，它可以帮助你将你的高级 ML 模型与更简单的模型进行比较。如果你不能用你的高级模型超越基准模型，那么 ML 模型是没有用的。
- en: '**Fancy ML model**'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**高级 ML 模型**'
- en: We will build the model using Sktime and LightGBM.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Sktime 和 LightGBM 来构建模型。
- en: Check out [Sktime documentation](https://www.sktime.net/en/latest/index.html)
    [3] and [LightGBM documentation](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)
    [4] here.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看 [Sktime 文档](https://www.sktime.net/en/latest/index.html) [3] 和 [LightGBM
    文档](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html) [4]。
- en: If you are into time series, check out this [Forecasting with Sktime tutorial](https://www.sktime.net/en/latest/examples/01_forecasting.html#1.-Basic-forecasting-workflows)
    [6]. If you only want to understand the system's big picture, you can continue.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对时间序列感兴趣，请查看这个 [Sktime 预测教程](https://www.sktime.net/en/latest/examples/01_forecasting.html#1.-Basic-forecasting-workflows)
    [6]。如果你只想了解系统的大致情况，你可以继续。
- en: LightGBM will be your regressor that learns patterns within the data and forecasts
    future values.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: LightGBM 将作为你的回归模型，用于学习数据中的模式并预测未来的值。
- en: Using the **WindowSummarizer** class from **Sktime,** you can quickly compute
    lags and mean & standard deviation for various windows.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 使用来自**Sktime**的**WindowSummarizer**类，你可以快速计算各种窗口的滞后和均值及标准差。
- en: For example, for the lag, we provide a default value of **list(range(1, 72 +
    1)),** which translates to "compute the lag for the last 72 hours".
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于滞后，我们提供了默认值**list(range(1, 72 + 1)),** 这意味着“计算过去72小时的滞后”。
- en: Also, as an example of the mean lag, we have the default value of **[[1, 24],
    [1, 48], [1, 72]].** For example, **[1, 24]** translates to a lag of 1 and a window
    size of 24, meaning it will compute the mean in the last 24 days. Thus, in the
    end, for **[[1, 24], [1, 48], [1, 72]],** you will have the mean for the last
    24, 46, and 72 days.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，作为均值滞后的示例，我们有默认值**[[1, 24], [1, 48], [1, 72]].** 例如，**[1, 24]** 表示滞后为1，窗口大小为24，这意味着它将计算过去24天的均值。因此，最终对于**[[1,
    24], [1, 48], [1, 72]],** 你将得到过去24天、46天和72天的均值。
- en: The same principle applies to the standard deviation values. [Check out this
    doc to learn more](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.transformations.series.summarize.WindowSummarizer.html?highlight=windowsummarizer)
    [2].
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的原则适用于标准差值。[查看此文档以了解更多](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.transformations.series.summarize.WindowSummarizer.html?highlight=windowsummarizer)
    [2]。
- en: You wrap the LightGBM model using the **make_reduction()** function from **Sktime.**
    By doing so, you can easily attach the **WindowSummarizer** you initialized earlier.
    Also, by specifying **strategy = "recursive",** you can easily forecast multiple
    values into the future using a recursive paradigm. For example, if you want to
    predict 3 hours into the future, the model will first forecast the value for T
    + 1\. Afterward, it will use as input the value it forecasted at T + 1 to forecast
    the value at T + 2, and so on…
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用**Sktime**中的**make_reduction()**函数来包装LightGBM模型。通过这样做，你可以轻松附加之前初始化的**WindowSummarizer**。此外，通过指定**strategy
    = "recursive"**，你可以使用递归范式轻松预测多个未来值。例如，如果你想预测未来3小时，模型将首先预测T + 1的值。然后，它将使用T + 1预测的值作为输入来预测T
    + 2的值，以此类推……
- en: 'Finally, we will build the **ForecastingPipeline** where we will attach two
    transformers:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将构建**ForecastingPipeline**，在其中附加两个转换器：
- en: '**transformers.AttachAreaConsumerType():** a custom transformer that takes
    the area and consumer type from the index and adds it as an exogenous variable.
    We will show you how we defined it.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**transformers.AttachAreaConsumerType():** 一个自定义转换器，它从索引中提取区域和消费者类型，并将其作为外生变量添加。我们将向你展示我们如何定义它。'
- en: '**DateTimeFeatures():** a transformer from **Sktime** that computes different
    datetime-related exogenous features. In our case, we used only the day of the
    week and the hour of the day as additional features.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**DateTimeFeatures():** 一个来自**Sktime**的转换器，用于计算不同的与日期时间相关的外生特征。在我们的案例中，我们仅使用了星期几和一天中的小时作为额外特征。'
- en: Note that these transformers are similar to the ones from **Sklearn,** as **Sktime**
    kept the same interface and design. Using transformers is a critical step in designing
    modular models. To learn more about Sklearn transformers and pipelines, check
    out my article about [How to Quickly Design Advanced Sklearn Pipelines](/how-to-quickly-design-advanced-sklearn-pipelines-3cc97b59ce16).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些转换器类似于**Sklearn**中的那些，因为**Sktime**保持了相同的接口和设计。使用转换器是设计模块化模型中的关键步骤。要了解更多关于Sklearn转换器和管道的内容，请查看我的文章：[如何快速设计高级Sklearn管道](/how-to-quickly-design-advanced-sklearn-pipelines-3cc97b59ce16)。
- en: Finally, we initialized the hyperparameters of the pipeline and model with the
    given configuration.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们用给定的配置初始化了管道和模型的超参数。
- en: The **AttachAreaConsumerType** transformer is quite easy to comprehend. We implemented
    it as an example to show what is possible.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**AttachAreaConsumerType**转换器很容易理解。我们将其实现为一个示例，展示其可能性。'
- en: Long story short, it just copies the values from the index into its own column.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 长话短说，它只是将索引中的值复制到它自己的列中。
- en: '**IMPORTANT OBSERVATION — DESIGN DECISION**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要观察——设计决策**'
- en: As you can see, all the feature engineering steps are built-in into the forecasting
    pipeline object.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，所有的特征工程步骤都内置在预测管道对象中。
- en: 'You might ask: "But why? By doing so, don''t we keep the feature engineering
    logic in the training pipeline?"'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问：“但为什么？这样做，我们不是将特征工程逻辑保留在训练流程中吗？”
- en: Well, yes… and no…
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，是的……也不是……
- en: We indeed defined the forecasting pipeline in the training script, but the key
    idea is that we will save the whole forecasting pipeline to the model registry.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实在训练脚本中定义了预测管道，但关键思想是我们将整个预测管道保存到模型注册表中。
- en: Thus, when we load the model, we will also load all the preprocessing and postprocessing
    steps included in the forecasting pipeline.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们加载模型时，也会加载预测管道中包含的所有预处理和后处理步骤。
- en: This means all the feature engineering is encapsulated in the forecasting pipeline,
    and we can safely treat it as a black box.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着所有的特征工程都封装在预测管道中，我们可以安全地将其视为一个黑箱。
- en: This is one way to store the transformation + the raw data in the feature store,
    as discussed in [Lesson 1](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种将转换 + 原始数据存储在特征存储中的方式，如[Lesson 1](/a-framework-for-building-a-production-ready-feature-engineering-pipeline-f0b29609b20f)中讨论的那样。
- en: We could have also stored the transformation functions independently in the
    feature store, but composing a single pipeline object is cleaner.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们本来也可以在特征存储中独立存储转换函数，但组合一个单一的管道对象会更简洁。
- en: Hyperparameter Tuning
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数调整
- en: '**How to use W&B sweeps**'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用W&B sweeps**'
- en: You will use W&B to perform hyperparameter tuning. They provide all the methods
    you need. Starting from a regular Grid Search until a Bayesian Search.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用W&B进行超参数调整。他们提供了你需要的所有方法。从常规的网格搜索到贝叶斯搜索。
- en: W&B uses ***sweeps*** to do hyperparameter tuning. A sweep is a fancy word for
    a single experiment within multiple experiments based on your hyperparameter search
    space.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: W&B使用***sweeps***来进行超参数调整。sweep是指在基于超参数搜索空间的多个实验中的单个实验的高级术语。
- en: We will use the MAPE (mean absolute percentage error) metric to compare experiments
    to find the best hyperparameter configuration. We chose MAPE over MAE or RMSE
    because the values are normalized between [0, 1], thus making it easier to analyze.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用MAPE（平均绝对百分比误差）指标来比较实验，以找到最佳的超参数配置。我们选择MAPE而不是MAE或RMSE，因为它的值在[0, 1]之间归一化，从而使分析更为容易。
- en: Check out the video below to see how the sweeps board looks in W&B 👇
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 查看下面的视频，了解W&B中的sweeps面板的样子 👇
- en: Now that we understand our goal let's look at the code under the [**training_pipeline/hyperparamter_tuning.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/hyperparameter_tuning.py)
    file.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们明白了我们的目标，让我们查看[**training_pipeline/hyperparamter_tuning.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/hyperparameter_tuning.py)文件中的代码。
- en: As you can see in the function below, we load the dataset from the feature store
    for a specific **feature_view_version** and a **training_dataset_version.**
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如下函数所示，我们从特征存储中加载特定**feature_view_version**和**training_dataset_version**的数据集。
- en: Using solely the training data, we start the hyperparameter optimization.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用训练数据，我们开始进行超参数优化。
- en: '**Note:** It is essential that you don''t use your test data for your hyperparameter
    optimization search. Otherwise, you risk overfitting your test split, and your
    model will not generalize. Your test split should be used only for the final decision.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 你必须确保不要使用测试数据进行超参数优化搜索。否则，你可能会导致测试拆分过拟合，从而使模型无法泛化。测试拆分应仅用于最终决策。'
- en: Finally, we save the metadata of the run, which contains the **sweep_id** of
    the search.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们保存运行的元数据，其中包含搜索的**sweep_id**。
- en: Now, let's look at the **run_hyperparameter_optimization()** function, which
    takes the training data, creates a new sweep and starts a W&B agent.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下**run_hyperparameter_optimization()**函数，它接收训练数据，创建一个新的sweep并启动一个W&B代理。
- en: Within a single sweep run, we build the model and train the model using cross-validation.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在单次sweep运行中，我们构建模型并使用交叉验证训练模型。
- en: As you can see, the config is provided by W&B based on the given hyperparameter
    search space (we will explain this in a bit). Also, we log the config as an artifact
    to access it later.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，配置由W&B提供，基于给定的超参数搜索空间（稍后我们会详细解释）。此外，我们将配置作为一个工件进行日志记录，以便以后访问。
- en: In our example, we used a simple grid search to perform hyperparameter tuning.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们使用了简单的网格搜索来进行超参数调整。
- en: As you can see below, we created a Python dictionary called **sweep_config**
    with themethod, the metric to minimize, and the parameters to search for.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，我们创建了一个名为**sweep_config**的Python字典，其中包含了方法、需要最小化的指标和要搜索的参数。
- en: '[Check out W&B official docs to learn more about sweeps](https://docs.wandb.ai/guides/sweeps)
    [5].'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看W&B官方文档以了解更多关于扫频的信息](https://docs.wandb.ai/guides/sweeps) [5]。'
- en: '**Note:** With a few tweaks, you can quickly run multiple W&B agents in parallel
    within a single sweep. Thus, speeding up the hyperparameter tuning drastically.
    [Check out their docs if you want to learn more](https://docs.wandb.ai/guides/sweeps/parallelize-agents)
    [5].'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 通过一些调整，你可以在单个扫频中快速并行运行多个W&B代理。因此，显著加快了超参数调优的速度。[如果你想了解更多，请查看他们的文档](https://docs.wandb.ai/guides/sweeps/parallelize-agents)
    [5]。'
- en: '**How to do cross-validation with time series data**'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何对时间序列数据进行交叉验证**'
- en: So, I highlighted that it is critical to do hyperparameter-tuning only using
    the training dataset.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我强调了只使用训练数据集进行超参数调优是至关重要的。
- en: But then, on what split should you compute your metrics?
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，应该在什么拆分上计算你的指标呢？
- en: Well, you will be using cross-validation adapted to time series.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，你将使用适应于时间序列的交叉验证。
- en: As shown in the image below, we used a 3-fold cross-validation technique. The
    key idea is that because you are using time series data, you can't pick the whole
    dataset for every fold. It makes sense, as you can't learn from the future to
    predict the past.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，我们使用了3折交叉验证技术。关键点是，由于你使用的是时间序列数据，你不能为每个折叠选择整个数据集。这是合理的，因为你不能从未来学习以预测过去。
- en: Thus, using the same principles as when we split the data between train and
    test, we sample 1/3 from the beginning of the dataset, where the **forecasting
    horizon (the orange segment)** is used to compute the validation metric. The next
    fold takes 2/3, and the last one 3/3 of the dataset.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用与我们拆分数据集进行训练和测试时相同的原则，我们从数据集开始的1/3中抽样，其中**预测范围（橙色部分）**用于计算验证指标。下一个折叠使用2/3，最后一个折叠使用3/3的数据集。
- en: '![](../Images/f6149c500f3a27660f20c03f1fc9d6c2.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6149c500f3a27660f20c03f1fc9d6c2.png)'
- en: Once again, **Sktime** makes our lives easier. Using the **ExpandingWindowSplitter**
    class and **cv_evaluate()** function, you can quickly train and evaluate the model
    using the specified cross-validation strategy — [official docs here](https://github.com/sktime/sktime/blob/main/examples/window_splitters.ipynb)
    [8]
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，**Sktime**让我们的生活变得更简单。使用**ExpandingWindowSplitter**类和**cv_evaluate()**函数，你可以快速训练和评估模型，使用指定的交叉验证策略——[官方文档在这里](https://github.com/sktime/sktime/blob/main/examples/window_splitters.ipynb)
    [8]。
- en: In the end, we restructured the **results** DataFrame, which the **cv_evaluate()**
    function returned to fit our interface.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们重构了**results**数据框，使其适应我们的接口，这个数据框是**cv_evaluate()**函数返回的。
- en: Excellent, now you finished running your hyperparameter tuning step using W&B
    sweeps.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，现在你已经完成了使用W&B扫频的超参数调优步骤。
- en: At the end of this step, we have a **sweep_id** that has attached multiple experiments,
    where each experiment has a **config artifact.**
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步结束时，我们有一个附加了多个实验的**sweep_id**，每个实验都有一个**config artifact**。
- en: Now we have to parse this information and create a **best_config artifact.**
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们必须解析这些信息并创建一个**best_config artifact**。
- en: Upload the Best Configuration from the Hyperparameter Tuning Search
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从超参数调优搜索中上传最佳配置
- en: Using the [**training_pipeline/best_config.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/best_config.py)script,
    we will parse all the experiments for the given **sweep_id** and find the best
    experiment with the lowest MAPE validation score.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[**training_pipeline/best_config.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/best_config.py)脚本，我们将解析给定**sweep_id**的所有实验，并找到具有最低MAPE验证分数的最佳实验。
- en: Fortunately, this is done automatically by W&B when we call the **best_run()**
    function. After, you resume the **best_run** and rename the run to **best_experiment.**
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，当我们调用**best_run()**函数时，W&B会自动完成这项工作。之后，你恢复**best_run**并将运行重命名为**best_experiment**。
- en: Also, you upload the config attached to the best configuration into its artifact
    called **best_config.**
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，你将附加到最佳配置的配置上传到其称为**best_config**的artifact中。
- en: Later, we will use this artifact to train models from scratch as often as we
    want.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将使用这个artifact从头开始训练模型，无论多少次。
- en: Now you have the **best_config** artifact that tells you precisely what hyperparameters
    you should use to train your final model on.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了**best_config** artifact，它准确地告诉你应使用什么超参数来训练你的最终模型。
- en: Train the Final Model Using the Best Configuration
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用最佳配置训练最终模型
- en: Finally, training and loading the final model to the model registry is the last
    piece of the puzzle.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，将最终模型训练并加载到模型注册表是最后一步。
- en: 'Within the **from_best_config()** function from the [**training_pipeline/train.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/train.py)file,
    we perform the following steps:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在[**training_pipeline/train.py**](https://github.com/iusztinpaul/energy-forecasting/blob/main/training-pipeline/training_pipeline/train.py)
    文件中的 **from_best_config()** 函数中，我们执行以下步骤：
- en: Load the data from Hopsworks.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Hopsworks 加载数据。
- en: Initialize a W&B run.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 W&B 运行。
- en: Load the best_config artifact.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载最佳配置工件。
- en: Build the baseline model.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建基线模型。
- en: Train and evaluate the baseline model on the test split.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上训练和评估基线模型。
- en: Build the fancy model using the latest best configuration.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用最新的最佳配置构建高级模型。
- en: Train and evaluate the fancy model on the test split.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上训练和评估高级模型。
- en: Render the results to see how they perform visually.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 渲染结果以查看它们的视觉表现。
- en: Retrain the model on the whole dataset. This is critical for time series models
    as you must retrain them until the present moment to forecast the future.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在整个数据集上重新训练模型。这对时间序列模型至关重要，因为你必须将它们重新训练到当前时刻，以预测未来。
- en: Forecast future values.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测未来值。
- en: Render the forecasted values.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 渲染预测值。
- en: Save the best model as an Artifact in W&B
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最佳模型保存为 W&B 中的工件。
- en: Save the best model in the Hopsworks' model registry
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最佳模型保存在 Hopsworks 的模型注册表中。
- en: '**Note:** You can either use W&B Artifacts as a model registry or directly
    use the Hopsworks model registry feature. We will show you how to do it both ways.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 你可以使用 W&B Artifacts 作为模型注册表，也可以直接使用 Hopsworks 模型注册功能。我们将展示这两种方法。'
- en: '*Notice how we used* ***wandb.log()*** *to upload to W&B all the variables
    of interest.*'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意我们如何使用* ***wandb.log()*** *将所有感兴趣的变量上传到 W&B。*'
- en: Check out this video to visually see how we use W&B as an experiment tracker
    👇
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这个视频，直观地了解我们如何使用 W&B 作为实验跟踪器 👇
- en: '**Train & evaluate the model.**'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练和评估模型。**'
- en: To train any **Sktime** model, we implemented this general function that takes
    in any model, the data, and the forecast horizon.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练任何**Sktime**模型，我们实现了这个通用函数，接受任何模型、数据和预测范围。
- en: Using the method below, we evaluated the model on the test split using both
    aggregated metrics and slices over all the unique combinations of areas and consumer
    types.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 使用下述方法，我们通过聚合指标和在所有独特的区域和消费者类型组合上切片来评估模型。
- en: By evaluating the model on slices, you can quickly investigate for fairness
    and bias.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在切片上评估模型，你可以快速调查公平性和偏差。
- en: As you can see, most of the heavy lifting, such as the implementation of MAPE
    and RMSPE, is directly accessible from **Sktime**.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，大部分繁重的工作，例如 MAPE 和 RMSPE 的实现，都可以直接从**Sktime**中访问。
- en: '**Render the results**'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '**渲染结果**'
- en: Using **Sktime,** you can quickly render various time series into a single plot.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**Sktime**，你可以快速将各种时间序列渲染到一个图表中。
- en: As shown in the video above, we rendered the results for every (area, consumer_type)
    combination in the W&B experiment tracker.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如上视频所示，我们在 W&B 实验跟踪器中渲染了每个（区域，消费者类型）组合的结果。
- en: '![](../Images/c490f268faaed419d02eeec4355a86f9.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c490f268faaed419d02eeec4355a86f9.png)'
- en: Visually comparing the prediction and real observations for area = 2 and consumer
    type = 119 [Image by the Author].
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 直观比较区域 = 2 和消费者类型 = 119 的预测与实际观察 [作者提供的图片]。
- en: '![](../Images/d681a7c647abe694bb25917c6cb84b61.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d681a7c647abe694bb25917c6cb84b61.png)'
- en: Visually observing forecasted values into the future for area = 2 and consumer
    type = 119 [Image by the Author].
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 直观观察未来的预测值，对于区域 = 2 和消费者类型 = 119 [作者提供的图片]。
- en: '**Upload the model to the model registry**'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '**将模型上传到模型注册表**'
- en: The last step is to upload the model to a model registry. After the model is
    uploaded, it will be downloaded and used by our batch prediction pipeline.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将模型上传到模型注册表。上传后，模型将被下载并用于我们的批量预测管道。
- en: During the experiment, we already uploaded the model as a W&B Artifact. If you
    plan to have dependencies with W&B in your applications, using it directly from
    there is perfectly fine.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验过程中，我们已经将模型上传为 W&B 工件。如果你计划在应用程序中依赖 W&B，直接使用它是完全可以的。
- en: But we wanted to keep the batch prediction pipeline dependent only on Hopsworks.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们希望保持批量预测管道仅依赖 Hopsworks。
- en: Thus, we used Hopswork's model registry feature.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用了 Hopswork 的模型注册功能。
- en: In the following code, based on the given **best_model_artifact,** we added
    a tag to the Hopsworks feature view to link the two. This is helpful for debugging.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，基于给定的**best_model_artifact**，我们在 Hopsworks 特征视图中添加了一个标签，以将两者链接起来。这有助于调试。
- en: Finally, we downloaded the best model weights and loaded them to the Hopsworks
    model registry using the **mr.python.create_model()** method.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们下载了最佳模型权重，并使用 **mr.python.create_model()** 方法将其加载到 Hopsworks 模型注册表中。
- en: Now with a few lines of code, you can download and run inference on your model
    without carrying any more about all the complicated steps we showed you in this
    lesson.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过几行代码，你可以下载并对你的模型进行推断，而无需再担心我们在本课中展示的所有复杂步骤。
- en: '[Check out Lesson 3](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)
    to see how we will build a batch prediction pipeline using the model from the
    Hopsworks model registry.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看第 3 课](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)
    以了解我们将如何使用来自 Hopsworks 模型注册表的模型构建批量预测流程。'
- en: Conclusion
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Congratulations! You finished the **second lesson** from the **Full Stack 7-Steps
    MLOps Framework** course.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你完成了 **第二课** 来自 **全栈 7 步 MLOps 框架** 课程。
- en: 'If you have reached this far, you know how to:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经读到这里，你应该知道如何：
- en: use an ML platform for experiment & metadata tracking
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 ML 平台进行实验和元数据跟踪
- en: use an ML platform for hyperparameter tuning
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 ML 平台进行超参数调优
- en: read data from the feature store based on a given version
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据给定版本从特征存储中读取数据
- en: build an encapsulated ML model and pipeline
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个封装的 ML 模型和流程
- en: upload your model to a model registry
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将你的模型上传到模型注册表
- en: Now that you understand the power of using an ML platform, you can finally take
    control over your experiments and quickly export your model as an artifact to
    be easily used in your inference pipelines.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你了解了使用 ML 平台的强大功能，你可以最终掌控你的实验，并快速将你的模型导出为工件，以便在推断流程中轻松使用。
- en: '[Check out Lesson 3](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)
    to learn about implementing a batch prediction pipeline and packaging your Python
    modules using Poetry.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看第 3 课](https://medium.com/towards-data-science/unlock-the-secret-to-efficient-batch-prediction-pipelines-using-python-a-feature-store-and-gcs-17a1462ca489)
    以了解如何实现批量预测流程和使用 Poetry 打包你的 Python 模块。'
- en: '**Also,** [**you can access the GitHub repository here**](https://github.com/iusztinpaul/energy-forecasting)**.**'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**另外，** [**你可以在这里访问 GitHub 仓库**](https://github.com/iusztinpaul/energy-forecasting)**。**'
- en: 💡 My goal is to help machine learning engineers level up in designing and productionizing
    ML systems. Follow me on [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    or subscribe to my [weekly newsletter](https://pauliusztin.substack.com/) for
    more insights!
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 💡 我的目标是帮助机器学习工程师在设计和生产 ML 系统方面提升水平。关注我在 [LinkedIn](https://www.linkedin.com/in/pauliusztin/)
    或订阅我的 [每周通讯](https://pauliusztin.substack.com/) 获取更多见解！
- en: 🔥 If you enjoy reading articles like this and wish to support my writing, consider
    [becoming a Medium member](https://pauliusztin.medium.com/membership). By using
    [my referral link](https://pauliusztin.medium.com/membership), you can support
    me without any extra cost while enjoying limitless access to Medium’s rich collection
    of stories.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 🔥 如果你喜欢阅读这样的文章并希望支持我的写作，可以考虑 [成为 Medium 会员](https://pauliusztin.medium.com/membership)。通过使用
    [我的推荐链接](https://pauliusztin.medium.com/membership)，你可以在享受 Medium 丰富故事内容的同时，支持我而无需额外费用。
- en: '[](https://pauliusztin.medium.com/membership?source=post_page-----6fdaef594cee--------------------------------)
    [## Join Medium with my referral link - Paul Iusztin'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pauliusztin.medium.com/membership?source=post_page-----6fdaef594cee--------------------------------)
    [## 使用我的推荐链接加入 Medium - Paul Iusztin'
- en: 🤖 Join to get exclusive content about designing and building production-ready
    ML systems 🚀 Unlock full access to…
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 🤖 加入以获取关于设计和构建生产就绪 ML 系统的独家内容 🚀 解锁完整访问权…
- en: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----6fdaef594cee--------------------------------)
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: pauliusztin.medium.com](https://pauliusztin.medium.com/membership?source=post_page-----6fdaef594cee--------------------------------)
- en: References
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [Energy Consumption per DE35 Industry Code from Denmark API](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [Denmark Energy Data Service](https://www.energidataservice.dk/about/)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [来自丹麦 API 的每小时能源消耗数据](https://www.energidataservice.dk/tso-electricity/ConsumptionDE35Hour),
    [丹麦能源数据服务](https://www.energidataservice.dk/about/)'
- en: '[2] [WindowSummarizer Documentation](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.transformations.series.summarize.WindowSummarizer.html?highlight=windowsummarizer),
    Sktime Documentation'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [WindowSummarizer 文档](https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.transformations.series.summarize.WindowSummarizer.html?highlight=windowsummarizer)，Sktime
    文档'
- en: '[3] [Sktime Documentation](https://www.sktime.net/en/latest/index.html)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [Sktime 文档](https://www.sktime.net/en/latest/index.html)'
- en: '[4] [LightGBM Documentation](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] [LightGBM 文档](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html)'
- en: '[5] [W&B Sweeps Documentation](https://docs.wandb.ai/guides/sweeps), W&B Documentation'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] [W&B Sweeps 文档](https://docs.wandb.ai/guides/sweeps)，W&B 文档'
- en: '[6] [Sktime Forecasting Tutorial](https://www.sktime.net/en/latest/examples/01_forecasting.html#1.-Basic-forecasting-workflows),
    Sktime Documentation'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] [Sktime 预测教程](https://www.sktime.net/en/latest/examples/01_forecasting.html#1.-Basic-forecasting-workflows)，Sktime
    文档'
- en: '[7] [Sktime Hierarchical, Global, and Panel Forecasting Tutorial](https://github.com/sktime/sktime/blob/main/examples/01c_forecasting_hierarchical_global.ipynb),
    Sktime Documentation'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '[7] [Sktime 分层、全球和面板预测教程](https://github.com/sktime/sktime/blob/main/examples/01c_forecasting_hierarchical_global.ipynb)，Sktime
    文档'
- en: '[8] [Sktime Window Splitters Tutorial](https://github.com/sktime/sktime/blob/main/examples/window_splitters.ipynb),
    Sktime Documentation'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '[8] [Sktime 窗口分割器教程](https://github.com/sktime/sktime/blob/main/examples/window_splitters.ipynb)，Sktime
    文档'
