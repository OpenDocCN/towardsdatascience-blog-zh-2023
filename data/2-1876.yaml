- en: 'Sklearn Tutorial: Module 2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sklearn 教程：第 2 章
- en: 原文：[https://towardsdatascience.com/sklearn-tutorial-module-2-0739c44f595a](https://towardsdatascience.com/sklearn-tutorial-module-2-0739c44f595a)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/sklearn-tutorial-module-2-0739c44f595a](https://towardsdatascience.com/sklearn-tutorial-module-2-0739c44f595a)
- en: I took the official sklearn MOOC tutorial. Here are my takeaways.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我参加了官方的 sklearn MOOC 教程。这是我的收获。
- en: '[](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)[![Yoann
    Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----0739c44f595a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----0739c44f595a--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)[![Yoann
    Mocquin](../Images/b30a0f70c56972aabd2bc0a74baa90bb.png)](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----0739c44f595a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----0739c44f595a--------------------------------)
    [Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----0739c44f595a--------------------------------)
    ·14 min read·Nov 25, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----0739c44f595a--------------------------------)
    ·14分钟阅读·2023年11月25日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: After years of playing with the Python scientific stack (NumPy, Matplotlib,
    SciPy, Pandas, and Seaborn), it became obvious to me that the next step was scikit-learn,
    or “sklearn”.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在多年使用 Python 科学计算栈（NumPy、Matplotlib、SciPy、Pandas 和 Seaborn）之后，我明显感觉到下一步是 scikit-learn，即“sklearn”。
- en: '![](../Images/12ce198b8d409170b76046f45bd4f12c.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12ce198b8d409170b76046f45bd4f12c.png)'
- en: Photo by [Nick Morrison](https://unsplash.com/@nickmorrison?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Nick Morrison](https://unsplash.com/@nickmorrison?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: This second module focuses on the concept of models scores, including the test
    score and train score. Those scores are then used to define overfitting and underfitting,
    as well as the concepts of bias and variance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个模块侧重于模型分数的概念，包括测试分数和训练分数。这些分数用于定义过拟合和欠拟合，以及偏差和方差的概念。
- en: We’ll also see how to inspect model’s performance with respect to their complexity
    and the number of input samples.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将了解如何根据模型的复杂性和输入样本的数量来检查模型的性能。
- en: '*All images by author.*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有图片由作者提供。*'
- en: 'If you didn’t catch it, I strongly recommend my first post of this series —
    it’ll be way easier to follow along:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有看到，我强烈推荐你查看本系列的第一篇文章——这样会更容易跟上：
- en: '[](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----0739c44f595a--------------------------------)
    [## Sklearn Tutorial: Module 1'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----0739c44f595a--------------------------------)
    [## Sklearn 教程：第 1 章'
- en: I took the official sklearn MOOC tutorial. Here are my takeaways.
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我参加了官方的 sklearn MOOC 教程。这是我的收获。
- en: towardsdatascience.com](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----0739c44f595a--------------------------------)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/sklearn-tutorial-module-1-f31b3964a3b4?source=post_page-----0739c44f595a--------------------------------)
- en: '**Score: train score and test score**'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**分数：训练分数和测试分数**'
- en: 'The first concept I want to talk about are **train score and test score**.
    **The score is a way to numericaly express the performance of a model**. To compute
    such performance, we use a score function, that aggregates the “distance” or “error”
    between what the model predicted versus what the ground truth is. For example:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我想讨论的第一个概念是**训练分数和测试分数**。**分数是以数字形式表达模型性能的一种方式**。为了计算这种性能，我们使用分数函数，该函数聚合了模型预测与实际值之间的“距离”或“误差”。例如：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In sklearn, all models (also called estimators) provide an even quicker way
    to compute a score using the model:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在 sklearn 中，所有模型（也称为估算器）提供了一种更快捷的方式来计算模型的分数：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**The actual score function of the model depends on the model and the kind
    of problem it is designed to solve**. For example a linear regressor is the R²
    coefficient (numerical regression) while a support-verctor classifier (classication)
    will use the accuracy which is basicaly the number of good class-prediction.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型的实际评分函数依赖于模型及其设计解决的问题类型**。例如，线性回归器使用的是R²系数（数值回归），而支持向量分类器（分类）则使用准确率，这基本上是正确分类预测的数量。'
- en: 'If the default score of the model doesn’t fit your need, you can also import
    score function from sklearn’s metrics. Numerous score functions can be used to
    compute the score of a model, each with their pros and cons. They are available
    in sklearn.metrics module:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型的默认评分不符合您的需求，您还可以从sklearn的metrics导入评分函数。许多评分函数可以用于计算模型的评分，每种都有其优缺点。它们在sklearn.metrics模块中可用：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'So remember for what follows: from a dataset, we create a train set and a test
    set. After training the model, we can compute a score both ot the train set and
    test set to estimate the performance of the fitted model.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以请记住以下内容：从数据集中，我们创建一个训练集和一个测试集。训练模型后，我们可以计算训练集和测试集上的评分，以估计拟合模型的性能。
- en: Given a fixed input dataset, these scores depend on the choice of model, the
    parameters of that model (like the degree for a polynomial fit for example), the
    way we split that dataset (which sample goes into which set) and the choice of
    the score function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个固定的输入数据集，这些分数依赖于模型的选择、该模型的参数（例如多项式拟合的度数）、我们如何划分数据集（哪个样本进入哪个集合）以及评分函数的选择。
- en: It was important to introduce the test and train scores, because those concepts
    are usefull to inspect the “fitting state” - over or under-fitting- of a model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 引入测试和训练得分很重要，因为这些概念用于检查模型的“拟合状态”——过拟合或欠拟合。
- en: '**Relation between over/under-fitting and train/test-score**'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**过拟合/欠拟合与训练/测试得分的关系**'
- en: 'Remember from the previous the rationale behind splitting and cross-validation:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住之前拆分和交叉验证背后的原理：
- en: '**splitting**: allows to esimate the generalization performances'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拆分**：可以估计模型的泛化性能。'
- en: '**cross-validation**: estimate the robustness of the generalization, evens
    out the luck/no-luck in a single split'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交叉验证**：估计泛化的稳健性，平衡单次拆分中的运气/非运气。'
- en: 'Also, remember that in the process of cross-validation, different splits are
    used, but the rest of the process is the same: once split, train the model on
    the train set, and we can then compute the scores of that model (train score and
    test score).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，请记住，在交叉验证过程中使用了不同的拆分，但其余的过程是相同的：拆分后，在训练集上训练模型，然后我们可以计算该模型的评分（训练得分和测试得分）。
- en: That being said, let’s define what over-fitting and under-fitting mean. As their
    name suggest, they correspond to opposite state of your model, relative to the
    dataset at stake.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 既然如此，让我们定义什么是过拟合和欠拟合。顾名思义，它们对应于模型相对于相关数据集的对立状态。
- en: '**We say a trained model is over-fitted** if it learned to much the dataset
    it was trained on, and hence lacks generalization abilities. This can be seen
    when the train score is very good (the model make very little error on the data
    it was trained on) but the test score is bad, so it is not good at generazlization.
    This can happen if the model is too complex/flexible (a very high degree polynom
    for example), if the trainset was too small or is very noisy. In this case, small
    changes in the train set imply big changes in the test predictions.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**我们说一个训练好的模型过拟合**，如果它对训练数据学习得太多，从而缺乏泛化能力。当训练得分非常好（模型在训练数据上几乎没有错误）但测试得分很差时，可以看出这一点，因此它在泛化方面表现不佳。这可能发生在模型过于复杂/灵活（例如，非常高的多项式度数）、训练集太小或噪声很大时。在这种情况下，训练集的小变化会导致测试预测的重大变化。'
- en: '**On the other hand, a trained model is under-fitted** if it only focuses on
    very general global trend and not enough on details. This can be seen when the
    train score is not good enough, meaning that the model didn’t have the flexibility
    to learn the complexity of the data. This happens when the model is not flexible
    enough (we also say the model is too “constrained”), which can be a consequence
    of the choice of the model or of its parameters (like setting a 1-degree polynom
    to fit a 10-degree problem).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**另一方面，如果训练模型只是关注非常一般的全局趋势而忽略细节，模型则会出现欠拟合**。当训练分数不够好时就能看出这一点，这意味着模型没有足够的灵活性来学习数据的复杂性。这通常发生在模型不够灵活时（我们也说模型过于“受限”），这可能是模型选择或其参数（例如，将1度多项式用于拟合10度问题）选择的结果。'
- en: Our job is to find the sweet-middle spot, where there’s the best trade-off between
    over and underfitting, by tuning the model — in the very general way, including
    model choice, preprocessing choice, and all associated parameters.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作是找到最佳的中间点，在过拟合和欠拟合之间找到最佳平衡点，通过调整模型——在非常一般的意义上，包括模型选择、预处理选择以及所有相关参数。
- en: 'So to summarize, the relation between train error, test error and model complexity
    (with a fixed input dataset):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，训练误差、测试误差和模型复杂度之间的关系（在固定输入数据集的情况下）：
- en: '**Underfit**: at very low complexity, the model will underfit the train set
    (because it does not have the flexibility to bear the actual complexity in the
    data) and lead to errors on both the trainset and testset (train set and test
    set should have more or less the same complexity/noise, since they are drawn from
    the same population/dataset)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欠拟合**：在非常低的复杂度下，模型会欠拟合训练集（因为它没有足够的灵活性来承受数据中的实际复杂性），导致训练集和测试集上都有误差（训练集和测试集应有更多或更少相同的复杂性/噪声，因为它们来自相同的人群/数据集）。'
- en: '**Sweetspot**: as the model complexity increases away from heavy underfitting,
    the train error and test error will decrease.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最佳点**：随着模型复杂度的增加，远离严重欠拟合，训练误差和测试误差都会减少。'
- en: '**Overfit**: if the complexity increases too much, the train error will decrease
    (since we give the model more flexibility to learn the train set), but the test
    error will increase exponentially (because the model “learned too much” the train
    set, it performs less on the new data of the test set)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：如果复杂度增加过多，训练误差会减少（因为我们给模型更多的灵活性来学习训练集），但测试误差会呈指数增长（因为模型“过度学习”了训练集，因此在测试集的新数据上表现较差）。'
- en: 'Let’s see a quick example: we will modify the model complexity by changing
    the degree of a polynomial fit. The truth model is 0.5 * X**2 + X + 2, and we
    try various degrees: 0, 1, 2, 10 and 25\. Since the model has 0-th, 1-st and 2-nd
    order, we now that 0 degree will probably underfit, and 25 degrees will probably
    overfit.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个快速示例：我们将通过改变多项式拟合的度数来修改模型复杂度。真实模型是0.5 * X**2 + X + 2，我们尝试了不同的度数：0、1、2、10和25。由于模型具有0、1和2次方，因此我们知道0度可能会欠拟合，而25度可能会过拟合。
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result looks like this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '![](../Images/f08840caf44ad4fb78d835bc73290701.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f08840caf44ad4fb78d835bc73290701.png)'
- en: From left to right, the complexity is increased using the degree. Both scores
    start low, and increase up to degree 2/10\. After that the test score strongly
    decreases indicating lack of generalization and over-fitting.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从左到右，复杂度通过度数增加。两个分数都从较低开始，并增加到度数2/10。之后，测试分数明显下降，表明缺乏泛化能力和过拟合。
- en: '**On the extreme lowest-complexity, 0 degree**, the model underfits. Both the
    train and test scores are pretty low (for a linear regression, the optimum score
    is 1).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**在极低复杂度的0度**时，模型欠拟合。训练和测试分数都很低（对于线性回归来说，最佳分数是1）。'
- en: '**Increasing the degree to 1** brings significant improvements of both scores,
    but we can still see visually that the model is too simple to fit the data trend.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**将度数提高到1**显著改善了两个分数，但我们仍然可以在视觉上看到模型过于简单，无法拟合数据趋势。'
- en: '**With a degree of 2**, the model seems to approach an optimum. The scores
    are again way better, and we get a visual accordance. **Compared to degree 5**
    for which the scores are a bit better, we can see a misfit bump (actually overfit).
    It is likely that for another split (like done in cross-validation), that degree
    5 would be quite different.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**度数为2**时，模型似乎接近最佳。分数再次明显提高，我们得到了视觉上的一致性。**相比于度数为5**，虽然分数稍微好一些，但我们可以看到一个不匹配的峰值（实际上是过拟合）。可能在另一个划分（如交叉验证）中，度数5会有很大不同。'
- en: '**With a degree of 25**, we see a clear decrease of the test score and the
    train score keeps improving: this is a clear sign of over-fitting. At this point,
    our model is memorizing the train set and cannot generalize on new data.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**在25度时**，我们可以看到测试分数明显下降，而训练分数不断提高：这明显是过拟合的信号。此时，我们的模型正在记忆训练集，无法对新数据进行泛化。'
- en: This dependence of train/test scores with model complexity shows how over-fitting
    and under-fitting occurs. We will inspect this further with validation curve below.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这种训练/测试分数与模型复杂性的依赖关系展示了过拟合和欠拟合是如何发生的。我们将在下面的验证曲线中进一步检查这一点。
- en: 'Note another important term: ‘**inductive bias**’: this is the bias introduced
    by the choice/kind of model. It is builtin the model itself, not the hyperparameters
    or number of samples (as opposed to bias introduced by the different hyperparameters
    like the degree of a polynomial regression). Remember that a model’s complexity
    depend both on the kind of model and its parameters.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要术语是：**归纳偏差**：这是由模型的选择/类型引入的偏差。它内置于模型本身，而不是超参数或样本数量（与由不同超参数如多项式回归的度数引入的偏差相对）。记住，模型的复杂性取决于模型的类型及其参数。
- en: '**Model performance with number of samples**'
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**模型性能与样本数量的关系**'
- en: While in most cases, we have to work with fixed size input data, another way
    to look at the model performance and the overall ML exercice, is to inspect how
    the scores change with the number of sample data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在大多数情况下，我们必须处理固定大小的输入数据，但另一种查看模型性能和整体机器学习过程的方法是检查分数如何随样本数据的数量变化。
- en: 'Again, we have more or less 3 zones:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以分为大致3个区域：
- en: '**with few samples**, both train and test errors are important (there is not
    enough data for the model to understand what is happening, whatever its flexibility)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**当样本数量较少时**，训练误差和测试误差都很重要（数据不足，模型无法理解发生了什么，无论其灵活性如何）'
- en: '**as the number of samples increases**, the train error will increase (since
    the model complexity is fixed), but the test error will decrease (adding more
    samples allowed the model to learn better)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随着样本数量的增加**，训练误差将增加（因为模型复杂性固定），但测试误差将下降（添加更多样本使得模型能够更好地学习）'
- en: '**if the number of samples increases a lot**, the train and test error will
    almost converge together: the model has reached its potential. The train error
    stopped increasing because the model itself (what it learns) is not changed by
    any new data point, and the test error is limited by the model complexity and
    cannot decrease anymore.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如果样本数量大幅增加**，训练误差和测试误差将几乎趋于一致：模型达到了其潜力。训练误差停止增加，因为模型自身（它所学习的内容）不会被任何新数据点改变，而测试误差受限于模型复杂性，无法再降低。'
- en: 'In this last case of very high number of samples, we say the model approaches
    the **Bayes error rate**: this is the error of the best model trained on unlimited
    data, when predictions are just limited by noise in the data.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在样本数量非常大的情况下，我们说模型接近于**贝叶斯误差率**：这是在无限数据上训练的最佳模型的误差，当预测仅受数据中的噪声限制时。
- en: '**Visualizing scores as function of complexity and number of samples**'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**将分数可视化为复杂性和样本数量的函数**'
- en: 'Finally, it can be a good practice to visualize those concepts using what are
    called “Validation curve” and “Learning curve”:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用所谓的“验证曲线”和“学习曲线”来可视化这些概念是一个不错的实践：
- en: '**validation curve**: plot the test score and train score as a funtion of model
    complexity (like the degree of polynomial fit): `score=f(complexity)`'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证曲线**：将测试分数和训练分数绘制为模型复杂性的函数（如多项式拟合的度数）：`score=f(complexity)`'
- en: '**learning curve**: plot the test score and train score as a function of input
    size (for a given input data matrix, we can use just a portion of the total available
    data): `score=f(#samples)`'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习曲线**：将测试分数和训练分数绘制为输入大小的函数（对于给定的输入数据矩阵，我们可以只使用总数据的一部分）：`score=f(#samples)`'
- en: 'Both curves can be generated pretty simply with sklearn:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 两条曲线可以通过sklearn简单生成：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/5b50e6efba9ed51c4c28ddebb50ced07.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b50e6efba9ed51c4c28ddebb50ced07.png)'
- en: As you can see, both the train score and test increase quickly in the [0–2]
    range. For higher degrees, the test score starts decreasing, indicating a loss
    of generalization of. the model. Obviously, the training keeps increasing when
    the model complexity increases.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，训练分数和测试分数在[0–2]范围内快速增加。对于更高的度数，测试分数开始下降，表明模型的泛化能力下降。显然，随着模型复杂性的增加，训练分数持续增加。
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/cee4cf2b13557f60fa45e9919b41ef16.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cee4cf2b13557f60fa45e9919b41ef16.png)'
- en: As you can see, with a fixed complexity of degree=2, the train score and test
    scores converge toward the same value for very high number of samples. This kind
    of curve can help you analyse if the input data you’re working with is enough
    for your model to approach its Bayes error rate.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，固定度数为2时，训练分数和测试分数在样本数量非常多时趋于相同的值。这种曲线可以帮助你分析你所处理的输入数据是否足够让你的模型接近其贝叶斯误差率。
- en: '**The bias-variance tradeoff**'
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**偏差-方差权衡**'
- en: 'The concepts of bias, variance and the bias-variance is strongly related to
    the concepts of over-fitting and underfitting. We already covered overfitting
    and underfitting, so I’ll make this quick:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差、方差和偏差-方差权衡的概念与过拟合和欠拟合的概念密切相关。我们已经讨论了过拟合和欠拟合，所以我会简要说明：
- en: '**variance** refers to the variation a model’s reponse changes with the train
    set. In other words, a model can exihbits strong variance when the trainset is
    very small and/or the model complexity is very high. Overfitting is often associated
    with high variance because the model is sensitive to the specifics of the training
    data.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方差** 指的是模型响应在训练集中的变化程度。换句话说，当训练集非常小和/或模型复杂性非常高时，模型可能会表现出强烈的方差。过拟合通常与高方差相关，因为模型对训练数据的具体情况非常敏感。'
- en: '**bias** refers to how the fitted model will be “biased” compared to the perfect
    model, and will be pretty much the same whatever the input its fed. This happens
    especially if the model complexity/flexibility is very low compared to what we
    want it to learn. In other words, the model is biased towards its assumptions
    and might not adapt well to the complexities of the data. Underfitting is associated
    with high bias because the model is not flexible enough to adapt to the complexities
    of the data.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏差** 指的是拟合模型相对于完美模型的“偏倚”，无论输入什么内容，结果都大致相同。这尤其发生在模型复杂性/灵活性与我们希望它学习的内容相比非常低时。换句话说，模型对其假设有偏见，可能无法很好地适应数据的复杂性。欠拟合与高偏差相关，因为模型的灵活性不足以适应数据的复杂性。'
- en: 'The **bias-variance tradeoff** is then a key concept in ML: it suggests that
    there is a tradeoff between bias and variance. Increasing model complexity tends
    to decrease bias but increase variance, and vice versa. The goal is to find the
    right balance that minimizes both bias and variance, leading to a model that generalizes
    well to new, unseen data. So our job as data-scientist is to tune the model and
    find this sweet spot.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏差-方差权衡** 是机器学习中的一个关键概念：它表明偏差和方差之间存在权衡。增加模型复杂性通常会减少偏差，但增加方差，反之亦然。目标是找到一个合适的平衡点，以最小化偏差和方差，从而得到一个能很好地泛化到新的、未见过的数据的模型。因此，我们作为数据科学家的工作是调整模型并找到这个甜蜜点。'
- en: The example below shows how a simple polynomial fit of a single variable, so
    y=p(x) can have either high bias or high variance, depending on the degree allowed
    for the model (the code is available further down, below the figure).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的示例展示了一个单变量的简单多项式拟合，即 y=p(x)，它可以具有高偏差或高方差，这取决于模型允许的度数（代码在下方的图形下面提供）。
- en: 'The idea is the following: we create a toy dataset y with a known polynomial
    function p(x)=0.5X³ + X + 2 + noise. So the true coefficients we would like the
    polynomial fit to learn are 2 for the constant coefficient, 1 for the X coefficient,
    and 0.5 fort the X³ coefficient. We test 2 models: a very low degree polynom with
    degree=1, and a high degree polynom with degree=15.'
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 思路如下：我们创建一个玩具数据集 y，其已知多项式函数为 p(x)=0.5X³ + X + 2 + 噪声。因此，我们希望多项式拟合学习到的真实系数是常数项为
    2，X 项为 1，以及 X³ 项为 0.5。我们测试 2 个模型：一个度数为1的低度多项式和一个度数为15的高度多项式。
- en: ''
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Once the data is generated, we split it 50–50 into a first train/test set. Both
    low and high degree models are fitted on this split, and their learned coefs,
    preditcions and score are computed. Then we just switch the train set and test
    set, so for the second split, we are training on what was the test set and testing
    on what was the train set. This is not common practice but rather a pedagogical
    trick. Again, both low and high degree models are fitted, and again their learned
    coefs, predictions and scores are computed.
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一旦生成数据，我们将其分成50–50的训练集/测试集。低度和高度模型都在这个划分上进行拟合，并计算它们的学习系数、预测和评分。然后我们交换训练集和测试集，即第二次划分时，我们在原测试集上训练，在原训练集上测试。这不是常见的做法，而是一种教学技巧。再次，低度和高度模型都进行拟合，并计算它们的学习系数、预测和评分。
- en: 'The results are the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '![](../Images/333de7b5faf21a84790d24aa13fd9b45.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/333de7b5faf21a84790d24aa13fd9b45.png)'
- en: '**As you can see for the low degree plots (middle column plots)**, both splits
    lead to pretty much the same coefficients solution. The predictions are “biased”
    from the true data, there is this kind of constant “offset” in the learned coefs.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**正如你可以看到低度数的图（中间列的图）**，两个拆分得出的系数解几乎是一样的。预测与真实数据有“偏差”，学习到的系数存在这种常量“偏移”。'
- en: '**On the other hand for the high degree plots (right column plots)**, both
    splits lead to very different coefficients. There is a high variance in their
    response.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**另一方面，对于高阶图（右列图）**，两个拆分得到的系数差异很大。它们的响应具有高方差。'
- en: 'Here is the code used:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用的代码：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Wrapup
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'To summarize, remember these important concepts:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，记住这些重要概念：
- en: '**Score/Train Score/Test Score:** Scores quantify the performance of a model;
    Train Score reflects its accuracy on the training data, Test Score on unseen data.
    Balancing high train score with a comparable test score is crucial for a model
    that generalizes well.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分数/训练分数/测试分数：** 分数量化了模型的表现；训练分数反映了模型在训练数据上的准确性，测试分数则是在未见数据上的准确性。平衡高训练分数与可比较的测试分数对一个能够良好泛化的模型至关重要。'
- en: '**Underfitting/Overfitting:** Underfitting occurs when a model is too simplistic,
    missing data complexities; Overfitting arises when a model overly tailors itself
    to training data, hindering generalization. Finding balance in model complexity
    is essential to avoid both underfitting’s simplicity and overfitting’s memorization.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欠拟合/过拟合：** 欠拟合发生在模型过于简单，未能捕捉数据复杂性；过拟合发生在模型过度适应训练数据，阻碍泛化。找到模型复杂度的平衡对避免欠拟合的简单性和过拟合的记忆化至关重要。'
- en: '**Model Performance as a Function of Complexity and Number of Samples:** Examining
    how a model’s scores change with complexity (e.g., polynomial degree) or dataset
    size provides insights into its behavior. Assessing performance across varied
    complexities and sample sizes aids in identifying the optimal model characteristics.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型性能作为复杂性和样本数的函数：** 检查模型分数如何随复杂性（例如，多项式度数）或数据集大小的变化而变化，可以提供有关其行为的见解。在不同复杂性和样本大小下评估性能有助于识别最佳模型特征。'
- en: '**Bias and Variance in Model Evaluation:** Bias refers to a model’s tendency
    to deviate from the true data pattern; low flexibility yields high bias. Variance
    captures a model’s sensitivity to dataset changes; high complexity leads to high
    variance'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型评估中的偏差和方差：** 偏差指的是模型偏离真实数据模式的倾向；低灵活性会产生高偏差。方差则捕捉了模型对数据集变化的敏感性；高复杂性导致高方差。'
- en: Finally, achieving the bias-variance balance is often the key point in a good
    ML exercise to tune a model to its best possible performance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，实现偏差-方差平衡通常是调整模型以获得最佳性能的关键点。
- en: 'You might like some of my other posts, make sure to check them out:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会喜欢我的其他一些帖子，确保查看一下：
- en: '![Yoann Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![Yoann Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
- en: Sklearn tutorial
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sklearn 教程
- en: '[View list](https://mocquin.medium.com/list/sklearn-tutorial-2e46a0e06b39?source=post_page-----0739c44f595a--------------------------------)9
    stories![](../Images/4ffe6868fb22c241a959bd5d5a9fd5d7.png)![](../Images/8aa32b00faa0ef7376e121ba9c9ffdb7.png)![](../Images/9f986423d7983bc08fc2073534603c35.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/sklearn-tutorial-2e46a0e06b39?source=post_page-----0739c44f595a--------------------------------)9
    个故事![](../Images/4ffe6868fb22c241a959bd5d5a9fd5d7.png)![](../Images/8aa32b00faa0ef7376e121ba9c9ffdb7.png)![](../Images/9f986423d7983bc08fc2073534603c35.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
- en: Scientific/numerical python
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 科学/数值 Python
- en: '[View list](https://mocquin.medium.com/list/scientificnumerical-python-9ce115122ab6?source=post_page-----0739c44f595a--------------------------------)3
    stories![Ironicaly, an array of containers](../Images/4ecd0326a3efdda93947f60872018d41.png)![](../Images/f11076a724463f7b11d819d95bcf0ea4.png)![](../Images/e340b22f444d2bd311537341cf1a105a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/scientificnumerical-python-9ce115122ab6?source=post_page-----0739c44f595a--------------------------------)3
    个故事![讽刺地，容器数组](../Images/4ecd0326a3efdda93947f60872018d41.png)![](../Images/f11076a724463f7b11d819d95bcf0ea4.png)![](../Images/e340b22f444d2bd311537341cf1a105a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
- en: Data science and Machine Learning
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学与机器学习
- en: '[View list](https://mocquin.medium.com/list/data-science-and-machine-learning-ba3fb2206051?source=post_page-----0739c44f595a--------------------------------)3
    stories![](../Images/c078e74fd67e0141c2b54b82823c78d4.png)![](../Images/79988eda04a078da9373f03d7db51c51.png)![](../Images/6a5966e529bf4ba9b16c592fec7b591a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/data-science-and-machine-learning-ba3fb2206051?source=post_page-----0739c44f595a--------------------------------)3
    篇故事![](../Images/c078e74fd67e0141c2b54b82823c78d4.png)![](../Images/79988eda04a078da9373f03d7db51c51.png)![](../Images/6a5966e529bf4ba9b16c592fec7b591a.png)![Yoann
    Mocquin](../Images/234a99f243ff3c70fd90170ddde8659d.png)'
- en: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[Yoann Mocquin](https://mocquin.medium.com/?source=post_page-----0739c44f595a--------------------------------)'
- en: Fourier-transforms for time-series
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 时间序列的傅里叶变换
- en: '[View list](https://mocquin.medium.com/list/fouriertransforms-for-timeseries-ed423e3f38ad?source=post_page-----0739c44f595a--------------------------------)4
    stories![](../Images/86efd63d329650eb9b6d7c33625d6884.png)![](../Images/c693e4e596df5c1a8ef1b0fb3777d7ac.png)![](../Images/b6bc5330fb2d92bc3aad36f5bbc950da.png)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://mocquin.medium.com/list/fouriertransforms-for-timeseries-ed423e3f38ad?source=post_page-----0739c44f595a--------------------------------)4
    篇故事![](../Images/86efd63d329650eb9b6d7c33625d6884.png)![](../Images/c693e4e596df5c1a8ef1b0fb3777d7ac.png)![](../Images/b6bc5330fb2d92bc3aad36f5bbc950da.png)'
