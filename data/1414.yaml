- en: Can ChatGPT Compete with Domain-Specific Sentiment Analysis Machine Learning
    Models?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT能与领域特定情感分析机器学习模型竞争吗？
- en: 原文：[https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460?source=collection_archive---------4-----------------------#2023-04-25](https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460?source=collection_archive---------4-----------------------#2023-04-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460?source=collection_archive---------4-----------------------#2023-04-25](https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460?source=collection_archive---------4-----------------------#2023-04-25)
- en: A hands-on comparison using ChatGPT and Domain-Specific Model
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个使用ChatGPT与领域特定模型的动手比较
- en: '[](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)[![Francisco
    Caio Lima Paiva](../Images/4cfbed5b2ec5944e593d2eec9ec7bf3d.png)](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)
    [Francisco Caio Lima Paiva](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)[![Francisco
    Caio Lima Paiva](../Images/4cfbed5b2ec5944e593d2eec9ec7bf3d.png)](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)
    [Francisco Caio Lima Paiva](https://medium.com/@francisco.paiva?source=post_page-----cdcd9937b460--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb20176e45fd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&user=Francisco+Caio+Lima+Paiva&userId=b20176e45fd4&source=post_page-b20176e45fd4----cdcd9937b460---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)
    ·15 min read·Apr 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcdcd9937b460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&user=Francisco+Caio+Lima+Paiva&userId=b20176e45fd4&source=-----cdcd9937b460---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb20176e45fd4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&user=Francisco+Caio+Lima+Paiva&userId=b20176e45fd4&source=post_page-b20176e45fd4----cdcd9937b460---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cdcd9937b460--------------------------------)
    ·15分钟阅读·2023年4月25日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcdcd9937b460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&user=Francisco+Caio+Lima+Paiva&userId=b20176e45fd4&source=-----cdcd9937b460---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcdcd9937b460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&source=-----cdcd9937b460---------------------bookmark_footer-----------)![](../Images/78d74b03be2070788f3ee96a1287eb02.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcdcd9937b460&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460&source=-----cdcd9937b460---------------------bookmark_footer-----------)![](../Images/78d74b03be2070788f3ee96a1287eb02.png)'
- en: Photo by [K. Mitch Hodge](https://unsplash.com/@kmitchhodge?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [K. Mitch Hodge](https://unsplash.com/@kmitchhodge?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: ChatGPT is a GPT (**G**enerative **P**re-trained **T**ransformer) machine learning
    (ML) tool that has surprised the world. Its breathtaking capabilities impress
    casual users, professionals, researchers, and even its [own creators](https://twitter.com/janleike/status/1625207251630960640?t=wHDHT50I-UYEbL7kRDsgfw&s=08).
    Moreover, its capacity to be an ML model trained for general tasks and perform
    very well in domain-specific situations is impressive. I am a researcher, and
    its ability to do sentiment analysis (SA) interests me.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 是一个 GPT (**生成式** **预训练** **变换器**) 机器学习（ML）工具，令世界惊叹。它令人惊叹的能力让普通用户、专业人士、研究人员甚至其[自身的创造者](https://twitter.com/janleike/status/1625207251630960640?t=wHDHT50I-UYEbL7kRDsgfw&s=08)
    都感到印象深刻。此外，它作为一个为通用任务训练的机器学习模型，在特定领域情况下表现出色，这一点令人印象深刻。作为一名研究人员，我对它进行情感分析（SA）的能力很感兴趣。
- en: SA is a very widespread Natural Language Processing (NLP). It has several applications
    and thus can be used in several domains (e.g., finance, entertainment, psychology).
    However, some fields adopt specific terms and jargon (e.g., [finance](https://doi.org/10.1111/j.1540-6261.2010.01625.x)).
    Hence, [whether general domain ML models can be as capable as domain-specific](https://aclanthology.org/D16-1057/)
    models is still an [open research question in NLP](http://dx.doi.org/10.1016/j.eswa.2014.06.009).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: SA 是一种非常广泛的自然语言处理（NLP）技术。它有多个应用，因此可以用于多个领域（例如，金融、娱乐、心理学）。然而，一些领域采用特定的术语和行话（例如，[金融](https://doi.org/10.1111/j.1540-6261.2010.01625.x)）。因此，[通用领域的机器学习模型是否可以与特定领域的](https://aclanthology.org/D16-1057/)
    模型一样强大，仍然是一个[NLP中的开放研究问题](http://dx.doi.org/10.1016/j.eswa.2014.06.009)。
- en: If you ask the ChatGPT this research question — which is this article’s title
    — it will give you a humble answer (go on, try it). But, oh, my dear reader, I
    usually wouldn’t spoil this for you, but you have no idea how surprisingly modest
    this ChatGPT answer was…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你问 ChatGPT 这个研究问题——也就是本文的标题——它会给你一个谦逊的回答（继续试试吧）。但是，哦，我亲爱的读者，我通常不会给你剧透，但你完全无法想象这个
    ChatGPT 回答有多么出人意料地谦虚……
- en: Still, as an AI researcher, industry professional, and hobbyist, I am used to
    fine-tuning general domain NLP machine learning tools (e.g., GloVe) for usage
    in domain-specific tasks. This is the case because it was uncommon for most domains
    to find an out-of-the-box solution that could do well enough without some fine-tuning.
    I will show you how this could no longer be the case.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 AI 研究员、行业专家和爱好者，我习惯于对通用领域的 NLP 机器学习工具（例如，GloVe）进行微调，以用于特定领域的任务。这是因为大多数领域很少能找到一个开箱即用的解决方案，能够在没有一些微调的情况下表现得足够好。我将展示如何不再是这种情况。
- en: 'In this text, I compare ChatGPT to a domain-specific ML model by discussing
    the following topics:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我通过讨论以下主题来比较 ChatGPT 与一个特定领域的机器学习模型：
- en: SemEval 2017 Task 5 — A domain-specific challenge
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: SemEval 2017 任务 5 —— 一个特定领域的挑战
- en: Using ChatGPT API to label a dataset with code examples
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 ChatGPT API 给数据集打标签的代码示例
- en: Verdict and results of the comparison with reproducibility details
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较的裁决和结果及其可重复性细节
- en: Conclusion and Results Discussion
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结论与结果讨论
- en: 'BONUS: How this comparison can be done in an applied scenario'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 额外内容：如何在实际场景中进行这种比较
- en: '**Note 1**: *This is just a simple hands-on experiment that sheds some light
    on the subject,* ***NOT*** *an exhaustive scientific investigation.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**注释 1**：*这只是一个简单的实践实验，稍微揭示了这个主题，* ***而非*** *详尽的科学调查。*'
- en: '**Note 2**: *All images unless otherwise noted are by the author.*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**注释 2**：*除非另有说明，所有图片均由作者提供。*'
- en: 1\. SemEval 2017 Task 5 — A domain-specific challenge
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. SemEval 2017 任务 5 —— 一个特定领域的挑战
- en: '[SemEval (**Sem**antic **Eval**uation)](https://semeval.github.io/) is a renowned
    NLP workshop where research teams compete scientifically in sentiment analysis,
    text similarity, and question-answering tasks. The organizers provide textual
    data and gold-standard datasets created by annotators (domain specialists) and
    linguists to evaluate state-of-the-art solutions for each task.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[SemEval (**语义评估**)](https://semeval.github.io/) 是一个著名的NLP研讨会，研究团队在情感分析、文本相似性和问答任务中进行科学竞争。组织者提供由标注员（领域专家）和语言学家创建的文本数据和金标准数据集，以评估每项任务的最先进解决方案。'
- en: 'In particular, SemEval’s [Task 5 of the 2017 edition](https://aclanthology.org/S17-2089/)
    asked researchers to score financial microblogs and news headlines for sentiment
    analysis on a -1 (most negative) to 1 (most positive) scale. We’ll use the gold-standard
    dataset from that year’s SemEval to test ChatGPT’s performance in a domain-specific
    task. Subtask 2 dataset (news headlines) had two sets of sentences (maximum of
    30 words each): the training (1,142 sentences) and the testing (491 sentences)
    sets.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，SemEval 的[2017年任务5](https://aclanthology.org/S17-2089/)要求研究人员对金融微博和新闻标题进行情感分析，评分范围从
    -1（最负面）到 1（最正面）。我们将使用那一年 SemEval 的金标准数据集来测试 ChatGPT 在特定领域任务中的表现。子任务 2 数据集（新闻标题）包含两个句子集（每个最多
    30 个单词）：训练集（1,142 个句子）和测试集（491 个句子）。
- en: Considering these sets, the data distribution of sentiment scores and text sentences
    is displayed below. The plot below shows bimodal distributions in both training
    and testing sets. Moreover, the graph indicates more positive than negative sentences
    in the dataset. This will be a piece of handy information in the evaluation section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些数据集，下面展示了情感评分和文本句子的分布情况。下图显示了训练集和测试集中都有双峰分布。此外，图表还显示数据集中正面句子多于负面句子。这将在评估部分提供有用的信息。
- en: '![](../Images/984d1518ff6754bef42d870bc3dfcd3d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/984d1518ff6754bef42d870bc3dfcd3d.png)'
- en: SemEval 2017 Task 5 Subtask 2 (news headlines) data distribution sentiment score
    considering the training (left — 1,142 sentences) and testing (right — 491 sentences)
    sets.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SemEval 2017 任务 5 子任务 2（新闻标题）数据分布情感评分，考虑到训练集（左 — 1,142 个句子）和测试集（右 — 491 个句子）。
- en: For this subtask, the winning research team (i.e., which ranked best on the
    test set) named their ML architecture [Fortia-FBK](https://aclanthology.org/S17-2138/).
    Inspired by this competition’s discoveries, some colleagues and I made a research
    article ([Assessing Regression-Based Sentiment Analysis Techniques in Financial
    Texts](https://doi.org/10.5753/eniac.2019.9329)) where we implemented our version
    of Fortia-FBK and evaluated ways to improve this architecture.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个子任务，获胜的研究团队（即在测试集上排名最佳的团队）将他们的机器学习架构命名为[Fortia-FBK](https://aclanthology.org/S17-2138/)。受这一竞赛发现的启发，我和一些同事撰写了研究文章（[评估基于回归的金融文本情感分析技术](https://doi.org/10.5753/eniac.2019.9329)），在其中我们实现了
    Fortia-FBK 的版本，并评估了改进该架构的方法。
- en: Also, we investigated the factors that made this architecture the winning one.
    Thus, our implementation ([code is here](https://bit.ly/3kzau8G)) of this winning
    architecture (i.e., Fortia-FBK) will be used for comparison with ChatGPT. The
    architecture (CNN+GloVe+Vader) employed is the one shown below.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还调查了使这一架构成为获胜架构的因素。因此，我们的实现（[代码在这里](https://bit.ly/3kzau8G)）将用于与 ChatGPT
    进行比较。所采用的架构（CNN+GloVe+Vader）如下所示。
- en: '![](../Images/7dfd1ae2e006d8b16f27985fde3cf5bf.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7dfd1ae2e006d8b16f27985fde3cf5bf.png)'
- en: Domain-specific sentiment analysis ML model for financial news domain. Architecture
    developed for the research article “[Assessing Regression-Based Sentiment Analysis
    Techniques in Financial Texts](https://doi.org/10.5753/eniac.2019.9329)”. **Source:**
    Author Master’s dissertation (Lima Paiva, F.C. in “Assimilating sentiment analysis
    in reinforcement learning for intelligent trading”).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 针对金融新闻领域的特定领域情感分析机器学习模型。架构是为研究文章“[评估基于回归的金融文本情感分析技术](https://doi.org/10.5753/eniac.2019.9329)”开发的。**来源：**
    作者硕士论文（Lima Paiva, F.C.，《将情感分析融入强化学习以实现智能交易》）。
- en: 2\. Using ChatGPT API to label a dataset
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 使用 ChatGPT API 对数据集进行标注
- en: Using ChatGPT API has already been discussed here on Medium [for synthesizing
    data](/hands-on-sentiment-analysis-on-hotels-reviews-using-artificial-intelligence-and-open-ais-chatgpt-d1939850c79e).
    Also, you can find sentiment labeling examples in the [ChatGPT API code samples
    section](https://platform.openai.com/playground/p/default-adv-tweet-classifier?model=text-davinci-003)
    (Notice that using the API is not free). For this code example, consider SemEval’s
    2017 Task gold-standard dataset that you can [get here](https://bitbucket.org/ssix-project/semeval-2017-task-5-subtask-2/src/master/).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于使用 ChatGPT API 的讨论已在 Medium 上的[数据合成](https://hands-on-sentiment-analysis-on-hotels-reviews-using-artificial-intelligence-and-open-ais-chatgpt-d1939850c79e)中进行过。此外，你还可以在[ChatGPT
    API 代码示例部分](https://platform.openai.com/playground/p/default-adv-tweet-classifier?model=text-davinci-003)找到情感标注示例（请注意，使用该
    API 并非免费）。在这个代码示例中，请考虑 SemEval 2017 任务的金标准数据集，你可以[在这里获取](https://bitbucket.org/ssix-project/semeval-2017-task-5-subtask-2/src/master/)。
- en: Then, to use the API for labeling several sentences at once, use a code as such,
    where I prepare a full prompt with sentences from a dataframe with the Gold-Standard
    dataset with the sentence to be labeled and the target company to which the sentiment
    refers.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了同时标注多个句子，使用如下代码，其中我准备了一个完整的提示，包含来自数据框的句子，黄金标准数据集中的要标注的句子以及情感所指的目标公司。
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then, call the API for the *text-davinci-003* *engine* (GPT-3 version). Here
    I made some adjustments to the code to account for the max number of total characters
    in the prompt plus the answer, which must be at most 4097 characters.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，调用*text-davinci-003* *引擎*（GPT-3版本）的API。在这里，我对代码进行了一些调整，以考虑提示加回答的最大字符数，总共最多4097个字符。
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Ultimately, doing that for a total of 1633 (training + testing sets) sentences
    in the gold-standard dataset and you get the following results with ChatGPT API
    labels.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，对黄金标准数据集中1633个（训练 + 测试集）句子进行处理，你会得到以下ChatGPT API标签的结果。
- en: '![](../Images/0d9d998311830d06e8d4ac8b053962de.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d9d998311830d06e8d4ac8b053962de.png)'
- en: Example of SemEval 2017 Task 5 Subtask 2 (news headlines) Gold-Standard dataset
    with sentiment labeled using the ChatGPT API.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ChatGPT API标注情感的SemEval 2017任务5子任务2（新闻头条）黄金标准数据集示例。
- en: 2.1\. Issues with ChatGPT and its API at scale
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1\. ChatGPT及其API在规模化时的问题
- en: As with any other API, there are some typical requirements
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他API一样，有一些典型要求
- en: Requests rate limit that requires throttling adjustments
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求速率限制需要进行节流调整
- en: Request limit of 25000 tokens (i.e., sub-word unit or a byte-pair encoding)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求限制为25000 tokens（即子词单元或字节对编码）
- en: Maximum length of 4096 tokens per request (prompt + response included)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个请求的最大长度为4096 tokens（包括提示 + 响应）
- en: 'Cost of $0.0200 / 1K tokens (Note: I never spent more than U$ 2 after everything
    I did)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本为$0.0200 / 1K tokens（注：我在所有操作后从未花费超过U$ 2）
- en: However, these are just the typical requirements when dealing with most APIs.
    Moreover, remember that in this domain-specific problem, there is a target entity
    (i.e., company) for each sentence for the sentiment. So I had to play around until
    I designed a prompt pattern that made it possible to label the sentiment of several
    sentences at once and make it easy to process the results afterward. Furthermore,
    that are other limitations that impacted the prompt and code that I showed previously.
    Specifically, I found issues using this text API for several sentences (>1000).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些只是处理大多数API时的典型要求。此外，记住在这个领域特定的问题中，每个句子都有一个目标实体（即公司）用于情感分析。因此，我不得不进行一些调整，直到设计出一个使得能够一次标注多个句子的情感并且后续处理结果变得简单的提示模式。此外，还有其他限制影响了我之前展示的提示和代码。具体来说，我发现使用这个文本API处理多个句子（>1000）时存在问题。
- en: '**Reproducibility:** ChatGPT’s sentiment assessments on sentiment can change
    significantly with very few changes to the prompt (e..g, adding or removing a
    comma or a dot of the sentence).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重复性：** ChatGPT的情感评估在提示中做出很小的修改（例如，添加或删除句子中的逗号或句号）后可能会发生显著变化。'
- en: '**Consistency:** If you do not clearly specify the pattern response, ChatGPT
    will get creative (even if you select a very low randomness parameter), making
    it hard to process results. Moreover, even when you specify the pattern, it can
    output inconsistent output formats.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性：** 如果你没有明确指定模式响应，ChatGPT会变得富有创意（即使你选择了非常低的随机性参数），这使得处理结果变得困难。此外，即使你指定了模式，它也可能输出不一致的格式。'
- en: '**Mismatches:** Even though it can very precisely identify the target entity
    (e.g., company) you want to have the sentiment assessed in a sentence, it can
    mix up results when doing this at scale. For example, suppose you pass on 10 sentences
    each with a target company. Still, some of the companies appear in other sentences
    or are repeated. In that case, ChatGPT can mismatch the targets and sentence sentiments,
    change the order of the sentiment labels or provide fewer than 10 labels.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不匹配：** 尽管它可以非常准确地识别你在句子中想要评估情感的目标实体（例如公司），但在大规模处理时，它可能会混淆结果。例如，假设你传递了10个包含目标公司的句子。如果这些公司出现在其他句子中或重复出现，ChatGPT可能会混淆目标和句子情感，改变情感标签的顺序或提供少于10个标签。'
- en: '**Bias:** Currently, the [issue of ChatGPT bias is well known](https://hbswk.hbs.edu/item/chatgpt-did-big-tech-set-up-the-world-for-ai-bias-disaster).
    And there are [ideas on how to improve this problem](https://www.technologyreview.com/2023/02/21/1068893/how-openai-is-trying-to-make-chatgpt-safer-and-less-biased/).
    However, until then, beware that you are learning to use a Biased API.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏见：** 目前，[ChatGPT 偏见问题是众所周知的](https://hbswk.hbs.edu/item/chatgpt-did-big-tech-set-up-the-world-for-ai-bias-disaster)。而且有[改进这个问题的想法](https://www.technologyreview.com/2023/02/21/1068893/how-openai-is-trying-to-make-chatgpt-safer-and-less-biased/)。然而，在那之前，请注意你正在学习使用一个有偏见的
    API。'
- en: All of these issues imply a learning curve to properly use the (biased) API.
    It required some fine-tuning to get what I needed. Sometimes I had to do many
    trials until I reached the desired outcome with minimal consistency.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些问题都意味着需要一个学习曲线来正确使用（有偏见的）API。它需要一些微调才能得到我需要的结果。有时我不得不进行许多尝试，直到以最小的一致性达到了期望的结果。
- en: You should send as many sentences as possible at once in an ideal situation
    for two reasons. First, you want to get your labels as fast as possible. Second,
    the prompt counts as tokens in the cost, so fewer requests mean less cost. Yet,
    we have a limit of 4096 tokens per request. Also, given the issues I mentioned,
    another notable API limitation exists. Passing too many sentences at once increases
    the chance of mismatches and inconsistencies. Thus, it is up to you to keep increasing
    and decreasing the number of sentences until you find your sweet spot for consistency
    and cost. If you do not do that properly, you will suffer in the post-processing
    results phase.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想情况下，你应该一次发送尽可能多的句子，原因有二。首先，你希望尽快获得标签。其次，提示作为令牌计算成本，因此请求越少，成本越低。然而，每次请求有 4096
    个令牌的限制。此外，考虑到我提到的问题，另一个显著的 API 限制存在。一次传递太多句子增加了不匹配和不一致的机会。因此，你需要不断增加和减少句子的数量，直到找到一致性和成本的最佳平衡点。如果不这样做，你会在后处理结果阶段遭遇问题。
- en: In summary, if you have thousands of sentences to process, start with a batch
    of a few half-dozen sentences and no more than 10 prompts to check on the reliability
    of the responses. Then, slowly increase the number to verify capacity and quality
    until you find the optimal prompt and rate that fits your task.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，如果你需要处理成千上万的句子，先从几句开始，并且最多用 `10` 个提示来检查响应的可靠性。然后，逐渐增加数量以验证容量和质量，直到找到适合你的任务的最佳提示和比例。
- en: 3\. Verdict and results of the comparison
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 判决和比较结果
- en: 3.1\. Details of the comparison
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1. 比较的细节
- en: ChatGPT, in its GPT-3 version, cannot attribute sentiment to text sentences
    using numeric values (no matter how much I tried). However, specialists attributed
    numeric scores to sentence sentiments in this particular Gold-Standard dataset.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在其 GPT-3 版本中，ChatGPT 不能使用数值为文本句子赋予情感（无论我尝试了多少次）。然而，专家在这个特定的黄金标准数据集中为句子情感赋予了数值评分。
- en: 'So, to make a viable comparison, I had to:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了进行有效的比较，我必须：
- en: Categorize the dataset scores into *Positive*, *Neutral*, or *Negative* labels.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集评分分类为 *正面*、*中性* 或 *负面* 标签。
- en: Do the same to the scores produced from the domain-specific ML model.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对领域特定的机器学习模型生成的评分做相同的操作。
- en: Define a range of possible thresholds (with steps of 0.001) for determining
    where one category begins and ends. Then, given the threshold *TH*,scores above
    +*TH* are considered *Positive* sentiment, below -*TH* is *Negat*ive, and between
    are *Neutral*.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义可能的阈值范围（步长为 0.001），以确定一个类别的开始和结束。然后，根据阈值 *TH*，超过 +*TH* 的评分被视为 *正面* 情感，低于 -*TH*
    为 *负面*，介于两者之间的是 *中性*。
- en: Iterate over the range of thresholds and evaluate both models’ accuracy at each
    point.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历阈值范围，并在每个点评估两个模型的准确性。
- en: Investigate their performance by sets (i.e., training or testing), given that
    the domain-specific model would have an unfair advantage in the training set.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照集合（即训练或测试）来调查它们的表现，因为领域特定的模型在训练集上可能具有不公平的优势。
- en: The code for step 3 is below. And the complete code for replicating the whole
    comparison [is here](https://drive.google.com/drive/folders/1_FpNvcGjnl8N2Z_Az3FGGWQ4QxmutmgG?usp=share_link).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 3 的代码如下。完整的比较代码[在这里](https://drive.google.com/drive/folders/1_FpNvcGjnl8N2Z_Az3FGGWQ4QxmutmgG?usp=share_link)。
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '3.2\. Verdict: Yes, ChatGPT can not only win but shatter the competition'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2. 判决：是的，ChatGPT 不仅可以赢，而且可以超越竞争对手
- en: The final result is displayed in the plot below, which shows how the accuracy
    (y-axis) changes for both models when categorizing the numeric Gold-Standard dataset,
    as the threshold (x-axis) is adjusted. Also, the training and testing sets are
    on the left and right sides, respectively.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果显示在下面的图表中，该图表展示了当调整阈值（x轴）时，两个模型在对数字黄金标准数据集进行分类时的准确性（y轴）变化。此外，训练集和测试集分别位于左右两侧。
- en: '![](../Images/7df2607c6c8bce7123a2fa61934611bd.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7df2607c6c8bce7123a2fa61934611bd.png)'
- en: Comparison between ChatGPT and the Domain-specific ML model that considers the
    training (left side) and testing (right side) set separately. This evaluation
    assesses how the accuracy (y-axis) changes regarding the threshold (x-axis) for
    categorizing the numeric Gold-Standard dataset for both models.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 比较 ChatGPT 和领域特定机器学习模型，分别考虑训练集（左侧）和测试集（右侧）。这项评估评估了两个模型在对数字黄金标准数据集进行分类时，准确性（y轴）如何随阈值（x轴）的变化而变化。
- en: First, I must be honest. I was not expecting this smashing result. Consequently,
    to not be unfair with ChatGPT, I replicated the original SemEval 2017 competition
    setup, where the Domain-Specific ML model would be built with the training set.
    Then the actual ranking and comparison would only occur over the test set.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我必须诚实。我没想到会得到如此惊人的结果。因此，为了对 ChatGPT 公平，我复制了原始 SemEval 2017 竞赛设置，其中领域特定的机器学习模型将使用训练集进行构建。然后，实际排名和比较仅会在测试集上进行。
- en: However, even in the training set, with the most favorable scenario — threshold
    of 0.066 vs. 0.014 for ChatGPT — the Domain-Specific ML model achieved at most
    an accuracy 2pp worse than ChatGPT’s best accuracy (0.73 vs. 0.75). Moreover,
    ChatGPT showed a superior accuracy across all thresholds than the Domain-Specific
    model in both training and testing sets.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使在训练集中，在最有利的情况下——ChatGPT 的阈值为 0.066，而领域特定模型的阈值为 0.014——领域特定的机器学习模型的准确率最多比
    ChatGPT 的最佳准确率低 2 个百分点（0.73 对 0.75）。此外，ChatGPT 在训练集和测试集中所有阈值下的准确率均优于领域特定模型。
- en: Interestingly, the best threshold for both models (0.038 and 0.037) was close
    in the test set. And at this threshold, ChatGPT achieved an 11pp better accuracy
    than the Domain-Specific model (0.66 vs. 077). Also, ChatGPT showed a much better
    consistency across threshold changes than the Domain-Specific Model. Thus, it
    is visible that ChatGPT’s accuracy decreased much less steeply.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，两个模型的最佳阈值（0.038 和 0.037）在测试集中接近。在这个阈值下，ChatGPT 的准确率比领域特定模型高出 11 个百分点（0.66
    对 0.77）。此外，ChatGPT 在阈值变化中的一致性明显优于领域特定模型。因此，可以看出 ChatGPT 的准确率下降得要少得多。
- en: In resume, ChatGPT vastly outperformed the Domain-Specific ML model in accuracy.
    Also, the idea is that ChatGPT could be fine-tuned to specific tasks. Hence, imagine
    how much better ChatGPT could become.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，ChatGPT 在准确性方面远远超过了领域特定的机器学习模型。另一方面，ChatGPT 还可以根据特定任务进行微调。因此，想象一下 ChatGPT
    会变得多么优秀。
- en: 3.3\. Investigating ChatGPT sentiment labeling
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3. 调查 ChatGPT 的情感标注
- en: I always intended to do a more micro investigation by taking examples where
    ChatGPT was inaccurate and comparing it to the Domain-Specific Model. However,
    as ChatGPT went much better than anticipated, I moved on to investigate only the
    cases where it missed the correct sentiment.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我一直打算进行更深入的调查，通过分析 ChatGPT 不准确的例子，并将其与领域特定模型进行比较。然而，由于 ChatGPT 的表现远超预期，我转而只调查它未能正确判断情感的案例。
- en: Initially, I performed a similar evaluation as before, but now using the complete
    Gold-Standard dataset at once. Next, I selected the threshold (0.016) for converting
    the Gold-Standard numeric values into the Positive, Neutral, and Negative labels
    that incurred ChatGPT’s best accuracy (0.75). Then, I made a confusion matrix.
    The plots are below.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，我进行了一次类似的评估，但这次使用了完整的黄金标准数据集。接着，我选择了将黄金标准数值转换为正面、中性和负面标签的阈值（0.016），以获得 ChatGPT
    的最佳准确率（0.75）。然后，我制作了一个混淆矩阵。图表如下。
- en: '![](../Images/426659a3ea372555089dfe2778fa693e.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/426659a3ea372555089dfe2778fa693e.png)'
- en: On the left side, a line plot for assessing how the ChatGPT’s accuracy (y-axis)
    changes regarding the threshold (x-axis) for categorizing the numeric Gold-Standard
    complete dataset. The confusion matrix for the positive, neutral, and negative
    labels is on the right side, given that the threshold leading to maximum ChatGPT
    performance is 0.016\. Also, the confusion matrix contains the percentage of ChatGPT’s
    hits and misses according to the converted labels.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧是一个线图，用于评估ChatGPT的准确性（y轴）如何随阈值（x轴）的变化而变化，以便对数字Gold-Standard完整数据集进行分类。右侧是正面、中性和负面标签的混淆矩阵，给出了最大ChatGPT性能的阈值为0.016。此外，混淆矩阵包含了根据转换标签的ChatGPT的命中率和遗漏率的百分比。
- en: Recall that I showed a distribution of data sentences with more positive scores
    than negative sentences in a previous section. Here in the confusion matrix, observe
    that considering the threshold of 0.016, there are 922 (56.39%) positive sentences,
    649 (39.69%) negative, and 64 (3.91%) neutral.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请回忆一下我在前一节中展示的数据句子分布，其中正面句子的分数比负面句子的分数要高。在混淆矩阵中，观察到考虑到0.016的阈值，正面句子有922个（56.39%），负面句子有649个（39.69%），中性句子有64个（3.91%）。
- en: Also, notice that ChatGPT is less accurate with neutral labels. This is expected,
    as these are the labels that are more prone to be affected by the limits of the
    threshold. Interestingly, ChatGPT tended to categorize most of these neutral sentences
    as positive. However, since fewer sentences are considered neutral, this phenomenon
    may be related to greater positive sentiment scores in the dataset.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意ChatGPT在中性标签上的准确性较低。这是可以预期的，因为这些标签更容易受到阈值限制的影响。有趣的是，ChatGPT倾向于将大多数这些中性句子分类为正面句子。然而，由于中性句子较少，这一现象可能与数据集中较高的正面情感分数有关。
- en: On the other hand, when considering the other labels, ChatGPT showed the capacity
    to identify correctly 6pp more positive categories than negative (78.52% vs. 72.11%).
    In this case, I am not sure this is related to each score spectrum’s number of
    sentences. First, because there are much more sentences of each category type.
    Second, observe the number of ChatGPT’s misses that went to labels in the opposite
    direction (positive to negative or vice-versa). Again, ChatGPT makes more such
    mistakes with the negative category, which is much less numerous. Thus, ChatGPT
    seems more troubled with negative sentences than with positive ones.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在考虑其他标签时，ChatGPT显示出识别正面类别的能力比负面类别高出6个百分点（78.52%对72.11%）。在这种情况下，我不确定这是否与每个评分范围内句子的数量有关。首先，因为每种类别的句子数量更多。其次，请观察ChatGPT将标签错误分类到相反方向（正面到负面或反之）的次数。再次，ChatGPT在负面类别上的错误更多，而负面类别的句子数量较少。因此，ChatGPT似乎在处理负面句子时比处理正面句子时更有困难。
- en: 3.4\. Some specific cases and comparison to Human Specialists
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4\. 一些特定案例及与人类专家的比较
- en: I selected a few sentences with the most noticeable particularities between
    the Gold-Standard (human scores) and ChatGPT. Then, I used the same threshold
    established previously to convert the numerical scores into sentiment labels (0.016).
    Moreover, [ChatGPT has already been reported to outperform humans](https://arxiv.org/abs/2303.15056).
    Thus, I investigated the discrepancies and gave my ruling, to which either Humans
    or the Chatgpt I found was more precise.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了一些在Gold-Standard（人类评分）和ChatGPT之间具有最明显特征的句子。然后，我使用了之前确定的相同阈值将数值评分转换为情感标签（0.016）。此外，[ChatGPT已经被报道表现优于人类](https://arxiv.org/abs/2303.15056)。因此，我调查了这些差异，并给出了我的裁决，即人类还是ChatGPT更精确。
- en: 'Also, since at least 2018, the American agency [DARPA has delved into the significance
    of bringing explainability to AI decisions](https://www.darpa.mil/program/explainable-artificial-intelligence).
    Outstandingly, ChatPGT presents such a capacity: it can explain its decisions.
    This capability helped me to give my ruling. The table below displays this examination.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，自2018年以来，美国机构[DARPA已经深入研究了让AI决策具备解释性的重要性](https://www.darpa.mil/program/explainable-artificial-intelligence)。值得注意的是，ChatGPT具备这种能力：它可以解释其决策。这一能力帮助我做出了裁决。下表展示了这一检查结果。
- en: '![](../Images/f47bcdc041dd08bfd889a25b8321db1e.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f47bcdc041dd08bfd889a25b8321db1e.png)'
- en: The table shows examples of sentences with mismatches between the Gold-Standard
    labels (converted from human specialists’ scores using the 0.016 thresholds) and
    ChatGPT. Moreover, I gave my ruling on which I agreed best.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表格显示了Gold-Standard标签（通过使用0.016阈值从人类专家分数转换而来）与ChatGPT之间存在不匹配的句子示例。此外，我给出了我认为最好的裁决。
- en: 'Starting with the cases where I ruled in favor of human specialists. In the
    cases of sentences 3 and 4, ChatGPT should have realized that getting back payouts
    and company alliances are generally considered beneficial in the finance domain.
    However, in the case of sentence 7, I asked it to explain its decision, and here
    is what ChatGPT replied:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 从我支持人类专家的案例开始。在句子3和4的情况下，ChatGPT应该意识到，获得回款和公司联盟通常被认为在金融领域是有利的。然而，在句子7的情况下，我要求它解释其决定，ChatGPT的回复是：
- en: The positive sentiment towards Barclays is conveyed by the word “record,” which
    implies a significant accomplishment for the company in successfully resolving
    legal issues with regulatory bodies.
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对Barclays的积极情感通过“创纪录”一词传达，这意味着公司在成功解决与监管机构的法律问题上取得了显著成就。
- en: In the case of this sentence, ChatGPT did not comprehend that, although striking
    a record deal may generally be good, the SEC is a regulatory body. Hence, striking
    a record deal with the SEC means that Barclays and Credit Suisse had to pay a
    record value in fines.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个句子，ChatGPT没有理解到，尽管达成创纪录的交易通常是好的，但SEC是一个监管机构。因此，与SEC达成创纪录的交易意味着Barclays和Credit
    Suisse必须支付创纪录的罚款。
- en: Moving on to sentences 5 and 8, these were very tough calls. Let me be clear,
    humans were correct in their assessments. However, it is just the case that ChatGPT
    just couldn’t have guessed those ones. In sentence 5, it required knowledge of
    the situation at that moment in time to understand that the sentence represented
    a good outcome. And for sentence 8, knowledge is needed that an oil price drop
    correlates to a stock price drop for that specific target company.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 继续讨论句子5和8，这些都是非常艰难的判断。让我明确，人类在评估中是正确的。然而，ChatGPT确实无法猜到这些。在句子5中，需要了解当时的情况才能理解这个句子代表了一个好的结果。对于句子8，需要知道油价下跌与特定目标公司的股票价格下跌相关。
- en: 'Then, for sentence 6, the most neutral a sentence can get with a zero sentiment
    score, ChatGPT explained its decision as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，对于句子6，最中性的句子可以获得零情感分数，ChatGPT解释了其决定如下：
- en: The sentence is positive as it is announcing the appointment of a new Chief
    Operating Officer of Investment Bank, which is a good news for the company.
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这个句子是积极的，因为它宣布了新的投资银行首席运营官的任命，对公司来说是个好消息。
- en: However, this was a generic and not very insightful response and did not justify
    why ChatGPT thinks the appointment of this particular executive was good. Thus,
    I agreed with the human specialists in this case.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个回答很普通，没有很有洞察力，也没有解释为什么ChatGPT认为这位特定高管的任命是好的。因此，我在这种情况下同意了人类专家的观点。
- en: Interestingly, I ruled favorably in sentences 1, 2, 9, and 10 for ChatGPT. Moreover,
    looking carefully, human specialists should have paid more attention to the target
    company or the overall message. This is particularly emblematic in sentence 1,
    where specialists should have recognized that although the sentiment was positive
    for Glencore, the target company was Barclays, which just wrote the report. In
    this sense, ChatGPT did better discerning the sentiment target and meaning in
    these sentences.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我在句子1、2、9和10中对ChatGPT的评判是有利的。此外，仔细观察，人类专家应该更多关注目标公司或整体信息。这在句子1中尤其明显，专家们应当认识到虽然对Glencore的情感是积极的，但目标公司是Barclays，而不是撰写报告的公司。在这方面，ChatGPT在识别情感目标和意义方面做得更好。
- en: 4\. Conclusion and Results Discussion
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 结论和结果讨论
- en: As seen in the table below, achieving such a performance required lots of financial
    and human resources.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从下表可以看出，实现这样的表现需要大量的财务和人力资源。
- en: '![](../Images/21adc02dbe9932ffa050d45c2473ef8f.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/21adc02dbe9932ffa050d45c2473ef8f.png)'
- en: A comparison of aspects of models such as the number of parameters, word embedding
    size used, cost, the number of researchers to build it, best accuracy in the test
    set, and whether its decision is explainable.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 比较模型的各个方面，例如参数数量、使用的词嵌入大小、成本、构建所需的研究人员数量、测试集中的最佳准确性，以及其决策是否可解释。
- en: In this sense, even though ChatGPT outperformed the domain-specific model, the
    ultimate comparison would need fine-tuning ChatGPT for a domain-specific task.
    Doing so would help address if the gains in performance of fine-tuning outweigh
    the effort costs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，尽管ChatGPT优于领域特定模型，但最终比较仍需要对ChatGPT进行领域特定任务的微调。这将有助于确定微调的性能提升是否超过了投入的成本。
- en: Furthermore, [one of the most essential factors in a textual model is the size
    of the word embeddings](https://doi.org/10.5753/eniac.2019.9329). This technology
    has evolved since the SemEval 2017 edition. Thus, some updates in this part could
    significantly increase the results of the domain-specific model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，[文本模型中最重要的因素之一是词嵌入的大小](https://doi.org/10.5753/eniac.2019.9329)。自 SemEval
    2017 版以来，这项技术已有所发展。因此，这部分的一些更新可能会显著提高领域特定模型的结果。
- en: On another note, with the popularity of generative text models and LLMs, some
    [open-source versions](https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html)
    could help assemble an interesting future comparison. Moreover, the capacity of
    LLMs such as ChatGPT to explain their decisions is an outstanding, arguably unexpected
    accomplishment that can revolutionize the field.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，随着生成文本模型和大型语言模型（LLMs）的流行，一些[开源版本](https://www.kdnuggets.com/2023/04/8-opensource-alternative-chatgpt-bard.html)可以帮助组装一个有趣的未来对比。此外，像
    ChatGPT 这样的 LLM 能够解释其决策是一个杰出的、可能出乎意料的成就，这可能会彻底改变这一领域。
- en: '5\. BONUS: How this comparison can be done in an applied scenario'
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 附加：如何在应用场景中进行这种对比
- en: Sentiment analysis in different domains is a stand-alone scientific endeavor
    on its own. Still, applying the results of sentiment analysis in an appropriate
    scenario can be another scientific problem. Also, as we are considering sentences
    from the financial domain, it would be convenient to experiment with adding sentiment
    features to an applied intelligent system. This is precisely what some researchers
    have been doing, and I am experimenting with that, also.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同领域的情感分析是一个独立的科学工作。然而，在合适的场景中应用情感分析的结果可能是另一个科学问题。此外，考虑到我们处理的是金融领域的句子，尝试将情感特征添加到应用智能系统中会比较方便。这正是一些研究人员一直在做的事情，我也在尝试这样做。
- en: In 2021 I and some colleagues published a [research article on how to employ
    sentiment analysis on a applied scenario](https://doi.org/10.1145/3490354.3494445).
    In this article — presented at the Second ACM International Conference on AI in
    Finance (ICAIF’21) — we proposed an efficient way to incorporate market sentiment
    into a reinforcement learning architecture. The source code for the implementation
    of this architecture is [available here](https://github.com/xicocaio/its-sentarl),
    and a part of it’s overall design is displayed below.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2021 年，我和一些同事发表了一篇[关于如何在应用场景中使用情感分析的研究文章](https://doi.org/10.1145/3490354.3494445)。在这篇文章中——在第二届
    ACM 国际金融人工智能会议（ICAIF’21）上呈现——我们提出了一种将市场情绪纳入强化学习架构的高效方法。该架构的实现源代码[在这里可以获得](https://github.com/xicocaio/its-sentarl)，其整体设计的一部分如下所示。
- en: '![](../Images/94e44b2161b2b5b156194d6a9e398531.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94e44b2161b2b5b156194d6a9e398531.png)'
- en: 'A part of an architecture example of how to incorporate market sentiment into
    a reinforcement learning architecture for applied situations. **Source:** *Intelligent
    Trading Systems: A Sentiment-Aware Reinforcement Learning Approach. Proceedings
    of the Second ACM International Conference on AI in Finance (ICAIF ‘21).* ***Lima
    Paiva, F. C.****; Felizardo, L. K.; Bianchi, R. A. d. C. B.; Costa, A. H. R.*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个将市场情绪纳入应用场景的强化学习架构的示例架构部分。**来源：** *《智能交易系统：一种情感感知的强化学习方法》。第二届 ACM 国际金融人工智能会议（ICAIF
    ‘21）论文集。* ***Lima Paiva, F. C.****; Felizardo, L. K.; Bianchi, R. A. d. C. B.;
    Costa, A. H. R.*
- en: This architecture was designed to work with numerical sentiment scores like
    those in the Gold-Standard dataset. Still, there are techniques (e.g., [Bullishnex
    index](https://doi.org/10.1111/j.1540-6261.2004.00662.x)) for converting categorical
    sentiment, as generated by ChatGPT in appropriate numerical values. Applying such
    a conversion makes it possible to use ChatGPT-labeled sentiment in such an architecture.
    Moreover, this is an example of what you can do in such a situation and is what
    I intend to do in a future analysis.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 该架构旨在处理像 Gold-Standard 数据集中那样的数值情感分数。然而，也有技术（例如，[Bullishnex 指数](https://doi.org/10.1111/j.1540-6261.2004.00662.x)）可以将由
    ChatGPT 生成的类别情感转换为适当的数值。应用这种转换使得可以在这样的架构中使用 ChatGPT 标记的情感。此外，这也是在这种情况下可以做的一种示例，并且是我计划在未来分析中做的事情。
- en: 5.1\. Other articles in my line of research (NLP, RL)
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1\. 我研究领域的其他文章（NLP，RL）
- en: '***Lima Paiva, F. C.****; Felizardo, L. K.; Bianchi, R. A. d. C. B.; Costa,
    A. H. R.* [*Intelligent Trading Systems: A Sentiment-Aware Reinforcement Learning
    Approach*](https://doi.org/10.1145/3490354.3494445). Proceedings of the Second
    ACM International Conference on AI in Finance (ICAIF ‘21).'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***利马·帕伊瓦，F. C.****; 弗利扎多，L. K.; 比安基，R. A. d. C. B.; 科斯塔，A. H. R.* [*智能交易系统：一种情感感知的强化学习方法*](https://doi.org/10.1145/3490354.3494445)。第二届ACM国际金融人工智能会议（ICAIF
    ‘21）论文集。'
- en: 'Felizardo, L. K.; **Lima Paiva, F. C.**; de Vita Graves, C.; Matsumoto, E.
    Y.; Costa, A. H. R.; Del-Moral-Hernandez, E.; Brandimarte, P. [*Outperforming
    algorithmic trading reinforcement learning systems: A supervised approach to the
    cryptocurrency market*](https://doi.org/10.1016/j.eswa.2022.117259). Expert Systems
    with Applications (2022), v. 202, p. 117259.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弗利扎多，L. K.; **利马·帕伊瓦，F. C.**; 德维塔·格雷夫斯，C.; 松本，E. Y.; 科斯塔，A. H. R.; 德尔-莫拉尔-埃尔南德斯，E.;
    布兰迪马特，P. [*超越算法交易强化学习系统：对加密货币市场的监督方法*](https://doi.org/10.1016/j.eswa.2022.117259)。应用专家系统（2022年），第202卷，第117259页。
- en: 'Felizardo, L. K.; **Lima Paiva, F. C.**; Costa, A. H. R.; Del-Moral-Hernandez,
    E. [*Reinforcement Learning Applied to Trading Systems: A Survey*](https://arxiv.org/abs/2212.06064)*.*
    arXiv, 2022.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弗利扎多，L. K.; **利马·帕伊瓦，F. C.**; 科斯塔，A. H. R.; 德尔-莫拉尔-埃尔南德斯，E. [*应用于交易系统的强化学习：一项调查*](https://arxiv.org/abs/2212.06064)*.*
    arXiv，2022年。
- en: Resources Used Here
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的资源
- en: '[Comparison Jupyter notebook](https://drive.google.com/drive/folders/1_FpNvcGjnl8N2Z_Az3FGGWQ4QxmutmgG?usp=sharing)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比较 Jupyter 笔记本](https://drive.google.com/drive/folders/1_FpNvcGjnl8N2Z_Az3FGGWQ4QxmutmgG?usp=sharing)'
- en: '[Domain-specific machine learning model](https://bit.ly/3kzau8G)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[领域特定机器学习模型](https://bit.ly/3kzau8G)'
- en: '[Gold-Standard Dataset](https://bitbucket.org/ssix-project/semeval-2017-task-5-subtask-2/src/master/)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[金标准数据集](https://bitbucket.org/ssix-project/semeval-2017-task-5-subtask-2/src/master/)'
- en: '[Code for applied sentiment analsyis scenario (ITS-SentARL)](https://github.com/xicocaio/its-sentarl)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[应用情感分析场景的代码（ITS-SentARL）](https://github.com/xicocaio/its-sentarl)'
- en: Main References
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要参考文献
- en: 'Khadjeh Nassirtoussi, A., Aghabozorgi, S., Ying Wah, T., and Ngo, D. C. L.
    [Text mining for market prediction: A systematic review](http://dx.doi.org/10.1016/j.eswa.2014.06.009).
    Expert Systems with Applications (2014), 41(16):7653–7670.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡杰赫·纳西尔图西，A.，阿赫博佐尔吉，S.，英·瓦赫，T.，和吴，D. C. L. [市场预测中的文本挖掘：一项系统综述](http://dx.doi.org/10.1016/j.eswa.2014.06.009)。应用专家系统（2014年），41(16):7653–7670。
- en: Loughran, T. and Mcdonald, B. [When Is a Liability Not a Liability ? Textual
    Analysis , Dictionaries , and 10-Ks](https://doi.org/10.1111/j.1540-6261.2010.01625.x).
    Journal of Finance (2011), 66(1):35–65.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 洛赫兰，T. 和 麦克唐纳，B. [何为负债？文本分析、词典和10-K报告](https://doi.org/10.1111/j.1540-6261.2010.01625.x)。金融杂志（2011年），66(1):35–65。
- en: Hamilton, W. L., Clark, K., Leskovec, J., and Jurafsky, D. [Inducing domain-specific
    sentiment lexicons from unlabeled corpora.](https://aclanthology.org/D16-1057/)
    Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,
    pages 595–605.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汉密尔顿，W. L.，克拉克，K.，列斯科维奇，J.，和朱拉夫斯基，D. [从未标记语料库中诱导领域特定情感词典。](https://aclanthology.org/D16-1057/)
    2016年自然语言处理经验方法会议论文集，页595–605。
- en: 'Cortis, K.; Freitas, A.; Daudert, T.; Huerlimann, M.; Zarrouk, M.; Handschuh,
    S.; Davis, B. [*SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial
    Microblogs and News*](https://aclanthology.org/S17-2089/). Proceedings of the
    11th International Workshop on Semantic Evaluation (SemEval-2017).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科尔蒂斯，K.; 弗雷塔斯，A.; 道德特，T.; 赫尔利曼，M.; 扎鲁克，M.; 汉施胡，S.; 戴维斯，B. [*SemEval-2017任务5：金融微博和新闻的细粒度情感分析*](https://aclanthology.org/S17-2089/)。第11届语义评价国际研讨会（SemEval-2017）论文集。
- en: Davis, B., Cortis, K., Vasiliu, L., Koumpis, A., Mcdermott, R., and Handschuh,
    S. [Social Sentiment Indices Powered by X-Scores](https://www.thinkmind.org/index.php?view=article&articleid=alldata_2016_1_40_90041).
    ALLDATA, The Second Inter-national Conference on Big Data, Small Data, Linked
    Data and Open Data (2016).
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 戴维斯，B.，科尔蒂斯，K.，瓦西留，L.，孔皮斯，A.，麦克德莫特，R.，和汉施胡，S. [由X-Scores驱动的社交情感指数](https://www.thinkmind.org/index.php?view=article&articleid=alldata_2016_1_40_90041)。ALLDATA，第二届国际大数据、小数据、关联数据和开放数据会议（2016年）。
- en: Ferreira, Taynan; **Lima Paiva, F. C.**; Silva, Roberto da; Paula, Angel de;
    Costa, Anna; Cugnasca, Carlos. [*Assessing Regression-Based Sentiment Analysis
    Techniques in Financial Texts*](https://doi.org/10.5753/eniac.2019.9329). 16th
    National Meeting on Artificial and Computational Intelligence (ENIAC), 2019.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferreira, Taynan; **利马·帕伊瓦，F. C.**; 西尔瓦，罗伯托·达; 保拉，安赫尔·德; 科斯塔，安娜; 库尼亚斯卡，卡洛斯。[*评估基于回归的金融文本情感分析技术*](https://doi.org/10.5753/eniac.2019.9329)。第16届国家人工智能与计算智能会议（ENIAC），2019年。
- en: Reaching Out
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系方式
- en: '[Linkedin](https://www.linkedin.com/in/xicocaio/)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Linkedin](https://www.linkedin.com/in/xicocaio/)'
- en: '[Website](https://sites.google.com/alumni.usp.br/francisco-paiva)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[网站](https://sites.google.com/alumni.usp.br/francisco-paiva)'
- en: '[Research Gate](https://www.researchgate.net/profile/Francisco-Lima-Paiva)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[研究门户](https://www.researchgate.net/profile/Francisco-Lima-Paiva)'
