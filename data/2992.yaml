- en: 16, 8, and 4-bit Floating Point Formats — How Does it Work?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 16位、8位和4位浮点格式——它是如何工作的？
- en: 原文：[https://towardsdatascience.com/16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef?source=collection_archive---------0-----------------------#2023-09-30](https://towardsdatascience.com/16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef?source=collection_archive---------0-----------------------#2023-09-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef?source=collection_archive---------0-----------------------#2023-09-30](https://towardsdatascience.com/16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef?source=collection_archive---------0-----------------------#2023-09-30)
- en: Let’s go into bits and bytes
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们深入探讨位和字节
- en: '[](https://dmitryelj.medium.com/?source=post_page-----d157a31ef2ef--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----d157a31ef2ef--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d157a31ef2ef--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d157a31ef2ef--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----d157a31ef2ef--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://dmitryelj.medium.com/?source=post_page-----d157a31ef2ef--------------------------------)[![Dmitrii
    Eliuseev](../Images/7c48f0c016930ead59ddb785eaf3e0e6.png)](https://dmitryelj.medium.com/?source=post_page-----d157a31ef2ef--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d157a31ef2ef--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d157a31ef2ef--------------------------------)
    [Dmitrii Eliuseev](https://dmitryelj.medium.com/?source=post_page-----d157a31ef2ef--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F65c1f6ba75db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef&user=Dmitrii+Eliuseev&userId=65c1f6ba75db&source=post_page-65c1f6ba75db----d157a31ef2ef---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d157a31ef2ef--------------------------------)
    ·13 min read·Sep 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd157a31ef2ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef&user=Dmitrii+Eliuseev&userId=65c1f6ba75db&source=-----d157a31ef2ef---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F65c1f6ba75db&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef&user=Dmitrii+Eliuseev&userId=65c1f6ba75db&source=post_page-65c1f6ba75db----d157a31ef2ef---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d157a31ef2ef--------------------------------)
    · 13分钟阅读 · 2023年9月30日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd157a31ef2ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef&user=Dmitrii+Eliuseev&userId=65c1f6ba75db&source=-----d157a31ef2ef---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd157a31ef2ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef&source=-----d157a31ef2ef---------------------bookmark_footer-----------)![](../Images/476c842d2b1c3c19c59cc3d6b6898aa1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd157a31ef2ef&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F16-8-and-4-bit-floating-point-formats-how-does-it-work-d157a31ef2ef&source=-----d157a31ef2ef---------------------bookmark_footer-----------)![](../Images/476c842d2b1c3c19c59cc3d6b6898aa1.png)'
- en: Image by Adrien Converse on [Unsplash](https://unsplash.com/@adrienconverse)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自Adrien Converse在[Unsplash](https://unsplash.com/@adrienconverse)
- en: For 50 years, from the time of Kernighan, Ritchie, and their 1st edition of
    the C Language book, it was known that a single-precision “float” type has a 32-bit
    size and a double-precision type has 64 bits. There was also an 80-bit “long double”
    type with extended precision, and all these types covered almost all the needs
    for floating-point data processing. However, during the last few years, the advent
    of large neural network models required developers to move into another part of
    the spectrum and to shrink floating point types as much as possible.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 50年来，从Kernighan、Ritchie及其《C语言》第一版开始，人们知道单精度的“float”类型具有32位大小，而双精度类型则有64位。还有一种80位的“long
    double”类型，具有扩展的精度，所有这些类型几乎涵盖了浮点数据处理的所有需求。然而，近年来，随着大型神经网络模型的出现，开发者们需要进入另一部分领域，并尽可能地缩小浮点类型的大小。
- en: Honestly, I was surprised when I discovered that the 4-bit floating-point format
    exists. How on Earth can it be possible? The best way to know is to test it on
    our own. In this article, we will discover the most popular floating point formats,
    make a simple neural network, and see how it works.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 说实话，当我发现4位浮点格式存在时感到很惊讶。究竟怎么可能呢？最好的方法是亲自测试。在本文中，我们将探讨最流行的浮点格式，创建一个简单的神经网络，并观察它的工作原理。
- en: Let’s get started.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: A “Standard” 32-bit Floating point
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “标准”32位浮点数
- en: 'Before going into “extreme” formats, let’s recall a standard one. An [IEEE
    754](https://en.wikipedia.org/wiki/IEEE_754) standard for floating-point arithmetic
    was established in 1985 by the Institute of Electrical and Electronics Engineers
    (IEEE). A typical number in a 32-float type looks like this:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入“极端”格式之前，先回顾一个标准格式。[IEEE 754](https://en.wikipedia.org/wiki/IEEE_754)浮点运算标准由电气和电子工程师协会（IEEE）于1985年制定。一个典型的32位浮点数如下所示：
