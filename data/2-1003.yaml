- en: 'GPT-4 vs. ChatGPT: An exploration of training, performance, capabilities, and
    limitations'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-4与ChatGPT：对训练、性能、能力和局限性的探讨
- en: 原文：[https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5](https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5](https://towardsdatascience.com/gpt-4-vs-chatgpt-an-exploration-of-training-performance-capabilities-and-limitations-35c990c133c5)
- en: GPT-4 is an improvement, but temper your expectations.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4是一次改进，但要适度期望。
- en: '[](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)[![Mary
    Newhauser](../Images/7f0d7287f7b735bb9391858f1fc641ee.png)](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)
    [Mary Newhauser](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)[![Mary
    Newhauser](../Images/7f0d7287f7b735bb9391858f1fc641ee.png)](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)
    [Mary Newhauser](https://medium.com/@mary.newhauser?source=post_page-----35c990c133c5--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)
    ·7 min read·Mar 17, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----35c990c133c5--------------------------------)
    ·阅读时长7分钟·2023年3月17日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/8ebc0c71e1eaa32026c30fe54eb8b0d9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ebc0c71e1eaa32026c30fe54eb8b0d9.png)'
- en: Image created by the author.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创作。
- en: OpenAI stunned the world when it dropped [ChatGPT](https://openai.com/blog/chatgpt)
    in late 2022\. The new generative language model is expected to totally transform
    entire industries, including media, education, law, and tech. In short, ChatGPT
    threatens to disrupt just about everything. And even before we had time to truly
    envision a post-ChatGPT world, OpenAI dropped [GPT-4](https://openai.com/research/gpt-4).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI在2022年底发布了[ChatGPT](https://openai.com/blog/chatgpt)，震惊了世界。这个新的生成语言模型预计将彻底改变整个行业，包括媒体、教育、法律和技术。简而言之，ChatGPT威胁到几乎所有的领域。即便在我们还没来得及真正设想后ChatGPT时代的世界时，OpenAI又发布了[GPT-4](https://openai.com/research/gpt-4)。
- en: In recent months, the speed with which groundbreaking large language models
    have been released is astonishing. If you still don’t understand how ChatGPT differs
    from GPT-3, let alone GPT-4, I don’t blame you.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最近几个月，突破性的大型语言模型发布的速度令人惊叹。如果你仍然不理解ChatGPT与GPT-3，甚至是GPT-4的区别，我不怪你。
- en: In this article, we will cover the key similarities and differences between
    ChatGPT and GPT-4, including their training methods, performance and capabilities,
    and limitations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨ChatGPT和GPT-4之间的关键相似点和差异，包括它们的训练方法、性能和能力，以及局限性。
- en: 'ChatGPT vs. GPT-4: Similarities & differences in training methods'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT与GPT-4：训练方法的相似性与差异
- en: ChatGPT and GPT-4 both stand on the shoulders of giants, building on previous
    versions of GPT models while adding improvements to model architecture, employing
    more sophisticated training methods, and increasing the number of training parameters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT和GPT-4都建立在前人的基础上，继承了先前版本的GPT模型，同时在模型架构上进行改进，采用更复杂的训练方法，并增加了训练参数的数量。
- en: Both models are based on the transformer architecture. [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
    and [GPT-3](https://arxiv.org/pdf/2005.14165.pdf) use multi-headed self-attention
    to decide which text inputs to pay the most attention to. The models also use
    a [decoder-only](https://jalammar.github.io/illustrated-gpt2/) architecture that
    generates output sequences one token at a time, iteratively predicting the next
    token in a sequence. Although the precise architectures for ChatGPT and GPT-4
    have not been released, we can assume they continue to be decoder-only models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 两种模型都基于变换器架构。[GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)和
    [GPT-3](https://arxiv.org/pdf/2005.14165.pdf) 使用多头自注意力机制来决定关注哪些文本输入。模型还使用[仅解码器](https://jalammar.github.io/illustrated-gpt2/)架构，逐个生成输出序列，迭代预测序列中的下一个标记。虽然ChatGPT和GPT-4的具体架构尚未公布，但我们可以假设它们仍然是仅解码器模型。
- en: OpenAI’s [GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf) offers
    little information on GPT-4’s model architecture and training process, citing
    the “competitive landscape and the safety implications of large-scale models.”
    What we do know is that ChatGPT and GPT-4 are probably trained in a similar manner,
    which is a departure from training methods used for GPT-2 and GPT-3\. We know
    much more about the training methods for ChatGPT than GPT-4, so we’ll start there.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的[GPT-4技术报告](https://cdn.openai.com/papers/gpt-4.pdf)对于GPT-4的模型架构和训练过程信息有限，引用了“大规模模型的竞争格局和安全性影响”。我们所知道的是，ChatGPT和GPT-4可能以类似的方式进行训练，这与GPT-2和GPT-3的训练方法有所不同。我们对ChatGPT的训练方法了解更多，因此我们从这里开始。
- en: ChatGPT
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT
- en: To start with, ChatGPT is trained on dialogue datasets, including demonstration
    data, in which human annotators provide demonstrations of the expected output
    of a chatbot assistant in response to specific prompts. This data is used to fine-tune
    GPT3.5 with supervised learning, producing a policy model, which is used to generate
    multiple responses when fed prompts. Human annotators then rank which of the responses
    for a given prompt produced the best results, which is used to train a reward
    model. The reward model is then used to iteratively fine-tune the policy model
    using reinforcement learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，ChatGPT在对话数据集上进行训练，包括演示数据，其中人类注释员提供对特定提示的聊天助手预期输出的演示。这些数据用于用监督学习微调GPT3.5，生成一个策略模型，该模型在输入提示时生成多个响应。然后，人类注释员对每个提示的响应进行排名，以确定哪个响应效果最佳，这用于训练奖励模型。奖励模型随后用于通过强化学习迭代微调策略模型。
- en: '![](../Images/c520850d7d2cfde00d40aafaf710a0b7.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c520850d7d2cfde00d40aafaf710a0b7.png)'
- en: Image created by the author.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建。
- en: To sum it up in one sentence, ChatGPT is trained using [Reinforcement Learning
    from Human Feedback](https://openai.com/research/learning-from-human-preferences)
    (RLHF), a way of incorporating human feedback to improve a language model during
    training. *This allows the model’s output to align to the task requested by the
    user, rather than just predict the next word in a sentence based on a corpus of
    generic training data, like GPT-3.*
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，ChatGPT使用[来自人类反馈的强化学习](https://openai.com/research/learning-from-human-preferences)（RLHF）进行训练，这是一种在训练过程中整合人类反馈以改进语言模型的方法。*这使得模型的输出可以与用户请求的任务对齐，而不仅仅是根据通用训练数据语料库预测句子中的下一个词，就像GPT-3一样。*
- en: GPT-4
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4
- en: OpenAI has yet to divulge details on how it trained GPT-4\. Their Technical
    Report doesn’t include “details about the architecture (including model size),
    hardware, training compute, dataset construction, training method, or similar.”
    *What we do know is that GPT-4 is a transformer-style generative multimodal model
    trained on both publicly available data and licensed third-party data and subsequently
    fine-tuned using RLHF.* Interestingly, OpenAI did share details regarding their
    upgraded RLHF techniques to make the model responses more accurate and less likely
    to veer outside safety guardrails.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI尚未透露如何训练GPT-4。他们的技术报告中不包括“关于架构（包括模型大小）、硬件、训练计算、数据集构建、训练方法或类似内容的详细信息”。*我们所知道的是，GPT-4是一个变换器风格的生成多模态模型，训练数据包括公开可用的数据和授权的第三方数据，并随后使用RLHF进行微调。*
    有趣的是，OpenAI分享了他们升级的RLHF技术细节，以使模型响应更准确，减少偏离安全保护措施的可能性。
- en: After training a policy model (as with ChatGPT), RLHF is used in adversarial
    training, a process that trains a model on malicious examples intended to deceive
    the model in order to defend the model against such examples in the future. In
    the case of GPT-4, human domain experts across several fields rate the responses
    of the policy model to adversarial prompts. These responses are then used to train
    additional reward models that iteratively fine-tune the policy model, resulting
    in a model that’s less likely to give out dangerous, evasive, or inaccurate responses.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个策略模型（如 ChatGPT）后，RLHF 被用于对抗性训练，这是一个通过恶意示例训练模型的过程，目的是让模型防御未来的此类示例。以 GPT-4
    为例，来自多个领域的人类领域专家对策略模型对抗性提示的响应进行评分。这些响应随后被用来训练额外的奖励模型，迭代地微调策略模型，最终得到一个不容易产生危险、回避或不准确回答的模型。
- en: '![](../Images/3f22d2d1c180b28800d23f55ed6a6a46.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3f22d2d1c180b28800d23f55ed6a6a46.png)'
- en: Image created by the author.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者创建的图像。
- en: 'ChatGPT vs. GPT-4: Similarities & differences in performance and capabilities'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 与 GPT-4：性能和能力的相似性与差异
- en: Capabilities
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 能力
- en: In terms of capabilities, ChatGPT and GPT-4 are more similar than they are different.
    Like its predecessor, GPT-4 also interacts in a conversational style that aims
    to align with the user. As you can see below, the responses between the two models
    for a broad question are very similar.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在能力方面，ChatGPT 和 GPT-4 比较类似，而不是不同。像其前身一样，GPT-4 也以对话风格进行互动，旨在与用户对齐。如下面所示，对于一个广泛的问题，两者的回应非常相似。
- en: '![](../Images/678e8b3ff33d0bfa3463a090d0379362.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/678e8b3ff33d0bfa3463a090d0379362.png)'
- en: Image created by the author.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由作者创建的图像。
- en: OpenAI agrees that the distinction between the models can be subtle and claims
    that “difference comes out when the complexity of the task reaches a sufficient
    threshold.” Given the six months of adversarial training the GPT-4 base model
    underwent in its post-training phase, this is probably an accurate characterization.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 同意模型之间的区别可能很微妙，并声称“当任务的复杂性达到足够的阈值时，区别才会显现。”鉴于 GPT-4 基础模型在其后训练阶段经历了六个月的对抗性训练，这大概是一个准确的描述。
- en: Unlike ChatGPT, which accepts only text, GPT-4 accepts prompts composed of both
    images and text, returning textual responses. As of the publishing of this article,
    unfortunately, the capacity for using image inputs is not yet available to the
    public.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 与只接受文本的 ChatGPT 不同，GPT-4 接受由图像和文本组成的提示，返回文本回应。截至本文发布时，不幸的是，使用图像输入的功能尚未向公众开放。
- en: Performance
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能
- en: As referenced earlier, OpenAI reports significant improvement in safety performance
    for GPT-4, compared to GPT-3.5 (from which ChatGPT was fine-tuned). However, whether
    the reduction in responses to requests for disallowed content, reduction in toxic
    content generation, and improved responses to sensitive topics are due to the
    GPT-4 model itself or the additional adversarial testing is unclear at this time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，OpenAI 报告称，相比于 GPT-3.5（ChatGPT 是在此基础上微调的），GPT-4 在安全性表现上有显著改进。然而，目前尚不清楚对禁止内容请求的响应减少、毒性内容生成减少和对敏感话题的改善是否由于
    GPT-4 模型本身还是额外的对抗性测试。
- en: Additionally, GPT-4 outperforms GPT-3.5 on most academic and professional exams
    taken by humans. Notably, GPT-4 scores in the 90th percentile on the Uniform Bar
    Exam compared to GPT-3.5, which scores in the 10th percentile. GPT-4 also significantly
    outperforms its predecessor on traditional language model benchmarks as well as
    other SOTA models (although sometimes just barely).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，GPT-4 在大多数由人类参加的学术和职业考试中表现优于 GPT-3.5。值得注意的是，GPT-4 在统一律师考试中得分在第 90 个百分位，而
    GPT-3.5 的得分在第 10 个百分位。GPT-4 在传统语言模型基准测试和其他 SOTA 模型上也显著优于其前身（尽管有时只是略微）。
- en: 'ChatGPT vs. GPT-4: Similarities & differences in limitations'
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 与 GPT-4：限制的相似性与差异
- en: Both ChatGPT and GPT-4 have significant limitations and risks. The GPT-4 System
    Card includes insights from a detailed exploration of such risks conducted by
    OpenAI.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 和 GPT-4 都有显著的限制和风险。GPT-4 系统卡包括 OpenAI 对这些风险的详细探索所得的见解。
- en: 'These are just a few of the risks associated with both models:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是与这两个模型相关的一些风险：
- en: Hallucination (the tendency to produce nonsensical or factually inaccurate content)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幻觉（产生无意义或事实不准确内容的倾向）
- en: Producing harmful content that violates OpenAI’s policies (e.g. hate speech,
    incitements to violence)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成违反 OpenAI 政策的有害内容（例如仇恨言论、煽动暴力）
- en: Amplifying and perpetuating stereotypes of marginalized people
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 放大和延续边缘化群体的刻板印象
- en: Generating realistic disinformation intended to deceive
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成旨在欺骗的逼真虚假信息
- en: While ChatGPT and GPT-4 struggle with the same limitations and risks, OpenAI
    has made special efforts, including extensive adversarial testing, to mitigate
    them for GPT-4\. While this is encouraging, the GPT-4 System Card ultimately demonstrates
    how vulnerable ChatGPT was (and possibly still is). For a more detailed explanation
    of harmful unintended consequences, I recommend reading the GPT-4 System Card,
    which starts on page 38 of the [GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 ChatGPT 和 GPT-4 遇到相同的局限性和风险，OpenAI 已做出特别努力，包括广泛的对抗性测试，以减轻这些问题对 GPT-4 的影响。虽然这令人鼓舞，但
    GPT-4 系统卡片最终展示了 ChatGPT 的脆弱性（以及可能仍然存在的脆弱性）。有关有害意外后果的更详细解释，我推荐阅读 GPT-4 系统卡片，该文档从
    [GPT-4 技术报告](https://cdn.openai.com/papers/gpt-4.pdf) 第 38 页开始。
- en: Conclusion
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we review the most important similarities and differences between
    ChatGPT and GPT-4, including their training methods, performance and capabilities,
    and limitations and risks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们回顾了 ChatGPT 和 GPT-4 之间最重要的相似性和差异，包括它们的训练方法、性能和能力，以及限制和风险。
- en: While we know much less about the model architecture and training methods behind
    GPT-4, it appears to be a refined version of ChatGPT that now accepts image and
    text inputs and claims to be safer, more accurate, and more creative. Unfortunately,
    we will have to take OpenAI’s word for it, as GPT-4 is only available as part
    of the ChatGPT Plus subscription.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们对 GPT-4 背后的模型架构和训练方法知之甚少，但它似乎是 ChatGPT 的一个改进版本，现在支持图像和文本输入，并声称更安全、更准确、更具创造性。不幸的是，我们只能听从
    OpenAI 的说法，因为 GPT-4 仅作为 ChatGPT Plus 订阅的一部分提供。
- en: 'The table below illustrates the most important similarities and differences
    between ChatGPT and GPT-4:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了 ChatGPT 和 GPT-4 之间最重要的相似性和差异：
- en: '![](../Images/38414f3c07eba431c9d5bd868106ee91.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/38414f3c07eba431c9d5bd868106ee91.png)'
- en: Image created by the author.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者创建。
- en: The race for creating the most accurate and dynamic large language models has
    reached breakneck speed, with the release of ChatGPT and GPT-4 within mere months
    of each other. Staying informed on the advancements, risks, and limitations of
    these models is essential as we navigate this exciting but rapidly evolving landscape
    of large language models.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建最准确和动态的大型语言模型的竞赛已达到快速发展的阶段，ChatGPT 和 GPT-4 的发布仅相隔数月。了解这些模型的进展、风险和局限性是至关重要的，因为我们在这个令人兴奋但快速变化的大型语言模型领域中航行。
- en: '*If you’d like to stay up-to-date on the latest data science trends, technologies,
    and packages, consider becoming a Medium member. You’ll get unlimited access to
    articles and blogs like Towards Data Science and you’ll be supporting my writing.
    (I earn a small commission for each membership).*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你希望跟上最新的数据科学趋势、技术和工具，可以考虑成为 Medium 会员。你将获得对像 Towards Data Science 这样的文章和博客的无限访问权，并且你也在支持我的写作。（我每卖出一份会员资格都会获得少量佣金）。*'
- en: '[](https://medium.com/@mary.newhauser/membership?source=post_page-----35c990c133c5--------------------------------)
    [## Join Medium with my referral link - Mary Newhauser'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mary.newhauser/membership?source=post_page-----35c990c133c5--------------------------------)
    [## 通过我的推荐链接加入 Medium - Mary Newhauser'
- en: Get access to unlimited Medium articles for $5 per month 🤗 Your membership fee
    directly supports Mary Newhauser and…
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 以每月 5 美元获取无限 Medium 文章 🤗 你的会员费用直接支持 Mary Newhauser 和…
- en: medium.com](https://medium.com/@mary.newhauser/membership?source=post_page-----35c990c133c5--------------------------------)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@mary.newhauser/membership?source=post_page-----35c990c133c5--------------------------------)
- en: Want to connect?
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 想要联系我？
- en: 📖 Follow me on [Medium](https://medium.com/@mary.newhauser)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 📖 在 [Medium](https://medium.com/@mary.newhauser) 上关注我
- en: 💌 [Subscribe](https://medium.com/@mary.newhauser/subscribe) to get an email
    whenever I publish
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 💌 [订阅](https://medium.com/@mary.newhauser/subscribe) 以在我发布新内容时收到邮件
- en: 🖌️ Check out my generative AI [blog](https://www.gptechblog.com/)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🖌️ 查看我的生成式 AI [博客](https://www.gptechblog.com/)
- en: 🔗 Take a look at my [portfolio](https://www.datascienceportfol.io/marynewhauser)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🔗 查看我的 [作品集](https://www.datascienceportfol.io/marynewhauser)
- en: 👩‍🏫 I’m also a data science [coach](https://www.datajump.co/)!
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 👩‍🏫 我也是一名数据科学 [教练](https://www.datajump.co/)！
- en: 'I’ve also written:'
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我还写过：
- en: '[](https://medium.com/nlplanet/fine-tuning-distilbert-on-senator-tweets-a6f2425ca50e?source=post_page-----35c990c133c5--------------------------------)
    [## Fine-tuning DistilBERT on senator tweets'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/nlplanet/fine-tuning-distilbert-on-senator-tweets-a6f2425ca50e?source=post_page-----35c990c133c5--------------------------------)
    [## 微调 DistilBERT 以处理参议员推文'
- en: A guide to fine-tuning DistilBERT on the tweets of American Senators with snscrape,
    SQLite, and Transformers (PyTorch)…
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一份关于如何使用 snscrape、SQLite 和 Transformers (PyTorch) 微调 DistilBERT，以处理美国参议员的推文的指南……
- en: medium.com](https://medium.com/nlplanet/fine-tuning-distilbert-on-senator-tweets-a6f2425ca50e?source=post_page-----35c990c133c5--------------------------------)
    [](/making-the-jump-from-data-analyst-to-data-scientist-in-2023-74e2cf7fc139?source=post_page-----35c990c133c5--------------------------------)
    [## Making the Jump from Data Analyst to Data Scientist in 2023
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/nlplanet/fine-tuning-distilbert-on-senator-tweets-a6f2425ca50e?source=post_page-----35c990c133c5--------------------------------)
    [](/making-the-jump-from-data-analyst-to-data-scientist-in-2023-74e2cf7fc139?source=post_page-----35c990c133c5--------------------------------)
    [## 从数据分析师到数据科学家的跳跃（2023 年）
- en: The skills and resources you need to transition from a data analyst to data
    scientist position.
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你需要的技能和资源，以从数据分析师职位转变为数据科学家职位。
- en: towardsdatascience.com](/making-the-jump-from-data-analyst-to-data-scientist-in-2023-74e2cf7fc139?source=post_page-----35c990c133c5--------------------------------)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/making-the-jump-from-data-analyst-to-data-scientist-in-2023-74e2cf7fc139?source=post_page-----35c990c133c5--------------------------------)
- en: References
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1) OpenAI, [Introducing ChatGPT](https://openai.com/blog/chatgpt) (2022).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: (1) OpenAI, [介绍 ChatGPT](https://openai.com/blog/chatgpt) (2022)。
- en: (2) OpenAI, [GPT-4](https://openai.com/research/gpt-4) (2023).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: (2) OpenAI, [GPT-4](https://openai.com/research/gpt-4) (2023)。
- en: (3) A. Radford et al., [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
    (2019).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: (3) A. Radford 等, [语言模型是无监督的多任务学习者](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
    (2019)。
- en: (4) T. Brown et al., [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
    (2020).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: (4) T. Brown 等, [语言模型是少量样本学习者](https://arxiv.org/pdf/2005.14165.pdf) (2020)。
- en: (5) J. Alammar, [The Illustrated GPT-2 (Visualizing Transformer Language Models)](https://jalammar.github.io/illustrated-gpt2/)
    (2019).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: (5) J. Alammar, [插图版 GPT-2（可视化 Transformer 语言模型）](https://jalammar.github.io/illustrated-gpt2/)
    (2019)。
- en: (6) OpenAI, [GPT-4 Technical Report](https://cdn.openai.com/papers/gpt-4.pdf)
    (2023).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: (6) OpenAI, [GPT-4 技术报告](https://cdn.openai.com/papers/gpt-4.pdf) (2023)。
- en: (7) OpenAI, [Learning from human preferences](https://openai.com/research/learning-from-human-preferences)
    (2017).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: (7) OpenAI, [从人类偏好中学习](https://openai.com/research/learning-from-human-preferences)
    (2017)。
