- en: Hands-On Introduction to Delta Lake with (py)Spark
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实操介绍 Delta Lake 和 (py)Spark
- en: 原文：[https://towardsdatascience.com/hands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae?source=collection_archive---------0-----------------------#2023-02-16](https://towardsdatascience.com/hands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae?source=collection_archive---------0-----------------------#2023-02-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/hands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae?source=collection_archive---------0-----------------------#2023-02-16](https://towardsdatascience.com/hands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae?source=collection_archive---------0-----------------------#2023-02-16)
- en: Concepts, theory, and functionalities of this modern data storage framework
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现代数据存储框架的概念、理论和功能
- en: '[](https://joaopedro214.medium.com/?source=post_page-----b39460a4b1ae--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----b39460a4b1ae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b39460a4b1ae--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b39460a4b1ae--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----b39460a4b1ae--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://joaopedro214.medium.com/?source=post_page-----b39460a4b1ae--------------------------------)[![João
    Pedro](../Images/64a0e14527be213e5fde0a02439fbfa7.png)](https://joaopedro214.medium.com/?source=post_page-----b39460a4b1ae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b39460a4b1ae--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b39460a4b1ae--------------------------------)
    [João Pedro](https://joaopedro214.medium.com/?source=post_page-----b39460a4b1ae--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----b39460a4b1ae---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b39460a4b1ae--------------------------------)
    ·10 min read·Feb 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb39460a4b1ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----b39460a4b1ae---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fb111eee95c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=post_page-b111eee95c----b39460a4b1ae---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b39460a4b1ae--------------------------------)
    ·10 分钟阅读·2023年2月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb39460a4b1ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae&user=Jo%C3%A3o+Pedro&userId=b111eee95c&source=-----b39460a4b1ae---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb39460a4b1ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae&source=-----b39460a4b1ae---------------------bookmark_footer-----------)![](../Images/303f0065d94538660d3d2564a8209807.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb39460a4b1ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-introduction-to-delta-lake-with-py-spark-b39460a4b1ae&source=-----b39460a4b1ae---------------------bookmark_footer-----------)![](../Images/303f0065d94538660d3d2564a8209807.png)'
- en: Photo by [Nick Fewings](https://unsplash.com/@jannerboy62?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Nick Fewings](https://unsplash.com/@jannerboy62?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: I think it’s now perfectly clear to everybody the value data can have. To use
    a hyped example, models like ChatGPT could only be built on a huge mountain of
    data, produced and collected over years.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为现在大家对数据的价值已经非常清楚。以一个热门的例子来说，像 ChatGPT 这样的模型只能基于多年来产生和收集的大量数据构建。
- en: 'I would like to emphasize the word “can” because there is a phrase in the world
    of programming that still holds, and probably ever will: garbage in, garbage out.
    Data by itself has no value, it needs to be organized, standardized, and clean.
    Governance is needed. In this context, data management in an organization is a
    key point for the success of its projects involving data.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我想强调“可以”这个词，因为编程领域有一句话仍然适用，并且可能永远适用：垃圾进，垃圾出。数据本身没有价值，它需要组织、标准化和清理。治理是必要的。在这种情况下，组织中的数据管理是其涉及数据的项目成功的关键点。
- en: One of the main aspects of correct data management is the definition of a data
    architecture. Data architecture is the set of practices, technologies, and services
    that meet the data demand of a given organization, both technical (speed, volume,
    frequency, availability) and non-technical (business rules, compliance with data
    legislation) needs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的数据管理的一个主要方面是数据架构的定义。数据架构是满足特定组织数据需求的一套实践、技术和服务，包括技术需求（速度、容量、频率、可用性）和非技术需求（业务规则、数据立法遵从）。
- en: Nowadays, almost by default, organizations will have to deal with data in different
    formats (CSV, pdf, video, parquet, etc), hence the success of blob storage like
    amazon’s S3\. However, this type of approach can bring some problems due to the
    absence of management tools on raw files (especially in tabular data), such as
    schema enforcement, versioning, and data lineage.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，几乎默认情况下，组织必须处理不同格式的数据（CSV、pdf、视频、parquet 等），这就是像亚马逊的 S3 这样的 blob 存储取得成功的原因。然而，这种方法可能会带来一些问题，因为缺乏对原始文件（特别是表格数据）的管理工具，如模式强制、版本控制和数据血缘。
- en: With that in mind (and a bunch of other things), Delta Lake was developed, an
    open-source data storage framework that implements/materializes the Lakehouse
    architecture and the topic of today’s post.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点（以及其他一些因素），开发了 Delta Lake，一个开源数据存储框架，实施/体现了 Lakehouse 架构，并且是今天文章的主题。
- en: What is Delta Lake?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 Delta Lake？
- en: Before going into further details on Delta Lake, we need to remember the concept
    of Data Lake, so let’s travel through some history.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论 Delta Lake 之前，我们需要记住数据湖的概念，所以让我们回顾一些历史。
- en: The Data Lake architecture was proposed in a period of great growth in the data
    volume, especially in non-structured and semi-structured data, when traditional
    Data Warehouse systems start to become incapable of dealing with this demand.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖架构是在数据量大幅增长的时期提出的，特别是非结构化和半结构化数据，当传统的数据仓库系统开始无法处理这种需求时。
- en: The proposal is simple — “Trow everything you have here inside and worry later”.
    The main player in the context of the first data lakes was Hadoop, a distributed
    file system, with MapReduce, a processing paradigm built over the idea of minimal
    data movement and high parallelism. In theory, was just throwing everything inside
    Hadoop and later on writing jobs to process the data into the expected results,
    getting rid of complex data warehousing systems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 提案很简单——“把你拥有的一切都扔进来，稍后再担心”。在第一个数据湖的背景下，主要的参与者是 Hadoop，一个分布式文件系统，配合 MapReduce，这是一个建立在最小数据移动和高并行性的理念上的处理范式。理论上，只需将所有数据扔进
    Hadoop，然后编写作业处理数据以得到预期结果，从而摆脱复杂的数据仓库系统。
- en: Legend says, that this didn’t go well. The files were thrown with no quality
    worries, no versioning, and no management. The data became useless. The problem
    was so big that the terms “data swamp”, a joke on very messy data lakes, and “WORN
    paradigm”, Write Once Read Never, were created. In practice, the guarantees imposed
    by traditional Data Warehouse systems, especially RDBMS were still needed to assure
    data quality. (I was a child at the time, I read all this history recently from
    modern literature)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 传说中，这一过程并不顺利。文件被随意丢弃，没有质量担忧，没有版本控制，也没有管理。数据变得毫无用处。问题如此严重，以至于创造了“数据沼泽”这一术语，调侃非常混乱的数据湖，以及“WORN
    paradigm”（写一次读永不再读）。实际上，传统数据仓库系统，特别是关系数据库管理系统（RDBMS）所施加的保障仍然需要，以确保数据质量。（那时我还很小，我最近才从现代文献中了解到这一切历史）
- en: Time has passed and, based on the hits and misses of the past, new architectures
    were proposed. The Lakehouse architecture was one of them. In a nutshell, it tries
    to mix the advantages of both Data Lakes (flexibility) and Data Warehouses (guarantees).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 时间流逝，基于过去的成功与失败，提出了新的架构。其中之一就是 Lakehouse 架构。简而言之，它试图结合数据湖（灵活性）和数据仓库（保障）的优点。
- en: Delta Lake is nothing more than a practical implementation of a storage framework/solution
    with a Lakehouse vision.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Delta Lake 只是一个具有 Lakehouse 视角的存储框架/解决方案的实际实现。
- en: 'Let’s go to it:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧：
- en: A table in Delta Lake (aka Delta Table) is nothing more than a *parquet* file
    with a transaction log in JSON that stores all the change history on that file.
    In that way, even with data stored in files, it is possible to have total control
    over all that happened to it, including reading previous versions and reverting
    operations. Delta Lake also works with the concept of ACID transactions, that
    is, no partial writing caused by job failures or inconsistent readings. Delta
    Lake also refuses writes with wrongly formatted data (schema enforcement) and
    allows for schema evolution. Finally, it also provides the usual CRUD functionalities
    (insert, update, merge, and delete), usually not available in raw files.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Delta Lake（即 Delta 表）中的表实际上就是一个包含 JSON 事务日志的 *parquet* 文件，该日志记录了文件上的所有变更历史。通过这种方式，即使数据存储在文件中，也可以完全控制所有发生的事件，包括读取以前的版本和恢复操作。Delta
    Lake 还使用 ACID 事务的概念，即防止因作业失败或读取不一致导致的部分写入。Delta Lake 还会拒绝格式不正确的数据写入（模式强制）并允许模式演变。最后，它还提供了通常在原始文件中不可用的
    CRUD 功能（插入、更新、合并和删除）。
- en: This post will tackle these functionalities in a hands-on approach with pyspark
    in the following sections.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将以实际操作的方式使用 pyspark 讨论这些功能。
- en: '**The data**'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据**'
- en: The data used in this post is the list of traffic accidents that occurred on
    Brazillian highways, collected by the PRF (Polícia Rodoviária Federal, our highway
    police) and publicly available in the Brazillian Open Data Portal [[Link](https://www.gov.br/prf/pt-br/acesso-a-informacao/dados-abertos/dados-abertos-acidentes)][[License
    — CC BY-ND 3.0].](https://creativecommons.org/licenses/by-nd/3.0/deed.pt_BR)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用的数据是发生在巴西高速公路上的交通事故列表，由 PRF（巴西公路警察）收集，并在巴西开放数据门户网站上公开提供 [[Link](https://www.gov.br/prf/pt-br/acesso-a-informacao/dados-abertos/dados-abertos-acidentes)][[License
    — CC BY-ND 3.0].](https://creativecommons.org/licenses/by-nd/3.0/deed.pt_BR)
- en: 'The data covers the period from 2007 up to 2021 and contains various information
    about the accidents: place, highway, km, latitude and longitude, number of people
    involved, accident type, and so on.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据涵盖了 2007 年到 2021 年期间的各种事故信息：地点、高速公路、公里数、纬度和经度、涉及人员数量、事故类型等。
- en: The implementation
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现
- en: 0\. Setting Up the environment
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 0\. 设置环境
- en: 'As always, the project is developed using docker containers:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，该项目使用 docker 容器进行开发：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: All the code is available in this [GitHub repository](https://github.com/jaumpedro214/posts).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码均可在此 [GitHub 仓库](https://github.com/jaumpedro214/posts)中获取。
- en: 1\. Creating a Delta Table
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 创建 Delta 表
- en: The first thing to do is instantiate a Spark Session and configure it with the
    Delta-Lake dependencies.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 首先需要实例化一个 Spark 会话，并将其配置为使用 Delta-Lake 依赖项。
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Creating a Delta Table is very simple, it’s just like writing a new file in
    a specific format. The code below reads the CSV with the 2020’s accidents and
    writes the data as a delta table.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 Delta 表非常简单，就像以特定格式编写一个新文件一样。以下代码读取 2020 年的事故数据，并将数据写入 delta 表。
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/d72cfddfa1e866eeb230fbc31680a2a5.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d72cfddfa1e866eeb230fbc31680a2a5.png)'
- en: First 5 rows of 2020.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 2020 年前 5 行。
- en: Writing the delta table.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 编写 delta 表。
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: And that’s all.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了。
- en: As mentioned, a Delta-Lake table (in terms of files) is just the traditional
    *parquet* file with a transaction log in JSON that stores all the changes made.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Delta-Lake 表（就文件而言）仅仅是传统的 *parquet* 文件，附带一个记录所有变更的 JSON 事务日志。
- en: '![](../Images/3c877b178787f54d87ff170643be3325.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c877b178787f54d87ff170643be3325.png)'
- en: Delta Table with the JSON Transaction Log.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 带有 JSON 事务日志的 Delta 表。
- en: 2\. Read from a Delta Table
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 从 Delta 表中读取数据
- en: Again, there is nothing (yet) special about reading a Delta Table.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，读取 Delta 表并没有特别之处。
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/1681c30993e3e05d2b8ee361a767d1db.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1681c30993e3e05d2b8ee361a767d1db.png)'
- en: Let’s count the number of rows
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算行数
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 3\. Add new data to the Delta Table
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 向 Delta 表中添加新数据
- en: Delta Tables support the “append” write mode, so it’s possible to add new data
    to the already existing table. Let’s add the readings from 2019.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Delta 表支持“追加”写入模式，因此可以将新数据添加到已存在的表中。让我们添加 2019 年的数据。
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Appending to the Delta Table
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 向 Delta 表追加数据
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'It’s important to empathize: Delta Tables will perform schema enforcement,
    so it’s only possible to write data that have the same schema as the already existing
    table, otherwise, Spark will throw an error.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要强调：Delta表会执行模式强制，因此只能写入与已存在表具有相同模式的数据，否则，Spark会抛出错误。
- en: Let’s check the number of rows in the Delta Table
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查Delta表中的行数。
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 4\. View the history (logs) of the Delta Table
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 查看Delta表的历史记录（日志）
- en: The Log of the Delta Table is a record of all the operations that have been
    performed on the table. It contains a detailed description of each operation performed,
    including all the metadata about the operation.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Delta表的日志记录了所有对表执行的操作。它包含了对每个操作的详细描述，包括关于操作的所有元数据。
- en: To read the log, we need to use a special python object called `DeltaTable`
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要读取日志，我们需要使用一个名为`DeltaTable`的特殊Python对象。
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/be4e3d84b827c8be00d4a2507942ae17.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be4e3d84b827c8be00d4a2507942ae17.png)'
- en: The history object is a Spark Data Frame.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 历史对象是一个Spark数据框。
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](../Images/281f55740f79b0a5d92674832c0b3550.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/281f55740f79b0a5d92674832c0b3550.png)'
- en: 'As we can see, there are currently two table versions, one for each operation
    performed: the overwrite write when the table was created and the append write
    made previously.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，目前有两个表版本，每个操作都有一个版本：表创建时的覆盖写入和之前进行的追加写入。
- en: 5\. Read a specific version of the Delta Table
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 读取Delta表的特定版本
- en: If nothing is specified, Spark will read the latest version of the Delta Table.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有指定任何内容，Spark将读取Delta表的最新版本。
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'But it’s also possible to read from a specific version by just adding a single
    line of code:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 但也可以通过仅添加一行代码从特定版本中读取数据：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The counts dropped because we’re reading from version 0, before the 2019’s data
    was inserted.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 计数下降了，因为我们正在从版本0读取，在2019年的数据插入之前。
- en: 6\. Revert to a previous version
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 恢复到先前版本
- en: It’s possible to revert to a previous version of a table. This is very useful
    to quickly solve errors made by a pipeline. This operation is also performed via
    the DeltaTable object created earlier.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 可以恢复到表的先前版本。这对于快速解决管道中出现的错误非常有用。此操作也是通过之前创建的DeltaTable对象执行的。
- en: 'Let’s restore the table to version 0:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将表恢复到版本0：
- en: '[PRE15]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, the latest counts will be =63576 again, because we reverted to a version
    when the data from 2019’s have yet not been included.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，最新的计数将再次为=63576，因为我们恢复到了数据尚未包括2019年的版本。
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The **RESTORE** operation is also stored in the log. So, in practice, no information
    is lost:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**RESTORE**操作也记录在日志中。因此，实际上没有信息丢失：'
- en: '[PRE17]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](../Images/91cd2dbd7153e9e98eb26a74c366d2b9.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/91cd2dbd7153e9e98eb26a74c366d2b9.png)'
- en: Let’s restore back to version 1.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们恢复到版本1。
- en: '[PRE18]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 7\. Update
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 更新
- en: The update operation can also be done by the `DeltaTable` object, but we will
    perform it with the SQL syntax, just to try a new approach.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 更新操作也可以通过`DeltaTable`对象完成，但我们将使用SQL语法来尝试一种新方法。
- en: 'First, let’s write the data from 2016 to the delta table. This data contains
    the “data_inversa” (date) column wrongly formatted: dd/MM/yy instead of yyyy-MM-dd'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将2016年的数据写入增量表。这些数据中的“data_inversa”（日期）列格式错误：dd/MM/yy而不是yyyy-MM-dd。
- en: '[PRE19]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](../Images/01ea716ec1c9fa6aef3faddbfe900d64.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01ea716ec1c9fa6aef3faddbfe900d64.png)'
- en: 'Let’s save the data:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们保存数据：
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: But, because our data_inversa field is of type string, no errors occur. Now,
    we have bad data inserted on our table that we need to fix. Of course, we could
    just REVERT this last operation and insert the data again correctly, but let’s
    use the UPDATE operation instead.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 但由于我们的data_inversa字段是字符串类型，因此不会发生错误。现在，我们的表中插入了错误的数据，需要进行修复。当然，我们可以只需恢复这次操作，并再次正确插入数据，但让我们改用UPDATE操作。
- en: The SQL code below fixes the data formatting just for the year = 2016.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下SQL代码仅修复年份=2016的数据格式。
- en: '[PRE21]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And the number of rows with wrongly formatted data is 0:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 错误格式化数据的行数为0：
- en: '[PRE22]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 8\. Merge
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 合并
- en: The last operation that’ll be covered is the MERGE (a.k.a UPSERT) operation.
    It’s a mix of INSERT and UPDATE,
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后将介绍的操作是MERGE（也称为UPSERT）操作。它是INSERT和UPDATE的混合。
- en: It will try to insert new rows to a target table considering some columns as
    keys. If the row to be inserted already exists in the target table (i.e. the row
    keys are already present in the target table), it will just update the row (with
    some logic specified), other else, it will insert the new row.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 它会尝试将新行插入目标表格，将某些列视为关键列。如果要插入的行已经存在于目标表中（即行键已经在目标表中存在），它将仅更新该行（按照指定的一些逻辑），否则，它将插入新行。
- en: 'In a nutshell: if exists, then update, if not, then insert.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说：如果存在，则更新；如果不存在，则插入。
- en: '![](../Images/653b122d4d312b4a778daf114b76f102.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/653b122d4d312b4a778daf114b76f102.png)'
- en: Merge example. Image by Author.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 合并示例。图片由作者提供。
- en: To demonstrate this method let’s insert some data from 2018 with the number
    of *people* = 0 (*pessoas —* number of people involved in the accident) for all
    rows, simulating a partial report with incomplete data.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这种方法，让我们插入一些2018年的数据，所有行的*人* = 0（*pessoas —* 参与事故的人数），模拟一个包含不完整数据的部分报告。
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: If we now want to update the table with the complete data from 2018, we must
    assure that the already inserted rows have just the *people* column updated and
    all the new rows are inserted.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在想用2018年的完整数据更新表格，我们必须确保已经插入的行仅更新*人*列，并插入所有新的行。
- en: 'This can be performed with the following MERGE operation, which considers the
    accident’s id and date as keys:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过以下MERGE操作来完成，该操作将事故的id和日期视为关键：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Conclusion
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Defining a data architecture is extremely important to all organizations that
    aim at creating data-driven products, like BI reports and Machine Learning applications.
    A data architecture defines the tools, technologies, and practices that will ensure
    that the technical and non-technical data needs of an organization are met.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 定义数据架构对所有旨在创建数据驱动产品的组织（如BI报告和机器学习应用）至关重要。数据架构定义了将确保组织的技术和非技术数据需求得到满足的工具、技术和实践。
- en: In private companies, it can help to speed up the development of such products,
    improve their quality and efficiency, and give commercial advantages that turn
    into profit. In public organizations, the benefits of a data architecture turn
    into better public policies, a better understanding of the current situation in
    a specific area like transport, safety, budget, and improvement in transparency
    and management.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在私营公司中，这可以帮助加快此类产品的开发，提升其质量和效率，并带来转化为利润的商业优势。在公共组织中，数据架构的好处转化为更好的公共政策，更好地了解特定领域的现状，如交通、安全、预算，以及提高透明度和管理水平。
- en: Many architectures have been proposed in the last decades, each one with its
    own benefits in each context. The Lakehouse paradigm tries to mix together the
    benefits of Data Lakes and Data Warehouses. The Delta Lake is a framework for
    storage based on the Lakehouse paradigm. In a nutshell, it brings many of the
    guarantees usually only available in classical RDBMS (ACID transactions, logs,
    revert operations, CRUD operations) on top of file-based storage (based on *parquet*).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年中，提出了许多架构，每种架构在不同背景下都有其自身的优势。Lakehouse范式试图将数据湖和数据仓库的优势结合起来。Delta Lake是基于Lakehouse范式的存储框架。简而言之，它将通常仅在经典RDBMS中可用的许多保证（ACID事务、日志、撤销操作、CRUD操作）带到基于*parquet*的文件存储之上。
- en: In this post, we explored a few of these functionalities using data from traffic
    accidents on Brazilian highways. I hope I helped you somehow, I am not an expert
    in any of the subjects discussed, and I strongly recommend further reading (see
    some references below) and discussion.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们使用巴西高速公路交通事故的数据探索了这些功能中的一些。我希望我能有所帮助，我对讨论的任何主题都不是专家，我强烈建议进一步阅读（见下方一些参考文献）和讨论。
- en: Thank you for reading! ;)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您的阅读！;)
- en: References
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*All the code is available in* [*this GitHub repository*](https://github.com/jaumpedro214/posts)*.*'
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*所有代码都可以在* [*这个 GitHub 仓库*](https://github.com/jaumpedro214/posts)*找到。*'
- en: '[1] Chambers, B., & Zaharia, M. (2018). *Spark: The definitive guide: Big data
    processing made simple*. “ O’Reilly Media, Inc.”'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Chambers, B., & Zaharia, M. (2018). *Spark: The definitive guide: Big data
    processing made simple*. “O’Reilly Media, Inc.”'
- en: '[2] Databricks. (2020, March 26). *Tech Talk | Diving into Delta Lake Part
    1: Unpacking the Transaction Log* [[Video](https://www.youtube.com/watch?v=F91G4RoA8is)].
    YouTube.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Databricks. (2020年3月26日). *Tech Talk | Diving into Delta Lake Part 1: Unpacking
    the Transaction Log* [[视频](https://www.youtube.com/watch?v=F91G4RoA8is)]. YouTube.'
- en: '[2] *How to Rollback a Delta Lake Table to a Previous Version with Restore*.
    (2022, October 3). Delta Lake. [Link](https://delta.io/blog/2022-10-03-rollback-delta-lake-restore/)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] *如何使用恢复功能将Delta Lake表回滚到先前版本*。 (2022年10月3日)。Delta Lake。 [链接](https://delta.io/blog/2022-10-03-rollback-delta-lake-restore/)'
- en: '[3] *Delta Lake Official Page*. (n.d.). Delta Lake. [https://delta.io/](https://delta.io/)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] *Delta Lake 官方页面*。 (无日期)。Delta Lake。 [https://delta.io/](https://delta.io/)'
- en: '[4] Databricks. (2020a, March 12). *Simplify and Scale Data Engineering Pipelines
    with Delta Lake* [[Video](https://www.youtube.com/watch?v=qtCxNSmTejk)]. YouTube.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Databricks. (2020年3月12日). *简化和扩展使用Delta Lake的数据工程管道* [[视频](https://www.youtube.com/watch?v=qtCxNSmTejk)]。YouTube。'
- en: '[5] Databricks. (2020c, September 15). *Making Apache SparkTM Better with Delta
    Lake* [[Video](https://www.youtube.com/watch?v=LJtShrQqYZY)]. YouTube.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] Databricks. (2020年9月15日). *利用Delta Lake改进Apache SparkTM* [[视频](https://www.youtube.com/watch?v=LJtShrQqYZY)]。YouTube。'
- en: '[6] Reis, J., & Housley, M. (2022c). *Fundamentals of Data Engineering: Plan
    and Build Robust Data Systems* (1st ed.). O’Reilly Media.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] Reis, J., & Housley, M. (2022年). *数据工程基础：规划和构建稳健的数据系统* (第1版)。O’Reilly Media。'
