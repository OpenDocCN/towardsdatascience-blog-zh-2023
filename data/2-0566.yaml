- en: Convolution Explained — Introduction to Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积解释——卷积神经网络简介
- en: 原文：[https://towardsdatascience.com/convolution-explained-introduction-to-convolutional-neural-networks-5babc47fbcaa](https://towardsdatascience.com/convolution-explained-introduction-to-convolutional-neural-networks-5babc47fbcaa)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/convolution-explained-introduction-to-convolutional-neural-networks-5babc47fbcaa](https://towardsdatascience.com/convolution-explained-introduction-to-convolutional-neural-networks-5babc47fbcaa)
- en: The fundamental building block of CNNs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNNs的基本构建块
- en: '[](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)[![Egor
    Howell](../Images/1f796e828f1625440467d01dcc3e40cd.png)](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5babc47fbcaa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5babc47fbcaa--------------------------------)
    [Egor Howell](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)[![Egor
    Howell](../Images/1f796e828f1625440467d01dcc3e40cd.png)](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5babc47fbcaa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5babc47fbcaa--------------------------------)
    [Egor Howell](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5babc47fbcaa--------------------------------)
    ·8 min read·Dec 27, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5babc47fbcaa--------------------------------)
    ·8分钟阅读·2023年12月27日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/725d855cae28fe1f795da02e71253227.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/725d855cae28fe1f795da02e71253227.png)'
- en: ”[https://www.flaticon.com/free-icons/neural-network](https://www.flaticon.com/free-icons/neural-network)"
    title=”neural network icons.” Neural network icons created by Freepik — Flaticon.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ”[https://www.flaticon.com/free-icons/neural-network](https://www.flaticon.com/free-icons/neural-network)"
    标题为“神经网络图标。” 神经网络图标由Freepik创建 — Flaticon。
- en: 'My recent articles have been a series on neural networks where we go from the
    simple [***perceptron***](https://medium.com/gitconnected/intro-perceptron-architecture-neural-networks-101-2a487062810c)
    to complicated architectures and how to deal with [***common problems in deep
    learning***](https://medium.com/towards-data-science/vanishing-exploding-gradient-problem-neural-networks-101-c8f48ec6a80b).
    If you are interested, feel free to check the series here:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近的文章系列是关于神经网络的，我们从简单的 [***感知器***](https://medium.com/gitconnected/intro-perceptron-architecture-neural-networks-101-2a487062810c)
    讲到复杂的架构以及如何处理 [***深度学习中的常见问题***](https://medium.com/towards-data-science/vanishing-exploding-gradient-problem-neural-networks-101-c8f48ec6a80b)。如果你感兴趣，可以在这里查看系列文章：
- en: '![Egor Howell](../Images/e969a9f3c3357e1c80dcd0092d9a1288.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![Egor Howell](../Images/e969a9f3c3357e1c80dcd0092d9a1288.png)'
- en: '[Egor Howell](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[Egor Howell](https://medium.com/@egorhowell?source=post_page-----5babc47fbcaa--------------------------------)'
- en: Neural Networks
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络
- en: '[View list](https://medium.com/@egorhowell/list/neural-networks-616db722dbbb?source=post_page-----5babc47fbcaa--------------------------------)9
    stories![](../Images/66f86f14ddf20d9da9cac53dee54bae3.png)![](../Images/d968b0bd4358bb0d60bd296aef08a720.png)![](../Images/30f3f4354836e6d3d56175fe20cf6b7c.png)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看列表](https://medium.com/@egorhowell/list/neural-networks-616db722dbbb?source=post_page-----5babc47fbcaa--------------------------------)9个故事![](../Images/66f86f14ddf20d9da9cac53dee54bae3.png)![](../Images/d968b0bd4358bb0d60bd296aef08a720.png)![](../Images/30f3f4354836e6d3d56175fe20cf6b7c.png)'
- en: One exciting area neural networks have made significant strides in is [***computer
    vision***](https://en.wikipedia.org/wiki/Computer_vision). Think AI for self-driving
    cars and face recognition!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络在 [***计算机视觉***](https://en.wikipedia.org/wiki/Computer_vision) 领域取得了显著进展。这是自驾车和面部识别的AI！
- en: However, the regular fully connected neural network that most people know about
    is not suitable for many real-life image recognition tasks. It works on the famous
    [***MNIST***](https://en.wikipedia.org/wiki/MNIST_database#:~:text=Article%20Talk,the%20field%20of%20machine%20learning.)
    dataset, but it has small images of ***28×28*** pixels.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数人所了解的常规全连接神经网络并不适合许多现实中的图像识别任务。它在著名的 [***MNIST***](https://en.wikipedia.org/wiki/MNIST_database#:~:text=Article%20Talk,the%20field%20of%20machine%20learning.)
    数据集上有效，但其图像尺寸为 ***28×28*** 像素。
- en: High-definition (HD) images have ***1280×720*** pixels. That’s approximately
    ***1,000,000*** pixels, which would mean ***1,000,000 neurons*** in the input
    layer. Not to mention the millions of weights required for the hidden layers,
    rendering regular neural networks unsuitable due to the dimensional complexity.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 高清 (HD) 图像有 ***1280×720*** 像素。这大约是 ***1,000,000*** 像素，这意味着输入层需要 ***1,000,000
    个神经元***。更不用说隐藏层所需的数百万个权重，这使得常规神经网络因维度复杂性而不适用。
- en: So, what do we do?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们该怎么做？
- en: Convolutional Neural Networks!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络！
- en: '[***Convolutional neural networks (CNN)***](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    are the gold standard for the majority of computer vision tasks today. Instead
    of fully connected layers, they have *partially* connected layers and share their
    weights, reducing the complexity of the model.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[***卷积神经网络 (CNN)***](https://en.wikipedia.org/wiki/Convolutional_neural_network)
    现在是大多数计算机视觉任务的金标准。它们不像全连接层那样，而是具有 *部分* 连接的层，并且共享其权重，从而减少模型的复杂性。'
- en: For instance, for each neuron in a fully connected neural network layer, we
    would require ***10,000*** weight of an image of ***100×100*** pixels. However,
    a CNN can have only ***25*** neurons to process the same image.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于全连接神经网络层中的每个神经元，我们需要处理一张 ***100×100*** 像素的图像的 ***10,000*** 个权重。然而，CNN 只需
    ***25*** 个神经元即可处理相同的图像。
- en: In this article, we are going to dive into the fundamental building block behind
    CNNs, [***convolution***](https://en.wikipedia.org/wiki/Convolution).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将深入探讨 CNN 的基本构建块，[***卷积***](https://en.wikipedia.org/wiki/Convolution)。
- en: Intuition
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 直觉
- en: Like many things in machine learning, CNNs are inspired by nature. Computer
    scientists looked at how the [***visual cortex***](https://en.wikipedia.org/wiki/Visual_cortex)inthe
    brain works and applied a similar concept to neural networks.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 就像机器学习中的许多事物一样，CNN 也受到自然的启发。计算机科学家观察了大脑中的 [***视觉皮层***](https://en.wikipedia.org/wiki/Visual_cortex)
    的工作方式，并将类似的概念应用于神经网络。
- en: The visual cortex doesn’t process all the pixels in an image at the same time.
    The biological neurons only respond to a small region in the [***receptive field***](https://en.wikipedia.org/wiki/Receptive_field).
    However, these small regions overlap leading the animal to understand the whole
    image.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉皮层不会同时处理图像中的所有像素。生物神经元只对 [***感受野***](https://en.wikipedia.org/wiki/Receptive_field)
    中的小区域做出反应。然而，这些小区域会重叠，使动物能够理解整个图像。
- en: Furthermore, some biological neurons with the same receptive field can only
    detect lines of different orientations, an example of [***filtering***](https://medium.com/@sumit-kr-sharma/image-filtering-in-computer-vision-ec60ec8a3e1).
    Some neurons also have larger receptive fields, meaning that higher-level neurons
    are a combination of lower-level neurons.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些具有相同感受野的生物神经元只能检测不同方向的线条，这是 [***滤波***](https://medium.com/@sumit-kr-sharma/image-filtering-in-computer-vision-ec60ec8a3e1)
    的一个例子。一些神经元还具有更大的感受野，这意味着高层神经元是低层神经元的组合。
- en: These biological discoveries inspired the [***neocognitron***](https://en.wikipedia.org/wiki/Neocognitron)
    in 1979\. Over time, the neocognitron became the convolutional neural network,
    which is where we are today!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些生物学发现启发了 1979 年的 [***新认知机***](https://en.wikipedia.org/wiki/Neocognitron)。随着时间的推移，新认知机演变成了卷积神经网络，这就是我们今天所拥有的！
- en: What is Convolution?
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是卷积？
- en: 'The naming behind the CNN is from the [***convolution***](https://en.wikipedia.org/wiki/Convolution#:~:text=In%20mathematics%20(in%20particular%2C%20functional,is%20modified%20by%20the%20other.)
    mathematical operation, which is defined as:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 的命名来源于 [***卷积***](https://en.wikipedia.org/wiki/Convolution#:~:text=In%20mathematics%20(in%20particular%2C%20functional,is%20modified%20by%20the%20other.)
    这个数学操作，其定义如下：
- en: '![](../Images/e9e408c33cfac8e5cf1d05eaeae61c99.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9e408c33cfac8e5cf1d05eaeae61c99.png)'
- en: Continuous convolution theorem. Equation by author in LaTeX.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 连续卷积定理。作者用 LaTeX 表示的方程式。
- en: '![](../Images/e0b04fd904fe239a320a742507aadd1a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0b04fd904fe239a320a742507aadd1a.png)'
- en: Discrete convolution theorem. Equation by author in LaTeX.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 离散卷积定理。作者用 LaTeX 表示的方程式。
- en: '***f*∗*g:*** Convolution between functions, ***f*** and ***g***.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***f*∗*g:*** 函数 ***f*** 和 ***g*** 之间的卷积。'
- en: '***t:*** The point where the convolution is being evaluated.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***t:*** 卷积被评估的点。'
- en: '***f(τ):*** The value of function ***f*** at point ***τ***.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***f(τ):*** 在点 ***τ*** 处的函数 ***f*** 值。'
- en: '***g(t−τ):*** The value of ***g*** shifted by ***τ*** and evaluated at ***t***.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***g(t−τ):*** 被 ***τ*** 移动并在 ***t*** 处评估的 ***g*** 值。'
- en: This expression doesn’t intuitively tell us what a convolution is. Let’s break
    it down in more layman’s terms.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表达式并没有直观地告诉我们卷积是什么。让我们用更通俗的术语来解释一下。
- en: What a convolution does is mix two functions. In the above case, we have the
    input, ***f***, and we are sliding over some function ***g*** (known as a kernel)
    over ***f.***
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积的作用是混合两个函数。在上述情况下，我们有输入的 ***f***，并且我们在 ***f*** 上滑动某个函数 ***g***（称为内核）。
- en: '**Input**: This is a function, in our case an image, to analyze or manipulate.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**输入**：这是一个函数，在我们的情况下是图像，用于分析或操作。'
- en: '**Kernel**: A small matrix to apply visual effects such as blurring, sharpening,
    edge detection, etc. to the image.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**内核**：一个小矩阵，用于对图像应用视觉效果，例如模糊、锐化、边缘检测等。'
- en: '**Sliding Kernel**: The kernel is slid over the input image one pixel at a
    time computing a new pixel value.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**滑动内核**：内核一次滑过输入图像一个像素，计算新的像素值。'
- en: '**Computing Outpu**t: The output at each pixel is calculated by multiplying
    the overlapping values of the input and kernel together and summing these products.
    Then, it’s normalized by dividing it by the number of elements in the kernel.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算输出**：每个像素的输出是通过将输入和内核的重叠值相乘并求和这些乘积来计算的。然后，通过除以内核中的元素数量进行归一化。'
- en: '**Result**: The output is a new image, which has been transformed by the kernel.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**结果**：输出是一个新图像，这个图像已经被内核转换过。'
- en: Example Convolution
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例卷积
- en: Let’s go through a simple convolution example for image processing using some
    visuals.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一些视觉示例来了解图像处理的简单卷积示例。
- en: In the diagram below, we have an input grayscale image, which is ***5x5*** pixels,
    and a ***3x3*** kernel with all ***1s*** that will cause a blurring effect (specially
    a [***box blur***](https://en.wikipedia.org/wiki/Box_blur)).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图示中，我们有一个输入的灰度图像，其尺寸为 ***5x5*** 像素，以及一个 ***3x3*** 的内核，其中全是 ***1s***，这将产生模糊效果（特别是一个
    [***箱型模糊***](https://en.wikipedia.org/wiki/Box_blur)）。
- en: '![](../Images/ab2eb9f458f2ed5e17b27b1411c48567.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab2eb9f458f2ed5e17b27b1411c48567.png)'
- en: Example convolution for applying a blurring effect on a grayscale image. Diagram
    created by author.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 示例卷积用于在灰度图像上应用模糊效果。图示由作者创建。
- en: The smaller the pixel value, the darker it is. A value of 0 is black and 255
    is white, with values in-between being somewhere on the grayscale.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 像素值越小，图像越暗。值为0表示黑色，255表示白色，中间的值则是灰度值。
- en: If we take the middle pixel (highlighted in red), its convolution output is
    computed by multiplying each pixel value with the corresponding element in the
    kernel and summing these products. It’s then normalised by the number of elements
    in the kernel to ensure the image doesn’t get brighter or darker.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们取中间的像素（用红色高亮显示），其卷积输出是通过将每个像素值与内核中对应的元素相乘并求和这些乘积来计算的。然后，通过内核中的元素数量进行归一化，以确保图像不会变亮或变暗。
- en: Below is the step-by-step walkthrough of this process.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是此过程的逐步讲解。
- en: '[PRE0]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is then repeated for all the other pixels in the input image (only where
    the kernel fits) to produce the shown output.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然后对输入图像中的所有其他像素（仅在内核适合的地方）重复此操作，以生成所示输出。
- en: Notice how the resultant output image pixels are now a lot closer in values
    than the original image. This is because our kernel has averaged the pixel values
    in the neighborhood, creating a blur effect.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，结果图像的像素值现在比原始图像的像素值更接近。这是因为我们的内核对邻域中的像素值进行了平均，产生了模糊效果。
- en: 'This convolutional can easily be implemented in Python and show the resulting
    output image:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这种卷积可以很容易地在 Python 中实现，并显示结果图像：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/0608af17b582be4c58fc0df0fed9a0e3.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0608af17b582be4c58fc0df0fed9a0e3.png)'
- en: Example of blurring an image. Plot created by author in Python.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊图像的示例。图表由作者在 Python 中创建。
- en: 'The code used to produce this image can be found on my GitHub here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 用于生成此图像的代码可以在我的 GitHub 上找到：
- en: '[](https://github.com/egorhowell/Medium-Articles/blob/main/Neural%20Networks/convolution_image.py?source=post_page-----5babc47fbcaa--------------------------------)
    [## Medium-Articles/Neural Networks/convolution_image.py at main · egorhowell/Medium-Articles'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/egorhowell/Medium-Articles/blob/main/Neural%20Networks/convolution_image.py?source=post_page-----5babc47fbcaa--------------------------------)
    [## Medium-Articles/Neural Networks/convolution_image.py at main · egorhowell/Medium-Articles'
- en: Code I use in my medium blog/articles. Contribute to egorhowell/Medium-Articles
    development by creating an account on…
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我在我的中等博客/文章中使用的代码。通过创建帐户来为 egorhowell/Medium-Articles 的开发做出贡献...
- en: github.com](https://github.com/egorhowell/Medium-Articles/blob/main/Neural%20Networks/convolution_image.py?source=post_page-----5babc47fbcaa--------------------------------)
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/egorhowell/Medium-Articles/blob/main/Neural%20Networks/convolution_image.py?source=post_page-----5babc47fbcaa--------------------------------)'
- en: 'Certain kernel structures lead to different effects on the image. Below are
    some commonly used kernels along with their effect:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 某些卷积核结构对图像有不同的效果。下面是一些常用卷积核及其效果：
- en: '![](../Images/1fce459dc8be4ee5e91e85c3e6a787cc.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1fce459dc8be4ee5e91e85c3e6a787cc.png)'
- en: Kernel’s and their effects. Diagram by author.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积核及其效果。作者的图示。
- en: A full list of kernels and their operations can be found [here](https://en.wikipedia.org/wiki/Kernel_(image_processing)).
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一份完整的卷积核及其操作列表可以在[这里](https://en.wikipedia.org/wiki/Kernel_(image_processing))找到。
- en: Dimensionality, Stride & Padding
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维度、步幅与填充
- en: Output Dimensions
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出维度
- en: 'You may have noticed that applying our kernel led to a reduction in the dimensions
    of the image compared to its original. The formula to deduce what the output dimensions
    are is:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，与原始图像相比，应用卷积核会导致图像尺寸减小。推导输出尺寸的公式是：
- en: '![](../Images/49542c2ac79fe5b6c3b51ab0b4aff936.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/49542c2ac79fe5b6c3b51ab0b4aff936.png)'
- en: Output dimension. Equation by author in LaTeX.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 输出维度。作者的 LaTeX 公式。
- en: '***H_in***​ and ***W_in***​ are the height and width of the input image.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***H_in*** 和 ***W_in*** 是输入图像的高度和宽度。'
- en: '***H_filter***​ and ***W_filter***​ are the height and width of the kernel.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***H_filter*** 和 ***W_filter*** 是卷积核的高度和宽度。'
- en: '***Padding_height***​ and ***Padding_width***​ are the amount of padding applied
    to the height and width of the input image.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Padding_height*** 和 ***Padding_width*** 是应用于输入图像高度和宽度的填充量。'
- en: '***Stride_height*** ​and ***Stride_width***​ are the step sizes of the kernel
    along the height and width of the input image.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***Stride_height*** 和 ***Stride_width*** 是卷积核在输入图像高度和宽度上的步长。'
- en: There are two concepts we haven’t discussed yet that are present in the above
    equations, [***stride***](https://deepai.org/machine-learning-glossary-and-terms/stride)
    and [***padding***](https://www.geeksforgeeks.org/cnn-introduction-to-padding/).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未讨论的两个概念出现在上述方程中，[***步幅***](https://deepai.org/machine-learning-glossary-and-terms/stride)和[***填充***](https://www.geeksforgeeks.org/cnn-introduction-to-padding/)。
- en: Stride
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步幅
- en: Stride is how many pixels we slide the kernel over the input image. A stride
    of 1 moves the kernel one pixel and a stride of 2 moves the kernel two pixels
    at a time. The sliding can be done vertically, horizontally, or even both depending
    on what we set it.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅是我们在输入图像上滑动卷积核的像素数。步幅为1表示卷积核移动一个像素，步幅为2表示卷积核每次移动两个像素。滑动可以是垂直、水平，或根据设置同时进行。
- en: 'Increasing the stride leads to:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 增加步幅会导致：
- en: '*Reducing the output image’s dimension size.*'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*减少输出图像的尺寸大小。*'
- en: '*Lower compute cost due to fewer operations.*'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*由于操作较少，计算成本更低。*'
- en: '*Bigger view field of view of the input image.*'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输入图像的视野范围更大。*'
- en: '*Skipping pixels leads to loss of information.*'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*跳过像素会导致信息丢失。*'
- en: '![](../Images/e8c11ade7b1193a03d5be9b18838096e.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8c11ade7b1193a03d5be9b18838096e.png)'
- en: Stride of 1 example. Diagram by author.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅为1的示例。作者的图示。
- en: Padding
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 填充
- en: One problem with convolutions is that we tend to *lose pixels* and information
    on the perimeter of the image. This is down to how many times they are utilised
    by the kernel. The corner pixels will only ever get used once, whilst the middle
    pixels get used a lot more.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积的一个问题是我们往往会*丢失像素*和图像边缘的信息。这取决于卷积核的使用次数。角落像素只会被使用一次，而中间像素则会使用得更多。
- en: If we keep applying our kernel multiple times, which is what happens in a CNN,
    the output images will become a lot smaller than the original input image. This
    is not good as we will lose quite a bit of information, particularly about the
    boundaries of the image.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们多次应用卷积核，这在CNN中会发生，输出图像会比原始输入图像小很多。这不好，因为我们会丢失大量信息，特别是关于图像边界的信息。
- en: 'A way around this problem is to “pad” the input image with ***zeros*** around
    the edges. Below is an example using our previous image from the above section:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一种方法是对输入图像的边缘进行***零填充***。下面是使用前面部分图像的示例：
- en: '![](../Images/b244fc04933d33006aaa84a4c73d642b.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b244fc04933d33006aaa84a4c73d642b.png)'
- en: Zero padding. Diagram by author.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 零填充。作者的图示。
- en: The input image is now ***7x7*** pixels. Using the above formula, we can verify
    that applying a ***3x3*** kernel to this padded image will give us an output with
    dimensions ***5x5***.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像现在是***7x7***像素。使用上述公式，我们可以验证，应用一个***3x3***的核到这个填充图像上将得到一个***5x5***尺寸的输出。
- en: '![](../Images/a216e333bd85f1c7de7128f1dfb824ea.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a216e333bd85f1c7de7128f1dfb824ea.png)'
- en: Example calculation of output dimension when padding is applied. Equation by
    author in LaTeX.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 应用填充时输出维度的示例计算。方程由作者用LaTeX表示。
- en: This would increase the utilization of the pixels on the perimeter and render
    the output image having the same dimensions as the original input image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这将增加周边像素的利用率，并使输出图像具有与原始输入图像相同的尺寸。
- en: Zero padding is an example of **same padding.** Having no padding at all is
    known **as valid padding.** There is also another type called **casual padding**,
    which is asymmetric and typically applied to time series and natural language
    processing.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 零填充是**相同填充**的一种示例。完全不填充称为**有效填充**。还有另一种类型叫做**因果填充**，它是不对称的，通常应用于时间序列和自然语言处理。
- en: 'We don’t necessarily always have to pad with zeros, although that is the most
    common technique. Below is a list of some other padding strategies:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不一定总是要使用零填充，尽管这是一种最常见的技术。以下是一些其他填充策略的列表：
- en: '[**Reflect/Mirror Padding**](https://dev.to/sally20921/padding-in-neural-network-o8m):
    We pad by reflecting the image around a boundary.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**反射/镜像填充**](https://dev.to/sally20921/padding-in-neural-network-o8m)：我们通过在边界周围反射图像来进行填充。'
- en: '[**Replicate Padding**](https://www.educative.io/answers/types-of-padding-in-images):
    The padding values are values of the pixels closest to the boundary.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**复制填充**](https://www.educative.io/answers/types-of-padding-in-images)：填充值是最接近边界的像素值。'
- en: Summary & Further Thoughts
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要与进一步思考
- en: Convolutional neural networks are the gold standard for computer vision tasks
    today. Their main feature is utilizing the convolution mathematical operation
    that allows us to “blend” two functions together. This is used in image processing
    by applying a kernel, which is a matrix, over our image, a matrix of pixels, to
    carry out effects such as blurring and sharpening. This allows us to manipulate
    and analyze images, which is the building blocks of CNNs and how they “see” images.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）是目前计算机视觉任务的金标准。它们的主要特点是利用卷积数学运算，这使我们能够将两个函数“融合”在一起。这种方法在图像处理中通过在我们的图像上应用一个矩阵（即核），来实现模糊和锐化等效果。这样我们就能操控和分析图像，这是CNN的基础，也是它们如何“看”图像的方式。
- en: Another Thing!
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另一个话题！
- en: I have a free newsletter, [**Dishing the Data**](https://dishingthedata.substack.com/),
    where I share weekly tips for becoming a better Data Scientist. There is no “fluff”
    or “clickbait,” just pure actionable insights from a practicing Data Scientist.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一个免费的新闻通讯，[**数据分享**](https://dishingthedata.substack.com/)，在其中我每周分享成为更好的数据科学家的小贴士。没有“虚头八脑”的内容或“点击诱饵”，只有来自一名实践数据科学家的纯粹可操作的见解。
- en: '[](https://newsletter.egorhowell.com/?source=post_page-----5babc47fbcaa--------------------------------)
    [## Dishing The Data | Egor Howell | Substack'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://newsletter.egorhowell.com/?source=post_page-----5babc47fbcaa--------------------------------)
    [## 数据分享 | Egor Howell | Substack'
- en: How To Become A Better Data Scientist. Click to read Dishing The Data, by Egor
    Howell, a Substack publication with…
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何成为更好的数据科学家。点击阅读《数据分享》，作者Egor Howell，Substack出版的……
- en: newsletter.egorhowell.com](https://newsletter.egorhowell.com/?source=post_page-----5babc47fbcaa--------------------------------)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[newsletter.egorhowell.com](https://newsletter.egorhowell.com/?source=post_page-----5babc47fbcaa--------------------------------)'
- en: Connect With Me!
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与我联系！
- en: '[**YouTube**](https://www.youtube.com/@egorhowell?sub_confirmation=1)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**YouTube**](https://www.youtube.com/@egorhowell?sub_confirmation=1)'
- en: '[**LinkedIn**](https://www.linkedin.com/in/egor-howell-092a721b3/)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**LinkedIn**](https://www.linkedin.com/in/egor-howell-092a721b3/)'
- en: '[**Twitter**](https://twitter.com/EgorHowell)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Twitter**](https://twitter.com/EgorHowell)'
- en: '[**GitHub**](https://github.com/egorhowell)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**GitHub**](https://github.com/egorhowell)'
- en: References and Further Reading
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献和进一步阅读
- en: '[*Great computerphile video on kernels*](https://www.youtube.com/watch?v=C_zFhWdM4ic)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*关于核的精彩计算机视频*](https://www.youtube.com/watch?v=C_zFhWdM4ic)'
- en: '[*Good article on CNNs*](/convolutional-neural-networks-explained-9cc5188c4939)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*关于CNN的好文章*](/convolutional-neural-networks-explained-9cc5188c4939)'
- en: '[*Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition.
    Aurélien Géron. September 2019\. Publisher(s): O’Reilly Media, Inc. ISBN: 9781492032649*](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*.*'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*动手学习 Scikit-Learn、Keras 和 TensorFlow，第2版。奥雷利安·热龙。2019年9月。出版社：O’Reilly Media,
    Inc. ISBN: 9781492032649*](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*.*'
- en: '[*More info on padding*](https://www.knowledgehut.com/blog/data-science/padding-in-cnn)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*有关填充的更多信息*](https://www.knowledgehut.com/blog/data-science/padding-in-cnn)'
