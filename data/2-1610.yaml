- en: Organizational Processes for Machine Learning Risk Management
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习风险管理中的组织过程
- en: 原文：[https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f](https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f](https://towardsdatascience.com/organizational-processes-for-machine-learning-risk-management-14f4444dd07f)
- en: Responsible AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负责任的人工智能
- en: '*Organizational processes are a key nontechnical determinant of reliability
    in ML systems.*'
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*组织过程是机器学习系统可靠性的一个关键非技术性决定因素。*'
- en: '[](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[![Parul
    Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)
    [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[![Parul
    Pandey](../Images/760b72a4feacfad6fc4224835c2e1f19.png)](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)
    [Parul Pandey](https://pandeyparul.medium.com/?source=post_page-----14f4444dd07f--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)
    ·7 min read·Sep 23, 2023
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----14f4444dd07f--------------------------------)
    ·7分钟阅读·2023年9月23日
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/6f17ca9325b10e97b1e4f7c65396c676.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6f17ca9325b10e97b1e4f7c65396c676.png)'
- en: Image by Author
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: In our ongoing series on Machine Learning Risk Management, we've been looking
    at some of the critical elements that ensure the trustworthiness of Machine Learning
    (ML) systems. In our first installment, we discussed the [**Cultural Competencies
    for Machine Learning Risk Managemen**](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed)**t**,
    in detail. The insights presented therein lay the foundation for our current exploration,
    and therefore, I highly recommend that you go through the part before continuing
    with this article.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们关于机器学习风险管理的持续系列中，我们已经研究了一些确保机器学习（ML）系统可信赖性的关键元素。在我们的第一篇文章中，我们详细讨论了 [**机器学习风险管理中的文化能力**](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed)**t**。其中提供的见解为我们当前的探索奠定了基础，因此，我强烈建议你在继续阅读本文章之前先阅读那部分内容。
- en: '[](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------)
    [## Cultural Competencies for Machine Learning Risk Management'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------)
    [## 机器学习风险管理中的文化能力'
- en: An organization's culture is an essential aspect of responsible AI.
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 组织的文化是负责任的人工智能的一个重要方面。
- en: towardsdatascience.com](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?source=post_page-----14f4444dd07f--------------------------------)
- en: 'In this second article, we’ll shift our focus to another vital element in the
    context of ML systems: **Organizational Processes**. While technical intricacies
    often overshadow these processes, they hold the key to guaranteeing the safety
    and performance of machine learning models. Just as we recognized the significance
    of cultural competencies, we now acknowledge that organizational processes are
    the foundational cornerstone upon which the reliability of ML systems is constructed.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇第二篇文章中，我们将重点转向机器学习系统背景下的另一个重要元素：**组织过程**。虽然技术细节常常掩盖了这些过程，但它们是确保机器学习模型安全性和性能的关键。正如我们认识到文化能力的重要性一样，我们现在承认组织过程是构建机器学习系统可靠性的基础基石。
- en: This article discusses the vital role of organizational processes in the area
    of Machine Learning Risk Management (MRM). Throughout the article, we emphasize
    the criticality of practitioners meticulously considering, documenting, and proactively
    addressing any known or foreseeable failure modes within their ML systems.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本文讨论了组织过程在机器学习风险管理（MRM）领域中的重要作用。整篇文章强调了从业者必须认真考虑、记录和主动解决其ML系统中已知或可预见的故障模式的关键性。
- en: 1️. *Forecasting Failure Modes*
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1️. *预测失败模式*
- en: 'While it is crucial to identify and address possible problems in ML systems,
    turning this idea into action takes time and effort. However, in recent years,
    there has been a significant increase in resources that can help ML system designers
    predict issues more systematically. By carefully sorting out potential problems,
    making ML systems stronger and safer in real-world situations becomes easier.
    In this context, the following strategies can be explored:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）系统中识别和解决可能出现的问题至关重要，但将这一理念付诸实践需要时间和精力。然而，近年来，能够帮助ML系统设计师更系统地预测问题的资源显著增加。通过仔细整理潜在问题，使得在现实世界中让ML系统变得更强大、更安全变得更容易。在这种背景下，可以探索以下策略：
- en: '**Learning from past failures**'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**从过去的失败中学习**'
- en: Much like how transportation professionals investigate and catalog incidents
    to prevent future occurrences, ML researchers and organizations have started collecting
    and analyzing A.I. incidents. The [**A.I. Incident Database**](https://incidentdatabase.ai/),
    which we also brought up in the [last article](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf),
    is a prominent repository that allows users to search for incidents and glean
    valuable insights. When developing an ML system, consulting this resource is crucial.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 就像交通专业人员调查和编目事件以防止未来的发生一样，ML研究人员和组织也开始收集和分析A.I.事件。[**A.I.事件数据库**](https://incidentdatabase.ai/)是一个重要的存储库，允许用户搜索事件并获得宝贵的见解。开发ML系统时，咨询此资源至关重要。
- en: If a similar approach has caused an incident in the past, it serves as a strong
    warning sign that the new system may also pose risks, necessitating careful consideration.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果类似的方法在过去曾导致事件，这就作为一个强烈的警告信号，表明新系统也可能存在风险，需要仔细考虑。
- en: '![](../Images/ca438fee401ddf54467264085c27b526.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca438fee401ddf54467264085c27b526.png)'
- en: 'Preventing Repeated Real-World A.I. Failures by Cataloging Incidents: The A.I.
    Incident Database | Source: [https://arxiv.org/pdf/2011.08512.pdf](https://arxiv.org/pdf/2011.08512.pdf)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '通过编目事件防止现实世界中的人工智能失败重复发生：人工智能事件数据库 | 来源: [https://arxiv.org/pdf/2011.08512.pdf](https://arxiv.org/pdf/2011.08512.pdf)'
- en: '**Addressing *failures of imagination***'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**解决*想象力失败***'
- en: '![](../Images/81f296fe49ada9a1879b9e79680e678c.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/81f296fe49ada9a1879b9e79680e678c.png)'
- en: 'Overcoming Failures of Imagination in AI-Infused System Development and Deployment
    | Source: [https://arxiv.org/pdf/2011.13416.pdf](https://arxiv.org/pdf/2011.13416.pdf)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '克服人工智能系统开发和部署中的想象力失败 | 来源: [https://arxiv.org/pdf/2011.13416.pdf](https://arxiv.org/pdf/2011.13416.pdf)'
- en: Often, A.I. incidents stem from unforeseen or poorly understood contexts and
    details of ML systems' operations. Structured approaches outlined in the paper
    [Overcoming Failures of Imagination in AI-Infused System Development and Deployment](https://arxiv.org/pdf/2011.13416.pdf)
    offer ways to hypothesize about these challenging future risks, in addition to
    considering aspects such as **who** (including investors, customers, and vulnerable
    nonusers), **what** (covering well-being, opportunities, and dignity), **when**
    (including immediate, frequent, and long-term scenarios), and **how** (involving
    actions and belief alterations) related to A.I. incidents.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，人工智能（A.I.）事件源于ML系统操作中未预见或理解不足的背景和细节。论文中概述的结构化方法[克服人工智能系统开发和部署中的想象力失败](https://arxiv.org/pdf/2011.13416.pdf)提供了对这些具有挑战性的未来风险进行假设的方法，并考虑了**谁**（包括投资者、客户和易受害者）、**什么**（涵盖福祉、机会和尊严）、**何时**（包括即时、频繁和长期情境）以及**如何**（涉及行动和信念改变）等方面。
- en: '*While AI incidents can be embarrassing, costly, or even illegal for organizations,
    foresight can mitigate many known incidents, potentially leading to system improvements.
    In such cases, the temporary delay in implementation is far less costly than the
    potential harm to the organization and the public from a flawed system release.*'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*虽然人工智能事件可能会对组织造成尴尬、昂贵，甚至非法的后果，但预见性可以缓解许多已知事件，可能会导致系统的改进。在这种情况下，实施的暂时延迟远远低于由于系统缺陷发布给组织和公众带来的潜在伤害。*'
- en: 2\. Model Risk Management Processes
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 模型风险管理流程
- en: '![](../Images/7b4207ae290dab7f3c97c3ad8024a2cd.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b4207ae290dab7f3c97c3ad8024a2cd.png)'
- en: '***A snapshot of the 21-page S.R. 11–7 model risk management guidance. The
    document is for free public access |*** *Source:* [https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '***21页的S.R. 11–7模型风险管理指南的快照。该文档可免费公开访问 |*** *来源:* [https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)'
- en: Machine Learning Risk Management (MRM) constitutes a comprehensive framework
    and a series of procedures designed to identify, assess, mitigate, and monitor
    risks associated with developing, deploying, and operating machine learning systems.
    These elements form a significant part of the governance structure, particularly
    within the context of the U.S. Federal Reserve's [**Supervisory Guidance on Model
    Risk Management (S.R. 11–07)**](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf),
    which oversees predictive models employed in substantial consumer finance applications.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习风险管理（MRM）构成了一个全面的框架和一系列程序，旨在识别、评估、缓解和监控与开发、部署和操作机器学习系统相关的风险。这些元素是治理结构的重要组成部分，特别是在美国联邦储备系统的[**模型风险管理监督指南（S.R.
    11–07）**](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)的背景下，该指南监督用于重要消费者金融应用的预测模型。
- en: Documentation is where compliance becomes tangible, holding practitioners accountable
    and guiding them to build robust models
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 文档是合规性变得具体的地方，使从业者承担责任并指导他们构建稳健的模型
- en: While complete MRM implementation may be more attainable for larger organizations,
    smaller ones can also extract valuable insights. This section dissects MRM procedures
    into smaller, more manageable components, making them easier to understand and
    use.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然较大的组织可能更容易实现完整的MRM，但较小的组织也可以提取有价值的见解。本节将MRM程序分解为更小、更易管理的组件，使其更易于理解和使用。
- en: 1\. Risk Tiering
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 风险分级
- en: 'When evaluating risk in ML system deployment, a common approach involves calculating
    ***materiality*** considering the likelihood of harm and anticipated loss. High-materiality
    applications demand greater attention. Effective governance appropriately allocates
    resources to high, medium, and low-risk systems. For example, the recently released
    [Anthropic A.I.''s Responsible Scaling policy](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)
    introduces the concept of A.I. safety levels (ASL), loosely inspired by the U.S.
    government''s biosafety level (BSL) standards for managing hazardous biological
    materials. Here is a snapshot of the same:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估机器学习系统部署中的风险时，常见的方法涉及计算***重要性***，考虑伤害的可能性和预期损失。高重要性的应用程序需要更多的关注。有效的治理适当地将资源分配给高、中和低风险的系统。例如，最近发布的[Anthropic
    A.I.负责任的扩展政策](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)引入了人工智能安全级别（ASL）的概念，这一概念在一定程度上受到美国政府生物安全等级（BSL）标准的启发，用于管理危险的生物材料。以下是一个快照：
- en: '![](../Images/5ccd0ed5e761e5b7ed5f122e78eb3305.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5ccd0ed5e761e5b7ed5f122e78eb3305.png)'
- en: 'A snapshot from Anthropic’s RSP | Source: [https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 来自Anthropic的RSP快照 | 来源：[https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf](https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf)
- en: 2\. Model Documentation
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 模型文档
- en: MRM standards require comprehensive system documentation, fulfilling multiple
    purposes, including stakeholder accountability, ongoing maintenance, and incident
    response. Standardized documentation across systems streamlines audit and review
    processes, making it a critical aspect of compliance. Documentation templates
    guide data scientists and engineers throughout the model development process,
    ensuring that all necessary steps are conducted to construct a reliable model.
    Incomplete documentation indicates inadequacies in the training process, as most
    templates require practitioners to fill in every section. Furthermore, including
    one's name and contact information in the final model document fosters accountability.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: MRM 标准要求全面的系统文档，以满足多个目的，包括利益相关者责任、持续维护和事件响应。系统间的标准化文档简化了审计和审查流程，使其成为合规性的关键方面。文档模板指导数据科学家和工程师在模型开发过程中，确保所有必要步骤都得到执行，以构建可靠的模型。不完整的文档表明训练过程存在不足，因为大多数模板要求从业人员填写每个部分。此外，在最终模型文档中包括姓名和联系信息，有助于促进问责制。
- en: '![](../Images/1aba70f788f661e75a31bb5cb22babbc.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1aba70f788f661e75a31bb5cb22babbc.png)'
- en: '*A rough combination of typical sections in MRM documentation and the sections
    recommended by the Annexes to the* [*E.U. Artificial Intelligence Act*](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206)
    *| Image by the author*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*MRM 文档中典型部分的粗略组合以及附件中推荐的* [*欧盟人工智能法案*](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206)
    *| 图片由作者提供*'
- en: Extensive model documentation can be daunting; smaller organizations can opt
    for simpler frameworks like datasheets, and model cards can assist smaller organizations
    in achieving these objectives.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 详尽的模型文档可能令人望而却步；较小的组织可以选择像数据表这样的简单框架，模型卡可以帮助较小的组织实现这些目标。
- en: '![](../Images/2f426bcc44d64d2d794cb7ec03cc971a.png)![](../Images/cb9e0a734a53bcad1744cfd60e983a79.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2f426bcc44d64d2d794cb7ec03cc971a.png)![](../Images/cb9e0a734a53bcad1744cfd60e983a79.png)'
- en: 'L: **Datasheets for Datasets** : Source: [https://arxiv.org/pdf/1803.09010.pdf](https://arxiv.org/pdf/1803.09010.pdf)
    | R: **Model cards for Model Monitoring** : Source: [https://arxiv.org/pdf/1810.03993.pdf](https://arxiv.org/pdf/1810.03993.pdf)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 'L: **数据集数据表**：来源：[https://arxiv.org/pdf/1803.09010.pdf](https://arxiv.org/pdf/1803.09010.pdf)
    | R: **模型监控卡**：来源：[https://arxiv.org/pdf/1810.03993.pdf](https://arxiv.org/pdf/1810.03993.pdf)'
- en: 3\. Model Monitoring
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 模型监控
- en: The foundation of machine learning (ML) safety rests on the intrinsic unpredictability
    of ML system behavior in real-world contexts, necessitating the continuous surveillance
    of these systems from their deployment until their decommissioning. A principal
    concern revolves around **input drift**, which emerges when real-world circumstances
    deviate from the static training data due to factors like market fluctuations,
    regulatory alterations, or unexpected occurrences like pandemics. This divergence
    poses a potential threat to the system's functionality.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）安全的基础在于 ML 系统在现实世界环境中的固有不可预测性，因此需要对这些系统进行持续监控，从部署到退役。一个主要关注点是 **输入漂移**，当现实世界情况与静态训练数据发生偏差时，例如市场波动、监管变化或意外事件（如疫情）时，输入漂移会出现。这种偏差可能对系统功能构成威胁。
- en: '![](../Images/e2abd24be1bc0362670cd4b5f2a8667f.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2abd24be1bc0362670cd4b5f2a8667f.png)'
- en: '**Machine Learning in Research vs. Production.** | Slide from ''Safe and Reliable
    Machine Learning: Preventing and Identifying Failures'' presented at ICLR-2019,
    accessible at [https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures](https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures)
    under the CCO License'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**研究与生产中的机器学习。** | 幻灯片来自于‘安全可靠的机器学习：防止和识别故障’，在 ICLR-2019 上展示，可在 [https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures](https://slideslive.com/38915708/safe-and-reliable-machine-learning-preventing-and-identifying-failures)
    查阅，采用 CCO 许可协议'
- en: Efficient ML systems reduce these risks by carefully monitoring for changes
    in data and model quality. This monitoring goes beyond just performance; it also
    looks for unusual data or predictions, security problems, and fairness issues.
    This helps ensure thorough risk management in a changing operational setting.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 高效的 ML 系统通过仔细监控数据和模型质量的变化来降低这些风险。这种监控不仅关注性能，还会查看异常数据或预测、安全问题和公平性问题。这有助于确保在不断变化的操作环境中进行全面的风险管理。
- en: 4\. Model Inventories
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 模型清单
- en: At the heart of MRM is the **model inventory** — comprehensive databases that
    list all of an organization's ML systems and connect to essential resources like
    monitoring strategies, audit results, system maintenance records, and incident
    response plans.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: MRM 的核心是**模型清单**——全面的数据库，列出组织中所有的机器学习系统，并连接到监控策略、审计结果、系统维护记录和事件响应计划等重要资源。
- en: 'Any organization that is deploying ML should be able to answer straightforward
    questions like:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 任何部署机器学习的组织都应该能够回答像这样简单明了的问题：
- en: '![](../Images/123759f71b67dccacaf128b5dc13a17b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/123759f71b67dccacaf128b5dc13a17b.png)'
- en: Any organization that is deploying ML should be able to answer these straightforward
    questions | Image by the Author
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 任何部署机器学习的组织都应该能够回答这些简单明了的问题 | 图片来源：作者
- en: For any organization serious about leveraging ML, maintaining a robust model
    inventory isn't just a good practice — it's a necessity.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何重视利用机器学习的组织而言，维护一个强大的模型清单不仅是一个良好的实践——而是必不可少的。
- en: '*5\. System validation and process auditing*'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*5. 系统验证和过程审计*'
- en: An essential aspect of traditional MRM practice is that it undergoes two primary
    evaluations before an ML system is released. First, experts test its technical
    parts, finding and fixing issues. Next, a team ensures the system follows all
    rules and guidelines, including its design and future plans. These systems are
    reviewed again if they have big updates. Some smaller companies might feel they
    can only do some of these checks, but the basic idea is to have someone outside
    the design team test it, ensure it meets all rules, and get approval before using
    essential systems.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 传统 MRM 实践的一个重要方面是，在机器学习系统发布之前，它会经过两个主要评估。首先，专家测试其技术部分，查找并修复问题。接着，一个团队确保系统遵循所有规则和指南，包括其设计和未来计划。如果这些系统有重大更新，还会再次审查。有些小公司可能觉得只能进行部分检查，但基本的想法是要有外部的人员来测试，确保它符合所有规则，并在使用重要系统之前获得批准。
- en: Effective MRM in Machine Learning means dual scrutiny
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在机器学习中，有效的 MRM（模型风险管理）意味着双重审查。
- en: '*6\. Change management*'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*6. 变更管理*'
- en: ML systems, like other complex software, have various parts like backend code,
    APIs, and user interfaces. Changes in one component can affect others. Challenges
    like shifting data patterns, new privacy laws, and reliance on third-party software
    make managing these changes crucial. In the early stages of a critical ML system,
    planning for these changes is essential. Without this planning, mistakes, such
    as using data without permission or system mismatches, can occur and might go
    unnoticed until problems arise.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统像其他复杂的软件一样，拥有各种组件，如后台代码、API 和用户界面。一个组件的变化可能会影响其他组件。数据模式的变化、新的隐私法律以及对第三方软件的依赖等挑战使得管理这些变化变得至关重要。在关键机器学习系统的早期阶段，规划这些变化是必要的。如果没有这种规划，可能会发生错误，例如未经许可使用数据或系统不匹配，并且这些错误可能在问题出现之前未被察觉。
- en: Conclusion
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: From [cultural competencies](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed)
    to organizational processes, we've explored various aspects that contribute to
    ensuring the safety and performance of machine learning systems. As we've seen,
    forecasting failure modes, meticulous model risk management, and vigilant monitoring
    are key pillars in this journey. Building robust models, maintaining comprehensive
    inventories, and embracing change management are crucial steps toward responsible
    AI. These foundational elements not only ensure the safety and performance of
    the ML systems but also the trust of their users and stakeholders.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [文化能力](/cultural-competencies-for-machine-learning-risk-management-c38616c2ccdf?sk=8ed4f0c5e9624e21d9f6dae9017d5bed)
    到组织流程，我们探讨了确保机器学习系统安全性和性能的各种方面。正如我们所看到的，预测失败模式、细致的模型风险管理和警惕的监控是这一路径中的关键支柱。构建强健的模型、维护全面的清单和拥抱变更管理是实现负责任的人工智能的关键步骤。这些基础要素不仅确保了机器学习系统的安全性和性能，还赢得了用户和利益相关者的信任。
- en: '***> Read the next article in this series >***'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '***> 阅读本系列中的下一篇文章 >***'
- en: '[](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------)
    [## Bridging Domains: Infusing Financial, Privacy, and Software Best Practices
    into ML Risk Management'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------)
    [## 跨领域桥接：将金融、隐私和软件最佳实践融入机器学习风险管理'
- en: Understanding strategies that go beyond traditional Model Risk Management
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解超越传统模型风险管理的策略
- en: towardsdatascience.com](/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[向数据科学迈进](https://towardsdatascience.com/bridging-domains-infusing-financial-privacy-and-software-best-practices-into-ml-risk-management-3de1fa1e6dd2?source=post_page-----14f4444dd07f--------------------------------)'
- en: References & Further Reading
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料与进一步阅读
- en: '[Preventing Repeated Real-World A.I. Failures by Cataloging Incidents: The
    A.I. Incident Database](https://arxiv.org/pdf/2011.08512.pdf)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过记录事件防止现实世界中重复的人工智能失败：人工智能事件数据库](https://arxiv.org/pdf/2011.08512.pdf)'
- en: '[Overcoming Failures of Imagination in AI-Infused System Development and Deployment](https://arxiv.org/pdf/2011.13416.pdf)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[克服人工智能驱动系统开发和部署中的想象力失败](https://arxiv.org/pdf/2011.13416.pdf)'
- en: '[Machine Learning For High-Risk Application, Chapter 1 — Organizational Processes
    for Machine Learning Risk Management](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[高风险应用中的机器学习，第1章 — 机器学习风险管理的组织流程](https://www.amazon.in/Machine-Learning-High-Risk-Applications-Responsible/dp/1098102436)'
- en: '[E.U. Artificial Intelligence Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[欧盟人工智能法案](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206)'
- en: '[S.R. 11–7 Model risk management guidance](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[S.R. 11–7 模型风险管理指南](https://www.federalreserve.gov/supervisionreg/srletters/sr1107a1.pdf)'
