- en: 5 Fantastic Data Pipeline Orchestration Tools For R
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 ç§é€‚ç”¨äº R çš„æä½³æ•°æ®ç®¡é“ç¼–æ’å·¥å…·
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/5-fantastic-data-pipeline-orchestration-tools-for-r-f34ab71b1730](https://towardsdatascience.com/5-fantastic-data-pipeline-orchestration-tools-for-r-f34ab71b1730)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/5-fantastic-data-pipeline-orchestration-tools-for-r-f34ab71b1730](https://towardsdatascience.com/5-fantastic-data-pipeline-orchestration-tools-for-r-f34ab71b1730)
- en: Explore Excellent Options for Data Pipeline Orchestration for R Users
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¢ç´¢é€‚ç”¨äº R ç”¨æˆ·çš„æ•°æ®ç®¡é“ç¼–æ’çš„ä¼˜ç§€é€‰é¡¹
- en: '[](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)[![Chengzhi
    Zhao](../Images/186bba91822dbcc0f926426e56faf543.png)](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f34ab71b1730--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f34ab71b1730--------------------------------)
    [Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)[![Chengzhi
    Zhao](../Images/186bba91822dbcc0f926426e56faf543.png)](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f34ab71b1730--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f34ab71b1730--------------------------------)
    [Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f34ab71b1730--------------------------------)
    Â·11 min readÂ·Jan 30, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f34ab71b1730--------------------------------)
    Â·é˜…è¯»æ—¶é—´ 11 åˆ†é’ŸÂ·2023 å¹´ 1 æœˆ 30 æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/c2f54ada9cd590d65eda4378e24afa28.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2f54ada9cd590d65eda4378e24afa28.png)'
- en: Photo by [Daria Nepriakhina ğŸ‡ºğŸ‡¦](https://unsplash.com/ko/@epicantus?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/kXDHR_bXIZo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [Daria Nepriakhina ğŸ‡ºğŸ‡¦](https://unsplash.com/ko/@epicantus?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    æä¾›ï¼Œ[Unsplash](https://unsplash.com/photos/kXDHR_bXIZo?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: The data pipeline orchestration tool is critical for producing healthy and reliable
    data-driven decisions. R is one of the popular languages for data scientists.
    With Râ€™s exceptional packages, the R programming language is great for data manipulation,
    statistical analysis, and visualization.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç®¡é“ç¼–æ’å·¥å…·å¯¹äºç”Ÿæˆå¥åº·ä¸”å¯é çš„æ•°æ®é©±åŠ¨å†³ç­–è‡³å…³é‡è¦ã€‚R æ˜¯æ•°æ®ç§‘å­¦å®¶å¸¸ç”¨çš„è¯­è¨€ä¹‹ä¸€ã€‚å‡­å€Ÿ R çš„ä¼˜ç§€åŒ…ï¼ŒR ç¼–ç¨‹è¯­è¨€éå¸¸é€‚åˆæ•°æ®å¤„ç†ã€ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–ã€‚
- en: One pattern that often brings data scientistsâ€™ R local script to production
    is to rewrite using Python or Scala (Spark), then schedule the data pipeline and
    model building via modern data pipeline orchestration tools like Apache Airflow.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¸¸è§çš„æ¨¡å¼æ˜¯å°†æ•°æ®ç§‘å­¦å®¶åœ¨ R ä¸­ç¼–å†™çš„æœ¬åœ°è„šæœ¬é‡å†™ä¸º Python æˆ– Scalaï¼ˆSparkï¼‰ï¼Œç„¶åé€šè¿‡ç°ä»£æ•°æ®ç®¡é“ç¼–æ’å·¥å…·å¦‚ Apache Airflow
    è°ƒåº¦æ•°æ®ç®¡é“å’Œæ¨¡å‹æ„å»ºã€‚
- en: However, many modern data orchestration projects like Apache Airflow, Prefect,
    and Luigi are Python-based. Can they work seamlessly with R? Can you write in
    R to define a DAG? In this article, letâ€™s explore the popular data pipeline orchestration
    tool for R scripts and review which fits your use case.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè®¸å¤šç°ä»£æ•°æ®ç¼–æ’é¡¹ç›®å¦‚ Apache Airflowã€Prefect å’Œ Luigi éƒ½æ˜¯åŸºäº Python çš„ã€‚å®ƒä»¬èƒ½ä¸ R æ— ç¼é…åˆå—ï¼Ÿä½ èƒ½ç”¨
    R ç¼–å†™æ¥å®šä¹‰ DAG å—ï¼Ÿåœ¨æœ¬æ–‡ä¸­ï¼Œè®©æˆ‘ä»¬æ¢ç´¢é€‚ç”¨äº R è„šæœ¬çš„æµè¡Œæ•°æ®ç®¡é“ç¼–æ’å·¥å…·ï¼Œå¹¶è¯„ä¼°å“ªä¸ªé€‚åˆä½ çš„ä½¿ç”¨åœºæ™¯ã€‚
- en: The Key Components of the Successful Data Pipeline Orchestration
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆåŠŸçš„æ•°æ®ç®¡é“ç¼–æ’çš„å…³é”®ç»„æˆéƒ¨åˆ†
- en: 'Data pipeline orchestration can be broken down into three main components from
    my experience: **DAG (dependencies), Scheduler, and Plugins.**'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æˆ‘çš„ç»éªŒï¼Œæ•°æ®ç®¡é“ç¼–æ’å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š**DAGï¼ˆä¾èµ–å…³ç³»ï¼‰ã€è°ƒåº¦ç¨‹åºå’Œæ’ä»¶**ã€‚
- en: DAG (Directed acyclic graph)
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰
- en: '**Dag defines the blueprint of the data pipeline**. It provides a direction
    for the execution path. At the same time, you can track back the dependencies
    by looking at the dag.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**DAG å®šä¹‰äº†æ•°æ®ç®¡é“çš„è“å›¾**ã€‚å®ƒä¸ºæ‰§è¡Œè·¯å¾„æä¾›äº†æ–¹å‘ã€‚åŒæ—¶ï¼Œä½ å¯ä»¥é€šè¿‡æŸ¥çœ‹ DAG æ¥è¿½è¸ªä¾èµ–å…³ç³»ã€‚'
- en: '*Why is DAG crucial for the success of any data pipeline?* It is because working
    with data needs to have an ordering to extract the insights from the data. This
    order cannot be changed from a business rule perspective. Otherwise, the output
    from the data is useless or errors out.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä¸ºä»€ä¹ˆ DAG å¯¹ä»»ä½•æ•°æ®ç®¡é“çš„æˆåŠŸè‡³å…³é‡è¦ï¼Ÿ* å› ä¸ºå¤„ç†æ•°æ®éœ€è¦æœ‰ä¸€ä¸ªé¡ºåºï¼Œä»¥ä»æ•°æ®ä¸­æå–è§è§£ã€‚è¿™ä¸€é¡ºåºä»ä¸šåŠ¡è§„åˆ™çš„è§’åº¦æ¥çœ‹ä¸èƒ½æ›´æ”¹ã€‚å¦åˆ™ï¼Œæ•°æ®çš„è¾“å‡ºå°†æ˜¯æ— ç”¨çš„æˆ–å‡ºé”™çš„ã€‚'
- en: Looking at each node in the directed acyclic graph as an individual function,
    DAG provides an alignment that the current node has to follow the rules defined
    by upstream nodes. For example, the current node is only triggered if all the
    upstream nodes are successful; or the current node is executable when one of the
    upstream nodes fails.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†æœ‰å‘æ— ç¯å›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„åŠŸèƒ½ï¼ŒDAG æä¾›äº†ä¸€ä¸ªå¯¹é½æ–¹å¼ï¼Œä½¿å½“å‰èŠ‚ç‚¹å¿…é¡»éµå¾ªä¸Šæ¸¸èŠ‚ç‚¹å®šä¹‰çš„è§„åˆ™ã€‚ä¾‹å¦‚ï¼Œå½“å‰èŠ‚ç‚¹ä»…åœ¨æ‰€æœ‰ä¸Šæ¸¸èŠ‚ç‚¹æˆåŠŸæ—¶è§¦å‘ï¼›æˆ–è€…å½“å‰èŠ‚ç‚¹åœ¨ä¸€ä¸ªä¸Šæ¸¸èŠ‚ç‚¹å¤±è´¥æ—¶å¯æ‰§è¡Œã€‚
- en: The DAG conveniently provides a view of data lineage. It enhances visibility
    while significantly streamlining the ability to trace errors in the data pipeline.
    When it comes to the time that the data pipeline encounters the unpleasant error
    for the morning on-call, the instance of the DAG execution can quickly point out
    where the error occurs.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: DAG æ–¹ä¾¿åœ°æä¾›äº†æ•°æ®æ¥æºçš„è§†å›¾ã€‚å®ƒæå‡äº†å¯è§æ€§ï¼ŒåŒæ—¶æ˜¾è‘—ç®€åŒ–äº†åœ¨æ•°æ®ç®¡é“ä¸­è¿½è¸ªé”™è¯¯çš„èƒ½åŠ›ã€‚å½“æ•°æ®ç®¡é“åœ¨æ—©æ™¨å€¼ç­æ—¶é‡åˆ°ä¸æ„‰å¿«çš„é”™è¯¯æ—¶ï¼ŒDAG æ‰§è¡Œçš„å®ä¾‹å¯ä»¥å¿«é€ŸæŒ‡å‡ºé”™è¯¯å‘ç”Ÿçš„ä½ç½®ã€‚
- en: The power to visualize DAG as a blueprint and its instance at run time to check
    the job running status is crucial nowadays for any data orchestration tools.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ç°å¦‚ä»Šï¼Œèƒ½å¤Ÿå°† DAG è§†ä¸ºè“å›¾å¹¶åœ¨è¿è¡Œæ—¶æŸ¥çœ‹å…¶å®ä¾‹ä»¥æ£€æŸ¥ä½œä¸šè¿è¡ŒçŠ¶æ€çš„åŠŸèƒ½å¯¹äºä»»ä½•æ•°æ®ç¼–æ’å·¥å…·éƒ½è‡³å…³é‡è¦ã€‚
- en: Scheduler
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è°ƒåº¦å™¨
- en: '**Scheduler is the driver for executing the data pipeline.** A scheduler can
    be simple as a cron job. A more complex scheduler involves building your own,
    like the one in Airflow, which manages all the task states and aggressively snapshots.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**è°ƒåº¦å™¨æ˜¯æ‰§è¡Œæ•°æ®ç®¡é“çš„é©±åŠ¨ç¨‹åºã€‚** ä¸€ä¸ªè°ƒåº¦å™¨å¯ä»¥åƒ cron ä½œä¸šä¸€æ ·ç®€å•ã€‚æ›´å¤æ‚çš„è°ƒåº¦å™¨æ¶‰åŠæ„å»ºè‡ªå·±çš„è°ƒåº¦å™¨ï¼Œæ¯”å¦‚ Airflow ä¸­çš„è°ƒåº¦å™¨ï¼Œå®ƒç®¡ç†æ‰€æœ‰ä»»åŠ¡çŠ¶æ€å¹¶ç§¯æå¿«ç…§ã€‚'
- en: '*What does the scheduler do?* The scheduler is a daemon, which can be treated
    as a background process. It is supposed to run 24/7 and monitor a time or event
    when it reaches that point. If the time or event for scheduling is called, execute
    the task and watch for the next one.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*è°ƒåº¦å™¨çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ* è°ƒåº¦å™¨æ˜¯ä¸€ä¸ªå®ˆæŠ¤è¿›ç¨‹ï¼Œå¯ä»¥è¢«è§†ä¸ºåå°è¿›ç¨‹ã€‚å®ƒåº”è¯¥å…¨å¤©å€™è¿è¡Œï¼Œå¹¶åœ¨è¾¾åˆ°æŸä¸ªæ—¶é—´æˆ–äº‹ä»¶æ—¶è¿›è¡Œç›‘æ§ã€‚å¦‚æœè°ƒç”¨äº†è°ƒåº¦çš„æ—¶é—´æˆ–äº‹ä»¶ï¼Œæ‰§è¡Œä»»åŠ¡å¹¶ç­‰å¾…ä¸‹ä¸€ä¸ªä»»åŠ¡ã€‚'
- en: '![](../Images/af4e7a2e23d3bf464651a20a259de223.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/af4e7a2e23d3bf464651a20a259de223.png)'
- en: Scheduling Cycle | Image By Author
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: è°ƒåº¦å‘¨æœŸ | å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Plugins
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ’ä»¶
- en: '**Plugins are for extensibility and are considered as the potential for the
    data pipeline.** Itâ€™s common to leverage existing packages instead of reinventing
    the wheel. The richness of the plugins of the orchestration tools can save you
    time to concentrate on business logic than spending days googling & coding â€œ*How
    to write script submit a Spark job to EMR?*â€'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ’ä»¶ç”¨äºæ‰©å±•æ€§ï¼Œè¢«è§†ä¸ºæ•°æ®ç®¡é“çš„æ½œåŠ›ã€‚** åˆ©ç”¨ç°æœ‰çš„è½¯ä»¶åŒ…è€Œä¸æ˜¯é‡æ–°å‘æ˜è½®å­æ˜¯å¾ˆå¸¸è§çš„ã€‚ç¼–æ’å·¥å…·æ’ä»¶çš„ä¸°å¯Œæ€§å¯ä»¥èŠ‚çœä½ é›†ä¸­äºä¸šåŠ¡é€»è¾‘çš„æ—¶é—´ï¼Œè€Œä¸æ˜¯èŠ±è´¹æ•°å¤©çš„æ—¶é—´æœç´¢å’Œç¼–å†™â€œ*å¦‚ä½•ç¼–å†™è„šæœ¬å°†
    Spark ä½œä¸šæäº¤åˆ° EMRï¼Ÿ*â€'
- en: If a data orchestration tool grows, it attracts more vendors and additional
    community developers to add more plugins to draw additional users. It is also
    expensive to migrate to other data pipeline orchestration tools.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ•°æ®ç¼–æ’å·¥å…·ä¸æ–­å‘å±•ï¼Œå®ƒä¼šå¸å¼•æ›´å¤šçš„ä¾›åº”å•†å’Œé¢å¤–çš„ç¤¾åŒºå¼€å‘è€…æ¥æ·»åŠ æ›´å¤šæ’ä»¶ï¼Œä»¥å¸å¼•æ›´å¤šç”¨æˆ·ã€‚è¿ç§»åˆ°å…¶ä»–æ•°æ®ç®¡é“ç¼–æ’å·¥å…·ä¹Ÿå¾ˆæ˜‚è´µã€‚
- en: Options Not Cover
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸æ¶µç›–çš„é€‰é¡¹
- en: '[taskscheduleR](https://cran.r-project.org/web/packages/taskscheduleR/readme/README.html):
    a Windows-specific scheduler with the Windows task scheduler. If you are on Windows,
    definitely an option to explore.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[taskscheduleR](https://cran.r-project.org/web/packages/taskscheduleR/readme/README.html)ï¼šä¸€ä¸ª
    Windows ä¸“ç”¨çš„è°ƒåº¦å™¨ï¼Œä¸ Windows ä»»åŠ¡è°ƒåº¦ç¨‹åºä¸€èµ·ä½¿ç”¨ã€‚å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Windowsï¼Œè¿™ç»å¯¹æ˜¯ä¸€ä¸ªå€¼å¾—æ¢ç´¢çš„é€‰é¡¹ã€‚'
- en: '[https://github.com/kirillseva/ruigi](https://github.com/kirillseva/ruigi)
    â€” It is an admirable attempt. However, the project seems idle, and no more activities
    since May 26, 2019 Git'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/kirillseva/ruigi](https://github.com/kirillseva/ruigi)
    â€” è¿™æ˜¯ä¸€ä¸ªä»¤äººé’¦ä½©çš„å°è¯•ã€‚ç„¶è€Œï¼Œè¯¥é¡¹ç›®ä¼¼ä¹å¤„äºé—²ç½®çŠ¶æ€ï¼Œè‡ª2019å¹´5æœˆ26æ—¥ä»¥æ¥æ²¡æœ‰æ›´å¤šæ´»åŠ¨ã€‚'
- en: Explore Data Pipeline Orchestration Tools For R
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¢ç´¢ R çš„æ•°æ®ç®¡é“ç¼–æ’å·¥å…·
- en: We will discuss the following 5 different tools, which fit distinct use cases.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è®¨è®ºä»¥ä¸‹ 5 ç§ä¸åŒçš„å·¥å…·ï¼Œè¿™äº›å·¥å…·é€‚ç”¨äºä¸åŒçš„ä½¿ç”¨æ¡ˆä¾‹ã€‚
- en: '[cronR](https://github.com/bnosac/cronR)'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[cronR](https://github.com/bnosac/cronR)'
- en: '[targets](https://github.com/ropensci/targets)'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[targets](https://github.com/ropensci/targets)'
- en: '[Kestra](https://kestra.io/)'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Kestra](https://kestra.io/)'
- en: '[Apache Airflow](https://airflow.apache.org/)'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Apache Airflow](https://airflow.apache.org/)'
- en: '[Mage](https://www.mage.ai/)'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Mage](https://www.mage.ai/)'
- en: 1\. cronR
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. cronR
- en: One of the key components for successful data pipeline orchestration is scheduling.
    A scheduler gives you peace of mind to run a data pipeline without human intervention.
    To schedule an R script, cronR is the first solution youâ€™d explore.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æˆåŠŸçš„æ•°æ®ç®¡é“åè°ƒçš„å…³é”®ç»„æˆéƒ¨åˆ†ä¹‹ä¸€æ˜¯è°ƒåº¦ã€‚è°ƒåº¦ç¨‹åºè®©ä½ åœ¨æ— éœ€äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹è¿è¡Œæ•°æ®ç®¡é“æ›´åŠ å®‰å¿ƒã€‚è¦è°ƒåº¦ R è„šæœ¬ï¼ŒcronR æ˜¯ä½ é¦–å…ˆè¦æ¢ç´¢çš„è§£å†³æ–¹æ¡ˆã€‚
- en: '[](https://github.com/bnosac/cronR?source=post_page-----f34ab71b1730--------------------------------)
    [## GitHub - bnosac/cronR: A simple R package for managing your cron jobs.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/bnosac/cronR?source=post_page-----f34ab71b1730--------------------------------)
    [## GitHub - bnosac/cronR: ä¸€ä¸ªç®€å•çš„ R åŒ…ï¼Œç”¨äºç®¡ç†ä½ çš„ cron ä½œä¸šã€‚]'
- en: Schedule R scripts/processes with the cron scheduler. This allows R users working
    on Unix/Linux to automate R processesâ€¦
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ cron è°ƒåº¦ç¨‹åºè°ƒåº¦ R è„šæœ¬/è¿›ç¨‹ã€‚è¿™å…è®¸åœ¨ Unix/Linux ä¸Šå·¥ä½œçš„ R ç”¨æˆ·è‡ªåŠ¨åŒ– R è¿›ç¨‹â€¦
- en: github.com](https://github.com/bnosac/cronR?source=post_page-----f34ab71b1730--------------------------------)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/bnosac/cronR?source=post_page-----f34ab71b1730--------------------------------)
- en: The package enhanced a set of wrappers to `crontab` make adopting more straightforward
    using R only. Thus, you donâ€™t need to worry about setting up the crontab, and
    the `cronR` provides an interface that reduces the complexity.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥åŒ…å¢å¼ºäº†ä¸€ç»„å¯¹ `crontab` çš„åŒ…è£…ï¼Œä½¿å¾—ä»…ä½¿ç”¨ R è¿›è¡Œé‡‡çº³å˜å¾—æ›´åŠ ç›´æ¥ã€‚å› æ­¤ï¼Œä½ ä¸éœ€è¦æ‹…å¿ƒè®¾ç½® crontabï¼Œ`cronR` æä¾›äº†ä¸€ä¸ªå‡å°‘å¤æ‚æ€§çš„æ¥å£ã€‚
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Usage Suggestion**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨å»ºè®®**'
- en: This option is a quick and lightweight solution if you only want to schedule
    the R script. It is suitable for use cases such as ad-hoc scheduling, simple dependencies,
    or less state management involved.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ åªæƒ³è°ƒåº¦ R è„šæœ¬ï¼Œè¿™ä¸ªé€‰é¡¹æ˜¯ä¸€ä¸ªå¿«é€Ÿä¸”è½»é‡çš„è§£å†³æ–¹æ¡ˆã€‚å®ƒé€‚ç”¨äºä¸´æ—¶è°ƒåº¦ã€ç®€å•ä¾èµ–å…³ç³»æˆ–æ¶‰åŠè¾ƒå°‘çŠ¶æ€ç®¡ç†çš„ç”¨ä¾‹ã€‚
- en: '**Limitation**'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™åˆ¶**'
- en: Since cronR only gives you a scheduler. Youâ€™d need to build workflow dependencies
    by yourself. Itâ€™s doable if a single R script is manageable. However, if the scriptâ€™s
    size becomes enormous and intermedia stages are required, youâ€™d want to break
    it down. Those are the times cronR isnâ€™t sufficient as it only handles the scheduling
    part without DAG definition and plugins.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº cronR ä»…æä¾›è°ƒåº¦ç¨‹åºã€‚ä½ éœ€è¦è‡ªå·±æ„å»ºå·¥ä½œæµä¾èµ–å…³ç³»ã€‚å¦‚æœä¸€ä¸ª R è„šæœ¬å¯ç®¡ç†ï¼Œé‚£æ˜¯å¯è¡Œçš„ã€‚ç„¶è€Œï¼Œå¦‚æœè„šæœ¬çš„è§„æ¨¡å˜å¾—å·¨å¤§å¹¶ä¸”éœ€è¦ä¸­é—´é˜¶æ®µï¼Œä½ å¯èƒ½å¸Œæœ›å°†å…¶æ‹†åˆ†ã€‚è¿™äº›æ˜¯
    cronR ä¸è¶³ä»¥å¤„ç†çš„æƒ…å†µï¼Œå› ä¸ºå®ƒä»…å¤„ç†è°ƒåº¦éƒ¨åˆ†è€Œä¸åŒ…æ‹¬ DAG å®šä¹‰å’Œæ’ä»¶ã€‚
- en: 2\. targets
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. targets
- en: The `[targets](https://github.com/ropensci/targets)` package is a [Make](https://www.gnu.org/software/make/)-like
    pipeline toolkit for Statistics and data science in R.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`[targets](https://github.com/ropensci/targets)` åŒ…æ˜¯ä¸€ä¸ª [Make](https://www.gnu.org/software/make/)-ç±»ä¼¼çš„
    R ç»Ÿè®¡å’Œæ•°æ®ç§‘å­¦ç®¡é“å·¥å…·åŒ…ã€‚'
- en: '[targets](https://github.com/ropensci/targets) is initiated as an R programming
    language for data pipelines. You can easily define a DAG to create the dependencies
    graph. The main goal for targets is to provide reproducible workflow. It doesnâ€™t
    come with a scheduler, but connecting with the other tools I mentioned here shouldn''t
    be challenging to schedule the DAG generated from targets.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[targets](https://github.com/ropensci/targets) æ˜¯ä¸€ä¸ªç”¨äºæ•°æ®ç®¡é“çš„ R ç¼–ç¨‹è¯­è¨€å·¥å…·ã€‚ä½ å¯ä»¥è½»æ¾å®šä¹‰ä¸€ä¸ª
    DAG æ¥åˆ›å»ºä¾èµ–å›¾ã€‚targets çš„ä¸»è¦ç›®æ ‡æ˜¯æä¾›å¯é‡ç°çš„å·¥ä½œæµã€‚å®ƒæ²¡æœ‰è‡ªå¸¦è°ƒåº¦ç¨‹åºï¼Œä½†ä¸æˆ‘åœ¨è¿™é‡Œæåˆ°çš„å…¶ä»–å·¥å…·è¿æ¥ï¼Œä¸åº”è¯¥éš¾ä»¥è°ƒåº¦ä» targets
    ç”Ÿæˆçš„ DAGã€‚'
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The pipeline and the function definition are divided into two R files. You can
    build the dependencies tree within `_targets.R` file and visualize it by `tar_visnetwork()`
    and get a DAG automatically.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ç®¡é“å’Œå‡½æ•°å®šä¹‰è¢«åˆ†ä¸ºä¸¤ä¸ª R æ–‡ä»¶ã€‚ä½ å¯ä»¥åœ¨ `_targets.R` æ–‡ä»¶ä¸­æ„å»ºä¾èµ–æ ‘ï¼Œå¹¶é€šè¿‡ `tar_visnetwork()` è¿›è¡Œå¯è§†åŒ–ï¼Œä»è€Œè‡ªåŠ¨ç”Ÿæˆ
    DAGã€‚
- en: '![](../Images/9b33dea61e11ce0f8c89ea0cf57ee81d.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9b33dea61e11ce0f8c89ea0cf57ee81d.png)'
- en: targets visualize DAG | Image by Author
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: targets å¯è§†åŒ– DAG | ä½œè€…æä¾›çš„å›¾ç‰‡
- en: '**Usage Suggestion**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨å»ºè®®**'
- en: Youâ€™d need native support utilizing R for the data pipeline. The targets package
    can help R users to improve their efficiency in their day-to-day data analysis
    work. It doesnâ€™t require an additional daemon running in the background to get
    a DAG for visualization and running on demand. Suppose you are looking for a solution
    you can run manually and seek a DAG management solution. targets is an excellent
    option for R users.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ éœ€è¦æœ¬åœ°æ”¯æŒ R æ¥å¤„ç†æ•°æ®ç®¡é“ã€‚targets åŒ…å¯ä»¥å¸®åŠ© R ç”¨æˆ·æé«˜æ—¥å¸¸æ•°æ®åˆ†æå·¥ä½œçš„æ•ˆç‡ã€‚å®ƒä¸éœ€è¦åå°è¿è¡Œé¢å¤–çš„å®ˆæŠ¤è¿›ç¨‹æ¥è·å– DAG è¿›è¡Œå¯è§†åŒ–å’ŒæŒ‰éœ€è¿è¡Œã€‚å¦‚æœä½ åœ¨å¯»æ‰¾ä¸€ä¸ªå¯ä»¥æ‰‹åŠ¨è¿è¡Œå¹¶å¯»æ‰¾
    DAG ç®¡ç†è§£å†³æ–¹æ¡ˆçš„é€‰é¡¹ï¼Œtargets å¯¹äº R ç”¨æˆ·æ¥è¯´æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ã€‚
- en: '**Limitation**'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™åˆ¶**'
- en: If you decide to go with targets, you have a powerful DAG management tool. Nevertheless,
    youâ€™d need to get a scheduler and additional plugins to make it a data pipeline
    orchestrator in production. Combining with a scheduler like cronR can give you
    a purely R solution.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å†³å®šä½¿ç”¨targetsï¼Œä½ å°†æ‹¥æœ‰ä¸€ä¸ªå¼ºå¤§çš„DAGç®¡ç†å·¥å…·ã€‚ç„¶è€Œï¼Œä½ éœ€è¦ä¸€ä¸ªè°ƒåº¦å™¨å’Œé¢å¤–çš„æ’ä»¶æ¥ä½¿å…¶æˆä¸ºç”Ÿäº§ä¸­çš„æ•°æ®ç®¡é“ç¼–æ’å·¥å…·ã€‚ç»“åˆåƒcronRè¿™æ ·çš„è°ƒåº¦å™¨å¯ä»¥ä¸ºä½ æä¾›ä¸€ä¸ªçº¯Rè§£å†³æ–¹æ¡ˆã€‚
- en: 3\. Kestra
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. Kestra
- en: '[Kestra](https://kestra.io/) is a generic data pipeline orchestration tool.
    It currently only supports three types of scripts: *Bash, Node, and Python*.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kestra](https://kestra.io/) æ˜¯ä¸€ä¸ªé€šç”¨çš„æ•°æ®ç®¡é“ç¼–æ’å·¥å…·ã€‚å®ƒç›®å‰ä»…æ”¯æŒä¸‰ç§ç±»å‹çš„è„šæœ¬ï¼š*Bash, Node, å’Œ Python*ã€‚'
- en: Although the R language isnâ€™t included as the supported script. You can still
    achieve the goal of orchestrating the R script by using the bash script with `Rscript`
    command.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡Rè¯­è¨€æœªè¢«åŒ…å«åœ¨æ”¯æŒçš„è„šæœ¬ä¸­ï¼Œä½†ä½ ä»ç„¶å¯ä»¥é€šè¿‡ä½¿ç”¨å¸¦æœ‰`Rscript`å‘½ä»¤çš„bashè„šæœ¬æ¥å®ç°Rè„šæœ¬çš„ç¼–æ’ã€‚
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: A more complex DAG can be set up using [Flowable Task](https://kestra.io/docs/developer-guide/flowable/)
    in the YAML file. The scheduling is also done in the YAML file by [Schedule](https://kestra.io/docs/developer-guide/triggers/schedule.html).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: å¯ä»¥é€šè¿‡åœ¨YAMLæ–‡ä»¶ä¸­ä½¿ç”¨ [Flowable Task](https://kestra.io/docs/developer-guide/flowable/)
    æ¥è®¾ç½®æ›´å¤æ‚çš„DAGã€‚è°ƒåº¦ä¹Ÿåœ¨YAMLæ–‡ä»¶ä¸­é€šè¿‡ [Schedule](https://kestra.io/docs/developer-guide/triggers/schedule.html)
    å®Œæˆã€‚
- en: '**Usage Suggestion**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨å»ºè®®**'
- en: As R users, Kestra allows you to orchestrate the R code via the bash command.
    Additionally, Kestra has the flexibility to run the data pipeline in various languages.
    It shows you a feeling of a modern version of [Oozie](https://oozie.apache.org/).
    If you are familiar with Oozie, Kestra should be much simpler to onboard.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºRç”¨æˆ·ï¼ŒKestraå…è®¸ä½ é€šè¿‡bashå‘½ä»¤ç¼–æ’Rä»£ç ã€‚æ­¤å¤–ï¼ŒKestraå…·æœ‰åœ¨å¤šç§è¯­è¨€ä¸­è¿è¡Œæ•°æ®ç®¡é“çš„çµæ´»æ€§ã€‚å®ƒç»™ä½ ä¸€ç§ç°ä»£ç‰ˆçš„ [Oozie](https://oozie.apache.org/)
    çš„æ„Ÿè§‰ã€‚å¦‚æœä½ å¯¹Oozieæ¯”è¾ƒç†Ÿæ‚‰ï¼ŒKestraåº”è¯¥æ›´å®¹æ˜“ä¸Šæ‰‹ã€‚
- en: '**Limitation**'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™åˆ¶**'
- en: Running R isnâ€™t natively supported. Retrieving the metadata at run time isnâ€™t
    trivial for just using `Rscript` command. Everything is based on `type` , finding
    the proper core or plugin to develop more effectively might take extra time to
    learn.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡ŒRä¸æ˜¯åŸç”Ÿæ”¯æŒçš„ã€‚è¿è¡Œæ—¶æ£€ç´¢å…ƒæ•°æ®å¹¶éç®€å•ï¼Œå•çº¯ä½¿ç”¨`Rscript`å‘½ä»¤å¯èƒ½éœ€è¦é¢å¤–çš„å­¦ä¹ æ—¶é—´æ¥å¯»æ‰¾åˆé€‚çš„æ ¸å¿ƒæˆ–æ’ä»¶ä»¥æ›´æœ‰æ•ˆåœ°å¼€å‘ã€‚
- en: 4\. Apache Airflow
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. Apache Airflow
- en: Airflow is by far the most popular data pipeline orchestration tool. However,
    to write a DAG, youâ€™d need to write Python. You can use the Airflow operator to
    execute your R script. However, to define DAG, R is not part of the implementation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Airflowè¿„ä»Šä¸ºæ­¢æ˜¯æœ€å—æ¬¢è¿çš„æ•°æ®ç®¡é“ç¼–æ’å·¥å…·ã€‚ç„¶è€Œï¼Œè¦ç¼–å†™DAGï¼Œä½ éœ€è¦ä½¿ç”¨Pythonã€‚ä½ å¯ä»¥ä½¿ç”¨Airflowæ“ä½œç¬¦æ¥æ‰§è¡Œä½ çš„Rè„šæœ¬ã€‚ç„¶è€Œï¼Œå®šä¹‰DAGæ—¶ï¼ŒRä¸åœ¨å®ç°èŒƒå›´å†…ã€‚
- en: The Airflow community had a proposal to create an `ROperator`. The proposal
    is to leverage [rpy2](https://rpy2.github.io/), which creates an interface for
    **R** running embedded in a Python process. The core idea is to pass the `r_command`,
    then copy the R script to a temporary file and source it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Airflowç¤¾åŒºæ›¾æå‡ºåˆ›å»º`ROperator`çš„ææ¡ˆã€‚è¯¥ææ¡ˆæ˜¯åˆ©ç”¨ [rpy2](https://rpy2.github.io/)ï¼Œå®ƒä¸º**R**åœ¨Pythonè¿›ç¨‹ä¸­åµŒå…¥è¿è¡Œåˆ›å»ºæ¥å£ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯ä¼ é€’`r_command`ï¼Œç„¶åå°†Rè„šæœ¬å¤åˆ¶åˆ°ä¸´æ—¶æ–‡ä»¶ä¸­å¹¶è¿›è¡Œæºä»£ç å¤„ç†ã€‚
- en: There are many people interested in this pull request from the R users.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å¾ˆå¤šRç”¨æˆ·å¯¹è¿™ä¸ªæ‹‰å–è¯·æ±‚æ„Ÿå…´è¶£ã€‚
- en: '[](https://github.com/apache/airflow/pull/3115?source=post_page-----f34ab71b1730--------------------------------)
    [## [AIRFLOW-2193] Add ROperator for using R by briandconnelly Â· Pull Request
    #3115 Â· apache/airflow'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/apache/airflow/pull/3115?source=post_page-----f34ab71b1730--------------------------------)
    [## [AIRFLOW-2193] ä¸ºä½¿ç”¨Ræ·»åŠ ROperator Â· briandconnelly Â· Pull Request #3115 Â· apache/airflow'
- en: Make sure you have checked all steps below. JIRA My PR addresses the following
    Airflow JIRA issues and references themâ€¦
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç¡®ä¿ä½ æ£€æŸ¥äº†ä»¥ä¸‹æ‰€æœ‰æ­¥éª¤ã€‚JIRA æˆ‘çš„PRæ¶‰åŠä»¥ä¸‹Airflow JIRAé—®é¢˜å¹¶å¼•ç”¨äº†å®ƒä»¬â€¦â€¦
- en: github.com](https://github.com/apache/airflow/pull/3115?source=post_page-----f34ab71b1730--------------------------------)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/apache/airflow/pull/3115?source=post_page-----f34ab71b1730--------------------------------)
- en: However, it didnâ€™t land. Scanning through the pull request. We noticed the R
    language support isnâ€™t something Airflow CI does at that point, and other options
    could execute the R scripts, so the priority to have a `ROperator` is low. There
    are a few options if youâ€™d want to stick with the Airflow ecosystem.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™é¡¹åŠŸèƒ½å°šæœªå®ç°ã€‚æµè§ˆäº†è¿™ä¸ªæ‹‰å–è¯·æ±‚åï¼Œæˆ‘ä»¬æ³¨æ„åˆ°Rè¯­è¨€çš„æ”¯æŒåœ¨å½“æ—¶ä¸æ˜¯Airflow CIçš„ä¸€éƒ¨åˆ†ï¼Œå…¶ä»–é€‰é¡¹å¯ä»¥æ‰§è¡ŒRè„šæœ¬ï¼Œå› æ­¤ä¼˜å…ˆçº§è¾ƒä½ã€‚å¦‚æœä½ å¸Œæœ›åšæŒä½¿ç”¨Airflowç”Ÿæ€ç³»ç»Ÿï¼Œè¿˜æœ‰ä¸€äº›é€‰æ‹©ã€‚
- en: Use `BashOperator` and to run R code. If you can run your R script from the
    terminal, the `BashOperator` meets that requirement. Using the `BashOperator`
    also makes it easy to build the DAG relationship and pass arguments to `bash_command`
    , and add more complex logic like retry and email alert
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ `BashOperator` æ¥è¿è¡Œ R ä»£ç ã€‚å¦‚æœä½ å¯ä»¥ä»ç»ˆç«¯è¿è¡Œä½ çš„ R è„šæœ¬ï¼Œ`BashOperator` æ»¡è¶³è¿™ä¸ªè¦æ±‚ã€‚ä½¿ç”¨ `BashOperator`
    ä¹Ÿä½¿å¾—æ„å»º DAG å…³ç³»ã€å°†å‚æ•°ä¼ é€’åˆ° `bash_command` ä»¥åŠæ·»åŠ æ›´å¤æ‚çš„é€»è¾‘ï¼Œå¦‚é‡è¯•å’Œé‚®ä»¶è­¦æŠ¥ï¼Œå˜å¾—ç®€å•ã€‚
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Run R in Docker containers (see [rocker](https://www.rocker-project.org/)) and
    use the `DockerOperator` . This option is similar to `BashOperator` . A nice thing
    about using a Docker container is you spend less time configuring R script to
    execute within the same environment as Airflow. The Docker container gives you
    a fresh environment for R to run each time. Itâ€™s a nice and clean solution.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨ Docker å®¹å™¨ä¸­è¿è¡Œ Rï¼ˆå‚è§ [rocker](https://www.rocker-project.org/)ï¼‰å¹¶ä½¿ç”¨ `DockerOperator`ã€‚è¿™ä¸ªé€‰é¡¹ç±»ä¼¼äº
    `BashOperator`ã€‚ä½¿ç”¨ Docker å®¹å™¨çš„å¥½å¤„æ˜¯ï¼Œä½ å¯ä»¥å‡å°‘åœ¨ä¸ Airflow ç›¸åŒç¯å¢ƒä¸­æ‰§è¡Œ R è„šæœ¬çš„é…ç½®æ—¶é—´ã€‚Docker å®¹å™¨æ¯æ¬¡æä¾›ä¸€ä¸ªæ–°çš„
    R ç¯å¢ƒã€‚è¿™æ˜¯ä¸€ä¸ªä¸é”™ä¸”å¹²å‡€çš„è§£å†³æ–¹æ¡ˆã€‚
- en: '*[If you still want to have a dedicated* `*ROperator*`*]* you can copy and
    paste `r_operator.py` from the pull request above and make them add them from
    your Airflow infra team.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*[å¦‚æœä½ ä»ç„¶æƒ³è¦ä¸€ä¸ªä¸“ç”¨çš„* `*ROperator*`*]*ï¼Œä½ å¯ä»¥å¤åˆ¶å¹¶ç²˜è´´ä¸Šè¿°æ‹‰å–è¯·æ±‚ä¸­çš„ `r_operator.py`ï¼Œå¹¶è®© Airflow
    åŸºç¡€è®¾æ–½å›¢é˜Ÿå°†å…¶æ·»åŠ è¿›å»ã€‚'
- en: Similar situation for [Prefect](https://github.com/PrefectHQ/prefect). it has
    an open pull request without resolution, and the PR has been marked as low priority.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼çš„æƒ…å†µä¹Ÿå‡ºç°åœ¨ [Prefect](https://github.com/PrefectHQ/prefect)ã€‚å®ƒæœ‰ä¸€ä¸ªæœªè§£å†³çš„å¼€æºæ‹‰å–è¯·æ±‚ï¼Œè€Œä¸”è¯¥
    PR è¢«æ ‡è®°ä¸ºä½ä¼˜å…ˆçº§ã€‚
- en: '[](https://github.com/PrefectHQ/prefect/issues/5449?source=post_page-----f34ab71b1730--------------------------------)
    [## Add `RTask` to the Task Library Â· Issue #5449 Â· PrefectHQ/prefect'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/PrefectHQ/prefect/issues/5449?source=post_page-----f34ab71b1730--------------------------------)
    [## æ·»åŠ  `RTask` åˆ°ä»»åŠ¡åº“ Â· é—®é¢˜ #5449 Â· PrefectHQ/prefect'
- en: You can't perform that action at this time. You signed in with another tab or
    window. You signed out in another tab orâ€¦
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½ ç›®å‰ä¸èƒ½æ‰§è¡Œè¯¥æ“ä½œã€‚ä½ åœ¨å¦ä¸€ä¸ªæ ‡ç­¾é¡µæˆ–çª—å£ä¸­ç™»å½•äº†ã€‚ä½ åœ¨å¦ä¸€ä¸ªæ ‡ç­¾é¡µæˆ–çª—å£ä¸­æ³¨é”€äº†â€¦
- en: github.com](https://github.com/PrefectHQ/prefect/issues/5449?source=post_page-----f34ab71b1730--------------------------------)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[github.com](https://github.com/PrefectHQ/prefect/issues/5449?source=post_page-----f34ab71b1730--------------------------------)'
- en: Many modern data pipeline orchestrations are built using Python. However, when
    it comes to leveraging another popular data-related language like R, the possibility
    of prioritizing it becomes low as it didnâ€™t start with other languages while designing
    it. Later, the project becomes too big to make fundamental changes and requires
    tremendous effort from the ground.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šç°ä»£æ•°æ®ç®¡é“ç¼–æ’æ˜¯ä½¿ç”¨ Python æ„å»ºçš„ã€‚ç„¶è€Œï¼Œå½“æ¶‰åŠåˆ°åˆ©ç”¨å¦ä¸€ä¸ªæµè¡Œçš„æ•°æ®ç›¸å…³è¯­è¨€å¦‚ R æ—¶ï¼Œç”±äºå…¶åœ¨è®¾è®¡æ—¶æ²¡æœ‰ä¸å…¶ä»–è¯­è¨€ä¸€èµ·å¼€å§‹ï¼Œæ‰€ä»¥ä¼˜å…ˆçº§è¾ƒä½ã€‚åæ¥ï¼Œé¡¹ç›®å˜å¾—è¿‡äºåºå¤§ï¼Œéš¾ä»¥è¿›è¡Œæ ¹æœ¬æ€§çš„æ›´æ”¹ï¼Œå¹¶ä¸”éœ€è¦ä»å¤´å¼€å§‹ä»˜å‡ºå·¨å¤§åŠªåŠ›ã€‚
- en: '**Usage Suggestion**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨å»ºè®®**'
- en: This option is good if you already have Airflow infrastructure as the data pipeline
    orchestrator. Airflow provides the three key elements of a successful data pipeline
    orchestration platform. You have the foundation and resources set up, and running
    R is possible with the abovementioned options.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å·²ç»æœ‰äº†ä½œä¸ºæ•°æ®ç®¡é“ç¼–æ’å™¨çš„ Airflow åŸºç¡€è®¾æ–½ï¼Œè¿™ä¸ªé€‰é¡¹æ˜¯å¥½çš„ã€‚Airflow æä¾›äº†æˆåŠŸçš„æ•°æ®ç®¡é“ç¼–æ’å¹³å°çš„ä¸‰ä¸ªå…³é”®å…ƒç´ ã€‚ä½ å·²ç»å»ºç«‹äº†åŸºç¡€å’Œèµ„æºï¼Œä½¿ç”¨ä¸Šè¿°é€‰é¡¹è¿è¡Œ
    R æ˜¯å¯èƒ½çš„ã€‚
- en: '**Limitation**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™åˆ¶**'
- en: R isnâ€™t the first citizen in Airflow. In Airflow, running R isnâ€™t natively supported.
    You have multiple workarounds, but R is still treated as a foreign language. Whether
    you decide to go with `BashOperator` or `DockerOperator` or even fork that PR,
    there is still additional support youâ€™d need to get to the data infra team to
    help you to make the R script runnable in Airflow.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: R å¹¶ä¸æ˜¯ Airflow ä¸­çš„ç¬¬ä¸€ä¸ªå…¬æ°‘ã€‚åœ¨ Airflow ä¸­ï¼ŒåŸç”Ÿä¸æ”¯æŒè¿è¡Œ Rã€‚è™½ç„¶æœ‰å¤šç§è§£å†³æ–¹æ³•ï¼Œä½† R ä»ç„¶è¢«è§†ä¸ºå¤–è¯­ã€‚æ— è®ºä½ é€‰æ‹©ä½¿ç”¨`BashOperator`è¿˜æ˜¯`DockerOperator`ï¼Œç”šè‡³æ˜¯åˆ†å‰é‚£ä¸ª
    PRï¼Œä½ ä»ç„¶éœ€è¦é¢å¤–çš„æ”¯æŒï¼Œä¸æ•°æ®åŸºç¡€è®¾æ–½å›¢é˜Ÿæ²Ÿé€šï¼Œä»¥å¸®åŠ©ä½ ä½¿ R è„šæœ¬åœ¨ Airflow ä¸­å¯è¿è¡Œã€‚
- en: Another limitation is that it is not straightforward to pull the Airflow macros
    (Airflowâ€™s metadata) at run time with R. You can still use a nontrivial solution
    by querying Airflow's backend. However, it isnâ€™t user-friendly for R users without
    depth knowledge of Airflow.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé™åˆ¶æ˜¯ï¼Œä½¿ç”¨ R æ—¶ï¼Œå®æ—¶æ‹‰å– Airflow å®ï¼ˆAirflow çš„å…ƒæ•°æ®ï¼‰å¹¶ä¸ç®€å•ã€‚ä½ ä»ç„¶å¯ä»¥é€šè¿‡æŸ¥è¯¢ Airflow çš„åç«¯æ¥ä½¿ç”¨å¤æ‚çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå¯¹äºæ²¡æœ‰æ·±å…¥äº†è§£
    Airflow çš„ R ç”¨æˆ·æ¥è¯´ï¼Œè¿™å¹¶ä¸å‹å¥½ã€‚
- en: 5\. Mage
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. æ³•å¸ˆ
- en: Mage is the new player in the data pipeline orchestration. The biggest win for
    our discussion is that **Mage recognizes R as part of its support language by
    default and enables users to define DAG regardless of the choice of languages
    (python/SQL/R at this point).**
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Mage æ˜¯æ•°æ®ç®¡é“ç¼–æ’é¢†åŸŸçš„æ–°ç©å®¶ã€‚æˆ‘ä»¬è®¨è®ºçš„æœ€å¤§æ”¶è·æ˜¯ **Mage é»˜è®¤å°† R è¯†åˆ«ä¸ºæ”¯æŒè¯­è¨€çš„ä¸€éƒ¨åˆ†ï¼Œå¹¶å…è®¸ç”¨æˆ·å®šä¹‰ DAGï¼Œè€Œä¸è®ºé€‰æ‹©ä½•ç§è¯­è¨€ï¼ˆç›®å‰ä¸º
    python/SQL/Rï¼‰ã€‚**
- en: This is a milestone for R users. UserswholoveR donâ€™t have to switch to Python
    syntax when they define a DAG that wraps the R script in a limited supported tool.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ R ç”¨æˆ·çš„ä¸€ä¸ªé‡Œç¨‹ç¢‘ã€‚å–œæ¬¢ R çš„ç”¨æˆ·åœ¨å®šä¹‰ä¸€ä¸ªå°† R è„šæœ¬å°è£…åœ¨å—é™æ”¯æŒå·¥å…·ä¸­çš„ DAG æ—¶ï¼Œä¸å¿…åˆ‡æ¢åˆ° Python è¯­æ³•ã€‚
- en: Mage allows users to write the main ETL (Extraction, Transformation, and Loading)
    blocks using R. Mage constructs the DAG by maintaining DAG dependencies relationships
    in a YAML file. This becomes a flexible option by bypassing the choices of programming
    language. You can also visualize the DAG along with the R code block while developing
    your DAG
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Mage å…è®¸ç”¨æˆ·ä½¿ç”¨ R ç¼–å†™ä¸»è¦çš„ ETLï¼ˆæå–ã€è½¬æ¢å’ŒåŠ è½½ï¼‰å—ã€‚Mage é€šè¿‡åœ¨ YAML æ–‡ä»¶ä¸­ç»´æŠ¤ DAG ä¾èµ–å…³ç³»æ¥æ„å»º DAGã€‚è¿™æˆä¸ºäº†ä¸€ç§çµæ´»çš„é€‰æ‹©ï¼Œç»•è¿‡äº†ç¼–ç¨‹è¯­è¨€çš„é€‰æ‹©ã€‚ä½ è¿˜å¯ä»¥åœ¨å¼€å‘
    DAG æ—¶å¯è§†åŒ– DAG åŠå…¶ R ä»£ç å—ã€‚
- en: '![](../Images/173007d39faa27f767b129ceb431a85e.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/173007d39faa27f767b129ceb431a85e.png)'
- en: Mage Pipeline Edit Mode Using R | Image by author
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Mage ç®¡é“ç¼–è¾‘æ¨¡å¼ä½¿ç”¨ R | ä½œè€…æä¾›çš„å›¾åƒ
- en: Below are the 3 main blocks I used to demonstrate how to use R to code the pipeline
    and build the DAG in Mage. Furthermore, you can access the scheduler metadata
    like `execution_date` easily in R.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯æˆ‘ç”¨æ¥æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ R ç¼–å†™ç®¡é“å¹¶åœ¨ Mage ä¸­æ„å»º DAG çš„ä¸‰ä¸ªä¸»è¦å—ã€‚æ­¤å¤–ï¼Œä½ å¯ä»¥è½»æ¾åœ°åœ¨ R ä¸­è®¿é—®è°ƒåº¦ç¨‹åºå…ƒæ•°æ®ï¼Œå¦‚ `execution_date`ã€‚
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Once the pipeline has been developed in Mage, you can attach a trigger by scheduling
    the pipeline with a crontab.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦åœ¨ Mage ä¸­å¼€å‘äº†ç®¡é“ï¼Œä½ å¯ä»¥é€šè¿‡ä½¿ç”¨ crontab è°ƒåº¦ç®¡é“æ¥é™„åŠ è§¦å‘å™¨ã€‚
- en: '![](../Images/0c0338e2a94a4208e2a79a43b4d2b92c.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0c0338e2a94a4208e2a79a43b4d2b92c.png)'
- en: Mage Pipeline Scheduling | Image by author
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Mage ç®¡é“è°ƒåº¦ | ä½œè€…æä¾›çš„å›¾åƒ
- en: Internally, Mage still uses Python as its core and parses R script into a `tmp`
    file, then run the Rscript command with that file.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å†…éƒ¨ï¼ŒMage ä»ç„¶ä½¿ç”¨ Python ä½œä¸ºæ ¸å¿ƒï¼Œå¹¶å°† R è„šæœ¬è§£ææˆ `tmp` æ–‡ä»¶ï¼Œç„¶åä½¿ç”¨è¯¥æ–‡ä»¶è¿è¡Œ Rscript å‘½ä»¤ã€‚
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If youâ€™d want to learn more about Mage as an alternative to Apache Airflow,
    I wrote an article on it.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äº Mage ä½œä¸º Apache Airflow æ›¿ä»£æ–¹æ¡ˆçš„å†…å®¹ï¼Œæˆ‘å†™äº†ä¸€ç¯‡æ–‡ç« ã€‚
- en: '[](https://chengzhizhao.medium.com/is-apache-airflow-due-for-replacement-the-first-impression-of-mage-ai-ade8208fb2a0?source=post_page-----f34ab71b1730--------------------------------)
    [## Is Apache Airflow Due for Replacement? The First Impression Of mage-ai'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://chengzhizhao.medium.com/is-apache-airflow-due-for-replacement-the-first-impression-of-mage-ai-ade8208fb2a0?source=post_page-----f34ab71b1730--------------------------------)
    [## Apache Airflow æ˜¯å¦è¯¥è¢«æ›¿ä»£ï¼Ÿmage-ai çš„åˆæ­¥å°è±¡]'
- en: Introduction to mage-ai as the alternative to Apache Airflow for data engineers
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä½œä¸ºæ•°æ®å·¥ç¨‹å¸ˆå¯¹ Apache Airflow çš„æ›¿ä»£æ–¹æ¡ˆä»‹ç» mage-ai
- en: chengzhizhao.medium.com](https://chengzhizhao.medium.com/is-apache-airflow-due-for-replacement-the-first-impression-of-mage-ai-ade8208fb2a0?source=post_page-----f34ab71b1730--------------------------------)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: chengzhizhao.medium.com](https://chengzhizhao.medium.com/is-apache-airflow-due-for-replacement-the-first-impression-of-mage-ai-ade8208fb2a0?source=post_page-----f34ab71b1730--------------------------------)
- en: '**Usage Suggestion**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**ä½¿ç”¨å»ºè®®**'
- en: R becomes the first citizen in Mage. You can write the R blocks and access the
    scheduler metadata smoothly without worrying about how to inject or query the
    backend. Developing in Mage is also interactive. Engineers can rapidly iterate
    on testing while developing; They can visualize the result than having a giant
    DAG to debug.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: R æˆä¸º Mage çš„ä¸»è¦è¯­è¨€ã€‚ä½ å¯ä»¥ç¼–å†™ R å—å¹¶é¡ºåˆ©è®¿é—®è°ƒåº¦ç¨‹åºå…ƒæ•°æ®ï¼Œè€Œæ— éœ€æ‹…å¿ƒå¦‚ä½•æ³¨å…¥æˆ–æŸ¥è¯¢åå°ã€‚åœ¨ Mage ä¸­å¼€å‘ä¹Ÿå…·æœ‰äº’åŠ¨æ€§ã€‚å·¥ç¨‹å¸ˆå¯ä»¥åœ¨å¼€å‘è¿‡ç¨‹ä¸­å¿«é€Ÿè¿­ä»£æµ‹è¯•ï¼›ä»–ä»¬å¯ä»¥å¯è§†åŒ–ç»“æœï¼Œè€Œä¸æ˜¯è°ƒè¯•ä¸€ä¸ªåºå¤§çš„
    DAGã€‚
- en: '**Limitation**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™åˆ¶**'
- en: Mage is a new project founded in 2021 and is in its early stages. A lot of documentation
    needs to improve. Additionally, the number of plugins in Mage isnâ€™t comparable
    to Airflow.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Mage æ˜¯ä¸€ä¸ªæˆç«‹äº 2021 å¹´çš„æ–°é¡¹ç›®ï¼Œç›®å‰ä»å¤„äºæ—©æœŸé˜¶æ®µã€‚å¤§é‡æ–‡æ¡£éœ€è¦æ”¹è¿›ã€‚æ­¤å¤–ï¼ŒMage çš„æ’ä»¶æ•°é‡æ— æ³•ä¸ Airflow ç›¸æ¯”ã€‚
- en: '**Final Thoughts**'
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**æœ€ç»ˆæƒ³æ³•**'
- en: Many data pipeline orchestration options havenâ€™t been uncovered here. For R
    users, better integration with R language for data pipeline orchestration reduces
    the pressure to move initial data analysis to the data pipeline in production.
    I hope the options here can give you better insights into various data pipeline
    orchestration tools for R users.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ²¡æœ‰æ¶µç›–è®¸å¤šæ•°æ®ç®¡é“ç¼–æ’é€‰é¡¹ã€‚å¯¹äº R ç”¨æˆ·æ¥è¯´ï¼Œæ›´å¥½åœ°ä¸ R è¯­è¨€é›†æˆçš„æ•°æ®ç®¡é“ç¼–æ’å¯ä»¥å‡å°‘å°†åˆå§‹æ•°æ®åˆ†æè½¬ç§»åˆ°ç”Ÿäº§æ•°æ®ç®¡é“ä¸­çš„å‹åŠ›ã€‚æˆ‘å¸Œæœ›è¿™é‡Œçš„é€‰é¡¹èƒ½ä¸º
    R ç”¨æˆ·æä¾›å¯¹å„ç§æ•°æ®ç®¡é“ç¼–æ’å·¥å…·çš„æ›´å¥½è§è§£ã€‚
- en: 'I hope this story is helpful to you. This article is **part of a series** of
    my engineering & data science stories that currently consist of the following:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰æ‰€å¸®åŠ©ã€‚è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å…³äºå·¥ç¨‹ä¸æ•°æ®ç§‘å­¦æ•…äº‹çš„**ç³»åˆ—ä¹‹ä¸€**ï¼Œç›®å‰åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
- en: '![Chengzhi Zhao](../Images/51b8d26809e870b4733e4e5b6d982a9f.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![èµµæˆå¿—](../Images/51b8d26809e870b4733e4e5b6d982a9f.png)'
- en: '[Chengzhi Zhao](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[èµµæˆå¿—](https://chengzhizhao.medium.com/?source=post_page-----f34ab71b1730--------------------------------)'
- en: Data Engineering & Data Science Stories
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®å·¥ç¨‹ä¸æ•°æ®ç§‘å­¦æ•…äº‹
- en: '[View list](https://chengzhizhao.medium.com/list/data-engineering-data-science-stories-ddab37f718e7?source=post_page-----f34ab71b1730--------------------------------)53
    stories![](../Images/8b5085966553259eef85cc643e6907fa.png)![](../Images/9dcdca1fc00a5694849b2c6f36f038d4.png)![](../Images/2a6b2af56aa4d87fa1c30407e49c78f7.png)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[æŸ¥çœ‹åˆ—è¡¨](https://chengzhizhao.medium.com/list/data-engineering-data-science-stories-ddab37f718e7?source=post_page-----f34ab71b1730--------------------------------)53
    ä¸ªæ•…äº‹ï¼[](../Images/8b5085966553259eef85cc643e6907fa.png)![](../Images/9dcdca1fc00a5694849b2c6f36f038d4.png)![](../Images/2a6b2af56aa4d87fa1c30407e49c78f7.png)'
- en: You can also [**subscribe to my new articles**](https://chengzhizhao.medium.com/subscribe)
    or become a [**referred Medium member**](https://chengzhizhao.medium.com/membership)who
    gets unlimited access to all the stories on Medium.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ ä¹Ÿå¯ä»¥[**è®¢é˜…æˆ‘çš„æ–°æ–‡ç« **](https://chengzhizhao.medium.com/subscribe)æˆ–æˆä¸º[**æ¨èçš„ Medium
    ä¼šå‘˜**](https://chengzhizhao.medium.com/membership)ï¼Œè·å–å¯¹ Medium ä¸Šæ‰€æœ‰æ•…äº‹çš„æ— é™è®¿é—®æƒé™ã€‚
- en: In case of questions/comments, **do not hesitate to write in the comments**
    of this story or **reach me directly** through [Linkedin](https://www.linkedin.com/in/chengzhizhao/)
    or [Twitter](https://twitter.com/ChengzhiZhao).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ‰é—®é¢˜/æ„è§ï¼Œè¯·**éšæ—¶åœ¨æœ¬æ–‡ä¸‹æ–¹è¯„è®º**æˆ–é€šè¿‡[Linkedin](https://www.linkedin.com/in/chengzhizhao/)æˆ–[Twitter](https://twitter.com/ChengzhiZhao)ä¸æˆ‘ç›´æ¥è”ç³»ã€‚
