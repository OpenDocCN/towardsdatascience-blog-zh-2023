- en: Can Synthetic Data Boost Machine Learning Performance?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合成数据能提升机器学习性能吗？
- en: 原文：[https://towardsdatascience.com/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda](https://towardsdatascience.com/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda](https://towardsdatascience.com/can-synthetic-data-boost-machine-learning-performance-6b4041e75dda)
- en: Investigating the Capability of Synthetic Data to Enhance Model Performance
    on Imbalanced Datasets
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研究合成数据在不平衡数据集上提高模型性能的能力
- en: '[](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)[![John
    Adeojo](../Images/f6460fae462b055d36dce16fefcd142c.png)](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)
    [John Adeojo](https://johnadeojo.medium.com/?source=post_page-----6b4041e75dda--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)
    ·7 min read·Jul 5, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----6b4041e75dda--------------------------------)
    ·阅读时间7分钟·2023年7月5日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/71bd354c415afacf5396ba2c0956b4fc.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71bd354c415afacf5396ba2c0956b4fc.png)'
- en: 'Image by Author: Generated with Midjourney'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供：由Midjourney生成
- en: Background — Imbalanced Datasets
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景——不平衡数据集
- en: 'Imbalanced classification problems frequently occur in commercial machine learning
    use cases. You may encounter them in churn prediction, fraud detection, medical
    diagnosis, or spam detection. In all these scenarios, what we aim to detect belongs
    to the minority class, which can be highly underrepresented in our data. There
    are several approaches proposed for enhancing the performance of models on imbalanced
    datasets:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在商业机器学习应用中，数据不平衡分类问题经常发生。你可能会在客户流失预测、欺诈检测、医疗诊断或垃圾邮件检测中遇到它们。在所有这些情况下，我们要检测的对象都属于少数类，而这些少数类在数据中可能严重不足。为提高模型在不平衡数据集上的表现，提出了几种方法：
- en: '**Undersampling**: Achieve a more balanced training dataset by randomly undersampling
    the majority class.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欠采样**：通过随机欠采样多数类来实现更平衡的训练数据集。'
- en: '**Oversampling**: Obtain a balanced training dataset by randomly oversampling
    the minority class.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过采样**：通过随机过采样少数类来获得平衡的训练数据集。'
- en: '**Weighted Losses**: Assign weights to the loss function in relation to the
    minority class.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加权损失**：根据少数类为损失函数分配权重。'
- en: '**Synthetic Data**: Use generative AI to create high-fidelity synthetic data
    samples of the minority class.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合成数据**：使用生成式AI创建高保真度的少数类合成数据样本。'
- en: In this article I demonstrate how training a model on synthetic data surpasses
    the other approaches in enhancing the performance of the classifier.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我展示了如何通过在合成数据上训练模型来超越其他方法，从而提高分类器的性能。
- en: The Dataset
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: The data is sourced from [Kaggle](https://www.kaggle.com/), consisting of 284,807
    credit card transactions, 492 (0.172%) of which are labelled as fraudulent. The
    data is available for both commercial and non-commercial usage under the Open
    [Data Commons license](https://opendatacommons.org/licenses/dbcl/1-0/).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据来自[Kaggle](https://www.kaggle.com/)，包括284,807笔信用卡交易，其中492笔（0.172%）被标记为欺诈交易。数据可用于商业和非商业用途，采用[开放数据公共许可证](https://opendatacommons.org/licenses/dbcl/1-0/)。
- en: For interested readers, Kaggle offers more detailed information and basic [descriptive
    statistics](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) about the
    data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对感兴趣的读者，Kaggle提供了有关数据的更多详细信息和基本[描述性统计](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)。
- en: 'From this Kaggle dataset, I create two subsets: a training set and a holdout
    set. The training set comprises 80% of the total data, along with synthetically
    generated samples when exploring that approach. The holdout set constitutes 20%
    of the original data, excluding any synthetic samples.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个Kaggle数据集中，我创建了两个子集：一个训练集和一个持出集。训练集包含总数据的80%，以及在探索该方法时生成的合成样本。持出集则包含原始数据的20%，不包括任何合成样本。
- en: '![](../Images/bd244d3062156d0eec2447cd9c9fc53b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd244d3062156d0eec2447cd9c9fc53b.png)'
- en: 'Image by Author: Data splitting process'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：数据拆分过程
- en: The Model
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: I use [Ludwig](https://ludwig.ai/latest/), an open-source, declarative framework
    for building deep learning models due to it’s ease of implementation. Models are
    easily built and trained by declaring them in a yaml file and running a training
    job through Ludwig’s python API. I have written an [article](https://medium.com/towards-data-science/ludwig-a-friendlier-deep-learning-framework-946ee3d3b24)
    previously that details Ludwig for those who are interested.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了[Ludwig](https://ludwig.ai/latest/)，这是一个开源的声明式框架，用于构建深度学习模型，因为它易于实现。通过在yaml文件中声明模型并通过Ludwig的Python
    API运行训练任务，可以轻松构建和训练模型。我之前写过一篇[文章](https://medium.com/towards-data-science/ludwig-a-friendlier-deep-learning-framework-946ee3d3b24)，详细介绍了Ludwig，供感兴趣的读者参考。
- en: For each approach, I use the same baseline model, only adjusting specific parameters
    as necessary. For instance, Ludwig allows for weight and sampling adjustments
    natively — These are simply adjusted in the yaml file. I have provided links to
    the model configuration yaml files for each approach for your exploration.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每种方法，我使用相同的基线模型，仅根据需要调整特定参数。例如，Ludwig原生支持权重和采样调整——这些可以简单地在yaml文件中进行调整。我提供了每种方法的模型配置yaml文件的链接，供您探索。
- en: Baseline Model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/baseline_model.yaml)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基线模型 — [链接](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/baseline_model.yaml)
- en: Weighted losses model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_weighted_loss.yaml)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权损失模型 — [链接](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_weighted_loss.yaml)
- en: Undersampling model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_undersample.yaml)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欠采样模型 — [链接](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_undersample.yaml)
- en: Oversampling model — [link](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_oversample.yaml)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过采样模型 — [链接](https://github.com/john-adeojo/Credit-Card-Fraud-Model-Registry/blob/main/model%20yaml%20files/synthetic_data/model_oversample.yaml)
- en: Synthetic data — Utilises the same model as the baseline as the classes are
    balanced.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合成数据 — 使用与基线相同的模型，因为类别是平衡的。
- en: Generating Synthetic Data
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成合成数据
- en: I utilise Synthetic Data Vault (SDV), an open-source library for generating
    synthetic data samples. With SDV, I generate an additional 284k synthetic fraud
    samples, thereby achieving equal representation of both classes in the training
    dataset.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了合成数据库（SDV），这是一个用于生成合成数据样本的开源库。使用SDV，我生成了额外的284k合成欺诈样本，从而在训练数据集中实现了两个类别的均等表示。
- en: The synthetic samples are generated with variational autoencoders adapted for
    tabular data (TVAE). You can find more details on the theory behind TVAEs in this
    [paper](https://arxiv.org/pdf/1907.00503.pdf).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 合成样本是通过适用于表格数据的变分自编码器（TVAE）生成的。有关TVAE背后的理论，您可以在这篇[论文](https://arxiv.org/pdf/1907.00503.pdf)中找到更多细节。
- en: '[SDV](https://docs.sdv.dev/sdv/) offers diagnostic statistics, giving an indication
    of fit quality. You can manually explore the fit quality by comparing variable
    distributions in the real data versus the generated data as shown in the examples
    below.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[SDV](https://docs.sdv.dev/sdv/)提供了诊断统计数据，显示拟合质量的指示。您可以通过比较真实数据与生成数据中的变量分布，手动探索拟合质量，示例如下。'
- en: '![](../Images/54121d9ed8930d1145cb1c2b16a0531e.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54121d9ed8930d1145cb1c2b16a0531e.png)'
- en: 'Image by Author: Real vs synthetic distribution for variable v1'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：真实与合成的变量v1分布对比
- en: '![](../Images/046f7c574ca531d64ea1b8e845ce76e9.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/046f7c574ca531d64ea1b8e845ce76e9.png)'
- en: 'Image by Author: Real vs synthetic distribution for variable v10'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：真实与合成的变量v10分布对比
- en: '![](../Images/e0aa806a65638bbdd960eba187b4db50.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0aa806a65638bbdd960eba187b4db50.png)'
- en: 'Image by Author: Real vs. synthetic distribution for variable amount'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：真实与合成的变量分布对比
- en: Assessing Performance with Precision Recall Charts
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用精确度召回图表评估性能
- en: We assess the performance of each model by plotting the precision versus recall
    curves of the models against the holdout dataset.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过绘制模型与持出数据集的精确度与召回率曲线来评估每个模型的性能。
- en: Precision-Recall Curve
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确度-召回率曲线
- en: The Precision-Recall curve, a plot of Precision (on the y-axis) against Recall
    (on the x-axis) for varying thresholds, is akin to the [ROC curve](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc#:~:text=An%20ROC%20curve%20(receiver%20operating,False%20Positive%20Rate).
    It serves as a robust diagnostic tool for evaluating model performance in scenarios
    of significant class imbalance, such as our credit card fraud detection use case,
    a prime example.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度-召回率曲线，即将精确度（在 y 轴上）与召回率（在 x 轴上）进行绘制的图，与 [ROC 曲线](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc#:~:text=An%20ROC%20curve%20(receiver%20operating,False%20Positive%20Rate)
    )类似。它作为一种强健的诊断工具，用于评估模型在显著类别不平衡场景中的性能，例如我们的信用卡欺诈检测用例，便是一个典型例子。
- en: The top-right corner of the plot represents the “ideal” point — a false positive
    rate of zero and a true positive rate of one. A skilled model should reach this
    point or come close to it, implying a larger area under the curve (AUC-PR) can
    suggest a superior model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图表的右上角代表“理想”点 —— 假阳性率为零，真正阳性率为一。一个熟练的模型应该能够达到或接近这一点，这意味着曲线下面积（AUC-PR）较大的模型可能更优越。
- en: No Skill Predictor
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无技能预测器
- en: A “no skill” predictor is a naïve model that makes predictions randomly. For
    imbalanced datasets, the no skill line is a horizontal line at a height equivalent
    to the positive class proportion. This is because if the model randomly predicts
    the positive class, precision would be equivalent to the positive instances proportion
    in the dataset.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: “无技能”预测器是一个简单的模型，其预测是随机的。对于不平衡数据集，无技能线是一个高度等于正类比例的水平线。这是因为如果模型随机预测正类，精确度将等于数据集中正实例的比例。
- en: Model Performance — Baseline
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型性能 — 基线
- en: The baseline model is the deep neural network with no sample adjustments, loss
    function adjustments, or augmented training data. Each approach is compared to
    the baseline performance, which serves as a performance bench mark.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 基线模型是没有样本调整、损失函数调整或增强训练数据的深度神经网络。每种方法与基线性能进行比较，基线性能作为性能基准。
- en: '![](../Images/389d22765e6bb2466c6609912444ae32.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/389d22765e6bb2466c6609912444ae32.png)'
- en: 'Image by Author: Precision-recall curve for baseline model'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：基线模型的精确度-召回率曲线
- en: Model Performance — Weighted Losses Approach
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型性能 — 加权损失方法
- en: Weighted loss adjusts the loss function based on the ratio of fraudulent to
    non-fraudulent transactions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 加权损失根据欺诈交易与非欺诈交易的比例调整损失函数。
- en: '![](../Images/ad6118e9e5c3b6e863d4a4710ee78b60.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ad6118e9e5c3b6e863d4a4710ee78b60.png)'
- en: 'Image by Author: Precision-recall curve for loss weighted approach'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：加权损失方法的精确度-召回率曲线
- en: Model Performance — Oversampling Approach
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型性能 — 过采样方法
- en: Oversampling randomly oversamples the fraudulent transactions until there is
    equal representation across the classes in the training dataset.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 过采样随机地过度采样欺诈交易，直到训练数据集中各类别之间的表示均等。
- en: '![](../Images/bc225c1fbad884c19136df4a0516504d.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc225c1fbad884c19136df4a0516504d.png)'
- en: 'Image by Author: Precision-recall curve for oversampling approach'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：过采样方法的精确度-召回率曲线
- en: Model Performance — Undersampling Approach
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型性能 — 欠采样方法
- en: Undersampling randomly undersamples the non-fraudulent transactions until there
    is equal representation across classes in the training dataset.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 欠采样随机地欠采样非欺诈交易，直到训练数据集中各类别之间的表示均等。
- en: '![](../Images/bf43d3a05070ce9ad42512b9c49c2969.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bf43d3a05070ce9ad42512b9c49c2969.png)'
- en: 'Image by Author: Precision-recall curve for undersampling approach'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：欠采样方法的精确度-召回率曲线
- en: Model Performance — Synthetic Data Approach
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型性能 — 人工合成数据方法
- en: Leverage the TVAEs to produce 284k synthetic, fraudulent samples to gain an
    equal representation across classes in the training dataset.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 TVAEs 生成 284k 人工合成的欺诈样本，以在训练数据集中获得各类别的均等表示。
- en: '![](../Images/0b46183b2f1de8ae3ae1ba925d718749.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b46183b2f1de8ae3ae1ba925d718749.png)'
- en: 'Image by Author: Precision-recall curve for synthetic data approach'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：人工合成数据方法的精确度-召回率曲线
- en: Bootstrapping Holdout Dataset
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自助法持出数据集
- en: To obtain a robust view of performance on the holdout set, I created fifty bootstrapped
    holdout sets from the original. Running the models associated with each approach
    across all sets provides a distribution of performance. We can then determine
    whether each approach is statistically significantly different from the baseline
    using the Kolmogorov-Smirnov test.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得对保留集性能的稳健视角，我从原始数据中创建了五十个自举保留集。对每种方法关联的模型在所有集上运行，提供了性能分布。然后，我们可以使用Kolmogorov-Smirnov检验来确定每种方法是否与基线存在统计显著差异。
- en: '**Weighted**: The weighted approach marginally underperformed across recall
    and AUC relative to the baseline. In addition to this, the variance across each
    performance metric appears quite high relative to the other approaches.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**加权**：加权方法在召回率和AUC方面相对于基线表现略逊。除此之外，各性能指标的方差相对于其他方法显得较高。'
- en: '![](../Images/2cbf98db34757c7b0777fb03de7f26d7.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2cbf98db34757c7b0777fb03de7f26d7.png)'
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Weighted Loss, KS stats — AUC 0.420 p-value < 0.000, precision 0.260
    p-value 0.068, Recall 0.520 p-value < 0.000'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型性能指标在50个自举保留样本上的表现。基线与加权损失，KS统计 — AUC 0.420 p值 < 0.000，精度 0.260 p值
    0.068，召回率 0.520 p值 < 0.000
- en: '**Oversampling**: The oversampling approach improves model recall relative
    to baseline, but results in a drastic deterioration of the precision.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**过采样**：过采样方法提高了模型的召回率，但导致精度的急剧恶化。'
- en: '![](../Images/da5bc03287b1607c6f2a95ae98c8b772.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da5bc03287b1607c6f2a95ae98c8b772.png)'
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Oversampling, KS stats — AUC 0.160 p-value 0.549, precision 1.0 p-value
    < 0.000, Recall 0.9 p-value < 0.000'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型性能指标在50个自举保留样本上的表现。基线与过采样，KS统计 — AUC 0.160 p值 0.549，精度 1.0 p值 < 0.000，召回率
    0.9 p值 < 0.000
- en: '**Undersampling**: The approach performs worse than baseline across all metrics.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**欠采样**：该方法在所有指标上表现都不如基线。'
- en: '![](../Images/9d0481f0207a1e82b2260a9f6cd37405.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9d0481f0207a1e82b2260a9f6cd37405.png)'
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Oversampling, KS stats — AUC 0.880 p-value < 0.000, precision 0.6
    p-value < 0.000, Recall 1.0 p-value < 0.000'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型性能指标在50个自举保留样本上的表现。基线与过采样，KS统计 — AUC 0.880 p值 < 0.000，精度 0.6 p值 <
    0.000，召回率 1.0 p值 < 0.000
- en: '**Synthetic**: The synthetic method uplifts model recall, albeit at the cost
    of precision. While the impact on precision remains substantial, the synthetic
    approach provides a more resilient alternative for enhancing model recall with
    less of a detriment to precision when compared to the oversampling approach. The
    robustness of the synthetic approach is further evidenced by the uplift in AUC-PR.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**合成**：合成方法提升了模型的召回率，尽管以牺牲精度为代价。尽管精度的影响仍然显著，但与过采样方法相比，合成方法提供了更具韧性的替代方案，能够在不显著影响精度的情况下提升模型召回率。合成方法的稳健性在AUC-PR的提升中得到了进一步证明。'
- en: '![](../Images/aa624f4f7cd1058e4bd764e3c2e7b950.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aa624f4f7cd1058e4bd764e3c2e7b950.png)'
- en: 'Image by Author: Model performance metrics over 50 bootstrapped holdout samples.
    Baseline vs Synthetic, KS stats — AUC 0.620, Precision 0.560, Recall 0.360 all
    p-values ≤ 0.003'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像：模型性能指标在50个自举保留样本上的表现。基线与合成，KS统计 — AUC 0.620，精度 0.560，召回率 0.360 所有p值
    ≤ 0.003
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We’ve noted that the synthetic data approach can boost model recall relative
    to the baseline at the expense of precision. Oversampling accomplishes a similar
    result, but model precision suffers drastically in comparison.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到，相对于基线，合成数据方法可以提升模型的召回率，但以牺牲精度为代价。过采样也能实现类似的结果，但模型精度相比之下急剧下降。
- en: In our specific context of credit card fraud detection, false positives are
    not as costly as false negatives. Therefore, we can afford to compromise on model
    precision if it results in a significant boost in recall. Enriching our training
    data with synthetic instances seems to be an effective strategy to enhance recall
    while mitigating the detrimental effects on precision. This enhancement could
    notably affect profitability, especially when scaling the model to handle millions
    of transactions. Ultimately, attributing a exact cost to false positives and negatives
    will provide us with a clearer understanding of the most commercially viable approach,
    a topic beyond the scope of this article.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们特定的信用卡欺诈检测背景下，假阳性不像假阴性那样昂贵。因此，如果提高召回率能够显著提高，我们可以在模型精度上做出一定妥协。通过合成实例丰富我们的训练数据似乎是提高召回率同时减轻精度不良影响的有效策略。这种增强可能会显著影响盈利能力，特别是在将模型扩展到处理数百万笔交易时。最终，将假阳性和假阴性的确切成本进行归因，将使我们更清楚地理解最具商业可行性的方法，这一话题超出了本文的范围。
- en: It would be fascinating to examine the performance across varying sample sizes
    of synthetic data, perhaps in conjunction with weighted losses. Similarly, experimenting
    with diverse oversampling ratios could potentially yield comparable effects to
    what we have observed with the synthetic approach.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 检查不同样本规模的合成数据的表现将非常有趣，也许可以与加权损失结合起来。类似地，尝试不同的过采样比例可能会产生与我们观察到的合成方法类似的效果。
- en: The notebook for this project is available in my [GitHub repo](https://github.com/john-adeojo/synthetic_data_credit_cards/blob/main/notebook/Synthetic%20Data%20Experiment.ipynb)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目的笔记本可以在我的 [GitHub repo](https://github.com/john-adeojo/synthetic_data_credit_cards/blob/main/notebook/Synthetic%20Data%20Experiment.ipynb)
    中找到
- en: '*Follow me on* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*在* [*LinkedIn*](https://www.linkedin.com/in/john-adeojo/) *上关注我*'
- en: '*Subscribe to medium to get more insights from me:*'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*订阅 Medium 以获取更多来自我的见解：*'
- en: '[](https://johnadeojo.medium.com/membership?source=post_page-----6b4041e75dda--------------------------------)
    [## Join Medium with my referral link — John Adeojo'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://johnadeojo.medium.com/membership?source=post_page-----6b4041e75dda--------------------------------)
    [## 使用我的推荐链接加入 Medium — John Adeojo'
- en: I share data science projects, experiences, and expertise to assist you on your
    journey You can sign up to medium via…
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我分享数据科学项目、经验和专业知识，以帮助你在旅程中。你可以通过…
- en: johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----6b4041e75dda--------------------------------)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: johnadeojo.medium.com](https://johnadeojo.medium.com/membership?source=post_page-----6b4041e75dda--------------------------------)
- en: '*Should you be interested in integrating AI or data science into your business
    operations, we invite you to schedule a complimentary initial consultation with
    us:*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你有兴趣将 AI 或数据科学整合到你的业务操作中，我们邀请你预约与我们进行免费的初步咨询：*'
- en: '[](https://www.data-centric-solutions.com/book-online?source=post_page-----6b4041e75dda--------------------------------)
    [## Book Online | Data-Centric Solutions'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://www.data-centric-solutions.com/book-online?source=post_page-----6b4041e75dda--------------------------------)
    [## 在线预约 | 数据驱动解决方案'
- en: Discover our expertise in helping businesses achieve ambitious goals with a
    free consultation. Our data scientists and…
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过免费咨询发现我们在帮助企业实现雄心勃勃目标方面的专业知识。我们的数据科学家和…
- en: www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----6b4041e75dda--------------------------------)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: www.data-centric-solutions.com](https://www.data-centric-solutions.com/book-online?source=post_page-----6b4041e75dda--------------------------------)
