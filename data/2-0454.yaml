- en: Building Owly an AI Comic Video Generator For My Son
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为我儿子打造的 AI 漫画视频生成器
- en: 原文：[https://towardsdatascience.com/building-owly-an-ai-comic-story-generator-for-my-son-c99fb695d83b](https://towardsdatascience.com/building-owly-an-ai-comic-story-generator-for-my-son-c99fb695d83b)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/building-owly-an-ai-comic-story-generator-for-my-son-c99fb695d83b](https://towardsdatascience.com/building-owly-an-ai-comic-story-generator-for-my-son-c99fb695d83b)
- en: Utilising the fine-tuned Stable Diffusion 2.1 on Amazon SageMaker JumpStart,
    I developed an AI tech called Owly that crafts personalised comic videos with
    music, starring my son’s toys as the lead characters
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用在 Amazon SageMaker JumpStart 上精细调整的 Stable Diffusion 2.1，我开发了一种名为 Owly 的 AI
    技术，能够制作带有音乐的个性化漫画视频，以我儿子的玩具作为主角。
- en: '[](https://agustinus-nalwan.medium.com/?source=post_page-----c99fb695d83b--------------------------------)[![Agustinus
    Nalwan](../Images/7c5ade9ab8bca1d27a317b5c09d1b734.png)](https://agustinus-nalwan.medium.com/?source=post_page-----c99fb695d83b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c99fb695d83b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c99fb695d83b--------------------------------)
    [Agustinus Nalwan](https://agustinus-nalwan.medium.com/?source=post_page-----c99fb695d83b--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://agustinus-nalwan.medium.com/?source=post_page-----c99fb695d83b--------------------------------)[![Agustinus
    Nalwan](../Images/7c5ade9ab8bca1d27a317b5c09d1b734.png)](https://agustinus-nalwan.medium.com/?source=post_page-----c99fb695d83b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c99fb695d83b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c99fb695d83b--------------------------------)
    [Agustinus Nalwan](https://agustinus-nalwan.medium.com/?source=post_page-----c99fb695d83b--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c99fb695d83b--------------------------------)
    ·24 min read·Apr 11, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c99fb695d83b--------------------------------)
    ·24 分钟阅读·2023年4月11日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/e337e899f2f9184b93e905364049f799.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e337e899f2f9184b93e905364049f799.png)'
- en: Owly the AI Comic Story Teller [AI Generated Image]
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Owly AI 漫画故事讲述者 [AI 生成图像]
- en: Every evening, it has become a cherished routine to share bedtime stories with
    my 4-year-old son Dexie, who absolutely adores them. His collection of books is
    impressive, but he’s especially captivated when I create tales from scratch. Crafting
    stories this way also allows me to incorporate moral values I want him to learn,
    which can be difficult to find in store-bought books. Over time, I’ve honed my
    skills in crafting personalised narratives that ignite his imagination — from
    dragons with fractured walls to a lonely sky lantern seeking companionship. Lately,
    I’ve been spinning yarns about fictional superheroes like Slow-Mo Man and Fart-Man,
    which have become his favourites.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每天晚上，与我4岁的儿子 Dexie 分享睡前故事已经成为一种珍贵的例行公事，他非常喜欢这些故事。他的书籍收藏相当丰富，但他特别着迷于我从零开始编写的故事。以这种方式创作故事也让我能够融入我希望他学习的道德价值观，这些在商店购买的书籍中可能很难找到。随着时间的推移，我磨练了编写个性化叙事的技巧，点燃了他的想象力——从有裂缝的龙到寻找陪伴的孤独天灯。最近，我编造了像
    Slow-Mo Man 和 Fart-Man 这样的虚构超级英雄故事，这些故事已经成为他的最爱。
- en: While it’s been a delightful journey for me, after half a year of nightly storytelling,
    my creative reservoir is being tested. To keep him engaged with fresh and exciting
    stories without exhausting myself, I need a more sustainable solution — an AI
    technology that can generate captivating tales automatically! I named her Owly,
    after his favourite bird, an owl.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这段时间对我来说充满了乐趣，但在经过半年的每晚讲故事后，我的创意储备正在经受考验。为了让他持续获得新鲜而有趣的故事而不使自己精疲力竭，我需要一个更可持续的解决方案——一种能够自动生成引人入胜的故事的AI技术！我给她起了个名字叫
    Owly，以他最喜欢的鸟类——猫头鹰来命名。
- en: Pookie and the secret door to a magic forest — Generated by AI Comic Generator.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Pookie 和通往魔法森林的秘密门——由 AI 漫画生成器生成。
- en: Concept
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念
- en: As I started assembling my wish list, it quickly ballooned, driven by my eagerness
    to test the frontiers of modern technology. No ordinary text-based story would
    do — I envisioned an AI crafting a full-blown comic with up to 10 panels. To amp
    up the excitement for Dexie, I aimed to customise the comic using characters he
    knew and loved, like Zelda and Mario, and maybe even toss in his toys for good
    measure. Frankly, the personalisation angle emerged from a need for visual consistency
    across the comic strips, which I will dive into later. But hold your horses, that’s
    not all — I also wanted the AI to narrate the story aloud, backed by a fitting
    soundtrack to set the mood. Tackling this project would be equal parts amusing
    and challenging for me, while Dexie would be treated to a tailor-made, interactive
    storytelling extravaganza.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始组装我的愿望清单时，它很快膨胀起来，这种膨胀源于我对测试现代技术前沿的渴望。普通的文本故事是不够的——我设想了一个 AI 制作一个完整的漫画，最多可有
    10 个面板。为了增加 Dexie 的兴奋感，我计划使用他熟悉和喜爱的角色，如 Zelda 和 Mario，甚至可以加入他的玩具。坦率地说，个性化的角度源于对漫画条纹的视觉一致性的需求，我稍后会深入讨论。但别急，这还不是全部——我还希望
    AI 朗读故事，并配上合适的音乐来营造气氛。完成这个项目对我来说既有趣又具有挑战性，而 Dexie 将会享受到一场量身定制的互动故事盛宴。
- en: '![](../Images/df7699d891b1c4df5249699786443d18.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df7699d891b1c4df5249699786443d18.png)'
- en: Dexie’s toys as comic story’s leading characters [Image by Author]
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Dexie 的玩具作为漫画故事的主要角色 [作者提供的图片]
- en: Brainstorming
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 脑力风暴
- en: 'To conquer the aforementioned requirements, I realised I needed to assemble
    five marvellous modules:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了征服上述要求，我意识到需要组装五个奇妙的模块：
- en: The Story Script Generator, conjuring up a multi-paragraph story where each
    paragraph will be transformed into a comic strip section. Plus, it recommends
    a musical style to pluck a fitting tune from my library. To pull this off, I enlisted
    the mighty OpenAI GPT3.5 Large Language Model (LLM).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 故事脚本生成器，编写多段故事，每段故事将被转换为漫画条纹部分。此外，它会推荐一种音乐风格，以从我的库中挑选合适的曲调。为了实现这一目标，我请来了强大的
    OpenAI GPT3.5 大型语言模型 (LLM)。
- en: The Comic Strip Image Generator, whipping up images for each story segment.
    Stable Diffusion 2.1 teamed up with Amazon SageMaker JumpStart, SageMaker Studio
    and Batch Transform to bring this to life.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 漫画图像生成器，为每个故事片段生成图像。Stable Diffusion 2.1 与 Amazon SageMaker JumpStart、SageMaker
    Studio 和 Batch Transform 联手，将这一切变为现实。
- en: The Text-to-Speech Module, turning the written tale into an audio narration.
    Amazon Polly’s neural engine leaped to the rescue.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本转语音模块，将书面故事转换为音频叙述。Amazon Polly 的神经引擎跃然而出，提供了救援。
- en: The Video Maker, weaving the comic strips, audio narration, and music into a
    self-playing masterpiece. MoviePy was the star of this show.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视频制作器，将漫画条纹、音频叙述和音乐编织成一个自播放的杰作。MoviePy 是这个节目的明星。
- en: And finally, The Controller, orchestrating the grand symphony of all four modules,
    built on the mighty foundation of AWS Batch.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，控制器将这四个模块的宏伟交响曲协调起来，建立在强大的 AWS Batch 基础上。
- en: The game plan? Get the Story Script Generator to weave a 7–10 paragraph narrative,
    with each paragraph morphing into a comic strip section. The Comic Strip Image
    Generator then generates images for each segment, while the Text-to-Speech Module
    crafts the audio narration. A melodious tune will be selected based on the story
    generator’s recommendation. And finally, the Video Maker combines images, audio
    narration, and music to create a whimsical video. Dexie is in for a treat with
    this one-of-a-kind, interactive story-time adventure!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 游戏计划？让故事脚本生成器编织一个 7-10 段的叙述，每段转变为漫画条纹部分。然后，漫画图像生成器为每个片段生成图像，而文本转语音模块则制作音频叙述。根据故事生成器的推荐选择一段悦耳的音乐。最后，视频制作器将图像、音频叙述和音乐结合在一起，创造一个异想天开的视频。Dexie
    将会在这个独一无二的互动故事冒险中获得极大的享受！
- en: Comic Strip Image Generator
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 漫画图像生成器
- en: Before delving into the Story Script Generator, let’s first explore the image
    generator module to provide context for any references to the image generation
    process. There are numerous text-to-image AI models available, but I chose the
    Stable Diffusion 2.1 model for its popularity and ease of building, fine-tuning,
    and deployment using Amazon SageMaker and the broader AWS ecosystem.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨故事脚本生成器之前，让我们首先探索图像生成模块，以便为任何关于图像生成过程的参考提供背景。有许多文本到图像的 AI 模型可供选择，但我选择了
    Stable Diffusion 2.1 模型，因为它在使用 Amazon SageMaker 和更广泛的 AWS 生态系统进行构建、微调和部署方面非常受欢迎且容易。
- en: Amazon SageMaker Studio is an integrated development environment (IDE) that
    offers a unified web-based interface for all machine learning (ML) tasks, streamlining
    data preparation, model building, training, and deployment. This boosts data science
    team productivity by up to 10x. Within SageMaker Studio, users can seamlessly
    upload data, create notebooks, train and tune models, adjust experiments, collaborate
    with their team, and deploy models to production.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker Studio 是一个集成开发环境（IDE），提供了一个统一的基于 Web 的界面，处理所有机器学习（ML）任务，简化数据准备、模型构建、训练和部署。这提高了数据科学团队的生产力，最多可提高
    10 倍。在 SageMaker Studio 中，用户可以无缝上传数据、创建笔记本、训练和调整模型、调整实验、与团队协作，并将模型部署到生产环境中。
- en: Amazon SageMaker JumpStart, a valuable feature within SageMaker Studio, provides
    an extensive collection of widely-used pre-trained AI models. Some models, including
    Stable Diffusion 2.1 base, can be fine-tuned with your own training set and come
    with a sample Jupyter Notebook. This enables you to quickly and efficiently experiment
    with the model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker JumpStart 是 SageMaker Studio 中的一个宝贵功能，提供了大量广泛使用的预训练 AI 模型。一些模型，包括
    Stable Diffusion 2.1 base，可以使用你自己的训练集进行微调，并附带一个示例 Jupyter Notebook。这使得你可以快速高效地对模型进行实验。
- en: '![](../Images/4d446f4bbd308eb24a093ea3e66506d9.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4d446f4bbd308eb24a093ea3e66506d9.png)'
- en: Launching Stable Diffusion 2.1 Notebook on Amazon SageMaker JumpStart [Image
    by Author]
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Amazon SageMaker JumpStart 上启动 Stable Diffusion 2.1 Notebook [图片来源：作者]
- en: I navigated to the Stable Diffusion 2.1 base view model page and launched the
    Jupyter notebook by clicking on the Open Notebook button.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我导航到 Stable Diffusion 2.1 base 视图模型页面，并通过点击 Open Notebook 按钮启动了 Jupyter Notebook。
- en: '![](../Images/f68f92e541642429129259ed5ff0db03.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f68f92e541642429129259ed5ff0db03.png)'
- en: Stable Diffusion 2.1 Base model card [Image by Author]
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 2.1 Base 模型卡 [图片来源：作者]
- en: In a matter of seconds, Amazon SageMaker Studio presented the example notebook,
    complete with all the necessary code to load the text-to-image model from JumpStart,
    deploy the model, and even fine-tune it for personalised image generation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟内，Amazon SageMaker Studio 提供了示例笔记本，其中包含所有必要的代码，用于从 JumpStart 加载文本到图像模型、部署模型，甚至为个性化图像生成进行微调。
- en: '![](../Images/7922b6473c613664816317eaea0948be.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7922b6473c613664816317eaea0948be.png)'
- en: Amazon SageMaker Studio IDE [Image by Author]
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker Studio IDE [图片来源：作者]
- en: Numerous text-to-image models are available, with many tailored to specific
    styles by their creators. Utilising the JumpStart API, I filtered and listed all
    text-to-image models using the filter_value “task == txt2img” and displayed them
    in a dropdown menu for convenient selection.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多文本到图像的模型可用，许多模型由其创建者为特定风格量身定制。利用 JumpStart API，我筛选并列出了所有文本到图像的模型，使用 filter_value
    “task == txt2img” 并在下拉菜单中展示以便于选择。
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The model I required was model-txt2img-stabilityai-stable-diffusion-v2–1-base
    which allow fine-tuning.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要的模型是 model-txt2img-stabilityai-stable-diffusion-v2–1-base，它允许微调。
- en: '![](../Images/a191eade754916822826a83a3a418f1c.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a191eade754916822826a83a3a418f1c.png)'
- en: Huge selection of text-to-image models [Image by Author]
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 大量文本到图像的模型 [图片来源：作者]
- en: In under 5 minutes, utilising the provided code, I deployed the model to a SageMaker
    endpoint running a g4dn.2xlarge GPU instance. I swiftly generated my first image
    from my text prompts, which you can see showcased below.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在不到 5 分钟的时间内，利用提供的代码，我将模型部署到了运行 g4dn.2xlarge GPU 实例的 SageMaker 端点。我迅速从我的文本提示中生成了第一张图片，你可以在下面查看展示效果。
- en: '![](../Images/0ffecd6b0b6b30089fc97a64ec9aeaa5.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ffecd6b0b6b30089fc97a64ec9aeaa5.png)'
- en: My image generator crafts an image of turtle swimming underwater [Image by Author]
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我的图像生成器创建了一张海龟在水下游泳的图像 [图片来源：作者]
- en: The Amazon SageMaker Studio streamlines my experimentation and prototyping process,
    allowing me to swiftly experiment with various image generation prompts and view
    the resulting images directly within the IDE using the file explorer and the preview
    window. Furthermore, I can upload images within the IDE, utilise the built-in
    terminal to launch AWS CLI for uploading and downloading images to and from an
    S3 bucket, and execute SageMaker batch transform jobs against my models to generate
    numerous images at once for a large scale testing.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker Studio 简化了我的实验和原型制作过程，使我能够迅速尝试各种图像生成提示，并通过文件浏览器和预览窗口直接在 IDE
    中查看生成的图像。此外，我可以在 IDE 中上传图像，利用内置终端启动 AWS CLI 将图像上传到 S3 存储桶或从中下载图像，并执行 SageMaker
    批量转换作业以对模型生成大量图像进行大规模测试。
- en: '**Story Script Generator**'
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**故事脚本生成器**'
- en: 'The task of this module is quite straightforward: produce a story script given
    a story topic and a character name. Generating a story on a specific topic with
    GPT3.5 API is incredibly simple.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模块的任务非常简单：根据故事主题和角色名称制作故事脚本。使用 GPT3.5 API 生成关于特定主题的故事非常简单。
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For example, using the prompt “Write me a 1000-word story about Bob the penguin
    who wants to travel to Europe to see famous landmarks. He learns that his bravery
    and curiosity lead him to experience many exciting things.” GPT3.5 will effortlessly
    craft a captivating story on this topic as if it were penned by a professional
    storyteller, much like the example below.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用提示“写一篇关于企鹅 Bob 想要去欧洲看著名地标的 1000 字故事。他发现自己的勇气和好奇心让他体验了许多令人兴奋的事情。” GPT3.5
    会轻松地编写出引人入胜的故事，就像由专业讲故事的人撰写的一样，下面就是一个类似的例子。
- en: Bob the penguin had always dreamed of traveling to Europe and visiting famous
    landmarks. He had heard stories from his friends about the Eiffel Tower in Paris,
    the Colosseum in Rome, and the Big Ben in London. He had grown tired of his routine
    life in Antarctica and yearned for adventure.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 企鹅 Bob 一直梦想着去欧洲旅行，参观著名的地标。他听朋友们讲过巴黎的埃菲尔铁塔、罗马的斗兽场和伦敦的大本钟。他对南极洲的日常生活感到厌倦，渴望冒险。
- en: ''
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: One day, Bob decided to take the plunge and begin planning his trip. He spent
    hours researching the best travel routes and the most affordable accommodations.
    After careful consideration, he decided to start his journey in Paris.
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一天，Bob 决定勇敢地开始规划他的旅行。他花了几个小时研究最佳的旅行路线和最实惠的住宿。经过仔细考虑，他决定从巴黎开始他的旅程。
- en: ''
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The boat ride was long and tiring, but he was excited to finally be in Europe.
    He checked into his hotel and immediately set off to see the Eiffel Tower. As
    he walked through the streets of Paris, he felt a sense of wonder and excitement
    that he had never felt before.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 船程漫长而疲惫，但他对终于到达欧洲感到兴奋。他登记入住酒店后，立即出发去看埃菲尔铁塔。当他走在巴黎的街道上时，他感到前所未有的惊奇和兴奋。
- en: ''
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Over the next few days, he visited famous landmarks like the Louvre Museum,
    Notre Dame Cathedral, and the Palace of Versailles. He tried new foods and met
    new people, each experience adding to his adventure.
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在接下来的几天里，他参观了像卢浮宫、巴黎圣母院和凡尔赛宫这样的著名地标。他尝试了新的食物，结识了新朋友，每一次经历都为他的冒险增添了色彩。
- en: The story itself is fantastic, but to transform it into comic strips, I need
    to divide the story into sections and create an image for each one. The most logical
    approach would be to convert each paragraph into a section. However, as you can
    see, the images generated from those paragraphs present some significant challenges.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 故事本身很棒，但为了将其转化为漫画，我需要将故事分成若干部分，并为每一部分创建一幅图像。最合逻辑的方法是将每个段落转换为一个部分。然而，正如你所见，从这些段落生成的图像呈现出一些重大挑战。
- en: '![](../Images/a794e2ca793257bf93cbc91d361dddd5.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a794e2ca793257bf93cbc91d361dddd5.png)'
- en: Our bob the penguin is portrayed as different characters [AI generated image]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的企鹅 Bob 被描绘成不同角色 [AI 生成的图像]
- en: Character chaos ensued! Each comic strip depicted Bob as an entirely different
    character. In the first strip, he’s a penguin doll; in the second, he’s a person’s
    leg; in the third, a suited-up gentleman; and in the fourth, a man in a blue shirt.
    This happens because only the first paragraph mentions “Bob the penguin,” while
    the second refers to him as just “Bob,” and the rest as “he.” Given this scant
    information, it’s no wonder the image generator portrayed Bob in so many different
    guises.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 角色混乱出现了！每幅漫画中，Bob 都被描绘成完全不同的角色。在第一幅中，他是一个企鹅玩偶；在第二幅中，他是一个人的腿；在第三幅中，他是一个穿着西装的绅士；在第四幅中，他是一个穿蓝衬衫的男人。这种情况发生是因为只有第一段提到了“企鹅
    Bob”，而第二段仅称他为“Bob”，其余段落则用“他”来指代。鉴于这些稀少的信息，难怪图像生成器将 Bob 以多种不同的形象呈现。
- en: The scenes also lacked focus. The first comic strip showed a penguin doll sitting
    on a table instead of an Antarctic-dwelling penguin dreaming of European adventures.
    A similar issue arose in the second comic strip, which showed someone’s leg soaring
    high above a city. It appears the image generator interpreted “One day, Bob decided
    to take the plunge” as skydiving from an airplane, while the paragraph’s focus
    should have been on Bob planning his trip to Europe. Long paragraphs with multiple
    focal points often confuse the image generator, resulting in out-of-context images.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些场景也缺乏焦点。第一幅漫画展示了一个企鹅玩偶坐在桌子上，而不是一个居住在南极的企鹅梦想着欧洲冒险。在第二幅漫画中也出现了类似的问题，展示了某个人的腿高高飞过城市。看来图像生成器将“一天，鲍勃决定冒险”理解成了从飞机跳伞，而该段落的重点应该是鲍勃计划他的欧洲之行。长段落中有多个焦点往往会使图像生成器感到困惑，导致图像脱离上下文。
- en: To tackle the scene’s out-of-focus issue and improve character consistency,
    I refined my prompt to include a request for a concise, one-sentence scene description
    for each paragraph wrapped in [] so they can be programatically extracted. This
    allowed me to provide detailed examples and guide the image generator in creating
    more focused and accurate images.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决场景缺乏焦点的问题并提高角色的一致性，我对提示进行了细化，要求每段包含一个简洁的一句话场景描述，格式为[]，以便可以程序化提取。这使我能够提供详细的示例，并指导图像生成器创建更集中和准确的图像。
- en: For each section please describe the scene in details and always include the
    location in one sentence within [] with the following format [a photo of character
    in the location], [a photo of character in front of an object], [a photo of character
    next to an object], [a photo of a location]
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于每个部分，请详细描述场景，并始终在一段中包含位置的句子，格式为[a photo of character in the location]、[a photo
    of character in front of an object]、[a photo of character next to an object]、[a
    photo of a location]。
- en: With the updated prompt, here’s the resulting story that was generated.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用更新后的提示，这里是生成的故事。
- en: '[a photo of Bob the penguin in Antarctica]'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[鲍勃企鹅在南极的照片]'
- en: Bob the penguin was a happy and curious penguin who lived in the Antarctic.
    He was content with his life there, surrounded by his friends and family. But
    one day, he decided to take the plunge and explore the world beyond the icy continent.
    He had heard stories of the many beautiful and exotic places around the world,
    and he wanted to experience them for himself.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 鲍勃企鹅是一只快乐和好奇的企鹅，生活在南极。他对在那里与朋友和家人一起的生活感到满足。但有一天，他决定冒险，探索冰冷大陆之外的世界。他听说了许多美丽而异国情调的地方，并希望亲自体验。
- en: ''
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[a photo of Bob the penguin reading a book]'
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[鲍勃企鹅在读书的照片]'
- en: Bob the penguin started researching the world, looking at maps and reading up
    on different countries and cultures. He was particularly drawn to Europe, with
    its many famous landmarks and sights. He decided that Europe was the place he
    wanted to visit, so he began to plan his journey.
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 鲍勃企鹅开始研究世界，查看地图并阅读不同国家和文化的信息。他特别被欧洲吸引，那里的许多著名地标和景点让他向往。他决定欧洲是他想要访问的地方，于是开始计划他的旅行。
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[a photo of Bob the penguin on a cruise ship]'
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[鲍勃企鹅在游轮上的照片]'
- en: He started to make the long journey by boat. He was excited and couldn’t wait
    to get there, and he was determined to make it to Europe. After a few weeks of
    travelling, he eventually arrived at his destination.
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他开始了漫长的船程。他感到兴奋，迫不及待地想要到达那里，并且决心去欧洲。在几周的旅行后，他终于到达了目的地。
- en: ''
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[a photo of Bob the penguin at Eiffel Tower]'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[鲍勃企鹅在埃菲尔铁塔的照片]'
- en: Bob the penguin started exploring Europe and was amazed by all the different
    places he visited. He went to the Eiffel Tower in Paris, the Colosseum in Rome,
    and the Cliffs of Moher in Ireland. Everywhere he went he was filled with awe
    and delight.
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 鲍勃企鹅开始探索欧洲，对他访问的各种不同地方感到惊叹。他去了巴黎的埃菲尔铁塔、罗马的斗兽场和爱尔兰的莫赫悬崖。他去的每个地方都让他充满了敬畏和喜悦。
- en: As you can observe, the generated scene descriptions are considerably more focused.
    They mention a single scene, a location, and/or an activity being performed, often
    starting with the character’s name. These concise prompts prove to be much more
    effective for my image generator, as evidenced by the improved images generated
    below.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所观察到的，生成的场景描述要集中得多。它们提到单一场景、位置和/或正在进行的活动，通常以角色的名字开头。这些简洁的提示对于我的图像生成器效果显著，如下所示的改进图像就是证明。
- en: '![](../Images/f68791a0532c23e24307fe61b207cef9.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f68791a0532c23e24307fe61b207cef9.png)'
- en: A more consistent look of our Bob the penguin [AI generated image]
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 Bob 企鹅的更一致外观 [AI 生成的图像]
- en: Bob the penguin has made a triumphant return, but he’s still sporting a new
    look in each comic strip. Since the image generation process treats each image
    separately, and no information is provided about Bob’s colour, size, or type of
    penguin, consistency remains elusive.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Bob 企鹅已成功回归，但他在每个漫画条幅中依然呈现出全新的形象。由于图像生成过程将每张图像视为独立的，而且没有提供有关 Bob 的颜色、大小或企鹅类型的信息，因此一致性仍然难以实现。
- en: 'I previously considered generating a detailed character description as part
    of the story generation to maintain character consistency across images. However,
    this approach proved to be impractical for two reasons:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前考虑过将详细的角色描述作为故事生成的一部分，以保持图像中的角色一致性。然而，这种方法由于两个原因被证明是不切实际的：
- en: Sometimes it’s nearly impossible to describe a character with enough detail
    without resorting to an overwhelming amount of text. While there may not be many
    types of penguins, consider birds in general — with countless shapes, colours,
    and species such as cockatoos, parrots, canaries, pelicans, and owls, the task
    becomes daunting.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时，很难在不 resorting 到大量文本的情况下详细描述一个角色。虽然企鹅的种类可能不多，但考虑到鸟类的一般情况——有着无数形状、颜色和品种如葵花鹦鹉、鹦鹉、金丝雀、鹈鹕和猫头鹰，这项任务变得令人生畏。
- en: The character generated doesn’t always adhere to the provided description within
    the prompt. For example, a prompt describing a green parrot with a red beak might
    result in an image of a green parrot with a yellow beak instead.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的角色不总是符合提示中提供的描述。例如，一个描述绿色鹦鹉带红色喙的提示可能会生成一只绿色鹦鹉带黄色喙的图像。
- en: So, despite our best efforts, our penguin pal Bob continues to experience something
    of an identity crisis.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，尽管我们尽了最大努力，我们的企鹅朋友 Bob 仍然经历着某种身份危机。
- en: Adding Personalisation to the Image Generator
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为图像生成器添加个性化
- en: The solution to our penguin predicament lies in giving the Stable Diffusion
    model a visual cue of what our penguin character should look like to influence
    the image generation process and to maintain consistency across all generated
    images. In the world of Stable Diffusion, this process is known as fine-tuning,
    where you supply a handful (usually 5 to 15) of images containing the same object
    and a sentence describing it. These images shall henceforth be known as training
    images.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决企鹅困境的方法在于为 Stable Diffusion 模型提供一个关于我们企鹅角色应有外观的视觉提示，以影响图像生成过程并保持生成图像的一致性。在
    Stable Diffusion 的世界中，这一过程被称为微调，你需要提供一些（通常是 5 到 15 张）包含相同对象的图像以及描述它的句子。这些图像将被称为训练图像。
- en: As it turns out, this added personalisation is not just a solution but also
    a mighty cool feature for my comic generator. Now, I can use many of Dexie’s toys
    as the main characters in the stories, such as his festive Christmas penguin,
    breathing new life into Bob the penguin, making them even more personalised and
    relatable for my young but tough audience. So, the quest for consistency turns
    into a triumph for tailor-made tales!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，这种个性化不仅仅是解决方案，还是我漫画生成器的一个非常酷的功能。现在，我可以将 Dexie 的许多玩具作为故事中的主要角色，例如他节日的圣诞企鹅，为
    Bob 企鹅注入新生命，使其对我年轻但坚韧的观众更加个性化和易于关联。因此，一致性的追求变成了为定制故事的胜利！
- en: '![](../Images/260183bbcad7490bf76ee61a63799b66.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/260183bbcad7490bf76ee61a63799b66.png)'
- en: Dexie’s toy is now Bob the penguin [Image by Author]
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Dexie 的玩具现在是 Bob 企鹅 [作者提供的图像]
- en: 'During my exhilarating days of experimentation, I’ve discovered a few nuggets
    of wisdom to share for achieving the best results when fine-tuning the model to
    reduce the chance of overfitting:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在我令人兴奋的实验日子里，我发现了一些智慧的结晶可以分享，以在微调模型时实现最佳结果，减少过拟合的可能性：
- en: Keep the backgrounds in your training images diverse. This way, the model won’t
    confuse the backdrop with the object, preventing unwanted background cameos in
    the generated images
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持训练图像中的背景多样化。这样，模型就不会将背景与对象混淆，防止在生成图像中出现不必要的背景配角。
- en: Capture the target object from various angles. This helps provide more visual
    information, enabling the model to generate the object with a greater range of
    angles, thus better matching the scene.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从不同角度捕捉目标对象。这有助于提供更多视觉信息，使模型能够生成具有更大角度范围的对象，从而更好地匹配场景。
- en: Mix close-ups with full-body shots. This ensures the model doesn’t assume a
    specific pose is necessary, granting more flexibility for the generated object
    to harmonise with the scene.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合特写镜头和全身镜头。这确保了模型不会假设特定姿势是必要的，从而为生成的对象与场景的和谐提供了更多灵活性。
- en: To perform the Stable Diffusion model fine-tuning, I launched a SageMaker Estimator
    training job with Amazon SageMaker Python SDK on an ml.g5.2xlarge GPU instance
    and directed the training process to my collection of training images in an S3
    bucket. A resulting fine-tuned model file will then be saved in s3_output_location.
    And, with just a few lines of code, the magic began to unfold!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行稳定扩散模型的精细调整，我启动了一个 SageMaker Estimator 训练作业，使用 Amazon SageMaker Python SDK
    在 ml.g5.2xlarge GPU 实例上，并将训练过程定向到 S3 桶中的训练图像集合。生成的精细调整模型文件将保存在 s3_output_location
    中。仅需几行代码，魔力便开始显现！
- en: '[PRE2]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To prepare the training set, ensure it contains the following files:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为准备训练集，确保它包含以下文件：
- en: A series of images named instance_image_x.jpg, where x is a number from 1 to
    N. In this case, N represents the number of images, ideally more than 10.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一系列名为 instance_image_x.jpg 的图像，其中 x 是从 1 到 N 的数字。在这种情况下，N 代表图像的数量，理想情况下应大于 10。
- en: A dataset_info.json file that includes a mandatory field called instance_prompt.
    This field should provide a detailed description of the object, with a unique
    identifier preceding the object’s name. For example, “a photo of Bob the penguin,”
    where ‘Bob’ acts as the unique identifier. By using this identifier, you can direct
    your fine-tuned model to generate either a standard penguin (referred to as “penguin”)
    or the penguin from your training set (referred to as “Bob the penguin”). Some
    sources suggest using unique names such as sks or xyz, but I discovered that it’s
    not essential to do so.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 dataset_info.json 文件，其中包含一个必需字段，称为 instance_prompt。该字段应提供对象的详细描述，并在对象名称前加上唯一标识符。例如，“Bob
    企鹅的照片”，其中‘Bob’充当唯一标识符。通过使用该标识符，你可以引导精细调整后的模型生成标准企鹅（称为“企鹅”）或来自训练集中的企鹅（称为“Bob 企鹅”）。一些来源建议使用像
    sks 或 xyz 这样的唯一名称，但我发现这样做并非必要。
- en: The dataset_info.json file can also include an optional field called class_prompt,
    which offers a general description of the object without the unique identifier
    (e.g., “a photo of a penguin”). This field is utilised only when the prior_preservation
    parameter is set to True; otherwise, it will be disregarded. I will discuss more
    about it at the advanced fine-tuning section below.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: dataset_info.json 文件还可以包含一个可选字段，称为 class_prompt，它提供对象的一般描述，而没有唯一标识符（例如，“一只企鹅的照片”）。此字段仅在
    prior_preservation 参数设置为 True 时使用；否则，将被忽略。我将在下面的高级精细调整部分进一步讨论。
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After a few test runs with Dexie’s toys, the image generator delivered some
    truly impressive results. It brought Dexie’s kangaroo magnetic block creation
    to life, hopping its way into the virtual world. The generator also masterfully
    depicted his beloved shower turtle toy swimming underwater, surrounded by a vibrant
    school of fish. The image generator certainly captured the magic of Dexie’s playtime
    favourites!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几次使用 Dexie 的玩具进行测试后，图像生成器产生了一些真正令人印象深刻的结果。它将 Dexie 的袋鼠磁性积木创作栩栩如生地呈现出来，使其跃入虚拟世界。生成器还巧妙地描绘了他心爱的淋浴乌龟玩具在水下游泳的场景，周围环绕着色彩斑斓的鱼群。图像生成器确实捕捉到了
    Dexie 玩耍时最喜欢的魔力！
- en: '![](../Images/4595906178a31df2bd32e1b36bf7deb1.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4595906178a31df2bd32e1b36bf7deb1.png)'
- en: Dexie’s toys are brought to life [AI generated image]
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Dexie 的玩具栩栩如生 [AI 生成的图像]
- en: '**Batch Transform against fine-tuned Stable Diffusion model**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**针对精细调整的稳定扩散模型进行批量转换**'
- en: Since I needed to generate over a hundred images for each comic strip, deploying
    a SageMaker endpoint (think of it as a Rest API) and generating one image at a
    time wasn’t the most efficient approach. Instead, I opted to run a batch transform
    against my model, supplying it with text files in an S3 bucket containing the
    prompts to generate the images.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我需要为每个漫画条生成一百多张图像，因此部署 SageMaker 端点（可以将其视为 Rest API）并一次生成一张图像并不是最有效的方法。因此，我选择对我的模型进行批量转换，向其提供包含生成图像提示的
    S3 桶中的文本文件。
- en: 'I’ll provide more details about this process since I initially struggled with
    it, and I hope my explanation will save you some time. You’ll need to prepare
    one text file per image prompt with the following JSON content: {“prompt”: “a
    photo of Bob the penguin in Antarctica”}. While it appears that there’s a way
    to combine multiple inputs into one file using the MultiRecord strategy, I was
    unable to figure out how it works.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '我会提供更多关于这个过程的细节，因为我最初对它感到困惑，我希望我的解释能为你节省一些时间。你需要为每个图像提示准备一个文本文件，文件中包含以下 JSON
    内容：{“prompt”: “a photo of Bob the penguin in Antarctica”}。虽然似乎有一种方法可以使用 MultiRecord
    策略将多个输入合并到一个文件中，但我未能弄清楚它的工作原理。'
- en: Another challenge I encountered was executing a batch transform against my fine-tuned
    model. You can’t execute a batch transform using a transformer object returned
    by Estimator.transformer(), which usually works in my previous projects. Instead,
    you need to first create a SageMaker model object by specifying the S3 location
    of your fine-tuned model as the model_data. From there, you can create the transformer
    object using this model object.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我遇到的另一个挑战是对我的微调模型执行批量转换。你不能使用 `Estimator.transformer()` 返回的转换器对象执行批量转换，这通常在我之前的项目中有效。相反，你需要先创建一个
    SageMaker 模型对象，将微调模型的 S3 位置指定为 `model_data`。之后，你可以使用这个模型对象创建转换器对象。
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: And with that, my customised image generator is all ready!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，我的定制图像生成器已经准备好了！
- en: '**Advanced Stable Diffusion model fine-tuning**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**高级 Stable Diffusion 模型微调**'
- en: While it’s not essential for my comic generator project, I’d like to touch on
    some advanced fine-tuning techniques involving the manipulation of max_steps,
    prior_reservation, and train_text_encoder hyper parameters, in case they come
    in handy for your projects.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这对我的漫画生成器项目并非必需，但我想提到一些涉及 `max_steps`、`prior_reservation` 和 `train_text_encoder`
    超参数的高级微调技术，以防它们对你的项目有用。
- en: Stable Diffusion model fine-tuning is highly susceptible to overfitting due
    to the vast difference between the number of training images you provide and those
    used in the base model. For example, you might only supply 10 images of Bob the
    penguin, while the base model’s training set contains thousands of penguin images.
    A larger number of images reduces the likelihood of overfitting and erroneous
    associations between the target object and other elements.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 模型的微调由于你提供的训练图像数量与基础模型使用的图像数量之间的巨大差异，非常容易过拟合。例如，你可能只提供了 10
    张 Bob the penguin 的图像，而基础模型的训练集包含了数千张企鹅图像。图像数量更多会降低过拟合的可能性，并减少目标对象与其他元素之间的错误关联。
- en: When setting prior_reservation to True, Stable Diffusion generates a default
    of x (typically 100) images using the class_prompt provided, and combines them
    with your instance_images during fine-tuning. Alternatively, you can manually
    supply these images by placing them in the class_data_dir subfolder. In my experience,
    prior_preservation is often crucial when fine-tuning Stable Diffusion for human
    faces. When employing prior_reservation, ensure you provide a class_prompt that
    mentions the most suitable generic name or common object resembling your character.
    For Bob the penguin, this object is clearly a penguin, so your class prompt would
    be “a photo of a penguin”. This technique can also be used to generate a blend
    between two characters, which I will discuss later.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当将 `prior_reservation` 设置为 `True` 时，Stable Diffusion 使用提供的 `class_prompt` 生成默认数量的
    x 张图像（通常为 100），并在微调过程中将这些图像与 `instance_images` 结合起来。或者，你可以通过将这些图像放置在 `class_data_dir`
    子文件夹中来手动提供这些图像。根据我的经验，`prior_preservation` 在对 Stable Diffusion 进行微调以生成真人面孔时通常至关重要。当使用
    `prior_reservation` 时，确保提供一个提到最合适的通用名称或与角色相似的常见对象的 `class_prompt`。对于 Bob the penguin，这个对象显然是一只企鹅，所以你的类提示应该是
    “a photo of a penguin”。这种技术也可以用来生成两个角色之间的混合体，稍后我会讨论。
- en: Another helpful parameter for advanced fine-tuning is train_text_encoder. Set
    it to True to enable text encoder training during the fine-tuning process. The
    resulting model will better understand more complex prompts and generate human
    faces with greater accuracy.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个对高级微调有帮助的参数是 `train_text_encoder`。将其设置为 `True` 以启用在微调过程中对文本编码器的训练。结果模型将更好地理解更复杂的提示，并更准确地生成真人面孔。
- en: Depending on your specific use case, different hyper parameter values may yield
    better results. Additionally, you’ll need to adjust the max_steps parameter to
    control the number of fine-tuning steps required. Keep in mind that a larger training
    set might lead to overfitting.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你具体的使用案例，不同的超参数值可能会产生更好的结果。此外，你需要调整 max_steps 参数来控制所需的微调步骤数。请记住，较大的训练集可能会导致过拟合。
- en: Text to Speech and Video Generation
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本转语音和视频生成
- en: By utilising Amazon Polly’s Neural Text To Speech (NTTS) feature, I was able
    to create audio narration for each paragraph of the story. The quality of the
    audio narration is exceptional, as it sounds incredibly natural and human-like,
    making it an ideal story-teller.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用 Amazon Polly 的神经文本转语音（NTTS）功能，我能够为故事的每个段落创建音频叙述。音频叙述的质量非常出色，因为它听起来非常自然和像人类发声，使其成为理想的讲故事者。
- en: To accommodate a younger audience, such as Dexie, I employed the SSML format
    and utilised the <prosody rate> tag to reduce the speaking speed to 90% of its
    normal rate, ensuring the content would not be delivered too quickly for them
    to follow.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为了适应年轻观众，如 Dexie，我采用了 SSML 格式，并利用了 <prosody rate> 标签将说话速度降低到正常速度的 90%，确保内容不会传递得太快，以便他们能够跟上。
- en: '[PRE5]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After all the hard work, I used MoviePy — a fantastic Python framework — to
    magically turn all the photos, audio narration, and music into an awesome mp4
    video. Speaking of music, I gave my tech the power to choose the perfect soundtrack
    to match the video’s vibe. How, you ask? Well, I just modified my story script
    generator to return a music style from a pre-determined list using some clever
    prompts. How cool is that?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有辛勤工作之后，我使用了 MoviePy —— 一个非常棒的 Python 框架 —— 神奇地将所有照片、音频叙述和音乐转变成一个令人惊叹的 mp4
    视频。说到音乐，我让我的技术选择完美的配乐来匹配视频的氛围。怎么做的呢？好吧，我只是修改了我的故事脚本生成器，使用一些巧妙的提示从预定列表中返回一种音乐风格。这有多酷？
- en: At the start of the story please suggest song style from the following list
    only which matches the story and put it within <>. Song style list are action,
    calm, dramatic, epic, happy and touching.
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在故事开始时，请从以下列表中建议匹配故事的歌曲风格，并用<>标出。歌曲风格列表包括 action、calm、dramatic、epic、happy 和
    touching。
- en: Once the music style is selected, the next step is to randomly pick an MP3 track
    from the relevant folder, which contains a handful of MP3 files. This helps to
    add a touch of unpredictability and excitement to the final product.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选择了音乐风格，下一步是从相关文件夹中随机挑选一个 MP3 曲目，该文件夹包含了一些 MP3 文件。这有助于为最终产品增添一点不可预测性和兴奋感。
- en: Controller Module
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制模块
- en: To orchestrate the entire system, I needed a controller module in the form of
    a Python script that could run each module seamlessly. But, of course, I needed
    a compute environment to execute this script. I had two options to explore — the
    first being my preferred option — a server-less architecture with AWS Lambda.
    This involved using several AWS Lambdas, paired with SQS. The first lambda is
    used as public API using API Gateway as an entry point. This API would take in
    the training image URLs and story topic text and pre-process the data, dropping
    it into an SQS queue. Another Lambda would pick up the data from the topic and
    conduct data preparation — think image resizing, creating dataset_info.json, and
    triggering the next Lambda to call Amazon SageMaker Jumpstart to prepare the Stable
    Diffusion model and execute SageMaker training job to fine-tune the model. Phew,
    that’s a mouthful. Finally, Amazon EventBridge would be used as an event bus to
    detect the completion of the training job and trigger the next Lambda to execute
    SageMaker Batch Transform using the fine-tuned model to generate images.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 为了协调整个系统，我需要一个以 Python 脚本形式存在的控制模块，它能够无缝地运行每个模块。当然，我还需要一个计算环境来执行这个脚本。我有两个选择
    — 第一个是我偏好的选择 — 使用 AWS Lambda 的无服务器架构。这涉及使用多个 AWS Lambda，配合 SQS。第一个 Lambda 作为公共
    API，使用 API Gateway 作为入口点。这个 API 会接收训练图像的 URL 和故事主题文本，并对数据进行预处理，将其放入 SQS 队列中。另一个
    Lambda 会从主题中提取数据并进行数据准备 —— 比如图像调整大小、创建 dataset_info.json，并触发下一个 Lambda 调用 Amazon
    SageMaker Jumpstart 来准备 Stable Diffusion 模型，并执行 SageMaker 训练作业以微调模型。唷，这真是一口气说完。最后，Amazon
    EventBridge 将作为事件总线，用于检测训练作业的完成，并触发下一个 Lambda 使用微调后的模型执行 SageMaker Batch Transform
    生成图像。
- en: But alas, this option was not possible because the AWS Lambda function had a
    max storage limit of 10GB. And when executing the batch transform against the
    SageMaker model, the SageMaker Python SDK would download and extract the model.tar.gzip
    file temporarily in the local /tmp before sending it to the managed system that
    ran the batch transform. Unfortunately, my model was a whopping 5GB compressed,
    so the SageMaker Python SDK threw an error saying “Out of disk space.” For most
    use cases where the model size is smaller, this will the best and cleanest solution.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个选项不可行，因为 AWS Lambda 函数的最大存储限制为 10GB。在对 SageMaker 模型执行批处理转换时，SageMaker Python
    SDK 会在本地 /tmp 临时下载并提取 model.tar.gzip 文件，然后将其发送到运行批处理转换的管理系统。不幸的是，我的模型压缩后为 5GB，因此
    SageMaker Python SDK 抛出一个错误，说“磁盘空间不足。”对于大多数模型尺寸较小的使用场景，这将是最佳和最清洁的解决方案。
- en: So, I had to resort to my second option — AWS Batch. It worked well, but it
    did cost a bit more since the AWS Batch compute instance had to run throughout
    the entire process —even during fine-tuning the model, and executing the batch
    transform which were executed in a separate compute environment within SageMaker.
    I could have split the process into several AWS Batch instances and glued them
    together with Amazon EventBridge and SQS, just like I would have done previously
    using the server-less approach. But with AWS Batch’s longer startup time (around
    5 mins), it would have added way too much latency to the overall process. So,
    I went with the all-in-one AWS Batch option instead.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我不得不选择第二个选项——AWS Batch。它运行良好，但成本稍高，因为 AWS Batch 计算实例必须在整个过程中运行——即使在对模型进行微调和执行批处理转换时，这些操作都是在
    SageMaker 内的独立计算环境中执行的。我本可以将过程拆分为多个 AWS Batch 实例，并通过 Amazon EventBridge 和 SQS
    将它们连接起来，就像我之前使用无服务器方法一样。但由于 AWS Batch 启动时间较长（约 5 分钟），这会给整体过程增加过多的延迟。因此，我选择了集成的
    AWS Batch 选项。
- en: '![](../Images/53df06845e734287275aa29ada8b07b1.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53df06845e734287275aa29ada8b07b1.png)'
- en: Owly system architecture
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Owly 系统架构
- en: Feast your eyes upon Owly’s majestic architecture diagram! Our adventure kicks
    off by launching AWS Batch through the AWS Console, equipping it with an S3 folder
    brimming with training images, a captivating story topic, and a delightful character,
    all supplied via AWS Batch environment variables.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 欣赏 Owly 壮丽的架构图吧！我们的冒险从通过 AWS 控制台启动 AWS Batch 开始，为其配备充满训练图像的 S3 文件夹、一个引人入胜的故事主题和一个令人愉快的角色，这些都通过
    AWS Batch 环境变量提供。
- en: '[PRE6]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The AWS Batch springs into action, retrieving the training images from the S3
    folder specified by JOB_ID, resizing them to a 768x768, and creating a dataset_info.json
    file before placing them in a staging S3 bucket.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Batch 立即启动，从 JOB_ID 指定的 S3 文件夹中检索训练图像，将其调整为 768x768，并在将其放入暂存 S3 桶之前创建 dataset_info.json
    文件。
- en: Next up, we call up the OpenAI GPT3.5 model API to whip up an engaging story
    and a complementary song style in harmony with the chosen topic and character.
    We then summon Amazon SageMaker JumpStart to unleash the powerful Stable Diffusion
    2.1 base model. With the model at our disposal, we initiate a SageMaker training
    job to fine-tune it to our carefully selected training images. After a brief 30-minute
    interlude, we forge image prompts for each story paragraph in the guise of text
    files, which are then dropped into an S3 bucket as input for the image generation
    extravaganza. Amazon SageMaker Batch Transform is unleashed on the fine-tuned
    model to produce these images in a batch, a process that lasts a mere 5 minutes.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们调用 OpenAI GPT3.5 模型 API 来编写一个引人入胜的故事，并与所选主题和角色相协调的补充歌曲风格。然后我们召唤 Amazon
    SageMaker JumpStart 来释放强大的 Stable Diffusion 2.1 基础模型。使用该模型，我们启动 SageMaker 训练作业，对其进行微调以适应我们精心挑选的训练图像。经过短短
    30 分钟的间歇后，我们为每个故事段落制作图像提示，以文本文件的形式，然后将其放入 S3 桶中，作为图像生成盛宴的输入。Amazon SageMaker Batch
    Transform 被用来在短短 5 分钟内批量生成这些图像。
- en: Once complete, we enlist the help of Amazon Polly to craft audio narrations
    for each paragraph in the story, saving them as mp3 files in just 30 seconds.
    We then randomly pick an mp3 music file from libraries sorted by song style, based
    on the selection made by our masterful story generator.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们借助 Amazon Polly 为故事中的每个段落制作音频讲解，仅需 30 秒即可将其保存为 mp3 文件。然后我们从按歌曲风格分类的库中随机挑选一个
    mp3 音乐文件，基于我们巧妙的故事生成器的选择。
- en: The final act sees the resulting images, audio narration mp3s, and music.mp3
    files expertly woven together into a video slideshow with the help of MoviePy.
    Smooth transitions and the Ken Burns effect are added for that extra touch of
    elegance. The pièce de résistance, the finished video, is then hoisted up to the
    output S3 bucket, awaiting your eager download!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的工作将生成的图像、音频讲述mp3文件和音乐.mp3文件巧妙地编织成一个视频幻灯片，借助MoviePy完成。为了增加优雅感，我们添加了平滑的过渡和肯·伯恩斯效果。最后的杰作，完成的视频，随后被上传到输出S3存储桶，等待你的急切下载！
- en: Testing and adding some enhancement
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试并添加一些增强功能
- en: I must say, I’m rather chuffed with the results! The story script generator
    has truly outdone itself, performing far better than anticipated. Almost every
    story script crafted is not only well-written but also brimming with positive
    morals, showcasing the awe-inspiring prowess of Large Language Models (LLM). As
    for image generation, well, it’s a bit of a mixed bag.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须说，我对结果感到相当满意！故事脚本生成器真的是超乎预期地表现出色。几乎每一个制作的故事脚本不仅写得很好，而且充满了积极的道德观，展示了大型语言模型（LLM）的令人惊叹的能力。至于图像生成，嘛，这就有点参差不齐了。
- en: With all the enhancements I’ve described earlier, one in five stories can be
    used in the final video right off the bat. The remaining four, however, usually
    have one or two images plagued by common issues.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我之前描述的所有改进，一五分之一的故事可以直接用于最终视频。其余的四分之一，通常有一到两张图像存在常见问题。
- en: First, we’ve got inconsistent characters, still. Sometimes the model conjures
    up a character that’s slightly different from the original in the training set,
    often opting for a photorealistic version rather than the toy counterpart. But
    fear not! Adding a desired photo style within the text prompt, like “A cartoon-style
    Rex the turtle swimming under the sea,” helps curb this issue. However, it does
    require manual intervention since certain characters may warrant a photorealistic
    style.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们仍然遇到不一致的角色。有时模型会生成一个与训练集中原始角色略有不同的角色，通常选择现实主义版本而不是玩具版本。但不要担心！在文本提示中添加期望的照片风格，如“一个卡通风格的海龟雷克斯在海里游泳”，有助于缓解这个问题。然而，这确实需要人工干预，因为某些角色可能需要现实主义风格。
- en: Then there’s the curious case of missing body parts. Occasionally, our generated
    characters appear with absent limbs or heads. Yikes! To mitigate this, we’ve added
    negative prompts supported by the Stable Diffusion model, such as “missing limbs,
    missing head,” encouraging the generation of images that steer clear of these
    peculiar attributes.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后就是缺失身体部位的奇特情况了。偶尔，我们生成的角色会出现四肢或头部缺失的情况。哎呀！为了解决这个问题，我们在稳定扩散模型中添加了负面提示，比如“缺失四肢，缺失头部”，以鼓励生成避免这些奇特属性的图像。
- en: '![](../Images/23405b7a5b6b62c47bf19fd3a0880da3.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23405b7a5b6b62c47bf19fd3a0880da3.png)'
- en: Rex the turtle in different style (bottom right image is in a photo realistic
    style, top right image is in a mixed style, the rest are in a toy style) and missing
    a head (top left image) [AI generated image]
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 雷克斯海龟的不同风格（右下角的图像为现实主义风格，右上角的图像为混合风格，其余为玩具风格）和缺少头部（左上角的图像）[AI生成的图像]
- en: Bizarre images emerge when dealing with uncommon interactions between objects.
    Generating images of characters in specific locations typically produces satisfactory
    results. However, when it comes to illustrating characters interacting with other
    objects, especially in an uncommon way, the outcome is often less than ideal.
    For instance, attempting to depict Tom the hedgehog milking a cow results in a
    peculiar blend of hedgehog and cow. Meanwhile, crafting an image of Tom the hedgehog
    holding a flower bouquet leads to a person clutching both a hedgehog and a bouquet
    of flowers. Regrettably, I have yet to devise a strategy to remedy this issue,
    leading me to conclude that it’s simply a limitation of current image generation
    technology. If the object or activity in the image you’re trying to generate is
    highly unusual, the model lacks prior knowledge, as none of the training data
    has ever depicted such scenes or activities.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当处理对象之间不常见的互动时，会出现奇异的图像。生成角色在特定位置的图像通常会得到令人满意的结果。然而，当涉及到描绘角色与其他对象互动时，尤其是以不寻常的方式，结果往往不尽如人意。例如，尝试描绘刺猬汤姆挤奶牛时，会产生刺猬与奶牛的奇特混合体。同时，制作汤姆·刺猬拿着花束的图像则会变成一个人同时抓着刺猬和花束。不幸的是，我尚未制定出解决这一问题的策略，这使我得出结论，这是当前图像生成技术的局限。如果你试图生成的图像中的对象或活动非常不寻常，模型缺乏先验知识，因为训练数据中从未出现过这样的场景或活动。
- en: '![](../Images/a53697ea5844f4941eb1f4e660e0a834.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a53697ea5844f4941eb1f4e660e0a834.png)'
- en: Mixed of a hedgehog and a cow (top images)is generated from “Tom the hedgehog
    is milking a cow” prompt. A person holding a hedgehog and a flower (bottom left
    image) is generated from “Tom the hedgehog is holding a flower” [AI generated
    image]
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从“汤姆刺猬在挤奶牛”提示生成的混合体（顶部图像）是刺猬和奶牛的混合。 从“汤姆刺猬拿着花”生成的图像（底部左侧图像）则是一个人同时抱着刺猬和花束 [AI生成的图像]
- en: In the end, to boost the odds of success in story generation, I cleverly tweaked
    my story generator to produce three distinct scenes per paragraph. Moreover, for
    each scene, I instructed my image generator to create five image variations. With
    this approach, I increased the likelihood of obtaining at least one top-notch
    image from the fifteen available. Having three different prompt variations also
    aids in generating entirely unique scenes, especially when one scene proves too
    rare or complex to create. Below is my updated story generation prompt.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，为了提高故事生成的成功率，我巧妙地调整了我的故事生成器，使其每段生成三个不同的场景。此外，对于每个场景，我指示我的图像生成器创建五个图像变体。通过这种方法，我增加了从十五个可用图像中获得至少一个优质图像的可能性。拥有三种不同的提示变体也有助于生成完全独特的场景，尤其是当一个场景过于稀有或复杂以至于无法创建时。以下是我更新后的故事生成提示。
- en: '[PRE7]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The only additional cost is a bit of manual intervention after the image generation
    step is done, where I handpick the best image for each scene and then proceed
    with the comic generation process. This minor inconvenience aside, I now boast
    a remarkable success rate of 9 out of 10 in crafting splendid comics!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的额外成本是在图像生成步骤完成后进行一点手动干预，我会挑选每个场景的最佳图像，然后继续进行漫画生成过程。尽管有这一小小的不便，我现在在制作精彩漫画方面的成功率达到了9/10！
- en: Showtime
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上演时刻
- en: With the Owly system fully assembled, I decided to put this marvel of technology
    to the test one fine Saturday afternoon. I generated a handful of stories from
    his toys collection, ready to enhance bedtime storytelling for Dexie using a nifty
    portable projector I had purchased. That night, as I saw Dexie’s face light up
    and his eyes widen with excitement, the comic playing out on his bedroom wall,
    I knew all my efforts had been worth it.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Owly系统的全面组装，我决定在一个美好的星期六下午对这项技术奇迹进行测试。我从他的玩具收藏中生成了一些故事，准备利用我购买的巧妙便携式投影仪来提升Dexie的睡前故事体验。那天晚上，当我看到Dexie的脸上绽放出兴奋的光芒和眼睛睁大的神情，漫画在他的卧室墙上播放时，我知道我的努力都值得了。
- en: '![](../Images/9232d0f6ba9ade5709222aa2a16ab996.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9232d0f6ba9ade5709222aa2a16ab996.png)'
- en: Dexie is watching the comic on his bedroom wall [Image by Author]
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Dexie正在看着他卧室墙上的漫画 [图片来源于作者]
- en: The cherry on top is that it now takes me under two minutes to whip up a new
    story using photos of his toy characters I’ve already captured. Plus, I can seamlessly
    incorporate valuable morals I want him to learn from each story, such as not talking
    to strangers, being brave and adventurous, or being kind and helpful to others.
    Here are some of the delightful stories generated by this fantastic system.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最棒的是，现在我只需不到两分钟就能利用我已经拍摄的玩具角色照片创作一个新故事。此外，我可以无缝地将我希望他从每个故事中学到的宝贵道德融入其中，比如不与陌生人交谈、勇敢冒险或对他人友善和乐于助人。以下是这个神奇系统生成的一些令人愉快的故事。
- en: Super Hedgehog Tom Saves His City From a Dragon — Generated by AI Comic Generator.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 《超级刺猬汤姆拯救他的城市免受龙的威胁》 — 由AI漫画生成器生成。
- en: 'Bob the Brave Penguin: Adventures in Europe — Generated by AI Comic Generator.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 《勇敢的企鹅鲍勃：欧洲历险记》 — 由AI漫画生成器生成。
- en: Some interesting experiments
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一些有趣的实验
- en: As a curious tinkerer, I couldn’t help but fiddle with the image generation
    module to push Stable Diffusion’s boundaries and merge two characters into one
    magnificent hybrid. I fine-tuned the model with Kwazi Octonaut images, but I threw
    in a twist by assigning Zelda as both the unique and class character name. Setting
    prior_preservation to True, I ensured that Stable Diffusion would “octonaut-ify”
    Zelda while still keeping her distinct essence intact.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个好奇的发明家，我忍不住尝试图像生成模块，以推动Stable Diffusion的边界，并将两个角色合并成一个宏伟的混合体。我用科瓦兹·奥克诺特的图像对模型进行了微调，但我加了一点变化，把塞尔达设定为既独特又经典的角色名。设置`prior_preservation`为True，我确保Stable
    Diffusion会“奥克诺特化”塞尔达，同时保持她的独特本质。
- en: I cleverly utilised a modest max_step of 400, just enough to preserve Zelda’s
    original charm without her being entirely consumed by Kwazi the Octonaut’s irresistible
    allure. Behold the glorious fusion of Zelda and Kwazi, united as one!
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我巧妙地利用了适度的`max_step`为400，刚好能够保留塞尔达的原始魅力，同时避免她被科瓦兹·奥克诺特的无法抗拒的魅力完全吞噬。请看塞尔达与科瓦兹的辉煌融合，合而为一！
- en: Dexie brimmed with excitement as he witnessed a fusion of his two favourite
    characters spearheading the action in his bedtime story. He embarked on thrilling
    adventures, combating extraterrestrial beings and hunting for hidden treasure
    chests!
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Dexie兴奋不已地见证了他最喜欢的两个角色在他的睡前故事中大展拳脚。他踏上了激动人心的冒险，打击外星生物并寻找隐藏的宝藏！
- en: Unfortunately to protect the IP owner I cannot show the resulting images.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，为了保护知识产权，我不能展示生成的图像。
- en: Generative AI, particularly Large Language Models (LLMs), is here to stay and
    set to become the powerful tools for not only software development but many other
    industries as well. I’ve experienced the true power of LLMs firsthand in a few
    projects. Just last year, I built a [robotic teddy bear called Ellie, capable
    of moving its head and engaging in conversations like a real human](https://medium.com/towards-data-science/building-ellee-a-gpt-3-and-computer-vision-powered-talking-robotic-teddy-bear-with-human-level-db7d08259583).
    While this technology is undeniably potent, it’s important to exercise caution
    to ensure the safety and quality of the outputs it generates, as it can be a double-edged
    sword.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 生成型AI，特别是大型语言模型（LLMs），将长期存在，并成为不仅仅是软件开发，还包括许多其他行业的强大工具。我在一些项目中亲身体验了LLMs的真正力量。就在去年，我构建了一个[名为Ellie的机器人泰迪熊，能够移动头部并像真正的人类一样进行对话](https://medium.com/towards-data-science/building-ellee-a-gpt-3-and-computer-vision-powered-talking-robotic-teddy-bear-with-human-level-db7d08259583)。虽然这项技术无疑强大，但重要的是要谨慎使用，以确保生成结果的安全性和质量，因为它可能是一把双刃剑。
- en: And there you have it, folks! I hope you found this blog interesting. If so,
    please shower me with your claps. Feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/agustinus-nalwan/)
    or check out my other AI endeavours on my [Medium profile](https://medium.com/@agustinus-nalwan).
    Stay tuned, as I’ll be sharing the complete source code in the coming weeks!
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 各位，这就是全部了！希望你们觉得这个博客有趣。如果是的话，请给我多多点赞。随时在[LinkedIn](https://www.linkedin.com/in/agustinus-nalwan/)与我联系，或查看我在[Medium个人主页](https://medium.com/@agustinus-nalwan)上的其他AI项目。敬请关注，我将在接下来的几周内分享完整的源代码！
- en: Finally, I would like to say thanks to [Mike Chambers](https://www.linkedin.com/in/mikegchambers/)
    from AWS who helped me troubleshoot my fine-tuned Stable Diffusion model batch
    transform code.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我要感谢来自AWS的[Mike Chambers](https://www.linkedin.com/in/mikegchambers/)，他帮助我排查了微调后的Stable
    Diffusion模型批量转换代码的问题。
