- en: An Implementation of VGG
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VGG的实现
- en: 原文：[https://towardsdatascience.com/an-implementation-of-vgg-dea082804e14](https://towardsdatascience.com/an-implementation-of-vgg-dea082804e14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/an-implementation-of-vgg-dea082804e14](https://towardsdatascience.com/an-implementation-of-vgg-dea082804e14)
- en: A beginner-friendly tutorial
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 面向初学者的教程
- en: '[](https://medium.com/@mina.ghashami?source=post_page-----dea082804e14--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----dea082804e14--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dea082804e14--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dea082804e14--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----dea082804e14--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@mina.ghashami?source=post_page-----dea082804e14--------------------------------)[![Mina
    Ghashami](../Images/745f53b94f5667a485299b49913c7a21.png)](https://medium.com/@mina.ghashami?source=post_page-----dea082804e14--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dea082804e14--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dea082804e14--------------------------------)
    [Mina Ghashami](https://medium.com/@mina.ghashami?source=post_page-----dea082804e14--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dea082804e14--------------------------------)
    ·9 min read·Oct 31, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dea082804e14--------------------------------)
    ·9分钟阅读·2023年10月31日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In this post, we look at a VGG implementation and its training on STL10 [2,
    3] dataset.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们查看VGG的实现及其在STL10 [2, 3]数据集上的训练。
- en: We reviewed the VGG architecture in a [previous post](https://medium.com/towards-data-science/image-classification-for-beginners-8546aa75f331).
    Please take a look if you are unfamiliar.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[上一篇文章](https://medium.com/towards-data-science/image-classification-for-beginners-8546aa75f331)中回顾了VGG架构。如果不熟悉，请查看。
- en: '[](/image-classification-for-beginners-8546aa75f331?source=post_page-----dea082804e14--------------------------------)
    [## Image Classification For Beginners'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/image-classification-for-beginners-8546aa75f331?source=post_page-----dea082804e14--------------------------------)
    [## 面向初学者的图像分类'
- en: VGG and ResNet architecture from 2014
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VGG和ResNet架构自2014年
- en: towardsdatascience.com](/image-classification-for-beginners-8546aa75f331?source=post_page-----dea082804e14--------------------------------)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](/image-classification-for-beginners-8546aa75f331?source=post_page-----dea082804e14--------------------------------)'
- en: In a nutshell,
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，
- en: '***VGG*** *stands for* ***Visual Geometry Group*** *and is a research group
    at the university of Oxford. In 2014, they designed a deep convolutional neural
    network architecture for image classification task and named it after themselves;
    i.e. VGG [1].*'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***VGG*** *代表* ***视觉几何组*** *，是牛津大学的一个研究小组。2014年，他们设计了一种用于图像分类任务的深度卷积神经网络架构，并以他们自己命名；即VGG
    [1].*'
- en: The VGGNet comes in few configurations such as VGG16 (with 16 layers) and VGG19
    (with 19 layers).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: VGGNet有几种配置，如VGG16（16层）和VGG19（19层）。
- en: 'VGG16’s architecture is as below: it has 13 convolutional layers and 3 fully
    connected layers.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16的架构如下：它有13个卷积层和3个全连接层。
- en: '![](../Images/1d4da4d93ace6621f6ce11b018e4bb23.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d4da4d93ace6621f6ce11b018e4bb23.png)'
- en: Image by author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像
- en: Model Implementation
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型实现
- en: Let’s implement VGG16 in PyTorch.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在PyTorch中实现VGG16。
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Note, the implementation is structured in terms of two attributes:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，实现的结构基于两个属性：
- en: 'features: contains all the convolutional and max pool layers'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征：包含所有的卷积层和最大池化层
- en: 'classifier: contains fully connected layer and the softmax layer for classification'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类器：包含全连接层和用于分类的softmax层
- en: Also note we have passed the *input_channel* as an input argument. This parameter
    is 3 if the images are colored, and it is 1 if images are greyscale.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 还需注意，我们将*input_channel*作为输入参数传递。该参数为3时表示图像为彩色，为1时表示图像为灰度。
- en: Last but not least, the first fully connected layer is *nn.Linear(512 * 3* 3,
    4096).* The reason its input dimension is *512*3*3* is because we have set it
    up so that it works for our input images which are *96*96*. If we pass images
    of different sizes, we have to change this value. For example, for 224*224 images
    this layer becomes *nn.Linear(512 * 7* 7, 4096).*
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，第一个全连接层是*nn.Linear(512 * 3 * 3, 4096).* 之所以输入维度是*512 * 3 * 3*，是因为我们设置它以适应输入图像为*96
    * 96*。如果我们传递不同尺寸的图像，则需要更改此值。例如，对于224 * 224的图像，该层变为*nn.Linear(512 * 7 * 7, 4096).*
- en: 'We then implement the *forward()* method:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们实现*forward()*方法：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now that the network is complete, let’s pass a random tensor through it and
    see how its shape changes as it goes through various layers.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在网络已经完成，让我们通过它传递一个随机张量，并查看它在经过各层时形状的变化。
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And it prints the following shapes:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 它打印出以下形状：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: So the final output is a 10-dimensional vector which represents probability
    of the image belonging to any of the 10 classes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所以最终输出是一个10维的向量，表示图像属于10个类别中任何一个类别的概率。
- en: Data Transformation — STL10
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据转换 — STL10
- en: Now, let’s train it on STL10 dataset [2,3] which is licensed for commercial
    use. This dataset contains 5000 colored images in 10 categories.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在STL10数据集[2,3]上进行训练，该数据集已获得商业使用许可。此数据集包含5000张彩色图像，分为10个类别。
- en: 'Each image is 96x96 pixels, and the 10 categories are as following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 每张图像为96x96像素，10个类别如下：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s load the data and take a look at few images:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载数据并查看一些图像：
- en: '[PRE5]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'and it prints these images with their labels:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 它打印这些图像及其标签：
- en: '![](../Images/b470475af27e16e006cd7b1b4ddb4edd.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b470475af27e16e006cd7b1b4ddb4edd.png)'
- en: Image by author
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: 'Next, let’s normalize the data. To normalize the data we compute the *mean*
    and *std* first:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们对数据进行标准化。为了标准化数据，我们首先计算*均值*和*标准差*：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that in *trainloader* we are setting *batch_size = len(trainset)* so that
    we load the whole dataset for computing mean and std. Later, when we want to train
    the model, we load data in smaller batch of 128 images.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在*trainloader*中，我们设置了*batch_size = len(trainset)*，以便加载整个数据集来计算均值和标准差。之后，当我们想要训练模型时，我们将数据以128张图像的小批量加载。
- en: 'Notice from above that *np_images* is of shape (5000, 3, 96, 96) i.e. it is
    5000 images of 96x96 pixels in color scale (note the number of channels is 3 which
    indicates images are colored). So the mean and std are as following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面可以看出，*np_images*的形状是(5000, 3, 96, 96)，即5000张96x96像素的彩色图像（注意通道数为3，表示图像是彩色的）。因此，均值和标准差如下：
- en: '**mean = [**0.44671103, 0.43980882, 0.40664575]'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**均值 = [**0.44671103, 0.43980882, 0.40664575]'
- en: '**std =** [0.2603408, 0.25657743, 0.2712671'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**标准差 =** [0.2603408, 0.25657743, 0.2712671'
- en: 'We will use this mean and std to normalize both test and train data. Let’s
    define transformations of each dataset:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个均值和标准差来标准化测试数据和训练数据。让我们定义每个数据集的转换：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Training the Model
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'We first define the hyper-parameters such as:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义超参数，例如：
- en: learning rate
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率
- en: learning rate scheduler
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率调度器
- en: 'loss function: which is cross entropy for classification'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失函数：用于分类的交叉熵
- en: optimizer
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化器
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we define two functions:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义两个函数：
- en: '**Method 1:** train_batch: for all batches in data, it trains the model, computes
    the loss and update the parameters. This method applies backpropagation and computes
    training loss.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法1：** train_batch：对于数据中的所有批次，它训练模型，计算损失并更新参数。此方法应用反向传播并计算训练损失。'
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Method 2**: is the validate_batch function where we validate the model on
    a batch from test loader. Often after each epoch we call this function to get
    the performance of model at the end of each epoch. This function computes the
    loss on test set (the unseen data) and DOES NOT apply any backpropagation.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**方法2**：是validate_batch函数，其中我们在测试加载器的一个批次上验证模型。通常，在每个训练周期之后，我们调用此函数来获取模型在每个训练周期末的性能。此函数计算测试集（即未见数据）的损失，并且**不**进行任何反向传播。'
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Let the actual training start …
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让实际训练开始 …
- en: For every epoch, we train the model and check the performance of the model on
    test dataset. We call *vgg_scheduler.step()* then inform scheduler to increment
    its internal counter and update the learning rate.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一个训练周期，我们训练模型并检查模型在测试数据集上的表现。我们调用*vgg_scheduler.step()*，然后通知调度器递增其内部计数器并更新学习率。
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We see the following performance:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到以下性能：
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We see the accuracy of the model at epoch 11 reaches 80.8% on test set.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到模型在第11个周期的准确率达到80.8%。
- en: 'Next, let’s look at 10 images and what model has predicted for their label:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查看10张图像以及模型对它们标签的预测：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For example, we see the following image that is a bird and model has predicted
    it correctly to be a bird.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们看到以下图像是一只鸟，模型正确地预测为鸟。
- en: '![](../Images/336b04bab40050a1c566163b49fec182.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/336b04bab40050a1c566163b49fec182.png)'
- en: image by author
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: 'And we see an example of a wrong prediction where the image is a plane but
    VGG predicts it as a bird:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们看到一个错误预测的例子，其中图像是一架飞机，但VGG将其预测为一只鸟：
- en: '![](../Images/f1507f014439c9d579fec6483005cf3f.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1507f014439c9d579fec6483005cf3f.png)'
- en: Image by author
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于作者
- en: This concludes our implementation part on VGG model. We see that VGG has a very
    deep architecture with many parameters, however its implementation is quite straightforward
    and this is due to its uniformity in the architecture.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们对 VGG 模型的实现部分。我们看到 VGG 具有非常深的架构和许多参数，但其实现非常直接，这归功于其架构的统一性。
- en: So far, we have reviewed [VGG and ResNet in concept](/image-classification-for-beginners-8546aa75f331)
    and only VGG in code. In the next post, we can look at ResNet implementation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经回顾了[VGG 和 ResNet 的概念](/image-classification-for-beginners-8546aa75f331)以及
    VGG 的代码。在下一篇文章中，我们可以查看 ResNet 的实现。
- en: Let me know if you have any comment or questions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如有任何评论或问题，请告知我。
- en: 'If you have any questions or suggestions, feel free to reach out to me:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有任何问题或建议，请随时联系我：
- en: 'Email: mina.ghashami@gmail.com'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '邮箱: mina.ghashami@gmail.com'
- en: 'LinkedIn: [https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 'LinkedIn: [https://www.linkedin.com/in/minaghashami/](https://www.linkedin.com/in/minaghashami/)'
- en: References
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: '[Very deep convolutional networks for large scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[非常深层的卷积网络用于大规模图像识别](https://arxiv.org/pdf/1409.1556.pdf)'
- en: '[https://pytorch.org/vision/main/generated/torchvision.datasets.STL10.html](https://pytorch.org/vision/main/generated/torchvision.datasets.STL10.html)'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://pytorch.org/vision/main/generated/torchvision.datasets.STL10.html](https://pytorch.org/vision/main/generated/torchvision.datasets.STL10.html)'
- en: '[https://cs.stanford.edu/~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/)'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[https://cs.stanford.edu/~acoates/stl10/](https://cs.stanford.edu/~acoates/stl10/)'
