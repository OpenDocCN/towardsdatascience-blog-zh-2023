- en: My First Exploratory Data Analysis with ChatGPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我与 ChatGPT 的第一次探索性数据分析
- en: 原文：[https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc](https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc](https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc)
- en: 'Unleashing the power of ChatGPT: A deep dive into an exploratory data analysis
    and future opportunities'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发掘 ChatGPT 的力量：深入探讨探索性数据分析和未来机会
- en: '[](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[![Jye
    Sawtell-Rickson](../Images/e16c2b5020d24331812a4f35e9bd7890.png)](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    [Jye Sawtell-Rickson](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[![Jye
    Sawtell-Rickson](../Images/e16c2b5020d24331812a4f35e9bd7890.png)](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    [Jye Sawtell-Rickson](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    ·15 min read·May 10, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    ·15 分钟阅读·2023年5月10日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2d8f14196cf7b2834ea040accdadbbe9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d8f14196cf7b2834ea040accdadbbe9.png)'
- en: “An AI exploring a vast world of data. Digital art. Vivid colours.” (Author
    generated via DALL-E 2)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “一个 AI 探索广阔的数据世界。数字艺术。生动的色彩。”（作者通过 DALL-E 2 生成）
- en: ChatGPT is an extraordinary tool for working more efficiently, and that doesn’t
    stop with data analytics. In this article we’ll run through an example of exploratory
    data analysis (EDA) run by ChatGPT. We’ll cover the various stages of an EDA,
    see some impressive outputs (Wordclouds!) and note where ChatGPT does well (and
    not so well). Finally, we’ll touch on the future of LLMs in analytics and how
    excited we are for it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 是一个非凡的工具，可以提高工作效率，这不仅仅局限于数据分析。在本文中，我们将通过一个 ChatGPT 执行的探索性数据分析（EDA）示例进行介绍。我们将覆盖
    EDA 的各个阶段，看到一些令人印象深刻的输出（词云！），并指出 ChatGPT 表现好的地方（和不太好的地方）。最后，我们将讨论 LLM 在分析中的未来以及我们对此的兴奋之情。
- en: The dataset used for the analysis is a sample from [Common Crawl](https://commoncrawl.org/),
    which is [free to be accessed and analysed by anyone](https://commoncrawl.org/terms-of-use/).
    The Common Crawl dataset is a vast collection of web crawl data, comprising billions
    of web pages from the internet. The dataset includes various web content types
    and is regularly updated. It serves as a significant resource for training language
    models like LLMs and made up [60% of the training data for ChatGPT](https://medium.com/@dlaytonj2/chatgpt-show-me-the-data-sources-11e9433d57e8).
    You can find the dataset sample curated by the author hosted on Kaggle [here](https://www.kaggle.com/datasets/jyesawtellrickson/commoncrawl).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 用于分析的数据集是来自 [Common Crawl](https://commoncrawl.org/) 的样本，该数据集 [免费供任何人访问和分析](https://commoncrawl.org/terms-of-use/)。Common
    Crawl 数据集是一个庞大的网络爬虫数据集合，包含来自互联网的数十亿网页。该数据集包括各种网页内容类型，并且定期更新。它作为训练语言模型（如 LLMs）的重要资源，占
    [ChatGPT 训练数据的 60%](https://medium.com/@dlaytonj2/chatgpt-show-me-the-data-sources-11e9433d57e8)。你可以在
    Kaggle 上找到由作者策划的数据集样本 [这里](https://www.kaggle.com/datasets/jyesawtellrickson/commoncrawl)。
- en: Throughout the post, content will be truncated, so feel free to follow along
    directly on [the Google Colab used to run this analysis](https://colab.research.google.com/drive/1REJ3xa37Z3milf8-4-1-2fB69AONI0Zz).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个文章中，内容将会被截断，所以可以直接查看 [用于运行此分析的 Google Colab](https://colab.research.google.com/drive/1REJ3xa37Z3milf8-4-1-2fB69AONI0Zz)。
- en: 'We’ve broken down the analysis into five sections:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分析分为五个部分：
- en: 🤔 Overall Structure
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🤔 总体结构
- en: 🧹 Data Cleaning
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🧹 数据清理
- en: 💯 Basic Analysis
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 💯 基本分析
- en: 🇬🇧 NLP Approaches
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🇬🇧 NLP 方法
- en: 🔑 Key Findings
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 🔑 关键发现
- en: With all that out of the way, let’s jump into the analysis!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以上内容介绍完毕，让我们开始分析吧！
- en: Structuring Work
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化工作
- en: 'Before starting analytics work, it’s good to formulate a plan. EDA’s typically
    follow a standard structure to start with, before going off on tangents as interesting
    insights are discovered in the analysis. One such template is [this](/exploratory-data-analysis-eda-a-practical-guide-and-template-for-structured-data-abfbf3ee3bd9),
    which details the core components: preview data, clean data, plot data. We could
    use this as a starting point, but let’s assume we know nothing and see what ChatGPT
    comes up with.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始分析工作之前，制定一个计划是很好的。EDA通常遵循一个标准结构，开始时的步骤是固定的，然后在分析中发现有趣的见解时再进行扩展。一个这样的模板是[这个](/exploratory-data-analysis-eda-a-practical-guide-and-template-for-structured-data-abfbf3ee3bd9)，它详细介绍了核心组件：预览数据、清理数据、绘制数据。我们可以以此为起点，但假设我们一无所知，看看ChatGPT会提出什么。
- en: 'Prompt:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`Let''s run an EDA on the Common Crawl text dataset together. The dataset is
    a scrape of many web pages on the internet. The columns are ''text'', ''WARC-Type'',
    ''WARC-Target-URI'', ''WARC-Date'', ''WARC-Record-ID'', ''WARC-Refers-To'', ''WARC-Block-Digest'',
    ''WARC-Identified-Content-Language'', ''Content-Type'', and ''Content-Length''.
    The dataset is saved in a csv file called common_crawl_text.`'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`让我们一起对Common Crawl文本数据集进行EDA。数据集是从互联网上许多网页抓取的。列包括''text''、''WARC-Type''、''WARC-Target-URI''、''WARC-Date''、''WARC-Record-ID''、''WARC-Refers-To''、''WARC-Block-Digest''、''WARC-Identified-Content-Language''、''Content-Type''和''Content-Length''。数据集保存在一个名为common_crawl_text的csv文件中。`'
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`You should give me an overall plan, then we can go through step-by-step. In
    each step you should write some code and I will run it in the terminal then report
    back to you the results.`'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`你应该给我一个整体计划，然后我们可以一步一步进行。在每一步中，你应该写一些代码，我会在终端中运行它，然后将结果反馈给你。`'
- en: 'Response:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '`Sure, here''s a high-level plan for the EDA on the Common Crawl text dataset:`'
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`当然，这里是对Common Crawl文本数据集进行EDA的高层次计划：`'
- en: '`Load the dataset into a pandas DataFrame.`'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`将数据集加载到一个pandas DataFrame中。`'
- en: '`Check for missing values in each column and handle them appropriately.`'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`检查每列中的缺失值，并适当地处理它们。`'
- en: '`Explore the distribution of the target variable ''WARC-Type''.`'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`探索目标变量''WARC-Type''的分布。`'
- en: '`Check the distribution of ''WARC-Identified-Content-Language''.`'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`检查''WARC-Identified-Content-Language''的分布。`'
- en: '`Check the distribution of ''Content-Type''.`'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`检查''Content-Type''的分布。`'
- en: '`Explore the ''text'' column, including the distribution of text lengths and
    the most common words.`'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`探索''text''列，包括文本长度的分布和最常见的单词。`'
- en: '`Check for any correlations between the different columns.`'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`检查不同列之间的相关性。`'
- en: '`Summarize the findings and identify any interesting patterns or insights.`'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`总结发现并识别任何有趣的模式或见解。`'
- en: '`Let''s start with step 1 and load the dataset into a pandas DataFrame.`'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`让我们从第1步开始，将数据集加载到一个pandas DataFrame中。`'
- en: ChatGPT has done a pretty good job here covering the standard steps. Notice
    that it doesn’t want us to deeply analyse all columns, but has a subset that it’s
    specifically interested in. This is sensible, but I think it’s missing some valuable
    data points. For example, “WARC-Target-URI” is worth exploring, and the “WARC-Date”
    column will give insights to when the data was collected.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT在这里做得相当好，覆盖了标准步骤。注意，它并不要求我们深入分析所有列，而是对特定子集感兴趣。这很合理，但我觉得它遗漏了一些有价值的数据点。例如，“WARC-Target-URI”值得探索，“WARC-Date”列将提供数据收集时间的见解。
- en: I prompted ChatGPT with this, and it happily included these into the plan. At
    the same time, it added in the creation of a Wordcloud, something I had in the
    back of my mind.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我用这个提示了ChatGPT，它很高兴地将这些内容纳入了计划。同时，它还添加了创建Wordcloud的步骤，这是我一直在考虑的。
- en: I love this sort of interaction, where it feels like a partnership, rather than
    just reading a book.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我喜欢这种互动方式，感觉像是合作，而不仅仅是阅读一本书。
- en: Data Cleaning
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清理
- en: 'With each of the steps outlined in the structure, we can ask ChatGPT to expand
    on that step and give us the exact code to run. To start off, it suggests:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 按照结构中的每个步骤，我们可以要求ChatGPT扩展该步骤，并给我们提供精确的代码。首先，它建议：
- en: '`We can start by loading the Common Crawl text dataset and taking a look at
    its structure. Here''s the code to load the dataset into a Pandas DataFrame:`'
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`我们可以从加载Common Crawl文本数据集并查看其结构开始。以下是将数据集加载到Pandas DataFrame中的代码：`'
- en: ''
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`import pandas as pd`'
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`import pandas as pd`'
- en: ''
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df = pd.read_csv("common_crawl_text.csv")`'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df = pd.read_csv("common_crawl_text.csv")`'
- en: ''
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Once you''ve loaded the dataset, you can check the structure of the DataFrame
    using the following code:`'
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`一旦加载了数据集，你可以使用以下代码检查DataFrame的结构：`'
- en: ''
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df.head()`'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df.head()`'
- en: ''
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`This will show you the first five rows of the DataFrame. You can also use
    the [df.info](<http://df.info/>)() method to get an overview of the columns and
    their data types, as well as the number of non-null values in each column.`'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`这将显示数据框的前五行。你也可以使用 [df.info](<http://df.info/>)() 方法来获取列及其数据类型的概述，以及每列中非空值的数量。`'
- en: 'After giving it the results, it’s able to share some basic information back:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供结果后，它能够分享一些基本信息：
- en: '`Based on the provided data, it seems like we have a dataset of web archive
    records with different attributes such as the type of the record, the URI (Uniform
    Resource Identifier) of the record, the date it was recorded, the length of the
    content, and the content itself. The content is in different languages and formats,
    such as plain text, and the length of the content varies. The dataset contains
    37832 records, and some of them have null values in the content length column.`'
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`根据提供的数据，似乎我们有一个包含不同属性的网页档案记录的数据集，例如记录的类型、记录的 URI（统一资源标识符）、记录的日期、内容的长度和内容本身。内容以不同的语言和格式存在，例如纯文本，内容长度也各不相同。数据集包含
    37832 条记录，其中一些记录在内容长度列中有空值。`'
- en: 'We can go a little further and ask it to give a detailed description of each
    column:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步要求它给出每一列的详细描述：
- en: 'Prompt:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: '`Can you give a detailed list of the columns and the expected meaning?`'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`你能提供一个详细的列列表和预期含义吗？`'
- en: 'Response:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 响应：
- en: '`Sure! Here''s a detailed list of the columns in the DataFrame and their expected
    meaning:`'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`当然！这是数据框中列的详细列表及其预期含义：`'
- en: '`WARC-Type: The type of WARC record. A WARC (Web ARChive) record is a format
    for storing internet resources such as web pages and their associated metadata.`'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Type: WARC 记录的类型。WARC（Web ARChive）记录是一种用于存储互联网资源（如网页及其相关元数据）的格式。`'
- en: '`WARC-Target-URI: The target URI (Uniform Resource Identifier) of the archived
    web page.`'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Target-URI: 被存档网页的目标 URI（统一资源标识符）。`'
- en: '`WARC-Date: The date and time when the web page was archived.`'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Date: 网页被存档的日期和时间。`'
- en: '`WARC-Record-ID: The unique identifier of the WARC record.`'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Record-ID: WARC 记录的唯一标识符。`'
- en: '`WARC-Refers-To: The identifier of a related WARC record that this record refers
    to.`'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Refers-To: 此记录所引用的相关 WARC 记录的标识符。`'
- en: '`WARC-Block-Digest: A cryptographic hash value computed over the contents of
    the WARC record.`'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Block-Digest: 对 WARC 记录内容计算的加密哈希值。`'
- en: '`WARC-Identified-Content-Language: The language(s) identified in the content
    of the web page.`'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Identified-Content-Language: 在网页内容中识别的语言。`'
- en: '`Content-Type: The media type of the content, such as text/plain or text/html.`'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Content-Type: 内容的媒体类型，例如 text/plain 或 text/html。`'
- en: '`Content-Length: The length of the content in bytes.`'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Content-Length: 内容的字节长度。`'
- en: '`text: The extracted text content of the web page.`'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`text: 网页提取的文本内容。`'
- en: '`Note that some of these columns are specific to the WARC format and may not
    be present in other types of data.`'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`请注意，其中一些列是特定于 WARC 格式的，可能在其他类型的数据中不存在。`'
- en: It’s done a fairly good job at guessing what these columns mean. Some of these
    may not be correct (e.g. Content-Length), but it’s a helpful starting point. It
    may actually know these specific names thanks to its training data, but I’ve experimented
    around with arbitrary column names and it can usually guess what the column will
    contain from a combination of the name and data returned.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 它在猜测这些列的含义方面做得相当不错。虽然有些可能不正确（例如 Content-Length），但这是一个有用的起点。它可能确实知道这些特定名称，因为它的训练数据，但我已经尝试了任意列名，它通常可以从名称和返回的数据的组合中猜测列将包含什么。
- en: 'Now, it noticed there were missing values, so let’s see how to deal with that:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，它注意到有缺失值，我们来看看如何处理这些问题：
- en: 'Prompt:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: '`Should we do something about the missing values?`'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`我们应该对缺失值做些什么吗？`'
- en: 'Response:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 响应：
- en: '`Yes, it would be a good idea to handle the missing values in the Content-Length
    column. One option is to remove the rows that have missing values if they are
    not a significant portion of the data. Another option is to impute the missing
    values using some statistical method such as mean, median, or mode. However, the
    best approach would depend on the nature of the data and the analysis being performed.`'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`是的，处理 Content-Length 列中的缺失值是个好主意。一种选择是删除那些缺失值的行，如果它们不是数据的重要部分。另一种选择是使用一些统计方法（例如均值、中位数或众数）来填补缺失值。然而，最佳方法将取决于数据的性质和所执行的分析。`'
- en: These are the ways I would probably deal with it. In this case, I’m happy to
    just delete the entries since there aren’t too many.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可能是我处理它的方式。在这种情况下，我很乐意直接删除这些条目，因为数量不是很多。
- en: 'Prompt:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: '`Let''s just remove them as there are very few. How can I do that?`'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`我们就将这些删除，因为数量非常少。我该怎么做呢？`'
- en: 'Response:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 响应：
- en: '`You can drop the rows containing missing values using the dropna() function
    in pandas. Here''s an example:`'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`你可以使用 pandas 中的 dropna() 函数删除包含缺失值的行。以下是一个示例：`'
- en: ''
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`import pandas as pd`'
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`import pandas as pd`'
- en: ''
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`# create a dataframe`'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`# 创建一个数据框`'
- en: ''
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df = pd.DataFrame({''A'': [1, 2, None, 4], ''B'': [5, None, 7, 8]})`'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df = pd.DataFrame({''A'': [1, 2, None, 4], ''B'': [5, None, 7, 8]})`'
- en: ''
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`# drop rows with missing values`'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`# 删除缺失值的行`'
- en: ''
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df.dropna(inplace=True) print(df)`'
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df.dropna(inplace=True) print(df)`'
- en: ''
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Output:`'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`输出：`'
- en: ''
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`A B 0 1.0 5.0 3 4.0 8.0`'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`A B 0 1.0 5.0 3 4.0 8.0`'
- en: ''
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In this example, the dropna() function removes the second row which contains
    missing values. The inplace=True argument modifies the original DataFrame, so
    the resulting DataFrame only contains rows without any missing values.`'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`在这个示例中，dropna() 函数会删除第二行，该行包含缺失值。inplace=True 参数会修改原始数据框，因此结果数据框只包含没有缺失值的行。`'
- en: Notice how it gives working code, and comments each line of the code. It also
    gives an explanation of what is happening at the end. This is great because we
    can learn what’s happening in the code, and if there’s anything we want to modify,
    it’s a lot easier.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意它如何提供有效的代码，并对每一行代码进行注释。它还在最后提供了发生了什么的解释。这很好，因为我们可以了解代码的运行情况，如果有需要修改的地方，也会变得容易得多。
- en: We can now get started with the first parts of the analysis.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始分析的第一部分。
- en: Basic Analysis
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本分析
- en: Steps 3–5 are roughly the same, plot some distributions of data and see if there’s
    anything interesting there.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 3–5 大致相同，绘制一些数据分布图并查看是否有任何有趣的发现。
- en: 'When prompted to start step 3:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当提示开始步骤 3 时：
- en: '[PRE0]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And that outputs a graph for us. In this case, it’s not very interesting as
    there’s actually only one “WARC-Type”, but it was a nice idea. The issue with
    images is that it’s hard to feed the results back to ChatGPT. I found that it’s
    better to suggest ChatGPT to return tables of data to solve this, as well as additional
    plots where it makes sense.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这样会为我们输出一个图表。在这种情况下，图表并不特别有趣，因为实际上只有一个“WARC-Type”，但这是个不错的主意。图像的问题在于很难将结果反馈给
    ChatGPT。我发现，建议 ChatGPT 返回数据表以解决这个问题会更好，同时在有意义的地方附上额外的图表。
- en: 'After learning the column only has one value, ChatGPT is happy to move on to
    the next stage. When exploring the “WARC-Content-Language” we start to see something
    a little more complex. The results returned are:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 了解列中只有一个值后，ChatGPT 很乐意继续进行下一阶段。当我们探索“WARC-Content-Language”时，我们开始看到一些更复杂的东西。返回的结果是：
- en: '`eng 15903`'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`eng 15903`'
- en: ''
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`rus 1551`'
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`rus 1551`'
- en: ''
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`...`'
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`...`'
- en: ''
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`hrv,nno,bel 1`'
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`hrv,nno,bel 1`'
- en: ''
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`zul,eng 1`'
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`zul,eng 1`'
- en: 'Of which it learns:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从中学到的是：
- en: '`It seems like there are 1187 unique values for the ''WARC-Identified-Content-Language''
    column, and the most common language is English (''eng'') followed by Russian
    (''rus''), German (''deu''), and Chinese (''zho''). Since there are so many unique
    values, it might be difficult to analyze the distribution of the variable. One
    approach to simplifying the analysis could be to group languages into broader
    categories, such as "English", "Romance languages", "Slavic languages", etc. depending
    on the research question.`'
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`似乎“WARC-Identified-Content-Language”列有 1187 个独特的值，最常见的语言是英语（''eng''），其次是俄语（''rus''）、德语（''deu''）和中文（''zho''）。由于有如此多的独特值，分析变量的分布可能会很困难。简化分析的一种方法可能是将语言分为更广泛的类别，例如“英语”、“罗曼语系语言”、“斯拉夫语言”等，具体取决于研究问题。`'
- en: It’s a great point about grouping, but it’s missed something here — each row
    can have multiple languages. When prompted about this (a few times), it comes
    up with a good approach.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 关于分组的观点非常好，但这里有遗漏——每行可以包含多种语言。当多次询问这个问题时，它提出了一个很好的方法。
- en: '[PRE1]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After combining this with some prompts about the language grouping, we’re able
    to get out a nice plot:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 将这与一些关于语言分组的提示结合后，我们可以得到一个不错的图表：
- en: One thing I particularly like about this is that it is giving labels to the
    chart. It can be a little annoying to write out labels every time, but it does
    make a difference, so it’s nice to see that it’s smart enough to give sensible
    ones here.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我特别喜欢的一点是它给图表添加了标签。每次都写标签可能有点麻烦，但确实会有区别，所以看到它足够聪明地提供合理的标签是很不错的。
- en: Seems English is still the dominant language — by how much?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来英语仍然是主导语言——主导程度如何？
- en: 'Prompt:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: '`It looks like it''s mostly English language. Can you calculate what percentage
    of the agg data is english?`'
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`看起来主要是英语。你能计算一下汇总数据中英语的百分比吗？`'
- en: 'Response:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '`Sure, here''s some code to calculate the percentage of the aggregated data
    that is English: english_percentage = (agg_data.loc[''eng'', ''weight''] / agg_data[''weight''].sum())
    * 100`'
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`当然，这里有一些代码来计算汇总数据中英语的百分比：english_percentage = (agg_data.loc[''eng'', ''weight'']
    / agg_data[''weight''].sum()) * 100`'
- en: ''
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`print(f"The percentage of the aggregated data that is English is: {english_percentage:.2f}%")`'
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`print(f"The percentage of the aggregated data that is English is: {english_percentage:.2f}%")`'
- en: ''
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`This should output the percentage of the aggregated data that is English,
    rounded to 2 decimal places.`'
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`这应该输出汇总数据中英语的百分比，保留到小数点后两位。`'
- en: '![](../Images/97e45cc4ac8d41f1e2bc71e205b86932.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97e45cc4ac8d41f1e2bc71e205b86932.png)'
- en: (Author created image)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: （作者创建的图像）
- en: Natural Language Processing
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: Now we can move on to step 6 which involves doing some exploration of the text
    column. This is going to be more analytics heavy and will require Natural Language
    Processing (NLP) techniques. Let’s see how ChatGPT does.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进入第6步，这涉及对文本列进行一些探索。这将更注重分析，并需要自然语言处理（NLP）技术。让我们看看ChatGPT的表现。
- en: 'Prompt:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`Great. Let''s move on to step 6:`'
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`很好。我们进入第6步：`'
- en: ''
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`"Explore the ''text'' column, including the distribution of text lengths and
    the most common words."`'
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`"探索“text”列，包括文本长度的分布和最常见的词汇。"`'
- en: 'Response:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '[PRE2]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This yields:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下：
- en: '`[(''nan'', 36847), (''0'', 3467), (''1'', 2809), (''keresőoptimalizálás'',
    2498), (''idősgondozás'', 1852), (''2'', 1740), (''3'', 1559), (''szerződés'',
    1529), (''eltartási'', 1527), (''brands'', 1442), (''5'', 1362), (''4'', 1350),
    (''usd'', 1245), (''us'', 1205), (''2023'', 1204), (''new'', 1178), (''sex'',
    1165), (''2022'', 1031), (''home'', 919), (''cookies'', 904)]`'
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`[(''nan'', 36847), (''0'', 3467), (''1'', 2809), (''keresőoptimalizálás'',
    2498), (''idősgondozás'', 1852), (''2'', 1740), (''3'', 1559), (''szerződés'',
    1529), (''eltartási'', 1527), (''brands'', 1442), (''5'', 1362), (''4'', 1350),
    (''usd'', 1245), (''us'', 1205), (''2023'', 1204), (''new'', 1178), (''sex'',
    1165), (''2022'', 1031), (''home'', 919), (''cookies'', 904)]`'
- en: I wasn’t very happy with this, as we can see that a lot of the ‘top words’ are
    just numbers, or stopwords from another language (it only used English ones).
    I was able to prod it on this, and it helped clean it up by filtering out words
    which were non-alphabetic tokens and including stopword lists for other languages.
    Now let’s visualise these in a Wordcloud.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我对此不是很满意，因为我们可以看到很多“常见词汇”只是数字，或者是其他语言的停用词（它只使用了英语停用词）。我能够在这方面进行调整，通过过滤掉非字母字符的词汇和包括其他语言的停用词列表来帮助清理数据。现在让我们在词云中可视化这些数据。
- en: 'Prompt:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`Can you make it a wordcloud?`'
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`你能制作一个词云吗？`'
- en: 'Response:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '[PRE3]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/f2578e3bf779c3c2340e134247601bd0.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2578e3bf779c3c2340e134247601bd0.png)'
- en: 'WARNING: contains explicit language. For those who are wondering, “keresőoptimalizálás”
    is Hungarian for “Search engine optimization” (author created image).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：包含明显的语言。对于那些好奇的人，“keresőoptimalizálás”是匈牙利语中的“搜索引擎优化”（作者创建的图像）。
- en: 'I’m not sure what to take away from this plot. It seems there are some words
    which could have useful content associated with them (e.g “information”, “blog”,
    “brands”), but there is also a lot of undesirable content. I shared the top words
    to ChatGPT and asked what it thought:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我不确定从这个图中能得到什么。似乎有一些词可能关联有用的内容（例如“信息”、“博客”、“品牌”），但也有很多不需要的内容。我将这些常见词汇分享给ChatGPT并询问它的看法：
- en: 'Prompt:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`What can we say about this?`'
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`我们对此可以说些什么？`'
- en: 'Response:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '`Based on the top words found in the ''text'' column, it appears that the data
    may contain a lot of spam or irrelevant information, as many of the top words
    are related to online dating, reviews, loans, and escorts. Additionally, the presence
    of words like ''nan'' suggests that there may be missing or incomplete data in
    the ''text'' column. It would be important to further investigate the nature and
    quality of the data in the ''text'' column to determine how useful it is for any
    downstream analysis.`'
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`根据“text”列中发现的常见词汇，数据可能包含很多垃圾信息或不相关的信息，因为许多常见词汇与在线约会、评论、贷款和陪玩相关。此外，像“nan”这样的词汇表明“text”列中可能有缺失或不完整的数据。进一步调查“text”列的数据性质和质量对于确定其在后续分析中的有用性是重要的。`'
- en: That’s a fair conclusion to make, and indeed, companies that work with the Common
    Crawl dataset have stated that they invest considerable resources cleaning up
    the dataset to make it usable for training AI models.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个合理的结论，实际上，与Common Crawl数据集合作的公司确实表示，他们投入了大量资源来清理数据集，以使其适合训练AI模型。
- en: Wrapping Up
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Wrapping Up
- en: This concludes the plan outlined by ChatGPT, so we’ll wrap up the analysis here
    and see what findings it has.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了ChatGPT概述的计划，所以我们将在这里结束分析，并查看它有什么发现。
- en: 'Prompt:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：
- en: '`Great. Let''s move on to step 8\. Can you summarise the findings from all
    our analysis so far?`'
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`很好。让我们继续第8步。你能总结一下我们迄今为止的所有分析结果吗？`'
- en: 'Response:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 回复：
- en: '`Sure, based on the analysis we have conducted so far, here are some key findings:
    Language distribution: The most common language in the dataset is English, followed
    by Russian, German, Chinese, and Spanish. Content-Type distribution: The majority
    of the content in the dataset is of the type "text/plain". Text length: The text
    length in the dataset ranges from 0 to 8,542,524, with an average length of 20,566\.
    Common words: The most frequent words in the dataset are not particularly informative,
    as they include many stop words and other non-informative terms. Correlations:
    There is a strong positive correlation between the length of the text and the
    content length. There is also a weak positive correlation between the number of
    languages detected in a text and the content length.`'
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`当然，基于我们目前进行的分析，以下是一些关键发现：语言分布：数据集中最常见的语言是英语，其次是俄语、德语、中文和西班牙语。内容类型分布：数据集中大多数内容类型为"text/plain"。文本长度：数据集中，文本长度范围从0到8,542,524，平均长度为20,566。常见词：数据集中最频繁的词汇并不特别有信息量，因为它们包含许多停用词和其他非信息性术语。相关性：文本长度与内容长度之间存在强正相关。检测到的语言数量与内容长度之间也存在弱正相关。`'
- en: If a data analyst came to me with this, I’d be pretty disappointed. As mentioned
    at the start, there are some columns it could have analysed in more detailed,
    and it’s generally better to make some suggestions for next steps. However, we
    never gave it a goal for the analysis, nor told it to give us suggestions so I’m
    not going to penalise it too much.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有数据分析师带着这些内容来找我，我会感到非常失望。正如开始时提到的，有一些列数据可以分析得更详细，并且通常更好的是提出一些下一步的建议。然而，我们从未给它设定分析的目标，也没告诉它给出建议，所以我不会太过苛责。
- en: Discussion
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: 'As you can see, the prompting used throughout was relatively simple. Given
    that, it’s impressive at how well ChatGPT was able to understand what I wanted
    done and give useful answers. These prompts could definitely be improved by providing
    more context in each prompt and being stricter on what we want back. For example,
    each prompt could contain references to the specific task it is focusing on, as
    well as additional text to have it do exactly what we want:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，整个过程中使用的提示相对简单。考虑到这一点，ChatGPT能够很好地理解我想要的并给出有用的回答，这一点令人印象深刻。这些提示可以通过在每个提示中提供更多上下文以及对我们希望返回的内容更严格来改进。例如，每个提示可以包含对其专注的具体任务的引用，以及额外的文本以确保其做我们想要的：
- en: '`Don’t respond with superfluous text. Assume pandas, numpy and matplotlib have
    been imported in the standard way.`'
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`不要回应多余的文本。假设pandas、numpy和matplotlib已按标准方式导入。`'
- en: These could be maintained in your own set of prompt templates to speed up this
    sort of work, or done with a tool such as [LangChain](https://python.langchain.com/en/latest/index.html).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可以保存在你自己的提示模板中以加快这类工作的进度，或者使用诸如[LangChain](https://python.langchain.com/en/latest/index.html)这样的工具来完成。
- en: We could also define our own overall template. I let ChatGPT come up with a
    plan, but it wasn’t perfect. We could define an overall structure for it to follow,
    and a standard way to e.g. analyse each variable. With templates, ChatGPT is less
    likely to miss insights in such an analysis.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以定义自己的总体模板。我让ChatGPT提出一个计划，但它并不完美。我们可以定义一个总体结构供其遵循，以及分析每个变量的标准方法。通过模板，ChatGPT在这种分析中遗漏洞察的可能性较小。
- en: While it was fun going back and forth with ChatGPT to get data outputs to it,
    it quickly became tiring. ChatGPT is much more powerful when it can run the code
    directly itself. ChatGPT can connected to a Python runtime by instead working
    with the [Python API](https://medium.com/geekculture/a-simple-guide-to-chatgpt-api-with-python-c147985ae28).
    In this case, the code could be run automatically, but to cut the human out of
    the loop we’ll need one more tool.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然与ChatGPT反复交流以获取数据输出很有趣，但很快变得疲惫。ChatGPT在能够直接运行代码时更为强大。ChatGPT可以通过使用[Python
    API](https://medium.com/geekculture/a-simple-guide-to-chatgpt-api-with-python-c147985ae28)连接到Python运行时。在这种情况下，代码可以自动运行，但要将人从循环中剔除，我们还需要一个额外的工具。
- en: AutoGPT has been very popular in the last month as a power-up to ChatGPT which
    effectively provides a guide to ChatGPT agents which allows them to keep executing
    towards some goal. AutoGPT could replace me in this situation, asking ChatGPT
    agents to design code, then executing it, feeding the results back to ChatGPT,
    proceeding until it has a detailed analysis. It would also interface with a memory
    database which would allow it to execute much larger analyses.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去一个月里，AutoGPT 作为 ChatGPT 的增强工具非常受欢迎，它有效地为 ChatGPT 代理提供了指南，允许他们持续朝着某个目标执行。AutoGPT
    可以在这种情况下取代我，让 ChatGPT 代理设计代码，然后执行它，将结果反馈给 ChatGPT，直到它得到详细的分析。它还将与一个内存数据库接口，从而允许它执行更大规模的分析。
- en: With a tool like AutoGPT we can set a clear goal with requirements such as detail
    of analysis and expected conclusion style. In this case, we can check in less
    regularly with the outcomes and eventually have to do little work to get a decent
    analysis out.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像 AutoGPT 这样的工具，我们可以设定一个明确的目标，包括分析的细节和期望的结论风格。在这种情况下，我们可以较少地检查结果，并最终很少需要工作即可得到一个不错的分析。
- en: Finally, we should call out that ChatGPT is far from ‘perfect’ and even in this
    mock analysis, I had to massage the prompts to get an answer that was close to
    what I wanted. It was a lot less difficult than I expected, but still worth noting.
    It created some code that had errors, though it managed to fix the errors every
    time it was told. At times it created code that I wouldn’t have wanted to run,
    and I needed to suggest it follow a different path, but again, upon prompting
    it could come up with a decent solution.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们应该指出 ChatGPT 远未达到“完美”，即便在这次模拟分析中，我也需要调整提示，以获得接近我想要的答案。虽然这比我预期的要容易得多，但仍然值得注意。它创建了一些有错误的代码，尽管每次被告知后都能修复这些错误。有时它创建的代码是我不想运行的，我需要建议它采用不同的方法，但再次提示后，它能够提出一个不错的解决方案。
- en: Conclusion
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, we’ve seen how ChatGPT can be used to support the running of
    an Exploratory Data Analysis (EDA). We’ve seen that we’re able to get surprisingly
    good results working with the system, with little exterior help. We also noted
    that there are already tools which allow us to extend this idea such as AutoGPT
    which could make an even more powerful assistant.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们已经看到 ChatGPT 如何用于支持探索性数据分析（EDA）的运行。我们发现，与系统合作时能够获得意想不到的良好结果，几乎不需要外部帮助。我们还注意到，已经存在一些工具可以扩展这一想法，例如
    AutoGPT，它可能成为一个更强大的助手。
- en: As a data analyst, I’m already using ChatGPT to help with my analytics in some
    of the ways described above, though I rarely use it for an end-to-end analysis
    as detailed in this article. As more integrations are built out with tools like
    AutoGPT, and the friction to use is reduced, I expect to be using it more and
    more and am very much excited for it (while I’m not made obsolete ;) ).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名数据分析师，我已经在使用 ChatGPT 帮助我的分析，尽管我很少使用它进行本文中详细描述的端到端分析。随着像 AutoGPT 这样的工具的更多集成，以及使用摩擦的减少，我预计会越来越多地使用它，并且对此非常期待（虽然我不会被取代
    ;) ）。
