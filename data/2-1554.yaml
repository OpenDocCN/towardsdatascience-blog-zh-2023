- en: My First Exploratory Data Analysis with ChatGPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ ChatGPT çš„ç¬¬ä¸€æ¬¡æ¢ç´¢æ€§æ•°æ®åˆ†æ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc](https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc](https://towardsdatascience.com/my-first-exploratory-data-analysis-with-chatgpt-7f100005efdc)
- en: 'Unleashing the power of ChatGPT: A deep dive into an exploratory data analysis
    and future opportunities'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‘æ˜ ChatGPT çš„åŠ›é‡ï¼šæ·±å…¥æ¢è®¨æ¢ç´¢æ€§æ•°æ®åˆ†æå’Œæœªæ¥æœºä¼š
- en: '[](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[![Jye
    Sawtell-Rickson](../Images/e16c2b5020d24331812a4f35e9bd7890.png)](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    [Jye Sawtell-Rickson](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[![Jye
    Sawtell-Rickson](../Images/e16c2b5020d24331812a4f35e9bd7890.png)](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    [Jye Sawtell-Rickson](https://jyesr.medium.com/?source=post_page-----7f100005efdc--------------------------------)'
- en: Â·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    Â·15 min readÂ·May 10, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f100005efdc--------------------------------)
    Â·15 åˆ†é’Ÿé˜…è¯»Â·2023å¹´5æœˆ10æ—¥
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/2d8f14196cf7b2834ea040accdadbbe9.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2d8f14196cf7b2834ea040accdadbbe9.png)'
- en: â€œAn AI exploring a vast world of data. Digital art. Vivid colours.â€ (Author
    generated via DALL-E 2)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: â€œä¸€ä¸ª AI æ¢ç´¢å¹¿é˜”çš„æ•°æ®ä¸–ç•Œã€‚æ•°å­—è‰ºæœ¯ã€‚ç”ŸåŠ¨çš„è‰²å½©ã€‚â€ï¼ˆä½œè€…é€šè¿‡ DALL-E 2 ç”Ÿæˆï¼‰
- en: ChatGPT is an extraordinary tool for working more efficiently, and that doesnâ€™t
    stop with data analytics. In this article weâ€™ll run through an example of exploratory
    data analysis (EDA) run by ChatGPT. Weâ€™ll cover the various stages of an EDA,
    see some impressive outputs (Wordclouds!) and note where ChatGPT does well (and
    not so well). Finally, weâ€™ll touch on the future of LLMs in analytics and how
    excited we are for it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT æ˜¯ä¸€ä¸ªéå‡¡çš„å·¥å…·ï¼Œå¯ä»¥æé«˜å·¥ä½œæ•ˆç‡ï¼Œè¿™ä¸ä»…ä»…å±€é™äºæ•°æ®åˆ†æã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ª ChatGPT æ‰§è¡Œçš„æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰ç¤ºä¾‹è¿›è¡Œä»‹ç»ã€‚æˆ‘ä»¬å°†è¦†ç›–
    EDA çš„å„ä¸ªé˜¶æ®µï¼Œçœ‹åˆ°ä¸€äº›ä»¤äººå°è±¡æ·±åˆ»çš„è¾“å‡ºï¼ˆè¯äº‘ï¼ï¼‰ï¼Œå¹¶æŒ‡å‡º ChatGPT è¡¨ç°å¥½çš„åœ°æ–¹ï¼ˆå’Œä¸å¤ªå¥½çš„åœ°æ–¹ï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬å°†è®¨è®º LLM åœ¨åˆ†æä¸­çš„æœªæ¥ä»¥åŠæˆ‘ä»¬å¯¹æ­¤çš„å…´å¥‹ä¹‹æƒ…ã€‚
- en: The dataset used for the analysis is a sample from [Common Crawl](https://commoncrawl.org/),
    which is [free to be accessed and analysed by anyone](https://commoncrawl.org/terms-of-use/).
    The Common Crawl dataset is a vast collection of web crawl data, comprising billions
    of web pages from the internet. The dataset includes various web content types
    and is regularly updated. It serves as a significant resource for training language
    models like LLMs and made up [60% of the training data for ChatGPT](https://medium.com/@dlaytonj2/chatgpt-show-me-the-data-sources-11e9433d57e8).
    You can find the dataset sample curated by the author hosted on Kaggle [here](https://www.kaggle.com/datasets/jyesawtellrickson/commoncrawl).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨äºåˆ†æçš„æ•°æ®é›†æ˜¯æ¥è‡ª [Common Crawl](https://commoncrawl.org/) çš„æ ·æœ¬ï¼Œè¯¥æ•°æ®é›† [å…è´¹ä¾›ä»»ä½•äººè®¿é—®å’Œåˆ†æ](https://commoncrawl.org/terms-of-use/)ã€‚Common
    Crawl æ•°æ®é›†æ˜¯ä¸€ä¸ªåºå¤§çš„ç½‘ç»œçˆ¬è™«æ•°æ®é›†åˆï¼ŒåŒ…å«æ¥è‡ªäº’è”ç½‘çš„æ•°åäº¿ç½‘é¡µã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬å„ç§ç½‘é¡µå†…å®¹ç±»å‹ï¼Œå¹¶ä¸”å®šæœŸæ›´æ–°ã€‚å®ƒä½œä¸ºè®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆå¦‚ LLMsï¼‰çš„é‡è¦èµ„æºï¼Œå 
    [ChatGPT è®­ç»ƒæ•°æ®çš„ 60%](https://medium.com/@dlaytonj2/chatgpt-show-me-the-data-sources-11e9433d57e8)ã€‚ä½ å¯ä»¥åœ¨
    Kaggle ä¸Šæ‰¾åˆ°ç”±ä½œè€…ç­–åˆ’çš„æ•°æ®é›†æ ·æœ¬ [è¿™é‡Œ](https://www.kaggle.com/datasets/jyesawtellrickson/commoncrawl)ã€‚
- en: Throughout the post, content will be truncated, so feel free to follow along
    directly on [the Google Colab used to run this analysis](https://colab.research.google.com/drive/1REJ3xa37Z3milf8-4-1-2fB69AONI0Zz).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ•´ä¸ªæ–‡ç« ä¸­ï¼Œå†…å®¹å°†ä¼šè¢«æˆªæ–­ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥æŸ¥çœ‹ [ç”¨äºè¿è¡Œæ­¤åˆ†æçš„ Google Colab](https://colab.research.google.com/drive/1REJ3xa37Z3milf8-4-1-2fB69AONI0Zz)ã€‚
- en: 'Weâ€™ve broken down the analysis into five sections:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åˆ†æåˆ†ä¸ºäº”ä¸ªéƒ¨åˆ†ï¼š
- en: ğŸ¤” Overall Structure
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ¤” æ€»ä½“ç»“æ„
- en: ğŸ§¹ Data Cleaning
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ§¹ æ•°æ®æ¸…ç†
- en: ğŸ’¯ Basic Analysis
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ’¯ åŸºæœ¬åˆ†æ
- en: ğŸ‡¬ğŸ‡§ NLP Approaches
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ‡¬ğŸ‡§ NLP æ–¹æ³•
- en: ğŸ”‘ Key Findings
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ğŸ”‘ å…³é”®å‘ç°
- en: With all that out of the way, letâ€™s jump into the analysis!
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸Šå†…å®¹ä»‹ç»å®Œæ¯•ï¼Œè®©æˆ‘ä»¬å¼€å§‹åˆ†æå§ï¼
- en: Structuring Work
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“æ„åŒ–å·¥ä½œ
- en: 'Before starting analytics work, itâ€™s good to formulate a plan. EDAâ€™s typically
    follow a standard structure to start with, before going off on tangents as interesting
    insights are discovered in the analysis. One such template is [this](/exploratory-data-analysis-eda-a-practical-guide-and-template-for-structured-data-abfbf3ee3bd9),
    which details the core components: preview data, clean data, plot data. We could
    use this as a starting point, but letâ€™s assume we know nothing and see what ChatGPT
    comes up with.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¼€å§‹åˆ†æå·¥ä½œä¹‹å‰ï¼Œåˆ¶å®šä¸€ä¸ªè®¡åˆ’æ˜¯å¾ˆå¥½çš„ã€‚EDAé€šå¸¸éµå¾ªä¸€ä¸ªæ ‡å‡†ç»“æ„ï¼Œå¼€å§‹æ—¶çš„æ­¥éª¤æ˜¯å›ºå®šçš„ï¼Œç„¶ååœ¨åˆ†æä¸­å‘ç°æœ‰è¶£çš„è§è§£æ—¶å†è¿›è¡Œæ‰©å±•ã€‚ä¸€ä¸ªè¿™æ ·çš„æ¨¡æ¿æ˜¯[è¿™ä¸ª](/exploratory-data-analysis-eda-a-practical-guide-and-template-for-structured-data-abfbf3ee3bd9)ï¼Œå®ƒè¯¦ç»†ä»‹ç»äº†æ ¸å¿ƒç»„ä»¶ï¼šé¢„è§ˆæ•°æ®ã€æ¸…ç†æ•°æ®ã€ç»˜åˆ¶æ•°æ®ã€‚æˆ‘ä»¬å¯ä»¥ä»¥æ­¤ä¸ºèµ·ç‚¹ï¼Œä½†å‡è®¾æˆ‘ä»¬ä¸€æ— æ‰€çŸ¥ï¼Œçœ‹çœ‹ChatGPTä¼šæå‡ºä»€ä¹ˆã€‚
- en: 'Prompt:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`Let''s run an EDA on the Common Crawl text dataset together. The dataset is
    a scrape of many web pages on the internet. The columns are ''text'', ''WARC-Type'',
    ''WARC-Target-URI'', ''WARC-Date'', ''WARC-Record-ID'', ''WARC-Refers-To'', ''WARC-Block-Digest'',
    ''WARC-Identified-Content-Language'', ''Content-Type'', and ''Content-Length''.
    The dataset is saved in a csv file called common_crawl_text.`'
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`è®©æˆ‘ä»¬ä¸€èµ·å¯¹Common Crawlæ–‡æœ¬æ•°æ®é›†è¿›è¡ŒEDAã€‚æ•°æ®é›†æ˜¯ä»äº’è”ç½‘ä¸Šè®¸å¤šç½‘é¡µæŠ“å–çš„ã€‚åˆ—åŒ…æ‹¬''text''ã€''WARC-Type''ã€''WARC-Target-URI''ã€''WARC-Date''ã€''WARC-Record-ID''ã€''WARC-Refers-To''ã€''WARC-Block-Digest''ã€''WARC-Identified-Content-Language''ã€''Content-Type''å’Œ''Content-Length''ã€‚æ•°æ®é›†ä¿å­˜åœ¨ä¸€ä¸ªåä¸ºcommon_crawl_textçš„csvæ–‡ä»¶ä¸­ã€‚`'
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`You should give me an overall plan, then we can go through step-by-step. In
    each step you should write some code and I will run it in the terminal then report
    back to you the results.`'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ä½ åº”è¯¥ç»™æˆ‘ä¸€ä¸ªæ•´ä½“è®¡åˆ’ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥ä¸€æ­¥ä¸€æ­¥è¿›è¡Œã€‚åœ¨æ¯ä¸€æ­¥ä¸­ï¼Œä½ åº”è¯¥å†™ä¸€äº›ä»£ç ï¼Œæˆ‘ä¼šåœ¨ç»ˆç«¯ä¸­è¿è¡Œå®ƒï¼Œç„¶åå°†ç»“æœåé¦ˆç»™ä½ ã€‚`'
- en: 'Response:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '`Sure, here''s a high-level plan for the EDA on the Common Crawl text dataset:`'
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`å½“ç„¶ï¼Œè¿™é‡Œæ˜¯å¯¹Common Crawlæ–‡æœ¬æ•°æ®é›†è¿›è¡ŒEDAçš„é«˜å±‚æ¬¡è®¡åˆ’ï¼š`'
- en: '`Load the dataset into a pandas DataFrame.`'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`å°†æ•°æ®é›†åŠ è½½åˆ°ä¸€ä¸ªpandas DataFrameä¸­ã€‚`'
- en: '`Check for missing values in each column and handle them appropriately.`'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`æ£€æŸ¥æ¯åˆ—ä¸­çš„ç¼ºå¤±å€¼ï¼Œå¹¶é€‚å½“åœ°å¤„ç†å®ƒä»¬ã€‚`'
- en: '`Explore the distribution of the target variable ''WARC-Type''.`'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`æ¢ç´¢ç›®æ ‡å˜é‡''WARC-Type''çš„åˆ†å¸ƒã€‚`'
- en: '`Check the distribution of ''WARC-Identified-Content-Language''.`'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`æ£€æŸ¥''WARC-Identified-Content-Language''çš„åˆ†å¸ƒã€‚`'
- en: '`Check the distribution of ''Content-Type''.`'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`æ£€æŸ¥''Content-Type''çš„åˆ†å¸ƒã€‚`'
- en: '`Explore the ''text'' column, including the distribution of text lengths and
    the most common words.`'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`æ¢ç´¢''text''åˆ—ï¼ŒåŒ…æ‹¬æ–‡æœ¬é•¿åº¦çš„åˆ†å¸ƒå’Œæœ€å¸¸è§çš„å•è¯ã€‚`'
- en: '`Check for any correlations between the different columns.`'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`æ£€æŸ¥ä¸åŒåˆ—ä¹‹é—´çš„ç›¸å…³æ€§ã€‚`'
- en: '`Summarize the findings and identify any interesting patterns or insights.`'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`æ€»ç»“å‘ç°å¹¶è¯†åˆ«ä»»ä½•æœ‰è¶£çš„æ¨¡å¼æˆ–è§è§£ã€‚`'
- en: '`Let''s start with step 1 and load the dataset into a pandas DataFrame.`'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`è®©æˆ‘ä»¬ä»ç¬¬1æ­¥å¼€å§‹ï¼Œå°†æ•°æ®é›†åŠ è½½åˆ°ä¸€ä¸ªpandas DataFrameä¸­ã€‚`'
- en: ChatGPT has done a pretty good job here covering the standard steps. Notice
    that it doesnâ€™t want us to deeply analyse all columns, but has a subset that itâ€™s
    specifically interested in. This is sensible, but I think itâ€™s missing some valuable
    data points. For example, â€œWARC-Target-URIâ€ is worth exploring, and the â€œWARC-Dateâ€
    column will give insights to when the data was collected.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPTåœ¨è¿™é‡Œåšå¾—ç›¸å½“å¥½ï¼Œè¦†ç›–äº†æ ‡å‡†æ­¥éª¤ã€‚æ³¨æ„ï¼Œå®ƒå¹¶ä¸è¦æ±‚æˆ‘ä»¬æ·±å…¥åˆ†ææ‰€æœ‰åˆ—ï¼Œè€Œæ˜¯å¯¹ç‰¹å®šå­é›†æ„Ÿå…´è¶£ã€‚è¿™å¾ˆåˆç†ï¼Œä½†æˆ‘è§‰å¾—å®ƒé—æ¼äº†ä¸€äº›æœ‰ä»·å€¼çš„æ•°æ®ç‚¹ã€‚ä¾‹å¦‚ï¼Œâ€œWARC-Target-URIâ€å€¼å¾—æ¢ç´¢ï¼Œâ€œWARC-Dateâ€åˆ—å°†æä¾›æ•°æ®æ”¶é›†æ—¶é—´çš„è§è§£ã€‚
- en: I prompted ChatGPT with this, and it happily included these into the plan. At
    the same time, it added in the creation of a Wordcloud, something I had in the
    back of my mind.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç”¨è¿™ä¸ªæç¤ºäº†ChatGPTï¼Œå®ƒå¾ˆé«˜å…´åœ°å°†è¿™äº›å†…å®¹çº³å…¥äº†è®¡åˆ’ã€‚åŒæ—¶ï¼Œå®ƒè¿˜æ·»åŠ äº†åˆ›å»ºWordcloudçš„æ­¥éª¤ï¼Œè¿™æ˜¯æˆ‘ä¸€ç›´åœ¨è€ƒè™‘çš„ã€‚
- en: I love this sort of interaction, where it feels like a partnership, rather than
    just reading a book.
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æˆ‘å–œæ¬¢è¿™ç§äº’åŠ¨æ–¹å¼ï¼Œæ„Ÿè§‰åƒæ˜¯åˆä½œï¼Œè€Œä¸ä»…ä»…æ˜¯é˜…è¯»ä¸€æœ¬ä¹¦ã€‚
- en: Data Cleaning
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ•°æ®æ¸…ç†
- en: 'With each of the steps outlined in the structure, we can ask ChatGPT to expand
    on that step and give us the exact code to run. To start off, it suggests:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‰ç…§ç»“æ„ä¸­çš„æ¯ä¸ªæ­¥éª¤ï¼Œæˆ‘ä»¬å¯ä»¥è¦æ±‚ChatGPTæ‰©å±•è¯¥æ­¥éª¤ï¼Œå¹¶ç»™æˆ‘ä»¬æä¾›ç²¾ç¡®çš„ä»£ç ã€‚é¦–å…ˆï¼Œå®ƒå»ºè®®ï¼š
- en: '`We can start by loading the Common Crawl text dataset and taking a look at
    its structure. Here''s the code to load the dataset into a Pandas DataFrame:`'
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`æˆ‘ä»¬å¯ä»¥ä»åŠ è½½Common Crawlæ–‡æœ¬æ•°æ®é›†å¹¶æŸ¥çœ‹å…¶ç»“æ„å¼€å§‹ã€‚ä»¥ä¸‹æ˜¯å°†æ•°æ®é›†åŠ è½½åˆ°Pandas DataFrameä¸­çš„ä»£ç ï¼š`'
- en: ''
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`import pandas as pd`'
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`import pandas as pd`'
- en: ''
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df = pd.read_csv("common_crawl_text.csv")`'
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df = pd.read_csv("common_crawl_text.csv")`'
- en: ''
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Once you''ve loaded the dataset, you can check the structure of the DataFrame
    using the following code:`'
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ä¸€æ—¦åŠ è½½äº†æ•°æ®é›†ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç æ£€æŸ¥DataFrameçš„ç»“æ„ï¼š`'
- en: ''
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df.head()`'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df.head()`'
- en: ''
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`This will show you the first five rows of the DataFrame. You can also use
    the [df.info](<http://df.info/>)() method to get an overview of the columns and
    their data types, as well as the number of non-null values in each column.`'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`è¿™å°†æ˜¾ç¤ºæ•°æ®æ¡†çš„å‰äº”è¡Œã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ [df.info](<http://df.info/>)() æ–¹æ³•æ¥è·å–åˆ—åŠå…¶æ•°æ®ç±»å‹çš„æ¦‚è¿°ï¼Œä»¥åŠæ¯åˆ—ä¸­éç©ºå€¼çš„æ•°é‡ã€‚`'
- en: 'After giving it the results, itâ€™s able to share some basic information back:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æä¾›ç»“æœåï¼Œå®ƒèƒ½å¤Ÿåˆ†äº«ä¸€äº›åŸºæœ¬ä¿¡æ¯ï¼š
- en: '`Based on the provided data, it seems like we have a dataset of web archive
    records with different attributes such as the type of the record, the URI (Uniform
    Resource Identifier) of the record, the date it was recorded, the length of the
    content, and the content itself. The content is in different languages and formats,
    such as plain text, and the length of the content varies. The dataset contains
    37832 records, and some of them have null values in the content length column.`'
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`æ ¹æ®æä¾›çš„æ•°æ®ï¼Œä¼¼ä¹æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«ä¸åŒå±æ€§çš„ç½‘é¡µæ¡£æ¡ˆè®°å½•çš„æ•°æ®é›†ï¼Œä¾‹å¦‚è®°å½•çš„ç±»å‹ã€è®°å½•çš„ URIï¼ˆç»Ÿä¸€èµ„æºæ ‡è¯†ç¬¦ï¼‰ã€è®°å½•çš„æ—¥æœŸã€å†…å®¹çš„é•¿åº¦å’Œå†…å®¹æœ¬èº«ã€‚å†…å®¹ä»¥ä¸åŒçš„è¯­è¨€å’Œæ ¼å¼å­˜åœ¨ï¼Œä¾‹å¦‚çº¯æ–‡æœ¬ï¼Œå†…å®¹é•¿åº¦ä¹Ÿå„ä¸ç›¸åŒã€‚æ•°æ®é›†åŒ…å«
    37832 æ¡è®°å½•ï¼Œå…¶ä¸­ä¸€äº›è®°å½•åœ¨å†…å®¹é•¿åº¦åˆ—ä¸­æœ‰ç©ºå€¼ã€‚`'
- en: 'We can go a little further and ask it to give a detailed description of each
    column:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥è¦æ±‚å®ƒç»™å‡ºæ¯ä¸€åˆ—çš„è¯¦ç»†æè¿°ï¼š
- en: 'Prompt:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºï¼š
- en: '`Can you give a detailed list of the columns and the expected meaning?`'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ä½ èƒ½æä¾›ä¸€ä¸ªè¯¦ç»†çš„åˆ—åˆ—è¡¨å’Œé¢„æœŸå«ä¹‰å—ï¼Ÿ`'
- en: 'Response:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å“åº”ï¼š
- en: '`Sure! Here''s a detailed list of the columns in the DataFrame and their expected
    meaning:`'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`å½“ç„¶ï¼è¿™æ˜¯æ•°æ®æ¡†ä¸­åˆ—çš„è¯¦ç»†åˆ—è¡¨åŠå…¶é¢„æœŸå«ä¹‰ï¼š`'
- en: '`WARC-Type: The type of WARC record. A WARC (Web ARChive) record is a format
    for storing internet resources such as web pages and their associated metadata.`'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Type: WARC è®°å½•çš„ç±»å‹ã€‚WARCï¼ˆWeb ARChiveï¼‰è®°å½•æ˜¯ä¸€ç§ç”¨äºå­˜å‚¨äº’è”ç½‘èµ„æºï¼ˆå¦‚ç½‘é¡µåŠå…¶ç›¸å…³å…ƒæ•°æ®ï¼‰çš„æ ¼å¼ã€‚`'
- en: '`WARC-Target-URI: The target URI (Uniform Resource Identifier) of the archived
    web page.`'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Target-URI: è¢«å­˜æ¡£ç½‘é¡µçš„ç›®æ ‡ URIï¼ˆç»Ÿä¸€èµ„æºæ ‡è¯†ç¬¦ï¼‰ã€‚`'
- en: '`WARC-Date: The date and time when the web page was archived.`'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Date: ç½‘é¡µè¢«å­˜æ¡£çš„æ—¥æœŸå’Œæ—¶é—´ã€‚`'
- en: '`WARC-Record-ID: The unique identifier of the WARC record.`'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Record-ID: WARC è®°å½•çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚`'
- en: '`WARC-Refers-To: The identifier of a related WARC record that this record refers
    to.`'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Refers-To: æ­¤è®°å½•æ‰€å¼•ç”¨çš„ç›¸å…³ WARC è®°å½•çš„æ ‡è¯†ç¬¦ã€‚`'
- en: '`WARC-Block-Digest: A cryptographic hash value computed over the contents of
    the WARC record.`'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Block-Digest: å¯¹ WARC è®°å½•å†…å®¹è®¡ç®—çš„åŠ å¯†å“ˆå¸Œå€¼ã€‚`'
- en: '`WARC-Identified-Content-Language: The language(s) identified in the content
    of the web page.`'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WARC-Identified-Content-Language: åœ¨ç½‘é¡µå†…å®¹ä¸­è¯†åˆ«çš„è¯­è¨€ã€‚`'
- en: '`Content-Type: The media type of the content, such as text/plain or text/html.`'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Content-Type: å†…å®¹çš„åª’ä½“ç±»å‹ï¼Œä¾‹å¦‚ text/plain æˆ– text/htmlã€‚`'
- en: '`Content-Length: The length of the content in bytes.`'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Content-Length: å†…å®¹çš„å­—èŠ‚é•¿åº¦ã€‚`'
- en: '`text: The extracted text content of the web page.`'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`text: ç½‘é¡µæå–çš„æ–‡æœ¬å†…å®¹ã€‚`'
- en: '`Note that some of these columns are specific to the WARC format and may not
    be present in other types of data.`'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`è¯·æ³¨æ„ï¼Œå…¶ä¸­ä¸€äº›åˆ—æ˜¯ç‰¹å®šäº WARC æ ¼å¼çš„ï¼Œå¯èƒ½åœ¨å…¶ä»–ç±»å‹çš„æ•°æ®ä¸­ä¸å­˜åœ¨ã€‚`'
- en: Itâ€™s done a fairly good job at guessing what these columns mean. Some of these
    may not be correct (e.g. Content-Length), but itâ€™s a helpful starting point. It
    may actually know these specific names thanks to its training data, but Iâ€™ve experimented
    around with arbitrary column names and it can usually guess what the column will
    contain from a combination of the name and data returned.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒåœ¨çŒœæµ‹è¿™äº›åˆ—çš„å«ä¹‰æ–¹é¢åšå¾—ç›¸å½“ä¸é”™ã€‚è™½ç„¶æœ‰äº›å¯èƒ½ä¸æ­£ç¡®ï¼ˆä¾‹å¦‚ Content-Lengthï¼‰ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„èµ·ç‚¹ã€‚å®ƒå¯èƒ½ç¡®å®çŸ¥é“è¿™äº›ç‰¹å®šåç§°ï¼Œå› ä¸ºå®ƒçš„è®­ç»ƒæ•°æ®ï¼Œä½†æˆ‘å·²ç»å°è¯•äº†ä»»æ„åˆ—åï¼Œå®ƒé€šå¸¸å¯ä»¥ä»åç§°å’Œè¿”å›çš„æ•°æ®çš„ç»„åˆä¸­çŒœæµ‹åˆ—å°†åŒ…å«ä»€ä¹ˆã€‚
- en: 'Now, it noticed there were missing values, so letâ€™s see how to deal with that:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œå®ƒæ³¨æ„åˆ°æœ‰ç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•å¤„ç†è¿™äº›é—®é¢˜ï¼š
- en: 'Prompt:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºï¼š
- en: '`Should we do something about the missing values?`'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`æˆ‘ä»¬åº”è¯¥å¯¹ç¼ºå¤±å€¼åšäº›ä»€ä¹ˆå—ï¼Ÿ`'
- en: 'Response:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å“åº”ï¼š
- en: '`Yes, it would be a good idea to handle the missing values in the Content-Length
    column. One option is to remove the rows that have missing values if they are
    not a significant portion of the data. Another option is to impute the missing
    values using some statistical method such as mean, median, or mode. However, the
    best approach would depend on the nature of the data and the analysis being performed.`'
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`æ˜¯çš„ï¼Œå¤„ç† Content-Length åˆ—ä¸­çš„ç¼ºå¤±å€¼æ˜¯ä¸ªå¥½ä¸»æ„ã€‚ä¸€ç§é€‰æ‹©æ˜¯åˆ é™¤é‚£äº›ç¼ºå¤±å€¼çš„è¡Œï¼Œå¦‚æœå®ƒä»¬ä¸æ˜¯æ•°æ®çš„é‡è¦éƒ¨åˆ†ã€‚å¦ä¸€ç§é€‰æ‹©æ˜¯ä½¿ç”¨ä¸€äº›ç»Ÿè®¡æ–¹æ³•ï¼ˆä¾‹å¦‚å‡å€¼ã€ä¸­ä½æ•°æˆ–ä¼—æ•°ï¼‰æ¥å¡«è¡¥ç¼ºå¤±å€¼ã€‚ç„¶è€Œï¼Œæœ€ä½³æ–¹æ³•å°†å–å†³äºæ•°æ®çš„æ€§è´¨å’Œæ‰€æ‰§è¡Œçš„åˆ†æã€‚`'
- en: These are the ways I would probably deal with it. In this case, Iâ€™m happy to
    just delete the entries since there arenâ€™tÂ tooÂ many.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¯èƒ½æ˜¯æˆ‘å¤„ç†å®ƒçš„æ–¹å¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘å¾ˆä¹æ„ç›´æ¥åˆ é™¤è¿™äº›æ¡ç›®ï¼Œå› ä¸ºæ•°é‡ä¸æ˜¯å¾ˆå¤šã€‚
- en: 'Prompt:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºï¼š
- en: '`Let''s just remove them as there are very few. How can I do that?`'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`æˆ‘ä»¬å°±å°†è¿™äº›åˆ é™¤ï¼Œå› ä¸ºæ•°é‡éå¸¸å°‘ã€‚æˆ‘è¯¥æ€ä¹ˆåšå‘¢ï¼Ÿ`'
- en: 'Response:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å“åº”ï¼š
- en: '`You can drop the rows containing missing values using the dropna() function
    in pandas. Here''s an example:`'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ä½ å¯ä»¥ä½¿ç”¨ pandas ä¸­çš„ dropna() å‡½æ•°åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼š`'
- en: ''
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`import pandas as pd`'
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`import pandas as pd`'
- en: ''
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`# create a dataframe`'
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`# åˆ›å»ºä¸€ä¸ªæ•°æ®æ¡†`'
- en: ''
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df = pd.DataFrame({''A'': [1, 2, None, 4], ''B'': [5, None, 7, 8]})`'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df = pd.DataFrame({''A'': [1, 2, None, 4], ''B'': [5, None, 7, 8]})`'
- en: ''
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`# drop rows with missing values`'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`# åˆ é™¤ç¼ºå¤±å€¼çš„è¡Œ`'
- en: ''
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`df.dropna(inplace=True) print(df)`'
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`df.dropna(inplace=True) print(df)`'
- en: ''
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`Output:`'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`è¾“å‡ºï¼š`'
- en: ''
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`A B 0 1.0 5.0 3 4.0 8.0`'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`A B 0 1.0 5.0 3 4.0 8.0`'
- en: ''
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`In this example, the dropna() function removes the second row which contains
    missing values. The inplace=True argument modifies the original DataFrame, so
    the resulting DataFrame only contains rows without any missing values.`'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œdropna() å‡½æ•°ä¼šåˆ é™¤ç¬¬äºŒè¡Œï¼Œè¯¥è¡ŒåŒ…å«ç¼ºå¤±å€¼ã€‚inplace=True å‚æ•°ä¼šä¿®æ”¹åŸå§‹æ•°æ®æ¡†ï¼Œå› æ­¤ç»“æœæ•°æ®æ¡†åªåŒ…å«æ²¡æœ‰ç¼ºå¤±å€¼çš„è¡Œã€‚`'
- en: Notice how it gives working code, and comments each line of the code. It also
    gives an explanation of what is happening at the end. This is great because we
    can learn whatâ€™s happening in the code, and if thereâ€™s anything we want to modify,
    itâ€™s a lot easier.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„å®ƒå¦‚ä½•æä¾›æœ‰æ•ˆçš„ä»£ç ï¼Œå¹¶å¯¹æ¯ä¸€è¡Œä»£ç è¿›è¡Œæ³¨é‡Šã€‚å®ƒè¿˜åœ¨æœ€åæä¾›äº†å‘ç”Ÿäº†ä»€ä¹ˆçš„è§£é‡Šã€‚è¿™å¾ˆå¥½ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥äº†è§£ä»£ç çš„è¿è¡Œæƒ…å†µï¼Œå¦‚æœæœ‰éœ€è¦ä¿®æ”¹çš„åœ°æ–¹ï¼Œä¹Ÿä¼šå˜å¾—å®¹æ˜“å¾—å¤šã€‚
- en: We can now get started with the first parts of the analysis.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å¯ä»¥å¼€å§‹åˆ†æçš„ç¬¬ä¸€éƒ¨åˆ†ã€‚
- en: Basic Analysis
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŸºæœ¬åˆ†æ
- en: Steps 3â€“5 are roughly the same, plot some distributions of data and see if thereâ€™s
    anything interesting there.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 3â€“5 å¤§è‡´ç›¸åŒï¼Œç»˜åˆ¶ä¸€äº›æ•°æ®åˆ†å¸ƒå›¾å¹¶æŸ¥çœ‹æ˜¯å¦æœ‰ä»»ä½•æœ‰è¶£çš„å‘ç°ã€‚
- en: 'When prompted to start step 3:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æç¤ºå¼€å§‹æ­¥éª¤ 3 æ—¶ï¼š
- en: '[PRE0]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And that outputs a graph for us. In this case, itâ€™s not very interesting as
    thereâ€™s actually only one â€œWARC-Typeâ€, but it was a nice idea. The issue with
    images is that itâ€™s hard to feed the results back to ChatGPT. I found that itâ€™s
    better to suggest ChatGPT to return tables of data to solve this, as well as additional
    plots where it makes sense.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·ä¼šä¸ºæˆ‘ä»¬è¾“å‡ºä¸€ä¸ªå›¾è¡¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›¾è¡¨å¹¶ä¸ç‰¹åˆ«æœ‰è¶£ï¼Œå› ä¸ºå®é™…ä¸Šåªæœ‰ä¸€ä¸ªâ€œWARC-Typeâ€ï¼Œä½†è¿™æ˜¯ä¸ªä¸é”™çš„ä¸»æ„ã€‚å›¾åƒçš„é—®é¢˜åœ¨äºå¾ˆéš¾å°†ç»“æœåé¦ˆç»™
    ChatGPTã€‚æˆ‘å‘ç°ï¼Œå»ºè®® ChatGPT è¿”å›æ•°æ®è¡¨ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ä¼šæ›´å¥½ï¼ŒåŒæ—¶åœ¨æœ‰æ„ä¹‰çš„åœ°æ–¹é™„ä¸Šé¢å¤–çš„å›¾è¡¨ã€‚
- en: 'After learning the column only has one value, ChatGPT is happy to move on to
    the next stage. When exploring the â€œWARC-Content-Languageâ€ we start to see something
    a little more complex. The results returned are:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: äº†è§£åˆ—ä¸­åªæœ‰ä¸€ä¸ªå€¼åï¼ŒChatGPT å¾ˆä¹æ„ç»§ç»­è¿›è¡Œä¸‹ä¸€é˜¶æ®µã€‚å½“æˆ‘ä»¬æ¢ç´¢â€œWARC-Content-Languageâ€æ—¶ï¼Œæˆ‘ä»¬å¼€å§‹çœ‹åˆ°ä¸€äº›æ›´å¤æ‚çš„ä¸œè¥¿ã€‚è¿”å›çš„ç»“æœæ˜¯ï¼š
- en: '`eng 15903`'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`eng 15903`'
- en: ''
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`rus 1551`'
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`rus 1551`'
- en: ''
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`...`'
  id: totrans-108
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`...`'
- en: ''
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`hrv,nno,bel 1`'
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`hrv,nno,bel 1`'
- en: ''
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`zul,eng 1`'
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`zul,eng 1`'
- en: 'Of which it learns:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ä¸­å­¦åˆ°çš„æ˜¯ï¼š
- en: '`It seems like there are 1187 unique values for the ''WARC-Identified-Content-Language''
    column, and the most common language is English (''eng'') followed by Russian
    (''rus''), German (''deu''), and Chinese (''zho''). Since there are so many unique
    values, it might be difficult to analyze the distribution of the variable. One
    approach to simplifying the analysis could be to group languages into broader
    categories, such as "English", "Romance languages", "Slavic languages", etc. depending
    on the research question.`'
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ä¼¼ä¹â€œWARC-Identified-Content-Languageâ€åˆ—æœ‰ 1187 ä¸ªç‹¬ç‰¹çš„å€¼ï¼Œæœ€å¸¸è§çš„è¯­è¨€æ˜¯è‹±è¯­ï¼ˆ''eng''ï¼‰ï¼Œå…¶æ¬¡æ˜¯ä¿„è¯­ï¼ˆ''rus''ï¼‰ã€å¾·è¯­ï¼ˆ''deu''ï¼‰å’Œä¸­æ–‡ï¼ˆ''zho''ï¼‰ã€‚ç”±äºæœ‰å¦‚æ­¤å¤šçš„ç‹¬ç‰¹å€¼ï¼Œåˆ†æå˜é‡çš„åˆ†å¸ƒå¯èƒ½ä¼šå¾ˆå›°éš¾ã€‚ç®€åŒ–åˆ†æçš„ä¸€ç§æ–¹æ³•å¯èƒ½æ˜¯å°†è¯­è¨€åˆ†ä¸ºæ›´å¹¿æ³›çš„ç±»åˆ«ï¼Œä¾‹å¦‚â€œè‹±è¯­â€ã€â€œç½—æ›¼è¯­ç³»è¯­è¨€â€ã€â€œæ–¯æ‹‰å¤«è¯­è¨€â€ç­‰ï¼Œå…·ä½“å–å†³äºç ”ç©¶é—®é¢˜ã€‚`'
- en: Itâ€™s a great point about grouping, but itâ€™s missed something here â€” each row
    can have multiple languages. When prompted about this (a few times), it comes
    up with a good approach.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºåˆ†ç»„çš„è§‚ç‚¹éå¸¸å¥½ï¼Œä½†è¿™é‡Œæœ‰é—æ¼â€”â€”æ¯è¡Œå¯ä»¥åŒ…å«å¤šç§è¯­è¨€ã€‚å½“å¤šæ¬¡è¯¢é—®è¿™ä¸ªé—®é¢˜æ—¶ï¼Œå®ƒæå‡ºäº†ä¸€ä¸ªå¾ˆå¥½çš„æ–¹æ³•ã€‚
- en: '[PRE1]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After combining this with some prompts about the language grouping, weâ€™re able
    to get out a nice plot:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¿™ä¸ä¸€äº›å…³äºè¯­è¨€åˆ†ç»„çš„æç¤ºç»“åˆåï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªä¸é”™çš„å›¾è¡¨ï¼š
- en: One thing I particularly like about this is that it is giving labels to the
    chart. It can be a little annoying to write out labels every time, but it does
    make a difference, so itâ€™s nice to see that itâ€™s smart enough to give sensible
    ones here.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç‰¹åˆ«å–œæ¬¢çš„ä¸€ç‚¹æ˜¯å®ƒç»™å›¾è¡¨æ·»åŠ äº†æ ‡ç­¾ã€‚æ¯æ¬¡éƒ½å†™æ ‡ç­¾å¯èƒ½æœ‰ç‚¹éº»çƒ¦ï¼Œä½†ç¡®å®ä¼šæœ‰åŒºåˆ«ï¼Œæ‰€ä»¥çœ‹åˆ°å®ƒè¶³å¤Ÿèªæ˜åœ°æä¾›åˆç†çš„æ ‡ç­¾æ˜¯å¾ˆä¸é”™çš„ã€‚
- en: Seems English is still the dominant language â€” by how much?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹èµ·æ¥è‹±è¯­ä»ç„¶æ˜¯ä¸»å¯¼è¯­è¨€â€”â€”ä¸»å¯¼ç¨‹åº¦å¦‚ä½•ï¼Ÿ
- en: 'Prompt:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºï¼š
- en: '`It looks like it''s mostly English language. Can you calculate what percentage
    of the agg data is english?`'
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`çœ‹èµ·æ¥ä¸»è¦æ˜¯è‹±è¯­ã€‚ä½ èƒ½è®¡ç®—ä¸€ä¸‹æ±‡æ€»æ•°æ®ä¸­è‹±è¯­çš„ç™¾åˆ†æ¯”å—ï¼Ÿ`'
- en: 'Response:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '`Sure, here''s some code to calculate the percentage of the aggregated data
    that is English: english_percentage = (agg_data.loc[''eng'', ''weight''] / agg_data[''weight''].sum())
    * 100`'
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`å½“ç„¶ï¼Œè¿™é‡Œæœ‰ä¸€äº›ä»£ç æ¥è®¡ç®—æ±‡æ€»æ•°æ®ä¸­è‹±è¯­çš„ç™¾åˆ†æ¯”ï¼šenglish_percentage = (agg_data.loc[''eng'', ''weight'']
    / agg_data[''weight''].sum()) * 100`'
- en: ''
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`print(f"The percentage of the aggregated data that is English is: {english_percentage:.2f}%")`'
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`print(f"The percentage of the aggregated data that is English is: {english_percentage:.2f}%")`'
- en: ''
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`This should output the percentage of the aggregated data that is English,
    rounded to 2 decimal places.`'
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`è¿™åº”è¯¥è¾“å‡ºæ±‡æ€»æ•°æ®ä¸­è‹±è¯­çš„ç™¾åˆ†æ¯”ï¼Œä¿ç•™åˆ°å°æ•°ç‚¹åä¸¤ä½ã€‚`'
- en: '![](../Images/97e45cc4ac8d41f1e2bc71e205b86932.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/97e45cc4ac8d41f1e2bc71e205b86932.png)'
- en: (Author created image)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆä½œè€…åˆ›å»ºçš„å›¾åƒï¼‰
- en: Natural Language Processing
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡ªç„¶è¯­è¨€å¤„ç†
- en: Now we can move on to step 6 which involves doing some exploration of the text
    column. This is going to be more analytics heavy and will require Natural Language
    Processing (NLP) techniques. Letâ€™s see how ChatGPT does.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿›å…¥ç¬¬6æ­¥ï¼Œè¿™æ¶‰åŠå¯¹æ–‡æœ¬åˆ—è¿›è¡Œä¸€äº›æ¢ç´¢ã€‚è¿™å°†æ›´æ³¨é‡åˆ†æï¼Œå¹¶éœ€è¦è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æŠ€æœ¯ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ChatGPTçš„è¡¨ç°ã€‚
- en: 'Prompt:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`Great. Let''s move on to step 6:`'
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`å¾ˆå¥½ã€‚æˆ‘ä»¬è¿›å…¥ç¬¬6æ­¥ï¼š`'
- en: ''
  id: totrans-134
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`"Explore the ''text'' column, including the distribution of text lengths and
    the most common words."`'
  id: totrans-135
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`"æ¢ç´¢â€œtextâ€åˆ—ï¼ŒåŒ…æ‹¬æ–‡æœ¬é•¿åº¦çš„åˆ†å¸ƒå’Œæœ€å¸¸è§çš„è¯æ±‡ã€‚"`'
- en: 'Response:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '[PRE2]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This yields:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå¦‚ä¸‹ï¼š
- en: '`[(''nan'', 36847), (''0'', 3467), (''1'', 2809), (''keresÅ‘optimalizÃ¡lÃ¡s'',
    2498), (''idÅ‘sgondozÃ¡s'', 1852), (''2'', 1740), (''3'', 1559), (''szerzÅ‘dÃ©s'',
    1529), (''eltartÃ¡si'', 1527), (''brands'', 1442), (''5'', 1362), (''4'', 1350),
    (''usd'', 1245), (''us'', 1205), (''2023'', 1204), (''new'', 1178), (''sex'',
    1165), (''2022'', 1031), (''home'', 919), (''cookies'', 904)]`'
  id: totrans-139
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`[(''nan'', 36847), (''0'', 3467), (''1'', 2809), (''keresÅ‘optimalizÃ¡lÃ¡s'',
    2498), (''idÅ‘sgondozÃ¡s'', 1852), (''2'', 1740), (''3'', 1559), (''szerzÅ‘dÃ©s'',
    1529), (''eltartÃ¡si'', 1527), (''brands'', 1442), (''5'', 1362), (''4'', 1350),
    (''usd'', 1245), (''us'', 1205), (''2023'', 1204), (''new'', 1178), (''sex'',
    1165), (''2022'', 1031), (''home'', 919), (''cookies'', 904)]`'
- en: I wasnâ€™t very happy with this, as we can see that a lot of the â€˜top wordsâ€™ are
    just numbers, or stopwords from another language (it only used English ones).
    I was able to prod it on this, and it helped clean it up by filtering out words
    which were non-alphabetic tokens and including stopword lists for other languages.
    Now letâ€™s visualise these in a Wordcloud.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯¹æ­¤ä¸æ˜¯å¾ˆæ»¡æ„ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¾ˆå¤šâ€œå¸¸è§è¯æ±‡â€åªæ˜¯æ•°å­—ï¼Œæˆ–è€…æ˜¯å…¶ä»–è¯­è¨€çš„åœç”¨è¯ï¼ˆå®ƒåªä½¿ç”¨äº†è‹±è¯­åœç”¨è¯ï¼‰ã€‚æˆ‘èƒ½å¤Ÿåœ¨è¿™æ–¹é¢è¿›è¡Œè°ƒæ•´ï¼Œé€šè¿‡è¿‡æ»¤æ‰éå­—æ¯å­—ç¬¦çš„è¯æ±‡å’ŒåŒ…æ‹¬å…¶ä»–è¯­è¨€çš„åœç”¨è¯åˆ—è¡¨æ¥å¸®åŠ©æ¸…ç†æ•°æ®ã€‚ç°åœ¨è®©æˆ‘ä»¬åœ¨è¯äº‘ä¸­å¯è§†åŒ–è¿™äº›æ•°æ®ã€‚
- en: 'Prompt:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`Can you make it a wordcloud?`'
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ä½ èƒ½åˆ¶ä½œä¸€ä¸ªè¯äº‘å—ï¼Ÿ`'
- en: 'Response:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '[PRE3]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/f2578e3bf779c3c2340e134247601bd0.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2578e3bf779c3c2340e134247601bd0.png)'
- en: 'WARNING: contains explicit language. For those who are wondering, â€œkeresÅ‘optimalizÃ¡lÃ¡sâ€
    is Hungarian for â€œSearch engine optimizationâ€ (author created image).'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: è­¦å‘Šï¼šåŒ…å«æ˜æ˜¾çš„è¯­è¨€ã€‚å¯¹äºé‚£äº›å¥½å¥‡çš„äººï¼Œâ€œkeresÅ‘optimalizÃ¡lÃ¡sâ€æ˜¯åŒˆç‰™åˆ©è¯­ä¸­çš„â€œæœç´¢å¼•æ“ä¼˜åŒ–â€ï¼ˆä½œè€…åˆ›å»ºçš„å›¾åƒï¼‰ã€‚
- en: 'Iâ€™m not sure what to take away from this plot. It seems there are some words
    which could have useful content associated with them (e.g â€œinformationâ€, â€œblogâ€,
    â€œbrandsâ€), but there is also a lot of undesirable content. I shared the top words
    to ChatGPT and asked what it thought:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ç¡®å®šä»è¿™ä¸ªå›¾ä¸­èƒ½å¾—åˆ°ä»€ä¹ˆã€‚ä¼¼ä¹æœ‰ä¸€äº›è¯å¯èƒ½å…³è”æœ‰ç”¨çš„å†…å®¹ï¼ˆä¾‹å¦‚â€œä¿¡æ¯â€ã€â€œåšå®¢â€ã€â€œå“ç‰Œâ€ï¼‰ï¼Œä½†ä¹Ÿæœ‰å¾ˆå¤šä¸éœ€è¦çš„å†…å®¹ã€‚æˆ‘å°†è¿™äº›å¸¸è§è¯æ±‡åˆ†äº«ç»™ChatGPTå¹¶è¯¢é—®å®ƒçš„çœ‹æ³•ï¼š
- en: 'Prompt:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 'Prompt:'
- en: '`What can we say about this?`'
  id: totrans-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`æˆ‘ä»¬å¯¹æ­¤å¯ä»¥è¯´äº›ä»€ä¹ˆï¼Ÿ`'
- en: 'Response:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response:'
- en: '`Based on the top words found in the ''text'' column, it appears that the data
    may contain a lot of spam or irrelevant information, as many of the top words
    are related to online dating, reviews, loans, and escorts. Additionally, the presence
    of words like ''nan'' suggests that there may be missing or incomplete data in
    the ''text'' column. It would be important to further investigate the nature and
    quality of the data in the ''text'' column to determine how useful it is for any
    downstream analysis.`'
  id: totrans-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`æ ¹æ®â€œtextâ€åˆ—ä¸­å‘ç°çš„å¸¸è§è¯æ±‡ï¼Œæ•°æ®å¯èƒ½åŒ…å«å¾ˆå¤šåƒåœ¾ä¿¡æ¯æˆ–ä¸ç›¸å…³çš„ä¿¡æ¯ï¼Œå› ä¸ºè®¸å¤šå¸¸è§è¯æ±‡ä¸åœ¨çº¿çº¦ä¼šã€è¯„è®ºã€è´·æ¬¾å’Œé™ªç©ç›¸å…³ã€‚æ­¤å¤–ï¼Œåƒâ€œnanâ€è¿™æ ·çš„è¯æ±‡è¡¨æ˜â€œtextâ€åˆ—ä¸­å¯èƒ½æœ‰ç¼ºå¤±æˆ–ä¸å®Œæ•´çš„æ•°æ®ã€‚è¿›ä¸€æ­¥è°ƒæŸ¥â€œtextâ€åˆ—çš„æ•°æ®æ€§è´¨å’Œè´¨é‡å¯¹äºç¡®å®šå…¶åœ¨åç»­åˆ†æä¸­çš„æœ‰ç”¨æ€§æ˜¯é‡è¦çš„ã€‚`'
- en: Thatâ€™s a fair conclusion to make, and indeed, companies that work with the Common
    Crawl dataset have stated that they invest considerable resources cleaning up
    the dataset to make it usable for training AI models.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ä¸ªåˆç†çš„ç»“è®ºï¼Œå®é™…ä¸Šï¼Œä¸Common Crawlæ•°æ®é›†åˆä½œçš„å…¬å¸ç¡®å®è¡¨ç¤ºï¼Œä»–ä»¬æŠ•å…¥äº†å¤§é‡èµ„æºæ¥æ¸…ç†æ•°æ®é›†ï¼Œä»¥ä½¿å…¶é€‚åˆè®­ç»ƒAIæ¨¡å‹ã€‚
- en: Wrapping Up
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Wrapping Up
- en: This concludes the plan outlined by ChatGPT, so weâ€™ll wrap up the analysis here
    and see what findings it has.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±ç»“æŸäº†ChatGPTæ¦‚è¿°çš„è®¡åˆ’ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†åœ¨è¿™é‡Œç»“æŸåˆ†æï¼Œå¹¶æŸ¥çœ‹å®ƒæœ‰ä»€ä¹ˆå‘ç°ã€‚
- en: 'Prompt:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºï¼š
- en: '`Great. Let''s move on to step 8\. Can you summarise the findings from all
    our analysis so far?`'
  id: totrans-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`å¾ˆå¥½ã€‚è®©æˆ‘ä»¬ç»§ç»­ç¬¬8æ­¥ã€‚ä½ èƒ½æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬è¿„ä»Šä¸ºæ­¢çš„æ‰€æœ‰åˆ†æç»“æœå—ï¼Ÿ`'
- en: 'Response:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å›å¤ï¼š
- en: '`Sure, based on the analysis we have conducted so far, here are some key findings:
    Language distribution: The most common language in the dataset is English, followed
    by Russian, German, Chinese, and Spanish. Content-Type distribution: The majority
    of the content in the dataset is of the type "text/plain". Text length: The text
    length in the dataset ranges from 0 to 8,542,524, with an average length of 20,566\.
    Common words: The most frequent words in the dataset are not particularly informative,
    as they include many stop words and other non-informative terms. Correlations:
    There is a strong positive correlation between the length of the text and the
    content length. There is also a weak positive correlation between the number of
    languages detected in a text and the content length.`'
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`å½“ç„¶ï¼ŒåŸºäºæˆ‘ä»¬ç›®å‰è¿›è¡Œçš„åˆ†æï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å…³é”®å‘ç°ï¼šè¯­è¨€åˆ†å¸ƒï¼šæ•°æ®é›†ä¸­æœ€å¸¸è§çš„è¯­è¨€æ˜¯è‹±è¯­ï¼Œå…¶æ¬¡æ˜¯ä¿„è¯­ã€å¾·è¯­ã€ä¸­æ–‡å’Œè¥¿ç­ç‰™è¯­ã€‚å†…å®¹ç±»å‹åˆ†å¸ƒï¼šæ•°æ®é›†ä¸­å¤§å¤šæ•°å†…å®¹ç±»å‹ä¸º"text/plain"ã€‚æ–‡æœ¬é•¿åº¦ï¼šæ•°æ®é›†ä¸­ï¼Œæ–‡æœ¬é•¿åº¦èŒƒå›´ä»0åˆ°8,542,524ï¼Œå¹³å‡é•¿åº¦ä¸º20,566ã€‚å¸¸è§è¯ï¼šæ•°æ®é›†ä¸­æœ€é¢‘ç¹çš„è¯æ±‡å¹¶ä¸ç‰¹åˆ«æœ‰ä¿¡æ¯é‡ï¼Œå› ä¸ºå®ƒä»¬åŒ…å«è®¸å¤šåœç”¨è¯å’Œå…¶ä»–éä¿¡æ¯æ€§æœ¯è¯­ã€‚ç›¸å…³æ€§ï¼šæ–‡æœ¬é•¿åº¦ä¸å†…å®¹é•¿åº¦ä¹‹é—´å­˜åœ¨å¼ºæ­£ç›¸å…³ã€‚æ£€æµ‹åˆ°çš„è¯­è¨€æ•°é‡ä¸å†…å®¹é•¿åº¦ä¹‹é—´ä¹Ÿå­˜åœ¨å¼±æ­£ç›¸å…³ã€‚`'
- en: If a data analyst came to me with this, Iâ€™d be pretty disappointed. As mentioned
    at the start, there are some columns it could have analysed in more detailed,
    and itâ€™s generally better to make some suggestions for next steps. However, we
    never gave it a goal for the analysis, nor told it to give us suggestions so Iâ€™m
    not going to penalise it too much.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæœ‰æ•°æ®åˆ†æå¸ˆå¸¦ç€è¿™äº›å†…å®¹æ¥æ‰¾æˆ‘ï¼Œæˆ‘ä¼šæ„Ÿåˆ°éå¸¸å¤±æœ›ã€‚æ­£å¦‚å¼€å§‹æ—¶æåˆ°çš„ï¼Œæœ‰ä¸€äº›åˆ—æ•°æ®å¯ä»¥åˆ†æå¾—æ›´è¯¦ç»†ï¼Œå¹¶ä¸”é€šå¸¸æ›´å¥½çš„æ˜¯æå‡ºä¸€äº›ä¸‹ä¸€æ­¥çš„å»ºè®®ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä»æœªç»™å®ƒè®¾å®šåˆ†æçš„ç›®æ ‡ï¼Œä¹Ÿæ²¡å‘Šè¯‰å®ƒç»™å‡ºå»ºè®®ï¼Œæ‰€ä»¥æˆ‘ä¸ä¼šå¤ªè¿‡è‹›è´£ã€‚
- en: Discussion
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®¨è®º
- en: 'As you can see, the prompting used throughout was relatively simple. Given
    that, itâ€™s impressive at how well ChatGPT was able to understand what I wanted
    done and give useful answers. These prompts could definitely be improved by providing
    more context in each prompt and being stricter on what we want back. For example,
    each prompt could contain references to the specific task it is focusing on, as
    well as additional text to have it do exactly what we want:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚ä½ æ‰€è§ï¼Œæ•´ä¸ªè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æç¤ºç›¸å¯¹ç®€å•ã€‚è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼ŒChatGPTèƒ½å¤Ÿå¾ˆå¥½åœ°ç†è§£æˆ‘æƒ³è¦çš„å¹¶ç»™å‡ºæœ‰ç”¨çš„å›ç­”ï¼Œè¿™ä¸€ç‚¹ä»¤äººå°è±¡æ·±åˆ»ã€‚è¿™äº›æç¤ºå¯ä»¥é€šè¿‡åœ¨æ¯ä¸ªæç¤ºä¸­æä¾›æ›´å¤šä¸Šä¸‹æ–‡ä»¥åŠå¯¹æˆ‘ä»¬å¸Œæœ›è¿”å›çš„å†…å®¹æ›´ä¸¥æ ¼æ¥æ”¹è¿›ã€‚ä¾‹å¦‚ï¼Œæ¯ä¸ªæç¤ºå¯ä»¥åŒ…å«å¯¹å…¶ä¸“æ³¨çš„å…·ä½“ä»»åŠ¡çš„å¼•ç”¨ï¼Œä»¥åŠé¢å¤–çš„æ–‡æœ¬ä»¥ç¡®ä¿å…¶åšæˆ‘ä»¬æƒ³è¦çš„ï¼š
- en: '`Donâ€™t respond with superfluous text. Assume pandas, numpy and matplotlib have
    been imported in the standard way.`'
  id: totrans-162
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ä¸è¦å›åº”å¤šä½™çš„æ–‡æœ¬ã€‚å‡è®¾pandasã€numpyå’Œmatplotlibå·²æŒ‰æ ‡å‡†æ–¹å¼å¯¼å…¥ã€‚`'
- en: These could be maintained in your own set of prompt templates to speed up this
    sort of work, or done with a tool such as [LangChain](https://python.langchain.com/en/latest/index.html).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å¯ä»¥ä¿å­˜åœ¨ä½ è‡ªå·±çš„æç¤ºæ¨¡æ¿ä¸­ä»¥åŠ å¿«è¿™ç±»å·¥ä½œçš„è¿›åº¦ï¼Œæˆ–è€…ä½¿ç”¨è¯¸å¦‚[LangChain](https://python.langchain.com/en/latest/index.html)è¿™æ ·çš„å·¥å…·æ¥å®Œæˆã€‚
- en: We could also define our own overall template. I let ChatGPT come up with a
    plan, but it wasnâ€™t perfect. We could define an overall structure for it to follow,
    and a standard way to e.g. analyse each variable. With templates, ChatGPT is less
    likely to miss insights in such an analysis.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥å®šä¹‰è‡ªå·±çš„æ€»ä½“æ¨¡æ¿ã€‚æˆ‘è®©ChatGPTæå‡ºä¸€ä¸ªè®¡åˆ’ï¼Œä½†å®ƒå¹¶ä¸å®Œç¾ã€‚æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªæ€»ä½“ç»“æ„ä¾›å…¶éµå¾ªï¼Œä»¥åŠåˆ†ææ¯ä¸ªå˜é‡çš„æ ‡å‡†æ–¹æ³•ã€‚é€šè¿‡æ¨¡æ¿ï¼ŒChatGPTåœ¨è¿™ç§åˆ†æä¸­é—æ¼æ´å¯Ÿçš„å¯èƒ½æ€§è¾ƒå°ã€‚
- en: While it was fun going back and forth with ChatGPT to get data outputs to it,
    it quickly became tiring. ChatGPT is much more powerful when it can run the code
    directly itself. ChatGPT can connected to a Python runtime by instead working
    with the [Python API](https://medium.com/geekculture/a-simple-guide-to-chatgpt-api-with-python-c147985ae28).
    In this case, the code could be run automatically, but to cut the human out of
    the loop weâ€™ll need one more tool.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ä¸ChatGPTåå¤äº¤æµä»¥è·å–æ•°æ®è¾“å‡ºå¾ˆæœ‰è¶£ï¼Œä½†å¾ˆå¿«å˜å¾—ç–²æƒ«ã€‚ChatGPTåœ¨èƒ½å¤Ÿç›´æ¥è¿è¡Œä»£ç æ—¶æ›´ä¸ºå¼ºå¤§ã€‚ChatGPTå¯ä»¥é€šè¿‡ä½¿ç”¨[Python
    API](https://medium.com/geekculture/a-simple-guide-to-chatgpt-api-with-python-c147985ae28)è¿æ¥åˆ°Pythonè¿è¡Œæ—¶ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»£ç å¯ä»¥è‡ªåŠ¨è¿è¡Œï¼Œä½†è¦å°†äººä»å¾ªç¯ä¸­å‰”é™¤ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªé¢å¤–çš„å·¥å…·ã€‚
- en: AutoGPT has been very popular in the last month as a power-up to ChatGPT which
    effectively provides a guide to ChatGPT agents which allows them to keep executing
    towards some goal. AutoGPT could replace me in this situation, asking ChatGPT
    agents to design code, then executing it, feeding the results back to ChatGPT,
    proceeding until it has a detailed analysis. It would also interface with a memory
    database which would allow it to execute much larger analyses.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿‡å»ä¸€ä¸ªæœˆé‡Œï¼ŒAutoGPT ä½œä¸º ChatGPT çš„å¢å¼ºå·¥å…·éå¸¸å—æ¬¢è¿ï¼Œå®ƒæœ‰æ•ˆåœ°ä¸º ChatGPT ä»£ç†æä¾›äº†æŒ‡å—ï¼Œå…è®¸ä»–ä»¬æŒç»­æœç€æŸä¸ªç›®æ ‡æ‰§è¡Œã€‚AutoGPT
    å¯ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹å–ä»£æˆ‘ï¼Œè®© ChatGPT ä»£ç†è®¾è®¡ä»£ç ï¼Œç„¶åæ‰§è¡Œå®ƒï¼Œå°†ç»“æœåé¦ˆç»™ ChatGPTï¼Œç›´åˆ°å®ƒå¾—åˆ°è¯¦ç»†çš„åˆ†æã€‚å®ƒè¿˜å°†ä¸ä¸€ä¸ªå†…å­˜æ•°æ®åº“æ¥å£ï¼Œä»è€Œå…è®¸å®ƒæ‰§è¡Œæ›´å¤§è§„æ¨¡çš„åˆ†æã€‚
- en: With a tool like AutoGPT we can set a clear goal with requirements such as detail
    of analysis and expected conclusion style. In this case, we can check in less
    regularly with the outcomes and eventually have to do little work to get a decent
    analysis out.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨åƒ AutoGPT è¿™æ ·çš„å·¥å…·ï¼Œæˆ‘ä»¬å¯ä»¥è®¾å®šä¸€ä¸ªæ˜ç¡®çš„ç›®æ ‡ï¼ŒåŒ…æ‹¬åˆ†æçš„ç»†èŠ‚å’ŒæœŸæœ›çš„ç»“è®ºé£æ ¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥è¾ƒå°‘åœ°æ£€æŸ¥ç»“æœï¼Œå¹¶æœ€ç»ˆå¾ˆå°‘éœ€è¦å·¥ä½œå³å¯å¾—åˆ°ä¸€ä¸ªä¸é”™çš„åˆ†æã€‚
- en: Finally, we should call out that ChatGPT is far from â€˜perfectâ€™ and even in this
    mock analysis, I had to massage the prompts to get an answer that was close to
    what I wanted. It was a lot less difficult than I expected, but still worth noting.
    It created some code that had errors, though it managed to fix the errors every
    time it was told. At times it created code that I wouldnâ€™t have wanted to run,
    and I needed to suggest it follow a different path, but again, upon prompting
    it could come up with a decent solution.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬åº”è¯¥æŒ‡å‡º ChatGPT è¿œæœªè¾¾åˆ°â€œå®Œç¾â€ï¼Œå³ä¾¿åœ¨è¿™æ¬¡æ¨¡æ‹Ÿåˆ†æä¸­ï¼Œæˆ‘ä¹Ÿéœ€è¦è°ƒæ•´æç¤ºï¼Œä»¥è·å¾—æ¥è¿‘æˆ‘æƒ³è¦çš„ç­”æ¡ˆã€‚è™½ç„¶è¿™æ¯”æˆ‘é¢„æœŸçš„è¦å®¹æ˜“å¾—å¤šï¼Œä½†ä»ç„¶å€¼å¾—æ³¨æ„ã€‚å®ƒåˆ›å»ºäº†ä¸€äº›æœ‰é”™è¯¯çš„ä»£ç ï¼Œå°½ç®¡æ¯æ¬¡è¢«å‘ŠçŸ¥åéƒ½èƒ½ä¿®å¤è¿™äº›é”™è¯¯ã€‚æœ‰æ—¶å®ƒåˆ›å»ºçš„ä»£ç æ˜¯æˆ‘ä¸æƒ³è¿è¡Œçš„ï¼Œæˆ‘éœ€è¦å»ºè®®å®ƒé‡‡ç”¨ä¸åŒçš„æ–¹æ³•ï¼Œä½†å†æ¬¡æç¤ºåï¼Œå®ƒèƒ½å¤Ÿæå‡ºä¸€ä¸ªä¸é”™çš„è§£å†³æ–¹æ¡ˆã€‚
- en: Conclusion
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In this article, weâ€™ve seen how ChatGPT can be used to support the running of
    an Exploratory Data Analysis (EDA). Weâ€™ve seen that weâ€™re able to get surprisingly
    good results working with the system, with little exterior help. We also noted
    that there are already tools which allow us to extend this idea such as AutoGPT
    which could make an even more powerful assistant.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ° ChatGPT å¦‚ä½•ç”¨äºæ”¯æŒæ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰çš„è¿è¡Œã€‚æˆ‘ä»¬å‘ç°ï¼Œä¸ç³»ç»Ÿåˆä½œæ—¶èƒ½å¤Ÿè·å¾—æ„æƒ³ä¸åˆ°çš„è‰¯å¥½ç»“æœï¼Œå‡ ä¹ä¸éœ€è¦å¤–éƒ¨å¸®åŠ©ã€‚æˆ‘ä»¬è¿˜æ³¨æ„åˆ°ï¼Œå·²ç»å­˜åœ¨ä¸€äº›å·¥å…·å¯ä»¥æ‰©å±•è¿™ä¸€æƒ³æ³•ï¼Œä¾‹å¦‚
    AutoGPTï¼Œå®ƒå¯èƒ½æˆä¸ºä¸€ä¸ªæ›´å¼ºå¤§çš„åŠ©æ‰‹ã€‚
- en: As a data analyst, Iâ€™m already using ChatGPT to help with my analytics in some
    of the ways described above, though I rarely use it for an end-to-end analysis
    as detailed in this article. As more integrations are built out with tools like
    AutoGPT, and the friction to use is reduced, I expect to be using it more and
    more and am very much excited for it (while Iâ€™m not made obsolete ;) ).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€åæ•°æ®åˆ†æå¸ˆï¼Œæˆ‘å·²ç»åœ¨ä½¿ç”¨ ChatGPT å¸®åŠ©æˆ‘çš„åˆ†æï¼Œå°½ç®¡æˆ‘å¾ˆå°‘ä½¿ç”¨å®ƒè¿›è¡Œæœ¬æ–‡ä¸­è¯¦ç»†æè¿°çš„ç«¯åˆ°ç«¯åˆ†æã€‚éšç€åƒ AutoGPT è¿™æ ·çš„å·¥å…·çš„æ›´å¤šé›†æˆï¼Œä»¥åŠä½¿ç”¨æ‘©æ“¦çš„å‡å°‘ï¼Œæˆ‘é¢„è®¡ä¼šè¶Šæ¥è¶Šå¤šåœ°ä½¿ç”¨å®ƒï¼Œå¹¶ä¸”å¯¹æ­¤éå¸¸æœŸå¾…ï¼ˆè™½ç„¶æˆ‘ä¸ä¼šè¢«å–ä»£
    ;) ï¼‰ã€‚
