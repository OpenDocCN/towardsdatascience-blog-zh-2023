- en: Decoding Auto-GPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解码Auto-GPT
- en: 原文：[https://towardsdatascience.com/decoding-auto-gpt-fae16ff1ee75](https://towardsdatascience.com/decoding-auto-gpt-fae16ff1ee75)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/decoding-auto-gpt-fae16ff1ee75](https://towardsdatascience.com/decoding-auto-gpt-fae16ff1ee75)
- en: The Mechanics of an **Autonomous** GPT-4
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**自主**GPT-4的机制'
- en: '[](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)[![Maarten
    Grootendorst](../Images/58e24b9cf7e10ff1cd5ffd75a32d1a26.png)](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)
    [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)[![Maarten
    Grootendorst](../Images/58e24b9cf7e10ff1cd5ffd75a32d1a26.png)](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)
    [Maarten Grootendorst](https://medium.com/@maartengrootendorst?source=post_page-----fae16ff1ee75--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)
    ·8 min read·Aug 8, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----fae16ff1ee75--------------------------------)
    ·阅读时间8分钟·2023年8月8日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/ccce7f423325fb2990f06b6a85bc947e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccce7f423325fb2990f06b6a85bc947e.png)'
- en: There have been many interesting, complex, and innovative solutions since the
    release of ChatGPT. The community has explored countless possibilities for improving
    its capabilities.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 自ChatGPT发布以来，出现了许多有趣、复杂和创新的解决方案。社区探索了无数改进其能力的可能性。
- en: One of those is the well-known [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)
    package. With more than **140k stars**, it is one of the highest-ranking repositories
    on Github!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 其中之一是著名的[Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)包。它拥有超过**14万**个星标，是Github上排名最高的仓库之一！
- en: '![](../Images/47bcc2b61fc850759406607d46b2e448.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47bcc2b61fc850759406607d46b2e448.png)'
- en: Auto-GPT’s number of stars on Github. Retrieved from star-history.com
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT在Github上的星标数量。数据来源于star-history.com
- en: Auto-GPT is an attempt at making GPT-4 fully **autonomous**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT尝试使GPT-4完全**自主**。
- en: Auto-GPT gives GPT-4 the power to make its own decisions
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Auto-GPT赋予GPT-4自己做决定的能力
- en: It sounds incredible and it definitely is! But how does it work?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来令人难以置信，确实如此！但它是如何工作的呢？
- en: In this post, we will go through Auto-GPT’s architecture and explore how it
    can reach autonomous behavior.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们将探讨Auto-GPT的架构，并探索它如何实现自主行为。
- en: The Architecture
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构
- en: Auto-GPT has an overall architecture, or a main loop of sorts, that it uses
    to model autonomous behavior.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT具有一个整体架构，或者说是一种主要循环，用于建模自主行为。
- en: 'Let’s start by describing this overall after which we will go through each
    step in-depth:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先描述这个整体架构，然后我们将深入探讨每个步骤：
- en: '![](../Images/0b5f05f9f213c9fd03d615fed94a6648.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b5f05f9f213c9fd03d615fed94a6648.png)'
- en: The main cyclical loop that describes Auto-GPT main’s autonomous behavioral
    mechanism.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 描述Auto-GPT主要自主行为机制的主要循环。
- en: 'The core of Auto-GPT is a cyclical sequence of steps:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT的核心是一个循环步骤序列：
- en: Initialize the **prompt** with summarized information
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用总结的信息初始化**提示**。
- en: GPT-4 proposes an **action**
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPT-4提出一个**行动**方案
- en: The action is **executed**
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 行动被**执行**。
- en: '**Embed** both the input and output of this cycle'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入**这个循环的输入和输出'
- en: Save embeddings to a **vector database**
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将嵌入保存到**向量数据库**中
- en: These 5 steps make up the core of Auto-GPT and represent its main autonomous
    behavior.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这5个步骤构成了Auto-GPT的核心，并代表了它的主要自主行为。
- en: Before we go through each step in-depth, there is a step before this cyclical
    sequence, namely **initializing the agent**.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨每个步骤之前，还有一个步骤是在这个循环序列之前，即**初始化代理**。
- en: 0\. Initializing the Agent
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 0\. 初始化代理
- en: Before Auto-GPT completes a task fully autonomous, it first needs to initialize
    an **Agent**. This agent essentially describes who GPT-4 is and what goal it should
    pursue
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在Auto-GPT完全自主完成任务之前，它首先需要初始化一个**代理**。这个代理基本上描述了GPT-4的身份以及它应该追求的目标。
- en: Let’s say that we want Auto-GPT to create a **recipe for vegan chocolate**.
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 假设我们希望Auto-GPT创建一个**素食巧克力配方**。
- en: 'With that goal in mind, we need to give GPT-4 a bit of context about what an
    agent should be and what it should achieve:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个目标，我们需要给GPT-4一些关于代理应该是什么以及应该实现什么的背景信息：
- en: '![](../Images/8501a4534e2d7a1f8b5225d99593e41c.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8501a4534e2d7a1f8b5225d99593e41c.png)'
- en: 'Prompt: Create sub-goals and a name for our Agent.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：为我们的代理创建子目标和名称。
- en: 'We create a prompt defining two things:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个定义两个方面的提示：
- en: Create **5 highly effective goals** (these can be updated later on)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建**5个高效目标**（这些目标可以稍后更新）
- en: Create an appropriate **role-based name** (_GPT)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个合适的**基于角色的名称**（_GPT）
- en: The name helps GPT-4 to continuously remember what it should model. The sub-goals
    are especially helpful to make small tasks for it to achieve.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 名称有助于GPT-4持续记住它应该建模的内容。子目标特别有助于创建小任务供其完成。
- en: 'Next, we give an example of what the desired output should be:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们提供一个期望输出的示例：
- en: '![](../Images/561098a39fbbf7494190604c759d992f.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/561098a39fbbf7494190604c759d992f.png)'
- en: 'Prompt: GPT-4 works much better if we provide it with an example of the desired
    output.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：如果我们提供一个期望输出的示例，GPT-4的效果会更好。
- en: Giving examples to any generative Large Language Model works really well. By
    describing what the output should look like, it more easily generates accurate
    answers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 向任何生成型大语言模型提供示例效果很好。通过描述输出应该是什么样的，它可以更容易生成准确的答案。
- en: 'When we pass this prompt to GPT-4 using Auto-GPT, we get the following response:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用Auto-GPT将此提示传递给GPT-4时，我们得到以下响应：
- en: '![](../Images/d970a4adac0e66e1d2b807d2a680f10f.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d970a4adac0e66e1d2b807d2a680f10f.png)'
- en: GPT-4 created a description of **RecipeGPT** for us!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4为我们创建了**RecipeGPT**的描述！
- en: It seems that GPT-4 has created a description of **RecipeGPT** for us. We can
    give this context to GPT-4 as a **system prompt** so that it continuously remembers
    its purpose.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来GPT-4为我们创建了**RecipeGPT**的描述。我们可以将这个背景提供给GPT-4作为**系统提示**，以便它持续记住其目标。
- en: Now that Auto-GPT has created a description of its agent, along with clear goals,
    it can start by taking its first autonomous action.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在Auto-GPT已经创建了其代理的描述，并设定了明确的目标，它可以开始执行其第一个自主行动。
- en: 1\. First Prompt
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 首次提示
- en: The very first step in its cyclical sequence is creating the prompt that triggers
    an action.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 其循环序列中的第一步是创建触发操作的提示。
- en: '![](../Images/11f292d65655d4fa7ed8cbc8348f9a08.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11f292d65655d4fa7ed8cbc8348f9a08.png)'
- en: The first step in Auto-GPT’s autonomous cycle. We ask GPT-4 to use a single
    command based on a system prompt and a summary of events that happened in the
    past.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT自主周期中的第一步。我们要求GPT-4使用基于系统提示和过去事件总结的单一命令。
- en: 'The prompt consists of three components:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 提示由三个组件组成：
- en: System Prompt
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统提示
- en: Summary
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总结
- en: Call to Action
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行动召唤
- en: We will go into the summary a bit later but the call to action is nothing more
    than asking GPT-4 which command it should use. The commands GPT-4 can use are
    defined in its **System Prompt**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会深入总结，但行动召唤无非是询问GPT-4应使用哪个命令。GPT-4可以使用的命令在其**系统提示**中定义。
- en: System Prompt
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 系统提示
- en: The system prompt is the context that we give to GPT-4 so that it remembers
    certain guidelines that it should follow.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 系统提示是我们给GPT-4的背景信息，以便它记住应该遵循的某些指南。
- en: '![](../Images/024e942b605d6147de555b6abea2c401.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/024e942b605d6147de555b6abea2c401.png)'
- en: The format of the system prompt.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 系统提示的格式。
- en: 'As shown above, it consists of **six guidelines**:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，它包含**六项指南**：
- en: The goals and description of the initialized **Agent**
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化**代理**的目标和描述
- en: '**Constrains** it should adhere to'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**约束**它应该遵守'
- en: '**Commands** it can use'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命令**它可以使用'
- en: '**Resources** it has access to'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源**它可以访问'
- en: '**Evaluation** steps'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估**步骤'
- en: Example of a valid **JSON** output
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有效**JSON**输出的示例
- en: The last five steps are essentially constraints the Agent should adhere to.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后五个步骤本质上是代理应该遵守的约束条件。
- en: 'Here is a more in-depth overview of what these guidelines and constraints generally
    look like:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是这些指南和约束的一种更深入的概述：
- en: '![](../Images/68a2472fee1ebf891ddde6670d773b3d.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68a2472fee1ebf891ddde6670d773b3d.png)'
- en: The constraints that are given in the system prompt.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 系统提示中给定的约束条件。
- en: As you can see, the system prompt sketches the boundaries in which GPT-4 can
    act. For example, in *“Resources”,* it describes that GPT-4 can use GPT-3.5 Agents
    for the delegation of simple tasks. Similarly, *“Evaluation,”* tells GPT-4 that
    it should continuously self-criticize its own behavior to improve upon its next
    actions.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，系统提示勾画了 GPT-4 可以行动的边界。例如，在*“资源”*中，它描述了 GPT-4 可以使用 GPT-3.5 代理来委派简单任务。类似地，*“评估”*
    告诉 GPT-4 它应不断自我批评自己的行为，以改进下一步行动。
- en: Example of the First Prompt
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一个提示的示例
- en: 'Together, the very first prompt looks a bit like the following:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始的提示大致如下所示：
- en: '![](../Images/3fa3a09bac37d892796ec859bd373dec.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fa3a09bac37d892796ec859bd373dec.png)'
- en: 'The full first prompt. Note the three components: System prompt, summary, and
    call to action.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的第一个提示。注意三个组成部分：系统提示、总结和行动呼吁。
- en: Notice that in blue *“I was created”* is mentioned. Typically, this would contain
    a summary of all the actions it has taken. Since it was just created, it has no
    action taken before and the summary is nothing more than *“I was created”*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到蓝色的 *“我被创建”* 提到了。通常，这会包含它采取的所有行动的总结。由于它刚刚被创建，之前没有任何行动，所以总结仅仅是 *“我被创建”*。
- en: '**2\. GPT-4 Proposes an Action**'
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**2\. GPT-4 提出一个行动**'
- en: 'In step 2, we give GPT-4 the prompt we defined in the previous step. It can
    then propose an action to take which should adhere to the following format:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 2 中，我们给 GPT-4 提供了在前一步定义的提示。然后它可以提出一个行动，该行动应遵循以下格式：
- en: '![](../Images/6d67b46daaf0b8fb09398db89784aeea.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d67b46daaf0b8fb09398db89784aeea.png)'
- en: The second step in Auto-GPT’s autonomous cycle. GPT-4 executes the previous
    command and uses a framework called ReACT to demonstrate complex output.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 自主循环中的第二步。GPT-4 执行之前的命令，并使用一个叫做 ReACT 的框架来展示复杂的输出。
- en: 'You can see six individual steps being mentioned:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到提到了六个独立的步骤：
- en: Thoughts
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思考
- en: Reasoning
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理
- en: Plan
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计划
- en: Criticism
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批评
- en: Speak
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 说话
- en: Action
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动作
- en: These steps describe a format of prompting called Reason and ACT (**ReACT**).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤描述了一种叫做 Reason and ACT (**ReACT**) 的提示格式。
- en: ReACT is one of Auto-GPT’s superpowers!
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ReACT 是 Auto-GPT 的超能力之一！
- en: ReACT allows for GPT-4 to mimic self-criticism and demonstrate more complex
    reasoning than what is possible if we just ask the model directly.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ReACT 允许 GPT-4 模仿自我批评，并展示比直接询问模型更复杂的推理能力。
- en: '![](../Images/f4e63816bf2e6227c1aeea98249a3bc6.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4e63816bf2e6227c1aeea98249a3bc6.png)'
- en: A basic and illustrative example of ReACT. Most GPT models would get this question
    right with the basic prompt but it demonstrates how you could use ReACT for more
    complex questions.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ReACT 的一个基本和说明性示例。大多数 GPT 模型在基本提示下会正确回答这个问题，但它演示了如何将 ReACT 用于更复杂的问题。
- en: Whenever we ask GPT-4 a question using the ReACT framework, we ask GPT-4 to
    output individual thoughts, actions, and observations before coming to a conclusion.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们使用 ReACT 框架向 GPT-4 提问时，我们要求 GPT-4 在得出结论之前输出单独的思考、行动和观察。
- en: By having the model mimic extensive reasoning, it tends to give more accurate
    answers compared to directly answering the question.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过让模型模仿广泛的推理，它往往能给出比直接回答问题更准确的答案。
- en: 'In our example, Auto-GPT has extended the base ReACT framework and generates
    the following response:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，Auto-GPT 扩展了基础 ReACT 框架，并生成了以下响应：
- en: '![](../Images/cda528db7142676e6b4166132a19f5fa.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cda528db7142676e6b4166132a19f5fa.png)'
- en: The ReACT framework as used by Auto-GPT
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ReACT 框架在 Auto-GPT 中的应用
- en: As you can see, it follows the ReACT pipeline that we described before but includes
    additional criticism and reasoning steps.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它遵循了我们之前描述的 ReACT 流程，但包括了额外的批评和推理步骤。
- en: It proposes to **search the web** to extract more information about popular
    recipes.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 它提议 **搜索网络** 以提取关于流行食谱的更多信息。
- en: 3\. Execute Action
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 执行动作
- en: 'After having generated a response, in valid JSON format. We can extract what
    the **RecipeGPT** wants to do. In this case, it calls for a web search:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成响应后，以有效的 JSON 格式。我们可以提取 **RecipeGPT** 想要做什么。在这种情况下，它调用了网络搜索：
- en: '![](../Images/c7fa15cb60dfc77a715e91e24b90c07a.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c7fa15cb60dfc77a715e91e24b90c07a.png)'
- en: The next action as proposed by GPT-4.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 提出的下一步行动。
- en: 'and in turn, will execute searching the web:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 并且，接下来将执行网络搜索：
- en: '![](../Images/31b6ef621b9c64174ff6fc063eedd73a.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31b6ef621b9c64174ff6fc063eedd73a.png)'
- en: The third step in Auto-GPT’s autonomous cycle. Auto-GPT executes the previously
    proposed behavior.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 自主循环中的第三步。Auto-GPT 执行之前提出的行为。
- en: This action it can take, searching the web, is simply a tool at its disposal
    that generates a file containing the main body of the page.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以采取的这个行动，搜索网页，只是它的一种工具，可以生成一个包含页面主体的文件。
- en: Since we explained to GPT-4 in its system prompt that it can use web search,
    it considers this a valid action.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在系统提示中向GPT-4解释了它可以使用网络搜索，它将此视为一种有效的行动。
- en: Auto-GPT is as autonomous as the number of tools it possesses
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Auto-GPT的自主性取决于它拥有的工具数量。
- en: Do note that if the only tool at its disposal is searching the web, then we
    can start to argue how autonomous such a model really is!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果它唯一的工具是搜索网页，那么我们可以开始讨论这样一个模型究竟有多自主！
- en: Either way, we *save the output to a file* for later use.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，我们*将输出保存到文件中*以备后用。
- en: 4\. Embed Everything!
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 嵌入所有内容！
- en: Every step Auto-GPT has taken thus far is vital information for any next steps
    to take. Especially when it needs to take dozens of steps, for example for [taking
    over the world](https://www.youtube.com/@ChaosGPT), remembering what it has done
    thus far is important.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT迄今为止采取的每一步都是任何下一步的关键信息。尤其是当它需要采取数十个步骤时，例如[征服世界](https://www.youtube.com/@ChaosGPT)，记住它迄今为止做了什么是重要的。
- en: One method of doing so is by embedding the prompts and output it has generated.
    This allows us to convert text into numerical representations (embeddings) that
    we can save later on.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是嵌入它生成的提示和输出。这使我们能够将文本转换为数值表示（嵌入），以便我们稍后可以保存。
- en: '![](../Images/a220ef903d1c500864650ac14cd456f7.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a220ef903d1c500864650ac14cd456f7.png)'
- en: The fourth step in Auto-GPT’s autonomous cycle. Embed every relevant text it
    has seen thus far. Input, output, observations, actions, etc.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT自主循环的第四步。嵌入它迄今为止看到的所有相关文本。输入、输出、观察、行动等。
- en: These embeddings are generated using OpenAI’s *text-embedding-ada-002* model
    which works tremendously well across [many use cases](https://huggingface.co/spaces/mteb/leaderboard).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些嵌入是使用OpenAI的*text-embedding-ada-002*模型生成的，该模型在[许多用例](https://huggingface.co/spaces/mteb/leaderboard)中表现非常出色。
- en: 5\. Vector Database + Summarization
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 向量数据库 + 总结
- en: After having generated the embeddings, we need a place to store them. [Pinecone](https://pinecone.io/)
    is often used to create the vector database but many other systems can be used
    as long as you can easily find similar vectors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成嵌入后，我们需要一个地方来存储它们。[Pinecone](https://pinecone.io/)通常用于创建向量数据库，但只要能轻松找到相似向量，也可以使用许多其他系统。
- en: '![](../Images/a9deac81005d34d3ae61547f6c6b96da.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a9deac81005d34d3ae61547f6c6b96da.png)'
- en: The fifth step in Auto-GPT’s autonomous cycle. Save all embeddings in a vector
    database such that they can easily be accessed and searched for.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT自主循环的第五步。将所有嵌入保存在向量数据库中，以便可以轻松访问和搜索。
- en: The vector database allows us to quickly find information for an input query.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库使我们能够快速找到输入查询的信息。
- en: 'We can query the vector database to find all steps it has taken thus far. Using
    that information, we ask GPT-4 to create a **summary** of all actions it has taken
    thus far:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查询向量数据库以找到它到目前为止采取的所有步骤。利用这些信息，我们要求GPT-4创建一个**总结**，涵盖它到目前为止采取的所有行动：
- en: '![](../Images/f1a6782a5aa64ddb3065b0d6b3022589.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1a6782a5aa64ddb3065b0d6b3022589.png)'
- en: Create a summary of everything that has happened thus far using the vector database
    and GPT-4.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用向量数据库和GPT-4创建一个到目前为止发生的一切的总结。
- en: This summary is then used to construct the prompt as we did in step 1.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用这个总结来构建提示，就像我们在第1步中做的那样。
- en: That way, it can *“remember”* what it has done thus far and think about the
    next steps to be taken.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，它可以*“记住”*它迄今为止所做的事情，并考虑接下来的步骤。
- en: This completes the very first cycle of Auto-GPT’s autonomous behavior!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了Auto-GPT自主行为的第一个循环！
- en: 6\. Do it all over again!
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 重新开始！
- en: As you might have guessed, the cycle continues from where we started, asking
    GPT-4 to take action based on a history of actions.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能猜到的，循环从我们开始的地方继续，要求GPT-4根据行动历史采取行动。
- en: '![](../Images/0e979f9aac8d9b60dadf8999b1f1172b.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0e979f9aac8d9b60dadf8999b1f1172b.png)'
- en: Auto-GPT’s cycle of Autonomy.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT的自主循环。
- en: Auto-GPT will continue until it has reached its goal or when you interrupt it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT将继续进行，直到它达到目标或被你中断。
- en: During this cyclical process, it can keep track of estimated costs in order
    to make sure you do not spend too much on your Agent.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个循环过程中，它可以跟踪估计的成本，以确保你不会在你的代理上花费过多。
- en: In the future, especially with the release of [Llama2](https://huggingface.co/meta-llama/Llama-2-7b),
    I expect and hope that local models can reliably be used in Auto-GPT!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，特别是随着[Llama2](https://huggingface.co/meta-llama/Llama-2-7b)的发布，我期望并希望本地模型能在Auto-GPT中可靠地使用！
- en: Thank you for reading!
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 感谢阅读！
- en: If you are, like me, passionate about AI and/or Psychology, please feel free
    to add me on [**LinkedIn**](https://www.linkedin.com/in/mgrootendorst/), follow
    me on [**Twitter**](https://twitter.com/MaartenGr), or subscribe to my [**Newsletter**](http://maartengrootendorst.substack.com/).
    You can also find some of my content on my [**Personal Website**](https://maartengrootendorst.com/).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你和我一样，对AI和/或心理学充满热情，请随时在[**LinkedIn**](https://www.linkedin.com/in/mgrootendorst/)上添加我，关注我的[**Twitter**](https://twitter.com/MaartenGr)，或订阅我的[**Newsletter**](http://maartengrootendorst.substack.com/)。你也可以在我的[**Personal
    Website**](https://maartengrootendorst.com/)上找到我的一些内容。
- en: '*All images without a source credit were created by the author*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*所有没有来源注明的图片均由作者创作*'
