- en: Scaling Agglomerative Clustering for Big Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展聚合聚类以适应大数据
- en: 原文：[https://towardsdatascience.com/scaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad?source=collection_archive---------2-----------------------#2023-08-30](https://towardsdatascience.com/scaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad?source=collection_archive---------2-----------------------#2023-08-30)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/scaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad?source=collection_archive---------2-----------------------#2023-08-30](https://towardsdatascience.com/scaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad?source=collection_archive---------2-----------------------#2023-08-30)
- en: Learn how to use Reciprocal Agglomerative Clustering (RAC) to power hierarchical
    clustering of large datasets
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解如何使用互惠聚合聚类（RAC）来提升大数据集的层次聚类
- en: '[](https://medium.com/@danielfrees?source=post_page-----fb26a6b326ad--------------------------------)[![Daniel
    Frees](../Images/1551fc64acc5fb23a0db3a690def05b9.png)](https://medium.com/@danielfrees?source=post_page-----fb26a6b326ad--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb26a6b326ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb26a6b326ad--------------------------------)
    [Daniel Frees](https://medium.com/@danielfrees?source=post_page-----fb26a6b326ad--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielfrees?source=post_page-----fb26a6b326ad--------------------------------)[![Daniel
    Frees](../Images/1551fc64acc5fb23a0db3a690def05b9.png)](https://medium.com/@danielfrees?source=post_page-----fb26a6b326ad--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb26a6b326ad--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb26a6b326ad--------------------------------)
    [Daniel Frees](https://medium.com/@danielfrees?source=post_page-----fb26a6b326ad--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc941373ce27d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad&user=Daniel+Frees&userId=c941373ce27d&source=post_page-c941373ce27d----fb26a6b326ad---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb26a6b326ad--------------------------------)
    ·8 min read·Aug 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb26a6b326ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad&user=Daniel+Frees&userId=c941373ce27d&source=-----fb26a6b326ad---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc941373ce27d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad&user=Daniel+Frees&userId=c941373ce27d&source=post_page-c941373ce27d----fb26a6b326ad---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb26a6b326ad--------------------------------)
    ·8 min read·2023年8月30日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb26a6b326ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad&user=Daniel+Frees&userId=c941373ce27d&source=-----fb26a6b326ad---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb26a6b326ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad&source=-----fb26a6b326ad---------------------bookmark_footer-----------)![](../Images/ea07a10f9d8bbec3f54f02f1d40062d2.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb26a6b326ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fscaling-agglomerative-clustering-for-big-data-an-introduction-to-rac-fb26a6b326ad&source=-----fb26a6b326ad---------------------bookmark_footer-----------)![](../Images/ea07a10f9d8bbec3f54f02f1d40062d2.png)'
- en: '**Photo** by [Nastya Dulhiier](https://unsplash.com/@dulhiier) on [Unsplash](https://unsplash.com/photos/OKOOGO578eo).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**照片** 由 [Nastya Dulhiier](https://unsplash.com/@dulhiier) 在 [Unsplash](https://unsplash.com/photos/OKOOGO578eo)
    提供。'
- en: '**Introduction**'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**简介**'
- en: Agglomerative clustering is one of the best clustering tools in data science,
    but traditional implementations fail to scale to large datasets.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 聚合聚类是数据科学中最好的聚类工具之一，但传统实现无法扩展到大数据集。
- en: In this article, I will take you through some background on agglomerative clustering,
    an introduction to reciprocal agglomerative clustering (RAC) based on [2021 research
    from Google](https://arxiv.org/abs/2105.11653), a runtime comparison between `RAC++`
    and `scikit-learn`’s AgglomerativeClustering, and finally a brief explanation
    of the theory behind RAC.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将带你了解一些关于凝聚层次聚类的背景，介绍基于[2021年Google研究](https://arxiv.org/abs/2105.11653)的互惠凝聚层次聚类（RAC），`RAC++`与`scikit-learn`的AgglomerativeClustering的运行时间比较，以及最后对RAC背后理论的简要解释。
- en: Background on Agglomerative Clustering
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 凝聚层次聚类背景
- en: In data science, it is frequently useful to cluster unlabeled data. With applications
    ranging from grouping of search engine results, to genotype classification, to
    banking anomaly detection, clustering is an essential piece of a data scientist’s
    toolkit.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据科学中，对未标记的数据进行聚类通常是很有用的。无论是搜索引擎结果分组，还是基因型分类，还是银行异常检测，聚类都是数据科学家工具箱中的一个重要组成部分。
- en: 'Agglomerative clustering is one of the most popular clustering approaches in
    data-science and for good reason, it:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 凝聚层次聚类是数据科学中最受欢迎的聚类方法之一，这也是有充分理由的，它：
- en: ✅ Is easy to use with little to no parameter tuning
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 使用简单，几乎无需参数调整
- en: ✅ Creates meaningful taxonomies
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 创建有意义的分类法
- en: ✅ Works well with high-dimensional data
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 在高维数据上表现良好
- en: ✅ Does not need to know the number of clusters beforehand
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 无需事先知道簇的数量
- en: ✅ Creates the same clusters every time
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ✅ 每次都创建相同的簇
- en: In comparison, partitioning methods like `K-Means` require the data scientist
    to guess at the number of clusters, the very popular density-based method `DBSCAN`
    requires some parameters around density calculation radius (epsilon) and min neighborhood
    size, and `Gaussian mixture models` make strong assumptions about the underlying
    cluster data distribution.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，像`K-Means`这样的分区方法要求数据科学家猜测簇的数量，而非常流行的基于密度的方法`DBSCAN`需要一些关于密度计算半径（epsilon）和最小邻域大小的参数，而`Gaussian
    mixture models`对底层簇数据分布做了强假设。
- en: With agglomerative clustering, all you need to specify is a distance metric.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用凝聚层次聚类，你只需指定一个距离度量。
- en: '*At a high-level, agglomerative clustering follows the below algorithm:*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*从高层次来看，凝聚层次聚类遵循以下算法：*'
- en: '`Identify cluster distances between all pairs of clusters (each cluster begins
    as a single point)`'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`识别所有簇对之间的簇距离（每个簇开始时都是一个单独的点）`'
- en: '`Merge the two clusters which are closest to one another`'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`合并两个最接近的簇`'
- en: '`Repeat`'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`重复`'
- en: '*The result:* a beautiful dendrogram that can then be partitioned based on
    domain expertise.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*结果：*一个美丽的树状图，可以根据领域知识进行分区。'
- en: In fields like biology and natural language processing, clusters (of cells,
    genes, or words) naturally follow a hierarchical relationship. Agglomerative clustering
    therefore enables a more natural and data-driven selection of the final clustering
    cutoff.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在生物学和自然语言处理等领域，簇（如细胞、基因或单词）自然地遵循层次关系。因此，凝聚层次聚类使得最终的聚类截止点选择更加自然和数据驱动。
- en: '*Pictured below is a sample agglomerative clustering of the famous* [*Iris
    Dataset.*](https://www.kaggle.com/datasets/arshid/iris-flower-dataset)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*下图是著名的* [*鸢尾花数据集*](https://www.kaggle.com/datasets/arshid/iris-flower-dataset)
    *的一个样本凝聚层次聚类*'
- en: '![](../Images/7f74c340408007ed7a8d59d729485277.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f74c340408007ed7a8d59d729485277.png)'
- en: Clustering the famous Iris dataset by sepal length and sepal width. Graphs produced
    by co-author Porter Hunley.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通过萼片长度和萼片宽度对著名的鸢尾花数据集进行聚类。图形由共同作者Porter Hunley生成。
- en: So why not use agglomerative clustering for every unsupervised classification
    problem?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 那么为什么不对每一个无监督分类问题都使用凝聚层次聚类呢？
- en: ❌ Agglomerative clustering has a *terrible* runtime as datasets increase in
    size.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❌ 随着数据集规模的增大，凝聚层次聚类的运行时间*非常糟糕*。
- en: Unfortunately, traditional agglomerative clustering does not scale. The runtime
    is `O(n³)` or `O(n²log(n))` if implemented with a min-heap. Even worse, agglomerative
    clustering runs sequentially on a single-core and cannot be scaled up with compute.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，传统的凝聚层次聚类无法扩展。如果用最小堆实现，运行时间为`O(n³)`或`O(n²log(n))`。更糟的是，凝聚层次聚类在单核上顺序运行，无法通过计算资源进行扩展。
- en: In the field of NLP, agglomerative clustering is a top performer… for small
    datasets.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理领域，凝聚层次聚类在小型数据集上表现突出。
- en: Reciprocal Agglomerative Clustering (RAC)
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 互惠凝聚层次聚类（RAC）
- en: Reciprocal Agglomerative Clustering (RAC) is a [method proposed by Google](https://arxiv.org/abs/2105.11653)
    to scale the benefits of traditional Agglomerative clustering to larger datasets.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 递归凝聚聚类（RAC）是由[谷歌提出的一种方法](https://arxiv.org/abs/2105.11653)，旨在将传统凝聚聚类的优势扩展到更大的数据集。
- en: RAC decreases the runtime complexity while also parallelizing the operations
    to utilize a multi-core architecture. Despite these optimizations, RAC produces
    the exact same results as traditional Agglomerative clustering when the data is
    *fully connected* (see below).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: RAC 减少了运行时间复杂度，同时还将操作并行化，以利用多核架构。尽管进行了这些优化，RAC 在数据*完全连接*时仍然产生与传统凝聚聚类相同的结果（见下文）。
- en: '*Note: Fully connected data means that a distance metric can be calculated
    between any pair of points. Non-fully connected datasets have connectivity constraints
    (usually provided in the form of a linkage matrix) whereby some points are considered
    disconnected.*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：完全连接的数据意味着可以计算任意一对点之间的距离度量。非完全连接的数据集有连接约束（通常以连接矩阵的形式提供），其中一些点被认为是断开的。*'
- en: '![](../Images/fab556d0824638732d92c22031dd5f14.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fab556d0824638732d92c22031dd5f14.png)'
- en: RAC produces the exact same results as traditional agglomerative clustering
    when data is fully connected! (Top) and often continues to do so with connectivity
    constraints (Bottom). Graphs produced by co-author Porter Hunley.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: RAC 在数据完全连接时产生与传统凝聚聚类相同的结果！（上图）并且在有连接约束时通常也会如此（下图）。图表由合著者 Porter Hunley 制作。
- en: Even with connectivity constraints (data which is not fully connected), RAC
    and Agglomerative clustering are still typically identical, as seen in the second
    [Swiss Roll dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html)
    example above.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在有连接约束的情况下（数据不是完全连接的），RAC 和凝聚聚类通常仍然相同，正如上面第二个[Swiss Roll数据集](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html)示例所示。
- en: 'However, large discrepancies can emerge when there are very few possible clusters.
    The [Noisy Moons dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html)
    is a good example of this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当可能的聚类数量非常少时，可能会出现较大差异。[Noisy Moons数据集](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html)就是一个很好的例子：
- en: '![](../Images/46f4af8634c7bb089d17dbbf01c97c88.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46f4af8634c7bb089d17dbbf01c97c88.png)'
- en: Inconsistent results between RAC and sklearn. Graphs produced by co-author Porter
    Hunley.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: RAC 和 sklearn 之间的结果不一致。图表由合著者 Porter Hunley 制作。
- en: RAC++ scales to larger datasets than scikit-learn
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAC++ 比 scikit-learn 能处理更大的数据集。
- en: We can compare `[RAC++](https://github.com/porterehunley/RACplusplus)` (an implementation
    of reciprocal agglomerative clustering) to its counterpart, [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html),
    in `scikit-learn`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将 `[RAC++](https://github.com/porterehunley/RACplusplus)`（递归凝聚聚类的实现）与其对应的
    [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)
    在 `scikit-learn` 中进行比较。
- en: Let’s generate some example data with 25 dimensions, and test how long agglomerative
    clustering takes using `racplusplus.rac` vs. `sklearn.cluster.AgglomerativeClustering`
    for datasets ranging in size from 1,000 to 64,000 points.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们生成一些具有 25 个维度的示例数据，并测试 `racplusplus.rac` 与 `sklearn.cluster.AgglomerativeClustering`
    在数据集大小从 1,000 到 64,000 点之间所需的时间。
- en: '*Note: I am using a connectivity matrix to limit memory consumption.*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：我使用了连接矩阵来限制内存消耗。*'
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here is a graph of the runtime results for each size dataset:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是每种数据集大小的运行时间结果图：
- en: '![](../Images/33370be559570d8b7609a6017ff32e85.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/33370be559570d8b7609a6017ff32e85.png)'
- en: Runtime explodes for big datasets when using sklearn in comparison to racplusplus.
    Graph produced by co-author Porter Hunley.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 sklearn 时，处理大数据集的运行时间会爆炸，相较于 racplusplus。图表由合著者 Porter Hunley 制作。
- en: As we can see, there are drastic difference in runtime between RAC++ and traditional
    Agglomerative clustering.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，RAC++ 和传统的凝聚聚类在运行时间上存在显著差异。
- en: At just over 30k points, `RAC++` is around 100x faster! Even more improtantly,
    `scikit-learn`’s Agglomerative clustering hits a time limit at ~35 thousand points,
    while `RAC++` could scale to hundreds of thousands of points by the time it hits
    a reasonable time limit.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在超过 30k 个点时，`RAC++` 的速度大约快 100 倍！更重要的是，`scikit-learn` 的凝聚聚类在约 35,000 个点时达到时间限制，而
    `RAC++` 在达到合理的时间限制时能够扩展到数十万点。
- en: '**RAC++ can scale to high-dimensions**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAC++ 可以扩展到高维度**'
- en: We can also compare how well `RAC++` scales to high-dimensional data vs its
    traditional counterpart.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以比较`RAC++`在高维数据上的扩展效果与其传统对手。
- en: '![](../Images/a0b01365935489bed4018a500117db53.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a0b01365935489bed4018a500117db53.png)'
- en: Scaling time complexity by data dimensionality for RAC++ and sklearn. Graph
    by co-author Porter Hunley.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对比RAC++和sklearn的数据维度扩展时间复杂度。图表由共同作者Porter Hunley提供。
- en: Time taken to generate clusters vs dimensionality for 3,000 points
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 生成簇的时间与维度对3000个点的关系
- en: For 3,000 points we can see that traditional agglomerative clustering is faster
    but it scales linearly while `RAC++` is nearly constant. Working with 768 or 1536
    dimensional embeddings has become the norm in the field of NLP, and so scaling
    dimensionality to meet those requirements is important.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于3000个点，我们可以看到传统的聚合聚类更快，但它是线性扩展的，而`RAC++`几乎是常量的。在NLP领域，使用768或1536维的嵌入已成为常态，因此扩展维度以满足这些要求非常重要。
- en: '**RAC++ has a better runtime**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAC++具有更好的运行时间**'
- en: Researchers at [Google proved that RAC has a runtime of](https://arxiv.org/abs/2105.11653)
    `[O(nk)](https://arxiv.org/abs/2105.11653)` [where](https://arxiv.org/abs/2105.11653)
    `[k](https://arxiv.org/abs/2105.11653)` [is the connectivity constraint and](https://arxiv.org/abs/2105.11653)
    `[n](https://arxiv.org/abs/2105.11653)`[is the number of points](https://arxiv.org/abs/2105.11653)—
    a linear runtime. However, this is excluding the initial distance matrix calculation
    which is `O(n²)` — a quadratic runtime.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[谷歌的研究人员证明了RAC的运行时间为](https://arxiv.org/abs/2105.11653) `[O(nk)](https://arxiv.org/abs/2105.11653)`
    [，其中](https://arxiv.org/abs/2105.11653) `[k](https://arxiv.org/abs/2105.11653)`
    [是连接约束](https://arxiv.org/abs/2105.11653) 和 `[n](https://arxiv.org/abs/2105.11653)`
    [是点的数量](https://arxiv.org/abs/2105.11653) —— 线性运行时间。然而，这不包括初始距离矩阵计算，该计算是`O(n²)`
    —— 二次运行时间。'
- en: 'Our results, running a constant 30-neighbor connectivity constraint do confirm
    an `O(n²)` runtime:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果显示，在进行恒定的30邻居连接约束下，确实证实了`O(n²)`的运行时间：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Doubling data-points is a 4x increase in time.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据点翻倍会导致时间增加4倍。
- en: A quadratic runtime limits how well RAC++ will perform as datasets become truly
    massive, however, this runtime is already a big improvement over the traditional
    `O(n³)` or min-heap optimized`O(n²log(n))` runtime.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 二次运行时间限制了RAC++在数据集变得极其庞大时的性能，但这一运行时间已经比传统的`O(n³)`或最小堆优化的`O(n²log(n))`运行时间有了很大改进。
- en: '*Note: the developers of* `*RAC++*` *are working on passing the distance matrix
    as a parameter which would give* `*RAC++*` *a linear runtime.*'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：* `*RAC++*` *的开发者正在努力将距离矩阵作为参数传递，这将使* `*RAC++*` *具有线性运行时间。*'
- en: How RAC Works
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAC的工作原理
- en: 'Why is RAC++ so must faster? We can reduce the underlying algorithm to a few
    steps:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么RAC++如此快速？我们可以将底层算法简化为几个步骤：
- en: '`Pair clusters with reciprocal nearest neighbors`'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`用互为最近邻的点配对簇`'
- en: '`Merge the pairs of clusters`'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`合并簇对`'
- en: '`Update neighbors`'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`更新邻居`'
- en: Note that the only difference between this and the traditional agglomerative
    clustering algorithm is that we make sure to pair *reciprocal nearest neighbors*
    together. This is where the name Reciprocal Agglomerative Clustering (RAC) comes
    from. As you’ll see, this reciprocal pairing enables us to parallelize the most
    computationally expensive step of agglomerative clustering.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这与传统的聚合聚类算法的唯一区别在于我们确保将*互为最近邻的点*配对在一起。这就是名字“互为最近邻的聚合聚类”（RAC）的由来。正如你将看到的，这种互为配对使我们能够并行化最耗费计算的聚合聚类步骤。
- en: '**Pair clusters with reciprocal nearest neighbors**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**用互为最近邻的点配对簇**'
- en: First we loop through to find clusters with reciprocal nearest neighbors, meaning
    that their closest neighbors are each-other *(remember, distance can be directional!)*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们循环查找具有互为最近邻的簇，这意味着它们的最近邻彼此是*（记住，距离可以是有方向的！）*。
- en: '![](../Images/2889c911af71d713b2ecbdc2887ddd81.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2889c911af71d713b2ecbdc2887ddd81.png)'
- en: Identifying reciprocal nearest neighbors. Figure by co-author Porter Hunley.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 识别互为最近邻的点。图示由共同作者Porter Hunley提供。
- en: '**Merge pairs**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**合并对**'
- en: RAC is parallelizable because it does not matter what order reciprocal nearest
    neighbors are merged in, as long as the linkage method is *reducible*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: RAC是可并行的，因为无论互为最近邻的点以什么顺序合并，只要连接方法是*可还原的*。
- en: A linkage method is the function that determines the distance between two clusters,
    based on pairwise distances between the points contained in each cluster. A *reducible*
    linkage method guarantees that the new merged cluster is not closer to any other
    cluster after the merge.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 链路方法是根据每个簇中包含的点的成对距离来确定两个簇之间距离的函数。*可还原*链路方法保证新合并的簇在合并后不会比其他簇更近。
- en: '![](../Images/890d967e8d72fc0a73cbff0bec6f13b4.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/890d967e8d72fc0a73cbff0bec6f13b4.png)'
- en: ab_c will not be closer than a_c or b_c if reducible linkage is used. Figure
    by co-author Porter Hunley.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用可还原链路，则 ab_c 不会比 a_c 或 b_c 更接近。图像由共同作者波特·汉利提供。
- en: 'Fortunately, the four most popular linkage methods are reducible:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，四种最流行的链路方法都是可还原的：
- en: Single linkage — min distance
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单链路 — 最小距离
- en: Average linkage — average of the distances
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均链路 — 距离的平均值
- en: Complete linkage — max distance
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完整链路 — 最大距离
- en: Ward linkage — minimizing variance
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ward 链路 — 最小化方差
- en: '![](../Images/afc5c06e9af08f3843891b326ff6fe2f.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afc5c06e9af08f3843891b326ff6fe2f.png)'
- en: Visual representation of the 4 reducible linkage methods. Figures drawn by me,
    inspired by [http://www.saedsayad.com/clustering_hierarchical.htm](http://www.saedsayad.com/clustering_hierarchical.htm).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 4 种可还原链路方法的可视化表示。图像由我绘制，灵感来自于[http://www.saedsayad.com/clustering_hierarchical.htm](http://www.saedsayad.com/clustering_hierarchical.htm)。
- en: Since we know that our identified reciprocal pairs are each other’s nearest
    neighbor, and we know that reducible linkage merges will never make a newly merged
    cluster closer to another cluster, we can safely merge all reciprocal nearest
    neighbor pairs together at once. Each nearest-neighbor pair can be placed into
    an available thread to be merged according to the linkage method.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们知道识别出的互为最近邻的对彼此是最近邻，并且我们知道可还原链路的合并不会使新合并的簇更接近其他簇，我们可以安全地将所有互为最近邻的对一次性合并。每对最近邻可以放入可用线程中，根据链路方法进行合并。
- en: The fact that we can merge reciprocal nearest neighbors at the same time is
    fantastic, because merging clusters is the most computationally expensive step!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够同时合并互为最近邻这一事实非常棒，因为合并簇是计算最昂贵的步骤！
- en: '![](../Images/46c0ebb69d4db2999ca0c97ba75c9275.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46c0ebb69d4db2999ca0c97ba75c9275.png)'
- en: Visualizing clusters getting ready to merge. Figure by co-author Porter Hunley.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化准备合并的簇。图像由共同作者波特·汉利提供。
- en: '**Update nearest neighbors**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新最近邻**'
- en: With reducible linkage the order in which nearest neighbors are updated after
    merging also does not matter. Therefore, with some clever design, we can update
    the relevant neighbors in parallel as well.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用可还原链路时，合并后最近邻的更新顺序也不重要。因此，通过一些巧妙的设计，我们也可以并行更新相关的邻居。
- en: '![](../Images/31bf487b5bab07e5c37243a2b6575726.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31bf487b5bab07e5c37243a2b6575726.png)'
- en: Identifying new nearest neighbors after the merge. Image by co-author Porter
    Hunley.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在合并后识别新的最近邻。图像由共同作者波特·汉利提供。
- en: Conclusion
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: With a few test datasets, we have shown that `RAC++` produces the exact same
    results as traditional Agglomerative Clustering (ie. `sklearn`) for fully connected
    datasets at a much better runtime. With an understanding of reducible linkage
    metrics and a basic understanding of parallel programming, we can understand the
    logic that makes `RAC++` so much faster.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一些测试数据集，我们展示了`RAC++`在运行时间更优的情况下，产生了与传统的凝聚聚类（即`sklearn`）完全相同的结果。了解可还原链路度量和基本的并行编程知识，我们可以理解`RAC++`如此快速的逻辑。
- en: For a more complete understanding (and proof) of the algorithm `RAC++`has adopted
    into open-source, take a look at the [original Google research](https://arxiv.org/abs/2105.11653)
    it was based on.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要更全面地理解（并证明）`RAC++`所采用的开源算法，请查看基于的[原始 Google 研究](https://arxiv.org/abs/2105.11653)。
- en: '**The future**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**未来**'
- en: Porter Hunley started building RAC++ to create taxonomies for clinical term
    endpoints produced via fine-tuned BERT embeddings. Each of these medical embeddings
    had 768 dimensions and out of the many clustering algorithms he tried, only agglomerative
    clustering gave good results.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 波特·汉利开始构建 RAC++ 以创建通过微调 BERT 嵌入生成的临床术语端点的分类法。这些医学嵌入具有 768 个维度，在他尝试的许多聚类算法中，只有凝聚聚类给出了好的结果。
- en: All other high-scale clustering methods required reducing dimensionality to
    give any coherent results at all. There is, unfortunately, no fool-proof way to
    reduce dimensionality — you will always lose information.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他高尺度聚类方法都需要降低维度才能给出任何连贯的结果。不幸的是，没有万无一失的方法来降低维度——你总会丢失信息。
- en: After discovering Google’s research around RAC, Porter decided to build a custom
    open-source clustering implementation to support his clinical term clustering
    research. Porter lead development, and I co-developed portions of RAC, particularly
    wrapping the C++ implementation in python, optimizing runtime, and packaging the
    software for distribution.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在发现谷歌关于RAC的研究后，Porter决定构建一个定制的开源聚类实现，以支持他的临床术语聚类研究。Porter主导了开发，而我则共同开发了RAC的部分内容，特别是将C++实现封装到Python中，优化运行时间，并打包软件以供分发。
- en: '`RAC++` enables tons of clustering applications which are too slow using traditional
    agglomerative clustering, and will eventually be scalable to millions of datapoints.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`RAC++` 支持大量传统聚合聚类方法过于缓慢的聚类应用，并且最终能够扩展到数百万的数据点。'
- en: '**Although RAC++ can already be used to cluster large datasets, there are improvements
    to be made… RAC++ is still in development — please contribute!**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**虽然RAC++已经可以用于聚类大数据集，但仍有改进的空间… RAC++仍在开发中——请贡献！**'
- en: '***Contributing authors****:*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '***贡献作者****:*'
- en: 'Porter Hunley, Senior Software Engineer at Daceflow.ai: [github](https://github.com/porterehunley)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Porter Hunley，Daceflow.ai的高级软件工程师：[github](https://github.com/porterehunley)
- en: 'Daniel Frees, MS Stats & Data Science Student at Stanford, Data Scientist at
    IBM: [github](https://github.com/danielfrees)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Daniel Frees，斯坦福大学统计与数据科学硕士生，IBM数据科学家：[github](https://github.com/danielfrees)
- en: '[**GitHub — porterehunley/RACplusplus: A high performance implementation of
    Reciprocal Agglomerative…**](https://github.com/porterehunley/RACplusplus)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[**GitHub — porterehunley/RACplusplus: 一种高性能的Reciprocal Agglomerative实现…**](https://github.com/porterehunley/RACplusplus)'
