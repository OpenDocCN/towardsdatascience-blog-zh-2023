- en: 'MLOps made simple: how to run a batch prediction pipeline using Azure Machine
    Learning components'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps 简化版：如何使用 Azure 机器学习组件运行批量预测管道
- en: 原文：[https://towardsdatascience.com/mlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8?source=collection_archive---------11-----------------------#2023-02-06](https://towardsdatascience.com/mlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8?source=collection_archive---------11-----------------------#2023-02-06)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/mlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8?source=collection_archive---------11-----------------------#2023-02-06](https://towardsdatascience.com/mlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8?source=collection_archive---------11-----------------------#2023-02-06)
- en: You just want to get your model .pt file, upload it somewhere and get the predictions,
    right? Let’s see how to do it using AML infrastructure
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你只是想获取你的模型.pt 文件，上传到某个地方并获得预测，对吗？让我们看看如何使用 AML 基础设施来做到这一点。
- en: '[](https://medium.com/@dehhmesquita?source=post_page-----ea7931e818c8--------------------------------)[![Déborah
    Mesquita](../Images/3b77b7eb569e24f2679875429173daf1.png)](https://medium.com/@dehhmesquita?source=post_page-----ea7931e818c8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea7931e818c8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea7931e818c8--------------------------------)
    [Déborah Mesquita](https://medium.com/@dehhmesquita?source=post_page-----ea7931e818c8--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@dehhmesquita?source=post_page-----ea7931e818c8--------------------------------)[![Déborah
    Mesquita](../Images/3b77b7eb569e24f2679875429173daf1.png)](https://medium.com/@dehhmesquita?source=post_page-----ea7931e818c8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ea7931e818c8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ea7931e818c8--------------------------------)
    [Déborah Mesquita](https://medium.com/@dehhmesquita?source=post_page-----ea7931e818c8--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd9e06a0a640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=post_page-dd9e06a0a640----ea7931e818c8---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea7931e818c8--------------------------------)
    ·7 min read·Feb 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea7931e818c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=-----ea7931e818c8---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fdd9e06a0a640&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=post_page-dd9e06a0a640----ea7931e818c8---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ea7931e818c8--------------------------------)
    ·7分钟阅读·2023年2月6日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fea7931e818c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8&user=D%C3%A9borah+Mesquita&userId=dd9e06a0a640&source=-----ea7931e818c8---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea7931e818c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8&source=-----ea7931e818c8---------------------bookmark_footer-----------)![](../Images/591289eeaf235b40ba0fd589b0304db8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fea7931e818c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmlops-made-simple-how-to-run-a-batch-prediction-pipeline-using-azure-machine-learning-components-ea7931e818c8&source=-----ea7931e818c8---------------------bookmark_footer-----------)![](../Images/591289eeaf235b40ba0fd589b0304db8.png)'
- en: Pic by [Sarah Dorweiler](https://unsplash.com/ko/@sarahdorweiler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/pt-br/fotografias/x2Tmfd1-SgA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Sarah Dorweiler](https://unsplash.com/ko/@sarahdorweiler?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/pt-br/fotografias/x2Tmfd1-SgA?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: In our day-to-day as data scientists we often need to use some models for internal
    purposes. If we worked in a team of 1 it would be ok to run them in our own machines,
    but we usually need to share our work with other teammates. Sharing Jupyter Notebooks
    that run our scripts is a way of doing it, but notebooks become hard to manage
    and operate after we pass the experiments phase.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在日常工作中，作为数据科学家，我们经常需要使用一些模型用于内部目的。如果我们是一个人团队，将其运行在自己的机器上是可以的，但我们通常需要与其他队友共享我们的工作。共享运行脚本的Jupyter笔记本是一种方法，但在实验阶段之后，笔记本会变得难以管理和操作。
- en: Recently Azure introduced [**components**](https://learn.microsoft.com/en-us/azure/machine-learning/concept-component),
    a “self-contained piece of code that does one step in a machine learning pipeline”.
    We can use the components to build independently executable workflows and share
    them with other teammates. In today’s article we’re going to use components to
    create a Feature Matching pipeline.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Azure引入了[**组件**](https://learn.microsoft.com/en-us/azure/machine-learning/concept-component)，这是一种“自包含的代码片段，执行机器学习管道中的一个步骤”。我们可以使用这些组件构建独立可执行的工作流，并与其他队友共享。在今天的文章中，我们将使用组件创建一个特征匹配管道。
- en: 'Note: if you’re totally new to Azure Machine Learning it might be good to read
    [this other article](https://medium.com/towards-data-science/automl-for-object-detection-how-to-train-a-model-to-identify-potholes-e22c3f4b774)
    where I give a brief review of some AML concepts.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你对Azure Machine Learning完全陌生，阅读[这篇文章](https://medium.com/towards-data-science/automl-for-object-detection-how-to-train-a-model-to-identify-potholes-e22c3f4b774)可能会对你有所帮助，其中简要回顾了一些AML概念。
- en: MLOps 101
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MLOps 101
- en: 'As [Ville Tuulos](https://twitter.com/vtuulos) points out in the book [Effective
    Data Science Infrastructure: How to make data scientists productive](https://www.manning.com/books/effective-data-science-infrastructure)
    (great read, I highly recommend reading it), there are 3 building blocks for a
    data science infrastructure:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[Ville Tuulos](https://twitter.com/vtuulos)在书籍[《高效数据科学基础设施：如何提高数据科学家的生产力》](https://www.manning.com/books/effective-data-science-infrastructure)（一本很棒的书，我强烈推荐阅读）中指出的那样，数据科学基础设施有三个构建块：
- en: '**Architecture**: what the actual code looks like and how the system looks
    and feels to the data scientist'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**架构**：实际代码的样子以及系统对数据科学家的感受'
- en: '**Job scheduler:** how workflows are triggered, executed, and monitored and
    how failures are handled'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作业调度器：**工作流如何触发、执行、监控以及如何处理失败'
- en: '**Compute resources:** where the code executes in practice'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算资源：**代码实际执行的地方'
- en: For us the **Architecture** part consists of our python code. This part doesn’t
    change much from platform to platform. The **Job scheduler** and the **Compute
    resources** do change depending on the platform we’re running the workflows.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说，**架构**部分包含我们的python代码。这部分在不同平台上变化不大。**作业调度器**和**计算资源**会根据我们运行工作流的平台而有所不同。
- en: Most of the data science workflow failures happen not because of the code itself
    but because something changed in the data or in the environment we’re running
    the code. Each AML component has its own environment and dependencies, so it contributes
    a lot to the stability of our workflows.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据科学工作流失败并不是由于代码本身，而是由于数据或我们运行代码的环境发生了变化。每个AML组件都有自己的环境和依赖项，因此它对我们工作流的稳定性贡献很大。
- en: Using the AML stack we can build the **Architecture** using [components](https://learn.microsoft.com/en-us/azure/machine-learning/concept-component),
    use pipelines jobs as our **Job Scheduler** and use [compute clusters](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python#what-is-a-compute-cluster)
    or [compute instances](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-instance)
    to run our workflows.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AML堆栈，我们可以通过[组件](https://learn.microsoft.com/en-us/azure/machine-learning/concept-component)构建**架构**，使用管道作业作为我们的**作业调度器**，并使用[计算集群](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python#what-is-a-compute-cluster)或[计算实例](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-instance)来运行我们的工作流。
- en: Now let’s see how we can use all that inside a AML Workspace.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何在AML工作区中使用这些内容。
- en: Our batch prediction pipeline
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的批量预测管道
- en: We’re going to create a batch prediction pipeline using [Superglue and Superpoint](https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition)
    [1]. Our input can have a target image (a movie poster for example), and for each
    image in the dataset we want to know if the movie poster is there or not.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个批处理预测管道，使用 [Superglue 和 Superpoint](https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition)
    [1]。我们的输入可以是目标图像（例如电影海报），我们希望知道数据集中每张图像是否包含该电影海报。
- en: Have you heard of [Feature Matching using OpenCV](https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html)?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你听说过 [使用 OpenCV 进行特征匹配](https://docs.opencv.org/4.x/dc/dc3/tutorial_py_matcher.html)
    吗？
- en: '![](../Images/95697fa9ca0c969e1b04ee18f1ecb36c.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/95697fa9ca0c969e1b04ee18f1ecb36c.png)'
- en: Brute-Force Matching with SIFT Descriptors and Ratio Test
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SIFT 描述符和比率测试的暴力匹配
- en: Superglue and Superpoint accomplish that using deep learning. The best part
    is that we don’t need to train the models again since Superpoint is trained in
    a self-supervised manner [2].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Superglue 和 Superpoint 使用深度学习来完成这个任务。最棒的是，我们不需要重新训练模型，因为 Superpoint 是以自监督的方式训练的
    [2]。
- en: AML Components
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AML 组件
- en: Components require a well-defined interface (inputs and outputs). We can share
    and reuse them across pipelines and they’re versioned, so we can keep improving
    the code and make modifications as we go. The code of the component can be in
    any language (python, R, etc.); the only requirement is that it must be able to
    execute it by a shell command.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 组件需要一个明确定义的接口（输入和输出）。我们可以在管道之间共享和重用它们，并且它们有版本控制，所以我们可以不断改进代码并根据需要进行修改。组件的代码可以用任何语言编写（python、R
    等）；唯一的要求是它必须能够通过 shell 命令执行。
- en: Our main component will read data from a data asset, run Superpoint+Superglue
    and output a csv file with the image urls that has the target image in it. The
    input [data asset](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-data-assets?tabs=cli)
    will have the list of images we want to verify and a .jpeg file with the movie
    poster.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要组件将从数据资产中读取数据，运行 Superpoint+Superglue，并输出一个包含目标图像的图像 URL 的 CSV 文件。输入的 [数据资产](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-data-assets?tabs=cli)
    将包含我们要验证的图像列表和一张包含电影海报的 .jpeg 文件。
- en: 'We can build the components using the Azure ML CLI v2 or the Azure ML SDK v2\.
    Here we’ll use the python SDK. The code is adapted from the [superglue_rank_images.py
    script written by Ariya Sontrapornpol](https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition/blob/master/superglue_rank_images.py).
    This is how the component looks like:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Azure ML CLI v2 或 Azure ML SDK v2 构建组件。在这里我们将使用 python SDK。代码改编自 [Ariya
    Sontrapornpol 编写的 superglue_rank_images.py 脚本](https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition/blob/master/superglue_rank_images.py)。这就是组件的样子：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The **@command_component** decorator transforms the python function into static
    specification (YAML) that the pipeline service uses. We need to provide this metadata
    [3]:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**@command_component** 装饰器将 python 函数转换为管道服务使用的静态规范（YAML）。我们需要提供这些元数据 [3]：'
- en: '`name` is the unique identifier of the component'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name` 是组件的唯一标识符'
- en: '`version` is the current version of the component. A component can have multiple
    versions.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`version` 是组件的当前版本。一个组件可以有多个版本。'
- en: '`display_name` is a friendly display name of the component in UI, which isn''t
    unique'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`display_name` 是组件在 UI 中的友好显示名称，这个名称不是唯一的'
- en: '`description` usually describes what task this component can complete'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`description` 通常描述该组件可以完成的任务'
- en: '`environment` specifies the run-time environment for this component. The environment
    of this component specifies a docker image and refers to the `conda.yaml` file.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`environment` 指定了该组件的运行时环境。该组件的环境指定了一个 docker 镜像，并引用了 `conda.yaml` 文件。'
- en: Being able to provide the environment for each component is great because we
    can isolate the dependencies that each component uses.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 能够为每个组件提供环境非常好，因为我们可以隔离每个组件使用的依赖项。
- en: The `uri_folder` input type has a read only mount mode and the `uri_folder`
    output type has read-write mount mode. For more info about acessing data in pipeline
    jobs you can refer to [Access data in a job](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-read-write-data-v2?tabs=python)
    and [Data concepts in Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/concept-data).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`uri_folder` 输入类型具有只读挂载模式，而 `uri_folder` 输出类型具有读写挂载模式。有关在管道作业中访问数据的更多信息，请参考
    [在作业中访问数据](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-read-write-data-v2?tabs=python)
    和 [Azure 机器学习中的数据概念](https://learn.microsoft.com/en-us/azure/machine-learning/concept-data)。'
- en: 'To register this component in our AML workspace we’ll use the python SDK as
    well, here is the code:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的 AML 工作区注册此组件，我们还将使用 Python SDK，以下是代码：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we can see the component in the AML workspace.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在 AML 工作区中看到这个组件。
- en: '![](../Images/9248054cf7d19cb4606c1f15dedabbb5.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9248054cf7d19cb4606c1f15dedabbb5.png)'
- en: The component we’ve created
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的组件
- en: The next step is to create the pipeline to use the component.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建管道以使用该组件。
- en: AML Pipelines
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AML 管道
- en: We can define pipelines using the Azure ML CLI v2, Azure ML SDK v2 or using
    the Designer. Since our pipeline is simple we’ll define it using the designer.
    To create the input data asset we’ll also use the workspace UI.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Azure ML CLI v2、Azure ML SDK v2 或 Designer 来定义管道。由于我们的管道很简单，我们将使用设计器来定义它。要创建输入数据资产，我们也将使用工作区
    UI。
- en: '![](../Images/3d8c3ec55132766ca60cb08189e85e74.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d8c3ec55132766ca60cb08189e85e74.png)'
- en: Creating a data asset using the UI
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 UI 创建数据资产
- en: Since our pipeline has a custom component we need to create a custom pipeline
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的管道有一个自定义组件，我们需要创建一个自定义管道
- en: '![](../Images/1828bb84d05885da2f07de30bb6d8019.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1828bb84d05885da2f07de30bb6d8019.png)'
- en: Tab to create a custom pipeline
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 制作自定义管道的选项卡
- en: To submit the pipeline run we need to specify the compute resource. You can
    create one using the UI as well.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 提交管道运行时，我们需要指定计算资源。您也可以使用 UI 创建一个。
- en: '![](../Images/5f3194f47ab79622c55ab371827d4871.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5f3194f47ab79622c55ab371827d4871.png)'
- en: Creating the pipeline using Designer
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Designer 创建管道
- en: Final thoughts
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后的想法
- en: AML components are a great way to organize our code in our data science day-to-day
    activities. Since they can be written any language, we can run the code in any
    platform that can run shell commands, not only inside Azure Machine Learning.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: AML 组件是组织我们在数据科学日常活动中代码的绝佳方式。由于它们可以用任何语言编写，我们可以在任何可以运行 shell 命令的平台上运行这些代码，而不仅仅是在
    Azure Machine Learning 内部。
- en: By using AML though we get the UI to manage them, create data assets, manage
    our compute resources and so on. The AML ecosystem offers a great way of starting
    to use MLOps principles in our workflows.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 AML，我们可以获得 UI 来管理它们、创建数据资产、管理计算资源等。AML 生态系统为在工作流程中开始使用 MLOps 原则提供了一个很好的方法。
- en: References
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition](https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition](https://github.com/jomariya23156/SuperGlue-for-Visual-Place-Recognition)'
- en: '[2] DeTone, Daniel, Tomasz Malisiewicz, and Andrew Rabinovich. “Superpoint:
    Self-supervised interest point detection and description.” *Proceedings of the
    IEEE conference on computer vision and pattern recognition workshops*. 2018.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] DeTone, Daniel, Tomasz Malisiewicz, 和 Andrew Rabinovich. “Superpoint: 自监督兴趣点检测和描述。”
    *IEEE 计算机视觉与模式识别会议研讨会论文集*. 2018.'
- en: '[3] [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-create-component-pipeline-python)'
