- en: 'Leveraging LLMs with Information Retrieval: A Simple Demo'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用信息检索增强LLMs：一个简单的演示
- en: 原文：[https://towardsdatascience.com/leveraging-llms-with-information-retrieval-a-simple-demo-600825d3cb4c](https://towardsdatascience.com/leveraging-llms-with-information-retrieval-a-simple-demo-600825d3cb4c)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/leveraging-llms-with-information-retrieval-a-simple-demo-600825d3cb4c](https://towardsdatascience.com/leveraging-llms-with-information-retrieval-a-simple-demo-600825d3cb4c)
- en: A demo of integrating a Question-Answering LLM with retrieval components
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个将问答LLM与检索组件集成的演示
- en: '[](https://medium.com/@vuphuongthao9611?source=post_page-----600825d3cb4c--------------------------------)[![Thao
    Vu](../Images/9d44a2f199cdc9c29da72d9dc4971561.png)](https://medium.com/@vuphuongthao9611?source=post_page-----600825d3cb4c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----600825d3cb4c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----600825d3cb4c--------------------------------)
    [Thao Vu](https://medium.com/@vuphuongthao9611?source=post_page-----600825d3cb4c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@vuphuongthao9611?source=post_page-----600825d3cb4c--------------------------------)[![Thao
    Vu](../Images/9d44a2f199cdc9c29da72d9dc4971561.png)](https://medium.com/@vuphuongthao9611?source=post_page-----600825d3cb4c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----600825d3cb4c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----600825d3cb4c--------------------------------)
    [Thao Vu](https://medium.com/@vuphuongthao9611?source=post_page-----600825d3cb4c--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----600825d3cb4c--------------------------------)
    ·7 min read·Aug 14, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----600825d3cb4c--------------------------------)
    ·阅读时间7分钟·2023年8月14日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/309014edda2c597a2486ed5abab55028.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/309014edda2c597a2486ed5abab55028.png)'
- en: Image generated by the author using Stable Diffusion
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者使用Stable Diffusion生成
- en: Large language models (LLM) can store an impressive amount of factual data,
    but their capabilities are limited by the number of parameters. Furthermore, frequently
    updating LLM is expensive, while old training data can make LLM produce out-of-date
    responses.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）可以存储大量的事实数据，但其能力受到参数数量的限制。此外，频繁更新LLM是昂贵的，而旧的训练数据可能使LLM产生过时的回答。
- en: To tackle the problem above, we can augment LLM with external tools. In this
    article, I will share how to integrate LLM with retrieval components to enhance
    performance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，我们可以使用外部工具来增强LLM。在本文中，我将分享如何将LLM与检索组件集成以提高性能。
- en: Retrieval-Augmented (RA)
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检索增强（RA）
- en: A retrieval component can provide the LLM with more up-to-date and precise knowledge.
    Given input ***x***, we want to predict output ***p(y|x)***. From an external
    data source ***R***, we retrieve a list of contexts ***z***=(***z_1, z_2,..,z_n)***
    relevant to ***x***. We can join **x** and ***z*** together and make full use
    of ***z***’s rich information to predict ***p(y|x,z)****.* Besides, maintaining
    **R** up-to-date is also much cheaper.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 检索组件可以为LLM提供更为最新和准确的知识。给定输入***x***，我们希望预测输出***p(y|x)***。从外部数据源***R***中，我们检索与***x***相关的上下文列表***z***=(***z_1,
    z_2,..,z_n)***。我们可以将**x**和***z***结合在一起，充分利用***z***的丰富信息来预测***p(y|x,z)***。此外，保持**R**的更新也要便宜得多。
- en: '![](../Images/3fe2cc3cad76ee8963d0c05e7be2de8f.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3fe2cc3cad76ee8963d0c05e7be2de8f.png)'
- en: Retrieval Augmented pipeline (Image by the author)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强管道（图像来源于作者）
- en: QA Demo Using Wikipedia data + ChatGPT
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用维基百科数据和ChatGPT的QA演示
- en: 'In this demo, for a given question, we do the following steps:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个演示中，对于给定的问题，我们执行以下步骤：
- en: Retrieve Wikipedia documents related to the question.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索与问题相关的维基百科文档。
- en: Provide both the question and the Wikipedia to ChatGPT.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将问题和维基百科提供给ChatGPT。
- en: We want to compare and see how the extra context affects ChatGPT’s responses.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望比较并查看额外的上下文如何影响ChatGPT的回答。
- en: Dataset
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: For the Wikipedia dataset, we can extract it from [here](https://huggingface.co/datasets/wikipedia).
    I use “20220301.simple” subset with more than 200k documents. Due to the context
    length limit, I only use the title and abstract parts. For each document, I also
    add a doc id for the retrieval purpose later. So the data examples look like this.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于维基百科数据集，我们可以从[这里](https://huggingface.co/datasets/wikipedia)提取。我使用了“20220301.simple”子集，其中包含超过20万份文档。由于上下文长度的限制，我只使用了标题和摘要部分。对于每个文档，我还添加了一个文档ID，以便后续检索使用。因此，数据示例如下所示。
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We combine the title and the abstract passage and prepare them for encoding.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们结合标题和摘要段落，并准备它们进行编码。
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Encoding
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码
- en: Afterwards, we need a reliable embedding model to build our retrieval index.
    In this demo, I use the pre-trained [multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)
    with dim=1024 to encode the docs. For faster indexing and storage efficiency,
    you can choose other small-dimension embedding models.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要一个可靠的嵌入模型来构建我们的检索索引。在这个演示中，我使用了预训练的[multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)，维度为1024来编码文档。为了更快的索引和存储效率，你可以选择其他小维度的嵌入模型。
- en: My first embedding model choice was the pre-trained [ALBERT](https://huggingface.co/docs/transformers/model_doc/albert),
    but the results’ quality was poor. You should do a few test cases to make sure
    your index works reasonably well before moving to the next step. To pick a good
    embedding for retrieval, you can check out [this leaderboard](https://huggingface.co/spaces/mteb/leaderboard).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我最初选择的嵌入模型是预训练的[ALBERT](https://huggingface.co/docs/transformers/model_doc/albert)，但结果的质量较差。在进入下一步之前，你应该进行一些测试案例，以确保你的索引工作合理。为了选择一个好的检索嵌入，你可以查看[这个排行榜](https://huggingface.co/spaces/mteb/leaderboard)。
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ANN Index
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ANN 索引
- en: We have got our documents’ embeddings and ids list ready. The next step is to
    index them nicely for retrieval. I use the [HNSW](https://arxiv.org/pdf/1603.09320.pdf)
    index with cosine distance measurement.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好了文档的嵌入和ID列表。下一步是将它们很好地索引以进行检索。我使用[HNSW](https://arxiv.org/pdf/1603.09320.pdf)索引并使用余弦距离度量。
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Given a question, we can first go to the retrieval index and look for some
    relevant information. To avoid the wrong context, you can set a threshold for
    distance here. In this way, only relevant documents will be used:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个问题，我们可以首先到检索索引中查找一些相关信息。为了避免错误的上下文，你可以在这里设置一个距离阈值。这样，只有相关的文档才会被使用：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ChatGPT API
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT API
- en: So now our retrieval pipeline is ready! For the next step, let’s prepare a prompt
    to ask ChatGPT. We prepare 2 prompt formats as below, one only has the question
    and one with both the question and relevant Wikipedia text.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的检索管道已经准备好了！下一步，让我们准备一个提示来问ChatGPT。我们准备了以下两种提示格式，一种只有问题，另一种同时包含问题和相关的维基百科文本。
- en: The **‘question’** placeholder here is the target question we want to ask ChatGPT,
    while **‘info’** is the Wikipedia document retrieved from our HNSW index.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的**‘question’**占位符是我们希望问ChatGPT的目标问题，而**‘info’**是从我们的HNSW索引中检索到的维基百科文档。
- en: '[PRE5]{question}[PRE6]{question}[PRE7]{info}[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE5]{question}[PRE6]{question}[PRE7]{info}[PRE8]'
- en: Filling the placeholder with the question and corresponding Wikipedia doc, we
    can send out the request to [openai ChatCompletion API](https://platform.openai.com/docs/guides/gpt/chat-completions-api).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 填充占位符与问题和相应的维基百科文档后，我们可以向[openai ChatCompletion API](https://platform.openai.com/docs/guides/gpt/chat-completions-api)发送请求。
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: I have tried sending a few requests with and without Wikipedia documents and
    see the difference.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我尝试了发送一些带有和不带有维基百科文档的请求，并观察了差异。
- en: Example 1
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 1
- en: '**Question**: what does the cost of living include?'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**问题**：生活成本包括哪些内容？'
- en: ''
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ChatGPT**: The cost of living typically includes expenses such as housing,
    food, transportation, healthcare, utilities, and other basic necessities required
    to maintain a certain standard of living in a particular location. It may also
    include taxes, insurance, and other miscellaneous expenses.'
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ChatGPT**：生活成本通常包括如住房、食物、交通、医疗保健、公用事业及维持特定生活水平所需的其他基本必需品等费用。它还可能包括税收、保险和其他杂项费用。'
- en: ''
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Wiki info**: [[‘Cost of living</s>Cost of living is the amount of money it
    costs just to live in a certain place. It includes food, housing, etc.’]]'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**维基百科信息**：[[‘生活成本</s>生活成本是指在某个地方生活所需的金额。它包括食物、住房等。’]]'
- en: ''
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ChatGPT + wiki info**: The cost of living includes the amount of money it
    costs to live in a certain place, which encompasses expenses such as food, housing,
    and other necessary expenses.'
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ChatGPT + 维基百科信息**：生活成本包括在某个地方生活所需的金额，其中涵盖了食物、住房和其他必要开支等费用。'
- en: Example 2
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 2
- en: '**Question**: how to make cheese?'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**问题**：如何制作奶酪？'
- en: ''
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ChatGPT:** Cheese can be made by curdling milk with the help of an acid or
    rennet, separating the curds from the whey, and then pressing and aging the curds
    to develop flavor and texture. The specific process and ingredients used can vary
    depending on the type of cheese being made.'
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ChatGPT**：奶酪可以通过用酸或凝乳酶使牛奶凝固，分离凝乳和乳清，然后压制和陈化凝乳以发展风味和质地来制作。具体的过程和使用的配料可以根据制作的奶酪类型而有所不同。'
- en: ''
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Wiki info:** [[‘Cheese</s>Cheese is a dairy product that is made from milk.
    There are many types of cheese, such as cheddar, Swiss, and provolone. ‘]]'
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**维基百科信息：** [[‘奶酪</s>奶酪是一种由牛奶制成的乳制品。有很多种奶酪，比如切达奶酪、瑞士奶酪和普罗沃洛奶酪。‘]]'
- en: ''
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ChatGPT + wiki info:** To make cheese, you need milk as the main ingredient.
    Cheese is a dairy product that is made from milk. There are many types of cheese,
    such as cheddar, Swiss, and provolone.'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ChatGPT + 维基百科信息：** 要制作奶酪，你需要以牛奶为主要成分。奶酪是一种由牛奶制成的乳制品。有很多种奶酪，比如切达奶酪、瑞士奶酪和普罗沃洛奶酪。'
- en: Example 3
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 3
- en: '**Question:** can you explain the seq2seq model?'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**问题：** 你能解释一下 seq2seq 模型吗？'
- en: ''
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ChatGPT:** The seq2seq (sequence-to-sequence) model is a type of neural network
    architecture used for tasks that involve generating a sequence of output values
    from a sequence of input values. It consists of two main components: an encoder
    and a decoder. The encoder takes in the input sequence and generates a fixed-length
    vector representation of it, which is then passed to the decoder. The decoder
    uses this vector to generate the output sequence, one element at a time. The model
    is commonly used in natural language processing tasks such as machine translation,
    text summarization, and speech recognition.'
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ChatGPT：** seq2seq（序列到序列）模型是一种神经网络架构，用于生成一系列输出值的任务，该任务基于一系列输入值。它由两个主要组件组成：编码器和解码器。编码器接收输入序列，并生成一个固定长度的向量表示，然后将其传递给解码器。解码器使用这个向量来逐个生成输出序列。该模型常用于自然语言处理任务，如机器翻译、文本摘要和语音识别。'
- en: ''
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Wiki info:** [[‘Computability theory</s>Computability theory is part of computer
    science. Scientists want to know what can be computed, and what can not. ‘]]'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**维基百科信息：** [[‘可计算性理论</s>可计算性理论是计算机科学的一部分。科学家们想知道什么是可以计算的，什么是不能计算的。‘]]'
- en: ''
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**ChatGPT + wiki info:** The seq2seq model, or sequence-to-sequence model,
    is a type of neural network architecture used for natural language processing
    tasks such as machine translation, text summarization, and conversational modeling.
    It consists of two recurrent neural networks (RNNs), an encoder and a decoder,
    that work together to transform an input sequence into an output sequence. The
    encoder processes the input sequence and produces a fixed-length vector representation,
    which is then fed into the decoder to generate the output sequence. This model
    has been successful in many NLP tasks and has become a popular choice for language
    generation. The provided additional information about computability theory is
    not directly related to the question about seq2seq model.'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**ChatGPT + 维基百科信息：** seq2seq 模型，或称为序列到序列模型，是一种神经网络架构，用于自然语言处理任务，如机器翻译、文本摘要和对话建模。它由两个递归神经网络（RNNs）组成，一个编码器和一个解码器，它们共同作用将输入序列转换为输出序列。编码器处理输入序列并生成一个固定长度的向量表示，然后该向量被输入到解码器中以生成输出序列。该模型在许多
    NLP 任务中表现出色，已成为语言生成的热门选择。提供的关于可计算性理论的额外信息与有关 seq2seq 模型的问题不直接相关。'
- en: At first sight, we can see that the ANN index works quite well, but our dataset
    coverage is quite small. A better method is to expand your retrieval using Google
    Search results. You can also update your retrieval index with relevant documents
    when doing QA on a specific domain.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，我们可以看到 ANN 索引效果很好，但我们的数据集覆盖面相当小。一种更好的方法是通过 Google 搜索结果扩展检索。你还可以在对特定领域进行
    QA 时，用相关文档更新你的检索索引。
- en: In examples 1 and 2, when the Wikipedia page seems related, ChatGPT's answer
    seems to heavily depend on additional information. But the model may not be able
    to distinguish if the additional information is actually helpful (example 2).
    In order to avoid bad cases like this, you can add a few examples in the prompt
    to let the model know when and when not to use the extra information.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在示例 1 和 2 中，当维基百科页面似乎相关时，ChatGPT 的回答似乎在很大程度上依赖于额外的信息。但模型可能无法区分这些额外的信息是否真的有帮助（示例
    2）。为了避免这种情况，你可以在提示中添加一些示例，让模型了解何时使用额外信息，何时不使用。
- en: Another case is example 3, where the Wikipedia text is completely irrelevant.
    Fortunately, the answer seems not to be affected by the extra context.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种情况是示例 3，其中维基百科文本完全不相关。幸运的是，答案似乎不受额外上下文的影响。
- en: You can find the code [here](https://github.com/thao9611/chatgpt_and_retrieval).
    Hope you enjoy the reading :-)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [这里](https://github.com/thao9611/chatgpt_and_retrieval) 找到代码。希望你喜欢阅读 :-)
