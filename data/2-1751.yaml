- en: PyTorch Introduction — Building your First Linear Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch 介绍 — 构建你的第一个线性模型
- en: 原文：[https://towardsdatascience.com/pytorch-introduction-building-your-first-linear-model-d868a8681a41](https://towardsdatascience.com/pytorch-introduction-building-your-first-linear-model-d868a8681a41)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/pytorch-introduction-building-your-first-linear-model-d868a8681a41](https://towardsdatascience.com/pytorch-introduction-building-your-first-linear-model-d868a8681a41)
- en: Learn how to build your first PyTorch model, by using the “magical” Linear layer
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习如何通过使用“神奇”的 Linear 层来构建你的第一个 PyTorch 模型。
- en: '[](https://ivopbernardo.medium.com/?source=post_page-----d868a8681a41--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page-----d868a8681a41--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d868a8681a41--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d868a8681a41--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page-----d868a8681a41--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ivopbernardo.medium.com/?source=post_page-----d868a8681a41--------------------------------)[![Ivo
    Bernardo](../Images/39887b6f3e63a67c0545e87962ad5df0.png)](https://ivopbernardo.medium.com/?source=post_page-----d868a8681a41--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d868a8681a41--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d868a8681a41--------------------------------)
    [Ivo Bernardo](https://ivopbernardo.medium.com/?source=post_page-----d868a8681a41--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d868a8681a41--------------------------------)
    ·8 min read·Dec 12, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d868a8681a41--------------------------------)
    ·阅读时长 8 分钟·2023年12月12日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/48de4c355c69f4666a6e07d34fb89e52.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48de4c355c69f4666a6e07d34fb89e52.png)'
- en: Regression Model — Image generated by AI
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 回归模型 — AI 生成的图像
- en: In my last blog post, we’ve learned [how to work with PyTorch tensors](https://medium.com/towards-data-science/pytorch-introduction-tensors-and-tensor-calculations-412ff818bd5b?sk=2cf4d44549664fc647baa3455e9d78e8),
    the most important object in the PyTorch library. Tensors are the backbone of
    deep learning models so naturally we can use them to fit simpler machine learning
    models to our datasets.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我上一篇博客中，我们学习了[如何使用 PyTorch 张量](https://medium.com/towards-data-science/pytorch-introduction-tensors-and-tensor-calculations-412ff818bd5b?sk=2cf4d44549664fc647baa3455e9d78e8)，这是
    PyTorch 库中最重要的对象。张量是深度学习模型的骨架，因此我们可以利用它们来将更简单的机器学习模型拟合到我们的数据集上。
- en: Although PyTorch is known for its Deep Learning capabilities, we are also able
    to fit simple linear models using the framework — and this is actually one of
    the best ways to get familiar with the `torch` API!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 PyTorch 以其深度学习能力而闻名，但我们也可以使用该框架来拟合简单的线性模型——这实际上是熟悉`torch` API的最佳方式之一！
- en: In this blog post, we’re going to continue with the PyTorch introduction series
    by checking how we can develop a simple linear regression using the `torch` library.
    In the process, we’ll learn about `torch` Optimizers, Weights and other parameters
    of our learning model, something that will be extremely useful for more complex
    architectures.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将继续 PyTorch 介绍系列，查看如何使用 `torch` 库开发一个简单的线性回归模型。在这个过程中，我们将了解 `torch`
    的优化器、权重和其他学习模型参数，这对于更复杂的架构将非常有用。
- en: Let’s start!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: '**Loading and Processing Data**'
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**加载和处理数据**'
- en: 'For this blog post, we’ll use the song popularity dataset where we’ll want
    to predict the popularity of a certain song based on some song features. Let’s
    take a peek at the head of the dataset below:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将使用歌曲流行度数据集，我们希望根据一些歌曲特征来预测某首歌曲的流行度。让我们先看一下数据集的前几行：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/d4eab71b89cb0b1002c96e186c73e9d9.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d4eab71b89cb0b1002c96e186c73e9d9.png)'
- en: Song Popularity Feature Columns — Image by Author
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 歌曲流行度特征列 — 作者提供的图像
- en: 'Some of the features of this dataset include interesting metrics about each
    song, for example:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集的一些特征包括关于每首歌曲的有趣指标，例如：
- en: a level of song “energy”
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 歌曲的“能量”级别。
- en: a label encoding of the key (for example, A, B, C, D, etc.) of the song
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对歌曲的关键（例如 A、B、C、D 等）进行标签编码
- en: Song loudness
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 歌曲响度
- en: Song tempo.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 歌曲节奏。
- en: 'Our goal is to use these features to predict the song popularity, an index
    ranging from 0 to 100\. In the examples we show above, we are aiming to predict
    the following song popularity:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是利用这些特征来预测歌曲流行度，这是一个从 0 到 100 的指数。在我们上面展示的示例中，我们旨在预测以下歌曲流行度：
- en: '![](../Images/f50d07927df9b45944546fbada9d76d4.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f50d07927df9b45944546fbada9d76d4.png)'
- en: Song Popularity Target Column— Image by Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 歌曲受欢迎程度目标列— 图片由作者提供
- en: Instead of using `sklearn`, we are going to use PyTorch modules to predict this
    continuous variable. The good part of learning how to fit linear regressions in
    `pytorch`? The knowledge we’re going to gather can be applied with other complex
    models such as deep-layer neural networks!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 PyTorch 模块来预测这个连续变量，而不是使用 `sklearn`。学习如何在 `pytorch` 中拟合线性回归的好处是什么？我们将获得的知识可以应用于其他复杂模型，如深层神经网络！
- en: 'Let’s start by preparing our dataset and subset the features and target first:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从准备数据集开始，首先对特征和目标进行子集划分：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We’ll use`train_test_split` to divide the data into train and test. We’ll perform
    this transformation before transforming our data into`tensors` as `sklearn` ‘s
    method will automatically turn the data into `pandas` or `numpy` format:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `train_test_split` 将数据划分为训练集和测试集。我们将在将数据转换为 `tensors` 之前执行此转换，因为 `sklearn`
    的方法会自动将数据转换为 `pandas` 或 `numpy` 格式：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With `X_train` , `X_test` , `y_train` and `y_test` created, we can now transform
    our data into `torch.tensor` — doing that is easy by passing our data through
    the `torch.Tensor` function:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了 `X_train` 、 `X_test` 、 `y_train` 和 `y_test` 后，我们现在可以将数据转换为 `torch.tensor`
    — 通过将数据传递给 `torch.Tensor` 函数来完成这个过程很简单：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Our objects are now in`torch.Tensor` format, the format expected by the `nn.Module`.
    Çet’s see `X_train` below:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的对象现在是 `torch.Tensor` 格式，这是 `nn.Module` 期望的格式。下面是 `X_train`：
- en: '![](../Images/404cbdaf0a5afb1ec7400d029ee70130.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/404cbdaf0a5afb1ec7400d029ee70130.png)'
- en: X_train tensor — Image by Author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: X_train 张量 — 图片由作者提供
- en: Cool — so we have our train and test data in `tensor`format. We’re ready to
    create our first `torch` model, something that we will do next!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒——我们已经将训练和测试数据转换为 `tensor` 格式。我们准备好创建我们的第一个 `torch` 模型了，接下来我们将做这件事！
- en: Building our Linear Model
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建我们的线性模型
- en: We’ll train our model using a `LinearRegressionModel class`that inherits from
    the `nn.Module` parent. The `nn.Module` class is Pytorch’s base class for all
    neural networks.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个继承自 `nn.Module` 父类的 `LinearRegressionModel class` 来训练我们的模型。`nn.Module`
    类是 Pytorch 所有神经网络的基础类。
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this class, we only need a single argument when creating an object — the
    `optimizer`. We’re doing this as we’ll want to test different optimizers during
    the training process. In the code above, let’s zoom in on the weight initialization
    right after `# Initialize Weights and Bias`:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类中，我们创建对象时只需要一个参数——`optimizer`。我们这样做是因为我们希望在训练过程中测试不同的优化器。在上面的代码中，让我们聚焦于
    `# Initialize Weights and Bias` 之后的权重初始化：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'A linear regression is a very simple function consisting of the formula `y
    = b0 + b1x1 + ... bnxn` where:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是一个非常简单的函数，公式为 `y = b0 + b1x1 + ... bnxn` 其中：
- en: y is equal to the target we want to predict
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: y 等于我们想要预测的目标
- en: b0 is equal to the bias term.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: b0 等于偏差项。
- en: b1, …, bn are equal to the weights of the model (how much each variable should
    weight in the final decision and if it contributes negatively or positively).
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: b1, …, bn 等于模型的权重（每个变量在最终决策中的权重以及它是负面还是正面贡献）。
- en: x1, …, xn are the values of the features.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: x1, …, xn 是特征的值。
- en: The idea behind the `nn.Parameter` is to initialize *b0* (the bias being initialized
    in `self.bias`) and the *b1, … , bn* (the weights being initialized in `self.weights`
    ). We are initializing 13 weights, given that we have 13 features in our training
    dataset.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.Parameter` 的理念是初始化 *b0*（在 `self.bias` 中初始化的偏差）和 *b1, … , bn*（在 `self.weights`
    中初始化的权重）。我们正在初始化 13 个权重，因为我们的训练数据集中有 13 个特征。'
- en: As we’re dealing with a linear regression there’s only a single value for the
    bias, so we just initialize a single random scalar ([check my first post if this
    name sounds alien to you!](https://medium.com/towards-data-science/pytorch-introduction-tensors-and-tensor-calculations-412ff818bd5b?sk=2cf4d44549664fc647baa3455e9d78e8)).
    Also, notice that we’re initializing these parameters randomly using `torch.randn`
    .
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们处理的是线性回归，因此只有一个偏差值，所以我们只需初始化一个随机标量（[如果这个名字对你来说很陌生，可以查看我的第一篇文章！](https://medium.com/towards-data-science/pytorch-introduction-tensors-and-tensor-calculations-412ff818bd5b?sk=2cf4d44549664fc647baa3455e9d78e8)）。此外，请注意，我们正在使用
    `torch.randn` 随机初始化这些参数。
- en: 'Now, our goal is to optimize these weights via backpropagation — for that we
    need to setup our linear layer, consisting of the regression formula:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的目标是通过反向传播优化这些权重——为此，我们需要设置我们的线性层，包括回归公式：
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `trainModel` method will help us perform backpropagation and weight adjustment:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainModel` 方法将帮助我们执行反向传播和权重调整：'
- en: '[PRE7]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this method, we can choose between using between Stochastic Gradient Descent
    (SGD) or Adaptive Moment Estimation (*Adam*) optimizers. More importantly, let’s
    zoom in on what happens between each epoch (a pass on the entire dataset):'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方法中，我们可以选择使用随机梯度下降（SGD）或自适应矩估计（*Adam*）优化器。更重要的是，让我们深入了解每个训练周期（对整个数据集的一次遍历）之间发生了什么：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This code is extremely important in the context of Neural Networks. It consists
    of the training process of a typical `torch` model:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码在神经网络的背景下极为重要。它包括了典型的`torch`模型的训练过程：
- en: We set the model in training mode using `self.train()`
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`self.train()`将模型设置为训练模式
- en: Next, we pass the data through the model using `self(X_train)` — this will pass
    the data through the forward layer.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`self(X_train)`将数据传递给模型 — 这将把数据传递通过前向层。
- en: '`loss_fn` calculates the loss on the training data. Our loss is `torch.L1Loss`
    that consists of the Mean Absolute Error.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_fn`计算训练数据上的损失。我们的损失函数是`torch.L1Loss`，由平均绝对误差组成。'
- en: '`optimizer.zero_grad()` sets the gradients to zero (they accumulate every epoch,
    so we want them to start clean in every pass).'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer.zero_grad()`将梯度设置为零（它们会在每个周期累积，因此我们希望在每次遍历时从零开始）。'
- en: '`loss.backward()` calculates the gradient for every weight with respect to
    the loss function. This is the step where our weights are optimized.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss.backward()`计算每个权重相对于损失函数的梯度。这是优化权重的步骤。'
- en: Finally, we update the model’s parameters using `optimizer.step()`
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用`optimizer.step()`更新模型的参数
- en: 'The final touch is revealing how our model will be evaluated using the `evaluate`
    method:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的步骤是揭示如何使用`evaluate`方法评估我们的模型：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This code performs a calculation of the loss in the test set. Also, we’ll use
    this method to print our loss in both train and test sets for every 10 epochs.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码计算测试集中的损失。此外，我们将使用这种方法在每10个周期中打印训练和测试集的损失。
- en: Having our model ready, let’s train it on our data and visualize the learning
    curves for train and test!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 模型准备好后，让我们在数据上训练它，并可视化训练和测试的学习曲线！
- en: Fitting the Model
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合模型
- en: 'Let’s use the code we’ve built to train our model and see the training process
    — First, we’ll train a model using `Adam` optimizer and `0.001` learning rate
    for 500 epochs:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用构建的代码来训练模型并观察训练过程 — 首先，我们将使用`Adam`优化器和`0.001`学习率训练模型500个周期：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here I’m training a model using the `adam` optimizer for 200 epochs. The overview
    of the train and test loss is shown next:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我使用`adam`优化器训练模型200个周期。训练和测试损失的概述如下：
- en: '![](../Images/170b4bd07e394c19b1882ff88d07f4eb.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/170b4bd07e394c19b1882ff88d07f4eb.png)'
- en: Train and Test evolution for the first 150 Epochs — Image by Author
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 前150个周期的训练和测试演变 — 作者提供的图片
- en: 'We can also plot the training and test loss throughout the epochs:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以绘制整个周期的训练和测试损失：
- en: '![](../Images/02396ed220643923d7f33fb675b4ad9f.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02396ed220643923d7f33fb675b4ad9f.png)'
- en: Train and Test Loss — Image by Author
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和测试损失 — 作者提供的图片
- en: Our loss is still a bit high (on the last epoch, an MAE of around 21) as a linear
    regression may not be able to solve this problem.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的损失仍然有点高（在最后一个周期，MAE约为21），因为线性回归可能无法解决这个问题。
- en: 'Finally, let’s just fit a model with `SGD` :'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们只用`SGD`拟合模型：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/e636b24a94e0bdea6de6243f45ff609c.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e636b24a94e0bdea6de6243f45ff609c.png)'
- en: Train and Test Loss for SGD Model — Image by Author
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: SGD模型的训练和测试损失 — 作者提供的图片
- en: Interesting — train and test loss do not improve! This happens because SGD is
    very sensitive to feature scaling and may have trouble calculating the gradient
    with features that have a different scale. As a challenge, try to scale the features
    and check the results with `SGD` . After scaling, you will also notice a stabler
    behavior on the `Adam` optimizer model!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是 — 训练和测试损失没有改善！这发生是因为SGD对特征缩放非常敏感，可能在处理不同尺度的特征时难以计算梯度。作为挑战，尝试对特征进行缩放，并用`SGD`检查结果。缩放后，你还会注意到`Adam`优化器模型的行为更稳定！
- en: Conclusion
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Thank you for taking the time to read this post! In this blog post, we’ve checked
    how we can use `torch` to train a simple linear regression model. While PyTorch
    is famous for it’s deep learning (more layers and complex functions), learning
    simple models is a great way to play around the framework. Also, this is an excellent
    use case to get familiar with the concept of “loss” function and gradients.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您抽出时间阅读这篇文章！在这篇博客文章中，我们检查了如何使用`torch`训练一个简单的线性回归模型。虽然PyTorch因其深度学习（更多层和复杂功能）而闻名，但学习简单模型是玩转这个框架的好方法。此外，这也是熟悉“损失”函数和梯度概念的绝佳用例。
- en: We’ve also seen how the `SGD` and `Adam` optimizers work, particularly how sensitive
    they are to unscaled features.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了 `SGD` 和 `Adam` 优化器的工作原理，特别是它们对未缩放特征的敏感程度。
- en: 'Finally, I want you to retain the process that can be expanded to other types
    of models, functions and processes:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我希望你保留这个过程，它可以扩展到其他类型的模型、函数和过程：
- en: '`train()` to set the model into training mode.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train()` 将模型设置为训练模式。'
- en: Pass the data through the model using `torch.model`
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `torch.model` 将数据传递给模型。
- en: Using `nn.L1Loss()` for regression problems. Other loss functions are available
    [here](https://pytorch.org/docs/stable/nn.html#loss-functions).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `nn.L1Loss()` 进行回归问题。其他损失函数可以在[这里](https://pytorch.org/docs/stable/nn.html#loss-functions)找到。
- en: '`optimizer.zero_grad()` sets the gradients to zero.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer.zero_grad()` 将梯度设置为零。'
- en: '`loss.backward()` calculates the gradient for every weight with respect to
    the loss function.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss.backward()` 计算每个权重相对于损失函数的梯度。'
- en: Using `optimizer.step()` to update the weights of the model.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `optimizer.step()` 更新模型的权重。
- en: See you on the next PyTorch post! I also recommend that you visit [PyTorch Zero
    to Mastery Course](https://www.learnpytorch.io/01_pytorch_workflow/), an amazing
    free resource that inspired the methodology behind this post.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 下次 PyTorch 的帖子见！我还推荐你访问 [PyTorch 从零到精通课程](https://www.learnpytorch.io/01_pytorch_workflow/)，这是一个精彩的免费资源，激发了这篇文章的方法论。
- en: Feel free to join my newly created YouTube Channel — the [Data Journey](https://www.youtube.com/@TheDataJourney42).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎加入我新创建的 YouTube 频道——[数据之旅](https://www.youtube.com/@TheDataJourney42)。
- en: '*The dataset used in this blog post is available on the Kaggle Platform and
    was extracted using Spotify Official APP (*[https://www.kaggle.com/datasets/yasserh/song-popularity-dataset/data)](https://www.kaggle.com/datasets/yasserh/song-popularity-dataset/data).
    *The dataset is under license CC0: Public Domain*'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*本博客文章中使用的数据集可以在 Kaggle 平台上获得，并通过 Spotify 官方 APP 提取（*[https://www.kaggle.com/datasets/yasserh/song-popularity-dataset/data](https://www.kaggle.com/datasets/yasserh/song-popularity-dataset/data)*）。*
    数据集的许可证为 CC0：公有领域*'
