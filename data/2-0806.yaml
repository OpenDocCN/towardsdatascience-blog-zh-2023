- en: Enhance Your ML Experimentation Workflow with Real-Time Plots
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过实时图表提升您的机器学习实验工作流程
- en: 原文：[https://towardsdatascience.com/enhance-your-ml-experimentation-workflow-with-real-time-plots-434106b1a1c2](https://towardsdatascience.com/enhance-your-ml-experimentation-workflow-with-real-time-plots-434106b1a1c2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/enhance-your-ml-experimentation-workflow-with-real-time-plots-434106b1a1c2](https://towardsdatascience.com/enhance-your-ml-experimentation-workflow-with-real-time-plots-434106b1a1c2)
- en: '![](../Images/14872005fa4fb7dbad42661022c573bb.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/14872005fa4fb7dbad42661022c573bb.png)'
- en: Image generated with Midjourney
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 Midjourney 生成
- en: Part 2 of the tutorial on how to run and evaluate experiments without leaving
    your IDE
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何在不离开 IDE 的情况下运行和评估实验的教程第 2 部分
- en: '[](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)[![Eryk
    Lewinson](../Images/56e09e19c0bbfecc582da58761d15078.png)](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)
    [Eryk Lewinson](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)[![Eryk
    Lewinson](../Images/56e09e19c0bbfecc582da58761d15078.png)](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)
    [Eryk Lewinson](https://eryk-lewinson.medium.com/?source=post_page-----434106b1a1c2--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)
    ·13 min read·Mar 13, 2023
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----434106b1a1c2--------------------------------)
    ·阅读时间 13 分钟·2023年3月13日
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: In [the previous article of this series](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27),
    I demonstrated how to use DVC’s VS Code extension to transform our IDE into an
    experimentation platform, allowing us to directly run and evaluate ML experiments.
    I also mentioned that the extension offers useful plotting functionalities, which
    enable us to visualize and evaluate the performance of our experiments using interactive
    plots. To make it even better, the extension also offers live plotting of certain
    metrics during the training phase. You can get a sneak peek of this feature in
    the following figure.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[本系列的上一篇文章](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27)中，我演示了如何使用
    DVC 的 VS Code 扩展将我们的 IDE 转变为实验平台，使我们能够直接运行和评估机器学习实验。我还提到，该扩展提供了有用的绘图功能，允许我们使用交互式图表可视化和评估实验的性能。为了进一步提升体验，该扩展还提供了在训练阶段实时绘制某些指标的功能。你可以在以下图中预览这一特性。
- en: '![](../Images/523d72401f29f69adb75ac1bec395dce.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/523d72401f29f69adb75ac1bec395dce.png)'
- en: '[Source](https://dvc.org/doc/dvclive/get-started?tab=DVC-Extension-for-VS-Code),
    GIF used with permission by iterative'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://dvc.org/doc/dvclive/get-started?tab=DVC-Extension-for-VS-Code)，GIF
    经 iterative 许可使用'
- en: This article will demonstrate how to enhance the previously-introduced experimentation
    workflow by monitoring model performance and evaluating experiments with interactive
    plots, all within VS Code. To achieve this, we’ll tackle a binary image classification
    problem. First, we will provide an overview of transfer learning in computer vision
    and share some details about the selected dataset.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将演示如何通过在 VS Code 中监控模型性能和评估实验结果，利用交互式图表来增强之前介绍的实验工作流程。为实现这一目标，我们将处理一个二分类图像问题。首先，我们将概述计算机视觉中的迁移学习，并分享一些关于所选数据集的细节。
- en: Problem definition and methodology
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题定义与方法论
- en: Image classification is one of the most popular tasks in the field of computer
    vision. For our example, we will use the cat vs dog classification problem, which
    has been widely used in the research community to benchmark different deep learning
    models. As you might have guessed, the goal of the project is to classify an input
    image as either a cat or a dog.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是计算机视觉领域中最受欢迎的任务之一。作为我们的示例，我们将使用猫与狗的分类问题，这一问题已被广泛用于研究社区中，用于基准测试不同的深度学习模型。正如你可能猜到的，该项目的目标是将输入图像分类为猫或狗。
- en: To achieve high accuracy even with limited training data, we will leverage transfer
    learning to speed up the training process. Transfer learning is a powerful deep
    learning technique that has recently gained significant popularity, especially
    in various domains of computer vision. With the vast amount of data available
    on the internet, transfer learning allows us to leverage existing knowledge from
    one domain/problem and apply it to a different one.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在有限的训练数据下实现高准确性，我们将利用迁移学习来加快训练过程。迁移学习是一种强大的深度学习技术，最近在计算机视觉的各种领域获得了显著的关注。利用互联网上的大量数据，迁移学习使我们能够利用一个领域/问题的现有知识，并将其应用于不同的领域。
- en: One of the approaches to using transfer learning for computer vision is based
    on the idea of feature extraction. First, a model is trained on a large and general
    dataset (for example, the [ImageNet dataset](https://en.wikipedia.org/wiki/ImageNet)).
    This model serves as a generic model of “vision”. Then, we can use the learned
    feature maps of such a model without having to start the training of a custom
    network from scratch
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉中使用迁移学习的一种方法是基于特征提取的思想。首先，在一个大型且通用的数据集上训练一个模型（例如，[ImageNet数据集](https://en.wikipedia.org/wiki/ImageNet)）。这个模型作为“视觉”的通用模型。然后，我们可以使用这种模型学习到的特征图，而无需从头开始训练自定义网络。
- en: 'For our use case, we will utilize a pre-trained model (ResNet50) to extract
    relevant features for our binary classification problem. The approach consists
    of a few steps:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的使用案例，我们将利用一个预训练的模型（ResNet50）来提取与我们的二分类问题相关的特征。这个方法包括几个步骤：
- en: Obtain a pre-trained model, i.e., a saved network that was previously trained
    on a large dataset. You can find some examples [here](https://www.tensorflow.org/api_docs/python/tf/keras/applications).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取一个预训练的模型，即一个已经在大型数据集上训练过的保存网络。你可以在[这里](https://www.tensorflow.org/api_docs/python/tf/keras/applications)找到一些示例。
- en: Use the feature maps learned by the selected network to extract meaningful features
    from images that the network was not trained on.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用所选网络学习到的特征图来从网络没有训练过的图像中提取有意义的特征。
- en: Add a new classifier on top of the pre-trained network. The classifier will
    be trained from scratch since the classification component of the pre-trained
    model is specific to its original task.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在预训练的网络上添加一个新的分类器。由于预训练模型的分类组件是特定于其原始任务的，因此分类器将从头开始训练。
- en: We will show how to do all of this in the following sections. However, please
    bear in mind that this is not a tutorial on transfer learning. If you would like
    to learn more about the theory and implementation, please refer to [this article](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)
    or [this tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分展示如何完成这些操作。然而，请记住，这不是一个关于迁移学习的教程。如果你想了解更多关于理论和实现的内容，请参考[这篇文章](https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/)或[这个教程](https://www.tensorflow.org/tutorials/images/transfer_learning)。
- en: Getting the data
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: By using the following snippet, we can download the cats vs. dogs dataset. The
    [original dataset](https://www.microsoft.com/en-us/download/details.aspx?id=54765)
    contained 12500 images of each class. However, for our project, we will be using
    a smaller, filtered dataset that contains 1000 training images and 500 validation
    images per class. The additional benefit of downloading the filtered dataset via
    TensorFlow is that it does not contain some corrupted images that were present
    in the original dataset (please see [here](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs)
    for more information).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码片段，我们可以下载猫狗数据集。[原始数据集](https://www.microsoft.com/en-us/download/details.aspx?id=54765)包含每个类别的12500张图像。然而，对于我们的项目，我们将使用一个较小的、过滤后的数据集，其中每个类别包含1000张训练图像和500张验证图像。通过TensorFlow下载过滤后的数据集的额外好处是，它不包含原始数据集中存在的一些损坏图像（更多信息请见[这里](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs)）。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following tree presents the structure of the directories containing the
    downloaded images:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下树状图展示了包含下载图像的目录结构：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In case you would like to use the complete dataset for your experiments, you
    can load it using `[tensorflow_datasets](https://www.tensorflow.org/guide/keras/transfer_learning#getting_the_data)`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想使用完整的数据集进行实验，你可以使用`[tensorflow_datasets](https://www.tensorflow.org/guide/keras/transfer_learning#getting_the_data)`来加载它。
- en: Experimenting with Neural Networks
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验神经网络
- en: 'In this section, we will show the code used for training and experimenting
    with our neural network classifier. Specifically, we will need the following three
    files:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示用于训练和实验我们的神经网络分类器的代码。具体来说，我们将需要以下三个文件：
- en: '`train.py` — contains the code used for training the neural network.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.py` — 包含用于训练神经网络的代码。'
- en: '`params.yaml` — contains the parameters used for training the neural network,
    such as the size of the input images, batch size, learning rate, number of epochs,
    etc.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`params.yaml` — 包含用于训练神经网络的参数，例如输入图像的大小、批处理大小、学习率、训练轮次等。'
- en: '`dvc.yaml` — contains the DVC pipeline, which stores information about all
    the steps that are executed within our project, including their respective dependencies
    and outputs. For a more thorough description of this file and its structure, please
    refer to [my previous article](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dvc.yaml` — 包含DVC管道，其中存储有关我们项目中所有执行步骤的信息，包括它们的依赖关系和输出。有关该文件及其结构的更详细描述，请参阅[我的上一篇文章](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27)。'
- en: As a matter of fact, our current setup is more advanced than the bare minimum.
    While we could have started with just the training script, we chose to implement
    a more sophisticated setup right from the start. This will allow us to conveniently
    run experiments in a queue and easily parameterize them, among other benefits.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们当前的设置比最低要求更先进。虽然我们本可以仅从训练脚本开始，但我们选择从一开始就实现更复杂的设置。这将使我们能够方便地排队运行实验并轻松地参数化它们，还有其他好处。
- en: Let’s start with the `dvc.yaml` file as it contains this project’s pipeline.
    As this is a relatively simple project, it only has one stage called `train`.
    In the file, we can see which script contains the stage’s code, what its dependencies
    are, where the parameters are located, and what the outputs are. The `outs` step
    contains a directory that does not exist yet (`dvclive`), which will be automatically
    created while running our experiments.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从`dvc.yaml`文件开始，因为它包含了该项目的管道。由于这是一个相对简单的项目，它只有一个名为`train`的阶段。在文件中，我们可以看到哪个脚本包含阶段的代码，它的依赖关系是什么，参数的位置在哪里，以及输出是什么。`outs`步骤包含一个尚不存在的目录（`dvclive`），在运行实验时将自动创建。
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s proceed to the `params.yaml` file. We have already mentioned what it
    contains, so its contents should not come as a surprise:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续查看`params.yaml`文件。我们已经提到它包含的内容，所以其内容应该不会让人感到惊讶：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Naturally, the file can contain many more parameters for multiple stages of
    the project, which are defined in the DVC pipeline.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，该文件可以包含更多阶段的多个参数，这些参数在DVC管道中定义。
- en: 'Finally, we proceed to the file used for training the neural network. To make
    it more readable, we will break it down into three code snippets. In the first
    one, we execute the following steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进入用于训练神经网络的文件。为了使其更具可读性，我们将其分解为三个代码片段。在第一个片段中，我们执行以下步骤：
- en: Import the necessary libraries.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入必要的库。
- en: Define the data directories separately for the training and validation datasets.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分别为训练和验证数据集定义数据目录。
- en: Load the parameters from the `params.yaml` file.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`params.yaml`文件中加载参数。
- en: Define the training and validation datasets using the `image_dataset_from_directory`
    functionality of `keras`.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`keras`的`image_dataset_from_directory`功能定义训练和验证数据集。
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The second part of the training script contains the definition of the neural
    network architecture that we want to use for this project.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本的第二部分包含了我们希望在此项目中使用的神经网络架构的定义。
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will not dive deeply into the code used for transfer learning, as it is
    slightly outside the scope of this article. However, it is worth mentioning that:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨用于迁移学习的代码，因为它略超出本文的范围。然而，值得一提的是：
- en: 'We used some very simple image augmentation techniques: random horizontal flip
    and random rotation. These augmentations are only applied to the training set.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用了一些非常简单的图像增强技术：随机水平翻转和随机旋转。这些增强仅应用于训练集。
- en: While training the model, we want to track its accuracy. We chose this metric
    because we are dealing with a balanced dataset, but we could easily track additional
    metrics such as precision and recall.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练模型时，我们希望跟踪其准确性。我们选择了这个指标，因为我们处理的是一个平衡的数据集，但我们可以很容易地跟踪其他指标，如精确度和召回率。
- en: 'The third and last snippet contains the main body of our script:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个也是最后一个代码片段包含了我们脚本的主要部分：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this snippet, we do the following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们执行以下操作：
- en: We create the `models` directory if it does not exist.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 `models` 目录不存在，我们会创建它。
- en: We get the model using the `get_model` function defined in the previous snippet.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用在前面的代码片段中定义的 `get_model` 函数来获取模型。
- en: We define the callbacks we want to use. The first two are standard callbacks
    used while training neural networks. The first one is used for creating checkpoints
    while training. The second one stores the selected metrics (in our case, accuracy
    and loss) after each epoch into a CSV file. We will cover the third callback in
    a moment.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了要使用的回调函数。前两个是训练神经网络时使用的标准回调函数。第一个用于在训练过程中创建检查点。第二个在每个 epoch 后将选择的指标（在我们的案例中是准确率和损失）存储到
    CSV 文件中。我们将稍后介绍第三个回调函数。
- en: We fit the model to the training data and evaluate using the validation set.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将模型拟合到训练数据上，并使用验证集进行评估。
- en: The third callback we used, `DVCLiveCallback`, comes from a companion library
    called DVCLive. In general, it is a library that provides utilities for logging
    ML parameters, metrics, and other metadata in simple file formats. You can think
    of it as an ML logger similar to, for example, MLFlow. The biggest difference
    is that by using DVCLive, we do not have to use any additional services or servers.
    All of the logged metrics and metadata are stored as plain text files, which can
    be versioned with Git.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的第三个回调 `DVCLiveCallback` 来自一个名为 DVCLive 的辅助库。总的来说，它是一个提供用于记录 ML 参数、指标和其他元数据的简单文件格式的工具库。你可以把它看作是类似于
    MLFlow 的 ML 记录器。最大区别在于，通过使用 DVCLive，我们不需要使用任何额外的服务或服务器。所有记录的指标和元数据都存储为纯文本文件，这些文件可以使用
    Git 进行版本控制。
- en: In this particular case, we used a Keras-compatible callback provided by DVCLive.
    DVCLive provides similar utilities for the most popular machine and deep learning
    libraries, such as TensorFlow, PyTorch, LightGBM, XGBoost, and more. You can find
    the complete list of supported libraries [here](https://dvc.org/doc/dvclive/api-reference/ml-frameworks).
    It is also worth mentioning that even though DVCLive provides many useful callbacks
    that we can use out-of-the-box, it does not mean this is the only way to log the
    metrics. We can [manually log](https://dvc.org/doc/dvclive/how-it-works) whichever
    metrics/plots we want at any point we want.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定案例中，我们使用了 DVCLive 提供的 Keras 兼容回调。DVCLive 为最受欢迎的机器学习和深度学习库（如 TensorFlow、PyTorch、LightGBM、XGBoost
    等）提供类似的工具。你可以在[这里](https://dvc.org/doc/dvclive/api-reference/ml-frameworks)找到支持的库的完整列表。还值得一提的是，即使
    DVCLive 提供了许多可以开箱即用的有用回调，这并不意味着这是记录指标的唯一方式。我们可以[手动记录](https://dvc.org/doc/dvclive/how-it-works)任何我们想要的指标/图表。
- en: When we specified the `DVCLiveCallback`, we set the `save_dvc_exp` argument
    to `True`. By doing so, we indicated that we would like to automatically track
    the results using Git.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们指定 `DVCLiveCallback` 时，我们将 `save_dvc_exp` 参数设置为 `True`。这样做表明我们希望通过 Git 自动跟踪结果。
- en: 'At this point, we are ready to run our first experiment. For that, we will
    use the parameters we have initially specified in the `params.yaml` file. To run
    the experiment, we can either press the *Run Experiment* button in the *Experiments*
    tab of the DVC panel or use the following command in the terminal:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备运行第一次实验。为此，我们将使用最初在 `params.yaml` 文件中指定的参数。要运行实验，我们可以在 DVC 面板的 *Experiments*
    标签页中按 *Run Experiment* 按钮，或在终端中使用以下命令：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: For more information on running the experiments and navigating the *Experiments*
    tab, please refer to [my previous article](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 关于运行实验和导航到 *Experiments* 标签页的更多信息，请参阅[我之前的文章](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27)。
- en: 'After running the experiment, we notice that a new directory was created —`dvclive`.
    The DVCLive callback we used in our code automatically logged data and stored
    it in plain text files in that directory. In our case, the directory looks like
    this:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行实验后，我们注意到创建了一个新目录——`dvclive`。我们在代码中使用的 DVCLive 回调自动记录数据，并将其存储在该目录中的纯文本文件中。在我们的案例中，该目录如下所示：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We provide a brief description of the generated files:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了生成文件的简要描述：
- en: The TSV files contain the accuracy and loss over epochs, separately for the
    training and validation datasets.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TSV 文件包含每个 epoch 的准确率和损失，分别针对训练和验证数据集。
- en: '`metrics.json` contains the requested metrics for the final epoch.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metrics.json` 包含最终 epoch 的请求指标。'
- en: '`report.html` contains plots of the tracked metrics in a form of an HTML report.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`report.html` 包含以 HTML 报告形式呈现的跟踪指标的图表。'
- en: At this point, we can inspect the tracked metrics in the HTML report. However,
    we can also do that directly from VS Code by navigating to the *Plots* tab in
    the DVC extension.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以在HTML报告中检查跟踪的指标。然而，我们也可以直接从VS Code中检查，通过导航到DVC扩展中的*图表*选项卡。
- en: '![](../Images/e8a53a352f01a619b84332cffce8f043.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8a53a352f01a619b84332cffce8f043.png)'
- en: Using the left-hand sidebar, we can select the experiments we want to visualize.
    I have chosen the `main` one, but you can see that I have already run a few experiments
    before. In the *Plots* menu, we can select which metrics we want to plot. This
    functionality is very handy when we track a lot of metrics, but we only want to
    inspect a few of them at a time.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用左侧边栏，我们可以选择要可视化的实验。我选择了`main`实验，但您可以看到我之前已经运行了几个实验。在*图表*菜单中，我们可以选择要绘制的指标。当我们跟踪许多指标时，这个功能非常方便，但我们一次只想检查其中的一些指标。
- en: In the main view, we can see the visualized metrics. The upper plots present
    the metrics calculated using the validation set, while the lower ones are based
    on the training set. What you cannot see in the static image is that those plots
    are live plots. It means that the metrics are updated after each epoch of training
    is completed. We can use this tab to monitor the progress of our training jobs
    in real-time.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在主视图中，我们可以看到可视化的指标。上方的图表呈现了使用验证集计算的指标，而下方的图表则基于训练集。您在静态图像中看不到的是这些图表是实时图表。这意味着指标在每个训练轮次完成后都会更新。我们可以使用这个选项卡实时监控我们的训练进度。
- en: 'For the second experiment, we increase the learning rate from 0.01 to 0.1\.
    We can run such an experiment using the following command:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个实验，我们将学习率从0.01增加到0.1。我们可以使用以下命令运行这样的实验：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To monitor the model during training, we also selected the `workspace` experiment
    in the *Experiments* menu. In the image below, you can see what the plots look
    like while the neural network is still in the training stage (you can see that
    the process is running in the terminal window).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在训练期间监控模型，我们还在*实验*菜单中选择了`workspace`实验。在下图中，您可以看到在神经网络仍处于训练阶段时图表的样子（您可以看到进程正在终端窗口中运行）。
- en: '![](../Images/b662fcb293a00d4a09afd2b2cedc1b9f.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b662fcb293a00d4a09afd2b2cedc1b9f.png)'
- en: 'So far, all of our plots were generated in the *Data Series* section of the
    *Plots* tab. In total, there are three sections, each with different kinds of
    plots:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们所有的图表都在*数据系列*部分的*图表*选项卡中生成。总共有三个部分，每个部分有不同类型的图表：
- en: '*Data Series* — contains visualizations of metrics stored in text files (JSON,
    YAML, CSV, or TSV).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据系列* — 包含存储在文本文件（JSON、YAML、CSV或TSV）中的指标的可视化。'
- en: '*Images* — contains side-by-side visualizations of stored images, such as JPG
    files.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图像* — 包含并排显示的存储图像，如JPG文件。'
- en: '*Trends* — contains automatically generated and updated scalar metrics per
    epoch if [DVC checkpoints](https://dvc.org/doc/user-guide/experiment-management/checkpoints)
    are enabled.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*趋势* — 包含每个epoch自动生成和更新的标量指标，如果启用了[DVC检查点](https://dvc.org/doc/user-guide/experiment-management/checkpoints)。'
- en: We have already explored how to track and visualize metrics using DVCLive’s
    callbacks. Using DVC also allows us to track plots stored as images. For instance,
    we could create a bar chart representing the feature importance obtained from
    a certain model. Or, to simplify, we could track a confusion matrix.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探索了如何使用DVCLive的回调跟踪和可视化指标。使用DVC还允许我们跟踪存储为图像的图表。例如，我们可以创建一个条形图，表示从某个模型中获得的特征重要性。或者，为了简化，我们可以跟踪一个混淆矩阵。
- en: 'The general approach to track and visualize custom plots using DVC is to create
    the plot manually, save it as an image, and then track it. This allows us to track
    any custom plot we create. Alternatively, for certain `scikit-learn` plots, we
    can use DVCLive’s `log_sklearn_plot` method and generate the plot using data (predictions
    vs. ground truth) stored in JSON files. This approach currently works for the
    following kinds of plots: probability calibration, confusion matrix, ROC curve,
    and precision-recall curve.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用DVC跟踪和可视化自定义图表的一般方法是手动创建图表，将其保存为图像，然后跟踪它。这允许我们跟踪我们创建的任何自定义图表。或者，对于某些`scikit-learn`图表，我们可以使用DVCLive的`log_sklearn_plot`方法，利用存储在JSON文件中的数据（预测与真实值）生成图表。这种方法目前适用于以下类型的图表：概率校准、混淆矩阵、ROC曲线和精确度-召回曲线。
- en: For this example, we will demonstrate how to start tracking a confusion matrix.
    In the code snippet below, you can see the modified `train.py` script. We have
    removed many things that did not change, making it easier to follow the modifications.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将演示如何开始跟踪混淆矩阵。在下面的代码片段中，你可以看到修改后的`train.py`脚本。我们删除了许多没有改变的内容，使得跟踪修改更加容易。
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see, this time we created an instance of a `Live` object, which we
    use both for the callback and the `log_sklearn_plot` method. To track all the
    metrics, we used a context manager (the `with` statement) to instantiate the `Live`
    instance. Without doing so, DVCLive would create an experiment when `keras` calls
    `on_train_end`. As a result, any data logged after that (in our case, the confusion
    matrix plot) would not be tracked within the experiment.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这次我们创建了一个`Live`对象的实例，我们在回调和`log_sklearn_plot`方法中都使用了它。为了跟踪所有指标，我们使用了上下文管理器（`with`语句）来实例化`Live`实例。如果不这样做，DVCLive
    会在`keras`调用`on_train_end`时创建实验。结果是，之后记录的任何数据（在我们例子中是混淆矩阵图）都不会在实验中被跟踪。
- en: After modifying the training script, we ran again the two experiments with different
    learning rates (0.1 vs. 0.01). As a result, we can now see the confusion matrices
    in the *Plots* tab, right under the previously explored plots.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在修改训练脚本后，我们再次运行了两个不同学习率（0.1 与 0.01）的实验。结果是，我们现在可以在*Plots*标签下看到混淆矩阵，位于之前探索的图表下方。
- en: '![](../Images/117aa0f0844b327b85954c7c0670e101.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/117aa0f0844b327b85954c7c0670e101.png)'
- en: The last thing to mention is that running the modified training script also
    modifies the `dvc.yaml` pipeline within the `dvclive` directory. As you can see
    below, it now contains information about the tracked confusion matrix, such as
    how to build it, which template to use, and what labels to use.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后要提到的是，运行修改后的训练脚本也会修改`dvclive`目录中的`dvc.yaml`管道。如下面所示，它现在包含有关跟踪的混淆矩阵的信息，例如如何构建它、使用哪个模板以及使用什么标签。
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Wrapping up
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In the previous article of the series, we showed how to start using DVC and
    the dedicated VS Code extension to turn your IDE into an ML experimentation platform.
    In this part, we continued where we left off and we explored various (live-) plotting
    capabilities of the extension. Using those, we can easily evaluate and compare
    experiments to choose the best one.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在系列的上一篇文章中，我们展示了如何开始使用 DVC 和专用的 VS Code 扩展，将你的 IDE 转变为 ML 实验平台。在这一部分，我们继续从我们停下的地方开始，探索了扩展的各种（实时）绘图功能。利用这些功能，我们可以轻松评估和比较实验，以选择最佳方案。
- en: In my opinion, there are two significant advantages of using a DVC-enhanced
    workflow. First, we do not need any external services or setups to start our experiments.
    The only requirement is a Git repo. Furthermore, DVC works with Git in a clean
    way. Although every experiment is saved in a Git commit, those commits are hidden
    and do not clutter our repository. In fact, we do not even need to create separate
    branches.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，使用 DVC 增强工作流有两个显著优势。首先，我们不需要任何外部服务或设置来启动实验。唯一的要求是一个 Git 仓库。此外，DVC 与 Git
    的配合非常干净。虽然每个实验都保存在 Git 提交中，但这些提交是隐藏的，不会使我们的仓库杂乱。实际上，我们甚至不需要创建单独的分支。
- en: Secondly, everything happens within our IDE, enabling us to focus on our project
    without constantly switching between the IDE, browser, and other tools. This way,
    we can avoid distractions and the ever-threatening context-switching.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，一切都在我们的 IDE 中进行，使我们可以专注于项目，而无需不断切换 IDE、浏览器和其他工具。这样，我们可以避免干扰和不断切换上下文的威胁。
- en: As always, any constructive feedback is more than welcome. You can reach out
    to me on [Twitter](https://twitter.com/erykml1) or in the comments. You can find
    all the code used for this article in [](https://github.com/erykml/vscode_exp_tracking_with_dvc)
    [this repository](https://github.com/erykml/cats_vs_dogs_classification).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，任何建设性的反馈都非常欢迎。你可以通过 [Twitter](https://twitter.com/erykml1) 或在评论中联系我。你可以在
    [](https://github.com/erykml/vscode_exp_tracking_with_dvc) [这个仓库](https://github.com/erykml/cats_vs_dogs_classification)
    中找到所有用于本文的代码。
- en: '*Liked the article? Become a Medium member to continue learning by reading
    without limits. If you use* [*this link*](https://eryk-lewinson.medium.com/membership)
    *to become a member, you will support me at no extra cost to you. Thanks in advance
    and see you around!*'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '*喜欢这篇文章吗？成为 Medium 会员继续无限制阅读，继续学习。如果你使用* [*这个链接*](https://eryk-lewinson.medium.com/membership)
    *成为会员，你将以没有额外费用的方式支持我。提前感谢，并期待与你再见！*'
- en: 'You might also be interested in one of the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能也对以下内容感兴趣：
- en: '[](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------)
    [## Turn VS Code into a One-Stop Shop for ML Experiments'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://towardsdatascience.com/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------](https://towardsdatascience.com/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------)
    [## 将 VS Code 转变为机器学习实验的一站式平台'
- en: How to run and evaluate experiments without leaving your IDE
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何在不离开 IDE 的情况下运行和评估实验
- en: towardsdatascience.com](/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------)
    [](/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------)
    [## 3 Simple Ways to Create a Waterfall Plot in Python
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://towardsdatascience.com/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------](https://towardsdatascience.com/turn-vs-code-into-a-one-stop-shop-for-ml-experiments-49c97c47db27?source=post_page-----434106b1a1c2--------------------------------)
    [https://towardsdatascience.com/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------](https://towardsdatascience.com/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------)
    [## 用 Python 创建瀑布图的三种简单方法'
- en: Learn how to quickly create a presentation-ready plot to aid your data storytelling
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习如何快速创建一个适合演示的图表，以辅助你的数据叙事
- en: towardsdatascience.com](/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------)
    [](https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------)
    [## Introducing the second edition of Python for Finance Cookbook
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://towardsdatascience.com/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------](https://towardsdatascience.com/3-simple-ways-to-create-a-waterfall-plot-in-python-1124f7afc90f?source=post_page-----434106b1a1c2--------------------------------)
    [https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------](https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------)
    [## 介绍《Python 财务食谱》的第二版'
- en: What led me to write a second edition and what you can expect from reading it
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 是什么促使我编写第二版以及你可以从阅读中期待什么
- en: eryk-lewinson.medium.com](https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------)
    [](/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------)
    [## R Shiny is coming to Python
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------](https://eryk-lewinson.medium.com/introducing-the-second-edition-of-python-for-finance-cookbook-f42f59c8acd0?source=post_page-----434106b1a1c2--------------------------------)
    [https://towardsdatascience.com/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------](https://towardsdatascience.com/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------)
    [## R Shiny 正在进入 Python'
- en: Shiny is joining the ranks of web app tools such as Streamlit and Dash
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Shiny 正在加入 Streamlit 和 Dash 等网页应用工具的行列
- en: towardsdatascience.com](/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://towardsdatascience.com/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------](https://towardsdatascience.com/r-shiny-is-coming-to-python-1653bbe231ac?source=post_page-----434106b1a1c2--------------------------------)'
- en: References
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[https://www.microsoft.com/en-us/download/details.aspx?id=54765](https://www.microsoft.com/en-us/download/details.aspx?id=54765)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.microsoft.com/en-us/download/details.aspx?id=54765](https://www.microsoft.com/en-us/download/details.aspx?id=54765)'
- en: '[https://www.kaggle.com/competitions/dogs-vs-cats/overview](https://www.kaggle.com/competitions/dogs-vs-cats/overview)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/competitions/dogs-vs-cats/overview](https://www.kaggle.com/competitions/dogs-vs-cats/overview)'
- en: '[https://github.com/iterative/dvclive](https://github.com/iterative/dvclive)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/iterative/dvclive](https://github.com/iterative/dvclive)'
- en: '[https://iterative.ai/blog/exp-tracking-dvc-python/](https://iterative.ai/blog/exp-tracking-dvc-python/)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://iterative.ai/blog/exp-tracking-dvc-python/](https://iterative.ai/blog/exp-tracking-dvc-python/)'
- en: '[https://keras.io/examples/vision/image_classification_from_scratch/](https://keras.io/examples/vision/image_classification_from_scratch/)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://keras.io/examples/vision/image_classification_from_scratch/](https://keras.io/examples/vision/image_classification_from_scratch/)'
- en: All images, unless noted otherwise, are by the author.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 除非另有说明，否则所有图片均由作者提供。
