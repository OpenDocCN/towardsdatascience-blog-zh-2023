- en: Is ChatGPT Actually Intelligent?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 真的智能吗？
- en: 原文：[https://towardsdatascience.com/is-chatgpt-actually-intelligent-42d07462fe59](https://towardsdatascience.com/is-chatgpt-actually-intelligent-42d07462fe59)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/is-chatgpt-actually-intelligent-42d07462fe59](https://towardsdatascience.com/is-chatgpt-actually-intelligent-42d07462fe59)
- en: Maybe not…
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 也许不是……
- en: '[](https://huonglanchu.medium.com/?source=post_page-----42d07462fe59--------------------------------)[![Lan
    Chu](../Images/813b24f60d6cfe2c9273e064d850c7fe.png)](https://huonglanchu.medium.com/?source=post_page-----42d07462fe59--------------------------------)[](https://towardsdatascience.com/?source=post_page-----42d07462fe59--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----42d07462fe59--------------------------------)
    [Lan Chu](https://huonglanchu.medium.com/?source=post_page-----42d07462fe59--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://huonglanchu.medium.com/?source=post_page-----42d07462fe59--------------------------------)[![兰楚](../Images/813b24f60d6cfe2c9273e064d850c7fe.png)](https://huonglanchu.medium.com/?source=post_page-----42d07462fe59--------------------------------)[](https://towardsdatascience.com/?source=post_page-----42d07462fe59--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----42d07462fe59--------------------------------)
    [兰楚](https://huonglanchu.medium.com/?source=post_page-----42d07462fe59--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----42d07462fe59--------------------------------)
    ·12 min read·Jul 21, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----42d07462fe59--------------------------------)
    ·阅读时间 12 分钟·2023年7月21日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: If you have been on any social media platform in the past months, I am sure
    you have heard about ChatGPT, Google Bard, Microsoft Bing and a myriad of new
    language models. All these new models, some can argue, are better writers than
    you and me and their English is definitely much better than mine **🥲** Every few
    years, somebody just invents something crazy that makes you totally reconsider
    what is possible. And in this article, we will be talking about the kind of invention
    that is rocking everyone in the world — yes, you guessed it — ChatGPT.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在过去几个月里使用过任何社交媒体平台，我相信你一定听说过 ChatGPT、Google Bard、Microsoft Bing 和许多新的语言模型。所有这些新模型，有人可能会争辩说，比你我写得更好，他们的英语也确实比我的好
    **🥲** 每隔几年，就会有人发明一些疯狂的东西，让你完全重新考虑可能性。而在这篇文章中，我们将讨论一种让全世界都在震撼的发明——是的，你猜对了——ChatGPT。
- en: '![](../Images/e9402ce0a1ff589cf90aaf22d6fcd633.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9402ce0a1ff589cf90aaf22d6fcd633.png)'
- en: Image generated with Bing image creator. Artistic representation of human intelligence.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 Bing 图像创建器生成。对人类智能的艺术表现。
- en: As we will increasingly rely on AI to do things for us, to make decisions for
    us, it is natural to ask whether AI is truly intelligent in the sense that its
    understanding of language mirrors our own, or that it is fundamentally different?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们越来越依赖 AI 为我们做事和做决策，提出 AI 是否真正智能的问题是自然的，特别是它对语言的理解是否反映了我们自己的理解，还是在本质上有所不同？
- en: To make sense of it all, we are going to first look into how the Generative-Pretrained
    Transformer (GPT) and ChatGPT works, and then discuss what it means for an AI
    to be intelligent.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一切，我们将首先探讨生成预训练变换器（GPT）和 ChatGPT 的工作原理，然后讨论 AI 智能的含义。
- en: Understanding GPT Model
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 GPT 模型
- en: The GPT model, first proposed by OpenAI in their paper [Improving Language Understanding
    by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf),
    uses unsupervised pre-training followed by supervised fine-tuning on various language
    tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: GPT 模型最初由 OpenAI 在其论文 [改进语言理解的生成预训练](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
    中提出，使用无监督预训练，然后在各种语言任务上进行监督微调。
- en: '![](../Images/46fbb43138db57f871a9d50d3d8a1fb9.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/46fbb43138db57f871a9d50d3d8a1fb9.png)'
- en: 'Source: [language_understanding_paper.pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [language_understanding_paper.pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)'
- en: The model architecture is based on Transformers, which has demonstrated robust
    performance in tasks such as machine translation and document generation. This
    model architecture was first introduced in the paper “[Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf)”
    by Google researchers. It provides an organized memory for managing long-term
    dependencies in text compared to [recurrent neural networks](https://en.wikipedia.org/wiki/Recurrent_neural_network)
    and [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network),
    leading to better performance across a wide range of tasks.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型架构基于 Transformers，已在机器翻译和文档生成等任务中展现出强大的性能。该模型架构首次在 Google 研究人员的论文 “[Attention
    is all you need](https://arxiv.org/pdf/1706.03762.pdf)” 中提出。与[递归神经网络](https://en.wikipedia.org/wiki/Recurrent_neural_network)和[卷积神经网络](https://en.wikipedia.org/wiki/Convolutional_neural_network)相比，它提供了一个有组织的内存，用于管理文本中的长期依赖关系，从而在广泛的任务中实现了更好的性能。
- en: '**It’s a prediction game**'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**这是一个预测游戏**'
- en: You can think of GPT model as a machine that is good at guessing what comes
    next. For example, if you give it the phrase “**Instead of turning right, she
    turns**…”, GPT might predict “left” or “back” or something else as the next word.
    How did it learn this? It does this by reading a large amount of existing text
    and learning how words tend to appear in context with other words and predicting
    the next most likely word that might appear in response to a request from users.
    Or to be precise, it learns how to interpret the positional encoding from the
    data. This means that we slap a number of each word in a sentence and as you train
    the model on a lot of text, it learns how to interpret the positional encoding
    of each word in a sentence.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将 GPT 模型视为一种擅长预测下一个内容的机器。例如，如果你给它短语“**她没有右转，而是转**……”，GPT 可能会预测“左转”或“回转”或其他作为下一个单词。它是如何学习到这一点的？它通过阅读大量现有文本，学习单词在与其他单词的上下文中如何出现，并预测可能出现的下一个最可能的单词。或者更准确地说，它学习如何解读数据中的位置编码。这意味着我们给句子中的每个单词打上一个编号，当你在大量文本上训练模型时，它学习如何解读句子中每个单词的位置编码。
- en: '![](../Images/8070cda8dd03456a317466de5d392c79.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8070cda8dd03456a317466de5d392c79.png)'
- en: Image by author.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '![](../Images/22381e723a004acaaec9ddddca29a381.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22381e723a004acaaec9ddddca29a381.png)'
- en: Image by author
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '**Transformer**'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Transformer**'
- en: But it is not just guessing one word at a time, it is thinking about whole sentences
    and even paragraphs — and this is where the transformer architecture comes into
    the picture.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但这不仅仅是一次猜一个词，它是在考虑整个句子甚至段落——这就是 transformer 架构发挥作用的地方。
- en: The “magic ingredient” that helps GPT make these predictions is the self-attention
    mechanism in transformer architecture. This mechanism helps the model determine
    the importance of each word in a sentence when predicting the next word. For instance,
    in the sentence “I walked my dog every day because it makes me…”, the word “dog”
    might indicate to GPT that the next word is likely related to dogs and feelings,
    such as “happy” or “relaxed”.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 帮助 GPT 做出这些预测的“魔法成分”是 transformer 架构中的自注意力机制。该机制帮助模型在预测下一个单词时确定句子中每个单词的重要性。例如，在句子“我每天都带着我的狗散步，因为它让我……”中，单词“狗”可能会提示
    GPT 下一个单词很可能与狗和情感相关，如“快乐”或“放松”。
- en: '![](../Images/7cb0aa616f35cb69351873f681a480a4.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7cb0aa616f35cb69351873f681a480a4.png)'
- en: 'Source: [language_understanding_paper.pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[language_understanding_paper.pdf](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)
- en: '**Self-attention mechanism**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**自注意力机制**'
- en: What is self-attention anyway? Let’s imagine a group of people (words) playing
    a game (sentence). In this game, each player represents a word in a sentence.
    Now, imagine that each player needs to determine how much attention they should
    pay to every other player on the field, including themselves, to predict the next
    move in the game.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力究竟是什么？让我们想象一群人（单词）正在玩一个游戏（句子）。在这个游戏中，每个玩家代表一个句子中的单词。现在，想象每个玩家需要确定他们应该多关注场上其他每个玩家，包括自己，以预测游戏中的下一个动作。
- en: In this context, self-attention is like each player communicating with every
    other player in the game. This communication allows them to assess the importance
    of every other player. Some players may seem highly significant (high attention)
    to you, while others may seem less so (low attention).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个上下文中，自注意力机制就像每个玩家与游戏中的其他所有玩家进行交流。这种交流使他们能够评估其他每个玩家的重要性。有些玩家对你可能显得非常重要（高注意力），而其他玩家可能显得不那么重要（低注意力）。
- en: '![](../Images/8396ac02a5a2d75f61400a4406ce0d6d.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8396ac02a5a2d75f61400a4406ce0d6d.png)'
- en: Image by author. The thickness of the arrow represents the strong attention
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。箭头的粗细代表了强注意力。
- en: The level of importance is determined by how relevant each player is to the
    individual’s understanding of the game. For instance, if you’re a forward in a
    soccer game, you might find the midfielders highly relevant because they support
    your attacks, while the goalkeeper might seem less important to your immediate
    actions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 重要性的级别由每个玩家与个人对游戏理解的相关性决定。例如，如果你在足球比赛中是前锋，你可能会发现中场球员非常重要，因为他们支持你的进攻，而门将可能对你的即时行动看起来不那么重要。
- en: Now, imagine all of this happening simultaneously, with every single player
    communicating with all others to understand their relevance to the game. From
    this, each player calculates the significance score of every other player, including
    themselves.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，想象这一切同时发生，每一个玩家与所有其他玩家进行沟通，以了解他们在游戏中的相关性。由此，每个玩家计算出每个其他玩家的显著性分数，包括他们自己。
- en: In other words, each player isn’t just considering one other player at a time,
    but all other players on the field simultaneously. This simultaneous consideration
    is a key feature of the self-attention mechanism, and it’s what enables the model
    to capture complex relationships and dependencies between players in a game.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，每个玩家不仅仅是考虑一个其他玩家，而是同时考虑场上所有其他玩家。这种同时考虑是自注意力机制的一个关键特性，它使模型能够捕捉游戏中玩家之间复杂的关系和依赖。
- en: '![](../Images/29147d03b9d9b5ae6bb8f3d6a7274e4b.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/29147d03b9d9b5ae6bb8f3d6a7274e4b.png)'
- en: Image by author.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片。
- en: In the above example, the “word” server means very different things. Self-attention
    allows a model to understand a word in the context of the words around it. When
    the model processed the word “server” in the first sentence, it might be attending
    to the word “check” while in the second sentence, the server might be attending
    to the word “crashed” because the only way for the model to understand that the
    word “server” in the second sentence is a computer server/system is because of
    the word “crashed”. Meanwhile in the first sentence, the word server is attending
    itself to the word “check” because that is the only way the model can understand
    that the word “server” in the first sentence refers to a human.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述例子中，“word”这个词的意思非常不同。自注意力机制允许模型在周围词语的上下文中理解一个词。当模型处理第一个句子中的“server”时，它可能会关注“check”这个词，而在第二个句子中，服务器可能会关注“crashed”这个词，因为模型理解第二个句子中“server”指的是计算机服务器/系统的唯一方式是通过“crashed”这个词。同时，在第一个句子中，词“server”关注“check”这个词，因为这是模型理解第一个句子中“server”指的是一个人的唯一方式。
- en: The self-attention mechanism allows the GPT model to weigh the importance of
    each word in the sentence when predicting the next word by outputting the weights
    of each word as a vector, which will be used as the input for the prediction layer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 自注意力机制允许GPT模型在预测下一个词时权衡句子中每个词的重要性，通过将每个词的权重输出为一个向量，这些向量将作为预测层的输入。
- en: '**The prediction layer**'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**预测层**'
- en: The final part on top of the transformer layer is a linear layer that transforms
    the vector output of the Transformer layer into a set of logits — scores that
    the machine learning model assigns to predict the next word in a sentence. Each
    possible next token gets a logit (a score). These logits are then passed through
    a SoftMax function to get probabilities, and the word with the highest probability
    is selected as the prediction.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer层顶部的最终部分是一个线性层，它将Transformer层的向量输出转换为一组logits——机器学习模型分配的用于预测句子中下一个词的分数。每个可能的下一个词汇都获得一个logit（一个分数）。这些logits随后通过SoftMax函数获得概率，具有最高概率的词被选择为预测词。
- en: '**This process is akin to a prediction game.** And because there are many possible
    words that could come next in our example sentence “Instead of turning right,
    she turns...”, there is an element of randomness in the way a model can respond.
    In many cases, the GPT models can answer the same question in different ways —
    which I think all of us have experienced while playing with ChatGPT.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**这个过程类似于一个预测游戏。** 由于在我们的示例句子“Instead of turning right, she turns...”中，可能出现很多种接下来的单词，因此模型响应的方式中存在一定的随机性。在许多情况下，GPT
    模型可以用不同的方式回答相同的问题——我认为我们所有人都在与 ChatGPT 互动时经历过这种情况。'
- en: How ChatGPT Works
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 的工作原理
- en: Fine-tuning GPT model for dialogue
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微调 GPT 模型以进行对话
- en: ChatGPT is a fine-tuned version of GPT-3.5 and has been developed in a way that
    allows it to understand and respond to user questions and instructions.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 是 GPT-3.5 的一个微调版本，并且已经以一种允许它理解和响应用户问题和指令的方式进行了开发。
- en: Training data
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据
- en: The three primary sources of information are (1) information that is publicly
    available on the internet, (2) information that is licensed from third parties,
    and (3) information that users or human trainers provide.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 三个主要的信息来源是（1）互联网上公开可用的信息，（2）从第三方处获得的许可信息，以及（3）用户或人类训练师提供的信息。
- en: Training process
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练过程
- en: In this section, I will give a high-level explanation of the training process
    of ChatGPT, which involves supervised fine-tuning, the creation of a reward model
    for reinforcement learning, and fine-tuning with Proximal Policy Optimisation
    (PPO).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我将对 ChatGPT 的训练过程进行高层次的解释，其中包括监督微调、创建奖励模型用于强化学习以及使用邻近策略优化（PPO）进行微调。
- en: '![](../Images/0abe4e197e41c0f7bf301ff4fc4960b8.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0abe4e197e41c0f7bf301ff4fc4960b8.png)'
- en: 'Source: Training language models to follow instructions with human feedback
    OpenAI et al., 2022 [https://arxiv.org/pdf/2203.02155.pdf](https://arxiv.org/pdf/2203.02155.pdf).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：训练语言模型以遵循人类反馈的指令 OpenAI 等，2022 [https://arxiv.org/pdf/2203.02155.pdf](https://arxiv.org/pdf/2203.02155.pdf)。
- en: '**Step 1: Train a supervised learning model**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 1 步：训练一个监督学习模型**'
- en: In this step, the goal is to provide the model with examples of the desired
    behavior. This is done by having human AI trainers interact with the model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步中，目标是向模型提供所需行为的示例。这是通过让人类 AI 训练师与模型进行互动来实现的。
- en: This starts with collecting prompts from users. These prompts are then given
    to the AI trainers who generate responses that demonstrate the desired output
    behavior. This prompt-response labelled data is then used to fine-tune GPT-3.5,
    with the goal of learning to generate similar responses when presented with similar
    prompts in the future.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这从收集用户的提示开始。这些提示然后交给 AI 训练师，AI 训练师生成展示所需输出行为的响应。然后，这些提示-响应标注数据被用来微调 GPT-3.5，目标是在未来面对类似提示时生成类似的响应。
- en: '**Step 2: Train a reward model for Reinforcement learning**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 2 步：训练一个奖励模型以进行强化学习**'
- en: The goal is to train a reward model that gives a score to the Supervised fine-tuned
    model outputs based on how desirable these outputs are for AI trainers. In other
    words, this reward model says something about the quality of the output based
    on the AI trainer’s preference.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是训练一个奖励模型，该模型根据监督微调模型输出的结果对其进行评分，这些输出对于 AI 训练师来说是多么令人满意。换句话说，这个奖励模型根据 AI 训练师的偏好对输出的质量进行评估。
- en: 'Here’s how it works:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是它的工作原理：
- en: A list of prompts is selected, and the supervised fine-tuned model generates
    multiple outputs for each prompt.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择一个提示列表，监督微调模型为每个提示生成多个输出。
- en: AI trainers rank the outputs from best to worst. The result is a new labeled
    dataset, where the rankings are the labels.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 训练师对输出结果进行从最好到最差的排名。结果是一个新的标注数据集，其中的排名就是标签。
- en: This new data is used to train a reward model that takes the output of the SFT
    model and ranks them in order of preference.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些新数据用于训练一个奖励模型，该模型接受 SFT 模型的输出并按偏好顺序对其进行排名。
- en: '**Step 3: Optimize the policy using the PPO algorithm**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**第 3 步：使用 PPO 算法优化策略**'
- en: '[**Reinforcement Learning**](https://www.assemblyai.com/blog/reinforcement-learning-with-deep-q-learning-explained/)
    (RL) is now applied to improve the policy by letting it optimize the reward model.
    In RL, a policy is a strategy or a set of rules that an agent follows to make
    decisions in an environment. It is a way for the agent to determine which action
    to take based on the current state.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[**强化学习**](https://www.assemblyai.com/blog/reinforcement-learning-with-deep-q-learning-explained/)（RL）现在被应用于通过优化奖励模型来改进策略。在RL中，策略是代理在环境中做出决策时遵循的策略或规则集合。这是一种让代理根据当前状态确定采取何种行动的方法。'
- en: How Reinforcement learning works — Example using Hide and Seek game
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习如何工作——以捉迷藏游戏为例
- en: RL is about learning from sequential interactions with the environment to optimize
    a long-term goal. Given the current input, you make a decision and the next input
    depends on your decisions. [PPO](https://openai.com/research/openai-baselines-ppo)
    (Proximal policy optimization) is the algorithm that is used by openAI to train
    agents in RL. In RL, **the agent/AI** **learns from and updates the current policy
    directly**, rather than learning only from past experiences (only training data).
    This means that PPO is continuously updating the current policy based on the actions
    that the agent is taking and the rewards it is receiving.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: RL是通过与环境的连续交互来优化长期目标的学习过程。根据当前输入，你做出决策，下一次输入取决于你的决策。[PPO](https://openai.com/research/openai-baselines-ppo)（近端策略优化）是OpenAI用来训练RL代理的算法。在RL中，**代理/AI**
    **直接从和更新当前策略中学习**，而不是仅仅从过去的经验（仅训练数据）中学习。这意味着PPO根据代理采取的行动和收到的奖励不断更新当前策略。
- en: First, the trained supervised fine-tuned model in step 1 is used to initialize
    the PPO model. It will generate a response given a prompt. In the next stage,
    the reward model (built in step 2) produces a reward score for the response. Finally,
    the reward is fed back to the baseline model to update the parameters using the
    PPO algorithm that is supposed to increase the likelihood of better responses
    in the future. This process is iterated multiple times, with the model improving
    as it receives more feedback from the reward model and adjusts its parameters
    accordingly using PPO. This allows the model to learn from human feedback and
    improve its ability to generate future better responses.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在第1步中训练过的监督微调模型用于初始化PPO模型。它会在给定提示时生成一个响应。在下一阶段，奖励模型（在第2步中建立）为响应生成奖励分数。最后，奖励反馈给基准模型，以使用PPO算法更新参数，旨在提高未来更好响应的可能性。这个过程会重复多次，模型随着从奖励模型收到更多反馈而不断改进，并使用PPO调整其参数。这使得模型能够从人类反馈中学习，并提高生成未来更好响应的能力。
- en: Is GPT model actually “intelligent”?
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT模型真的“智能”吗？
- en: While GPT model’s ability to generate human-like text is impressive, is its
    understanding of language the same or fundamentally different from human understanding?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管GPT模型生成类人文本的能力令人印象深刻，但它对语言的理解是否与人类的理解相同或有根本区别？
- en: '![](../Images/0fe9f4fcf8c5dce0ca73eddb65ba65e6.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0fe9f4fcf8c5dce0ca73eddb65ba65e6.png)'
- en: Image generated with Dall-E 2\. Classic idea of intelligence.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由Dall-E 2生成的图像。经典的智能概念。
- en: A [study](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1224/reports/custom_116874134.pdf)
    from Stanford University attempt to understand whether pre-trained language models
    (PTLM) such as BERT or RobBERTa can understand definitions by finding the semantic
    relevance between contexts and definitions. The approach is that given a target
    word **w** in a context sentence **c**, the models are required to detect if a
    sentence **g** can be considered as a description of the definition of **w**.
    The PTLMs calculate the semantic similarity between the context embedding and
    the candidate definition embedding by using cosine similarity, which calculates
    the cosine of the angle between the two embeddings. The closer the cosine similarity
    is to 1, the more semantically similar the two embeddings. The studies found that
    PTLM struggles to understand when the definitions are abstract.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一项来自斯坦福大学的[研究](https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1224/reports/custom_116874134.pdf)尝试了解预训练语言模型（PTLM），如BERT或RobBERTa，是否能够通过找出上下文与定义之间的语义相关性来理解定义。该方法是，在给定上下文句子**c**中的目标词**w**时，模型需要检测一个句子**g**是否可以被视为**w**定义的描述。PTLM通过使用余弦相似度计算上下文嵌入与候选定义嵌入之间的语义相似性，余弦相似度计算两个嵌入之间角度的余弦值。余弦相似度越接近1，两者的语义相似性越高。研究发现，PTLM在定义抽象时难以理解。
- en: So, I guess the first question to address is what “understanding” and “intelligence”
    actually mean.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我想第一个需要解决的问题是“理解”和“智能”实际上是什么意思。
- en: 'In this regard, the authors of [On the Dangers of Stochastic Parrots: Can Language
    Models Be Too Big?](https://dl.acm.org/doi/10.1145/3442188.3445922) argue that
    **the text, which is generated by large language models, lacks actual meaning
    and intention.**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，[《随机鹦鹉的危险：语言模型是否过大？》](https://dl.acm.org/doi/10.1145/3442188.3445922) 的作者认为**由大型语言模型生成的文本缺乏实际的意义和意图**。
- en: Traditionally, when two people engage in a conversation, they both try to understand
    each other’s beliefs, knowledge, experiences, and perspectives. The words we choose
    to use and **what we say depend on our mental “picture” or understanding of the
    other person**. Whether it is a child or an adult, a colleague or a family member,
    a partner, or someone we just met at the bus stop, we have certain assumptions
    about their thoughts and characteristics. Similarly, when we listen to someone
    else speaking, we automatically place their words in context based on our mental
    understanding of them, including their beliefs, knowledge, understanding, and
    intentions.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，当两个人进行对话时，他们都会尽力理解对方的信仰、知识、经验和观点。我们选择使用的词语和**我们所说的内容取决于我们对对方的心理“图景”或理解**。无论是孩子还是成人，同事还是家庭成员，伴侣，还是我们在公交车站刚认识的人，我们对他们的思想和特征都有一定的假设。同样，当我们听别人讲话时，我们会根据对他们的心理理解，包括他们的信仰、知识、理解和意图，自动将他们的话语置于背景中。
- en: '![](../Images/a169efa88221b1cb4bcf7d50bcc6c999.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a169efa88221b1cb4bcf7d50bcc6c999.png)'
- en: Photo by [Priscilla Du Preez](https://unsplash.com/@priscilladupreez?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/nF8xhLMmg0c?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[Priscilla Du Preez](https://unsplash.com/@priscilladupreez?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    于 [Unsplash](https://unsplash.com/photos/nF8xhLMmg0c?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: '**When a language model generates text, it doesn’t have any intention to communicate
    or consider the beliefs or thoughts of the person reading it**. The training data
    used to create the model didn’t involve interacting with listeners or understanding
    their perspectives. Essentially, the language model can not understand and engage
    in meaningful communication as humans do.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**当语言模型生成文本时，它没有任何沟通的意图，也不会考虑阅读者的信仰或思想**。用于创建模型的训练数据并未涉及与听众互动或理解他们的观点。实际上，语言模型不能像人类一样理解和进行有意义的沟通。'
- en: Our human brains however are so influenced by our language that we interpret
    our communication with large language models as if they are trying to convey meaningful
    intent. And if one side of the communication lacks actual meaning, our understanding
    of deeper/inferred meaning becomes an illusion.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的人脑受到语言的影响很大，我们将与大型语言模型的沟通解释为它们试图传达有意义的意图。如果沟通的一方缺乏实际意义，我们对更深层次/推断意义的理解就变成了一种幻觉。
- en: Looking at how the GPT model was built, it is obvious that **these language
    models do not process information and generate text consciously**. It was all
    a prediction game that foresees which words are coming next based on the patterns
    the models have seen from the training data. In addition, large language model
    like ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical
    answers because it does not have the common sense reasoning as we — humans do.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从 GPT 模型的构建方式来看，显然**这些语言模型并不以自觉的方式处理信息和生成文本**。这完全是一个预测游戏，根据模型从训练数据中看到的模式来预测接下来会出现哪些词。此外，像
    ChatGPT 这样的语言模型有时会写出看似合理但实际上错误或无意义的答案，因为它并不像我们——人类一样拥有常识推理能力。
- en: Can AI gain consciousness?
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能能获得意识吗？
- en: '**Human intelligence and understanding go hand in hand with consciousness**
    — which is the ability to feel things, pain, joy, love and angers. Consciousness
    is linked to an organic body so a natural question to ask is would it be possible
    that non-organic systems can obtain consciousness? Because we know so little about
    human consciousness, we can’t rule out the possibility of computer developing
    consciousness. It is still an ongoing research, and whether AI can have consciousness
    or not, we might see in the coming decades. But perhaps one piece of good news
    is that at least for now we won’t have to yet deal with the science-fiction nightmare
    of AI obtaining consciousness and deciding to enslave and wipe out human :).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**人类智能和理解与意识是密不可分的**——意识是感知事物、痛苦、快乐、爱和愤怒的能力。意识与有机体相关联，因此自然会有一个问题：非有机系统是否可能获得意识？因为我们对人类意识知之甚少，所以不能排除计算机发展意识的可能性。这仍然是一个正在进行的研究，无论AI是否能够拥有意识，我们可能在未来几十年中会看到。不过，也许有一个好消息是，至少目前我们不必面对科幻小说中的噩梦——AI获得意识并决定奴役和消灭人类的情景
    :).'
- en: I think there is still a long way to go before machine intelligence becomes
    similar to human intelligence. “It is no longer in the realm of science fiction
    to imagine AI systems having feelings and even human-level consciousness,” says
    the [BBC](https://www.bbc.com/news/technology-65401783). Most experts agree that
    AI is nowhere near this level of sophistication but it is evolving at lightning
    speed and it is difficult to imagine how it will look like in the next few years.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为，机器智能要达到类似于人类智能的水平还需要很长时间。“想象AI系统拥有情感甚至人类水平的意识已经不再是科幻小说中的场景，”[BBC](https://www.bbc.com/news/technology-65401783)说道。大多数专家同意，AI离这种复杂程度还很遥远，但它正以闪电般的速度发展，难以想象未来几年会是什么样子。
- en: What I believe is that we can say with reasonable confidence that current artificial
    intelligence models have developed a set of skills that are closely related to
    certain aspects of human intelligence. It might be the time for AI creators to
    invest more in understanding consciousness.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信我们可以相当有信心地说，当前的人工智能模型已经发展出一套与人类智能某些方面密切相关的技能。也许是时候让AI创造者更多地投资于理解意识。
- en: References
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Introducing ChatGPT (openai.com)](https://openai.com/blog/chatgpt)'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[介绍ChatGPT (openai.com)](https://openai.com/blog/chatgpt)'
- en: '[How ChatGPT and Our Language Models Are Developed | OpenAI Help Center](https://help.openai.com/en/articles/7842364-how-chatgpt-and-our-language-models-are-developed)'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ChatGPT和我们的语言模型如何开发 | OpenAI帮助中心](https://help.openai.com/en/articles/7842364-how-chatgpt-and-our-language-models-are-developed)'
- en: '[The inside story of how ChatGPT was built from the people who made it | MIT
    Technology Review](https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai/)'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[ChatGPT的幕后故事：由创建者讲述 | MIT技术评论](https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai/)'
- en: Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., …
    & Amodei, D. (2020). Language models are few-shot learners. *Advances in neural
    information processing systems*, *33*, 1877–1901.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., …
    & Amodei, D. (2020). 语言模型是少样本学习者。*神经信息处理系统的进展*, *33*, 1877–1901。
- en: Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., … &
    Lowe, R. (2022). Training language models to follow instructions with human feedback.
    *Advances in Neural Information Processing Systems*, *35*, 27730–27744.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., … &
    Lowe, R. (2022). 通过人类反馈训练语言模型以遵循指令。*神经信息处理系统的进展*, *35*, 27730–27744。
- en: Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving
    language understanding by generative pre-training.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). 通过生成预训练提高语言理解能力。
- en: 'Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021, March).
    On the dangers of stochastic parrots: Can language models be too big?🦜. In *Proceedings
    of the 2021 ACM conference on fairness, accountability, and transparency* (pp.
    610–623).'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021年3月). 关于随机鹦鹉的危险：语言模型是否可能过大？🦜.
    收录于*2021年ACM公平性、问责制与透明度会议论文集*（第610–623页）。
- en: '[Are AIs actually intelligent?. If you have been on any social media… | by
    Telmo Subira Rodriguez | Jul, 2023 | Medium](https://medium.com/@telmosubirar/are-ais-actually-intelligent-caacfb2fa7e8)'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[人工智能真的智能吗？如果你曾经在任何社交媒体上… | 作者：Telmo Subira Rodriguez | 2023年7月 | Medium](https://medium.com/@telmosubirar/are-ais-actually-intelligent-caacfb2fa7e8)'
- en: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    … & Polosukhin, I. (2017). Attention is all you need. *Advances in neural information
    processing systems*, *30*
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    … & Polosukhin, I. (2017). 注意力机制就是你所需的一切。*神经信息处理系统进展*, *30*
