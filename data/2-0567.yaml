- en: Convolutional Networks — Intuitively and Exhaustively Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积网络 — 直观且详尽的解释
- en: 原文：[https://towardsdatascience.com/convolutional-networks-intuitively-and-exhaustively-explained-ab08f6353f96](https://towardsdatascience.com/convolutional-networks-intuitively-and-exhaustively-explained-ab08f6353f96)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/convolutional-networks-intuitively-and-exhaustively-explained-ab08f6353f96](https://towardsdatascience.com/convolutional-networks-intuitively-and-exhaustively-explained-ab08f6353f96)
- en: Unpacking a cornerstone modeling strategy
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解构一个基石建模策略
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----ab08f6353f96--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----ab08f6353f96--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ab08f6353f96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ab08f6353f96--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----ab08f6353f96--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielwarfield1?source=post_page-----ab08f6353f96--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----ab08f6353f96--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ab08f6353f96--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ab08f6353f96--------------------------------)
    [丹尼尔·沃菲尔德](https://medium.com/@danielwarfield1?source=post_page-----ab08f6353f96--------------------------------)'
- en: ·Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ab08f6353f96--------------------------------)
    ·11 min read·Oct 26, 2023
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ab08f6353f96--------------------------------)
    ·阅读时间11分钟·2023年10月26日
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '![](../Images/eaf12909ea93c0a6b57e7c294ea991c2.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/eaf12909ea93c0a6b57e7c294ea991c2.png)'
- en: “Convolved” by the author using MidJourney. All images by the author unless
    otherwise specified.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: “卷积”由作者使用MidJourney完成。除非另有说明，所有图片均由作者提供。
- en: Convolutional neural networks are a mainstay in computer vision, signal processing,
    and a massive number of other machine learning tasks. They’re fairly straightforward
    and, as a result, many people take them for granted without *really* understanding
    them. In this article we’ll go over the theory of convolutional networks, intuitively
    and exhaustively, and we’ll explore their application within a few use cases.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络是计算机视觉、信号处理和大量其他机器学习任务中的主要方法。它们相对简单，因此许多人往往对它们视而不见，*真正*不了解它们。在本文中，我们将直观且详尽地讨论卷积网络的理论，并探讨它们在几个使用案例中的应用。
- en: '**Who is this useful for?** Anyone interested in computer vision, signal analysis,
    or machine learning.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**这对谁有用？** 对计算机视觉、信号分析或机器学习感兴趣的任何人。'
- en: '**How advanced is this post?** This is a very powerful, but very simple concept;
    great for beginners. This also might be a good refresher for seasoned data scientists,
    particularly in considering convolutions in various dimensions.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**这篇文章的难度如何？** 这是一个非常强大的但又非常简单的概念；非常适合初学者。对于经验丰富的数据科学家，这也可能是一个很好的复习，特别是在考虑不同维度的卷积时。'
- en: '**Pre-requisites:** A general familiarity of with backpropagation and dense
    neural networks might be useful, but is not required. I cover both of those in
    this post:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提条件：** 对反向传播和全连接神经网络有一定的了解可能会有所帮助，但不是必须的。我在这篇文章中涵盖了这两个内容：'
- en: '[](/what-are-gradients-and-why-do-they-explode-add23264d24b?source=post_page-----ab08f6353f96--------------------------------)
    [## What Are Gradients, and Why Do They Explode?'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[](/what-are-gradients-and-why-do-they-explode-add23264d24b?source=post_page-----ab08f6353f96--------------------------------)
    [## 什么是梯度，它们为何会爆炸？'
- en: By reading this post you will have a firm understanding of the most important
    concept in deep learning
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过阅读这篇文章，你将对深度学习中最重要的概念有一个扎实的理解
- en: towardsdatascience.com](/what-are-gradients-and-why-do-they-explode-add23264d24b?source=post_page-----ab08f6353f96--------------------------------)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: towardsdatascience.com](/what-are-gradients-and-why-do-they-explode-add23264d24b?source=post_page-----ab08f6353f96--------------------------------)
- en: The Reason Convolutional Networks Exist
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积网络存在的原因
- en: The first topic many fledgling data scientists explore is a dense neural network.
    This is the classic neural network consisting of nodes and edges which have certain
    learnable parameters. These parameters allow the model to learn subtle relationships
    about the topics they’re trained on.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 许多初学的数据科学家首先探索的主题是全连接神经网络。这是一种经典的神经网络，由具有一定可学习参数的节点和边组成。这些参数使得模型能够学习关于其训练主题的微妙关系。
- en: '![](../Images/8ed63e6c50fddbf5c687c1ab1a6ed2ff.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ed63e6c50fddbf5c687c1ab1a6ed2ff.png)'
- en: A conceptual diagram of a dense network which takes in some inputs and predicts
    an output. It learns the necessary parameters to perform well at the task by incrementally
    learning from known examples (i.e. the success and failure of previous super bowl
    teams).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一个概念图，展示了一个密集网络如何接受一些输入并预测输出。它通过逐步学习已知示例（即之前超级碗团队的成功与失败）来学习必要的参数以在任务中表现良好。
- en: As the number of neurons grow within the network, the connections between layers
    become more and more abundant. This can allow complex reasoning, which is great,
    but the “denseness” of dense networks presents a problem when dealing with images.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着网络中神经元数量的增加，层与层之间的连接变得越来越丰富。这可以实现复杂的推理，这很好，但密集网络的“密集性”在处理图像时会带来问题。
- en: Let’s say we wanted to train a dense neural network to predict if an image contains
    a dog or not. We might create a dense network which looks at each pixel of the
    image, then boil that information down to some final output.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想训练一个密集神经网络来预测图像中是否包含狗。我们可能会创建一个密集网络来观察图像的每一个像素，然后将这些信息归纳为最终输出。
- en: '![](../Images/3cb04a82b78418beafcfc19402fa5c94.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cb04a82b78418beafcfc19402fa5c94.png)'
- en: A conceptual diagram of what hooking up an image to a dense network might look
    like
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 连接图像到密集网络的概念图。
- en: Already we’re experiencing a big problem. Skipping through some math to get
    to the point, for this tiny little network we would need 1,544 learnable parameters.
    For a larger image we would need a larger network. Say we have 64 neurons in the
    first layer and we want to learn to classify images that are 256x256 pixels. Just
    the first layer alone would be 8,388,608 parameters. That’s a lot of parameters
    for a, still, pretty tiny image.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经遇到了一个大问题。略过一些数学细节，针对这个小网络，我们需要1,544个可学习参数。对于更大的图像，我们需要更大的网络。假设我们在第一层有64个神经元，我们想学习对256x256像素的图像进行分类。仅第一层就有8,388,608个参数。对于一个相对较小的图像，这确实有很多参数。
- en: Another problem with neural networks is their sensitivity to minor changes in
    an image. Say we made two representations of our dog image; one with the dog at
    the top of the image, and one with the dog at the bottom.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的另一个问题是对图像中微小变化的敏感性。假设我们制作了两种表示狗图像的方式；一种是狗在图像的顶部，另一种是狗在底部。
- en: '![](../Images/ac78b6f3aa330ee0c0d13e121df84a84.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac78b6f3aa330ee0c0d13e121df84a84.png)'
- en: A neural network looking at the same pixel on two similar images
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个神经网络观察两个相似图像上相同的像素。
- en: Even though these images are very similar to the human eye, their values from
    the perspective of a neural network are very different. The neural network not
    only has to logically define a dog, but also needs to make that logical definition
    of a dog robust to all sorts of changes in the image. This might be possible,
    but that means we need to feed the network a lot of training data, and because
    dense networks have such a large number of parameters, each of those training
    steps is going to take a long time to compute.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些图像对人眼来说非常相似，但从神经网络的角度来看，它们的值却大相径庭。神经网络不仅需要逻辑上定义什么是狗，还需要使这种对狗的逻辑定义对图像中的各种变化具有鲁棒性。这可能是可行的，但这意味着我们需要向网络输入大量的训练数据，并且由于密集网络具有如此多的参数，每一步训练都将花费很长时间来计算。
- en: So, dense networks aren’t good at images; they’re too big and too sensitive
    to minor changes. In the next sections we’ll go over how convolutional networks
    address both of these issues, first by defining what a convolution is, then by
    describing how convolution is done within a neural network.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，密集网络不适合处理图像；它们太庞大且对微小变化过于敏感。在接下来的部分中，我们将深入探讨卷积网络如何解决这些问题，首先定义什么是卷积，然后描述神经网络中如何进行卷积操作。
- en: Convolution in a Nutshell
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积简明介绍
- en: At the center of the Convolutional Network is the operation of “convolution”.
    A “convolution” is the act of “convolving” a “kernel” over some “target” in order
    to “filter” it. That’s a lot of words you may or may not be familiar with, so
    let’s break it down. We’ll use edge detection within an image as a sample use
    case.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络的核心是“卷积”操作。 “卷积”是将一个“卷积核”作用于某个“目标”以进行“过滤”的过程。这些词可能你不太熟悉，我们来详细解释一下。我们将使用图像中的边缘检测作为示例。
- en: A kernel, from a convolutional perspective, is a small array of numbers
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从卷积的角度来看，卷积核是一个小的数字数组。
- en: '![](../Images/9223c2f4cfaaa037d53286c2fdb82197.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9223c2f4cfaaa037d53286c2fdb82197.png)'
- en: An example of a kernel. This specific kernel is used in edge detection
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 内核的示例。这个特定的内核用于边缘检测。
- en: This kernel can be used to transform an input image into another image. The
    act of using a standard operation to transform an input into an output is typically
    called “filtering” (think instagram filters used to modify images).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这个内核可以用于将输入图像转换成另一幅图像。使用标准操作将输入转换为输出的过程通常称为“过滤”（想想 Instagram 滤镜用于修改图像）。
- en: '![](../Images/58c6b8f8f4405c065d05dd4f03a0cd09.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/58c6b8f8f4405c065d05dd4f03a0cd09.png)'
- en: The kernel gets used to filter an input image to an image which highlights edges
    in the original image. Generally the input image is sometimes referred to as the
    “target” image, while the output is sometimes referred to as the “filtered” image.
    [Source](https://en.wikipedia.org/wiki/Kernel_(image_processing))
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 内核被用于过滤输入图像，生成一幅突出原始图像边缘的图像。通常，输入图像有时被称为“目标”图像，而输出图像有时被称为“过滤”图像。 [来源](https://en.wikipedia.org/wiki/Kernel_(image_processing))
- en: The filtering actually gets done with “convolution”. The kernel, which is much
    smaller than the input image, is placed in every possible position within the
    image. Then, at a given location, the values of the kernel are multiplied by values
    of the input image. The results are then summed together to define the value of
    the output image.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的过滤操作是通过“卷积”完成的。内核，比输入图像要小得多，被放置在图像中的每一个可能的位置。然后，在特定位置，内核的值与输入图像的值相乘，结果被加总在一起，以定义输出图像的值。
- en: '![](../Images/bdfda836a21fba0f8295c30d8185108d.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bdfda836a21fba0f8295c30d8185108d.png)'
- en: “convolving” the kernel across the target image. the 3x3 kernel gets applied
    to every 3x3 square of the target image. The values of the kernel are multiplied
    by the values of the pixels in the corresponding location, and then all values
    are added together. to construct a single pixel in the output image.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: “卷积”内核到目标图像上。3x3 内核被应用到目标图像的每个 3x3 区域。内核的值与对应位置的像素值相乘，然后将所有值加在一起，以构建输出图像中的一个像素。
- en: In machine learning convolutional is most often applied to images, but they
    work perfectly well in other domains. You can convolve a wavelet over a one dimensional
    signal, you can convolve a three dimensional tensor over a three dimensional space.
    Convolution can take place in an arbitrary number of dimensions.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，卷积最常用于图像，但它们在其他领域也能很好地工作。你可以对一维信号进行小波卷积，也可以对三维空间进行三维张量卷积。卷积可以在任意维度上进行。
- en: '![](../Images/7aa04ea302a3b1de1c2f199d8aaf68e5.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7aa04ea302a3b1de1c2f199d8aaf68e5.png)'
- en: An example of convolution in 1D, left, and convolution in 3D, right. both cases
    function similarly to 2D convolution; the kernel (depicted in blue) is swept over
    all possible locations (examples in red), the overlapping values are then multiplied
    and the results are summed together to construct a single output value.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 1D卷积的示例（左），以及3D卷积的示例（右）。这两种情况的功能类似于2D卷积；内核（用蓝色表示）在所有可能的位置上滑动（红色示例），重叠的值被相乘，然后结果被加总，以构建单一的输出值。
- en: We’ll stay in two dimensions for most of this article, but it’s important to
    keep the general aspect of convolutions in mind; they can be used for many problem
    types outside of computer vision.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的大部分内容中，我们将保持在二维，但重要的是要记住卷积的一般方面；它们可以用于计算机视觉以外的许多问题类型。
- en: So, now we know what convolution is and how it works. In the next section we’ll
    explore how this idea can be used to build models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了什么是卷积以及它是如何工作的。在下一节中，我们将探讨如何利用这一理念来构建模型。
- en: Convolutional Neural Networks in a Nutshell
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络概述
- en: The whole idea of a convolutional network is to use a combination of convolutions
    and downsampling to incrementally break down an image into a smaller and more
    meaningful representation. Typically this broken down representation of the image
    is then passed to a dense network to generate the final inference.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络的整个理念是通过卷积和降采样的组合，逐步将图像分解成更小、更有意义的表示。通常，这种分解后的图像表示会传递给一个密集网络，以生成最终的推断结果。
- en: '![](../Images/dea0fd49ad9be01cc23061c452a6df41.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dea0fd49ad9be01cc23061c452a6df41.png)'
- en: The high level architecture of a typical convolutional neural network. The actual
    convolutions typically exist within a “backbone” of convolutions and downsampling.
    Once the input has been condensed into a meaning-rich representation (also known
    as a bottleneck), the next step is typically a dense network, which is commonly
    referred to as a “head” or “projection head”, that generates the desired final
    response. I talk about these concepts a bit more in depth in another article about
    [the importance of projection heads in self-supervised learning](https://medium.com/towards-data-science/self-supervised-learning-using-projection-heads-b77af3911d33).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 典型卷积神经网络的高层架构。实际的卷积通常存在于“主干”部分的卷积和下采样中。一旦输入被浓缩为一个富有意义的表示（也称为瓶颈），下一步通常是一个密集网络，通常被称为“头”或“投影头”，它生成所需的最终响应。我在另一篇关于[自监督学习中投影头的重要性](https://medium.com/towards-data-science/self-supervised-learning-using-projection-heads-b77af3911d33)的文章中对这些概念进行了更深入的讨论。
- en: Similarly to a fully connected neural network which learns weights between connections
    to get better at a task, convolutional neural networks learn the values of kernels
    within the convolutional layers to get better at a task.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于全连接神经网络通过学习连接之间的权重来提高任务性能，卷积神经网络在卷积层内学习卷积核的值，以提高任务性能。
- en: '![](../Images/bdfda836a21fba0f8295c30d8185108d.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bdfda836a21fba0f8295c30d8185108d.png)'
- en: Recall how the kernel is swept through an image to transform it into a different
    representation. A convolutional network incrementally adjusts the values of the
    kernel to make a filtered image which is somehow better for the final modeling
    task.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下卷积核如何在图像上滑动，将其转换为不同的表示。卷积网络逐步调整卷积核的值，以生成经过滤的图像，这样在最终建模任务中表现得更好。
- en: There are many ways to downsample in a convolutional network, but the most common
    approach is max pooling. Max pooling is similar to convolution, in that a window
    is swept across an entire input. Unlike convolution, max pooling only preserves
    the maximum value from the window, not some combination of the entire window.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积网络中有许多下采样的方法，但最常见的方法是最大池化。最大池化类似于卷积，即一个窗口在整个输入上滑动。与卷积不同的是，最大池化只保留窗口中的最大值，而不是窗口的某种组合。
- en: '![](../Images/093054e0163631c91daebef56c0a1f84.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/093054e0163631c91daebef56c0a1f84.png)'
- en: An example of max pooling applied to an image, which downsamples the image from
    6x9 to 2x3\. If you’re curious why these squares don’t overlap while convolution
    does, that’s because of “stride”, which we’ll cover in a later section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个应用最大池化于图像的示例，它将图像从6x9下采样到2x3。如果你想知道为什么这些方块没有重叠，而卷积却有，那是因为“步幅”，我们将在后面的部分中讨论这个问题。
- en: So, through layers of a convolution and max pooling, an image is incrementally
    filtered and downsampled. Through each successive layer the image becomes more
    and more abstract, and smaller and smaller in size, until it contains an abstract
    and condensed representation of the image.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过卷积和最大池化层，图像被逐步过滤和下采样。通过每一层，图像变得越来越抽象，尺寸也越来越小，直到它包含图像的抽象和浓缩表示。
- en: And that’s were a lot of people stop in terms of theory. However, convolutional
    neural networks have some more critical concepts which people often disregard.
    Particularly, the feature dimension and how convolution relates with it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 很多人在理论层面上会停留在这里。然而，卷积神经网络还有一些更关键的概念，通常被忽视。特别是，特征维度以及卷积如何与之相关。
- en: '[⚠️](https://emojipedia.org/warning) **Epilepsy** **Warning: The following
    sections contain rapidly moving animations**[⚠️](https://emojipedia.org/warning)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[⚠️](https://emojipedia.org/warning) **癫痫** **警告：以下部分包含快速移动的动画**[⚠️](https://emojipedia.org/warning)'
- en: '**The Feature Dimension**'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**特征维度**'
- en: You might have noticed, in some of the previous examples, we used grayscale
    images. In reality images typically have three color channels; red, green, and
    blue. In other words, an image has two spatial dimensions (width and height) and
    one feature dimension (color).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在之前的一些示例中，我们使用了灰度图像。实际上，图像通常有三个颜色通道：红色、绿色和蓝色。换句话说，图像有两个空间维度（宽度和高度）和一个特征维度（颜色）。
- en: 'This idea of the feature dimension is critical to the thorough understanding
    of convolutional networks, so let’s look at a few examples:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 特征维度的这个概念对于深入理解卷积神经网络至关重要，因此我们来看看一些示例：
- en: '**Example 1) RGB images**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 1) RGB 图像**'
- en: Because an image contains two spatial dimension (height and width) and one feature
    dimension (color), an image can be conceptualized as three dimensional.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因为图像包含两个空间维度（高度和宽度）和一个特征维度（颜色），所以图像可以被概念化为三维。
- en: '![](../Images/cc5e6245277b03a52b7c8c17c2c337ca.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc5e6245277b03a52b7c8c17c2c337ca.png)'
- en: An image (on the left), the three channels that make up the image (middle),
    and the shape of the data which we’ll feed into the model (right)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧是图像，中间是构成图像的三个通道，右侧是我们将输入模型的数据形状。
- en: Generally, convolutional networks move their kernel along all spatial dimensions,
    **but not along the feature dimension**. With a two dimensional input like an
    image one usually uses a 3D kernel, which has the same depth as the feature dimension,
    but a smaller width and height. This kernel is then swept through all spatial
    dimensions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，卷积网络沿所有空间维度移动其核，**但不沿特征维度**。对于像图像这样的二维输入，通常使用一个3D核，它具有与特征维度相同的深度，但宽度和高度较小。然后，这个核在所有空间维度上滑动。
- en: '![](../Images/d7cc7e97118bafe0ae70b37539e0f5f8.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7cc7e97118bafe0ae70b37539e0f5f8.png)'
- en: 'A conceptual animation of convolution of an image. a 3D kernel is applied to
    the entire feature dimension, and is swept through both spatial dimensions. This
    is a 2D convolution, because the actual traversal takes place in two dimensions.
    Note: the feature dimension is also commonly referred to as “channels”.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图像卷积的概念动画。一个3D核应用于整个特征维度，并在两个空间维度上滑动。这是二维卷积，因为实际遍历发生在两个维度上。注意：特征维度也通常称为“通道”。
- en: Typically, instead of doing one convolution, it’s advantageous to do multiple
    convolutions, each with different kernels. This allows the convolutional network
    to create multiple representations of the image. Each of these convolutions uses
    its own learnable kernel, and the representations are concatenated together along
    the feature axis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，与其进行一次卷积，进行多次卷积，每次使用不同的核，会更有优势。这使得卷积网络能够创建图像的多种表示。每个卷积都使用自己的可学习核，这些表示沿特征轴连接在一起。
- en: '![](../Images/3dcbad1271225ed08a4e7ca96154f38c.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3dcbad1271225ed08a4e7ca96154f38c.png)'
- en: A conceptual diagram of three kernels applied to the input image. Each of these
    kernels create their own feature layer. all the values in each of the kernels
    are learnable parameters.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于输入图像的三个核的概念图。这些核中的每一个都创建自己的特征层。每个核中的所有值都是可学习的参数。
- en: As you may have inferred, you can have an arbitrary number of kernels, and can
    thus create a feature dimension of arbitrary depth. Many convolutional neural
    networks use a different number of features at various points within the model.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经推测的，你可以有任意数量的核，从而创建任意深度的特征维度。许多卷积神经网络在模型的不同点使用不同数量的特征。
- en: '![](../Images/1237ba1b57200527d64ef90b22658de8.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1237ba1b57200527d64ef90b22658de8.png)'
- en: The architecture for the original YOLO model, a landmark convolutional model
    in image processing. Notice how the boxes in the diagram are three dimensional,
    these boxes represent the height, width, and number of features at various points
    throughout the model. Don’t worry too much about the text of this image just yet,
    we’ll revisit this diagram later. [Source](https://arxiv.org/pdf/1506.02640.pdf)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 原始YOLO模型的架构，这是图像处理中的一个标志性卷积模型。注意图中的框是三维的，这些框代表了模型中各个点的高度、宽度和特征数量。不要过多担心这张图的文字，我们稍后会重新审视这个图。
    [来源](https://arxiv.org/pdf/1506.02640.pdf)
- en: Max pooling typically only considers a single feature layer at a time. In essence,
    we just do max pooling on each individual feature layer.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化通常只考虑单个特征层。本质上，我们只是对每个单独的特征层进行最大池化。
- en: '![](../Images/9f097b3bce52075c8e280d1de37d83f9.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9f097b3bce52075c8e280d1de37d83f9.png)'
- en: Conceptual diagram of maxpool applied to 3 features. Note, maxpool is typically
    applied after convolution, not before.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于三个特征的最大池化的概念图。注意，最大池化通常在卷积之后应用，而不是之前。
- en: Those are the two main operations, convolution and max pooling, on a two dimensional
    RGB image.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是二维RGB图像上的两个主要操作：卷积和最大池化。
- en: '**Example 2) Stereo Audio**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2) 立体声音频**'
- en: While time series signals like audio are typically thought of as one dimensional,
    they’re actually typically two dimensional, with one dimension representing time
    and another dimension representing multiple values at that time. For instance,
    stereo audio has two seperate channels, one for the left ear and one for the right
    ear.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然像音频这样的时间序列信号通常被认为是一维的，但实际上它们通常是二维的，一个维度表示时间，另一个维度表示该时间点的多个值。例如，立体声有两个独立的频道，一个用于左耳，一个用于右耳。
- en: '![](../Images/969984e9e726df61a073300d74b83630.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/969984e9e726df61a073300d74b83630.png)'
- en: The left and right sound waves from a snippet of stereo trumpet music, in the
    time domain. The X axis corresponds to time, in seconds, and the y axis corresponds
    to the amplitude of the signal, which controls the location of a speaker diaphragm,
    generating sound. From my article on the [frequency domain](https://medium.com/towards-data-science/use-frequency-more-frequently-14715714de38)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 来自一段立体小号音乐的左右声波，在时间域中。X轴对应于时间（以秒为单位），y轴对应于信号的幅度，控制扬声器振膜的位置，从而产生声音。参考我关于[频域](https://medium.com/towards-data-science/use-frequency-more-frequently-14715714de38)的文章。
- en: This can be conceptualized as a signal with one spatial dimension (time) and
    one feature dimension (which ear).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以被概念化为一个具有一个空间维度（时间）和一个特征维度（哪个耳朵）的信号。
- en: '![](../Images/20fa44207212e97762822e58968a905f.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/20fa44207212e97762822e58968a905f.png)'
- en: Our stereo audio data can be conceptualized as two dimensional; a time dimension
    and a feature dimension.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的立体声音频数据可以被概念化为二维的；一个时间维度和一个特征维度。
- en: Applying convolutions and max pooling to this data is very similar to images,
    except instead of iterating over two dimensions, we only iterate over one.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些数据应用卷积和最大池化与图像非常相似，只是我们只对一个维度进行迭代。
- en: '![](../Images/43bac5bfe848bb4adad6cb6da622717a.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43bac5bfe848bb4adad6cb6da622717a.png)'
- en: A conceptual diagram of one dimensional convolution. In this example we have
    three simple kernels applied to the input. Recall that these kernels are learnable,
    and their values would change throughout model training.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一维卷积的概念图。在这个示例中，我们对输入应用了三个简单的卷积核。请记住，这些卷积核是可学习的，它们的值在模型训练过程中会发生变化。
- en: Max pooling is also similar to the image approach discussed previously. We treat
    each row across the feature dimension separately, apply a moving window, and preserve
    the maximum within that window.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化也类似于之前讨论的图像方法。我们将特征维度的每一行分开处理，应用一个移动窗口，并保留该窗口中的最大值。
- en: '![](../Images/0ecbefb0c92f2dea20dafe805b0d706d.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0ecbefb0c92f2dea20dafe805b0d706d.png)'
- en: An example of max pooling. Each feature is divided into regions, and the maximum
    within those regions is preserved.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化的示例。每个特征被划分为区域，并保留这些区域内的最大值。
- en: '**Example 3) MRI/CT scans**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 3) MRI/CT扫描**'
- en: Depending on the application, data of scans can be conceptualized as three dimensional
    or two dimensional.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 根据应用的不同，扫描数据可以被概念化为三维或二维。
- en: '![](../Images/7abb24948cf3f917edf3e634fb1e0183.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7abb24948cf3f917edf3e634fb1e0183.png)'
- en: An animation of an MRI, slice by slice, of a human head. Typically this type
    of data is treated as a three dimensional problem. Image [source](https://commons.wikimedia.org/wiki/File:Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_(ANIMATED).gif)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 人头部的MRI逐切片动画。通常，这种类型的数据被视为三维问题。图像[来源](https://commons.wikimedia.org/wiki/File:Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_(ANIMATED).gif)
- en: '![](../Images/c311b52b67b01ee4875f9e931a2f2dc8.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c311b52b67b01ee4875f9e931a2f2dc8.png)'
- en: An example of a CT scan from the [Vesuvius Ink Detection Challenge](https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection),
    a challenge involving reading carbonized scrolls from pompeii without needing
    to destroy them through unraveling. This data is of a two dimensional object with
    depth. Sometimes, this type of data is referred to as “2.5D” because there are
    two major spatial dimensions and a minor spatial dimension which can be conceptualized
    as a feature dimension. [source](https://arxiv.org/pdf/2304.02084.pdf)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[维苏威火山墨水检测挑战](https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection)的CT扫描示例，这是一项涉及阅读庞贝城碳化卷轴的挑战，无需通过解卷的方式破坏这些卷轴。该数据是一个具有深度的二维对象。有时，这种类型的数据被称为“2.5D”，因为它有两个主要的空间维度和一个可以被概念化为特征维度的次要空间维度。[source](https://arxiv.org/pdf/2304.02084.pdf)'
- en: The example from the piece of paper can be treated as a 2D spatial data problem
    with a feature dimension representing depth. It’s really three dimensional, the
    paper has some thickness which is recorded by the CT scan, but the depth dimension
    is minor enough that it can be treated as a feature dimension. This would be just
    like our image example, except instead of a layer for every color, we would have
    a layer for every physical layer of data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 纸张上的示例可以视为一个具有特征维度表示深度的二维空间数据问题。它实际上是三维的，纸张有一定的厚度，这在CT扫描中被记录下来，但深度维度足够小，可以视为一个特征维度。这就像我们的图像示例，只不过每个物理数据层有一个层而不是每种颜色都有一个层。
- en: For the fully three dimensional scan of a human head, where it may not be useful
    to think of it as a flat object but as a full three dimensional object, we can
    use three dimensional convolution and max pooling. This is conceptually identical
    to the previous methods, but much harder to draw. We would do convolve over all
    three spatial dimensions, and depending on the number of kernels we employ, we
    would get a four dimensional output.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于完全三维的人头扫描来说，将其视为一个平面物体可能没有用处，更应当视为一个完整的三维物体，我们可以使用三维卷积和最大池化。这在概念上与之前的方法相同，但绘制起来要困难得多。我们将对所有三个空间维度进行卷积，具体的输出维度取决于我们使用的内核数量，最终得到一个四维输出。
- en: '![](../Images/b395b028324c87425bf40f6f483dd961.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b395b028324c87425bf40f6f483dd961.png)'
- en: An example of employing two convolutional kernels across a given three dimensional
    dataset with a single feature. This results in two 3D outputs, one for each kernel.
    The output would thus be four dimensional.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定的三维数据集中使用两个卷积内核的示例，每个内核产生一个三维输出。最终输出将是四维的。
- en: Technically there’s no limit to the dimensionality of convolutional networks.
    You could do convolution in five, six, or one thousand dimensions. I think three
    was already hard enough, and the vast majority of convolutional models work on
    two dimensional data anyway, so we’ll end our example exploration here.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，卷积网络的维度没有限制。你可以在五维、六维甚至一千维中进行卷积。我认为三维已经足够复杂了，绝大多数卷积模型实际上工作在二维数据上，因此我们将在这里结束示例探索。
- en: By this point you may have some fundamental questions like “do kernels always
    have to be a certain size”, or “do kernels always have to overlap?” We’ll cover
    questions like that in the next question.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到这时你可能会有一些基本问题，比如“内核是否总是必须有特定大小”或者“内核是否总是必须重叠？”我们将在下一个问题中讨论这些问题。
- en: Kernel Size, Stride, and Padding
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核大小、步幅和填充
- en: While we previously considered all kernels to be of size three, there’s no limit
    to the size of a convolutional kernel. This configurable size is often referred
    to as the **kernel size**.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们之前考虑了所有的内核都为三的大小，但卷积内核的大小没有限制。这种可配置的大小通常称为**内核大小**。
- en: '![](../Images/f2a3f1a72dfacaf4f02b3c04b669715a.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2a3f1a72dfacaf4f02b3c04b669715a.png)'
- en: Kernels of size two, three, and four on a two dimensional task
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在二维任务中，尺寸为二、三和四的内核
- en: I’ve also idealized all convolutions as only stepping one point at a time, but
    convolutions can step larger amounts, which is referred to as **stride**. Max
    pooling also has a stride parameter, which is often the size of the max pooling
    window. This is why I depicted max pooling as not overlapping.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我还将所有卷积理想化为每次只移动一个点，但卷积可以步进较大的量，这被称为**步幅**。最大池化也有一个步幅参数，通常是最大池化窗口的大小。这就是为什么我将最大池化描绘为不重叠的原因。
- en: '![](../Images/058bed1d1d1ee332047581687fd7c4e7.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/058bed1d1d1ee332047581687fd7c4e7.png)'
- en: Conceptual diagram of strides of length one (left), two (middle), and three
    (right), all for a kernel of size two.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅长度为一（左）、二（中）、三（右）的概念图，所有这些图都是针对尺寸为二的内核。
- en: Sometimes it’s advantageous to have the output size of a convolution equal to
    the input size of a convolution, but because kernels are typically larger than
    size one, any result of a convolution will necessarily be smaller than the input.
    As a result we can “pad” the borders of an image with some default value, maybe
    even a reflection of the input, in order to get an output that’s similarly sized.
    This general process is called **padding**.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有时将卷积的输出大小与卷积的输入大小相等是有利的，但由于内核通常大于一，因此卷积的任何结果必然会小于输入。因此，我们可以用一些默认值甚至是输入的反射来“填充”图像的边界，以获得类似大小的输出。这个过程被称为**填充**。
- en: Non Linear Activation Functions
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非线性激活函数
- en: Part of the thing that makes neural networks, in general, learn complex tasks
    is non-linearity. If we don’t use activation functions then, at the end of the
    day, convolutions can only create linear relationships (combinations of addition
    and multiplication). If we throw some activation functions in the mix, which map
    some input into an output non-linearly, we can get our convolutional network to
    learn much more complex relationships. The most common activation function used
    in convolutional networks is ReLu.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使神经网络能够学习复杂任务的一部分原因是非线性。如果我们不使用激活函数，那么卷积最终只能创建线性关系（加法和乘法的组合）。如果我们在混合中添加一些激活函数，将某些输入非线性地映射到输出，我们可以让我们的卷积网络学习更复杂的关系。在卷积网络中最常用的激活函数是ReLu。
- en: 'Typically, activation functions are applied after convolution and before max
    pooling, so something like this:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，激活函数在卷积之后和最大池化之前应用，因此是这样的：
- en: '[PRE0]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: However, while it’s not a big difference, it is slightly more performant to
    swap maxPool and activation, which doesn’t end up impacting the final output.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，尽管差别不大，将maxPool和激活函数交换的位置稍微提高了性能，但这不会影响最终输出。
- en: '[PRE1]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: regardless of how it’s done, adding non-linear activation functions within a
    model greatly increases the models ability to learn complex tasks.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，在模型中添加非线性激活函数会大大提高模型学习复杂任务的能力。
- en: Flattening and Dense Nets
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 展平和全连接网络
- en: Convolutional networks are good at breaking data down into it’s essence, but
    dense networks are better at doing logical inference. After passing data through
    a convolutional network, the data is often “flattened” then passed through a dense
    network.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络擅长将数据拆解到其本质，但全连接网络在进行逻辑推理方面更出色。在数据通过卷积网络之后，数据通常会被“展平”然后传递给全连接网络。
- en: '![](../Images/4dc62d48b213a1c28b06b016067d25ee.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4dc62d48b213a1c28b06b016067d25ee.png)'
- en: Conceptual diagram of how flattenting relates to the greater convolutional modeling
    paradigm. Fully connected networks typically expect a list of data, and convolutional
    models typically come in higher than one dimension. The output of the conv. net
    is usually unraveled into a list before passing it to a dense network, an operation
    called flattening.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 展平如何与更广泛的卷积建模范式相关的概念图。全连接网络通常期望数据列表，而卷积模型通常有多个维度。卷积网络的输出通常会被“展平”成列表，然后传递给全连接网络，这一操作称为展平。
- en: 'I have more information on the role of dense networks as “projection heads”
    in the following article:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我在以下文章中有关于全连接网络作为“投影头”的更多信息：
- en: '[](/self-supervised-learning-using-projection-heads-b77af3911d33?source=post_page-----ab08f6353f96--------------------------------)
    [## Self-Supervised Learning Using Projection Heads'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 自监督学习使用投影头](https://example.org/self-supervised-learning-using-projection-heads-b77af3911d33?source=post_page-----ab08f6353f96--------------------------------)'
- en: Boost performance with unlabeled data.
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用未标记的数据提升性能。
- en: towardsdatascience.com](/self-supervised-learning-using-projection-heads-b77af3911d33?source=post_page-----ab08f6353f96--------------------------------)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[towardsdatascience.com](https://example.org/self-supervised-learning-using-projection-heads-b77af3911d33?source=post_page-----ab08f6353f96--------------------------------)'
- en: Conclusion
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: And that’s it! I wouldn’t say we went over every possible approach or theory
    of convolutional networks (that would be a pretty long article), but we covered
    the theory necessary to understand pretty much every approach that exists. You
    should have an idea of why conv nets are better than dense nets for some applications,
    what a kernel is, what convolution is, and what max pooling is. You should have
    an understanding of the feature dimension and how it’s used across various 1D,
    2D, and 3D use cases. You should also understand key parameters, like kernel size,
    padding, and stride.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我不会说我们讨论了卷积网络的每一种可能方法或理论（那将是一篇相当长的文章），但我们覆盖了理解几乎所有存在的方法所需的理论。你应该知道为什么卷积网络在某些应用中优于全连接网络，什么是卷积核，什么是卷积，什么是最大池化。你应该理解特征维度及其在各种1D、2D和3D用例中的应用。你还应该理解关键参数，如卷积核大小、填充和步幅。
- en: '![](../Images/1237ba1b57200527d64ef90b22658de8.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1237ba1b57200527d64ef90b22658de8.png)'
- en: Take a look at the YOLO diagram, and consider how kernel size, stride, number
    of features/kernels, flattening, and dense networks relate to the diagram. [Source](https://arxiv.org/pdf/1506.02640.pdf)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下YOLO图，考虑卷积核大小、步幅、特征/卷积核数量、展平和全连接网络如何与图相关联。[来源](https://arxiv.org/pdf/1506.02640.pdf)
- en: Follow For More!
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关注获取更多信息！
- en: I describe papers and concepts in the ML space, with an emphasis on practical
    and intuitive explanations.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我描述机器学习领域的论文和概念，重点在于实用和直观的解释。
- en: '[](https://medium.com/@danielwarfield1/subscribe?source=post_page-----ab08f6353f96--------------------------------)
    [## Get an email whenever Daniel Warfield publishes'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielwarfield1/subscribe?source=post_page-----ab08f6353f96--------------------------------)
    [## 每当**丹尼尔·沃菲尔德**发布文章时，获取邮件通知'
- en: High quality data science articles straight to your inbox. Get an email whenever
    Daniel Warfield publishes. By signing up, you…
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高质量的数据科学文章直送到你的邮箱。每当**丹尼尔·沃菲尔德**发布文章时，你都会收到邮件。通过注册，你可以…
- en: medium.com](https://medium.com/@danielwarfield1/subscribe?source=post_page-----ab08f6353f96--------------------------------)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: medium.com](https://medium.com/@danielwarfield1/subscribe?source=post_page-----ab08f6353f96--------------------------------)
- en: '**Attribution:** All of the resources in this document were created by Daniel
    Warfield, unless a source is otherwise provided. You can use any resource in this
    post for your own non-commercial purposes, so long as you reference this article,
    [https://danielwarfield.dev](https://danielwarfield.dev/), or both. An explicit
    commercial license may be granted upon request.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**归属声明：** 本文档中的所有资源均由**丹尼尔·沃菲尔德**创建，除非另有来源提供。你可以将本文中的任何资源用于自己的非商业用途，只要你引用了本文或[https://danielwarfield.dev](https://danielwarfield.dev/)，或两者兼有。应要求可提供明确的商业许可。'
