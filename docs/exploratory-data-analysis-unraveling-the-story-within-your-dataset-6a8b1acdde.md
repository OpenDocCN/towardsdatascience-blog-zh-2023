# 探索性数据分析：揭示数据集中的故事

> 原文：[`towardsdatascience.com/exploratory-data-analysis-unraveling-the-story-within-your-dataset-6a8b1acdde`](https://towardsdatascience.com/exploratory-data-analysis-unraveling-the-story-within-your-dataset-6a8b1acdde)

## 探索数据的秘密艺术——理解、清理和揭示数据集中的隐藏见解

[](https://medium.com/@deepakchopra2911?source=post_page-----6a8b1acdde--------------------------------)![Deepak Chopra | Talking Data Science](https://medium.com/@deepakchopra2911?source=post_page-----6a8b1acdde--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6a8b1acdde--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----6a8b1acdde--------------------------------) [Deepak Chopra | Talking Data Science](https://medium.com/@deepakchopra2911?source=post_page-----6a8b1acdde--------------------------------)

·发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6a8b1acdde--------------------------------) ·8 分钟阅读·2023 年 7 月 6 日

--

![](img/81db40098ec031a32117e7af7ff0583a.png)

由 [Andrew Neel](https://unsplash.com/@andrewtneel?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral) 上拍摄的照片

作为数据爱好者，探索一个新的数据集是一项激动人心的工作。它让我们深入了解数据，并为成功分析奠定基础。对一个新数据集有一个良好的感觉并不总是容易的，需要时间。然而，一个好的、彻底的探索性数据分析（EDA）可以帮助你更好地理解你的数据集，感受数据之间的连接，以及需要做什么来正确处理你的数据集。

事实上，**你可能会把 80% 的时间花在数据准备和探索上，只有 20% 用于实际的数据建模**。对于其他类型的分析，探索可能会占用你更多的时间。

# **什么是探索性数据分析。

**探索性数据分析，简单来说，就是探索数据的艺术。** 这是从不同角度调查数据的过程，以增强你的理解，探索模式，建立变量之间的关系，并在必要时增强数据本身。

就像和你的数据集去‘盲目’约会一样，坐在这个神秘的数字和文本集合对面，渴望在开始一段严肃的关系之前理解它。就像盲目约会一样，EDA 允许你揭示数据集的隐藏面貌。你观察模式，检测异常值，探索细微差别，然后再做出任何重大承诺。这完全是关于了解和建立信任，与数字建立稳固的基础，确保在得出结论之前你是稳固的。

> 我们都经历过；无论是有意还是无意，深入统计工具或筛选报告——我们都曾在某个时点探索过某种数据！

# **为什么。

作为分析师和数据科学家，我们应该最好地理解数据。当涉及到理解和解释数据时，我们必须成为专家。无论是机器学习模型、实验框架还是简单的分析——结果取决于数据的质量。

> 记住，垃圾进，垃圾出！！

EDA 使数据分析师和科学家能够探索、理解和从数据中提取有意义的见解。就在你认为一切都已弄清楚时，数据集却给你来了个意外。你发现了缺失值、不一致性和混乱的数据。这就像发现你的约会对象有一只秘密的宠物短吻鳄或一系列独角兽雕像。探索性数据分析为你提供了清理混乱和理解一切的工具。

*——这就像给你的数据集一个大改造，将它从杂乱无章变成一个光彩夺目的伙伴。*

最终，探索性数据分析的核心在于深入了解你的数据，在过程中享受乐趣，并为进一步分析奠定坚实基础。所以戴上你的侦探帽，和你的数据集一起踏上这段激动人心的冒险之旅。谁知道呢，你可能会发现隐藏的宝藏甚至是真爱！

# **如何。

探索性数据分析，顾名思义，就是对数据进行探索的分析。它包含了多个组件；这些组件并非所有时候都是必需的，也并非所有组件都有同等重要性。以下，我将根据我的经验列出一些组件。

*请注意，这绝不是详尽无遗的列表，而是一个指导框架。*

## 1\. 理解数据的现状。

*你不知道自己不知道什么——但你可以探索！*

首先要做的是感受数据——查看数据条目，观察列值。你有多少行，多少列。

+   一个零售数据集可能会告诉你——*X 先生在 2023 年 8 月 1 日访问了 2000 号商店，并购买了一罐可乐和一包沃克脆片*

+   一个社交媒体数据集可能会告诉你——*Y 女士在 6 月 3 日早上 09:00 登录社交网站，浏览了 A、B 和 C 板块，搜索了她的朋友 A 先生，然后在 20 分钟后注销。*

了解你拥有的数据的业务背景，了解数据的来源和收集机制是有益的；*例如，调查数据与数字收集数据等*。

## 2\. 深入探讨变量

变量是数据集的“语言”，它们在不断与你交流。你只需要提出正确的问题，并仔细倾听。

**→ 要问的问题::** - 变量的含义是什么？

- 这些变量是连续的还是分类的？.. 是否有固有的顺序？

- 变量可能取什么值？

**→ 行动::**

+   对于连续变量——使用直方图、箱线图检查分布，并仔细研究均值、中位数、标准差等。

+   对于分类/有序变量——找出它们的唯一值，并进行频率表检查最常见/最少见的值。

> 你可能无法理解所有变量、标签和数值——但尽量获取尽可能多的信息

## 3\. 查找数据中的模式/关系

通过 EDA，你可以发现数据中的模式、趋势和关系。

**→ 需要问的问题::** *- 你是否对变量之间的关系有任何先前的假设/假设？

- 某些变量之间有业务上的关联理由吗？

- 变量是否遵循特定的分布？*

> 数据可视化技术、总结和相关性分析有助于揭示初看不明显的隐藏模式。理解这些模式可以为决策制定或假设生成提供有价值的见解。

**→ 行动::** 思考双变量视觉分析。

+   对于连续变量——使用散点图、创建相关矩阵/热图等。

+   对于混合连续变量和有序/分类变量——考虑绘制条形图或饼图，并创建经典的列联表以可视化共现情况。

> EDA（探索性数据分析）允许你验证统计假设，例如正态性、线性或独立性，以进行分析或数据建模。

## 4\. 检测异常。

这是你成为数据上的福尔摩斯并寻找任何异常的机会！问问自己::

## **- 数据集中是否有重复条目？**

重复项是指多次表示相同样本点的条目。在大多数情况下，重复项没有用处，因为它们不会提供任何额外的信息。它们可能是错误的结果，并且可能会干扰你的均值、中位数和其他统计数据。

→ 与你的利益相关者确认，并从数据中删除这些错误。

## **- 分类变量的标记错误？**

查找分类变量的唯一值并创建频率图。查找拼写错误和可能表示相似事物的标签？

## **- 是否有变量缺失值？**

这可能发生在数值和分类变量中。检查是否

+   **是否有在很多变量（列）中缺失值的行？** 这意味着有些数据点在大多数列中都是空白的 → 它们的用处不大，我们可能需要删除这些行。

+   **是否有在多行中缺失值的变量（或列）？** 这意味着有些变量在大多数数据点中没有值/标签 → 它们对我们的理解贡献不大，我们可能需要删除这些变量。

> →**行动::**
> 
> - 计算所有变量的 NULL 或缺失值的比例。超过 15%-20%的变量应引起你的怀疑。
> 
> - 过滤掉某列中缺失值的行，并检查其余列的情况。是否大多数列一起有缺失值？..是否有模式？

## **- 我的数据集中是否存在异常值？**

异常值检测是关于识别那些不符合常规的数据点。你可能会看到某些数值变量的非常高或极低的值，或者分类变量的高频/低频。

+   **看似异常值的可能是数据错误。** 虽然异常值是对于给定特征分布来说不寻常的数据点，但不需要的条目或记录错误是那些本来不应该存在的样本。

+   **看似异常值的可能只是异常值。** 在其他情况下，我们可能只是有一些极端值的数据点，并且背后有完全合理的解释。

> →**行动步骤::**
> 
> 研究直方图、散点图和频率条形图，以了解是否有一些数据点与其余数据点相距较远。思考：
> 
> - 这些值是否可能是真的，并且符合这些极端值？
> 
> - 对于这些极端值是否有业务上的理由或解释？
> 
> - 这些在后续阶段会对你的分析有价值吗？

## 5. 数据清洗。

[数据清洗](https://www.simplilearn.com/data-cleaning-why-and-how-to-get-started-article)指的是从数据集中移除不需要的变量和值，并消除其中的任何不规则性。这些异常可能会不成比例地扭曲数据，从而对我们从该数据集中得出的分析结果产生不利影响。

> 记住：垃圾进，垃圾出。

## - 纠正你的数据。

+   删除任何你发现的重复条目、缺失值和异常值——这些都没有为你的数据集增加价值。去除不必要的行/列。

+   纠正数据中你观察到的任何拼写错误或标签错误。

+   你发现的任何没有增加数据价值的数据错误也需要被移除。

## - 截断异常值或保持现状。

+   在一些数据建模场景中，我们可能需要对异常值进行截断。截断通常在高端的第 99/95 百分位或低端的第 1/5 百分位进行。

## **- 处理缺失值。**

> 我们通常会丢弃那些在变量中有很多缺失值的数据点（行）。同样，我们会丢弃那些在大量数据点中有缺失值的变量（列）。

如果有一些缺失值，我们可以考虑填补这些空缺，或者保持现状。

+   对于有缺失值的连续变量，我们可以通过使用均值或中位数（可能在特定分层中）来填补这些缺失值。

+   对于分类缺失值，我们可能会分配最常用的“类别”或创建一个新的“未定义”类别。

## - 数据丰富化。

根据未来分析的需要，你可以向数据集中添加更多的特征（变量）；例如（但不限于）

+   创建指示某事物存在或不存在的二元变量。

+   通过使用 IF-THEN-ELSE 子句创建额外的标签/类别。

+   根据未来分析的需求来缩放或编码你的变量。

+   结合两个或多个变量——使用各种数学函数，如求和、差异、均值、对数以及其他许多变换。

# 总结

EDA 使数据科学家能够发现有价值的见解，解决数据质量问题，并为进一步的分析和建模奠定坚实的基础。它确保数据分析的结果是可靠、准确且具有影响力的。

## EDA 的关键组件：

1.  了解数据的来源和“含义”。

1.  了解所有变量及其分布、标签/类别。

1.  寻找变量之间的模式/关系，以验证任何先前的假设或假定。

1.  发现任何异常——数据错误、离群值、缺失值。

1.  数据清理——删除或修正任何数据错误/异常，处理离群值，填补缺失值（如有需要），缩放/变换现有变量，并创建额外的衍生变量，丰富你的数据集，以便后续分析。

# 连接、学习与成长 ..

如果你喜欢这篇文章并对类似内容感兴趣，可以在 [***Medium***](https://medium.com/@deepakchopra2911)、[***LinkedIn***](https://www.linkedin.com/in/deepakchopra2911/)、[***与我 1:1 联系***](https://topmate.io/deepakchopra2911)、[***加入我的邮件列表***](https://medium.com/subscribe/@deepakchopra2911) 上关注我，*(如果你还没有的话)*，快来成为 [***Medium 家庭的成员***](https://medium.com/@deepakchopra2911/membership)，以获取数千篇有用的文章。*(如果你使用以上链接，我将获得你会员费用的 ~50%)* 

***.. 继续学习，继续成长！***
