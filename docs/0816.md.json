["```py\nrules:\n    - rulename: rule5\n      description: un-ordered set of events by host\n      action: temporal\n      ordered: false\n      tags:\n        - name: recon_cmd_a\n        - name: recon_cmd_b\n        - name: recon_cmd_c\n```", "```py\nrules:\n    - rulename: rule4\n      description: propagate to child only\n      action: parent\n      parent: parent_id\n      child: id\n      tags:\n        - name: parent_process_feature1\n```", "```py\nselect\n\n    -- regroup each rule's tags in a map (ruleName -> Tags)\n    map(\n        'rule1', map('cr1_selection', cr1_selection,\n                    'cr1_filter_empty', cr1_filter_empty,\n                    'cr1_filter', cr1_filter,\n                    'cr1_filter_localserver_fp', cr1_filter_localserver_fp,\n                    'pr1_filter_iexplorer', pr1_filter_iexplorer,\n                    'pr1_filter_msiexec_syswow64', pr1_filter_msiexec_syswow64,\n                    'pr1_filter_msiexec_system32', pr1_filter_msiexec_system32),\n        'rule2', map('cr2_filter_provider', cr2_filter_provider,\n                    'cr2_filter_git', cr2_filter_git,\n                    'pr2_selection', pr2_selection,\n                    'pr2_filter_git', pr2_filter_git),\n        'rule3', map('cr3_selection_other', cr3_selection_other,\n                    'cr3_selection_atexec', cr3_selection_atexec,\n                    'pr3_selection_other', pr3_selection_other,\n                    'pr3_selection_atexec', pr3_selection_atexec)\n       ) as sigma\n```", "```py\nrules:\n    - rulename: rule1\n      description: ordered list of events by host\n      action: temporal\n      ordered: true\n      tags:\n        - name: recon_cmd_a\n        - name: recon_cmd_b\n        - name: recon_cmd_c\n\n    - rulename: rule3\n      description: propagate to all decendents\n      action: ancestor\n      tags:\n        - name: ancestor_process_feature1\n      parent: parent_id\n      child: id\n```", "```py\ncase class FluxCapacitorMapFunction(\n    val tagCapacity: Int,\n    val specification: String\n) {\n\ndef processBatch(\n      key: String,\n      rows: Iterator[Row],\n      state: GroupState[FluxState]\n  ): Iterator[Row] = {\n\n    val bloom =\n    if (state.exists()) {\n      state.get()\n    } else {\n      BloomFilter.create(Funnels.stringFunnel(), tagCapacity, 0.01)\n    }\n\n    val rulesConf = RulesConf.load(specification)\n    val rules = new RulesAdapter(new Rules(rulesConf, bloom))\n    val outputRows = rows.map(row => rules.evaluateRow(row))\n    state.update(bloom)\n    outputRows.iterator\n  }\n```", "```py\nval taggedEventsDF = ...\n\nval specification = \"\"\"\nrules:\n    - rulename: rule1\n      description: ordered list of events by host\n      action: temporal\n      ordered: true\n      tags:\n        - name: recon_cmd_a\n        - name: recon_cmd_b\n        - name: recon_cmd_c\n\n    - rulename: rule3\n      description: propagate to all decendents\n      action: ancestor\n      tags:\n        - name: ancestor_process_feature1\n      parent: parent_id\n      child: id\n\"\"\"\n\nval tagCapacity = 200000\nval flux = new FluxCapacitorMapFunction(tagCapacity, specification)\n```", "```py\n// create encoders to serialize/deserialize the output rows and the bloom\nval outputEncoder = RowEncoder(taggedEventsDF.schema).resolveAndBind()\nval stateEncoder = Encoders.javaSerialization(BloomFilter.class)\n\n// we associate a bloom with each host\nvar groupKeyIndex = df.schema.fieldIndex(\"host_id\")\n\ntaggedEventsDF\n  .groupByKey(row => row.getString(groupKeyIndex))\n  .flatMapGroupsWithState(\n     Append,\n     GroupStateTimeout.NoTimeout()\n  )(flux.processBatch)(stateEncoder, outputEncoder)\n```"]