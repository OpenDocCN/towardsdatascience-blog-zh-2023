- en: 'Linear Algebra 4: Matrix Equations'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '线性代数 4: 矩阵方程'
- en: 原文：[https://towardsdatascience.com/linear-algebra-4-matrix-equations-914ebb371950?source=collection_archive---------5-----------------------#2023-11-10](https://towardsdatascience.com/linear-algebra-4-matrix-equations-914ebb371950?source=collection_archive---------5-----------------------#2023-11-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/linear-algebra-4-matrix-equations-914ebb371950?source=collection_archive---------5-----------------------#2023-11-10](https://towardsdatascience.com/linear-algebra-4-matrix-equations-914ebb371950?source=collection_archive---------5-----------------------#2023-11-10)
- en: '![](../Images/e020de936494e3bab2467f8217eced6c.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e020de936494e3bab2467f8217eced6c.png)'
- en: Solving matrix equations Ax= b
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 求解矩阵方程 Ax= b
- en: '[](https://medium.com/@t9nz?source=post_page-----914ebb371950--------------------------------)[![tenzin
    migmar (t9nz)](../Images/d9a3e1fe10afba1f1dc0fc7e4d241d73.png)](https://medium.com/@t9nz?source=post_page-----914ebb371950--------------------------------)[](https://towardsdatascience.com/?source=post_page-----914ebb371950--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----914ebb371950--------------------------------)
    [tenzin migmar (t9nz)](https://medium.com/@t9nz?source=post_page-----914ebb371950--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@t9nz?source=post_page-----914ebb371950--------------------------------)[![tenzin
    migmar (t9nz)](../Images/d9a3e1fe10afba1f1dc0fc7e4d241d73.png)](https://medium.com/@t9nz?source=post_page-----914ebb371950--------------------------------)[](https://towardsdatascience.com/?source=post_page-----914ebb371950--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----914ebb371950--------------------------------)
    [tenzin migmar (t9nz)](https://medium.com/@t9nz?source=post_page-----914ebb371950--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6ff685c466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-algebra-4-matrix-equations-914ebb371950&user=tenzin+migmar+%28t9nz%29&userId=d6ff685c466&source=post_page-d6ff685c466----914ebb371950---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----914ebb371950--------------------------------)
    ·7 min read·Nov 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F914ebb371950&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-algebra-4-matrix-equations-914ebb371950&user=tenzin+migmar+%28t9nz%29&userId=d6ff685c466&source=-----914ebb371950---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd6ff685c466&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-algebra-4-matrix-equations-914ebb371950&user=tenzin+migmar+%28t9nz%29&userId=d6ff685c466&source=post_page-d6ff685c466----914ebb371950---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----914ebb371950--------------------------------)
    ·7分钟阅读·2023年11月10日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F914ebb371950&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-algebra-4-matrix-equations-914ebb371950&user=tenzin+migmar+%28t9nz%29&userId=d6ff685c466&source=-----914ebb371950---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F914ebb371950&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-algebra-4-matrix-equations-914ebb371950&source=-----914ebb371950---------------------bookmark_footer-----------)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F914ebb371950&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flinear-algebra-4-matrix-equations-914ebb371950&source=-----914ebb371950---------------------bookmark_footer-----------)'
- en: Preface
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前言
- en: Welcome back to the fourth edition of my ongoing series on the basics of Linear
    Algebra, the foundational math behind machine learning. In my previous [article](https://medium.com/@t9nz/linear-algebra-1-1-15b70e48bab9),
    I introduced vectors, linear combinations, and vector spans. This essay will take
    a look at the matrix equation *A*x = **b** and we’ll see how the very principle
    of solving a system of linear equations is linked to the matrix equation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎回到我持续进行的线性代数基础系列的第四篇。在我之前的[文章](https://medium.com/@t9nz/linear-algebra-1-1-15b70e48bab9)中，我介绍了向量、线性组合和向量跨度。这篇文章将探讨矩阵方程
    *A*x = **b**，并将展示如何通过矩阵方程解决线性方程组的原理。
- en: This article would best serve readers if read in accompaniment with Linear Algebra
    and Its Applications by David C. Lay, Steven R. Lay, and Judi J. McDonald. Consider
    this series as a companion resource.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章若与 David C. Lay、Steven R. Lay 和 Judi J. McDonald 的《线性代数及其应用》一书一同阅读，将更具价值。请将这个系列作为辅导资源来参考。
- en: Feel free to share thoughts, questions, and critique.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 随时分享您的想法、问题和批评。
- en: The Intuition
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直观理解
- en: We last left off on learning about linear combinations which I promised would
    have important implications. Recall that given vectors v₁, v₂, … vₐ in ℝⁿ and
    scalars (also known as weights) c₁, c₂, … cₐ, the **linear combination** is the
    vector defined by the sum of the scalar multiples, c₁v₁ + c₂v₂ + … + cₐvₐ.¹
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们上次讲述了线性组合的概念，我承诺这会有重要的意义。请回忆一下，给定向量v₁, v₂, … vₐ在ℝⁿ中，以及标量（也称为权重）c₁, c₂, … cₐ，**线性组合**是由标量倍数的和定义的向量，c₁v₁
    + c₂v₂ + … + cₐvₐ。¹
- en: '![](../Images/3331d6f445bd06ed295fc84671874d0a.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3331d6f445bd06ed295fc84671874d0a.png)'
- en: We say that a vector **b** is a linear combination of a set of vectors v₁, v₂,
    .. vₐₚ in Rⁿ, if there exists a set of weights c₁, c₂, … cₐ (a solution) such
    that c₁v₁ + c₂v₂ + … + cₐvₐ = **b**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果向量**b**是向量空间Rⁿ中一组向量v₁, v₂, .. vₐₚ的线性组合，那么存在一组权重c₁, c₂, … cₐ（一种解决方案），使得c₁v₁
    + c₂v₂ + … + cₐvₐ = **b**。
- en: 'To determine if **b** is a linear combination of some given vectors v₁, v₂,
    .. vₐ we arranged our vectors into a system of linear equations, then created
    an augmented matrix of our equations and used row reduction operations to reduce
    the matrix to reduced echelon form. If the row reduced echelon form had an inconsistency,
    that is, a row that looked like this: [0, 0, … | **m**] where **m** ≠ 0, that
    meant that our vector **b** is not a linear combination of the vectors because
    no set of weights exist for the equation c₁v₁ + c₂v₂ + … + cₐvₐ = **b** tohold
    true.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定**b**是否是给定向量v₁, v₂, .. vₐ的线性组合，我们将我们的向量排列成一组线性方程，然后创建一个增广矩阵，并使用行简化运算将矩阵化简为简化阶梯形式。如果简化阶梯形式有不一致性，也就是一行看起来像这样：[0,
    0, … | **m**]其中**m** ≠ 0，那意味着我们的向量**b**不是向量组的线性组合，因为没有一组权重能使等式c₁v₁ + c₂v₂ + …
    + cₐvₐ = **b**成立。
- en: '![](../Images/122a31f721cbab27ab07d70b4186cf65.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/122a31f721cbab27ab07d70b4186cf65.png)'
- en: If there was no such inconsistency, that meant that we could write the vector
    b as a linear combination of a set of vectors, such as the example above. Do you
    remember how we verified our answer at the end? We’d multiply each vector by its
    respective scalar and then find the vector sum. If the vector sum equalled **b**,
    we knew that we had done our calculations correctly and that **b** was indeed
    a linear combination.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有这样的不一致，那意味着我们可以将向量**b**写成一组向量的线性组合，比如上面的例子。你还记得我们如何在最后验证答案吗？我们会将每个向量乘以它的对应标量，然后找到向量和。如果向量和等于**b**，我们知道我们计算正确，并且**b**确实是一个线性组合。
- en: '![](../Images/8bb411a027318f9feb0d86c6aa5f8df9.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8bb411a027318f9feb0d86c6aa5f8df9.png)'
- en: This verification process is the matrix equation *A*x = **b** in disguise!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个验证过程就是矩阵方程*A*x = **b**的变形！
- en: Ax = b
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*Ax = b*'
- en: If *A* is an *m* x *n* matrix, and x is in Rⁿ (you’ll see why it’s important
    x is in Rⁿ next section), then the product *A*x is the linear combination of the
    vectors (columns) in *A*, using the corresponding scalars in x.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*A*是一个*m* x *n*矩阵，而*x*属于Rⁿ（你将会在下一节看到为什么*x*属于Rⁿ很重要），那么乘积*A*x就是矩阵*A*中向量（列）的线性组合，使用*x*中对应的标量。
- en: '![](../Images/e8e39515c441ef8c37be3b91288c48f1.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e8e39515c441ef8c37be3b91288c48f1.png)'
- en: Notice that none of this is new material, we’ve already unknowingly computed
    *A*x when verifying our linear combinations in my previous article. The *A*x =
    **b** matrix equation is still fundamental though because it formalizes all of
    this into a compact notation and will resurface later on in new ways.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这一切都不是新材料，我们在前一篇文章中不知不觉地计算了*A*x来验证我们的线性组合。然而，矩阵方程*A*x = **b**仍然很重要，因为它将所有这些内容形式化为紧凑的符号，并且将在后续以新的方式重新出现。
- en: 'Now we know that if we are given an *m* x *n* matrix *A* and x and we compute
    the matrix product *A*x and it is equal to **b**, then **b** can be written as
    a linear combination of the vectors (columns) in A and the scalars/entries in
    x. So in summary: the equation *A*x = **b** will only have a solution (x) if b
    can be written as a linear combination of the columns of A.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道，如果给定一个*m* x *n*矩阵*A*和向量*x*，并且我们计算矩阵乘积*A*x等于**b**，那么**b**可以写成矩阵*A*中向量（列）和向量*x*中的标量/条目的线性组合。所以总结一下：方程*A*x
    = **b**只有一个解（x），如果b可以写成A的列向量的线性组合。
- en: '![](../Images/bef0724127bb92a8abb968e30906c440.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bef0724127bb92a8abb968e30906c440.png)'
- en: Matrix Multiplication
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵乘法
- en: I’ve introduced *A*x = **b** as a matrix product, but I haven’t yet explained
    matrix multiplication (which is what *A*x is)!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经将*A*x = **b**介绍为一个矩阵乘积，但我还没有解释矩阵乘法（这就是*A*x的内容）！
- en: '**Matrix multiplication** is the operation of multiplying two matrices to produce
    one, their product. We’ve already seen matrix addition where two matrices are
    added to produce their sum. In order for matrix addition to be defined, the two
    matrices that are being added, matrix A and matrix B must be of the same size.
    Similarly, matrix multiplication also has a requirement. To multiply matrix *A*
    and matrix *B* and produce *AB*, the number of columns in matrix *A* must be equal
    to the number of rows in matrix *B*. The size of the product of matrix *A* and
    *B*, which we’ll call matrix *C* will depend on the number of rows in matrix *A*
    and number of columns in matrix *B*. Matrix *C* will have m (# of rows in matrix
    *A*) rows and p (# of columns in matrix *B*) columns.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**矩阵乘法** 是将两个矩阵相乘得到它们的乘积的操作。我们已经见过矩阵加法，即两个矩阵相加得到它们的和。为了使矩阵加法有定义，被加的两个矩阵，矩阵
    A 和矩阵 B 必须具有相同的大小。类似地，矩阵乘法也有一个要求。要将矩阵 *A* 和矩阵 *B* 相乘得到 *AB*，矩阵 *A* 的列数必须等于矩阵 *B*
    的行数。矩阵 *A* 和 *B* 的乘积，我们称为矩阵 *C*，其大小取决于矩阵 *A* 的行数和矩阵 *B* 的列数。矩阵 *C* 将有 m（矩阵 *A*
    的行数）行和 p（矩阵 *B* 的列数）列。'
- en: '![](../Images/c21d4d9d3df65d4438c5b2faab8ad4d4.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c21d4d9d3df65d4438c5b2faab8ad4d4.png)'
- en: So, how does matrix multiplication work? If we were to multiply matrix A and
    B, each of the i-th row, j-th column entries in the matrix product is the **dot
    product** of the i-th row in matrix A and the j-th row in matrix B.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，矩阵乘法是如何工作的呢？如果我们要计算矩阵 A 和 B 的乘积，那么乘积矩阵中第 i 行、第 j 列的每个元素是矩阵 A 第 i 行和矩阵 B 第
    j 列的**点积**。
- en: '![](../Images/5b1b2472ac07d18a01f163d641da0190.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b1b2472ac07d18a01f163d641da0190.png)'
- en: For now, all you need to know is that the **dot product** is the summation of
    product of corresponding entries between two vectors and that it is only defined
    when the two vectors have the same number of entries. This explanation is far
    from doing the dot product justice, but I’ll save the full geometric intuition
    for later.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你只需知道**点积**是两个向量对应元素的乘积之和，并且仅当两个向量具有相同数量的元素时才有定义。这个解释远不能充分说明点积的几何直觉，但我会在稍后详细说明。
- en: '![](../Images/a326f62154c7efd4753bce02075e7234.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a326f62154c7efd4753bce02075e7234.png)'
- en: For brevity, I’ve computed the matrix product of two 2 x 2 matrices, but the
    same procedure generalizes for matrices of any size as long as the matrices meet
    the criteria for matrix multiplication, otherwise their product will be undefined.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 简洁起见，我已计算了两个 2 x 2 矩阵的乘积，但同样的过程适用于任何大小的矩阵，只要矩阵符合矩阵乘法的条件，否则它们的乘积将未定义。
- en: Properties of the Matrix Multiplication
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵乘法的性质
- en: If *A*, *B* and *C* are *n* x *n* matrices and **c** and **d** are scalars,
    then the following properties are true.³
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 *A*、*B* 和 *C* 是 *n* x *n* 矩阵，**c** 和 **d** 是标量，那么以下性质成立。³
- en: '*AB* **≠** BA (not commutative in general)'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*AB* **≠** BA（一般情况下不可交换）'
- en: (AB)C = A(BC) (associative)
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (AB)C = A(BC)（结合律）
- en: A(B+C) = AB + AC and (B+C)A = BA + CA (distributive)
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A(B+C) = AB + AC 和 (B+C)A = BA + CA（分配律）
- en: 0A = 0 (multiplicative property of zero)
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 0A = 0（零的乘法性质）
- en: Take care in noting that matrix multiplication is not commutative, this property
    might take a while to stick given we are intuitively used to commutativity with
    real numbers.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意矩阵乘法不是可交换的，这个性质可能需要一段时间才能理解，因为我们通常对实数的可交换性有直观的认知。
- en: These properties are useful for computing matrix products, which will be a recurring
    subject throughout Linear Algebra.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些性质对于计算矩阵乘积非常有用，这将是线性代数中的一个重要主题。
- en: Conclusion
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Matrix multiplication is a fundamental mathematical operation that underpins
    the core functionality of neural networks, particularly in their feedforward and
    back propagation phases.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法是支持神经网络核心功能的基础数学操作，特别是在它们的前向传播和反向传播阶段。
- en: In the feedforward phase of a neural network, data is processed through its
    various layers, and matrix multiplication is at the heart of this operation. Each
    layer in a neural network is composed of neurons, which are represented as weighted
    sums of the inputs, followed by an activation function. These weighted sums are
    calculated using matrix multiplication.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络的前向传播阶段，数据通过其各个层进行处理，而矩阵乘法是这一操作的核心。神经网络中的每一层由神经元组成，它们表示为输入的加权和，接着是激活函数。这些加权和通过矩阵乘法计算得出。
- en: During the back propagation pass, the neural network is learning from its mistakes.
    It adjusts the weights of neurons to minimize the error between predicted and
    actual outputs. Matrix multiplication is again a key component of this process,
    specifically in calculating gradients, which indicate how much each weight should
    be adjusted to minimize the error.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播过程中，神经网络从其错误中学习。它调整神经元的权重以最小化预测输出与实际输出之间的误差。矩阵乘法再次成为此过程的关键组成部分，特别是在计算梯度时，梯度指示了每个权重应该如何调整以最小化误差。
- en: Learning math is an exciting venture purely on its own merit, but learning about
    the applications of Linear Algebra alongside the theory can make the journey up
    a steep learning curve even more inspiring.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 学习数学本身就是一次令人兴奋的冒险，但是学习线性代数理论及其应用，可以使这段充满挑战的学习旅程更加鼓舞人心。
- en: Summary
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we learned about:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了以下内容：
- en: 'The intuition behind linear combinations and the matrix product *A*x = **b**:
    how the matrix product isn’t necessarily a new concept, but one that formalizes
    a procedure we’d already been using!'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性组合和矩阵乘积 *A*x = **b** 背后的直觉：矩阵乘积并非一个全新的概念，而是形式化了我们已经在使用的一个过程！
- en: '*A*x = **b**: the matrix product has a solution x if **b** is a linear combination
    of a the set of vectors (columns) in *A*.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*A*x = **b**：如果**b**是矩阵*A*中向量（列）集合的线性组合，则矩阵乘积有解x。'
- en: 'Matrix multiplication: the operation behind *A*x = **b** that is widely used
    in machine learning applications, specific examples including in neural networks.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵乘法：*A*x = **b** 的操作，在机器学习应用中广泛使用，特别是在神经网络中的具体例子。
- en: 'Properties of matrix multiplication: non-commutativity, associativity, distributive
    and the multiplicative property of zero.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 矩阵乘法的属性：非交换性、结合律、分配律和零的乘法性质。
- en: Notes
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 笔记
- en: '*All images created by the author unless otherwise noted.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，所有图片均由作者创建。'
- en: '*I apologize for taking a while to continue where we last left off. I am currently
    in the midst of taking midterm exams (including one for Linear Algebra haha!)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*抱歉让你久等了，我正在参加期中考试（包括线性代数哈哈！）。'
- en: ¹Definition for linear combinations referenced from Linear Algebra and Its Applications
    6th Edition by David C. Lay, Steven R. Lay, and Judi J. McDonald
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ¹线性组合的定义参考自《线性代数及其应用》第六版，作者为David C. Lay、Steven R. Lay和Judi J. McDonald。
- en: ²Definition for matrix product properties referenced from Linear Algebra and
    Its Applications 6th Edition by David C. Lay, Steven R. Lay, and Judi J. McDonald
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ²矩阵乘积属性的定义参考自《线性代数及其应用》第六版，作者为David C. Lay、Steven R. Lay和Judi J. McDonald。
- en: ³Matrix properties referenced from [src](https://www.khanacademy.org/math/precalculus/x9e81a4f98389efdf:matrices/x9e81a4f98389efdf:properties-of-matrix-multiplication/a/properties-of-matrix-multiplication).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ³矩阵属性参考自[src](https://www.khanacademy.org/math/precalculus/x9e81a4f98389efdf:matrices/x9e81a4f98389efdf:properties-of-matrix-multiplication/a/properties-of-matrix-multiplication)。
- en: '![](../Images/ccb6930f4dbcc5c08c98bc5c0ff6cff1.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ccb6930f4dbcc5c08c98bc5c0ff6cff1.png)'
