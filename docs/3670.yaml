- en: Fine-Tune Your Own Open-Source LLM Using the Latest Techniques
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用最新技术微调您自己的开源LLM
- en: 原文：[https://towardsdatascience.com/how-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48?source=collection_archive---------4-----------------------#2023-12-15](https://towardsdatascience.com/how-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48?source=collection_archive---------4-----------------------#2023-12-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48?source=collection_archive---------4-----------------------#2023-12-15](https://towardsdatascience.com/how-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48?source=collection_archive---------4-----------------------#2023-12-15)
- en: In this article, I tune a base LLama2 LLM to output SQL code. I use Parameter
    Efficient Fine-Tuning techniques to optimise the process.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在这篇文章中，我微调了一个基础LLama2 LLM以输出SQL代码。我使用了**参数高效微调**技术来优化这一过程。
- en: '[](https://medium.com/@christopher_karg?source=post_page-----03a4e67d1b48--------------------------------)[![Christopher
    Karg](../Images/9d163d59e0c3167732f55d497caf9db2.png)](https://medium.com/@christopher_karg?source=post_page-----03a4e67d1b48--------------------------------)[](https://towardsdatascience.com/?source=post_page-----03a4e67d1b48--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----03a4e67d1b48--------------------------------)
    [Christopher Karg](https://medium.com/@christopher_karg?source=post_page-----03a4e67d1b48--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@christopher_karg?source=post_page-----03a4e67d1b48--------------------------------)[![克里斯托弗·卡格](../Images/9d163d59e0c3167732f55d497caf9db2.png)](https://medium.com/@christopher_karg?source=post_page-----03a4e67d1b48--------------------------------)[](https://towardsdatascience.com/?source=post_page-----03a4e67d1b48--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----03a4e67d1b48--------------------------------)
    [克里斯托弗·卡格](https://medium.com/@christopher_karg?source=post_page-----03a4e67d1b48--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fbda6d16c39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48&user=Christopher+Karg&userId=5fbda6d16c39&source=post_page-5fbda6d16c39----03a4e67d1b48---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----03a4e67d1b48--------------------------------)
    ·13 min read·Dec 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F03a4e67d1b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48&user=Christopher+Karg&userId=5fbda6d16c39&source=-----03a4e67d1b48---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5fbda6d16c39&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48&user=Christopher+Karg&userId=5fbda6d16c39&source=post_page-5fbda6d16c39----03a4e67d1b48---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----03a4e67d1b48--------------------------------)
    · 13 分钟阅读 · 2023年12月15日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F03a4e67d1b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48&user=Christopher+Karg&userId=5fbda6d16c39&source=-----03a4e67d1b48---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F03a4e67d1b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48&source=-----03a4e67d1b48---------------------bookmark_footer-----------)![](../Images/389987bb764f9aceba43b821ecf0128e.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F03a4e67d1b48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-efficiently-fine-tune-your-own-open-source-llm-using-novel-techniques-code-provided-03a4e67d1b48&source=-----03a4e67d1b48---------------------bookmark_footer-----------)![](../Images/389987bb764f9aceba43b821ecf0128e.png)'
- en: 'Source: [https://www.pexels.com/photo/calm-body-of-lake-between-mountains-346529/](https://www.pexels.com/photo/calm-body-of-lake-between-mountains-346529/)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.pexels.com/photo/calm-body-of-lake-between-mountains-346529/](https://www.pexels.com/photo/calm-body-of-lake-between-mountains-346529/)'
- en: 'In [a previous article](https://medium.com/towards-data-science/quantisation-and-co-reducing-inference-times-on-llms-by-80-671db9349bdb),
    I began to make a case for why you would consider training your own LLM. I also
    provided a brief introduction to the hardware requirements, as well as methods
    for optimising the training and inference. In this article, I will cover exactly
    how to fine-tune an open-source LLM and provide code snippets for you to follow
    along and reproduce the results. We will tune a Llama2–7B model to provide us
    with SQL output based on natural language input — in other words, the model will
    convert a question we ask in natural language:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [上一篇文章](https://medium.com/towards-data-science/quantisation-and-co-reducing-inference-times-on-llms-by-80-671db9349bdb)
    中，我开始说明为什么你可能会考虑训练自己的 LLM。我还简要介绍了硬件要求以及优化训练和推理的方法。在这篇文章中，我将详细讲解如何微调开源 LLM，并提供代码片段供你跟随和复现结果。我们将调优一个
    Llama2–7B 模型，以根据自然语言输入提供 SQL 输出——换句话说，模型将把我们用自然语言提问的问题：
- en: '*“How many customers decided to buy eggs in the month of November?”*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*“有多少顾客在十一月决定购买鸡蛋？”*'
- en: 'To a SQL query that fetches the corresponding result:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 转换为一个获取相应结果的 SQL 查询：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In each case, the schema of the database (DB) will be provided as the context
    for the LLM to work with:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在每种情况下，数据库 (DB) 的模式将作为 LLM 工作的上下文提供。
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
