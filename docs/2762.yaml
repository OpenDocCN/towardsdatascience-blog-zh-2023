- en: 'Tidying Up the Framework of Dataset Shifts: The Example'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5?source=collection_archive---------4-----------------------#2023-09-01](https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5?source=collection_archive---------4-----------------------#2023-09-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*How the conditional probability changes as a function of the three probability
    elements*'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)[![Valeria
    Fonseca Diaz](../Images/880222be555e8fa7df660f9dd1233818.png)](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)
    [Valeria Fonseca Diaz](https://medium.com/@valefonsecadiaz?source=post_page-----77807ee952f5--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e363caf1c79&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=post_page-6e363caf1c79----77807ee952f5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----77807ee952f5--------------------------------)
    ·7 min read·Sep 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F77807ee952f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&user=Valeria+Fonseca+Diaz&userId=6e363caf1c79&source=-----77807ee952f5---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F77807ee952f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftidying-up-the-framework-of-dataset-shifts-the-example-77807ee952f5&source=-----77807ee952f5---------------------bookmark_footer-----------)![](../Images/9e31584718ba2bf5d2608bb69b7ab98e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: I recently talked about the causes of model performance degradation, meaning
    when their prediction quality drops with respect to the moment we trained and
    deployed our models. [In this other post](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7),
    I proposed a new way of thinking about the causes of model degradation. In that
    framework, the so-called conditional probability comes out as the global cause.
  prefs: []
  type: TYPE_NORMAL
- en: The conditional probability is, by definition, composed of three probabilities
    which I call the specific causes. The most important learning of this restructure
    of concepts is that *covariate shift* and *conditional shift* are not two separate
    or parallel concepts. *Conditional shift* can happen as a function of *covariate
    shift*.
  prefs: []
  type: TYPE_NORMAL
- en: With this restructuring, I believe it becomes easier to think about the causes
    and it becomes more logical to interpret the shifts that we observe in our applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the scheme of causes and model performance for machine learning models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41a53ba3896a9e14a9b7ada026ce2104.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author. Adapted from [https://towardsdatascience.com/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7](/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)
  prefs: []
  type: TYPE_NORMAL
- en: In this scheme, we see the clear path that connects the causes to the prediction
    performance of our estimated models. One fundamental assumption we need to make
    in statistical learning is that our models are “good” estimators of the real models
    (real decision boundaries, real regression functions, etc.). “Good” can have different
    meanings, such as unbiased estimators, precise estimators, complete estimators,
    sufficient estimators, etc. But, for the sake of simplicity and the upcoming discussion,
    let’s say that they are good in the sense that they have a small prediction error.
    In other words, we assume that they are representative of the real models.
  prefs: []
  type: TYPE_NORMAL
- en: With this assumption, we are able to look for the causes of model degradation
    of the estimated model in the probabilities ***P(X), P(Y), P(X|Y),*** and consequently***,
    P(Y|X)***.
  prefs: []
  type: TYPE_NORMAL
- en: So, what we will do today is to exemplify and walk through different scenarios
    to see how ***P(Y|X)*** changes as a function of the 3 probabilities ***P(X|Y)***,
    ***P(X)***, and ***P(Y)***. We will do so by using a population of a few points
    in a 2D space and calculating the probabilities from these sample points in the
    way Laplace would do. The purpose is to digest the hierarchy scheme of causes
    of model degradation, keeping ***P(Y|X)*** as the global cause, and the other
    three as the specific causes. In that way, we can understand, for example, how
    a potential covariate shift can be sometimes the argument of the conditional shift
    rather than being a separate shift of its own.
  prefs: []
  type: TYPE_NORMAL
- en: The example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The case we will draw for our lesson today is a very simple one. We have a
    space of two covariates ***X1*** and ***X2*** and the output ***Y*** is a binary
    variable. This is what our model space looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9dfb0f5e2a871c9c8f7b8fa4e1f989de.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: You see there that the space is organized in 4 quadrants and the decision boundary
    in this space is the cross. This means that the model classifies samples in class
    1 if they lie in the 1st and 3rd quadrants, and in class 0 otherwise. For the
    sake of this exercise, we will walk through the different cases comparing ***P(Y=1|X1>a)***.
    This will be our conditional probability to showcase. If you are wondering why
    not taking also ***X2***, it’s only for the simplicity of the exercise. It doesn’t
    affect the insight we want to understand.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re still with a bittersweet feeling, taking **P(Y=1|X1>a)** is equivalent
    to **P(Y=1|X1>a, -inf <X2 < inf)**, so theoretically, we are still taking **X2**
    into account.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/d82c6e1f04e4f16ef6d95e5fdc45629e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Reference model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So to start with, we calculate our showcase probability and we obtain ***1/2***.
    Pretty much here our group of samples is quite uniform throughout the space and
    the prior probabilities are also uniform:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88048c01fd014a51c24ce82084572ac3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Shifts are coming up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*One extra sample appears in the bottom right quadrant. So the first thing
    we ask is: Are we talking about a covariate shift?*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Well, yes, because there is more sampling in ***X1>a*** than there was before.
    So, is this only a *covariate shift* but not a *conditional shift*? Let’s see.
    Here is the calculation of all the same probabilities as before with the updated
    set of points (The probabilities that changed are in orange):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3109fa31a6427b9b5f6a068653d9ba86.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: What did we see here? In fact, not only did we get a *covariate shift*, but
    overall, all the probabilities changed. The *prior* probability also changed because
    the covariate shift brought a new point of class 1 making the incidence of this
    class bigger than class 2\. Then also, the *inverse probability* ***P(X1>a|Y=1)***
    changed precisely because of the *prior shift*. All of that overall led to a *conditional
    shift* so we now got ***P(Y=1|X1>a)=2/3*** instead of ***1/2***.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s a thought bubble. A very important one actually.
  prefs: []
  type: TYPE_NORMAL
- en: With this shift in the sampling distribution, we obtained shifts in all the
    probabilities that play a role in the whole scheme of our models. Yet, the decision
    boundary that existed based on the initial sampling remained valid for this shift.
  prefs: []
  type: TYPE_NORMAL
- en: What does this mean?
  prefs: []
  type: TYPE_NORMAL
- en: Even though we obtained a conditional shift, the decision boundary did not necessarily
    degrade. Because the decision boundary comes from the expected value, if we calculate
    this value based on the current shift, the boundary may remain the same but with
    a different conditional probability.
  prefs: []
  type: TYPE_NORMAL
- en: '*2\. Samples at the first quadrant don’t exist anymore.*'
  prefs: []
  type: TYPE_NORMAL
- en: So, for ***X1>a*** things remained unchanged. Let’s see what happens to the
    conditional probability we’re showcasing and its elements.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/52f461e1e292851cf4fee30558575749.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, because within ***X1>a*** things remain unchanged, the conditional
    probability remained the same. Yet, when we look at ***P(X1>a)*** we obtain ***2/3***
    instead of ***1/2*** compared to the training sampling. So here we have a *covariate
    shift* ***without*** *a conditional shift*.
  prefs: []
  type: TYPE_NORMAL
- en: From a math perspective, how can the covariate probability change without the
    conditional probability changing? This is because ***P(Y=1)*** and ***P(X1>a|Y=1)***
    changed accordingly to the covariate probability. Therefore the compensation makes
    up for an unchanged conditional probability.
  prefs: []
  type: TYPE_NORMAL
- en: With these changes, just as before, the decision boundary remained valid.
  prefs: []
  type: TYPE_NORMAL
- en: '*3\. Throwing in some samples in different quadrants while the decision boundary
    remained valid.*'
  prefs: []
  type: TYPE_NORMAL
- en: We have here 2 extra combinations. In one case, the *prior* remained the same
    while the other two probabilities changed, still not changing the conditional
    probability. In the second case, *only* the *inverse probability* was associated
    with a conditional shift. Check the shifts here below. The latter is a pretty
    important one, so don’t miss it!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77461159b07a374577cd8b77cefaaf64.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: With this, we have now a pretty solid perspective on how the conditional probability
    can change as a function of the other three probabilities. But most importantly,
    we also know that not all conditional shifts invalidate the existing decision
    boundary. So what’s the deal with it?
  prefs: []
  type: TYPE_NORMAL
- en: Concept drift
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[In the previous post](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7),
    I also proposed a more specific way of defining *concept drift* (or *concept shift*).
    The proposal is:'
  prefs: []
  type: TYPE_NORMAL
- en: We refer to a change in the **concept** when the decision boundary or regression
    function becomes invalid when the probabilities at play are shifting.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So, the crucial point about this is that if the decision boundary becomes invalid,
    surely there is a conditional shift. The reverse, as we discussed in [the previous
    post](https://medium.com/towards-data-science/tidying-up-the-framework-of-dataset-shifts-cd9f922637b7)
    and as we saw in the examples above, is not necessarily true.
  prefs: []
  type: TYPE_NORMAL
- en: This might not be so fantastic from a practical perspective because it means
    that to truly know if there’s a concept drift, we might be forced to re-estimate
    the boundary or function. But at least, for our theoretical understanding, this
    is just as fascinating.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s an example in which we have a *concept drift*, naturally with a *conditional
    shift*, but actually *without a covariate or a prior shift*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a22fa23667500064f5b8917ba4ab1c63.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by author
  prefs: []
  type: TYPE_NORMAL
- en: How cool is this separation of components? The only element that changed here
    was the *inverse probability*, but, contrary to the previous shift we studied
    above, this change in the inverse probability was linked to the change in the
    decision boundary. Now, a valid decision boundary is only the separation according
    to ***X1>a*** discarding the boundary dictated by ***X2***.
  prefs: []
  type: TYPE_NORMAL
- en: What have we learned?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have walked very slowly through the decomposition of the causes of model
    degradation. We studied different shifts of the probability elements and how they
    relate to the degradation of the prediction performance of our machine learning
    models. The most important insights are:'
  prefs: []
  type: TYPE_NORMAL
- en: A conditional shift is a global cause of prediction degradation in machine learning
    models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The specific causes are covariate shift, prior shift, and inverse probability
    shift
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can have many different cases of probability shifts while the decision boundary
    remains valid
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A change in the decision boundary causes a conditional shift, but the reverse
    is not necessarily true!
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Concept drift* may be more specifically associated with the decision boundary
    rather than with the overall conditional probability distribution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What follows from this? Reorganizing our practical solutions in light of this
    hierarchy of definitions is the biggest invitation I make. We might find so many
    wanted answers to our current questions regarding the way in which we can monitor
    our models.
  prefs: []
  type: TYPE_NORMAL
- en: If you are currently working on model performance monitoring using these definitions,
    don’t hesitate to share your thoughts on this framework.
  prefs: []
  type: TYPE_NORMAL
- en: '*Happy thinking to everyone!*'
  prefs: []
  type: TYPE_NORMAL
