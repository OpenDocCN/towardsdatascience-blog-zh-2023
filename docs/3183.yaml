- en: Understanding and Mitigating LLM Hallucinations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç†è§£å’Œå‡è½»LLMå¹»è§‰
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/understanding-and-mitigating-llm-hallucinations-be88d31c4200?source=collection_archive---------1-----------------------#2023-10-23](https://towardsdatascience.com/understanding-and-mitigating-llm-hallucinations-be88d31c4200?source=collection_archive---------1-----------------------#2023-10-23)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/understanding-and-mitigating-llm-hallucinations-be88d31c4200?source=collection_archive---------1-----------------------#2023-10-23](https://towardsdatascience.com/understanding-and-mitigating-llm-hallucinations-be88d31c4200?source=collection_archive---------1-----------------------#2023-10-23)
- en: LLM hallucination detection challenges and a possible solution presented in
    a prominent research paper
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM å¹»è§‰æ£€æµ‹æŒ‘æˆ˜åŠå…¶åœ¨ä¸€ç¯‡é‡è¦ç ”ç©¶è®ºæ–‡ä¸­æå‡ºçš„å¯èƒ½è§£å†³æ–¹æ¡ˆã€‚
- en: '[](https://felipe-p-adachi.medium.com/?source=post_page-----be88d31c4200--------------------------------)[![Felipe
    de Pontes Adachi](../Images/58c9544ae85f43548c5e5b56fda31bb4.png)](https://felipe-p-adachi.medium.com/?source=post_page-----be88d31c4200--------------------------------)[](https://towardsdatascience.com/?source=post_page-----be88d31c4200--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----be88d31c4200--------------------------------)
    [Felipe de Pontes Adachi](https://felipe-p-adachi.medium.com/?source=post_page-----be88d31c4200--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://felipe-p-adachi.medium.com/?source=post_page-----be88d31c4200--------------------------------)[![Felipe
    de Pontes Adachi](../Images/58c9544ae85f43548c5e5b56fda31bb4.png)](https://felipe-p-adachi.medium.com/?source=post_page-----be88d31c4200--------------------------------)[](https://towardsdatascience.com/?source=post_page-----be88d31c4200--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----be88d31c4200--------------------------------)
    [Felipe de Pontes Adachi](https://felipe-p-adachi.medium.com/?source=post_page-----be88d31c4200--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa038269245d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-mitigating-llm-hallucinations-be88d31c4200&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=post_page-a038269245d5----be88d31c4200---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----be88d31c4200--------------------------------)
    Â·8 min readÂ·Oct 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbe88d31c4200&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-mitigating-llm-hallucinations-be88d31c4200&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=-----be88d31c4200---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa038269245d5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-mitigating-llm-hallucinations-be88d31c4200&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=post_page-a038269245d5----be88d31c4200---------------------post_header-----------)
    å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----be88d31c4200--------------------------------)
    Â·8 min readÂ·Oct 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbe88d31c4200&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-mitigating-llm-hallucinations-be88d31c4200&user=Felipe+de+Pontes+Adachi&userId=a038269245d5&source=-----be88d31c4200---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbe88d31c4200&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-mitigating-llm-hallucinations-be88d31c4200&source=-----be88d31c4200---------------------bookmark_footer-----------)![](../Images/ada358f0bc7233d554233f71e47aa0b8.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbe88d31c4200&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-and-mitigating-llm-hallucinations-be88d31c4200&source=-----be88d31c4200---------------------bookmark_footer-----------)![](../Images/ada358f0bc7233d554233f71e47aa0b8.png)'
- en: '[Image by Enrique from Pixabay](https://pixabay.com/photos/forest-person-surreal-poisoning-7772371/)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç”± Enrique æä¾›çš„å›¾ç‰‡](https://pixabay.com/photos/forest-person-surreal-poisoning-7772371/)'
- en: Recently, large language models (LLMs) have shown impressive and increasing
    capabilities, including generating highly fluent and convincing responses to user
    prompts. However, LLMs are known for their ability to generate non-factual or
    nonsensical statements, more commonly known as â€œhallucinations.â€ This characteristic
    can undermine trust in many scenarios where factuality is required, such as summarization
    tasks, generative question answering, and dialogue generations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»ä¸”ä¸æ–­å¢å¼ºçš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬å¯¹ç”¨æˆ·æç¤ºç”Ÿæˆé«˜åº¦æµç•…å’Œä»¤äººä¿¡æœçš„å“åº”ã€‚ç„¶è€Œï¼ŒLLMs ä»¥ç”Ÿæˆéäº‹å®æ€§æˆ–è’è°¬é™ˆè¿°è€Œé—»åï¼Œè¿™ç§ç‰¹æ€§é€šå¸¸ç§°ä¸ºâ€œå¹»è§‰â€ã€‚è¿™ç§ç‰¹å¾å¯èƒ½ä¼šåœ¨è®¸å¤šéœ€è¦äº‹å®æ€§çš„åœºæ™¯ä¸­æŸå®³ä¿¡ä»»ï¼Œå¦‚æ€»ç»“ä»»åŠ¡ã€ç”Ÿæˆå¼é—®ç­”å’Œå¯¹è¯ç”Ÿæˆã€‚
- en: Detecting hallucinations has always been challenging among humans, which remains
    true in the context of LLMs. This is especially challenging, considering we usually
    donâ€™t have access to ground truth context for consistency checks. Additional information
    on the LLMâ€™s generations, like the output probability distributions, can help
    with this task. Still, it is often the case where this type of information is
    unavailable, making the task even more difficult.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: æ£€æµ‹å¹»è§‰åœ¨äººç±»ä¸­ä¸€ç›´æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œåœ¨ LLM çš„èƒŒæ™¯ä¸‹åŒæ ·å¦‚æ­¤ã€‚è¿™å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæˆ‘ä»¬é€šå¸¸æ— æ³•è·å–ç”¨äºä¸€è‡´æ€§æ£€æŸ¥çš„çœŸå®èƒŒæ™¯ä¿¡æ¯ã€‚æœ‰å…³ LLM ç”Ÿæˆçš„é™„åŠ ä¿¡æ¯ï¼Œå¦‚è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒï¼Œå¯ä»¥å¸®åŠ©å®Œæˆè¿™ä¸€ä»»åŠ¡ã€‚ç„¶è€Œï¼Œè¿™ç±»ä¿¡æ¯å¾€å¾€ä¸å¯ç”¨ï¼Œä½¿å¾—ä»»åŠ¡æ›´åŠ å›°éš¾ã€‚
- en: 'Hallucination detection has yet to be solved and is an active area of research.
    In this blog post, weâ€™ll present the task in general and its challenges and one
    possible approach published in the research paper [**SELFCHECKGPT: Zero-Resource
    Black-Box Hallucination Detection for Generative Large Language Models**](https://arxiv.org/pdf/2303.08896.pdf?ref=content.whylabs.tds)[1].
    We will illustrate some of the approaches presented in the paper with real examples,
    pointing out some pros and cons of each method. You can review the examples yourself
    by going to this [Google Colab Notebook](https://colab.research.google.com/drive/1ftgiASR3TeMaRTQ-cTd81iEoh2j0UP16?usp=sharing&ref=content.whylabs.ai).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 'å¹»è§‰æ£€æµ‹å°šæœªè§£å†³ï¼Œä»æ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€èˆ¬ä»‹ç»ä»»åŠ¡åŠå…¶æŒ‘æˆ˜ï¼Œå¹¶ä»‹ç»åœ¨ç ”ç©¶è®ºæ–‡ [**SELFCHECKGPT: Zero-Resource
    Black-Box Hallucination Detection for Generative Large Language Models**](https://arxiv.org/pdf/2303.08896.pdf?ref=content.whylabs.tds)[1]
    ä¸­æå‡ºçš„ä¸€ç§å¯èƒ½çš„æ–¹æ³•ã€‚æˆ‘ä»¬å°†ç”¨å®é™…ä¾‹å­è¯´æ˜è®ºæ–‡ä¸­æå‡ºçš„ä¸€äº›æ–¹æ³•ï¼Œå¹¶æŒ‡å‡ºæ¯ç§æ–¹æ³•çš„ä¸€äº›ä¼˜ç¼ºç‚¹ã€‚ä½ å¯ä»¥é€šè¿‡è®¿é—® [Google Colab Notebook](https://colab.research.google.com/drive/1ftgiASR3TeMaRTQ-cTd81iEoh2j0UP16?usp=sharing&ref=content.whylabs.ai)
    æ¥æŸ¥çœ‹è¿™äº›ç¤ºä¾‹ã€‚'
- en: '*ğŸ’¡* ***Update****: Inspired by the research done in this blog post, we released
    a new feature in* [***LangKit***](https://github.com/whylabs/langkit)*. The* ***response_hallucination***
    *module will automatically calculate consistency scores to help you gain insights
    on the presence of hallucinated responses in your LLM. You can check it out in*
    [*this example notebook*](https://github.com/whylabs/langkit/blob/main/langkit/examples/Response_Consistency.ipynb)'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*ğŸ’¡* ***æ›´æ–°****ï¼šå—æœ¬åšå®¢æ–‡ç« ç ”ç©¶çš„å¯å‘ï¼Œæˆ‘ä»¬åœ¨* [***LangKit***](https://github.com/whylabs/langkit)*ä¸­å‘å¸ƒäº†ä¸€ä¸ªæ–°åŠŸèƒ½ã€‚*
    ***response_hallucination*** *æ¨¡å—å°†è‡ªåŠ¨è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°ï¼Œå¸®åŠ©ä½ äº†è§£ LLM ä¸­å¹»è§‰å“åº”çš„å­˜åœ¨ã€‚ä½ å¯ä»¥åœ¨* [*è¿™ä¸ªç¤ºä¾‹ç¬”è®°æœ¬*](https://github.com/whylabs/langkit/blob/main/langkit/examples/Response_Consistency.ipynb)
    *ä¸­æŸ¥çœ‹å®ƒã€‚*'
- en: 'This blog will cover:'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ¬åšå®¢å°†æ¶µç›–ï¼š
- en: What Is LLM Hallucination
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ LLM å¹»è§‰
- en: 'The Approach: SelfCheckGPT'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ–¹æ³•ï¼šSelfCheckGPT
- en: Consistency Check
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€è‡´æ€§æ£€æŸ¥
- en: 1\. BERTScore
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1\. BERTScore
- en: 2\. Natural Language Inference
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2\. è‡ªç„¶è¯­è¨€æ¨ç†
- en: 3\. LLM Prompt
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 3\. LLM æç¤º
- en: Experiments
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å®éªŒ
- en: Conclusion
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: References
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: What Is LLM Hallucination
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ LLM å¹»è§‰
- en: 'In natural language generation, hallucination can be defined as â€œgenerated
    content that is nonsensical or unfaithful to the provided source contentâ€[2].
    The source content can represent different functions for different tasks. For
    example, for summarization tasks, the source is the input text being summarized,
    while for generative question-answering tasks, the source is considered the world
    knowledge[2]. Letâ€™s focus on the question-answering task and take a look at one
    example of a user question and the answer given by OpenAIâ€™s GPT model (text-davinci-003):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆä¸­ï¼Œå¹»è§‰å¯ä»¥å®šä¹‰ä¸ºâ€œç”Ÿæˆçš„å†…å®¹æ˜¯æ— æ„ä¹‰çš„æˆ–ä¸å¿ äºæä¾›çš„æºå†…å®¹â€[2]ã€‚æºå†…å®¹å¯ä»¥ä»£è¡¨ä¸åŒä»»åŠ¡çš„ä¸åŒåŠŸèƒ½ã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ‘˜è¦ä»»åŠ¡ï¼Œæºå†…å®¹æ˜¯è¢«æ‘˜è¦çš„è¾“å…¥æ–‡æœ¬ï¼Œè€Œå¯¹äºç”Ÿæˆå¼é—®ç­”ä»»åŠ¡ï¼Œæºå†…å®¹è¢«è®¤ä¸ºæ˜¯ä¸–ç•ŒçŸ¥è¯†[2]ã€‚æˆ‘ä»¬æ¥å…³æ³¨é—®ç­”ä»»åŠ¡ï¼Œå¹¶ä»¥ç”¨æˆ·é—®é¢˜å’Œ
    OpenAI çš„ GPT æ¨¡å‹ï¼ˆtext-davinci-003ï¼‰ç»™å‡ºçš„ç­”æ¡ˆä¸ºä¾‹ï¼š
- en: 'User Prompt: **Who was Philip Hayworth?**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·æç¤ºï¼š**è²åˆ©æ™®Â·æµ·æ²ƒæ–¯æ˜¯è°ï¼Ÿ**
- en: 'LLM Response: **Philip Hayworth was an English barrister and politician who
    served as Member of Parliament for Thetford from 1859 to 1868.**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: LLM å“åº”ï¼š**è²åˆ©æ™®Â·æµ·æ²ƒæ–¯æ˜¯è‹±å›½çš„ä¸€åå¾‹å¸ˆå’Œæ”¿æ²»å®¶ï¼Œæ›¾äº1859å¹´è‡³1868å¹´æ‹…ä»»ç‰¹ç‰¹ç¦å¾·çš„å›½ä¼šè®®å‘˜ã€‚**
- en: 'At first sight, that looks like a coherent response, but after a while, we
    might ask ourselves a very reasonable question: is it true?'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åˆçœ‹èµ·æ¥ï¼Œè¿™ä¼¼ä¹æ˜¯ä¸€ä¸ªè¿è´¯çš„å›ç­”ï¼Œä½†è¿‡ä¸€æ®µæ—¶é—´ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šé—®ä¸€ä¸ªéå¸¸åˆç†çš„é—®é¢˜ï¼šè¿™æ˜¯çœŸçš„å—ï¼Ÿ
- en: We donâ€™t have much information to answer our new question, though. We donâ€™t
    have a context with proven facts we can use to verify the statement. LLMs are
    typically trained under a massive corpora of texts, and it can be hard to verify
    if the statement is grounded in a particular source of information. A quick Google
    search does not show any hits for a person matching the response. What exactly
    constitutes a hallucination is still not well established, but this example could
    be understandably considered a hallucination because the subject with this name,
    location, and employment may not have existed at all.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¿‡ï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”è¿™ä¸ªæ–°é—®é¢˜ã€‚æˆ‘ä»¬æ²¡æœ‰å¯ä»¥ç”¨æ¥éªŒè¯é™ˆè¿°çš„ç»è¿‡éªŒè¯çš„äº‹å®çš„èƒŒæ™¯ã€‚LLMé€šå¸¸åœ¨å¤§é‡æ–‡æœ¬ä¸­è¿›è¡Œè®­ç»ƒï¼Œå› æ­¤å¾ˆéš¾éªŒè¯é™ˆè¿°æ˜¯å¦åŸºäºç‰¹å®šçš„ä¿¡æ¯æ¥æºã€‚å¿«é€Ÿçš„Googleæœç´¢æ²¡æœ‰æ˜¾ç¤ºå‡ºåŒ¹é…å›ç­”çš„äººçš„ä»»ä½•ä¿¡æ¯ã€‚ä»€ä¹ˆç¡®åˆ‡æ„æˆå¹»è§‰ä»ç„¶æ²¡æœ‰å¾ˆå¥½åœ°å»ºç«‹ï¼Œä½†è¿™ä¸ªä¾‹å­å¯ä»¥è¢«ç†è§£ä¸ºå¹»è§‰ï¼Œå› ä¸ºè¿™ä¸ªåå­—ã€åœ°ç‚¹å’ŒèŒä¸šçš„ä¸»é¢˜å¯èƒ½æ ¹æœ¬ä¸å­˜åœ¨ã€‚
- en: 'Letâ€™s try this again with another question:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å†è¯•ä¸€æ¬¡å¦ä¸€ä¸ªé—®é¢˜ï¼š
- en: 'User Prompt: **Who is Bill Gates?**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨æˆ·æç¤ºï¼š**æ¯”å°”Â·ç›–èŒ¨æ˜¯è°ï¼Ÿ**
- en: 'LLM Response: **Bill Gates is a technology entrepreneur, investor, and philanthropist.
    He is the co-founder of Microsoft Corporation and is one of the wealthiest people
    in the world.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: LLMå›åº”ï¼š**æ¯”å°”Â·ç›–èŒ¨æ˜¯æŠ€æœ¯ä¼ä¸šå®¶ã€æŠ•èµ„è€…å’Œæ…ˆå–„å®¶ã€‚ä»–æ˜¯å¾®è½¯å…¬å¸çš„å…±åŒåˆ›å§‹äººï¼Œä¹Ÿæ˜¯ä¸–ç•Œä¸Šæœ€å¯Œæœ‰çš„äººä¹‹ä¸€ã€‚**
- en: Ok, these statements are much easier to verify and are supported by a quick
    check on Wikipedia, so this is unlikely to be a hallucination. During training,
    it is very likely that the LLM has seen a lot of statements about Bill Gates,
    so the following tokens after â€œBill Gates is _â€ will likely be generated with
    high confidence. On the other hand, the LLM might not be sure about which words
    to use after â€œPhilip Hayworth is _â€. This insight allows us to link uncertainty
    with factuality, as factual sentences will likely contain tokens predicted with
    a higher probability when compared to hallucinated sentences. However, we might
    not have the output probability distribution at hand for a good number of cases.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¥½çš„ï¼Œè¿™äº›é™ˆè¿°æ›´å®¹æ˜“éªŒè¯ï¼Œå¹¶ä¸”é€šè¿‡å¿«é€Ÿæ£€æŸ¥ç»´åŸºç™¾ç§‘å¾—åˆ°äº†æ”¯æŒï¼Œæ‰€ä»¥è¿™ä¸å¤ªå¯èƒ½æ˜¯å¹»è§‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒLLMå¾ˆå¯èƒ½è§è¿‡å¾ˆå¤šå…³äºæ¯”å°”Â·ç›–èŒ¨çš„é™ˆè¿°ï¼Œå› æ­¤â€œæ¯”å°”Â·ç›–èŒ¨æ˜¯_â€ä¹‹åçš„ä»¤ç‰Œå¾ˆå¯èƒ½ä¼šä»¥è¾ƒé«˜çš„ä¿¡å¿ƒç”Ÿæˆã€‚å¦ä¸€æ–¹é¢ï¼ŒLLMå¯èƒ½å¯¹â€œPhilip
    Hayworth æ˜¯_â€ä¹‹åä½¿ç”¨å“ªäº›è¯ä¸å¤ªç¡®å®šã€‚è¿™ä¸€è§è§£ä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†ä¸ç¡®å®šæ€§ä¸çœŸå®æ€§è”ç³»èµ·æ¥ï¼Œå› ä¸ºäº‹å®å¥å­é€šå¸¸ä¼šåŒ…å«é¢„æµ‹æ¦‚ç‡è¾ƒé«˜çš„ä»¤ç‰Œï¼Œè€Œå¹»è§‰å¥å­åˆ™ä¸ç„¶ã€‚ç„¶è€Œï¼Œå¯¹äºè®¸å¤šæ¡ˆä¾‹ï¼Œæˆ‘ä»¬å¯èƒ½æ²¡æœ‰æ‰‹å¤´çš„è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒã€‚
- en: The example and content of the current session was based on the original paper
    [1], and we will continue to explore the paperâ€™s approach in the following sections.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬æ¬¡ä¼šè®®çš„ç¤ºä¾‹å’Œå†…å®¹åŸºäºåŸå§‹è®ºæ–‡[1]ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ç»§ç»­æ¢ç´¢è®ºæ–‡çš„æ–¹æ³•ã€‚
- en: 'The Approach: SelfCheckGPT'
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ–¹æ³•ï¼šSelfCheckGPT
- en: 'Throughout the last section, we considered two important considerations for
    our approach: access to an external context and access to the LLMâ€™s output probability
    distribution. When a method does not require an external context or database to
    perform the consistency check, we can call it a **zero-resource** method. Similarly,
    when a method requires only the LLMâ€™s generated text, it can be called a **black-box**
    method.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬è€ƒè™‘äº†æˆ‘ä»¬æ–¹æ³•çš„ä¸¤ä¸ªé‡è¦å› ç´ ï¼šè®¿é—®å¤–éƒ¨èƒŒæ™¯å’Œè®¿é—®LLMçš„è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒã€‚å½“ä¸€ç§æ–¹æ³•ä¸éœ€è¦å¤–éƒ¨èƒŒæ™¯æˆ–æ•°æ®åº“æ¥è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ç§°å…¶ä¸º**é›¶èµ„æº**æ–¹æ³•ã€‚ç±»ä¼¼åœ°ï¼Œå½“ä¸€ç§æ–¹æ³•åªéœ€è¦LLMç”Ÿæˆçš„æ–‡æœ¬æ—¶ï¼Œå¯ä»¥ç§°ä¹‹ä¸º**é»‘ç®±**æ–¹æ³•ã€‚
- en: The approach we want to talk about in this blog post is a zero-resource black-box
    hallucination detection method and is based on the premise that **sampled responses
    to the same prompt will likely diverge and contradict each other for hallucinated
    facts, and will likely be similar and consistent with each other for factual statements**.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­è¦è®¨è®ºçš„æ–¹æ³•æ˜¯ä¸€ç§é›¶èµ„æºé»‘ç®±å¹»è§‰æ£€æµ‹æ–¹æ³•ï¼ŒåŸºäºè¿™æ ·ä¸€ä¸ªå‰æï¼š**å¯¹ç›¸åŒæç¤ºçš„é‡‡æ ·å›ç­”å¯¹äºå¹»è§‰äº‹å®å¯èƒ½ä¼šå‡ºç°åˆ†æ­§å’ŒçŸ›ç›¾ï¼Œè€Œå¯¹äºäº‹å®é™ˆè¿°åˆ™å¯èƒ½ä¼šç›¸ä¼¼å’Œä¸€è‡´**ã€‚
- en: 'Letâ€™s revisit the previous examples. To apply the detection method, we need
    more samples, so letâ€™s ask the LLM the same question three more times:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é‡æ–°å®¡è§†ä¹‹å‰çš„ä¾‹å­ã€‚ä¸ºäº†åº”ç”¨æ£€æµ‹æ–¹æ³•ï¼Œæˆ‘ä»¬éœ€è¦æ›´å¤šçš„æ ·æœ¬ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬å†å‘LLMæå‡ºä¸‰ä¸ªç›¸åŒçš„é—®é¢˜ï¼š
- en: '![](../Images/6a353b00255ca73e9f5e6b8a22b0adbe.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a353b00255ca73e9f5e6b8a22b0adbe.png)'
- en: Table by author
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„è¡¨æ ¼
- en: Indeed, the answers contradict each other â€” at times, Philip Hayworth is a British
    politician, and in other samples, he is an Australian engineer or an American
    lawyer, who all lived and acted in different periods.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®ï¼Œç­”æ¡ˆç›¸äº’çŸ›ç›¾â€”â€”æœ‰æ—¶ï¼ŒPhilip Hayworth æ˜¯ä¸€ä½è‹±å›½æ”¿æ²»å®¶ï¼Œè€Œåœ¨å…¶ä»–æ ·æœ¬ä¸­ï¼Œä»–æ˜¯æ¾³å¤§åˆ©äºšå·¥ç¨‹å¸ˆæˆ–ç¾å›½å¾‹å¸ˆï¼Œä»–ä»¬ç”Ÿæ´»å’Œè¡ŒåŠ¨äºä¸åŒçš„æ—¶æœŸã€‚
- en: 'Letâ€™s compare with the Bill Gates example:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»¥æ¯”å°”Â·ç›–èŒ¨çš„ä¾‹å­è¿›è¡Œæ¯”è¾ƒï¼š
- en: '![](../Images/3c9d9bc9e5e6b6c8712ed29f0cf3eb18.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c9d9bc9e5e6b6c8712ed29f0cf3eb18.png)'
- en: Table by author
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨æ ¼ä½œè€…æä¾›
- en: We can observe that the occupations, organizations, and traits assigned to Bill
    Gates are consistent across samples, with equal or semantically similar terms
    being used.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œæ¯”å°”Â·ç›–èŒ¨åˆ†é…çš„èŒä¸šã€ç»„ç»‡å’Œç‰¹å¾åœ¨æ ·æœ¬ä¹‹é—´æ˜¯ä¸€è‡´çš„ï¼Œä½¿ç”¨äº†ç›¸ç­‰æˆ–è¯­ä¹‰ç›¸ä¼¼çš„æœ¯è¯­ã€‚
- en: Consistency Check
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€è‡´æ€§æ£€æŸ¥
- en: Now that we have multiple samples, the final step is to perform a consistency
    check â€” a way to determine whether the answers agree with each other. This can
    be done in a number of ways, so letâ€™s explore some approaches presented in the
    paper. Feel free to execute the code yourself by checking this [Google Colab Notebook](https://colab.research.google.com/drive/1ftgiASR3TeMaRTQ-cTd81iEoh2j0UP16?usp=sharing&ref=content.whylabs.tds).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†å¤šä¸ªæ ·æœ¬ï¼Œæœ€åä¸€æ­¥æ˜¯è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥â€”â€”ç¡®å®šç­”æ¡ˆæ˜¯å¦å½¼æ­¤ä¸€è‡´ã€‚è¿™å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼å®Œæˆï¼Œæ‰€ä»¥è®©æˆ‘ä»¬æ¢ç´¢ä¸€ä¸‹è®ºæ–‡ä¸­æå‡ºçš„ä¸€äº›æ–¹æ³•ã€‚ä½ å¯ä»¥é€šè¿‡æŸ¥çœ‹è¿™ä¸ª
    [Google Colab Notebook](https://colab.research.google.com/drive/1ftgiASR3TeMaRTQ-cTd81iEoh2j0UP16?usp=sharing&ref=content.whylabs.tds)
    è‡ªè¡Œæ‰§è¡Œä»£ç ã€‚
- en: BERTScore
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BERTScore
- en: An intuitive approach to perform this check is by measuring the semantic similarity
    between the samples, and BERTScore[3] is one way to do that. BERTScore computes
    a similarity score for each token in the candidate sentence with each token in
    the reference sentence to calculate a similarity score between the sentences.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰§è¡Œæ­¤æ£€æŸ¥çš„ä¸€ç§ç›´è§‚æ–¹æ³•æ˜¯æµ‹é‡æ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œè€Œ BERTScore[3] æ˜¯ä¸€ç§å®ç°æ–¹å¼ã€‚BERTScore ä¸ºå€™é€‰å¥å­ä¸­çš„æ¯ä¸ªè¯ä¸å‚è€ƒå¥å­ä¸­çš„æ¯ä¸ªè¯è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œä»¥è®¡ç®—å¥å­ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°ã€‚
- en: In the context of SelfCheckGPT, the score is calculated per sentence. Each sentence
    of the original answer will be scored against each sentence of a given sample
    to find the most similar sentence. These maximum similarity scores will be averaged
    across all samples, resulting in a final hallucination score for each sentence
    in the original answer. The final score needs to tend towards 1 for dissimilar
    sentences and 0 for similar sentences, so we need to subtract the similarity score
    from 1.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ SelfCheckGPT çš„èƒŒæ™¯ä¸‹ï¼Œåˆ†æ•°æ˜¯é€å¥è®¡ç®—çš„ã€‚åŸå§‹ç­”æ¡ˆçš„æ¯ä¸ªå¥å­å°†ä¸ç»™å®šæ ·æœ¬çš„æ¯ä¸ªå¥å­è¿›è¡Œè¯„åˆ†ï¼Œä»¥æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å¥å­ã€‚è¿™äº›æœ€å¤§ç›¸ä¼¼åº¦åˆ†æ•°å°†åœ¨æ‰€æœ‰æ ·æœ¬ä¸­è¿›è¡Œå¹³å‡ï¼Œä»è€Œä¸ºåŸå§‹ç­”æ¡ˆä¸­çš„æ¯ä¸ªå¥å­å¾—åˆ°æœ€ç»ˆçš„å¹»è§‰åˆ†æ•°ã€‚æœ€ç»ˆåˆ†æ•°éœ€è¦è¶‹è¿‘äº
    1ï¼ˆè¡¨ç¤ºä¸ç›¸ä¼¼çš„å¥å­ï¼‰å’Œ 0ï¼ˆè¡¨ç¤ºç›¸ä¼¼çš„å¥å­ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦ä» 1 ä¸­å‡å»ç›¸ä¼¼åº¦åˆ†æ•°ã€‚
- en: 'Letâ€™s show how this works with the first sentence of our original answer being
    checked against the first sample:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å±•ç¤ºå¦‚ä½•ç”¨åŸå§‹ç­”æ¡ˆçš„ç¬¬ä¸€ä¸ªå¥å­ä¸ç¬¬ä¸€ä¸ªæ ·æœ¬è¿›è¡Œæ£€æŸ¥ï¼š
- en: '![](../Images/00483d188ef30cfd8e58a5c812887998.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/00483d188ef30cfd8e58a5c812887998.png)'
- en: Image by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ä½œè€…æä¾›
- en: The maximum score for the first sample is 0.69\. Repeating the process for the
    two remaining samples and assuming the other maximum scores were 0.72 and 0.72,
    our final score for this sentence would be **1 â€” (0.69+0.72+0.72)/3 = 0.29**.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æœ€é«˜åˆ†æ˜¯ 0.69ã€‚é‡å¤å¯¹å‰©ä½™ä¸¤ä¸ªæ ·æœ¬çš„å¤„ç†ï¼Œå¹¶å‡è®¾å…¶ä»–æœ€é«˜åˆ†ä¸º 0.72 å’Œ 0.72ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯¹è¯¥å¥å­çš„æœ€ç»ˆåˆ†æ•°å°†æ˜¯ **1 â€” (0.69+0.72+0.72)/3
    = 0.29**ã€‚
- en: Using semantic similarity to verify consistency is an intuitive approach. Other
    encoders can be used for embedding representations, so itâ€™s also an approach that
    can be further explored.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ¥éªŒè¯ä¸€è‡´æ€§æ˜¯ä¸€ç§ç›´è§‚çš„æ–¹æ³•ã€‚å…¶ä»–ç¼–ç å™¨ä¹Ÿå¯ä»¥ç”¨äºåµŒå…¥è¡¨ç¤ºï¼Œå› æ­¤è¿™ä¹Ÿæ˜¯ä¸€ç§å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢çš„æ–¹æ³•ã€‚
- en: Natural Language Inference
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡ªç„¶è¯­è¨€æ¨ç†
- en: Natural language inference is the task of determining entailment, that is, whether
    a hypothesis is true, false, or undetermined based on a premise[4]. In our case,
    each sample is used as the premise and each sentence of the original answer is
    used as our hypothesis. The scores across samples are averaged for each sentence
    to obtain the final score. The entailment is performed with a Deberta model fine-tuned
    to the Multi-NLI dataset[5]. Weâ€™ll use the normalized prediction probability instead
    of the actual classes, such as â€œentailmentâ€ or â€œcontradiction,â€ to compute the
    scores.[6]
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªç„¶è¯­è¨€æ¨ç†æ˜¯ç¡®å®šè•´æ¶µçš„ä»»åŠ¡ï¼Œå³æ ¹æ®å‰æ[4]åˆ¤æ–­ä¸€ä¸ªå‡è®¾æ˜¯å¦ä¸ºçœŸã€å‡æˆ–æœªç¡®å®šã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæ¯ä¸ªæ ·æœ¬ç”¨ä½œå‰æï¼Œæ¯ä¸ªåŸå§‹ç­”æ¡ˆçš„å¥å­ç”¨ä½œæˆ‘ä»¬çš„å‡è®¾ã€‚é€šè¿‡å¯¹æ¯ä¸ªå¥å­çš„æ ·æœ¬åˆ†æ•°è¿›è¡Œå¹³å‡ï¼Œå¾—åˆ°æœ€ç»ˆåˆ†æ•°ã€‚è•´æ¶µé€šè¿‡å¯¹
    Multi-NLI æ•°æ®é›†[5] è¿›è¡Œå¾®è°ƒçš„ Deberta æ¨¡å‹æ¥æ‰§è¡Œã€‚æˆ‘ä»¬å°†ä½¿ç”¨å½’ä¸€åŒ–é¢„æµ‹æ¦‚ç‡æ¥è®¡ç®—åˆ†æ•°ï¼Œè€Œä¸æ˜¯å®é™…ç±»åˆ«ï¼Œå¦‚â€œè•´æ¶µâ€æˆ–â€œçŸ›ç›¾â€ã€‚[6]
- en: The entailment task is closer to our goal of consistency checking, so we can
    expect that a model fine-tuned for that purpose will perform well. The author
    also publicly shared [the model on HuggingFace](https://huggingface.co/potsawee/deberta-v3-large-mnli?ref=content.whylabs.tds),
    and other NLI models are publicly available, making this approach very accessible.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è•´æ¶µä»»åŠ¡æ›´æ¥è¿‘æˆ‘ä»¬çš„ä¸€è‡´æ€§æ£€æŸ¥ç›®æ ‡ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥æœŸå¾…ä¸ºæ­¤ç›®çš„å¾®è°ƒçš„æ¨¡å‹ä¼šè¡¨ç°è‰¯å¥½ã€‚ä½œè€…è¿˜åœ¨ [HuggingFace](https://huggingface.co/potsawee/deberta-v3-large-mnli?ref=content.whylabs.tds)
    ä¸Šå…¬å¼€åˆ†äº«äº†è¯¥æ¨¡å‹ï¼Œå…¶ä»– NLI æ¨¡å‹ä¹Ÿå…¬å¼€å¯ç”¨ï¼Œä½¿å¾—è¿™ç§æ–¹æ³•éå¸¸å®¹æ˜“è·å–ã€‚
- en: LLM Prompt
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM Prompt
- en: 'Considering we already use LLMs to generate the answers and samples, we might
    as well use an LLM to perform the consistency check. We can query the LLM for
    a consistency check for each original sentence and each sample as our context.
    The image below, taken from the original paperâ€™s repository, illustrates how this
    is done:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°æˆ‘ä»¬å·²ç»ä½¿ç”¨ LLM æ¥ç”Ÿæˆç­”æ¡ˆå’Œæ ·æœ¬ï¼Œæˆ‘ä»¬ä¸å¦¨ä½¿ç”¨ LLM æ¥æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥ã€‚æˆ‘ä»¬å¯ä»¥å¯¹æ¯ä¸ªåŸå§‹å¥å­å’Œæ¯ä¸ªæ ·æœ¬è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼Œå°† LLM ä½œä¸ºæˆ‘ä»¬çš„ä¸Šä¸‹æ–‡ã€‚ä¸‹é¢çš„å›¾ç‰‡ï¼Œæ¥è‡ªåŸå§‹è®ºæ–‡çš„ä»“åº“ï¼Œè¯´æ˜äº†å¦‚ä½•è¿›è¡Œè¿™ä¸ªæ“ä½œï¼š
- en: '![](../Images/d0c3428d1c9cb81ab76b5d1a1b75ec9b.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d0c3428d1c9cb81ab76b5d1a1b75ec9b.png)'
- en: '**SELFCHECKGPT WITH LLM PROMPT. FROM:** [**HTTPS://GITHUB.COM/POTSAWEE/SELFCHECKGPT/TREE/MAIN**](https://github.com/potsawee/selfcheckgpt/tree/main?ref=content.whylabs.ai)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**SELFCHECKGPT WITH LLM PROMPT. æ¥æºï¼š** [**HTTPS://GITHUB.COM/POTSAWEE/SELFCHECKGPT/TREE/MAIN**](https://github.com/potsawee/selfcheckgpt/tree/main?ref=content.whylabs.ai)'
- en: The final score can be computed by assigning 1 to â€œNoâ€, 0 to â€œYesâ€, 0.5 for
    N/A, and averaging the values across samples.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆå¾—åˆ†å¯ä»¥é€šè¿‡å°†â€œå¦â€èµ‹å€¼ä¸º 1ï¼Œâ€œæ˜¯â€èµ‹å€¼ä¸º 0ï¼Œâ€œä¸é€‚ç”¨â€èµ‹å€¼ä¸º 0.5ï¼Œå¹¶å¯¹æ ·æœ¬çš„å€¼è¿›è¡Œå¹³å‡æ¥è®¡ç®—ã€‚
- en: Unlike the other two approaches, this one incurs extra calls to the LLM of your
    choice, meaning additional latency and, possibly, additional costs. On the other
    hand, we can leverage the LLMâ€™s capabilities to help us perform this check.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å…¶ä»–ä¸¤ç§æ–¹æ³•ä¸åŒï¼Œè¿™ç§æ–¹æ³•éœ€è¦é¢å¤–è°ƒç”¨ä½ é€‰æ‹©çš„ LLMï¼Œè¿™æ„å‘³ç€é¢å¤–çš„å»¶è¿Ÿå’Œå¯èƒ½çš„é¢å¤–æˆæœ¬ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ LLM çš„èƒ½åŠ›æ¥å¸®åŠ©æˆ‘ä»¬è¿›è¡Œæ£€æŸ¥ã€‚
- en: Experiments
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å®éªŒ
- en: Letâ€™s see what we get as results for the two examples weâ€™ve been discussing
    for each of the three approaches.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹åœ¨ä¸‰ç§æ–¹æ³•ä¸­è®¨è®ºçš„ä¸¤ä¸ªç¤ºä¾‹çš„ç»“æœå¦‚ä½•ã€‚
- en: '![](../Images/bbb277288b2562da66001aba60dd5e1d.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bbb277288b2562da66001aba60dd5e1d.png)'
- en: Table by author
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œè€…æä¾›çš„è¡¨æ ¼
- en: These values are solely meant to illustrate the method. With only three sentences,
    itâ€™s not supposed to be a means to compare and determine which approach is best.
    For that purpose, the original paper shares the experimental results on the paperâ€™s
    repository [here](https://github.com/potsawee/selfcheckgpt/tree/main?ref=content.whylabs.ai#experimental-results),
    which includes additional versions that werenâ€™t discussed in this blog post. I
    wonâ€™t go into the details of the results, but by all three metrics (NonFact, Factual,
    and Ranking), the LLM-Prompt is the best-performing version, closely followed
    by the NLI version. The BERTScore version looks to be considerably worse than
    the remaining two. Our simple examples seem to follow along the lines of the shared
    results.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å€¼ä»…ç”¨äºè¯´æ˜æ–¹æ³•ã€‚åªæœ‰ä¸‰ä¸ªå¥å­çš„æƒ…å†µä¸‹ï¼Œå®ƒä¸åº”è¯¥ç”¨æ¥æ¯”è¾ƒå’Œç¡®å®šå“ªç§æ–¹æ³•æœ€ä½³ã€‚ä¸ºæ­¤ï¼ŒåŸå§‹è®ºæ–‡åœ¨è®ºæ–‡çš„ä»“åº“ä¸­åˆ†äº«äº†å®éªŒç»“æœ [è¿™é‡Œ](https://github.com/potsawee/selfcheckgpt/tree/main?ref=content.whylabs.ai#experimental-results)ï¼ŒåŒ…æ‹¬äº†åœ¨è¿™ç¯‡åšå®¢ä¸­æœªè®¨è®ºçš„é™„åŠ ç‰ˆæœ¬ã€‚æˆ‘ä¸ä¼šè¯¦ç»†è®¨è®ºç»“æœï¼Œä½†æ ¹æ®æ‰€æœ‰ä¸‰ä¸ªæŒ‡æ ‡ï¼ˆNonFactã€Factual
    å’Œ Rankingï¼‰ï¼ŒLLM-Prompt æ˜¯è¡¨ç°æœ€å¥½çš„ç‰ˆæœ¬ï¼Œå…¶æ¬¡æ˜¯ NLI ç‰ˆæœ¬ã€‚BERTScore ç‰ˆæœ¬æ˜æ˜¾æ¯”å‰©ä½™ä¸¤ä¸ªç‰ˆæœ¬è¦å·®ã€‚æˆ‘ä»¬çš„ç®€å•ç¤ºä¾‹ä¼¼ä¹ç¬¦åˆå…±äº«ç»“æœçš„æ–¹å‘ã€‚
- en: Conclusion
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: We hope this blog post helped explain the hallucination problem and provides
    one possible solution for hallucination detection. This is a relatively new problem,
    and itâ€™s good to see that efforts are being made towards solving it.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›è¿™ç¯‡åšå®¢æ–‡ç« æœ‰åŠ©äºè§£é‡Šå¹»è§‰é—®é¢˜ï¼Œå¹¶æä¾›ä¸€ç§å¯èƒ½çš„å¹»è§‰æ£€æµ‹è§£å†³æ–¹æ¡ˆã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å¯¹è¾ƒæ–°çš„é—®é¢˜ï¼Œå¾ˆé«˜å…´çœ‹åˆ°å·²ç»æœ‰åŠªåŠ›åœ¨è§£å†³å®ƒã€‚
- en: 'The discussed approach has the advantage of not requiring external context
    (zero-resource) and also not requiring the LLMâ€™s output probability distribution
    (black-box). However, this comes with a cost: in addition to the original response,
    we need to generate extra samples to perform the consistency check, increasing
    latency and cost. The consistency check will also require additional computation
    and language models for encoding the responses into embeddings, performing textual
    entailment, or querying the LLM, depending on the chosen method.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è®¨è®ºçš„æ–¹æ³•å…·æœ‰ä¸éœ€è¦å¤–éƒ¨ä¸Šä¸‹æ–‡ï¼ˆé›¶èµ„æºï¼‰å’Œä¸éœ€è¦LLMçš„è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒï¼ˆé»‘ç®±ï¼‰çš„ä¼˜ç‚¹ã€‚ç„¶è€Œï¼Œè¿™ä¹Ÿå¸¦æ¥äº†æˆæœ¬ï¼šé™¤äº†åŸå§‹å“åº”å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ç”Ÿæˆé¢å¤–çš„æ ·æœ¬æ¥æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼Œä»è€Œå¢åŠ äº†å»¶è¿Ÿå’Œæˆæœ¬ã€‚ä¸€è‡´æ€§æ£€æŸ¥è¿˜éœ€è¦é¢å¤–çš„è®¡ç®—å’Œè¯­è¨€æ¨¡å‹æ¥å°†å“åº”ç¼–ç ä¸ºåµŒå…¥ï¼Œè¿›è¡Œæ–‡æœ¬è•´å«ï¼Œæˆ–æŸ¥è¯¢LLMï¼Œè¿™å–å†³äºæ‰€é€‰çš„æ–¹æ³•ã€‚
- en: References
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] â€” Manakul, Potsawee, Adian Liusie, and Mark JF Gales. â€œSelfcheckgpt: Zero-resource
    black-box hallucination detection for generative large language models.â€ arXiv
    preprint arXiv:2303.08896 (2023).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] â€” Manakul, Potsawee, Adian Liusie, å’Œ Mark JF Galesã€‚â€œSelfcheckgptï¼šç”¨äºç”Ÿæˆå¤§å‹è¯­è¨€æ¨¡å‹çš„é›¶èµ„æºé»‘ç®±å¹»è§‰æ£€æµ‹ã€‚â€
    arXivé¢„å°æœ¬ arXiv:2303.08896 (2023)ã€‚'
- en: '[2] â€” JI, Ziwei et al. Survey of hallucination in natural language generation.
    **ACM Computing Surveys**, v. 55, n. 12, p. 1â€“38, 2023.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] â€” JI, Ziwei ç­‰äººã€‚ã€Šè‡ªç„¶è¯­è¨€ç”Ÿæˆä¸­çš„å¹»è§‰è°ƒæŸ¥ã€‹ã€‚**ACMè®¡ç®—è°ƒæŸ¥**ï¼Œç¬¬55å·ï¼Œç¬¬12æœŸï¼Œé¡µç 1â€“38ï¼Œ2023å¹´ã€‚'
- en: '[3] â€” ZHANG, Tianyi et al. Bertscore: Evaluating text generation with bert.
    **arXiv preprint arXiv:1904.09675**, 2019.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] â€” ZHANG, Tianyi ç­‰äººã€‚Bertscoreï¼šä½¿ç”¨bertè¯„ä¼°æ–‡æœ¬ç”Ÿæˆã€‚**arXivé¢„å°æœ¬ arXiv:1904.09675**ï¼Œ2019å¹´ã€‚'
- en: '[4] â€” [https://nlpprogress.com/english/natural_language_inference.html](https://nlpprogress.com/english/natural_language_inference.html?ref=content.whylabs.ai)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] â€” [https://nlpprogress.com/english/natural_language_inference.html](https://nlpprogress.com/english/natural_language_inference.html?ref=content.whylabs.ai)'
- en: '[5] â€” Williams, A., Nangia, N., & Bowman, S. R. (2017). A broad-coverage challenge
    corpus for sentence understanding through inference. arXiv preprint arXiv:1704.05426.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[5] â€” Williams, A., Nangia, N., & Bowman, S. R. (2017)ã€‚ç”¨äºé€šè¿‡æ¨ç†ç†è§£å¥å­çš„å¹¿æ³›è¦†ç›–æŒ‘æˆ˜è¯­æ–™åº“ã€‚arXivé¢„å°æœ¬
    arXiv:1704.05426ã€‚'
- en: '[6] â€” [https://github.com/potsawee/selfcheckgpt/tree/main#selfcheckgpt-usage-nli](https://github.com/potsawee/selfcheckgpt/tree/main#selfcheckgpt-usage-nli)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[6] â€” [https://github.com/potsawee/selfcheckgpt/tree/main#selfcheckgpt-usage-nli](https://github.com/potsawee/selfcheckgpt/tree/main#selfcheckgpt-usage-nli)'
