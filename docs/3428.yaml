- en: Mastering Batch Data Processing with Versatile Data Kit (VDK)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mastering-batch-data-processing-with-versatile-data-kit-vdk-e631454819aa?source=collection_archive---------14-----------------------#2023-11-17](https://towardsdatascience.com/mastering-batch-data-processing-with-versatile-data-kit-vdk-e631454819aa?source=collection_archive---------14-----------------------#2023-11-17)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Data Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A tutorial on how to use VDK to perform batch data processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://alod83.medium.com/?source=post_page-----e631454819aa--------------------------------)[![Angelica
    Lo Duca](../Images/45aa2e2e504bb3af6d3b8009dc6f030e.png)](https://alod83.medium.com/?source=post_page-----e631454819aa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e631454819aa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e631454819aa--------------------------------)
    [Angelica Lo Duca](https://alod83.medium.com/?source=post_page-----e631454819aa--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff8bc34d63aee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-batch-data-processing-with-versatile-data-kit-vdk-e631454819aa&user=Angelica+Lo+Duca&userId=f8bc34d63aee&source=post_page-f8bc34d63aee----e631454819aa---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e631454819aa--------------------------------)
    ·5 min read·Nov 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe631454819aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-batch-data-processing-with-versatile-data-kit-vdk-e631454819aa&user=Angelica+Lo+Duca&userId=f8bc34d63aee&source=-----e631454819aa---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe631454819aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-batch-data-processing-with-versatile-data-kit-vdk-e631454819aa&source=-----e631454819aa---------------------bookmark_footer-----------)![](../Images/e423c3ada05189d8098c2d2cc2d01a63.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Mika Baumeister](https://unsplash.com/@mbaumi?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[Versatile Data Ki](https://github.com/vmware/versatile-data-kit)t (VDK) is
    an open-source data ingestion and processing framework designed to simplify data
    management complexities. While VDK can handle various data integration tasks,
    including real-time streaming, this article will focus on how to use it in batch
    data processing.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This article covers:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Batch Data Processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and Managing Batch Processing Pipelines in VDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring Batch Data Processing in VDK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1 Introducing Batch Data Processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Batch data processing is a method for processing large volumes of data at specified
    intervals. Batch data must be:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Time-independent**: data doesn’t require immediate processing and is typically
    not sensitive to real-time requirements. Unlike streaming data, which needs instant
    processing, batch data can be processed at scheduled intervals or when resources
    become available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Splittable in chunks**: instead of processing an entire dataset in a single,
    resource-intensive operation, batch data can be divided into smaller, more manageable
    segments. These segments can then be processed sequentially or in parallel, depending
    on the capabilities of the data processing system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, batch data can be processed offline, meaning it doesn’t require
    a constant connection to data sources or external services. This characteristic
    is precious when data sources may be intermittent or temporarily unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: 'ELT (Extract, Load, Transform) is a typical use case for batch data processing.
    ELT comprises three main phases:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Extract (E)**: data is extracted from multiple sources in different formats,
    both structured and unstructured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Load (L)**: data is loaded into a target destination, such as a data warehouse.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transform (T)**: the extracted data typically requires preliminary processing,
    such as cleaning, harmonization, and transformations into a common format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that you have learned what batch data processing is, let’s move on to the
    next step: creating and managing batch processing pipelines in VDK.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Creating and Managing Batch Processing Pipelines in VDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: VDK adopts a component-based approach, enabling you to build data processing
    pipelines quickly. For an introduction to VDK, refer to my previous article, [An
    Overview of Versatile Data Kit](/an-overview-of-versatile-data-kit-a812cfb26de7).
    This article assumes that you have already installed VDK on your computer.
  prefs: []
  type: TYPE_NORMAL
- en: To explain how the batch processing pipeline works in VDK, we consider a scenario
    where you must perform an ELT task.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you want to ingest and process, in VDK, Vincent Van Gogh’s paintings
    available in [Europeana](https://www.europeana.eu/en), a well-known European aggregator
    for cultural heritage. Europeana provides all cultural heritage objects through
    its public [REST API](https://pro.europeana.eu/page/intro#access). Regarding Vincent
    Van Gogh, Europeana provides more than 700 works.
  prefs: []
  type: TYPE_NORMAL
- en: The following figure shows the steps for batch data processing in this scenario.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/37c5458a0e1cecc95842ac62cc06de5c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: Let’s investigate each point separately. You can find the complete code to implement
    this scenario in the [VDK GitHub repository](https://github.com/vmware/versatile-data-kit/tree/main/examples/online-exhibition).
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Extract and Load
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This phase includes VDK jobs calling the Europeana REST API to extract raw
    data. Specifically, it defines three jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: job1 — delete the existing table (if any)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: job2 — create a new table
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: job3 — ingest table values directly from the REST API.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This example requires an active Internet connection to work correctly to access
    the Europeana REST API. This operation is a batch process because it downloads
    data only once and does not require streamlining.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll store the extracted data in a table. The difficulty of this task is building
    a mapping between the REST API, which is done in job3.
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing job3 involves simply writing the Python code to perform this mapping,
    but instead of saving the extracted file into a local file, we call a VDK function
    (`job_input.send_tabular_data_for_ingestion`) to save the file to VDK, as shown
    in the following snippet of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: For the complete code, refer to the [example in GitHub](https://github.com/vmware/versatile-data-kit/blob/main/examples/online-exhibition/online-exhibition/03_ingest_table_assets.py).
    Please note that you need a free API key to download data from Europeana.
  prefs: []
  type: TYPE_NORMAL
- en: The output produced during the extraction phase is a table containing the raw
    values.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Transform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This phase involves cleaning data and extracting only relevant information.
    We can implement the related jobs in VDK through two jobs:'
  prefs: []
  type: TYPE_NORMAL
- en: job4 — delete the existing table (if any)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: job5 — create the cleaned table.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Job5 simply involves writing an SQL query, as shown in the following snippet
    of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Running this job in VDK will produce another table named `cleaned_asset` containing
    the processed values. Finally, we are ready to use the cleaned data somewhere.
    In our case, we can build a Web app that shows the extracted paintings. You can
    find the complete code to perform this task in the [VDK GitHub repository](https://github.com/vmware/versatile-data-kit/blob/main/examples/online-exhibition/view.py).
  prefs: []
  type: TYPE_NORMAL
- en: 3 Monitoring Batch Data Processing in VDK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: VDK provides the VDK UI, a graphical user interface to monitor data jobs. To
    install VDK UI, follow the official VDK video at [this link](https://www.youtube.com/watch?v=DLRGCCGUp0U).
    The following figure shows a snapshot of VDK UI.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec6fe077b8c94f069f56198ef1db996b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main pages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Explore**: This page enables you to explore data jobs, such as the job execution
    success rate, jobs with failed executions in the last 24 hours, and the most failed
    executions in the last 24 hours.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manage**: This page gives more job details. You can order jobs by column,
    search multiple parameters, filter by some of the columns, view the source for
    the specific job, add other columns, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Watch the following official VDK video to learn how to use VDK UI.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You have just learned how to implement batch data processing
    in VDK! It only requires ingesting raw data, manipulating it, and, finally, using
    it for your purposes! You can find many other examples in the [VDK GitHub repository](https://github.com/vmware/versatile-data-kit/tree/main/examples).
  prefs: []
  type: TYPE_NORMAL
- en: Stay up-to-date with the latest data processing developments and best practices
    in [VDK](https://github.com/vmware/versatile-data-kit/tree/main). Keep exploring
    and refining your expertise!
  prefs: []
  type: TYPE_NORMAL
- en: Other articles you may be interested in…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](/an-overview-of-versatile-data-kit-a812cfb26de7?source=post_page-----e631454819aa--------------------------------)
    [## An Overview of Versatile Data Kit'
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with the Versatile Data Kit, a framework which makes the Data
    Engineer work more efficient
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/an-overview-of-versatile-data-kit-a812cfb26de7?source=post_page-----e631454819aa--------------------------------)
    [](/handling-missing-values-in-versatile-data-kit-bb4f2a907b9c?source=post_page-----e631454819aa--------------------------------)
    [## Handling Missing Values in Versatile Data Kit
  prefs: []
  type: TYPE_NORMAL
- en: A tutorial on how to build data pipelines using VDK to handle missing values
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'towardsdatascience.com](/handling-missing-values-in-versatile-data-kit-bb4f2a907b9c?source=post_page-----e631454819aa--------------------------------)
    [](/from-raw-data-to-a-cleaned-database-a-deep-dive-into-versatile-data-kit-ab5fd992a02e?source=post_page-----e631454819aa--------------------------------)
    [## From Raw Data to a Cleaned Database: A Deep Dive into Versatile Data Kit'
  prefs: []
  type: TYPE_NORMAL
- en: A complete example using the Versatile Data Kit (a Framework recently released
    by VMware) and Trino DB
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/from-raw-data-to-a-cleaned-database-a-deep-dive-into-versatile-data-kit-ab5fd992a02e?source=post_page-----e631454819aa--------------------------------)
  prefs: []
  type: TYPE_NORMAL
