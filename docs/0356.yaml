- en: Dockerizing Apache Zeppelin and Apache Spark for Easy Deployment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker 化 Apache Zeppelin 和 Apache Spark 以便捷部署
- en: 原文：[https://towardsdatascience.com/dockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245?source=collection_archive---------8-----------------------#2023-01-24](https://towardsdatascience.com/dockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245?source=collection_archive---------8-----------------------#2023-01-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/dockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245?source=collection_archive---------8-----------------------#2023-01-24](https://towardsdatascience.com/dockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245?source=collection_archive---------8-----------------------#2023-01-24)
- en: Learn How To Build a Portable and Scalable Data Analysis Environment with Docker-Compose
    And Volumes.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解如何使用 Docker-Compose 和卷构建一个便携且可扩展的数据分析环境。
- en: '[](https://anbento4.medium.com/?source=post_page-----1814d0c1c245--------------------------------)[![Antonello
    Benedetto](../Images/bf802bb46dce03dd3bd4e17c1dffe5b7.png)](https://anbento4.medium.com/?source=post_page-----1814d0c1c245--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1814d0c1c245--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1814d0c1c245--------------------------------)
    [Antonello Benedetto](https://anbento4.medium.com/?source=post_page-----1814d0c1c245--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://anbento4.medium.com/?source=post_page-----1814d0c1c245--------------------------------)[![Antonello
    Benedetto](../Images/bf802bb46dce03dd3bd4e17c1dffe5b7.png)](https://anbento4.medium.com/?source=post_page-----1814d0c1c245--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1814d0c1c245--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1814d0c1c245--------------------------------)
    [Antonello Benedetto](https://anbento4.medium.com/?source=post_page-----1814d0c1c245--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2d93b58a0f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245&user=Antonello+Benedetto&userId=2d93b58a0f8a&source=post_page-2d93b58a0f8a----1814d0c1c245---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1814d0c1c245--------------------------------)
    ·9 min read·Jan 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1814d0c1c245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245&user=Antonello+Benedetto&userId=2d93b58a0f8a&source=-----1814d0c1c245---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2d93b58a0f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245&user=Antonello+Benedetto&userId=2d93b58a0f8a&source=post_page-2d93b58a0f8a----1814d0c1c245---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1814d0c1c245--------------------------------)
    ·9 分钟阅读·2023年1月24日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1814d0c1c245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245&user=Antonello+Benedetto&userId=2d93b58a0f8a&source=-----1814d0c1c245---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1814d0c1c245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245&source=-----1814d0c1c245---------------------bookmark_footer-----------)![](../Images/dcd662fabf5ce0f263fe35015b17886d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1814d0c1c245&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdockerizing-apache-zeppelin-and-apache-spark-for-easy-deployment-1814d0c1c245&source=-----1814d0c1c245---------------------bookmark_footer-----------)![](../Images/dcd662fabf5ce0f263fe35015b17886d.png)'
- en: Photo by [Tom Fisk](https://www.pexels.com/@tomfisk/) On [Pexels](https://www.pexels.com/photo/birds-eye-view-photo-of-freight-containers-2226458/)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Tom Fisk](https://www.pexels.com/@tomfisk/) 提供，发布在 [Pexels](https://www.pexels.com/photo/birds-eye-view-photo-of-freight-containers-2226458/)
- en: On-Demand Courses | Recommended
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 按需课程 | 推荐
- en: '*A few of my readers have contacted me asking for on-demand courses to learn
    more about* ***Apache Spark with Python****. These are 3 great resources I would
    recommend:*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*一些读者联系我，询问有关* ***使用 Python 的 Apache Spark**** 的按需课程。这些是我推荐的 3 个优秀资源：*'
- en: '[**Data Streaming With Apache Kafka & Apache Spark Nano-Degree (UDACITY)**](https://imp.i115008.net/zaX10r)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**使用 Apache Kafka 和 Apache Spark 的数据流处理与 Apache Spark 纳米学位（UDACITY）**](https://imp.i115008.net/zaX10r)'
- en: '[**Data Engineering Nano-Degree (UDACITY)**](https://imp.i115008.net/zaX10r)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据工程纳米学位 (UDACITY)**](https://imp.i115008.net/zaX10r)'
- en: '[**Spark And Python For Big Data With PySpark (UDEMY)**](https://click.linksynergy.com/deeplink?id=533LxfDBSaM&mid=39197&murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fspark-and-python-for-big-data-with-pyspark%2F)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**大数据与PySpark的Spark和Python (UDEMY)**](https://click.linksynergy.com/deeplink?id=533LxfDBSaM&mid=39197&murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fspark-and-python-for-big-data-with-pyspark%2F)'
- en: '*Not a Medium member yet? Consider signing up with my* [*referral link*](https://anbento4.medium.com/membership)
    *to gain access to everything Medium has to offer for as little as $5 a month!*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*还不是Medium会员？考虑通过我的* [*推荐链接*](https://anbento4.medium.com/membership) *注册，以最低每月$5的费用获取Medium的所有服务！*'
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Docker has revolutionised the way we deploy and manage our applications and
    data analysis tools. It allows for effortless scaling, and the ability to easily
    customise the services to suit specific needs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Docker彻底改变了我们部署和管理应用程序以及数据分析工具的方式。它允许轻松扩展，并能轻松定制服务以满足特定需求。
- en: In this tutorial, I will show you how to quickly deploy Apache Zeppelin and
    Apache Spark using a `docker-compose.yaml` file and take advantage of volumes
    to manage data dependencies among services.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我将展示如何使用`docker-compose.yaml`文件快速部署Apache Zeppelin和Apache Spark，并利用卷来管理服务之间的数据依赖。
