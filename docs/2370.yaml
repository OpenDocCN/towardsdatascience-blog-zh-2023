- en: 'ChatGPT Moderation API: Input/Output Control'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/chatgpt-moderation-api-input-output-artificial-intelligence-chatgpt3-data-4754389ec9c8?source=collection_archive---------1-----------------------#2023-07-23](https://towardsdatascience.com/chatgpt-moderation-api-input-output-artificial-intelligence-chatgpt3-data-4754389ec9c8?source=collection_archive---------1-----------------------#2023-07-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Using the OpenAI’s Moderation Endpoint for Responsible AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@andvalenzuela?source=post_page-----4754389ec9c8--------------------------------)[![Andrea
    Valenzuela](../Images/ddfc1534af92413fd91076f826cc49b6.png)](https://medium.com/@andvalenzuela?source=post_page-----4754389ec9c8--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4754389ec9c8--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4754389ec9c8--------------------------------)
    [Andrea Valenzuela](https://medium.com/@andvalenzuela?source=post_page-----4754389ec9c8--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa6f3f1654c3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-moderation-api-input-output-artificial-intelligence-chatgpt3-data-4754389ec9c8&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=post_page-a6f3f1654c3----4754389ec9c8---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4754389ec9c8--------------------------------)
    ·9 min read·Jul 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4754389ec9c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-moderation-api-input-output-artificial-intelligence-chatgpt3-data-4754389ec9c8&user=Andrea+Valenzuela&userId=a6f3f1654c3&source=-----4754389ec9c8---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4754389ec9c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchatgpt-moderation-api-input-output-artificial-intelligence-chatgpt3-data-4754389ec9c8&source=-----4754389ec9c8---------------------bookmark_footer-----------)![](../Images/733cc16aa1f0f391b10378392a4daae2.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Self-made gif.
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) have undoubtedly transformed the way we interact
    with technology. ChatGPT, among the prominent LLMs, has proven to be an invaluable
    tool, serving users with a vast array of information and helpful responses. However,
    like any technology, **ChatGPT is not without its limitations**.
  prefs: []
  type: TYPE_NORMAL
- en: Recent discussions have brought to light an important concern — **the potential
    for ChatGPT to generate inappropriate or biased responses**. This issue stems
    from its training data, which comprises the collective writings of individuals
    across diverse backgrounds and eras. **While this diversity enriches the model’s
    understanding, it also brings with it the biases and prejudices prevalent in the
    real world**.
  prefs: []
  type: TYPE_NORMAL
- en: As a result, some responses generated by ChatGPT may reflect these biases. *But
    let’s be fair*, **inappropriate responses can be triggered by inappropriate user
    queries**.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will explore the importance of actively moderating both
    the model’s inputs and outputs when building LLM-powered applications. To do so,
    we will use the so-called ***OpenAI Moderation API* that helps identify inappropriate
    content and take action accordingly**.
  prefs: []
  type: TYPE_NORMAL
