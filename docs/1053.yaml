- en: 'Intro to TorchData: A Walkthrough with Conceptual Captions 3M'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/intro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41?source=collection_archive---------10-----------------------#2023-03-22](https://towardsdatascience.com/intro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41?source=collection_archive---------10-----------------------#2023-03-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how to use TorchData and DataPipes to efficiently stream large datasets
    like Conceptual Captions 3M.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)[![Frank
    Odom](../Images/31a2789d5ff0e5299fa623c6668563e3.png)](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)[](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)
    [Frank Odom](https://frank-odom.medium.com/?source=post_page-----928144b5bc41--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f77d545fa4e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&user=Frank+Odom&userId=6f77d545fa4e&source=post_page-6f77d545fa4e----928144b5bc41---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----928144b5bc41--------------------------------)
    ·8 min read·Mar 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F928144b5bc41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&user=Frank+Odom&userId=6f77d545fa4e&source=-----928144b5bc41---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F928144b5bc41&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintro-to-torchdata-a-walkthrough-with-conceptual-captions-3m-928144b5bc41&source=-----928144b5bc41---------------------bookmark_footer-----------)![](../Images/0de5ae5a50936751b7539aca8dd3ab1c.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Quinten de Graaf](https://unsplash.com/@quinten149?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When working with large datasets, especially in deep learning, it can be impractical
    to download them locally for training. Instead, streaming the dataset directly
    during training can be a more efficient approach. In this tutorial, we will introduce
    the TorchData library and demonstrate how to use it to stream the Conceptual Captions
    3M dataset, which consists of 3 million images with their corresponding captions.
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** Conceptual Captions is freely available under an open-source license.
    For more information, see the [LICENSE](https://github.com/google-research-datasets/conceptual-captions/blob/master/LICENSE)
    from the [official GitHub repo](https://github.com/google-research-datasets/conceptual-captions).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ll start by providing a brief overview of TorchData and its main components.
    Then, we’ll walk through the process of setting up our data pipeline for the Conceptual
    Captions 3M dataset, and finally, we’ll show an example of how to use the pipeline
    to stream the dataset in real-time.
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial is designed to be accessible to absolute beginners, so we’ll take
    the time to explain each concept and code snippet in detail. Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7f3d6898c60f6b7bc4a811319008af34.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Braden Collum](https://unsplash.com/@bradencollum?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Intro to TorchData
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'TorchData is a library of common data loading methods for easily constructing
    flexible and performant data pipelines. An excerpt from the [TorchData README](https://github.com/pytorch/data#torchdata):'
  prefs: []
  type: TYPE_NORMAL
- en: It introduces composable Iterable-style and Map-style building blocks called
    DataPipes that work well out of the box with PyTorch’s `DataLoader`. These built-in
    DataPipes provide functionalities for loading files (from local or cloud storage),
    parsing, caching, transforming, filtering, and many more utilities.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: DataPipes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/204ac73ab96a4a66ce5bffec893180f6.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [T K](https://unsplash.com/@realaxer?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: At the core of TorchData are DataPipes, which can be thought of as composable
    building blocks for data pipelines. DataPipes are simply renamed and repurposed
    PyTorch `Dataset`s designed for composed usage. They take in an access function
    over Python data structures, `__iter__` for `IterDataPipes` and `__getitem__`
    for `MapDataPipes`, and return a new access function with a slight transformation
    applied.
  prefs: []
  type: TYPE_NORMAL
- en: By chaining together DataPipes, we can create sophisticated data pipelines with
    streamed operation as a first-class citizen. This enables us to handle large datasets
    efficiently and reduce the need for local storage.
  prefs: []
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start with an example to get familiar with the basic concepts. Let’s
    create a basic DataPipe that takes an iterable of integers and doubles their values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This code defines a custom `DoublingDataPipe` that takes an iterable source
    of data (in our case, a list of integers) and yields each item from the source
    data multiplied by 2\. When we run this code, we should see the doubled values
    printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: TorchData also provides lots of built-in pipeline methods, which could have
    made this example much more concise.
  prefs: []
  type: TYPE_NORMAL
- en: The `.map()`, `.filter()`, `.shuffle()`, and `.chain()` methods, to name a few,
    enable us to quickly build powerful and flexible data pipelines without having
    to write custom DataPipes for every operation. They can be applied directly to
    an `IterDataPipe` to perform common data processing tasks, such as applying transformations,
    filtering data, randomizing order, and concatenating multiple DataPipes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore a few examples. We’ll use the `source_data` list from our previous
    example as the input for our DataPipes.
  prefs: []
  type: TYPE_NORMAL
- en: '`.map()`: Applies a function to each element in the DataPipe.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The entire `DoublingDataPipe` example from earlier is reproduced here in a
    single line of code: `data_pipe.map(lambda x: x * 2)`.'
  prefs: []
  type: TYPE_NORMAL
- en: '2\. `.filter()`: Filters the elements in the DataPipe based on a condition.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '3\. `.shuffle()`: Randomizes the order of elements in the DataPipe.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '4\. `.chain()`: Concatenates two or more DataPipes.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Setting Up Conceptual Captions 3M
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/c8bc5e53a8a2eec26b42be6af9b5e661.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [John Schnobrich](https://unsplash.com/@johnschno?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll walk through the process of setting up our data pipeline
    for the Conceptual Captions 3M dataset. This dataset consists of 3 million images
    and their corresponding captions, making it impractical to download locally for
    training. Instead, we’ll use TorchData to stream the dataset directly during training.
  prefs: []
  type: TYPE_NORMAL
- en: Dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before diving into the code, let’s first install the required dependencies
    for this tutorial. You’ll need the following Python packages:'
  prefs: []
  type: TYPE_NORMAL
- en: torchdata
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: tqdm (for displaying progress bars)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: aiohttp (for asynchronous HTTP requests)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pillow (for handling images)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can install them using pip:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Async Helper Functions for Asynchronous Image Download
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since we’ll be streaming images from remote URLs, we need a way to efficiently
    download them in parallel. We’ll use the `aiohttp` library to make asynchronous
    HTTP requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s create a helper function `async_get_image` that takes an `aiohttp.ClientSession`
    and a URL as input and returns the downloaded image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Next, we’ll create another helper function `async_batch_get_images` that takes
    a sequence of URLs, and returns a list of downloaded images. It uses `aiohttp.ClientSession`to
    run multiple requests in parallel with minimal overhead, which is crucial for
    performance when fetching a large number of images from remote URLs in real-time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: ParallelSampleLoader DataPipe
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/16b48083c503e4759a6046809a906360.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Tom Strecker](https://unsplash.com/@tom_stre?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our helper functions for downloading images, let’s create a
    custom `ParallelSampleLoader` DataPipe that takes an `IterDataPipe` of tuples
    containing image URLs and captions, and returns an iterator over the downloaded
    images and their corresponding captions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Putting It All Together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we’ll create a function `conceptual_captions_3m` that takes a `split`
    argument (either "train" or "val") and returns an `IterDataPipe` of tuples containing
    the downloaded images and their corresponding captions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Conceptual Captions 3M
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With our data pipeline set up, we can now use it to stream the Conceptual Captions
    3M dataset in real-time. In this example, we’ll use the `conceptual_captions_3m`
    function to create an `IterDataPipe` for the training split and iterate over the
    dataset, printing out the first 10 captions and displaying their corresponding
    image sizes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Here’s another simple example to benchmark how quickly images can be loaded
    through this pipeline. We use the `tqdm` library to create a progress bar, which
    displays the number of samples iterated per second.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Download speeds are **very** dependent on your internet connection. Virtual
    machines from most cloud providers have extremely fast network connections, which
    makes them ideal for using DataPipes. I ran the benchmark above on my Google Cloud
    VM, which reaches download speeds of roughly 120 images per second. For small-scale
    ML training using a single GPU-enabled machine, that should be more than enough
    speed. (Few ML models train at faster than 120 images/sec, unless you’re using
    more expensive GPU hardware.)
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TorchData offers a powerful and flexible way to handle large datasets by providing
    composable DataPipes and built-in pipeline methods. By utilizing these tools,
    you can effectively stream and process your data on-the-fly without the need for
    downloading data to local disk beforehand. This approach not only saves time and
    storage resources, but enables a more seamless integration of the dataset into
    your project. All of the dataset logic is now codified in your Python project,
    and does not require detailed setup instructions in your README (common in many
    projects). By encapsulating the pipeline within your code, TorchData allows for
    better reproducibility and portability, making it an invaluable tool for modern
    machine learning projects dealing with large datasets.
  prefs: []
  type: TYPE_NORMAL
- en: With this tutorial, you should now have a better understanding of how to use
    the TorchData library to create a data pipeline for streaming large datasets like
    Conceptual Captions 3M. This approach can be applied to other large datasets,
    and it can be easily adapted for various data processing and augmentation tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7bd75bdd41f51055eebf971fa0caee84.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Vasily Koloda](https://unsplash.com/@napr0tiv?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
