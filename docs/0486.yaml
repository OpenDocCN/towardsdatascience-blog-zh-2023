- en: 'Your First Recommendation System: From Data Preparation to ML Debugging and
    Improvements Assessment'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/your-first-recommendation-system-from-data-preparation-to-ml-debugging-and-improvements-assessment-eb628573436?source=collection_archive---------8-----------------------#2023-02-02](https://towardsdatascience.com/your-first-recommendation-system-from-data-preparation-to-ml-debugging-and-improvements-assessment-eb628573436?source=collection_archive---------8-----------------------#2023-02-02)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Resolve your issues, save time, and avoid mistakes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alexanderchaptykov?source=post_page-----eb628573436--------------------------------)[![Alexander
    Chaptykov](../Images/45dba3d647e069ca2f6df13a1d6d15b8.png)](https://medium.com/@alexanderchaptykov?source=post_page-----eb628573436--------------------------------)[](https://towardsdatascience.com/?source=post_page-----eb628573436--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----eb628573436--------------------------------)
    [Alexander Chaptykov](https://medium.com/@alexanderchaptykov?source=post_page-----eb628573436--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fac86875480da&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-recommendation-system-from-data-preparation-to-ml-debugging-and-improvements-assessment-eb628573436&user=Alexander+Chaptykov&userId=ac86875480da&source=post_page-ac86875480da----eb628573436---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----eb628573436--------------------------------)
    ·12 min read·Feb 2, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Feb628573436&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-recommendation-system-from-data-preparation-to-ml-debugging-and-improvements-assessment-eb628573436&user=Alexander+Chaptykov&userId=ac86875480da&source=-----eb628573436---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Feb628573436&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fyour-first-recommendation-system-from-data-preparation-to-ml-debugging-and-improvements-assessment-eb628573436&source=-----eb628573436---------------------bookmark_footer-----------)![](../Images/c36e53a896f0ab94c96b15c75e4db4d5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by [Vska](https://ru.freepik.com/author/vska) from [freepik.com](https://ru.freepik.com/premium-vector/conceptual-technology-illustration-of-artificial-intelligence_34375876.htm)
  prefs: []
  type: TYPE_NORMAL
- en: So you’ve begun to develop your first production recommendation system, and
    although you have experience in programming and ML, you are bombarded with an
    enormous volume of new information, like model selection, metrics selection, inference
    problems and quality assurance.
  prefs: []
  type: TYPE_NORMAL
- en: We cover steps for creating the first working version of an ML model, including
    data processing, model selection, metrics selection, ML debugging, results interpretation
    and evaluation of improvements.
  prefs: []
  type: TYPE_NORMAL
- en: The code of the article is [here](https://github.com/AlexanderChaptykov/personalize),
    it can serve as a starting point for your own work. The file [rec_sys.ipynb](https://github.com/AlexanderChaptykov/personalize/blob/main/rec_sys.ipynb)
    contains a step-by-step guide.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start, we need a minimum available dataset consisting of 3 entities: `user`,
    `item`, `rating`. Each record of this dataset will tell us about user''s interaction
    with an item. For this article we have chosen a dataset [MovieLens](https://files.grouplens.org/datasets/movielens/ml-latest-small.zip)
    [1](used with permission) with 100k records containing 943 unique users and 1682
    movies. For the this dataset `user` - `UserId`, `item` - `MovieId` , `rating`
    - `Rating` .'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a65e76de4164d32ff9e461aff3fad0f6.png)'
  prefs: []
  type: TYPE_IMG
- en: MovieLens also contains a metadata for each movie. This has information by genre.
    We will need this to interpret the predictions.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c0ceab8595b089d83f2bbfc2eaf984e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here there are the special preprocessing steps for recommendation system. I
    want to skip obvious steps like drop NaN elements, drop duplicate elements, data
    cleaning.
  prefs: []
  type: TYPE_NORMAL
- en: Rating generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we don’t have a rating, then create a rating column with the value 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Also if the rating is not explicit it can be created by various aggregating
    functions, for example, based on the number of interactions, duration, etc.
  prefs: []
  type: TYPE_NORMAL
- en: '**Entity encoding** If you have objects in the item and user fields, these
    fields need to be converted to a numeric format. A great way to accomplish this
    is to use **LabelEncoder.**'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Sparsity index
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Sparsity index must be lowered for quality model training.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4e49bc8dded3b277e5a6f9c19a1b018d.png)'
  prefs: []
  type: TYPE_IMG
- en: What do the high values of this index tell us? It means that we have a lot of
    users who have not watched many movies, and we also have movies that have a low
    audience. The more inactive users and unpopular movies we have, the higher this
    level is.
  prefs: []
  type: TYPE_NORMAL
- en: This situation happens most often when, for example, when number of all users
    is suddenly increasing. Or we decided to drastically increase our movie library,
    and we have absolutely no views for new movies.
  prefs: []
  type: TYPE_NORMAL
- en: Reducing sparsity is critical for training. Let’s say you’ve loaded your data
    and are trying to train a model, and you’re getting extremely low metrics. You
    don’t need to start searching for special hyperparameters, or looking for other
    better models. Start by checking the sparsity index.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can see from the graph that reducing this index by almost 2% has a very
    positive effect on metrics
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/9e9a0ad340376e799f070ef0269195bd.png)![](../Images/3a674f29fad2c0d7b8fe0d43c564d027.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The graph shows that 81% of users are inactive (they have watched less than
    20 movies). They need to be removed. And this function will help us with this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: So we had to remove some users and movies, but this will allow us to train the
    model better. It is desirable to reduce the sparsity level carefully and choose
    it for each dataset based on the situation. In my experience, a sparsity-index
    of about 98% is already sufficient for training.
  prefs: []
  type: TYPE_NORMAL
- en: Selecting metrics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are good articles detailing popular metrics for recommender systems.
    For example, [“Recommender Systems: Machine Learning Metrics and Business Metrics”](https://neptune.ai/blog/recommender-systems-metrics)
    by Zuzanna Deutschman and [“Automatic Evaluation of Recommendation Systems: Coverage,
    Novelty and Diversity”](https://medium.com/mlearning-ai/automatic-evaluation-of-recommendation-systems-coverage-novelty-and-diversity-cc140330d3e7)
    by Zahra Ahmad. For this article I decided to focus on 4 metrics that can serve
    as a minimum set to get you started.'
  prefs: []
  type: TYPE_NORMAL
- en: Precision@k
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*P = (relevant elements) / k*'
  prefs: []
  type: TYPE_NORMAL
- en: This is a simple metric that does not take into account the order of predictions,
    so it will have higher values than using MAP. This metric is also sensitive to
    changes in the model, which can be useful for model monitoring and evaluation.
    It is easier to interpret, so we can include it in our list of metrics.
  prefs: []
  type: TYPE_NORMAL
- en: MAP (Mean Average precision)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This metric, unlike the previous one, is important for the order of predictions,
    the closer to the top of the list of recommendations we are wrong, the greater
    the penalty.
  prefs: []
  type: TYPE_NORMAL
- en: Coverage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Coverage = num of uniq items in recommendations / all uniq items*'
  prefs: []
  type: TYPE_NORMAL
- en: The metric allows you to see percentage of movies used by the recommendation
    system. This is usually very important for businesses to make sure that the content
    (in this case, movies) they have on their site is used to its full potential.
  prefs: []
  type: TYPE_NORMAL
- en: Diversity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of this metric is to calculate how diverse the recommendations are.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the paper [“Automatic Evaluation of Recommendation Systems: Coverage, Novelty
    and Diversity”](https://medium.com/mlearning-ai/automatic-evaluation-of-recommendation-systems-coverage-novelty-and-diversity-cc140330d3e7)
    by Zahra Ahmad, diversity is the average similarity for top_n.'
  prefs: []
  type: TYPE_NORMAL
- en: But in this article diversity will be treated differently — as a median value
    of the number of unique genres. High diversity values mean that users have an
    opportunity to discover new genres, diversify their experience, and spend more
    time on the site. As a rule, it increases the retention rate and has a positive
    impact on revenue. This way of calculating metrics has a high degree of interpretability
    for business, unlike the abstract mean similarity ratio.
  prefs: []
  type: TYPE_NORMAL
- en: Interpretation of metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is an excellent [repository on recommender systems](https://github.com/microsoft/recommenders)
    that contains not only the models themselves, but also an analysis of the metrics.
    Studying this table gives us an understanding of the possible range of metrics,
    and intuition in model evaluation. For example, Precision@k values below 0.02,
    in most cases, should be considered bad.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4df017f23d9b4e627a523a5f67b2ae0b.png)'
  prefs: []
  type: TYPE_IMG
- en: So we have quality metrics tied and not tied to the rank. There are metrics
    indirectly responsible for business and money, as well as for the use and availability
    of content. Now we can move on to the choice of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Model selection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ALS matrix factorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a great model to start with. Written in [Spark](https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/recommendation.html#ALS)
    the algorithm is relatively simple
  prefs: []
  type: TYPE_NORMAL
- en: During training, the model initialises the User Matrix and Item Matrix and trains
    them in such a way as to minimize the error of reconstructing the Rating matrix.
    Each vector of the User Matrix is a representation of some `user` and each vector
    of the Item Matrix is a representation of a particular `item` . Accordingly, the
    prediction is a scalar multiplication of the corresponding vectors from the User
    and Item Matrices.
  prefs: []
  type: TYPE_NORMAL
- en: It’s a great model to start with, because it’s extremely easy to implement,
    and very often it’s better to start with simple models at the research stage,
    because this model will learn quickly, which means the iteration time is reduced,
    which will speed up the project considerably. Also, the model will not overload
    memory and in case there is a lot of data, it will cope, which will save on infrastructure
    in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Bilateral Variational Autoencoder (BiVAE)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The model is based on the paper [“Bilateral variational autoencoder for collaborative
    filtering”](https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=6955&context=sis_research)
    by Quoc Tuan TRUONG, Aghiles SALAH, Hady W. LAUW.
  prefs: []
  type: TYPE_NORMAL
- en: The model is broadly similar to the previous one — in the process of training,
    the matrix of users Theta and the matrix of Beta units are trained.
  prefs: []
  type: TYPE_NORMAL
- en: But the structure of the model is much more complex than in ALS. We have User
    encoder and Item encoder consisting of a sequence of linear layers. Their task
    is to train hidden variables Theta and Beta respectively. Decoding and inference
    is done by scalar multiplication of these two variables. The error function (Evidence
    lower bound in this case) is counted twice between the created user vectors and
    the actual values, then the same is done for the item encoder.
  prefs: []
  type: TYPE_NORMAL
- en: The model has been chosen as the best one in the comparison table. This model
    is the part of [Cornac](https://cornac.readthedocs.io/en/latest/) zoo of models
    for recommender systems, with Pytorch under the hood. The model has a custom implementation
    of learning mode. It is slower than its predecessor, and will require more spending
    on support and infrastructure, but perhaps its high metrics are worth it.
  prefs: []
  type: TYPE_NORMAL
- en: Most popular
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Yes, the simplest model, and in some situations the most effective.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Although this approach seems too simple, it will nevertheless allow us to compare
    metrics and, for example, find out how far ML models have gone from such a simple
    model. Having such a model can justify or disprove the need for ML implementation.
  prefs: []
  type: TYPE_NORMAL
- en: Random model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This model will just give out random Item. It also creates the necessary contrast
    when evaluating metrics and predictions of ML models.
  prefs: []
  type: TYPE_NORMAL
- en: So, we chose 4 models for the experiment. One is optimized for speed, another
    for quality, and 2 others for comparison and a better understanding of the results.
    We are now ready to begin training.
  prefs: []
  type: TYPE_NORMAL
- en: Model training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will train 4 models at once to make it convenient to compare them. We will
    use the settings that were in the [recomenders](https://github.com/microsoft/recommenders)
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Inference
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Predictions for recommender systems have their own specifics. Predicting all
    units for all users, we get a matrix of n-users x n-items. Accordingly, we can
    predict **only** for those users and units that were at the time of training.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then:'
  prefs: []
  type: TYPE_NORMAL
- en: Remove from the prediction those units that were on the trainee.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sort by rating in descending order for each user. Otherwise, the metrics will
    be bad.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An important point, since people often forget to remove seemed items(or train
    items), this will have a negative impact on the metrics, because the top will
    be those things that are not in the test dataset. In addition, users will have
    a negative experience associated with the fact that the model will recommend what
    they have already seen.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Analysis of results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/59295cacfa3b3ba02f9f99c683d988ee.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the BIVAE model showed the best precision metrics, it was able
    to adjust very precisely to the tastes of users. And good precision has a downside
    — Coverage and Diversity are worse than ALS model. This means that a huge amount
    of content will likely never get a chance to be seen by users. In this particular
    case BIVAE still looks preferable.
  prefs: []
  type: TYPE_NORMAL
- en: But sometimes Diversity is more important to the business than Precision, and
    this can happen, for example, if on your site users watch only romantic comedies
    and other genres are not preferred, but you would like to encourage your audience
    to watch other genres.
  prefs: []
  type: TYPE_NORMAL
- en: The same can be said about the MostPopular model, this model has better performance
    than the ALS machine learning model. And it seems that why need all this ML complexity,
    when we have a ready-made model! But if you look carefully we see that Coverage
    is very low, and usually with the increase of content, the percentage will fall
    even more, for example we have only 1682 films, but what happens if tomorrow the
    business decides to expand the library by 100k films? The Coverage percentage
    would drop even more for that model. The same rule works in the opposite direction
    — the less data you have, the more likely it is that a simple MostPopular model
    will work.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also interesting to consider RandomModel, since in terms of Precision metric
    it doesn’t look too bad in comparison with ALS, and its Coverage is 100%. Again,
    don’t jump to conclusions. The small number of films in this dataset contributes
    to this success.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, a suitable model which has high quality and acceptable Coverage
    and Diversity is BIVAE. We can build our base recommendation system this model.
  prefs: []
  type: TYPE_NORMAL
- en: Tips for ML debugging
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes debugging ml can be very difficult. Where and how to look for problems
    if the metrics are not very good? In the code? In the data? In the choice of model
    or its hyperarameters?
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some tips:'
  prefs: []
  type: TYPE_NORMAL
- en: If you have low metrics, for example PrecisionK below 0.1, and you don’t know
    what the reason is — the data or the model, or maybe the metric calculation, you
    can take the MovieLens dataset and train your model on it. If its metrics are
    low on MovieLens too, then the cause is in the model, if the metrics are good,
    then the likely cause lies in the preprocessing and postprocessing stages.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If Random model and Most popular model metrics are close to ML models, it is
    worth checking the data — maybe the number of unique items is too low. This can
    also happen if we have very little data, or maybe there is a bug in the training
    code.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Values higher than 0.5 for PrecisionK look too high and it is worth checking
    if there is a bug in the script or if we are lowering the sparsity index too much.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Always compare how many users and items you have left after lowering the sparsity
    index. Sometimes in the pursuit of quality you can lose almost all users, so you
    should look for a compromise.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assessment of necessary improvements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So what do we do next, if we want to get the model to production? We need to
    figure out what else we need to do and how much work we need to do.
  prefs: []
  type: TYPE_NORMAL
- en: BIVAE optimization and functionality expansion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are no cold-start mechanisms out of the box. Taking into account the fact
    that we lowered the sparsity index, meaning that many users simply will not have
    predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is necessary to implement a batch predict algorithm. Now the mechanism is
    implemented to predict one user, i.e. batch_size=1, naturally this greatly slows
    down the speed of work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using metadata about users and objects (movies).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Postprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Advanced data diversification algorithms may be required. Which can sometimes
    be comparable to the model development time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: development of new metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: data quality check
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Of course, in each case, this list can be different, I have listed only the
    most likely improvements, and perhaps, after compiling such a list, there will
    be a desire to use another model that will have such features out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We tested different models, including the latest solutions, to ensure their
    effectiveness and learned how to choose the most suitable model based on technical
    and business metrics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Made the first predictions that can already be used to show users.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In addition, we have outlined a further action plan related to the development
    of the model and its release into production (prod).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can find all the code for the article [here](https://github.com/AlexanderChaptykov/personalize).
  prefs: []
  type: TYPE_NORMAL
- en: I would like to tell you more about the BiVAE architecture, about cold start
    and increasing diversification, about down-stream tasks such as item / user similarity,
    about how quality can be controlled and about online or offline inference, about
    how to transfer all this to pipelines. But this is much beyond the scope of the
    article, and if the readers like the article, then it will be possible to release
    a sequel where I will go into everything in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Enjoyed This Story?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Subscribe*](https://medium.com/@alexanderchaptykov/subscribe) *to get notified
    when I publish a new story.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**References:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[1]F. Maxwell Harper and Joseph A. Konstan. 2015\. The MovieLens Datasets:
    History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS)
    5, 4: 19:1–19:19\. [https://doi.org/10.1145/2827872](https://doi.org/10.1145/2827872)'
  prefs: []
  type: TYPE_NORMAL
- en: All images unless otherwise noted are by the author.
  prefs: []
  type: TYPE_NORMAL
