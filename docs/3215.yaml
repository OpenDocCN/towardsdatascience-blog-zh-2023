- en: Why Probabilistic Linkage is More Accurate than Fuzzy Matching or Term Frequency
    based approaches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/why-probabilistic-linkage-is-more-accurate-than-fuzzy-matching-or-term-frequency-based-approaches-15a28c733e73?source=collection_archive---------7-----------------------#2023-10-26](https://towardsdatascience.com/why-probabilistic-linkage-is-more-accurate-than-fuzzy-matching-or-term-frequency-based-approaches-15a28c733e73?source=collection_archive---------7-----------------------#2023-10-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How effectively do different approaches to record linkage use information in
    the records to make predictions?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://robinlinacre.medium.com/?source=post_page-----15a28c733e73--------------------------------)[![Robin
    Linacre](../Images/e408a4ff6e79c23cc6ff1fc6190ab107.png)](https://robinlinacre.medium.com/?source=post_page-----15a28c733e73--------------------------------)[](https://towardsdatascience.com/?source=post_page-----15a28c733e73--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----15a28c733e73--------------------------------)
    [Robin Linacre](https://robinlinacre.medium.com/?source=post_page-----15a28c733e73--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F8a6a0dc508d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-probabilistic-linkage-is-more-accurate-than-fuzzy-matching-or-term-frequency-based-approaches-15a28c733e73&user=Robin+Linacre&userId=8a6a0dc508d6&source=post_page-8a6a0dc508d6----15a28c733e73---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----15a28c733e73--------------------------------)
    ·4 min read·Oct 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F15a28c733e73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-probabilistic-linkage-is-more-accurate-than-fuzzy-matching-or-term-frequency-based-approaches-15a28c733e73&user=Robin+Linacre&userId=8a6a0dc508d6&source=-----15a28c733e73---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F15a28c733e73&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhy-probabilistic-linkage-is-more-accurate-than-fuzzy-matching-or-term-frequency-based-approaches-15a28c733e73&source=-----15a28c733e73---------------------bookmark_footer-----------)![](../Images/e0e3237d3ad7b6527286b4e82bd0913a.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Wringing information out of data. Image created by the author using DALL·E 3
  prefs: []
  type: TYPE_NORMAL
- en: A pervasive data quality problem is to have multiple different records that
    refer to the same entity but no unique identifier that ties these entities together.
  prefs: []
  type: TYPE_NORMAL
- en: In the absence of a unique identifier such as a Social Security number, we can
    use a combination of individually non-unique variables such as name, gender and
    date of birth to identify individuals.
  prefs: []
  type: TYPE_NORMAL
- en: To get the best accuracy in record linkage, we need a model that wrings as much
    information from this input data as possible.
  prefs: []
  type: TYPE_NORMAL
- en: This article describes the three types of information that are most important
    in making an accurate prediction, and how all three are leveraged by the Fellegi-Sunter
    model as used in [Splink](https://github.com/moj-analytical-services/splink) (a
    free Python package for data linking and deduplication).
  prefs: []
  type: TYPE_NORMAL
- en: It also describes how some alternative record linkage approaches throw away
    some of this information, leaving accuracy on the table.
  prefs: []
  type: TYPE_NORMAL
- en: The three types of information
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Broadly, there are three categories of information that are relevant when trying
    to predict whether a pair of records match:'
  prefs: []
  type: TYPE_NORMAL
- en: Similarity of the pair of records
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Frequency of values in the overall dataset, and more broadly measuring how common
    different scenarios are
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Data quality of the overall dataset
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s look at each in turn.
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Similarity of the pairwise record comparison: Fuzzy matching'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most obvious way to predict whether two records represent the same entity
    is to measure whether the columns contain the same or similar information.
  prefs: []
  type: TYPE_NORMAL
- en: The similarity of each column can be measured quantitatively using fuzzy matching
    functions like [Levenshtein](https://en.wikipedia.org/wiki/Levenshtein_distance)
    or [Jaro-Winker](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance)
    for text, or numeric differences such as absolute or percentage difference.
  prefs: []
  type: TYPE_NORMAL
- en: For example, `Hammond` vs `Hamond` has a Jaro-Winkler similarity of 0.97 (1.0
    is a perfect score). It's probably a typo.
  prefs: []
  type: TYPE_NORMAL
- en: These measures could be assigned weights, and summed together to compute a total
    similarity score.
  prefs: []
  type: TYPE_NORMAL
- en: The approach is sometimes known as fuzzy matching, and it is an important part
    of an accurate linkage model.
  prefs: []
  type: TYPE_NORMAL
- en: 'However using this approach alone has major drawback: the weights are arbitrary:'
  prefs: []
  type: TYPE_NORMAL
- en: The importance of different fields has to be guessed at by the user. For example,
    what weight should be assigned to a match on age? How does this compare to a match
    on first name? How should we decide on the size of punitive weights when information
    does not matches?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The relationship between the strength of prediction and each fuzzy matching
    metric has to be guessed by the user, as opposed to being estimated. For example,
    how much should our prediction change if the first name is a Jaro-Winkler 0.9
    fuzzy match as opposed to an exact match? Should it change by the same amount
    if the Jaro-Winkler score reduces to 0.8?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2\. Frequency of values in the overall dataset, or more broadly measuring how
    common different scenarios are
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can improve on fuzzy matching by accounting for the frequency of values in
    the overall dataset (sometimes known as ‘term frequencies’).
  prefs: []
  type: TYPE_NORMAL
- en: For example, `John` vs `John`, and `Joss` vs `Joss` are both exact matches so
    have the same similarity score, but the later is stronger evidence of a match
    than the former, because `Joss` is an unusual name.
  prefs: []
  type: TYPE_NORMAL
- en: The relative term frequencies of `John` v `Joss` provide a data-driven estimate
    of the relative importance of these different names, which can be used to inform
    the weights.
  prefs: []
  type: TYPE_NORMAL
- en: This concept can be extended to encompass similar records that are not an exact
    match. Weights can derived from an estimate of how common it is to observe fuzzy
    matches across the dataset. For example, if it’s really common to see fuzzy matches
    on first name at a Jaro-Winkler score of 0.7, even amongst non-matching records,
    then if we observe such a match, it doesn’t offer much evidence in favour of a
    match. In probabilistic linkage, this information is captured in parameters known
    as the `u` probabilities, which is described in more detail [here](https://moj-analytical-services.github.io/splink/topic_guides/theory/fellegi_sunter.html#u-probability).
  prefs: []
  type: TYPE_NORMAL
- en: '3\. Data quality of the overall dataset: measuring the importance of non-matching
    information'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve seen that fuzzy matching and term frequency based approaches can allow
    us to score the similarity between records, and even, to some extent, weight the
    importance of matches on different columns.
  prefs: []
  type: TYPE_NORMAL
- en: However, none of these techniques help quantify the relative importance of non-matches
    to the predicted match probability.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic methods explicitly estimate the relative importance of these scenarios
    by estimating data quality. In probabilistic linkage, this information is captured
    in the `m` probabilities, which are defined more precisely [here](https://moj-analytical-services.github.io/splink/topic_guides/theory/fellegi_sunter.html#m-probability).
  prefs: []
  type: TYPE_NORMAL
- en: For example, if the data quality in the gender variable is extremely high, then
    a non-match on gender would be strong evidence against the two records being a
    true match.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, if records have been observed over a number of years, a non-match
    on age wouldn’t be strong evidence of the two records being a match.
  prefs: []
  type: TYPE_NORMAL
- en: Probabilistic linkage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Much of the power of probabilistic models comes from combining all three sources
    of information in a way which is not possible in other models.
  prefs: []
  type: TYPE_NORMAL
- en: Not only is all of this information be incorporated in the prediction, the [partial
    match weights](https://moj-analytical-services.github.io/splink/topic_guides/theory/fellegi_sunter.html#match-weights)
    in the Fellegi-Sunter model enable the relative importance of the different types
    of information to be estimated from the data itself, and hence weighted together
    correctly to optimise accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, fuzzy matching techniques often use arbitrary weights, and cannot
    fully incorporate information from all three sources. Term frequency approaches
    lack the ability to use information about data quality to negatively weight non-matching
    information, or a mechanism to appropriately weight fuzzy matches.
  prefs: []
  type: TYPE_NORMAL
- en: '*The author is the developer of* [*Splink*](http://github.com/moj-analytical-services/splink)*,
    a free and open source Python package for probabilistic linkage at scale.*'
  prefs: []
  type: TYPE_NORMAL
