- en: Pumpkin Spice Time Series Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/pumpkin-spice-time-series-analysis-afd8daaedce1?source=collection_archive---------3-----------------------#2023-10-24](https://towardsdatascience.com/pumpkin-spice-time-series-analysis-afd8daaedce1?source=collection_archive---------3-----------------------#2023-10-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Throw on your comfiest lo-fi, grab an oversized sweater, your favorite hot beverage,
    and let’s python.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ls.casanave?source=post_page-----afd8daaedce1--------------------------------)[![Louis
    Casanave](../Images/ca6ddaa01d86491f05d7e516aeda0baa.png)](https://medium.com/@ls.casanave?source=post_page-----afd8daaedce1--------------------------------)[](https://towardsdatascience.com/?source=post_page-----afd8daaedce1--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----afd8daaedce1--------------------------------)
    [Louis Casanave](https://medium.com/@ls.casanave?source=post_page-----afd8daaedce1--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa25bdaa6a5ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpumpkin-spice-time-series-analysis-afd8daaedce1&user=Louis+Casanave&userId=a25bdaa6a5ad&source=post_page-a25bdaa6a5ad----afd8daaedce1---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----afd8daaedce1--------------------------------)
    ·8 min read·Oct 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fafd8daaedce1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpumpkin-spice-time-series-analysis-afd8daaedce1&user=Louis+Casanave&userId=a25bdaa6a5ad&source=-----afd8daaedce1---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fafd8daaedce1&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpumpkin-spice-time-series-analysis-afd8daaedce1&source=-----afd8daaedce1---------------------bookmark_footer-----------)![](../Images/caaeaeed7ab1087b2fd0f9723b4df342.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Nathan Dumlao](https://unsplash.com/@nate_dumlao?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: It’s that time again in the northern hemisphere — a time for apples, pumpkins,
    and various configurations of cinnamon, nutmeg, ginger, allspice, and cloves.
    And as the grocery isles start getting ready for Halloween, Thanksgiving, and
    the winter holidays, it’s a great time to dust off my statistical modeling skills.
    Hold onto your seasoned lattes, and let’s do some function-oriented seasonal modeling.
    [The full code notebook can be found here.](https://github.com/casanave/Pumpkin_Spice/tree/main)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Hypothesis:'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pumpkin Spice’s popularity as a Google searched term in the USA will have strong
    seasonality since it’s associated with American Fall Holidays and seasonal food
    dishes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'Null hypothesis:'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using last week’s or last year’s data will be more predictive of this week’s
    level of popularity for the search term “pumpkin spice.”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: 'Data:'
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[The last 5 years of data from Google Trends, pulled on the 7th of October,
    2023\.](https://github.com/casanave/Pumpkin_Spice/blob/main/pumpkin_spice_5_years.csv)
    [1]'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: 'Iterative Modeling Method:'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Make a naive model where last week’s/last year’s data is this week’s prediction.
    Specifically, it’s not enough for my final model to be accurate or inaccurate
    in a void. My final model must outperform using historical data as a direct prediction.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The train test split will give me two sets of data, one for the algorithm to
    learn from. The other is for me to test how well my algorithm performed.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seasonal decomposition will give me a rough idea of how predictable my data
    is by trying to separate the yearly overall trend from the seasonal patterns and
    the noise. A smaller scale of noise will imply that more of the data can be captured
    in an algorithm.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A series of statistical tests to determine if the data is stationary. If the
    data is not stationary, I’ll need to take a first difference (run a time-delta
    function where each time interval’s data only shows the difference from the previous
    time interval’s data. This will force the data to become stationary.)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make some SARIMA models, using inferences from autocorrelation plots for the
    moving average term, and inferences from partial auto-correlation plots for the
    autoregressive term. SARIMA is a go-to for time series modeling and I’ll be trying
    ACF and PACF inferencing before I try a brute-force approach with Auto Arima.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try using Auto Arima, which will iterate through many terms and select the best
    combination of terms. I want to experiment to learn if the parameters it gives
    me for a SARIMA model yield a better-performing model.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try ETS models, using inference from the seasonal decomposition as to whether
    x is additive or multiplicative over time. ETS models focus more heavily on seasonality
    and overall trend than SARIMA family models do, and may give me an edge when capturing
    the relationship pumpkin spice has to time.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Performance plotting KPIs:'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Try using the MAPE score because it's an industry standard in many workplaces,
    and folks may be used to it. It’s easy to understand.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Try using the RMSE score because it’s more useful.](/forecast-kpi-rmse-mae-mape-bias-cdc5703d242d)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plot predictions against the test data and visually check for performance.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Eyeballing the data:'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/2d10979a1d55d85be291f50863337530.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: Image by the author.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the above plot, this data shows strong potential for seasonal
    modeling. There’s a clear spike in the second half of each year, with a taper
    and another spike before a drop down into our baseline.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: However, each year’s primary spike is larger each year besides 2021, which makes
    sense, given the pandemic, when folks may not have had celebrating the season
    on their minds.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，除了2021年外，每年的主要峰值都在增加，这也是合情合理的，因为在疫情期间，人们可能没有考虑庆祝季节。
- en: 'Imports:'
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入：
- en: 'Note: These imports appear differently in the notebook itself, as in the notebook
    I’m relying on `seasonal_mod.py` which has a lot of my imports baked in.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这些导入在笔记本中显示得有所不同，因为在笔记本中我依赖于`seasonal_mod.py`，其中包含了许多我的导入。
- en: Image by the author.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: These are the libraries I used to make the code notebook. I went for statsmodels
    instead of scikit-learn for their time series packages, I like statsmodels better
    for most linear regression problems.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我用来制作代码笔记本的库。我选择了statsmodels而不是scikit-learn，因为statsmodels的时间序列包更符合我的需求，我对大多数线性回归问题更喜欢statsmodels。
- en: 'Function-Based Approach to the Code:'
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于函数的方法：
- en: I don’t know about you but I don’t want to write several lines of code each
    time I make a new model and then more code to verify. So instead I made some functions
    to keep my code DRY and prevent myself from making errors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道你是否一样，但我不想每次创建新模型时都写几行代码，然后再写更多代码来验证。因此，我制作了一些函数，以保持我的代码简洁并防止我出错。
- en: Image by the author.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: These three little functions work together so I only need to run `metrics_graph()`with
    `y_true` and `y_preds` as the input and it will give me a blue line of true data
    and a red line of predictive data, along with the MAPE and RMSE. That will save
    me time and hassle.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个小函数协同工作，所以我只需用`metrics_graph()`运行`y_true`和`y_preds`作为输入，它会给我一条真实数据的蓝线和一条预测数据的红线，以及MAPE和RMSE。这将节省我的时间和麻烦。
- en: 'Using Last Year’s Data as a Benchmark for Success:'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用去年的数据作为成功的基准：
- en: My experience in retail management informed my decision to try last week’s data
    and last year’s data as a direct prediction for this year’s data. Often in retail,
    we used last season’s (1 unit of time ago’s) data as a direct prediction, to ensure
    inventory during Black Friday for example. Last week’s data didn’t perform as
    well as last year’s data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我的零售管理经验促使我尝试使用上周的数据和去年的数据作为对今年数据的直接预测。在零售中，我们通常使用上个季节（1个时间单位前）的数据作为直接预测，以确保例如黑色星期五期间的库存。上周的数据表现不如去年的数据。
- en: '![](../Images/5b7fd5c7e2f44c61a58c1c760c5a356f.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5b7fd5c7e2f44c61a58c1c760c5a356f.png)'
- en: Image by the author.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: Last week’s data to predict this week’s data showed a MAPE score of just over
    18, with a RMSE of about 11\. By comparison, last year’s data as a direct prediction
    to this year’s data showed a MAPE score of just about 12 with a RMSE of about
    7.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上周的数据预测本周的数据显示MAPE得分略高于18，RMSE约为11\. 相比之下，去年的数据作为对今年数据的直接预测显示MAPE得分约为12，RMSE约为7。
- en: '![](../Images/55ff4865aa6ae49dcb370932e5fa31df.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/55ff4865aa6ae49dcb370932e5fa31df.png)'
- en: Image by the author.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: Therefore I chose to compare all statistical models I built to a naive model
    using last year’s data. This model got the timing of the spikes and decreases
    more accurately than our naive weekly model, however, I still thought I could
    do better. The next step in modeling was doing a seasonal decomposition.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我选择将我构建的所有统计模型与使用去年的数据的简单模型进行比较。这个模型在峰值和下降的时间上比我们的简单周模型更准确，然而，我仍然认为我可以做得更好。建模的下一步是进行季节性分解。
- en: The following function helped me run my season decomposition and I’ll be keeping
    it as reusable code for all future modeling moving forward.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数帮助我运行了季节性分解，我将把它作为可重用的代码用于未来所有的建模工作。
- en: Image by the author.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: The below shows how I used that seasonal decomposition.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下面展示了我如何使用这个季节性分解。
- en: '![](../Images/0181b2dcfdc242a221a18973b75acd4d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0181b2dcfdc242a221a18973b75acd4d.png)'
- en: Image by the author.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: The additive model had a reoccurring yearly pattern in the residuals, evidence
    that an additive model wasn’t able to completely decompose all the recurring patterns.
    It was a good reason to try a multiplicative model for the yearly spikes.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 加法模型在残差中表现出每年的重复模式，这表明加法模型无法完全分解所有的重复模式。这是尝试乘法模型来处理年度峰值的一个很好的理由。
- en: '![](../Images/e300ec40e29fb24857e9c37100d00ae0.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e300ec40e29fb24857e9c37100d00ae0.png)'
- en: Image by the author.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像。
- en: Now the residuals in the multiplicative decomposition were much more promising.
    They were much more random and on a much smaller scale, proving that a multiplicative
    model would capture the data best. The residuals being so small — on a scale between
    1.5 to -1, meant that there was a lot of promise in modeling.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在乘法分解中的残差更有希望。它们变得更随机且规模更小，证明了乘法模型能更好地捕捉数据。残差如此之小——在1.5到-1的范围内，这意味着建模具有很大的潜力。
- en: But now I wanted a function for running SARIMA models specifically, only inputting
    the order. I wanted to experiment running `c`,`t` and `ct` versions of the SARIMA
    model with those orders as well since the seasonal decomposition favored a multiplicative
    type of model over an additive type of model. Using the `c`, `t` and `ct` in the
    `trend =` parameter, I was able to add multipliers to my SARIMA model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在我想要一个专门运行SARIMA模型的函数，只输入顺序。我还想实验运行`c`、`t`和`ct`版本的SARIMA模型，因为季节性分解更倾向于乘法模型而非加法模型。通过在`trend
    =`参数中使用`c`、`t`和`ct`，我能够为SARIMA模型添加乘数。
- en: Image by the author.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: I’ll skip describing the part where I looked at the AFC and PACF plots and the
    part where I also tried PMD auto arima to find the best terms to use in the SARIMA
    models. [If you’re interested in those details, please see my full code notebook.](https://github.com/casanave/Pumpkin_Spice/blob/main/Pumpkin_Spice.ipynb)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我将跳过描述我查看AFC和PACF图的部分以及我尝试PMD自动ARIMA以找到SARIMA模型中最佳项的部分。[如果你对这些细节感兴趣，请查看我的完整代码笔记本。](https://github.com/casanave/Pumpkin_Spice/blob/main/Pumpkin_Spice.ipynb)
- en: 'My best SARIMA model:'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我的最佳SARIMA模型：
- en: '![](../Images/6077d7a41020e81a621208f399979170.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6077d7a41020e81a621208f399979170.png)'
- en: Image by the author.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: So my best SARIMA model had a higher MAPE score than my naive model, nearly
    29 to nearly 12, but a lower RMSE by about a unit, nearly 7 to nearly 6\. My biggest
    problem with using this model is it really underpredicted the 2023 spike, there’s
    a fair amount of area between the red and blue lines from August to September
    of 2023\. There are reasons to like it better than my yearly naive model or worse
    than my yearly naive model, depending on your opinions about RMSE vs MAPE. However,
    I wasn’t done yet. My final model was definitively better than my yearly naive
    model.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我最好的SARIMA模型的MAPE分数比我的基准模型高，接近29对比12，但RMSE却低了大约一个单位，从接近7降到接近6。使用这个模型最大的问题是它对2023年高峰的预测严重不足，从2023年8月到9月，红线和蓝线之间的误差区域较大。根据你对RMSE和MAPE的看法，可能会有理由更喜欢它或不如年度基准模型。然而，我还没完。我最终的模型确实比我的年度基准模型好。
- en: 'Final Model:'
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终模型：
- en: I used an ETS (exponential smoothing) model for my final model, which allowed
    me to explicitly use the `seasonal` parameter to make it use a multiplicative
    approach.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了一个ETS（指数平滑）模型作为最终模型，这让我可以明确使用`seasonal`参数，使其采用乘法方法。
- en: '![](../Images/37f625785b389c03c959354c901ca918.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/37f625785b389c03c959354c901ca918.png)'
- en: Image by the author.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: Now you may be thinking “but this model has a higher MAPE score than the yearly
    naive model.” And you’d be correct, by about 0.3%. However, I think that’s a more
    than fair trade considering that I now have an RMSE of about 4 and a half instead
    of 7\. While this model does struggle a bit more in December of 2022 than my best
    SARIMA model, it’s off by less area amount for that spike than the larger spike
    for fall of 2023, which I care more about. [You can find that model here.](https://github.com/casanave/Pumpkin_Spice/blob/main/ps_predictor.sav)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能会想，“但这个模型的MAPE分数比年度基准模型高。” 你说得对，大约高了0.3%。不过，我认为这是一种非常公平的交换，因为我的RMSE从7降低到了大约4.5。虽然这个模型在2022年12月的表现比我最好的SARIMA模型差一点，但它在那个高峰期的误差比2023年秋季的更小，而我更关心的是后者。[你可以在这里找到那个模型。](https://github.com/casanave/Pumpkin_Spice/blob/main/ps_predictor.sav)
- en: 'Further Validation:'
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步验证：
- en: I will wait until 10/7/2024 and do another data pull and see how the model did
    against last year’s data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我将等到2024年10月7日，再进行一次数据提取，看看模型在去年的数据上的表现如何。
- en: 'Conclusion:'
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论：
- en: To sum up, I was able to disprove the null hypothesis, my final model outperformed
    a naive yearly model. I’ve proved that pumpkin spice popularity on Google is very
    seasonal and can be predicted. Between naive, SARMA models, and ETS models, ETS
    was better able to capture the relationship between time and pumpkin spice popularity.
    The multiplicative relationship of pumpkin spice to time implies that pumpkin
    spice’s popularity is based on more than one independent variable besides time
    in the expression `time * unknown_independant_var = pumpkin_spice_popularity`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我能够证伪零假设，我的最终模型优于朴素的年度模型。我证明了 Google 上的南瓜香料受欢迎程度具有很强的季节性并且可以预测。在朴素、SARMA
    模型和 ETS 模型之间，ETS 更好地捕捉了时间与南瓜香料受欢迎程度之间的关系。南瓜香料与时间的乘法关系表明，南瓜香料的受欢迎程度基于除了时间之外的一个或多个独立变量，表达式为
    `time * unknown_independant_var = pumpkin_spice_popularity`。
- en: 'What I Learned and Future Work:'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我学到了什么以及未来的工作：
- en: My next step is to use some version of [Meta’s graph API](https://developers.facebook.com/docs/instagram-api/)
    to look for “pumpkin spice” being used in business articles. I wonder how correlated
    that data will be to my Google trends data. I also learned that when the seasonal
    decomposition points towards a multiplicative model, I’ll reach for an ETS much
    sooner in my process.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我的下一步是使用某种版本的 [Meta’s graph API](https://developers.facebook.com/docs/instagram-api/)
    来查找“南瓜香料”在商业文章中的使用情况。我想知道这些数据与我的 Google 趋势数据的相关性如何。我还了解到，当季节性分解指向乘法模型时，我会在过程中更早地选择
    ETS。
- en: Furthermore, I’m interested in automating a lot of this process. Ideally, I’d
    like to build a Python module where the input is a CSV directly from Google Trends
    and the output can be a useable model with good enough documentation that a nontechnical
    user could make and test their own predictive models. On the eventuality that
    a user would pick data that is hard to predict (IE a naive or random walk model
    would suit better), I hope to build the module to explain that to users. I could
    then collect data from an app using that module to showcase findings of seasonality
    across lots of untested data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我对自动化这整个过程很感兴趣。理想情况下，我希望构建一个 Python 模块，其中输入是直接来自 Google Trends 的 CSV 文件，输出可以是一个可用的模型，并且文档足够好，使非技术用户能够创建和测试他们自己的预测模型。对于用户选择难以预测的数据（例如，朴素或随机游走模型可能更适用）的可能性，我希望构建该模块以向用户解释这一点。然后，我可以利用该模块从应用程序中收集数据，以展示未测试数据中的季节性发现。
- en: Look out for that app by pumpkin spice season of next year!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请关注明年南瓜香料季节的那个应用程序！
- en: '[1] Google Trends, N/A ([https://www.google.com/trends](http://www.google.com/trends))'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Google Trends, N/A ([https://www.google.com/trends](http://www.google.com/trends))'
