- en: Transformers — Intuitively and Exhaustively Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=collection_archive---------0-----------------------#2023-09-20](https://towardsdatascience.com/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=collection_archive---------0-----------------------#2023-09-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Exploring the modern wave of machine learning: taking apart the transformer
    step by step'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdc4072cbfdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&user=Daniel+Warfield&userId=bdc4072cbfdc&source=post_page-bdc4072cbfdc----58a5c5df8dbb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)
    ·15 min read·Sep 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F58a5c5df8dbb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&user=Daniel+Warfield&userId=bdc4072cbfdc&source=-----58a5c5df8dbb---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58a5c5df8dbb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&source=-----58a5c5df8dbb---------------------bookmark_footer-----------)![](../Images/edb20757aa401a62d13a932e35ee4b95.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by author using MidJourney. All images by the author unless otherwise
    specified.
  prefs: []
  type: TYPE_NORMAL
- en: In this post you will learn about the transformer architecture, which is at
    the core of the architecture of nearly all cutting-edge large language models.
    We’ll start with a brief chronology of some relevant natural language processing
    concepts, then we’ll go through the transformer step by step and uncover how it
    works.
  prefs: []
  type: TYPE_NORMAL
- en: '**Who is this useful for?** Anyone interested in natural language processing
    (NLP).'
  prefs: []
  type: TYPE_NORMAL
- en: '**How advanced is this post?** This is not a complex post, but there are a
    lot of concepts, so it might be daunting to less experienced data scientists.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-requisites:** A good working understanding of a standard neural network.
    Some cursory experience with embeddings, encoders, and decoders would probably
    also be helpful.'
  prefs: []
  type: TYPE_NORMAL
- en: A Brief Chronology of NLP Up To The Transformer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following sections contain useful concepts and technologies to know before
    getting into transformers. Feel free to skip ahead if you feel confident.
  prefs: []
  type: TYPE_NORMAL
- en: Word Vector Embeddings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
