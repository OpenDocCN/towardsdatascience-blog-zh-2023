- en: Transformers — Intuitively and Exhaustively Explained
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变换器 — 直观而全面的解释
- en: 原文：[https://towardsdatascience.com/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=collection_archive---------0-----------------------#2023-09-20](https://towardsdatascience.com/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=collection_archive---------0-----------------------#2023-09-20)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=collection_archive---------0-----------------------#2023-09-20](https://towardsdatascience.com/transformers-intuitively-and-exhaustively-explained-58a5c5df8dbb?source=collection_archive---------0-----------------------#2023-09-20)
- en: 'Exploring the modern wave of machine learning: taking apart the transformer
    step by step'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索现代机器学习的浪潮：一步一步拆解变换器
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----58a5c5df8dbb--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdc4072cbfdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&user=Daniel+Warfield&userId=bdc4072cbfdc&source=post_page-bdc4072cbfdc----58a5c5df8dbb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)
    ·15 min read·Sep 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F58a5c5df8dbb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&user=Daniel+Warfield&userId=bdc4072cbfdc&source=-----58a5c5df8dbb---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdc4072cbfdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&user=Daniel+Warfield&userId=bdc4072cbfdc&source=post_page-bdc4072cbfdc----58a5c5df8dbb---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----58a5c5df8dbb--------------------------------)
    ·15分钟阅读·2023年9月20日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F58a5c5df8dbb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&user=Daniel+Warfield&userId=bdc4072cbfdc&source=-----58a5c5df8dbb---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58a5c5df8dbb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&source=-----58a5c5df8dbb---------------------bookmark_footer-----------)![](../Images/edb20757aa401a62d13a932e35ee4b95.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F58a5c5df8dbb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftransformers-intuitively-and-exhaustively-explained-58a5c5df8dbb&source=-----58a5c5df8dbb---------------------bookmark_footer-----------)![](../Images/edb20757aa401a62d13a932e35ee4b95.png)'
- en: Image by author using MidJourney. All images by the author unless otherwise
    specified.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 MidJourney 制作。除非另有说明，否则所有图片均由作者提供。
- en: In this post you will learn about the transformer architecture, which is at
    the core of the architecture of nearly all cutting-edge large language models.
    We’ll start with a brief chronology of some relevant natural language processing
    concepts, then we’ll go through the transformer step by step and uncover how it
    works.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你将了解变换器架构，这几乎是所有前沿大型语言模型的核心架构。我们将从一些相关的自然语言处理概念的简要时间轴开始，然后逐步深入变换器，揭示它的工作原理。
- en: '**Who is this useful for?** Anyone interested in natural language processing
    (NLP).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**这对谁有用？** 任何对自然语言处理（NLP）感兴趣的人。'
- en: '**How advanced is this post?** This is not a complex post, but there are a
    lot of concepts, so it might be daunting to less experienced data scientists.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**这篇文章有多高级？** 这不是一篇复杂的文章，但概念较多，因此对经验较少的数据科学家来说可能会感到有些望而生畏。'
- en: '**Pre-requisites:** A good working understanding of a standard neural network.
    Some cursory experience with embeddings, encoders, and decoders would probably
    also be helpful.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**前提条件：** 对标准神经网络有良好的工作理解。对嵌入、编码器和解码器有一些初步经验也可能会有所帮助。'
- en: A Brief Chronology of NLP Up To The Transformer
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 NLP 到 Transformer 的简要时间线
- en: The following sections contain useful concepts and technologies to know before
    getting into transformers. Feel free to skip ahead if you feel confident.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分包含在深入了解 Transformer 之前需要掌握的有用概念和技术。如果你感到自信，可以随意跳过。
- en: Word Vector Embeddings
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 词向量嵌入
