["```py\nfrom evidently.metric_preset import DataDriftPreset\nfrom evidently.report import Report\nfrom kestra import Kestra\n\ndata_drift_report = Report(metrics=[DataDriftPreset()])\ndata_drift_report.run(reference_data=reference, current_data=current)\nreport = data_drift_report.as_dict()\ndrift_detected = report[\"metrics\"][0][\"result\"][\"dataset_drift\"]\n\nif drift_detected:\n    print(\"Detect dataset drift\")\nelse:\n    print(\"Detect no dataset drift\")\n\nKestra.outputs({\"drift_detected\": drift_detected})\n```", "```py\ndef train_model(X_train: pd.DataFrame, y_train: pd.Series, model_params: DictConfig):\n    y_train_log = np.log1p(y_train)\n    model = Ridge()\n    scorer = metrics.make_scorer(rmsle, greater_is_better=True)\n    params = dict(model_params)\n\n    grid = GridSearchCV(model, params, scoring=scorer, cv=3, verbose=3)\n    grid.fit(X_train, y_train_log)\n    return grid\n\nmodel = train_model(X_train, y_train, config.model.params)\njoblib.dump(model, \"model.pkl\")\n```", "```py\ndocker compose up -d\n```", "```py\nid: get-reference-table\nnamespace: dev\ntasks:\n  - id: getReferenceTable\n    type: io.kestra.plugin.jdbc.postgresql.CopyOut\n    url: jdbc:postgresql://host.docker.internal:5432/\n    username: \"{{secret('POSTGRES_USERNAME')}}\"\n    password: \"{{secret('POSTGRES_PASSWORD')}}\"\n    format: CSV\n    sql: SELECT * FROM reference\n    header: true\n  - id: wdir\n    type: io.kestra.core.tasks.flows.WorkingDirectory\n    tasks:\n    - id: saveReferenceToCSV\n      type: io.kestra.core.tasks.storages.LocalFiles\n      inputs:\n        data/reference.csv: \"{{outputs.getReferenceTable.uri}}\"\n    - id: runPythonScript\n      type: io.kestra.plugin.scripts.python.Script\n      beforeCommands:\n        - pip install pandas\n      script: | \n        import pandas as pd\n        df = pd.read_csv(\"data/reference.csv\")\n        print(df.head(10))\n```", "```py\nid: get-current-table\nnamespace: dev\ninputs:\n  - name: startDate\n    type: STRING\n    defaults: \"2011-03-01\"\n  - name: endDate\n    type: STRING\n    defaults: \"2011-03-31\"\n  - name: dataURL\n    type: STRING \n    defaults: \"https://raw.githubusercontent.com/khuyentran1401/detect-data-drift-pipeline/main/data/bikeride.csv\"\ntasks:\n  - id: getCurrentCSV\n    type: io.kestra.plugin.scripts.python.Script\n    beforeCommands:\n      - pip install pandas\n    script: |\n      import pandas as pd\n      df = pd.read_csv(\"{{inputs.dataURL}}\", parse_dates=[\"dteday\"])\n      print(f\"Getting data from {{inputs.startDate}} to {{inputs.endDate}}\")\n      df = df.loc[df.dteday.between(\"{{inputs.startDate}}\", \"{{inputs.endDate}}\")]\n      df.to_csv(\"current.csv\", index=False)\n```", "```py\niid: save-current-table\nnamespace: dev\ntasks:\n  - id: wdir\n    type: io.kestra.core.tasks.flows.WorkingDirectory\n    tasks:\n    - id: getCurrentCSV\n      type: io.kestra.plugin.scripts.python.Script\n      beforeCommands:\n        - pip install pandas\n      script: |\n        import pandas as pd\n        data_url = \"https://raw.githubusercontent.com/khuyentran1401/detect-data-drift-pipeline/main/data/bikeride.csv\"\n        df = pd.read_csv(data_url, parse_dates=[\"dteday\"])\n        df.to_csv(\"current.csv\", index=False)\n    - id: saveFiles\n      type: io.kestra.core.tasks.storages.LocalFiles\n      outputs:\n        - current.csv\n  - id: saveToCurrentTable\n    type: io.kestra.plugin.jdbc.postgresql.CopyIn\n    url: jdbc:postgresql://host.docker.internal:5432/\n    username: \"{{secret('POSTGRES_USERNAME')}}\"\n    password: \"{{secret('POSTGRES_PASSWORD')}}\"\n    from: \"{{outputs.saveFiles.uris['current.csv']}}\"\n    table: current\n    format: CSV\n    header: true\n    delimiter: \",\"\n```", "```py\nid: clone-repository\nnamespace: dev\ntasks:\n  - id: wdir\n    type: io.kestra.core.tasks.flows.WorkingDirectory\n    tasks:\n      - id: cloneRepository\n        type: io.kestra.plugin.git.Clone\n        url: https://github.com/khuyentran1401/detect-data-drift-pipeline\n        branch: main\n      - id: runPythonCommand\n        type: io.kestra.plugin.scripts.python.Commands\n        commands:\n          - python src/example.py\n```", "```py\nid: triggered-flow\nnamespace: dev\ntasks:\n  - id: hello\n    type: io.kestra.core.tasks.log.Log\n    message: Hello world\ntriggers:\n  - id: schedule\n    type: io.kestra.core.models.triggers.types.Schedule\n    cron: \"0 11 * * MON\"\n```", "```py\nid: upload-to-S3\nnamespace: dev\ntasks:\n  - id: wdir\n    type: io.kestra.core.tasks.flows.WorkingDirectory\n    tasks:\n    - id: createPickle\n      type: io.kestra.plugin.scripts.python.Script\n      script: |\n        import pickle\n        data = [1, 2, 3]\n        with open('data.pkl', 'wb') as f:\n          pickle.dump(data, f)\n    - id: saveToPickle\n      type: io.kestra.core.tasks.storages.LocalFiles\n      outputs:\n        - data.pkl  \n  - id: upload\n    type: io.kestra.plugin.aws.s3.Upload\n    accessKeyId: \"{{secret('AWS_ACCESS_KEY_ID')}}\"\n    secretKeyId: \"{{secret('AWS_SECRET_ACCESS_KEY_ID')}}\"\n    region: us-east-2\n    from: '{{outputs.saveToPickle.uris[\"data.pkl\"]}}'\n    bucket: bike-sharing\n    key: data.pkl\n```", "```py\nid: detect-data-drift\nnamespace: dev\ninputs:\n  - name: startDate\n    type: STRING\n    defaults: \"2011-03-01\"\n  - name: endDate\n    type: STRING\n    defaults: \"2011-03-31\"\n  - name: data_url\n    type: STRING \n    defaults: \"https://raw.githubusercontent.com/khuyentran1401/detect-data-drift-pipeline/main/data/bikeride.csv\"\ntasks:\n  - id: getReferenceTable\n    type: io.kestra.plugin.jdbc.postgresql.CopyOut\n    url: jdbc:postgresql://host.docker.internal:5432/\n    username: \"{{secret('POSTGRES_USERNAME')}}\"\n    password: \"{{secret('POSTGRES_PASSWORD')}}\"\n    format: CSV\n    sql: SELECT * FROM reference\n    header: true\n  - id: wdir\n    type: io.kestra.core.tasks.flows.WorkingDirectory\n    tasks:\n      - id: cloneRepository\n        type: io.kestra.plugin.git.Clone\n        url: https://github.com/khuyentran1401/detect-data-drift-pipeline\n        branch: main\n      - id: saveReferenceToCSV\n        type: io.kestra.core.tasks.storages.LocalFiles\n        inputs:\n          data/reference.csv: \"{{outputs.getReferenceTable.uri}}\"\n      - id: getCurrentCSV\n        type: io.kestra.plugin.scripts.python.Script\n        beforeCommands:\n          - pip install pandas\n        script: |\n          import pandas as pd\n          df = pd.read_csv(\"{{inputs.data_url}}\", parse_dates=[\"dteday\"])\n          print(f\"Getting data from {{inputs.startDate}} to {{inputs.endDate}}\")\n          df = df.loc[df.dteday.between(\"{{inputs.startDate}}\", \"{{inputs.endDate}}\")]\n          df.to_csv(\"data/current.csv\", index=False)\n      - id: detectDataDrift\n        type: io.kestra.plugin.scripts.python.Commands\n        beforeCommands:\n          - pip install -r src/detect/requirements.txt\n        commands:\n          - python src/detect/detect_data_drift.py\n      - id: saveFileInStorage\n        type: io.kestra.core.tasks.storages.LocalFiles\n        outputs:\n          - data/current.csv\n  - id: saveToCurrentTable\n    type: io.kestra.plugin.jdbc.postgresql.CopyIn\n    url: jdbc:postgresql://host.docker.internal:5432/\n    username: \"{{secret('POSTGRES_USERNAME')}}\"\n    password: \"{{secret('POSTGRES_PASSWORD')}}\"\n    from: \"{{outputs.saveFileInStorage.uris['data/current.csv']}}\"\n    table: current\n    format: CSV\n    header: true\n    delimiter: \",\"\ntriggers:\n  - id: schedule\n    type: io.kestra.core.models.triggers.types.Schedule\n    cron: \"0 11 * * MON\"\n```", "```py\nid: send-slack-message\nnamespace: dev\ntasks:\n  - id: send\n    type: io.kestra.plugin.notifications.slack.SlackExecution\n    url: \"{{secret('SLACK_WEBHOOK')}}\"\n    customMessage: Detect data drift\n\ntriggers:\n  - id: listen\n    type: io.kestra.core.models.triggers.types.Flow\n    conditions:\n    - type: io.kestra.core.models.conditions.types.ExecutionFlowCondition\n      namespace: dev\n      flowId: detect-data-drift\n    - type: io.kestra.core.models.conditions.types.VariableCondition\n      expression: \"{{outputs.detectDataDrift.vars.drift_detected}} == true\"\n```", "```py\nid: train-model\nnamespace: dev\ntasks:\n  - id: getCurrentTable\n    type: io.kestra.plugin.jdbc.postgresql.CopyOut\n    url: jdbc:postgresql://host.docker.internal:5432/\n    username: \"{{secret('POSTGRES_USERNAME')}}\"\n    password: \"{{secret('POSTGRES_PASSWORD')}}\"\n    format: CSV\n    sql: SELECT * FROM current\n    header: true\n  - id: wdir\n    type: io.kestra.core.tasks.flows.WorkingDirectory\n    tasks:\n      - id: cloneRepository\n        type: io.kestra.plugin.git.Clone\n        url: https://github.com/khuyentran1401/detect-data-drift-pipeline\n        branch: main\n      - id: saveCurrentToCSV\n        type: io.kestra.core.tasks.storages.LocalFiles\n        inputs:\n          data/current.csv: \"{{outputs.getCurrentTable.uri}}\"\n      - id: trainModel\n        type: io.kestra.plugin.scripts.python.Commands\n        beforeCommands:\n          - pip install -r src/train/requirements.txt\n        commands:\n          - python src/train/train_model.py\n      - id: saveToPickle\n        type: io.kestra.core.tasks.storages.LocalFiles\n        outputs:\n          - model.pkl\n  - id: upload\n    type: io.kestra.plugin.aws.s3.Upload\n    accessKeyId: \"{{secret('AWS_ACCESS_KEY_ID')}}\"\n    secretKeyId: \"{{secret('AWS_SECRET_ACCESS_KEY_ID')}}\"\n    region: us-east-2\n    from: '{{outputs.saveToPickle.uris[\"model.pkl\"]}}'\n    bucket: bike-sharing\n    key: model.pkl\ntriggers:\n  - id: listenFlow\n    type: io.kestra.core.models.triggers.types.Flow\n    conditions:\n      - type: io.kestra.core.models.conditions.types.ExecutionFlowCondition\n        namespace: dev\n        flowId: detect-data-drift\n      - type: io.kestra.core.models.conditions.types.VariableCondition\n        expression: \"{{outputs.detectDataDrift.vars.drift_detected}} == true\"After running this flow, the model.pkl file will be uploaded to the \"bike-sharing\" bucket.\n```"]