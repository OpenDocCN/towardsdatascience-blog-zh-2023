["```py\nfrom scipy import stats\nmean = [3,3]\nvar = [[6, 3],\n       [3, 3.5]]\nn = 100\ndata_raw = np.random.multivariate_normal(mean, var, 100)\n```", "```py\nimport numpy as np\ndata_centered = data_raw - np.mean(data_raw, axis=0)\n```", "```py\ncov_mat = np.matmul(data_centered.T, data_centered)/(len(data_centered) - 1)\n# > array([[5.62390186, 2.47275007],\n# >       [2.47275007, 3.19395349]])\n```", "```py\nfrom scipy.linalg import eigh\neigvals, eigvecs = eigh(cov_mat)\n\n# Sorting the eigenvalues and eigenvectors\nindices = eigvals.argsort()[::-1]\neigvals, eigvecs = eigvals[indices], eigvecs[:,indices]\n\neigvecs\n# > array([[-0.82348021,  0.56734499],\n# >        [-0.56734499, -0.82348021]])\n```", "```py\nmax_abs_cols = np.argmax(np.abs(eigvecs), axis=0)\nsigns = np.sign(eigvecs[max_abs_cols, range(eigvecs.shape[1])])\neigvecs = eigvecs*signs\neigvecs\n# > array([[ 0.82348021, -0.56734499],\n# >      [ 0.56734499,  0.82348021]])\n```", "```py\nnew_features = np.dot(data_centered, eigvecs)\n```", "```py\n# Variance of each individual component as bars\nplt.bar(\n    [f\"PC_{i}\" for i in range(1,len(eigvals)+1)],\n    eigvals/sum(eigvals)\n)\n\n# Percentage held by m components as the line\nplt.plot(\n    [f\"PC_{i}\" for i in range(1,len(eigvals)+1)],\n    np.cumsum(eigvals)/sum(eigvals),\n    color='red'\n)\nplt.scatter(\n    [f\"PC_{i}\" for i in range(1,len(eigvals)+1)],\n    np.cumsum(eigvals)/sum(eigvals),\n    color='red'\n)\n```", "```py\nfrom sklearn.datasets import make_blobs\nX, y = make_blobs()\n\nplt.scatter(X[:,0], X[:,1],c=y)\nplt.legend()\nplt.show()\n```", "```py\nimport numpy as np\nfrom scipy.linalg import eigh\n\nclass PCA:\n    \"\"\"Principal Component Analysis.\n    \"\"\"\n    def __init__(self, n_components):\n        \"\"\"Constructor of the PCA class.\n\n        Parameters:\n        ===========\n        n_components: int\n            The number of dimensions for the transformed data.\n            Must be less than or equal to n_features.\n        \"\"\"\n        self.n_components = n_components\n        self._fit_instance = False\n```", "```py\n def fit(self, X):\n        \"\"\"Compute eigenvectors to transform data later\n\n        Parameters:\n        ===========\n        X: np.array of shape [n_examples, n_features]\n            The data matrix\n\n        Returns:\n        ===========\n        None\n        \"\"\"\n        # Fit the mean of the data and center it\n        self.mean = np.mean(X, axis=0)\n        X_centered = X - self.mean\n\n        # Compute covariance matrix\n        cov_mat = np.matmul(X_centered.T, X_centered)/(len(X_centered) - 1)\n\n        # Compute eigenvalues, eigenvectors and sort them\n        eigenvalues, eigenvectors = eigh(cov_mat)\n        self.eigenvalues, self.eigenvectors = self._sort_eigen(eigenvalues, eigenvectors)\n\n        # Get the explained variance rations\n        self.explained_variance_ratio = self.eigenvalues/np.sum(self.eigenvalues)\n\n        # Enforce determinism by flipping the eigenvectors\n        self.eigenvectors = self._flip_eigenvectors(self.eigenvectors)[:, :self.n_components]\n\n        self._fit_instance = True\n```", "```py\n def transform(self, X):\n        \"\"\"Project the data in the directions of the eigenvectors.\n\n        Parameters:\n        ===========\n        X: np.array of shape [n_examples, n_features]\n            The data matrix\n\n        Returns:\n        ===========\n        pcs: np.array[n_examples, n_components]\n            The new, uncorrelated features from PCA.\n        \"\"\"\n        if not self._fit_instance:\n            raise Exception(\"PCA must be fitted to the data first! Call fit()\")\n\n        X_centered = X - self.mean\n        return np.dot(X_centered, self.eigenvectors)\n```", "```py\ndef fit_transform(self, X):\n       \"\"\"Fits PCA and transforms the data.\n       \"\"\"\n       self.fit(X)\n       return self.transform(X)\n```", "```py\n def _flip_eigenvectors(self, eigenvectors):\n        \"\"\"Enforce determinism by changing the signs of the eigenvectors.\n        \"\"\"\n        max_abs_cols = np.argmax(np.abs(eigenvectors), axis=0)\n        signs = np.sign(eigenvectors[max_abs_cols, range(eigenvectors.shape[1])])\n        return eigenvectors*signs\n\n    def _sort_eigen(self, eigenvalues, eigenvectors):\n        \"\"\"Sort eigenvalues in descending order and their corresponding eigenvectors.\n        \"\"\"\n        indices = eigenvalues.argsort()[::-1]\n        return eigenvalues[indices], eigenvectors[:, indices]\n```", "```py\nfrom pca import PCA\n\n# Using our PCA implementation\npca = PCA(n_components=1)\nX_transformed = pca.fit_transform(X)\n\n# Plotting the first PC\nplt.scatter(X_transformed[:,0], [0]*len(X_transformed),c=y)\nplt.legend()\nplt.show()\n```"]