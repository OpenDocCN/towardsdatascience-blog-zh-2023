- en: Understanding the Denoising Diffusion Probabilistic Model (DDPMs), the Socratic
    Way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/understanding-the-denoising-diffusion-probabilistic-model-the-socratic-way-445c1bdc5756?source=collection_archive---------2-----------------------#2023-02-25](https://towardsdatascience.com/understanding-the-denoising-diffusion-probabilistic-model-the-socratic-way-445c1bdc5756?source=collection_archive---------2-----------------------#2023-02-25)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A deep dive into the motivation behind the denoising diffusion model and detailed
    derivations for the loss function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://jasonweiyi.medium.com/?source=post_page-----445c1bdc5756--------------------------------)[![Wei
    Yi](../Images/24b7a438912082519f24d18e11ac9638.png)](https://jasonweiyi.medium.com/?source=post_page-----445c1bdc5756--------------------------------)[](https://towardsdatascience.com/?source=post_page-----445c1bdc5756--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----445c1bdc5756--------------------------------)
    [Wei Yi](https://jasonweiyi.medium.com/?source=post_page-----445c1bdc5756--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1b4bd5317a6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-denoising-diffusion-probabilistic-model-the-socratic-way-445c1bdc5756&user=Wei+Yi&userId=1b4bd5317a6e&source=post_page-1b4bd5317a6e----445c1bdc5756---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----445c1bdc5756--------------------------------)
    ·69 min read·Feb 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F445c1bdc5756&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-denoising-diffusion-probabilistic-model-the-socratic-way-445c1bdc5756&user=Wei+Yi&userId=1b4bd5317a6e&source=-----445c1bdc5756---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F445c1bdc5756&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-denoising-diffusion-probabilistic-model-the-socratic-way-445c1bdc5756&source=-----445c1bdc5756---------------------bookmark_footer-----------)![](../Images/207ffc71c7a7072f719d371f7f6f951f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Chaozzy Lin](https://unsplash.com/@chaozzy?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'The [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf)
    by Jonathan Ho et. al. is a great paper. But I had difficulty understanding it.
    So I decided to dive into the model and worked out all the derivations. In this
    article, I will focus on the two main obstacles to understand the paper:'
  prefs: []
  type: TYPE_NORMAL
- en: why is the denoising diffusion model designed in terms of the forward process,
    the forward process posteriors, and backward process. And what is the relationship
    among these processes? By the way, in this article I call the forward process
    posteriors “the reverse of the forward process” because I find the word “posteriors”
    confuses me, and/or subconsciously I want to avoid that word as it frightens me
    — every time it appears, things become complicated.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: how to derive the mysterious loss function. In the paper, there are many skipped
    steps in deriving the loss function *Lₛᵢₘₚₗₑ.* I went through all derivations
    to fill in the missing steps. Now I realize the derivation of the analytical formula
    for *Lₛᵢₘₚₗₑ* tells a truly beautiful Bayesian story. And after all the steps
    filled in, the whole story…
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
