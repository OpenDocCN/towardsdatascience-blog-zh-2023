- en: '4 Ways to Write Data To Parquet With Python: A Comparison'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/4-ways-to-write-data-to-parquet-with-python-a-comparison-3c4f54ee5fec?source=collection_archive---------1-----------------------#2023-03-13](https://towardsdatascience.com/4-ways-to-write-data-to-parquet-with-python-a-comparison-3c4f54ee5fec?source=collection_archive---------1-----------------------#2023-03-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn How To Efficiently Write Data To Parquet Format Using Pandas, FastParquet,
    PyArrow or PySpark.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://anbento4.medium.com/?source=post_page-----3c4f54ee5fec--------------------------------)[![Antonello
    Benedetto](../Images/bf802bb46dce03dd3bd4e17c1dffe5b7.png)](https://anbento4.medium.com/?source=post_page-----3c4f54ee5fec--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3c4f54ee5fec--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3c4f54ee5fec--------------------------------)
    [Antonello Benedetto](https://anbento4.medium.com/?source=post_page-----3c4f54ee5fec--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2d93b58a0f8a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-ways-to-write-data-to-parquet-with-python-a-comparison-3c4f54ee5fec&user=Antonello+Benedetto&userId=2d93b58a0f8a&source=post_page-2d93b58a0f8a----3c4f54ee5fec---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3c4f54ee5fec--------------------------------)
    ·7 min read·Mar 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3c4f54ee5fec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-ways-to-write-data-to-parquet-with-python-a-comparison-3c4f54ee5fec&user=Antonello+Benedetto&userId=2d93b58a0f8a&source=-----3c4f54ee5fec---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c4f54ee5fec&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F4-ways-to-write-data-to-parquet-with-python-a-comparison-3c4f54ee5fec&source=-----3c4f54ee5fec---------------------bookmark_footer-----------)![](../Images/39041e5a101311da2fe0002dd298f589.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[Photo by Dominika Roseclay](https://www.pexels.com/photo/background-of-pile-of-firewood-with-rough-surface-4318196/)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: On-Demand Courses | Recommended
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*A few of my readers have contacted me asking for on-demand courses to learn
    more about* ***Data Engineering with Python & PySpark****. These are 3 great resources
    I would recommend:*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '[**Data Streaming With Apache Kafka & Apache Spark Nano-Degree (UDACITY)**](https://imp.i115008.net/zaX10r)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Data Engineering Nano-Degree (UDACITY)**](https://imp.i115008.net/zaX10r)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Spark And Python For Big Data With PySpark (UDEMY)**](https://click.linksynergy.com/deeplink?id=533LxfDBSaM&mid=39197&murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fspark-and-python-for-big-data-with-pyspark%2F)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Spark 和 Python 用于大数据与 PySpark (UDEMY)**](https://click.linksynergy.com/deeplink?id=533LxfDBSaM&mid=39197&murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fspark-and-python-for-big-data-with-pyspark%2F)'
- en: '*Not a Medium member yet? Consider signing up with my* [*referral link*](https://anbento4.medium.com/membership)
    *to gain access to everything Medium has to offer for as little as $5 a month!*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*还不是 Medium 会员？考虑通过我的* [*推荐链接*](https://anbento4.medium.com/membership) *注册，每月仅需
    $5 即可访问 Medium 提供的所有内容！*'
- en: Introduction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In today’s data-driven world, efficient storage and processing of large datasets
    is a crucial requirement for many businesses and organisations. This is where
    the Parquet file format comes into play.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今数据驱动的世界中，大规模数据集的高效存储和处理是许多企业和组织的关键需求。这就是 Parquet 文件格式的作用所在。
- en: '[Parquet is a **columnar storage format** that is designed to optimise data
    processing and querying performance while minimising storage space.](https://www.databricks.com/glossary/what-is-parquet)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[Parquet 是一种**列式存储格式**，旨在优化数据处理和查询性能，同时最小化存储空间。](https://www.databricks.com/glossary/what-is-parquet)'
