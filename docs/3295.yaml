- en: Hidden Markov Models Explained with a Real Life Example and Python code
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/hidden-markov-models-explained-with-a-real-life-example-and-python-code-2df2a7956d65?source=collection_archive---------0-----------------------#2023-11-05](https://towardsdatascience.com/hidden-markov-models-explained-with-a-real-life-example-and-python-code-2df2a7956d65?source=collection_archive---------0-----------------------#2023-11-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://carolinabento.medium.com/?source=post_page-----2df2a7956d65--------------------------------)[![Carolina
    Bento](../Images/9585232979bf7c2dbad05934f0735d89.png)](https://carolinabento.medium.com/?source=post_page-----2df2a7956d65--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2df2a7956d65--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2df2a7956d65--------------------------------)
    [Carolina Bento](https://carolinabento.medium.com/?source=post_page-----2df2a7956d65--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe960c0367546&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhidden-markov-models-explained-with-a-real-life-example-and-python-code-2df2a7956d65&user=Carolina+Bento&userId=e960c0367546&source=post_page-e960c0367546----2df2a7956d65---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2df2a7956d65--------------------------------)
    ·14 min read·Nov 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2df2a7956d65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhidden-markov-models-explained-with-a-real-life-example-and-python-code-2df2a7956d65&user=Carolina+Bento&userId=e960c0367546&source=-----2df2a7956d65---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2df2a7956d65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhidden-markov-models-explained-with-a-real-life-example-and-python-code-2df2a7956d65&source=-----2df2a7956d65---------------------bookmark_footer-----------)![](../Images/418afba8ee3df1346601a1d1e5c1623f.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: '*Hidden Markov Models are probabilistic models used to solve real life problems
    ranging from something everyone thinks about at least once a week — how is the
    weather going to be like tomorrow?*[1] — *to hard molecular biology problems,
    such as predicting peptide binders to the human MHC class II molecule*[2].'
  prefs: []
  type: TYPE_NORMAL
- en: '*Hidden Markov Models are close relatives of Markov Chains, but their hidden
    states make them a unique tool to use when you’re interested in determining the
    probability of a sequence of random variables.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*In this article we’ll breakdown Hidden Markov Models into all its different
    components and see, step by step with both the Math and Python code, which emotional
    states led to your dog’s results in a training exam. We’ll be using the Viterbi
    Algorithm to determine the probability of observing a specific sequence of observations,
    and how you can use the Forward Algorithm to determine the likelihood of an observed
    sequence, when you’re given a sequence of hidden states.*'
  prefs: []
  type: TYPE_NORMAL
- en: The real world is full of phenomena for which we can see the final outcome,
    but can’t actually observe the underlying factors that generated those outcomes.
    One example is predicting the weather, determining if it’s going to be rainy or
    sunny tomorrow, based on past weather observations and the observed probabilities
    of the different weather outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Although driven by factors we can’t observe, with an **Hidden Markov Model**
    it’s possible to model these phenomena as probabilistic systems.
  prefs: []
  type: TYPE_NORMAL
- en: Markov Models with Hidden States
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Hidden Markov Models](https://en.wikipedia.org/wiki/Hidden_Markov_model),
    known as HMM for short, are statistical models that work as a sequence of labeling
    problems. These are the types of problems that describe the evolution of observable
    events, which themselves, are dependent on internal factors that can’t be directly
    observed — they are **hidden**[3].'
  prefs: []
  type: TYPE_NORMAL
- en: An Hidden Markov Model is made of two distinct [stochastic processes](https://en.wikipedia.org/wiki/Stochastic_process),
    meaning those are processes that can be defined as sequences of [random variables](https://en.wikipedia.org/wiki/Random_variable)
    — variables that depend on random events.
  prefs: []
  type: TYPE_NORMAL
- en: There’s an **invisible process** and an **observable process**.
  prefs: []
  type: TYPE_NORMAL
- en: The **invisible process** is a [Markov Chain](/markov-models-and-markov-chains-explained-in-real-life-probabilistic-workout-routine-65e47b5c9a73),
    like chaining together multiple **hidden states** that are traversed over time
    in order to reach an outcome. This is a probabilistic process because all the
    parameters of the Markov Chain, as well as the score of each sequence, are in
    fact probabilities[4].
  prefs: []
  type: TYPE_NORMAL
- en: Hidden Markov Models describe the evolution of observable events, which themselves,
    are dependent on internal factors that can’t be directly observed — they are **hidden**[3]
  prefs: []
  type: TYPE_NORMAL
- en: Just like any other [Markov Chain](/markov-models-and-markov-chains-explained-in-real-life-probabilistic-workout-routine-65e47b5c9a73),
    in order to know which state you’re going next, the only thing that matters is
    where you are now — in which state of the Markov Chain you’re currently in. None
    of the previous *history* of states you’ve been in the past matters to understand
    where you’re going next.
  prefs: []
  type: TYPE_NORMAL
- en: This kind of *short-term* memory is one of the key characteristics of HMMs and
    it’s called the **Markov Assumption**, indicating that the probability of reaching
    the next state is only dependent on the probability of the current state.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/097a3c7f00c78d7bb4e6a10be3600758.png)'
  prefs: []
  type: TYPE_IMG
- en: Markov Assumption. (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The other key characteristic of an HMM, is that it also assumes that each observation
    is only dependent on the state that produced it therefore, being completely independent
    from any other state in the chain[5].
  prefs: []
  type: TYPE_NORMAL
- en: The **Markov Assumption** states that the probability of reaching the next state
    is only dependent on the probability of the current state.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is all great background information on HMM but, what classes of problems
    are they actually used in?
  prefs: []
  type: TYPE_NORMAL
- en: 'HMMs help model the behavior of phenomena. Besides modeling and allowing to
    run simulations, you can also ask different types of questions those phenomena:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Likelihood** or **Scoring**, as in, determining the probability of observing
    a sequence'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decoding** the best sequence of states that generated a specific observation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learning** the parameters of the HMM that led to observing a given sequence,
    that traversed a specific set of states.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's see this in practice!
  prefs: []
  type: TYPE_NORMAL
- en: Dog Training Performance as an HMM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Today you’re not as worried about the weather forecast, what’s on your mind
    is that your dog is possibly graduating from their training lessons. After all
    the time, effort and dog treats involved, all you want is for them to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: During dog training sessions, your four-legged friend is expected to do a few
    actions or tricks, so the trainer can *observe* and grade their performance. After
    combining the scores of three trials, they’ll determine if your dog graduates
    or needs additional training.
  prefs: []
  type: TYPE_NORMAL
- en: The trainer only sees the outcome, but there are several factors involved that
    can’t be directly observed such as, if your dog is tired, happy, if they don’t
    like the trainer at all or the other dogs around them.
  prefs: []
  type: TYPE_NORMAL
- en: None of these are directly observed, unless there’s undoubtably a specific action
    your dog does only when they feel a certain way. Would be great if they could
    express how they feel in words, maybe in the future!
  prefs: []
  type: TYPE_NORMAL
- en: With Hidden Markov Models fresh in your mind, this looks like the perfect opportunity
    to try to predict how your dog was feeling during the exam. They might get a certain
    score because they were feeling tired, maybe they were hungry, or they were annoyed
    at the trainer.
  prefs: []
  type: TYPE_NORMAL
- en: Your dog has been taking lessons for a while and, based on data collected during
    that training, you have all the building blocks needed to build a Hidden Markov
    Model.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to build a HMM that models the performance of your dog in the training
    evaluation you need:'
  prefs: []
  type: TYPE_NORMAL
- en: Hidden States
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transition Matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence of Observations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observation Likelihood Matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Initial Probability Distribution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hidden States** arethose non-observable factors that influence the observation
    sequence. You’ll only consider if your dog is Tired or Happy.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/787e1db3f5cad33f98426995562f4dc4.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Different hidden states in the HMM. (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: Knowing your dog very well, the non-observable factors that can impact their
    exam performance are simply being tired or happy.
  prefs: []
  type: TYPE_NORMAL
- en: Next you need to know what’s the probability of going from one state to another,
    which is captured in a **Transition Matrix**. This matrix must also be [**row
    stochastic**](https://en.wikipedia.org/wiki/Stochastic_matrix) meaning that the
    probabilities from one state to any other state in the chain, each row in the
    matrix, must sum to one.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/33188ec7cf3bd8bc24208d2287b6f5fa.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Transition Matrix: represents the probability of moving from one state to
    another.* (Image by Author)'
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of what type of problem you’re solving for, you always need a **Sequence
    of Observations.** Each observation representing the result of traversing the
    Markov Chain. Each observation is drawn from a specific vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/303710a9d5933e8f0a24d35346e02be6.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Vocabulary (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of your dog’s exam you observe the score they get after each trial,
    which can be *Fail*, *OK* or *Perfect*. These are all the possible *terms* in
    the observation vocabulary.
  prefs: []
  type: TYPE_NORMAL
- en: You also need the **Observation Likelihood Matrix**, which is the probability
    of an observation being generated from a specific state.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/374897edecaebef5b8b473b802176c83.png)'
  prefs: []
  type: TYPE_IMG
- en: Observation Likelihood Matrix. (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Finally, there’s the **Initial Probability Distribution**. This is the probability
    that the Markov Chain will start in each specific hidden state.
  prefs: []
  type: TYPE_NORMAL
- en: There can also be some states will never be the starting state in the Markov
    Chain. In these situations, their initial probability is zero. And just like the
    probabilities in the Transition Matrix, these sum of all initial probabilities
    must add up to one.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/50d55e6acc0101b554e7719829e25c82.png)'
  prefs: []
  type: TYPE_IMG
- en: Initial Probabilities (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The Initial Probability Distribution, along with the Transition Matrix and the
    Observation Likelihood, make up the **parameters of an HMM**. These are the probabilities
    you’re figuring out if you have a sequence of observations and hidden states,
    and attempt to *learn* which specific HMM could have generated them.
  prefs: []
  type: TYPE_NORMAL
- en: Putting all of these pieces together, this is what the Hidden Markov model that
    represents your dog’s performance on the training exam looks like
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1a03ebaab0ee07dd8844ca64513e59b4.png)'
  prefs: []
  type: TYPE_IMG
- en: Hidden states and the transition probabilities between them. (Image by Autor)
  prefs: []
  type: TYPE_NORMAL
- en: During the exam, your dog will perform three trials, and graduate only if they
    don’t *Fail* in two of those trials.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the day, if your dog needs more training, you’ll care for them
    all the same. The big question circling your mind is *How are they feeling during
    the exam.*
  prefs: []
  type: TYPE_NORMAL
- en: Imagining a scenario where they graduate with a score of *OK — Fail — Perfect*
    exactly in this order, what sequence of emotional states will they be in? Will
    they be mostly tired, or hungry throughout, or maybe a mix of both?
  prefs: []
  type: TYPE_NORMAL
- en: This type of problem falls right under the category of *Decoding* problems that
    HMMs can be applied to. In this case, you’re interested figuring out what’s the
    best sequence of states that generated a specific sequence of observations, *OK
    — Fail — Perfect.*
  prefs: []
  type: TYPE_NORMAL
- en: The problem of decoding the sequence of states that generated a given sequence
    of observations leverages the **Viterbi Algorithm**. However, is worth doing a
    short detour and take a peek into how you could calculate the probability of a
    given observation sequence — a Likelihood task — using the **Forward Algorithm**.
    This will set the stage to better understanding how the Viterbi Algorithm works.
  prefs: []
  type: TYPE_NORMAL
- en: The Forward Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you were modeling this problem like a regular [Markov Chain](https://medium.com/p/65e47b5c9a73),
    and wanted to calculate the likelihood of observing the sequence of outcomes *OK,
    Fail, Perfect* you’d traverse the chain by landing in each specific state that
    generates the desired outcome. At each step you would take the conditional probability
    of observing the current outcome given that you’ve observed the previous outcome
    and multiply that probability by the transition probability of going from one
    state to the other.
  prefs: []
  type: TYPE_NORMAL
- en: The big difference is that, in a regular Markov Chain, all states are well known
    and observable. Not in an Hidden Markov Model! In an Hidden Markov Model you observe
    a sequence of outcomes, not knowing which specific sequence of hidden states had
    to be traversed in order to observe that.
  prefs: []
  type: TYPE_NORMAL
- en: The big difference is that, in a regular Markov Chain, all states are well known
    and observable. Not in an Hidden Markov Model!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: At this point you might be thinking, *Well I can simply traverse all possible
    paths and eventually have a rule to pick between equivalent paths.* The mathematical
    definition for this approach looks something like this
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/33c668175694c5cdd6158a95bfffe1f3.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Calculating the probability of observing a sequence of outcomes, traversing
    every hidden state sequence possible. (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: That’s one strategy for sure! You’d have to calculate the probability of observing
    the sequence *OK, Fail, Perfect* for every single combination of hidden states
    that could ever generate that sequence.
  prefs: []
  type: TYPE_NORMAL
- en: When you have a small enough number of hidden states and sequence of observed
    outcomes, it's possible to do that calculation within a reasonable time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/97983f02f7cfe479a82bfea5e9e494d7.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Outline of the possible paths in your HMM (Image by Author)*'
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, the Hidden Markov model you just defined is relatively simple, with
    3 observed outcomes and 2 hidden states.
  prefs: []
  type: TYPE_NORMAL
- en: For an observed sequence of length L outcomes, on a HMM with M hidden states,
    you have “M to the power L” possible states which in your case, means *2 to the
    power of 3*, i.e., 8 possible paths for the sequence *OK — Fail — Perfect,* involving
    an exponential computational complexity of O(M^L L), described in [Big O-Notation](https://en.wikipedia.org/wiki/Big_O_notation).
    As the complexity of the model increases, the number of paths you need to take
    into account grows exponentially.
  prefs: []
  type: TYPE_NORMAL
- en: As the complexity of the model increases, the number of paths you need to take
    into account grows exponentially.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is where the **Forward Algorithm** shines.
  prefs: []
  type: TYPE_NORMAL
- en: The Forward Algorithm calculates the probability of a new symbol in the observed
    sequence, without the need to calculate the probabilities of all possible paths
    that form that sequence [3].
  prefs: []
  type: TYPE_NORMAL
- en: Instead of computing the probabilities of all possible paths that form that
    sequence the algorithm defines the **forward variable** and calculates its value
    [recursively](https://en.wikipedia.org/wiki/Recursion).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cd803b5f94fc52d8c67669787bf43c05.png)'
  prefs: []
  type: TYPE_IMG
- en: How the forward variable is calculated recursively. (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The fact that it uses recursion, is the key reason why this algorithm is faster
    than calculating all the probabilities of possible paths. In fact, it can calculate
    the probability of observing the sequence *x* in only “L times M squared” computations,
    instead of “M to the power of L times L”.
  prefs: []
  type: TYPE_NORMAL
- en: In your case, with 2 hidden states and a sequence of 3 observed outcomes, it’s
    the difference between calculating the probabilities O(MˆL L) = 2³x3 *=* 8x3 *=*
    24 times, as opposed to O(L Mˆ2)*=*3*2²=3x4 = 12 times.
  prefs: []
  type: TYPE_NORMAL
- en: This reduction in the number of calculations is achieved by [Dynamic Programming](https://en.wikipedia.org/wiki/Dynamic_programming),
    a programming technique that uses an auxiliary data structures to store intermediate
    information, therefore making sure the same calculations are not done multiple
    times.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Every time the algorithm is about to calculate a new probability it checks if
    it has already computed it, and if so, it can easily access that value in the
    intermediate data structure. Otherwise, the probability is calculated and the
    value is stored.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get back to your decoding problem, using the Viterbi Algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The Viterbi Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Thinking in *pseudo code*, If you were to brute force your way into decoding
    the sequence of hidden states that generate a specific observation sequence, all
    you needed to do was:'
  prefs: []
  type: TYPE_NORMAL
- en: generate all possible permutations of paths that lead to the desired observation
    sequence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use the Forward Algorithm to calculate the likelihood of each observation sequence,
    for each possible sequence of hidden states
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pick the sequence of hidden states with highest probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/844da6164710e90f629645ea79e948a8.png)'
  prefs: []
  type: TYPE_IMG
- en: All possible hidden state sequences that generate the observation sequence *OK
    — Fail — Perfect* (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: For your specific HMM, there are 8 possible paths that lead to an outcome of
    *OK — Fail — Perfect*. Add just one more observation, and you’ll have double the
    amount of possible sequences of hidden states! Similarly to what was described
    for the Forward Algorithm, you easily end up with an exponentially complex algorithm
    and hit performance ceiling.
  prefs: []
  type: TYPE_NORMAL
- en: The Viterbi Algorithm, gives you a hand with that.
  prefs: []
  type: TYPE_NORMAL
- en: When the sequence of hidden states in the HMM is traversed, at each step, the
    probability *vt(j)* is the probability that the HMM is in the hidden state *j*
    after seeing the observation and is being traversed through the most probable
    state that lead to *j*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/287242d38d5a258ccf9cba1292bb79aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Viterbi path to hidden state *j* on time step *t.* (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: The key to decoding the sequence of hidden states that generate a specific observation
    sequence, is this concept of the **most probable path**. Also called the **Viterbi
    path,** the most probable path, is the path that has highest likelihood, from
    all the paths that can lead to any given hidden state.
  prefs: []
  type: TYPE_NORMAL
- en: The key to decoding the sequence of hidden states that generate a specific observation
    sequence, is to use the Viterbi path. The most probable path that leads to any
    given hidden state.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You can draw a parallel between the Forward Algorithm and the Viterbi Algorithm.
    Where the Forward Algorithm sums all probabilities to obtain the likelihood of
    reaching a certain state taking into account all the paths that lead there, the
    Viterbi algorithm doesn’t want to explore all possibilities. It focuses on the
    most probable path that leads to any given state.
  prefs: []
  type: TYPE_NORMAL
- en: Going back to the task of decoding the sequence of hidden states that lead to
    the scores of OK — Fail — Perfect in their exam, *running* the **Viterbi Algorithm**
    by hand would look like this
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/786b06523dc656786c27591176108ea4.png)'
  prefs: []
  type: TYPE_IMG
- en: Viterbi paths and decoded sequence. (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Another unique characteristic of the Viterbi algorithm is that it must have
    a way to keep track of all the paths that led to any given hidden state, in order
    to compare their probabilities. To do that it keeps track of **backpointers**
    to each hidden state, using an auxiliary data structure typical of dynamic programming
    algorithms. That way it can easily access the probability of any viterbi path
    traversed in the past.
  prefs: []
  type: TYPE_NORMAL
- en: '**Backpointers are the key to figure out the most probable path that leads
    to an observation sequence.**'
  prefs: []
  type: TYPE_NORMAL
- en: In the example of your dogs’ exam, when you calculate the Viterbi paths *v3(Happy)*
    and *v3(Tired)*, you pick the path with highest probability and start going backwards,
    i.e., backtracking, through all the paths that led to where you are.
  prefs: []
  type: TYPE_NORMAL
- en: The Viterbi Algorithm in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Doing all of this by hand is time consuming and error prone. Miss one significant
    digit and you might have to start from scratch and re-check all your probabilities!
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that you can leverage software libraries like [hmmlearn](https://hmmlearn.readthedocs.io/en/stable/tutorial.html),
    and with a few lines of code you can decode the sequence of hidden states that
    lead to your dog graduating with *OK — Fail — Perfect* in the trials, exactly
    in this order.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In a few seconds you get an output that matches results the calculations you
    did by hand, much fast and with much less room for error.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41b354a93fb104c925d85c22edcd5966.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of running the code above. (Image by Author)
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What’s fascinating about Hidden Markov Models is how this statistical tool created
    in the mid 1960’s [6] is so powerful and applicable to real world problems in
    such distinct areas, from weather forecasting to finding the next word in a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, you had the chance to learn about the different components
    of an HMM, how they can be applied to different types of tasks, and spotting the
    similarities between the Forward Algorithm and Viterbi Algorithm. Two very similar
    algorithms that use dynamic programming to deal with the exponential number of
    calculations involved.
  prefs: []
  type: TYPE_NORMAL
- en: Either doing the calculations by hand or plugging in the parameters into TensorFlow
    code, hope you enjoyed diving deep into the world of HMMs.
  prefs: []
  type: TYPE_NORMAL
- en: '*Thank you for reading!*'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'D. Khiatani and U. Ghose, “Weather forecasting using Hidden Markov Model,”
    2017 International Conference on Computing and Communication Technologies for
    Smart Nation (IC3TSN), Gurgaon, India, 2017, pp. 220–225, doi: 10.1109/IC3TSN.2017.8284480.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Noguchi H, Kato R, Hanai T, Matsubara Y, Honda H, Brusic V, Kobayashi T. Hidden
    Markov model-based prediction of antigenic peptides that interact with MHC class
    II molecules. J Biosci Bioeng. 2002;94(3):264–70\. doi: 10.1263/jbb.94.264\. PMID:
    16233301.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Yoon BJ. [Hidden Markov Models and their Applications in Biological Sequence
    Analysis](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2766791/). Curr Genomics.
    2009 Sep;10(6):402–15\. doi: 10.2174/138920209789177575\. PMID: 20190955; PMCID:
    PMC2766791.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Eddy, S. [What is a hidden Markov model?](https://www.nature.com/articles/nbt1004-1315).
    *Nat Biotechnol* **22**, 1315–1316 (2004). [https://doi.org/10.1038/nbt1004-1315](https://doi.org/10.1038/nbt1004-1315)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Jurafsky, Dan and Martin, James H.. *Speech and language processing : an introduction
    to natural language processing, computational linguistics, and speech recognition*.
    Upper Saddle River, N.J.: Pearson Prentice Hall, 2009.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Baum, Leonard E., and Ted Petrie. “[Statistical Inference for Probabilistic
    Functions of Finite State Markov Chains.](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-37/issue-6/Statistical-Inference-for-Probabilistic-Functions-of-Finite-State-Markov-Chains/10.1214/aoms/1177699147.full)”
    *The Annals of Mathematical Statistics* 37, no. 6 (1966): 1554–63.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
