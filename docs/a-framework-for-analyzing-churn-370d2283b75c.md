# 分析流失的框架

> 原文：[https://towardsdatascience.com/a-framework-for-analyzing-churn-370d2283b75c?source=collection_archive---------4-----------------------#2023-01-13](https://towardsdatascience.com/a-framework-for-analyzing-churn-370d2283b75c?source=collection_archive---------4-----------------------#2023-01-13)

## 使用模拟数据集进行客户流失分析的逐步指南

[](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)[![Gabriele Albini](../Images/153b88c71ea4e5e221a90de3caa71cdb.png)](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------) [Gabriele Albini](https://gabri-albini.medium.com/?source=post_page-----370d2283b75c--------------------------------)

·

[阅读](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F93c18fcb4ee6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&user=Gabriele+Albini&userId=93c18fcb4ee6&source=post_page-93c18fcb4ee6----370d2283b75c---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----370d2283b75c--------------------------------) ·14分钟阅读·2023年1月13日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F370d2283b75c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&user=Gabriele+Albini&userId=93c18fcb4ee6&source=-----370d2283b75c---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F370d2283b75c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-framework-for-analyzing-churn-370d2283b75c&source=-----370d2283b75c---------------------bookmark_footer-----------)![](../Images/62f0f24f3727ca4e6109e0031b5222d6.png)

图片来源：[JESHOOTS.COM](https://unsplash.com/@jeshoots?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

# 介绍

“*客户流失*”已经成为一个常见的商业词汇，它指的是流失率的概念，维基百科定义为：

> “在给定时间段内离开供应商的合同客户或订阅者的比例”

从数据角度分析流失时，我们通常意味着使用现有工具提取有关现有客户群的信息，具体来说：量化当前的流失率并了解可能影响/预防未来流失的因素。

因此，当我们开发“流失模型”时，应该考虑使用现有数据并且要有两个目标：

1.  为现有活跃客户预测流失

1.  对影响客户流失决策的因素进行一些假设，识别出可能减少流失的潜在措施。

预测流失需要大量工作，这不是一项容易的任务，但更重要的是，它甚至不是*最终*目标：这是设计和实施客户“*留存*”策略的起点！

本文将重点介绍流失分析框架的实现，灵感来源于书籍：[1]*《用数据对抗流失》*，作者是卡尔·S·戈德。这是一本推荐给所有处理流失数据的人的优秀书籍：书中详细介绍了流失分析的全过程，提供了很多细节和示例（包括解释代码！）。在所有建议的步骤中，我提取了在我的经验中最相关和成功的部分，并将其调整为我熟悉的背景和数据集。本文将该框架应用于一个模拟数据集，灵感来源于一个真实的商业案例（[Github 仓库链接](https://github.com/gabri-al/churn_analysis)）。

## 目录：

1- [数据](#5487)

1.1- [开发流失模型时应考虑哪些数据？](#d95f)

1.2- [原始数据](#d95f)

2- [数据预处理：流失指标](#c74a)

2.1- [创建客户指标](#652c)

2.2- [分析流失指标](#048e)

3- [使用机器学习进行流失预测](#179c)

3.1- [逻辑回归](#179c)

3.2- [随机森林](#ba22)

3.3- [XGBoost](#481c)

4- [生成流失预测](#bd49)

5- [下一步](#f279)

[参考文献](#f062)

# 1. 数据

## 1.1 开发流失模型时应考虑哪些数据？

这不是一个简单的问题！很多不同的信息可能与流失相关，制定通用规则永远无法涵盖所有可能的业务、系统、背景等。例如，在考虑流失相关信息时，我们可能会考虑：

+   关于客户（或账户）的基本信息：性别、位置、年龄、任期等

+   与订阅相关的信息：客户订阅的产品、激活的附加功能、激活和取消日期等

+   支付信息：客户支付了多少？他们使用什么支付方式？他们是否定期付款？

+   产品使用信息：登录信息、点击信息、与产品的互动分钟数等

+   与客户支持互动相关的信息：客户进行的聊天或电话、支持服务的评分、投诉细节等

+   …

翻译成系统后，这些数据需要来自各种事务系统（CRM、ERP、计费等），并应适当地组织到某些数据湖/数据仓库中（理想情况下，频繁地拍摄覆盖几个月）。考虑到这一点，需要有大量的专业知识来了解哪些字段代表了哪些信息，通常，访问这些数据需要大量的批准，特别是如果外部顾问想要使用这些数据的话。

根据我的经验，所有这些数据（以及相关的历史记录）***很少可用***。通常，可用且已组织的数据是公司因财务或法律法规要求或仅因运行日常业务所需的数据。这些数据必须在*某处*可用。

例如：假设我们是一家提供按需视频培训的公司，我们需要知道客户拥有哪些订阅以及他们支付了多少，以提供我们的服务并制作财务报表。然而，我们不一定需要存储客户 XYZ 在完成特定视频之前暂停视频的具体时间。

鉴于所有这些原因，为了保持文章简洁和现实，我将重点关注一个“较小”的数据集，理想情况下这些数据应来自任何 CRM 中应有的数据。

## 1.2 原始数据

让我们假设我们是一家通过网站提供在线视频课程的 B2C（商业对消费者）公司。我们的业务运作方式如下：

+   新用户可以订阅两个领域的课程：机器学习（领域 A）和吉他（领域 B）。他们可以购买多个订阅，从而允许不同用户同时登录。此外，他们还可以选择包含“附加服务”的选项，该服务包括每周与所选领域的专家进行在线直播。

+   一旦订阅，用户将每月支付费用，并可能有或没有折扣。他们可以随时取消订阅，这意味着订阅将在月底不会续订。

+   用户可以打开实时聊天并联系支持团队解决任何问题。

原始数据将如下所示：

![](../Images/6a32434a393847910e9f5f5026ede0a6.png)

虚拟原始数据 | 图片来源作者

这种商业背景非常常见，适用于任何具有每月订阅和将附加服务添加到基本报价的 B2C 业务（例如：按需媒体内容、电信、公用事业、电子商务、保险和高级软件等企业）。

# 2. 数据预处理：流失指标

从原始数据开始，我们需要预测客户是否会流失。我们将把客户视为一个整体，无论他们有多少个订阅。

由于我们的目标是预测流失以制定留存策略，我们需要提前知道客户是否会流失，以便我们可以采取措施影响这一决定。

## 2.1 创建客户指标

考虑到以上原始数据，我们可以生成哪些KPI？以下是一些想法（它们是我们[数据集](https://github.com/gabri-al/churn_analysis)的列）：

+   “mrr_ratio” = 这是按订阅计算的每月经常性收入。因此，对于每个客户：我们对每个有效订阅求和([每月费用 — 折扣])，然后计算有效订阅的数量，并将两者相除。

+   “mrr_ratio_A”和“mrr_ratio_B” = 这些是按领域计算的每月经常性收入（A是机器学习；B是吉他），考虑领域内的mrr和活跃订阅数量。

+   “subs_A”和“subs_B” = 按领域的活跃订阅数量

+   “discount_ratio” = 客户的折扣百分比，计算方法为：1 — ([每月费用 — 折扣] / [每月费用])

+   “has_addon” = 一个标志，指示客户是否有至少一个带附加组件的订阅

+   “support_chats” = 客户在一个期间内发起的聊天次数

+   “is_churn” = 一个标志，指示客户是否将要流失（1）或不流失（0）

我认为使用我们历史原始数据来计算这些KPI的最佳方法是：

+   确定一些固定的观察期（例如每月20号），留出一些合理的时间从我们的续订（我们假设每月30号发生）。

+   创建一个表“A”，在其中，对于每一个“流失”的客户，我们包括他们过去的流失日期。

+   创建另一个表“B”，其中，对于每个客户，在每月20号，我们根据过去30天的数据计算KPI。换句话说，我们每月20号对客户指标进行月度快照。

+   我们将表“A”和“B”按客户ID连接，并标记所有将在下一个观察日期流失的行。

这些观察期和KPI通常在数据仓库中计算，然后导出到Python。我为项目模拟的数据正好代表了这种情况。假设我们刚刚从数据仓库中获得了以下数据集：

![](../Images/d22561b15385296e33661df0a17cb897.png)

虚拟流失指标 | 图片由作者提供

(*注意：这是一个模拟数据集。所有连续指标都从一个多变量高斯分布中提取，近似真实数据。这就是为什么我们有负值和应不为负值或小数的KPI的原因。此外，每一行应对应一个客户ID，但此信息并不相关*)。

## 2.2 分析流失指标

一旦我们拥有一些指标，我们可以开始检查它们与流失的关系。

最直观的方式来调查这种关系是通过**队列分析**。通常，通过将每个指标数据拆分成10个相等大小的桶来生成10个队列，具体取决于它们的值。然后，我们通过计算每个队列中的流失率，将每个指标与“is_churn”标志相关联。如果指标不是连续的且具有少于10个分类值，那么我们只考虑每个类别一个队列。

在左侧图表中，我们可以看到，平均而言，拥有更高mrr_ratio的客户流失更多，因为他们每个订阅支付更多：

![](../Images/635ff9d13ee409337f67d4cb586b2783.png)

流失指标队列 | 作者提供的图像

每当我们看到这样的行为，具有逻辑意义，并且根据指标值，我们看到流失有显著差异时，我们可以期望该指标在我们的分析中是相关的。

相反，如果我们看到指标中，无论队列的平均值如何，对流失没有影响（例如水平线），那么我们可能会考虑将该指标从模型中排除。

# 3\. 机器学习中的流失预测

我们现在将使用数据集来预测流失。

请注意，流失的预测是*不简单*的。决定流失是主观的，而且可能并不总是一个逻辑选择：一个客户可能因为费用问题而流失，其他客户可能因为质量问题而流失。此外，糟糕的客户服务或对产品/品牌的负面感受也可能主观地引发流失决定。

基于这些原因，模型的表现不会像其他机器学习任务那样高。根据Carl S. Gold [1]的说法，一个健康的流失预测模型的AUC得分应在0.6到0.8之间。

需要考虑的一些因素：

+   流失是一个二分类任务：模型将学习预测记录是否属于类1（流失客户）或类0（未流失）。然而，我们将关注***每条记录属于每个类别的概率***。在选择模型时，请记住这一点。

+   模型表现不能通过准确率来衡量。通常，少数客户流失，因此我们的数据集是不平衡的：仅约10%的虚拟数据属于类1（流失客户）。任何总是预测类0的模型将具有90%的准确率，但这样的模型完全没有帮助。相反，我们将使用***roc_auc得分***来衡量性能。

+   我们将使用交叉验证来调整模型的超参数。由于我们处理的是时间序列数据集，我们不能简单地使用随机记录分配到每个折叠。我们需要训练我们的模型使用当前或过去的数据，而不是未来的数据。因此，最佳实践建议使用***时间序列分割***（来自[sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) [2]），它适用于任何按时间排序的数据集。

*(注意：在交叉验证中，通常使用10个拆分。这里由于数据量有限和数据对类0极度不平衡，使用了3个拆分)。*

现在让我们比较三种分类模型。

## 3.1 逻辑回归

逻辑回归是一个广义的线性回归模型，这是一种非常常见的分类技术，尤其用于二分类问题。由于它是一个回归模型，许多假设需要事先验证；例如，我们不应违反“无多重共线性”假设，这意味着我们需要确保没有特征是相关的，即每个特征应提供独特且独立的信息。

尽管这很容易验证，我可以预见逻辑回归不会是性能最好的模型，因此我们不会使用我们可能获得的任何无效结果。

![](../Images/ddf9b140349ae80c8918d589f967f132.png)

逻辑回归 | 作者插图

## 3.2 随机森林

随机森林是一种基于树的集成方法。

**基于树的方法** 是非常强大的分类（或回归）算法，它们通过根据多个决策节点来划分我们的训练数据。每个决策节点根据特定特征执行一次“划分”，做出 True / False 决策。划分决策的确定方式是为了在树的下一层尽可能减少我们的数据集的“熵”。熵是数据无序程度的度量，它与我们在分类/回归任务中可以获得的“信息增益”相关。

+   例如，在一个二分类问题中，如果我们注意到通过根据一个特征来划分数据，我们得到的每个 True/False 结果分支中——95% 的数据属于一个类别，5% 的数据属于另一个类别，那么我们就成功地从数据中获得了更多的信息，降低了数据的无序程度或“熵”。

**随机森林（RF）** 构建了多个不同的树，然后取这些树的平均值或最频繁的结果来做最终预测。RF 确保每棵树与其他树的构建方式不同，这得益于两种方法：

+   *Bagging（自助聚合）*：每棵树都是通过使用整个训练集的样本进行训练的，因此每棵树都是使用不同的数据构建的。

+   *特征随机性*：每棵树都是通过限制可用特征来构建的，使用所有可用特征的一个子集。

现在让我们在数据集上调整 RF 的超参数，选择最佳模型，并展示最“重要”的特征（即每个特征用于生成决策分裂的频率）：

![](../Images/7740711313d8cd5ad8592673f7393a6e.png)

随机森林 | 作者插图

## 3.3 XGBoost

**XGBoost** 代表极端梯度提升，它是另一种基于树的集成技术，与 RF 类似，允许将多个决策树的预测结果进行结合。

XGBoost 是“*梯度提升*”方法的一个进化（“极端”）版本。因此，为了说明 XGBoost，让我们分别考察这两个方面。

+   在“**梯度提升**”方法中，与随机森林（RF）不同，构建的树之间有很大关联。预测是由“弱学习者”（即简单树）做出的，这些树会不断改进。通常，初始预测是目标值的平均值，然后通过创建新树进行精炼。每棵新树是基于前一棵树的错误构建的：因此，从前一轮“弱学习者”的残差/错误预测开始，建立新树，最小化成本函数，并对产生错误的属性分配更多权重。最后，通过加权每棵树的结果来组合结果。

+   从“梯度提升”开始，“**极端梯度提升**”是一个完整的算法，包括对梯度提升方法的几项改进，如性能优化和正则化参数（可以避免过拟合）。最重要的是，得益于这些附加元素，XGBoost 可以在像普通笔记本电脑这样的简单机器上运行。

![](../Images/96ab1b8c02fcb003325095f5156fd0db.png)

# 4\. 生成流失预测

表现最好的模型是 XGBoost，我们将使用它来预测 [测试集](https://github.com/gabri-al/churn_analysis)（包含在训练阶段未使用的新记录）的流失概率。

在导入测试集后，我们计算每条记录属于类别 1（流失客户）的模型预测概率，并绘制 ROC_AUC 分数：

![](../Images/4d6614cfc76923e1c41fea03710f7904.png)

测试集 AUC 分数 | 图片由作者提供

让我们将预测的类别添加到原始数据中。默认情况下，所有预测概率 ≥ .5 的记录将被分配到类别 1。我们可以降低这个阈值，并比较结果的混淆矩阵：

![](../Images/73e0e8b5c3e031a17c9c1ba91e67bca9.png)

混淆矩阵 | 图片由作者提供

通过降低阈值，我们可以识别更多的流失客户（真正的正例和假阳性），但仍有相当数量的客户会流失但我们未能识别（假阴性），尽管我们的 xgboost 模型表现良好。

我们可以尝试找到更好的模型，但预测流失通常很困难。因此，除了使用简单的流失与非流失区分外，一个想法是利用我们预测的概率来定义一些不同的留存策略：

+   对于预测概率大于 .75 的客户 = 高风险流失，我们可以设计一种“强力”的留存策略。由于我们预期的假阳性很少，因此我们可以更有信心地对这些客户进行投资。

+   预测概率在 .5 和 .75 之间的客户 = 中等流失风险和“中等”留存策略。

+   预测概率在 .25 和 .5 之间的客户 = 低风险流失和“弱”留存策略。

# 5\. 下一步

在这个阶段，我们应该有一个能够为任何新数据分配“流失概率”的工作模型。

我们分析的下一步是进一步定义前面提到的保留策略。我们的策略应包括：（a）可能导致流失减少的行动；（b）如何衡量我们行动的成功；（c）最后，推广计划。

这里有一些解决这些问题的想法：

## 确定导致流失减少的行动：

让我们结合上面看到的特征重要性与我们的预测。例如，两个基于树的模型将“**subs_B**”列为树中使用最多的特征。我们需要深入了解流失和非流失客户在subs_B方面的情况。之前看到的群体分析将有助于这里：

![](../Images/1da13d54c6f5d5cd0201a9bd691951a4.png)

在训练数据上进行群体分析 | 作者图像

看起来高流失的客户有最低值（即0订阅，数据已经被转换，因此x轴值在这里不太易于解释），或者“subs_B”的数量过多。我们必须小心地得出“subs_B”和“is_churn”之间的因果结论，因为此分析并未证明任何因果关系。然而，我们可以测试一些假设：

+   看起来客户对我们的B产品感到满意，将“B”产品交叉销售给仅拥有A产品的客户，是否有助于减少流失？

+   我们还应该了解客户拥有这么多“B”订阅背后的业务原因。我们可以教育他们更有效地使用我们的产品，从而减少B订阅。

## **如何衡量我们行动的成功**：

一旦我们确定了一些建议的行动，我们可以规划我们的测量方法。

A/B 测试是一种非常常见的方式：

+   我们从具有类似预测流失概率的客户中创建两个可比样本。一个样本将代表我们的处理组，并将暴露于我们的流失减少策略，另一个样本将代表我们的对照组，不会暴露于任何保留行动。

+   我们希望证明我们的处理组的流失率显著低于对照组。

## **推广计划：**

在建议保留行动时，我们不应忘记考虑其他背景因素。举几个例子：流失的担忧程度如何？（即是否有大量新客户以弥补流失？）解决问题的预算是多少？我们应该等多久才能看到结果？我们可以使用其他数据来改善模型吗？已经做了哪些工作？

这将帮助我们了解我们建议的可行性。

谢谢阅读！！

# 参考文献

[1] Carl S. Gold — “用数据对抗流失：客户保留的科学与策略”，2020年

[2] [Scikit-learn: Python中的机器学习](https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html)，Pedregosa *等*，JMLR 12，第2825–2830页，2011年
