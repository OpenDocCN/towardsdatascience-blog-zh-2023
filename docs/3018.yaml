- en: Summing Coin Values in Images using Lang-SAM and Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Lang-SAM和深度学习在图像中求和硬币值
- en: 原文：[https://towardsdatascience.com/coin-counting-using-lang-sam-b469827808a7?source=collection_archive---------9-----------------------#2023-10-03](https://towardsdatascience.com/coin-counting-using-lang-sam-b469827808a7?source=collection_archive---------9-----------------------#2023-10-03)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/coin-counting-using-lang-sam-b469827808a7?source=collection_archive---------9-----------------------#2023-10-03](https://towardsdatascience.com/coin-counting-using-lang-sam-b469827808a7?source=collection_archive---------9-----------------------#2023-10-03)
- en: '[](https://medium.com/@gamzsaglam?source=post_page-----b469827808a7--------------------------------)[![Gamze
    Zorlubas](../Images/30d8e1604a22dc6f1bd3ef96c8092cc1.png)](https://medium.com/@gamzsaglam?source=post_page-----b469827808a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b469827808a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b469827808a7--------------------------------)
    [Gamze Zorlubas](https://medium.com/@gamzsaglam?source=post_page-----b469827808a7--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@gamzsaglam?source=post_page-----b469827808a7--------------------------------)[![Gamze
    Zorlubas](../Images/30d8e1604a22dc6f1bd3ef96c8092cc1.png)](https://medium.com/@gamzsaglam?source=post_page-----b469827808a7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b469827808a7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b469827808a7--------------------------------)
    [Gamze Zorlubas](https://medium.com/@gamzsaglam?source=post_page-----b469827808a7--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd24f99cbdd78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcoin-counting-using-lang-sam-b469827808a7&user=Gamze+Zorlubas&userId=d24f99cbdd78&source=post_page-d24f99cbdd78----b469827808a7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b469827808a7--------------------------------)
    ·10 min read·Oct 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb469827808a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcoin-counting-using-lang-sam-b469827808a7&user=Gamze+Zorlubas&userId=d24f99cbdd78&source=-----b469827808a7---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd24f99cbdd78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcoin-counting-using-lang-sam-b469827808a7&user=Gamze+Zorlubas&userId=d24f99cbdd78&source=post_page-d24f99cbdd78----b469827808a7---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b469827808a7--------------------------------)
    ·10 min read·Oct 3, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb469827808a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcoin-counting-using-lang-sam-b469827808a7&user=Gamze+Zorlubas&userId=d24f99cbdd78&source=-----b469827808a7---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb469827808a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcoin-counting-using-lang-sam-b469827808a7&source=-----b469827808a7---------------------bookmark_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb469827808a7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcoin-counting-using-lang-sam-b469827808a7&source=-----b469827808a7---------------------bookmark_footer-----------)'
- en: In the latest developments of computer vision, image segmentation has seen impressive
    progress. A standout example is the “Segment Anything”Model (SAM), a dynamic deep-learning
    tool that predicts object masks from images using input prompts. Thanks to its
    advanced encoding and decoding capabilities, SAM can manage diverse segmentation
    challenges, proving invaluable for both researchers and developers.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉的最新进展中，图像分割取得了显著的进展。一个突出例子是“Segment Anything”模型（SAM），这是一个动态深度学习工具，通过输入提示从图像中预测对象掩码。得益于其先进的编码和解码能力，SAM能够处理各种分割挑战，对研究人员和开发者都极为宝贵。
- en: Lang-SAM is a project built on SAM. It extracts the masks of all instances of
    the objects within the image we want with a text prompt. It intelligently incorporates
    textual descriptions, bridging the gap between natural language processing and
    computer vision. This fusion allows for more context-aware, precise, and detailed
    segmentations, expanding the scope of intricate imaging challenges beyond traditional
    capabilities.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Lang-SAM是一个基于SAM的项目。它通过文本提示提取图像中所有对象实例的掩码。它智能地结合了文本描述，弥合了自然语言处理和计算机视觉之间的差距。这种融合允许更加上下文感知、精确和详细的分割，将复杂的图像挑战扩展到超越传统能力的范围。
- en: 'Having explored the capabilities of the SAM model, I found an exemplary use-case:
    estimating the total value of coins in an image that also includes various other
    objects. Let’s dive deeper into how SAM operates and examine how I’ve incorporated
    it into my coin summing project for both generating datasets and testing the neural
    network.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索了SAM模型的能力后，我发现了一个典型的用例：估算包含各种其他对象的图像中硬币的总价值。让我们深入了解SAM的操作，并查看我如何将其应用到我的硬币计数项目中，以生成数据集和测试神经网络。
- en: 1\. Segment-Anything
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. Segment-Anything
- en: Facebook’s research team, FAIR, introduced their segmentation model, SAM, in
    2022\. What’s amazing about SAM is that it can recognize and separate parts of
    images in ways it wasn’t specifically trained for.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Facebook的研究团队FAIR在2022年推出了他们的分割模型SAM。SAM令人惊叹的是，它能够识别和分离图像的部分，而不是专门为此训练的。
- en: '![](../Images/6ed1295bd8cc2faed82d6065a98be3a4.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ed1295bd8cc2faed82d6065a98be3a4.png)'
- en: 'Figure 1: SAM’s model architecture provided by Meta, downloaded by [https://segment-anything.com/](https://segment-anything.com/)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：由Meta提供的SAM模型架构，通过[https://segment-anything.com/](https://segment-anything.com/)下载
- en: 'At its core, SAM has three main parts: it understands the image, takes a prompt
    or command, and then creates a mask based on that command. To train SAM, Facebook
    created the biggest image dataset ever, called SA-1B, through a detailed three-step
    process. In technical terms, SAM uses a system similar to other popular models,
    but with its own unique features. Sometimes when given a vague command, it makes
    multiple guesses and picks the best one. In tests, SAM did better than other models
    on 23 different datasets. They even combined SAM with another tool for tasks like
    finding and highlighting specific objects in images.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: SAM的核心有三个主要部分：它理解图像，接受提示或命令，然后根据该命令创建掩码。为了训练SAM，Facebook创建了有史以来最大的图像数据集SA-1B，通过详细的三步过程。技术上，SAM使用了与其他流行模型类似的系统，但具有自己独特的特征。有时在给定模糊命令时，它会进行多次猜测并选择最佳结果。在测试中，SAM在23个不同数据集上的表现优于其他模型。它们甚至将SAM与其他工具结合使用，用于寻找和突出图像中的特定对象等任务。
- en: '**Although SAM was trained with a text encoder for text prompts, Meta hasn’t
    released the weights with text encoder. Therefore, only box or point prompts are
    available in the current public model.**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**尽管SAM使用文本编码器进行了文本提示训练，但Meta尚未发布带有文本编码器的权重。因此，当前公开模型中仅提供框或点提示。**'
- en: 2\. Language-Segment-Anything (Lang-SAM)
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. Language-Segment-Anything (Lang-SAM)
- en: To overcome the block of text prompts of SAM, Luca Medeiras made an open-source
    project called [Language-Segment-Anything (Lang-SAM)](https://github.com/luca-medeiros/lang-segment-anything/tree/main).
    Lang-SAM deploys GroundingDino and SAM sequentially. GroundingDino is a text-to-bounding
    box model to which user feeds an image and a text prompt; the model finds the
    masks of those objects based on the text prompt. These bounding boxes are then
    used as input prompts for the SAM model, which generates precise segmentation
    masks for the identified objects.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决SAM的文本提示问题，Luca Medeiras创建了一个名为[Language-Segment-Anything (Lang-SAM)](https://github.com/luca-medeiros/lang-segment-anything/tree/main)的开源项目。Lang-SAM依次部署了GroundingDino和SAM。GroundingDino是一个文本到边界框的模型，用户输入图像和文本提示，该模型根据文本提示找到这些对象的掩码。这些边界框然后用作SAM模型的输入提示，SAM生成识别对象的精确分割掩码。
- en: 'The following is the code snippet for running Lang-SAM in Python:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用Python运行Lang-SAM的代码片段：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Using the given code above, I made a test of segmentation of bicycles in an
    image. Results are visualized in the figure below.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述代码，我对图像中的自行车进行了分割测试。结果在下图中可视化。
- en: '![](../Images/7ba5ef5077ca262ef8595466b2f3e893.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7ba5ef5077ca262ef8595466b2f3e893.png)'
- en: 'Figure 2: Example segmentation result of Lang-SAM — Image by the author'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：Lang-SAM的示例分割结果 — 作者提供的图像
- en: 'Use-case for Lang-SAM: Counting the sum of coins'
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Lang-SAM的用例：硬币总和计数
- en: '![](../Images/d17dbba0ca3aa37fcb96ce499b19cc08.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d17dbba0ca3aa37fcb96ce499b19cc08.png)'
- en: 'Figure 3: Workflow of coin summing — Image by the author'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：硬币计数工作流程 — 作者提供的图像
- en: Let’s firstly decide on the worklow of the coin counting. As a general idea,
    we will have images in which there are various coins.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们决定硬币计数的工作流程。大致来说，我们将有包含各种硬币的图像。
- en: As a first step of the workflow, we can segment each coin in input image. This
    step can be done by using Lang-SAM as it enables us simply enter ‘coin’ as the
    text prompt. After getting coin masks, we can use a convolutional neural network
    to estimate the classes of coins. This neural network can be a custom one which
    we train with a dataset generated using Lang-SAM. Details of the architecture
    and how I trained it is given in **Step 2**, below. In the last step, estimated
    classes are simply summed up.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作为工作流程的第一步，我们可以对输入图像中的每个硬币进行分割。此步骤可以通过使用Lang-SAM来完成，因为它允许我们简单地输入“硬币”作为文本提示。在获得硬币掩码后，我们可以使用卷积神经网络来估算硬币的类别。这个神经网络可以是一个自定义的网络，我们用使用Lang-SAM生成的数据集来训练。架构细节和训练方法在**第2步**中给出。在最后一步中，估算的类别将被简单地汇总。
- en: 'Step 1: Usage of Lang-SAM'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第1步：使用Lang-SAM
- en: For segmenting coins in an image, I wrote the following function which takes
    an image as input and returns the masks and boxes of each coin in the image by
    using Lang-SAM model. Boxes of individual coins are used only in the visualisation
    purposes later on; thus not significant for now.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在图像中分割硬币，我编写了以下函数，该函数以图像作为输入，通过使用Lang-SAM模型返回每个硬币的掩码和框。单个硬币的框仅在后续的可视化过程中使用，因此目前并不重要。
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: From the input image containing multiple coins, the provided function above
    produces segmentation masks, which are showcased in the image below. However,
    the segmentation masks generated are in the image’s original resolution. Given
    that a significant portion of the segmented image, roughly 95%, is dominated by
    empty sections, this can be seen as redundant information. Such excessive data
    causes computational challenges when inputting into a neural network for subsequent
    training phases. To address this, I’ll be introducing a subsequent function to
    crop and focus on the relevant segmented regions, optimizing the data for further
    processing.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从包含多个硬币的输入图像中，提供的上述函数生成了分割掩码，如下图所示。然而，生成的分割掩码为图像的原始分辨率。由于分割图像的95%左右被空白区域占据，这可能被视为冗余信息。这种过多的数据在输入到神经网络进行后续训练阶段时会造成计算挑战。为了解决这个问题，我将引入一个后续函数，以裁剪和聚焦相关的分割区域，优化数据以便进一步处理。
- en: '![](../Images/dbf501cf27da63a18333f6e904b57db5.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dbf501cf27da63a18333f6e904b57db5.png)'
- en: 'Figure 4: input and outputs of find_coin_masks function — Image by the author'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：find_coin_masks函数的输入和输出 — 作者提供的图像
- en: I’ve created another function named `generate_coin_images`. This function starts
    by using `find_coin_mask` to get the masks in their original size. Next, it crops
    out the black area around the masks. The final mask is then resized to a standard
    size of 500x500 pixels. If the section with the coin is bigger than this size,
    it adjusts it to fit the 500x500 size, making sure we have a consistent input
    for our next steps.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了另一个名为`generate_coin_images`的函数。该函数首先使用`find_coin_mask`获取原始大小的掩码。接着，它裁剪掉掩码周围的黑色区域。最终掩码被调整为500x500像素的标准大小。如果包含硬币的区域大于这个尺寸，它会调整以适应500x500的大小，确保我们在下一步中有一致的输入。
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `generate_coin_images` function produces coin images, as exemplified below.
    Later on we will use this function when we create the dataset to train the neural
    network and also in our test pipeline . We can say that this function is the backbone
    of the project.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`generate_coin_images`函数生成硬币图像，如下所示。稍后我们将在创建数据集以训练神经网络时以及在测试流程中使用此函数。我们可以说这个函数是项目的核心。'
- en: '![](../Images/e4edaed257f58eacfadb2f69270d6a02.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4edaed257f58eacfadb2f69270d6a02.png)'
- en: 'Figure 5: input and outputs of generate_coin_images function — Image by the
    author'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：generate_coin_images函数的输入和输出 — 作者提供的图像
- en: 'Step 2: Creating a Coin Estimator Neural Network'
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步：创建硬币估算神经网络
- en: '*Step 2.1: Dataset Generation*'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*第2.1步：数据集生成*'
- en: 'Recognizing the absence of a dedicated dataset for European coins, I took the
    initiative to create one for my project. I sourced photos of six distinct European
    coin denominations from this [GitHub page](https://github.com/kaa/coins-dataset)
    : 2 euros, 1 euro, 50 cents, 20 cents, 10 cents, and 5 cents. Each image contained
    only a single coin, ensuring consistency in the dataset.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到缺乏专门的欧洲硬币数据集，我主动为我的项目创建了一个。我从这个[GitHub页面](https://github.com/kaa/coins-dataset)获取了六种不同欧洲硬币面值的照片：2欧元、1欧元、50分、20分、10分和5分。每张图片只包含一枚硬币，确保数据集的一致性。
- en: Utilizing the `generate_coin_image` function (which I previously described),
    I extracted and saved a masked version of each coin. These images were then systematically
    organized into folders based on their respective denominations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 利用`generate_coin_image`函数（我之前描述过的），我提取并保存了每个硬币的掩码版本。这些图像然后被系统地组织到以各自面额为基础的文件夹中。
- en: 'For clarity, the training dataset consists of 2,739 images, distributed across
    the six classes as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清晰起见，训练数据集由2,739张图像组成，分布在六个类别中，如下所示：
- en: '2 euros: 292 images'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2欧元：292张图像
- en: '1 euro: 301 images'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1欧元：301张图像
- en: '50 cents: 747 images'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 50美分：747张图像
- en: '20 cents: 444 images'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20美分：444张图像
- en: '10 cents: 662 images'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10美分：662张图像
- en: '5 cents: 293 images'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5美分：293张图像
- en: 'And the validation set consists of 73 images, distributed across the six classes
    as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 验证集由73张图像组成，分布在六个类别中，如下所示：
- en: '2 euros: 5 images'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2欧元：5张图像
- en: '1 euro: 12 images'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1欧元：12张图像
- en: '50 cents: 8 images'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 50美分：8张图像
- en: '20 cents: 17 images'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20美分：17张图像
- en: '10 cents: 16 images'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10美分：16张图像
- en: '5 cents: 15 images'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5美分：15张图像
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The image below provides a visual representation of our segmentation procedure,
    showing the processing of a 1 euro coin photo for dataset creation. Post-segmentation,
    the individual coin images are stored in the ‘1e/’ directory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下图提供了我们分割程序的可视化表示，显示了处理1欧元硬币照片以创建数据集的过程。分割后，单个硬币图像被存储在‘1e/’目录中。
- en: '![](../Images/dc5dda0f1d1fbadeaa359f872afa156e.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc5dda0f1d1fbadeaa359f872afa156e.png)'
- en: 'Figure 6: Dataset generation workflow’s input and outputs — Image by the author'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：数据集生成工作流程的输入和输出 — 作者提供的图片
- en: '*Step 2.2: Training*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2.2：训练*'
- en: 'The architecture of the neural network comprises two main components: several
    convolutional layers designed to extract spatial features from the input image,
    and two dense layers responsible for the final classification.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的架构包括两个主要组件：几个卷积层，用于从输入图像中提取空间特征，以及两个密集层，负责最终分类。
- en: Specifically, the network starts by takes and RGB input image with 500x500x3
    shape. As it progresses through the convolutional layers, the number of channels
    increases, with each convolution being followed by a ReLU activation. By a stride
    of 2 in these layers, the spatial dimensions of the feature maps are reduced at
    each stage, resulting in a encoding effect.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，网络从一个500x500x3形状的RGB输入图像开始。随着网络经过卷积层，通道数增加，每个卷积后跟一个ReLU激活。通过在这些层中使用步幅为2，特征图的空间维度在每个阶段都减少，产生编码效果。
- en: Following the convolutional stages, the spatial features are then flattened
    and passed to two fully connected layers. The output from the final layer provides
    a probability distribution across the classes, with a softmax activation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积阶段之后，空间特征被展平并传递到两个全连接层。最终层的输出提供了一个跨类别的概率分布，使用softmax激活。
- en: '![](../Images/de99e36e9f39987edc9b380251e9f72a.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/de99e36e9f39987edc9b380251e9f72a.png)'
- en: 'Figure 7: NN architecture of coin estimator — Image by the author'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：硬币估计器的神经网络架构 — 作者提供的图片
- en: I used Adam optimizer and Cross Entropy Loss to train the model. The training
    was continued until a point of saturation was noticed in the validation loss,
    which occurred at the 15th epoch.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用Adam优化器和交叉熵损失来训练模型。训练持续进行，直到验证损失出现饱和点，这发生在第15个epoch。
- en: '*Step 2.3: Performance benchmark*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2.3：性能基准测试*'
- en: Upon concluding the training, I proceeded to benchmark the checkpoint from the
    final epoch utilizing the script provided below. I used the function `compute_accuracy`
    given below, which takes the model and data loader as arguments, and computes
    the percentage of accurate predictions within the given dataset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成训练后，我利用下面提供的脚本对最后一个epoch的检查点进行了基准测试。我使用了下面提供的`compute_accuracy`函数，该函数接受模型和数据加载器作为参数，并计算给定数据集中的准确预测百分比。
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The subsequent computation of the average accuracy for both training and validation
    datasets are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 随后计算的训练集和验证集的平均准确率如下：
- en: 'training set: 87%'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集：87%
- en: 'validation set: 95%'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证集：95%
- en: The validation accuracy exceeded the training accuracy, potentially due to the
    relatively smaller size of the validation set. It’s vital to note that the primary
    intent of this project is to illustrate a potential application for new segmentation
    models rather than to construct a high-performance coin estimation network. Therefore,
    a deeper analytical dive into these observations will not be conducted.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 验证准确率超过了训练准确率，这可能是由于验证集相对较小。值得注意的是，项目的主要目的是展示新分割模型的潜在应用，而不是构建一个高性能的硬币估计网络。因此，对这些观察结果的深入分析将不会进行。
- en: 'Step 3: Pipeline of Coin Counting'
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步：硬币计数的流程
- en: Having trained the coin estimator network, all steps of the workflow, outlined
    in Figure 3, are now complete. Now, let’s come up with the pipeline that leverages
    both Lang-SAM and our custom Neural Network (NN) from end to end, aiming to calculate
    the total value of coins in an image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练了硬币估计网络后，图3中概述的所有工作流程步骤现已完成。现在，让我们构建一个从头到尾利用Lang-SAM和我们的自定义神经网络（NN）的流程，旨在计算图像中硬币的总价值。
- en: I created a Python notebook named `coin_counter.ipynb` which guides through
    the counting steps. Just like in the process we used to create our dataset, initially
    the `generate_coin_images` function is employed to make a mask for each coin in
    the image. Then, each of these masks is individually fed into the coin estimator
    network. Finally, the predicted coin values are added up to find the total amount
    of money in the image.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了一个名为`coin_counter.ipynb`的Python笔记本，该笔记本指导了计数步骤。就像我们在创建数据集的过程中一样，最初使用`generate_coin_images`函数为图像中的每个硬币生成掩膜。然后，这些掩膜会被逐一输入到硬币估计网络中。最后，将预测的硬币值相加，以找出图像中的总金额。
- en: Test Results
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试结果
- en: The coin image shown in Figure 3 was fed into the coin counting pipeline. The
    image below, which includes estimated class overlays, is presented below. While
    there are some incorrect estimations, the overall performance is acceptable.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图3中的硬币图像被输入到硬币计数流程中。下方的图像包含了估计的类别叠加。虽然有些估计不准确，但总体性能是可以接受的。
- en: '![](../Images/b9434b38d6a441ba7128792b92ccdc96.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b9434b38d6a441ba7128792b92ccdc96.png)'
- en: As mentioned earlier, the primary goal of this project is to demonstrate a potential
    application for new segmentation models that can take text input rather than to
    build a high-performance coin estimation network.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，本项目的主要目标是展示一种可以接受文本输入的新分割模型的潜在应用，而不是构建一个高性能的硬币估计网络。
- en: Here is my [Github repo](https://github.com/gamzez/lang-segment-anything) in
    which you can find the codes used throughout this blog.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我的[Github repo](https://github.com/gamzez/lang-segment-anything)，你可以在其中找到本博客中使用的代码。
- en: Thanks for reading my blog!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读我的博客！
