- en: It’s not all about scores
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/its-not-all-about-scores-1a5d97ea981d?source=collection_archive---------22-----------------------#2023-03-27](https://towardsdatascience.com/its-not-all-about-scores-1a5d97ea981d?source=collection_archive---------22-----------------------#2023-03-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Other criteria you should consider during model selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@doriandrost?source=post_page-----1a5d97ea981d--------------------------------)[![Dorian
    Drost](../Images/1795395ad0586eafd83d3e2f7b975ca8.png)](https://medium.com/@doriandrost?source=post_page-----1a5d97ea981d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1a5d97ea981d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1a5d97ea981d--------------------------------)
    [Dorian Drost](https://medium.com/@doriandrost?source=post_page-----1a5d97ea981d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F1d49ea537d1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fits-not-all-about-scores-1a5d97ea981d&user=Dorian+Drost&userId=1d49ea537d1c&source=post_page-1d49ea537d1c----1a5d97ea981d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1a5d97ea981d--------------------------------)
    ·8 min read·Mar 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1a5d97ea981d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fits-not-all-about-scores-1a5d97ea981d&user=Dorian+Drost&userId=1d49ea537d1c&source=-----1a5d97ea981d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1a5d97ea981d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fits-not-all-about-scores-1a5d97ea981d&source=-----1a5d97ea981d---------------------bookmark_footer-----------)![](../Images/c31db6f4c5aafd7f57312b3f605a67bb.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The difference between model selection and donut selection: In model selection,
    you can only choose one. Photo by [ELISA KERSCHBAUMER](https://unsplash.com/@__elisa__?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
  prefs: []
  type: TYPE_NORMAL
- en: As a data scientist or machine learning engineer, you spend much of your time
    improving a model’s performance by creating new features, comparing different
    types of models, trying out new model architectures, and much more. In the end,
    it’s the score on the test set that counts, so that is what you focus on when
    deciding on a model. However, as important as the model performance may be, there
    are other, secondary criteria you shouldn’t forget about.
  prefs: []
  type: TYPE_NORMAL
- en: What do you get from a model with almost perfect scores, if your MLOps department
    can’t host it? How does the user feel, if the prediction is accurate, but it takes
    ages to get it? What do you do, if your model performs well on the data you trained
    it with but becomes worse with time and you can’t adapt it to new data?
  prefs: []
  type: TYPE_NORMAL
- en: These are some examples of things to keep in mind when deciding on a model or
    an algorithm to use. In this article, I want to draw your attention to some secondary
    criteria for model selection that are often overlooked, although they can have
    a huge influence on the user’s experience.
  prefs: []
  type: TYPE_NORMAL
- en: 1) Inference speed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/056eab5ae327a83dc92ed8358ca22906.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [George Brynzan](https://unsplash.com/@nitros?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your model’s use case, speed can matter. If the prediction of your
    model is done in the background and asynchronously, it doesn’t matter whether
    it takes a few seconds more, but in scenarios where the user actively waits for
    the prediction, every tenth of a second could influence the user experience drastically.
    In machine learning, we often think about the time it takes to train a model,
    but the computation time of the inference is often neglected.
  prefs: []
  type: TYPE_NORMAL
- en: In easy tasks that are performed many times in a row, correcting a few more
    errors can be worth it if you get the predictions faster. Say your job is to mark
    all penguins on images presented to you. Luckily you don’t have to start from
    scratch, but there is an AI that already detects some of the penguins and draws
    bounding boxes around them, so you have to verify them, add missing bounding boxes,
    or correct them if they are not accurate. In that scenario, speed matters. A few
    points less on accuracy score cause you to correct the AI’s prediction more often
    but that is your job anyway. However, it would slow you down much more, if you
    needed to wait several seconds for each image to get the AI’s prediction.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, it is not always worth sacrificing accuracy over speed, of
    course. If you are a doctor who gets support from an AI that can detect malign
    parts of an X-ray image, it doesn’t matter if the prediction takes a few seconds
    more. You will need the prediction a few times per day only, and here accuracy
    is the most important aspect. As a patient, you wouldn’t want a false diagnosis
    just because it’s fast, would you?
  prefs: []
  type: TYPE_NORMAL
- en: 2) Retraining
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/3c888984071d58b841524535be346e62.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Danil Shostak](https://unsplash.com/@max010?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Most of the time, your model’s score is just a momentary snapshot on a specific
    and static test set. Of course, the score on this test set allows you to infer
    the model’s performance on real data to some extent, but you should always be
    aware, that the world out there may change over time. In that case, you need to
    be able to react accordingly. Even if you are able to collect new data, retraining
    a deep neural network may become very intensive in time and resources. In some
    scenarios, a more simple model can be the better choice, if you retrain it every
    night or every week.
  prefs: []
  type: TYPE_NORMAL
- en: Retraining or other ways of adapting a model’s behavior can become important
    if the data you work with is not complete or it is very heterogeneous and you
    are not able to reach the point where your model generalizes well to new data.
    If you create an AI that writes stories in a given author’s style that may work
    well for the authors it knows. However, how should it be able to write a novel
    in the style of Jane Austen, if it has never read any of her stories? With new
    authors appearing you may have to retrain the model from time to time. That becomes
    harder, the more parameters your model has.
  prefs: []
  type: TYPE_NORMAL
- en: There are even cases where you have to train multiple models, e.g. one for each
    of your customers. This can happen when data is so diverse, that training with
    data from customer X harms the model performance for customer Y. If your AI creates
    business plans for companies, it might appear to you, that the data differs very
    much between those. Some companies’ revenues are heavily influenced by the global
    economic situation, while others are rather stable. Some companies are on the
    market for a long time already and wish for sustainability, while others are very
    young and aim at rapid growth. As the data is so diverse, onboarding a new customer
    may include retraining or finetuning the model on their company’s data. It could
    also be because of legal reasons that you are not allowed to use data from customer
    X to create predictions for customer Y so you would have to train a new model
    for each customer. The longer the model needs to train, the more time and money
    it costs for each new customer.
  prefs: []
  type: TYPE_NORMAL
- en: 3) Deployability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/e2817d99414e7f5d5e19fdd536d02b59.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Ian Taylor](https://unsplash.com/@carrier_lost?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The best model is worth nothing if it can’t be used by anyone. There are multiple
    ways of bringing a model to the end user, which vary from hosting services on
    cloud servers to installing programs on your user’s devices. Which way to take
    depends on your use case, hence the model you decide on needs to fit the required
    way of deploying it.
  prefs: []
  type: TYPE_NORMAL
- en: Bigger models need longer to load and need more resources. A Docker container
    that needs to unpack a neural network plus related packages can easily be multiple
    gigabytes in size. A few more gigabytes on a cloud provider cost some money, and
    you can decide whether this is worth it, but if your users need to download the
    model, the problem may become even bigger. On a modern laptop, installing a few
    gigabytes may not be a problem, but if your main target group is living in less
    developed countries and uses phones that are a few years old, memory and computing
    power may become an issue.
  prefs: []
  type: TYPE_NORMAL
- en: If you train an AI to detect vermin or diseases in crop plants that will be
    used in Africa or South America primarily, you should expect that your users don’t
    have a stable internet connection. Hence the application should be able to run
    offline, which means the users have to download the model and compute the prediction
    on a smartphone that may be some years old and has limited resources. In that
    case, a smaller, more simple model may be the better choice, even if the deep
    neural network has better scores.
  prefs: []
  type: TYPE_NORMAL
- en: As already mentioned above, there are even cases where you need to host multiple
    models (e.g. one per customer). Here the model size becomes even more crucial.
    Deploying one neural network may be possible, but are you also able to host a
    hundred different ones? If not, smaller models may be the better option.
  prefs: []
  type: TYPE_NORMAL
- en: 4) Explainability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/4d5c958de3c557e4dced1ea93cc03392.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Crissy Jarvis](https://unsplash.com/@crissyjarvis?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: For a good reason, explainable AI becomes more and more important in current
    research. Most of the time we just accept, that most machine learning approaches
    are black boxes that give a model prediction without any possibility to explain
    why the model behaved in a certain way. However, there are many use cases in which
    such an explainability would help gain the user’s trust or enhance their experience.
    For a doctor, it is hard to decide how to continue if an AI makes a surprising
    diagnosis that is not explained, and a finance investor may not follow a model’s
    prediction if they can’t make any sense of it. Critical or sensitive decisions
    as they appear in health- or finance-related tasks, may need more explanation
    than other, less critical tasks. If the AI, that makes the pictures on your phone
    searchable, doesn’t find the image you are looking for, you may not care why.
    Here a better model performance would enhance your experience much more.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding explainability, simple models are often easier to understand than
    bigger ones. In linear regression, the weights have a clear meaning, whereas in
    a deep neural network they form a black box altogether. There is growing effort
    in making deep learning models understandable as well though, with [ELI5](https://eli5.readthedocs.io/en/latest/)
    being one of the most prominent examples. The model or algorithm that appears
    more trustworthy to the user may be used more often, even if its scores are lower
    than those of a competing model. You wouldn’t invest money only because an AI
    tells you to do so without explaining why, would you?
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I just showed you some criteria, that can be relevant for model selection,
    although they are often neglected. Of course, none of these is the most important
    criterion per se, and so isn’t the model’s score. In the end, you have to balance
    all criteria according to your use case. Instead of looking at the score alone,
    you may ask yourself whether you also considered the other criteria in an appropriate
    way:'
  prefs: []
  type: TYPE_NORMAL
- en: Is the model’s prediction still fast enough? Will my users actively wait for
    the model prediction? If so, is the inference time appropriate?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Am I able to host this model at all? Do I have the resources for that? Is a
    small improvement in score really worth having a bigger model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do I expect my data to change over time? If so, will I be able to retrain my
    model regularly?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do I still understand my model? Is it okay to have a black-box model, or is
    explainability in my case worth more than accuracy?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many other criteria, that can be important for different use cases,
    so start thinking about them when you are selecting your model. It’s not all about
    the scores!
  prefs: []
  type: TYPE_NORMAL
- en: '*Like this article?* [*Follow me*](https://medium.com/@doriandrost) *to be
    notified of my future posts.*'
  prefs: []
  type: TYPE_NORMAL
