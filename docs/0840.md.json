["```py\nversion: '3'\n\nservices:\n  spark:\n    build: .\n    environment:\n      - SPARK_MODE=master\n    ports:\n      - '8080:8080'\n      - '4040:4040'\n    volumes:\n      - ./data:/data\n      - ./src:/src\n  spark-worker:\n    build: .\n    environment:\n      - SPARK_MODE=worker\n      - SPARK_MASTER_URL=spark://spark:7077\n      - SPARK_WORKER_MEMORY=4G\n      - SPARK_EXECUTOR_MEMORY=4G\n      - SPARK_WORKER_CORES=4\n    volumes:\n      - ./data:/data\n      - ./src:/src \n```", "```py\nFROM docker.io/bitnami/spark:3.3.1\n\nCOPY *.jar $SPARK_HOME/jars\n\nRUN mkdir -p $SPARK_HOME/secrets\nCOPY ./src/credentials/gcp-credentials.json $SPARK_HOME/secrets/gcp-credentials.json\nENV GOOGLE_APPLICATION_CREDENTIALS=$SPARK_HOME/secrets/gcp-credentials.json\n\nRUN pip install delta-spark\n```", "```py\nmkdir -p ./data/\nmkdir -p ./src/credentials\nchmod -R 777 ./src\nchmod -R 777 ./data\n\nwget https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar\n```", "```py\ndocker compose up --build\n```", "```py\npython download_files.py\n```", "```py\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\nfrom delta import configure_spark_with_delta_pip\n\nMASTER_URI = \"spark://spark:7077\"\n\nif __name__ == \"__main__\":\n    # spark-submit --packages io.delta:delta-core_2.12:2.1.0 --master spark://spark:7077 insert_csv_into_delta_table_gcs.py\n\n    builder = SparkSession.builder\\\n        .master(MASTER_URI)\\\n        .appName(\"Insert CSV Censo into Delta Table\")\\\n        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n\n    spark = configure_spark_with_delta_pip(builder).getOrCreate()\n```", "```py\n# Read the CSV file\ndf_cursos = (\n    spark.read\n    .format(\"csv\")\n    .option(\"header\", \"true\")\n    .option(\"delimiter\", \";\")\n    .option(\"encoding\", \"ISO-8859-1\")\n    .option(\"inferSchema\", \"true\")\n    .load(\"/data/MICRODADOS_CADASTRO_CURSOS_*.CSV\") # read all csv files\n)\n```", "```py\n# Select Columns\ndf_cursos = df_cursos.select(\n    [   \n        # Year\n        \"NU_ANO_CENSO\",\n        # Course AND Institution\n        \"CO_IES\",\n        \"NO_CURSO\",\n        \"CO_CURSO\",\n        # Total of new students\n        \"QT_ING\",\n        # Age\n        \"QT_ING_0_17\",\n        # ...\n        # Skin Color\n        \"QT_ING_BRANCA\",\n        \"QT_ING_PRETA\",\n        # ...\n        # Gender COLUMNS\n        # Place COLUMNS\n        # Area of Knowledge (CINE) COLUMNS\n        # FIELDS OMITTED TO MAKE THIS CODE BLOCK SMALLER\n    ]\n)\n\n# cast columns to the correct type\nfor col in df_cursos.columns:\n    if col in [\"NU_ANO_CENSO\"] or col.startswith(\"QT_\"):\n        df_cursos = df_cursos.withColumn(col, df_cursos[col].cast(IntegerType()))\n    elif col.startswith(\"IN_\"):\n        df_cursos = df_cursos.withColumn(col, df_cursos[col].cast(BooleanType()))\n    else:\n        df_cursos = df_cursos.withColumn(col, df_cursos[col].cast(StringType()))\n```", "```py\ndf_cursos.write\\\n        .format(\"delta\")\\\n        .partitionBy([\"NU_ANO_CENSO\"])\\\n        .mode(\"overwrite\")\\\n        .save(\"gs://censo-ensino-superior/cens_cursos\")\n```", "```py\n# cd into the folder where the script is stored\nspark-submit --packages io.delta:delta-core_2.12:2.1.0 --master spark://spark:7077 insert_csv_into_delta_table_gcs.py\n```", "```py\ndf_censo = (\n      spark.read\n          .format(\"delta\")\n          .load(\"gs://censo-ensino-superior/cens_cursos\")\n)\n```", "```py\n df_censo = (\n        df_censo\n        # Bachelor and Licenciatura TP_GRAU_ACADEMICO = 4\n        .filter( \n            (F.col('TP_GRAU_ACADEMICO') == \"1\")  \n            | (F.col('TP_GRAU_ACADEMICO') == \"4\")\n        )\n        # Group by CO_CINE_AREA_DETALHADA, CO_UF (STATE) and NU_ANO_CENSO (YEAR)\n        .groupBy(\n            'CO_CINE_AREA_DETALHADA', 'CO_UF', 'NU_ANO_CENSO'\n        )\n        .agg(\n            F.max('NO_CINE_AREA_DETALHADA').alias('NO_CINE_AREA_DETALHADA'),\n\n            F.max('NO_CINE_AREA_ESPECIFICA').alias('NO_CINE_AREA_ESPECIFICA'),\n            F.max('CO_CINE_AREA_ESPECIFICA').alias('CO_CINE_AREA_ESPECIFICA'),\n            F.max('NO_CINE_AREA_GERAL').alias('NO_CINE_AREA_GERAL'),\n            F.max('CO_CINE_AREA_GERAL').alias('CO_CINE_AREA_GERAL'),\n\n            F.max('SG_UF').alias('SG_UF'),\n            F.max('NO_REGIAO').alias('NO_REGIAO'),\n            F.max('CO_REGIAO').alias('CO_REGIAO'),\n\n            F.count('CO_CURSO').alias('QT_CO_CURSO'),\n            F.sum('QT_CURSO').alias('QT_CURSO'),\n            F.sum('QT_VG_TOTAL').alias('QT_VG_TOTAL'),\n            F.sum('QT_ING').alias('QT_ING'),\n\n            F.sum('QT_ING_0_17').alias('QT_ING_0_17'),\n            F.sum('QT_ING_18_24').alias('QT_ING_18_24'),\n            F.sum('QT_ING_25_29').alias('QT_ING_25_29'),\n            F.sum('QT_ING_30_34').alias('QT_ING_30_34'),\n            F.sum('QT_ING_35_39').alias('QT_ING_35_39'),\n            F.sum('QT_ING_40_49').alias('QT_ING_40_49'),\n            F.sum('QT_ING_50_59').alias('QT_ING_50_59'),\n            F.sum('QT_ING_60_MAIS').alias('QT_ING_60_MAIS'),\n\n            F.sum('QT_ING_BRANCA').alias('QT_ING_BRANCA'),\n            F.sum('QT_ING_PRETA').alias('QT_ING_PRETA'),\n            F.sum('QT_ING_PARDA').alias('QT_ING_PARDA'),\n            F.sum('QT_ING_AMARELA').alias('QT_ING_AMARELA'),\n            F.sum('QT_ING_INDIGENA').alias('QT_ING_INDIGENA'),\n            F.sum('QT_ING_CORND').alias('QT_ING_CORND'),\n\n            F.sum('QT_ING_FEM').alias('QT_ING_FEM'),\n            F.sum('QT_ING_MASC').alias('QT_ING_MASC'),\n        )\n    )\n```", "```py\ndf_censo.write\\\n    .format(\"bigquery\")\\\n    .mode(\"overwrite\")\\\n    .option(\"temporaryGcsBucket\", \"censo-ensino-superior\")\\\n    .option(\"database\", \"censo_ensino_superior\")\\\n    .option(\"table\", \"censo_ensino_superior.cursos_graduacao_e_licenciatura\")\\\n    .option(\"createDisposition\", \"CREATE_IF_NEEDED\")\\\n    .save()\n```", "```py\n# cd into the folder where the script is stored\nspark-submit --packages io.delta:delta-core_2.12:2.1.0,com.google.cloud.spark:spark-3.1-bigquery:0.28.0-preview aggregate_delta_gcs_to_gbq_table.py\n```", "```py\nSELECT\n  CO_CINE_AREA_GERAL,\n  NO_CINE_AREA_GERAL,\n  SUM(QT_ING_MASC)/SUM(QT_ING_FEM + QT_ING_MASC) AS PERCENT_MASC,\n  SUM(QT_ING_FEM)/SUM(QT_ING_FEM + QT_ING_MASC) AS PERCENT_FEM  \nFROM \n  `censo_ensino_superior.cursos_graduacao_e_licenciatura`\nGROUP BY\n  NO_CINE_AREA_GERAL,\n  CO_CINE_AREA_GERAL\nORDER BY\n  PERCENT_MASC\n```"]