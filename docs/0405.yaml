- en: Quantile Loss & Quantile Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分位数损失与分位数回归
- en: 原文：[https://towardsdatascience.com/quantile-loss-and-quantile-regression-b0689c13f54d?source=collection_archive---------0-----------------------#2023-01-28](https://towardsdatascience.com/quantile-loss-and-quantile-regression-b0689c13f54d?source=collection_archive---------0-----------------------#2023-01-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/quantile-loss-and-quantile-regression-b0689c13f54d?source=collection_archive---------0-----------------------#2023-01-28](https://towardsdatascience.com/quantile-loss-and-quantile-regression-b0689c13f54d?source=collection_archive---------0-----------------------#2023-01-28)
- en: Learn how to adjust regression algorithms to predict any quantile of data
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习如何调整回归算法以预测数据的任意分位数
- en: '[](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----b0689c13f54d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)
    ·6 min read·Jan 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb0689c13f54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----b0689c13f54d---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----b0689c13f54d---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)
    ·6 分钟阅读·2023年1月28日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb0689c13f54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&source=-----b0689c13f54d---------------------bookmark_footer-----------)![](../Images/5611fd790e61af7a5888d479182c3303.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb0689c13f54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&source=-----b0689c13f54d---------------------bookmark_footer-----------)![](../Images/5611fd790e61af7a5888d479182c3303.png)'
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: 'Regression is a machine learning task where the goal is to predict a real value
    based on a set of feature vectors. There exists a large variety of regression
    algorithms: linear regression, logistic regression, gradient boosting or neural
    networks. During training, each of these algorithms adjusts the weights of a model
    based on the loss function used for optimization.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 回归是一个机器学习任务，其目标是基于一组特征向量预测一个实际值。存在各种回归算法：线性回归、逻辑回归、梯度提升或神经网络。在训练过程中，这些算法中的每一个都根据用于优化的损失函数调整模型的权重。
- en: The choice of a loss function depends on a certain task and particular values
    of a metric required to achieve. Many loss functions (like MSE, MAE, RMSLE etc.)
    focus on predicting the expected value of a variable given a feature vector.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数的选择依赖于特定任务和所需实现的度量值。许多损失函数（如 MSE、MAE、RMSLE 等）专注于根据特征向量预测变量的期望值。
- en: In this article, we will have a look at a special loss function called **quantile
    loss** used to predict particular variable quantiles. Before diving into the details
    of quantile loss, let us briefly revise the term of a quantile.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将查看一种特殊的损失函数，称为 **分位损失**，用于预测特定变量分位数。在深入分位损失的细节之前，让我们简要回顾一下分位数的术语。
- en: Quantile
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分位数
- en: '**Quantile** qₐ is a value that divides a given set of numbers in a way at
    which α ** 100%* of numbers are less than the value and *(1 —* α*) * 100%* of
    numbers are greater than the value.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**分位数** qₐ 是一个值，它将给定的数字集合划分为使得 α ** 100%* 的数字小于该值，而 *(1 —* α*) * 100%* 的数字大于该值。'
- en: ''
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Quantiles *qₐ* for *α = 0.25*, *α = 0.5* and *α = 0.75* are often utilized in
    statistics and called **quartiles**. These quartiles are denoted as *Q₁*, *Q₂*
    and *Q₃* respectively. Three quartiles split data into 4 equal parts.
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分位数 *qₐ* 对于 *α = 0.25*、*α = 0.5* 和 *α = 0.75* 经常在统计中使用，被称为 **四分位数**。这些四分位数分别表示为
    *Q₁*、*Q₂* 和 *Q₃*。三个四分位数将数据分成4个相等的部分。
- en: ''
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Similarly, there are **percentiles** p which divide a given set of numbers by
    100 equal parts. A percentile is denoted as pₐ where α is the percentage of numbers
    less than the corresponding value.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 类似地，有 **百分位数** p，将给定的数字集合分成100个相等的部分。一个百分位数表示为 pₐ，其中 α 是小于相应值的数字百分比。
- en: ''
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Quartiles Q₁, Q₂ and Q₃ correspond to percentiles p₂₅, p₅₀ and p₇₅ respectively.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 四分位数 Q₁、Q₂ 和 Q₃ 分别对应于百分位数 p₂₅、p₅₀ 和 p₇₅。
- en: In the example below, for a given set of numbers, all three quartiles are found.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的例子中，找到了给定数字集合的所有三个四分位数。
- en: '![](../Images/1e633fb607505561ec4ec0cfae4388e8.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1e633fb607505561ec4ec0cfae4388e8.png)'
- en: An example showing all three quartiles for a given set of numbers. The first
    quartile Q₁ is equal to 10 because 25% of values are less than 10 and 75% of values
    are greater than 10\. The analogy proceeds to other quartiles.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例显示了给定数字集合的所有三个四分位数。第一个四分位数 Q₁ 等于10，因为25%的值小于10，而75%的值大于10。类似地，这种类推适用于其他四分位数。
- en: Quantile Loss
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分位损失
- en: Machine learning algorithms aiming to predict a particular variable quantile
    use quantile loss as the loss function. Before going to the formulation, let us
    consider a simple example.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 旨在预测特定变量分位的机器学习算法使用分位损失作为损失函数。在进行表述之前，让我们考虑一个简单的例子。
- en: Imagine a problem where the goal is to predict the 75-th percentile of a variable.
    In fact, this statement is equivalent to the one that prediction errors have to
    be negative in 75% of cases and in the other 25% to be positive. That is the actual
    intuition used behind the quantile loss.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一个问题，其目标是预测一个变量的第75百分位。实际上，这句话等同于预测误差在75%的情况下必须为负，而在其余25%的情况下必须为正。这就是在分位损失背后的实际直觉。
- en: Formulation
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 表述
- en: The quantile loss formula is illustrated below. The *α* parameter refers to
    the quantile which needs to be predicted.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 分位损失公式如下所示。*α* 参数指的是需要预测的分位数。
- en: '![](../Images/43ffa8a88f2448eaddd581099d93f5b0.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/43ffa8a88f2448eaddd581099d93f5b0.png)'
- en: Quantile loss formula
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 分位损失公式
- en: 'The value of quantile loss depends on whether a prediction is less or greater
    than the true value. To understand better the logic behind it, let us suppose
    we objective is to predict the 80-th quantile, thus the value of *α* = 0.8 is
    plugged into the equations. As a result, the formula looks like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 分位损失的值取决于预测值是否小于或大于真实值。为了更好地理解其背后的逻辑，假设我们的目标是预测第80分位数，因此将 *α* = 0.8 插入公式。结果，公式看起来是这样的：
- en: '![](../Images/2a3c161d2bf02c3166335aaa89b476b9.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2a3c161d2bf02c3166335aaa89b476b9.png)'
- en: Basically, in such a case, the quantile loss penalizes under-estimated predictions
    4 times more than over-estimated. This way the model will be more critical to
    under-estimated errors and will predict higher values more often. As a result,
    the fitted model on average will over-estimate results approximately in 80% of
    cases and in 20% it will produce under-estimated.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，在这种情况下，分位损失对低估的预测处罚是对高估的预测的4倍。这样，模型对低估的误差会更加严格，并且更频繁地预测较高的值。结果是，拟合的模型在平均情况下会高估结果，大约在80%的情况下，并且在20%的情况下会产生低估。
- en: 'Right now assume that two predictions for the same target were obtained. The
    target has a value of 40, while the predictions are 30 and 50\. Let us calculate
    the quantile loss in both cases. Despite the fact that the absolute error of 10
    is the same in both cases, the loss value is different:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设为同一目标获得了两个预测。目标值为40，而预测值为30和50。让我们计算两种情况的分位损失。尽管在两种情况下绝对误差都是10，但损失值却不同：
- en: for 30, the loss value is *l = 0.8 * 10 = 8*
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于30，损失值为*l = 0.8 * 10 = 8*
- en: for 50, the loss value is *l =* *0.2 * 10 = 2*.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于50，损失值为*l =* *0.2 * 10 = 2*。
- en: This loss function is illustrated in the diagram below which shows loss values
    for different parameters of *α* when the true value is 40.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图表显示了在真实值为40时，不同*α*参数的损失值。
- en: '![](../Images/4c46d9641fbb078300e4dab010df206c.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4c46d9641fbb078300e4dab010df206c.png)'
- en: Inversely, if the value of *α* was 0.2, then over-estimated predictions would
    be penalized 4 times more than the under-estimated.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，如果*α*值为0.2，则高估的预测将比低估的预测受到4倍的惩罚。
- en: The problem of predicting a certain variable quantile is called **quantile regression**.
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 预测某个变量分位数的问题称为**分位数回归**。
- en: Example
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: Let us create a synthetic dataset with 10 000 samples where ratings of players
    in a video game will be estimated based on the number of playing hours.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个包含10,000个样本的合成数据集，其中玩家在视频游戏中的评分将基于游戏时长来估计。
- en: '![](../Images/b5d3d48827ebac0a38020fd35de5cb0c.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5d3d48827ebac0a38020fd35de5cb0c.png)'
- en: Dataset generation
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集生成
- en: '![](../Images/a4e96e824617fd2c6f0e920aafad6106.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a4e96e824617fd2c6f0e920aafad6106.png)'
- en: Scatter plot between the predictor (hours) and the target (rating)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 预测变量（小时）与目标（评分）之间的散点图
- en: 'Let us split the data on train and test in 80:20 proportion:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将数据按80:20的比例拆分为训练集和测试集：
- en: '![](../Images/4a1dd50e7d57b40ae9e3d833e7c4381c.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4a1dd50e7d57b40ae9e3d833e7c4381c.png)'
- en: Splitting dataset in 80:20 proportion
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 按80:20比例拆分数据集
- en: 'For comparison, let us build 3 regression models with different *α* values:
    0.2, 0.5 and 0.8\. Each of the regression models will be created by LightGBM —
    a library with an efficient implementation of gradient boosting.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较，我们将建立三个具有不同*α*值的回归模型：0.2、0.5和0.8。每个回归模型将由LightGBM创建——这是一个高效实现梯度提升的库。
- en: Based on the information from the [official documentation](https://lightgbm.readthedocs.io/en/v3.3.5/),
    LightGBM allows solving quantile regression problems by specifying the **objective**
    parameter as *‘quantile’* and passing a corresponding value of **alpha**.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[官方文档](https://lightgbm.readthedocs.io/en/v3.3.5/)的信息，LightGBM允许通过将**objective**参数指定为*‘quantile’*并传递相应的**alpha**值来解决分位数回归问题。
- en: After training 3 models, they can be used to obtain predictions (line 6).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 训练了3个模型后，可以用它们来获得预测（第6行）。
- en: '![](../Images/d802847a399c4cd81bc7548705d6cf15.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d802847a399c4cd81bc7548705d6cf15.png)'
- en: Training LGBM models with objective = ‘quantile’
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 训练LGBM模型，目标 = ‘quantile’
- en: 'Let us visualize the predictions via the code snippet below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过下面的代码片段来可视化预测：
- en: '![](../Images/d52addba80364294cfc79d548aa9e24f.png)![](../Images/2cd9789b2808f449865798db01ef59e0.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d52addba80364294cfc79d548aa9e24f.png)![](../Images/2cd9789b2808f449865798db01ef59e0.png)'
- en: Scatter plot between the predictor (hours) and the true / predicted target values
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 预测变量（小时）与真实/预测目标值之间的散点图
- en: From the scatter plot above, it is clear that with greater values of *α*, models
    tend to generate more over-estimated results. Additionally, let us compare the
    predictions of each model with all target values.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的散点图可以看出，随着*α*值的增大，模型生成的结果往往会更加高估。此外，我们还将比较每个模型的预测与所有目标值。
- en: '![](../Images/d7884c0b466fc691b12175778e786d56.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d7884c0b466fc691b12175778e786d56.png)'
- en: Comparison of predictions done by different models
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不同模型的预测比较
- en: 'This leads to the following output:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](../Images/efcf457edc9c04133b8bdbb71d5f2bd0.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/efcf457edc9c04133b8bdbb71d5f2bd0.png)'
- en: 'The pattern from the output is clearly seen: for any *α*, predicted values
    are greater than true values in approximately *α * 100%* of cases. Therefore,
    we can experimentally conclude that our prediction models work correctly.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以清楚地看到：对于任何*α*，预测值在大约*α * 100%*的情况下都高于真实值。因此，我们可以实验性地得出结论，我们的预测模型工作正常。
- en: Prediction errors of quantile regression models are negative approximately in
    α ** 100%* of cases and are positive in *(1 —* α*) * 100%* of cases.
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分位数回归模型的预测误差在大约*α ** 100%*的情况下为负值，而在*(1 —* α*) * 100%*的情况下为正值。
- en: Conclusion
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: We have discovered quantile loss — a flexible loss function that can be incorporated
    into any regression model to predict a certain variable quantile. Based on the
    example of LightGBM, we saw how to adjust a model, so it solves a quantile regression
    problem. In fact, many other popular machine learning libraries allow setting
    quantile loss as a loss function.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现了分位数损失——一种灵活的损失函数，可以纳入任何回归模型中以预测某个变量的分位数。以 LightGBM 为例，我们看到如何调整模型以解决分位数回归问题。事实上，许多其他流行的机器学习库也允许将分位数损失设置为损失函数。
- en: The code used in this article is available on [GitHub](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb).
  id: totrans-66
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 本文中使用的代码可在 [GitHub](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb)
    上获取。
- en: '[](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb?source=post_page-----b0689c13f54d--------------------------------)
    [## ML-medium/quantile_regression.ipynb at master · slavastar/ML-medium'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb?source=post_page-----b0689c13f54d--------------------------------)
    [## ML-medium/quantile_regression.ipynb at master · slavastar/ML-medium'
- en: This repository contains reproducible code from Data Science articles on my
    Medium blog …
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本库包含了我在 Medium 博客上的数据科学文章中的可重现代码……
- en: github.com](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb?source=post_page-----b0689c13f54d--------------------------------)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb?source=post_page-----b0689c13f54d--------------------------------)
- en: Resources
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: '[Quantile | Wikipedia](https://en.wikipedia.org/wiki/Quantile)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分位数 | 维基百科](https://en.wikipedia.org/wiki/Quantile)'
- en: '[Quantile Regression | Wikipedia](https://en.wikipedia.org/wiki/Quantile_regression)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分位数回归 | 维基百科](https://en.wikipedia.org/wiki/Quantile_regression)'
- en: '[LightGBM Documentation](https://lightgbm.readthedocs.io/en/v3.3.5/)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LightGBM 文档](https://lightgbm.readthedocs.io/en/v3.3.5/)'
- en: '*All images unless otherwise noted are by the author.*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '*除非另有说明，否则所有图片均由作者提供。*'
