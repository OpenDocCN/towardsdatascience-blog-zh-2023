- en: Quantile Loss & Quantile Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/quantile-loss-and-quantile-regression-b0689c13f54d?source=collection_archive---------0-----------------------#2023-01-28](https://towardsdatascience.com/quantile-loss-and-quantile-regression-b0689c13f54d?source=collection_archive---------0-----------------------#2023-01-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how to adjust regression algorithms to predict any quantile of data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)[![Vyacheslav
    Efimov](../Images/db4b02e75d257063e8e9d3f1f75d9d6d.png)](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)
    [Vyacheslav Efimov](https://medium.com/@slavahead?source=post_page-----b0689c13f54d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc8a0ca9d85d8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=post_page-c8a0ca9d85d8----b0689c13f54d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b0689c13f54d--------------------------------)
    ·6 min read·Jan 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb0689c13f54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&user=Vyacheslav+Efimov&userId=c8a0ca9d85d8&source=-----b0689c13f54d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb0689c13f54d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fquantile-loss-and-quantile-regression-b0689c13f54d&source=-----b0689c13f54d---------------------bookmark_footer-----------)![](../Images/5611fd790e61af7a5888d479182c3303.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Regression is a machine learning task where the goal is to predict a real value
    based on a set of feature vectors. There exists a large variety of regression
    algorithms: linear regression, logistic regression, gradient boosting or neural
    networks. During training, each of these algorithms adjusts the weights of a model
    based on the loss function used for optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: The choice of a loss function depends on a certain task and particular values
    of a metric required to achieve. Many loss functions (like MSE, MAE, RMSLE etc.)
    focus on predicting the expected value of a variable given a feature vector.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will have a look at a special loss function called **quantile
    loss** used to predict particular variable quantiles. Before diving into the details
    of quantile loss, let us briefly revise the term of a quantile.
  prefs: []
  type: TYPE_NORMAL
- en: Quantile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Quantile** qₐ is a value that divides a given set of numbers in a way at
    which α ** 100%* of numbers are less than the value and *(1 —* α*) * 100%* of
    numbers are greater than the value.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Quantiles *qₐ* for *α = 0.25*, *α = 0.5* and *α = 0.75* are often utilized in
    statistics and called **quartiles**. These quartiles are denoted as *Q₁*, *Q₂*
    and *Q₃* respectively. Three quartiles split data into 4 equal parts.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Similarly, there are **percentiles** p which divide a given set of numbers by
    100 equal parts. A percentile is denoted as pₐ where α is the percentage of numbers
    less than the corresponding value.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Quartiles Q₁, Q₂ and Q₃ correspond to percentiles p₂₅, p₅₀ and p₇₅ respectively.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the example below, for a given set of numbers, all three quartiles are found.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1e633fb607505561ec4ec0cfae4388e8.png)'
  prefs: []
  type: TYPE_IMG
- en: An example showing all three quartiles for a given set of numbers. The first
    quartile Q₁ is equal to 10 because 25% of values are less than 10 and 75% of values
    are greater than 10\. The analogy proceeds to other quartiles.
  prefs: []
  type: TYPE_NORMAL
- en: Quantile Loss
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine learning algorithms aiming to predict a particular variable quantile
    use quantile loss as the loss function. Before going to the formulation, let us
    consider a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a problem where the goal is to predict the 75-th percentile of a variable.
    In fact, this statement is equivalent to the one that prediction errors have to
    be negative in 75% of cases and in the other 25% to be positive. That is the actual
    intuition used behind the quantile loss.
  prefs: []
  type: TYPE_NORMAL
- en: Formulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The quantile loss formula is illustrated below. The *α* parameter refers to
    the quantile which needs to be predicted.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/43ffa8a88f2448eaddd581099d93f5b0.png)'
  prefs: []
  type: TYPE_IMG
- en: Quantile loss formula
  prefs: []
  type: TYPE_NORMAL
- en: 'The value of quantile loss depends on whether a prediction is less or greater
    than the true value. To understand better the logic behind it, let us suppose
    we objective is to predict the 80-th quantile, thus the value of *α* = 0.8 is
    plugged into the equations. As a result, the formula looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2a3c161d2bf02c3166335aaa89b476b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Basically, in such a case, the quantile loss penalizes under-estimated predictions
    4 times more than over-estimated. This way the model will be more critical to
    under-estimated errors and will predict higher values more often. As a result,
    the fitted model on average will over-estimate results approximately in 80% of
    cases and in 20% it will produce under-estimated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Right now assume that two predictions for the same target were obtained. The
    target has a value of 40, while the predictions are 30 and 50\. Let us calculate
    the quantile loss in both cases. Despite the fact that the absolute error of 10
    is the same in both cases, the loss value is different:'
  prefs: []
  type: TYPE_NORMAL
- en: for 30, the loss value is *l = 0.8 * 10 = 8*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for 50, the loss value is *l =* *0.2 * 10 = 2*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This loss function is illustrated in the diagram below which shows loss values
    for different parameters of *α* when the true value is 40.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4c46d9641fbb078300e4dab010df206c.png)'
  prefs: []
  type: TYPE_IMG
- en: Inversely, if the value of *α* was 0.2, then over-estimated predictions would
    be penalized 4 times more than the under-estimated.
  prefs: []
  type: TYPE_NORMAL
- en: The problem of predicting a certain variable quantile is called **quantile regression**.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us create a synthetic dataset with 10 000 samples where ratings of players
    in a video game will be estimated based on the number of playing hours.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b5d3d48827ebac0a38020fd35de5cb0c.png)'
  prefs: []
  type: TYPE_IMG
- en: Dataset generation
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a4e96e824617fd2c6f0e920aafad6106.png)'
  prefs: []
  type: TYPE_IMG
- en: Scatter plot between the predictor (hours) and the target (rating)
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us split the data on train and test in 80:20 proportion:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4a1dd50e7d57b40ae9e3d833e7c4381c.png)'
  prefs: []
  type: TYPE_IMG
- en: Splitting dataset in 80:20 proportion
  prefs: []
  type: TYPE_NORMAL
- en: 'For comparison, let us build 3 regression models with different *α* values:
    0.2, 0.5 and 0.8\. Each of the regression models will be created by LightGBM —
    a library with an efficient implementation of gradient boosting.'
  prefs: []
  type: TYPE_NORMAL
- en: Based on the information from the [official documentation](https://lightgbm.readthedocs.io/en/v3.3.5/),
    LightGBM allows solving quantile regression problems by specifying the **objective**
    parameter as *‘quantile’* and passing a corresponding value of **alpha**.
  prefs: []
  type: TYPE_NORMAL
- en: After training 3 models, they can be used to obtain predictions (line 6).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d802847a399c4cd81bc7548705d6cf15.png)'
  prefs: []
  type: TYPE_IMG
- en: Training LGBM models with objective = ‘quantile’
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us visualize the predictions via the code snippet below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d52addba80364294cfc79d548aa9e24f.png)![](../Images/2cd9789b2808f449865798db01ef59e0.png)'
  prefs: []
  type: TYPE_IMG
- en: Scatter plot between the predictor (hours) and the true / predicted target values
  prefs: []
  type: TYPE_NORMAL
- en: From the scatter plot above, it is clear that with greater values of *α*, models
    tend to generate more over-estimated results. Additionally, let us compare the
    predictions of each model with all target values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d7884c0b466fc691b12175778e786d56.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparison of predictions done by different models
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads to the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/efcf457edc9c04133b8bdbb71d5f2bd0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The pattern from the output is clearly seen: for any *α*, predicted values
    are greater than true values in approximately *α * 100%* of cases. Therefore,
    we can experimentally conclude that our prediction models work correctly.'
  prefs: []
  type: TYPE_NORMAL
- en: Prediction errors of quantile regression models are negative approximately in
    α ** 100%* of cases and are positive in *(1 —* α*) * 100%* of cases.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have discovered quantile loss — a flexible loss function that can be incorporated
    into any regression model to predict a certain variable quantile. Based on the
    example of LightGBM, we saw how to adjust a model, so it solves a quantile regression
    problem. In fact, many other popular machine learning libraries allow setting
    quantile loss as a loss function.
  prefs: []
  type: TYPE_NORMAL
- en: The code used in this article is available on [GitHub](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb?source=post_page-----b0689c13f54d--------------------------------)
    [## ML-medium/quantile_regression.ipynb at master · slavastar/ML-medium'
  prefs: []
  type: TYPE_NORMAL
- en: This repository contains reproducible code from Data Science articles on my
    Medium blog …
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/slavastar/ML-medium/blob/master/quantile_regression.ipynb?source=post_page-----b0689c13f54d--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: Resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Quantile | Wikipedia](https://en.wikipedia.org/wiki/Quantile)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Quantile Regression | Wikipedia](https://en.wikipedia.org/wiki/Quantile_regression)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[LightGBM Documentation](https://lightgbm.readthedocs.io/en/v3.3.5/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*All images unless otherwise noted are by the author.*'
  prefs: []
  type: TYPE_NORMAL
