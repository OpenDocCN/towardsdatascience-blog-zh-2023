["```py\nfrom torchdata.datapipes.iter import IterDataPipe\n\nclass DoublingDataPipe(IterDataPipe):\n    def __init__(self, source_data):\n        self.source_data = source_data\n\n    def __iter__(self):\n        for item in self.source_data:\n            yield item * 2\n\n# Initialize the DataPipe with a list of integers.\nsource_data = [1, 2, 3, 4, 5]\ndoubling_data_pipe = DoublingDataPipe(source_data)\n\n# Iterate over the DataPipe and print the results.\nfor doubled_item in doubling_data_pipe:\n    print(doubled_item)\n```", "```py\n2\n4\n6\n8\n10\n```", "```py\nfrom torchdata.datapipes.iter import IterableWrapper\n\ndata_pipe = IterableWrapper([1, 2, 3, 4, 5])\n\n# Double each element in the DataPipe.\ndoubled_data_pipe = data_pipe.map(lambda x: x * 2)\n\nfor item in doubled_data_pipe:\n    print(item)\n\n# Output: 2, 4, 6, 8, 10\n```", "```py\nfrom torchdata.datapipes.iter import IterableWrapper\n\ndata_pipe = IterableWrapper([1, 2, 3, 4, 5])\n\n# Filter out odd elements in the DataPipe.\neven_data_pipe = data_pipe.filter(lambda x: x % 2 == 0)\n\nfor item in even_data_pipe:\n    print(item)\n\n# Output: 2, 4\n```", "```py\nfrom torchdata.datapipes.iter import IterableWrapper\n\ndata_pipe = IterableWrapper([1, 2, 3, 4, 5])\n\n# Shuffle the elements in the DataPipe.\nshuffled_data_pipe = data_pipe.shuffle(buffer_size=5)\n\nfor item in shuffled_data_pipe:\n    print(item)\n\n# Output: Randomly ordered elements, e.g., 3, 1, 5, 2, 4\n```", "```py\nfrom torchdata.datapipes.iter import IterableWrapper\n\ndata_pipe1 = IterableWrapper([1, 2, 3])\ndata_pipe2 = IterableWrapper([4, 5, 6])\n\n# Chain the two DataPipes together.\nchained_data_pipe = data_pipe1.chain(data_pipe2)\n\nfor item in chained_data_pipe:\n    print(item)\n\n# Output: 1, 2, 3, 4, 5, 6\n```", "```py\npip install torchdata tqdm aiohttp Pillow\n```", "```py\nimport aiohttp\nfrom PIL import Image\nimport io\n\nasync def async_get_image(\n    session: aiohttp.ClientSession, url: str\n) -> Optional[Image.Image]:\n    try:\n        resp = await session.get(url)\n        image_bytes = await resp.read()\n        return Image.open(io.BytesIO(image_bytes))\n    except Exception:\n        # If an exception occurs, such as a timeout, invalid URL, etc, just\n        # return None, and the caller can handle skipping this\n        return None\n```", "```py\nasync def async_batch_get_images(\n    urls: Sequence[str], timeout: float = 1.0\n) -> List[Optional[Image.Image]]:\n    client_timeout = aiohttp.ClientTimeout(total=timeout)\n    async with aiohttp.ClientSession(timeout=client_timeout) as session:\n        return await asyncio.gather(*[async_get_image(session, url) for url in urls])\n```", "```py\nfrom torchdata.datapipes.iter import IterDataPipe\n\nclass ParallelSampleLoader(IterDataPipe):\n    def __init__(\n        self, dp: IterDataPipe[Tuple[str, str]], buffer_size: int = 256\n    ) -> None:\n        super().__init__()\n        self.dp = dp\n        self.buffer_size = buffer_size\n\n    def __iter__(self) -> Generator[Tuple[Image.Image, str], None, None]:\n        pipe: IterDataPipe[List[Tuple[str, str]]] = self.dp.batch(self.buffer_size)\n        for batch in pipe:\n            # The batch is a list of tuples, where the first element is the\n            # caption, and the second element is the URL of the image.\n            captions = [x[0] for x in batch]\n            image_urls = [x[1] for x in batch]\n            images = asyncio.run(async_batch_get_images(image_urls))\n\n            for image, caption in zip(images, captions):\n                if image is not None:\n                    yield image, caption\n```", "```py\nfrom torchdata.datapipes.iter import HttpReader, LineReader\n\ndef _datapipe_from_tsv_url(\n    tsv_url: str, buffer_size: int = 256\n) -> IterDataPipe[Tuple[Image.Image, str]]:\n    pipe = HttpReader([tsv_url])\n    pipe = LineReader(pipe, return_path=False)\n    # LineReader downloads raw bytes.  Decode them to strings, then split.\n    pipe = pipe.map(lambda line: line.decode(\"utf-8\").split(\"\\t\"))\n\n    return ParallelSampleLoader(pipe, buffer_size=buffer_size)\n\ndef conceptual_captions_3m(\n    split: str = \"train\", buffer_size: int = 256\n) -> IterDataPipe[Tuple[Image.Image, str]]:\n    return _datapipe_from_tsv_url(tsv_url=TSV_URLS[split], buffer_size=buffer_size)\n```", "```py\n# Create the IterDataPipe for the training split.\ndata_pipe = conceptual_captions_3m(split=\"train\")\n\nfor i, (image, caption) in enumerate(data_pipe):\n    if i >= 10:\n        break\n    print(f\"Caption {i + 1}: {caption}\")\n    print(f\"Image size: {image.size}\")\n```", "```py\nfrom tqdm import tqdm\n\n# Create the IterDataPipe for the training split.\ndata_pipe = conceptual_captions_3m(split=\"train\")\n\nfor image, caption in tqdm(data_pipe):\n    # Don't do anything here.  We just want to test the loading speed.\n    pass\n```"]