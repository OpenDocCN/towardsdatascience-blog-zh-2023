- en: Hyperbolic Deep Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/hyperbolic-deep-reinforcement-learning-b2de787cf2f7?source=collection_archive---------1-----------------------#2023-04-30](https://towardsdatascience.com/hyperbolic-deep-reinforcement-learning-b2de787cf2f7?source=collection_archive---------1-----------------------#2023-04-30)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: RL meets hyperbolic geometry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many RL problems have hierarchical tree-like nature. Hyperbolic geometry offers
    a powerful prior for such problems.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)[![Michael
    Bronstein](../Images/1aa876fce70bb07bef159fecb74e85bf.png)](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)
    [Michael Bronstein](https://michael-bronstein.medium.com/?source=post_page-----b2de787cf2f7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7b1129ddd572&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&user=Michael+Bronstein&userId=7b1129ddd572&source=post_page-7b1129ddd572----b2de787cf2f7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b2de787cf2f7--------------------------------)
    ·17 min read·Apr 30, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb2de787cf2f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&user=Michael+Bronstein&userId=7b1129ddd572&source=-----b2de787cf2f7---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb2de787cf2f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhyperbolic-deep-reinforcement-learning-b2de787cf2f7&source=-----b2de787cf2f7---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Many problems in Reinforcement Learning manifest a hierarchical tree-like nature.
    Hyperbolic spaces, which can be conceptualised as continuous analogies of trees,
    are thus suitable candidates to parameterise the agent’s deep model. In this post,
    we overview the basics of hyperbolic geometry, show empirically that it provides
    a good inductive bias for many RL problems, and describe a practical regularisation
    procedure allowing to resolve numerical instabilities in end-to-end optimisation
    with hyperbolic latent spaces. Our approach shows a near-universal performance
    improvement across a broad range of common benchmarks both with on-policy and
    off-policy RL algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6bdc310bab65aab0cc8849bfb1a4359.png)'
  prefs: []
  type: TYPE_IMG
- en: Stable Diffusion prompted with “Hyperbolic Atari Breakout game, icon design,
    flat design, vector art” (courtesy of [David Ha](https://twitter.com/hardmaru?lang=en))
  prefs: []
  type: TYPE_NORMAL
- en: '*This post was co-authored with* [*Edoardo Cetin*](https://aladoro.github.io/)*,*
    [*Ben Chamberlain*](https://twitter.com/DrBPChamberlain)*, and* [*Jonathan Hunt*](https://twitter.com/jjh)
    *and is based on the paper E. Cetin et al.,* [*Hyperbolic deep reinforcement learning*](https://arxiv.org/pdf/2210.01542.pdf)
    *(2023) ICLR. For more details, find us at ICLR 2023!*'
  prefs: []
  type: TYPE_NORMAL
- en: Basics of Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: RL problems can be described as a Markov Decision Process (MDP), where the agent
    observes some *state* *s*∈*S* from…
  prefs: []
  type: TYPE_NORMAL
