- en: How to Store Historical Data Much More Efficiently
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-to-store-historical-data-much-more-efficiently-78b0f2c8c811?source=collection_archive---------2-----------------------#2023-09-10](https://towardsdatascience.com/how-to-store-historical-data-much-more-efficiently-78b0f2c8c811?source=collection_archive---------2-----------------------#2023-09-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A hands-on tutorial using PySpark to store up to only 0.01% of a DataFrame’s
    rows without losing any information.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tomergabay?source=post_page-----78b0f2c8c811--------------------------------)[![Tomer
    Gabay](../Images/1fb1d408bc89415918c1aa6733df44e1.png)](https://medium.com/@tomergabay?source=post_page-----78b0f2c8c811--------------------------------)[](https://towardsdatascience.com/?source=post_page-----78b0f2c8c811--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----78b0f2c8c811--------------------------------)
    [Tomer Gabay](https://medium.com/@tomergabay?source=post_page-----78b0f2c8c811--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fc9c352dba00a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-store-historical-data-much-more-efficiently-78b0f2c8c811&user=Tomer+Gabay&userId=c9c352dba00a&source=post_page-c9c352dba00a----78b0f2c8c811---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----78b0f2c8c811--------------------------------)
    ·10 min read·Sep 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F78b0f2c8c811&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-store-historical-data-much-more-efficiently-78b0f2c8c811&user=Tomer+Gabay&userId=c9c352dba00a&source=-----78b0f2c8c811---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F78b0f2c8c811&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-to-store-historical-data-much-more-efficiently-78b0f2c8c811&source=-----78b0f2c8c811---------------------bookmark_footer-----------)![](../Images/e6a3ccf160e7ca3d2ab0eba9ba6199b7.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Supratik Deshmukh](https://unsplash.com/@supratikdeshmukh?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'In an era where companies and organizations are collecting more data than ever
    before, datasets tend to accumulate millions of unnecessary rows that don’t contain
    any new or valuable information. In this article, we’ll focus on a critical aspect
    of data management: deleting rows in a dataset if they provide no added value,
    using PySpark*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*[PySpark](https://spark.apache.org/docs/latest/api/python/index.html#:~:text=PySpark%20is%20the%20Python%20API,for%20interactively%20analyzing%20your%20data.)
    is used over pandas when dealing with very large datasets because it can process
    data across multiple computers, making it faster and more scalable. Pandas works
    well for smaller datasets that can fit in memory on a single machine but may become
    slow or even impractical for big data.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Let’s imagine the following situation: you work as a data engineer/scientist
    in the maintenance department of a real estate company. For the past ten years,
    your company has done a full load of all maintenance data from an external database
    containing the conditions of your buildings and stored it in the company’s cloud
    storage. The data could e.g. look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Three columns are present in this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '`id` -> for the ID of the building.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
