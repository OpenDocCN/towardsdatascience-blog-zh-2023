- en: 'Unlocking Data Modeling Success: 3 Must-Have Contextual Tables'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/unlocking-data-modeling-success-3-must-have-contextual-tables-7b9ae9d4ad84?source=collection_archive---------17-----------------------#2023-07-06](https://towardsdatascience.com/unlocking-data-modeling-success-3-must-have-contextual-tables-7b9ae9d4ad84?source=collection_archive---------17-----------------------#2023-07-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: And how to ingest valuable data for free
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mattgazzano?source=post_page-----7b9ae9d4ad84--------------------------------)[![Matthew
    Gazzano](../Images/23f154b154d05847c2c13ea17ceb7a57.png)](https://medium.com/@mattgazzano?source=post_page-----7b9ae9d4ad84--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7b9ae9d4ad84--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7b9ae9d4ad84--------------------------------)
    [Matthew Gazzano](https://medium.com/@mattgazzano?source=post_page-----7b9ae9d4ad84--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F626000912ce9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-data-modeling-success-3-must-have-contextual-tables-7b9ae9d4ad84&user=Matthew+Gazzano&userId=626000912ce9&source=post_page-626000912ce9----7b9ae9d4ad84---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7b9ae9d4ad84--------------------------------)
    ¬∑6 min read¬∑Jul 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b9ae9d4ad84&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-data-modeling-success-3-must-have-contextual-tables-7b9ae9d4ad84&user=Matthew+Gazzano&userId=626000912ce9&source=-----7b9ae9d4ad84---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b9ae9d4ad84&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-data-modeling-success-3-must-have-contextual-tables-7b9ae9d4ad84&source=-----7b9ae9d4ad84---------------------bookmark_footer-----------)![](../Images/7728d2da0190159ba9678148bdb1db24.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Photo](https://unsplash.com/photos/PkbZahEG2Ng) by [Tobias Fischer](https://unsplash.com/@tofi)
    on [Unsplash](https://unsplash.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: Data modeling can be a challenging task for analytics teams. With unique business
    entities in every organization, finding the right structure and granularity for
    each table becomes open-ended. But fear not! Some of the data you need is simplistic,
    free, and occupies minimal storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'When your data is modeled in full, you can see the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Queries are less complex to generate, and therefore more readable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reports are more scalable, reducing hard-coded values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are likely spending less time finding where the right data lives.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Below are 3 generic tables that can streamline your team‚Äôs analytics, which
    you can ingest into your Data Warehouse in the context of a dimensional model.
  prefs: []
  type: TYPE_NORMAL
- en: üóìÔ∏èThe Date Dimension
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***For Timeseries Reporting***'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have ever needed to show a business metric as it was at a given point
    in time, this is a nearly essential table to have. For example, you may be asked:'
  prefs: []
  type: TYPE_NORMAL
- en: '***‚ÄúWhat did sales look like in FY23?‚Äù***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Can you show me client churn on a daily basis?***'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Management frequently seeks insights from a timeseries perspective, asking questions
    like ‚ÄúHow is x growing or shrinking over time?‚Äù. A date dimension enables flexible
    analysis of various metrics based on different date attributes.
  prefs: []
  type: TYPE_NORMAL
- en: Most Date Dimension tables can be created solely using [DDL](https://www.javatpoint.com/ddl-commands-in-sql)
    statements directly in your Data Warehouse, with a mix of date functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the below example, I use BigQuery SQL to do just that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/9e5ca6ae342b0c68353e44384494737b.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Breaking this down:**'
  prefs: []
  type: TYPE_NORMAL
- en: We start with the [GENERATE_DATE_ARRAY](https://cloud.google.com/bigquery/docs/reference/standard-sql/array_functions#generate_date_array)
    function, which returns an array of dates in a range that you specify. We then
    use the UNNEST function to break each element of the array into separate rows,
    just like in a standard database table. Arrays in BigQuery use one row to display
    multiple values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then with our ***full_date*** column that was generated from the unnested array
    (which represents dates in the format of *XXXX-MM-DD)*, we can use many of BigQuery‚Äôs
    [EXTRACT](https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions#extract)
    functions to get segments of ***full_date*** into separate fields (month, day,
    year, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The [FORMAT_DATE](https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions#format_date)
    function has a similar purpose to EXTRACT, but gives us more customization on
    how the date value appears. You can use special [format elements described in
    Google‚Äôs documentation](https://cloud.google.com/bigquery/docs/reference/standard-sql/format-elements#format_elements_date_time)
    for details on what each ‚Äò%‚Äô character means.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also use the [DATE_SUB](https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions#date_sub)
    function which simply subtracts a value from one date. This is used to get the
    related fiscal year, which in this example would start on July of every calendar
    year. In this function, we specify a quantity (1 ‚Äî infinity), and the interval
    (day, months, years etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: üåéThe Zip Code Dimension
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***For Geospacial Reporting***'
  prefs: []
  type: TYPE_NORMAL
- en: If you have been tasked to create a heatmap visualization, or a general geospatial
    analysis ‚Äî a zip code dimension will be of great use for your team. This gives
    you the option to visualize elements by latitude and longitude, aggregate by county
    names, time zone, and append population data for benchmarking.
  prefs: []
  type: TYPE_NORMAL
- en: A Zip Code Dimension is a great supplemental table to a customer table. By using
    the Zip Code field as the join key, you can append meaningful contextual data
    to where your customer base resides, and patterns behind them.
  prefs: []
  type: TYPE_NORMAL
- en: '[Opendatasoft](https://data.opendatasoft.com/pages/home/) provides various
    free datasets with an open-source API connector. One that is perfect for this
    use case is the [***US Zip Codes Points- United States of America***](https://data.opendatasoft.com/explore/dataset/georef-united-states-of-america-zc-point%40public/table/?rows=)dataset.
    On this link, hover over to the ‚ÄòAPI‚Äô tab which lets you configure the URL to
    retrieve JSON data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With a few lines in Python, we can output the following Pandas DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/d55748137629a3223ccbaf5e1c728762.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Breaking this down:**'
  prefs: []
  type: TYPE_NORMAL
- en: Here I use the [requests](https://requests.readthedocs.io/en/latest/) library
    to retrieve data found at the following URL shown in the ‚Äòurl‚Äô variable, which
    was generated on the API tab of the opendatasoft website.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With Pandas, I use the [***json_normalize***](/all-pandas-json-normalize-you-should-know-for-flattening-json-13eae1dfb7dd)function
    to convert the JSON data into a Pandas DataFrame.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: üìàThe FX Rates Fact Table
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '***For Financial Analysis***'
  prefs: []
  type: TYPE_NORMAL
- en: Organizations with international clients often need to convert all transactions
    to a base currency for financial reporting. To understand how a foreign exchange
    rate fluctuation may be impacting revenue, a daily FX rate feed is a great solution
    to answer this question.
  prefs: []
  type: TYPE_NORMAL
- en: This is also particularly impactful when paired with time series reporting,
    to append exchange rates at the time of a given sale. In my experience building
    dashboards which show client revenue over a period of time, business users always
    appreciated the ability to toggle different FX rate values against revenue on
    a date axis. The FX Rates table lets you accomplish all of this.
  prefs: []
  type: TYPE_NORMAL
- en: '[Exchangerate.host](https://exchangerate.host/#/docs) is another open-source
    site that allows you to connect to a daily FX rates feed. Below is an example
    of how to retrieve the data ‚Äî more info can be found on [their documentation](https://exchangerate.host/#/docs):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/ac6bf1ef48a5b206e05fa3c8befbcc7d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Breaking this down:**'
  prefs: []
  type: TYPE_NORMAL
- en: Here we use the requests library to retrieve data in the form of a Python dictionary
    from the URL specified in the ‚Äòurl‚Äô variable. Please note ‚Äî I edited the URL per
    the documentation to specify the base currency to USD. Meaning, all rates will
    relate to their USD exchange rate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we convert the Python dictionary to a list, taking the data from the ‚Äòrates‚Äô
    key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we convert the list into a Pandas DataFrame and label the column headers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Finally a column is added ‚Äòcycle_date‚Äô which represents the ETL cycle date,
    denoting when the data is ingested into the Data Warehouse.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Incorporating publicly available data into your Data Warehouse can provide immediate
    value to analytics teams with minimal effort. These tables, as well as any properly
    modeled data entity, eliminate the need to store nested business logic solely
    in BI tools like Power BI or Tableau. They instead provide a centralized source
    of data that multiple analysts can reference and apply consistently in their reporting.
    This cohesive approach to data modeling empowers teams to scale reporting effortlessly,
    ensuring transparency into the source data. With the ability to leverage these
    types of contextual tables, your organization can streamline analytics processes,
    eliminate discrepancies in reporting, and achieve a higher level of data-driven
    decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: Happy Modeling!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
