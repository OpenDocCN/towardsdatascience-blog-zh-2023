- en: Vision-centric Semantic Occupancy Prediction for Autonomous Driving
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/vision-centric-semantic-occupancy-prediction-for-autonomous-driving-16a46dbd6f65?source=collection_archive---------7-----------------------#2023-05-29](https://towardsdatascience.com/vision-centric-semantic-occupancy-prediction-for-autonomous-driving-16a46dbd6f65?source=collection_archive---------7-----------------------#2023-05-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A review of the academic “Occupancy Networks” as of 2023H1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@patrickllgc?source=post_page-----16a46dbd6f65--------------------------------)[![Patrick
    Langechuan Liu](../Images/fecbf85146a9bde21e6b2251538ddd65.png)](https://medium.com/@patrickllgc?source=post_page-----16a46dbd6f65--------------------------------)[](https://towardsdatascience.com/?source=post_page-----16a46dbd6f65--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----16a46dbd6f65--------------------------------)
    [Patrick Langechuan Liu](https://medium.com/@patrickllgc?source=post_page-----16a46dbd6f65--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd875946648f7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvision-centric-semantic-occupancy-prediction-for-autonomous-driving-16a46dbd6f65&user=Patrick+Langechuan+Liu&userId=d875946648f7&source=post_page-d875946648f7----16a46dbd6f65---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----16a46dbd6f65--------------------------------)
    ·11 min read·May 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F16a46dbd6f65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvision-centric-semantic-occupancy-prediction-for-autonomous-driving-16a46dbd6f65&user=Patrick+Langechuan+Liu&userId=d875946648f7&source=-----16a46dbd6f65---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F16a46dbd6f65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fvision-centric-semantic-occupancy-prediction-for-autonomous-driving-16a46dbd6f65&source=-----16a46dbd6f65---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: One critical pain point of existing 3D object detection methods in autonomous
    driving is that they typically output concise 3D bounding boxes, neglecting finer
    geometric details and struggling to handle general, out-of-vocabulary objects.
    This pain point exists for both [monocular 3D object detection](/monocular-3d-object-detection-in-autonomous-driving-2476a3c7f57e)
    and [BEV multicamera object detection](/monocular-bev-perception-with-transformers-in-autonomous-driving-c41e4a893944).
    To address this problem, **Occupancy Network,** a vision-centric solution for
    general obstacle detection was first introduced in a [keynote speech by Tesla
    in CVPR 2022](https://www.youtube.com/watch?v=jPCV4GKX9Dw) and later popularized
    by [AI Day 2022](https://www.youtube.com/watch?v=ODSJsviD_SU). For more details,
    please refer to the previous blog post series on drivable space.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/@patrickllgc/drivable-space-in-autonomous-driving-the-industry-7a4624b94d41?source=post_page-----16a46dbd6f65--------------------------------)
    [## Drivable Space in Autonomous Driving — The Industry'
  prefs: []
  type: TYPE_NORMAL
- en: Recent trends in industry application as of 2023
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: medium.com](https://medium.com/@patrickllgc/drivable-space-in-autonomous-driving-the-industry-7a4624b94d41?source=post_page-----16a46dbd6f65--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: In academia, the equivalent perception track to Occupancy Network is known as
    **Semantic Occupancy Prediction (SOP)** and is sometimes also referred to as **Semantic
    Scene Completion (SSC)**, with some subtle differences between the two explained
    below. Semantic occupancy prediction assigns the occupancy state and semantic
    label to each voxel in the scene. This is a representation general and expressive
    enough to describe objects of known classes but with an irregular shape or objects
    out of the known white…
  prefs: []
  type: TYPE_NORMAL
