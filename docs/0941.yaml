- en: Discretizing the Continues Features in Reinforcement Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/discretizing-the-continues-features-in-reinforcement-learning-b69b388215ea?source=collection_archive---------17-----------------------#2023-03-13](https://towardsdatascience.com/discretizing-the-continues-features-in-reinforcement-learning-b69b388215ea?source=collection_archive---------17-----------------------#2023-03-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to convert infinite variables to a discrete space using tile coding and
    Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://eligijus-bujokas.medium.com/?source=post_page-----b69b388215ea--------------------------------)[![Eligijus
    Bujokas](../Images/061fd30136caea2ba927140e8b3fae3c.png)](https://eligijus-bujokas.medium.com/?source=post_page-----b69b388215ea--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b69b388215ea--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b69b388215ea--------------------------------)
    [Eligijus Bujokas](https://eligijus-bujokas.medium.com/?source=post_page-----b69b388215ea--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd61597e07b4d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdiscretizing-the-continues-features-in-reinforcement-learning-b69b388215ea&user=Eligijus+Bujokas&userId=d61597e07b4d&source=post_page-d61597e07b4d----b69b388215ea---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b69b388215ea--------------------------------)
    ·6 min read·Mar 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb69b388215ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdiscretizing-the-continues-features-in-reinforcement-learning-b69b388215ea&user=Eligijus+Bujokas&userId=d61597e07b4d&source=-----b69b388215ea---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb69b388215ea&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdiscretizing-the-continues-features-in-reinforcement-learning-b69b388215ea&source=-----b69b388215ea---------------------bookmark_footer-----------)![](../Images/bdde8e9b4d25e844f699ec37d46e776f.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Ehud Neuhaus](https://unsplash.com/@paramir?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'This article is a continuation of the Reinforcement Learning series. To recap,
    visit these articles:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '[](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----b69b388215ea--------------------------------)
    [## First Steps in the World Of Reinforcement Learning using Python'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Original Python implementation of how to find the best places to be in one of
    the fundamental worlds of reinforcement…
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍了如何在强化学习的基本世界之一中找到最佳位置的原始Python实现……
- en: towardsdatascience.com](/first-steps-in-the-world-of-reinforcement-learning-using-python-b843b76538e3?source=post_page-----b69b388215ea--------------------------------)
    [](/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=post_page-----b69b388215ea--------------------------------)
    [## Temporal Differences with Python — First Sample-Based Reinforcement Learning
    Algorithm
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[Python中的时间差异——基于样本的强化学习算法的第一次实现](https://towardsdatascience.com/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=post_page-----b69b388215ea--------------------------------) '
- en: Coding up and understanding the TD(0) algorithm using Python
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Python编写和理解TD(0)算法
- en: towardsdatascience.com](/temporal-differences-with-python-first-sample-based-reinforcement-learning-algorithm-54c11745a0ee?source=post_page-----b69b388215ea--------------------------------)
    [](/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=post_page-----b69b388215ea--------------------------------)
    [## The Values of Actions in Reinforcement Learning using Q-learning
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用Q学习进行强化学习中的行动价值](https://towardsdatascience.com/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=post_page-----b69b388215ea--------------------------------) '
- en: The Q-learning algorithm implemented from scratch in Python
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用Python从头实现的Q-learning算法
- en: towardsdatascience.com](/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=post_page-----b69b388215ea--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[使用Q学习进行强化学习中的行动价值](https://towardsdatascience.com/the-values-of-actions-in-reinforcement-learning-using-q-learning-cb4b03be5c81?source=post_page-----b69b388215ea--------------------------------)'
- en: 'The last article about Q-Learning explored the concept of assigning a number
    to a state action pair:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 上一篇关于Q学习的文章探讨了将数字分配给状态-动作对的概念：
- en: The states used were states that can be listed and written into a table. For
    example, we indexed all the available positions in a maze that our agent can be
    in. Even in a…
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的状态是可以列出并写入表格的状态。例如，我们对迷宫中所有可用的位置进行了索引，我们的代理可以处于这些位置中。即使在……
