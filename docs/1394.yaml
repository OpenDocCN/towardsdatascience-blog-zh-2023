- en: New Frontiers in Audio Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/new-frontiers-in-audio-machine-learning-6474ffaa5cb9?source=collection_archive---------9-----------------------#2023-04-20](https://towardsdatascience.com/new-frontiers-in-audio-machine-learning-6474ffaa5cb9?source=collection_archive---------9-----------------------#2023-04-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----6474ffaa5cb9--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----6474ffaa5cb9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6474ffaa5cb9--------------------------------)
    ·Sent as a [Newsletter](/newsletter?source=post_page-----6474ffaa5cb9--------------------------------)
    ·3 min read·Apr 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6474ffaa5cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&user=TDS+Editors&userId=7e12c71dfa81&source=-----6474ffaa5cb9---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6474ffaa5cb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-frontiers-in-audio-machine-learning-6474ffaa5cb9&source=-----6474ffaa5cb9---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Not that long ago, any workflow that involved processing audio files—even a
    fairly simple task like transcribing a podcast episode—came with a set of tough
    choices. You could go manual (and waste hours, if not days, in the process), rely
    on a few clunky and ultimately underwhelming apps, or patch together a Frankenstein’s
    monster-equivalent of tools and code.
  prefs: []
  type: TYPE_NORMAL
- en: Those days are behind us. The rise of powerful models and accessible AI interfaces
    has made working with audio and music exponentially more streamlined, and new
    horizons continue to open up every day. To help you catch up with some of the
    recent advances in audio-focused machine learning, we’ve collected a few standout
    articles from the past few weeks, covering a wide range of approaches and use
    cases. Tune out the noise and dive in!
  prefs: []
  type: TYPE_NORMAL
- en: '[**A look inside the black box of music tagging**](/making-music-tagging-ai-explainable-through-source-separation-2d9493547a7e).
    With thousands of songs added to platforms like Spotify and Apple Music every
    day, have you ever wondered how these services know which musical genre to assign
    to each one? [Max Hilsdorf](https://medium.com/u/d0c085a74ae8?source=post_page-----6474ffaa5cb9--------------------------------)’s
    fascinating project leverages Shapley values to determine how the presence of
    specific instruments shapes the way AI systems tag new tracks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Explore a deep learning approach to identifying bird calls**](/audio-classification-with-deep-learning-in-python-cf752b22ba07).
    [Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----6474ffaa5cb9--------------------------------)’s
    recent contribution covers last year’s BirdCLEF2022 Kaggle competition, where
    participants were tasked with creating a classifier for bird-song recordings.
    Leonie walks us through a neat approach that converts audio waveforms into mel
    spectrograms so a deep learning model can approach them the same way it does images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/bd4b9d5ac6e5d107fb089b0520914472.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Oskars Sylwan](https://unsplash.com/@oskarssylwan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '[**Get the gist of recorded conversations, lectures, and interviews**](/how-to-auto-generate-a-summary-from-long-youtube-videos-using-ai-a2a542b6698d).
    If you’re a consummate optimizer, you’ll appreciate [Bildea Ana](https://medium.com/u/c57d3db39a47?source=post_page-----6474ffaa5cb9--------------------------------)’s
    streamlined process for transcribing audio with OpenAI’s Whisper model on Hugging
    Face, and then summarizing it using the open-source BART encoder. You could apply
    this method to your own recordings and voice memos, or to any other audio file
    (as long as its owners allow it, of course—*always* double-check the copyright
    and license status of any data you’d like to use).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**Taking transcription to the next level**](/unlock-the-power-of-audio-data-advanced-transcription-and-diarization-with-whisper-whisperx-and-ed9424307281).
    [Luís Roque](https://medium.com/u/2195f049db86?source=post_page-----6474ffaa5cb9--------------------------------)’s
    latest project follows a parallel path to Ana’s, up to a point. It also relies
    on Whisper to transcribe audio files, but then explores a different direction
    altogether by deploying PyAnnotate for speaker diarization, “the process of identifying
    and segmenting speech by different speakers.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Please don’t stop the music, you say? We’re happy to oblige — here are some
    of our favorite recent articles on non-audio-related topics. Enjoy!
  prefs: []
  type: TYPE_NORMAL
- en: '*“*Learning neural networks should not be an exercise in decoding misleading
    diagrams,*”* say [Aaron Master](https://medium.com/u/31905cfe67ce?source=post_page-----6474ffaa5cb9--------------------------------)
    and Doron Bergman, who [propose a constructive, novel approach](/please-stop-drawing-neural-networks-wrong-ffd02b67ad77)
    to creating better and more accurate ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'From promotion design to inventory analysis, [Idil Ismiguzel](https://medium.com/u/6d965c736f2?source=post_page-----6474ffaa5cb9--------------------------------)
    demonstrates [the power of association rule mining](/a-guide-to-association-rule-mining-96c42968ba6):
    a technique that empowers data professionals to find frequent patterns in a dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a [hands-on approach to unsupervised learning and K-means clustering](/unsupervised-learning-with-k-means-clustering-generate-color-palettes-from-images-94bb8e6a1416),
    don’t miss [Nabanita Roy](https://medium.com/u/d36a8b28c928?source=post_page-----6474ffaa5cb9--------------------------------)’s
    new tutorial, which focuses on the use case of grouping image pixels by color.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you find [the intersection of AI, government regulations, and the intricacies
    of Canadian bureaucracy](/how-we-won-our-first-government-ai-project-8c67e58c22f0)
    fascinating (who wouldn’t?), [Mathieu Lemay](https://medium.com/u/f84a70d8f74?source=post_page-----6474ffaa5cb9--------------------------------)’s
    deep dive is the one article you absolutely shouldn’t miss this week.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As the role of synthetic data continues to evolve (and grow) in numerous sectors,
    [Miriam Santos](https://medium.com/u/243289394aaa?source=post_page-----6474ffaa5cb9--------------------------------)’
    practical [guide to generating it with CTGAN](/how-to-generate-real-world-synthetic-data-with-ctgan-af41b4d60fde)
    is as timely and useful as ever.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We couldn’t possibly go an entire week without a GPT-themed pick; if you haven’t
    read it already, we highly recommend [Henry Lai](https://medium.com/u/d5548707b59?source=post_page-----6474ffaa5cb9--------------------------------)’s
    overview of [the data-centric AI concepts behind these ever-popular models](/what-are-the-data-centric-ai-concepts-behind-gpt-models-a590071bb727).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thank you for tuning in to the Variable this week! If you enjoy the articles
    you read on TDS, consider [becoming a Medium member](https://bit.ly/tds-membership)—and
    if you’re a student in an eligible country, don’t miss a chance to [enjoy a substantial
    discount on a membership](https://blog.medium.com/new-student-discounts-cc10e964495b).
  prefs: []
  type: TYPE_NORMAL
- en: Until the next Variable,
  prefs: []
  type: TYPE_NORMAL
- en: TDS Editors
  prefs: []
  type: TYPE_NORMAL
