- en: 91% of ML Models Degrade in Time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/91-of-ml-models-degrade-in-time-cfd467905615?source=collection_archive---------10-----------------------#2023-04-11](https://towardsdatascience.com/91-of-ml-models-degrade-in-time-cfd467905615?source=collection_archive---------10-----------------------#2023-04-11)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The performance of ML models degrades as time passes and data distribution changes.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://santiviquez.medium.com/?source=post_page-----cfd467905615--------------------------------)[![Santiago
    Víquez](../Images/5526cf0e92f31d2438bf6522afa5b212.png)](https://santiviquez.medium.com/?source=post_page-----cfd467905615--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cfd467905615--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cfd467905615--------------------------------)
    [Santiago Víquez](https://santiviquez.medium.com/?source=post_page-----cfd467905615--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F85c82fdad717&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F91-of-ml-models-degrade-in-time-cfd467905615&user=Santiago+V%C3%ADquez&userId=85c82fdad717&source=post_page-85c82fdad717----cfd467905615---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cfd467905615--------------------------------)
    ·9 min read·Apr 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcfd467905615&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F91-of-ml-models-degrade-in-time-cfd467905615&user=Santiago+V%C3%ADquez&userId=85c82fdad717&source=-----cfd467905615---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcfd467905615&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F91-of-ml-models-degrade-in-time-cfd467905615&source=-----cfd467905615---------------------bookmark_footer-----------)![](../Images/a31369d8347657f5810e3b7f2b2559e5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Model aging chart showing the performance of an ML model degrading in time.
    Image retrieved from the original paper, annotated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: A recent study from MIT, Harvard, The University of Monterrey, and Cambridge
    showed that [91% of ML models degrade over time](https://www.nature.com/articles/s41598-022-15245-z).
    This study is one of the first of its kind, where researchers focus on studying
    machine learning models’ behavior after deployment and how their performance evolves
    with unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: “While much research has been done on various types and markers of temporal
    data drifts, there is no comprehensive study of how the models themselves can
    respond to these drifts.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This blog post will review the most critical parts of the research, highlight
    their results, and stress the importance of these results, especially for the
    ML industry.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you have been previously exposed to concepts like covariate shift or concept
    drift, you may be aware that changes in the distribution of the production data
    may affect the model’s performance. This phenomenon is one of the challenges of
    maintaining an ML model in production.
  prefs: []
  type: TYPE_NORMAL
- en: By definition, ML models depend on the data it was trained on, meaning that
    if the distribution of the production data starts to change, the model may no
    longer perform as well as before. And as time passes, the model’s performance
    may degrade more and more. The authors refer to this phenomenon as *“AI aging.”*
    I like to call it model performance degradation, and depending on how significant
    the drop in performance is, we may consider it a model failure.
  prefs: []
  type: TYPE_NORMAL
- en: To get a better understanding of this phenomenon, the authors developed a framework
    for identifying temporal model degradation. They applied the framework to 32 datasets
    from four industries, using four standard ML models, and investigated how temporal
    model degradation can develop under minimal drifts in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Models and Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To avoid any model bias, the authors chose four different standard ML methods
    (Linear Regression, Random Forest Regressor, XGBoost, and a Multilayer Perceptron
    Neural Network). Each of these methods represents different mathematical approaches
    to learning from data. By choosing different model types, they were able to investigate
    similarities and differences in the way diverse models can age **on the same data**.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, to avoid domain bias, they chose 32 datasets from four industries
    (Healthcare, Weather, Airport Traffic, and Financial).
  prefs: []
  type: TYPE_NORMAL
- en: Another critical decision is that they only investigated pairs of model-dataset
    with good initial performance. This decision is crucial since it is not worthwhile
    investigating the degradation of a model with a poor initial fit.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07c8874d017956cf56a2d2832630e1d7.png)'
  prefs: []
  type: TYPE_IMG
- en: Examples of original data used in temporal degradation experiments. The timeline
    is on the horizontal axis and, each dataset target variable is on the vertical
    axis. When multiple data points were collected per day, they were shown with background
    color and a moving daily average curve. The colors highlighting the titles are
    going to be used along the blog post to easily recognize each dataset industry.
    Image retrieved from the original paper, annotated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Proposed Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To identify temporal model performance degradation, the authors designed a framework
    that emulates a typical production ML model. And ran multiple dataset-model experiments
    following this framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each experiment, they did four things:'
  prefs: []
  type: TYPE_NORMAL
- en: Randomly select one year of historical data as training data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Select an ML model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Randomly pick a future datetime point where they will test the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate the model’s performance change
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To better understand the framework, we need a couple of definitions. The most
    recent point in the training data was defined as *t_0*. The number of days between
    *t_0* and the point in the future where they test the model was defined as *dT*,
    which symbolizes the model’s age.
  prefs: []
  type: TYPE_NORMAL
- en: For example, a weather forecasting model was trained with data from January
    1st to December 31st of 2022\. And on February 1st, 2023, we ask it to make a
    weather forecast.
  prefs: []
  type: TYPE_NORMAL
- en: In this case
  prefs: []
  type: TYPE_NORMAL
- en: '*t_0* = December 31st, 2022 since it is the most recent point in the training
    data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*dT* = 32 days (days from December 31st and February 1st). This is the age
    of the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The diagram below summarizes how they performed every “history-future” simulation.
    We have added annotations to make it easier to follow.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/70128da5eab652b9c09dc391f311a9d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Diagram of the AI temporal degradation experiment. Image retrieved from the
    original paper, annotated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: To quantify the model’s performance change, they measured the mean squared error
    (MSE) at time *t_0* as *MSE(t_0)* and at the time of the model evaluation as *MSE(t_1)*.
  prefs: []
  type: TYPE_NORMAL
- en: Since *MSE(t_0)* is supposed to be low (each model was generalizing well at
    dates close to training). One can measure the relative performance error as the
    ratio between *MSE(t_0)* and *MSE(t_1)*.
  prefs: []
  type: TYPE_NORMAL
- en: '*E_rel* = *MSE(t_1)/MSE(t_0)*'
  prefs: []
  type: TYPE_NORMAL
- en: The researchers ran 20,000 experiments of this type for each dataset-model pair!
    Where *t_0* and *dT* were randomly sampled from a uniform distribution.
  prefs: []
  type: TYPE_NORMAL
- en: After running all of these experiments, they reported an *aging model chart*
    for each dataset-model pair. This chart contains 20,000 purple points, each representing
    the relative performance error *E_rel* obtained at *dT* days after training.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a31369d8347657f5810e3b7f2b2559e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Model aging chart for the Financial dataset and the Neural Network model. Each
    small dot represents the outcome of a single temporal degradation experiment.
    Image retrieved from the original paper, annotated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chart summarizes how the model’s performance changes when the model’s age
    increases. Key takeaways:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The error increases over time:** the model becomes less and less performant
    as time passes. This may be happening due to a drift present in any of the model’s
    features or due to concept drift.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**The error variability increases over time:** The gap between the best and
    worst-case scenarios increases as the model ages. When an ML model has high error
    variability, it means that it sometimes performs well and sometimes badly. The
    model performance is not just degrading, but it has erratic behavior.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The reasonably low median model error may still create the illusion of accurate
    model performance while the actual outcomes become less and less certain.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Major Degradation Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After performing all the experiments for all 4 (models) x 32 (datasets) = 128
    (model, dataset) pairs, temporal model degradation was observed in **91% of the
    cases**. Here we will look at the four most common degradation patterns and their
    impact on ML model implementations.
  prefs: []
  type: TYPE_NORMAL
- en: Gradual or no degradation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although no strong degradation was observed in the two examples below, these
    results still present a challenge. Looking at the original Patient and Weather
    datasets, we can see that the patient data has a lot of outliers in the Delay
    variable. In contrast, the weather data has seasonal shifts in the Temperature
    variable. But even with these two behaviors in the target variables, both models
    seem to perform accurately over time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a462360b1374531bd605395323ea4bab.png)'
  prefs: []
  type: TYPE_IMG
- en: Gradual ML model degradation patterns, with relative model error increasing
    no faster than linearly over time. Image retrieved from the original paper, annotated
    by the author.
  prefs: []
  type: TYPE_NORMAL
- en: The authors claim that these and similar results demonstrate that data drifts
    alone cannot be used to explain model failures or trigger model quality checks
    and retraining.
  prefs: []
  type: TYPE_NORMAL
- en: We have also observed this in practice. Data drift does not necessarily translates
    into a model performance degradation. That is why in our [ML monitoring workflow](https://www.notion.so/efc658f138e047e9bceb51d6975d0153),
    we focus on performance monitoring and use data drift detection tools only to
    investigate plausible explanations of the degradation issue since data drifts
    alone should not be used to trigger model quality checks.
  prefs: []
  type: TYPE_NORMAL
- en: Explosive degradation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model performance degradation can also escalate very abruptly. Looking at the
    plot below, we can see that both models were performing well in the first year.
    But at some point, they started to degrade at an explosive rate. The authors claim
    that these degradations can’t be explained alone by a particular drift in the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cac6af66fbb95e4673baa338b236def1.png)'
  prefs: []
  type: TYPE_IMG
- en: Explosive ML model aging patterns. Image retrieved from the original paper,
    annotated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s compare two model aging plots made from the same dataset but with different
    ML models. On the left, we see an explosive degradation pattern, while on the
    right, almost no degradation was seen. Both models were performing well initially,
    but the neural network seemed to degrade in performance faster than the linear
    regression (labeled as RV model).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ff176754b0996ebf7c463567dac6579e.png)'
  prefs: []
  type: TYPE_IMG
- en: Explosive and no degradation comparison. Image retrieved from the original paper,
    annotated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: Given this, and similar results, the authors concluded that *Temporal model
    quality depends on the choice of the ML model and its stability on a certain data
    set.*
  prefs: []
  type: TYPE_NORMAL
- en: In practice, we can deal with this type of phenomenon by continuously monitoring
    the estimated model performance. This allows us to address the performance issues
    before an explosive degradation is found.
  prefs: []
  type: TYPE_NORMAL
- en: Increase in error variability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the yellow (25th percentile) and the black (median) lines remain at relatively
    low error levels, the gap between them and the red line (75th percentile) increases
    significantly with time. As mentioned before, this may create the illusion of
    an accurate model performance while the real model outcomes become less and less
    certain.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/35ceea74e6221416629ef5054ab955dc.png)'
  prefs: []
  type: TYPE_IMG
- en: Increasing unpredictability AI model aging patterns. Image retrieved from the
    original paper, annotated by the author.
  prefs: []
  type: TYPE_NORMAL
- en: '*Neither the data nor the model alone can be used to guarantee consistent predictive
    quality. Instead, the temporal model quality is determined by the stability of
    a specific model applied to the specific data at a particular time.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Potential Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once we have found the underlying cause of the model aging problem, we can search
    for the best technique to fix the problem. The appropriate solution is context-dependent,
    so there is no simple fix that fits every problem.
  prefs: []
  type: TYPE_NORMAL
- en: Every time we see a model performance degradation, we should investigate the
    issue and understand the cause of it. Automatic fixes are almost impossible to
    generalize for every situation since multiple reasons can cause the degradation
    issue.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the paper, the authors proposed a potential solution to the temporal degradation
    problem. It is focused on ML model retraining and assumes that we have access
    to newly labeled data, that there are no data quality issues, and that there is
    no concept drift. To make this solution practically feasible, they mentioned that
    one needs the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Alert when your model must be retrained.**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alerting when the model’s performance has been degrading is not a trivial task.
    One needs access to the latest ground truth or be able to estimate the model’s
    performance. Solutions like [DLE and CBPE](https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html#confidence-based-performance-estimation-cbpe)
    from [NannyML](https://go.nannyml.com/nanny-github) can help to do that. For example,
    DLE (Direct Looks Estimation) and CBPE (Confidence-based Performance Estimation)
    use probabilistic methods to estimate the model’s performance even when targets
    are absent. They monitor the estimated performance and alert when the model has
    degraded.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b79b7d98fe34ad960204bdc781ff820.png)'
  prefs: []
  type: TYPE_IMG
- en: Plot taken from [NannyML](https://nannyml.com/)
  prefs: []
  type: TYPE_NORMAL
- en: '**2\. Develop an efficient and robust mechanism for automatic model retraining.**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we know that there is no data quality issue or concept drift, frequently
    retraining the ML model with the latest labeled data could help. However, this
    may cause new challenges, such as lack of model convergence, suboptimal changes
    to the training parameters, and [“catastrophic forgetting”](https://en.wikipedia.org/wiki/Catastrophic_interference)
    which is the *tendency of an artificial neural network to abruptly forget previously
    learned information upon learning new information.*
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Have constant access to the most recent ground truth.
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most recent ground truth will allow us to retrain the ML model and calculate
    the realized performance. The problem is that in practice, ground truth is often
    delayed, or it is expensive and time-consuming to get newly labeled data.
  prefs: []
  type: TYPE_NORMAL
- en: When retraining is very expensive, one potential solution would be to have a
    model catalog and then use the estimated performance to select the model with
    the best-expected performance. This could fix the issue of different models aging
    differently on the same dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Other popular solutions used in the industry are reverting your model back to
    a previous checkpoint, fixing the issue downstream, or changing the business process.
    To learn more about when it is best to apply each solution check out our previous
    blog post on [How to address data distribution shift](https://nannyml.com/blog/6-ways-to-address-data-distribution-shift).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The study by Vela et al. showed that the ML model’s performance doesn’t remain
    static, even when they achieve high accuracy at the time of deployment. And that
    different ML models age at different rates even when trained on the same datasets.
    Another relevant remark is that not all temporal drifts will cause performance
    degradation. Therefore, the choice of the model and its stability also becomes
    one of the most critical factors in dealing with performance temporal degradation.
  prefs: []
  type: TYPE_NORMAL
- en: These results give a theoretical backup of why monitoring solutions are important
    for the ML industry. Furthermore, it shows that ML model performance is prone
    to degradation. This is why every production ML model must be monitored. Otherwise,
    the model may fail without alerting the businesses.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Vela, D., Sharp, A., Zhang, R., *et al.* Temporal quality degradation in AI
    models. *Sci Rep* 12, 11654 (2022). [https://doi.org/10.1038/s41598-022-15245-z](https://doi.org/10.1038/s41598-022-15245-z)
  prefs: []
  type: TYPE_NORMAL
- en: I’m constantly writing about data science and machine learning on [Twitter](https://twitter.com/santiviquez)
    and [LinkedIn](https://www.linkedin.com/in/santiagoviquez/). Follow me if you
    want to join me and keep learning in public :)
  prefs: []
  type: TYPE_NORMAL
