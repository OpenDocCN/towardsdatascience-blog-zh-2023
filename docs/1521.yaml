- en: Change Point Detection — A Bayesian Approach
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/change-point-detection-a-bayesian-approach-8eb3cfca4a6e?source=collection_archive---------3-----------------------#2023-05-04](https://towardsdatascience.com/change-point-detection-a-bayesian-approach-8eb3cfca4a6e?source=collection_archive---------3-----------------------#2023-05-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Identifying a change point in time series analysis could provide you much more
    information about the series than you previously thought
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@almeida.eas?source=post_page-----8eb3cfca4a6e--------------------------------)[![Everton
    Almeida](../Images/926e5a571a461022a882c50dd352c9cb.png)](https://medium.com/@almeida.eas?source=post_page-----8eb3cfca4a6e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----8eb3cfca4a6e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----8eb3cfca4a6e--------------------------------)
    [Everton Almeida](https://medium.com/@almeida.eas?source=post_page-----8eb3cfca4a6e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7060488ff9e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchange-point-detection-a-bayesian-approach-8eb3cfca4a6e&user=Everton+Almeida&userId=7060488ff9e&source=post_page-7060488ff9e----8eb3cfca4a6e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----8eb3cfca4a6e--------------------------------)
    ·13 min read·May 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8eb3cfca4a6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchange-point-detection-a-bayesian-approach-8eb3cfca4a6e&user=Everton+Almeida&userId=7060488ff9e&source=-----8eb3cfca4a6e---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8eb3cfca4a6e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fchange-point-detection-a-bayesian-approach-8eb3cfca4a6e&source=-----8eb3cfca4a6e---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Change point analysis has become a field of interest in many areas of study.
    This kind of analysis refers to the problem of finding abrupt or sudden changes
    in a given time series. According to the definition made by Iwata *et al.* (2018),
    change point analysis is “the method for identifying change points, which are
    the moments when the probability distribution of a time series changes.” According
    to Van den Burg and Williams (2020), “moments of abrupt change in the behavior
    of a time series are often the cause of alarm, as they can suggest a significant
    change in the data-generating process.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: As demonstrated by Aminikhanghahi and Cook (2017) and Iwata et al. (2018), the
    increasing attention paid to this kind of analysis is due to recent technological
    developments. These developments generate large amounts of data that often need
    to be closely monitored, such as robotics, medicine, meteorology, voice and image
    recognition, etc. There is a wide variety of models and methodologies to deal
    with such a problems. But since it is not the goal of this article to make a descriptive
    analysis of these models, I would like to suggest the work of Van den Burg and
    Williams (2020) to you to get a better overview of those methodologies. There
    you can find the differences between online and offline change point detection;
    univariate and multivariate approaches, which could be parametric or nonparametric;
    and supervised or unsupervised models.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 Aminikhanghahi 和 Cook (2017) 以及 Iwata 等人 (2018) 所示，对这种分析的关注度增加是由于最近的技术发展。这些发展生成大量的数据，这些数据往往需要被密切监控，例如机器人技术、医学、气象、语音和图像识别等。应对这些问题有多种模型和方法。然而，由于本文的目标不是对这些模型进行描述性分析，我建议你参考
    Van den Burg 和 Williams (2020) 的工作，以更好地了解这些方法论。在那里你可以找到在线和离线变化点检测的区别；单变量和多变量方法，这些方法可以是参数化的或非参数化的；以及监督或无监督模型。
- en: '![](../Images/1512724c7a33c1671165ca882e470972.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1512724c7a33c1671165ca882e470972.png)'
- en: Photo by [Tech Daily](https://unsplash.com/@techdailyca?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    — [Unsplash](https://unsplash.com/pt-br/fotografias/ztYmIQecyH4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源 [Tech Daily](https://unsplash.com/@techdailyca?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    — [Unsplash](https://unsplash.com/pt-br/fotografias/ztYmIQecyH4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: 'From the beginning, a time series, according to Ehlers (2007), “is a collection
    of observations made sequentially over time,” whose main characteristic is the
    dependence that a given observation has on the neighboring observations. A time
    series can be continuous or discrete, and in the first case, according to Ehlers
    (2007), having the set *T={t∶ t1< t < t2},* the series is denoted by *{X(t):t
    ∈ T}*. Therefore, taking an observation window of the time series T with n observations,
    we have a time series denoted by *{Xm, X(m+1),…, Xn }*. According to Aminikhanghahi
    and Cook (2017, p. 3), “the detection of the change point can be defined as a
    problem of hypothesis testing, between two alternatives”, namely “the null hypothesis
    *H0*: ‘no change occurs’ ‘ and the alternative hypothesis *H1*: ‘a change occurs’”.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '从一开始，根据 Ehlers (2007) 的定义，“时间序列是指在时间上顺序进行的观测集合”，其主要特征是给定观测对邻近观测的依赖性。时间序列可以是连续的或离散的，在前一种情况下，根据
    Ehlers (2007) 的定义，集合 *T={t∶ t1< t < t2},* 该序列表示为 *{X(t):t ∈ T}*。因此，取时间序列 T 的一个观测窗口，包含
    n 个观测值，我们得到一个表示为 *{Xm, X(m+1),…, Xn }* 的时间序列。根据 Aminikhanghahi 和 Cook (2017，第
    3 页) 的说法，“变化点的检测可以定义为一个假设检验问题，存在两个备选方案”，即“原假设 *H0*: ‘没有变化’” 和备择假设 *H1*: ‘发生了变化’”。'
- en: From the Beginning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从一开始
- en: 'So if you like to code, it’s time to run Jupyter Notebook and start making
    some simulations and analysis as we take a “random walk” throughout this approach.
    Let’s import the following packages:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果你喜欢编程，是时候启动 Jupyter Notebook 并开始进行一些模拟和分析，我们将通过这种方法进行“随机漫步”。让我们导入以下包：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will start with a time series *y(t)* consisting of two-time series, which
    are *y(t1)* with mean *μ=1* plus some noise and *y(t2)* with mean *μ=2* plus some
    noise, both with 30 observations. As you might think, the proposed time series
    will have a considerable change point.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个时间序列 *y(t)* 开始，该序列由两个时间序列组成，*y(t1)* 的均值是 *μ=1* 加上一些噪声，*y(t2)* 的均值是 *μ=2*
    加上一些噪声，两个序列都有 30 个观测值。正如你可能想的那样，提议的时间序列将会有一个显著的变化点。
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![](../Images/2eb2df4fb8ebc098b9217bc59a771927.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2eb2df4fb8ebc098b9217bc59a771927.png)'
- en: A time series with two differing averages — Image by author
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有两个不同均值的时间序列 — 作者提供的图片
- en: If you know Bayesian statistics, you know that the construction of any model
    is fundamentally composed of 3 distributions. The prior distribution *h(*θ), reflects
    our prior knowledge about the problem. The likelihood *f(x|*θ) reflects the data
    obtained and has to be incorporated into the prior distribution. And that will
    result in a posterior distribution *h(*θ|x), which we are interested in. That’s
    how we use Bayes’ theorem.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Fuzzy Clustering
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, the first (and most important?) problem we have, is to obtain
    a prior distribution from the time series we built — that’s the first piece of
    the model. **The problem is: We do not have one!** And if you are dealing with
    a time series, once we get a prior distribution, most of the tasks are already
    done.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: D’Angelo *et al.* (2011) took an interesting approach to get around this problem.
    He used a Kohonen Network to clusterize the time series. Unlike hard clustering,
    the Kohonen Network is a fuzzy clustering algorithm, which means that any given
    point X is associated with group A with probability *p*. This association is given
    by the function *fA(X)* which associates with each point in A a real number in
    the interval *[0, 1]*, representing the grade of membership of X in A.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'For a complete and better explanation of the Kohonen Network, you can refer
    to Kohonen (1990) and Haykin (2007). Using Python, I built such a network using
    two functions:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If you call both functions with our time series sequentially, you may plot
    the results and get something like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/4ee3386460982257b8757c13419ed68f.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: The fuzzy clusterization for the time series y(t) using Kohonen Network — Image
    by author
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: And that’s pretty interesting! With the Kohonen Network, we are able to split
    the time series *y(t)*. This chart shows we have two clusters since we set *K=2\.*
    In the *xlabel,* we have each point of the time series, while the *ylabel* shows
    the probability that a given point is associated with one of the two clusters.
    As you might see, the blue line shows us that until we reach point 30 all the
    points are more likely (around ~99%) to belong to the first group or the set *μ1(t)*.
    The red line shows the opposite since it represents the associations to the second
    group, namely the set *μ2(t)*. That’s reasonable since we built a time series
    with two different averages, and illustratively this plot is related to the first
    one.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Although interesting we did not really find a change point until now (we have
    some clues) and **there’s nothing Bayesian here.**
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: By the way, most of the time, the distinction between the points of a time series
    will not be that simple. For instance, if we built the time series *y(t)* with
    *y(t1)* with mean *μ=1* plus some noise and *y(t2)* with mean *μ=1.3* (instead
    of 2)plus some noise, would that split be that good? I will let you try this exercise…
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: The Metropolis-Hastings Algorithm comes to the Game
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you tried the exercise above, you found yourself in trouble using just the
    Kohonen Network to find any indication of a change point in an alternative time
    series. That is because the Kohonen network does not provide us with a change
    point, but two sets of continuous variables, representing the association of each
    point to a given cluster.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: But recall that the sets *μ1(t)* and *μ2(t)* have its values within the interval
    [0,1]. This implies saying that *μ1(t)* and *μ2(t)* are approximations of Beta
    distributions with different parameters (Have you ever heard about Kullback–Leibler?).
    According to D’Angelo *et al.* (2011), assuming that the change point is denoted
    by *m*, then for *t≤m*, we will have a *Beta(a,b)* distribution and a *Beta(c,d)*
    distribution for *t>m*. Given the properties of a Beta distribution, if there’s
    any change point in the time series, *parameter a* will be greater than *parameter
    b* in *Beta(a,b)* and *parameter c* will be smaller than *parameter d* in *Beta(c,d).*
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**The problem is:** How do you build those two Beta Distributions? The Metropolis-Hastings
    Algorithm is a form of a Markov Chain Monte Carlo initially proposed by Metropolis
    *et al.* (1953) and then generalized by Hastings (1970). According to Gelman *et
    al.* (2003), the goal of any Markov chain simulation “is to create a Markov process
    whose stationary distribution is specified by *p(θ | x).*” Running the simulation
    enough allows us to obtain a distribution close enough to the stationary and posterior
    distribution. The posterior could be resumed in terms of expectations of particular
    functions of a parameter θ, that is, *∫g(θ)p(θ | x)dθ = E [g(θ) | x].* Such integral
    is not trivial and that’s why the MCMC methods are good to approximate the posterior
    distribution.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 'Metropolis-Hastings’ algorithm uses the idea of rejection, which means it generates
    a value from an auxiliary distribution and accepts it with a given probability.
    If you are unfamiliar with MCMC methods, you might be questioning how the algorithm
    may reject a drawn value. We use the transition rule given by Hastings (1970):'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b2cc9ea9952a4f329b163b20d4c24abf.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Putting it in order words, we can use the two sets of continuous variables,
    given by the fuzzy clustering to reject randomly drawn values from a given prior
    distribution for the change point detection. If you want to learn more about MCMC
    methods, I suggest Gamerman and Lopes (2018).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get back to the Jupyter Notebook. The function below is an implementation
    of the Metropolis-Hastings Algorithm for this problem. Although powerfoul, this
    algorithm requires some things. The first is to set a prior distribution for every
    parameter that needs to be found. For the parameter *m*, we are using a uniform
    distribution between 1 and 60, which means the algorithm randomly selects a change
    point candidate in the time series. For the parameters *a, b, c* and *d,* I selected
    weakly information gamma distributions. The function also needs the arguments,
    which are a set of random variables (*μ1(t)* or *μ2(t))* and the number of simulations.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Call that function with the two required parameters: here, I sent ***center_1***
    given by the function *Fuzzy_Set* and ***n_sims=1000***'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/1d13f30e616dfe0d2ef69737988ce446.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: The Metropolis-Hastings Algorithm Simulations — Image by author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: You finally found the change point now. This chart is interesting because it
    shows us how the drawing process was made. The first value drawn given by the
    uniform distribution was *m=55*. The algorithm rejected it and then tried another
    until it get a satisfactory and stationary result. After ~150 additional runs
    the value of *m=30* could not be rejected by the algorithm anymore.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the function returns the sampled values for every parameter, we may plot
    their values as well. Starting with the parameter *m*, which is all the change
    points drawn. To see the density plot, you may discard the first 200 simulations
    as “burn-in”:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/dc7910e8207a36aea9c384e0ad8e96ef.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: Density Plot for the Change Point Candidates — Image by author
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: We may also create Beta distributions using the mean of the four other parameters,
    namely the parameters *a, b, c,* and *d.* As we discussed previously these parameters
    are essential for the Metropolis-Hastings algorithm once the reject rule must
    assert that for *t≤m*, we will have a *Beta(a,b)* distribution and a *Beta(c,d)*
    distribution for *t>m*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go ahead and build a representation of that using the variables *a_params,
    b_params, c_params* and *d_params*, which contains the sampled values for *a,
    b, c* and *d*
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The first Beta Distribution built with the mean of the parameters *a* and *b*
    is in red and the second with the mean of the parameters *c* and *d* is the blue
    one. In the middle, where both are less dense, we found the change point. Undoubtedly
    one of the great advantages of using such an approach is the availability of such
    distributions, since we can use them to make Bayesian inferences, enrich a predictive
    model or even use other types of Monte Carlo simulations.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d5bf808c5b18cb1b49dbdd5783a44c7f.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Representations of Two Beta Distribuitions for the A, B, and D parameters —
    Image by author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finding change points in time series could prevent systems from getting into
    serious trouble. Just imagine a machine whose temperature has to be controlled.
    Any abrupt changes must be recognized as soon as possible in order for an engineer
    to inspect them. Or the energy consumption in various production facilities. Any
    excessive consumption has to be analyzed because it may indicate some deviation
    in production or even energy leakage, significantly impacting production costs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: That said, the approach developed by D’Angelo (2011) and implemented here in
    Python proved to be of great value for detecting change points in a given time
    series. In addition, as previously pointed out, another great aspect of this approach
    is precisely the fact we obtain two beta distributions as outputs, which can be
    really useful.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AMINIKHANGHAHI, Samaneh e COOK, J. Diane. **A Survey of Methods for Time Series
    Change Point Detection.** Knowledge and Information Systems, 51, 2017.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: D’ANGELO, Marcos Flávio *et al.* A Fuzzy/Bayesian Approach for the Time Series
    Change Point Detection Problem. Pesquisa Operacional, 31(2), 2011.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: EHLERS, Ricardo S. **Inferência Bayesiana**. 5ª Ed. Departamento de Estatística
    da Universidade Federal do Paraná, 2007.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: FAMA, Eugene. **Random Walks in Stock Market Prices**. Financial Analysts, 21,
    1965.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: _____________ **Efficient Capital Markets:** A Review of Theory and Empirical
    Work. The Journal of Finance, 25, 1970.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: 'GAMERMAN, Dani. LOPES, Hedibert Freitas. **Markov Chain Monte Carlo:** Stochastic
    Simulation for Bayesian Inference. 2º Ed. Florida : Chapman & Hall/CRC, 2006\.
    315p.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'GELMAN, Andrew *et al.* **Bayesian Data Analysis.** 2ª Ed. Florida : Chapman
    & Hall/CRC, 2003\. 668p.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: HASTINGS, W. K. **Monte Carlo Sampling Methods Using Markov Chains and their
    Applications.** Biometrika, 57, 1970.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'HAYKIN, Simon. **Redes Neurais**: Princípios e Práticas. 2ª Ed. Porto Alegre
    : Bookman, 2007\. 900p.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'IWATA, Takuma *et al.* **Accelerating Online Change-Point Detection Algorithm
    using 10GbE FPGA NIC**. Trabalho apresentado na 24ª Conferência Internacional
    de Computação Paralela e Distribuída. Turim : 2018.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'KOHONEN, Teuvo. **Self-Organizing Maps**. Nova Iorque : Springer, 1990, 501p.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: METROPOLIS, Nicholas *et al.* **Equation of State Calculations by Fast Computing
    Machines**. Journal of Chemical Physics, 21, 1953.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'OH KJ, *et al*. **Developing Time-Based Clustering Neural Networks To Use Change-Point
    Detection: Application To Financial Time Series.** Asia-Pacific Journal of Operational
    Research, 22(1), 2005.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'PAULINO, Carlos Daniel *et al.* **Estatística Bayesiana**.2º Edição. Lisboa
    : Fundação Calouste Gulbenkian, 2018, 601p.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: VAN DEN BURG, Gerrit J. J., WILLIAMS, Christopher K. I. **An Evaluation of Change
    Point Detection Algorithms**. stat.ML, arXiv:2003.06222, 2020
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
