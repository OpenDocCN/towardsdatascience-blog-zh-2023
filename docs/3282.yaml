- en: Easily Implement Multiclass SVM From Scratch in Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 轻松用 Python 从头实现多分类支持向量机
- en: 原文：[https://towardsdatascience.com/implement-multiclass-svm-from-scratch-in-python-b141e43dc084?source=collection_archive---------2-----------------------#2023-11-04](https://towardsdatascience.com/implement-multiclass-svm-from-scratch-in-python-b141e43dc084?source=collection_archive---------2-----------------------#2023-11-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/implement-multiclass-svm-from-scratch-in-python-b141e43dc084?source=collection_archive---------2-----------------------#2023-11-04](https://towardsdatascience.com/implement-multiclass-svm-from-scratch-in-python-b141e43dc084?source=collection_archive---------2-----------------------#2023-11-04)
- en: Comes with a Free Deep Overview on SVMs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附带支持向量机的深度概述
- en: '[](https://essamwissam.medium.com/?source=post_page-----b141e43dc084--------------------------------)[![Essam
    Wisam](../Images/6320ce88ba2e5d56d70ce3e0f97ceb1d.png)](https://essamwissam.medium.com/?source=post_page-----b141e43dc084--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b141e43dc084--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b141e43dc084--------------------------------)
    [Essam Wisam](https://essamwissam.medium.com/?source=post_page-----b141e43dc084--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://essamwissam.medium.com/?source=post_page-----b141e43dc084--------------------------------)[![Essam
    Wisam](../Images/6320ce88ba2e5d56d70ce3e0f97ceb1d.png)](https://essamwissam.medium.com/?source=post_page-----b141e43dc084--------------------------------)[](https://towardsdatascience.com/?source=post_page-----b141e43dc084--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----b141e43dc084--------------------------------)
    [Essam Wisam](https://essamwissam.medium.com/?source=post_page-----b141e43dc084--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccb82b9f3b87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplement-multiclass-svm-from-scratch-in-python-b141e43dc084&user=Essam+Wisam&userId=ccb82b9f3b87&source=post_page-ccb82b9f3b87----b141e43dc084---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b141e43dc084--------------------------------)
    ·14 min read·Nov 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb141e43dc084&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplement-multiclass-svm-from-scratch-in-python-b141e43dc084&user=Essam+Wisam&userId=ccb82b9f3b87&source=-----b141e43dc084---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fccb82b9f3b87&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplement-multiclass-svm-from-scratch-in-python-b141e43dc084&user=Essam+Wisam&userId=ccb82b9f3b87&source=post_page-ccb82b9f3b87----b141e43dc084---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----b141e43dc084--------------------------------)
    ·14 min read·2023年11月4日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fb141e43dc084&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplement-multiclass-svm-from-scratch-in-python-b141e43dc084&user=Essam+Wisam&userId=ccb82b9f3b87&source=-----b141e43dc084---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb141e43dc084&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplement-multiclass-svm-from-scratch-in-python-b141e43dc084&source=-----b141e43dc084---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fb141e43dc084&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fimplement-multiclass-svm-from-scratch-in-python-b141e43dc084&source=-----b141e43dc084---------------------bookmark_footer-----------)'
- en: In this story, we shall implement the support vector machine learning algorithm
    in its general soft-margin and kernelized form. We will start by providing a brief
    overview of SVM and its training and inference equations, then subsequently translate
    these into code to develop the SVM model. Afterwards, we extend our implementation
    to handle multiclass scenarios and conclude by testing our model using Sci-kit
    Learn.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个故事中，我们将实现支持向量机学习算法的通用软边距和核化形式。我们将首先简要概述支持向量机及其训练和推断方程，然后将这些方程转换为代码以开发支持向量机模型。之后，我们扩展我们的实现以处理多分类场景，并通过使用
    Sci-kit Learn 测试我们的模型来总结。
- en: 'Thus, by the end of this story:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，到本故事结束时：
- en: You will gain a clear perspective of various important SVM concepts.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将清晰地理解各种重要的支持向量机概念。
- en: You will be able to implement, with genuine comprehension, the SVM model from
    scratch for the binary and multiclass cases.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将能够以真正的理解从头实现支持向量机模型，包括二分类和多分类情况。
- en: '![](../Images/6a4535e70a07e8f4eb155ced0108351c.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a4535e70a07e8f4eb155ced0108351c.png)'
- en: Beautiful Van Gogh painting for Two Stars and a Line Between them like Starry
    Night— Generated by author using DALLE 2
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 美丽的梵高画作，描绘了“星夜”中的“两颗星星与它们之间的线”——由作者使用 DALLE 2 生成
- en: Table of Content
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目录
- en: · [Brief Overview](#af4c)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: · [简要概述](#af4c)
- en: ∘ [Hard Margin SVM](#018a)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [硬间隔 SVM](#018a)
- en: ∘ [Soft Margin SVM](#0953)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [软间隔 SVM](#0953)
- en: ∘ [Kernel Soft Margin SVM](#a603)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [核软间隔 SVM](#a603)
- en: · [Implementation](#48da)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: · [实现](#48da)
- en: ∘ [Basic Imports](#25b3)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [基本导入](#25b3)
- en: ∘ [Defining Kernels and SVM Hyperparameters](#9c9f)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [定义核函数和 SVM 超参数](#9c9f)
- en: ∘ [Define the Predict Method](#ce06)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [定义预测方法](#ce06)
- en: ∘ [Define the Predict Method](#3067)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [定义预测方法](#3067)
- en: ∘ [Test the Implementation](#a728)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [测试实现](#a728)
- en: ∘ [Generalizing Fit to Multiclass](#19b6)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [对多分类的泛化适应](#19b6)
- en: ∘ [Generalizing Predict to Multiclass](#ec98)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [对多分类的泛化预测](#ec98)
- en: ∘ [Testing the Implementation](#6d1e)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ∘ [测试实现](#6d1e)
- en: Brief Overview
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简要概述
- en: Hard Margin SVM
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬间隔 SVM
- en: The goal in SVM is to fit the hyperplane that would attain the maximum margin
    (distance from the closest points from in the two classes). It can be shown, and
    is intuitive that such hyperplane (A) has better generalization properties and
    is more robust to noise than a hyperplane that doesn’t maximize the margin (B).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 的目标是拟合出能够获得最大间隔（距离两个类别中最近点的距离）的超平面。可以证明，并且直观上，这样的超平面（A）具有更好的泛化能力，并且比一个没有最大化间隔的超平面（B）更能抵抗噪声。
- en: '![](../Images/737a87973433b07c15a0387f14999fa6.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/737a87973433b07c15a0387f14999fa6.png)'
- en: Figure by [Ennepetaler86](https://commons.wikimedia.org/wiki/User:Ennepetaler86)
    on [Wikimedia](https://commons.wikimedia.org/wiki/File:Svm_intro.svg). [CC BY-SA
    3.0 Unported](https://creativecommons.org/licenses/by-sa/3.0/deed.en).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图示来源于 [Ennepetaler86](https://commons.wikimedia.org/wiki/User:Ennepetaler86)
    在 [Wikimedia](https://commons.wikimedia.org/wiki/File:Svm_intro.svg)。 [CC BY-SA
    3.0 Unported](https://creativecommons.org/licenses/by-sa/3.0/deed.en)。
- en: 'In order to achieve this, SVM finds the hyperplane’s *W* and b by solving the
    following optimization problem:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，SVM 通过解决以下优化问题来找到超平面的 *W* 和 b：
- en: '![](../Images/32796612256ef92f355b7ddfd38d5449.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/32796612256ef92f355b7ddfd38d5449.png)'
- en: 'It attempts to find *W,b* that maximizes the distance to the closest point
    and classifies everything correctly (as in the constraint where y takes ±1). This
    can be shown to be equivalent to the following optimization problem:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 它尝试找到*W, b*，以最大化到最近点的距离，并正确分类所有数据（如在y取±1的约束条件中）。这可以证明等价于以下优化问题：
- en: '![](../Images/1895a0f3d251c878035d72174f328005.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1895a0f3d251c878035d72174f328005.png)'
- en: For which one can write the equivalent [dual](https://medium.com/p/de09f645b068)
    optimization problem
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，可以写出等价的 [对偶](https://medium.com/p/de09f645b068) 优化问题
- en: '![](../Images/005e90809d22718fd8291ae9b8ccd40a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/005e90809d22718fd8291ae9b8ccd40a.png)'
- en: 'The solution to this yields a Lagrange multiplier for each point in the dataset
    which we assume to have size *m: (α****₁****, α₂, …, α_N)*. The objective function
    is clearly quadratic in *α* and the constraints are linear which means that this
    can be easily solved with [quadratic programming](https://en.wikipedia.org/wiki/Quadratic_programming).
    Once the solution found, it follows from the derivation of the dual that:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '这提供了一个拉格朗日乘子，针对数据集中每一个点，我们假设其大小为 *m: (α₁, α₂, …, α_N)*。目标函数在 *α* 上显然是二次的，约束条件是线性的，这意味着可以很容易地通过
    [二次规划](https://en.wikipedia.org/wiki/Quadratic_programming) 解决。一旦找到解决方案，从对偶问题的推导中可以得到：'
- en: '![](../Images/4482d9a60a50d728e3753aeb4fcf2c08.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4482d9a60a50d728e3753aeb4fcf2c08.png)'
- en: '*(xₛ,yₛ)* is any point with *α>0*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*(xₛ, yₛ)* 是任何 *α>0* 的点'
- en: Notice that only points with *α>0* define the hyperplane (contribute to the
    sum). Those are called support vectors.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，只有 *α>0* 的点定义了超平面（对和有贡献）。这些点称为支持向量。
- en: 'And thereby, the prediction equation, that when given a new example *x,* returns
    its prediction *y=±1* is:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当给定一个新的示例 *x* 时，预测方程返回其预测 *y=±1* 为：
- en: '![](../Images/be855d245c929e03b7b9c07efc96430e.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be855d245c929e03b7b9c07efc96430e.png)'
- en: Involves plugging then doing some algebraic simplification
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 涉及到插入并进行一些代数简化
- en: This basic form of SVM is called hard margin SVM because the optimization problem
    it solves (as defined above) enforces that all points in training must be classified
    correctly. In practical scenarios, there may be some noise that prevents or limits
    the existence of a hyperplane that perfectly separates the data in which case
    the optimization problem would return no or a poor solution.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种基本形式的SVM称为硬边界SVM，因为它解决的优化问题（如上所述）强制训练中的所有点必须被正确分类。在实际场景中，可能存在一些噪声，这些噪声阻止或限制了完全分开数据的超平面的存在，这种情况下优化问题可能没有返回解或返回了一个较差的解。
- en: Soft Margin SVM
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 软边界SVM
- en: '![](../Images/a76e2673690129189779c4d61cd0ec0f.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a76e2673690129189779c4d61cd0ec0f.png)'
- en: Fit by Soft Margin SVM by [Mangat et al](https://www.researchgate.net/publication/366243093_High-Frequency_Trading_with_Machine_Learning_Algorithms_and_Limit_Order_Book_Data)
    on [Research Gate](https://www.researchgate.net/figure/Support-vector-classification-for-the-non-separable-case-Points-corresponding-to-x-1-and_fig2_366243093).
    [CC BY-SA 4.0 International](https://creativecommons.org/licenses/by/4.0/)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由[Mangat等人](https://www.researchgate.net/publication/366243093_High-Frequency_Trading_with_Machine_Learning_Algorithms_and_Limit_Order_Book_Data)在[Research
    Gate](https://www.researchgate.net/figure/Support-vector-classification-for-the-non-separable-case-Points-corresponding-to-x-1-and_fig2_366243093)上适配的软边界SVM。[CC
    BY-SA 4.0 International](https://creativecommons.org/licenses/by/4.0/)
- en: 'To generalize hard margin SVM, soft margin SVM adapts the optimization problem
    by introducing a C constant (user given hyperparamer) that controls how “hard”
    it should be. In particular, it modifies the primal optimization problem to become
    the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了推广硬边界SVM，软边界SVM通过引入一个C常数（用户指定的超参数）来调整优化问题，以控制其“难度”。具体来说，它将原始优化问题修改为以下形式：
- en: '![](../Images/dcca387cb13de3cd5905b5325539708b.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dcca387cb13de3cd5905b5325539708b.png)'
- en: modifications in blue
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝色部分的修改
- en: which allows each point to make some violation ϵₙ (e.g., be in the wrong side
    of the hyperplane) but still aims to reduce them overall by weighting their sum
    in the objective function by C. It becomes equivalent to hard margin as C approaches
    infinity (generally before it does). Meanwhile, a smaller C would allow more violations
    (in return for a wider margin; i.e., smaller *wᵗw*).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这允许每个点有一些违例ϵₙ（例如，位于超平面错误的一侧），但仍然通过在目标函数中用C加权它们的总和来减少这些违例。随着C趋近于无穷大（通常在之前），它变得等同于硬边界。与此同时，更小的C会允许更多的违例（以换取更宽的边界；即，更小的*wᵗw*）。
- en: Quite surprisingly, it can be shown that the equivalent dual problem only changes
    by constraining *α* for each point to be *≤C.*
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 相当令人惊讶的是，可以证明等价的对偶问题仅通过将每个点的*α*限制为*≤C*而发生变化。
- en: '![](../Images/4e0378a5399a659e15e095b16648da47.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e0378a5399a659e15e095b16648da47.png)'
- en: Since violations are allowed, support vectors (points with *α>0)* are no longer
    all on the margin’s edge. It can be shown that any support vector that has committed
    a violation will have *α=C* and that non-support vectors (*α=0)* cannot commit
    violations. We call support vectors that potentially committed violations (*α=C*)
    “non-margin support vectors” and other pure ones (that have not committed violations;
    lie on the edge) “margin support vectors” (0<*α<C*).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于允许违例，支持向量（*α>0*的点）不再全部位于边界的边缘。可以证明，任何已发生违例的支持向量将有*α=C*，而非支持向量（*α=0*）不能发生违例。我们称潜在发生违例的支持向量（*α=C*）为“非边界支持向量”，而其他未发生违例的纯支持向量（位于边缘）称为“边界支持向量”（0<*α<C*）。
- en: 'It can be shown that the inference equation doesn’t change:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明推断方程没有变化：
- en: '![](../Images/be855d245c929e03b7b9c07efc96430e.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be855d245c929e03b7b9c07efc96430e.png)'
- en: However, now *(xₛ,yₛ)* must now be a support vector that has not committed violations
    because the equation assumes it’s on the margin’s edge (previously, any support
    vector could be used).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，现在*(xₛ,yₛ)*必须是一个没有发生违例的支持向量，因为方程假设它在边界的边缘（之前，任何支持向量都可以使用）。
- en: Kernel Soft Margin SVM
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核函数软边界SVM
- en: Soft Margin SVM extends the Hard Margin SVM to handle noise, but frequently,
    data is not separable by a hyperplane due to factors beyond noise, such as being
    naturally nonlinear. Soft Margin SVM can be used in cases like these, but then
    the optimal solution will probably involve a hyperplane that permits much more
    errors than is tolerable in reality.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 软边界SVM将硬边界SVM扩展以处理噪声，但通常数据由于噪声之外的因素，如自然非线性，而无法被超平面分开。在这些情况下，软边界SVM可以使用，但最佳解可能涉及允许比现实中容许的更多错误的超平面。
- en: '![](../Images/2ef99eb747b1d860fffc880654080914.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ef99eb747b1d860fffc880654080914.png)'
- en: Figure by [Machine Learner](https://commons.wikimedia.org/w/index.php?title=User%3AMachine_Learner&action=edit&redlink=1)
    on [Wikimedia](https://commons.wikimedia.org/wiki/File:Nonlinear_SVM_example_illustration.svg).
    [CC BY-SA 4.0 International](https://creativecommons.org/licenses/by/4.0/)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Kernel Soft Margin SVM generalizes Soft Margin SVM to deal with situations where
    the data is naturally nonlinear. For instance, in the example shown on the left
    there is no linear hyperplane that Soft Margin SVM can find, regardless to the
    setting of C, that would decently separate the data.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible, however, to map each point *x* in the dataset to a higher dimension
    via some transform function *z=Φ(x)*to make the data more linear (or perfectly
    linear) in the new higher dimensional space. This is equivalent to replacing *x*
    with *z* in the dual to get:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1386d4ace7586b2a1daf2f084989ac78.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: 'In reality, especially when *Φ* transforms into a very high-dimensional space,
    computing *z* can take a very long time. This is solved by the kernel trick which
    replaces the *z*ᵗ*z* with an **equivalent** computation of a mathematical function
    (called kernel function) and which is much faster (e.g., an algebraic simplification
    of *z*ᵗ*z).* For instance, here are some popular kernel functions (each of which
    corresponds to some transformation *Φ* to a higher dimensional space):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf4c4cc694cdc99432a46577cc381b04.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: Degree of polynomial (Q) and RBF γ are hyperparameters (decided by the user)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 'With this, the dual optimization problem becomes:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8efaaa3293103ac2d3719eb572b25de6.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: 'and intuitively, the inference equation becomes (after algebraic manipulation):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6cdc91661bd6a7a3600c83566e74ed4d.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
- en: A full derivation of all the equations above assuming that you have the [mathematical
    background](https://medium.com/p/de09f645b068) can be found [here](https://drive.google.com/file/d/1f_VRZ_SICOnciEoLr-Nig4cr2fLczE_y/view?usp=sharing).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b9d94720b23e6f3ccc0e570e0db6320a.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: Photo by [Scott Graham](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For the implementation we will use
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Basic Imports
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We start by importing some basic libraries:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Defining Kernels and SVM Hyperparameters
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We start by defining the three kernels using their respective functions
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bf4c4cc694cdc99432a46577cc381b04.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: Degree of polynomial (Q) and RBF γ are hyperparameters (decided by the user)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For consistency with other kernels, the linear kernel takes an extra useless
    hyperparameter. As obvious, `kernel_funs` takes a string for the kernel and returns
    the corresponding kernel function.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s carry on by defining the constructor:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The SVM has three main hyperparameters, the kernel (we store the string given
    and the corresponding kernel function), the regularization parameter C and the
    kernel hyperparameter (to be passed to the kernel function); it represents Q for
    the polynomial kernel and γ for the RBF kernel.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 有三个主要超参数，核函数（我们存储给定的字符串和相应的核函数）、正则化参数 C 和核超参数（传递给核函数）；它代表多项式核的 Q 和 RBF 核的
    γ。
- en: Define the Fit Method
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义 Fit 方法
- en: 'To extend this class with `fit` and `predict` functions in separate cells,
    we will define the following function and use it as a decorator later:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在单独的单元格中扩展此类，包含 `fit` 和 `predict` 函数，我们将定义以下函数，并稍后将其用作装饰器：
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Recall that fitting the SVM corresponds to finding the support vector *α* for
    each point by solving the dual optimization problem:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾拟合 SVM 对应于通过解决对偶优化问题找到每个点的支持向量 *α*：
- en: '![](../Images/8e481f884c10d6dc6e79e6d1a2d629e6.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e481f884c10d6dc6e79e6d1a2d629e6.png)'
- en: 'Let ***α*** be a variable column vector*(α****₁*** *α₂ … α_N)*ᵗ and let y be
    a constant column vector for the labels *(y****₁*** *y₂ … y_N)*ᵗ and let *K* be
    a constant matrix where *K[n,m]* computes the kernel at *(xₙ, xₘ)*. Recall the
    following index-based equivalences for the dot product, outer product and quadratic
    form respectively:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 设 ***α*** 为一个变量列向量 *(α****₁*** *α₂ … α_N)*ᵗ，并且设 y 为一个常量列向量 *(y****₁*** *y₂ …
    y_N)*ᵗ，并且设 *K* 为一个常量矩阵，其中 *K[n,m]* 计算 *(xₙ, xₘ)* 处的核函数值。回顾以下基于索引的点积、外积和二次形式的等价：
- en: '![](../Images/c2f6f972e0384b38163c88cab37a80c1.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2f6f972e0384b38163c88cab37a80c1.png)'
- en: 'to be able to write the dual optimization problem in matrix form as follow:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以便能够以矩阵形式写出对偶优化问题，如下：
- en: '![](../Images/ebff3482f7b778cab6f88c0dd476e20b.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebff3482f7b778cab6f88c0dd476e20b.png)'
- en: 'Knowing that this is a quadratic program as we hinted earlier, we can read
    over Quadratic Programming in CVXOPT’s documentation:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这如我们之前所提示的是一个二次规划问题，我们可以查看 CVXOPT 文档中的二次编程：
- en: '![](../Images/284be9ba0c0ee37d6eaea4c509310e0f.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/284be9ba0c0ee37d6eaea4c509310e0f.png)'
- en: From [CVXOPT](https://cvxopt.org/userguide/coneprog.html) Documentation. [GNU
    General Public License](http://www.gnu.org/licenses/gpl-3.0.html)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [CVXOPT](https://cvxopt.org/userguide/coneprog.html) 文档。[GNU 通用公共许可证](http://www.gnu.org/licenses/gpl-3.0.html)
- en: The square brackets tell you that you can call this with *(P,q)* only or *(P,q,G,h)*
    or *(P, q, G, h, A, b)* and so on (anything not given will be set by a default
    value such as 1).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 方括号告诉你，你可以仅用 *(P,q)*、*(P,q,G,h)* 或 *(P, q, G, h, A, b)* 等（任何未给出的项将被设置为默认值，例如
    1）。
- en: 'To know the values for *(P, q, G, h, A, b)* in our case, we make the following
    comparison:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解我们案例中 *(P, q, G, h, A, b)* 的值，我们进行以下比较：
- en: '![](../Images/72e0c1e764846319423f64a053c20afb.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72e0c1e764846319423f64a053c20afb.png)'
- en: 'Let’s the comparison easier by rewriting the first as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通过以下方式简化比较：
- en: '![](../Images/0b55408509fa24c6b148c5be93f13f9d.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0b55408509fa24c6b148c5be93f13f9d.png)'
- en: Notice that we changed the max to min by multiplying the function by -1
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们通过将函数乘以 -1 将 max 改为 min
- en: It’s now obvious that (note that *0≤****α*** is equivalent to *-α≤0):*
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在很明显（注意 *0≤****α*** 等价于 *-α≤0*）：*
- en: '![](../Images/3d0d0333f4492e1ba5846108e1255f36.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d0d0333f4492e1ba5846108e1255f36.png)'
- en: 'By this, we can write the following fit function:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，我们可以写出以下拟合函数：
- en: '[PRE4]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We ensure that this is a binary problem and that the binary labels are set as
    assumed by SVM (±1) and that *y* is a column vector with dimensions *(N,1)*. Then
    we solve the optimization problem to find *(α****₁*** *α₂ … α_N)*ᵗ.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确保这是一个二分类问题，且二分类标签按SVM假设设置为（±1），并且 *y* 是一个维度为 *(N,1)* 的列向量。然后我们解决优化问题以找到 *(α****₁***
    *α₂ … α_N)*ᵗ。
- en: We use *(α****₁*** *α₂ … α_N)*ᵗ to get an array of flags that is 1 at any index
    corresponding to a support vector so that we can later apply the prediction equation
    by only summing over support vectors and an index for a margin support vector
    for *(xₛ,yₛ).* Notice that in the checks we do assume that non-support vectors
    may not have *α=0* exactly, if it’s *α≤1e-3* then this is approximately zero (we
    know CVXOPT results may not be ultimately precise). Likewise, we assume that non-margin
    support vectors may not have *α=C* exactly.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 *(α****₁*** *α₂ … α_N)*ᵗ 来获得一个标志数组，其中任何对应于支持向量的索引为 1，以便我们可以稍后通过仅对支持向量求和，并为
    *(xₛ,yₛ)* 应用预测方程。注意，在检查中我们假设非支持向量的 *α* 可能不会完全为 0，如果是 *α≤1e-3*，则大致为零（我们知道 CVXOPT
    结果可能不是最终精确的）。同样，我们假设非边际支持向量的 *α* 可能不会完全为 *C*。
- en: Define the Predict Method
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义 Predict 方法
- en: 'Recall the prediction equation is:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾预测方程是：
- en: '![](../Images/6cdc91661bd6a7a3600c83566e74ed4d.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6cdc91661bd6a7a3600c83566e74ed4d.png)'
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: That’s it. We can also implement an `evaluate` method to compute the accuracy
    (used in fit above).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。我们还可以实现一个`evaluate`方法来计算准确性（用于上面的fit）。
- en: '[PRE6]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Test the Implementation
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试实现
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You can change the dataset and hyperparameter to further ensure that they are
    the same. Ideally, do so by comparing decision functions rather than accuracy.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以更改数据集和超参数以进一步确保它们是相同的。理想情况下，通过比较决策函数而不是准确性来进行。
- en: Generalizing Fit to Multiclass
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类推广
- en: '[PRE8]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To generalize the model to multiclass, over *k* classes. We train a binary SVM
    classifier for each class present where we loop on each class and relabel points
    belonging to it into +1 and points from all other classes into -1.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将模型推广到多类，我们在每个现有类别上训练一个二进制SVM分类器，其中我们对每个类别进行循环，将属于该类别的点重新标记为+1，将所有其他类别的点标记为-1。
- en: The result from training is *k* classifiers when given *k* classes where the
    *ith* classifier was trained on the data with the *ith* class being labeled as
    +1 and all others being labeled as -1.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 训练结果是* k *个分类器，当给定*k*类时，其中第* i *个分类器是在将第* i *类标记为+1而所有其他类标记为-1的数据上训练的。
- en: Generalizing Predict to Multiclass
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将预测推广到多类
- en: Then to perform prediction on a new example, we choose the class for which the
    corresponding classifier is most confident (has the highest score)
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在新的示例上进行预测时，我们选择对应分类器最有信心的类（具有最高得分）
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Testing the Implementation
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试实现
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Plotting the decision regions for each further leads to the following plot:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制每个决策区域会产生以下图：
- en: '![](../Images/63a5bb19e547c15ef319422d7c37cd60.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63a5bb19e547c15ef319422d7c37cd60.png)'
- en: Figure by the author
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图
- en: Beware that, although Sci-kit Learn’s SVM supports OVR by default (without an
    explicit call as shown above), that potentially also has further optimizations
    specific to SVM.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，尽管Sci-kit Learn的SVM默认支持OVR（如上所示没有显式调用），但这也可能具有特定于SVM的进一步优化。
- en: Full Code
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完整代码
- en: '[PRE11]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/50a2723007014b05afd3968090843780.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50a2723007014b05afd3968090843780.png)'
- en: Photo by [Nathan Van Egmond](https://unsplash.com/@thevanegmond?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Nathan Van Egmond](https://unsplash.com/@thevanegmond?utm_source=medium&utm_medium=referral)拍摄，[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)提供
- en: In summary, we implemented the support vector machine (SVM) learning algorithm,
    covering its general soft-margin and kernelized form. We provided an overview
    of SVM, developed the model in code, extended it for multiclass scenarios, and
    validated our implementation using Sci-kit Learn.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们实现了支持向量机（SVM）学习算法，涵盖了其一般的软边距和核化形式。我们提供了SVM的概述，开发了代码中的模型，扩展了多类场景，并使用Sci-kit
    Learn验证了我们的实现。
- en: Hope you find what you have learnt from this story useful for your work. Till
    next time, au revoir.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你发现从这个故事中学到的内容对你的工作有用。下次见，再见。
- en: '**Resources:**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: 'The code is mostly adaptations over the one present here ([MIT License](https://opensource.org/license/mit/)):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 代码主要是对这里存在的代码的适配（[MIT许可证](https://opensource.org/license/mit/)）：
- en: Persson, Aladdin. “[SVM from Scratch — Machine Learning Python (Support Vector
    Machine](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/algorithms/svm/svm.py)).”
    [YouTube](https://www.youtube.com/watch?v=gBTtR0bs-1k).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Persson, Aladdin. “[从零开始的SVM——机器学习Python（支持向量机](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/algorithms/svm/svm.py)）。”
    [YouTube](https://www.youtube.com/watch?v=gBTtR0bs-1k)。
