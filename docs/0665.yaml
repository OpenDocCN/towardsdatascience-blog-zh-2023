- en: Inference for Distributional Random Forests
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/inference-for-distributional-random-forests-64610bbb3927?source=collection_archive---------10-----------------------#2023-02-17](https://towardsdatascience.com/inference-for-distributional-random-forests-64610bbb3927?source=collection_archive---------10-----------------------#2023-02-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Confidence intervals for a powerful nonparametric method
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@jeffrey_85949?source=post_page-----64610bbb3927--------------------------------)[![Jeffrey
    Näf](../Images/0ce6db85501192cdebeeb910eb81a688.png)](https://medium.com/@jeffrey_85949?source=post_page-----64610bbb3927--------------------------------)[](https://towardsdatascience.com/?source=post_page-----64610bbb3927--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----64610bbb3927--------------------------------)
    [Jeffrey Näf](https://medium.com/@jeffrey_85949?source=post_page-----64610bbb3927--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fca780798011a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finference-for-distributional-random-forests-64610bbb3927&user=Jeffrey+N%C3%A4f&userId=ca780798011a&source=post_page-ca780798011a----64610bbb3927---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----64610bbb3927--------------------------------)
    ·17 min read·Feb 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F64610bbb3927&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finference-for-distributional-random-forests-64610bbb3927&user=Jeffrey+N%C3%A4f&userId=ca780798011a&source=-----64610bbb3927---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F64610bbb3927&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Finference-for-distributional-random-forests-64610bbb3927&source=-----64610bbb3927---------------------bookmark_footer-----------)![](../Images/a83708db984a87353847003d7999656b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'Features of (Distributional) Random Forests. In this article: The ability to
    provide uncertainty measures. Source: Author.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: In a previous [article](/drf-a-random-forest-for-almost-everything-625fa5c3bcb8),
    I extensively discussed the Distributional Random Forest method, a Random Forest-type
    algorithm that can nonparametrically estimate multivariate conditional distributions.
    This means that we are able to learn the whole distribution of a multivariate
    response ***Y*** given some covariates ***X*** nonparametrically, instead of “just”
    learning an aspect such as its conditional expectation. DRF does this by learning
    weights *w_i(****x****)* for the *i=1,…,n* training points that define the distribution
    and can be used to estimate a wide range of targets.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的[文章](/drf-a-random-forest-for-almost-everything-625fa5c3bcb8)中，我详细讨论了分布随机森林方法，这是一种可以非参数地估计多变量条件分布的随机森林类型算法。这意味着我们能够在给定一些协变量***X***的情况下，非参数地学习多变量响应***Y***的整个分布，而不仅仅是学习其条件期望。DRF通过学习权重
    *w_i(****x****)* 对于 *i=1,…,n* 训练点来完成这项工作，这些权重定义了分布，并且可以用于估计广泛的目标。
- en: So far this method only produced a “point estimate” of the distribution (i.e.
    a point estimate for the *n* weights *w_i(****x****)*). While this is enough to
    predict the whole distribution of a response, it doesn’t give a way to make inference
    that considers the randomness of the data-generating mechanism. That is, even
    though this point estimate gets increasingly close to the truth for large sample
    sizes (under a list of assumptions), there is still uncertainty in its estimate
    for finite sample sizes. Luckily there is now a (provable) method to quantify
    this uncertainty as I lay out in this article. This is based on our new paper
    on [arXiv](https://arxiv.org/pdf/2302.05761.pdf).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这种方法仅产生了分布的“点估计”（即* n* 权重 *w_i(****x****)* 的点估计）。虽然这足以预测响应的整个分布，但它并未提供考虑数据生成机制随机性的方法。也就是说，即使这个点估计在大样本量下（在一系列假设下）越来越接近真实值，但在有限样本量下其估计仍然存在不确定性。幸运的是，现在有一种（可证明的）方法来量化这种不确定性，如我在本文中阐述的。这基于我们关于[arXiv](https://arxiv.org/pdf/2302.05761.pdf)的新论文。
- en: 'The goal of this article is twofold: First, I want to discuss how to add uncertainty
    estimates to the DRF, based on our paper. The paper is quite theoretical, so I
    start with a few examples. The subsequent sections take a quick glance at these
    theoretical results, for those interested. I then explain how this can be used
    to get a (sampling-based) uncertainty measure for a wide range of targets. Second,
    I discuss the CoDiTE of [1] and a particularly interesting example of this concept,
    the conditional witness function. This function is a complicated object, yet,
    as we will see below, we can estimate it easily with DRF and can even provide
    asymptotic confidence bands, based on the concepts introduced in this article.
    An extensive real-data example of how this could be applied is given in [this
    article](https://medium.com/@jeffrey_85949/studying-the-gender-wage-gap-in-the-us-using-distributional-random-forests-ec4c2a69abf0).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目标有两个：首先，我想讨论如何基于我们的论文将不确定性估计添加到 DRF 中。论文相当理论化，因此我从几个示例开始。接下来的部分快速浏览这些理论结果，以供感兴趣的人参考。然后我解释了如何利用这些结果获取广泛目标的（基于采样的）不确定性度量。其次，我讨论了[1]的
    CoDiTE 和这一概念的一个特别有趣的例子，即条件见证函数。这个函数是一个复杂的对象，但正如我们将在下面看到的那样，我们可以轻松地使用 DRF 进行估计，并且基于本文中介绍的概念，甚至可以提供渐近置信带。一个如何应用的详细真实数据示例见[这篇文章](https://medium.com/@jeffrey_85949/studying-the-gender-wage-gap-in-the-us-using-distributional-random-forests-ec4c2a69abf0)。
- en: Throughout we assume to have a *d*-variate i.i.d. sample ***Y****_1, …,* ***Y****_n*
    of variables of interest and a *p*-variate i.i.d. sample ***X****_1,…,****X****_n*
    of covariates. The goal is to estimate the conditional distribution of ***Y****|****X=x***.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个过程中，我们假设有一个 *d* 变量的 i.i.d. 样本 ***Y****_1, …,* ***Y****_n* 和一个 *p* 变量的 i.i.d.
    样本 ***X****_1,…,****X****_n*。目标是估计 ***Y****|****X=x*** 的条件分布。
- en: 'We will need the following packages and functions for this:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要以下软件包和函数：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The functions in the file “CIdrf.R” can be found below.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 文件“CIdrf.R”中的函数如下所示。
- en: In the following, all images, unless otherwise noted, are by the author.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下所有图片，除非另有说明，均由作者提供。
- en: Examples
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例
- en: 'We simulate from a simple example with *d=1* and *p=2*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个简单的例子开始模拟，其中 *d=1* 和 *p=2*：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that this is simply a heteroskedastic linear model, with the variance of
    the error term depending on the *X_1* values. Of course, knowing the effect of
    ***X*** on *Y* is just linear, you would not use DRF, or any Random Forest for
    that matter, but directly go with linear regression. But for this purpose, it
    is convenient to know the truth. Since DRF’s job is to estimate a conditional
    distribution given ***X****=****x***, we now fix***x*** and estimate the conditional
    expectation and variance given ***X****=****x.***
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: We choose a point that is right in the center of the ***X*** distribution, with
    lots of observations surrounding it. In general, one should be careful when using
    any Random Forest method for points on the border of the ***X*** observations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we fit our DRF and obtain the weights *w_i(****x****)*:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As explained below, the DRF object we built here not only contains the weights
    *w_i(****x****)*, but also a sample of *B* weights that correspond to draws from
    the distribution of *w_i(****x****)*. We can use these *B* draws to approximate
    the distribution of anything we want to estimate, as I illustrate now in two examples.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 1: Conditional Expectation**'
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we simply do what most prediction methods do: We estimate the conditional
    expectation. With our new method, we also build a confidence interval around it.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Importantly, though the estimated value is a bit off, this CI contains the truth,
    which is given as
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/52ee2c7bbc6815322309981bda7f19fe.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: '**Example 2: Conditional Variance**'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Assume now we would like to find the variance Var(Y|**X**=**x**) instead of
    the conditional mean. This is quite a challenging example for a nonparametric
    method that cannot make use of the linearity. The truth is given as
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d2db80f11b107106d566d7dcc249eae5.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: 'Using DRF, we can estimate this as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Thus the true parameter is contained in the CI, as we would hope, and in fact,
    we are quite close to the truth with our estimate!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: We now study the theory underlying these examples, before we come to a third
    example in Causal Analysis.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Asymptotic Normality in the RKHS
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this and the next section, we briefly focus on the theoretical results derived
    in the paper. As explained above and in the article, DRF presents a distributional
    prediction at a test point **x**. That is, we obtain an estimate
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ef4a0a592b625a61439725d7f4146eca.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: of the conditional distribution of ***Y*** given ***X****=****x***. This is
    just a typical way of writing an empirical measure, the magic lies in the weights
    *w_i(****x****)* — they can be used to easily obtain estimators of quantities
    of interest, or even to sample directly from the distribution.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'To obtain this estimate, DRF actually estimates the conditional mean, but in
    a reproducing kernel Hilbert space (RKHS). An RKHS is defined through a kernel
    function *k(****y****_1,* ***y****_2)*. With this kernel, we can map each observation
    ***Y****_i* into the Hilbert space, as *k(****Y****_i, .)*. There is a myriad
    of methods using this extremely powerful tool, such as kernel ridge regression.
    The key point is that under some conditions, any distribution can be expressed
    as an element of this RKHS. It turns out that the true conditional distribution
    can be represented in the RKHS as the following expectation:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得这个估计，DRF 实际上是在再生核希尔伯特空间（RKHS）中估计条件均值。RKHS 是通过核函数 *k(****y****_1,* ***y****_2)*
    定义的。通过这个核，我们可以将每个观测 ***Y****_i* 映射到希尔伯特空间中，作为 *k(****Y****_i, .)*。利用这个极其强大的工具可以进行多种方法，例如核岭回归。关键点是，在某些条件下，任何分布都可以表示为这个
    RKHS 的一个元素。事实证明，真正的条件分布可以表示为 RKHS 中的以下期望：
- en: '![](../Images/bd156eb31d44300738e13e547b07d8d3.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd156eb31d44300738e13e547b07d8d3.png)'
- en: 'So this is just another way of expressing the conditional distribution of ***Y***
    given ***X****=****x***. We then try to estimate this element with DRF like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这只是另一种表达 ***Y*** 给定 ***X****=****x*** 的条件分布的方式。然后我们尝试用 DRF 来估计这个元素，如下所示：
- en: '![](../Images/1cb7f9837a62a83ca4fb45179088ebf7.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1cb7f9837a62a83ca4fb45179088ebf7.png)'
- en: Again we are using the weights obtained from DRF, but now form a weighted sum
    with *k(****Y****_i,.)* instead of the Dirac measures above. We can map back and
    forth between the two estimates by writing either of the two. The reason this
    matters is that we can write the conditional distribution estimate as a weighted
    mean in the RKHS! Just as the original Random Forest estimates a mean in the real
    numbers (the conditional expectation of *Y* given ***X****=****x***), DRF estimates
    a mean in the RKHS. Only with the latter, it turns out we also obtain an estimate
    of the conditional distribution.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次使用了从 DRF 获得的权重，但这次用 *k(****Y****_i,.)* 来形成加权和，而不是上述的狄拉克测度。我们可以通过编写任意两个中的任何一个来在两个估计之间来回映射。这很重要，因为我们可以将条件分布估计写成
    RKHS 中的加权均值！就像原始的随机森林在实数中估计均值（*Y* 给定 ***X****=****x*** 的条件期望）一样，DRF 在 RKHS 中估计均值。结果表明，我们还获得了条件分布的估计。
- en: The reason this is important for our story is that this weighted mean in the
    RKHS behaves quite similarly in some regards to a (weighted) mean in *d* dimensions.
    That is, we can study its consistency and asymptotic normality using the myriad
    of tools that are available for averages. This is quite remarkable, as all interesting
    RKHS will be infinite-dimensional. The [first DRF paper](https://www.jmlr.org/papers/v23/21-0585.html)
    already establishes consistency of the estimator in (1) in the RKHS. Our new paper
    now proves that, in addition,
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这对我们的故事很重要，因为在 RKHS 中，这个加权均值在某些方面表现得与 *d* 维的（加权）均值非常相似。也就是说，我们可以利用现有的工具来研究其一致性和渐近正态性。这是相当显著的，因为所有有趣的
    RKHS 都是无限维的。[第一篇 DRF 论文](https://www.jmlr.org/papers/v23/21-0585.html) 已经确立了 RKHS
    中估计器（1）的均衡性。我们的新论文现在进一步证明了，此外，
- en: '![](../Images/beb966c92670eb9ee62fecb884bf5abb.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/beb966c92670eb9ee62fecb884bf5abb.png)'
- en: where sigma_n is a standard deviation that goes to zero and ***Sigma****_****x***
    is an operator that takes the place of a covariance matrix (again it all works
    quite similarly as in *d*-dimensional Euclidean space).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 sigma_n 是趋近于零的标准差，而***Sigma****_****x*** 是一个替代协方差矩阵的算子（这与 *d* 维欧几里得空间中的表现非常相似）。
- en: Obtaining the sampling distribution
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获得采样分布
- en: Ok so, we have an asymptotic normality result in an infinite-dimensional space,
    what exactly does that mean? Well first, it means estimators derived from the
    DRF estimate that are “smooth’’ enough will also tend to be asymptotically normal.
    But this alone is still not useful, as we also need to have a variance estimate.
    Here a further result in our paper comes into play.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那么，我们在无限维空间中得到了一个渐近正态性结果，这到底意味着什么？首先，这意味着从 DRF 估计中得出的估计器如果“平滑”到足够程度，也将趋向于渐近正态。然而，这还不够有用，因为我们还需要有方差估计。这里我们论文中的进一步结果派上用场。
- en: 'We leave away a lot of details here, but essentially we can use the following
    subsample scheme: Instead of just fitting say *N* trees to build our forest, we
    build *B* groups of *L* trees (such that *N=B*L*). Now for each group of trees
    or mini forests, we subsample at random about half of the data points and then
    fit the forest using only this subsample. Let’s call this subset of samples chosen
    *S*. For each drawn *S* we then get another DRF estimator in the Hilbert space
    denoted'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里省略了很多细节，但本质上我们可以使用以下子样本方案：不是仅仅拟合*N*棵树来构建我们的森林，而是构建*B*组*L*棵树（使得*N=B*L*）。现在，对于每一组树或迷你森林，我们随机子样本约一半的数据点，然后仅使用此子样本拟合森林。我们称这个样本子集为*S*。对于每个抽取的*S*，我们得到另一个在希尔伯特空间中表示的DRF估计量
- en: '![](../Images/6c96b09934e8fd69d152821605f9250f.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c96b09934e8fd69d152821605f9250f.png)'
- en: only using the samples in *S*. Note that, as in bootstrapping, we now have two
    sources of randomness, even disregarding the randomness of the forest (in theory
    we assume *B* to be so large, as to make the randomness of the forest(s) negligible).
    One source from the data themselves and another artificial source of randomness,
    we introduce when choosing *S* at random. Crucially the randomness from *S*, given
    the data, is in our control — we can draw as many subsets *S* as we want. So the
    question is, what happens with our estimator in (2) if we only consider the randomness
    of *S* and fix the data? Remarkably, we can show that
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 仅使用*S*中的样本。请注意，与自助法一样，我们现在有两个随机性来源，即使忽略森林的随机性（理论上我们假设*B*足够大，以使森林的随机性可忽略不计）。一个来源是数据本身，另一个来源是我们在随机选择*S*时引入的人工随机性。关键是，给定数据的情况下，*S*的随机性在我们的控制之下——我们可以绘制任意数量的子集*S*。所以问题是，如果我们只考虑*S*的随机性并固定数据，那么我们的估计量（2）会发生什么？值得注意的是，我们可以证明
- en: '![](../Images/3a5d0db02cd4a1152ab28bbfa2d32eb0.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a5d0db02cd4a1152ab28bbfa2d32eb0.png)'
- en: 'This just means that if we fix the randomness of the data and only consider
    the randomness from *S*, the estimator (2) minus the estimator in (1) will converge
    in distribution to the same limit as the original estimator minus the truth! This
    is actually how bootstrap theory works: We have shown that something we can sample
    from, namely'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这仅仅意味着，如果我们固定数据的随机性，仅考虑来自*S*的随机性，那么估计量（2）减去估计量（1）将以相同的极限收敛到与原始估计量减去真实值相同的极限！这实际上是自助法理论的工作原理：我们已经证明了我们可以从中采样的东西，即
- en: '![](../Images/284228a4f892f49794336481ce31ae76.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/284228a4f892f49794336481ce31ae76.png)'
- en: converges to the same limit as what we cannot access, namely
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛到我们无法访问的东西，即
- en: '![](../Images/84b2fe390815c3b56f196fde0bf1bf82.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/84b2fe390815c3b56f196fde0bf1bf82.png)'
- en: So to make inference about the latter, we can use the former! This is actually
    the standard argument people make in bootstrap theory to justify why the bootstrap
    can be used to approximate the sampling distribution! That’s right, even bootstrap,
    a technique that people often use in small samples, only really makes sense (theoretically)
    in a large sample regime.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了对后者进行推断，我们可以使用前者！这实际上是人们在自助法理论中提出的标准论点，以证明为什么自助法可以用来近似采样分布！没错，即使是自助法，尽管人们经常在小样本中使用，它也只在大样本范围内才真正有意义（理论上）。
- en: Let’s use this now.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来使用这个。
- en: What does this actually mean?
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这实际上是什么意思？
- en: We now show what this means in practice. In the following, we define two new
    functions derived from the drf function of the CRAN package [drf](https://cran.r-project.org/web/packages/drf/index.html).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在展示这在实践中的含义。接下来，我们定义两个从CRAN包[drf](https://cran.r-project.org/web/packages/drf/index.html)的drf函数派生的新函数。
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: So from our method, we not only get the point estimate in form of weights *w_i(****x****)*,
    but a sample of *B* weights, each representing an independent draw from the distribution
    of the estimator of the conditional distribution (that sounds more confusing than
    it should be, please keep the examples in mind). This just means we are not only
    having an estimator, but also an approximation to its distribution!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过我们的方法，我们不仅得到点估计形式的权重*w_i(****x****)*，还得到*B*个权重的样本，每个样本表示从条件分布的估计量的分布中独立抽取的结果（这听起来比实际更令人困惑，请记住这些例子）。这仅仅意味着我们不仅有一个估计量，还有一个其分布的近似！
- en: I now turn to a more interesting example of something we can only do with DRF
    (as far as I know).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我转向一个更有趣的例子，这是我们仅能使用DRF做的（据我所知）。
- en: '**Causal Analysis Example: Witness Function**'
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**因果分析示例：见证函数**'
- en: 'Let’s assume we have two sets of observations, say group *W=1* and group *W=0*
    and we want to find the causal relationship between the group belonging and a
    variable *Y*. In the example of [*this article*](https://medium.com/@jeffrey_85949/studying-the-gender-wage-gap-in-the-us-using-distributional-random-forests-ec4c2a69abf0),
    the two groups would be male and female and *Y* would be the hourly wage. In addition,
    we have confounders ***X***, which we assume affect both *W* and *Y*. We assume
    here that ***X*** really includes all relevant confounders. This is a BIG assumption.
    Formally, we assume unconfoundedness:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两组观测值，分别是组 *W=1* 和组 *W=0*，我们想要找出组别与变量 *Y* 之间的因果关系。在 [*这篇文章*](https://medium.com/@jeffrey_85949/studying-the-gender-wage-gap-in-the-us-using-distributional-random-forests-ec4c2a69abf0)
    的例子中，这两组分别为男性和女性，而 *Y* 为小时工资。此外，我们有混杂变量 ***X***，我们假设它们影响 *W* 和 *Y*。我们在这里假设 ***X***
    确实包含所有相关的混杂变量。这是一个大假设。形式上，我们假设无混杂：
- en: '![](../Images/41019dc0794c12529c1e97f67d558a3a.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/41019dc0794c12529c1e97f67d558a3a.png)'
- en: 'and overlap:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 和重叠：
- en: '![](../Images/d2628db016d7b856e7d35b9b4262ae61.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d2628db016d7b856e7d35b9b4262ae61.png)'
- en: 'Often people then compare the conditional expectation between the two groups:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，人们会比较两个组之间的条件期望：
- en: '![](../Images/f68a21df53759761756554f6e747085c.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f68a21df53759761756554f6e747085c.png)'
- en: This is the Conditional Average Treatment Effect (CATE) at ***x***. This is
    a natural first starting point, but in a recent paper ([1]), the CoDiTE was introduced
    as a generalization of this idea. Instead of just looking at the difference in
    expected values the CoDiTE proposes to look at differences in other quantities
    as well. A particularly interesting example of this idea is the *conditional witness
    function:* For both groups, we take as above
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 ***x*** 处的条件平均处理效应（CATE）。这是一个自然的起点，但在最近的一篇论文 ([1]) 中，引入了 CoDiTE 作为这一思想的推广。CoDiTE
    不仅仅关注期望值的差异，还建议查看其他量的差异。一个特别有趣的例子是*条件见证函数*：对于两个组，我们如上所述
- en: '![](../Images/afdd6de7c361390ea2305e8804c7bbb8.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/afdd6de7c361390ea2305e8804c7bbb8.png)'
- en: 'So we consider the representation of the two conditional distributions in the
    RKHS. In addition to being representations of the conditional distributions, these
    quantities are also real-valued functions: For *j=0,1*,'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们考虑在 RKHS 中两个条件分布的表示。除了作为条件分布的表示，这些量也是实值函数：对于 *j=0,1*，
- en: '![](../Images/98b487eeaf5072792c5c007b3fd822b8.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/98b487eeaf5072792c5c007b3fd822b8.png)'
- en: The function that gives the difference between those two quantities,
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 给出这两个量之间差异的函数，
- en: '![](../Images/b42cf61f8df2f6f91847f49944db0f41.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b42cf61f8df2f6f91847f49944db0f41.png)'
- en: is called the *conditional witness function*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 称为*条件见证函数*。
- en: 'Why is this function interesting? It turns out that this function shows how
    the two densities behave in relation to each other: For values of *y* for which
    the function is negative, the conditional density of class 1 at *y* is smaller
    than the conditional density of 0\. Similarly, if the function is positive at
    *y*, it means the density of 1 is higher at *y* than the conditional density of
    0 (whereby “conditional” always refers to conditioning on ***X****=****x***).
    Crucially, this can be done *without having to estimate the densities*, which
    is hard, especially for multivariate ***Y***.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这个函数很有趣？事实证明，这个函数展示了两个密度如何相互关系：对于函数值为负的 *y*，类 1 在 *y* 处的条件密度小于 0 的条件密度。类似地，如果函数在
    *y* 处为正，这意味着 1 的密度在 *y* 处高于 0 的条件密度（其中“条件”始终指的是条件于 ***X***=****x***）。至关重要的是，这可以*不需要估计密度*，这很困难，尤其是对于多变量
    ***Y***。
- en: Finally, we can provide *uniform confidence bands* for our estimated conditional
    witness functions, by using the *B* samples from above. I do not go into details
    here, but these are essentially the analog to the confidence intervals for the
    conditional mean we used above. Crucially, these bands should be valid uniformly
    over the function values *y*, for one specific ***x***.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以为估计的条件见证函数提供*均匀置信带*，通过使用上面的 *B* 样本。我在这里不详细说明，但这些基本上是我们上面使用的条件均值置信区间的类比。至关重要的是，这些置信带应在特定的
    ***x*** 上对函数值 *y* 有效。
- en: 'Let’s illustrate this with an example: We simulate the following data-generating
    process:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来说明：我们模拟以下数据生成过程：
- en: '![](../Images/d50fab95d19e8b586d478f249897a0d4.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d50fab95d19e8b586d478f249897a0d4.png)'
- en: 'That is, *X_1, X_2* are independently uniformly distributed on (0,1), *W* is
    either 0 or 1, with a probability depending on *X_2* and *Y* is a function of
    *W* and *X_1*. This is a really hard problem; not only does ***X*** influence
    the probability of belonging to class 1 (i.e. the propensity), it also changes
    the treatment effect of *W* on *Y*. In fact, a small calculation shows that the
    CATE is given as:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 即，*X_1, X_2*在（0,1）上独立均匀分布，*W*为0或1，概率取决于*X_2*，*Y*是*W*和*X_1*的函数。这是一个非常困难的问题；不仅***X***影响属于类别1的概率（即倾向），它还改变了*W*对*Y*的处理效果。事实上，简单计算表明CATE给定为：
- en: (1 - 0.2)*X_1 - (0 - 0.2)*X_1 = X_1.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (1 - 0.2)*X_1 - (0 - 0.2)*X_1 = X_1。
- en: '![](../Images/c54d252b2f10464351b4cdbfbd3d16f6.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c54d252b2f10464351b4cdbfbd3d16f6.png)'
- en: Graph corresponding to the data-generating process
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据生成过程相对应的图形
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We now randomly choose a test point ***x*** and use the following code to estimate
    the witness function plus confidence band:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在随机选择一个测试点***x***，并使用以下代码来估计证据函数及其置信区间：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/8e33cecd895b14726387eef7739c5687.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e33cecd895b14726387eef7739c5687.png)'
- en: 'We can read from this plot that:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从这个图中看到：
- en: (1) The conditional density of group 1 is *lower* than the density of group
    0 for values of *y* between -3 and 0.3\. Moreover, this difference gets larger
    the larger *y* is until about *y = -1*, after which point the difference in densities
    starts to decrease again until the two densities are the same at around 0.3.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 组1的条件密度在*y*值介于-3和0.3之间时*低于*组0的密度。此外，这种差异随着*y*的增大而增大，直到约*y = -1*，之后密度差异开始再次减少，直到两者在约0.3时相同。
- en: (2) Symmetrically, the density of group 1 is higher than the density of group
    0 for values of *y* between 0.3 and 3 and this difference gets larger until it
    reaches a maximum at about *y = 1.5*. After this point, the difference decreases
    until it is almost zero again at *y = 3*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: (2) 对称地，组1的密度在*y*值介于0.3到3之间时高于组0的密度，这种差异逐渐增大，直到在约*y = 1.5*时达到最大值。在此点之后，差异逐渐减少，直到在*y
    = 3*时几乎回到零。
- en: (3) The difference between the two densities is statistically significant at
    the 95% percent level, as can be seen from the fact that for *y* approximately
    between -1.5 and -0.5 and between 1 and 2, the asymptotic confidence bands do
    not include the zero line.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (3) 两个密度之间的差异在95%置信水平上具有统计学意义，可以从事实中看到，对于*y*大致在-1.5到-0.5以及1到2之间，渐近置信区间不包括零线。
- en: 'Let’s check (1) and (2) for the simulated true conditional densities. That
    is, we simulate the truth a great number of times:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查（1）和（2）对模拟的真实条件密度的适用情况。也就是说，我们大量模拟真实情况：
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This leads to:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致：
- en: '![](../Images/d07cca78bc95a50ec272a3d9684e9e03.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d07cca78bc95a50ec272a3d9684e9e03.png)'
- en: It is a bit hard to compare visually, but we see that the two densities behave
    quite close to what the witness function above predicted. In particular, we see
    that the densities are about the same around 0.3 and the difference in densities
    appears to be maximal approximately around -1 and 1.5\. Thus both points (1) and
    (2) can be seen in the actual densities!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉上比较有点困难，但我们看到这两个密度与上面的证据函数预测的结果非常接近。特别是，我们看到在0.3左右密度几乎相同，密度差异在大约-1和1.5之间达到最大。因此，实际密度中可以看到点（1）和（2）！
- en: 'Moreover, to get (3) into context, a repeated simulation in the paper shows
    how the estimated witness function tends to look when no effect is visible:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了将（3）置于背景中，论文中的重复模拟展示了在没有可见效果时估计的证据函数的趋向：
- en: '![](../Images/b78fb42e38b3246856be32072c56a1b2.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b78fb42e38b3246856be32072c56a1b2.png)'
- en: Simulation of a 1000 witness functions in a similar setting as described here.
    In blue are the 1000 estimated witness functions, while in grey one can see the
    corresponding confidence bands. Taken from our paper on arXiv. There is no effect
    in this example, and 99% of CIs do not contain the zero line.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在与此处描述的类似设置中模拟了1000个证据函数。蓝色的是1000个估计的证据函数，而灰色的显示了相应的置信区间。摘自我们在arXiv上的论文。此示例中没有效果，99%的置信区间不包含零线。
- en: A real data example in Causal Inference is given in [this article](https://medium.com/p/ec4c2a69abf0/edit).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在[这篇文章](https://medium.com/p/ec4c2a69abf0/edit)中给出了因果推断中的一个真实数据示例。
- en: Conclusion
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: In this article, I discussed the new inferential tools available for Distributional
    Random Forests. I also looked at an important application of these new capabilities;
    estimating the conditional witness function with uniform confidence bands.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我讨论了适用于分布随机森林的新推断工具。我还查看了这些新能力的重要应用；用均匀置信区间估计条件见证函数。
- en: 'However, I also want to offer a few words of warning:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，我也想提供一些警告：
- en: The results are only valid for a given test point ***x***
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果仅对给定的测试点***x***有效。
- en: The results are only valid asymptotically
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 结果仅在渐近意义上有效。
- en: The current code is much much slower than it could be
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当前的代码比它应该有的慢得多。
- en: The first point is actually not so bad, in simulations, the asymptotic normality
    often also holds over a range of **x**. *Just be careful with test points that
    are close to the boundary of your sample!* Intuitively, DRF (and all other nearest
    neighborhood methods) need many sample points around the test point ***x*** to
    estimate the response for ***x***. So if the covariates *X* in your training set
    are standard normal, with most points between -2 and 2, then predicting an *x*
    in [-1,1] should be no problem. But if your *x* reaches -2 or 2, performance starts
    to deteriorate fast.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，第一点并不是那么糟糕，在模拟中，渐近正态性通常在一范围内的**x**上也成立。*只要小心样本边界附近的测试点！* 直观地说，DRF（以及所有其他最近邻方法）需要测试点***x***周围的许多样本点来估计***x***的响应。因此，如果你训练集中的协变量*X*是标准正态分布，大多数点在-2和2之间，那么预测[-1,1]中的*x*应该没有问题。但如果你的*x*达到了-2或2，性能会迅速恶化。
- en: Random Forests (and nearest neighbourhood methods in general) are not good at
    predicting for points that only have a few neighbours in the training set, such
    as points at the boundary of the support of ***X***.
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 随机森林（以及一般的最近邻方法）在预测训练集中只有少量邻居的点时表现不佳，例如***X***的支持边界上的点。
- en: The second point is also quite important. Asymptotic results have fallen somewhat
    out of fashion in contemporary research, in favor of finite sample results that
    in turn require assumptions such as “sub-Gaussianity”. I personally find this
    a bit ridiculous, asymptotic results provide extremely powerful approximations
    in complicated settings like these. And in fact, this approximation is pretty
    accurate for many targets for more than 1000 or 2000 data points (maybe you have
    92% coverage instead of 95% for your conditional mean/quantile). However, the
    witness function we introduced is a complicated object, and thus the more data
    points you have to estimate the uncertainty bands around it, the better!
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第二点也相当重要。渐近结果在当代研究中已经有些过时，研究者们更倾向于有限样本结果，这些结果需要诸如“次高斯性”的假设。我个人觉得这有点可笑，渐近结果在像这样的复杂设置中提供了极其强大的近似。实际上，对于许多目标来说，这种近似在超过1000或2000个数据点时相当准确（也许你的条件均值/分位数的覆盖率是92%而不是95%）。然而，我们引入的见证函数是一个复杂的对象，因此你需要更多的数据点来估计其不确定性区间，这样效果会更好！
- en: 'Finally point three is just a shortcoming on our side: While DRF itself is
    efficiently written in C, estimating the uncertainty with *S* is entirely based
    in R for the moment. Fixing this would provide an extreme speed-up to the code.
    We hope to be able to fix this in the future.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后第三点只是我们的一个缺陷：虽然DRF本身是用C语言高效编写的，但用*S*估计不确定性目前完全基于R语言。修复这一点将极大地加快代码速度。我们希望将来能够解决这个问题。
- en: Citations
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引用
- en: '[1] Junhyung Park, Uri Shalit, Bernhard Schölkopf, and Krikamol Muandet. “Conditional
    distributional treatment effect with kernel conditional mean embeddings and U-statistic
    regression.” In Proceedings of 38th International Conference on Machine Learning
    (ICML) , volume 139, pages 8401–8412\. PMLR, July 2021.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Junhyung Park, Uri Shalit, Bernhard Schölkopf 和 Krikamol Muandet. “使用核条件均值嵌入和
    U 统计量回归的条件分布治疗效果。” 见《第38届国际机器学习大会（ICML）论文集》，第139卷，第8401–8412页。PMLR，2021年7月。'
