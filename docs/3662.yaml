- en: Large Language Models and Vector Databases for News Recommendations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型和向量数据库在新闻推荐中的应用
- en: 原文：[https://towardsdatascience.com/large-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030?source=collection_archive---------1-----------------------#2023-12-14](https://towardsdatascience.com/large-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030?source=collection_archive---------1-----------------------#2023-12-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/large-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030?source=collection_archive---------1-----------------------#2023-12-14](https://towardsdatascience.com/large-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030?source=collection_archive---------1-----------------------#2023-12-14)
- en: '![](../Images/86e2c1ed6d4dee9531096a56a7242931.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/86e2c1ed6d4dee9531096a56a7242931.png)'
- en: Photo by [Roman Kraft](https://unsplash.com/@iamromankraft?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Roman Kraft](https://unsplash.com/@iamromankraft?utm_source=medium&utm_medium=referral)
    提供，来自 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: '*Making LLMs into production environments using Sentence Transformers and Qdrant*'
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*将 LLMs 应用到生产环境中，使用 Sentence Transformers 和 Qdrant*'
- en: '[](https://medium.com/@guedes.joaofelipe?source=post_page-----6f9348fd4030--------------------------------)[![João
    Felipe Guedes](../Images/4be4c6631a15540541fb96ac1bed88ec.png)](https://medium.com/@guedes.joaofelipe?source=post_page-----6f9348fd4030--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6f9348fd4030--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6f9348fd4030--------------------------------)
    [João Felipe Guedes](https://medium.com/@guedes.joaofelipe?source=post_page-----6f9348fd4030--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@guedes.joaofelipe?source=post_page-----6f9348fd4030--------------------------------)[![João
    Felipe Guedes](../Images/4be4c6631a15540541fb96ac1bed88ec.png)](https://medium.com/@guedes.joaofelipe?source=post_page-----6f9348fd4030--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6f9348fd4030--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6f9348fd4030--------------------------------)
    [João Felipe Guedes](https://medium.com/@guedes.joaofelipe?source=post_page-----6f9348fd4030--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F259f985d397f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030&user=Jo%C3%A3o+Felipe+Guedes&userId=259f985d397f&source=post_page-259f985d397f----6f9348fd4030---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6f9348fd4030--------------------------------)
    ·8 min read·Dec 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f9348fd4030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030&user=Jo%C3%A3o+Felipe+Guedes&userId=259f985d397f&source=-----6f9348fd4030---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F259f985d397f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030&user=Jo%C3%A3o+Felipe+Guedes&userId=259f985d397f&source=post_page-259f985d397f----6f9348fd4030---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6f9348fd4030--------------------------------)
    ·8 分钟阅读·2023年12月14日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6f9348fd4030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030&user=Jo%C3%A3o+Felipe+Guedes&userId=259f985d397f&source=-----6f9348fd4030---------------------clap_footer-----------)'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f9348fd4030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030&source=-----6f9348fd4030---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6f9348fd4030&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flarge-language-models-and-vector-databases-for-news-recommendations-6f9348fd4030&source=-----6f9348fd4030---------------------bookmark_footer-----------)'
- en: Large language models (LLMs) generated a global buzz in the machine learning
    community with recent releases of generative AI tools such as Chat-GPT, Bard,
    and others alike. One of the core ideas behind these solutions is to compute a
    numerical representation of unstructured data (such as texts and images) and find
    similarities between these representations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）随着最近生成 AI 工具如 Chat-GPT、Bard 等的发布，引起了机器学习社区的全球关注。这些解决方案的核心思想之一是计算非结构化数据（如文本和图像）的数值表示，并在这些表示之间找到相似性。
- en: 'However, taking all of these concepts into a production environment has its
    own set of machine learning engineering challenges:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将所有这些概念应用到生产环境中有其自身的一系列机器学习工程挑战：
- en: How to generate these representations quickly?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何快速生成这些表示？
- en: How to store them in a proper database?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将它们存储在合适的数据库中？
- en: How to quickly compute similarities for production environments?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在生产环境中快速计算相似性？
- en: 'In this article, I introduce two open-source solutions that aim to solve these
    questions:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我介绍了两种旨在解决这些问题的开源解决方案：
- en: '[**Sentence Transformers**](https://www.sbert.net/) **[1]**: an embedding generation
    technique based on textual information and;'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Sentence Transformers**](https://www.sbert.net/) **[1]**：一种基于文本信息的嵌入生成技术；'
- en: '[**Qdrant**](https://qdrant.tech/): a vector database capable of storing embeddings
    and providing an easy interface to query them.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**Qdrant**](https://qdrant.tech/)：一个能够存储嵌入并提供易于查询接口的向量数据库。'
- en: 'These tools are applied to NPR [2], a News Portal Recommendation dataset (openly
    available at [Kaggle](https://www.kaggle.com/datasets/joelpl/news-portal-recommendations-npr-by-globo))
    which was built to support the academic community to develop recommendation algorithms.
    By the end of the articles, you''ll see how to:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具应用于 NPR [2]，一个新闻门户推荐数据集（在 [Kaggle](https://www.kaggle.com/datasets/joelpl/news-portal-recommendations-npr-by-globo)
    上公开可用），该数据集旨在支持学术界开发推荐算法。在文章结束时，你将看到如何：
- en: Generate news embeddings with Sentence Transformers
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Sentence Transformers 生成新闻嵌入
- en: Store embeddings with Qdrant
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Qdrant 存储嵌入
- en: Query embeddings to recommend news articles
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询嵌入以推荐新闻文章
- en: All code for this article is made available on [Github](https://github.com/guedes-joaofelipe/vector-search-api).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的所有代码均可在 [Github](https://github.com/guedes-joaofelipe/vector-search-api)
    上获取。
- en: 1\. Generating embeddings with Sentence Transformers
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 使用 Sentence Transformers 生成嵌入
- en: First of all, we need to find a way to convert input data into vectors, which
    we'll call embeddings (if you want to dig deeper into the embedding concept, I
    recommend Boykis' article [What Are Embeddings?](https://vickiboykis.com/what_are_embeddings/about.html)
    [3]).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要找到一种将输入数据转换为向量的方法，我们称之为嵌入（如果你想深入了解嵌入的概念，我推荐阅读 Boykis 的文章 [What Are Embeddings?](https://vickiboykis.com/what_are_embeddings/about.html)
    [3]）。
- en: 'So let''s take a look at what kind of data we can work on with the NPR dataset:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 那么让我们来看看我们可以使用 NPR 数据集处理什么样的数据：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](../Images/cd97b85dc0c38903e97e0a8bdd45b542.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd97b85dc0c38903e97e0a8bdd45b542.png)'
- en: Sample data from NPR (image generated by author)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 NPR 的示例数据（作者生成的图像）
- en: 'We can see that NPR has some interesting textual data such as the articles''
    *title* and *body* content. We can use them in an embedding-generation process
    as the following image:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 NPR 拥有一些有趣的文本数据，如文章的 *标题* 和 *正文* 内容。我们可以在嵌入生成过程中使用它们，如下图所示：
- en: '![](../Images/aee62f2688e895578154d8ba93f13661.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/aee62f2688e895578154d8ba93f13661.png)'
- en: Embedding generation process (image by author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入生成过程（作者提供的图像）
- en: 'So once we define the textual features from our input data, we need to establish
    an embedding model to generate our numerical representation. Lucky for us, there
    are websites like [HuggingFace](https://huggingface.co/) where you can look for
    pre-trained models suitable for specific languages or tasks. In our example, we
    can use the [*neuralmind/bert-base-portuguese-cased*](https://huggingface.co/neuralmind/bert-base-portuguese-cased)
    model, which was trained in Brazilian portuguese for the following tasks:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了输入数据的文本特征，我们需要建立一个嵌入模型来生成我们的数值表示。幸运的是，我们可以在 [HuggingFace](https://huggingface.co/)
    等网站上寻找适合特定语言或任务的预训练模型。在我们的示例中，我们可以使用 [*neuralmind/bert-base-portuguese-cased*](https://huggingface.co/neuralmind/bert-base-portuguese-cased)
    模型，该模型为以下任务在巴西葡萄牙语上进行过训练：
- en: Named Entity Recognition
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名实体识别
- en: '**Sentence Textual Similarity**'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**句子文本相似性**'
- en: Recognizing Textual Entailment
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别文本蕴含
- en: 'Code-wise, this is how we translate the embedding-generation process:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从代码方面来看，我们如何翻译嵌入生成过程：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: So given an example input data, we can concatenate the *title* and *tags* content
    into a single text and pass it to an encoder to generate the text embedding.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，给定一个示例输入数据，我们可以将*title*和*tags*内容连接成一个文本，并传递给编码器生成文本嵌入。
- en: 'We can apply the same process for all other articles in the NPR dataset:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对NPR数据集中所有其他文章应用相同的过程：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Note**: bear in mind that this process might take a bit longer depending
    on your machine''s processing power.'
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意**：请注意，根据你机器的处理能力，这个过程可能会花费更多时间。'
- en: Once we have the embeddings for all news articles, let's define a strategy to
    store them.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们获得了所有新闻文章的嵌入，我们需要定义一种策略来存储它们。
- en: 2\. Storing embeddings
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 存储嵌入
- en: Since generating embeddings might be an expensive process, we can use a vector
    database to store these embeddings and execute queries based on diverse strategies.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 由于生成嵌入可能是一个耗费资源的过程，我们可以使用向量数据库来存储这些嵌入，并根据不同的策略执行查询。
- en: There are several vector database software to achieve this task, but I'll use
    **Qdrant** for this article, which is an open-source solution with APIs available
    for popular programming languages like *Python*, *Go,* and *Typescript*. For a
    better comparison between these vector databases, check this [article](https://www.datacamp.com/blog/the-top-5-vector-databases)
    [4].
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种向量数据库软件可以实现这个任务，但本文将使用**Qdrant**，这是一款开源解决方案，提供了适用于流行编程语言的API，如*Python*、*Go*和*Typescript*。要对这些向量数据库进行更好的比较，请查看这篇[文章](https://www.datacamp.com/blog/the-top-5-vector-databases)[4]。
- en: Setting Qdrant
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置Qdrant
- en: 'To deal with all Qdrant operations, we need to create a client object that
    points out to a vector database. Qdrant lets you create a free tier service to
    test remote connection to a database but, for the sake of simplicity, I''ll create
    and persist the database locally:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理所有Qdrant操作，我们需要创建一个指向向量数据库的客户端对象。Qdrant允许你创建一个免费的服务层级来测试与数据库的远程连接，但为了简便起见，我将创建并本地保存数据库：
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once this connection is stablished, we can create a collection in the database
    that will store the news articles embeddings:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦建立了这个连接，我们可以在数据库中创建一个集合，以存储新闻文章的嵌入：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Notice that vector configuration parameters are used to create the collection.
    These parameters tell Qdrant some properties from the vectors, like their *size*
    and the *distance* metric to be used when comparing vectors (I'll use the cosine
    similarity but you can also use other strategies like the [inner product or Euclidean
    distance](https://qdrant.tech/documentation/concepts/search/#metrics)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，向量配置参数用于创建集合。这些参数告诉Qdrant向量的一些属性，如它们的*size*和比较向量时使用的*distance*度量（我将使用余弦相似度，但你也可以使用其他策略，如[内积或欧氏距离](https://qdrant.tech/documentation/concepts/search/#metrics)）。
- en: Generating Vectors Points
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成向量点
- en: 'Prior to finally populating the database, we need to create proper objects
    to be uploaded. In Qdrant, vectors can be stored using a [*PointStruct*](https://qdrant.tech/documentation/concepts/points/)
    class, which you can use to define the following properties:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在最终填充数据库之前，我们需要创建适当的对象以进行上传。在Qdrant中，向量可以使用[*PointStruct*](https://qdrant.tech/documentation/concepts/points/)类进行存储，你可以使用这个类定义以下属性：
- en: '***id***: the vector''s ID (in the NPR case, is the *newsId*)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***id***：向量的ID（在NPR的情况下，是*newsId*）'
- en: '***vector***: a 1-dimensional array representing the vector (generated by the
    embedding model)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***vector***：表示向量的1维数组（由嵌入模型生成）'
- en: '***payload***: a dictionary containing any other relevant metadata that can
    later be used to query vectors in a collection (in the NPR case, the article''s
    *title*, *body,* and *tags*)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***payload***：包含任何其他相关元数据的字典，这些数据后来可以用于在集合中查询向量（在NPR的情况下，文章的*title*、*body*和*tags*）'
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Uploading Vectors
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传向量
- en: 'Finally, after all items are turned into point structures, we can upload them
    in chunks to the database:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在所有项目都转换为点结构后，我们可以将它们分批上传到数据库：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 3\. Querying Vectors
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 查询向量
- en: 'Now that collections are finally populated with vectors, we can start querying
    the database. There are many ways we can input information to query the database,
    but I think there are 2 very useful inputs we can use:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，集合已经填充了向量，我们可以开始查询数据库。我们可以用多种方式输入信息来查询数据库，但我认为有2种非常有用的输入方式：
- en: An input text
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入文本
- en: An input vector ID
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入向量ID
- en: 3.1 Querying vectors with an input vector
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 使用输入向量查询向量
- en: Let's say we built this vector database to be used in a search engine. In this
    case, we expect the user's input to be an input text and we have to return the
    most relevant items.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们建立了这个向量数据库以供搜索引擎使用。在这种情况下，我们期望用户输入的是一个文本输入，我们必须返回最相关的项目。
- en: Since all operations in a vector database are done with….VECTORS, we first need
    to transform the user's input text into a vector so we can find similar items
    based on that input. Recall that we used Sentence Transformers to encode textual
    data into embeddings, so we can use the very same encoder to generate a numerical
    representation for the user's input text.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于向量数据库中的所有操作都是用……向量来完成的，因此我们首先需要将用户输入的文本转换为向量，以便我们可以根据该输入找到相似的项目。回顾一下，我们使用了句子变换器将文本数据编码成嵌入，因此我们可以使用同样的编码器为用户的输入文本生成数值表示。
- en: 'Since the NPR contains news articles, let''s say the user typed *"Donald Trump"*
    to learn about US elections:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 NPR 包含新闻文章，我们假设用户输入了*“唐纳德·特朗普”*以了解美国选举：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once the input query vector is computed, we can search for the closest vectors
    in the collection and define what sort of output we want from those vectors, like
    their *newsId*, *title,* and *topics:*
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算出输入查询向量，我们可以在集合中搜索最接近的向量，并定义我们希望从这些向量中获得什么样的输出，如其*newsId*、*标题*和*主题：*
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Note**: by default, Qdrant uses Approximate Nearest Neighbors to scan for
    embeddings quickly, but [you can also do a full scan and bring the exact nearest
    neighbors](https://qdrant.tech/documentation/concepts/search/#search-api) — just
    bear in mind this is a much more expensive operation.'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意**：默认情况下，Qdrant 使用近似最近邻搜索快速扫描嵌入，但[你也可以进行全面扫描并获取准确的最近邻](https://qdrant.tech/documentation/concepts/search/#search-api)——只是请注意，这是一项成本更高的操作。'
- en: 'After running this operation, here are the generated output titles (translated
    into english for better comprehension):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此操作后，以下是生成的输出标题（为更好理解已翻译成英文）：
- en: '**Input Sentence**: *Donald Trump*'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入句子**：*唐纳德·特朗普*'
- en: '**Output 1***:* *Paraguayans go to the polls this Sunday (30) to choose a new
    president*'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 1**：*巴拉圭人在本周日（30日）去投票选举新总统*'
- en: '**Output 2*:*** *Voters say Biden and Trump should not run in 2024, Reuters/Ipsos
    poll shows*'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 2**：*选民表示拜登和特朗普不应在2024年竞选，路透/益普索民调显示*'
- en: '**Output 3*:*** *Writer accuses Trump of sexually abusing her in the 1990s*'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 3**：*记者指控特朗普在1990年代对她进行性虐待*'
- en: '**Output 4*:*** *Mike Pence, former vice president of Donald Trump, gives testimony
    in court that could complicate the former president*'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 4**：*迈克·彭斯，特朗普的前副总统，法院作证可能使前总统陷入困境*'
- en: It seems that besides bringing news related to Trump himself, the embedding
    model also managed to represent topics related to presidential elections. Notice
    that in the first output, there is no direct reference to the input term “*Donald
    Trump*” other than the presidential election.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来除了带来与特朗普本人相关的新闻外，嵌入模型还成功地表示了与总统选举相关的主题。注意在第一个输出中，除了总统选举，没有直接提到输入词“*唐纳德·特朗普*”。
- en: Also, I left out a *query_filter* parameters. This is a very useful tool if
    you want to specify that the output must satisfy some given condition. For instance,
    in a news portal, it is frequently important to filter only the most recent articles
    (say from the past 7 days onwards). Therefore, you could query for news articles
    that satisfy a minimum publication timestamp.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我遗漏了一个*query_filter*参数。如果你想指定输出必须满足某些条件，这个工具非常有用。例如，在新闻门户中，通常重要的是仅筛选出最新的文章（例如过去7天内）。因此，你可以查询符合最低发布时间戳的新闻文章。
- en: '**Note:** in the news recommendation context, there are multiple concerning
    aspects to consider like fairness and diversity. This is an open topic of discussion
    but, should you be interested in this area, take a look at the articles from the
    [NORMalize Workshop](https://sites.google.com/view/normalizeworkshop/home).'
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**注意：** 在新闻推荐的背景下，有多个值得关注的方面，如公平性和多样性。这是一个开放的话题，但如果你对此领域感兴趣，可以查看[NORMalize
    Workshop](https://sites.google.com/view/normalizeworkshop/home)上的文章。'
- en: 3.2 Querying vectors with an input vector ID
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 使用输入向量 ID 查询向量
- en: Lastly, we can ask the vector database to "recommend" items that are closer
    to some desired vector IDs but far from undesired vector IDs. The desired and
    undesired IDs are called *positive* and *negative* examples, respectively, and
    they are thought of as seeds for the recommendation.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以让向量数据库“推荐”更接近某些期望的向量 ID，但远离不希望的向量 ID。期望的和不希望的 ID 分别称为*正例*和*负例*，它们被视为推荐的种子。
- en: 'For instance, let''s say we have the following positive ID:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有以下正ID：
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can then ask for items similar to this example:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以请求类似于这个示例的项目：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After running this operation, here are the translated output titles :'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此操作后，以下是翻译后的输出标题：
- en: '**Input item:** *Learn why Joe Biden launched his bid for re-election this
    Tuesday*'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入项：** *了解乔·拜登为什么在本周二宣布竞选连任*'
- en: '**Output 1:** *Biden announces he will run for re-election*'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 1：** *拜登宣布他将竞选连任*'
- en: '**Output 2:** *USA: the 4 reasons that led Biden to run for re-election*'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 2：** *美国：拜登竞选连任的 4 个原因*'
- en: '**Output 3:** *Voters say Biden and Trump should not run in 2024, Reuters/Ipsos
    poll shows*'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 3：** *选民表示拜登和特朗普不应该在2024年参选，路透社/艾普索斯民调显示*'
- en: '**Output 4:** *Biden’s advisor’s gaffe that raised doubts about a possible
    second government after the election*'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出 4：** *拜登顾问的失言引发对选举后可能出现第二届政府的疑虑*'
- en: Conclusion
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This article demonstrates how to combine LLMs and vector databases to serve
    recommendations. In particular, Sentence Transformers were used to generate numerical
    representations (embeddings) from textual news articles in the NPR dataset. Once
    these embeddings are computed, they can populate a vector database such as Qdrant
    which facilitates querying vectors based on several strategies.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本文展示了如何将LLM和向量数据库结合起来以提供推荐。特别是使用了句子变换器来生成来自NPR数据集的文本新闻文章的数值表示（嵌入）。一旦这些嵌入被计算出来，它们可以填充像Qdrant这样的向量数据库，从而根据多种策略方便地查询向量。
- en: 'A whole lot of improvements can be made after the examples in this article,
    such as:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中的示例之后可以进行大量改进，例如：
- en: testing other embedding models
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试其他嵌入模型
- en: testing other distance metrics
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试其他距离度量
- en: testing other vector databases
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试其他向量数据库
- en: using compile-based programming languages like Go for better performance
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于编译的编程语言如Go来提高性能
- en: creating an API to serve recommendations
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个API以提供推荐
- en: In other words, many ideas may come up to improve the machine learning engineering
    of recommendations with LLMs. So, if you feel like sharing your ideas about these
    improvements, don't hesitate to send me a message [here](https://www.linkedin.com/in/joao-felipe-guedes/)
    :)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，可能会出现许多想法来改善LLM的推荐机器学习工程。因此，如果你想分享你对这些改进的想法，请随时通过[这里](https://www.linkedin.com/in/joao-felipe-guedes/)给我发消息
    :)
- en: About Me
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于我
- en: I am a senior data scientist at [Globo](https://www.globo.com/), a Brazilian
    media-tech company. Working at the company's recommendation team, I am surrounded
    by an amazing and talented team who put a lot of effort to deliver personalized
    content to millions of users through digital products like [G1](https://g1.globo.com/),
    [GE](https://ge.globo.com/), [Globoplay](https://globoplay.globo.com/), and many
    others. This article wouldn't be possible without their indispensable knowledge.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我是[Globo](https://www.globo.com/)的高级数据科学家，这是一家巴西媒体技术公司。作为公司推荐团队的一员，我身边有一个令人惊叹和才华横溢的团队，他们付出了很多努力，通过数字产品如[G1](https://g1.globo.com/)、[GE](https://ge.globo.com/)、[Globoplay](https://globoplay.globo.com/)等为数百万用户提供个性化内容。如果没有他们不可或缺的知识，这篇文章是不可能完成的。
- en: References
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] N. reimers and I. Gurevych, [Sentence-BERT: Sentence Embeddings using Siamese
    BERT-Networks](http://arxiv.org/abs/1908.10084) (2019), Association for Computational
    Linguistics.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] N. reimers 和 I. Gurevych, [Sentence-BERT: 使用 Siamese BERT 网络的句子嵌入](http://arxiv.org/abs/1908.10084)
    (2019), 计算语言学协会。'
- en: '[2] J. Pinho, J. Silva and L. Figueiredo, [NPR: a News Portal Recommendations
    dataset](https://sites.google.com/view/normalizeworkshop/contributions?authuser=0)
    (2023), ACM Conference on Recommender Systems'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] J. Pinho, J. Silva 和 L. Figueiredo, [NPR: 新闻门户推荐数据集](https://sites.google.com/view/normalizeworkshop/contributions?authuser=0)
    (2023), ACM 推荐系统会议'
- en: '[3] V. Boykis, [What are embeddings?](https://vickiboykis.com/what_are_embeddings/),
    personal blog'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] V. Boykis, [什么是嵌入？](https://vickiboykis.com/what_are_embeddings/)，个人博客'
- en: '[4] M. Ali, [The Top 5 Vector Databases](https://www.datacamp.com/blog/the-top-5-vector-databases)
    (2023), DataCamp blog'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] M. Ali, [前 5 大向量数据库](https://www.datacamp.com/blog/the-top-5-vector-databases)
    (2023), DataCamp 博客'
