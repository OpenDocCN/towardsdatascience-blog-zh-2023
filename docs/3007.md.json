["```py\nnews = [\n    \"Mark Zuckerberg touts potential of remote work in metaverse as Meta threatens employees for violating return-to-office mandate\",\n    \"Meta Quest 3 Shows Us the Metaverse Dream isn’t Dead Yet\",\n    \"Meta has Apple to thank for giving its annual VR conference added sizzle this year\",\n    \"Meta launches AI chatbots for Instagram, Facebook and WhatsApp\",\n    \"Meta Launches AI Chatbots for Snoop Dogg, MrBeast, Tom Brady, Kendall Jenner, Charli D’Amelio and More\",\n    \"Llama 2: why is Meta releasing open-source AI model and are there any risks?\",\n    \"Meta's Mandatory Return to Office Is 'a Mess'\",\n    \"Meta shares soar on resilient revenue and $40bn in buybacks\",\n    \"Facebook suffers fresh setback after EU ruling on use of personal data\",\n    \"Facebook owner Meta hit with record €1.2bn fine over EU-US data transfers\"\n]\n```", "```py\ndef get_embedding(text, \n                 model = 'text-embedding-ada-002'):\n    text = text.replace(\"\\n\", \" \")\n    return openai.Embedding.create(input = [text], engine = model)['data'][0]['embedding']\n\ndf['embedding'] = df.news.apply(lambda x: get_embedding(x))\ndf['embedding'] = df['embedding'].apply(np.array)\n\nmatrix = np.vstack(df['embedding'].values)\nmatrix.shape\n\n# Output: (10, 1536)\n```", "```py\n# Reduce the dimensionality of the embeddings to 2D using PCA\npca = PCA(n_components=2)\nreduced_matrix = pca.fit_transform(matrix)\nreduced_matrix.shape\n\n# Fit the Elliptic Envelope (MCD-based robust estimator)\nenvelope = EllipticEnvelope(contamination=0.2)  \nenvelope.fit(reduced_matrix)\n\n# Predict the labels of the sentences\nlabels = envelope.predict(reduced_matrix)\n\n# Find the indices of the novel sentences\nnovel_indices = np.where(labels == -1)[0]\nnovel_indices\n\n#Output: array([8, 9])\n```", "```py\n# Extract the location and covariance of the central mode\nlocation = envelope.location_\ncovariance = envelope.covariance_\n\n# Compute the angle, width, and height of the ellipse\neigenvalues, eigenvectors = np.linalg.eigh(covariance)\norder = eigenvalues.argsort()[::-1]\neigenvalues, eigenvectors = eigenvalues[order], eigenvectors[:, order]\nvx, vy = eigenvectors[:, 0]\ntheta = np.arctan2(vy, vx)\n\n# Compute the width and height of the ellipse based on the eigenvalues (variances)\nwidth, height = 2 * np.sqrt(eigenvalues)\n\n# Compute the Mahalanobis distance of the reduced 2D embeddings\nmahalanobis_distances = envelope.mahalanobis(reduced_matrix)\n\n# Compute the threshold based on the contamination parameter\nthreshold = np.percentile(mahalanobis_distances, (1 - envelope.contamination) * 100)\n\n# Scale the width and height of the ellipse based on the Mahalanobis distance threshold\nwidth, height = width * np.sqrt(threshold), height * np.sqrt(threshold)\n\n# Plot the inliers and outliers\ninliers = reduced_matrix[labels == 1]\noutliers = reduced_matrix[labels == -1]\n\n# Re-plot the inliers and outliers along with the elliptic envelope with annotations\nplt.scatter(inliers[:, 0], inliers[:, 1], c='b', label='Inliers')\nplt.scatter(outliers[:, 0], outliers[:, 1], c='r', label='Outliers', marker='x')\nellipse = Ellipse(location, width, height, angle=np.degrees(theta), edgecolor='k', facecolor='none')\nplt.gca().add_patch(ellipse)\n\n# Annotate each point with its index\nfor i, (x, y) in enumerate(reduced_matrix):\n    plt.annotate(str(i), (x, y), textcoords=\"offset points\", xytext=(0, 5), ha='center')\n\nplt.title('Novelty Detection using MCD with Annotations')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\nplt.grid(True)\nplt.show()\n```"]