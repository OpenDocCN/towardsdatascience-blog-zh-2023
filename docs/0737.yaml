- en: Parsing Irregular Spreadsheet Tables in Humanitarian Datasets (with Some Help
    from GPT-3)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24](https://towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Processing Irregular Excel Tables Without Using Hard-coded Rules
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)[](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----57efb3d80d45---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)
    Â·26 min readÂ·Feb 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----57efb3d80d45---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&source=-----57efb3d80d45---------------------bookmark_footer-----------)![](../Images/0fbcce7550af12dc6d701ff00255fbc1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Created by DALL-E2 with prompt â€œA painting of 10 wood tablesâ€. There are 9 tables
    in the image above.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '***TL;DR***'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '*As part of a* [*previous study*](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)
    *using data from the* [*Humanitarian Data Exchange*](https://data.humdata.org/)*,
    I had to analyze thousands of Excel files where tables within those files were
    often difficult to parse into database tables. Irregular layouts with merged cells,
    hierarchical columns, and annotations are difficult to anticipate with rule-based
    parsing when files originate from hundreds of organizations across the world.
    In this article, I explore using GPT-3 zero- single- and single-shot with reasoning
    completion to reformat irregular (small) tables, as well as fine-tuning the model
    to predict table attributes which can then be used for accurate parsing.*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: There have been quite a few times on my travels when Iâ€™ve needed to review a
    large number of Excel files to understand what data they contain, how well it
    is structured, and the work required to clean it into a form where we can get
    to the juicy stuff like training models. For the most part this is fairly straightforward,
    as long as the data is regular with nice neat column headings. However, life is
    never that easy and itâ€™s often the case the tables in these files can be in a
    less-than-perfect format to parse into neat data frames that can be uploaded into
    relational databases. Excel supports a lot of features such as pivot tables and
    cell merging, which human beings use to create a wide variety of layouts, with
    blank rows, random text here and there, and more!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example to illustrate â€¦
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b8a93c73e798926ce23cb65154d977a4.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: Example of an irregular table in Excel, with blank top rows, labels and merged
    cells. Perfectly readable for humans, but a challenge to parse for data science.
    This file was sourced from the [Humanitarian Data Exchange](https://data.humdata.org/dataset/kenya-number-of-acreage-under-irrigation-in-bomet-county)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: If we read the above file directly into Pandas â€¦
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We get this â€¦
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5089756e01020858fd71468ba8fd5fab.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Example of Pandas dataframe after parsing a table on an Excel sheet, where there
    are blank rows and merged cells to indicate hierarchical columns. Example data
    from the [Humanitarian Data Exchange](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Loading this into a database would result in near-unusable data because â€¦
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: There is a table title in the top-right cell
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Column â€˜Unnamed: 1â€™ title is actually whatâ€™s in the first column row 5 â€œWhat
    is the average size of land you own that â€¦â€'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Columns â€˜Unnamed:2â€™ and â€˜Unnamed:3â€™ are aggregate totals split into â€™Nâ€™ numeric
    and â€˜%â€™ percentage values
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Most columns are hierarchical, with merged cells above unmerged cells
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Itâ€™s not *that* bad, right?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: It is of course possible to provide parameters to [Pandas read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)
    that will convert hierarchical columns to indexes, which can then be collapsed
    into a single row. Alternatively, we might manipulate in [Openpxyl](https://openpyxl.readthedocs.io/en/stable/)
    using information from Excel itself about merged cells. However, these methods
    require knowledge of the table â€” specifically where the headings finish and the
    data starts and how hierarchical columns are structured â€” a luxury we might not
    always have if processing thousands of spreadsheets. Maintaining rule-based parsing
    for large volumes of files can be time-consuming and brittle, requiring continued
    maintenance as new layouts appear on the scene.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œå¯ä»¥å‘[Pandas read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)æä¾›å‚æ•°ï¼Œå°†å±‚æ¬¡åˆ—è½¬æ¢ä¸ºç´¢å¼•ï¼Œç„¶åå¯ä»¥å°†å…¶åˆå¹¶ä¸ºä¸€è¡Œã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨[Openpyxl](https://openpyxl.readthedocs.io/en/stable/)ä¸­å…³äºExcelè‡ªèº«çš„åˆå¹¶å•å…ƒæ ¼çš„ä¿¡æ¯è¿›è¡Œæ“ä½œã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¯¹è¡¨æ ¼æœ‰äº†è§£â€”â€”ç‰¹åˆ«æ˜¯æ ‡é¢˜åœ¨å“ªé‡Œç»“æŸã€æ•°æ®ä»å“ªé‡Œå¼€å§‹ä»¥åŠå±‚æ¬¡åˆ—çš„ç»“æ„â€”â€”è¿™æ˜¯æˆ‘ä»¬åœ¨å¤„ç†æˆåƒä¸Šä¸‡çš„ç”µå­è¡¨æ ¼æ—¶å¯èƒ½ä¸æ€»æ˜¯æ‹¥æœ‰çš„å¥¢ä¾ˆå“ã€‚å¯¹å¤§é‡æ–‡ä»¶è¿›è¡ŒåŸºäºè§„åˆ™çš„è§£æå¯èƒ½è€—æ—¶ä¸”è„†å¼±ï¼Œéœ€è¦éšç€æ–°å¸ƒå±€çš„å‡ºç°è€ŒæŒç»­ç»´æŠ¤ã€‚
- en: As it happens, I am not alone! Parsing irregular tables is a challenge being
    actively researched. For example, Microsoft authors have shown some great results
    using Convolutional Neural Networks to develop an algorithm called â€˜TableSenseâ€™
    [[1](https://arxiv.org/abs/2106.13500)]. This technique treats Excel sheets in
    a similar way to images but with richer featurization as each cell can have a
    range of attributes and data types, as well as formatting and merging characteristics.
    Very cool. I hope fantastic work like this will be included in Microsoftâ€™s products
    soon, but until then I wanted to explore some other approaches.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶å®ï¼Œæˆ‘å¹¶ä¸æ˜¯å”¯ä¸€ä¸€ä¸ªé‡åˆ°è¿™ä¸ªé—®é¢˜çš„äººï¼è§£æä¸è§„åˆ™è¡¨æ ¼æ˜¯ä¸€é¡¹æ­£åœ¨ç§¯æç ”ç©¶çš„æŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼Œå¾®è½¯çš„ä½œè€…å±•ç¤ºäº†åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œå¼€å‘çš„ä¸€ä¸ªåä¸ºâ€˜TableSenseâ€™çš„ç®—æ³•çš„å‡ºè‰²æˆæœ[[1](https://arxiv.org/abs/2106.13500)]ã€‚è¿™ç§æŠ€æœ¯å°†Excelè¡¨æ ¼è§†ä½œå›¾åƒæ¥å¤„ç†ï¼Œä½†å…·æœ‰æ›´ä¸°å¯Œçš„ç‰¹å¾åŒ–ï¼Œå› ä¸ºæ¯ä¸ªå•å…ƒæ ¼å¯èƒ½å…·æœ‰å¤šç§å±æ€§å’Œæ•°æ®ç±»å‹ï¼Œè¿˜åŒ…æ‹¬æ ¼å¼åŒ–å’Œåˆå¹¶ç‰¹å¾ã€‚éå¸¸é…·ã€‚æˆ‘å¸Œæœ›åƒè¿™æ ·çš„ç²¾å½©å·¥ä½œèƒ½å°½å¿«çº³å…¥å¾®è½¯çš„äº§å“ä¸­ï¼Œä½†åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘æƒ³æ¢ç´¢ä¸€äº›å…¶ä»–çš„æ–¹æ³•ã€‚
- en: 'Itâ€™s also worth noting that my use-case is not just to identify the range in
    a sheet where the table is (see [training data for the Microsoft paper above](https://github.com/microsoft/TableSense/blob/main/dataset/Table%20range%20annotations.txt)),
    but elements in the table so irregular formats can be converted to something that
    can be easily imported into a database. The main challenge is hierarchical columns
    in Excel, flattening these into a single row that captures information from overlying
    merged cells. Sounds simple to fix, but the challenge is: where do the headings
    stop and the data start? This is obvious to us humans, but itâ€™s surprising how
    something so simple can be quite noisy in the real world when processing sheets
    using code.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘çš„ä½¿ç”¨æ¡ˆä¾‹ä¸ä»…ä»…æ˜¯è¯†åˆ«è¡¨æ ¼åœ¨å·¥ä½œè¡¨ä¸­çš„èŒƒå›´ï¼ˆå‚è§[å¾®è½¯è®ºæ–‡çš„è®­ç»ƒæ•°æ®](https://github.com/microsoft/TableSense/blob/main/dataset/Table%20range%20annotations.txt)ï¼‰ï¼Œè¿˜åŒ…æ‹¬è¡¨æ ¼ä¸­çš„å…ƒç´ ï¼Œä»¥ä¾¿å°†ä¸è§„åˆ™çš„æ ¼å¼è½¬æ¢ä¸ºå¯ä»¥è½»æ¾å¯¼å…¥æ•°æ®åº“çš„æ ¼å¼ã€‚ä¸»è¦æŒ‘æˆ˜æ˜¯Excelä¸­çš„å±‚æ¬¡åˆ—ï¼Œå°†è¿™äº›å±‚æ¬¡åˆ—å±•å¹³æˆä¸€ä¸ªå•ç‹¬çš„è¡Œï¼Œä»è€Œæ•æ‰ä¸Šå±‚åˆå¹¶å•å…ƒæ ¼ä¸­çš„ä¿¡æ¯ã€‚å¬èµ·æ¥è§£å†³èµ·æ¥å¾ˆç®€å•ï¼Œä½†æŒ‘æˆ˜æ˜¯ï¼šæ ‡é¢˜åœ¨å“ªé‡Œç»“æŸï¼Œæ•°æ®ä»å“ªé‡Œå¼€å§‹ï¼Ÿè¿™å¯¹æˆ‘ä»¬äººç±»æ¥è¯´æ˜¾è€Œæ˜“è§ï¼Œä½†ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå½“ç”¨ä»£ç å¤„ç†å·¥ä½œè¡¨æ—¶ï¼Œè¿™æ ·ç®€å•çš„äº‹æƒ…åœ¨ç°å®ä¸–ç•Œä¸­å¯èƒ½ä¼šå˜å¾—éå¸¸å˜ˆæ‚ã€‚
- en: Given all the recent attention for generative AI and Large Language Models (LLMs),
    I wondered if perhaps [OpenAIâ€™s GPT-3](https://openai.com/blog/gpt-3-apps/) might
    be up to the challenge. These models are trained on huge amounts of data extracted
    from the internet, which includes tables and CSV files, so they might be useful
    in handling some of the nuances of tables put together by us crazy humans.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: é‰´äºæœ€è¿‘å¯¹ç”Ÿæˆå¼ AI å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…³æ³¨ï¼Œæˆ‘æƒ³çŸ¥é“ä¹Ÿè®¸[OpenAI çš„ GPT-3](https://openai.com/blog/gpt-3-apps/)å¯èƒ½ä¼šæ¥å—è¿™ä¸ªæŒ‘æˆ˜ã€‚è¿™äº›æ¨¡å‹åœ¨ä»äº’è”ç½‘æå–çš„å¤§é‡æ•°æ®ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬è¡¨æ ¼å’ŒCSVæ–‡ä»¶ï¼Œå› æ­¤å®ƒä»¬å¯èƒ½åœ¨å¤„ç†æˆ‘ä»¬è¿™äº›ç–¯ç‹‚äººç±»æ‹¼å‡‘çš„è¡¨æ ¼çš„æŸäº›ç»†èŠ‚æ–¹é¢ä¼šå¾ˆæœ‰ç”¨ã€‚
- en: Prompting GPT-3 to Tidy Up (a Small) Table
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æç¤º GPT-3 æ¸…ç†ï¼ˆä¸€ä¸ªå°çš„ï¼‰è¡¨æ ¼
- en: We will first try to solve our problem as zero- and few-shot tasks for GPT-3,
    before moving on to using fine-tuning techniques.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†é¦–å…ˆå°è¯•å°†é—®é¢˜ä½œä¸ºé›¶æ ·æœ¬å’Œå°‘é‡æ ·æœ¬ä»»åŠ¡è§£å†³ï¼Œç„¶åå†è½¬å‘ä½¿ç”¨å¾®è°ƒæŠ€æœ¯ã€‚
- en: '![](../Images/23eef763f4af285bab56ce5104601dbc.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/23eef763f4af285bab56ce5104601dbc.png)'
- en: Zero-shot, one-shot and few-shot tasks, contrasted with traditional fine-tuning.
    The panels above show four methods for performing a task with a language model.
    From Brown et al [[2](https://arxiv.org/pdf/2005.14165.pdf)]
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3 is trained on text scraped from the web, so we cannot prompt it with Excel
    (yet!), therefore we first have to convert our sheet into a form that is occurs
    on the web, CSV string â€¦
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Side note**: I also tried with Markdown and HTML tables, but got best results
    for my use-case with CSV.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Itâ€™s worth noting that for this analysis the tables we are dealing with are
    *thin,* ie having < 100 columns. This means the first 10 rows can be represented
    easily in a GPT-3 prompt. This is fine for most of the Excel tables I have been
    analyzing for the Humanitarian Data Exchange, but might not extend to other scenarios.
    Also, this analysis doesnâ€™t consider cases where there are multiple tables on
    the same Excel sheet â€¦ that is for a later blog post. ğŸ™‚
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '**Zero-Shot Prompt**'
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Letâ€™s now see if GPT-3 can reformat our untidy table with just a single prompt,
    a [zero-shot task](https://arxiv.org/pdf/2005.14165.pdf) [2] where we are providing
    no examples, just a CSV file of the table we want to be reformatted â€¦
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/d0bff692e6f0aa17d92fe2902f2d8efe.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
- en: It discarded unnecessary rows and converted the data to a nice regular table
    with column headings, but look closely and youâ€™ll see itâ€™s lost some key information,
    such as the breakdown by Male/Female. Classic [hallucination](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))
    territory, it looks very plausible but is wrong.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s play with the [temperature](https://platform.openai.com/docs/api-reference/completions/create)
    parameter. Lower values make the model more deterministic (giving the same results
    every time for the same prompt) whereas higher values are more random. With a
    higher temperature value, we get â€¦
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/f9ec19a4d12334d819089ceb85fdbbad.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
- en: '*Looks* nice! Almost all of the correct column headings from merged cells in
    our CSV, which is pretty amazing actually. However, spot-checking a few cells
    shows that though many are correct, some are not. Also, â€˜Overallâ€™ has been split
    into Male and Female in the above which is incorrect.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Another issue here is that calling GPT-3 exactly the same prompt will produce
    different results because of the high temperature value â€¦
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/7274d124424e64c6d953449273ad69d4.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: Not unreasonable, albeit with incorrect values, but an entirely different layout.
    Reproducibility is very important for our task, we should be able to process the
    tabular data in exactly the same way with each processing run.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: So high temperatures are not a good option for this use-case it seems.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: What about if we provide more context in the table? CSV isnâ€™t very expressive,
    for example, merged columns in hierarchical headers tell humans that the columns
    are grouped, but a CSV file doesnâ€™t capture this â€¦
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3e5d8eb9550c0dd1d246816daeccfb5d.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the above example, GPT-3 must infer that blank columns to the right of merged
    row titles correspond with those titles, and many times it actually does this.
    However, we can help a little since we know whether a cell is merged in our Excel
    file.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: To represent this in CSV we can unmerge merged cells and populate with their
    merged value â€¦
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/1790b27c754b07ba4517a577447e222c.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: Table where merged cells are unmerged and populated with merged value, to provide
    context in CSV file format
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The CSV file now captures overlying merged column headings. Letâ€™s see if this
    improves things, first with temperature=0.0 â€¦
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/780e6bd57ae7ca6db636a442ddae67c0.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
- en: And the same, but with temperature=1.0, just for fun â€¦
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2a7e421879c0e4b08e1525b6576b50e.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: A bit better, but there is always *something* a bit off. A missing category,
    cell values shifted, and neither table is usable if we require an accurate representation
    of the source data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, I experimented with various combinations of:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Prompts
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Temperature
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Markdown, HTML, and CSV to define the input table
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompting GPT-3 to generate the python for parsing rather than parsing the tables
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Occasionally the process was able to generate a table where column heading and
    values were perfect, but typically this required high temperature values and so
    wasnâ€™t reproducible. For the most part, results looked plausible but the data
    was incorrect.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: In fairness, we are really asking a lot of GPT-3 with what is a complicated
    zero-shot task. I am really impressed at how well it did, and perhaps with some
    better prompting and reframing of the problem â€” or GPT-4! â€” results may improve,
    but I wasnâ€™t able to achieve what was required.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '**Single-Shot Prompt**'
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, letâ€™s provide an example in the prompt. I took a similar Excel file from
    the Humanitarian Data Exchange â€¦
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6734984ce006423ea85a20d05d2a155.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
- en: Table we will use for our example in single-shot prompt. This file was sourced
    from the [Humanitarian Data Exchange](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: We want this to be processed to look like this â€¦
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ee9f834c88fea08684d2810cfe5bd4f.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: What our sample file should like after reformatting
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Obviously, this is an unrealistic â€˜Real worldâ€™ example, as the format and content
    are very similar to the table we are trying to process, but itâ€™s a good first
    test.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Converting our input table to CSV and unmerging merged cells as described above,
    we get â€¦
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f68f7f17e4a196691c5f3dd6e854da4e.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: We can now construct our single-shot prompt (assuming a temperature of zero
    for reproducibility) â€¦
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here is the generated prompt â€¦
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: And here is the completion from GPT-3 converted to a dataframe for easier display
    â€¦
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dce195b89914d22ee19d93cb75f89cf2.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: Generated table from single-shot prompt to reformat table with hierarchical
    headers (completion was a CSV, converted to a pandas dataframe here for easier
    display)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Nice! When provided an example, GPT-3 was able to reformat our new table perfectly.
    However, this isnâ€™t a great test because the example and test tables were very
    similar in structure and content, but itâ€™s interesting to note that even though
    the example did not have the Male/Female hierarchy, GPT-3 was able to collapse
    this extra level correctly.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Letâ€™s use the same example table to reformat a table that has a different layout
    and content data â€¦
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9e175fd03da4432492fa789dfb8f5f06.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: When processed with the same code results in this â€¦
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4362466354eb63c092183ca9952b5ba1.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
- en: Which is close, the headings are spot on, but the farm column has shifted to
    the left. Our single-shot prompt does quite well for reformatting very similar
    tables, but slight variation leads to poor results.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Single-Shot, with reasoning
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There has been quite a bit of research already around prompt engineering. A
    really great resource can be found in the OpenAI Cookbookâ€™s [Techniques to Improve
    Reliability](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
    [3]. One of the most effective methods to improve results is to include reasoning
    in the example prompt [[4](https://arxiv.org/abs/2205.11916)]. Using our previous
    table, letâ€™s adjust the prompt to include reasoning â€¦
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The full prompt looks like this â€¦
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Which results in this completion from GPT-3 for our input table â€¦
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Itâ€™s correct! The reformatted table is exactly what we wanted â€¦
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b44674a075c338a587502b102c6d2ca1.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
- en: Results are improved if we provide reasoning in the single-shot prompt
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: That said, the task we have provided isnâ€™t that great because even though the
    content is different to the provided example, the heading layout is still quite
    similar. In fact, if we tweak the table we want to reformat a little and add an
    extra column â€˜Organicâ€™ â€¦
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/886cf8bea9babb627b68d1e2fa6fb8d2.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
- en: Adding an extra column to the input
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: The prediction is now incorrect â€¦
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cbfa4266f749d5f3981baee97d382890.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
- en: Only off by just *one* extra comma in the title row, but this results in everything
    being shifted to the right.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: We might continue to engineer the prompt with more reasoning or apply [more
    advanced techniques](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)
    to automatically structure our prompt workflow, but the real issue is that one
    example isnâ€™t really enough to capture all the variations of table formats we
    might encounter. Itâ€™s amazing how well GPT-3 does even with one example, but itâ€™s
    not yet good enough for production for this task (at least how it has been framed
    so far).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Few-Shot â€¦. err, or not
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The next approach might be to provide more than a single example. However, table
    excerpts require a lot of tokens (more on this later), so if we have to provide
    multiple examples in a prompt, plus the tokens in the result, we start to hit
    the Open APIs token limits. For the davinci model this is currently set at [4,000](https://platform.openai.com/docs/models/gpt-3)
    tokens. Also, since we are charged by token it can get expensive to send and receive
    a lot of tokens for a small non-profit like [DataKind](https://www.datakind.org/).
    There are also performance implications with longer prompts, so few-shot prompts
    were not explored for this task.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: So I decided to skip few-shot for now.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It was interesting to explore zero- and single-shot prompts, and had that worked
    for this use-case it would have been an amazing result. In future, as models improve
    this may well become a viable option, but for now, it might make sense to reframe
    the task a little.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Another approach is to provide *lots* of examples through [fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
    As OpenAI note:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '*Fine-tuning lets you get more out of the models available through the API
    by providing:*'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '*Higher quality results than prompt design*'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ability to train on more examples than can fit in a prompt*'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Token savings due to shorter prompts*'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Lower latency requests*'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At first, I considered fine-tuning by providing GPT-3 (i) prompts of the raw
    table (with merged cells unmerged) and; (ii) completions being the reformatted
    table. The challenge with this approach however is that it still uses a lot of
    tokens, especially as we are now going to use hundreds of examples.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Instead of passing in raw table excerpts, letâ€™s try using attributes of that
    table and have GPT-3 predict key further attributes which we can use for parsing
    â€¦
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Reframing the Task â€” Using Table Attributes as Prompts
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a human (well, *mostly* human), when I scan a table in Excel I am able to
    pick out the structure by looking at the values and making a decision about where
    the data resides.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0b92fbbdfffa07263c0ca4bafb60f3c6.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: Identifying the data section in a table is key to parsing into a regular tabular
    structure
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Once I know the row at which data begins, itâ€™s straightforward to deduce heading
    hierarchies from the rows above and collapse them into a single header row in
    order to create a nice, regular table to use â€¦
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/81f481c588bb27c7779ca9dfc6c34b54.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
- en: Processed table with flat headings, easily imported into a relational database
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Identifying where the data begins at first seems trivial with a bit of manipulation
    in [openpyxl](https://openpyxl.readthedocs.io/en/stable/) or [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html).
    However, if working through tens of thousands of spreadsheets with different heading
    layouts, blank rows, and more, it can be challenging to develop a set of rules
    which can be used to identify exactly where the data starts in every sheet.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®å®šæ•°æ®çš„å¼€å§‹ä½ç½®ä¹ä¸€çœ‹ä¼¼ä¹å¾ˆç®€å•ï¼Œåªéœ€åœ¨ [openpyxl](https://openpyxl.readthedocs.io/en/stable/)
    æˆ– [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)
    ä¸­ç¨ä½œå¤„ç†å³å¯ã€‚ç„¶è€Œï¼Œå¦‚æœéœ€è¦å¤„ç†æˆåƒä¸Šä¸‡çš„å…·æœ‰ä¸åŒæ ‡é¢˜å¸ƒå±€ã€ç©ºç™½è¡Œç­‰çš„ç”µå­è¡¨æ ¼ï¼Œå¼€å‘ä¸€å¥—ç”¨äºå‡†ç¡®è¯†åˆ«æ¯ä¸ªå·¥ä½œè¡¨ä¸­æ•°æ®å¼€å§‹ä½ç½®çš„è§„åˆ™å°†æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚
- en: 'Itâ€™s complicated because:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¾ˆå¤æ‚ï¼Œå› ä¸ºï¼š
- en: Column headings can have a high degree of variability and look like data
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ—æ ‡é¢˜å¯èƒ½æœ‰å¾ˆé«˜çš„å˜åŒ–æ€§ï¼Œçœ‹èµ·æ¥åƒæ•°æ®ã€‚
- en: Blank cells and annotations can confusing parsing rules easily
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç©ºç™½å•å…ƒæ ¼å’Œæ³¨é‡Šå®¹æ˜“æ··æ·†è§£æè§„åˆ™ã€‚
- en: Data isnâ€™t always numeric, it can be categorical and look a lot like column
    headings
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°æ®ä¸æ€»æ˜¯æ•°å­—çš„ï¼Œå®ƒå¯ä»¥æ˜¯åˆ†ç±»çš„ï¼Œçœ‹èµ·æ¥å¾ˆåƒåˆ—æ ‡é¢˜ã€‚
- en: Some column headings are numbers and can look like data, for example, years
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸€äº›åˆ—æ ‡é¢˜æ˜¯æ•°å­—ï¼Œå¯èƒ½çœ‹èµ·æ¥åƒæ•°æ®ï¼Œä¾‹å¦‚å¹´ä»½ã€‚
- en: So what table attributes/features should we use to predict the row number where
    data first occurs?
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªäº›è¡¨æ ¼å±æ€§/ç‰¹å¾æ¥é¢„æµ‹æ•°æ®é¦–æ¬¡å‡ºç°çš„è¡Œå·å‘¢ï¼Ÿ
- en: I came up with a short list of table attributes I thought might might be useful
    â€¦
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åˆ—å‡ºäº†ä¸€ä¸ªæˆ‘è®¤ä¸ºå¯èƒ½æœ‰ç”¨çš„è¡¨æ ¼å±æ€§çš„ç®€çŸ­æ¸…å•â€¦â€¦
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Which gives output like this â€¦
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¼šäº§ç”Ÿè¿™æ ·çš„è¾“å‡ºâ€¦â€¦
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: These will be our prompts for fine-tuning the model.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å°†æ˜¯æˆ‘ä»¬ç”¨äºå¾®è°ƒæ¨¡å‹çš„æç¤ºã€‚
- en: To create completions for the fine-tuning file, I used the Humanitarian Data
    Exchange dataset for Kenya (see [here](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)
    for more details of how I extracted Excel files). Parsing files and looping through
    sheets in each, I generated prompts.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†åˆ›å»ºå¾®è°ƒæ–‡ä»¶çš„è¡¥å…¨ï¼Œæˆ‘ä½¿ç”¨äº†è‚¯å°¼äºšçš„äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢æ•°æ®é›†ï¼ˆæœ‰å…³å¦‚ä½•æå– Excel æ–‡ä»¶çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è§[è¿™é‡Œ](/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)ï¼‰ã€‚è§£ææ–‡ä»¶å¹¶å¾ªç¯éå†æ¯ä¸ªå·¥ä½œè¡¨ï¼Œæˆ‘ç”Ÿæˆäº†æç¤ºã€‚
- en: I used the following logic to create estimates of the row data starts on a sheet
    using the table parameters above â€¦
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä½¿ç”¨äº†ä»¥ä¸‹é€»è¾‘æ¥ä¼°ç®—æ•°æ®å¼€å§‹çš„è¡Œå·ï¼Œä½¿ç”¨äº†ä¸Šè¿°è¡¨æ ¼å‚æ•°â€¦â€¦
- en: '[PRE17]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This rule-based approach actually does a pretty good job, but it is not perfect,
    hence the need for GPT-3\. However, itâ€™s handy for creating a test set where most
    of the completions are accurate, I then only have to adjust a few where the logic
    above does not hold.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§åŸºäºè§„åˆ™çš„æ–¹æ³•å®é™…ä¸Šè¡¨ç°å¾—ç›¸å½“ä¸é”™ï¼Œä½†å®ƒå¹¶ä¸å®Œç¾ï¼Œå› æ­¤éœ€è¦ GPT-3ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒåœ¨åˆ›å»ºä¸€ä¸ªå¤§å¤šæ•°è¡¥å…¨éƒ½å‡†ç¡®çš„æµ‹è¯•é›†æ—¶å¾ˆæœ‰ç”¨ï¼Œæˆ‘åªéœ€è°ƒæ•´å‡ ä¸ªé€»è¾‘ä¸æˆç«‹çš„éƒ¨åˆ†å³å¯ã€‚
- en: For my training set, I used one table per organization from multiple Excel sheets
    labelled â€˜Kenyaâ€™ from 10 humanitarian provider organizations, where the prediction
    of the first data row was made using the rule-based approach above. I then reviewed
    this list and compared with the actual sheets to make corrections where the spreadsheet
    table started on a different row. I excluded cases where there were multiple tables
    on a sheet for this study, after which I had 232 fine-tuning prompts like this
    â€¦
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæˆ‘çš„è®­ç»ƒé›†ï¼Œæˆ‘ä½¿ç”¨äº†æ¥è‡ª 10 ä¸ªäººé“ä¸»ä¹‰æä¾›ç»„ç»‡çš„å¤šä¸ªæ ‡è®°ä¸ºâ€œKenyaâ€çš„ Excel è¡¨æ ¼ä¸­çš„æ¯ä¸ªç»„ç»‡çš„ä¸€ä¸ªè¡¨æ ¼ï¼Œå…¶ä¸­ä½¿ç”¨ä¸Šè¿°åŸºäºè§„åˆ™çš„æ–¹æ³•è¿›è¡Œäº†é¦–æ¬¡æ•°æ®è¡Œçš„é¢„æµ‹ã€‚æˆ‘éšåå®¡æŸ¥äº†è¿™ä»½æ¸…å•ï¼Œå¹¶ä¸å®é™…çš„å·¥ä½œè¡¨è¿›è¡Œäº†æ¯”è¾ƒï¼Œä»¥çº æ­£ç”µå­è¡¨æ ¼è¡¨æ ¼å¼€å§‹äºä¸åŒçš„è¡Œçš„æƒ…å†µã€‚æˆ‘æ’é™¤äº†æœ¬ç ”ç©¶ä¸­å­˜åœ¨å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µï¼Œæ­¤åæˆ‘å¾—åˆ°äº†
    232 ä¸ªè¿™æ ·çš„å¾®è°ƒæç¤ºâ€¦â€¦
- en: '[PRE18]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Side Note**: In the above you might notice Iâ€™ve added a â€˜meta_dataâ€™ element
    to each prompt. This isnâ€™t part of the required JSONL prompt record, but I include
    this to be able to easily associate each prompt with a file for debugging. The
    prompt file still seems to be accepted by OpenAI with this extra data, I think
    as long as there are â€˜promptâ€™ and â€˜completionâ€™ elements, itâ€™s happy!'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™„æ³¨**ï¼šåœ¨ä¸Šé¢çš„å†…å®¹ä¸­ï¼Œä½ å¯èƒ½æ³¨æ„åˆ°æˆ‘ä¸ºæ¯ä¸ªæç¤ºæ·»åŠ äº†ä¸€ä¸ªâ€œmeta_dataâ€å…ƒç´ ã€‚è¿™ä¸æ˜¯ JSONL æç¤ºè®°å½•çš„å¿…è¦éƒ¨åˆ†ï¼Œä½†æˆ‘è¿™æ ·åšæ˜¯ä¸ºäº†èƒ½å¤Ÿè½»æ¾å°†æ¯ä¸ªæç¤ºä¸æ–‡ä»¶å…³è”ä»¥ä¾¿äºè°ƒè¯•ã€‚åŒ…å«è¿™äº›é¢å¤–æ•°æ®çš„æç¤ºæ–‡ä»¶ä¼¼ä¹ä»ç„¶è¢«
    OpenAI æ¥å—ï¼Œæˆ‘è®¤ä¸ºåªè¦æœ‰â€œpromptâ€å’Œâ€œcompletionâ€å…ƒç´ ï¼Œå®ƒå°±ä¼šæ¥å—ï¼'
- en: I then fine-tuned a DaVinci model â€¦
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘å¾®è°ƒäº†ä¸€ä¸ª DaVinci æ¨¡å‹â€¦â€¦
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: I manually checked fine-tuning status as follows â€¦
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ‰‹åŠ¨æ£€æŸ¥äº†å¾®è°ƒçŠ¶æ€ï¼Œå¦‚ä¸‹æ‰€ç¤ºâ€¦â€¦
- en: '[PRE20]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Then once finished, retrieved the model â€¦
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åå®Œæˆåï¼Œæ£€ç´¢äº†æ¨¡å‹â€¦â€¦
- en: '[PRE21]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: For the test set I used one table from each Excel file sourced from organizations
    not in the training set (labeled â€˜Kenyaâ€™), first running the rule-based prediction
    above to generate prompts and completions and then correcting where this returned
    incorrect values. Again, excluding cases where multiple tables were specified
    on an excel sheet. This gave me a test set of 72 prompts.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '**Side Note:** In [my previous blog post](https://medium.com/towards-data-science/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)
    to predict HXL tags, I had to filter completions by log probability, but in this
    study it wasnâ€™t required.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: GPT-3 predicted the first data row on sheets in our test set with the following
    results â€¦
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: So GPT-3 does a nice job of predicting where the first data row is.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Putting it All Together
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Step 1 â€” Read in our data**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f631ffdb4c440854098cc64a07b849b.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
- en: Example spreadsheet, with varying hierarchical headers and notes in cells
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2 â€” Unmerge merged columns and populate with merged value**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e9623db509bee6348ad8d47e1441e67a.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
- en: Pandas dataframe of sheet after being processed by function â€˜pad_merged_cellsâ€™
    to unmerge and fill with merged values
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3 â€” Calculate table parameters to generate GPT-3 prompt**'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '**Step 4 â€” Call GPT-3 to predict where the data row starts**'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '**Step 5 â€” now we have the row data begins, concatenate column headings above
    this into one row**'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/457ae2d038f5792578767b18b888aef2.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
- en: Parsed sheet, with collapsed hierarchical columns, no random labels. This can
    now be imported into a database
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: This is a nice table we can upload into a relational database. See references
    section below for the full code.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Admittedly, it would be easy to manually parse this sheet manually, even specify
    some rules related to the table parameters we found, but the point of the above
    process is that it can be applied to a wide range of table layouts needed for
    analyzing the thousands of Excel sheets in the Humanitarian Data Exchange datasets.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions and Future Work
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Though there is great potential in zero- and single-shot prompting in general,
    they did not work out just yet for this particular task when prompted with CSV
    tables. As Large Language Models advance this will likely change â€” Iâ€™m excited
    to see what GPT-4 might be capable of â€” but for now, it seems that fine-tuning
    is a better option, predicting key table attributes which can be used in reformatting.
    This method does of course require some pre-processing in order to determine table
    parameters for the prompt. Itâ€™s also worth noting that in using table â€˜featuresâ€™
    it starts to look more like a classification task than text completion, and might
    be better framed that way. Irrespective, the technique performs well using the
    Humanitarian Data Exchange Excel files.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: I think it would be really interesting to extend this work to also handle cases
    where Excel sheets have multiple tables on any given sheet. This would require
    more table features than Iâ€™ve used in this study, such as cell formatting and
    column (rather than row) attributes.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¤ä¸ºå°†è¿™é¡¹å·¥ä½œæ‰©å±•åˆ°å¤„ç† Excel å·¥ä½œè¡¨ä¸Šæœ‰å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µå°†éå¸¸æœ‰è¶£ã€‚è¿™éœ€è¦æ¯”æˆ‘åœ¨è¿™é¡¹ç ”ç©¶ä¸­ä½¿ç”¨çš„æ›´å¤šçš„è¡¨æ ¼ç‰¹å¾ï¼Œæ¯”å¦‚å•å…ƒæ ¼æ ¼å¼å’Œåˆ—ï¼ˆè€Œä¸æ˜¯è¡Œï¼‰å±æ€§ã€‚
- en: More fun ahead!
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´å¤šæœ‰è¶£å†…å®¹æ•¬è¯·æœŸå¾…ï¼
- en: References
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '[1] Haoyu Dong et al, [TableSense: Spreadsheet Table Detection with Convolutional
    Neural Networks](https://arxiv.org/abs/2106.13500) (2021)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] Haoyu Dong ç­‰äººï¼Œ[TableSense: ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œç”µå­è¡¨æ ¼è¡¨æ ¼æ£€æµ‹](https://arxiv.org/abs/2106.13500)
    (2021)'
- en: '[2] Brown et al, [Language Models are Few Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)
    (2020).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] Brown ç­‰äººï¼Œ[è¯­è¨€æ¨¡å‹æ˜¯å°‘æ ·æœ¬å­¦ä¹ è€…](https://arxiv.org/pdf/2005.14165.pdf) (2020)ã€‚'
- en: '[3] [OpenAI Cookbook: Techniques to improve reliability](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[3] [OpenAI Cookbook: æé«˜å¯é æ€§çš„æŠ€æœ¯](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)'
- en: '[4] Kojima et al, [Large Language Models are Zero-shot reasoners](https://arxiv.org/abs/2205.11916)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[4] Kojima ç­‰äººï¼Œ[å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯é›¶æ ·æœ¬æ¨ç†è€…](https://arxiv.org/abs/2205.11916)'
- en: Code for this analysis can be found in [this notebook](https://github.com/datakind/gpt-3-meta-data-discovery/blob/main/gpt-3-table-parsing.ipynb).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåˆ†æçš„ä»£ç å¯ä»¥åœ¨[è¿™ä¸ªç¬”è®°æœ¬](https://github.com/datakind/gpt-3-meta-data-discovery/blob/main/gpt-3-table-parsing.ipynb)ä¸­æ‰¾åˆ°ã€‚
