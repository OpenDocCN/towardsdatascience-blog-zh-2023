- en: Optimizing Retrieval-Augmented Generation (RAG) by Selective Knowledge Graph
    Conditioning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过选择性知识图谱条件优化检索增强生成（RAG）
- en: 原文：[https://towardsdatascience.com/optimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69?source=collection_archive---------4-----------------------#2023-12-28](https://towardsdatascience.com/optimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69?source=collection_archive---------4-----------------------#2023-12-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/optimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69?source=collection_archive---------4-----------------------#2023-12-28](https://towardsdatascience.com/optimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69?source=collection_archive---------4-----------------------#2023-12-28)
- en: How SURGE substantially improves knowledge relevance through targeted augmentation
    while retaining language fluency
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何通过有针对性的增强显著提高知识相关性，同时保持语言流畅性
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----97a4cf96eb69--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----97a4cf96eb69--------------------------------)[](https://towardsdatascience.com/?source=post_page-----97a4cf96eb69--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----97a4cf96eb69--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----97a4cf96eb69--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@alcarazanthony1?source=post_page-----97a4cf96eb69--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----97a4cf96eb69--------------------------------)[](https://towardsdatascience.com/?source=post_page-----97a4cf96eb69--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----97a4cf96eb69--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----97a4cf96eb69--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----97a4cf96eb69---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----97a4cf96eb69--------------------------------)
    ·7 min read·Dec 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F97a4cf96eb69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----97a4cf96eb69---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----97a4cf96eb69---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----97a4cf96eb69--------------------------------)
    · 7分钟阅读 · 2023年12月28日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F97a4cf96eb69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69&source=-----97a4cf96eb69---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F97a4cf96eb69&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Foptimizing-retrieval-augmented-generation-rag-by-selective-knowledge-graph-conditioning-97a4cf96eb69&source=-----97a4cf96eb69---------------------bookmark_footer-----------)'
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用了人工智能软件来增强本文的语法、流畅性和可读性。*'
- en: Generative pre-trained models have shown impressive fluency and coherence when
    used for dialogue agents. However, a key limitation they suffer from is the lack
    of grounding in external knowledge. Left to their pre-trained parameters alone,
    these models often generate plausible-sounding but factually incorrect responses,
    also known as hallucinations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 生成预训练模型在用作对话代理时表现出令人印象深刻的流畅性和连贯性。然而，它们面临的一个关键局限是缺乏对外部知识的基础。如果仅依靠预训练参数，这些模型往往生成看似合理但事实错误的回应，也称为幻觉。
- en: 'Prior approaches to mitigate this have involved augmenting the dialogue context
    with entire knowledge graphs associated with entities mentioned in the chat. However,
    this indiscriminate conditioning on large knowledge graphs brings its own problems:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的减轻方法涉及将整个知识图谱与聊天中提到的实体进行增强对话上下文。然而，这种对大型知识图谱的盲目条件化带来了自身的问题：
- en: 'Limitations of Naive Knowledge Graph Augmentation:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 原始知识图谱增强的局限性：
- en: Much of the 1-hop context may be irrelevant to the dialogue, inserting unnecessary
    noise
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大部分1跳上下文可能与对话无关，插入了不必要的噪音
- en: Encoding entire knowledge subgraphs strains sequence length limits
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码整个知识子图会使序列长度限制变得紧张
- en: No guarantee model will use the relevant facts for generation
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有保证模型会使用相关的事实进行生成
- en: Risk of hallucination still exists despite knowledge grounding
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管进行了知识基础的处理，幻觉的风险仍然存在
