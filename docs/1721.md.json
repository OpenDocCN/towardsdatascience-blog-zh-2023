["```py\nimport openai\nopenai.api_key = \"YOUR KEY HERE\"\n```", "```py\ndef get_api_result(prompt):\n    request = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo-0301\",\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n\n    result = request['choices'][0]['message']['content']\n\n    print(result)\n```", "```py\ndef extract(prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can generate Python code. Please provide a natural language input text, and I will generate the corresponding Python code.\\nInput: {}\\nPython code:\"\"\".format(prompt)\n\n    get_api_result(prompt_template)\n```", "```py\nfrom sklearn.datasets import fetch_openml\n\nadult_income = fetch_openml(name='adult', version=2)\ndf = pd.DataFrame(adult_income.data, columns=adult_income.feature_names)\ndf['target'] = adult_income.target\n```", "```py\nimport pandas as pd\n\ndf = pd.read_csv(\"adult_income_prediction.csv\")\ndf.columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n              \"marital-status\", \"occupation\", \"relationship\", \"race\",\n              \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\",\n              \"native-country\", \"target\"]\n```", "```py\ndef transform(columns, column_types, prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can generate Python code. Please provide a natural language input text, and I will generate the corresponding Python code using the Pandas to preprocess the DataFrame. The DataFrame columns are {} and their corresponding dtypes are {}.\\nInput: {}\\nPython code:\"\"\".format(columns, column_types, prompt)\n\n    get_api_result(prompt_template)\n```", "```py\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the DataFrame\ndf = pd.read_csv('data.csv')\n\n# Convert categorical columns to one-hot encoded equivalents\ndf = pd.get_dummies(df, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])\n\n# Normalize numerical columns\nscaler = StandardScaler()\nnumerical_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\ndf[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n\n# Drop rows with NA or NaN values\ndf.dropna(inplace=True)\n\n# Drop rows with numeric column outliers\nz_scores = df[numerical_cols].apply(lambda x: (x - x.mean()) / x.std())\ndf = df[(z_scores > -3).all(axis=1) & (z_scores < 3).all(axis=1)]\n\n# Convert target column to 0 or 1 and change type to int\ndf['target'] = df['target'].apply(lambda x: 1 if x == '>50K' else 0).astype(int)\n```", "```py\ndef load(prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can generate Python code. Please provide a natural language input text, and I will generate the corresponding Python code.\\nInput: {}\\nPython code:\"\"\".format(prompt)\n\n    get_api_result(prompt_template)\n```", "```py\nimport sqlite3\nimport pandas as pd\n\n# Create a connection to the database\nconnection = sqlite3.connect(\"data.db\")\n\n# Define the DataFrame\ndf = pd.DataFrame()\n\n# Define the table name\ntable_name = \"income\"\n\n# Insert the data into the table\ndf.to_sql(table_name, connection, if_exists=\"replace\", index=False)\n\n# Commit the changes to the database\nconnection.commit()\n\n# Close the connection\nconnection.close()\n```", "```py\ndef train(prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can generate Python code. Focus on using scikit-learn when applicable. Please provide a natural language input text, and I will generate the corresponding Python code.\\nInput: {}\\nPython code:\"\"\".format(prompt)\n\n    get_api_result(prompt_template)\n```", "```py\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV, cross_validate\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport mlflow\nimport mlflow.sklearn\n\n# load the dataframe\ndf = pd.read_csv('path/to/dataframe.csv')\n\n# define the features and target columns\nfeatures = df.columns.drop('target')\ntarget = 'target'\n\n# set up mlflow\nmlflow.set_tracking_uri('localhost:5000') # or set up your own server\nmlflow.set_experiment(\"my_experiment\")\n\n# set up cross-validation\ncv = 5\n\n# define the models and corresponding hyperparameters to be tuned\nmodels = [\n    {\n        'name': 'Logistic Regression',\n        'estimator': LogisticRegression(),\n        'hyperparameters': {\n            'penalty': ['l1', 'l2'],\n            'C': [0.1, 1, 10]\n        }\n    },\n    {\n        'name': 'Decision Tree',\n        'estimator': DecisionTreeClassifier(),\n        'hyperparameters': {\n            'max_depth': [2, 4, 6, 8]\n        }\n    },\n    {\n        'name': 'Random Forest',\n        'estimator': RandomForestClassifier(),\n        'hyperparameters': {\n            'n_estimators': [10, 25, 50, 100],\n            'max_depth': [None, 2, 4, 6, 8]\n        }\n    }\n]\n\n# iterate through the models and corresponding hyperparameters to train and tune them\nwith mlflow.start_run():\n    best_model = None\n    best_metrics = {}\n\n    for model in models:\n        print(f\"Training {model['name']} model...\")\n\n        # set up grid search for hyperparameter tuning\n        gs = GridSearchCV(model['estimator'], model['hyperparameters'], cv=cv, verbose=2, n_jobs=-1, scoring='accuracy')\n        gs.fit(df[features], df[target])\n\n        # log metrics for all model types\n        metrics = cross_validate(gs.best_estimator_, df[features], df[target], cv=cv, n_jobs=-1,\n                                 scoring=[\"accuracy\", \"roc_auc\", \"f1\"])\n        for metric, values in metrics.items():\n            mlflow.log_metric(f\"{model['name']}_{metric}\", values.mean())\n\n        # check if this is the best model based on accuracy\n        if best_model is None or gs.best_score_ > best_metrics['accuracy']:\n            best_model = gs.best_estimator_\n            best_metrics = {'accuracy': gs.best_score_,\n                            'AUC': roc_auc_score(df[target], best_model.predict_proba(df[features])[:, 1]),\n                            'F1': f1_score(df[target], best_model.predict(df[features]))\n                           }\n\n    # register the best model in mlflow\n    mlflow.sklearn.log_model(sk_model=best_model, artifact_path=\"best_model\")\n\n    # log the best model's metrics\n    for metric, value in best_metrics.items():\n        mlflow.log_metric(f\"best_model_{metric}\", value)\n```", "```py\nfrom mlflow.models.signature import infer_signature\n```", "```py\nmlflow.sklearn.log_model(sk_model=best_model, artifact_path=\"best_model\", signature=infer_signature(df[features], best_model.predict(df[features])))\n```", "```py\ndef serve_model(model_path, prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can generate shell code for deploying models using MLFlow. Please provide a natural language input text, and I will generate the corresponding command to deploy the model. The model is located in the file {}.\\nInput: {}\\nShell command:\"\"\".format(model_path, prompt)\n\n    get_api_result(prompt_template)\n```", "```py\nmlflow models serve -m <model path here> -p 1111 --no-conda\n```", "```py\ndef send_request(prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can generate code for sending data to deployed MLFlow models. Please provide a natural language input text, and I will generate the corresponding command. \\nInput: {}\\nCommand:\"\"\".format(prompt)\n\n    get_api_result(prompt_template)\n```", "```py\ncurl -X POST -H \"Content-Type: application/json\" -d '<data here>' http://localhost:1111/invocations\n```", "```py\ncurl http://localhost:1111/invocations -X POST -H \"Content-Type: application/json\" -d '<data here>'\n```", "```py\ndef modify_request(prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can modify commands for sending data using \"curl\". Please provide a natural language instruction, corresponding command, and I will generate the modified command. \\nInput: {}\\nCommand:\"\"\".format(prompt)\n\n    get_api_result(prompt_template)\n```", "```py\ncode = \"\"\"curl -X POST -H \"Content-Type: application/json\" -d '<data here>' http://localhost:1111/invocations\"\"\"\nprompt = \"\"\"Please modify the following by placing the url before the \"-X POST\" argument:\\n{}\"\"\".format(code)\nmodify_request(prompt)\n```", "```py\ncurl http://localhost:1111/invocations -X POST -H \"Content-Type: application/json\" -d '<data here>'\n```", "```py\ndef create_payload(prompt):\n    prompt_template = \"\"\"You are a ChatGPT language model that can generate code for sending data to deployed MLFlow models. Please provide a natural language input text, and I will generate the corresponding command. \\nInput: {}\\nPython code:\"\"\".format(prompt)\n\n    get_api_result(prompt_template)\n```", "```py\njson_data = df.drop(\"target\", axis=1).to_json(orient=\"split\", double_precision=15)\nwrapped_data = f'{{\"dataframe_split\":{json_data}}}'\n```", "```py\njson_data = df[:5].drop(\"target\", axis=1).to_json(orient=\"split\", double_precision=15)\nwrapped_data = f'{{\"dataframe_split\":{json_data}}}'\n```", "```py\n{\"predictions\": [0, 0, 0, 1, 0]}\n```", "```py\nmlflow sagemaker build-and-push-container\n```", "```py\nmlflow deployments run-local -t sagemaker -m <model path> --name income_classifier\nmlflow deployments create -t sagemaker --name income_classifier -m model/ --config image_url=<docker image url> --config bucket=mlflow-serving --config region_name=us-east-1\n```"]