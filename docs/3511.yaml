- en: Preparing for Climate Change with an AI Assistant
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/preparing-for-climate-change-with-an-ai-assistant-cdceb5ce4426?source=collection_archive---------3-----------------------#2023-11-26](https://towardsdatascience.com/preparing-for-climate-change-with-an-ai-assistant-cdceb5ce4426?source=collection_archive---------3-----------------------#2023-11-26)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Simplifying complicated data through conversation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@astrobagel?source=post_page-----cdceb5ce4426--------------------------------)[![Matthew
    Harris](../Images/4fa3264bb8a028633cd8d37093c16214.png)](https://medium.com/@astrobagel?source=post_page-----cdceb5ce4426--------------------------------)[](https://towardsdatascience.com/?source=post_page-----cdceb5ce4426--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----cdceb5ce4426--------------------------------)
    [Matthew Harris](https://medium.com/@astrobagel?source=post_page-----cdceb5ce4426--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpreparing-for-climate-change-with-an-ai-assistant-cdceb5ce4426&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----cdceb5ce4426---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----cdceb5ce4426--------------------------------)
    ¬∑13 min read¬∑Nov 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fcdceb5ce4426&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpreparing-for-climate-change-with-an-ai-assistant-cdceb5ce4426&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----cdceb5ce4426---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fcdceb5ce4426&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fpreparing-for-climate-change-with-an-ai-assistant-cdceb5ce4426&source=-----cdceb5ce4426---------------------bookmark_footer-----------)![](../Images/843a51eb863429365131e0a7bd40f1dc.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image generated using OpenAI‚Äôs ChatGPT and Dall-E-3
  prefs: []
  type: TYPE_NORMAL
- en: TL;DR
  prefs: []
  type: TYPE_NORMAL
- en: '*In this article, we explore how to create a conversational AI agent using
    climate change data from the excellent* [*Probable Futures*](https://docs.probablefutures.org/)
    *API and the new OpenAI Assistants API. The AI agent is able to answer questions
    about how climate might affect a specified location and also perform basic data
    analysis. AI assistants can be well-suited to tasks like this, providing a promising
    channel for presenting complex data to non-technical users.*'
  prefs: []
  type: TYPE_NORMAL
- en: I was recently chatting with a neighbor about how climate change might affect
    us and how best to prepare homes for extreme weather events. There are some amazing
    websites that provide information related to this in map form, but I wondered
    if sometimes people might simply want to ask questions like ‚Äú***How will my home
    be affected by climate change?***‚Äù and ‚Äú***What can I do about it?***‚Äù and get
    a concise summary with tips on how to prepare. So I decided to explore some of
    the AI tools made available in the last few weeks.
  prefs: []
  type: TYPE_NORMAL
- en: Open AI‚Äôs Assistant API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI agents powered by large language models like [GPT-4](https://openai.com/research/gpt-4)
    are emerging as a way for people to interact with documents and data through conversation.
    These agents interpret what the person is asking, call APIs and databases to get
    data, generate and run code to carry out analysis, before presenting results back
    to the user. Brilliant frameworks like [langchain](https://www.langchain.com/)
    and [autogen](https://github.com/microsoft/autogen) are leading the way, providing
    patterns for easily implementing agents. Recently, OpenAI joined the party with
    their launch of [GPTs](https://openai.com/blog/introducing-gpts) as a no-code
    way to create agents, which I explored in [this article](https://medium.com/towards-data-science/developing-a-climate-gpt-using-nasas-power-api-37b3d9e2a664).
    These are designed very well and open the way for a much wider audience but they
    do have a few limitations. They require an API with an openapi.json specification,
    which means they don‚Äôt currently support standards such as [graphql](https://graphql.org/).
    They also don‚Äôt support the ability to register functions, which is to be expected
    for a no-code solution but can limit their capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Enter OpenAI‚Äôs other recent launch ‚Äî [Assistants API](https://platform.openai.com/docs/assistants/overview).
  prefs: []
  type: TYPE_NORMAL
- en: Assistants API (in beta) is a programmatic way to configure OpenAI Assistants
    which supports functions, web browsing, and knowledge retrieval from uploaded
    documents. The functions are a big difference compared to GPTs, as these enable
    more complex interaction with external data sources. Functions are where Large
    Language Models (LLMs) like GPT-4 are made aware that some user input should result
    in a call to a code function. The LLM will generate a response in JSON format
    with the exact parameters needed to call the function, which can then be used
    to execute locally. To see how they work in detail with OpenAI, see [here](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models).
  prefs: []
  type: TYPE_NORMAL
- en: A Comprehensive API for Climate Change ‚Äî Probable Futures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For us to be able to create an AI agent to help with preparing for climate change,
    we need a good source of climate change data and an API to extract that information.
    Any such resource must apply a rigorous approach to combine General Circulation
    Model (GCM) predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, the folks at [Probable Futures](https://probablefutures.org/) have
    done an amazing job!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/269fc20807be4eecd19871fb0094ee9a.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Probable Futures](https://probablefutures.org/) provide a range of resources
    related to climate change predictions'
  prefs: []
  type: TYPE_NORMAL
- en: 'Probable Futures is ‚Äú*A non-profit climate literacy initiative that makes practical
    tools, stories, and resources available online to everyone, everywhere.*‚Äù, and
    they provide a series of maps and data based on the CORDEX-CORE framework, a standardization
    for climate model output from the REMO2015 and REGCM4 regional climate models.
    [ Side note: I am not affiliated with Probable Futures ]'
  prefs: []
  type: TYPE_NORMAL
- en: Importantly, they provide a [GraphQL API](https://docs.probablefutures.org/calling-the-api/)
    for accessing this data which I could access after [requesting an API key](https://docs.probablefutures.org/api-access/).
  prefs: []
  type: TYPE_NORMAL
- en: Based on [the documentation](https://docs.probablefutures.org/calling-the-api/)
    I created functions which I saved into a file `assistant_tools.py` ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: I intentionally excluded `datasetId` in order to retrieve all indicators so
    that the AI agent has a wide range of information to work with.
  prefs: []
  type: TYPE_NORMAL
- en: The API is robust in that it accepts towns and cities as well as full addresses.
    For example ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Returns a JSON record with climate change information for the location ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Creating an OpenAI Assistant
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, we need to build the AI assistant using the beta API. There are some good
    resources in [the documentation](https://platform.openai.com/docs/assistants/overview)
    and also the very useful [OpenAI Cookbook](https://cookbook.openai.com/examples/assistants_api_overview_python).
    However, being so new and in beta, there isn‚Äôt *that* much information around
    yet so at times it was a bit of trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to configure tools the assistant can use such as the function
    to get climate change data. Following [the documentation](https://platform.openai.com/docs/assistants/tools/function-calling)
    ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: You‚Äôll notice we‚Äôve provided text descriptions for each parameter in the function.
    From experimentation, this seems to be used by the agent when populating parameters,
    so take care to be as clear as possible and to note any idiosyncracies so the
    LLM can adjust. From this we define the tools ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You‚Äôll notice I left code_interpretor in, giving the assistant the ability to
    run code needed for data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we need to specify a set of user instructions (a system prompt). These
    are absolutely key in tailoring the assistents‚Äôs performance to our task. Based
    on some quick experimentation I arrived at this set ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You can see I‚Äôve added instructions for the assistant to provide resources such
    as websites to help users prepare for climate change. This is a bit ‚ÄòOpen‚Äô, for
    a production assistant we‚Äôd probably want tighter curation of this.
  prefs: []
  type: TYPE_NORMAL
- en: One wonderful thing that‚Äôs now possible is we can also instruct regarding general
    tone, in the above case requesting that output is clear to a non-technical user.
    Obviously, all of this needs some systematic prompt engineering, but it‚Äôs interesting
    to note how we now ‚ÄòProgram‚Äô in part through persuasion. üòä
  prefs: []
  type: TYPE_NORMAL
- en: OK, now we have our tools and instructions, let‚Äôs create the assistant ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The above assumes we have defined keys and our agent id in a `.env` file. You‚Äôll
    notice the code first checks to see if the agent exists using the `ASSISTANT_ID`
    in the `.env` file and update it if so, otherwise it creates a brand-new agent
    and the ID generated must be copied to the `.env` file. Without this, I was creating
    a LOT of assistants!
  prefs: []
  type: TYPE_NORMAL
- en: Once the assistant is created, it becomes visible on the [OpenAI User Interface](https://platform.openai.com/assistants)
    where it can be tested in the [Playground](https://platform.openai.com/playground).
    Since most of the development and debugging related to function calls actually
    calling code, I didn‚Äôt find the playground super useful for this analysis, but
    it‚Äôs designed nicely and might be useful in other work.
  prefs: []
  type: TYPE_NORMAL
- en: For this analysis, I decided to use the new [GPT-4-Turbo](https://help.openai.com/en/articles/8555510-gpt-4-turbo)
    model by setting `model` to ‚Äúgpt-4‚Äì1106-preview‚Äù.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a User Interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We want to be able to create a full chatbot, so I started with this [chainlit
    cookbook example](https://github.com/Chainlit/cookbook/tree/main/openai-assistant),
    adjusting it slightly to separate agent code into a dedicated file and to access
    via ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Chainlit is very concise and the user interface easy to set up, you can find
    the code for the app [here](https://github.com/datakind/climate-change-assistant/blob/main/app.py).
  prefs: []
  type: TYPE_NORMAL
- en: Trying Out Our Climate Change Assistant AI Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Putting it all together ‚Äî see code [here‚Ää](https://github.com/datakind/climate-change-assistant/tree/main)‚Äî
    we start the agent with a simple `chainlit run app.py` ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c5919b5b0d6bf74ea521271af0f9fc17.png)'
  prefs: []
  type: TYPE_IMG
- en: Let‚Äôs ask about a location ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/532a9253a7abfc03622b330d1699eec2.png)'
  prefs: []
  type: TYPE_IMG
- en: Noting above that I intentionally misspelled Mombasa.
  prefs: []
  type: TYPE_NORMAL
- en: The agent then starts its work, calling the API and processing the JSON response
    (it took about 20 seconds) ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/49ed28382e012a30332ceb482eb82ec0.png)'
  prefs: []
  type: TYPE_IMG
- en: Based on our instructions, it then finishes off with ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e759fbfee93d2ea443add0f506ea5191.png)'
  prefs: []
  type: TYPE_IMG
- en: But is it right?
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs call the API and review the output ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Which queries the API with ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This gives the following (truncated to just display a few) ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Spot-checking it seems that the agent captured them perfectly and presented
    to the user an accurate summary.
  prefs: []
  type: TYPE_NORMAL
- en: Improving Usability Through Instruction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The AI agent can be improved through some instructions about how it presents
    information.
  prefs: []
  type: TYPE_NORMAL
- en: One of the instructions was to always generate a link to the map visualization
    back on the Probable Futures website, which when clicked goes to the right location
    ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/282e7fcb1c67dde0e6635cbcaf7951e9.png)'
  prefs: []
  type: TYPE_IMG
- en: The agent always generates a URL to take the user to the correct [map visualization](https://probablefutures.org/maps/?selected_map=days_above_32c&map_version=latest&volume=heat&warming_scenario=1.5&map_projection=mercator#9.2/-4/39.6)
    for their query on the probable futures website
  prefs: []
  type: TYPE_NORMAL
- en: Another instruction asked the agent to always prompt the user to try other warming
    scenarios. By default, the agent produces results for a predicted 1.5C global
    increase in temperature, but we allow the user to explore other ‚Äî and somewhat
    depressing ‚Äî scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Analysis Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we gave the AI agent the code interpreter skill, it should be able to
    execute Python code to do basic data analysis. Let‚Äôs try this out.
  prefs: []
  type: TYPE_NORMAL
- en: First I asked for how climate change would affect London and New York, to which
    the agent provided summaries. Then I asked ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a33e331f4044ea5a8dfd0ee42a1cf01c.png)'
  prefs: []
  type: TYPE_IMG
- en: This resulted in the Agent using code interpreter to generate and run Python
    code to create a plot ‚Ä¶
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1060482040ee01dc6b1981bae17f1cdb.png)'
  prefs: []
  type: TYPE_IMG
- en: The AI agent is able to carry out basic data analysis tasks using climate change
    data extracted from the API
  prefs: []
  type: TYPE_NORMAL
- en: Not bad!
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions and Future Work
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the Probable Futures API and an OpenAI assistant we were able to create
    a conversational interface showing how people might be able to ask questions about
    climate change and get advice on how to prepare. The agent was able to make API
    calls as well as do some basic data analysis. This offers another channel for
    climate awareness, which may be more attractive to some non-technical users.
  prefs: []
  type: TYPE_NORMAL
- en: We could of course have developed a chatbot to determine intent/entities and
    code to handle the API, but this is more work and would need to be revisited for
    any API changes and when new APIs are added. Also, a Large Language Model Agent
    does a good job of interpreting user input and summarization with very limited
    development, and takes things to another level in being able to run code and carry
    out basic data analysis. Our particular use-case seems particularly well suited
    to an AI agent because the task is constrained in scope.
  prefs: []
  type: TYPE_NORMAL
- en: There are some challenges though, the technique is a bit slow (queries took
    about 20‚Äì30 seconds to complete). Also, LLM token costs weren‚Äôt analyzed for this
    article and may be prohibitive.
  prefs: []
  type: TYPE_NORMAL
- en: That said, OpenAI Assistants API is in beta. Also the agent wasn‚Äôt tuned in
    any way and so with further work, extra functions for common tasks, performance
    and cost could likely be optimized for this exciting new technique.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*This article is based on data and other content made available by Probable
    Futures, a Project of SouthCoast Community Foundation and certain of that data
    may have been provided to Probable Futures by Woodwell Climate Research Center,
    Inc. or The Coordinated Regional climate Downscaling Experiment (CORDEX)*'
  prefs: []
  type: TYPE_NORMAL
- en: Code for this analysis can be found [here](https://github.com/datakind/climate-change-assistant/tree/main).
  prefs: []
  type: TYPE_NORMAL
- en: You can find more of my articles [here](https://medium.com/@astrobagel).
  prefs: []
  type: TYPE_NORMAL
