["```py\ntransforms = torch.nn.Sequential(\n    transforms.CenterCrop(10),\n    transforms.Normalize(\n      # Channel means\n      #    R,     G,     B\n      (0.485, 0.456, 0.406),\n      # Channel standard deviation\n      (0.229, 0.224, 0.225),\n    ),\n)\n```", "```py\ntorch.manual_seed(21)\nnum_channels = 3\n\n# Example tensor so that we can use randn_like() below.\ny = torch.randn(20, num_channels, 1, 1)\n\nmodel = nn.BatchNorm2d(num_channels)\n\n# nb is a dict containing the buffers (non-trainable parameters)\n# of the BatchNorm2d layer. Since these are non-trainable\n# parameters, we don't need to run a backward pass to update\n# these values. They will be updated during the forward pass itself.\nnb = dict(model.named_buffers())\nprint(f\"Buffers in BatchNorm2d: {nb.keys()}\\n\")\n\nstacked = torch.tensor([]).reshape(0, num_channels, 1, 1)\n\nfor i in range(2000):\n    x = torch.randn_like(y)\n    y_hat = model(x)\n    # Save all the input tensor into 'stacked' so that\n    # we can compute the mean and variance later.\n    stacked = torch.cat([stacked, x], dim=0)\n# end for\n\nprint(f\"Shape of stackend tensor: {stacked.shape}\\n\")\nsmean = stacked.mean(dim=(0, 2, 3))\nsvar = stacked.var(dim=(0, 2, 3))\nprint(f\"Manually Computed:\")\nprint(f\"------------------\")\nprint(f\"Mean: {smean}\\nVariance: {svar}\\n\")\nprint(f\"Computed by BatchNorm2d:\")\nprint(f\"------------------------\")\nrm, rv = nb['running_mean'], nb['running_var']\nprint(f\"Mean: {rm}\\nVariance: {rv}\\n\")\nprint(f\"Mean Absolute Differences:\")\nprint(f\"--------------------------\")\nprint(f\"Mean: {(smean-rm).abs().mean():.4f}, Variance: {(svar-rv).abs().mean():.4f}\")\n```", "```py\nBuffers in BatchNorm2d: dict_keys(['running_mean', 'running_var', 'num_batches_tracked'])\n\nShape of stackend tensor: torch.Size([40000, 3, 1, 1])\n\nManually Computed:\n------------------\nMean: tensor([0.0039, 0.0015, 0.0095])\nVariance: tensor([1.0029, 1.0026, 0.9947])\n\nComputed by BatchNorm2d:\n------------------------\nMean: tensor([-0.0628,  0.0649,  0.0600])\nVariance: tensor([1.0812, 1.0318, 1.0721])\n\nMean Absolute Differences:\n--------------------------\nMean: 0.0602, Variance: 0.0616\n```"]