- en: Augmenting LLMs with RAG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672?source=collection_archive---------1-----------------------#2023-10-10](https://towardsdatascience.com/augmenting-llms-with-rag-f79de914e672?source=collection_archive---------1-----------------------#2023-10-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An End to End Example Of Seeing How Well An LLM Model Can Answer Amazon SageMaker
    Related Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ram-vegiraju.medium.com/?source=post_page-----f79de914e672--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----f79de914e672--------------------------------)[](https://towardsdatascience.com/?source=post_page-----f79de914e672--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----f79de914e672--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----f79de914e672--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-llms-with-rag-f79de914e672&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b----f79de914e672---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----f79de914e672--------------------------------)
    ·9 min read·Oct 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff79de914e672&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-llms-with-rag-f79de914e672&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----f79de914e672---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff79de914e672&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Faugmenting-llms-with-rag-f79de914e672&source=-----f79de914e672---------------------bookmark_footer-----------)![](../Images/553cc94765b38c8f5437dbc15e3856a6.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image from [Unsplash](https://unsplash.com/photos/lUSFeh77gcs)
  prefs: []
  type: TYPE_NORMAL
- en: I’ve written quite a few blogs on Medium around different technical topics,
    and more heavily around [Machine Learning (ML) Model Hosting on Amazon SageMaker](https://ram-vegiraju.medium.com/list/amazon-sagemaker-f1b06f720fba).
    I’ve also lately developed an interest for the growing Generative AI/Large Language
    Model ecosystem (like everyone else in the industry lol).
  prefs: []
  type: TYPE_NORMAL
- en: These two different verticals led me to an interesting question. **How good
    are my Medium articles at teaching Amazon SageMaker?** To answer this I decided
    to implement a Generative AI solution that utilizes [Retrieval Augmented Generation
    (RAG)](https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html)
    with access to some of my articles to see how well it could answer some SageMaker
    related questions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article we’ll take a look at building an end to end Generative AI solution
    and utilize a few different popular tools to operationalize this workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**LangChain**](https://www.langchain.com/): LangChain is a popular Python
    framework that helps simplify Generative AI applications by providing ready made
    modules that help with Prompt Engineering, RAG implementation, and LLM workflow
    orchestration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**OpenAI**](https://openai.com/): LangChain will take care of the orchestration
    of our Generative AI App, the brains however is still the model. In this case
    we use…'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
