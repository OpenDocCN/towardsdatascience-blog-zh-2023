- en: Can LLMs Replace Data Analysts? Building An LLM-Powered Analyst
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce?source=collection_archive---------0-----------------------#2023-12-11](https://towardsdatascience.com/can-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce?source=collection_archive---------0-----------------------#2023-12-11)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Part 1: empowering ChatGPT with tools'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://miptgirl.medium.com/?source=post_page-----851578fa10ce--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----851578fa10ce--------------------------------)[](https://towardsdatascience.com/?source=post_page-----851578fa10ce--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----851578fa10ce--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page-----851578fa10ce--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----851578fa10ce---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----851578fa10ce--------------------------------)
    ·19 min read·Dec 11, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F851578fa10ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----851578fa10ce---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F851578fa10ce&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcan-llms-replace-data-analysts-building-an-llm-powered-analyst-851578fa10ce&source=-----851578fa10ce---------------------bookmark_footer-----------)![](../Images/b088e6e4add866f67e47f8714dd3bae5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Image by DALL-E 3
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: I think each of us has wondered at least once over the past year if (or rather
    when) ChatGPT will be able to replace your role. I’m no exception here.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: We have a somewhat consensus that the recent breakthroughs in Generative AI
    will highly affect our personal lives and work. However, there is no clear view
    yet of how our roles will change over time.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Spending lots of time thinking about different possible future scenarios and
    their probabilities might be captivating, but I suggest an absolutely different
    approach — to try to build your prototype yourself. First, it’s rather challenging
    and fun. Second, it will help us to look at our work in a more structured way.
    Third, it will give us an opportunity to try in practice one of the most cutting-edge
    approaches — LLM agents.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will start simple and learn how LLMs can leverage tools
    and do straightforward tasks. But in the following articles, we will dive deeper
    into different approaches and best practices for LLM agents.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: So, let the journey begin.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: What is data analytics?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before moving on to the LLMs, let’s try defining what analytics is and what
    tasks we do as analysts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: My motto is that the goal of the analytical team is to help the product teams
    make the right decisions based on data in the available time. It’s a good mission,
    but to define the scope of the LLM-powered analyst, we should decompose the analytical
    work further.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'I like [the framework](https://www.gartner.com/en/topics/data-and-analytics)
    proposed by Gartner. It identifies four different Data and Analytics techniques:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**Descriptive analytics** answers questions like “What happened?”. For example,
    what was the revenue in December? This approach includes reporting tasks and working
    with BI tools.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diagnostic analytics** goes a bit further and asks questions like “Why did
    something happen?”. For example, why revenue decreased by 10% compared to the
    previous year? This technique requires more drill-down and slicing & dicing of
    your data.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Predictive analytics** allows us to get answers to questions like “What will
    happen?”. The two cornerstones of this approach are forecasting (predicting the
    future for business-as-usual situations) and simulation (modelling different possible
    outcomes).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prescriptive analytics** impacts the final decisions. The common questions
    are “What should we focus on?” or “How could we increase volume by 10%?”.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, companies go through all these stages step by step. It’s almost impossible
    to start looking at forecasts and different scenario analyses if your company
    hasn’t mastered descriptive analytics yet (you don’t have a data warehouse, BI
    tools, or metrics definitions). So, this framework can also show the company’s
    data maturity.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, when an analyst grows from junior to senior level, she will likely
    go through all these stages, starting from well-defined reporting tasks and progressing
    to vague strategic questions. So, this framework is relevant on an individual
    level as well.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: If we return to our LLM-powered analyst, we should focus on descriptive analytics
    and reporting tasks. It’s better to start from the basics. So, we will focus on
    learning LLM to understand the basic questions about data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: We’ve defined our focus for the first prototype. So, we are ready to move on
    to the technical questions and discuss the concept of LLM agents and tools.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为第一个原型定义了重点。因此，我们准备进入技术问题，讨论 LLM 代理和工具的概念。
- en: LLM agents and tools
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 代理和工具
- en: When we were using LLMs before (for example, to do topic modelling [here](/topic-modelling-in-production-e3b3e99e4fca)),
    we described the exact steps ourselves in the code. For example, let’s look at
    the chain below. Firstly, we asked the model to determine the sentiment for a
    customer review. Then, depending on the sentiment, extract from the review either
    the advantages or disadvantages mentioned in the text.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们之前使用 LLM 时（例如，为了做主题建模[这里](/topic-modelling-in-production-e3b3e99e4fca)），我们在代码中自己描述了确切的步骤。例如，让我们看看下面的链条。首先，我们要求模型确定客户评论的情感。然后，根据情感，从评论中提取提到的优点或缺点。
- en: '![](../Images/351d036bc9e9dda4689b9cad8da4841b.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/351d036bc9e9dda4689b9cad8da4841b.png)'
- en: Illustration by author
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: In this example, we clearly defined the LLM’s behaviour, and the LLM solved
    this task pretty well. However, this approach won’t work if we build something
    more high-level and vague, like an LLM-powered analyst.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们明确地定义了 LLM 的行为，并且 LLM 很好地解决了这个任务。然而，如果我们构建更高层次和模糊的东西，比如一个由 LLM 驱动的分析师，这种方法就不起作用了。
- en: If you’ve ever worked as or with an analyst for at least one day, you would
    know that analysts are getting a vast range of different questions and asks, starting
    from basic questions (like “How many customers did we have on our site yesterday?”
    or “Could you make a graph for our Board meeting tomorrow?”) to very high-level
    ones (for example, “What are the main customer pain points?” or “What market should
    we launch next?”). It goes without saying it’s not feasible to describe all possible
    scenarios.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经作为分析师或与分析师合作过至少一天，你会知道分析师会收到各种不同的问题，从基础问题（如“昨天我们网站上有多少客户？”或“你能为我们明天的董事会会议做个图表吗？”）到非常高层次的问题（例如，“主要的客户痛点是什么？”或“我们应该接下来进入哪个市场？”）。不用说，描述所有可能的场景是不现实的。
- en: 'However, there’s an approach that could help us — agents. The core idea of
    the agents is to use LLMs as a reasoning engine that could choose what to do next
    and when it’s time to return the final answer to the customer. It sounds pretty
    close to our behaviour: we get a task, define needed tools, use them, and then
    come back with the final answer when ready.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一种方法可能对我们有所帮助——代理。代理的核心思想是将 LLM 用作推理引擎，可以选择下一步做什么，以及何时向客户返回最终答案。这听起来非常接近我们的行为：我们接到任务，定义所需工具，使用它们，然后在准备好时返回最终答案。
- en: The essential concept related to agents (that I’ve already mentioned above)
    is tools. Tools are functions that LLM could invoke to get missing information
    (for example, execute SQL, use a calculator or call a search engine). Tools are
    crucial because they allow you to bring LLMs to the next level and interact with
    the world. In this article, we will primarily focus on OpenAI functions as tools.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 与代理相关的基本概念（我已经在上面提到过）是工具。工具是 LLM 可以调用以获取缺失信息的功能（例如，执行 SQL、使用计算器或调用搜索引擎）。工具至关重要，因为它们使你能够将
    LLM 提升到一个新的水平，并与世界互动。在本文中，我们将主要关注作为工具的 OpenAI 函数。
- en: 'OpenAI has fine-tuned models to be able to work with functions so that:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 已经对模型进行了微调，以便能够处理函数：
- en: You can pass to the model the list of functions with descriptions;
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将包含描述的函数列表传递给模型；
- en: If it’s relevant to your query, the model will return you a function call —
    function name and input parameters to call it.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果与你的查询相关，模型会返回一个函数调用——函数名称和调用它的输入参数。
- en: You can find more info and the up-to-date list of models that support functions
    in [the documentation](https://platform.openai.com/docs/guides/function-calling).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[文档](https://platform.openai.com/docs/guides/function-calling)中找到更多信息和支持函数的模型的最新列表。
- en: 'There are two prominent use cases to use functions with LLMs:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LLM 的函数有两个显著的用例：
- en: Tagging & extraction — in these cases, functions are used to ensure the output
    format of the model. Instead of the usual output with content, you will get a
    structured function call.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记和提取——在这些情况下，函数用于确保模型的输出格式。你将得到一个结构化的函数调用，而不是通常的内容输出。
- en: Tools & routing — this is a more exciting use case that allows you to create
    an agent.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具和路由——这是一个更有趣的用例，允许你创建一个代理。
- en: Let’s start with the more straightforward use case of extraction to learn how
    to use OpenAI functions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从提取的更直接的用例开始，以了解如何使用 OpenAI 函数。
- en: 'Use Case #1: Tagging & Extraction'
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You might wonder what is the difference between tagging and extraction. These
    terms are pretty close. The only difference is whether the model extracts info
    presented in the text or labels the text providing new information (i.e. defines
    language or sentiment).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a5448906e9ce962ab3d0a17a25e1e470.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: Illustration by author
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we’ve decided to focus on descriptive analytics and reporting tasks,
    let’s use this approach to structure incoming data requests and pull the following
    components: metrics, dimensions, filters, period and desired output.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1ebc1a0b667eb225b3d60c210bc71d94.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: Illustration by author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: It will be an example of extraction since we only need information present in
    the text.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI Completion API basic example
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we need to define the function. OpenAI expects a function description
    as a JSON. This JSON will be passed to LLM, so we need to tell it all the context:
    what this function does and how to use it.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a function JSON. We’ve specified:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '`name` and `description` for the function itself,'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`type` and `description` for each argument,'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the list of required input parameters for the function.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: There’s no need to implement the function itself in this use case because we
    won’t be using it. We only get LLM responses in a structured way as function calls.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we could use the standard OpenAI Chat Completion API to call the function.
    We passed to the API call:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: model — I’ve used the latest ChatGPT 3.5 Turbo that can work with functions,
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: list of messages — one system message to set up the context and a user request,
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: list of functions we’ve defined earlier.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As a result, we got the following JSON.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Remember that functions and function calls will be counted into the tokens limits
    and be billed.
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The model returned a function call instead of a common response: we can see
    that the `content` is empty and `finish_reason` is equal to `function_call`. In
    the response, there are also the input parameters for the function call:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '`metric = "number of users"`,'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`filters = "platform = ''iOS''"`,'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dimensions = "date"`,'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`period_start = "2021-01-01"`,'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`period_start = "2021-12-31"`,'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`output_type = "visualisation"`.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model did a pretty good job. The only problem is that it presumed the period
    out of nowhere. We can fix it by adding more explicit guidance to the system message,
    for example, `"Extract the relevant information from the provided request. Extract
    ONLY the information presented in the initial request; don't add anything else.
    Return partial information if something is missing."`
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: By default, models decide whether to use functions independently (`function_call
    = 'auto'`). We can require it to return a specific function call every time or
    not to use functions at all.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We’ve got the first working program that uses LLM functions. That’s awesome.
    However, it’s not very convenient to describe functions in a JSON. Let’s discuss
    how to do it easier.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Using Pydantic to define functions
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To define functions more conveniently, we can leverage [Pydantic](https://docs.pydantic.dev/latest/).
    Pydantic is the most popular Python library for data validation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: We’ve already [used](https://medium.com/towards-data-science/topic-modelling-in-production-e3b3e99e4fca)
    Pydantic to define LangChain Output Parser.
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: First, we need to create a class inheriting from the `BaseModel` class and define
    all the fields (arguments of our function).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, we can use LangChain to convert the Pydantic class into the OpenAI function.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: LangChain validates the class we provided. For example, it ensures that the
    function description is specified since LLM needs it to be able to use this tool.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: As a result, we got the same JSON to pass to LLM, but now we express it as a
    Pydantic class.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, we could use it in our call to OpenAI. Let’s switch from OpenAI API to
    LangChain to make our API calls more modular.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Defining LangChain chain
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s define a chain to extract needed information from the requests. We will
    use LangChain since it’s the most popular framework for LLMs. If you haven’t worked
    with it before, I recommend you learn some basics in [one of my previous articles](https://medium.com/towards-data-science/topic-modelling-in-production-e3b3e99e4fca).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Our chain is simple. It consists of an Open AI model and prompt with one variable
    `request` (a user message).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: We’ve also used the `bind` function to pass `functions` argument to the model.
    The `bind` function [allows](https://python.langchain.com/docs/expression_language/how_to/binding)
    us to specify constant arguments for our models that are not part of the input
    (for example, `functions` or `temperature`).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now it’s time to try our function. We need to use the invoke method and pass
    a `request`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the output, we got `AIMessage` without any content but with a function call.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So, we’ve learned how to use OpenAI functions in LangChain to get structured
    output. Now, let’s move on to the more interesting use case — tools and routing.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: 'Use Case #2: Tools & Routing'
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s time to use tools and empower our model with external capabilities. Models
    in this approach are reasoning engines, and they can decide what tools to use
    and when (it’s called routing).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: LangChain has a concept of [tools](https://python.langchain.com/docs/modules/agents/tools/)
    — interfaces that agents can use to interact with the world. Tools can be functions,
    LangChain chains or even other agents.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: We can easily convert tools into OpenAI functions using `format_tool_to_openai_function`
    and keep passing the `functions` argument to LLMs.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Defining a custom tool
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s teach our LLM-powered analyst to calculate the difference between two
    metrics. We know that LLMs might make mistakes in math, so we would like to ask
    a model to use a calculator instead of counting on its own.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: To define a tool, we need to create a function and use a `@tool` decorator.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now, this function has `name` and `description` parameters that will be passed
    to LLMs.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: These parameters will be used to create an OpenAI function specification. Let’s
    convert our tool to an OpenAI function.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We got the following JSON as the result. It outlines the structure, but field
    descriptions are missing.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can use Pydantic to specify a schema for the arguments.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, if we convert a new version to the OpenAI function specification, it will
    include argument descriptions. It’s much better since we could share all the needed
    context with the model.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: So, we’ve defined the tool that LLM will be able to use. Let’s try it in practice.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Using a tool in practice
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s define a chain and pass our tool to the function. Then, we could test
    it on a user request.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We got a function call with the correct arguments, so it’s working.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To have a more convenient way to work with the output, we can use`OpenAIFunctionsAgentOutputParser`.
    Let’s add it to our chain.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now, we got output in a more structured way, and we could easily retrieve arguments
    for our tool as `result.tool_input` .
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: So, we could execute the function as the LLM requested like this.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: If we want to get the final answer from the model, we need to pass the function
    execution result back. To do it, we need to define a message list to pass to the
    model observations.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Then, we need to add the observation to our `observations` variable. We could
    use `format_to_openai_functions` function to format our results in an expected
    way for the model.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As a result, we got such a message that the LLM can understand.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Let’s invoke our chain one more time, passing the function execution result
    as an observation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now, we got the final result from the model, which sounds reasonable.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: If we were working with vanilla OpenAI Chat Completion API, we could just add
    another message with role = tool . You can find a detailed example [here](https://platform.openai.com/docs/guides/function-calling).
  id: totrans-138
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If we switch on debug, we can see the exact prompt that was passed to OpenAI
    API.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: To switch on LangChain debug, execute the following code and invoke your chain
    to see what is going on under the hood.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We’ve tried to work with one tool, but let’s extend our toolkit and see how
    LLM could handle it.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'Routing: using multiple tools'
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s add a couple more tools to our analyst’s toolkit:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: get monthly active users
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: using Wikipedia.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, let’s define a dummy function to calculate the audience with filters
    by month and city. We will again use Pydantic to specify the input arguments for
    our function.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Then, let’s use [the wikipedia](https://pypi.org/project/wikipedia/) Python
    package to allow model query Wikipedia.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Let’s define a dictionary with all the functions our model knows now. This dictionary
    will help us to do routing later.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'I’ve made a couple of changes to our previous setup:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: I tweaked the system prompt a bit to force LLM to consult with Wikipedia if
    it needs some basic knowledge.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I’ve changed the model to GPT 4 because it’s better for handling tasks requiring
    reasoning.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我已经将模型更改为 GPT 4，因为它更适合处理需要推理的任务。
- en: '[PRE31]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can invoke our chain with all the functions. Let’s start with a pretty straightforward
    query.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以调用我们的链条中的所有函数。让我们从一个非常直接的查询开始。
- en: '[PRE32]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We got in the result function call for `get_monthly_active_users` with input
    parameters — `{''month'': ''2023–04–01'', ''city'': ''Berlin''}` , which looks
    correct. The model was able to find the right tool and solve the task.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '我们得到的结果是对 `get_monthly_active_users` 的函数调用，输入参数为 `{''month'': ''2023–04–01'',
    ''city'': ''Berlin''}`，这看起来是正确的。模型能够找到正确的工具并解决任务。'
- en: Let’s try to make task a bit more complex.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试将任务变得更复杂一些。
- en: '[PRE33]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s pause for a minute and think how we would like the model to reason. It’s
    evident that there’s not enough information for the model to answer straight away,
    so it needs to make a bunch of function calls:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们停下来想一想我们希望模型如何推理。显然，模型没有足够的信息来直接回答，所以它需要进行一系列函数调用：
- en: call Wikipedia to get the capital of Germany
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用 Wikipedia 获取德国的首都
- en: call the `get_monthly_active_users` function twice to get MAU for April and
    May
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用 `get_monthly_active_users` 函数两次，以获取 4 月和 5 月的 MAU
- en: call `percentage_difference` to calculate the difference between metrics.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用 `percentage_difference` 以计算指标之间的差异。
- en: It looks pretty complex. Let’s see whether ChatGPT would be able to handle this
    question.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来相当复杂。让我们看看 ChatGPT 是否能够处理这个问题。
- en: 'For the first call, LLM returned back a function call to Wikipedia with the
    following params — `{''term'': ''capital of Germany''}`. So far, it’s following
    our plan.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '在第一次调用中，LLM 返回了一个对 Wikipedia 的函数调用，参数为 `{''term'': ''capital of Germany''}`。到目前为止，它遵循了我们的计划。'
- en: Let’s provide the observation and see what the next steps will be.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提供观察结果，看看接下来的步骤会是什么。
- en: '[PRE34]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The model wants to execute `get_monthly_active_users` with arguments `{''month'':
    ''2023–04–01'', ''city'': ''Berlin''}`. Let’s do it and return the information
    to the model once again.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '模型想要执行 `get_monthly_active_users`，参数为 `{''month'': ''2023–04–01'', ''city'':
    ''Berlin''}`。让我们执行它，并再次将信息返回给模型。'
- en: '[PRE35]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then, the model requests to call `get_monthly_active_users` again with arguments
    `{''month'': ''2023–05–01'', ''city'': ''Berlin''}`. So far, it’s doing an excellent
    job. Let’s follow its logic.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '然后，模型请求再次调用 `get_monthly_active_users`，参数为 `{''month'': ''2023–05–01'', ''city'':
    ''Berlin''}`。到目前为止，它表现得非常出色。让我们跟随它的逻辑。'
- en: '[PRE36]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The subsequent result is a function call for percentage_difference with the
    following arguments `{''metric1'': 168, ''metric2'': 1046}`. Let’s calculate observation
    and invoke our chain one more time. Hopefully, it will be the last step.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '随后的结果是一个对 percentage_difference 的函数调用，参数为 `{''metric1'': 168, ''metric2'':
    1046}`。让我们计算观察结果并再次调用我们的链条。希望这将是最后一步。'
- en: '[PRE37]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In the end, we got the following response from the model: `The number of users
    from Berlin, the capital of Germany, increased by approximately 523.27% between
    April and May 2023.`'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们从模型中得到以下响应：`德国首都柏林的用户数量在 2023 年 4 月到 5 月间增加了约 523.27%。`
- en: Here’s the complete scheme of the LLM calls for this question.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这是针对这个问题的 LLM 调用的完整方案。
- en: '![](../Images/227c76d1bfd7066c2b81cb64329fb0e6.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/227c76d1bfd7066c2b81cb64329fb0e6.png)'
- en: Illustration by author
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 作者插图
- en: In the above example, we triggered subsequent calls one by one manually, but
    it can be easily automated.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，我们手动逐一触发了后续调用，但这可以很容易地自动化。
- en: It’s a fantastic result, and we were able to see how LLMs can do reasoning and
    utilize multiple tools. It took model 5 steps to achieve the result, but it followed
    the plan we outlined initially, so it was a pretty logical path. However, if you
    plan to use LLMs in production, keep in mind that it might make mistakes and introduce
    evaluation and quality assurance processes.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很棒的结果，我们能够看到 LLM 如何进行推理并利用多种工具。模型用了 5 步达成结果，但它遵循了我们最初制定的计划，因此这是一个相当合乎逻辑的路径。然而，如果你计划将
    LLM 用于生产环境，请记住，它可能会犯错误，并引入评估和质量保证流程。
- en: You can find the full code on [GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/analyst_agent/functions_how_to.ipynb).
  id: totrans-183
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以在 [GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/analyst_agent/functions_how_to.ipynb)
    上找到完整的代码。
- en: Summary
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This article taught us how to empower LLMs with external tools using OpenAI
    functions. We’ve examined two use cases: extraction to get structured output and
    routing to use external information for questions. The final result inspires me
    since LLM could answer pretty complex questions using three different tools.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 本文教会了我们如何利用OpenAI函数为LLMs提供外部工具。我们已经考察了两个使用案例：提取以获得结构化输出和路由以使用外部信息回答问题。最终结果让我感到鼓舞，因为LLM能够使用三种不同的工具回答相当复杂的问题。
- en: Let’s return to the initial question of whether LLMs can replace data analysts.
    Our current prototype is basic and far from the junior analysts’ capabilities,
    but it’s only the beginning. Stay tuned! We will dive deeper into the different
    approaches to LLM agents. Next time, we will try to create an agent that can access
    the database and answer basic questions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 回到最初的问题，LLMs是否能取代数据分析师。我们当前的原型仍然很基础，远未达到初级分析师的能力，但这只是开始。敬请关注！我们将深入探讨LLM代理的不同方法。下次，我们将尝试创建一个能够访问数据库并回答基本问题的代理。
- en: Reference
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: This article is inspired by the [“Functions, Tools and Agents with LangChain”](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)
    course from DeepLearning.AI
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的灵感来源于DeepLearning.AI的[“LangChain中的函数、工具和代理”](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/)课程。
