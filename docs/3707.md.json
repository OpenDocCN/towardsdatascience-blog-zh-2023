["```py\nimport requests\nfrom bs4 import BeautifulSoup\nurl = \"https://medium.com/llamaindex-blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83\"\nsoup = BeautifulSoup(requests.get(url).text, 'html.parser')\nfiltered_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'p'])\nfiltered_tags[:14]\n```", "```py\n<p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb fc\" data-testid=\"headerSignUpButton\" href=\"https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fblog.llamaindex.ai%2Fboosting-rag-picking-the-best-embedding-reranker-models-42d079022e83&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign up</a></span></p>\n<p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerSignInButton\" href=\"https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fblog.llamaindex.ai%2Fboosting-rag-picking-the-best-embedding-reranker-models-42d079022e83&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign in</a></span></p>\n<p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb fc\" data-testid=\"headerSignUpButton\" href=\"https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fblog.llamaindex.ai%2Fboosting-rag-picking-the-best-embedding-reranker-models-42d079022e83&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign up</a></span></p>\n<p class=\"be b dw dx dy dz ea eb ec ed ee ef dt\"><span><a class=\"af ag ah ai aj ak al am an ao ap aq ar as at\" data-testid=\"headerSignInButton\" href=\"https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fblog.llamaindex.ai%2Fboosting-rag-picking-the-best-embedding-reranker-models-42d079022e83&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------\" rel=\"noopener follow\">Sign in</a></span></p>\n<h1 class=\"pw-post-title gp gq gr be gs gt gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr bj\" data-testid=\"storyTitle\" id=\"f2a9\">Boosting RAG: Picking the Best Embedding &amp; Reranker models</h1>\n<p class=\"be b iq ir bj\"><a class=\"af ag ah ai aj ak al am an ao ap aq ar is\" data-testid=\"authorName\" href=\"https://ravidesetty.medium.com/?source=post_page-----42d079022e83--------------------------------\" rel=\"noopener follow\">Ravi Theja</a></p>\n<p class=\"be b iq ir dt\"><span><a class=\"iv iw ah ai aj ak al am an ao ap aq ar eu ix iy\" href=\"https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F60738cbbc7df&amp;operation=register&amp;redirect=https%3A%2F%2Fblog.llamaindex.ai%2Fboosting-rag-picking-the-best-embedding-reranker-models-42d079022e83&amp;user=Ravi+Theja&amp;userId=60738cbbc7df&amp;source=post_page-60738cbbc7df----42d079022e83---------------------post_header-----------\" rel=\"noopener follow\">Follow</a></span></p>\n<p class=\"be b bf z jh ji jj jk jl jm jn jo bj\">LlamaIndex Blog</p>\n<p class=\"be b du z dt\"><span class=\"lq\">--</span></p>\n<p class=\"be b du z dt\"><span class=\"pw-responses-count lr ls\">5</span></p>\n<p class=\"be b bf z dt\">Listen</p>\n<p class=\"be b bf z dt\">Share</p>\n<p class=\"pw-post-body-paragraph nl nm gr nn b no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh oi gk bj\" id=\"4130\"><strong class=\"nn gs\">UPDATE</strong>: The pooling method for the Jina AI embeddings has been adjusted to use mean pooling, and the results have been updated accordingly. Notably, the <code class=\"cw oj ok ol om b\">JinaAI-v2-base-en</code> with <code class=\"cw oj ok ol om b\">bge-reranker-large</code>now exhibits a Hit Rate of 0.938202 and an MRR (Mean Reciprocal Rank) of 0.868539 and with<code class=\"cw oj ok ol om b\">CohereRerank</code> exhibits a Hit Rate of 0.932584, and an MRR of 0.873689.</p>\n<p class=\"pw-post-body-paragraph nl nm gr nn b no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh oi gk bj\" id=\"8267\">When building a Retrieval Augmented Generation (RAG) pipeline, one key component is the Retriever. We have a variety of embedding models to choose from, including OpenAI, CohereAI, and open-source sentence transformers. Additionally, there are several rerankers available from CohereAI and sentence transformers.</p>\n```", "```py\nfrom PyPDF2 import PdfFileReader\npdf = PdfFileReader(open('data/Boosting_RAG_Picking_the_Best_Embedding_&_Reranker_models.pdf','rb'))\npdf.getPage(0).extractText()\n```", "```py\n'Boosting RAG: Picking the Best\\nEmbedding & Reranker models\\n\nRavi Theja·Follow\\nPublished inLlamaIndex Blog·7 min read·Nov 3\\n\n389 5\\nUPDATE: The pooling method for the Jina AI embeddings has been adjusted\\n\nto use mean pooling, and the results have been updated accordingly.\\n\nNotably, the JinaAI-v2-base-en with bge-reranker-largenow exhibits a Hit\\n\nRate of 0.938202 and an MRR (Mean Reciprocal Rank) of 0.868539 and\\n\nwithCohereRerank exhibits a Hit Rate of 0.932584, and an MRR of 0.873689.\\n\nWhen building a Retrieval Augmented Generation (RAG) pipeline, one key\\n\ncomponent is the Retriever. We have a variety of embedding models to\\n\nchoose from, including OpenAI, CohereAI, and open-source sentence\\n\nOpen in app\\nSearch Write\\n'\n```", "```py\ndef format_html(tags):\n    formatted_text = \"\"\n    title = \"\"\n\n    for tag in tags:\n        if 'pw-post-title' in tag.get('class', []):\n            title = tag.get_text()\n        elif tag.name == 'p' and 'pw-post-body-paragraph' in tag.get('class', []):\n            formatted_text += \"\\n\"+ tag.get_text()\n        elif tag.name in ['h1', 'h2', 'h3', 'h4']:\n            formatted_text += \"\\n\\n\" + tag.get_text()\n\n    return {title: formatted_text}\n\nformatted_document = format_html(filtered_tags)\n```", "```py\n{'Boosting RAG: Picking the Best Embedding & Reranker models': \"\\n\nUPDATE: The pooling method for the Jina AI embeddings has been adjusted to use mean pooling, and the results have been updated accordingly. Notably, the JinaAI-v2-base-en with bge-reranker-largenow exhibits a Hit Rate of 0.938202 and an MRR (Mean Reciprocal Rank) of 0.868539 and withCohereRerank exhibits a Hit Rate of 0.932584, and an MRR of 0.873689.\\n\nWhen building a Retrieval Augmented Generation (RAG) pipeline, one key component is the Retriever. We have a variety of embedding models to choose from, including OpenAI, CohereAI, and open-source sentence transformers. Additionally, there are several rerankers available from CohereAI and sentence transformers.\\n\nBut with all these options, how do we determine the best mix for top-notch retrieval performance? How do we know which embedding model fits our data best? Or which reranker boosts our results the most?\\n\nIn this blog post, we’ll use the Retrieval Evaluation module from LlamaIndex to swiftly determine the best combination of embedding and reranker models. Let's dive in!\\n\nLet’s first start with understanding the metrics available in Retrieval Evaluation\\n\\n\n... }\n```", "```py\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"intfloat/e5-base-v2\")\n\ndef token_length_function(text_input):\n  return len(tokenizer.encode(text_input, add_special_tokens=False))\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    # Set a really small chunk size, just to show.\n    chunk_size = 128,\n    chunk_overlap  = 0,\n    length_function = token_length_function,\n    separators = [\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \"]\n)\n\nsplit_texts = text_splitter(formatted_document['Boosting RAG: Picking the Best Embedding & Reranker models'])\n```", "```py\nToken of text: 111 \n\nUPDATE: The pooling method for the Jina AI embeddings has been adjusted to use mean pooling, and the results have been updated accordingly. Notably, the JinaAI-v2-base-en with bge-reranker-largenow exhibits a Hit Rate of 0.938202 and an MRR (Mean Reciprocal Rank) of 0.868539 and withCohereRerank exhibits a Hit Rate of 0.932584, and an MRR of 0.873689.\n\n-----------\n\nToken of text: 112 \n\nWhen building a Retrieval Augmented Generation (RAG) pipeline, one key component is the Retriever. We have a variety of embedding models to choose from, including OpenAI, CohereAI, and open-source sentence transformers. Additionally, there are several rerankers available from CohereAI and sentence transformers.\nBut with all these options, how do we determine the best mix for top-notch retrieval performance? How do we know which embedding model fits our data best? Or which reranker boosts our results the most?\n\n-----------\n\nToken of text: 54 \n\nIn this blog post, we’ll use the Retrieval Evaluation module from LlamaIndex to swiftly determine the best combination of embedding and reranker models. Let's dive in!\nLet’s first start with understanding the metrics available in Retrieval Evaluation\n```", "```py\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('intfloat/e5-large')\n\nprepended_split_texts = [\"passage: \" + text for text in split_texts]\nembeddings = model.encode(prepended_split_texts, normalize_embeddings=True)\n\nprint(f'We now have {len(embeddings)} embeddings, each of size {len(embeddings[0])}')\n```", "```py\nWe now have 12 embeddings, each of size 1024\n```"]