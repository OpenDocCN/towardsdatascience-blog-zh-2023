["```py\nview = my_dataset.match(\n        F(\"ground_truth.detections.label\").contains([\"cat\"])\n    ).filter_labels(\n        \"predictions\", \n        F(\"label\") == \"dog\"\n    ).take(10)\n```", "```py\nimport fiftyone as fo\nimport fiftyone.zoo as foz\n\n# Load the dataset\ndataset = foz.load_zoo_dataset(\n    \"open-images-v6\",\n    split=\"validation\",\n    label_types=[\"detections\"],\n    classes=[\"Dog\"],\n)\n\n# Create a view stage that filters out images without any dog detections\nview_stage = fo.ViewStage(\"detections\", fo.FilterField(\"detections\", \"label\", \"Dog\"))\n\n# Apply the view stage to the dataset\ndataset = dataset.add_stage(view_stage)\n\n# View the dataset\nsession = fo.launch_app(dataset)\n```", "```py\nimport fiftyone as fo\nimport fiftyone.zoo as foz\n\n# Load your dataset\ndataset = fo.load_dataset(\"your_dataset_name\")\n\n# Define your false positive detection model\nmodel = foz.load_zoo_model(\"your_model_name\")\n\n# Define your pipeline\npipeline = [\n    {\"$set\": {\"predictions\": {\"$predict\": model}}},\n    {\"$match\": {\"predictions.mistakes.false_positive\": True}},\n    {\"$group\": {\"_id\": \"$filepath\"}},\n    {\"$count\": \"num_images\"},\n    {\"$sort\": {\"num_images\": -1}},\n]\n\n# Run your pipeline and display the results in a view stage\nview = dataset.aggregate(pipeline).limit(10).display()\n```", "```py\nYour task is to convert input natural language queries into Python code to generate ViewStages for the computer vision library FiftyOne.\nHere are some rules:\n- Avoid all header code like importing packages, and all footer code like saving the dataset or launching the FiftyOne App.\n- Just give me the final Python code, no intermediate code snippets or explanation.\n- always assume the dataset is stored in the Python variable `dataset`\n- you can use the following ViewStages to generate your response, in any combination: exclude, exclude_by, exclude_fields, exclude_frames, …\n```", "```py\nimages_with_fp = dataset.match(F(\"eval_fp\")>0)\n```", "```py\n- When a user asks for the most \"unique\" images, they are referring to the \"uniqueness\" field stored on samples.\n- When a user asks for the most \"wrong\" or \"mistaken\" images, they are referring to the \"mistakenness\" field stored on samples.\n- If a user doesn't specify a label field, e.g. \"predictions\" or \"ground_truth\" to which to apply certain operations, assume they mean \"ground_truth\" if a ground_truth field exists on the data.\n```", "```py\n- Object detection bounding boxes are in [top-left-x, top-left-y, width, height] format, all relative to the image width and height, in the range [0, 1]\n- possible label types include Classification, Classifications, Detection, Detections, Segmentation, Keypoint, Regression, and Polylines\n```", "```py\nA) \"Filepath starts with '/Users'\"\nB) `dataset.match(F(\"filepath\").starts_with(\"/Users\"))`\n\nA) \"Predictions with confidence > 0.95\"\nB) `dataset.filter_labels(\"predictions\", F(\"confidence\") > 0.95)`\n\n…\n```", "```py\nview = dataset.sort_by(\"uniqueness\")\n```", "```py\nfrom fiftyone import ViewField as F\nview = dataset.match(F(\"uniqueness\") > 0.8)\n```", "```py\nview = dataset.select_fields(\"uniqueness\")\n```", "```py\nQuery: \"most unique images with a false positive\"\nAlgorithms used: [\"uniqueness\", \"evaluation\"]\n```", "```py\n## query A:\n\"show me the 10 most similar images to image 1 with CLIP\"\n\n## query B:\n\"show me the 10 most similar images to image 1 with InceptionV3\"\n```", "```py\nQuery: \"Exclude model2 predictions from all samples\"\nAvailable fields: \"[id: string, filepath: string, tags: list, ground_truth: Detections, model1_predictions: Detections, model2_predictions: Detections, model3_predictions: Detections]\"\nRequired fields: \"[model2_predictions]\"\n```", "```py\nquery: \"20 random images with a table\"\n## becomes:\nquery: \"20 random images with a dining table\"\n```"]