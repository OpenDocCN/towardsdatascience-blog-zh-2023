- en: How to Train Time Series Forecasting Faster using Ray, part 3 of 3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä½¿ç”¨RayåŠ é€Ÿæ—¶é—´åºåˆ—é¢„æµ‹çš„è®­ç»ƒï¼Œç¬¬3éƒ¨åˆ†ï¼Œå…±3éƒ¨åˆ†
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/faster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774?source=collection_archive---------10-----------------------#2023-01-24](https://towardsdatascience.com/faster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774?source=collection_archive---------10-----------------------#2023-01-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/faster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774?source=collection_archive---------10-----------------------#2023-01-24](https://towardsdatascience.com/faster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774?source=collection_archive---------10-----------------------#2023-01-24)
- en: Train many models faster using distributed computing with Ray and Ray AIR
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Rayå’ŒRay AIRé€šè¿‡åˆ†å¸ƒå¼è®¡ç®—æ›´å¿«åœ°è®­ç»ƒå¤šä¸ªæ¨¡å‹
- en: '[](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)[![Christy
    Bergman](../Images/b8431b925cfe7bd0d3a035761fd1e7f8.png)](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)[](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------)
    [Christy Bergman](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)[![Christy
    Bergman](../Images/b8431b925cfe7bd0d3a035761fd1e7f8.png)](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)[](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------)
    [Christy Bergman](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff18ab4254b46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&user=Christy+Bergman&userId=f18ab4254b46&source=post_page-f18ab4254b46----632c96974774---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------)
    Â·11 min readÂ·Jan 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F632c96974774&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&user=Christy+Bergman&userId=f18ab4254b46&source=-----632c96974774---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff18ab4254b46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&user=Christy+Bergman&userId=f18ab4254b46&source=post_page-f18ab4254b46----632c96974774---------------------post_header-----------)
    å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------)
    Â·11åˆ†é’Ÿé˜…è¯»Â·2023å¹´1æœˆ24æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F632c96974774&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&user=Christy+Bergman&userId=f18ab4254b46&source=-----632c96974774---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F632c96974774&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&source=-----632c96974774---------------------bookmark_footer-----------)![](../Images/0b4cdf6bfa4d1843765d0442ef94d0b7.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F632c96974774&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&source=-----632c96974774---------------------bookmark_footer-----------)![](../Images/0b4cdf6bfa4d1843765d0442ef94d0b7.png)'
- en: Image by [StableDiffusion](https://stablediffusionweb.com/#demo), drawn on Jan
    5, 2022, with the query â€œdraw an image representing many different deep neural
    network time series models training at once cy twombly styleâ€.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ç‰‡ç”± [StableDiffusion](https://stablediffusionweb.com/#demo) ç»˜åˆ¶ï¼Œæ—¥æœŸä¸º2022å¹´1æœˆ5æ—¥ï¼ŒæŸ¥è¯¢å†…å®¹ä¸ºâ€œç»˜åˆ¶ä¸€å¹…å›¾åƒï¼Œå±•ç¤ºå¤šç§ä¸åŒçš„æ·±åº¦ç¥ç»ç½‘ç»œæ—¶é—´åºåˆ—æ¨¡å‹åŒæ—¶è®­ç»ƒçš„æ ·å­ï¼Œé£æ ¼ç±»ä¼¼Cy
    Twomblyâ€ã€‚
- en: Introduction / Motivation
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»‹ç» / åŠ¨æœº
- en: 'Even in the current age of Generative AI (Stable Diffusion, ChatGPT) and LLM
    (large language models), **Time Series Forecasting is still a fundamental part
    of running any business that depends on a supply chain or resources.** For example
    it can be used in:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿åœ¨å½“å‰ç”Ÿæˆå¼ AIï¼ˆå¦‚ç¨³å®šæ‰©æ•£ã€ChatGPTï¼‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ä»£ï¼Œ**æ—¶é—´åºåˆ—é¢„æµ‹ä»ç„¶æ˜¯ä»»ä½•ä¾èµ–ä¾›åº”é“¾æˆ–èµ„æºçš„ä¸šåŠ¡çš„åŸºç¡€éƒ¨åˆ†ã€‚** ä¾‹å¦‚ï¼Œå®ƒå¯ä»¥ç”¨äºï¼š
- en: '[Fulfillment prediction](https://www.youtube.com/watch?v=3t26ucTy0Rs) for inventory
    management by geography.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[æ ¹æ®åœ°ç†ä½ç½®è¿›è¡Œåº“å­˜ç®¡ç†çš„å±¥è¡Œé¢„æµ‹](https://www.youtube.com/watch?v=3t26ucTy0Rs)ã€‚'
- en: '[Demand forecasting](https://www.anyscale.com/blog/how-anastasia-implements-ray-and-anyscale-to-speed-up-ml-processes-9x)
    different products by product category.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ä¸åŒäº§å“ç±»åˆ«çš„éœ€æ±‚é¢„æµ‹](https://www.anyscale.com/blog/how-anastasia-implements-ray-and-anyscale-to-speed-up-ml-processes-9x)ã€‚'
- en: '[Utilization prediction](https://medium.com/kocdigital/using-ray-for-time-series-forecasting-at-scale-3355c9e4e28c)
    for datacenter provisioning by resource.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[èµ„æºåˆ©ç”¨é¢„æµ‹](https://medium.com/kocdigital/using-ray-for-time-series-forecasting-at-scale-3355c9e4e28c)
    ç”¨äºæ•°æ®ä¸­å¿ƒèµ„æºé…ç½®ã€‚'
- en: '**One thing all these use cases have in common is** [**training many models
    on different segments of data**](https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray)**.**
    Training, tuning, and deploying thousands of machine learning models in parallel
    using distributed computing can be a challenging task! Typical time series modeling
    software is not distributed by itself.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ‰€æœ‰è¿™äº›ç”¨ä¾‹çš„å…±åŒç‚¹æ˜¯** [**åœ¨ä¸åŒæ•°æ®ç‰‡æ®µä¸Šè®­ç»ƒå¤šä¸ªæ¨¡å‹**](https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray)**ã€‚**
    ä½¿ç”¨åˆ†å¸ƒå¼è®¡ç®—å¹¶è¡Œè®­ç»ƒã€è°ƒä¼˜å’Œéƒ¨ç½²æˆåƒä¸Šä¸‡çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¯èƒ½æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼ å…¸å‹çš„æ—¶é—´åºåˆ—å»ºæ¨¡è½¯ä»¶æœ¬èº«å¹¶ä¸å…·å¤‡åˆ†å¸ƒå¼åŠŸèƒ½ã€‚'
- en: '**This blog will show my tips to get started converting your forecasting workloads
    to distributed computing.** Iâ€™ll use the newest [Ray v2 APIs](https://docs.ray.io/en/latest/)
    with ARIMA using [statsforecast](https://github.com/Nixtla/statsforecast), [Prophet](https://facebook.github.io/prophet/),
    and [PyTorch Forecasting](https://pytorch-forecasting.readthedocs.io/en/stable/index.html)
    libraries. For the data, I will use the popular [NYC Taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),
    which contains historical taxi pickups by timestamp and location in NYC.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**æœ¬åšå®¢å°†å±•ç¤ºæˆ‘å¼€å§‹å°†é¢„æµ‹å·¥ä½œè´Ÿè½½è½¬æ¢ä¸ºåˆ†å¸ƒå¼è®¡ç®—çš„æŠ€å·§ã€‚** æˆ‘å°†ä½¿ç”¨æœ€æ–°çš„ [Ray v2 API](https://docs.ray.io/en/latest/)ï¼Œç»“åˆ
    ARIMA ä½¿ç”¨ [statsforecast](https://github.com/Nixtla/statsforecast)ã€[Prophet](https://facebook.github.io/prophet/)
    å’Œ [PyTorch Forecasting](https://pytorch-forecasting.readthedocs.io/en/stable/index.html)
    åº“ã€‚æ•°æ®æ–¹é¢ï¼Œæˆ‘å°†ä½¿ç”¨æµè¡Œçš„ [NYC Taxi æ•°æ®é›†](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)ï¼Œè¯¥æ•°æ®é›†åŒ…å«æŒ‰æ—¶é—´æˆ³å’Œåœ°ç‚¹è®°å½•çš„å†å²å‡ºç§Ÿè½¦æ¥é€ä¿¡æ¯ã€‚'
- en: Ray is an open-source framework for scaling AI workloads using distributed computing.
    For an overview of Ray, check out the [Ray documentation](https://docs.ray.io/en/latest/)
    or this [introductory blog post](/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Ray æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºé€šè¿‡åˆ†å¸ƒå¼è®¡ç®—æ‰©å±• AI å·¥ä½œè´Ÿè½½ã€‚æœ‰å…³ Ray çš„æ¦‚è¿°ï¼Œè¯·æŸ¥çœ‹ [Ray æ–‡æ¡£](https://docs.ray.io/en/latest/)
    æˆ–è¿™ç¯‡ [ä»‹ç»åšå®¢æ–‡ç« ](/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8)ã€‚
- en: '![](../Images/936ddd06d94b1c8950dcf87f360c7154.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/936ddd06d94b1c8950dcf87f360c7154.png)'
- en: '[Ray â€œAIR](https://docs.ray.io/en/latest/ray-air/getting-started.html)â€ (AI
    Runtime), available since Ray 2.0, includes [Ray Data](https://docs.ray.io/en/latest/data/dataset.html),
    [Ray Train](https://docs.ray.io/en/latest/train/train.html), [Ray Tune](https://docs.ray.io/en/latest/tune/index.html),
    [RLlib](https://docs.ray.io/en/latest/rllib/index.html), and [Ray Serve](https://docs.ray.io/en/latest/serve/index.html).
    Image by Author.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ray â€œAIR](https://docs.ray.io/en/latest/ray-air/getting-started.html)â€ï¼ˆAI
    Runtimeï¼‰ï¼Œè‡ª Ray 2.0 èµ·æä¾›ï¼ŒåŒ…æ‹¬ [Ray Data](https://docs.ray.io/en/latest/data/dataset.html)ã€[Ray
    Train](https://docs.ray.io/en/latest/train/train.html)ã€[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)ã€[RLlib](https://docs.ray.io/en/latest/rllib/index.html)
    å’Œ [Ray Serve](https://docs.ray.io/en/latest/serve/index.html)ã€‚å›¾ç‰‡æ¥æºäºä½œè€…ã€‚'
- en: 'This blog is organized in 4 sections:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬åšå®¢åˆ†ä¸º 4 ä¸ªéƒ¨åˆ†ï¼š
- en: Multi-model distributed training using Ray Core Multiprocessing.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Ray Core å¤šè¿›ç¨‹è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒã€‚
- en: Multi-model distributed tuning using Ray AIR.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Ray AIR è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜ã€‚
- en: Multi-model distributed tuning fewer, larger models using Ray AIR.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Ray AIR è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜ï¼Œé’ˆå¯¹æ›´å°‘ä½†æ›´å¤§çš„æ¨¡å‹ã€‚
- en: Multi-model distributed deployment using Ray AIR and Ray Serve.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ Ray AIR å’Œ Ray Serve è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼éƒ¨ç½²ã€‚
- en: 'Section 1: Multi-Model Distributed Training using Ray Core Multiprocessing'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€éƒ¨åˆ†ï¼šä½¿ç”¨ Ray Core å¤šè¿›ç¨‹è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒ
- en: Back in November 2021, I wrote a [blog article](https://medium.com/towards-data-science/scaling-time-series-forecasting-with-ray-arima-and-prophet-e6c856e605ee)
    demonstrating how to train many forecast models (either ARIMA or Prophet) in parallel
    using Ray Core on AWS cloud. **Since then,** [**Ray Multiprocessing**](https://docs.ray.io/en/latest/ray-more-libs/multiprocessing.html)
    **is a big improvement that makes things easier than Ray Core APIs.**
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å›åˆ°2021å¹´11æœˆï¼Œæˆ‘å†™äº†ä¸€ç¯‡ [åšå®¢æ–‡ç« ](https://medium.com/towards-data-science/scaling-time-series-forecasting-with-ray-arima-and-prophet-e6c856e605ee)
    æ¼”ç¤ºå¦‚ä½•åœ¨ AWS äº‘ä¸Šä½¿ç”¨ Ray Core å¹¶è¡Œè®­ç»ƒå¤šä¸ªé¢„æµ‹æ¨¡å‹ï¼ˆæ— è®ºæ˜¯ ARIMA è¿˜æ˜¯ Prophetï¼‰ã€‚**ä»é‚£æ—¶èµ·ï¼Œ** [**Ray å¤šè¿›ç¨‹**](https://docs.ray.io/en/latest/ray-more-libs/multiprocessing.html)
    **æ˜¯ä¸€ä¸ªå·¨å¤§çš„æ”¹è¿›ï¼Œä½¿äº‹æƒ…æ¯” Ray Core API æ›´åŠ ç®€å•ã€‚**
- en: 'Below is the code outline. The full, updated code is on [my github](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/train_prophet_blog.ipynb).
    First, letâ€™s start with a couple imports:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯ä»£ç å¤§çº²ã€‚å®Œæ•´çš„æ›´æ–°ä»£ç åœ¨ [æˆ‘çš„ GitHub](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/train_prophet_blog.ipynb)
    ä¸Šã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»å‡ ä¸ªå¯¼å…¥å¼€å§‹ï¼š
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, letâ€™s define Python functions to preprocess data, train and evaluate a
    model. To get to the distributed computing concepts quicker, we are going to pretend
    the time series data is already prepared and split into separate files per desired
    model.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å®šä¹‰ Python å‡½æ•°æ¥é¢„å¤„ç†æ•°æ®ã€è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚ä¸ºäº†æ›´å¿«åœ°äº†è§£åˆ†å¸ƒå¼è®¡ç®—æ¦‚å¿µï¼Œæˆ‘ä»¬å°†å‡è®¾æ—¶é—´åºåˆ—æ•°æ®å·²ç»å‡†å¤‡å¥½å¹¶æ ¹æ®æ‰€éœ€æ¨¡å‹æ‹†åˆ†ä¸ºä¸åŒçš„æ–‡ä»¶ã€‚
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We could parallelize this directly using Ray core API calls`[ray.remote](https://docs.ray.io/en/latest/ray-core/walkthrough.html)`,
    but Rayâ€™s [multiprocessing library](https://docs.ray.io/en/latest/ray-more-libs/multiprocessing.html),
    one of Rayâ€™s distributed libraries, makes this easier.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ Ray æ ¸å¿ƒ API è°ƒç”¨ `[ray.remote](https://docs.ray.io/en/latest/ray-core/walkthrough.html)`
    è¿›è¡Œå¹¶è¡ŒåŒ–ï¼Œä½† Ray çš„ [å¤šè¿›ç¨‹åº“](https://docs.ray.io/en/latest/ray-more-libs/multiprocessing.html)
    ä½œä¸º Ray çš„åˆ†å¸ƒå¼åº“ä¹‹ä¸€ï¼Œä½¿è¿™å˜å¾—æ›´ç®€å•ã€‚
- en: Below, wrapping the call to `pool` with `tqdm` gives a nice progress bar to
    monitor progress. Internally, Ray dispatches tasks to workers in the Ray cluster,
    which automatically handles issues such as fault tolerance and batching optimizations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢ï¼Œå°†å¯¹ `pool` çš„è°ƒç”¨åŒ…è£…åœ¨ `tqdm` ä¸­ï¼Œå¯ä»¥è·å¾—ä¸€ä¸ªå¾ˆå¥½çš„è¿›åº¦æ¡æ¥ç›‘æ§è¿›åº¦ã€‚åœ¨å†…éƒ¨ï¼ŒRay å°†ä»»åŠ¡åˆ†é…ç»™ Ray é›†ç¾¤ä¸­çš„å·¥ä½œèŠ‚ç‚¹ï¼Œè¿™è‡ªåŠ¨å¤„ç†å¦‚å®¹é”™å’Œæ‰¹å¤„ç†ä¼˜åŒ–ç­‰é—®é¢˜ã€‚
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/fdca6909d17c7ae9f3020f481ada53d7.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fdca6909d17c7ae9f3020f481ada53d7.png)'
- en: Screenshot while running the above example on my MacBook pro laptop with 8 CPU.
    Time to run Ray Multiprocessing was about a half-minute, which was *3.5x, or 300.0%
    speedup over serial Python. More speedup would be possible with a bigger cluster
    and/or bigger data. Image by Author.*
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘çš„ MacBook Pro ç¬”è®°æœ¬ç”µè„‘ï¼ˆé…å¤‡ 8 ä¸ª CPUï¼‰ä¸Šè¿è¡Œä¸Šè¿°ç¤ºä¾‹æ—¶çš„æˆªå›¾ã€‚Ray å¤šè¿›ç¨‹çš„è¿è¡Œæ—¶é—´å¤§çº¦ä¸ºåŠåˆ†é’Ÿï¼Œæ¯”ä¸²è¡Œ Python å¿«
    *3.5 å€ï¼Œå³ 300.0% çš„åŠ é€Ÿã€‚ä½¿ç”¨æ›´å¤§çš„é›†ç¾¤å’Œ/æˆ–æ›´å¤§çš„æ•°æ®å¯ä»¥è·å¾—æ›´å¤šåŠ é€Ÿã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚*
- en: Above, we can see the Ray job took less than 1 minute to train 12 models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šé¢ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° Ray ä½œä¸šåœ¨ä¸åˆ° 1 åˆ†é’Ÿçš„æ—¶é—´å†…è®­ç»ƒäº† 12 ä¸ªæ¨¡å‹ã€‚
- en: 'Section 2: Multi-Model Distributed Tuning using Ray AIR'
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ 2 éƒ¨åˆ†ï¼šä½¿ç”¨ Ray AIR è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜
- en: The astute reader may have noticed, in the above section, Ray Multiprocessing
    required the data to already be organized into one file per model you want to
    train. **But what if your data isnâ€™t already organized by model?** With Ray AIR,
    you can preprocess data in the same pipeline while training different models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ç²¾æ˜çš„è¯»è€…å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œåœ¨ä¸Šè¿°éƒ¨åˆ†ä¸­ï¼ŒRay å¤šè¿›ç¨‹è¦æ±‚æ•°æ®å·²ç»æŒ‰æ¨¡å‹ç»„ç»‡æˆä¸€ä¸ªæ–‡ä»¶ã€‚**ä½†å¦‚æœä½ çš„æ•°æ®å°šæœªæŒ‰æ¨¡å‹ç»„ç»‡æ€ä¹ˆåŠï¼Ÿ** ä½¿ç”¨ Ray AIRï¼Œä½ å¯ä»¥åœ¨è®­ç»ƒä¸åŒæ¨¡å‹çš„åŒæ—¶åœ¨åŒä¸€ç®¡é“ä¸­é¢„å¤„ç†æ•°æ®ã€‚
- en: Another problem, **what if you want to mix-and-match algorithms from more than
    one library at a time?** Ray Tune, which is part of Ray AIR, lets you run parallel
    trials to find the best choice of algorithm from any Python AI/ML libraries and
    hyperparameters, per segment of data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œ**å¦‚æœä½ æƒ³åŒæ—¶æ··åˆä½¿ç”¨æ¥è‡ªå¤šä¸ªåº“çš„ç®—æ³•æ€ä¹ˆåŠï¼Ÿ** Ray Tuneï¼Œä½œä¸º Ray AIR çš„ä¸€éƒ¨åˆ†ï¼Œå…è®¸ä½ è¿è¡Œå¹¶è¡Œè¯•éªŒï¼Œä»ä»»ä½• Python
    AI/ML åº“å’Œè¶…å‚æ•°ä¸­æ‰¾åˆ°æœ€ä½³ç®—æ³•é€‰æ‹©ï¼Œæ¯ä¸ªæ•°æ®æ®µã€‚
- en: 'Below are the steps to preprocess data and automatically tune models. Although
    specific to [Ray AIR](https://docs.ray.io/en/latest/ray-air/getting-started.html)
    and its [APIs](https://docs.ray.io/en/latest/ray-air/package-ref.html), these
    steps apply in general to converting serial Python to distributed Python:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ˜¯é¢„å¤„ç†æ•°æ®å’Œè‡ªåŠ¨è°ƒæ•´æ¨¡å‹çš„æ­¥éª¤ã€‚è™½ç„¶è¿™äº›æ­¥éª¤ç‰¹å®šäº [Ray AIR](https://docs.ray.io/en/latest/ray-air/getting-started.html)
    åŠå…¶ [API](https://docs.ray.io/en/latest/ray-air/package-ref.html)ï¼Œä½†è¿™äº›æ­¥éª¤é€šå¸¸é€‚ç”¨äºå°†ä¸²è¡Œ
    Python è½¬æ¢ä¸ºåˆ†å¸ƒå¼ Pythonï¼š
- en: Define Python functions to `**preprocess**` a segment of data.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®šä¹‰ Python å‡½æ•°æ¥ `**preprocess**` ä¸€ä¸ªæ•°æ®æ®µã€‚
- en: Define Python functions to `**train**` and `**evaluate**` a model on a segment
    of data.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®šä¹‰ Python å‡½æ•°æ¥ `**train**` å’Œ `**evaluate**` ä¸€ä¸ªæ•°æ®æ®µä¸Šçš„æ¨¡å‹ã€‚
- en: Define a calling function `**train_models**`, which calls all the above functions,
    and will be called in parallel for every permutation in the Tune search space!
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å®šä¹‰ä¸€ä¸ªè°ƒç”¨å‡½æ•°`**train_models**`ï¼Œè¯¥å‡½æ•°è°ƒç”¨æ‰€æœ‰ä¸Šè¿°å‡½æ•°ï¼Œå¹¶å°†ä¸ºTuneæœç´¢ç©ºé—´ä¸­çš„æ¯ä¸ªæ’åˆ—å¹¶è¡Œè°ƒç”¨ï¼
- en: 'Inside this [**train_models**](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs)
    function:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ª[**train_models**](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs)å‡½æ•°ä¸­ï¼š
- en: ğŸ“– The input parameters must include a config dictionary argument.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ“– è¾“å…¥å‚æ•°å¿…é¡»åŒ…æ‹¬ä¸€ä¸ªé…ç½®å­—å…¸å‚æ•°ã€‚
- en: ğŸ“ˆ The tuning metric (a modelâ€™s loss or error) must be calculated and reported
    using `session.report()`.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ğŸ“ˆ è°ƒä¼˜æŒ‡æ ‡ï¼ˆæ¨¡å‹çš„æŸå¤±æˆ–é”™è¯¯ï¼‰å¿…é¡»ä½¿ç”¨`session.report()`è®¡ç®—å¹¶æŠ¥å‘Šã€‚
- en: âœ”ï¸ `Checkpoint` (save) the model is recommended for fault tolerance and easy
    deployment later.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: âœ”ï¸ æ¨è`Checkpoint`ï¼ˆä¿å­˜ï¼‰æ¨¡å‹ä»¥ä¾¿äºå®¹é”™å’Œåç»­éƒ¨ç½²ã€‚
- en: '**Configure distributed compute scaling**.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**é…ç½®åˆ†å¸ƒå¼è®¡ç®—ç¼©æ”¾**ã€‚'
- en: '**Define a Tune search space** of all training parameters.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**å®šä¹‰Tuneæœç´¢ç©ºé—´**çš„æ‰€æœ‰è®­ç»ƒå‚æ•°ã€‚'
- en: (Optional) Specify a hyperparameter search strategy.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ï¼ˆå¯é€‰ï¼‰æŒ‡å®šè¶…å‚æ•°æœç´¢ç­–ç•¥ã€‚
- en: '**Run the experiment**.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**è¿è¡Œå®éªŒ**ã€‚'
- en: Below is the additional code we would add; full code is on [my github](https://github.com/christy/AnyscaleDemos/blob/6b1cea50a8c3b75bf9b680e77216f6927bdd2f85/forecasting_demos/Ray_v2/train_prophet_blog.ipynb).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹é¢æ˜¯æˆ‘ä»¬å°†æ·»åŠ çš„é™„åŠ ä»£ç ï¼›å®Œæ•´ä»£ç åœ¨[æˆ‘çš„GitHub](https://github.com/christy/AnyscaleDemos/blob/6b1cea50a8c3b75bf9b680e77216f6927bdd2f85/forecasting_demos/Ray_v2/train_prophet_blog.ipynb)ä¸Šã€‚
- en: The `preprocess_data` and `train_model` functions below are exactly the same
    as before, except they take in a list of files instead of a single file.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸‹é¢çš„`preprocess_data`å’Œ`train_model`å‡½æ•°ä¸ä¹‹å‰å®Œå…¨ç›¸åŒï¼Œåªæ˜¯å®ƒä»¬æ¥å—ä¸€ä¸ªæ–‡ä»¶åˆ—è¡¨è€Œä¸æ˜¯å•ä¸ªæ–‡ä»¶ã€‚
- en: The `train_models` function is exactly the same as `train_and_evaluate` except
    it takes in a list of files instead of a single file. It also trains an algorithm
    passed in the config instead of a fixed algorithm, and does checkpointing.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_models`å‡½æ•°ä¸`train_and_evaluate`å®Œå…¨ç›¸åŒï¼Œåªæ˜¯å®ƒæ¥å—ä¸€ä¸ªæ–‡ä»¶åˆ—è¡¨è€Œä¸æ˜¯å•ä¸ªæ–‡ä»¶ã€‚å®ƒè¿˜è®­ç»ƒé…ç½®ä¸­ä¼ é€’çš„ç®—æ³•ï¼Œè€Œä¸æ˜¯å›ºå®šçš„ç®—æ³•ï¼Œå¹¶è¿›è¡Œæ£€æŸ¥ç‚¹ä¿å­˜ã€‚'
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/0256c490f5411ce2ac7c0261144e0f9f.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0256c490f5411ce2ac7c0261144e0f9f.png)'
- en: '**Top**: Screenshot Ray Tune Trial Status showing the error of 768 candidate
    models (3 algorithm choices per 256 NYC taxi pickup locations). Trained in under
    45 minutes. **Bottom left**: Prophet model inference+prediction plot (actuals
    as black dots, forecast with confidence interval in blue) for NYC taxi pickup
    location=165\. **Bottom right**: ARIMA model inference+prediction plot (actuals
    in blue, forecast in orange) for NYC taxi pickup location=237\. All models trained
    using Anyscale on 10-node AWS cluster of [m5.4xlarges](https://aws.amazon.com/ec2/instance-types/m5/)
    worker nodes and one m5.2xlarge head node.Image by Author.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**é¡¶éƒ¨**ï¼šRay Tuneè¯•éªŒçŠ¶æ€çš„æˆªå›¾ï¼Œæ˜¾ç¤ºäº†768ä¸ªå€™é€‰æ¨¡å‹çš„é”™è¯¯ï¼ˆæ¯256ä¸ªNYCå‡ºç§Ÿè½¦æ¥é€ä½ç½®æœ‰3ç§ç®—æ³•é€‰æ‹©ï¼‰ã€‚åœ¨ä¸åˆ°45åˆ†é’Ÿå†…å®Œæˆè®­ç»ƒã€‚**å·¦ä¸‹**ï¼šProphetæ¨¡å‹æ¨æ–­+é¢„æµ‹å›¾ï¼ˆå®é™…å€¼ä¸ºé»‘ç‚¹ï¼Œå¸¦ç½®ä¿¡åŒºé—´çš„é¢„æµ‹ä¸ºè“è‰²ï¼‰ç”¨äºNYCå‡ºç§Ÿè½¦æ¥é€ä½ç½®=165ã€‚**å³ä¸‹**ï¼šARIMAæ¨¡å‹æ¨æ–­+é¢„æµ‹å›¾ï¼ˆå®é™…å€¼ä¸ºè“è‰²ï¼Œé¢„æµ‹ä¸ºæ©™è‰²ï¼‰ç”¨äºNYCå‡ºç§Ÿè½¦æ¥é€ä½ç½®=237ã€‚æ‰€æœ‰æ¨¡å‹ä½¿ç”¨Anyscaleåœ¨10èŠ‚ç‚¹çš„AWSé›†ç¾¤ä¸Šè®­ç»ƒï¼Œé›†ç¾¤åŒ…æ‹¬[
    m5.4xlarges](https://aws.amazon.com/ec2/instance-types/m5/)å·¥ä½œèŠ‚ç‚¹å’Œä¸€ä¸ªm5.2xlargeå¤´èŠ‚ç‚¹ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚'
- en: In the above screen shots, data since January 2018 was grouped and aggregated
    to daily-level. I have tried in the past to do this on SageMaker and just the
    data processing alone took too long, let alone Tuning that many models at once.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸Šè¿°æˆªå›¾ä¸­ï¼Œè‡ª2018å¹´1æœˆä»¥æ¥çš„æ•°æ®è¢«åˆ†ç»„å¹¶æ±‡æ€»åˆ°æ—¥çº§åˆ«ã€‚æˆ‘æ›¾å°è¯•åœ¨SageMakerä¸Šå®Œæˆè¿™é¡¹å·¥ä½œï¼Œä»…æ•°æ®å¤„ç†å°±èŠ±è´¹äº†å¤ªé•¿æ—¶é—´ï¼Œæ›´ä¸ç”¨è¯´åŒæ—¶è°ƒä¼˜å¦‚æ­¤å¤šçš„æ¨¡å‹äº†ã€‚
- en: 'Section 3: Multi-model Distributed Tuning (larger PyTorch models)'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰èŠ‚ï¼šå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜ï¼ˆæ›´å¤§çš„PyTorchæ¨¡å‹ï¼‰
- en: Often the goal is to create a few, larger models, such as one model by geographic
    zone, where you only have a handful of such zones. One year ago, in December 2021,
    I wrote a [blog article](https://medium.com/towards-data-science/how-to-train-time-series-forecasting-faster-using-ray-part-2-of-2-aacba89ca49a)
    demonstrating how to use Ray Lightning to train larger PyTorch Forecasting models.
    **Since then, a big improvement is the code development switch between laptop
    and cloud is more seamless, thanks to** [**Anyscale Workspaces**](https://docs.anyscale.com/user-guide/develop-and-debug/workspaces)**.**
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡é€šå¸¸æ˜¯åˆ›å»ºä¸€äº›æ›´å¤§çš„æ¨¡å‹ï¼Œä¾‹å¦‚æŒ‰åœ°ç†åŒºåŸŸåˆ’åˆ†çš„æ¨¡å‹ï¼Œå…¶ä¸­åªæœ‰å°‘æ•°å‡ ä¸ªè¿™æ ·çš„åŒºåŸŸã€‚ä¸€å¹´å‰ï¼Œå³2021å¹´12æœˆï¼Œæˆ‘å†™äº†ä¸€ç¯‡[åšå®¢æ–‡ç« ](https://medium.com/towards-data-science/how-to-train-time-series-forecasting-faster-using-ray-part-2-of-2-aacba89ca49a)ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Ray
    Lightningè®­ç»ƒæ›´å¤§çš„PyTorché¢„æµ‹æ¨¡å‹ã€‚**è‡ªé‚£æ—¶ä»¥æ¥ï¼Œä¸€ä¸ªé‡å¤§æ”¹è¿›æ˜¯ï¼Œæ„Ÿè°¢** [**Anyscale Workspaces**](https://docs.anyscale.com/user-guide/develop-and-debug/workspaces)**ï¼Œç¬”è®°æœ¬ç”µè„‘å’Œäº‘ä¹‹é—´çš„ä»£ç å¼€å‘åˆ‡æ¢æ›´åŠ æ— ç¼ã€‚**
- en: These larger models are sometimes called â€œglobal modelsâ€, because only 1 deep
    neural network model is trained across many different time series at once. Instead
    of 1 model per time series (Prophet or ARIMA).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›è¾ƒå¤§çš„æ¨¡å‹æœ‰æ—¶è¢«ç§°ä¸ºâ€œå…¨çƒæ¨¡å‹â€ï¼Œå› ä¸ºåªæœ‰ä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨å¤šä¸ªä¸åŒæ—¶é—´åºåˆ—ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œä¸æ˜¯æ¯ä¸ªæ—¶é—´åºåˆ—ä¸€ä¸ªæ¨¡å‹ï¼ˆProphet æˆ– ARIMAï¼‰ã€‚
- en: 'See [my github](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/ray_air/pytorch_forecasting.ipynb)
    for the full [PyTorch Forecasting](https://pytorch-forecasting.readthedocs.io/en/stable/index.html)
    code showing the latest Ray AIR APIs with [Ray Lightning](https://docs.ray.io/en/latest/tune/examples/tune-pytorch-lightning.html).
    You need to add a cluster ID to your data, then the steps for Tuning are the same
    as we saw in Section 2:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æŸ¥çœ‹ [æˆ‘çš„ GitHub](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/ray_air/pytorch_forecasting.ipynb)
    ä»¥è·å–å®Œæ•´çš„ [PyTorch Forecasting](https://pytorch-forecasting.readthedocs.io/en/stable/index.html)
    ä»£ç ï¼Œå…¶ä¸­å±•ç¤ºäº†æœ€æ–°çš„ Ray AIR API ä¸ [Ray Lightning](https://docs.ray.io/en/latest/tune/examples/tune-pytorch-lightning.html)ã€‚ä½ éœ€è¦å°†é›†ç¾¤
    ID æ·»åŠ åˆ°æ•°æ®ä¸­ï¼Œç„¶åè°ƒä¼˜æ­¥éª¤ä¸ç¬¬ 2 èŠ‚ä¸­çœ‹åˆ°çš„ç›¸åŒï¼š
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![](../Images/dc844e0d7e1c866b57556638403bbad8.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc844e0d7e1c866b57556638403bbad8.png)'
- en: '**Top**. Screenshot Ray Tune Trial Status while tuning six PyTorch Forecasting
    TemporalFusionTransformer models. (3 learning rates, 2 clusters of NYC taxi locations).
    Runtime less than 2 minutes total. Ran on a 2-node AWS cluster of m5.4xlarge worker
    nodes and one m5.2xlarge head node, within 2 minutes. **Bottom**: Inference forecast
    plots for several taxi pickup locations using a single model.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**é¡¶éƒ¨**ã€‚åœ¨è°ƒä¼˜å…­ä¸ª PyTorch Forecasting TemporalFusionTransformer æ¨¡å‹æ—¶æˆªå›¾ Ray Tune Trial
    çŠ¶æ€ã€‚ï¼ˆ3 ä¸ªå­¦ä¹ ç‡ï¼Œ2 ä¸ªçº½çº¦å¸‚å‡ºç§Ÿè½¦ä½ç½®ç°‡ï¼‰ã€‚æ€»è¿è¡Œæ—¶é—´å°‘äº 2 åˆ†é’Ÿã€‚åœ¨ 2 èŠ‚ç‚¹çš„ AWS é›†ç¾¤ï¼ˆm5.4xlarge å·¥ä½œèŠ‚ç‚¹å’Œä¸€ä¸ª m5.2xlarge
    ä¸»èŠ‚ç‚¹ï¼‰ä¸Šè¿è¡Œï¼Œæ—¶é—´ä¸è¶…è¿‡ 2 åˆ†é’Ÿã€‚**åº•éƒ¨**ï¼šä½¿ç”¨å•ä¸ªæ¨¡å‹å¯¹å¤šä¸ªå‡ºç§Ÿè½¦æ¥å®¢åœ°ç‚¹è¿›è¡Œçš„æ¨æ–­é¢„æµ‹å›¾ã€‚'
- en: Note that unlike the ARIMA and Prophet models, which were a single model per
    unique_id, each one of these larger models contains inferences for many unique_ids
    at once in a single model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä¸ ARIMA å’Œ Prophet æ¨¡å‹ï¼ˆæ¯ä¸ª unique_id ä¸€ä¸ªæ¨¡å‹ï¼‰ä¸åŒï¼Œè¿™äº›è¾ƒå¤§çš„æ¨¡å‹æ¯æ¬¡åŒ…å«å¯¹å¤šä¸ª unique_ids çš„æ¨æ–­ã€‚
- en: 'Section 4: Multi-model Distributed Deploying using Ray AIR with Ray Serve'
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç¬¬ 4 èŠ‚ï¼šä½¿ç”¨ Ray AIR å’Œ Ray Serve è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼éƒ¨ç½²
- en: Before you deploy, you have to decide if your deployment needs to be an online,
    always running http service or offline (Python service called on demand). Below,
    I demonstrate offline deployment using the new [Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html)
    with [Ray Serve](https://docs.ray.io/en/latest/serve/index.html).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨éƒ¨ç½²ä¹‹å‰ï¼Œä½ å¿…é¡»å†³å®šä½ çš„éƒ¨ç½²æ˜¯éœ€è¦ä¸€ä¸ªåœ¨çº¿ã€å§‹ç»ˆè¿è¡Œçš„ http æœåŠ¡ï¼Œè¿˜æ˜¯ç¦»çº¿çš„ï¼ˆæŒ‰éœ€è°ƒç”¨çš„ Python æœåŠ¡ï¼‰ã€‚ä¸‹é¢ï¼Œæˆ‘æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ–°çš„ [Ray
    AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) å’Œ [Ray
    Serve](https://docs.ray.io/en/latest/serve/index.html) è¿›è¡Œç¦»çº¿éƒ¨ç½²ã€‚
- en: 'The steps for offline deployment are:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç¦»çº¿éƒ¨ç½²çš„æ­¥éª¤æ˜¯ï¼š
- en: '**Step 1**. Instantiate a batch predictor using Ray AIR checkpoints.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 1**ã€‚ä½¿ç”¨ Ray AIR æ£€æŸ¥ç‚¹å®ä¾‹åŒ–ä¸€ä¸ªæ‰¹é‡é¢„æµ‹å™¨ã€‚'
- en: '**Step 2**. Create some test data.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 2**ã€‚åˆ›å»ºä¸€äº›æµ‹è¯•æ•°æ®ã€‚'
- en: '**Step 3**. Run `batch_predictor.predict(test_data)`.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 3**ã€‚è¿è¡Œ `batch_predictor.predict(test_data)`ã€‚'
- en: 'Replace Step 3 above with these steps for a custom predictor:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å°†ä¸Šè¿°æ­¥éª¤ 3 æ›¿æ¢ä¸ºè‡ªå®šä¹‰é¢„æµ‹å™¨çš„ä»¥ä¸‹æ­¥éª¤ï¼š
- en: '**Step 3**. Define a Ray Serve deployment class by using a Ray decorator `@serve.deployment`.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 3**ã€‚é€šè¿‡ä½¿ç”¨ Ray è£…é¥°å™¨ `@serve.deployment` å®šä¹‰ä¸€ä¸ª Ray Serve éƒ¨ç½²ç±»ã€‚'
- en: '**Step 4**. Deploy the predictor.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 4**ã€‚éƒ¨ç½²é¢„æµ‹å™¨ã€‚'
- en: '**Step 5**. Query the deployment and get the result.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**æ­¥éª¤ 5**ã€‚æŸ¥è¯¢éƒ¨ç½²å¹¶è·å–ç»“æœã€‚'
- en: Steps 3â€“5 above are only required if you are using a custom predictor (such
    as ARIMA, Prophet, or PyTorch Forecasting).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°æ­¥éª¤ 3â€“5 ä»…åœ¨ä½¿ç”¨è‡ªå®šä¹‰é¢„æµ‹å™¨ï¼ˆå¦‚ ARIMAã€Prophet æˆ– PyTorch Forecastingï¼‰æ—¶éœ€è¦ã€‚
- en: Otherwise for Ray AIR-integrated ML Libraries (HuggingFace transformers, PyTorch,
    TensorFlow, Scikit-learn, XGBoost, or LightGBM), all you have to do is call `batch_predictor.predict(test_data)`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å¦åˆ™ï¼Œå¯¹äºé›†æˆäº† Ray AIR çš„ ML åº“ï¼ˆHuggingFace transformersã€PyTorchã€TensorFlowã€Scikit-learnã€XGBoost
    æˆ– LightGBMï¼‰ï¼Œä½ åªéœ€è°ƒç”¨ `batch_predictor.predict(test_data)` å³å¯ã€‚
- en: Continuing the example for PyTorch Forecasting from the previous section, below
    is the deployment code. Full code is on [my github](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/ray_air/pytorch_forecasting.ipynb).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ç»§ç»­ä¸Šä¸€èŠ‚ä¸­å…³äº PyTorch Forecasting çš„ç¤ºä¾‹ï¼Œä¸‹é¢æ˜¯éƒ¨ç½²ä»£ç ã€‚å®Œæ•´ä»£ç åœ¨ [æˆ‘çš„ GitHub](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/ray_air/pytorch_forecasting.ipynb)
    ä¸Šã€‚
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../Images/352284bfab1b2d33c66eb92fe5f433e5.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/352284bfab1b2d33c66eb92fe5f433e5.png)'
- en: '**Left**: Screenshot from Ray dashboard (accessible by default at `localhost:8265
    on the head node`) while serving. **Right**: A screenshot from the Ray dashboard
    while running the above example. You can see 5 spikes in autoscaling while I made
    5 different iterations on the training code before deploying the final trained
    model. Ran Anyscale on 3-node AWS cluster of [m5.4xlarges](https://aws.amazon.com/ec2/instance-types/m5/)
    worker nodes and 1-m5.2xlarge head node.Image by Author.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**å·¦ä¾§**ï¼šRay ä»ªè¡¨æ¿çš„æˆªå›¾ï¼ˆé»˜è®¤åœ¨`localhost:8265`çš„ä¸»èŠ‚ç‚¹ä¸Šè®¿é—®ï¼‰åœ¨æœåŠ¡æœŸé—´çš„æƒ…å†µã€‚**å³ä¾§**ï¼šRay ä»ªè¡¨æ¿åœ¨è¿è¡Œä¸Šè¿°ç¤ºä¾‹æ—¶çš„æˆªå›¾ã€‚ä½ å¯ä»¥çœ‹åˆ°åœ¨è‡ªåŠ¨ç¼©æ”¾ä¸­æœ‰
    5 ä¸ªå³°å€¼ï¼Œå› ä¸ºåœ¨éƒ¨ç½²æœ€ç»ˆè®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘å¯¹è®­ç»ƒä»£ç è¿›è¡Œäº† 5 æ¬¡ä¸åŒçš„è¿­ä»£ã€‚Anyscale è¿è¡Œåœ¨ 3 èŠ‚ç‚¹ AWS é›†ç¾¤ä¸Šï¼Œå…¶ä¸­åŒ…æ‹¬[ m5.4xlarges](https://aws.amazon.com/ec2/instance-types/m5/)
    å·¥ä½œèŠ‚ç‚¹å’Œ 1 ä¸ª m5.2xlarge ä¸»èŠ‚ç‚¹ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚'
- en: The screenshot above right shows Ray cluster observability while training and
    serving. If you need to do post-processing on the predictor results, I have an
    example of that [at the end of this other notebook here](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/train_prophet_blog.ipynb).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸Šè¿°å³ä¾§çš„æˆªå›¾å±•ç¤ºäº†åœ¨è®­ç»ƒå’ŒæœåŠ¡æœŸé—´ Ray é›†ç¾¤çš„å¯è§‚å¯Ÿæ€§ã€‚å¦‚æœä½ éœ€è¦å¯¹é¢„æµ‹ç»“æœè¿›è¡Œåå¤„ç†ï¼Œæˆ‘åœ¨[è¿™ä¸ªç¬”è®°æœ¬çš„æœ«å°¾æœ‰ä¸€ä¸ªç¤ºä¾‹](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/train_prophet_blog.ipynb)ã€‚
- en: Conclusion
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: In conclusion, this blog showed steps how to train and tune many models in parallel
    using distributed computing with open-source Ray. The models did not have to be
    all the same type, they could be mixed-and-matched from any AI/ML Python libraries.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»ä¹‹ï¼Œæœ¬åšå®¢å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¼€æº Ray åœ¨åˆ†å¸ƒå¼è®¡ç®—ä¸­å¹¶è¡Œè®­ç»ƒå’Œè°ƒæ•´å¤šä¸ªæ¨¡å‹ã€‚æ¨¡å‹ä¸å¿…éƒ½æ˜¯ç›¸åŒç±»å‹çš„ï¼Œå¯ä»¥ä»ä»»ä½• AI/ML Python åº“ä¸­æ··åˆåŒ¹é…ã€‚
- en: Ray AIR APIs were clear, intuitive, and hid a lot of distributed computing complexity
    so it was easy to do a lot of complicated things, such as early stopping, ASHA
    scheduling, checkpointing, and deployment.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Ray AIR API æ¸…æ™°ã€ç›´è§‚ï¼Œå¹¶éšè—äº†è®¸å¤šåˆ†å¸ƒå¼è®¡ç®—çš„å¤æ‚æ€§ï¼Œå› æ­¤å¯ä»¥è½»æ¾å®Œæˆè®¸å¤šå¤æ‚çš„ä»»åŠ¡ï¼Œå¦‚æ—©æœŸåœæ­¢ã€ASHA è°ƒåº¦ã€æ£€æŸ¥ç‚¹å’Œéƒ¨ç½²ã€‚
- en: 'To take your learning further:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥å­¦ä¹ ï¼š
- en: Read the [Ray docs](https://docs.ray.io/en/latest/), for detailed explanations
    and examples.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é˜…è¯»[Ray æ–‡æ¡£](https://docs.ray.io/en/latest/)ï¼Œè·å–è¯¦ç»†çš„è§£é‡Šå’Œç¤ºä¾‹ã€‚
- en: Ask questions on [Slack](https://docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform)
    and [Discuss](https://discuss.ray.io/).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨[Slack](https://docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform)å’Œ[Discuss](https://discuss.ray.io/)ä¸Šæé—®ã€‚
- en: Use [Anyscale](https://docs.anyscale.com/user-guide/develop-and-debug/workspaces#workspaces-tutorial),
    which makes it easy to spin up a cluster and run your code on a Cloud (get the
    invite code [here](https://www.anyscale.com/signup)).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨[Anyscale](https://docs.anyscale.com/user-guide/develop-and-debug/workspaces#workspaces-tutorial)ï¼Œè¿™ä½¿å¾—å¯åŠ¨é›†ç¾¤å¹¶åœ¨äº‘ä¸Šè¿è¡Œä½ çš„ä»£ç å˜å¾—ç®€å•ï¼ˆè·å–é‚€è¯·ç [è¿™é‡Œ](https://www.anyscale.com/signup)ï¼‰ã€‚
