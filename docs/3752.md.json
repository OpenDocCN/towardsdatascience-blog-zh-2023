["```py\n# Initialize Segement Anything and pass in the image for auto mask generation\nmask_generator = SamAutomaticMaskGenerator(sam)\nmasks = mask_generator.generate(input_layer_img)\n```", "```py\n# Read the input image\ninput_layer_img: np.ndarray = cv2.imread(img_fp)\n\n# Downscale image for performance\ninput_layer_img = downscale(input_layer_img)\n\n# First, find all the labels in the image\n# The label position can help prompt SAM to generate segments better\nlabel_points: list[list[int, int]] = pallet_label_detector(input_layer_img)\n\n# Send the labels position to SAM and get a segment mask\nsegmented_mask: np.ndarray = prompt_segment(label_points, input_layer_img)\n\n# Draw on the original image with values from the mask\nsegment_color = np.random.random(3) * 100\n\nsegmented_img = input_layer_img.copy()\nsegmented_img[segmented_mask] = segment_color\nmask = cv2.inRange(segmented_img, segment_color - 10, segment_color + 10)\n\n# Based on the segmented image, find the fill rate\nfill_rate: float = fill_rate_calculation(label_points, mask, segmented_img)\n```", "```py\nlower_val = np.array([150, 150, 150], dtype=np.uint8)\nupper_val = np.array([255, 255, 255], dtype=np.uint8)\n\n# preparing the mask to overlay\nmask = cv2.inRange(layer_img, lower_val, upper_val)\n\n# find contours\ncontours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n\nnew_mask = np.ones(img.shape[:2], dtype=\"uint8\") * 255\nprompt_points = []\n\nfor c in contours:\n    x, y, w, h = cv2.boundingRect(c)\n\n    # only select points in our region of interest\n    if is_outside_roi(layer_img, x, y):\n        continue\n\n    if w * h < 1000:\n        continue\n\n    cv2.rectangle(new_mask, (x, y), (x + w, y + h), (0, 0, 255), -1)\n\n    # We calculate the center of the label to be passed for prompting\n    prompt_points.append([int(x + (w / 2)), int(y + (h / 2))])\n\nres_final = cv2.bitwise_and(layer_img, layer_img, mask=cv2.bitwise_not(new_mask))\ncv2.imshow(\"Labels only\", res_final)\n```", "```py\n# prompt_points contains the coordinates of the labels\n# [ [x, y], [x, y]...]\ninput_point_nd = np.array(prompt_points, dtype=np.int32)\n\n# As all the prompt points are labels, we are giving them a category of 1\ninput_label = np.ones(len(prompt_points), dtype=np.int32)\n\npredictor.set_image(segment_img)\nmasks, scores, _ = predictor.predict(\n    point_coords=input_point_nd,\n    point_labels=input_label,\n    multimask_output=False,\n)\n```", "```py\n# Sum of white pixels\ntotal_white = np.sum(fill_rate_used[tallest:ch, cx: cw] == 255)\n\n# Sum of black pixels\ntotal_black = np.sum(fill_rate_used[tallest:ch, cx: cw] == 0)\n\n# Percentage of white\nfill_rate = round(total_white / (total_white + total_black), 2)\n```"]