- en: 'Unlocking the Power of Facial Blurring in Media: A Comprehensive Exploration
    and Model Comparison'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513?source=collection_archive---------3-----------------------#2023-09-18](https://towardsdatascience.com/unlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513?source=collection_archive---------3-----------------------#2023-09-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Comparison of various face detection and blurring algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)[![Danilo
    Najkov](../Images/e0e8976f1f9f78ae58ba7efcc90a4f00.png)](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)[](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)
    [Danilo Najkov](https://medium.com/@danilo.najkov?source=post_page-----261031603513--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F19802d0e7d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&user=Danilo+Najkov&userId=19802d0e7d&source=post_page-19802d0e7d----261031603513---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----261031603513--------------------------------)
    ·12 min read·Sep 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F261031603513&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&user=Danilo+Najkov&userId=19802d0e7d&source=-----261031603513---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F261031603513&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funlocking-the-power-of-facial-blurring-in-media-a-comprehensive-exploration-and-model-comparison-261031603513&source=-----261031603513---------------------bookmark_footer-----------)![](../Images/7ec96f1f4a35203a82b0f809c11a43be.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Processed photo by [OSPAN ALI](https://unsplash.com/@ospanali?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In today’s data-driven world, ensuring the privacy and anonymity of individuals
    is of paramount importance. From protecting personal identities to complying with
    stringent regulations like GDPR, the need for efficient and reliable solutions
    to anonymize faces in various media formats has never been greater.
  prefs: []
  type: TYPE_NORMAL
- en: Contents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Face Detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '- Haar Cascade'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- MTCNN'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- YOLO'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Face Blurring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '- Gaussian Blur'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- Pixelization'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Results and Discussion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '- Real-Time performance'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- Scenario-based evaluation'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- Privacy'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Usage in videos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Web Application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this project, we explore and compare several solutions for the topic of
    face blurring and develop a web application that allows for easy evaluation. Let’s
    explore the diverse applications driving the demand for such a system:'
  prefs: []
  type: TYPE_NORMAL
- en: Preserving Privacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Navigating Regulatory Landscapes: With the regulatory landscape evolving rapidly,
    industries and regions worldwide are enforcing stricter norms to safeguard individuals’
    identities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training Data Confidentiality: Machine learning models thrive on diverse and
    well-prepared training data. However, sharing such data often requires careful
    anonymization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This solution can be distilled into two essential components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Face Detection**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Face Blurring Techniques**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Face detection
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To address the anonymization challenge, the first step is to locate the area
    in the image where a face is present. For this purpose, I tested three models
    for image detection.
  prefs: []
  type: TYPE_NORMAL
- en: Haar Cascade
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/718074f086356a231521438c3ac97d63.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. Haar-like features ([source](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)
    — original paper)
  prefs: []
  type: TYPE_NORMAL
- en: Haar Cascade is a machine learning method used for object detection, such as
    faces, in images or videos. It operates by utilizing a set of trained features
    called ‘Haar-like features’ (Figure 1), which are simple rectangular filters that
    focus on variations in pixel intensity within regions of the image. These features
    can capture edges, angles, and other characteristics commonly found in faces.
  prefs: []
  type: TYPE_NORMAL
- en: The training process involves providing the algorithm with positive examples
    (images containing faces) and negative examples (images without faces). The algorithm
    then learns to differentiate between these examples by adjusting the weights of
    the features. After training, the Haar Cascade essentially becomes a hierarchy
    of classifiers, with each stage progressively refining the detection process.
  prefs: []
  type: TYPE_NORMAL
- en: For face detection, I utilized a pre-trained Haar Cascade model trained on [forward-facing
    images of faces](https://github.com/kipr/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: MTCNN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/6a604819c3e72d536a3710a48dcadc6b.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. Face detection process in MTCNN ([source](https://arxiv.org/abs/1604.02878)
    — original paper)
  prefs: []
  type: TYPE_NORMAL
- en: MTCNN (Multi-Task Cascaded Convolutional Networks) stands as a sophisticated
    and highly accurate algorithm for face detection, surpassing the capabilities
    of Haar Cascades. Designed to excel in scenarios with diverse face sizes, orientations,
    and lighting conditions, MTCNN leverages a series of neural networks, each tailored
    to execute specific tasks within the face detection process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Phase One — Proposal Generation**: MTCNN initiates the process by generating
    a multitude of potential face regions (bounding boxes) through a small neural
    network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Phase Two — Refinement**: Candidates generated in the first phase undergo
    filtering in this step. A second neural network evaluates the proposed bounding
    boxes, adjusting their positions for a more precise alignment with the true face
    boundaries. This aids in enhancing accuracy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Phase Three — Facial Feature Points**: This stage identifies facial landmarks,
    such as eye corners, nose, and mouth. The neural network is employed to accurately
    pinpoint these features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MTCNN’s cascaded architecture allows it to swiftly discard regions devoid of
    faces early in the process, concentrating computations on areas with a higher
    probability of containing faces. Its ability to handle different scales (zoom
    levels) of faces and rotations makes it highly suitable for intricate scenarios
    compared to Haar Cascades. However, its computational intensity stems from its
    neural network-based sequential approach.
  prefs: []
  type: TYPE_NORMAL
- en: For the implementation of MTCNN, I utilized the [mtcnn](https://pypi.org/project/mtcnn/)
    library.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: YOLOv5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/4fd920a67df66fda40de057af89bd0bb.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. YOLO Object Detection Process ([source](https://arxiv.org/abs/1506.02640)
    — original paper)
  prefs: []
  type: TYPE_NORMAL
- en: 'YOLO (You Only Look Once) is an algorithm employed for detecting a multitude
    of objects, including faces. Unlike its predecessors, YOLO performs detection
    in a single pass through a neural network, rendering it faster and more suitable
    for real-time applications and videos. The process of detecting faces in media
    with YOLO can be distilled in four parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Image Grid Division**: The input image is divided into a grid of cells. Each
    cell is responsible for predicting objects located within its boundaries. For
    every cell, YOLO predicts bounding boxes, object probabilities, and class probabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bounding Box Prediction**: Within each cell, YOLO predicts one or more bounding
    boxes along with their corresponding probabilities. These bounding boxes represent
    potential object locations. Each bounding box is defined by its center coordinates,
    width, height, and the probability that an object exists within that bounding
    box.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Class Prediction**: For each bounding box, YOLO predicts the probabilities
    for various classes (e.g., ‘face,’ ‘car,’ ‘dog’) to which the object may belong.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Non-Maximum Suppression (NMS)**: To eliminate duplicate bounding boxes, YOLO
    applies NMS. This process discards redundant bounding boxes by evaluating their
    probabilities and overlap with other boxes, retaining only the most confident
    and non-overlapping ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The key advantage of YOLO lies in its speed. Since it processes the entire image
    in a single forward pass through the neural network, it’s significantly faster
    than algorithms involving sliding windows or region proposals. However, this speed
    might come at a slight trade-off with precision, especially for smaller objects
    or crowded scenes.
  prefs: []
  type: TYPE_NORMAL
- en: YOLO can be adapted for face detection by training it on face-specific data
    and modifying its output classes to include only one class (‘face’). For this,
    I utilized the ‘[yoloface](https://github.com/elyha7/yoloface)’ library, built
    upon YOLOv5.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Face blurring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After identifying the bounding boxes around potential faces in the image, the
    next step is to blur them to remove their identities. For this task, I developed
    two implementations. A reference image for demonstration is provided in Figure
    4.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/76d8d15e8b87064972fde45479f0b64d.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Reference image By [Ethan Hoover](https://unsplash.com/photos/0YHIlxeCuhg)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian Blur
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/bc158115ae16b6a1d0ba165e0d707cc8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. Blurred reference image (Figure 4) with Gaussian Blur
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian blur is an image processing technique used to reduce image noise and
    smudge details. This is particularly useful in the domain of face blurring as
    it erases specifics from that portion of the image. It computes an average of
    pixel values in the neighborhood around each pixel. This average is centered around
    the pixel being blurred and calculated using a Gaussian distribution, giving more
    weight to nearby pixels and less weight to distant ones. The result is a softened
    image with reduced high-frequency noise and fine details. The outcome of applying
    Gaussian Blur is depicted in Figure 5.
  prefs: []
  type: TYPE_NORMAL
- en: 'Gaussian Blur takes three parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: Image portion to be blurred.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kernel size: the matrix used for the blurring operation. A larger kernel size
    leads to stronger blurring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Standard deviation: A higher value enhances the blurring effect.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Pixelization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/1361eb7226b0368d220488b2dd515a54.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. Blurred reference image (Figure 4) with Pixelization
  prefs: []
  type: TYPE_NORMAL
- en: Pixelization is an image processing technique where the pixels in an image are
    replaced with larger blocks of a single color. This effect is achieved by dividing
    the image into a grid of cells, where each cell corresponds to a group of pixels.
    The color or intensity of all pixels in the cell is then taken as the average
    value of the colors of all pixels in that cell, and this average value is applied
    to all pixels in the cell. This process creates a simplified appearance, reducing
    the level of fine details in the image. The result of applying pixelization is
    shown in Figure 6\. As you can observe, pixelization significantly complicates
    the identification of a person’s identity.
  prefs: []
  type: TYPE_NORMAL
- en: Pixelization takes one main parameter, which determines how many grouped pixels
    should represent a specific area. For instance, if we have a (10,10) section of
    the image containing a face, it will be replaced with a 10x10 group of pixels.
    A smaller number leads to greater blurring.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Results and discussion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I will evaluate the different algorithms from two perspectives: Real-Time performance
    analysis and specific image scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: Real-Time performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the same reference image (Figure 4), the time required for each face detection
    algorithm to locate the bounding box of the face in the image was measured. The
    results are based on the average value of 10 measurements for each algorithm.
    The time needed for the blurring algorithms is negligible and will not be considered
    in the evaluation process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/241812e44e3f13fd89b590b23e1da35e.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Average time in seconds needed for each algorithm to detect face
  prefs: []
  type: TYPE_NORMAL
- en: It can be observed that YOLOv5 achieves the best performance (speed) due to
    its single-pass processing through the neural network. In contrast, methods like
    MTCNN require sequential traversal through multiple neural networks. This further
    complicates the process of parallelizing the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario-based performance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To evaluate the performance of the aforementioned algorithms, in addition to
    the reference image (Figure 4), I have selected several images that test the algorithms
    in various scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: Reference image (Figure 4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Group of people close together — to assess the algorithm’s ability to capture
    different face sizes, some closer and some further away (Figure 8)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Side-view faces — testing the algorithms’ capability to detect faces not looking
    directly at the camera (Figure 10)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Flipped face, 180 degrees — testing the algorithms’ ability to detect a face
    rotated by 180 degrees (Figure 11)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Flipped face, 90 degrees — testing the algorithms’ ability to detect a face
    rotated by 90 degrees, sideways (Figure 12)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/53e0e0aedf75d1a8c0d7039229f53530.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8\. Group of people by [Nicholas Green](https://unsplash.com/photos/nPz8akkUmDI)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/881174753c52dee6f608b65d1cd22392.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9\. Mutiple faces by [Naassom Azevedo](https://unsplash.com/photos/Q_Sei-TqSlc)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e1667ef7b5fe1cb9fd1efe1cac461d51.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10\. Side-view faces by [Kraken Images](https://unsplash.com/photos/376KN_ISplE)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a8b0b3781ac4f72a23d6787cbf1c98d3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11\. Flipped face 180 degrees from Figure 4.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9f2e95cb2f68ad9a0479030d421e3c9f.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12\. Flipped face 90 degrees from Figure 4.
  prefs: []
  type: TYPE_NORMAL
- en: '**Haar Cascade**'
  prefs: []
  type: TYPE_NORMAL
- en: The Haar Cascade algorithm generally performs well in anonymizing faces, with
    a few exceptions. It successfully detects the reference image (Figure 4) and the
    ‘Multiple faces’ scenario (Figure 9) excellently. In the ‘Group of people’ scenario
    (Figure 8), it handles the task decently, though there are faces that are not
    entirely detected or are farther away. Haar Cascade encounters challenges with
    faces not directly facing the camera (Figure 10) and rotated faces (Figures 11
    and 12), where it fails to recognize faces entirely.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ab8f6f2c241c691d4657e7206c1c169d.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 13\. Results with Haar Cascade
  prefs: []
  type: TYPE_NORMAL
- en: '**MTCNN**'
  prefs: []
  type: TYPE_NORMAL
- en: MTCNN manages to achieve very similar results to Haar Cascade, with the same
    strengths and weaknesses. Additionally, MTCNN struggles to detect the face in
    Figure 9 with a darker skin tone.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8def97a683be399043e98530536d933c.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14\. Results with MTCNN
  prefs: []
  type: TYPE_NORMAL
- en: '**YOLOv5**'
  prefs: []
  type: TYPE_NORMAL
- en: YOLOv5 yields slightly different results from Haar Cascade and MTCNN. It successfully
    detects one of the faces where people are not looking directly at the camera (Figure
    10), as well as the face rotated by 180 degrees (Figure 11). However, in the ‘Group
    of people’ image (Figure 8), it doesn’t detect the faces farther away as effectively
    as the previously mentioned algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/28688ebc82f93acee48e312e71e44606.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15\. Results with YOLOv5
  prefs: []
  type: TYPE_NORMAL
- en: Privacy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When addressing the challenge of privacy in image processing, a crucial aspect
    to consider is the delicate balance between rendering faces unrecognizable while
    maintaining the natural appearance of the images.
  prefs: []
  type: TYPE_NORMAL
- en: '**Gaussian Blur**'
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian blur effectively blurs the facial region in an image (as depicted in
    Figure 5). Nevertheless, its success is dependent upon the parameters of the Gaussian
    distribution employed for the blurring effect. In Figure 5, it’s evident that
    facial features remain discernible, suggesting the necessity for higher standard
    deviation and kernel sizes to achieve optimal results.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pixelization**'
  prefs: []
  type: TYPE_NORMAL
- en: Pixelization (as illustrated in Figure 6) often appears more visually pleasing
    to the human eye due to its familiarity as a face-blurring method compared to
    Gaussian blur. The number of pixels employed for pixelization plays a pivotal
    role in this context as a smaller pixel count renders the face less recognizable
    but may result in a less natural appearance.
  prefs: []
  type: TYPE_NORMAL
- en: Overall there has been a preference for pixelization over the Gaussian Blur
    algorithm. It lies in its familiarity and contextual naturalness, striking a balance
    between privacy and aesthetics.
  prefs: []
  type: TYPE_NORMAL
- en: '**Reverse Engineering**'
  prefs: []
  type: TYPE_NORMAL
- en: With the rise of AI tools, it becomes imperative to anticipate the potential
    for reverse engineering techniques aimed at removing privacy filters from blurred
    images. Nevertheless, the very act of blurring a face irreversibly replaces specific
    facial details with more generalized ones. As of now, AI tools are only capable
    of reverse engineering a blurred face when presented with clear reference images
    of that same person. Paradoxically, this contradicts the need for reverse engineering
    in the first place, as it presupposes knowledge of the individual’s identity.
    Thus, face blurring stands as an efficient and necessary means of safeguarding
    privacy in the face of evolving AI capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Usage in videos
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since videos are essentially a sequence of images, it is relatively straightforward
    to modify each algorithm to perform anonymization for videos. However, here, processing
    time becomes crucial. For a given 30-second video recorded at 60 frames per second
    (images per second), the algorithms would need to process 1800 frames. In this
    context, algorithms like MTCNN would not be feasible, despite their improvements
    in certain scenarios. Hence, I decided to implement video anonymization using
    the YOLO model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Web application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a simplified evaluation of the different algorithms, I created a web application
    where users can upload any image or video, select the face detection and blurring
    algorithm, and after processing, the result is returned to the user. The implementation
    was done using Flask with Python on the backend, utilizing the mentioned libraries
    as well as OpenCV, and React.js on the frontend for user interaction with the
    models. The complete code is available at [this link](https://github.com/dani2221/dpns).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Within the scope of this post, various face detection algorithms, including
    Haar Cascade, MTCNN, and YOLOv5, were explored, compared, and analyzed across
    different aspects. The project also focused on image-blurring techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Haar Cascade proved to be an efficient method in certain scenarios, exhibiting
    generally good temporal performance. MTCNN stood out as an algorithm with solid
    face detection capabilities in various conditions, although it struggled with
    faces that are not typically in a conventional orientation. YOLOv5, with its real-time
    face detection capabilities, emerged as an excellent choice for scenarios where
    time is a critical factor (such as videos), albeit with slightly reduced accuracy
    in group settings.
  prefs: []
  type: TYPE_NORMAL
- en: All algorithms and techniques were integrated into a single web application.
    This application provides easy access and utilization of all face detection and
    blurring methods, along with the ability to process videos using blurring techniques.
  prefs: []
  type: TYPE_NORMAL
- en: This post is a conclusion of my work for the “Digital Processing of Images”
    course at the Faculty of Computer Science and Engineering in Skopje. Thanks for
    reading!
  prefs: []
  type: TYPE_NORMAL
