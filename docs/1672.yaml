- en: 'Unveiling the Dropout Layer: An Essential Tool for Enhancing Neural Networks'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/unveiling-the-dropout-layer-an-essential-tool-for-enhancing-neural-networks-e090b726561e?source=collection_archive---------8-----------------------#2023-05-19](https://towardsdatascience.com/unveiling-the-dropout-layer-an-essential-tool-for-enhancing-neural-networks-e090b726561e?source=collection_archive---------8-----------------------#2023-05-19)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Understanding the Dropout Layer: Improving Neural Network Training and Reducing
    Overfitting with Dropout Regularization'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@niklas_lang?source=post_page-----e090b726561e--------------------------------)[![Niklas
    Lang](../Images/5fa71386db00d248438c588c5ae79c67.png)](https://medium.com/@niklas_lang?source=post_page-----e090b726561e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e090b726561e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e090b726561e--------------------------------)
    [Niklas Lang](https://medium.com/@niklas_lang?source=post_page-----e090b726561e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3631074637a9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-dropout-layer-an-essential-tool-for-enhancing-neural-networks-e090b726561e&user=Niklas+Lang&userId=3631074637a9&source=post_page-3631074637a9----e090b726561e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e090b726561e--------------------------------)
    ·7 min read·May 19, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe090b726561e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-dropout-layer-an-essential-tool-for-enhancing-neural-networks-e090b726561e&user=Niklas+Lang&userId=3631074637a9&source=-----e090b726561e---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe090b726561e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funveiling-the-dropout-layer-an-essential-tool-for-enhancing-neural-networks-e090b726561e&source=-----e090b726561e---------------------bookmark_footer-----------)![](../Images/8cbac42a6864089508adf36e1897f5f7.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Martin Sanchez](https://unsplash.com/@martinsanchez?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The dropout layer is a layer used in the construction of [neural networks](https://databasecamp.de/en/ml/artificial-neural-networks)
    to prevent [overfitting](https://databasecamp.de/en/ml/overfitting-en). In this
    process, individual nodes are excluded in various training runs using a probability,
    as if they were not part of the network architecture at all.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: dropout层是用于构建[神经网络](https://databasecamp.de/en/ml/artificial-neural-networks)的一种层，用于防止[过拟合](https://databasecamp.de/en/ml/overfitting-en)。在这个过程中，个别节点在各种训练运行中会根据概率被排除，就好像它们根本不属于网络结构一样。
- en: However, before we can get to the details of this layer, we should first understand
    how a neural network works and why [overfitting](https://databasecamp.de/en/ml/overfitting-en)
    can occur.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们深入了解这一层的细节之前，我们应首先理解神经网络的工作原理以及[过拟合](https://databasecamp.de/en/ml/overfitting-en)为何会发生。
- en: 'Quick Recap: How does a Perceptron work?'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速回顾：感知器是如何工作的？
- en: The perceptron is a mathematical model inspired by the structure of the human
    brain. It consists of a single neuron that receives numerical inputs with different
    weights. The inputs are multiplied by their weights and summed up, and the result
    is passed through an activation function. In its simplest form, the perceptron
    produces binary outputs, such as “Yes” or “No,” based on the activation function.
    The sigmoid function is commonly used as an activation function, mapping the weighted
    sum to values between 0 and 1\. If the weighted sum exceeds a certain threshold,
    the output transitions from…
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器是一个受人脑结构启发的数学模型。它由一个接收不同权重数值输入的单一神经元组成。输入被乘以它们的权重后相加，结果通过一个激活函数。在最简单的形式中，感知器根据激活函数产生二进制输出，例如“是”或“否”。
    sigmoid函数通常作为激活函数使用，将加权和映射到0和1之间的值。如果加权和超过某个阈值，输出将从…
