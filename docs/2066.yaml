- en: 'From Python to Julia: Feature Engineering and ML'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从 Python 到 Julia：特征工程与机器学习
- en: 原文：[https://towardsdatascience.com/from-python-to-julia-feature-engineering-and-ml-d55e8321f888?source=collection_archive---------11-----------------------#2023-06-26](https://towardsdatascience.com/from-python-to-julia-feature-engineering-and-ml-d55e8321f888?source=collection_archive---------11-----------------------#2023-06-26)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/from-python-to-julia-feature-engineering-and-ml-d55e8321f888?source=collection_archive---------11-----------------------#2023-06-26](https://towardsdatascience.com/from-python-to-julia-feature-engineering-and-ml-d55e8321f888?source=collection_archive---------11-----------------------#2023-06-26)
- en: '![](../Images/f7da00682658a8bdd533781a67403eaf.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f7da00682658a8bdd533781a67403eaf.png)'
- en: Photo by [CardMapr.nl](https://unsplash.com/ja/@cardmapr?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/credit-cards?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [CardMapr.nl](https://unsplash.com/ja/@cardmapr?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，[Unsplash](https://unsplash.com/s/photos/credit-cards?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    上的
- en: A Julia-based approach to building a fraud-detection model
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于 Julia 的欺诈检测模型构建方法
- en: '[](https://medium.com/@wangshenghao1993?source=post_page-----d55e8321f888--------------------------------)[![Wang
    Shenghao](../Images/c59ca7f4fc77ca81f6b670ea5435ac19.png)](https://medium.com/@wangshenghao1993?source=post_page-----d55e8321f888--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d55e8321f888--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d55e8321f888--------------------------------)
    [Wang Shenghao](https://medium.com/@wangshenghao1993?source=post_page-----d55e8321f888--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@wangshenghao1993?source=post_page-----d55e8321f888--------------------------------)[![王胜浩](../Images/c59ca7f4fc77ca81f6b670ea5435ac19.png)](https://medium.com/@wangshenghao1993?source=post_page-----d55e8321f888--------------------------------)[](https://towardsdatascience.com/?source=post_page-----d55e8321f888--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----d55e8321f888--------------------------------)
    [王胜浩](https://medium.com/@wangshenghao1993?source=post_page-----d55e8321f888--------------------------------)'
- en: ·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F75535ec0f14c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-python-to-julia-feature-engineering-and-ml-d55e8321f888&user=Wang+Shenghao&userId=75535ec0f14c&source=post_page-75535ec0f14c----d55e8321f888---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d55e8321f888--------------------------------)
    ·6 min read·Jun 26, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd55e8321f888&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-python-to-julia-feature-engineering-and-ml-d55e8321f888&user=Wang+Shenghao&userId=75535ec0f14c&source=-----d55e8321f888---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F75535ec0f14c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-python-to-julia-feature-engineering-and-ml-d55e8321f888&user=Wang+Shenghao&userId=75535ec0f14c&source=post_page-75535ec0f14c----d55e8321f888---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----d55e8321f888--------------------------------)
    ·6分钟阅读·2023年6月26日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fd55e8321f888&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-python-to-julia-feature-engineering-and-ml-d55e8321f888&user=Wang+Shenghao&userId=75535ec0f14c&source=-----d55e8321f888---------------------clap_footer-----------)'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd55e8321f888&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-python-to-julia-feature-engineering-and-ml-d55e8321f888&source=-----d55e8321f888---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd55e8321f888&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffrom-python-to-julia-feature-engineering-and-ml-d55e8321f888&source=-----d55e8321f888---------------------bookmark_footer-----------)'
- en: This is part 2 in my two part series on getting started with Julia for applied
    data science. In [the first article](https://medium.com/towards-data-science/from-python-to-julia-basic-data-manipulation-and-eda-51171b34f685),
    we went through a few examples of simple data manipulation and conducting exploratory
    data analysis with Julia. In this blog, we will carry on the task of building
    a fraud detection model to identify fraudulent transactions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我关于如何使用 Julia 进行应用数据科学的两部分系列中的第二部分。在 [第一篇文章](https://medium.com/towards-data-science/from-python-to-julia-basic-data-manipulation-and-eda-51171b34f685)
    中，我们回顾了几个简单的数据操作示例以及使用 Julia 进行的探索性数据分析。在本博客中，我们将继续构建一个欺诈检测模型以识别欺诈性交易。
- en: To recap briefly, we used a [credit card fraud detection dataset](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
    obtained from Kaggle. The dataset contains 30 features including transaction time,
    amount, and 28 principal component features obtained with PCA. Below is a screenshot
    of the first 5 instances of the dataset, loaded as a dataframe in Julia. Note
    that the transaction time feature records the elapsed time (in second) between
    the current transaction and the first transaction in the dataset.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 简要回顾，我们使用了从 Kaggle 获取的 [信用卡欺诈检测数据集](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)。该数据集包含
    30 个特征，包括交易时间、金额和 28 个通过 PCA 获得的主成分特征。下面是数据集前 5 个实例的截图，以数据框的形式加载到 Julia 中。请注意，交易时间特征记录了当前交易与数据集中第一笔交易之间的经过时间（以秒为单位）。
- en: Feature Engineering
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: Before training the fraud detection model, let’s prepare the data ready for
    the model to consume. Since the main purpose of this blog is to introduce Julia,
    we are not going to perform any feature selection or feature synthesis here.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练欺诈检测模型之前，让我们准备好供模型使用的数据。由于本博客的主要目的是介绍 Julia，因此我们不会在此进行特征选择或特征合成。
- en: Data splitting
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据划分
- en: When training a classification model, the data is typically split for training
    and test in a stratified manner. The main purpose is to maintain the distribution
    of the data with respect to the target class variable in both the training and
    test data. This is especially necessary when we are working with a dataset with
    extreme imbalance. The [MLDataUtils](https://mldatautilsjl.readthedocs.io/en/latest/index.html#)
    package in Julia provides a series of preprocessing functions including data splitting,
    label encoding, and feature normalisation. The following code shows how to perform
    stratified sampling using the `stratifiedobs` function from [MLDataUtils](https://mldatautilsjl.readthedocs.io/en/latest/index.html#).
    A random seed can be set so that the same data split can be reproduced.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练分类模型时，数据通常以分层的方式进行训练和测试划分。主要目的是在训练数据和测试数据中保持数据相对于目标类变量的分布。这在处理极度不平衡的数据集时尤其必要。[MLDataUtils](https://mldatautilsjl.readthedocs.io/en/latest/index.html#)
    包在 Julia 中提供了一系列预处理函数，包括数据划分、标签编码和特征归一化。以下代码展示了如何使用 [MLDataUtils](https://mldatautilsjl.readthedocs.io/en/latest/index.html#)
    的 `stratifiedobs` 函数进行分层抽样。可以设置随机种子以便重现相同的数据划分。
- en: Split data for training and test — Julia implementation
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据划分用于训练和测试 — Julia 实现
- en: The usage of the stratifiedobs function is quite similar to the train_test_split
    function from the sklearn library in Python. Take note that the input features
    X need to go through twice of transpose to restore the original dimensions of
    the dataset. This can be confusing for a Julia novice like me. I’m not sure why
    the author of [MLDataUtils](https://mldatautilsjl.readthedocs.io/en/latest/index.html#)
    developed the function in this way.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`stratifiedobs` 函数的使用与 Python 中 sklearn 库的 `train_test_split` 函数非常相似。请注意，输入特征
    X 需要经过两次转置以恢复数据集的原始维度。这对于像我这样的 Julia 新手来说可能会令人困惑。我不确定 [MLDataUtils](https://mldatautilsjl.readthedocs.io/en/latest/index.html#)
    的作者为何这样开发这个函数。'
- en: The equivalent Python sklearn implementation is as follows.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 等效的 Python sklearn 实现如下。
- en: '![](../Images/3e9ea400baf6f37072dd3dbc1e28af74.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e9ea400baf6f37072dd3dbc1e28af74.png)'
- en: Split data for training and test — Python implementation (Image by author)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据划分用于训练和测试 — Python 实现（图片来源于作者）
- en: Feature scaling
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征缩放
- en: As a recommended practice in machine learning, feature scaling brings the features
    to the same or similar ranges of values or distribution. Feature scaling helps
    improve the speed of convergence when training neural networks, and also avoids
    the domination of any individual feature during training.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作为机器学习中的推荐实践，特征缩放将特征调整到相同或类似的值范围或分布。特征缩放有助于提高训练神经网络时的收敛速度，并且避免了在训练过程中某个特征的主导地位。
- en: Although we are not training a neural network model in this work, I’d still
    like to find out how feature scaling can be performed in Julia. Unfortunately,
    I could not find a Julia library which provides both functions of fitting scaler
    and transforming features. The [feature normalization functions](https://mldatautilsjl.readthedocs.io/en/latest/data/feature.html)
    provided in the MLDataUtils package allow users to derive the mean and standard
    deviation of the features, but they cannot be easily applied on the training /
    test datasets to transform the features. Since the mean and standard deviation
    of the features can be easily calculated in Julia, we can implement the process
    of standard scaling manually.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在这项工作中没有训练神经网络模型，但我仍然想了解如何在 Julia 中进行特征缩放。不幸的是，我找不到一个同时提供缩放器拟合和特征变换功能的 Julia
    库。[特征归一化函数](https://mldatautilsjl.readthedocs.io/en/latest/data/feature.html)由
    MLDataUtils 包提供，允许用户推导特征的均值和标准差，但不能方便地应用于训练/测试数据集以进行特征变换。由于特征的均值和标准差可以在 Julia
    中轻松计算，我们可以手动实现标准缩放过程。
- en: The following code creates a copy of X_train and X_test, and calculates the
    mean and standard deviation of each feature in a loop.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码创建了 X_train 和 X_test 的副本，并在循环中计算每个特征的均值和标准差。
- en: Standadize features — Julia implementation
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化特征 — Julia 实现
- en: The transformed and original features are shown as follows.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 变换后的特征和原始特征如下所示。
- en: '![](../Images/9608d482d04912956f856e6f1dc422d7.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9608d482d04912956f856e6f1dc422d7.png)'
- en: Scaled features vs. orginal features — Julia implementation (Image by author)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 缩放后的特征与原始特征 — Julia 实现（图像作者提供）
- en: In Python, sklearn provides various options for feature scaling, including normalization
    and standardization. By declaring a feature scaler, the scaling can be done with
    two lines of code. The following code gives an example of using a [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，sklearn 提供了多种特征缩放选项，包括归一化和标准化。通过声明一个特征缩放器，可以用两行代码完成缩放。以下代码展示了如何使用一个[RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)的示例。
- en: '![](../Images/845227f504791224f4e127212246e518.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/845227f504791224f4e127212246e518.png)'
- en: Perform robust scaling to the features — Python implementation (Image by author)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对特征进行鲁棒缩放 — Python 实现（图像作者提供）
- en: Oversampling (by PyCall)
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过采样（通过 PyCall）
- en: A fraud detection dataset is typically severely imbalanced. For instance, the
    ratio of negative over positive examples of our dataset is above 500:1\. Since
    obtaining more data points is not possible, undersampling will result in a huge
    loss of data points from the majority class, oversampling becomes the best option
    in this case. Here I apply the popular SMOTE method to create synthetic examples
    for the positive class.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 欺诈检测数据集通常严重不平衡。例如，我们的数据集中负样本与正样本的比例超过了 500:1。由于无法获取更多的数据点，欠采样将导致多数类数据点的大量丢失，在这种情况下，过采样成为最佳选择。在这里，我使用了流行的
    SMOTE 方法来为正类创建合成样本。
- en: Currently, there is no working Julia library which provides implementation of
    SMOTE. The [ClassImbalance](https://github.com/bcbi/ClassImbalance.jl) package
    has not been maintained for two years, and cannot be used with the recent versions
    of Julia. Fortunately, Julia allows us to call the ready-to-use Python packages
    using a wrapper library called [PyCall](https://github.com/JuliaPy/PyCall.jl).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，没有可用的 Julia 库提供 SMOTE 的实现。[ClassImbalance](https://github.com/bcbi/ClassImbalance.jl)
    包已经有两年未维护，无法与最近的 Julia 版本兼容。幸运的是，Julia 允许我们使用一个名为[PyCall](https://github.com/JuliaPy/PyCall.jl)的包装库来调用现成的
    Python 包。
- en: To import a Python library to Julia, we need to install PyCall and specify the
    PYTHONPATH as an environment variable. I tried create a Python virtual environment
    here but it did not work out. Due to some reason, Julia cannot recognize the python
    path of the virtual environment. This is why I have to specify the system default
    python path. After this, we can import the Python implementation of SMOTE, which
    is provided in the [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn)
    library. The `pyimport` function provided by PyCall can be used to import the
    Python libraries in Julia. The following code shows how to activate PyCall and
    ask for help from Python in a Julia kernel.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Python 库导入 Julia，我们需要安装 PyCall 并将 PYTHONPATH 指定为环境变量。我尝试创建一个 Python 虚拟环境，但没有成功。由于某种原因，Julia
    无法识别虚拟环境的 Python 路径。因此，我不得不指定系统默认的 Python 路径。之后，我们可以导入由[imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn)库提供的
    Python 实现的 SMOTE。PyCall 提供的 `pyimport` 函数可以用于在 Julia 中导入 Python 库。以下代码展示了如何在 Julia
    内核中激活 PyCall 并寻求 Python 的帮助。
- en: Upsample training data with SMOTE — Julia implementation
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SMOTE 进行上采样训练数据 — Julia 实现
- en: The equivalent Python implementation is as follows. We can see the fit_resample
    function is used in the same way in Julia.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的 Python 实现如下。我们可以看到，`fit_resample` 函数在 Julia 中的用法是相同的。
- en: '![](../Images/9332c8f1e4c1ca50714575926017ca9d.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9332c8f1e4c1ca50714575926017ca9d.png)'
- en: Upsample training data with SMOTE — Python implementation (Image by author)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SMOTE 进行上采样训练数据 — Python 实现（图片由作者提供）
- en: Model Training
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: Now we reach the stage of model training. We will be training a binary classifier,
    which can be done with a variety of ML algorithms, including logistic regression,
    decision tree, and neural networks. Currently, the resources for ML in Julia are
    distributed across multiple Julia libraries. Let me list down a few most popular
    options with their specialised set of models.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们进入模型训练阶段。我们将训练一个二分类器，这可以通过多种机器学习算法完成，包括逻辑回归、决策树和神经网络。目前，Julia 中的机器学习资源分布在多个
    Julia 库中。让我列出几个最受欢迎的选项及其专业化的模型。
- en: '[MLJ](https://github.com/alan-turing-institute/MLJ.jl): traditional ML algorithms'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLJ](https://github.com/alan-turing-institute/MLJ.jl)：传统机器学习算法'
- en: '[ScikitLearn](https://github.com/cstjean/ScikitLearn.jl): traditional ML algorithms'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ScikitLearn](https://github.com/cstjean/ScikitLearn.jl)：传统机器学习算法'
- en: '[Mocha](https://github.com/pluskid/Mocha.jl): neural networks'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mocha](https://github.com/pluskid/Mocha.jl)：神经网络'
- en: '[Flux](https://github.com/FluxML/Flux.jl): neural networks'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Flux](https://github.com/FluxML/Flux.jl)：神经网络'
- en: Here I’m going to choose [XGBoost](https://github.com/dmlc/XGBoost.jl), considering
    its simplicity and superior performance over the traditional regression and classification
    problems. The process of training a XGBoost model in Julia is the same as that
    of Python, albeit there’s some minor difference in syntax.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我选择了[XGBoost](https://github.com/dmlc/XGBoost.jl)，考虑到它的简洁性和在传统回归及分类问题上的卓越表现。训练
    XGBoost 模型的过程在 Julia 中与 Python 相同，尽管语法上有一些小的差异。
- en: Train a fraud detection model with XGBoost — Julia implementation
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 XGBoost 训练欺诈检测模型 — Julia 实现
- en: The equivalent Python implementation is as follows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的 Python 实现如下。
- en: '![](../Images/f71e95666783f20e286643e7ac84b985.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f71e95666783f20e286643e7ac84b985.png)'
- en: Train a fraud detection model with XGBoost — Python implementation (Image by
    author)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 XGBoost 训练欺诈检测模型 — Python 实现（图片由作者提供）
- en: Model Evaluation
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: Finally, let’s look at how our model performs by looking at the precision, recall
    obtained on the test data, as well as the time spent on training the model. In
    Julia, the precision, recall metrics can be calculated using the [EvalMetrics](https://github.com/VaclavMacha/EvalMetrics.jl)
    library. An alternative package is [MLJBase](https://github.com/JuliaAI/MLJBase.jl)
    for the same purpose.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们通过查看在测试数据上获得的精度、召回率，以及训练模型所花费的时间来评估模型的表现。在 Julia 中，精度、召回率指标可以通过[EvalMetrics](https://github.com/VaclavMacha/EvalMetrics.jl)库计算。另一个可以实现相同目的的包是[MLJBase](https://github.com/JuliaAI/MLJBase.jl)。
- en: Make prediction and calculate metrics — Julia implementation
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 进行预测和计算指标 — Julia 实现
- en: In Python, we can employ sklearn to calculate the metrics.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，我们可以使用 sklearn 来计算指标。
- en: '![](../Images/82b89478a38a1dc21b83edcb0225f687.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/82b89478a38a1dc21b83edcb0225f687.png)'
- en: Make prediction and calculate metrics — Python implementation (Image by author)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 进行预测和计算指标 — Python 实现（图片由作者提供）
- en: So which is the winner between Julia and Python? To make a fair comparison,
    the two models were both trained with the default hyperparameters, and learning
    rate = 0.1, no. of estimators = 1000\. The performance metrics are summarised
    in the following table.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 Julia 和 Python 哪个是赢家？为了公平比较，两种模型都使用默认超参数进行训练，学习率 = 0.1，估算器数量 = 1000。性能指标总结在下面的表格中。
- en: It can be observed that the Julia model achieves a better precision and recall
    with a slightly longer training time. Since the [XGBoost](https://github.com/dmlc/xgboost)
    library used for training the Python model is written in C++ under the hood, whereas
    the [Julia XGBoost](https://github.com/dmlc/XGBoost.jl) library is completely
    written in Julia, Julia does run as fast as C++, just as it claimed!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 可以观察到，Julia 模型在训练时间稍长的情况下，达到了更好的精确度和召回率。由于用于训练 Python 模型的 [XGBoost](https://github.com/dmlc/xgboost)
    库底层是用 C++ 编写的，而 [Julia XGBoost](https://github.com/dmlc/XGBoost.jl) 库完全用 Julia
    编写，Julia 的运行速度确实与 C++ 一样快，就像它所声称的那样！
- en: 'The hardware used for the aforementioned test: 11th Gen Intel® Core™ i7–1165G7
    @ 2.80GHz — 4 cores.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 用于上述测试的硬件：第11代 Intel® Core™ i7–1165G7 @ 2.80GHz — 4 核心。
- en: Jupyter notebook can be found on [Github](https://github.com/shenghaowang/shenghao-blogs-work/tree/main/julia-traditional-ml).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter notebook 可以在 [Github](https://github.com/shenghaowang/shenghao-blogs-work/tree/main/julia-traditional-ml)
    找到。
- en: Takeways
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收获
- en: I’d like to end this series with a summary of the mentioned Julia libraries
    for different data science tasks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我想以对不同数据科学任务的 Julia 库的总结结束这一系列内容。
- en: Due to the lack of community support, the usability of Julia cannot be compared
    to Python at the moment. Nonetheless, given its superior performance, Julia still
    has a great potential in future.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缺乏社区支持，目前 Julia 的可用性无法与 Python 相比。然而，鉴于其优越的性能，Julia 仍然在未来具有很大的潜力。
- en: '**References**'
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: '[Machine Learning Group of ULB (Université Libre de Bruxelles)](http://mlg.ulb.ac.be/).
    (no date). *Credit Card Fraud Detection* [Dataset]. [H](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)i
    i (Database Contents License (DbCL))'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[布鲁塞尔自由大学机器学习小组 (Université Libre de Bruxelles)](http://mlg.ulb.ac.be/)。 (无日期)。*信用卡欺诈检测*
    [数据集]。[H](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)i i (数据库内容许可证
    (DbCL))'
- en: 'Akshay Gupta. May 13, 2021\. *Start Machine Learning With Julia: Top Julia
    Libraries for Machine Learning*. [https://www.analyticsvidhya.com/blog/2021/05/top-julia-machine-learning-libraries/](https://www.analyticsvidhya.com/blog/2021/05/top-julia-machine-learning-libraries/)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akshay Gupta. 2021年5月13日。*使用 Julia 开始机器学习：顶级 Julia 机器学习库*。[https://www.analyticsvidhya.com/blog/2021/05/top-julia-machine-learning-libraries/](https://www.analyticsvidhya.com/blog/2021/05/top-julia-machine-learning-libraries/)
