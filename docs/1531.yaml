- en: Train Image Segmentation Models to Accept User Feedback via Voronoi Tiling,
    Part 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Voronoi分割训练图像分割模型以接受用户反馈，第二部分
- en: 原文：[https://towardsdatascience.com/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9?source=collection_archive---------7-----------------------#2023-05-05](https://towardsdatascience.com/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9?source=collection_archive---------7-----------------------#2023-05-05)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9?source=collection_archive---------7-----------------------#2023-05-05](https://towardsdatascience.com/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9?source=collection_archive---------7-----------------------#2023-05-05)
- en: How to train an off-the-shelf image segmentation model to respond to user feedback
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何训练现成的图像分割模型以响应用户反馈
- en: '[](https://florin-andrei.medium.com/?source=post_page-----1f02eebbddb9--------------------------------)[![Florin
    Andrei](../Images/372ac3e80dbc03cbd20295ec1df5fa6f.png)](https://florin-andrei.medium.com/?source=post_page-----1f02eebbddb9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1f02eebbddb9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1f02eebbddb9--------------------------------)
    [Florin Andrei](https://florin-andrei.medium.com/?source=post_page-----1f02eebbddb9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://florin-andrei.medium.com/?source=post_page-----1f02eebbddb9--------------------------------)[![Florin
    Andrei](../Images/372ac3e80dbc03cbd20295ec1df5fa6f.png)](https://florin-andrei.medium.com/?source=post_page-----1f02eebbddb9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1f02eebbddb9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1f02eebbddb9--------------------------------)
    [Florin Andrei](https://florin-andrei.medium.com/?source=post_page-----1f02eebbddb9--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faeaeb9d7d248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9&user=Florin+Andrei&userId=aeaeb9d7d248&source=post_page-aeaeb9d7d248----1f02eebbddb9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1f02eebbddb9--------------------------------)
    ·9 min read·May 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1f02eebbddb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9&user=Florin+Andrei&userId=aeaeb9d7d248&source=-----1f02eebbddb9---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faeaeb9d7d248&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9&user=Florin+Andrei&userId=aeaeb9d7d248&source=post_page-aeaeb9d7d248----1f02eebbddb9---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1f02eebbddb9--------------------------------)
    ·9分钟阅读·2023年5月5日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1f02eebbddb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9&user=Florin+Andrei&userId=aeaeb9d7d248&source=-----1f02eebbddb9---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1f02eebbddb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9&source=-----1f02eebbddb9---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1f02eebbddb9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftrain-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-2-1f02eebbddb9&source=-----1f02eebbddb9---------------------bookmark_footer-----------)'
- en: This is Part 2 of a series of articles about training image segmentation models
    so that the models respond to user feedback and adjust their predictions based
    on the feedback (mouse clicks).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于训练图像分割模型以便这些模型可以响应用户反馈并根据反馈（鼠标点击）调整预测的系列文章的第二部分。
- en: '[In Part 1](https://medium.com/towards-data-science/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-1-8ab85d410d29)
    we’ve described the general strategy for training off-the-shelf image segmentation
    models to respond to user feedback. The problem identified at the end of [Part
    1](https://medium.com/towards-data-science/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-1-8ab85d410d29)
    was that manually generating the clicks needed to train the models is tedious,
    time-consuming, and may not be feasible at all if the datasets are very large
    and/or the models need to be re-trained often. Generating the clicks needs to
    be automated — this is the topic of this article.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[第1部分](https://medium.com/towards-data-science/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-1-8ab85d410d29)中，我们描述了训练现成图像分割模型以响应用户反馈的一般策略。[第1部分](https://medium.com/towards-data-science/train-image-segmentation-models-to-accept-user-feedback-via-voronoi-tiling-part-1-8ab85d410d29)结束时识别出的问题是，手动生成训练模型所需的点击是繁琐且耗时的，如果数据集非常大和/或模型需要频繁重新训练，这可能根本不可行。生成点击需要自动化——这就是本文的主题。'
- en: The Problem
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Let’s take a look again at the problem we’re trying to solve:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一看我们试图解决的问题：
- en: '![](../Images/8a8ae7bf47de6111503eb31dd631d71e.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8a8ae7bf47de6111503eb31dd631d71e.png)'
- en: 'source: Dataset of Breast Ultrasound Images'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：乳腺超声图像数据集
- en: The left-hand frame is the image with the ground-truth label; the region of
    interest (RoI) was marked in yellow by a human expert; this is the ideal shape
    of the prediction we expect from the model. The center frame is the actual prediction
    from the model. The right-hand frame shows true positive areas (where the label
    and the prediction coincide), false positive areas (where the model predicts an
    RoI but there is no such thing in the label), and false negative areas (where
    the model predicts nothing, but there is an actual RoI). TP areas are shown in
    white, FP in green, and FN in red.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧框是带有真实标签的图像；人类专家用黄色标记了感兴趣区域（RoI）；这是我们期望模型预测的理想形状。中间框是模型的实际预测。右侧框显示了真实阳性区域（标签和预测重合的地方）、假阳性区域（模型预测为RoI，但标签中没有此区域），以及假阴性区域（模型未预测任何内容，但实际存在RoI）。TP区域以白色显示，FP区域以绿色显示，FN区域以红色显示。
- en: To steer the model’s predictions, we’ve placed positive (green) clicks in the
    TP and FN areas, and negative (red) clicks in the FP areas, and then trained new
    models with the clicks included in the images.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了引导模型的预测，我们在TP和FN区域放置了正点击（绿色），在FP区域放置了负点击（红色），然后用包含点击的图像训练了新的模型。
- en: 'Placing the clicks is intuitively easy for a human operator. But if you break
    down the process into separate logical steps and criteria, it gets quite convoluted:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于人类操作员来说，放置点击直观上是简单的。但如果将过程分解成独立的逻辑步骤和标准，它会变得相当复杂：
- en: split TP, FP, FN areas into separate contiguous segments
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将TP、FP、FN区域拆分成独立的连续段
- en: discard very small segments as irrelevant
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丢弃非常小的段作为无关内容
- en: for each remaining segment, decide on the total number of clicks that will be
    placed within, based on the segment area
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个剩余的区域，根据区域面积决定要放置的总点击数
- en: the clicks cannot be placed too close to each other
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击不能彼此太近
- en: the clicks cannot be placed too close to the edge of the segment
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击不能太靠近区域边缘
- en: The last two criteria are hard. The ambiguity (“not too close”) and the fact
    that these two criteria contradict each other, make it seem like it would be difficult
    to generate the clicks in a way that is guaranteed to converge to a solution that
    imitates what a human operator would do.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个标准很困难。模糊性（“不能太近”）以及这两个标准相互矛盾，使得生成点击的过程看似很难保证能收敛到模拟人类操作员所做的解决方案。
- en: However, we will show there is such a method, which combines a mathematical
    concept (Voronoi tesselation) with hints from physics (energy, and simulated annealing)
    to produce the desired result.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们将展示一种方法，它结合了数学概念（Voronoi镶嵌）与物理学的提示（能量和模拟退火），以产生所需的结果。
- en: Voronoi Tesselation
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Voronoi镶嵌
- en: '[The Wikipedia page](https://en.wikipedia.org/wiki/Voronoi_diagram) explains
    the concept quite well, and this may seem familiar if you’ve studied the algorithm
    behind [k-means clustering](https://en.wikipedia.org/wiki/K-means_clustering),
    but let me add a few words here as well.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[维基百科页面](https://en.wikipedia.org/wiki/Voronoi_diagram)对该概念的解释相当到位，如果你研究过[聚类算法](https://en.wikipedia.org/wiki/K-means_clustering)，这可能会感到熟悉，但我在这里也补充几句。'
- en: '![](../Images/3cab9b1020ca213a09e02274f0b7db8f.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3cab9b1020ca213a09e02274f0b7db8f.png)'
- en: In the left-hand frame, we have a square area with a few seed points. For any
    seed point, there must be a region in the frame (a tile) in which all pixels are
    closer to that seed than to all the other seeds. In the right-hand frame we show
    these tiles, color-coded to match the seeds. Each tile is called a Voronoi cell,
    and the result of the process of finding the tiles is called Voronoi tesselation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧框架中，我们有一个带有几个种子点的正方形区域。对于任何种子点，框架中必须有一个区域（一个瓦片），其中所有像素距离该种子点比距离其他所有种子点更近。在右侧框架中，我们显示了这些瓦片，用颜色编码以匹配种子。每个瓦片被称为Voronoi单元，而寻找这些瓦片的过程称为Voronoi镶嵌。
- en: 'The seeds in this example are chosen randomly. The tesselation we get is not
    uniform. To get a uniform tesselation, the seeds would have to also be the centroids
    of their corresponding tiles (or close to the centroids) — this is called [centroidal
    Voronoi tesselation](https://en.wikipedia.org/wiki/Centroidal_Voronoi_tessellation).
    Here is a very trivial example out of many possible examples:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子中的种子是随机选择的。我们得到的镶嵌不是均匀的。为了获得均匀的镶嵌，种子还必须是其对应瓦片的质心（或接近质心）——这称为[质心Voronoi镶嵌](https://en.wikipedia.org/wiki/Centroidal_Voronoi_tessellation)。这里是一个非常简单的例子：
- en: '![](../Images/fae8daec08441cf7d34fbc971216a2b6.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fae8daec08441cf7d34fbc971216a2b6.png)'
- en: 'To find the click coordinates (the seeds) that would lead to a centroidal Voronoi
    tesselation of an area, or an approximation, something like [Lloyd’s algorithm](https://en.wikipedia.org/wiki/Lloyd%27s_algorithm)
    could be used, and it’s very fast (it is the standard solver for [k-means clustering](https://en.wikipedia.org/wiki/K-means_clustering)).
    Here is [a simulator for Lloyd’s algorithm](http://www.bitbanging.space/posts/lloyds-algorithm)
    which works in your browser in real time. But there are two problems:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到能导致区域的质心Voronoi镶嵌或其近似的点击坐标（种子），可以使用类似于[Lloyd算法](https://en.wikipedia.org/wiki/Lloyd%27s_algorithm)的东西，它非常快速（是[
    k均值聚类](https://en.wikipedia.org/wiki/K-means_clustering)的标准解算器）。这是一个[ Lloyd算法的模拟器](http://www.bitbanging.space/posts/lloyds-algorithm)，可以在你的浏览器中实时运行。但这里有两个问题：
- en: Lloyd’s algorithm is generally used to tile rectangular areas. It is not clear
    how (or whether) it would generalize to the arbitrary area shapes we need to tile
    for our models.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lloyd算法通常用于镶嵌矩形区域。尚不清楚它是否（或如何）推广到我们需要镶嵌的任意区域形状。
- en: We only want centroidal tiling when the shapes (area and tiles) are convex.
    When the shapes are concave, the centroids may fall outside the area we’re tiling,
    and that’s not what we want at all (the clicks would be outside the area).
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们只希望在形状（区域和瓦片）为凸时使用质心镶嵌。当形状为凹时，质心可能会落在我们镶嵌区域之外，这完全不是我们想要的（点击点会在区域之外）。
- en: So we need something that works with arbitrary shapes, keeps the clicks inside
    the area even when the shapes are concave, and behaves like Lloyd’s algorithm
    for trivial rectangular areas. A generalization of centroidal Voronoi tiling,
    that works with arbitrary areas, even with concave shapes. That’s the topic of
    the next section.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们需要一种能处理任意形状的方案，它能在形状凹陷时保持点击点在区域内，并且在处理简单矩形区域时表现得像Lloyd算法。这是对任意区域（即使是凹形）的质心Voronoi镶嵌的概括。这是下一节的主题。
- en: Simulated Annealing for Energy
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 能量的模拟退火
- en: 'Consider this tiling:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这种镶嵌：
- en: '![](../Images/1a3a4211bf55591d53f1e04fff47ddc9.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a3a4211bf55591d53f1e04fff47ddc9.png)'
- en: The click distribution is uniform enough, and the click coordinates are not
    far from the centroids (all shapes are convex). It’s not a bad distribution for
    our purposes. Can we find an objective function, corresponding to the click coordinates,
    that we could try to maximize or minimize, iteratively, that would lead us to
    such a distribution?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 点击分布足够均匀，点击坐标与质心的距离不远（所有形状均为凸形）。这对于我们的目的来说分布还不错。我们能否找到一个与点击坐标对应的目标函数，尝试迭代地最大化或最小化，以达到这样的分布？
- en: 'Let’s look at the space around the clicks:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看点击周围的空间：
- en: '![](../Images/e9ac35976c0792a2f744c61f498d4b8d.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e9ac35976c0792a2f744c61f498d4b8d.png)'
- en: heat map of pixel energy
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 像素能量的热图
- en: 'Imagine every pixel in the image is assigned an “energy”. Only one click contributes
    to the pixel’s energy — the closest click. All other clicks do not contribute
    at all. The energy of any pixel is inversely proportional to its distance to its
    nearest click. So to find the energy of any pixel, we need to:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 想象每个图像中的像素都被分配了一个“能量”。只有一个点击对像素的能量有贡献——最接近的点击。其他所有点击都没有贡献。任何像素的能量与其到最近点击的距离成反比。因此，要找出任何像素的能量，我们需要：
- en: find the nearest click
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找到最近的点击
- en: calculate the distance from the pixel to the click
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算像素到点击的距离
- en: calculate the inverse of the distance, which is the pixel’s energy
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算距离的倒数，即像素的能量
- en: The image shown above is just the heat map of pixel energies, given the click
    distribution. The edges of the Voronoi tiles are already suggested by the darkest
    areas mid-way between neighboring clicks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上面展示的图像只是给定点击分布的像素能量热图。Voronoi图块的边缘已经由邻近点击之间最暗的区域所提示。
- en: 'If we calculate the total energy of all pixels, and then move the clicks around,
    seeking the click positions that give the highest total energy, would that lead
    to a uniform tiling of the area? As a matter of fact, that’s exactly how the click
    distribution shown above was obtained:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们计算所有像素的总能量，然后移动点击，寻找提供最高总能量的点击位置，这会导致区域的均匀铺设吗？实际上，这正是上面展示的点击分布的获取方式：
- en: start with completely random click coordinates
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从完全随机的点击坐标开始
- en: compute the total energy of all pixels in the region of interest
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算感兴趣区域内所有像素的总能量
- en: apply [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing)
    to the click coordinates, so as to find the coordinates that maximize total energy
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对点击坐标应用[模拟退火](https://en.wikipedia.org/wiki/Simulated_annealing)，以找到最大化总能量的坐标
- en: 'The full code [is shown here](https://github.com/FlorinAndrei/segmentation_click_train/blob/main/uniform_clicks.py).
    The algorithm is robust and can handle concave shapes just fine — here is an example
    of placing clicks in a visually uniform way within a sickle-shaped segment:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码[在这里展示](https://github.com/FlorinAndrei/segmentation_click_train/blob/main/uniform_clicks.py)。该算法很强大，可以很好地处理凹形状——这是一个在镰刀形分割中以视觉上均匀的方式放置点击的示例：
- en: '![](../Images/24776028c12c4a5ee29a732567d07c34.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/24776028c12c4a5ee29a732567d07c34.png)'
- en: placing clicks in a concave shape
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在凹形中放置点击
- en: The segment is the lighter shade of blue, the shape of a sickle, that stands
    in contrast with the dark background. The clicks are the brightest spots.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 分割区域是较浅的蓝色阴影，形状像镰刀，与深色背景形成对比。点击是最亮的点。
- en: The clicks do not get too close to the edge of the segment, because that would
    reduce the total energy (pixels beyond the segment’s edge have no energy). They
    do not get too close to each other, because that would not “energize” pixels far
    from the tight group of clicks. The algorithm is self-regulating.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 点击不会离分割边缘太近，因为那样会减少总能量（分割边缘之外的像素没有能量）。它们也不会彼此靠得太近，因为那样不会“激活”远离紧密点击组的像素。该算法是自我调节的。
- en: 'Note: this problem has similarities to the cell phone tower coverage problem,
    where you try to place N cell phone towers on a map such that the signal is as
    strong as possible in most areas.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注：这个问题与手机塔覆盖问题有相似之处，即你尝试在地图上放置N个手机塔，使得信号在大多数区域尽可能强。
- en: Back to Segmentation Models
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 返回到分割模型
- en: 'To recap, we’re trying to train image segmentation models to make them responsive
    to user feedback (mouse clicks). [The overall process](https://github.com/FlorinAndrei/segmentation_click_train/blob/main/train_models.ipynb)
    is:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们尝试训练图像分割模型，使其对用户反馈（鼠标点击）做出响应。[总体过程](https://github.com/FlorinAndrei/segmentation_click_train/blob/main/train_models.ipynb)是：
- en: split the image dataset into 5 folds
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图像数据集分成5个折
- en: train a segmentation model for each fold; this produces the set of 5 **baseline
    models**
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个折训练一个分割模型；这会生成一组5个**基线模型**
- en: use the baseline models to make predictions on all images; each model makes
    predictions on images it has not seen in training
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基线模型对所有图像进行预测；每个模型对训练中未见过的图像进行预测
- en: compare predictions with labels; extract all areas containing true positive,
    false positive, false negative predictions
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较预测与标签；提取所有包含真正阳性、假阳性、假阴性预测的区域
- en: split the TP, FP, FN areas into contiguous segments; discard the smallest segments
    (less than 100 pixels or so)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将TP、FP、FN区域拆分成连续的段；丢弃最小的段（少于100个像素或更少）
- en: 'for each segment, generate uniform clicks as shown in this article; the number
    of clicks depends on the area of the segment: bigger segments receive more clicks,
    up to a reasonable limit (4 … 5 or so, for images 512x512 pixels in size)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个区域，生成均匀的点击，如本文所示；点击次数取决于区域的大小：较大的区域会收到更多的点击，直到一个合理的限制（例如，512x512 像素的图像大约为
    4 … 5 次）。
- en: move all image information into the B channel, vacate the R and G channels,
    embed the clicks into the R and G channels; clicks for the TP and FN areas are
    in the G channel (positive clicks); clicks for the FP areas are in the R channel
    (negative clicks)
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将所有图像信息移至 B 通道，腾出 R 和 G 通道，将点击嵌入 R 和 G 通道；TP 和 FN 区域的点击在 G 通道（正点击）；FP 区域的点击在
    R 通道（负点击）。
- en: using the click-augmented images, train a new set of 5 models on the same folds;
    these are the **click-trained models**, which are the final artifact of this whole
    project
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用点击增强图像，在相同的折叠上训练 5 个新的模型；这些是**点击训练模型**，是整个项目的最终成果。
- en: Here are some examples of uniform clicks generated for image segments from the
    actual baseline model predictions. We’ve picked 3 images from the dataset, made
    predictions with the baseline models, and we look at each image’s TP, FP, FN segments.
    Each segment is a lighter shade of blue than the background, and the clicks are
    the brightest spots in each segment.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是从实际基线模型预测中生成的图像区域均匀点击的一些示例。我们从数据集中选择了 3 张图像，使用基线模型进行预测，并查看每张图像的 TP、FP、FN
    区域。每个区域的颜色比背景色浅，点击是每个区域中最亮的点。
- en: '![](../Images/638f6400223efec0ebcd0f6f61ddc3ed.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/638f6400223efec0ebcd0f6f61ddc3ed.png)'
- en: 'source: Dataset of Breast Ultrasound Images'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：乳腺超声图像数据集
- en: 'The clicks end up being placed more or less where a human operator would place
    them: not too close to each other, not too close to the edge, favoring bulk or
    wide areas in each segment. The click distribution appears to be visually uniform.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 点击最终被放置在一个或多或少符合人工操作员放置位置的地方：彼此之间距离不太近，距离边缘也不太近，偏向于每个区域中的大面积或宽区域。点击分布似乎在视觉上是均匀的。
- en: Final Thoughts
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: We’ve trained off-the-shelf image segmentation models to respond to user feedback,
    without altering their architecture in any way, and without re-training them from
    scratch on ImageNet.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练了现成的图像分割模型来响应用户反馈，而没有以任何方式更改其架构，也没有在 ImageNet 上从头开始重新训练它们。
- en: The click-trained models do not necessarily perform better than the baseline
    models. Training with clicks as shown here only enables the models to respond
    to user feedback. Sure, the click-trained models will outperform the baseline
    models by a large margin on the dataset used to create the 5 training folds. That’s
    because creating the clicks essentially leaks data between training and testing.
    On data that is 100% previously unseen, the click-trained models and the baseline
    models perform the same.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 点击训练模型的表现不一定优于基线模型。正如这里所示，使用点击进行训练只是使模型能够响应用户反馈。当然，点击训练模型在用于创建 5 个训练折叠的数据集上会远远优于基线模型。这是因为创建点击本质上在训练和测试之间泄漏了数据。在
    100% 之前未见过的数据上，点击训练模型和基线模型的表现相同。
- en: Here are a couple more examples of the way the click-trained models respond
    to user feedback.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有更多点击训练模型对用户反馈响应的示例。
- en: Two different images are shown in the video. In both images you can see the
    model has high confidence in its predicted RoI. Attempts to place negative clicks
    in the predicted RoI are not very successful — the model continues to predict
    that region as an RoI.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 视频中展示了两张不同的图像。在这两张图像中，你可以看到模型对其预测的 RoI 有很高的信心。尝试在预测的 RoI 中放置负点击不是很成功——模型继续预测该区域为
    RoI。
- en: The model does accept suggestions for other areas as potential RoIs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 模型接受对其他区域作为潜在 RoI 的建议。
- en: 'In both cases you can see two kinds of outputs from the model: pure segmentation,
    and heat map. The heat map is simply a map of likelihood for the RoI.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，你可以看到模型的两种输出：纯分割和热图。热图只是 RoI 可能性的地图。
- en: Links, Citations, Comments
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 链接、引用、评论
- en: 'This project is an extension of my capstone project from the final semester
    of my MS in Data Science studies: [https://github.com/FlorinAndrei/datascience_capstone_project](https://github.com/FlorinAndrei/datascience_capstone_project)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这个项目是我在数据科学硕士学习最后一个学期的顶点项目的扩展：[https://github.com/FlorinAndrei/datascience_capstone_project](https://github.com/FlorinAndrei/datascience_capstone_project)
- en: Both the capstone and this work were done within the Computer Aided Diagnosis
    for Breast Ultrasound Imagery (CADBUSI) project at the University of Wisconsin-La
    Crosse, under the supervision of Dr. Jeff Baggett. [https://datascienceuwl.github.io/CADBUSI/](https://datascienceuwl.github.io/CADBUSI/)
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本毕业设计及相关工作都在威斯康辛大学拉克罗斯分校的乳腺超声图像计算机辅助诊断（CADBUSI）项目中完成，由Jeff Baggett博士监督。[https://datascienceuwl.github.io/CADBUSI/](https://datascienceuwl.github.io/CADBUSI/)
- en: 'The GitHub repository with code for this article: [https://github.com/FlorinAndrei/segmentation_click_train](https://github.com/FlorinAndrei/segmentation_click_train)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章的GitHub代码库：[https://github.com/FlorinAndrei/segmentation_click_train](https://github.com/FlorinAndrei/segmentation_click_train)
- en: 'All ultrasound images used in this article are part of the Dataset of Breast
    Ultrasound Images, available under the CC BY 4.0 license. Citation link:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的所有超声图像都属于乳腺超声图像数据集，可在CC BY 4.0许可下使用。引用链接：
- en: Al-Dhabyani, W., Gomaa, M., Khaled, H., & Fahmy, A. (2019). Dataset of Breast
    Ultrasound Images. *ResearchGate*. Retrieved May 1, 2023 from [https://www.sciencedirect.com/science/article/pii/S2352340919312181](https://www.sciencedirect.com/science/article/pii/S2352340919312181)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Al-Dhabyani, W., Gomaa, M., Khaled, H., & Fahmy, A. (2019). 乳腺超声图像数据集。*ResearchGate*。2023年5月1日检索自[https://www.sciencedirect.com/science/article/pii/S2352340919312181](https://www.sciencedirect.com/science/article/pii/S2352340919312181)
- en: 'Other links, citations and comments:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 其他链接、引用和评论：
- en: 'Liu, Q., Zheng, M., Planche, B., Karanam, S., Chen, T., Niethammer, M., & Wu,
    Z. (2022). PseudoClick: Interactive Image Segmentation with Click Imitation. *arXiv.org*.
    Retrieved May 1, 2023, from [https://arxiv.org/abs/2207.05282](https://arxiv.org/abs/2207.05282)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Liu, Q., Zheng, M., Planche, B., Karanam, S., Chen, T., Niethammer, M., & Wu,
    Z. (2022). PseudoClick：带有点击仿真的交互式图像分割。*arXiv.org*。2023年5月1日检索自[https://arxiv.org/abs/2207.05282](https://arxiv.org/abs/2207.05282)
- en: 'Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J. M., & Luo. P. (2021).
    SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers.
    arXiv.org. Retrieved May 1, 2023, from [https://arxiv.org/abs/2105.15203](https://arxiv.org/abs/2105.15203)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J. M., & Luo. P. (2021).
    SegFormer：用于语义分割的简单高效设计与Transformers。arXiv.org。2023年5月1日检索自[https://arxiv.org/abs/2105.15203](https://arxiv.org/abs/2105.15203)
- en: 'Pretrained SegFormer models at HuggingFace: [https://huggingface.co/docs/transformers/model_doc/segformer](https://huggingface.co/docs/transformers/model_doc/segformer)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: HuggingFace的预训练SegFormer模型：[https://huggingface.co/docs/transformers/model_doc/segformer](https://huggingface.co/docs/transformers/model_doc/segformer)
- en: Images in this article that are not part of the Dataset of Breast Ultrasound
    Images are created by the author.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中不属于乳腺超声图像数据集的图像由作者创建。
