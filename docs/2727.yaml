- en: AI-powered Personal VoiceBot for Language Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/ai-powered-personal-voicebot-for-language-learning-5ada0dfb1f9b?source=collection_archive---------2-----------------------#2023-08-28](https://towardsdatascience.com/ai-powered-personal-voicebot-for-language-learning-5ada0dfb1f9b?source=collection_archive---------2-----------------------#2023-08-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@gamzsaglam?source=post_page-----5ada0dfb1f9b--------------------------------)[![Gamze
    Zorlubas](../Images/30d8e1604a22dc6f1bd3ef96c8092cc1.png)](https://medium.com/@gamzsaglam?source=post_page-----5ada0dfb1f9b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5ada0dfb1f9b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5ada0dfb1f9b--------------------------------)
    [Gamze Zorlubas](https://medium.com/@gamzsaglam?source=post_page-----5ada0dfb1f9b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd24f99cbdd78&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-powered-personal-voicebot-for-language-learning-5ada0dfb1f9b&user=Gamze+Zorlubas&userId=d24f99cbdd78&source=post_page-d24f99cbdd78----5ada0dfb1f9b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5ada0dfb1f9b--------------------------------)
    ·11 min read·Aug 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5ada0dfb1f9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-powered-personal-voicebot-for-language-learning-5ada0dfb1f9b&user=Gamze+Zorlubas&userId=d24f99cbdd78&source=-----5ada0dfb1f9b---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5ada0dfb1f9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fai-powered-personal-voicebot-for-language-learning-5ada0dfb1f9b&source=-----5ada0dfb1f9b---------------------bookmark_footer-----------)![](../Images/7ec79878a9cb3bf3da2b34b1d22f9b95.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Created with Stable Diffusion XL — Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: What’s the most effective way to master a new language? Speaking it! But we
    all know how intimidating it can be to try out new words and phrases in front
    of others. What if you had a patient and understanding friend to practice with,
    free from judgment, free from shame?
  prefs: []
  type: TYPE_NORMAL
- en: That patient and understanding friend you’re looking for might just be a virtual
    language tutor powered by LLMs! This could be a game-changing way to master a
    language, all from the comfort of your own space.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, large language models have come onto the scene, and they’re changing
    the way we do things. These powerful tools have created chatbots that can respond
    just like humans, and they’ve quickly integrated into various aspects of our lives,
    being used in hundreds of different ways. One particularly interesting use is
    in language learning, especially when it comes to speaking practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'When I moved to Germany a while ago, I realized how challenging it can be to
    learn a new language and find opportunities to practice speaking it. Classes and
    language groups can be expensive or hard to fit into a busy schedule. As a person
    faced with these challenges, I had an idea: why not use chatbots for speaking
    practice? Texting alone wouldn’t be enough, though, since language learning involves
    more than just writing. Therefore, by combining an AI-powered chatbot with speech-to-text
    and text-to-speech technologies, I managed to create a learning experience that
    feels like talking to a real person.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, I will share the tools I have chosen, explain the process,
    and introduce the concept of speaking practice with an AI chatbot through voice
    commands and voice responses. The pipeline of the project consists of three main
    sections: speech-to-text transcription, employing a language model, and text-to-speech
    conversion. These will be explained under the following three headings.'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Speech-to-Text transcription
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Speech recognition for my language tutor acts as the bridge between the user’s
    spoken input and the AI’s text-based understanding to generate response. It’s
    a critical component that enables voice-driven interaction, contributing to a
    more immersive and effective language learning experience.
  prefs: []
  type: TYPE_NORMAL
- en: Accurate transcription is crucial for a smooth interaction with the Chatbot,
    especially in a language learning context where pronunciation, accent, and grammar
    are the key factors. There are various speech recognition tools which can be utilized
    to transcribe spoken input in Python such as [OpenAI’s Whisper](https://openai.com/research/whisper)
    and [Google Cloud’s Speech-to-Text](https://cloud.google.com/speech-to-text/?utm_source=google&utm_medium=cpc&utm_campaign=emea-de-all-en-dr-bkws-all-all-trial-e-gcp-1011340&utm_content=text-ad-none-any-DEV_c-CRE_574560786447-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt+%7E+AI+%26+ML+%7E+Speech-to-Text%23v19-KWID_43700053284440638-aud-606988877734%3Akwd-316837061214-userloc_9043449&utm_term=KW_google+audio+transcription-NET_g-PLAC_&gad=1&gclid=Cj0KCQjwuZGnBhD1ARIsACxbAVgO097bFIMyTzR-AwuEyAMxC1IGyUr-_T-y8_PM7Lv9dbrOBpOMAqMaAiTNEALw_wcB&gclsrc=aw.ds).
  prefs: []
  type: TYPE_NORMAL
- en: When selecting a speech recognition tool for the language tutor project, considerations
    such as accuracy, language support, cost, and whether an offline solution is required
    should be taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: Google has a [Python API](https://cloud.google.com/speech-to-text/) which requires
    internet connection and offers 60 minutes of transcription per month free of charge.
    Unlike Google, OpenAI published their Whisper model and you can run it locally
    without depending on the internet speed as far as you have enough computational
    power. That’s why I’ve chosen Whisper to reduce the latency of the transcription
    as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Language model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The language model is the backbone of this project. As I am already very acquainted
    with ChatGPT and its [API](https://openai.com/blog/introducing-chatgpt-and-whisper-apis),
    I’ve decided to use it for this project too. However, in case you have enough
    computational power, you can also deploy [Llama](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML)
    locally, which would be free of charge. ChatGPT costs a little money, but a lot
    more convenient as you just need a couple lines of code to run it.
  prefs: []
  type: TYPE_NORMAL
- en: To increase the consistency of responses and to have them in a specific template,
    you could also finetune language models (e.g.[how to finetune chatgpt on your
    use case](https://www.enterprisebot.ai/blog/how-to-finetune-chatgpt-on-your-use-case)).
    You need to generate exemplary sentences and corresponding optimal responses,
    and feed them into a finetuning training. However, the basic tutor I want to build
    doesn’t need a fine-tuning and I will use the generalised GPT3.5-turbo in my project.
  prefs: []
  type: TYPE_NORMAL
- en: I will provide an example of an API call to facilitate a conversation between
    user and ChatGPT via its API in Python, below. First, if you don’t already have
    one, you’ll need to open an OpenAI account and set an API Key to interact with
    ChatGPT. Instructions are given [here](https://www.geeksforgeeks.org/how-to-use-chatgpt-api-in-python/).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve set up your API key, you can begin generating text using the `openai.ChatCompletion.create`
    method. This method requires two parameters: the `model` parameter, which specifies
    the particular GPT model to be accessed via the API, and the `messages` parameter,
    which includes the structure for a conversation with ChatGPT. The `messages` parameter
    consists of two key components: `role` and `content`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a code snippet to illustrate the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `system` role is defined to determine the behaviour of the ChatGPT by adding
    an instruction within the content at the beginning of the message list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During the chat, the `user` message is received from the user via mentioned
    speech recognition model to get a response from ChatGPT.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, ChatGPT’s responses are appended to the message list in the`assistant`role
    to log the conversation history.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3\. Text-to-Speech conversion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the Speech-to-Text transcription section, I explained how the user utilizes
    voice commands to simulate a conversational experience, as if speaking with a
    real person. To further enhance this sensation and create a more dynamic and interactive
    learning experience, the next step involves converting the text output from GPT
    into audible speech using a text-to-speech tool like gTTS. This not only helps
    creating a more engaging and easy-to-follow experience but also addresses a critical
    aspect of language learning: the challenge of comprehension through listening
    rather than reading. By integrating this auditory component, we are facilitating
    a more comprehensive practice that closely mirrors real-world language use.'
  prefs: []
  type: TYPE_NORMAL
- en: There are various TTS tools available, such as Google’s Text-to-Speech (gTTS)
    and IBM Watson’s Text to Speech. In this project, I preferred gTTS since it is
    super easy-to-use, presents a natural voice quality without costing a penny. To
    use the gTTS library, you will need to have an internet connection as the library
    requires access to the Google’s server to convert the text to speech.
  prefs: []
  type: TYPE_NORMAL
- en: Detailed Explanation of the Pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into the pipeline, you might want to take a look at the entire
    code on my [Github](https://github.com/gamzez/language_tutor) page, as I will
    be referring to some sections of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The figure below explains the workflow of AI-powered virtual language tutor
    that is designed to set up a real-time, voice-based conversational learning experience:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/23b3b3a1169fa7c5e3c19235f59c9e99.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart of the pipeline — Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: The user begins the conversation by initiating a recording of their speech,
    temporarily saving it as a .wav file. This is accomplished by pressing and holding
    the spacebar, and the recording is stopped when the spacebar is released. The
    sections of the Python code that enable this press-and-talk functionality are
    explained below.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following global variables are used to manage the state of the recording
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The `listen_for_keys` function is for checking key presses and releases. It
    sets the global variables based on the state of the spacebar and esc button.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The `callback` function is used to handle the audio data when recording. It
    checks the `recording` flag to determine whether to record the incoming audio
    data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `press2record` function is the main function which is responsible for handling
    voice recording when the user presses and holds the spacebar.
  prefs: []
  type: TYPE_NORMAL
- en: It initialises global variables to manage the recording state and determines
    the sample rate, and it creates a temporary file to store the recorded audio.
  prefs: []
  type: TYPE_NORMAL
- en: The function then opens a SoundFile object to write the audio data and an InputStream
    object to capture the audio from the microphone, using the previously mentioned
    `callback` function. A thread is started to listen for key presses, specifically
    the spacebar for recording and the 'esc' key to stop. Inside a loop, the function
    checks the recording flag and writes the audio data to the file if recording is
    active. If the recording is stopped, the function returns -1; otherwise, it returns
    the filename of the recorded audio.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Finally, the `get_voice_command` function calls `press2record` to record user's
    voice command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Having captured and saved the voice command in a temporary .wav file, we now
    enter the transcription phase. In this stage, the recorded audio is converted
    into text using Whisper. The corresponding script for simply running transcription
    task for a .wav file is given below:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This method takes two parameters: the path to the recorded audio file, `saved_file`,
    and an optional flag to use FP16 precision if CUDA is available to enhances performance
    on compatible hardware. It simply returns the transcribed text.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the transcribed text is sent to ChatGPT to generate an appropriate response
    in the `interact_with_tutor()` function. The corresponding code segment is as
    follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The function `interact_with_tutor` starts by defining the system role of ChatGPT
    to shape its behaviour throughout the conversation. Since my goal is to practice
    German, I set the system role accordingly. I called my virtual tutor as “Anna”
    and set my language proficiency level for her to adjust her responses. Additionally,
    I instructed her to keep the conversation engaging by asking questions.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the user’s transcribed voice command is appended to the message list with
    the role of “user.” This message is then sent to ChatGPT. As the conversation
    continues within a while loop, the entire history of user commands and GPT responses
    is logged in the messages list.
  prefs: []
  type: TYPE_NORMAL
- en: After the each response of ChatGPT, we convert the text message into speech
    using gTTS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The `gTTS()` function gets 4 parameters : `text`, `tld`, `lang`, and `slow`.
    The `text` parameter is being assigned the content of the last message in the
    `messages` list (indicated by `[-1]`) which you want to convert into speech. The
    `tld` parameter specifies the top-level domain for the Google Translate service.
    Setting it to `"de"` means that the German domain is used, which can be significant
    for ensuring that the pronunciation and intonation are appropriate for the German.
    The `lang` parameter specifies the language in which the text should be spoken.
    In this code, the `language` variable is set to `''de''`, meaning that the text
    will be spoken in German.`slow=False`: the `slow` parameter controls the speed
    of the speech. Setting it to `False` means that the speech will be spoken at a
    normal speed. If it were set to `True`, the speech would be spoken more slowly.'
  prefs: []
  type: TYPE_NORMAL
- en: The converted speech of ChatGPT response is then saved as a temporary .wav file,
    played back to the user, and then removed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The`interact_with_tutor` function repeatedly runs when user continues the conversation
    by pressing the spacebar again.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the user presses “esc”, conversation ends and the entire conversation is
    saved to a pickle file,`chat_log.pkl`. You can use it later for some analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Command line usage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For running the script, simply run the python code in terminal as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`sudo` is needed as the script requires to access the microphone and utilize
    the keyboard library. If you use anaconda, you can also start the anaconda terminal
    by “run as administrator” to give the full access.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a demo video to show how the code runs on my laptop. You can get a
    feeling of the performance:'
  prefs: []
  type: TYPE_NORMAL
- en: Demo video created by the author
  prefs: []
  type: TYPE_NORMAL
- en: Final Remarks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I set the language of the tutor to German by simply setting the ChatGPT’s system
    role and adjusting the parameters within the gTTs function to align with German
    language. However, you could easily switch it to another language. It would only
    take seconds to configure it for your target language.
  prefs: []
  type: TYPE_NORMAL
- en: If you’d like to chat about a specific topic, you can also add it in the system
    role of ChatGPT. For example, practicing for interviews with it might be a nice
    use-case. You can also specify your language level to adjust its responses.
  prefs: []
  type: TYPE_NORMAL
- en: One important remark is that the overall speed of the chat depends on your internet
    connection (due to ChatGPT API and gTTS) as well as your hardware (due to local
    deployment of Whisper). In my case, overall response time after my inputs ranges
    between 4–10 seconds.
  prefs: []
  type: TYPE_NORMAL
