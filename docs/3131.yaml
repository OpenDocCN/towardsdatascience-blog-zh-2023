- en: 'Mastering the Future: Evaluating LLM-Generated Data Architectures leveraging
    IaC technologies'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/mastering-the-future-evaluating-llm-generated-data-architectures-leveraging-iac-technologies-dee75302a355?source=collection_archive---------4-----------------------#2023-10-16](https://towardsdatascience.com/mastering-the-future-evaluating-llm-generated-data-architectures-leveraging-iac-technologies-dee75302a355?source=collection_archive---------4-----------------------#2023-10-16)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Evaluate the suitability of LLMs for the generation of Infrastructure as Code
    to provision, configure, and deploy modern applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@josu.arcaya?source=post_page-----dee75302a355--------------------------------)[![Josu
    Diaz de Arcaya](../Images/1476305f0be9c4171a7dd09ae5a2a662.png)](https://medium.com/@josu.arcaya?source=post_page-----dee75302a355--------------------------------)[](https://towardsdatascience.com/?source=post_page-----dee75302a355--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----dee75302a355--------------------------------)
    [Josu Diaz de Arcaya](https://medium.com/@josu.arcaya?source=post_page-----dee75302a355--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F97cdebb24692&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-the-future-evaluating-llm-generated-data-architectures-leveraging-iac-technologies-dee75302a355&user=Josu+Diaz+de+Arcaya&userId=97cdebb24692&source=post_page-97cdebb24692----dee75302a355---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----dee75302a355--------------------------------)
    ·9 min read·Oct 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdee75302a355&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-the-future-evaluating-llm-generated-data-architectures-leveraging-iac-technologies-dee75302a355&user=Josu+Diaz+de+Arcaya&userId=97cdebb24692&source=-----dee75302a355---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdee75302a355&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-the-future-evaluating-llm-generated-data-architectures-leveraging-iac-technologies-dee75302a355&source=-----dee75302a355---------------------bookmark_footer-----------)![](../Images/7fe40321056c9eb3d7292d48e6c4dbae.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [ZHENYU LUO](https://unsplash.com/@mrnuclear?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this article, we address the suitability of LLMs to leverage the lifecycle
    of real applications, ranging from the infrastructure provisioning to the configuration
    management and deployment. The source code resulting from this effort is publicly
    available on GitHub¹¹. Infrastructure as Code (IaC) solutions facilitate the management
    and provisioning of infrastructure through code instead of through a manual process¹.
    They are becoming commonplace, and major cloud providers have implemented their
    own flavor of IaC solutions for interacting with their services. In this regard,
    AWS CloudFormation, Google Cloud Deployment Manager, and Azure Resource Manager
    Templates streamline the provisioning of cloud services, eliminating the need
    for IT Operations to manually spin up servers, databases, and networks. However,
    these many possibilities introduce the risk of vendor locking since the definition
    of the required IaC for a given cloud provider is not portable and would need
    to be translated if a different cloud provider is required. In this regard, tools
    like Terraform² or Pulumi³ provide an abstraction over the various implementations
    of the different cloud providers and facilitate the development of portable deployments.
    This way, the risk of vendor locking is severely reduced, and organizations can
    react dynamically to their needs without incurring significant implementation
    costs. On top of this, there are numerous benefits that IaC technologies bring
    to the table⁴:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consistency: it permits the automation of the infrastructure provisioning by
    enabling repeatable deployments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Decreased Risk: it promotes a less error-prone approximation to infrastructure
    management, as manual interventions are minimized.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cost Optimization: it enables easier identification of unnecessary resources,
    and faster migration among cloud providers reacting to billing changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Improved Collaboration: scripts can be integrated into version control tools,
    which promotes collaboration between individuals and teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, the application lifecycle goes beyond infrastructure provisioning.
    The following figure displays the application lifecycle supported by different
    IaC technologies⁵.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/171a40d7108f995f9712816d2860a60e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The application lifecycle supported by Infrastructure as Code technologies.
    | Source: Josu Diaz-de-Arcaya et al.⁵'
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, the goal of IaC technologies extends beyond the mere provisioning
    of infrastructural resources. After spinning up the necessary infrastructure,
    the configuration management stage ensures that all the requirements are appropriately
    installed. This stage is usually accomplished with tools such as ansible⁶, chef⁷,
    or puppet⁸. Finally, the application deployment oversees the orchestration of
    the application over the various infrastructural devices.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large Language Models (LLMs) refer to a class of artificial intelligence models
    that are designed to understand and generate human-like text based on the input
    provided to them. These models are known for their considerable number of parameters,
    which enable them to capture complex patterns and nuances in language⁹.
  prefs: []
  type: TYPE_NORMAL
- en: '**Text Generation**: Text created by LLMs can be cohesive and relevant to its
    surroundings. They are employed for activities like finishing texts, producing
    material, and even doing creative writing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Language Comprehension**: LLMs are capable of comprehending and extracting
    information from text. They are capable of attitude analysis, text classification,
    and information retrieval.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Translation**: LLMs can translate text from one language to another. This
    is very beneficial for machine translation applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Answering questions**: LLMs can answer questions based on a given context.
    They are used in chatbots and virtual assistants to answer user queries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text Summarization**: LLMs can summarize long passages of text into shorter,
    more coherent summaries. This is useful for condensing information for quick consumption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Among the aforementioned capabilities, we will focus on text generation. In
    particular, in its ability to produce the correct IaC code based on the input
    prompts, Large Language Models (LLMs) have made significant advances in the field
    of natural language processing, but they have also raised **several challenges
    and concerns**. Some of the key issues and concerns associated with LLMs at that
    time include:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Biases and fairness**: LLMs can learn biases present in the data they are
    trained on, which can lead to biased or unfair results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Misinformation and disinformation:** LLMs may generate false or misleading
    information, which may contribute to the spread of misinformation and disinformation
    online. These models have the potential to create content that appears credible
    but is factually incorrect.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and privacy:** LLMs can be misused to generate malicious content,
    such as deepfake texts, fake news, or phishing emails.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following table displays a comparison among various LLMs¹⁰
  prefs: []
  type: TYPE_NORMAL
- en: Generating IaC with LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to test how current LLM tools perform in the field of IaC, a use case
    has been designed. The final objective is to build an API in a virtual machine
    using the FastAPI framework that allows the client to perform search and delete
    tasks in an Elasticsearch cluster using HTTP methods. The cluster will be composed
    of three nodes, each one in its own virtual machine, and in another machine will
    be Kibana, an administration tool for the cluster that supports visualizations.
    Everything must be in the AWS cloud. The following figure shows this architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec4f6f1048255259e2ed89c1e5c1056c.png)'
  prefs: []
  type: TYPE_IMG
- en: Use case designed to test the feasibility of LLMs generated IaC
  prefs: []
  type: TYPE_NORMAL
- en: The challenge is to complete the following three tasks successfully using LLM
    tools. In this article, we have used OpenAI’s ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform code to build an infrastructure with five virtual machines in AWS.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Source code of the FastAPI application to perform document search and delete
    operations through HTTP methods of the API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ansible code for the deployment and installation of an Elasticsearch cluster
    on three nodes, Kibana on another node, and a FastAPI application on the remaining
    node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Task #1**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this challenge, we have used the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: 'I need to create, via Terraform, five virtual machines at a public cloud provider
    you want. The purpose of these virtual machines is the following: Three of them
    are for deploying an Elasticsearch cluster, which is going to ingest 2G of data
    each day; the other one is for Kibana; and the last one is for deploying a FastAPI
    application. You should choose the hardware for each virtual machine and the cloud
    provider for each virtual machine. For the variables you don’t know, use variables
    as placeholders. Use cheap instances.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The initial response was a good effort, but we needed to keep iterating. For
    instance, we wanted all the variables to be defined in a separate file, which
    resulted in the following image.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the variables.tf, which contains the variables to be configured.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, we would like to know the IP addresses of the deployment, and we
    want this configuration to be in a separate file.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the output.tf, containing the IP addresses of the freshly provisioned
    virtual machines.
  prefs: []
  type: TYPE_NORMAL
- en: The AI did an excellent job at describing the instances we wanted, as well as
    configuring them with the security groups each of the required.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the main.tf, which contains the virtual machines to be provisioned
  prefs: []
  type: TYPE_NORMAL
- en: It also created the necessary resources for security groups we wanted, and used
    place holders when to define the various ports as variables.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the main.tf, which contains the security groups to be used.
  prefs: []
  type: TYPE_NORMAL
- en: In general, ChatGPT did a fine job at doing this task. However, it took us a
    while to obtain a viable configuration. get the networking configuration correct.
    For instance, we wanted to connect to each of the provisioned virtual machines,
    which we indicated in the following way.
  prefs: []
  type: TYPE_NORMAL
- en: I want ssh access to all of them from my laptop, and the kibana instance requires
    http and https access from my laptop.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The above prompt produced a code that was almost correct, since the AI got confused
    with the ingress and egress policies. Nevertheless, this was easy to spot and
    fix.
  prefs: []
  type: TYPE_NORMAL
- en: After being able to reach the virtual machines, we had the issue of not being
    able to connect to them due to the lack of permissions. This resulted in a longer
    conversation, and it ended up being easier to add these lines ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: '**Task #2**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this challenge, we have used the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: I need to create a FastAPI application. The purpose of these API is to have
    methods for storing single json document in Elasticsearch cluster, storing multiple
    documents and for deleting them. Elasticsearch cluster is deployed in 3 nodes,
    and it has a basic authentication with user “tecnalia” and password “iac-llm”.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The result of this prompt has been remarkably successful. The app uses the Elasticsearch
    python package¹² to interact with Elasticsearch cluster and it is completely valid.
    We must only remember that we need to change the IP addresses of the nodes where
    the cluster is deployed. In the following picture, the first method has been created
    with serves the purpose of inserting a single document in Elasticsearch.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt for the store single document method.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the second method is used to create a bulk insert of various documents
    in a single call.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt for the store multiple documents method.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the last method can be used to delete a single document from the Elasticsearch
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt for the delete document method.
  prefs: []
  type: TYPE_NORMAL
- en: We reckon this experiment has been highly successful, as it correctly selects
    an appropriate library for doing the task. However, further manual refinements
    are necessary to turn this code into production ready software.
  prefs: []
  type: TYPE_NORMAL
- en: '**Task #3**'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this challenge, we have used the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate ansible code to install Elasticsearch cluster on three nodes. Please
    also add a Kibana node connected to the cluster.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This prompt did an OK job at producing the desired ansible scripts. It did
    an excellent job at organizing the source code into various files. First, the
    inventory with details about all the nodes. Keep in mind this file needs to be
    adjusted with the correct IP addresses generated in Task #1.'
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the inventory.ini
  prefs: []
  type: TYPE_NORMAL
- en: Then, the main ansible script for installing Elasticsearch is displayed in the
    following figure. This represents an excerpt of it, the complete example can be
    found in the repository¹¹.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the elasticsearch_playbook.yml
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the necessary configuration for each of the Elasticsearch
    nodes has been generated conveniently as a Jinja file. In this case, we had to
    manually add the *path.logs* and *path.data* configurations as Elasticsearch was
    unable to boot up due to permission issues.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the elasticsearch.yml.j2.
  prefs: []
  type: TYPE_NORMAL
- en: On a similar note, ChatGPT was able to generate a similar configuration for
    the Kibana instance. However, in this case we manually separated the configuration
    into a separate file for convenience. An excerpt of this file can be seen in the
    following image.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the kibana_playbook.yml.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the following jinja file which refers to the Kibana instance seems
    good, even though the IP addresses would be better to be parameterized.
  prefs: []
  type: TYPE_NORMAL
- en: Code excerpt of the kibana.yml.j2
  prefs: []
  type: TYPE_NORMAL
- en: In general, we found ChatGPT extremely good at producing a skeleton of the project.
    However, there are still plenty of actions required to turn that skeleton into
    a production level application. In this regard, deep expertise in the utilized
    technologies is required to tweak the project.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This article addresses the use of LLMs to oversee the application’s lifecycle.
    The pros and cons of this effort are discussed in the following lines.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pros**'
  prefs: []
  type: TYPE_NORMAL
- en: The use of LLMs for the support of the various stages of the application lifecycle
    is particularly beneficial in kicking off the project, particularly in well-known
    technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The initial skeleton is well structured, and it provides structures and methodologies
    that otherwise would not have been utilized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons**'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are subject to the bias risk associated with the use of AI solutions; in
    this instance, ChatGPT chose AWS over similar options.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polishing the project to be production-ready can be troublesome, and it is sometimes
    easier to adjust the code by hand, which requires extensive knowledge of the utilized
    technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This work is funded by the SIIRSE Elkartek project (Robust, safe and ethical
    smart industrial systems for Industry 5.0: Advanced paradigms for the specification,
    design, evaluation, & monitoring) from the Basque Government (ELKARTEK 2022 KK-2022/00007).'
  prefs: []
  type: TYPE_NORMAL
- en: Authorship contribution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The conceptualization, analysis, investigation, and writing are a joint effort
    of [Juan Lopez de Armentia](https://www.linkedin.com/in/juan-lopez-de-armentia/),
    [Ana Torre](https://www.linkedin.com/in/anaistobas/), and [Gorka Zárate](https://www.linkedin.com/in/gorka-z%C3%A1rate-martinez-748a4961/).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*What is Infrastructure as Code (IaC)?* (2022). [https://www.redhat.com/en/topics/automation/what-is-infrastructure-as-code-iac](https://www.redhat.com/en/topics/automation/what-is-infrastructure-as-code-iac)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Terraform by HashiCorp*. (n.d.). Retrieved October 5, 2023, from [https://www.terraform.io](https://www.terraform.io/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Pulumi — Universal Infrastructure as Code*. (n.d.). Retrieved October 5, 2023,
    from [https://www.pulumi.com/](https://www.pulumi.com/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*The 7 Biggest Benefits of Infrastructure as Code — DevOps*. (n.d.). Retrieved
    October 5, 2023, from [https://duplocloud.com/blog/infrastructure-as-code-benefits/](https://duplocloud.com/blog/infrastructure-as-code-benefits/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Diaz-De-Arcaya, J., Lobo, J. L., Alonso, J., Almeida, A., Osaba, E., Benguria,
    G., Etxaniz, I., & Torre-Bastida, A. I. (2023). *IEM: A Unified Lifecycle Orchestrator
    for Multilingual IaC Deployments ACM Reference Format*. [https://doi.org/10.1145/3578245.3584938](https://doi.org/10.1145/3578245.3584938)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Ansible is Simple IT Automation*. (n.d.). Retrieved October 5, 2023, from
    [https://www.ansible.com/](https://www.ansible.com/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Chef Software DevOps Automation Solutions | Chef*. (n.d.). Retrieved October
    5, 2023, from [https://www.chef.io/](https://www.chef.io/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Puppet Infrastructure & IT Automation at Scale | Puppet by Perforce*. (n.d.).
    Retrieved October 5, 2023, from [https://www.puppet.com/](https://www.puppet.com/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kerner, S. M. (n.d.). *What are Large Language Models? | Definition from TechTarget*.
    Retrieved October 5, 2023, from [https://www.techtarget.com/whatis/definition/large-language-model-LLM](https://www.techtarget.com/whatis/definition/large-language-model-LLM)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sha, A. (2023). *12 Best Large Language Models (LLMs) in 2023 | Beebom*. [https://beebom.com/best-large-language-models-llms/](https://beebom.com/best-large-language-models-llms/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Diaz-de-Arcaya, J., Lopez de Armentia, J., & Zarate, G. (n.d.). *iac-llms GitHub*.
    Retrieved October 5, 2023, from [https://github.com/josu-arcaya/iac-llms](https://github.com/josu-arcaya/iac-llms)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Elastic Client Library Maintainers. (2023). *elasticsearch · PyPI*. [https://pypi.org/project/elasticsearch/](https://pypi.org/project/elasticsearch/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
