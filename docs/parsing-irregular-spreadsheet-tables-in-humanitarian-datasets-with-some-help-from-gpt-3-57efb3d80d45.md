# åœ¨äººé“ä¸»ä¹‰æ•°æ®é›†ä¸­è§£æä¸è§„åˆ™ç”µå­è¡¨æ ¼ï¼ˆå€ŸåŠ© GPT-3 çš„å¸®åŠ©ï¼‰

> åŸæ–‡ï¼š[`towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24`](https://towardsdatascience.com/parsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45?source=collection_archive---------2-----------------------#2023-02-24)

## å¤„ç†ä¸è§„åˆ™ Excel è¡¨æ ¼ï¼Œæ— éœ€ä½¿ç”¨ç¡¬ç¼–ç è§„åˆ™

[](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)![é©¬ä¿®Â·å“ˆé‡Œæ–¯](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)[](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------)![æ•°æ®ç§‘å­¦å‰æ²¿](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------) [é©¬ä¿®Â·å“ˆé‡Œæ–¯](https://medium.com/@astrobagel?source=post_page-----57efb3d80d45--------------------------------)

Â·

[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F4a2cd25b8ff9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=post_page-4a2cd25b8ff9----57efb3d80d45---------------------post_header-----------) å‘å¸ƒäº [æ•°æ®ç§‘å­¦å‰æ²¿](https://towardsdatascience.com/?source=post_page-----57efb3d80d45--------------------------------) Â· 26 åˆ†é’Ÿé˜…è¯» Â· 2023 å¹´ 2 æœˆ 24 æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&user=Matthew+Harris&userId=4a2cd25b8ff9&source=-----57efb3d80d45---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F57efb3d80d45&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fparsing-irregular-spreadsheet-tables-in-humanitarian-datasets-with-some-help-from-gpt-3-57efb3d80d45&source=-----57efb3d80d45---------------------bookmark_footer-----------)![](img/0fbcce7550af12dc6d701ff00255fbc1.png)

ç”± DALL-E2 æ ¹æ®æç¤ºâ€œ10 å¼ æœ¨æ¡Œçš„ç”»ä½œâ€åˆ›ä½œã€‚ä¸Šå›¾ä¸­æœ‰ 9 å¼ æ¡Œå­ã€‚

***ç®€çŸ­è¯´æ˜***

*ä½œä¸º* *ä¹‹å‰çš„ç ”ç©¶* *çš„ä¸€éƒ¨åˆ†ï¼Œä½¿ç”¨äº†æ¥è‡ª* [*äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢*](https://data.humdata.org/) *çš„æ•°æ®ï¼Œæˆ‘ä¸å¾—ä¸åˆ†ææˆåƒä¸Šä¸‡çš„ Excel æ–‡ä»¶ï¼Œè¿™äº›æ–‡ä»¶ä¸­çš„è¡¨æ ¼å¸¸å¸¸éš¾ä»¥è§£ææˆæ•°æ®åº“è¡¨ã€‚æ–‡ä»¶æ¥è‡ªå…¨çƒæ•°ç™¾ä¸ªç»„ç»‡æ—¶ï¼Œåˆå¹¶å•å…ƒæ ¼ã€ä¸è§„åˆ™å¸ƒå±€ã€å±‚æ¬¡åŒ–åˆ—å’Œæ³¨é‡Šéš¾ä»¥é€šè¿‡åŸºäºè§„åˆ™çš„è§£ææ¥é¢„è§ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘æ¢è®¨äº†ä½¿ç”¨ GPT-3 çš„é›¶-shotã€å•-shot å’Œæ¨ç†è¡¥å…¨æ¥é‡æ–°æ ¼å¼åŒ–ä¸è§„åˆ™ï¼ˆå°å‹ï¼‰è¡¨æ ¼ï¼Œå¹¶å¾®è°ƒæ¨¡å‹ä»¥é¢„æµ‹è¡¨æ ¼å±æ€§ï¼Œä»è€Œç”¨äºå‡†ç¡®è§£æã€‚*

åœ¨æˆ‘çš„æ—…è¡Œä¸­ï¼Œæœ‰ä¸å°‘æ¬¡éœ€è¦æŸ¥çœ‹å¤§é‡ Excel æ–‡ä»¶ï¼Œä»¥äº†è§£å®ƒä»¬åŒ…å«çš„æ•°æ®ã€æ•°æ®çš„ç»“æ„å¦‚ä½•ï¼Œä»¥åŠå°†å…¶æ¸…ç†æˆå¯ä»¥å¤„ç†çš„å½¢å¼æ‰€éœ€çš„å·¥ä½œã€‚å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œåªè¦æ•°æ®è§„åˆ™ä¸”åˆ—æ ‡é¢˜æ•´é½ï¼Œè¿™ä¸ªè¿‡ç¨‹ç›¸å½“ç®€å•ã€‚ç„¶è€Œï¼Œç°å®ä»æœªé‚£ä¹ˆç®€å•ï¼Œè¿™äº›æ–‡ä»¶ä¸­çš„è¡¨æ ¼å¾€å¾€ä»¥ä¸å®Œç¾çš„æ ¼å¼å­˜åœ¨ï¼Œéš¾ä»¥è§£ææˆå¯ä»¥ä¸Šä¼ åˆ°å…³ç³»æ•°æ®åº“çš„æ•°æ®æ¡†ã€‚Excel æ”¯æŒè®¸å¤šåŠŸèƒ½ï¼Œå¦‚æ•°æ®é€è§†è¡¨å’Œå•å…ƒæ ¼åˆå¹¶ï¼Œäººä»¬ä½¿ç”¨è¿™äº›åŠŸèƒ½åˆ›å»ºå„ç§å„æ ·çš„å¸ƒå±€ï¼ŒåŒ…æ‹¬ç©ºç™½è¡Œã€éšæœºæ–‡æœ¬ç­‰ç­‰ï¼

è¿™é‡Œæœ‰ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜â€¦â€¦

![](img/b8a93c73e798926ce23cb65154d977a4.png)

Excel ä¸­çš„ä¸è§„åˆ™è¡¨æ ¼ç¤ºä¾‹ï¼Œå¸¦æœ‰ç©ºç™½é¡¶éƒ¨è¡Œã€æ ‡ç­¾å’Œåˆå¹¶å•å…ƒæ ¼ã€‚å¯¹äººç±»æ¥è¯´å®Œå…¨å¯è¯»ï¼Œä½†å¯¹æ•°æ®ç§‘å­¦æ¥è¯´æ˜¯è§£æçš„æŒ‘æˆ˜ã€‚è¯¥æ–‡ä»¶æ¥è‡ª[äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢](https://data.humdata.org/dataset/kenya-number-of-acreage-under-irrigation-in-bomet-county)

å¦‚æœæˆ‘ä»¬ç›´æ¥å°†ä¸Šè¿°æ–‡ä»¶è¯»å…¥ Pandas ä¸­â€¦â€¦

```py
import pandas as pd
df = pd.read_excel(filename)
df = df.fillna("")
display(df)
```

æˆ‘ä»¬å¾—åˆ°è¿™ä¸ªâ€¦â€¦

![](img/5089756e01020858fd71468ba8fd5fab.png)

Pandas æ•°æ®æ¡†åœ¨è§£æ Excel è¡¨æ ¼åçš„ç¤ºä¾‹ï¼Œå…¶ä¸­åŒ…å«ç©ºè¡Œå’Œåˆå¹¶å•å…ƒæ ¼ï¼Œä»¥æŒ‡ç¤ºå±‚æ¬¡åˆ—ã€‚ç¤ºä¾‹æ•°æ®æ¥è‡ª[äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)

å°†å…¶åŠ è½½åˆ°æ•°æ®åº“ä¸­ä¼šå¯¼è‡´æ•°æ®å‡ ä¹æ— æ³•ä½¿ç”¨ï¼Œå› ä¸ºâ€¦â€¦

1.  å³ä¸Šè§’å•å…ƒæ ¼ä¸­æœ‰ä¸€ä¸ªè¡¨æ ¼æ ‡é¢˜ã€‚

1.  åˆ—â€˜Unnamed: 1â€™çš„æ ‡é¢˜å®é™…ä¸Šæ˜¯ç¬¬ä¸€åˆ—ç¬¬ 5 è¡Œçš„å†…å®¹â€œä½ æ‹¥æœ‰çš„åœŸåœ°çš„å¹³å‡é¢ç§¯æ˜¯å¤šå°‘â€¦â€¦â€

1.  åˆ—â€˜Unnamed:2â€™å’Œâ€˜Unnamed:3â€™æ˜¯åˆ†ä¸ºâ€™Nâ€˜ æ•°å€¼å’Œâ€˜%â€™ ç™¾åˆ†æ¯”å€¼çš„æ±‡æ€»æ€»æ•°ã€‚

1.  å¤§å¤šæ•°åˆ—æ˜¯å±‚æ¬¡åŒ–çš„ï¼Œåˆå¹¶å•å…ƒæ ¼ä½äºæœªåˆå¹¶å•å…ƒæ ¼ä¹‹ä¸Šã€‚

è¿™ä¹Ÿä¸*é‚£ä¹ˆ*ç³Ÿç³•ï¼Œå¯¹å§ï¼Ÿ

å½“ç„¶ï¼Œå¯ä»¥å‘[Pandas read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)æä¾›å‚æ•°ï¼Œå°†å±‚æ¬¡åˆ—è½¬æ¢ä¸ºç´¢å¼•ï¼Œç„¶åå¯ä»¥å°†å…¶åˆå¹¶ä¸ºä¸€è¡Œã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨[Openpyxl](https://openpyxl.readthedocs.io/en/stable/)ä¸­å…³äº Excel è‡ªèº«çš„åˆå¹¶å•å…ƒæ ¼çš„ä¿¡æ¯è¿›è¡Œæ“ä½œã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¯¹è¡¨æ ¼æœ‰äº†è§£â€”â€”ç‰¹åˆ«æ˜¯æ ‡é¢˜åœ¨å“ªé‡Œç»“æŸã€æ•°æ®ä»å“ªé‡Œå¼€å§‹ä»¥åŠå±‚æ¬¡åˆ—çš„ç»“æ„â€”â€”è¿™æ˜¯æˆ‘ä»¬åœ¨å¤„ç†æˆåƒä¸Šä¸‡çš„ç”µå­è¡¨æ ¼æ—¶å¯èƒ½ä¸æ€»æ˜¯æ‹¥æœ‰çš„å¥¢ä¾ˆå“ã€‚å¯¹å¤§é‡æ–‡ä»¶è¿›è¡ŒåŸºäºè§„åˆ™çš„è§£æå¯èƒ½è€—æ—¶ä¸”è„†å¼±ï¼Œéœ€è¦éšç€æ–°å¸ƒå±€çš„å‡ºç°è€ŒæŒç»­ç»´æŠ¤ã€‚

å…¶å®ï¼Œæˆ‘å¹¶ä¸æ˜¯å”¯ä¸€ä¸€ä¸ªé‡åˆ°è¿™ä¸ªé—®é¢˜çš„äººï¼è§£æä¸è§„åˆ™è¡¨æ ¼æ˜¯ä¸€é¡¹æ­£åœ¨ç§¯æç ”ç©¶çš„æŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼Œå¾®è½¯çš„ä½œè€…å±•ç¤ºäº†åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œå¼€å‘çš„ä¸€ä¸ªåä¸ºâ€˜TableSenseâ€™çš„ç®—æ³•çš„å‡ºè‰²æˆæœ[[1](https://arxiv.org/abs/2106.13500)]ã€‚è¿™ç§æŠ€æœ¯å°† Excel è¡¨æ ¼è§†ä½œå›¾åƒæ¥å¤„ç†ï¼Œä½†å…·æœ‰æ›´ä¸°å¯Œçš„ç‰¹å¾åŒ–ï¼Œå› ä¸ºæ¯ä¸ªå•å…ƒæ ¼å¯èƒ½å…·æœ‰å¤šç§å±æ€§å’Œæ•°æ®ç±»å‹ï¼Œè¿˜åŒ…æ‹¬æ ¼å¼åŒ–å’Œåˆå¹¶ç‰¹å¾ã€‚éå¸¸é…·ã€‚æˆ‘å¸Œæœ›åƒè¿™æ ·çš„ç²¾å½©å·¥ä½œèƒ½å°½å¿«çº³å…¥å¾®è½¯çš„äº§å“ä¸­ï¼Œä½†åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘æƒ³æ¢ç´¢ä¸€äº›å…¶ä»–çš„æ–¹æ³•ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘çš„ä½¿ç”¨æ¡ˆä¾‹ä¸ä»…ä»…æ˜¯è¯†åˆ«è¡¨æ ¼åœ¨å·¥ä½œè¡¨ä¸­çš„èŒƒå›´ï¼ˆå‚è§[å¾®è½¯è®ºæ–‡çš„è®­ç»ƒæ•°æ®](https://github.com/microsoft/TableSense/blob/main/dataset/Table%20range%20annotations.txt)ï¼‰ï¼Œè¿˜åŒ…æ‹¬è¡¨æ ¼ä¸­çš„å…ƒç´ ï¼Œä»¥ä¾¿å°†ä¸è§„åˆ™çš„æ ¼å¼è½¬æ¢ä¸ºå¯ä»¥è½»æ¾å¯¼å…¥æ•°æ®åº“çš„æ ¼å¼ã€‚ä¸»è¦æŒ‘æˆ˜æ˜¯ Excel ä¸­çš„å±‚æ¬¡åˆ—ï¼Œå°†è¿™äº›å±‚æ¬¡åˆ—å±•å¹³æˆä¸€ä¸ªå•ç‹¬çš„è¡Œï¼Œä»è€Œæ•æ‰ä¸Šå±‚åˆå¹¶å•å…ƒæ ¼ä¸­çš„ä¿¡æ¯ã€‚å¬èµ·æ¥è§£å†³èµ·æ¥å¾ˆç®€å•ï¼Œä½†æŒ‘æˆ˜æ˜¯ï¼šæ ‡é¢˜åœ¨å“ªé‡Œç»“æŸï¼Œæ•°æ®ä»å“ªé‡Œå¼€å§‹ï¼Ÿè¿™å¯¹æˆ‘ä»¬äººç±»æ¥è¯´æ˜¾è€Œæ˜“è§ï¼Œä½†ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå½“ç”¨ä»£ç å¤„ç†å·¥ä½œè¡¨æ—¶ï¼Œè¿™æ ·ç®€å•çš„äº‹æƒ…åœ¨ç°å®ä¸–ç•Œä¸­å¯èƒ½ä¼šå˜å¾—éå¸¸å˜ˆæ‚ã€‚

é‰´äºæœ€è¿‘å¯¹ç”Ÿæˆå¼ AI å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å…³æ³¨ï¼Œæˆ‘æƒ³çŸ¥é“ä¹Ÿè®¸[OpenAI çš„ GPT-3](https://openai.com/blog/gpt-3-apps/)å¯èƒ½ä¼šæ¥å—è¿™ä¸ªæŒ‘æˆ˜ã€‚è¿™äº›æ¨¡å‹åœ¨ä»äº’è”ç½‘æå–çš„å¤§é‡æ•°æ®ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå…¶ä¸­åŒ…æ‹¬è¡¨æ ¼å’Œ CSV æ–‡ä»¶ï¼Œå› æ­¤å®ƒä»¬å¯èƒ½åœ¨å¤„ç†æˆ‘ä»¬è¿™äº›ç–¯ç‹‚äººç±»æ‹¼å‡‘çš„è¡¨æ ¼çš„æŸäº›ç»†èŠ‚æ–¹é¢ä¼šå¾ˆæœ‰ç”¨ã€‚

# æç¤º GPT-3 æ¸…ç†ï¼ˆä¸€ä¸ªå°çš„ï¼‰è¡¨æ ¼

æˆ‘ä»¬å°†é¦–å…ˆå°è¯•å°†é—®é¢˜ä½œä¸ºé›¶æ ·æœ¬å’Œå°‘é‡æ ·æœ¬ä»»åŠ¡è§£å†³ï¼Œç„¶åå†è½¬å‘ä½¿ç”¨å¾®è°ƒæŠ€æœ¯ã€‚

![](img/23eef763f4af285bab56ce5104601dbc.png)

é›¶æ ·æœ¬ã€å•æ ·æœ¬å’Œå°‘æ ·æœ¬ä»»åŠ¡ï¼Œä¸ä¼ ç»Ÿçš„å¾®è°ƒå¯¹æ¯”ã€‚ä¸Šé¢çš„é¢æ¿å±•ç¤ºäº†ç”¨è¯­è¨€æ¨¡å‹æ‰§è¡Œä»»åŠ¡çš„å››ç§æ–¹æ³•ã€‚æ¥æºäº Brown ç­‰äºº [[2](https://arxiv.org/pdf/2005.14165.pdf)]ã€‚

GPT-3 æ˜¯åœ¨ä»ç½‘ç»œä¸ŠæŠ“å–çš„æ–‡æœ¬ä¸Šè®­ç»ƒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸èƒ½ç”¨ Excel æç¤ºå®ƒï¼ˆè¿˜ä¸è¡Œï¼ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆå¿…é¡»å°†æˆ‘ä»¬çš„è¡¨æ ¼è½¬æ¢æˆä¸€ç§ç½‘ç»œä¸Šå¸¸è§çš„å½¢å¼ï¼Œä¾‹å¦‚ CSV å­—ç¬¦ä¸²â€¦â€¦

```py
df = pd.read_excel('sample.xlsx', sheet_name='Sheet1')
df = df.fillna("")
print(df.to_csv())
```

```py
,Unnamed: 0,Unnamed: 1,Unnamed: 2,Unnamed: 3,Unnamed: 4,Unnamed: 5,Unnamed: 6,Unnamed: 7,Unnamed: 8,Unnamed: 9,Unnamed: 10,Unnamed: 11
0,Table 3: Number of acreage under irrigation,,,,,,,,,,,
1,,,OVERALL,,Sub county,,,,,,,
2,,,,,Chepalungu,,,,Bomet Central,,,
3,,,,,Male,,Female,,Male,,Female,
4,,,N,%,N,%,N,%,N,%,N,%
5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%
6,,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%
7,,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%
8,,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%
9,,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%
10,,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%
```

**é™„æ³¨**ï¼šæˆ‘è¿˜å°è¯•äº† Markdown å’Œ HTML è¡¨æ ¼ï¼Œä½†å‘ç° CSV åœ¨æˆ‘çš„ç”¨ä¾‹ä¸­æ•ˆæœæœ€å¥½ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¯¹äºè¿™é¡¹åˆ†æï¼Œæˆ‘ä»¬å¤„ç†çš„è¡¨æ ¼æ˜¯*ç¨€ç–çš„*ï¼Œå³åˆ—æ•°å°‘äº 100ã€‚è¿™æ„å‘³ç€å‰ 10 è¡Œå¯ä»¥å¾ˆå®¹æ˜“åœ°åœ¨ GPT-3 æç¤ºä¸­è¡¨ç¤ºã€‚è¿™å¯¹æˆ‘åœ¨æ´åŠ©æ•°æ®äº¤æ¢ä¸­åˆ†æçš„å¤§å¤šæ•° Excel è¡¨æ ¼æ¥è¯´æ˜¯åˆé€‚çš„ï¼Œä½†å¯èƒ½ä¸é€‚ç”¨äºå…¶ä»–æƒ…å†µã€‚æ­¤å¤–ï¼Œè¿™é¡¹åˆ†æä¸è€ƒè™‘åŒä¸€ Excel å·¥ä½œè¡¨ä¸Šæœ‰å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µâ€¦â€¦è¿™å°†æ˜¯ç¨ååšå®¢æ–‡ç« çš„å†…å®¹ã€‚ğŸ™‚

# **é›¶æ ·æœ¬æç¤º**

ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹ GPT-3 æ˜¯å¦å¯ä»¥ä»…é€šè¿‡ä¸€ä¸ªæç¤ºé‡æ–°æ ¼å¼åŒ–æˆ‘ä»¬å‡Œä¹±çš„è¡¨æ ¼ï¼Œè¿™æ˜¯ä¸€é¡¹[é›¶æ ·æœ¬ä»»åŠ¡](https://arxiv.org/pdf/2005.14165.pdf) [2]ï¼Œæˆ‘ä»¬æ²¡æœ‰æä¾›ç¤ºä¾‹ï¼Œåªæ˜¯æä¾›äº†è¦é‡æ–°æ ¼å¼åŒ–çš„ CSV æ–‡ä»¶â€¦â€¦

```py
import openai as ai

# Open AI API key should be put into this file
ai.api_key_path = "./api_key.txt"

csv_as_str = df.to_csv()

prompt = (
    "Reformat this table to be a simpler markdown table with "
    + "no hierarchical columns, no pivoting, values and percentages in different columns, "
    + "and no blank cells\n\n"
    + csv_as_str
)

completions = ai.Completion.create(
    engine="text-davinci-003",
    temperature=0.0,
    prompt=prompt,
    max_tokens=999,
    n=1,
    stop=None,
)

Markdown(completions.choices[0].text)
```

![](img/d0bff692e6f0aa17d92fe2902f2d8efe.png)

å®ƒä¸¢å¼ƒäº†ä¸å¿…è¦çš„è¡Œï¼Œå°†æ•°æ®è½¬æ¢ä¸ºä¸€ä¸ªè§„èŒƒçš„è¡¨æ ¼ï¼Œå¸¦æœ‰åˆ—æ ‡é¢˜ï¼Œä½†ä»”ç»†è§‚å¯Ÿä¼šå‘ç°ï¼Œå®ƒä¸¢å¤±äº†ä¸€äº›å…³é”®ä¿¡æ¯ï¼Œå¦‚æŒ‰æ€§åˆ«çš„åˆ†ç±»ã€‚è¿™æ˜¯ç»å…¸çš„[å¹»è§‰](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))ç°è±¡ï¼Œçœ‹èµ·æ¥å¾ˆå¯ä¿¡ï¼Œä½†å´æ˜¯é”™è¯¯çš„ã€‚

è®©æˆ‘ä»¬ç©ç©[æ¸©åº¦](https://platform.openai.com/docs/api-reference/completions/create)å‚æ•°ã€‚è¾ƒä½çš„å€¼ä½¿æ¨¡å‹æ›´åŠ ç¡®å®šæ€§ï¼ˆå¯¹äºç›¸åŒçš„æç¤ºæ¯æ¬¡éƒ½ç»™å‡ºç›¸åŒçš„ç»“æœï¼‰ï¼Œè€Œè¾ƒé«˜çš„å€¼åˆ™æ›´éšæœºã€‚ä½¿ç”¨æ›´é«˜çš„æ¸©åº¦å€¼ï¼Œæˆ‘ä»¬å¾—åˆ°â€¦â€¦

```py
prompt = (
    "Reformat this table to be a simpler markdown table with "
    + "no hierarchical columns, no pivoting, values and percentages in different columns, "
    + "and no blank cells\n\n"
    + csv_as_str
)

completions = ai.Completion.create(
    engine="text-davinci-003",
    temperature=1.0,
    prompt=prompt,
    max_tokens=999,
    n=1,
    stop=None,
)

Markdown(completions.choices[0].text)
```

![](img/f9ec19a4d12334d819089ceb85fdbbad.png)

*çœ‹èµ·æ¥*ä¸é”™ï¼å‡ ä¹æ‰€æœ‰çš„æ­£ç¡®åˆ—æ ‡é¢˜éƒ½æ¥è‡ªæˆ‘ä»¬ CSV æ–‡ä»¶ä¸­çš„åˆå¹¶å•å…ƒæ ¼ï¼Œè¿™å®é™…ä¸Šç›¸å½“æƒŠäººã€‚ç„¶è€Œï¼ŒæŠ½æŸ¥å‡ ä¸ªå•å…ƒæ ¼æ˜¾ç¤ºï¼Œå°½ç®¡è®¸å¤šæ˜¯æ­£ç¡®çš„ï¼Œä½†ä¹Ÿæœ‰ä¸€äº›ä¸æ­£ç¡®ã€‚æ­¤å¤–ï¼Œä¸Šé¢çš„â€œæ€»ä½“â€è¢«åˆ†æˆäº†ç”·æ€§å’Œå¥³æ€§ï¼Œè¿™æ˜¯ä¸æ­£ç¡®çš„ã€‚

å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œè°ƒç”¨ GPT-3 å®Œå…¨ç›¸åŒçš„æç¤ºä¼šäº§ç”Ÿä¸åŒçš„ç»“æœï¼Œå› ä¸ºé«˜æ¸©å€¼â€¦â€¦

```py
completions = ai.Completion.create(
    engine="text-davinci-003",
    temperature=1.0,
    prompt=prompt,
    max_tokens=999,
    n=1,
    stop=None,
)

Markdown(completions.choices[0].text)
```

![](img/7274d124424e64c6d953449273ad69d4.png)

ä¸æ— é“ç†ï¼Œå°½ç®¡å€¼ä¸æ­£ç¡®ï¼Œä½†å¸ƒå±€å®Œå…¨ä¸åŒã€‚å¯é‡å¤æ€§å¯¹æˆ‘ä»¬çš„ä»»åŠ¡éå¸¸é‡è¦ï¼Œæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿåœ¨æ¯æ¬¡å¤„ç†è¿è¡Œä¸­ä»¥å®Œå…¨ç›¸åŒçš„æ–¹å¼å¤„ç†è¡¨æ ¼æ•°æ®ã€‚

æ‰€ä»¥é«˜æ¸©ä¼¼ä¹ä¸æ˜¯è¿™ä¸ªç”¨ä¾‹çš„å¥½é€‰æ‹©ã€‚

å¦‚æœæˆ‘ä»¬åœ¨è¡¨æ ¼ä¸­æä¾›æ›´å¤šä¸Šä¸‹æ–‡ä¼šæ€ä¹ˆæ ·ï¼ŸCSV å¹¶ä¸æ˜¯å¾ˆå…·è¡¨ç°åŠ›ï¼Œä¾‹å¦‚ï¼Œå±‚çº§æ ‡é¢˜ä¸­çš„åˆå¹¶åˆ—å‘Šè¯‰äººç±»è¿™äº›åˆ—æ˜¯åˆ†ç»„çš„ï¼Œä½† CSV æ–‡ä»¶å¹¶æœªæ•æ‰åˆ°è¿™ä¸€ç‚¹â€¦â€¦

![](img/3e5d8eb9550c0dd1d246816daeccfb5d.png)

```py
1,,,OVERALL,,Sub county,,,,,,,
2,,,,,Chepalungu,,,,Bomet Central,,,
3,,,,,Male,,Female,,Male,,Female,
4,,,N,%,N,%,N,%,N,%,N,%
```

åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼ŒGPT-3 å¿…é¡»æ¨æ–­å‡ºåˆå¹¶çš„è¡Œæ ‡é¢˜å³ä¾§çš„ç©ºç™½åˆ—ä¸è¿™äº›æ ‡é¢˜å¯¹åº”ï¼Œå¹¶ä¸”å¾ˆå¤šæ—¶å€™å®ƒç¡®å®èƒ½å¤Ÿåšåˆ°è¿™ä¸€ç‚¹ã€‚ç„¶è€Œï¼Œç”±äºæˆ‘ä»¬çŸ¥é“ Excel æ–‡ä»¶ä¸­å“ªäº›å•å…ƒæ ¼æ˜¯åˆå¹¶çš„ï¼Œæˆ‘ä»¬å¯ä»¥ç¨å¾®å¸®åŠ©ä¸€ä¸‹ã€‚

ä¸ºäº†åœ¨ CSV ä¸­è¡¨ç¤ºè¿™ä¸ªï¼Œæˆ‘ä»¬å¯ä»¥å–æ¶ˆåˆå¹¶åˆå¹¶çš„å•å…ƒæ ¼ï¼Œå¹¶ç”¨å…¶åˆå¹¶å€¼å¡«å…… â€¦

```py
def pad_merged_cells(sheet):
    """
    Unmerge merged cells and fill with merged value.

    Input Parameters
    ----------------
    sheet: Obj
        Openpyxl sheet object

    Output Parameters
    -----------------
    df: Dataframe
        Pandas dataframe of the table
    """

    dd = pd.DataFrame(sheet.values)

    # Scan for maxn rows
    maxn = 10

    hasmerged = False
    if len(sheet.merged_cells.ranges) > 0:
        hasmerged = True

    if hasmerged:
        merge_list = []
        for merge in sheet.merged_cells.ranges:
            merge_list.append(merge)

        for cell_group in merge_list:
            min_col, min_row, max_col, max_row = range_boundaries(
                str(cell_group))
            top_left_cell_value = sheet.cell(row=min_row, column=min_col).value
            sheet.unmerge_cells(str(cell_group))
            for row in sheet.iter_rows(
                min_col=min_col, min_row=min_row, max_col=max_col, max_row=max_row
            ):
                for cell in row:
                    cell.value = top_left_cell_value

    # Extract data and save to dataframe
    data = []
    for row in sheet.iter_rows(min_row=1):
        row_data = []
        for cell in row:
            if cell.value is None:
                row_data.append(None)
            else:
                row_data.append(cell.value)
        if any(row_data):
            data.append(row_data)

    df = pd.DataFrame(data)

    # Remove duplicate columns
    df = df.T.drop_duplicates().T

    # Remove duplicate rows
    df = df.drop_duplicates()

    # Fill NaN with blank string for easier viewing
    df = df.fillna("")

    return df, sheet, hasmerged

wb = openpyxl.load_workbook(filename)
sheet = wb['Sheet1']
merged_table, sheet, hasmerged = pad_merged_cells(sheet)

display(merged_table)
```

![](img/1790b27c754b07ba4517a577447e222c.png)

è¡¨æ ¼ä¸­åˆå¹¶çš„å•å…ƒæ ¼è¢«å–æ¶ˆåˆå¹¶ï¼Œå¹¶ç”¨åˆå¹¶å€¼å¡«å……ï¼Œä»¥åœ¨ CSV æ–‡ä»¶æ ¼å¼ä¸­æä¾›ä¸Šä¸‹æ–‡ã€‚

```py
,Table 3: Number of acreage under irrigation,,,,,,,,,,,
1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county
2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Chepalungu,Chepalungu,Bomet Central,Bomet Central,Bomet Central,Bomet Central
3,,,OVERALL,OVERALL,Male,Male,Female,Female,Male,Male,Female,Female
4,,,N,%,N,%,N,%,N,%,N,%
5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%
6,What is the average size of land you own that is currently under irrigation?,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%
7,What is the average size of land you own that is currently under irrigation?,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%
8,What is the average size of land you own that is currently under irrigation?,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%
9,What is the average size of land you own that is currently under irrigation?,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%
10,What is the average size of land you own that is currently under irrigation?,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%
```

CSV æ–‡ä»¶ç°åœ¨æ•è·äº†å åŠ çš„åˆå¹¶åˆ—æ ‡é¢˜ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯å¦èƒ½æ”¹å–„æƒ…å†µï¼Œé¦–å…ˆæ¸©åº¦=0.0 â€¦

```py
csv_as_str_merged = merged_table.to_csv()

prompt = (
    "Reformat this table to be a simpler markdown table with "
    + "no hierarchical columns, no pivoting, values and percentages in different columns, "
    + "and no blank cells\n\n"
    + csv_as_str_merged
)

completions = ai.Completion.create(
    engine="text-davinci-003",
    temperature=0.0,
    prompt=prompt,
    max_tokens=999,
    n=1,
    stop=None,
)

Markdown(completions.choices[0].text)
```

![](img/780e6bd57ae7ca6db636a442ddae67c0.png)

åŒæ ·çš„ï¼Œä½†æ¸©åº¦=1.0ï¼Œåªæ˜¯ä¸ºäº†å¥½ç© â€¦

![](img/f2a7e421879c0e4b08e1525b6576b50e.png)

ç¨å¾®å¥½äº†ä¸€äº›ï¼Œä½†æ€»æ˜¯*æœ‰äº›*åœ°æ–¹ä¸å¤ªå¯¹ã€‚ç¼ºå¤±çš„ç±»åˆ«ï¼Œå•å…ƒæ ¼å€¼åç§»ï¼Œå¦‚æœæˆ‘ä»¬éœ€è¦å‡†ç¡®è¡¨ç¤ºæºæ•°æ®ï¼Œä¸¤ä¸ªè¡¨æ ¼éƒ½æ— æ³•ä½¿ç”¨ã€‚

æ­¤æ—¶ï¼Œæˆ‘å°è¯•äº†å„ç§ç»„åˆï¼š

+   æç¤º

+   æ¸©åº¦

+   ä½¿ç”¨ Markdownã€HTML å’Œ CSV å®šä¹‰è¾“å…¥è¡¨æ ¼

+   æç¤º GPT-3 ç”Ÿæˆç”¨äºè§£æçš„ Python ä»£ç ï¼Œè€Œä¸æ˜¯è§£æè¡¨æ ¼

æœ‰æ—¶è¯¥è¿‡ç¨‹èƒ½å¤Ÿç”Ÿæˆåˆ—æ ‡é¢˜å’Œæ•°å€¼å®Œç¾çš„è¡¨æ ¼ï¼Œä½†é€šå¸¸è¿™éœ€è¦é«˜æ¸©åº¦å€¼ï¼Œå› æ­¤ä¸å¯é‡å¤ã€‚å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œç»“æœçœ‹èµ·æ¥åˆç†ï¼Œä½†æ•°æ®ä¸æ­£ç¡®ã€‚

å…¬å¹³åœ°è¯´ï¼Œæˆ‘ä»¬çœŸçš„å¯¹ GPT-3 æå‡ºäº†å¾ˆé«˜çš„è¦æ±‚ï¼Œè¿™æ˜¯ä¸€é¡¹å¤æ‚çš„é›¶æ ·æœ¬ä»»åŠ¡ã€‚æˆ‘å¯¹å®ƒçš„è¡¨ç°æ„Ÿåˆ°éå¸¸æ»¡æ„ï¼Œä¹Ÿè®¸é€šè¿‡æ›´å¥½çš„æç¤ºå’Œé—®é¢˜çš„é‡æ–°æ¡†å®š â€”â€” æˆ– GPT-4ï¼â€”â€” ç»“æœå¯èƒ½ä¼šæœ‰æ‰€æ”¹å–„ï¼Œä½†æˆ‘æ²¡æœ‰èƒ½å¤Ÿå®ç°æ‰€éœ€çš„ç»“æœã€‚

# **å•æ¬¡æç¤º**

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨æç¤ºä¸­æä¾›ä¸€ä¸ªç¤ºä¾‹ã€‚æˆ‘ä»äººé“æ•°æ®äº¤æ¢è·å–äº†ä¸€ä¸ªç±»ä¼¼çš„ Excel æ–‡ä»¶ â€¦

![](img/b6734984ce006423ea85a20d05d2a155.png)

æˆ‘ä»¬å°†åœ¨å•æ¬¡æç¤ºä¸­ä½¿ç”¨çš„è¡¨æ ¼ã€‚æ­¤æ–‡ä»¶æ¥æºäº [äººé“æ•°æ®äº¤æ¢](https://data.humdata.org/dataset/kenya-production-of-rice-in-irrigation-schemes)

æˆ‘ä»¬å¸Œæœ›è¿™è¢«å¤„ç†æˆå¦‚ä¸‹æ‰€ç¤º â€¦

![](img/7ee9f834c88fea08684d2810cfe5bd4f.png)

æˆ‘ä»¬çš„ç¤ºä¾‹æ–‡ä»¶åœ¨é‡æ–°æ ¼å¼åŒ–åçš„æ ·å­

æ˜¾ç„¶ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸åˆ‡å®é™…çš„â€œçœŸå®ä¸–ç•Œâ€ç¤ºä¾‹ï¼Œå› ä¸ºæ ¼å¼å’Œå†…å®¹ä¸æˆ‘ä»¬å°è¯•å¤„ç†çš„è¡¨æ ¼éå¸¸ç›¸ä¼¼ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åˆæ­¥æµ‹è¯•ã€‚

å°†æˆ‘ä»¬çš„è¾“å…¥è¡¨æ ¼è½¬æ¢ä¸º CSV å¹¶å–æ¶ˆåˆå¹¶åˆå¹¶çš„å•å…ƒæ ¼ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬å¾—åˆ° â€¦

![](img/f68f7f17e4a196691c5f3dd6e854da4e.png)

æˆ‘ä»¬ç°åœ¨å¯ä»¥æ„å»ºæˆ‘ä»¬çš„å•æ¬¡æç¤ºï¼ˆå‡è®¾æ¸©åº¦ä¸ºé›¶ä»¥ä¾¿å¯é‡å¤ï¼‰ â€¦

```py
from io import StringIO

wb = openpyxl.load_workbook(prompt_sample_table1, data_only=True)
sheet = wb["Sheet1"]
example_before, sheet, hasmerged = pad_merged_cells(sheet)
example_before_csv = example_before.to_csv()
example_after, hasmerged, report = parse_excel_sheet(sheet)
example_after_markdown = example_after.to_markdown()
example_after_csv = example_after.to_csv()

example_before_csv = """
 ,0,1,2,3,4,5,6,7
0,Table 16: % of infants on Minimum Dietary Diversity,,,,,,,
1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county
2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Bomet Central,Bomet Central
3,,,N,%,n,%,n,%
4,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%
5,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%
6,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%
"""

example_after_markdown = (
    """
 |    |                                      |                                         |   OVERALL - N | OVERALL - %   |   Sub county - Chepalungu | Sub county - Chepalungu - %   |   Sub county - Bomet Central | Sub county - Bomet Central - %   |
|---:|:-------------------------------------|:----------------------------------------|--------------:|:--------------|--------------------------:|:------------------------------|-----------------------------:|:---------------------------------|
|  1 | Infants         on Dietary Diversity | Infants  on  Minimum  Dietary Diversity |            37 | 17.5%         |                        24 | 17.9%                         |                           13 | 16.7%                            |
|  2 | Infants         on Dietary Diversity | Infants not on Dietary Diversity        |           175 | 82.5%         |                       110 | 82.1%                         |                           65 | 83.3%                            |
|  3 | Infants         on Dietary Diversity | Total                                   |           212 | 100.0%        |                       134 | 100.0%                        |                           78 | 100.0%                           |
""".replace(
        ":|", "|"
    )
    .replace("|:", "|")
    .replace("\n", "\n<RETURN>")
)

example_after_csv = """
 , , ,OVERALL - N,OVERALL - %,Sub county - Chepalungu,Sub county - Chepalungu - %,Sub county - Bomet Central,Sub county - Bomet Central - %
1,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%
2,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%
3,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%
"""

table_to_parse_padded = """
,0,1,2,3,4,5,6,7,8,9,10,11
0,Table 3: Number of acreage under irrigation,,,,,,,,,,,
1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county
2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Chepalungu,Chepalungu,Bomet Central,Bomet Central,Bomet Central,Bomet Central
3,,,OVERALL,OVERALL,Male,Male,Female,Female,Male,Male,Female,Female
4,,,N,%,N,%,N,%,N,%,N,%
5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%
6,What is the average size of land you own that is currently under irrigation?,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%
7,What is the average size of land you own that is currently under irrigation?,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%
8,What is the average size of land you own that is currently under irrigation?,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%
9,What is the average size of land you own that is currently under irrigation?,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%
10,What is the average size of land you own that is currently under irrigation?,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%
"""

prompt = (
    "Reformat this table to only have a single header row: \n\n"
    + example_before_csv
    + "\n\n"
    + "Result: \n\n"
    + example_after_csv
    + "\n\n"
    + "Reformat this table to only have a single header row: \n\n"
    + table_to_parse_padded
    + "\n\n"
    + "Result: \n\n"
)

print("\n\n", prompt, "\n\n")

completions = ai.Completion.create(
    engine="text-davinci-003",
    temperature=0.0,
    prompt=prompt,
    n=1,
    stop=None,
    max_tokens=2068,
    top_p=1,
    frequency_penalty=0,
    presence_penalty=0,
)

print("\n========== Model prediction:\n")

display(pd.read_csv(StringIO(completions.choices[0].text)))
```

è¿™æ˜¯ç”Ÿæˆçš„æç¤º â€¦

```py
Reformat this table to only have a single header row: 

 ,0,1,2,3,4,5,6,7
0,Table 16: % of infants on Minimum Dietary Diversity,,,,,,,
1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county
2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Bomet Central,Bomet Central
3,,,N,%,n,%,n,%
4,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%
5,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%
6,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%

Result: 

 , , ,OVERALL - N,OVERALL - %,Sub county - Chepalungu,Sub county - Chepalungu - %,Sub county - Bomet Central,Sub county - Bomet Central - %
1,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%
2,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%
3,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%

Reformat this table to only have a single header row: 

,0,1,2,3,4,5,6,7,8,9,10,11
0,Table 3: Number of acreage under irrigation,,,,,,,,,,,
1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county,Sub county
2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Chepalungu,Chepalungu,Bomet Central,Bomet Central,Bomet Central,Bomet Central
3,,,OVERALL,OVERALL,Male,Male,Female,Female,Male,Male,Female,Female
4,,,N,%,N,%,N,%,N,%,N,%
5,What is the average size of land you own that is currently under irrigation?,0 - 2 acres,22,2.8%,4,2.2%,10,3.8%,3,1.7%,5,2.9%
6,What is the average size of land you own that is currently under irrigation?,2 - 5 acres,6,.8%,2,1.1%,2,.8%,0,0.0%,2,1.2%
7,What is the average size of land you own that is currently under irrigation?,5 - 10 acres,1,.1%,0,0.0%,0,0.0%,0,0.0%,1,.6%
8,What is the average size of land you own that is currently under irrigation?,More than 10 acres,0,0.0%,0,0.0%,0,0.0%,0,0.0%,0,0.0%
9,What is the average size of land you own that is currently under irrigation?,None,760,96.3%,176,96.7%,251,95.4%,170,98.3%,163,95.3%
10,What is the average size of land you own that is currently under irrigation?,Total,789,100.0%,182,100.0%,263,100.0%,173,100.0%,171,100.0%

Result: 
```

è¿™æ˜¯ GPT-3 çš„å®Œæˆç»“æœï¼Œè½¬æ¢ä¸ºæ•°æ®æ¡†ä»¥ä¾¿æ›´å®¹æ˜“æ˜¾ç¤º â€¦

![](img/dce195b89914d22ee19d93cb75f89cf2.png)

ä»å•æ¬¡æç¤ºç”Ÿæˆçš„è¡¨æ ¼ï¼Œé‡æ–°æ ¼å¼åŒ–å…·æœ‰å±‚æ¬¡ç»“æ„æ ‡é¢˜çš„è¡¨æ ¼ï¼ˆå®Œæˆç»“æœæ˜¯ CSVï¼Œè¿™é‡Œä¸ºä¾¿äºå±•ç¤ºè½¬æ¢ä¸º pandas æ•°æ®æ¡†ï¼‰

å¾ˆå¥½ï¼å½“æä¾›ä¸€ä¸ªç¤ºä¾‹æ—¶ï¼ŒGPT-3 èƒ½å¤Ÿå®Œç¾åœ°é‡æ–°æ ¼å¼åŒ–æˆ‘ä»¬çš„æ–°è¡¨æ ¼ã€‚ç„¶è€Œï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æµ‹è¯•ï¼Œå› ä¸ºç¤ºä¾‹è¡¨æ ¼å’Œæµ‹è¯•è¡¨æ ¼åœ¨ç»“æ„å’Œå†…å®¹ä¸Šéå¸¸ç›¸ä¼¼ï¼Œä½†æœ‰è¶£çš„æ˜¯ï¼Œå³ä½¿ç¤ºä¾‹ä¸­æ²¡æœ‰ç”·æ€§/å¥³æ€§çš„å±‚çº§ï¼ŒGPT-3 ä»èƒ½æ­£ç¡®åœ°æŠ˜å è¿™ä¸ªé¢å¤–çš„å±‚çº§ã€‚

è®©æˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„ç¤ºä¾‹è¡¨æ ¼æ¥é‡æ–°æ ¼å¼åŒ–ä¸€ä¸ªå…·æœ‰ä¸åŒå¸ƒå±€å’Œå†…å®¹æ•°æ®çš„è¡¨æ ¼ â€¦

![](img/9e175fd03da4432492fa789dfb8f5f06.png)

ä½¿ç”¨ç›¸åŒçš„ä»£ç å¤„ç†å¾—åˆ°çš„æ˜¯ â€¦

![](img/4362466354eb63c092183ca9952b5ba1.png)

è¿™å¾ˆæ¥è¿‘ï¼Œæ ‡é¢˜å®Œå…¨æ­£ç¡®ï¼Œä½†å†œåœºåˆ—å‘å·¦ç§»åŠ¨äº†ã€‚æˆ‘ä»¬çš„å•æ¬¡æç¤ºåœ¨é‡æ–°æ ¼å¼åŒ–éå¸¸ç›¸ä¼¼çš„è¡¨æ ¼æ—¶è¡¨ç°ä¸é”™ï¼Œä½†ç¨å¾®çš„å˜åŒ–å¯¼è‡´äº†è¾ƒå·®çš„ç»“æœã€‚

# å•æ¬¡æç¤ºï¼Œå¸¦æœ‰æ¨ç†

å…³äºæç¤ºå·¥ç¨‹å·²ç»æœ‰ç›¸å½“å¤šçš„ç ”ç©¶ã€‚ä¸€ä¸ªéå¸¸å¥½çš„èµ„æºå¯ä»¥åœ¨ OpenAI Cookbook çš„ [æå‡å¯é æ€§çš„æŠ€æœ¯](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md) [3] ä¸­æ‰¾åˆ°ã€‚æé«˜ç»“æœçš„æœ€æœ‰æ•ˆæ–¹æ³•ä¹‹ä¸€æ˜¯åŒ…å«æ¨ç†åœ¨ç¤ºä¾‹æç¤ºä¸­ [[4](https://arxiv.org/abs/2205.11916)]ã€‚ä»¥æˆ‘ä»¬ä¹‹å‰çš„è¡¨æ ¼ä¸ºä¾‹ï¼Œè°ƒæ•´æç¤ºä»¥åŒ…æ‹¬æ¨ç† â€¦

```py
prompt = (
    "We need to reformat this table to only have a single header row: \n\n"
    + example_before_csv
    + "\n"
    + "Let's think step by step \n"
    + "Row 1 is just an index row, it has no text or data \n"
    + "Row 2 contains just label text \n"
    + "Rows 3 to 5 contain column headers \n"
    + "Rows 6 onwards contain data \n"
    + "Columns are separated by commas, there should be 7 commas on each row \n"
    + "If we combine each colummn of rows 3 to 5 by concatenating vertically, we get \n"
    + example_after_csv
    + "\n\n"
    + "We need to reformat this table to only have a single header row: \n\n"
    + table_to_parse_padded
    + "\n\n"
    + "Let's think step by step \n\n"
)
```

å®Œæ•´çš„æç¤ºå¦‚ä¸‹ â€¦

```py
We need to reformat this table to only have a single header row: 

 ,0,1,2,3,4,5,6,7
0,Table 16: % of infants on Minimum Dietary Diversity,,,,,,,
1,,,OVERALL,OVERALL,Sub county,Sub county,Sub county,Sub county
2,,,OVERALL,OVERALL,Chepalungu,Chepalungu,Bomet Central,Bomet Central
3,,,N,%,n,%,n,%
4,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%
5,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%
6,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%

Let's think step by step 
Row 1 is just an index row, it has no text or data 
Row 2 contains just label text 
Rows 3 to 5 contain column headers 
Rows 6 onwards contain data 
Columns are separated by commas, there should be 7 commas on each row 
If we combine each colummn of rows 3 to 5 by concatenating vertically, we get 

 , , ,OVERALL - N,OVERALL - %,Sub county - Chepalungu - N,Sub county - Chepalungu - %,Sub county - Bomet Central - N,Sub county - Bomet Central - %
1,Infants         on Dietary Diversity,Infants  on  Minimum  Dietary Diversity,37,17.5%,24,17.9%,13,16.7%
2,Infants         on Dietary Diversity,Infants not on Dietary Diversity,175,82.5%,110,82.1%,65,83.3%
3,Infants         on Dietary Diversity,Total,212,100.0%,134,100.0%,78,100.0%

We need to reformat this table to only have a single header row: 

,0,1,2,3,4,5
0,Random text here,,,,,
1,,Cows,Cows,Cowboy Hats,Cowboy Hats,Cowboy Hats
2,,TOT,Farm,Small ,Medium,Large
3,,97,6666,0.65,,0.13
4,,93,Bar M,,0.2,
5,,140,Daisy,0.3,0.89,
6,,,Plew,0.2,0.5,0.1
7,,119,Birdie,0.2,0.1,
8,,29,Kit Kat,,0.55,

Let's think step by step 
```

è¿™å¯¼è‡´ GPT-3 å¯¹æˆ‘ä»¬è¾“å…¥è¡¨æ ¼çš„å®Œæˆç»“æœæ˜¯ â€¦

```py
Row 1 is just an index row, it has no text or data 
Row 2 contains just label text 
Rows 3 to 8 contain column headers 
Rows 9 onwards contain data 
Columns are separated by commas, there should be 6 commas on each row 
If we combine each colummn of rows 3 to 8 by concatenating vertically, we get 

 , ,Cows - TOT,Cows - Farm,Cowboy Hats - Small ,Cowboy Hats - Medium,Cowboy Hats - Large
1,,97,6666,0.65,,0.13
2,,93,Bar M,,0.2,
3,,140,Daisy,0.3,0.89,
4,,,Plew,0.2,0.5,0.1
5,,119,Birdie,0.2,0.1,
6,,29,Kit Kat,,0.55,
```

è¿™å¾ˆæ­£ç¡®ï¼é‡æ–°æ ¼å¼åŒ–åçš„è¡¨æ ¼æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ â€¦

![](img/b44674a075c338a587502b102c6d2ca1.png)

å¦‚æœæˆ‘ä»¬åœ¨å•æ¬¡æç¤ºä¸­æä¾›æ¨ç†ï¼Œç»“æœä¼šæœ‰æ‰€æ”¹å–„

ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬æä¾›çš„ä»»åŠ¡å¹¶ä¸æ˜¯å¾ˆå¥½ï¼Œå› ä¸ºå°½ç®¡å†…å®¹ä¸æä¾›çš„ç¤ºä¾‹ä¸åŒï¼Œä½†æ ‡é¢˜å¸ƒå±€ä»ç„¶ç›¸ä¼¼ã€‚äº‹å®ä¸Šï¼Œå¦‚æœæˆ‘ä»¬ç¨å¾®è°ƒæ•´ä¸€ä¸‹è¦é‡æ–°æ ¼å¼åŒ–çš„è¡¨æ ¼å¹¶æ·»åŠ ä¸€ä¸ªé¢å¤–çš„â€œæœ‰æœºâ€åˆ— â€¦

![](img/886cf8bea9babb627b68d1e2fa6fb8d2.png)

å‘è¾“å…¥ä¸­æ·»åŠ ä¸€ä¸ªé¢å¤–çš„åˆ—

é¢„æµ‹ç°åœ¨ä¸æ­£ç¡® â€¦

![](img/cbfa4266f749d5f3981baee97d382890.png)

åªæ˜¯æ ‡é¢˜è¡Œä¸­å¤šäº†*ä¸€ä¸ª*é¢å¤–çš„é€—å·ï¼Œè¿™å¯¼è‡´æ‰€æœ‰å†…å®¹å‘å³ç§»åŠ¨ã€‚

æˆ‘ä»¬å¯èƒ½ä¼šç»§ç»­é€šè¿‡æ›´å¤šæ¨ç†æ¥ä¼˜åŒ–æç¤ºï¼Œæˆ–åº”ç”¨ [æ›´é«˜çº§çš„æŠ€æœ¯](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md) è‡ªåŠ¨æ„å»ºæˆ‘ä»¬çš„æç¤ºå·¥ä½œæµï¼Œä½†çœŸæ­£çš„é—®é¢˜æ˜¯ä¸€ä¸ªç¤ºä¾‹å¹¶ä¸è¶³ä»¥æ•æ‰æˆ‘ä»¬å¯èƒ½é‡åˆ°çš„æ‰€æœ‰è¡¨æ ¼æ ¼å¼å˜ä½“ã€‚å°½ç®¡ GPT-3 åœ¨ä»…æœ‰ä¸€ä¸ªç¤ºä¾‹çš„æƒ…å†µä¸‹è¡¨ç°å¾—éå¸¸å¥½ï¼Œä½†å¯¹äºè¿™ä¸ªä»»åŠ¡æ¥è¯´ï¼Œå®ƒè¿˜ä¸å¤Ÿå¥½ï¼ˆè‡³å°‘å°±ç›®å‰çš„æ¡†æ¶è€Œè¨€ï¼‰ã€‚

# å°‘é‡ç¤ºä¾‹â€¦. æˆ–è€…è¯´ä¸æ˜¯

ä¸‹ä¸€ä¸ªæ–¹æ³•å¯èƒ½æ˜¯æä¾›å¤šä¸ªç¤ºä¾‹ã€‚ç„¶è€Œï¼Œè¡¨æ ¼ç‰‡æ®µéœ€è¦å¤§é‡çš„ä»¤ç‰Œï¼ˆç¨åä¼šè¯¦ç»†è¯´æ˜ï¼‰ï¼Œæ‰€ä»¥å¦‚æœæˆ‘ä»¬å¿…é¡»åœ¨æç¤ºä¸­æä¾›å¤šä¸ªç¤ºä¾‹ï¼Œå†åŠ ä¸Šç»“æœä¸­çš„ä»¤ç‰Œï¼Œå°±ä¼šè§¦åŠ Open API çš„ä»¤ç‰Œé™åˆ¶ã€‚å¯¹äº davinci æ¨¡å‹ï¼Œç›®å‰çš„é™åˆ¶ä¸º[4,000](https://platform.openai.com/docs/models/gpt-3)ä¸ªä»¤ç‰Œã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬æŒ‰ä»¤ç‰Œæ”¶è´¹ï¼Œå¯¹äºåƒ[DataKind](https://www.datakind.org/)è¿™æ ·çš„å°å‹éè¥åˆ©ç»„ç»‡ï¼Œå‘é€å’Œæ¥æ”¶å¤§é‡ä»¤ç‰Œå¯èƒ½ä¼šå˜å¾—æ˜‚è´µã€‚æ›´é•¿çš„æç¤ºè¿˜æœ‰æ€§èƒ½å½±å“ï¼Œå› æ­¤å¯¹äºè¿™ä¸ªä»»åŠ¡æ²¡æœ‰æ¢ç´¢å°‘æ ·æœ¬æç¤ºã€‚

æ‰€ä»¥æˆ‘å†³å®šæš‚æ—¶è·³è¿‡å°‘æ ·æœ¬å­¦ä¹ ã€‚

# å¾®è°ƒ

æ¢ç´¢é›¶æ ·æœ¬å’Œå•æ ·æœ¬æç¤ºå¾ˆæœ‰è¶£ï¼Œå¦‚æœè¿™äº›æ–¹æ³•åœ¨è¿™ä¸ªç”¨ä¾‹ä¸­æœ‰æ•ˆï¼Œå°†ä¼šå–å¾—æƒŠäººçš„ç»“æœã€‚æœªæ¥ï¼Œéšç€æ¨¡å‹çš„æ”¹è¿›ï¼Œè¿™å¯èƒ½ä¼šæˆä¸ºä¸€ä¸ªå¯è¡Œçš„é€‰é¡¹ï¼Œä½†ç›®å‰ï¼Œé‡æ–°å®šä¹‰ä»»åŠ¡å¯èƒ½æ›´æœ‰æ„ä¹‰ã€‚

å¦ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡[å¾®è°ƒ](https://platform.openai.com/docs/guides/fine-tuning)æä¾›*å¤§é‡*ç¤ºä¾‹ã€‚æ­£å¦‚ OpenAI æ‰€è¿°ï¼š

*å¾®è°ƒå¯ä»¥é€šè¿‡æä¾›ä»¥ä¸‹å†…å®¹æ¥è®©ä½ æ›´å¥½åœ°åˆ©ç”¨ API æä¾›çš„æ¨¡å‹ï¼š*

1.  *æ¯”æç¤ºè®¾è®¡äº§ç”Ÿæ›´é«˜è´¨é‡çš„ç»“æœ*

1.  *èƒ½å¤Ÿåœ¨æ¯”æç¤ºä¸­èƒ½å®¹çº³çš„æ›´å¤šç¤ºä¾‹ä¸Šè¿›è¡Œè®­ç»ƒ*

1.  *ç”±äºæç¤ºè¾ƒçŸ­è€ŒèŠ‚çœä»¤ç‰Œ*

1.  *æ›´ä½å»¶è¿Ÿçš„è¯·æ±‚*

èµ·åˆï¼Œæˆ‘è€ƒè™‘é€šè¿‡æä¾› GPT-3ï¼ˆiï¼‰åŸå§‹è¡¨æ ¼çš„æç¤ºï¼ˆåˆå¹¶å•å…ƒæ ¼æœªåˆå¹¶ï¼‰å’Œï¼ˆiiï¼‰ä½œä¸ºé‡æ–°æ ¼å¼åŒ–è¡¨æ ¼çš„å®Œæˆé¡¹æ¥è¿›è¡Œå¾®è°ƒã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•çš„æŒ‘æˆ˜åœ¨äºï¼Œå®ƒä»ç„¶ä½¿ç”¨äº†å¤§é‡çš„ä»¤ç‰Œï¼Œå°¤å…¶æ˜¯æˆ‘ä»¬ç°åœ¨éœ€è¦ä½¿ç”¨æ•°ç™¾ä¸ªç¤ºä¾‹ã€‚

ä¸å…¶ä¼ é€’åŸå§‹è¡¨æ ¼ç‰‡æ®µï¼Œä¸å¦‚å°è¯•ä½¿ç”¨è¯¥è¡¨æ ¼çš„å±æ€§ï¼Œå¹¶è®© GPT-3 é¢„æµ‹æˆ‘ä»¬å¯ä»¥ç”¨æ¥è§£æçš„å…³é”®è¿›ä¸€æ­¥å±æ€§â€¦â€¦

# é‡æ–°å®šä¹‰ä»»åŠ¡ â€” ä½¿ç”¨è¡¨æ ¼å±æ€§ä½œä¸ºæç¤º

ä½œä¸ºä¸€ä¸ªäººï¼ˆå¥½å§ï¼Œ*å¤§éƒ¨åˆ†*æ˜¯äººï¼‰ï¼Œå½“æˆ‘æ‰«æ Excel ä¸­çš„è¡¨æ ¼æ—¶ï¼Œæˆ‘å¯ä»¥é€šè¿‡æŸ¥çœ‹å€¼æ¥è¯†åˆ«ç»“æ„ï¼Œå¹¶å†³å®šæ•°æ®çš„ä½ç½®ã€‚

![](img/0b92fbbdfffa07263c0ca4bafb60f3c6.png)

ç¡®å®šè¡¨æ ¼ä¸­çš„æ•°æ®éƒ¨åˆ†æ˜¯å°†å…¶è§£ææˆè§„åˆ™è¡¨æ ¼ç»“æ„çš„å…³é”®

ä¸€æ—¦æˆ‘çŸ¥é“æ•°æ®å¼€å§‹çš„è¡Œï¼Œå°±å¾ˆå®¹æ˜“ä»ä¸Šé¢çš„è¡Œæ¨æ–­å‡ºæ ‡é¢˜å±‚æ¬¡ï¼Œå¹¶å°†å®ƒä»¬åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„æ ‡é¢˜è¡Œï¼Œä»¥åˆ›å»ºä¸€ä¸ªæ•´é½ã€è§„åˆ™çš„è¡¨æ ¼æ¥ä½¿ç”¨â€¦â€¦

![](img/81f481c588bb27c7779ca9dfc6c34b54.png)

å¤„ç†åçš„è¡¨æ ¼å…·æœ‰å¹³é¢æ ‡é¢˜ï¼Œå®¹æ˜“å¯¼å…¥å…³ç³»æ•°æ®åº“

ç¡®å®šæ•°æ®çš„å¼€å§‹ä½ç½®ä¹ä¸€çœ‹ä¼¼ä¹å¾ˆç®€å•ï¼Œåªéœ€åœ¨ [openpyxl](https://openpyxl.readthedocs.io/en/stable/) æˆ– [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) ä¸­ç¨ä½œå¤„ç†å³å¯ã€‚ç„¶è€Œï¼Œå¦‚æœéœ€è¦å¤„ç†æˆåƒä¸Šä¸‡çš„å…·æœ‰ä¸åŒæ ‡é¢˜å¸ƒå±€ã€ç©ºç™½è¡Œç­‰çš„ç”µå­è¡¨æ ¼ï¼Œå¼€å‘ä¸€å¥—ç”¨äºå‡†ç¡®è¯†åˆ«æ¯ä¸ªå·¥ä½œè¡¨ä¸­æ•°æ®å¼€å§‹ä½ç½®çš„è§„åˆ™å°†æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚

è¿™å¾ˆå¤æ‚ï¼Œå› ä¸ºï¼š

+   åˆ—æ ‡é¢˜å¯èƒ½æœ‰å¾ˆé«˜çš„å˜åŒ–æ€§ï¼Œçœ‹èµ·æ¥åƒæ•°æ®ã€‚

+   ç©ºç™½å•å…ƒæ ¼å’Œæ³¨é‡Šå®¹æ˜“æ··æ·†è§£æè§„åˆ™ã€‚

+   æ•°æ®ä¸æ€»æ˜¯æ•°å­—çš„ï¼Œå®ƒå¯ä»¥æ˜¯åˆ†ç±»çš„ï¼Œçœ‹èµ·æ¥å¾ˆåƒåˆ—æ ‡é¢˜ã€‚

+   ä¸€äº›åˆ—æ ‡é¢˜æ˜¯æ•°å­—ï¼Œå¯èƒ½çœ‹èµ·æ¥åƒæ•°æ®ï¼Œä¾‹å¦‚å¹´ä»½ã€‚

é‚£ä¹ˆï¼Œæˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªäº›è¡¨æ ¼å±æ€§/ç‰¹å¾æ¥é¢„æµ‹æ•°æ®é¦–æ¬¡å‡ºç°çš„è¡Œå·å‘¢ï¼Ÿ

æˆ‘åˆ—å‡ºäº†ä¸€ä¸ªæˆ‘è®¤ä¸ºå¯èƒ½æœ‰ç”¨çš„è¡¨æ ¼å±æ€§çš„ç®€çŸ­æ¸…å•â€¦â€¦

```py
import openpyxl

def get_sheet_attributes(sheet, maxn):
    """
    Returns a set of table attributes for a given sheet

    Input Parameters:
        sheet: Obj
            Openpyxl sheet object
        maxn: int
            Number of rows to scan at start of sheet

    Returns:
        null_cells_in_rows: list of ints
            Count of NULL records in forst maxn rows
        float_cells_in_rows: list of ints
            Count of numeric records in first maxn rows
        unique_vals_in_rows: list of ints
            Count of unique values in first maxn rows
        year_vals_in_rows: list of ints
            Count of year values in first maxn rows
        hxl_row: int
            Row number of HXL header row
        first_float_row: int
            Row number of row with most numeric records
        first_not_null_row: int
            Row number of row with most non-null records

    """
    dd = pd.DataFrame(sheet.values)

    null_cells_in_rows = list(
        dd[0:maxn].apply(lambda x: x.isnull().sum(), axis="columns")
    )
    float_cells_in_rows = []
    unique_vals_in_rows = []
    year_vals_in_rows = []
    report_json = {}
    hxl_row = None
    for index, row in dd[0:maxn].iterrows():
        unique_vals = list(row.unique())
        unique_vals = [i for i in unique_vals if i is not None and str(i) != "nan"]
        unique_vals_in_rows.append(len(unique_vals))
        float_count = 0
        year_count = 0
        if check_hdx_header(list(row)):
            hxl_row = index
        for col in dd.columns:
            val = row[col]
            # Handle numbers that come through as strings
            if isinstance(val, str):
                val = val.replace(",", "").replace(" ", "")
                if val.isnumeric():
                    val = int(val)
            # Check for year values
            if (
                ((isinstance(val, int) or isinstance(val, float)) and val % 1 == 0)
                and val > 1900
                and val < 2100
            ):
                year_count += 1
                continue
            # Check for HXL tags
            if isinstance(val, float) or isinstance(val, int) or "^=" in str(row[col]):
                float_count += 1
        float_cells_in_rows.append(float_count)
        year_vals_in_rows.append(year_count)

    max_floats = max(float_cells_in_rows)
    min_nulls = min(null_cells_in_rows)
    first_float_row = 0
    if sum(float_cells_in_rows) > 0:
        for i in range(1, len(float_cells_in_rows)):
            # Use a ratio or special case where we go from zero to some
            if float_cells_in_rows[i] / max_floats > 0.5 or (
                float_cells_in_rows[i] > 0 and float_cells_in_rows[i - 1] == 0
            ):
                first_float_row = i
                break
    first_not_null_row = np.argmin(null_cells_in_rows)

    report = f"Nulls in first {maxn} rows: {str(null_cells_in_rows)}\n"
    report += f"Numeric first {maxn} rows: {str(float_cells_in_rows)}\n"
    report += f"Unique values in first {maxn} rows: {str(unique_vals_in_rows)}\n"
    report += f"Year values in first {maxn} rows: {str(year_vals_in_rows)}\n"
    report += f"HXL row: {str(hxl_row)}\n"

    report += f"\nFirst reduced nulls row: {str(first_not_null_row)}\n"
    report += f"First increased numeric row (excluding years): {str(first_float_row)}\n"

    report_json = {
        "null_cells_in_rows": null_cells_in_rows,
        "float_cells_in_rows": float_cells_in_rows,
        "unique_vals_in_rows": unique_vals_in_rows,
        "year_vals_in_rows": year_vals_in_rows,
        "hxl_row": hxl_row,
        "first_float_row": first_float_row,
        "first_not_null_row": first_not_null_row,
    }

    return report, report_json

wb = openpyxl.load_workbook(filename, data_only=True)
for s in wb.sheetnames:
    sheet = wb[s]
    report, report_json = get_sheet_attributes(sheet, maxn)
    print(report) 
```

è¿™ä¼šäº§ç”Ÿè¿™æ ·çš„è¾“å‡ºâ€¦â€¦

```py
Nulls in first 10 rows: [12, 11, 10, 10, 8, 2, 0, 1, 1, 1]
Numeric first 10 rows: [0, 0, 0, 0, 0, 0, 5, 5, 5, 5]
Unique values in first 10 rows: [0, 1, 2, 2, 2, 2, 12, 8, 6, 3]
Year values in first 10 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
HXL row: None

First reduced nulls row: 6
First increased numeric row (excluding years): 6
```

è¿™äº›å°†æ˜¯æˆ‘ä»¬ç”¨äºå¾®è°ƒæ¨¡å‹çš„æç¤ºã€‚

ä¸ºäº†åˆ›å»ºå¾®è°ƒæ–‡ä»¶çš„è¡¥å…¨ï¼Œæˆ‘ä½¿ç”¨äº†è‚¯å°¼äºšçš„äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢æ•°æ®é›†ï¼ˆæœ‰å…³å¦‚ä½•æå– Excel æ–‡ä»¶çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è§è¿™é‡Œï¼‰ã€‚è§£ææ–‡ä»¶å¹¶å¾ªç¯éå†æ¯ä¸ªå·¥ä½œè¡¨ï¼Œæˆ‘ç”Ÿæˆäº†æç¤ºã€‚

æˆ‘ä½¿ç”¨äº†ä»¥ä¸‹é€»è¾‘æ¥ä¼°ç®—æ•°æ®å¼€å§‹çš„è¡Œå·ï¼Œä½¿ç”¨äº†ä¸Šè¿°è¡¨æ ¼å‚æ•°â€¦â€¦

```py
# Make a guess at which row is the data row
datarow = max_not_null_row
# Sometimes we have header rows where none are null, in this case we want to use the row with the most floats
if max_float_row > datarow:
    datarow = max_float_row
# HXL row is always the row before the data row
if hxl_row is not None:
    datarow = hxl_row
# If we a row with a lot of year values below datarow, use that
if year_vals_in_rows[datarow] > 3:
    datarow = datarow + 1
```

è¿™ç§åŸºäºè§„åˆ™çš„æ–¹æ³•å®é™…ä¸Šè¡¨ç°å¾—ç›¸å½“ä¸é”™ï¼Œä½†å®ƒå¹¶ä¸å®Œç¾ï¼Œå› æ­¤éœ€è¦ GPT-3ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒåœ¨åˆ›å»ºä¸€ä¸ªå¤§å¤šæ•°è¡¥å…¨éƒ½å‡†ç¡®çš„æµ‹è¯•é›†æ—¶å¾ˆæœ‰ç”¨ï¼Œæˆ‘åªéœ€è°ƒæ•´å‡ ä¸ªé€»è¾‘ä¸æˆç«‹çš„éƒ¨åˆ†å³å¯ã€‚

å¯¹äºæˆ‘çš„è®­ç»ƒé›†ï¼Œæˆ‘ä½¿ç”¨äº†æ¥è‡ª 10 ä¸ªäººé“ä¸»ä¹‰æä¾›ç»„ç»‡çš„å¤šä¸ªæ ‡è®°ä¸ºâ€œKenyaâ€çš„ Excel è¡¨æ ¼ä¸­çš„æ¯ä¸ªç»„ç»‡çš„ä¸€ä¸ªè¡¨æ ¼ï¼Œå…¶ä¸­ä½¿ç”¨ä¸Šè¿°åŸºäºè§„åˆ™çš„æ–¹æ³•è¿›è¡Œäº†é¦–æ¬¡æ•°æ®è¡Œçš„é¢„æµ‹ã€‚æˆ‘éšåå®¡æŸ¥äº†è¿™ä»½æ¸…å•ï¼Œå¹¶ä¸å®é™…çš„å·¥ä½œè¡¨è¿›è¡Œäº†æ¯”è¾ƒï¼Œä»¥çº æ­£ç”µå­è¡¨æ ¼è¡¨æ ¼å¼€å§‹äºä¸åŒçš„è¡Œçš„æƒ…å†µã€‚æˆ‘æ’é™¤äº†æœ¬ç ”ç©¶ä¸­å­˜åœ¨å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µï¼Œæ­¤åæˆ‘å¾—åˆ°äº† 232 ä¸ªè¿™æ ·çš„å¾®è°ƒæç¤ºâ€¦â€¦

```py
{"prompt": "Nulls in first 15 rows: [9, 8, 7, 7, 3, 1, 2, 2, 2, 2, 2]\nNumeric first 15 rows: [0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3]\nUnique values in first 15 rows: [0, 1, 2, 2, 3, 8, 7, 7, 6, 6, 5]\nYear values in first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nHXL row: None\nFirst reduced nulls row: 5\nFirst increased numeric row (excluding years): 5", "completion": "Data starts at row: 5\n", "meta_data": "./data/Kenya/kenya-hand-washing-statistics-in-bomet-county_118ea93f-83ce-4b86-b1c4-ca54ea9acc8a/Hand_washing_practices_xlsx_efc74f32_ac23_463a_924b_d53c3656b406/Hand washing practices.xlsx"}
{"prompt": "Nulls in first 15 rows: [2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1]\nNumeric first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nUnique values in first 15 rows: [0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]\nYear values in first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nHXL row: None\nFirst reduced nulls row: 1\nFirst increased numeric row (excluding years): 0", "completion": "Data starts at row: 1\n", "meta_data": "./data/Kenya/shcchealthcare-dataset_02995168-3644-4b78-92be-cdf67275b39d/2018_SHCC_Overview_Data_xlsx_d053b42a_7d31_41b5_a6d9_c8b0a424241c/2018 SHCC Overview Data.xlsx"}
{"prompt": "Nulls in first 15 rows: [6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 7, 6, 3]\nNumeric first 15 rows: [0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 0, 0, 0]\nUnique values in first 15 rows: [1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 1, 4]\nYear values in first 15 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nHXL row: None\nFirst reduced nulls row: 1\nFirst increased numeric row (excluding years): 2", "completion": "Data starts at row: 2\n", "meta_data": "./data/Kenya/eastern-southern-africa-refugees-and-idps-situation-and-response-dec2019_e1f9f55e-08db-4166-a787-c7ea9969dc4d/UNICEF_ESARO_Regional_refugee_and_idp_db_2019_November_27_2019_xlsx_0696b7f3_6368_403e_bcb7_eccdc617961f/UNICEF ESARO Regional refugee and idp db 2019 November 27.2019.xlsx"}
```

**é™„æ³¨**ï¼šåœ¨ä¸Šé¢çš„å†…å®¹ä¸­ï¼Œä½ å¯èƒ½æ³¨æ„åˆ°æˆ‘ä¸ºæ¯ä¸ªæç¤ºæ·»åŠ äº†ä¸€ä¸ªâ€œmeta_dataâ€å…ƒç´ ã€‚è¿™ä¸æ˜¯ JSONL æç¤ºè®°å½•çš„å¿…è¦éƒ¨åˆ†ï¼Œä½†æˆ‘è¿™æ ·åšæ˜¯ä¸ºäº†èƒ½å¤Ÿè½»æ¾å°†æ¯ä¸ªæç¤ºä¸æ–‡ä»¶å…³è”ä»¥ä¾¿äºè°ƒè¯•ã€‚åŒ…å«è¿™äº›é¢å¤–æ•°æ®çš„æç¤ºæ–‡ä»¶ä¼¼ä¹ä»ç„¶è¢« OpenAI æ¥å—ï¼Œæˆ‘è®¤ä¸ºåªè¦æœ‰â€œpromptâ€å’Œâ€œcompletionâ€å…ƒç´ ï¼Œå®ƒå°±ä¼šæ¥å—ï¼

ç„¶åæˆ‘å¾®è°ƒäº†ä¸€ä¸ª DaVinci æ¨¡å‹â€¦â€¦

```py
 ai.api_key_path="./api_key.txt"

train_file = './prompts.json'

print("Uploading training file ...")
training_id = cli.FineTune._get_or_upload(train_file, True)

print("Fine-tuning model ...")
create_args = {
    "training_file": training_id,
    "model": "davinci"
}
resp = ai.FineTune.create(**create_args)
job_id = resp["id"]
status = resp["status"]

print(f'Fine-tunning model with jobID: {job_id}.')
```

æˆ‘æ‰‹åŠ¨æ£€æŸ¥äº†å¾®è°ƒçŠ¶æ€ï¼Œå¦‚ä¸‹æ‰€ç¤ºâ€¦â€¦

```py
ai.api_key_path="./api_key.txt"
result = ai.FineTune.retrieve(id=job_id)

print(result['status'])
```

ç„¶åå®Œæˆåï¼Œæ£€ç´¢äº†æ¨¡å‹â€¦â€¦

```py
model = result["fine_tuned_model"]
```

å¯¹äºæµ‹è¯•é›†ï¼Œæˆ‘ä½¿ç”¨äº†æ¥è‡ªè®­ç»ƒé›†ä¹‹å¤–ç»„ç»‡ï¼ˆæ ‡è®°ä¸ºâ€˜è‚¯å°¼äºšâ€™ï¼‰çš„æ¯ä¸ª Excel æ–‡ä»¶ä¸­çš„ä¸€ä¸ªè¡¨æ ¼ï¼Œé¦–å…ˆè¿è¡Œä¸Šè¿°åŸºäºè§„åˆ™çš„é¢„æµ‹ç”Ÿæˆæç¤ºå’Œå®Œæˆé¡¹ï¼Œç„¶åçº æ­£è¿”å›çš„é”™è¯¯å€¼ã€‚å†æ¬¡æ’é™¤æŒ‡å®šäº†å¤šä¸ªè¡¨æ ¼çš„ Excel è¡¨æ ¼ã€‚è¿™ç»™æˆ‘æä¾›äº† 72 ä¸ªæç¤ºçš„æµ‹è¯•é›†ã€‚

```py
 def make_gpt3_prediction(prompt, model, temperature=0.99, max_tokens=13):
    """
    Wrapper to call GPT-3 to make a prediction (completion) on a single prompt.
    Also calls post_process() to clean up the prediction.

    Parameters
    ----------
    prompt : str
        Prompt to use for prediction
    model : str
        GPT-3 model to use
    temperature : float
        Temperature to use for sampling
    max_tokens : int
        Maximum number of tokens to use for sampling

    Returns
    -------
    result : dict
        Dictionary with prompt, predicted, predicted_post_processed
    """
    result = {}
    result["prompt"] = prompt
    model_result = ai.Completion.create(
        engine=model,
        prompt=prompt,
        temperature=temperature,
        max_tokens=max_tokens,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=["\n"],
        logprobs=1,
    )
    result["predicted"] = model_result["choices"][0]["text"].replace(" ", "")
    result["logprobs"] = model_result["choices"][0]["logprobs"]["top_logprobs"]
    return result

def output_prediction_metrics(results, prediction_field="predicted_post_processed"):
    """
    Prints out model performance report if provided results in the format:

    [
        {
            'prompt': ' \'ISO3\' | "[\'RWA\', \'RWA\', \'RWA\', \'RWA\', \'RWA\', \'RWA\', \'RWA\', \'RWA\']"',
            'predicted': ' #country+code+iso3+v_iso3+',
            'expected': '#country+code'
        },
        ... etc ...
    ]

    Parameters
    ----------
    results : list
        See above for format
    prediction_field : str
        Field name of element with prediction. Handy for comparing raw and post-processed predictions.
    """
    y_test = []
    y_pred = []
    for r in results:
        if "expected" not in r:
            print("Provided results do not contain expected values.")
            sys.exit()
        y_pred.append(r[prediction_field])
        y_test.append(r["expected"])

    print(f"There were {len(y_test)} predictions made.")
    print(f"\nPrediction using field {prediction_field} ...\n")
    print(f"Accuracy: {round(accuracy_score(y_test, y_pred),2)}")
    print(
        f"Precision: {round(precision_score(y_test, y_pred, average='weighted', zero_division=0),2)}"
    )
    print(
        f"Recall: {round(recall_score(y_test, y_pred, average='weighted', zero_division=0),2)}"
    )
    print(
        f"F1: {round(f1_score(y_test, y_pred, average='weighted', zero_division=0),2)}"
    )

# File generated by downloading and processing HDX files. See this blog post
# for more details: https://medium.com/towards-data-science/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d
country='Kenya'
resources = pd.read_pickle(hdx_resources_pkl_file)

df = resources[(resources["resource_format"]=='XLSX')][["resource_format","file","sheet","dataset_name","dataset_org_title"]]
df.drop_duplicates(inplace=True)
orgs = df["dataset_org_title"].unique()

# Number of rows to use when calculating table row parameters
maxn = 15

# Determine test/train split, 0:10 used for training, 11:len(orgs) for test
dataset_orgs_cutoff = 10

for dataset_org in orgs[dataset_orgs_cutoff: len(orgs)]:
    rows = df.loc[df['dataset_org_title']== dataset_org]
    row = rows.iloc[0]  # Take one sheet from each org to get more variation
    filename = row["file"]
    sheetname = row["sheet"]

    wb = openpyxl.load_workbook(filename, data_only=True)
    for s in wb.sheetnames:
        sheet = wb[s]

        # Extract table attributes 
        report = get_sheet_attributes(sheet, maxn)

        report_elements = report.split('\n\n')
        prompt = report_elements[0] + report_elements[1]
        completion = report_elements[2]

        # Make our GPT-3 prediction
        res = make_gpt3_prediction(prompt, model, temperature=0.0)

        predicted = res["predicted"].split(':')[1].strip()
        actual = completion.split(':')[1].strip()

        results.append({
            "prompt": prompt,
            "predicted": predicted,
            "expected": actual
        })

output_prediction_metrics(results, prediction_field="predicted")
```

**é™„æ³¨ï¼š** åœ¨[æˆ‘ä¹‹å‰çš„åšå®¢æ–‡ç« ](https://medium.com/towards-data-science/predicting-metadata-for-humanitarian-datasets-using-gpt-3-b104be17716d)ä¸­é¢„æµ‹ HXL æ ‡ç­¾æ—¶ï¼Œæˆ‘å¿…é¡»é€šè¿‡å¯¹æ•°æ¦‚ç‡è¿‡æ»¤å®Œæˆé¡¹ï¼Œä½†åœ¨è¿™é¡¹ç ”ç©¶ä¸­æ²¡æœ‰å¿…è¦ã€‚

GPT-3 åœ¨æˆ‘ä»¬çš„æµ‹è¯•é›†ä¸­é¢„æµ‹äº†ç¬¬ä¸€è¡Œæ•°æ®çš„ç»“æœå¦‚ä¸‹â€¦â€¦

```py
Prediction using field predicted ...

Accuracy: 0.97
Precision: 1.0
Recall: 0.97
F1: 0.99
```

æ‰€ä»¥ GPT-3 åœ¨é¢„æµ‹ç¬¬ä¸€è¡Œæ•°æ®çš„ä½ç½®ä¸Šè¡¨ç°ä¸é”™ã€‚

# ç»¼åˆèµ·æ¥

**æ­¥éª¤ 1 â€” è¯»å–æˆ‘ä»¬çš„æ•°æ®**

![](img/9f631ffdb4c440854098cc64a07b849b.png)

ç¤ºä¾‹ç”µå­è¡¨æ ¼ï¼Œå…·æœ‰ä¸åŒçš„å±‚çº§æ ‡é¢˜å’Œå•å…ƒæ ¼ä¸­çš„å¤‡æ³¨

**æ­¥éª¤ 2 â€” å–æ¶ˆåˆå¹¶çš„åˆ—å¹¶å¡«å……åˆå¹¶å€¼**

![](img/e9623db509bee6348ad8d47e1441e67a.png)

Pandas æ•°æ®æ¡†åœ¨é€šè¿‡â€˜pad_merged_cellsâ€™å‡½æ•°å¤„ç†åï¼Œç”¨äºå–æ¶ˆåˆå¹¶å¹¶å¡«å……åˆå¹¶å€¼

**æ­¥éª¤ 3 â€” è®¡ç®—è¡¨æ ¼å‚æ•°ä»¥ç”Ÿæˆ GPT-3 æç¤º**

```py
Nulls in first 10 rows: [20, 20, 20, 21, 10, 8, 19, 9, 21, 0]
Numeric first 10 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 14]
Unique values in first 10 rows: [1, 1, 1, 0, 11, 13, 2, 4, 0, 21]
Year values in first 10 rows: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
HXL row: None

First reduced nulls row: 9
First increased numeric row (excluding years): 9
```

**æ­¥éª¤ 4 â€” è°ƒç”¨ GPT-3 é¢„æµ‹æ•°æ®è¡Œçš„èµ·å§‹ä½ç½®**

```py
GPT-3 prediction: 9
```

**æ­¥éª¤ 5 â€” ç°åœ¨æˆ‘ä»¬çŸ¥é“äº†æ•°æ®è¡Œçš„å¼€å§‹ä½ç½®ï¼Œå°†ä¸Šæ–¹çš„åˆ—æ ‡é¢˜è¿æ¥æˆä¸€è¡Œ**

![](img/457ae2d038f5792578767b18b888aef2.png)

è§£æåçš„è¡¨æ ¼ï¼Œå…·æœ‰æŠ˜å çš„å±‚çº§åˆ—ï¼Œæ²¡æœ‰éšæœºæ ‡ç­¾ã€‚ç°åœ¨å¯ä»¥å¯¼å…¥åˆ°æ•°æ®åº“ä¸­ã€‚

è¿™æ˜¯ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥ä¸Šä¼ åˆ°å…³ç³»æ•°æ®åº“çš„å¥½è¡¨æ ¼ã€‚æœ‰å…³å®Œæ•´ä»£ç ï¼Œè¯·å‚è§ä¸‹é¢çš„å‚è€ƒéƒ¨åˆ†ã€‚

è¯šç„¶ï¼Œæ‰‹åŠ¨è§£æè¿™ä¸ªè¡¨æ ¼å¹¶æŒ‡å®šä¸€äº›ä¸æˆ‘ä»¬å‘ç°çš„è¡¨æ ¼å‚æ•°ç›¸å…³çš„è§„åˆ™æ˜¯å¾ˆå®¹æ˜“çš„ï¼Œä½†ä¸Šè¿°è¿‡ç¨‹çš„é‡ç‚¹æ˜¯å®ƒå¯ä»¥åº”ç”¨äºäººé“ä¸»ä¹‰æ•°æ®äº¤æ¢æ•°æ®é›†ä¸­æˆåƒä¸Šä¸‡çš„ Excel è¡¨æ ¼çš„å¹¿æ³›è¡¨æ ¼å¸ƒå±€ã€‚

# ç»“è®ºä¸æœªæ¥å·¥ä½œ

å°½ç®¡é›¶æ¬¡å’Œä¸€æ¬¡æç¤ºå…·æœ‰å¾ˆå¤§çš„æ½œåŠ›ï¼Œä½†åœ¨ç”¨ CSV è¡¨æ ¼è¿›è¡Œæç¤ºæ—¶ï¼Œè¿™ç§æ–¹æ³•å°šæœªå¯¹è¿™ä¸ªç‰¹å®šä»»åŠ¡å¥æ•ˆã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›æ­¥ï¼Œè¿™ç§æƒ…å†µå¯èƒ½ä¼šæ”¹å˜â€”â€”æˆ‘å¾ˆæœŸå¾… GPT-4 çš„è¡¨ç°â€”â€”ä½†ç›®å‰çœ‹æ¥ï¼Œå¾®è°ƒæ˜¯æ›´å¥½çš„é€‰æ‹©ï¼Œå®ƒå¯ä»¥é¢„æµ‹å…³é”®çš„è¡¨æ ¼å±æ€§ï¼Œç”¨äºé‡æ–°æ ¼å¼åŒ–ã€‚å½“ç„¶ï¼Œè¿™ç§æ–¹æ³•éœ€è¦ä¸€äº›é¢„å¤„ç†ï¼Œä»¥ç¡®å®šæç¤ºçš„è¡¨æ ¼å‚æ•°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨è¡¨æ ¼â€˜ç‰¹å¾â€™æ—¶ï¼Œå®ƒæ›´åƒæ˜¯åˆ†ç±»ä»»åŠ¡è€Œä¸æ˜¯æ–‡æœ¬å®Œæˆï¼Œå¯èƒ½ä¼šæ›´é€‚åˆè¿™æ ·æ¡†æ¶ã€‚ä¸è¿‡ï¼Œæ— è®ºå¦‚ä½•ï¼Œè¿™ç§æŠ€æœ¯åœ¨ä½¿ç”¨äººé“ä¸»ä¹‰æ•°æ®äº¤æ¢ Excel æ–‡ä»¶æ—¶è¡¨ç°è‰¯å¥½ã€‚

æˆ‘è®¤ä¸ºå°†è¿™é¡¹å·¥ä½œæ‰©å±•åˆ°å¤„ç† Excel å·¥ä½œè¡¨ä¸Šæœ‰å¤šä¸ªè¡¨æ ¼çš„æƒ…å†µå°†éå¸¸æœ‰è¶£ã€‚è¿™éœ€è¦æ¯”æˆ‘åœ¨è¿™é¡¹ç ”ç©¶ä¸­ä½¿ç”¨çš„æ›´å¤šçš„è¡¨æ ¼ç‰¹å¾ï¼Œæ¯”å¦‚å•å…ƒæ ¼æ ¼å¼å’Œåˆ—ï¼ˆè€Œä¸æ˜¯è¡Œï¼‰å±æ€§ã€‚

æ›´å¤šæœ‰è¶£å†…å®¹æ•¬è¯·æœŸå¾…ï¼

# å‚è€ƒæ–‡çŒ®

[1] Haoyu Dong ç­‰äººï¼Œ[TableSense: ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œç”µå­è¡¨æ ¼è¡¨æ ¼æ£€æµ‹](https://arxiv.org/abs/2106.13500) (2021)

[2] Brown ç­‰äººï¼Œ[è¯­è¨€æ¨¡å‹æ˜¯å°‘æ ·æœ¬å­¦ä¹ è€…](https://arxiv.org/pdf/2005.14165.pdf) (2020)ã€‚

[3] [OpenAI Cookbook: æé«˜å¯é æ€§çš„æŠ€æœ¯](https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md)

[4] Kojima ç­‰äººï¼Œ[å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯é›¶æ ·æœ¬æ¨ç†è€…](https://arxiv.org/abs/2205.11916)

è¿™ä¸ªåˆ†æçš„ä»£ç å¯ä»¥åœ¨[è¿™ä¸ªç¬”è®°æœ¬](https://github.com/datakind/gpt-3-meta-data-discovery/blob/main/gpt-3-table-parsing.ipynb)ä¸­æ‰¾åˆ°ã€‚
