# æç¤ºå·¥ç¨‹ï¼šå¦‚ä½•è®© AI è§£å†³ä½ çš„é—®é¢˜

> åŸæ–‡ï¼š[`towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f`](https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f)

## 7 ä¸ªæç¤ºæŠ€å·§ã€LangChain å’Œ Python ç¤ºä¾‹ä»£ç 

[](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)![Shaw Talebi](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------) [Shaw Talebi](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)

Â·å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7ce1ed3b553f--------------------------------) Â·14 åˆ†é’Ÿé˜…è¯»Â·2023 å¹´ 8 æœˆ 25 æ—¥

--

è¿™æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹å®è·µç³»åˆ—ä¸­çš„ç¬¬å››ç¯‡æ–‡ç« ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å°†è®¨è®ºæç¤ºå·¥ç¨‹ï¼ˆPEï¼‰ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒæ¥æ„å»ºæ”¯æŒ LLM çš„åº”ç”¨ç¨‹åºã€‚æˆ‘é¦–å…ˆå›é¡¾å…³é”®çš„ PE æŠ€æœ¯ï¼Œç„¶åé€šè¿‡ Python ç¤ºä¾‹ä»£ç æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ LangChain æ„å»ºåŸºäº LLM çš„åº”ç”¨ç¨‹åºã€‚

![](img/51cee05215f7e6b279687f028ed20dcc.png)

å›¾ç‰‡ç”± [Jason Leung](https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral) æä¾›ï¼Œæ¥è‡ª [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

å½“é¦–æ¬¡å¬è¯´æç¤ºå·¥ç¨‹æ—¶ï¼Œè®¸å¤šæŠ€æœ¯äººå‘˜ï¼ˆåŒ…æ‹¬æˆ‘è‡ªå·±ï¼‰å¾€å¾€å¯¹è¿™ä¸ªæƒ³æ³•å—¤ä¹‹ä»¥é¼»ã€‚æˆ‘ä»¬å¯èƒ½ä¼šæƒ³ï¼Œâ€œ*æç¤ºå·¥ç¨‹ï¼Ÿå™—ï¼Œè¿™å¤ªæ— èŠäº†ã€‚å‘Šè¯‰æˆ‘æ€ä¹ˆä»å¤´å¼€å§‹æ„å»ºä¸€ä¸ª LLM å§ã€‚*â€

ç„¶è€Œï¼Œæ·±å…¥æ¢è®¨ä¹‹åï¼Œæˆ‘è¦æé†’å¼€å‘è€…ä¸è¦è‡ªåŠ¨å¿½è§†æç¤ºå·¥ç¨‹ã€‚æˆ‘ç”šè‡³å¯ä»¥è¯´ï¼Œ**æç¤ºå·¥ç¨‹å¯ä»¥å®ç°å¤§å¤šæ•° LLM ä½¿ç”¨æ¡ˆä¾‹çš„ 80%ä»·å€¼**ï¼Œä¸”ï¼ˆç›¸å¯¹ï¼‰èŠ±è´¹çš„ç²¾åŠ›éå¸¸å°‘ã€‚

æˆ‘å†™è¿™ç¯‡æ–‡ç« çš„ç›®æ ‡æ˜¯é€šè¿‡å¯¹æç¤ºå·¥ç¨‹çš„å®é™…å›é¡¾å’Œç¤ºä¾‹æ¥ä¼ è¾¾è¿™ä¸€è§‚ç‚¹ã€‚è™½ç„¶æç¤ºå·¥ç¨‹çš„åŠŸèƒ½ç¡®å®æœ‰ä¸€äº›ä¸è¶³ï¼Œä½†å®ƒä¸ºå‘ç°ç®€å•è€Œèªæ˜çš„è§£å†³æ–¹æ¡ˆæ‰“å¼€äº†å¤§é—¨ã€‚

é™„åŠ è§†é¢‘ã€‚

# **ä»€ä¹ˆæ˜¯æç¤ºå·¥ç¨‹ï¼Ÿ**

åœ¨æœ¬ç³»åˆ—çš„ç¬¬ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†**æç¤ºå·¥ç¨‹**å®šä¹‰ä¸º**ä»»ä½•å¼€ç®±å³ç”¨çš„ LLM çš„ä½¿ç”¨**ï¼ˆå³ä¸è®­ç»ƒä»»ä½•å†…éƒ¨æ¨¡å‹å‚æ•°ï¼‰ã€‚ç„¶è€Œï¼Œè¿˜æœ‰æ›´å¤šå¯ä»¥è¯´çš„ã€‚

1.  æç¤ºå·¥ç¨‹æ˜¯â€œ*é€šè¿‡æç¤ºç¼–ç¨‹ LLM çš„æ–¹æ³•ã€‚*â€ [[1](https://arxiv.org/abs/2302.11382)]

1.  æç¤ºå·¥ç¨‹æ˜¯â€œ*ä¸€ç§å°†æç¤ºè¿›è¡Œæ„å»ºå’Œæ ¼å¼åŒ–çš„ç»éªŒæ€§è‰ºæœ¯ï¼Œä»¥æœ€å¤§åŒ–æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°*ã€‚â€ [[2](https://arxiv.org/abs/2106.09685)]

1.  *â€œè¯­è¨€æ¨¡å‹â€¦å¸Œæœ›å®Œæˆæ–‡æ¡£ï¼Œå› æ­¤ä½ å¯ä»¥é€šè¿‡å®‰æ’è™šå‡çš„æ–‡æ¡£æ¥æ¬ºéª—å®ƒä»¬æ‰§è¡Œä»»åŠ¡*ã€‚â€ [[3](https://www.youtube.com/watch?v=bZQun8Y4L2A)]

ç¬¬ä¸€ä¸ªå®šä¹‰ä¼ è¾¾äº†æ¥è‡ª LLM çš„å…³é”®åˆ›æ–°ï¼Œå³**è®¡ç®—æœºç°åœ¨å¯ä»¥ä½¿ç”¨ç®€å•çš„è‹±è¯­è¿›è¡Œç¼–ç¨‹**ã€‚ç¬¬äºŒç‚¹å°†æç¤ºå·¥ç¨‹æ¡†æ¶åŒ–ä¸ºä¸€ç§ä¸»è¦ç»éªŒæ€§çš„å·¥ä½œï¼Œå…¶ä¸­ä»ä¸šè€…ã€ä¿®è¡¥è€…å’Œæ„å»ºè€…æ˜¯è¿™ä¸€æ–°ç¼–ç¨‹æ–¹å¼çš„ä¸»è¦æ¢ç´¢è€…ã€‚

ç¬¬ä¸‰ç‚¹ï¼ˆæ¥è‡ª [Andrej Karpathy](https://medium.com/u/ac9d9a35533e?source=post_page-----7ce1ed3b553f--------------------------------)ï¼‰æé†’æˆ‘ä»¬**LLM å¹¶æœªæ˜ç¡®è®­ç»ƒæ¥åšå‡ ä¹æˆ‘ä»¬è¦æ±‚çš„ä»»ä½•äº‹æƒ…**ã€‚å› æ­¤ï¼Œä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œæˆ‘ä»¬æ˜¯åœ¨â€œæ¬ºéª—â€è¿™äº›è¯­è¨€æ¨¡å‹ä»¥è§£å†³é—®é¢˜ã€‚æˆ‘è§‰å¾—è¿™æ•æ‰åˆ°äº†æç¤ºå·¥ç¨‹çš„æœ¬è´¨ï¼Œå®ƒä¾èµ–äºä½ çš„åˆ›é€ åŠ›è€ŒéæŠ€æœ¯æŠ€èƒ½ã€‚

# **æç¤ºå·¥ç¨‹çš„ä¸¤ä¸ªå±‚æ¬¡**

å¯ä»¥é€šè¿‡ä¸¤ç§ä¸åŒçš„æ–¹å¼è¿›è¡Œæç¤ºå·¥ç¨‹ï¼Œæˆ‘åœ¨æœ¬ç³»åˆ—çš„ ç¬¬ä¸€ç¯‡æ–‡ç«  ä¸­å°†å…¶ç§°ä¸ºâ€œ**ç®€å•æ–¹æ³•**â€å’Œâ€œ**è¾ƒéš¾çš„æ–¹æ³•**â€ã€‚

## ç®€å•çš„æ–¹æ³•

è¿™æ˜¯å¤§å¤šæ•°ä¸–ç•Œä¸Šäººä»¬è¿›è¡Œæç¤ºå·¥ç¨‹çš„æ–¹å¼ï¼Œå³é€šè¿‡ ChatGPTï¼ˆæˆ–ç±»ä¼¼çš„å·¥å…·ï¼‰ã€‚è¿™æ˜¯ä¸€ç§ç›´è§‚çš„ã€æ— éœ€ç¼–ç ä¸”æ— éœ€è´¹ç”¨çš„ä¸ LLM äº’åŠ¨çš„æ–¹å¼ã€‚

è™½ç„¶è¿™ç§æ–¹æ³•é€‚åˆå¿«é€Ÿå’Œç®€å•çš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ€»ç»“ä¸€é¡µæ–‡æœ¬ã€é‡å†™ä¸€å°é‚®ä»¶ã€å¸®åŠ©ä½ å¤´è„‘é£æš´ç”Ÿæ—¥æ´¾å¯¹è®¡åˆ’ç­‰ï¼Œä½†å®ƒä¹Ÿæœ‰å…¶ç¼ºç‚¹ã€‚ä¸€ä¸ªä¸»è¦é—®é¢˜æ˜¯**å°†è¿™ç§æ–¹æ³•æ•´åˆåˆ°æ›´å¤§çš„è‡ªåŠ¨åŒ–æµç¨‹æˆ–è½¯ä»¶ç³»ç»Ÿä¸­å¹¶ä¸å®¹æ˜“**ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦æ›´è¿›ä¸€æ­¥ã€‚

## è¾ƒéš¾çš„æ–¹æ³•

è¿™é€šè¿‡ä»¥ç¼–ç¨‹æ–¹å¼ä¸ LLM äº’åŠ¨æ¥è§£å†³äº†â€œç®€å•æ–¹æ³•â€çš„è®¸å¤šç¼ºç‚¹ï¼Œå³ä½¿ç”¨ Pythonã€‚æˆ‘ä»¬åœ¨æœ¬ç³»åˆ—çš„å‰ä¸¤ç¯‡æ–‡ç« ä¸­äº†è§£äº†å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ï¼Œå…¶ä¸­æ¢ç´¢äº† OpenAI çš„ Python API å’Œ Hugging Face Transformers åº“ã€‚

è™½ç„¶è¿™éœ€è¦æ›´å¤šçš„æŠ€æœ¯çŸ¥è¯†ï¼Œ**ä½†è¿™æ­£æ˜¯æç¤ºå·¥ç¨‹çš„çœŸæ­£åŠ›é‡æ‰€åœ¨**ï¼Œå› ä¸ºå®ƒå…è®¸å¼€å‘äººå‘˜å°†åŸºäº LLM çš„æ¨¡å—é›†æˆåˆ°æ›´å¤§çš„è½¯ä»¶ç³»ç»Ÿä¸­ã€‚

ä¸€ä¸ªå¥½çš„ï¼ˆä¹Ÿè®¸æ˜¯å…·æœ‰è®½åˆºæ„å‘³çš„ï¼‰ä¾‹å­æ˜¯ ChatGPTã€‚è¿™ä¸ªäº§å“çš„æ ¸å¿ƒæ˜¯æç¤ºä¸€ä¸ªé¢„è®­ç»ƒçš„æ¨¡å‹ï¼ˆå³ GPT-3.5-turboï¼‰å……å½“èŠå¤©æœºå™¨äººï¼Œç„¶åå°†å…¶å°è£…åœ¨ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„ç½‘é¡µç•Œé¢ä¸­ã€‚

å½“ç„¶ï¼Œå¼€å‘ GPT-3.5-turbo æ˜¯å›°éš¾çš„ï¼Œ**ä½†è¿™ä¸æ˜¯æˆ‘ä»¬éœ€è¦æ‹…å¿ƒçš„äº‹æƒ…**ã€‚å€ŸåŠ©æˆ‘ä»¬æ‰‹å¤´çš„æ‰€æœ‰é¢„è®­ç»ƒ LLMï¼Œå‡ ä¹ä»»ä½•å…·å¤‡åŸºæœ¬ç¼–ç¨‹æŠ€èƒ½çš„äººéƒ½å¯ä»¥åˆ›å»ºä¸€ä¸ªåƒ ChatGPT è¿™æ ·çš„å¼ºå¤§ AI åº”ç”¨ç¨‹åºï¼Œè€Œä¸å¿…æ˜¯ AI ç ”ç©¶å‘˜æˆ–æœºå™¨å­¦ä¹ åšå£«ã€‚

# **åˆ©ç”¨æç¤ºå·¥ç¨‹æ„å»º AI åº”ç”¨**

æ›´å›°éš¾çš„æ–¹æ³•è§£é”äº†**ç¼–ç¨‹å’Œè½¯ä»¶å¼€å‘çš„æ–°èŒƒå¼**ã€‚å¼€å‘è€…ä¸å†éœ€è¦åœ¨è½¯ä»¶ç³»ç»Ÿä¸­å®šä¹‰æ¯ä¸€å¯¸é€»è¾‘ã€‚ä»–ä»¬ç°åœ¨å¯ä»¥é€‰æ‹©å°†éçç¢çš„éƒ¨åˆ†è½¬ç§»ç»™ LLMã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œè¿™å¯èƒ½æ˜¯ä»€ä¹ˆæ ·çš„ã€‚

å‡è®¾ä½ æƒ³ä¸ºé«˜ä¸­å†å²è¯¾åˆ›å»ºä¸€ä¸ª**è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿ**ã€‚é—®é¢˜åœ¨äºæ‰€æœ‰é—®é¢˜éƒ½æœ‰ä¹¦é¢å›ç­”ï¼Œå› æ­¤é€šå¸¸ä¼šæœ‰å¤šä¸ªæ­£ç¡®ç­”æ¡ˆçš„ç‰ˆæœ¬ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹å¯¹â€œ*è°æ˜¯ç¾å›½çš„ç¬¬ 35 ä»»æ€»ç»Ÿï¼Ÿ*â€çš„å›ç­”å¯èƒ½éƒ½æ˜¯æ­£ç¡®çš„ã€‚

+   çº¦ç¿°Â·FÂ·è‚¯å°¼è¿ª

+   JFK

+   æ°å…‹Â·è‚¯å°¼è¿ªï¼ˆä¸€ä¸ªå¸¸è§çš„æ˜µç§°ï¼‰

+   çº¦ç¿°Â·FÂ·è‚¯å°¼è¿ªï¼ˆå¯èƒ½è¯•å›¾è·å¾—é¢å¤–çš„å­¦åˆ†ï¼‰

+   çº¦ç¿°Â·FÂ·è‚¯å°¼è¿ªï¼ˆæ‹¼å†™é”™è¯¯çš„å§“æ°ï¼‰

åœ¨**ä¼ ç»Ÿç¼–ç¨‹èŒƒå¼**ä¸­ï¼Œå¼€å‘è€…éœ€è¦æ‰¾å‡ºå¦‚ä½•å¤„ç†æ‰€æœ‰è¿™äº›å˜ä½“ã€‚ä¸ºæ­¤ï¼Œä»–ä»¬å¯èƒ½ä¼šåˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„æ­£ç¡®ç­”æ¡ˆï¼Œå¹¶ä½¿ç”¨ç²¾ç¡®çš„å­—ç¬¦ä¸²åŒ¹é…ç®—æ³•ï¼Œç”šè‡³å¯èƒ½ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ¥å¸®åŠ©å¤„ç†æ‹¼å†™é”™è¯¯çš„å•è¯ã€‚

ç„¶è€Œï¼Œå€ŸåŠ©è¿™ç§æ–°çš„**LLM å¯ç”¨çš„èŒƒå¼**ï¼Œ**é—®é¢˜å¯ä»¥é€šè¿‡ç®€å•çš„æç¤ºå·¥ç¨‹æ¥è§£å†³**ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æç¤ºæ¥è¯„ä¼°å­¦ç”Ÿçš„ç­”æ¡ˆã€‚

```py
You are a high school history teacher grading homework assignments. \
Based on the homework question indicated by â€œQ:â€ and the correct answer \
indicated by â€œA:â€, your task is to determine whether the student's answer is \
correct.
Grading is binary; therefore, student answers can be correct or wrong.
Simple misspellings are okay.

Q: {question}
A: {correct_answer}

Student Answer: {student_answer}
```

æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªæç¤ºè§†ä¸ºä¸€ä¸ªå‡½æ•°ï¼Œç»™å®šä¸€ä¸ª***é—®é¢˜***ã€***æ­£ç¡®ç­”æ¡ˆ***å’Œ***å­¦ç”Ÿç­”æ¡ˆ***ï¼Œå®ƒç”Ÿæˆå­¦ç”Ÿçš„è¯„åˆ†ã€‚ç„¶åï¼Œè¿™å¯ä»¥é›†æˆåˆ°ä¸€ä¸ªæ›´å¤§çš„å®ç°è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿçš„è½¯ä»¶ä¸­ã€‚

ä»èŠ‚çœæ—¶é—´çš„è§’åº¦æ¥çœ‹ï¼Œè¿™ä¸ªæç¤ºæˆ‘èŠ±äº†å¤§çº¦ 2 åˆ†é’Ÿæ¥ç¼–å†™ï¼Œè€Œå¦‚æœæˆ‘å°è¯•å¼€å‘ä¸€ä¸ªç®—æ³•æ¥åšåŒæ ·çš„äº‹æƒ…ï¼Œå®ƒå¯èƒ½éœ€è¦å‡ ä¸ªå°æ—¶ï¼ˆç”šè‡³å‡ å¤©ï¼‰ï¼Œè€Œä¸”æ€§èƒ½å¯èƒ½æ›´å·®ã€‚**å› æ­¤ï¼Œè¿™ç±»ä»»åŠ¡çš„æ—¶é—´èŠ‚çœæ˜¯ 100â€“1000 å€**ã€‚

å½“ç„¶ï¼Œæœ‰è®¸å¤šä»»åŠ¡ä¸­ LLM å¹¶æ²¡æœ‰æä¾›å®è´¨æ€§çš„å¥½å¤„ï¼Œå…¶ä»–ç°æœ‰æ–¹æ³•æ›´é€‚åˆï¼ˆä¾‹å¦‚é¢„æµ‹æ˜å¤©çš„å¤©æ°”ï¼‰ã€‚LLM ç»ä¸æ˜¯è§£å†³æ‰€æœ‰é—®é¢˜çš„æ–¹æ¡ˆï¼Œä½†å®ƒä»¬ç¡®å®åˆ›é€ äº†ä¸€å¥—æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œç”¨äºå¤„ç†éœ€è¦æœ‰æ•ˆå¤„ç†è‡ªç„¶è¯­è¨€çš„ä»»åŠ¡â€”â€”è¿™æ˜¯è®¡ç®—æœºå†å²ä¸Šä¸€ç›´å›°éš¾çš„ä»»åŠ¡ã€‚

# **æç¤ºå·¥ç¨‹çš„ 7 ä¸ªæŠ€å·§**

è™½ç„¶ä¹‹å‰çš„æç¤ºç¤ºä¾‹çœ‹èµ·æ¥åƒæ˜¯ä¸€ç§è‡ªç„¶ä¸”æ˜æ˜¾çš„è‡ªåŠ¨è¯„åˆ†ä»»åŠ¡æ¡†æ¶ï¼Œä½†å®ƒåˆ»æ„ä½¿ç”¨äº†ç‰¹å®šçš„æç¤ºå·¥ç¨‹å¯å‘å¼æ–¹æ³•ï¼ˆæˆ–è€…è¯´â€œæŠ€å·§â€ï¼Œå¦‚æˆ‘æ‰€ç§°ï¼‰ã€‚è¿™äº›ï¼ˆä»¥åŠå…¶ä»–ï¼‰æŠ€å·§å·²æˆä¸ºæé«˜ LLM å“åº”è´¨é‡çš„å¯é æ–¹æ³•ã€‚

å°½ç®¡æœ‰è®¸å¤šæ’°å†™è‰¯å¥½æç¤ºçš„æŠ€å·§å’Œçªé—¨ï¼Œä½†åœ¨è¿™é‡Œæˆ‘å°†è®¨è®ºé‚£äº›åŸºäºå°‘æ•°å‚è€ƒèµ„æ–™ï¼ˆIMOï¼‰çœ‹èµ·æ¥æœ€åŸºæœ¬çš„æŠ€å·§ã€‚å¯¹äºæ›´æ·±å…¥çš„äº†è§£ï¼Œæˆ‘å»ºè®®è¯»è€…æ¢ç´¢æ­¤å¤„å¼•ç”¨çš„æ¥æºã€‚

## **æŠ€å·§ 1ï¼šæè¿°æ€§å¼ºï¼ˆå¤šå¤šç›Šå–„ï¼‰**

LLMs çš„ä¸€ä¸ªå†³å®šæ€§ç‰¹å¾æ˜¯å®ƒä»¬åœ¨å¤§é‡æ–‡æœ¬è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒã€‚è¿™ä½¿å®ƒä»¬å…·å¤‡äº†å¹¿æ³›çš„ä¸–ç•ŒçŸ¥è¯†å’Œæ‰§è¡Œå„ç§ä»»åŠ¡çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ç§ä»¤äººå°è±¡æ·±åˆ»çš„æ™®éæ€§å¯èƒ½ä¼šåœ¨æ²¡æœ‰æä¾›é€‚å½“ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ï¼Œå½±å“ç‰¹å®šä»»åŠ¡çš„è¡¨ç°ã€‚

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬æ¯”è¾ƒä¸¤ä¸ªç”Ÿæˆæˆ‘çˆ¸çˆ¸ç”Ÿæ—¥ç¥ç¦çš„æç¤ºã€‚

***ä¸ä½¿ç”¨æŠ€å·§***

```py
Write me a birthday message for my dad.
```

***ä½¿ç”¨æŠ€å·§***

```py
Write me a birthday message for my dad no longer than 200 \
characters. This is a big birthday because he is turning 50\. To celebrate, \
I booked us a boys' trip to Cancun. Be sure to include some cheeky humor, he \
loves that.
```

## **æŠ€å·§ 2ï¼šæä¾›ç¤ºä¾‹**

ä¸‹ä¸€ä¸ªæŠ€å·§æ˜¯ç»™ LLM ç¤ºä¾‹å“åº”ï¼Œä»¥æé«˜å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚è¿™ä¸ªæŠ€æœ¯æœ¯è¯­æ˜¯**å°‘é‡å­¦ä¹ **ï¼Œå·²è¢«è¯æ˜èƒ½æ˜¾è‘—æé«˜ LLM çš„è¡¨ç° [6]ã€‚

è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ã€‚å‡è®¾æˆ‘ä»¬æƒ³ä¸º Towards Data Science æ–‡ç« å†™ä¸€ä¸ªå‰¯æ ‡é¢˜ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç°æœ‰çš„ç¤ºä¾‹æ¥æŒ‡å¯¼ LLM å®Œæˆã€‚

***ä¸ä½¿ç”¨æŠ€å·§***

```py
Given the title of a Towards Data Science blog article, write a subtitle for it.

Title: Prompt Engineeringâ€”How to trick AI into solving your problems
Subtitle:
```

***ä½¿ç”¨æŠ€å·§***

```py
Given the title of a Towards Data Science blog article, write a subtitle for it.

Title: A Practical Introduction to LLMs
Subtitle: 3 levels of using LLMs in practice

Title: Cracking Open the OpenAI (Python) API
Subtitle: A complete beginner-friendly introduction with example code

Title: Prompt Engineering-How to trick AI into solving your problems
Subtitle:
```

## **æŠ€å·§ 3ï¼šä½¿ç”¨ç»“æ„åŒ–æ–‡æœ¬**

ç¡®ä¿æç¤ºéµå¾ªæœ‰ç»„ç»‡çš„ç»“æ„ï¼Œä¸ä»…ä½¿å…¶æ›´æ˜“è¯»å’Œç¼–å†™ï¼Œè¿˜å¾€å¾€æœ‰åŠ©äºæ¨¡å‹ç”Ÿæˆè‰¯å¥½çš„å®Œæˆã€‚æˆ‘ä»¬åœ¨**æŠ€å·§ 2**çš„ç¤ºä¾‹ä¸­åº”ç”¨äº†è¿™ä¸€æŠ€æœ¯ï¼Œå…¶ä¸­æˆ‘ä»¬æ˜ç¡®æ ‡è®°äº†æ¯ä¸ªç¤ºä¾‹çš„*æ ‡é¢˜*å’Œ*å‰¯æ ‡é¢˜*ã€‚

ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥ä»¥æ— æ•°ç§æ–¹å¼ä¸ºæç¤ºæä¾›ç»“æ„ã€‚è¿™é‡Œæœ‰ä¸€äº›ä¾‹å­ï¼šä½¿ç”¨å…¨å¤§å†™æ¥å¼ºè°ƒï¼Œä½¿ç”¨åˆ†éš”ç¬¦å¦‚ ```py to highlight a body of text, use markup languages like Markdown or HTML to format text, use JSON to organize information, etc.

Now, letâ€™s see this in action.

***Without Trick***

```

ç»™æˆ‘ä¸€ä¸ªå·§å…‹åŠ›æ›²å¥‡é¥¼å¹²çš„é£Ÿè°±ã€‚

```py

***With Trick***

```

åˆ›å»ºä¸€ä¸ªç»„ç»‡è‰¯å¥½çš„å·§å…‹åŠ›æ›²å¥‡é¥¼å¹²é£Ÿè°±ã€‚ä½¿ç”¨ä»¥ä¸‹\

æ ¼å¼å…ƒç´ ï¼š

**æ ‡é¢˜**ï¼šç»å…¸å·§å…‹åŠ›æ›²å¥‡é¥¼å¹²

**ææ–™**ï¼šåˆ—å‡ºé…æ–™åŠå…¶å‡†ç¡®çš„æµ‹é‡å’Œæ ¼å¼ã€‚

**æ­¥éª¤**ï¼šä»¥ç¼–å·æ ¼å¼æä¾›é€æ­¥è¯´æ˜ï¼Œè¯¦ç»†è¯´æ˜çƒ˜ç„™è¿‡ç¨‹ã€‚

**æç¤º**ï¼šåŒ…æ‹¬ä¸€ä¸ªå•ç‹¬çš„éƒ¨åˆ†ï¼Œæä¾›æœ‰ç”¨çš„çƒ˜ç„™æç¤ºå’Œå¯èƒ½çš„å˜åŒ–ã€‚

```py

## **Trick 4: Chain of Thought**

This trick was proposed by Wei et al. [7]. The basic idea is to guide an LLM to think â€œstep by stepâ€. This helps break down complex problems into manageable sub-problems, which gives the LLM â€œtime to thinkâ€ [3,5]. Zhang et al. showed that this could be as simple as including the text â€œ*Letâ€™s think step by step*â€ in the prompt [8].

This notion can be extended to any recipe-like process. For example, if I want to create a LinkedIn post based on my latest Medium blog, I can guide the LLM to mirror the step-by-step process I follow.

***Without Trick***

```

æ ¹æ®ä»¥ä¸‹ Medium åšå®¢å†™ä¸€ç¯‡ LinkedIn å¸–å­ã€‚

Medium åšå®¢ï¼š{Medium åšå®¢æ–‡æœ¬}

```py

***With Trick***

```

æ ¹æ®é€æ­¥è¿‡ç¨‹å’Œ Medium åšå®¢å†™ä¸€ç¯‡ LinkedIn å¸–å­\

å¦‚ä¸‹æ‰€ç¤ºã€‚

ç¬¬ 1 æ­¥ï¼šæƒ³å‡ºä¸€ä¸ªä¸åšå®¢ç›¸å…³çš„ä¸€å¥è¯å¼•å­ã€‚

ç¬¬ 2 æ­¥ï¼šä»æ–‡ç« ä¸­æå– 3 ä¸ªå…³é”®ç‚¹

ç¬¬ 3 æ­¥ï¼šå°†æ¯ä¸ªè¦ç‚¹å‹ç¼©åˆ° 50 ä¸ªå­—ç¬¦ä»¥å†…ã€‚

ç¬¬ 4 æ­¥ï¼šå°†å¼•å­ã€ç¬¬ 3 æ­¥ä¸­çš„å‹ç¼©è¦ç‚¹å’Œè¡ŒåŠ¨å·å¬ç»“åˆèµ·æ¥\

ä»¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚

Medium åšå®¢ï¼š{Medium åšå®¢æ–‡æœ¬}

```py

## **Trick 5: Chatbot Personas**

A somewhat surprising technique that tends to improve LLM performance is to prompt it to take on a particular persona e.g. â€œ*you are an expert*â€. This is helpful because you may not know the best way to describe your problem to the LLM, but you may know who would help you solve that problem [[1](https://arxiv.org/abs/2302.11382)]. Hereâ€™s what this might look like in practice.

***Without Trick***

```

ç»™æˆ‘åˆ¶å®šä¸€ä¸ªåœ¨çº½çº¦å¸‚åº¦è¿‡å‘¨æœ«çš„æ—…è¡Œè®¡åˆ’ã€‚

```py

***With Trick***

```

å……å½“ä¸€ä½äº†è§£çº½çº¦å¸‚çš„ä¸€åˆ‡çš„çº½çº¦æœ¬åœ°äººå’Œå‡ºç§Ÿè½¦å¸æœºã€‚\

è¯·æ ¹æ®\

ä½ çš„ç»å†ã€‚ä¸è¦å¿˜è®°åœ¨ä½ çš„\

å“åº”ã€‚

```py

## **Trick 6: Flipped Approach**

It can be difficult to optimally prompt an LLM when **we do not know what it knows or how it thinks**. That is where the â€œflipped approachâ€ can be helpful. This is where you prompt the LLM to ask you questions until it has a sufficient understanding (i.e. context) of the problem you are trying to solve.

***Without Trick***

```

ä¸€ä¸ªåŸºäº LLM çš„åº”ç”¨ç¨‹åºçš„æƒ³æ³•æ˜¯ä»€ä¹ˆï¼Ÿ

```py

***With Trick***

```

æˆ‘å¸Œæœ›ä½ é—®æˆ‘é—®é¢˜ï¼Œä»¥å¸®åŠ©æˆ‘æå‡ºåŸºäº LLM çš„

åº”ç”¨ç¨‹åºæƒ³æ³•ã€‚ä¸€æ¬¡é—®æˆ‘ä¸€ä¸ªé—®é¢˜ï¼Œä»¥ä¿æŒå¯¹è¯æ€§ã€‚

```py

## **Trick 7: Reflect, Review, and Refine**

This final trick prompts the model to reflect on its past responses to improve them. Common use cases are having the model critically evaluate its own work by asking it if it â€œ*completed the assignment*â€ or having it â€œ*explain the reasoning and assumptions*â€ behind a response [1, 3].

Additionally, you can ask the LLM to refine not only its responses but **your prompts**. This is a simple way to automatically rewrite prompts so that they are easier for the model to â€œunderstandâ€.

***With Trick***

```

å¤æŸ¥ä½ ä¹‹å‰çš„å“åº”ï¼Œæ‰¾å‡ºæ”¹è¿›çš„åœ°æ–¹ï¼Œå¹¶æä¾›

æ”¹è¿›ç‰ˆã€‚ç„¶åè§£é‡Šä½ å¦‚ä½•æ”¹è¿›å“åº”çš„ç†ç”±ã€‚

```py

# **Example Code: Automatic Grader with LangChain**

Now that weâ€™ve reviewed several prompting heuristics letâ€™s see how we can apply them to a specific use case. To do this, we will return to the automatic grader example from before.

```

ä½ æ˜¯ä¸€åé«˜ä¸­å†å²è€å¸ˆï¼Œè´Ÿè´£è¯„åˆ†ä½œä¸šã€‚

åŸºäºç”± "Q:" æŒ‡ç¤ºçš„ä½œä¸šé—®é¢˜å’Œæ­£ç¡®ç­”æ¡ˆ

ç”± "A:" æŒ‡ç¤ºï¼Œä½ çš„ä»»åŠ¡æ˜¯ç¡®å®šå­¦ç”Ÿçš„ç­”æ¡ˆæ˜¯å¦

æ­£ç¡®ã€‚

è¯„åˆ†æ˜¯äºŒå…ƒçš„ï¼Œå› æ­¤ï¼Œå­¦ç”Ÿçš„å›ç­”å¯ä»¥æ˜¯æ­£ç¡®çš„æˆ–é”™è¯¯çš„ã€‚

ç®€å•çš„æ‹¼å†™é”™è¯¯æ˜¯å¯ä»¥çš„ã€‚

Q: {question}

A: {correct_answer}

å­¦ç”Ÿç­”æ¡ˆ: {student_answer}

```py

On second look, a few of the previously mentioned tricks should be apparent i.e. **Trick 6**: chatbot persona, **Trick 3**: use structured text, and **Trick 1**: be descriptive. This is what good prompting typically looks like in practice, namely combining multiple techniques in a single prompt.

While we could copy-paste this prompt template into ChatGPT and replace the *question*, *correct_answer*, and *student_answer* fields, **this is not a scalable way to implement the automatic grader**. Rather, what we want is to integrate this prompt into a larger software system so that we can build a user-friendly application that a human can use.

## LangChain

One way we can do this is via **LangChain**, which is **a Python library that helps simplify building applications on top of large language models**. It does this by providing a variety of handy abstractions for using LLMs programmatically.

The central class that does this is called **chain** (hence the library name). This abstracts the process of generating a prompt, sending it to an LLM, and parsing the output so that it can be easily called and integrated into a larger script.

Letâ€™s see how to use LangChain for our automatic grader use case. The example code is available on the [GitHub Repo](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example) for this article.

## Imports

We first start by importing the necessary library modules.

```

ä» langchain.chat_models å¯¼å…¥ ChatOpenAI

ä» langchain.prompts å¯¼å…¥ PromptTemplate

ä» langchain.chains å¯¼å…¥ LLMChain

ä» langchain.schema å¯¼å…¥ BaseOutputParser

```py

Here we will use gpt-3.5-turbo which requires a secret key for OpenAIâ€™s API. If you donâ€™t have one, I gave a step-by-step guide on how to get one in a past article of this series. I like to store the secret key in a separate Python file (*sk.py*) and import it with the following line of code.

```

ä» sk å¯¼å…¥ my_sk #ä»å¦ä¸€ä¸ª Python æ–‡ä»¶å¯¼å…¥å¯†é’¥

```py

## Our 1st chain

To define our chain, we need two core elements: the **LLM** and the **prompt**. We start by creating an object for the LLM.

```

# å®šä¹‰ LLM å¯¹è±¡

chat_model = ChatOpenAI(openai_api_key=my_sk, temperature=0)

```py

LangChain has a class specifically for OpenAI (and many other) chat models. I pass in my secret API key and set the temperature to 0\. The default model here is *gpt-3.5-turbo*, but you can alternatively use *gpt-4* using the â€œmodel_nameâ€ input argument. You can further customize the chat model by setting other [input arguments](https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html#langchain.chat_models.openai.ChatOpenAI).

Next, we define our **prompt template**. This object allows us to generate prompts dynamically via input strings that automatically update a base template. Hereâ€™s what that looks like.

```

# å®šä¹‰æç¤ºæ¨¡æ¿

prompt_template_text = """ä½ æ˜¯ä¸€åé«˜ä¸­å†å²è€å¸ˆï¼Œè´Ÿè´£è¯„åˆ†

ä½œä¸šã€‚åŸºäºç”± â€œ**Q:**â€ æŒ‡ç¤ºçš„ä½œä¸šé—®é¢˜

ä»¥åŠç”± â€œ**A:**â€ æŒ‡ç¤ºçš„æ­£ç¡®ç­”æ¡ˆï¼Œä½ çš„ä»»åŠ¡æ˜¯ç¡®å®š

ç¡®å®šå­¦ç”Ÿçš„ç­”æ¡ˆæ˜¯å¦æ­£ç¡®ã€‚è¯„åˆ†æ˜¯äºŒå…ƒçš„ï¼Œå› æ­¤ï¼Œ

å­¦ç”Ÿçš„å›ç­”å¯ä»¥æ˜¯æ­£ç¡®çš„æˆ–é”™è¯¯çš„ã€‚ç®€å•çš„æ‹¼å†™é”™è¯¯æ˜¯å¯ä»¥çš„ã€‚

**Q:** {question}

**A:** {correct_answer}

**å­¦ç”Ÿçš„ç­”æ¡ˆ:** {student_answer}

"""

prompt = PromptTemplate(

            input_variables=["question", "correct_answer", "student_answer"], 

            template = prompt_template_text)

```py

With our LLM and prompt, we can now define our chain.

```

# å®šä¹‰é“¾

chain = LLMChain(llm=chat_model, prompt=prompt)

```py

Next, we can pass inputs to the chain and obtain a grade in one line of code.

```

# å®šä¹‰è¾“å…¥

é—®é¢˜ = "è°æ˜¯ç¾å›½ç¬¬ 35 ä»»æ€»ç»Ÿï¼Ÿ"

æ­£ç¡®ç­”æ¡ˆ = "John F. Kennedy"

student_answer = "FDR"

# è¿è¡Œé“¾

chain.run({'question':question, 'correct_answer':correct_answer,

    'student_answer':student_answer})

# è¾“å‡º: å­¦ç”Ÿçš„ç­”æ¡ˆæ˜¯é”™è¯¯çš„ã€‚

```py

While this chain can perform the grading task effectively, its outputs may not be suitable for an automated process. For instance, in the above code block, the LLM correctly said the studentâ€™s answer of â€œFDRâ€ was wrong, but it would be better if the LLM gave us an output in a standard format that could be used in downstream processing.

## Output parser

This is where **output parsers** come in handy. These are functions we can integrate into a chain to convert LLM outputs to a standard format. Letâ€™s see how we can make an output parser that converts the LLM response to a boolean (i.e. *True* or *False*) output.

```

# å®šä¹‰è¾“å‡ºè§£æå™¨

class GradeOutputParser(BaseOutputParser):

    """ç¡®å®šè¯„åˆ†æ˜¯å¦æ­£ç¡®æˆ–é”™è¯¯"""

    def parse(self, text: str):

        """è§£æ LLM è°ƒç”¨çš„è¾“å‡ºã€‚"""

        è¿”å› "wrong" ä¸åœ¨ text.lower() ä¸­

```py

Here, we create a simple output parser that checks if the word â€œwrongâ€ is in the LLMâ€™s output. If not, we return *True*, indicating the student's correct answer. Otherwise, we return *False*, indicating the student's answer was incorrect.

We can then incorporate this output parser into our chain to seamlessly parse text when we run the chain.

```

# æ›´æ–°é“¾

chain = LLMChain(

    llm=chat_model,

    prompt=prompt,

    output_parser=GradeOutputParser()

)

```py

Finally, we can run the chain for a whole list of student answers and print the outputs.

```

# åœ¨ for å¾ªç¯ä¸­è¿è¡Œé“¾

student_answer_list = ["John F. Kennedy", "JFK", "FDR", "John F. Kenedy",

                "John Kennedy", "Jack Kennedy", "Jacquelin Kennedy",

                "Robert F. Kenedy"]

å¯¹äº student_answer_list ä¸­çš„ student_answer:

    print(student_answer + " - " +

    str(chain.run({'question':question, 'correct_answer':correct_answer,

                    'student_answer':student_answer})))

    print('\n')

# è¾“å‡º:

# John F. Kennedy - æ­£ç¡®

# JFK - æ­£ç¡®

# FDR - é”™è¯¯

# John F. Kenedy - æ­£ç¡®

# John Kennedy - æ­£ç¡®

# Jack Kennedy - æ­£ç¡®

# Jacqueline Kennedy - é”™è¯¯

# Robert F. Kenedy - é”™è¯¯

```

[](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example?source=post_page-----7ce1ed3b553f--------------------------------) [## YouTube-Blog/LLMs/langchain-example at main Â· ShawhinT/YouTube-Blog

### ä»£ç ç”¨äºè¡¥å…… YouTube è§†é¢‘å’Œ Medium åšå®¢æ–‡ç« ã€‚- YouTube-Blog/LLMs/langchain-example at main Â·â€¦

github.com](https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/langchain-example?source=post_page-----7ce1ed3b553f--------------------------------)

# é™åˆ¶

Prompt Engineering ä¸ä»…ä»…æ˜¯å‘ ChatGPT æ±‚åŠ©å†™ç”µå­é‚®ä»¶æˆ–äº†è§£é‡å­è®¡ç®—ã€‚å®ƒæ˜¯ä¸€ä¸ª***æ”¹å˜å¼€å‘è€…æ„å»ºåº”ç”¨ç¨‹åºæ–¹å¼çš„æ–°ç¼–ç¨‹èŒƒå¼***ã€‚

å°½ç®¡è¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åˆ›æ–°ï¼Œä½†å®ƒä¹Ÿæœ‰å…¶å±€é™æ€§ã€‚ä¾‹å¦‚ï¼Œæœ€ä½³çš„æç¤ºç­–ç•¥ä¾èµ–äº LLMã€‚ä¾‹å¦‚ï¼Œæç¤º GPT-3 â€œé€æ­¥æ€è€ƒâ€ åœ¨ç®€å•çš„æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å¸¦æ¥äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ [8]ã€‚ç„¶è€Œï¼Œå¯¹äºæœ€æ–°ç‰ˆæœ¬çš„ ChatGPTï¼Œç›¸åŒçš„ç­–ç•¥ä¼¼ä¹å¹¶æ²¡æœ‰å¸®åŠ©ï¼ˆå®ƒå·²ç»é€æ­¥æ€è€ƒï¼‰ã€‚

Prompt Engineering çš„å¦ä¸€ä¸ªé™åˆ¶æ˜¯å®ƒéœ€è¦å¤§è§„æ¨¡çš„é€šç”¨è¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚ ChatGPTï¼Œè¿™éœ€è¦æ˜¾è‘—çš„è®¡ç®—å’Œç»æµæˆæœ¬ã€‚è¿™å¯¹äºè®¸å¤šæ›´ç‹­ä¹‰çš„ç”¨ä¾‹ï¼Œä¾‹å¦‚å­—ç¬¦ä¸²åŒ¹é…ã€æƒ…æ„Ÿåˆ†ææˆ–æ–‡æœ¬æ‘˜è¦ï¼Œå¯èƒ½è¿‡äºå¤æ‚ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡**å¾®è°ƒ**é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æ¥å…‹æœè¿™ä¸¤ç§é™åˆ¶ã€‚è¿™æ˜¯æˆ‘ä»¬**å¯¹ç°æœ‰è¯­è¨€æ¨¡å‹è¿›è¡Œè°ƒæ•´ä»¥é€‚åº”ç‰¹å®šç”¨ä¾‹çš„è¿‡ç¨‹**ã€‚åœ¨[ä¸‹ä¸€ç¯‡æ–‡ç« ](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91)ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨æµè¡Œçš„å¾®è°ƒæŠ€æœ¯ï¼Œå¹¶é™„æœ‰ç¤ºä¾‹ Python ä»£ç ã€‚

ğŸ‘‰ **å…³äº LLMs çš„æ›´å¤šä¿¡æ¯**: ä»‹ç» | [OpenAI API](https://medium.com/towards-data-science/cracking-open-the-openai-python-api-230e4cae7971) | [Hugging Face Transformers](https://medium.com/towards-data-science/cracking-open-the-hugging-face-transformers-library-350aa0ef0161) | [å¾®è°ƒ](https://medium.com/towards-data-science/fine-tuning-large-language-models-llms-23473d763b91) | æ„å»º LLM | QLoRA | RAG | æ–‡æœ¬åµŒå…¥

![Shaw Talebi](img/02eefb458c6eeff7cd29d40c212e3b22.png)

[Shaw Talebi](https://shawhin.medium.com/?source=post_page-----7ce1ed3b553f--------------------------------)

## å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰

[æŸ¥çœ‹åˆ—è¡¨](https://shawhin.medium.com/list/large-language-models-llms-8e009ae3054c?source=post_page-----7ce1ed3b553f--------------------------------)13 ä¸ªæ•…äº‹![](img/82e865594c68f5307e75665842d197bb.png)![](img/b9436354721f807e0390b5e301be2119.png)![](img/59c8db581de77a908457dec8981f3c37.png)

# èµ„æº

**è”ç³»**: [æˆ‘çš„ç½‘ç«™](https://shawhintalebi.com/) | [é¢„çº¦ç”µè¯](https://calendly.com/shawhintalebi) | [é—®æˆ‘ä»»ä½•é—®é¢˜](https://shawhintalebi.com/contact/)

**ç¤¾äº¤åª’ä½“**: [YouTube ğŸ¥](https://www.youtube.com/channel/UCa9gErQ9AE5jT2DZLjXBIdA) | [LinkedIn](https://www.linkedin.com/in/shawhintalebi/) | [Twitter](https://twitter.com/ShawhinT)

**æ”¯æŒ**: [è¯·æˆ‘å–å’–å•¡](https://www.buymeacoffee.com/shawhint) â˜•ï¸

[](https://shawhin.medium.com/subscribe?source=post_page-----7ce1ed3b553f--------------------------------) [## å…è´¹è·å–æˆ‘å†™çš„æ¯ä¸€ä¸ªæ–°æ•…äº‹

### å…è´¹è·å–æˆ‘å†™çš„æ¯ä¸€ä¸ªæ–°æ•…äº‹ P.S. æˆ‘ä¸ä¼šå°†ä½ çš„ç”µå­é‚®ä»¶åˆ†äº«ç»™ä»»ä½•äºº é€šè¿‡æ³¨å†Œï¼Œä½ å°†åˆ›å»ºä¸€ä¸ªâ€¦

shawhin.medium.com](https://shawhin.medium.com/subscribe?source=post_page-----7ce1ed3b553f--------------------------------)

[1] [arXiv:2302.11382](https://arxiv.org/abs/2302.11382) **[cs.SE]**

[2] [arXiv:2106.09685](https://arxiv.org/abs/2106.09685) **[cs.CL]**

[3] [GPT çŠ¶æ€](https://www.youtube.com/watch?v=bZQun8Y4L2A) ç”± [Andrej Karpathy](https://medium.com/u/ac9d9a35533e?source=post_page-----7ce1ed3b553f--------------------------------) åœ¨ Microsoft Build 2023 ä¸Šæ¼”è®²

[4] [arXiv:2206.07682](https://arxiv.org/abs/2206.07682) **[cs.CL]**

[5] [ä¸ºå¼€å‘è€…è®¾è®¡çš„ ChatGPT æç¤ºå·¥ç¨‹](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/) ç”± deeplearning.ai æä¾›

[6] [arXiv:2005.14165](https://arxiv.org/abs/2005.14165) **[cs.CL]**

[7] [arXiv:2201.11903](https://arxiv.org/abs/2201.11903) **[cs.CL]**

[8] [arXiv:2210.03493](https://arxiv.org/abs/2210.03493) **[cs.CL]**
