["```py\npip install fiftyone openai replicate\n```", "```py\nimport replicate\n\nclass Text2Image(object):\n    \"\"\"Wrapper for a Text2Image model.\"\"\"\n    def __init__(self):\n        self.name = None\n        self.model_name = None\n\n    def generate_image(self, text):\n        response = replicate.run(self.model_name, input={\"prompt\": text})\n        if type(response) == list:\n            response = response[0]\n        return response\n```", "```py\nclass StableDiffusion(Text2Image):\n    \"\"\"Wrapper for a StableDiffusion model.\"\"\"\n    def __init__(self):\n        self.name = \"stable-diffusion\"\n        self.model_name = \"stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd7478\"\n```", "```py\nimport openai\nclass DALLE2(Text2Image):\n    \"\"\"Wrapper for a DALL-E 2 model.\"\"\"\n    def __init__(self):\n        self.name = \"dalle-2\"\n\n    def generate_image(self, text):\n        response = openai.Image.create(\n            prompt=text,\n            n=1,\n            size=\"512x512\"\n        )\n        return response['data'][0]['url']\n```", "```py\nclass Image2Text(object):\n    \"\"\"Wrapper for an Image2Text model.\"\"\"\n    def __init__(self):\n        self.name = None\n        self.model_name = None\n        self.task_description = \"Write a detailed description of this image.\"\n\n    def generate_text(self, image_url):\n        response = replicate.run(\n            self.model_name, \n            input={\n                \"image\": image_url,\n                \"prompt\": self.task_description,\n                }\n            )\n        return response \n```", "```py\nclass BLIP(Image2Text):\n    \"\"\"Wrapper for a BLIP model.\"\"\"\n    def __init__(self):\n        super().__init__()\n        self.name = \"blip\"\n        self.model_name = \"salesforce/blip:2e1dddc8621f72155f24cf2e0adbde548458d3cab9f00c0139eea840d0ac4746\"\n```", "```py\nI'm playing a game of telephone using text-to-image and image-to-text AI models. \nI want to evaluate these models based on their ability to retain complex semantic\ninformation over the course of long conversations. Your job is to give me 10 text\nprompts that I can use to run these games of telephone. You must give me one 3 \neasy, 3 medium, 3 hard, and 1 ultra-hard prompt\n```", "```py\nEasy:\n\n\"A red apple sitting on a wooden table with sunlight streaming in from a window.\"\n\nMedium:\n\n\"An astronaut floating in the International Space Station, looking out at Earth through the window, with a space capsule docked in the background.\"\n\nHard:\n\n\"A bustling marketplace in an ancient Middle Eastern city. Traders haggling over spices and silks, camels carrying goods, the sun setting behind a mosque with a crescent moon visible.\"\n\nImpossible:\n\n\"A panoramic scene of an advanced alien civilization on a distant exoplanet. Interstellar vehicles flying in an indigo sky above towering crystalline structures. Aliens with varying physical features are interacting, engaging in activities like exchanging energy orbs, communicating through light patterns, and tending to exotic, bio-luminescent flora. The planetâ€™s twin moons are visible in the horizon over a glistening alien ocean.\"\n```", "```py\nclass Prompt(object):\n    def __init__(self, text, level):\n        self.text = text\n        self.level = level\n\nlevels = [\"easy\", \"medium\", \"hard\", \"impossible\"]\nlevel_prompts = [easy_texts, medium_texts, hard_texts, impossible_texts]\n\ndef get_prompts():\n    prompts = []\n    for level, texts in zip(levels, level_prompts):\n        for text in texts:\n            prompts.append(Prompt(text, level))\n    return prompts\n```", "```py\nimport os\nimport hashlib\nimport fiftyone as fo\nfrom fiftyone import ViewField as F\n\nclass TelephoneLine(object):\n    \"\"\"Class for playing telephone with AI.\"\"\"\n    def __init__(self, t2i, i2t):\n        self.t2i = t2i\n        self.i2t = i2t\n        self.name = f\"{t2i.name}_{i2t.name}\"\n        self.conversations = {}\n\n    def get_conversation_name(self, text):\n        full_name = f\"{self.name}{text}\"\n        hashed_name = hashlib.md5(full_name.encode())\n        return hashed_name.hexdigest()[:6]\n\n    def play(self, prompt, nturns = 10):\n        \"\"\"Play a game of telephone.\"\"\"\n        print(f\"Connecting {self.t2i.name} <-> {self.i2t.name} with prompt: {prompt.text[:20]}...\")\n        texts = [prompt.text]\n        image_urls = []\n\n        for _ in range(nturns):\n            image_url = self.t2i.generate_image(texts[-1])\n            text = self.i2t.generate_text(image_url)\n            texts.append(text)\n            image_urls.append(image_url)\n\n        conversation_name = self.get_conversation_name(prompt.text)\n        self.conversations[conversation_name] = {\n            \"texts\": texts,\n            \"image_urls\": image_urls,\n            \"level\": prompt.level\n        }\n```", "```py\n def save_conversations_to_dataset(self, dataset):\n        \"\"\"Save conversations to a dataset.\"\"\"\n        for conversation_name in self.conversations.keys():\n            conversation = self.conversations[conversation_name]\n            prompt = conversation[\"texts\"][0]\n            level = conversation[\"level\"]\n            image_urls = conversation[\"image_urls\"]\n            texts = conversation[\"texts\"]\n\n            for i in range(len(image_urls)):\n                filename = f\"{conversation_name}_{i}.jpg\"\n                filepath = os.path.join(IMAGES_DIR, filename)\n                download_image(image_urls[i], filepath)\n\n                sample = fo.Sample(\n                    filepath = filepath,\n                    conversation_name = conversation_name,\n                    prompt = prompt,\n                    level = level,\n                    t2i_model = self.t2i.name,\n                    i2t_model = self.i2t.name,\n                    step_number = i,\n                    text_before = texts[i],\n                    text_after = texts[i+1]\n                )\n\n                dataset.add_sample(sample)\n```", "```py\n## Image2Text models\nmplug_owl = MPLUGOwl()\nblip = BLIP()\nclip_prefix = CLIPPrefix()\nmini_gpt4 = MiniGPT4()\nimage2text_models = [mplug_owl, blip, clip_prefix, mini_gpt4]\n\n## Text2Image models\nvqgan_clip = VQGANCLIP()\nsd = StableDiffusion()\ndalle2 = DALLE2()\ntext2image_models = [sd, dalle2, vqgan_clip]\n```", "```py\ncombos = [(t2i, i2t) for t2i in text2image_models for i2t in image2text_models]\nlines = [TelephoneLine(*combo) for combo in combos]\n```", "```py\nprompts = get_prompts()\n```", "```py\nimport fiftyone as fo\n\ndataset = fo.Dataset(name = 'telephone', persistent=True)\ndataset.add_sample_field(\"conversation_name\", fo.StringField)\ndataset.add_sample_field(\"prompt\", fo.StringField)\ndataset.add_sample_field(\"level\", fo.StringField)\ndataset.add_sample_field(\"t2i_model\", fo.StringField)\ndataset.add_sample_field(\"i2t_model\", fo.StringField)\ndataset.add_sample_field(\"step_number\", fo.IntField)\ndataset.add_sample_field(\"text_before\", fo.StringField)\ndataset.add_sample_field(\"text_after\", fo.StringField)\n```", "```py\nfrom tqdm import tqdm\n\nfor line in tqdm(lines):\n    for prompt in prompts:\n        line.play(prompt, nturns = 10)\n    line.save_conversations_to_dataset(dataset)\n\nsession = fo.launch_app(dataset)\n```", "```py\nfrom scipy.spatial.distance import cosine as cosine_distance\n```", "```py\nMODEL_NAME = \"daanelson/imagebind:0383f62e173dc821ec52663ed22a076d9c970549c209666ac3db181618b7a304\"\ndef embed_text(text):\n    response = replicate.run(\n        MODEL_NAME,\n        input={\n            \"text_input\": text,\n             \"modality\": \"text\"\n            }\n    )\n    return np.array(response)\n```", "```py\nimport hashlib\ndef hash_prompt(prompt):\n    return hashlib.md5(prompt.encode()).hexdigest()[:6]\n\n### Embed initial prompts\nprompt_embeddings = {}\ndataset.add_sample_field(\"prompt_hash\", fo.StringField)\n\n## Group samples by initial prompt\n## Add hash to all samples in group\nprompt_groups = dataset.group_by(\"prompt\")\nfor pg in prompt_groups.iter_dynamic_groups():\n    prompt = pg.first().prompt\n    hash = hash_prompt(prompt)\n    prompt_embeddings[hash] = embed_text(prompt)\n    view = pg.set_field(\"prompt_hash\", hash)\n    view.save(\"prompt_hash\")\n```", "```py\ndataset.add_sample_field(\"text_after_dist\", fo.FloatField)\n\nprompt_groups = dataset.group_by(\"conversation_name\")\nfor cg in conversation_groups.iter_dynamic_groups(progress=True):\n    hash = cg.first().prompt_hash\n    prompt_embedding = prompt_embeddings[hash]\n\n    ordered_samples = cg.sort_by(\"step_number\")\n    for sample in ordered_samples.iter_samples(autosave=True):\n        text_embedding = embed_text(sample.text_after)\n        sample[\"text_embedding\"] = text_embedding        \n        sample.text_after_dist = cosine_distance(\n            prompt_embedding,\n            text_embedding\n        )\n```"]