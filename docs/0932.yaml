- en: 'Multimodal Chain of Thoughts: Solving Problems in a Multimodal World'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=collection_archive---------8-----------------------#2023-03-13](https://towardsdatascience.com/multimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa?source=collection_archive---------8-----------------------#2023-03-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: NLP | MULTIMODALITY | CHAIN OF THOUGHTS |
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The world is not only text: How to extend the chain of thoughts to image and
    text?'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----961a8ab9d0fa--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----961a8ab9d0fa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----961a8ab9d0fa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----961a8ab9d0fa--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----961a8ab9d0fa--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd----961a8ab9d0fa---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----961a8ab9d0fa--------------------------------)
    ·14 min read·Mar 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F961a8ab9d0fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa&user=Salvatore+Raieli&userId=f1a08d9452cd&source=-----961a8ab9d0fa---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F961a8ab9d0fa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultimodal-chain-of-thoughts-solving-problems-in-a-multimodal-world-961a8ab9d0fa&source=-----961a8ab9d0fa---------------------bookmark_footer-----------)![](../Images/868bf8d7fafd276e2175a475fa6cc822.png)'
  prefs: []
  type: TYPE_NORMAL
- en: photo by [Giulio Magnifico](https://unsplash.com/it/@giuliomagnifico) on Unsplash
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes getting to the answer is not easy, especially when the question requires
    reasoning. A model does not always have the answer hidden in its parameters but
    can get there with the right context and approach. What is the chain of thoughts?
    Why does this approach make it possible to solve multi-step reasoning tasks? Can
    it be extended to multimodal problems (i.e., problems with images and text)? Are
    only large models capable of this?
  prefs: []
  type: TYPE_NORMAL
- en: '**This article discusses how to answer these questions.**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Chain of thought (CoT): what is it?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/118e0e262bad7b95096ebc2f40b9c948.png)'
  prefs: []
  type: TYPE_IMG
- en: photo by [Todd Cravens](https://unsplash.com/it/@toddcravens) on [Unsplash](https://unsplash.com/)
  prefs: []
  type: TYPE_NORMAL
- en: 'In recent years we have seen the number of model parameters grow (to well over
    100 B of parameters). This has been motivated by the scaling law: as the number
    of parameters increased, the error decreased.'
  prefs: []
  type: TYPE_NORMAL
