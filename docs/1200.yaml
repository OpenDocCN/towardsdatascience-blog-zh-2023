- en: 'Machines That Learn Like Us: Solving the Generalization-Memorization Dilemma'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/solving-machine-learnings-generalization-memorization-dilemma-3-promising-paradigms-ab9c236add3e?source=collection_archive---------9-----------------------#2023-04-05](https://towardsdatascience.com/solving-machine-learnings-generalization-memorization-dilemma-3-promising-paradigms-ab9c236add3e?source=collection_archive---------9-----------------------#2023-04-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 3 paradigms to solve one of the most important problems in Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@samuel.flender?source=post_page-----ab9c236add3e--------------------------------)[![Samuel
    Flender](../Images/390d82a673de8a8bb11cef66978269b5.png)](https://medium.com/@samuel.flender?source=post_page-----ab9c236add3e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ab9c236add3e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ab9c236add3e--------------------------------)
    [Samuel Flender](https://medium.com/@samuel.flender?source=post_page-----ab9c236add3e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fce56d9dcd568&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-machine-learnings-generalization-memorization-dilemma-3-promising-paradigms-ab9c236add3e&user=Samuel+Flender&userId=ce56d9dcd568&source=post_page-ce56d9dcd568----ab9c236add3e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ab9c236add3e--------------------------------)
    ·7 min read·Apr 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fab9c236add3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-machine-learnings-generalization-memorization-dilemma-3-promising-paradigms-ab9c236add3e&user=Samuel+Flender&userId=ce56d9dcd568&source=-----ab9c236add3e---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fab9c236add3e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsolving-machine-learnings-generalization-memorization-dilemma-3-promising-paradigms-ab9c236add3e&source=-----ab9c236add3e---------------------bookmark_footer-----------)![](../Images/d07a01c4830a1e5c49f4bbf135d147d5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: (Midjourney)
  prefs: []
  type: TYPE_NORMAL
- en: The “holy grail” of Machine Learning is the ability to build systems that can
    both memorize known patterns in the training data as well as generalize to unknown
    patterns in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: It’s the holy grail because this is how we humans learn as well. You can recognize
    your grandma in an old photo, but you could also recognize a Xoloitzcuintli as
    a dog even though you’ve never actually seen one before. Without memorization
    we’d have to constantly re-learn everything from scratch, and without generalization
    we wouldn’t be able to adapt to an ever-changing world. To survive, we need both.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional statistical learning theory tells us that this is impossible: models
    can either generalize well or memorize well, but not both. It’s the well-known
    bias-variance trade-off, one of the first things we learn in standard ML curricula.'
  prefs: []
  type: TYPE_NORMAL
- en: How then can we build such universal learning systems? Is the holy grail within
    reach?
  prefs: []
  type: TYPE_NORMAL
- en: In this post, let’s dive into 3 paradigms from the literature,
  prefs: []
  type: TYPE_NORMAL
- en: Generalize first, memorize later
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Generalize and memorize at the same time
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
