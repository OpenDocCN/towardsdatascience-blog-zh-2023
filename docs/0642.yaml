- en: 'Text search vs. Vector search: Better together?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本搜索与向量搜索：更好地结合？
- en: 原文：[https://towardsdatascience.com/text-search-vs-vector-search-better-together-3bd48eb6132a?source=collection_archive---------2-----------------------#2023-02-16](https://towardsdatascience.com/text-search-vs-vector-search-better-together-3bd48eb6132a?source=collection_archive---------2-----------------------#2023-02-16)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/text-search-vs-vector-search-better-together-3bd48eb6132a?source=collection_archive---------2-----------------------#2023-02-16](https://towardsdatascience.com/text-search-vs-vector-search-better-together-3bd48eb6132a?source=collection_archive---------2-----------------------#2023-02-16)
- en: Learn how to use OpenSearch to set up a hybrid search system so you can benefit
    from both text and vector search advantages
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解如何使用 OpenSearch 设置混合搜索系统，以便您可以同时受益于文本搜索和向量搜索的优势
- en: '[](https://medium.com/@noamschwartz1?source=post_page-----3bd48eb6132a--------------------------------)[![Noam
    Schwartz](../Images/c5bf11b1267a95242290ca6105eb0b16.png)](https://medium.com/@noamschwartz1?source=post_page-----3bd48eb6132a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3bd48eb6132a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3bd48eb6132a--------------------------------)
    [Noam Schwartz](https://medium.com/@noamschwartz1?source=post_page-----3bd48eb6132a--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@noamschwartz1?source=post_page-----3bd48eb6132a--------------------------------)[![Noam
    Schwartz](../Images/c5bf11b1267a95242290ca6105eb0b16.png)](https://medium.com/@noamschwartz1?source=post_page-----3bd48eb6132a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3bd48eb6132a--------------------------------)[![数据科学前沿](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3bd48eb6132a--------------------------------)
    [Noam Schwartz](https://medium.com/@noamschwartz1?source=post_page-----3bd48eb6132a--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F77ffd6350db9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-search-vs-vector-search-better-together-3bd48eb6132a&user=Noam+Schwartz&userId=77ffd6350db9&source=post_page-77ffd6350db9----3bd48eb6132a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3bd48eb6132a--------------------------------)
    ·8 min read·Feb 16, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3bd48eb6132a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-search-vs-vector-search-better-together-3bd48eb6132a&user=Noam+Schwartz&userId=77ffd6350db9&source=-----3bd48eb6132a---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F77ffd6350db9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-search-vs-vector-search-better-together-3bd48eb6132a&user=Noam+Schwartz&userId=77ffd6350db9&source=post_page-77ffd6350db9----3bd48eb6132a---------------------post_header-----------)
    发表在 [数据科学前沿](https://towardsdatascience.com/?source=post_page-----3bd48eb6132a--------------------------------)
    ·8分钟阅读·2023年2月16日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3bd48eb6132a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-search-vs-vector-search-better-together-3bd48eb6132a&user=Noam+Schwartz&userId=77ffd6350db9&source=-----3bd48eb6132a---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3bd48eb6132a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-search-vs-vector-search-better-together-3bd48eb6132a&source=-----3bd48eb6132a---------------------bookmark_footer-----------)![](../Images/aca0f6a6b0a70bba0d30d5f9db3b1511.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3bd48eb6132a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftext-search-vs-vector-search-better-together-3bd48eb6132a&source=-----3bd48eb6132a---------------------bookmark_footer-----------)![](../Images/aca0f6a6b0a70bba0d30d5f9db3b1511.png)'
- en: Photo by [Aarón Blanco Tejedor](https://unsplash.com/@innernature?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Aarón Blanco Tejedor](https://unsplash.com/@innernature?utm_source=medium&utm_medium=referral)
    提供，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Text databases play a critical role in many business workloads, especially in
    e-commerce where customers rely on product descriptions and reviews to make informed
    purchasing decisions. Vector search, a method that utilizes embeddings of text
    to find semantically similar documents is another powerful tool out there. However,
    due to concerns about the complexity of implementing it into their current workflow
    some businesses may be hesitant to try out vector search. But what if I told you
    that it could be done easily and with significant benefits?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据库在许多业务工作负载中扮演着关键角色，特别是在电子商务中，客户依赖产品描述和评论来做出明智的购买决定。向量搜索，利用文本嵌入来找到语义相似的文档，是另一个强大的工具。然而，由于对将其实施到现有工作流程的复杂性的担忧，一些企业可能会对尝试向量搜索持保留态度。但是，如果我告诉你这可以很容易地完成并且带来显著的好处呢？
- en: In this blog post, I’ll show you how to easily create a hybrid setup that combines
    the power of text and vector search. This setup will give you the most comprehensive
    and accurate search results. I’ll be using OpenSearch as the search engine and
    Hugging Face’s [Sentence Transformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
    for generating embeddings. The dataset I chose for this task is the ”XMarket”
    dataset (which is described in greater depth [here](https://arxiv.org/pdf/2109.05929.pdf)),
    where we will embed the title field into a vector representation during the indexing
    process.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客文章中，我将展示如何轻松创建一个结合文本和向量搜索的混合设置。这个设置将给你最全面和准确的搜索结果。我将使用 OpenSearch 作为搜索引擎，并使用
    Hugging Face 的 [Sentence Transformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
    来生成嵌入。我为这个任务选择的数据集是“XMarket”数据集（更详细的描述见 [这里](https://arxiv.org/pdf/2109.05929.pdf)），在索引过程中，我们将标题字段嵌入到向量表示中。
- en: '**Preparing the dataset**'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**准备数据集**'
- en: First, let’s start by indexing our documents using Sentence Transformers. This
    library has pre-trained models that can generate embeddings for sentences or paragraphs.
    These embeddings act as a unique fingerprint for a piece of text. During the indexing
    process, I converted the title field to a vector representation and indexed it
    in OpenSearch. You can do this by simply importing the model and encoding any
    textual field.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用 Sentence Transformers 来索引我们的文档。这个库有预训练的模型，可以生成句子或段落的嵌入。这些嵌入作为文本的独特指纹。在索引过程中，我将标题字段转换为向量表示，并将其在
    OpenSearch 中索引。你可以通过简单地导入模型并编码任何文本字段来实现这一点。
- en: 'The model can be imported by writing the following two lines:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过编写以下两行来导入模型：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It’s that simple!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 就这么简单！
- en: 'We will create an index named “products” by passing the following mapping:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过传递以下映射来创建一个名为“products”的索引：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*asin — the document unique ID which is taken from the product metadata.*'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*asin — 从产品元数据中获取的文档唯一 ID。*'
- en: '*description_vector — this is where we will store our encoded product title
    field.*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*description_vector — 这是我们存储编码后的产品标题字段的地方。*'
- en: '*item_image- this is an image url of the product*'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*item_image- 这是产品的图片网址*'
- en: '*text_field — this is the title of the product*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*text_field — 这是产品的标题*'
- en: Note that we are using standard OpenSearch analyzer, which knows to tokenize
    each word in a field into single keywords. OpenSearch takes these keywords and
    uses them for the Okapi BM25 algorithm. I also took the title field and saved
    it twice in the document; once in its raw format and once as a vector representation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们使用的是标准的 OpenSearch 分析器，它会将字段中的每个单词标记为单个关键词。OpenSearch 使用这些关键词来进行 Okapi
    BM25 算法。我还将标题字段保存了两次；一次是其原始格式，一次是向量表示。
- en: 'I will then use the model to encode the title field and create documents which
    will be bulked to OpenSearch:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我将使用该模型来编码标题字段，并创建将批量上传到 OpenSearch 的文档：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Hybrid search implementation**'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**混合搜索实现**'
- en: The plan is to create a client which will take input from the user, generate
    an embedding using the Sentence Transformers model and perform our hybrid search.
    The user will also be asked to provide a boost level, which is the amount of significance
    they want to give to either text or vector search. This way, the user can choose
    to prioritize one type of search over the other. So if for example the user wants
    the semantic meaning of his query to be taken into account more than the simple
    textual appearance in the description then he would give vector search a higher
    boost than text search.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 计划是创建一个客户端，该客户端将从用户那里获取输入，使用Sentence Transformers模型生成嵌入，并执行我们的混合搜索。用户还会被要求提供一个提升级别，即他们希望给予文本搜索或向量搜索的相对重要性。这样，用户可以选择优先考虑一种搜索类型。例如，如果用户希望他的查询的语义意义比描述中的简单文本出现更重要，他可以给向量搜索更高的提升等级。
- en: '**Search**'
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**搜索**'
- en: 'We’ll first run a text search on the index using OpenSearch’s search method.
    This method takes in a query string and returns a list of documents that match
    the query. OpenSearch obtains the results for text search by utilizing the Okapi
    BM25 as the ranking algorithm. Text search using OpenSearch is performed by sending
    the following request body:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用OpenSearch的搜索方法在索引上进行文本搜索。此方法接受一个查询字符串，并返回与查询匹配的文档列表。OpenSearch通过利用Okapi
    BM25作为排名算法来获取文本搜索结果。使用OpenSearch进行文本搜索是通过发送以下请求体进行的：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Where *textual_query* is the text written by the user. For my results to come
    back in a clean manner I added “_source” in order that OpenSearch will only return
    the specific fields I am interested in seeing.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *textual_query* 是用户输入的文本。为了使我的结果以干净的方式返回，我添加了“_source”，以便OpenSearch仅返回我感兴趣的特定字段。
- en: 'Since text and vector search’s ranking score algorithm are different we will
    need to bring the scores to the same scale in order to combine the results. To
    do that we’ll normalize the scores for each document from the text search. The
    maximum BM25 score is the highest score that can be assigned to a document in
    a collection for a given query. It represents the maximum relevance of a document
    for the query. The value of the maximum BM25 score depends on the parameters of
    the BM25 formula, such as the average document length, the term frequency, and
    the inverse document frequency. For that reason, I took the max score received
    from OpenSearch for each query and divided each of the results scores by it, giving
    us scores on the scale between 0 and 1\. The following function demonstrates our
    normalization algorithm:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于文本和向量搜索的排名分数算法不同，我们需要将分数调整到相同的尺度，以便结合结果。为此，我们将对每个文档的文本搜索分数进行归一化。最大BM25分数是针对特定查询在集合中分配给文档的最高分数。它表示文档与查询的最大相关性。最大BM25分数的值取决于BM25公式的参数，例如平均文档长度、术语频率和逆文档频率。因此，我取了OpenSearch为每个查询收到的最大分数，并将每个结果分数除以它，得到0到1之间的分数。以下函数演示了我们的归一化算法：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Next, we’ll conduct a vector search using the vector search method. This method
    takes a list of embeddings and returns a list of documents that are semantically
    similar to the embeddings.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用向量搜索方法进行向量搜索。此方法接受一个嵌入列表，并返回与这些嵌入在语义上相似的文档列表。
- en: 'The search query for OpenSearch looks like the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对OpenSearch的搜索查询如下所示：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Where get_vector_sentence_transformers sends the text to *model.encode(text_input)*
    which returns a vector representation of the text. Also note that the higher your
    topK results, the more accurate your results will be, but this will increase latency
    as well.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 get_vector_sentence_transformers 将文本发送到 *model.encode(text_input)*，该方法返回文本的向量表示。还要注意，您的
    topK 结果越高，结果越准确，但这也会增加延迟。
- en: '**Interpolate results and apply boost**'
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**插值结果并应用提升**'
- en: '![](../Images/c9d936ba33da7aa726d3b90eb3535cb9.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9d936ba33da7aa726d3b90eb3535cb9.png)'
- en: Photo by [Amol Tyagi](https://unsplash.com/@amoltyagi2?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Amol Tyagi](https://unsplash.com/@amoltyagi2?utm_source=medium&utm_medium=referral)
    提供的照片，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: Now we’ll need to combine the two search results. To do that, we’ll interpolate
    the results so every document that occurred in both searches will appear higher
    in the hybrid results list. This way, we can take advantage of the strengths of
    both text and vector search to get the most comprehensive results.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将两个搜索结果结合起来。为此，我们将对结果进行插值处理，使得在两个搜索中都出现的每个文档在混合结果列表中排名更高。这样，我们可以利用文本和向量搜索的优势，获得最全面的结果。
- en: The following function is used to interpolate the results of keyword search
    and vector search. It returns a dictionary containing the common elements between
    the two sets of hits as well as the scores for each document. If the document
    appears in only one of the search results, then we will assign it the lowest score
    that was retrieved.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数用于插值关键词搜索和向量搜索的结果。它返回一个字典，包含两个命中的结果集之间的共同元素及每个文档的分数。如果文档只出现在一个搜索结果中，则我们将其分配为检索到的最低分数。
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Ultimately we will have a dictionary with the document ID as a key and an array
    of score values as a value. The first element in the array is the vector search
    score and the second element is the text search normalized score.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最终我们将得到一个以文档ID为键，以分数数组为值的字典。数组中的第一个元素是向量搜索分数，第二个元素是文本搜索归一化分数。
- en: Finally, we apply a boost to our search results. We will iterate over the scores
    of the results and multiply the first element by the vector boost level and the
    second element by the text boost level.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们对搜索结果应用提升。我们将遍历结果的分数，将第一个元素乘以向量提升水平，第二个元素乘以文本提升水平。
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It’s time to see what we have! This is what the complete workflow looks like:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候看看我们有什么了！这就是完整的工作流程：
- en: '![](../Images/000c25b2e146cd2c629b827904ac79d0.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/000c25b2e146cd2c629b827904ac79d0.png)'
- en: GIF by the Author
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 作者制作的GIF
- en: 'I searched for a sentence “an ice cream scoop” with a 0.5 boost for vector
    search and a 0.5 boost for text search, and this is what I got in the top few
    results:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我搜索了一个句子“冰淇淋勺”，为向量搜索和文本搜索分别设置了0.5的提升，这就是我在前几个结果中得到的：
- en: Vector search returned —
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索返回 —
- en: '![](../Images/5e6554daeaa9b29867ea8166fa4922bc.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e6554daeaa9b29867ea8166fa4922bc.png)'
- en: Images from XMarket Dataset
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 来自XMarket数据集的图片
- en: Text search returned —
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 文本搜索返回 —
- en: '![](../Images/e58754765f018fd267f896b9de2dc8bc.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e58754765f018fd267f896b9de2dc8bc.png)'
- en: Images from XMarket Dataset
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 来自XMarket数据集的图片
- en: Hybrid search returned —
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 混合搜索返回 —
- en: '![](../Images/6a74a31afd65dba32864934c3b57be1d.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a74a31afd65dba32864934c3b57be1d.png)'
- en: Images from XMarket Dataset
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 来自XMarket数据集的图片
- en: 'In this example, we searched for “an ice cream scoop” using both text and vector
    search. The text search returns documents containing the keywords “an”, “ ice”,“cream”
    and “scoop”. The result that came in fourth for text search is an ice cream machine
    and it is certainly not a scoop. The reason it came in so high is because its
    title which is “Breville BCI600XL Smart Scoop Ice Cream Maker” contained three
    of the keywords in the sentence: “Scoop”, “Ice”, “Cream” and therefore scored
    highly on BM25 although it did not match our search. Vector search on the other
    hand, returns results that are semantically similar to the query, regardless of
    whether the keywords appear in the document or not. It knew that the fact that
    “scoop” appeared before “ice cream” meant that it would not match as well. Thus,
    we get a more comprehensive set of results that includes more than documents that
    mention “an ice cream scoop”.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用文本和向量搜索来搜索“冰淇淋勺”。文本搜索返回包含关键词“an”、“ice”、“cream”和“scoop”的文档。文本搜索排名第四的结果是一个冰淇淋机，它显然不是一个勺子。它排名如此靠前的原因是其标题“Breville
    BCI600XL Smart Scoop Ice Cream Maker”包含了句子中的三个关键词：“Scoop”、“Ice”、“Cream”，因此在BM25中的评分很高，尽管它与我们的搜索不匹配。而向量搜索则返回语义上与查询相似的结果，无论关键词是否出现在文档中。它知道“scoop”出现在“ice
    cream”之前意味着匹配度较低。因此，我们得到了一个更全面的结果集，其中包含了比单纯提到“冰淇淋勺”的文档更多的信息。
- en: Clearly, if you were to only use one type of search, you would miss out on valuable
    results or display inaccurate results and frustrate your customers. When using
    the advantages of both worlds we receive more accurate results. So, I do believe
    that the answer to our question is that better together has proven itself to be
    true.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，如果你只使用一种搜索方式，你将错过有价值的结果或显示不准确的结果，从而使客户感到沮丧。当利用两者的优势时，我们会得到更准确的结果。所以，我相信我们的答案是，"更好地结合"已经证明是正确的。
- en: But wait, can better become **even better**? One way to improve search experience
    is by utilizing the [power of the APU](/bolster-opensearch-performance-with-5-simple-steps-ca7d21234f6b)
    (Associative Processing Unit) in OpenSearch. By conducting the vector search on
    the APU using [Searchium.ai](https://www.searchium.ai/)’s plugin, we can take
    advantage of advanced algorithms and processing capabilities to further [improve
    the latency and significantly cut costs](https://betterprogramming.pub/tired-of-troubleshooting-idle-search-resources-use-opensearch-benchmark-for-performance-tuning-d4277c9f724)
    (for example, $0.23 vs. $8.76) of our search while still getting [similar results](https://www.youtube.com/watch?v=AqbRTT5Z7h0)
    for vector search.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等，更好的可以变得**更好**吗？改善搜索体验的一种方法是利用 OpenSearch 中的[APU 力量](/bolster-opensearch-performance-with-5-simple-steps-ca7d21234f6b)（联想处理单元）。通过使用
    [Searchium.ai](https://www.searchium.ai/) 的插件在 APU 上进行向量搜索，我们可以利用先进的算法和处理能力来进一步[改善延迟并显著降低成本](https://betterprogramming.pub/tired-of-troubleshooting-idle-search-resources-use-opensearch-benchmark-for-performance-tuning-d4277c9f724)（例如，$0.23
    对比 $8.76），同时仍然获得[类似的结果](https://www.youtube.com/watch?v=AqbRTT5Z7h0)。
- en: 'We can [install the plugin](https://www.youtube.com/watch?v=7p08K-Ul1O0), [upload
    the index to the APU](https://www.youtube.com/watch?v=RfoeZKmJcTY&t=3s) and search
    by sending a slightly modified request body:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以[安装插件](https://www.youtube.com/watch?v=7p08K-Ul1O0)、[将索引上传到 APU](https://www.youtube.com/watch?v=RfoeZKmJcTY&t=3s)，并通过发送略微修改过的请求体进行搜索：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: All the other steps are identical!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其他所有步骤都是相同的！
- en: In conclusion, by combining text and vector search using OpenSearch and Sentence
    Transformers, businesses can easily improve their search results. And, by utilizing
    the APU, businesses can take their search results to the next level while also
    cutting infrastructure costs. Don’t let concerns about complexity hold you back.
    Give it a try and see for yourself the benefits it can bring. Happy searching!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，通过结合使用 OpenSearch 和 Sentence Transformers 的文本与向量搜索，企业可以轻松改善搜索结果。而通过利用 APU，企业可以将搜索结果提升到一个新的水平，同时降低基础设施成本。不要让复杂性的问题阻碍你。试一试，看看它能带来哪些好处。祝搜索愉快！
- en: The full code can be found [here](https://github.com/Searchium-ai/hybrid-search)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码可以在[这里](https://github.com/Searchium-ai/hybrid-search)找到。
- en: A huge thanks to [Yaniv Vaknin](https://medium.com/@yaniv.vaknin) and [Daphna
    Idelson](https://www.linkedin.com/in/daphnaidelson/) for all of their help!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢[Yaniv Vaknin](https://medium.com/@yaniv.vaknin) 和[Daphna Idelson](https://www.linkedin.com/in/daphnaidelson/)的所有帮助！
