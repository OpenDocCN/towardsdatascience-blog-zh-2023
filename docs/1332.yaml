- en: Integrating Neo4j into the LangChain ecosystem
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/integrating-neo4j-into-the-langchain-ecosystem-df0e988344d2?source=collection_archive---------1-----------------------#2023-04-17](https://towardsdatascience.com/integrating-neo4j-into-the-langchain-ecosystem-df0e988344d2?source=collection_archive---------1-----------------------#2023-04-17)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how to develop a LangChain agent that has multiple ways of interacting
    with the Neo4j database
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://bratanic-tomaz.medium.com/?source=post_page-----df0e988344d2--------------------------------)[![Tomaz
    Bratanic](../Images/d5821aa70918fcb3fc1ff0013497b3d5.png)](https://bratanic-tomaz.medium.com/?source=post_page-----df0e988344d2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----df0e988344d2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----df0e988344d2--------------------------------)
    [Tomaz Bratanic](https://bratanic-tomaz.medium.com/?source=post_page-----df0e988344d2--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F57f13c0ea39a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neo4j-into-the-langchain-ecosystem-df0e988344d2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=post_page-57f13c0ea39a----df0e988344d2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----df0e988344d2--------------------------------)
    ·15 min read·Apr 17, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdf0e988344d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neo4j-into-the-langchain-ecosystem-df0e988344d2&user=Tomaz+Bratanic&userId=57f13c0ea39a&source=-----df0e988344d2---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdf0e988344d2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintegrating-neo4j-into-the-langchain-ecosystem-df0e988344d2&source=-----df0e988344d2---------------------bookmark_footer-----------)![](../Images/79e7c6ccc5293a96177b339b15d4db39.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Alex Knight](https://unsplash.com/@agk42?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '*Update: The so-called Cypher Search, where the LLM generates a Cypher statement
    to query the Neo4j database, has been integrated directly to the LangChain library.
    Learn more* [*here*](/langchain-has-added-cypher-search-cb9d821120d5)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '*2nd update: Vector search is now supported directly by vector index in Neo4j,
    so I have changed the vector search code to use the new index introduced in 5.11*'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT inspired the world and started a new AI revolution. However, it seems
    that the latest trend is supplying ChatGPT with external information to increase
    its accuracy and give it the ability to answer questions where the answers are
    not present in public datasets. Another trend around large language models (LLMs)
    is to turn them into agents, where they have an ability to interact with their
    environment through various API calls or other integrations.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Since enhancing LLMs is relatively new, there aren’t a lot of open-source libraries
    yet. However, it seems that the go-to library for building applications around
    LLMs like ChatGPT is called [LangChain](https://python.langchain.com/en/latest/index.html).
    The library provides the ability to enhance an LLM by giving it access to various
    tools and external data sources. Not only can it improve its responses by accessing
    external data, but it can also act as an agent and manipulate its environment
    through external endpoints.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: I randomly stumbled upon a LangChain project by [Ibis Prevedello](https://medium.com/u/fd610570f1c7?source=post_page-----df0e988344d2--------------------------------)
    that uses graph search to enhance the LLMs by providing additional external context.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/ibiscp/LLM-IMDB?source=post_page-----df0e988344d2--------------------------------)
    [## GitHub - ibiscp/LLM-IMDB: Proof of concept app using LangChain and LLMs to
    retrieve information…'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Proof of concept app using LangChain and LLMs to retrieve information from graphs,
    built with the IMDB dataset - GitHub…
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/ibiscp/LLM-IMDB?source=post_page-----df0e988344d2--------------------------------)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: The project by Ibis uses [NetworkX library](https://networkx.org/) to store
    the graph information. I really liked his approach and how easy it was to integrate
    graph search into the LangChain ecosystem. Therefore, I have decided to develop
    a project that would integrate [Neo4j](https://neo4j.com/), a graph database,
    into the LangChain ecosystem.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/tomasonjo/langchain2neo4j?source=post_page-----df0e988344d2--------------------------------)
    [## GitHub - tomasonjo/langchain2neo4j: Integrating Neo4j database into langchain
    ecosystem'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: The Langchain2Neo4j is a proof of concept application of how to integrate Neo4j
    into the Langchain ecosystem. This…
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/tomasonjo/langchain2neo4j?source=post_page-----df0e988344d2--------------------------------)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: 'After two weeks of coding, the project now allows a LangChain agent to interact
    with Neo4j in three different modes:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Generating Cypher statements to query the database
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Full-text keyword search of relevant entities
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector similarity search
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this blog post, I will walk you through the reasoning and implementation
    of each approach I developed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Environment setup
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we will configure the Neo4j environment. We will use the dataset available
    as the [recommendations project](https://sandbox.neo4j.com/?usecase=recommendations)
    in the Neo4j sandbox. The easiest solution is simply to create a Neo4j Sandbox
    instance by following [this link](https://sandbox.neo4j.com/?usecase=recommendations).
    However, if you would prefer a local instance of Neo4j, you can also restore a
    [database dump that is available on GitHub](https://github.com/neo4j-graph-examples/recommendations/tree/main/data).
    The dataset is part of the [MovieLens datasets](https://grouplens.org/datasets/movielens/)
    [1], specifically the small version.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将配置 Neo4j 环境。我们将使用 Neo4j 沙盒中作为 [recommendations project](https://sandbox.neo4j.com/?usecase=recommendations)
    提供的数据集。最简单的解决方案是通过 [这个链接](https://sandbox.neo4j.com/?usecase=recommendations)
    创建一个 Neo4j 沙盒实例。然而，如果你更倾向于使用本地 Neo4j 实例，你还可以恢复一个 [在 GitHub 上可用的数据库转储](https://github.com/neo4j-graph-examples/recommendations/tree/main/data)。该数据集是
    [MovieLens datasets](https://grouplens.org/datasets/movielens/) [1] 的一部分，具体是小版本。
- en: After the Neo4j database is instantiated, we should have a graph with the following
    schema populated.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j 数据库实例化后，我们应该拥有一个包含以下模式的图表。
- en: '![](../Images/7c83401d58a5c1a58e6cdc6d5294af0b.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7c83401d58a5c1a58e6cdc6d5294af0b.png)'
- en: Graph schema. Image by the author.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图谱模式。图像由作者提供。
- en: 'Next, you need to clone the langchain2neo4j repository by executing the following
    command:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要通过执行以下命令来克隆 langchain2neo4j 仓库：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the next step, you need to create an `.env` file and populate the neo4j and
    OpenAI credentials as shown in the `.env.example` file.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步中，你需要创建一个 `.env` 文件，并按照 `.env.example` 文件中的说明填写 neo4j 和 OpenAI 凭证。
- en: 'Lastly, you need to create a full-text index in Neo4j and import movie title
    embeddings by running:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你需要在 Neo4j 中创建一个全文索引，并通过运行以下命令导入电影标题嵌入：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you are a Windows user, the `seed_db` script probably won’t work. In that
    case, I have prepared a Jupyter notebook that can help you seed the database as
    an alternative to the shell script.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是 Windows 用户，`seed_db` 脚本可能无法正常工作。在这种情况下，我准备了一个 Jupyter 笔记本，可以作为替代 shell
    脚本来帮助你初始化数据库。
- en: Now, let’s jump to the LangChain integration.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们跳到 LangChain 集成部分。
- en: LangChain agent
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain 代理
- en: 'As far as I have seen, the most common data flow of using a LangChain agent
    to answer a user question is the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我所见，使用 LangChain 代理回答用户问题的最常见数据流如下：
- en: '![](../Images/7f905a41e80ab8cd9127f4d3ce7b1e7c.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f905a41e80ab8cd9127f4d3ce7b1e7c.png)'
- en: LangChain agent flow. Image by the author.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 代理流程。图像由作者提供。
- en: The agent data flow is initiated when it receives input from a user. The agent
    then sends a request to an LLM model that includes the user question along with
    the agent prompt, which is a set of instructions in a natural language the agent
    should follow. In turn, the LLM responds with further instructions to the agent.
    Most often, the first response is to use any available tools to gain additional
    information from external sources. However, tools are not limited to read-only
    operations. For example, you could use them to update a database. After the tool
    returns additional context, another call is made to an LLM that includes the newly
    gained information. The LLM now has the option to produce a final answer that
    is returned to a user, or it can decide it needs to perform more actions through
    its available tools.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 代理数据流在接收到用户输入时启动。代理随后向 LLM 模型发送一个请求，该请求包含用户问题以及代理提示，代理提示是一组代理应遵循的自然语言指令。接着，LLM
    会向代理发送进一步的指令。通常情况下，第一个响应是使用任何可用工具从外部来源获取额外的信息。然而，工具不仅限于只读操作。例如，你可以使用它们来更新数据库。在工具返回额外的上下文后，将再次调用包含新获得信息的
    LLM。LLM 现在可以选择生成返回给用户的最终答案，或者决定通过其可用工具执行更多操作。
- en: A LangChain agent uses LLMs for its reasoning. Therefore, the first step is
    to define which model to use. At the moment, the langchain2neo4j project supports
    only OpenAI’s chat completion models, specifically GPT-3.5-turbo, and GPT-4 models.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 代理使用 LLM 进行推理。因此，第一步是定义使用哪个模型。目前，langchain2neo4j 项目仅支持 OpenAI 的聊天完成模型，特别是
    GPT-3.5-turbo 和 GPT-4 模型。
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I haven’t yet explored other LLMs besides OpenAI’s. However, with LangChain,
    it should be easy, as it has integration with more than ten other LLMs. I didn’t
    know that that many existed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我还没有探索除 OpenAI 之外的其他 LLM。然而，使用 LangChain 应该很简单，因为它集成了十多种其他 LLM。我不知道竟然存在这么多。
- en: '[## Integrations'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 集成'
- en: Edit description
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编辑描述
- en: python.langchain.com](https://python.langchain.com/en/latest/modules/models/llms/integrations.html?source=post_page-----df0e988344d2--------------------------------)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: python.langchain.com](https://python.langchain.com/en/latest/modules/models/llms/integrations.html?source=post_page-----df0e988344d2--------------------------------)
- en: 'Next, we need to add a conversational memory with the following line:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要添加一个对话记忆，使用以下行：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'LangChain support [multiple types of agents](https://python.langchain.com/en/latest/modules/agents/agents.html).
    For example, some agents can use the memory component, while others cannot. Since
    the object was to build a chatbot, I chose the [Conversation Agent (for Chat Models)
    agent](https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html)
    type. What is interesting about the LangChain library is that half the code is
    written in Python, while the other half is prompt engineering. We can explore
    the [prompts that the conversational agent uses](https://github.com/hwchase17/langchain/blob/master/langchain/agents/conversational_chat/prompt.py).
    For example, the agents has some basic instructions it must follow:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 支持[多种类型的代理](https://python.langchain.com/en/latest/modules/agents/agents.html)。例如，一些代理可以使用记忆组件，而其他的则不能。由于目标是构建一个聊天机器人，我选择了[对话代理（针对聊天模型）代理](https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html)类型。LangChain
    库有趣的是，一半的代码用 Python 编写，另一半则是提示工程。我们可以探索[对话代理使用的提示](https://github.com/hwchase17/langchain/blob/master/langchain/agents/conversational_chat/prompt.py)。例如，代理有一些必须遵循的基本指令：
- en: Assistant is a large language model trained by OpenAI. Assistant is designed
    to be able to assist with a wide range of tasks, from answering simple questions
    to providing in-depth explanations and discussions on a wide range of topics.
    As a language model, Assistant is able to generate human-like text based on the
    input it receives, allowing it to engage in natural-sounding conversations and
    provide responses that are coherent and relevant to the topic at hand. Assistant
    is constantly learning and improving, and its capabilities are constantly evolving.
    It is able to process and understand large amounts of text, and can use this knowledge
    to provide accurate and informative responses to a wide range of questions. Additionally,
    Assistant is able to generate its own text based on the input it receives, allowing
    it to engage in discussions and provide explanations and descriptions on a wide
    range of topics. Overall, Assistant is a powerful system that can help with a
    wide range of tasks and provide valuable insights and information on a wide range
    of topics. Whether you need help with a specific question or just want to have
    a conversation about a particular topic, Assistant is here to assist.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Assistant 是一个由 OpenAI 训练的大型语言模型。Assistant 旨在能够协助处理各种任务，从回答简单问题到提供深入解释和讨论广泛话题。作为一个语言模型，Assistant
    能够根据接收到的输入生成类似人类的文本，使其能够进行自然流畅的对话，并提供与主题相关的连贯回应。Assistant 不断学习和改进，其能力也在不断发展。它能够处理和理解大量文本，并利用这些知识提供准确和有用的回应。此外，Assistant
    能够根据接收到的输入生成自己的文本，从而参与讨论并提供解释和描述。总体而言，Assistant 是一个强大的系统，可以帮助处理各种任务，并提供关于广泛话题的宝贵见解和信息。无论你是需要帮助回答具体问题还是只是想讨论某个特定话题，Assistant
    都在这里提供帮助。
- en: Additionally, the agent has instructions to use any of the specified tools if
    needed.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，代理有指令在需要时使用任何指定的工具。
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Interestingly, the prompt states that the assistant can ask the user to look
    up additional information using tools. However, the user is not a human but an
    application built on top of the LangChain library. Therefore, the entire process
    of finding further information is done automatically without any human in the
    loop. Of course, we can change the prompts if needed. The prompt also includes
    the format the LLMs should use to communicate with the agent.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，提示中指出助手可以要求用户使用工具查找额外信息。然而，用户不是人类，而是构建在 LangChain 库之上的应用程序。因此，整个寻找额外信息的过程是自动完成的，没有任何人类参与。当然，如果需要，我们可以更改提示。提示还包括
    LLMs 应该使用的与代理沟通的格式。
- en: '*Note that the agent prompt doesn’t include that the agent shouldn’t answer
    a question if the answer is not provided in the context returned by tools.*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*请注意，代理提示中没有包括代理在工具返回的上下文中没有提供答案时不应回答问题的内容。*'
- en: Now, all we have to do is to define the available tools. As mentioned, I have
    prepared three methods of interacting with Neo4j database.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The description of a tool is used to specify the capabilities of the tool as
    well as to inform the agent when to use it. Additionally, we need to specify the
    format of the input a tool expects. For example, both the Cypher and vector search
    expect a full question as an input, while the keyword search expects a list of
    relevant movies as input.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: LangChain is quite different from what I am used to in coding. It uses prompts
    to instruct the LLMs to do the work for you instead of coding it yourself. For
    example, the keyword search instructs the ChatGPT to extract relevant movies and
    use that as input. I spent 2 hours debugging the tool input format before realizing
    I could specify it using natural language, and the LLM will handle the rest.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Remember how I mentioned that the agent doesn’t have instructions that it shouldn’t
    answer questions where the information is not provided in the context? Let’s examine
    the following dialogue.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/379650f0d2d96d1a4aefa9d50b1d3db7.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
- en: Image by the author.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: The LLM decided that based on the tool descriptions, it cannot use any of them
    to retrieve relevant context. However, the LLM knows a lot by default, and since
    the agent has no constraints that it should only rely on external sources, the
    LLM can form the answer independently. We would need to change the agent prompt
    if we wanted to enforce different behavior.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Generating Cypher statements
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I have already developed a chatbot interacting with a Neo4j database by generating
    Cypher statements using the OpenAI’s [conversational models like the GPT-3.5-turbo
    and GPT-4](https://medium.com/neo4j/context-aware-knowledge-graph-chatbot-with-gpt-4-and-neo4j-d3a99e8ae21e).
    Therefore, I could borrow most of the ideas to implement a tool that allows the
    LangChain agent to retrieve information from the Neo4j database by constructing
    Cypher statements.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: The older models like text-davinci-003 and GPT-3.5-turbo work better as a few-shot
    Cypher generator, where we provide a couple of Cypher examples that the model
    can use to generate new Cypher statements. However, it seems the GPT-4 works well
    when we only present the graph schema. Consequently, since graph schema can be
    extracted with a Cypher query, the GPT-4 can be theoretically used on any graph
    schema without any manual work required by a human.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: I won’t walk you through what LangChain does under the hood. We will just look
    at the function that gets executed when the LangChain agents decides to interact
    with the Neo4j database using Cypher statements.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The Cypher generating tool gets the question along with the chat history as
    input. The input to the LLM is then combined by using the **system** message,
    **chat history**, and the current question. I have prepared the following **system**
    message prompt for the Cypher generating tool.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Prompt engineering feels more like art than science. In this example, we provide
    the LLM with a couple of Cypher statement examples and let it generate Cypher
    statements based on that information. Additionally, we place a couple of constraints,
    like allowing it to construct only Cypher statements that could be inferred from
    training examples. Additionally, we don’t let the model apologize or explain its
    thoughts (however, GPT-3.5-turbo won’t listen to that instructions). Finally,
    if the question lacks context, we allow the model to respond with that information
    instead of forcing it to generate Cypher statements.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程感觉更像是一门艺术而非科学。在这个示例中，我们给 LLM 提供了几个 Cypher 语句示例，让它基于这些信息生成 Cypher 语句。此外，我们设置了一些约束，比如只允许构造可以从训练示例中推断出的
    Cypher 语句。此外，我们不让模型道歉或解释它的想法（不过，GPT-3.5-turbo 不会听从这些指令）。最后，如果问题缺乏上下文，我们允许模型用这些信息进行回答，而不是强迫它生成
    Cypher 语句。
- en: After the LLM construct a Cypher statements, we simply use it to query a Neo4j
    database, and return the results to the Agent. Here is an example flow.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 构建 Cypher 语句后，我们简单地使用它查询 Neo4j 数据库，并将结果返回给代理。这里是一个示例流程。
- en: '![](../Images/d1b1003ba12bf55aa2646189c90598a5.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d1b1003ba12bf55aa2646189c90598a5.png)'
- en: Flow of the agent using a Cypher generating tool. Image by the author.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Cypher 生成工具的代理流程。图片由作者提供。
- en: When a user inputs their question, it gets sent to an LLM along with the agent
    prompt. In this example, the LLM responds that it needs to use the **Cypher search**
    tool. The Cypher search tool constructs a Cypher statement and uses it to query
    Neo4j. The results of the query are then passed back to the agent. Next, the agent
    sends another request to an LLM along with the new context. As the context contains
    the needed information to construct an answer, the LLM forms the final answer
    and instructs the agent to return it to the user.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户输入问题时，它会连同代理提示一起发送到 LLM。在这个示例中，LLM 反应说它需要使用**Cypher 搜索**工具。Cypher 搜索工具构造一个
    Cypher 语句并用它来查询 Neo4j。查询结果随后传递回代理。接着，代理将另一个请求连同新上下文发送到 LLM。由于上下文包含构造答案所需的信息，LLM
    形成最终答案并指示代理将其返回给用户。
- en: Of course, we can now ask follow up questions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们现在可以提出后续问题。
- en: '![](../Images/dd80db68f71b28fd477cb57d6e86231a.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dd80db68f71b28fd477cb57d6e86231a.png)'
- en: Follow up question. Image by the author.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 后续问题。图片由作者提供。
- en: Since the agent has memory, it is aware of who is the second actor and, therefore,
    can pass the information along to the Cypher search tool to construct appropriate
    Cypher statements.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代理具有记忆，它知道第二个参与者是谁，因此可以将信息传递给 Cypher 搜索工具，以构造合适的 Cypher 语句。
- en: Keyword search of relevant triples
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关三元组的关键词搜索
- en: I got the idea for keyword search from existing knowledge graph index implementations
    in both [LangChain](https://python.langchain.com/en/latest/modules/chains/index_examples/graph_qa.html?highlight=graph)
    and [GPT-index libraries](https://gpt-index.readthedocs.io/en/latest/reference/indices/kg_query.html).
    Both implementations are fairly similar. They ask an LLM to extract relevant entities
    from a question and search the graph for any triples that contain those entities.
    So I figured we could do something similar with Neo4j. However, while we could
    search for entities with a simple **MATCH** statement, I have decided that using
    Neo4j’s full-text index would be better. After relevant entities are found using
    the full-text index, we return the triples and hope the relevant information to
    answer the question is there.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我从现有的知识图谱索引实现中获得了关键词搜索的想法，这些实现包括 [LangChain](https://python.langchain.com/en/latest/modules/chains/index_examples/graph_qa.html?highlight=graph)
    和 [GPT-index libraries](https://gpt-index.readthedocs.io/en/latest/reference/indices/kg_query.html)。这两种实现相当相似。它们要求
    LLM 从问题中提取相关实体，并在图中搜索包含这些实体的三元组。因此，我认为我们可以在 Neo4j 中做类似的事情。然而，尽管我们可以使用简单的 **MATCH**
    语句搜索实体，但我决定使用 Neo4j 的全文索引会更好。在使用全文索引找到相关实体后，我们返回三元组，并希望那里有回答问题的相关信息。
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Remember, the agent has instructions to parse out relevant movie titles already
    and use that as input to the Keyword search tool. Therefore, we don’t have to
    deal with that. However, since multiple entities could exist in the question,
    we must construct appropriate Lucene query parameters as the full-text index is
    based on Lucene. Then, we simply query the full-text index and return hopefully
    relevant triples. The Cypher statement we use is the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，代理程序已经有指示来解析出相关的电影标题并将其作为输入传递给关键词搜索工具。因此，我们不需要处理这个问题。然而，由于问题中可能存在多个实体，我们必须构造适当的
    Lucene 查询参数，因为全文索引是基于 Lucene 的。然后，我们只需查询全文索引，并希望返回相关的三元组。我们使用的 Cypher 语句如下：
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So, we take the top five relevant entities returned by the full-text index.
    Next, we generate triples by traversing to their neighbors. I have specifically
    excluded the **RATED** relationships from being traversed because they contain
    irrelevant information. I haven’t explored it, but I have a good feeling we could
    also instruct the LLM to provide a list of relevant relationships to be investigated
    along with the appropriate entities, which would make our keyword search more
    focused. The keyword search can be initiated by explicitly instructing the agent.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们从全文索引中提取出前五个相关实体。接下来，我们通过遍历它们的邻居来生成三元组。我特别排除了**RATED** 关系，因为它们包含无关的信息。我没有进一步探索，但我有一种好感觉，我们还可以指示
    LLM 提供一个待调查的相关关系列表以及适当的实体，这将使我们的关键词搜索更加集中。关键词搜索可以通过明确指示代理程序来启动。
- en: '![](../Images/56fabe719ae3f80dcaaab4b30fd7d113.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56fabe719ae3f80dcaaab4b30fd7d113.png)'
- en: Keyword search flow. Image by the author.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词搜索流程。作者提供的图片。
- en: The LLM is instructed to use the **keyword search** tool. Additionally, the
    agent is told to provide the keywords search a list of relevant entities as input,
    which is only **Pokemon** in this example. The Lucene parameter is then used to
    query Neo4j. This approach casts a broader net and hopes the extracted triples
    contain relevant information. For example, the retrieved context includes information
    on the genre of Pokemon, which is irrelevant. Still, it also has information about
    who acted in the movie, which allows the agent to answer the user’s question.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 被指示使用**关键词搜索**工具。此外，代理程序被告知向关键词搜索工具提供一个相关实体列表作为输入，在这个例子中只有**Pokemon**。然后使用
    Lucene 参数查询 Neo4j。这种方法撒网更广，希望提取的三元组包含相关信息。例如，检索到的上下文包括关于 Pokemon 类型的信息，这些信息并不相关。但它也包含有关谁参演了电影的信息，这使代理程序能够回答用户的问题。
- en: '*As mentioned, we could instruct the LLM to produce a list of relevant relationship
    types along with appropriate entities, which could help the agent retrieve more
    relevant information.*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*如前所述，我们可以指示 LLM 生成一个相关关系类型的列表以及适当的实体，这可以帮助代理程序检索到更相关的信息。*'
- en: Vector similarity search
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量相似度搜索
- en: The vector similarity search is the last mode to interact with a Neo4j database
    we will examine. Vector search is trendy at the moment. For example, LangChain
    offers [integrations with more than ten vector databases](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html).
    Additionally, Neo4j has [added a vector index in their version 5.11](https://neo4j.com/blog/vector-search-deeper-insights/),
    which we will be using in this example. The idea behind vector similarity search
    is to embed a question into embedding space and find relevant documents based
    on the similarity of the embeddings of the question and documents. We only need
    to be careful to use the same embedding model to produce the vector representation
    of documents and the question. I have used the OpenAI’s embeddings in the vector
    search implementation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 向量相似度搜索是我们将要检查的与 Neo4j 数据库交互的最后一种模式。向量搜索目前非常流行。例如，LangChain 提供了[与十多个向量数据库的集成](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html)。此外，Neo4j
    在其 5.11 版本中[增加了一个向量索引](https://neo4j.com/blog/vector-search-deeper-insights/)，我们将在这个例子中使用。向量相似度搜索的核心思想是将问题嵌入到嵌入空间中，并根据问题和文档嵌入的相似性来查找相关文档。我们只需要小心使用相同的嵌入模型来生成文档和问题的向量表示。我在向量搜索实现中使用了
    OpenAI 的嵌入。
- en: '[PRE10]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'So, the first thing we do is embed the question. Next, we use the embedding
    to find relevant movies in the database. Usually, the vector databases return
    the text of a relevant document. However, we are dealing with a graph database.
    Therefore, I have decided to produce relevant information using the triple structure.
    The Cypher statement used is:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们做的第一件事是将问题嵌入。接下来，我们使用嵌入在数据库中查找相关电影。通常，向量数据库会返回相关文档的文本。然而，我们处理的是图数据库。因此，我决定使用三元组结构生成相关信息。使用的
    Cypher 语句是：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The Cypher statement is similar to the keyword search example. The only difference
    is that we use vector index instead of a full-text index to identify relevant
    movies.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Cypher 语句类似于关键字搜索示例。唯一的区别是我们使用向量索引，而不是全文索引来识别相关电影。
- en: '![](../Images/670b64f57b90aa96243df90b31c1dc60.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/670b64f57b90aa96243df90b31c1dc60.png)'
- en: Vector search flow. Image by the author.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索流程。图片由作者提供。
- en: When an agent is instructed to use the **vector search** tool, the first step
    is to embed the question as a vector. The OpenAI’s embedding model produces vector
    representations with a dimension of 1536\. So, the next step is to use the constructed
    vector and search for relevant information in the database using the vector index.
    Again, since we are dealing with a graph database, I have decided to return the
    information to the agent in the form of a triple.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当指示一个代理使用**向量搜索**工具时，第一步是将问题嵌入为一个向量。OpenAI 的嵌入模型生成的向量表示的维度为 1536。因此，下一步是使用构建的向量，并通过向量索引在数据库中搜索相关信息。同样，由于我们处理的是图数据库，我决定将信息以三元组的形式返回给代理。
- en: What is interesting about vector search is that even though we instructed the
    agent to search for the **Lord of the Ring** movies, the vector similarity search
    also returned information about the **Hobbit** movies. It looks like that Lord
    of the Ring and Hobbit movies are close in the embedded space, which is understandable.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 向量搜索有趣之处在于，即使我们指示代理搜索**指环王**系列电影，向量相似性搜索也返回了**霍比特人**系列电影的信息。这看起来指环王和霍比特人电影在嵌入空间中是接近的，这也是可以理解的。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: It looks like chatbots and generative agents that can access external tools
    and information are the next wave that follows the original ChatGPT hype. Having
    the ability to provide additional context to an LLM can greatly improve its results.
    Additionally, the agent’s tools are not restricted to read-only operations, which
    means they can update a database or even make orders on Amazon. For the most part,
    it seems that the LangChain library is the primary library at the moment to be
    used to implement generative agents. When you start using LangChain, you might
    need a bit of a shift in the coding process, as you need to combine LLM prompts
    with code to complete tasks. For example, messages between LLMs and tools can
    be shaped and reshaped with natural language instructions as prompts instead of
    Python code. I hope this project will help you implement the capabilities of a
    graph database like Neo4j into your LangChain project.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来，能够访问外部工具和信息的聊天机器人和生成代理是继原始 ChatGPT 热潮之后的下一个浪潮。具备为大型语言模型提供额外上下文的能力可以大大改善其结果。此外，代理的工具不仅限于只读操作，这意味着它们可以更新数据库甚至在亚马逊上下订单。大部分时间，LangChain
    库似乎是目前用于实现生成代理的主要库。当你开始使用 LangChain 时，你可能需要稍微调整编码过程，因为你需要将大型语言模型提示与代码结合起来完成任务。例如，LLM
    与工具之间的消息可以通过自然语言指令作为提示进行塑造和重塑，而不是 Python 代码。我希望这个项目能帮助你将像 Neo4j 这样的图数据库的功能融入到你的
    LangChain 项目中。
- en: As always, the code is available on [GitHub](https://github.com/tomasonjo/langchain2neo4j).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，代码可以在 [GitHub](https://github.com/tomasonjo/langchain2neo4j) 上找到。
- en: References
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] *F. Maxwell Harper and Joseph A. Konstan. 2015\. The MovieLens Datasets:
    History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS)
    5, 4: 19:1–19:19\.* [*https://doi.org/10.1145/2827872*](https://doi.org/10.1145/2827872)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] *F. Maxwell Harper 和 Joseph A. Konstan. 2015\. The MovieLens 数据集：历史与背景。ACM
    交互式智能系统交易（TiiS）5, 4: 19:1–19:19\.* [*https://doi.org/10.1145/2827872*](https://doi.org/10.1145/2827872)'
