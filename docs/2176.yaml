- en: 'Empowering Fairness: Recognizing and Addressing Bias in Generative Models'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/empowering-fairness-recognizing-and-addressing-bias-in-generative-models-1723ce3973aa?source=collection_archive---------11-----------------------#2023-07-06](https://towardsdatascience.com/empowering-fairness-recognizing-and-addressing-bias-in-generative-models-1723ce3973aa?source=collection_archive---------11-----------------------#2023-07-06)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With the integration of AI into our everyday lives, a biased model can have
    drastic consequences on users
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@kevin.berlemont?source=post_page-----1723ce3973aa--------------------------------)[![Kevin
    Berlemont, PhD](../Images/18697f38b76f1fb04870f565cfb04b4c.png)](https://medium.com/@kevin.berlemont?source=post_page-----1723ce3973aa--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1723ce3973aa--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1723ce3973aa--------------------------------)
    [Kevin Berlemont, PhD](https://medium.com/@kevin.berlemont?source=post_page-----1723ce3973aa--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F3dea771eb493&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fempowering-fairness-recognizing-and-addressing-bias-in-generative-models-1723ce3973aa&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=post_page-3dea771eb493----1723ce3973aa---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1723ce3973aa--------------------------------)
    ·6 min read·Jul 6, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1723ce3973aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fempowering-fairness-recognizing-and-addressing-bias-in-generative-models-1723ce3973aa&user=Kevin+Berlemont%2C+PhD&userId=3dea771eb493&source=-----1723ce3973aa---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1723ce3973aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fempowering-fairness-recognizing-and-addressing-bias-in-generative-models-1723ce3973aa&source=-----1723ce3973aa---------------------bookmark_footer-----------)![](../Images/49c317d74bb76b8a63d74a410f64cb29.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Dainis Graveris](https://unsplash.com/@dainisgraveris?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In 2021, Princeton University’s Center for Information Technology Policy released
    a report where they found that machine learning algorithms can pick up biases
    similar to those of humans from their training data. One striking example of this
    effect is a study about the AI hiring tool from Amazon **[1]**. The tool was trained
    on resumes submitted to Amazon during the previous year and was ranking the different
    candidates. Due to the huge gender imbalance in tech positions over the past decade,
    the algorithm had learned language that would associate to women, such as women’s
    sport teams and would downgrade the rank of such resumes. This example highlights
    the necessity of not only fair and accurate models but datasets too, to remove
    bias during training. In the current context of the fast development of generative
    models such as ChatGPT and the integration of AI into our everyday lives, a biased
    model can have drastic consequences and erode the trust of users and global acceptance.
    Addressing these biases is thus necessary from a business perspective and Data
    Scientists (in a broad definition) have to be aware of them to mitigate them and
    make sure they…
  prefs: []
  type: TYPE_NORMAL
