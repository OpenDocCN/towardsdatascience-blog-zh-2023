- en: Deploying Multiple Models with SageMaker Pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/deploying-multiple-models-with-sagemaker-pipelines-fb7363094c50?source=collection_archive---------7-----------------------#2023-03-23](https://towardsdatascience.com/deploying-multiple-models-with-sagemaker-pipelines-fb7363094c50?source=collection_archive---------7-----------------------#2023-03-23)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Applying MLOps best practices to advanced serving options
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)[![Ram
    Vegiraju](../Images/07d9334e905f710d9f3c6187cf69a1a5.png)](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)
    [Ram Vegiraju](https://ram-vegiraju.medium.com/?source=post_page-----fb7363094c50--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6e49569edd2b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-multiple-models-with-sagemaker-pipelines-fb7363094c50&user=Ram+Vegiraju&userId=6e49569edd2b&source=post_page-6e49569edd2b----fb7363094c50---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb7363094c50--------------------------------)
    ·8 min read·Mar 23, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb7363094c50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-multiple-models-with-sagemaker-pipelines-fb7363094c50&user=Ram+Vegiraju&userId=6e49569edd2b&source=-----fb7363094c50---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb7363094c50&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdeploying-multiple-models-with-sagemaker-pipelines-fb7363094c50&source=-----fb7363094c50---------------------bookmark_footer-----------)![](../Images/c86ec39899ba0ad0ba89fd4df2d483db.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image from [Unsplash](https://unsplash.com/photos/f7uCQxhucw4) by [Growtika](https://unsplash.com/@growtika)
  prefs: []
  type: TYPE_NORMAL
- en: MLOps is an essential practice to productionizing your Machine Learning workflows.
    With MLOps you can establish workflows that are catered for the ML lifecycle.
    These make it easier to centrally maintain resources, update/track models, and
    in general simplify the process as your ML experimentation scales up.
  prefs: []
  type: TYPE_NORMAL
- en: A key MLOps tool within the [Amazon SageMaker](https://aws.amazon.com/sagemaker/)
    ecosystem is [SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/).
    With SageMaker Pipelines you can define workflows that are composed of different
    defined ML **steps**. You can also structure these workflows by defining **parameters**
    that you can inject as variables into your Pipeline. For a more general introduction
    to SageMaker Pipelines, please refer to the [linked article](/an-introduction-to-sagemaker-pipelines-4018a819352d).
  prefs: []
  type: TYPE_NORMAL
- en: Defining a Pipeline in itself is not heavily complicated, but there’s a few
    advanced use-cases that need some extra configuring. Specifically, say that you
    are training multiple models that are needed for inference in your ML use-case.
    Within SageMaker there is a hosting option known as [Multi-Model Endpoints](https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html)
    (MME) where you can host several models on a singular endpoint and invoke a target
    model. However, within SageMaker Pipelines there’s no native support for defining
    or deploying a MME natively at the moment. In this blog post…
  prefs: []
  type: TYPE_NORMAL
