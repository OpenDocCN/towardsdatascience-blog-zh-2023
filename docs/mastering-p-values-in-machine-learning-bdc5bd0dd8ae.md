# 掌握机器学习中的 P 值

> 原文：[`towardsdatascience.com/mastering-p-values-in-machine-learning-bdc5bd0dd8ae`](https://towardsdatascience.com/mastering-p-values-in-machine-learning-bdc5bd0dd8ae)

## 理解 P 值和机器学习的应用场景

[](https://spierre91.medium.com/?source=post_page-----bdc5bd0dd8ae--------------------------------)![Sadrach Pierre, Ph.D.](https://spierre91.medium.com/?source=post_page-----bdc5bd0dd8ae--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bdc5bd0dd8ae--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----bdc5bd0dd8ae--------------------------------) [Sadrach Pierre, Ph.D.](https://spierre91.medium.com/?source=post_page-----bdc5bd0dd8ae--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bdc5bd0dd8ae--------------------------------) ·7 分钟阅读·2023 年 1 月 6 日

--

![](img/136a6ff1e3460e47037dfa4e55d94e19.png)

图片由 [Karolina Grabowska](https://www.pexels.com/@karolina-grabowska/) 提供，来自 [Pexels](https://www.pexels.com/photo/heart-shaped-gummy-candy-assorted-in-rows-with-one-candy-aside-against-pink-background-4016522/)

P 值是一个统计指标，帮助统计学家决定是否接受或拒绝原假设。P 值衡量的是变量之间没有关系的概率。低 P 值提供了反对原假设的证据。P 值常常被误解。例如，这常使人错误地认为低 P 值意味着变量之间*存在*关系。声称存在关系与声称拒绝或接受没有关系是有些不同的。P 值仅提供支持或反对原假设的证据。具体来说，P 值 < 0.05 是好的。P 值 < 0.05 意味着变量之间没有关系的概率为 5%。此外，小的 P 值可以解释为观察到的效果很小的概率是由于偶然因素。

例如，如果一家制药公司在临床试验中测试一种新药，可能会观察到该药物对治疗特定疾病的症状有效。尽管有这些观察结果，但药物效果可能是由于偶然因素，而药物实际上可能无效。为了得出观察结果不是偶然的、代表真实效果的结论，可以使用 P 值来衡量观察结果由于随机偶然的概率。

p 值传统上用于许多统计技术，包括方差分析（ANOVA）、t 检验和回归。除了传统技术之外，虽然较少见，但在构建机器学习模型时也可以使用 p 值来检验假设。根据我的经验，作为数据科学家，p 值的必要性存在于传统统计方法与机器学习之间的边界。例如，线性回归和逻辑回归等回归技术通常需要计算回归系数的 p 值。线性回归和逻辑回归都被统计学家和数据科学家使用。另一个例子是特征选择。p 值可用于测试特征选择技术，包括 ANOVA（传统统计方法）和基于树的特征选择（数据科学/机器学习方法）。此外，p 值还可用于评估机器学习预测和特征重要性计算中的置信水平。具体来说，p 值可以用来确定两个模型之间的性能差异是否具有统计学意义。

另一个值得注意的区别是推断（传统统计学）与预测（机器学习）之间的差异。由于这种区别，人们通常认为在机器学习中，p 值是不必要的。在推断统计中，重点通常是关系背后的理论，而在机器学习中，重点则更多是准确预测未见数据。推断统计采用诸如 p 值、R2 和 F 统计量等指标来进行模型验证。机器学习模型则需要交叉验证和样本外测试来进行模型验证。

为了进一步理解这种区别，让我们考虑之前的药物示例。在**统计推断**的背景下，我们希望能够有统计证据来反对“药物 X 对治疗疾病 Y 无效”这一说法。在**机器学习**中，我们则更感兴趣的是使用预测来筛选潜在药物目录，并将其标记为有效或无效。前者更多的是**验证关于关系的主张**，而后者则是**验证你能多好地预测**未见数据。尽管存在这些区别，但数据科学家仍然有充分的理由考虑理解和使用 p 值，而统计学家也应考虑使用可能需要或不需要 p 值的非参数机器学习模型。

虽然 p 值在自然科学和社会科学中都有应用，但它们也有其局限性。最近，p 值的局限性成为数据科学家和统计学家讨论的热门话题。例如，p 值并不能衡量效应大小、重要性，甚至不能确定效应是否百分之百真实。它更多是用来支持声明，而不是将声明确立为真。尽管如此，数据科学家应该理解它们在传统统计中的地位，以及它们如何与机器学习结合使用。

在这里，我们将讲解如何计算线性和逻辑回归模型中系数的 p 值。我们将讨论如何计算机器学习预测的 p 值。我们可以使用 p 值将新模型与基准模型进行比较，并比较不同 ML 算法的性能。

对于这项工作，我将使用 [Deepnote](https://deepnote.com/) 编写代码，这是一个协作数据科学笔记本，使运行可重复的实验变得非常简单。

对于我们的回归模型，我们将使用 [医疗费用数据集](https://www.kaggle.com/datasets/mirichoi0218/insurance)。我们将使用患者的年龄、体质指数和孩子数等属性来预测医疗费用。数据可以免费使用、修改和共享，遵循 [数据库内容许可](https://opendatacommons.org/licenses/dbcl/1-0/) (DbCL: 公共领域)。

对于我们的分类模型，我们将使用虚构的 [Telco Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) 数据集，该数据集在 Kaggle 上公开提供。数据集可以免费使用、修改和共享，遵循 [Apache 2.0 许可](https://www.apache.org/licenses/LICENSE-2.0)。

## 添加数据集

首先，让我们导航到 Deepnote 并创建一个新项目（如果你还没有账户，可以免费注册）。

让我们创建一个名为 ‘p_values’ 的项目，并在该项目中创建一个名为 ‘p_values_ml’ 的笔记本。同时，让我们将 insurance.csv 和 telco_churn.csv 文件拖放到页面左侧面板上标有 ‘FILES’ 的位置：

![](img/a63144c4297e8f50f94e542fc9389baa.png)

作者截图

## 线性回归系数的 p 值

我们将使用 p 值来测试以下内容：

***备择假设 (H1):*** 特征年龄、BMI 和孩子数对预测成本很重要。

***原假设 (H0)***: 特征年龄、BMI 和孩子数与成本没有关系。

我们将首先在 Python 中安装 stats 模块。这将使我们能够计算线性模型的 p 值，因为 Scikit-learn 不提供模型系数的 p 值。

作者创建的嵌入

接下来，让我们导入 Pandas 库，将保险数据读入 Pandas 数据框，并显示前五行：

作者创建的嵌入

接下来，让我们定义输入。我们将输入定义为年龄、BMI 和孩子数量，输出定义为费用。我们还将数据分为训练和测试集：

由作者创建的嵌入

接下来，让我们导入 stats 模型 API，并将我们的模型拟合到训练数据中。结果是一个总结我们模型的统计指标的表格。这里我们只对 P 值列感兴趣，但它还提供了其他指标，如 R 平方、t 检验和标准误差：

由作者创建的嵌入

我们看到年龄、BMI 和孩子数量的 P 值均小于 0.05。由此，我们有证据反对零假设，该假设表明输入和输出之间没有关系。

## 逻辑回归系数的 P 值

我们将使用 P 值测试以下内容：

***替代假设 (H1):*** 特征 tenure、monthly charges 和 tenure_squared 对预测流失很重要。

***零假设 (H0)***: 特征 tenure、monthly charges 和 tenure_squared 与流失没有关系。

我们可以对逻辑回归模型做类似的操作。让我们将流失数据读入数据框，生成编码的流失标签，并显示前五行：

由作者创建的嵌入

我们将输入定义为 tenure 和 monthly charges。我们还将计算每个特征的平方，并将其用作模型输入。输出将是流失列。我们还将数据分为训练和测试集：

由作者创建的嵌入

我们可以训练我们的逻辑回归模型并打印总结：

由作者创建的嵌入

P 值<0.05 提供了拒绝零假设的证据（输入与输出之间没有关系）。

## 比较随机森林回归模型的 P 值

***替代假设 (H1):*** 模型性能存在实际差异。

***零假设 (H0)***: 模型性能没有差异。

假设我们想比较两个随机森林回归模型。我们可以使用 P 值来提供拒绝零假设的证据。在这里，零假设是模型性能在两个模型之间没有差异。我们用默认的随机森林参数构建一个模型，再用`n_estimators =5`和`max_depth =5`构建第二个模型。然后，我们对测试集进行预测：

由作者创建的嵌入

接下来，我们需要安装[mlxtend](https://rasbt.github.io/mlxtend/)包。这将允许我们比较模型性能：

由作者创建的嵌入

接下来，让我们使用[paired_ttest_5x2cv](http://rasbt.github.io/mlxtend/user_guide/evaluate/paired_ttest_5x2cv/)方法生成我们的 P 值。我们传递两个估计器及其参数值，以及训练数据：

由作者创建的嵌入

我们看到在这里没有证据可以拒绝零假设。这意味着模型性能的差异可能是偶然的。

## 比较不同机器学习算法的 P 值

让我们将随机森林模型（使用默认参数）与线性回归模型进行比较：

由作者创建的嵌入

我们看到这里有证据拒绝原假设，因为 p <0.05。这意味着模型性能差异不太可能是偶然的。

本文中的代码可在[GitHub](https://github.com/spierre91/deepnote/blob/main/p_values_ml.ipynb)上找到。

## 结论

在本文中，我们讨论了如何将 p 值应用于机器学习用例。首先，我们研究了如何生成线性回归系数的 p 值。接着，我们讨论了如何生成逻辑回归的 p 值。随后，我们考虑了更现代的机器学习应用。我们展示了如何生成 p 值，以确定两个随机森林模型之间的性能差异是否显著。最后，我们使用 p 值来比较不同的机器学习算法类型。具体来说，我们计算了 p 值来比较随机森林和线性回归模型。
