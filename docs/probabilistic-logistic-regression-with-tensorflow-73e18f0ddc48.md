# ä½¿ç”¨ TensorFlow è¿›è¡Œæ¦‚ç‡é€»è¾‘å›å½’

> åŸæ–‡ï¼š[`towardsdatascience.com/probabilistic-logistic-regression-with-tensorflow-73e18f0ddc48`](https://towardsdatascience.com/probabilistic-logistic-regression-with-tensorflow-73e18f0ddc48)

## æ¦‚ç‡æ·±åº¦å­¦ä¹ 

[](https://medium.com/@luisroque?source=post_page-----73e18f0ddc48--------------------------------)![LuÃ­s Roque](https://medium.com/@luisroque?source=post_page-----73e18f0ddc48--------------------------------)[](https://towardsdatascience.com/?source=post_page-----73e18f0ddc48--------------------------------)![æ•°æ®ç§‘å­¦å‰æ²¿](https://towardsdatascience.com/?source=post_page-----73e18f0ddc48--------------------------------) [LuÃ­s Roque](https://medium.com/@luisroque?source=post_page-----73e18f0ddc48--------------------------------)

Â·å‘è¡¨äº [æ•°æ®ç§‘å­¦å‰æ²¿](https://towardsdatascience.com/?source=post_page-----73e18f0ddc48--------------------------------) Â·é˜…è¯»æ—¶é—´ 9 åˆ†é’ŸÂ·2023 å¹´ 1 æœˆ 25 æ—¥

--

# ä»‹ç»

æœ¬æ–‡å±äºâ€œæ¦‚ç‡æ·±åº¦å­¦ä¹ â€ç³»åˆ—ã€‚è¯¥ç³»åˆ—æ¯å‘¨ä»‹ç»æ·±åº¦å­¦ä¹ ä¸­çš„æ¦‚ç‡æ–¹æ³•ã€‚ä¸»è¦ç›®æ ‡æ˜¯æ‰©å±•æ·±åº¦å­¦ä¹ æ¨¡å‹ä»¥é‡åŒ–ä¸ç¡®å®šæ€§ï¼Œå³äº†è§£å®ƒä»¬ä¸çŸ¥é“çš„å†…å®¹ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»æ¦‚ç‡é€»è¾‘å›å½’çš„æ¦‚å¿µï¼Œè¿™æ˜¯ä¸€ç§å¼ºå¤§çš„æŠ€æœ¯ï¼Œå…è®¸åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­çº³å…¥ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬å°†æ¢è®¨è¿™ç§æ–¹æ³•å¦‚ä½•åœ¨æ•°æ®å™ªå£°å¤§æˆ–æ¨¡å‹è¿‡æ‹Ÿåˆçš„æƒ…å†µä¸‹æä¾›æ›´ç¨³å¥å’Œå‡†ç¡®çš„é¢„æµ‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨æ¨¡å‹å‚æ•°ä¸Šå¼•å…¥å…ˆéªŒåˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ¨¡å‹è¿›è¡Œæ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚è¿™ç§æ–¹æ³•æ˜¯è¿›å…¥è´å¶æ–¯æ·±åº¦å­¦ä¹ æ¿€åŠ¨äººå¿ƒçš„ä¸–ç•Œçš„ç»ä½³èµ·ç‚¹ã€‚

å·²å‘å¸ƒçš„æ–‡ç« ï¼š

1.  [TensorFlow Probability è½»æ¾å…¥é—¨ï¼šåˆ†å¸ƒå¯¹è±¡](https://medium.com/towards-data-science/gentle-introduction-to-tensorflow-probability-distribution-objects-1bb6165abee1)

1.  [TensorFlow Probability è½»æ¾å…¥é—¨ï¼šå¯è®­ç»ƒå‚æ•°](https://medium.com/towards-data-science/gentle-introduction-to-tensorflow-probability-trainable-parameters-5098ea4fed15)

1.  ä»é›¶å¼€å§‹çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡åœ¨ TensorFlow Probability ä¸­

1.  ä»é›¶å¼€å§‹çš„ TensorFlow æ¦‚ç‡çº¿æ€§å›å½’

1.  [Tensorflow ä¸­çš„æ¦‚ç‡å›å½’ä¸ç¡®å®šæ€§å›å½’](https://medium.com/towards-data-science/probabilistic-vs-deterministic-regression-with-tensorflow-85ef791beeef)

1.  [é¢‘ç‡å­¦æ´¾ä¸è´å¶æ–¯ç»Ÿè®¡å­¦åœ¨ Tensorflow ä¸­çš„å¯¹æ¯”](https://medium.com/towards-data-science/frequentist-vs-bayesian-statistics-with-tensorflow-fbba2c6c9ae5)

1.  ç¡®å®šæ€§ä¸æ¦‚ç‡æ·±åº¦å­¦ä¹ 

1.  ä»å¤´å¼€å§‹ä½¿ç”¨ TensorFlow å®ç°æœ´ç´ è´å¶æ–¯

1.  ä½¿ç”¨ TensorFlow è¿›è¡Œ**æ¦‚ç‡é€»è¾‘å›å½’**

![](img/93f68e2e7ac8cbc8894c52dd44805819.png)

å›¾ 1ï¼šä»Šå¤©çš„åº§å³é“­ï¼šç›´çº¿å¯ä»¥åˆ†éš”æ›´å¤šçš„äº‹ç‰©ï¼Œæ¯”æˆ‘ä»¬æƒ³è±¡çš„è¦å¤š ([source](https://unsplash.com/photos/lIdS6_XiAR0))

ä¸å¾€å¸¸ä¸€æ ·ï¼Œä»£ç å¯ä»¥åœ¨æˆ‘çš„ [GitHub](https://github.com/luisroque/probabilistic_deep_learning_with_TFP) ä¸Šæ‰¾åˆ°ã€‚

# åˆæ­¥å·¥ä½œ

åœ¨æˆ‘ä»¬ç³»åˆ—æ–‡ç« çš„å‰ä¸€ç¯‡ä¸­ï¼Œæˆ‘ä»¬ä»å¤´å¼€å§‹æ„å»ºäº†æœ´ç´ è´å¶æ–¯ç®—æ³•ï¼Œå¹¶ä½¿ç”¨å®ƒæ ¹æ®é€‰æ‹©çš„ç‰¹å¾å¯¹è‘¡è„é…’æ ·æœ¬è¿›è¡Œåˆ†ç±»ã€‚è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**æ¦‚ç‡é€»è¾‘å›å½’**æ–¹æ³•ã€‚ç”±äºæˆ‘ä»¬å·²ç»é‡‡ç”¨äº†ç«¯åˆ°ç«¯çš„æ–¹æ³•ï¼Œæˆ‘å°†è·³è¿‡å¤§éƒ¨åˆ†æ¢ç´¢æ€§æ•°æ®åˆ†æéƒ¨åˆ†å’Œç±»å…ˆéªŒåˆ†å¸ƒå®šä¹‰ã€‚

å”¯ä¸€éœ€è¦æ³¨æ„çš„æ˜¯æˆ‘ä»¬ä¸ºæ­¤æ¨¡å‹é€‰æ‹©çš„ç‰¹å¾æœ‰æ‰€ä¸åŒã€‚

![](img/a2e8b7b5c2fe0281cf88364c78545fd9.png)

å›¾ 2ï¼šæ ¹æ®é…’ç²¾å’Œè‰²è°ƒçš„ç›®æ ‡æ ·æœ¬åˆ†å¸ƒã€‚

æˆ‘ä»¬å°†ä½¿ç”¨è‰²è°ƒå’Œç±»é»„é…®ä½œä¸ºè‡ªå˜é‡ã€‚æ³¨æ„è¿™äº›ç‰¹å¾åœ¨åˆ†éš”ç›®æ ‡å˜é‡æ–¹é¢æ¯”é…’ç²¾å’Œè‰²è°ƒæ›´æœ‰æ•ˆã€‚

![](img/e7bfa9bd6d04e51dfc8d656ea2f977cf.png)

å›¾ 3ï¼šæ ¹æ®ç±»é»„é…®å’Œè‰²è°ƒçš„ç›®æ ‡æ ·æœ¬åˆ†å¸ƒã€‚

# **æ¦‚ç‡é€»è¾‘å›å½’**

é€»è¾‘å›å½’æ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„äºŒå…ƒåˆ†ç±»ç»Ÿè®¡æ–¹æ³•ï¼Œç”¨äºå»ºæ¨¡äºŒå…ƒå“åº”å˜é‡ä¸ä¸€ä¸ªæˆ–å¤šä¸ªé¢„æµ‹å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚é€»è¾‘å›å½’å¯ä»¥ç”¨æ¥å»ºæ¨¡äºŒå…ƒç»“æœçš„æ¦‚ç‡ä½œä¸ºé¢„æµ‹å˜é‡çš„å‡½æ•°ã€‚ä¼ ç»Ÿçš„é€»è¾‘å›å½’æ¨¡å‹æ˜¯ä¸€ä¸ªç¡®å®šæ€§æ¨¡å‹ï¼Œå‡è®¾é¢„æµ‹å˜é‡ä¸å“åº”å˜é‡ä¹‹é—´çš„å…³ç³»æ˜¯å›ºå®šä¸”å·²çŸ¥çš„ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šå®é™…åº”ç”¨ä¸­ï¼Œé¢„æµ‹å˜é‡ä¸å“åº”å˜é‡ä¹‹é—´çš„çœŸå®å…³ç³»æ˜¯ä¸ç¡®å®šçš„ï¼Œå› æ­¤ä½¿ç”¨**æ¦‚ç‡æ–¹æ³•**æ›´ä¸ºåˆé€‚ã€‚

**æ¦‚ç‡é€»è¾‘å›å½’**æ¨¡å‹é€šè¿‡æ¦‚ç‡æ¡†æ¶å»ºæ¨¡é¢„æµ‹å˜é‡ä¸äºŒå…ƒå“åº”å˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶èƒ½å¤Ÿè€ƒè™‘æ•°æ®å’Œæ¨¡å‹å‚æ•°çš„ä¸ç¡®å®šæ€§ã€‚è¿™æ˜¯é€šè¿‡å¯¹æ¨¡å‹å‚æ•°æ–½åŠ æ¦‚ç‡åˆ†å¸ƒæ¥å®ç°çš„ï¼Œè€Œä¸æ˜¯å‡è®¾å›ºå®šå€¼ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä¸ä¼ ç»Ÿé€»è¾‘å›å½’æ¨¡å‹ç›¸æ¯”ï¼Œ**æ¦‚ç‡é€»è¾‘å›å½’**æ¨¡å‹å¯ä»¥æä¾›æ›´å‡†ç¡®çš„é¢„æµ‹å’Œæ›´å¥½çš„ä¸ç¡®å®šæ€§é‡åŒ–ã€‚

æœ€æµè¡Œçš„é€»è¾‘å›å½’æ¦‚ç‡æ¨¡å‹ä¹‹ä¸€æ˜¯è´å¶æ–¯é€»è¾‘å›å½’æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åŸºäºè´å¶æ–¯å®šç†ï¼Œè¯¥å®šç†æŒ‡å‡ºï¼Œç»™å®šæ•°æ®çš„æ¨¡å‹å‚æ•°çš„åéªŒæ¦‚ç‡ä¸æ•°æ®ç»™å®šå‚æ•°çš„ä¼¼ç„¶å’Œå‚æ•°çš„å…ˆéªŒæ¦‚ç‡çš„ä¹˜ç§¯æˆæ­£æ¯”ã€‚é€šå¸¸ï¼Œè´å¶æ–¯é€»è¾‘å›å½’æ¨¡å‹ä½¿ç”¨å…±è½­å…ˆéªŒåˆ†å¸ƒæ¥å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œå»ºæ¨¡ï¼Œè¿™å…è®¸å¯¹åéªŒåˆ†å¸ƒè¿›è¡Œå°é—­å½¢å¼çš„è§£æ³•ã€‚è¿™ä½¿å¾—è®¡ç®—å“åº”å˜é‡ç»™å®šé¢„æµ‹å˜é‡çš„æ¦‚ç‡æˆä¸ºå¯èƒ½ï¼Œè¿™è¢«ç§°ä¸ºåéªŒé¢„æµ‹åˆ†å¸ƒã€‚

# ä¼¼ç„¶

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åœ¨é€»è¾‘å›å½’çš„æ¦‚ç‡æ–¹æ³•ä¸­è®¡ç®—ç±»åˆ«æ¡ä»¶å¯†åº¦çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºå‡å€¼çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå…¶ç”±ä»¥ä¸‹å…¬å¼ç»™å‡º

![](img/3b98d5052f470207f04229ae1581cee8.png)

å…¶ä¸­ ğ‘‹(ğ‘›)ğ‘– æ˜¯ç¬¬ n ä¸ªæ ·æœ¬çš„ç¬¬ i ä¸ªç‰¹å¾ï¼Œğ‘Œ(ğ‘›) æ˜¯ç¬¬ n ä¸ªæ ·æœ¬çš„ç›®æ ‡æ ‡ç­¾ï¼Œğ‘˜ æ˜¯ç±»åˆ«æ ‡ç­¾ï¼Œğ›¿(ğ‘Œ(ğ‘›)=ğ‘¦ğ‘˜) æ˜¯ä¸€ä¸ªæŒ‡ç¤ºå‡½æ•°ï¼Œå¦‚æœ ğ‘Œ(ğ‘›)=ğ‘¦ğ‘˜ åˆ™ç­‰äº 1ï¼Œå¦åˆ™ä¸º 0ã€‚

ä¸ºäº†ä¼°è®¡æ ‡å‡†å·® ğœğ‘–ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä»æ•°æ®ä¸­å­¦ä¹ è¿™äº›å‚æ•°æ¥å®ç°ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å°é—­å½¢å¼çš„è§£æ³•ã€‚æˆ‘ä»¬é€šè¿‡å®ç°è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œè¯¥å¾ªç¯é€šè¿‡æœ€å°åŒ–æ•°æ®çš„å¹³å‡æ¯ä¸ªç¤ºä¾‹è´Ÿå¯¹æ•°ä¼¼ç„¶æ¥ä¼˜åŒ–æ ‡å‡†å·®çš„å€¼ã€‚

æˆ‘ä»¬çš„å‡½æ•°æ ¹æ®ä¸Šè¿°æ–¹ç¨‹è®¡ç®—ç±»åˆ«æ¡ä»¶é«˜æ–¯åˆ†å¸ƒçš„å‡å€¼ ğœ‡ğ‘–ğ‘˜ã€‚ç„¶åï¼Œå®ƒä½¿ç”¨ MultivariateNormalDiag åˆ›å»ºä¸€ä¸ªå¤šå˜é‡é«˜æ–¯åˆ†å¸ƒå¯¹è±¡ï¼Œå°†å‡å€¼è®¾ç½®ä¸º ğœ‡ğ‘–ğ‘˜ï¼Œå°†å°ºåº¦è®¾ç½®ä¸º TensorFlow å˜é‡ã€‚

è¯¥å‡½æ•°è¿è¡Œä¸€ä¸ªè‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ï¼Œå¾ªç¯æ¬¡æ•°ä¸ºæŒ‡å®šçš„çºªå…ƒï¼Œå…¶ä¸­è®¡ç®—å¹³å‡æ¯ä¸ªç¤ºä¾‹çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚æ¥ä¸‹æ¥ï¼Œæ¢¯åº¦è¢«ä¼ æ’­ï¼Œå°ºåº¦å˜é‡ç›¸åº”åœ°æ›´æ–°ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼Œå°ºåº¦å˜é‡çš„å€¼å’ŒæŸå¤±éƒ½ä¼šè¢«ä¿å­˜ã€‚

å®ƒè¿”å›ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªå¯¹è±¡çš„å…ƒç»„ï¼šæŸå¤±å€¼ã€æ¯æ¬¡è¿­ä»£çš„å°ºåº¦å˜é‡å’Œæœ€ç»ˆå­¦ä¹ åˆ°çš„æ‰¹é‡ MultivariateNormalDiag åˆ†å¸ƒå¯¹è±¡ã€‚

```py
def train(x, y, scales, optimiser, epochs):
    estimated_scales = []
    n_classes = np.unique(y).shape[0]
    n_features = x.shape[1]
    counts = np.zeros(n_classes)
    mean_cond_class = []
    std_feature_given_class = []
    for c_k in range(n_classes):
        mean_cond_class.append(np.mean(x[np.squeeze(y==c_k)], axis=0))
    mean_cond_class = np.asarray(mean_cond_class, dtype=np.float32)
    x_c = np.concatenate((x,y.reshape(-1,1)), axis=1)

    mv_normal_diag = tfd.MultivariateNormalDiag(loc=mean_cond_class,scale_diag=scales)

    x = np.expand_dims(x , 1).astype('float32')

    for i in range(epochs):
        with tf.GradientTape() as tape:
            tape.watch(mv_normal_diag.trainable_variables)
            predictions = - mv_normal_diag.log_prob(x)
            p1 = tf.reduce_sum(predictions[np.squeeze(y==0)][:,0])
            p2 = tf.reduce_sum(predictions[np.squeeze(y==1)][:,1])
            loss = p1 + p2
            grads = tape.gradient(loss, mv_normal_diag.trainable_variables)

        opt.apply_gradients(zip(grads, mv_normal_diag.trainable_variables))
        estimated_scales.append(mv_normal_diag.trainable_variables[0].numpy())
        print('Step {:03d}: Loss: {:.3f}: Scale1: {:.3f}: Scale2: {:.3f}'.format(i, loss, mv_normal_diag.trainable_variables[0].numpy()[0], mv_normal_diag.trainable_variables[0].numpy()[1]))
    estimated_scales = np.asarray(estimated_scales)
    return estimated_scales, mv_normal_diag
```

è®©æˆ‘ä»¬åˆ›å»ºè¦è®­ç»ƒçš„å˜é‡ã€‚

```py
scales = tf.Variable([1., 1.], name='scales')
opt = tf.keras.optimizers.Adam(learning_rate=0.01)
epochs = 100
```

æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¼€å§‹è®­ç»ƒè¿‡ç¨‹ã€‚

```py
scales_arr, class_conditionals_binary = train(x_train, y_train, scales, opt, epochs)

-----
Step 000: Loss: 290.708: Scale1: 0.990: Scale2: 0.990
Step 001: Loss: 288.457: Scale1: 0.980: Scale2: 0.980
Step 002: Loss: 286.196: Scale1: 0.970: Scale2: 0.970
Step 003: Loss: 283.924: Scale1: 0.960: Scale2: 0.960
Step 004: Loss: 281.641: Scale1: 0.950: Scale2: 0.950
Step 005: Loss: 279.348: Scale1: 0.940: Scale2: 0.940
[...]
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ¨¡å‹å¦‚ä½•åŒºåˆ†æˆ‘ä»¬çš„è‘¡è„é…’ç±»åˆ«ã€‚

![](img/be1367ed1a5cbbc932d24d31412fb536.png)

å›¾ 4ï¼šç±»åˆ«æ¡ä»¶å¯†åº¦è½®å»“ã€‚

ä½¿ç”¨æˆ‘ä»¬åœ¨å‰ä¸€ç¯‡æ–‡ç« ä¸­å®šä¹‰çš„å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºæµ‹è¯•é›†ç”Ÿæˆé¢„æµ‹ã€‚åœ¨ä¸Šé¢çš„å›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç±»åˆ«è¢«å¾ˆå¥½åœ°åˆ†å¼€ï¼Œå› æ­¤æˆ‘ä»¬ä»æ¨¡å‹ä¸­è·å¾—äº†è‰¯å¥½çš„å‡†ç¡®ç‡ã€‚

```py
predictions = predict(prior_binary, class_conditionals_binary, x_test)

accuracy = accuracy_score(y_test, predictions)
print("Test accuracy: {:.4f}".format(accuracy))

---------
Test accuracy: 0.92
```

ä¸ºäº†å®šé‡è¯„ä¼°æˆ‘ä»¬çš„æ¦‚ç‡é€»è¾‘å›å½’æ¨¡å‹çš„æ€§èƒ½ï¼Œæˆ‘ä»¬ç»˜åˆ¶äº†å†³ç­–åŒºåŸŸã€‚è¿™äº›åŒºåŸŸç”±åˆ†éš”ä¸¤ä¸ªç±»åˆ«çš„è¾¹ç•Œå®šä¹‰ï¼Œä¸ºæ¨¡å‹åŒºåˆ†ç±»åˆ«çš„èƒ½åŠ›æä¾›äº†è§è§£ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ†éš”æ•°æ®é›†ä¸­çš„ä¸¤ä¸ªç±»åˆ«ï¼Œè¿™ä»è§†è§‰ä¸Šæ˜æ˜¾çš„åŒºåŸŸå¯ä»¥çœ‹å‡ºã€‚ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå†³ç­–è¾¹ç•Œè¢«é™åˆ¶ä¸ºçº¿æ€§ï¼Œè¿™æ˜¯é€»è¾‘å›å½’æ¨¡å‹çš„å‡è®¾ã€‚

```py
plt.figure(figsize=(9, 5))
plot_data(x_train, y_train)
x0_min, x_0_max = x_train[:, 0].min()-0.5, x_train[:, 0].max()+0.5
x1_min, x_1_max = x_train[:, 1].min()-0.5, x_train[:, 1].max()+0.5
contour_plot((x0_min, x0_max), (x1_min, x1_max), 
             lambda x: predict(prior_binary, class_conditionals_binary, x), 
             1, label_colors, levels=[-0.5, 0.5, 1.5],
             num_points=200)
plt.title("Training set with decision regions")
plt.show()
```

![](img/9181695e5c5d25a63646a2eab35ea724.png)

å›¾ 5ï¼šç±»åˆ«æ¡ä»¶å†³ç­–åŒºåŸŸã€‚

# é€»è¾‘å›å½’ä¸­çš„ç¼ºå¤±é“¾æ¥

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä¸Šè¿°ç±»åˆ«æ¡ä»¶å¯†åº¦çš„å®šä¹‰ä¸é€»è¾‘å›å½’è”ç³»èµ·æ¥ã€‚æˆ‘ä»¬å±•ç¤ºäº†é¢„æµ‹åˆ†å¸ƒ ğ‘ƒ(ğ‘Œ=ğ‘¦0|ğ‘‹) å¯ä»¥å†™ä½œ

![](img/7db37d902814496db2cfec21a921cc07.png)

å…¶ä¸­ ğ‘ƒ(ğ‘‹|ğ‘Œ=ğ‘¦0) å’Œ ğ‘ƒ(ğ‘‹|ğ‘Œ=ğ‘¦1) æ˜¯ç±»åˆ«æ¡ä»¶å¯†åº¦ï¼Œğ‘ƒ(ğ‘Œ=ğ‘¦0) å’Œ ğ‘ƒ(ğ‘Œ=ğ‘¦1) æ˜¯ç±»åˆ«å…ˆéªŒã€‚

è¿™ä¸ªæ–¹ç¨‹å¯ä»¥é‡æ–°æ’åˆ—ä¸º ğ‘ƒ(ğ‘Œ=ğ‘¦0|ğ‘‹)=ğœ(ğ‘)ï¼Œå…¶ä¸­

![](img/269d6513225ebe05b27a1e7ba8b33184.png)

æ˜¯ sigmoid å‡½æ•°ï¼Œä»¥åŠ

![](img/06aaf728416430df589244b420b559e9.png)

æ˜¯å¯¹æ•°èµ”ç‡ã€‚

é€šè¿‡æˆ‘ä»¬é¢å¤–çš„å»ºæ¨¡å‡è®¾ï¼Œå³å…±äº«åæ–¹å·®çŸ©é˜µ Î£ï¼Œå¯ä»¥ä½¿ç”¨é«˜æ–¯æ¦‚ç‡å¯†åº¦å‡½æ•°æ˜¾ç¤º ğ‘ å®é™…ä¸Šæ˜¯ ğ‘‹ çš„çº¿æ€§å‡½æ•°ï¼Œ

![](img/162844021b49c68e46b9aa7be22d906e.png)

å…¶ä¸­

![](img/be8553acfb09ac4ae9a6a406e41435ea.png)

è¿™ä¸ªçº¿æ€§å‡½æ•° ğ‘=ğ‘¤ğ‘‡ğ‘‹+ğ‘¤0 è§£é‡Šäº†é€»è¾‘å›å½’çš„å†³ç­–è¾¹ç•Œä¸ºä½•æ˜¯çº¿æ€§çš„ã€‚å¯ä»¥çœ‹å‡ºï¼Œå‚æ•° ğ‘¤ å’Œ ğ‘¤0 æ˜¯ç±»åˆ«æ¡ä»¶å¯†åº¦ ğ‘ƒ(ğ‘‹|ğ‘Œ=ğ‘¦0) å’Œ ğ‘ƒ(ğ‘‹|ğ‘Œ=ğ‘¦1) ä»¥åŠç±»åˆ«å…ˆéªŒ ğ‘ƒ(ğ‘Œ=ğ‘¦0) å’Œ ğ‘ƒ(ğ‘Œ=ğ‘¦1) çš„å‡½æ•°ã€‚è¿™äº›å‚æ•°é€šå¸¸é€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼Œå¦‚æˆ‘ä»¬åœ¨å‰é¢ç« èŠ‚ä¸­æ‰€åšçš„é‚£æ ·ã€‚

# ç”Ÿæˆé€»è¾‘å›å½’æ¨¡å‹

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å‰é¢ç« èŠ‚ä¸­æ¨å¯¼å‡ºçš„æ–¹ç¨‹æ¥ç›´æ¥å‚æ•°åŒ–ç”Ÿæˆé€»è¾‘å›å½’æ¨¡å‹çš„è¾“å‡ºä¼¯åŠªåˆ©åˆ†å¸ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨å…ˆéªŒåˆ†å¸ƒå’Œç±»åˆ«æ¡ä»¶åˆ†å¸ƒæ¥è®¡ç®—æƒé‡å’Œåç½®é¡¹ ğ‘¤ å’Œ ğ‘¤0ã€‚

ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬ç¼–å†™äº†ä¸€ä¸ªæ–°å‡½æ•°ï¼Œè¯¥å‡½æ•°ä»¥å…ˆéªŒåˆ†å¸ƒå’Œç±»åˆ«æ¡ä»¶åˆ†å¸ƒä½œä¸ºè¾“å…¥ã€‚è¯¥å‡½æ•°ä½¿ç”¨è¿™äº›åˆ†å¸ƒçš„å‚æ•°æ¥è®¡ç®—æƒé‡å’Œåç½®é¡¹ï¼Œæ ¹æ®å‰é¢ç« èŠ‚ä¸­æ¨å¯¼å‡ºçš„æ–¹ç¨‹ã€‚

å‡½æ•°çš„è¾“å…¥æ˜¯å¯¹ä¸¤ä¸ªç±»åˆ«çš„å…ˆéªŒåˆ†å¸ƒå’Œç±»åˆ«æ¡ä»¶åˆ†å¸ƒã€‚

ç„¶åï¼Œå‡½æ•°ä½¿ç”¨è¿™äº›è¾“å…¥æ¥è®¡ç®—æƒé‡å’Œåç½®é¡¹ï¼Œå¦‚ä¸‹æ‰€ç¤º

![](img/be8553acfb09ac4ae9a6a406e41435ea.png)

è¯¥å‡½æ•°è¿”å›ğ‘¤å’Œğ‘¤0ï¼Œè¿™å¯ä»¥ç”¨æ¥ç›´æ¥å‚æ•°åŒ–ç”Ÿæˆé€»è¾‘å›å½’æ¨¡å‹çš„è¾“å‡ºä¼¯åŠªåˆ©åˆ†å¸ƒã€‚è¿™å…è®¸å¯¹æ¨¡å‹å‚æ•°åŠå…¶ä¸å…ˆéªŒå’Œç±»æ¡ä»¶åˆ†å¸ƒçš„å…³ç³»æœ‰æ›´ç›´æ¥å’Œé€æ˜çš„ç†è§£ã€‚

```py
def get_logistic_regression_params(prior, class_conditionals):
    cov = class_conditionals.covariance()[0]
    cov_inv = tf.linalg.inv(cov)
    mu0 = class_conditionals.parameters['loc'][0]
    mu1 = class_conditionals.parameters['loc'][1]
    w = np.matmul(cov_inv,(mu0-mu1))
    w0 = - 0.5 * (np.matmul(tf.transpose(mu0), np.matmul(cov_inv, mu0)))\
         + 0.5 * (np.matmul(tf.transpose(mu1), np.matmul(cov_inv, mu1)))\
         + np.log(prior.parameters['probs'][0] / prior.parameters['probs'][1])
    return w, w0

w, w0 = get_logistic_regression_params(prior_binary, class_conditionals_binary)
```

æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨è¿™äº›å‚æ•°åˆ¶ä½œè½®å»“å›¾ï¼Œä»¥æ˜¾ç¤ºæˆ‘ä»¬é€»è¾‘å›å½’æ¨¡å‹çš„é¢„æµ‹åˆ†å¸ƒã€‚

```py
fig, ax = plt.subplots(1, 1, figsize=(9, 5))
plot_data(x_train, y_train, alpha=0.35)
x0_min, x0_max = x_train[:, 0].min()-0.5, x_train[:, 0].max()+0.5
x1_min, x1_max = x_train[:, 1].min()-0.5, x_train[:, 1].max()+0.5
X0, X1 = get_meshgrid((x0_min, x0_max), (x1_min, x1_max))

logits = np.dot(np.array([X0.ravel(), X1.ravel()]).T, w) + w0
Z = tf.math.sigmoid(logits)
lr_contour = ax.contour(X0, X1, np.array(Z).T.reshape(*X0.shape), levels=10)
ax.clabel(lr_contour, inline=True, fontsize=10)
contour_plot((x0_min, x0_max), (x1_min, x1_max), 
             lambda x: predict(prior_binary, class_conditionals_binary, x), 
             1, label_colors, levels=[-0.5, 0.5, 1.5],
             num_points=200)
plt.title("Training set with prediction contours")
plt.show()
```

![](img/7148914bfdb2d7c07d2ef4e63c054c23.png)

å›¾ 6: æˆ‘ä»¬é€»è¾‘å›å½’æ¨¡å‹é¢„æµ‹åˆ†å¸ƒçš„å¯†åº¦è½®å»“ã€‚

# æˆ‘ä»¬çš„æ–¹æ³•æ˜¯å¦å®Œå…¨æ˜¯è´å¶æ–¯çš„ï¼Ÿ

ä¸Šè¿°æ–¹æ³•å¯ä»¥è¢«è§†ä¸ºä¸€ç§è´å¶æ–¯æ¨æ–­å½¢å¼ï¼Œå› ä¸ºå®ƒæ¶‰åŠé€šè¿‡å…ˆéªŒåˆ†å¸ƒå¼•å…¥å…³äºæ¨¡å‹å‚æ•°çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¹¶é€šè¿‡ç±»æ¡ä»¶åˆ†å¸ƒä½¿ç”¨è§‚æµ‹æ•°æ®æ›´æ–°è¿™äº›çŸ¥è¯†ã€‚è¿™æ˜¯è´å¶æ–¯æ¨æ–­çš„ä¸€ä¸ªå…³é”®æ–¹é¢ï¼Œæ—¨åœ¨å°†å…³äºæ¨¡å‹å‚æ•°çš„å…ˆéªŒçŸ¥è¯†å’Œä¸ç¡®å®šæ€§èå…¥æ¨æ–­è¿‡ç¨‹ã€‚

åœ¨è´å¶æ–¯æ¨æ–­ä¸­ï¼Œç›®æ ‡æ˜¯è®¡ç®—ç»™å®šè§‚æµ‹æ•°æ®ä¸‹æ¨¡å‹å‚æ•°çš„åéªŒåˆ†å¸ƒã€‚ä¸Šè¿°æ–¹æ³•å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§è¿‘ä¼¼è´å¶æ–¯æ¨æ–­ï¼Œå› ä¸ºå®ƒæ¶‰åŠä½¿ç”¨ç±»æ¡ä»¶å¯†åº¦å’Œå…ˆéªŒåˆ†å¸ƒçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ¥è®¡ç®—æ¨¡å‹çš„æƒé‡å’Œåç½®ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•é€šè¿‡å…±äº«åæ–¹å·®çŸ©é˜µæ¥å¼•å…¥ä¸ç¡®å®šæ€§ï¼Œè¿™ä½œä¸ºæ­£åˆ™åŒ–é¡¹ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸Šè¿°æ–¹æ³•å¹¶éå®Œå…¨è´å¶æ–¯ï¼Œå› ä¸ºå®ƒæ²¡æœ‰æä¾›æ¨¡å‹å‚æ•°çš„åéªŒåˆ†å¸ƒçš„å°é—­å½¢å¼ã€‚ç›¸åï¼Œå®ƒä½¿ç”¨åŸºäºæœ€å¤§ä¼¼ç„¶ä¼°è®¡çš„è¿‘ä¼¼ã€‚

# ç»“è®º

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¦‚ç‡æ–¹æ³•æ¥å¤„ç†é¢„æµ‹è¿‡ç¨‹ä¸­çš„å†…åœ¨ä¸ç¡®å®šæ€§ã€‚é€šè¿‡åœ¨æ¨¡å‹å‚æ•°ä¸Šå¼•å…¥å…ˆéªŒåˆ†å¸ƒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹æ¨¡å‹è¿›è¡Œæ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ TensorFlow Probability å®ç°è¯¥æ–¹æ³•ä»¥åŠå¦‚ä½•åˆ†æå…¶ç»“æœã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡æˆ‘ä»¬çš„æ–¹æ³•åŒ…å«äº†è´å¶æ–¯åŸåˆ™ï¼Œä½†å®ƒå¹¶ä¸æ˜¯å®Œå…¨è´å¶æ–¯çš„æ–¹æ³•ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰æ¨¡å‹å‚æ•°çš„å®Œæ•´åéªŒåˆ†å¸ƒã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°é¢„æµ‹è¿‡ç¨‹ä¸­çš„å†…åœ¨ä¸ç¡®å®šæ€§ï¼Œå·²ç»ä½¿æˆ‘ä»¬å¯¹é¢„æµ‹è¿‡ç¨‹æ›´æœ‰ä¿¡å¿ƒã€‚

ä¿æŒè”ç³»: [LinkedIn](https://www.linkedin.com/in/luisbrasroque/)

# å‚è€ƒæ–‡çŒ®å’Œææ–™

[1] â€” [è‘¡è„é…’æ•°æ®é›†](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)

[2] â€” [Coursera: æ·±åº¦å­¦ä¹ ä¸“é¡¹è¯¾ç¨‹](https://www.coursera.org/specializations/deep-learning)

[3] â€” [Coursera: TensorFlow 2 æ·±åº¦å­¦ä¹ ä¸“é¡¹è¯¾ç¨‹](https://www.coursera.org/specializations/tensorflow2-deeplearning)

[4] â€” [TensorFlow æ¦‚ç‡æŒ‡å—å’Œæ•™ç¨‹](https://www.tensorflow.org/probability/overview)

[5] â€” [TensorFlow åšå®¢ä¸­çš„ TensorFlow æ¦‚ç‡å¸–å­](https://blog.tensorflow.org/search?label=TensorFlow+Probability&max-results=20)
