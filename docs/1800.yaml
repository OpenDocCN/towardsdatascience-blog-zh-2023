- en: Build Industry-Specific LLMs Using Retrieval Augmented Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68?source=collection_archive---------0-----------------------#2023-05-31](https://towardsdatascience.com/build-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68?source=collection_archive---------0-----------------------#2023-05-31)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Organizations are in a race to adopt Large Language Models. Let’s dive into
    how you can build industry-specific LLMs Through RAG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)[![Skanda
    Vivek](../Images/9d25bee2fb75176ca7f7ea6eff7d7ab5.png)](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)
    [Skanda Vivek](https://skanda-vivek.medium.com/?source=post_page-----af9e98bb6f68--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F220d9bbb8014&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68&user=Skanda+Vivek&userId=220d9bbb8014&source=post_page-220d9bbb8014----af9e98bb6f68---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af9e98bb6f68--------------------------------)
    ·10 min read·May 31, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf9e98bb6f68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68&user=Skanda+Vivek&userId=220d9bbb8014&source=-----af9e98bb6f68---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf9e98bb6f68&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuild-industry-specific-llms-using-retrieval-augmented-generation-af9e98bb6f68&source=-----af9e98bb6f68---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Companies stand to gain a lot of productivity improvements through LLMs like
    ChatGPT. But try asking ChatGPT “what is the current inflation in the U.S.” and
    it gives:'
  prefs: []
  type: TYPE_NORMAL
- en: I apologize for the confusion, but as an AI language model, I don’t have real-time
    data or browsing capabilities. My responses are based on information available
    up until September 2021\. Therefore, I cannot provide you with the current inflation
    rate in the U.S.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Which is a problem. ChatGPT is clearly missing relevant timely context, which
    could be essential while making informed decisions.
  prefs: []
  type: TYPE_NORMAL
- en: How Microsoft Is Solving This
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the Microsoft Build session [Vector Search Isn’t Enough](https://build.microsoft.com/en-US/sessions/038984b3-7c5d-4cc6-b24e-5d9f62bc2f0e?wt.mc_ID=Build2023_esc_corp_em_oo_mto_Marketo_FPnews_Elastic),
    they lay out their product that combines less context-aware LLMs with vector search,
    to create a more engaging experience.
  prefs: []
  type: TYPE_NORMAL
- en: The talk starts from the opposite direction of this piece — from the point of
    view of Elastic Search (or vector search) — and the idea that search by itself
    is limited, and adding the layer of LLMs can vastly improve…
  prefs: []
  type: TYPE_NORMAL
