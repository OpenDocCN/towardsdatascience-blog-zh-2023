- en: The Moat for Enterprise AI is RAG + Fine Tuning — Here’s Why
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-moat-for-enterprise-ai-is-rag-fine-tuning-heres-why-fb2038e40ce9?source=collection_archive---------0-----------------------#2023-11-13](https://towardsdatascience.com/the-moat-for-enterprise-ai-is-rag-fine-tuning-heres-why-fb2038e40ce9?source=collection_archive---------0-----------------------#2023-11-13)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To succeed with generative AI at scale, we need to give LLMs the diligence they
    deserve. Enter RAG and fine tuning.
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://barrmoses.medium.com/?source=post_page-----fb2038e40ce9--------------------------------)[![Barr
    Moses](../Images/4c74558ee692a85196d5a55ac1920718.png)](https://barrmoses.medium.com/?source=post_page-----fb2038e40ce9--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb2038e40ce9--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb2038e40ce9--------------------------------)
    [Barr Moses](https://barrmoses.medium.com/?source=post_page-----fb2038e40ce9--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2818bac48708&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-moat-for-enterprise-ai-is-rag-fine-tuning-heres-why-fb2038e40ce9&user=Barr+Moses&userId=2818bac48708&source=post_page-2818bac48708----fb2038e40ce9---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb2038e40ce9--------------------------------)
    ·10 min read·Nov 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb2038e40ce9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-moat-for-enterprise-ai-is-rag-fine-tuning-heres-why-fb2038e40ce9&user=Barr+Moses&userId=2818bac48708&source=-----fb2038e40ce9---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb2038e40ce9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-moat-for-enterprise-ai-is-rag-fine-tuning-heres-why-fb2038e40ce9&source=-----fb2038e40ce9---------------------bookmark_footer-----------)![](../Images/67e6dcf824922758dca811f6fdea6d8d.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Volodymyr Hryshchenko](https://unsplash.com/@lunarts?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/three-crumpled-yellow-papers-on-green-surface-surrounded-by-yellow-lined-papers-V5vqWC9gyEU?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The hype around LLMs is unprecedented, but it’s warranted. From AI-generated
    images of [the Pope in head-to-toe Balenciaga](https://www.forbes.com/sites/danidiplacido/2023/03/27/why-did-balenciaga-pope-go-viral/)
    to [customer support agents without pulses](https://www.zendesk.com/blog/ai-customer-service/),
    generative AI has the potential to transform society as we know it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕LLM的炒作是前所未有的，但也是有充分理由的。从AI生成的[全副装扮的教皇](https://www.forbes.com/sites/danidiplacido/2023/03/27/why-did-balenciaga-pope-go-viral/)到[没有脉搏的客户支持代理人](https://www.zendesk.com/blog/ai-customer-service/)，生成式AI有改变我们所知社会的潜力。
- en: And in many ways, LLMs are going to make data engineers more valuable — and
    that’s exciting!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在很多方面，LLM（大型语言模型）将会使数据工程师变得更加重要 — 这是令人兴奋的！
- en: Still, it’s one thing to show your boss a cool demo of a data discovery tool
    or text-to-SQL generator — it’s another thing to use it with your company’s proprietary
    data, or even more concerning, customer data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，向老板展示一个数据发现工具或文本转SQL生成器的酷炫演示一回事，将其与公司的专有数据，甚至更令人担忧的是客户数据一起使用则是另一回事。
- en: All too often, companies rush into building AI applications with little foresight
    into the financial and organizational impact of their experiments. And it’s not
    their fault — executives and boards are to blame for much of the “hurry up and
    go” mentality around this (and most) new technologies. (Remember NFTs?).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 太多时候，公司匆忙建立AI应用程序，却对其实验的财务和组织影响缺乏远见。而这并不是他们的错 — 高管和董事会对这（以及大多数）新技术的“赶快上路”的心态负有责任。（还记得NFT吗？）
- en: For AI — particularly generative AI — to succeed, we need to take a step back
    and remember how *any* software becomes enterprise ready. To get there, we can
    take cues from other industries to understand what enterprise readiness looks
    like and apply these tenets to generative AI.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要让AI — 特别是生成式AI — 取得成功，我们需要退一步，回想一下*任何*软件如何变得企业就绪。为了达到这一点，我们可以从其他行业获取启示，了解企业就绪的标准，并将这些原则应用到生成式AI中。
- en: 'In my opinion, enterpris-ready generative AI must be:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为，企业级生成式AI必须：
- en: '**Secure & private:** Your AI application must ensure that your data is secure,
    private, and compliant, with proper access controls. Think: SecOps for AI.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全与隐私：** 您的AI应用程序必须确保您的数据安全、私密且符合法规，具备适当的访问控制。想象一下：AI的安全运营。'
- en: '**Scalable:** your AI application must be easy to deploy, use, and upgrade,
    as well as be cost-efficient. You wouldn’t purchase — or build — a data application
    if it took months to deploy, was tedious to use, and impossible to upgrade without
    introducing a million other issues. We shouldn’t treat AI applications any differently.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性：** 您的AI应用程序必须易于部署、使用和升级，同时还要具备成本效益。如果一个数据应用程序需要花费数月才能部署，使用起来繁琐，并且升级时会引入无数其他问题，那么您也不会购买或自行开发这样的应用程序。我们不应该对待AI应用程序有任何不同。'
- en: '**Trusted.** Your AI application should be sufficiently reliable and consistent.
    I’d be hard-pressed to find a CTO who is willing to bet her career on buying or
    building a product that produces unreliable code or generates insights that are
    haphazard and misleading.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可信赖。** 您的AI应用程序应该足够可靠和一致。我很难想象有哪位CTO愿意赌自己的职业生涯，去购买或开发一个生成不可靠代码或生成的见解混乱且误导的产品。'
- en: With these guardrails in mind, it’s time we start giving generative AI the diligence
    it deserves. But it’s not so easy…
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些限制条件下，现在是我们开始认真对待生成式AI的时候了。但这并不容易……
- en: Why is enterprise AI hard to achieve?
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么企业级AI如此难以实现？
- en: Put simply, the underlying infrastructure to scale, secure, and operate LLM
    applications is not there yet.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，尚缺乏适合扩展、安全和运作LLM应用程序的基础设施。
- en: Unlike most applications, AI is very much a black box. We *know* what we’re
    putting in (raw, often unstructured data) and we *know* what we’re getting out,
    but we don’t know how it got there. And that’s difficult to scale, secure and
    operate.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 不同于大多数应用程序，AI 很大程度上是一个黑匣子。我们*知道*我们输入了什么（原始、通常是非结构化数据），我们也*知道*我们得到了什么结果，但我们不知道它是如何做到的。这使得扩展、安全和运作都变得困难。
- en: Take GPT-4 for example. [While GPT-4 blew GPT 3.5 out of the water](https://www.pcmag.com/news/gpt-4-offers-human-level-performance-hallucinations-and-better-bing-results)
    when it came to some tasks (like taking SAT and AP Calculus AB exam), some of
    its outputs were [riddled with hallucinations](https://spectrum.ieee.org/ai-hallucination)
    or lacked necessary context to adequately accomplish these tasks. Hallucinations
    are caused by [a variety of factors](https://www.pinecone.io/learn/options-for-solving-hallucinations-in-generative-ai/)
    from poor embeddings to knowledge cutoff, and frequently affect the quality of
    responses generated by publicly available or open LLMs trained on information
    scraped from the internet, which account for most models.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以GPT-4为例。[虽然GPT-4在某些任务（如SAT和AP Calculus AB考试）表现出色](https://www.pcmag.com/news/gpt-4-offers-human-level-performance-hallucinations-and-better-bing-results)，但其部分输出被[幻觉所困扰](https://spectrum.ieee.org/ai-hallucination)或缺乏足够的上下文来充分完成这些任务。幻觉的产生是由[多种因素](https://www.pinecone.io/learn/options-for-solving-hallucinations-in-generative-ai/)引起的，从低质量的嵌入到知识截断，经常影响由公开或开放LLM模型生成的响应质量，这些模型是根据从互联网上获取的信息训练的，占大多数。
- en: To reduce hallucinations and even more importantly — to answer meaningful business
    questions — companies need to augment LLMs with their own proprietary data, which
    includes necessary business context. For instance, if a customer asks an airline
    chatbot to cancel their ticket, the model would need to access information about
    the customer, about their past transactions, about cancellation policies and potentially
    other pieces of information. All of these currently exist in databases and data
    warehouses.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少幻觉，甚至更重要的是——回答有意义的业务问题——公司需要用自己的专有数据增强LLMs，包括必要的业务背景。例如，如果客户要求航空公司聊天机器人取消他们的机票，模型需要访问关于客户、其过往交易、取消政策以及可能的其他信息。所有这些信息当前都存在于数据库和数据仓库中。
- en: Without that context, an AI can only reason with the public information, typically
    published on the Internet, on which it was originally trained. And here lies the
    conundrum — exposing proprietary Enterprise data and incorporating it into business
    workflows or customer experiences almost always requires solid security, scalability
    and reliability.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 没有这些背景信息，AI只能根据公开信息进行推理，通常这些信息是最初训练模型的互联网上发布的。这就产生了一个难题——暴露专有企业数据并将其纳入业务工作流程或客户体验几乎总是需要坚实的安全性、可扩展性和可靠性。
- en: 'The two routes to enterprise-ready AI: RAG and fine tuning'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 两条通向企业就绪AI的路线：RAG和微调
- en: 'When it comes to making AI enterprise ready, the most critical parts come at
    the very end of the LLM development process: [**retrieval augmented generation
    (RAG)**](https://www.promptingguide.ai/techniques/rag) and [**fine tuning**](https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及使AI企业就绪时，最关键的部分出现在LLM开发过程的最后阶段：[**检索增强生成（RAG）**](https://www.promptingguide.ai/techniques/rag)
    和 [**微调**](https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts)。
- en: It’s important to note, however, that RAG and fine tuning are not mutually exclusive
    approaches, and should be leveraged — oftentimes in tandem — based on your specific
    needs and use case.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但需要注意的是，RAG和微调并不是互斥的方法，应根据您的具体需求和用例来利用——通常是并行使用的。
- en: '**When to use RAG**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用RAG**'
- en: '![](../Images/0a49265b77f0332c052b96fd349a238e.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0a49265b77f0332c052b96fd349a238e.png)'
- en: Image courtesy of author.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供。
- en: '**RAG** is a framework that improves the quality of LLM outputs by giving the
    model access to a database while attempting to answer a prompt. The database —
    being a curated and trusted body of potentially proprietary data — allows the
    model to incorporate up-to-date and reliable information into its responses and
    reasoning. This approach is best suited for AI applications that require additional
    contextual information, such as customer support responses (like our flight cancellations
    example) or semantic search in your company’s enterprise communication platform.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAG** 是一种通过让模型访问数据库来改进LLM输出质量的框架，试图在回答提示时提供支持。数据库作为一个经过精心策划和可信任的潜在专有数据集，允许模型将最新和可靠的信息整合到其响应和推理中。这种方法最适合需要额外上下文信息的AI应用，例如客户支持响应（例如我们的航班取消示例）或在公司企业通信平台中进行语义搜索。'
- en: RAG applications are designed to retrieve relevant information from knowledge
    sources before generating a response, making them well suited for querying structured
    and unstructured data sources, such as vector databases and feature stores. By
    retrieving information to increase the accuracy and reliability of LLMs at output
    generation, RAG is also highly effective at both [reducing hallucinations](https://www.pinecone.io/learn/options-for-solving-hallucinations-in-generative-ai/)
    and keeping training costs down. RAG also affords teams a level of transparency
    since you know the source of the data that you’re piping into the model to generate
    new responses.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: RAG应用程序旨在从知识来源中检索相关信息，然后生成响应，因此非常适合查询结构化和非结构化数据源，如向量数据库和特征存储。通过检索信息来提高LLM在输出生成时的准确性和可靠性，RAG在减少幻觉和降低培训成本方面也非常有效。RAG还为团队提供了一定程度的透明度，因为您知道将数据输入模型以生成新响应的数据源。
- en: One thing to note about RAG architectures is that their performance heavily
    relies on your ability to build effective data pipelines that make enterprise
    data available to AI models.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 关于RAG架构的一点需要注意的是，它们的性能在很大程度上依赖于您建立有效数据管道的能力，使企业数据对AI模型可用。
- en: '**When to use fine tuning**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用微调**'
- en: '![](../Images/bb51fa5c298308b10ef559a09cdbbc71.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb51fa5c298308b10ef559a09cdbbc71.png)'
- en: Image courtesy of author.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者提供。
- en: '**Fine tuning** is the process of training an existing LLM on a smaller, task-specific
    and labeled dataset, adjusting model parameters and embeddings based on this new
    data. Fine tuning relies on pre-curated datasets that inform not just information
    retrieval, but the nuance and terminologies of the domain for which you’re looking
    to generate outputs.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**微调**是在现有的语言模型上训练一个更小、任务特定且标记数据集的过程，根据这些新数据调整模型参数和嵌入。微调依赖于预先筛选过的数据集，这些数据集不仅仅用于信息检索，还包括所需领域的细微差别和术语。'
- en: In our experience, fine tuning is best suited for domain-specific situations,
    like responding to detailed prompts in a niche tone or style, i.e. a legal brief
    or customer support ticket. It is also a great fit for overcoming information
    bias and other limitations, such as language repetitions or inconsistencies. [Several](https://snorkel.ai/better-not-bigger-how-to-get-gpt-3-quality-at-0-1-the-cost/)
    [studies](https://openaccess.thecvf.com/content/CVPR2022/html/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.html)
    over the past year have shown that fine-tuned models significantly outperform
    off-the-shelf versions of GPT-3 and other publically available models. It has
    been established that for many use cases, a fine-tuned small model can outperform
    a large general purpose model — making fine tuning a plausible path for cost efficiency
    in certain cases.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的经验中，微调最适合特定领域的情况，比如以特定的语调或风格对详细提示作出回应，比如法律简报或客户支持票证。它还非常适合克服信息偏见和其他限制，比如语言重复或不一致之处。[几项](https://snorkel.ai/better-not-bigger-how-to-get-gpt-3-quality-at-0-1-the-cost/)
    [研究](https://openaccess.thecvf.com/content/CVPR2022/html/Wortsman_Robust_Fine-Tuning_of_Zero-Shot_Models_CVPR_2022_paper.html)
    在过去的一年中表明，经过微调的模型显著优于GPT-3和其他公开可用模型的即用版本。已经确定，对于许多用例来说，经过微调的小型模型可以胜过大型通用模型 ——
    这使得在某些情况下，微调成为成本效率的一种可行路径。
- en: Unlike RAG, fine tuning often requires less data but at the expense of more
    time and compute resources. Additionally, fine tuning operates like a black box;
    since the model internalizes the new data set, it becomes challenging to pinpoint
    the reasoning behind new responses and hallucinations remain a meaningful concern.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与RAG不同，微调通常需要更少的数据，但耗费更多的时间和计算资源。此外，微调操作像一个黑盒子；由于模型内化了新数据集，难以准确指出新响应背后的推理过程，并且幻觉仍然是一个值得关注的问题。
- en: Fine tuning — like RAG architectures — requires building effective data pipelines
    that make (labeled!) enterprise data available to the fine tuning process. No
    easy feat.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 和RAG架构一样，微调需要建立有效的数据管道，使（标记的！）企业数据可用于微调过程。这绝非易事。
- en: Why RAG probably makes sense for your team
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么RAG可能适合您的团队
- en: '![](../Images/733fe863d3094592583b9b0868cebd17.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/733fe863d3094592583b9b0868cebd17.png)'
- en: Image courtesy of author.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图像由作者提供。
- en: It’s important to remember that RAG and fine tuning are not mutually exclusive
    approaches, have varying strengths and weaknesses, and can be used together. However,
    for the vast majority of use cases, RAG likely makes the most sense when it comes
    to delivering enterprise Generative AI applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s why:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**RAG security and privacy is more manageable:** Databases have built-in roles
    and security unlike AI models, and it’s pretty well-understood who sees what due
    to standard access controls. Further, you have more control over what data is
    used by accessing a secure and private corpus of proprietary data. With fine tuning,
    any data included in the training set is exposed to all users of the application,
    with no obvious ways to manage who sees what. In many practical scenarios — especially
    when it comes to customer data — not having that control is a no-go.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RAG is more scalable:** RAG is less expensive than fine tuning because the
    latter involves updating all of the parameters of a large model, requiring extensive
    computing power. Further, RAG doesn’t require labeling and crafting training sets,
    a human-intensive process that can take weeks and months to perfect per model.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**RAG makes for more trusted results.** Simply put, RAG works better with dynamic
    data, generating deterministic results from a curated data set of up-to-date data.
    Since fine tuning largely acts like a black box, it can be difficult to pinpoint
    how the model generated specific results, decreasing trust and transparency. With
    fine tuning, hallucinations and inaccuracies are possible and even likely, since
    you are relying on the model’s weights to encode business information in a lossy
    manner.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our humble opinion, enterprise ready AI will primarily rely on RAG, with
    fine tuning involved in more nuanced or domain specific use cases. For the vast
    majority of applications, fine tuning will be a nice-to-have for niche scenarios
    and come into play much more frequently once the industry can reduce cost and
    resources necessary to run AI at scale.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of which one you use, however, your AI application development is
    going to require pipelines that feed these models with company data through some
    data store (be it Snowflake, Databricks, a standalone vector database like Pinecone,
    or something else entirely). At the end of the day, if generative AI is used in
    internal processes to extract analysis and insight from unstructured data — it
    will be used in… drumroll… a data pipeline.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: For RAG to work, you need data observability
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the early 2010s, [machine learning](https://www.montecarlodata.com/blog-why-production-machine-learning-fails-and-how-to-fix-it/)
    was touted as a magic algorithm that performed miracles on command if you gave
    its features the perfect weights. What typically improved ML performance, however,
    was investing in high quality features and in particular — data quality.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, in order for enterprise AI to work, you need to focus on the quality
    and reliability of the data on which generative models depend — likely through
    a RAG architecture.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Since it relies on dynamic, sometimes up-to-the-minute data, RAG requires [data
    observability](https://www.montecarlodata.com/product/data-observability-platform/)
    to live up to its enterprise ready expectations. Data can break for any number
    of reasons, such as misformatted third-party data, faulty transformation code
    or a failed Airflow job. And it always does.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Data observability gives teams the ability to monitor, alert, triage, and resolve
    data or pipeline issues at scale across your entire data ecosystem. For years,
    it’s been a must-have layer of the modern data stack; as RAG grows in importance
    and AI matures, observability will emerge as a critical partner in LLM development.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: The only way RAG — and enterprise AI — work is if you can trust the data. To
    achieve this, teams need a scalable, automated way to ensure reliability of data,
    as well as an enterprise-grade way to identify root cause and resolve issues quickly
    — before they impact the LLMs they service.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: So, what is the de facto LLM stack?
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The infrastructure and technical roadmap for AI tooling is being developed as
    we speak, with new startups emerging every day to solve various problems, and
    industry behemoths claiming that they, too, are tackling these challenges. When
    it comes to incorporating enterprise data into AI, I see three primary horses
    in this race.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'The first horse: vector databases. Pinecone, Weaviate, and others are making
    a name for themselves as the must-have database platforms to power RAG architectures.
    While these technologies show a lot of promise, they do require spinning up a
    new piece of the stack and creating workflows to support it from a security, scalability
    and reliability standpoint.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'The second horse: hosted versions of models built by third-party LLM developers
    like OpenAI or Anthropic. Currently, most teams get their generative AI fix via
    APIs with these up-and-coming AI leaders due to ease of use. Plug into the OpenAI
    API and leverage a cutting edge model in minutes? Count us in. This approach works
    great out-of-the-box if you need the model to generate code or solve well-known,
    non-specific prompts based on public information. If you do want to incorporate
    proprietary information into these models, you could use the built-in [fine tuning](https://platform.openai.com/docs/guides/fine-tuning)
    or [RAG](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval)
    features that these platforms provide.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'And finally, the third horse: [the modern data stack](https://www.montecarlodata.com/blog-how-to-build-a-5-layer-data-stack/).
    [Snowflake](https://www.snowflake.com/en/resources/case-study/cortex/) and [Databricks](https://www.databricks.com/company/newsroom/press-releases/databricks-introduces-new-generative-ai-tools-investing-lakehouse)
    have already announced that they’re embedding vector databases into their platforms
    as well as other tooling to help incorporate data that is already stored and processed
    on these platforms into LLMs. This makes a lot of sense for many, and allows data
    teams charged with AI initiatives to leverage the tools they already use. Why
    reinvent the wheel when you have the foundations in place? Not to mention the
    possibility of being able to easily join traditional relational data with vector
    data… Like the two other horses, there are some downsides to this approach: Snowflake
    Cortex, Lakehouse AI, and other MDS + AI products are nascent and require some
    upfront investment to incorporate vector search and model training into your existing
    workflows. For a more in-depth look at this approach, I encourage you to check
    out Meltano’s [pertinent piece](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/)
    on why the best LLM stack may be the one sitting right in front of you.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第三匹马：[现代数据堆栈](https://www.montecarlodata.com/blog-how-to-build-a-5-layer-data-stack/)。[Snowflake](https://www.snowflake.com/en/resources/case-study/cortex/)
    和 [Databricks](https://www.databricks.com/company/newsroom/press-releases/databricks-introduces-new-generative-ai-tools-investing-lakehouse)
    已经宣布他们正在将向量数据库嵌入其平台以及其他工具，以帮助将已存储和处理在这些平台上的数据整合到 LLM 中。对于许多人来说，这是非常合理的，并允许负责 AI
    项目的数据团队利用他们已经使用的工具。当您已经有了基础时，何必重新发明轮子呢？更不用说可以轻松地将传统关系型数据与向量数据结合起来的可能性了……像其他两匹马一样，这种方法也有一些缺点：Snowflake
    Cortex、Lakehouse AI 和其他 MDS + AI 产品还处于萌芽阶段，需要一些前期投资来将向量搜索和模型训练整合到您现有的工作流程中。如果您想更深入地了解这种方法，请查看
    Meltano 在其[相关文章](https://meltano.com/blog/llm-apps-are-mostly-data-pipelines/)中为什么最好的
    LLM 堆栈可能就在您眼前的观点。
- en: Regardless of the horse we choose, valuable business questions cannot be answered
    by a model trained on the data that is on the Internet. It needs to have context
    from within the company. And by providing this context in a secure, scalable,
    and trusted way, we can achieve enterprise ready AI.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们选择哪匹马，宝贵的商业问题都不能通过仅基于互联网数据训练的模型来回答。它需要具有公司内部背景的上下文。通过安全、可扩展和可信赖的方式提供这种背景，我们可以实现企业级
    AI。
- en: The future of enterprise AI is in your pipelines
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 企业 AI 的未来就在您的管道中。
- en: For AI to live up to this potential, data and AI teams need to treat LLM augmentation
    with the diligence they deserve and make security, scalability and reliability
    a first-class consideration. Whether your use case calls for RAG or fine tuning
    — or both — you’ll need to ensure that your data stack foundations are in place
    to keep costs low, performance consistent, and reliability high.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要使 AI 实现其潜力，数据和 AI 团队需要认真对待 LLM 增强，并将安全性、可扩展性和可靠性作为首要考虑因素。无论您的用例是否需要 RAG 或精细调整
    — 或两者兼有 — 您都需要确保您的数据堆栈基础设施已经就位，以保持成本低、性能稳定且可靠性高。
- en: Data needs to be secure and private; LLM deployment needs to be scalable; and
    your results need to be trusted. Keeping a steady pulse on data quality through
    observability are critical to these demands.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 数据需要安全和隐私保护；LLM 部署需要可扩展性；而您的结果需要得到信任。通过可观察性保持数据质量的稳定脉搏对这些需求至关重要。
- en: The best part of this evolution from siloed X demos to enterprise ready AI?
    RAG gives data engineers the best seat at the table when it comes to owning and
    driving ROI for generative AI investments.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这种从孤立的 X 演示转向企业级 AI 的演变中最好的部分是什么？RAG 使数据工程师在拥有和推动生成 AI 投资的 ROI 方面处于最佳位置。
- en: I’m ready for enterprise ready AI. Are you?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我已准备好迎接企业级 AI。你准备好了吗？
- en: '*Lior Gavish contributed to this article.*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*Lior Gavish 为本文作出了贡献。*'
- en: '**Connect with** [**Barr on LinkedIn**](https://www.linkedin.com/in/barrmoses/)
    **for more insights on data, AI, and the future of data trust.**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**与** [**巴尔在领英上联系**](https://www.linkedin.com/in/barrmoses/) **以获取有关数据、AI和数据信任未来的更多见解。**'
