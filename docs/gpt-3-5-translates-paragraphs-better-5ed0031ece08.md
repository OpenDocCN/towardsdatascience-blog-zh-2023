# GPT-3.5 更擅长翻译段落

> 原文：[`towardsdatascience.com/gpt-3-5-translates-paragraphs-better-5ed0031ece08`](https://towardsdatascience.com/gpt-3-5-translates-paragraphs-better-5ed0031ece08)

## 并且在翻译文学作品方面优于 Google 翻译

[](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)![Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------) [Benjamin Marie](https://medium.com/@bnjmn_marie?source=post_page-----5ed0031ece08--------------------------------)

·发布在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5ed0031ece08--------------------------------) ·9 分钟阅读·2023 年 5 月 25 日

--

![](img/ef7e5310e5962ca4223e72e1bf1cc46c.png)

图片来源于 [Pixabay](https://pixabay.com/vectors/translate-language-translation-6089103/)

根据 [以往研究](https://arxiv.org/pdf/2211.09102.pdf)，GPT 模型的表现与标准机器翻译系统相当，例如 Google 翻译。

这些研究主要集中在句子级翻译：机器翻译中默认的做法是逐句翻译，没有任何上下文。

翻译段落或整个文档对于标准机器翻译系统来说是非常困难的挑战。这些系统通常需要拆分输入或进行大量工程改造以接受和利用更长的输入。

然而，从直观上看，并遵循人工翻译者的工作流程，我们可以期待机器翻译系统在处理上下文时表现更好，例如翻译整个文档或段落。

这就是大型语言模型如 GPT 模型可以大放异彩的地方。它们可以接受比典型机器翻译系统显著更长的提示词输入。

但仍需评估以下内容：

1.  利用更多上下文是否有助于提高 GPT 的机器翻译质量。

1.  GPT 模型在翻译长文本时的表现，与标准机器翻译系统相比。

对于翻译段落的大型语言模型的评估面临几个挑战。

1.  **用于机器翻译评估的自动化指标并未设计用于段落级评估。**

1.  **评估数据在被评估系统训练期间不得出现过。**

1.  **评估应在多样的语言对上进行，以准确了解大型语言模型的翻译质量。**

1.  **提示词必须设计成利用整个段落，即不仅仅是像以往工作中那样的句子。**

这些挑战都由[Karpinska 和 Iyyer (2023) 的“**大型语言模型有效利用文档级上下文进行文学翻译，但仍存在关键错误**”](https://arxiv.org/pdf/2304.03245.pdf)解决。

在这篇博客文章中，我回顾并评论了他们的工作。我们将看到他们对 GPT-3.5 的评估如何表明“*在提供段落级上下文时，LLMs 产生更好的翻译*”，并且对于非常多样化的语言对，其翻译质量优于最先进的神经机器翻译系统。

# 段落翻译的人工评估

在机器翻译中常用的自动化评估指标是不适用的。在评估段落级翻译时，它们与人工判断的相关性尚不明确。

我们不能依赖自动化指标。

人工评估仍然是具有高可信度评估的主要选择，因此该研究的作者主要依赖于 MQM 框架（[Lommel et al., 2014](https://ddd.uab.cat/pub/tradumatica/tradumatica_a2014n12/tradumatica_a2014n12p455.pdf)）：

+   标记翻译错误的范围并对其进行分类

+   做出两种翻译中哪一种质量更高的偏好判断

+   提供自由形式的偏好判断理由。

在此次评估中，他们收集了总共 720 对翻译段落，涵盖了 18 种语言对。

数据量真是惊人！我迫不及待想看看数据集。它将发布在 GitHub 上，[这里](https://github.com/marzenakrp/LiteraryTranslation)。

# 文学作品的机器翻译

在评估中，这项工作选择专注于翻译文学作品。由于大多数以前的机器翻译工作集中在其他体裁/领域（新闻、用户生成文本等），因此这可能看起来是一个奇怪的选择。

文学文本的机器翻译研究不足且极具挑战性，特别是对于以句子级别工作的大型机器翻译系统。

在这种类型的文本中，上下文的细微差别非常重要，但如果系统独立翻译句子，就无法捕捉这些细微差别。通常，人工翻译者必须重组整个段落，以准确翻译成目标语言。

文学文本的翻译直观上是一个任务，其中系统以文档或段落作为输入会比仅接受较短输入的系统表现更好。

但在评估大型语言模型时，我们面临的一个主要限制是评估使用的数据必须是最新的。这对评估的可信度很重要。通过使用最近发布的数据进行评估，我们可以避免翻译可能用于训练评估模型的文本，即避免数据污染。

[](/the-decontaminated-evaluation-of-gpt-4-38a27fc45c30?source=post_page-----5ed0031ece08--------------------------------) ## GPT-4 的去污染评估

### GPT-4 很快不会成为你的律师

[towardsdatascience.com

在这项工作中，用于评估的大部分翻译都是在 2021 年后发布的。这些特定的翻译很可能不在 GPT-3.5 的训练数据中，因为 GPT-3.5 是基于 2022 年之前发布的数据进行训练的，依据 OpenAI 的说法。

然而，被翻译的原文要老得多（出版时间从 1884 年到 2020 年）。这些原文很可能已被在这项工作中评估的系统（GPT-3.5 和 Google Translate）见过。

此外，尽管被评估的系统不太可能见过这些特定的翻译，但它们可能见过其他语言中的翻译，或者同一语言中但较早发布的翻译。

数据污染有限但仍然存在。我认为完全防止文学文本的数据污染没有更好的办法。但对于新闻等其他类型的文本，这是可能的。

# 一个非常多样的语言对集合

这是这项工作的一个强项：作者评估了非常多样的语言对。

作为源语言，他们选择了来自不同语言家族的语言：印欧语系（罗曼语族、日耳曼语族、斯拉夫语族）、汉藏语系和日琉语系。通过这种方式，他们确保评估能够更准确地识别 GPT-3.5 在翻译具有不同形态特征和书写系统的语言方面的优缺点。

用于评估的翻译语言包括英语（en）、波兰语（pl）、俄语（ru）、捷克语（cs）、法语（fr）、德语（de）、日语（ja）和中文（zh）。

对于目标语言，他们选择了创建“简单”（相似语言）和“困难”（不相似语言）源目标语言对的语言。

例如，捷克语-波兰语是一个简单的语言对，因为这两种语言有很多共同点。另一方面，日语-波兰语是一个极其困难的语言对，因为这两种语言来自非常不同的语言家族，具有不同的语法和书写系统。对这个语言对的机器翻译研究也非常有限。

每种源语言的选定目标语言是英语（en）、日语（ja）和波兰语（pl）。

# 使用 GPT-3.5 进行翻译的提示工程

评估大型语言模型时最关键的步骤之一是设计提示。

机器翻译有许多可能的提示。理想情况下，我们应该广泛评估几个提示，以评估提示选择的影响程度。

我们还必须记住，科学工作得出的结论可能仅对我们评估的非常特定的提示有效。

在评估中包括许多提示是昂贵的，因为我们必须对每个提示运行大型语言模型的推理。实际上，这意味着我们只能选择有限数量的提示进行评估。

他们使用了 5-shot 上下文学习来翻译 GPT-3.5\. 提示中有 5 个翻译示例，更精确地指明了对 GPT-3.5 的期望。

选定的翻译示例对语言模型的翻译质量有着至关重要的影响。正如 [Vilar et al. (2022)](https://arxiv.org/pdf/2211.09102.pdf) 所证明的，示例的翻译质量才是最重要的。

关于示例选择，他们写道：

> 我们从文学文本中手动策划了每对 18 种语言中的五个示例，共计 90 个示例。这些示例来自于不在我们翻译数据集中的小说，因此可能存在主题和风格上的差异 […]

这不是很详细。特别是，我不清楚“策划”涉及什么。策划标准没有提供。

一旦选择，它们包括了三种提示中的例子，这些例子利用了不同大小的上下文。

## 句子级提示模板

使用这个模板，待翻译的段落句子会一个接一个地提供给 GPT。这是标准的序列到序列神经机器翻译系统的工作方式。

> 原文在 [SRC LANG] 中：
> 
> 源句子
> 
> 翻译到 [TRG LANG]：
> 
> 目标句子

*注意：[SRC LANG]和[TRG LANG]分别表示源语言和目标语言。*

## 带上下文提示模板的句子级翻译

翻译仍然是在句子级别进行，但句子是带有上下文的提供给 GPT-3.5 的：段落中句子之前和之后的内容都包含在提示中。

> 原文在 [SRC LANG] 中：
> 
> 源前缀
> 
> <translate> src sent </translate>
> 
> 源后缀
> 
> 翻译到 [TRG LANG]：
> 
> 目标前缀
> 
> <translated> trg sent </translated>

我发现这个设计非常有创意，但也很冒险。根据我的经验，如果我们没有明确地定义标签，GPT 模型可能会很容易混淆。在这种情况下，如果 GPT 只是翻译所有内容，包括标签（<translate> 和 <translated>），我也不会感到惊讶。

## 段落级提示模板

模板与第一个相同，但这里提供的是整段文本而非句子。

> 原文在 [SRC LANG] 中：
> 
> 源段落
> 
> 翻译到 [TRG LANG]：
> 
> 目标段落

现在我们有了提示，我们可以用它们来评估 GPT-3.5 的翻译质量。

# 对 GPT-3.5 段落翻译的评估

这次评估主要旨在回答两个问题：

+   像 GPT-3.5 这样的语言模型在翻译整段文本时是否比翻译单句时表现更好？

+   与 Google 翻译相比，GPT-3.5 在翻译整段文本时表现如何？

对于这次评估，作者主要依靠使用 MQM 框架的人类评估。

如果你对我的工作很熟悉，你已经知道我在写机器翻译评估时有多么苛刻。

[](/scientific-credibility-in-machine-translation-research-pitfalls-and-promising-trends-990ddabe8fb9?source=post_page-----5ed0031ece08--------------------------------) ## 机器翻译研究中的科学可信度：陷阱与有希望的趋势

### 我们是否处于一个转折点？我从对 1000 多篇科学论文的注释中得出的结论。

[towardsdatascience.com

对于这项工作，作者以非常高的科学可信度评估了他们的机器翻译系统。如果你在寻找一个优秀的机器翻译评估的例子，这就是其中之一。*注意：我还推荐阅读“*[*Prompting PaLM for Translation: Assessing Strategies and Performance*](https://arxiv.org/pdf/2211.09102.pdf)*”（Vilar 等，2022 年），这是另一个好的例子，就像我在博客文章“*[*How Good Is Google PaLM at Translation?*](https://medium.com/towards-data-science/how-good-is-google-palm-at-translation-f4a40c2ce562)*”中详细介绍的那样。*

他们没有依赖自动化指标，但仍然提供了更多分析的指标分数。所有复现这些分数的细节也一并提供。这非常罕见。

他们甚至测试了他们人工评估的统计显著性。

## 结果：

+   GPT-3.5 在翻译段落时比翻译单个句子要好。

+   GPT-3.5 优于 Google Translate。

但这些结果在语言对之间有所不同。

对于德语到日语的翻译方向，翻译单个句子的结果更好。这是唯一的例外。根据作者的说法，这是因为用于这个翻译方向的数据有非常长的句子。

令我最惊讶的是，GPT-3.5 在翻译单个句子时也优于 Google Translate。

自动化指标也产生了非常相似的结果：COMET、BLEURT、BERTScore 和 COMET-QE 都一致认为 GPT-3.5 在任何 3 种提示模板下都优于 Google Translate。

论文展示了对其人工评估的非常详细的分析。我不会在本文中进一步讨论，但邀请你阅读。这非常有洞察力。

# GPT 模型在翻译中的局限性。

论文中有一个“局限性”部分（第七部分），作者在这里讨论了使用 GPT 模型进行翻译的局限性。

作者指出，翻译段落时出现的翻译错误与翻译单个句子时的错误不同。

在翻译段落时，GPT-3.5 有时会跳过和忘记段落的一部分内容，导致翻译不正确。我在使用[ChatGPT 进行翻译](https://medium.com/towards-data-science/translate-with-chatgpt-f85609996a7f)时也观察到了类似的行为。

这个问题可以通过对 GPT-3.5 进行机器翻译的微调来纠正。*注意：不要忘记，这里评估的 GPT-3.5 模型尚未针对机器翻译进行微调。*

除此之外，GPT-3.5 仍然会出现一些较为常见的错误，例如翻译错误和语法错误，但这些错误远少于谷歌翻译，评估结果表明了这一点。

# 这项工作的局限性

我努力寻找这项工作的局限性，但在我看来至少有一个。

提示模板的影响尚不清楚。用于段落翻译的具体模板比用于句子翻译的模板表现更好。

但我们是否可以在这种设置下得出结论，即 GPT-3.5 在翻译整段文本时表现更好？

**如果我们更改模板，我们是否仍会得出相同的结论？**

我们无法轻易回答这个问题。我预计这一局限性将会在所有未来评估语言模型的机器翻译研究中出现。

此外，这项工作专注于翻译文学文本。我们不能确定这项工作的结论是否适用于其他类型的文本。我期待阅读未来将填补这一空白的研究。

# 结论

这项工作是机器翻译领域的一个里程碑。

这表明，一个大型语言模型可以超越更标准的神经机器翻译系统，如谷歌翻译，具有非常高的科学可信度。同时，它还表明，大型语言模型在段落级别翻译中能提供比句子级别翻译更好的翻译质量。

通过这项工作和[之前的 PaLM 翻译质量研究](https://medium.com/towards-data-science/how-good-is-google-palm-at-translation-f4a40c2ce562)，我们有越来越多的证据表明，机器翻译的未来将基于大型语言模型。
