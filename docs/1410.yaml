- en: How I Turned My Company’s Docs into a Searchable Database with OpenAI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何将公司的文档转变为可搜索的数据库，利用OpenAI
- en: 原文：[https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=collection_archive---------0-----------------------#2023-04-25](https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=collection_archive---------0-----------------------#2023-04-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=collection_archive---------0-----------------------#2023-04-25](https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736?source=collection_archive---------0-----------------------#2023-04-25)
- en: And how you can do the same with your docs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以及你如何用同样的方法处理你的文档
- en: '[](https://medium.com/@jacob_marks?source=post_page-----4f2d34bd8736--------------------------------)[![Jacob
    Marks, Ph.D.](../Images/94d9832b8706d1044e3195386613bfab.png)](https://medium.com/@jacob_marks?source=post_page-----4f2d34bd8736--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4f2d34bd8736--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4f2d34bd8736--------------------------------)
    [Jacob Marks, Ph.D.](https://medium.com/@jacob_marks?source=post_page-----4f2d34bd8736--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jacob_marks?source=post_page-----4f2d34bd8736--------------------------------)[![Jacob
    Marks, Ph.D.](../Images/94d9832b8706d1044e3195386613bfab.png)](https://medium.com/@jacob_marks?source=post_page-----4f2d34bd8736--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4f2d34bd8736--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4f2d34bd8736--------------------------------)
    [Jacob Marks, Ph.D.](https://medium.com/@jacob_marks?source=post_page-----4f2d34bd8736--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff7dc0c0eae92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=post_page-f7dc0c0eae92----4f2d34bd8736---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4f2d34bd8736--------------------------------)
    ·15 min read·Apr 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff7dc0c0eae92&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=post_page-f7dc0c0eae92----4f2d34bd8736---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4f2d34bd8736--------------------------------)
    ·15分钟阅读·2023年4月25日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&user=Jacob+Marks%2C+Ph.D.&userId=f7dc0c0eae92&source=-----4f2d34bd8736---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----4f2d34bd8736---------------------bookmark_footer-----------)![](../Images/a7959bea4e365ac7dd00c74aaa9d1aff.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4f2d34bd8736&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736&source=-----4f2d34bd8736---------------------bookmark_footer-----------)![](../Images/a7959bea4e365ac7dd00c74aaa9d1aff.png)'
- en: Image courtesy of Unsplash.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自Unsplash。
- en: For the past six months, I’ve been working at series A startup Voxel51, a and
    creator of the [open source computer vision toolkit FiftyOne](https://github.com/voxel51/fiftyone).
    As a machine learning engineer and developer evangelist, my job is to listen to
    our open source community and bring them what they need — new features, integrations,
    tutorials, workshops, you name it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的六个月里，我一直在系列A初创公司Voxel51工作，并且是[开源计算机视觉工具包FiftyOne](https://github.com/voxel51/fiftyone)的创建者。作为一名机器学习工程师和开发者推广员，我的工作是倾听我们的开源社区，满足他们的需求——新的功能、集成、教程、研讨会，等等。
- en: A few weeks ago, we added native support for vector search engines and text
    similarity queries to FiftyOne, so that users can find the most relevant images
    in their (often massive — containing millions or tens of millions of samples)
    datasets, via simple natural language queries.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 几周前，我们为 FiftyOne 添加了对向量搜索引擎和文本相似性查询的原生支持，以便用户可以通过简单的自然语言查询在他们（通常是庞大的——包含数百万或数千万样本的）数据集中找到最相关的图像。
- en: 'This put us in a curious position: it was now possible for people using open
    source FiftyOne to readily search datasets with natural language queries, but
    using our documentation still required traditional keyword search.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们处于一个奇特的位置：现在使用开源 FiftyOne 的人可以轻松地用自然语言查询搜索数据集，但使用我们的文档仍然需要传统的关键字搜索。
- en: We have a lot of documentation, which has its pros and cons. As a user myself,
    I sometimes find that given the sheer quantity of documentation, finding precisely
    what I’m looking for requires more time than I’d like.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有大量文档，这有利有弊。作为用户，我有时发现，由于文档量庞大，找到我确切需要的信息比我希望的时间要长。
- en: 'I was not going to let this fly… so I built this in my spare time:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我不打算就此罢休……所以我在业余时间构建了这个：
- en: '![](../Images/a88b4645cde0b9861a7a24dcf2bf89e3.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a88b4645cde0b9861a7a24dcf2bf89e3.png)'
- en: Semantically search your company’s docs from the command line. Image courtesy
    of author.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从命令行语义化搜索公司文档。图片由作者提供。
- en: 'So, here’s how I turned our docs into a semantically searchable vector database:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这是我如何将我们的文档转换为语义搜索的向量数据库：
- en: '[Converted all of the docs to a unified format](#eb87)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将所有文档转换为统一格式](#eb87)'
- en: '[Split docs into blocks and added some automated cleanup](#8ed1)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将文档拆分为块并添加了一些自动清理](#8ed1)'
- en: '[Computed embeddings for each block](#1a17)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为每个块计算了嵌入](#1a17)'
- en: '[Generated a vector index from these embedding](#34d3)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从这些嵌入生成了一个向量索引](#34d3)'
- en: '[Defined the index query](#87c5)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[定义了索引查询](#87c5)'
- en: '[Wrapped it all in a user-friendly command line interface and Python API](#9d79)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将所有内容封装在用户友好的命令行界面和 Python API 中](#9d79)'
- en: You can find all the code for this post in the [voxel51/fiftyone-docs-search](https://github.com/voxel51/fiftyone-docs-search)
    repo, and it’s easy to install the package locally in edit mode with `pip install
    -e .`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [voxel51/fiftyone-docs-search](https://github.com/voxel51/fiftyone-docs-search)
    仓库中找到本帖的所有代码，并且可以通过 `pip install -e .` 在本地编辑模式中轻松安装包。
- en: 'Better yet, if you want to implement semantic search for your own website using
    this method, you can follow along! Here are the ingredients you’ll need:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的是，如果你想使用这种方法为你自己的网站实现语义搜索，你可以跟着做！以下是你需要的材料：
- en: '*Install the* [*openai*](https://github.com/openai/openai-python) *Python package
    and create an account:* you will use this account to send your docs and queries
    to an inference endpoint, which will return an embedding vector for each piece
    of text.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安装* [*openai*](https://github.com/openai/openai-python) *Python 包并创建一个账户：*
    你将使用此账户将文档和查询发送到推断端点，该端点会返回每个文本片段的嵌入向量。'
- en: '*Install the* [*qdrant-client*](https://github.com/qdrant/qdrant_client) *Python
    package and launch a* [*Qdrant server via Docker*](https://qdrant.tech/): you
    will use [Qdrant](https://qdrant.tech/) to create a locally hosted vector index
    for the docs, against which queries will be run. The Qdrant service will run inside
    a Docker container.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安装* [*qdrant-client*](https://github.com/qdrant/qdrant_client) *Python 包并通过*
    [*Docker 启动 Qdrant 服务器*](https://qdrant.tech/)：你将使用 [Qdrant](https://qdrant.tech/)
    为文档创建一个本地托管的向量索引，查询将对其进行运行。Qdrant 服务将在 Docker 容器中运行。'
- en: Converting the docs to a unified format
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将文档转换为统一格式
- en: My company’s docs are all hosted as HTML documents at [https://docs.voxel51.com](https://docs.voxel51.com).
    A natural starting point would have been to download these docs with Python’s
    [requests](https://pypi.org/project/requests/) library and parse the document
    with [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我公司的文档都托管为 HTML 文档，地址是 [https://docs.voxel51.com](https://docs.voxel51.com)。一个自然的起点是使用
    Python 的 [requests](https://pypi.org/project/requests/) 库下载这些文档，并用 [Beautiful
    Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) 解析文档。
- en: As a developer (and author of many of our docs), however, I thought I could
    do better. I already had a working clone of the GitHub repository on my local
    computer that contained all of the raw files used to generate the HTML docs. Some
    of our docs are written in [Sphinx ReStructured Text (RST)](https://www.sphinx-doc.org/en/master/),
    whereas others, like tutorials, are converted to HTML from Jupyter notebooks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 作为开发者（以及我们许多文档的作者），我认为自己可以做得更好。我已经在本地计算机上有一个 GitHub 仓库的工作副本，其中包含生成 HTML 文档所用的所有原始文件。我们的某些文档是用
    [Sphinx ReStructured Text (RST)](https://www.sphinx-doc.org/en/master/) 编写的，而其他文档，如教程，则从
    Jupyter notebooks 转换为 HTML。
- en: I figured (mistakenly) that the closer I could get to the raw text of the RST
    and Jupyter files, the simpler things would be.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我（错误地）认为，离 RST 和 Jupyter 文件的原始文本越近，事情就会越简单。
- en: RST
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RST
- en: 'In RST documents, sections are delineated by lines consisting only of strings
    of `=`, `-` or `_`. For example, here’s a document from the FiftyOne User Guide
    which contains all three delineators:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RST 文档中，部分由仅包含 `=`、`-` 或 `_` 字符的行来划分。例如，这是 FiftyOne 用户指南中的一个文档，其中包含所有三种划分符：
- en: '![](../Images/3188d8c4ac25ff6414eabdf8675fbdd9.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3188d8c4ac25ff6414eabdf8675fbdd9.png)'
- en: RST document from open source FiftyOne Docs. Image courtesy of author.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 FiftyOne 文档中的 RST 文档。图片由作者提供。
- en: I could then remove all of the RST keywords, such as `toctree`, `code-block`,
    and `button_link` (there were many more), as well as the `:`, `::`, and `..` that
    accompanied a keyword, the start of a new block, or block descriptors.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我可以移除所有的 RST 关键字，如 `toctree`、`code-block` 和 `button_link`（还有许多其他的），以及随关键字、区块开始或区块描述符出现的
    `:`、`::` 和 `..`。
- en: 'Links were easy to take care of too:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 链接也很容易处理：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Things started to get dicey when I wanted to extract the section anchors from
    RST files. Many of our sections had anchors specified explicitly, whereas others
    were left to be inferred during the conversion to HTML.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当我想从 RST 文件中提取部分锚点时，情况开始变得棘手。我们许多部分明确指定了锚点，而其他部分则在转换为 HTML 时被推断出来。
- en: 'Here is an example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the brain.rst file in our User Guide docs (a portion of which is reproduced
    above), the *Visualizing embeddings* section has an anchor `#brain-embeddings-visualization`
    specified by `.. _brain-embeddings-visualization:`. The *Embedding methods* subsection
    which immediately follows, however, is given an auto-generated anchor.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们用户指南文档中的 brain.rst 文件（上面展示的部分），*Visualizing embeddings* 部分有一个由 `.. _brain-embeddings-visualization:`
    指定的锚点 `#brain-embeddings-visualization`。然而，紧随其后的 *Embedding methods* 子部分有一个自动生成的锚点。
- en: 'Another difficulty that soon reared its head was how to deal with tables in
    RST. [List tables](https://sublime-and-sphinx-guide.readthedocs.io/en/latest/tables.html#list-table-directive)
    were fairly straightforward. For instance, here’s a list table from our View Stages
    cheat sheet:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个很快出现的困难是如何处理 RST 中的表格。[List tables](https://sublime-and-sphinx-guide.readthedocs.io/en/latest/tables.html#list-table-directive)
    相对简单。例如，这是我们 View Stages 备忘单中的一个列表表格：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[Grid tables](https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html#grid-tables),
    on the other hand, can get messy fast. They give docs writers great flexibility,
    but this same flexibility makes parsing them a pain. Take this table from our
    Filtering cheat sheet:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[Grid tables](https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html#grid-tables)
    另一方面，很快就会变得凌乱。它们给文档作者提供了很大的灵活性，但这种灵活性使得解析起来非常麻烦。看看我们 Filtering 备忘单中的这张表格：'
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Within a table, rows can take up arbitrary numbers of lines, and columns can
    vary in width. Code blocks within grid table cells are also difficult to parse,
    as they occupy space on multiple lines, so their content is interspersed with
    content from other columns. This means that code blocks in these tables need to
    be effectively reconstructed during the parsing process.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在表格中，行可以占用任意数量的行，列的宽度也可以变化。网格表格单元格中的代码块也很难解析，因为它们占用多行空间，因此它们的内容与其他列的内容交错在一起。这意味着这些表格中的代码块需要在解析过程中有效地重建。
- en: Not the end of the world. But also not ideal.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是世界末日，但也不是理想状态。
- en: Jupyter
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jupyter
- en: 'Jupyter notebooks turned out to be relatively simple to parse. I was able to
    read the contents of a Jupyter notebook into a list of strings, with one string
    per cell:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter notebooks 解析起来相对简单。我能够将 Jupyter notebook 的内容读取为字符串列表，每个单元格一个字符串：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Furthermore, the sections were delineated by Markdown cells starting with `#`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，部分由以 `#` 开头的 Markdown 单元格划分。
- en: Nevertheless, given the challenges posed by RST, I decided to turn to HTML and
    treat all of our docs on equal footing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管面临 RST 带来的挑战，我决定转向 HTML 并平等对待我们的所有文档。
- en: HTML
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: HTML
- en: I built the HTML docs from my local install with `bash generate_docs.bash`,
    and began parsing them with Beautiful Soup. However, I soon realized that when
    RST code blocks and tables with inline code were being converted to HTML, although
    they were rendering correctly, the HTML itself was incredibly unwieldy. Take our
    filtering cheat sheet for example.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我通过`bash generate_docs.bash`从本地安装生成了 HTML 文档，并开始用 Beautiful Soup 解析它们。然而，我很快意识到，当
    RST 代码块和包含内联代码的表格被转换为 HTML 时，虽然渲染正确，但 HTML 本身却非常难以处理。以我们的过滤器备忘单为例。
- en: 'When rendered in a browser, the code block preceding the *Dates and times*
    section of our filtering cheat sheet looks like this:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当在浏览器中渲染时，我们过滤器备忘单中*日期和时间*部分之前的代码块如下所示：
- en: '![](../Images/79ae2b0dd021cda1c5fd07f853789c0a.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/79ae2b0dd021cda1c5fd07f853789c0a.png)'
- en: Screenshot from cheat sheet in open source FiftyOne Docs. Image courtesy of
    author.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 FiftyOne 文档中的备忘单截图。图片由作者提供。
- en: 'The raw HTML, however, looks like this:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，原始 HTML 看起来是这样的：
- en: '![](../Images/be7d519067dbbfc0ee85a947f7011790.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be7d519067dbbfc0ee85a947f7011790.png)'
- en: RST cheat sheet converted to HTML. Image courtesy of author.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: RST 备忘单转换为 HTML。图片由作者提供。
- en: This is not impossible to parse, but it is also far from ideal.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是不可能解析，但也远非理想。
- en: Markdown
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Markdown
- en: Fortunately, I was able to overcome these issues by converting all of the HTML
    files to Markdown with [markdownify](https://pypi.org/project/markdownify/). Markdown
    had a few key advantages that made it the best fit for this job.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我通过使用 [markdownify](https://pypi.org/project/markdownify/) 将所有 HTML 文件转换为
    Markdown 解决了这些问题。Markdown 有几个关键优点，使其成为这个工作的最佳选择。
- en: '**Cleaner than HTML**: code formatting was simplified from the spaghetti strings
    of `span` elements to inline code snippets marked with single `` ` `` before and
    after, and blocks of code were marked by triple quotes [PRE5] [PRE6]'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**比 HTML 更干净**：代码格式从一串杂乱的`span`元素简化为用单个`` ` ``标记的内联代码片段，代码块则用三重引号标记 [PRE5]
    [PRE6]'
- en: document = document.replace("\_", "_").replace("\*", "*")
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: document = document.replace("\_", "_").replace("\*", "*")
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: text_and_code = page_md.split('[PRE8]
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: text_and_code = page_md.split('[PRE8]
- en: 'Then I identified the start of a new section with a `#` to start a line in
    a text block. I extracted the section title and anchor from this line:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我用 `#` 标记文本块中的新节的开始。我从这一行中提取了节标题和锚点：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: And assigned each block of text or code to the appropriate section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将每个文本或代码块分配到适当的部分。
- en: Initially, I also tried splitting the text blocks into paragraphs, hypothesizing
    that because a section may contain information about many different topics, the
    embedding for that entire section may not be similar to an embedding for a text
    prompt concerned with only one of those topics. This approach, however, resulted
    in top matches for most search queries disproportionately being single line paragraphs,
    which turned out to not be terribly informative as search results.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，我还尝试将文本块拆分成段落，假设因为一个部分可能包含许多不同主题的信息，该部分的嵌入可能与只涉及其中一个主题的文本提示的嵌入不相似。然而，这种方法导致大多数搜索查询的最佳匹配过于集中在单行段落上，结果显示这些搜索结果并不十分有用。
- en: '*Check out the accompanying* [*GitHub repo*](https://github.com/voxel51/fiftyone-docs-search)
    *for the implementation of these methods that you can try out on your own docs!*'
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*查看附带的* [*GitHub 仓库*](https://github.com/voxel51/fiftyone-docs-search) *，了解这些方法的实现，并尝试在您自己的文档中应用！*'
- en: Embedding text and code blocks with OpenAI
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 OpenAI 嵌入文本和代码块
- en: With documents converted, processed, and split into strings, I generated an
    embedding vector for each of these blocks. Because large language models are flexible
    and generally capable by nature, I decided to treat both text blocks and code
    blocks on the same footing as pieces of text, and to embed them with the same
    model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 将文档转换、处理并拆分为字符串后，我为这些块生成了嵌入向量。由于大型语言模型本质上灵活且通常能力强，我决定将文本块和代码块视为相同的文本，并用相同的模型进行嵌入。
- en: I used OpenAI’s [text-embedding-ada-002 model](https://platform.openai.com/docs/guides/embeddings/embedding-models)
    because it is easy to work with, achieves the highest performance out of all of
    OpenAI’s embedding models (on the [BEIR benchmark](https://arxiv.org/pdf/2104.08663.pdf)),
    and is also the cheapest. It’s so cheap in fact ($0.0004/1K tokens) that generating
    all of the embeddings for the FiftyOne docs only cost a few cents! As OpenAI themselves
    put it, “We recommend using text-embedding-ada-002 for nearly all use cases. It’s
    better, cheaper, and simpler to use.”
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了 OpenAI 的 [text-embedding-ada-002 模型](https://platform.openai.com/docs/guides/embeddings/embedding-models)，因为它易于使用，且在所有
    OpenAI 的嵌入模型中（在 [BEIR 基准](https://arxiv.org/pdf/2104.08663.pdf)上）表现最佳，并且也是最便宜的。实际上，它的费用非常低（$0.0004/1K
    标记），以至于为 FiftyOne 文档生成所有嵌入仅花费了几美分！正如 OpenAI 自己所说，“我们建议几乎所有用例都使用 text-embedding-ada-002。它更好、更便宜、更简单。”
- en: With this embedding model, you can generate a 1536-dimensional vector representing
    any input prompt, up to 8,191 tokens (approximately 30,000 characters).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个嵌入模型，你可以生成一个 1536 维的向量，表示任何输入提示，最多 8,191 个标记（大约 30,000 个字符）。
- en: 'To get started, you need to create an OpenAI account, generate an API key at
    [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys),
    export this API key as an environment variable with:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用，你需要创建一个 OpenAI 账户，在 [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
    生成 API 密钥，使用以下命令将该 API 密钥导出为环境变量：
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You will also need to install the [openai Python library](https://github.com/openai/openai-python):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要安装 [openai Python 库](https://github.com/openai/openai-python)：
- en: '[PRE11]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'I wrote a wrapper around OpenAI’s API that takes in a text prompt and returns
    an embedding vector:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我编写了一个 OpenAI API 的包装器，该包装器接受文本提示并返回嵌入向量：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To generate embeddings for all of our docs, we just apply this function to each
    of the subsections — text and code blocks — across all of our docs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成所有文档的嵌入，我们只需对所有文档中的每个子部分——文本和代码块——应用此函数。
- en: Creating a Qdrant vector index
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 Qdrant 向量索引
- en: 'With embeddings in hand, I created a vector index to search against. I chose
    to use Qdrant for the same reasons we chose to add native Qdrant support to FiftyOne:
    it’s open source, free, and easy to use.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有嵌入后，我创建了一个向量索引用于搜索。我选择使用 Qdrant 的原因与我们选择在 FiftyOne 中添加本地 Qdrant 支持的原因相同：它是开源的、免费的，并且易于使用。
- en: 'To get started with Qdrant, you can pull a pre-built Docker image and run the
    container:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Qdrant，你可以拉取一个预构建的 Docker 镜像并运行容器：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Additionally, you will need to install the Qdrant Python client:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还需要安装 Qdrant Python 客户端：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'I created the Qdrant collection:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了 Qdrant 集合：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'I then created a vector for each subsection (text or code block):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我为每个子部分（文本或代码块）创建了一个向量：
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: For each vector, you can provide additional context as part of the [payload](https://qdrant.tech/documentation/payload/).
    In this case, I included the URL (and anchor) where the result can be found, the
    *type* of document, so the user can specify if they want to search through all
    of the docs, or just certain types of docs, and the contents of the string which
    generated the embedding vector. I also added the block type (text or code), so
    if the user is looking for a code snippet, they can tailor their search to that
    purpose.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个向量，你可以提供额外的上下文作为 [payload](https://qdrant.tech/documentation/payload/) 的一部分。在这种情况下，我包括了结果可以找到的
    URL（及锚点）、文档的 *类型*，以便用户可以指定是否希望搜索所有文档，或只是某些类型的文档，以及生成嵌入向量的字符串内容。我还添加了块类型（文本或代码），以便如果用户正在寻找代码片段，他们可以将搜索定制为此目的。
- en: 'Then I added these vectors to the index, one page at a time:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我将这些向量一个页面一个页面地添加到索引中：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Querying the index
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询索引
- en: Once the index has been created, running a search on the indexed documents can
    be accomplished by embedding the query text with the same embedding model, and
    then searching the index for similar embedding vectors. With a Qdrant vector index,
    a basic query can be performed with the Qdrant client’s `search()` command.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了索引，可以通过使用相同的嵌入模型对查询文本进行嵌入，并在索引中搜索相似的嵌入向量来执行对索引文档的搜索。使用 Qdrant 向量索引，可以通过
    Qdrant 客户端的 `search()` 命令执行基本查询。
- en: To make my company’s docs searchable, I wanted to allow users to filter by section
    of the docs, as well as by the type of block that was encoded. In the parlance
    of vector search, filtering results while still ensuring that a predetermined
    number of results (specified by the `top_k` argument) will be returned is referred
    to as *pre-filtering*.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使公司的文档可搜索，我希望允许用户按文档的部分以及编码的块类型进行筛选。在向量搜索术语中，筛选结果同时确保返回预定数量的结果（由`top_k`参数指定）被称为*预筛选*。
- en: 'To achieve this, I wrote a programmatic filter:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我编写了一个程序化过滤器：
- en: '[PRE18]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The internal `_parse_doc_types()` and `_parse_block_types()` functions handle
    cases where the argument is string or list-valued, or is None.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 内部的`_parse_doc_types()`和`_parse_block_types()`函数处理参数为字符串、列表或None的情况。
- en: Then I wrote a function `query_index()` that takes the user’s text query, pre-filters,
    searches the index, and extracts relevant information from the payload. The function
    returns a list of tuples of the form `(url, contents, score)`, where the score
    indicates how good of a match the result is to the query text.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我写了一个`query_index()`函数，它接受用户的文本查询，进行预筛选，搜索索引，并从负载中提取相关信息。该函数返回一个元组列表，形式为`(url,
    contents, score)`，其中得分表示结果与查询文本的匹配程度。
- en: '[PRE19]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Writing the search wrapper
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写搜索包装器
- en: The final step was providing a clean interface for the user to semantically
    search against these “vectorized” docs.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是为用户提供一个干净的界面，以便在这些“向量化”文档中进行语义搜索。
- en: I wrote a function `print_results()`, which takes the query, results from `query_index()`,
    and a `score` argument (whether or not to print the similarity score), and prints
    the results in an easy to interpret way. I used the [rich](https://rich.readthedocs.io/en/stable/introduction.html)
    Python package to format hyperlinks in the terminal so that when working in a
    terminal that supports hyperlinks, clicking on the hyperlink will open the page
    in your default browser. I also used [webbrowser](https://docs.python.org/3/library/webbrowser.html)
    to automatically open the link for the top result, if desired.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我编写了一个`print_results()`函数，它接受查询、`query_index()`的结果和一个`score`参数（是否打印相似度分数），并以易于理解的方式打印结果。我使用了[rich](https://rich.readthedocs.io/en/stable/introduction.html)
    Python包来格式化终端中的超链接，以便在支持超链接的终端中，点击超链接将打开默认浏览器中的页面。如果需要，我还使用了[webbrowser](https://docs.python.org/3/library/webbrowser.html)来自动打开最顶端结果的链接。
- en: '![](../Images/8e615542c724d5d85be45aba81a7b73a.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8e615542c724d5d85be45aba81a7b73a.png)'
- en: Display search results with rich hyperlinks. Image courtesy of author.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 显示带有丰富超链接的搜索结果。图片由作者提供。
- en: 'For Python-based searches, I created a class `FiftyOneDocsSearch` to encapsulate
    the document search behavior, so that once a `FiftyOneDocsSearch` object has been
    instantiated (potentially with default settings for search arguments):'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于Python的搜索，我创建了一个`FiftyOneDocsSearch`类来封装文档搜索行为，因此一旦实例化了`FiftyOneDocsSearch`对象（可能使用默认的搜索参数设置）：
- en: '[PRE20]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You can search within Python by calling this object. To query the docs for
    “How to load a dataset”, for instance, you just need to run:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过调用这个对象在Python中进行搜索。例如，要查询“如何加载数据集”，只需运行：
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/3c701dc79f3dbded374c760c96741967.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3c701dc79f3dbded374c760c96741967.png)'
- en: Semantically search your company’s docs within a Python process. Image courtesy
    of author.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python进程中对公司的文档进行语义搜索。图片由作者提供。
- en: 'I also used [argparse](https://docs.python.org/3/library/argparse.html) to
    make this docs search functionality available via the command line. When the package
    is installed, the docs are CLI searchable with:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我还使用了[argparse](https://docs.python.org/3/library/argparse.html)来通过命令行提供此文档搜索功能。当包被安装后，可以通过CLI搜索文档：
- en: '[PRE22]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Just for fun, because `fiftyone-docs-search query` is a bit cumbersome, I added
    an alias to my `.zsrch` file:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 仅为有趣，因为`fiftyone-docs-search query`有点繁琐，我在我的`.zsrch`文件中添加了一个别名：
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'With this alias, the docs are searchable from the command line with:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个别名，可以通过命令行搜索文档：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Conclusion
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Coming into this, I already fashioned myself a power user of my company’s open
    source Python library, FiftyOne. I had written many of the docs, and I had used
    (and continue to use) the library on a daily basis. But the process of turning
    our docs into a searchable database forced me to understand our docs on an even
    deeper level. It’s always great when you’re building something for others, and
    it ends up helping you as well!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，我已经把自己看作是公司开源Python库FiftyOne的重度用户。我编写了许多文档，并且每天都在使用（并继续使用）这个库。但将我们的文档转变为可搜索的数据库的过程迫使我以更深刻的方式理解我们的文档。当你为他人构建某些东西时，它也能帮助到你，这总是很棒的！
- en: 'Here’s what I learned:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我学到的：
- en: '**Sphinx RST is cumbersome**: it makes beautiful docs, but it is a bit of a
    pain to parse'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sphinx RST使用繁琐**：它能生成美观的文档，但解析起来有点麻烦'
- en: '**Don’t go crazy with preprocessing:** OpenAI’s text-embeddings-ada-002 model
    is great at understanding the meaning behind a text string, even if it has slightly
    atypical formatting. Gone are the days of stemming and painstakingly removing
    stop words and miscellaneous characters.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要在预处理上过度**：OpenAI的text-embeddings-ada-002模型非常擅长理解文本字符串背后的意义，即使它有稍微不典型的格式。再也不用进行词干提取和费力地去除停用词及各种字符了。'
- en: '**Small semantically meaningful snippets are best**: break your documents up
    into the smallest possible meaningful segments, and retain context. For longer
    pieces of text, it is more likely that overlap between a search query and a part
    of the text in your index will be obscured by less relevant text in the segment.
    If you break the document up too small, you run the risk that many entries in
    the index will contain very little semantic information.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小的语义有意义的片段最好**：将文档分解成尽可能小的有意义的部分，并保留上下文。对于较长的文本，搜索查询与索引中文本部分的重叠更可能被段落中的不相关文本遮掩。如果你将文档拆分得过小，许多索引条目可能包含很少的语义信息。'
- en: '**Vector search is powerful**: with minimal lift, and without any fine-tuning,
    I was able to dramatically enhance the searchability of our docs. From initial
    estimates, it appears that this improved docs search is more than twice as likely
    to return relevant results than the old keyword search approach. Furthermore,
    the semantic nature of this vector search approach means that users can now search
    with arbitrarily phrased, arbitrarily complex queries, and are guaranteed to get
    the specified number of results.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量搜索非常强大**：只需最少的工作量，不需任何微调，我就能显著提高文档的可搜索性。从初步估计来看，这种改进的文档搜索比旧的关键字搜索方法返回相关结果的可能性提高了两倍以上。此外，这种向量搜索方法的语义特性意味着用户现在可以用任意措辞、任意复杂的查询进行搜索，并且保证得到指定数量的结果。'
- en: If you find yourself (or others) constantly digging or sifting through treasure
    troves of documentation for specific kernels of information, I encourage you to
    adapt this process for your own use case. You can modify this to work for your
    personal documents, or your company’s archives. And if you do, I guarantee you’ll
    walk away from the experience seeing your documents in a new light!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现自己（或他人）不断地挖掘或筛选大量文档以寻找特定信息，我鼓励你将这一过程调整到你的用例中。你可以修改它以适用于你的个人文档或公司的档案。如果你这样做，我保证你会从中得到新的启发！
- en: Here are a few ways you could extend this for your own docs!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些方法可以扩展到你自己的文档中！
- en: '[Hybrid search](https://www.pinecone.io/learn/hybrid-search-intro/): combine
    vector search with traditional keyword search'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[混合搜索](https://www.pinecone.io/learn/hybrid-search-intro/): 将向量搜索与传统的关键字搜索结合起来'
- en: 'Go global: Use [Qdrant Cloud](https://cloud.qdrant.io/) to store and query
    the collection in the cloud'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全球化：使用[Qdrant Cloud](https://cloud.qdrant.io/)在云中存储和查询集合
- en: 'Incorporate web data: use [requests](https://pypi.org/project/requests/) to
    download HTML directly from the web'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入网络数据：使用[requests](https://pypi.org/project/requests/)直接从网络下载HTML
- en: 'Automate updates: use [Github Actions](https://docs.github.com/en/actions)
    to trigger recomputation of embeddings whenever the underlying docs change'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动更新：使用[Github Actions](https://docs.github.com/en/actions)在底层文档更改时触发嵌入的重新计算
- en: 'Embed: wrap this in a Javascript element and drop it in as a replacement for
    a traditional search bar'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入：将其包装在一个Javascript元素中，替代传统的搜索框
- en: All code used to build the package is open source, and can be found in the [voxel51/fiftyone-docs-search](https://github.com/voxel51/fiftyone-docs-search)
    repo.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 构建包所用的所有代码都是开源的，可以在[voxel51/fiftyone-docs-search](https://github.com/voxel51/fiftyone-docs-search)仓库中找到。
