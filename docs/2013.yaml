- en: 5 Signs That Your Data is Modeled Poorly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/5-signs-that-your-data-is-modeled-poorly-a646e8d33be0?source=collection_archive---------7-----------------------#2023-06-20](https://towardsdatascience.com/5-signs-that-your-data-is-modeled-poorly-a646e8d33be0?source=collection_archive---------7-----------------------#2023-06-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Common Challenges In The Cloud era
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mattgazzano?source=post_page-----a646e8d33be0--------------------------------)[![Matthew
    Gazzano](../Images/23f154b154d05847c2c13ea17ceb7a57.png)](https://medium.com/@mattgazzano?source=post_page-----a646e8d33be0--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a646e8d33be0--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a646e8d33be0--------------------------------)
    [Matthew Gazzano](https://medium.com/@mattgazzano?source=post_page-----a646e8d33be0--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F626000912ce9&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-signs-that-your-data-is-modeled-poorly-a646e8d33be0&user=Matthew+Gazzano&userId=626000912ce9&source=post_page-626000912ce9----a646e8d33be0---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a646e8d33be0--------------------------------)
    ·7 min read·Jun 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa646e8d33be0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-signs-that-your-data-is-modeled-poorly-a646e8d33be0&user=Matthew+Gazzano&userId=626000912ce9&source=-----a646e8d33be0---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa646e8d33be0&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F5-signs-that-your-data-is-modeled-poorly-a646e8d33be0&source=-----a646e8d33be0---------------------bookmark_footer-----------)![](../Images/6ab63520d19e990128b66de3607dc34e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Photo](https://unsplash.com/photos/lRoX0shwjUQ) by [Jan Antonin Kolar](https://unsplash.com/@jankolar)
    on [Unsplash](https://unsplash.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: With the expansion of cloud technology and cheap storage costs in the past decade,
    many organizations have amassed significantly larger volumes of data than previously
    imaginable. The pay-as-you go model offered by many cloud data warehouse providers
    ([AWS](https://aws.amazon.com/), [GCP](https://cloud.google.com/gcp?utm_source=google&utm_medium=cpc&utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1605212&utm_content=text-ad-none-any-DEV_c-CRE_491349594127-ADGP_Desk+%7C+BKWS+-+EXA+%7C+Txt+_+Google+Cloud+Platform+Core-KWID_43700064423315751-aud-1436107373682%3Akwd-26415313501&utm_term=KW_google+cloud+platform-ST_google+cloud+platform&gclid=CjwKCAjw-b-kBhB-EiwA4fvKrCt5QBXsaaB2cBQvmRsEyXEsswdmkhHXOP3PQtEGbPxx07cD1S5cABoCFJcQAvD_BwE&gclsrc=aw.ds&hl=en),
    [Azure](https://azure.microsoft.com/en-us)) has decreased the need for up-front
    capital resources and consideration of digital infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: The good news is that this ultimately makes data science efforts more accessible
    for most organizations.
  prefs: []
  type: TYPE_NORMAL
- en: The bad news is that Data Lakes are turning into more like Data Swamps.
  prefs: []
  type: TYPE_NORMAL
- en: What is Data Modeling? And What Challenges Surround it?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It's often difficult for Data Engineers to communicate the value of a well-modeled
    ecosystem to upper management. This is because all that is visible to stakeholders
    are the BI tools and predictive models that get presented. However, poorly modeled
    data causes major setbacks to analytics teams from a data governance perspective.
    This inevitably slows down workflow, introduces repetitive tasks, decreases reporting
    accuracy, as well as many other negative side effects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Defining “Well-Modeled” data is a topic of its own. But you can think of it
    by the following concepts in your Data Warehouse:'
  prefs: []
  type: TYPE_NORMAL
- en: A clear pattern exists on how to find data tables that relate to business entities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An intentional / known modeling technique is used, such as a dimensional model,
    entity relationship model, data vault, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table and field naming conventions are consistent, well documented, and hold
    business value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It should also be noted that there is a holistic and multi-system approach
    to data modeling. It starts in your OLTP (Online Transaction Processing) system,
    which is where data gets initially recorded. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: CRM systems like [Salesforce](https://www.salesforce.com/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Point-of-sale systems like [Stripe](https://stripe.com/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ecommerce platforms like [Amazon](https://www.amazon.com/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ideally, your data should be normalized in [3rd normal form](https://www.geeksforgeeks.org/third-normal-form-3nf/)
    when collected through a source system. Then it should be ingested into an analytics
    environment, otherwise known as an OLAP (Online Analytical Processing) system
    where an analytical modeling technique is applied. In the context of this article,
    the OLAP system is synonymous with a cloud data warehouse. But OLAP systems can
    also include independently hosted tools like SQL Server, MySQL, or PostgreSQL.
  prefs: []
  type: TYPE_NORMAL
- en: While data analysts and data scientists only interact with the OLAP system,
    an organization’s data modeling strategy needs to factor in both OLTP and OLAP
    to be sustainable.
  prefs: []
  type: TYPE_NORMAL
- en: Here are 5 key signs that illustrate your analytics environment is poorly modeled.
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1.) Tribal Knowledge is Required to Understand Where to Find Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order for a new analyst to be successful when hired, they need a clear roadmap
    as to what data is available in the Data Warehouse, where it is sourced, and what
    its business context is. However, teams with poorly modeled data often struggle
    to onboard new candidates, not understanding why it is taking new hires so long
    to answer basic business questions. Without the proper mentorship, analytics teams
    can experience high churn rates because new members are not given the tools they
    need to succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Data Analysts and Data Scientists should be focused on answering business problems
    and not wasting time to find where business entities live. The faster teams can
    become familiar with what data is available, the quicker that dashboards and predictive
    models can be completed. This ultimately boosts the team’s productivity.
  prefs: []
  type: TYPE_NORMAL
- en: If there are only a handful of analysts who know how to answer basic business
    questions, that is a problem. Working in such a siloed approach isn't scalable
    and will only limit the number of problems that the team is able to solve.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ba6eb54e39b719cb755fb9048b9fbe69.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Photo](https://unsplash.com/photos/IgUR1iX0mqM) by [Desola Lanre-Ologun](https://unsplash.com/@disruptxn)
    on [Unsplash](https://unsplash.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: 2.) Different Analysts are Producing Different Results For The Same Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If there is no single source of truth, it can be easy for different team members
    to calculate the same metric in different ways. For example, how is Revenue defined?
    And what tables are used to calculate this? There needs to be a clear path to
    define business logic, which all starts with an intentional data model.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve worked in environments where there were 3 different tables that have represented
    the same business entity, which all utilized different SQL logic to arrive at
    a similar, but not the same record output. Couple this scenario with a poorly
    managed reporting request queue, and you have two different analysts answering
    the same question with different results. This not only causes stakeholders to
    lose trust in the data, but also requires tedious and unneeded reconciling work
    across teams.
  prefs: []
  type: TYPE_NORMAL
- en: 3.) Teams Need to Reuse Redundant Code Blocks for Business Logic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I’ve seen teams have a google sheet of SQL CASE statements which outline specific
    business metrics. These were long in nature & difficult to read through. While
    it attempts to offer consistency across teams, the problem with this is that it
    violates DRY (Don't Repeat Yourself) principles within the organization.
  prefs: []
  type: TYPE_NORMAL
- en: For many teams with this type of issue, using a transformation tool such as
    DBT allows Analytics Engineers to define business logic in one place and then
    have analysts reference it in many places.
  prefs: []
  type: TYPE_NORMAL
- en: Think about the following example— if you're an ecommerce company and there
    is a complex way to calculate page views (which is okay), why would you be distributing
    & duplicating that business logic to happen in your BI tool? Not only is this
    risky in case logic isn't copied and pasted in the exact same way every time,
    but it is a waste of compute, which is the largest expense from most cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: To solve for this, consider mapping out common aggregations and business logic
    that needs to take place, run a transformation job daily (or as frequently as
    needed) and write it to a table. Then have your BI layer sit on top of that.
  prefs: []
  type: TYPE_NORMAL
- en: 4.) Your Data Warehouse Performs Poorly
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As pointed out above, poorly modeled data introduces redundancy. But it also
    creates unnecessary complexity. Excess computing resources is a biproduct of this,
    and all cloud data warehouses have limits up to a certain pricing threshold. Once
    that limit is reached, executing new queries may become extremely slow and not
    even feasible in some cases.
  prefs: []
  type: TYPE_NORMAL
- en: Any Data Engineer will tell you that just purchasing additional resources is
    not a sustainable solution to this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Long and complex queries not only take long to execute on their own, but will
    diminish the available resources in your environment. Consider an example where
    you need to run a query that involves 20 joins. There are very few scenarios where
    this is an ideal solution, as it illustrates that the data needed to answer a
    business problem is not stored in a format that is easily accessible. This many
    joins can be computationally expensive, especially when the related tables are
    large in volume or if the ON clause involves multiple columns. If you are implementing
    a dimensional model, your team might want to consider creating a new fact table
    in your database in these scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Resources are measured in different ways depending on what cloud provider you’re
    using, but they all follow the same concept of using a dedicated number of virtual
    CPUs. For example, BigQuery uses the concept of [slots](https://cloud.google.com/bigquery/docs/slots),
    which effectively is the number of available computing resources used to execute
    a query. Organizations with on demand pricing receive 2,000 slots to be used at
    any given point in time. So, if one query is highly complex & takes up more than
    the available number of slots, other queries will sit in the queue before they
    can even be executed.
  prefs: []
  type: TYPE_NORMAL
- en: 5.) You Often Have to Hard Code Values in SQL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hard coded values are often a tell-tale sign that there is required data missing
    in your Data Warehouse. In the context of a dimensional model, this usually means
    that a new dimension table needs to be created to source additional columns.
  prefs: []
  type: TYPE_NORMAL
- en: '[Zach Quinn](https://zachl-quinn.medium.com/) wrote an [article](https://medium.com/learning-sql/sql-users-reduce-your-case-statements-with-a-lookup-table-d09da47bf65)
    which outlines this concept really well, demonstrating how to eliminate long CASE
    statements with a lookup table. Putting this example in the context of a dimensional
    model — suppose your organization needs to do a lot of geospatial analysis. You
    have a *customer_dimension* table that gives the state abbreviation, but you want
    to display it as a full state name. You could write something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'But this type of CASE statement isn''t sustainable. If we want to improve upon
    this solution in greater detail, we need to join a *zip_code_dimension* tableto
    the *customer_dimension* table. You’ll see below that a *zip_code_dimension* will
    give us even greater granularity in an analysis. The table might look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/80b22cf424ec049028ea0f961df9694a.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by Author
  prefs: []
  type: TYPE_NORMAL
- en: 'So with that new table, imagine being able to run *this* query instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Not only is this a more elegant and readable query to produce the full state
    name, but it lets us answer more questions. With the *zip_code_dimension*, we
    can now append the latitude and longitude of that zip code to create map visualizations
    in a cleaner format. Additionally, there are a handful of other dimensional fields
    that could have taken hundreds of lines to hard code in if we wanted to include
    them in the output (country, timezone etc).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you found any of the above points to be relevant in your environment, it
    may be time to holistically look at your data pipelines and understand where analytics
    teams need to fill in the gap. To be able to model your teams data properly, you
    need to be able to conceptualize relevant business entities and organize them
    in a way that is conducive to common questions asked within your organization.
    There is no one size fits all approach, but it needs to be clear to all team members
    and created in a consistent way.
  prefs: []
  type: TYPE_NORMAL
