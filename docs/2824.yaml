- en: 'Model Explainability, Revisited: SHAP and Beyond'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/model-explainability-revisited-shap-and-beyond-1c6ee85b294?source=collection_archive---------9-----------------------#2023-09-07](https://towardsdatascience.com/model-explainability-revisited-shap-and-beyond-1c6ee85b294?source=collection_archive---------9-----------------------#2023-09-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://towardsdatascience.medium.com/?source=post_page-----1c6ee85b294--------------------------------)[![TDS
    Editors](../Images/4b2d1beaf4f6dcf024ffa6535de3b794.png)](https://towardsdatascience.medium.com/?source=post_page-----1c6ee85b294--------------------------------)[](https://towardsdatascience.com/?source=post_page-----1c6ee85b294--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----1c6ee85b294--------------------------------)
    [TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----1c6ee85b294--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-revisited-shap-and-beyond-1c6ee85b294&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----1c6ee85b294---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----1c6ee85b294--------------------------------)
    ·Sent as a [Newsletter](/newsletter?source=post_page-----1c6ee85b294--------------------------------)
    ·3 min read·Sep 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F1c6ee85b294&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-revisited-shap-and-beyond-1c6ee85b294&user=TDS+Editors&userId=7e12c71dfa81&source=-----1c6ee85b294---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1c6ee85b294&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmodel-explainability-revisited-shap-and-beyond-1c6ee85b294&source=-----1c6ee85b294---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: The rapid rise of large language models has dominated much of the conversation
    around AI in recent months—which is understandable, given LLMs’ novelty and the
    speed of their integration into the daily workflows of data science and ML professionals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Longstanding concerns around the performance of models and the risks they pose
    remain crucial, however, and explainability is at the core of these questions:
    how and why do models produce the predictions they offer us? What’s inside the
    black box?'
  prefs: []
  type: TYPE_NORMAL
- en: This week, we’re returning to the topic of model explainability with several
    recent articles that tackle its intricacies with nuance and offer hands-on approaches
    for practitioners to experiment with. Happy learning!
  prefs: []
  type: TYPE_NORMAL
- en: At the core of any explainability challenge is the question of which features
    in your data contribute the most to a model’s prediction. [Khouloud El Alami](https://medium.com/u/9c6a36490614?source=post_page-----1c6ee85b294--------------------------------)’s
    [**introduction to feature-importance analysis with SHAP**](/feature-importance-analysis-with-shap-i-learned-at-spotify-aacd769831b4)
    is a beginner-friendly resource, based on the author’s research project at Spotify.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you’ve already worked with SHAP in the past and are looking to expand your
    toolkit, [Conor O'Sullivan](https://medium.com/u/4ae48256fb37?source=post_page-----1c6ee85b294--------------------------------)
    offers a [**hands-on guide to handling more specialized use cases**](/shap-for-binary-and-multiclass-target-variables-ff2f43de0cf4),
    namely how to display SHAP plots for classification problems and aggregate SHAP
    values for multi-class targets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a fresh perspective on the possibilities that model explainability opens
    up, don’t miss [Diksha Sen Chaudhury](https://medium.com/u/d7f3ce137d78?source=post_page-----1c6ee85b294--------------------------------)’s
    recent writeup on [**a project that brings together healthcare data and machine
    learning**](/chronic-kidney-disease-prediction-a-fresh-perspective-6ad7fa85eb0d).
    Diksha’s goal was to show how using SHAP can make a model not just interpretable,
    but also useful for researchers who’d like to benchmark results against the findings
    in medical literature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9081a137af7f4c49a19c007b1f108324.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Alina Kovalchuk](https://unsplash.com/@moonofviolet?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: As [Vegard Flovik](https://medium.com/u/17ff8967433?source=post_page-----1c6ee85b294--------------------------------)
    aptly puts it, “for applications within safety-critical heavy-asset industries,
    where errors can lead to disastrous outcomes, lack of transparency can be a major
    roadblock for adoption.” To address this gap, Vegard provides a [**thorough guide
    to the open-source Iguanas framework**](/iguanas-more-than-just-reptiles-exploring-the-iguanas-toolkit-for-xai-beyond-black-box-models-4330ad69029),
    and shows how you can leverage its automated rule-generation powers for increased
    explainability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While SHAP values have proven beneficial in many real-world scenarios, they,
    too, come with limitations. [Samuele Mazzanti](https://medium.com/u/e16f3bb86e03?source=post_page-----1c6ee85b294--------------------------------)
    cautions against placing too much weight (pun intended!) on feature importance,
    and [**recommends paying equal attention to error contribution**](/your-features-are-important-it-doesnt-mean-they-are-good-ff468ae2e3d4),
    since “the fact that a feature is important doesn’t imply that it is beneficial
    for the model.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We know that the beginning of September is a hectic time of year for many of
    you, but if you have a bit more time to spare, you can’t go wrong with any of
    our other recommended reads this week:'
  prefs: []
  type: TYPE_NORMAL
- en: If you’re in a data science bootcamp right now—or are thinking of attending
    one in the future—[Alexandra Oberemok](https://medium.com/u/346def7ad86?source=post_page-----1c6ee85b294--------------------------------)’s
    [comprehensive guide to making the most of the experience](/how-to-ace-the-data-science-bootcamp-a-complete-guide-aad1eb10da18)
    is a must-read.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Runners, this one’s for you: [barrysmyth](https://medium.com/u/a995c3b2ae8?source=post_page-----1c6ee85b294--------------------------------)’s
    new deep dive [explores marathon data to assess different strategies](/the-controlled-fade-b972e11ab452)
    for optimizing your performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For his debut TDS article, [Christian Burke](https://medium.com/u/764fa444fa3?source=post_page-----1c6ee85b294--------------------------------)
    takes us [behind the scenes of an innovative MOMA generative-AI art project](/free-from-limitations-the-validation-of-machine-hallucinations-at-moma-7d56a38c335a)
    in which he played a key part.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Olga Chernytska](https://medium.com/u/cc932e019245?source=post_page-----1c6ee85b294--------------------------------)
    shared a new installment in her excellent “Building Better ML Systems” series,
    this time [focusing on all things baselines, metrics, and test sets](/building-better-ml-systems-chapter-3-modeling-let-the-fun-begin-73059c75e1d5).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not sure how to deal with missing data? [Miriam Santos](https://medium.com/u/243289394aaa?source=post_page-----1c6ee85b294--------------------------------)
    provides a [one-stop resource on this perennial issue](/missing-data-demystified-the-absolute-primer-for-data-scientists-8c9244c764c4),
    and explains how to identify and mark missing values in real-world datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you’re looking to [sink your teeth into a detailed technical explainer](/the-gradient-descent-algorithm-4d54e0d446cd),
    [Antonieta Mastrogiuseppe](https://medium.com/u/a8ee237975ec?source=post_page-----1c6ee85b294--------------------------------)’s
    overview of the gradient descent algorithm is clear and well-executed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thank you for supporting the work of our authors! If you enjoy the articles
    you read on TDS, consider [becoming a Medium member](https://bit.ly/tds-membership)
    — it unlocks our entire archive (and every other post on Medium, too).
  prefs: []
  type: TYPE_NORMAL
