# 2023 年最佳：关于 ChatGPT 和 LLMs

> 原文：[`towardsdatascience.com/tds-best-of-2023-on-chatgpt-and-llms-83bdfbb2136d?source=collection_archive---------3-----------------------#2023-12-14`](https://towardsdatascience.com/tds-best-of-2023-on-chatgpt-and-llms-83bdfbb2136d?source=collection_archive---------3-----------------------#2023-12-14)

[](https://towardsdatascience.medium.com/?source=post_page-----83bdfbb2136d--------------------------------)![TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----83bdfbb2136d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----83bdfbb2136d--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----83bdfbb2136d--------------------------------) [TDS Editors](https://towardsdatascience.medium.com/?source=post_page-----83bdfbb2136d--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e12c71dfa81&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftds-best-of-2023-on-chatgpt-and-llms-83bdfbb2136d&user=TDS+Editors&userId=7e12c71dfa81&source=post_page-7e12c71dfa81----83bdfbb2136d---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----83bdfbb2136d--------------------------------) · 发送为 [通讯](https://towardsdatascience.com/newsletter?source=post_page-----83bdfbb2136d--------------------------------) · 阅读时间 5 分钟·2023 年 12 月 14 日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F83bdfbb2136d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftds-best-of-2023-on-chatgpt-and-llms-83bdfbb2136d&user=TDS+Editors&userId=7e12c71dfa81&source=-----83bdfbb2136d---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F83bdfbb2136d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftds-best-of-2023-on-chatgpt-and-llms-83bdfbb2136d&source=-----83bdfbb2136d---------------------bookmark_footer-----------)

你可能会说 2023 年对数据科学家和机器学习专业人士来说是多事之年，但这并不能*完全*捕捉到过去 12 个月我们在这个领域所经历的繁忙活动量。

尽管我们总是力图抵制炒作和夸张，但我们不得不承认，是的，我们确实看到了一些戏剧性的变化，既包括从业者的观点，也包括社会整体对人工智能及其对我们日常生活影响的看法。ChatGPT 在 2022 年最后几周的发布远不是这种过渡的唯一因素，但很难否认它既是催化剂又是象征性的焦点。

当我们考虑如何盘点 2023 年我们作者的最佳和最受欢迎作品时，回顾关于大语言模型的文章——尤其是那个无处不在的聊天机器人——成为了一个非常自然的选择。我们在这里呈现的文章并不全面，但*确实*提供了一个具有代表性的样本，展示了你们这些读者对哪些文章反响最强烈——无论是你们无法停止阅读和分享的文章，还是那些在 TDS 及其他地方引发了最深刻讨论的文章。

在我们深入探讨过去一年中最引起关注的文章之前，我们想花一点时间感谢我们的整个社区对我们的支持。我们特别感谢我们了不起的作者们、[Medium](https://medium.com/u/a32c340ea342?source=post_page-----83bdfbb2136d--------------------------------)的合作伙伴、慷慨提供专业知识的志愿编辑组，以及我们的两位前同事和杰出编辑，[凯特琳·金迪格](https://medium.com/u/2155e1f99318?source=post_page-----83bdfbb2136d--------------------------------)和[凯瑟琳·普雷里](https://medium.com/u/29c9531ee6f5?source=post_page-----83bdfbb2136d--------------------------------)。

+   **ChatGPT 如何运作：模型背后的机器人**在最不令人惊讶的发展中，[莫莉·鲁比](https://medium.com/u/7a38f8e9fb80?source=post_page-----83bdfbb2136d--------------------------------)的易于理解且信息丰富的解释成为了我们 2023 年最受欢迎的文章。如果你还没读过，现在也不算太晚！

+   **封闭的 AI 模型造成糟糕的基准**在一个后 ChatGPT 世界中，自然语言处理研究将会采取什么方向？[安娜·罗杰斯](https://medium.com/u/201bcd64e17?source=post_page-----83bdfbb2136d--------------------------------)考察了这个迅速变化领域的现状。

+   **ChatGPT 能写出比数据分析师更好的 SQL 吗？**虽然大语言模型是否对整个职业构成威胁仍有待观察，[玛丽·陈](https://medium.com/u/4cfa1d0b321f?source=post_page-----83bdfbb2136d--------------------------------)在 ChatGPT 发布后不久便花时间调查了其编程技能。

+   **GPT 是一个不可靠的信息库**在对人工智能幻觉的前瞻性观察中，[诺布尔·阿克森](https://medium.com/u/68605bd278a3?source=post_page-----83bdfbb2136d--------------------------------)深入探讨了将大语言模型当作可靠搜索引擎使用的潜在风险。

![](img/ad425592ddeb01443641c0c130a09902.png)

图片由 [米奇·豪普特](https://unsplash.com/@rocinante_11?utm_source=medium&utm_medium=referral) 拍摄，来源于 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

+   **如何将任何文本转换成概念图** 由于 LLM，NLP 领域的可能性得到了探索，[Rahul Nayak](https://medium.com/u/473e87f4b733?source=post_page-----83bdfbb2136d--------------------------------) 提供了一种将文本语料库转换为知识图谱的实用方法。

+   **并非所有美好：ChatGPT 的阴暗面** 从内建偏见到隐私和剽窃问题，[Mary Reagan PhD](https://medium.com/u/4a596f4380a0?source=post_page-----83bdfbb2136d--------------------------------) 揭示了 ChatGPT 崛起后出现的一些主要风险。

+   **零 ETL、ChatGPT 与数据工程的未来** ChatGPT 和类似工具将如何影响日常的数据工程工作流？[Barr Moses](https://medium.com/u/2818bac48708?source=post_page-----83bdfbb2136d--------------------------------) 分享了对“后现代数据栈”未来的见解。

+   **构建你的第一个 LLM 应用所需了解的一切** 2023 年是 LLM 驱动的应用程序构建过程变得实际民主化的一年，这在很大程度上得益于像 [Dominik Polzer](https://medium.com/u/3ab8d3143e32?source=post_page-----83bdfbb2136d--------------------------------) 的广泛分享的教程。

+   **GPT-4 与 ChatGPT：训练、性能、能力与局限性的探讨** 在发布 ChatGPT 几个月后，OpenAI 通过最新的 GPT-4 提升了标准，[Mary Newhauser](https://medium.com/u/6b27bdb820b9?source=post_page-----83bdfbb2136d--------------------------------) 迅速提供了这两款产品的详细对比。

+   **TimeGPT：首个时间序列预测的基础模型** 随着年份的推进，我们遇到了越来越多针对特定用例的 LLM 解决方案。[Marco Peixeiro](https://medium.com/u/741c1c8fcfbd?source=post_page-----83bdfbb2136d--------------------------------) 对 TimeGPT 进行了解释，它是一个定制化基础模型的示例。

+   **掌握客户细分与 LLM** LLM 的实际应用案例及其支持的产品每天都在不断增长；[Damian Gil](https://medium.com/u/87864cbc1dda?source=post_page-----83bdfbb2136d--------------------------------) 为营销人员和商业战略家概述了一个有前途的方向。

+   **开始使用 LangChain：构建 LLM 驱动应用程序的初学者指南** 与 ChatGPT 一起，LangChain 成为了构建基于 LLM 的产品的热门工具；[Leonie Monigatti](https://medium.com/u/3a38da70d8dc?source=post_page-----83bdfbb2136d--------------------------------) 撰写了这本资源指南，适合任何对其进行探索的人。

+   **新的 ChatGPT 提示工程技术：程序模拟** 将我们的需求和目标转化为 LLM 可以正确解读的语言仍然是一个挑战。[Giuseppe Scalamogna](https://medium.com/u/e039aa8b7221?source=post_page-----83bdfbb2136d--------------------------------) 揭示了一种更有效的提示设计创新框架。

+   **GPT 模型如何工作** 作为对 GPT 模型背后的数学和理论的全面且易于理解的入门介绍，[Beatriz Stollnitz](https://medium.com/u/1c8863892480?source=post_page-----83bdfbb2136d--------------------------------)的深入分析仍然是初学者和经验丰富的从业者的顶级选择。

+   **如何从零开始构建 LLM** 如果你偏好更具实践性的学习方法，[Shawhin Talebi](https://medium.com/u/f3998e1cd186?source=post_page-----83bdfbb2136d--------------------------------) 的教程将带你从数据整理到模型评估——即使你不打算在家里创建下一个 Llama 或 Falcon 模型，它也值得一探！

+   **RAG 与微调——哪个是提升 LLM 应用的最佳工具？** 随着我们了解了预训练模型的局限性，新的方法出现以提升其性能。[Heiko Hotz](https://medium.com/u/993c21f1b30f?source=post_page-----83bdfbb2136d--------------------------------) 提供了对两种主要选项的有用比较：微调和检索增强生成（RAG）。

+   **在 CPU 上本地运行 Llama 2 进行文档问答** 能够与我们自己的文本文件、PDF 和音频记录“对话”已经成为 LLM 的一个流行日常应用场景。[Kenneth Leung](https://medium.com/u/dcd08e36f2d0?source=post_page-----83bdfbb2136d--------------------------------) 的逐步指南展示了我们如何在本地机器上创建这样的工作流程。

+   **LangChain 中链式 LLMs、代理和工具的温和介绍** 对于任何刚刚开始使用 LLMs 的人，[Dr. Varshita Sher](https://medium.com/u/f8ca36def59?source=post_page-----83bdfbb2136d--------------------------------)关于 LangChain 构建模块的有用且全面的教程是必读之作。

+   **分子生物学中的大型语言模型** 探索 LLMs 在科学研究中的潜力，[Serafim Batzoglou](https://medium.com/u/ccf342949c4?source=post_page-----83bdfbb2136d--------------------------------)的深度挖掘关注了其在分子生物学中的影响，应用范围从基因结构预测到药物发现。

**敬请关注！** 在 2023 年，我们发布了大量优秀文章，涵盖了远超 LLMs 和 ChatGPT 的广泛话题。下周，我们将把今年的最后一期 Variable 专注于数据科学和编程技能、职业道路以及特别项目的精彩文章。

再次感谢您在 2023 年支持我们作者的工作！如果您喜欢 TDS 上的文章，可以考虑[成为 Medium 的朋友会员](https://blog.medium.com/become-a-friend-of-medium-dd2fa7bf16c3)：这是一个新的会员等级，能为您喜爱的作者提供更大的奖励。

直到下一个 Variable，

TDS 编辑部
