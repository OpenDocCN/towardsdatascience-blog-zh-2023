- en: A New Kind of Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/a-new-kind-of-engineering-fee04ce567ba?source=collection_archive---------1-----------------------#2023-04-15](https://towardsdatascience.com/a-new-kind-of-engineering-fee04ce567ba?source=collection_archive---------1-----------------------#2023-04-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How LLM-based micro AGIs will require a paradigm shift towards modelling thought
    processes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@johannaappel?source=post_page-----fee04ce567ba--------------------------------)[![Johanna
    Appel](../Images/e8c6e95e56bb7dbfdf05f8610741d113.png)](https://medium.com/@johannaappel?source=post_page-----fee04ce567ba--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fee04ce567ba--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fee04ce567ba--------------------------------)
    [Johanna Appel](https://medium.com/@johannaappel?source=post_page-----fee04ce567ba--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fede7381126aa&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-new-kind-of-engineering-fee04ce567ba&user=Johanna+Appel&userId=ede7381126aa&source=post_page-ede7381126aa----fee04ce567ba---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fee04ce567ba--------------------------------)
    ·4 min read·Apr 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffee04ce567ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-new-kind-of-engineering-fee04ce567ba&user=Johanna+Appel&userId=ede7381126aa&source=-----fee04ce567ba---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffee04ce567ba&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fa-new-kind-of-engineering-fee04ce567ba&source=-----fee04ce567ba---------------------bookmark_footer-----------)![](../Images/3f4d7cf690eb080c4b6241c59aecb09d.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by author based on photo by [ALAN DE LA CRUZ](https://unsplash.com/@alandelacruz4?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/photos/TOOhhlGHOsQ?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  prefs: []
  type: TYPE_NORMAL
- en: As of writing this (April 2023), frameworks such as langchain [1] are pioneering
    more and more complex use-cases for LLMs. Recently, software agents augmented
    with LLM-based reasoning capabilities have started the race towards a human-level
    of machine intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: What are we talking about?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Agents](https://en.wikipedia.org/wiki/Intelligent_agent) are a pattern in
    software systems; they are algorithms that can make decisions and interact relatively
    autonomously with their environment. In the case of langchain agents, the environment
    is usually the text-in/text-out based interfaces to the internet, the user or
    other agents and tools.'
  prefs: []
  type: TYPE_NORMAL
- en: Running with this concept, other projects [2,3] have started working on more
    general problem solvers (some sort of ‘micro’ artificial general intelligence,
    or AGI — an AI system that approaches human-level reasoning capabilities). Although
    the current incarnation of these systems are still quite monolithic in that they
    come as one piece of software that takes goals/tasks/ideas as input, it is easy
    to see in their execution that they are relying on multiple distinct sub-systems
    under the hood.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c090fe80e6208388617dbbc47a4d6265.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Significant Gravitas ([https://github.com/Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT),
    30/03/2023)
  prefs: []
  type: TYPE_NORMAL
- en: 'The new paradigm we see with these systems is that they model thought processes:
    “think critically and examine your results”, “consult several sources”, “reflect
    on the quality of your solution”, “debug it using external tooling”, … these are
    close to how a human would think as well.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, in every day (human) life, we hire experts to do jobs that require a specific
    expertise. And my prediction is that in the near future, we will hire some sort
    of cognitive engineers to model AGI thought processes, probably by building specific
    [multi-agent systems](https://en.wikipedia.org/wiki/Multi-agent_system), to solve
    specific tasks with a better quality.
  prefs: []
  type: TYPE_NORMAL
- en: Why would I assume this? Why are monolithic AGIs not necessary good enough?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From how we work with LLMs already today, we are already doing this — modelling
    cognitive processes. We do this in specific ways, using prompt engineering and
    lots of results from adjacent fields of research, to achieve a required output
    quality. Even though what I described above might seem futuristic, this is already
    the status quo.
  prefs: []
  type: TYPE_NORMAL
- en: Where do we go from here? We will probably see ever smarter AI systems that
    might even surpass human-level at some point. And as they get ever smarter, it
    will get ever harder to align them with our goals — with what we want them to
    do. AGI alignment and the security concerns with over-powerful unaligned AIs is
    already a really active field of research, and the stakes are high — as explained
    in detail e.g. by Eliezer Yudkowski [4].
  prefs: []
  type: TYPE_NORMAL
- en: My hunch is that smaller i.e. ‘dumber’ systems are easier to align, and will
    therefore deliver a certain result with a certain quality with a higher probability.
    And these systems are precisely what we can build using the cognitive engineering
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: What we should be doing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We should get a good experimental understanding of how to build specialized
    AGI systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From this experience we should create and iterate the right abstractions to
    better enable the modelling of these systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the abstractions in place, we can start creating re-usable building blocks
    of thought, just like we use re-usable building blocks to create user interfaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the nearer future we will understand patterns and best practices of modelling
    these intelligent systems, and with that experience will come understanding of
    which architectures can lead to which outcomes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As a positive side effect, through this work and experience gain, it may be
    possible to learn how to better align smarter AGIs as well.
  prefs: []
  type: TYPE_NORMAL
- en: Where this will lead
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I expect to see a merge of knowledge from different disciplines into this emerging
    field soon.
  prefs: []
  type: TYPE_NORMAL
- en: Research from multi-agent systems and how to use them for problem-solving, as
    well as insights from psychology, business management and process modelling all
    can be beneficially be integrated into this new paradigm and into the emerging
    abstractions.
  prefs: []
  type: TYPE_NORMAL
- en: We will also need to think about how these systems can best be interacted with.
    E.g. human feedback loops, or at least regular evaluation points along the process,
    can help to achieve better results — you may know this personally from working
    with ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: This is a UX pattern previously unseen, where the computer becomes more like
    a co-worker or co-pilot that does the heavy lifting of low-level research, formulation,
    brainstorming, automation or reasoning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: About the author
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Johanna Appel is co-founder of the machine-intelligence consulting company [Altura.ai](https://altura.ai)
    GmbH, based in Zurich, Switzerland.
  prefs: []
  type: TYPE_NORMAL
- en: She helps companies to profit from these ‘micro’ AGI systems by integrating
    them into their existing business processes.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] Langchain GitHub Repository, [https://github.com/hwchase17/langchain](https://github.com/hwchase17/langchain)'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] AutoGPT GitHub Repository, [https://github.com/Significant-Gravitas/Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] BabyAGI GitHub Repository, [https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] “Eliezer Yudkowsky: Dangers of AI and the End of Human Civilization”, Lex
    Fridman Podcast [#368](https://www.youtube.com/hashtag/368), [https://www.youtube.com/watch?v=AaTRHFaaPG8](https://www.youtube.com/watch?v=AaTRHFaaPG8)'
  prefs: []
  type: TYPE_NORMAL
