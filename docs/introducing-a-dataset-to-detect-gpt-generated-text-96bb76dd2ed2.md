# 介绍一个用于检测 GPT 生成文本的数据集

> 原文：[https://towardsdatascience.com/introducing-a-dataset-to-detect-gpt-generated-text-96bb76dd2ed2?source=collection_archive---------7-----------------------#2023-02-08](https://towardsdatascience.com/introducing-a-dataset-to-detect-gpt-generated-text-96bb76dd2ed2?source=collection_archive---------7-----------------------#2023-02-08)

## 如何为 ChatGPT 检测模型创建数据集

[](https://medium.com/@aadityaubhat?source=post_page-----96bb76dd2ed2--------------------------------)[![Aaditya Bhat](../Images/4ae4a03d798d4a3fbec02d81c9c87146.png)](https://medium.com/@aadityaubhat?source=post_page-----96bb76dd2ed2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----96bb76dd2ed2--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----96bb76dd2ed2--------------------------------) [Aaditya Bhat](https://medium.com/@aadityaubhat?source=post_page-----96bb76dd2ed2--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Feff870d7210e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-a-dataset-to-detect-gpt-generated-text-96bb76dd2ed2&user=Aaditya+Bhat&userId=eff870d7210e&source=post_page-eff870d7210e----96bb76dd2ed2---------------------post_header-----------) 发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----96bb76dd2ed2--------------------------------) ·4 min read·2023年2月8日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F96bb76dd2ed2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-a-dataset-to-detect-gpt-generated-text-96bb76dd2ed2&user=Aaditya+Bhat&userId=eff870d7210e&source=-----96bb76dd2ed2---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F96bb76dd2ed2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fintroducing-a-dataset-to-detect-gpt-generated-text-96bb76dd2ed2&source=-----96bb76dd2ed2---------------------bookmark_footer-----------)![](../Images/f19e3823d8d934d82e0773690e2b7474.png)

照片由 [Markus Spiske](https://unsplash.com/@markusspiske?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 提供，来源于 [Unsplash](https://unsplash.com/photos/iar-afB0QQw?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

随着像 ChatGPT 这样的大型语言模型取得突破性成功，人们正在寻找将这些模型应用于日常生活的创新方式。然而，这也导致了一些意外后果，如学生在作业和考试中作弊、使用 ChatGPT 发布研究论文，甚至诈骗者利用这些模型来欺骗他人。为了解决这些问题，对能够检测 GPT 模型生成文本的模型的需求越来越大。构建强大 GPT 生成文本检测模型的一个关键要求是访问一个包含大量人工编写和 GPT 生成响应的数据集。本文介绍了这样一个数据集，由 150k 人工编写和 GPT 生成的维基百科主题回应组成，并概述了未来生成类似数据集的框架。

# 数据集

[GPT-wiki-intro 数据集](https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro) 在 Hugging Face 上提供。该数据集包含 150,000 个维基百科主题的人工编写和 GPT（Curie）生成的介绍。用于生成 GPT 响应的提示如下：

```py
f"200 word wikipedia style introduction on '{title}'
{starter_text}"
```

其中 `title` 是维基百科页面的标题，`starter_text` 是介绍段落中的前 7 个词。该数据集还具有有用的元数据，如 title_len、wiki_intro_len、generated_intro_len、prompt_tokens、generated_text_tokens 等。数据集的架构如下：

```py
----------------------------------------------------------------------------
|Column               |Datatype|Description                                |
|---------------------|--------|-------------------------------------------|
|id                   |int64   |ID                                         |
|url                  |string  |Wikipedia URL                              |
|title                |string  |Title                                      |
|wiki_intro           |string  |Introduction paragraph from wikipedia      |
|generated_intro      |string  |Introduction generated by GPT (Curie) model|
|title_len            |int64   |Number of words in title                   |
|wiki_intro_len       |int64   |Number of words in wiki_intro              |
|generated_intro_len  |int64   |Number of words in generated_intro         |
|prompt               |string  |Prompt used to generate intro              |
|generated_text       |string  |Text continued after the prompt            |
|prompt_tokens        |int64   |Number of tokens in the prompt             |
|generated_text_tokens|int64   |Number of tokens in generated text         |
----------------------------------------------------------------------------
```

该数据集以 Creative Commons 许可证共享，可以用于分发、混合、调整和构建。生成该数据集的代码可以在[这里](https://github.com/aadityaubhat/wiki_gpt)找到。

# 框架

该数据集是检测 GPT 生成文本的一般用途的良好起点。但如果你有特定的用例，例如检测 ChatGPT 生成的测试/作业问题的回答、识别消息是否由人类还是聊天机器人发送，或者你需要特定领域的大型数据集，你可以使用该框架生成自己的数据集。数据集生成过程涉及三个主要步骤：

1.  获取锚数据集

1.  清理锚数据集

1.  用人工编写/GPT 生成的数据扩充数据集

## **获取锚数据集**

在这一步中，我们获取锚数据集。这将是为特定用例现成的现有数据。对于[GPT-wiki-intro数据集](https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro)，锚数据集是[wikipedia数据集](https://huggingface.co/datasets/wikipedia#licensing-information)，该数据集包含各种语言的清理文章。对于检测考试和作业作弊，锚数据集可以是之前学生提交的问答对。如果你没有明确定义的锚数据集，可以探索Hugging Face和Kaggle上与用例匹配的各种开源数据集。锚数据集不必是人工编写的，我们也可以使用GPT生成的数据作为锚数据。例如，我们可以使用[ChatGPT提示响应库](https://www.emergentmind.com/)的数据。

## 清理锚数据集

一旦我们拥有锚数据集，我们需要清理数据以保留最相关的信息。ChatGPT检测模型对文本长度非常敏感。这些模型在较小的文本上表现不佳。我们可以设定一个阈值，并过滤掉任何短于该阈值的响应。例如，在GPT-wiki-intro数据集中，我们过滤掉所有引言长度少于150字或超过350字的行。我们还过滤掉标题超过三个词的所有行。在这一步中，我们还需要决定数据集的总大小。由于使用人工编写或GPT生成的响应来增强数据将会很昂贵，我们需要确定我们用例所需的最小数据集大小。

## 增强数据集，加入人工编写或GPT生成的数据

这是数据集生成的最终步骤。在此步骤中，我们通过人工编写或GPT生成的数据来增强锚数据集。这一步中最重要的是确定用于生成GPT响应的**提示**或由人类回答的**问题**。为了最终确定提示，我们可以利用[OpenAI Playground](https://platform.openai.com/playground)测试不同的提示、模型、温度、频率惩罚和存在惩罚。为了增加数据集的多样性，我们可以最终确定n个提示，并统一使用这些提示以获取响应。在人类回应的情况下，我们需要通过向小型调查人群提供不同的问题变体来最终确定问题，然后检查结果以最终确定n个问题。一旦提示或问题确定，我们可以使用OpenAI API生成GPT生成的响应，或使用像Mechanical Turk这样的服务获取人工编写的响应。

# 结论

总之，随着像ChatGPT这样的巨大语言模型的广泛使用，对能够检测这些模型生成的文本的模型的需求也在不断增加。本文介绍了[GPT-wiki-intro 数据集](https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro)并概述了生成类似数据集的框架。这些数据集的可用性将在开发用于检测GPT生成文本的强大模型以及应对这些模型使用的不良后果方面发挥关键作用。

# 引用

如果您觉得这项工作有帮助，请考虑引用：

```py
@misc {aaditya_bhat_2023,
    author       = { {Aaditya Bhat} },
    title        = { GPT-wiki-intro (Revision 0e458f5) },
    year         = 2023,
    url          = { https://huggingface.co/datasets/aadityaubhat/GPT-wiki-intro },
    doi          = { 10.57967/hf/0326 },
    publisher    = { Hugging Face }
}
```
