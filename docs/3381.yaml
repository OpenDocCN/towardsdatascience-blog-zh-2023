- en: 'TSMixer: The Latest Forecasting Model by Google'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb?source=collection_archive---------3-----------------------#2023-11-14](https://towardsdatascience.com/tsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb?source=collection_archive---------3-----------------------#2023-11-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Explore the architecture of TSMixer and implement it in Python for a long-horizon
    multivariate forecasting task
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)[![Marco
    Peixeiro](../Images/7cf0a81d87281d35ff47f51e3026a3e9.png)](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)
    [Marco Peixeiro](https://medium.com/@marcopeixeiro?source=post_page-----2fd1e29a8ccb--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=post_page-741c1c8fcfbd----2fd1e29a8ccb---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2fd1e29a8ccb--------------------------------)
    ·12 min read·Nov 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2fd1e29a8ccb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&user=Marco+Peixeiro&userId=741c1c8fcfbd&source=-----2fd1e29a8ccb---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2fd1e29a8ccb&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ftsmixer-the-latest-forecasting-model-by-google-2fd1e29a8ccb&source=-----2fd1e29a8ccb---------------------bookmark_footer-----------)![](../Images/e73873566af0876cf840a6284a7f2f21.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Zdeněk Macháček](https://unsplash.com/@zmachacek?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: The field of time series forecasting continues to be in effervescence, with
    many important recent contributions like N-HiTS, PatchTST, TimesNet and of course
    TimeGPT.
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, the Transformer architecture unlocked unprecedented performance
    in the field of natural language processing (NLP), but that is not true for time
    series forecasting.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, many Transformer-based model were proposed like Autoformer, Informer,
    FEDformer, and more. Those models are often very long to train and it turns out
    that simple linear models outperform them on many benchmark datasets (see [Zheng
    et al., 2022](https://arxiv.org/pdf/2205.13504.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: To that point, in September 2023, researchers from Google Cloud AI Research
    proposed **TSMixer**, a Multi-layer Perceptron (MLP) based model that focuses
    on mixing time and feature dimensions to make better predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In their paper [TSMixer: An All-MLP Architecture for Time Series Forecasting](https://arxiv.org/pdf/2303.06053.pdf),
    the authors demonstrate that this model achieves state-of-the-art performance
    on many benchmark datasets, while remaining simple to implement.'
  prefs: []
  type: TYPE_NORMAL
