- en: 'The Secret to Improved NLP: An In-Depth Look at the nn.Embedding Layer in PyTorch'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进 NLP 的秘密：深入了解 PyTorch 中的 nn.Embedding 层
- en: 原文：[https://towardsdatascience.com/the-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16?source=collection_archive---------0-----------------------#2023-01-24](https://towardsdatascience.com/the-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16?source=collection_archive---------0-----------------------#2023-01-24)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16?source=collection_archive---------0-----------------------#2023-01-24](https://towardsdatascience.com/the-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16?source=collection_archive---------0-----------------------#2023-01-24)
- en: Dissecting the `nn.Embedding` layer in PyTorch and a complete guide on how it
    works
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析 PyTorch 中的 `nn.Embedding` 层以及它的完整工作指南
- en: '[](https://medium.com/@will.badr?source=post_page-----6e901e193e16--------------------------------)[![Will
    Badr](../Images/46a4737eaedc1cb30f4f11ceb8373528.png)](https://medium.com/@will.badr?source=post_page-----6e901e193e16--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6e901e193e16--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6e901e193e16--------------------------------)
    [Will Badr](https://medium.com/@will.badr?source=post_page-----6e901e193e16--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@will.badr?source=post_page-----6e901e193e16--------------------------------)[![Will
    Badr](../Images/46a4737eaedc1cb30f4f11ceb8373528.png)](https://medium.com/@will.badr?source=post_page-----6e901e193e16--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6e901e193e16--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6e901e193e16--------------------------------)
    [Will Badr](https://medium.com/@will.badr?source=post_page-----6e901e193e16--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F551ba3f6b67d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16&user=Will+Badr&userId=551ba3f6b67d&source=post_page-551ba3f6b67d----6e901e193e16---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6e901e193e16--------------------------------)
    ·8 min read·Jan 24, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e901e193e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16&user=Will+Badr&userId=551ba3f6b67d&source=-----6e901e193e16---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F551ba3f6b67d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16&user=Will+Badr&userId=551ba3f6b67d&source=post_page-551ba3f6b67d----6e901e193e16---------------------post_header-----------)
    发表在 [数据科学的秘密](https://towardsdatascience.com/?source=post_page-----6e901e193e16--------------------------------)
    · 8分钟阅读 · 2023年1月24日'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e901e193e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16&source=-----6e901e193e16---------------------bookmark_footer-----------)![](../Images/78883177665ed8578c3715ef39211129.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e901e193e16&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-secret-to-improved-nlp-an-in-depth-look-at-the-nn-embedding-layer-in-pytorch-6e901e193e16&source=-----6e901e193e16---------------------bookmark_footer-----------)![](../Images/78883177665ed8578c3715ef39211129.png)'
- en: OpenAI DALL-E Generated Image
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI DALL-E 生成的图像
- en: You might have seen the famous PyTorch *nn.Embedding()* layer in multiple neural
    network architectures that involves natural language processing (NLP). This is
    one of the simplest and most important layers when it comes to designing advanced
    NLP architectures. Let me explain what it is, in simple terms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能在多个涉及自然语言处理（NLP）的神经网络架构中见过著名的 PyTorch *nn.Embedding()* 层。设计先进的 NLP 架构时，这是最简单且最重要的层之一。让我用简单的术语来解释一下它是什么。
- en: After spending some time looking into its C++ source code, here is what I found.
    The *nn.Embedding* layer is a simple lookup table that maps an index value to
    a weight matrix of a certain dimension. This simple operation is the foundation
    of many advanced NLP architectures, allowing for the processing of discrete input
    symbols in a continuous space. During the training the parameters of the *nn.Embedding*
    layer in a neural network are adjusted in order to optimize the performance of
    the model. Specifically, the embedding matrix is updated via backpropagation to
    minimize the loss function. This can be thought of as learning a mapping from
    discrete input tokens (such as words) to continuous embedding vectors in a high-dimensional
    space, where the vectors are optimised to represent the meaning or context of
    the input tokens in relation to the task the…
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在花了一些时间查看其 C++ 源代码后，我发现了以下内容。*nn.Embedding* 层是一个简单的查找表，它将索引值映射到某个维度的权重矩阵。这个简单的操作是许多高级
    NLP 架构的基础，使得在连续空间中处理离散输入符号成为可能。在训练过程中，神经网络中 *nn.Embedding* 层的参数会被调整，以优化模型的性能。具体来说，通过反向传播更新嵌入矩阵，以最小化损失函数。这可以被视为从离散输入标记（如单词）到高维空间中连续嵌入向量的映射学习，其中向量被优化以表示输入标记的含义或上下文，关联到任务的…
