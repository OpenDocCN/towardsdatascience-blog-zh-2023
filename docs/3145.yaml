- en: The Current State of Continual Learning in AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《人工智能中的持续学习现状》
- en: 原文：[https://towardsdatascience.com/the-current-state-of-continual-learning-in-ai-af4a05c42f3c?source=collection_archive---------1-----------------------#2023-10-18](https://towardsdatascience.com/the-current-state-of-continual-learning-in-ai-af4a05c42f3c?source=collection_archive---------1-----------------------#2023-10-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/the-current-state-of-continual-learning-in-ai-af4a05c42f3c?source=collection_archive---------1-----------------------#2023-10-18](https://towardsdatascience.com/the-current-state-of-continual-learning-in-ai-af4a05c42f3c?source=collection_archive---------1-----------------------#2023-10-18)
- en: Why is ChatGPT only trained up until 2021?
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么 ChatGPT 只训练到 2021 年？
- en: '[](https://medium.com/@jon.flynn2?source=post_page-----af4a05c42f3c--------------------------------)[![Jon
    Flynn](../Images/492cef280f4ea0b002e5d00ad2e083a5.png)](https://medium.com/@jon.flynn2?source=post_page-----af4a05c42f3c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af4a05c42f3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af4a05c42f3c--------------------------------)
    [Jon Flynn](https://medium.com/@jon.flynn2?source=post_page-----af4a05c42f3c--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jon.flynn2?source=post_page-----af4a05c42f3c--------------------------------)[![Jon
    Flynn](../Images/492cef280f4ea0b002e5d00ad2e083a5.png)](https://medium.com/@jon.flynn2?source=post_page-----af4a05c42f3c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af4a05c42f3c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af4a05c42f3c--------------------------------)
    [Jon Flynn](https://medium.com/@jon.flynn2?source=post_page-----af4a05c42f3c--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3ee742fae3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-current-state-of-continual-learning-in-ai-af4a05c42f3c&user=Jon+Flynn&userId=a3ee742fae3&source=post_page-a3ee742fae3----af4a05c42f3c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af4a05c42f3c--------------------------------)
    ·23 min read·Oct 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf4a05c42f3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-current-state-of-continual-learning-in-ai-af4a05c42f3c&user=Jon+Flynn&userId=a3ee742fae3&source=-----af4a05c42f3c---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa3ee742fae3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-current-state-of-continual-learning-in-ai-af4a05c42f3c&user=Jon+Flynn&userId=a3ee742fae3&source=post_page-a3ee742fae3----af4a05c42f3c---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af4a05c42f3c--------------------------------)
    ·23分钟阅读·2023年10月18日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf4a05c42f3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-current-state-of-continual-learning-in-ai-af4a05c42f3c&user=Jon+Flynn&userId=a3ee742fae3&source=-----af4a05c42f3c---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf4a05c42f3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-current-state-of-continual-learning-in-ai-af4a05c42f3c&source=-----af4a05c42f3c---------------------bookmark_footer-----------)![](../Images/295e18f233f38577ab964460240114a5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf4a05c42f3c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-current-state-of-continual-learning-in-ai-af4a05c42f3c&source=-----af4a05c42f3c---------------------bookmark_footer-----------)![](../Images/295e18f233f38577ab964460240114a5.png)'
- en: Image generated by author using DALL-E 3
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 DALL-E 3 生成
- en: '**Knowledge prerequisites:**'
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**知识前提：**'
- en: A couple of years ago, I learned the basics of deep learning through StatQuest
    videos, Lena Voita’s NLP blogs, and books like “Deep Learning for Coders” and
    “Talking Nets.” I’m now wanting to understand the current state of continual learning
    in deep learning. I found that there is not much information available that summarises
    this topic in simpler terms, and it requires sifting through expert research papers.
    Therefore, this article is intended for readers who have a basic understanding
    of the topic but find the research difficult to read and may not be experts. It
    holds a focus on chatbots, so knowing the training stages of chatGPT is also helpful.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，我通过StatQuest视频、Lena Voita的NLP博客以及《深度学习实践者》和《谈谈网络》等书籍学习了深度学习的基础。我现在希望了解深度学习中的持续学习的现状。我发现很少有信息能以简单的术语总结这个主题，并且需要筛选专家研究论文。因此，这篇文章是为那些对该主题有基本了解但发现研究难以阅读且可能不是专家的读者准备的。它集中在聊天机器人上，因此了解chatGPT的训练阶段也很有帮助。
- en: '**Intro**'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**简介**'
- en: '![](../Images/c1b8d3a88f40aa06733f43b29cfe4f48.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c1b8d3a88f40aa06733f43b29cfe4f48.png)'
- en: ChatGPT telling the user it is only trained up until September 2021 (screenshot
    by author)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT告诉用户它的训练只到2021年9月（作者截图）
- en: If large language models like ChatGPT could be continuously updated with new
    data, they would accelerate a wide range of tasks, from software development to
    legal processes to learning. It would also make articles like this one obsolete.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果像ChatGPT这样的语言模型能够不断用新数据更新，它们将加速从软件开发到法律程序到学习的一系列任务。这也会使像这样的一些文章变得过时。
- en: Continual learning is the ability to pause the model training process, save
    the model’s current state, and then later resume training on new data. The model
    should be able to generalise well to new data, while still maintaining its ability
    to generalise to old data. Refer to [this paper](https://arxiv.org/pdf/2302.00487.pdf)
    for a more formal definition.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 持续学习是暂停模型训练过程，保存模型当前状态，然后稍后在新数据上重新开始训练的能力。模型应该能够很好地泛化到新数据，同时仍保持对旧数据的泛化能力。有关更正式的定义，请参阅[这篇论文](https://arxiv.org/pdf/2302.00487.pdf)。
- en: 'Presently, the trend in the industry to augment chatbots with more data is
    to use RAG, combining queried vectors with prompt engineering to answer questions,
    rather than continuing to train the LLM with new data. ChatGPT’s zero-shot learning
    capability, which allows it to answer questions about new, unseen data, makes
    this approach very appealing. For instance, you could teach it a new programming
    language and then ask it questions about that language, with just a few prompts,
    although performance does degrade a bit proportionally to the amount of tokens
    input. Continually training the model to answer questions based on a new topic
    like this requires significant computing resources and more importantly, a wide
    variety of data on the relevant topic. Furthermore, if a topic has very low prevalence
    in the training set, it will generalise poorly to it. E.g.: take an unpopular
    public repo and it will know little about it and may hallucinate, despite having
    seen it at some point during the training process. Context windows (the amount
    of tokens the model can take as input) are getting increasingly larger very quickly,
    making RAG even more attractive. Ideally though, do we not want one intelligent
    all-knowing model, without the need for any external database?'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，行业内增强聊天机器人的数据趋势是使用RAG，将查询的向量与提示工程相结合来回答问题，而不是继续用新数据训练LLM。ChatGPT的零-shot学习能力，使其能够回答关于新、未见数据的问题，这种方法非常有吸引力。例如，你可以教它一种新的编程语言，然后用少量提示询问有关该语言的问题，尽管性能会随着输入的tokens数量增加而略微下降。基于新主题不断训练模型回答问题需要大量计算资源，更重要的是，需要广泛的相关主题数据。此外，如果一个主题在训练集中出现频率很低，它的泛化能力会很差。例如：拿一个不受欢迎的公共仓库，尽管它在训练过程中曾见过，但可能对它了解甚少，还可能出现幻觉。上下文窗口（模型能接收的tokens数量）正在迅速变大，使RAG更加吸引人。然而，理想情况下，我们是否不希望有一个智能的全知模型，而不需要任何外部数据库？
- en: Continual learning is an essential step towards AGI, and some doubt we will
    even be able to achieve it without significant changes in deep learning network
    architectures. Jeff Hawkins in his book, [“A Thousand Brains”](https://www.numenta.com/resources/books/a-thousand-brains-by-jeff-hawkins/),
    stated he does not think current ANN’s are capable of effective continual learning,
    and believes future models will probably need to be architected more similarly
    to the human brain using his theory on reference frames in the cortical columns
    of the neocortex.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 持续学习是通向AGI的重要一步，有人怀疑我们是否能够在没有深度学习网络架构重大变革的情况下实现这一目标。杰夫·霍金斯在他的书《[千脑](https://www.numenta.com/resources/books/a-thousand-brains-by-jeff-hawkins/)》中提到，他认为当前的ANN不具备有效的持续学习能力，并且认为未来的模型可能需要更类似于人脑的架构，利用他关于新皮质皮层柱中的参考框架的理论。
- en: Continual Learning in the pre-training vs fine-tuning stages of language models
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语言模型的预训练阶段与微调阶段的持续学习
- en: 'Earlier this year, a research paper called [“LIMA: Less Is More for Alignment”](https://arxiv.org/abs/2305.11206)
    was published. It introduced a chatbot that was not trained using Reinforcement
    Learning from Human Feedback (RLHF), but was instead fine-tuned on just 1,000
    carefully annotated question-and-answer samples. Surprisingly, the researchers
    said that in 43% of cases, “the chatbot’s responses were on par with those of
    GPT-4”. I did not take an in-depth look at how these were evaluated, but nonetheless,
    it’s widely acknowledged that a substantial amount of the model’s knowledge and
    capability is acquired during the pre-training phase, and research like this further
    proves this.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 今年早些时候，发布了一篇名为《[LIMA：少即是多的对齐](https://arxiv.org/abs/2305.11206)》的研究论文。该论文介绍了一个没有使用来自人类反馈的强化学习（RLHF）进行训练的聊天机器人，而是仅在1,000个精心标注的问答样本上进行了微调。令人惊讶的是，研究人员表示，在43%的情况下，“该聊天机器人的回应与GPT-4相当”。我没有深入了解这些回应是如何评估的，但尽管如此，普遍认为模型的大部分知识和能力是在预训练阶段获得的，这项研究进一步证明了这一点。
- en: Models like ChatGPT and Llama-chat have undergone extensive fine-tuning to generate
    more aligned and effective responses. OpenAI currently offer an API to further
    [fine-tune a model](https://platform.openai.com/docs/guides/fine-tuning), which
    takes Q&A data as input to be used for further training. However, this should
    not be used to teach the model new data, but rather to [customise the tone and
    steerability](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates).
    Fine-tuning a model in attempt to teach it new data can cause *catastrophic forgetting*,
    a problem where the model forgets what it has already learned. This article will
    go over some techniques that aim to mitigate this problem.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 像ChatGPT和Llama-chat这样的模型已经经历了广泛的微调，以生成更对齐和有效的响应。OpenAI目前提供一个API来进一步[微调模型](https://platform.openai.com/docs/guides/fine-tuning)，该API接受问答数据作为输入用于进一步训练。然而，这不应被用来教模型新数据，而是用来[定制语气和可调性](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates)。尝试通过微调模型来教它新数据可能会导致*灾难性遗忘*，即模型会忘记已学到的内容。本文将介绍一些旨在减轻这一问题的技术。
- en: 'This also leads us to a couple key questions about the feasibility and strategy
    of continual learning:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这也引出了关于持续学习的可行性和策略的一些关键问题：
- en: At which stage of development is it most beneficial and easiest to introduce
    continual learning?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在哪个阶段引入持续学习最为有利且最为容易？
- en: Given that both fine-tuning and RLHF alter the entire model’s parameters, is
    it even possible to revert to the pre-training stage for further modification?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鉴于微调和RLHF都会改变整个模型的参数，是否还有可能回到预训练阶段进行进一步修改？
- en: '*Note: I provide some PyTorch-like pseudocode for some of the papers discussed
    below. It has not been tested and may not work, it’s used to break the techniques
    down step by step and translate any confusing math notation to help the reader
    understand.*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*注：我为以下讨论的部分论文提供了一些类似PyTorch的伪代码。这些伪代码未经过测试，可能无法正常工作，用于逐步解析技术并翻译任何混淆的数学符号，以帮助读者理解。*'
- en: The 5 sub-categories of continual learning techniques
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续学习技术的5个子类别
- en: 'The [comprehensive overview of continual learning paper](https://arxiv.org/pdf/2302.00487.pdf)
    states training strategies for continual learning can be divided into 5 sub categories:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[持续学习的综合概述论文](https://arxiv.org/pdf/2302.00487.pdf)指出，持续学习的训练策略可以分为5个子类别：'
- en: 'Regularisation-based approach: this approach adds constraints or penalties
    to the learning process during the training process.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于正则化的方法：这种方法在训练过程中添加约束或惩罚。
- en: 'Optimisation-based approach: this technique focuses on modifying the optimisation
    algorithm.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于优化的方法：这种技术侧重于修改优化算法。
- en: 'Representation-based approach: this aims to learn a shared feature representation
    across different tasks, helping the model generalise better to new but related
    tasks.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于表示的方法：这旨在学习跨不同任务的共享特征表示，帮助模型更好地推广到新的但相关的任务。
- en: 'Replay-based approach: this involves storing some data or learned features
    from previous tasks and replaying them during training on new tasks to maintain
    performance on earlier learned tasks. In other words, mixing both the old and
    new datasets when training on new tasks.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于回放的方法：这涉及存储先前任务的一些数据或学习特征，并在训练新任务时重播它们，以维持对早期学习任务的性能。换句话说，在训练新任务时混合旧数据集和新数据集。
- en: 'Architecture-based approach: in this approach, the network architecture is
    dynamically adjusted, often by growing or partitioning, delegating different parts
    of the network to different tasks.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于架构的方法：在这种方法中，网络架构是动态调整的，通常通过增长或分区来委派网络的不同部分给不同的任务。
- en: 1\. Regularisation-based approaches
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 基于正则化的方法
- en: Soft Masking of Parameters
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数的软掩蔽
- en: The following soft-masking techniques mask and adjust the gradients of each
    parameter during the training process. The *optimisation-based approaches* coming
    up also manipulate the gradients for continual learning. Remember the gradients
    aren’t just temporary numbers that appear and disappear during training; they’re
    signals that guide the evolution of the weights.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的软掩蔽技术在训练过程中对每个参数的梯度进行掩蔽和调整。接下来的*基于优化的方法*也会操纵梯度以实现持续学习。记住，梯度不只是在训练期间出现和消失的临时数字，它们是指导权重演变的信号。
- en: SPG
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SPG
- en: 'This [paper](https://arxiv.org/pdf/2306.14775.pdf) proposes a technique named
    SPG (Soft-masking of Parameter-level Gradient flow) which aims to:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本[论文](https://arxiv.org/pdf/2306.14775.pdf) 提出了一种名为 SPG（Soft-masking of Parameter-level
    Gradient flow）的技术，旨在：
- en: Train the model on each task until convergence.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个任务上训练模型直至收敛。
- en: After training, calculate the “importance” of each parameter for the task.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练后，计算每个任务的每个参数的“重要性”。
- en: Soft-mask parameters based on their accumulated importance, making important
    parameters less likely to change during the learning of new tasks.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据其累积重要性软掩蔽参数，使重要参数在学习新任务时更不可能改变。
- en: 'Let’s break the approach down step by step:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步分解这个方法：
- en: 1\. Training the First Task
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 训练第一个任务
- en: Train the model on the first task’s dataset as normal.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如常在第一个任务的数据集上训练模型。
- en: 2\. Calculate Parameter Importance for the First Task
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 计算第一个任务的参数重要性
- en: After the training of the first task is complete, we calculate the importance
    of each model parameter. The intuition here is simple, we use the gradients of
    each parameter to compute its importance. A larger gradient implies that a small
    change in that parameter will result in a larger change in the loss, meaning the
    model’s performance could vary more significantly, hence that parameter is important.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个任务的训练完成后，我们计算每个模型参数的重要性。这里的直觉很简单，我们使用每个参数的梯度来计算其重要性。较大的梯度意味着该参数的微小变化将导致损失更大的变化，这意味着模型的性能可能会更显著地变化，因此该参数是重要的。
- en: The gradients are also normalised, because gradients in the first layer could
    be small, while those in the last layer could be large. If you’re calculating
    importance based on these raw gradient values, parameters in the last layer would
    seem more important because of the scale of their gradients, not necessarily because
    they are genuinely more crucial for the task.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度也被归一化，因为第一层的梯度可能很小，而最后一层的梯度可能很大。如果你基于这些原始梯度值计算重要性，最后一层的参数会显得更重要，因为其梯度的规模，并非因为它们在任务中真正更关键。
- en: '![](../Images/315a4134afb5961eac6c44a9e83f2760.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/315a4134afb5961eac6c44a9e83f2760.png)'
- en: Equations for calculating the importance of the model parameters in SPG (section
    3.1 of [paper](https://arxiv.org/pdf/2306.14775.pdf))
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 SPG（详见[论文](https://arxiv.org/pdf/2306.14775.pdf) 第3.1节）中模型参数重要性的方程式
- en: 'Let’s translate this calculation to PyTorch-like pseudocode:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个计算翻译成类似于 PyTorch 的伪代码：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 3\. Accumulating Importance Across Tasks
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 跨任务积累重要性
- en: The accumulated importance of each parameter across task is simply calculated
    by taking the max value at any stage.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 每个参数在任务之间的累计重要性是通过在任何阶段取最大值来简单计算的。
- en: '4\. Training Subsequent Tasks, combined loss and the soft-masking mechanism:'
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 训练后续任务、组合损失和软掩码机制：
- en: When training on new tasks, the researchers use a combined loss function consisting
    of two parts. One is the standard loss function which is used as normal on the
    new task and data, and the second is an additional loss function which involves
    putting the *new* data through the *old* model (the converged model checkpoint
    after the previous task) and summing up the logits produced. In classification
    networks the logits are usually the raw non normalised predictions generated by
    the model in one of the last layers before going through something like a softmax
    function. This sum of logits serves as a form of loss. The rationale is that if
    the summed logits are significantly affected when the model parameters change,
    those parameters are crucial for the performance of the previously learned task.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在新任务上进行训练时，研究人员使用一个由两个部分组成的组合损失函数。其中一个是标准损失函数，用于新任务和数据，另一个是额外的损失函数，它涉及将*新*数据通过*旧*模型（即上一个任务之后的收敛模型检查点），并汇总生成的logits。在分类网络中，logits通常是模型在通过类似softmax函数之前生成的原始非标准化预测。这些logits的总和作为一种损失形式。其理由是，如果在模型参数发生变化时，总和logits受到显著影响，那么这些参数对之前学习任务的性能至关重要。
- en: The gradients generated from this additional loss serve as a guide during backpropagation,
    nudging the shared parameters to change in a direction that is less likely to
    harm performance on the first task. It therefore acts as a sort of penalty term
    to enforce that any updates made to the model do not lead to a significant loss
    of information related to previous tasks.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些额外损失生成的梯度在反向传播过程中作为指导，推动共享参数朝着一个不容易损害第一个任务性能的方向改变。因此，它充当了一种惩罚项，以强制确保对模型所做的任何更新不会导致与先前任务相关的重要信息的显著丧失。
- en: 'Train the model on the next task. Use a standard training loop, but modify
    the gradients during backpropagation based on their accumulated importance. This
    is the soft-masking mechanism:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个任务上训练模型。使用标准训练循环，但在反向传播过程中，根据梯度的累计重要性来修改梯度。这就是软掩码机制：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 5\. Soft-Masking Special Cases
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 软掩码特殊情况
- en: 'Feature Extractor: Gradients of parameters in the shared feature extractor
    are modified based on their specific accumulated importance.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取器：共享特征提取器中参数的梯度根据其特定的累计重要性进行修改。
- en: 'Classification Head: For the classification head, gradients are modified based
    on the average importance of the feature extractor.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类头：对于分类头，梯度根据特征提取器的平均重要性进行修改。
- en: Applying this to LLMs
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将其应用于大型语言模型（LLMs）
- en: Bear in mind, this paper does not experiment this with a language model, but
    I assume in a language model you could think of the transformer layers as analogous
    to the “feature extractor,” and the final classification layer (which predicts
    the next word or token in the sequence) as the “classification head.”
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这篇论文没有用语言模型进行实验，但我假设在语言模型中，你可以将变换器层视为类似于“特征提取器”，将最终分类层（预测序列中的下一个词或标记）视为“分类头”。
- en: Soft-masking applied to continual pre-training in a language model
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用于语言模型持续预训练的软掩码
- en: Next we’ll go into a paper which applies similar soft-masking to the pre-training
    stage in language modelling.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将讨论一篇将类似软掩码应用于语言建模中的预训练阶段的论文。
- en: '[This paper](https://arxiv.org/pdf/2302.03241.pdf) introduces a technique called
    DAS (Continual DA-pre-training of LMs with Soft-masking) for continual learning
    in the pre-training stage of a large language model. It applies a soft-masking
    technique similar to the one just discussed along with a couple other techniques
    in attempt to continue pre-training of an LLM without running into catastrophic
    forgetting.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[这篇论文](https://arxiv.org/pdf/2302.03241.pdf)介绍了一种称为DAS（带软掩码的持续DA预训练）的方法，用于大型语言模型预训练阶段的持续学习。它应用了一种类似于刚才讨论的软掩码技术，并结合了其他几种技术，试图在不遇到灾难性遗忘的情况下继续对LLM进行预训练。'
- en: 'Let’s break it down step by step:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步步分解：
- en: Initial Pre-training Phase
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始预训练阶段
- en: Pre-train the LLM like normal.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 像正常一样预训练LLM。
- en: Further Pre-training on A New Domain
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在新领域的进一步预训练
- en: 'Prepare New Domain Data:'
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备新领域数据：
- en: A new dataset from a different domain is prepared.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 准备一个来自不同领域的新数据集。
- en: Calculating the importance of each neuron
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算每个神经元的重要性
- en: SPG used gradients to determine the importance of each parameter, and then applied
    the calculated importance value to mask the gradient adjustments of parameters
    during training. This paper tries to determine the importance of each unit/neuron,
    rather than parameter, and then uses this in the same way by masking the gradient
    during training.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: SPG 使用梯度来确定每个参数的重要性，然后将计算得到的重要性值应用于训练过程中参数梯度调整的掩码。本文试图确定每个单元/神经元的重要性，而不是参数，然后在训练过程中以相同的方式使用这种重要性，通过掩盖梯度来进行训练。
- en: This paper uses two different methods to calculate the importance of neurons,
    depending on the task at hand. One, a gradient-based importance detection method
    (originally outlined in [this paper](https://arxiv.org/pdf/1905.10650.pdf)), and
    two, a custom “proxy loss function”.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 本文使用两种不同的方法来计算神经元的重要性，具体取决于任务。其一是基于梯度的重要性检测方法（最初在[这篇论文](https://arxiv.org/pdf/1905.10650.pdf)中概述），其二是定制的“代理损失函数”。
- en: The first introduced is *not* used in the continual learning of the *first*
    new domain. Why? It needs data from the training dataset to work and the authors
    state that users “don’t have access to the massive original pre-training dataset”,
    which is a fair assumption. The proxy loss function is used instead for the first
    phase of continual learning and then for each subsequent phase the other method
    is used.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先介绍的是*不是*用于*第一个*新领域的持续学习。为什么？它需要来自训练数据集的数据才能工作，而作者表示用户“无法访问庞大的原始预训练数据集”，这是一个合理的假设。因此，在持续学习的第一个阶段使用的是代理损失函数，然后在随后的每个阶段使用其他方法。
- en: '**The proxy loss function (“Proxy KL-divergence loss”):**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**代理损失函数（“代理 KL 散度损失”）：**'
- en: 'I found this term confusing at first, but it’s called this because the original
    gradient-based importance detection method is defined as a loss function itself,
    which you can then use to run the network’s outputs through to get the gradients
    of each neuron, which can then be used to derive importance, just like the SPG
    technique. It’s calculated by the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我最初觉得这个术语令人困惑，但它之所以这样称呼，是因为原始的基于梯度的重要性检测方法本身被定义为一种损失函数，你可以用它来运行网络的输出以获得每个神经元的梯度，然后可以用这些梯度来推导重要性，就像
    SPG 技术一样。计算方法如下：
- en: Take a subset of the new domain we’re wanting to train on and feed it twice
    through the model to get two different representations. These representations
    will differ a bit due to the existing dropout masks in the Transformer architecture.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取出我们希望训练的新领域的一个子集，并将其通过模型输入两次，以获得两个不同的表示。这些表示会有所不同，因为 Transformer 架构中存在的 dropout
    掩码。
- en: Compute the KL-divergence between these two representations.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算这两个表示之间的 KL 散度。
- en: Modified Backpropagation Flow with Proxy and Combined Loss
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用代理和综合损失的修改版反向传播流程
- en: '**Forward Pass:** Data goes through a forward pass in the neural network.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**前向传播：** 数据通过神经网络进行前向传播。'
- en: '**Backpropagation:**'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**反向传播：**'
- en: '**Apply Proxy Loss for Gradient Adjustment:** The proxy loss function’s unit-level
    importance is used to soft-mask the original gradients. This is expressed as:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**应用代理损失以调整梯度：** 代理损失函数的单元级重要性用于软掩盖原始梯度。这可以表示为：'
- en: '[PRE2]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Calculate Combined Loss (MLM + Contrastive Loss):** Compute the combined
    loss using both MLM and contrastive loss.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算综合损失（MLM + 对比损失）：** 使用 MLM 和对比损失来计算综合损失。'
- en: Further Pre-training on More Domains
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在更多领域进行进一步预训练
- en: '**Direct Importance Calculation:** For each new domain, the importance of each
    unit can now be directly calculated using the data from the new domain via the
    gradient-based method outlined in equation 3, eliminating the need for the proxy
    loss function which is only once used after the initial pre-training.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**直接重要性计算：** 对于每个新领域，现在可以直接使用来自新领域的数据通过方程 3 中概述的基于梯度的方法来计算每个单元的重要性，从而消除了在初始预训练后仅使用一次的代理损失函数的需要。'
- en: '**The importance of neurons is updated incrementally as each new task is learned.**
    This update is done using element-wise max. “Element-wise maximum (EMax) operation”
    refers to comparing two vectors element by element, and taking the maximum value
    for each corresponding element to create a new vector. E.g.: if you have two vectors
    A and B of the same length, the element-wise maximum will result in a new vector
    C where each element *C*[*i*] is the maximum between *A*[*i*] and *B*[*i*].'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**神经元的重要性在每个新任务学习时逐步更新。** 这种更新使用逐元素最大值。“逐元素最大（EMax）操作”指的是逐个元素比较两个向量，并取每个对应元素的最大值来创建一个新向量。例如：如果你有两个相同长度的向量A和B，逐元素最大值将产生一个新向量C，其中每个元素
    *C*[*i*] 是 *A*[*i*] 和 *B*[*i*] 之间的最大值。'
- en: 2\. Optimisation-based approaches
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 基于优化的方法
- en: We’ll refer to the two techniques outlined in the [comprehensive survey paper](https://arxiv.org/pdf/2302.00487.pdf)
    in section 3.1
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将参考[综合调查论文](https://arxiv.org/pdf/2302.00487.pdf)第3.1节中概述的两种技术。
- en: Gradient Direction Preservation
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度方向保持
- en: The paper talks about manipulating the gradient-based optimisation process to
    make the gradient *directions* of new training samples close to those from old
    training samples. The formula
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 论文讨论了操控基于梯度的优化过程，以使新训练样本的梯度*方向*接近旧训练样本的梯度。公式
- en: ⟨ ∇θ Lₖ(θ; Dₖ), ∇θ Lₖ(θ; Mₜ) ⟩ ≥ 0
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⟨ ∇θ Lₖ(θ; Dₖ), ∇θ Lₖ(θ; Mₜ) ⟩ ≥ 0
- en: enforces that learning the new task should not increase the loss for the old
    tasks. Essentially, the gradients of the new task and the old tasks are encouraged
    to align.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 强制要求学习新任务时不会增加旧任务的损失。本质上，鼓励新任务和旧任务的梯度对齐。
- en: Breaking down the formula, we take the dot product of the gradient of the loss
    from the new task (∇θ Lₖ(θ; Dₖ)) and the gradient of the loss from the old task
    (∇θ Lₖ(θ; Mₜ)) should be non-negative. In this context, a positive dot product
    implies that the gradients for the old task and the new task are generally pointing
    in the same direction, with the angle between these two vectors is less than or
    equal to 90 degrees.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 分解公式时，我们取新任务的损失梯度（∇θ Lₖ(θ; Dₖ)）与旧任务的损失梯度（∇θ Lₖ(θ; Mₜ)）的点积，应该是非负的。在这种情况下，正的点积意味着旧任务和新任务的梯度通常指向相同的方向，这两个向量之间的角度小于或等于90度。
- en: 'Forward/Backward Passes:'
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向/反向传播：
- en: 'Forward Pass:'
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向传播：
- en: You would run your input data *Dₖ* for the new task and *Mₜ*​ for the old task
    through the same model to calculate the loss for each.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要将新任务的输入数据 *Dₖ* 和旧任务的 *Mₜ*​ 通过同一个模型来计算每个任务的损失。
- en: 'Backward Pass:'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播：
- en: Compute the gradients of the loss with respect to the network parameters for
    both the old and new task.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算旧任务和新任务的网络参数的损失梯度。
- en: 'Alignment Check: Compute the dot product of the two gradients. You’d then use
    this information to modify the gradients for the new task in such a way that the
    dot product is non-negative.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对齐检查：计算两个梯度的点积。然后使用这些信息以使新任务的梯度的点积为非负。
- en: 'Update Weights: Update the model parameters using these “aligned” gradients.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新权重：使用这些“对齐”的梯度更新模型参数。
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Gradient Direction Preservation without needing old training samples
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无需旧训练样本的梯度方向保持
- en: The text also highlights that gradient projection can be performed even without
    storing old samples. NCL (Natural continual learning, [paper link](https://proceedings.neurips.cc/paper/2021/hash/ec5aa0b7846082a2415f0902f0da88f2-Abstract.html))
    is the technique summarised here. Note, this can be categorised as both a regularisation
    and optimisation based approach.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 文本还强调，即使不存储旧样本，也可以进行梯度投影。NCL（自然连续学习，[论文链接](https://proceedings.neurips.cc/paper/2021/hash/ec5aa0b7846082a2415f0902f0da88f2-Abstract.html)）是这里总结的技术。请注意，这可以归类为正则化和优化两种方法。
- en: 'Training process step by step:'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练过程逐步：
- en: '**Forward Pass:**'
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**前向传播：**'
- en: You would run your new data through the network and calculate the loss as usual.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要将新数据通过网络并计算损失。
- en: '**Backward Pass:**'
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**反向传播：**'
- en: '**Objective:** The aim is to minimise the task-specific loss *ℓk(θ)* while
    adhering to a distance constraint *d*(*θ*,*θ*+*δ*)≤*r.*'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**目标：** 目的是在遵守距离约束 *d*(*θ*,*θ*+*δ*)≤*r.* 的同时，最小化任务特定的损失 *ℓk(θ)*。'
- en: '**Algorithm step by step**:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**算法逐步**：'
- en: As normal, compute the gradient of the loss with respect to the model parameters
    ∇*θ*​ℓ*k*​(*θ*).
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如常，计算模型参数∇*θ*​ℓ*k*​(*θ*)的损失梯度。
- en: The *δ* is calculated using the update rule. This gives you the “suggested”
    changes to the model parameters *θ* based on the new task’s requirements.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*δ* 是使用更新规则计算的。这为你提供了基于新任务要求的模型参数 *θ* 的“建议”更改。'
- en: 'Then, you plug this *δ* into the distance constraint formula: *d(θ,θ+δ)=squareroot(δ⊤Λ_k-1​δ)*​.
    The constraint acts like a boundary around the current parameters *θ*, defined
    by the distance metric *d*(*θ*,*θ*+*δ*) and the radius *r*. I struggled to see
    why they called it a “radius”, and not just “constraint number” or something.
    I think it’s because the researchers are visualising the gradients and training
    process in a high-dimensional space. When you apply a constraint based on the
    distance metric, you’re essentially defining a “sphere” around your current parameter
    values in that high-dimensional space. The “radius” *r* of this sphere sets a
    limit on how much the parameter can move while learning a new task.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将这个 *δ* 插入到距离约束公式中：*d(θ,θ+δ)=squareroot(δ⊤Λ_k-1​δ)*​。约束在当前参数 *θ* 周围起到边界作用，由距离度量
    *d*(*θ*,*θ*+*δ*) 和半径 *r* 定义。我很难理解为什么叫它“半径”，而不是“约束值”或其他什么。我认为这是因为研究人员在高维空间中可视化梯度和训练过程。当你基于距离度量应用约束时，本质上是在高维空间中定义了一个围绕当前参数值的“球体”。这个球体的“半径”
    *r* 设置了在学习新任务时参数可以移动的限制。
- en: If the proposed *δ* would move *θ* too far according to this distance metric,
    i.e., beyond this boundary, you scale it down so that it stays within the allowable
    region defined by the radius *r*.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果提议的 *δ* 根据这个距离度量将 *θ* 移动得过远，即超出了这个边界，你就将其缩小，以使其保持在由半径 *r* 定义的允许区域内。
- en: 'Let’s look at each bit more in-depth:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地查看每一部分：
- en: '**Update Rule:** The update rule provides a direction in which *θ* should move.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新规则：** 更新规则提供了 *θ* 应该移动的方向。'
- en: '![](../Images/54949a33247d881c077379249243497d.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/54949a33247d881c077379249243497d.png)'
- en: NCL update rule from section 3.1 in the [comprehensive overview of continual
    learning paper](https://arxiv.org/pdf/2302.00487.pdf)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 [持续学习论文的综合概述](https://arxiv.org/pdf/2302.00487.pdf) 第3.1节的 NCL 更新规则
- en: 'Breaking it down:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 分解如下：
- en: '*∇θ ℓk(θ)* represents the gradients for all parameters (*θ)* calculated by
    the loss function.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*∇θ ℓk(θ)* 表示由损失函数计算的所有参数 (*θ*) 的梯度。'
- en: 'Parameter importance calculation (*Λ^(k-1)_(-1)*): This term represents a *precision
    matrix* and it is yet another way to calculate the importance of parameters in
    the network. *more details below*'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '参数重要性计算 (*Λ^(k-1)_(-1)*): 这个术语表示一个 *精度矩阵*，它是计算网络中参数重要性的另一种方式。*更多细节见下*'
- en: 'Regularisation Term (*θ — μ_(k-1)*): This term pulls the updated parameters
    closer to the optimal parameters *μ_(k-1)*​ from the previous task. Like the before
    techniques, it acts as a regulariser to avoid deviation from what was already
    learned.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '正则化项 (*θ — μ_(k-1)*): 这个项将更新后的参数拉近到来自先前任务的最佳参数 *μ_(k-1)*。像之前的方法一样，它作为正则化器以避免偏离已经学到的内容。'
- en: Learning Rate (*λ*)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率 (*λ*)
- en: '**Distance Constraint:** Before applying this update, you’d usually check whether
    this change *δ* would violate the distance constraint *d*(*θ*,*θ*+*δ*)≤*r*. If
    it does, you’d typically scale down *δ* so that it satisfies the constraint.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**距离约束：** 在应用这个更新之前，你通常会检查这个变化 *δ* 是否会违反距离约束 *d*(*θ*,*θ*+*δ*)≤*r*。如果违反了，你通常会缩小
    *δ*，以使其满足约束。'
- en: '**Precision matrix explanation:** before in the soft-masking methods we saw
    the calculation of importance via the output of all neurons or their gradients.
    In this method a precision matrix is used. This is a bit more complex so I’ll
    attempt to explain it:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**精度矩阵解释：** 在之前的软掩蔽方法中，我们通过所有神经元的输出或它们的梯度来计算重要性。在这个方法中使用了一个精度矩阵。这有点复杂，所以我会尽力解释：'
- en: We first calculate the *covariance matrix* for the networks parameters. In the
    context of neural networks, the columns in the gradient matrix *G* correspond
    to the parameters (weights and biases) of the model. Each row in *G* represents
    the gradient vector for a single training example, with respect to all of those
    parameters.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先计算网络参数的 *协方差矩阵*。在神经网络的上下文中，梯度矩阵 *G* 的列对应于模型的参数（权重和偏差）。*G* 的每一行代表一个训练样本的梯度向量，相对于所有这些参数。
- en: So, if you have a neural network with *P* parameters (this includes all the
    weights and biases from all layers), then each gradient vector will have *P* elements,
    one for each parameter. Therefore, *G* will be a matrix of shape *N* × *P*, *N*
    representing each batch and therefore each row representing the average gradient
    vector across all the training examples in a given batch.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个具有 *P* 个参数的神经网络（这包括所有层的所有权重和偏置），那么每个梯度向量将有 *P* 个元素，每个元素对应一个参数。因此，*G* 将是一个形状为
    *N* × *P* 的矩阵，其中 *N* 代表每个批次，因此每行代表在给定批次中的所有训练样本的平均梯度向量。
- en: When you calculate the covariance matrix Σ from *G*, the resulting matrix will
    have dimensions *P* × *P*. The diagonal entries Σ*ii*​ will indicate the variance
    of the gradient with respect to the *ith* parameter, and the off-diagonal entries
    Σ*ij*​ will indicate the covariance between the gradients with respect to the
    *ith* and *jth* parameters. This gives you an idea of how these parameters interact
    or co-vary during the training process. The inverse of this matrix is the *precision
    matrix*, which is what we use to determine importance.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当你从 *G* 计算协方差矩阵 Σ 时，得到的矩阵将具有 *P* × *P* 的维度。对角线条目 Σ*ii*​ 将指示与 *ith* 参数相关的梯度的方差，而非对角线条目
    Σ*ij*​ 将指示与 *ith* 和 *jth* 参数相关的梯度之间的协方差。这让你了解这些参数在训练过程中如何相互作用或协变。该矩阵的逆矩阵是 *精度矩阵*，我们用它来确定重要性。
- en: Why the *precision matrix* over the *covariance matrix*? While the covariance
    matrix Σ does capture how parameters interact with each other during training,
    it doesn’t specifically indicate how crucial each parameter is to the task at
    hand when all other parameters are considered. In contrast, the precision matrix
    allows us to assess the *conditional independence* (this is a concept in probability
    theory, look it up) of parameters. Large values in the precision matrix indicate
    that knowing one parameter is highly informative about another, given all the
    other parameters. I’m not going to go into examples of how this works so get ChatGPT
    to generate some examples using a very small neural network to see how the values
    can be interpreted.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么选择 *精度矩阵* 而不是 *协方差矩阵*？虽然协方差矩阵 Σ 确实捕捉了参数在训练过程中如何相互作用，但它没有特别指示每个参数在考虑所有其他参数时对当前任务的关键程度。相比之下，精度矩阵允许我们评估
    *条件独立性*（这是概率论中的一个概念，查阅一下）。精度矩阵中的大值表示，在给定所有其他参数的情况下，知道一个参数对另一个参数的了解具有很高的信息量。我不会进入如何运作的示例，所以请让ChatGPT生成一些示例，使用一个非常小的神经网络来看看这些值如何被解释。
- en: Previous methods we saw that calculate importance focus on individual neurons
    or parameters, ignoring the relationships between them. The precision matrix,
    on the other hand, can capture these relationships. Like everything in deep learning,
    whether this is a better way to calculate the importance of a network, is going
    to be empirical and could differ depending on the task and scale of the network.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前看到的计算重要性的方法关注于单个神经元或参数，忽略了它们之间的关系。另一方面，精度矩阵可以捕捉这些关系。像深度学习中的一切一样，这是否是一种更好的计算网络重要性的方法，还需要通过经验来验证，并且可能会根据任务和网络规模的不同而有所不同。
- en: '**Algorithm step by step in PyTorch:**'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyTorch中的算法步骤：**'
- en: '[PRE4]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 3\. Representation-based approach
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 基于表示的方法
- en: Firstly, it’s important to note that the pre-training of LLM’s to be further
    fine-tuned on a downstream task is an example of continual learning in this sub-category.
    I think ChatGPT’s ability to reason about never-before-seen data is also an example
    of this approach. Although we technically call it zero-shot learning, and the
    term “continual learning” requires updating model parameters, it goes beyond anything
    we’ve seen before. As discussed in the introduction, prompt engineering could
    be the future of continual learning, instead of continually updating the parameters.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，需要注意的是，对LLM进行预训练以便进一步在下游任务中进行微调，是这个子类别中的持续学习的一个例子。我认为ChatGPT在处理从未见过的数据时的推理能力也是这种方法的一个例子。虽然我们从技术上称之为零样本学习，而“持续学习”这个术语要求更新模型参数，但它超越了我们以前见过的任何东西。正如介绍中所讨论的，提示工程可能是持续学习的未来，而不是不断更新参数。
- en: Below we’ll take a look at using knowledge distillation for continual learning.
    I’m not really sure which sub-category this falls under, but I’d guess it’s probably
    a mix between representation, architecture and replay approaches. Even though
    some of the techniques we’re reviewing may seem random and unproven at large scale,
    breakthroughs in this field are often unpredictable. Therefore, it’s important
    to maintain a broad perspective.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将探讨使用知识蒸馏进行持续学习。我不太确定这属于哪个子类别，但我猜这可能是表示、架构和重放方法的混合。尽管我们正在审查的一些技术可能看起来随意且在大规模上未经验证，但这一领域的突破往往是不可预测的。因此，保持广阔的视角非常重要。
- en: Knowledge Distillation for continual learning
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识蒸馏用于持续学习
- en: You can transfer (or “distill”) the knowledge of one network into another network,
    and the second network does a reasonable job of approximating the function learned
    by the original network.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将一个网络的知识（或“蒸馏”）转移到另一个网络中，第二个网络能够合理地近似原始网络所学习的功能。
- en: 'The distilled model (the *student*), is trained to mimic the output of the
    larger network (the *teacher*), instead of training it on the raw data directly.
    For example, say you want to train a smaller student model to mimic a large pre-trained
    language model (the teacher). Run the original pre-training dataset through the
    teacher model to generate “soft targets.” These are probability distributions
    over potential outputs, i.e.: next-word predictions. For instance, for a next-word
    prediction task, instead of predicting “cat,” the teacher might provide probabilities
    like 90% for “cat”, 5% for “kitten”, 3% for “feline”, etc.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 蒸馏模型（*学生*）被训练来模仿较大网络（*教师*）的输出，而不是直接用原始数据进行训练。例如，假设你想训练一个较小的学生模型来模仿一个大型预训练语言模型（教师）。将原始预训练数据集通过教师模型生成“软目标”。这些是潜在输出的概率分布，例如：下一词预测任务中，教师可能会提供像
    90% 为“cat”、5% 为“kitten”、3% 为“feline”等概率。
- en: This is usually done to transfer knowledge to much smaller models, and it yields
    great results despite the smaller model.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常是为了将知识转移到更小的模型上，并且尽管模型较小，但效果非常好。
- en: 'Let’s see how some researchers [applied this with success](https://ojs.aaai.org/index.php/AAAI/article/view/17600)
    to a NER (named entity recognition) model. The training process is fairly straightforward:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些研究人员是如何[成功应用](https://ojs.aaai.org/index.php/AAAI/article/view/17600)到一个NER（命名实体识别）模型上的。训练过程非常简单：
- en: Training process step by step
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练过程一步步进行
- en: 'There are two primary methods outlined in the paper: AddNER and ExtendNER.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中概述了两种主要方法：AddNER 和 ExtendNER。
- en: AddNER Model
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AddNER 模型
- en: 'Note, NER models work by taking a sequence of tokens (usually a sentence) as
    input and then output a probability distribution (for the different types of entities)
    for each token. IOB tagging is commonly used for NER models, each token can be
    labeled as ‘O’, or as the beginning (‘B-’) or inside (‘I-’) of an entity of type
    *X*. ‘O’ stands for ‘Outside’, it just means the current token doesn’t belong
    to any entity. Therefore, for *n* entity types, you will have 2*n* output neurons
    in the classification layer: *n* for the ‘B-’ tags (one for each entity type)
    and *n* for the ‘I-’ tags (again, one for each entity type). Add to this the ‘O’
    label, which signifies that a token doesn’t belong to any entity, and you end
    up with 2*n* + 1 possible labels for each token. The final dimensions can be written
    as *h* × (2*n* + 1), where *h* is the size of the hidden layer’s output. Bear
    in mind, this is only for models where tokens can only be one entity. E.g.: “Apple”
    could be tagged as both “FOOD” and “COMPANY”.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，NER 模型通过接收一系列标记（通常是一个句子）作为输入，然后为每个标记输出一个概率分布（针对不同类型的实体）。IOB 标记法通常用于 NER
    模型，每个标记可以被标记为‘O’，或作为实体类型 *X* 的开始（‘B-’）或内部（‘I-’）。‘O’表示‘Outside’，这意味着当前标记不属于任何实体。因此，对于
    *n* 个实体类型，你将在分类层中得到 2*n* 个输出神经元：*n* 个用于‘B-’ 标签（每种实体类型一个），*n* 个用于‘I-’ 标签（同样，每种实体类型一个）。加上‘O’
    标签，表示一个标记不属于任何实体，你将得到 2*n* + 1 个可能的标签。最终的维度可以写成 *h* × (2*n* + 1)，其中 *h* 是隐藏层输出的大小。请注意，这仅适用于标记只能属于一个实体的模型。例如：“Apple”
    可以被标记为“FOOD”和“COMPANY”。
- en: Architecture and teacher-student setup
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构和师生设置
- en: The student model in this case is a copy of the teacher model, with an additional
    output classification layer for each new entity type that the model should learn.
    During training, the new output layer learns from the new annotated data, and
    the older layers are guided by the teacher model’s outputs to minimise forgetting.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，学生模型是教师模型的一个副本，额外增加了一个输出分类层，以学习模型需要识别的每种新实体类型。在训练过程中，新的输出层从新的标注数据中学习，而旧的层则通过教师模型的输出进行指导，以减少遗忘。
- en: After training, the old output layers are not discarded. It then uses the algorithm
    and heuristics described in the conflict resolver section *(end of section 3.3)*
    to combine these outputs into a single, final prediction for each token in the
    sequence.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后，旧的输出层不会被丢弃。它接着使用冲突解决器部分*(第3.3节末尾)*中描述的算法和启发式方法，将这些输出组合成每个序列中的单一最终预测。
- en: '![](../Images/31710e332c9941fc063c2fed5783abe9.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/31710e332c9941fc063c2fed5783abe9.png)'
- en: Diagram of the AddNER model from section 3.2 of the [paper](https://ojs.aaai.org/index.php/AAAI/article/view/17600)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[AddNER模型的示意图](https://ojs.aaai.org/index.php/AAAI/article/view/17600)来自第3.2节'
- en: Forward Pass
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向传播
- en: 'Old Entity Types: The input sentence is passed through the teacher model to
    obtain probability distributions (the “soft targets” in this context) for the
    old entity types.'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 旧实体类型：将输入句子通过教师模型，以获得旧实体类型的概率分布（在此背景下为“软目标”）。
- en: 'New Entity Types: The same sentence is also passed through the new student
    model with additional output layers specific to the new entity types​.'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新实体类型：相同的句子也会通过新学生模型，该模型具有专门针对新实体类型的额外输出层。
- en: Backward Pass
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后向传播
- en: '**Combined loss function:**'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**组合损失函数：**'
- en: 'KD Loss: calculated by comparing how closely the output probabilities of the
    old entity types from the new model (student) match those from the old model (teacher).
    It uses KL-divergence to calculate this. It’s probably calculated token-by-token
    and then summed or averaged over all tokens in a sentence or batch, but I don’t
    think the paper goes into this.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: KD损失：通过比较新模型（学生）对旧实体类型的输出概率与旧模型（教师）的匹配程度来计算。它使用KL散度来计算。它可能是逐个标记计算的，然后在句子或批次中的所有标记上求和或取平均，但我认为论文没有详细说明这一点。
- en: 'Cross-Entropy Loss: This is the usual loss function that compares the model’s
    predictions for the new entity types against the actual labels from the new dataset.'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交叉熵损失：这是常用的损失函数，用于比较模型对新实体类型的预测与来自新数据集的实际标签。
- en: 'Combining the two: these two losses are combined into a combined loss by taking
    a weighted sum of them both. The weights for combining these losses are set by
    the hyperparameters alpha and beta, which are adjusted like any other hyperparameter
    to better performance based on experiments.'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两者结合：这两种损失通过加权求和的方式结合成一个组合损失。结合这些损失的权重由超参数alpha和beta设定，像调整其他超参数一样，根据实验结果优化性能。
- en: '[PRE5]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ExtendNER Model
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ExtendNER模型
- en: Architecture and teacher-student setup
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构和师生设置
- en: 'The ExtendNER model extends the output layer dimensions to accommodate new
    entity types, instead of adding new output layers. The paper explains quite simply
    how the dimensions are to be:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ExtendNER模型扩展了输出层的维度，以适应新的实体类型，而不是添加新的输出层。论文相当简单地解释了这些维度应如何设置：
- en: “Assuming that *Mi* was able to recognize *n* entity types, its final layer
    can be considered as a matrix with dimension *h×(2n+1)*. The output layer of *Mi+1*
    will then be extended to be a matrix with dimension *h × (2n + 2m + 1)* in order
    to accommodate the new entity types.”
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: “假设*Mi*能够识别*n*个实体类型，它的最终层可以被视为一个*h×(2n+1)*的矩阵。然后，*Mi+1*的输出层将扩展为一个*h × (2n +
    2m + 1)*的矩阵，以适应新的实体类型。”
- en: '![](../Images/e04816628dc4e50a569db1c30a59c8d1.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e04816628dc4e50a569db1c30a59c8d1.png)'
- en: Diagram of the ExtendNER model from section 3.4 of the [paper](https://ojs.aaai.org/index.php/AAAI/article/view/17600)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[ExtendNER模型的示意图](https://ojs.aaai.org/index.php/AAAI/article/view/17600)来自第3.4节'
- en: Forward Pass
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前向传播
- en: Same as in AddNER, but with extended dimensions.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 与AddNER相同，但维度扩展。
- en: Backward Pass
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后向传播
- en: 'The loss calculation uses *either* the KL-divergence loss or the cross-entropy
    loss, depending on the following:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 损失计算使用*KL散度损失*或交叉熵损失，具体取决于以下因素：
- en: When the NER category label *y* is “O” (from the IOB tagging schema), the KL
    divergence loss is used.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当NER类别标签*y*为“O”（来自IOB标注模式）时，使用KL散度损失。
- en: When the category label *y* is NOT “O”, the Cross-Entropy loss is used.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当类别标签*y*不是“O”时，使用交叉熵损失。
- en: Final Prediction
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终预测
- en: Viterbi algorithm is applied to decode the final entity types.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Viterbi算法用于解码最终的实体类型。
- en: Both AddNER and ExtendNER models performed well for continual learning and the
    results did not differ between them much
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: AddNER和ExtendNER模型在持续学习中表现良好，结果之间差异不大
- en: 4\. Replay-based approach
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 基于回放的方法
- en: “Fine-tuned language models are continual learners”
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “微调的语言模型是持续学习者”
- en: '[paper link](https://arxiv.org/pdf/2205.12393.pdf)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[论文链接](https://arxiv.org/pdf/2205.12393.pdf)'
- en: The model in the paper is not a generic, single-task model like GPT trained
    just for conversational response. Instead, it’s fine-tuned for a sequence of specialised
    tasks, ranging from text simplification to Haiku generation. Each of these tasks
    has unique requirements, evaluation metrics, and specialised training datasets.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中的模型不是像GPT这样仅用于对话回应的通用单任务模型。相反，它是为一系列专业任务进行微调的，从文本简化到俳句生成。这些任务各自有独特的要求、评估标准和专业训练数据集。
- en: The researchers mix parts of the old dataset with the new dataset, and achieve
    great results by mixing in just 1% of the previous task’s dataset when fine-tuning
    on a new task. This is done sequentially for many tasks (8). The model also performs
    well in zero-shot learning settings, meaning it can generalise well to tasks it
    hasn’t been trained on. For instance, it can generate a Haiku with the correct
    syllable count when given an unseen topic, showing its ability to generalise.
    The researchers also mention that their approach is task-order invariant, meaning
    the sequence in which tasks are learned does not affect the model’s performance.
    The experiments find that the amount of the old dataset mixed in with the new
    one doesn’t significantly affect the main task’s performance. However, it does
    affect the zero-shot learning. At 0% rehearsal, the model tends to forget the
    zero-shot tasks, while at 1% rehearsal, the model maintains its performance in
    those tasks very well.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员将旧数据集的部分与新数据集混合，通过在微调新任务时只混入1%的旧任务数据集，取得了很好的效果。这是在多个任务上顺序进行的（8）。该模型在零-shot学习设置中也表现良好，意味着它可以很好地推广到未经过训练的任务。例如，当给定一个未见过的主题时，它可以生成具有正确音节数的俳句，显示出其推广能力。研究人员还提到，他们的方法是任务顺序不变的，意味着学习任务的顺序不会影响模型的表现。实验发现，与新数据集混合的旧数据集的数量不会显著影响主要任务的表现。然而，它会影响零-shot学习。在0%复习时，模型倾向于忘记零-shot任务，而在1%复习时，模型在这些任务中的表现保持得很好。
- en: This all seems positive, the fact we can just add 1% of the old dataset and
    continual learning is solved, but of course, applying it to a chatbot like chatGPT,
    will be empirical and can be completely different. Even if, hypothetically, chatGPT
    could be continually trained in the fine-tuning and RLHF stages like this, it
    would require an immense amount of labeled conversation data.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都显得积极，我们可以只添加1%的旧数据集并解决持续学习的问题，但当然，将其应用于像chatGPT这样的聊天机器人，将是经验性的，并且可能完全不同。即使假设chatGPT可以在微调和RLHF阶段持续训练，也需要大量标记的对话数据。
- en: 5\. Architecture-based approach
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 基于架构的方法
- en: I won’t go into any specific paper or implementation in detail here, but I will
    provide a brief overview of this approach and a couple different techniques. I
    recommend reading this section (4.5) of the [comprehensive survey paper](https://arxiv.org/pdf/2302.00487.pdf).
    It is also easier to read than the other sections.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会在这里详细讨论具体的论文或实现，但我会简要概述这种方法和几种不同的技术。我建议阅读[这篇综合调查论文](https://arxiv.org/pdf/2302.00487.pdf)的第4.5节。它比其他章节更容易阅读。
- en: 'Parameter Allocation: Here, a subset of the network parameters is dedicated
    to each task. This can be done either by masking out irrelevant neurons or by
    explicitly identifying important ones for the current task.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 参数分配：在这里，网络参数的一个子集被分配给每个任务。这可以通过屏蔽无关的神经元或明确识别当前任务的重要神经元来实现。
- en: 'Modular Network: This involves using separate sub-networks or modules for each
    task.'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模块化网络：这涉及为每个任务使用独立的子网络或模块。
- en: 'Sub-networks can be connected in various ways to form an ensemble or a more
    complex architecture. Below are a few common methods for connecting sub-networks:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 子网络可以以各种方式连接，以形成一个集成体或更复杂的架构。以下是几种常见的子网络连接方法：
- en: 'Concatenation of Outputs:'
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出的连接：
- en: In this approach, the outputs of multiple sub-networks are concatenated into
    a single tensor, which can then be passed through additional layers to produce
    the final output.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，多个子网络的输出被串联成一个张量，然后可以通过额外的层处理以生成最终输出。
- en: 'Voting Mechanism:'
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 投票机制：
- en: In some models, each sub-network casts a “vote” on the likely outcome, and the
    final decision is made by taking the majority vote or a weighted vote. This has
    biological inspiration as it’s similar to how different cortical columns in the
    neocortex cast votes.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些模型中，每个子网络对可能的结果进行“投票”，最终决定通过多数投票或加权投票来做出。这有生物学启发，因为它类似于新皮层中不同皮层柱进行投票的方式。
- en: 'Skip Connections:'
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跳跃连接：
- en: Some architectures allow sub-networks to have skip connections to other parts
    of the model, allowing information to flow across modules.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一些架构允许子网络具有跳跃连接到模型的其他部分，从而允许信息在模块之间流动。
- en: 'Sequential:'
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 顺序：
- en: In this case, the output of one sub-network serves as the input to the next.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，一个子网络的输出作为下一个子网络的输入。
- en: Going back to talking about chatbots, what I find particularly interesting if
    it were possible to create such an architecture with two sub-networks. The first
    one is the pre-trained model which holds the general “knowledge”. The second holds
    knowledge for aligning the model. Once the model is aligned, it would no longer
    need labeled conversational data. Instead, it could be continually updated by
    training the pre-trained subnetwork in an unsupervised way.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 回到聊天机器人，如果能创建一个由两个子网络组成的架构，我觉得特别有趣。第一个是预训练模型，它包含通用的“知识”。第二个包含对齐模型所需的知识。一旦模型对齐，它将不再需要标记的对话数据。相反，它可以通过以无监督的方式训练预训练子网络来不断更新。
- en: '**Conclusion**'
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**结论**'
- en: In conclusion the subfield of continual learning in deep learning is challenging
    and mostly unknown. This is because we do not fully understand how the neurons
    in LLMs work, and as outlined in the intro, could also be that current network
    architectures, or deep learning in general, is just not suited for it.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，深度学习中持续学习的子领域具有挑战性，并且大部分仍未被了解。这是因为我们尚未完全理解大规模语言模型中的神经元如何工作，正如引言中所述，当前的网络架构或深度学习本身可能不适合此任务。
- en: I noticed last month that ChatGPT (GPT-4 only) had [been updated](https://stackdiary.com/chatgpts-cutoff-date-upgraded-to-january-2022/)
    as it now says “Since my training cutoff in January 2022”, so I wonder what the
    folks at OpenAI did to achieve this.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我注意到上个月 ChatGPT（仅 GPT-4）已经[更新](https://stackdiary.com/chatgpts-cutoff-date-upgraded-to-january-2022/)，现在它显示“自我的训练截止日期是
    2022 年 1 月”，所以我想知道 OpenAI 的团队是如何实现这一点的。
- en: '![](../Images/1746b4e381fc5d968f5a8d60d20a46a6.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1746b4e381fc5d968f5a8d60d20a46a6.png)'
- en: ChatGPT (GPT-4 variant) telling the user it is trained up until January 2022
    (screenshot by author)
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT（GPT-4 变体）告知用户其训练数据截至到 2022 年 1 月（作者截图）
