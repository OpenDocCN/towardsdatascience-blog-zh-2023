- en: How Google Used Fake Datasets to Train Generative Music AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19?source=collection_archive---------3-----------------------#2023-05-28](https://towardsdatascience.com/how-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19?source=collection_archive---------3-----------------------#2023-05-28)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)[](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----def6f3f71f19--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd0c085a74ae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&user=Max+Hilsdorf&userId=d0c085a74ae8&source=post_page-d0c085a74ae8----def6f3f71f19---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----def6f3f71f19--------------------------------)
    ·6 min read·May 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fdef6f3f71f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&user=Max+Hilsdorf&userId=d0c085a74ae8&source=-----def6f3f71f19---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fdef6f3f71f19&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-google-used-fake-datasets-to-train-generative-music-ai-def6f3f71f19&source=-----def6f3f71f19---------------------bookmark_footer-----------)![](../Images/ed2c5ce433310ba9f1ace3de4d277849.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [James Stamler](https://unsplash.com/@jamesstamler?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we explore Google’s innovative approach to training their remarkable
    text-to-music models, including MusicLM and Noise2Music. We’ll delve into the
    concept of “fake” datasets and how they were utilized in these breakthrough models.
    If you’re curious about the inner workings of these techniques and their impact
    on advancing music AI, you’ve come to the right place.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Lack of Labeled Music Data**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Large language models (LLMs) like ChatGPT or Bard are trained on huge amounts
    of unstructured text data. Although it can be computationally expensive to collect
    the content of millions of websites, there is an abundance of training data on
    the public web. In contrast, text-to-image models like DALL-E 2 require a totally
    different kind of dataset consisting of pairs of images with corresponding descriptions.
  prefs: []
  type: TYPE_NORMAL
- en: In the same way, text-to-music models rely on songs with descriptions of their
    musical content. However, unlike images, labeled music is really hard to find
    on the internet. Sometimes, metadata like instrumentation, genre, or mood, are
    available, but full-text in-depth descriptions are exceptionally hard to obtain.
    This poses a serious problem for researchers and companies trying to collect data
    to train generative music models.
  prefs: []
  type: TYPE_NORMAL
