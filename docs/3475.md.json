["```py\nrclone sync -P \\\n            --transfers 4 \\\n            --multi-thread-streams 4 \\\n            S3store:my-bucket/my_files ./my_files \n```", "```py\n[S3store]\n    type = s3\n    provider = AWS\n    access_key_id = <id>\n    secret_access_key = <key>\n    region = us-east-1\n```", "```py\ntime aws s3 cp s3://my-bucket/2GB.bin .\n```", "```py\nrclone sync -P S3store:my-bucket/2GB.bin .\n```", "```py\ntime s5cmd --run cmds.txt\n```", "```py\ncp s3://my-bucket/small_files/<i>.jpg <local_path>/<i>.jpg\n```", "```py\nrclone -P --transfers 256 --files-from files.txt S3store:my-bucket /my-local\n```", "```py\nsmall_files/<i>.jpg\n```", "```py\ns5cmd cat s3://my-bucket/file \\\n      | aws s3 cp --endpoint-url https://storage.googleapis.com\n      --profile gcp - s3://gs-bucket/file\n```", "```py\n[S3store]\n    type = s3\n    provider = AWS\n    access_key_id = <id>\n    secret_access_key = <key>\n\n[GSstore]\n    type = s3\n    provider = GCS\n    access_key_id = <id>\n    secret_access_key = <key>\n    endpoint = https://storage.googleapis.com\n```", "```py\nrclone copy -P S3store:my-bucket/file GSstore:gs-bucket/file\n```", "```py\nrclone copy -P --transfers 256 --files-from files.txt \\\n            S3store:my-bucket/file GSstore:gs-bucket/file\n```"]