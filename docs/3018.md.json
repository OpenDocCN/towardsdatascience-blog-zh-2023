["```py\nfrom  PIL  import  Image\nfrom lang_sam import LangSAM\nfrom lang_sam.utils import draw_image\n\n# Initialize LangSAM model\nmodel = LangSAM()\n# Load the image and convert it to RGB\nimage_pil = Image.open('./assets/image.jpeg').convert(\"RGB\")\n# Set the text prompt for the segmentation\ntext_prompt = 'bicycle'\n# Perform prediction to obtain masks, bounding boxes, labels, and logits\nmasks, boxes, labels, logits = model.predict(image_pil, text_prompt)\n# Draw segmented image using the utility function\nimage = draw_image(image_pil, masks, boxes, labels)\n```", "```py\ndef find_coin_masks(image):\n    # Suppress warning messages\n    warnings.filterwarnings(\"ignore\")\n    text_prompt = \"coin\"\n    try:\n        model = LangSAM()\n        masks, boxes, _, _ = model.predict(image, text_prompt)\n\n        if len(masks) == 0:\n            print(f\"No objects of the '{text_prompt}' prompt detected in the image.\")\n        else:\n            # Convert masks to numpy arrays\n            masks_np = [mask.squeeze().cpu().numpy() for mask in masks]\n            boxes_np = [box.squeeze().cpu().numpy() for box in boxes]\n            return masks_np, boxes_np\n\n    except (requests.exceptions.RequestException, IOError) as e:\n        print(f\"Error: {e}\") \n```", "```py\ndef generate_coin_images(image_dir):\n    # Load the image and convert it to RGB format\n    image = Image.open(image_dir).convert(\"RGB\")\n\n    # Use the previously defined function to obtain masks and bounding boxes\n    masks, boxes = find_coin_masks(image)\n\n    # Convert image to a numpy array for further processing\n    image = np.array(image)\n\n    # List to store final coin images\n    coins = []\n    for index in range(len(masks)):\n        # Apply mask to image and obtain relevant segment\n        mask = np.broadcast_to(np.expand_dims(masks[index],-1), image.shape)\n        masked_image = mask * image\n\n        # Find the bounding box coordinates for the non-zero pixels in the masked image\n        nonzero_indices = np.nonzero(masked_image[:,:,0])\n        nonzero_indices = np.array(nonzero_indices)\n        y_min, y_max, x_min, x_max = find_boundary_of_coin(nonzero_indices)\n\n        # Crop the masked image to the bounding box size\n        masked_image = masked_image[y_min:y_max,x_min:x_max]  \n        # Creating a 500x500 mask \n        if (y_max - y_min)<500 and (x_max - x_min)<500:\n            difference_y = 500 - (y_max - y_min)\n            difference_x = 500 - (x_max - x_min)\n            if difference_y != 0:\n                if difference_y % 2 == 0:\n                    masked_image = np.pad(masked_image, [(difference_y//2, difference_y//2), (0, 0), (0, 0)])\n                else:\n                    masked_image = np.pad(masked_image, [((difference_y-1)//2, (difference_y-1)//2 + 1), (0, 0), (0, 0)])\n            if difference_x != 0:\n                if difference_x % 2 == 0:\n                    masked_image = np.pad(masked_image, [(0, 0), (difference_x//2, difference_x//2), (0, 0)])\n                else:\n                    masked_image = np.pad(masked_image, [(0, 0), ((difference_x-1)//2, (difference_x-1)//2 + 1), (0, 0)])\n            coins.append(masked_image)\n        else:\n            dim = (500, 500)\n            resized_masked_image = cv2.resize(masked_image, dim, interpolation = cv2.INTER_AREA)\n            coins.append(resized_masked_image)\n\n    return coins, boxes\n```", "```py\noutput_dir = \"coin_dataset/training/\"\ndataset_dir = \"coin_images/\"\nsubfolders = os.listdir(dataset_dir) \n\nfor subfolder in subfolders:\n    files = os.listdir(os.path.join(dataset_dir,subfolder)) \n    if '.DS_Store' in files:\n        files.remove('.DS_Store')\n    if '.git' in files:\n        files.remove('.git')\n    files = [file for file in files if file.endswith('.jpg') or file.endswith('.png')] \n\n    for file in files:\n\n        # Generate coin images with generate_coin_images function and loop through them\n        padded_coins, boxes = generate_coin_images(os.path.join(dataset_dir,subfolder,file))\n\n        for padded_coin in padded_coins:\n\n            # Convert the numpy array image back to PIL Image object\n            image = Image.fromarray((padded_coin).astype(np.uint8))\n            if os._exists(os.path.join(output_dir, subfolder, '.DS_Store')):\n                os.remove(os.path.join(output_dir, subfolder, '.DS_Store'))\n            last_index = find_last_index(os.listdir(os.path.join(output_dir, subfolder)))\n            image_name = f\"img_{last_index+1}.png\"\n            subfolder_for_padded_coins = os.path.join(output_dir, subfolder, image_name)\n            image.save(subfolder_for_padded_coins)\n```", "```py\ndef compute_accuracy(model, data_loader, device):\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Forward pass\n            outputs = model(inputs)\n\n            # Get the predicted class index by finding the max value in the output tensor along dimension 1\n            _, predicted = torch.max(outputs.data, 1)  \n            total_predictions += labels.size(0)\n\n            # Update correct predictions count: \n            # Sum up all instances where the predicted class index equals the true class index\n            correct_predictions += (predicted == labels).sum().item()\n\n    return (correct_predictions / total_predictions) * 100\n\n# Compute the accuracy on the training dataset and validation sets\ntrain_accuracy = compute_accuracy(model, train_loader, device)\nval_accuracy = compute_accuracy(model, val_loader, device)\n\nprint(f\"Training set accuracy: {train_accuracy:.2f}%\")\nprint(f\"Validation set accuracy: {val_accuracy:.2f}%\")\n```"]