["```py\nimport torch, time\nimport torch.optim\nimport torch.utils.data\nimport torch.distributed as dist\nfrom torch.nn.parallel.distributed import DistributedDataParallel as DDP\nimport torch.multiprocessing as mp\n\n# modify batch size according to GPU memory\nbatch_size = 64\n\nfrom timm.models.vision_transformer import VisionTransformer\n\nfrom torch.utils.data import Dataset\n\n# use random data\nclass FakeDataset(Dataset):\n    def __len__(self):\n        return 1000000\n\n    def __getitem__(self, index):\n        rand_image = torch.randn([3, 224, 224], dtype=torch.float32)\n        label = torch.tensor(data=[index % 1000], dtype=torch.int64)\n        return rand_image, label\n\ndef mp_fn(local_rank, *args):\n    # configure process\n    dist.init_process_group(\"nccl\",\n                            rank=local_rank,\n                            world_size=torch.cuda.device_count())\n    torch.cuda.set_device(local_rank)\n    device = torch.cuda.current_device()\n\n    # create dataset and dataloader\n    train_set = FakeDataset()\n    train_loader = torch.utils.data.DataLoader(\n        train_set, batch_size=batch_size,\n        num_workers=12, pin_memory=True)\n\n    # define ViT-Huge model\n    model = VisionTransformer(\n            embed_dim=1280,\n            depth=32,\n            num_heads=16,\n        ).cuda(device)\n    model = DDP(model, device_ids=[local_rank])\n\n    # define loss and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n    model.train()\n\n    t0 = time.perf_counter()\n    summ = 0\n    count = 0\n\n    for step, data in enumerate(train_loader):\n        # copy data to GPU\n        inputs = data[0].to(device=device, non_blocking=True)\n        label = data[1].squeeze(-1).to(device=device, non_blocking=True)\n\n        # use mixed precision to take advantage of bfloat16 support\n        with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n            outputs = model(inputs)\n            loss = criterion(outputs, label)\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()\n\n        # capture step time\n        batch_time = time.perf_counter() - t0\n        if step > 10:  # skip first steps\n            summ += batch_time\n            count += 1\n        t0 = time.perf_counter()\n        if step > 50:\n            break\n    print(f'average step time: {summ/count}')\n\nif __name__ == '__main__':\n    mp.spawn(mp_fn,\n             args=(),\n             nprocs=torch.cuda.device_count(),\n             join=True)\n```", "```py\nimport transformer_engine.pytorch as te\nfrom transformer_engine.common import recipe\n\nclass TE_Block(te.transformer.TransformerLayer):\n    def __init__(\n            self,\n            dim,\n            num_heads,\n            mlp_ratio=4.,\n            qkv_bias=False,\n            qk_norm=False,\n            proj_drop=0.,\n            attn_drop=0.,\n            init_values=None,\n            drop_path=0.,\n            act_layer=None,\n            norm_layer=None,\n            mlp_layer=None\n    ):\n        super().__init__(\n            hidden_size=dim,\n            ffn_hidden_size=int(dim * mlp_ratio),\n            num_attention_heads=num_heads,\n            hidden_dropout=proj_drop,\n            attention_dropout=attn_drop\n            )\n```", "```py\n model = VisionTransformer(\n      embed_dim=1280,\n      depth=32,\n      num_heads=16,\n      block_fn=TE_Block\n      ).cuda(device)\n```", "```py\nwith torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n    with te.fp8_autocast(enabled=True):\n        outputs = model(inputs)\n    loss = criterion(outputs, label)\n```"]