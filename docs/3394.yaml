- en: Detecting Generative AI Content
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测生成式人工智能内容
- en: 原文：[https://towardsdatascience.com/detecting-generative-ai-content-286200498f93?source=collection_archive---------5-----------------------#2023-11-15](https://towardsdatascience.com/detecting-generative-ai-content-286200498f93?source=collection_archive---------5-----------------------#2023-11-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/detecting-generative-ai-content-286200498f93?source=collection_archive---------5-----------------------#2023-11-15](https://towardsdatascience.com/detecting-generative-ai-content-286200498f93?source=collection_archive---------5-----------------------#2023-11-15)
- en: On deepfakes, authenticity, and the President’s Executive Order on AI
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于 deepfakes、真实性以及总统关于人工智能的行政命令
- en: '[](https://medium.com/@s.kirmer?source=post_page-----286200498f93--------------------------------)[![Stephanie
    Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page-----286200498f93--------------------------------)[](https://towardsdatascience.com/?source=post_page-----286200498f93--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----286200498f93--------------------------------)
    [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page-----286200498f93--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@s.kirmer?source=post_page-----286200498f93--------------------------------)[![Stephanie
    Kirmer](../Images/f9d9ef9167febde974c223dd4d8d6293.png)](https://medium.com/@s.kirmer?source=post_page-----286200498f93--------------------------------)[](https://towardsdatascience.com/?source=post_page-----286200498f93--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----286200498f93--------------------------------)
    [Stephanie Kirmer](https://medium.com/@s.kirmer?source=post_page-----286200498f93--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa8dc77209ef3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-generative-ai-content-286200498f93&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=post_page-a8dc77209ef3----286200498f93---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----286200498f93--------------------------------)
    ·8 min read·Nov 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F286200498f93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-generative-ai-content-286200498f93&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=-----286200498f93---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[跟随](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa8dc77209ef3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-generative-ai-content-286200498f93&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=post_page-a8dc77209ef3----286200498f93---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----286200498f93--------------------------------)
    ·8 分钟阅读·2023 年 11 月 15 日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F286200498f93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-generative-ai-content-286200498f93&user=Stephanie+Kirmer&userId=a8dc77209ef3&source=-----286200498f93---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F286200498f93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-generative-ai-content-286200498f93&source=-----286200498f93---------------------bookmark_footer-----------)![](../Images/685390d42ddd17dd4950fdcfcd925ec4.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F286200498f93&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdetecting-generative-ai-content-286200498f93&source=-----286200498f93---------------------bookmark_footer-----------)![](../Images/685390d42ddd17dd4950fdcfcd925ec4.png)'
- en: Can you detect the fake? Photo by [Liberty Ann](https://unsplash.com/@libertyanns?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你能识别出假的吗？由 [Liberty Ann](https://unsplash.com/@libertyanns?utm_source=medium&utm_medium=referral)
    拍摄的照片在 [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
- en: One of the many interesting ethical issues that comes with the advances of generative
    AI is **detection of the product of models**. It’s a practical issue as well,
    for those of us who consume media. Is this thing I am reading or looking at the
    product of a person’s thoughtful work, or just words or images probabilistically
    generated to appeal to me? Does it matter? If so, what do we do?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生成技术进步带来的众多有趣的伦理问题之一是**模型生成产品的检测**。对于那些消费媒体的我们来说，这也是一个实际问题。我正在阅读或观看的内容是一个人深思熟虑的作品，还是仅仅是概率生成的文字或图像，旨在吸引我？这是否重要？如果重要，我们该怎么办？
- en: The Meaning of Indistinguishable Content
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不可区分内容的含义
- en: When we talk about content being difficult or impossible to detect as AI generated,
    we’re getting into something akin to a Turing Test. Say that I give you a paragraph
    of text or an image file. If I ask you, “was this produced by a human being or
    a machine learning model?”, and you can’t accurately tell, then we’ve reached
    the point where we need to think about these issues.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论内容难以或不可能检测为AI生成时，我们实际上是在进入类似于图灵测试的领域。假设我给你一段文本或一张图像文件。如果我问你，“这是人类还是机器学习模型生成的？”而你无法准确判断，那么我们就到了需要考虑这些问题的地步。
- en: In many areas we’re close to this, especially with GPT-4, but even with less
    sophisticated models, depending on what kind of prompt we use and the volume of
    context. If we have a long document from a GPT model, it’s likely going to be
    easier to detect that it’s not human generated, because every new word is a chance
    for the model to do something that a regular person wouldn’t do. Same for a video
    or high-res image — the more chances for pixellation or the uncanny valley to
    show up, the more opportunity for us to spot the fake.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多领域，我们接近这一点，特别是对于GPT-4，但即使是较不复杂的模型，也取决于我们使用什么样的提示和上下文的量。如果我们有一份来自GPT模型的长文档，那么检测它不是人类生成的可能会更容易，因为每个新词都是模型做一些普通人不会做的事情的机会。视频或高分辨率图像也是如此——像素化或“恐怖谷”出现的机会越多，我们就越容易发现伪造内容。
- en: It also seems clear to me that as we get more familiar with model generated
    content, we’re going to get better at identifying tell tale signs of AI involvement
    in the content. Just like I described several weeks ago in my explanation of how
    Generative Adversarial Networks work, we are in something of a GAN relationship
    with generative AI ourselves. The models are working on creating the most human-like
    content possible, and we are increasing our ability to tell that it’s not human.
    It’s like a race where each side is working to outwit the other.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我也很清楚，随着我们对模型生成内容的熟悉程度提高，我们将会更擅长识别内容中AI参与的明显迹象。正如我几周前在解释生成对抗网络（GAN）如何工作的文章中所描述的那样，我们和生成AI之间存在某种GAN关系。模型致力于创造尽可能类似人类的内容，而我们则提高识别这些内容非人类的能力。这就像一场比赛，双方都在努力超越对方。
- en: As we get more familiar with model generated content, we’re going to get better
    at identifying tell tale signs of AI involvement in the content.
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 随着我们对模型生成内容的熟悉程度提高，我们将会更擅长识别内容中AI参与的明显迹象。
- en: Detection Approaches
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测方法
- en: However, there’s probably a limit to how good we can get at this detection,
    and models will win out over regular human eyes and ears (if they haven’t already).
    We just don’t have the sensory capabilities and the pattern-recognition sophistication
    that a giant model can have. Fortunately, we can use models as tools on our side
    of the race as well, training models to scrutinize content and determine that
    it isn’t human generated, so that’s one tool in our quiver.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们在这种检测方面可能会有一个极限，模型最终可能会超越普通人眼耳（如果尚未如此的话）。我们只是没有像大型模型那样的感知能力和模式识别复杂性。幸运的是，我们也可以将模型作为我们这边比赛的工具，训练模型来审查内容并确定其是否由人类生成，这也是我们的一种工具。
- en: At some point, though, there may really not be any reliably detectable signs
    of machine learning origins for some content, especially in small quantities.
    Philosophically speaking, given unlimited model advancement, there is probably
    a point at which there IS no real difference between the two kinds of content.
    In addition, most of us won’t be using a model to test all the media we consume
    to make sure it’s human generated and authentic. In response, some organizations,
    such as the [Content Authenticity Initiative](https://contentauthenticity.org/),
    are driving efforts to get content authentication metadata adopted broadly, which
    could be a help. These kinds of efforts, however, require goodwill and work on
    the part of people making the models available.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，尤其是小量内容中，可能真的没有任何可靠的迹象表明其来源于机器学习。从哲学上讲，考虑到模型的无限进步，可能有一个点在于这两种内容之间真的没有实际差别。此外，大多数人不会使用模型来测试我们消费的所有媒体，以确保其由人类生成且真实。作为回应，一些组织，如[内容真实性倡议](https://contentauthenticity.org/)，正在推动内容认证元数据的广泛采用，这可能会有所帮助。然而，这些努力需要模型提供者的善意和工作。
- en: At some point, though, there may really not be any reliably detectable signs
    of machine learning origins for some content.
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，某些内容可能真的没有任何可靠的迹象表明其来源于机器学习。
- en: You might ask, well, what about people who are intentionally bad actors trying
    to create harm with deepfakes or misinformation using AI generated content? They’re
    not going to volunteer to identify their content, are they? It’s a fair question.
    However, at least at this moment, the models that are sophisticated enough to
    fool people at scale are mostly under the control of large companies (OpenAI,
    etc). This won’t continue to be the case, but right this minute it would at least
    make a solid dent in the issue of provenance if the people who serve the most
    sophisticated LLMs to the public took some action on this.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，那么，有些故意恶意行为者试图使用深度伪造或使用AI生成的内容制造伤害的人怎么办呢？他们不会自愿识别他们的内容，对吧？这是一个公平的问题。然而，至少目前，那些足够复杂以至于能够大规模欺骗人们的模型大多受到大公司（如OpenAI等）的控制。这种情况不会持续太久，但就目前而言，如果向公众提供最先进的LLM的人们采取一些行动，至少会在内容来源的问题上起到一定作用。
- en: This isn’t a very optimistic story, so far. Generative AI is careening rapidly
    towards a place where those very powerful models are small enough that bad actors
    can run their own, and where those models easily create content that is literally
    indistinguishable from organic human content, even by other models.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这不是一个非常乐观的故事。生成式AI正迅速向一个使得那些非常强大的模型足够小，以至于恶意行为者可以运行自己的模型，并且这些模型很容易创建出与有机人类内容在字面上无法区分的内容的地方发展。即使是其他模型也无法分辨。
- en: Reasons for Detecting
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测的原因
- en: I’ve gotten a little ahead of myself, though. Why is it so important to everyone
    that we figure out whether content came from a model in the first place? If you
    can’t tell, does it matter?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我有点过于急躁了。但是，为什么大家都如此重视我们首先要弄清楚内容是否来自模型呢？如果你分辨不出来，那有什么关系呢？
- en: One major reason is that the purveyor of the content may have malicious intentions,
    such as misinformation or deepfakes. Creating images, audio, and video are the
    most common scenarios here — making it appear like someone said or did something
    they didn’t do. If you’ve been following the [US President’s Executive Order on
    AI](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/),
    you may have heard that President Biden in fact got interested in this because
    he heard of the potential for people to use his likeness and voice fraudulently
    for misinformation. This is a very serious issue, because at this time, we tend
    to trust what we see with our own eyes in images or videos, and that can have
    a significant impact on people’s lives and safety.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个主要原因是，内容的传播者可能有恶意意图，例如误导信息或深度伪造。在这里，创建图像、音频和视频是最常见的情况之一——使其看起来像某人说过或做过某事。如果你一直在关注[美国总统关于人工智能的行政命令](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)，你可能已经听说拜登总统实际上因为听说有人可能会恶意使用他的肖像和声音来进行误导信息而对此感兴趣。这是一个非常严重的问题，因为目前我们倾向于相信我们用自己的眼睛看到的图像或视频，这可能会对人们的生活和安全产生重大影响。
- en: At this time, we tend to trust what we see with our own eyes in images or videos,
    and that can have a significant impact on people’s lives and safety.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目前，我们倾向于相信我们用自己的眼睛看到的图像或视频，这可能会对人们的生活和安全产生重大影响。
- en: A related issue is when models are used to imitate the work of specific humans
    not for necessarily malicious reasons, but just because that work is enjoyable
    and popular, and potentially profitable. It’s straightforwardly unethical, but
    in most cases probably not meant to actively hurt either the audience or the person
    being mimicked. (It does hurt people, of course — taking away the earning potential
    and livelihoods of artists and writers, which producers of the content should
    take responsibility for.) This can also cause reputational damage when deepfakes
    are used to lie about people’s actions. (Just ask [Joe Rogan, who’s been fighting
    ads](https://mashable.com/article/joe-rogan-tiktok-deepfake-ad) using his likeness
    in deepfakes.)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个相关问题是，当模型用于模仿特定人类的作品时，不一定是出于恶意原因，而仅仅是因为那份工作令人愉悦和受欢迎，可能也是有利可图的。这是明显不道德的，但在大多数情况下可能并不是要积极伤害观众或被模仿的人。当深度伪造用于虚构某人的行为时，这也会造成声誉损害。（只需问问[乔·罗根，他一直在打击](https://mashable.com/article/joe-rogan-tiktok-deepfake-ad)使用他的肖像进行深度伪造的广告。）
- en: A third angle that I began thinking about after Casey Newton discussed it in
    his [October 5 issue of Platformer](https://open.substack.com/pub/platformer/p/how-authoritarian-governments-are?r=7xzvu&utm_medium=ios&utm_campaign=post)
    is the risk that public figures can invert the issue and claim that real, authentic
    evidence of their bad behavior is artificially generated. What do we do when we
    can’t reliably uncover misdeeds using evidence, because “it’s a deepfake” is an
    unfalsifiable response? We’re not quite there yet, but I could see this becoming
    a real issue in the not too distant future.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我在Casey Newton在他[10月5日的Platformer期刊](https://open.substack.com/pub/platformer/p/how-authoritarian-governments-are?r=7xzvu&utm_medium=ios&utm_campaign=post)讨论后开始思考的第三个角度是，公众人物可能会将问题颠倒过来，声称他们不良行为的真实、真实证据是人为生成的。当我们无法通过证据可靠地揭露不当行为时，该怎么办，因为“这是深度伪造”是一个无法反驳的回应？我们还未完全到达这一点，但我可以预见这在不久的将来可能成为一个真正的问题。
- en: What do we do when we can’t reliably uncover misdeeds using evidence, because
    “it’s a deepfake” is an unfalsifiable response?
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当我们无法通过证据可靠地揭露不当行为时，该怎么办，因为“这是深度伪造”是一个无法反驳的回应？
- en: Less urgently, I also think there’s something to wanting my consumption of media
    to represent engaging with another person, even though it is a mainly one way
    movement of ideas. I think of reading or consuming art as engagement with the
    thoughts of another person, and engaging with words strung together by a model
    doesn’t quite have the same feel. So personally, I’d like to know if content I’m
    consuming is human produced.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不那么紧迫的是，我也认为希望我的媒体消费能代表与另一个人互动，即使这是主要是单向的思想交流。我认为阅读或欣赏艺术是与另一个人的思想互动，而与模型编排的文字互动却没有相同的感觉。因此，就个人而言，我希望知道我消费的内容是否是由人类创作的。
- en: The Executive Order
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行政命令
- en: Given all these very real risks, we are facing some serious challenges. There
    seems to be a tradeoff between detectable provenance (meaning, safety for the
    general public and all the issues I described above) and model sophistication,
    and as an industry, data science is driving forward on the side of model sophistication.
    Who’s going to balance the scales out?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于所有这些非常现实的风险，我们面临着一些严重的挑战。似乎在可检测来源（即，公众安全和我上述描述的所有问题）和模型复杂性之间存在权衡，作为一个行业，数据科学正朝着模型复杂性方向推进。谁来平衡这些尺度呢？
- en: The president’s executive order represents some significant progress on this
    topic. (It talks about a lot of other important issues as well, which I may discuss
    another time.) I spent the last week and a half thinking about this executive
    order and reading other people’s perspectives on it from around the industry.
    While there are some who argue that it’s going to stifle advancement (and that
    it will reify the big players in generative AI, at the expense of smaller competitors),
    I think I’ve landed on the side of being optimistic about the executive order.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 总统的行政命令在这个话题上代表了一些重要的进展。（它还讨论了许多其他重要问题，我可能会在其他时候讨论。）我花了过去一个半星期时间思考这一行政命令，并阅读了来自行业各方的观点。虽然有些人认为这会抑制进步（并且会使生成型
    AI 的大玩家得以巩固，而小型竞争者则受到牺牲），但我认为我倾向于对这一行政命令持乐观态度。
- en: Creating competitive generative AI models is incredibly expensive, and resource
    intensive, and this naturally limits how many competitors can get into the space
    in the first place. Protecting hypothetical new players in the space at the expense
    of broader social safety doesn’t make sense to me. I also don’t think the executive
    order is at all onerous for those organizations who have the resources to be in
    this room in the first place.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 创建具有竞争力的生成型 AI 模型是极其昂贵且资源密集的，这自然限制了最初有多少竞争者能够进入这一领域。以牺牲更广泛的社会安全来保护这一领域的假设新玩家对我来说没有意义。我也不认为该行政命令对那些有资源进入这一领域的组织来说是过于繁琐的。
- en: The order itself is also not that prescriptive. It calls for a number of things
    to be created, but leaves open wide latitude for how that should happen, and hopefully
    well informed people will be involved in those processes. 🤞 (Data scientists in
    the field ought to make a point to monitor what happens and be vocal if it’s going
    off the rails.) In particular, it asks for the Commerce Department to create “standards
    and best practices for detecting AI-generated content and authenticating official
    content”. There are also some important components around safety and security
    where models are concerned.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 命令本身也不是那么具备规范性。它要求创建一些东西，但对如何实现这些目标留有很大弹性，希望有见识的人会参与这些过程。🤞（领域中的数据科学家应该留意发生的情况，如果情况失控，就要积极发声。）特别是，它要求商务部制定“检测
    AI 生成内容和验证官方内容的标准和最佳实践”。还有一些关于安全性和模型相关的重要组成部分。
- en: '**Do I have tremendous trust that our government will do a great job regulating
    AI while not damaging innovation?** **No, not really.** But, I feel confident
    that industry left to its own devices will not pay as much attention to the issues
    of provenance and content detection as is needed — they haven’t demonstrated that
    this is a priority so far.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**我是否对我们的政府在监管 AI 的同时不损害创新方面有极大的信任？** **不，真的没有。** 但我相信，如果让行业自行其是，它不会像所需的那样关注来源和内容检测的问题——到目前为止，他们还没有表现出这是一个优先事项。'
- en: I feel confident that industry left to its own devices will not pay as much
    attention to the issues of provenance and content detection as is needed.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我相信，如果让行业自行其是，它不会像所需的那样关注来源和内容检测的问题。
- en: At the same time, I’m not sure that detecting generative AI produced content
    will in fact be physically possible in all or even most contexts, especially as
    we make advances. The executive order doesn’t say anything about preventing models
    from being developed if their content crosses into undetectable territory, but
    that risk does worry me. That really would be stifling innovation, and we need
    to think very carefully about what the tradeoffs are or could be. Although, the
    horse may be out of that particular barn already — so many open source generative
    AI models are out there in the world, continuously getting better at what they
    do.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，我不确定检测生成性 AI 生成的内容在所有或大多数情况下是否实际上是可能的，特别是随着我们取得进展。行政命令没有提及如果内容跨越到不可检测的领域，是否阻止开发这些模型，但这种风险让我担忧。这真的会扼杀创新，我们需要仔细考虑权衡是什么或可能是什么。尽管如此，这匹马可能已经跑出了那座特定的马厩——如此多的开源生成性
    AI 模型已经存在于世界上，不断在改进它们的能力。
- en: Conclusion
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This topic is hard, and the right action to take is not necessarily very clear.
    The more sophisticated and complex the output of a model is, the better our chances
    of detecting that output is not human-generated, but we’re in a technological
    race that will make that detection harder and harder. Policy engagement on the
    topic may give us some guard rails, but we can’t know yet whether it will really
    help, or if it will turn out to be a ham-fisted disaster.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个话题很棘手，正确的行动并不一定很明确。模型输出越复杂，我们检测这些输出不是人类生成的可能性就越高，但我们正处于一个技术竞赛中，这将使得检测越来越困难。对这一话题的政策参与可能会给我们一些保护措施，但我们还不能确定这是否真的有帮助，或者是否会变成一场笨拙的灾难。
- en: This is one of those times when I don’t have a way to tie up the discussion
    in a neat bow. The potential and actual risks of indistinguishable generative
    AI output are serious, and should be treated as such. However, we are in a scientific/mathematical
    place where we can’t create a quick or easy solution, and we need to give weight
    to the benefits that more advanced generative AI could produce.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是其中一个我无法将讨论 neatly tie up 的时候。不可区分的生成性 AI 输出的潜在和实际风险是严重的，应当如此对待。然而，我们处于一个科学/数学的阶段，无法创造出快速或简单的解决方案，我们需要重视更先进的生成性
    AI 可能带来的好处。
- en: Regardless, data scientists should take time to read the executive order or
    at least the factsheet, and be clear about what the statement does and does not
    say. As regular readers will know, I think we’ve got to be responsible for spreading
    accurate and accessible information about these issues to the laypersons in our
    lives, and this is a good opportunity, since the topic is in the news. Make sure
    you contribute positively to the data science literacy around you.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: See more of my work at [www.stephaniekirmer.com](https://www.stephaniekirmer.com).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Casey Newton - [October 5 issue of Platformer](https://open.substack.com/pub/platformer/p/how-authoritarian-governments-are?r=7xzvu&utm_medium=ios&utm_campaign=post)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[The Fact Sheet on the Executive Order on AI](https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[The full document of the Executive Order on AI](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '[Reporting on deepfake fraud in ads, featuring Joe Rogan](https://mashable.com/article/joe-rogan-tiktok-deepfake-ad)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://contentauthenticity.org/?source=post_page-----286200498f93--------------------------------)
    [## Content Authenticity Initiative'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Creating the standard for digital content provenance.
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: contentauthenticity.org](https://contentauthenticity.org/?source=post_page-----286200498f93--------------------------------)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
