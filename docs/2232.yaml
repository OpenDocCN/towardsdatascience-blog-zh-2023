- en: 'Double Machine Learning, Simplified: Part 1 â€” Basic Causal Inference Applications'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŒé‡æœºå™¨å­¦ä¹ ç®€åŒ–ç‰ˆï¼šç¬¬1éƒ¨åˆ† â€” åŸºæœ¬çš„å› æœæ¨æ–­åº”ç”¨
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/double-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee?source=collection_archive---------2-----------------------#2023-07-12](https://towardsdatascience.com/double-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee?source=collection_archive---------2-----------------------#2023-07-12)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/double-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee?source=collection_archive---------2-----------------------#2023-07-12](https://towardsdatascience.com/double-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee?source=collection_archive---------2-----------------------#2023-07-12)
- en: '![](../Images/da07206f53b52134eaecbb622ac56914.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/da07206f53b52134eaecbb622ac56914.png)'
- en: All Images By Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€æœ‰å›¾ç‰‡ç”±ä½œè€…æä¾›
- en: Learn how to utilize DML in causal inference tasks
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å­¦ä¹ å¦‚ä½•åœ¨å› æœæ¨æ–­ä»»åŠ¡ä¸­åˆ©ç”¨DML
- en: '[](https://medium.com/@jakepenzak?source=post_page-----3f7afc9852ee--------------------------------)[![Jacob
    Pieniazek](../Images/2d9c6295d39fcaaec4e62f11c359cb29.png)](https://medium.com/@jakepenzak?source=post_page-----3f7afc9852ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3f7afc9852ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3f7afc9852ee--------------------------------)
    [Jacob Pieniazek](https://medium.com/@jakepenzak?source=post_page-----3f7afc9852ee--------------------------------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@jakepenzak?source=post_page-----3f7afc9852ee--------------------------------)[![Jacob
    Pieniazek](../Images/2d9c6295d39fcaaec4e62f11c359cb29.png)](https://medium.com/@jakepenzak?source=post_page-----3f7afc9852ee--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3f7afc9852ee--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3f7afc9852ee--------------------------------)
    [Jacob Pieniazek](https://medium.com/@jakepenzak?source=post_page-----3f7afc9852ee--------------------------------)'
- en: Â·
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0948d99b1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdouble-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=post_page-6f0948d99b1c----3f7afc9852ee---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3f7afc9852ee--------------------------------)
    Â·17 min readÂ·Jul 12, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3f7afc9852ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdouble-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=-----3f7afc9852ee---------------------clap_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6f0948d99b1c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdouble-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=post_page-6f0948d99b1c----3f7afc9852ee---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3f7afc9852ee--------------------------------)
    Â·17åˆ†é’Ÿé˜…è¯»Â·2023å¹´7æœˆ12æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3f7afc9852ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdouble-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee&user=Jacob+Pieniazek&userId=6f0948d99b1c&source=-----3f7afc9852ee---------------------clap_footer-----------)'
- en: --
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f7afc9852ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdouble-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee&source=-----3f7afc9852ee---------------------bookmark_footer-----------)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3f7afc9852ee&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdouble-machine-learning-simplified-part-1-basic-causal-inference-applications-3f7afc9852ee&source=-----3f7afc9852ee---------------------bookmark_footer-----------)'
- en: This article is the **1st** in a 2 part series on simplifying and democratizing
    Double Machine Learning. In the 1st part, we will be covering the fundamentals
    of Double Machine Learning, along with two basic causal inference applications
    in python. Then, in [pt. 2](https://medium.com/towards-data-science/double-machine-learning-simplified-part-2-extensions-the-cate-99926151cac),
    we will extend this knowledge to turn our causal inference problem into a prediction
    task, wherein we predict individual level treatment effects to aid in decision
    making and data-driven targeting.
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æœ¬æ–‡æ˜¯**2éƒ¨åˆ†**ç³»åˆ—ä¸­çš„**ç¬¬1éƒ¨åˆ†**ï¼Œæ—¨åœ¨ç®€åŒ–å’Œæ™®åŠåŒé‡æœºå™¨å­¦ä¹ ã€‚åœ¨ç¬¬1éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†è¦†ç›–åŒé‡æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†ï¼Œä»¥åŠä¸¤ä¸ªåŸºæœ¬çš„å› æœæ¨æ–­åº”ç”¨ç¤ºä¾‹ï¼ˆä½¿ç”¨pythonï¼‰ã€‚ç„¶åï¼Œåœ¨[ç¬¬2éƒ¨åˆ†](https://medium.com/towards-data-science/double-machine-learning-simplified-part-2-extensions-the-cate-99926151cac)ä¸­ï¼Œæˆ‘ä»¬å°†æ‰©å±•è¿™äº›çŸ¥è¯†ï¼Œå°†å› æœæ¨æ–­é—®é¢˜è½¬åŒ–ä¸ºé¢„æµ‹ä»»åŠ¡ï¼Œå…¶ä¸­æˆ‘ä»¬é¢„æµ‹ä¸ªä½“çº§åˆ«çš„å¤„ç†æ•ˆæœï¼Œä»¥è¾…åŠ©å†³ç­–å’Œæ•°æ®é©±åŠ¨çš„ç›®æ ‡å®šä½ã€‚
- en: The conceptual & practical distinctions between statistical/machine learning
    (ML) and causal inference/econometric (CI) tasks have been established for yearsâ€”
    ML seeks to predict, whereas CI seeks to infer a treatment effect or a â€œcausalâ€
    relationship between variables. However, it was, and still is, common for the
    data scientist to draw causal conclusions from parameters of a trained machine
    learning model, or some other interpretable ML methodology. Despite this, there
    has been significant strides in industry and across many academic disciplines
    to push more rigorousness in making causal claims, and this has stimulated a much
    wider and open discourse on CI. In this stride, we have seen amazing work come
    out that has begun to bridge the conceptual gap between ML and CI, specifically
    tools in CI that take advantage of the power of ML methodologies.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç»Ÿè®¡/æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä¸å› æœæ¨æ–­/è®¡é‡ç»æµå­¦ï¼ˆCIï¼‰ä»»åŠ¡ä¹‹é—´çš„æ¦‚å¿µæ€§å’Œå®è·µæ€§åŒºåˆ«å·²ç»å­˜åœ¨å¤šå¹´â€”â€”MLæ—¨åœ¨é¢„æµ‹ï¼Œè€ŒCIæ—¨åœ¨æ¨æ–­å¤„ç†æ•ˆæœæˆ–å˜é‡ä¹‹é—´çš„â€œå› æœâ€å…³ç³»ã€‚ç„¶è€Œï¼Œæ•°æ®ç§‘å­¦å®¶ä»ç„¶å¸¸å¸¸ä»è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹æˆ–å…¶ä»–å¯è§£é‡Šçš„MLæ–¹æ³•ä¸­å¾—å‡ºå› æœç»“è®ºã€‚å°½ç®¡å¦‚æ­¤ï¼Œä¸šç•Œå’Œè®¸å¤šå­¦æœ¯å­¦ç§‘åœ¨æ¨åŠ¨å› æœå£°æ˜çš„ä¸¥è°¨æ€§æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œè¿™ä¹Ÿåˆºæ¿€äº†å› æœæ¨æ–­é¢†åŸŸçš„å¹¿æ³›è®¨è®ºã€‚åœ¨è¿™ä¸€è¿›å±•ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸€äº›æƒŠäººçš„å·¥ä½œï¼Œå¼€å§‹å¼¥åˆMLä¸CIä¹‹é—´çš„æ¦‚å¿µå·®è·ï¼Œç‰¹åˆ«æ˜¯CIå·¥å…·åˆ©ç”¨äº†MLæ–¹æ³•çš„å¼ºå¤§èƒ½åŠ›ã€‚
- en: 'The primary motivation for this series is to democratize the usage of & applications
    of Double Machine Learning (DML), first introduced by Chernozhukov *et al.* in
    their pioneering paper â€œDouble Machine Learning for Treatment and Causal Parametersâ€,
    and to enable the data scientist to utilize DML in their daily causal inference
    tasks.[1] In doing so, we will first dive into the fundamentals of DML. Specifically,
    we will cover some of the conceptual/theoretical underpinnings, including the
    regression framework for causality & the [Frisch-Waugh-Lovell Theorem](https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem),
    and then we will use this framework to develop DML. Lastly, we will demonstrate
    two notable applications of Double Machine Learning:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç³»åˆ—çš„ä¸»è¦åŠ¨æœºæ˜¯ä½¿åŒé‡æœºå™¨å­¦ä¹ ï¼ˆDMLï¼‰çš„ä½¿ç”¨å’Œåº”ç”¨å˜å¾—æ™®åŠï¼Œè¿™ä¸€æ–¹æ³•é¦–æ¬¡ç”±Chernozhukov *ç­‰äºº*åœ¨å…¶å¼€åˆ›æ€§è®ºæ–‡ã€Šç”¨äºå¤„ç†å’Œå› æœå‚æ•°çš„åŒé‡æœºå™¨å­¦ä¹ ã€‹ä¸­ä»‹ç»ï¼Œå¹¶ä½¿æ•°æ®ç§‘å­¦å®¶èƒ½å¤Ÿåœ¨æ—¥å¸¸å› æœæ¨æ–­ä»»åŠ¡ä¸­åˆ©ç”¨DMLã€‚[1]
    ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†é¦–å…ˆæ·±å…¥æ¢è®¨DMLçš„åŸºç¡€çŸ¥è¯†ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å°†æ¶µç›–ä¸€äº›æ¦‚å¿µ/ç†è®ºåŸºç¡€ï¼ŒåŒ…æ‹¬å› æœå…³ç³»çš„å›å½’æ¡†æ¶åŠ[Frisch-Waugh-Lovellå®šç†](https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem)ï¼Œç„¶åæˆ‘ä»¬å°†åˆ©ç”¨è¿™ä¸€æ¡†æ¶æ¥å‘å±•DMLã€‚æœ€åï¼Œæˆ‘ä»¬å°†å±•ç¤ºåŒé‡æœºå™¨å­¦ä¹ çš„ä¸¤ä¸ªæ˜¾è‘—åº”ç”¨ï¼š
- en: '*Converging towards Exogeneity/CIA/Ignorability in our Treatment given Non-Experimental/Observational
    Data (particularly when our set of covariates is of high dimensionality),* and'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*åœ¨æˆ‘ä»¬çš„å¤„ç†è¿‡ç¨‹ä¸­è¶‹å‘äºå¤–ç”Ÿæ€§/CIA/å¯å¿½ç•¥æ€§ï¼ˆå°¤å…¶æ˜¯å½“æˆ‘ä»¬çš„åå˜é‡é›†å…·æœ‰é«˜ç»´åº¦æ—¶ï¼‰*'
- en: '*Improving Precision & Statistical Power in Experimental Data (Randomized Controlled
    Trialâ€™s (RCTs) or A/B Tests)*'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*åœ¨å®éªŒæ•°æ®ï¼ˆéšæœºå¯¹ç…§è¯•éªŒï¼ˆRCTsï¼‰æˆ–A/Bæµ‹è¯•ï¼‰ä¸­æé«˜ç²¾ç¡®åº¦å’Œç»Ÿè®¡åŠŸæ•ˆ*'
- en: If this already all feels extremely foreign, I recommend checking out my [previous
    article](https://medium.com/towards-data-science/controlling-for-x-9cb51652f7ad)
    that covers the regression framework for causality and the Frisch-Waugh-Lovell
    Theorem. Nevertheless, I will cover these topic below and do my best to simplify
    and make this accessible to all. Letâ€™s first dive into a quick overview of these
    theoretical underpinnings!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœè¿™äº›å†…å®¹å¯¹ä½ æ¥è¯´ä»æ„Ÿåˆ°éå¸¸é™Œç”Ÿï¼Œæˆ‘æ¨èæŸ¥çœ‹æˆ‘çš„[ä¸Šä¸€ç¯‡æ–‡ç« ](https://medium.com/towards-data-science/controlling-for-x-9cb51652f7ad)ï¼Œå…¶ä¸­æ¶µç›–äº†å› æœå›å½’æ¡†æ¶å’ŒFrisch-Waugh-Lovellå®šç†ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä¼šåœ¨ä¸‹é¢æ¶µç›–è¿™äº›ä¸»é¢˜ï¼Œå¹¶å°½åŠ›ç®€åŒ–å¹¶ä½¿å…¶å¯¹æ‰€æœ‰äººéƒ½æ˜“äºç†è§£ã€‚è®©æˆ‘ä»¬é¦–å…ˆå¿«é€Ÿæ¦‚è¿°ä¸€ä¸‹è¿™äº›ç†è®ºåŸºç¡€ï¼
- en: '**Regression Framework for Causality & the FWL Theorem**'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**å› æœå›å½’æ¡†æ¶ä¸FWLå®šç†**'
- en: 'The gold standard for establishing causality is an RCT or A/B test, wherein
    we randomly assign a subset of individuals to receive treatment, ***T***, (the
    test group) and others to not receive treatment (the control group), or a different
    treatment (in â€œA/Bâ€ testing). To estimate the average treatment effect (ATE) of
    treatment on outcome ***y***, we can estimate the following bivariate linear regression:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ç¡®ç«‹å› æœå…³ç³»çš„é‡‘æ ‡å‡†æ˜¯RCTæˆ–A/Bæµ‹è¯•ï¼Œåœ¨è¿™äº›æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬éšæœºåˆ†é…ä¸€éƒ¨åˆ†ä¸ªä½“æ¥å—å¤„ç†ï¼Œ***T***ï¼ˆæµ‹è¯•ç»„ï¼‰ï¼Œè€Œå…¶ä»–ä¸ªä½“åˆ™ä¸æ¥å—å¤„ç†ï¼ˆå¯¹ç…§ç»„ï¼‰æˆ–æ¥å—ä¸åŒçš„å¤„ç†ï¼ˆåœ¨â€œA/Bâ€æµ‹è¯•ä¸­ï¼‰ã€‚ä¸ºäº†ä¼°è®¡å¤„ç†å¯¹ç»“æœ***y***çš„å¹³å‡å¤„ç†æ•ˆåº”ï¼ˆATEï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ä¼°è®¡ä»¥ä¸‹åŒå˜é‡çº¿æ€§å›å½’ï¼š
- en: '![](../Images/87b4dd0faf84275195a1089a75aeeeac.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/87b4dd0faf84275195a1089a75aeeeac.png)'
- en: (1)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: (1)
- en: 'Because treatment is randomly assigned, we ensure that treatment is exogenous;
    that is, independent of the error term, Îµ, and thus there exists not confounders
    (a variable that effects both treatment and the outcome) that we have not controlled
    forâ€” cov(T,Îµ)=0 (e.g., suppose, as a violation, y = earnings & T = years of education,
    then we can anticipate a variable such as IQ in Îµ to confound the true relationship).
    Because of this independence, the coefficient estimate on ***T*** takes on a causal
    interpretation â€” the ATE:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºå¤„ç†æ˜¯éšæœºåˆ†é…çš„ï¼Œæˆ‘ä»¬ç¡®ä¿å¤„ç†æ˜¯å¤–ç”Ÿçš„ï¼›å³ï¼Œç‹¬ç«‹äºè¯¯å·®é¡¹Îµï¼Œå› æ­¤ä¸å­˜åœ¨æˆ‘ä»¬æœªæ§åˆ¶çš„æ··æ‚å˜é‡ï¼ˆå½±å“å¤„ç†å’Œç»“æœçš„å˜é‡ï¼‰â€”â€” cov(T,Îµ)=0ï¼ˆä¾‹å¦‚ï¼Œå‡è®¾è¿åæƒ…å†µä¸‹ï¼Œy
    = æ”¶å…¥ & T = æ•™è‚²å¹´é™ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥é¢„æœŸä¾‹å¦‚IQè¿™æ ·çš„å˜é‡ä¼šåœ¨Îµä¸­æ··æ‚çœŸå®å…³ç³»ï¼‰ã€‚ç”±äºè¿™ç§ç‹¬ç«‹æ€§ï¼Œ***T***ä¸Šçš„ç³»æ•°ä¼°è®¡å…·æœ‰å› æœè§£é‡Šâ€”â€”ATEï¼š
- en: '![](../Images/213cbd04b9c2a4f3c5ffa3c312ca5a9d.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/213cbd04b9c2a4f3c5ffa3c312ca5a9d.png)'
- en: (2) Discrete Treatment
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: (2) ç¦»æ•£å¤„ç†
- en: '![](../Images/3e46a068bc011e05cddc440fe236c909.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e46a068bc011e05cddc440fe236c909.png)'
- en: (3) Continuous Treatment
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (3) è¿ç»­å¤„ç†
- en: 'When we are dealing with non-experimental or observational data, it is almost
    always the case that the treatment of interest is *not* independent of Îµ, or endogenous
    â€” cov(T,Îµ)â‰ 0, and there exists confounders that we have not accounted for. In
    other words, we no longer can parse out the true random variation in our treatment
    to explain our outcome. In this case, a simple bivariate regression will result
    in a biased estimate of the ATE (Î² (true ATE) + bias) due to [omitted variable
    bias](https://en.wikipedia.org/wiki/Omitted-variable_bias). However, if we can
    control for all possible confounders, ***X****, and the confounding functional
    form if using parametric models*, we can achieve exogeneity in our treatment,
    or what is also known as the conditional independence assumption (CIA), or [Ignorability](https://en.wikipedia.org/wiki/Ignorability).
    In other words again, the remaining variation in our treatment is â€œas good as
    randomâ€. That is, there are no remaining confounders in the error term, or:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å¤„ç†éå®éªŒæˆ–è§‚å¯Ÿæ•°æ®æ—¶ï¼Œå‡ ä¹æ€»æ˜¯å¤„ç†å˜é‡*ä¸æ˜¯*ä¸Îµç‹¬ç«‹çš„ï¼Œæˆ–è€…æ˜¯å†…ç”Ÿçš„â€”â€”cov(T,Îµ)â‰ 0ï¼Œå¹¶ä¸”å­˜åœ¨æˆ‘ä»¬æœªè€ƒè™‘çš„æ··æ‚å˜é‡ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬ä¸èƒ½å†å°†å¤„ç†ä¸­çš„çœŸå®éšæœºå˜åŒ–ä¸ç»“æœè§£é‡Šåˆ†å¼€ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç®€å•çš„åŒå˜é‡å›å½’å°†å› [é—æ¼å˜é‡åå€š](https://en.wikipedia.org/wiki/Omitted-variable_bias)è€Œå¯¼è‡´ATEçš„åå€šä¼°è®¡ï¼ˆÎ²ï¼ˆçœŸå®ATEï¼‰+åå€šï¼‰ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬èƒ½æ§åˆ¶æ‰€æœ‰å¯èƒ½çš„æ··æ‚å˜é‡ï¼Œ***X***ï¼Œä»¥åŠåœ¨ä½¿ç”¨å‚æ•°æ¨¡å‹æ—¶çš„æ··æ‚å‡½æ•°å½¢å¼ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æˆ‘ä»¬çš„å¤„ç†ä¸Šå®ç°å¤–ç”Ÿæ€§ï¼Œæˆ–è€…ä¹Ÿç§°ä¸ºæ¡ä»¶ç‹¬ç«‹å‡è®¾ï¼ˆCIAï¼‰ï¼Œæˆ–[å¯å¿½ç•¥æ€§](https://en.wikipedia.org/wiki/Ignorability)ã€‚æ¢å¥è¯è¯´ï¼Œå¤„ç†ä¸­çš„å‰©ä½™å˜åŒ–æ˜¯â€œå¥½åƒæ˜¯éšæœºçš„â€ã€‚å³ï¼Œåœ¨è¯¯å·®é¡¹ä¸­æ²¡æœ‰å‰©ä½™çš„æ··æ‚å› ç´ ï¼Œæˆ–è€…ï¼š
- en: '![](../Images/3a1755f6c8ffa8a77aa93b329115582c.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a1755f6c8ffa8a77aa93b329115582c.png)'
- en: (4)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: (4)
- en: 'If exogeneity holds (there are no confounders outside of ***X***), then controlling
    for ***X*** in a multiple regressionallows for the coefficient estimate on ***T***
    to take on the similar causal interpretation of the ATE:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœå¤–ç”Ÿæ€§æˆç«‹ï¼ˆ***X***ä¹‹å¤–æ²¡æœ‰æ··æ‚å˜é‡ï¼‰ï¼Œé‚£ä¹ˆåœ¨å¤šå…ƒå›å½’ä¸­æ§åˆ¶***X***å…è®¸***T***ä¸Šçš„ç³»æ•°ä¼°è®¡å…·æœ‰ç±»ä¼¼çš„ATEå› æœè§£é‡Šï¼š
- en: '![](../Images/477994ca9c5169f96e9c1b94ac8a385a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/477994ca9c5169f96e9c1b94ac8a385a.png)'
- en: (5)
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: (5)
- en: '**Warning:** It is not best practice to control for every possible covariate,
    but rather variables that are hypothesized/known to influence both the outcome,
    y, and treatment of interest, T. This is the concept of a [confounder](https://en.wikipedia.org/wiki/Confounding).
    Conversely, if both y and T influence a variable, we do not want to control for
    this variable, as this can introduce a spurious association between y and T. This
    is the concept of a [collider](https://en.wikipedia.org/wiki/Collider_(statistics))
    variable. We will show an example of this in action further in this article. Additionally,
    we do not want to include variables that are mediators of our treatment; that
    is, a covariate that is impacted by the treatment that in turn impacts the outcome.
    The inclusion of this mediator variable can eat away at the estimate of our treatment
    effect. In short, we only want to include confounders (and, possibly, non-mediator
    & non-collider predictors of y to improve precision; this is discussed in example
    2 below).'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**è­¦å‘Šï¼š** æ§åˆ¶æ‰€æœ‰å¯èƒ½çš„åå˜é‡ä¸æ˜¯æœ€ä½³å®è·µï¼Œè€Œæ˜¯æ§åˆ¶é‚£äº›è¢«å‡è®¾/å·²çŸ¥ä¼šå½±å“ç»“æœ***y***å’Œæ„Ÿå…´è¶£çš„å¤„ç†***T***çš„å˜é‡ã€‚è¿™æ˜¯[æ··æ·†å˜é‡](https://en.wikipedia.org/wiki/Confounding)çš„æ¦‚å¿µã€‚ç›¸åï¼Œå¦‚æœ***y***å’Œ***T***éƒ½å½±å“æŸä¸ªå˜é‡ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›æ§åˆ¶è¯¥å˜é‡ï¼Œå› ä¸ºè¿™å¯èƒ½ä¼šå¼•å…¥***y***å’Œ***T***ä¹‹é—´çš„è™šå‡å…³è”ã€‚è¿™æ˜¯[ç¢°æ’å˜é‡](https://en.wikipedia.org/wiki/Collider_(statistics))çš„æ¦‚å¿µã€‚æˆ‘ä»¬å°†åœ¨æœ¬æ–‡åé¢å±•ç¤ºè¿™ä¸€ç‚¹çš„å®é™…ä¾‹å­ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›åŒ…æ‹¬é‚£äº›æ˜¯æˆ‘ä»¬å¤„ç†å˜é‡çš„ä¸­ä»‹å˜é‡çš„å˜é‡ï¼›å³ï¼Œä¸€ä¸ªå—å¤„ç†å½±å“è¿›è€Œå½±å“ç»“æœçš„åå˜é‡ã€‚åŒ…æ‹¬è¿™ç§ä¸­ä»‹å˜é‡å¯èƒ½ä¼šä¾µèš€æˆ‘ä»¬å¤„ç†æ•ˆåº”çš„ä¼°è®¡ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬åªå¸Œæœ›åŒ…æ‹¬æ··æ·†å˜é‡ï¼ˆä»¥åŠå¯èƒ½çš„éä¸­ä»‹å’Œéç¢°æ’é¢„æµ‹å˜é‡ä»¥æé«˜ç²¾ç¡®åº¦ï¼›è¿™å°†åœ¨ä¸‹é¢çš„ä¾‹å­2ä¸­è®¨è®ºï¼‰ã€‚'
- en: However, in practice, exogeneity/CIA/Ignorability is very difficult to obtain
    and justify as it is unlikely that we will be able to observe every confounder
    and control for potential non-linear relationships these confounders may take
    on. This provides one particular motivation for DML â€” however, letâ€™s first discuss
    the FWL theorem, as this allows us to theoretically develop DML.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œå¤–ç”Ÿæ€§/CIA/å¯å¿½ç•¥æ€§éå¸¸éš¾ä»¥è·å¾—å’Œè¯æ˜ï¼Œå› ä¸ºæˆ‘ä»¬ä¸å¤ªå¯èƒ½è§‚å¯Ÿåˆ°æ‰€æœ‰çš„æ··æ·†å˜é‡å¹¶æ§åˆ¶è¿™äº›æ··æ·†å˜é‡å¯èƒ½å‡ºç°çš„æ½œåœ¨éçº¿æ€§å…³ç³»ã€‚è¿™æ˜¯DMLçš„ä¸€ä¸ªç‰¹å®šåŠ¨æœºâ€”â€”ç„¶è€Œï¼Œè®©æˆ‘ä»¬é¦–å…ˆè®¨è®ºFWLå®šç†ï¼Œå› ä¸ºè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿç†è®ºä¸Šå¼€å‘DMLã€‚
- en: 'The [FWL theorem](https://en.wikipedia.org/wiki/Frisch%e2%80%93Waugh%e2%80%93Lovell_theorem)
    is a notable econometric theorem that allows us to obtain the ***identical***
    ATE parameter estimate, Î²â‚, on the treatment, ***T***, in the multiple regression
    above (eq. 5) utilizing the following 3 step procedure:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[FWLå®šç†](https://en.wikipedia.org/wiki/Frisch%e2%80%93Waugh%e2%80%93Lovell_theorem)æ˜¯ä¸€ä¸ªé‡è¦çš„è®¡é‡ç»æµå­¦å®šç†ï¼Œå®ƒå…è®¸æˆ‘ä»¬åœ¨ä¸Šè¿°å¤šé‡å›å½’ï¼ˆæ–¹ç¨‹5ï¼‰ä¸­åˆ©ç”¨ä»¥ä¸‹3æ­¥ç¨‹åºè·å¾—***ç›¸åŒçš„***ATEå‚æ•°ä¼°è®¡Î²â‚ï¼Œå…³äºå¤„ç†å˜é‡***T***ï¼š'
- en: Separately regress ***y*** on ***X*** and ***T*** on ***X***
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åˆ†åˆ«å¯¹***y***è¿›è¡Œå›å½’***X***ï¼Œå¯¹***T***è¿›è¡Œå›å½’***X***
- en: Save the residuals from step 1â€” call it ***y**** and ***T****
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä¿å­˜ç¬¬1æ­¥çš„æ®‹å·®â€”â€”ç§°ä¹‹ä¸º***y***å’Œ***T***ã€‚
- en: Regress ***y**** on ***T****
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹***y***è¿›è¡Œå›å½’***T***
- en: In quasi- python code,
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å‡†Pythonä»£ç ä¸­ï¼Œ
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Intuitively, the FWL theorem partials out the variation in ***T*** and ***y***
    that is explained by the confounders, ***X***, and then uses the remaining variation
    to explain the key relationship of interest (ie, how ***T*** effects ***y***).
    More specifically, it exploits a special type of orthogonal projection matrix
    of ***X*** known as an annihilator matrix or residual-maker matrix to residualize
    ***T*** and ***y***. For a hands-on application of the FWL procedure, see my [previous
    post](/controlling-for-x-9cb51652f7ad). This theorem is pivotal in understanding
    DML.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´è§‚åœ°è¯´ï¼ŒFWLå®šç†å°†***T***å’Œ***y***ä¸­çš„å˜å¼‚éƒ¨åˆ†ä»æ··æ·†å˜é‡***X***ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œç„¶ååˆ©ç”¨å‰©ä½™çš„å˜å¼‚æ¥è§£é‡Šå…³é”®çš„å…³ç³»ï¼ˆå³ï¼Œ***T***å¦‚ä½•å½±å“***y***ï¼‰ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œå®ƒåˆ©ç”¨***X***çš„ä¸€ç§ç‰¹æ®Šç±»å‹çš„æ­£äº¤æŠ•å½±çŸ©é˜µï¼Œç§°ä¸ºæ¶ˆé™¤çŸ©é˜µæˆ–æ®‹å·®ç”ŸæˆçŸ©é˜µï¼Œæ¥æ®‹å·®åŒ–***T***å’Œ***y***ã€‚æœ‰å…³FWLç¨‹åºçš„å®é™…åº”ç”¨ï¼Œè¯·å‚è§æˆ‘ä¹‹å‰çš„[å¸–å­](/controlling-for-x-9cb51652f7ad)ã€‚è¯¥å®šç†å¯¹äºç†è§£DMLè‡³å…³é‡è¦ã€‚
- en: Note that I have (intentionally) glossed over some additional causal inference
    assumptions, such as Positivity/Common Support & SUTVA/Counterfactual Consistency.
    In general, the CIA/Ignorability assumption is the most common assumption that
    needs to be defended. However, it is recommended that the interested reader familiarize
    themselves with the additional assumptuons. In brief, Positivity ensures we have
    non-treated households that are similar & comparable to treated households to
    enable counterfactual estimation & SUTVA ensures there is no spillover/network
    type effects (treatment of one individual impacts another).
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæˆ‘ï¼ˆæ•…æ„ï¼‰ç•¥è¿‡äº†ä¸€äº›é¢å¤–çš„å› æœæ¨æ–­å‡è®¾ï¼Œä¾‹å¦‚ Positivity/Common Support å’Œ SUTVA/åäº‹å®ä¸€è‡´æ€§ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒCIA/å¯å¿½ç•¥æ€§å‡è®¾æ˜¯éœ€è¦è¾©æŠ¤çš„æœ€å¸¸è§å‡è®¾ã€‚ç„¶è€Œï¼Œå»ºè®®æ„Ÿå…´è¶£çš„è¯»è€…ç†Ÿæ‚‰é¢å¤–çš„å‡è®¾ã€‚ç®€è¨€ä¹‹ï¼ŒPositivity
    ç¡®ä¿æˆ‘ä»¬æœ‰ä¸å¤„ç†è¿‡çš„å®¶åº­ç›¸ä¼¼ä¸”å¯æ¯”è¾ƒçš„æœªå¤„ç†å®¶åº­ï¼Œä»¥ä¾¿è¿›è¡Œåäº‹å®ä¼°è®¡ï¼Œè€Œ SUTVA ç¡®ä¿æ²¡æœ‰æº¢å‡º/ç½‘ç»œç±»å‹æ•ˆåº”ï¼ˆä¸€ä¸ªä¸ªä½“çš„å¤„ç†å½±å“å¦ä¸€ä¸ªä¸ªä½“ï¼‰ã€‚
- en: Double Machine Learningâ€¦ Simplified!
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åŒé‡æœºå™¨å­¦ä¹ â€¦ ç®€åŒ–ç‰ˆï¼
- en: 'Double Machine Learning, at its core, allows for the residualization/orthogonalization
    done in steps 1) and 2) of the FWL procedure to be conducted using any highly
    flexible ML model, thus constructing a partially linear model. That is, we can
    estimate the ATE via:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åŒé‡æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ˜¯å…è®¸åœ¨ FWL ç¨‹åºçš„æ­¥éª¤ 1) å’Œ 2) ä¸­è¿›è¡Œçš„æ®‹å·®åŒ–/æ­£äº¤åŒ–ä½¿ç”¨ä»»ä½•é«˜åº¦çµæ´»çš„ ML æ¨¡å‹ï¼Œä»è€Œæ„é€ ä¸€ä¸ªéƒ¨åˆ†çº¿æ€§æ¨¡å‹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¼°è®¡
    ATEï¼š
- en: '![](../Images/ff40e6bdeac9222544390e90e9b8ed1a.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ff40e6bdeac9222544390e90e9b8ed1a.png)'
- en: (6)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: (6)
- en: 'where **ğ‘€ğ‘¦** and ***MT*** are both any *ML* models to predict ***y*** and ***T***
    given confounders and/or controls, ***X***, respectively. **ğ‘€ğ‘¦** and ***MT***
    are also known as the â€œnuisance functionsâ€ as we are constructing functions to
    partial out the variation in ***y*** and ***T*** explained by X, which is not
    of primary interest. To avoid overfitting and to ensure robustness in this approach,
    we use *cross-validation prediction* via sample- & cross-fitting. I believe it
    will be useful again here to see this procedure outlined in quasi- python code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­**ğ‘€ğ‘¦**å’Œ***MT***éƒ½æ˜¯ä»»ä½•ç”¨äºé¢„æµ‹***y***å’Œ***T***çš„*ML*æ¨¡å‹ï¼Œç»™å®šæ··æ·†å› ç´ å’Œ/æˆ–æ§åˆ¶å˜é‡***X***ã€‚**ğ‘€ğ‘¦**å’Œ***MT***ä¹Ÿè¢«ç§°ä¸ºâ€œå¹²æ‰°å‡½æ•°â€ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨æ„é€ å‡½æ•°æ¥éƒ¨åˆ†å»é™¤***y***å’Œ***T***ä¸­ç”±
    X è§£é‡Šçš„å˜åŒ–ï¼Œè¿™ä¸æ˜¯ä¸»è¦å…³æ³¨çš„å†…å®¹ã€‚ä¸ºäº†é¿å…è¿‡æ‹Ÿåˆå¹¶ç¡®ä¿è¿™ç§æ–¹æ³•çš„ç¨³å¥æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨*äº¤å‰éªŒè¯é¢„æµ‹*é€šè¿‡æ ·æœ¬å’Œäº¤å‰æ‹Ÿåˆã€‚æˆ‘ç›¸ä¿¡è¿™é‡Œå†æ¬¡çœ‹åˆ°è¿™ç§ç¨‹åºåœ¨å‡† Python
    ä»£ç ä¸­çš„ç¤ºä¾‹ä¼šå¾ˆæœ‰ç”¨ï¼š
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Where the coefficient on *T_residual* will be our estimated ATE, with asymptotically
    normal inference around our estimate. And, thatâ€™s it!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *T_residual* ä¸Šçš„ç³»æ•°å°†æ˜¯æˆ‘ä»¬ä¼°è®¡çš„ ATEï¼Œå¹¶ä¸”å›´ç»•æˆ‘ä»¬çš„ä¼°è®¡æœ‰æ¸è¿‘æ­£æ€æ¨æ–­ã€‚å°±è¿™æ ·ï¼
- en: This is the procedure behind DML for estimating the ATE. *It enables our modeling
    of the confounding to be highly flexible and non-parametric, particularly in the
    presence of a high dimensional set of covariates.*
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ DML ä¼°è®¡ ATE èƒŒåçš„è¿‡ç¨‹ã€‚*å®ƒä½¿æˆ‘ä»¬çš„æ··æ·†å»ºæ¨¡å…·æœ‰é«˜åº¦çš„çµæ´»æ€§å’Œéå‚æ•°ç‰¹æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨å­˜åœ¨é«˜ç»´åå˜é‡çš„æƒ…å†µä¸‹ã€‚*
- en: I will not dive too deep into the technicalities of why this works, and I will
    refer the interested reader to the [original paper](https://arxiv.org/pdf/1608.00060.pdf)
    and [EconML documentation](https://econml.azurewebsites.net/index.html). However,
    in brief, DML satisfies a condition known as Neyman Orthogonality (ie, small perturbations
    in the nuisance functions around the true value has second order effects on the
    moment condition and thus does not impact our key parameter estimate), which solves
    for regularization bias, and when combined with the cross-validation procedure
    in DML, which solves for overfitting bias, we ensure robustness in this method.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ä¼šæ·±å…¥æ¢è®¨ä¸ºä»€ä¹ˆè¿™æœ‰æ•ˆçš„æŠ€æœ¯ç»†èŠ‚ï¼Œå¹¶ä¸”æˆ‘ä¼šå°†æ„Ÿå…´è¶£çš„è¯»è€…å¼•å¯¼åˆ°[åŸå§‹è®ºæ–‡](https://arxiv.org/pdf/1608.00060.pdf)å’Œ[EconML
    æ–‡æ¡£](https://econml.azurewebsites.net/index.html)ã€‚ç„¶è€Œï¼Œç®€è€Œè¨€ä¹‹ï¼ŒDML æ»¡è¶³ä¸€ä¸ªç§°ä¸º Neyman æ­£äº¤æ€§çš„æ¡ä»¶ï¼ˆå³ï¼Œå¹²æ‰°å‡½æ•°åœ¨çœŸå®å€¼é™„è¿‘çš„å°æ‰°åŠ¨å¯¹çŸ©æ¡ä»¶æœ‰äºŒé˜¶æ•ˆåº”ï¼Œå› æ­¤ä¸ä¼šå½±å“æˆ‘ä»¬çš„å…³é”®å‚æ•°ä¼°è®¡ï¼‰ï¼Œè¿™è§£å†³äº†æ­£åˆ™åŒ–åå·®çš„é—®é¢˜ï¼Œå¹¶ä¸”ä¸
    DML ä¸­çš„äº¤å‰éªŒè¯ç¨‹åºç»“åˆä½¿ç”¨ï¼Œè§£å†³äº†è¿‡æ‹Ÿåˆåå·®ï¼Œä»è€Œç¡®ä¿äº†è¯¥æ–¹æ³•çš„ç¨³å¥æ€§ã€‚
- en: There are some very cool extensions on DML that will be covered in [part 2](https://medium.com/towards-data-science/double-machine-learning-simplified-part-2-extensions-the-cate-99926151cac)
    of the series, but for now letâ€™s see this in action via two applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: DML æœ‰ä¸€äº›éå¸¸é…·çš„æ‰©å±•å°†åœ¨ç³»åˆ—çš„[ç¬¬ 2 éƒ¨åˆ†](https://medium.com/towards-data-science/double-machine-learning-simplified-part-2-extensions-the-cate-99926151cac)ä¸­è®¨è®ºï¼Œä½†ç°åœ¨æˆ‘ä»¬å…ˆé€šè¿‡ä¸¤ä¸ªåº”ç”¨æ¥æŸ¥çœ‹å®ƒçš„å®é™…æ•ˆæœã€‚
- en: DML Applications
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DML åº”ç”¨
- en: '**Application 1:** *Converging towards Exogeneity/CIA/Ignorability in our Treatment
    given Non-Experimental/Observational Data*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**åº”ç”¨ 1ï¼š** *åœ¨å¤„ç†éå®éªŒ/è§‚å¯Ÿæ•°æ®æ—¶ï¼Œè¶‹å‘äºå¤–ç”Ÿæ€§/CIA/å¯å¿½ç•¥æ€§*'
- en: 'Recall that we discussed how in the absence of randomized experimental data
    we must control for all potential confounders to ensure we obtain exogeneity in
    our treatment of interest. In other words, when we control for all potential confounders,
    our treatment is â€œas good as randomly assignedâ€. There are two primary problems
    that still persist here:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å›é¡¾ä¸€ä¸‹ï¼Œæˆ‘ä»¬è®¨è®ºäº†åœ¨æ²¡æœ‰éšæœºå®éªŒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»æ§åˆ¶æ‰€æœ‰æ½œåœ¨çš„æ··æ‚å› ç´ ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬è·å¾—æˆ‘ä»¬æ„Ÿå…´è¶£çš„å¤„ç†çš„å¤–ç”Ÿæ€§ã€‚æ¢å¥è¯è¯´ï¼Œå½“æˆ‘ä»¬æ§åˆ¶äº†æ‰€æœ‰æ½œåœ¨çš„æ··æ‚å› ç´ æ—¶ï¼Œæˆ‘ä»¬çš„å¤„ç†æ˜¯â€œå¦‚åŒéšæœºåˆ†é…â€ã€‚è¿™é‡Œä»ç„¶å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼š
- en: It is difficult, and impossible in some cases, to truly know all of the confounders
    and, furthermore, to obtain the data for all these confounders. Solutioning this
    involves strong institutional knowledge of the data generating process, careful
    construction of the causal model (i.e., building a [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)
    while evaluating potential confounders and avoiding colliders), and/or exploiting
    [quasi-experimental](https://en.wikipedia.org/wiki/Quasi-experiment) designs.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: äº†è§£æ‰€æœ‰æ··æ‚å› ç´ å¹¶ä¸”è·å–æ‰€æœ‰è¿™äº›æ··æ‚å› ç´ çš„æ•°æ®æ˜¯å›°éš¾çš„ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ç”šè‡³æ˜¯ä¸å¯èƒ½çš„ã€‚è§£å†³è¿™ä¸ªé—®é¢˜æ¶‰åŠå¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„æ·±å…¥äº†è§£ï¼Œä»”ç»†æ„å»ºå› æœæ¨¡å‹ï¼ˆå³ï¼Œæ„å»ºä¸€ä¸ª[DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph)çš„åŒæ—¶è¯„ä¼°æ½œåœ¨æ··æ‚å› ç´ å¹¶é¿å…ç¢°æ’å™¨ï¼‰ï¼Œä»¥åŠ/æˆ–è€…åˆ©ç”¨[å‡†å®éªŒ](https://en.wikipedia.org/wiki/Quasi-experiment)è®¾è®¡ã€‚
- en: If we do take manage to take care of point 1, we still have to specify the correct
    parametric form of confounding, including interactions and higher-order terms,
    when utilizing a parametric model (such as in the regression framework). Simply
    including linear terms in a regression may not sufficiently control for the confounding.
    This is where DML steps in; it can flexibly partial out the confounding in a highly
    non-parametric fashion. This is particularly beneficial in saving the data scientist
    the trouble of directly modeling the functional forms of confounding, and allows
    more attention to be directed towards identifying and measuring the confounders.
    Letâ€™s see how this works!
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ç¡®å®å¤„ç†äº†ç¬¬ä¸€ç‚¹ï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦åœ¨ä½¿ç”¨å‚æ•°æ¨¡å‹ï¼ˆä¾‹å¦‚åœ¨å›å½’æ¡†æ¶ä¸­ï¼‰æ—¶æŒ‡å®šæ··æ‚çš„æ­£ç¡®å‚æ•°å½¢å¼ï¼ŒåŒ…æ‹¬äº¤äº’é¡¹å’Œé«˜é˜¶é¡¹ã€‚ä»…åœ¨å›å½’ä¸­åŒ…å«çº¿æ€§é¡¹å¯èƒ½ä¸è¶³ä»¥æ§åˆ¶æ··æ‚ã€‚è¿™å°±æ˜¯DMLå‘æŒ¥ä½œç”¨çš„åœ°æ–¹ï¼›å®ƒå¯ä»¥ä»¥é«˜åº¦éå‚æ•°çš„æ–¹å¼çµæ´»åœ°éƒ¨åˆ†æ§åˆ¶æ··æ‚ã€‚è¿™ç‰¹åˆ«æœ‰åˆ©äºèŠ‚çœæ•°æ®ç§‘å­¦å®¶ç›´æ¥å»ºæ¨¡æ··æ‚çš„å‡½æ•°å½¢å¼çš„éº»çƒ¦ï¼Œå¹¶ä½¿æ›´å¤šçš„æ³¨æ„åŠ›å¯ä»¥é›†ä¸­åœ¨è¯†åˆ«å’Œæµ‹é‡æ··æ‚å› ç´ ä¸Šã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼
- en: 'Suppose, as a highly stylized example, we work for an e-commerce company and
    we are tasked with estimating the ATE of an individuals time spent on the website
    on their purchase amount, or sales, in the past month. However, further assume
    we only have observational data to work with, but we have measured all potential
    confounders (those variables that influence both time spent on the website and
    sales). Let this causal process be outlined via the following Directed Acyclic
    Graph (DAG):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ï¼Œä½œä¸ºä¸€ä¸ªé«˜åº¦ç®€åŒ–çš„ä¾‹å­ï¼Œæˆ‘ä»¬åœ¨ä¸€å®¶ç”µå­å•†åŠ¡å…¬å¸å·¥ä½œï¼Œå¹¶ä¸”æˆ‘ä»¬çš„ä»»åŠ¡æ˜¯ä¼°è®¡ä¸ªäººåœ¨ç½‘ç«™ä¸ŠèŠ±è´¹çš„æ—¶é—´å¯¹ä»–ä»¬åœ¨è¿‡å»ä¸€ä¸ªæœˆçš„è´­ä¹°é‡‘é¢æˆ–é”€å”®é¢çš„å¹³å‡å¤„ç†æ•ˆåº”ï¼ˆATEï¼‰ã€‚ç„¶è€Œï¼Œè¿›ä¸€æ­¥å‡è®¾æˆ‘ä»¬åªæœ‰è§‚å¯Ÿæ•°æ®å¯ä»¥ä½¿ç”¨ï¼Œä½†æˆ‘ä»¬å·²ç»æµ‹é‡äº†æ‰€æœ‰æ½œåœ¨çš„æ··æ‚å› ç´ ï¼ˆé‚£äº›å½±å“ç½‘ç«™åœç•™æ—¶é—´å’Œé”€å”®é¢çš„å˜é‡ï¼‰ã€‚è®©è¿™ä¸ªå› æœè¿‡ç¨‹é€šè¿‡ä»¥ä¸‹çš„æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰è¿›è¡Œæè¿°ï¼š
- en: '![](../Images/53ff709528289a0762c49af8579e9f7a.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/53ff709528289a0762c49af8579e9f7a.png)'
- en: 'Let the data generating process be as follows (*note that all values & data
    are chosen and generated arbitrarily for demonstrative purposes, and thus should
    not necessarily represent a large degree of real world intuition per se outside
    of our estimates of the ATE*):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æ•°æ®ç”Ÿæˆè¿‡ç¨‹å¦‚ä¸‹ï¼ˆ*è¯·æ³¨æ„ï¼Œæ‰€æœ‰å€¼å’Œæ•°æ®éƒ½æ˜¯ä¸ºäº†æ¼”ç¤ºç›®çš„è€Œéšæ„é€‰æ‹©å’Œç”Ÿæˆçš„ï¼Œå› æ­¤ä¸ä¸€å®šä»£è¡¨çœŸå®ä¸–ç•Œç›´è§‚çš„å¾ˆå¤§ç¨‹åº¦ï¼Œé™¤éæˆ‘ä»¬å¯¹ATEçš„ä¼°è®¡*ï¼‰ï¼š
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'By construction, our treatment of interest (hours spent on the website in the
    past month) and our outcome (sales in the past month) have the following confounders:
    Age, Number of Social Media Accounts, & Years Member of Website, and this confounding
    is arbitrarily non-linear. Furthermore, we can see that the constructed **ground
    truth for the ATE is $5** (outlined in the DGP for sales in the code above above).
    *That is, on average, for every additional hour the individual spends on the website,
    they spend an additional $5\.* Note, we also include a collider variable (a variable
    that is influenced by both time spent on the website and sales), which will be
    utilized for demonstration below on how this biases the ATE.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ„å»ºï¼Œæˆ‘ä»¬çš„å…´è¶£å¤„ç†ï¼ˆè¿‡å»ä¸€ä¸ªæœˆåœ¨ç½‘ç«™ä¸ŠèŠ±è´¹çš„æ—¶é—´ï¼‰å’Œæˆ‘ä»¬çš„ç»“æœï¼ˆè¿‡å»ä¸€ä¸ªæœˆçš„é”€å”®é¢ï¼‰æœ‰ä»¥ä¸‹æ··æ‚å› ç´ ï¼šå¹´é¾„ã€ç¤¾äº¤åª’ä½“è´¦æˆ·æ•°é‡å’Œç½‘ç«™ä¼šå‘˜å¹´é™ï¼Œè¿™ç§æ··æ‚æ˜¯ä»»æ„éçº¿æ€§çš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ„å»ºçš„**ATE
    çœŸå®å€¼æ˜¯ $5**ï¼ˆåœ¨ä¸Šé¢çš„é”€å”® DGP ä¸­è¯´æ˜ï¼‰ã€‚*ä¹Ÿå°±æ˜¯è¯´ï¼Œå¹³å‡è€Œè¨€ï¼Œæ¯å¢åŠ ä¸€å°æ—¶çš„åœ¨ç½‘ç«™ä¸ŠèŠ±è´¹çš„æ—¶é—´ï¼Œä¸ªäººä¼šå¤šèŠ± $5ã€‚* æ³¨æ„ï¼Œæˆ‘ä»¬è¿˜åŒ…æ‹¬äº†ä¸€ä¸ªç¢°æ’å™¨å˜é‡ï¼ˆå—ç½‘ç«™èŠ±è´¹æ—¶é—´å’Œé”€å”®é¢å½±å“çš„å˜é‡ï¼‰ï¼Œè¯¥å˜é‡å°†åœ¨ä¸‹é¢çš„æ¼”ç¤ºä¸­ç”¨äºè¯´æ˜è¿™ç§åå·®å¦‚ä½•å½±å“
    ATEã€‚
- en: 'To demonstrate the ability of DML to flexibly partial out the highly non-linear
    confounding, we will run the 4 following models:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å±•ç¤º DML çµæ´»éƒ¨åˆ†åŒ–é«˜åº¦éçº¿æ€§æ··æ‚å› ç´ çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬å°†è¿è¡Œä»¥ä¸‹ 4 ä¸ªæ¨¡å‹ï¼š
- en: NaÃ¯ve OLS of sales (y) on hours spent on the website (T)
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é”€å”®ï¼ˆyï¼‰å¯¹ç½‘ç«™ä¸ŠèŠ±è´¹çš„æ—¶é—´ï¼ˆTï¼‰è¿›è¡Œå¤©çœŸçš„ OLS å›å½’
- en: Multiple OLS of sales (y) on hours spent on the website (T) and linear terms
    of all of the confounders
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é”€å”®ï¼ˆyï¼‰å¯¹ç½‘ç«™ä¸ŠèŠ±è´¹çš„æ—¶é—´ï¼ˆTï¼‰åŠæ‰€æœ‰æ··æ‚å› ç´ çš„çº¿æ€§é¡¹è¿›è¡Œå¤šé‡ OLS å›å½’
- en: OLS utilizing DML residualization procedure outlined in eq. (5)
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ DML æ®‹å·®åŒ–è¿‡ç¨‹çš„ OLS å›å½’ï¼Œè¯¦è§å…¬å¼ (5)
- en: OLS utilizing DML residualization procedure, including collider variable
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: åŒ…æ‹¬ç¢°æ’å™¨å˜é‡çš„ DML æ®‹å·®åŒ–è¿‡ç¨‹çš„ OLS å›å½’
- en: 'The code of this is as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç å¦‚ä¸‹ï¼š
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'with the corresponding results (see code in appendix for creating this table):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹åº”çš„ç»“æœï¼ˆè§é™„å½•ä¸­çš„ä»£ç ä»¥åˆ›å»ºæ­¤è¡¨ï¼‰ï¼š
- en: '![](../Images/6d270c529361708fb89a92c20fbb0fb1.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6d270c529361708fb89a92c20fbb0fb1.png)'
- en: 'Recall our simulated source of truth for the ATE is **$5**. Notice that the
    only model that is able to capture this value is the DML procedure! We can see
    that the naÃ¯ve model has a significant positive bias in the estimate, whereas
    controlling only for linear terms of the confounders in the multiple regression
    slightly reduces this bias. Additionally, the DML procedure w/ a collider demonstrates
    a negative bias; this negative association between sales and our treatment that
    arises from controlling for the collider can be ***loosely*** demonstrated/observed
    by solving for sales in our collider DGP as such:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å›å¿†ä¸€ä¸‹æˆ‘ä»¬æ¨¡æ‹Ÿçš„ ATE çœŸå®å€¼æ˜¯**$5**ã€‚æ³¨æ„ï¼Œå”¯ä¸€èƒ½å¤Ÿæ•æ‰è¿™ä¸ªå€¼çš„æ¨¡å‹æ˜¯ DML è¿‡ç¨‹ï¼æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¤©çœŸçš„æ¨¡å‹åœ¨ä¼°è®¡ä¸­æœ‰æ˜¾è‘—çš„æ­£åå·®ï¼Œè€Œä»…å¯¹æ··æ‚å› ç´ çš„çº¿æ€§é¡¹è¿›è¡Œæ§åˆ¶çš„å¤šé‡å›å½’åˆ™ç¨å¾®å‡å°‘äº†è¿™ç§åå·®ã€‚æ­¤å¤–ï¼Œå¸¦æœ‰ç¢°æ’å™¨çš„
    DML è¿‡ç¨‹å±•ç¤ºäº†ä¸€ä¸ªè´Ÿåå·®ï¼›é€šè¿‡åœ¨æˆ‘ä»¬çš„ç¢°æ’å™¨ DGP ä¸­æ±‚è§£é”€å”®é¢ï¼Œå¯ä»¥*æ¾æ•£åœ°*æ¼”ç¤º/è§‚å¯Ÿåˆ°é”€å”®ä¸æˆ‘ä»¬å¤„ç†ä¹‹é—´çš„è¿™ç§è´Ÿç›¸å…³ã€‚
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: These results demonstrate the unequivocal power of using flexible, non-parametric
    ML models in the DML procedure for residualizing out the confounding! Pretty satisfying,
    no? **DML removes the necessity for correct parametric specification of the confounding
    DGP (given all of the confounders are controlled for)!**
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç»“æœå±•ç¤ºäº†ä½¿ç”¨çµæ´»çš„éå‚æ•° ML æ¨¡å‹åœ¨ DML è¿‡ç¨‹ä¸­å»é™¤æ··æ‚çš„æ˜ç¡®èƒ½åŠ›ï¼ç›¸å½“ä»¤äººæ»¡æ„ï¼Œå¯¹å§ï¼Ÿ **DML å»é™¤äº†å¯¹æ··æ‚ DGP çš„æ­£ç¡®å‚æ•°åŒ–è§„æ ¼çš„å¿…è¦æ€§ï¼ˆå‰ææ˜¯æ‰€æœ‰æ··æ‚å› ç´ éƒ½è¢«æ§åˆ¶ï¼‰ï¼**
- en: The careful reader will have noticed that we included arbitrary covariate ***Z***
    in our data generating process for sales. However, note that ***Z*** does not
    directly influence time spent on the website, thus it does not meet the definition
    of a confounder and thus has no impact on the results (outside of possibly improving
    the precision of the estimate â€” see application 2)
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ç»†å¿ƒçš„è¯»è€…ä¼šæ³¨æ„åˆ°ï¼Œæˆ‘ä»¬åœ¨é”€å”®çš„ç”Ÿæˆè¿‡ç¨‹ä¸­åŒ…æ‹¬äº†ä»»æ„çš„åå˜é‡ ***Z***ã€‚ç„¶è€Œï¼Œæ³¨æ„åˆ° ***Z*** å¹¶ä¸ä¼šç›´æ¥å½±å“åœ¨ç½‘ç«™ä¸ŠèŠ±è´¹çš„æ—¶é—´ï¼Œå› æ­¤å®ƒä¸ç¬¦åˆæ··æ‚å› ç´ çš„å®šä¹‰ï¼Œå› æ­¤å¯¹ç»“æœæ²¡æœ‰å½±å“ï¼ˆé™¤äº†å¯èƒ½æé«˜ä¼°è®¡çš„ç²¾ç¡®åº¦â€”â€”è§åº”ç”¨ç¨‹åº
    2ï¼‰
- en: '**Application 2:** *Improving Precision & Statistical Power in Experimental
    Data (Randomized Controlled Trialâ€™s (RCTs) or A/B Tests)*'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**åº”ç”¨ç¨‹åº 2ï¼š** *æé«˜å®éªŒæ•°æ®çš„ç²¾ç¡®åº¦å’Œç»Ÿè®¡æ•ˆèƒ½ï¼ˆéšæœºå¯¹ç…§è¯•éªŒ (RCTs) æˆ– A/B æµ‹è¯•ï¼‰*'
- en: It is a common misconception that if one runâ€™s an experiment with a *large enough*
    sample size, one can obtain sufficient [statistical power](https://en.wikipedia.org/wiki/Power_of_a_test)
    to accurately measure the treatment of interest. However, one commonly overlooked
    component in determining statistical power in an experiment, and ultimately the
    precision in the ATE estimate, is the variation in the outcome you are trying
    measure.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå¸¸è§çš„è¯¯è§£æ˜¯ï¼Œå¦‚æœä¸€ä¸ªå®éªŒæœ‰ä¸€ä¸ª*è¶³å¤Ÿå¤§çš„*æ ·æœ¬é‡ï¼Œå°±å¯ä»¥è·å¾—è¶³å¤Ÿçš„[ç»Ÿè®¡åŠŸæ•ˆ](https://en.wikipedia.org/wiki/Power_of_a_test)æ¥å‡†ç¡®æµ‹é‡æ„Ÿå…´è¶£çš„å¤„ç†ã€‚ç„¶è€Œï¼Œç¡®å®šå®éªŒä¸­çš„ç»Ÿè®¡åŠŸæ•ˆä»¥åŠæœ€ç»ˆATEä¼°è®¡ç²¾åº¦çš„ä¸€ä¸ªå¸¸è¢«å¿½è§†çš„å› ç´ æ˜¯ä½ è¯•å›¾æµ‹é‡çš„ç»“æœçš„å˜å¼‚æ€§ã€‚
- en: 'For example, suppose we are interested in measuring the impact of a specific
    advertisement on an individuals purchase amount, and we anticipate the effect
    to be small, but non-trivial â€” say an ATE of $5\. However, suppose the standard
    deviation in individual sales is very largeâ€¦ perhaps, in the $100s or even $1000s.
    In this case, it may be difficult to accurately capture the ATE given this high
    variation â€”that is, we may obtain very low precision (large standard errors) in
    our estimate. However, capturing this ATE of $5 may be economically significant
    (if we run the experiment on 100,000 households, this can amount to $500,000).
    This is where DML can come to the rescue. Before we demonstrate this in action,
    letâ€™s first visit the formula for the standard error of our ATE estimate from
    the simple regression in equation (1):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬å¯¹æŸä¸ªç‰¹å®šå¹¿å‘Šå¯¹ä¸ªäººè´­ä¹°é‡‘é¢çš„å½±å“æ„Ÿå…´è¶£ï¼Œå¹¶ä¸”æˆ‘ä»¬é¢„è®¡æ•ˆæœè¾ƒå°ï¼Œä½†å¹¶éå¾®ä¸è¶³é“â€”â€”ä¾‹å¦‚ï¼ŒATEä¸º$5ã€‚ç„¶è€Œï¼Œå‡è®¾ä¸ªäººé”€å”®é¢çš„æ ‡å‡†å·®éå¸¸å¤§â€¦â€¦å¯èƒ½åœ¨$100ç”šè‡³$1000çš„èŒƒå›´å†…ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç”±äºè¿™ç§é«˜å˜å¼‚æ€§ï¼Œå‡†ç¡®æ•æ‰ATEå¯èƒ½ä¼šéå¸¸å›°éš¾â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬çš„ä¼°è®¡å¯èƒ½ä¼šè·å¾—éå¸¸ä½çš„ç²¾åº¦ï¼ˆå¤§çš„æ ‡å‡†è¯¯å·®ï¼‰ã€‚ç„¶è€Œï¼Œæ•æ‰åˆ°$5çš„ATEå¯èƒ½åœ¨ç»æµä¸Šæ˜¯æœ‰æ„ä¹‰çš„ï¼ˆå¦‚æœæˆ‘ä»¬å¯¹100,000æˆ·å®¶åº­è¿›è¡Œå®éªŒï¼Œè¿™å¯èƒ½è¾¾åˆ°$500,000ï¼‰ã€‚è¿™å°±æ˜¯DMLèƒ½å¤Ÿå‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚åœ¨æˆ‘ä»¬å±•ç¤ºå®é™…æ“ä½œä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆæŸ¥çœ‹æ–¹ç¨‹ï¼ˆ1ï¼‰ä¸­ç®€å•å›å½’çš„ATEä¼°è®¡çš„æ ‡å‡†è¯¯å·®å…¬å¼ï¼š
- en: '![](../Images/10bfc0c5637eea234212e656f6f7d254.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/10bfc0c5637eea234212e656f6f7d254.png)'
- en: (7)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: (7)
- en: 'Here we observe that the standard error of our estimate is directly influenced
    by the size of our residuals (Îµ). What does this tell us then? If our treatment
    is randomized, we can include covariates in a multiple OLS or DML procedure, not
    to obtain exogeneity, but to reduce the variation in our outcome. More specifically,
    we can include variables that are strong predictors of our outcome to reduce the
    residuals and, consequently, the standard error of our estimate. Letâ€™s take a
    look at this in action. First, assume the following DAG (note treatment is randomized
    so there are no confounders):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æˆ‘ä»¬ä¼°è®¡çš„æ ‡å‡†è¯¯å·®ç›´æ¥å—åˆ°æ®‹å·®ï¼ˆÎµï¼‰å¤§å°çš„å½±å“ã€‚é‚£ä¹ˆè¿™å‘Šè¯‰æˆ‘ä»¬ä»€ä¹ˆå‘¢ï¼Ÿå¦‚æœæˆ‘ä»¬çš„å¤„ç†æ˜¯éšæœºåŒ–çš„ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å¤šé‡æ™®é€šæœ€å°äºŒä¹˜æ³•ï¼ˆOLSï¼‰æˆ–åŒé‡æœºå™¨å­¦ä¹ ï¼ˆDMLï¼‰ç¨‹åºä¸­åŒ…å«åå˜é‡ï¼Œè¿™æ ·åšçš„ç›®çš„æ˜¯å‡å°‘æˆ‘ä»¬ç»“æœçš„å˜å¼‚æ€§ï¼Œè€Œä¸æ˜¯è·å¾—å¤–ç”Ÿæ€§ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬å¯ä»¥åŒ…å«é‚£äº›å¯¹ç»“æœæœ‰å¼ºé¢„æµ‹ä½œç”¨çš„å˜é‡ï¼Œä»è€Œå‡å°‘æ®‹å·®ï¼Œå¹¶å› æ­¤é™ä½æˆ‘ä»¬ä¼°è®¡çš„æ ‡å‡†è¯¯å·®ã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹è¿™ä¸ªå®é™…åº”ç”¨ã€‚é¦–å…ˆï¼Œå‡è®¾ä»¥ä¸‹æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ï¼ˆæ³¨æ„å¤„ç†æ˜¯éšæœºåŒ–çš„ï¼Œæ‰€ä»¥æ²¡æœ‰æ··æ‚å› ç´ ï¼‰ï¼š
- en: '![](../Images/5a4415a300956d8869404a4abecf0e4f.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a4415a300956d8869404a4abecf0e4f.png)'
- en: 'Furthermore, suppose the following DGP:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤å¤–ï¼Œå‡è®¾ä»¥ä¸‹æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼ˆDGPï¼‰ï¼š
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here again, we artificially simulate our **ground truth ATE of $5**. This time,
    however, we generate sales such that we have a very large variance, thus making
    it difficult to detect the $5 ATE.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å†æ¬¡äººå·¥æ¨¡æ‹Ÿ**çœŸå®çš„ATEä¸º$5**ã€‚ä¸è¿‡è¿™æ¬¡ï¼Œæˆ‘ä»¬ç”Ÿæˆçš„é”€å”®æ•°æ®å…·æœ‰éå¸¸å¤§çš„æ–¹å·®ï¼Œå› æ­¤éš¾ä»¥æ£€æµ‹åˆ°$5çš„ATEã€‚
- en: 'To demonstrate how the inclusion of covariates that are strong predictors of
    our outcome in the DML procedure greatly improve the precision of our ATE estimates,
    we will run the following 3 models:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ¼”ç¤ºåœ¨DMLç¨‹åºä¸­åŒ…å«é‚£äº›å¯¹æˆ‘ä»¬çš„ç»“æœæœ‰å¼ºé¢„æµ‹ä½œç”¨çš„åå˜é‡å¦‚ä½•å¤§å¤§æé«˜ATEä¼°è®¡çš„ç²¾åº¦ï¼Œæˆ‘ä»¬å°†è¿è¡Œä»¥ä¸‹ä¸‰ä¸ªæ¨¡å‹ï¼š
- en: NaÃ¯ve OLS of sales (y) on *randomized* exposure to advertisement (T)
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é”€å”®ï¼ˆyï¼‰å¯¹*éšæœº*å¹¿å‘Šæš´éœ²ï¼ˆTï¼‰çš„ç®€å•OLS
- en: Multiple OLS of sales (y) on *randomized* exposure to advertisement (T) and
    linear terms of all of the sales predictors
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é”€å”®ï¼ˆyï¼‰å¯¹*éšæœº*å¹¿å‘Šæš´éœ²ï¼ˆTï¼‰åŠæ‰€æœ‰é”€å”®é¢„æµ‹å˜é‡çš„çº¿æ€§é¡¹çš„å¤šé‡OLS
- en: OLS utilizing DML residualization procedure outlined in eq. (5)
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨DMLæ®‹å·®åŒ–ç¨‹åºçš„OLSï¼Œå¦‚æ–¹ç¨‹ï¼ˆ5ï¼‰æ‰€è¿°
- en: 'The code is as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç å¦‚ä¸‹ï¼š
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You may notice that we include the ML model to predict advertisement exposure
    as well. This is primarily for consistency with the DML procedure. However, because
    we know advertisement exposure is random this is not entirely necessary, but I
    would recommend verifying the model in our example truly is unable to learn anything
    (i.e., in our case it should predict ~0.50 probability for all individuals, thus
    the residuals will maintain the same variation as initial treatment assignment).
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‚¨å¯èƒ½ä¼šæ³¨æ„åˆ°æˆ‘ä»¬è¿˜åŒ…æ‹¬äº†ç”¨äºé¢„æµ‹å¹¿å‘Šæ›å…‰çš„MLæ¨¡å‹ã€‚è¿™ä¸»è¦æ˜¯ä¸ºäº†ä¸DMLç¨‹åºä¿æŒä¸€è‡´ã€‚ ç„¶è€Œï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“å¹¿å‘Šæ›å…‰æ˜¯éšæœºçš„ï¼Œè¿™å¹¶éå®Œå…¨å¿…è¦ï¼Œä½†æˆ‘å»ºè®®éªŒè¯æˆ‘ä»¬çš„ç¤ºä¾‹æ¨¡å‹ç¡®å®æ— æ³•å­¦åˆ°ä»»ä½•ä¸œè¥¿ï¼ˆå³ï¼Œåœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œå®ƒåº”è¯¥ä¸ºæ‰€æœ‰ä¸ªä½“é¢„æµ‹
    ~0.50 çš„æ¦‚ç‡ï¼Œå› æ­¤æ®‹å·®å°†ä¿æŒä¸åˆå§‹å¤„ç†åˆ†é…ç›¸åŒçš„å˜å¼‚ï¼‰ã€‚
- en: 'With the corresponding results of these models (see code in appendix for creating
    this table):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ¨¡å‹çš„ç›¸åº”ç»“æœï¼ˆè¯·å‚é˜…é™„å½•ä¸­çš„ä»£ç ä»¥åˆ›å»ºæ­¤è¡¨ï¼‰ï¼š
- en: '![](../Images/853d63b779cac7d5151c932063b68296.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/853d63b779cac7d5151c932063b68296.png)'
- en: First, note that b/c treatment was randomly assigned, there is no true confounding
    that is occurring above. The poor estimates of the ATE in (1) and (2) are the
    direct result of imprecise estimates (see the large standard errorâ€™s in the parenthesis).
    Notice how the standard error gets smaller (precision increasing) as we move from
    (1)-(3), with the DML procedure having the most precise estimate. Draw your attention
    to the â€œResidual Std. Errorâ€ row outlined in the red box above. We can see how
    the DML procedure was able to greatly reduce the variation in the ATE model residuals
    via partialling out the variation that was able to be learnt (non-parametrically)
    from the predictors in the ML model of our outcome, sales. Again, in this example,
    we see DML being the only model to obtain the true ATE!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè¯·æ³¨æ„ï¼Œç”±äºå¤„ç†æ˜¯éšæœºåˆ†é…çš„ï¼Œå› æ­¤ä¸Šé¢æ²¡æœ‰å‘ç”ŸçœŸæ­£çš„æ··æ·†ã€‚ (1) å’Œ (2) ä¸­çš„ATEä¼°è®¡è¯¯å·®æ˜¯ç”±äºä¸ç²¾ç¡®çš„ä¼°è®¡ï¼ˆè§æ‹¬å·ä¸­çš„å¤§æ ‡å‡†è¯¯å·®ï¼‰ç›´æ¥å¯¼è‡´çš„ã€‚
    æ³¨æ„éšç€æˆ‘ä»¬ä» (1) åˆ° (3) è¿ç§»ï¼Œæ ‡å‡†è¯¯å·®å¦‚ä½•å˜å°ï¼ˆç²¾åº¦æé«˜ï¼‰ï¼Œå…¶ä¸­DMLç¨‹åºå…·æœ‰æœ€ç²¾ç¡®çš„ä¼°è®¡ã€‚ è¯·æ³¨æ„ä¸Šé¢çº¢æ¡†ä¸­çš„â€œæ®‹å·®æ ‡å‡†è¯¯å·®â€è¡Œã€‚ æˆ‘ä»¬å¯ä»¥çœ‹åˆ°DMLç¨‹åºé€šè¿‡ä»æˆ‘ä»¬ç»“æœçš„MLæ¨¡å‹ï¼ˆé”€å”®ï¼‰ä¸­çš„é¢„æµ‹å› å­ä¸­éƒ¨åˆ†æ¶ˆé™¤å¯å­¦ä¹ çš„å˜å¼‚ï¼Œæ˜¾è‘—å‡å°‘äº†ATEæ¨¡å‹æ®‹å·®çš„å˜å¼‚ã€‚
    å†æ¬¡ï¼Œåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°DMLæ˜¯å”¯ä¸€ä¸€ä¸ªèƒ½å¤Ÿè·å¾—çœŸå®ATEçš„æ¨¡å‹ï¼
- en: These results demonstrate the benefit of using DML in an experimental setting
    to increase statistical power and precision of oneâ€™s ATE estimate. Specifically,
    this can be utilized in RCT or A/B testing settings where the variation in the
    outcome is very large and/or one is struggling with achieving precise estimates
    and one has access to strong predictors of the outcome of interest.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç»“æœå±•ç¤ºäº†åœ¨å®éªŒç¯å¢ƒä¸­ä½¿ç”¨DMLä»¥æé«˜ç»Ÿè®¡èƒ½åŠ›å’ŒATEä¼°è®¡ç²¾åº¦çš„å¥½å¤„ã€‚ å…·ä½“è€Œè¨€ï¼Œè¿™å¯ä»¥åº”ç”¨äºRCTæˆ–A/Bæµ‹è¯•ç¯å¢ƒï¼Œå…¶ä¸­ç»“æœçš„å˜å¼‚éå¸¸å¤§å’Œ/æˆ–åœ¨ç²¾ç¡®ä¼°è®¡æ–¹é¢é‡åˆ°å›°éš¾ï¼Œå¹¶ä¸”å¯ä»¥è®¿é—®å¼ºæœ‰åŠ›çš„ç»“æœé¢„æµ‹å› å­ã€‚
- en: Conclusion
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: And there you have it â€” Double Machine Learning simplified (hopefully)! Thank
    you for taking the time to read through my article. I hope this article has provided
    you with a clear and intuitive understanding of the basics of DML and **the true
    power DML holds**, along with how you can utilize DML in your daily causal inference
    tasks.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·â€”â€”åŒé‡æœºå™¨å­¦ä¹ ç®€åŒ–ç‰ˆï¼ˆå¸Œæœ›å¦‚æ­¤ï¼‰ï¼ æ„Ÿè°¢æ‚¨èŠ±æ—¶é—´é˜…è¯»æˆ‘çš„æ–‡ç« ã€‚ æˆ‘å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½ä¸ºæ‚¨æä¾›å¯¹DMLåŸºç¡€çŸ¥è¯†çš„æ¸…æ™°è€Œç›´è§‚çš„ç†è§£ï¼Œä»¥åŠ**DMLæ‰€å…·å¤‡çš„çœŸæ­£åŠ›é‡**ï¼Œä»¥åŠå¦‚ä½•åœ¨æ—¥å¸¸å› æœæ¨æ–­ä»»åŠ¡ä¸­åˆ©ç”¨DMLã€‚
- en: Stay tuned for [part 2](https://medium.com/towards-data-science/double-machine-learning-simplified-part-2-extensions-the-cate-99926151cac)
    of this series where we will dive into some very cool extensions of DML that turn
    our causal inference problem into a prediction task, where we go beyond the ATE
    & predict individual level treatment effects to aid in decision making and data-driven
    targeting.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: æ•¬è¯·å…³æ³¨[ç¬¬2éƒ¨åˆ†](https://medium.com/towards-data-science/double-machine-learning-simplified-part-2-extensions-the-cate-99926151cac)ç³»åˆ—ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ä¸€äº›éå¸¸é…·çš„DMLæ‰©å±•ï¼Œè¿™äº›æ‰©å±•å°†æˆ‘ä»¬çš„å› æœæ¨æ–­é—®é¢˜è½¬åŒ–ä¸ºé¢„æµ‹ä»»åŠ¡ï¼Œæˆ‘ä»¬è¶…è¶ŠATEï¼Œé¢„æµ‹ä¸ªä½“çº§åˆ«çš„å¤„ç†æ•ˆåº”ï¼Œä»¥è¾…åŠ©å†³ç­–å’Œæ•°æ®é©±åŠ¨çš„ç›®æ ‡ã€‚
- en: As always, I hope you have enjoyed reading this as much as I enjoyed writing
    it!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€å¦‚æ—¢å¾€ï¼Œæˆ‘å¸Œæœ›ä½ ä»¬è¯»è¿™ç¯‡æ–‡ç« æ—¶å’Œæˆ‘å†™è¿™ç¯‡æ–‡ç« æ—¶ä¸€æ ·æ„‰å¿«ï¼
- en: Appendix
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é™„å½•
- en: '*Creating the pretty tables:*'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*åˆ›å»ºæ¼‚äº®çš„è¡¨æ ¼ï¼š*'
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Resources
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èµ„æº
- en: '[1] V. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, and a.
    W. Newey. Double Machine Learning for Treatment and Causal Parameters. *ArXiv
    e-prints*, July 2016.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] V. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, å’Œ a.
    W. Newey. åŒé‡æœºå™¨å­¦ä¹ ç”¨äºå¤„ç†å’Œå› æœå‚æ•°ã€‚*ArXiv ç”µå­å°åˆ·å“*ï¼Œ2016å¹´7æœˆã€‚'
- en: '*Access all the code via this GitHub Repo:* [https://github.com/jakepenzak/Blog-Posts](https://github.com/jakepenzak/Blog-Posts)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '*I appreciate you reading my post! My posts on Medium seek to explore real-world
    and theoretical applications utilizing* ***econometric*** *and* ***statistical/machine
    learning*** *techniques. Additionally, I seek to provide posts on the theoretical
    underpinnings of various methodologies via theory and simulations. Most importantly,
    I write to learn and help others learn! I hope to make complex topics slightly
    more accessible to all. If you enjoyed this post, please consider* [***following
    me on Medium***](https://medium.com/@jakepenzak)*!*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
