- en: Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and Parallel Knowledge Graph Retrieval
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=collection_archive---------4-----------------------#2023-11-18](https://towardsdatascience.com/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=collection_archive---------4-----------------------#2023-11-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----a4b8018b619a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)
    ·8 min read·Nov 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4b8018b619a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----a4b8018b619a---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4b8018b619a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a&source=-----a4b8018b619a---------------------bookmark_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with just a handful of examples.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)
    [## Why RAG (Retrieval Augmented Generation) will become a cornerstone of system
    design using LLM…'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)
    [## 为什么 RAG（检索增强生成）将成为使用 LLM 的系统设计基石…'
- en: Recent advances in large language models (LLMs) like GPT-3 [1] have demonstrated
    powerful few-shot learning abilities —…
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最近，大型语言模型（LLMs）如 GPT-3 [1] 展示了强大的少样本学习能力——…
- en: ai.plainenglish.io](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[ai.plainenglish.io](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)'
- en: However, despite their advances, LLMs still face limitations in complex reasoning
    involving chaotic contexts overloaded with disjoint facts. To address this challenge,
    researchers have explored techniques like chain-of-thought prompting that guide
    models to incrementally analyze information. Yet on their own, these methods struggle
    to fully capture all critical details across vast contexts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大语言模型（LLMs）取得了进展，它们在涉及混乱背景和过多分散事实的复杂推理中仍面临局限性。为了解决这一挑战，研究人员探索了如链式思维提示等技术，这些技术引导模型逐步分析信息。然而，单靠这些方法仍难以全面捕捉广泛背景下的所有关键细节。
- en: This article proposes a technique combining Thread-of-Thought (ToT) prompting
    with a Retrieval Augmented Generation (RAG) framework accessing multiple knowledge
    graphs in parallel. While ToT acts as the reasoning “backbone” that structures
    thinking, the RAG system broadens available knowledge to fill gaps. Parallel querying
    of diverse information sources improves efficiency and coverage compared to sequential
    retrieval. Together, this…
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文提出了一种技术，将思维链（ToT）提示与检索增强生成（RAG）框架结合起来，后者可以并行访问多个知识图谱。虽然 ToT 作为推理的“支柱”来结构化思维，但
    RAG 系统扩展了可用知识以填补空白。与顺序检索相比，多源并行查询提高了效率和覆盖面。综合来看，这…
