- en: Achieving Structured Reasoning with LLMs in Chaotic Contexts with Thread of
    Thought Prompting and Parallel Knowledge Graph Retrieval
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=collection_archive---------4-----------------------#2023-11-18](https://towardsdatascience.com/achieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a?source=collection_archive---------4-----------------------#2023-11-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----a4b8018b619a--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----a4b8018b619a---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a4b8018b619a--------------------------------)
    ·8 min read·Nov 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fa4b8018b619a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----a4b8018b619a---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fa4b8018b619a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-structured-reasoning-with-llms-in-chaotic-contexts-with-thread-of-thought-prompting-and-a4b8018b619a&source=-----a4b8018b619a---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  prefs: []
  type: TYPE_NORMAL
- en: Large language models (LLMs) demonstrated impressive few-shot learning capabilities,
    rapidly adapting to new tasks with just a handful of examples.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)
    [## Why RAG (Retrieval Augmented Generation) will become a cornerstone of system
    design using LLM…'
  prefs: []
  type: TYPE_NORMAL
- en: Recent advances in large language models (LLMs) like GPT-3 [1] have demonstrated
    powerful few-shot learning abilities —…
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ai.plainenglish.io](https://ai.plainenglish.io/why-rag-retrieval-augmented-generation-will-become-a-cornerstone-of-system-design-using-llm-719657fbfebe?source=post_page-----a4b8018b619a--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: However, despite their advances, LLMs still face limitations in complex reasoning
    involving chaotic contexts overloaded with disjoint facts. To address this challenge,
    researchers have explored techniques like chain-of-thought prompting that guide
    models to incrementally analyze information. Yet on their own, these methods struggle
    to fully capture all critical details across vast contexts.
  prefs: []
  type: TYPE_NORMAL
- en: This article proposes a technique combining Thread-of-Thought (ToT) prompting
    with a Retrieval Augmented Generation (RAG) framework accessing multiple knowledge
    graphs in parallel. While ToT acts as the reasoning “backbone” that structures
    thinking, the RAG system broadens available knowledge to fill gaps. Parallel querying
    of diverse information sources improves efficiency and coverage compared to sequential
    retrieval. Together, this…
  prefs: []
  type: TYPE_NORMAL
