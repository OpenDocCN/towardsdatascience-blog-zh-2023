- en: Thinking about fine-tuning a LLM? Here’s 3 considerations before you get started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/thinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293?source=collection_archive---------0-----------------------#2023-06-15](https://towardsdatascience.com/thinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293?source=collection_archive---------0-----------------------#2023-06-15)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)[![Sean
    Smith](../Images/611395d113b10ec4bbfaf781301139c7.png)](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)
    [Sean Smith](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6957f6523097&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&user=Sean+Smith&userId=6957f6523097&source=post_page-6957f6523097----c1f483f293---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)
    ·11 min read·Jun 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc1f483f293&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&user=Sean+Smith&userId=6957f6523097&source=-----c1f483f293---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc1f483f293&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&source=-----c1f483f293---------------------bookmark_footer-----------)![](../Images/fabd8f334f6e560c8750dadc546fdd8e.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Brett Jordan](https://unsplash.com/@brett_jordan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: LLMs (Large Language Models) and generative AI are all the rage right now. A
    staggering statistic from [IBM](https://www.ibm.com/thought-leadership/institute-business-value/report/generative-ai-data-story)
    reveals that nearly 2 in 3 C-Suite executives feel pressure from investors to
    accelerate their adoption of generative AI. Naturally, this pressure is trickling
    down to Data Science and Machine Learning teams, who are responsible for navigating
    the hype and creating winning implementations.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the landscape evolves, the ecosystem for LLMs has diverged between open
    source and industry models, with a [quickly filling moat](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither).
    This emerging scene has prompted many teams to consider the following question:
    How can we make a LLM more specific for our use case?'
  prefs: []
  type: TYPE_NORMAL
- en: In this article we explore some key considerations that should be top of mind
    when contemplating the investment of time and engineering cycles to build a niche
    LLM. On this journey, it is crucial to be aware of some of the recent research
    surrounding potential limitations and best practices for building fine-tuned language
    models. After reading this article, you’ll be equipped with a few more ideas to
    lead your organization to the correct decision to train or not to train and how
    to train.
  prefs: []
  type: TYPE_NORMAL
- en: You might not be able to mimic GPT with an open source model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
