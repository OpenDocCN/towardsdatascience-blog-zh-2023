- en: Thinking about fine-tuning a LLM? Here’s 3 considerations before you get started
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在考虑微调LLM吗？这里有三个开始之前的注意事项
- en: 原文：[https://towardsdatascience.com/thinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293?source=collection_archive---------0-----------------------#2023-06-15](https://towardsdatascience.com/thinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293?source=collection_archive---------0-----------------------#2023-06-15)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/thinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293?source=collection_archive---------0-----------------------#2023-06-15](https://towardsdatascience.com/thinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293?source=collection_archive---------0-----------------------#2023-06-15)
- en: '[](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)[![Sean
    Smith](../Images/611395d113b10ec4bbfaf781301139c7.png)](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)
    [Sean Smith](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)[![Sean
    Smith](../Images/611395d113b10ec4bbfaf781301139c7.png)](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)
    [Sean Smith](https://medium.com/@smsmith714?source=post_page-----c1f483f293--------------------------------)'
- en: ·
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6957f6523097&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&user=Sean+Smith&userId=6957f6523097&source=post_page-6957f6523097----c1f483f293---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)
    ·11 min read·Jun 15, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc1f483f293&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&user=Sean+Smith&userId=6957f6523097&source=-----c1f483f293---------------------clap_footer-----------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6957f6523097&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&user=Sean+Smith&userId=6957f6523097&source=post_page-6957f6523097----c1f483f293---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----c1f483f293--------------------------------)
    · 11分钟阅读 · 2023年6月15日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc1f483f293&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&user=Sean+Smith&userId=6957f6523097&source=-----c1f483f293---------------------clap_footer-----------)'
- en: --
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc1f483f293&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&source=-----c1f483f293---------------------bookmark_footer-----------)![](../Images/fabd8f334f6e560c8750dadc546fdd8e.png)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc1f483f293&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthinking-about-fine-tuning-an-llm-heres-3-considerations-before-you-get-started-c1f483f293&source=-----c1f483f293---------------------bookmark_footer-----------)![](../Images/fabd8f334f6e560c8750dadc546fdd8e.png)'
- en: Photo by [Brett Jordan](https://unsplash.com/@brett_jordan?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Brett Jordan](https://unsplash.com/@brett_jordan?utm_source=medium&utm_medium=referral)拍摄，发布在[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)上
- en: LLMs (Large Language Models) and generative AI are all the rage right now. A
    staggering statistic from [IBM](https://www.ibm.com/thought-leadership/institute-business-value/report/generative-ai-data-story)
    reveals that nearly 2 in 3 C-Suite executives feel pressure from investors to
    accelerate their adoption of generative AI. Naturally, this pressure is trickling
    down to Data Science and Machine Learning teams, who are responsible for navigating
    the hype and creating winning implementations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，大型语言模型（LLMs）和生成型人工智能（generative AI）正受到极大关注。[IBM](https://www.ibm.com/thought-leadership/institute-business-value/report/generative-ai-data-story)的一个惊人统计数据显示，近三分之二的C级高管感受到来自投资者的压力，要求加快生成型人工智能的应用。这种压力自然也传递到了数据科学和机器学习团队，他们负责应对这种炒作并创建成功的实施方案。
- en: 'As the landscape evolves, the ecosystem for LLMs has diverged between open
    source and industry models, with a [quickly filling moat](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither).
    This emerging scene has prompted many teams to consider the following question:
    How can we make a LLM more specific for our use case?'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着形势的发展，LLMs的生态系统在开源和行业模型之间出现了分化，并且存在一个[迅速填补的护城河](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)。这一新兴局面促使许多团队考虑以下问题：我们如何使LLM更符合我们的使用案例？
- en: In this article we explore some key considerations that should be top of mind
    when contemplating the investment of time and engineering cycles to build a niche
    LLM. On this journey, it is crucial to be aware of some of the recent research
    surrounding potential limitations and best practices for building fine-tuned language
    models. After reading this article, you’ll be equipped with a few more ideas to
    lead your organization to the correct decision to train or not to train and how
    to train.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们探讨了在考虑投入时间和工程周期来构建特定领域LLM时应该重点关注的一些关键因素。在这个过程中，了解一些关于潜在限制和最佳实践的最新研究至关重要，以便构建精细调整的语言模型。阅读本文后，你将获得一些更多的思路，以帮助你的组织做出是否训练以及如何训练的正确决定。
- en: You might not be able to mimic GPT with an open source model
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你可能无法用开源模型模拟GPT
