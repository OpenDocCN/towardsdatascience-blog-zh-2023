- en: How can Machine Learning be used in Audio Analysis?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6?source=collection_archive---------18-----------------------#2023-01-10](https://towardsdatascience.com/how-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6?source=collection_archive---------18-----------------------#2023-01-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how machine learning could be used to analyze audio signals and generate
    predictions for both classification and regression tasks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://suhas-maddali007.medium.com/?source=post_page-----847ebbefeb6--------------------------------)[![Suhas
    Maddali](../Images/933f27eab8ba9ee1f06ed2f24746d788.png)](https://suhas-maddali007.medium.com/?source=post_page-----847ebbefeb6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----847ebbefeb6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----847ebbefeb6--------------------------------)
    [Suhas Maddali](https://suhas-maddali007.medium.com/?source=post_page-----847ebbefeb6--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a74f90399ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6&user=Suhas+Maddali&userId=2a74f90399ae&source=post_page-2a74f90399ae----847ebbefeb6---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----847ebbefeb6--------------------------------)
    ·5 min read·Jan 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F847ebbefeb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6&user=Suhas+Maddali&userId=2a74f90399ae&source=-----847ebbefeb6---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F847ebbefeb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6&source=-----847ebbefeb6---------------------bookmark_footer-----------)![](../Images/d1e975b087ca839a3673a143c82e847a.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Jarrod Reed](https://unsplash.com/@jarrodreed?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine learning** has been gaining rapid traction in the recent decade.
    In fact, it is being used in numerous industries such as **healthcare**, **agriculture**,
    and **manufacturing**. There are a lot of potential applications of machine learning
    being created with the advancement of technology and computational power. Since
    data is available in various formats in abundance, it is the right time to use
    **machine learning** and **data science** to extract various insights from data
    and make predictions using them.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the most interesting applications of machine learning is in **audio analysis**
    and understanding the quality of different audio formats respectively. Therefore,
    using various machine learning and deep learning algorithms ensures that predictions
    are created and understood with the **audio data**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02331be5af79b613fd7061997c4a26a3.png)'
  prefs: []
  type: TYPE_IMG
- en: Photo by [Med Badr Chemmaoui](https://unsplash.com/@medbadrc?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Before doing audio analysis, samples of the signals must be taken and analyzed
    individually. The rate at which we would be taking the samples is also known as
    **the sampling rate** or **Nyquist rate**. It would be really handy to convert
    a time-domain signal to a frequency domain to get a good logical understanding
    of the signal along with computing useful components such as power and energy.
    All these could be given as features to our machine learning models which would
    use them for making predictions.
  prefs: []
  type: TYPE_NORMAL
- en: There is a popular conversion of an audio signal to a spectrogram (image) so
    that it could be given to **convolutional neural networks (CNNs)** for prediction.
    A spectrogram can capture important characteristics of an audio signal and give
    representations in 2D which can hence be used with image-based networks.
  prefs: []
  type: TYPE_NORMAL
- en: There are plenty of ML models that perform a very good task of predicting the
    output labels if they are given an image. Therefore, an audio signal which is
    composed of amplitude along with different units of frequency, could also be converted
    to an **image** and used for robust ML predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we would be going over how to read an audio file by considering
    a random example and plotting it to understand its graphical representation. Later,
    we will perform feature engineering with the image data and perform convolutional
    operations as the audio is converted to an image. Finally, we will get **sample
    predictions** for unseen data. Note that this code is used for demonstration and
    does not take into account specific datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Reading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to import necessary libraries that are used for reading an audio
    file in the form that is mostly present in the **‘.wav’** format. After reading
    the file, we are getting an array representation as shown in the code cell above.
    Finally, we would be plotting the output just to see how it looks with matplotlib.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Engineering
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that the data is plotted and visualized to see anomalies in the ‘.wav’ file,
    we would now be using a popular library called **‘librosa’** that can be used
    to calculate the short-term Fourier transform of the audio data. This is to ensure
    that the signal is decomposed into its constituent frequencies and is a technique
    that is widely used in a large number of industries.
  prefs: []
  type: TYPE_NORMAL
- en: Training the Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have used ‘librosa’ to get the frequency components, we would be
    using machine learning models to make predictions. It is to be noted that it is
    a classification problem and hence, we go ahead with using a **random forest classifier**.
    However, feel free to use any other machine learning model that suits your needs
    and the business.
  prefs: []
  type: TYPE_NORMAL
- en: We are now going to be using the same code but for regression tasks where the
    output is **continuous** instead of discrete. Below is the coding cell about how
    training could be done and performance monitored with the help of a random forest
    regressor.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter Tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to determine the right hyperparameters for the model (Random
    Forest) before it could be deployed in real-time. There are a lot of hyperparameters
    to **search** for when it comes to deep neural networks. Since we are using random
    forests as our baseline models, we should be able to get the right hyperparameters
    in a minimal search space. Let us see how to perform hyperparameter tuning on
    the general dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the code cell, we specify the **number of estimators** and the **maximum
    depth** of the tree that we search for to get the best results on the test set.
    We finally monitor the score and see how changes in the hyperparameters can lead
    to better performance by the model.
  prefs: []
  type: TYPE_NORMAL
- en: Model Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have performed hyperparameter tuning to give the most accurate predictions,
    it is time to save the machine learning models that provided the best results.
    Therefore, we would be using the **pickle** library in python so that we would
    be having the freedom to save the machine learning model that could be later used
    for serving.
  prefs: []
  type: TYPE_NORMAL
- en: After saving the model, we would again load it when we are building a **production-ready**
    code and use it to make predictions on incoming batches or streams of data. It
    is to be noted that the set of steps that were used to perform featurization during
    the training data must also be performed on the test set so that there is no skew
    in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Constant Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We know that the model is performing a good job in serving data where it is
    receiving incoming data from users, it is also an important yet neglected step
    which is to **monitor** the predictive quality of the models. There are often
    scenarios where the models might not be performing as they were during the training.
    This can be because there is a difference between the training and serving data.
    For example, there can be situations such as **concept drift** or **data drift**
    that can have a significant impact on the performance of the inference model that
    is put into production.
  prefs: []
  type: TYPE_NORMAL
- en: Constant monitoring ensures that steps are taken to check the predictive models
    and understand their behavior with changing data. If the predictions are the **least
    accurate** and it is leading to a loss of revenue for the business, steps should
    be taken to again train the models with this deviant data so that there is no
    unexpected change in the behavior of the models respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After going through this article, you might have gotten a good idea about how
    to perform machine learning for **audio data** and understand the overall workflow.
    We have seen steps such as reading the data, feature engineering, training the
    models, hyperparameter tuning, model deployment along with constant monitoring.
    Applying each of these steps and ensuring that there are no mistakes when developing
    a pipeline would lead to a robust machine learning production system.
  prefs: []
  type: TYPE_NORMAL
- en: '*Below are the ways where you could contact me or take a look at my work.*'
  prefs: []
  type: TYPE_NORMAL
- en: '***GitHub:***[*suhasmaddali (Suhas Maddali ) (github.com)*](https://github.com/suhasmaddali)'
  prefs: []
  type: TYPE_NORMAL
- en: '***YouTube:***[*https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q*](https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q)'
  prefs: []
  type: TYPE_NORMAL
- en: '***LinkedIn:***[*(1) Suhas Maddali, Northeastern University, Data Science |
    LinkedIn*](https://www.linkedin.com/in/suhas-maddali/)'
  prefs: []
  type: TYPE_NORMAL
- en: '***Medium:*** [*Suhas Maddali — Medium*](https://suhas-maddali007.medium.com/)'
  prefs: []
  type: TYPE_NORMAL
