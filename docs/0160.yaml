- en: How can Machine Learning be used in Audio Analysis?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/how-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6?source=collection_archive---------18-----------------------#2023-01-10](https://towardsdatascience.com/how-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6?source=collection_archive---------18-----------------------#2023-01-10)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Learn how machine learning could be used to analyze audio signals and generate
    predictions for both classification and regression tasks
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://suhas-maddali007.medium.com/?source=post_page-----847ebbefeb6--------------------------------)[![Suhas
    Maddali](../Images/933f27eab8ba9ee1f06ed2f24746d788.png)](https://suhas-maddali007.medium.com/?source=post_page-----847ebbefeb6--------------------------------)[](https://towardsdatascience.com/?source=post_page-----847ebbefeb6--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----847ebbefeb6--------------------------------)
    [Suhas Maddali](https://suhas-maddali007.medium.com/?source=post_page-----847ebbefeb6--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2a74f90399ae&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6&user=Suhas+Maddali&userId=2a74f90399ae&source=post_page-2a74f90399ae----847ebbefeb6---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----847ebbefeb6--------------------------------)
    ·5 min read·Jan 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F847ebbefeb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6&user=Suhas+Maddali&userId=2a74f90399ae&source=-----847ebbefeb6---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F847ebbefeb6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhow-can-machine-learning-be-used-in-audio-analysis-847ebbefeb6&source=-----847ebbefeb6---------------------bookmark_footer-----------)![](../Images/d1e975b087ca839a3673a143c82e847a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Jarrod Reed](https://unsplash.com/@jarrodreed?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine learning** has been gaining rapid traction in the recent decade.
    In fact, it is being used in numerous industries such as **healthcare**, **agriculture**,
    and **manufacturing**. There are a lot of potential applications of machine learning
    being created with the advancement of technology and computational power. Since
    data is available in various formats in abundance, it is the right time to use
    **machine learning** and **data science** to extract various insights from data
    and make predictions using them.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: One of the most interesting applications of machine learning is in **audio analysis**
    and understanding the quality of different audio formats respectively. Therefore,
    using various machine learning and deep learning algorithms ensures that predictions
    are created and understood with the **audio data**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/02331be5af79b613fd7061997c4a26a3.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: Photo by [Med Badr Chemmaoui](https://unsplash.com/@medbadrc?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Before doing audio analysis, samples of the signals must be taken and analyzed
    individually. The rate at which we would be taking the samples is also known as
    **the sampling rate** or **Nyquist rate**. It would be really handy to convert
    a time-domain signal to a frequency domain to get a good logical understanding
    of the signal along with computing useful components such as power and energy.
    All these could be given as features to our machine learning models which would
    use them for making predictions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: There is a popular conversion of an audio signal to a spectrogram (image) so
    that it could be given to **convolutional neural networks (CNNs)** for prediction.
    A spectrogram can capture important characteristics of an audio signal and give
    representations in 2D which can hence be used with image-based networks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: There are plenty of ML models that perform a very good task of predicting the
    output labels if they are given an image. Therefore, an audio signal which is
    composed of amplitude along with different units of frequency, could also be converted
    to an **image** and used for robust ML predictions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we would be going over how to read an audio file by considering
    a random example and plotting it to understand its graphical representation. Later,
    we will perform feature engineering with the image data and perform convolutional
    operations as the audio is converted to an image. Finally, we will get **sample
    predictions** for unseen data. Note that this code is used for demonstration and
    does not take into account specific datasets.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Reading the data
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to import necessary libraries that are used for reading an audio
    file in the form that is mostly present in the **‘.wav’** format. After reading
    the file, we are getting an array representation as shown in the code cell above.
    Finally, we would be plotting the output just to see how it looks with matplotlib.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Feature Engineering
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that the data is plotted and visualized to see anomalies in the ‘.wav’ file,
    we would now be using a popular library called **‘librosa’** that can be used
    to calculate the short-term Fourier transform of the audio data. This is to ensure
    that the signal is decomposed into its constituent frequencies and is a technique
    that is widely used in a large number of industries.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经被绘制和可视化以查看‘.wav’文件中的异常，我们将使用一个流行的库**‘librosa’**，它可以用来计算音频数据的短时傅里叶变换。这是为了确保信号被分解成其组成频率，这是一种在众多行业中广泛使用的技术。
- en: Training the Models
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型训练
- en: Now that we have used ‘librosa’ to get the frequency components, we would be
    using machine learning models to make predictions. It is to be noted that it is
    a classification problem and hence, we go ahead with using a **random forest classifier**.
    However, feel free to use any other machine learning model that suits your needs
    and the business.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用`librosa`获取了频率成分，我们将使用机器学习模型进行预测。需要注意的是，这是一项分类问题，因此，我们选择使用**随机森林分类器**。不过，也可以使用任何其他适合你的需求和业务的机器学习模型。
- en: We are now going to be using the same code but for regression tasks where the
    output is **continuous** instead of discrete. Below is the coding cell about how
    training could be done and performance monitored with the help of a random forest
    regressor.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用相同的代码，但用于回归任务，其中输出是**连续的**而不是离散的。下面是关于如何进行训练和使用随机森林回归器监控性能的代码单元格。
- en: Hyperparameter Tuning
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数调优
- en: It is important to determine the right hyperparameters for the model (Random
    Forest) before it could be deployed in real-time. There are a lot of hyperparameters
    to **search** for when it comes to deep neural networks. Since we are using random
    forests as our baseline models, we should be able to get the right hyperparameters
    in a minimal search space. Let us see how to perform hyperparameter tuning on
    the general dataset.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型（随机森林）可以实时部署之前，确定正确的超参数非常重要。在深度神经网络中，有很多超参数需要**搜索**。由于我们使用的是随机森林作为基准模型，因此我们应该能够在最小的搜索空间内找到正确的超参数。让我们看看如何在通用数据集上进行超参数调优。
- en: In the code cell, we specify the **number of estimators** and the **maximum
    depth** of the tree that we search for to get the best results on the test set.
    We finally monitor the score and see how changes in the hyperparameters can lead
    to better performance by the model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码单元格中，我们指定**估计器数量**和**树的最大深度**，以便在测试集上获得最佳结果。我们最终监控得分，并观察超参数的变化如何导致模型性能的提升。
- en: Model Deployment
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署
- en: Now that we have performed hyperparameter tuning to give the most accurate predictions,
    it is time to save the machine learning models that provided the best results.
    Therefore, we would be using the **pickle** library in python so that we would
    be having the freedom to save the machine learning model that could be later used
    for serving.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经进行了超参数调优以提供最准确的预测，是时候保存提供最佳结果的机器学习模型了。因此，我们将使用python中的**pickle**库，以便能够保存可以用于服务的机器学习模型。
- en: After saving the model, we would again load it when we are building a **production-ready**
    code and use it to make predictions on incoming batches or streams of data. It
    is to be noted that the set of steps that were used to perform featurization during
    the training data must also be performed on the test set so that there is no skew
    in the data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 保存模型后，我们将在构建**生产就绪**代码时再次加载它，并用它来对 incoming batches 或数据流进行预测。需要注意的是，在训练数据期间使用的特征化步骤也必须在测试集上执行，以避免数据偏差。
- en: Constant Monitoring
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持续监控
- en: We know that the model is performing a good job in serving data where it is
    receiving incoming data from users, it is also an important yet neglected step
    which is to **monitor** the predictive quality of the models. There are often
    scenarios where the models might not be performing as they were during the training.
    This can be because there is a difference between the training and serving data.
    For example, there can be situations such as **concept drift** or **data drift**
    that can have a significant impact on the performance of the inference model that
    is put into production.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道模型在处理接收用户数据时表现良好，但一个重要且常被忽视的步骤是**监控**模型的预测质量。模型的表现可能会与训练期间有所不同。这可能是因为训练数据和服务数据之间存在差异。例如，可能会出现**概念漂移**或**数据漂移**，这些情况会对投入生产的推理模型的性能产生显著影响。
- en: Constant monitoring ensures that steps are taken to check the predictive models
    and understand their behavior with changing data. If the predictions are the **least
    accurate** and it is leading to a loss of revenue for the business, steps should
    be taken to again train the models with this deviant data so that there is no
    unexpected change in the behavior of the models respectively.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 持续监控确保采取措施检查预测模型，并了解其在变化数据下的行为。如果预测的**准确性最低**，并导致企业收入损失，则应采取措施用这些异常数据重新训练模型，以确保模型行为不会出现意外变化。
- en: Conclusion
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: After going through this article, you might have gotten a good idea about how
    to perform machine learning for **audio data** and understand the overall workflow.
    We have seen steps such as reading the data, feature engineering, training the
    models, hyperparameter tuning, model deployment along with constant monitoring.
    Applying each of these steps and ensuring that there are no mistakes when developing
    a pipeline would lead to a robust machine learning production system.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读完这篇文章后，你可能对如何进行**音频数据**的机器学习以及整体工作流程有了很好的了解。我们见识了读取数据、特征工程、模型训练、超参数调整、模型部署及持续监控等步骤。应用这些步骤并确保在开发管道时没有错误，将导致一个稳健的机器学习生产系统。
- en: '*Below are the ways where you could contact me or take a look at my work.*'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*以下是你可以联系我或查看我的工作的方式。*'
- en: '***GitHub:***[*suhasmaddali (Suhas Maddali ) (github.com)*](https://github.com/suhasmaddali)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '***GitHub：***[*suhasmaddali (Suhas Maddali ) (github.com)*](https://github.com/suhasmaddali)'
- en: '***YouTube:***[*https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q*](https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '***YouTube：***[*https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q*](https://www.youtube.com/channel/UCymdyoyJBC_i7QVfbrIs-4Q)'
- en: '***LinkedIn:***[*(1) Suhas Maddali, Northeastern University, Data Science |
    LinkedIn*](https://www.linkedin.com/in/suhas-maddali/)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '***LinkedIn：***[*(1) Suhas Maddali, Northeastern University, Data Science |
    LinkedIn*](https://www.linkedin.com/in/suhas-maddali/)'
- en: '***Medium:*** [*Suhas Maddali — Medium*](https://suhas-maddali007.medium.com/)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '***中等：*** [*Suhas Maddali — Medium*](https://suhas-maddali007.medium.com/)'
