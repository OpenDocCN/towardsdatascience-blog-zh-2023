- en: Engineering Features for Contextual Recommendation Engines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上下文推荐引擎的特征工程
- en: 原文：[https://towardsdatascience.com/engineering-features-for-contextual-recommendation-engines-bb80bf0e0453?source=collection_archive---------5-----------------------#2023-04-27](https://towardsdatascience.com/engineering-features-for-contextual-recommendation-engines-bb80bf0e0453?source=collection_archive---------5-----------------------#2023-04-27)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/engineering-features-for-contextual-recommendation-engines-bb80bf0e0453?source=collection_archive---------5-----------------------#2023-04-27](https://towardsdatascience.com/engineering-features-for-contextual-recommendation-engines-bb80bf0e0453?source=collection_archive---------5-----------------------#2023-04-27)
- en: Analysis of distinct cases where contextual information dominates
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对于上下文信息主导的不同案例的分析
- en: '[](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)[![Andrew
    Charabin](../Images/8cfe2657a9cd16c3ce30b98e3c9e9945.png)](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)
    [Andrew Charabin](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)[![Andrew
    Charabin](../Images/8cfe2657a9cd16c3ce30b98e3c9e9945.png)](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)
    [安德鲁·查拉宾](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff282e085f18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&user=Andrew+Charabin&userId=f282e085f18e&source=post_page-f282e085f18e----bb80bf0e0453---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)
    ·11 min read·Apr 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb80bf0e0453&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&user=Andrew+Charabin&userId=f282e085f18e&source=-----bb80bf0e0453---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff282e085f18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&user=Andrew+Charabin&userId=f282e085f18e&source=post_page-f282e085f18e----bb80bf0e0453---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)
    · 11 分钟阅读 · 2023年4月27日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb80bf0e0453&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&user=Andrew+Charabin&userId=f282e085f18e&source=-----bb80bf0e0453---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb80bf0e0453&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&source=-----bb80bf0e0453---------------------bookmark_footer-----------)![](../Images/aaf4b2ef0a1cf95f7b08c1bd6f54c55b.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb80bf0e0453&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&source=-----bb80bf0e0453---------------------bookmark_footer-----------)![](../Images/aaf4b2ef0a1cf95f7b08c1bd6f54c55b.png)'
- en: Image via VectorStock under license to Andrew Charabin
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源于 VectorStock，授权给**安德鲁·查拉宾**
- en: From entertainment applications to dating platforms, social networking sites
    to retail, recommendation engines play a pivotal role in today’s society. Not
    only have they made significant progress in their effectiveness, but they are
    playing an ever-increasing role in our lives from guiding our attention, personalizing
    to our interests, and surfacing items of personal value. While each recommendation
    engine is unique and needs to account for the intricacies of a problem, the business,
    and available data, many of the building blocks are the same — user/item embeddings,
    user histories, contextual features, and neural collaborative layers to map users
    and items to ratings. Models can bypass assumptive and error-prone hand-made data
    and instead use large datasets of implicit and explicit feedback to predict ratings.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从娱乐应用到约会平台，从社交网络到零售，推荐引擎在当今社会中发挥了至关重要的作用。它们不仅在有效性上取得了显著进展，而且在引导我们的注意力、根据我们的兴趣进行个性化和推荐个人价值的项目等方面扮演着越来越重要的角色。虽然每个推荐引擎都是独特的，需要考虑问题、业务和可用数据的复杂性，但许多构建块是相同的——用户/项目嵌入、用户历史、上下文特征以及神经协作层来将用户和项目映射到评分。模型可以绕过假设性和容易出错的手动数据，转而使用大量的隐含和明确反馈数据来预测评分。
- en: 'Recommender engines are machine learning or rules-based models that provide
    recommendations like the best content/item for a user, the right customers to
    target for a product, or a fair price. They follow the generic structure:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎是机器学习或基于规则的模型，提供如最适合用户的内容/项目、目标客户、或公平价格等推荐。它们遵循以下通用结构：
- en: Outcome = F(U, I, C)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 = F(U, I, C)
- en: Where U is a user, I is an item, C is the context, and F is a function that
    maps the combination of a U, I, and C to an outcome. An outcome could be explicit
    feedback like a rating, implicit feedback like watch time, or a non-feedback quantity
    like price.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 U 是用户，I 是项目，C 是上下文，F 是一个将 U、I 和 C 的组合映射到结果的函数。结果可以是明确的反馈，如评分，隐含的反馈，如观看时间，或非反馈量，如价格。
- en: When a recommendation engine is packaged along with a data pipeline to source
    required input data, an ability host or obtain batch inferences from the model
    and make updates over time, and a user-interface to receive and interact with
    recommendations, it becomes a recommendation system.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当推荐引擎与数据管道打包在一起以获取所需的输入数据、具备从模型中获取批量推断和随时间进行更新的能力，以及一个用户界面以接收和互动推荐时，它就成为了一个推荐系统。
- en: A simple example of a recommendation engine is a model that recommends a movie
    (I) for a user of a streaming platform (U) on the weekend (C).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎的一个简单示例是一个为流媒体平台上的用户（U）在周末（C）推荐电影（I）的模型。
- en: A [collaborative recommendation engine](https://towardsdatascience.com/tagged/collaborative-filtering)
    can be used to map users and items to a common embedding space, after which the
    closest items in space can be recommended to a user. In order to map users and
    items to this new embedding space, matrix factorization approaches or multi-layer
    perceptrons can be applied. So long as there is sufficient past data on user and
    item feedback, approaches to automatically map and find the similarity between
    users and items tend to lead to much better recommendations than those using hand-made
    features like user and item metadata.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[协作推荐引擎](https://towardsdatascience.com/tagged/collaborative-filtering)可以用来将用户和项目映射到一个共同的嵌入空间，然后可以推荐空间中最接近的项目给用户。为了将用户和项目映射到这个新的嵌入空间，可以应用矩阵分解方法或多层感知机。只要有足够的过去的用户和项目反馈数据，自动映射和寻找用户与项目之间相似性的方式往往比使用手动特征（如用户和项目元数据）的推荐更为有效。'
- en: Consider the following embedding space based on 2 hand-made features, the level
    to which a movie falls within drama and fantasy genres out of 5, and considering
    3 movies.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下基于 2 个手动特征的嵌入空间：一部电影在戏剧和奇幻类型中的评分（满分 5 分），并考虑 3 部电影。
- en: '![](../Images/c5907f58ffa70a9b3b27667a4fa006b1.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c5907f58ffa70a9b3b27667a4fa006b1.png)'
- en: Chart 1 by author
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 作者图表 1
- en: Instead of using 2 hand-made features, collaborative systems are trained to
    automatically map users and items to for example k=10 different ‘latent dimensions’
    that can be found using past ratings and without requiring additional item/user
    metadata.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用 2 个手动制作的特征不同，协作系统被训练来自动将用户和项目映射到例如 k=10 个不同的“潜在维度”，这些维度可以通过过去的评分找到，而无需额外的项目/用户元数据。
- en: You’ll also note that both drama and fantasy play an ~ equal weight in determining
    an item’s location in space in the above. Using multi-layer perceptrons vs. matrix
    factorization, there is more flexibility in how embeddings are derived and used
    to find the most similar items to users. For example, embeddings can be learned
    whereby different dimensions have different weights in determining the users location
    in space. I.e. if drama was twice as important as fantasy in a movie’s position,
    you could picture the Y axis getting squashed in half, and Memento’s relative
    distance to Star Wars being slightly reduced.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会注意到，戏剧和奇幻在上面确定项目在空间中的位置时都扮演着~ 相等的角色。使用多层感知机与矩阵分解相比，嵌入的衍生和使用方式更具灵活性，以找到与用户最相似的项目。例如，可以学习嵌入，使得不同的维度在确定用户在空间中的位置时具有不同的权重。即，如果戏剧在电影的位置中比奇幻重要两倍，你可以想象Y轴被压缩了一半，*记忆碎片*与《星球大战》的相对距离略有减少。
- en: '![](../Images/509d760e7d84568257c903785a502772.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/509d760e7d84568257c903785a502772.png)'
- en: Chart 2 by author
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图表2
- en: '[Neural collaborative filtering (NCF)](https://arxiv.org/pdf/1708.05031.pdf)
    is a generalized framework to predict user by items ratings which allows relaxing
    some of the linear restrictions of matrix factorization akin to Chart 1 — all
    dimensions having the same weight, and the rating being inversely proportional
    to distance in space (known as the interaction function being linear).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[神经协同过滤（NCF）](https://arxiv.org/pdf/1708.05031.pdf)是一个广义框架，用于通过项目评分预测用户，这允许放宽类似于图表1中的矩阵分解的线性限制——所有维度具有相同的权重，且评分与空间中的距离成反比（称为交互函数是线性的）。'
- en: Contextual information like when the movie is watched or who a user is watching
    it with can be considered after the initial recommendation is made by filtering
    results (contextual post-filtering), or before by treating items as separate depending
    on the context in which they are consumed (contextual pre-filtering).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文信息，如电影何时观看或用户与谁一起观看，可以在初始推荐后通过结果过滤（上下文后过滤），或在初始推荐前通过根据消费上下文将项目视为独立项（上下文前过滤）来考虑。
- en: For greater rigor, contextual fields can be integrated as additional dimensions
    in the space. Consider the below example where we add a hand-made feature on the
    vertical axis that indicates the prevalence of users watching the movie with their
    family.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更高的严谨性，可以将上下文字段作为空间中的附加维度集成。考虑下面的示例，我们在垂直轴上添加了一个手工制作的特征，表示用户与家人一起观看电影的普及程度。
- en: '![](../Images/c30bf2acba19a7e89bf7098358d62566.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c30bf2acba19a7e89bf7098358d62566.png)'
- en: Chart 3 by author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图表3
- en: However, since the computational complexity of traditional embedding techniques
    grows exponentially with the number of contextual dimensions (i.e. see [multiverse](https://dl.acm.org/doi/10.1145/1864708.1864727#:~:text=In%20the%20proposed%20model%2C%20called,to%20provide%20context%2Daware%20recommendations.)
    as an example), alternative approaches like [factorization machines](/an-intuitive-explanation-of-field-aware-factorization-machines-a8fee92ce29f)
    can be employed to preserve tractability.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于传统嵌入技术的计算复杂度随着上下文维度的增加而呈指数增长（例如，参见[多重宇宙](https://dl.acm.org/doi/10.1145/1864708.1864727#:~:text=In%20the%20proposed%20model%2C%20called,to%20provide%20context%2Daware%20recommendations.)作为一个例子），可以采用诸如[因子分解机](/an-intuitive-explanation-of-field-aware-factorization-machines-a8fee92ce29f)等替代方法来保持可处理性。
- en: Given each real-world recommender system case is unique, modern recommendation
    systems are often a purpose-built combination of various building blocks like
    item embeddings, matrix factorization, and neural layers to find connections between
    users and items. For example, consider [YouTube’s video recommendation engine](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)
    that combines two different deep neural networks, a first to select good candidate
    videos that you’d like if you watched, and a second to pick the best candidates
    that you are most likely to watch the longest.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于每个现实世界的推荐系统案例都是独特的，现代推荐系统通常是各种构建模块的专门组合，如项目嵌入、矩阵分解和神经网络层，以寻找用户与项目之间的连接。例如，考虑[YouTube的视频推荐引擎](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)，它结合了两个不同的深度神经网络，第一个选择你可能喜欢的优质候选视频，第二个挑选出你最可能观看时间最长的最佳候选视频。
- en: In this article, I’d like to discuss two general examples I’ve encountered that
    deviate from traditional user by item recommender systems, as well as some unique
    ways to engineer features to use to solve such problems with tree-based or deep
    learning models. In both examples, contextual information plays a relatively greater
    role in predicting successful interactions than in traditional examples like movie
    recommenders.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我想讨论我遇到的两个偏离传统用户按项目推荐系统的一般示例，以及使用基于树或深度学习模型解决这类问题时一些独特的特征工程方法。在这两个示例中，上下文信息在预测成功交互方面的作用相对较大，而不像传统的电影推荐系统那样。
- en: 'The scenarios are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些场景如下：
- en: High Context & Low User Importance > Outcome = F(I, C)
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高上下文 & 低用户重要性 > 结果 = F(I, C)
- en: High Context & No Item > Outcome = F(U, C)
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高上下文 & 无项目 > 结果 = F(U, C)
- en: '**Scenario 1**'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**场景 1**'
- en: Outcome = F(I, C)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 = F(I, C)
- en: The first scenario is where the items and context play a dominant role in the
    recommender, whereas the user takes a backseat. Consider cases where the majority
    of users are first-time so there is limited value in user history/similarity,
    many items are new and have never been rated, or the right fit items depend entirely
    on context and little on the user.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种情况是项目和上下文在推荐系统中起主导作用，而用户则处于次要位置。考虑到大多数用户是首次使用，因此用户历史/相似性的价值有限，许多项目是新的且从未被评分过，或者合适的项目完全依赖于上下文，与用户关系不大。
- en: To select the best freelancer for a job, you’d want to understand how well they
    performed similar jobs, how past users rated them, and if they have a reputation
    of getting their work done on time. The fact that you recently worked with an
    online copywriter may not be the most relevant to finding the right person for
    your current on-premise photography job.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要选择最合适的自由职业者来完成工作，您需要了解他们在类似工作中的表现如何，过去用户如何评价他们，以及他们是否有按时完成工作的声誉。最近与在线文案撰稿人合作的事实可能并不是找到当前现场摄影工作合适人选的最相关因素。
- en: How would traditional recommender engines work in such a scenario? A content-based
    one may recommend somebody similar to your copywriter, while a collaborative one
    may recommend freelancers that others had hired after hiring the copywriter. Neither
    of these recommendations would be particularly helpful. Because of the differing
    context, experience other users have had hiring for photography jobs in the area
    may be more relevant to you then your past experience.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，传统的推荐引擎如何运作呢？基于内容的推荐可能会推荐与您的文案撰稿人相似的人，而协同推荐可能会推荐在雇佣文案撰稿人后其他人也雇佣过的自由职业者。这些推荐都可能并不特别有帮助。由于不同的上下文，其他用户在雇佣该地区摄影工作时的经验可能比您过去的经验更相关。
- en: So we’d like to understand the best freelancers that were hired for previous
    jobs that matched the current context, regardless of the user. But what if there
    are a multitude of different contextual dimensions of the job, i.e. type of work,
    skills, scope etc., as well as different ways to measure the user feedback i.e.
    speed of delivery, rating, and hires?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们希望了解先前被雇用的最佳自由职业者，这些自由职业者与当前上下文匹配，而与用户无关。但是，如果工作具有多种不同的上下文维度，例如工作类型、技能、范围等，以及衡量用户反馈的不同方法，例如交付速度、评级和雇佣情况，该如何处理呢？
- en: One solution is to take a cartesian product of contextual and feedback dimensions,
    then aggregate item histories across all users.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一种解决方案是对上下文和反馈维度进行笛卡尔积，然后汇总所有用户的项目历史记录。
- en: '**Cartesian Product of Context & Past Feedback**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文与过去反馈的笛卡尔积**'
- en: To do this we first need to one-hot-encode dimensions to have dedicated dimensions
    for each level. For illustrative purposes, the result looks as follows for a candidate
    freelancer. Noting that when used in a model we would unroll each row in the last
    3 columns into dedicated feature columns with names like avg_delivery_on_time_photography.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们首先需要对维度进行独热编码，以便为每个级别分配专用维度。为了说明问题，以下是候选自由职业者的结果。请注意，在模型中使用时，我们将会把最后三列中的每一行展开为具有名称如`avg_delivery_on_time_photography`的专用特征列。
- en: '![](../Images/46fead61be3cd2cf5a4f3a27c46a8575.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/46fead61be3cd2cf5a4f3a27c46a8575.png)'
- en: Chart 4 by author
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图表 4 作者提供
- en: But if we have n initial contextual dimensions each with h — 1 one-hot encoded
    levels and k feedback dimensions, n x h — 1 x k model features are required to
    map all possible combinations. In the above incomplete example, that leads to
    51 features.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果我们有 n 个初始上下文维度，每个维度具有 h - 1 个独热编码级别和 k 个反馈维度，那么需要 n x (h - 1) x k 个模型特征来映射所有可能的组合。在上面的不完整示例中，这导致了
    51 个特征。
- en: Furthermore, many of the features are related to additional types of jobs (software
    development) that aren’t relevant to the current context but have been created
    by the cartesian product.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，许多特征与额外类型的工作（软件开发）相关，这些工作与当前上下文无关，但已通过笛卡尔积创建。
- en: 'A more compact and meaningful way to encode this information is by finding
    past history that matches the current context across all contextual and feedback
    dimensions, which instead requires n x k features. Such contextual aggregations
    can easily be accomplished in SQL using case logic akin to the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 更简洁且有意义的编码方法是找到匹配当前上下文的所有上下文和反馈维度的过去历史，这需要 `n x k` 特征。这种上下文聚合可以通过类似以下的 SQL 使用案例逻辑轻松实现：
- en: avg(case when past_job.type_of_work = job.type_of_work then delivery_on_time
    end) as avg_delivery_type_of_work
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`avg(case when past_job.type_of_work = job.type_of_work then delivery_on_time
    end)` 作为 `avg_delivery_type_of_work`'
- en: Where the job table contains information on the current job context and the
    past_job table contains information for past jobs.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中工作表包含当前工作上下文的信息，而 `past_job` 表包含过去工作的相关信息。
- en: 'The improvement looks as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 改进情况如下：
- en: '![](../Images/7e36f7e983af03b448b513842d4c7fb6.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e36f7e983af03b448b513842d4c7fb6.png)'
- en: Chart 5 by author
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图表 5 由作者提供
- en: The end result is rich information on how past freelancers (items) performed
    for similar jobs (context) while limiting unnecessarily high dimensionality. To
    produce features, contextual dimensions are only considered linearly. Combination
    like past ratings when both the budget is medium and the experience level is expert
    are omitted. Non-linearities can still be derived by the training algorithm, or
    additional contextual dimensions can be created as the the product of existing
    ones.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果是关于过去自由职业者（项目）在类似工作（上下文）中的表现的丰富信息，同时限制了不必要的高维度。为了生成特征，上下文维度仅按线性方式考虑。诸如预算中等且经验水平为专家时的过去评分等组合被省略。非线性特性仍然可以由训练算法导出，或者可以创建额外的上下文维度作为现有维度的乘积。
- en: We can then unroll each feedback by context column into a dedicated feature
    column, with a row indicating a distinct freelancer. Then, stack all freelancers
    meeting hard criteria (i.e. does photography work) and their associated features
    into additional rows. We can rebuild this representation now considering each
    past job as the current job, stacking each past job as a set of additional rows.
    For past jobs, we can create an additional column to capture explicit feedback
    received by the freelancer such as being hired, or implicit feedback like being
    messaged.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将每个反馈按上下文列展开为一个专用特征列，行指示一个独特的自由职业者。接着，将所有符合严格标准（即从事摄影工作）的自由职业者及其相关特征堆叠到额外的行中。现在我们可以重新构建这种表示，将每个过去的工作视为当前工作，将每个过去的工作堆叠为一组额外的行。对于过去的工作，我们可以创建一个额外的列来捕捉自由职业者收到的明确反馈，例如被雇佣，或隐性反馈如被联系。
- en: '![](../Images/3332880791ab40ab37fc767529f32463.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3332880791ab40ab37fc767529f32463.png)'
- en: Chart 6 by author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图表 6 由作者提供
- en: 'Finally, we can train a tree-based model like XGBoost to use the engineered
    features (job and talent # excluded) to predict feedback talent received among
    completed jobs, deploy the model, and apply it to newly posted jobs to recommend
    the best freelancers.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，我们可以训练一个基于树的模型如 XGBoost，使用工程特征（排除工作和才艺 #）来预测完成工作的反馈才艺，部署该模型，并将其应用于新发布的工作，以推荐最佳自由职业者。'
- en: '**Scenario 2**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**场景 2**'
- en: Outcome = F(U, C)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 结果 = F(U, C)
- en: Another instance is when the recommendation isn’t for a discrete item, but rather
    a continuous value. Consider a platform recommending the price a property rental
    company should charge for a property on a weekend.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是，当推荐不是针对离散项，而是针对连续值时。考虑一个平台推荐物业租赁公司在周末应收取的物业租金。
- en: In such an instance, we can observe past prices for rentals that matched contextual
    dimensions, but now instead of performing a cartesian product with types of item
    feedback, we can multiply by whether or not the rental was for the same user or
    another user. Finally, we can aggregate past prices such as through an average.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以观察到与上下文维度匹配的过去租金价格，但现在我们不再对项反馈类型执行笛卡尔积，而是通过租赁是否为同一用户或其他用户来进行乘法运算。最后，我们可以通过计算平均值来汇总过去的价格。
- en: '![](../Images/c75316e523c031ac7c09c626b89c32c7.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c75316e523c031ac7c09c626b89c32c7.png)'
- en: Chart 7 by author
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图表 7 由作者提供
- en: We can then perform the additional steps outlined at the end of Scenario 1.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以执行场景 1 末尾概述的额外步骤。
- en: '**Layered Models**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**分层模型**'
- en: Another option is to create an initial contextual model to make a prediction
    across all users, and then a second model that takes the user-agnostic prediction
    and tailors it to the user. One benefit of such an approach is that it provides
    two different yet meaningful predictions that you can recommend to the user or
    otherwise apply to drive the desired behavior.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是创建一个初步的上下文模型，以便在所有用户中进行预测，然后再创建一个第二个模型，将用户无关的预测调整为用户特定的预测。这种方法的一个好处是提供了两种不同但有意义的预测，您可以推荐给用户或用于驱动期望的行为。
- en: Consider the example of a model that inputs a job description and associated
    metadata to recommend a position’s salary prior to recruitment. A first model
    can predict the salary agnostic of the company to find the ‘market rate’ for the
    position.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个模型为例，该模型输入职位描述和相关元数据以推荐招聘前的职位薪资。第一个模型可以预测与公司无关的薪资，从而找到该职位的“市场价格”。
- en: A second model can be trained with the first model’s prediction as an input,
    and additional company features similar to the third column in Chart 7, to find
    the ‘tailored’ salary prediction, i.e. the salary prediction considering similar
    positions filled and whether they were filled by the same or another company.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 可以用第一个模型的预测作为输入，并结合类似于图表7第三列的额外公司特征来训练第二个模型，以找到“量身定制”的薪资预测，即考虑到类似职位是否由同一家公司或另一家公司填补的薪资预测。
- en: If the tailored prediction is substantially different than the market rate,
    it may be useful for the company to understand the delta and it’s implications.
    For example, another model could be developed to predict the tenure of a new hire
    based on the job description, candidate hired, starting salary, and company. The
    difference in predicted tenure could be computed using the market rate as opposed
    to the tailored salary as input. Let’s say the market rate is $75K and the tailored
    salary is $65K, but the predicted tenure at $75K is 1 year greater. The recommender
    system could present $75K as the recommended salary and provide a tool to observe
    how predicted tenure changes by the salary offered.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果量身定制的预测与市场价格有显著不同，公司可能需要了解这一差异及其影响。例如，可以开发另一种模型，基于职位描述、招聘的候选人、起始薪资和公司来预测新员工的在职时间。可以使用市场价格与量身定制的薪资作为输入来计算预测的在职时间差异。假设市场价格为$75K，量身定制的薪资为$65K，但在$75K的预测在职时间多出1年。推荐系统可以将$75K作为推荐薪资，并提供一个工具观察不同薪资下的预测在职时间变化。
- en: To train layered models while [preventing leakage](https://machinelearningmastery.com/data-preparation-without-data-leakage/),
    where ‘knowledge from the hold-out set leaks into the dataset used to train the
    model,’ you’ll need to ensure that observations used to train each layer do not
    overlap.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在[防止泄漏](https://machinelearningmastery.com/data-preparation-without-data-leakage/)的情况下训练分层模型，即“避免从持出集泄漏到用于训练模型的数据集中”，需要确保用于训练每一层的观察数据没有重叠。
- en: Furthermore, if you integrate a feature in the second-layer model that finds
    the difference between historical company salaries for similar positions and market
    rate salaries predicted by the first layer model, i.e. say resulting in an average
    of $8K below the market rate, you’ll need to sample your training, evaluation,
    and testing sets on a company vs. position level. This is because as a feature
    to predict the salary for a position, you’ve also integrated information on the
    market rate predictions from all prior positions filled at the company. To avoid
    bias, the predictions of observations used to train a first model should not be
    used in anyway as features for a subsequent model. We end up with a train/test
    split as follows, excluding the validation set, and using a split ratio 80% for
    illustrative purposes.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果在第二层模型中集成了一个特征，该特征计算类似职位的历史公司薪资与第一个层模型预测的市场价格之间的差异，例如，结果为低于市场价格的平均$8K，则需要在公司与职位层级上对训练、评估和测试集进行抽样。这是因为作为职位薪资预测的特征，您还集成了所有公司之前填补的职位的市场价格预测。为了避免偏差，用于训练第一个模型的观察预测不应以任何方式作为后续模型的特征。我们最终得到一个训练/测试划分如下，不包括验证集，使用80%的划分比例作为示例。
- en: '![](../Images/9bfe8e862084178d7c48324347556190.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bfe8e862084178d7c48324347556190.png)'
- en: Chart 8 by author
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 作者的图表8
- en: Evidently, a layered approach is only a viable alternative when there is a substantial
    volume of past data. A relatively lower split ratio like 70% may be preferable.
    Any improvements to the model through the additional user features made available
    in the layered approach need to be contrasted with observation loss in the second
    layer model. However, in the specific regression use cases where I’ve evaluated
    a layered approach, I’ve found that just by integrating the prediction from an
    initial tree-based model trained on 80% of observations into a second one trained
    on a remaining 16% of observations, the resulting MSE on the final 4% of observations
    ~ the MSE of a model trained on all 96% of training observations.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，只有在过去数据量相当大时，分层方法才是一种可行的替代方案。像70%这样相对较低的分割比可能更可取。在分层方法中提供的附加用户特征对第二层模型的观察损失进行了对比，然而，在我评估过的特定回归用例中，仅通过将80%观测数据训练的初始基于树的模型的预测整合到余下16%观测数据训练的第二个模型中，最终4%观测数据上的MSE约等于在所有96%训练观测数据上训练的模型的MSE。
- en: '**Combining Recommendations From Contextual & Collaborative Models**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**结合来自上下文和协同模型的推荐**'
- en: F(I, C) + F(U, I)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: F(I, C) + F(U, I)
- en: Finally, recommendations derived from contextual models can always be weighted
    with those obtained from user/item similarity in a collaborative model to provide
    to the best recommendations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从上下文模型衍生的推荐始终可以与从用户/物品相似性中获得的推荐加权，以提供最佳推荐。
- en: To better understand alternative approaches to measure user/item similarity
    given embeddings, I’d strongly recommend [this](https://www.baeldung.com/cs/euclidean-distance-vs-cosine-similarity#:~:text=The%20Euclidean%20distance%20corresponds%20to,the%20product%20of%20their%20magnitudes.)
    article that distinguishes L-norms and angular measures.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解给定嵌入的用户/物品相似性的替代方法，我强烈推荐阅读[这篇文章](https://www.baeldung.com/cs/euclidean-distance-vs-cosine-similarity#:~:text=The%20Euclidean%20distance%20corresponds%20to,the%20product%20of%20their%20magnitudes.)，该文章区分了L-范数和角度度量。
- en: Closing remarks
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: While our current society has seen remarkable advancements in recommenders,
    less research has focused on incorporating contextual information that alters
    the nature of user and item interactions. Neural collaborative filtering (NCF)
    provides a framework for the development of neural networks where the first layer
    takes in a user and item identity to derive embeddings, and later layers model
    the interaction with the user and item embeddings to predict ratings. For now,
    relevant context still needs to be hand-made and explicitly fed into models. While
    NCF approaches are the recommended way to go, used by the likes of YouTube and
    Google, in some cases they may be a bit overkill such as in non-traditional cases
    when contextual information plays a dominant role.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们当前的社会在推荐系统方面取得了显著进展，但较少的研究集中于整合改变用户和物品交互性质的上下文信息。神经协同过滤（NCF）提供了一个框架，用于开发神经网络，其中第一层接收用户和物品标识以推导嵌入，后续层模拟与用户和物品嵌入的交互以预测评分。目前，相关的上下文仍然需要手工制作并显式地输入到模型中。虽然NCF方法是推荐的方式，被YouTube和Google等公司使用，但在某些情况下，例如在上下文信息起主导作用的非传统情况下，它们可能有些过度。
- en: I’ve walked through a couple of recommender cases I’ve personally experienced;
    where user information isn’t very important, and where there are no items. I’ve
    displayed some intriguing ways to engineer hand-made features in these cases such
    as through cartesian products and layered models.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经详细介绍了我个人经历过的几个推荐系统案例；在这些案例中，用户信息并不是非常重要，也没有物品。我展示了一些有趣的方法来在这些情况下制作手工特征，例如通过笛卡尔积和分层模型。
- en: I hope the ideas here helped spark some creativity, grow your knowledge, and
    motivate you to further explore the captivating field of recommendation engines.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这里的想法有助于激发一些创意，扩展你的知识，并激励你进一步探索迷人的推荐引擎领域。
- en: Thanks for reading! If you liked this article, follow me to get notified of
    my new posts. Also, feel free to share any comments/suggestions.
  id: totrans-83
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 感谢阅读！如果你喜欢这篇文章，请关注我以获取我的新文章通知。同时，欢迎分享任何意见/建议。
