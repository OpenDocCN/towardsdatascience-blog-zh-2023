- en: Engineering Features for Contextual Recommendation Engines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/engineering-features-for-contextual-recommendation-engines-bb80bf0e0453?source=collection_archive---------5-----------------------#2023-04-27](https://towardsdatascience.com/engineering-features-for-contextual-recommendation-engines-bb80bf0e0453?source=collection_archive---------5-----------------------#2023-04-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Analysis of distinct cases where contextual information dominates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)[![Andrew
    Charabin](../Images/8cfe2657a9cd16c3ce30b98e3c9e9945.png)](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)[](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)
    [Andrew Charabin](https://medium.com/@andrewcharabin?source=post_page-----bb80bf0e0453--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff282e085f18e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&user=Andrew+Charabin&userId=f282e085f18e&source=post_page-f282e085f18e----bb80bf0e0453---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----bb80bf0e0453--------------------------------)
    ·11 min read·Apr 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fbb80bf0e0453&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&user=Andrew+Charabin&userId=f282e085f18e&source=-----bb80bf0e0453---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fbb80bf0e0453&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fengineering-features-for-contextual-recommendation-engines-bb80bf0e0453&source=-----bb80bf0e0453---------------------bookmark_footer-----------)![](../Images/aaf4b2ef0a1cf95f7b08c1bd6f54c55b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image via VectorStock under license to Andrew Charabin
  prefs: []
  type: TYPE_NORMAL
- en: From entertainment applications to dating platforms, social networking sites
    to retail, recommendation engines play a pivotal role in today’s society. Not
    only have they made significant progress in their effectiveness, but they are
    playing an ever-increasing role in our lives from guiding our attention, personalizing
    to our interests, and surfacing items of personal value. While each recommendation
    engine is unique and needs to account for the intricacies of a problem, the business,
    and available data, many of the building blocks are the same — user/item embeddings,
    user histories, contextual features, and neural collaborative layers to map users
    and items to ratings. Models can bypass assumptive and error-prone hand-made data
    and instead use large datasets of implicit and explicit feedback to predict ratings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recommender engines are machine learning or rules-based models that provide
    recommendations like the best content/item for a user, the right customers to
    target for a product, or a fair price. They follow the generic structure:'
  prefs: []
  type: TYPE_NORMAL
- en: Outcome = F(U, I, C)
  prefs: []
  type: TYPE_NORMAL
- en: Where U is a user, I is an item, C is the context, and F is a function that
    maps the combination of a U, I, and C to an outcome. An outcome could be explicit
    feedback like a rating, implicit feedback like watch time, or a non-feedback quantity
    like price.
  prefs: []
  type: TYPE_NORMAL
- en: When a recommendation engine is packaged along with a data pipeline to source
    required input data, an ability host or obtain batch inferences from the model
    and make updates over time, and a user-interface to receive and interact with
    recommendations, it becomes a recommendation system.
  prefs: []
  type: TYPE_NORMAL
- en: A simple example of a recommendation engine is a model that recommends a movie
    (I) for a user of a streaming platform (U) on the weekend (C).
  prefs: []
  type: TYPE_NORMAL
- en: A [collaborative recommendation engine](https://towardsdatascience.com/tagged/collaborative-filtering)
    can be used to map users and items to a common embedding space, after which the
    closest items in space can be recommended to a user. In order to map users and
    items to this new embedding space, matrix factorization approaches or multi-layer
    perceptrons can be applied. So long as there is sufficient past data on user and
    item feedback, approaches to automatically map and find the similarity between
    users and items tend to lead to much better recommendations than those using hand-made
    features like user and item metadata.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following embedding space based on 2 hand-made features, the level
    to which a movie falls within drama and fantasy genres out of 5, and considering
    3 movies.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c5907f58ffa70a9b3b27667a4fa006b1.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 1 by author
  prefs: []
  type: TYPE_NORMAL
- en: Instead of using 2 hand-made features, collaborative systems are trained to
    automatically map users and items to for example k=10 different ‘latent dimensions’
    that can be found using past ratings and without requiring additional item/user
    metadata.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll also note that both drama and fantasy play an ~ equal weight in determining
    an item’s location in space in the above. Using multi-layer perceptrons vs. matrix
    factorization, there is more flexibility in how embeddings are derived and used
    to find the most similar items to users. For example, embeddings can be learned
    whereby different dimensions have different weights in determining the users location
    in space. I.e. if drama was twice as important as fantasy in a movie’s position,
    you could picture the Y axis getting squashed in half, and Memento’s relative
    distance to Star Wars being slightly reduced.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/509d760e7d84568257c903785a502772.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 2 by author
  prefs: []
  type: TYPE_NORMAL
- en: '[Neural collaborative filtering (NCF)](https://arxiv.org/pdf/1708.05031.pdf)
    is a generalized framework to predict user by items ratings which allows relaxing
    some of the linear restrictions of matrix factorization akin to Chart 1 — all
    dimensions having the same weight, and the rating being inversely proportional
    to distance in space (known as the interaction function being linear).'
  prefs: []
  type: TYPE_NORMAL
- en: Contextual information like when the movie is watched or who a user is watching
    it with can be considered after the initial recommendation is made by filtering
    results (contextual post-filtering), or before by treating items as separate depending
    on the context in which they are consumed (contextual pre-filtering).
  prefs: []
  type: TYPE_NORMAL
- en: For greater rigor, contextual fields can be integrated as additional dimensions
    in the space. Consider the below example where we add a hand-made feature on the
    vertical axis that indicates the prevalence of users watching the movie with their
    family.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c30bf2acba19a7e89bf7098358d62566.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 3 by author
  prefs: []
  type: TYPE_NORMAL
- en: However, since the computational complexity of traditional embedding techniques
    grows exponentially with the number of contextual dimensions (i.e. see [multiverse](https://dl.acm.org/doi/10.1145/1864708.1864727#:~:text=In%20the%20proposed%20model%2C%20called,to%20provide%20context%2Daware%20recommendations.)
    as an example), alternative approaches like [factorization machines](/an-intuitive-explanation-of-field-aware-factorization-machines-a8fee92ce29f)
    can be employed to preserve tractability.
  prefs: []
  type: TYPE_NORMAL
- en: Given each real-world recommender system case is unique, modern recommendation
    systems are often a purpose-built combination of various building blocks like
    item embeddings, matrix factorization, and neural layers to find connections between
    users and items. For example, consider [YouTube’s video recommendation engine](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)
    that combines two different deep neural networks, a first to select good candidate
    videos that you’d like if you watched, and a second to pick the best candidates
    that you are most likely to watch the longest.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I’d like to discuss two general examples I’ve encountered that
    deviate from traditional user by item recommender systems, as well as some unique
    ways to engineer features to use to solve such problems with tree-based or deep
    learning models. In both examples, contextual information plays a relatively greater
    role in predicting successful interactions than in traditional examples like movie
    recommenders.
  prefs: []
  type: TYPE_NORMAL
- en: 'The scenarios are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: High Context & Low User Importance > Outcome = F(I, C)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: High Context & No Item > Outcome = F(U, C)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Scenario 1**'
  prefs: []
  type: TYPE_NORMAL
- en: Outcome = F(I, C)
  prefs: []
  type: TYPE_NORMAL
- en: The first scenario is where the items and context play a dominant role in the
    recommender, whereas the user takes a backseat. Consider cases where the majority
    of users are first-time so there is limited value in user history/similarity,
    many items are new and have never been rated, or the right fit items depend entirely
    on context and little on the user.
  prefs: []
  type: TYPE_NORMAL
- en: To select the best freelancer for a job, you’d want to understand how well they
    performed similar jobs, how past users rated them, and if they have a reputation
    of getting their work done on time. The fact that you recently worked with an
    online copywriter may not be the most relevant to finding the right person for
    your current on-premise photography job.
  prefs: []
  type: TYPE_NORMAL
- en: How would traditional recommender engines work in such a scenario? A content-based
    one may recommend somebody similar to your copywriter, while a collaborative one
    may recommend freelancers that others had hired after hiring the copywriter. Neither
    of these recommendations would be particularly helpful. Because of the differing
    context, experience other users have had hiring for photography jobs in the area
    may be more relevant to you then your past experience.
  prefs: []
  type: TYPE_NORMAL
- en: So we’d like to understand the best freelancers that were hired for previous
    jobs that matched the current context, regardless of the user. But what if there
    are a multitude of different contextual dimensions of the job, i.e. type of work,
    skills, scope etc., as well as different ways to measure the user feedback i.e.
    speed of delivery, rating, and hires?
  prefs: []
  type: TYPE_NORMAL
- en: One solution is to take a cartesian product of contextual and feedback dimensions,
    then aggregate item histories across all users.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cartesian Product of Context & Past Feedback**'
  prefs: []
  type: TYPE_NORMAL
- en: To do this we first need to one-hot-encode dimensions to have dedicated dimensions
    for each level. For illustrative purposes, the result looks as follows for a candidate
    freelancer. Noting that when used in a model we would unroll each row in the last
    3 columns into dedicated feature columns with names like avg_delivery_on_time_photography.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46fead61be3cd2cf5a4f3a27c46a8575.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 4 by author
  prefs: []
  type: TYPE_NORMAL
- en: But if we have n initial contextual dimensions each with h — 1 one-hot encoded
    levels and k feedback dimensions, n x h — 1 x k model features are required to
    map all possible combinations. In the above incomplete example, that leads to
    51 features.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, many of the features are related to additional types of jobs (software
    development) that aren’t relevant to the current context but have been created
    by the cartesian product.
  prefs: []
  type: TYPE_NORMAL
- en: 'A more compact and meaningful way to encode this information is by finding
    past history that matches the current context across all contextual and feedback
    dimensions, which instead requires n x k features. Such contextual aggregations
    can easily be accomplished in SQL using case logic akin to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: avg(case when past_job.type_of_work = job.type_of_work then delivery_on_time
    end) as avg_delivery_type_of_work
  prefs: []
  type: TYPE_NORMAL
- en: Where the job table contains information on the current job context and the
    past_job table contains information for past jobs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The improvement looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7e36f7e983af03b448b513842d4c7fb6.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 5 by author
  prefs: []
  type: TYPE_NORMAL
- en: The end result is rich information on how past freelancers (items) performed
    for similar jobs (context) while limiting unnecessarily high dimensionality. To
    produce features, contextual dimensions are only considered linearly. Combination
    like past ratings when both the budget is medium and the experience level is expert
    are omitted. Non-linearities can still be derived by the training algorithm, or
    additional contextual dimensions can be created as the the product of existing
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: We can then unroll each feedback by context column into a dedicated feature
    column, with a row indicating a distinct freelancer. Then, stack all freelancers
    meeting hard criteria (i.e. does photography work) and their associated features
    into additional rows. We can rebuild this representation now considering each
    past job as the current job, stacking each past job as a set of additional rows.
    For past jobs, we can create an additional column to capture explicit feedback
    received by the freelancer such as being hired, or implicit feedback like being
    messaged.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3332880791ab40ab37fc767529f32463.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 6 by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we can train a tree-based model like XGBoost to use the engineered
    features (job and talent # excluded) to predict feedback talent received among
    completed jobs, deploy the model, and apply it to newly posted jobs to recommend
    the best freelancers.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Scenario 2**'
  prefs: []
  type: TYPE_NORMAL
- en: Outcome = F(U, C)
  prefs: []
  type: TYPE_NORMAL
- en: Another instance is when the recommendation isn’t for a discrete item, but rather
    a continuous value. Consider a platform recommending the price a property rental
    company should charge for a property on a weekend.
  prefs: []
  type: TYPE_NORMAL
- en: In such an instance, we can observe past prices for rentals that matched contextual
    dimensions, but now instead of performing a cartesian product with types of item
    feedback, we can multiply by whether or not the rental was for the same user or
    another user. Finally, we can aggregate past prices such as through an average.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c75316e523c031ac7c09c626b89c32c7.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 7 by author
  prefs: []
  type: TYPE_NORMAL
- en: We can then perform the additional steps outlined at the end of Scenario 1.
  prefs: []
  type: TYPE_NORMAL
- en: '**Layered Models**'
  prefs: []
  type: TYPE_NORMAL
- en: Another option is to create an initial contextual model to make a prediction
    across all users, and then a second model that takes the user-agnostic prediction
    and tailors it to the user. One benefit of such an approach is that it provides
    two different yet meaningful predictions that you can recommend to the user or
    otherwise apply to drive the desired behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the example of a model that inputs a job description and associated
    metadata to recommend a position’s salary prior to recruitment. A first model
    can predict the salary agnostic of the company to find the ‘market rate’ for the
    position.
  prefs: []
  type: TYPE_NORMAL
- en: A second model can be trained with the first model’s prediction as an input,
    and additional company features similar to the third column in Chart 7, to find
    the ‘tailored’ salary prediction, i.e. the salary prediction considering similar
    positions filled and whether they were filled by the same or another company.
  prefs: []
  type: TYPE_NORMAL
- en: If the tailored prediction is substantially different than the market rate,
    it may be useful for the company to understand the delta and it’s implications.
    For example, another model could be developed to predict the tenure of a new hire
    based on the job description, candidate hired, starting salary, and company. The
    difference in predicted tenure could be computed using the market rate as opposed
    to the tailored salary as input. Let’s say the market rate is $75K and the tailored
    salary is $65K, but the predicted tenure at $75K is 1 year greater. The recommender
    system could present $75K as the recommended salary and provide a tool to observe
    how predicted tenure changes by the salary offered.
  prefs: []
  type: TYPE_NORMAL
- en: To train layered models while [preventing leakage](https://machinelearningmastery.com/data-preparation-without-data-leakage/),
    where ‘knowledge from the hold-out set leaks into the dataset used to train the
    model,’ you’ll need to ensure that observations used to train each layer do not
    overlap.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, if you integrate a feature in the second-layer model that finds
    the difference between historical company salaries for similar positions and market
    rate salaries predicted by the first layer model, i.e. say resulting in an average
    of $8K below the market rate, you’ll need to sample your training, evaluation,
    and testing sets on a company vs. position level. This is because as a feature
    to predict the salary for a position, you’ve also integrated information on the
    market rate predictions from all prior positions filled at the company. To avoid
    bias, the predictions of observations used to train a first model should not be
    used in anyway as features for a subsequent model. We end up with a train/test
    split as follows, excluding the validation set, and using a split ratio 80% for
    illustrative purposes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9bfe8e862084178d7c48324347556190.png)'
  prefs: []
  type: TYPE_IMG
- en: Chart 8 by author
  prefs: []
  type: TYPE_NORMAL
- en: Evidently, a layered approach is only a viable alternative when there is a substantial
    volume of past data. A relatively lower split ratio like 70% may be preferable.
    Any improvements to the model through the additional user features made available
    in the layered approach need to be contrasted with observation loss in the second
    layer model. However, in the specific regression use cases where I’ve evaluated
    a layered approach, I’ve found that just by integrating the prediction from an
    initial tree-based model trained on 80% of observations into a second one trained
    on a remaining 16% of observations, the resulting MSE on the final 4% of observations
    ~ the MSE of a model trained on all 96% of training observations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Combining Recommendations From Contextual & Collaborative Models**'
  prefs: []
  type: TYPE_NORMAL
- en: F(I, C) + F(U, I)
  prefs: []
  type: TYPE_NORMAL
- en: Finally, recommendations derived from contextual models can always be weighted
    with those obtained from user/item similarity in a collaborative model to provide
    to the best recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand alternative approaches to measure user/item similarity
    given embeddings, I’d strongly recommend [this](https://www.baeldung.com/cs/euclidean-distance-vs-cosine-similarity#:~:text=The%20Euclidean%20distance%20corresponds%20to,the%20product%20of%20their%20magnitudes.)
    article that distinguishes L-norms and angular measures.
  prefs: []
  type: TYPE_NORMAL
- en: Closing remarks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While our current society has seen remarkable advancements in recommenders,
    less research has focused on incorporating contextual information that alters
    the nature of user and item interactions. Neural collaborative filtering (NCF)
    provides a framework for the development of neural networks where the first layer
    takes in a user and item identity to derive embeddings, and later layers model
    the interaction with the user and item embeddings to predict ratings. For now,
    relevant context still needs to be hand-made and explicitly fed into models. While
    NCF approaches are the recommended way to go, used by the likes of YouTube and
    Google, in some cases they may be a bit overkill such as in non-traditional cases
    when contextual information plays a dominant role.
  prefs: []
  type: TYPE_NORMAL
- en: I’ve walked through a couple of recommender cases I’ve personally experienced;
    where user information isn’t very important, and where there are no items. I’ve
    displayed some intriguing ways to engineer hand-made features in these cases such
    as through cartesian products and layered models.
  prefs: []
  type: TYPE_NORMAL
- en: I hope the ideas here helped spark some creativity, grow your knowledge, and
    motivate you to further explore the captivating field of recommendation engines.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading! If you liked this article, follow me to get notified of
    my new posts. Also, feel free to share any comments/suggestions.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
