- en: Schedule and Invoke Notebooks as Web Services using Jupyter API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/schedule-and-invoke-notebooks-as-web-services-using-jupyter-api-fb71c1e8a008?source=collection_archive---------3-----------------------#2023-08-10](https://towardsdatascience.com/schedule-and-invoke-notebooks-as-web-services-using-jupyter-api-fb71c1e8a008?source=collection_archive---------3-----------------------#2023-08-10)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@tfoldi?source=post_page-----fb71c1e8a008--------------------------------)[![Tamas
    Foldi](../Images/0453bdb63701bda8c68490b08e8d4a24.png)](https://medium.com/@tfoldi?source=post_page-----fb71c1e8a008--------------------------------)[](https://towardsdatascience.com/?source=post_page-----fb71c1e8a008--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----fb71c1e8a008--------------------------------)
    [Tamas Foldi](https://medium.com/@tfoldi?source=post_page-----fb71c1e8a008--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa586bc473bbf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fschedule-and-invoke-notebooks-as-web-services-using-jupyter-api-fb71c1e8a008&user=Tamas+Foldi&userId=a586bc473bbf&source=post_page-a586bc473bbf----fb71c1e8a008---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----fb71c1e8a008--------------------------------)
    ·6 min read·Aug 10, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ffb71c1e8a008&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fschedule-and-invoke-notebooks-as-web-services-using-jupyter-api-fb71c1e8a008&user=Tamas+Foldi&userId=a586bc473bbf&source=-----fb71c1e8a008---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffb71c1e8a008&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fschedule-and-invoke-notebooks-as-web-services-using-jupyter-api-fb71c1e8a008&source=-----fb71c1e8a008---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to serverless cloud services like GCP CloudRunner and Cloud Functions,
    we don’t need to manage costly virtual machines or servers to deploy our notebooks
    and execute them periodically. With Jupyter API, you can lift and shift your notebooks
    to the cloud, turn them into web services and integrate them with scheduling.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/35bed8a4f657cf3d4fb00571a23e9562.png)'
  prefs: []
  type: TYPE_IMG
- en: Python notebook scheduled in the cloud, generated by MidJourney, instructed
    by the author
  prefs: []
  type: TYPE_NORMAL
- en: However, the most commonly used approach (unless you’re using a cloud-native
    services like Vertex AI or SageMaker) is to convert notebooks to Python code using
    `nbconvert` and adding the code to a freshly bootstrapped Tornado or Flask custom
    web application.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7ad9ec48534503b421be4057882796a1.png)'
  prefs: []
  type: TYPE_IMG
- en: Traditional containerization of a Python Notebook without, image by the author
  prefs: []
  type: TYPE_NORMAL
- en: This includes some coding and external libraries, but the good news is that
    we can leave our code in our Jupyter development container and trigger it directly
    from there using the [Jupyter Rest API](https://jupyter-server.readthedocs.io/en/latest/developers/rest-api.html).
  prefs: []
  type: TYPE_NORMAL
- en: Accessing a Notebook over Web API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we jump into the details of how to use Jupyter API, I’ll demonstrate
    how the architecture will work. First, let’s take a simple notebook we can use
    for testing.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/dcf053ff6404f88f5756605f5377177e.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Simple test notebook](https://github.com/tfoldi/jupyterapi_nbrunner/blob/main/tests/test_notebook/JupyterAPI_Test.ipynb)
    returning with “15" if all works well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To run it locally using Jupyter, the easiest way is to run it in a Jupyter
    Lab container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Once the service starts, you’ll be able to access the notebook at [http://127.0.0.1:8888/lab/tree/work](http://127.0.0.1:8888/lab/tree/work)
    using the token passed in the JUPYTER_TOKEN environment variable.
  prefs: []
  type: TYPE_NORMAL
- en: Calling the Notebook from the command line
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From the command line, you can download [this](https://github.com/tfoldi/jupyterapi_nbrunner/blob/main/main.py)
    small script (it requires `requests` and `websocket-client` packages) or run it
    through a Docker container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This script connects to our newly created JupyterLab server, executes our notebook,
    returns the last cell’s result, then exits. The entire procedure occurs over web
    protocols without requiring any modifications to the notebook code or additional
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Under the hood
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unfortunately, there’s no single endpoint in Jupyter API to execute a notebook
    end-to-end. First, we have to initialize a new kernel (or use an existing one),
    retrieve the notebook metadata, get all code cells and send an `execute_request`
    for each one of them.
  prefs: []
  type: TYPE_NORMAL
- en: To retrieve the results, we need to listen for incoming messages in the WebSocket
    channel. Since there’s no “end of all code executions” message, we have to manually
    keep track of how many code blocks we sent for execution and how many of them
    have actually been completed by counting all messages of type `execute_reply`.
    Once everything has finished executing, we can stop the kernel or leave it in
    an idle stage for future executions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the complete flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/11c524c1045884750fb7a48d56e4dacf.png)'
  prefs: []
  type: TYPE_IMG
- en: Steps to execute a Jupyter Notebook over the Rest API. Notebook-level actions
    use Rest API, while cell-level invocations are on WebSockets. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: To remain authenticated, we have to pass the `Authorization` header for all
    HTTP and WebSocket calls.
  prefs: []
  type: TYPE_NORMAL
- en: If this feels like a somewhat excessive amount of steps just to execute a notebook,
    I hear you. I’m sure it would be useful to implement a higher-level function inside
    Jupyter Server to reduce the complexity.
  prefs: []
  type: TYPE_NORMAL
- en: The complete [script is here](https://github.com/tfoldi/jupyterapi_nbrunner/blob/main/main.py),
    ready to be used in your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Schedule our workbook on GCP for Free (almost)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While there are many options for hosting a notebook, the most cost-effective
    way is to leverage Google Cloud’s Cloud Run service. With Cloud Run, you only
    pay for the exact runtime of your job, making it a cost-efficient choice for infrequently
    triggered tasks without extra packages or additional SaaS vendors (other than
    Google) — and, again, without writing a single line of code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture and invocation flow will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/431947b505e850f4b423574ed62ab90b.png)'
  prefs: []
  type: TYPE_IMG
- en: We’re going to use serverless services only to keep the costs down. Image by
    the author.
  prefs: []
  type: TYPE_NORMAL
- en: First, we have to deploy our notebook in GCP Cloud Run. There are multiple ways
    to add a file to a Cloud Run service, but perhaps the easiest one is to copy our
    notebooks to a Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: To build and make the container available in Cloud Run, we can simply specify
    the `--source` option with `gcloud run deploy`, pointing it to a directory where
    our notebooks and `Dockerfile` are located.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: JupyterLab will be available at the Service URL. Google Cloud Run will provide
    the SSL certificates and the mechanisms to start or suspend the container depending
    on requests hitting the deployment.
  prefs: []
  type: TYPE_NORMAL
- en: To trigger our newly deployed notebook from the Cloud Scheduler, we have to
    create a Cloud Function tied to a PubSub topic. The following command will deploy
    `main.py` and `requirements.txt` from [this repository](https://github.com/tfoldi/jupyterapi_nbrunner/).
    The `main.py` is the same script we used previously to trigger our code from the
    command line.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s test our new Cloud Function by sending a message to the `t_nbtrigger`
    topic with the appropriate parameters, just like we did in the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If you check the `nbtrigger` Cloud Function’s logs, you may notice that emitting
    a record to the topic successfully triggered the execution of the notebook we
    specified:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/471606b8c7c1dfcc3bca2028c26c355b.png)'
  prefs: []
  type: TYPE_IMG
- en: The logs show the successful execution of our notebook. Image by the author.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final step is to create a schedule that runs at specified times. In this
    case, we are about to run our notebook every hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: You’re all set — you just scheduled your first Jupyter Notebook in a serverless
    way.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/579099583726993d1558e9d706617887.png)'
  prefs: []
  type: TYPE_IMG
- en: CloudRun automatically shuts down our container after the job execution. The
    “idle” state is also free of charge in case we do not specify min-instances.
  prefs: []
  type: TYPE_NORMAL
- en: Our Notebook will consume only a few cents per day, making this deployment method
    one of the most cost-effective in Google Cloud.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/69712ebc972347c1dc3f9f582dc4b078.png)'
  prefs: []
  type: TYPE_IMG
- en: After few days of execution the costs are around three cents.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We used to rely on converting our Jupyter Notebooks to Python code to make them
    available to cloud-native tools, or on more complex and expensive services like
    Vertex AI or SageMaker. However, by utilizing the Jupyter Rest API and deploying
    your Notebooks along with its “development environment,” you can skip the extra
    steps and enable web service calls or scheduling for your Notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: While this approach is not necessarily appropriate for large-scale projects
    with compute-heavy long-running notebooks, it is perfectly fine for your home
    automation or hobby projects — without (over)spending on infrastructure.
  prefs: []
  type: TYPE_NORMAL
