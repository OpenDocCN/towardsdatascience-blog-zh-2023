- en: 'RecList 2.0: Open-Source Systematic Testing of ML Models'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/reclist-2-0-open-source-systematic-testing-of-ml-models-9c62b654170c?source=collection_archive---------9-----------------------#2023-08-08](https://towardsdatascience.com/reclist-2-0-open-source-systematic-testing-of-ml-models-9c62b654170c?source=collection_archive---------9-----------------------#2023-08-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A new RecList to provide more flexibility and better support for evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://fede-bianchi.medium.com/?source=post_page-----9c62b654170c--------------------------------)[![Federico
    Bianchi](../Images/fa38ff2051af04df7803af7d84c5cd4d.png)](https://fede-bianchi.medium.com/?source=post_page-----9c62b654170c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----9c62b654170c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----9c62b654170c--------------------------------)
    [Federico Bianchi](https://fede-bianchi.medium.com/?source=post_page-----9c62b654170c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F2aff872fe60e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freclist-2-0-open-source-systematic-testing-of-ml-models-9c62b654170c&user=Federico+Bianchi&userId=2aff872fe60e&source=post_page-2aff872fe60e----9c62b654170c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----9c62b654170c--------------------------------)
    ·7 min read·Aug 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9c62b654170c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freclist-2-0-open-source-systematic-testing-of-ml-models-9c62b654170c&user=Federico+Bianchi&userId=2aff872fe60e&source=-----9c62b654170c---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9c62b654170c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Freclist-2-0-open-source-systematic-testing-of-ml-models-9c62b654170c&source=-----9c62b654170c---------------------bookmark_footer-----------)![](../Images/d17b7a68ebe3a9dc2e4940a8b7867ef1.png)'
  prefs: []
  type: TYPE_NORMAL
- en: '[Photo by Lucas Pezeta](https://www.pexels.com/photo/black-telescope-under-blue-and-blacksky-2034892/)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Evaluation is a complex matter. It is often hard to manage the different components
    that are involved in writing evaluation pipelines, you have your model somewhere,
    you need to load it, then get the test, then run the tests, and so on and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: And then? well, you have to save results somewhere and maybe log outputs online
    so you can keep track of them.
  prefs: []
  type: TYPE_NORMAL
- en: As this is always a hard procedure, we recently tried to provide a more structured
    way to do testing. In this blog post, we introduce and show how to use [RecList](https://github.com/RecList/reclist)
    beta, our open-source package for evaluation; RecList is a general plug-and-play
    approach to scale-up testing, with an easy-to-extend interface for custom use
    cases. RecList is an open-source project freely available on [GitHub](https://github.com/RecList/reclist).
  prefs: []
  type: TYPE_NORMAL
- en: Reclist allows you to separate the evaluation portion of your code and encapsulate
    it in a class that handles several other things (e.g., storage and logging) automatically
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e3548430dfd118198443b185c1249228.png)'
  prefs: []
  type: TYPE_IMG
- en: Reclist offers a simple way to systematize testing and save all the information
    you need after you trained your own model.
  prefs: []
  type: TYPE_NORMAL
- en: We started working on RecList a couple of years ago and the alpha version of
    RecList came out a bit more than a year ago. Since then, RecList has collected
    over 400 GitHub stars.
  prefs: []
  type: TYPE_NORMAL
- en: We have used RecList and stress-tested it to run a RecSys challenge at CIKM
    in 2022 and currently preparing for an upcoming one at KDD 2023\. RecList allowed
    us to systematize the evaluation for all the participants. The idea is that, once
    everybody is provided with the same RecList, comparing different evaluations becomes
    easy. A summary of our experience appears in our [Nature Machine Intelligence](https://www.nature.com/articles/s42256-022-00606-0)
    comment piece.
  prefs: []
  type: TYPE_NORMAL
- en: 'RecList was originally introduced in an academic paper, but we also had a general
    overview that was presented in a Towards Data Science publication you can read
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](/ndcg-is-not-all-you-need-24eb6d2f1227?source=post_page-----9c62b654170c--------------------------------)
    [## NDCG Is Not All You Need'
  prefs: []
  type: TYPE_NORMAL
- en: Behavioral testing for recSys with RecList
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: towardsdatascience.com](/ndcg-is-not-all-you-need-24eb6d2f1227?source=post_page-----9c62b654170c--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'Chia, P. J., Tagliabue, J., Bianchi, F., He, C., & Ko, B. (2022, April). Beyond
    nDCG: Behavioral Testing of Recommender Systems with Reclist. In *Companion Proceedings
    of the Web Conference 2022* (pp. 99–104).'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While we originally designed RecList for recommender system testing, nothing
    prevents using RecList for testing other machine learning models. So, why there
    is a new blog post? well, after developing the first version we realized it needed
    some updates.
  prefs: []
  type: TYPE_NORMAL
- en: 'What Did We Learn: Rethinking an API'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is often only after you build something that you realize how to improve it.
  prefs: []
  type: TYPE_NORMAL
- en: For those that used RecList 1.0, we have made major updates to the RecList API.
    Originally, we had harder constraints on code structure and input/output pairs.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, when we implemented Reclist we intended to provide a more general API
    for the evaluation of Recommender Systems that offered several out-of-the-box
    functionalities. However, to do this we had to create several abstract interfaces
    that users had to implement.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the **original Reclist 1.0** required users to wrap their own models
    and dataset into pre-defined abstract classes (i.e., RecModel and RecDataset).
    This allowed us to implement a common set of behaviors that were connected by
    these abstractions. However, we soon realized that this might often complicate
    flows and requires a lot of additional work that some people might not like.
  prefs: []
  type: TYPE_NORMAL
- en: 'In **RecList 2.0** we decided to make these constraints optional: we made testing
    much more flexible. Users define their own evaluation use case, wrap it around
    a handy decorator, and they get metadata storage and logging already implemented.
    Users can then share the test interface with other people and they can run your
    very same experiments.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary of this**: we realized how important flexibility is when we build
    software that other people have to use.'
  prefs: []
  type: TYPE_NORMAL
- en: RecList 2.0 In Action
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s explore a simple use case on how to use RecList to write and run
    an evaluation pipeline. We are going to use very simple models that output numbers
    at random to reduce the complexity that is involved in making a machine learning
    project.
  prefs: []
  type: TYPE_NORMAL
- en: A Simple Use Case
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s create a very simple use case with a very simple dataset. Let’s assume
    we have a target sequence of integers, each with an associated category. We are
    simply going to generate some random data.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Our very simple dataset should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: A Simple Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s now assume we have a DummyModel that outputs integers at random. Of course,
    as we said, this is not a “good” model, but it’s a good abstraction we can use
    to see an entire evaluation pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Now, how do we run evaluations?
  prefs: []
  type: TYPE_NORMAL
- en: A Simple RecList
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A RecList is a Python class that inherits functionalities from our RecList abstract
    class. RecList implements RecTests, simple abstractions that allow you to systematize
    evaluation. For example, this could be a possible accuracy test.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We are taking sklearn accuracy metric and wrapping it in another method. What
    makes this different from a simple accuracy function? well, the decorator allows
    us to bring over some additional features: for example, the rectest will **now
    automatically store information in a local folder**. Also, defining a type of
    chart **allows us to create some visualizations for these results.**'
  prefs: []
  type: TYPE_NORMAL
- en: What if we wanted a more sophisticated test? For example, what if we want to
    see how stable is our accuracy across the different categories (e.g., is the accuracy
    computed on red objects higher than for yellow objects?)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let’s now look at an example of a complete RecList!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Few lines of code are needed to put all we need in one single place. We can
    reuse this piece of code for new models, or add tests and re-run past models.
  prefs: []
  type: TYPE_NORMAL
- en: As long as your metrics return some values, you can implement them in any way
    you like. For example, this BasicRecList evaluates a specific model in a specific
    context. But nothing prevents you from generating more model-specific reclists
    (e.g., GPT-RecList) or dataset-specific reclists (e.g., IMDB-Reclist). If you
    want to see an example of a deep model on RecList, you can [check out this colab](https://colab.research.google.com/drive/1Ftl2B7BVFMfFjyjWweFCP_gA_LdCl7-a?usp=sharing).
  prefs: []
  type: TYPE_NORMAL
- en: Running and Getting The Outputs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s run the RecList. We need our target data, the metadata, and the predictions.
    We can also specify a logger and a metadata store.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'What’s the output of this procedure? What we are going to see in our command
    line is the following set of results: for each test, we have an actual score.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e654f565771e8e18b5cbe8a9e7ee25e5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The metrics are also automatically plotted. For example, the AccuracyByCountry
    should show something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/356054d8c1e7af98c49ace17f2c82382.png)'
  prefs: []
  type: TYPE_IMG
- en: Example of plot generated by a RecTest.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to this, RecList saves a JSON file that contains all the information
    from the experiments we have just run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The nice thing is that with a few lines of additional code, most of the logging
    is taken care of for us!
  prefs: []
  type: TYPE_NORMAL
- en: Using Online Loggers and Metadata Storages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By default, the RecList runner is going to use the following logger and metadata
    setup.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: However, nothing prevents us from using online and cloud solutions. For example,
    we wrap around both CometML and Neptune APIs so that you can directly use them
    in your evaluation pipeline. We also offer support for S3 data storage.
  prefs: []
  type: TYPE_NORMAL
- en: For example, adding a couple of parameters to the BasicReclist will allow us
    to log information on [Neptune](https://www.loom.com/share/e2db2a15d77741f08fc84e2284bed8e2?sid=83290789-98d3-4d3e-9271-2f8e91d980e9)
    (we offer similar support for [Comet.ml](https://www.loom.com/share/870d1b256a0e4bd18b98f5f7c9a78759?sid=3161eb5b-5ab1-4863-ba50-373757d5e0cc))!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In a very similar way, adding the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: will allow us to use an S3 Bucket to store metadata (of course, you will need
    to set some environment keys even for this).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That’s all! We have created RecList to make the evaluation in Recommender Systems
    more systematic and organized. We hope this large API refactoring can help people
    build more reliable evaluation pipelines!
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Between June and December 2022, the development of our beta has been supported
    by the awesome folks at Comet, Neptune, Gantry, and developed with the help of
    Unnati Patel.
  prefs: []
  type: TYPE_NORMAL
