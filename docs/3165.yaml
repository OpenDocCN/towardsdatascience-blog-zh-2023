- en: Building a Batch Data Pipeline with Athena and MySQL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŽŸæ–‡ï¼š[https://towardsdatascience.com/building-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c?source=collection_archive---------6-----------------------#2023-10-20](https://towardsdatascience.com/building-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c?source=collection_archive---------6-----------------------#2023-10-20)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: An End-To-End Tutorial for Beginners
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)[![ðŸ’¡Mike
    Shakhomirov](../Images/bc6895c7face3244d488feb97ba0f68e.png)](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)
    [ðŸ’¡Mike Shakhomirov](https://mshakhomirov.medium.com/?source=post_page-----7e60575ff39c--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fe06a48b3dd48&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=post_page-e06a48b3dd48----7e60575ff39c---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----7e60575ff39c--------------------------------)
    Â·16 min readÂ·Oct 20, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7e60575ff39c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&user=%F0%9F%92%A1Mike+Shakhomirov&userId=e06a48b3dd48&source=-----7e60575ff39c---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7e60575ff39c&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbuilding-a-batch-data-pipeline-with-athena-and-mysql-7e60575ff39c&source=-----7e60575ff39c---------------------bookmark_footer-----------)![](../Images/368293b91e4bc0283007a555789b6479.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Redd F](https://unsplash.com/@raddfilms?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: In this story I will speak about one of the most popular ways to run data transformation
    tasks â€” batch data processing. This data pipeline design pattern becomes incredibly
    useful when we need to process data in chunks making it very efficient for ETL
    jobs that require scheduling. I will demonstrate how it can be achieved by building
    a data transformation pipeline using MySQL and Athena. We will use infrastructure
    as code to deploy it in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that you have just joined a company as a Data Engineer. Their data stack
    is modern, event-driven, cost-effective, flexible, and can scale easily to meet
    the growing data resources you have. External data sources and data pipelines
    in your data platform are managed by the data engineering team using a flexible
    environment setup with CI/CD GitHub integration.
  prefs: []
  type: TYPE_NORMAL
- en: As a data engineer you need to create a business intelligence dashboard that
    displays the geography of company revenue streams as shown below. Raw payment
    data is stored in the server database (MySQL). You want to build a batch pipeline
    that extracts data from that database daily, then use AWS S3 to store data files
    and Athena to process it.
  prefs: []
  type: TYPE_NORMAL
