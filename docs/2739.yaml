- en: Regression and Bayesian Methods in Modern Preference Elicitation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/regression-and-bayesian-methods-in-modern-preference-elicitation-39a21435898d?source=collection_archive---------5-----------------------#2023-08-29](https://towardsdatascience.com/regression-and-bayesian-methods-in-modern-preference-elicitation-39a21435898d?source=collection_archive---------5-----------------------#2023-08-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Application to simple smoothie-making
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://ouaguenouni-hachemi.medium.com/?source=post_page-----39a21435898d--------------------------------)[![Ouaguenouni
    Mohamed](../Images/6822685015770dab0431b3a1d5966d6c.png)](https://ouaguenouni-hachemi.medium.com/?source=post_page-----39a21435898d--------------------------------)[](https://towardsdatascience.com/?source=post_page-----39a21435898d--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----39a21435898d--------------------------------)
    [Ouaguenouni Mohamed](https://ouaguenouni-hachemi.medium.com/?source=post_page-----39a21435898d--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F6c5dbf6956c8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregression-and-bayesian-methods-in-modern-preference-elicitation-39a21435898d&user=Ouaguenouni+Mohamed&userId=6c5dbf6956c8&source=post_page-6c5dbf6956c8----39a21435898d---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----39a21435898d--------------------------------)
    ·14 min read·Aug 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F39a21435898d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregression-and-bayesian-methods-in-modern-preference-elicitation-39a21435898d&user=Ouaguenouni+Mohamed&userId=6c5dbf6956c8&source=-----39a21435898d---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F39a21435898d&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fregression-and-bayesian-methods-in-modern-preference-elicitation-39a21435898d&source=-----39a21435898d---------------------bookmark_footer-----------)![](../Images/8639022815e07b35f4283dd0b0b115b8.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Denis Tuksar](https://unsplash.com/@dtuksar?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression is often considered the workhorse of predictive modeling,
    yet its application extends beyond straightforward predictive tasks. This article
    seeks to enrich the dialogue around regression techniques by introducing Probit
    Linear Regression as an effective tool for modeling preferences. Furthermore,
    we employ a Bayesian framework to transition from classical to Bayesian Linear
    Regression, elucidating the intrinsic relationship between cost-based optimization
    — specifically Binary Cross-Entropy (BCE) loss minimization — and maximum likelihood
    estimation.
  prefs: []
  type: TYPE_NORMAL
- en: In doing so, we aim to demonstrate that regularization can be considered a form
    of Bayesian prior selection, thereby bridging cost function approaches with probabilistic
    reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will discuss how Bayesian Linear Regression allows not only for
    point estimates but also provides a distribution over these predictions, offering
    a richer, uncertainty-aware perspective.
  prefs: []
  type: TYPE_NORMAL
- en: The Bayesian Framework
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Bayes Framework identifies two principal components: the data *D* and the
    model *w*. By specifying the likelihood *P*(*D*∣*w*) and a prior over the model
    *P*(*w*), we aim to find the model that maximizes the posterior *P*(*w*∣*D*),
    derived via Bayes’ theorem as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5f43fcae2575abf52b8ad9bf08e67ebc.png)'
  prefs: []
  type: TYPE_IMG
- en: In preference learning, having a distribution over *w* offers the advantage
    of capturing the uncertainty inherent in human preferences, thereby providing
    not just a single ‘best guess’ but a range of plausible models.
  prefs: []
  type: TYPE_NORMAL
- en: The Preference Elicitation Problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Preference Elicitation is a key component in decision theory, aimed at identifying
    a decision-maker’s choices based on available data. In this study, we tackle the
    Preference Elicitation Problem by fitting a model to a partial set of preferences.
    In our case, preferences are expressed in their most straightforward form: pairwise
    comparisons. To illustrate this concept, consider a set of fruits, denoted by
    *F*, including apple, banana, orange, litchi, and mango.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/74260e1eca490358d745b0aa582aee8c.png)'
  prefs: []
  type: TYPE_IMG
- en: In our context, the alternative set *A* consists of all possible smoothies that
    can be created using one or multiple ingredients from set *F*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1c0579c5f141ddaf41b9a25c24a6fcb6.png)'
  prefs: []
  type: TYPE_IMG
- en: The user articulates their preferences through a set of ordered pairs (*A*,*B*),
    where *A* is strictly preferred over *B*.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b57a0e52cff1b056c31178b57c96cac0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The subsequent section of this article will introduce the family of functions
    specifically chosen to capture user preferences: additive functions. These mathematical
    constructs provide a straightforward yet robust framework for understanding how
    different factors contribute to an individual’s preferences, thereby enabling
    effective modeling of the choices expressed through pairwise comparisons.'
  prefs: []
  type: TYPE_NORMAL
- en: Additive Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Linear Additive Model is the most straightforward model that could be used
    to capture the preferences of the user.
  prefs: []
  type: TYPE_NORMAL
- en: The additive linear model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An additive utility model is one that assigns a specific weight to each individual
    ingredient in our set. The overall utility or ‘likability’ of a smoothie is then
    calculated by summing up the weights of its constituent ingredients. Formally,
    given a vector of weights
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/21fc22fe58a5d138c9d123bd46f0983d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The utility of a smoothie made from a subset A of ingredients is:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e18598ce3522be9380edfceb69962c02.png)'
  prefs: []
  type: TYPE_IMG
- en: Where I is the identity function that tests whether I am in A or not.
  prefs: []
  type: TYPE_NORMAL
- en: The additive model with binary interactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The 2-additive model builds upon the 1-additive model by introducing an additional
    layer of complexity. Not only does the weight vector contain a weight for each
    individual ingredient, but it also includes weights for every possible pair of
    ingredients. This allows the model to capture synergies between pairs of fruits,
    effectively recognizing how the combination of two ingredients can influence the
    overall utility. Formally, the weight vector **w** is extended to include weights
    ​ for each pair (*i*,*j*) in addition to the singletons:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ce533d540397c61288f99ba8dedce633.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And with the 2-additive linear model, the utility of a smoothie is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9b83e08e3fe84756efb6d279b39bcae8.png)'
  prefs: []
  type: TYPE_IMG
- en: Where F² is the set of singletons and pairs.
  prefs: []
  type: TYPE_NORMAL
- en: The n-additive model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Extending the concept even further, the *n*-additive model offers a highly flexible
    utility framework. In this model, the weight vector not only accounts for individual
    ingredients and pairs but also extends to include weights for any subset of up
    to *n* ingredients. This generalization allows the model to capture intricate
    relationships and synergies among multiple ingredients simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Formally, the weight vector **w** is expanded to include weights for all possible
    combinations of up to *n* ingredients:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/305e7329be95fe3b1f639b3688a6400a.png)'
  prefs: []
  type: TYPE_IMG
- en: This *n*-additive model can capture the full range of interactions among ingredients,
    making it an extremely powerful tool for understanding complex preference structures.
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of this analysis, we will restrict ourselves to 2-additive
    models, as we believe that the complexity of the preference relationships among
    ingredients is unlikely to exceed pairwise interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Learning the preferences by solving a Probit Regression problem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While traditional regression models output real-valued predictions, our goal
    is to predict a binary preference relation.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this, we modify our regression model to output the probability that
    option *A* is preferred over option *B*. We then derive an appropriate cost function
    to effectively fit this probabilistic model to our data.
  prefs: []
  type: TYPE_NORMAL
- en: One classic way to squash a value between 0 and 1 is to use the Probit function.
    The Probit function is defined as follows
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fcae2b379eefb68d8fea18dcc54d0664.png)'
  prefs: []
  type: TYPE_IMG
- en: The following figure illustrates its shape
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a13fa996771b732d3bc51385e2cdc94e.png)'
  prefs: []
  type: TYPE_IMG
- en: Shape of the probit function (by me)
  prefs: []
  type: TYPE_NORMAL
- en: By applying this function to the difference between *f*(*A*) and *f*(*B*), our
    model will yield a probability approaching 1 if *f*(*A*) significantly exceeds
    *f*(*B*). Conversely, it will produce a probability near 0.5 if *f*(*A*) is approximately
    equal to *f*(*B*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the preference elicitation problem can be rephrased as the search for
    an optimal weight vector **w** such that:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0dfd4428cdcfb41d29681cd670834fc5.png)'
  prefs: []
  type: TYPE_IMG
- en: Binary Cross-Entropy (BCE) loss
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Binary Cross-Entropy (BCE) loss, also known as log loss, serves as a performance
    metric for classification models that output probabilities ranging from 0 to 1,
    typically used in binary classification tasks. Mathematically, given the true
    labels *y* (either 0 or 1) and the predicted probabilities *p*, the BCE is defined
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/027d438930246ef9cf3446ce9917c43e.png)'
  prefs: []
  type: TYPE_IMG
- en: Toy Data Generation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To validate our methods, we introduce a protocol for generating synthetic data.
  prefs: []
  type: TYPE_NORMAL
- en: The process begins by randomly sampling a weight vector **w**. We then set some
    of its parameters to zero, To introduce a layer of realism and simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: Operating under the assumption that the user’s preferences align with this sampled
    function, we can employ it as a benchmark to assess the accuracy of our predictive
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Then we encode each alternative with a binary vector where the components are
    in the same order as in the model parameters using the following function
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Then to evaluate a particular smoothie we use a product
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'To construct our dataset, we begin by sampling a weight vector **w**. Next,
    we generate a set of smoothies and evaluate each based on the sampled weights.
    For every pair of smoothies *A* and *B* where *f*(*A*)>*f*(*B*), we add a corresponding
    preference to our dataset. Each preference between *A* and *B* is captured in
    a vector, defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e8d20cd5c9aecac92c1c327ee473704.png)'
  prefs: []
  type: TYPE_IMG
- en: For each pair A,B where f(A) > f(B) we add two rows v(A,B) and v(B,A) the first
    labelled with the class 1 and the second with the class 0.
  prefs: []
  type: TYPE_NORMAL
- en: The following code gives us a dataset on n smoothies.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The cost-based resolution
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way of solving the problem is by using the convexity of the BCE loss and
    a library such as Torch.
  prefs: []
  type: TYPE_NORMAL
- en: We start by wrapping the generated data into the proper Dataset Loaders provided
    by PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Now, we create a simple linear model
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: And we train it using the autograd functionalities of PyTorch.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Then we test the obtained model using the test dataset
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: With 20% of the data used for the training, we obtained about 98.32% of accuracy
    which is not bad at all.
  prefs: []
  type: TYPE_NORMAL
- en: The Maximum Likelihood Estimation (MLE)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An alternative method for addressing the probit regression challenge involves
    explicitly formulating the likelihood of the data given a weight vector **w**.
  prefs: []
  type: TYPE_NORMAL
- en: 'We begin by assuming that the model produces a probability *p* indicating that
    *A* is preferred over *B*. The predictive distribution for this scenario is expressed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/23ccb46867f2bc8314928beb7fd9b1a9.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The likelihood of a pair (x,y) given a vector of weights is then expressed
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e924f0a3ab9ac63c7d930e15ae326bd6.png)'
  prefs: []
  type: TYPE_IMG
- en: The probability of the dataset is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/804943e3f83db3d19887710ae7eec446.png)'
  prefs: []
  type: TYPE_IMG
- en: Likelihood values can be extremely small, significant when multiplying many
    probabilities together. This can lead to numerical underflow (where very small
    floating-point numbers are rounded to zero). Taking the logarithm of these values
    turns them into more manageable numbers, which are typically negative and of a
    larger magnitude.
  prefs: []
  type: TYPE_NORMAL
- en: The log-likelihood is thus given by
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/52ce1997d47fa44457be3f2dcd6dad75.png)'
  prefs: []
  type: TYPE_IMG
- en: You will probably notice that this loss is the negative of the BCE loss, and
    this is why **maximizing the likelihood is equivalent to minimizing the BCE loss**.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/45e183df60348ae43c630c5651400e9f.png)'
  prefs: []
  type: TYPE_IMG
- en: Regularization Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regularization is a key technique in machine learning to combat overfitting,
    where a model excessively adapts to training data, including its noise, impairing
    its performance on new data. It works by adding penalty terms to the loss to limit
    the complexity of model parameters. This promotes simpler models, striking a balance
    between fitting the training data and maintaining model simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: L1 (Lasso) and L2 (Ridge) are common regularization forms, each introducing
    unique penalty terms to the model’s objective.
  prefs: []
  type: TYPE_NORMAL
- en: L1 adds a penalty based on the absolute value of parameters, leading to sparse
    models with some weights being zero.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/76763393d01134971157fc90f5212933.png)'
  prefs: []
  type: TYPE_IMG
- en: In contrast, L2 penalizes the square magnitude of parameters, shrinking weights
    without making them zero.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b476b58e4cca61245fcdc0709798d67b.png)'
  prefs: []
  type: TYPE_IMG
- en: L1 (Lasso) and L2 (Ridge) regularization techniques differentiate in how they
    penalize model parameters. L1 applies a penalty proportional to the absolute values,
    leading to some weights being entirely zero, facilitating feature selection. In
    contrast, L2 penalizes the squared magnitudes of the weights, ensuring they remain
    small but generally non-zero, preserving all features with reduced impact.
  prefs: []
  type: TYPE_NORMAL
- en: Maximum a Posteriori
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As previously mentioned, Bayes’ Theorem allows us to estimate the posterior
    distribution of model parameters, denoted as *P*(*w*∣*X*,*y*), by leveraging the
    likelihood function and a chosen prior distribution *P*(*w*) for the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, the prior encapsulates our initial beliefs or assumptions about
    the parameters before observing any data, while the likelihood quantifies how
    well the parameters explain the observed data. Bayes’ Theorem combines these elements
    to produce a posterior distribution that represents our updated belief about the
    parameters, given both the prior and the data.
  prefs: []
  type: TYPE_NORMAL
- en: Two very known priors are the **Laplace** and the **Gaussian** priors.
  prefs: []
  type: TYPE_NORMAL
- en: The Laplace prior operates under the assumption that the weights *w* are drawn
    from a Laplace distribution with location parameter *μ*=0 and scale parameter
    b.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, it presumes that the distribution of the weights centres around
    zero and decays exponentially as values deviate from this central point, reflecting
    a preference for sparser models in which many weights may be set to zero.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d632ecc933faf53bb432d57995966040.png)'
  prefs: []
  type: TYPE_IMG
- en: The Gaussian prior operates under the assumption that the weights *w* are drawn
    from a Gaussian (or Normal) distribution with mean *μ*=0 and variance *σ*.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, it supposes that the distribution of the weights is symmetrically
    centred around zero, with a bell-shaped profile indicating that weights are most
    likely to be close to the mean, tapering off less likely values as you move further
    away. This leads to a preference for models where weights are smoothly regularized,
    ensuring they remain small in magnitude without necessarily driving any to be
    exactly zero.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f2c691ea0da96e69368763c9486776d6.png)'
  prefs: []
  type: TYPE_IMG
- en: The log-posterior is given by
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db75cc9ca9533ce3a5c3318adfd7c51d.png)'
  prefs: []
  type: TYPE_IMG
- en: By optimizing our model, we find that maximizing the log posterior is fundamentally
    equivalent to minimizing a specific regularized loss.
  prefs: []
  type: TYPE_NORMAL
- en: Notably, the distinction between L1 and L2 regularization rests upon the chosen
    form of prior distribution considered.
  prefs: []
  type: TYPE_NORMAL
- en: Using the posterior in an MCMC method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a Bayesian framework, everything is treated probabilistically. So, instead
    of estimating fixed values for regression coefficients as in classical linear
    regression, Bayesian Linear Regression estimates a distribution over possible
    coefficient values.
  prefs: []
  type: TYPE_NORMAL
- en: One way of using the posterior distribution is by sampling a set of weights
    from the distribution P(w|X,y).
  prefs: []
  type: TYPE_NORMAL
- en: A simple way to do so is by using an MCMC method, the starting point to understand
    an MCMC method is the Metropolis-Hasting Approach.
  prefs: []
  type: TYPE_NORMAL
- en: Metropolis Hasting Approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Metropolis-Hastings (M-H) algorithm is a method in Bayesian statistics to
    sample from complex probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: It uses a simpler “proposal distribution” to explore a target distribution,
    accepting or rejecting samples based on a calculated probability. Notably, the
    M-H algorithm doesn’t require knowledge of the exact target distribution; having
    a distribution proportional to it is sufficient.
  prefs: []
  type: TYPE_NORMAL
- en: We will not use it because other approaches are more reliable and efficient
    but we will still briefly explain how it works because M-H algorithm is a foundational
    MCMC method.
  prefs: []
  type: TYPE_NORMAL
- en: Choose an initial guess
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set a proposal distribution, typically a Gaussian centred at the current value
    w.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9265da9a9f6ac979a19e30e9f9ecb60f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Then for each iteration, we proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Sample a new w’ from the proposal distribution P(w’|w).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute the acceptance probability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/9ab0d6bd9ab8ca5f1c614708db06bece.png)'
  prefs: []
  type: TYPE_IMG
- en: Draw a random number u from a uniform distribution over [0,1]. If u ≤ α, accept
    w’ as the new sample; otherwise, retain w.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NUTS Sampler and pyMC3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Metropolis-Hastings approach involves proposing a new point in the parameter
    space, and then deciding whether to accept this new point based on a comparison
    of its likelihood to the current point’s likelihood. Its efficiency depends heavily
    on the choice of proposal distribution, and it can suffer from random-walk behaviour
    in high-dimensional spaces, leading to slow convergence.
  prefs: []
  type: TYPE_NORMAL
- en: NUTS (No-U-Turn Sampler) is an extension of the Hamiltonian Monte Carlo (HMC)
    method. Instead of a random walk, NUTS utilizes gradient information from the
    target distribution to propose leapfrog steps, allowing it to traverse the distribution
    more efficiently. One of its main advantages is that it automatically determines
    the optimal number of leapfrog steps, thus avoiding the random walk problem and
    the tedious task of tuning this manually.
  prefs: []
  type: TYPE_NORMAL
- en: PyMC3 is a popular probabilistic programming framework that seamlessly integrates
    both these methods (and others), enabling users to fit complex Bayesian models
    with ease, without getting bogged down in the intricacies of the underlying algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, this code will sample a sequence of weights from the posterior
    distribution P(w|X,y).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: We can plot the different distributions of each weight.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c37c83543b2bfc866c8893597140c185.png)'
  prefs: []
  type: TYPE_IMG
- en: Distributions of the weights and their convergence plot (by me)
  prefs: []
  type: TYPE_NORMAL
- en: We see that each weight converges to a Gaussian distribution. And so now each
    prediction could be made probabilistically and the distribution of the predictions
    will also be a Gaussian.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the preferences of our fictive decider for an Orange smoothie,
    for an Orange-Apple smoothie, and for a Banana-Apple smoothie are given by the
    following Gaussians.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8e57ba69da7383b5f92e77e0e167f108.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the model that generated the data we can see that the ground truth utility
    of the three smoothies are respectively -0.66, -0.24 and 0.79 so the Gaussian
    actually reflects the preferences and the gap between them pretty well.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog post, we have journeyed from the intricacies of preference elicitation
    to the complexities of Bayesian linear regression models. Our discussion began
    with an exploration of 2-additive models, which serve as a realistic yet computationally
    tractable means of capturing user preferences. By transitioning from basic linear
    regression to more advanced probit models, we offered a new lens through which
    to understand preference data.
  prefs: []
  type: TYPE_NORMAL
- en: We also dove into the equivalence between a cost-based perspective and a probabilistic
    one, shedding light on how minimizing Binary Cross-Entropy loss is analogous to
    maximizing likelihood, and how regularization serves as the implicit selection
    of a prior.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we discussed the utility of a Bayesian framework in generating not just
    point estimates but entire predictive distributions. This approach lends a higher
    level of confidence and interpretability to our models, particularly useful in
    the nuanced task of preference learning.
  prefs: []
  type: TYPE_NORMAL
- en: With this groundwork laid, future research can delve deeper into the application
    of these sophisticated models to increasingly complex and large-scale preference
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Special thank to [Anissa Hacene](https://medium.com/u/7bb6c80751ad?source=post_page-----39a21435898d--------------------------------)
    my coworker/friend for her contribution in this work and to the TDS team for their
    prompt review and insightful remarks.
  prefs: []
  type: TYPE_NORMAL
