- en: Efficiently Serving Open Source LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/efficiently-serving-open-source-llms-5f0bf5d8fd59?source=collection_archive---------6-----------------------#2023-08-14](https://towardsdatascience.com/efficiently-serving-open-source-llms-5f0bf5d8fd59?source=collection_archive---------6-----------------------#2023-08-14)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ryanshrott?source=post_page-----5f0bf5d8fd59--------------------------------)[![Ryan
    Shrott](../Images/186524066383b4b02c994692aebb3ea5.png)](https://medium.com/@ryanshrott?source=post_page-----5f0bf5d8fd59--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5f0bf5d8fd59--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5f0bf5d8fd59--------------------------------)
    [Ryan Shrott](https://medium.com/@ryanshrott?source=post_page-----5f0bf5d8fd59--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Faba7ffb1d8f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficiently-serving-open-source-llms-5f0bf5d8fd59&user=Ryan+Shrott&userId=aba7ffb1d8f5&source=post_page-aba7ffb1d8f5----5f0bf5d8fd59---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5f0bf5d8fd59--------------------------------)
    ·5 min read·Aug 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5f0bf5d8fd59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficiently-serving-open-source-llms-5f0bf5d8fd59&user=Ryan+Shrott&userId=aba7ffb1d8f5&source=-----5f0bf5d8fd59---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5f0bf5d8fd59&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficiently-serving-open-source-llms-5f0bf5d8fd59&source=-----5f0bf5d8fd59---------------------bookmark_footer-----------)![](../Images/c16d4589aafa99416a26da8bff1b5afe.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Mariia Shalabaieva](https://unsplash.com/@maria_shalabaieva?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: 'This article explains my personal experiences using 6 common methods for serving
    open source LLMs: AWS Sage Maker, Hugging Face, Together.AI, VLLM and Petals.ml.'
  prefs: []
  type: TYPE_NORMAL
- en: The struggle…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You’ve felt the pain, struggle and glory of serving your own fine-tuned open
    source LLM, however, you ultimately decided to return to Open AI or Anthropic
    due to cost, inference time, reliability and technology challenges :( You’ve also
    given up on renting a A100 GPU (many providers have GPUs fully booked until the
    end of 2023!). And you don’t have 100K to shell out for a 2 tier A100 server box.
    Still, you’re dreaming, and you really want to get open source to work for your
    solution. Perhaps your firm does not want to send it’s private data to Open AI
    or you want a fine tuned model for a very specific task? In this article, I will
    outline and compare some of the most effective inference methods/platforms for
    serving open source LLMs in 2023\. I will compare and contrast 6 methods and explain
    when you should use one or the other. I have personally tried all 6 of these and
    will detail my personal experience with these solutions: **AWS Sage Maker, Hugging
    Face Inference endpoints, Together.AI, VLLM and Petals.ml**. I don’t have all
    the answers, but I will do my best to detail my experiences. I have no monetary
    connection with any of these providers and am simply sharing my…'
  prefs: []
  type: TYPE_NORMAL
