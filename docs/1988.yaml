- en: Data Modeling Techniques For Data Warehouse
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/data-modeling-techniques-for-data-warehouse-3edcb541e34e?source=collection_archive---------0-----------------------#2023-06-19](https://towardsdatascience.com/data-modeling-techniques-for-data-warehouse-3edcb541e34e?source=collection_archive---------0-----------------------#2023-06-19)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@mariusz_kujawski?source=post_page-----3edcb541e34e--------------------------------)[![Mariusz
    Kujawski](../Images/72a2dafb84cabfd54b0ef54a6689a001.png)](https://medium.com/@mariusz_kujawski?source=post_page-----3edcb541e34e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----3edcb541e34e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----3edcb541e34e--------------------------------)
    [Mariusz Kujawski](https://medium.com/@mariusz_kujawski?source=post_page-----3edcb541e34e--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fa60a4246b015&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-modeling-techniques-for-data-warehouse-3edcb541e34e&user=Mariusz+Kujawski&userId=a60a4246b015&source=post_page-a60a4246b015----3edcb541e34e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----3edcb541e34e--------------------------------)
    ·11 min read·Jun 19, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F3edcb541e34e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-modeling-techniques-for-data-warehouse-3edcb541e34e&user=Mariusz+Kujawski&userId=a60a4246b015&source=-----3edcb541e34e---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3edcb541e34e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdata-modeling-techniques-for-data-warehouse-3edcb541e34e&source=-----3edcb541e34e---------------------bookmark_footer-----------)![](../Images/bcd0e966ffefd7625453d48e696cd863.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Zdeněk Macháček](https://unsplash.com/@zmachacek?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
    on [Unsplash](https://unsplash.com/photos/silver-and-diamond-studded-cross-pendant-rGzUMs-QsCM?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash)
  prefs: []
  type: TYPE_NORMAL
- en: Data modeling is a process of creating a conceptual representation of the data
    and its relationships within an organization or system. Dimensional modeling is
    an advanced technique that attempts to present data in a way that is intuitive
    and understandable for any user. It also allows for high-performance access, flexibility,
    and scalability to accommodate changes in business needs.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, I will provide an in-depth overview of data modeling, with
    a specific focus on Kimball’s methodology. Additionally, I will introduce other
    techniques used to present data in a user-friendly and intuitive manner. One particularly
    interesting technique for modern data warehouses is storing data in one wide table,
    although this approach may not be suitable for all query engines. I will present
    techniques that can be used in Data Warehouses, Data Lakes, Data Lakehouses, etc.
    However, it is important to choose the appropriate methodology for your specific
    use case and query engine.
  prefs: []
  type: TYPE_NORMAL
- en: What is dimensional modeling?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every dimensional model consists of one or more tables with a multipart key,
    referred to as the fact table, along with a set of tables known as dimension tables.
    Each dimension table has a primary key that precisely corresponds to one of the
    components of the multipart key in the fact table. This distinct structure is
    commonly referred to as a star schema. In some cases, a more intricate structure
    called a snowflake schema can be used, where dimension tables are connected to
    smaller dimension tables
  prefs: []
  type: TYPE_NORMAL
- en: 'Benefits of dimensional modeling:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Dimensional modeling provides a practical and efficient approach to organizing
    and analyzing data, resulting in the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Simplicity and understandability for business users.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved query performance for faster data retrieval.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flexibility and scalability to adapt to changing business needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensured data consistency and integration across multiple sources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enhanced user adoption and self-service analytics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have discussed what dimensional modeling is and the value it brings
    to organizations, let’s explore how to effectively leverage it.
  prefs: []
  type: TYPE_NORMAL
- en: Data and dimensional modeling methodologies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While I intend to primarily focus on Kimball’s methodology, let’s briefly touch
    upon a few other popular techniques before diving into it.
  prefs: []
  type: TYPE_NORMAL
- en: Inmon methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Inmon suggests utilizing a normalized data model within the data warehouse.
    This methodology supports the creation of data marts. These data marts are smaller,
    specialized subsets of the data warehouse that cater to specific business areas
    or user groups. These are designed to provide a more tailored and efficient data
    access experience for particular business functions or departments.
  prefs: []
  type: TYPE_NORMAL
- en: Data vault
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data Vault is a modeling methodology that focuses on scalability, flexibility,
    and traceability. It consists of three core components: the Hub, the Link, and
    the Satellite.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hubs**'
  prefs: []
  type: TYPE_NORMAL
- en: Hubs are collections of all distinct entities. For example, an account hub would
    include account, account_ID, load_date, and src_name. This allows us to track
    where the record originally came from when it was loaded, and if we need a surrogate
    key generated from the business key.
  prefs: []
  type: TYPE_NORMAL
- en: '**Links**'
  prefs: []
  type: TYPE_NORMAL
- en: Links establish relationships between hubs and capture the associations between
    different entities. They contain the foreign keys of the related hubs, enabling
    the creation of many-to-many relationships.
  prefs: []
  type: TYPE_NORMAL
- en: '**Satellites**'
  prefs: []
  type: TYPE_NORMAL
- en: Satellites store the descriptive information about the hubs, providing additional
    context and attributes. They include historical data, audit information, and other
    relevant attributes associated with a specific point in time.
  prefs: []
  type: TYPE_NORMAL
- en: Data Vault’s design allows for a flexible and scalable data warehouse architecture.
    It promotes data traceability, auditability, and historical tracking. This makes
    it suitable for scenarios where data integration and agility are critical, such
    as in highly regulated industries or rapidly changing business environments.
  prefs: []
  type: TYPE_NORMAL
- en: One big table (OBT)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OBT stores data in one wide table. Using one big table, or a denormalized table,
    can simplify queries, improve performance, and streamline data analysis. It eliminates
    the need for complex joins, eases data integration, and can be beneficial in certain
    scenarios. However, it may lead to redundancy, data integrity challenges, and
    increased maintenance complexity. Consider the specific requirements before opting
    for a single large table.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2b36ef7f7f59f4d90d6c5509f236dba9.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fd80be2f450e6d9bb262696929318624.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In the case of one wide table we don’t need to join tables. We can use only
    one table to aggregate data and make analyzes. This method improves performance
    in BigQuery.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38ee5df5fb0b2e9441c4bac0d842af0a.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Kimball methodology
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Kimball methodology places significant emphasis on the creation of a centralized
    data repository known as the data warehouse. This data warehouse serves as a singular
    source of truth, integrating and storing data from various operational systems
    in a consistent and structured manner.
  prefs: []
  type: TYPE_NORMAL
- en: This approach offers a comprehensive set of guidelines and best practices for
    designing, developing, and implementing data warehouse systems. It places a strong
    emphasis on creating dimensional data models and prioritizes simplicity, flexibility,
    and ease of use. Now, let’s delve into the key principles and components of the
    Kimball methodology.
  prefs: []
  type: TYPE_NORMAL
- en: Entity model to dimensional model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our data warehouses, the sources of data are often found in entity models
    that are normalized into multiple tables, which contain the business logic for
    applications. In such a scenario, it can be challenging as one needs to understand
    the dependencies between tables and the underlying business logic. Creating an
    analytical report or generating statistics often requires joining multiple tables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1a947ad8d14ba9efcdc4eddd888dc990.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: To create a dimensional model, the data needs to undergo an Extract, Transform,
    and Load (ETL) process to denormalize it into a star schema or snowflake schema.
    The key activity in this process involves identifying the fact and dimension tables
    and defining the granularity. The granularity determines the level of detail stored
    in the fact table. For example, transactions can be aggregated per hour or day.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/03b560d9831197a64117c53619483fdb.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume we have a company that sells bikes and bike accessories. In this
    case, we have information about:'
  prefs: []
  type: TYPE_NORMAL
- en: Transactions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clients
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Products
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on our business knowledge, we know that we need to collect information
    about sales volume, quantity over time, and segmented by regions, customers, and
    products. With this information, we can design our data model. The transactions’
    table will serve as our fact table, and the stores, clients, and products tables
    will act as dimensional tables.
  prefs: []
  type: TYPE_NORMAL
- en: Fact table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A fact table typically represents a business event or transaction and includes
    the metrics or measures associated with that event. These metrics can encompass
    various data points such as sales amounts, quantities sold, customer interactions,
    website clicks, or any other measurable data that offers insights into business
    performance. The fact table also includes foreign key columns that establish relationships
    with dimension tables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5ae5b71eda11bbbfcdf349d3e6bf204e.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: The best practice in the fact table design is to put all foreign keys on the
    top of the table and then measure.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fact Tables Types**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Transaction Fact Tables** gives a grain at its lowest level as one row represents
    a record from the transaction system. Data is refreshed on a daily basis or in
    real time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Periodic Snapshot Fact Tables** capture a snapshot of a fact table at a point
    in time, like for instance the end of month.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Accumulating Snapshot Fact Table** summarizes the measurement events occurring
    at predictable steps between the beginning and the end of a process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Factless Fact Table** keeps information about events occurring without any
    masseurs or metrics.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Dimension table
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A dimension table is a type of table in dimensional modeling that contains descriptive
    attributes like for instance information about products, its category, and type.
    Dimension tables provide the context and perspective to the quantitative data
    stored in the fact table.
  prefs: []
  type: TYPE_NORMAL
- en: Dimension tables contain a unique key that identifies each record in the table,
    named the surrogate key. The table can contain a business key that is a key from
    a source system. A good practice is to generate a surrogate key instead of using
    a business key.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several approaches to creating a [surrogate key](https://docs.getdbt.com/terms/surrogate-key):'
  prefs: []
  type: TYPE_NORMAL
- en: '-Hashing: a surrogate key can be generated using a hash function like MD5,
    SHA256(e.g. md5(key_1, key_2, key_3) ).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '-Incrementing: a surrogate key that is generated by using a number that is
    always incrementing (e.g. row_number(), identity).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '-Concatenating: a surrogate key that is generated by concatenating the unique
    key columns (e.g. concat(key_1, key_2, key_3) ).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '-Unique generated: a surrogate key that is generated by using a function that
    generates a unique identifier (e.g. GENERATE_UUID())'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The method that you will choose depends on the engine that you use to process
    and store data. It can impact performance of querying data.
  prefs: []
  type: TYPE_NORMAL
- en: Dimensional tables often contain hierarchies.
  prefs: []
  type: TYPE_NORMAL
- en: a) For example, the parent-child hierarchy can be used to represent the relationship
    between an employee and their manager.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/7400319e972334b96a44a27bbf50af4c.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: b) Hierarchical relationships between attributes. For example, a time dimension
    might have attributes like year, quarter, month, and day, forming a hierarchical
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b3514eac53f64cdef2228faa0da08fa1.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: Types of dimension tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Conformed Dimension:**'
  prefs: []
  type: TYPE_NORMAL
- en: A conformed dimension is a dimension that can be used by multiple fact tables.
    For example, a region table can be utilized by different fact tables.
  prefs: []
  type: TYPE_NORMAL
- en: '**Degenerate Dimension:**'
  prefs: []
  type: TYPE_NORMAL
- en: A degenerate dimension occurs when an attribute is stored in the fact table
    instead of a dimension table. For instance, the transaction number can be found
    in a fact table.
  prefs: []
  type: TYPE_NORMAL
- en: '**Junk Dimension:**'
  prefs: []
  type: TYPE_NORMAL
- en: This one contains non-meaningful attributes that do not fit well in existing
    dimension tables, or are combinations of flags and binary values representing
    various combinations of states.
  prefs: []
  type: TYPE_NORMAL
- en: '**Role-Playing Dimension:**'
  prefs: []
  type: TYPE_NORMAL
- en: The same dimension key includes more than one foreign key in the fact table.
    For example, a date dimension can refer to different dates in a fact table, such
    as creation date, order date, and delivery date.
  prefs: []
  type: TYPE_NORMAL
- en: '**Static Dimension:**'
  prefs: []
  type: TYPE_NORMAL
- en: A static dimension is a dimension that typically never changes. It can be loaded
    from reference data without requiring updates. An example could be a list of branches
    in a company.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bridge Table:**'
  prefs: []
  type: TYPE_NORMAL
- en: Bridge tables are used when there are one-to-many relationships between a fact
    table and a dimension table.
  prefs: []
  type: TYPE_NORMAL
- en: Slowly changing dimension
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A Slowly Changing Dimension (SCD) is a concept in dimensional modeling. It
    handles changes to dimension attributes over time in dimension tables. SCD provides
    a mechanism for maintaining historical and current data within a dimension table
    as business entities evolve and their attributes change. There are six types of
    SCD, but the three most popular ones are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**SCD Type 0**: In this type, only new records are imported into dimension
    tables without any updates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SCD Type 1**: In this type, new records are imported into dimension tables,
    and existing records are updated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SCD Type 2**: In this type, new records are imported, and new records with
    new values are created for changed attributes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, when John Smith moves to another city, we use SCD Type 2 to keep
    information about transactions related to London. In this case, we create a new
    record and update the previous one. As a result, historical reports will retain
    information that his purchases were made in London.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c306976ff4f127eca061b72ecd2e909b.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b4cdc58db4d5b1c5cdd84a8c9438c7c9.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This is how SCD 3 looks when we keep new and previous values in separate columns.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d2a51a21a63e1326f5dc2f9ecb214dc4.png)'
  prefs: []
  type: TYPE_IMG
- en: Star schema vs. snowflake schema
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most popular approach to designing a data warehouse is to utilize either
    a star schema or a snowflake schema. The star schema has fact tables and dimensional
    tables that are in relation to the fact table. In a star schema, there are fact
    tables and dimensional tables that are directly related to the fact table. On
    the other hand, a snowflake schema consists of a fact table, dimension tables
    related to the fact table, and additional dimensions related to those dimension
    tables.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d41c14bae29ccbc8c586f723e2194ea7.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by author*'
  prefs: []
  type: TYPE_NORMAL
- en: The main differences between these two designs lie in their normalization approach.
    The star schema keeps data denormalized, while the snowflake schema ensures normalization.
    The star schema is designed for better query performance. The snowflake schema
    is specifically tailored to handle updates on large dimensions. If you encounter
    challenges with updates to extensive dimension tables, consider transitioning
    to a snowflake schema.
  prefs: []
  type: TYPE_NORMAL
- en: Data loading strategies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our data warehouse, data lake, and data lake house we can have various load
    strategies like:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Full Load:** The full load strategy involves loading all data from source
    systems into the data warehouse. This strategy is typically used in the case of
    performance issues or lack of columns that could inform about row modification.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Incremental Load:** The incremental load strategy involves loading only new
    data since the last data load. If rows in the source system can’t be changed,
    we can load only new records based on a unique identifier or creation date. We
    need to define a “watermark” that we will use to select new rows.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Delta Load:** The delta load strategy focuses on loading only the changed
    and new records since the last load. It differs from incremental load in that
    it specifically targets the delta changes rather than all records. Delta load
    strategies can be efficient when dealing with high volumes of data changes and
    significantly reduce the processing time and resources required.'
  prefs: []
  type: TYPE_NORMAL
- en: The most common strategy to load data is to populate dimension tables and then
    fact tables. The order here is important because we need to use primary keys from
    dimension tables in fact tables to create relationships between tables. There
    is an exception. When we need to load a fact table before a dimension table, this
    technique name is late arriving dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: In this technique, we can create surrogate keys in a dimension table, and update
    it by ETL process after populating the fact table.
  prefs: []
  type: TYPE_NORMAL
- en: '**Summary**'
  prefs: []
  type: TYPE_NORMAL
- en: After a thorough reading of the article, if you have any questions or would
    like to further discuss data modeling and effective dimensional models, feel free
    to reach out to me on [LinkedIn](https://www.linkedin.com/in/mariusz-kujawski-812bb1103/).
    Implementing data modeling can unlock the potential of your data, providing valuable
    insights for informed decision-making while gaining knowledge in methods and best
    practices.
  prefs: []
  type: TYPE_NORMAL
