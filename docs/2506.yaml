- en: 7 Lessons Learned on Creating a Complete Product Using ChatGPT
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85?source=collection_archive---------2-----------------------#2023-08-05](https://towardsdatascience.com/7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85?source=collection_archive---------2-----------------------#2023-08-05)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ChatGPT‚Äôs coding abilities make it super easy to code entire products in no-time
    ‚Äî if you know how to use it the right way
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://shakedzy.medium.com/?source=post_page-----462038856c85--------------------------------)[![Shaked
    Zychlinski üéóÔ∏è](../Images/4d050b916bccab64df3c02236b3129eb.png)](https://shakedzy.medium.com/?source=post_page-----462038856c85--------------------------------)[](https://towardsdatascience.com/?source=post_page-----462038856c85--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----462038856c85--------------------------------)
    [Shaked Zychlinski üéóÔ∏è](https://shakedzy.medium.com/?source=post_page-----462038856c85--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F43218078e688&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85&user=Shaked+Zychlinski+%F0%9F%8E%97%EF%B8%8F&userId=43218078e688&source=post_page-43218078e688----462038856c85---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----462038856c85--------------------------------)
    ¬∑9 min read¬∑Aug 5, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F462038856c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85&user=Shaked+Zychlinski+%F0%9F%8E%97%EF%B8%8F&userId=43218078e688&source=-----462038856c85---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F462038856c85&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2F7-lessons-learned-on-creating-a-complete-product-using-chatgpt-462038856c85&source=-----462038856c85---------------------bookmark_footer-----------)![](../Images/d5f9f954d8d215c025a78ee8ac90a7f1.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Generated using StableDiffusion
  prefs: []
  type: TYPE_NORMAL
- en: Not long ago I shared with you how I [created my own French tutor out of ChatGPT](/how-i-coded-my-own-private-french-tutor-out-of-chatgpt-16b3e15007bb)
    (it‚Äôs [open-sourced](https://github.com/shakedzy/companion), by the way). I described
    how I designed the app (and specifically it‚Äôs backend) and how I connected and
    configured the different AI-based services. But there was one thing I pretty much
    skipped, which is how I created the frontend of the app. You see, I‚Äôm not a frontend
    programmer, and my knowledge of JavaScript sums up to the fact I know I need to
    place it within *<script></script>* tags.
  prefs: []
  type: TYPE_NORMAL
- en: But the app I had in mind required a UI, and a quite dynamic one. That means
    HTML, JavaScript and CSS ‚Äî but I had no idea how to even begin coding these.
  prefs: []
  type: TYPE_NORMAL
- en: What I did know is what I *wanted* it to look like. I had the design in my mind,
    and I knew how *I* would do it if I would‚Äôve known how to code these. And so I
    decided to go for a new and quite radical approach ‚Äî I‚Äôll ask ChatGPT to write
    the code for me. At that point I already had experience with asking ChatGPT for
    code-related requests, but never have I tried something so complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Well, as you‚Äôre reading these lines, you know it worked ‚Äî I‚Äôve created an entire
    app by simply instructing an LLM (Large Language Model) what I‚Äôd like to see.
    I really want to write this one more time, just to make sure we all understand
    what just happened: *an algorithm coded an entire app just by me explaining it
    in plain English.* üò≤'
  prefs: []
  type: TYPE_NORMAL
- en: Still, as astonishing as it was, this process wasn‚Äôt as trivial as it might
    sound ‚Äî and therefore I‚Äôd like to take the opportunity and share some tips I learned
    on how to generate complex code using ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Design it yourself
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are powerful tools for creating code and content, but they don‚Äôt *think*
    ‚Äî the can only fulfill requests (or at least they try). That means it‚Äôs up to
    you to do the thinking, and specifically the design. Make sure you know how the
    final product should look like before you begin sending requests to generative
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'More on this ‚Äî it‚Äôs up to you to do the research on what‚Äôs the best tech-stack
    for you. As you‚Äôll need to break your complex app to steps (see #2 below), the
    LLM can‚Äôt foresee what the final product will look like, and might use sub-optimal
    libraries or services.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the first UI ChatGPT generated for me was based on *tkinter*,
    which creates an actual application and not a web UI. This makes dynamic UI something
    much more complicated to create (and less standard these days). Another attempt
    was based on *steamlit*, which makes non-complex UIs super-easy to create, but
    again wasn‚Äôt designed for complex requests (for example: *‚Äúadd a play-recording
    button only next to the user messages but only if the user recorded an audio‚Äù*).
    In my case, it was up to me to understand that using *Flask* will be the optimal
    way to go.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Break it down to tasks & start simple
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you ask ChatGPT to code the entire product all at once, good chance you‚Äôll
    get a broken code. As ‚Äúsmart‚Äù as it is, don‚Äôt expect it to be able to pay attention
    to all given details all at once. Break your design to tasks and phases, starting
    with something rather simple, and adding on top of it.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, here‚Äôs my final chat UI, the one I initially designed and planned:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bb4cf3a47f2797d501e732b465059387.png)'
  prefs: []
  type: TYPE_IMG
- en: The chatbot UI
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see there are all sort of buttons and functionalities on the UI, and
    yet, my very first prompt to ChatGPT was:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'No special buttons, no profile images next to the messages, nothing special.
    Just a simple chat UI, which is will be the core I‚Äôll build upon. This prompt
    yielded 4 files:'
  prefs: []
  type: TYPE_NORMAL
- en: A Python file functioning as the backend (using Flask)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An HTML file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A JavaScript file (using jQuery)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A CSS file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once I had this, I could start making the product more complex.
  prefs: []
  type: TYPE_NORMAL
- en: You might think I just contradicted myself ‚Äî telling you to break you app to
    small steps, yet confessing my first prompt generated four files. Per each request
    from ChatGPT, there‚Äôs a trade-off between how much code is required to complete
    the task versus how non-standard and specific it is. Asking for an entire chat
    UI will generate something quite general, yet requires a lot of code. Asking to
    ‚Äú*add a translation button next to the tutor messages‚Äù*, and to also make sure
    it‚Äôs located on the right side of the message-bubble, always on the vertical-center
    and above the *play-sound* button is something very specific, and so it‚Äôll be
    a request by itself.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Explain carefully what you really want
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each request and addition you‚Äôll make to your product can potentially involve
    changes to more than one file (and to more than a single change per each file).
    That means new variables, functions and endpoints will be created at each such
    request, and will be referenced from different locations. The names provided to
    those will be given by ChatGPT, and it will do its best to provide them with meaningful
    names ‚Äî but it can only do so it you‚Äôll explain the context well.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if you‚Äôd like to add a ‚ÄúSave‚Äù button to your product, prefer asking
    it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'instead of a context-lacking prompt as so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Preferring context-rich prompts will yield better naming conventions.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Be very aware of exactly what you ask
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here‚Äôs a true issue I has to solve and didn‚Äôt see coming: I wanted the UI to
    display the generated text from my French tutor as it is being streamed, similarly
    to the effect in ChatGPT. The Python API I was using to create the tutor‚Äôs response
    (OpenAI *ChatCompletion* API) returns a Python *Generator*, which was then needed
    to be consumed and printed on the screen. And so I asked ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: What I didn‚Äôt know ‚Äî as I‚Äôve never written any serious JavaScript in my life
    ‚Äî was that I asked for something impossible; JavaScript has no way of handling
    a Python Generator. What happened was that ChatGPT gave me all sort of weird and
    completely useless solutions, as it tried to do exactly what I asked ‚Äî alter the
    JavaScript code.
  prefs: []
  type: TYPE_NORMAL
- en: You have to remember that ChatGPT tries to fulfill your requests exactly as
    you asked, as long as they don‚Äôt violate its guidelines. What I truly needed at
    that point was for it to *tell me* I‚Äôm asking for something dumb, but that‚Äôs just
    not how it works.
  prefs: []
  type: TYPE_NORMAL
- en: 'This issue was only fixed once *I figured out* I‚Äôm asking for the impossible
    (the old way ‚Äî Google and StackOverflow), and altered my prompt to something like
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: which resulted in modifications to both the JavaScript *and* the Python file,
    which allowed the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38122452e132858f6d754376a14f10a9.png)'
  prefs: []
  type: TYPE_IMG
- en: Generated using StableDiffusion
  prefs: []
  type: TYPE_NORMAL
- en: 5\. LLMs cannot revert their code (and how to revert)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While ChatGPT is exceptional at writing code, it‚Äôs still just a language model,
    and it doesn‚Äôt do well on reverting its own changes ‚Äî especially if you ask it
    to revert and go back two or three prompts back. When working with LLMs to generate
    code in phases, I highly recommend always keeping a copy of the last working version
    of the code you‚Äôre happy with; so if some new code ChatGPT added is broken and
    cannot be repaired, you can easily revert your code to when it worked last.
  prefs: []
  type: TYPE_NORMAL
- en: 'But there‚Äôs a catch ‚Äî because if you do revert your code, you‚Äôll *need* to
    revert ChatGPT too, to make sure it knows exactly how your code looks now. The
    best way to the that it by starting a new session, and kicking it off with a prompt
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: your HTML code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: your JavaScript code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: your CSS code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: your Python code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: (You can also upload the files to ChatGPT‚Äôs Code Interpreter, which was not
    available at that time). If the prompt is too long to be sent as a single message,
    split it to two. Click *‚ÄúStop Generating‚Äù* when in between these messages, to
    prevent the bot from inserting unnecessary text in between.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Don‚Äôt fight it for too long
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the cool things about coding with ChatGPT is that if it writes broken
    code, or the code doesn‚Äôt perform as intended, you can just send it the error
    message, and it will fix the code accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: But that doesn‚Äôt always happen. Sometimes ChatGPT doesn‚Äôt manage to fix the
    bug, or created another bug instead. We then send it the new error, and ask it
    again to fix it. If that happens more than two or three times, there‚Äôs a descent
    chance the code will be so broken or overly-modified, it will simply not work.
    If you‚Äôve reached that point, stop, revert (see above) and rephrase your request.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Learn how to prompt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While the whole point of ChatGPT is the fact you can interact with it using
    everyday language, knowing how write your prompts correctly can have an immense
    effect on the result. I truly recommend taking the time to learn how to do that.
    For example, this [free course by OpenAI and DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)
    on prompt engineering is a must, and specifically the lesson how to combine instructions,
    code and examples in a single prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most important things you can learn about prompting is to first
    to make sure there‚Äôs a distinguishable difference between the free-text and the
    code in your prompt. So instead of this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'write it like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'def func(x):'
  prefs: []
  type: TYPE_NORMAL
- en: return x*2
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, if possible, provide it with input-output examples. That the best method
    to explain an LLM what it should do, as it removes any ambiguities in your request
    (*what should the model return id the input is positive? keep it x*2 or maybe
    nothing?*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'def func(x):'
  prefs: []
  type: TYPE_NORMAL
- en: return x*2
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Bonus: Choose the right LLM'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Remember that ‚ÄúChatGPT‚Äù is a name of the web product, not the model itself.
    The free version gives you access to GPT-3.5, while the paid version includes
    GPT-4, which performs dramatically better in coding tasks The new Code Interpreter
    makes it also far better, as it can actually *run and test* its code.
  prefs: []
  type: TYPE_NORMAL
- en: Even if you decide to chose another LLM to work with, make sure the one you
    choose performs well on coding tasks. Otherwise, none of these tips will be of
    any assistance.
  prefs: []
  type: TYPE_NORMAL
- en: As I‚Äôm wrapping this all up, I guess the most important thing to realize when
    communicating with LLMs is that *every word matters*. LLMs don‚Äôt think and they
    can‚Äôt truly understand what we want without explicitly explaining it to them the
    way *they need*, because ‚Äî thank God ‚Äî they‚Äôre not human (yet?), they‚Äôre only
    a tool. And just like every tool ‚Äî if you don‚Äôt know how to work with it, you
    won‚Äôt get any job done. I do hope you‚Äôll find these tips useful on your next project!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/72db9dae8fd870a11c548f15b52a7292.png)'
  prefs: []
  type: TYPE_IMG
- en: Generated using StableDiffusion
  prefs: []
  type: TYPE_NORMAL
