["```py\n# Initialize the messages with setting behavior(s).\nmessages = [{\"role\": \"system\", \"content\": \"Enter behaviour(s) here.\"}]\n\n# Start an infinite loop to continue the conversation with the user.\nwhile True:\n    content = input(\"User: \") # Get input from the user to respond.\n    messages.append({\"role\": \"user\", \"content\": content})# Append the user's input to the messages.\n\n    # Use the OpenAI GPT-3.5 model to generate a response to the user's input.\n    completion = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        messages=messages\n    )\n\n    chat_response = completion.choices[0].message.content # Extract the chat response from the API response.\n    print(f'ChatGPT: {chat_response}') # Print the response.\n\n    # Append the response to the messages with the role \"assistant\" to store the chat history.\n    messages.append({\"role\": \"assistant\", \"content\": chat_response})\n```", "```py\nrecording = False       # Indicates whether the system is currently recording audio\ndone_recording = False  # Indicates that the user has completed recording a voice command \nstop_recording = False  # Indicates that the user wants to exit the conversation\n```", "```py\ndef listen_for_keys():\n    # Function to listen for key presses to control recording\n    global recording, done_recording, stop_recording\n    while True:\n        if keyboard.is_pressed('space'):  # Start recording on spacebar press\n            stop_recording = False\n            recording = True\n            done_recording = False\n        elif keyboard.is_pressed('esc'):  # Stop recording on 'esc' press\n            stop_recording = True\n            break\n        elif recording:  # Stop recording on spacebar release\n            recording = False\n            done_recording = True\n            break\n        time.sleep(0.01)\n```", "```py\ndef callback(indata, frames, time, status):\n    # Function called for each audio block during recording.\n    if recording:\n        if status:\n            print(status, file=sys.stderr)\n        q.put(indata.copy())\n```", "```py\ndef press2record(filename, subtype, channels, samplerate):\n    # Function to handle recording when a key is pressed\n    global recording, done_recording, stop_recording\n    stop_recording = False\n    recording = False\n    done_recording = False\n    try:\n        # Determine the samplerate if not provided\n        if samplerate is None:\n            device_info = sd.query_devices(None, 'input')\n            samplerate = int(device_info['default_samplerate'])\n            print(int(device_info['default_samplerate']))\n        # Create a temporary filename if not provided\n        if filename is None:\n            filename = tempfile.mktemp(prefix='captured_audio',\n                                       suffix='.wav', dir='')\n        # Open the sound file for writing\n        with sf.SoundFile(filename, mode='x', samplerate=samplerate,\n                          channels=channels, subtype=subtype) as file:\n            with sd.InputStream(samplerate=samplerate, device=None,\n                                channels=channels, callback=callback, blocksize=4096) as stream:\n                print('press Spacebar to start recording, release to stop, or press Esc to exit')\n                listener_thread = threading.Thread(target=listen_for_keys)  # Start the listener on a separate thread\n                listener_thread.start()\n                # Write the recorded audio to the file\n                while not done_recording and not stop_recording:\n                    while recording and not q.empty():\n                        file.write(q.get())\n        # Return -1 if recording is stopped\n        if stop_recording:\n            return -1\n\n    except KeyboardInterrupt:\n        print('Interrupted by user')\n\n    return filename\n```", "```py\ndef get_voice_command():\n    # ...\n    saved_file = press2record(filename=\"input_to_gpt.wav\", subtype = args.subtype, channels = args.channels, samplerate = args.samplerate)\n    # ...\n```", "```py\ndef get_voice_command():\n    # ...\n    result = audio_model.transcribe(saved_file, fp16=torch.cuda.is_available())\n    # ...\n```", "```py\ndef interact_with_tutor():\n    # Define the system role to set the behavior of the chat assistant\n    messages = [\n        {\"role\": \"system\", \"content\" : \"Du bist Anna, meine deutsche Lernpartnerin. \n                                        Du wirst mit mir chatten. Ihre Antworten werden kurz sein.\n                                        Mein Niveau ist B1, stell deine Satzkomplexit√§t auf mein Niveau ein. \n                                        Versuche immer, mich zum Reden zu bringen, indem du Fragen stellst, und vertiefe den Chat immer.\"}\n    ]\n    while True:\n        # Get the user's voice command\n        command = get_voice_command()  \n        if command == -1:\n            # Save the chat logs and exit if recording is stopped\n            save_response_to_pkl(messages)\n            return \"Chat has been stopped.\"\n\n        # Add the user's command to the message history\n        messages.append({\"role\": \"user\", \"content\": command})  \n\n        # Generate a response from the chat assistant\n        completion = openai.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=messages\n        )  \n\n        # Extract the response from the completion\n        chat_response = completion.choices[0].message.content  # Extract the response from the completion\n        print(f'ChatGPT: {chat_response} \\n')  # Print the assistant's response\n        messages.append({\"role\": \"assistant\", \"content\": chat_response})  # Add the assistant's response to the message history\n        # ...\n```", "```py\ndef interact_with_tutor():\n  # ...\n  # Convert the text response to speech\n  speech_object = gTTS(text=messages[-1]['content'],tld=\"de\", lang=language, slow=False)\n  speech_object.save(\"GPT_response.wav\")\n  current_dir = os.getcwd()\n  audio_file = \"GPT_response.wav\"\n  # Play the audio response\n  play_wav_once(audio_file, args.samplerate, 1.0)\n  os.remove(audio_file) # Remove the temporary audio file\n```", "```py\nsudo python chat.py\n```"]