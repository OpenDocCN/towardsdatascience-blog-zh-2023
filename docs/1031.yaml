- en: Four Approaches to build on top of Generative AI Foundational Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 四种构建在生成式人工智能基础模型之上的方法
- en: 原文：[https://towardsdatascience.com/four-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5?source=collection_archive---------1-----------------------#2023-03-21](https://towardsdatascience.com/four-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5?source=collection_archive---------1-----------------------#2023-03-21)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/four-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5?source=collection_archive---------1-----------------------#2023-03-21](https://towardsdatascience.com/four-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5?source=collection_archive---------1-----------------------#2023-03-21)
- en: What works, the pros and cons, and example code for each approach
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每种方法的优缺点、有效性以及示例代码
- en: '[](https://lakshmanok.medium.com/?source=post_page-----43c1a64cffd5--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page-----43c1a64cffd5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43c1a64cffd5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43c1a64cffd5--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page-----43c1a64cffd5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://lakshmanok.medium.com/?source=post_page-----43c1a64cffd5--------------------------------)[![Lak
    Lakshmanan](../Images/9faaaf72d600f592cbaf3e9089cbb913.png)](https://lakshmanok.medium.com/?source=post_page-----43c1a64cffd5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----43c1a64cffd5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----43c1a64cffd5--------------------------------)
    [Lak Lakshmanan](https://lakshmanok.medium.com/?source=post_page-----43c1a64cffd5--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F247b0630b5d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffour-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5&user=Lak+Lakshmanan&userId=247b0630b5d6&source=post_page-247b0630b5d6----43c1a64cffd5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43c1a64cffd5--------------------------------)
    ·11 min read·Mar 21, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F43c1a64cffd5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffour-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5&user=Lak+Lakshmanan&userId=247b0630b5d6&source=-----43c1a64cffd5---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F247b0630b5d6&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffour-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5&user=Lak+Lakshmanan&userId=247b0630b5d6&source=post_page-247b0630b5d6----43c1a64cffd5---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----43c1a64cffd5--------------------------------)
    · 11 分钟阅读 · 2023 年 3 月 21 日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F43c1a64cffd5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffour-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5&user=Lak+Lakshmanan&userId=247b0630b5d6&source=-----43c1a64cffd5---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F43c1a64cffd5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffour-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5&source=-----43c1a64cffd5---------------------bookmark_footer-----------)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F43c1a64cffd5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffour-approaches-to-build-on-top-of-generative-ai-foundational-models-43c1a64cffd5&source=-----43c1a64cffd5---------------------bookmark_footer-----------)'
- en: '*If some of the terminology I use here is unfamiliar, I encourage you to read
    my* [*earlier article on LLMs*](https://becominghuman.ai/why-large-language-models-like-chatgpt-are-bullshit-artists-c4d5bb850852)
    *first.*'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果我在这里使用的术语对你来说不熟悉，我鼓励你先阅读我的* [*关于大型语言模型的早期文章*](https://becominghuman.ai/why-large-language-models-like-chatgpt-are-bullshit-artists-c4d5bb850852)
    *。*'
- en: There *are* teams that are employing ChatGPT or its competitors (Anthropic,
    Google’s Flan T5 or PaLM, Meta’s LLaMA, Cohere, AI21Labs, etc.) for real rather
    for cutesy demos. Unfortunately, informative content about how they are doing
    so is lost amidst marketing hype and technical jargon. Therefore, I see folks
    who are getting started with generative AI take approaches that experts in the
    field will tell you are not going to pan out. This article is my attempt at organizing
    this space and showing you what’s working.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 确实*有*团队在实际应用中使用 ChatGPT 或其竞争者（如 Anthropic、Google 的 Flan T5 或 PaLM、Meta 的 LLaMA、Cohere、AI21Labs
    等），而不是仅仅用于炫酷的演示。不幸的是，关于他们如何做到这一点的信息在市场营销噱头和技术术语中被掩盖。因此，我看到刚开始接触生成式 AI 的人们采取了一些领域专家会告诉你不会奏效的方法。本文尝试组织这个领域并展示哪些方法有效。
- en: '![](../Images/ab78a68eafba35e68323a1f2c22b6a4f.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ab78a68eafba35e68323a1f2c22b6a4f.png)'
- en: Photo by [Sen](https://unsplash.com/es/@sen7?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    on [Unsplash](https://unsplash.com/s/photos/lego?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Sen](https://unsplash.com/es/@sen7?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
    提供，来源于 [Unsplash](https://unsplash.com/s/photos/lego?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
- en: The bar to clear
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要跨越的标准
- en: The problem with many of the cutesy demos and hype-filled posts about generative
    AI is that they [hit the training dataset](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)
    — they don’t really tell you how well it will work when applied to the chaos of
    real human users and actually novel input. Typical software is expected to work
    at 99%+ reliability —for example, it was only when speech recognition crossed
    this accuracy bar on phrases that the market for Voice AI took off. Same for automated
    captioning, translation, etc.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 许多关于生成式 AI 的炫酷演示和充满噱头的帖子存在的问题在于它们 [击中了训练数据集](https://aisnakeoil.substack.com/p/gpt-4-and-professional-benchmarks)
    ——它们并没有真正告诉你在应用于真实用户和实际新输入的混乱情况下效果如何。典型软件预计要达到 99% 以上的可靠性 ——例如，只有当语音识别技术在短语上跨越了这一准确度标准时，语音
    AI 市场才得以起飞。自动字幕、翻译等情况也是如此。
- en: 'I see two ways in which teams are addressing this issue in their production
    systems:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我看到团队在其生产系统中解决这一问题有两种方式：
- en: Human users are more forgiving if the UX is in a situation where they already
    expect to correct errors (this seems to be what helps GitHub Copilot) or where
    it is positioned as being interactive and helpful but not ready to use (ChatGPT,
    Bing Chat, etc.)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户体验在他们已经预期需要纠正错误的情况下，人类用户会更宽容（这似乎是 GitHub Copilot 帮助的原因），或者如果它被定位为互动和有帮助但尚未准备好使用（如
    ChatGPT、Bing Chat 等）。
- en: Fully automated applications of generative AI are mostly in the trusted-tester
    stage today, and the jury is out on whether these applications are actually able
    to clear this bar. That said, the results are promising and trending upwards,
    and it’s likely only a matter of time before the bar’s met.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前，生成式 AI 的完全自动化应用大多处于受信测试阶段，是否能够真正达到这一标准仍有待观察。尽管如此，结果令人鼓舞，并且趋势向上发展，最终达到标准只是时间问题。
- en: Personally, I have been experimenting with GPT 3.5 Turbo and Google Flan-T5
    with specific production use cases in mind, and learning quite a bit about what
    works and what doesn’t. None of *my* models have crossed the 99% bar. I also haven’t
    yet gotten access to GPT-4 or to Google’s PaLM API at the time of writing (March
    2023). I’m basing this article on my experiments, on published research, and on
    publicly announced projects.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 就个人而言，我一直在尝试 GPT 3.5 Turbo 和 Google Flan-T5，并针对特定的生产使用案例进行实验，并了解了许多有效和无效的方面。*我的*模型都没有跨越
    99% 的标准。到写作时（2023 年 3 月），我也尚未获得 GPT-4 或 Google 的 PaLM API 的访问权限。我基于我的实验、已发布的研究和公开宣布的项目撰写了这篇文章。
- en: With all uses of generative AI, it is helpful to firmly keep in mind that the
    pretrained models are trained on internet content and can be biased in multiple
    ways. Safeguard against those biases in your application layer.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有生成式 AI 的应用中，牢记预训练模型是基于互联网内容进行训练的，并可能存在多种偏见。这些偏见在你的应用层面上要加以防范。
- en: 'Approach 1: Use the API Directly'
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法 1：直接使用 API
- en: The first approach is the simplest because many users encountered GPT through
    the interactive interface offered by ChatGPT. It seems very intuitive to try out
    various prompts until you get one that generates the output you want. This is
    why you have a lot of LinkedIn influencers publishing ChatGPT prompts that [work
    for sales emails](https://www.linkedin.com/posts/mkosoglow_i-see-sdrs-aes-csms-and-execs-consistently-activity-7024033440933007360-CCmn)
    or whatever.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个方法是最简单的，因为许多用户通过 ChatGPT 提供的交互式界面遇到了 GPT。尝试各种提示直到得到你想要的输出似乎非常直观。这就是为什么你会看到许多
    LinkedIn 影响者发布了 [适用于销售邮件的 ChatGPT 提示](https://www.linkedin.com/posts/mkosoglow_i-see-sdrs-aes-csms-and-execs-consistently-activity-7024033440933007360-CCmn)
    或其他内容。
- en: 'When it comes to automating this workflow, the natural method is to use the
    [REST API endpoint](https://platform.openai.com/docs/api-reference/completions/create)
    of the service and directly invoke it with the final, working prompt:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到自动化这个工作流时，自然的方法是使用服务的 [REST API 端点](https://platform.openai.com/docs/api-reference/completions/create)
    并用最终有效的提示直接调用它：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'However, this approach does not lend itself to operationalization. There are
    several reasons:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法不适合操作化。原因有几个：
- en: '**Brittleness**. The underlying models keep improving. Sudden changes in the
    deployed models [broke](https://twitter.com/rishdotblog/status/1626273042472271872)
    many production workloads, and people learned from that experience. ML workloads
    are brittle enough already; adding additional points of failure in the form of
    prompts that are fine-tuned to specific models is not wise.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**脆弱性**。底层模型持续改进。部署模型的突然变化 [破坏了](https://twitter.com/rishdotblog/status/1626273042472271872)
    许多生产工作负载，人们从这些经验中学到了很多。机器学习工作负载已经很脆弱了；在特定模型的提示中添加额外的失败点是不明智的。'
- en: '**Injection**. It is rare that the instruction and input are plain strings
    as in the example above. Most often, they include variables that are input from
    users. These variables have to be incorporated into the prompts and inputs. And
    as any programmer knows, injection by string concatenation is rife with security
    problems. You put yourself at the mercy of the guardrails placed around the Generative
    AI API when you do this. As when guarding against SQL injection, it’s better to
    use an API that handles variable injection for you.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**注入**。像上述示例中那样，指令和输入通常不是简单的字符串。它们大多包括来自用户的变量。这些变量必须被纳入提示和输入中。正如任何程序员所知道的那样，通过字符串连接进行注入充满了安全问题。当你这样做时，你将自己置于生成式
    AI API 周围的保护措施的摆布之下。像防御 SQL 注入一样，使用一个处理变量注入的 API 更为妥当。'
- en: '**Multiple prompts**. It is rare that you will be able to get a prompt to work
    in one-shot. More common is to send multiple prompts to the model, and get the
    model to modify its output based on these prompts. These prompts themselves may
    have some human input (such as follow-up inputs) embedded in the workflow. Also
    common is for the prompts to provide a few examples of the desired output (called
    few-shot learning).'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多个提示**。很少能在一次尝试中让一个提示奏效。更常见的做法是向模型发送多个提示，并让模型根据这些提示修改其输出。这些提示本身可能会在工作流中嵌入一些人工输入（例如后续输入）。提示提供一些期望输出的示例（称为少量示例学习）也是很常见的。'
- en: A way to resolve all three of these problems is to use langchain.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这三个问题的一种方法是使用 langchain。
- en: 'Approach 2: Use langchain'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法二：使用 langchain
- en: 'Langchain is rapidly becoming the library of choice that allows you to invoke
    LLMs from different vendors, handle variable injection, and do few-shot training.
    [Here’s an example of using langchain](https://langchain.readthedocs.io/en/latest/modules/prompts/examples/few_shot_examples.html):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Langchain 正迅速成为一个首选库，允许你调用来自不同供应商的 LLM，处理变量注入，并进行少量示例训练。 [这是一个使用 langchain 的示例](https://langchain.readthedocs.io/en/latest/modules/prompts/examples/few_shot_examples.html)：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: I strongly recommend using langchain vs. using a vendor’s API directly. Then,
    make sure that everything you do works with at least two APIs or use a LLM checkpoint
    that will not change under you. Either of these approaches will avoid your prompts/code
    being brittle to changes in the underlying LLM. (Here, I’m using API to mean a
    managed LLM endpoint).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈推荐使用 langchain 而不是直接使用供应商的 API。然后，确保你所做的一切与至少两个 API 兼容，或者使用一个不会在你使用期间改变的
    LLM 检查点。这两种方法都能避免你的提示/代码对底层 LLM 的变化过于脆弱。（这里，我使用 API 指代一个托管的 LLM 端点）。
- en: Langchain today [supports APIs](https://langchain.readthedocs.io/en/latest/reference/integrations.html)
    from Open AI, Cohere, HuggingFace Hub (and hence Google Flan-T5), etc. and [LLMs
    from](https://langchain.readthedocs.io/en/latest/reference/modules/llms.html)
    AI21, Anthropic, Open AI, HuggingFace Hub, etc.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Langchain 目前 [支持来自](https://langchain.readthedocs.io/en/latest/reference/integrations.html)
    Open AI、Cohere、HuggingFace Hub（因此包括 Google Flan-T5）等的 API，以及 [来自](https://langchain.readthedocs.io/en/latest/reference/modules/llms.html)
    AI21、Anthropic、Open AI、HuggingFace Hub 等的 LLM。
- en: 'Approach 3: Finetune the Generative AI Chain'
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法 3：微调生成 AI 链
- en: This is the leading-edge approach in that it’s the one I see used by most of
    the sophisticated production applications of generative AI. As just an example
    (no endorsement), [finetuning is how](https://techcrunch.com/2023/03/20/numbers-station-raises-17-5m-to-bring-ai-to-your-data-stack/)
    a startup consisting of Stanford PhDs is approaching standard enterprise use cases
    like SQL generation and record matching.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前沿的方法，因为这是我看到大多数复杂生成 AI 生产应用程序所使用的方法。仅举一个例子（并非 endorsement），[微调就是](https://techcrunch.com/2023/03/20/numbers-station-raises-17-5m-to-bring-ai-to-your-data-stack/)
    一家由斯坦福博士组成的初创公司如何接近像 SQL 生成和记录匹配这样的标准企业用例。
- en: 'To understand the rationale behind this approach, it helps to know that there
    are four machine learning models that underpin ChatGPT (or its competitors):'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这种方法背后的理由，了解支撑 ChatGPT（或其竞争者）的四个机器学习模型是有帮助的：
- en: A Large Language Model (LLM) is trained to predict the next word of text given
    the previous words. It does this by learning word associations and patterns on
    a vast corpus of documents. The model is large enough that it learns these patterns
    in different contexts.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）被训练以预测给定前一个词后的下一个词。它通过学习在大量文档中的词汇关联和模式来实现这一点。模型足够大，可以在不同的上下文中学习这些模式。
- en: A Reinforcement Learning based on Human Feedback Model (RL-HF) is trained by
    showing humans examples of generated text, and asking them to approve text that
    is pleasing to read. The reason this is needed is that an LLM’s output is probabilistic
    — it doesn’t predict a single next word; instead, it predicts a set of words each
    of which has a certain probability of coming next. The RL-HF uses human feedback
    to learn how to choose the continuation that will generate the text that appeals
    to humans.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于人类反馈的强化学习模型（RL-HF）通过向人类展示生成的文本示例，并要求他们批准令人愉悦的文本来进行训练。之所以需要这样做，是因为 LLM 的输出是概率性的——它不会预测一个单一的下一个词，而是预测一组词，每个词都有一定的概率会出现。RL-HF
    使用人类反馈来学习如何选择生成对人类有吸引力的文本的延续。
- en: Instruction Model is a supervised model that is trained by showing prompts (“generate
    a sales email that proposes a demo to the engineering leadership”) and training
    the model on examples of sales emails.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指令模型是一个监督模型，通过显示提示（“生成一封向工程领导提议演示的销售邮件”）并在销售邮件的示例上训练模型来进行训练。
- en: Context Model is trained to carry on a conversation with the user, allowing
    them to craft the output through successive prompts.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上下文模型被训练以与用户进行对话，使他们能够通过连续的提示来制定输出。
- en: In addition, there are guardrails (filters on both the input and output). The
    model declines to answer certain types of queries, and retracts certain answers.
    In practice, these are both machine learning models that are constantly updated.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有保护机制（对输入和输出的过滤器）。模型会拒绝回答某些类型的问题，并撤回某些答案。在实际应用中，这些都是不断更新的机器学习模型。
- en: '![](../Images/4f76492aeae2cdeeaa19e4d0fc8f9796.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4f76492aeae2cdeeaa19e4d0fc8f9796.png)'
- en: 'Step 2: How RL-HF works. Image from [Stiennon et al, 2020](https://proceedings.neurips.cc/paper/2020/file/1f89885d556929e98d3ef9b86448f951-Paper.pdf)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2：RL-HF 如何工作。图片来自 [Stiennon et al, 2020](https://proceedings.neurips.cc/paper/2020/file/1f89885d556929e98d3ef9b86448f951-Paper.pdf)
- en: 'There are open-source generative AI models ([Meta’s LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/),
    Google’s [Flan-T5](https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html))
    which allow you to pick up at any of the above steps (e.g. use steps 1–2 from
    the released checkpoint, train 3 on your own data, don’t do 4). Note that LLaMA
    does not permit commercial use, and Flan-T5 is a year old (so you are compromising
    on quality). To learn where to break off, it is helpful to understand the cost/benefit
    of each stage:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些开源生成 AI 模型（[Meta 的 LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)，Google
    的 [Flan-T5](https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html)）允许您从上述任意步骤开始（例如，使用发布的检查点中的步骤
    1-2，自行在您的数据上训练第 3 步，不执行第 4 步）。请注意，LLaMA 不允许商业使用，而 Flan-T5 已经有一年时间（因此您需要在质量上做出妥协）。了解每个阶段的成本/收益有助于您决定从哪里开始。
- en: If your application uses very different jargon and words, it may be helpful
    to build a LLM from scratch on your own data (i.e., start at step 1). The problem
    is that you may not have enough data and even if you have enough data, the training
    is going to be expensive (on the order of 3–5 million dollars per training run).
    This seems to be what Salesforce has done with the [generative AI they use for
    developers](https://www.salesforce.com/news/press-releases/2023/03/07/einstein-generative-ai/).
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的应用程序使用的术语和词汇非常不同，可能有必要从头开始在您的数据上构建一个 LLM（即，从第 1 步开始）。问题是您可能没有足够的数据，即使有足够的数据，训练成本也会很高（每次训练运行的费用在
    300 万到 500 万美元之间）。这似乎是 Salesforce 对 [他们为开发人员使用的生成 AI](https://www.salesforce.com/news/press-releases/2023/03/07/einstein-generative-ai/)
    所做的。
- en: The RL-HF model is trained to appeal to a group of testers who may not be subject-matter
    experts, or representative of your own users. If your application requires subject
    matter expertise, you may be better off starting with a LLM and branching off
    from step 2\. The dataset you need for this is much smaller — Stiennon et al 2020
    used 125k documents and presented a pair of outputs for each input document in
    each iteration (see diagram). So, you need human labelers on standby to rate about
    1 million outputs. Assuming that a labeler takes 10 min to rate each pair of documents,
    the cost is that of 250 human-months of labor per training run. I’d estimate $250k
    to $2m depending on location and skillset.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RL-HF 模型经过训练，旨在吸引那些可能不是主题专家或代表您自己用户的测试人员。如果您的应用程序需要主题专业知识，您可能更适合从 LLM 开始，然后从第
    2 步分支出去。所需的数据集要小得多——Stiennon 等人在 2020 年使用了 125k 文档，并在每次迭代中为每个输入文档呈现一对输出（见图示）。因此，您需要人类标注者随时待命，以对约
    100 万个输出进行评分。假设一个标注者需要 10 分钟来评分每对文档，那么每次训练的人工成本大约是 250 人月。我估计费用在 25 万美元到 200 万美元之间，具体取决于地点和技能水平。
- en: ChatGPT is trained to respond to thousands of different prompts. Your application,
    on the other hand, probably requires only one or two specific ones. It can be
    convenient to train a model such as Google Flan-T5 on your specific instruction
    and input. Such a model can be much smaller (and therefore cheaper to deploy).
    This advantage in serving costs explains why step 3 is the most common point of
    branching off. It’s possible to fine-tune Google Flan-T5 for your specific task
    with about 10k documents using [HuggingFace](https://www.philschmid.de/fine-tune-flan-t5)
    and/or [Keras](https://keras.io/examples/nlp/t5_hf_summarization/). You’d do this
    on your usual ML framework such as Databricks, Sagemaker, or Vertex AI and use
    the same services to deploy the trained model. Because Flan-T5 is a Google model,
    GCP makes training and deployment really easy by providing [pre-built containers](https://medium.com/google-cloud/finetuning-flan-t5-base-and-online-deployment-in-vertex-ai-bf099c3a4a86)
    in Vertex AI. The cost would be perhaps $50 or so.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatGPT 被训练来响应成千上万的不同提示。另一方面，您的应用程序可能只需要一两个特定的提示。将 Google Flan-T5 训练到您的特定指令和输入上可能会很方便。这样的模型可以更小（因此部署成本更低）。这种服务成本上的优势解释了为什么第
    3 步是最常见的分支点。您可以使用 [HuggingFace](https://www.philschmid.de/fine-tune-flan-t5) 和/或
    [Keras](https://keras.io/examples/nlp/t5_hf_summarization/) 对 Google Flan-T5 进行针对您特定任务的微调。您可以在常用的
    ML 框架如 Databricks、Sagemaker 或 Vertex AI 上进行，并使用相同的服务来部署训练后的模型。由于 Flan-T5 是 Google
    的模型，GCP 通过在 Vertex AI 中提供 [预构建容器](https://medium.com/google-cloud/finetuning-flan-t5-base-and-online-deployment-in-vertex-ai-bf099c3a4a86)
    使训练和部署变得非常简单。费用可能在 50 美元左右。
- en: Theoretically, it’s possible to train a different way to maintain conversational
    context. However, I haven’t seen this in practice. What most people do instead
    is to use a conversational agent framework like Dialogflow that already has a
    LLM built into it, and design a custom chatbot for their application. The infra
    costs are negligible and you don’t need any AI expertise, just domain knowledge.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理论上，有可能通过不同的方法来保持对话上下文。然而，我在实际应用中没有看到这种做法。大多数人做的是使用像Dialogflow这样的对话代理框架，它已经内置了LLM，并为他们的应用设计一个定制的聊天机器人。基础设施成本微不足道，你只需要领域知识，无需任何AI专业知识。
- en: 'It is possible to break off at any of these stages. Limiting my examples to
    publicly published work in medicine:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在这些阶段中的任何一个进行中断。以下例子仅限于公开发布的医学研究：
- en: 'This [Nature article](https://www.nature.com/articles/s41746-022-00742-2) builds
    a custom 8.9-billion parameter LLM from 90 billion words extracted from medical
    records (i.e., they start from step 1). For comparison, Flan-PaLM used in #3 below
    is [540 billion parameters](https://huggingface.co/google/flan-t5-base) and the
    “small/efficient” PaLM is 62 billion parameters. Obviously, cost is a constraint
    in going much bigger on your custom language model.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这篇[Nature文章](https://www.nature.com/articles/s41746-022-00742-2)从从医学记录中提取的90亿字中构建了一个自定义的89亿参数LLM（即，它们从第1步开始）。作为比较，下文第3种方法中使用的Flan-PaLM具有[5400亿参数](https://huggingface.co/google/flan-t5-base)，而“小型/高效”PaLM为620亿参数。显然，成本是定制语言模型变得更大的一个限制因素。
- en: This [MIT CSAIL study](https://news.mit.edu/2022/large-language-models-help-decipher-clinical-notes-1201)
    forces the model to closely hew to existing text and also doing instruction fine-tuning
    (i.e., they are starting from step 2).
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这项[MIT CSAIL研究](https://news.mit.edu/2022/large-language-models-help-decipher-clinical-notes-1201)要求模型严格遵循现有文本，并进行指令微调（即，它们从第2步开始）。
- en: '[Deep Mind’s MedPaLM](https://arxiv.org/abs/2212.13138) starts from an instruction-tuned
    variation of PaLM called Flan-PaLM (i.e. it starts after step 3). They report
    that 93% of healthcare professionals rated the AI as being on par with human answers.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[Deep Mind的MedPaLM](https://arxiv.org/abs/2212.13138)从一种指令调优的PaLM变体Flan-PaLM开始（即，它从第3步开始）。他们报告称，93%的医疗专业人员认为该AI的回答与人类回答相当。'
- en: My advice is to choose where to break off based on how different your application
    space is from the generic internet text on which the foundational models are trained.
    Which model should you fine-tune? Currently, Google Flan T5 is the most sophisticated
    fine-tuneable model available and open for commercial use. For non-commercial
    uses, Meta’s LLaMA is the most sophisticated model available.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我的建议是，根据你的应用领域与基础模型训练所用的通用互联网文本的差异，选择中断的位置。你应该微调哪个模型？目前，Google Flan T5是最先进的可微调模型，且开放用于商业用途。对于非商业用途，Meta的LLaMA是最先进的模型。
- en: 'A word of caution though: when you tap into the chain using open-source models,
    the guardrail filters won’t exist, so **you will have to put in toxicity safeguards**.
    One option is to use the [detoxify](https://github.com/unitaryai/detoxify) library.
    Make sure to incorporate toxicity filtering around any API endpoint in production
    — otherwise, you’ll find yourself having to [take it back down](https://www.theregister.com/2023/03/21/stanford_ai_alpaca_taken_offline/).
    API gateways can be a convenient way to ensure that you are doing this for all
    your ML model endpoints.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 但需要注意的是：当你使用开源模型进行链式操作时，保护过滤器不会存在，因此**你需要设置毒性安全措施**。一个选项是使用[detoxify](https://github.com/unitaryai/detoxify)库。确保在生产环境中的任何API端点周围都实施毒性过滤，否则你会发现自己不得不[撤下它](https://www.theregister.com/2023/03/21/stanford_ai_alpaca_taken_offline/)。API网关可以是确保你对所有ML模型端点进行此操作的便捷方式。
- en: 'Approach 4: Simplify the problem'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法4：简化问题
- en: There are smart approaches to reframe the problem you are solving in such as
    way that you can use a Generative AI model (as in Approach 3) but avoid problems
    with hallucination, etc.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些聪明的方法可以重新定义你所解决的问题，以便可以使用生成式AI模型（如第3种方法），但避免出现幻觉等问题。
- en: 'For example, suppose you want to do question-answering. You could start with
    a powerful LLM and then struggle to “tame” the wild beast to have it not hallucinate.
    A much simpler approach is to reframe the problem. Change the model from one that
    predicts the output text to a model that has three outputs: the URL of a document,
    the starting position within that document, and the length of text. That is what
    Google Search is doing here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你想做问答系统。你可以从一个强大的 LLM 开始，然后努力“驯服”这个“野兽”，使其不出现幻觉。一个更简单的方法是重新定义问题。将模型从一个预测输出文本的模型改为一个有三个输出的模型：文档的
    URL、文档中的起始位置和文本长度。这就是谷歌搜索在这里做的：
- en: '![](../Images/e0ebbc9c4057ace3341e972199a34c60.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e0ebbc9c4057ace3341e972199a34c60.png)'
- en: Google’s Q&A model predicts a URL, starting position, and length of text. This
    avoids problems with hallucination.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的问答模型预测一个 URL、起始位置和文本长度。这避免了幻觉问题。
- en: At worst, the model will show you irrelevant text. What it will not do is to
    hallucinate because you don’t allow it to actually predict text.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最糟糕的情况下，模型会显示不相关的文本。它不会出现幻觉，因为你不允许它真正预测文本。
- en: 'A [Keras sample that follows](https://keras.io/examples/nlp/question_answering/)
    this approach tokenizes the inputs and context (the document that you are finding
    the answer within):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 [遵循此方法的 Keras 示例](https://keras.io/examples/nlp/question_answering/) 将输入和上下文（你要在其中找到答案的文档）进行标记化：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'and then passes the tokens into a Keras regression model whose first layer
    is the Transformer model that takes in these tokens and that outputs the position
    of the answer within the “context” text:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将这些令牌传递给一个 Keras 回归模型，其第一层是 Transformer 模型，该模型接收这些令牌并输出答案在“上下文”文本中的位置：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'During inference, you get the predicted locations:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理过程中，你会得到预测的位置：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You will note that the sample does not predict the URL — the context is assumed
    to be the result of a typical search query (such as returned by a matching engine
    or vector database), and the sample model only does extraction. However, you can
    build the search also into the model by having a separate layer in Keras.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，样本并没有预测 URL——上下文假定是典型搜索查询的结果（例如由匹配引擎或向量数据库返回），样本模型只进行提取。然而，你可以通过在 Keras
    中添加一个单独的层来将搜索功能也构建到模型中。
- en: Summary
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'There are four approaches that I see being used to build production applications
    on top of generative AI foundational models:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我见到的四种在生成 AI 基础模型之上构建生产应用程序的方法：
- en: Use the REST API of an all-in model such as GPT-4 for one-shot prompts.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用像 GPT-4 这样的全能模型的 REST API 进行单次提示。
- en: Use langchain to abstract away the LLM, input injection, multi-turn conversations,
    and few-shot learning.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 langchain 来抽象化 LLM、输入注入、多轮对话和少样本学习。
- en: Finetune on your custom data by tapping into the set of models that comprise
    an end-to-end generative AI model.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利用一组模型来对你的自定义数据进行微调，这些模型构成了一个端到端的生成 AI 模型。
- en: Reframe the problem into a form that avoids the dangers of generative AI (bias,
    toxicity, hallucination).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将问题重新定义为一种避免生成 AI（偏见、毒性、幻觉）风险的形式。
- en: 'Approach #3 is what I see most commonly used by sophisticated teams.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '方法 #3 是我见过的最常被成熟团队使用的方法。'
