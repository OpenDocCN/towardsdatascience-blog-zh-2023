# 利用大语言模型（LLMs）完善推荐知识图谱

> 原文：[`towardsdatascience.com/augmenting-intelligence-leveraging-llms-to-complete-recommendation-knowledge-graphs-a0585e311d3f`](https://towardsdatascience.com/augmenting-intelligence-leveraging-llms-to-complete-recommendation-knowledge-graphs-a0585e311d3f)

[](https://medium.com/@alcarazanthony1?source=post_page-----a0585e311d3f--------------------------------)![安东尼·阿尔卡拉兹](https://medium.com/@alcarazanthony1?source=post_page-----a0585e311d3f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----a0585e311d3f--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----a0585e311d3f--------------------------------) [安东尼·阿尔卡拉兹](https://medium.com/@alcarazanthony1?source=post_page-----a0585e311d3f--------------------------------)

·发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----a0585e311d3f--------------------------------) ·6 分钟阅读·2023 年 11 月 6 日

--

*人工智能软件被用来提升本文文本的语法、流畅性和可读性。*

随着互联网和在线平台的快速增长，用户面临的选择变得琳琅满目。推荐系统在预测用户偏好和推荐相关内容方面变得至关重要，从而帮助用户应对信息过载。然而，提供准确和个性化的推荐仍然是一个持久的挑战。

问题的关键在于通过建模用户行为来理解用户的真实兴趣和意图。推荐系统依赖于从用户数据中提取的模式，如浏览历史、购买记录、评分和互动。然而，现实世界中的用户数据通常是稀疏和有限的，缺乏捕捉用户意图细微差别所需的重要上下文信号。

因此，推荐模型无法学习全面的用户和项目表示。它们的建议最终往往过于笼统、重复或无关。冷启动问题使得新用户在活动历史较少的情况下问题更加复杂。企业也因客户体验不佳而遭受损失，导致收入损失。

这需要找到能够从用户数据中挖掘更深层次洞见的解决方案。一种新兴的方法是使用知识图谱来封装事实和实体之间的连接。构建良好的知识图谱在解决推荐系统中的关键挑战方面具有巨大的潜力。

知识图谱不仅仅是对用户-项目交互的建模。它们编码了跨多个实体的各种上下文元数据、属性和关系。这种多维度的链接结构模拟了人类记忆存储世界知识的方式。

通过在这些互联的知识上训练专门的图神经网络模型，推荐系统可以学习更具信息量的用户行为和项目特征的表示。丰富的理解导致了针对细化用户需求和场景的建议。

然而，这一愿景面临的障碍是现实世界的知识图谱远非完美。它们存在不完整性，缺少关键的连接和细节。这阻碍了推荐模型真正把握用户的上下文和意图。

幸运的是，语言模型的最新进展带来了希望。像 GPT-3 这样的预训练模型展示了卓越的自然语言生成能力，这得益于其广泛的世界知识。早期利用这种模型进行上下文学习以增强知识图谱的探索显示出很大的前景（Wei et al., 2023）。

在本文中，我们将深入探讨语言模型的增强智能如何转变知识图谱。我们将探讨像 GPT-3 这样的模型驱动的关系预测和属性丰富化等技术。通过综合实例，我们将展示语言模型增强的知识图谱如何解锁智能推荐系统的下一个层级。

# 知识图谱 — 编码连接

知识图谱将实体（用户、产品）表示为节点，将它们的关系表示为边。将用户与他们的兴趣、人口统计信息、购买历史等连接起来，可以让推荐系统学习更好的表示方式。

然而，基于用户数据的现实世界知识图谱通常存在稀疏性和不完整性。许多潜在的连接被简单地忽略，这限制了系统真正理解用户意图的能力。

这是大型语言模型（LLMs）承诺带来突破的地方。

# LLMs — 增强智能

LLMs 因其生成出色的类人文本能力而获得了巨大的受欢迎程度。但更令人印象深刻的是，它们通过在大量文本语料库上进行预训练而编码的大量知识。

最近的研究探讨了利用这些知识来改进由图神经网络（GNNs）驱动的推荐系统。关键思想是使用 LLMs 增强现有的知识图谱，通过强化边缘和增强节点属性来实现。

# LLMs 强化图连接

LLMs 可以预测用户和项目之间可能存在但在源数据中未明确出现的潜在连接。例如，通过分析用户的购买历史，它们可以建议用户可能感兴趣的相关产品。

这些 LLM 预测的链接有助于稠密化稀疏图谱，为偏好建模提供关键信号。强化边缘增强了邻域，并允许协作模式的出现。

# LLMs 增强节点属性

知识图谱中的节点代表诸如用户和项目等实体。LLMs 可以基于与这些节点相关的文本数据增强其属性。

例如，产品描述和评论可以通过 LLMs 处理，以提取缺失的规格或标签。用户评论和帖子也可以类似地分析，以填补稀疏的个人资料信息。

这导致节点具有丰富的特征向量，克服了冷启动问题。增强的属性改善了语义，从而提供更好的推荐。

# 改进的建模与增强图谱

通过在 LLM 增强的知识图谱上训练图神经网络，推荐系统可以学习到更优的用户和项目表示。

改进的结构和节点特征导致了捕获细微偏好和项目特征的嵌入。这解决了许多推荐引擎面临的稀疏性和冷启动等关键挑战。

研究显示，通过在将图谱输入 GNN 架构之前使用 LLMs 增强图谱，可以显著提高召回率和降低延迟。

# LLMRec 技术：

使用逐步方程增强知识图谱的 LLMRec 技术：

## 第 1 步：为 LLM 构建提示

首先，我们需要创建提供背景的提示，以便 LLM 生成有用的增强数据。

用于增强用户-项目连接：

```py
PUI = {D, H, C, F}
```

其中：

+   PUI: 用户-项目交互提示

+   D: 任务描述

+   H: 用户的历史交互

+   C: 候选项

+   F: 所需的输出格式

用于增强节点属性：

```py
PA = {D, E, F)
```

其中：

+   PA: 属性增强提示

+   D: 任务描述

+   E: 可用实体属性

+   F: 缺失属性的输出格式

## 第 2 步：从 LLM 获取增强数据

现在我们可以使用这些提示从 LLM 获取增强数据：

```py
EA = LLM(PUI) 
AA = LLM(PA)
```

其中：

+   EA: 增强的用户-项目交互

+   AA: 增强的属性

+   LLM(): 语言模型（例如 GPT-3）

## 第 3 步：纳入增强

增强数据可以作为以下内容纳入：

```py
E' = E + EA
A' = A + AA
```

其中：

+   E’: 原始交互和增强交互的联合

+   A’: 原始属性和增强属性的联合

## 第 4 步：训练增强推荐系统

推荐模型随后在改进后的图上进行训练：

```py
θ* = argmaxθ P(θ|A', E')
```

其中：

+   θ*: 优化的模型参数

+   P(): 后验概率

# 数据稳健化技术

LLMRec 中用于处理增强数据噪声的去噪数据稳健化技术：

**嘈杂用户-项目交互修剪**

+   在每次训练迭代后，将使用增强的用户-项目对计算的损失值按升序排序。

+   修剪或丢弃一定比例的损失值最高的对。这些很可能对应于噪声或不可靠的样本。

+   仅保留损失最小的最可靠对，以便在下一次迭代中进行训练。

+   数学上，通过对损失张量进行排序和切片来实现：

```py
Lsorted = SortAscend(L) 
Lpruned = Lsorted[0:N]
```

其中 N 是修剪后保留的样本数量。

**通过 MAE 增强增强特征**

+   使用[MASK]标记掩盖图中部分增强的节点特征。

+   使用掩码自编码器从掩码版本中重建原始特征。

+   原始特征与掩码特征之间的特征重建损失作为正则化手段，以提高特征质量。

+   从数学角度看，损失计算公式如下：

```py
LFR = 1/|V| Σ (1 - f⋅f' / ||f||⋅||f'|| )
```

其中，f 是原始特征，f’是掩码特征，V 是掩码节点的集合。

这些技术共同作用，修剪不可靠的增强内容，并施加约束，以确保噪声人工数据不会降低性能。这导致使用高质量增强图谱的干净、稳健的训练过程。

# 无限可能性与 LLMs

知识图谱代表了构建更智能、更具上下文理解的下一代推荐系统的一个极具潜力的方向。通过编码多方面的实体连接，它们可以捕捉到细微的用户行为模式和项目关系。

然而，现实世界的知识图谱通常面临如稀疏性和不完整性等关键问题，这限制了它们的有效性。这正是大型语言模型通过预测缺失的连接和生成缺失的描述性属性提供颠覆性机会的地方。

正如我们通过详细的示例所见，像关系强化和属性增强这样的技术，借助 LLMs 可以显著增强现有的知识图谱。增强的智能如同缺失的拼图碎片，将各部分连接起来，创建一个更完整的图景。

在这种丰富的表示上训练图神经网络，释放了知识图谱的全部潜力。这使得学习复杂的用户和项目嵌入成为可能，从而捕捉细微和语义信息。

结果是能够真正理解用户上下文和意图的推荐系统。LLM 驱动的知识图谱为智能助手铺平了道路，这些助手可以满足细致的用户需求和场景。

随着语言模型的不断进化，它们的知识增强能力也将不断提升。通过因果推理和对话互动等进展，它们可能帮助构建解释性图谱，将推荐与用户行为和理由联系起来。

大规模应用确实需要解决计算开销和可能出现的算法偏差等挑战。但这些可能性使得这是未来推荐系统中最有前景的方向之一。

知识就是力量。在推荐系统领域，语言模型补充的知识图谱看似将释放这种力量。这标志着智能推荐的新纪元的开始。在这个时代，系统不仅仅是模式匹配，而是表现出对用户上下文和需求的更深刻理解，从而提供有针对性的建议。

![](img/80fa24d339b7d18a5ce26a715d2778a2.png)

作者提供的图片
