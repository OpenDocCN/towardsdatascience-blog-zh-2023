["```py\nquestions_answers = [\n     {'subject': 'אוסטרליה',\n      'subject_translation': 'Australia',\n      'question': \"איזו עיר בויקטוריה נחשבת לבירת הספורט של אוסטרליה?\",\n      'answer': \"מלבורן\",\n      'question_translation': \"Which city in Victoria is considered the sporting capital of Australia?\",\n      'answer_translation': \"Melbourne\"},\n     {'subject': 'אוניברסיטה',\n      'subject_translation': 'University',\n      'question': \"איזה נהר ממוקם בקרבת אוניברסיטת הארווארד?\",\n      'answer': \"נהר צ'ארלס\",\n      'question_translation': \"Which river is located in the vicinity of Harvard University?\",\n      'answer_translation': \"Charles River\"},\n     {'subject': 'המוות השחור',\n      'subject_translation': 'The black plague',\n      'question': \"כמה אנשים ברחבי העולם נספו בעקבות המוות השחור?\",\n      'answer': \"בין 75 ל200 מיליון איש\",\n      'question_translation': \"How many people in the world died from the black plague?\",\n      'answer_translation': \"Between 75 and 200 million\"},\n]\n```", "```py\nfrom googletrans import Translator\nimport openai\n\ndef complete(prompt):\n    # query text-davinci-003\n    res = openai.Completion.create(\n        engine='text-davinci-003',\n        prompt=prompt,\n        temperature=0,\n        max_tokens=400,\n        top_p=1,\n        frequency_penalty=0,\n        presence_penalty=0,\n        stop=None\n    )\n    return res['choices'][0]['text'].strip()\n\ndef print_question_answer(question, query, expected_answer, question_translation, expected_answer_translation):\n  translator = Translator()\n  answer = complete(query)\n  print(f'Question: {question}\\n' \\\n        f'Question (translation): {question_translation}\\n' \\\n        f'Answer: {answer}\\n' \\\n        f'Answer (translation): {translator.translate(answer).text}\\n' \\\n        f'Expected Answer: {expected_answer}\\n' \\\n        f'Expected Answer (translation): {expected_answer_translation}'\n        )\n\nfor i, qa_dct in enumerate(questions_answers):\n  print(f'####################')\n  print(f'Question #{i + 1}:')\n  print_question_answer(qa_dct['question'],\n                        qa_dct['question'],\n                        qa_dct['answer'],\n                        qa_dct['question_translation'],\n                        qa_dct['answer_translation'],\n                        )\n```", "```py\n####################\nQuestion #1:\nQuestion: איזו עיר בויקטוריה נחשבת לבירת הספורט של אוסטרליה?\nQuestion (translation): Which city in Victoria is considered the sporting capital of Australia?\nAnswer: סידני.\nAnswer (translation): Sydney.\nExpected Answer: מלבורן\nExpected Answer (translation): Melbourne\n####################\nQuestion #2:\nQuestion: איזה נהר ממוקם בקרבת אוניברסיטת הארווארד?\nQuestion (translation): Which river is located in the vicinity of Harvard University?\nAnswer: הנהר הקרוב ביותר לאוניברסיטת הארווארד הוא נהר הקונגו.\nAnswer (translation): The closest river to Harvard University is the Congo River.\nExpected Answer: נהר צ'ארלס\nExpected Answer (translation): Charles River\n####################\nQuestion #3:\nQuestion: כמה אנשים ברחבי העולם נספו בעקבות המוות השחור?\nQuestion (translation): How many people in the world died from the black plague?\nAnswer: בעקבות המוות השחור של ג'ורג' פלאי, הפגנו אלפי אנשים ברחבי העולם בכדי להגיב לפעולות הפולישיות של המשטרה האמריקאית. אלפי אנשים הפגינו בערים בכל הארצות האמריקאיות, כמו ג'קסוןביל, ניו יורק, לוס אנג'לס, פילדלפיה, אתרוג, אוסטין, סנט לואיס, אוסטין, אינדיאנה, מישיגן, אורלנדו, קליפורניה, אוהיו, אריזונה, אוקלהומה, ארצות הברית החדשות ועוד. אף אנשים\nAnswer (translation): Following the black death of George Flay, thousands of people demonstrated around the world to respond to the police actions of the American police. Thousands of people demonstrated in cities in all American countries, such as Jacksonville, New York, Los Angeles, Philadelphia, Etrog, Austin, St. Louis, Austin, Indiana, Michigan, Orlando, California, Ohio, Arizona, Oklahoma, New United States and more . no people\nExpected Answer: בין 75 ל200 מיליון איש\nExpected Answer (translation): Between 75 and 200 million\n```", "```py\nwith open('/content/drive/MyDrive/Datasets/hebrew_wikipedia/full.txt') as f:\n  hebrew_wiki = f.readlines()\n\nopenai_price_per_1k = 0.00004\nn_tokens = sum([len(x) for x in hebrew_wiki])\nprint(f'This hebrew wikipedia dataset contains {len(hebrew_wiki)} sentences')\nprint(f'In total it amounts to {n_tokens} tokens')\nprint(f'With the current pricing of openAI it will cost {(openai_price_per_1k * n_tokens) / 1000:.3f}$ to embed everything')\n```", "```py\nThis hebrew wikipedia dataset contains 3833140 sentences\nIn total it amounts to 380692471 tokens\nWith the current pricing of openAI it will cost 15.228$ to embed everything\n```", "```py\ndef get_lines_per_subject(hebrew_wiki, subject, subject_translation):\n  subject_lines = [(i, x) for i, x in enumerate(hebrew_wiki) if subject in x]\n  n_tokens = sum([len(x[1]) for x in subject_lines])\n  print(f'There are {len(subject_lines)} sentences that have the words {subject_translation} in them')\n  print(f'In total it amounts to {n_tokens} tokens')\n  print(f'With the current pricing of openAI it will cost {(openai_price_per_1k * n_tokens) / 1000:.3f}$ to embed everything')\n  return subject_lines\n\nsubject_lines = {}\nfor qa_dct in questions_answers:\n  subject_lines[qa_dct['subject']] = get_lines_per_subject(hebrew_wiki, qa_dct['subject'], qa_dct['subject_translation'])\n```", "```py\nThere are 7772 sentences that have the words Australia in them\nIn total it amounts to 1026137 tokens\nWith the current pricing of openAI it will cost 0.041$ to embed everything\nThere are 15908 sentences that have the words University in them\nIn total it amounts to 1904404 tokens\nWith the current pricing of openAI it will cost 0.076$ to embed everything\nThere are 160 sentences that have the words The black plague in them\nIn total it amounts to 19410 tokens\nWith the current pricing of openAI it will cost 0.001$ to embed everything\n```", "```py\nimport pinecone\n\nindex_name = 'hebrew-wikipedia'\n\n# initialize connection to pinecone (get API key at app.pinecone.io)\npinecone.init(\n    api_key=pinecone_key,\n    environment=\"us-east1-gcp\"\n)\n\n# check if index already exists (it shouldn't if this is first time)\nif index_name not in pinecone.list_indexes():\n    # if does not exist, create index\n    pinecone.create_index(\n        index_name,\n        dimension=len(res['data'][0]['embedding']),\n        metric='cosine',\n        metadata_config={'indexed': ['contains_keywords']}\n    )\n# connect to index\nindex = pinecone.Index(index_name)\n# view index stats\nindex.describe_index_stats()\n```", "```py\nfrom tqdm.auto import tqdm\nimport datetime\nfrom time import sleep\n\nembed_model = \"text-embedding-ada-002\"\nbatch_size = 32  # how many embeddings we create and insert at once\n\ndef insert_into_pinecone(lines, subject):\n  print(f'Inserting {len(lines)} of subject: {subject} into pinecone')\n  for i in tqdm(range(0, len(lines), batch_size)):\n      # find end of batch\n      i_end = min(len(lines), i+batch_size)\n      meta_batch = lines[i:i_end]\n      ids_batch = [str(x[0]) for x in meta_batch]\n      texts = [x[1] for x in meta_batch]\n      try:\n          res = openai.Embedding.create(input=texts, engine=embed_model)\n      except:\n          done = False\n          while not done:\n              sleep(5)\n              try:\n                  res = openai.Embedding.create(input=texts, engine=embed_model)\n                  done = True\n              except:\n                  pass\n      embeds = [record['embedding'] for record in res['data']]\n      # cleanup metadata\n      meta_batch = [{\n          'contains_keywords': subject,\n          'text': x,\n      } for x in texts]\n      to_upsert = list(zip(ids_batch, embeds, meta_batch))\n      # upsert to Pinecone\n      index.upsert(vectors=to_upsert)\n\nfor subject, lines in subject_lines.items():\n  insert_into_pinecone(lines, subject)\n```", "```py\nres = openai.Embedding.create(\n    input=[questions_answers[0]['question']],\n    engine=embed_model\n)\n\n# retrieve from Pinecone\nxq = res['data'][0]['embedding']\n\n# get relevant contexts (including the questions)\nres = index.query(xq, top_k=2, include_metadata=True)\n\nres\n```", "```py\n{'matches': [{'id': '2642286',\n              'metadata': {'contains_keywords': 'אוסטרליה',\n                           'text': 'העיר שוכנת לחופה הצפון-מערבי של '\n                                   'אוסטרליה.\\n'},\n              'score': 0.899194837,\n              'values': []},\n             {'id': '2282112',\n              'metadata': {'contains_keywords': 'אוסטרליה',\n                           'text': 'אוסטרלאסיה היה השם של נבחרת הספורטאים '\n                                   'מאוסטרליה וניו זילנד שהשתתפה באולימפיאדת '\n                                   'לונדון (1908) ובאולימפיאדת סטוקהולם '\n                                   '(1912).\\n'},\n              'score': 0.893916488,\n              'values': []}],\n 'namespace': ''}\n```", "```py\nlimit = 3000\n\ndef retrieve(query, filter_subjects=None, add_dont_know=False):\n    res = openai.Embedding.create(\n        input=[query],\n        engine=embed_model\n    )\n\n    # retrieve from Pinecone\n    xq = res['data'][0]['embedding']\n\n    # get relevant contexts\n    res = index.query(xq,\n                      {'contains_keywords': {'$in': filter_subjects}}\n                      if filter_subjects is not None else None,\n                      top_k=100,\n                      include_metadata=True)\n    contexts = [\n        x['metadata']['text'] for x in res['matches']\n    ]\n\n    # build our prompt with the retrieved contexts included\n    idk_str = '''. If the question cannot be answered using the\n    information provided answer with \"I don't know\"''' if add_dont_know else ''\n    prompt_start = (\n        \"Answer the question based on the context below.\" + idk_str + \"\\n\\n\" +\n        \"Context:\\n\"\n    )\n    prompt_end = (\n        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n    )\n    # append contexts until hitting limit\n    for i in range(1, len(contexts)):\n        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n            prompt = (\n                prompt_start +\n                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n                prompt_end\n            )\n            break\n        elif i == len(contexts)-1:\n            prompt = (\n                prompt_start +\n                \"\\n\\n---\\n\\n\".join(contexts) +\n                prompt_end\n            )\n    return prompt\n\noriginal_subjects = ['אוסטרליה', 'אוניברסיטה', 'המוות השחור']\n\nfor i, qa_dct in enumerate(questions_answers):\n  print(f'####################')\n  print(f'Question #{i + 1} with context:')\n  query_with_contexts = retrieve(qa_dct['question'],\n                                 filter_subjects=original_subjects,\n                                 add_dont_know=True)\n  print(f'Length of query with contexts: {len(query_with_contexts)}')\n  print_question_answer(qa_dct['question'],\n                        query_with_contexts,\n                        qa_dct['answer'],\n                        qa_dct['question_translation'],\n                        qa_dct['answer_translation'],\n                        )\n```", "```py\n####################\nQuestion #1 with context:\nLength of query with contexts: 3207\nQuestion: איזו עיר בויקטוריה נחשבת לבירת הספורט של אוסטרליה?\nQuestion (translation): Which city in Victoria is considered the sporting capital of Australia?\nAnswer: קנברה\nAnswer (translation): Canberra\nExpected Answer: מלבורן\nExpected Answer (translation): Melbourne\n####################\nQuestion #2 with context:\nLength of query with contexts: 3179\nQuestion: איזה נהר ממוקם בקרבת אוניברסיטת הארווארד?\nQuestion (translation): Which river is located in the vicinity of Harvard University?\nAnswer: I don't know\nAnswer (translation): I don't know\nExpected Answer: נהר צ'ארלס\nExpected Answer (translation): Charles River\n####################\nQuestion #3 with context:\nLength of query with contexts: 3138\nQuestion: כמה אנשים ברחבי העולם נספו בעקבות המוות השחור?\nQuestion (translation): How many people in the world died from the black plague?\nAnswer: I don't know.\nAnswer (translation): I don't know.\nExpected Answer: בין 75 ל200 מיליון איש\nExpected Answer (translation): Between 75 and 200 million\n```", "```py\nadditional_subjects = [\n    ('מלבורן', 'Melbourne'),\n    ('סידני', 'Sydney'),\n    ('אדלייד', 'Adelaide'),\n    ('הרווארד', 'Harvard'),\n    (\"מסצ'וסטס\", 'Massachusetts'),\n    (\"צ'ארלס\", 'Charles'),\n    ('בוסטון', 'Boston'),\n    ('מגפה', 'plague'),\n    ('האבעבועות השחורות', 'smallpox'),\n    ('אבעבועות שחורות', 'smallpox'),\n    ('מונגוליה', 'mongolia')\n]\n\nadditional_subject_lines = {}\nfor subject, subject_translation in additional_subjects:\n  additional_subject_lines[subject] = get_lines_per_subject(hebrew_wiki, subject, subject_translation)\n\nfor subject, lines in additional_subject_lines.items():\n  insert_into_pinecone(lines, subject)\n```", "```py\nThere are 948 sentences that have the words Melbourne in them\nIn total it amounts to 119669 tokens\nWith the current pricing of openAI it will cost 0.005$ to embed everything\nThere are 2812 sentences that have the words Sydney in them\nIn total it amounts to 347608 tokens\nWith the current pricing of openAI it will cost 0.014$ to embed everything\nThere are 213 sentences that have the words Adelaide in them\nIn total it amounts to 24480 tokens\nWith the current pricing of openAI it will cost 0.001$ to embed everything\nThere are 1809 sentences that have the words Harvard in them\nIn total it amounts to 228918 tokens\nWith the current pricing of openAI it will cost 0.009$ to embed everything\nThere are 1476 sentences that have the words Massachusetts in them\nIn total it amounts to 179227 tokens\nWith the current pricing of openAI it will cost 0.007$ to embed everything\nThere are 5025 sentences that have the words Charles in them\nIn total it amounts to 647501 tokens\nWith the current pricing of openAI it will cost 0.026$ to embed everything\nThere are 2912 sentences that have the words Boston in them\nIn total it amounts to 361337 tokens\nWith the current pricing of openAI it will cost 0.014$ to embed everything\nThere are 1007 sentences that have the words plague in them\nIn total it amounts to 116961 tokens\nWith the current pricing of openAI it will cost 0.005$ to embed everything\nThere are 39 sentences that have the words smallpox in them\nIn total it amounts to 5417 tokens\nWith the current pricing of openAI it will cost 0.000$ to embed everything\nThere are 135 sentences that have the words smallpox in them\nIn total it amounts to 15815 tokens\nWith the current pricing of openAI it will cost 0.001$ to embed everything\nThere are 742 sentences that have the words mongolia in them\nIn total it amounts to 90607 tokens\nWith the current pricing of openAI it will cost 0.004$ to embed everything\n```", "```py\nfor i, qa_dct in enumerate(questions_answers):\n  print(f'####################')\n  print(f'Question #{i + 1} with context:')\n  query_with_contexts = retrieve(qa_dct['question'], add_dont_know=Tue)\n  print(f'Length of query with contexts: {len(query_with_contexts)}')\n  print_question_answer(qa_dct['question'],\n                        query_with_contexts,\n                        qa_dct['answer'],\n                        qa_dct['question_translation'],\n                        qa_dct['answer_translation'],\n                        )\n```", "```py\n####################\nQuestion #1 with context:\nLength of query with contexts: 3158\nQuestion: איזו עיר בויקטוריה נחשבת לבירת הספורט של אוסטרליה?\nQuestion (translation): Which city in Victoria is considered the sporting capital of Australia?\nAnswer: מלבורן\nAnswer (translation): Melbourne\nExpected Answer: מלבורן\nExpected Answer (translation): Melbourne\n####################\nQuestion #2 with context:\nLength of query with contexts: 3106\nQuestion: איזה נהר ממוקם בקרבת אוניברסיטת הארווארד?\nQuestion (translation): Which river is located in the vicinity of Harvard University?\nAnswer: נהר צ'ארלס\nAnswer (translation): Charles River\nExpected Answer: נהר צ'ארלס\nExpected Answer (translation): Charles River\n####################\nQuestion #3 with context:\nLength of query with contexts: 3203\nQuestion: כמה אנשים ברחבי העולם נספו בעקבות המוות השחור?\nQuestion (translation): How many people in the world died from the black plague?\nAnswer: לפי הערכות שונות, כ-35 מיליון בני אדם בסין לבדה, ובין 20 ל-25 מיליון בני אדם באירופה.\nAnswer (translation): According to various estimates, about 35 million people in China alone, and between 20 and 25 million people in Europe.\nExpected Answer: בין 75 ל200 מיליון איש\nExpected Answer (translation): Between 75 and 200 million\n```"]