- en: 'Back to the Basics: Probit Regression'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到基础知识：Probit 回归
- en: 原文：[https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09](https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09](https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09)
- en: '**A crucial method in binary outcome analysis**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**二元结果分析中的关键方法**'
- en: '[](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[![Akif
    Mustafa](../Images/1fb81af6fc0aeefedc1da59b3ba2b7ba.png)](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    [Akif Mustafa](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[![Akif
    Mustafa](../Images/1fb81af6fc0aeefedc1da59b3ba2b7ba.png)](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    [Akif Mustafa](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7ff7bb988de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=post_page-7ff7bb988de----ac05f4694d49---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    ·7 min read·Nov 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=-----ac05f4694d49---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7ff7bb988de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=post_page-7ff7bb988de----ac05f4694d49---------------------post_header-----------)
    发布于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    ·7 min read·Nov 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=-----ac05f4694d49---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&source=-----ac05f4694d49---------------------bookmark_footer-----------)![](../Images/cba21459a99759f2f68dd7f9ac9432f5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&source=-----ac05f4694d49---------------------bookmark_footer-----------)![](../Images/cba21459a99759f2f68dd7f9ac9432f5.png)'
- en: Image by [Issac Smith](https://unsplash.com/@isaacmsmith) on [Unsplash](https://unsplash.com/photos/pen-on-paper-6EnTPvPPL6I)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Issac Smith](https://unsplash.com/@isaacmsmith) 提供，来自 [Unsplash](https://unsplash.com/photos/pen-on-paper-6EnTPvPPL6I)
- en: Whenever we face any task related to analyzing binary outcomes, we often think
    of logistic regression as the go-to method. That’s why most articles about binary
    outcome regression focus exclusively on logistic regression. However, logistic
    regression is not the only option available. There are other methods, such as
    the Linear Probability Model (LPM), Probit regression, and Complementary Log-Log
    (Cloglog) regression. Unfortunately, there is a lack of articles on these topics
    available on the internet.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们面对与分析二元结果相关的任务时，我们往往会将 logistic 回归视为首选方法。这就是为什么大多数关于二元结果回归的文章都专注于 logistic
    回归。然而，logistic 回归并不是唯一的选择。还有其他方法，例如线性概率模型（LPM）、Probit 回归和互补对数对数（Cloglog）回归。不幸的是，互联网上缺乏这些主题的文章。
- en: The Linear Probability Model is rarely used because it is not very effective
    in capturing the curvilinear relationship between a binary outcome and independent
    variables. I have previously discussed [Cloglog regression](/a-gentle-introduction-to-complementary-log-log-regression-8ac3c5c1cd83)
    in one of my previous articles. While there are some articles on Probit regression
    available on the internet, they tend to be technical and difficult for non-technical
    readers to understand. In this article, we will explain the basic principles of
    Probit regression and its applications and compare it with logistic regression.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 线性概率模型很少被使用，因为它在捕捉二元结果与自变量之间的曲线关系方面效果不佳。我在之前的一篇文章中讨论过[Cloglog回归](/a-gentle-introduction-to-complementary-log-log-regression-8ac3c5c1cd83)。虽然互联网上有一些关于Probit回归的文章，但它们往往技术性较强，非技术读者难以理解。在这篇文章中，我们将解释Probit回归的基本原理及其应用，并与逻辑斯蒂回归进行比较。
- en: '**Background**'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**背景**'
- en: 'This is how a relationship between a binary outcome variable and an independent
    variable typically looks:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是二元结果变量与自变量之间关系的典型表现：
- en: '![](../Images/f6808504cc3f7a3e8253ac59265506e7.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6808504cc3f7a3e8253ac59265506e7.png)'
- en: Image by the author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'The curve you see is called an S-shaped curve or sigmoid curve. If we closely
    observe this plot, we’ll notice that it resembles a cumulative distribution function
    (CDF) of a random variable. Therefore, it makes sense to use the CDF to model
    the relationship between a binary outcome variable and independent variables.
    The two most commonly used CDFs are the logistic and the normal distributions.
    Logistic regression utilizes the logistic CDF, given with the following equation:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到的曲线被称为S形曲线或逻辑斯蒂曲线。如果我们仔细观察这个图，我们会发现它类似于一个随机变量的累积分布函数（CDF）。因此，使用CDF来建模二元结果变量与自变量之间的关系是有意义的。最常用的CDF是逻辑斯蒂分布和正态分布。逻辑斯蒂回归使用逻辑斯蒂CDF，其方程如下：
- en: '![](../Images/9bda309e68a1678272c519fcf3cd0a70.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bda309e68a1678272c519fcf3cd0a70.png)'
- en: Image by the author
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: 'In Probit regression, we utilize the cumulative distribution function (CDF)
    of the normal distribution. Reasonably, we can just replace logistic CDF with
    normal distribution CDF to get the equation of Probit regression:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在Probit回归中，我们利用正态分布的累积分布函数（CDF）。合理地，我们可以用正态分布CDF替换逻辑斯蒂CDF，以得到Probit回归的方程：
- en: '![](../Images/ac9d1cf34c6ba4bd208f6b80ec5f3c4f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ac9d1cf34c6ba4bd208f6b80ec5f3c4f.png)'
- en: Image by the author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: Where Φ() represents the cumulative distribution function of the standard normal
    distribution.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 其中Φ()表示标准正态分布的累积分布函数。
- en: We can memorise this equation, but it will not clarify our concept related to
    the Probit regression. Therefore, we will adopt a different approach to gain a
    better understanding of how Probit regression works.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以记住这个方程式，但它并不能澄清我们对Probit回归的概念。因此，我们将采用一种不同的方法来更好地理解Probit回归的工作原理。
- en: The basic concept behind Probit regression
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Probit回归的基本概念
- en: Let us say we have data on the weight and depression status of a sample of 1000
    individuals. Our objective is to examine the relationship between weight and depression
    using Probit regression. (Download the data from this [link](https://github.com/akifiips/Probit-Regression).
    )
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一组关于1000名个体的体重和抑郁状态的数据。我们的目标是使用Probit回归来研究体重与抑郁之间的关系。（从这个[链接](https://github.com/akifiips/Probit-Regression)下载数据。）
- en: To provide some intuition, let’s imagine that whether an individual (the “ith”
    individual) will experience depression or not depends on an unobservable latent
    variable, denoted as A*i*. This latent variable is influenced by one or more independent
    variables. In our scenario, the weight of an individual determines the value of
    the latent variable. The probability of experiencing depression increases with
    increase in the latent variable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一些直观的理解，让我们假设一个个体（“第i个”个体）是否会经历抑郁取决于一个不可观察的潜在变量，记作A*i*。这个潜在变量受到一个或多个自变量的影响。在我们的场景中，个体的体重决定了潜在变量的值。经历抑郁的概率随着潜在变量的增加而增加。
- en: '![](../Images/df5b70583fe819163df54b8af44e4b74.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/df5b70583fe819163df54b8af44e4b74.png)'
- en: Image by the author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图片
- en: The question is, since A*i* is an unobserved latent variable, how do we estimate
    the parameters of the above equation? Well, if we assume that it is normally distributed
    with the same mean and variance, we will be able to obtain some information regarding
    the latent variable and estimate the model parameters. I will explain the equations
    in more detail later, but first, let’s perform some practical calculations.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，由于A*i*是一个未观察到的潜在变量，我们如何估计上述方程的参数？好吧，如果我们假设它呈正态分布且具有相同的均值和方差，我们将能够获得关于潜在变量的一些信息，并估计模型参数。我稍后会更详细地解释这些方程，但首先，让我们进行一些实际计算。
- en: 'Coming back to our data: In our data, let us calculate the probability of depression
    for each age and tabulate it. For example, there are 7 people with a weight of
    40kg, and 1 of them has depression, so the probability of depression for weight
    40 is 1/7 = 0.14286\. If we do this for all weight, we will get this table:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的数据：在我们的数据中，让我们计算每个年龄的抑郁症概率并将其制表。例如，有7个人体重为40公斤，其中1人有抑郁症，因此体重40的抑郁症概率为1/7
    = 0.14286。如果我们对所有体重进行此操作，我们将得到以下表格：
- en: '![](../Images/a6a9562b9b557587aae7df55048005aa.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a6a9562b9b557587aae7df55048005aa.png)'
- en: Image by the author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: 'Now, how do we get the values of the latent variable? We know that the normal
    distribution gives the probability of Y for a given value of X. However, the inverse
    cumulative distribution function (CDF) of the normal distribution enables us to
    obtain the value of X for a given probability value. In this case, we already
    have the probability values, which means we can determine the corresponding value
    of the latent variable by using the inverse CDF of the normal distribution. [Note:
    Inverse Normal CDF function is available in almost every statistical software,
    including Excel.]'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何获得潜在变量的值呢？我们知道正态分布给出了给定X值的Y的概率。然而，正态分布的逆累积分布函数（CDF）使我们能够获得给定概率值的X值。在这种情况下，我们已经有了概率值，这意味着我们可以通过使用正态分布的逆CDF来确定潜在变量的相应值。
    [注意：逆正态CDF函数几乎在所有统计软件中都可以找到，包括Excel。]
- en: '![](../Images/cdb42364c72440473ae33791b277a51c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cdb42364c72440473ae33791b277a51c.png)'
- en: Image by the author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: This unobserved latent variable A*i* is known as normal equivalent deviate (n.e.d.)
    or simply **normit**. Looking closely, it is nothing but Z-scores associated with
    the unobserved latent variable. Once we have the estimated Ai, estimating β1 and
    β2 is relatively simple. We can run a simple linear regression between A*i* and
    our independent variable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个未观察到的潜在变量A*i*被称为正态等效偏差（n.e.d.），或简单地称为**normit**。仔细观察，这只是与未观察到的潜在变量相关的Z分数。一旦我们有了估计的Ai，估计β1和β2相对简单。我们可以在A*i*和我们的自变量之间进行简单的线性回归。
- en: '![](../Images/ec220f56971134bc8a46bcb08a94b3f4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec220f56971134bc8a46bcb08a94b3f4.png)'
- en: Image by the author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: The coefficient of weight 0.0256 gives us the change in the z-score of the outcome
    variable (depression) associated with a one-unit change in weight. Specifically,
    a one-unit increase in weight is associated with an increase of approximately
    0.0256 z-score units in the likelihood of having high depression. We can calculate
    the probability of depression for any age using standard normal distribution.
    For example, for weight 70,
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 权重为0.0256的系数给出了与权重的单位变化相关的结果变量（抑郁症）的z分数的变化。具体而言，权重的单位增加与抑郁症高概率的z分数单位增加约0.0256相关。我们可以使用标准正态分布计算任何年龄的抑郁症概率。例如，对于体重70，
- en: A*i* = -1.61279 + (0.02565)*70
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: A*i* = -1.61279 + (0.02565)*70
- en: A*i* = 0.1828
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: A*i* = 0.1828
- en: The probability associated with a z-score of 0.1828 (P(x<Z)) is 0.57; i.e. the
    predicted probability of depression for weight 70 is 0.57.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 与z分数0.1828（P(x<Z)）相关的概率是0.57；即体重70的抑郁症预测概率是0.57。
- en: It is quite reasonable to say that the above explanation was an oversimplification
    of a moderately complex method. It is also important to note that it is just an
    illustration of the basic principle behind the use of cumulative normal distribution
    in Probit regression. Now, let us have a look at the mathematical equations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，上述解释对一个适度复杂的方法进行了过度简化是相当合理的。同时也需要注意，这只是使用累积正态分布在Probit回归中的基本原理的一个说明。现在，让我们看看数学方程。
- en: Mathematical Structure
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学结构
- en: 'We discussed earlier that there exists a latent variable, A*i*, that is determined
    by the predictor variables. It will be very logical to consider that there exists
    a critical or threshold value (A*i*_c) of the latent variable such that if A*i*
    exceeds A*i*_c, the individual will have depression; otherwise, he/she will not
    have depression. Given the assumption of normality, the probability that A*i*
    is less than or equal to A*i*_c can be calculated from standardized normal CDF:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过存在一个潜在变量A*i*，它由预测变量决定。考虑到潜在变量存在一个临界或阈值（A*i*_c）是很合逻辑的，即如果A*i*超过A*i*_c，则个体将会有抑郁症；否则，他/她将不会有抑郁症。假设正态分布的前提下，可以从标准化正态累积分布函数中计算A*i*小于或等于A*i*_c的概率：
- en: '![](../Images/c216e27ff8f4ba06ab339d49eb614d29.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c216e27ff8f4ba06ab339d49eb614d29.png)'
- en: Image by the author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Where Z*i* is the standard normal variable, i.e., Z ∼ N(0, σ 2) and F is the
    standard normal CDF.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其中Z*i*是标准正态变量，即Z ∼ N(0, σ 2)，F是标准正态累积分布函数。
- en: 'The information related to the latent variable and β1 and β2 can be obtained
    by taking the inverse of the above equation:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 与潜在变量及β1和β2相关的信息可以通过对上述方程取逆得到：
- en: '![](../Images/e738e781d358e44f5b3f08082b83167a.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e738e781d358e44f5b3f08082b83167a.png)'
- en: Image by the author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Inverse CDF of standardized normal distribution is used when we want to obtain
    the value of Z for a given probability value.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要获得给定概率值的Z值时，会使用标准正态分布的逆累积分布函数。
- en: Now, the estimation process of β1, β2, and A*i* depends on whether we have grouped
    data or individual-level ungrouped data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，β1、β2和A*i*的估计过程取决于我们是否拥有分组数据或个体级别的未分组数据。
- en: When we have grouped data, it is easy to calculate the probabilities. In our
    depression example, the initial data is ungrouped, i.e. there is weight for each
    individual and his/her status of depression (1 and 0). Initially, the total sample
    size was 1000, but we grouped that data by weight, resulting in 71 groups, and
    calculated the probability of depression in each weight group.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有分组数据时，计算概率是很容易的。在我们的抑郁症例子中，初始数据是未分组的，即每个个体的权重及其抑郁状态（1和0）。最初，总样本量为1000，但我们按权重将数据分组，结果形成71个组，并计算了每个权重组中的抑郁概率。
- en: 'However, when the data is ungrouped, the Maximum Likelihood Estimation (MLE)
    method is utilized to estimate the model parameters. The figure below shows the
    Probit regression on our ungrouped data (n = 1000):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当数据未分组时，使用最大似然估计（MLE）方法来估计模型参数。下图显示了我们未分组数据（n = 1000）上的Probit回归：
- en: '![](../Images/6a9673fd95ca38165a07d2a39b89ce1d.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a9673fd95ca38165a07d2a39b89ce1d.png)'
- en: Image by the author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: It can be observed that the coefficient of weight is very close to what we estimated
    with the grouped data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可以观察到，权重系数非常接近我们使用分组数据估计的结果。
- en: '**Probit vs Logit**'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**Probit与Logit**'
- en: 'Now that we have grasped the concept of Probit regression and are familiar
    (hopefully) with logistic regression, the question arises: which model is preferable?
    Which model performs better under different conditions? Well, both models are
    quite similar in their application and yield comparable results (in terms of predicted
    probabilities). The only minor distinction lies in their sensitivity to extreme
    values. Let’s take a closer look at both models:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了Probit回归的概念，并且对逻辑回归（希望）也比较熟悉，问题来了：哪个模型更优？在不同条件下哪个模型表现更好？事实上，这两个模型在应用上非常相似，并且在预测概率方面的结果也相当接近。唯一的细微区别在于它们对极端值的敏感性。让我们更详细地了解这两个模型：
- en: '![](../Images/d8d4a3d10f4738dc60a343b8021486df.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8d4a3d10f4738dc60a343b8021486df.png)'
- en: Image by the author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: From the plot, we can observe that the Probit and Logit models are quite similar.
    However, Probit is less sensitive to extreme values compared to Logit. It means
    that at extreme values, the change in probability of outcome with respect to unit
    change in the predictor variable is higher in the logit model compared to the
    Probit model. So, if you want your model to be sensitive at extreme values, you
    may prefer using logistic regression. However, this choice will not significantly
    affect the estimates, as both models yield similar results in terms of predicted
    probabilities. It is important to note that the coefficients obtained from both
    models represent different quantities and cannot be directly compared. Logit regression
    provides changes in the log odds of the outcome with changes in the predictor
    variable, while Probit regression provides changes in the z-score of the outcome.
    However, if we calculate the predicted probabilities of the outcome using both
    models, the results will be very similar.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中我们可以观察到，Probit和Logit模型非常相似。然而，Probit对极端值的敏感性较低。这意味着在极端值下，预测变量单位变化对结果概率的影响在Logit模型中高于Probit模型。因此，如果你希望模型对极端值敏感，你可能会更倾向于使用逻辑回归。然而，这种选择不会显著影响估计结果，因为两种模型在预测概率方面产生的结果相似。需要注意的是，来自两种模型的系数表示的是不同的量，不能直接比较。Logit回归提供了结果与预测变量变化的对数赔率的变化，而Probit回归提供了结果的z-score的变化。然而，如果我们使用两种模型计算预测概率，结果将非常相似。
- en: In practice, logistic regression is preferred over Probit regression because
    of its mathematical simplicity and easy interpretation of the coefficients.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，逻辑回归因其数学简洁性和系数解释的方便性而优于Probit回归。
