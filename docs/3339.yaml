- en: 'Back to the Basics: Probit Regression'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09](https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**A crucial method in binary outcome analysis**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[![Akif
    Mustafa](../Images/1fb81af6fc0aeefedc1da59b3ba2b7ba.png)](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    [Akif Mustafa](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7ff7bb988de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=post_page-7ff7bb988de----ac05f4694d49---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    ·7 min read·Nov 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=-----ac05f4694d49---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&source=-----ac05f4694d49---------------------bookmark_footer-----------)![](../Images/cba21459a99759f2f68dd7f9ac9432f5.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by [Issac Smith](https://unsplash.com/@isaacmsmith) on [Unsplash](https://unsplash.com/photos/pen-on-paper-6EnTPvPPL6I)
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we face any task related to analyzing binary outcomes, we often think
    of logistic regression as the go-to method. That’s why most articles about binary
    outcome regression focus exclusively on logistic regression. However, logistic
    regression is not the only option available. There are other methods, such as
    the Linear Probability Model (LPM), Probit regression, and Complementary Log-Log
    (Cloglog) regression. Unfortunately, there is a lack of articles on these topics
    available on the internet.
  prefs: []
  type: TYPE_NORMAL
- en: The Linear Probability Model is rarely used because it is not very effective
    in capturing the curvilinear relationship between a binary outcome and independent
    variables. I have previously discussed [Cloglog regression](/a-gentle-introduction-to-complementary-log-log-regression-8ac3c5c1cd83)
    in one of my previous articles. While there are some articles on Probit regression
    available on the internet, they tend to be technical and difficult for non-technical
    readers to understand. In this article, we will explain the basic principles of
    Probit regression and its applications and compare it with logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: '**Background**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is how a relationship between a binary outcome variable and an independent
    variable typically looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6808504cc3f7a3e8253ac59265506e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 'The curve you see is called an S-shaped curve or sigmoid curve. If we closely
    observe this plot, we’ll notice that it resembles a cumulative distribution function
    (CDF) of a random variable. Therefore, it makes sense to use the CDF to model
    the relationship between a binary outcome variable and independent variables.
    The two most commonly used CDFs are the logistic and the normal distributions.
    Logistic regression utilizes the logistic CDF, given with the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9bda309e68a1678272c519fcf3cd0a70.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 'In Probit regression, we utilize the cumulative distribution function (CDF)
    of the normal distribution. Reasonably, we can just replace logistic CDF with
    normal distribution CDF to get the equation of Probit regression:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac9d1cf34c6ba4bd208f6b80ec5f3c4f.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Where Φ() represents the cumulative distribution function of the standard normal
    distribution.
  prefs: []
  type: TYPE_NORMAL
- en: We can memorise this equation, but it will not clarify our concept related to
    the Probit regression. Therefore, we will adopt a different approach to gain a
    better understanding of how Probit regression works.
  prefs: []
  type: TYPE_NORMAL
- en: The basic concept behind Probit regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us say we have data on the weight and depression status of a sample of 1000
    individuals. Our objective is to examine the relationship between weight and depression
    using Probit regression. (Download the data from this [link](https://github.com/akifiips/Probit-Regression).
    )
  prefs: []
  type: TYPE_NORMAL
- en: To provide some intuition, let’s imagine that whether an individual (the “ith”
    individual) will experience depression or not depends on an unobservable latent
    variable, denoted as A*i*. This latent variable is influenced by one or more independent
    variables. In our scenario, the weight of an individual determines the value of
    the latent variable. The probability of experiencing depression increases with
    increase in the latent variable.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df5b70583fe819163df54b8af44e4b74.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: The question is, since A*i* is an unobserved latent variable, how do we estimate
    the parameters of the above equation? Well, if we assume that it is normally distributed
    with the same mean and variance, we will be able to obtain some information regarding
    the latent variable and estimate the model parameters. I will explain the equations
    in more detail later, but first, let’s perform some practical calculations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Coming back to our data: In our data, let us calculate the probability of depression
    for each age and tabulate it. For example, there are 7 people with a weight of
    40kg, and 1 of them has depression, so the probability of depression for weight
    40 is 1/7 = 0.14286\. If we do this for all weight, we will get this table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6a9562b9b557587aae7df55048005aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, how do we get the values of the latent variable? We know that the normal
    distribution gives the probability of Y for a given value of X. However, the inverse
    cumulative distribution function (CDF) of the normal distribution enables us to
    obtain the value of X for a given probability value. In this case, we already
    have the probability values, which means we can determine the corresponding value
    of the latent variable by using the inverse CDF of the normal distribution. [Note:
    Inverse Normal CDF function is available in almost every statistical software,
    including Excel.]'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cdb42364c72440473ae33791b277a51c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: This unobserved latent variable A*i* is known as normal equivalent deviate (n.e.d.)
    or simply **normit**. Looking closely, it is nothing but Z-scores associated with
    the unobserved latent variable. Once we have the estimated Ai, estimating β1 and
    β2 is relatively simple. We can run a simple linear regression between A*i* and
    our independent variable.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec220f56971134bc8a46bcb08a94b3f4.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: The coefficient of weight 0.0256 gives us the change in the z-score of the outcome
    variable (depression) associated with a one-unit change in weight. Specifically,
    a one-unit increase in weight is associated with an increase of approximately
    0.0256 z-score units in the likelihood of having high depression. We can calculate
    the probability of depression for any age using standard normal distribution.
    For example, for weight 70,
  prefs: []
  type: TYPE_NORMAL
- en: A*i* = -1.61279 + (0.02565)*70
  prefs: []
  type: TYPE_NORMAL
- en: A*i* = 0.1828
  prefs: []
  type: TYPE_NORMAL
- en: The probability associated with a z-score of 0.1828 (P(x<Z)) is 0.57; i.e. the
    predicted probability of depression for weight 70 is 0.57.
  prefs: []
  type: TYPE_NORMAL
- en: It is quite reasonable to say that the above explanation was an oversimplification
    of a moderately complex method. It is also important to note that it is just an
    illustration of the basic principle behind the use of cumulative normal distribution
    in Probit regression. Now, let us have a look at the mathematical equations.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical Structure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We discussed earlier that there exists a latent variable, A*i*, that is determined
    by the predictor variables. It will be very logical to consider that there exists
    a critical or threshold value (A*i*_c) of the latent variable such that if A*i*
    exceeds A*i*_c, the individual will have depression; otherwise, he/she will not
    have depression. Given the assumption of normality, the probability that A*i*
    is less than or equal to A*i*_c can be calculated from standardized normal CDF:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c216e27ff8f4ba06ab339d49eb614d29.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Where Z*i* is the standard normal variable, i.e., Z ∼ N(0, σ 2) and F is the
    standard normal CDF.
  prefs: []
  type: TYPE_NORMAL
- en: 'The information related to the latent variable and β1 and β2 can be obtained
    by taking the inverse of the above equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e738e781d358e44f5b3f08082b83167a.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: Inverse CDF of standardized normal distribution is used when we want to obtain
    the value of Z for a given probability value.
  prefs: []
  type: TYPE_NORMAL
- en: Now, the estimation process of β1, β2, and A*i* depends on whether we have grouped
    data or individual-level ungrouped data.
  prefs: []
  type: TYPE_NORMAL
- en: When we have grouped data, it is easy to calculate the probabilities. In our
    depression example, the initial data is ungrouped, i.e. there is weight for each
    individual and his/her status of depression (1 and 0). Initially, the total sample
    size was 1000, but we grouped that data by weight, resulting in 71 groups, and
    calculated the probability of depression in each weight group.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, when the data is ungrouped, the Maximum Likelihood Estimation (MLE)
    method is utilized to estimate the model parameters. The figure below shows the
    Probit regression on our ungrouped data (n = 1000):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6a9673fd95ca38165a07d2a39b89ce1d.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: It can be observed that the coefficient of weight is very close to what we estimated
    with the grouped data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Probit vs Logit**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have grasped the concept of Probit regression and are familiar
    (hopefully) with logistic regression, the question arises: which model is preferable?
    Which model performs better under different conditions? Well, both models are
    quite similar in their application and yield comparable results (in terms of predicted
    probabilities). The only minor distinction lies in their sensitivity to extreme
    values. Let’s take a closer look at both models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d8d4a3d10f4738dc60a343b8021486df.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  prefs: []
  type: TYPE_NORMAL
- en: From the plot, we can observe that the Probit and Logit models are quite similar.
    However, Probit is less sensitive to extreme values compared to Logit. It means
    that at extreme values, the change in probability of outcome with respect to unit
    change in the predictor variable is higher in the logit model compared to the
    Probit model. So, if you want your model to be sensitive at extreme values, you
    may prefer using logistic regression. However, this choice will not significantly
    affect the estimates, as both models yield similar results in terms of predicted
    probabilities. It is important to note that the coefficients obtained from both
    models represent different quantities and cannot be directly compared. Logit regression
    provides changes in the log odds of the outcome with changes in the predictor
    variable, while Probit regression provides changes in the z-score of the outcome.
    However, if we calculate the predicted probabilities of the outcome using both
    models, the results will be very similar.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, logistic regression is preferred over Probit regression because
    of its mathematical simplicity and easy interpretation of the coefficients.
  prefs: []
  type: TYPE_NORMAL
