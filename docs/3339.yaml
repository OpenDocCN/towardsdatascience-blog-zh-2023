- en: 'Back to the Basics: Probit Regression'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09](https://towardsdatascience.com/back-to-the-basics-probit-regression-ac05f4694d49?source=collection_archive---------5-----------------------#2023-11-09)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**A crucial method in binary outcome analysis**'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[![Akif
    Mustafa](../Images/1fb81af6fc0aeefedc1da59b3ba2b7ba.png)](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)[](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    [Akif Mustafa](https://medium.com/@akif.iips?source=post_page-----ac05f4694d49--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7ff7bb988de&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=post_page-7ff7bb988de----ac05f4694d49---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----ac05f4694d49--------------------------------)
    ·7 min read·Nov 9, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&user=Akif+Mustafa&userId=7ff7bb988de&source=-----ac05f4694d49---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fac05f4694d49&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fback-to-the-basics-probit-regression-ac05f4694d49&source=-----ac05f4694d49---------------------bookmark_footer-----------)![](../Images/cba21459a99759f2f68dd7f9ac9432f5.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Image by [Issac Smith](https://unsplash.com/@isaacmsmith) on [Unsplash](https://unsplash.com/photos/pen-on-paper-6EnTPvPPL6I)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we face any task related to analyzing binary outcomes, we often think
    of logistic regression as the go-to method. That’s why most articles about binary
    outcome regression focus exclusively on logistic regression. However, logistic
    regression is not the only option available. There are other methods, such as
    the Linear Probability Model (LPM), Probit regression, and Complementary Log-Log
    (Cloglog) regression. Unfortunately, there is a lack of articles on these topics
    available on the internet.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: The Linear Probability Model is rarely used because it is not very effective
    in capturing the curvilinear relationship between a binary outcome and independent
    variables. I have previously discussed [Cloglog regression](/a-gentle-introduction-to-complementary-log-log-regression-8ac3c5c1cd83)
    in one of my previous articles. While there are some articles on Probit regression
    available on the internet, they tend to be technical and difficult for non-technical
    readers to understand. In this article, we will explain the basic principles of
    Probit regression and its applications and compare it with logistic regression.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '**Background**'
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is how a relationship between a binary outcome variable and an independent
    variable typically looks:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6808504cc3f7a3e8253ac59265506e7.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'The curve you see is called an S-shaped curve or sigmoid curve. If we closely
    observe this plot, we’ll notice that it resembles a cumulative distribution function
    (CDF) of a random variable. Therefore, it makes sense to use the CDF to model
    the relationship between a binary outcome variable and independent variables.
    The two most commonly used CDFs are the logistic and the normal distributions.
    Logistic regression utilizes the logistic CDF, given with the following equation:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9bda309e68a1678272c519fcf3cd0a70.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: 'In Probit regression, we utilize the cumulative distribution function (CDF)
    of the normal distribution. Reasonably, we can just replace logistic CDF with
    normal distribution CDF to get the equation of Probit regression:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ac9d1cf34c6ba4bd208f6b80ec5f3c4f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Where Φ() represents the cumulative distribution function of the standard normal
    distribution.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: We can memorise this equation, but it will not clarify our concept related to
    the Probit regression. Therefore, we will adopt a different approach to gain a
    better understanding of how Probit regression works.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: The basic concept behind Probit regression
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us say we have data on the weight and depression status of a sample of 1000
    individuals. Our objective is to examine the relationship between weight and depression
    using Probit regression. (Download the data from this [link](https://github.com/akifiips/Probit-Regression).
    )
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: To provide some intuition, let’s imagine that whether an individual (the “ith”
    individual) will experience depression or not depends on an unobservable latent
    variable, denoted as A*i*. This latent variable is influenced by one or more independent
    variables. In our scenario, the weight of an individual determines the value of
    the latent variable. The probability of experiencing depression increases with
    increase in the latent variable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df5b70583fe819163df54b8af44e4b74.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: The question is, since A*i* is an unobserved latent variable, how do we estimate
    the parameters of the above equation? Well, if we assume that it is normally distributed
    with the same mean and variance, we will be able to obtain some information regarding
    the latent variable and estimate the model parameters. I will explain the equations
    in more detail later, but first, let’s perform some practical calculations.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 'Coming back to our data: In our data, let us calculate the probability of depression
    for each age and tabulate it. For example, there are 7 people with a weight of
    40kg, and 1 of them has depression, so the probability of depression for weight
    40 is 1/7 = 0.14286\. If we do this for all weight, we will get this table:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a6a9562b9b557587aae7df55048005aa.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, how do we get the values of the latent variable? We know that the normal
    distribution gives the probability of Y for a given value of X. However, the inverse
    cumulative distribution function (CDF) of the normal distribution enables us to
    obtain the value of X for a given probability value. In this case, we already
    have the probability values, which means we can determine the corresponding value
    of the latent variable by using the inverse CDF of the normal distribution. [Note:
    Inverse Normal CDF function is available in almost every statistical software,
    including Excel.]'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cdb42364c72440473ae33791b277a51c.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: This unobserved latent variable A*i* is known as normal equivalent deviate (n.e.d.)
    or simply **normit**. Looking closely, it is nothing but Z-scores associated with
    the unobserved latent variable. Once we have the estimated Ai, estimating β1 and
    β2 is relatively simple. We can run a simple linear regression between A*i* and
    our independent variable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ec220f56971134bc8a46bcb08a94b3f4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
- en: Image by the author
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: The coefficient of weight 0.0256 gives us the change in the z-score of the outcome
    variable (depression) associated with a one-unit change in weight. Specifically,
    a one-unit increase in weight is associated with an increase of approximately
    0.0256 z-score units in the likelihood of having high depression. We can calculate
    the probability of depression for any age using standard normal distribution.
    For example, for weight 70,
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: A*i* = -1.61279 + (0.02565)*70
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: A*i* = 0.1828
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: The probability associated with a z-score of 0.1828 (P(x<Z)) is 0.57; i.e. the
    predicted probability of depression for weight 70 is 0.57.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: It is quite reasonable to say that the above explanation was an oversimplification
    of a moderately complex method. It is also important to note that it is just an
    illustration of the basic principle behind the use of cumulative normal distribution
    in Probit regression. Now, let us have a look at the mathematical equations.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical Structure
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We discussed earlier that there exists a latent variable, A*i*, that is determined
    by the predictor variables. It will be very logical to consider that there exists
    a critical or threshold value (A*i*_c) of the latent variable such that if A*i*
    exceeds A*i*_c, the individual will have depression; otherwise, he/she will not
    have depression. Given the assumption of normality, the probability that A*i*
    is less than or equal to A*i*_c can be calculated from standardized normal CDF:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论过存在一个潜在变量A*i*，它由预测变量决定。考虑到潜在变量存在一个临界或阈值（A*i*_c）是很合逻辑的，即如果A*i*超过A*i*_c，则个体将会有抑郁症；否则，他/她将不会有抑郁症。假设正态分布的前提下，可以从标准化正态累积分布函数中计算A*i*小于或等于A*i*_c的概率：
- en: '![](../Images/c216e27ff8f4ba06ab339d49eb614d29.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c216e27ff8f4ba06ab339d49eb614d29.png)'
- en: Image by the author
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Where Z*i* is the standard normal variable, i.e., Z ∼ N(0, σ 2) and F is the
    standard normal CDF.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其中Z*i*是标准正态变量，即Z ∼ N(0, σ 2)，F是标准正态累积分布函数。
- en: 'The information related to the latent variable and β1 and β2 can be obtained
    by taking the inverse of the above equation:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 与潜在变量及β1和β2相关的信息可以通过对上述方程取逆得到：
- en: '![](../Images/e738e781d358e44f5b3f08082b83167a.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e738e781d358e44f5b3f08082b83167a.png)'
- en: Image by the author
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: Inverse CDF of standardized normal distribution is used when we want to obtain
    the value of Z for a given probability value.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要获得给定概率值的Z值时，会使用标准正态分布的逆累积分布函数。
- en: Now, the estimation process of β1, β2, and A*i* depends on whether we have grouped
    data or individual-level ungrouped data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，β1、β2和A*i*的估计过程取决于我们是否拥有分组数据或个体级别的未分组数据。
- en: When we have grouped data, it is easy to calculate the probabilities. In our
    depression example, the initial data is ungrouped, i.e. there is weight for each
    individual and his/her status of depression (1 and 0). Initially, the total sample
    size was 1000, but we grouped that data by weight, resulting in 71 groups, and
    calculated the probability of depression in each weight group.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有分组数据时，计算概率是很容易的。在我们的抑郁症例子中，初始数据是未分组的，即每个个体的权重及其抑郁状态（1和0）。最初，总样本量为1000，但我们按权重将数据分组，结果形成71个组，并计算了每个权重组中的抑郁概率。
- en: 'However, when the data is ungrouped, the Maximum Likelihood Estimation (MLE)
    method is utilized to estimate the model parameters. The figure below shows the
    Probit regression on our ungrouped data (n = 1000):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当数据未分组时，使用最大似然估计（MLE）方法来估计模型参数。下图显示了我们未分组数据（n = 1000）上的Probit回归：
- en: '![](../Images/6a9673fd95ca38165a07d2a39b89ce1d.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a9673fd95ca38165a07d2a39b89ce1d.png)'
- en: Image by the author
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: It can be observed that the coefficient of weight is very close to what we estimated
    with the grouped data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可以观察到，权重系数非常接近我们使用分组数据估计的结果。
- en: '**Probit vs Logit**'
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**Probit与Logit**'
- en: 'Now that we have grasped the concept of Probit regression and are familiar
    (hopefully) with logistic regression, the question arises: which model is preferable?
    Which model performs better under different conditions? Well, both models are
    quite similar in their application and yield comparable results (in terms of predicted
    probabilities). The only minor distinction lies in their sensitivity to extreme
    values. Let’s take a closer look at both models:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了Probit回归的概念，并且对逻辑回归（希望）也比较熟悉，问题来了：哪个模型更优？在不同条件下哪个模型表现更好？事实上，这两个模型在应用上非常相似，并且在预测概率方面的结果也相当接近。唯一的细微区别在于它们对极端值的敏感性。让我们更详细地了解这两个模型：
- en: '![](../Images/d8d4a3d10f4738dc60a343b8021486df.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d8d4a3d10f4738dc60a343b8021486df.png)'
- en: Image by the author
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: From the plot, we can observe that the Probit and Logit models are quite similar.
    However, Probit is less sensitive to extreme values compared to Logit. It means
    that at extreme values, the change in probability of outcome with respect to unit
    change in the predictor variable is higher in the logit model compared to the
    Probit model. So, if you want your model to be sensitive at extreme values, you
    may prefer using logistic regression. However, this choice will not significantly
    affect the estimates, as both models yield similar results in terms of predicted
    probabilities. It is important to note that the coefficients obtained from both
    models represent different quantities and cannot be directly compared. Logit regression
    provides changes in the log odds of the outcome with changes in the predictor
    variable, while Probit regression provides changes in the z-score of the outcome.
    However, if we calculate the predicted probabilities of the outcome using both
    models, the results will be very similar.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中我们可以观察到，Probit和Logit模型非常相似。然而，Probit对极端值的敏感性较低。这意味着在极端值下，预测变量单位变化对结果概率的影响在Logit模型中高于Probit模型。因此，如果你希望模型对极端值敏感，你可能会更倾向于使用逻辑回归。然而，这种选择不会显著影响估计结果，因为两种模型在预测概率方面产生的结果相似。需要注意的是，来自两种模型的系数表示的是不同的量，不能直接比较。Logit回归提供了结果与预测变量变化的对数赔率的变化，而Probit回归提供了结果的z-score的变化。然而，如果我们使用两种模型计算预测概率，结果将非常相似。
- en: In practice, logistic regression is preferred over Probit regression because
    of its mathematical simplicity and easy interpretation of the coefficients.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，逻辑回归因其数学简洁性和系数解释的方便性而优于Probit回归。
