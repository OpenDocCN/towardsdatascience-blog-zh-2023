- en: Monitoring unstructured data for LLM and NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/monitoring-unstructured-data-for-llm-and-nlp-efff42704e5b?source=collection_archive---------10-----------------------#2023-06-27](https://towardsdatascience.com/monitoring-unstructured-data-for-llm-and-nlp-efff42704e5b?source=collection_archive---------10-----------------------#2023-06-27)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A code tutorial on using text descriptors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@elena.samuylova?source=post_page-----efff42704e5b--------------------------------)[![Elena
    Samuylova](../Images/bc3024500f8b90a97f13d82ecaa1c9e7.png)](https://medium.com/@elena.samuylova?source=post_page-----efff42704e5b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----efff42704e5b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----efff42704e5b--------------------------------)
    [Elena Samuylova](https://medium.com/@elena.samuylova?source=post_page-----efff42704e5b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F9621354b583a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonitoring-unstructured-data-for-llm-and-nlp-efff42704e5b&user=Elena+Samuylova&userId=9621354b583a&source=post_page-9621354b583a----efff42704e5b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----efff42704e5b--------------------------------)
    ·14 min read·Jun 27, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fefff42704e5b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonitoring-unstructured-data-for-llm-and-nlp-efff42704e5b&user=Elena+Samuylova&userId=9621354b583a&source=-----efff42704e5b---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fefff42704e5b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmonitoring-unstructured-data-for-llm-and-nlp-efff42704e5b&source=-----efff42704e5b---------------------bookmark_footer-----------)![](../Images/9449b853160c4015be247a0c901aee69.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Once you deploy an NLP or LLM-based solution, you need a way to keep tabs on
    it. But how do you monitor unstructured data to make sense of the pile of texts?
  prefs: []
  type: TYPE_NORMAL
- en: There are a few approaches here, from [detecting drift in raw text data](https://www.evidentlyai.com/blog/tutorial-detecting-drift-in-text-data)
    and [embedding drift](https://www.evidentlyai.com/blog/embedding-drift-detection)
    to using regular expressions to run rule-based checks.
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, we’ll dive into one particular approach — tracking interpretable
    text descriptors that help assign specific properties to every text.
  prefs: []
  type: TYPE_NORMAL
- en: '**First, we’ll cover some theory:**'
  prefs: []
  type: TYPE_NORMAL
- en: What is a text descriptor, and when to use them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of text descriptors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to select custom descriptors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Next, get to code!** You will work with e-commerce review data and go through
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Get an overview of the text data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluate text data drift using standard descriptors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add a custom text descriptor using an external pre-trained model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement pipeline tests to monitor data changes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use the [Evidently open-source Python library](https://github.com/evidentlyai/evidently)
    to generate text descriptors and evaluate changes in the data.
  prefs: []
  type: TYPE_NORMAL
- en: '***Code example:*** *If you prefer to go straight to the code, here is the*
    [*example notebook*](https://github.com/evidentlyai/community-examples/blob/main/tutorials/How_to_add_a_custom_text_descriptor.ipynb)*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What is a text descriptor?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A text descriptor is any feature or property that describes objects in the text
    dataset. For example, the length of texts or the number of symbols in them.
  prefs: []
  type: TYPE_NORMAL
- en: You might already have helpful metadata to accompany your texts that will serve
    as descriptors. For example, e-commerce user reviews might come with user-assigned
    ratings or topic labels.
  prefs: []
  type: TYPE_NORMAL
- en: Otherwise, you can generate your own descriptors! You do this by adding “virtual
    features” to your text data. Each helps describe or classify your texts using
    some meaningful criteria.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4d3ad2d6d7d7d91249e42b8d12b13dec.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: By creating these descriptors, you basically come up with your own simple “embedding”
    and map each text to several interpretable dimensions. This helps make sense of
    the otherwise unstructured data.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then use these text descriptors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**To monitor production NLP models.** You can track the properties of your
    data in time and detect when they change. For example, descriptors help detect
    text length spikes or drift in sentiment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To test models during updates.** When you iterate on models, you can compare
    the properties of the evaluation datasets and model responses. For example, you
    can check that the lengths of the LLM-generated answers remain similar, and they
    consistently include words you expect to see.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**To debug data drift or model decay.** If you detect [embedding drift](https://www.evidentlyai.com/blog/embedding-drift-detection)
    or directly observe a drop in the model quality, you can use text descriptors
    to explore where it comes from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples of text descriptors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a few text descriptors we consider good defaults:'
  prefs: []
  type: TYPE_NORMAL
- en: Text length
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/184e6533f48040200fe1378cad612a11.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Image by Author. Text overview metric visualization using the* [*Evidently
    Python library*](https://github.com/evidentlyai/evidently)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: An excellent place to start is simple text statistics. For example, you can
    look at the **length of texts** measured in words, symbols, or sentences. You
    can evaluate average and min-max length and look at distributions.
  prefs: []
  type: TYPE_NORMAL
- en: You can set expectations based on your use case. Say, product reviews tend to
    be between 5 and 100 words. If they are shorter or longer, this might signal a
    change in context. If there is a spike in fixed-length reviews, this might signal
    a spam attack. If you know that negative reviews are often longer, you can track
    the share of reviews above a certain length.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also quick sanity checks: if you run a chatbot, you might expect
    non-zero responses or that there is some minimum length for the meaningful output.'
  prefs: []
  type: TYPE_NORMAL
- en: Out-of-vocabulary words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/a65c56974f1b1f3ae2d41514a07315b3.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author. *The mean OOV share in the example reference dataset is 5.378%.*
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating the share of words outside the defined vocabulary is a good “crude”
    measure of data quality. Did your users start writing reviews in a new language?
    Are users talking to your chatbot in Python, not English? Are users filling the
    responses with “ggg” instead of actual words?
  prefs: []
  type: TYPE_NORMAL
- en: This is a single practical measure to detect all sorts of changes. Once you
    catch a shift, you can then debug deeper.
  prefs: []
  type: TYPE_NORMAL
- en: You can shape expectations about the share of OOV words based on the examples
    from “good” production data accumulated over time. For example, if you look at
    the corpus of previous product reviews, you might expect OOV to be under 10% and
    monitor if the value goes above this threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Non-letter characters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Related, but with a twist: this descriptor will count all sorts of special
    symbols that are not letters or numbers, including commas, brackets, hashes, etc.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes you expect a fair share of special symbols: your texts might contain
    code or be structured as a JSON. Sometimes, you only expect punctuation marks
    in human-readable text.'
  prefs: []
  type: TYPE_NORMAL
- en: Detecting a shift in non-letter characters can expose data quality issues, like
    HTML codes leaking into the texts of the reviews, spam attacks, unexpected use
    cases, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0b6feb7078990f2fd42ebf4054b2cb2b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author. *Baseline “sentiment” distribution in the example e-commerce
    reviews dataset.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Text sentiment is another indicator. It is helpful in various scenarios: from
    chatbot conversations to user reviews and writing marketing copy. You can typically
    set an expectation about the sentiment of the texts you deal with.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Even if the sentiment “does not apply,” this might translate to the expectation
    of a primarily neutral tone. The potential appearance of either a negative or
    positive tone is worth tracking and looking into. It might indicate unexpected
    usage scenarios: is the user using your virtual mortgage advisor as a complaint
    channel?'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might also expect a certain balance: for example, there is always a share
    of conversations or reviews with a negative tone, but you’d expect it not to exceed
    a certain threshold or the overall distribution of review sentiment to remain
    stable.'
  prefs: []
  type: TYPE_NORMAL
- en: Trigger words
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/b8cb44f8a4202672b43ca925422086b8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Image by Author. *Reviews consistently mention dresses: no distribution drift
    is detected.*'
  prefs: []
  type: TYPE_NORMAL
- en: You can also check whether the texts contain words from a specific list or lists
    and treat this as a binary feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a powerful way to encode multiple expectations about your texts. You
    need some effort to curate lists manually, but you can design many handy checks
    this way. For example, you can create lists of trigger words like:'
  prefs: []
  type: TYPE_NORMAL
- en: Mentions of products or brands.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mentions of competitors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mentions of locations, cities, places, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mentions of words that represent particular topics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can curate (and continuously extend) lists like this that are specific to
    your use case.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if an advisor chatbot helps choose between products offered by
    the company, you might expect most of the responses to contain the names of one
    of the products from the list.
  prefs: []
  type: TYPE_NORMAL
- en: RegExp matches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The inclusion of specific words from the list is one example of a pattern you
    can formulate as a regular expression. You can come up with others: do you expect
    your texts to start with “hello” and end with “thank you”? Include emails? Contain
    known named elements?'
  prefs: []
  type: TYPE_NORMAL
- en: If you expect the model inputs or outputs to match a specific format, you can
    use regular expression match as another descriptor.
  prefs: []
  type: TYPE_NORMAL
- en: Custom descriptors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can extend this idea further. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Evaluate other text properties**: toxicity, subjectivity, the formality of
    the tone, readability score, etc. You can often find open pre-trained models to
    do the trick.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Count specific components:** emails, URLs, emojis, dates, and parts of speech.
    You can use external models or even simple regular expressions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Get granular with stats:** you can track very detailed text statistics if
    they are meaningful to your use case, e.g., track average lengths of words, whether
    they are upper or lower case, the ratio of unique words, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor personally identifiable information**: for example, when you do not
    expect it to come up in chatbot conversations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use named entity recognition:** to extract specific entities and treat them
    as tags. **‍**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use topic modeling** to build a topic monitoring system. This is the most
    laborious approach but powerful when done right. It is useful when you expect
    the texts to stay mostly on-topic and have the corpus of previous examples to
    train the model. You can use unsupervised topic clustering and create a model
    to assign new texts to known clusters. You can then treat assigned classes as
    descriptors to monitor the changes in the distribution of topics in the new data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/56ae75356635ea5aebe10c8b079438e6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author. *Example of a summary drift report for multiple descriptors.*
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few things to keep in mind when designing descriptors to monitor:'
  prefs: []
  type: TYPE_NORMAL
- en: '**It is best to stay focused** and try to find a small number of suitable quality
    indicators that match the use case rather than monitor all possible dimensions.
    Think of descriptors as model features. You want to find a few strong ones rather
    than generate a lot of weak or unhelpful features. Many of them are bound to be
    correlated: language and share of OOV words, length in sentences and symbols,
    etc. Pick your favorite!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Use exploratory data analysis** to evaluate text properties in existing data
    (for example, logs of previous conversations) to test your assumptions before
    adding them to model monitoring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Learn from model failures**. Whenever you face an issue with production model
    quality that you expect to reappear (e.g., texts in a foreign language), consider
    how to develop a test case or a descriptor to add to detect it in the future.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mind the computation cost.** Using external models to score your texts by
    every possible dimension is tempting, but this comes at a cost. Consider it when
    working with larger datasets: every external classifier is an extra model to run.
    You can often get away with fewer or simpler checks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step-by-step tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To illustrate the idea, let’s walk through the following scenario: you are
    building a classifier model to score reviews that users leave on an e-commerce
    website and tag them by topic. Once it is in production, you want to detect changes
    in the data and model environment, but you do not have the true labels. You need
    to run a separate labeling process to get them.'
  prefs: []
  type: TYPE_NORMAL
- en: How can you keep tabs on the changes without the labels?
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take an example dataset and go through the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '***Code example:*** *head to the* [*example notebook*](https://github.com/evidentlyai/community-examples/blob/main/tutorials/How_to_add_a_custom_text_descriptor.ipynb)
    *to follow all the steps.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 💻 1\. Install Evidently
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, install Evidently. Use the Python package manager to install it in your
    environment. If you are working in Colab, run *!pip install*. In the Jupyter Notebook,
    you should also install nbextension. Check out the [instructions](https://docs.evidentlyai.com/user-guide/install-evidently/?utm_source=website&utm_medium=referral&utm_campaign=blog_text&utm_content=unstructured-data-monitoring)
    for your environment.
  prefs: []
  type: TYPE_NORMAL
- en: You will also need to import a few other libraries like *pandas* and specific
    Evidently components. Follow the instructions in the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: 🔡 2\. Prepare the data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you have it all set, let’s look at the data! You will work with an open
    dataset from e-commerce reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how the dataset looks:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/61dc47d6fb8c0c43b9c82d3180b95766.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll focus on the “Review_Text” column for demo purposes. In production, we
    want to monitor changes in the texts of the reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will need to specify the column that contains texts using column mapping:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You should also split the data into two: reference and current. Imagine that
    “reference” data is the data for some representative past period (e.g., previous
    month) and “current” is the current production data (e.g., this month). These
    are the two datasets that you will compare using descriptors.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Note:*** *it’s important to establish a suitable historical baseline. Pick
    the period that reflects your expectations about how the data should look in the
    future.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We selected 5000 examples for each sample. To make things interesting, we introduced
    an artificial shift by selecting the negative reviews for our current dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 📊 3\. Exploratory data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To better understand the data, you can generate a visual report using Evidently.
    There is a pre-built **Text Overview Preset** that helps quickly compare two text
    datasets. It combines various descriptive checks and evaluates overall data drift
    (in this case, using a [model-based drift detection method](https://www.evidentlyai.com/blog/evidently-data-quality-monitoring-and-drift-detection-for-text-data)).
  prefs: []
  type: TYPE_NORMAL
- en: 'This report also includes a few standard descriptors and allows you to add
    descriptors using lists of Trigger Words. We’ll look at the following descriptors
    as part of the report:'
  prefs: []
  type: TYPE_NORMAL
- en: Length of texts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Share of OOV words
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Share of Non-letter symbols
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sentiment of the reviews
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviews that include either words “dress” or “gown”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviews that include either words “blouse” or “shirt”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Check out the Evidently* [*docs on Descriptors for details*](https://docs.evidentlyai.com/user-guide/customization/text-descriptors-parameters/?utm_source=website&utm_medium=referral&utm_campaign=blog_text&utm_content=unstructured-data-monitoring)*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here is the code you need to run this report. You can assign custom names to
    each descriptor.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Running a report like this helps explore patterns and shape your expectations
    about particular properties, such as text length distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The distribution of the “sentiment” descriptor quickly exposes the trick we
    did when splitting the data. We put reviews with a ranking above 3 in “reference”
    and more negative reviews in “current” datasets. The results are visible:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6f0128ec9976fe67cdfb3d79e3cd4b2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The default report is very comprehensive and helps look at many text properties
    at once. Up to exploring correlations between descriptors and other columns in
    the dataset!
  prefs: []
  type: TYPE_NORMAL
- en: You can use it during the exploratory phase, but this is probably not something
    you’d need to go through all the time.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, it’s easy to customize.
  prefs: []
  type: TYPE_NORMAL
- en: '***Evidently Presets and Metrics****. Evidently has report presets that quickly
    generate the reports out of the box. However, there are a lot of individual metrics
    to choose from! You can combine them to create a custom report. Browse the* [*presets*](https://docs.evidentlyai.com/presets/all-presets/?utm_source=website&utm_medium=referral&utm_campaign=blog_text&utm_content=unstructured-data-monitoring)
    *and metrics to understand what’s there.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 📈 4\. Monitor descriptors drift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s say that based on exploratory analysis and your understanding of the
    business problem, you decide only to track a small number of properties:'
  prefs: []
  type: TYPE_NORMAL
- en: 'You want to notice when there is a statistical change: the distributions of
    these properties differ from the reference period. To detect it, you can use drift
    detection methods implemented in Evidently. For example, for numerical features
    like “sentiment,” it will, by default, monitor the shift using Wasserstein distance.
    You can also choose a different method.'
  prefs: []
  type: TYPE_NORMAL
- en: Here is how you can create a simple drift report to track changes in the three
    descriptors.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you run the report, you will get combined visualizations for all chosen
    descriptors. Here is one:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/167750d2843c66fe380500152b7584da.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The dark green line is the mean sentiment in the reference dataset. The green
    area covers one standard deviation from the mean. You can notice that the current
    distribution (in red) is visibly more negative.
  prefs: []
  type: TYPE_NORMAL
- en: '***Note:*** *In this scenario, it also makes sense to monitor the output drift:
    by tracking shifts in the predicted classes. You can use categorical* [*data drift
    detection methods*](https://docs.evidentlyai.com/reference/data-drift-algorithm/?utm_source=website&utm_medium=referral&utm_campaign=blog_text&utm_content=unstructured-data-monitoring)*,
    like JS divergence. We do not cover this in the tutorial, as we focus only on
    inputs and do not generate predictions. In practice, prediction drift is often
    the first signal to react to.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 😍 5\. Add an “emotion” descriptor
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s say you decided to track one more meaningful property: the emotion expressed
    in the review. The overall sentiment is one thing, but it also helps distinguish
    between “sad” and “angry” reviews, for example.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s add this custom descriptor! You can find an appropriate external open-source
    model to score your dataset. Then, you will work with this property as an additional
    column.
  prefs: []
  type: TYPE_NORMAL
- en: We will take the [Distilbert model](https://huggingface.co/bhadresh-savani/distilbert-base-uncased-emotion)
    from Huggingface, which classifies the text by five emotions.
  prefs: []
  type: TYPE_NORMAL
- en: You can consider using any other model for your use case, such as named entity
    recognition, language detection, toxicity detection, etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'You must install transformers to be able to run the model. Check [the instructions](https://huggingface.co/docs/transformers/installation)
    for more details. Then, apply it to the review dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '***Note:*** *this step will score the dataset using the external model. It
    will take some time to execute, depending on your environment. To understand the
    principle without waiting, refer to the “Simple Example” section in the example
    notebook.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: After you add the new column “emotion” to the dataset, you must reflect this
    in Column Mapping. You should specify that it is a new categorical variable in
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Now, you can add the “emotion” distribution drift monitoring to the Report.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here is what you get!
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8ca2d594a2f48d88dec8b624c5ca703b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: You can see a significant increase in “sad” reviews and a decrease in “joy.”
  prefs: []
  type: TYPE_NORMAL
- en: Does it appear helpful to track over time? You can continue running this check
    by scoring new data as it comes.
  prefs: []
  type: TYPE_NORMAL
- en: 🏗️ 6\. Run pipeline tests
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To perform regular analysis of your data inputs, it makes sense to package the
    evaluations as tests. You get a clear “pass” or “fail” result in this scenario.
    You probably do not need to look at the plots if all tests pass. You’re only interested
    when things change!
  prefs: []
  type: TYPE_NORMAL
- en: Evidently has an alternative interface called Test Suite that works this way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how you create a Test Suite to check for statistical distribution in
    the same four descriptors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '***Note:*** *we go with defaults, but you can also set* [*custom drift methods
    and conditions*](https://docs.evidentlyai.com/user-guide/customization/options-for-statistical-tests/?utm_source=website&utm_medium=referral&utm_campaign=blog_text&utm_content=unstructured-data-monitoring)*.*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here is the result. The output is neatly structured so you can see which descriptors
    have drifted.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/77d27b490b8c0aa4b642b8509c854d7e.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting statistical distribution drift is one of the ways to monitor changes
    in the text property. There are others! Sometimes, it is convenient to run rule-based
    expectations on the descriptor’s min, max, or mean values.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you want to check that all review texts are longer than two words.
    If at least one review is shorter than two words, you want the test to fail and
    see the number of short texts in the response.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how you do that! You can pick a **TestNumberOfOutRangeValues()** check.
    This time, you should set a custom boundary: the “left” side of the expected range
    is two words. You must also set a test condition: **eq=0**. This means you expect
    the number of objects outside this range to be 0\. If it is higher, you want the
    test to return a fail.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Here is the result. You can also see the test details that show the defined
    expectation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c7522aa55016dfa55e61e8499366d7d2.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: You can follow this principle to design other checks.
  prefs: []
  type: TYPE_NORMAL
- en: Support Evidently
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Enjoyed the tutorial? Star* [*Evidently on GitHub*](https://github.com/evidentlyai/evidently)
    *to contribute back! This helps us continue creating free, open-source tools and
    content for the community.* [*⭐️ Star on GitHub ⟶*](https://github.com/evidentlyai/evidently)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Summing up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Text descriptors map text data to interpretable dimensions you can express as
    a numerical or a categorical attribute. They help describe, evaluate, and monitor
    unstructured data.
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, you learned how to monitor text data using descriptors.
  prefs: []
  type: TYPE_NORMAL
- en: You can use this approach to monitor the behavior of NLP and LLM-powered models
    production. You can customize and combine your descriptors with other methods,
    such as [monitoring embedding drift](https://www.evidentlyai.com/blog/embedding-drift-detection).
  prefs: []
  type: TYPE_NORMAL
- en: Are there other descriptors you consider universally useful? Let us know! Join
    our [Discord community](https://discord.com/invite/xZjKRaNp8b) to share your thoughts.
  prefs: []
  type: TYPE_NORMAL
- en: '*Originally published at* [*https://www.evidentlyai.com*](https://www.evidentlyai.com/blog/unstructured-data-monitoring)
    *on June 27, 2023\. Thanks to* [*Olga Filippova*](https://www.evidentlyai.com/author/olga-fillipova)
    *for co-authoring the article.*'
  prefs: []
  type: TYPE_NORMAL
