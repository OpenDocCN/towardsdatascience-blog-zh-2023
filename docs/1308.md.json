["```py\ngit clone https://github.com/triton-inference-server/fastertransformer_backend.git\ncd fastertransformer_backend && git checkout -b t5_gptj_blog remotes/origin/dev/t5_gptj_blog\n```", "```py\ndocker build --rm  --build-arg TRITON_VERSION=22.03 -t triton_with_ft:22.03 -f docker/Dockerfile .\ncd ../\n```", "```py\ndocker run -it --rm --gpus=all --shm-size=4G  -v $(pwd):/ft_workspace -p 8888:8888 triton_with_ft:22.03 bash\n```", "```py\ngit clone https://github.com/NVIDIA/FasterTransformer.git\n\nmkdir -p FasterTransformer/build && cd FasterTransformer/build\ngit submodule init && git submodule update\ncmake -DSM=xx -DCMAKE_BUILD_TYPE=Release -DBUILD_PYT=ON -DBUILD_MULTI_GPU=ON ..\n#I put -j8 below because my CPU has 8 cores.\n#Since this compilation can take some time, I recommend that you change this number to the number of cores your CPU has.\nmake -j8\n```", "```py\ncd ../../\nmkdir models\nwget https://the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.zstd\ntar -axf step_383500_slim.tar.zstd -C ./models/ \n```", "```py\ncd models\npip install nvidia-cuda-nvcc\npython3 ../FasterTransformer/examples/pytorch/gptj/utils/gptj_ckpt_convert.py --output-dir ./gptj6b_ckpt/ --ckpt-dir ./step_383500/ --n-inference-gpus 1\n```", "```py\npip install --upgrade \"jax[cuda11_local]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n```", "```py\n./FasterTransformer/build/bin/gpt_gemm 8 1 32 12 128 6144 51200 1 2\n```", "```py\nparameters {\n  key: \"tensor_para_size\"\n  value: {\n    string_value: \"1\"\n  }\n}\n```", "```py\nparameters {\n  key: \"model_checkpoint_path\"\n  value: {\n    string_value: \"./models/gptj6b_ckpt/1-gpu/\"\n  }\n}\n```", "```py\nCUDA_VISIBLE_DEVICES=0 /opt/tritonserver/bin/tritonserver  --model-repository=./triton-model-store/mygptj/ &\n```", "```py\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg\n\n#Add the official GPG key\nsudo mkdir -m 0755 -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\n#Set up the repository\necho \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" |  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n\n#Update again\nsudo apt-get update\n\n#Then we can finally install docker\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n#Optional: If you run Ubuntu under WSL2, you may need to start Docker manually\nsudo service docker start\n\n#If everything is properly installed, this should work\nsudo docker run hello-world\n```", "```py\n#Add the repository\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\\n      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\\n            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n\n#Get and install the nvidia container toolkit\nsudo apt-get update\nsudo apt-get install -y nvidia-container-toolkit\n\n#Restart docker\nsudo systemctl restart docker\n\n#or run \"sudo service docker start\" if you use WSL2\n```"]