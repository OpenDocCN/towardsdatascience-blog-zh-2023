["```py\nfrom pyscipopt import Model, quicksum\nimport numpy as np\nimport pickle\n\nrnd = np.random\nmodels_output = []\nfor k in range(1000):\n    info = {}\n    np.random.seed(k)\n    n_dc = 100\n    n_cus = 200\n    c = []\n    loc_x_dc = rnd.rand(n_dc)*100\n    loc_y_dc = rnd.rand(n_dc)*100\n    loc_x_cus = rnd.rand(n_cus)*100\n    loc_y_cus = rnd.rand(n_cus)*100\n    xy_dc = [[x,y] for x,y in zip(loc_x_dc,loc_y_dc)]\n    xy_cus = [[x,y] for x,y in zip(loc_x_cus,loc_y_cus)]\n    for i in xy_dc:\n        c_i = []\n        for j in xy_cus:\n            c_i.append(np.sqrt((i[0]-j[0])**2 + (i[1]-j[1])**2)*0.01)\n        c.append(c_i)    \n\n    f= []\n    m = []\n    d = []\n\n    for i in range(n_dc):\n        f_rand = np.round(np.random.normal(100,15))\n        if f_rand < 40:\n            f.append(40)\n        else:\n            f.append(f_rand)\n        m_rand = np.round(np.random.normal(70,10))\n        if m_rand < 30:\n            m.append(30)\n        else:\n            m.append(m_rand)\n    for i in range(n_cus):\n        d_rand = np.round(np.random.normal(20,5))\n        if d_rand < 5:\n            d.append(5)\n        else:\n            d.append(d_rand)\n\n    f = np.array(f)\n    m = np.array(m)\n    d = np.array(d)\n    c = np.array(c)\n\n    model = Model(\"facility selection\")\n    x,y = {},{}\n    x_names = ['x_'+str(i)+'_'+str(j) for i in range(n_dc) for j in range(n_cus)]\n    y_names = ['y_'+str(i) for i in range(n_dc)]\n    for i in range(n_dc):\n        for j in range(n_cus):\n            x[i,j] = model.addVar(name=x_names[i*n_cus+j])\n    for i in range(n_dc):\n        y[i] = model.addVar(name=y_names[i],vtype='BINARY')\n    model.setObjective(quicksum(f[i]*y[i] for i in range(n_dc))+quicksum(c[i,j]*x[i,j] for i in range(n_dc) for j in range(n_cus)), 'minimize')\n    for j in range(n_cus):\n        model.addCons(quicksum(x[i,j] for i in range(n_dc)) == d[j])\n    for i in range(n_dc):\n        model.addCons(quicksum(x[i,j] for j in range(n_cus)) <= m[i]*y[i])\n    model.optimize()\n\n    y_sol = []\n    for i in range(n_dc):\n        y_sol.append(model.getVal(y[i]))\n    x_sol = []\n    for i in range(n_dc):\n        x_i = []\n        for j in range(n_cus):\n            x_i.append(model.getVal(x[i,j]))\n        x_sol.append(x_i)\n    obj_vol = model.getObjVal()\n\n    info['f'] = f\n    info['m'] = m\n    info['d'] = d\n    info['c'] = c\n    info['y'] = y_sol\n    info['x'] = x_sol\n    info['obj'] = obj_vol\n    info['xy_dc'] = xy_dc\n    info['xy_cus'] = xy_cus\n    models_output.append(info)\n\nwith open('models_output.pkl', 'wb') as outp:\n    pickle.dump(models_output, outp)\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nimport torch\n\nwith open('models_output.pkl', 'rb') as f:\n    models_output = pickle.load(f)\n\ndef convert_coord(xy):\n    r = np.sqrt((xy[0]-50)**2 + (xy[1]-50)**2)\n    theta = np.arctan2(xy[1],xy[0])\n    return [theta, r]\n\ndataset = []\nfor k in range(len(models_output)):\n    data = {}\n    xy_site = []\n    new_xy_dc = [convert_coord(i) for i in models_output[k]['xy_dc']]\n    new_xy_cus = [convert_coord(i) for i in models_output[k]['xy_cus']]\n    xy_site.extend(new_xy_dc)\n    xy_site.extend(new_xy_cus)\n    d_site = []\n    d_site.extend([[i] for i in models_output[k]['m']])\n    d_site.extend([[i] for i in models_output[k]['d']])\n    f_site = []\n    f_site.extend([[i] for i in models_output[k]['f']])\n    f_site.extend([[0] for i in range(200)])\n    i_site = []\n    i_site.extend([[0] for i in range(100)])\n    i_site.extend([[1] for i in range(200)])\n    x = np.concatenate((xy_site, d_site), axis=1)\n    x = np.concatenate((x, f_site), axis=1)\n    x = np.concatenate((x, i_site), axis=1)\n    if k == 0:\n        scaler_x = MinMaxScaler()\n        x = scaler_x.fit_transform(x)\n    else:\n        x = scaler_x.transform(x)\n    x = np.expand_dims(x,axis=1)\n    y = []\n    y_cus = [2 for i in range(200)]\n    y.extend(models_output[k]['y'])\n    y.extend(y_cus)\n    x = torch.from_numpy(x).float()\n    y = torch.from_numpy(np.array(y)).long()\n    data['x'] = x\n    data['y'] = y\n    dataset.append(data)\n    mask = []\n    mask_true = [True for i in range(100)]\n    mask_false = [False for i in range(200)]\n    mask.extend(mask_true)\n    mask.extend(mask_false)\n```", "```py\nimport torch\nfrom torch import nn, Tensor\nimport torch.nn.functional as F\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\n\nclass TransformerModel(nn.Module):\n    def __init__(self, n_class=2, d_input=5, d_model=256, nhead=8, d_hid=256, nlayers=3, dropout=0.5):\n        super().__init__()\n        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n        self.d_model = d_model\n        self.encoder = nn.Linear(d_input, d_model)\n        self.decoder = nn.Linear(d_model, n_class)\n\n        self.init_weights()\n\n    def init_weights(self) -> None:\n        initrange = 0.1\n        self.decoder.weight.data.uniform_(-initrange, initrange)\n\n    def forward(self, src: Tensor) -> Tensor:\n        src = self.encoder(src)\n        output = self.transformer_encoder(src)\n        output = self.decoder(output)\n        return output\n```", "```py\nimport torch.optim as optim\n\ndef acc(y_pred, y_test):\n    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n    correct_pred = (y_pred_tags == y_test).float()\n    acc = correct_pred.sum() / len(correct_pred)\n    return acc\n\nLEARNING_RATE = 0.0001\nEPOCHS = 100\nmodel = TransformerModel()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nn_class = 2\n\nfor e in range(1,EPOCHS+1):\n    model.train()\n    e_train_loss = []\n    e_train_acc = []\n    for i in range(560):\n        optimizer.zero_grad()\n        y_pred = model(dataset[i]['x'])\n        train_loss = criterion(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n        train_acc = acc(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n        train_loss.backward()\n        optimizer.step()\n        e_train_loss.append(train_loss.item())\n        e_train_acc.append(train_acc.item())\n    with torch.no_grad():\n        model.eval()\n        e_val_loss = []\n        e_val_acc = []\n        for i in range(560,800):\n            y_pred = model(dataset[i]['x'])\n            val_loss = criterion(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n            val_acc = acc(y_pred.view(-1,n_class)[mask], dataset[i]['y'][mask])\n            e_val_loss.append(val_loss.item())\n            e_val_acc.append(val_acc.item())\n    print('epoch:', e)\n    print('train loss:', np.mean(e_train_loss))\n    print('train acc:', np.mean(e_train_acc)) \n    print('val loss:', np.mean(e_val_loss))\n    print('val acc:', np.mean(e_val_acc))\n\ntorch.save(model.state_dict(), desired_path)\n```", "```py\nimport time\nfrom bisect import bisect\n\ndef resolve_infeasibility(m,f,d,y):\n    idx = np.arange(len(y))\n    idx = idx[y==0]\n    m = m[idx]\n    f = f[idx]\n    r = f/m\n    r_idx = np.argsort(r)\n    m_sort = m[r_idx]\n    idx = idx[r_idx]\n    m_sort_sum = np.cumsum(m_sort)\n    up_to_idx = bisect(m_sort_sum,d)\n    idx = idx[:up_to_idx+1]\n    for i in idx:\n        y[i] = 1\n    return y\n\ntransformer_model = TransformerModel()\ntransformer_model.load_state_dict(torch.load(desired_path))\n\nobj_transformer = []\ngap_transformer = []\ntime_transformer = []\nobj_original = []\ngap_original = []\ntime_original = []\n\nrnd = np.random\n\nfor k in range(800,900):\n    np.random.seed(k)\n    n_dc = 100\n    n_cus = 200\n    c = []\n    loc_x_dc = rnd.rand(n_dc)*100\n    loc_y_dc = rnd.rand(n_dc)*100\n    loc_x_cus = rnd.rand(n_cus)*100\n    loc_y_cus = rnd.rand(n_cus)*100\n    xy_dc = [[x,y] for x,y in zip(loc_x_dc,loc_y_dc)]\n    xy_cus = [[x,y] for x,y in zip(loc_x_cus,loc_y_cus)]\n    for i in xy_dc:\n        c_i = []\n        for j in xy_cus:\n            c_i.append(np.sqrt((i[0]-j[0])**2 + (i[1]-j[1])**2)*0.01)\n        c.append(c_i)    \n\n    f= []\n    m = []\n    d = []\n\n    for i in range(n_dc):\n        f_rand = np.round(np.random.normal(100,15))\n        if f_rand < 40:\n            f.append(40)\n        else:\n            f.append(f_rand)\n        m_rand = np.round(np.random.normal(70,10))\n        if m_rand < 30:\n            m.append(30)\n        else:\n            m.append(m_rand)\n    for i in range(n_cus):\n        d_rand = np.round(np.random.normal(20,5))\n        if d_rand < 5:\n            d.append(5)\n        else:\n            d.append(d_rand)\n\n    f = np.array(f)\n    m = np.array(m)\n    d = np.array(d)\n    c = np.array(c)\n\n    start_time = time.time()\n    model = Model(\"facility selection\")\n    x,y = {},{}\n    x_names = ['x_'+str(i)+'_'+str(j) for i in range(n_dc) for j in range(n_cus)]\n    y_names = ['y_'+str(i) for i in range(n_dc)]\n    for i in range(n_dc):\n        for j in range(n_cus):\n            x[i,j] = model.addVar(name=x_names[i*n_cus+j])\n    for i in range(n_dc):\n        y[i] = model.addVar(name=y_names[i],vtype='BINARY')\n    model.setObjective(quicksum(f[i]*y[i] for i in range(n_dc))+quicksum(c[i,j]*x[i,j] for i in range(n_dc) for j in range(n_cus)), 'minimize')\n    for j in range(n_cus):\n        model.addCons(quicksum(x[i,j] for i in range(n_dc)) == d[j])\n    for i in range(n_dc):\n        model.addCons(quicksum(x[i,j] for j in range(n_cus)) <= m[i]*y[i])\n    model.optimize()\n    time_original.append(time.time()-start_time)\n    obj_original.append(model.getObjVal())\n    gap_original.append(model.getGap())\n\n    start_time = time.time()\n    xy_site = []\n    new_xy_dc = [convert_coord(i) for i in xy_dc]\n    new_xy_cus = [convert_coord(i) for i in xy_cus]\n    xy_site.extend(new_xy_dc)\n    xy_site.extend(new_xy_cus)\n    d_site = []\n    d_site.extend([[i] for i in m])\n    d_site.extend([[i] for i in d])\n    f_site = []\n    f_site.extend([[i] for i in f])\n    f_site.extend([[0] for i in range(200)])\n    i_site = []\n    i_site.extend([[0] for i in range(100)])\n    i_site.extend([[1] for i in range(200)])\n    x = np.concatenate((xy_site, d_site), axis=1)\n    x = np.concatenate((x, f_site), axis=1)\n    x = np.concatenate((x, i_site), axis=1)\n    x = scaler_x.transform(x)\n    x = np.expand_dims(x,axis=1)\n    x = torch.from_numpy(x).float()\n\n    transformer_model.eval()\n    y_pred = transformer_model(x)\n    y_pred_softmax = torch.log_softmax(y_pred.view(-1,2)[mask], dim = 1)\n    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n    if np.sum(m*y_pred_tags.numpy()) < np.sum(d):\n        y_pred_corrected = resolve_infeasibility(m,f,np.sum(d)-np.sum(m*y_pred_tags.numpy()),y_pred_tags.numpy())\n    else:\n        y_pred_corrected = y_pred_tags.numpy()\n\n    model = Model(\"facility selection with transformer\")\n    x,y = {},{}\n    x_names = ['x_'+str(i)+'_'+str(j) for i in range(n_dc) for j in range(n_cus)]\n    y_names = ['y_'+str(i) for i in range(n_dc)]\n    for i in range(n_dc):\n        for j in range(n_cus):\n            x[i,j] = model.addVar(name=x_names[i*n_cus+j])\n\n    for i in range(n_dc):\n        if y_pred_corrected[i] == 1:\n            y[i] = model.addVar(name=y_names[i],vtype='BINARY',lb=1)\n        else:\n            y[i] = model.addVar(name=y_names[i],vtype='BINARY',ub=0)\n    model.setObjective(quicksum(f[i]*y[i] for i in range(n_dc))+quicksum(c[i,j]*x[i,j] for i in range(n_dc) for j in range(n_cus)), 'minimize')\n    for j in range(n_cus):\n        model.addCons(quicksum(x[i,j] for i in range(n_dc)) == d[j])\n    for i in range(n_dc):\n        model.addCons(quicksum(x[i,j] for j in range(n_cus)) <= m[i]*y[i])\n    model.optimize()\n    time_transformer.append(time.time()-start_time)\n    obj_transformer.append(model.getObjVal())\n    gap_transformer.append(model.getGap())\n```", "```py\n f = []\nm = []\nd = []\n\nfor i in range(n_dc):\n    f_rand = np.round(np.random.normal(200,30))\n    if f_rand < 80:\n        f.append(80)\n    else:\n        f.append(f_rand)\n    m_rand = np.round(np.random.normal(140,20))\n    if m_rand < 60:\n        m.append(60)\n    else:\n        m.append(m_rand)\nfor i in range(n_cus):\n    d_rand = np.round(np.random.normal(40,10))\n    if d_rand < 10:\n        d.append(10)\n    else:\n        d.append(d_rand)\n```", "```py\nf = []\nm = []\nd = []\n\nfor i in range(n_dc):\n    f_rand = np.round(np.random.normal(50,7.5))\n    if f_rand < 20:\n        f.append(20)\n    else:\n        f.append(f_rand)\n    m_rand = np.round(np.random.normal(35,5))\n    if m_rand < 15:\n        m.append(15)\n    else:\n        m.append(m_rand)\nfor i in range(n_cus):\n    d_rand = np.round(np.random.normal(10,2.5))\n    if d_rand < 3:\n        d.append(3)\n    else:\n        d.append(d_rand)\n```"]