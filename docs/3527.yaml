- en: Bias, Toxicity, and Jailbreaking Large Language Models (LLMs)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/bias-toxicity-and-jailbreaking-large-language-models-llms-37cd71a3048f?source=collection_archive---------5-----------------------#2023-11-28](https://towardsdatascience.com/bias-toxicity-and-jailbreaking-large-language-models-llms-37cd71a3048f?source=collection_archive---------5-----------------------#2023-11-28)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A review of recent research on concerning characteristics of LLMs
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://rachel-draelos.medium.com/?source=post_page-----37cd71a3048f--------------------------------)[![Rachel
    Draelos, MD, PhD](../Images/edc30d41f9fea7e57dcf0c44caf68165.png)](https://rachel-draelos.medium.com/?source=post_page-----37cd71a3048f--------------------------------)[](https://towardsdatascience.com/?source=post_page-----37cd71a3048f--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----37cd71a3048f--------------------------------)
    [Rachel Draelos, MD, PhD](https://rachel-draelos.medium.com/?source=post_page-----37cd71a3048f--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F209c0f742bcf&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-toxicity-and-jailbreaking-large-language-models-llms-37cd71a3048f&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=post_page-209c0f742bcf----37cd71a3048f---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----37cd71a3048f--------------------------------)
    ·17 min read·Nov 28, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F37cd71a3048f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-toxicity-and-jailbreaking-large-language-models-llms-37cd71a3048f&user=Rachel+Draelos%2C+MD%2C+PhD&userId=209c0f742bcf&source=-----37cd71a3048f---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F37cd71a3048f&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fbias-toxicity-and-jailbreaking-large-language-models-llms-37cd71a3048f&source=-----37cd71a3048f---------------------bookmark_footer-----------)![](../Images/7ca68df720b68138e8d971d351c51b49.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: The featured image is derived from the [Galton box video from Wikimedia Commons](https://en.wikipedia.org/wiki/File:Galton_box.webm)
    (Creative Commons Attribution-Share Alike 4.0 International license).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'CONTENT WARNING: This post contains examples of biased, toxic text generated
    by LLMs.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'This post provides a deep dive into recent research on bias, toxicity, and
    jailbreaking of large language models (LLMs), especially ChatGPT and GPT-4\. I’ll
    discuss the ethical guidelines companies are currently using in LLM development
    and the approaches they use to try to safeguard against generation of undesirable
    content. Then I’ll review recent research papers studying toxic content generation,
    jailbreaking, and bias from multiple angles: gender, race, medicine, politics,
    the workplace, and fiction.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文深入探讨了关于偏见、毒性以及大型语言模型（LLMs）越狱的最新研究，特别是ChatGPT和GPT-4。我将讨论公司在LLM开发中目前使用的伦理指南，以及它们为防止生成不良内容而采取的方法。然后，我将从多个角度审视近期研究论文，探讨毒性内容生成、越狱以及偏见：包括性别、种族、医学、政治、职场和虚构内容。
- en: Bias refers to prejudice in favor or or against a specific group, person, or
    thing, while toxicity refers to disrespectful, vulgar, rude, or harm-promoting
    content. LLMs are biased and have the capacity to generate toxic content because
    they are trained on vast quantities of Internet data, which unfortunately represents
    both the good and bad sides of humanity, including all of our biases and toxicity.
    Thankfully, developers of LLMs like OpenAI and Google have taken steps to reduce
    the chances of LLMs producing overtly biased or toxic content. However, as we
    will see, that doesn’t mean the models are…
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 偏见指的是对特定群体、个人或事物的偏向或歧视，而毒性则指的是不尊重、粗俗、无礼或有害的内容。大型语言模型（LLMs）存在偏见，并且有生成毒性内容的能力，因为它们是在大量的互联网数据上进行训练的，这些数据不幸地代表了人性的好与坏，包括我们的所有偏见和毒性。幸运的是，像OpenAI和Google这样的LLM开发者已经采取了措施，以减少LLM生成明显偏见或毒性内容的可能性。然而，正如我们将看到的，这并不意味着这些模型是……
