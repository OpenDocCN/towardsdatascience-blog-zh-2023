- en: 'Unleashing the Power of GPT-3: Fine-Tuning for Superhero Descriptions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4?source=collection_archive---------0-----------------------#2023-02-18](https://towardsdatascience.com/unleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4?source=collection_archive---------0-----------------------#2023-02-18)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Step-by-step guide for GPT-3 fine-tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)[![Olivier
    Caelen](../Images/5315295f68999af7c14b456694d19979.png)](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)
    [Olivier Caelen](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd7268030c8a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&user=Olivier+Caelen&userId=d7268030c8a8&source=post_page-d7268030c8a8----da35c90766c4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)
    Â·11 min readÂ·Feb 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fda35c90766c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&user=Olivier+Caelen&userId=d7268030c8a8&source=-----da35c90766c4---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda35c90766c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&source=-----da35c90766c4---------------------bookmark_footer-----------)![](../Images/d11e6869ddaac2af15c755bc2460aae9.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [h heyerlein](https://unsplash.com/@heyerlein?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Since the end of 2022, the launch of ChatGPT by OpenAI has been considered by
    many of us to be the iPhone moment of AI. However, OpenAIâ€™s chatbot is not the
    first generative AI text machine learning model and follows the launch of GPT-3,
    which was launched two years earlier.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI provides us with a ready-to-use GPT-3 trained model. Furthermore, a specific
    task can be fine-tuned on a smaller dataset. For example, suppose you want to
    create an email response generator specific to your company. First, you must collect
    a large amount of data about your particular business domain, such as customer
    email inquiries and responses. You can then use this data to fine-tune GPT-3 to
    learn your companyâ€™s specific language patterns and phrases. By fine-tuning GPT-3,
    creating a highly customized and specialized email response generator is possible,
    specifically tailored to the language patterns and words used in a particular
    business domain.
  prefs: []
  type: TYPE_NORMAL
- en: In this blog post, I will show you how to fine-tune GPT-3\. We will do this
    with python code and without assuming prior knowledge about GPT-3.
  prefs: []
  type: TYPE_NORMAL
- en: What is needed for fine-tuning?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike the GPT-2 model available for instance on Hugging Face (when this blog
    is written), we donâ€™t have direct access to the GPT-3 model. Therefore, you first
    need to get an API key from OpenAI and install the Python package *openai*, which
    can be quickly done via *pip*.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the API key from OpenAI:'
  prefs: []
  type: TYPE_NORMAL
- en: go to [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
    ,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: create an account,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: click on â€˜*Create new secret keyâ€™* and
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: do a copy of the key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The key is a long string of characters starting with â€˜sk-â€™. Make sure you keep
    it secret! Once you have your key, an easy way to get access to your key is to
    do the following in your terminal: (personally, for simplicity, I put it in my
    *.bachrc*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Using GPT-3 models has a cost. We need credits. At the time of this writing,
    when you create a new account, you get free credits to try out the tool. I donâ€™t
    know if this will continueâ€¦
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have our key and Python package, it is time to think about the data
    we need to fine-tune. First, we need a file of examples for fine-tuning, where
    each example is a *prompt* followed by the appropriate *completion*.
  prefs: []
  type: TYPE_NORMAL
- en: A superhero description generation tool
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '![](../Images/96f93f7ff3d3b406b69c8ec1a2ffb322.png)'
  prefs: []
  type: TYPE_IMG
- en: A superhero from DALL-E 2
  prefs: []
  type: TYPE_NORMAL
- en: We will build a tool for this demo to create descriptions of imaginary superheroes.
    In the end, the tool will receive the age, gender, and power of the superhero,
    and it will automatically produce a description of our superhero.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, after fine-tuning the model, all we have to say is
    â€™*40, woman, Healing ->*â€™, and we will automatically get a description from the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6cd099cf773d7c6e17b6b7f8867d23b5.png)'
  prefs: []
  type: TYPE_IMG
- en: This is what itâ€™s all about!! ğŸ˜ƒ
  prefs: []
  type: TYPE_NORMAL
- en: Creation of a synthetic set of data for fine-tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In some situations, you may have a data set you want to use for fine-tuning.
    But since I donâ€™t have one, letâ€™s see how to create a synthetic data set with
    the description of the superheroes directly from GPT-3\. The following code will
    give me a CSV file with examples of *prompts* and the corresponding *completions*.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Letâ€™s look at how this code works ğŸ§.
  prefs: []
  type: TYPE_NORMAL
- en: The variable *f_prompt* contains the following sentence where *{age}*, *{gender},*
    and *{power}* are missing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine a complete and detailed description of a {age}-year-old {gender} fictional
    character who has the superpower of {power}. Write out the entire description
    in a maximum of 100 words in great detail:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the first three *for* loops of the code, we iterate over different values
    of {age}, {gender}, and {power}. At each step of the loop, we replace the 3 missing
    variables with different values. Then we use the *openai.Completion.create* function
    to ask GPT to generate a response to our prompt.
  prefs: []
  type: TYPE_NORMAL
- en: The most important parameters of this function are
  prefs: []
  type: TYPE_NORMAL
- en: '*model*: The model used to generate the response. OpenAI offers four standard
    GPT-3 models (`ada`, `babbage`, `curie`, or `davinci`) that vary in size â€¦ and
    price of use. Here it is *davinci* â€” the biggest model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*prompt*: The prompt that we want to fulfill with GPT-3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*temperature*: The temperature is a number between 0 and 1 and controls how
    much randomness is in the output. We set the temperature to the maximum to allow
    the model to be as creative as possible in creating the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*max_tokens*: Defines the maximum length of the response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of this script, we have a Pandas table stored in the file *out_openai_completion.csv.*
    The two primary columns in this table that interest us are *sub_prompt* and *response_txt.*
  prefs: []
  type: TYPE_NORMAL
- en: The *sub_prompt* will be for exampleâ€˜*18, man, invisibilityâ€™.* It contains the
    three values that were replaced, separated by commas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *response_txt* contains the output of the GPT model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning the GPT model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following code retrieves the previously created file *out_openai_completion.csv*
    and uses *openai* to fine-tune a GPT-3 model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Letâ€™s take the time to understand this code as well ğŸ¤“!
  prefs: []
  type: TYPE_NORMAL
- en: First, the content of the file *out_openai_completion.csv* is loaded into the
    data frame *df*. As a reminder, in our task, if the user enters â€™40, female, healingâ€™,
    we want to have a description of a 40-year-old female character with the power
    of healing. To perform fine-tuning, it is necessary to provide GPT with examples
    of what the user might type and the corresponding desired response. In the data
    frame *df*, the columns *sub_prompt* and *response_txt* contain examples of input
    with the corresponding desired response. In the code above, we first extract these
    two colons and then rename them to *prompt* and *completion*, respectively. The
    resulting data frame is stored in a new file *prepared_data.csv* containing only
    these two columns.
  prefs: []
  type: TYPE_NORMAL
- en: 'This file *prepared_data.csv* looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The Python *subprocess.run()* function runs a command as a subprocess. It is
    often used to execute external programs as if they were run in a terminal.
  prefs: []
  type: TYPE_NORMAL
- en: We use *subprocess.run()* to execute â€˜*openai tools fine_tunes.prepare_dataâ€™*.
    This function takes the input file *prepared_data.csv*, checks that the data are
    correct, and produces a JSONL file called *prepared_data_prepared.jsonl*. A JSONL
    file is a format that stores each JSON object on a separate line. JSONL files
    contain a sequence of JSON objects, each separated by a newline character.
  prefs: []
  type: TYPE_NORMAL
- en: Note that we have added the option â€œ- - quietâ€ to automatically accept all recommendations
    made by â€˜*openai tools fine_tunes.prepare_dataâ€™. F*or example, it suggests adding
    a â€˜-->â€™ to the end of all prompts and adding a token *END* to the end of each
    response.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first lines of this JSONL file look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The fine-tuning of the GPT-3 model is really achieved in the second *subprocess.run(),*
    where *openai api fine_tunes.create* is executed. In this function, we start by
    giving the name of the JSONL file created just before. You will then need to select
    the model you wish to fine-tune. OpenAI offers four main models with different
    performance levels suitable for various tasks. *Davinci* is the most powerful
    model, and Ada is the fastest. *Davinci* is also the most expensive model ğŸ˜¨.
  prefs: []
  type: TYPE_NORMAL
- en: Since the purpose of my model is to create descriptions of superheroes, we give
    my new model the suffix â€œ*Superhero*â€.
  prefs: []
  type: TYPE_NORMAL
- en: And thatâ€™s it ğŸ˜‰ After a few minutes, you will have a fine-tuned model ready
    to use ğŸŒŸ.
  prefs: []
  type: TYPE_NORMAL
- en: And now itâ€™s time to test your new model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are different ways to use a model for completion. Mainly via the Playground
    provided by OpenAI or via programming languages like Python.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest way is probably to use the [playground](https://platform.openai.com/playground).
  prefs: []
  type: TYPE_NORMAL
- en: Go to [https://platform.openai.com/playground](https://platform.openai.com/playground).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Click on â€˜Modelâ€™ and search for the one with the suffix â€œ*Superhero*â€.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add in â€˜Stop sequencesâ€™ the token â€˜ENDâ€™.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/94c1ac78c2f2ebb1b5694840743e4dbf.png)'
  prefs: []
  type: TYPE_IMG
- en: It is now time to ask our model for a new prediction. We will ask to describe
    an 18-year-old male character who really has an unnecessary power ğŸ˜‰ We will ask
    to describe a character who has the powerâ€¦ â€˜*can eat a lot*â€™â€¦ and see what happensâ€¦
    ğŸ˜†
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e5746b85ae0ca808c0b93c6dc9905c3b.png)'
  prefs: []
  type: TYPE_IMG
- en: Not so bad ğŸ˜…
  prefs: []
  type: TYPE_NORMAL
- en: Do you want to do it in Python? Simple! Click on â€˜View codeâ€™ at the top right
    of the screen.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/17fc2789ecac12e829d6a248e8dd1050.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In our case, in â€˜View codeâ€™ we have this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: You just have to copy and paste it ğŸ‘.
  prefs: []
  type: TYPE_NORMAL
- en: To conclude
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this blog, we have seen how to generate synthetic data to refine our model
    and how to do that fine-tuning. We have used a use case of creating a superhero,
    but the same method can be used for any use case you may have. The most important
    thing is to have enough quality examples with prompts and desired responses.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Please consider following me if you wish to stay up to date with my latest publications
    and increase the visibility of this blog.
  prefs: []
  type: TYPE_NORMAL
