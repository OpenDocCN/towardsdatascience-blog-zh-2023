- en: 'Unleashing the Power of GPT-3: Fine-Tuning for Superhero Descriptions'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é‡Šæ”¾ GPT-3 çš„åŠ›é‡ï¼šè¶…çº§è‹±é›„æè¿°çš„å¾®è°ƒ
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/unleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4?source=collection_archive---------0-----------------------#2023-02-18](https://towardsdatascience.com/unleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4?source=collection_archive---------0-----------------------#2023-02-18)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: åŸæ–‡ï¼š[https://towardsdatascience.com/unleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4?source=collection_archive---------0-----------------------#2023-02-18](https://towardsdatascience.com/unleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4?source=collection_archive---------0-----------------------#2023-02-18)
- en: Step-by-step guide for GPT-3 fine-tuning
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-3 å¾®è°ƒçš„é€æ­¥æŒ‡å—
- en: '[](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)[![Olivier
    Caelen](../Images/5315295f68999af7c14b456694d19979.png)](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)
    [Olivier Caelen](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)[![å¥¥åˆ©ç»´è€¶Â·å¡ä¼¦](../Images/5315295f68999af7c14b456694d19979.png)](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)[](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)
    [å¥¥åˆ©ç»´è€¶Â·å¡ä¼¦](https://medium.com/@ocaelen?source=post_page-----da35c90766c4--------------------------------)'
- en: Â·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Â·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd7268030c8a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&user=Olivier+Caelen&userId=d7268030c8a8&source=post_page-d7268030c8a8----da35c90766c4---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)
    Â·11 min readÂ·Feb 18, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fda35c90766c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&user=Olivier+Caelen&userId=d7268030c8a8&source=-----da35c90766c4---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd7268030c8a8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&user=Olivier+Caelen&userId=d7268030c8a8&source=post_page-d7268030c8a8----da35c90766c4---------------------post_header-----------)
    å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----da35c90766c4--------------------------------)
    Â·11 min é˜…è¯»Â·2023å¹´2æœˆ18æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fda35c90766c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&user=Olivier+Caelen&userId=d7268030c8a8&source=-----da35c90766c4---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda35c90766c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&source=-----da35c90766c4---------------------bookmark_footer-----------)![](../Images/d11e6869ddaac2af15c755bc2460aae9.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fda35c90766c4&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Funleashing-the-power-of-gpt-how-to-fine-tune-your-model-da35c90766c4&source=-----da35c90766c4---------------------bookmark_footer-----------)![](../Images/d11e6869ddaac2af15c755bc2460aae9.png)'
- en: Photo by [h heyerlein](https://unsplash.com/@heyerlein?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ‘„å½±ï¼šh heyerlein](https://unsplash.com/@heyerlein?utm_source=medium&utm_medium=referral)
    äº [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)'
- en: Since the end of 2022, the launch of ChatGPT by OpenAI has been considered by
    many of us to be the iPhone moment of AI. However, OpenAIâ€™s chatbot is not the
    first generative AI text machine learning model and follows the launch of GPT-3,
    which was launched two years earlier.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ª2022å¹´åº•ä»¥æ¥ï¼ŒOpenAI æ¨å‡ºçš„ ChatGPT è¢«è®¸å¤šäººè®¤ä¸ºæ˜¯äººå·¥æ™ºèƒ½çš„ iPhone æ—¶åˆ»ã€‚ç„¶è€Œï¼ŒOpenAI çš„èŠå¤©æœºå™¨äººå¹¶ä¸æ˜¯ç¬¬ä¸€ä¸ªç”Ÿæˆå¼
    AI æ–‡æœ¬æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå®ƒè·Ÿéšçš„æ˜¯ä¸¤å¹´å‰æ¨å‡ºçš„ GPT-3ã€‚
- en: OpenAI provides us with a ready-to-use GPT-3 trained model. Furthermore, a specific
    task can be fine-tuned on a smaller dataset. For example, suppose you want to
    create an email response generator specific to your company. First, you must collect
    a large amount of data about your particular business domain, such as customer
    email inquiries and responses. You can then use this data to fine-tune GPT-3 to
    learn your companyâ€™s specific language patterns and phrases. By fine-tuning GPT-3,
    creating a highly customized and specialized email response generator is possible,
    specifically tailored to the language patterns and words used in a particular
    business domain.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç°æˆçš„ GPT-3 è®­ç»ƒæ¨¡å‹ã€‚æ­¤å¤–ï¼Œç‰¹å®šä»»åŠ¡å¯ä»¥åœ¨è¾ƒå°çš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä½ æƒ³åˆ›å»ºä¸€ä¸ªé’ˆå¯¹ä½ å…¬å¸ç‰¹å®šçš„ç”µå­é‚®ä»¶å›å¤ç”Ÿæˆå™¨ã€‚é¦–å…ˆï¼Œä½ å¿…é¡»æ”¶é›†å¤§é‡æœ‰å…³ä½ ç‰¹å®šä¸šåŠ¡é¢†åŸŸçš„æ•°æ®ï¼Œå¦‚å®¢æˆ·ç”µå­é‚®ä»¶å’¨è¯¢å’Œå›å¤ã€‚ç„¶åï¼Œä½ å¯ä»¥ä½¿ç”¨è¿™äº›æ•°æ®æ¥å¾®è°ƒ
    GPT-3ï¼Œä»¥å­¦ä¹ ä½ å…¬å¸ç‰¹å®šçš„è¯­è¨€æ¨¡å¼å’ŒçŸ­è¯­ã€‚é€šè¿‡å¾®è°ƒ GPT-3ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªé«˜åº¦å®šåˆ¶å’Œä¸“ä¸šåŒ–çš„ç”µå­é‚®ä»¶å›å¤ç”Ÿæˆå™¨ï¼Œä¸“é—¨é’ˆå¯¹ç‰¹å®šä¸šåŠ¡é¢†åŸŸä½¿ç”¨çš„è¯­è¨€æ¨¡å¼å’Œè¯æ±‡ã€‚
- en: In this blog post, I will show you how to fine-tune GPT-3\. We will do this
    with python code and without assuming prior knowledge about GPT-3.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•å¾®è°ƒ GPT-3ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ python ä»£ç è¿›è¡Œæ“ä½œï¼Œå¹¶ä¸”ä¸å‡è®¾å¯¹ GPT-3 æœ‰ä»»ä½•å…ˆéªŒçŸ¥è¯†ã€‚
- en: What is needed for fine-tuning?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¾®è°ƒéœ€è¦ä»€ä¹ˆï¼Ÿ
- en: Unlike the GPT-2 model available for instance on Hugging Face (when this blog
    is written), we donâ€™t have direct access to the GPT-3 model. Therefore, you first
    need to get an API key from OpenAI and install the Python package *openai*, which
    can be quickly done via *pip*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸å½“å‰åœ¨ Hugging Face ä¸Šæä¾›çš„ GPT-2 æ¨¡å‹ä¸åŒï¼ˆæ’°å†™æœ¬æ–‡æ—¶ï¼‰ï¼Œæˆ‘ä»¬æ²¡æœ‰ç›´æ¥è®¿é—® GPT-3 æ¨¡å‹çš„æƒé™ã€‚å› æ­¤ï¼Œä½ é¦–å…ˆéœ€è¦ä» OpenAI
    è·å–ä¸€ä¸ª API å¯†é’¥ï¼Œå¹¶å®‰è£… Python åŒ… *openai*ï¼Œå¯ä»¥é€šè¿‡ *pip* å¿«é€Ÿå®Œæˆã€‚
- en: 'For the API key from OpenAI:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è·å– OpenAI çš„ API å¯†é’¥ï¼š
- en: go to [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
    ,
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¿é—® [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)
    ï¼Œ
- en: create an account,
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªè´¦æˆ·ï¼Œ
- en: click on â€˜*Create new secret keyâ€™* and
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‚¹å‡»â€˜*åˆ›å»ºæ–°å¯†é’¥*â€™ï¼Œç„¶å
- en: do a copy of the key.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤åˆ¶å¯†é’¥ã€‚
- en: 'The key is a long string of characters starting with â€˜sk-â€™. Make sure you keep
    it secret! Once you have your key, an easy way to get access to your key is to
    do the following in your terminal: (personally, for simplicity, I put it in my
    *.bachrc*):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®æ˜¯ä»¥â€˜sk-â€™å¼€å¤´çš„ä¸€é•¿ä¸²å­—ç¬¦ã€‚ç¡®ä¿ä½ ä¿å¯†ï¼ä¸€æ—¦ä½ æ‹¥æœ‰äº†ä½ çš„å¯†é’¥ï¼Œä¸€ä¸ªç®€å•çš„è·å–å¯†é’¥çš„æ–¹æ³•æ˜¯åœ¨ç»ˆç«¯ä¸­æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼šï¼ˆä¸ªäººè€Œè¨€ï¼Œä¸ºäº†ç®€ä¾¿ï¼Œæˆ‘å°†å…¶æ”¾åœ¨æˆ‘çš„*.bachrc*ä¸­ï¼‰ï¼š
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Using GPT-3 models has a cost. We need credits. At the time of this writing,
    when you create a new account, you get free credits to try out the tool. I donâ€™t
    know if this will continueâ€¦
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ GPT-3 æ¨¡å‹æ˜¯æœ‰æˆæœ¬çš„ã€‚æˆ‘ä»¬éœ€è¦ç§¯åˆ†ã€‚æ’°å†™æœ¬æ–‡æ—¶ï¼Œå½“ä½ åˆ›å»ºä¸€ä¸ªæ–°è´¦æˆ·æ—¶ï¼Œä½ ä¼šè·å¾—å…è´¹çš„ç§¯åˆ†æ¥å°è¯•è¿™ä¸ªå·¥å…·ã€‚æˆ‘ä¸çŸ¥é“è¿™ç§æƒ…å†µæ˜¯å¦ä¼šæŒç»­â€¦
- en: Now that we have our key and Python package, it is time to think about the data
    we need to fine-tune. First, we need a file of examples for fine-tuning, where
    each example is a *prompt* followed by the appropriate *completion*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†å¯†é’¥å’Œ Python åŒ…ï¼Œæ˜¯æ—¶å€™è€ƒè™‘æˆ‘ä»¬éœ€è¦å¾®è°ƒçš„æ•°æ®äº†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªç”¨äºå¾®è°ƒçš„ç¤ºä¾‹æ–‡ä»¶ï¼Œå…¶ä¸­æ¯ä¸ªç¤ºä¾‹éƒ½æ˜¯ä¸€ä¸ª *prompt*ï¼Œåè·Ÿç›¸åº”çš„
    *completion*ã€‚
- en: A superhero description generation tool
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªè¶…çº§è‹±é›„æè¿°ç”Ÿæˆå·¥å…·
- en: '![](../Images/96f93f7ff3d3b406b69c8ec1a2ffb322.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/96f93f7ff3d3b406b69c8ec1a2ffb322.png)'
- en: A superhero from DALL-E 2
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª DALL-E 2 çš„è¶…çº§è‹±é›„
- en: We will build a tool for this demo to create descriptions of imaginary superheroes.
    In the end, the tool will receive the age, gender, and power of the superhero,
    and it will automatically produce a description of our superhero.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä¸ºè¿™ä¸ªæ¼”ç¤ºæ„å»ºä¸€ä¸ªå·¥å…·ï¼Œä»¥åˆ›å»ºè™šæ„è¶…çº§è‹±é›„çš„æè¿°ã€‚æœ€ç»ˆï¼Œå·¥å…·å°†æ¥æ”¶è¶…çº§è‹±é›„çš„å¹´é¾„ã€æ€§åˆ«å’Œèƒ½åŠ›ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆè¶…çº§è‹±é›„çš„æè¿°ã€‚
- en: In the following example, after fine-tuning the model, all we have to say is
    â€™*40, woman, Healing ->*â€™, and we will automatically get a description from the
    model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»¥ä¸‹ç¤ºä¾‹ä¸­ï¼Œç»è¿‡æ¨¡å‹å¾®è°ƒåï¼Œæˆ‘ä»¬åªéœ€è¾“å…¥'*40, woman, Healing ->*'ï¼Œæ¨¡å‹å°†è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªæè¿°ã€‚
- en: '![](../Images/6cd099cf773d7c6e17b6b7f8867d23b5.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6cd099cf773d7c6e17b6b7f8867d23b5.png)'
- en: This is what itâ€™s all about!! ğŸ˜ƒ
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯ä¸€åˆ‡çš„å…³é”®ï¼ï¼ ğŸ˜ƒ
- en: Creation of a synthetic set of data for fine-tuning
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªåˆæˆçš„æ•°æ®é›†ç”¨äºå¾®è°ƒ
- en: In some situations, you may have a data set you want to use for fine-tuning.
    But since I donâ€™t have one, letâ€™s see how to create a synthetic data set with
    the description of the superheroes directly from GPT-3\. The following code will
    give me a CSV file with examples of *prompts* and the corresponding *completions*.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä½ å¯èƒ½æœ‰ä¸€ä¸ªæ•°æ®é›†æƒ³è¦ç”¨äºå¾®è°ƒã€‚ä½†ç”±äºæˆ‘æ²¡æœ‰ç°æˆçš„æ•°æ®é›†ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•ç›´æ¥ä» GPT-3 åˆ›å»ºä¸€ä¸ªåˆæˆæ•°æ®é›†ï¼Œç”¨äºè¶…çº§è‹±é›„çš„æè¿°ã€‚ä»¥ä¸‹ä»£ç å°†ç»™æˆ‘ä¸€ä¸ªåŒ…å«
    *prompts* å’Œç›¸åº” *completions* çš„ CSV æ–‡ä»¶ã€‚
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Letâ€™s look at how this code works ğŸ§.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ·±å…¥äº†è§£è¿™æ®µä»£ç æ˜¯å¦‚ä½•å·¥ä½œçš„ ğŸ§ã€‚
- en: The variable *f_prompt* contains the following sentence where *{age}*, *{gender},*
    and *{power}* are missing.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å˜é‡*f_prompt*åŒ…å«ä»¥ä¸‹å¥å­ï¼Œå…¶ä¸­*{age}*ã€*{gender}*å’Œ*{power}*æ˜¯ç¼ºå¤±çš„ã€‚
- en: 'Imagine a complete and detailed description of a {age}-year-old {gender} fictional
    character who has the superpower of {power}. Write out the entire description
    in a maximum of 100 words in great detail:'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æƒ³è±¡ä¸€ä¸‹ä¸€ä¸ªè¯¦ç»†æè¿°çš„{age}å²{gender}è™šæ„è§’è‰²ï¼Œä»–æ‹¥æœ‰{power}çš„è¶…çº§èƒ½åŠ›ã€‚ç”¨æœ€å¤š100ä¸ªå­—å†™å‡ºæ•´ä¸ªè¯¦ç»†æè¿°ï¼š
- en: In the first three *for* loops of the code, we iterate over different values
    of {age}, {gender}, and {power}. At each step of the loop, we replace the 3 missing
    variables with different values. Then we use the *openai.Completion.create* function
    to ask GPT to generate a response to our prompt.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»£ç çš„å‰ä¸‰ä¸ª*for*å¾ªç¯ä¸­ï¼Œæˆ‘ä»¬éå†ä¸åŒçš„{age}ã€{gender}å’Œ{power}å€¼ã€‚åœ¨æ¯ä¸€æ­¥å¾ªç¯ä¸­ï¼Œæˆ‘ä»¬ç”¨ä¸åŒçš„å€¼æ›¿æ¢3ä¸ªç¼ºå¤±çš„å˜é‡ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨*openai.Completion.create*å‡½æ•°è¯·æ±‚GPTç”Ÿæˆå¯¹æˆ‘ä»¬æç¤ºçš„å“åº”ã€‚
- en: The most important parameters of this function are
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå‡½æ•°çš„æœ€é‡è¦å‚æ•°æ˜¯
- en: '*model*: The model used to generate the response. OpenAI offers four standard
    GPT-3 models (`ada`, `babbage`, `curie`, or `davinci`) that vary in size â€¦ and
    price of use. Here it is *davinci* â€” the biggest model.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*model*ï¼šç”¨äºç”Ÿæˆå“åº”çš„æ¨¡å‹ã€‚OpenAIæä¾›äº†å››ç§æ ‡å‡†GPT-3æ¨¡å‹ï¼ˆ`ada`ã€`babbage`ã€`curie`æˆ–`davinci`ï¼‰ï¼Œå®ƒä»¬åœ¨è§„æ¨¡å’Œä½¿ç”¨ä»·æ ¼ä¸Šæœ‰æ‰€ä¸åŒã€‚è¿™é‡Œä½¿ç”¨çš„æ˜¯*davinci*â€”â€”æœ€å¤§çš„æ¨¡å‹ã€‚'
- en: '*prompt*: The prompt that we want to fulfill with GPT-3.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*prompt*ï¼šæˆ‘ä»¬å¸Œæœ›GPT-3å®Œæˆçš„æç¤ºã€‚'
- en: '*temperature*: The temperature is a number between 0 and 1 and controls how
    much randomness is in the output. We set the temperature to the maximum to allow
    the model to be as creative as possible in creating the response.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*temperature*ï¼šæ¸©åº¦æ˜¯ä¸€ä¸ªä»‹äº0å’Œ1ä¹‹é—´çš„æ•°å­—ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ã€‚æˆ‘ä»¬å°†æ¸©åº¦è®¾ç½®ä¸ºæœ€å¤§å€¼ï¼Œä»¥ä¾¿æ¨¡å‹åœ¨ç”Ÿæˆå“åº”æ—¶å°½å¯èƒ½å…·æœ‰åˆ›é€ åŠ›ã€‚'
- en: '*max_tokens*: Defines the maximum length of the response.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*max_tokens*ï¼šå®šä¹‰å“åº”çš„æœ€å¤§é•¿åº¦ã€‚'
- en: At the end of this script, we have a Pandas table stored in the file *out_openai_completion.csv.*
    The two primary columns in this table that interest us are *sub_prompt* and *response_txt.*
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªè„šæœ¬çš„æœ€åï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå­˜å‚¨åœ¨æ–‡ä»¶*out_openai_completion.csv*ä¸­çš„Pandasè¡¨æ ¼ã€‚è¿™ä¸ªè¡¨æ ¼ä¸­æˆ‘ä»¬æ„Ÿå…´è¶£çš„ä¸¤ä¸ªä¸»è¦åˆ—æ˜¯*sub_prompt*å’Œ*response_txt*ã€‚
- en: The *sub_prompt* will be for exampleâ€˜*18, man, invisibilityâ€™.* It contains the
    three values that were replaced, separated by commas.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*sub_prompt*ä¾‹å¦‚ä¼šæ˜¯â€˜*18, man, invisibility*â€™ã€‚å®ƒåŒ…å«äº†ä¸‰ä¸ªç”¨é€—å·åˆ†éš”çš„è¢«æ›¿æ¢çš„å€¼ã€‚'
- en: The *response_txt* contains the output of the GPT model.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*response_txt*åŒ…å«GPTæ¨¡å‹çš„è¾“å‡ºã€‚'
- en: Fine-tuning the GPT model
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¾®è°ƒGPTæ¨¡å‹
- en: The following code retrieves the previously created file *out_openai_completion.csv*
    and uses *openai* to fine-tune a GPT-3 model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç æ£€ç´¢ä¹‹å‰åˆ›å»ºçš„æ–‡ä»¶*out_openai_completion.csv*ï¼Œå¹¶ä½¿ç”¨*openai*å¯¹GPT-3æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Letâ€™s take the time to understand this code as well ğŸ¤“!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬èŠ±æ—¶é—´æ¥ç†è§£è¿™æ®µä»£ç  ğŸ¤“ï¼
- en: First, the content of the file *out_openai_completion.csv* is loaded into the
    data frame *df*. As a reminder, in our task, if the user enters â€™40, female, healingâ€™,
    we want to have a description of a 40-year-old female character with the power
    of healing. To perform fine-tuning, it is necessary to provide GPT with examples
    of what the user might type and the corresponding desired response. In the data
    frame *df*, the columns *sub_prompt* and *response_txt* contain examples of input
    with the corresponding desired response. In the code above, we first extract these
    two colons and then rename them to *prompt* and *completion*, respectively. The
    resulting data frame is stored in a new file *prepared_data.csv* containing only
    these two columns.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæ–‡ä»¶*out_openai_completion.csv*çš„å†…å®¹è¢«åŠ è½½åˆ°æ•°æ®æ¡†*df*ä¸­ã€‚ä¸ºäº†æé†’ä¸€ä¸‹ï¼Œåœ¨æˆ‘ä»¬çš„ä»»åŠ¡ä¸­ï¼Œå¦‚æœç”¨æˆ·è¾“å…¥'40, female,
    healing'ï¼Œæˆ‘ä»¬å¸Œæœ›å¾—åˆ°ä¸€ä¸ªå…³äº40å²å¥³æ€§è§’è‰²æ‹¥æœ‰æ²»æ„ˆèƒ½åŠ›çš„æè¿°ã€‚ä¸ºäº†è¿›è¡Œå¾®è°ƒï¼Œéœ€è¦å‘GPTæä¾›ç”¨æˆ·å¯èƒ½è¾“å…¥çš„ç¤ºä¾‹ä»¥åŠç›¸åº”çš„æœŸæœ›å“åº”ã€‚åœ¨æ•°æ®æ¡†*df*ä¸­ï¼Œ*sub_prompt*å’Œ*response_txt*åˆ—åŒ…å«äº†è¾“å…¥ç¤ºä¾‹å’Œå¯¹åº”çš„æœŸæœ›å“åº”ã€‚åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæå–è¿™ä¸¤åˆ—ï¼Œç„¶åå°†å…¶åˆ†åˆ«é‡å‘½åä¸º*prompt*å’Œ*completion*ã€‚ç»“æœæ•°æ®æ¡†è¢«å­˜å‚¨åœ¨ä¸€ä¸ªæ–°çš„æ–‡ä»¶*prepared_data.csv*ä¸­ï¼Œä»…åŒ…å«è¿™ä¸¤åˆ—ã€‚
- en: 'This file *prepared_data.csv* looks like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–‡ä»¶*prepared_data.csv*çš„å†…å®¹å¦‚ä¸‹ï¼š
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The Python *subprocess.run()* function runs a command as a subprocess. It is
    often used to execute external programs as if they were run in a terminal.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Pythonçš„*subprocess.run()*å‡½æ•°å°†å‘½ä»¤ä½œä¸ºå­è¿›ç¨‹è¿è¡Œã€‚å®ƒé€šå¸¸ç”¨äºæ‰§è¡Œå¤–éƒ¨ç¨‹åºï¼Œå°±åƒåœ¨ç»ˆç«¯ä¸­è¿è¡Œä¸€æ ·ã€‚
- en: We use *subprocess.run()* to execute â€˜*openai tools fine_tunes.prepare_dataâ€™*.
    This function takes the input file *prepared_data.csv*, checks that the data are
    correct, and produces a JSONL file called *prepared_data_prepared.jsonl*. A JSONL
    file is a format that stores each JSON object on a separate line. JSONL files
    contain a sequence of JSON objects, each separated by a newline character.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨ *subprocess.run()* æ‰§è¡Œâ€˜*openai tools fine_tunes.prepare_data*â€™ã€‚è¿™ä¸ªå‡½æ•°æ¥å—è¾“å…¥æ–‡ä»¶
    *prepared_data.csv*ï¼Œæ£€æŸ¥æ•°æ®æ˜¯å¦æ­£ç¡®ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªåä¸º *prepared_data_prepared.jsonl* çš„ JSONL æ–‡ä»¶ã€‚JSONL
    æ–‡ä»¶æ˜¯ä¸€ç§å°†æ¯ä¸ª JSON å¯¹è±¡å­˜å‚¨åœ¨å•ç‹¬ä¸€è¡Œçš„æ ¼å¼ã€‚JSONL æ–‡ä»¶åŒ…å«ä¸€ç³»åˆ— JSON å¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡ä¹‹é—´ç”¨æ¢è¡Œç¬¦åˆ†éš”ã€‚
- en: Note that we have added the option â€œ- - quietâ€ to automatically accept all recommendations
    made by â€˜*openai tools fine_tunes.prepare_dataâ€™. F*or example, it suggests adding
    a â€˜-->â€™ to the end of all prompts and adding a token *END* to the end of each
    response.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œæˆ‘ä»¬å·²æ·»åŠ é€‰é¡¹â€œ- - quietâ€ä»¥è‡ªåŠ¨æ¥å—â€˜*openai tools fine_tunes.prepare_data*â€™æ‰€åšçš„æ‰€æœ‰å»ºè®®ã€‚ä¾‹å¦‚ï¼Œå®ƒå»ºè®®åœ¨æ‰€æœ‰æç¤ºçš„æœ«å°¾æ·»åŠ â€˜-->â€™ï¼Œå¹¶åœ¨æ¯ä¸ªå“åº”çš„æœ«å°¾æ·»åŠ ä¸€ä¸ª*END*æ ‡è®°ã€‚
- en: 'The first lines of this JSONL file look like this:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ª JSONL æ–‡ä»¶çš„å‰å‡ è¡Œçœ‹èµ·æ¥åƒè¿™æ ·ï¼š
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The fine-tuning of the GPT-3 model is really achieved in the second *subprocess.run(),*
    where *openai api fine_tunes.create* is executed. In this function, we start by
    giving the name of the JSONL file created just before. You will then need to select
    the model you wish to fine-tune. OpenAI offers four main models with different
    performance levels suitable for various tasks. *Davinci* is the most powerful
    model, and Ada is the fastest. *Davinci* is also the most expensive model ğŸ˜¨.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3 æ¨¡å‹çš„å¾®è°ƒå®é™…ä¸Šæ˜¯åœ¨ç¬¬äºŒä¸ª *subprocess.run()* ä¸­å®ç°çš„ï¼Œå…¶ä¸­æ‰§è¡Œäº† *openai api fine_tunes.create*ã€‚åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆæä¾›åˆšåˆšåˆ›å»ºçš„
    JSONL æ–‡ä»¶çš„åç§°ã€‚ç„¶åä½ éœ€è¦é€‰æ‹©è¦å¾®è°ƒçš„æ¨¡å‹ã€‚OpenAI æä¾›äº†å››ä¸ªä¸»è¦æ¨¡å‹ï¼Œå…·æœ‰ä¸åŒçš„æ€§èƒ½æ°´å¹³ï¼Œé€‚ç”¨äºå„ç§ä»»åŠ¡ã€‚*Davinci* æ˜¯æœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œè€Œ
    Ada æ˜¯æœ€å¿«çš„ã€‚*Davinci* ä¹Ÿæ˜¯æœ€æ˜‚è´µçš„æ¨¡å‹ ğŸ˜¨ã€‚
- en: Since the purpose of my model is to create descriptions of superheroes, we give
    my new model the suffix â€œ*Superhero*â€.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæˆ‘æ¨¡å‹çš„ç›®çš„æ˜¯åˆ›å»ºè¶…çº§è‹±é›„çš„æè¿°ï¼Œå› æ­¤æˆ‘ä»¬ç»™æˆ‘çš„æ–°æ¨¡å‹æ·»åŠ äº†åç¼€â€œ*è¶…çº§è‹±é›„*â€ã€‚
- en: And thatâ€™s it ğŸ˜‰ After a few minutes, you will have a fine-tuned model ready
    to use ğŸŒŸ.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ğŸ˜‰ å‡ åˆ†é’Ÿåï¼Œä½ å°†æ‹¥æœ‰ä¸€ä¸ªå¯ä»¥ä½¿ç”¨çš„å¾®è°ƒæ¨¡å‹ğŸŒŸã€‚
- en: And now itâ€™s time to test your new model
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯æ—¶å€™æµ‹è¯•ä½ çš„æ–°æ¨¡å‹äº†ã€‚
- en: There are different ways to use a model for completion. Mainly via the Playground
    provided by OpenAI or via programming languages like Python.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ¨¡å‹è¿›è¡Œè¡¥å…¨æœ‰ä¸åŒçš„æ–¹æ³•ã€‚ä¸»è¦é€šè¿‡ OpenAI æä¾›çš„ Playground æˆ–è€…é€šè¿‡åƒ Python è¿™æ ·çš„ç¼–ç¨‹è¯­è¨€ã€‚
- en: The simplest way is probably to use the [playground](https://platform.openai.com/playground).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç®€å•çš„æ–¹æ³•å¯èƒ½æ˜¯ä½¿ç”¨ [playground](https://platform.openai.com/playground)ã€‚
- en: Go to [https://platform.openai.com/playground](https://platform.openai.com/playground).
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¿é—® [https://platform.openai.com/playground](https://platform.openai.com/playground)ã€‚
- en: Click on â€˜Modelâ€™ and search for the one with the suffix â€œ*Superhero*â€.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‚¹å‡»â€˜æ¨¡å‹â€™å¹¶æœç´¢å¸¦æœ‰åç¼€â€œ*è¶…çº§è‹±é›„*â€çš„æ¨¡å‹ã€‚
- en: Add in â€˜Stop sequencesâ€™ the token â€˜ENDâ€™.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨â€˜åœæ­¢åºåˆ—â€™ä¸­æ·»åŠ æ ‡è®°â€˜ENDâ€™ã€‚
- en: '![](../Images/94c1ac78c2f2ebb1b5694840743e4dbf.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/94c1ac78c2f2ebb1b5694840743e4dbf.png)'
- en: It is now time to ask our model for a new prediction. We will ask to describe
    an 18-year-old male character who really has an unnecessary power ğŸ˜‰ We will ask
    to describe a character who has the powerâ€¦ â€˜*can eat a lot*â€™â€¦ and see what happensâ€¦
    ğŸ˜†
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯æ—¶å€™è¦æ±‚æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œæ–°çš„é¢„æµ‹äº†ã€‚æˆ‘ä»¬å°†è¦æ±‚æè¿°ä¸€ä¸ª18å²çš„ç”·æ€§è§’è‰²ï¼Œä»–çœŸçš„æœ‰ä¸€ä¸ªä¸å¿…è¦çš„èƒ½åŠ›ğŸ˜‰ æˆ‘ä»¬å°†è¦æ±‚æè¿°ä¸€ä¸ªæ‹¥æœ‰â€˜*åƒå¾ˆå¤š*â€™èƒ½åŠ›çš„è§’è‰²â€¦â€¦çœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆâ€¦â€¦ğŸ˜†
- en: '![](../Images/e5746b85ae0ca808c0b93c6dc9905c3b.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e5746b85ae0ca808c0b93c6dc9905c3b.png)'
- en: Not so bad ğŸ˜…
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸é”™ ğŸ˜…
- en: Do you want to do it in Python? Simple! Click on â€˜View codeâ€™ at the top right
    of the screen.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ æƒ³ç”¨ Python æ¥åšå—ï¼Ÿå¾ˆç®€å•ï¼ç‚¹å‡»å±å¹•å³ä¸Šè§’çš„â€˜æŸ¥çœ‹ä»£ç â€™ã€‚
- en: '![](../Images/17fc2789ecac12e829d6a248e8dd1050.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17fc2789ecac12e829d6a248e8dd1050.png)'
- en: 'In our case, in â€˜View codeâ€™ we have this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œåœ¨â€˜æŸ¥çœ‹ä»£ç â€™ä¸­æˆ‘ä»¬æœ‰ï¼š
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You just have to copy and paste it ğŸ‘.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ åªéœ€è¦å¤åˆ¶å¹¶ç²˜è´´å³å¯ğŸ‘ã€‚
- en: To conclude
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: In this blog, we have seen how to generate synthetic data to refine our model
    and how to do that fine-tuning. We have used a use case of creating a superhero,
    but the same method can be used for any use case you may have. The most important
    thing is to have enough quality examples with prompts and desired responses.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªåšå®¢ä¸­ï¼Œæˆ‘ä»¬å·²ç»äº†è§£äº†å¦‚ä½•ç”Ÿæˆåˆæˆæ•°æ®ä»¥ä¼˜åŒ–æˆ‘ä»¬çš„æ¨¡å‹ä»¥åŠå¦‚ä½•è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬ä½¿ç”¨äº†åˆ›å»ºè¶…çº§è‹±é›„çš„ç”¨ä¾‹ï¼Œä½†ç›¸åŒçš„æ–¹æ³•ä¹Ÿå¯ä»¥ç”¨äºä½ å¯èƒ½æ‹¥æœ‰çš„ä»»ä½•ç”¨ä¾‹ã€‚æœ€é‡è¦çš„æ˜¯è¦æœ‰è¶³å¤Ÿçš„è´¨é‡ç¤ºä¾‹ï¼ŒåŒ…å«æç¤ºå’ŒæœŸæœ›çš„å“åº”ã€‚
- en: Thanks for reading!
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼
- en: Please consider following me if you wish to stay up to date with my latest publications
    and increase the visibility of this blog.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¸Œæœ›ä¿æŒæœ€æ–°çš„å‡ºç‰ˆç‰©å¹¶å¢åŠ è¿™ä¸ªåšå®¢çš„å¯è§æ€§ï¼Œè¯·è€ƒè™‘å…³æ³¨æˆ‘ã€‚
