- en: Figuring out the most unusual segments in data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2?source=collection_archive---------8-----------------------#2023-07-13](https://towardsdatascience.com/figuring-out-the-most-unusual-segments-in-data-af5fbeacb2b2?source=collection_archive---------8-----------------------#2023-07-13)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to find segments to focus on using common sense and machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://miptgirl.medium.com/?source=post_page-----af5fbeacb2b2--------------------------------)[![Mariya
    Mansurova](../Images/b1dd377b0a1887db900cc5108bca8ea8.png)](https://miptgirl.medium.com/?source=post_page-----af5fbeacb2b2--------------------------------)[](https://towardsdatascience.com/?source=post_page-----af5fbeacb2b2--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----af5fbeacb2b2--------------------------------)
    [Mariya Mansurova](https://miptgirl.medium.com/?source=post_page-----af5fbeacb2b2--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F15a29a4fc6ad&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffiguring-out-the-most-unusual-segments-in-data-af5fbeacb2b2&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=post_page-15a29a4fc6ad----af5fbeacb2b2---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----af5fbeacb2b2--------------------------------)
    ·13 min read·Jul 13, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf5fbeacb2b2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffiguring-out-the-most-unusual-segments-in-data-af5fbeacb2b2&user=Mariya+Mansurova&userId=15a29a4fc6ad&source=-----af5fbeacb2b2---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf5fbeacb2b2&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffiguring-out-the-most-unusual-segments-in-data-af5fbeacb2b2&source=-----af5fbeacb2b2---------------------bookmark_footer-----------)![](../Images/55977911cccb6b801adf2e71c8ae9970.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Klara Kulikova](https://unsplash.com/@kkalerry?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: Analysts often have tasks of finding the “interesting” segments — the segments
    where we could focus our efforts to get the maximum potential impact. For example,
    it may be interesting to determine what customer segments have the most significant
    effect on churn. Or you could try to understand what types of orders affect customer
    support workload and the company’s revenue.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we could look at graphs to find such outstanding features. But it
    may be time-consuming because we usually track dozens or even hundreds of customers’
    characteristics. More than that, we need to look at combinations of different
    factors so that it may lead to a combinatorial explosion. With such tasks, a framework
    would be really helpful because it could save you hours of analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article, I would like to share with you two approaches for finding
    the most outstanding slices of data:'
  prefs: []
  type: TYPE_NORMAL
- en: based on common sense and basic maths,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: based on machine learning — our data science team at Wise has open-sourced a
    library [***Wise Pizza***](https://github.com/transferwise/wise-pizza#readme)
    that gives you answers in three lines of code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Example: Churn for bank customers'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can find the complete code for this example on [GitHub](https://github.com/miptgirl/miptgirl_medium/blob/main/slices_wise_pizza/bank_churn_segments.ipynb).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We will be using data for bank customers’ churn as an example. [This dataset](https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers)
    can be found on Kaggle under [CC0: Public Domain](https://www.kaggle.com/datasets/mathchi/churn-for-bank-customers)
    license.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will try to find the segments with the most significant impact on churn
    using different approaches: graphs, common sense and machine learning. But let’s
    start with data preprocessing.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/38476a2ad4f1f62ec00941d08faa0f50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The dataset lists customers and their characteristics: credit score, country
    of residency, age & gender, how much money customers have on balance etc. Also,
    for each customer, we know whether they churned or not — parameter `exited`.'
  prefs: []
  type: TYPE_NORMAL
- en: Our main goal is to find the customer segments with the highest impact on the
    number of churned customers. After that, we could try to understand the problems
    specific to these user groups. If we focus on fixing issues for these segments,
    we will have the most significant effect on the number of churned customers.
  prefs: []
  type: TYPE_NORMAL
- en: To simplify calculations and interpretations, we will define segments as sets
    of filters, for example, `gender = Male` or `gender = Male, country = United Kingdom`.
  prefs: []
  type: TYPE_NORMAL
- en: We will be working with discrete characteristics, so we have to transform continuous
    metrics, such as `age` or `balance`. For this, we could look at distributions
    and define suitable buckets. For example, let’s look at age.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c0b4e39a32a63ffd44bb08b40309c655.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph by author
  prefs: []
  type: TYPE_NORMAL
- en: '*Code example for bucketing continuous characteristic*'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The most straightforward way to find intriguing segments in data is to look
    at visualisations. We can look at churn rates split by one or two dimensions using
    bar charts or heat maps.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the correlation between age and churn. Churn rates are low for
    customers under 35 years — less than 10%. While for customers between 45 and 64
    years, retention is the worst — almost half of customers have churned.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/994e6c1cfe29f97735f663e9ad4537c2.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph by author
  prefs: []
  type: TYPE_NORMAL
- en: Let’s add one more parameter (`gender`) to try to find more complex relations.
    Barchart won’t be able to show us two-dimensional relationships, so let’s switch
    to a heatmap.
  prefs: []
  type: TYPE_NORMAL
- en: Churn rates for females are higher for all age groups, so gender is an influential
    factor.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ad2fc34dddffec14880b8879891f001.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph by author
  prefs: []
  type: TYPE_NORMAL
- en: 'Such visualisations can be pretty insightful, but there are a couple of problems
    with this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: we don’t take into account the size of segments,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: it may be time-consuming to look at all possible combinations of characteristics
    you have,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: it’s challenging to visualize more than two dimensions in one graph.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So let’s move on to more structured approaches that will help us to get a prioritized
    list of interesting segments with estimated effects.
  prefs: []
  type: TYPE_NORMAL
- en: Common sense approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assumptions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How could we calculate the potential impact of fixing problems for a specific
    segment? We can compare it to the “ideal” scenario with a lower churn rate.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ff798190db2886d853a2790dd3dfce1a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You may wonder how we could estimate the benchmark for churn rate. There are
    several ways to do it:'
  prefs: []
  type: TYPE_NORMAL
- en: '**benchmarks from the market:** you can try to search for typical churn rates
    levels for products in your domain,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**high-performing segments in your product:** usually, you have a bit better-performing
    segments (for example, you can split by country or platform) and you can use them
    as a benchmark,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**average value:** the most conservative approach is looking at the global
    mean value and estimating the potential effect of reaching the average churn rates
    for all segments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s play safe and use the average churn rate from our dataset as a benchmark
    — 20.37%.
  prefs: []
  type: TYPE_NORMAL
- en: Listing all possible segments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next step is to build all possible segments. Our dataset has ten dimensions
    with 3–6 unique values for each. The total number of combinations is around 1.2M.
    It looks computationally costly even though we have just a few dimensions and
    different values for them. In actual tasks, you usually have dozens of characteristics
    and unique values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We definitely need to think about some performance optimizations. Otherwise,
    we may have to spend hours waiting for results. Here are a couple of tips on reducing
    computations:'
  prefs: []
  type: TYPE_NORMAL
- en: First of all, we don’t need to build all possible combinations. It will be reasonable
    to limit the depth to 4–6\. The possibility that your product team should focus
    on a user segment defined by 42 different filters is pretty low.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secondly, we may define the size of the effect we are interested in. Let’s say
    we would like to increase the retention rate by at least 1% point. It means we
    are not interested in segments with a size of less than 1% of all users. Then
    we can stop splitting a segment further if its size is below this threshold —
    it will reduce the number of operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Last but not least, you can significantly reduce the data size and resources
    spent on calculations in real-life datasets. For that, you can group all small
    characteristics for each dimension into an `other` group. For example, there are
    hundreds of countries, and each country’s users’ share usually follows [Zipf’s
    law](https://en.wikipedia.org/wiki/Zipf's_law) as with many other real data relations.
    So you will have many countries with a size of less than 1% of all users. As we
    discussed earlier, we are not interested in such small user groups, and we can
    just group them all into one segment `country = other` to make calculations easier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/b61ffb300a8b407ab8f727b4d0d46621.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph by author
  prefs: []
  type: TYPE_NORMAL
- en: We will be using recursion to build all combinations of filters up to `max_depth`.
    I like this concept of computer science because, in many cases, it allows you
    to solve complex problems elegantly. Unfortunately, data analysts rarely face
    the need to write recursive code — I can remember three tasks through 10 years
    of data analysis experience.
  prefs: []
  type: TYPE_NORMAL
- en: The idea of recursion is pretty straightforward — it’s when your function calls
    itself during the execution. It’s handy when you are working with hierarchies
    or graphs. If you would like to learn more about recursion in Python, read [this
    article](https://betterprogramming.pub/recursion-in-python-32d464653984).
  prefs: []
  type: TYPE_NORMAL
- en: 'The high-level concept in our case is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We start with the entire dataset and no filters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we try to add one more filter (if the segment size is big enough and we
    haven’t reached maximum depth) and apply our function to it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeat the previous step until conditions are valid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As a result, we got around 10K segments. Now we can calculate the estimated
    effects for each, filter segments with negative effects and look at the user groups
    with the highest potential impact.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: It should be a Holly Graal that gives all the answers. But wait, there are too
    many duplicates and segments subsequent to one another. Could we reduce duplication
    and keep only the most informative user groups?
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/cbba7d3af9ff11b40ac440629b1eeffb.png)'
  prefs: []
  type: TYPE_IMG
- en: Grooming
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s look at a couple of examples.
  prefs: []
  type: TYPE_NORMAL
- en: The churn rate for the child segment `age_group = 45–54, gender = Male` is lower
    than `age_group = 45–54`. Adding a `gender = Male` filter doesn’t bring us closer
    to the specific problem. So we can eliminate such cases.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c4c0a2b942ccf64f650fe78701e771c4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The example below shows the opposite situation: the churn rate for the child
    segment is significantly higher, and, more than that, the child segment includes
    80% of churned customers from the parent node. In this case, it’s reasonable to
    eliminate a `credit_score_group = poor, tenure_group = 8+` segment because the
    main problem is within a `is_active_member = 0` group.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b943b19492090d5632740eb0c2fd20dd.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s filter all those not-so-interesting segments.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now we have around 4K interesting segments. With this toy dataset, we see little
    difference after this grooming for the top ones. However, with real-life data,
    these efforts often pay out.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6d7d211859d589d203a4e4f85618f8d9.png)'
  prefs: []
  type: TYPE_IMG
- en: Root causes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last thing we can do to leave the most meaningful slices is to keep only
    the root nodes of our segments. These segments are the root causes, and others
    are included in them. If you would like to dig deeper into one of the root causes,
    look at child nodes.
  prefs: []
  type: TYPE_NORMAL
- en: To get only the root causes, we need to eliminate all segments for which we
    have a parent node in our final list of interesting ones.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: So here it is, now we have a list of user groups to focus on. We got only one-dimensional
    segments at the top since there are few complex relations in data where a couple
    of characteristics explain the full effect.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5bea2be4ac745153e59bb474148fb1a6.png)'
  prefs: []
  type: TYPE_IMG
- en: It’s crucial to discuss how we could interpret the results. We got a list of
    customer segments with the estimated impact. Our estimation is based on the hypothesis
    that we could decrease the churn rate for the whole segment to reach the benchmark
    level (in our example — the average value). So we estimated the impact of fixing
    the problems for each user group.
  prefs: []
  type: TYPE_NORMAL
- en: You must keep in mind that this approach only gives you a high-level view of
    what user groups to focus on. It doesn’t take into account whether it’s possible
    to fix these problems entirely or not.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve written quite a lot of code to get results. Maybe there’s another approach
    to solving this task using data science and machine learning that won’t require
    so much effort.
  prefs: []
  type: TYPE_NORMAL
- en: Pizza time
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Actually, there is another way. Our data science team at Wise has developed
    a library [***Wise Pizza***](https://github.com/transferwise/wise-pizza#readme)
    that could find the most intriguing segments in a blink of an eye. It’s open-sourced
    under Apache 2.0 license, so you also could use it for your tasks.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested to learn more about **Wise Pizza** library, don’t miss
    Egor’s presentation on [Data Science Festival](https://datasciencefestival.com/session/unleashing-wisepizza-finding-unusual-segments-in-your-data/).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Applying Wise Pizza
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The library is easy to use. You need to write just a couple of lines and specify
    the dimensions and number of segments you want in a result.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a0afe50ffd627e30b6ba3d548a0a0862.png)'
  prefs: []
  type: TYPE_IMG
- en: Graph by author
  prefs: []
  type: TYPE_NORMAL
- en: As a result, we also got a list of the most interesting segments and their potential
    impact on our product churn. Segments are similar to the ones we’ve obtained using
    the previous approach. However, the impact estimations differ a lot. To interpret
    Wise Pizza results correctly and understand the differences, we need to discuss
    how it works in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: How it works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The library is based on Lasso and LP solvers. If we simplify it, the library
    does something similar to one-hot-encoding, adding flags for segments (the same
    ones we’ve calculated before) and then uses Lasso regression with churn rate as
    a target variable.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/9ff2779de24248ae111093262dc64fa5.png)'
  prefs: []
  type: TYPE_IMG
- en: As you may remember from machine learning, the Lasso regression tends to have
    many zero coefficients, selecting a few significant factors. ***Wise Pizza***
    finds the appropriate `alpha` coefficient for Lasso regression so that you will
    get a specified number of segments as a result.
  prefs: []
  type: TYPE_NORMAL
- en: For revising Lasso (L1) and Ridge (L2) regularisations, you could consult [the
    article](https://pub.towardsai.net/lasso-l1-and-ridge-l2-regularization-techniques-33b7f12ac0b).
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to interpret results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Impact is estimated as the result of multiplication of coefficient and segment
    size.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/8450ab992704763ee2953281f125d92e.png)'
  prefs: []
  type: TYPE_IMG
- en: So as you could see, it’s completely different to what we’ve estimated before.
    The common sense approach estimates the impact of completely fixing the problems
    for user groups, while Wise Pizza’s impact shows incremental effects to other
    selected segments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The advantage of this approach is that you can sum up different effects. However,
    you need to be accurate during the results’ interpretations because the impact
    for each segment depends on other selected segments since they may be correlated.
    For example, in our case, we have three correlated segments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`age_group = 45-54`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_of_products = 1, age_group = 44–54`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_active_member = 1, age_group = 44–54`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The impact for `age_group = 45–54` grasps potential effects for the whole age
    group, while others estimate additional impact from specific subgroups. Such dependencies
    may lead to significant results differences depending on `min_segments` parameter,
    because you will have different sets of final segments and correlations between
    them.
  prefs: []
  type: TYPE_NORMAL
- en: It’s crucial to pay attention to the whole picture and interpret ***Wise Pizza***
    results correctly. Otherwise, you may jump to the wrong conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: I appreciate this library as an invaluable tool for getting quick insights from
    data and the first segment candidates to dive deeper. However, suppose I need
    to do opportunity sizing and more robust analysis to share the potential impact
    of our focus with my product team. In that case, I still use a common sense approach
    with a reasonable benchmark because it’s much easier to interpret.
  prefs: []
  type: TYPE_NORMAL
- en: '**TL;DR**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finding interesting slices in your data is a common task for analysts (especially
    at the discovery stage). Luckily, you don’t need to make dozens of graphs to solve
    such questions. There are frameworks which are more comprehensive and easy-to-use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can use the [***Wise Pizza***](https://github.com/transferwise/wise-pizza#readme)
    ML library to get quick insights on the segments with the most significant impact
    on average (*it also allows you to look at the difference between two datasets*).
    I usually use it to get the first list of meaningful dimensions and segments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ML approach can give you a high-level view and prioritization in a blink of
    an eye. However, I recommend you to pay attention to results interpretation and
    make sure you and you stakeholders fully understand it. However, if you need to
    do a robust estimation of potential effect on KPIs of fixing problems for the
    whole user group, it’s worth using a good old common sense approach based on arithmetics.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Thank you a lot for reading this article. I hope it was insightful to you. If
    you have any follow-up questions or comments, please don’t hesitate to leave them
    in the comments section.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
