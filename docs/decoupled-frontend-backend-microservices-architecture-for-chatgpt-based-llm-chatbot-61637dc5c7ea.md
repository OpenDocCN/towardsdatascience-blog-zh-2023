# é¢å‘ ChatGPT çš„ LLM èŠå¤©æœºå™¨äººè§£è€¦å‰ç«¯â€”â€”åç«¯å¾®æœåŠ¡æ¶æ„

> åŸæ–‡ï¼š[`towardsdatascience.com/decoupled-frontend-backend-microservices-architecture-for-chatgpt-based-llm-chatbot-61637dc5c7ea`](https://towardsdatascience.com/decoupled-frontend-backend-microservices-architecture-for-chatgpt-based-llm-chatbot-61637dc5c7ea)

## **ä½¿ç”¨ Streamlitã€FastAPI å’Œ OpenAI API æ„å»ºæ— å¤´ ChatGPT åº”ç”¨ç¨‹åºçš„å®ç”¨æŒ‡å—**

[](https://stephen-leo.medium.com/?source=post_page-----61637dc5c7ea--------------------------------)![Marie Stephen Leo](https://stephen-leo.medium.com/?source=post_page-----61637dc5c7ea--------------------------------)[](https://towardsdatascience.com/?source=post_page-----61637dc5c7ea--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----61637dc5c7ea--------------------------------) [Marie Stephen Leo](https://stephen-leo.medium.com/?source=post_page-----61637dc5c7ea--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----61637dc5c7ea--------------------------------) Â·é˜…è¯»æ—¶é—´ 8 åˆ†é’ŸÂ·2023 å¹´ 5 æœˆ 24 æ—¥

--

![](img/64f56820c6449617c8f28c080da1275e.png)

å›¾ç‰‡ç”±ä½œè€…ä½¿ç”¨ Midjourney V5.1 ç”Ÿæˆï¼Œæç¤ºè¯ï¼šâ€œè§£è€¦å‰ç«¯åç«¯è½¯ä»¶åº”ç”¨â€

åœ¨[æˆ‘ä¹‹å‰çš„æ–‡ç« ](https://medium.com/towards-data-science/anatomy-of-llm-based-chatbot-applications-monolithic-vs-microservice-architectural-patterns-77796216903e)ä¸­ï¼Œæˆ‘è®¨è®ºäº†åŸºäº LLM çš„èŠå¤©æœºå™¨äººåº”ç”¨ç¨‹åºçš„å•ä½“ä¸å¾®æœåŠ¡æ¶æ„æ¨¡å¼ä¹‹é—´çš„å·®å¼‚ã€‚é€‰æ‹©å¾®æœåŠ¡æ¶æ„æ¨¡å¼çš„ä¸€ä¸ªæ˜¾è‘—ä¼˜åŠ¿æ˜¯ï¼Œå®ƒå…è®¸å‰ç«¯ä»£ç ä¸æ•°æ®ç§‘å­¦é€»è¾‘åˆ†ç¦»ï¼Œä½¿å¾—æ•°æ®ç§‘å­¦å®¶å¯ä»¥ä¸“æ³¨äºæ•°æ®ç§‘å­¦é€»è¾‘ï¼Œè€Œä¸å¿…æ‹…å¿ƒå‰ç«¯ä»£ç ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Streamlitã€FastAPI å’Œ OpenAI API æ„å»ºå¾®æœåŠ¡èŠå¤©æœºå™¨äººåº”ç”¨ç¨‹åºã€‚æˆ‘ä»¬å°†å‰ç«¯å’Œåç«¯ä»£ç è§£è€¦ï¼Œä»¥ä¾¿å¯ä»¥è½»æ¾åœ°å°†å‰ç«¯æ›¿æ¢ä¸ºå…¶ä»–å‰ç«¯æ¡†æ¶ï¼Œå¦‚ Reactã€Swiftã€Dashã€Gradio ç­‰ã€‚

é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ conda ç¯å¢ƒå¹¶å®‰è£…æ‰€éœ€çš„åº“ã€‚

```py
# Create and activate a conda environment
conda create -n openai_chatbot python=3.10
conda activate openai_chatbot

# Install the necessary libraries
pip install ipykernel streamlit "fastapi[all]" openai
```

# **åç«¯ï¼šæ•°æ®ç§‘å­¦é€»è¾‘**

åƒæˆ‘ä¹‹å‰çš„åšå®¢æ–‡ç« ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ FastAPI æ„å»ºåç«¯ã€‚ä»»ä½• API ä¸­æœ€å…³é”®çš„éƒ¨åˆ†æ˜¯ API å¥‘çº¦ï¼Œå®ƒå®šä¹‰äº† API æ¥å—çš„è¾“å…¥æ ¼å¼å’Œ API å°†å‘é€å›å®¢æˆ·ç«¯çš„è¾“å‡ºæ ¼å¼ã€‚å®šä¹‰å¹¶éµå¾ªä¸€ä¸ªå¥å…¨çš„ API å¥‘çº¦å¯ä»¥ä½¿å‰ç«¯å¼€å‘äººå‘˜ç‹¬ç«‹äº API å¼€å‘äººå‘˜è¿›è¡Œå·¥ä½œï¼Œåªè¦åŒæ–¹éƒ½å°Šé‡å¥‘çº¦ã€‚è¿™å°±æ˜¯å°†å‰ç«¯ä¸åç«¯è§£è€¦çš„å¥½å¤„ã€‚FastAPI å…è®¸æˆ‘ä»¬ä½¿ç”¨ Pydantic æ¨¡å‹è½»æ¾åœ°æŒ‡å®šå’ŒéªŒè¯ API å¥‘çº¦ã€‚æˆ‘ä»¬çš„åç«¯ API å¥‘çº¦å¦‚ä¸‹ï¼š

![](img/9db859fa99931c586aa7bb73965cbf0a.png)

API åˆåŒç»†èŠ‚ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›

åç«¯å°†è´Ÿè´£ä»¥ä¸‹ä»»åŠ¡ï¼š

1.  é¦–å…ˆï¼Œæˆ‘ä»¬åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„ FastAPI åº”ç”¨ï¼ŒåŠ è½½ OpenAI API å¯†é’¥ï¼Œå¹¶å®šä¹‰ä¸€ä¸ªç³»ç»Ÿæç¤ºï¼Œä»¥å‘ŠçŸ¥ ChatGPT æˆ‘ä»¬å¸Œæœ›å®ƒæ‰®æ¼”çš„è§’è‰²ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ› ChatGPT æ‰®æ¼”æ¼«ç”»ä¹¦åŠ©æ‰‹çš„è§’è‰²ï¼Œå› æ­¤æˆ‘ä»¬è¿™æ ·æç¤ºå®ƒã€‚å¯ä»¥éšæ„â€œè®¾è®¡â€ä¸åŒçš„æç¤ºï¼Œå¹¶æŸ¥çœ‹ ChatGPT çš„å›åº”ï¼

1.  æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸¤ä¸ª Pydantic æ¨¡å‹ï¼Œ`Conversation` å’Œ `ConversationHistory`ï¼Œç”¨äºéªŒè¯ API è´Ÿè½½ã€‚`Conversation` æ¨¡å‹å°†éªŒè¯å¯¹è¯å†å²è®°å½•ä¸­çš„æ¯æ¡æ¶ˆæ¯ï¼Œè€Œ `ConversationHistory` æ¨¡å‹åªæ˜¯ä¸€ä¸ªå¯¹è¯åˆ—è¡¨ï¼Œç”¨äºéªŒè¯æ•´ä¸ªå¯¹è¯å†å²è®°å½•ã€‚OpenAI ChatGPT API åªæ¥å— `assistant` æˆ– `user` ä½œä¸º `role` å‚æ•°ï¼Œå› æ­¤æˆ‘ä»¬åœ¨ `Conversation` æ¨¡å‹ä¸­æŒ‡å®šäº†è¿™ä¸ªé™åˆ¶ã€‚å¦‚æœå°è¯•åœ¨ `role` å‚æ•°ä¸­å‘é€å…¶ä»–å€¼ï¼ŒAPI å°†è¿”å›é”™è¯¯ã€‚ä½¿ç”¨ Pydantic æ¨¡å‹ä¸ FastAPI é…åˆä½¿ç”¨çš„å¥½å¤„ä¹‹ä¸€å°±æ˜¯éªŒè¯ã€‚

1.  æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¸ºå¥åº·æ£€æŸ¥ä¿ç•™æ ¹è·¯ç”±ã€‚

1.  æœ€åï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ª `/chat` è·¯ç”±ï¼Œè¯¥è·¯ç”±æ¥å—ä¸€ä¸ª `POST` è¯·æ±‚ã€‚è¯¥è·¯ç”±å°†æ¥æ”¶ä¸€ä¸ª `ConversationHistory` è´Ÿè½½ï¼Œè¿™æ˜¯ä¸€ç³»åˆ—å¯¹è¯ã€‚ç„¶åï¼Œè¯¥è·¯ç”±å°†è´Ÿè½½è½¬æ¢ä¸º Python å­—å…¸ï¼Œä½¿ç”¨ç³»ç»Ÿæç¤ºå’Œè´Ÿè½½ä¸­çš„æ¶ˆæ¯åˆ—è¡¨åˆå§‹åŒ–å¯¹è¯å†å²è®°å½•ï¼Œä½¿ç”¨ OpenAI ChatGPT API ç”Ÿæˆå“åº”ï¼Œå¹¶å°†ç”Ÿæˆçš„å“åº”å’Œä»¤ç‰Œä½¿ç”¨æƒ…å†µè¿”å›ç»™ API è°ƒç”¨è€…ã€‚

```py
# %%writefile backend.py
import os
from typing import Literal

import openai
from fastapi import FastAPI
from pydantic import BaseModel, Field

app = FastAPI()

# Load your API key from an environment variable or secret management service
openai.api_key = os.getenv("OPENAI_API_KEY")

system_prompt = "You are a comic book assistant. You reply to the user's question strictly from the perspective of a comic book assistant. If the question is not related to comic books, you politely decline to answer."

class Conversation(BaseModel):
    role: Literal["assistant", "user"]
    content: str

class ConversationHistory(BaseModel):
    history: list[Conversation] = Field(
        example=[
            {"role": "user", "content": "tell me a quote from DC comics about life"},
        ]
    )

@app.get("/")
async def health_check():
    return {"status": "OK!"}

@app.post("/chat")
async def llm_response(history: ConversationHistory) -> dict:
    # Step 0: Receive the API payload as a dictionary
    history = history.dict()

    # Step 1: Initialize messages with a system prompt and conversation history
    messages = [{"role": "system", "content": system_prompt}, *history["history"]]

    # Step 2: Generate a response
    llm_response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo", messages=messages
    )

    # Step 3: Return the generated response and the token usage
    return {
        "message": llm_response.choices[0]["message"],
        "token_usage": llm_response["usage"],
    }
```

å°±è¿™æ ·ï¼æˆ‘ä»¬ç°åœ¨å¯ä»¥ä½¿ç”¨ `uvicorn backend:app â€” reload` åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œåç«¯ï¼Œå¹¶é€šè¿‡ [`127.0.0.1:8000/docs.`](http://127.0.0.1:8000/docs.) ä½¿ç”¨ Swagger UI è¿›è¡Œæµ‹è¯•ã€‚

![](img/46bbd7111851acebf2ca5fffa50dd1b2.png)

FastAPI åç«¯æ–‡æ¡£ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›

# **å‰ç«¯ï¼šç”¨æˆ·ç•Œé¢**

æˆ‘ä»¬å°†æ„å»ºå‰ç«¯ï¼Œä½¿å…¶å®Œå…¨ç‹¬ç«‹äºåç«¯ã€‚æˆ‘ä»¬åªéœ€è¦éµå®ˆåç«¯ä½¿ç”¨çš„ API åˆåŒã€‚åœ¨æ„å»ºå‰ç«¯ç”¨æˆ·ç•Œé¢ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å®šä¹‰ä¸€äº›è¾…åŠ©å‡½æ•°ã€‚

1.  `display_conversation()` å°†å¸®åŠ©æˆ‘ä»¬ä½¿ç”¨ [åŸç”Ÿ streamlit èŠå¤©å…ƒç´ ](https://docs.streamlit.io/library/api-reference/chat) æ˜¾ç¤ºå¯¹è¯å†å²è®°å½•ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¡¨æƒ…ç¬¦å·æˆ–æ–‡ä»¶è·¯å¾„ä¸ºç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯é€‰æ‹©ç‹¬ç‰¹çš„å¤´åƒã€‚

1.  `clear_conversation()` å°†å¸®åŠ©æˆ‘ä»¬æ¸…é™¤å¯¹è¯å†å²è®°å½•ã€‚å®ƒè¿˜å°†åˆå§‹åŒ– `conversation_history` ä¼šè¯çŠ¶æ€å˜é‡ä»¥å­˜å‚¨å¯¹è¯å†å²è®°å½•ï¼Œä»¥åŠ `total_cost` ä¼šè¯çŠ¶æ€å˜é‡ä»¥ä¿å­˜æ€»å¯¹è¯æˆæœ¬ã€‚

1.  `download_conversation()` å°†å…è®¸æˆ‘ä»¬å°†å¯¹è¯å†å²è®°å½•ä¸‹è½½ä¸º CSV æ–‡ä»¶ã€‚

1.  `calc_cost()`: å°†å¸®åŠ©æˆ‘ä»¬æ ¹æ®ä½¿ç”¨çš„ä»¤ç‰Œæ•°é‡è®¡ç®—å¯¹è¯æˆæœ¬ã€‚[OpenAI API å¯¹æ¯ 1000 ä¸ªè¾“å‡ºä»¤ç‰Œæ”¶è´¹ $0.002ï¼Œå¯¹æ¯ 1000 ä¸ªè¾“å…¥ä»¤ç‰Œæ”¶è´¹ $0.0015](https://openai.com/pricing#chat)ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨è¿™äº›è´¹ç”¨æ¥è®¡ç®—å¯¹è¯æˆæœ¬ã€‚

```py
# %%writefile utils.py
from datetime import datetime

import pandas as pd
import streamlit as st

user_avatar = "ğŸ˜ƒ"
assistant_avatar = "ğŸ¦¸"

def display_conversation(conversation_history):
    """Display the conversation history"""

    # Loop over all messages in the conversation
    for message in conversation_history:
        # Change avatar based on the role
        avatar = user_avatar if message["role"] == "user" else assistant_avatar

        # Display the message content
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])

            if "api_call_cost" in message:
                st.caption(f"Cost: US${message['api_call_cost']:.5f}")

def clear_conversation():
    """Clear the conversation history."""
    if (
        st.button("ğŸ§¹ Clear conversation", use_container_width=True)
        or "conversation_history" not in st.session_state
    ):
        st.session_state.conversation_history = []
        st.session_state.total_cost = 0

def download_conversation():
    """Download the conversation history as a CSV file."""
    conversation_df = pd.DataFrame(
        st.session_state.conversation_history, columns=["role", "content"]
    )
    csv = conversation_df.to_csv(index=False)

    st.download_button(
        label="ğŸ’¾ Download conversation",
        data=csv,
        file_name=f"conversation_{datetime.now().strftime('%Y%m%d%H%M%S')}.csv",
        mime="text/csv",
        use_container_width=True,
    )

def calc_cost(token_usage):
    # https://openai.com/pricing

    return (token_usage["prompt_tokens"] * 0.0015 / 1000) + (
        token_usage["completion_tokens"] * 0.002 / 1000
    )
```

ç°åœ¨æˆ‘ä»¬æ‹¥æœ‰äº†ä½¿ç”¨ Streamlit æ„å»ºç”¨æˆ·ç•Œé¢æ‰€éœ€çš„ä¸€åˆ‡ã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª frontend.py æ–‡ä»¶å¹¶å¯¼å…¥æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„åŠ©æ‰‹å‡½æ•°ã€‚

1.  é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®šä¹‰æˆ‘ä»¬ FastAPI åç«¯çš„ URLã€‚

1.  `openai_llm_response()` å°†ä½¿ç”¨ `user` è§’è‰²å°†æœ€æ–°çš„ç”¨æˆ·è¾“å…¥é™„åŠ åˆ° `conversation_history` ä¼šè¯çŠ¶æ€å˜é‡ä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç¬¦åˆæˆ‘ä»¬åç«¯ FastAPI åº”ç”¨ç¨‹åºæœŸæœ›çš„æ ¼å¼çš„æœ‰æ•ˆè´Ÿè½½ï¼ŒåŒ…å« `history` å­—æ®µã€‚æœ€åï¼Œæˆ‘ä»¬å°†æœ‰æ•ˆè´Ÿè½½å‘é€åˆ°åç«¯ï¼Œå¹¶å°†ç”Ÿæˆçš„å“åº”åŠå•æ¬¡ API è°ƒç”¨çš„æˆæœ¬é™„åŠ åˆ° `conversation_history` ä¼šè¯çŠ¶æ€å˜é‡ä¸­ã€‚æˆ‘ä»¬è¿˜å°†ç”¨ç”Ÿæˆå“åº”çš„æˆæœ¬å¢åŠ æ€»æˆæœ¬ã€‚

1.  `main()`: æ˜¯ UI è®¾è®¡çš„ä¸»è¦éƒ¨åˆ†ã€‚åœ¨æ ‡é¢˜ä¸‹æ–¹ï¼Œæˆ‘ä»¬ä½¿ç”¨ utils.py ä¸­çš„åŠ©æ‰‹å‡½æ•°æ·»åŠ äº†æ¸…é™¤å’Œä¸‹è½½å¯¹è¯çš„æŒ‰é’®ã€‚æ¥ç€æˆ‘ä»¬æœ‰ä¸€ä¸ªèŠå¤©è¾“å…¥æ¡†ï¼Œç”¨æˆ·å¯ä»¥åœ¨å…¶ä¸­è¾“å…¥é—®é¢˜ã€‚æŒ‰ä¸‹å›è½¦å°†æŠŠè¾“å…¥æ¡†ä¸­è¾“å…¥çš„æ–‡æœ¬å‘é€åˆ°åç«¯ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºå¯¹è¯çš„æˆæœ¬å’Œå¯¹è¯å†å²ã€‚

```py
# %%writefile frontend.py
import requests
import streamlit as st
import utils

# Replace with the URL of your backend
app_url = "http://127.0.0.1:8000/chat"

@st.cache_data(show_spinner="ğŸ¤” Thinking...")
def openai_llm_response(user_input):
    """Send the user input to the LLM API and return the response."""

    # Append user question to the conversation history
    st.session_state.conversation_history.append(
        {"role": "user", "content": user_input}
    )

    # Send the entire conversation history to the backend
    payload = {"history": st.session_state.conversation_history}
    response = requests.post(app_url, json=payload).json()

    # Generate the unit api call cost and add it to the response
    api_call_cost = utils.calc_cost(response["token_usage"])
    api_call_response = response["message"]
    api_call_response["api_call_cost"] = api_call_cost

    # Add everything to the session state
    st.session_state.conversation_history.append(api_call_response)
    st.session_state.total_cost += api_call_cost

def main():
    st.title("ğŸ¦¸ ChatGPT Comic Book Assistant")

    col1, col2 = st.columns(2)
    with col1:
        utils.clear_conversation()

    # Get user input
    if user_input := st.chat_input("Ask me any comic book question!", max_chars=50):
        openai_llm_response(user_input)

    # Display the total cost
    st.caption(f"Total cost of this session: US${st.session_state.total_cost:.5f}")

    # Display the entire conversation on the frontend
    utils.display_conversation(st.session_state.conversation_history)

    # Download conversation code runs last to ensure the latest messages are captured
    with col2:
        utils.download_conversation()

if __name__ == "__main__":
    main()
```

å°±è¿™æ ·ï¼æˆ‘ä»¬å·²å®Œæˆå‰ç«¯åº”ç”¨ç¨‹åºã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `streamlit run frontend.py` è¿›è¡Œæµ‹è¯•ã€‚

![](img/0c5887d6217d4671781ef04e23b45722.png)

Streamlit App ç•Œé¢ã€‚å›¾åƒæ¥æºï¼šä½œè€…

# **ç»“è®º**

ä½¿ç”¨ OpenAI API æ„å»ºä¸€ä¸ªèŠå¤©æœºå™¨äººï¼Œé‡‡ç”¨å¾®æœåŠ¡æ¶æ„é€šè¿‡å°†å‰ç«¯ä¸åç«¯è§£è€¦æ˜¯å¾ˆç®€å•çš„ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›è€ƒè™‘ä½•æ—¶é‡‡ç”¨è§£è€¦æ¶æ„çš„æƒ³æ³•ï¼š

1.  ä½ çš„åº”ç”¨ç›¸å¯¹å¤æ‚æˆ–éœ€è¦æ”¯æŒä¸­åˆ°å¤§è§„æ¨¡çš„æµé‡ã€‚è§£è€¦æ¶æ„å…è®¸å‰ç«¯å’Œåç«¯ç‹¬ç«‹æ‰©å±•ï¼Œä»¥å¤„ç†å¤§è§„æ¨¡æµé‡ã€‚

1.  ä½ æœ‰ä¸“é—¨çš„å‰ç«¯å¼€å‘èµ„æºæ¥æ„å»º UIï¼Œæˆ–è€…éœ€è¦ä¸ºå¤–éƒ¨å®¢æˆ·æä¾›é«˜åº¦ç²¾è‡´çš„ UIã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† Streamlit æ„å»ºäº†ä¸€ä¸ªç®€å•çš„ç”¨æˆ·ç•Œé¢ï¼Œä½†æ„å»ºæ›´å¤æ‚çš„ UI å¯èƒ½ä¼šå˜å¾—å›°éš¾ç”šè‡³ä¸å¯èƒ½ã€‚æœ€å¥½ä½¿ç”¨åƒ Reactã€Swift ç­‰ä¸“ä¸š UI æ¡†æ¶æ¥æ„å»ºé¢å‘å®¢æˆ·çš„åº”ç”¨ç¨‹åºã€‚

1.  ä½ æƒ³ç‹¬ç«‹äºå‰ç«¯æ”¹è¿›æ•°æ®ç§‘å­¦é€»è¾‘ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥æ›´æ–°æç¤ºè¯æˆ–æ·»åŠ å¤šä¸ªå¾®æœåŠ¡ï¼Œæ‰€æœ‰è¿™äº›éƒ½ç”± API æœåŠ¡å™¨å…¥å£ç‚¹è¿›è¡Œåè°ƒï¼Œåªè¦ä½ éµå®ˆä¸å‰ç«¯å·¥ç¨‹å¸ˆè¾¾æˆçš„ç›¸åŒ API åˆåŒï¼Œå°±æ— éœ€æ‹…å¿ƒå‰ç«¯ä»£ç ã€‚

ç„¶è€Œï¼Œå¯èƒ½ä¼šæœ‰ä¸€äº›æƒ…å†µä¸‹ï¼Œè§£è€¦ä¸æ˜¯ä½ åº”ç”¨çš„æœ€ä½³æ¶æ„é€‰æ‹©ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å…³äºä½•æ—¶ä¸ä½¿ç”¨è§£è€¦æ¶æ„çš„æƒ³æ³•ï¼š

1.  ä½ çš„åº”ç”¨å¾ˆç®€å•æˆ–æµé‡è¾ƒä½ã€‚ä½ å¯ä»¥ä½¿ç”¨å•ä½“åº”ç”¨ç¨‹åºï¼Œå› ä¸ºæ‰©å±•ä¸æ˜¯é—®é¢˜ã€‚

1.  ä½ æ²¡æœ‰ä¸“é—¨çš„å‰ç«¯å¼€å‘èµ„æºæ¥æ„å»ºç”¨æˆ·ç•Œé¢ï¼Œæˆ–è€…ä½ çš„åº”ç”¨ç¨‹åºä»…æœåŠ¡äºå†…éƒ¨å®¢æˆ·ï¼Œè¿™äº›å®¢æˆ·å¯èƒ½å¯¹ç²—ç³™çš„ç”¨æˆ·ç•Œé¢è®¾è®¡æ›´ä¸ºå®½å®¹ã€‚å°¤å…¶æ˜¯åœ¨æ„å»ºæœ€å°å¯è¡Œäº§å“æˆ–åŸå‹æ—¶ï¼Œè¿™ä¸€ç‚¹å°¤ä¸ºæ˜æ˜¾ã€‚

1.  ä½ æ˜¯ä¸€ä¸ªæƒ³è¦åŒæ—¶æå‡æ•°æ®ç§‘å­¦é€»è¾‘å’Œå‰ç«¯ç•Œé¢çš„ç‹¬è§’å…½ï¼
