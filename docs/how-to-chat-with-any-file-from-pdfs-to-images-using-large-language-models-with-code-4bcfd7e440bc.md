# å¦‚ä½•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸ä»»ä½• PDF å’Œå›¾åƒæ–‡ä»¶è¿›è¡ŒèŠå¤© â€” å¸¦ä»£ç 

> åŸæ–‡ï¼š[`towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc`](https://towardsdatascience.com/how-to-chat-with-any-file-from-pdfs-to-images-using-large-language-models-with-code-4bcfd7e440bc)

## å®Œæ•´æŒ‡å—ï¼Œæ•™ä½ å¦‚ä½•æ„å»ºä¸€ä¸ªå¯ä»¥å›ç­”ä»»ä½•æ–‡ä»¶é—®é¢˜çš„ AI åŠ©æ‰‹

[](https://zoumanakeita.medium.com/?source=post_page-----4bcfd7e440bc--------------------------------)![Zoumana Keita](https://zoumanakeita.medium.com/?source=post_page-----4bcfd7e440bc--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4bcfd7e440bc--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----4bcfd7e440bc--------------------------------) [Zoumana Keita](https://zoumanakeita.medium.com/?source=post_page-----4bcfd7e440bc--------------------------------)

Â·å‘è¡¨äº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4bcfd7e440bc--------------------------------) Â·9 åˆ†é’Ÿé˜…è¯»Â·2023 å¹´ 8 æœˆ 5 æ—¥

--

# ä»‹ç»

PDF å’Œå›¾åƒæ–‡ä»¶ä¸­å›°è—ç€å¦‚æ­¤å®è´µçš„ä¿¡æ¯ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬æœ‰è¿™äº›å¼ºå¤§çš„å¤§è„‘ï¼Œèƒ½å¤Ÿå¤„ç†è¿™äº›æ–‡ä»¶ä»¥æ‰¾åˆ°ç‰¹å®šä¿¡æ¯ï¼Œè¿™å®é™…ä¸Šéå¸¸æ£’ã€‚

> ä½†æˆ‘ä»¬ä¸­æœ‰å¤šå°‘äººï¼Œå†…å¿ƒæ·±å¤„å¹¶ä¸å¸Œæœ›æ‹¥æœ‰ä¸€ä¸ªèƒ½å›ç­”å…³äºç»™å®šæ–‡æ¡£çš„ä»»ä½•é—®é¢˜çš„å·¥å…·å‘¢ï¼Ÿ

è¿™å°±æ˜¯æœ¬æ–‡çš„å…¨éƒ¨ç›®çš„ã€‚æˆ‘å°†é€æ­¥è§£é‡Šå¦‚ä½•æ„å»ºä¸€ä¸ªèƒ½å¤Ÿä¸ä»»ä½• PDF å’Œå›¾åƒæ–‡ä»¶èŠå¤©çš„ç³»ç»Ÿã€‚

> å¦‚æœä½ æ›´æ„¿æ„è§‚çœ‹è§†é¢‘ï¼Œè¯·æŸ¥çœ‹ä¸‹é¢çš„é“¾æ¥ï¼š

æ–‡ç« çš„è§†é¢‘æ ¼å¼

## é¡¹ç›®çš„æ€»ä½“å·¥ä½œæµç¨‹

æ¸…æ¥šäº†è§£ç³»ç»Ÿçš„ä¸»è¦ç»„ä»¶æ€»æ˜¯å¥½çš„ã€‚é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ã€‚

![](img/84a8f95dccd53c58aa61e24bcae40112.png)

æ•´ä¸ªèŠå¤©ç³»ç»Ÿçš„ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹ï¼ˆä½œè€…æä¾›çš„å›¾åƒï¼‰

+   é¦–å…ˆï¼Œç”¨æˆ·æäº¤éœ€è¦å¤„ç†çš„æ–‡æ¡£ï¼Œå¯ä»¥æ˜¯ PDF æˆ–å›¾åƒæ ¼å¼ã€‚

+   ç¬¬äºŒä¸ªæ¨¡å—ç”¨äºæ£€æµ‹æ–‡ä»¶æ ¼å¼ï¼Œä»¥ä¾¿åº”ç”¨ç›¸å…³çš„å†…å®¹æå–åŠŸèƒ½ã€‚

+   ç„¶åï¼Œæ–‡æ¡£çš„å†…å®¹ä½¿ç”¨`Data Splitter`æ¨¡å—è¢«æ‹†åˆ†æˆå¤šä¸ªå—ã€‚

+   è¿™äº›å—æœ€ç»ˆé€šè¿‡`Chunk Transformer`è½¬æ¢ä¸ºåµŒå…¥ï¼Œç„¶åå­˜å‚¨åœ¨å‘é‡å­˜å‚¨ä¸­ã€‚

+   åœ¨å¤„ç†ç»“æŸæ—¶ï¼Œç”¨æˆ·çš„æŸ¥è¯¢è¢«ç”¨æ¥æ‰¾åˆ°åŒ…å«è¯¥æŸ¥è¯¢ç­”æ¡ˆçš„ç›¸å…³å—ï¼Œç»“æœä»¥ JSON æ ¼å¼è¿”å›ç»™ç”¨æˆ·ã€‚

## 1\. æ£€æµ‹æ–‡æ¡£ç±»å‹

å¯¹äºæ¯ä¸ªè¾“å…¥æ–‡æ¡£ï¼Œæ ¹æ®å…¶ç±»å‹åº”ç”¨ç‰¹å®šçš„å¤„ç†ï¼Œæ— è®ºæ˜¯`PDF`è¿˜æ˜¯`image.`

è¿™å¯ä»¥é€šè¿‡ç»“åˆä½¿ç”¨`detect_document_type`çš„è¾…åŠ©å‡½æ•°å’Œå†…ç½® Python æ¨¡å—ä¸­çš„`guess`å‡½æ•°æ¥å®ç°ã€‚

```py
def detect_document_type(document_path):

    guess_file = guess(document_path)
    file_type = ""
    image_types = ['jpg', 'jpeg', 'png', 'gif']

    if(guess_file.extension.lower() == "pdf"):
        file_type = "pdf"

    elif(guess_file.extension.lower() in image_types):
        file_type = "image"

    else:
        file_type = "unkown"

    return file_type
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥åœ¨ä¸¤ç§ç±»å‹çš„æ–‡æ¡£ä¸Šæµ‹è¯•è¿™ä¸ªåŠŸèƒ½ï¼š

+   `transformer_paper.pdf` æ˜¯ Transformers ç ”ç©¶è®ºæ–‡ [æ¥è‡ª Arxiv](https://arxiv.org/pdf/1706.03762.pdf)ã€‚

+   `zoumana_article_information.png` æ˜¯åŒ…å«æœ‰å…³æˆ‘åœ¨ Medium ä¸Šæ‰€æ¶µç›–çš„ä¸»è¦ä¸»é¢˜ä¿¡æ¯çš„å›¾åƒæ–‡æ¡£ã€‚

```py
research_paper_path = "./data/transformer_paper.pdf"
article_information_path = "./data/zoumana_article_information.png"

print(f"Research Paper Type: {detect_document_type(research_paper_path)}")
print(f"Article Information Document Type: {detect_document_type(article_information_path)}")
```

è¾“å‡ºï¼š

![](img/0f6456b0157ceb2106c561fe6d04c038.png)

æ–‡ä»¶ç±»å‹æˆåŠŸæ£€æµ‹ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

`detect_document_type` å‡½æ•°æˆåŠŸæ£€æµ‹äº†è¿™ä¸¤ç§æ–‡ä»¶ç±»å‹ã€‚

## 2\. åŸºäºæ–‡æ¡£ç±»å‹æå–å†…å®¹

`[langchain](https://python.langchain.com/docs/get_started/introduction.html)` åº“æä¾›äº†ä¸åŒçš„æ¨¡å—æ¥æå–ç‰¹å®šç±»å‹æ–‡æ¡£çš„å†…å®¹ã€‚

+   `UnstructuredImageLoader` æå–å›¾åƒå†…å®¹ã€‚

+   `UnstructuredFileLoader` æå–ä»»ä½• pdf å’Œ Txt æ–‡ä»¶çš„å†…å®¹ã€‚

æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ¨¡å—ä¸ä¸Šè¿°`detect_document_type`å‡½æ•°ç»“åˆèµ·æ¥ï¼Œå®ç°æ–‡æœ¬æå–é€»è¾‘ã€‚

è¿™äº›æ¨¡å—å¯ä»¥ç”¨äºåœ¨`extract_file_content`å‡½æ•°ä¸­å®ç°ç«¯åˆ°ç«¯çš„æ–‡æœ¬æå–é€»è¾‘ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å®ƒä»¬çš„å®é™…æ•ˆæœï¼ ğŸ”¥

```py
from langchain.document_loaders.image import UnstructuredImageLoader
from langchain.document_loaders import UnstructuredFileLoader

def extract_file_content(file_path):

    file_type = detect_document_type(file_path)

    if(file_type == "pdf"):
        loader = UnstructuredFileLoader(file_path)

    elif(file_type == "image"):
        loader = UnstructuredImageLoader(file_path)

    documents = loader.load()
    documents_content = '\n'.join(doc.page_content for doc in documents)

    return documents_content
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ‰“å°æ¯ä¸ªæ–‡ä»¶å†…å®¹çš„å‰ `400` ä¸ªå­—ç¬¦ã€‚

```py
research_paper_content = extract_file_content(research_paper_path)
article_information_content = extract_file_content(article_information_path)

nb_characters = 400

print(f"First {nb_characters} Characters of the Paper: \n{research_paper_content[:nb_characters]} ...")
print("---"*5)
print(f"First {nb_characters} Characters of Article Information Document :\n {research_paper_content[:nb_characters]} ...")
```

è¾“å‡ºï¼š

ä»¥ä¸Šæ¯ä¸ªæ–‡æ¡£çš„å‰ 400 ä¸ªå­—ç¬¦å¦‚ä¸‹ï¼š

+   ç ”ç©¶è®ºæ–‡çš„å†…å®¹ä»¥`Provided proper attribution is provided` å¼€å§‹ï¼Œä»¥`Jacod Uszkoreit* Google Research usz@google.com.` ç»“æŸã€‚

+   å›¾åƒæ–‡æ¡£çš„å†…å®¹ä»¥`This document provides a quick summary` å¼€å§‹ï¼Œä»¥`Data Science section covers basic to advance concepts.` ç»“æŸã€‚

![](img/c03c271f7d3bd2cb53d17f3989ac0dd5.png)

Transformers è®ºæ–‡å’Œæ–‡ç« ä¿¡æ¯æ–‡æ¡£çš„å‰ 400 ä¸ªå­—ç¬¦ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

## 3\. èŠå¤©å®ç°

è¾“å…¥æ–‡æ¡£è¢«åˆ†æˆå—ï¼Œç„¶åä¸ºæ¯ä¸ªå—åˆ›å»ºåµŒå…¥ï¼Œä¹‹åå®ç°é—®ç­”é€»è¾‘ã€‚

**a. æ–‡æ¡£åˆ†å—**

è¿™äº›å—ä»£è¡¨äº†è¾ƒå¤§æ–‡æœ¬çš„ä¸€å°æ®µã€‚è¿™ä¸€è¿‡ç¨‹å¯¹äºç¡®ä¿å†…å®¹å°½å¯èƒ½å°‘çš„å™ªéŸ³ï¼Œå¹¶ä¿æŒè¯­ä¹‰ç›¸å…³æ€§è‡³å…³é‡è¦ã€‚

å¯ä»¥åº”ç”¨å¤šç§åˆ†å—ç­–ç•¥ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬æœ‰ `NLTKTextSplitter`ã€`SpacyTextSplitter`ã€`RecursiveCharacterTextSplitter`ã€`CharacterTextSplitter` ç­‰ã€‚

è¿™äº›ç­–ç•¥å„æœ‰ä¼˜ç¼ºç‚¹ã€‚

æœ¬æ–‡çš„é‡ç‚¹æ˜¯ `CharacterTextSplitter`ï¼Œå®ƒæ ¹æ® `\n\n` ä»è¾“å…¥æ–‡æ¡£ä¸­åˆ›å»ºå—ï¼Œå¹¶é€šè¿‡å­—ç¬¦æ•°é‡ï¼ˆ`length_function`ï¼‰æ¥è¡¡é‡æ¯ä¸ªå—çš„é•¿åº¦ã€‚

```py
text_splitter = CharacterTextSplitter(        
    separator = "\n\n",
    chunk_size = 1000,
    chunk_overlap  = 200,
    length_function = len,
)
```

`chunk_size` æŒ‡å®šæˆ‘ä»¬å¸Œæœ›æ¯ä¸ªå—æœ€å¤šåŒ…å« 1000 ä¸ªå­—ç¬¦ï¼Œè€Œè¾ƒå°çš„å€¼å°†å¯¼è‡´æ›´å¤šçš„å—ï¼Œè€Œè¾ƒå¤§çš„å€¼å°†ç”Ÿæˆæ›´å°‘çš„å—ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`chunk_size` çš„é€‰æ‹©æ–¹å¼ä¼šå½±å“æ•´ä½“ç»“æœã€‚å› æ­¤ï¼Œä¸€ä¸ªå¥½çš„æ–¹æ³•æ˜¯å°è¯•ä¸åŒçš„å€¼ï¼Œé€‰æ‹©æœ€é€‚åˆè‡ªå·±ç”¨ä¾‹çš„é‚£ä¸ªã€‚

æ­¤å¤–ï¼Œ`chunk_overlap` è¡¨ç¤ºæˆ‘ä»¬å¸Œæœ›è¿ç»­å—ä¹‹é—´æœ‰æœ€å¤š 200 ä¸ªé‡å å­—ç¬¦ã€‚

ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«æ–‡æœ¬ `Chat with your documents using LLMs` çš„æ–‡æ¡£ï¼Œå¹¶æƒ³ä½¿ç”¨ `Chunk Size = 10` å’Œ `Chunk overlap = 5` æ¥åº”ç”¨å—åŒ–ã€‚

è¯¥è¿‡ç¨‹åœ¨ä¸‹é¢çš„å›¾åƒä¸­è¿›è¡Œäº†è¯´æ˜ï¼š

![](img/0c513e3c8a79c4e85371ebed619bb1ca.png)

æ–‡æ¡£å—åŒ–ç¤ºä¾‹ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äºä¸€ä¸ªåŒ…å« 35 ä¸ªå­—ç¬¦ï¼ˆåŒ…æ‹¬ç©ºæ ¼ï¼‰çš„è¾“å…¥æ–‡æ¡£ï¼Œæˆ‘ä»¬æœ€ç»ˆå¾—åˆ°äº† 7 ä¸ªå—ã€‚

> ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆè¦ä½¿ç”¨è¿™äº›é‡å éƒ¨åˆ†å‘¢ï¼Ÿ

åŒ…æ‹¬è¿™äº›é‡å éƒ¨åˆ†ï¼Œ`CharacterTextSplitter` ç¡®ä¿åœ¨å—ä¹‹é—´ä¿æŒåº•å±‚ä¸Šä¸‹æ–‡ï¼Œè¿™åœ¨å¤„ç†é•¿æ–‡æ¡£æ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚

ç±»ä¼¼äº `chunk_size`ï¼Œ`chunk_overlap` æ²¡æœ‰å›ºå®šå€¼ã€‚éœ€è¦æµ‹è¯•ä¸åŒçš„å€¼ä»¥é€‰æ‹©æ•ˆæœæ›´å¥½çš„å€¼ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å®ƒä»¬åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­çš„åº”ç”¨ï¼š

```py
research_paper_chunks = text_splitter.split_text(research_paper_content)
article_information_chunks = text_splitter.split_text(article_information_content)

print(f"# Chunks in Research Paper: {len(research_paper_chunks)}")
print(f"# Chunks in Article Document: {len(article_information_chunks)}")
```

è¾“å‡ºï¼š

![](img/15039c16589eb887d710631a85066443.png)

æ¯ä¸ªæ–‡æ¡£ä¸­çš„å—æ•°ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

å¯¹äºåƒç ”ç©¶è®ºæ–‡è¿™æ ·çš„è¾ƒå¤§æ–‡æ¡£ï¼Œæˆ‘ä»¬æœ‰æ›´å¤šçš„å—ï¼ˆ51 ä¸ªï¼‰ï¼Œè€Œä¸€é¡µæ–‡ç« æ–‡æ¡£åªæœ‰ 2 ä¸ªå—ã€‚

**b. åˆ›å»ºå—çš„åµŒå…¥**

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `OpenAIEmbeddings` æ¨¡å—ï¼Œè¯¥æ¨¡å—é»˜è®¤ä½¿ç”¨ `text-embedding-ada-002` æ¨¡å‹æ¥åˆ›å»ºå—çš„åµŒå…¥ã€‚

å¯ä»¥é€šè¿‡æ›´æ”¹ä»¥ä¸‹å‚æ•°ï¼Œä½¿ç”¨ä¸åŒçš„æ¨¡å‹ï¼ˆä¾‹å¦‚ `gpt-3.5-turbo-0301`ï¼‰æ¥ä»£æ›¿ `text-embedding-ada-002`ï¼š

+   model = â€œ`gpt-3.5-turbo-0301`â€

+   deployment = "`<DEPLOYMENT-NAME>` "ï¼Œè¿™å¯¹åº”äºåœ¨æ¨¡å‹éƒ¨ç½²æœŸé—´ç»™å‡ºçš„åç§°ã€‚é»˜è®¤å€¼ä¹Ÿæ˜¯ `text-embedding-ada-002`

ä¸ºäº†ç®€å•èµ·è§ï¼Œåœ¨æœ¬æ•™ç¨‹ä¸­æˆ‘ä»¬å°†åšæŒä½¿ç”¨é»˜è®¤å‚æ•°å€¼ã€‚ä½†åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è·å– OpenAI å‡­æ®ï¼Œæ‰€æœ‰æ­¥éª¤åœ¨ [ä»¥ä¸‹æ–‡ç« ](https://medium.com/geekculture/how-to-fine-tune-gpt3-using-openai-api-and-python-9ef813879af4) ä¸­æä¾›ã€‚

```py
from langchain.embeddings.openai import OpenAIEmbeddings
import os

os.environ["OPENAI_API_KEY"] = "<YOUR_KEY>"
embeddings = OpenAIEmbeddings()
```

**c. åˆ›å»ºæ–‡æ¡£æœç´¢**

è¦å›ç­”ç»™å®šçš„æŸ¥è¯¢ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªå‘é‡å­˜å‚¨ï¼Œä»¥æ‰¾åˆ°ä¸è¯¥æŸ¥è¯¢æœ€åŒ¹é…çš„å—ã€‚

è¿™æ ·çš„å‘é‡å­˜å‚¨å¯ä»¥ä½¿ç”¨ `FAISS` æ¨¡å—ä¸­çš„ `from_texts` å‡½æ•°åˆ›å»ºï¼Œè¯¥å‡½æ•°éœ€è¦ä¸¤ä¸ªä¸»è¦å‚æ•°ï¼š`text_splitter` å’Œ `embeddings`ï¼Œè¿™ä¸¤è€…éƒ½å·²å®šä¹‰ã€‚

```py
from langchain.vectorstores import FAISS

def get_doc_search(text_splitter):

    return FAISS.from_texts(text_splitter, embeddings)
```

é€šè¿‡åœ¨ç ”ç©¶è®ºæ–‡å—ä¸Šè¿è¡Œ `get_doc_search`ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç»“æœæ˜¯ `vectorstores`ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ article_information_chunksï¼Œç»“æœä¹Ÿä¼šç›¸åŒã€‚

```py
doc_search_paper = get_doc_search(research_paper_chunks)
print(doc_search_paper)
```

è¾“å‡ºï¼š

![](img/83925a3f53662ad0e178de1561b3efcb.png)

ç ”ç©¶è®ºæ–‡çš„å‘é‡å­˜å‚¨ï¼ˆä½œè€…æä¾›çš„å›¾ç‰‡ï¼‰

**d. å¼€å§‹ä¸ä½ çš„æ–‡æ¡£èŠå¤©**

æ­å–œä½ èµ°åˆ°è¿™ä¸€æ­¥ï¼ ğŸ‰

`chat_with_file` å‡½æ•°ç”¨äºå®ç°èŠå¤©çš„ç«¯åˆ°ç«¯é€»è¾‘ï¼Œå°†æ‰€æœ‰ä¸Šè¿°å‡½æ•°ä¸ `similarity_search` å‡½æ•°ç»“åˆä½¿ç”¨ã€‚

æœ€ç»ˆå‡½æ•°éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼š

+   æˆ‘ä»¬æƒ³è¦èŠå¤©çš„æ–‡ä»¶ï¼Œä»¥åŠ

+   ç”¨æˆ·æä¾›çš„æŸ¥è¯¢

```py
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
chain = load_qa_chain(OpenAI(), chain_type = "map_rerank",  
                      return_intermediate_steps=True)

def chat_with_file(file_path, query):

    file_content = extract_file_content(file_path)
    text_splitter = text_splitter.split_text(file_content)

    document_search = get_doc_search(text_splitter)
    documents = document_search.similarity_search(query)

    results = chain({
                        "input_documents":documents, 
                        "question": query
                    }, 
                    return_only_outputs=True)
    answers = results['intermediate_steps'][0]

    return answers
```

è®©æˆ‘ä»¬é€€ä¸€æ­¥ï¼Œä»¥æ­£ç¡®ç†è§£ä¸Šè¿°ä»£ç å—ä¸­å‘ç”Ÿçš„äº‹æƒ…ã€‚

+   `load_qa_chain` æä¾›äº†ä¸€ä¸ªæ¥å£ï¼Œç”¨äºåœ¨ä¸€ç»„æ–‡æ¡£ä¸Šæ‰§è¡Œé—®ç­”ã€‚åœ¨è¿™ä¸ªç‰¹å®šçš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯é»˜è®¤çš„ `OpenAI GPT-3` å¤§å‹è¯­è¨€æ¨¡å‹ã€‚

+   `chain_type` æ˜¯ `map_rerank` ã€‚é€šè¿‡è¿™æ ·åšï¼Œ`load_qa_chain` å‡½æ•°æ ¹æ®é“¾æä¾›çš„ç½®ä¿¡åº¦åˆ†æ•°è¿”å›ç­”æ¡ˆã€‚è¿˜æœ‰å…¶ä»–å¯ä»¥ä½¿ç”¨çš„ `chain_type`ï¼Œå¦‚ `map_reduce`ã€`stuff`ã€`refine` ç­‰ã€‚æ¯ç§éƒ½æœ‰å…¶ä¼˜ç¼ºç‚¹ã€‚

+   é€šè¿‡è®¾ç½® `return_intermediate_steps=True`ï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®è¯¸å¦‚ä¸Šè¿°ç½®ä¿¡åº¦åˆ†æ•°ç­‰å…ƒæ•°æ®ã€‚

å®ƒçš„è¾“å‡ºæ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªé”®çš„å­—å…¸ï¼šæŸ¥è¯¢çš„ **ç­”æ¡ˆ** å’Œç½®ä¿¡åº¦ **åˆ†æ•°**ã€‚

æˆ‘ä»¬ç»ˆäºå¯ä»¥å¼€å§‹ä¸æˆ‘ä»¬çš„æ–‡ä»¶èŠå¤©ï¼Œä»å›¾åƒæ–‡æ¡£å¼€å§‹ï¼š

+   **ä¸å›¾åƒæ–‡æ¡£èŠå¤©**

è¦ä¸å›¾åƒæ–‡æ¡£èŠå¤©ï¼Œæˆ‘ä»¬æä¾›æ–‡æ¡£è·¯å¾„å’Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹å›ç­”çš„é—®é¢˜ã€‚

```py
query = "What is the document about"

results = chat_with_file(article_information_path, query)

answer = results["answer"]
confidence_score = results["score"]

print(f"Answer: {answer}\n\nConfidence Score: {confidence_score}")
```

è¾“å‡ºï¼š

![](img/34fd452b4430151ca4a7a5bea6dbceb1.png)

å¯¹å›¾åƒæ–‡æ¡£çš„æŸ¥è¯¢ç»“æœï¼ˆå›¾åƒæ¥æºï¼šä½œè€…ï¼‰

æ¨¡å‹å¯¹å…¶å“åº”æœ‰ 100% çš„ä¿¡å¿ƒã€‚é€šè¿‡æŸ¥çœ‹ä¸‹é¢çš„åŸå§‹æ–‡æ¡£çš„ç¬¬ä¸€æ®µï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¨¡å‹çš„å“åº”ç¡®å®æ˜¯æ­£ç¡®çš„ã€‚

![](img/110f996f430c1236dcc24ef9b5b2b9b4.png)

åŸå§‹æ–‡ç« å›¾åƒæ–‡æ¡£çš„å‰ä¸¤æ®µï¼ˆå›¾åƒæ¥æºï¼šä½œè€…ï¼‰

æœ€æœ‰è¶£çš„éƒ¨åˆ†ä¹‹ä¸€æ˜¯å®ƒæä¾›äº†æ–‡æ¡£ä¸­ä¸»è¦ä¸»é¢˜çš„ç®€è¦æ€»ç»“ï¼ˆç»Ÿè®¡ã€æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ã€SQL æŸ¥è¯¢ç­‰ï¼‰ã€‚

+   **ä¸ PDF æ–‡ä»¶èŠå¤©**

PDF æ–‡ä»¶çš„å¤„ç†è¿‡ç¨‹ç±»ä¼¼äºä¸Šè¿°éƒ¨åˆ†ã€‚

```py
query = "Why is the self-attention approach used in this document?"

results = chat_with_file(research_paper_path, query)

answer = results["answer"]
confidence_score = results["score"]

print(f"Answer: {answer}\n\nConfidence Score: {confidence_score}")
```

è¾“å‡ºï¼š

æˆ‘ä»¬å†æ¬¡ä»æ¨¡å‹ä¸­è·å¾—äº† 100% çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚é—®é¢˜çš„ç­”æ¡ˆçœ‹èµ·æ¥éå¸¸æ­£ç¡®ï¼

![](img/6947fe479ba82c3cde792c3bf82f6981.png)

å¯¹ PDF æ–‡æ¡£çš„æŸ¥è¯¢ç»“æœï¼ˆå›¾åƒæ¥æºï¼šä½œè€…ï¼‰

åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹éƒ½èƒ½å¤Ÿåœ¨å‡ ç§’é’Ÿå†…æä¾›ç±»ä¼¼äººç±»çš„å“åº”ã€‚è®©ä¸€ä¸ªäººç»å†ç›¸åŒçš„è¿‡ç¨‹å°†éœ€è¦å‡ åˆ†é’Ÿï¼Œç”šè‡³å‡ å°æ—¶ï¼Œå…·ä½“å–å†³äºæ–‡æ¡£çš„é•¿åº¦ã€‚

# ç»“è®º

æ­å–œï¼ï¼ï¼ğŸ‰

æˆ‘å¸Œæœ›è¿™ç¯‡æ–‡ç« æä¾›äº†è¶³å¤Ÿçš„å·¥å…·æ¥å¸®åŠ©ä½ æå‡çŸ¥è¯†æ°´å¹³ã€‚ä»£ç å¯åœ¨ [æˆ‘çš„ GitHub](https://github.com/keitazoumana/Medium-Articles-Notebooks/blob/main/Chat_With_Any_Document.ipynb) ä¸Šè·å–ã€‚

åœ¨æˆ‘çš„ä¸‹ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†è§£é‡Šå¦‚ä½•å°†è¿™ä¸ªç³»ç»Ÿé›†æˆåˆ°ä¸€ä¸ªæ¼‚äº®çš„ç”¨æˆ·ç•Œé¢ä¸­ã€‚æ•¬è¯·æœŸå¾…ï¼

å¦‚æœä½ å–œæ¬¢é˜…è¯»æˆ‘çš„æ•…äº‹å¹¶å¸Œæœ›æ”¯æŒæˆ‘çš„å†™ä½œï¼Œè€ƒè™‘æˆä¸º Medium ä¼šå‘˜ã€‚æ¯æœˆ $5ï¼Œä½ å°†è·å¾—å¯¹æˆåƒä¸Šä¸‡çš„ Python æŒ‡å—å’Œæ•°æ®ç§‘å­¦æ–‡ç« çš„æ— é™è®¿é—®ã€‚

é€šè¿‡ä½¿ç”¨ [æˆ‘çš„é“¾æ¥](https://zoumanakeita.medium.com/membership)ï¼Œæˆ‘å°†è·å¾—å°‘é‡ä½£é‡‘ï¼Œè€Œä½ æ— éœ€é¢å¤–æ”¯ä»˜ã€‚

[](https://zoumanakeita.medium.com/membership?source=post_page-----4bcfd7e440bc--------------------------------) [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium - Zoumana Keita]

### ä½œä¸º Medium ä¼šå‘˜ï¼Œä½ çš„ä¼šå‘˜è´¹ç”¨çš„ä¸€éƒ¨åˆ†ä¼šç”¨äºæ”¯æŒä½ é˜…è¯»çš„ä½œè€…ï¼ŒåŒæ—¶ä½ å¯ä»¥å®Œå…¨è®¿é—®æ¯ä¸ªæ•…äº‹â€¦â€¦

[zoumanakeita.medium.com](https://zoumanakeita.medium.com/membership?source=post_page-----4bcfd7e440bc--------------------------------)

æ¬¢è¿é€šè¿‡ [Twitter](https://twitter.com/zoumana_keita_) å’Œ [YouTube](https://www.youtube.com/channel/UC9xKdy8cz6ZuJU5FTNtM_pQ) å…³æ³¨æˆ‘ï¼Œæˆ–è€…åœ¨ [LinkedIn](https://www.linkedin.com/in/zoumana-keita/) ä¸Šæ‰“ä¸ªæ‹›å‘¼ã€‚

[åœ¨è¿™é‡Œä¸æˆ‘è”ç³»è¿›è¡Œä¸€å¯¹ä¸€è®¨è®º](https://topmate.io/zoumanakeita)

ç¦»å¼€ä¹‹å‰ï¼Œä¸‹é¢è¿˜æœ‰æ›´å¤šä½ å¯èƒ½æ„Ÿå…´è¶£çš„ä¼˜è´¨èµ„æºï¼

[ä½¿ç”¨ OpenAI API è¿›è¡Œæ–‡æœ¬åµŒå…¥ä»‹ç»](https://medium.com/geekculture/introduction-to-text-embeddings-with-the-openai-api-1f83d2a15fda)

[å¦‚ä½•ä»ä»»ä½• PDF å’Œå›¾åƒä¸­æå–æ–‡æœ¬ä»¥ä¾›å¤§å‹è¯­è¨€æ¨¡å‹ä½¿ç”¨](https://medium.com/towards-data-science/how-to-extract-text-from-any-pdf-and-image-for-large-language-model-2d17f02875e6)
