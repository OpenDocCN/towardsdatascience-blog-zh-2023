# 掌握语言模型

> 原文：[https://towardsdatascience.com/mastering-language-models-32e1d891511a?source=collection_archive---------5-----------------------#2023-10-03](https://towardsdatascience.com/mastering-language-models-32e1d891511a?source=collection_archive---------5-----------------------#2023-10-03)

## 通过温度、top-p、top-k等来平衡质量与多样性

[](https://medium.com/@samuel.montgomery59?source=post_page-----32e1d891511a--------------------------------)[![Samuel Montgomery](../Images/52f12c797b53706ad1039459238ece44.png)](https://medium.com/@samuel.montgomery59?source=post_page-----32e1d891511a--------------------------------)[](https://towardsdatascience.com/?source=post_page-----32e1d891511a--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----32e1d891511a--------------------------------) [Samuel Montgomery](https://medium.com/@samuel.montgomery59?source=post_page-----32e1d891511a--------------------------------)

·

[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbf5cf7332a65&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-language-models-32e1d891511a&user=Samuel+Montgomery&userId=bf5cf7332a65&source=post_page-bf5cf7332a65----32e1d891511a---------------------post_header-----------) 发表于 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----32e1d891511a--------------------------------) · 12 min read · 2023年10月3日 [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F32e1d891511a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-language-models-32e1d891511a&user=Samuel+Montgomery&userId=bf5cf7332a65&source=-----32e1d891511a---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F32e1d891511a&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmastering-language-models-32e1d891511a&source=-----32e1d891511a---------------------bookmark_footer-----------)

如果你曾经通过操控台或API使用过语言模型，你可能被要求选择一些输入参数。对于我们许多人来说，这些参数的意义（以及正确的使用方法）可能并不十分清楚。

![](../Images/b9bdc5e91439bacb53807788c292484d.png)

一张显示 SillyTavern 界面中参数选择的截图。图片由作者提供。

这篇文章将教你如何使用这些参数来控制幻觉，注入创造力到模型输出中，并进行其他细微的调整以优化行为。就像提示工程一样，输入参数调整可以让你的模型达到110%的性能。

在本文结束时，你将成为五个重要输入参数的专家——温度、top-p、top-k、频率惩罚和存在惩罚。你还将了解这些参数如何帮助我们在质量和多样性之间进行权衡。

所以，拿一杯咖啡，我们开始吧！

## 目录

· [背景](#5876)

· [质量、多样性与温度](#1164)

· [Top-k 和 Top-p](#a476)

· [频率和存在惩罚](#e517)

· [参数调整备忘单](#c9f4)

· [总结](#7610)

# 背景

在我们开始选择输入参数之前，我们需要了解一些背景信息。让我们来谈谈这些模型是如何选择生成的单词的。

要读取文档，语言模型将其分解为一系列标记。标记只是模型可以轻松理解的小块文本：它可以是一个词、一个音节或一个字符。例如，“Megaputer Intelligence Inc.”可能会被分解为五个标记：[“Mega”，“puter”，“Intelligence”，“Inc”，“.”]。

我们熟悉的大多数语言模型通过反复生成序列中的下一个标记来操作。每当模型想要生成另一个标记时，它会重新读取整个序列，并预测下一个应该出现的标记。这种策略被称为*自回归*生成。

![](../Images/ff9f86565a19ba6f422e13157cd7b039.png)

语言模型的自回归标记生成。GIF由[Echo Lu](https://www.linkedin.com/in/echoxlu/)提供，包含由[Annie Surla](https://developer.nvidia.com/blog/author/anniesurla/)修改的[NVIDIA](https://developer.nvidia.com/blog/how-to-get-better-outputs-from-your-large-language-model/)的图像。经版权所有者许可修改。

这解释了为什么ChatGPT一次输出一个单词：它在写字的时候把单词流式传输给你。

要选择序列中的下一个标记，语言模型首先为其词汇表中的每个标记分配一个可能性分数。如果标记是文本的良好延续，它会获得一个高可能性分数；如果标记是文本的较差延续，它会获得一个低可能性分数，模型会进行评估。

![](../Images/40490cd101aa2e34bdc072b88614741d.png)

语言模型分配可能性分数以预测序列中的下一个标记。原始图像由[Annie Surla](https://developer.nvidia.com/blog/author/anniesurla/)提供，来自[NVIDIA](https://developer.nvidia.com/blog/how-to-get-better-outputs-from-your-large-language-model/)，经[Echo Lu](https://www.linkedin.com/in/echoxlu/)修改，经过版权所有者许可。

在分配了可能性分数之后，通过考虑可能性分数的标记采样方案来选择标记。标记采样方案可能会包含一些随机性，以便语言模型不会每次以相同的方式回答相同的问题。这种随机性在聊天机器人或其他应用中可能是一个很好的特性。

*TLDR: 语言模型将文本拆分为标记，预测序列中的下一个标记，并混入一些随机性。根据需要重复以生成语言。*

# 质量、多样性和温度

那么，为什么我们要选择第二好的标记、第三好的标记，或除了最佳标记之外的其他任何标记呢？难道我们不应该每次都选择最佳标记（即具有最高可能性得分的标记）吗？通常，我们确实如此。但是，如果我们每次都选择最佳答案，我们会每次得到相同的答案。如果我们想要多样化的答案，我们可能需要牺牲一些质量以获得它。这种为多样性而牺牲质量的权衡被称为质量-多样性权衡。

鉴于此，*temperature* 告诉机器如何在质量-多样性权衡中导航。低温意味着更高的质量，而高温则意味着更多的多样性。当温度设置为零时，模型总是采样具有最高可能性得分的标记，这导致查询之间的多样性为零，但确保我们总是选择模型评估的最高质量的续集。

很多时候，我们会想要将温度设置为零。作为一项规则，对于你只会传递给模型一次的任何提示，你应该始终选择温度零，因为这最有可能得到一个好的答案。在我的数据分析工作中，我将温度设置为零用于实体提取、事实提取、情感分析以及大多数其他标准任务。

在高温下，我们会看到更多的垃圾和幻觉，连贯性较差，响应质量也较低，但也会有更多的创造力和答案的多样性。我们建议你*仅*在想要对同一个问题得到两个不同答案时使用非零温度。

![](../Images/72a0df19da4637d3f2f8b985de25958c.png)

高温带来了多样性、创造力和多种答案，但也增加了垃圾、无序和幻觉。图片由[Echo Lu](https://www.linkedin.com/in/echoxlu/)提供。

那么，为什么我们要对同一个提示得到两个不同的答案呢？在某些情况下，对一个提示有多个答案可能是有用的。例如，有一种技术是生成多个答案并只保留最佳答案，这通常比温度为零的单次查询产生更好的结果。另一个用例是合成数据生成：我们想要许多多样的合成数据点，而不仅仅是一个非常好的数据点。我们可能会在以后的文章中讨论这些用例（以及其他用例），但更多时候，我们每个提示只想要一个答案。**有疑问时，选择温度零！**

需要注意的是，虽然理论上温度为零应该每次产生相同的答案，但实际情况可能并非如此！这是因为模型运行的 GPU 可能会出现小的计算误差，比如四舍五入错误。这些错误会在计算中引入微小的随机性，即使在温度为零时也是如此。由于在文本中改变一个词可能会显著改变其含义，因此一个错误可能会引起后续文本中不同词汇的连锁反应，从而导致几乎完全不同的输出。但请放心，这通常对质量的影响微乎其微。我们提到这一点是为了让你在温度为零时遇到一些随机性时不会感到惊讶。

除了温度，还有很多其他方法可以在质量和多样性之间取得平衡。在下一节中，我们将讨论一些对温度采样技术的修改。但如果你对使用温度为零感到满意，可以暂时跳过这部分。你可以放心，你选择的这些参数在温度为零时不会影响你的答案。

*总结：温度增加了多样性，但通过将随机性添加到模型输出中而降低了质量。*

# Top-k 和 Top-p

调整我们的词汇采样公式的一种常见方法叫做 top-k 采样。Top-k 采样与普通的温度采样类似，只是排除了最低概率的词汇：只有“前 k”个最佳选择会被考虑，这也是名字的由来。这个方法的优势在于它防止我们选择真正糟糕的词汇。

比如说，我们试图为“太阳在……升起”生成一个续写。如果不使用 top-k 采样，模型会考虑词汇表中的每一个词作为序列的可能延续。这样可能会有非零的几率生成诸如“太阳在冰箱里升起”这样荒谬的内容。使用 top-k 采样，模型会过滤掉这些真正糟糕的选择，只考虑前 k 个最佳选项。通过剪掉长尾，我们会失去一点多样性，但质量会大幅提升。

![](../Images/9d2e8cbeca38c147e31be7b9657736f9.png)

Top-k 采样通过仅保留 k 个最佳候选词并丢弃其余词来提高质量。图片来源于[Echo Lu](https://www.linkedin.com/in/echoxlu/)。

Top-k 采样是一种“既要蛋糕又要吃蛋糕”的方法：它以比单独使用温度更小的成本获得所需的多样性。由于这一技术效果显著，它激发了许多变体。

Top-k 采样的一种常见变体叫做 top-p 采样，也称为核采样。Top-p 采样与 top-k 非常相似，只是它使用概率得分而不是词汇排名来确定剪切尾部的标准。更具体地说，它只考虑那些排名前列的、其组合概率超过阈值 p 的词汇，丢弃其余词汇。

当存在许多质量低劣或平庸的延续时，与top-k抽样相比，top-p抽样的优势变得明显。例如，假设下一个标记只有几个好的选择，而有数十个模糊合理的选择。如果我们使用k=25的top-k抽样，我们将考虑许多质量低劣的延续。相反，如果我们使用top-p抽样来过滤掉概率分布的底部10%，我们可能只会考虑那些好的标记，同时过滤掉其余的标记。

在实践中，与top-k抽样相比，top-p抽样通常能够产生更好的结果。通过关注累积概率，它能够适应输入的上下文并提供更灵活的截断。因此，总之，top-p和top-k抽样都可以在非零温度下使用，以在较低的质量成本下捕捉多样性，但通常top-p抽样做得更好。

提示：对于这两个设置，较低的值=更多过滤。当值为零时，它们将过滤掉除排名第一的标记以外的所有标记，这与将温度设置为零具有相同效果。因此，请使用这些参数时，请注意不要将它们设置得太低，否则会损失所有的多样性。

*TLDR：Top-k和top-p在只付出较小代价以增加质量的情况下提高质量。它们通过在随机抽样之前移除最差的标记选择来实现这一点。*

# 频率和存在惩罚

在我们开始总结之前，我们只需讨论另外两个参数：频率和存在惩罚。这些参数——大惊小怪——是导航质量多样性权衡的又一种方式。虽然温度参数通过在标记抽样过程中添加随机性来实现多样性，频率和存在惩罚则通过对已经在文本中出现过的标记施加惩罚来增加多样性。这使得旧的和过度使用的标记的抽样变得不太可能，影响模型进行更新颖的标记选择。

频率惩罚为每次标记在文本中出现都添加一定的惩罚。这样做可以减少重复使用相同的标记/词语/短语，同时也会导致模型讨论更多样化的主题并更频繁地更换话题。另一方面，存在惩罚是一种固定的惩罚，如果一个标记已经在文本中出现过，则会应用该惩罚。这使得模型引入更多新的标记/词语/短语，导致它讨论更多样化的主题并更频繁地更换话题，而且不会显著地抑制经常使用的词语的重复出现。

类似于温度，频率和存在惩罚使我们远离“最佳”答案，趋向于更具创意的答案。但不同的是，它们不是通过随机性实现的，而是通过精心计算的有针对性的惩罚来注入多样性。在一些少见的需要非零温度的任务中（当你需要对同一提示获得多个答案时），你也可以考虑加入小幅的频率或存在惩罚，以提升创意。但对于那些只希望找到唯一正确答案的提示，在一次尝试中设置所有这些参数为零时，你成功的机会最高。

通常，当只有一个正确答案，并且你只问一次时，应该将频率和存在惩罚设置为零。但如果有多个正确答案，比如在文本摘要中呢？在这种情况下，你有一点自由裁量权。如果你发现模型的输出无聊、缺乏创意、重复或范围有限，合理应用频率或存在惩罚可能是个不错的方法来增加趣味。但对于这些参数，我们的最终建议和温度参数一样：**当有疑问时，选择零！**

我们应该注意，虽然温度和频率/存在惩罚都能增加模型响应的多样性，但它们增加的多样性种类并不相同。频率/存在惩罚增加了*单次响应内的多样性*。这意味着，一个响应将具有比没有这些惩罚时更多的不同词汇、短语、主题和学科。但当你两次输入相同的提示时，不会更容易得到两个不同的答案。这与温度形成对比，温度增加了*响应之间的多样性*：在较高的温度下，当多次将相同提示输入模型时，你会得到更为多样化的回答。

我喜欢将这种区分称为响应内多样性与响应间多样性。温度参数增加了响应内和响应间的多样性，而频率/存在惩罚仅增加响应内的多样性。因此，当我们需要多样性时，我们对参数的选择应取决于我们需要的多样性种类。

*总结：频率和存在惩罚增加了模型讨论的主题多样性，并使其更频繁地更换话题。频率惩罚还通过减少词汇和短语的重复来增加词汇选择的多样性。*

# 参数调整备忘单

本节旨在作为选择模型输入参数的实用指南。我们首先提供一些明确的规则来决定哪些值应设置为零。然后，我们给出一些建议，帮助你找到适合非零参数的正确值。

我强烈建议你在选择输入参数时使用这份备忘单。现在就去收藏此页面，以免丢失！

## 将参数设置为零的规则：

温度：

+   每个提示**一个答案**：零。

+   每个提示**多个答案**：非零。

频率和存在惩罚：

+   当有**一个正确答案**时：零。

+   当有**多个正确答案**时：可选。

Top-p/Top-k：

+   在**零温度**下：输出不受影响。

+   在**非零温度**下：非零。

如果你的语言模型有其他未列出的参数，保持其默认值也是可以的。

## 调整非零参数的提示：

列出应该具有非零值的那些参数，然后去试验场中尝试一些测试提示以查看效果。***但如果上述规则要求将参数保持在零，则保持在零！***

调整温度/top-p/top-k：

1.  为了更多的多样性/随机性，增加温度。

1.  在非零温度下，从 top-p 约 0.95（或 top-k 约 250）开始，根据需要逐渐降低。

故障排除：

1.  如果出现过多的废话、垃圾或幻觉，降低温度和/或减少 top-p/top-k。

1.  如果温度高而多样性低，增加 top-p/top-k。

提示：虽然一些界面允许你同时使用 top-p 和 top-k，但我们倾向于选择其中之一以保持简单。Top-k 更易于使用和理解，但 top-p 通常更有效。

调整频率惩罚和存在惩罚：

1.  为了更多的多样化主题和内容，增加存在惩罚。

1.  为了更丰富且不重复的语言，增加频率惩罚。

故障排除：

1.  如果输出显得零散且主题变化过快，减少存在惩罚。

1.  如果有太多新词和不寻常的词，或者存在惩罚设置为零但仍然有太多主题变化，减少频率惩罚。

*TLDR：你可以将此部分作为调整语言模型的备忘单。你* ***肯定*** *会**忘记这些规则，因此请收藏此页面，并在以后作为参考使用。*

# 总结

虽然定义令牌采样策略的方法无穷无尽，但我们讨论过的参数——温度、top-k、top-p、频率惩罚和存在惩罚——是最常用的参数。这些参数是你可以在 Claude、Llama 和 GPT 系列等模型中找到的。本文展示了所有这些参数实际上只是帮助我们导航质量与多样性权衡的工具。

在我们结束之前，还有一个最后的输入参数需要提及：最大令牌长度。最大令牌长度就是模型停止打印答案的截止点，即使答案未完成。在复杂的讨论之后，我们希望这个参数是不言自明的。🙂

随着我们在这一系列中的深入，我们将更深入地探讨诸如提示工程、为你的使用案例选择合适的语言模型等主题！我还会展示一些来自我在Megaputer Intelligence担任数据分析顾问时的实际应用案例。敬请期待更多见解，祝建模愉快！

*TLDR: 如果有疑问，将温度、频率惩罚和存在惩罚设置为零。如果这样做对你不起作用，请参考上面的备忘单。*
