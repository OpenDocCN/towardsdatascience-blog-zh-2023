- en: What GPT-4 Brings to the AI Table
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-4带来的AI新视角
- en: 原文：[https://towardsdatascience.com/what-gpt-4-brings-to-the-ai-table-74e392a32ac3?source=collection_archive---------9-----------------------#2023-04-14](https://towardsdatascience.com/what-gpt-4-brings-to-the-ai-table-74e392a32ac3?source=collection_archive---------9-----------------------#2023-04-14)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/what-gpt-4-brings-to-the-ai-table-74e392a32ac3?source=collection_archive---------9-----------------------#2023-04-14](https://towardsdatascience.com/what-gpt-4-brings-to-the-ai-table-74e392a32ac3?source=collection_archive---------9-----------------------#2023-04-14)
- en: Natural Language Processing
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: A language model and more
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种语言模型及更多内容
- en: '[](https://medium.com/@doziesixtus?source=post_page-----74e392a32ac3--------------------------------)[![Dozie](../Images/50d7c589ebe462b8658109e4b2498b57.png)](https://medium.com/@doziesixtus?source=post_page-----74e392a32ac3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----74e392a32ac3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----74e392a32ac3--------------------------------)
    [Dozie](https://medium.com/@doziesixtus?source=post_page-----74e392a32ac3--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@doziesixtus?source=post_page-----74e392a32ac3--------------------------------)[![Dozie](../Images/50d7c589ebe462b8658109e4b2498b57.png)](https://medium.com/@doziesixtus?source=post_page-----74e392a32ac3--------------------------------)[](https://towardsdatascience.com/?source=post_page-----74e392a32ac3--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----74e392a32ac3--------------------------------)
    [Dozie](https://medium.com/@doziesixtus?source=post_page-----74e392a32ac3--------------------------------)'
- en: ·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcbd576093dd8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-gpt-4-brings-to-the-ai-table-74e392a32ac3&user=Dozie&userId=cbd576093dd8&source=post_page-cbd576093dd8----74e392a32ac3---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----74e392a32ac3--------------------------------)
    ·7 min read·Apr 14, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74e392a32ac3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-gpt-4-brings-to-the-ai-table-74e392a32ac3&user=Dozie&userId=cbd576093dd8&source=-----74e392a32ac3---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fcbd576093dd8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-gpt-4-brings-to-the-ai-table-74e392a32ac3&user=Dozie&userId=cbd576093dd8&source=post_page-cbd576093dd8----74e392a32ac3---------------------post_header-----------)
    发表在[Towards Data Science](https://towardsdatascience.com/?source=post_page-----74e392a32ac3--------------------------------)
    ·7分钟阅读·2023年4月14日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F74e392a32ac3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-gpt-4-brings-to-the-ai-table-74e392a32ac3&user=Dozie&userId=cbd576093dd8&source=-----74e392a32ac3---------------------clap_footer-----------)'
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74e392a32ac3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-gpt-4-brings-to-the-ai-table-74e392a32ac3&source=-----74e392a32ac3---------------------bookmark_footer-----------)![](../Images/0e0c0b42cb53b2761b7503bab87e66ba.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F74e392a32ac3&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fwhat-gpt-4-brings-to-the-ai-table-74e392a32ac3&source=-----74e392a32ac3---------------------bookmark_footer-----------)![](../Images/0e0c0b42cb53b2761b7503bab87e66ba.png)'
- en: Image from [Unsplash](https://unsplash.com/photos/Snqm29dhfOk)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来自[Unsplash](https://unsplash.com/photos/Snqm29dhfOk)
- en: 'The long-awaited release of the latest Generative Pre-trained Transformers
    (GPT) model has finally come. The fourth release of OpenAI’s GPT model has seen
    some improvements from its previous versions, in addition to some extended features.
    GPT-4, like its predecessors, was trained and fine-tuned on a corpus of text using
    **semi-supervised training**. The semi-supervised training used in GPT models
    is done in a two-step process: an unsupervised generative pre-training and a supervised
    discriminative fine-tuning. These training steps helped to circumvent the language
    understanding barriers that other language models faced due to poorly annotated
    data.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 期待已久的最新生成预训练变换器（GPT）模型终于发布了。OpenAI的GPT模型第四版在前几版的基础上有了一些改进，并且新增了一些扩展功能。像前几代模型一样，GPT-4使用**半监督训练**进行训练和微调。GPT模型中使用的半监督训练是通过两个步骤完成的：无监督生成预训练和有监督的判别微调。这些训练步骤帮助绕过了其他语言模型因标注数据不良而面临的语言理解障碍。
- en: How GPT-4 got this far
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4如何走到今天
- en: OpenAI released GPT-4 on 14th March, 2023, nearly five years after the initial
    lunch of GPT-1\. There have been some improvements in the speed, understanding
    and reasoning of these models with each new release. Much of the improvements
    on these models could be attributed to the amount of data used in the training
    process, the robustness of the model and the new advances in computing devices.
    GPT-1 had access to barely 4.5GB of text from BookCorpus during training. GPT-1
    model had a parameter size of 117 million — which was by far massive compared
    to other language models existing at the time of its release. GPT-1 outperformed
    other language models in the different tasks it was fine-tuned on. These tasks
    were on natural language inference, question answering, semantic similarity and
    classification tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 于 2023 年 3 月 14 日发布了 GPT-4，距初次推出 GPT-1 已近五年。每次新版本发布时，这些模型的速度、理解能力和推理能力都有所提高。这些改进在很大程度上归因于训练过程中使用的数据量、模型的稳健性以及计算设备的新进展。GPT-1
    在训练期间只能访问 4.5GB 的 BookCorpus 文本。GPT-1 模型的参数大小为 1.17 亿——相较于发布时存在的其他语言模型，这已经非常庞大。GPT-1
    在它经过微调的不同任务中表现优异。这些任务包括自然语言推断、问答、语义相似性和分类任务。
- en: Those who were still uncertain about the possibility of a model surpassing GPT-1
    were blown away by the numbers GPT-2 had on its release. The parameter size and
    the text size used in training were roughly ten times the size seen on GPT-1\.
    The size of GPT-2 wasn’t the only new addition. In contrast to GPT-1, OpenAI removed
    the need for an additional fine-tuning step for specific tasks. Few shots learning
    was used to ensure that GPT-2 was able to attribute meaning and context to words
    without needing to encounter the words multiple times.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些仍对模型是否会超越 GPT-1 感到不确定的人来说，GPT-2 发布时的数字让他们大吃一惊。GPT-2 的参数大小和用于训练的文本大小大约是 GPT-1
    的十倍。GPT-2 的尺寸并不是唯一的新增加内容。与 GPT-1 相比，OpenAI 去除了对特定任务进行额外微调步骤的需求。使用了少量样本学习，以确保 GPT-2
    能够为单词赋予意义和上下文，而无需多次遇到这些单词。
- en: Just like GPT-2, GPT-3 and other subsequent language models do not require additional
    fine-tuning on specific tasks. The 175 billion parameter model of GPT-3 was trained
    on 570GB of text from Common Crawl, Web Text, English Wikipedia and some books
    corporal. The language understanding and reasoning of GPT-3 were profound, and
    further improvements led to the development of ChatGPT, an interactive dialogue
    API. OpenAI developed ChatGPT to enable a web-based dialogue environment for users
    to have a first-hand experience of the capabilities of the extended GPT-3 by making
    the language model converse and respond to users based on inputs from the user.
    A user can ask a question or request detailed information about just any topic
    within the training scope of the model. OpenAI furthermore regulated the extent
    of information their models could provide. There was a bit of extra care in answers
    relating to prompts involving crime, weapons, adult content, etc.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 就像 GPT-2 一样，GPT-3 和其他后续语言模型不需要针对特定任务进行额外的微调。GPT-3 的 1750 亿参数模型是在 570GB 的文本上进行训练的，这些文本来源于
    Common Crawl、Web Text、英文维基百科以及一些书籍。GPT-3 的语言理解和推理能力非常深刻，进一步的改进导致了 ChatGPT 的开发，这是一个互动对话
    API。OpenAI 开发了 ChatGPT，以便为用户提供一个基于网页的对话环境，使用户可以亲身体验扩展版 GPT-3 的能力，通过让语言模型根据用户的输入进行对话和响应。用户可以提出问题或请求有关模型训练范围内任何主题的详细信息。OpenAI
    进一步规定了其模型能够提供的信息的范围。在涉及犯罪、武器、成人内容等的提示中，答案会特别小心。
- en: Exciting features of GPT-4
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4 的令人兴奋的特性
- en: Each new release of GPT comes with a set of features that would have seemed
    impossible in the past. ChatGPT impressed users with its level of reasoning and
    comprehension. Users were able to get accurate responses to their queries on any
    topic, as long as the subject matter was part of the text ChatGPT was trained
    on. There have been cases where ChatGPT struggled to respond to queries on the
    events that occurred after when the model was trained. The difficulty in understanding
    novel topics should be expected since NLP models regurgitate texts and try to
    map entities within time and space of appearance to suit the desired context.
    Therefore, only topics existing in the dataset it was trained on can be recalled,
    and it would be quite ambitious to generalize on new topics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 每一次GPT的新版本发布都带来了一系列在过去看似不可能的功能。ChatGPT以其推理和理解能力给用户留下了深刻印象。用户能够获得关于任何主题的准确回应，只要这些主题是ChatGPT训练文本的一部分。但也有案例显示，ChatGPT在回应发生在模型训练后事件的查询时遇到了困难。理解新主题的难度应是预期中的，因为NLP模型是对文本的再现，并尝试将时间和空间中的实体映射到期望的上下文中。因此，只有在其训练数据集中存在的主题才能被回忆起，对新主题进行概括将是相当雄心勃勃的。
- en: Not only was the reasoning of the GPT-3 model relatively limited, but the model
    was unimodal. Only sequences of texts can be processed by this model. The latest
    release of GPT comes with improvements on the previous release. Due to its higher
    level of reasoning, GPT-4 models can make better estimates of sentence context
    and make general understanding based on this context. Based on the glimpse of
    the capabilities of this new model, other new features are as follows;
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3模型的推理不仅相对有限，而且是单模态的。该模型只能处理文本序列。最新发布的GPT在前一版本的基础上进行了改进。由于其更高的推理水平，GPT-4模型可以更好地估计句子的上下文，并根据该上下文进行一般理解。根据对新模型能力的初步了解，其他新特性如下：
- en: An increase in its word limit, with a word limit size of 25,000 compared to
    the 3,000-word limit on ChatGPT. GPT-4 has an increased context window, with a
    size of 8,129 and 32,768 tokens compared to 4,096 and 2,049 tokens on GPT-3.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字数限制的增加，限制大小为25,000字，而ChatGPT的限制为3,000字。GPT-4具有更大的上下文窗口，大小为8,129和32,768个标记，而GPT-3为4,096和2,049个标记。
- en: Improvements in reasoning and understanding. Texts are well understood and,
    better reasoning is performed on texts.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理和理解的改进。文本理解得更好，并对文本进行更好的推理。
- en: GPT-4 is multi-modal. It accepts text inputs as well as images. GPT-4 recognizes
    and understands an image’s contents and can make logical deductions from the image
    with human-level accuracy.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-4是多模态的。它接受文本输入以及图像。GPT-4能够识别和理解图像的内容，并以人类水平的准确性从图像中做出逻辑推断。
- en: Texts generated on GPT-4 are more difficult to be flagged as machine-generated
    text. The texts have been more human-generated and make use of sentence features
    like emojis to make texts feel more personal and instill a bit of emotion in the
    text.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由GPT-4生成的文本更难被标记为机器生成文本。这些文本更具人类生成的特点，并利用诸如表情符号等句子特征，使文本感觉更个人化，并注入一些情感。
- en: Lastly, I would like to single out the new dynamic logo that comes with GPT-4\.
    The logo shows how variable this model is and the dynamism in its potential use
    cases. I think the logo has to be one of the best identities given to a model.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我想特别提到GPT-4附带的新动态标志。该标志展示了该模型的多变性以及其潜在应用场景的活力。我认为这个标志可能是赋予模型的最佳身份之一。
- en: Truths and myths
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 真实与虚构
- en: Visual representation of the size of GPT-4
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4的大小可视化表示
- en: At some point during the wait for the release of GPT-4, this picture was in
    circulation on Twitter. The image is a visual representation of the rumoured size
    of GPT-4\. The image shows a considerable increase in the size of the parameters
    of the new model compared to the size of the parameters used in ChatGPT. While
    the representation communicated by this image might sound groundbreaking, it might
    not be entirely true. Even OpenAI’s CEO has debunked the rumours about the size
    of the model. The official documentation of the architecture and the size of the
    model parameters used in training the multi-modal language model has not been
    released. We can’t really tell if the approach used in creating this model was
    by scaling the past models or some new approach. Some AI experts argue that scaling
    wouldn’t provide the much-needed General Intelligence the AI world is striving
    towards.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在等待GPT-4发布期间的某个时间点，这张图片曾在Twitter上流传。这张图片是GPT-4规模的传闻大小的视觉表现。与ChatGPT使用的参数大小相比，这张图片显示了新模型参数的显著增加。虽然这张图片传达的表现可能听起来是突破性的，但这可能并非完全真实。甚至OpenAI的CEO也驳斥了关于模型大小的传闻。关于训练多模式语言模型的架构和模型参数大小的官方文档尚未发布。我们无法确定创建这种模型的方法是通过缩放过去的模型还是一些新方法。一些AI专家认为，缩放不会提供AI世界正在努力实现的急需的通用智能。
- en: OpenAI presented the big strengths of GPT-4 in text generation, but have we
    bothered to ask how good the generated texts are compared to some standard exams?
    GPT-4, while performing quite well in some exams, faltered in exams that required
    higher level of reasoning. The technical report released by Open AI showed that
    GPT-4 was always in the 54th percentile of the Graduate Record Examination (GRE)
    Writing for the two versions of GPT-4 that was released¹. This exam is one of
    many exams that tests the reasoning and writing abilities of a graduate. It can
    be said that the text generation from GPT-4 is barely as good as a university
    graduate, which isn’t bad for a “computer”. We can also say that this language
    model doesn’t like math, or rather, it doesn’t do well in calculus. It performed
    in the 43rd — 59th percentile of the AP Calculus BC exam, which is quite low compared
    to the high percentile scores seen in the Biology, History, English, Chemistry,
    Psychology and Statistics counterparts of the same exam board. The model falters
    with increasing levels of difficulty. Humans are still at the top echelon of thinking
    for the time being.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 在文本生成方面展示了GPT-4的巨大优势，但我们是否曾经想过生成文本与一些标准考试的生成文本相比如何？尽管GPT-4在某些考试中表现相当不错，但在需要更高推理能力的考试中表现不佳。Open
    AI发布的技术报告显示，GPT-4 在两个版本的GRE写作考试中一直处于第54百分位¹。这门考试是许多考试中考验研究生推理和写作能力的考试之一。可以说，GPT-4生成的文本几乎与大学毕业生一样好，这对于一台“计算机”来说并不差。我们还可以说，这种语言模型不喜欢数学，或者更确切地说，在微积分方面表现不佳。它在AP微积分BC考试中的表现处于第43至59百分位，与同一考试委员会的生物学、历史学、英语、化学、心理学和统计学对应学科的高百分位得分相比显得较低。随着难度的增加，该模型表现出了困难。目前人类仍然处于思维的顶端。
- en: Ever cared to wonder how well these language models perform in coding? GPT-4
    coding abilities were checked on some Leetcode tasks. The general performance
    on the easy tasks was quite good, but there’s a constant decline in its performance
    with an increase in difficulty in the tasks. It is also worth noting that the
    overall score of GPT-4 on Leetcode tasks is almost similar to that of GPT-3\.
    OpenAI definitely didn’t do better this time or they were possibly not trying
    to turn GPT models into the next Github Copilot. Imagine a computer performing
    better than an average programmer on interview coding questions. Crazy!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有想过这些语言模型在编码方面的表现如何？GPT-4 在一些Leetcode任务上进行了编码能力检验。它在简单任务上的表现相当不错，但随着任务难度的增加，其表现却在持续下降。值得注意的是，GPT-4
    在Leetcode任务的总体得分几乎与GPT-3相似。OpenAI 这次的表现并不比以前好，或者说他们可能没有试图将GPT模型打造成下一个Github Copilot。想象一台计算机在面试编码问题上表现优于一般程序员，真是太疯狂了！
- en: While some features didn’t see many improvements compared to the predecessor
    model, it’s worth noting how well the model performs on other tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管某些功能与前代模型相比并未见到许多改进，值得注意的是模型在其他任务上的表现如何。
- en: Conclusion
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: This fourth release of GPT has shown that there isn’t any limit on the scope
    of language models since these models are not multi-modal and can accept inputs
    other than texts. This could be seen as a harbinger of more advanced features
    in versions to come. We probably could have a language model performing as well
    or even better than computer vision models in image recognition tasks with the
    capabilities shown by GPT-4 image understanding. We are gradually moving towards
    General Artificial Intelligence. It’s still a long way there, but we clearly have
    a direction and a sense of where we are heading.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: GPT 的第四个版本展示了语言模型的范围没有限制，因为这些模型并不是多模态的，能够接受文本以外的输入。这可以被视为未来版本更高级功能的先兆。我们可能会看到一个语言模型在图像识别任务中表现得和计算机视觉模型一样好，甚至更好，这得益于
    GPT-4 的图像理解能力。我们正逐步朝着通用人工智能迈进。虽然还有很长的路要走，但我们显然有一个方向，并且知道我们要去哪里。
- en: '[1]: OpenAI. (March 16 2023). *GPT-4 Technical Report* [https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]: OpenAI. (2023年3月16日). *GPT-4 技术报告* [https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)'
- en: Thank you!
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谢谢！
- en: '*If you liked my article, please do well to* [*follow me*](https://medium.com/@doziesixtus)
    *so that you would get notifications whenever I publish a story. I would be publishing
    more articles in this space. Wish you the best in your endeavors.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果你喜欢我的文章，请* [*关注我*](https://medium.com/@doziesixtus) *，这样你就会在我发布故事时收到通知。我将在这个领域发布更多文章。祝你一切顺利。*'
