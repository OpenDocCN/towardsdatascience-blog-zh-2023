- en: Achieving Greater Self-Consistency in Large Language Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7?source=collection_archive---------9-----------------------#2023-12-01](https://towardsdatascience.com/achieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7?source=collection_archive---------9-----------------------#2023-12-01)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[![Anthony
    Alcaraz](../Images/6a71a1752677bd07c384246fb0c7f7e8.png)](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    [Anthony Alcaraz](https://medium.com/@alcarazanthony1?source=post_page-----6e6cb5f3c5b7--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F30bc9ffd2f4b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=post_page-30bc9ffd2f4b----6e6cb5f3c5b7---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6e6cb5f3c5b7--------------------------------)
    ·8 min read·Dec 1, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6e6cb5f3c5b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&user=Anthony+Alcaraz&userId=30bc9ffd2f4b&source=-----6e6cb5f3c5b7---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6e6cb5f3c5b7&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fachieving-greater-self-consistency-in-large-language-models-6e6cb5f3c5b7&source=-----6e6cb5f3c5b7---------------------bookmark_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: '*Artificial intelligence software was used to enhance the grammar, flow, and
    readability of this article’s text.*'
  prefs: []
  type: TYPE_NORMAL
- en: When LLMs are used to evaluate qualities like the correctness, accuracy, or
    relevance of a piece of text, consistency is paramount. If an LLM exhibits inconsistent
    judgements, then its evaluations become unreliable and untrustworthy.
  prefs: []
  type: TYPE_NORMAL
- en: If an LLM evaluates the reasoning quality of arguments, but contradicts itself
    by rating an invalid argument as more logically sound than a perfectly valid one,
    then it fails as an arbiter of reason. Its evaluations lose credibility due to
    the model’s own lack of logical consistency.
  prefs: []
  type: TYPE_NORMAL
- en: When such inconsistencies appear, there is no stable basis for comparison between
    the LLM’s assessments of different pieces of text. If the model arbitrarily contradicts
    itself, then sentences cannot be reliably ranked against one another based on
    the model’s inconsistent scorings.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, inconsistency destroys the grounds for comparison that evaluations
    aim to provide in the first place. If an LLM cannot demonstrate consistent application
    of assessment criteria, then using it to evaluate text loses all effectiveness
    and utility.
  prefs: []
  type: TYPE_NORMAL
- en: So, consistency in judgement and evaluation is mandatory for LLMs employed to
    score or judge textual qualities and features. Without a high level of stability
    in its assessments, grounded in a consistent understanding of concepts being evaluated,
    the basis for…
  prefs: []
  type: TYPE_NORMAL
