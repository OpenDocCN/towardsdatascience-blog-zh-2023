- en: Making Music-Tagging AI Explainable through Source Separation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过源分离实现音乐标记AI的可解释性
- en: 原文：[https://towardsdatascience.com/making-music-tagging-ai-explainable-through-source-separation-2d9493547a7e?source=collection_archive---------10-----------------------#2023-04-04](https://towardsdatascience.com/making-music-tagging-ai-explainable-through-source-separation-2d9493547a7e?source=collection_archive---------10-----------------------#2023-04-04)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/making-music-tagging-ai-explainable-through-source-separation-2d9493547a7e?source=collection_archive---------10-----------------------#2023-04-04](https://towardsdatascience.com/making-music-tagging-ai-explainable-through-source-separation-2d9493547a7e?source=collection_archive---------10-----------------------#2023-04-04)
- en: Let’s open the black box
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们打开黑匣子
- en: '[](https://medium.com/@maxhilsdorf?source=post_page-----2d9493547a7e--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----2d9493547a7e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2d9493547a7e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2d9493547a7e--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----2d9493547a7e--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/@maxhilsdorf?source=post_page-----2d9493547a7e--------------------------------)[![Max
    Hilsdorf](../Images/01da76c553e43d5ed6b6849bdbfd00da.png)](https://medium.com/@maxhilsdorf?source=post_page-----2d9493547a7e--------------------------------)[](https://towardsdatascience.com/?source=post_page-----2d9493547a7e--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----2d9493547a7e--------------------------------)
    [Max Hilsdorf](https://medium.com/@maxhilsdorf?source=post_page-----2d9493547a7e--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd0c085a74ae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-music-tagging-ai-explainable-through-source-separation-2d9493547a7e&user=Max+Hilsdorf&userId=d0c085a74ae8&source=post_page-d0c085a74ae8----2d9493547a7e---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----2d9493547a7e--------------------------------)
    ·10 min read·Apr 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d9493547a7e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-music-tagging-ai-explainable-through-source-separation-2d9493547a7e&user=Max+Hilsdorf&userId=d0c085a74ae8&source=-----2d9493547a7e---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fd0c085a74ae8&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-music-tagging-ai-explainable-through-source-separation-2d9493547a7e&user=Max+Hilsdorf&userId=d0c085a74ae8&source=post_page-d0c085a74ae8----2d9493547a7e---------------------post_header-----------)
    发表于[Towards Data Science](https://towardsdatascience.com/?source=post_page-----2d9493547a7e--------------------------------)
    ·10 min read·Apr 4, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F2d9493547a7e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-music-tagging-ai-explainable-through-source-separation-2d9493547a7e&user=Max+Hilsdorf&userId=d0c085a74ae8&source=-----2d9493547a7e---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d9493547a7e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-music-tagging-ai-explainable-through-source-separation-2d9493547a7e&source=-----2d9493547a7e---------------------bookmark_footer-----------)![](../Images/7b1d37ae9034fdd2de1ac91d8ea421c3.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2d9493547a7e&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmaking-music-tagging-ai-explainable-through-source-separation-2d9493547a7e&source=-----2d9493547a7e---------------------bookmark_footer-----------)![](../Images/7b1d37ae9034fdd2de1ac91d8ea421c3.png)'
- en: Images by [Jadson Thomas](https://www.pexels.com/de-de/foto/mann-der-trommel-spielt-542553/),
    [Clem Onojeghuo](https://www.pexels.com/de-de/foto/mann-sitzt-auf-gitarrenverstarker-und-spielt-e-gitarre-375893/),
    and [Dmitry Demidov](https://www.pexels.com/de-de/foto/mann-im-weissen-t-shirt-das-braune-e-gitarre-spielt-3807838/).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Jadson Thomas](https://www.pexels.com/de-de/foto/mann-der-trommel-spielt-542553/)，[Clem
    Onojeghuo](https://www.pexels.com/de-de/foto/mann-sitzt-auf-gitarrenverstarker-und-spielt-e-gitarre-375893/)和[Dmitry
    Demidov](https://www.pexels.com/de-de/foto/mann-im-weissen-t-shirt-das-braune-e-gitarre-spielt-3807838/)提供。
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Why do We Need This?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么我们需要这个？
- en: AI systems for music tagging have been around for quite a while. Ever since
    the mid-2010s, music streaming services have been competing for the most innovative
    music recommendation system using sophisticated tagging AI in the background.
    Slowly, production music libraries and music labels have caught on to tagging
    AIs, using it to categorize, filter, and query their huge music databases. Today,
    even artists are using auto-tagging systems to gain objective insights into their
    music to find the right audience for it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐标记的AI系统已经存在了一段时间。自2010年代中期以来，音乐流媒体服务一直在竞争最具创新性的音乐推荐系统，后台使用复杂的标记AI。逐渐地，制作音乐库和音乐标签公司开始关注标记AI，用于对其庞大的音乐数据库进行分类、过滤和查询。今天，甚至艺术家们也在使用自动标记系统，以获得对自己音乐的客观见解，找到合适的受众。
- en: 'Although widespread, little is known about the inner workings of auto-tagging
    systems. Because audio data is complex and high-dimensional, deep learning models
    consistently outperform traditional machine learning approaches on music tagging
    tasks. The problem with deep learning is well-known: by building more and more
    complex and capable models, we sacrifice interpretability. Deep learning models
    are effectively black boxes where we have no idea what is really going on inside.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管自动标签系统广泛存在，但其内部工作原理鲜为人知。由于音频数据复杂且高维，深度学习模型在音乐标记任务中始终优于传统的机器学习方法。深度学习的问题是显而易见的：通过构建越来越复杂和高效的模型，我们牺牲了可解释性。深度学习模型实际上是黑箱，我们无法确切了解内部发生了什么。
- en: The Goal of this Project
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本项目的目标
- en: This project aims to lay out a method to explain the behavior of music-tagging
    AI systems by breaking down tracks into their instrumental sources (stems) and
    seeing how the classification changes. This method was inspired by a well-known
    Explainable AI (XAI) concept called **Shapley Values**.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目旨在通过将音轨拆分成其乐器来源（stem）并观察分类如何变化，来阐释音乐标记AI系统的行为。这种方法受到了一个著名的可解释AI（XAI）概念的启发，称为**Shapley值**。
- en: Shapley Values are derived from cooperative game theory. Suppose we have different
    players who can form “coalitions” to achieve a common goal. The goal, then, is
    to assign each player a value that states how adding them to a coalition tends
    to improve the outcome, on average — to determine their fair share, in some sense.
    Now, what does this concept have to do with music tagging and instrument source
    separation?
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley值来源于合作博弈论。假设我们有不同的玩家，他们可以组成“联盟”来实现共同目标。目标是为每个玩家分配一个值，表示将他们加入联盟通常如何改善结果，即确定他们的公平份额。那么，这个概念与音乐标记和乐器源分离有什么关系呢？
- en: '*Figure 1* helps you to understand the analogy between game theory and a music
    classifier. If a track is assigned the genre “jazz” by an AI tagging system, we
    might wonder how much each instrument in the band (drums, guitar, vocals) contributed
    to this classification. In other words: We want to find out how important each
    instrument is for the track to sound like “jazz” music.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1* 帮助你理解博弈论与音乐分类器之间的类比。如果一首曲目被AI标记系统指定为“爵士”风格，我们可能会想知道乐队中的每种乐器（鼓、吉他、声乐）对这一分类的贡献有多大。换句话说：我们想找出每种乐器对使曲目听起来像“爵士”音乐有多重要。'
- en: '![](../Images/59ad3faef8e94daa71fbb48743ddb889.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/59ad3faef8e94daa71fbb48743ddb889.png)'
- en: '**Figure 1**: Illustration of the goal of this project. Image by author.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**图1**：本项目目标的插图。图像由作者提供。'
- en: Method
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 方法
- en: Example Tracks
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例音乐
- en: All example tracks used for this analysis are taken from the [Free Music Archive
    (FMA)](https://github.com/mdeff/fma), a dataset with thousands of copyright-free
    music snippets. The first example is a track with multiple distorted guitars,
    heavy drums, and rather soft male vocals in the beginning. This track will serve
    as our **“rock” example**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所有用于此分析的示例曲目均取自[Free Music Archive (FMA)](https://github.com/mdeff/fma)，这是一个包含成千上万的免版权音乐片段的数据集。第一个示例是一首包含多个失真的吉他、重鼓和开头较柔和男声的曲目。这首曲目将作为我们的**“摇滚”示例**。
- en: Excerpt from “Look of Wonder” by Aviv Mark (CC BY-NC-ND 3.0 license).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 摘自Aviv Mark的《Wonder的面貌》（CC BY-NC-ND 3.0许可证）。
- en: The next piece has a walking bass, broomstick drums, laid-back guitar chords,
    and a dominant piano improvising a solo. This one will serve as our **“jazz” example**.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 下一段音乐包含步伐感强的贝斯、扫帚鼓、轻松的吉他和一个主导的即兴钢琴。这将作为我们的**“爵士”示例**。
- en: Excerpt from “Jingle Jazz” by Quantum Jazz (CC BY-SA 3.0 license).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 摘自Quantum Jazz的《Jingle Jazz》（CC BY-SA 3.0许可证）。
- en: The third and last track is a mixture of the “jazz” and “rock” genres, combining
    a bluesy piano, drums with a slight swing, distorted electric guitars, and more
    rock-like vocals. This piece will serve as our **“mixed genre” example**.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 第三条也是最后一条轨道是“爵士”和“摇滚”流派的混合，结合了布鲁斯风格的钢琴、带有轻微摆动的鼓、失真的电吉他和更像摇滚的声音。这一片段将作为我们的**“混合流派”示例**。
- en: Excerpt from “Vermouth and Baby” by Sakee Sed (CC BY-NC-ND 3.0 license).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 摘自Sakee Sed的《Vermouth和Baby》（CC BY-NC-ND 3.0许可证）。
- en: Source Separation & Recombination
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 源分离与重组
- en: For this project, I used the [source separation tool by LALAL.AI](https://www.lalal.ai/),
    a startup company focusing specifically on this technology. While there are many
    other competing solutions like Spleeter or Vocalremover.org, I decided on LALAL.AI
    after I was quite impressed by their online demos. Furthermore, they were so kind
    as to provide me with the resources to perform the source separation jobs required
    for this article.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，我使用了[LALAL.AI的源分离工具](https://www.lalal.ai/)，这是一家专门从事此技术的初创公司。虽然还有许多其他竞争解决方案，如Spleeter或Vocalremover.org，但在我对他们的在线演示印象深刻之后，我选择了LALAL.AI。此外，他们还非常友好地提供了进行本文所需源分离工作的资源。
- en: After I had split the three tracks into their instrumental sources, I combined
    the isolated sources to form all possible source combinations for each track.
    For the tracks with 4 sources (“rock” and “jazz”), this resulted in 15 new audio
    files, ranging from solo drum tracks to the full band setup. For the “mixed genre”
    track, which has 5 instruments, a total of 31 combinations were possible. Each
    of these combinations is analogous to the “coalition” concept from the Shapley
    Value game theory.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在将三条轨道拆分成其乐器源后，我将这些孤立的源组合起来，形成每条轨道的所有可能源组合。对于具有4个源（“摇滚”和“爵士”）的轨道，这导致了15个新的音频文件，从单一的鼓轨道到完整的乐队设置。而对于有5种乐器的“混合流派”轨道，总共有31种组合可能。每种组合都类似于Shapley值博弈理论中的“联盟”概念。
- en: Genre & Mood Tagging
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 流派与心情标记
- en: As for the auto-tagging AI, I made use of another service called [“Cyanite AI”](https://cyanite.ai/).
    Cyanite is an auto-tagging tool offering tags from different categories like genre,
    mood, or instruments. Again, while there are other auto-tagging providers like
    AudioRanger and Songtradr’s musicube, I am familiar with Cyanite’s product, having
    contributed to it myself as a working student. Cyanite also kindly provided me
    with the resources to analyze the example tracks for this project.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 至于自动标记AI，我使用了另一个名为[“Cyanite AI”](https://cyanite.ai/)的服务。Cyanite是一个自动标记工具，提供来自不同类别的标签，如流派、心情或乐器。虽然还有其他自动标记提供商，如AudioRanger和Songtradr的musicube，但我对Cyanite的产品非常熟悉，因为我曾作为工作学生为其做过贡献。Cyanite还慷慨地为我提供了分析本项目示例轨道的资源。
- en: The auto tagger outputs a score between 0 and 1 for each tag, indicating how
    well (1) or badly (0) the tag fits the track. This output value can be interpreted
    as the degree to which a track is “rock”, “metal”, or even “sad”, or “angry”.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 自动标记器为每个标签输出0到1之间的分数，表示标签与轨道的匹配程度（1表示非常匹配，0表示不匹配）。这个输出值可以解释为轨道是“摇滚”、“金属”还是“悲伤”或“愤怒”的程度。
- en: Computing Shapley Values
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算Shapley值
- en: For each track, I analyzed all source coalitions in terms of the track’s two
    most prominent genres and moods. To obtain the Shapley value for an instrument,
    I computed the difference between the genre & mood scores of each coalition where
    the instrument is absent with the respective coalition where the instrument is
    present. The average of these differences, i.e. the average contribution of adding
    this instrument to the mix, is the Shapley value.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每条轨道，我分析了所有源联盟的两个最显著的流派和心情。为了获得乐器的Shapley值，我计算了每个乐器缺席的联盟与该乐器存在的联盟之间的流派和心情评分差异。这些差异的平均值，即将该乐器添加到混音中的平均贡献，就是Shapley值。
- en: Results
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: Rock Track
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摇滚轨道
- en: Excerpt from “Look of Wonder” by Aviv Mark (CC BY-NC-ND 3.0 license).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 摘自Aviv Mark的《Wonder的外观》（CC BY-NC-ND 3.0许可证）。
- en: The “Rock” track was labeled as “rock” and “metal” for genres and as “energetic”
    and “aggressive” for moods by the auto-tagging tool.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: “摇滚”轨道被自动标记工具标记为“摇滚”和“金属”流派，以及“充满活力”和“攻击性”心情。
- en: '![](../Images/19b167d6ea1d08a863ef1fdbfeab32f6.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19b167d6ea1d08a863ef1fdbfeab32f6.png)'
- en: '**Figure 2**: Stem-Based Shapley Values for the “Rock” Track. Image by author.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2**：基于Stem的“摇滚”轨道Shapley值。图像来源：作者。'
- en: What can we see?
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们能看到什么？
- en: '*Figure 2* shows how each instrument source contributed to the respective tag.
    For example, we can see that the electric guitar, on average, increases the “metal”
    score by more than 50 percentage points. On the other hand, the “rock” score increases
    only around 5 percentage points. From that, we can already tell that the electric
    guitar sounds more like a “metal” guitar than like a “rock” guitar. For the vocals,
    the opposite is true: The vocals strongly increase the “rock” score while decreasing
    the “metal” score. This tells us the vocals and the electric guitar in this song
    contrast each other when it comes to genre. Isn’t that cool?'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2* 显示了每个乐器来源对各自标签的贡献。例如，我们可以看到，电吉他平均增加了“金属”评分超过 50 个百分点。另一方面，“摇滚”评分仅增加了大约
    5 个百分点。从中我们可以看出，电吉他的声音更像是一把“金属”吉他，而不是“摇滚”吉他。对于人声，则正好相反：人声显著提高了“摇滚”评分，同时降低了“金属”评分。这告诉我们，这首歌中的人声和电吉他在风格上相互对比。这不是很酷吗？'
- en: Looking at moods, we can see that the electric guitar is particularly important
    for expressing this track's “energetic” and “aggressive” mood. Unlike in the genre
    graph, all instruments seem to convey the same moods, just to different degrees.
    Interestingly, the bass instrument does not seem to contribute to the genre or
    mood scores. This could be because the bass is not very expressive, either because
    it is rather quiet or because it is played in a way that is not characteristic
    of a specific genre or mood.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从情绪的角度来看，我们可以看到电吉他在表达这首曲目的“充满活力”和“攻击性”情绪方面特别重要。与风格图不同，所有乐器似乎都传达了相同的情绪，只是程度不同。有趣的是，贝斯乐器似乎对风格或情绪评分没有贡献。这可能是因为贝斯的表现不够鲜明，要么是因为它比较安静，要么是因为它的演奏方式不具备某种特定风格或情绪的特点。
- en: What can we do with it?
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们能用它做什么？
- en: Already, the Shapley value approach helps us to understand the output of the
    auto-tagging system by analyzing which instrument contributes in which way to
    (or against) a specific genre or mood we are interested in. For example, if we
    wanted this track to achieve a higher “metal” score, we should consider rerecording
    the vocals with a different singer or singing style. To make it more “rock” and
    less “metal”, we could try to turn down the distortion of the electric guitar.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Shapley 值方法已经帮助我们通过分析哪些乐器以何种方式对我们感兴趣的特定风格或情绪做出贡献（或相反），来理解自动标记系统的输出。例如，如果我们希望这首曲目获得更高的“金属”评分，我们应该考虑用不同的歌手或唱腔重新录制人声。为了使其更“摇滚”而不那么“金属”，我们可以尝试降低电吉他的失真度。
- en: Jazz Track
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 爵士曲目
- en: Excerpt from “Jingle Jazz” by Quantum Jazz (CC BY-SA 3.0 license).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 摘自 Quantum Jazz 的《Jingle Jazz》（CC BY-SA 3.0 许可证）。
- en: For the “Jazz” track, the only genre output was “jazz” and the mood outputs
    were “happy” and “chill”.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“爵士”曲目，唯一的音乐风格输出为“爵士”，情绪输出为“愉快”和“放松”。
- en: '![](../Images/ed2d30ff7c74d11407f73fe4d9fc0c6b.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ed2d30ff7c74d11407f73fe4d9fc0c6b.png)'
- en: '**Figure 3**: Stem-Based Shapley Values for the “Jazz” Track. Image by author.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3**：基于 Stem 的 Shapley 值用于“爵士”曲目。图像由作者提供。'
- en: What can we see?
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们能看到什么？
- en: '**Figure 3** reveals that the piano and drums are what makes this song sound
    particularly “jazzy”. Although, from a musical point of view, the bass and electric
    guitar are also played very “jazzy” in the recording, it makes sense to highlight
    the piano and drums because they are just much more dominant in the mix and seem
    to carry the “stylistic weight” of the song, to my ears. The drums and piano alone
    would make a great-sounding jazz track, while the guitar and bass alone would
    sound odd without any of the other instruments present.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3** 显示了钢琴和鼓使这首歌听起来特别“爵士”。虽然从音乐的角度来看，贝斯和电吉他在录音中也表现得非常“爵士”，但突出钢琴和鼓是有道理的，因为它们在混音中更为突出，似乎承载了歌曲的“风格重量”，在我听来。单凭鼓和钢琴就能做出一首听起来很棒的爵士曲目，而如果只有吉他和贝斯，没有其他乐器的话则会显得奇怪。'
- en: The mood analysis reveals that all instruments positively contribute to the
    same moods. However, the piano and drums increase the “happy” score more than
    they do the “chill” score. The opposite applies to the electric guitar and bass,
    which contribute more to the “chill” score of the track. This is interesting because,
    while the piano and drums are also the most important instruments for the mood
    tags, the track would still be significantly less “chill” if the electric guitar
    and bass were not present or played differently.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 情绪分析揭示了所有乐器对相同情绪的积极贡献。然而，钢琴和鼓比对“轻松”情绪的贡献更多地提高了“快乐”分数。电吉他和贝斯则相反，它们对曲子的“轻松”分数贡献更多。这一点很有趣，因为尽管钢琴和鼓也是情绪标签中最重要的乐器，但如果没有电吉他和贝斯或它们的演奏方式不同，这首曲子会显著地少一些“轻松”感。
- en: What can we do with it?
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们可以用它做什么？
- en: Again, through our analysis, we gain insights into which instruments are most
    important for the tags assigned to the track. Additionally, we can see that we
    could now manipulate the mood characteristics of the song by changing the way
    some instruments are played, recorded, or mixed.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的分析，我们再次获得了哪些乐器对曲目标签最重要的见解。此外，我们还可以看到，通过改变一些乐器的演奏、录制或混音方式，我们现在可以操控歌曲的情绪特征。
- en: Mixed Track
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混音曲目
- en: Excerpt from “Vermouth and Baby” by Sakee Sed (CC BY-NC-ND 3.0 license).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 摘自Sakee Sed的《Vermouth and Baby》（CC BY-NC-ND 3.0许可证）。
- en: As expected, this track is labeled as both “rock” and “jazz”. As for moods,
    “happy” and “chill” were tagged.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期，这首曲子被标记为“摇滚”和“爵士”。至于情绪，“快乐”和“轻松”也被标记了。
- en: '![](../Images/b253362898315ad14a64f39f30377c98.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b253362898315ad14a64f39f30377c98.png)'
- en: '**Figure 4**: Stem-Based Shapley Values for the “Jazz” Track. Image by author.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**图4**: “爵士”曲目的基于干音的Shapley值。作者提供的图像。'
- en: What can we see?
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们可以看到什么？
- en: The results displayed in *Figure 4* are truly amazing to me! For one, our approach
    identifies that the piano is very “jazzy” and does not fit the “rock” genre well.
    On the other hand, the vocals are very untypical for “jazz” and contribute more
    to a “rock” classification. The other instruments are also contrastive, i.e. they
    point in either of the two genre directions, but their overall contribution scores
    are really low.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4*中展示的结果令我非常惊讶！首先，我们的方法识别出钢琴非常“爵士”，并且不太适合“摇滚”风格。另一方面，声乐非常不典型于“爵士”，更倾向于“摇滚”分类。其他乐器也是对比性的，即它们指向两个风格方向中的任何一个，但它们的整体贡献分数确实很低。'
- en: For the first time, we see some contrastive mood score contributions, although
    small ones. The graph implies that the vocals and drums contribute to the track
    being more “happy” and less “chill”. Still, most of the weight is carried by the
    piano, which makes the track both, more “happy” and more “chill”.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首次看到了一些对比性的情绪分数贡献，尽管数值较小。图表暗示，声乐和鼓使得这首曲子更“快乐”而更少“轻松”。然而，大部分的权重还是由钢琴承担的，这使得曲子更“快乐”且更“轻松”。
- en: What can we do with it?
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们可以用它做什么？
- en: This analysis gives us some great advice on which instruments contributed to
    the genre and mood outputs of the auto-tagging AI. We can also see that removing
    or changing the piano part would make the track less “jazzy”, but could, at the
    same time, decrease its “happiness” and “chillness”.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这项分析为我们提供了一些关于哪些乐器对自动标记 AI 的风格和情绪输出有贡献的宝贵建议。我们还可以看到，去掉或改变钢琴部分会使这首曲子少一些“爵士”风格，但同时也可能减少其“快乐”和“轻松”感。
- en: Discussion
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 讨论
- en: What worked well?
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么效果良好？
- en: The overall goal of this article, to find an algorithmic solution that offers
    local explanations for black-box auto-tagging systems using source separation,
    was reached. The generated explanations offer insights into how each instrument
    contributed to the genre and mood outputs of the auto-tagging system. Although
    we looked only at a few selected genres and moods, this approach can be expanded
    to other tags like decades, brand values, locations, etc. without much additional
    effort.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的整体目标是找到一种算法解决方案，通过源分离为黑箱自动标记系统提供局部解释，这一目标已经达成。生成的解释提供了每种乐器如何对自动标记系统的风格和情绪输出做出贡献的见解。尽管我们只查看了几个选定的风格和情绪，但这种方法可以扩展到其他标签，如年代、品牌价值、地点等，而无需额外的努力。
- en: I can see two use cases where this approach could benefit the work of musicians.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以看到这种方法可以在两个用例中对音乐家的工作有所帮助。
- en: Musicians could use it to check if their music is interpreted by the AI in a
    way that they deem appropriate. If that is not the case, the Shapley values give
    recommendations on which instruments could be changed to achieve this goal. This
    could help musicians achieve better visibility in music catalogs or on streaming
    services.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 音乐家可以使用它来检查他们的音乐是否以他们认为合适的方式被AI解读。如果不是这样，Shapley值会给出关于哪些乐器可以更改以实现这一目标的建议。这可以帮助音乐家在音乐目录或流媒体服务中获得更好的可见性。
- en: Lastly, this approach could be useful for the composition and production process
    itself. Musicians could analyze their demos and get some AI feedback on which
    genres, moods, etc. each instrument in the song is characteristic for. This could
    help the composer to further flesh out their work or to try new stylistic approaches.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，这种方法对创作和制作过程本身可能是有用的。音乐家可以分析他们的演示，并获得一些关于歌曲中每个乐器的特征，如哪些流派、情绪等的AI反馈。这可以帮助作曲家进一步完善他们的作品或尝试新的风格方法。
- en: What did not work so well?
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有哪些方面表现不佳？
- en: The main problem with the proposed algorithm is that it is resource-inefficient.
    An input music track has to be split into all instruments/instrument groups present.
    This alone takes a long time, as music source separation systems are complex and
    require lots of computing power. Then, all combinations of instrument sources
    are generated and thrown separately into an AI auto-tagger. If we have 6 instrument
    sources in the track, this means that the auto-tagger has to process 31 tracks
    instead of just one. Once this is done, the Shapley values, at least, can be computed
    very efficiently. All in all, doing this for a few tracks is feasible, but applying
    this algorithm at scale may be out-of-scope with the current technology.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 提议的算法主要问题是资源效率低。输入的音乐轨道必须被拆分成所有存在的乐器/乐器组。这本身就需要很长时间，因为音乐源分离系统复杂且需要大量计算能力。然后，所有乐器源的组合被生成并分别输入到AI自动标签器中。如果我们在轨道中有6个乐器源，这意味着自动标签器需要处理31条轨道而不是仅仅一条。一旦完成，Shapley值至少可以非常高效地计算。总的来说，对少量轨道进行这种处理是可行的，但在当前技术下，规模化应用此算法可能超出了范围。
- en: Another weakness of this approach is that, although source separation tools
    have been getting much better over the last years, the results are still not perfect.
    If we automate the algorithm and do not check every single separated source, individually,
    we will not realize when the separation did not work so well. This could drastically
    distort the results of the analysis.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的另一个弱点是，尽管源分离工具在过去几年中取得了显著进步，但结果仍然不完美。如果我们自动化算法而不逐个检查每个分离的源，我们将无法发现分离效果不佳的情况。这可能会严重扭曲分析结果。
- en: What could be the next steps?
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步可能是什么？
- en: The proposed method has a high algorithmic complexity and therefore does not
    scale well with the number of instruments present in a track. Additionally, it
    is unclear whether we can sufficiently rely on the quality of current source separation
    systems. Both of these challenges will be less of a problem as computing resources
    become cheaper and as the quality of source separation tools increases even further.
    Still, the algorithmic complexity will remain a problem, unless an efficient approximation
    is found and developed.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 提议的方法具有较高的算法复杂性，因此在轨道中乐器数量增加时不易扩展。此外，目前我们是否可以充分依赖源分离系统的质量尚不清楚。随着计算资源变得更便宜以及源分离工具的质量进一步提高，这两个挑战将不再是问题。然而，算法复杂性仍将是一个问题，除非找到并开发出一种高效的近似算法。
- en: The code written for this blog post is far from efficient and was solely created
    for the purpose of this article. And while I do publish the code on [GitHub](https://github.com/MaxHilsdorf/music_stem_shapley_values),
    I advise against using it as a basis for a real-world implementation of the algorithm.
    In my estimation, it would be better to construct an efficient pipeline for this
    multi-stage process from scratch and with an eye for detail. A cloud-based implementation
    looks promising, as most parts of the process can be sped up drastically by leveraging
    parallel computing.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为这篇博客文章编写的代码远非高效，仅仅是为了文章目的而创建的。虽然我会在[GitHub](https://github.com/MaxHilsdorf/music_stem_shapley_values)上发布代码，但我建议不要将其作为实际应用该算法的基础。我认为，最好从头开始构建一个高效的多阶段处理流程，并注重细节。基于云的实现看起来很有前途，因为大多数处理过程可以通过利用并行计算来大幅加速。
- en: Zooming out a bit, this approach applies the concept of Shapley values to abstract
    features of a piece of music, not to the “real” data as the AI sees it (e.g. the
    values of a spectrogram or a waveform). I am sure that there are other applications
    for this kind of feature abstraction in other domains where non-tabular data is
    used to train AI models (e.g. images, text, speech). For instance, we could split
    a text into its individual sentences and attempt something similar to what we
    did here. With such an approach, we might be able to tell which sentence in a
    mail lead to the mail being classified as spam, for example. There must be more
    like this out there to find and implement!
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从宏观角度来看，这种方法将Shapley值的概念应用于音乐作品的抽象特征，而不是AI所看到的“真实”数据（例如，光谱图或波形的值）。我相信这种特征抽象的方法在其他使用非表格数据训练AI模型的领域也有其他应用（例如图像、文本、语音）。例如，我们可以将一段文本拆分成单独的句子，并尝试类似于我们在这里做的事情。通过这种方法，我们可能能够识别出邮件中哪个句子导致邮件被分类为垃圾邮件。一定还有更多类似的应用等待发现和实施！
- en: '**Thank you so much for reading this!**'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**非常感谢你的阅读！**'
- en: 'I write a lot about AI and music. Here are some related posts you might like:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我写了很多关于AI和音乐的文章。以下是一些相关的帖子，你可能会感兴趣：
- en: '[Natural Audio Data Augmentation Using Spotify’s Pedalboard](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Spotify的Pedalboard进行自然音频数据增强](/natural-audio-data-augmentation-using-spotifys-pedalboard-212ea59d39ce)'
- en: '[Zero-Shot Song Lyrics Transcription Using Whisper](https://medium.com/mlearning-ai/zero-shot-song-lyrics-transcription-using-whisper-3f360499bcfe)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Whisper进行零-shot歌曲歌词转录](https://medium.com/mlearning-ai/zero-shot-song-lyrics-transcription-using-whisper-3f360499bcfe)'
- en: '[Music Classification Using a Divide & Conquer CRNN](/music-genre-classification-using-a-divide-conquer-crnn-2ff1cf49859f)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用分治法CRNN进行音乐分类](/music-genre-classification-using-a-divide-conquer-crnn-2ff1cf49859f)'
