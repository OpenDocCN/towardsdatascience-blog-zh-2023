# é’ˆå¯¹äº§å“å’Œå·¥ç¨‹é¢†å¯¼è€…çš„åŠ¨æ‰‹ GenAI

> åŸæ–‡ï¼š[https://towardsdatascience.com/hands-on-genai-for-product-engineering-leaders-6ee6ad94e058?source=collection_archive---------10-----------------------#2023-11-28](https://towardsdatascience.com/hands-on-genai-for-product-engineering-leaders-6ee6ad94e058?source=collection_archive---------10-----------------------#2023-11-28)

## é€šè¿‡æ·±å…¥äº†è§£åŸºäºLLMçš„äº§å“ï¼Œåšå‡ºæ›´å¥½çš„äº§å“å†³ç­–

[](https://medium.com/@ninadsohoni?source=post_page-----6ee6ad94e058--------------------------------)[![Ninad Sohoni](../Images/8d6ec40665bb85fb7b4ece99e6a40913.png)](https://medium.com/@ninadsohoni?source=post_page-----6ee6ad94e058--------------------------------)[](https://towardsdatascience.com/?source=post_page-----6ee6ad94e058--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----6ee6ad94e058--------------------------------) [Ninad Sohoni](https://medium.com/@ninadsohoni?source=post_page-----6ee6ad94e058--------------------------------)

Â·

[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5ee93978501b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-genai-for-product-engineering-leaders-6ee6ad94e058&user=Ninad+Sohoni&userId=5ee93978501b&source=post_page-5ee93978501b----6ee6ad94e058---------------------post_header-----------) å‘è¡¨åœ¨ [Towards Data Science](https://towardsdatascience.com/?source=post_page-----6ee6ad94e058--------------------------------) Â· 35 åˆ†é’Ÿé˜…è¯» Â· 2023å¹´11æœˆ28æ—¥ [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F6ee6ad94e058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-genai-for-product-engineering-leaders-6ee6ad94e058&user=Ninad+Sohoni&userId=5ee93978501b&source=-----6ee6ad94e058---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6ee6ad94e058&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fhands-on-genai-for-product-engineering-leaders-6ee6ad94e058&source=-----6ee6ad94e058---------------------bookmark_footer-----------)![](../Images/4b2f853b2bede6542039512f44e4c4c2.png)

å›¾ç‰‡ç”± [Bing Image Creator](https://www.bing.com/create) æ ¹æ®æç¤ºâ€œä¸ºæœºå™¨å­¦ä¹ é©±åŠ¨çš„åº”ç”¨ç¨‹åºå·¥ä½œä¸­çš„äº§å“æ‰€æœ‰è€…â€ç”Ÿæˆ

# ä»‹ç»

å¦‚æœä½ æ˜¯ä¸€ä¸ªæ™®é€šå¸æœºï¼Œä½ å¯èƒ½ä¸åœ¨ä¹ä½ è½¦çš„å¼•æ“ç›–ä¸‹æ˜¯ä»€ä¹ˆã€‚ç„¶è€Œï¼Œå¦‚æœä½ æ˜¯è®¾è®¡å’Œæ‰§è¡Œé“¾æ¡ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œè´Ÿè´£æ‰“é€ æ›´å¥½çš„æ±½è½¦ï¼Œäº†è§£ä¸åŒéƒ¨ä»¶æ˜¯ä»€ä¹ˆä»¥åŠå®ƒä»¬å¦‚ä½•ååŒå·¥ä½œï¼Œå°†å¸®åŠ©ä½ æ‰“é€ æ›´å¥½çš„æ±½è½¦ã€‚

åŒæ ·ï¼Œä½œä¸ºäº§å“è´Ÿè´£äººã€ä¸šåŠ¡é¢†å¯¼æˆ–è´Ÿè´£åˆ›å»ºæ–°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨äº§å“çš„å·¥ç¨‹å¸ˆï¼Œæˆ–å°†LLM/ç”Ÿæˆæ€§AIå¼•å…¥ç°æœ‰äº§å“çš„å·¥ç¨‹å¸ˆï¼Œäº†è§£LLMé©±åŠ¨äº§å“çš„æ„å»ºæ¨¡å—å°†å¸®åŠ©ä½ è§£å†³ä¸æŠ€æœ¯ç›¸å…³çš„æˆ˜ç•¥å’Œæˆ˜æœ¯é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œ

1.  æˆ‘ä»¬çš„ä½¿ç”¨æ¡ˆä¾‹æ˜¯å¦é€‚åˆLLMé©±åŠ¨çš„è§£å†³æ–¹æ¡ˆï¼Ÿä¹Ÿè®¸ä¼ ç»Ÿçš„åˆ†æã€ç›‘ç£å¼æœºå™¨å­¦ä¹ æˆ–å…¶ä»–æ–¹æ³•æ›´åˆé€‚ï¼Ÿ

1.  å¦‚æœLLMæ˜¯å¯è¡Œçš„ï¼Œæˆ‘ä»¬çš„ä½¿ç”¨æ¡ˆä¾‹ç°åœ¨æˆ–åœ¨ä¸ä¹…çš„å°†æ¥æ˜¯å¦å¯ä»¥é€šè¿‡ç°æˆçš„äº§å“ï¼ˆæ¯”å¦‚ChatGPT Enterpriseï¼‰æ¥è§£å†³ï¼Ÿè¿™æ˜¯ç»å…¸çš„æ„å»ºä¸è´­ä¹°å†³ç­–ã€‚

1.  æˆ‘ä»¬çš„LLMé©±åŠ¨äº§å“çš„ä¸åŒæ„å»ºæ¨¡å—æœ‰å“ªäº›ï¼Ÿå…¶ä¸­å“ªäº›å·²ç»å•†å“åŒ–ï¼Œå“ªäº›å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´æ¥æ„å»ºå’Œæµ‹è¯•ï¼Ÿ

1.  æˆ‘ä»¬å¦‚ä½•è¡¡é‡è§£å†³æ–¹æ¡ˆçš„æ€§èƒ½ï¼Ÿæœ‰å“ªäº›æ æ†å¯ä»¥æé«˜æˆ‘ä»¬äº§å“è¾“å‡ºçš„è´¨é‡ï¼Ÿ

1.  æˆ‘ä»¬çš„æ•°æ®è´¨é‡æ˜¯å¦ç¬¦åˆä½¿ç”¨æ¡ˆä¾‹çš„è¦æ±‚ï¼Ÿæˆ‘ä»¬æ˜¯å¦æ­£ç¡®åœ°ç»„ç»‡äº†æ•°æ®ï¼Œå¹¶å°†ç›¸å…³æ•°æ®ä¼ é€’ç»™äº†LLMï¼Ÿ

1.  æˆ‘ä»¬èƒ½å¦ç¡®ä¿¡LLMçš„å›ç­”å§‹ç»ˆæ˜¯äº‹å®å‡†ç¡®çš„ï¼Ÿä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆæ˜¯å¦ä¼šåœ¨ç”Ÿæˆå›ç­”æ—¶å¶å°”å‡ºç°â€œå¹»è§‰â€ï¼Ÿ

è™½ç„¶è¿™äº›é—®é¢˜åœ¨æ–‡ç« åé¢ä¼šå¾—åˆ°å›ç­”ï¼Œä½†é€šè¿‡åŠ¨æ‰‹å®è·µçš„ç›®æ ‡æ˜¯å»ºç«‹å¯¹LLMé©±åŠ¨è§£å†³æ–¹æ¡ˆçš„ç›´è§‚ç†è§£ï¼Œè¿™åº”è¯¥æœ‰åŠ©äºä½ è‡ªå·±å›ç­”è¿™äº›é—®é¢˜ï¼Œæˆ–è€…è‡³å°‘è®©ä½ æ›´å¥½åœ°è¿›è¡Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚

åœ¨ä¸€ç¯‡[ä¸Šä¸€ç¯‡æ–‡ç« ](/how-genai-solutions-revolutionize-business-automation-57747b0f11ce)ä¸­ï¼Œæˆ‘**æ·±å…¥æ¢è®¨**äº†ä¸æ„å»ºLLMé©±åŠ¨äº§å“ç›¸å…³çš„ä¸€äº›åŸºç¡€æ¦‚å¿µã€‚ä½†ä½ ä¸èƒ½ä»…ä»…é€šè¿‡é˜…è¯»åšå®¢æˆ–è§‚çœ‹è§†é¢‘æ¥å­¦ä¼šé©¾é©¶â€”â€”è¿™éœ€è¦ä½ äº²è‡ªä¸Šè·¯ã€‚å¥½åœ¨æˆ‘ä»¬ç”Ÿæ´»çš„æ—¶ä»£æä¾›äº†å…è´¹çš„å·¥å…·ï¼ˆè¿™äº›å·¥å…·çš„åˆ›å»º[èŠ±è´¹äº†æ•°ç™¾ä¸‡ç¾å…ƒ](https://lambdalabs.com/blog/demystifying-gpt-3)ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸åˆ°ä¸€å°æ—¶çš„æ—¶é—´é‡Œæ„å»ºè‡ªå·±çš„LLMè§£å†³æ–¹æ¡ˆï¼å› æ­¤ï¼Œåœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å»ºè®®æˆ‘ä»¬å°±è¿™æ ·åšã€‚è¿™æ¯”å­¦ä¹ é©¾é©¶è¦å®¹æ˜“å¾—å¤šğŸ˜ã€‚

**æ„å»ºä¸€ä¸ªå…è®¸ä½ ä¸ç½‘ç«™â€œèŠå¤©â€çš„èŠå¤©æœºå™¨äºº**

> ç›®æ ‡ï¼šæ„å»ºä¸€ä¸ªåŸºäºæä¾›çš„ç½‘ç«™ä¿¡æ¯å›ç­”é—®é¢˜çš„èŠå¤©æœºå™¨äººï¼Œ**ä»¥æ›´å¥½åœ°ç†è§£**å½“å‰æµè¡Œçš„GenAIè§£å†³æ–¹æ¡ˆçš„æ„å»ºæ¨¡å—

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåŸºäºçŸ¥è¯†åº“ä¿¡æ¯å›ç­”é—®é¢˜çš„é—®ç­”èŠå¤©æœºå™¨äººã€‚è¿™ç§è§£å†³æ–¹æ¡ˆæ¨¡å¼ï¼Œç§°ä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ï¼Œå·²æˆä¸ºå…¬å¸ä¸­çš„é¦–é€‰è§£å†³æ–¹æ¡ˆæ¨¡å¼ã€‚RAG ä¹‹æ‰€ä»¥å—æ¬¢è¿çš„ä¸€ä¸ªåŸå› æ˜¯ï¼Œå®ƒä¸ä»…ä¾èµ–äº LLM è‡ªèº«çš„çŸ¥è¯†ï¼Œè¿˜å¯ä»¥ä»¥è‡ªåŠ¨åŒ–çš„æ–¹å¼å°†å¤–éƒ¨ä¿¡æ¯å¸¦å…¥ LLMã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¤–éƒ¨ä¿¡æ¯å¯ä»¥æ¥è‡ªç»„ç»‡è‡ªå·±çš„çŸ¥è¯†åº“ï¼ŒåŒ…å«ä¸“æœ‰ä¿¡æ¯ï¼Œä»¥ä½¿äº§å“èƒ½å¤Ÿå›ç­”æœ‰å…³ä¸šåŠ¡ã€äº§å“ã€ä¸šåŠ¡æµç¨‹ç­‰é—®é¢˜ã€‚RAG è¿˜å‡å°‘äº† LLM çš„â€œå¹»è§‰â€ï¼Œå³ç”Ÿæˆçš„å“åº”æ˜¯åŸºäºæä¾›ç»™ LLM çš„ä¿¡æ¯çš„ã€‚æ ¹æ® [æœ€è¿‘çš„ä¸€æ¬¡æ¼”è®²](https://www.youtube.com/watch?v=xa7k9MUeIdk)ï¼Œ

> â€œRAG å°†æ˜¯ä¼ä¸šä½¿ç”¨ LLM çš„é»˜è®¤æ–¹å¼â€
> 
> -Dr. Waleed Kadous, Chief Scientist, AnyScale

åœ¨æˆ‘ä»¬çš„å®æ“ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†å…è®¸ç”¨æˆ·è¾“å…¥ä¸€ä¸ªç½‘ç«™ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆå°†â€œè¯»å–â€è¯¥ç½‘ç«™åˆ°å…¶çŸ¥è¯†åº“ä¸­ã€‚ç„¶åï¼Œè§£å†³æ–¹æ¡ˆå°†èƒ½å¤Ÿæ ¹æ®ç½‘ç«™ä¸Šçš„ä¿¡æ¯å›ç­”é—®é¢˜ã€‚è¿™ä¸ªç½‘ç«™æ˜¯ä¸€ä¸ªå ä½ç¬¦â€”â€”å®é™…ä¸Šï¼Œå¯ä»¥è°ƒæ•´ä¸ºä»ä»»ä½•æ•°æ®æºå¦‚ PDFsã€Excelã€å…¶ä»–äº§å“æˆ–å†…éƒ¨ç³»ç»Ÿç­‰è·å–æ–‡æœ¬ã€‚è¿™ç§æ–¹æ³•ä¹Ÿé€‚ç”¨äºå…¶ä»–åª’ä½“â€”â€”å¦‚å›¾åƒâ€”â€”ä½†å®ƒä»¬éœ€è¦ä¸€äº›ä¸åŒçš„ LLMã€‚ç›®å‰ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨æ¥è‡ªç½‘ç«™çš„æ–‡æœ¬ã€‚

ä½œä¸ºç¤ºä¾‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸ºæœ¬åšå®¢åˆ›å»ºçš„ç¤ºä¾‹ä¹¦å•ç½‘é¡µï¼š[Books Iâ€™d Pick Up â€” If There Were More Hours in the Day!](https://ninadsohoni.github.io/booklist/) æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨æ‚¨é€‰æ‹©çš„å…¶ä»–ç½‘ç«™ã€‚

è¿™å°±æ˜¯æˆ‘ä»¬çš„ç»“æœçš„æ ·å­ï¼š

![](../Images/781fc874901946c9c92cb4c6ab0f0984.png)

LLM é©±åŠ¨çš„èŠå¤©æœºå™¨äººå¯ä»¥æ ¹æ®ç½‘ç«™ä¸Šçš„ä¿¡æ¯æ™ºèƒ½å›ç­”é—®é¢˜ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰

ä»¥ä¸‹æ˜¯æˆ‘ä»¬å°†éµå¾ªçš„æ­¥éª¤æ¥æ„å»ºæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆï¼š

0\. è®¾ç½® â€” Google Colaboratory å’Œ OpenAI API å¯†é’¥

1\. åˆ›å»ºçŸ¥è¯†åº“

2\. æœç´¢ä¸é—®é¢˜ç›¸å…³çš„ä¸Šä¸‹æ–‡

3\. ä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆ

4\. æ·»åŠ â€œèŠå¤©â€åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰

5\. æ·»åŠ ä¸€ä¸ªç®€å•çš„é¢„ç¼–ç  UIï¼ˆå¯é€‰ï¼‰

## **0.1\. è®¾ç½® â€” Google Colaboratory å’Œ OpenAI API å¯†é’¥**

è¦æ„å»ºä¸€ä¸ª LLM è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªç¼–å†™å’Œè¿è¡Œä»£ç çš„åœ°æ–¹ï¼Œä»¥åŠä¸€ä¸ªç”Ÿæˆé—®é¢˜å›ç­”çš„ LLMã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Google Colab ä½œä¸ºä»£ç ç¯å¢ƒï¼Œå¹¶ä½¿ç”¨ ChatGPT èƒŒåçš„æ¨¡å‹ä½œä¸ºæˆ‘ä»¬çš„ LLMã€‚

é¦–å…ˆè®¾ç½® [Google Colab](https://colab.google/)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”± Google æä¾›çš„å…è´¹æœåŠ¡ï¼Œå¯ä»¥ä»¥æ˜“äºé˜…è¯»çš„æ ¼å¼è¿è¡Œ Python ä»£ç  â€” æ— éœ€åœ¨è®¡ç®—æœºä¸Šå®‰è£…ä»»ä½•ä¸œè¥¿ã€‚æˆ‘å‘ç°å°† Colab æ·»åŠ åˆ° Google Drive ä¸­å¾ˆæ–¹ä¾¿ï¼Œè¿™æ ·æˆ‘å°±å¯ä»¥è½»æ¾æ‰¾åˆ° Colab ç¬”è®°æœ¬ã€‚

ä¸ºæ­¤ï¼Œå¯¼èˆªè‡³ **Google Drive**ï¼ˆä½¿ç”¨æµè§ˆå™¨ï¼‰ **> æ–°å»º > æ›´å¤š > è¿æ¥æ›´å¤šåº”ç”¨ >** åœ¨ Google Marketplace ä¸­ **æœç´¢ â€œColaboratoryâ€** **> å®‰è£…ã€‚**

è¦å¼€å§‹ä½¿ç”¨ Colabï¼Œä½ å¯ä»¥é€‰æ‹© **æ–°å»º** > **æ›´å¤š** > **Google Colaboratory**ã€‚è¿™å°†ä¼šåœ¨ä½ çš„ Google äº‘ç«¯ç¡¬ç›˜ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„ç¬”è®°æœ¬ï¼Œæ–¹ä¾¿ä½ è¿”å›ç»§ç»­ä½¿ç”¨ã€‚

![](../Images/ee514c154f891d1fd129b21195a698bd.png)

Google Colaboratory å¯ä»¥åœ¨ Google äº‘ç«¯ç¡¬ç›˜ä¸­è®¿é—®ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬è·å–å¯¹ LLM çš„è®¿é—®æƒé™ã€‚æœ‰å‡ ä¸ªå¼€æºå’Œä¸“æœ‰é€‰é¡¹å¯ä¾›é€‰æ‹©ã€‚è™½ç„¶å¼€æº LLM æ˜¯å…è´¹çš„ï¼Œä½†å¼ºå¤§çš„ LLM é€šå¸¸éœ€è¦å¼ºå¤§çš„ GPU æ¥å¤„ç†è¾“å…¥å’Œç”Ÿæˆå“åº”ï¼Œä¸” GPU çš„è¿è¡Œæˆæœ¬è¾ƒä½ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ OpenAI çš„æœåŠ¡æ¥ä½¿ç”¨ ChatGPT æ‰€ç”¨çš„ LLMã€‚ä¸ºæ­¤ï¼Œä½ éœ€è¦ä¸€ä¸ª API å¯†é’¥ï¼Œå®ƒç±»ä¼¼äºç”¨æˆ·å/å¯†ç çš„ç»„åˆï¼Œç”¨ä»¥è®© OpenAI çŸ¥é“æ˜¯è°åœ¨å°è¯•è®¿é—® LLMã€‚æ ¹æ®æ­¤æ—¶çš„ä¿¡æ¯ï¼ŒOpenAI ä¸ºæ–°ç”¨æˆ·æä¾›äº† $5 çš„ä¿¡ç”¨é¢åº¦ï¼Œè¶³ä»¥ç”¨äºæœ¬å®è·µæ•™ç¨‹ã€‚ä»¥ä¸‹æ˜¯è·å– API å¯†é’¥çš„æ­¥éª¤ï¼š

è®¿é—®[**OpenAI å¹³å°ç½‘ç«™**](https://platform.openai.com/signup/)> **å¼€å§‹ä½¿ç”¨ > æ³¨å†Œ**ï¼Œä½¿ç”¨ç”µå­é‚®ä»¶å’Œå¯†ç è¿›è¡Œæ³¨å†Œï¼Œæˆ–ä½¿ç”¨ Google æˆ– Microsoft å¸æˆ·æ³¨å†Œã€‚ä½ è¿˜å¯èƒ½éœ€è¦ä¸€ä¸ªç”µè¯å·ç è¿›è¡ŒéªŒè¯ã€‚

ç™»å½•åï¼Œç‚¹å‡»å³ä¸Šè§’çš„ä¸ªäººèµ„æ–™å›¾æ ‡ > **æŸ¥çœ‹ API å¯†é’¥** > **åˆ›å»ºæ–°å¯†é’¥**ã€‚å¯†é’¥å°†ç±»ä¼¼äºä»¥ä¸‹å†…å®¹ï¼ˆä»…ä¾›å‚è€ƒçš„å‡å¯†é’¥ï¼‰ã€‚è¯·ä¿å­˜ä»¥å¤‡åç”¨ã€‚

```py
sk-4f3a9b8e7c4f4c8f8f3a9b8e7c4f4c8f-UsH4C3vE64
```

ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½æ„å»ºè§£å†³æ–¹æ¡ˆäº†ã€‚

## 0.2\. å‡†å¤‡æ„å»ºè§£å†³æ–¹æ¡ˆçš„ç¬”è®°æœ¬

æˆ‘ä»¬éœ€è¦åœ¨ Colab ç¯å¢ƒä¸­å®‰è£…ä¸€äº›è½¯ä»¶åŒ…ä»¥æ–¹ä¾¿æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆã€‚åªéœ€åœ¨ Colab ä¸­çš„æ–‡æœ¬æ¡†ï¼ˆç§°ä¸ºâ€œå•å…ƒæ ¼â€ï¼‰ä¸­è¾“å…¥ä»¥ä¸‹ä»£ç ï¼Œç„¶åæŒ‰â€œShift + Returnï¼ˆEnterï¼‰â€ã€‚æˆ–è€…ï¼Œç›´æ¥ç‚¹å‡»å•å…ƒæ ¼å·¦ä¾§çš„â€œæ’­æ”¾â€æŒ‰é’®æˆ–ä½¿ç”¨ç¬”è®°æœ¬é¡¶éƒ¨çš„â€œè¿è¡Œâ€èœå•ã€‚ä½ å¯èƒ½éœ€è¦ä½¿ç”¨èœå•æ’å…¥æ–°çš„ä»£ç å•å…ƒæ ¼ä»¥è¿è¡Œåç»­ä»£ç ï¼š

```py
# Install OpenAI & tiktoken packages to use the embeddings model as well as the chat completion model
!pip install openai tiktoken
# Install the langchain package to facilitate a most of the functionality in our solution, from processing documents to enabling "chat" using LLM
!pip install langchain
# Install ChromaDB - an in-memory vector database package - to save the "knowledge" relied on by our solution to answer questions
!pip install chromadb
# Install HTML to text package to transform webpage content to a more human readable format
!pip install html2text
# Install gradio to create a basic UI for our solution
!pip install gradio
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åº”è¯¥ä»å·²å®‰è£…çš„è½¯ä»¶åŒ…ä¸­æå–ä»£ç ï¼Œä»¥ä¾¿åœ¨ç¼–å†™çš„ä»£ç ä¸­ä½¿ç”¨è¿™äº›è½¯ä»¶åŒ…ã€‚ä½ å¯ä»¥ä½¿ç”¨æ–°çš„ä»£ç å•å…ƒæ ¼å¹¶å†æ¬¡æŒ‰â€œShift + Returnâ€ â€” ä»¥è¿™ç§æ–¹å¼ç»§ç»­è¿›è¡Œæ¯ä¸ªåç»­çš„ä»£ç å—ã€‚

```py
# Import packages needed to enable different functionality for the solution
from langchain.document_loaders import AsyncHtmlLoader # To load website content into a document
from langchain.text_splitter import MarkdownHeaderTextSplitter # To document into smaller chunks by document headings 
from langchain.document_transformers import Html2TextTransformer # To converrt HTML to Markdown text
from langchain.chat_models import ChatOpenAI # To use OpenAI's LLM
from langchain.prompts import PromptTemplate # To formulate instructions / prompts
from langchain.chains import RetrievalQA, ConversationalRetrievalChain # For RAG
from langchain.memory import ConversationTokenBufferMemory # To maintain chat history
from langchain.embeddings.openai import OpenAIEmbeddings # To convert text to numerical representation
from langchain.vectorstores import Chroma # To interact with vector database
import pandas as pd, gradio as gr # To show data as tables, and to build UI respectively
import chromadb, json, textwrap # Vector database, converting json to text, and prettify printing respectively
from chromadb.utils import embedding_functions # Setting up embedding function, following protocol required by Chroma
```

æœ€åï¼Œå°† OpenAI API å¯†é’¥æ·»åŠ åˆ°ä¸€ä¸ªå˜é‡ä¸­ã€‚è¯·æ³¨æ„ï¼Œè¿™ä¸ªå¯†é’¥ç±»ä¼¼äºä½ çš„å¯†ç  â€” è¯·å‹¿åˆ†äº«ã€‚æ­¤å¤–ï¼Œåœ¨åˆ†äº«ä½ çš„ Colab ç¬”è®°æœ¬å‰ï¼Œè¯·åŠ¡å¿…å…ˆåˆ é™¤ API å¯†é’¥ã€‚

```py
# Add your OpenAI API Key to a variable
# Saving the key in a variable like so is bad practice. It should be loaded into environment variables and loaded from there, but this is okay for a quick demo
OPENAI_API_KEY='sk-4f3a9b8e7c4f4c8f8f3a9b8e7c4f4c8f-UsH4C3vE64' # Fake Key - use your own real key here
```

ç°åœ¨æˆ‘ä»¬å‡†å¤‡å¼€å§‹æ„å»ºè§£å†³æ–¹æ¡ˆã€‚ä»¥ä¸‹æ˜¯æ¥ä¸‹æ¥æ­¥éª¤çš„é«˜çº§è§†å›¾ï¼š

![](../Images/f4773785ae6fd1047c8a8c724bb381bf.png)

æ„å»º RAG è§£å†³æ–¹æ¡ˆçš„æ ¸å¿ƒæ­¥éª¤ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

åœ¨ç¼–ç æ—¶ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨LangChainï¼Œå®ƒå·²ç»æˆä¸ºæ„å»ºæ­¤ç±»è§£å†³æ–¹æ¡ˆçš„æµè¡Œæ¡†æ¶ã€‚å®ƒæœ‰åŠ©äºä»è¿æ¥æ•°æ®æºåˆ°å‘é€å’Œæ¥æ”¶LLMä¿¡æ¯çš„æ¯ä¸ªæ­¥éª¤ã€‚LlamaIndexæ˜¯å¦ä¸€ä¸ªç®€åŒ–æ„å»ºLLMé©±åŠ¨åº”ç”¨çš„é€‰é¡¹ã€‚è™½ç„¶å¹¶ä¸ä¸¥æ ¼è¦æ±‚ä½¿ç”¨LangChainï¼ˆæˆ–LlamaIndexï¼‰ï¼Œå¹¶ä¸”åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé«˜çº§æŠ½è±¡å¯èƒ½ä½¿å›¢é˜Ÿå¯¹å†…éƒ¨å‘ç”Ÿçš„äº‹æƒ…ä¸€æ— æ‰€çŸ¥ï¼Œä½†æˆ‘ä»¬å°†ä½¿ç”¨LangChainï¼Œä½†ä»ä¼šç»å¸¸æŸ¥çœ‹å†…éƒ¨æƒ…å†µã€‚

è¯·æ³¨æ„ï¼Œç”±äºåˆ›æ–°çš„é€Ÿåº¦å¦‚æ­¤ä¹‹å¿«ï¼Œå¯èƒ½ä¼šæœ‰ä»£ç ä¸­ä½¿ç”¨çš„åŒ…æ›´æ–°ï¼Œæœ‰äº›æ›´æ–°å¯èƒ½ä¼šå¯¼è‡´ä»£ç åœæ­¢å·¥ä½œï¼Œé™¤éç›¸åº”åœ°è¿›è¡Œæ›´æ–°ã€‚æˆ‘ä¸æ‰“ç®—ä¿æŒä»£ç çš„æœ€æ–°çŠ¶æ€ã€‚ç„¶è€Œï¼Œæœ¬æ–‡æ—¨åœ¨ä½œä¸ºæ¼”ç¤ºï¼Œä»£ç å¯ä»¥ä½œä¸ºå‚è€ƒæˆ–èµ·ç‚¹ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œè°ƒæ•´ã€‚

## 1\. åˆ›å»ºçŸ¥è¯†åº“

**1.1\. ç¡®å®šå¹¶è¯»å–æ–‡æ¡£** è®©æˆ‘ä»¬è®¿é—®ä¹¦å•å¹¶å°†å†…å®¹è¯»å–åˆ°æˆ‘ä»¬çš„Colabç¯å¢ƒä¸­ã€‚å†…å®¹æœ€åˆä»¥HTMLæ ¼å¼åŠ è½½ï¼Œè¿™å¯¹ç½‘é¡µæµè§ˆå™¨å¾ˆæœ‰ç”¨ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨HTMLè½¬æ–‡æœ¬å·¥å…·å°†å…¶è½¬æ¢ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼ã€‚

```py
url = "https://ninadsohoni.github.io/booklist/" # Feel free to use any other website here, but note that some code might need to be edited to display contents properly

# Load HTML from URL and transform to a more readable text format
docs = Html2TextTransformer().transform_documents(AsyncHtmlLoader(url).load())

# Let's take a quick peek again to see what do we have now
print("\n\nIncluded metadata:\n", textwrap.fill(json.dumps(docs[0].metadata), width=100), "\n\n")
print("Page content loaded:")
print('...', textwrap.fill(docs[0].page_content[2500:3000], width=100, replace_whitespace=False), '...')
```

ä»¥ä¸‹æ˜¯è¿è¡Œä»£ç åœ¨Google Colabä¸Šç”Ÿæˆçš„å†…å®¹ï¼š

![](../Images/de6416c74c20602de4edbb11a39d23f5.png)

æ‰§è¡Œä¸Šè¿°ä»£ç çš„ç»“æœã€‚ç½‘ç«™å†…å®¹è¢«åŠ è½½åˆ°Colabç¯å¢ƒä¸­ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

**1.2\. å°†æ–‡æ¡£åˆ†è§£ä¸ºè¾ƒå°çš„æ‘˜å½•** åœ¨æˆ‘ä»¬å°†åšå®¢çš„ä¿¡æ¯åŠ è½½åˆ°æˆ‘ä»¬çš„çŸ¥è¯†åº“ï¼ˆå³æˆ‘ä»¬é€‰æ‹©çš„æ•°æ®åº“ï¼‰ä¹‹å‰ï¼Œè¿˜æœ‰ä¸€æ­¥ã€‚æ–‡æœ¬ä¸åº”æŒ‰åŸæ ·åŠ è½½åˆ°æ•°æ®åº“ä¸­ã€‚å®ƒåº”é¦–å…ˆåˆ†å‰²æˆè¾ƒå°çš„å—ã€‚è¿™æœ‰å‡ ä¸ªåŸå› ï¼š

1.  å¦‚æœæˆ‘ä»¬çš„æ–‡æœ¬å¤ªé•¿ï¼Œç”±äºè¶…å‡ºæ–‡æœ¬é•¿åº¦é˜ˆå€¼ï¼ˆå³*â€œä¸Šä¸‹æ–‡å¤§å°â€*ï¼‰ï¼Œåˆ™ä¸èƒ½å‘é€ç»™LLMã€‚

1.  è¾ƒé•¿çš„æ–‡æœ¬å¯èƒ½åŒ…å«å¹¿æ³›ä¸”æ¾æ•£ç›¸å…³çš„ä¿¡æ¯ã€‚æˆ‘ä»¬å°†ä¾èµ–LLMæŒ‘é€‰å‡ºç›¸å…³éƒ¨åˆ†â€”â€”è¿™å¯èƒ½ä¸ä¼šæ€»æ˜¯å¦‚é¢„æœŸé‚£æ ·æœ‰æ•ˆã€‚ä½¿ç”¨è¾ƒå°çš„å—ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨æ£€ç´¢æœºåˆ¶æ¥è¯†åˆ«ä»…ç›¸å…³çš„ä¿¡æ¯å¹¶å‘é€ç»™LLMï¼Œå¦‚æˆ‘ä»¬åé¢å°†çœ‹åˆ°çš„ã€‚

1.  LLMå¯¹æ–‡æœ¬çš„å¼€å§‹å’Œç»“æŸéƒ¨åˆ†å…³æ³¨è¾ƒå¼ºï¼Œå› æ­¤è¾ƒé•¿çš„å—å¯èƒ½å¯¼è‡´LLMå¯¹åé¢æ›´å¤šçš„å†…å®¹å…³æ³¨è¾ƒå°‘ï¼ˆç§°ä¸º*â€œåœ¨ä¸­é—´è¿·å¤±â€*ï¼‰ã€‚

æ¯ä¸ªç”¨ä¾‹çš„é€‚å½“å—å¤§å°å°†æ ¹æ®ç”¨ä¾‹çš„å…·ä½“æƒ…å†µè€Œæœ‰æ‰€ä¸åŒï¼ŒåŒ…æ‹¬å†…å®¹ç±»å‹ã€ä½¿ç”¨çš„LLMåŠå…¶ä»–å› ç´ ã€‚æ˜æ™ºçš„åšæ³•æ˜¯å°è¯•ä¸åŒçš„å—å¤§å°å¹¶åœ¨ç¡®å®šè§£å†³æ–¹æ¡ˆä¹‹å‰è¯„ä¼°å“åº”è´¨é‡ã€‚åœ¨æœ¬æ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åˆ†å—ï¼Œå…¶ä¸­ä¹¦å•ä¸­çš„æ¯ä¸ªä¹¦ç±æ¨èéƒ½æœ‰è‡ªå·±çš„å—ã€‚

```py
# Now we split the entire content of the website into smaller chunks
# Each book review will get its own chunk since we are splitting by headings
# The LangChain splitter used here will also create a set of metadata from headings and associate it with the text in each chunk
headers_to_split_on = [ ("#", "Header 1"), ("##", "Header 2"),
    ("###", "Header 3"), ("####", "Header 4"), ("#####", "Header 5") ]
splitter = MarkdownHeaderTextSplitter(headers_to_split_on = headers_to_split_on)
chunks = splitter.split_text(docs[0].page_content)

print(f"{len(chunks)} smaller chunks generated from original document")

# Let's look at one of the chunks
print("\nLooking at a sample chunk:")
print("Included metadata:\n", textwrap.fill(json.dumps(chunks[5].metadata), width=100), "\n\n")
print("Page content loaded:")
print(textwrap.fill(chunks[5].page_content[:500], width=100, drop_whitespace=False), '...')
```

![](../Images/ca21a3be9e3be635cf3f4fdb21f09bd4.png)

åŸå§‹å†…å®¹æ‹†åˆ†åçš„ä¼—å¤šæ–‡æ¡£å—ä¹‹ä¸€ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

è¯·æ³¨æ„ï¼Œå¦‚æœè¿„ä»Šä¸ºæ­¢åˆ›å»ºçš„æ–‡æœ¬å—ä»ç„¶æ¯”æ‰€éœ€çš„é•¿åº¦é•¿ï¼Œå¯ä»¥ä½¿ç”¨å…¶ä»–æ–‡æœ¬æ‹†åˆ†ç®—æ³•è¿›ä¸€æ­¥æ‹†åˆ†ï¼Œè¿™äº›ç®—æ³•å¯ä»¥é€šè¿‡ LangChain æˆ– LlamaIndex è½»æ¾è·å¾—ã€‚ä¾‹å¦‚ï¼Œæ¯æœ¬ä¹¦çš„è¯„è®ºå¯ä»¥æ ¹æ®éœ€è¦æ‹†åˆ†ä¸ºæ®µè½ã€‚

**1.3\. å°†æ‘˜å½•åŠ è½½åˆ°çŸ¥è¯†åº“** æ–‡æœ¬å—ç°åœ¨å‡†å¤‡å¥½åŠ è½½åˆ°çŸ¥è¯†åº“ä¸­ã€‚è¿™äº›æ–‡æœ¬å—é¦–å…ˆé€šè¿‡åµŒå…¥æ¨¡å‹è½¬æ¢ä¸ºä¸€ç³»åˆ—æ•æ‰æ–‡æœ¬æ„ä¹‰çš„æ•°å­—ã€‚ç„¶åï¼Œå®é™…çš„æ–‡æœ¬åŠå…¶æ•°å€¼è¡¨ç¤ºï¼ˆå³åµŒå…¥ï¼‰å°†åŠ è½½åˆ°å‘é‡æ•°æ®åº“â€”â€”æˆ‘ä»¬çš„çŸ¥è¯†åº“ä¸­ã€‚è¯·æ³¨æ„ï¼ŒåµŒå…¥ä¹Ÿç”±å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆï¼Œåªæ˜¯ä¸èŠå¤© LLM çš„ç±»å‹ä¸åŒã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äºåµŒå…¥çš„å†…å®¹ï¼Œ[ä¸Šä¸€ç¯‡æ–‡ç« ](/how-genai-solutions-revolutionize-business-automation-57747b0f11ce)é€šè¿‡ç¤ºä¾‹å±•ç¤ºäº†è¿™ä¸€æ¦‚å¿µã€‚

æˆ‘ä»¬å°†ä½¿ç”¨å‘é‡æ•°æ®åº“æ¥å­˜å‚¨æ‰€æœ‰ä¿¡æ¯ã€‚è¿™å°†å®ç°æˆ‘ä»¬çš„çŸ¥è¯†åº“ã€‚å‘é‡æ•°æ®åº“æ˜¯ä¸“é—¨è®¾è®¡ç”¨äºé€šè¿‡åµŒå…¥ç›¸ä¼¼æ€§è¿›è¡Œæœç´¢çš„ã€‚å¦‚æœæˆ‘ä»¬æƒ³ä»æ•°æ®åº“ä¸­æœç´¢æŸäº›å†…å®¹ï¼Œæœç´¢è¯é¦–å…ˆé€šè¿‡åµŒå…¥æ¨¡å‹è½¬æ¢ä¸ºæ•°å€¼è¡¨ç¤ºï¼Œç„¶åå°†é—®é¢˜çš„åµŒå…¥ä¸æ•°æ®åº“ä¸­çš„æ‰€æœ‰åµŒå…¥è¿›è¡Œæ¯”è¾ƒã€‚ä¸é—®é¢˜åµŒå…¥æœ€æ¥è¿‘çš„è®°å½•ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå°±æ˜¯å…³äºæ¯æœ¬ä¹¦çš„æ–‡æœ¬å—ï¼‰ä½œä¸ºæœç´¢ç»“æœè¿”å›ï¼Œåªè¦å®ƒä»¬è¶…è¿‡äº†ä¸€ä¸ªé˜ˆå€¼ã€‚

```py
# We will get embeddings for each chunk (and subsequently questions) using an embeddings model from OpenAI
openai_embedding_func = embedding_functions.OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY)

# Initialize vector DB and create a collection
persistent_chroma_client = chromadb.PersistentClient()
collection = persistent_chroma_client.get_or_create_collection("my_rag_demo_collection", embedding_function=openai_embedding_func)
cur_max_id = collection.count() # To not overwrite existing data

# Let's add data to our collection in the vector DB
collection.add(
    ids=[str(t) for t in range(cur_max_id+1, cur_max_id+len(chunks)+1)],
    documents=[t.page_content for t in chunks],
    metadatas=[None if len(t.metadata) == 0 else t.metadata for t in chunks]
    )

print(f"{collection.count()} documents in vector DB")
#  25 documents in vector DB

# Optional: We will write a scrappy helper function to print data slightly better -
#  it limits the length embeddings shown on the screen (since these are over a 1,000 long numbers).
#  Also shows a subset of text from documents as well as metadatas fields
def render_vectorDB_content(chromadb_collection):
    vectordb_data = pd.DataFrame(chromadb_collection.get(include=["embeddings", "metadatas", "documents"]))
    return pd.DataFrame({'IDs': [str(t) if len(str(t)) <= 10 else str(t)[:10] + '...'for t in vectordb_data.ids],
                         'Embeddings': [str(t)[:27] + '...' for t in vectordb_data.embeddings],
                         'Documents': [str(t) if len(str(t)) <= 300 else str(t)[:300] + '...' for t in vectordb_data.documents],
                         'Metadatas': ['' if not t else json.dumps(t) if len(json.dumps(t))  <= 90 else '...' + json.dumps(t)[-90:] for t in vectordb_data.metadatas]
                        })

# Let's take a look at what is in the vector DB using our helper function. We will look at the first 4 chunks
render_vectorDB_content(collection)[:4]
```

![](../Images/06255fabddafae0036919bdeaa6d2fdf.png)

åŠ è½½åˆ°å‘é‡æ•°æ®åº“ä¸­çš„å‰å‡ ä¸ªæ–‡æœ¬å—åŠå…¶æ•°å€¼è¡¨ç¤ºï¼ˆå³åµŒå…¥ï¼‰çš„è§†å›¾ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

## 2\. æœç´¢é—®é¢˜ç›¸å…³çš„ä¸Šä¸‹æ–‡

æˆ‘ä»¬çš„ç»ˆæç›®æ ‡æ˜¯è®©æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆä»å‘é‡æ•°æ®åº“çŸ¥è¯†åº“ä¸­æŒ‘é€‰ç›¸å…³ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä¸æˆ‘ä»¬å¸Œæœ› LLM å›ç­”çš„é—®é¢˜ä¸€èµ·ä¼ é€’ç»™ LLMã€‚è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹å‘é‡æ•°æ®åº“æœç´¢ï¼Œè¯¢é—®é—®é¢˜â€œä½ èƒ½æ¨èå‡ æœ¬ä¾¦æ¢å°è¯´å—ï¼Ÿâ€

```py
# Here we are linking to the previously created an instance of the ChromaDB database using a LangChain ChromaDB client
vectordb = Chroma(client=persistent_chroma_client, collection_name="my_rag_demo_collection", 
                  embedding_function=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
                  )

# Optional - We will define another scrappy helper function to print data slightly better
def render_source_documents(source_documents):
    return pd.DataFrame({'#': range(1, len(source_documents) + 1), 
                         'Documents': [t.page_content if len(t.page_content) <= 300 else t.page_content[:300] + '...' for t in source_documents],
                         'Metadatas': ['' if not t else '...' + json.dumps(t.metadata, indent=2)[-88:] for t in source_documents]
                         })

# Here's where we are compiling the question
question = "Can you recommend a few detective novels?"

# Running the search against the vector DB based on our question
relevant_chunks = vectordb.similarity_search(question)

# Printing results
print(f"Top {len(relevant_chunks)} search results")
render_source_documents(relevant_chunks)
```

![](../Images/15bebbaf8b218ae61b888fe54953a1f3.png)

é—®é¢˜â€œä½ èƒ½æ¨èå‡ æœ¬ä¾¦æ¢å°è¯´å—ï¼Ÿâ€çš„æœç´¢ç»“æœå‰ 4 åï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¾—åˆ°å‰ 4 ä¸ªç»“æœï¼Œé™¤éæˆ‘ä»¬æ˜ç¡®è®¾ç½®ä¸åŒçš„å€¼ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæ’åç¬¬ä¸€çš„ç»“æœæ˜¯ä¸€æœ¬ç¦å°”æ‘©æ–¯å°è¯´ï¼Œç›´æ¥æåˆ°äº†â€œä¾¦æ¢â€ä¸€è¯ã€‚ç¬¬äºŒä¸ªç»“æœï¼ˆ*ã€Šæ°å…‹å°”çš„æ—¥å­ã€‹*ï¼‰è™½ç„¶æ²¡æœ‰â€œä¾¦æ¢â€ä¸€è¯ï¼Œä½†æåˆ°äº†â€œè­¦å¯Ÿæœºæ„â€å’Œâ€œæ­éœ²é˜´è°‹â€ï¼Œè¿™äº›ä¸â€œä¾¦æ¢å°è¯´â€åœ¨è¯­ä¹‰ä¸Šç›¸å…³ã€‚ç¬¬ä¸‰ä¸ªç»“æœï¼ˆ*ã€Šå§åº•ç»æµå­¦å®¶ã€‹*ï¼‰æåˆ°äº†â€œå§åº•â€ä¸€è¯ï¼Œå°½ç®¡å®ƒæ˜¯å…³äºç»æµå­¦çš„ã€‚æˆ‘è®¤ä¸ºæœ€åä¸€ä¸ªç»“æœè¢«è·å–æ˜¯å› ä¸ºå®ƒä¸å°è¯´/ä¹¦ç±æœ‰å…³ï¼Œè€Œä¸æ˜¯ç‰¹å®šçš„â€œä¾¦æ¢å°è¯´â€ï¼Œå› ä¸ºè¯·æ±‚äº†å››ä¸ªç»“æœã€‚

åŒæ ·ï¼Œä½¿ç”¨å‘é‡æ•°æ®åº“å¹¶ä¸æ˜¯ç»å¯¹å¿…è¦çš„ã€‚æ‚¨å¯ä»¥åŠ è½½åµŒå…¥å¹¶åœ¨å…¶ä»–å­˜å‚¨å½¢å¼ä¸­è¿›è¡Œæœç´¢ã€‚â€œæ™®é€šâ€å…³ç³»æ•°æ®åº“ç”šè‡³ Excel éƒ½å¯ä»¥ä½¿ç”¨ã€‚ä½†æ‚¨éœ€è¦åœ¨åº”ç”¨ç¨‹åºé€»è¾‘ä¸­å¤„ç†â€œç›¸ä¼¼æ€§â€è®¡ç®—ï¼Œå½“ä½¿ç”¨ OpenAI åµŒå…¥æ—¶ï¼Œè¿™å¯ä»¥æ˜¯ç‚¹ç§¯ã€‚å¦ä¸€æ–¹é¢ï¼Œå‘é‡æ•°æ®åº“ä¸ºæ‚¨å¤„ç†äº†è¿™äº›ã€‚

è¯·æ³¨æ„ï¼Œå¦‚æœæˆ‘ä»¬æƒ³é€šè¿‡å…ƒæ•°æ®é¢„ç­›é€‰ä¸€äº›æœç´¢ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·åšã€‚ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†æ ¹æ®å…ƒæ•°æ®ä¸­ä»ä¹¦å•åŠ è½½çš„â€œHeader 2â€è¿‡æ»¤ã€‚

```py
# Let's try filtering and accessing records that match a specific metadata filter. This can probably be transformed into a pre-filter if needed
pd.DataFrame(vectordb.get(where = {'Header 2': 'Finance'}))
```

![](../Images/3e7381e8da847e76b51f202714d7e319.png)

åŸºäºåº”ç”¨å…ƒæ•°æ®é¢„ç­›é€‰çš„æœç´¢ç»“æœï¼Œä»…æ˜¾ç¤ºå…³é”®åˆ—ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰

LLM æä¾›äº†ä¸€ä¸ªæœ‰è¶£çš„æœºä¼šï¼Œå³åˆ©ç”¨ LLM æœ¬èº«æ¥æ£€æŸ¥ç”¨æˆ·é—®é¢˜ï¼Œå®¡æŸ¥å¯ç”¨çš„å…ƒæ•°æ®ï¼Œè¯„ä¼°æ˜¯å¦éœ€è¦å’Œå¯èƒ½è¿›è¡ŒåŸºäºå…ƒæ•°æ®çš„é¢„ç­›é€‰ï¼Œå¹¶åˆ¶å®šé¢„ç­›é€‰æŸ¥è¯¢ä»£ç ï¼Œè¿™äº›ä»£ç å¯ä»¥åœ¨å‘é‡æ•°æ®åº“ä¸Šå®é™…é¢„ç­›é€‰æ•°æ®ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ LangChain çš„ [è‡ªæŸ¥è¯¢æ£€ç´¢å™¨](https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/)ã€‚

## 3\. ä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆ

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å‘ LLM æ·»åŠ æŒ‡ä»¤ï¼ŒåŸºæœ¬ä¸Šæ˜¯è¯´â€œæˆ‘å°†ç»™ä½ ä¸€äº›ä¿¡æ¯ç‰‡æ®µå’Œä¸€ä¸ªé—®é¢˜ã€‚è¯·ä½¿ç”¨æä¾›çš„ä¿¡æ¯ç‰‡æ®µå›ç­”é—®é¢˜â€ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›æŒ‡ä»¤ã€å‘é‡æ•°æ®åº“ä¸­çš„æœç´¢ç»“æœå’Œæˆ‘ä»¬çš„é—®é¢˜æ‰“åŒ…ï¼Œå¹¶å‘é€ç»™ LLM è¿›è¡Œå›åº”ã€‚æ‰€æœ‰è¿™äº›æ­¥éª¤éƒ½ç”±ä»¥ä¸‹ä»£ç å®Œæˆã€‚

è¯·æ³¨æ„ï¼ŒLangChain æä¾›äº†æŠ½è±¡ä¸€äº›ä»£ç çš„æœºä¼šï¼Œå› æ­¤æ‚¨çš„ä»£ç ä¸å¿…åƒä»¥ä¸‹ä»£ç é‚£æ ·å†—é•¿ã€‚ç„¶è€Œï¼Œä»¥ä¸‹ä»£ç çš„ç›®çš„æ˜¯å±•ç¤ºå‘é€åˆ°è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤ã€‚è¿™é‡Œä¹Ÿæ˜¯è‡ªå®šä¹‰è¿™äº›æŒ‡ä»¤çš„åœ°æ–¹â€”â€”ä¾‹å¦‚ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé»˜è®¤æŒ‡ä»¤è¢«æ›´æ”¹ä¸ºè¯·æ±‚ LLM å°½å¯èƒ½ç®€æ´åœ°å›åº”ã€‚å¦‚æœé»˜è®¤è®¾ç½®é€‚ç”¨äºæ‚¨çš„ç”¨ä¾‹ï¼Œæ‚¨çš„ä»£ç å¯ä»¥å®Œå…¨è·³è¿‡é—®é¢˜æ¨¡æ¿éƒ¨åˆ†ï¼ŒLangChain ä¼šåœ¨å‘ LLM å‘é€è¯·æ±‚æ—¶ä½¿ç”¨å…¶åŒ…ä¸­çš„é»˜è®¤æç¤ºã€‚

```py
# Let's select the language model behind free version of ChatGPT: GPT-3.5-turbo
llm = ChatOpenAI(model_name = 'gpt-3.5-turbo', temperature = 0, openai_api_key = OPENAI_API_KEY)

# Let's build a prompt. This is what actually gets sent to the ChatGPT LLM, with the context from our vector database and question injected into the prompt
template = """Use the following pieces of context to answer the question at the end. 
If you don't know the answer, just say that the available information is not sufficient to answer the question. 
Don't try to make up an answer. Keep the answer as concise as possible, limited to five sentences.
{context}
Question: {question}
Helpful Answer:"""
QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

# Define a Retrieval QA chain, which will take the question, get the relevant context from the vectorDB, and pass both to the language model for a response
qa_chain = RetrievalQA.from_chain_type(llm, 
                                       retriever=vectordb.as_retriever(),
                                       return_source_documents=True,
                                       chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
                                       )
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å†æ¬¡è¯·æ±‚ä¾¦æ¢å°è¯´çš„æ¨èï¼Œçœ‹çœ‹æˆ‘ä»¬ä¼šå¾—åˆ°ä»€ä¹ˆå›åº”ã€‚

```py
# Let's ask a question and run our question-answering chain
question = "Can you recommend a few detective novels?"

result = qa_chain({"query": question})

# Let's look at the result
result["result"]
```

![](../Images/546144d38d406b1c88712edd0333f838.png)

æ¨èä¾¦æ¢å°è¯´çš„è§£å†³æ–¹æ¡ˆå›åº”ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰

è®©æˆ‘ä»¬ç¡®è®¤æ¨¡å‹æ˜¯å¦å›é¡¾äº†æˆ‘ä»¬ä»å‘é‡æ•°æ®åº“ä¸­è·å¾—çš„æ‰€æœ‰å››ä¸ªæœç´¢ç»“æœï¼Œè¿˜æ˜¯ä»…ä»…è·å–äº†å“åº”ä¸­æåˆ°çš„ä¸¤ä¸ªç»“æœï¼Ÿ

```py
# Let's look at the source documents used as context by the LLM
# We will use our helper function from before to limit the size of the information shown
render_source_documents(result["source_documents"])
```

![](../Images/5f951dd421f7adbca2edefd17e925e95.png)

ä¸é—®é¢˜ä¸€èµ·ä¼ é€’ç»™ LLM çš„ä¸Šä¸‹æ–‡ï¼Œä»¥ä¾¿äºå“åº”ã€‚ï¼ˆå›¾åƒç”±ä½œè€…æä¾›ï¼‰

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒLLM ä»ç„¶è®¿é—®äº†æ‰€æœ‰å››ä¸ªæœç´¢ç»“æœï¼Œå¹¶æ¨æ–­å‡ºåªæœ‰å‰ä¸¤æœ¬ä¹¦æ˜¯ä¾¦æ¢å°è¯´ã€‚

è¯·æ³¨æ„ï¼ŒLLM çš„å“åº”æ¯æ¬¡æé—®æ—¶å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒï¼Œå°½ç®¡å‘é€çš„æ˜¯ç›¸åŒçš„æŒ‡ä»¤å’Œæ¥è‡ªå‘é‡æ•°æ®åº“çš„ç›¸åŒä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œåœ¨è¯¢é—®å…³äºå¥‡å¹»ä¹¦ç±æ¨èæ—¶ï¼ŒLLM æœ‰æ—¶ç»™å‡ºä¸‰æœ¬ä¹¦ç±æ¨èï¼Œæœ‰æ—¶åˆ™æ›´å¤šâ€”â€”å°½ç®¡éƒ½æ˜¯æ¥è‡ªä¹¦å•ã€‚åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæœ€æ¨èçš„ä¹¦ç±ä¿æŒä¸å˜ã€‚è¯·æ³¨æ„ï¼Œè¿™äº›å˜åŒ–å‘ç”Ÿåœ¨å°†ä¸€è‡´æ€§â€”â€”åˆ›é€ åŠ›è°±â€”â€”å³â€œæ¸©åº¦â€å‚æ•°é…ç½®ä¸º 0 ä»¥æœ€å°åŒ–å·®å¼‚çš„æƒ…å†µä¸‹ã€‚

## 4\. æ·»åŠ â€œèŠå¤©â€åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰

ç°åœ¨ï¼Œè§£å†³æ–¹æ¡ˆå…·å¤‡äº†å¿…è¦çš„æ ¸å¿ƒåŠŸèƒ½â€”â€”å®ƒèƒ½å¤Ÿä»ç½‘ç«™ä¸­è¯»å–ä¿¡æ¯å¹¶æ ¹æ®è¿™äº›ä¿¡æ¯å›ç­”é—®é¢˜ã€‚ä½†ç›®å‰å®ƒå¹¶æœªæä¾›â€œå¯¹è¯å¼â€çš„ç”¨æˆ·ä½“éªŒã€‚æ„Ÿè°¢ ChatGPTï¼Œâ€œèŠå¤©ç•Œé¢â€å·²æˆä¸ºä¸»æµè®¾è®¡ï¼šæˆ‘ä»¬ç°åœ¨æœŸæœ›è¿™æˆä¸ºä¸ç”Ÿæˆå¼ AI å°¤å…¶æ˜¯ LLM äº’åŠ¨çš„â€œè‡ªç„¶â€æ–¹å¼ ğŸ˜…ã€‚å®ç°èŠå¤©ç•Œé¢çš„ç¬¬ä¸€æ­¥æ¶‰åŠå‘è§£å†³æ–¹æ¡ˆä¸­æ·»åŠ â€œå†…å­˜â€ã€‚

è¿™é‡Œçš„â€œå†…å­˜â€æ˜¯ä¸€ç§å‡è±¡ï¼ŒLLM å®é™…ä¸Šå¹¶ä¸è®°ä½åˆ°ç›®å‰ä¸ºæ­¢çš„å¯¹è¯â€”â€”å®ƒéœ€è¦åœ¨æ¯æ¬¡å›åˆä¸­å±•ç¤ºå®Œæ•´çš„å¯¹è¯è®°å½•ã€‚å› æ­¤ï¼Œå¦‚æœç”¨æˆ·å‘ LLM æé—®åç»­é—®é¢˜ï¼Œè§£å†³æ–¹æ¡ˆå°†æ‰“åŒ…åŸå§‹é—®é¢˜ã€LLM çš„åŸå§‹ç­”æ¡ˆä»¥åŠåç»­é—®é¢˜ï¼Œå¹¶å°†å…¶å‘é€ç»™ LLMã€‚LLM é˜…è¯»æ•´ä¸ªå¯¹è¯å¹¶ç”Ÿæˆæœ‰æ„ä¹‰çš„å“åº”ä»¥ç»§ç»­å¯¹è¯ã€‚

åœ¨é—®ç­”èŠå¤©æœºå™¨äººä¸­ï¼Œå¦‚æˆ‘ä»¬æ­£åœ¨æ„å»ºçš„è¿™ä¸ªï¼Œé€šå¸¸éœ€è¦è¿›ä¸€æ­¥æ‰©å±•æ­¤æ–¹æ³•ï¼Œå› ä¸ºå­˜åœ¨ä¸­é—´æ­¥éª¤éœ€è¦ä»å‘é‡æ•°æ®åº“ä¸­æå–ç›¸å…³ä¿¡æ¯ä»¥åˆ¶å®šå¯¹ç”¨æˆ·åç»­é—®é¢˜çš„å“åº”ã€‚åœ¨é—®ç­”èŠå¤©æœºå™¨äººä¸­ï¼Œâ€œå†…å­˜â€æ˜¯è¿™æ ·æ¨¡æ‹Ÿçš„ï¼š

1.  å°†æ‰€æœ‰é—®é¢˜å’Œå“åº”ä¿ç•™ï¼ˆåœ¨ä¸€ä¸ªå˜é‡ä¸­ï¼‰ä½œä¸ºâ€œèŠå¤©è®°å½•â€

1.  å½“ç”¨æˆ·æé—®æ—¶ï¼Œå°†èŠå¤©è®°å½•å’Œæ–°é—®é¢˜å‘é€ç»™ LLMï¼Œå¹¶è¦æ±‚ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹çš„é—®é¢˜

1.  æ­¤æ—¶ï¼ŒèŠå¤©è®°å½•ä¸å†éœ€è¦ã€‚ä½¿ç”¨ç‹¬ç«‹çš„é—®é¢˜åœ¨å‘é‡æ•°æ®åº“ä¸Šè¿›è¡Œæ–°çš„æœç´¢

1.  å°†ç‹¬ç«‹é—®é¢˜å’Œæœç´¢ç»“æœä¼ é€’ç»™ LLMï¼Œå¹¶é™„ä¸ŠæŒ‡ä»¤ä»¥è·å¾—æœ€ç»ˆç­”æ¡ˆã€‚è¿™ä¸ªæ­¥éª¤ç±»ä¼¼äºæˆ‘ä»¬åœ¨ä¹‹å‰é˜¶æ®µâ€œä½¿ç”¨ LLM ç”Ÿæˆç­”æ¡ˆâ€ä¸­å®æ–½çš„æ­¥éª¤

è™½ç„¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç®€å•çš„å˜é‡æ¥è·Ÿè¸ªèŠå¤©è®°å½•ï¼Œä½†æˆ‘ä»¬å°†ä½¿ç”¨ LangChain çš„ä¸€ç§å†…å­˜ç±»å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨çš„ç‰¹å®šå†…å­˜å¯¹è±¡æä¾›äº†ä¸€ä¸ªå¾ˆå¥½çš„åŠŸèƒ½ï¼Œå³åœ¨è¾¾åˆ°ä½ æŒ‡å®šçš„å¤§å°é™åˆ¶æ—¶è‡ªåŠ¨æˆªæ–­è¾ƒæ—§çš„èŠå¤©è®°å½•ï¼Œé€šå¸¸æ˜¯é€‰å®š LLM å¯ä»¥æ¥å—çš„æ–‡æœ¬å¤§å°ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼ŒLLM åº”è¯¥èƒ½å¤Ÿæ¥å—ç•¥è¶…è¿‡ 4,000 ä¸ªâ€œtokensâ€ï¼ˆå³è¯æ±‡éƒ¨åˆ†ï¼‰ï¼Œè¿™å¤§çº¦æ˜¯ 3,000 ä¸ªå•è¯æˆ– ~5 é¡µçš„ Word æ–‡æ¡£ã€‚OpenAI æä¾›äº†ç›¸åŒ ChatGPT LLM çš„ 16k å˜ä½“ï¼Œå¯ä»¥æ¥å— 4 å€çš„è¾“å…¥ã€‚å› æ­¤ï¼Œéœ€è¦é…ç½®å†…å­˜å¤§å°ã€‚

è¿™æ˜¯å®ç°è¿™äº›æ­¥éª¤çš„ä»£ç ã€‚åŒæ ·ï¼ŒLangChainæä¾›äº†æ›´é«˜å±‚æ¬¡çš„æŠ½è±¡ï¼Œä»£ç ä¸å¿…å¦‚æ­¤æ˜ç¡®ã€‚è¿™ä¸ªç‰ˆæœ¬åªæ˜¯ä¸ºäº†å±•ç¤ºå‘é€åˆ°LLMçš„åº•å±‚æŒ‡ä»¤â€”â€”é¦–å…ˆå°†èŠå¤©è®°å½•æµ“ç¼©æˆä¸€ä¸ªç‹¬ç«‹çš„å•ä¸€é—®é¢˜ï¼Œç„¶åç”¨äºå‘é‡æ•°æ®åº“æœç´¢ï¼Œå…¶æ¬¡æ ¹æ®å‘é‡æ•°æ®åº“æœç´¢ç»“æœç”Ÿæˆå¯¹ç”Ÿæˆçš„ç‹¬ç«‹é—®é¢˜çš„å“åº”ã€‚

```py
# Let's create a memory object to track chat history. This will start accumulating human messages and AI responses.
# Here a "token" based memory is used to restrict the length of chat history to what can be passed into the selected LLM. 
# Generally, the maximum token length configured will depend on the LLM. Assuming we are using the 4K version of the LLM, 
#  we will set the token maximum to 3K, to allow some room for the question prompt.
#  The LLM parameter is to make LangChain aware of the tokenization scheme of the selected LLM. 
memory = ConversationTokenBufferMemory(memory_key="chat_history", return_messages=True, input_key="question", output_key="answer", max_token_limit=3000, llm=llm)

# While LangChain includes a default prompt to generate a standalone question based on the users' latest question and
# any context from the conversation up to that point, we will extend the default prompt with additional instructions.
standalone_question_generator_template = """Given the following conversation and a follow up question, 
rephrase the follow up question to be a standalone question, in its original language.
Be as explicit as possible in formulating the standalone question, and 
include any context necessary to clarify the standalone question.

Conversation:
{chat_history}
Follow Up Question: {question}
Standalone question:"""
updated_condense_question_prompt = PromptTemplate.from_template(standalone_question_generator_template)

# Let's rebuild the final prompt (again, optional since LangChain uses a default prompt, though it might be a little different)
final_response_synthesizer_template = """Use the following pieces of context to answer the question at the end. 
If you don't know the answer, just say that the available information is not sufficient to answer the question. 
Don't try to make up an answer. Keep the answer as concise as possible, limited to five sentences.
{context}
Question: {question}
Helpful Answer:"""
custom_final_prompt = PromptTemplate.from_template(final_response_synthesizer_template)

qa = ConversationalRetrievalChain.from_llm(
    llm=llm, 
    retriever=vectordb.as_retriever(), 
    memory=memory,
    return_source_documents=True,
    return_generated_question=True,
    condense_question_prompt= updated_condense_question_prompt,
    combine_docs_chain_kwargs={"prompt": custom_final_prompt})

# Let's again ask the question we previously asked the retrieval QA chain
query = "Can you recommend a few detective novels?"
result = qa({"question": query})
print(textwrap.fill(result['answer'], width=100))
```

![](../Images/e472c9c36dc137b348e73db60cfafa78.png)

è§£å†³æ–¹æ¡ˆçš„ä¾¦æ¢å°è¯´æ¨èã€‚ä¸ä¹‹å‰ä»…ä½¿ç”¨â€œé—®ç­”â€èƒ½åŠ›è€Œæ²¡æœ‰â€œè®°å¿†â€æ—¶æ”¶åˆ°çš„å“åº”ç›¸åŒï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

è®©æˆ‘ä»¬æå‡ºä¸€ä¸ªåç»­é—®é¢˜ï¼Œå¹¶æŸ¥çœ‹å“åº”ä»¥éªŒè¯è§£å†³æ–¹æ¡ˆç°åœ¨å…·æœ‰â€œè®°å¿†â€å¹¶ä¸”å¯ä»¥å¯¹åç»­é—®é¢˜è¿›è¡Œå¯¹è¯å¼å›ç­”ï¼š

```py
query = "Tell me more about the second book"
result = qa({"question": query})
print(textwrap.fill(result['answer'], width=100))
```

![](../Images/fed2232a1253700a345d4e1bb406e967.png)

å¯¹â€œç¬¬äºŒæœ¬ä¹¦â€çš„æ›´å¤šä¿¡æ¯çš„åç»­é—®é¢˜çš„å“åº”ã€‚è§£å†³æ–¹æ¡ˆè¿”å›æ›´å¤šå…³äºåŒä¸€æœ¬ä¹¦çš„ä¿¡æ¯ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

è®©æˆ‘ä»¬çœ‹çœ‹åœ¨å¼•æ“ç›–ä¸‹å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä»¥éªŒè¯è§£å†³æ–¹æ¡ˆç¡®å®ç»è¿‡äº†æœ¬èŠ‚å¼€å¤´æ¦‚è¿°çš„å››ä¸ªæ­¥éª¤ã€‚è®©æˆ‘ä»¬ä»èŠå¤©è®°å½•å¼€å§‹ï¼Œä»¥éªŒè¯è§£å†³æ–¹æ¡ˆç¡®å®è®°å½•äº†åˆ°ç›®å‰ä¸ºæ­¢çš„å¯¹è¯ï¼š

```py
# Let's look at chat history upto this point
result['chat_history']
```

![](../Images/5eb9194b5133cbb28fd5070319810bf1.png)

æé—®ç¬¬äºŒä¸ªé—®é¢˜åçš„èŠå¤©è®°å½•ã€‚æ³¨æ„æ­¤æ—¶å“åº”ä¹ŸåŒ…æ‹¬åœ¨å¯¹è¯ä¸­ã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

è®©æˆ‘ä»¬çœ‹çœ‹è§£å†³æ–¹æ¡ˆé™¤äº†èŠå¤©è®°å½•å¤–è¿˜è·Ÿè¸ªäº†ä»€ä¹ˆï¼š

```py
# Let's print the other parts of the results
print("Here is the standalone question generated by the LLM based on chat history:")
print(textwrap.fill(result['generated_question'], width=100 ))
print("\nHere are the source documents the model referenced:")
display(render_source_documents(result['source_documents']))
print(textwrap.fill(f"\nGenerated Answer: {result['answer']}", width=100, replace_whitespace=False) )
```

![](../Images/396886e2b0b33096284054126381fe35.png)

æé—®ç¬¬äºŒä¸ªé—®é¢˜åï¼Œé™¤èŠå¤©è®°å½•ä¹‹å¤–çš„è¾“å‡ºã€‚ï¼ˆå›¾ç‰‡ç”±ä½œè€…æä¾›ï¼‰

è§£å†³æ–¹æ¡ˆå†…éƒ¨ä½¿ç”¨LLMå°†é—®é¢˜*â€œå‘Šè¯‰æˆ‘æ›´å¤šå…³äºç¬¬äºŒæœ¬ä¹¦çš„äº‹â€*è½¬æ¢ä¸º*â€œä½ èƒ½æä¾›æ›´å¤šå…³äºå¼—é›·å¾·é‡Œå…‹Â·ç¦èµ›æ–¯çš„ã€Šè´¼æ—¥ã€‹â€˜The Day of the Jackalâ€™çš„ä¿¡æ¯å—ï¼Ÿâ€*ã€‚æœ‰äº†è¿™ä¸ªé—®é¢˜ï¼Œè§£å†³æ–¹æ¡ˆèƒ½å¤Ÿåœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢ä»»ä½•ç›¸å…³ä¿¡æ¯ï¼Œå¹¶è¿™æ¬¡é¦–å…ˆæ£€ç´¢åˆ°ã€Šè´¼æ—¥ã€‹çš„ä¿¡æ¯ã€‚è™½ç„¶æ³¨æ„åˆ°ä¹ŸåŒ…æ‹¬äº†ä¸€äº›å…³äºå…¶ä»–ä¹¦ç±çš„æ— å…³æœç´¢ç»“æœã€‚

## å¿«é€Ÿçš„å¯é€‰ä¾§è¾¹æ è®¨è®ºæ½œåœ¨é—®é¢˜

**æ½œåœ¨é—®é¢˜ #1 â€” ç‹¬ç«‹é—®é¢˜ç”Ÿæˆä¸ä½³ï¼š** åœ¨æˆ‘çš„æµ‹è¯•ä¸­ï¼ŒèŠå¤©è§£å†³æ–¹æ¡ˆåœ¨ç”Ÿæˆä¸€ä¸ªå¥½çš„ç‹¬ç«‹é—®é¢˜æ—¶å¹¶ä¸æ€»æ˜¯æˆåŠŸï¼Œç›´åˆ°è°ƒæ•´äº†é—®é¢˜ç”Ÿæˆå™¨æç¤ºã€‚ä¾‹å¦‚ï¼Œå¯¹äºä¸€ä¸ªåç»­é—®é¢˜ï¼Œâ€œå‘Šè¯‰æˆ‘å…³äºç¬¬äºŒæœ¬ä¹¦çš„äº‹â€ï¼Œç”Ÿæˆçš„åç»­é—®é¢˜å¾€å¾€æ˜¯â€œä½ èƒ½å‘Šè¯‰æˆ‘å…³äºç¬¬äºŒæœ¬ä¹¦çš„ä»€ä¹ˆï¼Ÿâ€è¿™æœ¬èº«å¹¶æ²¡æœ‰ç‰¹åˆ«çš„æ„ä¹‰ï¼Œå¹¶å¯¼è‡´éšæœºçš„æœç´¢ç»“æœï¼Œå› æ­¤LLMçš„ç”Ÿæˆå“åº”çœ‹èµ·æ¥ä¹Ÿæ˜¯éšæœºçš„ã€‚

**æ½œåœ¨é—®é¢˜ #2 â€” åŸå§‹é—®é¢˜ä¸è·Ÿè¿›é—®é¢˜ä¹‹é—´çš„æœç´¢ç»“æœå˜åŒ–ï¼š** å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå³ä½¿ç¬¬äºŒä¸ªç”Ÿæˆçš„é—®é¢˜æ˜ç¡®æåˆ°æ„Ÿå…´è¶£çš„ä¹¦ç±ï¼Œå‘é‡æ•°æ®åº“æœç´¢è¿”å›çš„ç»“æœä¸­ä¹ŸåŒ…æ‹¬å…¶ä»–ä¹¦ç±çš„ç»“æœï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œè¿™äº›æœç´¢ç»“æœä¸åŸå§‹é—®é¢˜çš„ç»“æœä¸åŒï¼åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œè¿™ç§æœç´¢ç»“æœçš„å˜åŒ–æ˜¯æœŸæœ›çš„ï¼Œå› ä¸ºé—®é¢˜ä»â€œä¾¦æ¢å°è¯´æ¨èâ€å˜æˆäº†ç‰¹å®šçš„å°è¯´ã€‚ç„¶è€Œï¼Œå½“ç”¨æˆ·æå‡ºè·Ÿè¿›é—®é¢˜ä»¥æ·±å…¥æ¢è®¨æŸä¸ªä¸»é¢˜æ—¶ï¼Œé—®é¢˜è¡¨è¿°çš„å˜åŒ–æˆ–LLMç”Ÿæˆçš„ç‹¬ç«‹é—®é¢˜å¯èƒ½ä¼šå¯¼è‡´ä¸åŒçš„æœç´¢ç»“æœæˆ–æœç´¢ç»“æœçš„ä¸åŒæ’åºï¼Œè¿™å¯èƒ½*ä¸*æ˜¯æœŸæœ›çš„ã€‚

è¿™ä¸ªé—®é¢˜å¯èƒ½ä¼šåœ¨ä¸€å®šç¨‹åº¦ä¸Šè‡ªåŠ¨å¾—åˆ°ç¼“è§£ï¼Œè‡³å°‘æ˜¯é€šè¿‡å¯¹å‘é‡æ•°æ®åº“è¿›è¡Œæ›´å¹¿æ³›çš„åˆæ­¥æœç´¢â€”â€”è¿”å›æ›´å¤šçš„ç»“æœï¼Œè€Œä¸ä»…ä»…æ˜¯æˆ‘ä»¬ç¤ºä¾‹ä¸­çš„4-5ä¸ªâ€”â€”å¹¶å¯¹ç»“æœè¿›è¡Œé‡æ–°æ’åºï¼Œä»¥ç¡®ä¿æœ€ç›¸å…³çš„ç»“æœä¸Šå‡åˆ°é¡¶éƒ¨å¹¶å§‹ç»ˆå‘é€åˆ°LLMä»¥ç”Ÿæˆæœ€ç»ˆå“åº”ï¼ˆå‚è§[Cohereçš„â€œé‡æ–°æ’åºâ€](https://docs.cohere.com/docs/reranking)ï¼‰ã€‚æ­¤å¤–ï¼Œåº”ç”¨ç¨‹åºåº”ç›¸å¯¹å®¹æ˜“è¯†åˆ«æœç´¢ç»“æœæ˜¯å¦å‘ç”Ÿäº†å˜åŒ–ã€‚å¯èƒ½å¯ä»¥åº”ç”¨ä¸€äº›å¯å‘å¼æ–¹æ³•æ¥åˆ¤æ–­æœç´¢ç»“æœçš„å˜åŒ–ç¨‹åº¦ï¼ˆé€šè¿‡æ’åºå’Œé‡å åº¦é‡ï¼‰ä»¥åŠé—®é¢˜å˜åŒ–çš„ç¨‹åº¦ï¼ˆé€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦ç­‰è·ç¦»åº¦é‡ï¼‰æ˜¯å¦åŒ¹é…ã€‚è‡³å°‘åœ¨æœç´¢ç»“æœåœ¨èŠå¤©è½®æ¬¡ä¸­å‡ºç°æ„å¤–æ³¢åŠ¨çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥æ ¹æ®ç”¨ä¾‹çš„å…³é”®æ€§ä»¥åŠæœ€ç»ˆç”¨æˆ·çš„åŸ¹è®­æˆ–ç´ å…»ï¼Œæé†’æœ€ç»ˆç”¨æˆ·å¹¶è®©ä»–ä»¬å‚ä¸æ›´è¯¦ç»†çš„æ£€æŸ¥ã€‚

æ§åˆ¶è¿™ç§è¡Œä¸ºçš„å¦ä¸€ä¸ªæƒ³æ³•æ˜¯åˆ©ç”¨LLMæ¥å†³å®šè·Ÿè¿›é—®é¢˜æ˜¯å¦éœ€è¦å†æ¬¡è®¿é—®å‘é‡æ•°æ®åº“ï¼Œæˆ–è€…è¿™ä¸ªé—®é¢˜æ˜¯å¦å¯ä»¥ç”¨ä¹‹å‰è·å–çš„ç»“æœæœ‰æ„ä¹‰åœ°å›ç­”ã€‚ä¸€äº›ç”¨ä¾‹å¯èƒ½å¸Œæœ›ç”Ÿæˆä¸¤ç»„æœç´¢ç»“æœå’Œå›ç­”ï¼Œè®©LLMåœ¨ç­”æ¡ˆä¹‹é—´è£å®šï¼Œå¦ä¸€äº›ç”¨ä¾‹å¯èƒ½é€šè¿‡èµ‹äºˆç”¨æˆ·å†»ç»“ä¸Šä¸‹æ–‡çš„èƒ½åŠ›æ¥å°†æ§åˆ¶ä¸Šä¸‹æ–‡çš„è´£ä»»è½¬äº¤ç»™ç”¨æˆ·ï¼ˆè¿™å–å†³äºç”¨ä¾‹ã€ç”¨æˆ·åŸ¹è®­æˆ–ç´ å…»ä»¥åŠå…¶ä»–è€ƒè™‘å› ç´ ï¼‰ï¼Œè¿˜æœ‰ä¸€äº›ç”¨ä¾‹å¯èƒ½å¯¹è·Ÿè¿›é—®é¢˜ä¸­æœç´¢ç»“æœçš„å˜åŒ–æŒå®½å®¹æ€åº¦ã€‚

æ­£å¦‚ä½ å¯èƒ½å·²ç»çœ‹å‡ºï¼Œè·å¾—ä¸€ä¸ªåŸºæœ¬è§£å†³æ–¹æ¡ˆæ˜¯ç›¸å¯¹ç®€å•çš„ï¼Œä½†åšåˆ°å®Œç¾â€”â€”è¿™æ‰æ˜¯éš¾ç‚¹ã€‚è¿™é‡Œæåˆ°çš„é—®é¢˜åªæ˜¯å†°å±±ä¸€è§’ã€‚å¥½äº†ï¼Œå›åˆ°ä¸»è¦ä»»åŠ¡ â€¦

## 5\. æ·»åŠ é¢„ç¼–ç UI

æœ€åï¼ŒèŠå¤©æœºå™¨äººçš„åŠŸèƒ½å·²ç»å‡†å¤‡å¥½ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªæ¼‚äº®çš„ç”¨æˆ·ç•Œé¢ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒã€‚è¿™æ˜¯ï¼ˆæŸç§ç¨‹åº¦ä¸Šï¼‰ç”±äºPythonåº“å¦‚Gradioå’ŒStreamlitï¼Œä½¿å¾—åŸºäºPythonç¼–å†™çš„æŒ‡ä»¤æ„å»ºå‰ç«¯å°éƒ¨ä»¶æˆä¸ºå¯èƒ½ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Gradioå¿«é€Ÿåˆ›å»ºä¸€ä¸ªç”¨æˆ·ç•Œé¢ã€‚

ä»¥ä½¿ä»»ä½•å°šæœªæ‰§è¡Œä»£ç çš„äººèƒ½å¤Ÿè·Ÿä¸Šè¿›åº¦ï¼Œå¹¶æ¼”ç¤ºä¸€äº›è¾¾åˆ°ç›¸åŒç»“æœçš„å˜ä½“ï¼Œä»¥ä¸‹ä¸¤ä¸ªä»£ç å—æ˜¯è‡ªåŒ…å«çš„ï¼Œå¯ä»¥åœ¨å…¨æ–°çš„Colabç¬”è®°æœ¬ä¸­è¿è¡Œï¼Œä»¥ç”Ÿæˆå®Œæ•´çš„èŠå¤©æœºå™¨äººã€‚

```py
# Initial setup - Install necessary software in code environment
!pip install openai tiktoken langchain chromadb html2text gradio   # Uncomment by removing '#' at the beginning if you're starting here and haven't yet installed anything

# Import packages needed to enable different functionality for the solution
from langchain.document_loaders import AsyncHtmlLoader # To load website content into a document
from langchain.text_splitter import MarkdownHeaderTextSplitter # To document into smaller chunks by document headings 
from langchain.document_transformers import Html2TextTransformer # To converrt HTML to Markdown text
from langchain.chat_models import ChatOpenAI # To use OpenAI's LLM
from langchain.prompts import PromptTemplate # To formulate instructions / prompts
from langchain.chains import RetrievalQA, ConversationalRetrievalChain # For RAG
from langchain.memory import ConversationTokenBufferMemory # To maintain chat history
from langchain.embeddings.openai import OpenAIEmbeddings # To convert text to numerical representation
from langchain.vectorstores import Chroma # To interact with vector database
import pandas as pd, gradio as gr # To show data as tables, and to build UI respectively
import chromadb, json, textwrap # Vector database, converting json to text, and prettify printing respectively
from chromadb.utils import embedding_functions # Setting up embedding function, following protocol required by Chroma

# Add the OpenAI API Key to a variable
# Saving the key in a variable like so is bad practice. It should be loaded into environment variables and loaded from there, but this is okay for a quick demo
OPENAI_API_KEY='sk-4f3a9b8e7c4f4c8f8f3a9b8e7c4f4c8f-UsH4C3vE64' # Fake Key - use your own real key here
```

åœ¨è¿è¡Œä¸‹ä¸€ç»„ä»£ç ä»¥å‘ˆç°èŠå¤©æœºå™¨äººUIä¹‹å‰ï¼Œè¯·æ³¨æ„ï¼Œå½“é€šè¿‡Colabæ¸²æŸ“æ—¶ï¼Œåº”ç”¨ç¨‹åºå¯¹äºä»»ä½•æ‹¥æœ‰é“¾æ¥çš„äººå…¬å¼€å¯è®¿é—®3å¤©ï¼ˆé“¾æ¥åœ¨Colabç¬”è®°æœ¬å•å…ƒè¾“å‡ºä¸­æä¾›ï¼‰ã€‚ç†è®ºä¸Šï¼Œå¯ä»¥é€šè¿‡å°†ä»£ç ä¸­çš„æœ€åä¸€è¡Œæ›´æ”¹ä¸º*demo.launch(share=False)*æ¥ä¿æŒåº”ç”¨çš„ç§å¯†æ€§ï¼Œä½†é‚£æ—¶æˆ‘æ— æ³•ä½¿åº”ç”¨æ­£å¸¸å·¥ä½œã€‚ç›¸åï¼Œæˆ‘æ›´å€¾å‘äºåœ¨Colabä¸­ä»¥â€œè°ƒè¯•â€æ¨¡å¼è¿è¡Œï¼Œè¿™æ ·Colabå•å…ƒä¼šâ€œè¿è¡Œâ€ç›´åˆ°åœæ­¢ï¼Œç„¶åç»ˆæ­¢èŠå¤©æœºå™¨äººã€‚æˆ–è€…ï¼Œåœ¨ä¸åŒçš„Colabå•å…ƒä¸­è¿è¡Œä¸‹é¢çš„ä»£ç ï¼Œä»¥ç»ˆæ­¢èŠå¤©æœºå™¨äººå¹¶åˆ é™¤åœ¨Colabä¸­åŠ è½½åˆ°Chromaå‘é‡æ•°æ®åº“ä¸­çš„å†…å®¹ã€‚

```py
# To be run at the end to terminate the demo chatbot
demo.close() # To end the chat session and terminate the shared demo

# Retrieve and delete the vector DB collection created for the chatbot
vectordb = Chroma(client=persistent_chroma_client, collection_name="my_rag_demo_collection", embedding_function=openai_embedding_func_for_langchain)
vectordb.delete_collection()
```

ä»¥ä¸‹æ˜¯å°†èŠå¤©æœºå™¨äººä½œä¸ºåº”ç”¨è¿è¡Œçš„ä»£ç ã€‚å¤§éƒ¨åˆ†ä»£ç é‡å¤äº†åˆ°ç›®å‰ä¸ºæ­¢çš„æ–‡ç« ä¸­çš„ä»£ç ï¼Œæ‰€ä»¥åº”è¯¥å¾ˆç†Ÿæ‚‰ã€‚è¯·æ³¨æ„ï¼Œä¸ä¹‹å‰çš„ä»£ç ç›¸æ¯”ï¼Œä¸‹é¢çš„ä»£ç å­˜åœ¨ä¸€äº›å·®å¼‚ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ²¡æœ‰ä½¿ç”¨ä¹‹å‰ç”¨è¿‡çš„LangChainçš„â€˜tokenâ€™å†…å­˜å¯¹è±¡è¿›è¡Œå†…å­˜ç®¡ç†ã€‚è¿™æ„å‘³ç€éšç€å¯¹è¯çš„ç»§ç»­ï¼Œå†å²è®°å½•å°†å˜å¾—è¿‡é•¿ï¼Œæ— æ³•ä¼ é€’ç»™è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡ï¼Œåº”ç”¨éœ€è¦é‡å¯ã€‚

```py
# Initiate OpenAI embedding functions. There are two because the function protocol is different when passing the function to Chroma DB directly vs using it with Chroma DB via LangChain
openai_embedding_func_for_langchain = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
openai_embedding_func_for_chroma = embedding_functions.OpenAIEmbeddingFunction(api_key=OPENAI_API_KEY)

# Initiate the LangChain chat model object using the GPT 3.5 turbo model
llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0, openai_api_key=OPENAI_API_KEY)

# Initialize vector DB and create a collection
persistent_chroma_client = chromadb.PersistentClient()
collection = persistent_chroma_client.get_or_create_collection("my_rag_demo_collection", embedding_function=openai_embedding_func_for_chroma)

# Function to load website content into vector DB
def load_content_from_url(url):
  # Load HTML from URL and transform to a more readable text format
  docs = Html2TextTransformer().transform_documents(AsyncHtmlLoader(url).load())
  # Split docs by section
  headers_to_split_on = [ ("#", "Header 1"), ("##", "Header 2"), ("###", "Header 3"), ("####", "Header 4"), ("#####", "Header 5") ]
  chunks = MarkdownHeaderTextSplitter(headers_to_split_on = headers_to_split_on).split_text(docs[0].page_content)
  # Here we are linking to the previously created an instance of the ChromaDB database
  vectordb_collection = persistent_chroma_client.get_or_create_collection("my_rag_demo_collection", embedding_function=openai_embedding_func_for_chroma)
  # Let's add data to the vector DB; specifically to our collection in the vector DB
  cur_max_id = vectordb_collection.count()
  vectordb_collection.add(ids=[str(t) for t in range(cur_max_id+1, cur_max_id+len(chunks)+1)],
                           documents=[t.page_content for t in chunks],
                           metadatas=[None if len(t.metadata) == 0 else t.metadata for t in chunks]
                           )
  # Alert user that content is loaded and ready to be queried
  gr.Info(f"Website content loaded. Vector DB now has {vectordb_collection.count()} chunks")
  return

# Define the UI and the chat function
with gr.Blocks() as demo:

  # Function to chat with language model using documents for context
  def predict(message, history):
    # Here we are linking to the previously created an instance of the ChromaDB database using a LangChain ChromaDB client
    langchain_chroma = Chroma(client=persistent_chroma_client, collection_name="my_rag_demo_collection", embedding_function=openai_embedding_func_for_langchain)
    # Convert to langchain chat history format - list of tuples rather than list of lists
    langchain_history_format = []
    for human, ai in history:
      langchain_history_format.append((human, ai))
    # We are now defining the ConversationalRetrieval chain, starting with the prompts used
    standalone_question_generator_template = """Given the following conversation and a follow up question, 
    rephrase the follow up question to be a standalone question, in its original language. Be as explicit as possible 
    in formulating the standalone question, and include any context necessary to clarify the standalone question.

    Conversation: {chat_history}
    Follow Up Question: {question}
    Standalone question:"""
    updated_condense_question_prompt = PromptTemplate.from_template(standalone_question_generator_template)
    # Let's rebuild the final prompt (again, optional since LangChain uses a default prompt, though it might be a little different)
    final_response_synthesizer_template = """Use the following pieces of context to answer the question at the end. 
    If you don't know the answer, just say that the available information is not sufficient to answer the question. 
    Don't try to make up an answer. Keep the answer as concise as possible, limited to five sentences.
    {context}
    Question: {question}
    Helpful Answer:"""
    custom_final_prompt = PromptTemplate.from_template(final_response_synthesizer_template)
    # Define the chain
    qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=langchain_chroma.as_retriever(), 
                                                     return_source_documents=True, return_generated_question=True, 
                                                     condense_question_prompt= updated_condense_question_prompt,
                                                     combine_docs_chain_kwargs={"prompt": custom_final_prompt})
    # Execute the chain
    gpt_response = qa_chain({"question": message, "chat_history": langchain_history_format})
    # Add human message and LLM response to chat history
    langchain_history_format.append((message, gpt_response['answer']))
    return gpt_response['answer'] 

  gr.Markdown(
      """
      # Chat with Websites
      ### Enter URL to extract content from website and start question-answering using this Chatbot
      """
  )
  with gr.Row():
    url_text = gr.Textbox(show_label=False, placeholder='Website URL to load content', scale = 5)
    url_submit = gr.Button(value="Load", scale = 1)
    url_submit.click(fn=load_content_from_url, inputs=url_text)

  with gr.Row():
    gr.ChatInterface(fn=predict)

demo.launch(debug=True)
```

ä½ å¯ä»¥é€šè¿‡ç»™åº”ç”¨æä¾›ä¸åŒçš„URLæ¥åŠ è½½å†…å®¹è¿›è¡Œå°è¯•ã€‚æ— éœ€å¤šè¨€ï¼šè¿™ä¸æ˜¯ä¸€ä¸ªç”Ÿäº§çº§åº”ç”¨ï¼Œåªæ˜¯ç”¨æ¥æ¼”ç¤ºåŸºäºRAGçš„GenAIè§£å†³æ–¹æ¡ˆçš„æ„å»ºå—ã€‚è¿™å……å…¶é‡æ˜¯ä¸€ä¸ªæ—©æœŸåŸå‹ï¼Œå¦‚æœè¦å°†å…¶è½¬æ¢ä¸ºå¸¸è§„äº§å“ï¼Œå¤§éƒ¨åˆ†çš„è½¯ä»¶å·¥ç¨‹å·¥ä½œè¿˜åœ¨å‰é¢ã€‚

## é‡æ–°å®¡è§†ä»‹ç»ä¸­çš„å¸¸è§é—®é¢˜

æ ¹æ®æˆ‘ä»¬åˆ›å»ºçš„èŠå¤©æœºå™¨äººèƒŒæ™¯å’ŒçŸ¥è¯†ï¼Œè®©æˆ‘ä»¬é‡æ–°å®¡è§†åœ¨*ä»‹ç»*ä¸­æå‡ºçš„ä¸€äº›é—®é¢˜ï¼Œå¹¶æ·±å…¥æ¢è®¨ä¸€ä¸‹ã€‚

1.  *æˆ‘ä»¬çš„ç”¨ä¾‹æ˜¯å¦é€‚åˆLLMé©±åŠ¨çš„è§£å†³æ–¹æ¡ˆï¼Ÿä¹Ÿè®¸ä¼ ç»Ÿçš„åˆ†ææ–¹æ³•ã€ç›‘ç£å­¦ä¹ æˆ–å…¶ä»–æ–¹æ³•æ›´åˆé€‚ï¼Ÿ*

    LLM åœ¨â€œç†è§£â€è¯­è¨€ç›¸å…³ä»»åŠ¡ä»¥åŠéµå¾ªæŒ‡ä»¤æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚å› æ­¤ï¼ŒLLM çš„æ—©æœŸä½¿ç”¨æ¡ˆä¾‹åŒ…æ‹¬é—®ç­”ã€æ€»ç»“ã€ç”Ÿæˆï¼ˆåœ¨è¿™é‡Œæ˜¯æ–‡æœ¬ï¼‰ã€æä¾›æ›´å¥½çš„åŸºäºæ„ä¹‰çš„æœç´¢ã€æƒ…æ„Ÿåˆ†æã€ç¼–ç ç­‰ã€‚LLM è¿˜è·å¾—äº†è§£å†³é—®é¢˜å’Œæ¨ç†çš„èƒ½åŠ›ã€‚ä¾‹å¦‚ï¼ŒLLM å¯ä»¥å……å½“å­¦ç”Ÿä½œä¸šçš„è‡ªåŠ¨è¯„åˆ†å‘˜ï¼Œåªè¦ä½ æä¾›ç­”æ¡ˆé”®ï¼Œç”šè‡³æœ‰æ—¶ä¸æä¾›ã€‚

    å¦ä¸€æ–¹é¢ï¼ŒåŸºäºå¤§é‡æ•°æ®ç‚¹çš„é¢„æµ‹æˆ–åˆ†ç±»ã€ç”¨äºè¥é”€ä¼˜åŒ–çš„å¤šè‡‚èµŒåšæœºå®éªŒã€æ¨èç³»ç»Ÿã€å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿï¼ˆå¦‚ Roombaã€Nest æ¸©æ§å™¨ã€ä¼˜åŒ–èƒ½æºæ¶ˆè€—æˆ–åº“å­˜æ°´å¹³ç­‰ï¼‰æ˜¯å…¶ä»–ç±»å‹åˆ†ææˆ–æœºå™¨å­¦ä¹ çš„å¼ºé¡¹â€¦â€¦è‡³å°‘ç›®å‰æ˜¯è¿™æ ·ã€‚ä¼ ç»Ÿ ML æ¨¡å‹å‘ LLM æä¾›ä¿¡æ¯å’Œåå‘ä¼ é€’ä¿¡æ¯çš„æ··åˆæ–¹æ³•ä¹Ÿåº”è€ƒè™‘ä½œä¸ºè§£å†³æ ¸å¿ƒä¸šåŠ¡é—®é¢˜çš„æ•´ä½“æ–¹æ¡ˆã€‚

1.  *å¦‚æœ LLM æ˜¯å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼Œæˆ‘ä»¬çš„ä½¿ç”¨æ¡ˆä¾‹æ˜¯å¦å¯ä»¥é€šè¿‡ç°æˆçš„äº§å“ï¼ˆä¾‹å¦‚ï¼ŒChatGPT Enterpriseï¼‰ç°åœ¨æˆ–åœ¨ä¸ä¹…çš„å°†æ¥å¾—åˆ°è§£å†³ï¼Ÿç»å…¸çš„æ„å»ºä¸è´­ä¹°å†³ç­–ã€‚*

    OpenAIã€AWS å’Œå…¶ä»–å…¬å¸æä¾›çš„æœåŠ¡å’Œäº§å“å°†å˜å¾—æ›´åŠ å¹¿æ³›ã€æ›´å¥½ï¼Œå¯èƒ½è¿˜æ›´ä¾¿å®œã€‚ä¾‹å¦‚ï¼ŒChatGPT å…è®¸ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶è¿›è¡Œåˆ†æï¼ŒBing Chat å’Œ Google çš„ Bard è®©ä½ æŒ‡å‘å¤–éƒ¨ç½‘ç«™è¿›è¡Œé—®ç­”ï¼ŒAWS Kendra å°†è¯­ä¹‰æœç´¢å¼•å…¥ä¼ä¸šçš„ä¿¡æ¯ä¸­ï¼ŒMicrosoft Copilot è®©ä½ åœ¨ Wordã€Powerpointã€Excel ç­‰åº”ç”¨ä¸­ä½¿ç”¨ LLMã€‚æ­£å¦‚å…¬å¸ä¸ä¼šè‡ªå·±æ„å»ºæ“ä½œç³»ç»Ÿæˆ–æ•°æ®åº“ä¸€æ ·ï¼Œå…¬å¸ä¹Ÿåº”è¯¥è€ƒè™‘æ˜¯å¦éœ€è¦æ„å»ºå¯èƒ½è¢«å½“å‰å’Œæœªæ¥çš„ç°æˆäº§å“æ‰€å–ä»£çš„ AI è§£å†³æ–¹æ¡ˆã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœå…¬å¸çš„ä½¿ç”¨æ¡ˆä¾‹éå¸¸å…·ä½“æˆ–åœ¨æŸç§ç¨‹åº¦ä¸Šå—é™ï¼Œä¾‹å¦‚ç”±äºæ•æ„Ÿæ€§æˆ–æ³•è§„æŒ‡å¯¼ä¸èƒ½å°†æ•æ„Ÿæ•°æ®å‘é€ç»™ä»»ä½•ä¾›åº”å•†ï¼Œé‚£ä¹ˆå¯èƒ½éœ€è¦åœ¨å…¬å¸å†…éƒ¨æ„å»ºç”Ÿæˆæ€§ AI äº§å“ä»¥è§£å†³è¿™äº›ä½¿ç”¨æ¡ˆä¾‹ã€‚ä½¿ç”¨ LLM æ¨ç†èƒ½åŠ›ä½†æ‰¿æ‹…çš„ä»»åŠ¡æˆ–ç”Ÿæˆçš„è¾“å‡ºä¸ç°æˆè§£å†³æ–¹æ¡ˆå·®å¼‚å¤ªå¤§çš„äº§å“å¯èƒ½éœ€è¦å†…éƒ¨å¼€å‘ã€‚ä¾‹å¦‚ï¼Œç›‘æ§å·¥å‚è½¦é—´ã€åˆ¶é€ è¿‡ç¨‹æˆ–åº“å­˜æ°´å¹³çš„ç³»ç»Ÿå¯èƒ½éœ€è¦å®šåˆ¶å¼€å‘ï¼Œç‰¹åˆ«æ˜¯å½“æ²¡æœ‰å¥½çš„é¢†åŸŸç‰¹å®šäº§å“æ—¶ã€‚æ­¤å¤–ï¼Œå¦‚æœåº”ç”¨éœ€è¦ä¸“ä¸šé¢†åŸŸçŸ¥è¯†ï¼Œé‚£ä¹ˆåœ¨é¢†åŸŸç‰¹å®šæ•°æ®ä¸Šå¾®è°ƒçš„ LLM å¯èƒ½ä¼šä¼˜äº OpenAI çš„é€šç”¨ LLMï¼Œå†…éƒ¨å¼€å‘ä¹Ÿå¯ä»¥è€ƒè™‘ã€‚

1.  *æˆ‘ä»¬çš„ LLM é©±åŠ¨äº§å“çš„ä¸åŒæ„å»ºæ¨¡å—æœ‰å“ªäº›ï¼Ÿè¿™äº›æ¨¡å—ä¸­å“ªäº›å·²ç»å•†å“åŒ–ï¼Œå“ªäº›å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´æ¥æ„å»ºå’Œæµ‹è¯•ï¼Ÿ*

    åƒæˆ‘ä»¬æ„å»ºçš„RAGè§£å†³æ–¹æ¡ˆçš„é«˜çº§æ„å»ºå—åŒ…æ‹¬æ•°æ®ç®¡é“ã€å‘é‡æ•°æ®åº“ã€æ£€ç´¢ã€ç”Ÿæˆï¼Œå½“ç„¶è¿˜æœ‰LLMã€‚LLMå’Œå‘é‡æ•°æ®åº“æœ‰å¾ˆå¤šä¼˜ç§€çš„é€‰æ‹©ã€‚æ•°æ®ç®¡é“ã€æ£€ç´¢ã€ç”Ÿæˆçš„æç¤ºå·¥ç¨‹å°†éœ€è¦ä¸€äº›ä¼ ç»Ÿçš„æ•°æ®ç§‘å­¦å®éªŒæ¥é’ˆå¯¹å…·ä½“ç”¨ä¾‹è¿›è¡Œä¼˜åŒ–ã€‚ä¸€æ—¦åˆæ­¥è§£å†³æ–¹æ¡ˆåˆ°ä½ï¼Œç”Ÿäº§åŒ–å°†éœ€è¦å¤§é‡å·¥ä½œï¼Œè¿™åœ¨ä»»ä½•æ•°æ®ç§‘å­¦/æœºå™¨å­¦ä¹ ç®¡é“ä¸­éƒ½æ˜¯çœŸå®çš„ã€‚æœ¬è®²åº§æä¾›äº†æœ‰å…³ç”Ÿäº§åŒ–çš„å®è´µç»éªŒï¼š[LLMs in Production: Learning from Experience, Dr. Waleed Kadous, Chief Scientist, AnyScale](https://youtu.be/xa7k9MUeIdk?si=LQizYwFt4m-XOYpk)

1.  *æˆ‘ä»¬å¦‚ä½•è¡¡é‡è§£å†³æ–¹æ¡ˆçš„æ€§èƒ½ï¼Ÿæœ‰å“ªäº›æ æ†å¯ä»¥æ”¹å–„æˆ‘ä»¬äº§å“çš„è¾“å‡ºè´¨é‡ï¼Ÿ* ä¸ä»»ä½•æŠ€æœ¯ï¼ˆæˆ–éæŠ€æœ¯ï¼‰è§£å†³æ–¹æ¡ˆä¸€æ ·ï¼Œå•†ä¸šå½±å“åº”ä½¿ç”¨é¢†å…ˆçš„å…³é”®ç»©æ•ˆæŒ‡æ ‡æ¥è¡¡é‡ã€‚ä¸€äº›ç›´æ¥åº¦é‡éš¾ä»¥æµ‹é‡ï¼Œé€šå¸¸ä¼šè¢«æ›¿ä»£æŒ‡æ ‡å¦‚æ¯æ—¥æ´»è·ƒç”¨æˆ·æ•°ï¼ˆDAUï¼‰å’Œå…¶ä»–äº§å“æŒ‡æ ‡æ‰€å–ä»£ã€‚

    å•†ä¸šæŒ‡æ ‡åº”è¡¥å……æŠ€æœ¯æŒ‡æ ‡ï¼Œä»¥è¯„ä¼°RAGè§£å†³æ–¹æ¡ˆçš„æ€§èƒ½ã€‚å¯ä»¥ä½¿ç”¨ä¸€ç³»åˆ—æµ‹è¯•ä¿¡æ¯é‡ã€äº‹å®å‡†ç¡®æ€§ã€ç›¸å…³æ€§ã€æ¯’æ€§ç­‰çš„æŒ‡æ ‡æ¥è¯„ä¼°å›åº”çš„æ•´ä½“è´¨é‡â€”â€”ç³»ç»Ÿçš„å›åº”ä¸ä¸“å®¶æˆ–å¦‚GPT-4ï¼ˆå½“å‰ï¼‰çš„æœ€å…ˆè¿›æ¨¡å‹çš„å›åº”ç›¸æ¯”å¦‚ä½•ã€‚è¿™æœ‰åŠ©äºæ·±å…¥äº†è§£å„ä¸ªç»„ä»¶çš„æ€§èƒ½ï¼Œä»¥ä¾¿è¿­ä»£å’Œæ”¹è¿›æ¯ä¸ªç»„ä»¶ï¼šè§£å†³æ–¹æ¡ˆå°†ç”¨ä½œä¸Šä¸‹æ–‡çš„ä¿¡æ¯è´¨é‡ã€æ£€ç´¢å’Œç”Ÿæˆã€‚

    i. **æ•°æ®è´¨é‡**å¦‚ä½•ï¼Ÿå¦‚æœç»„ç»‡å¯ç”¨çš„æ•°æ®å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­æ²¡æœ‰æ‰€éœ€çš„ä¿¡æ¯ï¼Œåˆ™æ²¡æœ‰äººæˆ–LLMèƒ½å¤ŸåŸºäºè¿™äº›ä¿¡æ¯æ„é€ å›åº”ã€‚

    ii. **æ£€ç´¢**æ•ˆæœå¦‚ä½•ï¼Ÿå‡è®¾ä¿¡æ¯å¯ç”¨ï¼Œç³»ç»Ÿåœ¨æ‰¾åˆ°å’Œæå–ç›¸å…³ä¿¡æ¯æ–¹é¢æœ‰å¤šæˆåŠŸï¼Ÿ

    iii. **ç”Ÿæˆï¼ˆå³åˆæˆï¼‰**æ•ˆæœå¦‚ä½•ï¼Ÿå‡è®¾ä¿¡æ¯å¯ç”¨ã€æ£€ç´¢æ­£ç¡®ï¼Œå¹¶ä¼ é€’ç»™LLMç”Ÿæˆæœ€ç»ˆå›åº”ï¼ŒLLMæ˜¯å¦æŒ‰é¢„æœŸä½¿ç”¨è¿™äº›ä¿¡æ¯ï¼Ÿ

    æ¯ä¸ªé¢†åŸŸéƒ½å¯ä»¥å•ç‹¬è¯„ä¼°å¹¶åŒæ—¶æ”¹è¿›ï¼Œä»¥æå‡æ•´ä½“è¾“å‡ºã€‚

    **æ”¹å–„æ•°æ®è´¨é‡ï¼š** å…¬å¸éœ€è¦åœ¨æ•°æ®ç®¡é“ä¸Šè¿›è¡Œå·¥ä½œï¼Œä»¥å‘ç³»ç»Ÿæä¾›è‰¯å¥½çš„ä¿¡æ¯ã€‚å¦‚æœå‘é‡æ•°æ®åº“ä¸­çš„ä¿¡æ¯è´¨é‡å·®ï¼Œæ‹¥æœ‰ä¼˜ç§€çš„LLMä¹Ÿä¸ä¼šæ˜¾è‘—æ”¹å–„è¾“å‡ºã€‚é™¤äº†é‡‡ç”¨ä¼ ç»Ÿçš„æ•°æ®è´¨é‡å’Œæ²»ç†æ¡†æ¶å¤–ï¼Œå…¬å¸è¿˜åº”è€ƒè™‘æ”¹å–„åˆ†å—çš„è´¨é‡ï¼ˆä¸‹ä¸€é—®é¢˜çš„å›åº”ä¸­å°†æ›´å¤šè®¨è®ºæ­¤äº‹ï¼‰ã€‚

    **æ”¹å–„æ£€ç´¢ï¼š** é€šè¿‡å°è¯•ä¸åŒçš„æ£€ç´¢ç®—æ³•ã€è¯­ä¹‰é‡æ’åºã€ç»“åˆè¯­ä¹‰æœç´¢å’Œå…³é”®è¯æœç´¢çš„æ··åˆæœç´¢ï¼Œä»¥åŠå¾®è°ƒåµŒå…¥ï¼Œå¯ä»¥æ”¹å–„æ£€ç´¢ã€‚æ”¹å–„æŒ‡ä»¤/æç¤ºä¹Ÿåº”æœ‰åŠ©äºæå‡æ£€ç´¢è´¨é‡ã€‚

    **æ”¹å–„ç”Ÿæˆï¼š** éšç€LLMçš„è¿›æ­¥ï¼Œåˆæˆæ­¥éª¤å°†å¾—åˆ°æ”¹å–„ï¼Œæ£€ç´¢å¯èƒ½ä¹Ÿä¼šå› ä¸ºåµŒå…¥æ¨¡å‹çš„æ”¹è¿›è€Œå¾—åˆ°æå‡ã€‚å¦ä¸€ç§é€‰æ‹©æ˜¯è¿›è¡Œå¾®è°ƒï¼Œå‰ææ˜¯èµ„æºå’Œæ—¶é—´å……è¶³ï¼Œè¿™å¯ä»¥æé«˜ç‰¹å®šé¢†åŸŸå’Œä»»åŠ¡çš„å“åº”è´¨é‡ã€‚ä¾‹å¦‚ï¼Œé’ˆå¯¹ç‰¹å®šåŒ»ç–—æ¡ä»¶è¿›è¡Œå¾®è°ƒçš„å°æ¨¡å‹å¯èƒ½åœ¨ä»»åŠ¡ä¸Šä¼˜äºåƒGPT-4è¿™æ ·çš„é€šç”¨æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿæ›´å¿«ã€æ›´ä¾¿å®œã€‚

1.  *æˆ‘ä»¬çš„æ•°æ®è´¨é‡æ˜¯å¦é€‚åˆç”¨ä¾‹ï¼Ÿæˆ‘ä»¬æ˜¯å¦æ­£ç¡®ç»„ç»‡äº†æ•°æ®ï¼Œå¹¶å°†ç›¸å…³æ•°æ®ä¼ é€’ç»™LLMï¼Ÿ*

    æ•°æ®è´¨é‡å¯ä»¥é€šè¿‡ä¼ ç»Ÿçš„æ•°æ®è´¨é‡ä¸æ²»ç†æ¡†æ¶è¿›è¡Œè¯„ä¼°ã€‚æ­¤å¤–ï¼Œå¯¹äºLLMé©±åŠ¨çš„è§£å†³æ–¹æ¡ˆï¼ŒLLMå›ç­”ç”¨æˆ·é—®é¢˜æˆ–æ‰§è¡Œä»»åŠ¡æ‰€éœ€çš„ä¿¡æ¯åº”åœ¨è§£å†³æ–¹æ¡ˆå¯ç”¨çš„æ•°æ®ä¸­å­˜åœ¨ã€‚

    å‡è®¾æ•°æ®æ˜¯å¯ç”¨çš„ï¼Œæ•°æ®åº”æ ¹æ®ç”¨ä¾‹å’Œæ‰€ä½¿ç”¨çš„LLMè¿›è¡Œé€‚å½“çš„æ‹†åˆ†ã€‚å—ä¸åº”è¿‡äºå®½æ³›ï¼Œä»¥å…ç¨€é‡Šä¸ç‰¹å®šä¸»é¢˜ç›¸å…³çš„è¿è´¯æ€§ï¼Œä¹Ÿä¸åº”è¿‡äºç‹­çª„ï¼Œä»¥å…é—æ¼æ‰€æœ‰å¿…è¦çš„ä¸Šä¸‹æ–‡ã€‚æ•°æ®ä¸åº”ä»¥å°†å¿…è¦çš„ä¸Šä¸‹æ–‡åˆ†å‰²åœ¨å—ä¹‹é—´å¹¶ä¸”åœ¨è¿™ç§åˆ†éš”ä¸‹æ¯«æ— æ„ä¹‰çš„æ–¹å¼è¿›è¡Œæ‹†åˆ†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸‹é¢çš„ä¸¤ä¸ªå¥å­è¢«æ‹†åˆ†æˆä¸¤ä¸ªå—ï¼Œ

    *â€œOpenAIçš„GPT-3.5æ˜¯ä¸€ä¸ªå¼ºå¤§çš„LLMã€‚å®ƒå¯ä»¥æ”¯æŒé«˜è¾¾16Kä»¤ç‰Œçš„ä¸Šä¸‹æ–‡å¤§å°ã€‚â€*

    åƒâ€œå‘Šè¯‰æˆ‘å…³äºGPT 3.5 LLMçš„æƒ…å†µâ€è¿™æ ·çš„é—®é¢˜å¯èƒ½ä¸ä¼šè·å–ç¬¬äºŒå¥ï¼Œå› ä¸ºå®ƒæ²¡æœ‰æåˆ°GPT 3.5ï¼Œè€Œè¿™æ¡ä¿¡æ¯å¯èƒ½ä¸ä¼šæä¾›ç»™ç”¨æˆ·ï¼Œä»…ä»…æ˜¯ç”±äºå­ä¼˜åŒ–å—çš„åŸå› ã€‚æ›´å±é™©çš„æ˜¯ï¼Œç”±äºä¸Šä¸‹æ–‡å¤§å°å’Œä»¤ç‰Œä¸LLMçš„è¯­ä¹‰å…³è”ï¼Œå½“è¯¢é—®å®Œå…¨ä¸åŒçš„LLMæ—¶ï¼Œå¯èƒ½ä»ä¼šè·å–è¯¥å¥å­ï¼Œä¸”å›ç­”å¯èƒ½æ˜¯å…¶ä»–é‡ç‚¹æ¨¡å‹çš„ä¸Šä¸‹æ–‡å¤§å°é«˜è¾¾16Kï¼Œè¿™å°†æ˜¯ä¸å‡†ç¡®çš„ã€‚è¿™æ˜¯ä¸€ä¸ªåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä¸å¤ªå¯èƒ½é‡åˆ°çš„ç®€åŒ–ç¤ºä¾‹ï¼Œä½†è¿™ä¸ªæƒ³æ³•æ˜¯æˆç«‹çš„ã€‚

    æ”¹å–„å†…å®¹è´¨é‡çš„ä¸€ç§å¯èƒ½æ–¹æ³•æ˜¯ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ–‡æœ¬æ‹†åˆ†ï¼Œä¾‹å¦‚æŒ‰é€»è¾‘éƒ¨åˆ†æ‹†åˆ†ï¼ˆå¦‚æˆ‘ä»¬ä¹¦å•çš„ç¤ºä¾‹ï¼‰ã€‚å¦‚æœä»»ä½•é€»è¾‘å—è¿‡å¤§â€”â€”ä¾‹å¦‚ï¼Œç»´åŸºç™¾ç§‘ä¸Šå…³äºæŸäº›ä¸»é¢˜çš„é¡µé¢å¯èƒ½éå¸¸é•¿â€”â€”å®ƒä»¬å¯ä»¥è¿›ä¸€æ­¥æŒ‰é€»è¾‘éƒ¨åˆ†æˆ–æŒ‰è¯­ä¹‰å•å…ƒï¼ˆå¦‚æ®µè½ï¼‰æ‹†åˆ†ï¼ŒåŒæ—¶åœ¨å—ä¹‹é—´ä¿æŒæœ‰æ„ä¹‰çš„é‡å ï¼Œå¹¶ç¡®ä¿å°†æ•´ä½“å…ƒæ•°æ®å’Œå—ç‰¹å®šçš„å…ƒæ•°æ®ä¼ é€’ç»™LLMã€‚

1.  *æˆ‘ä»¬èƒ½å¦ç¡®ä¿¡LLMçš„å›ç­”æ€»æ˜¯äº‹å®å‡†ç¡®çš„ï¼Ÿä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆä¼šä¸ä¼šåœ¨ç”Ÿæˆå›ç­”æ—¶å¶å°”â€˜å¹»è§‰â€™ï¼Ÿ*

    RAGçš„ä¸€ä¸ªå…³é”®å–ç‚¹æ˜¯æ¨åŠ¨äº‹å®å‡†ç¡®æ€§ã€‚GPT 3.5å’ŒGPT-4åœ¨éµå¾ªæŒ‡ä»¤æ–¹é¢è¡¨ç°è‰¯å¥½ï¼šâ€œä»…ä»æä¾›çš„ä¸Šä¸‹æ–‡ä¸­å›åº”ï¼Œæˆ–è¯´â€˜åŸºäºæä¾›çš„ä¿¡æ¯æ— æ³•å›ç­”è¯¥é—®é¢˜â€™â€ã€‚è¿™è¢«æ¨æµ‹æ˜¯ç”±äºOpenAIè¿›è¡Œäº†å¤§é‡çš„åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ã€‚ä½œä¸ºæ¨è®ºï¼Œå…¶ä»–LLMå¯èƒ½å½“å‰åœ¨éµå¾ªæŒ‡ä»¤æ–¹é¢è¡¨ç°ä¸ä½³ã€‚å¯¹äºç”Ÿäº§åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯é¢å‘å¤–éƒ¨çš„åº”ç”¨ï¼Œè¿›è¡Œå¤§é‡æµ‹è¯•ä»¥éªŒè¯ç”Ÿæˆçš„è¾“å‡ºæ˜¯å¦å¿ å®äºä»å‘é‡æ•°æ®åº“æ£€ç´¢çš„å¯ç”¨ä¸Šä¸‹æ–‡ï¼Œå³ä½¿LLMç›¸ä¿¡è¿™æ˜¯æ­£ç¡®çš„ï¼Œä¹Ÿæ˜¯æ˜æ™ºçš„ã€‚æ–¹æ³•åŒ…æ‹¬å¯¹æ ·æœ¬è¿›è¡Œæ‰‹åŠ¨æµ‹è¯•ï¼Œä½¿ç”¨å¼ºå¤§çš„æ¨¡å‹å¦‚GPT-4æµ‹è¯•æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ ·æœ¬å’Œå…¶ä»–æ¨¡å‹ç”Ÿæˆçš„å“åº”ï¼Œæˆ–ä½¿ç”¨å¦‚[Galileo](https://www.rungalileo.io/)è¿™æ ·çš„æœåŠ¡å’Œäº§å“ï¼Œä¸“æ³¨äºå®æ—¶æ£€æµ‹LLMå¹»è§‰ã€‚

## ç»“è®º

å¦‚æœä½ åœ¨11ä¸ªæœˆå‰å°±çŸ¥é“è¿™äº›å†…å®¹ï¼Œè¿™å°†å€¼å¾—ä¸ä½ å…¬å¸é¦–å¸­æ‰§è¡Œå®˜è¿›è¡Œä¸€æ¬¡æ¼”ç¤ºï¼Œç”šè‡³å¯èƒ½æœ‰ä¸€ä¸ªTEDæ¼”è®²å‘æ›´å¹¿æ³›çš„è§‚ä¼—ä»‹ç»ã€‚ä»Šå¤©ï¼Œè¿™å·²æˆä¸ºAIç´ å…»çš„åŸºæœ¬è¦æ±‚ï¼Œç‰¹åˆ«æ˜¯å¦‚æœä½ å‚ä¸ç”Ÿæˆå¼AIäº§å“çš„äº¤ä»˜ã€‚å¸Œæœ›é€šè¿‡è¿™æ¬¡ç»ƒä¹ ï¼Œä½ èƒ½æ¯”è¾ƒè·Ÿå¾—ä¸Šï¼ğŸ‘

ä¸€äº›ç»“æŸè¯­ï¼Œ

+   è¿™é¡¹æŠ€æœ¯å…·æœ‰å·¨å¤§çš„æ½œåŠ›â€”â€”è¿˜æœ‰å¤šå°‘å…¶ä»–æŠ€æœ¯èƒ½â€œæ€è€ƒâ€åˆ°è¿™ç§ç¨‹åº¦ï¼Œå¹¶ä¸”èƒ½ä½œä¸ºâ€œæ¨ç†å¼•æ“â€ï¼ˆç”¨å®‰å¾·é²Â·å´åšå£«çš„è¯è¯´ï¼Œå‚è§[è¿™é‡Œ](https://learn.deeplearning.ai/langchain/lesson/7/agents)ï¼‰ï¼Ÿ

+   è™½ç„¶å‰æ²¿æ¨¡å‹ï¼ˆç›®å‰ä¸ºGPT-4ï¼‰å°†ç»§ç»­è¿›æ­¥ï¼Œä½†å¼€æºæ¨¡å‹åŠå…¶é¢†åŸŸç‰¹å®šå’Œä»»åŠ¡ç‰¹å®šçš„å¾®è°ƒå˜ä½“åœ¨è®¸å¤šä»»åŠ¡ä¸­å°†å…·æœ‰ç«äº‰åŠ›ï¼Œå¹¶æ‰¾åˆ°è®¸å¤šåº”ç”¨ã€‚

+   æ— è®ºå¥½åï¼Œè¿™é¡¹è€—èµ„æ•°ç™¾ä¸‡ï¼ˆç”šè‡³æ•°äº¿ï¼Ÿï¼‰ç¾å…ƒå¼€å‘çš„å‰æ²¿æŠ€æœ¯ç°åœ¨æ˜¯å…è´¹çš„â€”â€”ä½ å¯ä»¥å¡«å†™ä¸€ä¸ªè¡¨æ ¼ï¼Œä¸‹è½½MetaåŠŸèƒ½å¼ºå¤§çš„Llama2æ¨¡å‹ï¼Œæ‹¥æœ‰éå¸¸å®½æ¾çš„è®¸å¯ã€‚HuggingFaceçš„æ¨¡å‹ä¸­å¿ƒå‡ ä¹æœ‰30ä¸‡ä¸ªåŸºç¡€LLMæˆ–å…¶å¾®è°ƒå˜ä½“ã€‚ç¡¬ä»¶ä¹Ÿå·²ç»å•†å“åŒ–ã€‚

+   OpenAIæ¨¡å‹ç°åœ¨èƒ½å¤Ÿè¯†åˆ«å¹¶ä½¿ç”¨â€œå·¥å…·â€ï¼ˆåŠŸèƒ½ã€APIç­‰ï¼‰ï¼Œä½¿å¾—è§£å†³æ–¹æ¡ˆä¸ä»…èƒ½ä¸äººç±»å’Œæ•°æ®åº“æ¥å£ï¼Œè¿˜èƒ½ä¸å…¶ä»–ç¨‹åºæ¥å£ã€‚LangChainå’Œå…¶ä»–è½¯ä»¶åŒ…å·²ç»å±•ç¤ºäº†å¦‚ä½•å°†LLMä½œä¸ºâ€œæ™ºèƒ½ä½“â€çš„â€œå¤§è„‘â€ï¼Œè¿™äº›æ™ºèƒ½ä½“èƒ½å¤Ÿæ¥å—è¾“å…¥ã€å†³å®šé‡‡å–çš„è¡ŒåŠ¨å¹¶æ‰§è¡Œï¼Œé‡å¤è¿™äº›æ­¥éª¤ç›´åˆ°æ™ºèƒ½ä½“å®ç°ç›®æ ‡ã€‚æˆ‘ä»¬çš„ç®€å•èŠå¤©æœºå™¨äººåœ¨ç¡®å®šæ€§åºåˆ—ä¸­ä½¿ç”¨äº†ä¸¤ä¸ªLLMè°ƒç”¨â€”â€”ç”Ÿæˆç‹¬ç«‹é—®é¢˜ï¼Œå¹¶å°†æœç´¢ç»“æœåˆæˆæˆè¿è´¯çš„è‡ªç„¶è¯­è¨€å“åº”ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæ•°ç™¾æ¬¡å¯¹å¿«é€Ÿå‘å±•çš„LLMè¿›è¡Œçš„è°ƒç”¨ä¼šå–å¾—ä»€ä¹ˆæˆæœï¼

+   è¿™äº›å¿«é€Ÿè¿›å±•æ˜¯ç”±äºGenAIå‘¨å›´çš„å·¨å¤§åŠ¨åŠ›ï¼Œå®ƒå°†é€šè¿‡æˆ‘ä»¬çš„è®¾å¤‡æ¸—é€åˆ°ä¼ä¸šå’Œæ—¥å¸¸ç”Ÿæ´»ä¸­ã€‚æœ€åˆæ˜¯ä»¥æ›´ç®€å•çš„æ–¹å¼ï¼Œä½†éšåå°†åœ¨åˆ©ç”¨æŠ€æœ¯çš„æ¨ç†å’Œå†³ç­–èƒ½åŠ›çš„è¶Šæ¥è¶Šå¤æ‚çš„åº”ç”¨ä¸­ä½“ç°ï¼Œä¸ä¼ ç»ŸAIèåˆã€‚

+   æœ€ç»ˆï¼Œç°åœ¨æ˜¯ä¸€ä¸ªç»ä½³çš„æ—¶æœºæ¥å‚ä¸ï¼Œå› ä¸ºåº”ç”¨è¿™é¡¹æŠ€æœ¯çš„ç«äº‰ç¯å¢ƒç›¸å¯¹å…¬å¹³â€”â€”è‡ª2022å¹´12æœˆChatGPTçš„çˆ†å‘ä»¥æ¥ï¼Œæ¯ä¸ªäººåŸºæœ¬ä¸Šéƒ½åœ¨åŒä¸€æ—¶é—´å­¦ä¹ è¿™é¡¹æŠ€æœ¯ã€‚å½“ç„¶ï¼Œç ”å‘æ–¹é¢æƒ…å†µæœ‰æ‰€ä¸åŒï¼Œå¤§å‹ç§‘æŠ€å…¬å¸å·²ç»æŠ•å…¥äº†å¤šå¹´å’Œæ•°åäº¿ç¾å…ƒæ¥å¼€å‘è¿™é¡¹æŠ€æœ¯ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä¸ºäº†å°†æ¥æ„å»ºæ›´å¤æ‚çš„è§£å†³æ–¹æ¡ˆï¼Œç°åœ¨æ­£æ˜¯å¼€å§‹çš„æœ€ä½³æ—¶æœºï¼

## é¢å¤–èµ„æº

+   **LangChainï¼š** [Deeplearning.ai](http://deeplearning.ai/)è¯¾ç¨‹ï¼š[LangChainï¼šä¸æ‚¨çš„æ•°æ®å¯¹è¯](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/) | LangChain [æ–‡æ¡£](https://python.langchain.com/docs/get_started/introduction)

+   **Gradioï¼š** [Deeplearning.ai](https://www.deeplearning.ai/)è¯¾ç¨‹ - [ä½¿ç”¨Gradioæ„å»ºç”Ÿæˆæ€§AIåº”ç”¨](https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio/) | Gradioæ–‡æ¡£å’Œ[æŒ‡å—](https://www.gradio.app/guides)

+   æˆ‘å‘ç°[Shawhin Talebi](https://medium.com/u/f3998e1cd186?source=post_page-----6ee6ad94e058--------------------------------)çš„æ–‡ç« éå¸¸å…·æœ‰å¯å‘æ€§ã€‚è¯·å‚é˜…[ç ´è§£OpenAI (Python) API](/cracking-open-the-openai-python-api-230e4cae7971)ï¼Œ[ç ´è§£Hugging Face Transformersåº“](/cracking-open-the-hugging-face-transformers-library-350aa0ef0161)ä»¥åŠå…¶ä»–è¿‘æœŸæ–‡ç« ã€‚

+   [LLMsåœ¨ç”Ÿäº§ä¸­çš„åº”ç”¨ï¼šä»ç»éªŒä¸­å­¦ä¹ ï¼ŒAnyScaleé¦–å¸­ç§‘å­¦å®¶Dr. Waleed Kadous](https://youtu.be/xa7k9MUeIdk?si=LQizYwFt4m-XOYpk)

+   ç”±LlamaIndexçš„è”åˆåˆ›å§‹äººJerry Liuæ‰€åšçš„æ¼”è®²æ¦‚è¿°äº†è¾“å‡ºè¯„ä¼°çš„å„ç§æ–¹æ³•ï¼š[æ„å»ºç”Ÿäº§å°±ç»ªçš„LLMåº”ç”¨çš„å®ç”¨æ•°æ®è€ƒè™‘](https://youtu.be/xbeFAZl3uCk?si=XBpo6cWt0Z9P9v_w)
