# å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Langchain å’Œ BentoML æ„å»ºå’Œéƒ¨ç½²ä¸€ä¸ªè¯­éŸ³èŠå¤©æœºå™¨äºº

> åŸæ–‡ï¼š[`towardsdatascience.com/deploy-a-voice-based-chatbot-with-bentoml-langchain-and-gradio-7f25af3e45df`](https://towardsdatascience.com/deploy-a-voice-based-chatbot-with-bentoml-langchain-and-gradio-7f25af3e45df)

## BentoML å¯¹æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå°±åƒä¹é«˜ç§¯æœ¨

[](https://ahmedbesbes.medium.com/?source=post_page-----7f25af3e45df--------------------------------)![Ahmed Besbes](https://ahmedbesbes.medium.com/?source=post_page-----7f25af3e45df--------------------------------)[](https://towardsdatascience.com/?source=post_page-----7f25af3e45df--------------------------------)![Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f25af3e45df--------------------------------) [Ahmed Besbes](https://ahmedbesbes.medium.com/?source=post_page-----7f25af3e45df--------------------------------)

Â·å‘è¡¨äº[Towards Data Science](https://towardsdatascience.com/?source=post_page-----7f25af3e45df--------------------------------) Â·é˜…è¯»æ—¶é•¿ 11 åˆ†é’ŸÂ·2023 å¹´ 5 æœˆ 2 æ—¥

--

![](img/62bdc77c059993e827235577879e894c.png)

[Jason Leung](https://unsplash.com/@ninjason?utm_source=medium&utm_medium=referral)çš„ç…§ç‰‡ï¼Œæ¥è‡ª[Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æŒ‡å¯¼ä½ å¦‚ä½•æ„å»ºä¸€ä¸ªåŸºäºè¯­éŸ³çš„ ChatGPT å…‹éš†ï¼Œä¾èµ–äº OpenAI API å¹¶ä½¿ç”¨ç»´åŸºç™¾ç§‘ä½œä¸ºé¢å¤–çš„æ•°æ®æºã€‚

è¦æ„å»ºå’Œéƒ¨ç½²è¿™ä¸ªåº”ç”¨ç¨‹åºï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[BentoML](https://github.com/bentoml/BentoML)ï¼šä¸€ä¸ªç”¨äºæ¨¡å‹æœåŠ¡å’Œéƒ¨ç½²çš„ Python æ¡†æ¶ã€‚

BentoML ä¸ä»…å¸®åŠ©ä½ æ„å»ºè¿æ¥åˆ°ç¬¬ä¸‰æ–¹ä¸“æœ‰ API çš„æœåŠ¡ï¼Œè¿˜é€šè¿‡å°†è¿™äº›æœåŠ¡ä¸å…¶ä»–å¼€æºæ¨¡å‹ç»“åˆèµ·æ¥ï¼Œè¶…çº§å¢å¼ºäº†è¿™äº›æœåŠ¡ï¼Œå½¢æˆå¤æ‚ä¸”å¼ºå¤§çš„æ¨ç†å›¾ã€‚

å®é™…ä¸Šï¼Œæˆ‘ä»¬å°†è¦æ„å»ºçš„åº”ç”¨ç¨‹åºå°†åŒ…å«**è¯­éŸ³è½¬æ–‡æœ¬**å’Œ**æ–‡æœ¬è½¬è¯­éŸ³**ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡å°†ç”±æ¥è‡ª HuggingFace [hub](https://huggingface.co/)çš„ä¸åŒæ¨¡å‹å¤„ç†ï¼ŒLLM ä»»åŠ¡å°†ç”±[**LangChain**](https://langchain.readthedocs.io/)ç®¡ç†ã€‚

åœ¨æœ¬åœ°æµ‹è¯•é¡¹ç›®åï¼Œæˆ‘ä»¬å°†æŠŠå®ƒæ¨é€åˆ° BentoCloudï¼Œè¿™ä¸ªå¹³å°ç®€åŒ–äº†ç‰ˆæœ¬æ§åˆ¶ã€è·Ÿè¸ªå’Œå°†æœºå™¨å­¦ä¹ æœåŠ¡éƒ¨ç½²åˆ°äº‘ç«¯çš„è¿‡ç¨‹ã€‚

> ***åœ¨æœ¬æ–‡ç»“æŸæ—¶ï¼Œä½ åº”è¯¥å¯¹ä½¿ç”¨ BentoML æ„å»ºå’Œéƒ¨ç½²å¤šæ¨¡å‹æœåŠ¡æœ‰å…¨é¢çš„äº†è§£ã€‚ä½ è¿˜å°†å­¦ä¹ åˆ°ä¸€äº›ç‰¹å®šçš„åŠŸèƒ½ï¼Œä½¿æ¨¡å‹å·¥ä¸šåŒ–å˜å¾—æ›´å®¹æ˜“ã€‚***

ä¸å†èµ˜è¨€ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹ ğŸ”ã€‚

# æ¼”ç¤º

è¿™æ˜¯åº”ç”¨ç¨‹åºçš„ä¸€åˆ†é’Ÿæ¼”ç¤ºã€‚

ä½œè€…çš„è§†é¢‘ â€” å¿«é€Ÿæ¼”ç¤º

# ä¸ºä»€ä¹ˆé€‰æ‹© BentoMLï¼ŸğŸ±

éšç€è¶Šæ¥è¶Šå¤šçš„å¼€æºæœºå™¨å­¦ä¹ æ¨¡å‹è§£å†³å„ç§ä»»åŠ¡ï¼Œè½¯ä»¶åº”ç”¨ç¨‹åºå°†é€æ¸æˆä¸ºä¸€ç§é›†æˆäº†é¢„è®­ç»ƒæ¨¡å‹ã€è‡ªæˆ‘è®­ç»ƒæ¨¡å‹æˆ–é€šè¿‡ API è®¿é—®æ¨¡å‹çš„äººå·¥æ™ºèƒ½åº”ç”¨ç¨‹åºã€‚

é‰´äºè®¸å¤š SOTA æ¨¡å‹å¾ˆå¤§å¹¶ä¸”éœ€è¦å¼ºå¤§çš„ç¡¬ä»¶å’Œåˆ†å¸ƒå¼éƒ¨ç½²ï¼Œå°†æ‰€æœ‰å†…å®¹æ”¾å…¥ä¸€å°æœºå™¨ä¸­å¹¶ä¸æ˜¯ä¸€ä¸ªå®é™…çš„è§£å†³æ–¹æ¡ˆï¼Œå°¤å…¶æ˜¯å½“åº”ç”¨ç¨‹åºç»“åˆäº†è‡³å°‘ 2 æˆ– 3 ä¸ªæ¨¡å‹æ—¶ã€‚

> ***â†’ BentoML æ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œé€šè¿‡è®©ç”¨æˆ·ç¼–å†™ç®€å•çš„ Python ä»£ç æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒåŒæ—¶å°†æ¨¡å‹éƒ¨ç½²ä¸ºåˆ†å¸ƒå¼å¾®æœåŠ¡ã€‚***

æˆ‘å·²ç»ç©å¼„å’Œå®éªŒäº† BentoML ä¸€æ®µæ—¶é—´ï¼Œå®ƒç»å¯¹æ˜¯æˆ‘éƒ¨ç½²æœºå™¨å­¦ä¹ æ¨¡å‹å’ŒæœåŠ¡çš„é¦–é€‰è§£å†³æ–¹æ¡ˆã€‚å‡­å€Ÿå…¶è‡ªå·±çš„åˆ†å‘æ ¼å¼ *bento*ï¼Œè¿™ä¸ªåº“ä½¿å¾—å°†æ‰€æœ‰ä¸ ML ç›¸å…³çš„å†…å®¹æ‰“åŒ…åˆ°ä¸€ä¸ªåœ°æ–¹å˜å¾—éå¸¸ç®€å•ï¼šæºä»£ç å’Œä¾èµ–é¡¹ã€API å®šä¹‰ã€æ¨¡å‹æƒé‡ã€Docker é•œåƒç­‰ã€‚

éƒ¨ç½²å˜å¾—æ›´åŠ å®¹æ˜“ï¼Œå› ä¸ºå®ƒä¾èµ–äºå°†ä¸Šè¿° bento æ¨é€åˆ°äº‘ç«¯ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†é¦–å…ˆåŸå‹åŒ–åº”ç”¨ç¨‹åºï¼Œæ„å»ºæœ¬åœ°çš„ bentoï¼Œå¹¶å°†å…¶æ¨é€åˆ° BentoCloud è¿›è¡Œéƒ¨ç½²ã€‚

ä½ å¯ä»¥é€šè¿‡è‡ªæˆ‘ç®¡ç†ä¸€ä¸ªéƒ¨ç½²å¹³å°ï¼ˆæŸ¥çœ‹ [Yatai](https://github.com/bentoml/Yatai) é¡¹ç›®äº†è§£æ›´å¤šç»†èŠ‚ï¼‰æˆ–ä½¿ç”¨åä¸º [bentoctl](https://github.com/bentoml/bentoctl) çš„éƒ¨ç½²å·¥å…·ï¼Œå°†ä½ çš„ bento éƒ¨ç½²åˆ°å„ç§äº‘æœåŠ¡ä¸­ã€‚

> å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äº BentoML å’Œä¸åŒéƒ¨ç½²ç­–ç•¥çš„ä¿¡æ¯ï¼Œå¯ä»¥æŸ¥çœ‹æˆ‘ä¹‹å‰çš„å¸–å­ *â¬*

[## BentoML å¦‚ä½•å¸®åŠ©ä½ æœåŠ¡å’Œæ‰©å±•æœºå™¨å­¦ä¹ æ¨¡å‹çš„ 10 ç§æ–¹å¼](https://towardsdatascience.com/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d?source=post_page-----7f25af3e45df--------------------------------)

### ä» Jupyter ç¬”è®°æœ¬è¿ç§»åˆ°ç”Ÿäº§å…¶å®å¹¶ä¸æ˜¯é‚£ä¹ˆå›°éš¾

[## å¿«é€Ÿåœ¨ AWS EC2 ä¸Šä½¿ç”¨ BentoML éƒ¨ç½²æœºå™¨å­¦ä¹  API](https://levelup.gitconnected.com/quickly-deploy-a-machine-learning-api-on-aws-ec2-using-bentoml-dbb13bc09d51?source=post_page-----7f25af3e45df--------------------------------)

### ç”¨ä¾‹ï¼šä¸€ä¸ªç«¯åˆ°ç«¯çš„æœåŠ¡æ¥æ€»ç»“ YouTube è§†é¢‘ ğŸ¥

[## å¦‚ä½•å°† PyTorch æ¨¡å‹éƒ¨ç½²ä¸ºç”Ÿäº§å°±ç»ªçš„ APIï¼Ÿ](https://levelup.gitconnected.com/how-to-deploy-pytorch-models-as-production-ready-apis-f61136fd0244?source=post_page-----7f25af3e45df--------------------------------)

### ä¸€ä¸ªç»“åˆäº† PyTorch Lightning å’Œ BentoML çš„ç«¯åˆ°ç«¯ç”¨ä¾‹ ğŸš€

[## å¦‚ä½•å°† PyTorch æ¨¡å‹éƒ¨ç½²ä¸ºç”Ÿäº§å°±ç»ªçš„ APIï¼Ÿ](https://towardsdatascience.com/how-to-deploy-pytorch-models-as-production-ready-apis-f61136fd0244?source=post_page-----7f25af3e45df--------------------------------)

# ä»£ç  ğŸ’»

æœ¬é¡¹ç›®çš„ä»£ç å¯ä»¥åœ¨ [Github](https://github.com/ahmedbesbes/BentoChain) ä¸Šæ‰¾åˆ°ã€‚ä½ å¯ä»¥å…‹éš†å®ƒå¹¶åœ¨æœ¬åœ°è¿è¡Œåº”ç”¨ç¨‹åºï¼Œæˆ–æ„å»ºä¸€ä¸ªè‡ªåŒ…å«çš„ bento ä»¥ä¾¿åç»­éƒ¨ç½²ã€‚

# ä¾èµ–é¡¹

æˆ‘ä»¬å°†ä½¿ç”¨ [transformers](https://github.com/huggingface/transformers) å’Œå…¶ä»–å‡ ä¸ªå¤„ç†éŸ³é¢‘æ•°æ®çš„åº“ï¼Œä»¥åŠæµè¡Œçš„ [LangChain](https://langchain.readthedocs.io/) åŒ…æ¥è½»æ¾é›†æˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ [poetry](https://python-poetry.org/) æ¥ç®¡ç†é¡¹ç›®çš„ä¾èµ–ã€‚

```py
git clone git@github.com:ahmedbesbes/BentoChain.git
cd BentoChain/
poetry install 
```

å®‰è£…åŒ…åï¼Œä½ éœ€è¦ç”Ÿæˆ SSL å¯†é’¥å’Œè¯ä¹¦ã€‚è¿™å°†å»ºç«‹ä¸€ä¸ª HTTPS è¿æ¥ï¼Œç°ä»£æµè§ˆå™¨éœ€è¦æ­¤è¿æ¥ä»¥å…è®¸ä½¿ç”¨éº¦å…‹é£ã€‚

```py
mkdir ssl
cd ssl
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 365 -nodes
```

# ä¸‹è½½æ¨¡å‹å¹¶ä¿å­˜

è¯¥é¡¹ç›®å‡è®¾æ²¡æœ‰è®­ç»ƒã€‚æˆ‘ä»¬å°†ä» HuggingFace çš„ hub ä¸‹è½½æ¨¡å‹æƒé‡ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸º BentoML æ¨¡å‹ã€‚

å°†æ¨¡å‹ä¿å­˜ä¸º BentoML å·¥ä»¶æœ‰åŠ©äºå°†å®ƒä»¬çº³å…¥ bento å½’æ¡£ä¸­ï¼Œä»¥ä¾¿å®ƒä»¬ä¸ä¼šæ„æˆå¤–éƒ¨ä¾èµ–ã€‚

åœ¨ç²¾ç¡®ç¡®å®šæ‰€éœ€æ¨¡å‹åï¼Œä½ å¯ä»¥é€šè¿‡åˆå§‹åŒ–æ¨¡å‹å…ˆå°†å…¶ä¸‹è½½åˆ°æœ¬åœ°ã€‚

```py
import logging
import bentoml
from transformers import (
    SpeechT5Processor,
    SpeechT5ForTextToSpeech,
    SpeechT5HifiGan,
    WhisperForConditionalGeneration,
    WhisperProcessor,
)

logging.basicConfig(level=logging.WARN)

if __name__ == "__main__":
    t5_processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts")
    t5_model = SpeechT5ForTextToSpeech.from_pretrained("microsoft/speecht5_tts")
    t5_vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")

    whisper_processor = WhisperProcessor.from_pretrained("openai/whisper-tiny")
    whisper_model = WhisperForConditionalGeneration.from_pretrained(
        "openai/whisper-tiny"
    )
    whisper_model.config.forced_decoder_ids = None
```

ç„¶åï¼Œä½ å¯ä»¥é€šè¿‡è°ƒç”¨`bentoml.transformers.save_model`å‡½æ•°å°†å…¶ä¿å­˜ä¸º BentoML æ¨¡å‹ï¼š

```py
 saved_t5_processor = bentoml.transformers.save_model(
        "speecht5_tts_processor", t5_processor
    )
    print(f"Saved: {saved_t5_processor}")

    saved_t5_model = bentoml.transformers.save_model(
        "speecht5_tts_model",
        t5_model,
        signatures={"generate_speech": {"batchable": False}},
    )
    print(f"Saved: {saved_t5_model}")

    saved_t5_vocoder = bentoml.transformers.save_model(
        "speecht5_tts_vocoder", t5_vocoder
    )
    print(f"Saved: {saved_t5_vocoder}")

    saved_whisper_processor = bentoml.transformers.save_model(
        "whisper_processor",
        whisper_processor,
    )
    print(f"Saved: {saved_whisper_processor}")

    saved_whisper_model = bentoml.transformers.save_model(
        "whisper_model",
        whisper_model,
    )
    print(f"Saved: {saved_whisper_model}")
```

å®Œæ•´ä»£ç åœ¨`train.py`è„šæœ¬ä¸­ï¼Œå¹¶åº”è¿è¡Œä¸€æ¬¡ï¼š

```py
poetry shell
python train.py
```

![](img/4eeac49acaaf50c39b99fa9fbba8bb55.png)

ä¿å­˜æ¨¡å‹ âœ… â€” ä½œè€…æˆªå›¾

# åº”ç”¨æ¶æ„æ¦‚è¿°

åœ¨è¯¦ç»†è¯´æ˜ä¹‹å‰ï¼Œè®©æˆ‘ä»¬é¦–å…ˆæ¾„æ¸…æ•°æ®å·¥ä½œæµç¨‹ï¼Œä»¥äº†è§£åº”ç”¨çš„å·¥ä½œæ–¹å¼ï¼š

+   ç”¨æˆ·é€šè¿‡ HTTP POST è¯·æ±‚å‘ API æœåŠ¡å™¨å‘é€éŸ³é¢‘æ¶ˆæ¯

+   API æœåŠ¡å™¨å°†éŸ³é¢‘æ¶ˆæ¯é‡å®šå‘åˆ° speech2text è¿è¡Œå™¨ï¼Œè¯¥è¿è¡Œå™¨å°†å…¶è½¬å½•ä¸ºæ–‡æœ¬å¹¶å°†å…¶è¿”å›

+   API æœåŠ¡å™¨å°†è½¬å½•çš„æ–‡æœ¬æ¶ˆæ¯ä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡ LangChain ä»£ç†ä¼ é€’ï¼Œç”Ÿæˆå“åº”ï¼Œç„¶åå°†å…¶å‘é€åˆ° text2speech è¿è¡Œå™¨

+   text2speech è¿è¡Œå™¨ä»è¾“å…¥æ–‡æœ¬ç”ŸæˆéŸ³é¢‘ç‰‡æ®µï¼Œå¹¶å°†å…¶è¿”å›ç»™ API æœåŠ¡å™¨ï¼Œåè€…å†å°†å…¶å‘é€å›ç”¨æˆ·

ä»¥ä¸‹å›¾è¡¨æ€»ç»“äº†è¿™äº›æ­¥éª¤ã€‚

![](img/7ad715efc3619895dadcb6660ec5dd9e.png)

åº”ç”¨æ¶æ„ âœ… â€” ä½œè€…å›¾ç‰‡

# ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨ä¸¤ä¸ªè¿è¡Œå™¨ï¼Ÿ

BentoML çš„æœ‰è¶£ä¹‹å¤„åœ¨äºï¼Œå½“éƒ¨ç½²åˆ° BentoCloudï¼ˆæˆ–ä»»ä½•è‡ªæˆ‘ç®¡ç†çš„å¹³å°ï¼‰æ—¶ï¼Œè¿è¡Œå™¨å’Œ API æœåŠ¡å™¨å¯ä»¥åœ¨ä¸‰ä¸ªä¸åŒçš„ Kubernetes pod ä¸Šåˆ†åˆ«éƒ¨ç½²ã€‚

è¿™æä¾›äº† 3 ä¸ªä¸»è¦å¥½å¤„ï¼š

+   **å…³æ³¨åˆ†ç¦»**ï¼šè¿è¡Œå™¨ä¸“æ³¨äºè®¡ç®—ï¼Œå¹¶ä¸ç½‘é¡µæœåŠ¡è§£è€¦

+   **å®šåˆ¶åŒ–**ï¼šæ¯ä¸ªè¿è¡Œå™¨å¯ä»¥æ ¹æ®å…¶æ‰§è¡Œçš„ä»»åŠ¡å…·æœ‰ç‰¹å®šçš„ç¡¬ä»¶é…ç½®ï¼šä¾‹å¦‚ï¼Œtext2speech è¿è¡Œå™¨çš„é…ç½®å°†åŒ…æ‹¬ GPUï¼Œè€Œ speech2text è¿è¡Œå™¨åˆ™ä¸éœ€è¦

+   **è‡ªåŠ¨æ‰©å±•**ï¼šè¿è¡Œå™¨è¿˜ä¼šæ ¹æ®èµ„æºä½¿ç”¨æƒ…å†µç‹¬ç«‹è‡ªåŠ¨æ‰©å±•

> *æƒ³äº†è§£æ›´å¤šå…³äº BentoML è¿è¡Œå™¨çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹è¿™ä¸ª* [*é¡µé¢*](https://docs.bentoml.org/en/latest/concepts/runner.html)*ã€‚*

ç°åœ¨æˆ‘ä»¬å¯¹åº”ç”¨æœ‰äº†æ•´ä½“äº†è§£ï¼Œè®©æˆ‘ä»¬å…³æ³¨æ¯ä¸ªè¿è¡Œå™¨ï¼š

# è¯­éŸ³è½¬æ–‡æœ¬è¿è¡Œå™¨ ğŸ¤ â†’ ğŸ“

è¿™ä¸ªè¿è¡Œå™¨å°†ä¾èµ– OpenAI çš„ Whisper æ¨¡å‹å°†éŸ³é¢‘è½¬å½•ä¸ºæ–‡æœ¬ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒå°†ä½¿ç”¨ **tiny** [æ¨¡å‹](https://huggingface.co/openai/whisper-tiny)ã€‚

è¿™ä¸ªæ¨¡å‹å°†æ¥æ”¶ä¸€ä¸ªè¾“å…¥ç‰¹å¾çš„å¼ é‡ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªè½¬å½•ç»“æœã€‚

ä»£ç éå¸¸ç›´æ¥ï¼šå®ƒåªå®šä¹‰äº†ä¸€ä¸ª`**SpeechToTextRunnable**`ç±»ï¼Œè¯¥ç±»ç»§æ‰¿è‡ª`**bentoml.Runnable**`ï¼Œå®ä¾‹åŒ–äº†æ¨¡å‹å’Œå¤„ç†å™¨ï¼Œå¹¶å®šä¹‰äº†æ¨ç†æ–¹æ³•ã€‚

```py
import torch
import bentoml

s2t_processor_ref = bentoml.models.get("whisper_processor:latest")
s2t_model_ref = bentoml.models.get("whisper_model:latest")

class Speech2TextRunnable(bentoml.Runnable):
    SUPPORTED_RESOURCES = ("nvidia.com/gpu", "cpu")
    SUPPORTS_CPU_MULTI_THREADING = True

    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.processor = bentoml.transformers.load_model(s2t_processor_ref)
        self.model = bentoml.transformers.load_model(s2t_model_ref)
        self.model.to(self.device)

    @bentoml.Runnable.method(batchable=False)
    def transcribe_audio(self, tensor):
        if tensor is not None:
            predicted_ids = self.model.generate(tensor.to(self.device))
            transcriptions = self.processor.batch_decode(
                predicted_ids, skip_special_tokens=True
            )
            transcription = transcriptions[0]
            return transcription 
```

# ä¸€ä¸ªæ–‡æœ¬åˆ°è¯­éŸ³çš„è¿è¡Œå™¨ ğŸ“ â†’ ğŸ¤

è¿™ä¸ªè¿è¡Œå™¨æ‰§è¡Œå®Œå…¨ç›¸åçš„ä»»åŠ¡ï¼šå®ƒæ¥å—æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªç”± NumPy æ•°ç»„è¡¨ç¤ºçš„è¯­éŸ³ã€‚

æ³¨æ„ï¼Œå½“è®¾å¤‡å¯ç”¨æ—¶ï¼Œå¿…é¡»å°†å…¶å£°æ˜ä¸º `**Text2SpeechRunnable**` ç±»çš„å±æ€§ï¼Œä»¥æ”¯æŒ GPU åŠ é€Ÿã€‚

```py
import bentoml
import torch
from datasets import load_dataset

t2s_processor_ref = bentoml.models.get("speecht5_tts_processor:latest")
t2s_model_ref = bentoml.models.get("speecht5_tts_model:latest")
t2s_vocoder_ref = bentoml.models.get("speecht5_tts_vocoder:latest")

class Text2SpeechRunnable(bentoml.Runnable):
    SUPPORTED_RESOURCES = ("nvidia.com/gpu", "cpu")
    SUPPORTS_CPU_MULTI_THREADING = True

    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.processor = bentoml.transformers.load_model(t2s_processor_ref)
        self.model = bentoml.transformers.load_model(t2s_model_ref)
        self.vocoder = bentoml.transformers.load_model(t2s_vocoder_ref)
        self.embeddings_dataset = load_dataset(
            "Matthijs/cmu-arctic-xvectors",
            split="validation",
        )
        self.speaker_embeddings = torch.tensor(
            self.embeddings_dataset[7306]["xvector"]
        ).unsqueeze(0)
        self.model.to(self.device)
        self.vocoder.to(self.device)

    @bentoml.Runnable.method(batchable=False)
    def generate_speech(self, inp: str):
        inputs = self.processor(text=inp, return_tensors="pt")
        speech = self.model.generate_speech(
            inputs["input_ids"].to(self.device),
            self.speaker_embeddings.to(self.device),
            vocoder=self.vocoder,
        )
        return speech.cpu().numpy()
```

# ä¸€ä¸ª BentoML æœåŠ¡

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæœåŠ¡ï¼Œå®šä¹‰åœ¨ bento éƒ¨ç½²æ—¶å¯ä»¥è®¿é—®çš„ API è·¯ç”±ã€‚

æˆ‘ä»¬é¦–å…ˆå¼€å§‹åˆå§‹åŒ–æˆ‘ä»¬å®šä¹‰çš„ä¸¤ä¸ªå‰ä¸€ä¸ªè¿è¡Œå™¨ï¼š

```py
import bentoml
import gradio as gr
from chatbot import create_block, ChatWrapper
from fastapi import FastAPI
from speech2text_runner import s2t_processor_ref, s2t_model_ref, Speech2TextRunnable
from text2speech_runner import (
    t2s_processor_ref,
    t2s_model_ref,
    t2s_vocoder_ref,
    Text2SpeechRunnable,
)

speech2text_runner = bentoml.Runner(
    Speech2TextRunnable,
    name="speech2text_runner",
    models=[s2t_processor_ref, s2t_model_ref],
)
text2speech_runner = bentoml.Runner(
    Text2SpeechRunnable,
    name="text2speech_runner",
    models=[t2s_processor_ref, t2s_model_ref, t2s_vocoder_ref],
)
```

ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¾èµ–äºè¿™äº›è·¯ç”±çš„ Service å¯¹è±¡ï¼š

```py
svc = bentoml.Service(
    "voicegpt",
    runners=[
        text2speech_runner,
        speech2text_runner,
    ],
)
```

ä¸€æ—¦æœåŠ¡åˆ›å»ºå®Œæˆï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸¤ä¸ª API è·¯ç”±ï¼š

+   **generate_text:** è¿™ä¸ªè·¯ç”±å°†æ¥å—ä¸€ä¸ªæ•°ç»„ä½œä¸ºè¾“å…¥ï¼Œå¹¶é€šè¿‡è°ƒç”¨ speech2text_runner ç”Ÿæˆæ–‡æœ¬

```py
@svc.api(input=bentoml.io.NumpyNdarray(), output=bentoml.io.Text())
def generate_text(tensor):
    text = speech2text_runner.transcribe_audio.run(tensor)
    return text
```

+   **generate_speech:** è¿™ä¸ªè·¯ç”±å°†æ¥å—ä¸€ä¸ªæ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶é€šè¿‡è°ƒç”¨ text2speech_runner ç”Ÿæˆä¸€ä¸ªæ•°ç»„ä½œä¸ºè¾“å‡º

```py
 @svc.api(input=bentoml.io.Text(), output=bentoml.io.NumpyNdarray())
def generate_speech(inp: str):
    return text2speech_runner.generate_speech.run(inp)
```

# ChatWrapper å®ç”¨ç¨‹åºç±»

æˆ‘ä»¬è¿˜æ²¡æœ‰å®ŒæˆæœåŠ¡æºä»£ç ã€‚

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æŠŠ FastAPI åº”ç”¨æŒ‚è½½ä¸ºâ€œ/chatbotâ€è·¯å¾„ä¸Šçš„ HTTP ç«¯ç‚¹ã€‚

è¿™ä¸ªåº”ç”¨å°†æä¾›ä¸€ä¸ª Gradio èŠå¤©æœºå™¨äººç•Œé¢ï¼Œè¯¥ç•Œé¢å°†ä¸ä¹‹å‰å®šä¹‰çš„ä¸¤ä¸ª API è·¯ç”±è¿›è¡Œäº¤äº’ï¼š`**generate_text**` å’Œ `**generate_speech**`ã€‚

```py
chat = ChatWrapper(generate_speech, generate_text)
app = FastAPI()
app = gr.mount_gradio_app(app, create_block(chat), path="/chatbot")
svc.mount_asgi_app(app, "/")
```

â€œchatâ€å˜é‡æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œå®ƒè·å–ç”¨æˆ·çš„éŸ³é¢‘è¾“å…¥ï¼Œå°†å…¶è½¬å½•ä¸ºæ–‡æœ¬ï¼Œä¼ é€’ç»™ LangChainï¼Œæå–å“åº”ï¼Œå¹¶è¿”å›ä¸€å †æ›´æ–°åº”ç”¨ç•Œé¢å’ŒçŠ¶æ€çš„æ•°æ®ã€‚

chat å¯¹è±¡æ˜¯ä¸€ä¸ªå¯è°ƒç”¨çš„å¯¹è±¡ï¼Œå®ƒæœŸæœ›ä»¥ä¸‹å‚æ•°ï¼š

+   **api_key**: OpenAI API å¯†é’¥

+   **audio_path**: å½“ä½¿ç”¨éº¦å…‹é£å½•åˆ¶éŸ³é¢‘æ–‡ä»¶æ—¶çš„ä¸´æ—¶æ–‡ä»¶ä½ç½®

+   **text_message**: ä»£æ›¿éŸ³é¢‘æ–‡ä»¶å‘é€çš„æ–‡æœ¬æ¶ˆæ¯

+   **history**: ä¸€ä¸ªåŒ…å«é—®é¢˜åŠå…¶å¯¹åº”å“åº”çš„å…ƒç»„ï¼ˆï¼ˆâ€œHelloâ€, â€œhiâ€ï¼‰ï¼Œï¼ˆâ€œHow are you?â€, â€œFine, thank you. What about you?â€ï¼‰ï¼‰

+   **chain**: ä¸€ä¸ªæ¥è‡ª LangChain çš„ ConversationChain å¯¹è±¡

åœ¨ä»¥ä¸‹ä»£ç ç‰‡æ®µä¸­ï¼ŒChatWrapper __call__ æ–¹æ³•é¦–å…ˆæ£€æŸ¥è¾“å…¥æ•°æ®ã€‚å¦‚æœæ˜¯éŸ³é¢‘æ ¼å¼ï¼Œå®ƒä¼šä½¿ç”¨ generate_text æ–¹æ³•è¿›è¡Œè½¬å½•ï¼Œå¦åˆ™ä¿æŒåŸæ ·ã€‚

ç„¶åï¼Œå®ƒä¼šæ£€æŸ¥ OpenAI å¯†é’¥æ˜¯å¦æ­£ç¡®åŠ è½½ã€‚å¦‚æœæ²¡æœ‰ï¼Œå®ƒä¼šæ‰“å°å‡ºâ€œPlease paste your Open AI key.â€çš„æ¶ˆæ¯ï¼Œå¹¶é™„ä¸ŠéŸ³é¢‘è½¬å½•ã€‚

å¦‚æœå¯†é’¥æ­£ç¡®åŠ è½½ï¼ŒLangChain ä»£ç†å°†è¿è¡Œï¼Œå¹¶è¾“å‡ºä¸€æ¡æ¶ˆæ¯ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™ generate_speech æ–¹æ³•ä»¥ç”Ÿæˆè¾“å‡ºéŸ³é¢‘ã€‚

```py
class ChatWrapper:
    def __init__(self, generate_speech, generate_text):
        self.lock = Lock()
        self.generate_speech = generate_speech
        self.generate_text = generate_text
        self.s2t_processor_ref = bentoml.models.get("whisper_processor:latest")
        self.processor = bentoml.transformers.load_model(self.s2t_processor_ref)

    def __call__(
        self,
        api_key: str,
        audio_path: str,
        text_message: str,
        history: Optional[Tuple[str, str]],
        chain: Optional[ConversationChain],
    ):
        """Execute the chat functionality."""
        self.lock.acquire()
        try:
            if audio_path is None and text_message is not None:
                transcription = text_message
            elif audio_path is not None and text_message in [None, ""]:
                audio_dataset = Dataset.from_dict({"audio": [audio_path]}).cast_column(
                    "audio",
                    Audio(sampling_rate=16000),
                )
                sample = audio_dataset[0]["audio"]

                if sample is not None:
                    input_features = self.processor(
                        sample["array"],
                        sampling_rate=sample["sampling_rate"],
                        return_tensors="pt",
                    ).input_features

                    transcription = self.generate_text(input_features)
                else:
                    transcription = None
                    speech = None

            if transcription is not None:
                history = history or []
                # If chain is None, that is because no API key was provided.
                if chain is None:
                    response = "Please paste your Open AI key."
                    history.append((transcription, response))
                    speech = (PLAYBACK_SAMPLE_RATE, self.generate_speech(response))
                    return history, history, speech, None, None
                # Set OpenAI key
                import openai

                openai.api_key = api_key
                # Run chain and append input.
                output = chain.run(input=transcription)
                speech = (PLAYBACK_SAMPLE_RATE, self.generate_speech(output))
                history.append((transcription, output))

        except Exception as e:
            raise e
        finally:
            self.lock.release()
        return history, history, speech, None, None
```

# Gradio ç”¨æˆ·ç•Œé¢

è¿˜è®°å¾—æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ create_block å‡½æ•°å—ï¼Ÿè¿™ä¸ªå‡½æ•°æ¥å—ä¸€ä¸ª ChatWrapper å®ä¾‹ä½œä¸ºè¾“å…¥å¹¶ç”Ÿæˆç”¨æˆ·ç•Œé¢ã€‚

```py
chat = ChatWrapper(generate_speech, generate_text)
app = FastAPI()
app = gr.mount_gradio_app(app, create_block(chat), path="/chatbot")
svc.mount_asgi_app(app, "/")
```

![](img/4077681d5e4f02c67fa9bc38c7795045.png)

åº”ç”¨çš„ UI â€” ç”¨æˆ·æˆªå›¾

è®©æˆ‘ä»¬å°† UI æ‹†è§£å¼€æ¥ï¼Œä»¥å‡†ç¡®ç†è§£æ•°æ®çš„æµåŠ¨æ–¹å¼ã€‚

**openai_api_key_textbox:** è¿™ä¸ªæ–‡æœ¬æ¡†æœŸå¾…æ‚¨åœ¨å…¶ä¸­ç²˜è´´æ‚¨çš„ OpenAI å¯†é’¥ã€‚

```py
with block:
    with gr.Row():
        gr.Markdown("<h3><center>BentoML LangChain Demo</center></h3>")

        openai_api_key_textbox = gr.Textbox(
            placeholder="Paste your OpenAI API key (sk-...)",
            show_label=False,
            lines=1,
            type="password",
        )
```

å½“ç”¨æˆ·ç²˜è´´å…¶å¯†é’¥å¹¶æäº¤æ—¶ï¼Œè¯¥å¯†é’¥ä¼šä¼ é€’ç»™æ‰§è¡Œçš„ set_openai_api_key å‡½æ•°ã€‚ç„¶åï¼Œè¿™ä¸ªå‡½æ•°è¿”å›åŠ è½½çš„é“¾ï¼Œå¹¶å°†å…¶ä¼ é€’åˆ°åº”ç”¨çš„çŠ¶æ€ä¸­ã€‚è¿™æ ·ï¼Œé“¾å¯¹è±¡å°±ä¸ä¸º Noneï¼Œå¹¶ä¸”å¯ä»¥åœ¨ä¼ é€’ç»™èŠå¤©å¯¹è±¡æ—¶ä½¿ç”¨ã€‚

```py
def set_openai_api_key(api_key: str):
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
        chain = load_chain()
        os.environ["OPENAI_API_KEY"] = ""
        return chain

agent_state = gr.State()

openai_api_key_textbox.change(
  set_openai_api_key,
  inputs=[openai_api_key_textbox],
  outputs=[agent_state],
  show_progress=False,
)
```

è¿™é‡Œæ˜¯å…¶ä»– UI ç»„ä»¶ï¼š

+   **chatbot:** æ˜¾ç¤ºèŠå¤©æœºå™¨äººè¾“å‡ºï¼Œå±•ç¤ºç”¨æˆ·æäº¤çš„æ¶ˆæ¯å’Œå›åº”ã€‚

+   **audio:** ä¸€ä¸ªæ’­æ”¾ç”¨æˆ·å½•åˆ¶çš„éŸ³é¢‘ç‰‡æ®µçš„å°éƒ¨ä»¶

+   **state**ï¼šåº”ç”¨çš„å…¨å±€çŠ¶æ€

+   **audio_message:** ç”¨æˆ·æäº¤çš„éŸ³é¢‘

+   **text_message**ï¼šç”¨æˆ·æäº¤çš„æ–‡æœ¬

é‚£ä¹ˆï¼Œå½“ç”¨æˆ·ä»éº¦å…‹é£å½•åˆ¶éŸ³é¢‘æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿï¼ˆå‘é€æ–‡æœ¬æ—¶ä¹Ÿæ˜¯å¦‚æ­¤ï¼‰

èŠå¤©å¯¹è±¡ä¼šä½¿ç”¨æ¥è‡ª UI çš„è¾“å…¥åˆ—è¡¨ [openai_api_key_textbox, audio_message, text_message, state, agent_state] æ‰§è¡Œï¼Œå¹¶è¾“å‡ºä¸€ä¸ªè¾“å‡ºåˆ—è¡¨ï¼Œè¯¥åˆ—è¡¨æ›´æ–°ä»¥ä¸‹ç»„ä»¶ [chatbot, state, audio, audio_message, text_message]

```py
audio_message.change(
    chat,
    inputs=[
        openai_api_key_textbox,
        audio_message,
        text_message,
        state,
        agent_state,
    ],
    outputs=[chatbot, state, audio, audio_message, text_message],
    show_progress=False,
)
```

ç®€è€Œè¨€ä¹‹ï¼Œè¿™å…è®¸æ˜¾ç¤ºç”¨æˆ·çš„é—®é¢˜å’Œæœºå™¨äººçš„å›ç­”ï¼Œä»¥åŠèŠå¤©è®°å½•å’Œæœ€åå“åº”çš„éŸ³é¢‘ã€‚

![](img/7493404c7f1969da8149143173c515f0.png)

ä½œè€…æˆªå›¾

# åœ¨æœ¬åœ°æä¾›åº”ç”¨

è¦åœ¨æœ¬åœ°è¿è¡Œåº”ç”¨ç¨‹åºï¼Œè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```py
poetry shell 
bentoml serve service:svc --reload --ssl-certfile ssl/cert.pem --ssl-keyfile ssl/key.pem
```

è¿™å°†å¯åŠ¨ä¸€ä¸ª SwaggerUIï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­å°è¯•ä¸¤ä¸ªç«¯ç‚¹ã€‚

è¿™ä¹Ÿåœ¨â€œ/chatbotâ€è·¯å¾„ä¸Šæä¾› Gradio åº”ç”¨ã€‚

![](img/c663a378e452b841d8d68e814613df44.png)![](img/f4395a4f7ca487b97d66faca46c2a7af.png)

ç”¨æˆ·æˆªå›¾

# éƒ¨ç½²åˆ° BentoCloud

åœ¨éƒ¨ç½²åˆ° BentoCloud ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æ„å»º bentoï¼š

```py
bentoml build
```

![](img/ae1bb1ac88c9ad0b9e40dcff04f37327.png)

ä½œè€…æˆªå›¾

ç„¶åï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¨é€å®ƒã€‚

```py
bentoml push voicegpt:jnalivxin2qcehqa
```

è¿™å°†åŒæ—¶å°†æˆ‘ä»¬çš„ **bento** å’Œåº•å±‚çš„ **models** ä¸Šä¼ åˆ°äº‘ç«¯ã€‚

![](img/39ec450b96bb2398140d984d65c0f803.png)

ä½œè€…æˆªå›¾

ç°åœ¨ï¼Œç®€å•çš„éƒ¨åˆ†ï¼šç™»å½• BentoCloudï¼Œå‰å¾€éƒ¨ç½²é€‰é¡¹å¡ï¼Œç„¶åç‚¹å‡»åˆ›å»ºã€‚

é€‰æ‹©ä¸€ä¸ªéƒ¨ç½²åç§°ï¼Œå¯ç”¨å…¬å…±è®¿é—®å¹¶é€‰æ‹©åˆé€‚çš„ bento æ ‡ç­¾ç‰ˆæœ¬ã€‚

![](img/b40f1354a8791d04fa0f81883153a831.png)

ç°åœ¨ï¼Œå®šä¹‰ API æœåŠ¡å™¨é…ç½®ï¼š

![](img/588fa38c5b62c70b9858533b17d4d278.png)

API æœåŠ¡å™¨é…ç½® â€” ä½œè€…æˆªå›¾

å¹¶ä¸ºæ¯ä¸ªè¿è¡Œå™¨è®¾ç½®é…ç½®ã€‚

![](img/2fdb1f88115a47e5a03e52774fd4ccf4.png)![](img/be11f4ea4b6b1dc8fbe9e876b1b4a58f.png)

Runners é…ç½® â€” ä½œè€…æˆªå›¾

å½“ä¸€åˆ‡å‡†å¤‡å°±ç»ªæ—¶ï¼Œç‚¹å‡»æäº¤æŒ‰é’®å¹¶ç­‰å¾…éƒ¨ç½²ã€‚

å½“ bento è¢«æ ‡è®°ä¸ºæ­£åœ¨è¿è¡Œæ—¶ï¼Œæ‚¨ä¼šçœ‹åˆ°ä¸€ä¸ªå…¬å…± URLï¼Œç”¨äºæä¾›èŠå¤©æœºå™¨äººæœåŠ¡ï¼ˆä¸è¦å¿˜è®°æ·»åŠ  HTTPSï¼‰

# ç»“è®º

è¿™ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªæœºä¼šï¼Œå‚ä¸åˆ°å›´ç»• LLM çš„æŒç»­çƒ­æ½®ä¸­ï¼Œå¹¶ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªä¸ä»…è°ƒç”¨ LangChainï¼Œè¿˜ç»“åˆå…¶ä»–æ¨¡å‹çš„åº”ç”¨ã€‚

å½“ç„¶ï¼Œæˆ‘å±•ç¤ºçš„å·¥ä½œæµç¨‹ä¸­ä¸åŒæ­¥éª¤è¿˜æœ‰æ”¹è¿›çš„ç©ºé—´ï¼šæˆ‘åªæ˜¯å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½ä¸ºä½ å¼€å§‹æ„å»ºæ›´é«˜çº§çš„æœºå™¨äººæä¾›ä¸€ä¸ªè‰¯å¥½çš„å¼€ç«¯ã€‚

# æ–°åŠ å…¥ Mediumï¼Ÿä½ å¯ä»¥ä»¥æ¯æœˆ $5 è®¢é˜…ï¼Œè§£é”å„ç§ä¸»é¢˜ï¼ˆæŠ€æœ¯ã€è®¾è®¡ã€åˆ›ä¸šâ€¦â€¦ï¼‰çš„æ— é™æ–‡ç« ã€‚ä½ å¯ä»¥é€šè¿‡ç‚¹å‡»æˆ‘çš„æ¨è[é“¾æ¥](https://ahmedbesbes.medium.com/membership)æ¥æ”¯æŒæˆ‘ã€‚

[](https://ahmedbesbes.medium.com/membership?source=post_page-----7f25af3e45df--------------------------------) [## é€šè¿‡æˆ‘çš„æ¨èé“¾æ¥åŠ å…¥ Medium - Ahmed Besbes

### é˜…è¯» Ahmed Besbes çš„æ¯ä¸ªæ•…äº‹ï¼ˆä»¥åŠ Medium ä¸Šå…¶ä»–æ•°åƒä½ä½œè€…çš„æ–‡ç« ï¼‰ã€‚ä½ çš„ä¼šå‘˜è´¹ç›´æ¥æ”¯æŒâ€¦â€¦

ahmedbesbes.medium.com](https://ahmedbesbes.medium.com/membership?source=post_page-----7f25af3e45df--------------------------------)
