# ä½¿ç”¨RayåŠ é€Ÿæ—¶é—´åºåˆ—é¢„æµ‹çš„è®­ç»ƒï¼Œç¬¬3éƒ¨åˆ†ï¼Œå…±3éƒ¨åˆ†

> åŸæ–‡ï¼š[https://towardsdatascience.com/faster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774?source=collection_archive---------10-----------------------#2023-01-24](https://towardsdatascience.com/faster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774?source=collection_archive---------10-----------------------#2023-01-24)

## ä½¿ç”¨Rayå’ŒRay AIRé€šè¿‡åˆ†å¸ƒå¼è®¡ç®—æ›´å¿«åœ°è®­ç»ƒå¤šä¸ªæ¨¡å‹

[](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)[![Christy Bergman](../Images/b8431b925cfe7bd0d3a035761fd1e7f8.png)](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)[](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------)[![Towards Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------) [Christy Bergman](https://medium.com/@christybergman?source=post_page-----632c96974774--------------------------------)

Â·

[å…³æ³¨](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff18ab4254b46&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&user=Christy+Bergman&userId=f18ab4254b46&source=post_page-f18ab4254b46----632c96974774---------------------post_header-----------) å‘å¸ƒäº [Towards Data Science](https://towardsdatascience.com/?source=post_page-----632c96974774--------------------------------) Â·11åˆ†é’Ÿé˜…è¯»Â·2023å¹´1æœˆ24æ—¥[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F632c96974774&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&user=Christy+Bergman&userId=f18ab4254b46&source=-----632c96974774---------------------clap_footer-----------)

--

[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F632c96974774&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Ffaster-time-series-forecasting-with-ray-air-distributed-computing-part-3-of-3-632c96974774&source=-----632c96974774---------------------bookmark_footer-----------)![](../Images/0b4cdf6bfa4d1843765d0442ef94d0b7.png)

å›¾ç‰‡ç”± [StableDiffusion](https://stablediffusionweb.com/#demo) ç»˜åˆ¶ï¼Œæ—¥æœŸä¸º2022å¹´1æœˆ5æ—¥ï¼ŒæŸ¥è¯¢å†…å®¹ä¸ºâ€œç»˜åˆ¶ä¸€å¹…å›¾åƒï¼Œå±•ç¤ºå¤šç§ä¸åŒçš„æ·±åº¦ç¥ç»ç½‘ç»œæ—¶é—´åºåˆ—æ¨¡å‹åŒæ—¶è®­ç»ƒçš„æ ·å­ï¼Œé£æ ¼ç±»ä¼¼Cy Twomblyâ€ã€‚

## ä»‹ç» / åŠ¨æœº

å³ä½¿åœ¨å½“å‰ç”Ÿæˆå¼ AIï¼ˆå¦‚ç¨³å®šæ‰©æ•£ã€ChatGPTï¼‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ä»£ï¼Œ**æ—¶é—´åºåˆ—é¢„æµ‹ä»ç„¶æ˜¯ä»»ä½•ä¾èµ–ä¾›åº”é“¾æˆ–èµ„æºçš„ä¸šåŠ¡çš„åŸºç¡€éƒ¨åˆ†ã€‚** ä¾‹å¦‚ï¼Œå®ƒå¯ä»¥ç”¨äºï¼š

+   [æ ¹æ®åœ°ç†ä½ç½®è¿›è¡Œåº“å­˜ç®¡ç†çš„å±¥è¡Œé¢„æµ‹](https://www.youtube.com/watch?v=3t26ucTy0Rs)ã€‚

+   [ä¸åŒäº§å“ç±»åˆ«çš„éœ€æ±‚é¢„æµ‹](https://www.anyscale.com/blog/how-anastasia-implements-ray-and-anyscale-to-speed-up-ml-processes-9x)ã€‚

+   [èµ„æºåˆ©ç”¨é¢„æµ‹](https://medium.com/kocdigital/using-ray-for-time-series-forecasting-at-scale-3355c9e4e28c) ç”¨äºæ•°æ®ä¸­å¿ƒèµ„æºé…ç½®ã€‚

**æ‰€æœ‰è¿™äº›ç”¨ä¾‹çš„å…±åŒç‚¹æ˜¯** [**åœ¨ä¸åŒæ•°æ®ç‰‡æ®µä¸Šè®­ç»ƒå¤šä¸ªæ¨¡å‹**](https://www.anyscale.com/blog/training-one-million-machine-learning-models-in-record-time-with-ray)**ã€‚** ä½¿ç”¨åˆ†å¸ƒå¼è®¡ç®—å¹¶è¡Œè®­ç»ƒã€è°ƒä¼˜å’Œéƒ¨ç½²æˆåƒä¸Šä¸‡çš„æœºå™¨å­¦ä¹ æ¨¡å‹å¯èƒ½æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼ å…¸å‹çš„æ—¶é—´åºåˆ—å»ºæ¨¡è½¯ä»¶æœ¬èº«å¹¶ä¸å…·å¤‡åˆ†å¸ƒå¼åŠŸèƒ½ã€‚

**æœ¬åšå®¢å°†å±•ç¤ºæˆ‘å¼€å§‹å°†é¢„æµ‹å·¥ä½œè´Ÿè½½è½¬æ¢ä¸ºåˆ†å¸ƒå¼è®¡ç®—çš„æŠ€å·§ã€‚** æˆ‘å°†ä½¿ç”¨æœ€æ–°çš„ [Ray v2 API](https://docs.ray.io/en/latest/)ï¼Œç»“åˆ ARIMA ä½¿ç”¨ [statsforecast](https://github.com/Nixtla/statsforecast)ã€[Prophet](https://facebook.github.io/prophet/) å’Œ [PyTorch Forecasting](https://pytorch-forecasting.readthedocs.io/en/stable/index.html) åº“ã€‚æ•°æ®æ–¹é¢ï¼Œæˆ‘å°†ä½¿ç”¨æµè¡Œçš„ [NYC Taxi æ•°æ®é›†](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)ï¼Œè¯¥æ•°æ®é›†åŒ…å«æŒ‰æ—¶é—´æˆ³å’Œåœ°ç‚¹è®°å½•çš„å†å²å‡ºç§Ÿè½¦æ¥é€ä¿¡æ¯ã€‚

Ray æ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œç”¨äºé€šè¿‡åˆ†å¸ƒå¼è®¡ç®—æ‰©å±• AI å·¥ä½œè´Ÿè½½ã€‚æœ‰å…³ Ray çš„æ¦‚è¿°ï¼Œè¯·æŸ¥çœ‹ [Ray æ–‡æ¡£](https://docs.ray.io/en/latest/) æˆ–è¿™ç¯‡ [ä»‹ç»åšå®¢æ–‡ç« ](/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8)ã€‚

![](../Images/936ddd06d94b1c8950dcf87f360c7154.png)

[Ray â€œAIR](https://docs.ray.io/en/latest/ray-air/getting-started.html)â€ï¼ˆAI Runtimeï¼‰ï¼Œè‡ª Ray 2.0 èµ·æä¾›ï¼ŒåŒ…æ‹¬ [Ray Data](https://docs.ray.io/en/latest/data/dataset.html)ã€[Ray Train](https://docs.ray.io/en/latest/train/train.html)ã€[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)ã€[RLlib](https://docs.ray.io/en/latest/rllib/index.html) å’Œ [Ray Serve](https://docs.ray.io/en/latest/serve/index.html)ã€‚å›¾ç‰‡æ¥æºäºä½œè€…ã€‚

æœ¬åšå®¢åˆ†ä¸º 4 ä¸ªéƒ¨åˆ†ï¼š

+   ä½¿ç”¨ Ray Core å¤šè¿›ç¨‹è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒã€‚

+   ä½¿ç”¨ Ray AIR è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜ã€‚

+   ä½¿ç”¨ Ray AIR è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜ï¼Œé’ˆå¯¹æ›´å°‘ä½†æ›´å¤§çš„æ¨¡å‹ã€‚

+   ä½¿ç”¨ Ray AIR å’Œ Ray Serve è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼éƒ¨ç½²ã€‚

## ç¬¬ä¸€éƒ¨åˆ†ï¼šä½¿ç”¨ Ray Core å¤šè¿›ç¨‹è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒ

å›åˆ°2021å¹´11æœˆï¼Œæˆ‘å†™äº†ä¸€ç¯‡ [åšå®¢æ–‡ç« ](https://medium.com/towards-data-science/scaling-time-series-forecasting-with-ray-arima-and-prophet-e6c856e605ee) æ¼”ç¤ºå¦‚ä½•åœ¨ AWS äº‘ä¸Šä½¿ç”¨ Ray Core å¹¶è¡Œè®­ç»ƒå¤šä¸ªé¢„æµ‹æ¨¡å‹ï¼ˆæ— è®ºæ˜¯ ARIMA è¿˜æ˜¯ Prophetï¼‰ã€‚**ä»é‚£æ—¶èµ·ï¼Œ** [**Ray å¤šè¿›ç¨‹**](https://docs.ray.io/en/latest/ray-more-libs/multiprocessing.html) **æ˜¯ä¸€ä¸ªå·¨å¤§çš„æ”¹è¿›ï¼Œä½¿äº‹æƒ…æ¯” Ray Core API æ›´åŠ ç®€å•ã€‚**

ä¸‹é¢æ˜¯ä»£ç å¤§çº²ã€‚å®Œæ•´çš„æ›´æ–°ä»£ç åœ¨ [æˆ‘çš„ GitHub](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/train_prophet_blog.ipynb) ä¸Šã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä»å‡ ä¸ªå¯¼å…¥å¼€å§‹ï¼š

```py
import time, dateutil
from typing import Tuple, List
import numpy as np
import pandas as pd
# Import libraries for reading from partitioned parquet.
import pyarrow.parquet as pq
import pyarrow.dataset as pds
# Import forecasting libraries.
import prophet
from prophet import Prophet
# Import Ray's multiprocessing library.
import ray
from ray.util.multiprocessing import Pool 
import tqdm
```

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å®šä¹‰ Python å‡½æ•°æ¥é¢„å¤„ç†æ•°æ®ã€è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ã€‚ä¸ºäº†æ›´å¿«åœ°äº†è§£åˆ†å¸ƒå¼è®¡ç®—æ¦‚å¿µï¼Œæˆ‘ä»¬å°†å‡è®¾æ—¶é—´åºåˆ—æ•°æ®å·²ç»å‡†å¤‡å¥½å¹¶æ ¹æ®æ‰€éœ€æ¨¡å‹æ‹†åˆ†ä¸ºä¸åŒçš„æ–‡ä»¶ã€‚

```py
##########
# STEP 1\. Define a Python function to read and preprocess a file of data. 
##########
def preprocess_data(file_path: str) -> Tuple[pd.DataFrame, np.int32]:

    # Read a single pyarrow parquet S3 file.
    data = pq.read_table(file_path,
           filters=[ ("pickup_location_id", "=", SAMPLE_UNIQUE_ID) ],
           columns=[ "pickup_at", "pickup_location_id", TARGET ])\
          .to_pandas()

    # Transform data.
    data["ds"] = data["pickup_at"].dt.to_period("D").dt.to_timestamp()
    data.rename(columns={TARGET: "y"}, inplace=True)
    data.rename(columns={"pickup_location_id": "unique_id"}, inplace=True)
    data.drop("pickup_at", inplace=True, axis=1)
    unique_id = data["unique_id"][0]
    return data, unique_id

##########
# STEP 2\. Define Python functions to train and evaluate a model on a file of data.
##########
def train_model(file_path: str) -> Tuple[pd.DataFrame, pd.DataFrame, 
    'prophet.forecaster.Prophet', np.int32]:

    # Prepare data from a single S3 file.
    data, unique_id = preprocess_data(file_path)

    # Split data into train, test.
    train_end = data.ds.max() - relativedelta(days=FORECAST_LENGTH - 1)
    train_df = data.loc[(data.ds <= train_end), :].copy()
    test_df = data.iloc[-(FORECAST_LENGTH):, :].copy()

    # Define Prophet model with 75% confidence interval.
    model = Prophet(interval_width=0.75, seasonality_mode="multiplicative")      

    # Train and fit Prophet model.
    model = model.fit(train_df[["ds", "y"]])
    return train_df, test_df, model, unique_id

def evaluate_model(model: 'prophet.forecaster.Prophet', train: pd.DataFrame, 
    valid: pd.DataFrame, input_value: np.int32) -> Tuple[float, pd.DataFrame]:

    # Inference model using FORECAST_LENGTH.
    future_dates = model.make_future_dataframe(
        periods=FORECAST_LENGTH, freq="D")
    future = model.predict(future_dates)

    # Merge in the actual y-values.
    future = pd.merge(future, train[['ds', 'y']], on=['ds'], how='left')
    future = pd.merge(future, valid[['ds', 'y']], on=['ds'], how='left')
    future['y'] = future.y_x.combine_first(future.y_y)
    future.drop(['y_x', 'y_y'], inplace=True, axis=1)
    future['unique_id'] = input_value

    # Calculate mean absolute forecast error.
    temp = future.copy()
    temp["forecast_error"] = np.abs(temp["yhat"] - temp["y"])
    temp.dropna(inplace=True)
    error = np.mean(temp["forecast_error"])
    return error, future

############
# STEP 3\.  Define a calling function which calls all the above functions,
#          and will be called in parallel for every data file.
############
def train__and_evaluate(file_path: str) -> Tuple[pd.DataFrame, 
    'prophet.forecaster.Prophet', pd.DataFrame, float, np.int16]:

    # Read S3 file and train a Prophet model.
    train_df, valid_df, model, unique_id = train_model(file_path)

    # Inference model and evaluate error.
    error, future = evaluate_model(model, train_df, valid_df, unique_id)
    return valid_df, model, future, error, unique_id
```

æˆ‘ä»¬å¯ä»¥ç›´æ¥ä½¿ç”¨ Ray æ ¸å¿ƒ API è°ƒç”¨ `[ray.remote](https://docs.ray.io/en/latest/ray-core/walkthrough.html)` è¿›è¡Œå¹¶è¡ŒåŒ–ï¼Œä½† Ray çš„ [å¤šè¿›ç¨‹åº“](https://docs.ray.io/en/latest/ray-more-libs/multiprocessing.html) ä½œä¸º Ray çš„åˆ†å¸ƒå¼åº“ä¹‹ä¸€ï¼Œä½¿è¿™å˜å¾—æ›´ç®€å•ã€‚

ä¸‹é¢ï¼Œå°†å¯¹ `pool` çš„è°ƒç”¨åŒ…è£…åœ¨ `tqdm` ä¸­ï¼Œå¯ä»¥è·å¾—ä¸€ä¸ªå¾ˆå¥½çš„è¿›åº¦æ¡æ¥ç›‘æ§è¿›åº¦ã€‚åœ¨å†…éƒ¨ï¼ŒRay å°†ä»»åŠ¡åˆ†é…ç»™ Ray é›†ç¾¤ä¸­çš„å·¥ä½œèŠ‚ç‚¹ï¼Œè¿™è‡ªåŠ¨å¤„ç†å¦‚å®¹é”™å’Œæ‰¹å¤„ç†ä¼˜åŒ–ç­‰é—®é¢˜ã€‚

```py
start = time.time()
# Create a pool, where each worker is assigned 1 CPU by Ray.
pool = Pool(ray_remote_args={"num_cpus": 1})

# Use the pool to run `train_model` on the data, in batches of 1.
iterator = pool.imap_unordered(train__and_evaluate, models_to_train, chunksize=1)

# Track the progress using tqdm and retrieve the results into a list.
results = list(tqdm.tqdm(iterator, total=len(models_to_train)))

# Print some training stats.
time_ray_multiprocessing = time.time() - start
print(f"Total number of models: {len(results)}")
print(f"TOTAL TIME TAKEN: {time_ray_multiprocessing/60:.2f} minutes")
print(type(results[0][0]), type(results[0][1]), type(results[0][2]), 
      type(results[0][3]), type(results[0][4]))
```

![](../Images/fdca6909d17c7ae9f3020f481ada53d7.png)

åœ¨æˆ‘çš„ MacBook Pro ç¬”è®°æœ¬ç”µè„‘ï¼ˆé…å¤‡ 8 ä¸ª CPUï¼‰ä¸Šè¿è¡Œä¸Šè¿°ç¤ºä¾‹æ—¶çš„æˆªå›¾ã€‚Ray å¤šè¿›ç¨‹çš„è¿è¡Œæ—¶é—´å¤§çº¦ä¸ºåŠåˆ†é’Ÿï¼Œæ¯”ä¸²è¡Œ Python å¿« *3.5 å€ï¼Œå³ 300.0% çš„åŠ é€Ÿã€‚ä½¿ç”¨æ›´å¤§çš„é›†ç¾¤å’Œ/æˆ–æ›´å¤§çš„æ•°æ®å¯ä»¥è·å¾—æ›´å¤šåŠ é€Ÿã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚*

ä¸Šé¢ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° Ray ä½œä¸šåœ¨ä¸åˆ° 1 åˆ†é’Ÿçš„æ—¶é—´å†…è®­ç»ƒäº† 12 ä¸ªæ¨¡å‹ã€‚

## ç¬¬ 2 éƒ¨åˆ†ï¼šä½¿ç”¨ Ray AIR è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜

ç²¾æ˜çš„è¯»è€…å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œåœ¨ä¸Šè¿°éƒ¨åˆ†ä¸­ï¼ŒRay å¤šè¿›ç¨‹è¦æ±‚æ•°æ®å·²ç»æŒ‰æ¨¡å‹ç»„ç»‡æˆä¸€ä¸ªæ–‡ä»¶ã€‚**ä½†å¦‚æœä½ çš„æ•°æ®å°šæœªæŒ‰æ¨¡å‹ç»„ç»‡æ€ä¹ˆåŠï¼Ÿ** ä½¿ç”¨ Ray AIRï¼Œä½ å¯ä»¥åœ¨è®­ç»ƒä¸åŒæ¨¡å‹çš„åŒæ—¶åœ¨åŒä¸€ç®¡é“ä¸­é¢„å¤„ç†æ•°æ®ã€‚

å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œ**å¦‚æœä½ æƒ³åŒæ—¶æ··åˆä½¿ç”¨æ¥è‡ªå¤šä¸ªåº“çš„ç®—æ³•æ€ä¹ˆåŠï¼Ÿ** Ray Tuneï¼Œä½œä¸º Ray AIR çš„ä¸€éƒ¨åˆ†ï¼Œå…è®¸ä½ è¿è¡Œå¹¶è¡Œè¯•éªŒï¼Œä»ä»»ä½• Python AI/ML åº“å’Œè¶…å‚æ•°ä¸­æ‰¾åˆ°æœ€ä½³ç®—æ³•é€‰æ‹©ï¼Œæ¯ä¸ªæ•°æ®æ®µã€‚

ä»¥ä¸‹æ˜¯é¢„å¤„ç†æ•°æ®å’Œè‡ªåŠ¨è°ƒæ•´æ¨¡å‹çš„æ­¥éª¤ã€‚è™½ç„¶è¿™äº›æ­¥éª¤ç‰¹å®šäº [Ray AIR](https://docs.ray.io/en/latest/ray-air/getting-started.html) åŠå…¶ [API](https://docs.ray.io/en/latest/ray-air/package-ref.html)ï¼Œä½†è¿™äº›æ­¥éª¤é€šå¸¸é€‚ç”¨äºå°†ä¸²è¡Œ Python è½¬æ¢ä¸ºåˆ†å¸ƒå¼ Pythonï¼š

1.  å®šä¹‰ Python å‡½æ•°æ¥ `**preprocess**` ä¸€ä¸ªæ•°æ®æ®µã€‚

1.  å®šä¹‰ Python å‡½æ•°æ¥ `**train**` å’Œ `**evaluate**` ä¸€ä¸ªæ•°æ®æ®µä¸Šçš„æ¨¡å‹ã€‚

1.  å®šä¹‰ä¸€ä¸ªè°ƒç”¨å‡½æ•°`**train_models**`ï¼Œè¯¥å‡½æ•°è°ƒç”¨æ‰€æœ‰ä¸Šè¿°å‡½æ•°ï¼Œå¹¶å°†ä¸ºTuneæœç´¢ç©ºé—´ä¸­çš„æ¯ä¸ªæ’åˆ—å¹¶è¡Œè°ƒç”¨ï¼

    åœ¨è¿™ä¸ª[**train_models**](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs)å‡½æ•°ä¸­ï¼š

    ğŸ“– è¾“å…¥å‚æ•°å¿…é¡»åŒ…æ‹¬ä¸€ä¸ªé…ç½®å­—å…¸å‚æ•°ã€‚

    ğŸ“ˆ è°ƒä¼˜æŒ‡æ ‡ï¼ˆæ¨¡å‹çš„æŸå¤±æˆ–é”™è¯¯ï¼‰å¿…é¡»ä½¿ç”¨`session.report()`è®¡ç®—å¹¶æŠ¥å‘Šã€‚

    âœ”ï¸ æ¨è`Checkpoint`ï¼ˆä¿å­˜ï¼‰æ¨¡å‹ä»¥ä¾¿äºå®¹é”™å’Œåç»­éƒ¨ç½²ã€‚

1.  **é…ç½®åˆ†å¸ƒå¼è®¡ç®—ç¼©æ”¾**ã€‚

1.  **å®šä¹‰Tuneæœç´¢ç©ºé—´**çš„æ‰€æœ‰è®­ç»ƒå‚æ•°ã€‚

1.  ï¼ˆå¯é€‰ï¼‰æŒ‡å®šè¶…å‚æ•°æœç´¢ç­–ç•¥ã€‚

1.  **è¿è¡Œå®éªŒ**ã€‚

ä¸‹é¢æ˜¯æˆ‘ä»¬å°†æ·»åŠ çš„é™„åŠ ä»£ç ï¼›å®Œæ•´ä»£ç åœ¨[æˆ‘çš„GitHub](https://github.com/christy/AnyscaleDemos/blob/6b1cea50a8c3b75bf9b680e77216f6927bdd2f85/forecasting_demos/Ray_v2/train_prophet_blog.ipynb)ä¸Šã€‚

+   ä¸‹é¢çš„`preprocess_data`å’Œ`train_model`å‡½æ•°ä¸ä¹‹å‰å®Œå…¨ç›¸åŒï¼Œåªæ˜¯å®ƒä»¬æ¥å—ä¸€ä¸ªæ–‡ä»¶åˆ—è¡¨è€Œä¸æ˜¯å•ä¸ªæ–‡ä»¶ã€‚

+   `train_models`å‡½æ•°ä¸`train_and_evaluate`å®Œå…¨ç›¸åŒï¼Œåªæ˜¯å®ƒæ¥å—ä¸€ä¸ªæ–‡ä»¶åˆ—è¡¨è€Œä¸æ˜¯å•ä¸ªæ–‡ä»¶ã€‚å®ƒè¿˜è®­ç»ƒé…ç½®ä¸­ä¼ é€’çš„ç®—æ³•ï¼Œè€Œä¸æ˜¯å›ºå®šçš„ç®—æ³•ï¼Œå¹¶è¿›è¡Œæ£€æŸ¥ç‚¹ä¿å­˜ã€‚

```py
import os
num_cpu = os.cpu_count()
# Import another forecasting library.
import statsforecast
from statsforecast import StatsForecast
from statsforecast.models import AutoARIMA
# Import Ray AIR libraries.
from ray import air, tune
from ray.air import session, ScalingConfig
from ray.air.checkpoint import Checkpoint

##########
# STEP 1\. Define Python functions to read and prepare a segment of data.
##########
def preprocess_per_uniqueid(
    s3_files: List[str], sample_location_id: np.int32) -> pd.DataFrame:

    # Load data.
    df_list = [read_data(f, sample_location_id) for f in s3_files]
    df_raw = pd.concat(df_list, ignore_index=True)

    # Transform data.
    df = transform_df(df_raw)
    df.sort_values(by="ds", inplace=True)
    return df

##########
# STEP 2\. Define Python functions to train and evaluate a model on a segment of data.
##########
def train_prophet(s3_files: List[str], sample_unique_id: np.int32,
    model_type: str) -> Tuple[pd.DataFrame, pd.DataFrame, 
                        'prophet.forecaster.Prophet', np.int32]:

    # Prepare data from a list of S3 files.
    data = preprocess_per_uniqueid(s3_files, sample_unique_id)

    # Split data into train, test.
    train_end = data.ds.max() - relativedelta(days=FORECAST_LENGTH - 1)
    train_df = data.loc[(data.ds <= train_end), :].copy()
    test_df = data.iloc[-(FORECAST_LENGTH):, :].copy()

    # Define Prophet model with 75% confidence interval.
    if model_type == "prophet_additive":
        model = Prophet(interval_width=0.75, seasonality_mode="additive")
    elif model_type == "prophet_multiplicative":
        model = Prophet(interval_width=0.75, seasonality_mode="multiplicative")     

    # Train and fit Prophet model.
    model = model.fit(train_df[["ds", "y"]])
    return train_df, test_df, model

# Train an ARIMA model. Full code not shown here.
def train_arima(): 

# Evaluate an ARIMA model. Full code not shown here.
def evaluate_arima(): 

############
# STEP 3\.  Define a calling function `train_models`, which calls all 
#          the above functions, and will be called in parallel for every 
#          permutation in the Tune search space.
############
def train_models(config: dict) -> None:

    # Get Tune parameters
    file_list = config['params']['file_list']
    model_type = config['params']['algorithm']
    sample_unique_id = config['params']['location']

    # Train model.
    if model_type == "arima":
        # Train and fit the Prophet model.
        train_df, valid_df, model = \
            train_arima(file_list, sample_unique_id)
        # Inference model and evaluate error.
        error, future = \
            evaluate_arima(model, valid_df)
    else:
        # Train and fit the Prophet model.
        train_df, valid_df, model = \
            train_prophet(file_list, sample_unique_id, model_type)
        # Inference model and evaluate error.
        error, future = evaluate_model(model, train_df, valid_df, sample_unique_id)

    # Define a model checkpoint using AIR API.
    checkpoint = ray.air.checkpoint.Checkpoint.from_dict({
          "model": model,
          "valid_df": valid_df,
          "forecast_df": future,
          "location_id": sample_unique_id,
        })
    metrics = dict(error=error)
    session.report(metrics, checkpoint=checkpoint)

############
# STEP 4\. Customize distributed compute scaling.
############
num_training_workers = min(num_cpu - 2, 32)
scaling_config = ScalingConfig(
    # Number of distributed workers.
    num_workers=num_training_workers,
    # Turn on/off GPU.
    use_gpu=False,
    # Specify resources used for trainer.
    trainer_resources={"CPU": 1},
    # Try to schedule workers on different nodes.
    placement_strategy="SPREAD")

############
# STEP 5\. Define a search space dict of all config parameters.
############
search_space = {
    "scaling_config": scaling_config,
    "params": {
        "file_list": tune.grid_search([files_to_use]),
        "algorithm": tune.grid_search(algorithms_to_use),
        "location": tune.grid_search(models_to_train),
    },
}

# Optional STEP 6\. Specify the hyperparameter tuning search strategy.

##########
# STEP 7\. Run the experiment with Ray AIR APIs.
##########
# Define a tuner object.
tuner = tune.Tuner(
        train_models,
        param_space=search_space,
        tune_config=tune.TuneConfig(
            metric="error",
            mode="min",
        ),
        run_config=air.RunConfig(
            # Redirect logs to relative path instead of default ~/ray_results/.
            local_dir="my_Tune_logs",
            # Specify name to make logs easier to find in log path.
            name="tune_nyc",
        ),
    )
# Fit the tuner object.
results = tuner.fit()
```

![](../Images/0256c490f5411ce2ac7c0261144e0f9f.png)

**é¡¶éƒ¨**ï¼šRay Tuneè¯•éªŒçŠ¶æ€çš„æˆªå›¾ï¼Œæ˜¾ç¤ºäº†768ä¸ªå€™é€‰æ¨¡å‹çš„é”™è¯¯ï¼ˆæ¯256ä¸ªNYCå‡ºç§Ÿè½¦æ¥é€ä½ç½®æœ‰3ç§ç®—æ³•é€‰æ‹©ï¼‰ã€‚åœ¨ä¸åˆ°45åˆ†é’Ÿå†…å®Œæˆè®­ç»ƒã€‚**å·¦ä¸‹**ï¼šProphetæ¨¡å‹æ¨æ–­+é¢„æµ‹å›¾ï¼ˆå®é™…å€¼ä¸ºé»‘ç‚¹ï¼Œå¸¦ç½®ä¿¡åŒºé—´çš„é¢„æµ‹ä¸ºè“è‰²ï¼‰ç”¨äºNYCå‡ºç§Ÿè½¦æ¥é€ä½ç½®=165ã€‚**å³ä¸‹**ï¼šARIMAæ¨¡å‹æ¨æ–­+é¢„æµ‹å›¾ï¼ˆå®é™…å€¼ä¸ºè“è‰²ï¼Œé¢„æµ‹ä¸ºæ©™è‰²ï¼‰ç”¨äºNYCå‡ºç§Ÿè½¦æ¥é€ä½ç½®=237ã€‚æ‰€æœ‰æ¨¡å‹ä½¿ç”¨Anyscaleåœ¨10èŠ‚ç‚¹çš„AWSé›†ç¾¤ä¸Šè®­ç»ƒï¼Œé›†ç¾¤åŒ…æ‹¬[ m5.4xlarges](https://aws.amazon.com/ec2/instance-types/m5/)å·¥ä½œèŠ‚ç‚¹å’Œä¸€ä¸ªm5.2xlargeå¤´èŠ‚ç‚¹ã€‚å›¾åƒç”±ä½œè€…æä¾›ã€‚

åœ¨ä¸Šè¿°æˆªå›¾ä¸­ï¼Œè‡ª2018å¹´1æœˆä»¥æ¥çš„æ•°æ®è¢«åˆ†ç»„å¹¶æ±‡æ€»åˆ°æ—¥çº§åˆ«ã€‚æˆ‘æ›¾å°è¯•åœ¨SageMakerä¸Šå®Œæˆè¿™é¡¹å·¥ä½œï¼Œä»…æ•°æ®å¤„ç†å°±èŠ±è´¹äº†å¤ªé•¿æ—¶é—´ï¼Œæ›´ä¸ç”¨è¯´åŒæ—¶è°ƒä¼˜å¦‚æ­¤å¤šçš„æ¨¡å‹äº†ã€‚

## ç¬¬ä¸‰èŠ‚ï¼šå¤šæ¨¡å‹åˆ†å¸ƒå¼è°ƒä¼˜ï¼ˆæ›´å¤§çš„PyTorchæ¨¡å‹ï¼‰

ç›®æ ‡é€šå¸¸æ˜¯åˆ›å»ºä¸€äº›æ›´å¤§çš„æ¨¡å‹ï¼Œä¾‹å¦‚æŒ‰åœ°ç†åŒºåŸŸåˆ’åˆ†çš„æ¨¡å‹ï¼Œå…¶ä¸­åªæœ‰å°‘æ•°å‡ ä¸ªè¿™æ ·çš„åŒºåŸŸã€‚ä¸€å¹´å‰ï¼Œå³2021å¹´12æœˆï¼Œæˆ‘å†™äº†ä¸€ç¯‡[åšå®¢æ–‡ç« ](https://medium.com/towards-data-science/how-to-train-time-series-forecasting-faster-using-ray-part-2-of-2-aacba89ca49a)ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Ray Lightningè®­ç»ƒæ›´å¤§çš„PyTorché¢„æµ‹æ¨¡å‹ã€‚**è‡ªé‚£æ—¶ä»¥æ¥ï¼Œä¸€ä¸ªé‡å¤§æ”¹è¿›æ˜¯ï¼Œæ„Ÿè°¢** [**Anyscale Workspaces**](https://docs.anyscale.com/user-guide/develop-and-debug/workspaces)**ï¼Œç¬”è®°æœ¬ç”µè„‘å’Œäº‘ä¹‹é—´çš„ä»£ç å¼€å‘åˆ‡æ¢æ›´åŠ æ— ç¼ã€‚**

è¿™äº›è¾ƒå¤§çš„æ¨¡å‹æœ‰æ—¶è¢«ç§°ä¸ºâ€œå…¨çƒæ¨¡å‹â€ï¼Œå› ä¸ºåªæœ‰ä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨å¤šä¸ªä¸åŒæ—¶é—´åºåˆ—ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œä¸æ˜¯æ¯ä¸ªæ—¶é—´åºåˆ—ä¸€ä¸ªæ¨¡å‹ï¼ˆProphet æˆ– ARIMAï¼‰ã€‚

è¯·æŸ¥çœ‹ [æˆ‘çš„ GitHub](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/ray_air/pytorch_forecasting.ipynb) ä»¥è·å–å®Œæ•´çš„ [PyTorch Forecasting](https://pytorch-forecasting.readthedocs.io/en/stable/index.html) ä»£ç ï¼Œå…¶ä¸­å±•ç¤ºäº†æœ€æ–°çš„ Ray AIR API ä¸ [Ray Lightning](https://docs.ray.io/en/latest/tune/examples/tune-pytorch-lightning.html)ã€‚ä½ éœ€è¦å°†é›†ç¾¤ ID æ·»åŠ åˆ°æ•°æ®ä¸­ï¼Œç„¶åè°ƒä¼˜æ­¥éª¤ä¸ç¬¬ 2 èŠ‚ä¸­çœ‹åˆ°çš„ç›¸åŒï¼š

```py
# Import forecasting libraries.
import torch
import pytorch_lightning as pl
import pytorch_forecasting as ptf 
import tensorboard as tb  
# Import ray libraries.
import ray_lightning
from ray_lightning import RayStrategy
from ray_lightning.tune import get_tune_resources, TuneReportCheckpointCallback
from ray import air, tune
from ray.tune.schedulers import ASHAScheduler

# Define a tuner object.
tuner = tune.Tuner(
        tune.with_resources(
            train_with_parameters,
            resources=get_tune_resources(num_workers=num_training_workers),
        ),
        tune_config=tune.TuneConfig(
            metric="loss",
            mode="min",
            scheduler=scheduler,
        ),
        run_config=air.RunConfig(
            # Redirect logs to relative path instead of default ~/ray_results/.
            local_dir="my_Tune_logs",
            # Specify name to make logs easier to find in log path.
            name="ptf_nyc",
        ),
        param_space=FORECAST_CONFIG,
    )

# Fit the tuner object.
results = tuner.fit()

# Get checkpoint for best model from results object, code not shown.

# Plot inference forecasts for some unique_ids.
some_unique_ids = [25, 41, 14, 24, 4]
for idx in some_unique_ids:
    best_model.plot_prediction(x, raw_predictions, idx=idx)
```

![](../Images/dc844e0d7e1c866b57556638403bbad8.png)

**é¡¶éƒ¨**ã€‚åœ¨è°ƒä¼˜å…­ä¸ª PyTorch Forecasting TemporalFusionTransformer æ¨¡å‹æ—¶æˆªå›¾ Ray Tune Trial çŠ¶æ€ã€‚ï¼ˆ3 ä¸ªå­¦ä¹ ç‡ï¼Œ2 ä¸ªçº½çº¦å¸‚å‡ºç§Ÿè½¦ä½ç½®ç°‡ï¼‰ã€‚æ€»è¿è¡Œæ—¶é—´å°‘äº 2 åˆ†é’Ÿã€‚åœ¨ 2 èŠ‚ç‚¹çš„ AWS é›†ç¾¤ï¼ˆm5.4xlarge å·¥ä½œèŠ‚ç‚¹å’Œä¸€ä¸ª m5.2xlarge ä¸»èŠ‚ç‚¹ï¼‰ä¸Šè¿è¡Œï¼Œæ—¶é—´ä¸è¶…è¿‡ 2 åˆ†é’Ÿã€‚**åº•éƒ¨**ï¼šä½¿ç”¨å•ä¸ªæ¨¡å‹å¯¹å¤šä¸ªå‡ºç§Ÿè½¦æ¥å®¢åœ°ç‚¹è¿›è¡Œçš„æ¨æ–­é¢„æµ‹å›¾ã€‚

è¯·æ³¨æ„ï¼Œä¸ ARIMA å’Œ Prophet æ¨¡å‹ï¼ˆæ¯ä¸ª unique_id ä¸€ä¸ªæ¨¡å‹ï¼‰ä¸åŒï¼Œè¿™äº›è¾ƒå¤§çš„æ¨¡å‹æ¯æ¬¡åŒ…å«å¯¹å¤šä¸ª unique_ids çš„æ¨æ–­ã€‚

## ç¬¬ 4 èŠ‚ï¼šä½¿ç”¨ Ray AIR å’Œ Ray Serve è¿›è¡Œå¤šæ¨¡å‹åˆ†å¸ƒå¼éƒ¨ç½²

åœ¨éƒ¨ç½²ä¹‹å‰ï¼Œä½ å¿…é¡»å†³å®šä½ çš„éƒ¨ç½²æ˜¯éœ€è¦ä¸€ä¸ªåœ¨çº¿ã€å§‹ç»ˆè¿è¡Œçš„ http æœåŠ¡ï¼Œè¿˜æ˜¯ç¦»çº¿çš„ï¼ˆæŒ‰éœ€è°ƒç”¨çš„ Python æœåŠ¡ï¼‰ã€‚ä¸‹é¢ï¼Œæˆ‘æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ–°çš„ [Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) å’Œ [Ray Serve](https://docs.ray.io/en/latest/serve/index.html) è¿›è¡Œç¦»çº¿éƒ¨ç½²ã€‚

ç¦»çº¿éƒ¨ç½²çš„æ­¥éª¤æ˜¯ï¼š

**æ­¥éª¤ 1**ã€‚ä½¿ç”¨ Ray AIR æ£€æŸ¥ç‚¹å®ä¾‹åŒ–ä¸€ä¸ªæ‰¹é‡é¢„æµ‹å™¨ã€‚

**æ­¥éª¤ 2**ã€‚åˆ›å»ºä¸€äº›æµ‹è¯•æ•°æ®ã€‚

**æ­¥éª¤ 3**ã€‚è¿è¡Œ `batch_predictor.predict(test_data)`ã€‚

å°†ä¸Šè¿°æ­¥éª¤ 3 æ›¿æ¢ä¸ºè‡ªå®šä¹‰é¢„æµ‹å™¨çš„ä»¥ä¸‹æ­¥éª¤ï¼š

**æ­¥éª¤ 3**ã€‚é€šè¿‡ä½¿ç”¨ Ray è£…é¥°å™¨ `@serve.deployment` å®šä¹‰ä¸€ä¸ª Ray Serve éƒ¨ç½²ç±»ã€‚

**æ­¥éª¤ 4**ã€‚éƒ¨ç½²é¢„æµ‹å™¨ã€‚

**æ­¥éª¤ 5**ã€‚æŸ¥è¯¢éƒ¨ç½²å¹¶è·å–ç»“æœã€‚

ä¸Šè¿°æ­¥éª¤ 3â€“5 ä»…åœ¨ä½¿ç”¨è‡ªå®šä¹‰é¢„æµ‹å™¨ï¼ˆå¦‚ ARIMAã€Prophet æˆ– PyTorch Forecastingï¼‰æ—¶éœ€è¦ã€‚

å¦åˆ™ï¼Œå¯¹äºé›†æˆäº† Ray AIR çš„ ML åº“ï¼ˆHuggingFace transformersã€PyTorchã€TensorFlowã€Scikit-learnã€XGBoost æˆ– LightGBMï¼‰ï¼Œä½ åªéœ€è°ƒç”¨ `batch_predictor.predict(test_data)` å³å¯ã€‚

ç»§ç»­ä¸Šä¸€èŠ‚ä¸­å…³äº PyTorch Forecasting çš„ç¤ºä¾‹ï¼Œä¸‹é¢æ˜¯éƒ¨ç½²ä»£ç ã€‚å®Œæ•´ä»£ç åœ¨ [æˆ‘çš„ GitHub](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/ray_air/pytorch_forecasting.ipynb) ä¸Šã€‚

```py
import pickle
import numpy as np
import pandas as pd
import pyarrow
import pyarrow.parquet as pq
# Import forecasting libraries. 
import torch
import pytorch_lightning as pl
import pytorch_forecasting as ptf
# Import ray libraries.
import ray
from ray import serve

##########
# STEP 1\. Instantiate a batch predictor from checkpoint.
##########
batch_predictor = ptf.models.TemporalFusionTransformer.load_from_checkpoint(model_path)

##########
# STEP 2\. Create some test data. 
##########
# Being lazy, pretend the last test data is our out-of-sample test data.
max_prediction_length = FORECAST_CONFIG['forecast_horizon']
new_prediction_data = df.copy()
new_prediction_data["time_idx"] = new_prediction_data["time_idx"] + max_prediction_length
# Convert data from pandas to PyTorch tensors.
_, _, test_loader = convert_pandas_pytorch_timeseriesdata(
    new_prediction_data, FORECAST_CONFIG)

##########
# STEP 3\. Define a Ray Serve deployment class.
##########
@serve.deployment
class ForecastPredictor:
    def __init__(self, predictor, test_data):
        self.predictor = predictor
        self.test_data = test_data

    def predict(self):
        raw_predictions, x = \
          self.predictor.predict(self.test_data, mode="raw", return_x=True)
        return x, raw_predictions

    def __call__(self):
        x, raw_predictions = self.predict()
        return [x, raw_predictions]

##########
# STEP 4\. Deploy the predictor.
##########
# Bind arguments to the Class constructor.
my_first_deployment = ForecastPredictor.bind(
    predictor=batch_predictor,
    test_data=test_loader)

##########
# STEP 5\. Query the deployment and get the result.
##########
# Get handle from serve.run().
handle = serve.run(my_first_deployment)

# ray.get() the results from the handle.
ray_return = ray.get(handle.remote())
new_x = ray_return[0]
new_pred = ray_return[1]
```

![](../Images/352284bfab1b2d33c66eb92fe5f433e5.png)

**å·¦ä¾§**ï¼šRay ä»ªè¡¨æ¿çš„æˆªå›¾ï¼ˆé»˜è®¤åœ¨`localhost:8265`çš„ä¸»èŠ‚ç‚¹ä¸Šè®¿é—®ï¼‰åœ¨æœåŠ¡æœŸé—´çš„æƒ…å†µã€‚**å³ä¾§**ï¼šRay ä»ªè¡¨æ¿åœ¨è¿è¡Œä¸Šè¿°ç¤ºä¾‹æ—¶çš„æˆªå›¾ã€‚ä½ å¯ä»¥çœ‹åˆ°åœ¨è‡ªåŠ¨ç¼©æ”¾ä¸­æœ‰ 5 ä¸ªå³°å€¼ï¼Œå› ä¸ºåœ¨éƒ¨ç½²æœ€ç»ˆè®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘å¯¹è®­ç»ƒä»£ç è¿›è¡Œäº† 5 æ¬¡ä¸åŒçš„è¿­ä»£ã€‚Anyscale è¿è¡Œåœ¨ 3 èŠ‚ç‚¹ AWS é›†ç¾¤ä¸Šï¼Œå…¶ä¸­åŒ…æ‹¬[ m5.4xlarges](https://aws.amazon.com/ec2/instance-types/m5/) å·¥ä½œèŠ‚ç‚¹å’Œ 1 ä¸ª m5.2xlarge ä¸»èŠ‚ç‚¹ã€‚å›¾ç‰‡ç”±ä½œè€…æä¾›ã€‚

ä¸Šè¿°å³ä¾§çš„æˆªå›¾å±•ç¤ºäº†åœ¨è®­ç»ƒå’ŒæœåŠ¡æœŸé—´ Ray é›†ç¾¤çš„å¯è§‚å¯Ÿæ€§ã€‚å¦‚æœä½ éœ€è¦å¯¹é¢„æµ‹ç»“æœè¿›è¡Œåå¤„ç†ï¼Œæˆ‘åœ¨[è¿™ä¸ªç¬”è®°æœ¬çš„æœ«å°¾æœ‰ä¸€ä¸ªç¤ºä¾‹](https://github.com/christy/AnyscaleDemos/blob/main/forecasting_demos/Ray_v2/train_prophet_blog.ipynb)ã€‚

## ç»“è®º

æ€»ä¹‹ï¼Œæœ¬åšå®¢å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¼€æº Ray åœ¨åˆ†å¸ƒå¼è®¡ç®—ä¸­å¹¶è¡Œè®­ç»ƒå’Œè°ƒæ•´å¤šä¸ªæ¨¡å‹ã€‚æ¨¡å‹ä¸å¿…éƒ½æ˜¯ç›¸åŒç±»å‹çš„ï¼Œå¯ä»¥ä»ä»»ä½• AI/ML Python åº“ä¸­æ··åˆåŒ¹é…ã€‚

Ray AIR API æ¸…æ™°ã€ç›´è§‚ï¼Œå¹¶éšè—äº†è®¸å¤šåˆ†å¸ƒå¼è®¡ç®—çš„å¤æ‚æ€§ï¼Œå› æ­¤å¯ä»¥è½»æ¾å®Œæˆè®¸å¤šå¤æ‚çš„ä»»åŠ¡ï¼Œå¦‚æ—©æœŸåœæ­¢ã€ASHA è°ƒåº¦ã€æ£€æŸ¥ç‚¹å’Œéƒ¨ç½²ã€‚

è¿›ä¸€æ­¥å­¦ä¹ ï¼š

+   é˜…è¯»[Ray æ–‡æ¡£](https://docs.ray.io/en/latest/)ï¼Œè·å–è¯¦ç»†çš„è§£é‡Šå’Œç¤ºä¾‹ã€‚

+   åœ¨[Slack](https://docs.google.com/forms/d/e/1FAIpQLSfAcoiLCHOguOm8e7Jnn-JJdZaCxPGjgVCvFijHB5PLaQLeig/viewform)å’Œ[Discuss](https://discuss.ray.io/)ä¸Šæé—®ã€‚

+   ä½¿ç”¨[Anyscale](https://docs.anyscale.com/user-guide/develop-and-debug/workspaces#workspaces-tutorial)ï¼Œè¿™ä½¿å¾—å¯åŠ¨é›†ç¾¤å¹¶åœ¨äº‘ä¸Šè¿è¡Œä½ çš„ä»£ç å˜å¾—ç®€å•ï¼ˆè·å–é‚€è¯·ç [è¿™é‡Œ](https://www.anyscale.com/signup)ï¼‰ã€‚
