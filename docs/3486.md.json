["```py\nimport numpy as np\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the Breast Cancer dataset\ndata = load_breast_cancer()\nX = data.data\ny = data.target\n```", "```py\ncancer = load_breast_cancer()\ndf = pd.DataFrame(np.c_[cancer['data'], cancer['target']],\n                  columns= np.append(cancer['feature_names'], ['target']))\ndf.head()\n```", "```py\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Fit a Decision Tree Classifier on the non-PCA-transformed dataset\noriginal_tree = DecisionTreeClassifier(random_state=42)\noriginal_tree.fit(X_train, y_train)\n\n# Predictions on the original dataset\noriginal_predictions = original_tree.predict(X_test)\n```", "```py\n# Finding the optimal number of PCA components using the elbow method\npca = PCA()\npca.fit(X_train)\n\nexplained_variance = pca.explained_variance_ratio_\ncumulative_explained_variance = np.cumsum(explained_variance)\n\n# Plot explained variance\nplt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')\nplt.title('PCA Explained Variance')\nplt.grid()\nplt.show()\n\n# Determine the optimal number of components (elbow point)\noptimal_num_components = np.where(cumulative_explained_variance >= 0.99999)[0][0] + 1\n\nprint(f\"Optimal number of PCA components: {optimal_num_components}\")\n```", "```py\n# Apply PCA with the optimal number of components\npca = PCA(n_components=optimal_num_components, svd_solver=\"full\")\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n\n# Fit a Decision Tree Classifier on the PCA-transformed dataset\npca_tree = DecisionTreeClassifier(random_state=42)\npca_tree.fit(X_train_pca, y_train)\n\n# Predictions on the PCA-transformed dataset\npca_predictions = pca_tree.predict(X_test_pca)\n```", "```py\n# Confusion matrix\npca_cm = confusion_matrix(y_test, pca_predictions)\n\n# Precision and Recall scores for the original dataset\noriginal_precision = precision_score(y_test, original_predictions, average=’weighted’)\noriginal_recall = recall_score(y_test, original_predictions, average='weighted')\noriginal_accuracy = accuracy_score(y_test, original_predictions)\n\n# Precision and Recall scores\npca_precision = precision_score(y_test, pca_predictions)\npca_recall = recall_score(y_test, pca_predictions)\npca_accuracy = accuracy_score(y_test, pca_predictions)\n\n# Output precision and recall scores\nprint(f\"Original Dataset - Precision: {original_precision:.4f}, Recall: {original_recall:.4f}, Accuracy: {original_accuracy:.4f}\")\nprint(f\"PCA-Transformed Dataset - Precision: {pca_precision:.4f}, Recall: {pca_recall:.4f}, Accuracy: {pca_accuracy:.4f}\")\n```", "```py\n# Plot the confusion matrices\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nsns.heatmap(original_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=data.target_names, yticklabels=data.target_names)\nplt.title(\"Original Decision Tree Confusion Matrix\\nPrecision: {:.2f}, Recall: {:.2f}\".format(original_precision, original_recall))\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.subplot(1, 2, 2)\nsns.heatmap(pca_cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=data.target_names, yticklabels=data.target_names)\nplt.title(\"Decision Tree with PCA Confusion Matrix\\nPrecision: {:.2f}, Recall: {:.2f}\".format(pca_precision, pca_recall))\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.tight_layout()\nplt.show()\n```", "```py\n# Get the explained variance ratio of each principal component\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Get the PCA components\npca_components = pca.components_\n\n# Create a DataFrame to display the contributions of original features to each principal component\ndf_components = pd.DataFrame(data=pca_components, columns=data.feature_names)\n\n# Print the top features contributing to each principal component\nfor i in range(optimal_num_components):\n    print(f\"Top features for PC{i+1}:\")\n    sorted_features = df_components.iloc[i].abs().sort_values(ascending=False)\n    print(sorted_features.head())\n    print(\"\\nExplained Variance Ratio:\", explained_variance_ratio[i])\n    print(\"=\" * 50)\n```"]