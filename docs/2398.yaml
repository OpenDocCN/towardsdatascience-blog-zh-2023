- en: All You Need to Know about In-Context Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: åŸæ–‡ï¼š[https://towardsdatascience.com/all-you-need-to-know-about-in-context-learning-55bde1180610?source=collection_archive---------7-----------------------#2023-07-25](https://towardsdatascience.com/all-you-need-to-know-about-in-context-learning-55bde1180610?source=collection_archive---------7-----------------------#2023-07-25)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '| IN CONTEXT LEARNING | LARGE LANGUAGE MODELS| LLMs'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What is and how does it work what makes Large Language Models so powerful
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)[![Salvatore
    Raieli](../Images/6bb4520e2df40d20283e7283141b5e06.png)](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)[](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)
    [Salvatore Raieli](https://salvatore-raieli.medium.com/?source=post_page-----55bde1180610--------------------------------)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Â·
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Ff1a08d9452cd&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-you-need-to-know-about-in-context-learning-55bde1180610&user=Salvatore+Raieli&userId=f1a08d9452cd&source=post_page-f1a08d9452cd----55bde1180610---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----55bde1180610--------------------------------)
    Â·19 min readÂ·Jul 25, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F55bde1180610&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-you-need-to-know-about-in-context-learning-55bde1180610&user=Salvatore+Raieli&userId=f1a08d9452cd&source=-----55bde1180610---------------------clap_footer-----------)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F55bde1180610&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fall-you-need-to-know-about-in-context-learning-55bde1180610&source=-----55bde1180610---------------------bookmark_footer-----------)![](../Images/7f1b46371aebe6ca8e4684f7f9be78fa.png)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [ğŸ‡¸ğŸ‡® Janko FerliÄ](https://unsplash.com/ko/@itfeelslikefilm?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: â€œFor me context is the key â€” from that comes the understanding of everything.â€
    â€” Kenneth Noland
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In-context learning (ICL) is one of the most surprising model skills. Observed
    with GPT-3 it caught the authorsâ€™ attention. **Exactly what is ICL? More importantly,
    what gives rise to it?**
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'This article is divided into different sections, for each section we will answer
    these questions:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: What is In-Context Learning (ICL)? Why this is interesting? Why it is useful?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ï¼Ÿä¸ºä»€ä¹ˆè¿™å¾ˆæœ‰è¶£ï¼Ÿä¸ºä»€ä¹ˆå®ƒæœ‰ç”¨ï¼Ÿ
- en: 'The mystery of ICL: how does it work? Is the training data? is the prompt?
    it is the architecture?'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICL çš„ç¥ç§˜ï¼šå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿæ˜¯è®­ç»ƒæ•°æ®ï¼Ÿæ˜¯æç¤ºï¼Ÿè¿˜æ˜¯æ¶æ„ï¼Ÿ
- en: What is the future of ICL? What are the remaining challenges?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ICL çš„æœªæ¥æ˜¯ä»€ä¹ˆï¼Ÿå‰©ä¸‹çš„æŒ‘æˆ˜æœ‰å“ªäº›ï¼Ÿ
- en: Check the list of references at the end of the article, I provide also some
    suggestions to deepen the topics.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æŸ¥çœ‹æ–‡ç« æœ«å°¾çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ï¼Œæˆ‘è¿˜æä¾›äº†ä¸€äº›æ·±å…¥æ¢è®¨ä¸»é¢˜çš„å»ºè®®ã€‚
- en: What is In-Context Learning (ICL)?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ï¼Ÿ
