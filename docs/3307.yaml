- en: LoRA — Intuitively and Exhaustively Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/lora-intuitively-and-exhaustively-explained-e944a6bff46b?source=collection_archive---------1-----------------------#2023-11-07](https://towardsdatascience.com/lora-intuitively-and-exhaustively-explained-e944a6bff46b?source=collection_archive---------1-----------------------#2023-11-07)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Natural Language Processing | Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Exploring the modern wave of machine learning with cutting edge fine tuning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@danielwarfield1?source=post_page-----e944a6bff46b--------------------------------)[![Daniel
    Warfield](../Images/c1c8b4dd514f6813e08e401401324bca.png)](https://medium.com/@danielwarfield1?source=post_page-----e944a6bff46b--------------------------------)[](https://towardsdatascience.com/?source=post_page-----e944a6bff46b--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----e944a6bff46b--------------------------------)
    [Daniel Warfield](https://medium.com/@danielwarfield1?source=post_page-----e944a6bff46b--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fbdc4072cbfdc&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flora-intuitively-and-exhaustively-explained-e944a6bff46b&user=Daniel+Warfield&userId=bdc4072cbfdc&source=post_page-bdc4072cbfdc----e944a6bff46b---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----e944a6bff46b--------------------------------)
    ·18 min read·Nov 7, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fe944a6bff46b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flora-intuitively-and-exhaustively-explained-e944a6bff46b&user=Daniel+Warfield&userId=bdc4072cbfdc&source=-----e944a6bff46b---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe944a6bff46b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Flora-intuitively-and-exhaustively-explained-e944a6bff46b&source=-----e944a6bff46b---------------------bookmark_footer-----------)![](../Images/ea13e6af7448529f375da8c5e914e006.png)'
  prefs: []
  type: TYPE_NORMAL
- en: “Lora The Tuner” By Daniel Warfield using MidJourney. All images by the author
    unless otherwise specified.
  prefs: []
  type: TYPE_NORMAL
- en: Fine tuning is the process of tailoring a machine learning model to a specific
    application, which can be vital in achieving consistent and high quality performance.
    In this article we’ll discuss “Low-Rank Adaptation” (LoRA), one of the most popular
    fine tuning strategies. First we’ll cover the theory, then we’ll use LoRA to fine
    tune a language model, improving its question answering abilities.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/88f897196d79cc9be45b43f42a722cb2.png)'
  prefs: []
  type: TYPE_IMG
- en: The results of fine tuning. Before fine tuning the output is gibberish, the
    model repeats the question and a bogus answers repeatedly. After fine tuning the
    output is clear, concise, and accurate.
  prefs: []
  type: TYPE_NORMAL
- en: '**Who is this useful for?** Anyone interested in learning state of the art
    machine learning approaches. We’ll be focusing on language modeling in this article,
    but LoRA is a popular choice in many machine learning applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '**How advanced is this post?** This article should be approachable to novice
    data scientists and enthusiasts, but contains topics which are critical in advanced
    applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-requisites:** While not required, a solid working understanding of large
    language models (LLMs) would probably be…'
  prefs: []
  type: TYPE_NORMAL
