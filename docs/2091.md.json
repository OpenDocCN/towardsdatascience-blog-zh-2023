["```py\nfrom sklearn.datasets import make_regression\nfrom sklearn.svm import LinearSVR\nfrom sklearn.multioutput import MultiOutputRegressor\n\n# Construct a toy dataset\nRANDOM_STATE = 100\nxs, ys = make_regression(\n    n_samples=2000, n_features=7, n_informative=5, \n    n_targets=3, random_state=RANDOM_STATE, noise=0.2\n)\n\n# Wrap the Linear SVR to enable multi-output modeling\nwrapped_model = MultiOutputRegressor(\n    LinearSVR(random_state=RANDOM_STATE)\n).fit(xs, ys)\n```", "```py\nfrom sklearn.datasets import make_regression\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Construct a toy dataset\nRANDOM_STATE = 100\nxs, ys = make_regression(\n    n_samples=2000, n_features=7, n_informative=5, \n    n_targets=3, random_state=RANDOM_STATE, noise=0.2\n)\n\n# Train a multi-output model directly using a decision tree\nmodel = DecisionTreeRegressor(random_state=RANDOM_STATE).fit(xs, ys)\n```", "```py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.datasets import make_classification\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Construct a toy dataset\nRANDOM_STATE = 100\ndata = make_classification(n_samples=2000, n_features=7, n_classes=1, random_state=RANDOM_STATE, class_sep=2, n_informative=3)\ndf = pd.DataFrame(data[0]).applymap(lambda x: int(abs(x)))\n\n#####\n# Step 1: Create training and validation datasets\n#####\n\nTRAIN_TEST_SPLIT_FRAC = 0.8\nn = int(df.shape[0]*TRAIN_TEST_SPLIT_FRAC)\n\ndf_training, df_validation = df.iloc[:n, :], df.iloc[n:, :].reset_index(drop=True)\n\n#####\n# Step 2: Create noisy/masked copies of training and validation datasets\n#####\n\n# Example of random masking where each decision to mask a value is framed as a coin toss (Bernoulli event)\ndef random_masking(value): return -1 if np.random.binomial(n=1, p=0.5) else value\ndf_training_masked = df_training.applymap(random_masking)\ndf_validation_masked = df_validation.applymap(random_masking)\n\n#####\n# Step 3: Train a multi-output model to be used as a denoising-based imputer\n#####\n\n# Notice that the masked data is used to model the original data\nmodel = DecisionTreeClassifier(random_state=RANDOM_STATE).fit(X=df_training_masked, y=df_training)\n\n#####\n# Step 4: Apply imputer to masked validation dataset\n#####\n\ndf_validation_imputed = pd.DataFrame(model.predict(df_validation_masked))\n\n#####\n# Step 5: Evaluate imputation accuracy on validation dataset\n#####\n\n# Check basic top-1 accuracy metric, accounting for inflated results\nfeature_accuracy_dict = {}\nfor i in range(df_validation_masked.shape[1]):\n    # Get list of row indexes where feature i was masked, i.e., needed to be imputed\n    masked_indexes = df_validation_masked.index[df_validation_masked[i] == -1]\n    # Compute imputation accuracy only for those rows for feature i\n    feature_accuracy_dict[i] = (df_validation_imputed.iloc[masked_indexes, i] == df_validation.iloc[masked_indexes, i]).mean()\nprint(feature_accuracy_dict)\n```"]