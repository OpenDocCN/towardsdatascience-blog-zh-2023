- en: 'Decoding the Symphony of Sound: Audio Signal Processing for Musical Engineering'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解码声音交响曲：用于音乐工程的音频信号处理
- en: 原文：[https://towardsdatascience.com/decoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5?source=collection_archive---------0-----------------------#2023-08-08](https://towardsdatascience.com/decoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5?source=collection_archive---------0-----------------------#2023-08-08)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://towardsdatascience.com/decoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5?source=collection_archive---------0-----------------------#2023-08-08](https://towardsdatascience.com/decoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5?source=collection_archive---------0-----------------------#2023-08-08)
- en: The Ultimate Guide to Time and Frequency Domain Audio Feature Extraction using
    Python
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 进行时间和频率域音频特征提取的终极指南
- en: '[](https://namanagr03.medium.com/?source=post_page-----c66f09a4d0f5--------------------------------)[![Naman
    Agrawal](../Images/6bb885397aec17f5029cfac7f01edad9.png)](https://namanagr03.medium.com/?source=post_page-----c66f09a4d0f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c66f09a4d0f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c66f09a4d0f5--------------------------------)
    [Naman Agrawal](https://namanagr03.medium.com/?source=post_page-----c66f09a4d0f5--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://namanagr03.medium.com/?source=post_page-----c66f09a4d0f5--------------------------------)[![Naman
    Agrawal](../Images/6bb885397aec17f5029cfac7f01edad9.png)](https://namanagr03.medium.com/?source=post_page-----c66f09a4d0f5--------------------------------)[](https://towardsdatascience.com/?source=post_page-----c66f09a4d0f5--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----c66f09a4d0f5--------------------------------)
    [Naman Agrawal](https://namanagr03.medium.com/?source=post_page-----c66f09a4d0f5--------------------------------)'
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ·
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bbb90aa727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5&user=Naman+Agrawal&userId=5bbb90aa727&source=post_page-5bbb90aa727----c66f09a4d0f5---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c66f09a4d0f5--------------------------------)
    ·38 min read·Aug 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc66f09a4d0f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5&user=Naman+Agrawal&userId=5bbb90aa727&source=-----c66f09a4d0f5---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[关注](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5bbb90aa727&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5&user=Naman+Agrawal&userId=5bbb90aa727&source=post_page-5bbb90aa727----c66f09a4d0f5---------------------post_header-----------)
    发表在 [Towards Data Science](https://towardsdatascience.com/?source=post_page-----c66f09a4d0f5--------------------------------)
    ·38 分钟阅读·2023年8月8日[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Fc66f09a4d0f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5&user=Naman+Agrawal&userId=5bbb90aa727&source=-----c66f09a4d0f5---------------------clap_footer-----------)'
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: --
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc66f09a4d0f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5&source=-----c66f09a4d0f5---------------------bookmark_footer-----------)![](../Images/ac09b22a9b2c26e99c2e075151c5184a.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc66f09a4d0f5&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fdecoding-the-symphony-of-sound-audio-signal-processing-for-musical-engineering-c66f09a4d0f5&source=-----c66f09a4d0f5---------------------bookmark_footer-----------)![](../Images/ac09b22a9b2c26e99c2e075151c5184a.png)'
- en: Image by [OpenClipart-Vectors](https://pixabay.com/users/openclipart-vectors-30363/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=153212)
    from [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=153212)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [OpenClipart-Vectors](https://pixabay.com/users/openclipart-vectors-30363/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=153212)
    提供，来自 [Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=153212)
- en: Contents
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内容
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍
- en: Time Domain Feature Extraction
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 时间域特征提取
- en: '2.1 Basics of Audio Signal Processing: Frame Size and Hop Length'
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2.1 音频信号处理基础：帧大小和跳步长度
- en: '2.2 Feature 1: Amplitude Envelope'
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2.2 特征 1：幅度包络
- en: '2.3 Feature 2: Root Mean Square Energy'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.4 Feature 3: Crest Factor'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.5 Feature 4: Zero Crossing Rate'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Frequency Domain Feature Extraction
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '3.1 Feature 5: Band Energy Ratio'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.2 Feature 6: Spectral Centroid'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.3 Feature 7: Spectral Bandwidth'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.4 Feature 8: Spectral Flatness'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: References
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ability to process and analyze data of different kinds to obtain practical
    insights is one of the most vital skills of the information age. Data is all around
    us: from the books we read to the movies we watch, from the Instagram posts we
    like to the music we listen to. In this article, we will try to understand the
    basics of Audio Signal Processing:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: How does a computer read an audio signal
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are time and frequency domain features?
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are these features extracted?
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do these features need to be extracted?
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In particular, we will cover the following features in detail:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: 'Time Domain features: Amplitude envelope, root mean square energy, crest factor
    (and peak-to-average power ratio), zero crossing rate.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Frequency Domain Features: Band energy ratio, spectral centroid, spectral bandwidth
    (spread), spectral flatness.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will describe the theory and write Python codes from scratch to extract
    each of these features for audio signals from 3 different musical instruments:
    Acoustic Guitar, Brass, and Drum Set. The sample audio data files used can be
    downloaded here: [https://github.com/namanlab/Audio-Signal-Processing-Feature-Extraction](https://github.com/namanlab/Audio-Signal-Processing-Feature-Extraction)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'The entire code file is also available at the above repository or can be accessed
    via this link: [https://github.com/namanlab/Audio-Signal-Processing-Feature-Extraction/blob/main/Audio_Signal_Extraction.ipynb](https://github.com/namanlab/Audio-Signal-Processing-Feature-Extraction/blob/main/Audio_Signal_Extraction.ipynb)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Time Domain Feature Extraction
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s begin by recalling what is sound and how is it perceived by us. As some
    of you might remember from your high school lessons, sound is the propagation
    of vibrations through a medium. The production of sound sets the surrounding air
    molecules to vibration, which manifests in alternating regions of compression
    (high pressure) and rarefaction (low pressure). These compressions and rarefactions
    travel through the medium and reach our ears allowing us to perceive sound the
    way it is. Thus, the propagation of sound involves the transmission of these pressure
    variations over time. The time domain representation of sound involves capturing
    and analyzing these pressure variations at different time intervals by sampling
    the sound wave at discrete points in time (typically using a digital audio recording
    technique). Each sample represents the sound pressure level at a specific moment.
    By plotting these samples, we obtain a waveform that shows how the sound pressure
    level changes over time. The horizontal axis represents time, while the vertical
    axis represents the amplitude or intensity of the sound, usually scaled to fit
    between -1 and 1, where positive values indicate compression and negative values
    indicate rarefaction. This helps us give a visual representation of the sound
    wave’s characteristics, such as its amplitude, frequency, and duration.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始回顾什么是声音以及我们是如何感知它的。正如你们中的一些人可能记得的高中课程中所讲，声音是通过介质传播的振动。声音的产生使得周围的空气分子发生振动，这表现为交替的压缩（高压）和稀疏（低压）区域。这些压缩和稀疏通过介质传播并到达我们的耳朵，让我们感知声音。声音的传播涉及这些压力变化随时间的传递。声音的时域表示涉及在不同时间间隔捕获和分析这些压力变化，通过在离散时间点（通常使用数字音频录制技术）对声波进行采样。每个样本代表特定时刻的声音压力水平。通过绘制这些样本，我们获得一个波形，展示声音压力水平随时间的变化。横轴表示时间，而纵轴表示声音的振幅或强度，通常在
    -1 和 1 之间缩放，其中正值表示压缩，负值表示稀疏。这有助于我们给出声音波形特征的视觉表现，如其振幅、频率和持续时间。
- en: '![](../Images/0f504202b068284f511d538e2f20b355.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0f504202b068284f511d538e2f20b355.png)'
- en: Basics of Sound Propagation [Image by Author]
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 声音传播基础 [作者图像]
- en: 'In order to extract the waveform of a given audio using Python, we begin by
    loading the required packages:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 Python 提取给定音频的波形，我们首先需要加载所需的包：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: NumPy is a popular Python package for processing and working with arrays and
    matrices. It contains a vast range of tools from linear algebra to making many
    tasks simpler!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 是一个流行的 Python 包，用于处理和操作数组和矩阵。它包含从线性代数到简化许多任务的广泛工具！
- en: 'librosa is Python’s package for audio processing and analysis and contains
    several functions and tools to make it quite easy to harness different kinds of
    audio features. As told earlier, we’ll be analyzing the waveforms for 3 different
    musical instruments: Acoustic Guitar, Brass, and Drum Set. You may download the
    audio files from the link shared earlier and upload them to your local repository.
    In order to listen to the audio files we use IPython.display. The code is given
    below:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: librosa 是 Python 的音频处理和分析包，包含多个函数和工具，使得利用不同的音频特征变得相当简单。如前所述，我们将分析三种不同乐器的波形：原声吉他、铜管乐器和鼓组。你可以从之前分享的链接下载音频文件并上传到你的本地库。为了听取音频文件，我们使用
    IPython.display。代码如下：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we load the music files in *librosa* using the function *librosa.load()*.
    This function allows us to parse the audio file and return two objects:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用函数 *librosa.load()* 在 *librosa* 中加载音乐文件。这个函数允许我们解析音频文件并返回两个对象：
- en: '*y* (NumPy Array): Contains the amplitude values for different time intervals.
    Try printing the array to see it yourself!'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*y*（NumPy 数组）：包含不同时间间隔的振幅值。试着打印数组看看！'
- en: '*sr* (number > 0): Sampling Rate'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*sr*（数字 > 0）：采样率'
- en: The sampling rate refers to the number of samples taken per unit of time while
    converting an analog signal into its digital representation. As discussed above,
    the pressure variation across the medium constitutes an analog signal, one that
    has a waveform that continuously varies in time. Theoretically, storing continuous
    data would require an infinite amount of space. Thus, in order to process and
    store these analog signals digitally, they need to be converted into a discrete
    representation. This is where sampling steps in to capture screenshots of the
    sound wave at discrete (uniformly spaced) time intervals. The spacing between
    these intervals is captured by the inverse of the sampling rate.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: The sampling rate determines how frequently samples are taken from the analog
    signal and is therefore measured in samples per second or hertz (Hz). A higher
    sampling rate means more samples are taken every second, resulting in a more accurate
    representation of the original analog signal, but requiring more memory resources.
    In contrast, a lower sampling rate means lesser samples are taken every second,
    resulting in a less accurate representation of the original analog signal, but
    requiring fewer memory resources.
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The usual default sampling rate is 22050\. However, as per application/memory,
    the user may choose a lower or higher sampling rate, which can be specified by
    the *sr* argument of *librosa.load()*. While choosing an appropriate sampling
    rate for analog-to-digital conversion, it may be important to know about the Nyquist-Shannon
    sampling theorem, which states that in order to accurately capture and reconstruct
    an analog signal, the sampling rate must be at least twice the highest frequency
    component present in the audio signal (called the Nyquist Rate/Frequency).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/86b7038f25d41d8f0dc383e9dc949dfe.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: 'By sampling at a frequency higher than the Nyquist Frequency, we can avoid
    a phenomenon called aliasing, which can distort the original signal. The discussion
    on aliasing isn’t particularly relevant for the purpose of this article. If you’re
    interested in reading more about it, here’s an excellent source: [https://thewolfsound.com/what-is-aliasing-what-causes-it-how-to-avoid-it/](https://thewolfsound.com/what-is-aliasing-what-causes-it-how-to-avoid-it/.)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'Following is the code to read the audio signals:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the above example, the sampling rate is said to be 22050 (which is also the
    default rate). Executing the above code returns 3 arrays, each of which stores
    the amplitude values at discrete time intervals (specified by the sampling rate).
    Next, we visualize the waveforms for each of the 3 audio samples using *librosa.display.waveshow()*.
    Some transparency has been added (by setting alpha = 0.5) for clearer visualization
    of the amplitude density across time.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](../Images/31614d4489718763ace7115d0674452c.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: Waveform for Acoustic Guitar [Image by Author]
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/07747c2e732e52da787d85e744622f76.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: Waveform for Brass [Image by Author]
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e1d9b07f35cae08eaee31af193b78707.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: Waveform for Drum Set [Image by Author]
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Take some time to review the above plots. Think about the patterns that you
    see. In the waveform of the acoustic guitar, we can identify a periodic pattern
    characterized by regular oscillations in the amplitude, which reflects the harmonically
    rich nature of the guitar’s sound. The oscillations correspond to the vibrations
    produced by the plucked strings that generate a complex waveform consisting of
    multiple harmonics contributing to the characteristic tone and timbre of the guitar.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Likewise, the brass waveform also exhibits a periodic pattern resulting in a
    consistent pitch and timbre. Brass instruments produce sound through the buzzing
    of the musician’s lips into a mouthpiece. This buzzing action generates a waveform
    with distinct harmonics and a regular pattern of amplitude variations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, the waveform of a drum set does not display a clear periodic pattern
    as drums produce sound through the impact of a drumstick or hand on a drumhead
    or other percussion surfaces creating complex and irregular waveforms, with varying
    amplitudes and duration. The absence of a discernible periodic pattern reflects
    the percussive and non-tonal nature of drum sounds.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: 'Basics of Audio Signal Processing: Frame Size and Hop Length'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before discussing the vital time-domain audio features, it is imperative to
    talk about two vital feature extraction parameters: Frame Size and Hop Length.
    Usually, once a signal has been digitally processed, it is split into frames (a
    set of discrete time intervals that may or may not be overlapping). The frame
    length describes the size of these frames, while the hop length encapsulates information
    about how much the frames overlap. But, why is framing important?'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of framing is to capture the time variation in different features
    of the signal. Usual feature extraction methods give a one-number summary of the
    input signal (e.g., mean, min, or max). The problem with using these feature extraction
    methods directly is that this completely annihilates any information associated
    with time. For example, if you’re interested in computing the mean amplitude of
    your signal, you get a single number summary, say x. However, naturally, there
    are intervals when the mean is less and others when the mean is more. Taking a
    single-number summary eliminates any information about the time variation of the
    mean, The solution in turn is to split the signals into frames e.g., [0 ms, 10
    ms), [10 ms, 20 ms), … The mean is subsequently computed for the portion of the
    signal in each of these time frames and this collective set of features gives
    the final extracted feature vector, a time-dependent feature summary, ain’t that
    cool!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s talk about the two parameters in detail:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '**Frame Size:** Describes the size of each frame. For example, if the frame
    size is 1024, you include 1024 samples in every frame and compute the necessary
    features for each of these sets of 1024 samples. In general, it is recommended
    to have the frame size as a power of 2\. The reasoning behind this isn’t important
    for the purpose of this article. But if you’re curious, it’s because the Fast
    Fourier Transformation (a very efficient algorithm to transform a signal from
    time-domain to frequency-domain), requires the frames to have a size that is a
    power of 2\. We will be talking more about Fourier transformations in the subsequent
    sections.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**框架大小（Frame Size）：** 描述了每个框架的大小。例如，如果框架大小是1024，那么每个框架中包含1024个样本，并计算这些1024个样本集合所需的特征。一般推荐将框架大小设置为2的幂。这背后的原因对于本文的目的并不重要。但如果你感兴趣，这是因为快速傅里叶变换（一个非常高效的将信号从时间域转换到频率域的算法）要求框架大小是2的幂。我们将在后续部分更多地讨论傅里叶变换。'
- en: '**Hop Length:** Refers to the number of samples by which a frame is advanced
    at each step across the sequence of data i.e., the number of samples we shift
    to the right before generating a new frame. It may be useful to think of the frame
    as a sliding window that moves across the signal in steps defined by the hop length.
    At each step, the window is applied to a new section of the signal or sequence,
    and feature extraction is performed on that segment. The hop length, therefore,
    determines the overlap between consecutive audio frames. A hop length of equal
    to the frame size means there is no overlap as each frame starts exactly where
    the previous one ends. However, to mitigate the impact of a phenomenon called
    spectral leakage (which occurs when converting a signal from its time domain to
    the frequency domain), a windowing function is applied resulting in the loss of
    data around the edges of each frame (the technical explanation is beyond the purpose
    of this article, but if you’re curious, feel free to check this link: [https://dspillustrations.com/pages/posts/misc/spectral-leakage-zero-padding-and-frequency-resolution.html](https://dspillustrations.com/pages/posts/misc/spectral-leakage-zero-padding-and-frequency-resolution.html)).
    Thus, often intermediate hop lengths are chosen to preserve the edge samples,
    resulting in varying degrees of overlap between frames.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跳跃长度（Hop Length）：** 指的是在数据序列中，每一步框架前进的样本数量，即生成新框架前我们向右移动的样本数。可以将框架视为一个在信号上滑动的窗口，滑动的步长由跳跃长度定义。在每一步，窗口会应用到信号或序列的新部分，并在该段上进行特征提取。因此，跳跃长度决定了连续音频框架之间的重叠情况。跳跃长度等于框架大小意味着没有重叠，因为每个框架恰好在前一个框架结束的地方开始。然而，为了减轻将信号从时间域转换到频率域时发生的一个现象称为谱泄漏的影响，应用了一个窗口函数，导致每个框架边缘附近的数据丢失（技术解释超出了本文的目的，但如果你感兴趣，可以查看这个链接：[https://dspillustrations.com/pages/posts/misc/spectral-leakage-zero-padding-and-frequency-resolution.html](https://dspillustrations.com/pages/posts/misc/spectral-leakage-zero-padding-and-frequency-resolution.html)）。因此，通常选择中间跳跃长度以保留边缘样本，从而导致框架之间的重叠程度不同。'
- en: In general, a smaller hop length provides a higher temporal resolution allowing
    us to capture more details and rapid changes in the signal. However, it also increases
    memory requirements. Conversely, a larger hop length reduces the temporal resolution
    but also helps reduce space complexity.
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一般来说，较小的跳跃长度提供了更高的时间分辨率，使我们能够捕捉信号中的更多细节和快速变化。然而，它也增加了内存需求。相反，较大的跳跃长度降低了时间分辨率，但也有助于减少空间复杂度。
- en: '![](../Images/e00cb4e5fecb76b82e01c4fe29892b5e.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e00cb4e5fecb76b82e01c4fe29892b5e.png)'
- en: Frame Size and Hop Length [Image by Author]
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 框架大小和跳跃长度 [作者提供的图片]
- en: 'Note: For clearer visualization, the frame size is shown to be quite large
    in the above image. For practical purposes, the chosen frame size is much smaller
    (maybe a few 1000 samples, around 20–40 ms).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了更清晰的可视化，以上图像中的框架大小显示得相当大。实际上，选择的框架大小要小得多（可能是几千个样本，约20-40毫秒）。
- en: 'Before proceeding to the time-domain different feature extraction methods,
    let’s clarify some mathematical notations. We will use the following notations
    throughout this article:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续讨论时间域不同特征提取方法之前，让我们澄清一些数学符号。我们将在本文中使用以下符号：
- en: '**xᵢ:** the amplitude of the ith sample'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**xᵢ:** 第i个样本的幅度'
- en: '**K:** Frame Size'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**K:** 框架大小'
- en: '**H:** Hop Length'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H:** 跳跃长度'
- en: 'Feature 1: Amplitude Envelope'
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征 1：幅度包络
- en: 'First, let’s talk about the amplitude envelope. This is one of the easiest
    to compute (yet quite useful) features in time domain analysis. The amplitude
    envelope for a frame of an audio signal is simply the maximum value of its amplitude
    in that frame. Mathematically, the amplitude envelope (for non-overlapping frames)
    of the kth frame is given by:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们来讨论包络线。这是时间域分析中最容易计算（但相当有用）的特征之一。音频信号一帧的包络线简单来说就是该帧内幅度的最大值。在数学上，第 k 帧的包络线（对于不重叠的帧）由下式给出：
- en: '![](../Images/3e868837349f4db63f0fbd5c4c2fe942.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3e868837349f4db63f0fbd5c4c2fe942.png)'
- en: 'In general, for any frame k containing samples xⱼ₁ , xⱼ₂ , · · · , xⱼₖ, the
    amplitude envelope is:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，对于包含样本 xⱼ₁ , xⱼ₂ , · · · , xⱼₖ 的任意帧 k，包络线是：
- en: '![](../Images/bb8e59bc558444acd51ae63c454cd139.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb8e59bc558444acd51ae63c454cd139.png)'
- en: 'The Python code for computing the amplitude envelope of a given signal is given
    below:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是计算给定信号包络线的 Python 代码：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the above code, we have defined a function called *amplitude_envelope* which
    takes in the input signal array (generated using *librosa.load()*), frame size
    (K), and hop length (H), and returns an array of size equal to the number of frames.
    The kth value in the array corresponds to the value of the amplitude envelope
    for the kth frame. The computation is done using a simple for loop that iterates
    through the entire signal with steps determined by the hop length. A list (*res*)
    is defined to store these values and is finally converted to a NumPy array before
    being returned. Another function called *plot_amplitude* envelope is defined which
    takes in the same set of inputs (along with a name argument) and overlays the
    plot of the amplitude envelope over the original frame. In order to plot the waveform,
    the traditional *librosa.display.waveform()* has been used, as explained in the
    previous section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们定义了一个名为 *amplitude_envelope* 的函数，该函数接受输入信号数组（由 *librosa.load()* 生成）、帧大小
    (K) 和跳步长度 (H)，并返回一个大小等于帧数的数组。数组中的第 k 个值对应于第 k 帧的包络线值。计算通过一个简单的 for 循环完成，该循环以跳步长度为步长遍历整个信号。定义了一个列表
    (*res*) 来存储这些值，并在返回之前将其转换为 NumPy 数组。另一个名为 *plot_amplitude* 的函数被定义，它接受相同的一组输入（以及一个名称参数），并在原始帧上叠加包络线图。为了绘制波形，使用了传统的
    *librosa.display.waveform()*，如前一节所述。
- en: 'To plot the amplitude envelope, we need the time and the corresponding amplitude
    envelope values. The time values are obtained using the very helpful function
    *librosa.frames_to_times()*, which takes in two inputs: an iterable corresponding
    to the number of frames (which is defined using the *range* function), and the
    hop length) to generate the mean time for each frame. Subsequently, *matplotlib.pyplot*
    is used to overlay the red plot. The above-described process will be consistently
    used for all time-domain feature extraction methods.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要绘制包络线，我们需要时间值和对应的包络线值。时间值通过非常有用的函数 *librosa.frames_to_times()* 获取，该函数接受两个输入：一个对应帧数的可迭代对象（由
    *range* 函数定义），以及跳步长度）以生成每帧的平均时间。随后，使用 *matplotlib.pyplot* 来叠加红色图。上述描述的过程将一致用于所有时间域特征提取方法。
- en: The following figures show the computed amplitude envelope for each of the musical
    instruments. They have been added as a red line over the original waveform and
    tend to approximate the upper boundary of the waveform. The amplitude envelope
    not only preserves the periodic pattern but also indicates the general difference
    in the audio amplitudes as reflected in the lower intensities of brass compared
    to acoustic guitar and drum sets.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了每种乐器计算出的包络线。它们以红线的形式叠加在原始波形上，并倾向于近似波形的上边界。包络线不仅保留了周期性模式，还显示了音频幅度的一般差异，如铜管乐器与原声吉他和鼓组相比的低强度所反映的那样。
- en: '![](../Images/692fb7a87dcb763c13290ea88c9e823e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/692fb7a87dcb763c13290ea88c9e823e.png)'
- en: Amplitude Envelope for Acoustic Guitar [Image by Author]
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 原声吉他的包络线 [作者提供的图像]
- en: '![](../Images/8171bcb1a4c366e8123d19e148224d70.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8171bcb1a4c366e8123d19e148224d70.png)'
- en: Amplitude Envelope for Brass [Image by Author]
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的包络线 [作者提供的图像]
- en: '![](../Images/c2d12ea87310e744f4cf15341443c14f.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c2d12ea87310e744f4cf15341443c14f.png)'
- en: Amplitude Envelope for Drum Set [Image by Author]
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓组的包络线 [作者提供的图像]
- en: 'Feature 2: Root Mean Square Energy'
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征 2：均方根能量
- en: 'Next, let’s talk about the root mean square energy (RMSE), another vital feature
    in time domain analysis. The root mean square energy for a frame of an audio signal
    is obtained by taking the square root of the mean of the square of all the amplitude
    values in a frame. Mathematically, the root mean square energy (for non-overlapping
    frames) of the kth frame is given by:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们谈谈均方根能量（RMSE），这是时域分析中的另一个重要特征。音频信号帧的均方根能量是通过对帧内所有振幅值的平方均值开方得到的。数学上，k帧的均方根能量（对于非重叠帧）表示为：
- en: '![](../Images/2ae65334564b6e2f3e109164a0afc343.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ae65334564b6e2f3e109164a0afc343.png)'
- en: 'In general, for any frame k containing samples xⱼ₁ , xⱼ₂ , · · · , xⱼₖ, the
    RMSE is:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，对于包含样本 xⱼ₁ , xⱼ₂ , · · · , xⱼₖ 的任意帧k，均方根误差为：
- en: '![](../Images/4ea8ce6469033c8d4d7901dee96e21e5.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ea8ce6469033c8d4d7901dee96e21e5.png)'
- en: The RMS energy provides a representation of the overall intensity or strength
    of a sound signal by taking into account both positive and negative excursions
    of the waveform, providing a more accurate measure of the signal’s power compared
    to other measures such as peak amplitude. The Python code for computing the RMSE
    of a given signal is given below. The structure of the code is the same as that
    for generating the amplitude envelope. The only change is in the function used
    for extracting the feature. Instead of the max, the RMSE value is calculated by
    taking the mean of the squared values in the current portion of the signal followed
    by a square root.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 均方根能量通过考虑波形的正负偏移，提供了声音信号的整体强度或力度的表征，比起峰值振幅等其他度量提供了更准确的信号功率测量。计算给定信号均方根误差的Python代码如下。代码结构与生成振幅包络的代码相同。唯一的变化在于提取特征所用的函数。通过对信号当前部分的平方值取平均后再开方来计算均方根误差值，而不是取最大值。
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The following figures show the computed RMS Energy for each of the musical instruments.
    They have been added as a red line over the original waveform and tend to approximate
    the center of mass of the waveform. Just as before, this measure not only preserves
    the periodic pattern but also approximates the overall intensity level of the
    sound wave.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了每个乐器计算的均方根能量。它们被添加为原始波形上的红线，趋近于波形的质心。正如之前一样，这一度量不仅保留了周期模式，还近似了声波的整体强度水平。
- en: '![](../Images/5c4ff44f45548d7e89d63e606b4de2da.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c4ff44f45548d7e89d63e606b4de2da.png)'
- en: RMSE for Acoustic Guitar [Image by Author]
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 声学吉他的均方根误差 [作者提供的图片]
- en: '![](../Images/207079a8ed072fa3f904868abc990982.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/207079a8ed072fa3f904868abc990982.png)'
- en: RMSE for Brass [Image by Author]
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的均方根误差 [作者提供的图片]
- en: '![](../Images/4e37c496d2cd18897a1d1b259a3d3e74.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4e37c496d2cd18897a1d1b259a3d3e74.png)'
- en: RMSE for Drum Set [Image by Author]
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓组的均方根误差 [作者提供的图片]
- en: 'Feature 3: Crest Factor'
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征3：峰值因子
- en: 'Now, let’s talk about the crest factor, a measure of the extremeness of the
    peaks in the waveform. The crest factor for a frame of an audio signal is obtained
    by dividing the peak amplitude (the largest absolute value of the amplitude) by
    the RMS Energy. Mathematically, the crest factor (for non-overlapping frames)
    of the kth frame is given by:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们谈谈峰值因子，它是波形峰值极端程度的度量。音频信号帧的峰值因子是通过将峰值振幅（振幅的最大绝对值）除以均方根能量来获得的。数学上，k帧的峰值因子（对于非重叠帧）表示为：
- en: '![](../Images/1dc81336ba6cbf06976c659165b6e33f.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1dc81336ba6cbf06976c659165b6e33f.png)'
- en: 'In general, for any frame k containing samples xⱼ₁ , xⱼ₂ , · · · , xⱼₖ, the
    crest factor is:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，对于包含样本 xⱼ₁ , xⱼ₂ , · · · , xⱼₖ 的任意帧k，峰值因子为：
- en: '![](../Images/fb416d06faa9303179cc2d07bc9f10cf.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb416d06faa9303179cc2d07bc9f10cf.png)'
- en: The crest factor indicates the ratio of the highest peak level and the average
    intensity level of a waveform. The Python code for computing the crest factor
    of a given signal is given below. The structure follows as above, involving the
    computation of the RMSE value (the denominator) and the highest peak value (the
    numerator), which is then used to obtain the desired fraction (the crest factor!).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 峰值因子表示波形的最高峰值水平与平均强度水平的比率。计算给定信号峰值因子的Python代码如下。结构与上述相同，涉及计算均方根误差值（分母）和最高峰值（分子），然后用来获得所需的分数（峰值因子！）。
- en: '[PRE6]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following figures show the computed crest factor for each of the musical
    instruments:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了每个乐器的计算峰值因子：
- en: '![](../Images/6375554e46514bbaaae4ab4b8ad9f67c.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6375554e46514bbaaae4ab4b8ad9f67c.png)'
- en: Crest Factor for Acoustic Guitar [Image by Author]
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 声学吉他的峰值因子 [作者提供的图片]
- en: '![](../Images/d46315051ff1cb1520ef37815696085d.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d46315051ff1cb1520ef37815696085d.png)'
- en: Crest Factor for Brass [Image by Author]
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的峰值因子 [图片作者]
- en: '![](../Images/7f780d83f0579adababf31510a75b78c.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f780d83f0579adababf31510a75b78c.png)'
- en: Crest Factor for Brass Set [Image by Author]
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器组的峰值因子 [图片作者]
- en: A higher crest factor, as seen for acoustic guitar and brass, indicates a larger
    difference between peak levels and average levels suggesting a more dynamic or
    peaky signal with greater variations in amplitude. A lower crest factor, as seen
    for a drum set, suggests a more uniform or compressed signal with smaller variations
    in amplitude. The crest factor is particularly relevant in cases where it is imperative
    to consider the headroom or available dynamic range of the system. For instance,
    a high crest factor in a music recording may require careful consideration to
    prevent distortion or clipping when played back on equipment with limited headroom.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的峰值因子，如在声学吉他和铜管乐器中所见，表示峰值水平和平均水平之间的差异较大，表明信号更具动态性或峰值特征，振幅变化较大。较低的峰值因子，如在鼓组中所见，表明信号更均匀或压缩，振幅变化较小。峰值因子在需要考虑系统头间隙或可用动态范围的情况下尤为重要。例如，在音乐录音中，高峰值因子可能需要仔细考虑，以防在有限头间隙的设备上播放时发生失真或削波。
- en: 'In fact, there is another feature called peak-to-average power ratio (PAPR),
    closely related to the crest factor. PAPR is simply the squared value of the crest
    factor, usually converted to a decibel power ratio. In general, for any frame
    k containing samples xⱼ₁ , xⱼ₂ , · · · , xⱼₖ, the peak-to-average power ratio
    is:'
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 实际上，还有一个特性叫做峰值与平均功率比（PAPR），它与峰值因子密切相关。PAPR 只是峰值因子的平方值，通常转换为分贝功率比。一般来说，对于任何包含样本
    xⱼ₁ 、xⱼ₂ 、· · · 、xⱼₖ 的帧 k，峰值与平均功率比为：
- en: '![](../Images/2c9e26ae2d1a9c710ff3e5e3a47ccb65.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c9e26ae2d1a9c710ff3e5e3a47ccb65.png)'
- en: As a fun challenge, try modifying the above code to generate a plot of the PAPR
    for each of the 3 musical instruments and analyze your findings.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个有趣的挑战，尝试修改上述代码以生成每种音乐乐器的 PAPR 图，并分析你的发现。
- en: 'Feature 4: Zero Crossing Rate'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特性 4：零交叉率
- en: 'Finally, we’ll talk about the Zero Crossing Rate (ZCR). The zero crossing rate
    for a frame of an audio signal is simply the number of times the signal crosses
    zero (the x/time axis). Mathematically, the ZCR (for non-overlapping frames) of
    the kth frame is given by:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论零交叉率（ZCR）。音频信号的一帧的零交叉率就是信号穿过零点（x/时间轴）的次数。数学上，第 k 帧的 ZCR（对于非重叠帧）定义为：
- en: '![](../Images/5566f25a6fde5ff70cbff9b72c6dfb1d.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5566f25a6fde5ff70cbff9b72c6dfb1d.png)'
- en: 'If the consecutive values have the same sign, the expression inside the absolute
    value cancels out, giving 0\. If they have the opposite signs (indicating that
    the signal has crossed the time axis), the values add yielding 2 (after taking
    absolute value). Since each zero crossing gives a value of 2, we multiply the
    result by a factor of half to obtain the required count. In general, for any frame
    k containing samples xⱼ₁ , xⱼ₂ , · · · , xⱼₖ, the ZCR is:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果连续的值具有相同的符号，则绝对值内部的表达式将抵消，结果为 0。如果它们具有相反的符号（表示信号已穿过时间轴），这些值相加将得到 2（取绝对值后）。由于每个零交叉给出的值为
    2，我们将结果乘以半的系数以获得所需的计数。一般来说，对于任何包含样本 xⱼ₁ 、xⱼ₂ 、· · · 、xⱼₖ 的帧 k，ZCR 为：
- en: '![](../Images/48d48723e109da9aba738a1fc36a55b3.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/48d48723e109da9aba738a1fc36a55b3.png)'
- en: Note that, in the above expression, the zero crossing rate is calculated by
    simply adding up the number of times the signal crosses the axis. However, as
    per application, one may also normalize the values (by dividing by the length
    of the frame). The Python code for computing the crest factor of a given signal
    is given below. The structure follows from above, with the definition of another
    function called as num sign changes, which determines the number of times the
    sign changes in the given signal.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在上述表达式中，零交叉率是通过简单地将信号交叉轴的次数相加来计算的。然而，根据应用需求，也可以对这些值进行归一化（通过除以帧的长度）。计算给定信号的峰值因子的
    Python 代码如下。其结构与上述相似，并定义了一个名为 num sign changes 的函数，用于确定信号中符号变化的次数。
- en: '[PRE7]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The following figures show the computed zero crossing rate for each of the musical
    instruments.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了各音乐乐器计算出的零交叉率。
- en: '![](../Images/5efdb0a9c1a4740125be2651b89d9881.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5efdb0a9c1a4740125be2651b89d9881.png)'
- en: Zero Crossing for Acoustic Guitar [Image by Author]
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 声学吉他的零交叉率 [图片作者]
- en: '![](../Images/8b61156308ed896d83bb4829b502c456.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8b61156308ed896d83bb4829b502c456.png)'
- en: Zero Crossing for Brass [Image by Author]
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的零交叉率 [图片来源：作者]
- en: '![](../Images/7f780d83f0579adababf31510a75b78c.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7f780d83f0579adababf31510a75b78c.png)'
- en: Zero Crossing for Drum Set [Image by Author]
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓组的零交叉率 [图片来源：作者]
- en: A higher zero crossing rate shows that the signal changes its direction frequently,
    suggesting the presence of higher-frequency components or a more dynamic waveform.
    Conversely, a lower zero crossing rate indicates a relatively smoother or constant
    waveform.
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 较高的零交叉率表明信号经常改变方向，暗示存在更高频率成分或更动态的波形。相反，较低的零交叉率则表示波形相对平滑或恒定。
- en: Zero crossing rate is particularly useful in applications of speech and music
    analysis due to its ability to provide insights into properties such as timbre
    and rhythmic patterns. For instance, in speech analysis, the zero crossing rate
    helps distinguish between voiced and unvoiced sounds as voiced sounds tend to
    have a higher zero crossing rate due to the vibration of the vocal cords. It’s
    vital to note that, while zero crossing rate is a simple and computationally efficient
    feature, it may not capture all aspects of a signal’s complexity (as you can see
    in the above figures, the periodicity is completely lost). Therefore, it is often
    used in conjunction with other features for a more comprehensive analysis of audio
    signals.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 零交叉率在语音和音乐分析中特别有用，因为它能够提供有关音色和节奏模式等属性的见解。例如，在语音分析中，零交叉率有助于区分有声和无声声音，因为有声声音由于声带的振动，往往具有更高的零交叉率。需要注意的是，虽然零交叉率是一个简单且计算高效的特征，但它可能无法捕捉信号复杂性的所有方面（如上图所示，周期性完全丢失）。因此，它通常与其他特征一起使用，以便对音频信号进行更全面的分析。
- en: Frequency Domain Feature Extraction
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 频率域特征提取
- en: The frequency domain offers an alternative representation of an audio wave.
    Unlike the time domain, where the signal is represented as a function of time,
    in the frequency domain, the signal is decomposed into its constituent frequencies,
    revealing the amplitude and phase information associated with each frequency i.e.,
    the signal is represented as a function of frequency. Instead of looking at the
    signal’s amplitude at various points in time, we examine the amplitudes of the
    different frequency components that constitute the signal. Each frequency component
    represents a sinusoidal wave of a particular frequency and by combining these
    components we can reconstruct the original signal in the time domain.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 频率域提供了音频波形的另一种表示方式。与时间域不同，在频率域中，信号被分解为其组成的频率，揭示了与每个频率相关的幅度和相位信息，即信号作为频率的函数表示。我们不是查看信号在不同时间点的幅度，而是检查构成信号的不同频率分量的幅度。每个频率分量代表一个特定频率的正弦波，通过组合这些分量，我们可以在时间域中重建原始信号。
- en: 'The (most common) mathematical tool used to convert a signal from the time
    domain to the frequency domain is the Fourier transformation. The Fourier transformation
    takes the signal as input and decomposes it into a sum of sine and cosine waves
    of varying frequencies having their own amplitude and phase. The resulting representation
    is what constitutes the frequency spectrum. Mathematically, the Fourier transform
    of a continuous signal in its time domain g(t) is defined as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 将信号从时间域转换到频率域的（最常见的）数学工具是傅里叶变换。傅里叶变换以信号为输入，将其分解为不同频率的正弦波和余弦波的总和，这些波具有各自的幅度和相位。得到的表示就是频率谱。数学上，连续信号在其时间域g(t)的傅里叶变换定义如下：
- en: '![](../Images/cc21f24a8cd7bd25ad5e8be0cc7be299.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc21f24a8cd7bd25ad5e8be0cc7be299.png)'
- en: 'where i = √−1 is the imaginary number. Yes, the Fourier transformation yields
    a complex output, with the phase and the magnitude corresponding to those of the
    constituent sine wave! However, for most applications, we care only about the
    magnitude of the transformation and simply ignore the associated phase. Since
    digitally processed sound is discrete, we can define the analogous discrete Fourier
    transform (DFT):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 其中i = √−1是虚数。是的，傅里叶变换会产生复杂的输出，其中相位和幅度对应于组成的正弦波！然而，对于大多数应用，我们只关心变换的幅度，而简单地忽略相关的相位。由于数字处理的声音是离散的，我们可以定义类似的离散傅里叶变换（DFT）：
- en: '![](../Images/fceb4530184bd65ec0e108cfec837119.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fceb4530184bd65ec0e108cfec837119.png)'
- en: 'where T is the duration of one sample. In terms, of sampling rate:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 其中T是一个样本的持续时间。在采样率方面：
- en: '![](../Images/35eba50d3258f1545d3750587449fbe2.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/35eba50d3258f1545d3750587449fbe2.png)'
- en: Since frequency representations are also continuous, we evaluate the Fourier
    transform on discretized frequency bins to obtain a discrete frequency domain
    representation of the audio wave. This is called the short-term Fourier transform.
    Mathematically,
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 由于频率表示也是连续的，我们在离散化的频率区间上评估傅里叶变换，以获得音频波的离散频率域表示。这称为短时傅里叶变换。数学上，
- en: '![](../Images/523b094182569e1cd0c4bf365b068369.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/523b094182569e1cd0c4bf365b068369.png)'
- en: 'Don’t get anxious! Let’s review it carefully. The hat-h(k) is the function
    that maps an integer k ∈ {0, 1, · · · , N − 1} to the magnitude of the frequency
    k · Sᵣ/N. Notice that we consider only the discrete frequency bins that are integral
    multiples of Sᵣ/N, where N is the number of samples in the signal. If you’re still
    unsure about how this works, here’s an excellent explanation of Fourier transforms:
    [https://www.youtube.com/watch?v=spUNpyF58BY&t=393s](https://www.youtube.com/watch?v=spUNpyF58BY&t=393s)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 不要紧张！让我们仔细复习一下。函数 hat-h(k) 是将整数 k ∈ {0, 1, · · · , N − 1} 映射到频率 k · Sᵣ/N 的幅度。注意，我们只考虑
    Sᵣ/N 的整数倍的离散频率区间，其中 N 是信号中的样本数。如果你对这个如何运作仍然不确定，这里有一个关于傅里叶变换的优秀解释：[https://www.youtube.com/watch?v=spUNpyF58BY&t=393s](https://www.youtube.com/watch?v=spUNpyF58BY&t=393s)
- en: The Fourier transform is one of the most beautiful mathematical innovations,
    so it’s worth knowing about it, even though the discussion isn’t specifically
    relevant to the purpose of this article. In Python, you can easily obtain the
    short-term Fourier transform using *librosa.stft()*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 傅里叶变换是最美丽的数学创新之一，因此值得了解，尽管讨论内容与本文的目的并不特别相关。在 Python 中，你可以轻松地使用 *librosa.stft()*
    获得短时傅里叶变换。
- en: 'Note: For large audio data, there is a more efficient way to compute the Fourier
    transform, called the Fast Fourier Transformation (FFT), feel free to check it
    out if you’re curious!'
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注：对于大型音频数据，有一种更高效的傅里叶变换计算方法，称为快速傅里叶变换（FFT），如果你感兴趣的话可以查阅一下！
- en: 'As before, we aren’t just interested in knowing which frequencies are more
    dominant: we also want to show when these frequencies are dominant. So, we seek
    a simultaneous frequency-time representation that shows which frequencies dominate
    at what point in time. This is where framing steps in: we split the signal into
    time frames and obtain the magnitude of the resulting Fourier transform in each
    frame. This gives us a matrix of values, where the number of rows is given by
    the number of frequency bins (Φ, usually equal to K/2 + 1, where K is the frame
    size), and the number of columns is given by the number of frames. Since the Fourier
    transform gives complex-valued output, the matrix generated is complex-valued.
    In Python, the frame size and hop length parameters can easily be specified as
    arguments and the resultant matrix can be simply computed using *librosa.stft(signal,
    n fft=frame size, hop length=hop length)*. Since we only care about the magnitude,
    we may use *numpy.abs()* to convert the complex-valued matrix into a real-valued
    one. It is quite convenient to plot the obtained matrix to have a visually captivating
    representation of the signal that provides valuable insights into the frequency
    content and temporal characteristics of the given sound. The so-called representation
    is called a Spectrogram.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们不仅仅对哪些频率更为主导感兴趣：我们还希望展示这些频率何时主导。因此，我们寻求一种同时的频率-时间表示，显示哪些频率在何时占主导地位。这就是帧的作用：我们将信号分成时间帧，并在每个帧中获得傅里叶变换的幅度。这给我们一个值矩阵，其中行数由频率区间的数量（Φ，通常等于
    K/2 + 1，其中 K 是帧大小）给出，列数由帧数给出。由于傅里叶变换给出的是复值输出，生成的矩阵是复值的。在 Python 中，帧大小和跳跃长度参数可以轻松指定为参数，并且结果矩阵可以使用*librosa.stft(signal,
    n fft=frame size, hop length=hop length)*简单计算。由于我们只关心幅度，我们可以使用 *numpy.abs()* 将复值矩阵转换为实值矩阵。绘制获得的矩阵是相当方便的，它提供了信号的视觉吸引力表现，并提供了对给定声音的频率内容和时间特征的宝贵见解。所谓的表示称为谱图。
- en: Spectrograms are obtained by plotting time frames on the x-axis and the frequency
    bins on the y-axis. Colors are then used to indicate the intensity or the magnitude
    of the frequency for the given time frame. Usually, the frequency axis is converted
    to a log scale (since humans are known to perceive them better under a log transformation),
    and the magnitude is expressed in decibels.
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 谱图通过在 x 轴上绘制时间帧，在 y 轴上绘制频率箱来获得。然后使用颜色表示给定时间帧的频率强度或幅度。通常，频率轴被转换为对数尺度（因为人类在对数转换下的感知较好），幅度以分贝表示。
- en: 'The Python code for generating a Spectrogram is shown below:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 生成谱图的 Python 代码如下：
- en: '[PRE8]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the above code, we have defined a function called plot spectrogram that
    takes in 4 arguments: the input signal array, sampling rate, frame size, and hop
    length. First, *librosa.stft()* is used to obtain the Spectrogram matrix. Subsequently,
    *np.abs()* is used to extract the magnitude followed by a conversion of the amplitude
    values to decibels using the function *librosa.amplitude_to_db()*. Finally, the
    function *librosa.display.specshow()* is used to plot the Spectrogram. This function
    takes in the transformed Spectrogram matrix, the sampling rate, hop length, and
    the specifications for the x and the y axes. A log-transformed y-axis can be specified
    using the y-axis = ‘log’ argument. An optional color bar can be added using *plt.colorbar()*.
    The resultant Spectrograms for the 3 musical instruments are shown below:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们定义了一个名为 plot spectrogram 的函数，该函数接受 4 个参数：输入信号数组、采样率、帧大小和跳跃长度。首先，*librosa.stft()*
    用于获取谱图矩阵。随后，*np.abs()* 用于提取幅度，然后通过 *librosa.amplitude_to_db()* 函数将幅度值转换为分贝。最后，*librosa.display.specshow()*
    函数用于绘制谱图。该函数接受转换后的谱图矩阵、采样率、跳跃长度以及 x 轴和 y 轴的规格。可以使用 y-axis = ‘log’ 参数指定对数转换的 y
    轴。还可以使用 *plt.colorbar()* 添加一个可选的颜色条。以下是 3 种乐器的谱图：
- en: '![](../Images/9c9b98d15484a9ad5d8ff2a4b02cb6bc.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9c9b98d15484a9ad5d8ff2a4b02cb6bc.png)'
- en: Spectrogram for Acoustic Guitar [Image by Author]
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 原声吉他的谱图 [作者提供的图片]
- en: '![](../Images/e4d2e6440108fb556b9ae77a25a016a3.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e4d2e6440108fb556b9ae77a25a016a3.png)'
- en: Spectrogram for Brass [Image by Author]
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的谱图 [作者提供的图片]
- en: '![](../Images/50511b1f13102342837ee21a72ea7f7d.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/50511b1f13102342837ee21a72ea7f7d.png)'
- en: Spectrogram for Drum Set [Image by Author]
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓组的谱图 [作者提供的图片]
- en: Spectrograms offer a unique way of visualizing the time-frequency trade-off.
    The time domain gives us a precise representation of how a signal evolves over
    time, while the frequency domain, allows us to see the distribution of energy
    across different frequencies. This enables us to identify not only the presence
    of specific frequencies but also helps us grasp their duration and temporal variations.
    Spectrograms are one of the most useful ways to represent sound and are frequently
    used in audio signal machine learning applications (for example, feeding the Spectrogram
    of a sound wave into a deep convolutional neural network to make predictions).
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 谱图提供了一种独特的时间-频率折衷可视化方式。时间域为我们提供了信号随时间演变的精确表示，而频率域则让我们看到不同频率下的能量分布。这使我们不仅能够识别特定频率的存在，还能掌握它们的持续时间和时间变化。谱图是表示声音的最有用的方式之一，并且常用于音频信号的机器学习应用（例如，将声音波形的谱图输入深度卷积神经网络进行预测）。
- en: 'Before proceeding to the different frequency-domain feature extraction methods,
    let’s clarify some mathematical notations. We will use the following notations
    for the subsequent sections:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续进行不同频率域特征提取方法之前，让我们澄清一些数学符号。我们将在后续部分使用以下符号：
- en: 'mₖ(i): the amplitude of the ith frequency of the kth frame.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: mₖ(i)：第 k 帧的第 i 个频率的幅度。
- en: 'K: Frame Size'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K：帧大小
- en: 'H: Hop Length'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H：跳跃长度
- en: 'Φ: The number of frequency bins (= K/2 + 1)'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Φ：频率箱的数量（= K/2 + 1）
- en: 'Feature 5: Band Energy Ratio'
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征 5：带能量比
- en: 'First, let’s talk about the band energy ratio. The band energy ratio is a metric
    used to quantify the ratio of the energies of the lower frequencies to that of
    the higher frequencies in a given time frame. Mathematically, for any frame k,
    the band energy ratio is:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们谈谈带能量比。带能量比是用于量化给定时间帧中低频能量与高频能量之比的指标。从数学上讲，对于任何帧 k，带能量比为：
- en: '![](../Images/39cf460c05b115b6b1c0f66fadb1862c.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/39cf460c05b115b6b1c0f66fadb1862c.png)'
- en: 'where σբ denotes the split frequency bin: a parameter to distinguish the lower
    frequencies from the higher frequencies. While calculating the band energy ratio,
    all frequencies having a value lesser than the frequency corresponding to σբ (called
    the split frequency) are treated as lower frequencies. The sum of the squared
    energies or these frequencies determines the numerator. Similarly, all frequencies
    having a value higher than the split frequency are treated as higher frequencies
    and the sum of the squared energies or these frequencies determines the denominator.
    The Python code for computing the band energy ratio of a signal is shown below:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The structure of the above code is quite similar to that of the time domain
    extraction. The first step is to define a function called find *split_freq_bin()*
    which takes in the spectrogram, the value of the split frequency, and the sample
    rate to determine the split frequency bin (σբ ) corresponding to the split frequency.
    The process is rather simple. It involves finding the range of the frequencies
    (which, as explained earlier is the Nyquists frequency, Sᵣ/2). The number of frequency
    bins is given by the number of rows of the spectrograms, which is extracted as
    *spec.shape[0]*. Dividing the total range of frequencies by the number of frequency
    bins allows us to compute the change in frequency per bin, which can be divided
    by the given split frequency to determine the split frequency bin.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Next, we use this function to calculate the band energy ratio vector. The function
    *band_energy_ratio()* takes in the input signal, split frequency, sample rate,
    frame size, and hop length. First, it uses *librosa.stft()* to extract the spectrogram,
    followed by a calculation of the split frequency bin. Next, the magnitude of the
    spectrogram is calculated using *np.abs()* followed by transposition to facilitate
    iteration across every frame. During the iteration, the band energy ratio for
    each frame is calculated using the defined formula and the found split frequency
    bin. The values are stored in a list, *res* which is finally returned as a NumPy
    Array. Finally, the values are plotted using the *plot_band_energy_ratio()* function.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: The band energy ratio plots for the 3 musical instruments are shown below. For
    these plots, the splitting frequency is chosen to be 2048 Hz i.e., frequencies
    below 2048 Hz are considered the lower energy frequencies, and the ones above
    are taken to be higher energy frequencies.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3d3ada0021b62b8e156b9e262298a08e.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: Band Energy Ratio for Acoustic Guitar [Image by Author]
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d8955c1ed97757b1f9f1fd222d59c019.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: Band Energy Ratio for Brass [Image by Author]
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2aee6d3361cb05678ae26decc6b0e89b.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
- en: Band Energy Ratio for Drum Set [Image by Author]
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: A high band energy ratio (for brass) indicates the larger presence of lower-frequency
    components relative to the higher-frequency components. Thus, we observe that
    brass instruments produce a significant amount of energy in the lower frequency
    bands compared to the higher frequency bands. The acoustic guitar has a lower
    BER compared to brass instruments, indicating a relatively lesser energy contribution
    in the lower frequency bands compared to the higher frequency bands. In general,
    acoustic guitars tend to have a more balanced energy distribution across the frequency
    spectrum, with relatively less emphasis on the lower frequencies compared to other
    instruments. Finally, the drum set has the lowest BER among the three, suggesting
    a comparatively lower energy contribution in the lower frequency bands relative
    to other instruments.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 高频带能量比（对于铜管乐器）表明低频成分相对于高频成分的存在量较大。因此，我们观察到铜管乐器在低频带产生的能量远大于高频带。声学吉他的 BER 相较于铜管乐器较低，表明在低频带的能量贡献相对较少。总体而言，声学吉他在频率谱上的能量分布较为均衡，相较于其他乐器，对低频的强调较少。最后，鼓组在三者中具有最低的
    BER，表明与其他乐器相比，在低频带的能量贡献相对较低。
- en: 'Feature 6: Spectral Centroid'
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征 6：谱质心
- en: 'Next, we will talk about the spectral centroid, a measure that quantifies information
    about the center of mass or the average frequency of a signal’s spectrum in a
    given time frame. Mathematically, for any frame k, the spectral centroid is:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论谱质心，这是一个量化信号在给定时间范围内的质心或平均频率的信息的度量。数学上，对于任何帧 k，谱质心为：
- en: '![](../Images/34fdfd3c2e0b32919947896ed8a566a3.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/34fdfd3c2e0b32919947896ed8a566a3.png)'
- en: 'Think of it like a weighted sum of the frequency bin indexes, where the weight
    is determined by the energy contribution of the bin in the given time frame. Normalization
    is also done by dividing the weighted sum by the sum of all the weights to facilitate
    uniform comparison across different signals. The Python code for computing the
    spectral centroid of a signal is shown below:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将其视为频率箱索引的加权和，其中权重由给定时间范围内箱的能量贡献决定。归一化通过将加权和除以所有权重的总和来完成，以便在不同信号之间进行均匀比较。计算信号谱质心的
    Python 代码如下所示：
- en: '[PRE10]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the above code, the spectral centroid function is defined to produce the
    array of spectral centroids for all time frames. Subsequently, the *sc()* function
    is defined to calculate the spectral centroid of one frame through a simple iterative
    process that multiplies the index values with the magnitude followed by normalization
    to obtain the average frequency bin. Before plotting the spectral centroid values
    returned by *spectral_centroid()*, an additional function called bin to freq is
    defined as a helper function for plotting. This function converts the average
    bin values to the corresponding frequency values which can be plotted over the
    original spectrogram to have a consistent idea about the variation of the spectral
    centroid across time. The output plots (with the overlay of centroid variation
    over the spectrogram) are shown below:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，定义了谱质心函数，以生成所有时间帧的谱质心数组。随后，定义了*sc()*函数，通过简单的迭代过程计算一个帧的谱质心，该过程将索引值与幅度相乘，然后进行归一化以获得平均频率箱。在绘制由*spectral_centroid()*返回的谱质心值之前，定义了一个名为
    bin to freq 的附加函数，作为绘图的辅助函数。该函数将平均箱值转换为相应的频率值，可以在原始谱图上绘制，以便对谱质心在时间上的变化有一致的了解。输出图（带有谱质心变化的叠加）如下所示：
- en: '![](../Images/52ed8382641aca369d41dfe7be931b8c.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/52ed8382641aca369d41dfe7be931b8c.png)'
- en: Spectral Centroid for Acoustic Guitar [Image by Author]
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 对于声学吉他的谱质心 [图片由作者提供]
- en: '![](../Images/c9983d258163de11ade2b18cb269a0be.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c9983d258163de11ade2b18cb269a0be.png)'
- en: Spectral Centroid for Brass [Image by Author]
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的谱质心 [图片由作者提供]
- en: '![](../Images/115edba0ee7751f1c76a8544ca2f1cdd.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/115edba0ee7751f1c76a8544ca2f1cdd.png)'
- en: Spectral Centroid for Drum Set [Image by Author]
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于鼓组的谱质心 [图片由作者提供]
- en: The spectral centroid is quite analogous to the RMSE metric for time-domain
    analysis and is commonly used as a descriptor for sound timbre and brightness.
    Sounds with higher spectral centroids tend to have a brighter or more treble-oriented
    quality, while lower centroid values are associated with a rather darker or bass-oriented
    character. Spectral centroid is one of the most important features for audio machine
    learning, often used in applications involving audio/music genre classification.
  id: totrans-200
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 频谱质心与时间域分析中的 RMSE 度量非常类似，通常用作声音音色和亮度的描述符。具有较高频谱质心的声音往往具有更明亮或偏向高音的特质，而较低质心值则与较暗或偏向低音的特质相关联。频谱质心是音频机器学习中最重要的特征之一，常用于音频/音乐类型分类的应用中。
- en: 'Feature 7: Spectral Bandwidth'
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '特征 7: 频谱带宽'
- en: 'Now, we will talk about spectral bandwidth/spread, a measure that quantifies
    information about the spread of energies across the component frequencies of a
    signal’s spectrum in a given time frame. Think of it this way: If the spectral
    centroid is the mean/average value, the spectral bandwidth is a measure of its
    spread/variance about the centroid. Mathematically, for any frame k, the spectral
    bandwidth is:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将讨论频谱带宽/扩展，它是量化信号频谱在给定时间框架内能量分布的信息的度量。可以这样理解：如果频谱质心是均值/平均值，那么频谱带宽就是它围绕质心的扩展/方差的度量。数学上，对于任何帧
    k，频谱带宽为：
- en: '![](../Images/cc6c9a8519b30c3f69c03d1e78d76db5.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cc6c9a8519b30c3f69c03d1e78d76db5.png)'
- en: 'where SCₖ denotes the spectral centroid of the kth frame. As before, normalization
    is done by dividing the weighted sum by the sum of all the weights to facilitate
    uniform comparison across different signals. The Python code for computing the
    spectral bandwidth of a signal is shown below:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 SCₖ 表示第 k 帧的频谱质心。如前所述，通过将加权和除以所有权重的总和来进行归一化，以便在不同信号之间进行统一比较。用于计算信号频谱带宽的 Python
    代码如下所示：
- en: '[PRE11]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As before, in the above code, the spectral bandwidth function is defined to
    produce the array of spectral spread for all time frames using the sb helper function,
    which iteratively calculates the bandwidth of one frame. Finally, the plot spectral
    bandwidth function is employed to plot these bandwidth values. The output plots
    are shown below:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，在上述代码中，频谱带宽函数被定义为使用 sb 辅助函数生成所有时间帧的频谱扩展数组，该函数迭代地计算一个帧的带宽。最后，使用绘图频谱带宽函数绘制这些带宽值。输出的图示如下：
- en: '![](../Images/11b589be693d397604637c8fe7c86248.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/11b589be693d397604637c8fe7c86248.png)'
- en: Spectral Bandwidth for Acoustic Guitar [Image by Author]
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 原声吉他的频谱带宽 [图像来源：作者]
- en: '![](../Images/61b937459a1d5e947ba6159454bf07af.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61b937459a1d5e947ba6159454bf07af.png)'
- en: Spectral Bandwidth for Brass [Image by Author]
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的频谱带宽 [图像来源：作者]
- en: '![](../Images/f217303174680d417cfec24ba244a7f1.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f217303174680d417cfec24ba244a7f1.png)'
- en: Spectral Bandwidth for Drum Set [Image by Author]
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓组的频谱带宽 [图像来源：作者]
- en: Spectral bandwidth can be used in various audio analysis/classification tasks
    owing to its ability to provide information about the spread or width of frequencies
    present in a signal. A higher spectral bandwidth (as seen for brass and drum sets)
    indicates a wider range of frequencies, suggesting a more diverse or complex signal.
    On the other hand, a lower bandwidth suggests a narrower range of frequencies,
    indicating a more focused or tonally pure signal.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱带宽可以用于各种音频分析/分类任务，因为它能够提供关于信号中频率分布或宽度的信息。较高的频谱带宽（如铜管乐器和鼓组所示）表示频率范围较宽，暗示信号更为多样或复杂。另一方面，较低的带宽则表示频率范围较窄，指示信号更集中或音调更纯。
- en: 'Feature 8: Spectral Flatness'
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '特征 8: 频谱平坦度'
- en: Finally, we will talk about spectral flatness (aka Weiner entropy), a measure
    that informs about the flatness’ or uniformity of the power spectrum of an audio
    signal. It helps us know how close the audio signal is to a pure tone (as opposed
    to noise-like) and is therefore also called the tonality coefficient. For any
    frame k, the spectral flatness is the ratio of its geometric mean to the arithmetic
    mean. Mathematically,
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论频谱平坦度（又称为维纳熵），这是一种衡量音频信号功率谱平坦度或均匀度的度量。它帮助我们了解音频信号距离纯音（与噪声相比）有多近，因此也被称为音调系数。对于任何帧
    k，频谱平坦度是其几何均值与算术均值的比率。数学上，
- en: '![](../Images/039fe5b4860d15758e14aeb5fc0dd847.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/039fe5b4860d15758e14aeb5fc0dd847.png)'
- en: 'The Python code for computing the spectral flatness of a signal is shown below:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 用于计算信号频谱平坦度的 Python 代码如下所示：
- en: '[PRE12]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The structure of the above code is the same as those for other frequency domain
    extraction methods. The only difference lies in the feature extraction function
    inside the for loop, which computes the arithmetic and geometric mean using NumPy
    functions and calculates their ratio to produce the spectral flatness values for
    each time frame. The output plots are shown below:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的结构与其他频域提取方法相同。唯一的区别在于for循环内的特征提取函数，它使用NumPy函数计算算术和几何均值，并计算其比率以生成每个时间帧的频谱平坦度值。输出图如下：
- en: '![](../Images/1a46c99fcd48d804ebe34976d1e67454.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1a46c99fcd48d804ebe34976d1e67454.png)'
- en: Spectral Flatness for Acoustic Guitar [Image by Author]
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 声学吉他的频谱平坦度 [作者提供的图片]
- en: '![](../Images/3a9273be70cc839ff70e9c5766c1a79a.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3a9273be70cc839ff70e9c5766c1a79a.png)'
- en: Spectral Flatness for Brass [Image by Author]
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 铜管乐器的频谱平坦度 [作者提供的图片]
- en: '![](../Images/22e29a629051482360e907a6e307f02e.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22e29a629051482360e907a6e307f02e.png)'
- en: Spectral Flatness for Drum Set [Image by Author]
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓组的频谱平坦度 [作者提供的图片]
- en: A high spectral flatness value (one that is closer to 1), indicates a more uniform
    or balanced distribution of energy across different frequencies in the signal.
    This is seen consistently for the drum set, suggesting a sound that is more ”noise-like”
    or broadband, without prominent peaks or emphasis on specific frequencies (as
    noticed earlier from the lack of periodicity).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 高频谱平坦度值（即接近1的值）表示信号中能量在不同频率上的分布更均匀或平衡。这在鼓组中表现得尤为明显，表明这种声音更具“噪声性”或宽频带，没有显著的峰值或对特定频率的强调（如之前从缺乏周期性中观察到的）。
- en: On the other hand, a low spectral flatness value (especially for acoustic guitar
    and somewhat for brass) implies a more uneven power spectrum, with energy being
    concentrated around a few specific frequencies. This shows the presence of tonal
    or harmonic components in the sound (as reflected in their periodic time domain
    structure). In general, music with distinct pitch/frequencies tends to have lower
    spectral flatness values, while noisier (and non-tonal) sounds exhibit higher
    spectral flatness values.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，低频谱平坦度值（特别是对于声学吉他以及某程度上对于铜管乐器）表示功率谱更不均匀，能量集中在几个特定频率周围。这表明声音中存在音调或谐波成分（如其周期性时间域结构所反映的）。一般来说，具有明确音高/频率的音乐往往具有较低的频谱平坦度值，而噪声（以及非音调）声音则表现出较高的频谱平坦度值。
- en: Conclusion
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'In this article, we dived deep into the different strategies and techniques
    for feature extraction that constitutes an integral part of audio-signal processing
    in musical engineering. We started with learning about the basics of sound production
    and propagation that can be effectively translated into pressure variations over
    time giving rise to its time domain representation. We discussed the digital representation
    of sound and its vital parameters including sampling rate, frame size, and hop
    length. Time domain features such as amplitude envelope, root mean square energy,
    crest factor, peak-to-power ratio, and zero crossing rate were discussed theoretically
    and evaluated computationally on 3 musical instruments: acoustic guitar, brass,
    and drum sets. Subsequently, the frequency-domain representation of sound was
    presented and analyzed through various theoretical discussions on the Fourier
    transform and spectrograms. This paved the way for a wide array of frequency-domain
    features including band energy ratio, spectral centroid, bandwidths, and tonality
    coefficient, each of which can be efficiently utilized to gauge a particular characteristic
    of the input audio. There’s a lot more to signal processing applications including
    mel-spectrograms, cepstral coefficients, noise control, audio synthesis, et al.
    I hope this explanation will serve as a foundation for further exploration of
    advanced concepts in the field.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Hope you enjoyed reading this article! In case you have any doubts or suggestions,
    do reply in the comment box.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Please feel free to contact me via [mail](mailto:naman.agr03@gmail.com).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: If you liked my article and want to read more of them, please follow me.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '**Note:** All images (except for the cover image) have been made by the author.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Crest factor. (2023). In *Wikipedia*. [https://en.wikipedia.org/w/index.php?title=Crest_factor&oldid=1158501578](https://en.wikipedia.org/w/index.php?title=Crest_factor&oldid=1158501578)
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '*librosa — Librosa 0.10.1dev documentation*. (n.d.). Retrieved June 5, 2023,
    from [https://librosa.org/doc/main/index.html](https://librosa.org/doc/main/index.html)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Spectral flatness. (2022). In *Wikipedia*. [https://en.wikipedia.org/w/index.php?title=Spectral_flatness&oldid=1073105086](https://en.wikipedia.org/w/index.php?title=Spectral_flatness&oldid=1073105086)
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: The Sound of AI. (2020, August 1). *Valerio Velardo*. [https://valeriovelardo.com/the-sound-of-ai/](https://valeriovelardo.com/the-sound-of-ai/)
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
