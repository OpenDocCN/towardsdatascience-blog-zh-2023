- en: Efficient Model Fine-Tuning with Bottleneck Adapter
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/efficient-model-fine-tuning-with-bottleneck-adapter-5162fcec3909?source=collection_archive---------9-----------------------#2023-11-22](https://towardsdatascience.com/efficient-model-fine-tuning-with-bottleneck-adapter-5162fcec3909?source=collection_archive---------9-----------------------#2023-11-22)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: How to fine-tune Transformer-based models with bottleneck adapters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@marcellusruben?source=post_page-----5162fcec3909--------------------------------)[![Ruben
    Winastwan](../Images/15ad0dd03bf5892510abdf166a1e91e1.png)](https://medium.com/@marcellusruben?source=post_page-----5162fcec3909--------------------------------)[](https://towardsdatascience.com/?source=post_page-----5162fcec3909--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----5162fcec3909--------------------------------)
    [Ruben Winastwan](https://medium.com/@marcellusruben?source=post_page-----5162fcec3909--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F5dae9da73c9b&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-model-fine-tuning-with-bottleneck-adapter-5162fcec3909&user=Ruben+Winastwan&userId=5dae9da73c9b&source=post_page-5dae9da73c9b----5162fcec3909---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----5162fcec3909--------------------------------)
    ·14 min read·Nov 22, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F5162fcec3909&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-model-fine-tuning-with-bottleneck-adapter-5162fcec3909&user=Ruben+Winastwan&userId=5dae9da73c9b&source=-----5162fcec3909---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F5162fcec3909&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fefficient-model-fine-tuning-with-bottleneck-adapter-5162fcec3909&source=-----5162fcec3909---------------------bookmark_footer-----------)![](../Images/b79802cb5528fbfe5bb1a2f50166d41b.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Photo by Karolina Grabowska: [https://www.pexels.com/photo/set-of-modern-port-adapters-on-black-surface-4219861/](https://www.pexels.com/photo/set-of-modern-port-adapters-on-black-surface-4219861/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fine-tuning is one of the most common things that we can do to gain better
    performance from a deep learning model on our specific task. The time we need
    to fine-tune a model normally corresponds to its size: the bigger the size of
    the model, the longer the time needed to fine-tune it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I think we can agree that nowadays, deep learning models such as Transformer-based
    models are becoming increasingly sophisticated. Overall, this is a good thing
    to see but it comes with a caveat: they tend to have huge number of parameters.
    Thus, fine-tuning large models is becoming more challenging to manage and we need
    a more efficient way to do it.'
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’re going to discuss one of several efficient fine-tuning
    methods called bottleneck adapter. Although you can apply this method to any deep
    learning model, we’ll only focus our attention to its application on Transformer-based
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The structure of this article is as follows: first, we’re going to do a normal
    fine-tuning of a BERT model on a specific dataset. Then, we will insert some bottleneck
    adapters into our BERT model with the help of `adapter-transformers` library to
    see how they can help us to make fine-tuning…'
  prefs: []
  type: TYPE_NORMAL
