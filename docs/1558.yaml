- en: The Ultimate Preprocessing Pipeline for Your NLP Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-ultimate-preprocessing-pipeline-for-your-nlp-models-80afd92650fe?source=collection_archive---------15-----------------------#2023-05-08](https://towardsdatascience.com/the-ultimate-preprocessing-pipeline-for-your-nlp-models-80afd92650fe?source=collection_archive---------15-----------------------#2023-05-08)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Get the most out of training NLP ML models by feeding the best possible input
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://rahulraj24.medium.com/?source=post_page-----80afd92650fe--------------------------------)[![Rahulraj
    Singh](../Images/8bfa5fdcb41c9c81c026b88744145b11.png)](https://rahulraj24.medium.com/?source=post_page-----80afd92650fe--------------------------------)[](https://towardsdatascience.com/?source=post_page-----80afd92650fe--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----80afd92650fe--------------------------------)
    [Rahulraj Singh](https://rahulraj24.medium.com/?source=post_page-----80afd92650fe--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ·
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2Fafe0d8607525&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-preprocessing-pipeline-for-your-nlp-models-80afd92650fe&user=Rahulraj+Singh&userId=afe0d8607525&source=post_page-afe0d8607525----80afd92650fe---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----80afd92650fe--------------------------------)
    ·10 min read·May 8, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F80afd92650fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-preprocessing-pipeline-for-your-nlp-models-80afd92650fe&user=Rahulraj+Singh&userId=afe0d8607525&source=-----80afd92650fe---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F80afd92650fe&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-ultimate-preprocessing-pipeline-for-your-nlp-models-80afd92650fe&source=-----80afd92650fe---------------------bookmark_footer-----------)![](../Images/e689a96f5fd638b621c932f2bb07d426.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Cyrus Crossan](https://unsplash.com/@cys_escapes?utm_source=medium&utm_medium=referral)
    on [Unsplash](https://unsplash.com/?utm_source=medium&utm_medium=referral)
  prefs: []
  type: TYPE_NORMAL
- en: If you have worked on a text summarization project before, you would have noticed
    the difficulty in seeing the results you expect to see. You have a notion in mind
    for how the algorithm should work and what sentences it should mark in the text
    summaries, but more often than not the algorithm sends out results that are “not-so-accurate”.
    Even more interesting is keyword extraction because all sorts of algorithms from
    topic modeling to vectorizing embeddings, are all really good but given a paragraph
    as an input the results they give out are again “not-so-accurate” because the
    most often occurring word is not always the most important word of the paragraph.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing and data cleaning requirements vary largely based on the use case
    you are trying to solve. I will attempt to create a generalized pipeline that
    should work well for all NLP models, but you will always need to tune the steps
    to achieve the best results for your use-case. In this story, I will focus on
    NLP models that solve for **topic modelling, keyword extraction, and text summarization**.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
