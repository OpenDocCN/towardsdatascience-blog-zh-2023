- en: 'The Research Agent: Addressing the Challenge of Answering Questions Based on
    a Large Text Corpus'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://towardsdatascience.com/the-research-agent-4ef8e6f1b741?source=collection_archive---------0-----------------------#2023-08-29](https://towardsdatascience.com/the-research-agent-4ef8e6f1b741?source=collection_archive---------0-----------------------#2023-08-29)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I made an **Autonomous AI Research Agent** that can answer difficult questions
    with deep multi-hop reasoning capabilities
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@rahul.nyk?source=post_page-----4ef8e6f1b741--------------------------------)[![Rahul
    Nayak](../Images/9f8aa2f9af4e02b31c114222756489e5.png)](https://medium.com/@rahul.nyk?source=post_page-----4ef8e6f1b741--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4ef8e6f1b741--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4ef8e6f1b741--------------------------------)
    [Rahul Nayak](https://medium.com/@rahul.nyk?source=post_page-----4ef8e6f1b741--------------------------------)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: ·
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F473e87f4b733&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-research-agent-4ef8e6f1b741&user=Rahul+Nayak&userId=473e87f4b733&source=post_page-473e87f4b733----4ef8e6f1b741---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4ef8e6f1b741--------------------------------)
    ·16 min read·Aug 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4ef8e6f1b741&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-research-agent-4ef8e6f1b741&user=Rahul+Nayak&userId=473e87f4b733&source=-----4ef8e6f1b741---------------------clap_footer-----------)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: --
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ef8e6f1b741&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-research-agent-4ef8e6f1b741&source=-----4ef8e6f1b741---------------------bookmark_footer-----------)![](../Images/91b348b741ea57a92d2e3b954a304f27.png)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Image by the Author (Generated using Photoshop Generative fill)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '**Introduction to the problem**'
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 2021, I started working on the challenge of answering questions based on
    a large corpus of text. In the era before the pre-trained transformers, this problem
    was a tough one to crack.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: And to my frustration, I started my experiments with one of the most complex
    and intricate stories ever written, The Mahabharata. For those unfamiliar with
    the work, the Mahabharata is a collection of 18 books with a total of about 1.8
    million words. It is the largest poem ever written with about 90,000 verses. It
    is roughly ten times the length of the Iliad and the Odyssey combined. But it
    is not only the length but also the breadth of Mahabharata that is staggering.
    Highly nonlinear and complex in its causes and effects, it has thousands of characters
    spanning seven generations, and out of those, not a single one is completely good
    or evil. It has profound philosophical commentaries on Duty (Karma), Choices and
    Human existence, especially on the conflicts of duties and the choices between
    multiple wrongs. The Bhagavad Gita (Key philosophy of Hinduism) is also a part
    of the 6th book of the Mahabharata.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 令我沮丧的是，我开始用《摩诃婆罗多》这一最复杂、最精细的故事之一进行实验。对于那些不熟悉这部作品的人来说，《摩诃婆罗多》是一部由18本书组成的总字数约为180万的作品。它是有史以来最长的诗歌，大约有90,000节。它的长度大约是《伊利亚特》和《奥德赛》总和的十倍。但《摩诃婆罗多》的震撼不仅在于长度，还有其广度。它在因果关系上高度非线性和复杂，拥有跨越七代的数千个角色，而这些角色中没有一个是完全善良或邪恶的。它对职责（业）、选择和人类存在，尤其是职责冲突和多重错误选择的冲突进行了深刻的哲学评论。《博伽梵歌》（印度教的核心哲学）也是《摩诃婆罗多》第六本书的一部分。
- en: I compiled the [Mahabharata text data](https://github.com/rahulnyk/mahabharata.git)
    from multiple sources online into a clean data set. However, I could not find
    a method to implement meaningful QA on the text.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我将来自多个在线来源的[《摩诃婆罗多》文本数据](https://github.com/rahulnyk/mahabharata.git)整理成了一个干净的数据集。然而，我找不到一种方法来对这些文本实施有意义的问答。
- en: In less than two years, all that changed.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 不到两年的时间，一切都发生了变化。
- en: The rapid advancements in AI and Large pre-trained transformers are changing
    the world of technology profoundly and fundamentally. And I am fascinated by it,
    much like most techies these days are.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: AI 和大型预训练变换器的快速进步正在深刻而根本地改变技术世界。我对这一点感到着迷，就像现在大多数技术人员一样。
- en: So, a few months ago, I returned to the problem with a naive knowledge of the
    newborn art of prompt engineering. But this time with a general idea of making
    an **Autonomous** **Research Agent** that can work with any complex knowledge
    base.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 几个月前，我带着对新兴的提示工程艺术的初步了解重新审视了这个问题。但这次我有了一个大致的想法，即创建一个可以处理任何复杂知识库的**自主** **研究代理**。
- en: The Mahabharata is one of the most complex use cases. However, in every domain
    of knowledge, Law, Scientific research, Education, Medical, etc., every project
    starts with deep research on the prior art. So the problem is worthy enough to
    solve.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 《摩诃婆罗多》是最复杂的用例之一。然而，在每个知识领域，如法律、科学研究、教育、医疗等，每个项目都从对前人工作的深入研究开始。因此，这个问题是值得解决的。
- en: '**The Research Agent**'
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**研究代理**'
- en: Here, I will discuss the design and implementation of an Autonomous **AI Research
    Agent** that can solve the problem of multi-hop KBQA with deep reasoning capability.
    I will share the git repo with an initial implementation of the research agent
    in a Python notebook. If you are interested only in that part, please feel free
    to skip to the Implementation section later in this article.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将讨论一个可以解决多跳 KBQA 问题并具备深度推理能力的**自主 AI 研究代理**的设计和实施。我会分享一个包含研究代理初步实现的 Python
    笔记本的 git 仓库。如果你对这部分内容感兴趣，请随时跳到本文后面的实施部分。
- en: If you are interested in knowing more about AI Agent, ‘Knowledge-Based Question
    Answer’ (KBQA), the ‘Why’, the ‘What’, and the design evolution of the AI Research
    Agent, then please read along.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对了解更多关于 AI 代理、‘基于知识的问题回答’（KBQA）、‘为什么’、‘什么’以及 AI 研究代理的设计演变感兴趣，请继续阅读。
- en: '**Why?**'
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**为什么？**'
- en: The first question that one may ask is why not just use the ChatGPT interface
    and ask questions. It has been trained on a humungous volume of Internet data
    generated till 2021, so a text corpus like the Mahabharata is known to it.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可能有人会问，为什么不直接使用 ChatGPT 接口提问。它已经在2021年之前生成的大量互联网数据上进行了训练，因此像《摩诃婆罗多》这样的文本语料库对它来说是已知的。
- en: That was my first approach. I asked the ChatGPT several questions about the
    Mahabharata. I got good answers to some questions. However, they lack the rigour
    for the most. And that is expected. The GPT is trained over general data sets.
    It can very well understand and interpret natural languages. It can also reason
    well enough. However, it is not an expert in any specific domain. So, while it
    might have some knowledge of The Mahabharata, it may not respond with deeply researched
    answers. At times the GPT may not have any answer at all. In those cases, it either
    humbly refuses to answer the question, or confidently makes them up (Hallucinations).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我的第一种方法。我问 ChatGPT 关于《摩诃婆罗多》的几个问题。我得到了对一些问题的良好回答。然而，大部分答案缺乏严谨性。这是可以预料的。GPT
    是在通用数据集上训练的。它可以很好地理解和解释自然语言。它的推理能力也足够好。然而，它在任何特定领域都不是专家。所以，尽管它可能对《摩诃婆罗多》有一些了解，但可能不会给出深入研究的答案。有时
    GPT 甚至可能没有任何答案。在这些情况下，它要么谦虚地拒绝回答问题，要么自信地编造答案（幻觉）。
- en: The second most obvious way to achieve KBQA is to use a Retrieval QA Prompt.
    Here is where LangChain starts being extremely useful.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 KBQA 的第二种最明显的方法是使用检索问答提示。这时，LangChain 显得极为有用。
- en: '**Retrieval QA**'
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**检索问答**'
- en: For those unfamiliar with the LangChain library, It is one of the best ways
    to use LLMs like GPT in your code. Here is an implementation of KBQA using LangChain.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些不熟悉 LangChain 库的人来说，它是将 LLMs（如 GPT）用于代码中的最佳方式之一。这里是使用 LangChain 实现 KBQA
    的方法。
- en: '[](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa?source=post_page-----4ef8e6f1b741--------------------------------)
    [## QA using a Retriever | 🦜️🔗 Langchain'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[## 使用检索器进行问答 | 🦜️🔗 Langchain](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa?source=post_page-----4ef8e6f1b741--------------------------------)'
- en: This example showcases question answering over an index.
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这个示例展示了在索引上进行问答。
- en: python.langchain.com](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa?source=post_page-----4ef8e6f1b741--------------------------------)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[python.langchain.com](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa?source=post_page-----4ef8e6f1b741--------------------------------)'
- en: To summarise, here are the steps to achieve KBQA on any body of documents
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，实现任何文档集合上的 KBQA 的步骤如下
- en: Split the knowledge base into text chunks.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将知识库拆分成文本块。
- en: Create a numerical representation (Embeddings) for each chunk and save them
    to a vector database.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个文本块创建数值表示（嵌入）并将其保存到向量数据库中。
- en: '*If your data is static, Steps 1 and 2 are one-time efforts.*'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*如果你的数据是静态的，第 1 步和第 2 步是一次性的工作。*'
- en: Run a semantic search using the user’s query on this database and fetch relevant
    text chunks.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用用户的查询在这个数据库上进行语义搜索，并获取相关的文本块。
- en: Send these text chunks to the LLM along with the user’s questions and ask them
    to Answer.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这些文本块与用户的问题一起发送到 LLM，并要求其回答。
- en: Here is a graphical representation of this process.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该过程的图示表示。
- en: '![](../Images/63234bd045fe01ff4f4ca296ff725645.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/63234bd045fe01ff4f4ca296ff725645.png)'
- en: Image by the Author created using draw.io
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 作者通过 draw.io 创建的图片
- en: So why go any further? It seems like a solved problem!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么要继续呢？这似乎是一个已解决的问题！
- en: Not quite 🙁
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 不太对 🙁
- en: This approach works well for simple questions on a simple and factual knowledge
    base. However, it does not work for a more complex knowledge base and more complicated
    questions that require deeper, Multi-hop, reasoning. Multi-hop reasoning refers
    to a process in which multiple steps of logical or contextual inference are taken
    to arrive at a conclusion or answer to a question.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法适用于简单问题和简单的事实知识库。然而，对于需要更深层次、多跳推理的复杂知识库和更复杂的问题则不适用。多跳推理指的是通过多个逻辑或上下文推理步骤来得出结论或回答问题的过程。
- en: Moreover, the LLMs are limited in the length of text they can chew in one prompt.
    You can, of course, send the documents one at a time and then ‘refine’ or ‘reduce’
    the answer with every call. However, this approach does not allow for complex
    ‘multi-hop’ reasoning. In some cases, the results using the ‘refine’ or ‘reduce’
    approach are better than simply stuffing all the documents in a single prompt,
    but not by a high margin.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LLMs 在一次提示中处理文本的长度是有限的。你可以当然逐个发送文档，然后通过每次调用来‘细化’或‘缩减’答案。然而，这种方法不允许进行复杂的‘多跳’推理。在某些情况下，使用‘细化’或‘缩减’方法得到的结果比仅仅将所有文档塞进一个提示中要好，但差距不大。
- en: For a complex knowledge base, the users’ question by itself may not be enough
    to find all the relevant documents that can help the LLM arrive at an accurate
    answer.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Who was Arjuna?
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is a simple question and can be answered with limited context. However,
    the following question:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Why did the Mahabharata war happen?
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is a question that has its context spread all across the text corpus. The question
    itself has limited information about its context. To find the relevant chunks
    of text and then to reason based on that may not work.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: So what next?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '**AI Agents**'
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is one of the coolest concepts that has emerged after the advent of AI.
    If you don’t know the concept of an AI Agent, I can’t wait to explain it to you,
    but I may still fail to convey its awesomeness. Let me use ChatGPT to explain
    it first.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: An AI agent, also known simply as an “agent,” refers to a software program or
    system that can autonomously perceive its environment, make decisions, and take
    actions to achieve specific goals. AI agents are designed to mimic human-like
    behaviour in problem-solving and decision-making tasks. They operate within a
    defined environment and interact with that environment to achieve desired outcomes.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Simply speaking, an Agent is a program that takes a problem, decides how to
    solve it, and then solves it. The Agent is provided with a set of tools like Functions,
    methods, API calls, etc. It can use any of them if it chooses to do so in any
    sequence it deems fit. Contrast this to conventional software, where the sequence
    of steps needed to solve the problem is pre-programmed. This is, of course, a
    very vague definition. But you probably get the hang of it by now.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Here are the two different agents I tried for our KBQA use case.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '***React*** This Agent uses a [‘ReAct’ (Reason and Action) style of reasoning](https://www.promptingguide.ai/techniques/react)
    to decide which tool to use for the given problem.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the langChain implementation of a ReAct Agent:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://python.langchain.com/docs/modules/agents/agent_types/react?source=post_page-----4ef8e6f1b741--------------------------------)
    [## ReAct | 🦜️🔗 Langchain'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: This walkthrough showcases using an agent to implement the ReAct logic.
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: python.langchain.com](https://python.langchain.com/docs/modules/agents/agent_types/react?source=post_page-----4ef8e6f1b741--------------------------------)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'I provided the Agent with the following tools to choose from:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval QA chain with a document store.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Character Glossary search (I created a glossary with Named Entity Recognition
    using a pre-trained model)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikipedia search.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The react agent did not give me good results and failed to converge to any answer
    most of the time. It does not work well with GPT 3.5\. It may work better with
    GPT 4, which is 20 -30 times more expensive than GPT 3.5, so that may not be an
    option yet.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Even when it converged, I could not get good results. Someone more knowledgeable
    in creating ‘react’ prompts probably would have done better.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 即使它收敛了，我也无法获得好的结果。可能在创建“反应”提示方面更有经验的人会做得更好。
- en: '***Self-Ask Agent*** This agent asks follow-up questions based on the original
    question and then tries to find the intermediate answers. Using these intermediate
    answers, it finally arrives at a final answer. Here is an article explaining the
    Self-Ask Agent'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '***自我提问代理*** 这个代理根据原始问题提出后续问题，然后尝试找到中间答案。通过这些中间答案，它最终得出一个最终答案。这里是解释自我提问代理的文章'
- en: '[](https://cobusgreyling.medium.com/self-ask-prompting-d0805ea31faa?source=post_page-----4ef8e6f1b741--------------------------------)
    [## Self-Ask Prompting'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://cobusgreyling.medium.com/self-ask-prompting-d0805ea31faa?source=post_page-----4ef8e6f1b741--------------------------------)
    [## 自我提问提示'
- en: Self-Ask Prompting is a progression from Chain Of Thought Prompting. Below are
    a few practical examples and an…
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自我提问提示是一种从链式思维提示演变而来的方法。下面是一些实际的例子和…
- en: cobusgreyling.medium.com](https://cobusgreyling.medium.com/self-ask-prompting-d0805ea31faa?source=post_page-----4ef8e6f1b741--------------------------------)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[cobusgreyling.medium.com](https://cobusgreyling.medium.com/self-ask-prompting-d0805ea31faa?source=post_page-----4ef8e6f1b741--------------------------------)'
- en: This approach gave me some good results. It works well for a Single-hop reason.
    But even this fails for questions that require multiple hops.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法给了我一些不错的结果。它在单跳推理的情况下效果很好，但即使这样，对于需要多跳的问提也会失败。
- en: 'For example, the questions:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，问题：
- en: Who killed Karna, and why?
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 谁杀了卡尔纳，为什么？
- en: Is relatively easy to answer with this approach
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 用这种方法相对容易回答。
- en: The question
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 问题
- en: Why did Arjuna kill Karna, his half-brother?
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为什么阿周那杀了他的半兄卡尔纳？
- en: Is much more difficult to answer. It requires the LLM to know the fact that
    Arjuna did not know that Karna was his half-brother. The LLM can’t know that it
    needs to know this fact, either by understanding the question or by asking further
    questions based on the original question.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要回答这个问题要困难得多。它要求 LLM 知道阿周那不知道卡尔纳是他的半兄弟的事实。LLM 无法知道它需要知道这个事实，无论是通过理解问题还是通过基于原始问题提出进一步的问题。
- en: '**Human Research Process**'
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**人类研究过程**'
- en: Quoting GPT again
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 再次引用 GPT
- en: AI agents are designed to mimic human-like behaviour in problem-solving and
    decision-making tasks
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AI 代理被设计成在解决问题和决策任务中模仿类似人类的行为。
- en: So, my next idea was to research how humans research, the meta-research if you
    like. I imagined myself sitting in a library (College nostalgia) with easy access
    to all the books relevant to the topic of my research. I took a notebook and a
    pen and started jotting down the process I follow when I research a topic.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我的下一个想法是研究人类如何研究，也就是元研究。我想象自己坐在图书馆里（大学的怀旧情怀），能够轻松获取所有与我的研究主题相关的书籍。我拿出一个笔记本和一支笔，开始记录我在研究一个主题时遵循的过程。
- en: Here is what I came up with.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我得到的结果。
- en: '**Research methodology:**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**研究方法论：**'
- en: Note down the original query on a page.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在一页上记下原始查询。
- en: I try to answer the current question by reading a few books. In the process,
    I make a few notes and bookmark a few excerpts that I find most relevant to the
    current question.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我尝试通过阅读几本书来回答当前的问题。在过程中，我做了些笔记，并标记了一些我认为与当前问题最相关的摘录。
- en: Invariably, I find many unknowns in these excerpts. I note these unknowns and
    write down a few more questions that can help me learn about these unknowns.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我在这些摘录中总能发现许多未知之处。我记录下这些未知，并写下更多问题以帮助我了解这些未知。
- en: Out of these questions, I choose one question that is most pertinent to the
    original question.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这些问题中，我选择一个与原始问题最相关的问题。
- en: I go back to step 1
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我回到第一步
- en: After a few such iterations, I ask myself if I have enough information to answer
    the original question.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几次这样的迭代，我问自己是否有足够的信息来回答原始问题。
- en: If yes, then job well done!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是，那么干得好！
- en: If no, then toil on.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不是，那就继续努力吧。
- en: Voila!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 看啊！
- en: Finally, I knew what to code. I hoped that, with some prompt engineering, this
    process could give me more profound answers than any of the other approaches I
    have tried previously.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我知道该编写什么代码。我希望通过一些提示工程，这个过程能给我比之前尝试的其他方法更深刻的答案。
- en: Spoiler alert… it did! :)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 剧透警告……确实如此！:)
- en: Before sitting down to code, I searched the internet for similar ideas. And
    I discovered the BabyAGI. What a wonderful world!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始编码之前，我在互联网上搜索了类似的想法。我发现了 BabyAGI。真是一个奇妙的世界！
- en: Here is a repo describing [the BabyAGI](https://github.com/yoheinakajima/babyagi/tree/main)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是描述 [BabyAGI](https://github.com/yoheinakajima/babyagi/tree/main) 的一个仓库
- en: I realised there were many similarities between BabyAGI and the above research
    process. So with gratitude, I took some inspiration from the prompts used in the
    BabyAGI implementation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我意识到 BabyAGI 与上述研究过程之间有许多相似之处。因此，我怀着感激之情，从 BabyAGI 实现中使用的提示中获得了一些灵感。
- en: '**The Research Agent — Implementation**'
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**研究代理— 实现**'
- en: Here is the same process converted to a flow chart using the amazing [draw.io](http://draw.io)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用惊人的 [draw.io](http://draw.io) 将相同的过程转换为流程图
- en: '![](../Images/e2834b738664984ebb9d6b3b0eb5d794.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2834b738664984ebb9d6b3b0eb5d794.png)'
- en: Image by the Author (Generated using draw.io)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 作者提供的图像（使用 draw.io 生成）
- en: Every blue box in this chart is a call to an LLM.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中的每个蓝色框都是对 LLM 的调用。
- en: '**Components**'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**组件**'
- en: '**QA Agent —** Search for answers and further context'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**QA 代理—** 搜索答案和进一步的背景信息'
- en: This is a simple ***‘stuff’*** Retrieval QA chain that uses a vector store.
    In the future, this can be an AI Agent that uses tools like vector stores, search
    APIs or Wikipedia APIs, Moderation APIs and previous research data. The prompt
    here is tuned to generate succinct answers based on the 1\. The context (documents),
    and 2\. the pertinence to the ***original question***.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个简单的***‘stuff’*** 检索 QA 链，它使用了一个向量存储。在未来，这可以是一个使用向量存储、搜索 API 或维基百科 API、内容审核
    API 和以往研究数据等工具的 AI 代理。这里的提示经过调整，以根据 1. 上下文（文档）和 2. 与***原始问题***的相关性来生成简洁的答案。
- en: Except for the first loop, the ***current question*** is always an intermediate
    question generated in step 2 and chosen in step 3\. The Agent appends the intermediate
    answer to the notes and the latest excerpts (the documents used to answer the
    ***current question***) to the bookmarks. The most recent of these documents are
    utilised in step 2.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了第一轮外，***当前问题*** 总是步骤 2 中生成的中间问题，并在步骤 3 中选择。代理将中间答案附加到笔记中，并将最新的摘录（用于回答***当前问题***的文档）附加到书签中。最新的这些文档将在步骤
    2 中使用。
- en: '**Question Generator —** Ask more questions based on fresh notes'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**问题生成器—** 根据新的笔记提出更多问题'
- en: Here, the agent uses the most recent vector search results matching the ***current
    question*** and uses them to generate more questions pertinent to the ***original
    question***. It appends these questions to the list of ***unanswered questions***.
    The prompt here is tuned such that the newly generated questions do not overlap
    with the existing list of questions.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，代理使用与***当前问题***匹配的最新向量搜索结果，并利用这些结果生成与***原始问题***相关的更多问题。它将这些问题附加到***未回答的问题***列表中。这里的提示经过调整，以确保新生成的问题不会与现有的问题列表重叠。
- en: '**Most Pertinent Question Picker —** Pick one question most pertinent to the
    original question'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最相关问题挑选器—** 挑选出与原始问题最相关的一个问题'
- en: This prompt picks one question from the list of unanswered questions that is
    the most pertinent to the ***original question***. This question is used as the
    ***current question*** for the next loop.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个提示从未回答的问题列表中挑选出一个与***原始问题***最相关的问题。这个问题将作为下一轮的***当前问题***。
- en: In the next loop, the agent removes this question from the list of ***unanswered
    questions*** after generating a fresh set of questions.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在下一轮中，代理会在生成一组新的问题后，从***未回答的问题***列表中删除这个问题。
- en: '**Analyser —** Do I know enough?'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分析器—** 我是否知道足够多？'
- en: I am using a ***max_iterations*** parameter to exit the loop. This works pretty
    well for now. However, it might be better to dynamically decide on the number
    of iterations or an exit strategy based on the evolving context. I will work on
    an ‘analyser’ that can do this autonomously in the future.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我使用了一个***max_iterations*** 参数来退出循环。现在这效果不错。然而，根据不断变化的上下文动态决定迭代次数或退出策略可能会更好。我将来会致力于开发一个可以自主完成这项任务的‘分析器’。
- en: '**Research Compiler —** Compile the research'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**研究编译器—** 编译研究'
- en: This is the final prompt. It uses the notes made during the research process
    to arrive at an elaborate `final answer` to the `original questions`.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是最终的提示。它利用研究过程中记录的笔记，得出对`原始问题`的详细`最终答案`。
- en: '**Results**'
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**结果**'
- en: The Research Agent is a big improvement over all the previous approaches I have
    tried. It yields more detailed and accurate answers than any other approach. I
    have been playing with this for a few weeks now, and I am surprised by the richness
    of the answers I get.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 研究代理在我尝试过的所有方法中是一个重大改进。它提供的答案比任何其他方法都更详细、准确。我玩了几个星期这个方法，对得到的答案的丰富性感到惊讶。
- en: The Agent avoids the problem of hallucinations to a greater extent than any
    previous approach. It autocorrects the hallucinations and the factual errors it
    generates in the first few iterations, during later ones. The deeper it gets into
    a problem, the more accurately it yields the result.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 该代理在避免幻觉问题方面比任何以前的方法都有更大的进展。它会在初期的几次迭代中自动纠正产生的幻觉和事实错误。它在问题的深入处理过程中，结果会更为准确。
- en: Here is an example run.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例运行。
- en: 'Questions: *Why did the Pandavas have to go live in the forest for 12 years?*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：*为什么潘达瓦斯必须在森林中生活12年？*
- en: Output —
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 输出 —
- en: '![](../Images/b47104951fa815be1000dafbcc2a7428.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b47104951fa815be1000dafbcc2a7428.png)'
- en: Just in case you are curious, here is the final answer
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣，这是最终答案
- en: '[PRE0]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This answer is quite an elaborate one. But the beauty of the agent is not just
    that it answered the original question accurately but that it went further and
    found out the story surrounding the question.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这个答案相当详细。但代理的美妙之处不仅在于它准确回答了原始问题，还在于它进一步探索了与问题相关的故事。
- en: In most cases, the answers I get are rich in such details. And every such answer
    inspires my curiosity for further enquiry.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，我得到的答案充满了细节。每个这样的答案都激发了我进一步探究的好奇心。
- en: The Agent also yields a set of ***answered questions*** and **unanswered questions**
    that it notes down during the research process. So after every run, it leads me
    to many other questions that I can ask. In the past few weeks, I have learned
    more about the Mahabharata than I did in many years before that.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该代理还会生成一组***已回答的问题***和**未回答的问题**，并在研究过程中记录下来。因此，每次运行后，它都会引导我提出更多的问题。在过去的几周里，我对《摩诃婆罗多》的了解比以前的多年都要多。
- en: '[PRE1]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Imagine following the same process for other domains of knowledge, quite an
    exhilarating thought!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下将相同的过程应用于其他知识领域，真是令人兴奋的想法！
- en: '**The Code**'
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**代码**'
- en: And here are the Python notebooks with the implementation of the Research Agent.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是实现研究代理的 Python 笔记本。
- en: '[](https://github.com/rahulnyk/research_agent?source=post_page-----4ef8e6f1b741--------------------------------)
    [## GitHub - rahulnyk/research_agent'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/rahulnyk/research_agent?source=post_page-----4ef8e6f1b741--------------------------------)
    [## GitHub - rahulnyk/research_agent'
- en: Contribute to rahulnyk/research_agent development by creating an account on
    GitHub.
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过在 GitHub 上创建一个帐户，来为 rahulnyk/research_agent 的开发做出贡献。
- en: github.com](https://github.com/rahulnyk/research_agent?source=post_page-----4ef8e6f1b741--------------------------------)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/rahulnyk/research_agent?source=post_page-----4ef8e6f1b741--------------------------------)
- en: The Git repository of the Mahabharata dataset
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 《摩诃婆罗多》数据集的 Git 仓库
- en: '[](https://github.com/rahulnyk/mahabharata?source=post_page-----4ef8e6f1b741--------------------------------)
    [## GitHub - rahulnyk/mahabharata: Mahabharata text compiled from multiple sources,
    split into chunks…'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[](https://github.com/rahulnyk/mahabharata?source=post_page-----4ef8e6f1b741--------------------------------)
    [## GitHub - rahulnyk/mahabharata: 从多个来源编纂的《摩诃婆罗多》文本，分割成若干部分…'
- en: Mahabharata text is compiled from multiple sources, split into chunks, and parsed
    into CSV files with metadata. Named entities…
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 《摩诃婆罗多》文本是从多个来源编纂的，分割成若干部分，并解析成带有元数据的 CSV 文件。命名实体…
- en: github.com](https://github.com/rahulnyk/mahabharata?source=post_page-----4ef8e6f1b741--------------------------------)
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: github.com](https://github.com/rahulnyk/mahabharata?source=post_page-----4ef8e6f1b741--------------------------------)
- en: '**What next?**'
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**接下来做什么？**'
- en: The current implementation is a simple version of the idea of an autonomous
    AI Research Agent. I turned the research process several times throughout the
    implementation of the Agent. It has been an exciting journey, but the fun is not
    over yet. Here are some of the enhancements I am currently working on.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 当前实现是自主 AI 研究代理概念的一个简单版本。在代理的实现过程中，我对研究过程进行了几次修改。这是一次令人兴奋的旅程，但乐趣还未结束。以下是我目前正在进行的一些改进。
- en: Deploy this agent on a public link and observe more usage patterns.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在公共链接上部署这个代理，并观察更多的使用模式。
- en: Use the Agent with different source documents other than The Mahabharata.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用不同于《摩诃婆罗多》的源文档来使用该代理。
- en: Step 1 of the process is currently a simple ‘stuff’ QA chain that uses a vector
    store with the source text corpus. I am working to replace it with a ‘ReAct’ Agent
    so that other tools like search APIs, Wikipedia, moderation APIs etc., can be
    used in the research process.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过程的第1步目前是一个简单的‘stuff’ QA 链，它使用了一个包含源文本语料库的向量存储。我正在努力将其替换为‘ReAct’代理，以便在研究过程中可以使用其他工具，如搜索
    API、维基百科、审核 API 等。
- en: I am saving the data and metadata generated during every run to a `runs` vector
    store. I am also saving the embeddings of the original question to the same store.
    This has helped me follow the reasoning trail of the Agent and observe several
    logical patterns that emerge out of it. This can help tune the QA agent to follow
    a tighter reasoning path.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '-   我将每次运行生成的数据和元数据保存到一个`runs`向量存储中。我还将原始问题的嵌入保存到同一存储中。这帮助我跟踪代理的推理过程，并观察到其中出现的几个逻辑模式。这有助于调整QA代理，以跟随更紧密的推理路径。'
- en: Currently, the Research Agent exist after a fixed set of iterations. This works
    quite well for most questions. However, it might be better to dynamically decide
    on the number of iterations or an exit strategy based on the evolving context.
    I will work on an ‘analyser’ that can do this autonomously.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '-   目前，研究代理在经过固定的迭代次数后存在。这对大多数问题来说效果很好。然而，根据不断变化的背景，动态决定迭代次数或退出策略可能更好。我会开发一个能够自主完成这一任务的“分析器”。'
- en: The Agent works well for most types of questions, except for the meta-questions.
    For example, if I ask ‘Describe what happens in book 5 chapter 3’, the Agent struggles
    to answer. In future versions, I will include a self-query retriever with the
    ‘ReAct’ Agent to deal with such cases.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '-   这个代理对大多数类型的问题效果很好，但对元问题除外。例如，如果我问“描述第五卷第三章中发生了什么”，代理会很难回答。在未来的版本中，我将加入一个带有‘ReAct’代理的自查询检索器，以处理此类情况。'
- en: So far, I have tried the Agent only with the OpenAI GPT3.5 model. It costs me
    about $0.02 per run. I will soon try the Research Agent with a smaller model like
    Llama, that can be hosted locally.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '-   到目前为止，我只尝试了 OpenAI GPT3.5 模型的代理。每次运行的费用约为 $0.02。我很快会尝试使用像 Llama 这样可以本地托管的较小模型。'
- en: In the next article, I plan to write about my findings after implementing some
    of these updates. The larger idea is to create a top-notch Autonomous AI Research
    Agent that can excel at finding deeply researched answers to difficult questions.
    So, please feel free to suggest and if possible, partner with me to mature this
    further.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '-   在下一篇文章中，我计划写下在实施这些更新后的发现。更大的构想是创建一个顶尖的**自主人工智能研究代理**，能够在寻找深度研究的问题的答案方面表现出色。所以，请随时提出建议，如果可能，和我合作进一步完善。'
- en: I hope you find this article and the shared code helpful.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '-   希望你觉得这篇文章和分享的代码对你有帮助。'
- en: Thanks for reading.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '-   谢谢阅读。'
- en: I hope you find the AI Research Agent exciting and useful.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '-   希望你觉得这个人工智能研究代理既令人兴奋又有用。'
- en: The notebook I shared is just a simple implementation of this larger idea of
    creating an **Autonomous AI Research Agent**. A lot more can be done to make this
    Agent a top-notch researcher.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '-   我分享的笔记本只是创建一个**自主人工智能研究代理**这一更大构想的简单实现。为了使这个代理成为顶尖研究者，还有很多工作要做。'
- en: So, please feel free to suggest and if possible, partner with me to mature this
    further.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '-   所以，请随时提出建议，如果可能，和我合作进一步完善。'
- en: Thanks for reading.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '-   谢谢阅读。'
- en: Credits for the data sets I used in the above article, along with the licensing
    information.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '-   上述文章中使用的数据集的致谢以及许可证信息。'
- en: '[Complete Translation by K. M. Ganguli](https://en.wikipedia.org/wiki/Kisari_Mohan_Ganguli):
    Available in the public domain.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[K. M. Ganguli 的完整翻译](https://en.wikipedia.org/wiki/Kisari_Mohan_Ganguli)：可在公共领域获得。'
- en: '[Laura Gibbs Tiny Tales](https://microfables.blogspot.com/2020/11/tiny-tales-from-mahabharata.html):
    This is a retelling of the Mahabharata using two hundred episodes that are each
    100 words long. I am using her work here with her permission.'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '-   [Laura Gibbs Tiny Tales](https://microfables.blogspot.com/2020/11/tiny-tales-from-mahabharata.html)：这是对《摩诃婆罗多》的重述，使用了两百个每个100字长的故事。我在这里使用她的作品是经过她的许可。'
- en: '[Kaggle data repo by Tilak](https://www.kaggle.com/datasets/tilakd/mahabharata):
    All 18 Parvas of Mahabharata in text format for NLP. Shared with public domain
    license by [Tilak](https://www.kaggle.com/tilakd)'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '-   [Tilak 的 Kaggle 数据库](https://www.kaggle.com/datasets/tilakd/mahabharata)：18
    部《摩诃婆罗多》的文本格式数据用于 NLP。由[Tilak](https://www.kaggle.com/tilakd)以公共领域许可证共享。'
