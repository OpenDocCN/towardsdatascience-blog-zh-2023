- en: 'The Research Agent: Addressing the Challenge of Answering Questions Based on
    a Large Text Corpus'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ÂéüÊñáÔºö[https://towardsdatascience.com/the-research-agent-4ef8e6f1b741?source=collection_archive---------0-----------------------#2023-08-29](https://towardsdatascience.com/the-research-agent-4ef8e6f1b741?source=collection_archive---------0-----------------------#2023-08-29)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I made an **Autonomous AI Research Agent** that can answer difficult questions
    with deep multi-hop reasoning capabilities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://medium.com/@rahul.nyk?source=post_page-----4ef8e6f1b741--------------------------------)[![Rahul
    Nayak](../Images/9f8aa2f9af4e02b31c114222756489e5.png)](https://medium.com/@rahul.nyk?source=post_page-----4ef8e6f1b741--------------------------------)[](https://towardsdatascience.com/?source=post_page-----4ef8e6f1b741--------------------------------)[![Towards
    Data Science](../Images/a6ff2676ffcc0c7aad8aaf1d79379785.png)](https://towardsdatascience.com/?source=post_page-----4ef8e6f1b741--------------------------------)
    [Rahul Nayak](https://medium.com/@rahul.nyk?source=post_page-----4ef8e6f1b741--------------------------------)'
  prefs: []
  type: TYPE_NORMAL
- en: ¬∑
  prefs: []
  type: TYPE_NORMAL
- en: '[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F473e87f4b733&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-research-agent-4ef8e6f1b741&user=Rahul+Nayak&userId=473e87f4b733&source=post_page-473e87f4b733----4ef8e6f1b741---------------------post_header-----------)
    Published in [Towards Data Science](https://towardsdatascience.com/?source=post_page-----4ef8e6f1b741--------------------------------)
    ¬∑16 min read¬∑Aug 29, 2023[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F4ef8e6f1b741&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-research-agent-4ef8e6f1b741&user=Rahul+Nayak&userId=473e87f4b733&source=-----4ef8e6f1b741---------------------clap_footer-----------)'
  prefs: []
  type: TYPE_NORMAL
- en: --
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4ef8e6f1b741&operation=register&redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-research-agent-4ef8e6f1b741&source=-----4ef8e6f1b741---------------------bookmark_footer-----------)![](../Images/91b348b741ea57a92d2e3b954a304f27.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Image by the Author (Generated using Photoshop Generative fill)
  prefs: []
  type: TYPE_NORMAL
- en: '**Introduction to the problem**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 2021, I started working on the challenge of answering questions based on
    a large corpus of text. In the era before the pre-trained transformers, this problem
    was a tough one to crack.
  prefs: []
  type: TYPE_NORMAL
- en: And to my frustration, I started my experiments with one of the most complex
    and intricate stories ever written, The Mahabharata. For those unfamiliar with
    the work, the Mahabharata is a collection of 18 books with a total of about 1.8
    million words. It is the largest poem ever written with about 90,000 verses. It
    is roughly ten times the length of the Iliad and the Odyssey combined. But it
    is not only the length but also the breadth of Mahabharata that is staggering.
    Highly nonlinear and complex in its causes and effects, it has thousands of characters
    spanning seven generations, and out of those, not a single one is completely good
    or evil. It has profound philosophical commentaries on Duty (Karma), Choices and
    Human existence, especially on the conflicts of duties and the choices between
    multiple wrongs. The Bhagavad Gita (Key philosophy of Hinduism) is also a part
    of the 6th book of the Mahabharata.
  prefs: []
  type: TYPE_NORMAL
- en: I compiled the [Mahabharata text data](https://github.com/rahulnyk/mahabharata.git)
    from multiple sources online into a clean data set. However, I could not find
    a method to implement meaningful QA on the text.
  prefs: []
  type: TYPE_NORMAL
- en: In less than two years, all that changed.
  prefs: []
  type: TYPE_NORMAL
- en: The rapid advancements in AI and Large pre-trained transformers are changing
    the world of technology profoundly and fundamentally. And I am fascinated by it,
    much like most techies these days are.
  prefs: []
  type: TYPE_NORMAL
- en: So, a few months ago, I returned to the problem with a naive knowledge of the
    newborn art of prompt engineering. But this time with a general idea of making
    an **Autonomous** **Research Agent** that can work with any complex knowledge
    base.
  prefs: []
  type: TYPE_NORMAL
- en: The Mahabharata is one of the most complex use cases. However, in every domain
    of knowledge, Law, Scientific research, Education, Medical, etc., every project
    starts with deep research on the prior art. So the problem is worthy enough to
    solve.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Research Agent**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, I will discuss the design and implementation of an Autonomous **AI Research
    Agent** that can solve the problem of multi-hop KBQA with deep reasoning capability.
    I will share the git repo with an initial implementation of the research agent
    in a Python notebook. If you are interested only in that part, please feel free
    to skip to the Implementation section later in this article.
  prefs: []
  type: TYPE_NORMAL
- en: If you are interested in knowing more about AI Agent, ‚ÄòKnowledge-Based Question
    Answer‚Äô (KBQA), the ‚ÄòWhy‚Äô, the ‚ÄòWhat‚Äô, and the design evolution of the AI Research
    Agent, then please read along.
  prefs: []
  type: TYPE_NORMAL
- en: '**Why?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first question that one may ask is why not just use the ChatGPT interface
    and ask questions. It has been trained on a humungous volume of Internet data
    generated till 2021, so a text corpus like the Mahabharata is known to it.
  prefs: []
  type: TYPE_NORMAL
- en: That was my first approach. I asked the ChatGPT several questions about the
    Mahabharata. I got good answers to some questions. However, they lack the rigour
    for the most. And that is expected. The GPT is trained over general data sets.
    It can very well understand and interpret natural languages. It can also reason
    well enough. However, it is not an expert in any specific domain. So, while it
    might have some knowledge of The Mahabharata, it may not respond with deeply researched
    answers. At times the GPT may not have any answer at all. In those cases, it either
    humbly refuses to answer the question, or confidently makes them up (Hallucinations).
  prefs: []
  type: TYPE_NORMAL
- en: The second most obvious way to achieve KBQA is to use a Retrieval QA Prompt.
    Here is where LangChain starts being extremely useful.
  prefs: []
  type: TYPE_NORMAL
- en: '**Retrieval QA**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For those unfamiliar with the LangChain library, It is one of the best ways
    to use LLMs like GPT in your code. Here is an implementation of KBQA using LangChain.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa?source=post_page-----4ef8e6f1b741--------------------------------)
    [## QA using a Retriever | ü¶úÔ∏èüîó Langchain'
  prefs: []
  type: TYPE_NORMAL
- en: This example showcases question answering over an index.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: python.langchain.com](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa?source=post_page-----4ef8e6f1b741--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: To summarise, here are the steps to achieve KBQA on any body of documents
  prefs: []
  type: TYPE_NORMAL
- en: Split the knowledge base into text chunks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a numerical representation (Embeddings) for each chunk and save them
    to a vector database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*If your data is static, Steps 1 and 2 are one-time efforts.*'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Run a semantic search using the user‚Äôs query on this database and fetch relevant
    text chunks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Send these text chunks to the LLM along with the user‚Äôs questions and ask them
    to Answer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Here is a graphical representation of this process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/63234bd045fe01ff4f4ca296ff725645.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author created using draw.io
  prefs: []
  type: TYPE_NORMAL
- en: So why go any further? It seems like a solved problem!
  prefs: []
  type: TYPE_NORMAL
- en: Not quite üôÅ
  prefs: []
  type: TYPE_NORMAL
- en: This approach works well for simple questions on a simple and factual knowledge
    base. However, it does not work for a more complex knowledge base and more complicated
    questions that require deeper, Multi-hop, reasoning. Multi-hop reasoning refers
    to a process in which multiple steps of logical or contextual inference are taken
    to arrive at a conclusion or answer to a question.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, the LLMs are limited in the length of text they can chew in one prompt.
    You can, of course, send the documents one at a time and then ‚Äòrefine‚Äô or ‚Äòreduce‚Äô
    the answer with every call. However, this approach does not allow for complex
    ‚Äòmulti-hop‚Äô reasoning. In some cases, the results using the ‚Äòrefine‚Äô or ‚Äòreduce‚Äô
    approach are better than simply stuffing all the documents in a single prompt,
    but not by a high margin.
  prefs: []
  type: TYPE_NORMAL
- en: For a complex knowledge base, the users‚Äô question by itself may not be enough
    to find all the relevant documents that can help the LLM arrive at an accurate
    answer.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: Who was Arjuna?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is a simple question and can be answered with limited context. However,
    the following question:'
  prefs: []
  type: TYPE_NORMAL
- en: Why did the Mahabharata war happen?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is a question that has its context spread all across the text corpus. The question
    itself has limited information about its context. To find the relevant chunks
    of text and then to reason based on that may not work.
  prefs: []
  type: TYPE_NORMAL
- en: So what next?
  prefs: []
  type: TYPE_NORMAL
- en: '**AI Agents**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is one of the coolest concepts that has emerged after the advent of AI.
    If you don‚Äôt know the concept of an AI Agent, I can‚Äôt wait to explain it to you,
    but I may still fail to convey its awesomeness. Let me use ChatGPT to explain
    it first.
  prefs: []
  type: TYPE_NORMAL
- en: An AI agent, also known simply as an ‚Äúagent,‚Äù refers to a software program or
    system that can autonomously perceive its environment, make decisions, and take
    actions to achieve specific goals. AI agents are designed to mimic human-like
    behaviour in problem-solving and decision-making tasks. They operate within a
    defined environment and interact with that environment to achieve desired outcomes.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Simply speaking, an Agent is a program that takes a problem, decides how to
    solve it, and then solves it. The Agent is provided with a set of tools like Functions,
    methods, API calls, etc. It can use any of them if it chooses to do so in any
    sequence it deems fit. Contrast this to conventional software, where the sequence
    of steps needed to solve the problem is pre-programmed. This is, of course, a
    very vague definition. But you probably get the hang of it by now.
  prefs: []
  type: TYPE_NORMAL
- en: Here are the two different agents I tried for our KBQA use case.
  prefs: []
  type: TYPE_NORMAL
- en: '***React*** This Agent uses a [‚ÄòReAct‚Äô (Reason and Action) style of reasoning](https://www.promptingguide.ai/techniques/react)
    to decide which tool to use for the given problem.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the langChain implementation of a ReAct Agent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://python.langchain.com/docs/modules/agents/agent_types/react?source=post_page-----4ef8e6f1b741--------------------------------)
    [## ReAct | ü¶úÔ∏èüîó Langchain'
  prefs: []
  type: TYPE_NORMAL
- en: This walkthrough showcases using an agent to implement the ReAct logic.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: python.langchain.com](https://python.langchain.com/docs/modules/agents/agent_types/react?source=post_page-----4ef8e6f1b741--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: 'I provided the Agent with the following tools to choose from:'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval QA chain with a document store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Character Glossary search (I created a glossary with Named Entity Recognition
    using a pre-trained model)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wikipedia search.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The react agent did not give me good results and failed to converge to any answer
    most of the time. It does not work well with GPT 3.5\. It may work better with
    GPT 4, which is 20 -30 times more expensive than GPT 3.5, so that may not be an
    option yet.
  prefs: []
  type: TYPE_NORMAL
- en: Even when it converged, I could not get good results. Someone more knowledgeable
    in creating ‚Äòreact‚Äô prompts probably would have done better.
  prefs: []
  type: TYPE_NORMAL
- en: '***Self-Ask Agent*** This agent asks follow-up questions based on the original
    question and then tries to find the intermediate answers. Using these intermediate
    answers, it finally arrives at a final answer. Here is an article explaining the
    Self-Ask Agent'
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://cobusgreyling.medium.com/self-ask-prompting-d0805ea31faa?source=post_page-----4ef8e6f1b741--------------------------------)
    [## Self-Ask Prompting'
  prefs: []
  type: TYPE_NORMAL
- en: Self-Ask Prompting is a progression from Chain Of Thought Prompting. Below are
    a few practical examples and an‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: cobusgreyling.medium.com](https://cobusgreyling.medium.com/self-ask-prompting-d0805ea31faa?source=post_page-----4ef8e6f1b741--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: This approach gave me some good results. It works well for a Single-hop reason.
    But even this fails for questions that require multiple hops.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Who killed Karna, and why?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is relatively easy to answer with this approach
  prefs: []
  type: TYPE_NORMAL
- en: The question
  prefs: []
  type: TYPE_NORMAL
- en: Why did Arjuna kill Karna, his half-brother?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Is much more difficult to answer. It requires the LLM to know the fact that
    Arjuna did not know that Karna was his half-brother. The LLM can‚Äôt know that it
    needs to know this fact, either by understanding the question or by asking further
    questions based on the original question.
  prefs: []
  type: TYPE_NORMAL
- en: '**Human Research Process**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Quoting GPT again
  prefs: []
  type: TYPE_NORMAL
- en: AI agents are designed to mimic human-like behaviour in problem-solving and
    decision-making tasks
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So, my next idea was to research how humans research, the meta-research if you
    like. I imagined myself sitting in a library (College nostalgia) with easy access
    to all the books relevant to the topic of my research. I took a notebook and a
    pen and started jotting down the process I follow when I research a topic.
  prefs: []
  type: TYPE_NORMAL
- en: Here is what I came up with.
  prefs: []
  type: TYPE_NORMAL
- en: '**Research methodology:**'
  prefs: []
  type: TYPE_NORMAL
- en: Note down the original query on a page.
  prefs: []
  type: TYPE_NORMAL
- en: I try to answer the current question by reading a few books. In the process,
    I make a few notes and bookmark a few excerpts that I find most relevant to the
    current question.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Invariably, I find many unknowns in these excerpts. I note these unknowns and
    write down a few more questions that can help me learn about these unknowns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Out of these questions, I choose one question that is most pertinent to the
    original question.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I go back to step 1
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After a few such iterations, I ask myself if I have enough information to answer
    the original question.
  prefs: []
  type: TYPE_NORMAL
- en: If yes, then job well done!
  prefs: []
  type: TYPE_NORMAL
- en: If no, then toil on.
  prefs: []
  type: TYPE_NORMAL
- en: Voila!
  prefs: []
  type: TYPE_NORMAL
- en: Finally, I knew what to code. I hoped that, with some prompt engineering, this
    process could give me more profound answers than any of the other approaches I
    have tried previously.
  prefs: []
  type: TYPE_NORMAL
- en: Spoiler alert‚Ä¶ it did! :)
  prefs: []
  type: TYPE_NORMAL
- en: Before sitting down to code, I searched the internet for similar ideas. And
    I discovered the BabyAGI. What a wonderful world!
  prefs: []
  type: TYPE_NORMAL
- en: Here is a repo describing [the BabyAGI](https://github.com/yoheinakajima/babyagi/tree/main)
  prefs: []
  type: TYPE_NORMAL
- en: I realised there were many similarities between BabyAGI and the above research
    process. So with gratitude, I took some inspiration from the prompts used in the
    BabyAGI implementation.
  prefs: []
  type: TYPE_NORMAL
- en: '**The Research Agent ‚Äî Implementation**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here is the same process converted to a flow chart using the amazing [draw.io](http://draw.io)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e2834b738664984ebb9d6b3b0eb5d794.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by the Author (Generated using draw.io)
  prefs: []
  type: TYPE_NORMAL
- en: Every blue box in this chart is a call to an LLM.
  prefs: []
  type: TYPE_NORMAL
- en: '**Components**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**QA Agent ‚Äî** Search for answers and further context'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is a simple ***‚Äòstuff‚Äô*** Retrieval QA chain that uses a vector store.
    In the future, this can be an AI Agent that uses tools like vector stores, search
    APIs or Wikipedia APIs, Moderation APIs and previous research data. The prompt
    here is tuned to generate succinct answers based on the 1\. The context (documents),
    and 2\. the pertinence to the ***original question***.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Except for the first loop, the ***current question*** is always an intermediate
    question generated in step 2 and chosen in step 3\. The Agent appends the intermediate
    answer to the notes and the latest excerpts (the documents used to answer the
    ***current question***) to the bookmarks. The most recent of these documents are
    utilised in step 2.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Question Generator ‚Äî** Ask more questions based on fresh notes'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here, the agent uses the most recent vector search results matching the ***current
    question*** and uses them to generate more questions pertinent to the ***original
    question***. It appends these questions to the list of ***unanswered questions***.
    The prompt here is tuned such that the newly generated questions do not overlap
    with the existing list of questions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Most Pertinent Question Picker ‚Äî** Pick one question most pertinent to the
    original question'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This prompt picks one question from the list of unanswered questions that is
    the most pertinent to the ***original question***. This question is used as the
    ***current question*** for the next loop.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the next loop, the agent removes this question from the list of ***unanswered
    questions*** after generating a fresh set of questions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Analyser ‚Äî** Do I know enough?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I am using a ***max_iterations*** parameter to exit the loop. This works pretty
    well for now. However, it might be better to dynamically decide on the number
    of iterations or an exit strategy based on the evolving context. I will work on
    an ‚Äòanalyser‚Äô that can do this autonomously in the future.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Research Compiler ‚Äî** Compile the research'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This is the final prompt. It uses the notes made during the research process
    to arrive at an elaborate `final answer` to the `original questions`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Results**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Research Agent is a big improvement over all the previous approaches I have
    tried. It yields more detailed and accurate answers than any other approach. I
    have been playing with this for a few weeks now, and I am surprised by the richness
    of the answers I get.
  prefs: []
  type: TYPE_NORMAL
- en: The Agent avoids the problem of hallucinations to a greater extent than any
    previous approach. It autocorrects the hallucinations and the factual errors it
    generates in the first few iterations, during later ones. The deeper it gets into
    a problem, the more accurately it yields the result.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example run.
  prefs: []
  type: TYPE_NORMAL
- en: 'Questions: *Why did the Pandavas have to go live in the forest for 12 years?*'
  prefs: []
  type: TYPE_NORMAL
- en: Output ‚Äî
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b47104951fa815be1000dafbcc2a7428.png)'
  prefs: []
  type: TYPE_IMG
- en: Just in case you are curious, here is the final answer
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This answer is quite an elaborate one. But the beauty of the agent is not just
    that it answered the original question accurately but that it went further and
    found out the story surrounding the question.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, the answers I get are rich in such details. And every such answer
    inspires my curiosity for further enquiry.
  prefs: []
  type: TYPE_NORMAL
- en: The Agent also yields a set of ***answered questions*** and **unanswered questions**
    that it notes down during the research process. So after every run, it leads me
    to many other questions that I can ask. In the past few weeks, I have learned
    more about the Mahabharata than I did in many years before that.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Imagine following the same process for other domains of knowledge, quite an
    exhilarating thought!
  prefs: []
  type: TYPE_NORMAL
- en: '**The Code**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: And here are the Python notebooks with the implementation of the Research Agent.
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/rahulnyk/research_agent?source=post_page-----4ef8e6f1b741--------------------------------)
    [## GitHub - rahulnyk/research_agent'
  prefs: []
  type: TYPE_NORMAL
- en: Contribute to rahulnyk/research_agent development by creating an account on
    GitHub.
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/rahulnyk/research_agent?source=post_page-----4ef8e6f1b741--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: The Git repository of the Mahabharata dataset
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://github.com/rahulnyk/mahabharata?source=post_page-----4ef8e6f1b741--------------------------------)
    [## GitHub - rahulnyk/mahabharata: Mahabharata text compiled from multiple sources,
    split into chunks‚Ä¶'
  prefs: []
  type: TYPE_NORMAL
- en: Mahabharata text is compiled from multiple sources, split into chunks, and parsed
    into CSV files with metadata. Named entities‚Ä¶
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: github.com](https://github.com/rahulnyk/mahabharata?source=post_page-----4ef8e6f1b741--------------------------------)
  prefs: []
  type: TYPE_NORMAL
- en: '**What next?**'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The current implementation is a simple version of the idea of an autonomous
    AI Research Agent. I turned the research process several times throughout the
    implementation of the Agent. It has been an exciting journey, but the fun is not
    over yet. Here are some of the enhancements I am currently working on.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy this agent on a public link and observe more usage patterns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the Agent with different source documents other than The Mahabharata.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 1 of the process is currently a simple ‚Äòstuff‚Äô QA chain that uses a vector
    store with the source text corpus. I am working to replace it with a ‚ÄòReAct‚Äô Agent
    so that other tools like search APIs, Wikipedia, moderation APIs etc., can be
    used in the research process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I am saving the data and metadata generated during every run to a `runs` vector
    store. I am also saving the embeddings of the original question to the same store.
    This has helped me follow the reasoning trail of the Agent and observe several
    logical patterns that emerge out of it. This can help tune the QA agent to follow
    a tighter reasoning path.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Currently, the Research Agent exist after a fixed set of iterations. This works
    quite well for most questions. However, it might be better to dynamically decide
    on the number of iterations or an exit strategy based on the evolving context.
    I will work on an ‚Äòanalyser‚Äô that can do this autonomously.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Agent works well for most types of questions, except for the meta-questions.
    For example, if I ask ‚ÄòDescribe what happens in book 5 chapter 3‚Äô, the Agent struggles
    to answer. In future versions, I will include a self-query retriever with the
    ‚ÄòReAct‚Äô Agent to deal with such cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, I have tried the Agent only with the OpenAI GPT3.5 model. It costs me
    about $0.02 per run. I will soon try the Research Agent with a smaller model like
    Llama, that can be hosted locally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next article, I plan to write about my findings after implementing some
    of these updates. The larger idea is to create a top-notch Autonomous AI Research
    Agent that can excel at finding deeply researched answers to difficult questions.
    So, please feel free to suggest and if possible, partner with me to mature this
    further.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you find this article and the shared code helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading.
  prefs: []
  type: TYPE_NORMAL
- en: I hope you find the AI Research Agent exciting and useful.
  prefs: []
  type: TYPE_NORMAL
- en: The notebook I shared is just a simple implementation of this larger idea of
    creating an **Autonomous AI Research Agent**. A lot more can be done to make this
    Agent a top-notch researcher.
  prefs: []
  type: TYPE_NORMAL
- en: So, please feel free to suggest and if possible, partner with me to mature this
    further.
  prefs: []
  type: TYPE_NORMAL
- en: Thanks for reading.
  prefs: []
  type: TYPE_NORMAL
- en: Credits for the data sets I used in the above article, along with the licensing
    information.
  prefs: []
  type: TYPE_NORMAL
- en: '[Complete Translation by K. M. Ganguli](https://en.wikipedia.org/wiki/Kisari_Mohan_Ganguli):
    Available in the public domain.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Laura Gibbs Tiny Tales](https://microfables.blogspot.com/2020/11/tiny-tales-from-mahabharata.html):
    This is a retelling of the Mahabharata using two hundred episodes that are each
    100 words long. I am using her work here with her permission.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Kaggle data repo by Tilak](https://www.kaggle.com/datasets/tilakd/mahabharata):
    All 18 Parvas of Mahabharata in text format for NLP. Shared with public domain
    license by [Tilak](https://www.kaggle.com/tilakd)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
